An Integrated UnderstanderRoger  C. SchankMichae l  Lebowi tzLawrence  B i rnbaumDepar tment  of Computer  ScienceYale UniversityNew Haven,  Connect icut  06520A new type of natural language parser is presented.
The idea behind this parser isto map input sentences into the deepest form of the representation of their meaningand inferences, as is appropriate.
The parser is not distinct from an entire understand-ing system.
It uses an integrated conception of inferences, scripts, plans, and otherknowledge to aid in the parse.
Furthermore, it does not attempt to parse everything itsees.
Rather, it determines what is most interesting and concentrates on that, ignoringthe rest.1.
Overview of Conceptual Dependency ParsingOver the course of the last ten years, researchersin our project have designed and programmed alarge number of parsers.
The task of these parserswas the initial mapping of natural language into aninternal representation.
(Note that the first phase ofthe understanding process traditionally refers to thediscovery of the syntactic form of the input.
Howev-er, the term "parsing" can just as meaningfully beapplied to whatever the first phase of understandingmight be.)
In this paper we will discuss some of theproblems which have arisen in the development ofparsers, and present a new theory of the way pars-ing works in the normal reading process.
We willdescribe a program which implements this theoryand understands newspaper stories about terrorism.All our parsers were programs that mapped Eng-lish sentences into the Conceptual Dependency(CD) representation of their meaning.
Underlyingtheir construction was always the methodologicalassumption that the parsing algorithm that they wereto employ was to be as psychologically correct aspossible.
Thus, our parsers are intended to modelthe way we believe people parse.
This methodologi-cal assumption brought with it an operating principlewhich was (with one exception to be discussed later)always followed, namely that the parsing algorithmwas a left-to-right, one-pass operation without back-tracking.
These parsers were not designed to handletrue "garden path" sentences where people have tobacktrack.The first parser that we worked on (Schank andTesler, 1969), used what we called "realizationrules" to map English syntactic structures into CD.
(This term was taken from Lamb (1966) and signi-fied that we were mapping from one linguistic levelto another.)
The primary problem with this parserwas that it violated our methodological goal of mod-eling human processes.
For many English sentencesthat were ambiguous, the algorithm we used exhibit-ed no clear preference for one interpretation overanother, even though people clearly had such prefer-ences.In Schank et al (1970) we proposed a solutionto remedy this problem in the design of a new par-ser which we called SPINOZA II.
SPINOZA II wasto use the CD representat ion itself to drive theparse.
That is, during the parsing process, the mean-ing that had been understood up to any point wouldhelp in the determination of the meaning of the restof the sentence.
This idea brought with it the con-comitant idea that, since meaning would be drivingthe parse, we really might not have to rely verymuch on syntax to do our parsing.
(Wilks (1973)was working on a similar idea at the same time andhis view helped to support our own belief in thefeasibility of the idea.)
We did not believe that wecould avoid syntax altogether.
Rather, it was ourview that relying on meaning considerations firstwould drastically reduce our parsers' dependence onsyntax.Copyright 1980 by the Association for Computational Linguistics.
Permission to copy without fee all or part of this material isgranted provided that the copies are not made for direct commercial advantage and the Journal reference and this copyrightnotice are included on the first page.
To copy otherwise, or to republish, requires a fee and/or specific permission.0362-613X/80/010013-18501.00American Journal of Computational Linguistics, Volume 6, Number 1, January-March 1980 13Roger C. Schank, Michael Lebowitz, and Lawrence Birnbaum An Integrated UnderstanderWhile these parsers were being developed, otherresearchers were devising methods for parsing natu-ral language input into an internal representation.Most of these methods concentrated on the syntaxof sentences.
One very popular technique has beenthe Augmented Transition Network (ATN).
Parsersof this sort have been discussed in Thorne, et.
al.
(1967), Bobrow and Fraser (1969), Woods (1969)and Kaplan (1975).
A parser strongly related toATN's is in Winograd (1972).
ATN's have tendedto deal primarily with syntax, perhaps occasionallychecking a few simple semantic properties of words.Even more closely tied to syntax are the parsersbased on Transformational Grammar, such as Plath(1974).
A more recent parser which views syntax asan isolatable sub-part of language understanding isin Marcus (1979).
The important thing to noteabout all of these programs is that they view syn-tactic parsing as a process totally isolated from therest of understanding.
Syntax drove these systems,although in some cases the syntactic parser was al-lowed to request semantic information.
Some speechunderstanding systems, Hearsay-I I  in particular(CMU Computer Science Speech Group, 1976) usea more integrated approach, but they are only mar-ginally concerned with the level of processing thatwe are interested in.
Our view has always stressedthe integration of semantics and syntax in parsing.SPINOZA II was only partially finished when itwas abandoned for reasons other than academicones.
A few other attempts were made at starting itup again until Chris Riesbeck designed a parser thatwas similar in spirit, but different in form from SPI-NOZA II (see Riesbeck, 1975).
His program wasbased on what he termed requests, a form of prod-uctions (see Newell, 1973).
Requests were activat-ed whenever expectations about some syntactic orsemantic information could be made, and were exec-uted if the expectations they embodied came true.Thus, expectations guided the parse, makingRiesbeck's system, later called ELI, very top down(see Riesbeck and Schank, 1976).ELI was used as a front end to SAM our script-based understanding system (Schank et al, 1975and Cullingford, 1978), and was combined withGershman's (1977) work on noun groups to providea parser that could handle very complex sentences.One of the major problems with ELI  is its fragili-ty.
Granger (1977) designed FOUL-UP,  an adjunctto ELI  which determines the meaning of unknownwords in context, and this produced a more robustparser.
But, in actual day-to-day use, students haveoften found it simpler to design special purpose par-sers patterned after EL/  that are less cumbersomeand easier to use.
Carbonell 's (1979) POLITICSprogram, a model of subjective understanding ofpolitical events, for example, uses a parser that issimilar to ELI, but was written by Carbonell him-self.Perhaps the most important feature ofCarbonell's work is that it has pointed out to therest of us a major flaw in our reasoning behind thedesign of large understanding systems.
We havealways leaned in the direction of modularity in thedesign of our programs, both because this has al-ways been considered good programming style, andbecause, since our systems are very large, each sepa-rate module has often been the work of a differentperson.But, this modularity has caused a number ofproblems.
Any understanding system that we build,for example, should ideally use ELI as a front end.But ELI  is a very large and cumbersome program towork with.
Furthermore, there is another practicalproblem, namely that the vocabulary for any newdomain to be handled by some system we set up isunlikely to be already present in ELI.
Since in ELIthe definitions of words are in a sense programsthemselves, any new system will require the writingof a large part of its parsing program from scratch inany case.
This practical problem leads to a muchmore interesting issue.
In the same way that we real-ized years ago that it was important o take advan-tage of the power of the CD representations availa-ble to us to build a more integrated parsing system,any new parser designed for a new system should, inprinciple, take advantage of the higher level under-standing processes that are a part of the new sys-tem.
Thus, POLITICS can parse more effectively ifit can use not only the partially constructed CDrepresentation of what it has already understood,but also its place in the ideology it is using, its over-all significance, and so on.
That is, modularity is, inan important sense, a disadvantage.
Why not capi-talize on everything that is available to help parsingalong?
People are no more likely to use only syntaxand some particular notions of meaning (but notothers) to help in the parsing than they are to useonly syntax.
Understanding is a completely inte-grated process.
The idea of building modular sys-tems has hampered advances in parsing, because thefull range of our knowledge should obviously beavailable to help disambiguate, find appropriateword senses, and just as importantly (as we shall seelater in this paper) to help us know what to ignore.It should be emphasized what we mean when wesay that modularity was a handicap in parser devel-opment.
Clearly from a programming point of viewour parsers must be modular.
However, if modulesseem to be spending all of their time communicatingwith each other, then the particular modularizationscheme must be suspect - the modules really form anintegrated unit.
Since communicating amongst mo-dules tends to be hard, the tendency is to avoid it.14 American Journal of Computational Linguistics.
Volume 8, Number 1, January-March 1980Roger C. Schank, Michael Lebowitz.
and Lawrence Birnbaum An Integrated UnderstanderThis can result in processes which should interactstrongly becoming isolated from each other.
This iswhat happened with the modularization strategy wehave described.2.
Paying Attention To Less Than EverythingOne of the major problems with SAM, and alsowith EL I  as a part of SAM, was its inability to han-dle texts for which it was unprepared.
A new vocab-ulary item, domain of discourse, or previously unen-countered syntactic construction could, and oftenwould, throw things into disarray.
One of the out-puts produced by SAM was a summary of what ithad read.
It seemed to us that we could produceessentially the same output with a much more robustand much faster program, FRUMP (DeJong, 1977).FRUMP does not process every word of every storythat is input.
Rather, it has embodied within it atheory of skimming that guides it in what it is read-ing.
FRUMP skims for what it is interested in - usu-ally the items of information it wishes to include inits summary for any particular domain that it hasknowledge about.
FRUMP is thus a highly top-downsystem and for this reason it cannot be consideredas a replacement for SAM.
SAM could, in principle,respond to inputs it was unprepared for, although inpractice this did not happen very often!
FRUMPcannot respond to aspects of stories it is unpreparedfor; but then neither is it unable to process suchstories at all.For our purposes here however, what is particu-larly interesting about FRUMP is that it is an exam-ple of a working, robust, integrated (that is, non-modular) system.
FRUMP's  parser is virtually indis-tinct from its inferencer.
The reason is simple.FRUMP knows what it needs to find in a story.
Ithas rules for how to find these things, which can beeither inference rules or parsing rules.
But suchrules are really just the low-level manifestations ofhigher level decisions that have been made on thebasis of many considerations, only some of whichare related to parsing.
FRUMP works as well as itdoes because its interests guide what it looks for.
Itcan ignore what it is not interested in and concen-trate on what it wants to know.Now let's consider how a normal, literate adultreads a story, a newspaper story, for instance.
Wehave considered seriously the question of whether ahuman reads in detail, like SAM, or skims, likeFRUMP,  in his normal reading mode.
And, althoughwe possess no hard evidence one way or the other,we now feel that a human is more FRUMP-l ike thanwe previously believed.
If this is true, it has impor-tant implications about what a parser ought actuallyto look like.
We are not suggesting that FRUMP'sparser is adequate.
Clearly it is not, as it misses sig-nificant aspects of many stories.
On the other hand,some kind of combination of FRUMP parsing andEL I  parsing might make for a very powerful androbust system for story understanding.3.
Time of Processing in ParsingOne of the major factors to be considered indiscussions of the design of a human-like parser isthe speed with which humans can read text.
Consid-ering all the inferences and bringing in of back-ground knowledge and other problems that an un-derstander must deal with in the course of readingor listening to a sentence, people are very fast at thejob.
They finish understanding, for the most part,as soon as the sentence they are hearing is finishedbeing uttered.
This implies that the amount of timethat they have available for inferencing and knowl-edge application cannot wait until the end, afterparsing is finished.
Rather, such additional process-es must be going on at the same time as parsing isgoing on.
This is confirmed by psychological evi-dence such as Marslen-Wilson (1975) which useserrors in the shadowing of sentences to show high-level processing must be occurring throughout hereading of a sentence.
Such a conclusion certainlymakes the argument we were stating above muchmore significant.
It implies that human processes arehighly integrated.
That is, people must be inferringfrom the early parts of a sentence before they evenhear the latter parts of the sentence.
If this is so,then it also follows that people will make use ofwhatever else they discover, thus allowing wordsense identification, etc., to be affected by higherlevel processes.
Thus, as models of human process-ing, parsers that first do their job completely andthen send their results off to inferencers make nosense.There is a further consequence to this as well.We must ask ourselves when this non-parsing typeprocessing takes place.
There are two possible an-swers.
Either people employ parallel processes and itall goes on at the same time, or if processing is seri-al, space must be being made to do this work at theexpense of something else.
This something else islikely to be the complete processing of every wordthat is seen.
That is, in the serial view, not all wordsare equal.
Some words get a lot of the processingtime (those that have great syntactic, semantic andinferential importance for example) and others hard-ly get noticed.Now the question of whether the serial or paral-lel explanation is correct is really not resolvablehere.
However,  even with some parallel processing,it seems plausible that the total processing capabilityavailable at any one time for use in understandingmust have some bounds, and that the speed of inputmust often overwhelm those bounds.
Thus we areAmerican Journal of Computational Linguistics, Volume 6, Number 1, January-March 1980 15Roger C. Schank, Michael Lebowitz, and Lawrence Birnbaum An Integrated Understanderstill left with the necessity of processing some wordsat the expense of others.The serial explanation, then, presumes a model ofparsing which is in some places incomplete.
As wehave discussed elsewhere (Sehank, 1975, for in-stance), the process of doing a complete parse isextremely complex.
Simply stated, it takes n milli-seconds to read a word and it takes m milli-secondsto completely process a word.
Since it seems quitelikely that m is much larger than n in ordinaryspeech and reading, and since words come instreams in ordinary speech and reading, then it isobvious that people cannot be completely processingevery word they hear.
What is more likely the caseis that they are deciding what to pay serious atten-tion to and what to pay casual attention to as theygo.
Such decisions can be explained on the basis ofmany factors.
One most obvious one is interest.That is, people are liable to pay attention to (that is,devote their processing time to)  what interests them.We have discussed the concept of interest and itsramifications for the inference problem in Schank(1978).
The main conclusion there was that infer-ence is controlled by interest.
This is likely also tobe true in this revised view of the parsing processthen because we are now viewing the entire under-standing process as an integrated phenomenon.Consider the following sentence:A small twin engine airplane carrying federalmarshals and a convicted murderer who wasbeing transported to Leavenworth crashedduring an emergency landing at O 'Hare  Air-port yesterday.Intuitively, some parts of this sentence are moreinteresting than others.
But more than that, it iscrucial, according to the idea stated above with re-spect to the amount of processing time available,that the processing of some words must take lesstime than the time it takes to read or hear them.Now at first glance this may seem a bit bizarre.How can a word be processed in less time than ittakes to read or hear it if reading or hearing it is apart of that processing?
Yet we are in precisely thisparadoxical situation if we hold to the idea that theprocessing of any one word in a sentence can takelonger than the time it takes to read or hear it, sinceit takes no longer to process an entire sentence thanit does to hear it and since the individual wordscome in at such a rate that there is no time betweenthem in which to process.
(This is obviously thecase since just finding the word boundaries in a sen-tence is a very complex task because the speechstream is continuous.
)Since the amount of processing time available islimited by the rate of flow of the input (which iscontinuous for speech), then some words are proba-bly not being processed at all (or in any case theyare processed so partially that they are hardly seen).Since the most important words often come at theend of a phrase, the preceding words may be virtual-ly ignored until they can be 'gathered up' right toleft.
Then top down processing helps the understan-der know what to ignore.
According to this scheme,words are stored in a buffer and virtually ignoreduntil a word that initiates processing is found.
Whensuch a word is found, the words in the buffer aregathered up and their analysis completed.
Wordswhich initiate processing usually appear at the endof phrases or breath groups.In order to process a noun phrase such as "smalltwin engine airplane" then, we must assume that aprocessor virtually ignores all the words until'airplane',  simply marking their existence in shortterm memory for retrieval after the head noun isfound.
Once we know that 'airplane' is the subjectof the sentence, expectations can be generated thatallow us to have a better idea of what to look for(and therefore of what to ignore).
For example, themeaning of 'carrying' can be virtually ignored, sinceas we are only beginning to recognize what word itis, we hear about the marshals and the murderer anddecide to pay attention to those items.The point here is that we are really not seeingthings one word at a time, but rather since we areseeing a continuous tream we can pick out what wefind interesting, go back to discover just those rela-tionships that connect together what we are interest-ed in and virtually ignore the rest.
Do we care thatthe verb 'carrying' was used instead of 'containing',or that the construction used was not "in which theywere flying"?
We have already predicted that therelationship between the peop le  and the airplanewas containment because that is what it ordinarilyis.
We need only confirm the fact that nothing con-tradicts this prediction and this can be done on thefly.
Under this theory there is little wonder at thefact that understanders frequently cannot rememberthe actual words that they read.
They may neverhave actually read them at all!A theory of partial parsing then, says that mostwords are barely noticed until some reason is foundto pay attention to them.
A major issue in our theo-ry then is how we know what words we must payattention to and begin to process seriously.If certain elements of language are skipped en-tirely, or processed only slightly in the course ofnormal understanding, one might ask why they ap-pear at all.
Why doesn't the author just omit them?The answer to this is that the same story can beunderstood by different readers with varying degreesof completeness.
It is possible for a reader payingattention to every detail of a story to discovernuances that a partial understander like the one we16 American Journal of Computational Linguistics, Volume 6, Number 1, January-March 1980Roger C. Schank, Michael Lebowitz, and Lawrence Birnbaum An Integrated Understanderare describing would miss.
However,  it is our beliefthat most of the time, when dealing with media suchas newspapers, people do not do extensive process-ing, and yet are able to extract the vast majority ofinformation of interest.
That is the process we areattempting to model here.
We do not claim that itrepresents the only level of processing a person canuse, but we do believe it is a very important andwidely used level of understanding.
(There is an aside that is worth making at thispoint.
We have talked over the years about howexpectations drive various parts of the understandingprocess (Riesbeck, 1975 and Cullingford, 1978 forexample).
The contrast here is between expectation-based processes and interest-driven processes.
Obvi-ously the most powerful and important mechanismsavailable to an understander are both expectationand interest driven at the same time.
)Reasons for completely processing a given wordoccur at all levels of the system.
Some of these are:parser expectations: if the parser expects a certainkind of word, the satisfaction of that expectationcan be taken as an extremely important force in theparser.
Thus, a parser might function best that ex-pected certain syntactic or conceptual types to theextent that it ignored everything else until it foundthem.
This is again a violation of the idea of left toright parsing since a parser might not become inter-ested in something until it had already passed it,ignored it, and then seen an item that caused expec-tations to be raised that could only be satisfied bychecking backwards.syntax: main nouns in a noun phrase can cause aprocessor to try to gather up its modifiers for whichthere is a need or interest.
Certain function wordscause words to be paid attention to if their interestvalue has been predicted.
Thus, ' to'  is noticed to theextent that it can focus attention on the followinghead noun if it has already been determined that alocation is expected and desired.interest values: how does the parser decide what i twants to pursue?
Obviously we need a fully inte-grated system where the parser and memory talkduring the parsing of a sentence.
Without such inte-gration, there would be no overriding reasons fornoticing one thing and not another.
It is the role ofepisodic memory and world knowledge to inform theparser of what to pay attention to.
Interest valuesare stored in memory as part of the knowledge asso-ciated with concepts.
Certain concepts are nearlyalways interesting, others are interesting in certaincircumstances.
More importantly, certain things areinteresting on the basis of what has preceded them -interestingness i a dynamic property.
Thus, theobject of a shooting might be expected to be moreinteresting if the shooting took place in an embassyas opposed to a generally low-interest location suchas a bar.
(But of course, contexts can be createdwhere bars can be very important.
This is why it isnecessary to have a dynamic memory available asopposed to just a dictionary.
)top level expectations: if we are reading about anevent that fits into a high level knowledge structuresuch as a script or a plan, predictions from thatscript or plan can focus interest during the process-ing of a sentence.
Thus, we can know that the targetof an assassination and the identity of the assassinare of critical importance in reading a story about anassassination and we can thus focus in on thoseitems as top-down predictions during parsing.To see how all this is used consider the sentenceform "X went to visit Y": Memory is accessed tosee if X is interesting because it is a main noun andbecause it is a person.
When no information isfound, the processing should be faster than wheninformation is found.
Thus, when X is ' John'  or'Sam' we proceed quickly.
If X were 'HenryKissinger' or 'your mother'  we would presumablyproceed more slowly because more expectationsabout their behavior that are of interest would befound.
'Went'  is an item that urges us to continue proc-essing since it has no specific meaning in isolation.
(That is, we could have 'went crazy', 'went fishing','went to Boston',  and we can't  do anything until wesee the next words.
The theory here is why specu-late at all, just go on.)
'Visit' is a word that calls upa script ($VISIT) if the object of the visit is anequal or a family member.
But other scripts can becalled up by the word visit that are distinct from$VISIT.
If the object of visit is 'museum' or'Congress'  we would get quite different scripts oreven no available script at all.
(What script does'went to visit a mortuary'  bring up?)
Obviously, theproblem here is that 'visit' is also almost totally ig-nored since it too means very little.
Its real purposeis to get us interested in the object that followsnext.
That is, we don't  really start processing thissentence deeply until we see what Y is.
Then, if Ymeets certain criteria we instantiate $VISIT.
If Y isa member of the opposite sex, we have an ambigu-ous sentence in terms of script (and thus process-ing).
In that case, either $VISIT or the RO-MANCE script would be applicable, and we willnow want to figure out which.Notice that while most of the examples we havepresented, and those we will present, describe sto-ries in terms of scripts, there is no reason our proc-essing ideas could not be used to handle stories bet-ter represented by other knowledge structures, suchas plans and goals (Schank and Abelson, 1977, Wil-ensky, 1978).
In fact, we believe they will applygenerally to whatever is represented in memory.Scripts are prominent in our early development ofAmerican Journal of Computational Linguistics, Volume 6, Number 1, January-March 1980 17JRoger C. Schank, Michael Lebowitz, and Lawrence Birnbaum An Integrated Understanderour parsers, because the domain we are concentrat-ing on, newspaper stories, tends to involve manystereotypical situations.
However,  we expect to ex-tend this work to handle stories requiring differenttypes of representations.4.
An ExampleThe following is a sentence taken from a frontpage story in the New York Times:An Arabic speaking gunman shot his way intothe Iraqi Embassy here (Paris) yesterdaymorning, held hostages through most of theday before surrendering to French policemenand then was shot by Iraqi security officials ashe was led away by the French officers.We will now examine this sentence word by wordand consider the kind of processing we desire in anintegrated understanding scheme.
The  program wewill describe later does such processing.
Our modelwill skip the uninteresting parts and build up itsrepresentat ion when necessary, attempting to becompletely finished with each sub-part at the righttime.
That is, we desire that the model we proposebe finished processing only slightly after the inputhas been received - just as a person would do.One important point here is that although we willdiscuss this sentence in a left-to-right word-by-wordfashion, there is no real reason to believe that hu-man understanding goes one word at a time.
Actual-ly, words enter in chunks, both visually (in reading)and aurally (in speech).
We can thus process thesame way.
Thus, for example, the next word to beread is available for any word under consideration.Such an assumption can simplify the problem ofdisambiguation.
*****************************An Arabic speaking gunman...AN is a word that need only be saved initially.
Thismeans that it is looked up in the dictionary, andwhat is found there are instructions to go to thenext word and place AN in some form of short termmemory (STM) to be examined later.ARABIC is listed in the dictionary as a word that isskippable when it has been preceded by a skippableword, so it is skipped and placed in STM.
(ThatARABIC is skippable has already been determinedand is simply looked up.
The procedure for deter-mining what can be skipped is obviously one of theinteresting problems in the issue of the developmentof language ability.
(See Schank and Selfridge, 1977,for a discussion of these issues.)
In general, adjec-tives can be skipped, though not all can be.
In par-ticular, 'Russian' could not be skipped because itcan also be an actor.
Also, adjectives designated asinteresting may not be skipped, i. e. 'disgusting','murderous',  lecherous', etc.
)SPEAKING is also skippable as long as no potentialactors have been so far encountered.
A search forACTORs in STM finds none, so this word is alsoskipped.GUNMAN is marked as an ACTOR,  as a NOUN,and as a H IGH INTEREST ACTOR.
The fact thatwe have a H IGH INTEREST word causes us tocreate top-down requests to fill in certain informa-tion, in particular we now want to know the answersto the following questions:WHO is he?
.
.
.
.
causes us to gather up stacked ad-jectives (e.g.
ARABIC)  and add them to thememory token for this GUNMANWHAT did he do?
.
.
.
.
this is answered by an itemfound on the token for GUNMAN,  namelySHOOT.
Thus, an inference that the gun-man shot or will shoot somebody is madehere before anything else comes in as inputWHOM did he shoot?
.
.
.
.
causes us to be interestedin the syntactic object of the verb which weassume will be SHOOTWHY did he shoot?
.
.
.
.
causes us to look for a rea-sonWHERE did this happen?
.
.
.
.
causes us to look fora locationWHAT SCRIPTS might this instantiate?
.
.
.
.
GUN-MAN can itself cause a script to be instanti-ated.
Prime candidates are $ROBBERY,$TERRORISM and $KIDNAP.
We can nowlook for confirmation in the rest of the sen-tence.The formulation of the above questions (as re-quests, see Riesbeck, 1975) now guides the parsingof the rest of this sentence.
Here it is important opoint out that much more than just parsing is beingguided at this point by these requests.
This informa-tion is what we are interested in as understanders.We are actually performing the entire process ofunderstanding this story These requests relate tomatters of parsing and inference and scripts applica-tion and goal pursuit as well.
**********************************shot his way into the Iraqi Embassy...SHOT is encountered and immediately is found tosatisfy an expectation that was derived from GUN-MAN.
Satisfying an expectation of this sort is theway that conceptual structures are built and we nowbuild the first one, namely a SHOOT action with thegunman token as actor and an unfilled final direc-tion for the shooting.
This unfilled slot is marked asthe same one that satisfies the answer to the WHOquestion asked before and the parser now is inter-18 American Journal of Computational Linguistics, Volume 6, Number 1, January-March 1980Roger C. Schank, Michael Lebowitz, and Lawrence Birnbaum An Integrated Understanderested in satisfying that request by looking for thenext main noun in the next noun phrase.HIS is skipped and held in STM as before.WAY does not satisfy the expectation to fill theempty slot.
WAY is also listed as both skippableand pointing to a direction or location.
A request isset up for the location and we attempt o skip untilwe find it.INTO dictionary entry says to keep on going and itis skipped.THE is saved and skipped.IRAQI  is saved and skipped.EMBASSY is found to be a location and is set up asthe location of the SHOOT event.
Furthermore,EMBASSY is marked as interesting and a place ofpolitical significance.
This latter piece of informationsatisfies the request for instantiating the$TERRORISM script that we had predicted (amongothers) from GUNMAN.
Since EMBASSY is inter-esting, its requests are activated.
One of these is fora country whose EMBASSY it is.
IRAQI  is thusfound in STM as filling this request and is pickedup.Setting up $TERRORISM causes us to lose inter-est in the representation of the sentence as such andfocuses us on setting up and filling requests fromthat script for the representation for the entire story.Thus, we now expect answers to the following re-quests:Were HOSTAGES taken?What demands were made?
(money; free politicalprisoners?
)Was any damage done?What measures to counteract the terrorist weremade?
(return fire; arrest; free hostages?
)***********************here yesterday morning...***********************HERE always refers to the dateline location in anews story.
It adds this location to the story repre-sentation.YESTERDAY is found to be a time word and isthus added to the time slot of the event.MORNING is also handled in this manner.
*************************************held hostages through most of the day ....*************************************HELD is skipped since it matches none of the re-quests.
It matches none of them because the infor-mation found about HELD in the part of the dic-t ionary we look at at this point is just that it is averb.
No verbs were predicted so we skip it.
Whatcould have changed this would have been some in-terest marking under HELD or other item of signifi-cance.
Note that HELD is a highly ambiguous wordthat previously might have caused us to make agreat many predictions and look for evidence ofwhat sense was intended.
With an integrated under-standing system we need not do that at all.
The rea-son for this can be seen in what happens in subse-quent processing of this phrase.HOSTAGES is immediately found to satisfy an ex-tant request.
The TAKE HOSTAGES scene of$TERRORISM is instantiated.
At this point a checkis made on the stacked verb to see if doing this isokay.
If the stacked verb were 'shot',  for example,this instantiation would not work.
HELD is found tobe precisely the kind of word that fits here.
Theimportant point is that the meaning of HELD neverhad to be determined in isolation, which is nice be-cause words like HELD really do not have any par-ticular meaning.
.
Its meaning is derived from its con-nection to HOSTAGES,  and HOSTAGES is under-stood through $TERRORISM.
Thus integrated un-derstanding plus "save and skip" parsing facilitatesprocessing tremendously.THROUGHOUT is found to point to either a timeor place, so a request is made for a time or placeword.
However,  at this point our understanding sys-tem knows what it is interested in.
In particular,satisfying the requests that are still active is veryimportant because they are death-related requests(see Schank, 1978).
Thus we virtually ignore therest of this phrase due to lack of interest.MOST is saved and skipped.OF is skipped.THE is saved and skipped.DAY is recognized and ignored.
It also satisfies thelow level request for a time word and this informa-tion is added to what we know about time to beused later if we ever get interested in what we havenow decided is uninteresting.before surrendering to French policemen...BEFORE is a time ordering word that prepares usto set up a new event and mark its time relative tothe preceding event.SURRENDERING is a word that is both marked asof high interest and  as part of a number of scriptsincluding $TERRORISM.
The surrender scene of$TERRORISM is instantiated and requests are firedoff concerning the reasons for this action, his cap-tors etc.
Certain words are marked as indicatingwhich of these might follow.
Thus, 'because' marksoff reasons, and 'to'  marks off captors.TO tells us that captors is coming.FRENCH is held in STM.American Journal of Computational Linguistics, Volume 6, Number 1, January-March 1980 19Roger C. Schenk, Michael Lebowitz, and Lawrence Birnbaum An Integrated UnderstanderPOL ICEMEN is marked as a noun that can be anACTOR, so STM is consulted to gather up its rele-vant components.
POL ICEMAN also is a possiblecaptor (because it is both a human and an institu-tion, either of which would do), so it satisfies twoextant requests.and then was shot by Iraqi security officials ....******************************************AND says whenever an event has just ended, a newevent may be coming.THEN orders the time of the event.WAS specifies that the actor stored in STM is theconceptual object of the new event.
This sets uprequests for the actor and the action.SHOT is found to be interesting and is treated simi-larly to the way that GUNMAN was, except that wedo not expect the things that were particular toGUNMAN as opposed to the action he was per-forming.
Thus we have:WHOM did he shoot?
.
.
.
.
ARAB GUNMANWHO shot?
.
.
.
.
not answeredWHY did he shoot?
.
.
.
.
not answeredWHERE did this happen?
.
.
.
.
already knownWHAT SCRIPTS does this instantiate?
.
.
.
.
SHOOTcan also cause a script to be instantiated.Prime candidates are $ROBBERY,$TERRORISM and $KIDNAP, ordinarily.But we are in a context set up by$TERRORISM.
None of the above are nor-mal continuations of $TERRORISM.
Thiscauses us to look for plans and goals.WHAT were the RESULTS of this action?
-- Arequest is set up to find the results.
If thisrequest is not satisfied the usual results ofthis action are inferred.
In this case deathfor the object.Since SHOT is interesting, we need to explain it.No scripts are available here, so we need to ask whowould want to kill the GUNMAN and why.
Theserequests are added to the active requests.BY tells us the actor is to follow.IRAQI  is stacked and skipped.SECURITY is stacked and skipped.OFF IC IALS  is used to end the processing of thenoun group.
It satisfies the requests for WHO didthe shooting, and, as we now have an actor, we askabout why he would kill a TERRORIST.
This causesus to examine the themes we have for why TER-RORISTS might be killed after capture.
At thispoint we might make the connection between IRA-QI SECURITY OFFICIALS and IRAQI  EMBASSY,but that does not lead to an explanation.
This caus-es us to be surprised by this event.
We seek to ex-plain it by postulating a REVENGE or SHUT HIMUP type theme, but we are certainly not sure of it.as he was led away by French officers.
***********************************We are basically done now as no further requestsneed to be satisfied immediately.
(We know thisafter we have seen a period and found no new re-quests.)
We are still interested in the goals of eachof the actors, however, so WHY requests are stillalive.AS is known to be a time co-occurrence word.Since we are not interested in anything that occur-red at the same time unless it is itself interesting, wecan now skip ahead looking for actions or actorsthat are interesting.
AS can also indicate causality,but in that case the semantic predictions et up ear-lier will find the cause.HE is skipped.WAS is skipped.LED is uninteresting and is recognized and thenskipped.AWAY is skipped.BY is skipped.THE is skipped.FRENCH is skipped.OFFICERS is skipped because there are no requestsasking for it.The period tells us we are done.The final representation for this sentence is:$TERRORISMACTOR - Arab gunmanPLACE - Paris, Iraqi EmbassySCENES$HOSTAGES - some$CAPTUREACTOR - French policemenOBJECT - Arab gunmanPLACE - Paris, Iraqi EmbassyUNEXPECTED RESULT:ACTOR - Iraqi officersACT ION - SHOOTOBJECT - Arab gunmanRESULTACTOR - Arab gunmanSTATE - dead5.
Processing in In tegrated Partial  ParsingWe have written a program which implements thetheory of parsing illustrated above - an IntegratedPartial Parser (hereafter IPP).
In this section weshall look at how this parser works.
It was writtento handle a limited class of stories, namely newspa-per stories about terrorism and related areas.
Wehave not tried to address all the issues involved in20 American Journal of Computational Linguistics, Volume 6, Number 1, January-March 1980Roger C. Schank, Michael Lebowitz, and Lawrence Birnbaum An Integrated Understanderparsing.
Rather we have concentrated on the areaswhich are crucial to IPP.
One obvious problem wehave not addressed is words with multiple senses.Fortunately, in the class of stories we are process-ing, most words, especially the interesting ones, haveone strongly preferred sense.
IPP has successfullyprocessed over 200 stories taken directly from vari-ous newspapers.
Many of these were processed sightunseen.
IPP current has a vocabulary of over 2000words.
The parser is written in LISP, and runs on aDEC System 20/50.The program's limitations center around its vo-cabulary and knowledge of the world.
2000 words, asizable vocabulary for a typical AI program, is still abit too small, even for stories about terrorism.
Weare currently expanding the vocabulary.
The pro-gram is also limited to understanding stories forwhich it has appropriate world knowledge.
We haveconcentrated on stories that are script-based, but asmentioned earlier, we believe the general techniquesof IPP will extend to other forms of knowledge.IPP's ability can be increased both by adding morescript-type information, similar to that it alreadyhas, and by considering these other types of worldknowledge.Another limitation IPP has is that it has problemswith stories which are subtly phrased - those wherejumping to a conclusion causes problems.
But theseare exactly the kinds of stories people have troublewith when they are reading quickly.
The projectedsolution for this problem is to give IPP the capabili-ty of going back and reading text in a more carefulmode than it normally does.The parsing scheme implemented in IPP is basedon classifying the words in the dictionary in terms ofwhat the parser should do with each word as it readsit.
Thus, labels such as noun, verb, etc.
only makesense in a parser if they cause different processingdependent on seeing such classifications.It is very well to say, as we have, that a givenword should be skipped or saved or whatever.
Wemust make these determinations beforehand, howev-er.
Thus the key issues in the realization of this par-ser are, first, the establishment of a set of categoriesfor the words in the dictionary that will be useful insuch a scheme; and, second, a procedure for deter-mining what category a given word fits into.
As wewill see shortly, the category a word is assigned tomay be domain dependent.Looking back at the example in the last section,we can see that there are basically three differentthings that can be done with a word when it is read.It can be skipped, it can be saved and then skipped,or it can be completely processed immediately.The first possibility is that it may simply be skip-ped.
There are many words which have no signifi-cant conceptual content for normal reading.
Exam-ples from the story in the last section include theWords 'most', 'way', and 'held'.The second possibility that we can see from theexample is that a word may be saved in some kindof short term memory and then skipped.
Words forwhich this processing strategy seems appropriatehave some functional purpose or significant concep-tual content of a rather dull and uninteresting sort.Nevertheless, we cannot simply ignore them, be-cause their meanings may be important in elaborat-ing our knowledge of the events or things that weare interested in.
For example, they may be used tofill roles in the conceptual structures representinginteresting events.
They may a lso  never be usedagain.
Many of the words in our example are proc-essed this way.
Examples include the words'Arabic', 'Iraqi', and 'his', as well as all articles.Two things can happen with these words.
Eithertheir meaning does help elaborate something inter-esting, in which case that meaning will be incorpo-rated in the representation, or it doesn't.
For exam-ple, the meaning of the word 'French' in the phrase(1) before surrendering to French policeis incorporated into the representation because weare interested in whom the terrorist surrendered to,i.e.
'police'.
On the other hand, the meaning of theword 'French' in the phrase(2) as he was led away by the French officersis not incorporated into the meaning representationbecause we never become interested in 'officers'.Words with some conceptual content will oftenalso have some associated processing information, inthe form of expectations, which can help to elabo-rate on their own meaning.
Many of the wordswhich are processed by the "save and skip" strategyare objects of these sorts of expectations.
For ex-ample, it seems quite plausible that the word'embassy' has an expectation which looks for thename of the country which the embassy represents,and that the words 'police', 'officers', and 'officials'have expectations for the name of the governmentalauthority in whose name they operate.
But if aword is subject to the "save and skip" strategy,these expectations hould not be applied until weknow that the concept associated with the wordactually elaborates on our knowledge of somethinginteresting.
If it turns out that we don't care aboutthe concept, we don't want to have done unneces-sary processing.
Let's compare our processing of'police' in phrase (1) above with our processing of'officers' in phrase (2).
Since it turns out that theconcept of police in the first case adds to ourknowledge of an interesting event, it seems plausiblethat the expectation that the word 'police' has forthe authority governing the police would be used.In the second case, since the concept of 'officers'American Journal of Computational Linguistics, Volume 6, Number 1, January-March 1980 21Roger C. Schank, Michael Lebowitz, and Lawrence Birnbaum An Integrated Understanderdoes not add to our knowledge of anything interest-ing, there is simply no point in applying any similarrule.The third possible processing strategy we canapply to a word is to process it immediately, i.e.
payattention to its meaning and the expectations it gen-erates.
This is the strategy that we apply when theword has a significant and interesting conceptualcontent.
It is these concepts and their associatedexpectations that drive the analysis.
Examples fromthe story of the last section include the words'gunman', 'shot', and 'hostages'.
The expectationswhich these words generate include the same kind ofsimple elaborative, or "slot-fil l ing", expectationsassociated with some of the words for which a "skipand save" strategy is appropriate.
For example, it isquite plausible that one expectation generated bythe word 'gunman' looks for the nationality or polit-ical affiliation of the gunman.These words can also generate expectationswhich operate at a much higher level.
For example,when we read the word 'gunman', we expect o readthat he may have performed the action of shooting aweapon.
We also expect the events associated withseveral possible scripts, including $ROBBERY and$TERRORISM.
These expectations operate in amanner somewhat akin to script application (seeCullingford, 1978), in that they serve to recognizeevents, and so recognize that they are sensible in thegiven context.
So, as described in the example ofthe last section, once we know that the gunman isquite likely a terrorist, we expect that he may holdhostages, that he may shoot or kill some people, andthat he may make demands.
We also know thatthere are only a small number of possible outcomesof the episode: the terrorist might be captured, hemight surrender, he might be killed, or he mightescape.
These high level expectations help us decidewhat is important in the text in a very top-downway.
The analysis process depends crucially on this.But its flexibility also depends on its ability to pur-sue questions about interesting things and events,even if they were not anticipated.The expectations used by IPP are implemented inthe form of requests (see Riesbeek, 1975).
A re-quest is a form of production, or test-action pair.
Ifthe test of an active request is checked and found tobe true, then the corresponding sets of actions areperformed.
The list of requests is ordered so thatwhen the active requests are considered, the mostrecently activated are considered first, since theyrepresent newer, and so probably better, expecta-tions.While in theory the tests and actions which re-quests perform could be arbitrary, in our system wehave found that only a restricted set is necessary.Requests may do the following:build new conceptual structures -- usually agiven request will only build one such struc-ture;fill a slot in some conceptual structure withsome other conceptual structure -- for exam-ple, filling the ACTOR slot of $SHOOT withthe token for the gunman;activate other requests -- these will often berequests trying to fill slots in the structurebuilt by the activating request; they can alsobe expectations for possible actions, states, ormore complicated episodes which may follow;de-activate requests -- requests are able todeactivate requests, including themselves,when they are no longer appropriate.There are three types of tests which requests per-form:checks for specific lexical items -- for exam-ple, function words tend to be specific to agiven construction; so in the phrase"surrender to French police", the requestsassociated with 'surrender'  (or $SUR-RENDER),  can look for the occurrence of theword :to' to precede the authority to whomthe surrender is taking place;checks for lexical items satisfying some prop-erty -- for example, words which activate aspecific script;look for tokens or events of a specified type-- this might be as simple as matching a par-ticular structure; or it may involve use of se-mantic tests such as 'human' or 'authority'.The fact that requests can look for specific lexicalitems is very important in reducing processing time.This savings is realized both by requests looking forfunction words to fill slots (such as 'to' or 'by'), andby requests which look for more substantial events.Often a word may create expectations which lookfor specific words which indicate what script is ap-plicable.
As an example, gunman creates expecta-tions which look for the terrorist, hijack, and rob-bery scripts.
The request looking for the hijackscript may include tests for specific words (or phras-es), such as 'diverted', 'hijack', 'took over', all ofwhich indicate the hijack script.
Requests will nor-mally have checks at the conceptual level as well.The request activated by 'gunman' which checks forthe terrorist script looks at the location of the ac-tion.
If that location is the location of a politicalentity, such as an embassy or the office of somepolitical organization, that is a good clue that theterrorist script may be relevant.
A sample request isshown on the next page.Within the broad categories of words that areprocessed immediately, and words that are savedand skipped, there are subcategories that help to22 American Journal of Computational Linguistics, Volume 6, Number 1, January-March 1980Roger C. Schank, Michael Lebowitz, and Lawrence Birnbaum An Integrated UnderstanderSamp~ Request~ F IND-$HI JACK ins tant ia tes  the h i jack ing  scr ip t  by not i c ing  anappropr ia te  word  or concept ,  bu i lds  a h i jack ing  event,~ and sets off  severa l  new requests ,  look ing  for scenes~ and other  act ions.
(Created  by GUNMAN.
)(DEF-REQ F IND-$HI JACKTEST (H I JACK- INSTANTIATOR *NEW- ITEM*)ACT ION (REQ-EVENT 8 (SCRIPT  SHI JACKACTOR NILDEMANDS NILFROM NILDEST INAT ION N ILTO NILPASSENGERS N ILVEHICLE  NIL)~ Test  looks for words  wh ich~ ind icate  the h i jack  sc r ip t~ Act ion  bu i lds  an event  for~ the h i jack  scr ip t  of~ in teres t  8, w i th  the s lotsshown here.
It f i l l s  inthe actor  s lot  w i th  thelast  actor  in *ACTOR-STACK*( (ACTOR .
(TOP-OF *ACTOR-STACK*) ) )(REDUNDANT-H I JACK-WORDS ~ These  new requests  areF IND-H I JACK-DEST INAT ION ~ act ivated.F IND-H I JACK-VEHICLEF IND-H I JACK-PASSENGERSF IND-H I JACK-EVENTSSURRENDER-SCENERECOGNIZE-DEMANDSRECOGNIZE-COUNTER-MEASURES\ ]decide what to do with a given word.
There are twoconsiderations that affect a word's classification.The first is how a given word modifies the repre-sentation we are building; the second is the kind ofexpectations that a word sets up.
The classificationscheme is based on these two considerations.
Wewill now describe each class of words, and how IPPprocesses them.
For each class, a sample dictionaryentry is shown.A - Words that are immediately processedWithin a theory of integrated parsing, words arebest classified according to the type of conceptualstructures that they build.
That is, the most impor-tant role that a word plays, in this conception ofprocessing, is not its syntactic role such as noun orverb, or even its conceptual role, such as actor oraction.
The most significant hing about a word fromthis point of view is how it affects the processingwithin the integrated understanding process.In the representation given above for the Arabgunman sentence there are two different kinds ofitems.
There are the events involved - the terrorismscript, the capture scene, the gunman being shot,and so forth; there are also the individual conceptsthat play roles - the gunman who fills the ACTORslot of the terrorism script, or the Iraqi embassy,which fills the LOCATION slot of this script, forexample.
These role fillers we shall refer to as to-kens.
With the distinction between tokens andevents in mind, we can look at a classification ofwords.A1 - Event BuildersOne class of words are those that build eventstructures.
We call these Event Builders (EB's) Thisclass of words includes many verbs, and a numberof nouns, such as 'killing', 'r iot', and 'hijacker'.
AllEB's have an associated interestingness.
This helpsdetermine whether an event is significant enough tobe included in the final representation - whether it isinteresting enough to cause us to construe it as acentral event in the representation, and whether it isimportant enough that we should spend valuableprocessing time attempting to fill its open slots.
AllEB's also have an associated set of expectations thathelp to guide the rest of the parse.
These expecta-tions vary from explicit requests to place subsequentitems in specific slots, to general expectations aboutevents that are likely to occur eventually (such asthe scenes of a script).EB's are further subdivided according to the typeof event they build.
Many very common words, suchas 'give',  'went ' ,  and 'ate' ,  build simple (and notintrinsically very interesting) events.
These eventsare the kind that we have always been able to repre-sent very easily in Conceptual Dependency (Schank,1972, 1975).
In our recent work on higher levelknowledge structures, we have found that the kindsof representations that are most significant are thoseAmerican Journal of Computational Linguistics, Volume 6, Number 1, January-March 1980 23Roger C. Schank, Michael Lebowitz, and Lawrence Birnbaum An Integrated Understanderthat relate to scripts, plans, and goals (see Schankand Abelson, 1977).
Consequently, those EB's thatbuild simple Conceptual Dependency structures, areprecisely those that need the least processing be-cause they are the least interesting.
They constitutea special class of EB's then, (CDEB's),  that rarelyrequire us to spend much time on them.
They haverather simple expectations, generally to fill in theirACTOR,  OBJECT,  TO, FROM, and INSTRU-MENT slots.
In order for us to attempt o find theinformation that fills these expectations, ome more.
interesting event must expect hem, or there must bean interesting actor whom we expect to be involvedwith the action.Other kinds of EB's are script builders ($EB's)and scene builders (SEB's).
Both of these types canhave rather more involved requests, often suggestingevents that might occur.
The only real 'dif ferencebetween $EB's (words such as 'hijacked', 'kidnap')and SEB's ('surrendered', 'convicted') is that fromSEB's we try to infer a script, since scenes cannotoccur in isolation, and from $EB's we create expec-tations for the scenes of the script.Other knowledge structures used to understandstories, such as plans, goals, and themes also haveassociated EB's (that is, words that build thesestructures directly) but the EB's described so farare sufficient for a large class of newspaper stories.
(Higher level knowledge structures are generally notstated directly by any particular word.
Rather, thepresence of such structures usually must be detectedby inference.
)When an EB is read, an empty event structure isbuilt from a template in the dictionary.
IPP thenchecks to see if any requests are looking for thisevent.
Expectations created by the context of thestory frequently explain an event with little furthereffort.
If there are no relevant expectations, theevent's interest value, listed in the dictionary, ischecked.
If the event has little interest, processingmoves to the next word.
If the event has significantinterest, the expectations listed in the word's dic-tionary entry are instantiated, with a pointer to thenew event structure.IPP keeps track of a story's main event.
Itchecks to see if a new event is more interesting thanits current main event.
If an interesting event lessinteresting than the current main event is created,and it does not fulfill an expectation, then it is savedas an unexplained event, indicating IPP should lookfor an explanation.A2 - Token MakersMany words, including most nouns, such as'gunman' and 'embassy', contribute to the process ofunderstanding by filling open slots in event struc-tures.
We call this class of words Token Makers(TM's).
These words cause a token to be built.
Ifthe word is interesting, or an interesting modifierhas been saved in short term memory (and only inthese cases), then the words which modify the tokenare retrieved from short term memory.
The tokensbuilt are frequently objects looked for by expecta-tions made during the processing of previous wordsin the sentence.The class of TM's can be subdivided in twoways.
There are several different types of tokenswhich can be built, such as actor tokens, place to-kens, organization tokens, vehicle tokens and timetokens.
The type of token built is one factor in de-termining whether the new token satisfies an expec-tation made earlier.The other subdivision of TM's concerns the ef-fects that TM has on subsequent processing.
ThisSumps Dmtionary Entry (A1)WORD-DEF OCCUPIEDINTEREST 5TYPE EBSUBCLASSTEMPLATEF ILLREQSSEBSCRIPT  SDEMONSTRATE N OCCUPIED bu i lds  a s t ruc tureACTOR NIL  ~ spec i fy ing  the demonst ra teOBJECT N IL  - sc r ip t  w i th  an occupyDEMANDS NIL  ~ sceneMETHOD (SCENE $OCCUPYACTOR N ILLOCATION NIL) )( (ACTOR)  (TOP-OF  *ACTOR-STACK*) )  - ACTOR s lots( (METHOD ACTOR)  (TOP-OF  *ACTOR-STACK*) ) )  ~ are f i l led.F IND-DEMON-OBJECT ~ Expectat ion  we might  see who is be ingdemonst ra ted  aga inst .F IND-OCCUPY-LOC - Expectat ion  we might  see the s i te  ofthe demonst ra t ion .RECOGNIZE-DEMANDS\ ]  ~ Expectat ion  we might  see demands.24 Amer ican Journal  of Computat iona l  Linguistics, Vo lume 6, Number  1, January-March 1980Roger C. Schank, Michael Lebowitz, and Lawrence Birnbaum An Integrated UnderstanderSample Dictmna~ Ent~ (A2)(WORD-DEF  GUNMANINTEREST 5TYPE TMSUBCLASS ACTORMEMORY TREQS (CONFIRM-SHOOTF IND-WHY-SHOOT(F IND-$TERRORISMF IND-$ROBBERYF IND-$K IDNAPF IND-$HI JACK\ ]~ GUNMAN is an ITMExpectat ion  we might  see a shoot ing .Expectat ion  we might  see why  thegunman wou ld  shoot  someone.~ Set  of expectat ions  wh ich  spec i fy~ sc r ip ts  we are l i ke ly  to see.~ If one is sat i s f ied ,  the o thers~ are deact ivated .division is based on how interesting the TM is.
In-teresting TM's (ITM's) generate xpectations as towhat we might see next in the sentence.
Thus'gunman', an ITM, generates expectations for shoot-ing, hijacking, and robbery events, for example.ITM's that fill the actor role in an event naturallygenerate expectations that more information aboutthese people will be forthcoming.
For example,'gunman' activates requests looking for feasiblescripts.TM's that are not interesting, and hence do notgenerate any expectations, can be placed into twoclasses, normal (NTM's) and empty (ETM's).NTM's can easily be associated with objects alreadyin memory, even though they are not interesting.Examples of NTM's are 'airport', 'Vermont',  and'officials'.
The tokens built by NTM's can be usedto fill slots in the representation.
ETM's, on theother hand, are words which are so indistinct inmemory that it is virtually meaningless to includethem in the final representation of the sentence.Words such as 'people', 'place', and 'someone' fallinto this class.
These words build tokens which candeactivate xpectations, but they are not added intothe final representation.
If there is no expectationfor the token built, and it is not interesting by itself,it is ignored in our parsing scheme, since there islittle reason to remember it.B - Words that are saved and skippedMany words need no processing when they arefirst read.
They are simply saved in short termmemory and their processing completed later, ifnecessary.
There are two important points to recog-nize about save and skip words.
First, the fact thatwe save a word does not commit us to doing anyfurther processing of it.
Most save and skip wordsare not very interesting, and unless a subsequentinteresting word requests that saved words be con-sidered, save and skip words can easily require noprocessing other than being saved.
Presumably theprocess of saving a word is very easy, so that saveand skip words often consume very little processingtime.
An important point about save and skip wordsis that domain and context are important in deter-mining which words are save and skippable, andwhich are totally skippable.
So for example, a wordlike 'tall', is totally skippable in most domains (suchas stories in most sections of a newspaper), butwhen reading a sports story, it may become a saveand skip word, since height can be salient in certainsituations.The class of save and skippable words can besubdivided into several classes, based on what we dowith the word, if we do decide to process it further.
(Remember - there is a good chance no furtherprocessing will be done.
)B1 - Token RefinersOne class of save and skip words, token refiners(TR's), add information to the tokens built by TM's.Most of the words which commonly appear in nounphrases, including many adjectives, are TR's in do-mains in which they cannot be skipped entirely.Above, 'Arabic' is a TR which refines the actor to-ken built for the gunman, by marking it "nationality:Arabic".
The processing for all TR's begins in thesame way.
Each TR is stored temporarily, until theTM it modifies is found, at which point it may beretrieved and processed further, in a manner de-pendent on the TR type.
(If the TM proves to beuninteresting, no further processing will be done.
)The class of TR's can be subdivided three ways,based on how they alter the tokens they modify.
Alarge class of TR's simply add a property to a token.These TR's, which will be referred to as simple TR's(STR's) include common adjectives, such as 'red','tall', and 'Arabic', in the cases where they are notjust skippable.
Words like 'early', or 'late', fall intothis class, usually modifying time TM's.Other TR's modify properties added to a tokenby another modifier.
For instance, in the phrase"about 20 gunmen," 20 would add to the token forgunmen, "NUMBER 20," and 'about'  would alterthis to "NUMBER (APPROX 20)."
Words in thisAmerican Journal of Computational Linguistics, Volume 6, Number 1, January-March 1980 25Roger C. Schank, Michael  Lebowitz, and Lawrence Birnbaum An Integrated Understanderclass of TR's are called TR modifiers, or TRM's.
Itis not clear how often words in this class are notsimply skippable.
It seems likely that most of thesewords tend to get ignored nearly all of the time, butsometimes they must be saved and skipped.The third class of TR's are names (TRN's).
Theysimply add to the token they modify the informationabout the token's name.
So in "Kennedy Interna-tional Airport," 'Kennedy' adds to the airport tokenthe fact that its name is Kennedy.
TRN's differ inprocessing from STR's only in that they cannot bemodified by TR Modifiers.One aspect of processing which is common to alltypes of TR's is that their dictionary entries canindicate they should make the token they modifymore interesting.
So, "Arabic gunman," is moreinteresting than 'gunman', due to the inherent inter-est of the TR 'Arabic'.Notice that "save and skip" processing wouldmake it very easy to handle TR's whose meaning isdependent upon the words they modify, since theactual definition of the TR is not processed until theTM is known.
It also simplifies cases where the TMactively looks for specific types of words whichmight modify it.Sample Dictionary Entry (B1)( WORD-DEF  ARABICTYPE  TRSUBCLASS STRINTEREST 2MEMORY TDEF  (NAT IONAL ITY  .
ARABIC \ ]B2 - Event RefinersEvent refiners (ER) are very similar to TR's,except they modify events, not tokens.
Typical ofthis class are adverbs such as 'quickly', 'stupidly',and other 'ly' words.
Other words such as 'here' and'away' also fall into this class, since they alter a Slotof the event they modify, as in "was shot here," or"was led away."
Words which might appear to fallinto this class are even more likely to turn out to beskippable than TR's.
The 'ly' words just mentionedare ER's when they are saved, but in general theyare very dull words, and get skipped entirely.
Asmentioned above, the determination of whether theword must in fact be saved is domain dependent.ER's divide into standard ER's (SER's) and ERmodifiers (ERM's) in a manner similar to STR's andTRM's.
Processing is similar to that for TR's, exceptit occurs when an event is created, and ER's arelooked for following the event, as well as thosewhich have been saved in STM.Sample Dictionary Entry (B2)( WORD-DEF  AWAYTYPE  ERSUBCLASS SERDEF  ( TO .
NOT-HERE\ ]B3 - Function WordsThere is an important class of words in Englishwhich have little or no meaning of their own, butexist solely to guide processing.
These words, knownas function words (FW's), are quite common, andinclude articles, prepositions, and auxiliary verbs.Function words in general cannot be totally skipped,but quite often the parsing process never returns tothem.
They must be saved, since if interesting itemsfollow they may become important, but by them-selves they do not demand processing.The role of articles (a, an, the) is to mark thebeginning of noun phrases, and help indicate whichToken Refiners go along with which Token Makers.When read, they are saved with the TR's.
Then,when processing a TM, we look back on the wordsjust encountered trying to find TR's.
If we find anarticle, this search terminates.Prepositions (with, to, from ...) have a variety offunctions in English.
Often they precede TM's andindicate how the TM should be added to the struc-ture being built.
In our system, the most frequentuse for prepositions i an inactive one.
An EB willoften create expectations for a certain preposition,with instructions for what to do with the TM follow-ing the preposition.
Thus 'shot' creates an expecta-tion for 'with', and knows that the TM following'with' should go into the INSTRUMENT slot of theevent.Auxiliary verbs have a variety of functions, suchas setting time (did go), or making the event to fol-low hypothetical (may go).
One of the more impor-tant uses of auxiliary verbs is the use of forms of 'tobe' to make a verb passive.
When an event is creat-ed by a past participle, IPP checks for such an auxil-iary, and if one is present, modifies low-level proc-essing appropriately.Sample Dictionary Entry (B3)( WORD-DEF  ATYPE  FWSUBCLASS ART\]B4 - Relational WordsRelational words create a link between twoevents.
Processing of all these words tends be thesame.
The word is saved temporarily until a signifi-cant event is found.
Then the proper link betweenthat event and the previous event is made.
If the26 American Journal of Computat ional  Linguistics, Volume 6, Number 1, January-March 1980Roger C. Schank, Michael Lebowitz, and Lawrence Birnbaum An Integrated Understanderrelational word connects uninteresting events in thesentence, no additional processing will be done.Relational words create two main kinds of links -temporal and causal.
Words such as 'before','while', and 'after' indicate temporal relations be-tween events, and 'because', 'since', and 'therefore'indicate causal relations.Sample Dictionary Entry (B4)( WORD-DEF  BEFORETYPE RWSUBCLASS TRWRELAT ION AFTER\]C - Sk ippable  WordsA somewhat surprisingly large class of words isentirely skippable.
When we process them, absolute-ly nothing is done.
This is presumably one means forsaving substantial amounts of time during process-ing.
Words such as 'and', 'who', and 'speaking' (asused above) fall into this class.
An important topicof future study is to discover just what qualifies aword as skippable.
The larger the skippable classbecomes, the faster this program will be.
It is likelythat few, if any, words are skippable in all domains,for all readers, whatever level they are processing.But for a given reader, working in a given domain,many words are skippable.Also words can be added to the skippable classdynamically, even seemingly quite interesting words.So if we already know the "hold hostage" script istaking place, words like 'terror', 'siege', and'gunfire', become skippable, since we have alreadyinferred anything they would build.
Expectationsfor such words are created which neutralize theirinherent interest.6.
Examples of IPPThe first three examples shown here are comput-er runs of IPP on three stories taken from the NewYork Times.Ya le  TOPS-20  Command processor  3(414)@DO IPP* (PARSE SI)Input:(AN ARABIC  SPEAKING GUNMAN SHOT HIS WAYINTO THE IRAQI  EMBASSY HERE THIS MORNINGHELD HOSTAGES THROUGHOUT MOST OF THE DAYBEFORE SURRENDERING TO FRENCH POL ICEMENAND THEN WAS SHOT BY IRAQI  SECURITYOFF IC IALS  AS HE WAS LED AWAY BY FRENCHOFF ICERS)** MAIN EVENT **SCRIPT  STERRORISMACTOR ARAB GUNMANPLACE IRAQI  EMBASSYC ITY  PARIST IME MORNINGSCENESSCRIPT  SHOLD-HOSTAGESACTOR ARAB GUNMANPLACE IRAQI EMBASSYSCRIPT  $CAPTUREACTOR POL ICEMENOBJECT ARAB GUNMANPLACE IRAQI EMBASSYAFTER SHOLD-HOSTAGES SCENE** UNEXPECTED EVENTS **SCRIPT  $SHOOTACTOR IRAQI OFF IC IALSOBJECT ARAB GUNMANAFTER $CAPTURE SCENERESULTSTATE DEADACTOR ARAB GUNMAN* (PARSE $2 )Input:(A GUNMAN WHO DIVERTED A VERMONT BOUNDBUS WITH MORE THAN TWENTYF IVE  PASSENGERSFROM THE BRONX TO KENNEDY INTERNATIONALA IRPORT AND K ILLED TWO HOSTAGESSURRENDERED ON A RUNWAY LATE LAST N IGHTENDING A DAYLONG S IEGE OF TERROR ANDGUNFIRE)Output :** MAIN  EVENT **SCRIPT  $HI JACKACTOR GUNMANFROM BRONXTO A IRPORTCARRYING PASSENGERSVEHICLE  BUSSCENESSCRIPT  SK ILLACTOR GUNMANV ICT IM HOSTAGESSCRIPT  $CAPTUREOBJECT GUNMANACTOR POL ICET IME N IGHT** UNEXPECTED EVENTS **NONEOutput :  * (PARSE $3 )American Journal of Computational Linguistics, Volume 6, Number 1, January-March 1980 27Roger C. Schank, Michael Lebowitz, and Lawrence Birnbaum An Integrated UnderstanderInput:(ABOUT TWENTY PERSONS OCCUPIED THE OFF ICEOF AMNESTY- INTERNATIONAL SEEK ING BETTERJA IL  CONDIT IONS FOR THREE ALLEGEDWEST-GERMAN TERRORISTS)Output:**  MAIN EVENT **SCRIPTOBJECTDEMANDSSDEMONSTRATEAMNESTY- INTERNATIONALIMPROVED JA IL  CONDIT IONS FORWEST-GERMAN TERRORISTSMETHODSCRIPT  $OCCUPY**  UNEXPECTED EVENTS **NONE\[PHOTO: te rminated  Thu 16-Nov-78 8:27AM\]The next two examples, the first from the BostonG~be and the second from the New York ~mes,illustrate how stories with simUar content are proc-essed similarly by IPP, despite differences in syntax.Yale  TOPS-20  Command processor  3A(415)@DO IPP* (PARSE $4)Input :( IR ISH REPUBL ICAN ARMY GUERRILLASAMBUSHED A MIL ITARY PATROL IN  WESTBELFAST YESTERDAY K ILL ING ONE BR IT ISHSOLDIER AND BADLY WOUNDING ANOTHER ARMYHEADQUARTERS REPORTED)Output :**  MAIN EVENT **SCRIPT  STERRORISMACTOR IRA GUERRILLASPLACE BELFASTT IME YESTERDAYSCENESSCRIPT  SK ILLACTOR IRA GUERRILLASV ICT IM I ENGL ISH SOLDIERPLACE BELFASTSCRIPT  SWOUNDACTOR IRA GUERRILLASPLACE BELFAST** UNEXPECTED EVENTS **NONE* (PARSE S5 )Input:(GUNMEN BEL IEVED TO BE BASQUE GUERRILLASTODAY SHOT AND SERIOUSLY  WOUNDED APROVINCIAL  SECRETARY OF THE R IGHT-WINGPOPULAR ALL IANCE PARTY POL ICE  SOURCESSAID)Output:**  MAIN EVENT **SCRIPT  STERRORISMACTOR BASQUE GUERRILLAST IME TODAYSCENESSCRIPT  $SHOOTV ICT IM SECRETARYACTOR BASQUE GUERRILLASSCRIPT  SWOUNDACTOR BASQUE GUERRILLASV ICT IM SECRETARYEXTENT GREATERTHAN-*NORM*** UNEXPECTED EVENTS **NONE\[PHOTO: te rminated  Tue 5 - Jun -79  I:08PM\]Notice that in $5, the primary designation of theactor is given in the participial phrase, "believed tobe Basque guerrillas," while in $4 "Irish RepublicanArmy Guerrillas" is simply the subject of the sen-tence.
IPP identifies the actors in the same way, justas people would normally do.
(I.e.
the qualifier"believed to be" is normally ignored.)
Also noticethat the events described in $4 by "killing" and"wounding" are no more difficult for IPP to under-stand than those described by "shot" and"wounded" in $5.
In fact, the processing is virtuallyidentical.The final two examples illustrate how IPP canjump to a conclusion about the representation of astory and then drop that representation when itfinds a more interesting possibility.
The first exam-ple, $6 is the initial fragment of the full sentenceprocessed in the second example, $7, which is fromthe New York Times.Ya le  TOPS-20  Command processor  3A(415)@DO IPP* (  PARSE $6 )Input  :(A YOUNG JAPANESE GUNMAN BROKE INTO ATOKYO BANK TODAY AND K ILLED TWOPOL ICEMEN )Output :**  MAIN EVENT **SCRIPT  SROBBERYACTOR JAPANESE GUNMANPLACE TOKYO BANK28 American Journal of Computational Linguistics, Volume 6, Number 1, January-March 1980Roger C. Schank, Michael Lebowitz, and Lawrence Birnbaum An Integrated UnderstanderTIME TODAYSCENESSCRIPT  SKILLACTOR JAPANESE GUNMANV ICT IM 2 POL ICEMENPLACE TOKYO BANK** UNEXPECTED EVENTS **NONE* (PARSE $7)Input:(A YOUNG JAPANESE GUNMAN BROKE INTO ATOKYO BANK TODAY K ILLED TWO POL ICEMENHELD 36 PERSONS HOSTAGE AND VOWED HEWOULD NOT LEAVE UNLESS HE RECEIVED$25OOOO)Output:**  MAIN EVENT **SCRIPT  STERRORISMACTOR JAPANESE GUNMANDEMANDS $250000PLACE TOKYO BANKSCENESSCRIPT  SKILLACTOR JAPANESE GUNMANV ICT IM 2 POL ICEMENPLACE TOKYO BANKSCRIPT  $HOLD-HOSTAGESHOSTAGES 36 PERSONSACTOR JAPANESE GUNMAN** UNEXPECTED EVENTS **NONE\[PHOTO: te rminated  Tue 5 - Jun -79  5:20PM\]Initially IPP assumed the story to be an instanceof the ROBBERY script, since 'bank' triggered aprediction from 'gunman'.
The ROBBERY script hascompletely disappeared in the final representation f$7.
Once IPP discovered the HOLD HOSTAGESscript, from which it inferred TERRORISM, it de-cided that was much more interesting than ROB-BERY, and selected it as its representation.
Howev-er, it did reincorporate the KILL scene into the newrepresentation.7.
ConclusionCareful readers will note that we have used littlein the way of Conceptual Dependency (Schank,1972, 1975) in the final representations that wehave used as the output of our parser.
This repre-sents a shift in our thinking about representationsthat has been going on for the last few years.
InSchank and Abelson (1977), we proposed an addi-tional level of representation, called the KnowledgeStructure level, that represented larger structures ofinformation than were available in our original viewof Conceptual Dependency.
In Schank and Carbo-nell (1978), we proposed yet another addition toour representational system to handle social andpolitical acts that were handled rather poorly in theprevious systems.
We have, of course known thatwere a great many issues that could not be ade-quately represented in Conceptual Dependency.
Theneed for additional representational schemes hasbeen, and still is, obvious.
But previously, we havealways attempted to parse into Conceptual Depen-dency first, preferring to write our inference mecha-nisms so as to begin with input represented in Con-ceptual Dependency.
This had two main advantages.First, it allowed the large number of people, andprograms that they built, that were working in ourproject to be able to communicate with one another.Conceptual Dependency was a kind of interlingua,or conceptual Esperanto, in terms of which everyonecould communicate.
Secondly, aside from this prag-matic advantage, we believed that this kind of mod-ularity was correct from a theoretical point of view.Simply stated, we believed that meanings were ex-tracted from sentences and then operated upon byother processes.The obvious proposal when we invented the twoadditional representational systems referred to abovewas to attempt o parse into them directly.
Althoughwe still believed that people extracted meaningsfrom what they heard, there really was no reason tobelieve that these meanings could have one and onlyone form.
If 'want' was best represented in a goalrelated fashion and rather complexly represented inConceptual Dependency, what reason was there tobelieve that one had to go through the complex formto get to the simple one?
Much of this kind of issuehas formed the basis of various researchers objec-tions to our notion of primitives.
In particular, Bo-brow and Winograd (1977) have made an issue ofour primitives from time to time.
They have pro-posed a notion of variable depth of processing as acounterproposal to our primitive representations.
Ina sense the system we have described here makesuse of that suggestion.
Bobrow and Winograd arecorrect when they assert that different levels ofprocessing make sense at different times.
We disa-gree with them on the issue of what constitutes theappropriate set of levels.
We do not believe eitherwords themselves or syntactic notions are ever sensi-ble stopping points.
But the absence of ConceptualDependency in parts of our final representationshere concedes the larger point.
That is, we agreethat one ought to go as far as one needs to duringthe understanding process.What then of Conceptual Dependency and primi-tives?
In our parser, Conceptual Dependency is usedas a kind of internal language used in situationswhere the f inal  representation is not apparent.
ItsAmerican Journal of Computational Linguistics, Volume 6, Number 1, January-March 1980 29Roger C. Schank, Michael  Lebowitz, and Lawrence Birnbaum An Integrated Understanderuse can al low conceptua l ly  based inferences to bemade.
Strangely enough, it has begun to bear  a cer-ta in s imi lar i ty to our use of  syntax in the pars ingprocess.
That  is, it is something that is there beh indthe scenes do ing its job  wi thout  ever  surfac ingmuch.The major  conclus ion of all this then is that  webel ieve that modu lar  systems will eventua l ly  fal lapar t  f rom their  own cumbersomeness .
Human- l i keunders tand ing  systems must  be in tegrated  to theextent  that  they  can be guided by their  inherentinterests,  delving into what  they fancy and sk ippingwhat  they do not.
This must  be truly what  is meantby  var iab le  depth  of  process ing.
Another  way  ofsaying this is that  if we actual ly  pay  equal  and de-ta i led a t tent ion  to everyth ing  we are cal led on tounderstand,  we may never  f inish the unders tand ingprocess.
To get al the in ferences  and re levantknowledge structures out all the t ime may be at theworst  imposs ib le  and at the best  unreal ist ic  in termsof process ing time.
A language unders tander  is guid=ed by what  he wants  to know (and what  he does notwant  to know) .
This enables  him to not  see all theambiguit ies,  tr iple meanings,  myr iad  impl icat ions ando ther  prob lems with what  he hears.
But  what  heloses in per fec t ion  he more  than makes  up for  inspeed and lack of  fragi l ity.
Perhaps  it is t ime togive our machines the same advantages.ReferencesBobrow, D. G., and Fraser, J.
B.
(1969).
An augmentedstate transition network analysis procedure.
Proc.
Int.Joint Conf.
on AI 1Bobrow, D. G., and Winograd, T. (1977).
An overview ofKRL, a knowledge representation language.
CognitiveScience 1, no.
1CMU Computer Science Speech Group (1976).
WorkingPapers in Speech Recognition - IV - The Hearsay II Sys-tem.Carbonell, J. G. Jr. (1979).
Subjective understanding: Com-puter models of belief systems.
Research Report 150,Department of Computer Science, Yale University.Cullingford, R. (1978).
Script application: computer under-standing of newspaper stories.
Research Report 116,Department of Computer Science, Yale University.DeJong, G. F. (1977).
Skimming newspaper stories by com-puter.
Research Report 104, Department of ComputerScience, Yale University.Gershman, A.
(1977).
Analyzing English Noun Groups forTheir Conceptual Content.
Research Report 110, Depart-ment of Computer Science, Yale University.Granger, R. H. (1977).
FOUL-UP: A Program That FiguresOut Meanings of Words from Context.
Fifth Internation-al Joint Conference on Artificial Intelligence, August1977, Cambridge, Massachusetts.Kaplan, R. M. (1975).
On process models for sentenceanalysis.
In D. A. Norman and D. E. Rumelhart, eds.,Explorations in Cognition.
W. H. Freeman and Compa-ny, San Francisco.Lamb, S. (1966).
Outline of Stratificational Grammar.
George-town University Press, Washington, D.C.Marcus, M. (1979).
A Theory of Syntactic Recognition forNatural Language, MIT Press, Cambridge, Massachusetts.Marslen-Wilson,W.
D. (1975).
Sentence Perception as anInteractive Parallel Process.
Science.
Vol.
189, pps.
226-228.Newell, A.
(1973).
Production systems: models of controlstructures.
In Chase, W.C.
(ed.
), Visual InformationProcessing, Academic Press, New York.Plath, W. J.
(1974).
Transformational Grammar and Trans-formational Parsing in the REQUEST System, Computa-tional and Mathematical Linguistics, in A. Zampolli ed.,Proc.
of the Int.
Cong.
of Computational Linguistics,Pisa, 1973, Casa Editrice Olschki, Firenze.Riesbeck, C. K. (1975).
Conceptual analysis.
In R. C.Schank (ed.
), Conceptual Information Processing.North Holland, Amsterdam.Riesbeck, C. K. and Schank, R. C. (1976).
Comprehensionby computer: Expectation-based analysis of sentences incontext.
Research Report 78, Department of ComputerScience, Yale University.Schank, R. C. (1972).
Conceptual Dependency: A theory ofnatural language understanding.
Cognitive Psychology,Vol.
3, No.
4.Schank, R. C. (1975).
Conceptual Information Processing.NOrth Holland, Amsterdam.Schank, R. C. (1978).
Interestingness: Controlling Inferenc-es.
Research Report 145, Department of Computer Sci-ence, Yale University.Schank, R. C. and Abelson, R. P. (1977).
Scripts, Plans,Goals and Understanding.
Lawrence Erlbaum Associates,Hillsdale, New Jersey.Schank, R. C. and Carbonell, J. C. (1978).
Re: The Gettys-burg Address: Representing Social and Political Acts.Research Report 127, Department of Computer Science,Yale University.Schank, R. C. and Selfridge, M. (1977).
How to Learn /What to Learn.
Fifth International Joint Conference onArtificial Intelligence, August 1977, Cambridge, Massa-chusetts.Schank, R. C. and Tesler, L. (1969).
A conceptual parser fornatural anguage.
Proceedings of the International JointConference on Artificial.
Intelligence, Washington, D.C.Schank, R. C., Tesler, L., and Weber, S. (1970).
Spinoza II:Conceptual case-based natural language analysis.
Stan-ford Artificial Intelligence Project Memo No.
AIM-109,Computer Science Department, Stanford University,Stanford, California.Schank, R. C. and Yale A. I.
Project (1975).
SAM -- A storyunderstander.
Research Report 43, Department of Com-puter Science, Yale University.Thorne, J., Bratley, P., and Dewar, H. (1968).
The syntacticanalysis of English by machine.
In D. Michie (ed.
), Ma-chine Intelligence 3, American Elsevier Publishing Com-pany, New York.Wilensky, R. (1978).
Understanding Goal-Based Stories.Research Report 140, Department of Computer Science,Yale University.Wilks, Y.
(1973).
An artificial intelligence approach to ma-chine translation.
In R. C. Schank and K. Colby, eds.,Computer Models of Thought and Language.
W. H. Free-man and Co., San Francisco.Winograd, T. (1972).
Understanding natural language.
Aca-demic Press, New York.Woods, W. A.
(1969).
Augmented transition networks fornatural language analysis.
Rep. CS-1, Computer Lab,Harvard University, Cambridge, Massachusetts.30 American Journal of Computat ional  Linguistics.
Volume 6, Number 1, January-March 1980
