Machine Translation vs. Dict ionary Term Translation- a Comparison for Engl ish- Japanese News Art ic le Al ignmentNige l  Co l l i e r ,  H idek i  H i rakawa and Ak i ra  KumanoCommunicat ion  and Informat ion Systems Laborator iesResearch and Development Center, Toshiba Corporat ion1 Komukai  Toshiba-cho, Kawasaki-shi,  Kanagawa 210-8582, Japan{nigel, hirakawa, kmn}@eel, rdc.
to shiba, co. j pAbst rac tBilingual news article alignment methods based onmulti-lingual information retrieval have been shownto be successful for the automatic production ofso-called noisy-parallel corpora.
In this paper wecompare the use of machine translation (MT) tothe commonly used dictionary term lookup (DTL)method for Reuter news article alignment in Englishand Japanese.
The results show the trade-off be-tween improved lexical disambiguation provided bymachine translation and extended synonym choiceprovided by dictionary term lookup and indicatethat MT is superior to DTL only at medium andlow recall levels.
At high recall levels DTL has su-perior precision.1 In t roduct ionIn this paper we compare the effectiveness of full ma-chine translation (MT) and simple dictionary termlookup (DTL) for the task of English-Japanese n wsarticle alignment using the vector space model frommulti-lingual information retrieval.
Matching textsdepends essentially on lexical coincidence betweenthe English text and the Japanese translation, andwe see that the two methods how the trade-off be-tween reduced transfer ambiguity in MT and in-creased synonymy in DTL.Corpus-based approaches tonatural language pro-cessing are now well established for tasks such as vo-cabulary and phrase acquisition, word sense disam-biguation and pattern learning.
The continued prac-tical application of corpus-based methods is crit-ically dependent on the availability of corpus re-sources.In machine translation we are concerned with theprovision of bilingual knowledge and we have foundthat the types of language domains which usersare interested in such as news, current affairs andtechnology, are poorly represented in today's pub-lically available corpora.
Our main area of interestis English-Japanese translation, but there are fewclean parallel corpora available in large quantities.As a result we have looked at ways of automaticallyacquiring large amounts of parallel text for vocabu-lary acquisition.The World Wide Web and other Internet re-sources provide a potentially valuable source of par-allel texts.
Newswire companies for example pub-lish news articles in various languages and variousdomains every day.
We can expect a coincidenceof content in these collections of text, but the de-gree of parallelism is likely to be less than is thecase for texts such as the United Nations and par-liamentary proceedings.
Nevertheless, we can expecta coincidence of vocabulary, in the case of names ofpeople and places, organisations and events.
Thistime-sensitive bilingual vocabulary is valuable formachine translation and makes a significant differ-ence to user satisfaction by improving the compre-hensibility of the output.Our goal is to automatically produce a parallelcorpus of aligned articles from collections of Englishand Japanese news texts for bilingual vocabulary ac-quisition.
The first stage in this process is to alignthe news texts.
Previously (Collier et al, 1998)adapted multi-lingual (also called "translingual" or"cross-language") information retrieval (MLIR) forthis purpose and showed the practicality of themethod.
In this paper we extend their investigationby comparing the performance of machine transla-tion and conventional dictionary term translation forthis task.2 ML IR  MethodsThere has recently been much interest in theMLIR task (Carbonell et al, 1997)(Dumais et al,1996)(Hull and Grefenstette, 1996).
MLIR differsfrom traditional informalion retrieval in several re-spects which we will discuss below.
The most ob-vious is that we must introduce a translation stagein between matching the query and the texts in thedocument collection.Query translation, which is currently consideredto be preferable to document collection translation,introduces several new factors to the IR task:?
Term t rans fer  mis takes  - analysis is far fromperfect in today's MT systems and we must con-263sider how to compensate for incorrect ransla-tions.?
Unresolved lexical ambiguity- occurs when anal-ysis cannot decide between alternative mean-ings of words in the target language.?
Synonym selection - when we use an MT sys-tem to translate a query, generation will usuallyresult in a single lexical choice, even though al-ternative synonyms exist.
For matching texts,the MT system may not have chosen the samesynonym in the translated query as the authorof the matching document.?
Vocabulary l imitations- are an inevitable factorwhen using bilingual dictionaries.Most of the previous work in MLIR has used sim-ple dictionary term translation within the vectorspace model (Salton, 1989).
This avoids synonymyselection constraints imposed by sentence generationin machine translation systems, but fails to resolvelexical transfer ambiguity.
Since all possible transla-tions are generated, the correctly matching term isassumed to be contained in the list and term transfermistakes are not an explicit factor.Two important issues need to be considered in dic-tionary term based MLIR.
The first, raised by Hullet al(Hull and Grefenstette, 1996), is that generat-ing multiple translations breaks the term indepen-dence assumption of the vector space model.
A sec-ond issue, identified by (Davis, 1996), is whether vec-tor matching methods can succeed given that theyessentially exploit linear (term-for-term) relations inthe query and target document.
This becomes im-portant for languages uch as English and Japanesewhere high-level transfer is necessary.Machine translation of the query on the otherhand, uses high level analysis and should be able toresolve much of the lexical transfer ambiguity sup-plied by the bilingual dictionary, leading to signif-icant improvements in performance over DTL, e.g.see (Davis, 1996).
We assume that the MT systemwill select only one synonym where a choice existsso term independence in the vector space model isnot a problem.
Term transfer mistakes clearly de-pend on the quality of analysis, but may become asignificant factor when the query contains only a fewterms and little surrounding context.Surprisingly, to the best of our knowledge, no com-parison has been attempted before between DTLand MT in MLIR.
This may be due either to the un-reliability of MT, or because queries in MLIR tendto be short phrases or single terms and MT is con-sidered too challenging.
In our application of articlealignment, where the query contains entences, it isboth meaningful and important o compare the twomethods.3 News Ar t i c le  A l ignmentThe goal of news article alignment is the same asthat in MLIR: we want to find relevant matchingdocuments in the source language corpus collectionfor those queries in the target language corpus col-lection.
The main characteristics which make newsarticle alignment different o MLIR are:?
Number of query terms - the number of termsin a query is very large compared to the usualIR task;?
Small search space - we can reduce the searchto those documents within a fixed range of thepublication date;?
Free text retrieval - we cannot control the searchvocabulary as is the case in some informationretrieval systems;?
High precision - is required because the qualityof the bilingual knowledge which we can acquireis directly related to the quality of article align-ment.We expect he end prod~act of article alignment tobe a noisy-parallel corpus.In contrast o clean-parallel texts we are just be-ginning to explore noisy-parallel texts as a seriousoption for corpus-based NLP, e.g.
(Fung and McK-eown, 1996).
Noisy-parallel texts are characterisedby heavy reformatting at the translation stage, in-cluding large sections of uatranslated text and tex-tual reordering.
Methods which seek to align singlesentences are unlikely to succeed with noisy paralleltexts and we seek to match whole documents ratherthan sentences before bilil~gual lexical knowledge ac-quisition.
The search effort required to align indi-vidual documents i considerable and makes manualalignment both tedious aJld time consuming.4 System Overv iewIn our collections of English and Japanese news arti-cles we find that the Japanese texts are much shorterthan the English texts, typically only two or threeparagraphs, and so it was natural to translate fromJapanese into English and to think of the Japanesetexts as queries.
The goal of article alignment canbe reformulated as an IR task by trying to findthe English document(s) in the collection (corpus)of news articles which most closely corresponded tothe Japanese query.
The overall system is outlinedin Figure 1 and discussed below.4.1 D ic t ionary  te rm lookup methodDTL takes each term in the query and performs dic-tionary lookup to produ,:e a list of possible trans-lation terms in the document collection language.Duplicate terms were not removed from the transla-tion list.
In our simulaticms we used a 65,000 term264,-_.=.- ?
.
.
.
.
.
.// I----i- - -  1/Figure 1: System Overviewcommon word bilingual dictionary and 14,000 termsfrom a proper noun bilingual dictionary which weconsider to be relevant o international news events.The disadvantage of term vector translation usingDTL arises from the shallow level of analysis.
Thisleads to the incorporation of a range of polysemesand homographs in the translated query which re-duces the precision of document retrieval.
In fact,the greater the depth of coverage in the bilinguallexicon, the greater this problem will become.4.2 Mach ine  t rans la t ion  methodFull machine translation (MT) is another option forthe translation stage and it should allow us to reducethe transfer ambiguity inherent in the DTL modelthrough linguistic analysis.
The system we use isToshiba Corporation's ASTRANSAC (Hirakawa etal., 1991) for Japanese to English translation.The translation model in ASTRANSAC is thetransfer method, following the standard process ofmorphological nalysis, syntactic analysis, semanticanalysis and selection of translation words.
Analy-sis uses ATNs (Augmented Transition Networks) ona context free grammar.
We modified the systemso that it used the same dictionary resources as theDTL method described above.4.3 Example  query  t rans la t ionFigure 2 shows an example sentence taken from aJapanese query together with its English translationproduced by MT and DTL methods.
We see that inboth translations there is missing vocabulary (e.g.
"7 ,~ 4~"  7~-~ ~ b" is not translated); since thetwo methods both use the same dictionary resourcethis is a constant factor and we can ignore it forcomparison purposes.As expected we see that MT has correctly re-solved some of the lexical ambiguities uch as '~:--+ world', whereas DTL has included the spu-Original Japanese text:Translation using MT:Although the American who aims at an independentworld round by the balloon, and Mr. Y,~ 4--7" :7e - -set are flying the India sky on 19th, it can seem to attaina simple world round.Translation using DTL:independent individual singlt.handed single separate solealone balloon round one rouad one revolution world earthuniverse world-wide internal ional base found ground de-pend turn hang approach come draw drop cause due twistchoose call according to bascd on owing to by by means ofunder due to through from accord owe round one roundone revolution go travel drive sail walk run American 7,4--7" aim direct toward shoot for have direct IndiaRepublic of India Rep. of India 7 ~--- Mr. Miss Ms.Mis.
Messrs. Mrs. Mmes.
Ms. Mses.
Esq.
Americansky skies upper air upper c~3ions high up in the sky up inthe air an altitude a height in the sky of over set arrange-ment arrange world earth universe world-wide universalinternational simple innoccr~t naive unsophisticated in-experienced fly hop flight aviation round one round onerevolution go travel drive sz, iI walk run seem appear en-caustic signs sign indicatioits attain achieve accomplishrealise fulfill achievement a lainmentFigure 2: Cross method comparison of a sample sen-tence taken from a Japanese query with its transla-tion in Englishrious homonym terms "earth, universe, world-wide,universal, international".In the case of synonyn-ty we notice that MT hasdecided on "independent" as the translation of "~~" ,  DTL also includes the synonyms "individual,singlehanded, single, separate, sole,..." ,etc..
The au-thor of the correctly matching English text actuallychose the term 'singlehauded', so synonym expan-sion will provide us with a better match in this case.The choice of synonyms is quite dependent on au-thor preference and style considerations which MTcannot be expected to second-guess.The limitations of MT analysis give us some selec-tion errors, for example we see that "4' ~" I <~ _1=~}~~L77~;5"  is translated as "flying the India sky.__.
",whereas the natural translation would be 'flying overIndia", even though 'over' is registered as a possibletranslation of '_l=~' in the dictionary.2655 CorpusThe English document collection consisted of Reuterdaily news articles taken from the internet for theDecember 1996 to the May 1997.
In total we have6782 English articles with an average of about 45articles per day.
After pre-processing to remove hy-pertext and formatting characters we are left withapproximately 140000 paragraphs of English text.In contrast to the English news articles, theJapanese articles, which are also produced aily byReuter's, are very short.
The Japanese is a trans-lated summary of an English article, but consider-able reformatting has taken place.
In many casesthe Japanese translation seems to draw on multiplesources including some which do not appear on thepublic newswire at all.
The 1488 Japanese articlescover the same period as the English articles.6 Imp lementat ionThe task of text alignment takes a list of texts{Q~ .... Q~} in a target language and a list of texts{Do, .., Din} in a source language and produces a listI of aligned pairs.
A pair < Q~, Dy > is in the list ifQ~ is a partial or whole translation of Dy.
In orderto decide on whether the source and target languagetext should be in the list of aligned pairs we translateQ~ into the source language to obtain Q~ using bilin-gual dictionary lookup.
We then match texts from{Q0, .., Qn } and {D0, .., Din} using standard modelsfrom Information Retrieval.
We now describe thebasic model.Termino logyAn index of t terms is generated from the docu-ment collection (English corpus) and the query set(Japanese translated articles).
Each document has adescription vector D = (Wdl, Wd2, .., Walt) where Wd~represents he weight of term k in document D. Theset of documents in the collection is N, and nk rep-resents the number of documents in which term kappears, tfdk denotes the term frequency of term kin document D. A query Q is formulated as a querydescription vector Q = (wql, wq~, .., Wqt).6.1 Mode lWe implemented the standard vector-space modelwith cosine normalisation, inverse document fre-quency idf and lexical stemming using the Porteralgorithm (Porter, 1980) to remove suffix variationsbetween surface words.The cosine rule is used to compensate for varia-tions in document length and the number of termswhen matching a query Q from the Japanese textcollection and a document D from the English textcollection.t~k=~ WqkWdk (1) Cos(Q, D) = t 9 t(Ek=l  l{~'qk X Ek=l  W2k) 1/2We combined term weights in the document andquery with a measure of the importance of the termin the document collection as a whole.
This gives usthe well-known inverse document frequency (tf+id\])score:w~:k = t fxk x log(lNl/nk ) (2)Since log(INI/nk) favours rarer terms idf is knownto improve precision.7 Exper imentIn order to automatically evaluate fractional recalland precision it was necessary to construct a repre-sentative set of Japanese articles with their correctEnglish article alignments.
We call this a judge-ment set.
Although it is a significant effort to eval-uate alignments by hand, this is possibly the onlyway to obtain an accurate assessment of the align-ment performance.
Once alignment has taken placewe compared the threshold filtered set of English-Japanese aligned articles with the judgement set toobtain recall-precision statistics.The judgement set consisted of 100 Japanesequeries with 454 relevant English documents.
Some24 Japanese queries had llO corresponding Englishdocument at all.
This large percentage of irrelevantqueries can be thought c,f as 'distractors' and is aparticular feature of this alignment ask.This set was then given to a bilingual checker whowas asked to score each aligned article pair accordingto (1) the two articles are t~'anslations of each other,(2) the two articles are strongly contextually related,(3) no match.
We removed type 3 correspondencesso that the judgement set contained pairs of articleswhich at least shared the same context, i.e.
referredto the same news event.Following inspection of matching articles we usedthe heuristic that the search space for each Japanesequery was one day either side of the day of publica-tion.
On average this was 135 articles.
This is smallby the standards of conventional IR tasks, but giventhe large number of distractor queries, the require-ment for high precision and the need to translatequeries, the task is challenging.We will define recall and precision in the usualway as follows:no.
of relevant items retrieved recall = (3)no.
of relevant items in collectionno.
of relevant items retrieved precision = (4)no.
of items retrieved266Results for the model with MT and DTL areshown in Figure 3.
We see that in the basic tf+idfmodel, machine translation provides significantlybetter article matching performance for medium andlow levels of recall.
For high recall evels DTL is bet-ter.
Lexical transfer disambiguation appears to beimportant for high precision, but synonym choicesare crucial for good recall.O,2 0.4  ReGImll 0.6  0 .8Figure 3: Model 1: Recall and precision for English-Japanese article alignment.
-4-: DTL x: MT.Overall the MT method obtained an average pre-cision of 0.72 in the 0.1 to 0.9 recall range and DTLhas an average precision of 0.67.
This 5 percent over-all improvement can be partly attributed to the factthat the Japanese news articles provided sufficientsurrounding context to enable word sense disam-biguation to be effective.
It may also show that syn-onym selection is not so detrimental where a largenumber of other terms exist in the query.
However,given these advantages we still see that DTL per-forms almost as well as MT and better at higherrecall levels.
In order to maximise recall, synonymlists provided by DTL seem to be important.
More-over, on inspection of the results we found that forsome weakly matching document-query pairs in thejudgement set, a mistranslation of an important orrare term may significantly bias the matching score.8 Conc lus ionWe have investigated the performance ofMLIR withthe DTL and MT models for news article alignmentusing English and Japanese texts.
The results inthis paper have shown surprisingly that MT doesnot have a clear advantage over the DTL model at alllevels of recall.
The trade-off between lexical trans-fer ambiguity and synonymy implies that we shouldseek a middle strategy: asophisticated system wouldperhaps perform homonym disambiguation a d thenleave alternative synonyms in the translation querylist.
This should maximise both precision and re-call and will be a target for our future work.
Fur-thermore, we would like to extend our investigationto other MLIR test sets to see how MT performsagainst DTL when the number of terms in the queryis smaller.AcknowledgementsWe gratefully acknowledge the kind permission ofReuters for the use of their newswire articles in ourresearch.
We especially thank Miwako Shimazu forevaluating the judgement, set used in our simula-tions.Re ferencesJ.
Carbonell, Y. Yang, R. Frederking, R. Brown,Y.
Geng, and D. Lee.
1997.
Translingual informa-tion retrieval: A comp:,'ative evaluation.
In Fif-teenth International Joint Conference on Artifi-cial Intelligence (IJCA 1-97), Nagoya, Japan, 23rd- 29th August.N.
Collier, A. Kumano, and H. Hirakawa.
1998.
Astudy of lexical and discourse factors in bilingualtext alignment using MLIR.
Trans.
of Informa-tion Processing Society of Japan (to appear).M.
Davis.
1996.
New exp,:riments in cross-languagetext retrieval at NMSU~s computing research lab.In Fifth Text Retrieval Conference (TREC-5).S.
Dumais, T. Landauer, and M. Littman.
1996.Automatic cross-language r trieval using latentsemantic indexing.
In G. Grefenstette, ditor,Working notes of the u'orkshop on cross-linguisticinformation retrieval A CM SIGIR.P.
Fung and K. McKeown.
1996.
A technical wordand term translation aid using noisy parallel cor-pora across language groups.
Machine Transla-tion - Special Issue on New Tools for HumanTranslators, pages 53-87.H.
Hirakawa, H. Nogami, and S. Amano.
1991.EJ / JE machine translation system ASTRANSAC- extensions towards personalization.
In Proceed-ings of the Machine Traaslation Summit III, pages73-80.D.
Hull and G. Grefenstette.
1996.
Querying acrosslanguages: A dictionary-based approach to mul-tilingual information retrieval.
In Proceedings ofthe 19th Annual International A CM SIGIR Con-ference on Research and Development in Informa-tion Retrieval, Zurich, Switzerland, pages 49-57,18-22 August.M.
Porter.
1980.
An algorithm for suffix stripping.Program, 14(3) :130-137.G.
Salton.
1989.
Automotic Text Processing- TheTransformation, Analgsis, and Retrieval of Infor-mation by Computer.
Addison-Wesley PublishingCompany, Inc., Reading, Massachusetts.267
