GRAPH: The Costs of Redundancy in Referring ExpressionsEmiel KrahmerTilburg UniversityThe Netherlandse.j.krahmer@uvt.nlMarie?t TheuneUniversity of TwenteThe Netherlandsm.theune@utwente.nlJette ViethenMacquarie UniversityAustraliajviethen@ics.mq.edu.auIris HendrickxUniversity of AntwerpBelgiumiris.hendrickx@ua.ac.beAbstractWe describe a graph-based generation sys-tem that participated in the TUNA attribute se-lection and realisation task of the REG 2008Challenge.
Using a stochastic cost function(with certain properties for free), and tryingattributes from cheapest to more expensive,the system achieves overall .76 DICE and .54MASI scores for attribute selection on the de-velopment set.
For realisation, it turns outthat in some cases higher attribute selectionaccuracy leads to larger differences betweensystem-generated and human descriptions.1 IntroductionReferring Expression Generation (REG) is a key-task in NLG, and the topic of the REG 2008 Chal-lenge.1 In this context, referring expressions areunderstood as distinguishing descriptions: descrip-tions that uniquely characterize a target object in avisual scene (e.g., ?the red sofa?
), and do not ap-ply to any of the other objects in the scene (the dis-tractors).
Generating such descriptions is usually as-sumed to be a two-step procedure: first, it has to bedecided which attributes of the target suffice to char-acterize it uniquely, and then the selected set of at-tributes should be converted into natural language.For the first step, attribute selection, we use a ver-sion of the Graph-based REG algorithm of Krahmeret al (2003).
In this approach, a visual scene is rep-resented as a directed labelled graph, where verticesrepresent the objects in the scene and edges their at-tributes.
A key ingredient of the approach is that1See http://www.itri.brighton.ac.uk/research/reg08/.costs can be assigned to attributes; the generationof referring expressions can then be defined as agraph search problem, which outputs the cheapestdistinguishing graph (if one exists) given a particu-lar cost function.
For the second step, realisation, weuse a simple template-based realiser written by IreneLangkilde-Geary from Brighton University that wasmade available to all REG 2008 participants.A version of the Graph-based algorithm was sub-mitted for the ASGRE 2007 Challenge (Theune etal.
2007).
For us, one of the most striking, gen-eral outcomes was the observed ?trend for the meanDICE score obtained by a system to decrease as theproportion of minimal descriptions increases?
(Belzand Gatt 2007).2 Thus, while REG systems havea tendency to produce minimal descriptions, hu-man speakers tend to include redundant properties intheir descriptions, which is in line with recent find-ings in psycholinguistics on the production of refer-ring expressions (e.g., Engelhardt et al 2006).In principle, the graph-based approach has the po-tential to deal with redundancy by allowing some at-tributes to have zero costs.
Viethen et al (2008),however, show that merely assigning zero costs toan attribute is not a sufficient condition for inclu-sion; if the search terminates before the free prop-erties are tried, they will not be included.
In otherwords: the order in which attributes are tried shouldbe explicitly controlled as well.
In the experimentwe describe here, we consider both these factors andtheir interplay.2DICE (like MASI) is a measure for similarity between a pre-dicted attribute set and a (human produced) reference set.2272 MethodWe experimentally combine four cost functions andtwo search orders (Table 1).
(1) Simple simply as-signs each edge a 1-point cost.
(2) Stochastic asso-ciates each edge with a frequency-based cost, basedon both the 2008 training and development sets (as-suming that a larger data set alows for more ac-curate frequency estimates).
(3) Free-Stochastic islike the previous cost function, except that highlyfrequent attributes are assigned 0 costs.
For the Fur-niture domain, this applies to ?colour?
; for Peopleto ?hasBeard = 1?
and ?hasGlasses = 1.?
(4) Free-Naive, finally, reduces the relatively fine-grainedcosts of Free-Stochastic to three values (0 = free,1 = cheap, 2 = expensive).
In addition, we com-pare results for two property orderings: (A) Proper-ties are tried in a Random order.
(B) Cost-based,where properties are tried (in stochastic order) fromcheapest to most expensive.
Finally, since humanspeakers nearly always include the ?type?
property,we decided to simply always include it.
Tables 2 to4 summarize the evaluation results for all combina-tions of cost functions and search orders.3 Attribute Selection ResultsThe measures used to evaluate attribute selection areDICE, MASI, attribute accuracy (A-A, the proportionof times the generated attribute set was identical tothe reference set), and minimality (MIN).Notice first that the order in which attributes aretried in the search process matters; the B-systemsnearly always outperform their A-counterparts.
Sec-ond, assigning varying costs also helps; both 1-variants (Simple costs) perform worse than the sys-tems building on Stochastic cost functions (2, 3and 4).
Third, adding free properties is also ben-eficial; the 3 and 4 variants clearly outperform the1 and 2 variants.
It is interesting to observe thatthe Free-naive cost function (4) performs equallywell as the more principled Free-stochastic (3), butonly in combination with the Cost-based order (B).To the extent that it is possible to compare the re-sults, the submitted GRAPH 4+B outperforms ourbest 2007 variant (GRAPH FP in Table 2).
This sug-gests that the interplay between property orderingand cost function is a flexible and efficient approachto attribute selection.Table 1: Overview of cost functions and search orders.The GRAPH 4+B settings were submitted to the REG2008 Challenge.Costs Orders1 Simple A Random2 Stochastic B Cost-based3 Free-stochastic4 Free-naiveTable 2: Furniture development set results (80 trials).GRAPH DICE MASI A-A MIN EDIT S-A1+A .61 .32 .12 .29 5.90 .041+B .61 .31 .12 .29 5.89 .042+A .71 .47 .31 .11 5.06 .052+B .69 .44 .28 .16 5.19 .053+A .80 .58 .45 .00 4.90 .053+B .80 .58 .45 .00 4.90 .054+A .80 .59 .48 .00 4.61 .054+B .80 .59 .48 .00 4.61 .05FP 2007 .71 ?
?
?
?
?Table 3: People development set results (68 trials).GRAPH DICE MASI A-A MIN EDIT S-A1+A .59 .36 .24 .00 6.54 .001+B .66 .42 .24 .00 6.78 .002+A .66 .42 .24 .00 6.78 .002+B .66 .42 .24 .00 6.78 .003+A .68 .41 .19 .00 6.79 .003+B .72 .48 .28 .00 6.96 .004+A .59 .34 .18 .00 6.56 .004+B .72 .48 .28 .00 6.96 .00FP 2007 .67 ?
?
?
?
?Table 4: Combined Furniture and People development setresults.GRAPH DICE MASI A-A MIN EDIT S-A1+A .60 .34 .18 .16 6.20 .021+B .63 .36 .18 .16 6.30 .022+A .69 .45 .28 .06 5.85 .032+B .68 .43 .26 .09 5.92 .033+A .74 .51 .33 .00 5.77 .033+B .76 .54 .37 .00 5.84 .034+A .70 .48 .34 .00 5.51 .034+B .76 .54 .39 .00 5.69 .03FP 2007 .69 ?
?
?
?
?2284 Realization ResultsTo evaluate realisation, the following two word-string comparison measures were used: string-editdistance (EDIT), which is the Levenshtein distancebetween generated word string and human referenceoutput, and string accuracy (S-A), which is the pro-portion of times the word string was identical to thereference string.For all settings of the algorithm, we see that S-Ais much lower than A-A.
This is as expected, sinceany set of attributes can be expressed in many differ-ent ways, and the chance that the realizer producesexactly the same string as the human reference isquite small.
For the furniture domain, we see thatS-A has a fairly constant low score, while EDIT fol-lows the same pattern as A-A: including redundant(free) properties leads to better results.
For the peo-ple domain, S-A is always 0, and surprisingly EDITgets worse as A-A gets better.To explain these results, we inspect those descrip-tions where A-A = 1 but S-A = 0, i.e., the attributeset is identical to the human reference but the wordstring is not.
In setting 4+B (submitted to REG 2008)this is the case for 34 furniture and 19 people de-scriptions.
For furniture, we see that the low S-Ascore can be largely explained by the fact that in 23of the 34 descriptions the human reference either in-cluded no determiner or an indefinite one, whereasthe system always included a definite determiner.This also explains why S-A hardly improves withhigher A-A scores, since determiner choice is inde-pendent from attribute selection.In the people domain, the zero scores for S-A canbe explained by the fact that the realizer always uses?person?
to express the type attribute, where the hu-man references have either ?man?
or ?guy?
(in linewith the human preference for basic level values; cf.Krahmer et al 2003).
We also encounter the de-terminer problem again, aggravated by the fact thatmany person descriptions include embedded nounphrases (e.g., ?man with beard?
).To find out why EDIT gets worse as A-A increasesfor different system settings in the people domain,we look at the six descriptions that have A-A = 1for setting 4+B but not for 4+A.
It turns out thatfive of these descriptions are realized as ?the light-haired person with a beard?, while the human refer-ence strings are variations of ?the man with a whitebeard?, resulting in a relatively high EDIT value.
Theproblem here is that the link between beard and haircolour has been lost in the data annotation process.In general, we can conclude that simply combin-ing more or less human-like attribute selection withan off-the-shelf surface realiser is not sufficient toproduce human-like referring expressions.Acknowledgements We thank the REG 2008 orga-nizers for making the realiser available, and HendriHondorp for his help with installing and using it.ReferencesBelz, A. and A. Gatt 2007.
The attribute selection forGRE challenge: Overview and evaluation results Pro-ceedings of UCNLG+MT 75-83Engelhardt, P., K. Bailey and F. Ferreira 2006.
Do speak-ers and listeners observe the Gricean Maxim of Quan-tity?
Journal of Memory and Language, 54, 554-573.Krahmer, E., S. van Erk and A. Verleg 2003.
Graph-based generation of referring expressions.
Computa-tional Linguistics, 29(1), 5372.Theune, M., P. Touset, J. Viethen, and E. Krahmer.
2007.Cost-based attribute selection for generating referringexpressions (GRAPH-FP and GRAPH-SC).
Proceedingsof the ASGRE Challenge 2007, Copenhagen, DenmarkViethen, J., R. Dale, E. Krahmer, M. Theune and P. Tou-set.
2008.
Controlling redundancy in referring expres-sions.
Proceedings LREC 08, Marrakech, Morroco.229
