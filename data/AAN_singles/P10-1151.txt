Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1492?1501,Uppsala, Sweden, 11-16 July 2010. c?2010 Association for Computational LinguisticsA Transition-Based Parser for 2-Planar Dependency StructuresCarlos Go?mez-Rodr?
?guezDepartamento de Computacio?nUniversidade da Corun?a, Spaincarlos.gomez@udc.esJoakim NivreDepartment of Linguistics and PhilologyUppsala University, Swedenjoakim.nivre@lingfil.uu.seAbstractFinding a class of structures that is richenough for adequate linguistic represen-tation yet restricted enough for efficientcomputational processing is an importantproblem for dependency parsing.
In thispaper, we present a transition system for2-planar dependency trees ?
trees that canbe decomposed into at most two planargraphs ?
and show that it can be usedto implement a classifier-based parser thatruns in linear time and outperforms a state-of-the-art transition-based parser on fourdata sets from the CoNLL-X shared task.In addition, we present an efficient methodfor determining whether an arbitrary treeis 2-planar and show that 99% or more ofthe trees in existing treebanks are 2-planar.1 IntroductionDependency-based syntactic parsing has becomea widely used technique in natural language pro-cessing, and many different parsing models havebeen proposed in recent years (Yamada and Mat-sumoto, 2003; Nivre et al, 2004; McDonald et al,2005a; Titov and Henderson, 2007; Martins et al,2009).
One of the unresolved issues in this areais the proper treatment of non-projective depen-dency trees, which seem to be required for an ad-equate representation of predicate-argument struc-ture, but which undermine the efficiency of depen-dency parsing (Neuhaus and Bro?ker, 1997; Buch-Kromann, 2006; McDonald and Satta, 2007).Caught between the Scylla of linguistically in-adequate projective trees and the Charybdis ofcomputationally intractable non-projective trees,some researchers have sought a middle ground byexploring classes of mildly non-projective depen-dency structures that strike a better balance be-tween expressivity and complexity (Nivre, 2006;Kuhlmann and Nivre, 2006; Kuhlmann and Mo?hl,2007; Havelka, 2007).
Although these proposalsseem to have a very good fit with linguistic data,in the sense that they often cover 99% or more ofthe structures found in existing treebanks, the de-velopment of efficient parsing algorithms for theseclasses has met with more limited success.
Forexample, while both Kuhlmann and Satta (2009)and Go?mez-Rodr?
?guez et al (2009) have shownhow well-nested dependency trees with boundedgap degree can be parsed in polynomial time, thebest time complexity for lexicalized parsing of thisclass remains a prohibitive O(n7), which makesthe practical usefulness questionable.In this paper, we explore another characteri-zation of mildly non-projective dependency treesbased on the notion of multiplanarity.
This wasoriginally proposed by Yli-Jyra?
(2003) but has sofar played a marginal role in the dependency pars-ing literature, because no algorithm was knownfor determining whether an arbitrary tree was m-planar, and no parsing algorithm existed for anyconstant value of m. The contribution of this pa-per is twofold.
First, we present a procedure fordetermining the minimal number m such that adependency tree is m-planar and use it to showthat the overwhelming majority of sentences in de-pendency treebanks have a tree that is at most 2-planar.
Secondly, we present a transition-basedparsing algorithm for 2-planar dependency trees,developed in two steps.
We begin by showing howthe stack-based algorithm of Nivre (2003) can begeneralized from projective to planar structures.We then extend the system by adding a secondstack and show that the resulting system capturesexactly the set of 2-planar structures.
Although thecontributions of this paper are mainly theoretical,we also present an empirical evaluation of the 2-planar parser, showing that it outperforms the pro-jective parser on four data sets from the CoNLL-Xshared task (Buchholz and Marsi, 2006).14922 Preliminaries2.1 Dependency GraphsLet w = w1 .
.
.
wn be an input string.1 An inter-val (with endpoints i and j) of the string w is a setof the form [i, j] = {wk | i ?
k ?
j}.Definition 1.
A dependency graph for w is a di-rected graph G = (Vw, E), where Vw = [1, n] andE ?
Vw ?
Vw.We call an edge (wi, wj) in a dependency graph Ga dependency link2 from wi to wj .
We say that wiis the parent (or head) of wj and, conversely, thatwj is a syntactic child (or dependent) of wi.
Forconvenience, we write wi ?
wj ?
E if the link(wi, wj) exists; wi ?
wj ?
E if there is a linkfrom wi to wj or from wj to wi; wi ??
wj ?
E ifthere is a (possibly empty) directed path from wito wj ; and wi ??
wj ?
E if there is a (possiblyempty) path between wi and wj in the undirectedgraph underlying G (omitting reference to E whenclear from the context).
The projection of a nodewi, denoted bwic, is the set of reflexive-transitivedependents of wi: bwic = {wj ?
V | wi ??
wj}.Most dependency representations do not allowarbitrary dependency graphs but typically requiregraphs to be acyclic and have at most one head pernode.
Such a graph is called a dependency forest.Definition 2.
A dependency graph G for a stringw1 .
.
.
wn is said to be a forest iff it satisfies:1.
Acyclicity: If wi ??
wj , then not wj ?
wi.2.
Single-head: If wj ?
wi, then not wk ?
wi(for every k 6= j).Nodes in a forest that do not have a head are calledroots.
Some frameworks require that dependencyforests have a unique root (i.e., are connected).Such a forest is called a dependency tree.2.2 ProjectivityFor reasons of computational efficiency, many de-pendency parsers are restricted to work with pro-jective dependency structures, that is, forests inwhich the projection of each node corresponds toa contiguous substring of the input:1For notational convenience, we will assume throughoutthe paper that all symbols in an input string are distinct, i.e.,i 6= j ?
wi 6= wj .
This can be guaranteed in practice byannotating each terminal symbol with its position in the input.2In practice, dependency links are usually labeled, but tosimplify the presentation we will ignore labels throughoutmost of the paper.
However, all the results and algorithmspresented can be applied to labeled dependency graphs andwill be so applied in the experimental evaluation.Definition 3.
A dependency forest G for a stringw1 .
.
.
wn is projective iff bwic is an interval forevery word wi ?
[1, n].Projective dependency trees correspond to the setof structures that can be induced from lexicalisedcontext-free derivations (Kuhlmann, 2007; Gaif-man, 1965).
Like context-free grammars, projec-tive dependency trees are not sufficient to repre-sent all the linguistic phenomena observed in natu-ral languages, but they have the advantage of beingefficiently parsable: their parsing problem can besolved in cubic time with chart parsing techniques(Eisner, 1996; Go?mez-Rodr?
?guez et al, 2008),while in the case of general non-projective depen-dency forests, it is only tractable under strong in-dependence assumptions (McDonald et al, 2005b;McDonald and Satta, 2007).2.3 PlanarityThe concept of planarity (Sleator and Temperley,1993) is closely related to projectivity3 and can beinformally defined as the property of a dependencyforest whose links can be drawn above the wordswithout crossing.4 To define planarity more for-mally, we first define crossing links as follows:let (wi, wk) and (wj , wl) be dependency links ina dependency graph G. Without loss of general-ity, we assume that min(i, k) ?
min(j, l).
Then,the links are said to be crossing if min(i, k) <min(j, l) < max (i, k) < max (j, l).Definition 4.
A dependency graph is planar iff itdoes not contain a pair of crossing links.2.4 MultiplanarityThe concept of planarity on its own does not seemto be very relevant as an extension of projectiv-ity for practical dependency parsing.
Accordingto the results by Kuhlmann and Nivre (2006), mostnon-projective structures in dependency treebanksare also non-planar, so being able to parse planarstructures will only give us a modest improvementin coverage with respect to a projective parser.However, our interest in planarity is motivated bythe fact that it can be generalised to multipla-narity (Yli-Jyra?, 2003):3For dependency forests that are extended with a uniqueartificial root located at position 0, as is commonly done, thetwo notions are equivalent.4Planarity in the context of dependency structures is not tobe confused with the homonymous concept in graph theory,which does not restrict links to be drawn above the nodes.1493Figure 1: A 2-planar dependency structure withtwo different ways of distributing its links into twoplanes (represented by solid and dotted lines).Definition 5.
A dependency graph G = (V,E)is m-planar iff there exist planar dependencygraphs G1 = (V,E1), .
.
.
, Gm = (V,Em) (calledplanes) such that E = E1 ?
?
?
?
?
Em.Intuitively, we can associate planes with coloursand say that a dependency graph G is m-planar if itis possible to assign one of m colours to each of itslinks in such a way that links with the same colourdo not cross.
Note that there may be multipleways of dividing an m-planar graph into planes,as shown in the example of Figure 1.3 Determining MultiplanaritySeveral constraints on non-projective dependencystructures have been proposed recently that seek agood balance between parsing efficiency and cov-erage of non-projective phenomena present in nat-ural language treebanks.
For example, Kuhlmannand Nivre (2006) and Havelka (2007) have shownthat the vast majority of structures present in exist-ing treebanks are well-nested and have a small gapdegree (Bodirsky et al, 2005), leading to an inter-est in parsers for these kinds of structures (Go?mez-Rodr?
?guez et al, 2009).
No similar analysis hasbeen performed for m-planar structures, althoughYli-Jyra?
(2003) provides evidence that all excepttwo structures in the Danish dependency treebankare at most 3-planar.
However, his analysis isbased on constraints that restrict the possible waysof assigning planes to dependency links, and he isnot guaranteed to find the minimal number m forwhich a given structure is m-planar.In this section, we provide a procedure for find-ing the minimal number m such that a dependencygraph is m-planar and use it to show that the vastmajority of sentences in dependency treebanks areFigure 2: The crossings graph corresponding tothe dependency structure of Figure 1.at most 2-planar, with a coverage comparable tothat of well-nestedness.
The idea is to reducethe problem of determining whether a dependencygraph G = (V,E) is m-planar, for a given valueof m, to a standard graph colouring problem.
Con-sider first the following undirected graph:U(G) = (E,C) whereC = {{ei, ej} | ei, ej are crossing links in G}This graph, which we call the crossings graph ofG, has one node corresponding to each link in thedependency graph G, with an undirected link be-tween two nodes if they correspond to crossinglinks in G. Figure 2 shows the crossings graphof the 2-planar structure in Figure 1.As noted in Section 2.4, a dependency graph Gis m-planar if each of its links can be assignedone of m colours in such a way that links with thesame colours do not cross.
In terms of the cross-ings graph, this means that G is m-planar if eachof the nodes of U(G) can be assigned one of mcolours such that no two neighbours have the samecolour.
This amounts to solving the well-known k-colouring problem for U(G), where k = m.For k = 1 the problem is trivial: a graph is 1-colourable only if it has no edges.
For k = 2, theproblem can be solved in time linear in the size ofthe graph by simple breadth-first search.
Given agraph U = (V,E), we pick an arbitrary node vand give it one of two colours.
This forces us togive the other colour to all its neighbours, the firstcolour to the neighbours?
neighbours, and so on.This process continues until we have processed allthe nodes in the connected component of v. If thishas resulted in assigning two different colours tothe same node, the graph is not 2-colourable.
Oth-erwise, we have obtained a 2-colouring of the con-nected component of U that contains v. If thereare still unprocessed nodes, we repeat the processby arbitrarily selecting one of them, continue withthe rest of the connected components, and in thisway obtain a 2-colouring of the whole graph if it1494Language Structures Non-Projective Not Planar Not 2-Planar Not 3-Pl.
Not 4-pl.
Ill-nestedArabic 2995 205 ( 6.84%) 158 ( 5.28%) 0 (0.00%) 0 (0.00%) 0 (0.00%) 1 (0.03%)Czech 87889 20353 (23.16%) 16660 (18.96%) 82 (0.09%) 0 (0.00%) 0 (0.00%) 96 (0.11%)Danish 5512 853 (15.48%) 827 (15.00%) 1 (0.02%) 1 (0.02%) 0 (0.00%) 6 (0.11%)Dutch 13349 4865 (36.44%) 4115 (30.83%) 162 (1.21%) 1 (0.01%) 0 (0.00%) 15 (0.11%)German 39573 10927 (27.61%) 10908 (27.56%) 671 (1.70%) 0 (0.00%) 0 (0.00%) 419 (1.06%)Portuguese 9071 1718 (18.94%) 1713 (18.88%) 8 (0.09%) 0 (0.00%) 0 (0.00%) 7 (0.08%)Swedish 6159 293 ( 4.76%) 280 ( 4.55%) 5 (0.08%) 0 (0.00%) 0 (0.00%) 14 (0.23%)Turkish 5510 657 (11.92%) 657 (11.92%) 10 (0.18%) 0 (0.00%) 0 (0.00%) 20 (0.36%)Table 1: Proportion of dependency trees classified by projectivity, planarity, m-planarity and ill-nestedness in treebanks for Arabic (Hajic?
et al, 2004), Czech (Hajic?
et al, 2006), Danish (Kromann,2003), Dutch (van der Beek et al, 2002), German (Brants et al, 2002), Portuguese (Afonso et al, 2002),Swedish (Nilsson et al, 2005) and Turkish (Oflazer et al, 2003; Atalay et al, 2003).exists.
Since this process can be completed by vis-iting each node and edge of the graph U once, itscomplexity is O(V + E).
The crossings graph ofa dependency graph with n nodes can trivially bebuilt in time O(n2) by checking each pair of de-pendency links to determine if they cross, and can-not contain more than n2 edges, which means thatwe can check if the dependency graph for a sen-tence of length n is 2-planar in O(n2) time.For k > 2, the k-colouring problem is knownto be NP-complete (Karp, 1972).
However, wehave found this not to be a problem when measur-ing multiplanarity in natural language treebanks,since the effective problem size can be reducedby noting that each connected component of thecrossings graph can be treated separately, and thatnodes that are not part of a cycle need not beconsidered.5 Given that non-projective sentencesin natural language tend to have a small propor-tion of non-projective links (Nivre and Nilsson,2005), the connected components of their cross-ings graphs are very small, and k-colourings forthem can quickly be found by brute-force search.By applying these techniques to dependencytreebanks of several languages, we obtain the datashown in Table 1.
As we can see, the coverageprovided by the 2-planarity constraint is compa-rable to that of well-nestedness.
In most of thetreebanks, well over 99% of the sentences are 2-planar, and 3-planarity has almost total coverage.As we will see below, the class of 2-planar depen-dency structures not only has good coverage of lin-guistic phenomena in existing treebanks but is alsoefficiently parsable with transition-based parsingmethods, making it a practically interesting sub-class of non-projective dependency structures.5If we have a valid colouring for all the cycles in thegraph, the rest of the nodes can be safely coloured by breadth-first search as in the k = 2 case.4 Parsing 1-Planar StructuresIn this section, we present a deterministic linear-time parser for planar dependency structures.
Theparser is a variant of Nivre?s arc-eager projec-tive parser (Nivre, 2003), modified so that it canalso handle graphs that are planar but not projec-tive.
As seen in Table 1, this only gives a modestimprovement in coverage compared to projectiveparsing, so the main interest of this algorithm liesin the fact that it can be generalised to deal with2-planar structures, as shown in the next section.4.1 Transition SystemsIn the transition-based framework of Nivre (2008),a deterministic dependency parser is defined by anon-deterministic transition system, specifying aset of elementary operations that can be executedduring the parsing process, and an oracle that de-terministically selects a single transition at eachchoice point of the parsing process.Definition 6.
A transition system for dependencyparsing is a quadruple S = (C, T, cs, Ct) where1.
C is a set of possible parser configurations,2.
T is a set of transitions, each of which is apartial function t : C ?
C,3.
cs is a function that maps each input sentencew to an initial configuration cs(w) ?
C,4.
Ct ?
C is a set of terminal configurations.Definition 7.
An oracle for a transition systemS = (C, T, cs, Ct) is a function o : C ?
T .An input sentence w can be parsed using a tran-sition system S = (C, T, cs, Ct) and an oracle oby starting in the initial configuration cs(w), call-ing the oracle function on the current configurationc, and updating the configuration by applying thetransition o(c) returned by the oracle.
This pro-cess is repeated until a terminal configuration is1495Initial configuration: cs(w1 .
.
.
wn) = ?
[], [w1 .
.
.
wn], ?
?Terminal configurations: Cf = {?
?, [], A?
?
C}Transitions: SHIFT ?
?, wi|B,A?
?
?
?|wi, B,A?REDUCE ?
?|wi, B,A?
?
?
?, B,A?LEFT-ARC ?
?|wi, wj |B,A?
?
?
?|wi, wj |B,A ?
{(wj , wi)}?only if 6 ?k|(wk, wi) ?
A (single-head) and not wi ??
wj ?
A (acyclicity).RIGHT-ARC ?
?|wi, wj |B,A?
?
?
?|wi, wj |B,A ?
{(wi, wj)}?only if 6 ?k|(wk, wj) ?
A (single-head) and not wi ??
wj ?
A (acyclicity).Figure 3: Transition system for planar dependency parsing.reached, and the dependency analysis of the sen-tence is defined by the terminal configuration.Each sequence of configurations that the parsercan traverse from an initial configuration to a ter-minal configuration for some input w is called atransition sequence.
If we associate each config-uration c of a transition system S = (C, T, cs, Ct)with a dependency graph g(c), we can say thatS is sound for a class of dependency graphs Gif, for every sentence w and transition sequence(cs(w), c1, .
.
.
, cf ) of S, g(cf ) is in G, and that Sis complete for G if, for every sentence w and de-pendency graph G ?
G for w, there is a transitionsequence (cs(w), c1, .
.
.
, cf ) such that g(cf ) = G.A transition system that is sound and complete forG is said to be correct for G.Note that, apart from a correct transition system,a practical parser needs a good oracle to achievethe desired results, since a transition system onlyspecifies how to reach all the possible dependencygraphs that could be associated to a sentence, butnot how to select the correct one.
Oracles for prac-tical parsers can be obtained by training classifierson treebank data (Nivre et al, 2004).4.2 A Transition System for PlanarStructuresA correct transition system for the class of planardependency forests can be obtained as a variant ofthe arc-eager projective system by Nivre (2003).As in that system, the set of configurations of theplanar transition system is the set of all triplesc = ?
?, B,A?
such that ?
and B are disjoint listsof words from Vw (for some input w), and A is aset of dependency links over Vw.
The list B, calledthe buffer, is initialised to the input string and isused to hold the words that are still to be read fromthe input.
The list ?, called the stack, is initiallyempty and holds words that have dependency linkspending to be created.
The system is shown in Fig-ure 3, where we use the notation ?|wi for a stackwith top wi and tail ?, and we invert the notationfor the buffer for clarity (i.e., wi|B is a buffer withtop wi and tail B).The system reads the input from left to right andcreates links in a left-to-right order by executingits four transitions:1.
SHIFT: pops the first (leftmost) word in thebuffer, and pushes it to the stack.2.
LEFT-ARC: adds a link from the first word inthe buffer to the top of the stack.3.
RIGHT-ARC: adds a link from the top of thestack to the first word in the buffer.4.
REDUCE: pops the top word from the stack,implying that we have finished building linksto or from it.Note that the planar parser?s transitions are morefine-grained than those of the arc-eager projectiveparser by Nivre (2003), which pops the stack aspart of its LEFT-ARC transition and shifts a wordas part of its RIGHT-ARC transition.
Forcing theseactions after creating dependency links rules outstructures whose root is covered by a dependencylink, which are planar but not projective.
In orderto support these structures, we therefore simplifythe ARC transitions (LEFT-ARC and RIGHT-ARC)so that they only create an arc.
For the same rea-son, we remove the constraint in Nivre?s parser bywhich words without a head cannot be reduced.This has the side effect of making the parser ableto output cyclic graphs.
Since we are interestedin planar dependency forests, which do not con-tain cycles, we only apply ARC transitions afterchecking that there is no undirected path betweenthe nodes to be linked.
This check can be donewithout affecting the linear-time complexity of the1496parser by storing the weakly connected componentof each node in g(c).The fine-grained transitions used by this parserhave also been used by Sagae and Tsujii (2008)to parse DAGs.
However, the latter parser differsfrom ours in the constraints, since it does not allowthe reduction of words without a head (disallowingforests with covered roots) and does not enforcethe acyclicity constraint (which is guaranteed bypost-processing the graphs to break cycles).4.3 Correctness and ComplexityFor reasons of space, we can only give a sketchof the correctness proof.
We wish to prove thatthe planar transition system is sound and com-plete for the set Fp of all planar dependencyforests.
To prove soundness, we have to showthat, for every sentence w and transition sequence(cs(w), c1, .
.
.
, cf ), the graph g(cf ) associatedwith cf is in Fp.
We take the graph associatedwith a configuration c = (?, B,A) to be g(c) =(Vw, A).
With this, we prove the stronger claimthat g(c) ?
Fp for every configuration c that be-longs to some transition sequence starting withcs(w).
This amounts to showing that in every con-figuration c reachable from cs(w), g(c) meets thefollowing three conditions that characterise a pla-nar dependency forest: (1) g(c) does not containnodes with more than one head; (2) g(c) is acyclic;and (3) g(c) contains no crossing links.
(1) is triv-ially guaranteed by the single-head constraint; (2)follows from (1) and the acyclicity constraint; and(3) can be established by proving that there is notransition sequence that will invoke two ARC tran-sitions on node pairs that would create crossinglinks.
At the point when a link from wi to wj iscreated, we know that all the words strictly locatedbetween wi and wj are not in the stack or in thebuffer, so no links can be created to or from them.To prove completeness, we show that everyplanar dependency forest G = (V,E) ?
Fpfor a sentence w can be produced by apply-ing the oracle function that maps a configuration?
?|wi, wj |B,A?
to:1.
LEFT-ARC if wj ?
wi ?
(E \A),2.
RIGHT-ARC if wi ?
wj ?
(E \A),3.
REDUCE if ?x[x<i][wx ?
wj ?
(E \A)],4.
SHIFT otherwise.We show completeness by setting the following in-variants on transitions traversed by the applicationof the oracle:1.
?a, b[a,b<j][wa?wb?E ?
wa?wb?A]2.
[wi?wj?A?
?k[i<k<j][wk?wj?E ?
wk?wj?A]]3.
?k[k<j][wk 6???
?l[l>k][wk?wl?E ?
wk?wl?A]]We can show that each branch of the oracle func-tion keeps these invariants true.
When we reach aterminal configuration (which always happens af-ter a finite number of transitions, since every tran-sition generating a configuration c = ?
?, B,A?decreases the value of the variant function |E| +|?| + 2|B| ?
|A|), it can be deduced from the in-variant that A = E, which proves completeness.The worst-case complexity of a deterministictransition-based parser is given by an upper boundon transition sequence length (Nivre, 2008).
Forthe planar system, like its projective counterpart,the length is clearly O(n) (where n is the numberof input words), since there can be no more thann SHIFT transitions, n REDUCE transitions, and nARC transitions in a transition sequence.5 Parsing 2-Planar StructuresThe planar parser introduced in the previous sec-tion can be extended to parse all 2-planar depen-dency structures by adding a second stack to thesystem and making REDUCE and ARC transitionsapply to only one of the stacks at a time.
Thismeans that the set of links created in the contextof each individual stack will be planar, but pairsof links created in different stacks are allowed tocross.
In this way, the parser will build a 2-planardependency forest by using each of the stacks toconstruct one of its two planes.The 2-planar transition system, shown in Figure4, has configurations of the form ?
?0,?1, B,A?,where we call ?0 the active stack and ?1 the in-active stack, and the following transitions:1.
SHIFT: pops the first (leftmost) word in thebuffer, and pushes it to both stacks.2.
LEFT-ARC: adds a link from the first word inthe buffer to the top of the active stack.3.
RIGHT-ARC: adds a link from the top of theactive stack to the first word in the buffer.4.
REDUCE: pops the top word from the activestack, implying that we have added all linksto or from it on the plane tied to that stack.5.
SWITCH: makes the active stack inactive andvice versa, changing the plane the parser isworking with.1497Initial configuration: cs(w1 .
.
.
wn) = ?
[], [], [w1 .
.
.
wn], ?
?Terminal configurations: Cf = {?
?0,?1, [], A?
?
C}Transitions: SHIFT ?
?0,?1, wi|B,A?
?
?
?0|wi,?1|wi, B,A?REDUCE ?
?0|wi,?1, B,A?
?
?
?0,?1, B,A?LEFT-ARC ?
?0|wi,?1, wj |B,A?
?
?
?0|wi,?1, wj |B,A ?
{(wj , wi)}?only if 6 ?k | (wk, wi) ?
A (single-head) and not wi ??
wj ?
A (acyclicity).RIGHT-ARC ?
?0|wi,?1, wj |B,A?
?
?
?0|wi,?1, wj |B,A ?
{(wi, wj)}?only if 6 ?k|(wk, wj) ?
A (single-head) and not wi ??
wj ?
A (acyclicity).SWITCH ?
?0,?1, B,A?
?
?
?1,?0, B,A?Figure 4: Transition system for 2-planar dependency parsing.5.1 Correctness and ComplexityAs in the planar case, we provide a brief sketchof the proof that the transition system in Figure 4is correct for the set F2p of 2-planar dependencyforests.
Soundness follows from a reasoning anal-ogous to the planar case, but applying the proofof planarity separately to each stack.
In this way,we prove that the sets of dependency links cre-ated by linking to or from the top of each of thetwo stacks are always planar graphs, and thus theirunion (which is the dependency graph stored in A)is 2-planar.
This, together with the single-head andacyclicity constraints, guarantees that the depen-dency graphs associated with reachable configura-tions are always 2-planar dependency forests.For completeness, we assume an extended formof the transition system where transitions take theform ?
?0,?1, B,A, p?, where p is a flag takingvalues in {0, 1} which equals 0 for initial config-urations and gets flipped by each application of aSWITCH transition.
Then we show that every 2-planar dependency forest G ?
F2p, with planesG0 = (V,E0) and G1 = (V,E1), can be producedby this system by applying the oracle function thatmaps a configuration ?
?0|wi,?1, wj |B,A, p?
to:1.
LEFT-ARC if wj?wi?
(Ep \A),2.
RIGHT-ARC if wi?wj ?
(Ep \A),3.
REDUCE if ?x[x<i][wx?wj ?
(Ep \A)??
?y[x<y?i][wy?wj ?
(Ep \A)]],4.
SWITCH if ?x<j : (wx, wj) or (wj , wx) ?
(Ep\A),5.
SHIFT otherwise.This can be shown by employing invariants analo-gous to the planar case, with the difference that thethird invariant applies to each stack and its corre-sponding plane: if ?y is associated with the planeEx,6 we have:3.
?k[k<j][wk 6?
?y]??l[l>k][wk?wl?Ex]?
[wk?wl?A]Since the presence of the flag p in configurationsdoes not affect the set of dependency graphs gen-erated by the system, the completeness of the sys-tem extended with the flag p implies that of thesystem in Figure 4.We can show that the complexity of the 2-planarsystem is O(n) by the same kind of reasoning asfor the 1-planar system, with the added complica-tion that we must constrain the system to preventtwo adjacent SWITCH transitions.
In fact, withoutthis restriction, the parser is not even guaranteedto terminate.5.2 ImplementationIn practical settings, oracles for transition-basedparsers can be approximated by classifiers trainedon treebank data (Nivre, 2008).
To do this, weneed an oracle that will generate transition se-quences for gold-standard dependency graphs.
Inthe case of the planar parser of Section 4.2, the or-acle of 4.3 is suitable for this purpose.
However,in the case of the 2-planar parser, the oracle usedfor the completeness proof in Section 5.1 cannotbe used directly, since it requires the gold-standardtrees to be divided into two planes in order to gen-erate a transition sequence.Of course, it is possible to use the algorithmpresented in Section 3 to obtain a division of sen-tences into planes.
However, for training purposesand to obtain a robust behaviour if non-2-planar6The plane corresponding to each stack in a configurationchanges with each SWITCH transition: ?x is associated withEx in configurations where p = 0, and with Ex in thosewhere p = 1.1498Czech Danish German PortugueseParser LAS UAS NPP NPR LAS UAS NPP NPR LAS UAS NPP NPR LAS UAS NPP NPR2-planar 79.24 85.30 68.9 60.7 83.81 88.50 66.7 20.0 86.50 88.84 57.1 45.8 87.04 90.82 82.8 33.8Malt P 78.18 84.12 ?
?
83.31 88.30 ?
?
85.36 88.06 ?
?
86.60 90.20 ?
?Malt PP 79.80 85.70 76.7 56.1 83.67 88.52 41.7 25.0 85.76 88.66 58.1 40.7 87.08 90.66 83.3 46.2Table 2: Parsing accuracy for 2-planar parser in comparison to MaltParser with (PP) and without (P)pseudo-projective transformations.
LAS = labeled attachment score; UAS = unlabeled attachment score;NPP = precision on non-projective arcs; NPR = recall on non-projective arcs.sentences are found, it is more convenient thatthe oracle can distribute dependency links into theplanes incrementally, and that it produces a dis-tribution of links that only uses SWITCH transi-tions when it is strictly needed to account for non-planarity.
Thus we use a more complex version ofthe oracle which performs a search in the crossingsgraph to check if a dependency link can be built onthe plane of the active stack, and only performs aswitch when this is not possible.
This has provedto work well in practice, as will be observed in theresults in the next section.6 Empirical EvaluationIn order to get a first estimate of the empirical ac-curacy that can be obtained with transition-based2-planar parsing, we have evaluated the parseron four data sets from the CoNLL-X shared task(Buchholz and Marsi, 2006): Czech, Danish, Ger-man and Portuguese.
As our baseline, we takethe strictly projective arc-eager transition systemproposed by Nivre (2003), as implemented in thefreely available MaltParser system (Nivre et al,2006a), with and without the pseudo-projectiveparsing technique for recovering non-projectivedependencies (Nivre and Nilsson, 2005).
For thetwo baseline systems, we use the parameter set-tings used by Nivre et al (2006b) in the originalshared task, where the pseudo-projective versionof MaltParser was one of the two top performingsystems (Buchholz and Marsi, 2006).
For our 2-planar parser, we use the same kernelized SVMclassifiers as MaltParser, using the LIBSVM pack-age (Chang and Lin, 2001), with feature modelsthat are similar to MaltParser but extended withfeatures defined over the second stack.7In Table 2, we report labeled (LAS) and un-labeled (UAS) attachment score on the four lan-guages for all three systems.
For the two systemsthat are capable of recovering non-projective de-7Complete information about experimental settings canbe found at http://stp.lingfil.uu.se/ nivre/exp/.pendencies, we also report precision (NPP) andrecall (NPR) specifically on non-projective depen-dency arcs.
The results show that the 2-planarparser outperforms the strictly projective variantof MaltParser on all metrics for all languages,and that it performs on a par with the pseudo-projective variant with respect to both overall at-tachment score and precision and recall on non-projective dependencies.
These results look verypromising in view of the fact that very little efforthas been spent on optimizing the training oracleand feature model for the 2-planar parser so far.It is worth mentioning that the 2-planar parserhas two advantages over the pseudo-projectiveparser.
The first is simplicity, given that it is basedon a single transition system and makes a singlepass over the input, whereas the pseudo-projectiveparsing technique involves preprocessing of train-ing data and post-processing of parser output(Nivre and Nilsson, 2005).
The second is the factthat it parses a well-defined class of dependencystructures, with known coverage8, whereas no for-mal characterization exists of the class of struc-tures parsable by the pseudo-projective parser.7 ConclusionIn this paper, we have presented an efficient algo-rithm for deciding whether a dependency graph is2-planar and a transition-based parsing algorithmthat is provably correct for 2-planar dependencyforests, neither of which existed in the literaturebefore.
In addition, we have presented empiricalresults showing that the class of 2-planar depen-dency forests includes the overwhelming majorityof structures found in existing treebanks and thata deterministic classifier-based implementation ofthe 2-planar parser gives state-of-the-art accuracyon four different languages.8If more coverage is desired, the 2-planar parser can begeneralised to m-planar structures for larger values of m byadding additional stacks.
However, this comes at the cost ofmore complex training models, making the practical interestof increasing m beyond 2 dubious.1499AcknowledgmentsThe first author has been partially supported byMinisterio de Educacio?n y Ciencia and FEDER(HUM2007-66607-C04) and Xunta de Galicia(PGIDIT07SIN005206PR, Rede Galega de Proce-samento da Linguaxe e Recuperacio?n de Infor-macio?n, Rede Galega de Lingu??
?stica de Corpus,Bolsas Estad?
?as INCITE/FSE cofinanced).ReferencesSusana Afonso, Eckhard Bick, Renato Haber, and Di-ana Santos.
2002.
?Floresta sinta?(c)tica?
: a tree-bank for Portuguese.
In Proceedings of the 3rd In-ternational Conference on Language Resources andEvaluation (LREC 2002), pages 1968?1703, Paris,France.
ELRA.Nart B. Atalay, Kemal Oflazer, and Bilge Say.
2003.The annotation process in the Turkish treebank.In Proceedings of EACL Workshop on Linguisti-cally Interpreted Corpora (LINC-03), pages 243?246, Morristown, NJ, USA.
Association for Com-putational Linguistics.Leonoor van der Beek, Gosse Bouma, Robert Malouf,and Gertjan van Noord.
2002.
The Alpino depen-dency treebank.
In Language and Computers, Com-putational Linguistics in the Netherlands 2001.
Se-lected Papers from the Twelfth CLIN Meeting, pages8?22, Amsterdam, the Netherlands.
Rodopi.Manuel Bodirsky, Marco Kuhlmann, and MathiasMo?hl.
2005.
Well-nested drawings as models ofsyntactic structure.
In 10th Conference on FormalGrammar and 9th Meeting on Mathematics of Lan-guage, Edinburgh, Scotland, UK.Sabine Brants, Stefanie Dipper, Silvia Hansen, Wolf-gang Lezius, and George Smith.
2002.
The tigertreebank.
In Proceedings of the Workshop on Tree-banks and Linguistic Theories, September 20-21,Sozopol, Bulgaria.Matthias Buch-Kromann.
2006.
Discontinuous Gram-mar: A Model of Human Parsing and LanguageAcquisition.
Ph.D. thesis, Copenhagen BusinessSchool.Sabine Buchholz and Erwin Marsi.
2006.
CoNLL-X shared task on multilingual dependency parsing.In Proceedings of the 10th Conference on Computa-tional Natural Language Learning (CoNLL), pages149?164.Chih-Chung Chang and Chih-Jen Lin, 2001.LIBSVM: A Library for Support Vec-tor Machines.
Software available athttp://www.csie.ntu.edu.tw/?cjlin/libsvm.Jason Eisner.
1996.
Three new probabilistic mod-els for dependency parsing: An exploration.
InProceedings of the 16th International Conferenceon Computational Linguistics (COLING-96), pages340?345, San Francisco, CA, USA, August.
ACL /Morgan Kaufmann.Haim Gaifman.
1965.
Dependency systems andphrase-structure systems.
Information and Control,8:304?337.Carlos Go?mez-Rodr?
?guez, John Carroll, and DavidWeir.
2008.
A deductive approach to depen-dency parsing.
In Proceedings of the 46th An-nual Meeting of the Association for Computa-tional Linguistics: Human Language Technologies(ACL?08:HLT), pages 968?976, Morristown, NJ,USA.
Association for Computational Linguistics.Carlos Go?mez-Rodr?
?guez, David Weir, and John Car-roll.
2009.
Parsing mildly non-projective depen-dency structures.
In Proceedings of the 12th Con-ference of the European Chapter of the Associationfor Computational Linguistics (EACL), pages 291?299.Jan Hajic?, Otakar Smrz?, Petr Zema?nek, Jan S?naidauf,and Emanuel Bes?ka.
2004.
Prague Arabic de-pendency treebank: Development in data and tools.In Proceedings of the NEMLAR International Con-ference on Arabic Language Resources and Tools,pages 110?117.Jan Hajic?, Jarmila Panevova?, Eva Hajic?ova?, JarmilaPanevova?, Petr Sgall, Petr Pajas, Jan S?te?pa?nek,Jir???
Havelka, and Marie Mikulova?.
2006.Prague Dependency Treebank 2.0.
CDROMCAT: LDC2006T01, ISBN 1-58563-370-4.
Linguis-tic Data Consortium.Jiri Havelka.
2007.
Beyond projectivity: Multilin-gual evaluation of constraints and measures on non-projective structures.
In Proceedings of the 45th An-nual Meeting of the Association of ComputationalLinguistics, pages 608?615.Richard M. Karp.
1972.
Reducibility among combi-natorial problems.
In R. Miller and J. Thatcher, ed-itors, Complexity of Computer Computations, pages85?103.
Plenum Press.Matthias T. Kromann.
2003.
The Danish dependencytreebank and the underlying linguistic theory.
InProceedings of the 2nd Workshop on Treebanks andLinguistic Theories (TLT), pages 217?220, Va?xjo?,Sweden.
Va?xjo?
University Press.Marco Kuhlmann and Mathias Mo?hl.
2007.
Mildlycontext-sensitive dependency languages.
In Pro-ceedings of the 45th Annual Meeting of the Associa-tion of Computational Linguistics, pages 160?167.Marco Kuhlmann and Joakim Nivre.
2006.
Mildlynon-projective dependency structures.
In Proceed-ings of the COLING/ACL 2006 Main ConferencePoster Sessions, pages 507?514.1500Marco Kuhlmann and Giorgio Satta.
2009.
Treebankgrammar techniques for non-projective dependencyparsing.
In Proceedings of the 12th Conference ofthe European Chapter of the Association for Com-putational Linguistics (EACL), pages 478?486.Marco Kuhlmann.
2007.
Dependency Structures andLexicalized Grammars.
Doctoral dissertation, Saar-land University, Saarbru?cken, Germany.Andre Martins, Noah Smith, and Eric Xing.
2009.Concise integer linear programming formulationsfor dependency parsing.
In Proceedings of theJoint Conference of the 47th Annual Meeting of theACL and the 4th International Joint Conference onNatural Language Processing of the AFNLP (ACL-IJCNLP), pages 342?350.Ryan McDonald and Giorgio Satta.
2007.
On the com-plexity of non-projective data-driven dependencyparsing.
In Proceedings of the 10th InternationalConference on Parsing Technologies (IWPT), pages122?131.Ryan McDonald, Koby Crammer, and FernandoPereira.
2005a.
Online large-margin training of de-pendency parsers.
In Proceedings of the 43rd An-nual Meeting of the Association for ComputationalLinguistics (ACL), pages 91?98.Ryan McDonald, Fernando Pereira, Kiril Ribarov, andJan Hajic?.
2005b.
Non-projective dependency pars-ing using spanning tree algorithms.
In HLT/EMNLP2005: Proceedings of the conference on HumanLanguage Technology and Empirical Methods inNatural Language Processing, pages 523?530, Mor-ristown, NJ, USA.
Association for ComputationalLinguistics.Peter Neuhaus and Norbert Bro?ker.
1997.
The com-plexity of recognition of linguistically adequate de-pendency grammars.
In Proceedings of the 35thAnnual Meeting of the Association for Computa-tional Linguistics (ACL) and the 8th Conference ofthe European Chapter of the Association for Com-putational Linguistics (EACL), pages 337?343.Jens Nilsson, Johan Hall, and Joakim Nivre.
2005.MAMBA meets TIGER: Reconstructing a Swedishtreebank from antiquity.
In Proceedings of NODAL-IDA 2005 Special Session on Treebanks, pages 119?132.
Samfundslitteratur, Frederiksberg, Denmark,May.Joakim Nivre and Jens Nilsson.
2005.
Pseudo-projective dependency parsing.
In ACL ?05: Pro-ceedings of the 43rd Annual Meeting of the Associa-tion for Computational Linguistics, pages 99?106,Morristown, NJ, USA.
Association for Computa-tional Linguistics.Joakim Nivre, Johan Hall, and Jens Nilsson.
2004.Memory-based dependency parsing.
In Proceed-ings of the 8th Conference on Computational Nat-ural Language Learning (CoNLL-2004), pages 49?56, Morristown, NJ, USA.
Association for Compu-tational Linguistics.Joakim Nivre, Johan Hall, and Jens Nilsson.
2006a.MaltParser: A data-driven parser-generator for de-pendency parsing.
In Proceedings of the 5th In-ternational Conference on Language Resources andEvaluation (LREC), pages 2216?2219.Joakim Nivre, Johan Hall, Jens Nilsson, Gu?lsenEryig?it, and Svetoslav Marinov.
2006b.
Labeledpseudo-projective dependency parsing with supportvector machines.
In Proceedings of the 10th Confer-ence on Computational Natural Language Learning(CoNLL), pages 221?225.Joakim Nivre.
2003.
An efficient algorithm for pro-jective dependency parsing.
In Proceedings of the8th International Workshop on Parsing Technologies(IWPT), pages 149?160.Joakim Nivre.
2006.
Constraints on non-projective de-pendency graphs.
In Proceedings of the 11th Con-ference of the European Chapter of the Associationfor Computational Linguistics (EACL), pages 73?80.Joakim Nivre.
2008.
Algorithms for Deterministic In-cremental Dependency Parsing.
Computational Lin-guistics, 34(4):513?553.Kemal Oflazer, Bilge Say, Dilek Zeynep Hakkani-Tu?r,and Go?khan Tu?r.
2003.
Building a Turkish tree-bank.
In A. Abeille (ed.
), Building and ExploitingSyntactically-annotated Corpora, pages 261?277,Dordrecht, the Netherlands.
Kluwer.Kenji Sagae and Jun?ichi Tsujii.
2008.
Shift-reducedependency DAG parsing.
In COLING ?08: Pro-ceedings of the 22nd International Conference onComputational Linguistics, pages 753?760, Morris-town, NJ, USA.
Association for Computational Lin-guistics.Daniel Sleator and Davy Temperley.
1993.
ParsingEnglish with a Link Grammar.
In Proceedings of theThird International Workshop on Parsing Technolo-gies (IWPT?93), pages 277?292.
ACL/SIGPARSE.Ivan Titov and James Henderson.
2007.
A latent vari-able model for generative dependency parsing.
InProceedings of the 10th International Conference onParsing Technologies (IWPT), pages 144?155.Hiroyasu Yamada and Yuji Matsumoto.
2003.
Statis-tical dependency analysis with support vector ma-chines.
In Proceedings of the 8th InternationalWorkshop on Parsing Technologies (IWPT), pages195?206.Anssi Mikael Yli-Jyra?.
2003.
Multiplanarity ?
amodel for dependency structures in treebanks.
InJoakim Nivre and Erhard Hinrichs, editors, TLT2003.
Proceedings of the Second Workshop on Tree-banks and Linguistic Theories, volume 9 of Mathe-matical Modelling in Physics, Engineering and Cog-nitive Sciences, pages 189?200, Va?xjo?, Sweden, 14-15 November.
Va?xjo?
University Press.1501
