Proceedings of the NAACL HLT Workshop on Computational Approaches to Linguistic Creativity, pages 9?16,Boulder, Colorado, June 2009. c?2009 Association for Computational LinguisticsTopic Model Analysis of Metaphor Frequency for Psycholinguistic StimuliSteven BethardComputer Science DepartmentStanford UniversityStanford, CA 94305bethard@stanford.eduVicky Tzuyin LaiDepartment of LinguisticsUniversity of Colorado295 UCB, Boulder CO 80309vicky.lai@colorado.eduJames H. MartinDepartment of Computer ScienceUniversity of Colorado430 UCB, Boulder CO 80309james.martin@colorado.eduAbstractPsycholinguistic studies of metaphor process-ing must control their stimuli not just forword frequency but also for the frequencywith which a term is used metaphorically.Thus, we consider the task of metaphor fre-quency estimation, which predicts how oftentarget words will be used metaphorically.
Wedevelop metaphor classifiers which representmetaphorical domains through Latent Dirich-let Allocation, and apply these classifiers tothe target words, aggregating their decisions toestimate the metaphorical frequencies.
Train-ing on only 400 sentences, our models are ableto achieve 61.3% accuracy on metaphor clas-sification and 77.8% accuracy on HIGH vs.LOW metaphorical frequency estimation.1 IntroductionPsycholinguistic studies of metaphor try to under-stand metaphorical language comprehension by pre-senting subjects with linguistic stimuli and observ-ing their responses.
Recent work has observed suchresponses at the electrophysiological level, measur-ing brain electrical activity as the stimuli are read(Coulson and Petten, 2002; Tartter et al, 2002; Iaki-mova et al, 2005; Arzouan et al, 2007; Lai et al,2007).
All these studies have attempted to makecomparisons across different types of stimuli (e.g.literal vs. metaphorical) by holding the frequen-cies of the target words constant across experimentalconditions.
For example, Tartter et al (2002) com-pared the metaphorical and literal sentences his facewas contorted by an angry cloud and his face wascontorted by an angry frown, where the two sen-tences end in different words, but where the finalwords cloud and frown had similar word frequen-cies.
As another example, Lai et al (2007) com-pared the metaphorical and literal sentences Theirtheories have collapsed and The old building hascollapsed, where the two sentences end in exactlythe same words, so the target word frequenciesacross conditions were perfectly matched.
In bothdesigns, controlling for word frequency allowed theresearchers to attribute the differences in experimen-tal conditions to interesting factors, like figurativity,rather than simple word frequency.However, word frequency is not the only type offrequency relevant to such experiments.
In particu-lar, metaphorical frequency, that is, how inherentlymetaphorical one word is as compared to another,may also play an important role in explaining thepsycholinguistic results.
For example, if collapsedis usually used literally, a greater processing effortmay be observed when a metaphorical instance ofcollapsed is presented.
Likewise, if collapsed isusually used metaphorically, greater effort may beobserved when a literal instance is presented.
Psy-cholinguistic studies of metaphor have not, to date,controlled for such metaphorical frequency becausethere were no corpora or algorithms which couldprovide the needed metaphorical frequencies.The present study aims to address this deficiencyby producing models which can automatically esti-mate how often a word is used metaphorically.
Webuild these models using only 50 examples each ofa small number of target words (< 10), rather thanrequiring 50 or more examples of every target word9(100+) in the stimuli, as would be required by stan-dard corpus linguistics methods.
Our approach isalso novel in that it combines metaphor classifica-tion with statistical topic models.
Topic models areintuitively promising for our task because they pro-duce topics that seem to translate well to the theoryof conceptual domains, which suggests that, for ex-ample, conceptual domains such as THEORIES andBUILDINGS are used to understand Their theorieshave collapsed.
These topic models also show somepromise for distinguishing conventional metaphorsfrom novel metaphors.2 Prior WorkTwo types of prior research inform our currentstudy: corpus analyses investigating metaphor fre-quency by hand, and machine learning models thatclassify text as either literal or metaphorical.
Thelatter could be used to estimate metaphor frequen-cies by applying the classifier to a corpus and aggre-gating the classifications.2.1 Metaphor FrequencyResearchers have manually estimated several differ-ent kinds of metaphor frequency.
Pollio et al (1990)looked at overall metaphorical frequency, perform-ing an exhaustive analysis of a variety of texts, andconcluding that there were about five metaphors forevery 100 words of text.
Martin (1994) looked atthe frequency of different types of metaphor, us-ing a sample of 600 sentences from the Wall StreetJournal (WSJ), and concluded among other thingsthat the most frequent type of WSJ metaphor wasVALUE is LOCATION, e.g.
Spain Fund tumbled23%.
Martin (2006) looked at conditional probabil-ities of metaphor, for example noting that in 2400WSJ sentences, the probability of seeing an instanceof a metaphor was greatly increased after a first in-stance had already been observed.
However, none ofthese studies provided the metaphorical frequenciesof individual words needed for our research.Sardinha (2008) performed what is probably clos-est to the type of analysis we are interested in.Using a corpus of Portuguese conference calls,Berber Sardinha identified 432 terms that were usedmetaphorically.
He then took 100 instances of eachof these terms in a general Brazilian corpus andmanually annotated them as being either literal ormetaphorical.
Berber Sardinha found that on aver-age these terms were used metaphorically 70% ofthe time, and provided analysis of the metaphor-ical frequencies of a number of individual terms.While it is exactly these kinds of individual termfrequencies that we are after, we cannot use BerberSardinha?s data because his corpus was in Por-tuguese while we are interested in English.
Thisbrings out one of the main drawbacks of the corpusannotation approach: moving to a new language (oreven a new genre) requires an extensive manual an-notation project.
Our goal is to avoid such costs bytaking advantage of machine learning techniques forautomatically identifying metaphorical text.2.2 Metaphor ClassificationRecent years have seen a rising interest in metaphorclassification systems.
Birke and Sarkar (2006) tooka semi-supervised approach, collecting noisy exam-ples of literal and non-literal sentences from bothWordNet and metaphor dictionaries, and using aword-based measure of sentence similarity to groupsentences into literal and non-literal clusters.
Theyevaluated on hand-annotated sentences for 25 targetwords and reported an F-score of 0.538, a substantialimprovement over the 0.294 majority class baseline.Gedigian et al (2006) approached metaphoridentification as supervised classification, annotat-ing around 4000 WSJ motion words as literal ormetaphorical, and training a maximum entropy clas-sifier using as features based on named entities,WordNet and semantic roles.
They achieved an ac-curacy of 95.1%, a decent improvement over thevery high majority class baseline of 93.8%.Krishnakumaran and Zhu (2007) focused on threesyntactically constrained sub-types of metaphors:nouns joined by be, nouns following verbs, andnouns following adjectives.
They combined Word-Net hypernym information with bigram statisticsand a threshold, and evaluated their algorithm onthe Berkeley Master Metaphor List (Lakoff, 1994),achieving an accuracy of around 46%.All of these approaches produced models whichcould be applied to new text to identify metaphors,but each has some drawbacks for our task.
TheWSJ study of Gedigian et al (2006) found 94% oftheir target words to be metaphorical, a vastly differ-10Target L M M%attacked 32 18 36%born 45 5 10%budding 16 34 68%collapsed 10 40 80%digest 7 43 86%drifted 16 34 68%floating 25 25 50%sank 31 19 38%spoke 47 3 6%Total 229 221 49%Table 1: Metaphorical (M) and literal (L) counts, andmetaphorical percentage (M%), for the annotated verbs.ent number from the 49% for our target words (seeSection 3).
Krishnakumaran and Zhu (2007) con-sidered only a few different syntactic constructions,but we need to consider all the ways a metaphormay be expressed to evaulate overall metaphor fre-quency.
Birke and Sarkar (2006) did consider a va-riety of target words in unrestricted text, but reliedon large scale language resources like WordNet andmetaphor dictionaries, while we are interested in ap-proaches that are less resource intensive.Thus, rather than basing our models on these priorsystems, we develop a novel approach to metaphorfrequency estimation based on using topic models tooperationalize metaphorical domains.3 DataThe first step in building models of metaphoricalfrequency is obtaining data for training and evalu-ation.
In one of the post-hoc analyses of the Lai etal.
(2007) experiment, 50 sentences from the BritishNational Corpus (BNC, 2007) were gathered foreach of nine of their target words.
They annotatedeach instance as either literal or metaphorical, andthen used these annotations to calculate metaphori-cal frequencies for analysis.This data served as our starting point for exploringcomputational approaches to estimating metaphor-ical frequency.
Table 1 shows the nine verbs andtheir metaphorical frequencies.
Table 2 shows someexamples.
Some verbs, such as digest, are almost al-ways used metaphorically (86% of the time), whileother verbs, such as spoke, are almost always usedL Aye, that?s where I was born and reared.M VATman threatens our budding entrepreneurs.M Suddenly all her bravado collapsed.L This makes it easier for us to digest the wheat.L Gulls drifted lethargically on the swell.M My heart sank as I looked around.Table 2: Examples of sentences with metaphorical (M)and literal (L) target words.T# Most frequent words00 book (4%) write (2%) read (2%) english (2%)17 record (3%) music (2%) band (2%) play (2%)42 social (3%) history (2%) culture (1%) society (1%)58 film (3%) play (2%) theatre (1%) women (1%)82 dog (9%) rabbit (2%) ferret (1%) pet (1%)Table 3: Example topics (T#) from the BNC and theirmost frequent words.
Numbers in parentheses indicatethe percent of the topic each word represents.literally (94% of the time).
Annotation of just 50instances of each of these nine verbs was time con-suming, and yet to fully re-analyze the ERP results,metaphorical frequencies would be needed for all ofthe over 100 target words.
Thus our goal was to au-tomate this process.4 Topic ModelsOur approach to estimating metaphorical frequen-cies was first to classify words in unrestricted textas literal or metaphorical, and then to aggregatethose decisions to estimate a frequency.
Thus, wefirst needed to build a model which could iden-tify metaphorical expressions.
Our approach to thisproblem was based on the theory of conceptual do-mains, in which metaphors are seen as taking termsfrom one domain (e.g.
attacked) and applying themto another domain (e.g.
argument).To operationalize these domains, we employedstatistical topic models, in particular, Latent Dirich-let Allocation (LDA) (Blei et al, 2003).
Intuitively,LDA looks at how words co-occur in the documentsof a large corpus, and identifies topics or groups ofwords that are semantically similar.
For example,Table 3 shows a few topics from the BNC.
Thesetopics can be thought of as grouping words by theirsemantic domains.
For example, we might think oftopic 00 as the Book domain and topic 42 as the Soci-ety domain.
Because LDA generates topics that look11much like the source and target domains associatedwith metaphors, we expect that LDA can provide aboost to metaphor identification models.The LDA algorithm is usually presented as a gen-erative model, that is, as an imagined process thatsomeone might go through when writing a text.
Thisgenerative process looks something like:1.
Decide what topics you want to write about.2.
Pick one of those topics.3.
Think of words used to discuss that topic.4.
Pick one of those words.5.
To generate the next word, go back to 2.This is a somewhat unrealistic description of thewriting process, but it gets at the idea that the wordsin a document are topically coherent.
Formally, theprocess above can be described as:1.
For each document d select a topic distribution?d ?
Dir(?)2.
Select a topic z ?
?d3.
For each topic select a word distribution?z ?
Dir(?)4.
Select a word w ?
?zThe goal of the LDA learning algorithm then is tomaximize the likelihood of our documents, wherefor one document p(d|?, ?)
= ?Ni=1 p(wi|?, ?).
Es-timating these probabilities can be done in a few dif-ferent ways, but in this paper we use Gibbs samplingas it has been widely implemented and was availablein the LingPipe toolkit (Alias-i, 2008).Gibbs sampling starts by randomly assigning top-ics to all words in the corpus.
Then the word-topicdistributions and document-topic distributions areestimated using the following equations:P (zi|zi?, wi, di, wi?, di?, ?, ?)
= ?ij?jd?Tt=1 ?it?td?ij = Cwordij+?
?Wk=1 Cwordkj+W?
?jd = Cdocdj+?
?Tk=1 Cdocdk+T?Cwordij is the number of times word i was assignedtopic j, Cdocdj is the number of times topic j ap-pears in document d, W is the total number ofunique words in the corpus, and T is the numberof topics requested.
In essence, we count the num-ber of times that a word is assigned a topic andthe number of times a topic appears in a document,and we use these numbers to estimate word-topicand document-topic probabilities.
Once topics havebeen assigned and distributions have been calcu-lated, Gibbs sampling repeats the process, this timeselecting a new topic for each word by looking atthe calculated probabilities.
The process is repeateduntil the distributions become stable or a set numberof iterations is reached.We ran LDA over the documents in the BNC, ex-tracting 100 topics after 2000 iterations of Gibbssampling.
We left the ?
and ?
parameters at theirLingPipe defaults of 0.1 and 0.01, respectively.
Ta-ble 3 shows some of the resulting topics.5 Metaphor FrequencyOur primary goal was to use the topics produced byLDA to help characterize words in terms of theirmetaphorical frequency.
We approached this prob-lem by first training metaphor classifiers based onLDA topics to identify target words in text as lit-eral or metaphorical.
Then we ran these classifiersover unseen data, and aggregated the individual de-cisions.
The result is an approximate metaphoricalfrequency for each word.
The following sections de-tail this process and discuss our preliminary results.5.1 Metaphor ClassificationOur data is composed of 50 sentences for each ofnine target words, with each sentence annotated aseither metaphorical or literal.
We treated this as aclassification task, where the classifier took as inputa sentence containing a target word, and produced asoutput either LITERAL or METAPHORICAL.We trained support vector machine (SVM) clas-sifiers on this data, using LDA topics as features.For each of the sentences in our data, we used theLDA topic models to assign topic probability distri-butions to each of the words in the sentence.
We thensummed the topic distributions over all the words inthe sentence to produce a sentence-wide topic dis-tribution.
The result was that for each sentence wecould say something like ?this sentence was com-posed of 5% topic 00, 2% topic 01, 8% topic 02,etc.?
We used these sentence-level topic probabil-ity distributions as features for an SVM classifier, inparticular, SVMperf (Joachims, 2005).We compared this SVM-LDA model against twobaselines.
The first was the standard majority class12classifier, which simply assigns all instances in thetest data whichever label (metaphorical or literal)was most comon in the training data.The second baseline was an SVM based on TF-IDF features, a well known document classificationmodel (Joachims, 1998; Sebastiani, 2002; Lewis etal., 2004).
Under this approach, there is a numericfeature for each of the 3000+ words in the trainingdata, and each word feature is assigned the weight:|{w ?
doc : w = word}||{w ?
doc}| ?log|{d ?
docs}||{d ?
docs : w ?
d}|Essentially, this formula means that the weight in-creases with the number of times the word occursin the document, and decreases with the number ofdocuments in the corpus that contain that word.
Thevectors of TF-IDF features are then normalized tohave Euclidean length 1.0, using the formula:weight(word) = tf-idf(word)?
?word?tf-idf(word?
)2To evaluate our model against both the majorityclass and the TF-IDF baselines, we ran nine-foldcross-validations, where each fold corresponded toa single target word.
Note that this means that wetrained our models on the sentences of eight targetwords, and tested on the sentences of the ninth tar-get word.
This is a harder evaluation than a strat-ified cross-validation where all target words wouldhave been observed during training.
But it is a muchmore realistic evaluation for our task, where we wantto learn enough about metaphors from nine targetwords that we can automatically classify instancesof the remaining 95.Table 4 compares the performance of our SVM-LDA model and the baseline models1.
The major-ity class classifier performs poorly, achieving only26.4% accuracy2.
The TF-IDF based model per-forms much better, at 50.7% accuracy.
However, ourSVM based on LDA features outperforms both base-line models, achieving 54.9% accuracy.1For all models, hyper parameters (the cost parameter, theloss function, etc.)
were set using only the training data of eachfold by running an inner eight-fold cross validation.2This might be initially surprising since our corpus was 49%metaphorical.
Consider, however, that during cross validation,holding out a more metaphorical target word for testing meansthat our training data is more literal, and vice versa.Model AccuracyMajority Class 26.4%SVM + TF-IDF 50.7%SVM + LDA topics 54.9%SVM + LDA topics + LDA groups 61.3%Table 4: Model performance on the literal vs. metaphor-ical classification task.Type Most frequent wordsCONCRETE book write read english novelABSTRACT god church christian jesus spiritMIXED sleep dream earth theory moonOTHER many time only number largeTable 5: Examples of annotated topics.5.2 Annotating TopicsThe metaphor classification results showed the ben-efit of operationalizing metaphor domains as LDAtopics.
But metaphors are typically viewed as map-ping a concrete source domain onto an abstract tar-get domain, and our LDA topics had no direct notionof this concrete/abstract distinction.
To try to repre-sent this distinction, we manually annotated3 the 100LDA topics with one of four labels: CONCRETE,ABSTRACT, MIXED or OTHER.
Table 5 shows ex-amples of the annotated topics.We then used the annotated topics to generate newfeatures for our classifiers.
In addition to the original100 topic probability features, we provided four newprobability features, one for each of our labels, cal-culated by taking the sum of the probabilities of thecorresponding topics.
For example, since topics 07,13, 37 and 77 were identified as ABSTRACT topics,the probability of the new ABSTRACT feature wasjust the sum of the probabilities of the topic features07, 13, 37 and 77.
The last row of Table 4 showsthe performance of the SVM model trained with theaugmented feature set.
This model outperforms allour other models, achieving an accuracy of 61.3%on the literal vs. metaphorical distinction.These results are interesting because they showthat human analysis of LDA topics can add substan-tial value for machine learning models at a low cost.Annotating the entire set of 100 topics took under3All annotation was performed by a single annotator.
Futurework will measure inter-annotator agreement.13Model AccuracyMajority Class 0.0%SVM + TF-IDF 22.2%SVM + LDA topics 55.6%SVM + LDA topics + LDA groups 77.8%Table 6: Model performance on the HIGH vs. LOWmetaphor frequency prediction task.an hour, and yet provided a 6% gain in model ac-curacy.
The speed of annotation suggests that LDAtopics are conceptually accessible to humans, andthe performance boost suggests that manual group-ing of LDA topics may be a fruitful area for featureengineering.5.3 Predicting Metaphorical FrequenciesHaving constructed successful metaphor classifica-tion models, we return to our question of metaphor-ical frequency.
Given a target word, can we pre-dict the frequency with which that word will beused metaphorically?
Our models are not accurateenough that we can expect the frequencies derivedfrom them to be exact predictions of metaphoricalfrequency.
But we may be able to distinguish, forexample, words with high metaphorical frequencyfrom words with low metaphorical frequency.Thus, we evaluate our models on the binary taskof assigning target words an overall metaporical fre-quency, either HIGH (?
50%) or LOW (< 50%).
Wecan perform this evaluation using the same data andcross validation technique as before, this time exam-ining each testing fold (which corresponds to a sin-gle target word) and aggregating the metaphor clas-sifications to get a metaphorical frequency estimateof that target.
Table 6 shows how the models faredon this task.
The majority class model misclassifiedall the words, and the TF-IDF model managed to getonly two of the nine correct.
The LDA models per-formed better, with the model including the groupedtopic features achieving 77.8% accuracy.
This sug-gests that our model may already be good enoughto use for analysis of the original Lai experimentaldata.
Of course, this evaluation was carried out onlyover the nine available target words, so additionalevaluation will be necessary to confirm these trends.To further analyze our model performance, welooked at the metaphorical frequency estimates forWord True Predicted Differenceattacked 36% 24% -12%born 10% 2% -8%budding 68% 98% +30%collapsed 80% 98% +18%digest 86% 40% -46%drifted 68% 92% +24%floating 50% 100% +50%sank 38% 26% -12%spoke 6% 62% +56%Table 7: Model performance on the HIGH vs. LOWmetaphor frequency prediction task.each target word.
Table 7 shows the estimates ofour best model along with the true metaphorical fre-quencies.
The three target words with the largest dif-ferences between true and predicted accuracies arespoke, floating and digest, with spoke and floatingpredicted to be much more metaphorical than theyactually are, and digest predicted to be much less.We also performed some analysis of the model er-rors.
In many cases it was difficult to judge why themodel succeeded or failed in identifying a metaphor,but a couple of things stood out.
First, 70% of thedigest instances our model misclassified were Di-gest (capitalized), e.g.
Middle East Economic Di-gest.
Our topic models were trained on all lower-cased words, so Digest and digest were not distin-guished.
Re-training the models without collaps-ing the case distinctions might address this prob-lem.
Second, spoke seems to be an inherently harderterm to classify because it co-occurs with so manyother topics.
About 40% of the spoke instances oc-curred as spoke of or spoke about, where speakingabout a metaphorical topic caused spoke to be inter-preted metaphorically, and speaking about a literaltopic caused spoke to be interpreted literally.
Ad-dressing this problem would probably require someunderstanding of argument structure, perhaps akinto what was done by Gedigian et al (2006).6 Metaphor NoveltyAs a final exploration of topic models for metaphor-ical domains, we considered metaphorical novelty,as used in the original Lai experiment.
In particular,we were interested in how LDA topics might reflect14Type Stimulus SentenceLIT Every soldier in the frontline was attackedCON Every point in my argument was attackedNOV Every second of our time was attackedANOM Every drop of rain was attackedLIT The old building has collapsedCON Their theories have collapsedNOV Their compromises have collapsedANOM The apples have collapsedTable 8: Example stimuli: literal (LIT), conventionalmetaphor (CON), novel metaphor (NOV) and anomalous(ANOM).more conventional or more novel metaphors.
In theLai experiment, conventional and novel metaphorsfor a particular target word shared the same sourcedomain (e.g.
WAR) but differed in the target domain(e.g.
ARGUMENT vs. TIME).
If LDA topics area good operationalization of such domains, then itshould be possible use LDA topics to distinguish be-tween conventional and novel metaphors.To explore this area, we employed the stimulifrom the Lai experiment, and looked in particularat the conventional and novel conditions.
The Laiexperiment used 104 different target words, so thesedata included 104 conventional metaphors and 104novel metaphors.
Novel metaphors were generatedfor the Lai experiment by considering a conventionalsource-target mapping and selecting a new targetdomain.
For example, the conventional metaphorEvery point in my argument was attacked mapsthe source domain WAR to the target domain AR-GUMENT, while the novel metaphor Every secondof our time was attacked maps the source domainWAR to the target domain TIME.
Table 8 shows ex-ample stimulus sentences from the Lai experiment.Though these experimental stimuli have the draw-back of being manually constructed, not collectedfrom a corpus, they have the advantage of beingalready annotated with a definition of novelty thatclearly distinguishes the two types of metaphors.We performed a simple correlational analysis us-ing the conventional and novel metaphors from theLai experiment.
We produced topic distributions foreach stimulus, using our topic models trained on theBNC.
We then labeled conventional metaphors as -1and novel metaphors as +1, and identified the top--0.19 like house old shop door look street room-0.18 darlington programme club said durham hall-0.15 film play theatre women actor work perform-0.14 area local plan develop land house rural urban-0.14 any sale good publish custom product priceTable 9: Top 5 topics correlated with conventionality.0.20 freud sexual sophie male joanna people female0.17 doctor leed rory dalek fergus date subject aug0.13 book write read english novel publish reader0.11 lorton kirov dougal jed manville vologski celia0.09 war british france britain french nation europeTable 10: Top 5 topics correlated with novelty.ics that correlated best with this distinction.
Table 9shows the most negatively correlated (conventional)topics and Table 10 shows the most positively corre-lated (novel) topics.Though even the best correlations are somewhatlow, there seem to be some trends in this analysis.Conventional metaphors seem to correspond moreto concrete terms, like house, club, play and sale.Novel metaphors have less of a coherent theme, in-cluding terms like freud and sexual as well as nameslike Rory, Kirov and Britain.
This may reflect areal distinction in the use of conventional and novelmetaphors, or it may be an artifact of how the exper-imental stimuli were created.
A deeper investigationinto the relations between LDA topics and metaphornovelty will probably require annotating sentencesfrom some naturally occuring data.7 ConclusionsWe presented a novel two-phase approach to the taskof metaphorical frequency estimation.
First, exam-ples of a target word were automatically classifiedas literal or metaphorical, and then these classifi-cations were aggregated to estimate how often thetarget word was used metaphorically.
Our classi-fiers operationalized metaphorical source and targetdomains using topics derived from Latent DirichletAllocation.
Support vector machine classifiers tookthese topic probability distributions and learned toclassify sentences as literal or metaphorical.
Thesemodels achieved 61.3% accuracy on the classifiationtask, and their aggregated classifications producedan accuracy of 77.8% on the task of distinguishing15between target words with high and low metaphori-cal frequencies.Future work will perform a larger scale eval-uation, and will use our model?s metaphoricalfrequency estimates to analyze psycholinguisticdata.
In particular, we will split the conventionalmetaphorical sentences of Lai et al (2007) intolow and high-frequency items.
If the low andhigh frequency items display significantly differ-ent brainwave patterns, then this could suggest thatmetaphorical frequency of a given word plays a crit-ical role in metaphor comprehension.Future work will also explore frequency effectsthat consider the sentential context in the stimulusitems.
For example, a context like ?Their theorieshave ?
probably gives a higher expectation of ametaphorical word filling in the blank than a contextlike ?The old building has ?.
Having a measureof how much the words in the preceding context pre-dict an upcoming metaphor would provide anotheruseful stimulus control.ReferencesAlias-i.
2008.
LingPipe 3.7.0. http://alias-i.com/lingpipe/, October.Yossi Arzouan, Abraham Goldstein, and Miriam Faust.2007.
Brainwaves are stethoscopes: ERP correlatesof novel metaphor comprehension.
Brain Research,1160:69?81, July.Julia Birke and Anoop Sarkar.
2006.
A clustering ap-proach for nearly unsupervised recognition of non-literal language.
In European Chapter of the ACL(EACL).David M. Blei, Andrew Y. Ng, and Michael I. Jordan.2003.
Latent dirichlet alocation.
Journal of MachineLearning Research, 3:993?1022.BNC.
2007.
The british national corpus, version 3(BNC XML edition).
Distributed by Oxford Univer-sity Computing Services on behalf of the BNC Con-sortium.
http://www.natcorp.ox.ac.uk/.Seana Coulson and Cyma Van Petten.
2002.
Conceptualintegration and metaphor: an event-related potentialstudy.
Memory & Cognition, 30(6):958?68, Septem-ber.
PMID: 12450098.Matt Gedigian, John Bryant, Srini Narayanan, and Bran-imir Ciric.
2006.
Catching metaphors.
In WorkshopOn Scalable Natural Language Understanding.Galina Iakimova, Christine Passerieux, Jean-Paul Lau-rent, and Marie-Christine Hardy-Bayle.
2005.ERPs of metaphoric, literal, and incongruous seman-tic processing in schizophrenia.
Psychophysiology,42(4):380?390.Thorsten Joachims, 1998.
Text categorization with Sup-port Vector Machines: Learning with many relevantfeatures, pages 137?142.
Springer Berlin / Heidel-berg.Thorsten Joachims.
2005.
A support vector method formultivariate performance measures.
In Proceedings ofthe 22nd international conference on Machine learn-ing, pages 377?384, Bonn, Germany.
ACM.Saisuresh Krishnakumaran and Xiaojin Zhu.
2007.Hunting elusive metaphors using lexical resources.
InWorkshop on Computational Approaches to FigurativeLanguage.Vicky Tzuyin Lai, Tim Curran, and Lise Menn.2007.
The comprehension of conventional and novelmetaphors: An ERP study.
In 13th Annual Confer-ence on Architectures and Mechanisms for LanguageProcessing, August.George Lakoff.
1994.
Conceptual metaphor WWWserver.
http://cogsci.berkeley.edu/lakoff/.David D. Lewis, Yiming Yang, Tony G. Rose, and FanLi.
2004.
RCV1: a new benchmark collection for textcategorization research.
J. Mach.
Learn.
Res., 5:361?397.James H. Martin.
1994.
MetaBank: a Knowledge-Baseof metaphoric language conventions.
ComputationalIntelligence, 10(2):134?149.James H. Martin.
2006.
A rational analysis of the con-text effect on metaphor processing.
In Stefan Th.
Griesand Anatol Stefanowitsch, editors, Corpus-Based Ap-proaches to Metaphor and Metonymy.
Mouton deGruyter.Howard R. Pollio, Michael K. Smith, and Marilyn R. Pol-lio.
1990.
Figurative language and cognitive psychol-ogy.
Language and Cognitive Processes, 5:141?167.Tony Berber Sardinha.
2008.
Metaphor probabilitiesin corpora.
In Mara Sofia Zanotto, Lynne Cameron,and Marilda do Couto Cavalcanti, editors, ConfrontingMetaphor in Use, pages 127?147.
John Benjamins.Fabrizio Sebastiani.
2002.
Machine learning in auto-mated text categorization.
ACM Computing Surveys(CSUR), 34(1):1?47.Vivien C. Tartter, Hilary Gomes, Boris Dubrovsky, So-phie Molholm, and Rosemarie Vala Stewart.
2002.Novel metaphors appear anomalous at least momen-tarily: Evidence from N400.
Brain and Language,80(3):488?509, March.16
