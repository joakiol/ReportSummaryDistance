Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, pages 189?192,Suntec, Singapore, 4 August 2009. c?2009 ACL and AFNLPLearning Semantic Categories from Clickthrough LogsMamoru KomachiNara Institute of Science and Technology (NAIST)8916-5 Takayama, Ikoma, Nara 630-0192, Japanmamoru-k@is.naist.jpShimpei Makimoto and Kei Uchiumi and Manabu SassanoYahoo Japan CorporationMidtown Tower, 9-7-1 Akasaka, Minato-ku, Tokyo 107-6211, Japan{smakimot,kuchiumi,msassano}@yahoo-corp.jpAbstractAs the web grows larger, knowledge ac-quisition from the web has gained in-creasing attention.
In this paper, we pro-pose using web search clickthrough logsto learn semantic categories.
Experimen-tal results show that the proposed methodgreatly outperforms previous work usingonly web search query logs.1 IntroductionCompared to other text resources, search queriesmore directly reflect search users?
interests (Sil-verstein et al, 1998).
Web search logs are get-ting a lot more attention lately as a source of in-formation for applications such as targeted adver-tisement and query suggestion.However, it may not be appropriate to usequeries themselves because query strings are oftentoo heterogeneous or inspecific to characterize theinterests of the user population.
Although it is notclear that query logs are the best source of learningsemantic categories, all the previous studies usingweb search logs rely on web search query logs.Therefore, we propose to use web searchclickthrough logs to learn semantic categories.Joachims (2002) developed a method that utilizesclickthrough logs for training ranking of searchengines.
A search clickthrough is a link whichsearch users click when they see the result oftheir search.
The intentions of two distinct searchqueries are likely to be similar, if not identical,when they have the same clickthrough.
Searchclickthrough logs are thus potentially useful forlearnin semantic categories.
Clickthrough logshave the additional advantage that they are avail-able in abundance and can be stored at very lowcost.1 Our proposed method employs search click-1As for data availability, MSN Search query logs(RFP 2006 dataset) were provided to WSCD09: Work-through logs to improve semantic category acqui-sition in both precision and recall.We cast semantic category acquisition fromsearch logs as the task of learning labeled in-stances from few labeled seeds.
To our knowledgethis is the first study that exploits search click-through logs for semantic category learning.22 Related WorkThere are many techniques that have been devel-oped to help elicit knowledge from query logs.These algorithms use contextual patterns to extracta category or a relation in order to learn a target in-stance which belongs to the category (e.g.
cat inanimal class) or a pair of words in specific relation(e.g.
headquarter to a company).
In this work,we focus on extracting named entities of the sameclass to learn semantic categories.Pas?ca and Durme (2007) were the first to dis-cover the importance of search query logs in nat-ural language processing applications.
They fo-cused on learning attributes of named entities, andthus their objective is different from ours.
An-other line of new research is to combine various re-sources such as web documents with search querylogs (Pas?ca and Durme, 2008; Talukdar et al,2008).
We differ from this work in that we usesearch clickthrough logs rather than search querylogs.Komachi and Suzuki (2008) proposed a boot-strapping algorithm called Tchai, dedicated to thetask of semantic category acquisition from searchquery logs.
It achieves state-of-the-art perfor-mance for this task, but it only uses web searchquery logs.shop on Web Search Click Data 2009 participants.
http://research.microsoft.com/en-US/um/people/nickcr/WSCD09/2After the submission of this paper, we found that (Xu etal., 2009) also applies search clickthrough logs to this task.This work independently confirms the effectiveness of click-through logs to this task using different sources.189Figure 1: Labels of seeds are propagated to unla-beled nodes.3 Quetchup3 AlgorithmIn this section, we describe an algorithm forlearning semantic categories from search logs us-ing label propagation.
We name the algorithmQuetchup.3.1 Semi-supervised Learning by LaplacianLabel PropagationGraph-based semi-supervised methods such as la-bel propagation are known to achieve high perfor-mance with only a few seeds and have the advan-tage of scalability.Figure 1 illustrates the process of label propa-gation using a seed term ?singapore?
to learn theTravel domain.This is a bipartite graph whose left-hand sidenodes are terms and right-hand side nodes arepatterns.
The strength of lines indicates related-ness between each node.
The darker a node, themore likely it belongs to the Travel domain.
Start-ing from ?singapore,?
the pattern ??
airlines?
4 isstrongly related to ?singapore,?
and thus the labelof ?singapore?
will be propagated to the pattern.On the other hand, the pattern ??
map?
is a neu-tral pattern which co-occurs with terms other thanthe Travel domain such as ?google?
and ?yahoo.
?Since the term ?china?
shares two patterns, ??
air-lines?
and ??
map,?
with ?singapore,?
the label ofthe seed term ?singapore?
propagates to ?china.??China?
will then be classified in the Travel do-main.
In this way, label propagation graduallypropagates the label of seed instances to neigh-bouring nodes, and optimal labels are given as the3Query Term Chunk Processor4?
is the place into which a query fits.Input:Seed instance vector F (0)Instance similarity matrix AOutput:Instance score vector F (t)1: Construct the normalized Laplacian matrix L = I ?D?1/2AD?1/22: Iterate F (t + 1) = ?
(?L)F (t) + (1 ?
?
)F (0) untilconvergenceFigure 2: Laplacian label propagation algorithmlabels at which the label propagation process hasconverged.Figure 2 describes label propagation based onthe regularized Laplacian.
Let a sample xibe xi?X , F (0) be a score vector of x comprised of alabel set yi?
Y , and F (t) be a score vector ofx after step t. Instance-instance similarity matrixA is defined as A = W TW where W is a row-normalized instance-pattern matrix.
The (i, j)-thelement of Wijcontains the normalized frequencyof co-occurrence of instance xiand pattern pj.
Dis a diagonal degree matrix of N where the (i, i)thelement of D is given as Dii=?jNij.This algorithm in Figure 2 is similar to (Zhouet al, 2004) except for the method of construct-ing A and the use of graph Laplacian.
Zhou et alproposed a heuristic to set Aii= 0 to avoid self-reinforcement5 because Gaussian kernel was usedto create A.
The Laplacian label propagation doesnot need such a heuristic because the graph Lapla-cian automatically reduces self-reinforcement byassigning negative weights to self-loops.In the task of learning one category, scores of la-beled (seed) instances are set to 1 whereas scoresof unlabeled instances are set to 0.
The output isa score vector which holds relatedness to seed in-stances in descending order.
In the task of learningtwo categories, scores of seed instances are set toeither 1 or ?1, respectively, and the final label ofinstance xiwill be determined by the sign of out-put score vector yi.Label propagation has a parameter ?
?
(0, 1]that controls how much the labels of seeds are em-phasized.
As ?
approaches 0 it puts more weighton labeled instances, while as ?
increases it em-ploys both labeled and unlabeled data.There exists a closed-form solution for Lapla-cian label propagation:5Avoiding self-reinforcement is important because itcauses semantic drift, a phenomenon where frequent in-stances and patterns unrelated to seed instances infect seman-tic category acquisition as iteration proceeds.190Category SeedTravel jal (Japan Airlines), ana (All NipponAirways), jr (Japan Railways),(jalan: online travel guide site), his(H.I.S.Co.,Ltd.
: travel agency)Finance (Mizuho Bank),(Sumitomo Mitsui Banking Corporation),jcb, (Shinsei Bank),(Nomura Securities)Table 1: Seed terms for each categoryF?=??t=0(?
(?L))tF (0) = (I + ?L)?1F (0)However, the matrix inversion leads to O(n3)complexity, which is far from realistic in a real-world configuration.
Nonetheless, it can be ap-proximated by fixing the number of steps for labelpropagation.4 Experiments with Web Search LogsWe will describe experimental result comparinga previous method Tchai to the proposed methodQuetchup with clickthrough logs (Quetchupclick)and with query logs (Quetchupquery).4.1 Experimental SettingsSearch logs We used Japanese search logs col-lected in August 2008 from Yahoo!
JAPAN WebSearch.
We thresholded both search query andclickthrough logs and retained the top 1 milliondistinct queries.
Search logs are accompanied bytheir frequencies within the logs.Construction of an instance-pattern matrixWe used clicked links as clickthrough patterns.Links clicked less than 200 times were removed.After that, links which had only one co-occurringquery were pruned.
6 On the other hand, we usedtwo term queries as contextual patterns.
For in-stance, if one has the term ?singapore?
and thequery ?singapore airlines,?
the contextual pattern??
airlines?
will be created.
Query patterns appear-ing less than 100 times were discarded.The (i, j)-th element of a row-normalizedinstance-pattern matrix W is given byWij=|xi,pj|?k|xi,pk|.Target categories We used two categories,Travel and Finance, to compare proposed methodswith (Komachi and Suzuki, 2008).6Pruning facilitates the computation time and reduces thesize of instance-pattern matrix drastically.When a query was a variant of a term or con-tains spelling mistakes, we estimated original formand manually assigned a semantic category.
Weallowed a query to have more than two categories.When a query had more than two terms, we as-signed a semantic category to the whole query tak-ing each term into account.7System We used the same seeds presented in Ta-ble 1 for both Tchai and Quetchup.
We used thesame parameter for Tchai described in (Komachiand Suzuki, 2008), and collected 100 instances byiterating 10 times and extracting 10 instances periteration.
The number of iteration of Quetchup isset to 10.
The parameter ?
is set to 0.0001.Evaluation It is difficult in general to define re-call for the task of semantic category acquisitionsince the true set of instances is not known.
Thus,we evaluated all systems using precision at k andrelative recall (Pantel and Ravichandran, 2004).8Relative recall is the coverage of a system givenanother system as baseline.4.2 Experimental Result4.2.1 Effectiveness of Clickthrough LogsFigures 3 to 6 plot precision and relative recallfor three systems to show effectiveness of searchclickthrough logs in improvement of precision andrelative recall.
Relative recall of QuetchupclickandTchai were calculated against Quetchupquery.Quetchupclickgave the best precision amongthree systems, and did not degenerate going downthrough the list.
In addition, it was demonstratedthat Quetchupclickgives high recall.
This resultshows that search clickthrough logs effectively im-prove both precision and recall for the task of se-mantic category acquisition.On the other hand, Quetchupquerydegraded inprecision as its rank increased.
Manual check ofthe extracted queries revealed that the most promi-nent queries were Pornographic queries, followedby Food, Job and Housing, which frequently ap-pear in web search logs.
Other co-occurrence met-rics such as pointwise mutual information wouldbe explored in the future to suppress the effect offrequent queries.In addition, Quetchupclickconstantly out-performed Tchai in both the Travel and Fi-7Since web search query logs contain many spelling mis-takes, we experimented in a realistic configuration.8Typically, precision at k is the most important measuresince the top k highest scored terms are evaluated by hand.19100.20.40.60.8110  20  30  40  50  60  70  80  90  100PrecisionRankQuetchup (click)Quetchup (query)TchaiFigure 3: Precision of Travel domain00.20.40.60.8110  20  30  40  50  60  70  80  90  100PrecisionRankQuetchup (click)Quetchup (query)TchaiFigure 4: Precision of Finance domain024681010  20  30  40  50  60  70  80  90  100RelativerecallRankQuetchup (click)TchaiFigure 5: Relative recall of Travel domain024681010  20  30  40  50  60  70  80  90  100RelativerecallRankQuetchup (click)TchaiFigure 6: Relative recall of Finance domainnance domains in precision and outperfomedQuetchupqueryin relative recall.
The differencesbetween the two domains of query-based systemsseem to lie in the size of correct instances.
The Fi-nance domain is a closed set which has only a feweffective query patterns, whereas Travel domain isan open set which has many query patterns thatmatch correct instances.
Quetchupclickhas an ad-ditional advantage that it is stable across over theranked list, because the variance of the number ofclicked links is small thanks to the nature of theranking algorithm of search engines.5 ConclusionWe have proposed a method called Quetchupto learn semantic categories from search click-through logs using Laplacian label propagation.The proposed method greatly outperforms previ-ous method, taking the advantage of search click-through logs.AcknowledgementsThe first author is partly supported by the grant-in-aid JSPS Fellowship for Young Researchers.
Wethank the anonymous reviewers for helpful com-ments and suggestions.ReferencesT.
Joachims.
2002.
Optimizing Search Engines Using Click-through Data.
KDD, pages 133?142.M.
Komachi and H. Suzuki.
2008.
Minimally SupervisedLearning of Semantic Knowledge from Query Logs.
IJC-NLP, pages 358?365.M.
Pas?ca and B. V. Durme.
2007.
What You Seek is WhatYou Get: Extraction of Class Attributes from Query Logs.IJCAI-07, pages 2832?2837.M.
Pas?ca and B. V. Durme.
2008.
Weakly-Supervised Ac-quisition of Open-Domain Classes and Class Attributesfrom Web Documents and Query Logs.
ACL-2008, pages19?27.P.
Pantel and D. Ravichandran.
2004.
Automatically Label-ing Semantic Classes.
HLT/NAACL-04, pages 321?328.C.
Silverstein, M. Henzinger, H. Marais, and M. Moricz.1998.
Analysis of a Very Large AltaVista Query Log.
Dig-ital SRC Technical Note 1998-014.P.
P. Talukdar, J. Reisinger, M. Pas?ca, D. Ravichandran,R.
Bhagat, and F. Pereira.
2008.
Weakly-Supervised Ac-quisition of Labeled Class Instances using Graph RandomWalks.
EMNLP-2008, pages 581?589.G.
Xu, S. Yang, and H. Li.
2009.
Named Entity Miningfrom Click-Through Log Using Weakly Supervised LatentDirichlet Allocation.
KDD.
to appear.D.
Zhou, O. Bousquet, T. N. Lal, J. Weston, and B. Scho?kopf.2004.
Learning with Local and Global Consistency.NIPS, 16:321?328.192
