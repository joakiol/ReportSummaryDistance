Ambigu i ty  resolution in a reductionistic parser *Atro Voutilainen & Pasi TapanainenResearch Unit for Computational LinguisticsP.O.
Box 4 (Keskuskatu 8)FIN-00014 University of HelsinkiFinlandAbstractWe are concerned with dependency-oriented morphosyntactic parsing of run-ning text.
While a parsing grammar shouldavoid introducing structurally unresolvabledistinctions in order to optimise on the ac-curacy of the parser, it also is beneficialfor the grammarian to have as expressive astructural representation available as possi-ble.
In a reductionistic parsing system thispolicy may result in considerable ambigu-ity in the input; however, even massive am-biguity can be tackled efficiently with anaccurate parsing description and effectiveparsing technology.1 IntroductionIn this paper we are concerned with grammar-basedsurface-syntactic analysis of running text.
Morpho-logical and syntactic analysis is here based on theuse of tags  that express surface-syntactic relationsbetween functional categories such as Subject, Mod-ifier, Main verb etc.
; consider the following simpleexample:I PRON ~SUBJECTsee  V PRES @MAINVERBa ART QDET>Nbird N ~OBJECTFULLSTOP*The development of ENGCG was supported byTEKES, the Finnish Technological Development Center,and a part of the work on Finite-state syntax has beensupported by the Academy of Finland.In this type of analysis, each word gets a mor-phosyntactic analysis I.The present work is closely connected with twoparsing formalisms, Constraint Grammar  \[Karls-son, 1990; Karlsson et aI., 1991; Voutilainen et aI.,1992; Karlsson et aI., 1993\] and Finlte-state syn-tax as advocated by \[Koskenniemi, 1990; Tapanai-nen, 1991; Koskenniemi et al, 1992\].
The Con-straint Grammar parser of English is a sequentialmodular system that assigns a shallow surface-truedependency-oriented functional analysis on runningtext, annotating each word with morphological andsyntactic tags.
The finite-state parser assigns a sim-ilar type of analysis, but it operates on all levels ofambiguity 2 in parallel rather than sequentially, en-abling the grammarian to refer to all levels of struc-tural description in a single uniform rule component.ENGCG,  a wide-coverage English ConstraintGrammar and lexicon, was written 1989-1992, andthe system is currently available 3.
The ConstraintGrammar framework was proposed by Fred Karls-son, and the English Constraint Grammar  was de-veloped by Afro Voutilainen (lexicon, morphologicaldisambiguation), Juha Heikkil~i (lexicon) and ArtoAnttila (syntax).
There are a few implementationslit consists of a base form, a morphological reading- part-of-speech, inflectional and other morphosyntacticfeatures - and a syntactic-functional t g, flanked by '@'.~Morphological, clause boundary, and syntacticambiguities3The ENGCG parser can currently be testedautomatically via E-mail by sending texts of upto 300 words to engcg@ling.Helsinki.FI.
The re-ply will contain the analysis as well as informa-tion on usage and availability.
Questions can alsobe directly sent to avoutila@ling.Helsinki.FI or topt apanai@ling.Helsinki.FI.394of the parser, and the latest, written in C by PasiTapanainen, analyses more than 1000 words per sec-ond on a Sun SparcStationl0, using a disambiguationgrammar of some 1300 constraints.Intensive work within the finite-state frameworkwas started by Tapanainen \[1991\] in 1990, and an op-erational parser was in existence the year after.
Thefirst nontrivial finite-state descriptions \[Koskenniemietal., 1992\] were written by Voutilainen 1991-1992,and currently he is working on a comprehensive En-glish grammar which is expected to reach a consider-able degree of maturity by the end of 1994.
Much ofthis emerging work is based on the ENGCG descrip-tion, (e.g.
the ENGTWOL lexicon is used as such);however, the design of the grammar has changed con-siderably, as will be seen below.We have two main theses.
Firstly, knowledge-based reductionistic grammatical nalysis will be fa-cilitated rather than hindered by the introductionof (new) linguistically motivated and structurallyresolvable distinctions into the parsing scheme, al-though this policy will increase the amount of am-biguity in the parser's input.
Secondly, the amountof ambiguity in the input does not predict he speedof analysis, so introduction of new ambiguities in theinput is not necessarily something to be avoided.Next, we present some observations about theENGCG parser: the linguistic description would be-come more economic and accurate if all levels ofstructural description were available at the outset ofreductionistic parsing (or disambiguation f alterna-tive readings).
In Section 3 we report on some earlyexperiments with finite-state parsing.
In Section 4we sketch a more satisfactory functional dependency-oriented escription.
A more expressive representa-tion implies more ambiguity in the input; in Section 5it is shown, however, that even massive ambiguityneed be no major problem for the parser.2 Constraint Grammar of EnglishA large-scale description has been written within theConstraint Grammar (CG) framework.
CG parsingconsists of the following sequential modules:?
Preprocessing and morphological nalysis?
Disambiguation of morphological (e.g.
part-of-speech) ambiguities?
Mapping of syntactic functions onto morpholog-ical categories?
Disambiguation f syntactic functionsHere we shall be concerned only with disambigua-tion of morphological mbiguities - this module,along with the TWOL-style morphological descrip-tion ENGTWOL, is the most mature part of theENGCG system.The morphological description is based on \[Quirket al, 1985\].
For each word, a base form, a part ofspeech as well as inflectional and also derivationaltags are provided, e.g.
("<*i>"("i" <*> ABBR NOM SG)("i" <*> <NonMod> PRON PERS NOM SGI))("<see>"("see" <SVO> V SUBJUNCTIVE VFIN)("see" <SVO> V IMP VFIN)("see" <SVO> Y INF)("see" <SVO> V PRES -SG3 VFIN))(,,<~>,,("a" <Indef> DET CENTRAL ART SG))("<bird>"("bird" <SV> V SUBJUNCTIVE VFIN)("bird" <SV> V IMP VFIN)("bird" <SV> V INF)("bird" <SV> V PRES -SG3 VFIN)("bird" S NOM SG))(,,<$.>,')Ambiguities due to part of speech and minor cat-egories are common in English - on an average, theENGTWOL analyser furnishes each word with tworeadings.
The task of the morphological disambiguevtor is certainly a nontrivial one.The disambiguator uses a hand-written constraintgrammar.
Here, we will not go into the technicalitiesof the CG rule formalism; suffice it to say that eachconstraint - presently some 1,300 in all - expresses apartial paraphrase ofsome thirty more general gram-mar statements, typically in the form of negative re-strictions.
- For instance, a constraint might rejectverb readings in an ambiguous morphological nal-ysis as contextually illegitimate if the immediatelypreceding word is an unambiguous determiner.
Thiscan be regarded as a roundabout partial statementabout the form of a noun phrase: a determiner is fol-lowed by a premodifier or a noun phrase head, so allmorphological readings that cannot act as nominalheads or premodifiers are to be discarded.Here is the disambiguated representation f thesentence:("<*i>"("i" <*> <NonMod> PRON PERS NOM SGI))("<see>"("see" <SVO> V PRES -SG3 VFIN))("<a>"("a" <Indef> DET CENTRAL ART SG))( *'<bird>"("bird" N NOM SG))(,,<$.>,,)Overall, the morphological disambiguator has avery attractive performance.
While the best knowncompetitors - typically based on statistical methods(see e.g.
\[Garside tal., 1987; Church, 1988\]) - makea misprediction about part of speech in up to 5% ofall words, the ENGCG disambiguator makes a falseprediction only in up to 0.3% of all cases \[Vouti-lainen, 1993\].
So far, ENGCG has been used in a395large-scale information management system (an ES-PRIT II project called SIMPR: Structured Informa.lion Management: Processing and Relrieval).
Cur-rently ENGCG is also used for tagging the Bank ofEnglish, a 200-million word corpus established bythe COBUILD team in Birmingham, England; thetagged corpus will become accessible to the researchcommunity.What makes ENGCG interesting for the presentdiscussion is the fact that the constraints are es-sentially partial expressions of the distribution offunctional-syntactic categories.
In other words, thegeneralisations underlying the disambiguation con-straints pertain to a higher level of description thanis explicitly coded in the input representation.The high number and also the complexity of mostof the constraints mainly results from the fact thatdirect reference to functional categories i not pos-sible in the constraint grammar because syntacticfunctions are systematically introduced only aftermorphological disambiguation has become disacti-vated.
Also explicit information about sentence-internal clause boundaries i missing, so a constraint,usually about clause-internal relations, has to ascer-tain that the words and features referred to are inthe same clause - again in a roundabout and usuallypartial fashion.Indeed, it is argued in \[Voutilainen, 1993\] that ifdirect reference to all appropriate categories werepossible, most or all of part-of-speech disambiguationwould be a mere side-effect of genuine functional-syntactic analysis.
In other words, it seems that theavailability of a more expressive grammatical repre-sentation would make part-of-speech analysis easier,even though the amount of ambiguity would increaseat the outset.The ENGCG disambiguator avoids risky predic-tions; some 3-6~ of all words remain partly am-biguous after part-of-speech disambiguation.
Alsomost of these remaining ambiguities appear struc-turally resolvable.
The reason why these ambiguitiesare not resolved by the ENGCG disambiguator isthat the expression of the pertinent grammar rulesas constraints, without direct reference to syntactic-function labels and clause boundaries, becomes pro-hibitively difficult.
Our hypothesis that also mostof the remaining part-of-speech ambiguities could beresolved if also clause boundary and syntactic de-scriptors were present in the input, even though thiswould imply more ambiguity at the outset of parsing.3 F i r s t  exper iences  w i th  F in i te -S ta tesyntaxFinite-state syntax, as originally proposed by Kos-kenniemi, s an emerging framework that has beenused in lexicon-based reductionistic parsing.
Somenontrivial English grammars of some 150-200 ruleshave been written recently.
The main improvementsare the following.?
All three types of structural ambiguity- mor-phological, clause boundary, and syntactic - are pre-sented in parallel.
No separate, potentially sequen-tially applied subgrammars formorphological disam-biguation, clause boundary determination, or syntaxproper, are needed - one uniform rule componentwill suffice for expressing the various aspects of thegrammar.
In this setting, therefore, a genuine testof the justification of three separate types of gram-mar is feasible: for instance, it is possible to test,whether morphological disambiguation is reducibleto essentially syntactic-functional grammar.?
The internal representation f the sentence ismore distinctive.
The FS parser represents eachsentence reading separately, whereas the CG parseronly distinguishes between alternative word read-ings.
Therefore the FS rules need not concern them-selves with more than one unambiguous, though po-tentially unacceptable, sentence reading at a time,and this improves parsing accuracy.?
The rule formalism is more expressive and flexi-ble than in CG; for instance, the full power of regularexpressions i  available.
The most useful kind of ruleappears to be the impl icat ion rule; consider thefollowing (somewhat simplified) rule about the dis-tribution of the subject in a finite clause:Subject =>_ .. F inVerbCha in ,F inAux  .
.
.
.
.
NonF inMainVerb  .
.
.
qUEST ION;It reads: 'A finite clause subject (a constant de-fined as a regular expression elsewhere in the gram-mar) occurs before a finite verb chain in the sameclause ('..'), or it occurs between a finite auxiliaryand a nonfinite main verb in the same clause, andthe sentence nds in a question mark.'
- If a sen-tence  reading contains a sequence of tags that is ac-cepted by the regular expression Subject and that isnot legitimated by the contexts, the sentence read-ing is discarded; otherwise it survives the evaluation,perhaps to be discarded by some other grammar rule.hnplication rules express distributions in astraightforward, positive fashion, and usually theyare very compact: several dozens of CG rules thatexpress bits and pieces of the same grammatical phe-nomenon can usually be expressed with one or twotransparent finite-state rules.?
The CG syntax was somewhat shallow.
Thedifference between finite and non-finite clauses wasmostly left implicit, and the functional descriptionwas not extended to clausal constructions, which alsocan serve e.g.
as subjects and objects.
In contrast,even the earlier FS grammars did distinguish be-tween finite and non-finite constructions, althoughthe functional description of these categories was stilllacking in several respects.
Still, even this modestenrichment of the grammatical representation madeit easier to state distributional generalisations, al-396though much still remained hard to express, e.g.
co-ordination of formally different but functionally sim-ilar categories.3.1 A pilot exper imentTo test whether the addition of clause boundaryand functional-syntactic information made morpho-logical disambiguation easier, a finite-state grammarconsisting of some 200 syntactic rules \[Koskenniemiet al, 1992\] was written, and a test text 4 was se-lected.
The objective was to see, whether thosemorphological mbiguities that are too hard for theENGCG disambiguator to resolve can be resolvedif a more expressive grammatical description (and amore powerful parsing formalism) is used.Writing a text-generic omprehensive parsinggrammar of a maturity comparable to the ENGCGdescription would have taken too much time to bepractical for this pilot test.
While most of the gram-mar rules were about relatively frequently occur-ring constructions, e.g.
about the structure of thefinite verb chain or of prepositional phrases, someof the rules were obviously 'inspired' by the testtext: the test grammar is more comprehensive onthe structural phenomena of the test text than ontexts in general.
However, all proposed rules werecarefully tested against various corpora, e.g.
a man-ually tagged collection of some 2,000 sentences takenfrom \[Quirk et al, 1985\], as well as large untaggedcorpora, in order to ascertain the generality of theproposed rules.Thus the resulting rammar was 'optimised' in thesense that all syntactic structures of the text weredescribed in the grammar, but not in the sense thatthe rules would have been true of the test text only.The test data was first analysed with the ENGCGdisambiguator.
Out of the 1,400 words, 43 remainedambiguous due to morphological category, and nomisanalyses were made.
Then the analysed atawas enriched with the more' expressive finite-statesyntactic description, i.e.
with new ambiguities, andthis data was then analysed with the finite-stateparser.
After finite-state parsing, only 3 words re-mained morphologically ambiguous, with no mis-analyses.
Thus the introduction of more descriptiveelements into the sentence representations made itpossible to safely resolve almost all of the remaining43 morphological mbiguities.This experiment suggests the usefulness of hav-ing available as much structural information as pos-sible, although undoubtedly some of the additionalprecision resulted from a more optimal internal rep-resentation of the input sentence and from a moreexpressive rule formalism.
Overall, these resultsseem to contradict certain doubts voiced \[Sampson,1987; Church, 1992\] about the usefulness of syntac-tic knowledge in e.g.
part-of-speech disambiguation.4An article from The New Grolier Electronic Encyclo-pedia, consisting of some 1,400 wordsPart-of-speech disambiguation is essentially syntac-tic in nature; at least current methods based on lexi-cal probabilities provide a less reliable approximationof correct part-of-speech tagging.4 A new tagg ing  schemeThe above observations suggest that grammar-basedanalysis of running text is a viable enterprise - notonly academically, but even for practical applica-tions.
A description that on the one hand avoidsintroducing systematic structurally unresolvable am-biguities, and, on the other, provides an expressivestructural description, will, together with a care-ful and detailed lexicography and grammar-writing,make for a robust and very accurate parsing system.The main remaining problem is the shortcomingsin the expressiveness of the grammatical representa-tion.
The descriptions were somewhat too shallowfor conveniently making functional generalisationsat higher levels of abstraction; this holds especiallyfor the functional description of non-finite and finiteclauses.This became clear also in connection with the ex-periment reported in the previous ection: althoughthe number of remaining morphological mbiguitieswas only three, the number of remaining syntacticambiguities was considerably higher: of the 64 sen-tences, 48 (75%) received a single syntactic analy-sis, 13 sentences (20%) received two analyses, onesentence received three analyses, and two sentencesreceived four analyses.Here, we sketch a more satisfying notation thathas already been manually applied on some 20,000words of running text from various genres as wellas on some 2,000 test sentences from a large gram-mar \[Quirk et al, 1985\].
Together, these test cor-pora serve as a first approximation f the inventoryof syntactic structures in written English, and theycan be conveniently used in the validation of the newgrammar under development.4.1 Tags in outl ineThe following is a schematic representation f thesyntactic tags:SUBJ SubjectF-SUBJ Formal subject0BJ ObjectF-0BJ Formal objectI-OBJ Indirect objectSC Subject complementOC Object complementP<< Preposition complement>>P Complement of deferredprepositionAPP Apposition@>AQA<AD-A, head fol lowsAD-A, head precedes397@>N@>PN<ADVLADVL/M<Determiner or premodifierModifier of a PPPostdetermineror postmodifierAdverbialAdverbial or postmodifier@CC Coord inator@CS Subord inatorAUX AuxiliaryMV Main verbMAINCmaincMain clauseNon-finite verbal fragmentn-head Nominal f ragmenta-head Adverb ia l  f ragmentThis list represents the tags in a somewhat ab-stract fashion.
Our description also employs a fewnotational conventions.Firstly, the notation makes an explicit differencebetween two kinds of clause: the finite and the non-finite.A finite clause typically contains (i) a verb chain,one or more in length, one of which is a finite verb,and (ii) a varying number of nominal and adver-bial constructs.
Verbs and nominal heads in a fi-nite clause are indicated with a tag written in theupper case, e.g.
Sam/@SUBJ was/@MV a/@>Nman/@SC.A verb chain in a non-finite clause, on the otherhand, contains only non-finite verbs.
Verbs and nom-inal heads in a non-finite clause are indicated with atag written in the lower case, e.g.
To/@auz be/@mvor/@CC not/@ADVL fo/@aux be/@mv.While a distinction is made between the upper andthe lower case in the description of verbs and nominalheads, no such distinction is made in the descriptionof other categories, which are all furnished with tagsin the upper case, of.
or/@CC not/@ADVL.Secondly, the notation accounts both for the inter-nal structure of clausal units and for their function intheir matrix clause.
Usually, all tags start with the'@' sign, but those tags that indicate the function ofa clausal unit rather than its internal structure ndwith the '~ '  sign.
The function tag of a clause is at-tached to the main verb of the clause, so main verbsalways get two tags instead of the ordinary one tag.An example is in order:How @ADVLto  @auxwr i te  @mv mainc@books @objHere write is a main verb in a non-finite clause(@mr), and the non-finite clause itself acts as an in-dependent non-finite clause (mainc@).4.2 Sample  analysesNext, we examine the tagging scheme with some con-crete examples.
Note, however, that most morpho-logical tags are left out in these examples; only apart-of-speech tag is given.
Consider the followinganalysis:@0smoking PCP1 @mv SUBJ@ Qc igaret tes  N Qobj @inspires V @MV MAINC@ @the DET @>N @fat A @>N @butcher ' s  N @>N @wife N @OBJ @and CC @CC @daughters  N @OBJ @FULLSTOP @@The boundary markers '@@', '~' ,  '@/', '@<' and'@>' indicate a sentence boundary, a plain wordboundary, an iterative clause boundary, the begin-ning, and the end, of a centre embedding, respec-tively.As in ENGCG, also here all words get a functiontag.
Smoking is a main verb in a non-finite con-struction (hence the lower case tag @my); cigaretteis an object in a non-finite construction; inspires i amain verb in a finite construction (hence the uppercase tag @MV), and so on.Main verbs also get a second tag that indicates thefunction of the verbal construction.
The non-finiteverbal construction Smoking cigarettes is a subjectin a finite clause, hence the tag SUB J@ for Smok-ing.
The finite clause is a main clause, hence the tagMAINC@ for inspires, the main verb of the finiteclause.The syntactic tags avoid telling what can be eas-ily inferred from the context.
For instance, the tag@>N indicates that the word is a determiner or apremodifier of a nominal.
A more detailed classifica-tion can be achieved by consulting the morphologicalcodes in the same morphological reading, so from thecombination DET @>N we may deduce that the isa determiner of a nominal in the right-hand context;from the combination A @>N we may deduce thatfat is an adjectival premodifier of a nominal, and soforth.The notation avoids introducing structurally un-resolvable distinctions.
Consider the analysis of fat.The syntactic tag @>N indicates that the word is apremodifier of a nominal, and the head is to the right- either it is the nominal head of the noun phrase,or otherwise it is another nominal premodifier in be-tween.
In other words, the tag @>N accounts forboth of the following bracketings:\[\[fat butcher's\] wife\]\[ \[fat \[butcher' s wife\]Note also that coordination often introduces un-resolvable ambiguities.
On structural criteria, it is398impossible to determine, for instance, whether fatmodifies the coordinated aughters as well in the fatbutcher's wife and daughters.
Our notation keepsalso this kind of ambiguity covert, which helps tokeep the amount of ambiguity within reasonable lim-its.In our description, the syntactic function is car-ried by the coordinates rather than by the coordi-nator - hence the object function tags on both wifeand daughters rather than on and.
An alternativeconvention would be the functional abelling of theconjunction.
The difference appears to be merelynotational.A distinction is made between finite and non-finiteconstructions.
As shown above, non-finiteness i  ex-pressed with lower case tags, and finite (and other)constructions are expressed with upper case tags.This kind of splitup makes the grammarian's taskeasier.
For instance, the grammarian might wishto state that a finite clause contains maximally onepotentially coordinated subject.
Now if potentialsubjects in non-finite clauses could not be treatedseparately, it would be more difficult to express thegrammar statement as a rule because xtra checks forthe existence of subjects of non-finite constructionswould have to be incorp6rated in the rule as well, ata considerable cost to transparency and perhaps alsoto generality.
Witness the following sample analysis:@@Henry g @SUBJ @dislikes V @MV MAINC@ @her PRON @subj @leaving PCPl @my OBJ@ @so ADV @>A @early ADV @ADVL @FULLSTOP @@Apparently, there are two simplex subjects in thesame clause; what makes them acceptable is thatthey have different verbal regents: Henry is a subjectin a finite clause, with dislikes as the main verb, whileher occurs in a non-finite clausal construction, withleaving as the main verb.With regard to the description of so early in theabove sentence, the present description makes nocommitments a to whether the adverbial attaches todislikes or leaving - in the notational system, thereis no separate tag for adverbials in non-finite con-structions.
The resolution of adverbial attachmentoften is structurally unresolvable, so our descriptionof these distinctions is rather shallow.Also finite clauses can have a nominal functions.Consider the following sample.
@@What PROM @SUBJ @makes V @MV SUBJ@ @them PRON @OBJ @acceptab le  A ~OC @/is V @MV MAINC@ @/that CS @CS @they  PRON @SUBJ @have V @MV SC@ @different A @>N Qverbal A ~>N @regents N @OBJ @FULLSTOP @@Here What makes them acceptable acts as a subjectin a finite clause, and that they have different verbalregents acts as a subject complement.
- Clauses in adependent role are always subordinate clauses thattypically have a more fixed word order than mainclauses.
Thus clause-function tags like SC@ can alsobe used in fixing clause-internal structure.Another advantage of the introduction of clause-function tags is that restricting the distribution ofclauses becomes more straightforward.
If, for in-stance, a clause is described as a postmodifyingclause, then it has to follow something to postmodify;if a clause is described as a subject, then it shouldalso have a predicate, and so on.
More generally:previous grammars contained some rules explicitlyabout clause boundary markers, for instance:e /  =>VFIN .
.
.
.
.
VFIN;In contrast, the grammar currently under develop-ment contains no rules of this type.
Clause boundarydetermination is likely to be reducible to functionalsyntax, much as is the case with morphological dis-ambiguation.
This new uniformity in the grammaris a consequence of the enrichment of the descriptionwith the functional account of clauses.Also less frequent of 'basic' word orders can be con-veniently accounted for with the present descriptiveapparatus.
For instance, in the following sentencethere is a 'deferred' preposition; here the comple-ment is to the left of the preposition.
@@What PRON @>>P @are V QAUX Qyou PRON @SUBJ @ta lk ing  PCP1 QHV MAINC@ @about  <Deferred> PREP @ADVL @?
QUESTION @@Here @>>P for What indicates that a deferredpreposition is to be found in the right-hand context,and the morphological feature <Deferred> indicatesthat about has no complement in the right-hand con-text: either the complement is to the left, as above,or it is missing altogether, as inTh is  PRON @SUBJ @i s  V QMV MAINC@ @the  DET Q>N @house  N @SO Q/she PRON QSUBJ @was V QAUX @399looking PCPI QMV N<@ Q usingfor <Deferred> PREP @ADVL @ theFULLSTOP @@ supportEllipsis and coordination often co-occur.
For in- stopstance, if finite clauses are coordinated, the verb is but tonoften left out from the non-first coordinates: anddriverPushkin N @SUBJ @gas V @MY NAINC~Russia's N @>N @greatest A @>N @poet  N ~SC Q/COMNA @and CC QCC @To ls toy  N QSUBJ Qher  PRON @>N @greatest A ~>N @novelist N @SC @FULLSTOP 0~Here, and Tolstoy her greatest novelist is granteda clause status, as indicated by the presence of theiterative clause boundary marker '@/'.Note that clausal constructions without a mainverb do not get a function tag because at presentthe clause function tag is attached to the main verb.If the ellipsis co-occurs with coordination, then thepresence of the coordinator in the beginning of theelliptical construction (i.e.
to the right of the itera-tive clause boundary marker '@/') may be a sufficientclue to the function tag: it is to the left, in the firstcoordinate.Verbless constructions also occur in simplex con-structions.
Consider the following real-text example:Q@Prov id ing PCP1 ?mv ADVL@ ~<the  DET @>N @p in  N ?SUBJ @has V @AUX @been V @AUXfully ADV ~ADVL @inserted V @MV obj~into PREP @ADVL Qthe DET ~>N @connect  PCPl @>Nrod N @P<< @>COMMA @ Jfinal A @>N @centralization N ~SUBJ @can V @AUX @COMMAif CS @CS @necessary  A @scCOMMA @be V @AUXdone PCP2 ~MV MAINC@ @on PREP @ADVL @a DET @>N @press N CP<< @PCP1 ~mv ADVL@ @DET @>N @N @>N QN @>N @N ?obj @CC ~CC QN QobjFULLSTOP ~QIn the analysis of if necessary, there is a subjectcomplement tag for necessary.
Subject complementstypically occur in clauses; clauses in general are as-signed a syntactic function in our description; here,however, no such analysis is given due to the lack ofa main verb.
Nevertheless, in this type of verblessconstruction there is a lexical marker in the begin-ning: a subordinating conjunction or a WH word,and from this we can imply that the verbless con-struction functions as an adverbial.An alternative strategy for dealing with the func-tional analysis of verbless constructions would bethe assignment of clause-function tags also to nom-inal and adverbial heads.
This would increase theamount of ambiguity at the outset, but on the otherhand this new ambiguity would be easily control-lable: a clausal construction serves only one func-tion at a time in our description, and this restrictioncan be easily formalised in the finite-state grammarformalism.Next, let us consider the description of preposi-tional phrases.
In general, the present grammar triesto distinguish here between the adverbial function(@ADVL) and the postmodifier function (@N<).
Inthe following somewhat contrived sentence, the dis-tinction is straightforward to make in some cases.Somebody PRON @SUBJwith PREP ~N<a DET @>Nte lescope  N %P<<saw V @MV MAINC@with PREP @ADVLdifficulty N @P<<the DET @>Nman N ?0BJof PREP @N<honor N ~P<<with PREP @ADVL/N<the DET Q>Nbinoculars N ~P<<FULLSTOP0@@@@q}Q@@@@@@Q~The phrase with difficulty is an unambiguous ad-verbial because it is directly preceded by a verb,which do not take postmodifiers.
Likewise, with atelescope and of honor are unambiguously postmod-ifiers: the former because postnominal prepositionalphrases without a verb in the left-hand context arepostmodifiers; the latter because a postnominal of_phrase is always a postmodifier unless the left-hand400context contains a member of a limited class of verbslike 'consist' and 'accuse' which take an of-phrase asa complement.On the contrary, with the binoculars i a problemcase: generally postnominal prepositional phraseswith a verb in the left-hand context are ambigu-ous due to the postmodifier and adverbial functions.Furthermore, several such ambiguous prepositionalphrases can occur in a clause at once, so in combi-nation they can produce quite many grammaticallyacceptable analyses for a sentence.
To avoid this un-comfortable situation, an underspecific tag has beenintroduced: a prepositional phrase is described un-ambiguously as @ADVL/N< if it occurs in a con-text legitimate for adverbials and postmodifiers -i.e., all other functions of prepositional phrases aredisallowed in this context (with the exception of of-phrases).
In all other contexts @ADVL/N< is disal-lowed.This solution may appear clumsy, e.g.
a new tag isintroduced for the purpose, but its advantage is thatdescription can take full benefit of the unambiguous'easy' cases without paying the penalty of unmanage-able ambiguity as a price for the extra information.- Overall, this kind of practise may be useful in thetreatment of certain other ambiguities as well.In this section we have examined the new tagscheme and how it responds to our two main require-ments: the requirement of structural resolvability(cf.
our treatment of premodifiers and prepositionalphrases) and expressiveness of surface-syntactic re-lations (witness e.g.
the manner in which the appli-cation of the Uniqueness principle as well as the de-scription of clause distributions was made easier byextending the description).It goes without saying that even the present an-notation will leave some ambiguities structurally un-resolvable.
For instance, coordination is still likelyto pose problems, cf.
the following ambiguity due tothe preposition complement and object analyses:They PROM @SUBJ @es tab l i shed  V @MV MAINC@neteorks  N QOBJ 0of PREP @N< @sta~e N @P<< @and CC @CC @l oca l  A ~>N Qsoc ie t ies  N C@OBJ --or-- QP<<\] @FULLSTOP @@Although the present system contains a powerfulmechanism for expressing heuristic rules that can beused for ranking alternative analyses, the satisfactorytreatment of ambiguities like this one seems to re-quire some further adjustment of the tag scheme, e.g.further underspecification - something like our de-scription of attachment ambiguities of prepositionalphrases.5 Ambigu i ty  reso lu t ion  w i th  af in i te -s ta te  parserIn a parsing system where all potential analyses areprovided in the input to the parser, there is boundto be a considerable amount of ambiguity as the de-scription becomes more distinctive.
Consider the fol-lowing sentence, 39 words in length:A pressure lubrication systemis employed, the pump, drivenfrom the distributor shaftextension, drawing oil from thesump through a strainer anddistributing it through thecartridge oil filter to a maingallery in the cylinder blockcasting.If only part-of-speech ambiguities are presented,there are 10 million sentence readings.
If each bound-ary between each word or punctuation mark is madefour-ways ambiguous due to the word and clauseboundary readings, the overall number of sentencereadings gets as high as 1032 readings.
If all syn-tactic ambiguities are added, the sentence represen-tation contains 10 ee sentence readings.
Regarded inisolation, each word in the sentence is 1-70 ways am-biguous.If we try to enumerate all 10 ee readings and dis-card them one by one, the work is far too huge to bedone.
But we do not have to do it that way.
Nextwe show that in fact the number of readings doesnot alone predict parsing complexity.
We show thatif we adopt a powerful rule formalism and an accu-rate grammar, which is also effectively applied, a lotof ambiguity can be resolved in a very short time.We have seen above that very accurate analysisof running text can be achieved with a knowledge-based approach.
Characteristic of such a systemis the possibility to refer to grammatical categoriesat various levels of description within an arbitrar-ily long sentence context.
- Regarding the viabilityof essentially statistical systems, the current experi-ence is that employing a window of more than twoor three words requires excessively hard computing.Another problem is that even acquiring collocationmatrices based on e.g.
four-grams or five-grams re-quires tagged corpora much larger than the currentmanually validated tagged ones are.
Also, mispredic-tions, which are a very common problem for statis-tical analysers, tend to bring in the accumulation ef-fect: more mispredictions are likely to occur at laterstages of analysis.
Therefore we do not have any rea-son to use unsure probabilistic information as long aswe can use our more reliable linguistic knowledge.Our rules can be considered as constraints thatdiscard some illegitimate readings.
When we apply401rules one by one, the number of these readings de-creases, and, if possible, in the end we have only onereading left.
In addition to the ordinary 'absolute'rules, the grammar can also contain separate 'heuris-tic' rules, which can be used for ranking remainingmultiple readings.We represent sentences as finite state automata.This makes it possible to store all relevant sentencereadings in a compact way.
We also compile eachgrammar ule into a finite state automaton.
Eachrule automaton can be regarded as a constraint thataccepts ome readings and rejects some.For example, consider the subject rule presentedin Section 3.
We can apply a rule like that on thesentence and, as a result, get an automaton thataccepts all the sentence readings that are correctaccording to the rule.
After this, our 1065-waysambiguous entence has, say, only some 1045 read-ings left.
This means that in some fractions of asecond/" the number of readings is reduced into a1/10000000000000000000O0th part.
All of these re-maining readings are accepted by the applied rule.Next, we can apply another ule, and so on.
The fol-lowing rules will not probably reduce as many am-biguities as the first one, but they will reduce theambiguity to some 'acceptable' level quite fast.
Thismeans that we cannot consider some sentences as un-parsable just because they may initially contain a lotof ambiguity (say, 101??
sentence readings).The real method we use is not as trivial as this,actually.
The method presented above can rather beregarded as a declarative approach to applying therules than as a description of a practical parser.
Arecent version of the parser combines everal meth-ods.
First, it decreases the amount of ambiguitywith some groups of carefully selected rules, as wedescribed above.
Then all other rules are applied to-gether.
This method seems \[Tapanainen, 1992\] toprovide a faster parser than more straightforwardmethods.Let us consider the different methods.
In the firstone we intersect a rule automaton with a sentenceautomaton and then we take another ule automa-ton that we intersect with the previous intermediateresult, and so, on until all (relevant) rules have beenapplied.
This method takes much time as we can seein the following table.
The second method is like thefirst one but the rule automata have been ordered be-fore processing: the most efficient rules are appliedfirst.
This ordering seems to make parsing faster.
Inthe third method we process all rules together andthe fourth method is the one that is suggested above.The last method is like the fourth one but also extrainformation is used to direct the parsing.
It seemsto be quite sufficient for parsing.Before parsing commences, we can also use twomethods for reducing the number of rule automata.Firstly, because the rules are represented as au-tomata, a set of them can be easily combined usingintersection of automata during the rule compilationphase.
Secondly, typically not all rules are neededin parsing because the rule may be about some cat-egory that is not even present in the sentence.
Wehave a quick method for selecting rules in run-time.These optimization techniques improve parsing timesconsiderably.Figure 1: Execution times of parsing methods (sec.
).Imethod I 1 12  \ ]3  14 I 5 Iopt imized  7000 840 350 110 30The test data is the same that was described abovein Section 3.1.
They were parsed on a Sun SparcSta-tion 2.The whole parsing scheme can be roughly pre-sented as?
Preprocessing (text normalising and sentenceboundary detection).?
Morphological analysis and enrichment withsyntactic and clause boundary ambiguities.?
Transform each sentence into a finite state au-tomaton.?
Select the relevant rules for the sentence.?
Intersect a couple of rule groups with the sen-tence automaton.
* Apply all remaining rules in parallel.?
Rank the resulting multiple analyses accordingto heuristic rules and select the best one if atotally unambiguous result is wanted.6 ConclusionIt seems to us that it is the nature of the grammarrules, rather than the amount of the ambiguity it-self, that determines the hardness of ambiguity res-olution.
It is quite easy to write a grammar thatis extremely hard to apply even for simple sentencewith a small amount of ambiguity.
Therefore parsingproblems that come up from using more or less in-complete grammars do not necessarily tell us aboutparsing text with a comprehensive grammar.
Pars-ing problems due to ambiguity seem to dissolve if wehave access to a more expressive grammatical rep-resentation; witness our experiences with morpho-logical disambiguation using the two approaches dis-cussed above.We do not need to hesitate to use features thatwe consider useful in our grammatical description.The amount of ambiguity itself is not what enablesor disables parsing.
More important is that we havean effective grammar and parser that interact witheach other in a sensible way, i.e.
we should not tryto kill mosquitos with artillery or to move mountains402with a spoon.
The ambiguity that is introduced hasLo be relevant for the grammar, not unmotivaLed orstructurally unresolvable ambiguity, but ambiguitythat provides us with information we need to resolveother ambiguities.Re ferences\[Church, 1988\] Kenneth W. Church.
A stochasticparts program and noun phrase parser for unre-stricted text.
In Proceedings of the Second Con-ference on Applied Natural Language Processing,pages 136-143, Austin, Texas, 1988.\[Church, 1992\] Kenneth W. Church.
Current Prac-tice in Part of Speech Tagging and Suggestions forthe Future.
In Simmons (editor), Abornik praci:In Honor of Henry IfuSera, Michigan Slavic Stud-ies, pages 13-48, Michigan, 1992.\[Garside t al., 1987\] Garside, R., Leech, G. andSampson, G., (editors) The Computational Anal-ysis of English.
A Corpus-Based Approach.
Long-man, London, 1987.\[Karlsson, 1990\] Fred Karlsson.
Constraint Gram-mar as a framework for parsing running text.
InH.
Karlgren (editor),.
COLING-90.
Papers pre-sented to the 13th International Conference onComputational Linguistics.
Vol.
3 pages 168-173,Helsinki, 1990.\[Karlsson et al, 1991\] Karlsson, F., Voutilainen, A.,Anttila, A. and Heikkil?, J. Constraint Grammar:a Language-Independent System for Parsing Un-restricted Text, with an Application to English.In Natural Language Text Retrievah WorkshopNotes from the Ninth National Conference on Ar-tificial Intelligence (AAAI-91).
Anaheim, Califor-nia, 1991.\[Karlsson et al, 1993\] Karlsson, F., Voutilainen, A.,Heikkilii, J. and Anttila, A. Constraint Grammar:a Language-Independent System for Parsing Un-restricted Text.
(In print).\[Koskenniemi, 1990\] Kimmo Koskenniemi.
Finite-state parsing and disambiguation.
In H. Karl-gren (editor), COLING-90.
Papers presented tothe 13th International Conference on Computa-tional Linguistics.
Vol.
2 pages 229-232, Helsinki,1990.\[Koskenniemi et al, 1992\] Kimmo Koskenniemi,Past Tapanainen and Atro Voutilainen.
Compil-ing and using finite-state syntactic rules.
In Pro-ceedings of the fifteenth International Conferenceon Computational Linguistics.
COLING-92.
Vol.
Ipages 156-162, Nantes, France.
1992.\[Sampson, 1987\] Geoffrey Sampson.
ProbabilisticModels of Analysis.
In \[Garside t al., 1987\].\[Tapanainen, 1991\] Past Tapanainen.
A~irellisin?
au-tomaatteina esitettyjen kielioppis~i~int6jen sovel-taminen luonnollisen kielen j~ent~ij~s~i (Naturallanguage parsing with finite-state syntactic rules).Master's thesis.
Dept.
of computer science, Uni-versity of Helsinki, 1991.\[Tapanainen, 1992\] Past Tapanainen.
Jk/irellisiinautomaatteihin perustuva luonnollisen kielenj/isennin (A finite state parser of natural lan-guage).
Licentiate (pre-doctoral) thesis.
Dept.
ofcomputer science, University of Helsinki, 1992.\[Quirk et al, 1985\] Quirk, R., Greenbaum, S.,Leech, G. and Svartvik, J.
A ComprehensiveGrammar of the English Language.
Longman,London, 1985.\[Voutilainen, 1993\] Atro Voutilainen.
Morphologicaldisambiguation.
In \[Karlsson et al, 1993\].\[Voutilainen et al, 1992\] Atro Voutilainen, JuhaHeikkil~i and Arto Anttila.
Constraint grammarof English.
A Performance-Oriented Introduction.Publications nr.
21, Dept.
of General Linguistics,University of Helsinki, 1992.403
