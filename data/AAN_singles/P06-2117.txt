Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 913?920,Sydney, July 2006. c?2006 Association for Computational LinguisticsBoosting Statistical Word Alignment UsingLabeled and Unlabeled DataHua Wu      Haifeng Wang      Zhanyi LiuToshiba (China) Research and Development Center5/F., Tower W2, Oriental Plaza, No.1, East Chang An Ave., Dong Cheng DistrictBeijing, 100738, China{wuhua, wanghaifeng, liuzhanyi}@rdc.toshiba.com.cnAbstractThis paper proposes a semi-supervisedboosting approach to improve statisticalword alignment with limited labeled dataand large amounts of unlabeled data.
Theproposed approach modifies the super-vised boosting algorithm to a semi-supervised learning algorithm by incor-porating the unlabeled data.
In this algo-rithm, we build a word aligner by usingboth the labeled data and the unlabeleddata.
Then we build a pseudo referenceset for the unlabeled data, and calculatethe error rate of each word aligner usingonly the labeled data.
Based on this semi-supervised boosting algorithm, we inves-tigate two boosting methods for wordalignment.
In addition, we improve theword alignment results by combining theresults of the two semi-supervised boost-ing methods.
Experimental results onword alignment indicate that semi-supervised boosting achieves relative er-ror reductions of 28.29% and 19.52% ascompared with supervised boosting andunsupervised boosting, respectively.1 IntroductionWord alignment was first proposed as an inter-mediate result of statistical machine translation(Brown et al, 1993).
In recent years, many re-searchers build alignment links with bilingualcorpora (Wu, 1997; Och and Ney, 2003; Cherryand Lin, 2003; Wu et al, 2005; Zhang andGildea, 2005).
These methods unsupervisedlytrain the alignment models with unlabeled data.A question about word alignment is whetherwe can further improve the performances of theword aligners with available data and availablealignment models.
One possible solution is to usethe boosting method (Freund and Schapire,1996), which is one of the ensemble methods(Dietterich, 2000).
The underlying idea of boost-ing is to combine simple "rules" to form an en-semble such that the performance of the singleensemble is improved.
The AdaBoost (AdaptiveBoosting) algorithm by Freund and Schapire(1996) was developed for supervised learning.When it is applied to word alignment, it shouldsolve the problem of building a reference set forthe unlabeled data.
Wu and Wang (2005) devel-oped an unsupervised AdaBoost algorithm byautomatically building a pseudo reference set forthe unlabeled data to improve alignment results.In fact, large amounts of unlabeled data areavailable without difficulty, while labeled data iscostly to obtain.
However, labeled data is valu-able to improve performance of learners.
Conse-quently, semi-supervised learning, which com-bines both labeled and unlabeled data, has beenapplied to some NLP tasks such as word sensedisambiguation (Yarowsky, 1995; Pham et al,2005), classification (Blum and Mitchell, 1998;Thorsten, 1999), clustering (Basu et al, 2004),named entity classification (Collins and Singer,1999), and parsing (Sarkar, 2001).In this paper, we propose a semi-supervisedboosting method to improve statistical wordalignment with both limited labeled data andlarge amounts of unlabeled data.
The proposedapproach modifies the supervised AdaBoost al-gorithm to a semi-supervised learning algorithmby incorporating the unlabeled data.
Therefore, itshould address the following three problems.
Thefirst is to build a word alignment model withboth labeled and unlabeled data.
In this paper,with the labeled data, we build a supervisedmodel by directly estimating the parameters in913the model instead of using the ExpectationMaximization (EM) algorithm in Brown et al(1993).
With the unlabeled data, we build an un-supervised model by estimating the parameterswith the EM algorithm.
Based on these two wordalignment models, an interpolated model is builtthrough linear interpolation.
This interpolatedmodel is used as a learner in the semi-supervisedAdaBoost algorithm.
The second is to build areference set for the unlabeled data.
It is auto-matically built with a modified "refined" combi-nation method as described in Och and Ney(2000).
The third is to calculate the error rate oneach round.
Although we build a reference setfor the unlabeled data, it still contains alignmenterrors.
Thus, we use the reference set of the la-beled data instead of that of the entire trainingdata to calculate the error rate on each round.With the interpolated model as a learner in thesemi-supervised AdaBoost algorithm, we inves-tigate two boosting methods in this paper to im-prove statistical word alignment.
The firstmethod uses the unlabeled data only in the inter-polated model.
During training, it only changesthe distribution of the labeled data.
The secondmethod changes the distribution of both the la-beled data and the unlabeled data during training.Experimental results show that both of these twomethods improve the performance of statisticalword alignment.In addition, we combine the final results of theabove two semi-supervised boosting methods.Experimental results indicate that this combina-tion outperforms the unsupervised boostingmethod as described in Wu and Wang (2005),achieving a relative error rate reduction of19.52%.
And it also achieves a reduction of28.29% as compared with the supervised boost-ing method that only uses the labeled data.The remainder of this paper is organized asfollows.
Section 2 briefly introduces the statisti-cal word alignment model.
Section 3 describesparameter estimation method using the labeleddata.
Section 4 presents our semi-supervisedboosting method.
Section 5 reports the experi-mental results.
Finally, we conclude in section 6.2 Statistical Word Alignment ModelAccording to the IBM models (Brown et al,1993), the statistical word alignment model canbe generally represented as in equation (1).
?=a'e|f,a'e|fa,e|fa,)Pr()Pr()Pr((1)Where  and f  represent the source sentenceand the target sentence, respectively.eIn this paper, we use a simplified IBM model4 (Al-Onaizan et al, 1999), which is shown inequation (2).
This simplified version does nottake into account word classes as described inBrown et al (1993).
))))(()](([))()](([()|( )|()Pr(0,110,111112000 00?????=>?===????+??=???????????
?=majjmajjmjajliiimjjjajjpjdahjcjdahjeftenppm?????
?e|fa,(2)ml,  are the lengths of the source sentence andthe target sentence respectively.j  is the position index of the target word.ja  is the position of the source word aligned tothe  target word.
thji?
is the number of target words that  isaligned to.ie0p ,  are the fertility probabilities for , and 1p 0e110 =+ pp .
)|jajet(f  is the word translation probability.
)|( ii en ?
is the fertility probability.
)(1jacjd ??
is the distortion probability for thehead word of cept1 i.
))((1 jpjd ?>  is the distortion probability for thenon-head words of cept i.
}:{min)( kkaikih ==  is the head of cept i.
}:{max)( kjjkaakjp ==<.i?
is the first word before  with non-zero  iefertility.ic  is the center of cept i.3 Parameter Estimation with LabeledDataWith the labeled data, instead of using EM algo-rithm, we directly estimate the three main pa-rameters in model 4: translation probability, fer-tility probability, and distortion probability.1 A cept is defined as the set of target words connected to a source word(Brown et al, 1993).9143.1 Translation Probability Where 1),( =yx?
if yx = .
Otherwise, 0),( =yx?
.The translation probability is estimated from thelabeled data as described in (3).
4 Boosting with Labeled Data andUnlabeled Data?=')',(),()|(fijiijfecountfecounteft(3) In this section, we first propose a semi-supervised AdaBoost algorithm for word align-ment, which uses both the labeled data and theunlabeled data.
Based on the semi-supervisedalgorithm, we describe two boosting methods forword alignment.
And then we develop a methodto combine the results of the two boosting meth-ods.Where  is the occurring frequency ofaligned to  in the labeled data.
),( ji fecountie jf3.2 Fertility ProbabilityThe fertility probability )|( ii en ?
describes thedistribution of the numbers of words that  isaligned to.
It is estimated as described in (4).ie 4.1 Semi-Supervised AdaBoost Algorithmfor Word Alignment?='),'(),()|(???
?iiiii ecountecounten(4)Figure 1 shows the semi-supervised AdaBoostalgorithm for word alignment by using labeledand unlabeled data.
Compared with the super-vised Adaboost algorithm, this semi-supervisedAdaBoost algorithm mainly has five differences.Where ),( ii ecount ?
describes the occurring fre-quency of word  aligned to ie i?
target words inthe labeled data.
Word Alignment Model0p  and   describe the fertility probabilitiesfor .
And  and  sum to 1.
We estimatedirectly from the labeled data, which isshown in (5).1p0e 0p 1p0pThe first is the word alignment model, whichis taken as a learner in the boosting algorithm.The word alignment model is built using both thelabeled data and the unlabeled data.
With thelabeled data, we train a supervised model by di-rectly estimating the parameters in the IBMmodel as described in section 3.
With the unla-beled data, we train an unsupervised model usingthe same EM algorithm in Brown et al (1993).Then we build an interpolation model by linearlyinterpolating these two word alignment models,which is shown in (8).
This interpolated model isused as the model  described in figure 1. lMAlignedNullAlignedp###0?=  (5)Where  is the occurring frequency ofthe target words that have counterparts in thesource language.
is the occurring fre-quency of the target words that have no counter-parts in the source language.Aligned#Null#3.3 Distortion Probability)(Pr)1()(Pr)Pr(US e|fa,e|fa,e|fa,?
?+?= ??
(8)There are two kinds of distortion probability inmodel 4: one for head words and the other fornon-head words.
Both of the distortion probabili-ties describe the distribution of relative positionsThus, if we leticjj ??=?
1  and )(1 jpjj ?=?
> ,the distortion probabilities for head words andnon-head words are estimated in (6) and (7) withthe labeled data, respectively.Where  and  are thetrained supervised model and unsupervisedmodel, respectively.
)(PrS e|fa, )(PrU e|fa,?
is an interpolation weight.We train the weight in equation (8) in the sameway as described in Wu et al (2005).Pseudo Reference Set for Unlabeled Data????????=?
'1 ''',''1,111),(),()(j cjcjiiiicjjcjjjd??????(6)?
?
?>?>>>> ????=?
'1'' )(,'''1)(,111))(,())(,()(j jpjjpjjpjjjpjjjd ??
(7)The second is the reference set for the unla-beled data.
For the unlabeled data, we automati-cally build a pseudo reference set.
In order tobuild a reliable pseudo reference set, we performbi-directional word alignment on the trainingdata using the interpolated model trained on thefirst round.
Bi-directional word alignment in-cludes alignment in two directions (source to915Input: A training set  including m  bilingual sentence pairs;  TSThe reference set  for the training data; TRThe reference sets  and  ( ) for the labeled data  and the unlabeleddata  respectively, whereLR UR TUL , RRR ?
LSUS LUT SSS ?=  and NULLLU =?
SS ;A loop count L.(1) Initialize the weights:mimiw ,...,1,/1)(1 ==(2) For , execute steps (3) to (9).
L l to1=(3) For each sentence pair i, normalize theweights on the training set:?
==jlll mijwiwip ,...,1),(/)()((4) Update the word alignment modelbased on the weighted training data.lM(5) Perform word alignment on the training setwith the alignment model :  lM)( lll pMh =(6) Calculate the error of  with the referenceset :lhLR ?
?=ill iip )()( ?
?Where )(i?
is calculated as in equation (9).
(7) If 2/1>l?
, then let , and end thetraining process.1?= lL(8) Let )1/( lll ???
?= .
(9) For all i, compute new weights:nknkiwiw lll /))(()()(1 ??
?+?=+where, n represents n alignment links inthe ith sentence pair.
k represents the num-ber of error links as compared with .
TROutput: The final word alignment result for a source word e :?=?
?==LllllfffehfeWTfeRSeh1F )),((),()1(logmaxarg),(maxarg)( ?
?Where 1),( =yx?
if yx = .
Otherwise, 0),( =yx?
.
is the weight of the alignment linkproduced by the model , which is calculated as described in equation (10).
),( feWTl),( fe lMFigure 1.
The Semi-Supervised Adaboost Algorithm for Word Alignmenttarget and target to source) as described in Ochand Ney (2000).
Thus, we get two sets of align-ment results  and  on the unlabeled data.Based on these two sets, we use a modified "re-fined" method (Och and Ney, 2000) to constructa pseudo reference set .1A 2AUR(1) The intersection  is added to thereference set .21 AAI ?=UR(2) We add  to  if a) is satis-fied or both b) and c) are satisfied.21)  ,( AAfe ??
URa) Neither  nor  has an alignment inand  is greater than a thresholde f UR)|( efp 1?
.
?=')',(),()|(ffecountfecountefpWhere  is the occurring fre-quency of the alignment link  inthe bi-directional word alignment results.
),( fecount)  ,( feb)  has a horizontal or a verticalneighbor that is already in .)
,( feURc) The set does not containalignments with both horizontal and ver-tical neighbors.
),(U feR ?Error of Word AlignerThe third is the calculation of the error of theindividual word aligner on each round.
For wordalignment, a sentence pair is taken as a sample.Thus, we calculate the error rate of each sentencepair as described in (9), which is the same as de-scribed in Wu and Wang (2005).||||||21)(RWRWSSSSi +??=?
(9)Where  represents the set of alignmentlinks of a sentence pair i identified by the indi-vidual interpolated model on each round.
isthe reference alignment set for the sentence pair.WSRSWith the error rate of each sentence pair, wecalculate the error of the word aligner on eachround.
Although we build a pseudo reference setfor the unlabeled data, it contains alignmenterrors.
Thus, the weighted sum of the error ratesof sentence pairs in the labeled data instead ofthat in the entire training data is used as the errorof the word aligner.UR916Weights Update for Sentence PairsThe forth is the weight update for sentencepairs according to the error and the reference set.In a sentence pair, there are usually several wordalignment links.
Some are correct, and othersmay be incorrect.
Thus, we update the weightsaccording to the number of correct and incorrectalignment links as compared with the referenceset, which is shown in step (9) in figure 1.Weights for Word Alignment LinksThe fifth is the weights used when we con-struct the final ensemble.
Besides the weight)/1log( l?
, which is the confidence measure ofthe  word aligner, we also use the weightto measure the confidence of eachalignment link produced by the model .
Theweight  is calculated as shown in (10).Wu and Wang (2005) proved that adding thisweight improved the word alignment results.thl),( feWTllM),( feWTl??
+?=''),'()',(),(2),(efl fecountfecountfecountfeWT(10)Where  is the occurring frequencyof the alignment link  in the word align-ment results of the training data produced by themodel .
),( fecount)  ,( felM4.2 Method 1This method only uses the labeled data as train-ing data.
According to the algorithm in figure 1,we obtain  and .
Thus, we onlychange the distribution of the labeled data.
How-ever, we build an unsupervised model using theunlabeled data.
On each round, we keep this un-supervised model unchanged, and we rebuild thesupervised model by estimating the parametersas described in section 3 with the weighted train-ing data.
Then we interpolate the supervisedmodel and the unsupervised model to obtain aninterpolated model as described in section 4.1.The interpolated model is used as the alignmentmodel  in figure 1.
Thus, in this interpolatedmodel, we use both the labeled and unlabeleddata.
On each round, we rebuild the interpolatedmodel using the rebuilt supervised model and theunchanged unsupervised model.
This interpo-lated model is used to align the training data.LT SS = LT RR =lMAccording to the reference set of the labeleddata, we calculate the error of the word aligneron each round.
According to the error and thereference set, we update the weight of each sam-ple in the labeled data.4.3 Method 2This method uses both the labeled data and theunlabeled data as training data.
Thus, we setULT SSS ?=  and ULT RRR ?=  as described infigure 1.
With the labeled data, we build a super-vised model, which is kept unchanged on eachround.2 With the weighted samples in the train-ing data, we rebuild the unsupervised model withEM algorithm on each round.
Based on these twomodels, we built an interpolated model as de-scribed in section 4.1.
The interpolated model isused as the alignment model  in figure 1.
Oneach round, we rebuild the interpolated modelusing the unchanged supervised model and therebuilt unsupervised model.
Then the interpo-lated model is used to align the training data.lMSince the training data includes both labeledand unlabeled data, we need to build a pseudoreference set  for the unlabeled data using themethod described in section 4.1.
According tothe reference set  of the labeled data, we cal-culate the error of the word aligner on eachround.
Then, according to the pseudo referenceset  and the reference set , we update theweight of each sentence pair in the unlabeleddata and in the labeled data, respectively.URLRUR LRThere are four main differences betweenMethod 2 and Method 1.
(1) On each round, Method 2 changes the distri-bution of both the labeled data and the unla-beled data, while Method 1 only changes thedistribution of the labeled data.
(2) Method 2 rebuilds the unsupervised model,while Method 1 rebuilds the supervisedmodel.
(3) Method 2 uses the labeled data instead of theentire training data to estimate the error ofthe word aligner on each round.
(4) Method 2 uses an automatically built pseudoreference set to update the weights for thesentence pairs in the unlabeled data.4.4 CombinationIn the above two sections, we described twosemi-supervised boosting methods for wordalignment.
Although we use interpolated models2 In fact, we can also rebuild the supervised model accord-ing to the weighted labeled data.
In this case, as we know,the error of the supervised model increases.
Thus, we keepthe supervised model unchanged in this method.917for word alignment in both Method 1 andMethod 2, the interpolated models are trainedwith different weighted data.
Thus, they performdifferently on word alignment.
In order to furtherimprove the word alignment results, we combinethe results of the above two methods as describedin (11).
)),(),((maxarg)(2211F3,feRSfeRSehf?+?= ?
?ods to calculate the precision, recall, f-measure,and alignment error rate (AER) are shown inequations (12), (13), (14), and (15).
It can beseen that the higher the f-measure is, the lowerthe alignment error rate is.|S||SS|GCG ?=precision      (12)|S||SS|CCG ?=recall  (11) (13)||||||2CGCGSSSSfmeasure +?
?=  Where  is the combined hypothesis forword alignment.
and  are thetwo ensemble results as shown in figure 1 forMethod 1 and Method 2, respectively.
)(F3, eh),(1 feRS ),(2 feRS1?
and 2?are the constant weights.
(14)fmeasureSSSSAER ?=+??
?= 1||||||21CGCG  (15)5.3 Experimental Results5 Experiments With the data in section 5.1, we get the wordalignment results shown in table 2.
For all of themethods in this table, we perform bi-directional(source to target and target to source) wordalignment, and obtain two alignment results onthe testing set.
Based on the two results, we getthe "refined" combination as described in Ochand Ney (2000).
Thus, the results in table 2 arethose of the "refined" combination.
For EMtraining, we use the GIZA++ toolkit4.In this paper, we take English to Chinese wordalignment as a case study.5.1 DataWe have two kinds of training data from generaldomain: Labeled Data (LD) and Unlabeled Data(UD).
The Chinese sentences in the data areautomatically segmented into words.
The statis-tics for the data is shown in Table 1.
The labeleddata is manually word aligned, including 156,421alignment links.Data # Sentence Pairs# EnglishWordsResults of Supervised MethodsUsing the labeled data, we use two methods toestimate the parameters in IBM model 4: one isto use the EM algorithm, and the other is to esti-mate the parameters directly from the labeleddata as described in section 3.
In table 2, themethod "Labeled+EM" estimates the parameterswith the EM algorithm, which is an unsupervisedmethod without boosting.
And the method "La-beled+Direct" estimates the parameters directlyfrom the labeled data, which is a supervisedmethod without boosting.
"Labeled+EM+Boost"and "Labeled+Direct+Boost" represent the twosupervised boosting methods for the above twoparameter estimation methods.# ChineseWordsLD 31,069 255,504 302,470UD 329,350 4,682,103 4,480,034Table 1.
Statistics for Training DataWe use 1,000 sentence pairs as testing set,which are not included in LD or UD.
The testingset is also manually word aligned, including8,634 alignment links in the testing set3.5.2 Evaluation MetricsWe use the same evaluation metrics as describedin Wu et al (2005), which is similar to those in(Och and Ney, 2000).
The difference lies in thatWu et al (2005) take all alignment links as surelinks.Our methods that directly estimate parametersin IBM model 4 are better than that using the EMalgorithm.
"Labeled+Direct" is better than "La-beled+EM", achieving a relative error rate reduc-tion of 22.97%.
And "Labeled+Direct+Boost" isbetter than "Labeled+EM+Boost", achieving arelative error rate reduction of 22.98%.
In addi-tion, the two boosting methods perform betterthan their corresponding methods withoutIf we use  to represent the set of alignmentlinks identified by the proposed method andto denote the reference alignment set, the meth-GSCS3 For a non one-to-one link, if m source words are aligned ton target words, we take it as one alignment link instead ofm?n alignment links.4 It is located at http://www.fjoch.com/ GIZA++.html.918Method Precision Recall F-Measure AERLabeled+EM 0.6588 0.5210 0.5819 0.4181Labeled+Direct 0.7269 0.6609 0.6924 0.3076Labeled+EM+Boost 0.7384 0.5651 0.6402 0.3598Labeled+Direct+Boost 0.7771 0.6757 0.7229 0.2771Unlabeled+EM 0.7485 0.6667 0.7052 0.2948Unlabeled+EM+Boost 0.8056 0.7070 0.7531 0.2469Interpolated 0.7555 0.7084 0.7312 0.2688Method 1 0.7986 0.7197 0.7571 0.2429Method 2 0.8060 0.7388 0.7709 0.2291Combination 0.8175 0.7858 0.8013 0.1987Table 2.
Word Alignment Resultsboosting.
For example, "Labeled+Direct+Boost"achieves an error rate reduction of 9.92% ascompared with "Labeled+Direct".Results of Unsupervised MethodsWith the unlabeled data, we use the EM algo-rithm to estimate the parameters in the model.The method "Unlabeled+EM" represents an un-supervised method without boosting.
And themethod "Unlabeled+EM+Boost" uses the sameunsupervised Adaboost algorithm as described inWu and Wang (2005).The boosting method "Unlabeled+EM+Boost"achieves a relative error rate reduction of 16.25%as compared with "Unlabeled+EM".
In addition,the unsupervised boosting method "Unla-beled+EM+Boost" performs better than the su-pervised boosting method "Labeled+Direct+Boost", achieving an error rate reduction of10.90%.
This is because the size of labeled datais too small to subject to data sparseness problem.Results of Semi-Supervised MethodsBy using both the labeled and the unlabeleddata, we interpolate the models trained by "La-beled+Direct" and "Unlabeled+EM" to get aninterpolated model.
Here, we use "interpolated"to represent it.
"Method 1" and  "Method 2" rep-resent the semi-supervised boosting methods de-scribed in section 4.2 and section 4.3, respec-tively.
"Combination" denotes the method de-scribed in section 4.4, which combines "Method1" and "Method 2".
Both of the weights 1?
and2?
in equation (11) are set to 0.5.
"Interpolated" performs better than the meth-ods using only labeled data or unlabeled data.
Itachieves relative error rate reductions of 12.61%and 8.82% as compared with "Labeled+Direct"and "Unlabeled+EM", respectively.Using an interpolation model, the two semi-supervised boosting methods "Method 1" and"Method 2" outperform the supervised boostingmethod "Labeled+Direct+Boost", achieving arelative error rate reduction of 12.34% and17.32% respectively.
In addition, the two semi-supervised boosting methods perform better thanthe unsupervised boosting method "Unlabeled+EM+Boost".
"Method 1" performs slightly betterthan "Unlabeled+EM+Boost".
This is becausewe only change the distribution of the labeleddata in "Method 1".
"Method 2" achieves an er-ror rate reduction of 7.77% as compared with"Unlabeled+EM+Boost".
This is because we usethe interpolated model in our semi-supervisedboosting method, while "Unlabeled+EM+Boost"only uses the unsupervised model.Moreover, the combination of the two semi-supervised boosting methods further improvesthe results, achieving relative error rate reduc-tions of 18.20% and 13.27% as compared with"Method 1" and "Method 2", respectively.
It alsooutperforms both the supervised boostingmethod "Labeled+Direct+Boost" and the unsu-pervised boosting method "Unlabeled+EM+Boost", achieving relative error rate reductions of28.29% and 19.52% respectively.Summary of the ResultsFrom the above result, it can be seen that allboosting methods perform better than their corre-sponding methods without boosting.
The semi-supervised boosting methods outperform the su-pervised boosting method and the unsupervisedboosting method.6 Conclusion and Future WorkThis paper proposed a semi-supervised boostingalgorithm to improve statistical word alignmentwith limited labeled data and large amounts ofunlabeled data.
In this algorithm, we built an in-terpolated model by using both the labeled data919and the unlabeled data.
This interpolated modelwas employed as a learner in the algorithm.
Then,we automatically built a pseudo reference for theunlabeled data, and calculated the error rate ofeach word aligner with the labeled data.
Basedon this algorithm, we investigated two methodsfor word alignment.
In addition, we developed amethod to combine the results of the above twosemi-supervised boosting methods.Experimental results indicate that our semi-supervised boosting method outperforms the un-supervised boosting method as described in Wuand Wang (2005), achieving a relative error ratereduction of 19.52%.
And it also outperforms thesupervised boosting method that only uses thelabeled data, achieving a relative error rate re-duction of 28.29%.
Experimental results alsoshow that all boosting methods outperform theircorresponding methods without boosting.In the future, we will evaluate our methodwith an available standard testing set.
And wewill also evaluate the word alignment results in amachine translation system, to examine whetherlower word alignment error rate will result inhigher translation accuracy.ReferencesYaser Al-Onaizan, Jan Curin, Michael Jahr, KevinKnight, John Lafferty, Dan Melamed, Franz-JosefOch, David Purdy, Noah A. Smith, and DavidYarowsky.
1999.
Statistical Machine TranslationFinal Report.
Johns Hopkins University Workshop.Sugato Basu, Mikhail Bilenko, and Raymond J.Mooney.
2004.
Probabilistic Framework for Semi-Supervised Clustering.
In Proc.
of the 10th ACMSIGKDD International Conference on KnowledgeDiscovery and Data Mining (KDD-2004), pages59-68.Avrim Blum and Tom Mitchell.
1998.
Combing La-beled and Unlabeled Data with Co-training.
InProc.
of the 11th Conference on ComputationalLearning Theory (COLT-1998), pages1-10.Peter F. Brown, Stephen A. Della Pietra, Vincent J.Della Pietra, and Robert L. Mercer.
1993.
TheMathematics of Statistical Machine Translation:Parameter Estimation.
Computational Linguistics,19(2): 263-311.Colin Cherry and Dekang Lin.
2003.
A ProbabilityModel to Improve Word Alignment.
In Proc.
of the41st Annual Meeting of the Association for Compu-tational Linguistics (ACL-2003), pages 88-95.Michael Collins and Yoram Singer.
1999.
Unsuper-vised Models for Named Entity Classification.
InProc.
of the Joint SIGDAT Conference on Empiri-cal Methods in Natural Language Processing andVery Large Corpora (EMNLP/VLC-1999), pages100-110.Thomas G. Dietterich.
2000.
Ensemble Methods inMachine Learning.
In Proc.
of the First Interna-tional Workshop on Multiple Classifier Systems(MCS-2000), pages 1-15.Yoav Freund and Robert E. Schapire.
1996.
Experi-ments with a New Boosting Algorithm.
In Proc.
ofthe 13th International Conference on MachineLearning (ICML-1996), pages 148-156.Franz Josef Och and Hermann Ney.
2000.
ImprovedStatistical Alignment Models.
In Proc.
of the 38thAnnual Meeting of the Association for Computa-tional Linguistics (ACL-2000), pages 440-447.Franz Josef Och and Hermann Ney.
2003.
A System-atic Comparison of Various Statistical AlignmentModels.
Computational Linguistics, 29(1):19-51.Thanh Phong Pham, Hwee Tou Ng, and Wee Sun Lee2005.
Word Sense Disambiguation with Semi-Supervised Learning.
In Proc.
of the 20th NationalConference on Artificial Intelligence (AAAI 2005),pages 1093-1098.Anoop Sarkar.
2001.
Applying Co-Training Methodsto Statistical Parsing.
In Proc.
of the 2nd Meeting ofthe North American Association for ComputationalLinguistics( NAACL-2001), pages 175-182.Joachims Thorsten.
1999.
Transductive Inference forText Classification Using Support Vector Ma-chines.
In Proc.
of the 16th International Confer-ence on Machine Learning (ICML-1999), pages200-209.Dekai Wu.
1997.
Stochastic Inversion TransductionGrammars and Bilingual Parsing of Parallel Cor-pora.
Computational Linguistics, 23(3): 377-403.Hua Wu and Haifeng Wang.
2005.
Boosting Statisti-cal Word Alignment.
In Proc.
of the 10th MachineTranslation Summit, pages 313-320.Hua Wu, Haifeng Wang, and Zhanyi Liu.
2005.Alignment Model Adaptation for Domain-SpecificWord Alignment.
In Proc.
of the 43rd Annual Meet-ing of the Association for Computational Linguis-tics (ACL-2005), pages 467-474.David Yarowsky.
1995.
Unsupervised Word SenseDisambiguation Rivaling Supervised Methods.
InProc.
of the 33rd Annual Meeting of the Associationfor Computational Linguistics (ACL-1995), pages189-196.Hao Zhang and Daniel Gildea.
2005.
Stochastic Lexi-calized Inversion Transduction Grammar forAlignment.
In Proc.
of the 43rd Annual Meeting ofthe Association for Computational Linguistics(ACL-2005), pages 475-482.920
