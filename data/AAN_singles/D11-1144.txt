Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 1557?1567,Edinburgh, Scotland, UK, July 27?31, 2011. c?2011 Association for Computational LinguisticsBootstrapped Named Entity Recognition for Product Attribute ExtractionDuangmanee (Pew) PutthividhyaeBay Inc.2065 Hamilton AveSan Jose, CA 95125dputthividhya@ebay.comJunling HueBay Inc.2065 Hamilton AveSan Jose, CA 95125juhu@ebay.comAbstractWe present a named entity recognition (NER)system for extracting product attributes andvalues from listing titles.
Information extrac-tion from short listing titles present a uniquechallenge, with the lack of informative con-text and grammatical structure.
In this work,we combine supervised NER with bootstrap-ping to expand the seed list, and output nor-malized results.
Focusing on listings fromeBay?s clothing and shoes categories, ourbootstrapped NER system is able to identifynew brands corresponding to spelling variantsand typographical errors of the known brands,as well as identifying novel brands.
Amongthe top 300 new brands predicted, our systemachieves 90.33% precision.
To output normal-ized attribute values, we explore several stringcomparison algorithms and found n-gram sub-string matching to work well in practice.1 IntroductionTraditional named entity recognition (NER) task hasexpanded beyond identifying people, location, andorganization to book titles, email addresses, phonenumbers, and protein names (Nadeau and Sekine2007).
Recently there has been a surge of interestin extracting product attributes from online data dueto the rapid growth of E-Commerce.
Current workin this domain focuses on mining product reviewsand descriptions from retailer websites.
Such textdata tend to be long and generate enough context forthe target task (Brody and Elhadad 2010; Liu et al2005; Popescu and Etzioni 2005).
In this paper, wefocus on mining short product listing titles, whichposes unique challenges.Short listings are typical in classified ads whereeach seller is given limited space (in terms of words)to describe the product.
On eBay, product listing ti-tles cannot exceed 55 characters in length.
Similarly,on Craigslist and newspaper ads, the length of a list-ing title is restricted.
Extracting product attributesfrom such short titles faces the following challenges:?
Loss of grammatical structure in short listingswhere many nouns are piled together.?
Typographical errors, abbreviations, andacronyms that must be normalized to thestandardized values.?
Lack of contextual information to infer productattribute value.It can be argued that the use of short listings simpli-fies the problem of attribute extraction, since shortlistings can be easily annotated and one can applysupervised learning approach to extract product at-tributes.
However, as the size of the data grows, ob-taining labeled training set on the scale of millionsof listings becomes very expensive.
In such a sce-nario, incorporating unlabeled examples in a semi-supervised fashion to scale up the solution becomesa necessity rather than a luxury.We formulate the product attribute extractionproblem as a named entity recognition (NER) taskand investigate supervised and semi-supervised ap-proaches to this problem.
In addition, we have in-vestigated attribute discovery, and normalization tostandardized values.
We use listings from eBay?sclothing and shoes categories and develop an at-tribute extraction system for 4 attribute types.
Wehave 105, 335 listings from men?s clothing categoryand 72, 628 listings from women?s clothing category1557on eBay, constituting a dataset of 1, 380, 337 wordtokens.In the first part of this work, we outline a super-vised learning approach to attribute value extractionwhere we train a sequential classifier and evaluatethe extraction performance on a set of hand-labeledlistings.
Using maximum entropy and SVM as thebase classifier (for classifying the individual wordtokens), a hidden Markov model (HMM) is trainedon the the probabilistic output of the base classifier,and a sequential label prediction is obtained using aViterbi decoding.
We show a performance compar-ison of supervised HMM, MaxEnt, SVM, and CRFfor this task.In the second part of our work, to grow our seedlist of attributes, we present a bootstrapped algo-rithm for attribute value discovery and normaliza-tion, honing in on one particular attribute (brand).The goal is given an initial list of unambiguousbrands, we grow the seed dictionary by discover-ing context patterns that are often associated withsuch attribute type.
First, we automatically parti-tion data into a training/test set by labeling word to-kens in each listing using exact matching to entriesin the dictionary.
Brand phrases that can be confusedwith other attributes, e.g.
the word camel ?
both abrand and a color ?
will not be a part of this ini-tial seed list to create the training set.
A classifieris then trained to learn context patterns surroundingthe known brands from the training set, and is usedto discover new brands from the test set.Finally, for known attribute values, we normalizethe results to match to words in our dictionary.
Nor-malizing the variants of a known brand to a singlenormalized output value is an important aspect ofa successful information extraction system.
To thisend, we investigate several string similarity/distancemeasures for this task and found that n-gram sub-string similarity (Kondrak 2005) yields accurate nor-malization results.The main contribution of this work is a productattribute extraction system that addresses the uniqueproblems of information extraction from short list-ing titles.
We combine supervised NER with boot-strapping to expand the seed list, and investigate sev-eral methods to normalize the extracted results.
Oursystem has been tested on large-scale eBay listingdatasets to demonstrate its effectiveness.2 Related WorkRecent work on product attribute extraction by(Brody and Elhadad 2010) applies a Latent Dirich-let Allocation (LDA) model to identify different as-pects of products from user reviews.
Similar workis presented in (Liu et al 2005).
Topic models suchas LDA groups similar words together by identify-ing topics (product aspects) from patterns of word-occurrences.
Such grouping can discover new as-pects of a product such as ?portability?
(for net-book computers), but it may generate aspects thatare vague and not easily interpretable.
Indeed, howto refine discovered aspects and clean up words ineach aspect remains an open question.
The LDAapproach also treats documents as bags of words,where important information in word sequences isnot taken into account in learning the model.Our work is most closely related to (Ghani 2006),where a set of product attributes of interests are pre-defined and a supervised learning method is appliedto extract the correct attribute values for each class.Starting out from a small set of training examples,a bootstrapping technique is used to generate moretraining data from unlabeled data.
The main dif-ference to our method lies in how bootstrapping isused.
(Ghani 2006) used EM to add more train-ing data from unlabeled data, while in our approachbootstrapping is used to expand the seed list.
First,we automatically generate labeled data by matchingseed list to unlabeled data.
Then, these auto-labeledtraining set is used to train a classifier to identify newattribute values from a separate set of unlabeled data.Thirdly, newly discovered product attribute valuesare added back to our seed list.
Thus our originalclassifier for product attribute extraction can be im-proved through an expanded seed list.In (Ghani and Jones 2002; Jones 2005), severalbootstrapping methods are compared.
These meth-ods include self-training, co-EM and EM.
All ofthese approaches are different from ours, as de-scribed in detail earlier.
In (Probst et al 2006),a Naive Bayes learner is combined with Co-EM togenerate more training data from unlabeled data, andattribute-value pairs are extracted on adjacent words.The automatic bootstrapping in this paper was in-spired by (Pakhomov 2002)?an acronym expansionalgorithm for medical text documents.
The underly-ing assumption is that abbreviated forms and their1558corresponding expansions occur in similar contexts;consequently, the surrounding context patterns canbe used in associating the correct expansion to itsacronym.Our seed list expansion algorithm indeed bearssome similarity to the work of (Nadeau el al 2006)and (Nadeau 2007).
In (Nadeau el al 2006), automo-bile brands are learned automatically from web pagecontext.
First, a small set of 196 seed brands are ex-tracted together with their associated web page con-texts from popular news feed.
The web context issubsequently used to extract additional automobilebrands, which result in a total of 5701 brands.
How-ever, the reported results in (Nadeau el al 2006) havelow precision, in some case less than 50%.
Eventu-ally their approach needs to rely on rule-based ambi-guity resolver to increase the precision.
Our systemdoes not rely on manually created rules.A more NLP-oriented approach is proposed in(Popescu and Etzioni 2005), where noun phrases areextracted from online user reviews.
Their systemtries to identify product features and user opinionsfrom such noun phrases.
A PMI (pointwise mutualinformation) score is evaluated between each nounphrase and discriminators associated with the prod-uct class.
The noun-phrase approach does not workwell in informal texts.
In our case, user-generatedshort product listings may have many nouns con-catenated together without forming a phrase orobeying correct grammatical rules.Finally, another similar bootstrapping method ispresented in (Mintz et al 2009), where instancesof known entity relations (or seed list in our paper)are matched to sentences in a set of Wikipedia arti-cles, and a learning algorithm is trained from the sur-rounding features of the entities.
The trained modelis then applied to a test set of Wikipedia articles,and has been reported to be able to discover new in-stances.
In our case, we apply our learned model toa new test set, and discover new brand names fromthe listings.The nature of non-grammatical text we facemakes our work similar to the NER work on infor-mal texts.
(Minkov et al 2005) proposes an NERsystem that extracts personal names from emails.The work in (Gruhl et al2009) identifies song titlesfrom online forums on popular music, where songtitles can be very ambiguous.
By using real-worldconstraints such as known song titles, (Gruhl et al2009) restricts the set of possible entities and areable to obtain reasonable recognition performance.3 CorpusThe data used in all analysis in this paper is obtainedfrom eBay?s clothing and shoes category.
Clothingand shoes have been important revenue-generatingcategories on the eBay site, and a successful at-tribute extraction system will serve as an invaluabletool for gathering important business and market-ing intelligence.
For these categories, the attributesthat we are interested in are brand (B), garmenttype/style (G), size (S), and color (C).
We gather105, 335 listings from men?s clothing category and72, 628 listings from women?s clothing category,constituting a dataset of 1, 380, 337 word tokens.
Onaverage, each listing title contains 7.76 words.A few examples of listings from eBay?s clothingand shoes categories are shown in Fig 1.
When de-signing an attribute extraction system to distinguishbetween the 4 attribute types, we must take into ac-count the fact that individual words alone ?
with-out considering context ?
are ambiguous, as eachword can belong to multiple attribute types.
To giveconcrete examples, inc is a brand name of women?sapparel but many sellers use it as an acronym forinch (brand vs. size).
The word blazer can be abrand entity or it can be a garment type (brand vs.garment type).
In addition, like other real-worlduser-generated texts, eBay listings are littered withsite-specific acronyms, e.g.
BNWT (brand new withtag), NIB (new in box), and abbreviations introducedby individual sellers, e.g.
immac (immaculate), trs(trousers).
In designing an information extractionsystem for our dataset, we need to account for thegeneral as well as specific properties of our dataset.4 Supervised Named Entity RecognitionIn the first part of this work, we adopt a supervisednamed entity recognition (NER) framework for theattribute extraction problem from eBay listing titles.The goal is to correctly extract attribute values cor-responding to the 4 attribute types, from each list-ing.
One key assumption of the supervised learn-ing paradigm is the availability of a labeled trainingdata for training a classifier to distinguish betweendifferent classes.
We generate our training data in1559Figure 1: Example listings and their corresponding labels from the clothing and shoes category.the following manner.
For each listing, we removeextraneous punctuation symbols (*,(,),!,:,;) and tok-enize each listing into a sequence of tokens.
Given 4dictionaries of seed values for the 4 attribute types,we match n-gram tokens to the seed values in thedictionaries, and create an initial round of labeledtraining set, which must then be manually inspectedfor correctness.
In this work, we tagged and manu-ally verified 1, 000 listings randomly sampled fromthe 105, 335 listings from the men?s clothing cate-gory, resulting in a total of 7, 921 labeled tokens with1, 521-word vocabulary.
Fig.
1 shows examples oflabeled listings, with tags B corresponding to brand,C for color, S for size, G for garment type/style, andNA for none of the above.4.1 ClassifiersOne of the most popular generative model basedclassifiers for named entity recognition tasks is Hid-den Markov Model (HMM), which explicitly cap-tures temporal statistics in the data by modelingstate (label/tag) transitions over time.
Discrimina-tive classifiers, which directly model the posteriordistribution of class label given features, i.e.
SVM(Isozaki and Kazawa 2002) and Maximum Entropymodel for NER (Chieu and Ng 2003), have beenshown to outperform generative model based clas-sifiers.
More recently, Conditional Random Fields(CRF) (Feng and McCallum 2004; McCallum 2003)has been proposed for a sequence labeling problemand has been established by many as the state-of-the-art model for supervised named entity recogni-tion task.
In this section, we briefly summarize thepros and cons of each approach.4.1.1 Hidden Markov ModelsA hidden Markov model (HMM) is a probabilisticgenerative model for sequential data.
HMM is char-acterized by 2 sets of model parameters ?
emissionprobabilities which produce the observation variablegiven the hidden state, and the state transition prob-ability matrix which captures the temporal correla-tion in the hidden state sequences.
Given a set of la-beled training sequences as shown in Figure 1, onecan train an HMM to model temporal statistics inthe observation sequences.
In our task, a sequenceof word tokens from listing titles are our observa-tions.
One simple approach to use HMM is to set ahidden state to correspond to a tag class.
In the train-ing phase, since all the tags are given, the hiddenstates indeed become visible and inference in thismodel becomes much more simplified.
The multino-mial parameter for the emission probabilities p(w|s)can be learned with a closed-form update (maximumlikelihood estimate).
During testing, however, an ef-ficient forward-backward algorithm must be used toinfer the most likely tag sequence that accounts forthe observation.One main drawback of HMM is the type of fea-tures that it can handle.
Like other probabilistic gen-erative models, in order to account for rich, over-lapping feature sets, e.g.
text formatting features,the correlation structures in the overlapping featuresmust be explicitly modeled.
Indeed, in the clas-sic HMM based NER, the simple feature used isthe word identity itself, which might not be suffi-ciently discriminative in distinguishing between dif-ferent classes.
In addition, because of data sparsity(out-of-vocabulary) problem due to the long-taileddistribution of words in natural language, sophisti-cated unknown word models are generally neededfor good performance (Klein et al 2003).4.1.2 Maximum Entropy modelsThe principle of maximum entropy states thatamong all the distributions that satisfy feature con-straints, we should pick the distribution with thehighest entropy, since it makes the least assumptionabout the data and will have better generalizationcapability to unseen data.
Maximum entropy clas-sifier, therefore, is the highest entropy conditionaldistribution of the class label given features, whichhas been shown to conveniently take an exponentialform.
Maximum entropy classifier is thus closelyrelated to logistic regression model.1560Position Features:- Position from the beginning of listing- Position to the end of listingOrthographic Features:- Identity of the current word- Current word contains a digit- Current word contains only digits- Current word is capitalized- Current word begins with a capitalized letter followed byall non-cap letters.- Current word is &- Current word is ?- N -gram substring features of current word (N = 4, 5, 6)Context Features:- Identity of 2 words before the current word- Identity of 2 words after the current word- Previous word is from- Previous word is by- Previous word is and- N -gram substring features of neighboring words (N = 4, 5, 6)Dictionary Features:- Membership to the 4 dictionaries of attributes- Exclusive membership to dictionary of brand names- Exclusive membership to dictionary of garment types- Exclusive membership to dictionary of sizes- Exclusive membership to dictionary of colorsTable 1: Feature set used in discriminative classifiers.MaxEnt classifiers (Ratnaparkhi 1996; Ratna-parkhi 1998) have been applied to various NLP ap-plications.
The attraction of the framework lies inthe ease with which different information sourcesused in the modeling process are combined and thegood results that are reported with the use of thesemodels.
The set of redundant features used for theMaxEnt classifier is the same as those used for theSVM classifier, which we outline in the next section.4.1.3 Support Vector MachinesSupport Vector Machine (SVM) is yet anotherpopular classifier for a supervised NER task.
In abinary classification case, SVM finds parameters ofa linearly separating hyperplane that best separatesdata from the 2 classes, in a sense that the marginof separation is maximized.
Since only the samplesclosest to the decision boundary (the so-called sup-port vectors) determine the location of the separatinghyperplane, SVM can be trained on very few train-ing examples even for data in a high-dimensionalspace.
For our supervised NER system, we use thefollowing features, as described in detail in Table 1,as input to the discriminative classifiers.The use of char N -gram (N -gram substring) fea-tures was inspired by the work of (Klein et al 2003),where the introduction of such features has beenshown to improve the overall F1 score by over 20%.In (Kanaris et al 2006), char N -gram features con-sistently outperform word features in learning effec-tive spam classifiers.
Indeed the use of character N -gram features as an input to the classifier subsumesthe use of prefix, suffix, and the entire word features.Generally speaking, char N -gram features provide amore robust representation against misspelling sincestring s1 and its spelling variant s2 may share manychar N -gram substrings in common.POS and punctuation features are not used in ourNER system.
This is mainly due to the fact that eBaylisting titles are not complete sentences and the out-put from running a POS tagger through such datacan indeed be unreliable.
For punctuation features,eBay sellers are known to abuse punctuation marksexcessively to draw attention of the potential buyersto click on their listings.
In addition, we find thatmorphological features are less predictive of entitynames in eBay listing titles than they are in formaldocuments.
To give a concrete example, capitaliza-tion is a good predictor of entity names in traditionalNER systems, but on the eBay site, many sellersuse all-cap or all-lowercase letters for every wordin their titles, bringing into question the discrimi-native power of widely used features in traditionalNER systems.4.1.4 Viterbi SmoothingThe Viterbi algorithm can be used to smooth theprediction output from SVM or MaxEnt.
Morespecifically, the Viterbi decoder enforces the tempo-ral consistency on the individual label prediction asinferred by the base classifier ?
MaxEnt or SVM,independently based on the feature representationof each word token.
The probabilistic ouput of thebase classifier is the observation or evidence, whilethe temporal consistency is encoded in the empiricalstate transition probability matrix inferred from thetraining data.
This scenario is analogous to compar-ing MAP (maximum a priori) estimate with that ofML (maximum likelihood) in that the former incor-porates a prior belief when making a final estimateof the parameter values (most likely label sequencepredicted by the Viterbi algorithm), while the latteruses only the observation to infer the most likely pa-rameter estimate (independently inferred predictedlabels of each word token from the base classifier).1561We adopt the approach from the work of (Chieuand Ng 2003), which uses Viterbi to improve theclassification results from MaxEnt classifier forNER tasks.
Instead of computing the transitionprobability matrix by recording the frequency ofhow many times state i at time T transitions to statej at time T + 1, we simply record that this state ito j transition is admissible.
This approach, indeed,divides a set of all label sequences into ones that areadmissible and inadmissible, and assign equal prob-abilities to all the admissible sequences.
Such an ap-proach therefore eliminates all the inadmissible se-quences of labels (i.e.
prohibit the scenario where-in sub-tag is followed by -begin sub-tag), while al-lowing the Viterbi algorithm to give more weight tothe classification outputs from SVM or MaxEnt.4.1.5 Conditional Random Field (CRF)Conditional Random Field, since its conception inthe seminal work of (Lafferty et al 2002), is a dis-criminative classifier for sequential data that com-bines the best of both worlds.
Like SVM and Max-Ent, CRF is a discriminative classifier that directlymodels the conditional distribution of the target vari-able given the observed variable, i.e.
no modelingresource is wasted in modeling complex correlationstructures in the observation sequences.
Like HMM,CRF makes prediction on the label sequence by in-corporating the temporal smoothness.
Indeed CRFhas been established by many as the state-of-the-art supervised named entity recognition system fortraditional NER tasks (Feng and McCallum 2004;McCallum 2003), for NER in biomedical texts (Set-tles 2004), and in various languages besides English,such as Bengali (Ekbal et al 2008) and Chinese(Mao et al2008).
Various modifications to CRFhave recently been introduced to take into accountof non-local dependencies (Krishnan and Manning2006) or broader context beyond training data (Duet al 2010).4.2 Experimental ResultsIn this section, we compare the generative modelbased and discriminative model classifiers for super-vised NER tasks.
Given 1, 000 manually tagged list-ings from the clothing and shoes category in eBay,we adopt a 90-10 split and use 90% of the data fortraining and 10% for testing.
Each listing title is to-kenized into a sequence of word tokens, each manu-SVM MaxEnt HMM CRFw/o Viterbi 89.05% 87.64% - -w/ Viterbi 89.47% 88.13% 83.82 93.35%Table 2: Classification accuracy (%) on 9-class NER onmen?s clothing dataset, comparing SVM, MaxEnt, super-vised HMM, and CRF.ally assigned to one of the 5 tags: brand (B), size(S), color (C), garment type (G), and none of theabove (NA).
In order to more accurately capture theboundary of multi-token attribute values, we furthersub-divide each tag into 2 classes using -beg and -insub-tags.
This step increases the number of classesthat our classifier needs to handle from 5 to 9 classesgiven as follows: {B-beg, B-in, C-beg, C-in, S-beg,S-in, G-beg, G-in, and NA}.Table 2 shows a comparison of classification ac-curacy from 4 classifiers ?
SVM, MaxEnt, HMM,and CRF.
Supervised HMM, with the most simplis-tic feature, yields the baseline result at 83.82% accu-racy.
All the discriminative classifiers ?
CRF, Max-Ent, and SVM ?
outperform the baseline by HMM,with CRF improving on the baseline performance bythe largest margin, concurring to other reports of itsstate-of-the-art results.
Indeed, when using exactlythe same set of features as SVM and MaxEnt, theperformance of CRF indeed drops to 89.11%, whichis on par with that of SVM and MaxEnt.
However,when restricting to using dictionary and word iden-tity features, the performance of CRF improves, in-dicating the importance of feature selection to suchmodel.
SVM and MaxEnt yield similar performancewith SVM slightly outperforming MaxEnt classifierby 1.6%.
The incorporation of temporal smoothnessconstraint enforced by the Viterbi algorithm slightlyimproves the label sequence prediction (comparingrow 1 and row 2 in Table 2).The HMM implementation used in our experi-ments is the Hunpos tagger in (Halacsy et al 2007),which captures the state transitional probabilities us-ing second-order Markov model.
For SVM, we usethe popular libSVM package (Chang and Lin 2001)which produces probabilistic output from fitting asigmoid function to the distances between samplesand the separating hyperplane.
We use linear kernelin our experiments, although RBF kernel with gridsearch for optimal parameters yield slightly superior1562performance, with a significantly higher computa-tional cost.
The MaxEnt implementation used in ourexperiment is the version available from the NLTKtoolkit, with BFGS optimizer.
For CRF, we use thelinear-chain CRF model available from the Malletpackage1.5 Bootstrapping for Dictionary ExpansionThe supervised learning approach assumes the ex-istence of an annotated set of training data.
Oftentimes, training data must be painstakingly markedup and collecting large-scale labeled training exam-ples can be very costly.
In recent years, more andmore research effort has been focused on how toleverage a vast amount of unlabeled data in a semi-supervised or entirely unsupervised fashion for NERas well as for other similar NLP tasks, e.g.
POStagging, sentence boundary detection, and wordsense disambiguation (Riloff 1999; Ghani and Jones2002; Probst et al 2006; Brody and Elhadad 2010;Haghighi 2010).One way to incorporate a vast amount of unla-beled data is to learn a clustering of words that as-signs syntactically similar words to the same clus-ters.
Popular clustering algorithms used prevalentlyin many NER systems are, for example, the combi-nation of distributional and morphological similar-ity work of (Clark 2003) or the classic N -gram lan-guage model based clustering algorithm of (Brownet al 1992).
In such a system, when training anNER classifier, we introduce a word cluster id as anadditional feature in the input, with the hope that themodel will pick out clusters that are highly indica-tive of each class.
When encountering words thatare out-of-vocabulary (OOV) in the test set, if thosewords are assigned the same cluster membership assome other words in the training set, the cluster fea-ture will fire, allowing for correct classification re-sults to be obtained (Lin and Wu 2009; Faruqui andPado 2010).5.1 Growing Seed DictionaryIn this work, we focus on the problem of how togrow the seed dictionary and discovering new brandnames from eBay listing data.
While the perfor-mances of supervised NER classifiers as describedin sections 4.1.1-4.1.5 are satisfactory, in practice,1http://mallet.cs.umass.edu/however, especially with a small training set size,we often find that the trained model puts too muchweight on the dictionary membership feature andnew attribute values are not properly detected.
Inthis section, instead of using the seed list of knownattribute values as a feature into a classifier, weuse the seed values to automatically generate la-beled training data.
For the specific case of branddiscovery, this initial list used to generate trainingdata must contain only names that are unambigu-ously brands.
We hence remove ambiguous namesor phrases that belong to multiple attribute typesfrom the list, such as jumpers(both a brand nameand a garment type), or (ii) camel is a short nameof brand Camel active as well as a color, or (iii) lrgis an acronym for a brand as well as an acronym forlarge which specifies size.The training/test data is generated by matchingN -gram tokens in listing titles to all the entries inthe initial brand seed dictionary.
Following the con-vention in (Minkov et al 2005), we use the follow-ing set of 5 tags, (1) one-token entity (B1 tag) (2)first token of a multi-token entity (Bo tag for Brand-open) (3) last token of a multi-token entity (Bc tagfor Brand-close) (4) middle token of a multi-tokenentity (Bi tag for Brand-inside) (5) token that is notpart of a brand entity (NA tag).
The listings withat least one non-NA tags are put in the training set,and listings that contain only NA tags are in the testset.
Similar to the acronym expansion algorithm of(Pakhomov 2002) which learns contexts that asso-ciate acronyms to their correct expansions, the in-tuition behind our work in this section is that theclassifier, trained on a labeled training set of knownbrands, learns context patterns that can discriminatethe current word as being a brand (more precisely aspart of a brand) from the other attribute types, whichare now lumped together as NA.5.2 ExperimentsIn the first experiment, a set of 72, 628 listings fromthe women?s clothing category is partitioned into atraining set of 39, 448 listings and test set of 33, 180listings based on an initial seed list of known 6, 312women?s apparel brands manually prepared by ourfashion experts.
The partitioning is done, as de-scribed in great detail above, in such a way thatknown brands in the seed list do not exist in the1563Women?s Clothing Men?s Clothing Garment Type?monsoon?
henley?s nightshirtriverislandtop abercrombie&fitch cargoshortsdorothyperkins lacost trenchcoatriver islanfd versace sweatpantsmarks&spencers sonnetti cardigansriver islands supremebeing boardshortsriver islan brookhaven tracksuitemonsoomn guiness swimshortsdorothry perkins ?next?
trousesprinciple suprerdry microfleece?river island henbury boilersuitbnwtmonsoon paul smiths snopantsmarella ricci pjssoulcal craghopper jktTable 3: Discovered attribute values, ranked order bytheir confidence scores.
(Left) Discovered brands fromWomen?s clothing category.
We use 6,312 brands as seedvalues.
(Middle) Discovered brands from Men?s clothingcategory, with 3,499 seed values used.
(Right) Discov-ered garment types (styles) from Men?s clothing category,learned from 203 seed values.test data (using exact string matching criterion).
Wetrain a 5-class MaxEnt classifier and adopt the samefeature sets as described in Section 4.1.3.
Duringthe test phase, the classifier predicts the most likelybrand attribute from each listing, where we are onlyinterested in the predictions with confidence scoresexceeding a set threshold.
We ranked order the pre-dicted brands by their confidence scores (probabil-ities) and the top 300 unique brands are selected.We manually verify the 300 predicted brands andfound that 90.33% of the predicted brands are indeednames of designers or women?s apparel stores (truepositive), resulting a precision score of 90.33%.Indeed, the precision score presented above is ob-tained using an exact matching criterion where par-tial extraction of a brand is regarded as a miss, i.e.our extractor extracts only Calvin when Calvin Kleinis present in the listing (false positive).
The left col-umn of Table 3 shows examples of newly discoveredbrands from Women?s clothing category.
Many ofthese newly discovered brands are indeed misspelledversions of the known brands in the seed dictionary.The middle column of Table 3 shows a set ofMen?s clothing brands learned automatically from asimilar experiment conducted on a set of 105, 335listings from Men?s clothing category.
Using an ini-Seed list Test set 1 Test set 2Orig.
seeds 83.56% 90.02%Orig.
seed + 200 new brands 92.75% 93.66%Table 4: NER Accuracy on 2 test sets as the seed dictio-nary for brands grows.
Results shown here are obtainedthe same Men?s clothing category dataset, as used to showthe supervised NER results in Table 2.tial set of 3, 499 known brand seeds, we partitionthe dataset into a training set of 67, 307 listings anda test set of 38, 028 listings (for later reference werefer to this test set as set A).
Based on the top 200predicted brands, 179 of which are verified as beingtrue positive samples, resulting in 89.5% precision.We carry out a similar experiment to grow the seeddictionary for garment type, and are able to iden-tify the top 60 new garment types.
54 out of 60 aretrue positive samples, resulting in precision score =90%.
Examples of the newly discovered garmenttypes are shown in Table 3 (right column), where ab-breviated forms of garment types such as jkt (shortfor jacket) and pjs (short for pajamas) are also dis-covered through our algorithm.By adding these newly discovered attributes backto the dictionary, we can now re-evaluate our super-vised NER system from section 4 with the grownseed list.
To this end, we construct 2 test sets fromthe same 105, 335 listings of Men?s clothing cate-gory as used in Section 4.
Test set 1 is a set of500 listings randomly sampled from the 38, 028-listing subset known not to contain any brands inthe original brand seed dictionary (set A).
As seenin Table 4, an improvement of 9% in accuracy re-sults from the use of the grown seed list.
Sincethis dataset is known to not contain any brands fromthe original brand seed dictionary, the addition of200 new brands solely accounts for all the accuracyboost.
Test set 2 is constructed slightly differentlyby randomly sampling 500 listings from the entire105, 335 listings of Men?s clothing category.
Asseen in Table 4, a smaller improvement of 3.7% isobserved.6 NormalizationWith the above described brand discovery algorithm,the newly discovered brands from the test set can begrouped into 2 categories ?
(i) misspelling, spelling1564invariants, abbreviated forms of known brands in theseed list or (ii) novel brands or clothing/shoes de-signers, which are not members of the original seedlist.
Normalizing the variants of a known brand toa single normalized output value is an important as-pect of our attribute extraction algorithm, as thesevariants account for over 20% of listings in the eBayclothing and shoes category.
When gathering busi-ness/marketing intelligence, missing out on 20% ofthe data could skew the calculation of supply, de-mand, and pricing metrics, and eventually lead tothe wrong policy decision made.The problem of alternate spellings of names hasbeen addressed in the database community success-fully using fuzzy string matching algorithms e.g.Soundex or string edit distance.
In this work, sincethe attribute values are often partially extracted, i.e.a word in a multi-word phrase is extracted, in or-der to match to the correct normalized value, wemust investigate robust substring matching algo-rithms suitable for partial matching.
To this end,we explore 2 string similarity/distance measures fornormalizing the extracted attributes.
First, we in-vestigate n-gram similarity measures defined as thenumber of shared character n-grams, i.e.
substringsof length n (Kondrak 2005).
More specifically, astring similarity measure between s1 and s2 is de-fined as the percentage of common substrings oflength n (out of all substrings of length n).
Thissimilarity measure is quite robust to partial match-ing, as a two-word phrase can appear out of orderwhile most of the character n-grams, where n = 3,remain virtually unchanged.
Certainly, finding theright value of n will greatly impact the matching per-formance of the algorithm.
In our experiment, wefind the optimal n for brands to be 3 and 4.
Table 5shows a few examples of normalized outputs as a re-sult of finding the best match for the extracted brandnames from among a set of predefined normalizedvalues.
When the best matching score falls below athreshold, we declare no match is found and classifythe extracted brand as a new brand.Another distance measure that we explore is theJaro-Winkler distance.
Designed to be more suitablefor matching short strings such as people?s names,Jaro-Winkler distance is defined based on the num-ber of character transpositions and the number ofmatching characters.
In addition, a prefix scale pExtracted brands Normalized valuesriver islands river islandfruit of loom fruit of the loomfruit loom fruit of the loom?ralph lauren ralph laurenmark & spencer marks & spenceryvessaintlaurent yves saint laurentyves st laurent yves saint laurentcombats combat?kickers?
kickerskickers kickersarmarni armaniabrecrombie abercrombielife & limb NEW BRANDoliver baker NEW BRANDhaines & bonner NEW BRANDdehavilland NEW BRANDnigel cabourn NEW BRANDTable 5: Extracted brands and their corresponding nor-malized values.parameter is used and can be tuned to weigh morefavorably on strings that match from the beginningfor a set prefix length.
In our experiments with brandnormalization, over 50% of the matches from theJaro-Winkler distance are, however, identified as be-ing incorrect.7 ConclusionIn this work, we have described an information ex-traction system for applications in the domain of in-ventory/business Intelligence.
The goal is given aneBay listing title, our system correctly extracts thedefining attributes in order to associate each item toa specific product.
We investigate and compare sev-eral supervised NER systems ?
supervised HMM,SVM, MaxEnt, and CRF ?
and found SVM andMaxEnt with Viterbi decoding to yield the best per-formance.
Focusing on the clothing and shoes cat-egories on eBay?s site, we presented a bootstrappedalgorithm that can identify new brand names corre-sponding to (1) spelling invariants or typographicalerrors of the known brands in the seed list and (2)novel brands or designers.
Our attribute extractorcorrectly discovers new brands with over 90% pre-cision on multiple corpora of listings.
To output nor-malized attribute values, we explore several fuzzystring comparison algorithms and found n-gram sub-string matching to work well in practice.15658 AcknowledgmentThe authors would like to thank Nalini Johnas andPadmanaban Ramasamy for their help in gatheringlisting data used in all of our experiments.ReferencesA.
Berger, S. Pietra, V. Pietra, A Maximum Entropy Ap-proach to Natural Language Processing, ACL 1996.S.
Brody, N. Elhadad, An Unsupervised Aspect-SentimentModel for Online Reviews, HLT-NAACL 2010.P.
Brown, P. deSouza, R. Mercer, V. Della Pietra, J.Lai, Class-based n-gram Models of Natural Language,ACL 1992.C.-C Chang, C.-J.
Lin, LibSVM: A Library for SupportVector Machines (2001).H.
L. Chieu, H. T. Ng, Named Entity Recognition with aMaximum Entropy Approach, ACL 2003.A.
Clark, Combining Distributional and MorphologicalInformation for Part of Speech Induction, EACL 2003G.
Demartini, C. S. Firan, M. Georgescu, T. Iofciu, R.Krestel, and W. Nejdl, An Architecture for Finding En-tities on the web, Latin American Web Congress 2009.J.
Du, Z. Zhang, J. Yan, Y. Cui, and Z. Chen.
Usingsearch session context for named entity recognition inquery.
In SIGIR10, Geneva, Switzerland, July 19-232010.Asif Ekbal, Rejwanul Haque, and Sivaji Bandyopadhyay.2008.
Named entity recognition in Bengali: A condi-tional random field approach.
In Proceedings of IJC-NLP, pages 589594.M.
Faruqui, S. Pado, Training and Evaluating a GermanNamed Entity Recognizer with Semantic Generaliza-tion, Proceedings of Konvens 2010, Saarbrucken, Ger-many.F.
Feng, A. McCallum, Chinese segmentation and newword detection using conditional random fields, inCOLING 2004.J.
R. Finkel, T. Grenager, and C. Manning, Incorporat-ing Non-local Information into Information ExtractionSystems by Gibbs Sampling, ACL 2005.J.
R. Finkel, C. Manning, Nested Named Entity Recogni-tion, EMNLP 2009.R.
Ghani, K. Probst, Y. Liu, M. Krema, A. Fano, TextMining for Product Attribute Extraction, SIGKDD,2006.R.
Ghani, R. Jones, A comparison of efficacy and as-sumptions of bootstrapping algorithms for traininginformation extraction systems, Workshop on Lin-guistic Knowledge Acquisition and Representation atthe Third International Conference on Language Re-sources and Evaluation (LREC), 2002.T.
Grenager, D. Klein, and C. D. Manning, UnsupervisedLearning of Field Segmentation Models for Informa-tion Extraction, ACL 2005.D.
Gruhl, M. Nagarajan, J. Pieper, C. Robson, and A.Sheth.
Context and Domain Knowledge Enhanced En-tity Spotting In Informal Text.
In Proceedings of the 8thInternational Semantic Web Conference (ISWC 2009).Springer, 2009.A.
D. Haghighi, Unsupervised Models of Entity Refer-ence Resolution, Ph.
D. Thesis, University of Calfor-nia, Berkeley, 2010.P.
Halacsy, A. Kornai, C. Oravecz, HunPos: an opensource trigram tagger, ACL 2007.H.
Isozaki and H. Kazawa, Efficient Support Vector Clas-sifiers for Named Entity Recognition, ACL 2002.R.
Jones, Learning to Extract Entities from Labeled andUnlabeled Text, PhD Thesis, 2005.I.
Kanaris, K. Kanaris, I. Houvardas, E. Stamatatos,Words vs.
Character N-grams for Anti-spam Filtering,International Journal on Artificial Intelligence Tools,2006.D.
Klein, J. Smarr, H. Nguyen, C. Manning, Named En-tity Recognition with Character-level Models, CoNLL2003.R.
Koeling, Chunking with Maximum Entropy Models,Proc.
of CoNLL-2000.G.
Kondrak, N-Gram Similarity and Distance, SPIRE2005.V.
Krishnan and C. D. Manning, An effective two-stagemodel for exploiting non-local dependencies in namedentity recognition, in ACL-COLING, 2006.T.
Kudo, Y. Matsumoto, Chunking with Support VectorMachines, ACL 2001.J.
Lafferty, A. McCallum, F. Pereira, Conditional Ran-dom Fields: Probabilistic Models for Segmenting andLabeling Sequence Data, ICML 2002.V.
I. Levenshtein, Binary code capable of correcting dele-tions, insertions, and reversals.
Phs.
Dokl., 6:707-710.D.
Lin, X. Wu, Phrase Clustering for DiscriminativeLearning, ACL 2009.B.
Liu, M. Hu, and J. Cheng, Opinion Observer: Ana-lyzing and Comparing Opinions on the Web, WWW2005.Xinnian Mao, Saike He, Sencheng Bao, Yuan Dong,and Haila Wang, Chinese Word Segmentation andNamed Entity Recognition Based on Conditional Ran-dom Fields, Sixth SIGHAN Workshop on ChineseLanguage Processing, 2008A.
McCallum, Efficiently Inducing Features of Condi-tional Random Fields, UAI 2003.A.
McCallum, D. Jensen, A Note on Unificationof Information Extraction and Data Mining usingConditional-Probability, Relational Models, Proceed-ings of IJCAI-2003 on Learning Statistical Modelsfrom Relational Data, 2003.1566J.
F. McCarthy, A Trainable Approach to CoreferenceResolution for Information Extraction, Ph.
D. Thesis,University of Massachusetts at Amherst, 1996.E.
Minkov, R. C. Wang, and W. W. Cohen, ExtractingPersonal Names from Email: Applying Named EntityRecognition to Informal Text, ACL 2005.Mike Mintz, Steven Bills, Rion Snow, Daniel Juraf-sky.
2009.
Distant Supervision for Relation Extractionwithout Labeled Data, In Proceedings of ACL/AFNLP2009.S.
Moghaddam, M. Ester, Opinion Digger: An Unsuper-vised Opinion Miner from Unstructured Product Re-views, CIKM 2010David Nadeau, P. Turney, S.Matwin, UnsupervisedNamed Entity Recognition: Generating Gazetteersand Resolving Ambiguity.
In Proc.
Canadian Confer-ence on Artificial Intelligence, 2006.David Nadeau and Satoshi Sekine.
A survey of named en-tity recognition and classification.
Linguisticae Inves-tigationes, 30(1):326, 2007.Nadeau, D., Semi-Supervised Named Entity Recognition:Learning to Recognize 100 Entity Types with Little Su-pervision, PhD thesis, University of Ottawa, 2007.S.
Pakhomov, Semi-supervised Maximum Entropy BasedApproach to Acronym and Abbreviation Normalizationin Medical Texts, ACL 2002.A.-M. Popescu, O. Etzioni, Extracting Product Featuresand Opinions from Reviews, EMNLP 2005.K.
Probst, R. Ghani, M. Krema, A. Fano, Semi-Supervised Learning to Extract Attribute-Value Pairsfrom Product Descriptions on the Web, ECML 2006.V.
Punyakanok, D. Roth, The use of classifiers in sequen-tial inference, NIPS 2001.H.
Raghavan, J. Allan, Matching Inconsistently SpelledNames in Automatic Speech Recognizer Output for In-formation Retrieval, HLT-EMNLP 2005.A.
Ratnaparkhi, A Maximum Entropy Part of Speech Tag-ger.
In EMNLP 1996.A.
Ratnaparkhi, Maximum Entropy Models forNaturalLanguage Ambiguity Resolution, Ph.
D. Thesis, Uni-versity of Pennsylvania.E.
Riloff, R. Jones, Learning Dictionaries for Informa-tion Extraction by Multi-Level Bootstrapping, AAAI1999.Settles, B.
(2004), Biomedical named entity recognitionusing conditional random fields and rich feature sets,in Proceedings of the International Joint Workshop onNatural Language Processing in Biomedicine and itsApplications (NLPBA), 2004, Geneva, Switzerland.W.
M. Soon, H. T. Ng, D. Chung, Y. Lim, A machinelearning approach to coreference resolution of nounphrases, Computational Linguistics, 27(4): 521-544,2001.H.
Wallach, Efficient Training of Conditional RandomFields, M. Sc.
Thesis, Division of Informatics, Uni-versity of Edinburgh, 2002.D.
Wu, W. S. Lee, N. Ye, and H. L. Chieu, Domainadaptive bootstrapping for named entity recognition,EMNLP 2009.Y.
Zhao, B. Qin, S. Hu, T. Liu, Generalizing SyntacticStructures for Product Attribute Candidate Extraction,ACL 20101567
