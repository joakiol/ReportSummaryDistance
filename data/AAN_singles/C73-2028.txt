WaRPa~N J. t'~ATHT1LANSFORMATIONAL G1LAMMAI:k AND TKANSFORMA-TIONAL PARSING IN THE REQUEST SYSTEM1.
INTRODUCTIONThe REQUEST (Restricted English Question-answering) System isan experimental natural language query system currently under devel-opment at the n3M Thomas J. Watson Research Center.
The generalobjective of this work is to explore the feasibility of using restrictedsubsets of natural language (in this case, English) as the basis for effec-tive man-computer communication, with particular emphasis on theproblem of making data-base-oriented s rvices readily available to non-programmer users.
Our initial implementation f R~QUEST (describedhere and in a companion paper by S. R. P~TRICK, in the I volume)addresses the data-base communication problem with reference to thespecific world of business statistics, as exemplified by the summary datapublished annually in the "Fortune 500"An essential feature of the language processing approach embodiedin the REQUEST System is the employment of a very general transfor-mational parsing algorithm and a large, explicitly formulated transfor-mational grammar in order to produce semantically interpretable un-derlying structures of input sentences (questions and commands).l~qu~sT thus differs markedly from such well-known systems as thoseof F. B. T~OlVIPSON (1973) (direct semantic interpretation of surfacestructures), W. A.
WOODS (1972) (representation of grammatical infor-mation and parsing strategy in augmented transition etworks), andT.
WINOGRAD (1972) (direct incorporation of grammatical informationwithin the parsing program).
Furthermore, the underlying structuresassigned by our current grammar do considerably more than merelycapturing a few relatively superficial syntactic generalizations such asthe relationship between active sentences and corresponding passives:they are significantly more abstract than the deep structures ofN.
CHOlVl-SKY'S Aspects (1965) and go a long way towards explicit representation368 WAR~N J. PI~ATI-Iof the meanings of sentences in a notation that bears certain strong re-semblances to the predicate calculus.
Among the motivations for ourchoice of approach are 1) the advantages ofa transformational model asa vehicle for capturing significant linguistic generalizations, 2) the rela-tive case of interpretation of our abstract underlying structures, and3) the perspicuity of a system organization which separates data fromalgorithms and represents linguistic rules direcdy as units, rather thanas discontinuous elements hat are distributed over networks or programs.2.
OVERALL SYSTEM ORGANIZATIONThe current version of the REQUEST System consists of a set of pro-grams written in Lisp 1.5, together with an associated set of data filescontaining the lexicon, grammar, semantic interpretation rules, anddata base.
The system runs interactively on a System/360 Model 67under CV\]cMs in 768K of virtual core.
As shown in Fig.
1, the trans-formational component of the system, whose function it is to analyzeinput word strings and compute their meanings (i.e., underlying struc-tures) consists of two main parts: a preprocessor and a parser.
The in-terpretive component of the system also has two parts: (i) a semanticinterpreter, which translates those meanings into executable code; and(ii) a retrieval component consisting of data accessing and formattingfunctions invoked by the semantic interpreter in order to complete thequestion-answering process.
The present paper deals predominantlywith linguistic and computational spects of the preprocessing andparsing phases, while Petrick's paper covers the details of semanticinterpretation and retrieval.The role of the preprocessor is to segment the input string into wordsand punctuation marks and then look up each segment in the lexicon,producing a preprocessed string of lexical trees which serves as input tothe parser.
Multi-word strings that function as lexical units are identifiedby lookup in a special phrase lexicon; while arabic numerals represent-ing cardinals, ordinals, and dates are supplied with lexical trees algo-rithmically rather than by matching against the lexicon.
In cases wherethe information i  the preprocessed string is inadequate, due to the pres-ence of misspellings, unknown words, ambiguous pronoun references,and the like, the preprocessor p ompts the user to supply the requiredinformation.TRANSFORMATIONAL GRAMMAR AND TRANSFORMATIONAL PARSING 369fffff (1!
!I TRANSVOR-\[ MA TIONALI COMPONENTII1I1IIIIIIII INTERPRETIVECOMPONENTIIIi11/fl Input WordStringPREPROCESSORStrhlgPARSERUnderlxing~ Str.cture(s)SEMANTIC ~ k -- - - INTERPRETER% Execlttable \Code \(Logical Form) XRETRIEVALI\[ ~ ~ -- - ~ @I Output _.1Fig.
1.
Overall System Organization.24370 WARREN J. PLATHOperation of the parser 1 proceeds in two stages: first, the rules of acontext-free surface structure grammar are applied to the preprocessedstring by a phrase structure parser in order to compute the surfacestructure of the sentence.
(Because of the well-known inadequacy ofpure phrase-structure systems in providing unambiguous surface anal-yses of sentences (S. KUNO, A. G. OETTINGER, 1963), it is oftenthe case that several structures are assigned).
Next, the transfor-mational parser processes each surface structure in turn, attempting:to map it step-by-step into a corresponding underlying structure.In this?rocess, the parser employs a set of transformational inverseswhich it applies in precisely the opposite order from that in whichthe "forward" counterparts of the same transformations would beemployed in sentence generation: inverses of the postcyclic transfor-mations are applied first, starting with the "latest" and ending withthe "earliest "; then the inverses of the cyclic transformations are ap-plied (also in last-to-first order) working down the tree from the leastdeeply embedded (main) clause to those that are most deeply embedded.The parser can check the validity of the inverse transformational der-ivation at each point by testing the corresponding forward transfor-mation to make sure a) that (if obligatory) it does not apply to the cur-rent tree if its inverse failed to apply and b) that it does apply if the in-verse applied (and in fact precisely undoes the effect of applying theinverse).
This mode of operation is particularly useful for debuggingpurposes.In the course of transformational p rsing, most of the spurious ur-face structures are rejected very quickly by special blocking rules whichemploy transformational pattern matching to filter out ill-formedconfigurations ot detectable by a context-free phrase structure mech-anism.
In the experiments we have carried out to date, it has almostuniformly been our experience that precisely one underlying structureis assigned to each sentence xcept in cases where a) there is genuinesemantic ambiguity or b) a sentence outside the current coverage ofthe transformational grammar has been entered into the system.
Atleast some of this initial success in disambiguation is due to a policy ofmaking certain transformations sensitive to semantic as well as syntacticinformation.1 The original design and implementation f the parser is due to S.R.
PETRICK (1973)More recently, it has been significantly revised and extended by M. Pivovonsky, who(with the help of E. O. Lippmann) has also been chiefly responsible for implementationof the preprocessor.
"TRANSFORMATIONAL GRAMMAR AND TRANSFORMATIONAL PARSING 3713.
AN EXAMPLEIn order to illustrate how the REQUEST System uses transformationalparsing to compute the underlying structures of input sentences, letus follow the processing of a typical query step by step.
At the startof the session (Fig.
2) the system prompts the user by typing out themessage " QUESTION?
", and the user responds by typing in "Whatwas GM's gross income for 1970?
".
At this point, the preprocessorsegments the input string into a sequence of words and punctuationmarks which is checked against the phrase lexicon to detect the presenceof any multiword lexical strings that should be treated as units.
Theresult of this process - consisting of a serially-numbered list comprisingwords, multi-word units, and punctuation marks - is typed out at theterminal to confirm receipt of the query.
As can be seen from Fig.
2,the input sequence " gross income" has been identified as a single unit" GP, OSS-INCOME " on the basis of lookup in the phrase lexicon.
(Had the user typed in " General Motors " or " G. M. " instead of" GM ", these strings would also have been handled in the samefashion.
)QUESTION?What was GM's gross income for 1970?WHAT(l) WAS(2) GM(3)'S (4) GROSS_INCOME(5) FOR(6) 1970(7) ?
(8)PR.EPROCESSING OUTPUT:((WHAT (OR (VADJ (+ ADJ + QUANT) WH SOME)(NP (NOM (V (+ ADJ + QUANT) WH SOME)(NOM (NOUN (-HUMAN + SG) (V THING)(INDEX (-CONST) Xl )))))))(WAS (AUK (+ PAST + SG) BE))(GM (NPROPNOM (NOUN (-HUMAN + SG) (INDEX (+ CONST + CO) GM))))('S (GENAF 'S)(GROSS-INCOME(NMNL (-HUMAN + SG + Q NOUN + ARG1 + PERIODIC + NMNL)(V (+ POSS2) AMOUNT MONEY GROSS)(INDEX (- CONST) X5)))(FOR.
(PREP FOR.
)(1970) (PR.OPNOM (NOUN (-HUMAN + SG + TIME) (INDEX (+ CONST + YEAR) 1970))))(?
(PUNCT (+ QUES) ? ))
)Fig.
2, Input and Processing Output for a Typical Query.372 wAm~m,l j. PLATHThe next action of the preprocessor is to look up each of the num-bered items in the lexicon.
Absence of a given item from the lexiconmay stem either from an actual gap in lexical coverage or from an inputtyping error on the part of the user.
In such cases the user is promptedto retype the offending item, but can also drop the entire question andstart again if he so chooses.
Since there are no errors or missing wordsin our current example, however, the preprocessor is able to completethe entire lookup successfully without calling upon the user for correc-tive action.The final output of the preprocessing phase (Fig.
2) is an orderedlist of dictionary entries, each consisting of art entry key paired with anassociated tree (or disjunction of trees) represented as a parenthesizedstring.
The basic notational convention used in our tree representationis that an expression of the form (A((+)FEATI {+)FEAT2...{ +)FEA Tn) B C) stands for a tree of the form:A((_C_+)FEArl (+) F2 Ar2...
(+)FEAr.
)/ \B Cwhere A, B and C are nodes and FEAT1 ... FEATn are syntactic orsemantic features.As an examination of the preprocessing output of Fig.
2 shows,the lexicon is designed in such a way that the process of substitutinglexical trees for corresponding input items results in making numerouslocal changes in the input string - changes which take it as far as pos-sible, at this early stage, along the way towards underlying structure(J. j. lkomNsoN, 1973).
Thus, on the one hand, all inflected itemsare replaced by stems whose part-of-speech nodes carry the corre-sponding tense and number information in the form of syntacticfeatures, along with a variety of semantic features.
Furthermore,common nouns such as "gross income" are already interpretedas combinations of underlying predicates (V) and variables (INDEX(-CONST)) in anticipation of the way they are represented in under-lying structure.
(The specific values of index variables, such as the"X1 " and "X5 " in Fig.
2, are used to keep track of matters ofreference in more complicated sentences by having the preprocessorassign identical variables to pronouns and their antecedents.
No suchcomplexity arises here, however, and the preprocessor simply employsthe word number of each common noun in manufacturing a uniqueTRANSFORMATIONAL GRAMMAR AND TRANSFORMATIONAL PARSING 373variable name.)
In addition, proper nouns, such as " 1970" and" GM ", are treated as logical constants (INDEX (+ CONST))which belong to particular semantic classes - in this case those ofyear names (+ YEAR) and company names (+ CO).Once specification of the preprocessed string is complete, controlpasses to the parser, whose first task is to attempt o assign a surfacestructure to the preprocessed string.
The parser makes use of a context-free surface grammar and standard phrase structure parsing techniquesin attempting to connect he sequence of lexical trees into a coherentsurface structure tree (actually as many such trees as the rules will allow).In this case three distinct surface structures are produced, as indicatedby the bracketed terminal strings displayed at the top of Fig.
3.
Theonly difference in the three surface analyses lies in the treatment of thestring "for 1970 ": In analysis (1) it is (correctly) treated as a postmod-i fief of "gross earnings " - now represented in standardized form as((AMOUNT MONEY GROSS) XS); in (2) the string is broken up,with " fo r "  treated as a stranded preposition postmodifying "grossearnings " and " 1970 " treated as a major noun phrase constituent ofthe sentence (e.g., as in " What year are those the figures for - 1970? ")
;while the third analysis again treats "for 1970" as a prepositionalphrase unit, but this time as a major constituent of the sentence ratherthan as a postmodifier of "gross earnings "Control now passes to the transformational parser, which takes eachsurface structure in turn (in last-to-first order) and attempts to map itstep by step into a corresponding underlying structure through thesystematic application of inverse transformations.
As shown in Fig.
3,analyses (3) and (2) are rapidly eliminated through the application of theblocking transformations TCMPDBLK (" time compound blocking ")and PRPBLOCK (" (stranded) preposition blocking "), respectively.TCMPDBLK exemplifies the interaction of syntactic and semanticinformation in the transformational component of the REQUEST Sys-tem, in that it filters out a variety of otherwise acceptable structures inwhich a noun phrase or prepositional phrase with head noun marked(+ TIME) is adjacent o a noun phrase with head noun marked (+PERIODIC), but where the former is not analyzed as a modifier ofthe latter.
PRPBLOCK simply eliminates analyses where a putativestranded preposition immediately precedes a nominal expression.The parser now proceeds to work on analysis (1), starting out byapplying inverse postcyclic transformations that eliminate terminalpunctuation (continuation 1.1) and genitive aftixes (continuation 1.2),QUESTION?What was GM's gross income for 19701WHAT(l) WAS(2) GM(3) 'S(4) GROSS INCOME(5) FOR(6) 1970(7) ?
(S)SUP.FACE STRUCTURES:1.
(((WH SOME) (THING X1)) BE ((GM 'S) (((AMOUNT MONEY GROSS) X5) (FOR 1970))) 1)2.
(((WH SOME) (THING X1)) BE ((GM 'S) (((AMOUNT MONEY GROSS) X5) FOR)) 1970 1)3.
(((WH SOME) (THING X1)) BE ((GM 'S) ((AMOUNT MONEY GROSS) X5)) (FOR 1970) 1)SENTENCE 3:(((WH SOME) (THING Xl)) ((GM' S) ((AMOUNT MONEY GP.OSS) X5)) (POP.
1970) 1)FORWARD TCMPDBLK APPLICABLE.
NO CONTINUATIONSENTENCE 2:(((WH SOME) (THING X1)) BE ((GM 'S) (((AMOUNT MONEY GROSS) XS) FOR)) 1970 ?
)FORWARD PRPBLOCK APPLICABLE.
NO CONTINUATIONSENTENCE 1:(((WH SOME) (THING Xl)) BE ((GM 'S) (((AMOUNT MONEY GROSS) X5) (FOP.
1970))) ?
)SPNCTINS APPLIED.
GO TO CONTINUATION 1.1CONTINUATION 1.1 :(((WH SOME) (THING Xl)) BE ((GM 'S) (((AMOUNT MONEY GtkOSS) XS) (FOIk 1970))))GENINFL APPLIED.
GO TO CONTINUATION 1.2CONTINUATION 1.2:(((WH SOME) (THING X1)) BE (GM (((AMOUNT MONEY GROSS) X5) (FOR 1970))))WHERASE APPLIED.
GO TO CONTINUATION 1.3CONTINUATION 1.3:(((WH SOME)(THING Xl)) BE (GM (((AMOUNT MONEY GROSS) X5) (FOR 1970))))INFOR APPLIED.
GO TO CONTINUATION 1.4CONTINUATION 1.4:(((WH SOME) (THING X1)) BE (GM (((AMOUNT MONEY GROSS)X5) (IN 1970))))WHATPRNT APPLIED.
GO TO CONTINUATION 1.5CONTINUATION 1.5(BE (GM (((AMOUNT MONEY GROSS) X5) (IN 1970))) ((WH SOME) (THING Xl)))PREPINS APPLIED.
GO TO CONTINUATION 1.6CONTINUATION 1,6:(BE (GM (((AMOUNT MONEY GROSS) XS) 1970)) ((WH SOME) (THING Xi)))WHATFORM APPLIED.
GO TO CONTINUATION 1.7CONTINUATION 1.7:(BE (GM (((AMOUNT MONEY GROSS) XS) 1970)) ((WH SOME) (AMOUNT X1)))WHATNUMA APPLIED.
GO TO CONTINUATION 1.8CONTINUATION 1.8:(BE (GM (((AMOUNT MONEY GROSS) X5) 1970)) (h (((WH SOME) LARGE) (AMOUNT Xl))))QUWHMARK APPLIED.
GO TO CONTINUATION 1.9CONTINUATION 1.9:(BE (GM (((AMOUNT MONEY GROSS) X5) 1970)) (A (((WH SOME) LARGE) (AMOUNT Xl))))ERASEBDS APPLIED.
GO TO CONTINUATION 1.10CONTINUATION 1.!0:(BD BE (GM (((AMOUNT MONEY GROSS) X5) 1970)) (A (((WH SOME)LARGE) (AMOUNT Xl))) BD)IDEQUDEL APPLIED.
GO TO CONTINUATION 1.11CONTINUATION 1.11:(BD BE EQUAL (GM (((AMOUNT MONEY GROSS) IS) 1970)) (A (((WH SOME) LARGE) (AMOUNTxl))) BD)AUXlNUMA APPLIED.
GO TO CONTINUATION 1.12CONTINUATION 1.12:(BD EQUAL (GM (((AMOUNT MONEY GROSS) X5) 1970)) C A (((WH SOME) LARGE) (AMOUNTXl))) BD)PRUNES APPLIED.
GO TO CONTINUATION 1.13CONTINUATION 1.13:(BD EQUAL (GM (((AMOUNT MONEY GROSS) X5) (?
1970 ~))) (A (((WH SOME )LARGE) (AMOUNTX1))) BD)NPPREPOS APPLIED.
GO TO CONTINUATION 1.14CONTINUATION 1.14:(BD EQUAL (THE (((AMOUNT MONEY GROSS) X5) (~' GM 1970 '0)) (A (((WH SOME) LARGE)(AMOUNT Xl))) BD)GENOFMRK APPLIED.
GO TO CONTINUATION 1.15CONTINUATION 1.15:(BD EQUAL (THE (((AMOUNT MONEY GROSS) X5) (~' GM 1970 ~,))) (A (((WH SOME) LARGE)(AMOUNT Xl))) BD)ORDNOUNF APPLIED.
GO TO CONTINUATION 1.16CONTINUATION 1.16:(BD EQUAL (THE (X5 (~ (AMOUNT MONEY GROSS) X5 GM 1970 ~))) (A (((WH SOME) LARGE)(AMOUNT Xl))) BE))SEARCHING FOR EMBEDDED CLAUSESSENTENCE 4:((AMOUNT MONEY GROSS) X5 GM 1970))ERASEBODS APPLIED.
GO TO CONTINUATION 4.1CONTINUATION 4.1 :(BD (AMOUNT MONEY GROSS) X5 GM 1970 BD)LOC2FEAT APPLIED.
GO TO CONTINUATION 4.2CONTINUATION 4.2:(BD (AMOUNT MONEY GROSS) X5 GM i970 BD)PREPPNP2 APPLIED.
GO TO CONTINUATION 4.3CONTINUATION 4.3:(BD (AMOUNT MONEY GROSS i X5 GM 1970 BD)SEARCHING FOR EMBEDDED CLAUSESA STRUCTURAL DESCRIPTION OF SENTENCE 4:(BD (AMOUNT MONEY GROSS) X5 GM 1970 'BD)A STRUCTURAL DESCRIPTION OF SENTENCE 1:(BD EQUAL (THE (X5 (~' BD (AMOUNT MONEY GROSS) X5 GM 1970 BD '0)) (A (((WH SOME) LARGE)(AMOUNT Xl))) BD)UNDERLYING STRUCTURES:1.
(BD EQUAL (THE (X5 (.
BD (AMOUNT MONEY GROSS) X5 GM 1970 BD .
)))(A (((WH SOME)LARGE) (AMOUNT X1))) BD)LOGICAL FORM: "(SIZEOF(SETX(QUOTE Xl)(QUOTE (AND (EQUAL (QUOTE 18752354000) X1 (AMOUNT Xl))) ) )ANSWERS:1.
$18752354000NEXT QUESTION?Fig.
3.
On-line Trace of t~e Processing of a Typical Query.376 WARREN J .
I~LATHsubstituting in their stead the features (q-QUES) and (-I-GEN), re-spectively, on higher nodes which do not show up in the trace displayedin Fig.
3.
Inverse WHERASE applies next, inserting the feature (-I-WH) on the NP node that dominates the structure ((WH SOME)(THING X1)) - an action once again not visible in the trace (continu-ation 1.3).
At this point, the inverse transformation INFOK recog-nizes the preposition "for" as a surface variant of " in" within a(q-- TIME) postmodifier of a (+ NMNL) noun (continuation 1.4), fol-lowing which inverse WHATFP, NT (one of five variants of WH-movement implemented in the current grammar) effects a major reor-dering of clause components by sister-adjoining the NP dominating((WH SOME) (THING X1)) to the right of the NP following theauxiliary (continuation 1.5).Processing the structure against he remainder of the postcyclictransformations successively deletes the preposition " in"  in favor ofthe features (q-LOC2) and (+ IN2) (continuation 1.6), replaces"thing " by the more specific noun "amount " (continuation 1.7),expands ((WH SOME) (AMOUNT X1))intoa (A (((WH SOME)LARGE) (AMOUNT X1))) (continuation 1.8), and finally eliminatesthe (q- WH) feature on the NP dominating the latter (continuation 1.9)i(It should be noted here in passing that the WHATNUMA transfor-mation not only accounts in part for the underlying equivalence ofsentence pairs like " What were GM's earnings? "
and "How largewere GM's earnings?
", but also for the equivalence of pairs beginning"How large j'an amo..t't of " and ~.
a number .f "'"" What { nmb~.
ouo, } of ... " .
)The application of inverse cyclical transformations begins with theinsertion of sentence boundaries (BD) on the highest clause by the in-verse EKASEBDS transformation (continuation 1.10).
This is followedby insertion of the main predicate "EQUAL" by inverse IDEQUDEL(continuation 1.11).
IDEQUDEL is one of a set of four related trans-formations that supply one of the five underlying predicates IDENTI-CAL, EQUAL, RANK, LOCATED, and MEMBEK in clauses witha BE auxiliary and no predicate head (verb or adjective), the choicedepending on syntactic and semantic features of the main NP's in theclause.
Examples of each of the five types of copulative clauses coveredby these transformations are:TRANSFLRMATIONAL GRAMMAR AND TRANSFORMATIONAL PARSING 377" Is Jones xYz's president?
", " What were GM's 1970 earnings?
","What company was fifth in 1969 sales?
", "Is the headquarters ofIBM in Pittsburgh?
", and" Is a city a place?
", respectively.After the main predicate "EQUAL " has been inserted, the aux-iliary is deleted by inverse AUXINUMA, whose forward counterpartcombines the functions of auxiliary insertion and number agreement(continuation 1.12).
Next (continuation 1.13), inverse S-pruning(PRUNES) turns the postmodifying structure " 1970 " into a subordi-nate clause fragment dominated by a sentence node $1.
(This showsup in the bracketed terminal string as insertion o f "  (* *) " surround-ing " 1970 ".)
Inverse noun phrase preposing (NPPREPOS), whichrelates such surface pairs as " GM's sales " and " the sales of GM ",then applies (continuation 1.14) (i) moving the NP node dominating" GM" into initial position in the subordinate clause fragment, (ii)marking that NP with the features (+ PREP) and (+ OF), and (iii)replacing the original copy of that NP by " THE ".
The features (+PREP) and (+ OF) are then erased by inverse GENOFMRK, whichalso replaces the feature (+ GEN) by the feature (+ POSS2), whichindicates inalienable possession.The final transformation that applies in the first cycle is inversenoun formation (ORDNOUNF), which moves the V dominating(AMOUNT MONEY GROSS) into the subordinate clause fragmentas main predicate along with an NP dominating a copy of the variableX5, with the original copy of X5 remaining outside the subordinateclause as the "binding " instance of that variable.
(The original versionof the noun formation transformation - and, more generally, the over-all treatment of variables and constants in the grammar - are due toPaul Postal.
)Application of the inverse cyclical transformations to the subordi-nate clause (now labelled " SENTENCE 4 " by the program) is rela-tively uneventful.
The only transformations that apply merely insertsentence boundaries (continuation 4.1) and delete the features (+ IN2)and (+ POSS2) from the NP nodes dominating " 1970" and " GM ",respectively.
Since there are no further embeddings, the transformationalparsing procedure terminates, producing a unique underlying structurefor the sentence.
As described by S. R. P~TRIC~:, the underlying struc-ture is then mapped by a Knuth-style semantic interpreter into a cor-responding logical form.
Finally, the logical form is evaluated inter-pretively to yield the answer " $18, 752, 354, 000"378 WARREN J. PLATH4.
CURRENT STATUS OF THE REQUEST GRAMMARThe immediately preceding example provides a partial illustrationof approximately one-quarter of the transformational apparatus of thecurrent REQUEST grammar, which includes 18 blocking rules and 63pairs of transformations (forward and corresponding inverse).
The sur-face grammar currently comprises 261 context-free rules which, throughthe use of rule-factoring techniques, effectively represent a set of rulesmore than half as large again.
The grammar also contains 18 base rulesand 222 auxiliary phrase structure rules, which are used by the parserin checking the well-formedness of underlying structures and transfor-mationally-derived structures, respectively.The grammatical coverage provided by the current REQUEST gram-mar is relatively extensive, but tends to be heavily concentrated in alimited number of areas, with certain important construction typesnot covered yet at all.
This pattern of coverage is not a product of acci-dent or oversight, but has arisen quite naturally from two basic consid-erations.
The first involves one of the more obvious strengths of atransformational model of natural anguage (particularly one with rel-atively "deep " underlying structures): its capacity for relating wideranges of synonymous surface structures to common underlying forms.Within the context of a man-machine interaction situation, it is highlydesirable to capitalize on this strength as a means of enhancing the natu-ralness of the interaction language for the user.
To this end, we havebeen attempting to build up our grammatical coverage in such a wayas to allow the user great latitude of grammatical formulation in expres-sing each of the limited number of semantic relationships provided forin the system.
With such "locally full " coverage, we hope to minimizewhat the user must learn about constructions to be avoided and howto avoid them.The second consideration is that for ~QUEST, as for any naturallanguage tmderstanding system, it makes sense to concentrate on gram-matical constructions of importance in expressing the central relation-ships in the "world " of the data base in question.
A case in point inour current grammar is the extensive coverage of constructions involv-ing notions of rank and ordinality - concepts which assume a centralrole in the world of the " Fortune 500 ".An example of what has been achieved so far in striving towardsthe goal of locally full coverage is the range of relative clause structuresTRANSFORMATIONAL GRAMMAR AND TRANSFORMATIONAL PARSING 379handled by the current grammar.
To begin with, the basic relative clausepatterns covered (1) include counterparts of all the declarative mainclause patterns handled by the system - among them patterns involvingactives (1. a, d, g, h, k, 1, m), passives (1. b, c, e, f, i, j), datives (1. d,e, f, g, h, i, j), and optional time and place adverbials (1. k, 1, m), aswell as the interaction of all of these with clausal negation.
In addition,the relative clause types covered not only share with wh-questions theoption of preposition stranding (1. c, f, h, j), but also include provisionsfor optional substitution of"  that" for the relative pronouns "which ",who , whom , when , and where under appropriate cir-cumstances (1. a, c, d, f, h,j, k, 1) as well as for optional deletion of thosepronouns under still more restricted circumstances (1. d, f, h, j, k, 1).(1)a.
companies ~that { diddidn, tnotf make computersb.
companies by which computers were not madeweren'twhich J ~ werec.
companies t that t c?mputers t werenot ?madebYweren,t  ,I which I ~did not d. companies that t didn t sell XYZ computerse.
companies by whichl were 1 I computers were not sold to XYZweren'tI I XYZ was not l sold computers wasn'tcomputers were not sold to XYZweren't ,tl w?
I XYZ was not sold computers wasn't II '?
'dl g. companies towhich ABC did notdidn't I sellcomputersby380 WARREN J. PLATHwhic !
s?ldlc?mPuterSt?sell h. companies that ABC l did not }didn'tt were ) i. companies to which computers were not ~ sold by ABCweren'tl which) l were t i. compauies t~at computers wer0weren, tnot ~ sold to by A~C1 w~chl l s?Xdl~.
~e ~o~;o~0~ ,~ t ~ I ~'?~i~ t ~?~ ~o, x~.in New York in 1969t in which f wheD.
I. the year that ABC I sold t did not j sell , { didnt t 1computers to XYZ I XYZ computers j in New YorkI inw ich  i where \[ sold m. the city *that i ABC did not ,~ ~ didn't J sellcomputers to XYZ I in 1969 I XYZ computersIn addition to the surface patterns exemplified in (1), a variety ofother relative clause constructions are covered.
In (2), we see examplesof possessive relatives, which appear in surface structures either as thepreposed genitive form "whose" or as the postmodifying preposition-al phrase " of which ".
As can be observed from (2.b-f), in producingsuch structures, the wh-movement rules of the current grammar caneither: (i) "pied pipe" a larger noun phrase containing a relative pro-noun to clause-initial position (2.b, d); (ii) front only a relative pro-noun which is the object of a preposition, leaving the remainder of thelarger NP behind along with a stranded preposition (2.c, f); or (iii)do a combination of (i) and (ii) (2.e).TRANSFORMATIONAL GRAMMAR AND TRANSFORMATIONAL PARSING 381(2)l whose headquarters t a. companies the headquarters of which are (located) in New Yorkl wh?se assets f Chile expropriated b. companies the assets of whichc.
companies that Chile expropriated the assets oft whose subsidiaries' earnings Id.
companies the earnings of whose subsidiaries the government impoundedthe earnings of the subsidiaries ofwhichi whose subsidiaries I e. companies the subsidiaries of which the government impounded the earnings oflw ,c lf.
companies that the government impounded the earnings of the subsidiaries ofAnother important part of relative clause handling in the currentgrammar is the coverage of a variety of patterns of relative clause re-duction (3).
In the case of adjectival predicates such as "profitable ",the (optional) reduction process involves deletion of the relative pro-noun and suppression of auxiliary insertion, producing reduced surfaceclauses like (3.b) from the same structures that underly full clauses like(3.a).
If the results of clause reduction contain only an adjectival cons-tituent (e.g., if no phrase like "in 1970" is present), it is obligatorily pre-posed to yield a structure like (3.c).
In cases uch as (3.d), where theadjectival predicate itself is independently subject o deletion, one ofthe possible outcomes (3.e) of the reduction process is a prepositionalphrase, with or without a preceding negative.
In cases where the predi-cate in the full relative clause is nonadjectival (3.f, h, j), there is a similarreduction process, again involving deletion of the relative pronoun andsuppression of the auxiliary.
Here, however, an additional process isinvolved: replacement of the predicate by the corresponding -ing form(3.g., i, k).
The final possibilities of relative clause reduction shown in(3) have to do with more restricted processes in which relative clauseswith the predicate "have " (3.j, 1) optionally reduce to prepositionalphrases with "with " or "o f "  (3.k, m).382 WARREN J. PLATH(3)profitable in 1970 a compan 0s  w chl I wet?
I that were notweren'tb.
companies (not) profitable in 1970c.
(un)profitable companiesin New Yorkaren't ~ ~ Yt located I in New York e. headquarters (not) { ef" 1969 earnings I which l that  I I diddidneXCeeded ln?
t t  l xceed $1,000,000g.
1969 earnings (not) exceeding $1,000, 000h.
the company I which I ' ranked f l see?rid (highes0 I that I was in second place in 1969 salesi.
the company (ranking) I sec?nd (highest) I in second place in 1969 salesl~.v,?~ I t ~" o. k. companies with ?.g.1.
the subsidiaries that ABC hast~.0 ~o~,~,.~o o~c I m. ABe's subsidiariesIn concluding our discussion of  the current status of the REQUESTGrammar, let us turn from our sampling of current coverage to a briefenumeration of  important constructions not now handled by the sys-tem.
At this writing, major known gaps include:(a) absence of any provisions for conjunction or disjunction;TRANSFORMATIONAL GRAMMAR AND TRANSFORMATIONAL PARSING 383(b) need to augment coverage of quantifiers (currently limited toordinal and cardinal numeral quantifiers) to include a much broaderrange of logical, numerical, and temporal quantifiers, e.g., "each ","every ", " all ", "any ", "some ", "no ", "none",  "more than n ","less than n.", "exactly n ", "at  most n ", "at  least n ", "once ",twice , n times , always , ever , never , more than ntimes ", "at  least n times ", " n times in succession ", etc.
;(c) absence of provisions for handling arithmetic predicates suchas "total ", "average ", "ratio ", "rate ", and "per ";(d) inadequate coverage of comparatives (currently limited to afew constructions with " exceed ") and superlatives (currently limitedto clauses with underlying predicate "rank ").The four areas of deficiency just cited are all of considerable impor-tance in relation to the provision of facilities for asking and answeringsemantically complex questions that seek information only implicitlystored in a collection of numerical data of the sort we are dealing with.They also represent areas of significant independent linguistic interest.Our present hope is that a reasonable range of the phenomena under(a) - (c) will prove tractable when dealt with under a presently contem-plated extension of the parser which will make transformational poweravailable at a point immediately prior to surface parsing: but the extentto which that hope is realized remains to be seen.
With regard to com-paratives and superlatives, a great deal of work lies ahead of us, partic-ularly when it comes to handling the changes in clause inclusion rela-tionships that seem to be involved in deriving sentence pairs l ike" XYZearned more than ABC " and "XYZ's earnings exceeded ABC's "from a common underlying source.In spite of the large amount of linguistic work remaining to be donein order to achieve truly satisfactory coverage, I believe we have pro-gressed sufficiently far at this point to have demonstrated both the ex-perimental viability and the future promise of a transformationally-based approach to natural anguage question answering.ILEFEILENCESN.
CHOMSKY, Aspects of the Theory ofSyntax, Cambridge (Mass.
), 1965.B.
HENISZ-DOSTERT, F. B. THOMPSON,The REL Project, in "Quarterly Prog-ress tLeport ", California Institute ofTechnology, Pasadena, April 1, 1973.S.
KuNo, A. G. O~TTmG~R, SyntacticStructure and Ambiguity of English, inProceedings of the 1963 Fail Joint Com-puter Conference, Baltimore, 1963.S.
IL.
P~TmCK, Transformational Analysis,in tL.
tLUSTIN (ed.
), Natural LanguageProcessing, New York, 1973, pp.
27-41.S.
1:~.. PI~TRICK, Semantic Interpretation ithe REQUEST System, in the I vol-ume of this book.J.
J. ROBINSON, An Inverse Transforma-tional Lexicon, in 1L.
ILUSTIN (ed.
),Natural Language Processing, New York,1973, pp.
43-60.T.
WINOGAD, Understanding NaturalLanguage, in ~ Cognitive Psychology ~,III (January 1972) 1, pp.
1-191.W.
A.
WooDs, P,.. M. KAPLAN, \]3.
NASH-W~B~a, The Lunar Sciences NaturalLanguage Information System, FinalReport, BBN tLeport No.
2378,Cambridge (Mass.
), June 15, 1972.
