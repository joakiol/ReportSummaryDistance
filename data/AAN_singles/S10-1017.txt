Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010, pages 88?91,Uppsala, Sweden, 15-16 July 2010.c?2010 Association for Computational LinguisticsRelaxCor: A Global Relaxation Labeling Approach to CoreferenceResolutionEmili Sapena, Llu?
?s Padr?o and Jordi TurmoTALP Research CenterUniversitat Polit`ecnica de CatalunyaBarcelona, Spain{esapena, padro, turmo}@lsi.upc.eduAbstractThis paper describes the participationof RelaxCor in the Semeval-2010 tasknumber 1: ?Coreference Resolution inMultiple Languages?.
RelaxCor is aconstraint-based graph partitioning ap-proach to coreference resolution solved byrelaxation labeling.
The approach com-bines the strengths of groupwise classifiersand chain formation methods in one globalmethod.1 IntroductionThe Semeval-2010 task is concerned with intra-document coreference resolution for six differentlanguages: Catalan, Dutch, English, German, Ital-ian and Spanish.
The core of the task is to iden-tify which noun phrases (NPs) in a text refer to thesame discourse entity (Recasens et al, 2010).RelaxCor (Sapena et al, 2010) is a graph rep-resentation of the problem solved by a relaxationlabeling process, reducing coreference resolutionto a graph partitioning problem given a set of con-straints.
In this manner, decisions are taken con-sidering the whole set of mentions, ensuring con-sistency and avoiding that classification decisionsare independently taken.The paper is organized as follows.
Section 2 de-scribes RelaxCor, the system used in the Semevaltask.
Next, Section 3 describes the tuning neededby the system to adapt it to different languages andother task issues.
The same section also analyzesthe obtained results.
Finally, Section 4 concludesthe paper.2 System DescriptionThis section briefly describes RelaxCor.
First, thegraph representation is presented.
Next, there isan explanation of the methodology used to learnconstraints and train the system.
Finally, the algo-rithm used for resolution is described.2.1 Problem RepresentationLetG = G(V,E) be an undirected graph where Vis a set of vertices and E a set of edges.
Let m =(m1, ...,mn) be the set of mentions of a documentwith n mentions to resolve.
Each mention miinthe document is represented as a vertex vi?
Vin the graph.
An edge eij?
E is added to thegraph for pairs of vertices (vi, vj) representing thepossibility that both mentions corefer.Let C be our set of constraints.
Given a pair ofmentions (mi, mj), a subset of constraints Cij?C restrict the compatibility of both mentions.
Cijis used to compute the weight value of the edgeconnecting viand vj.
Let wij?
W be the weightof the edge eij:wij=?k?Cij?kfk(mi,mj) (1)where fk(?)
is a function that evaluates the con-straint k and ?kis the weight associated to theconstraint.
Note that ?kand wijcan be negative.In our approach, each vertex (vi) in the graphis a variable (vi) for the algorithm.
Let Libe thenumber of different values (labels) that are possi-ble for vi.
The possible labels of each variable arethe partitions that the vertex can be assigned.
Avertex with index i can be in the first i partitions(i.e.
Li= i).88Distance and position:DIST: Distance betweenmiandmjin sentences: numberDIST MEN: Distance betweenmiandmjin mentions: numberAPPOSITIVE: One mention is in apposition with the other: y,nI/J IN QUOTES:mi/jis in quotes or inside a NP or a sentencein quotes: y,nI/J FIRST:mi/jis the first mention in the sentence: y,nLexical:I/J DEF NP:mi/jis a definitive NP: y,nI/J DEM NP:mi/jis a demonstrative NP: y,nI/J INDEF NP:mi/jis an indefinite NP: y,nSTR MATCH: String matching ofmiandmj: y,nPRO STR: Both are pronouns and their strings match: y,nPN STR: Both are proper names and their strings match: y,nNONPRO STR: String matching like in Soon et al (2001)and mentions are not pronouns: y,nHEAD MATCH: String matching of NP heads: y,nMorphological:NUMBER: The number of both mentions match: y,n,uGENDER: The gender of both mentions match: y,n,uAGREEMENT: Gender and number of bothmentions match: y,n,uI/J THIRD PERSON:mi/jis 3rd person: y,nPROPER NAME: Both mentions are proper names: y,n,uI/J PERSON:mi/jis a person (pronoun orproper name in a list): y,nANIMACY: Animacy of both mentions match(persons, objects): y,nI/J REFLEXIVE:mi/jis a reflexive pronoun: y,nI/J TYPE:mi/jis a pronoun (p), entity (e) or nominal (n)Syntactic:NESTED: One mention is included in the other: y,nMAXIMALNP: Both mentions have the same NP parentor they are nested: y,nI/J MAXIMALNP:mi/jis not included in anyother mention: y,nI/J EMBEDDED:mi/jis a noun and is not a maximal NP: y,nBINDING: Conditions B and C of binding theory: y,nSemantic:SEMCLASS: Semantic class of both mentions match: y,n,u(the same as (Soon et al, 2001))ALIAS: One mention is an alias of the other: y,n,u(only entities, else unknown)I/J SRL ARG: Semantic role ofmi/j: N,0,1,2,3,4,M,LSRL SAMEVERB: Both mentions have a semantic rolefor the same verb: y,nFigure 1: Feature functions used.2.2 Training ProcessEach pair of mentions (mi, mj) in a training doc-ument is evaluated by the set of feature functionsshown in Figure 1.
The values returned by thesefunctions form a positive example when the pairof mentions corefer, and a negative one otherwise.Three specialized models are constructed depend-ing on the type of anaphor mention (mj) of thepair: pronoun, named entity or nominal.A decision tree is generated for each specializedmodel and a set of rules is extracted with C4.5rule-learning algorithm (Quinlan, 1993).
Theserules are our set of constraints.
The C4.5rules al-gorithm generates a set of rules for each path fromthe learned tree.
It then checks if the rules can begeneralized by dropping conditions.Given the training corpus, the weight of a con-straint Ckis related with the number of exam-ples where the constraint applies ACkand howmany of them corefer CCk.
We define ?kasthe weight of constraint Ckcalculated as follows:?k=CCkACk?
0.52.3 Resolution AlgorithmRelaxation labeling (Relax) is a generic name fora family of iterative algorithms which performfunction optimization, based on local informa-tion (Hummel and Zucker, 1987).
The algorithmsolves our weighted constraint satisfaction prob-lem dealing with the edge weights.
In this manner,each vertex is assigned to a partition satisfying asmany constraints as possible.
To do that, the al-gorithm assigns a probability for each possible la-bel of each variable.
Let H = (h1,h2, .
.
.
,hn) bethe weighted labeling to optimize, where each hiis a vector containing the probability distributionof vi, that is: hi= (hi1, hi2, .
.
.
, hiLi).
Given thatthe resolution process is iterative, the probabilityfor label l of variable viat time step t is hil(t), orsimply hilwhen the time step is not relevant.Initialize:H := H0,Main loop:repeatFor each variable viFor each possible label l for viSil=?j?A(vi)wij?
hjlEnd forFor each possible label l for vihil(t + 1) =hil(t)?(1+Sil)?Lik=1hik(t)?
(1+Sik)End forEnd forUntil no more significant changesFigure 2: Relaxation labeling algorithmThe support for a pair variable-label (Sil) ex-presses how compatible is the assignment of la-bel l to variable vitaking into account the labelsof adjacent variables and the edge weights.
Thesupport is defined as the sum of the edge weightsthat relate variable viwith each adjacent variablevjmultiplied by the weight for the same label l ofvariable vj: Sil=?j?A(vi)wij?
hjlwhere wijisthe edge weight obtained in Equation 1 and vertexvihas |A(vi)| adjacent vertices.
In our version ofthe algorithm for coreference resolution A(vi) isthe list of adjacent vertices of vibut only consid-ering the ones with an index k < i.The aim of the algorithm is to find a weightedlabeling such that global consistency is maxi-mized.
Maximizing global consistency is defined89Figure 3: Representation of Relax.
The vertices represent-ing mentions are connected by weighted edges eij.
Each ver-tex has a vector hiof probabilities to belong to different par-titions.
The figure shows h2, h3and h4.as maximizing the average support for each vari-able.
The final partitioning is directly obtainedfrom the weighted labeling H assigning to eachvariable the label with maximum probability.The pseudo-code of the relaxation algorithmcan be found in Figure 2.
The process updatesthe weights of the labels in each step until con-vergence, i.e.
when no more significant changesare done in an iteration.
Finally, the assigned labelfor a variable is the one with the highest weight.Figure 3 shows an example of the process.3 Semeval task participationRelaxCor have participated in the Semeval task forEnglish, Catalan and Spanish.
The system doesnot detect the mentions of the text by itself.
Thus,the participation has been restricted to the gold-standard evaluation, which includes the manualannotated information and also provides the men-tion boundaries.All the knowledge required by the feature func-tions (Figure 1) is obtained from the annota-tions of the corpora and no external resourceshave been used, with the exception of WordNet(Miller, 1995) for English.
In this case, the sys-tem has been run two times for English: English-open, using WordNet, and English-closed, withoutWordNet.3.1 Language and format adaptationThe whole methodology of RelaxCor includingthe resolution algorithm and the training processis totally independent of the language of the docu-ment.
The only parts that need few adjustments arethe preprocess and the set of feature functions.
Inmost cases, the modifications in the feature func-tions are just for the different format of the datafor different languages rather than for specific lan-guage issues.
Moreover, given that the task in-cludes many information about the mentions of thedocuments such as part of speech, syntactic depen-dency, head and semantic role, no preprocess hasbeen needed.One of the problems we have found adapting thesystem to the task corpora was the large amountof available data.
As described in Section 2.2,the training process generates a feature vector foreach pair of mentions into a document for allthe documents of the training data set.
However,the great number of training documents and theirlength overwhelmed the software that learns theconstraints.
In order to reduce the amount of pairexamples, we run a clustering process to reducethe number of negative examples using the posi-tive examples as the centroids.
Note that negativeexamples are near 94% of the training examples,and many of them are repeated.
For each positiveexample (a corefering pair of mentions), only thenegative examples with distance less than a thresh-old d are included in the final training data.
Thedistance is computed as the number of differentvalues inside the feature vector.
After some exper-iments over development data, the value of d wasassigned to 3.
Thus, the negative examples werediscarded when they have more than three featuresdifferent than any positive example.Our results for the development data set areshown in Table 1.3.2 Results analysisResults of RelaxCor for the test data set are shownin Table 2.
One of the characteristics of the sys-tem is that the resolution process always takesinto account the whole set of mentions and avoidsany possible pair-linkage contradiction as well asforces transitivity.
Therefore, the system favorsthe precision, which results on high scores withmetrics CEAF and B3.
However, the system ispenalized with the metrics based on pair-linkage,specially with MUC.
Although RelaxCor has thehighest precision scores even for MUC, the recallis low enough to finally obtain low scores for F1.Regarding the test scores of the task comparingwith the other participants (Recasens et al, 2010),RelaxCor obtains the best performances for Cata-90- CEAF MUC B3language R P F1R P F1R P F1ca 69.7 69.7 69.7 27.4 77.9 40.6 67.9 96.1 79.6es 70.8 70.8 70.8 30.3 76.2 43.4 68.9 95.0 79.8en-closed 74.8 74.8 74.8 21.4 67.8 32.6 74.1 96.0 83.7en-open 75.0 75.0 75.0 22.0 66.6 33.0 74.2 95.9 83.7Table 1: Results on the development data set- CEAF MUC B3BLANClanguage R P F1R P F1R P F1R P BlancInformation: closed Annotation: goldca 70.5 70.5 70.5 29.3 77.3 42.5 68.6 95.8 79.9 56.0 81.8 59.7es 66.6 66.6 66.6 14.8 73.8 24.7 65.3 97.5 78.2 53.4 81.8 55.6en 75.6 75.6 75.6 21.9 72.4 33.7 74.8 97.0 84.5 57.0 83.4 61.3Information: open Annotation: golden 75.8 75.8 75.8 22.6 70.5 34.2 75.2 96.7 84.6 58.0 83.8 62.7Table 2: Results of the tasklan (CEAF and B3), English (closed: CEAF andB3; open: B3) and Spanish (B3).
Moreover, Relax-Cor is the most precise system for all the metricsin all the languages except for CEAF in English-open and Spanish.
This confirms the robustness ofthe results of RelaxCor but also remarks that moreknowledge or more information is needed to in-crease the recall of the system without loosing thisprecisionThe incorporation of WordNet to the Englishrun is the only difference between English-openand English-closed.
The scores are slightly higherwhen using WordNet but not significant.
Analyz-ing the MUC scores, note that the recall is im-proved, while precision decreases a little whichcorresponds with the information and the noisethat WordNet typically provides.The results for the test and development arevery similar as expected, except the Spanish (es)ones.
The recall considerably falls from develop-ment to test.
It is clearly shown in the MUC recalland also is indirectly affecting on the other scores.4 ConclusionThe participation of RelaxCor to the Semevalcoreference resolution task has been useful to eval-uate the system in multiple languages using datanever seen before.
Many published systems typi-cally use the same data sets (ACE and MUC) andit is easy to unintentionally adapt the system to thecorpora and not just to the problem.
This kind oftasks favor comparisons between systems with thesame framework and initial conditions.The results obtained confirm the robustness ofthe RelaxCor, and the performance is considerablygood in the state of the art.
The system avoids con-tradictions in the results which causes a high pre-cision.
However, more knowledge is needed aboutthe mentions in order to increase the recall withoutloosing that precision.
A further error analysis isneeded, but one of the main problem is the lack ofsemantic information and world knowledge spe-cially for the nominal mentions ?
the mentions thatare NPs but not including named entities neitherpronouns?.AcknowledgmentsThe research leading to these results has received fundingfrom the European Community?s Seventh Framework Pro-gramme (FP7/2007-2013) under Grant Agreement number247762 (FAUST), and from the Spanish Science and Inno-vation Ministry, via the KNOW2 project (TIN2009-14715-C04-04).ReferencesR.
A. Hummel and S. W. Zucker.
1987.
On the foundationsof relaxation labeling processes.
pages 585?605.G.A.
Miller.
1995.
WordNet: a lexical database for English.J.R.
Quinlan.
1993.
C4.5: Programs for Machine Learning.Morgan Kaufmann.M.
Recasens, L. M`arquez, E. Sapena, M.A.
Mart?
?, M. Taul?e,V.
Hoste, M. Poesio, and Y. Versley.
2010.
SemEval-2010Task 1: Coreference resolution in multiple languages.
InProceedings of the 5th International Workshop on Seman-tic Evaluations (SemEval-2010), Uppsala, Sweden.E.
Sapena, L. Padr?o, and J. Turmo.
2010.
A Global Relax-ation Labeling Approach to Coreference Resolution.
Sub-mitted.W.M.
Soon, H.T.
Ng, and D.C.Y.
Lim.
2001.
A MachineLearning Approach to Coreference Resolution of NounPhrases.
Computational Linguistics, 27(4):521?544.91
