Coling 2010: Poster Volume, pages 1435?1443,Beijing, August 2010Fusion of Multiple Features and Ranking SVM forWeb-based English-Chinese OOV Term TranslationYuejie Zhang, Yang Wang, Lei Cen,Yanxia Su, Cheng Jin, Xiangyang XueSchool of Computer Science, Shanghai Key La-boratory of Intelligent Information Processing,Fudan University{yjzhang,072021176,082024072,09210240074,jc,xyxue}@fudan.edu.cnJianping FanDepartment of ComputerScience,The University of NorthCarolina at Charlottejfan@uncc.eduAbstractThis paper focuses on the Web-basedEnglish-Chinese OOV term translationpattern, and emphasizes particularly onthe translation selection strategy basedon the fusion of multiple features andthe ranking mechanism based on Rank-ing Support Vector Machine (RankingSVM).
By utilizing the CoNLL2003corpus for the English Named EntityRecognition (NER) task and selectednew terms, the experiments based ondifferent data sources show the consis-tent results.
Our OOV term translationmodel can ?filter?
the most possibletranslation candidates with better abili-ty.
From the experimental results forcombining our OOV term translationmodel with English-Chinese Cross-Language Information Retrieval (CLIR)on the data sets of Text Retrieval Eval-uation Conference (TREC), it can befound that the obvious performanceimprovement for both query translationand retrieval can also be obtained.1 IntroductionIn Cross-Language Information Retrieval(CLIR), most of users?
queries are generallycomposed of short terms, in which there aremany Out-of-Vocabulary (OOV) terms likeNamed Entities (NEs), new words, terminolo-gies and so on.
The translation quality of OOVterm directly influences the precision of query-ing relevant multilingual information.
There-fore, OOV term translation has become a veryimportant and challenging issue in CLIR.With the increasing growth of Web informa-tion which includes multilingual hypertext re-sources with abundant topics, it appears thatWeb information can mitigate the problem ofthe restricted OOV term translation accuracy(Lu and Chien, 2002).
However, how to selectthe correct translations from Web informationand locate the appropriate translation resourcesrapidly is still the main goal for OOV termtranslation.
Hence, finding the effective featurerepresentation and the optimal ranking patternfor translation candidates is the core part forthe Web-based OOV term translation.This paper focuses on the Web-based Eng-lish-Chinese OOV term translation pattern, andemphasizes particularly on the translation se-lection strategy based on the fusion of multiplefeatures and the translation ranking mechanismbased on Ranking Support Vector Machine(Ranking SVM).
By utilizing the CoNLL2003corpus for the English Named Entity Recogni-tion (NER) task and manually selected newterms in various fields, the established OOVterm translation model can ?filter?
the mostpossible translation candidates with better abil-ity.
This paper also attempts to apply the OOVterm translation mechanism above in English-Chinese CLIR.
It can be observed from theexperimental results on the data sets of TextRetrieval Evaluation Conference (TREC) thatthe obvious performance improvement forquery translation can be obtained, which isvery beneficial to CLIR and can improve thewhole retrieval performance.2 Related WorkAt present, the methods for OOV term transla-tion have changed from the basic pattern basedon bilingual dictionary, transliteration or paral-lel corpus to the intermediate pattern based oncomparable corpus (Lee et al, 2006; Shao andNg, 2004; Virga and Khudanpur, 2003), and1435then become a new pattern based on Web min-ing (Fang et al, 2006; Sproat et al, 2006).In recent years, many researchers have uti-lized Web to find the translation candidates onwebpages (Wu and Chang, 2007).
Al-Onaizanand Knight (2002) used Web statistics infor-mation to validate the translation candidatesgenerated by language model, and obtained theaccuracy of 72.6% in Arabic-English OOVword translation.
Lu and Chien (2004) utilizedthe statistics information about the anchor textsin Web search results to recognize the transla-tion candidates, and got the accuracy of 63.6%in English-Chinese title query term translation.Zhang and Vines (2004) extracted the transla-tion candidates for OOV query terms in CLIRfrom Web, and improved the performance ofEnglish-Chinese/Chinese-English CLIR tosome extent.
Zhang et al (2005) searched thetranslation candidates by using cross-languagequery expansion and Web, and obtained theTop-1 accuracy of 81.0% in Chinese-EnglishOOV word translation.
Chen and Chen (2006)used the combination of Web statistics and thevocabulary, and acquired the Top-1 accuracyof 87.6% in Chinese-English OOV word trans-lation.
Jiang et al (2007) utilized the combina-tion of Web mining, transliteration and rankingbased on Maximum Entropy (ME), only fo-cused on English-Chinese person name transla-tion and got the Top-1 accuracy of 47.5%.Although the methods above can improvethe translation performance for OOV term to acertain degree, there are still three commonproblems in the OOV term translation based onWeb mining.
(1) Chinese key term extractionpattern from Web documents is over com-plex and the complexity is always higher.Because of the inherent property of having nosegmentation delimitation in Chinese, it?s verydifficult for English-Chinese OOV term trans-lation to extract Chinese key terms from Webdocuments.
The cost for the extraction compu-tation is generally overlarge (Wang et al, 2004;Zhang and Vines, 2004).
(2) The feature in-formation for the evaluation of translationcandidates is not enough and comprehensive.Most of OOV term translation methods im-plement the evaluation for candidates throughmining simple local and Boolean features, thatis, inherent features in candidates and theirsurrounding context features.
However, if onlya certain Web document that an OOV termappears is explored, the global informationcontained in the whole Web document set willbe ignored, and the inconsistency and polyse-my of candidates cannot be considered.
(3)The relevance measurement for translationpairs is very simple, or the computation costis too high.
For ranking candidates, most ofOOV term translation approaches adopt thesimple combination computation of the featurevalues used, or get assessment based on classi-fication models.
Hence, the feature weights aredetermined according to the correspondinginduction and suitable for some specific fields,but cannot guarantee the accuracy of the finaltranslation ranking results.
However, the Rank-ing SVM model can effectively express mul-tiple ranking constraints, and has better univer-sality and applicability (Cao et al, 2006; Joa-chimes, 2002; Vapnik, 1995).3 Our SolutionsTo support more precise English-ChineseOOV term translation, we establish a multiple-feature-based translation pattern based on Webmining and Ranking SVM.
On the one hand, aChinese key term extraction strategy is built onthe simplified extraction computation for PAT-Tree, in which the optimization processing forthe confidence of word building is improved toa certain extent.
On the other hand, translationcandidates are chosen by the fusion of multiplefeatures.
The representation forms of local,global and Boolean feature are constructedunder the consideration of the complex charac-teristics of English/Chinese OOV term andWeb information.
Moreover, for the relevancemeasurement between an OOV term to betranslated and its translation candidates, thesupervised learning based on Ranking SVM isintroduced to rank candidates precisely.At first, given an OOV term to be translatedas a query, it is input into the Google searchengine to acquire the returned webpage snippetset.
Next, Chinese key terms are extractedfrom the PAT-Tree built on the snippet set todetermine the translation candidates.
Subse-quently, local, global and Boolean features areextracted from the candidates based on the fu-sion of multiple features.
Finally, the candi-dates are filtered and ranked through the su-pervised learning based on Ranking SVM.14364 Chinese Key Term ExtractionIn Web mining of English-Chinese OOV termtranslation, an important problem is to extractthe target translation candidates from the re-turned Chinese Web documents, which can beconsidered as a key term extraction task.The PAT-Tree structure is an efficient in-dexing method in both IR and Information Ex-traction (IE) domains (Chien, 1997; Gonnet etal., 1992).
Its superior feature is the Semi Infi-nite String, which can store all the strings fromthe whole corpus (i.e., the returned snippet setin this paper) in a binary tree.
The branch nodeindicates the search direction and the leaf nodestores the index and frequency for a string.Generally, a Chinese character correspondsto a binary-coded form with 2 bytes (16 bits).Chinese strings can be transformed into binarystrings.
There is an ending tag for each stringand its binary form is ?00000000?.
Take ????????
(Chinese IE) and ??????
(IR)as an example, the binary strings for them aredescribed in Figure 1.
Thus a PAT-Tree can bebuilt based on these strings, as shown in Figure2.
The branch node stands for the comparisonbit (Comp-bit), which represents the positionof different bit in binary strings.
Some binarystrings have the value of 0 in such a bit and areclassified into the left branch, while othershave 1 and turn to the right branch.Figure  1.
Binary string representation instantiation.Figure 2.
PAT-Tree Instantiation for Figure 1.In the extraction process, the PAT-tree istraversed first, and the branch nodes with theComp-bit values larger than 32 are selected.This is because the minimum length of a Chi-nese common string is 2 characters and eachhas 16 binary bits.
Next, the frequency valuesof both two child nodes are added as the fre-quency of the common string (i.e., the parentbranch node).
At last, the common strings withthe frequency values larger than 2 are extractedas the key terms.
For the PAT-Tree in Figure 2,there is a branch node with the Comp-bit valueof 37, which indicates that at least the prefixesof two strings contain two identical characters.It can be known from the leaf nodes that twostrings are ??????
(IE) and ??????(IR).
Hence, the prefix substring ????
(in-formation) with the frequency of 2 is extractedas the common string.
Thus the key terms withthe arbitrary lengths and frequency values canbe retrieved from the built PAT-Tree.However, with the common strings beingextracted, large amounts of noisy terms andfragments are also extracted.
To filter noisyfragments, Wang et al (2004) used SPDCDand the Local-Maxima algorithm, but the com-putation cost was too expensive.
Therefore, thesimplified filtering manner is adopted here:( ) ( ) ( )( ) )1(1jinjijiccfccfccfcc LLLL ?=?where c1?cn is a n-gram that contains the sub-string ci?cj; ci?cj is the n-1-gram to be esti-mated, i.e., ci?cj=c1?cn-1 or ci?cj=c2?cn; f( )denotes the string frequency; ?
represents thecohesion factor of the n-1-gram string, that is,the ability of independent word building.
Thecloser to 1 the value of ?
is, the more possiblemeaningful key term ci?cj is.5 Multiple Feature RepresentationLocal Feature (LF) is constructed based onneighboring tokens and the token itself.
Thereare two types of contextual information to beconsidered when extracting LFs, namely inter-nal lexical and external contextual information.
(1) Term length (Len) ?
Aims to consider thelength of the translation candidate.
(2) Phonetic Value (PV) ?
Aims to investigatethe phonetic similarity between an OOV termand its translation candidates.
Because the as-sociated syllabification representations canoften be found between Chinese and Englishsyllables with fewer ambiguities, the syllabifi-cation has become an effective channel in pho-netic feature expression.
PV means that formeasuring the edit distance similarity betweenthe syllabification sequences of an OOV term1437and its candidates, the processing is executedaccording to the specific linguistic rules.
( ) ( )( ) ( ) )2(''','1,OOVOOVOOVOOVOOVOOV TLenSLenTSEditDistTSPV +?=where SOOV and TOOV denote the OOV term inthe source language and its translation candi-date in the target language respectively, SOOV?and TOOV?
are the character strings after thesyllabification and removing the vowels,EditDist( , ) indicates the edit distance betweentwo strings, and Len( ) is the string length.
(3) Length Ratio of OOV Term and ItsTranslation Candidate (LR) ?
Aims to ex-plore the composition possibility that the ex-tracted key term can be regarded as the transla-tion for an OOV term.
An OOV term and itstranslation should have the similar length, sothe LR value is close to 1 as possible.
A Chi-nese term is segmented into significant piecesfirst, and the number of pieces is taken as itslength.
For example, ???????
(SARS) issegmented into ???
(non), ????
(typical)and ????
(pneumonia), and its length is 3.For an English term, the number of words iscounted as the length.
If there is only one wordcomposed of capital letters, its length is de-fined as the number of letters, e.g., ?SARS?
hasthe length of 4.
Thus the LR value of ?SARS?and its candidate ???????
is 4/3=1.3.
(4) Phonetic and Semantic Integration Fea-ture (P&S_IF) ?
Aims to consider the phonet-ic information and senses of an OOV term andits candidates synthetically.
It is set up for mul-ti-word OOV terms, especially for NEs andnew terms.
Each constituent can be translatedby the phonetic information or senses.
( )( ) ( )( ) )3(1,'','',,_&++=OOVOOVOOVOOVOOVOOVOOVOOVTSLScoreTSPVTSLScoreTSIFSPwhere LScore( , ) is the matching word numberof non-transliteration words in SOOV and TOOV,while SOOV??
and TOOV??
are the remainingstrings of SOOV and TOOV after computingLScore.
For example, given SOOV ?CapitolineMuseum?
and its TOOV ??????????
(Capitoline Museum), the non-transliterationwords ?Museum?
and ?????
(museum) arematched, then LScore(SOOV, TOOV)=1; the PVvalue between the remaining strings ?Capito-line?
and ???????
(Capitoline) is 0.8, sothe final P&S_IF value is 1.8/2=0.9.Global Feature (GF) is extracted from otheroccurrences of the same or similar tokens inthe Web document set.
The common case inthe Web-based OOV term translation is thatthe translation candidates in the previous partsof Web documents will often occur with thesame or similar forms in the latter parts.
Thecontextual information from the same and oth-er Web documents may play an important rolein determining the final translation.
To utilizesuch global information, GFs are constructedbased on the characteristics of Web documents.
(1) Global Term Frequency (G_Freq) ?Aims to utilize the frequency information thatan OOV term and its translation candidatesappear in the Web document set.
It is alwaysthe most important feature and includes fourparameters.
FreqSOOV denotes the frequency ofSOOV in all the returned webpage snippets.TFTOOV indicates the number of TOOVs in all thesnippets.
DFTOOV represents the number ofsnippets that contain TOOV.
CO_Freq meansthe number of snippets that contain both SOOVand TOOV, i.e, co-occurrence frequency.
(2) Chi-Square (?2) Feature Value (CV) ?Aims to evaluate the semantic similarity be-tween an OOV term and its translation candi-dates by their occurrence in Web documents.
( ) ( )( ) ( ) ( ) ( ) )4(,22dcdbcabacbdaNTSCV OOVOOV +?+?+?+???
?=?where a is the number of snippets that containboth SOOV and TOOV, b is the number of snippetsthat contain SOOV but do not contain TOOV, c isthe number of snippets that do not contain SOOVbut contain TOOV, d is the number of snippetsthat do not contain neither of SOOV and TOOV,and N=a+b+c+d.
(3) Co-occurrence Distance (CO_Dist) ?Aims to investigate the distance between anOOV term and its candidates in Web docu-ments.
This distance is often very closer.For each snippet that contains both SOOV andTOOV, three positions are considered, that is, thefirst position that SOOV and TOOV appear (p1),the second position (p2) and the last one (p3).In the following snippet, SOOV is ?AARP?
andTOOV is ?????????
(America Associa-tion of Retired Persons, AARP).p1SOOV=6, p2SOOV=62, p3SOOV=97;p1TOOV=54, p2TOOV=-1, p3TOOV=54.1438The position is indexed from 0 and p2TOOV=-1means only one candidate exists in the snippet.Then the nearest position pair p2SOOV and p1TOOVcan be found for this example.
The distanceDist between SOOV and TOOV is computed as:( ) ( )( ) )5(,,,???<??>?
?=OOVOOVOOVOOVOOVOOVOOVOOVTSOOVSTTSOOVTSOOVOOV pjpiSLenpipjpjpiTLenpjpiTSDistGiven the example above, Dist=p2SOOV-p1TOOV-7=62-54-7=1, that is, SOOV and TOOV are a leftbracket ?(?
apart.
Finally, the average distanceCO-Dist in the snippet set can be computed as: ( ) ( )( )( ) )6(,_,_,_OOVOOVOOVOOVOOVOOVTSFreqCODistSumTSDistAVGTSDistCO==where Sum( ) is the sum of Dist in each snippet.
(4) Rank Value (RV) ?
Aims to consider therank for translation candidates in the Web doc-ument set.
It includes five parameters.Top_Rank (T_Rank) is the rank of the snippetthat first contains TOOV and given by the searchengine.
Average_Rank (A_Rank) is the aver-age position of TOOV in the returned snippets.
( ) ( )( ) )7(_ OOVTOOV TDFRankSumTRankAOOV=where Sum( ) denotes the rank sum of eachsnippet.
Simple_Rank (S_Rank) is computedas S_Rank(TOOV)=TFTOOV(TOOV)*Len(TOOV),which aims at investigating the impact of thefrequency and length of TOOV on ranking.R_Rank is utilized as a comparison basis.
( ) ( ) ( )( ) )8(1__ OOVSOOVTOOVOOV SFreqTTFWLMAXTTRankROOVOOV?
?+?= ?
?where ?
is set as 0.25 empirically, |TOOV| is thelength of TOOV, and MAX_WL denotes the max-imum length of candidate terms.
DF_Rank(D_Rank) is similar to S_Rank and computedas D_Rank(TOOV)=DFTOOV(TOOV)*Len(TOOV).Boolean Feature (BF) is a binary feature andequivalent to a heuristic rule designed for theparticular relationship between an OOV termand its translation candidates.
BFs are used toexplore the different occurrence forms withhigher possibility for the translation candidatesin Web documents.
(1) Position Distance withOOV Term (PD_SOOV) ?
If TOOV occurs closeto SOOV (within 10 characters), then this featureis set as 1, else -1.
(2) Neighbor Relationshipwith OOV Term (NR_SOOV) ?
If TOOV occursprior or next to SOOV, then this feature is set as1.
(3) Bracket Neighbor Relationship withOOV Term (BNR_SOOV) ?
If TOOV locatesprior or next to SOOV and occurs with the form?TOOV (SOOV)?
or ?SOOV (TOOV)?, then this fea-ture is set as 1.
(4) Special Mark Word (SMW)?
This is an intuitive feature.
Within a certainco-occurrence distance (usually less than 10characters) between an OOV term and its can-didates, if there is such a term like ????
(fullname), ???
(be named as), ????
(be trans-lated as ?
), ????
(name), or ?(?/?)???
((or/also) be called as ?
), or within 5 charac-ters if there are some punctuations like ?
( )?,?
[ ]?
and ???
?, then this feature is set as 1.6 Ranking based on Ranking SVMFor the OOV term translation based on Webmining, another difficulty is how to evaluatethe relevance between an OOV term and itstranslation candidates, that is, how to rank thetranslation candidates from ?best?
to ?worst?.The candidate ranking can be regarded as abinary classification problem.
However,usually only highly related fragments of OOVterms can be found, rather than their correcttranslations.
Instead of regarding the candidateranking as binary classification, it is solved asan Ordinal Regression problem.
RankingSVM maps different objects into a certain kindof order relation.
The key is modeling thejudgements for user?s preferences, and then theconstraint relations for ranking can be derived(Herbrich et al, 1999; Xu et al, 2005).For a given OOV term SOOV, if there are twotranslation candidates TOOVi and TOOVj, the pre-ference judgement can be formulated asTOOVi>SOOVTOOVj.
Thus more training samples areconstructed, which contain multiple constraintfeatures.
The preference judgement can betransformed into the feature function as: ( ) ( ) )9(,,,, OOVjOOVSOOViOOV STwfSTwf OOV>where w is a parameter and represented as a n-dimensional vector w={w1, w2, ?, wn}.
Thisfeature function can also be expressed as:( ) ( )( ) ( ) )10(,,,,,111??
?+=+==++=nqmOOVOOVmmqplOOVOOVllpkOOVOOVkkOOVOOVSTBFwSTGFwSTLFwSTwfwhere LFk( , ), GFl( , ) and BFm( , ) are  thelocal, global and Boolean feature representa-tion respectively.
These three kinds of featurerepresentation are incorporated as a whole andrepresented as a feature function family withthe multi-dimensional feature vector in (11).
( ) ( ) )11(,,, OOVOOVOOVOOV SThwSTwf ?=1439That is the ranking results for candidates.
Thusthe relevance for each feature vector x (transla-tion candidate) containing a group of featurescan be evaluated through Ranking SVM.7 Experiment and Analysis7.1 Data Set and Evaluation MetricsFor the performance evaluation, 4,593 EnglishNEs are selected from the English corpus ofthe NER task in CoNLL2003.
The test set con-tains 446 Person Names (PRNs), 329 LocationNames (LCNs) and 455 Organization Names(OGNs), and the remaining is taken as thetraining set (including 1,137 PRNs, 1,152LCNs and 1,074 OGNs) through manuallytagging.
Additionally, 300 English new termsare chosen randomly from 9 categories, includ-ing movie name, book title, brand name, ter-minology, idiom, rare animal name, rare PRNand OGN.
Such terms are used to investigatethe generalization ability of our model.Top-N-Inclusion-Rate is used as a measure-ment for the translation performance.
For a setof OOV terms to be translated, its Top-N-Inclusion-Rate is defined as the percentage ofthe OOV terms whose translations could befound in the first N extracted translations.7.2 Experiment on Parameter SettingFor Chinese key term extraction, the test on thethreshold ?
is performed.
As shown in Figure 3,when the lower bound of ?
is set as 0.4, thebest performance can be achieved.Figure 3.
Results for ?
value setting.To get the most relevant candidates into top-10 before the final ranking, an initial rankingtest is performed on S_Rank, R_Rank andD_Rank.
It can be seen from Figure 4 thatD_Rank exhibits the better performance.Figure 4.
Results for initial ranking manner.To find how many returned webpage snip-pets are suitable for the translation acquisition,the test on the snippet number is performed.
Asshown in Figure 5, the best performance can beobtained by using 200 snippets.Figure 5.
Results for webpage snippet number.7.3  Experiment on Multiple Feature FusionTo verify the effectiveness for multiple featurefusion, the test on the feature combination forOOV term translation is implemented.
Asshown in Table 1, the highest accuracy (thepercentage of the correct translations in all theextracted translations) of 83.1367% can be ac-quired by using all the features.Feature Accuracy ReductionAll Features 83.1367% ?NumericalFeatureLocalNumericalFeature-Len 81.7355% -1.4012%-PV 77.4494% -5.6873%-LR 81.4231% -1.7136%-P&S_IF 79.9002% -3.2365%GlobalNumericalFeatureGlobalFrequency-TFTOOV 82.9877% -0.1490%-DFTOOV 83.2112% +0.0745%-CO_Freq 83.0870% -0.0497%-CV 82.3125% -0.8242%-CO_Dist 81.8577% -1.2790%RV -T_Rank 83.0125% -0.1242%Boolean Feature-PD_SOOV 82.1806% -0.9561%-NR_SOOV 82.2923% -0.8444%-BNR_SOOV 80.7525% -2.3842%-SMW 83.1740% +0.0373%Table 1.
Results for feature combination.In Table 1, ?-?
before the specific featuredenotes that the OOV term is translated bycombining all the other features except thisfeature; ?Reduction?
represents the differencevalue between the translation accuracy ob-tained by using all the features and that by re-moving a specific feature.
The positive ?Re-duction?
indicates that the accuracy is im-proved after removing a specific feature, whilethe negative shows the accuracy is decreased.It can be seen from Table 1 that for miningthe translations for OOV terms, the most im-portant three features are PV, P&S_IF andBNR, then LR, Len and CO_Dist.
As for thefrequency feature, its contribution is limited,because many translation candidates withhigher PV or P&S_IF values are the terms withlow frequency.
It shows that PV and P&S_IFplay a very crucial role in mining the transla-tion candidates with low frequency.
In addition,1440the contribution degree of CV is also positive.However, when training based on only the fea-tures that are beneficial to the whole transla-tion performance, the best translation accuracyis 83.1243%, which is worse than that by com-bining all the features.
From a view of the ef-fect of the single feature on the whole transla-tion performance, some features may haveslightly negative impact.
Nevertheless, throughcombining all the features, the multiple featurefusion mechanism can indeed efficiently im-prove the translation accuracy.7.4   Experiment on OOV Term TranslationSome translation examples based on differentranking patterns are given in Table 2, in whichthe score represents the correlation degree be-tween the translation pair.
The closer to -1 thescore is, the more irrelevant the translation pairis; while the closer to 3 the score is, the morerelevant the translation pair is.PRN -- ?Santamaria?Candidates (Top-5) SVM Score Ranking SVM Score?????
1.1746 3.17754?????
0.7087 2.81014?????
0.9326 2.68914???
0.2879 2.26468???????
0.2051 2.1525LCN -- ?Gettysburg National Military Park?Candidates (Top-5) SVM Score Ranking SVM Score??????????
0.7500 2.4998???????
0.6666 2.4159??????
0.3973 1.8539?????????
0.2877 1.5172??????????????
-0.3407 0.8019OGN -- ?Federal Reserve Board?Candidates (Top-5) SVM Score Ranking SVM Score?????
0.9784 2.7435?????????
0.9483 2.7314????????
0.5387 2.7178?????????
1.2031 2.6684???????
0.7425 2.6003Table 2.
OOV term translation examples.Furthermore, Jiang et al (2007) utilized thecombination of Web mining, transliterationand ME-based ranking to implement English-Chinese PRN translation, which is very similarto our approach.
To make a contrast with it, weaccomplished this method on the same data set.The comparison results are shown in Table 3.Ranking Pattern Category Top-1 Top-2 Top-3based on SVM(Multiple Features)PRN 64.44% 85.07% 91.42%LCN 53.93% 73.33% 81.82%OGN 49.68% 70.70% 82.16%All 56.10% 76.59% 85.45%based on Ranking-SVM(Multiple Features)PRN 77.14% 89.20% 93.96%LCN 64.24% 75.15% 85.45%OGN 63.05% 79.61% 89.17%All 68.46% 81.87% 89.92%[Jiang et al, 2007]based on ME(PV+CV+NR_SOOV+BNR_SOOV)PRN(Only) 49.07% 57.33% 60.43%Table 3.
Performance comparison results.From the experimental results above, it canbe concluded that the ranking based on the su-pervised learning significantly outperforms theconventional ranking strategies, and RankingSVM is superior to SVM and ME for transla-tion candidate ranking.
From the contrast be-tween our model and Jiang?s method, it can befound that our approach is superior to Jiang?sand the better performance can be achievedbased on the fusion of multiple features pro-posed in this paper.
Meanwhile, it can also beobserved from Table 3 that the performancefor LCN and OGN translation is better, whilethe best performance is obtained for PRNtranslation.
It shows that our translation modelis sensitive to the category and the popularitydegree of OOV term to some extent.In order to test the translation performancefor the other kinds of English OOV term,another test is performed based on the OOVnew terms selected randomly from 9 categories.The experimental results are shown in Table 4.Top-N-Inclusion-Rate Top-1 Top-3 Top-5 Top-7 Top-9Other OOV Terms 49.41% 71.02% 72.46% 81.51% 84.30%Table 4.
Results for other OOV terms.Furthermore, the translations for some OOVterms based on different translation mannersare compared, including our proposed model,Google Translate and the Live Trans transla-tion model developed by WKD Lab at Nation-al Taiwan University, as shown in Table 5.OOV Terms Translation fromOur ModelTranslation fromGoogle TranslateTranslation fromLive TransForrest Gump ????/??
????????/?????
?Estee Lauder ???
?/      ???
????????/??/??
?Arteriosclerosis ????
??????
??/???
?WomanPace-Setter ??????????/??
????
?Dream ofthe Red Mansion ??/???
??????/???
?SARS ????
?/  ???????????????/????
?NASA ?????
?????
?????
?Table 5.
Comparison for different translation manners.The results above demonstrate that ourmodel can be applicable to all kinds of OOVterms and has better translation performance.7.5 Experiment on English-Chinese CLIRTo explore the applicability and usefulness ofour OOV term translation model in English-Chinese CLIR, four CLIR runs based on longquery (terms in both title and description fields)and short query (only terms in the title field)are carried out on the English topic set (25 top-ics) and Chinese corpus (127,938 documents)from TREC-9.
(1) E-C_LongCLIR1 ?
usinglong query and the bilingual-dictionary-basedquery translation; (2) E-C_LongCLIR2 ?
usinglong query, the bilingual-dictionary-based1441query translation and our OOV term transla-tion; (3) E-C_ShortCLIR1 ?
using short queryand the bilingual-dictionary-based query trans-lation; (4) E-C_ShortCLIR2 ?
using shortquery, the bilingual-dictionary-based querytranslation  and our OOV term translation.
ThePrecision-Recall curves and Median AveragePrecision (MAP) values are shown in Figure 6.Figure 6.
Results for English-Chinese CLIR com-bining our OOV term translation model.It can be seen from Figure 6 that the best runis E-C_LongCLIR2, and its results exceedthose by another run E-C_LongCLIR1 basedon long query.
By adopting both query transla-tion based on bilingual dictionary and OOVterm translation, the English-Chinese CLIR forlong query has gained the significant im-provement on the whole retrieval performance.Compared with the traditional query transla-tion based on bilingual dictionary, such a com-bination manner is exactly a better way forquery translation from the source language tothe target language.
Additionally, throughcomparing the results for the other two runs E-C_ShortCLIR1 and E-C_ShortCLIR2 based onshort query, it can also be further confirmedthat our OOV term translation mechanism canalso support CLIR for short query effectively.7.6 Analysis and DiscussionThrough analyzing the results for translationextraction and ranking, it can be found that thetranslation quality is highly related to the fol-lowing aspects.
(1) The translation resultsare associated with the search engine used,especially for some specific OOV terms.
Forexample, given an OOV term ?Cross-StraitThree-links?, the mining result based onGoogle in China is ??????
?, while somemeaningless information is mined by LiveTrans.
(2) Some terms are conventional ter-minologies and cannot be translated literally.For example, ?Woman Pace-Setter?, a propernoun with the Chinese characteristic, should betranslated into ??????
?, rather than ???????
(women?s pace) or ????
(estab-lishment) given by Google Translate.
(3) Theproposed model is sensitive to the notabilitydegree of OOV term.
This phenomenon is themain reason why there is obvious differenceamong the translation performance for PRN,LCN and OGN.
(4) There is a ?fragment ef-fect?
in PAT-Tree-based Chinese key termextraction.
The fragments of Chinese termshave become the main noisy data.
Such a prob-lem should be solved by setting the specificthreshold for additional features like heuristicrules and occurrence distance.
(5) Word SenseDisambiguation (WSD) should be added toimprove the translation performance.
Al-though most of OOV terms have a unique se-mantic definition, there are still a few OOVterms with ambiguity, e.g., ?AARP?
(AmericanAssociation of Retired Persons or AppleTalkAddress Resolution Protocol).
(6) The rank-ing pattern based on the supervised learningis able to synthesize various feature repre-sentations for translation candidates.
Thusthe rank for a candidate can be precisely pre-dicted through tagging and training.8 ConclusionsIn this paper, the proposed model improves theacquirement ability for OOV term translationthrough Web mining, and solves the translationpair selection and evaluation in a novel way byfusing multiple features and introducing thesupervised learning based on Ranking SVM.Furthermore, it is significant to apply the keytechniques in machine translation into OOVterm translation, such as OOV term recogni-tion, statistical machine learning, alignment ofsentence and phoneme, and WSD.
All theseaspects will be our research focus in the future.AcknowledgementsThis work is supported by National NaturalScience Fund of China (No.
60773124),Shanghai Natural Science Fund (No.09ZR1403000), National Science and Tech-nology Pillar Program of China (No.2007BAH09B03), 973 Program of China (No.2010CB327906), Shanghai Municipal R&DFoundation (No.
08dz1500109) and ShanghaiKey Laboratory of Intelligent InformationProcessing.
Cheng Jin from Fudan Universityis the corresponding author.1442ReferencesY.
Al-Onaizan, K. Knight.
2002.
TranslatingNamed Entities using Monolingual and BilingualResources.
In: The 30th Meeting of the Associa-tion for Computational Linguistics (ACL 2002),400-408.Y.B.
Cao, J. Xu, T.Y.
Liu, H. Li, Y.L.
Huang, andH.W.
Hon.
2006.
Adapting Ranking-SVM toDocument Retrieval.
In: The 29th Annual Inter-national ACM SIGIR Conference on Researchand Development in Information Retrieval (SI-GIR 2006), 186-193.C.
Chen, H.H.
Chen.
2006.
A High-Accurate Chi-nese-English NE Backward Translation SystemCombining Both Lexical Information and WebStatistics.
In: The Joint Conference of theInternational Committee on ComputationalLinguistics and the Association forComputational Linguistics (COLING-ACL2006), 81-88.L.F.
Chien.
1997.
PAT-Tree-based Keyword Ex-traction for Chinese Information Retrieval.
In:The 20th Annual International ACM SIGIR Con-ference on Research and Development in Infor-mation Retrieval (SIGIR 1997), 50-58.G.L.
Fang, H. Yu, and F. Nishino.
2006.
Chinese-English Term Translation Mining Based on Se-mantic Prediction.
In: The Joint Conference ofthe International Committee on ComputationalLinguistics and the Association forComputational Linguistics (COLING-ACL2006), 199-206.G.H.
Gonnet, R.A. Baeza-Yates, and T. Sinder.1992.
New Indices for Text: PAT Trees and PATArrays.
Information Retrieval Data Structures &Algorithms, 66-82.R.
Herbrich, T. Graepel, and K. Obermayer.
1999.Support Vector Learning for Ordinal Regression.In: The 9th International Conference on NeuralNetworks (ICANN 1999), 97-102.L.
Jiang, M. Zhou, L.F. Chien, and C. Niu.
2007.Named Entity Translation with Web Mining andTransliteration.
In: The 20th International JointConference on Artificial Intelligence (IJCAI2007), 1629-1634.T.
Joachimes.
2002.
Optimizing Search Enginesusing Click through Data.
In: The 8th ACMSIGKDD International Conference on Know-ledge Discovery and Data Mining (SIGKDD2002), 133-142.C.J.
Lee, J.S.
Chang, and J.R. Jang.
2006.
Align-ment of Bilingual Named Entities in ParallelCorpora Using Statistical Models and MultipleKnowledge Sources.
ACM Transactions onAsian Language Processing, 5(2):121-145.W.H.
Lu, L.F. Chien.
2002.
Translation of WebQueries using Anchor Text Mining.
ACM Trans-actions on Asian Language InformationProcessing, 1(2):159-172.W.H.
Lu, L.F. Chien.
2004.
Anchor Text Mining forTranslation of Web Queries: A Transitive Trans-lation Approach.
ACM Transactions on Informa-tion Systems, 22(2):242-269.L.
Shao, H.T.
Ng.
2004.
Mining New Word Trans-lations from Comparable Corpora.
In: The 20thInternational Conference on Computational Lin-guistics (COLING 2004), 618-624.R.
Sproat, T. Tao, and C.X.
Zhai.
2006.
NamedEntity Transliteration with Comparable Corpora.In: The Joint Conference of the InternationalCommittee on Computational Linguistics andthe Association for Computational Linguistics(COLING-ACL 2006), 73-80.V.N.
Vapnik.
1995.
The Nature of StatisticalLearning Theory.
Springer-Verlag New York,Inc., New York, NY.P.
Virga, S. Khudanpur.
2003.
Transliteration ofProper Names in Cross-Language Applications.In: The 26th Annual International ACM SIGIRConference on Research and Development in In-formation Retrieval (SIGIR 2003), 365-366.J.H.
Wang, J.W.
Teng, P.J.
Cheng, W.H.
Lu, andL.F.
Chien.
2004.
Translating Unknown Cross-Lingual Queries in Digital Libraries using aWeb-based Approach.
In: The Joint Conferenceon Digital Libraries (JCDL 2004), 108-116.J.C.
Wu, J.S.
Chang.
2007.
Learning to Find Eng-lish to Chinese Transliterations on the Web.
In:The Joint Meeting of the Conference on Empiri-cal Methods in Natural Language Processing andthe Conference on Computational Natural Lan-guage Learning (EMNLP-CoNLL 2007), 996-1004.J.
Xu, Y.B.
Cao, H. Li, and M. Zhao.
2005.
Rank-ing Definitions with Supervised Learning Me-thods.
In: The 14th International World WideWeb Conference (WWW 2005), 811-819.Y.
Zhang, P. Vines.
2004.
Using the Web for Auto-mated Translation Extraction in Cross-Language Information Retrieval.
In: The 27thAnnual International ACM SIGIR Conferenceon Research and Development in InformationRetrieval (SIGIR 2004), 162-169.Y.
Zhang, P. Vines.
2004.
Detection and Transla-tion of OOV Terms Prior to Query Time.
In: The27th Annual International ACM SIGIR Confe-rence on Research and Development in Informa-tion Retrieval (SIGIR 2004), 524-525.Y.
Zhang, F. Huang, and S. Vogel.
2005.
MiningTranslations of OOV Terms from the Webthrough Cross-Lingual Query Expansion.
In:The 28th Annual International ACM SIGIR Con-ference on Research and Development in Infor-mation Retrieval (SIGIR 2005), 669-670.1443
