RESTRICTING LOGIC GRAMMARSWITH GOVERNMENT-BINDING THEORYEdward P. Stabler ,  Jr. 1Department of Computer ScienceMiddlesex CollegeThe University of Western OntarioLondon, Ontario N6A 5B7 CanadaA parser formalism for natural languages that is so restricted as to rule out the definition of linguisticstructures that do not occur in any natural language can make the task of grammar construction easier,whether it is done manually (by a programmer) or automatically (by a grammar induction system).
Arestrictive grammar formalism for logic programming languages is presented that imposes some of theconstraints uggested by recent Chomskian linguistic theory.
In spite of these restrictions, this formalismallows for relatively elegant characterizations of natural languages that can be translated into efficientprolog parsers.1 INTRODUCTIONThe best-known parser formalisms for logic programmingsystems have typically aimed to be expressive and effi-cient rather than restrictive.
It is no surprise that in thesesystems a grammar writer can define linguistic structuresthat do not occur in any natural anguage.
These unna-tural structures might suffice for some particular process-ing of some particular fragment of a natural language,but there is a good chance that they will later needrevision if the grammar needs to be extended to covermore of the natural anguage.
On the other hand, if thegrammar writer's options could be limited in the rightway, there would be less to consider when a choice hadto be made among various ways to extend the currentgrammar with the aim of choosing an extension that willnot later need revision.
Thus a restricted formalism canactually make it easier to build large, correct, andupward-compatible natural anguage grammars.
A simi-lar point obviously holds for automatic language learningsystems.
If a large class of languages must be considered,this can increase the difficulty of the (grammarinduction) problem of correctly identifying an arbitrarylanguage in the class.
So there are certainly significantpractical advantages to formalisms for natural languageparsers that allow the needed linguistic structures to bedefined gracefully while making it impossible to definestructures that never occur.Recent work in linguistic theory provides some indi-cations about how we can limit the expressive power of agrammar notation without ruling out any humanlanguages.
There appear to be severe constraints on thepossible phrase structures and on the possible"movement" and "binding" relationships that can occur.The exact nature of these constraints is somewhatcontroversial.
This paper will not delve into this contro-versy, but will just show how some of the constraintsproposed recently by Chomsky and others - constraintsto which all human languages are thought o conform -can very easily be enforced in a parsing system thatallows an elegant grammar notation.
These grammars willbe called restricted logic grammars (RLGs).
Two wellknown logic grammar formalisms, definite clause gram-mars (DCGs) and extraposition grammars (XGs), will bebriefly reviewed, and then RLGs will be introduced byshowing how they differ from XGs.
RLGs have a newtype of rule ("switch rules") that is of particular value inthe definition of natural languages, and the automaticenforcement of some of Chomsky's constraints makesRLG movement rules simpler than XGs'.
We follow thework of Marcus (1981), Berwick (1980), Wehrli (1984)and others in pursuing this strategy of restricting thegrammar formalism by enforcing Chomsky's constraints,but we use a simple nondeterministic top-down back-tracking parsing method with lookahead, rather thanMarcus's deterministic LR(k,t)-like parsing method.
Thisapproach to parsing, which has been developed in logicCopydght1987 by the Association for Computational Linguistics.
Permission tocopy without fee all or part of this material isgranted provided thatthe copies are not made for direct commercial dvantage and the CL reference and this copyright notice are included on the first page.
To copyotherwise, or to republish, requires a fee and/or specific permission.0362-613X/87/010001=10503.00Computational Linguistics, Volume 13, Numbers 1-2, January-June 1987 1Edward P. Stabler, Jr.
Restricting Logic Grammars with Government-Binding Theoryprogramming systems by Pereira and Warren (1980) andothers, allows our rules to be very simple and intuitive.Since, on this approach, determinism is not demanded,we avoid Marcus's requirement hat all ambiguity beresolved in the course of a parse.2 DEFINITE CLAUSE GRAMMARSDefinite clause grammars (DCGs) are well known to logicprogrammers.
(See Pereira and Warren (1980) for a fullaccount.)
DCGs are similar to standard context freegrammars (CFGs), but they are augmented with certainspecial features.
These grammars are compiled intoprolog clauses that (in their most straightforward use)define a top-down, backtracking recognizer or parser inprolog.
2.
In the DCG grammar formalism, every rewriterule must expand exactly one nonterminal.A DCG rule that expands a nonterrninal into asequence of nonterminals i very similar to the standardCFG notation, except that when the right-hand side of arule contains more than one nonterminal, some operator(like a comma) is required to collect them together into asingle term.
The rules of the following grammar providea simple example:s -~.
np ,vp .np ~ det ,  n.vp-*- v.det ~ \[the\].n -~.
\[man\].n -~.
\[woman\].v ~ \[reads\].
(DCG 1)The elements of the terminal vocabulary are distin-guished by being enclosed in square brackets.
An emptyexpansion of a category cat is written cat ~ \[ \].
(DCG1) defines a simple context free language that includesthe woman reads.Two additional features provide DCGs with consider-ably more power; that is, they allow us to define a classof languages that properly includes the class defined byDCGs just described (those with only 0-place grammat-ical category symbols).
First, the nonterminals in theDCG rules may themselves have arguments to hold struc-tural representations or special features, and second, theright-hand side of any rule may include not only thegrammatical terminals and nonterminals but also arbi-trary predicates or "tests".
The tests must be distin-guished from the grammatical vocabulary, and so wemark them by enclosing them in braces, e.g., {test}.Pereira and Warren (1980) define a simple translationthat transforms rules like these into Horn clauses inwhich each 0-place nonterminal occurs as a predicatewith two arguments.
These two arguments provide a"difference list" representation of the string that is to beparsed under that nonterminal.
(DCG 1) is translatedinto the following Horn clauses, where variable namesbegin with an uppercase l tter:s(L0,L) :- np(L0,L1) ,  vp(L1,L).np(L0,L) :- det(L0,L1) ,  n(L1,L).vp(L0,L) :- v(L0,L).det(\[the I L\],L).n(\[man I El,L).n(\[woman \[ L\],L).v(\[reads I L\],L).The first of these clauses can be read declaratively as"what remains when L is taken off the tail of L0 is an s ifthe list from L0 to L1 is an np, and the list from L1 to Lis a vp".
The terminals in the rewrite rules are handleddifferently, since they must actually be present in thestring being recognized.
So, for example, the clause fordet says that when the difference between its two listarguments is just the element the, we have a det.
Anempty expansion of a category cat would be translatedinto the clause cat(L,L).Given the standard prolog depth-first, backtrackingproof technique, these clauses define a standard top-down backtracking parser.
To recognize the sentence theman reads, for example, we can ask for a proof of thegoal :- s(\[the, man, reads\],\[ ]).
The original string gets"consumed" from the front as it is passed to each gram-matical predicate that succeeds.Prolog tests and extra arguments on grammatical pred-icates are easily accommodated in the translation to Hornclauses: every n place DCG nonterrninal corresponds toan n+2 place predicate in the prolog translation, wherethe last two added arguments hold the difference lists asabove; and every test is simply conjoined with the trans-lations of the grammatical predicates without adding anyextra arguments.The DCG notation is very powerful.
The fact thatarbitrary prolog tests are allowed makes the notation aspowerful as prolog is: a DCG can effectively parse orrecognize exactly the class of effectively parsable orrecognizable languages, respectively.
Even eliminatingthe tests would not restrict the power of the system.
Weget the full power of pure prolog when we are allowed togive our grammatical predicates arbitrary arguments.With just two arguments to grammatical predicates tohold the difference list representation of the string to beparsed, we could recognize only context free languages,but with the extra arguments, it is not hard to definecontext sensitive languages like anbnc n that are notcontext free (cf., Pereira 1983).3 EXTRAPOSITION GRAMMARSIn spite of the power of DCGs, they are not convenientfor the definition of certain constructions in naturallanguages.
Most notable among these are the"movement" constructions.
These are constructions inwhich a constituent seems to have been moved fromanother position in the sentence.
There are well-knowntraditions in linguistic theory that do not use movementrules at all (cf., e.g., Gazdar et al 1985), but the2 Computational Linguistics, Volume 13, Numbers 1-2, January-June 1987Edward P. Stabler, Jr.
Restricting Logic Grammars with Government-Binding TheoryChomskian tradition ("Government-Binding" theory,and its predecessors) makes crucial use of movementanalyses, specifically the rule move-a.
It is natural tothink of this aspect of Government-Binding theory interms Of the movements of constituents, but as Wasow(1985) and others have noted, the main work done bythe movement rules is to relate ("co-index") positions inthe structural representations of the sentence.
So long asthese relations between structural positions are properlyconstrained, we do not really need to think of therelations as having been established by a movement froman original position (in "d-structure") to a new position(in "s-structure").
3This paper will not provide an introduction to Choms-kian syntax, but the basic idea behind movement rules isfairly easy to illustrate.
There are, for example, goodreasons to regard the relative pronoun that introduces arelative clause as having been moved from a subject orobject position in the clause.
In the following sentences,the relative clauses have been enclosed in brackets, andpositions from which who has moved is indicated by theposition of the co-indexed trace, \[t\]:The woman 1\[who \[t\] i likes books\] reads.The woman \[who i booksellers like \[t\]i\] reads.The woman \[who i the bookseller told me about \[t\]i\]reads.In ATN parsers like LUNAR (Woods 1970),constructions produced by movement are parsed by whatcan be regarded as a context-free parser augmented witha "HOLD" list: when a fronted whTphrase like who isparsed, it can be put into the HOLD list from which it canbe brought o fill (or to allow a co-indexed trace to fill) alater position in the sentence.
Fernando Pereira (1981,1983) showed how a very similar parsing method couldbe implemented in logic programming systems.
Theseaugmented grammars, which Pereira calls extrapositiongrammars (XGs) allow everything found in DCGs andallow, in addition, rules that put an element into a HOLDlist - actually, Pereira calls the data structure analogousto the ATN HOLD list an extraposition list.
So, for exam-ple, in addition to DCG rules, XGs accept rules like thefollowing:nt ... trace ~ RHSwhere the RHS is any sequence of terminals, nonte-rminals, and tests, as in DCGs.
The left side of an XGrule need not be a single nonterminal, but can be anonterminal followed by ' .
.
. '
and by any finite sequenceof terminals or nonterminals.
The last example can beread, roughly, as saying that nt can be expanded to RHSon condition that the category trace is given an emptyrealization later in the parse.
We realize nt as RHS andput trace on the extraposition list.This allows for a very natural treatment of certainmovement constructions.
For example, Pereira points outthat relative clauses can, at first blush, be handled withrules like the following:s * np ,  vp.vp -~ v.vp ~ v ,  np.np ~ det,  n ,  optional relative.np ~ trace.opt ional re lat ive --,.
\[ \].opt ional re lat ive -,.
relative.relative ~ rel marker, s.relqmarker...trace ~ rel pro.rel pro --,.
\[who\].These rules come close to enforcing the regularitynoted earlier: a relative clause has the structure of a rela-tive pronoun followed by a sentence that is missing anoun phrase.
What these rules say is that we can expandthe relative node to a rel marker and a sentence s, andthen expand the rel marker to a relative pronounrel.__pro on condition that some np that occurs after therelative pronoun be realized as a trace that is not realizedat all in the terminal string.It is not hard to see that this set of rules does not quiteenforce the noted regularity, though.
These rules willallow the relative pronoun to be followed by a sentencethat has no trace, so long as a trace can be placed some-where after the relative pronoun.
So, for example, thererules would accept a sentence like:?
the woman \[who i the man reads the book\] reads It\] i.In this sentence, a trace cannot be found in the sentencethe man reads the book, but since the second occurrenceof reads can be followed by an np, we can realize that npas the trace associated with the moved np, who.
But thisis clearly a mistake.To avoid this problem, Pereira suggests treating theextraposition list as a stack, and then "bracketing" rela-tive clauses by putting an element on the stack at thebeginning of the relative clause that must be popped offthe top before the parsing of the relative can be success-fully completed.
This can be accomplished by changingour rule for relatives to the following:relative -~ open,  rel marker, s ,  close.open...close -- \[ \].This prevents movements that would relate anythingoutside the relative clause to anything inside.3.1 THE IMPLEMENTATION OF XGsThe implementation of XGs is quite straightforward.Pereira translates each nonterminal category symbol withn arguments into a predicate with n+4 arguments: thefirst two added arguments hold the difference list repre-sentation of the string to be parsed (as in DCGs), and thesecond two additional arguments hold a representation fthe extraposition list (one argument has the list "comingin", the other holds the list "going out").
A rule like thelast rule defining open, translates into two prolog clauses:one" that rewrites open as the empty terminal string \[ \]and adds close to the top of the extraposition list; andComputational Linguistics, Volume 13, Numbers 1-2, January-June 1987 3Edward P. Stabler, Jr.
Restricting Logic Grammars with Government-Binding Theoryanother that says that close can be expanded as a "virtualconstituent" with no terminal realization at all:open(L,L,X,x(gap,nonterminal,close,X)).close(L,L,X0,X) :- virtual(close,X0,X).
(The functor that connects the elements of the extraposi-tion list is not any standard list constructor, but the func-tor x.)
The predicate virtual used in the rule for close isdefined with the single clause:virtual(NT,x(C,nonterminal,NT,X),X).This just says that we can realize a nonterminal NT (inany context C) just by taking it off the top of the extra-position list.
Like the lists that represent the string to beparsed, the extraposition lists are passed down from afather to the first sibling, and then from sibling to sibling,and so on to every nonterminal node in the tree.
This ismore efficient than treating the gaps as features that arepassed only to the descendants of a node, because of thefact that a particular moved constituent can (in mostcases) correspond to only one trace in a sentence.
Thus,if the subject np of a relative clause is trace, the directobject cannot be; if the direct object is trace, the indirectobject cannot be; and so on.
It makes sense to pass theextraposition list from sibling to sibling rather than justdown from the parent, because only one np can fill anyparticular gap, and often it can be any of a number ofcategories.
4The rest of this paper does not require a full under-standing of Pereira's XGs and their implementation.
Theimportant points are the ones we have noted: the extra-position list is used to capture the movementconstructions that can occur in natural language; it isused as a stack so that putting dummy elements on top ofthe stack can prevent access to the list in inappropriatecontexts; and the extraposition list is passed to everynode of the derivation tree.4 RESTRICTED LOGIC GRAMMARSThe XG rules for moved constituents are really veryuseful.
The restricted logic grammar (RLGs) formalismpresented now maintains this feature in a slightlyrestricted form, so the best way to introduce RLGs is toexplain how they differ from XGs.
They differ in threerespects which can be considered more or less independ-ently.
First, RLGs allow a new kind of rules, which wewill call switch rules.
Second, we will show how the powerof the XG leftward movement rules can be expanded inone respect and restricted in another to accommodate awider range of linguistic constructions.
And finally, weshow how a similar treatment allows constrained right-ward movement.4.1 SWITCH RULESIn the linguistic literature, the auxiliary verb system inEnglish has been one of the most common examples ofthe shortcomings of context free grammars.
The auxiliaryshows some striking regularities.
The basic idea has beenneatly formulated by Akmajian et al (1979) in thefollowing way: "The facts to be accounted for can bestated quite simply: an English sentence can contain anycombination of modal, perfective have, progressive be,and passive be, but when more than one of these is pres-ent, they must appear in the order given, and each of theelements of the sequence can appear at most once.
"These verbs occur before the main verb of the sentence,of course, but the more difficult thing to account forelegantly in a context-free definition is that the first in asequence of verbs can occur before the subject.
So forexample, we have:I have been successful.Have I been successful?
* I been have successful.
* Been I have shccessful?This is a rather peculiar phenomenon: it is as if the welldefined sequences of auxiliaries can "wrap" themselvesaround the (arbitrarily long) subject np of the sentence.
5Most parsers have special rules to try to exploit theregularity between simple declarative sentences and theircorresponding question forms.
Marcus (1980) andBerwick (1982), for example, use a "switch" rule which,when an auxiliary followed by a noun phrase is detectedat the beginning of a sentence, attaches the noun phraseto the parse tree first, leaving the auxiliary in its"unwrapped", canonical position, so that it can be parsedwith the same rules as are used for parsing the declarativeforms.
6Pereira (1983) does not attempt to provide a fullgrammar for English, but it is interesting that he proposesrules that treat the auxiliary inversion on the model ofmovement constructions, proposing a rule rather like thefollowing:s ~ fronted verb, s.fronted verb...aux verb(Features)aux verb(Features).These rules allow us to find an auxiliary verb followedby a sentence that is missing an auxiliary verb with thesame features.
This almost captures the regularity wewant, but it is too permissive in just the way our first setof XG rules for relative clauses was.
These rules wouldallow us to accept strings like:Has he \[t\] been saying that he has been succeeding?
* Has he has been saying that he \[t\] been succeeding?The problem is that we want to make sure that theaux  verb put on the extraposition list is removed rightafter the subject is parsed, not later in the sentence.There is no elegant way to use the bracketing technique,because there is no motivated constituent in thesesentences that contains the fronted auxiliary, the subjectnoun phrase, and the rest of the auxiliary verbs.
Some-thing rather different is required.It turns out to be very easy to implement a rule verymuch like Marcus's inversion rule in logic programmingsystems.
These rules do not put an element in the extra-4 Computational Linguistics, Volume 13, Numbers 1-2, January-June 1987Edward P. Stabler, Jr. Restricling Logic Grammars with Government-Binding Theoryposition list to be removed sometime before the end ofthe sentence.
Rather, when an auxiliary is found at thebeginning of a sentence, its parsing is postponed while anattempt is made to parse an np immediately following it.When that np is parsed, it is just removed from the list ofwords left to parse, leaving the auxiliary verb sequence inits canonical form.
We use a notation like the following:s~ switch(aux verb ,np) ,vp .The predicate switch triggers this special behavior: whenthe first word in the string to be parsed is an aux___.verb,it is ignored while an attempt is made to parse an np; ifthe attempt o parse an np is successful, then an attemptis made to parse a vp given the string that has theaux verb as its first element, followed by whateverfollowed the np.
In general, the argument o switch isalways a term of the form test1, test2, ..., teStn, cat, wheretest 1 .
.
.
.
.
test n are tests on features of the first n lexicalitems in the string, and cat is a nonterminal to be foundin the string that begins with the n+lst  element of thestring to be parsed.The implementation of switch rules is surprisinglyeasy.
7The simple rule given is translated into the follow-ing prolog clause:s(\[First I L0\],L,X0,X) :- aux verb(First) ,np(L0,L1,X0,X1),vp(\[First I L1\],L,X1,X).where aux___.verb(FirsO just checks the dictionary to see ifthis first element of the string is an auxiliary verb.
Acomplete treatment of the English auxiliary system (withnegation and adverbs, etc.)
is more complicated, but thiskind of rule with its simple "look ahead" is exactly whatis needed.
It is even more efficient han the XG approachdiscussed above.4.2 LEFTWARD MOVEMENTWhen introducing the movement rules of XGs above, weconsidered some rules for relative clauses but not rulesfor fronted wh-phrases like the one in In which garagedid you put the car?
or the one in Which car did you put inthe garage?.
The most natural rules for theseconstructions would look something like the following: 8s*wh phrase,s.wh phrase...pp trace(wh feature)--,-pp(wh feature).wh phrase...np trace(wh feature,Case,Agreement)np(wh feature,Case,Agreement).pp~ pp trace(wh feature).np(Case,Agreement)np trace(wh feature,Case,Agreement).If we assume that these rules are included in the grammaralong with the XG rules for relative clauses discussedabove, then we properly exclude any possibility of find-ing the trace of a fronted wh-phrase inside a relativeclause:* What car did the man \[who put \[np trace\] in thegarage\] go?
* In which garage did the man \[who put the car\[pp trace\]\]go?These sentences are properly ruled out by Pereira'sbracketing constraint.There are other restrictions on movement, though,that are not captured by the bracketing constraint onrelative clauses.
The following sentence, for example,would be allowed by rules like the ones proposed above:* \[About what\]i did they burn \[the politician's book\[pp trace\]i\]?
* What i did he ask where I hid \[np trace\]i?
* Who i did I wonder whether she was \[np trace\]i?These movements are unacceptable, but how can they beblocked?
We cannot just use another bracketingconstraint to disallow movements that cross vp bounda-ries, because that would disallow good sentences likeWhat i did they burn \[np trace\]i?.There is a very powerful and elegant set of constraintson movement that covers the cases we have consideredand subsumes the relative clause island constraint: theyare specified by Chomsky's (1981) theories of corefer-ence ("binding") and movement ("bounding").
The"co-indexing" of the moved constituent and its tracemarks a "binding" relationship: the trace is coreferentialwith the moved constituent.
The relevant principles canbe formulated in the following way: 9(i) A moved constituent must c-command iis trace,where a node a c-commands/3 if and only if a doesnot dominate /3, but the first branching node thatdominates a dominates/3.
(ii) No rule can relate a constituent X to constituents Yor Z in a structure of the form:...Y...\[a ...\[/3 ...X...\]...\]...Z ...where a and /3 are "bounding nodes".
(We willassume that the bounding nodes for leftward move-ment in English are s and np.
)The first rule, the c-command restriction on binding,suffices by itself to rule out sentences like the following:* The computer \[which i you wrote the program\] uses\[np trace\] i.
* I saw the man \[who i you knew him\] and I told\[np trace\] i.since the first branching node that dominates who andwhich in these cases is (on any of the prominentapproaches to syntax) a node that does not dominateanything after the him.
The second rule, called subjacen-ey, is a bounding restriction, a restriction on the constitu-ents that can be related by movement.
Subjacency rulesout sentences like* Who i \[s did \[np the man with \[np trace\] i \] like\]?
* \[About what\] i \[s did they burn \[rip my book\[pp trace\]i\]\]?In the first of these sentences, who does c-command thenp trace, but does so across two bounding nodes.
In thesecond of these sentences, notice that the ppt race  isComputational Linguistics, Volume 13, Numbers 1-2, January-June 1987 5Edward P. Stabler, Jr.
Restricting Logic Grammars with Government-Binding Theoryinside the np, so that we are not asking about the burningbut about the content of the book!
This is also properlyruled out by subjacency.There is one additional complication that needs to beadded to these constraints in order to allow sentenceslike:Who i \[s do you think \[s I said \[s I read \[np trace\]i\]\]\]?Who i \[s does Mary think \[s you think \[s I said\[s I read \[np trace\]i\]\]\]\]?These "movements" of wh-phrases are allowed inChomskian syntax by assuming that wh-phrase move-ments are "successive cyclic": that is, the movement tothe front of the sentence is composed of a number ofsmaller movements across one s-node into its cornp node.It is further assumed here that a wh-phrase cannot bemoved out of an s that already has a wh-phrase in itscomp.
This allows the last examples, while disallowingcases like the following:* Who i did you wonder whoj trace i saw tracej?
* Who i did you wonder whoj tracej saw tracei?The implementation of RLG movement rules to auto-matically enforce these constraints i quite natural.
In thefirst place, current syntactic theory does not allow justany constituent to be moved, so we do not need to passthe extraposition list to every node.
It only needs to bepassed to the nodes that could dominate a trace.
Forexample, the passing of the list to det, n, and v nodes isjust wasted effort since none of these categories can bemoved or dominate a trace.
Allowing only certain cate-gories to carry the extraposition list, where those catego-ries are all nonterminals, simplifies the translation toprolog clauses and makes the resulting parser more effi-cient.
(It also makes it convenient to use standard listnotation for the extraposition list.
)The trick then is to restrict he access to the extraposi-tion list so the parser will allow traces only in the posi-tions allowed by Chomsky's constraints.
Thec-command restriction can be enforced by indicating theintroduction of a trace at the first branching node thatdominates the moved constituent, and making sure thatthe trace is found before the parsing of that dominatingnode is complete.
So, for example, we replace the follow-ing three XG rules with two indicated RLG rules:(XG rules)relative * rel marker, s.rel marker.. ,  np t race*  rel pro.rel pro ~ \[who\].
(RLG rules)re la t ive<<<np t race*  rel pro ,s .rel p ro - -  \[who\].The change from the XG functor " .
.
. "
to "<<<" ismade to distinguish this approach to parsing constituentsthat are moved to the left (leaving a trace to the right)from RLG rules for rightward movement.
The XGs addi-tional (linguistically unmotivated) category rel.__.markeris not needed in the RLG because the trace is introducedto the extraposition list after the first category has beenparsed.
1?
So the translation of these RLG rules is similarto the XG translation of XG rules, except that rel.__prosare not passed the extraposition list, the traces areindexed, and a test is added to make sure that the tracethat is introduced to the extraposition list is gone whenthe last constituent of the relative has been parsed:relative(L0,L,X0,X) :- rel pro(L0,L1),s(L1,L,trace(Index).X0,X) ,tracegone(trace(Index),X).This enforces the c-command constraint, because very-thing that is c-commanded by the relative pronounrel___pro is under the relative node.The RLG grammar compiler can enforce subjacencyautomatically by giving special treatment o grammarrules that expand bounding categories.
All that isrequired is the addition of an indication of every bound-ing node that is crossed to the extraposition list, and thenchanging the XG definition of the predicate virtual toallow the appropriate relations across those nodes.
Thegrammar compiler takes care of this by introducing anelement np bound into the extraposition list before anydaughter of an np is parsed, and removing it when the npis complete, and similarly for s nodes.
So the followingRLG rules would be translated as shown:(RLG rules)s ~ np,  vp.np - -  det,  n ,  relative.
(PROLOG translations)s(L0,L,X0,X) :-np(L0,Ll,\[s bound( ) IX0 \ ] ,X1) ,vp(L1,L,Xl,\[s bound( ) IX \ ] ) .np(L0,L,X0,X) :-det(L0,L1),n(L1,L2),relative(L2,L,\[np bound I X0\],\[np bound I X\]).The prolog translation for s puts s___.bound(__..) on top ofthe incoming extraposition list X0, and removes it fromthe outgoing extraposition list, returning just X. Theargument of ~.___bound(...) in this bound indicator is ananonymous var iab le , ,  whose value indicates whetherthe comp node corresponding to the bound has or hashad a wh-phrase in it.
Since nps do not have comp posi-tions for elements to move into or through, npboundhas no argument.Now it is clear that we cannot just use the extraposi-tion list as a stack: we have introduced the indications ofbounding nodes, and we have indexed the traces.
Thelatter point means that the traces will have to be placednot just in any place where a trace is allowed; each traceis uniquely associated with a moved phrase and must beplaced in a position where the moved phrase could havecome from.
For example, it is easy to see that the follow-ing co-indexed relationships are not acceptable:* what i does the man whoj trace i reads like tracej?6 Computational Lingqdstics, Volume 13, Numbers 1-2, January-June 1987Edward P. Stabler, Jr.
Restricting Logic Grammars with Government-Binding TheoryThis sentence with the marked movements i  ruled out bysubjacency.
The same sentence with properly nestedco-indexing, on the other hand, is acceptable and isallowed by subjacency.In any case, it is clear that the extraposition list cannotliterally be treated as a stack.
The presence of the bound-ing node markers allows us to implement subjacency withthe rule that a trace cannot be removed from a list if it iscovered by more than one bounding marker, unless thetrace is of a wh-phrase and there is no more than onecovering bound that has no available comp argument.The following rules for virtual are a good first approxi-mation:virtual(NT,\[NT I X\],X).virtual(NT,\[np bound,NT I X\],\[np bound I X\]).virtual(NT,\[s bound(NT),NT I X\],\[s bound(NT) I X\]).virtual(NT,\[s bound(NT) I X\],\[s bound(NT) I Y\]) :-wh(NT) ,  virtual(NT,X,Y).The first of these rules just takes a trace off the top ofthe list, returning the remainder of the list.
The secondand third rules allow a trace to be removed from under asingle np bound or s.__bound.
The fourth rule allows atrace to be removed from under any number ofs.___bounds, filling the comp argument of each with themoved constituent fi to make it unavailable for otherwh-phrases.These rules about access to the extraposition list donot allow the removal of one trace from under another:the traces themselves are available on a strictly last in,first out basis, as if they were in a stack.
This has theconsequence that moved constituent-trace r lations canonly be properly nested, as in:\[Which violins\]i are \[the sonatas\]j easy to play tracejon trace i* \[Which violins\] i are \[the sonatas\]j easy to play trace ion tracejAn argument against this restriction on co-indexedrelations comes from sentences like the following: 11What i do you know howj to read trace i tracei?Fodor (1983) has argued, though, that this sort of cross-ing relation can only occur with traces of different cate-gories: in the last example, the crossing relations betweenan adverb and a noun phrase can occur, but crossingrelations between two noun phrases and their tracescannot occur (unless that relation is dictated by subja-cency or other constraints).
So we must allow one traceto be removed from the list across another when the trac-es are o f  different linguistic categories.
This modificationis easily made: the required modification in the defi~aitionof virtual is straightforward.Since the aim of this paper is to turn over to the gram-mar compiler the enforcement of universal constraints inorder to simplify the task of grammar construction, itshould be noted that the implementation of subjacencyjust described, while it may be appropriate for English, isnot appropriate for any language in which the boundingnodes are not s and np.
Rizzi (1982) has argued thatthere is variation among languages in the selection ofbounding nodes: in particular, he argues that the bound-ing nodes in Italian are s bar and np.
The RLG gram-mar compiler can easily accommodate this variableparameter: the appropriate bounding nodes just need tobe marked so that they can be submitted to the specialtreatment described here.
Similarly, the approach justdescribed requires that the grammar compiler knowwhich categories can dominate a trace.
It is easy toaccommodate variation here as well.
Our current imple-mentation requires that the grammar writer specify whatthese nodes are, but it would be possible to implement atwo-pass grammar compiler that would compute thesenodes after its first pass and then do the appropriatecompilation in to prolog clauses.
12In summary, to put the matter roughly, access to theRLG extraposition list is less restrictive than access to theXGs because the list of traces is not treated as a stack -we allow a trace to be removed from the list acrossanother of a different category; but it is more restrictivein enforcing the c-command and subjacency constraintsand because of the restrictions on the nodes at which theextraposition list is available.
These restrictions allow aconsiderable simplification in the grammar ules whilepreserving enough flexibility to allow for relevant vari-ations among different natural anguages.
134.3 RIGHTWARD MOVEMENTAlthough the preceding account does successfullyenforce subjacency for leftward movement, no provisionshave been made for any special treatment of rightwardmoved constituents, as in sentences like the following:\[The man \[t\]i\] arrived \[who I told you about\] i.\[What book \[t\] i\]arrived \[about the arms race\]i?
* The woman \[who likes \[the man \[t\]i\]\] arrived\[who I told you about\] i.
* What woman \[who likes \[the book \[t\]i\]\] arrived\[about the arms race\]i?It is worth pointing out just briefly how these can beaccommodated with techniques imilar to those alreadyintroduced.It should be noted that some phrase structureapproaches do not relate (what we are treating as) right-ward moved constituents to any other positions in thesentence structure (leaving that to the semantics), but wewill follow the Chomskian tradition in assuming that thesyntactic parser should mark this relation.
There are anumber of ways to do this:?
The standard top-down left-to-right strategy of"guessing" whether there is a rightward movedconstituent would obviously be expensive.
Backtrack-ing all the way to wherever the incorrect guess wasmade is an expensive process, since a whole sentencewith arbitrarily many words may intervene betweenthe incorrect guess and the point where the error caus-es a failure.Computational Linguistics, Volume 13, Numbers 1-2, January-June 1987 7Edward P. Stabler, Jr.
Restricting Logic Grammars with Government-Binding Theory?
One strategy for avoiding unnecessary backtracking isto use lookahead, but obviously, the lookahead cannotbe bounded by any particular number of words in thiscase.
More sophisticated lookahead (bounded to acertain number of linguistically motivated constitu-ents) can be used (cf., Berwick 1983), but thisapproach requires a complicated buffering and parse-building strategy.?
A third approach would involve special backwardmodification of the parse tree, but this is inelegant andcomputationally expensive.?
A fourth approach in left-to-right parsing is to leavethe parse tree to the left unspecified, passing a vari-able to the right.This last strategy can be implemented quite elegantly andfeasibly, and it allows for easy enforcement of subjacen-cy.To handle optional rightward "extraposition from np"using this last strategy, we use rules like the following:s ~ np, vp, opt iona lad junct .optional adjunct ~ \[ \].opt iona lad junct  ~ adjunct.optional re in  rel.opt ionalnrel  > > > ((adjunct ~ rel) ; Tree).In these rules, Tree is the variable that gets passed to theright.
The last rule can be read informally as saying thatoptional__.rel has the structure Tree, where the content ofTree will be empty unless an adjunct category isexpanded to a rel, in which case Tree can be instantiatedto a trace that can be co-indexed with rel.The situation here is more complicated than the situ-ation in leftward movement.
In rightward movement,following Baltin (1981), we provide a special node forattachment, the adjunct node.
This violation of the"structure preserving constraint" has been well motivatedby linguistic considerations.
The adjunct node can donothing but capture rightward moved pps or relativeclauses.
14A second respect in which rightward movement ismore complicated to handle than leftward movement is inthe enforcement of subjacency.
Since in a left-to-rightparse, rightward movement proceeds from an embeddedtrace position to the moved constituent, we must removeboundary indicators across the element in the extraposi-tion list that indicates a possible rightward movement.So to enforce subjacency, we cannot count boundaryindicators between the element and the top; rather wemust count the boundary indicators that have beenremoved across the element.
Subjacency can beenforced only if the element of the extraposition list thatcarries Tree to the right can also mark whether a bound-ing category has been passed (i.e., when the parse of adominating bounding category has been completed).
Inoptional movement, the crossing of a second boundingcategory can just instantiate Tree to the empty list.
Weuse an element in the extraposition list of the formright(Rule, Tree, BoundFlag).
Crossing one bound instanti-ates BoundFlag," crossing a second bound instantiatesTree to the empty list and removes the element from theextraposition list.
Again, the elaboration of the definitionof virtual required to implement these ideas is fairly easyto supply.One approach to implementing a rightward movementrule like the one above is to translate it into two prologclauses, one to initiate the rightward movement, and oneproviding the landing site:optional reI(L,L,X,\[right ((adjunct (S0,S,H0,H) :-rel(S0,S,H0,H)),Tree,Bound) I X\]).adjunct(L0,L,X0,X) :-r ightward(X0,Xl,adjunct(L0,L,X1,X).The head of the Rule, which is the first argument of theelement right(Rule, Tree, BoundFlag), specifies where themoved constituent can "land"; the body of the Rule tellsus what constituent has been moved.
The predicate right-ward is defined as part of the grammar interpreter:rightward(X0,X,Cat) :-find constituent(X0,X,(Cat:-RHS)), RHS.find constituent (X0,X,(Cat:-RHS)) :-X0= \[right ( (Cat : -RHS) , t race, j )  IX\].find constituent(X0,\[right(R,T,B) I X\],(Cat:-RHS)) :-X0= \[right(R,T,B) IX1\],find constituent(X1 ,X,(Cat:-RHS)).This enforcement of subjacency in rightward movementimmediately rules out the two ungrammatical examplesshown above.5 CONCLUSIONS AND FUTURE WORKEven grammar notations with unlimited expressive powercan lack a graceful way to define certain linguistic struc-tures.
DCGs have universal power, but XGs immediatelyoffer a facility for elegant characterization of the move-ment constructions common in natural anguages.
RLGsare one more step in this direction toward a notation forlogic grammars that is really appropriate for naturallanguages.
RLGs provide "switch rule" notation to allowfor elegant characterization of "inverted" or "wrapped"structures, and a notation for properly constrained left-ward and rightward movement, even when the resultingbindings are not properly nested.
Getting these results inan XG would be considerably more awkward.
15A fairly substantial RLG grammar for English hasbeen constructed, and it runs efficiently, but the realargument for RLGs is that their rules for movement aremuch simpler than would be possible if constraints onmovement were not automatically enforced.
We areexploring the automatic enforcement of more of the prin-ciples of government and binding theory.
It is unfortu-nate that efficient implementation of these constraintsrequires such careful attention to the procedural detailsof the parsing mechanism.
To formalize the problem ofimplementing these constraints, we are designing a"grammar grammar" that automatically compiles an8 Computational Linguistics, Volume 13, Numbers 1-2, January-June 1987Edward P. Stabler, Jr.
Restricting Logic Grammars with Government-Binding Theoryelegant, modular, logical statement of grammatical princi-ples into a parser that properly and efficiently enforcesthem.
This work extends the current approach anddiffers from the approach of Barton (1984), Barton andBerwick (1985), and others in that the constraints arerepresented explicitly rather than being respected invirtue of the of architecture of the parsing mechanism.REFERENCESAkmajian, A.; Steele, S.; and Wasow, T. 1979 The Category AUX inUniversal Grammar.
Linguistic Inquiry 10: 1-64.Baltin, M.R.
1981 Strict Bounding.
In Baker, C.L.
and McCarthy, J.J.,Eds., The Logical Problem of Language Acquisition.
MIT Press,Cambridge, Massachusetts.Barton, E. 1984 Toward a Principle-Based Parser.
A.I.
Memo 788,Artificial Intelligence Laboratory, Massachusetts Institute of Tech-nology, Cambridge, Massachusetts.Barton, E. and Berwick, R.C.
1985 Parsing with Assertion Sets andInformation Monotonicity.
Proceedings of the 9th 1JCAI.
LosAngeles, California.Berwick, R.C.
1982 Locality Principles and the Acquisition of SyntacticKnowledge.
Ph.D. dissertation, Massachusetts Institute of Technol-ogy, Cambridge, Massachusetts.Berwick, R.C.
1983 A Deterministic Parser with Broad Coverage.Proceedings of the 8th IJCAI.
Karlsruhle, Germany.Berwick, R.C.
and Weinberg, A.S. 1985 Deterministic Parsing andLinguistic Explanation.
MS, forthcoming in Language and CognitiveProcesses.Chomsky, N. 1981 Lectures on Government and Binding.
Foris Publica-tions, Dordrecht, Holland.Colmerauer, A.
1978 Metamorphosis Grammars.
In Bolc, L., Ed.,Natural Language Communication with Computers.
Springer-Verlag.Dahl, V. 1984 More on Gapping Grammars.
Proceedings of the Interna-tional Conference on Fifth Generation Computer Systems.Fodor, J.D.
1983 Phrase Structure Parsing and the Island Constraints.Linguistics and Philosophy 6: 163-223.Gazdar, G.; Klein, E.; Pullum, G.; and Sag, I.
1985 Generalized PhraseStructure Grammar.
Harvard University Press, Cambridge, Massa-chusetts.Manzini, M.R.
1983 On Control and Control Theory.
LinguisticInquiry 14(3): 421-446.Marcus, M. 1980 A Theory of Syntactic Recognition for NaturalLanguage.
MIT Press, Cambridge, Massachusetts.Pereira, F. 1981 Extraposition Grammars.
American Journal of  Compu-tational Linguistics 7:243 -256.Pereira, F. 1983 Logic for Natural Language Analysis.
Technical Note275, SRI International, Menlo Park, California.Pereira, F. 1985 Note on "DCGs and Parsing Strategy".
Prolog Digest3(41).Pereira, F. and Warren, D.H.D.
1980 Definite Clause Grammars forNatural Language Analysis.
Artificial Intelligence 13: 231-278.Pollard, C. \]984 Generalized Phrase Structure Grammars, Head Gram-mars, and Natural Language.
Ph.D. dissertation, Stanford Universi-ty, Palo Alto, California.Rizzi, L. 1982 Issues in Italian Syntax.
Foris Publications, Dordrecht,Holland.Stabler, E.P.
Jr. 1983 Deterministic and Bottom-Up Parsing in Prolog.Proceedings of the National Conference on Artificial Intelligence,AAAI-83.Wasow, T. 1985 Postscript.
In Sells, P., Ed., Lectures on ContemporarySyntactic Theories.
Center for the Study of Language and Informa-tion, Stanford University.Wehrli, E. 1984 A Government-Binding Parser for French.
WorkingPaper No.
48, Institut pour les I~tudes Semantiques et Cognitives,Universit6 de Geneve, Geneva, Switzerland.Woods, W.A.
1970 Transition Network Grammars for NaturalLanguage Analysis.
Communications of the A CM 13: 591-606.NOTES1.
I am indebted to Janet Dean Fodor, Fernando Pereira, and YuriyTarnawsky for helpful discussions of this material.
Discussionsafter a presentation of parts of this material at the University ofToronto in March 1986 also inspired some significant improve-ments, as did the comments of an anonymous referee.
RichardO'Keefe provided valuable advice on aspects of the design of theprolog implementations.2.
Tffe qualification "in their most straightforward use" really is /necessary.
As noted below, DCGs with tests or with grammaticalpredicates that have more than two arguments have the fulluniversal power of prolog.
It is no surprise, then, that DCGs canbe used to define bottom-up arsers, as Pereira (1985) points out.The DCG notation is actually a convenient one for the definitionof all sorts of parsers.
They provide a convenient representationof the string to be parsed, as we will see.3.
Chomsky (1981, p.33) points this out as well: "It is immaterial ...whether Move-a is regarded as a rule forming s-structure fromd-structure, or whether it is regarded as a property of s-structuresthat are 'base-generated'....
It is in fact far from clear that there isa distinction apart from terminology between these two formula-tions."4.
Parasitic gaps complicate the story here - hence the parentheticalqualification "in most cases", above.
In certain cases a singlemoved constituent can have two gaps, as in Which articles didDana file \[t\] without reading It\]?.
Gazdar et al (1985) in factproposes an analysis according to which any gap can be passed toboth the NP and the VP under an S node.
Consequently, theirgrammar accepts ome strange things like Which authors did review-ers of\[t\] always detest \[t\]?.
In a practical system, one wants to avoidgetting parses that are as unlikely to occur as these.
A morerestrictive Chomskian analysis of parasitic gaps has been proposedand looks like it may be usable in parsing with methods for left-ward movement like those described below.
Roughly, when the"real" trace is found, the trick is to put another special operator inthe extraposition list that allows a subjacent parasitic gap butdoesn't require one (Berwick and Weinberg 1985).
(I do not meanto claim that a restrictive GPSG analysis of parasitic gaps could notbe formulated - Gazdar et al (1985) is just an example of a rela-tively unrestricted analysis.)5.
This sort of rule may be useful for other constructions as well.Pollard (1984) argues that, even just in English, a similar"wrapping" analysis is appropriate for many constructions: thephrase take to task seems to wrap around its object in take Kim totask; the phrase much taller than Sandy seems wrapped into theadjective phrase in Kim is a much taller person than Sandy; and asimilar wrap analysis is proposed to relate Kim is very easy to pleaseand Kim is a very easy person to please.6.
Actually, Marcus (1980) used a special subject-auxiliary inversionrule, and Berwick (1982) noted that the effect of Marcus's rulecan be achieved with a very simple "switch" mechanism that canbe assumed to be one of a small set of primitive parser operations.7.
The "lookahead" technique used here for switch rules is describedin a slightly more general form in Stabler (1983).8.
Notice that we need different symbols for traces of different cate-gories, since our trace handling mechanism does not check theidentity of the node dominating a trace It\].9.
The principles actually proposed in Chomsky (1981) are a littlemore complex, but the versions formulated here suffice for illus-trating the basic approach which can be applied to the moresophisticated formulations.
In spite of the simplification, theversions presented here provide the desired simplification of thegrammar rules.10.
In any case in which the moved element was not the first siblingunder the dominating branching node, a different sort of rulewould have to be used.
We allow the three place predicate'<<<'(Nt,Trace,N),  where Nt can have at most M daughters andN E \[1,2,...,M-I\].
These rules introduce the Trace into the extra-position list after the Nth daughter of Nt.
Since'<<<'(Nt,Trace,1) is the most common case in English, we give itthe short form 'Nt<<<Trace' .Computational Linguistics, Volume 13, Numbers 1-2, January-June 1987 9Edward P. Stabler, Jr.
Restricting Logic Grammars with Government-Binding Theory11.
One other common construction with crossing bindings that Fodor(1983) mentions i  illustrated with examples like Who didyou ask 1 jtrace whether PRO to blame yourselfi?
As indicated the subject of, J J 'the embedded clause in this construction is not a trace producedby a movement but another type of empty category: a base-gener-ated pronominal element which is controlled by the higher subject.A movement analysis would be inappropriate for theseconstructions (Chomsky 1981; Manzini 1983).12.
A compiler that will do this is under construction, together with aproof of its correctness.
A complete account is beyond the scopeof this paper, but the idea is easy to see.
Basically, on the firstpass we construct a CFG corresponding to.the RLG being proc-essed, a CFG that would generate the same derivations as the RLGexcept hat it is not restricted by the requirements about the pres-ence of appropriate lements in the extraposition list for theexpansion of np or of a wh phrase to a trace.
We then computethe nodes that can dominate traces in this CFG, working back-wards from the right hand sides of the rules.
In specifiable cases(which will typically hold), this set will be exactly the set of nodesthat can in fact dominate the traces in RLG derivations; otherwise,it is a superset of the set of nodes that can dominate the traces inRLG derivations (though this superset will typically still be a prop-er subset of the set of nonterminals, and hence useful).13.
Notice that the XG rules that were shown as examples are compa-rable in complexity to the RLG rules shown, but the XG rules wereincorrect in the crucial respects that were pointed out!
The XGrules shown allowed ungrammatical sentences (viz., violations ofthe subjacency and c-command constraints) that the RLG rulesproperly rejected.
The XG rules that properly rule out these caseswould be considerably more complex.14.
These rules for rightward movement are oversimplified.
Mostlinguists in the Government-Binding tradition follow Baltin (1981 )and others in assuming that phrases extraposed from inside a vpare attached inside of that vp, whereas phrases extraposed fromsubject position are attached at the end of the sentence (in roughlythe position we have ~narked adjunct).
Baltin (1981) points outthat this special constraint on rightward movement seems to holdin other languages as well, and that we can capture it by countingvp as a bounding category for rightward movement.
This approachcould easily be managed in the framework we have set up here,though we do not currently have it implemented.
Notice thatalthough rightward movement is not structure-preserving on thislinguistic approach, the parser rules for this movement are struc-ture-preserving in the trivial sense that they supply the categoryadjunct just to accommodate hese movements.15.
Colmerauer's (1978) MGs, Dahl's (1984) GGs, and other systemsare very powerful, and they sometimes allow fairly elegant rulesfor natural anguage constructions, but they are not designed toautomatically enforce constraints: that burden is left to the gram-mar writer, and it is not a trivial burden.10 Computational Linguistics, Volume 13, Numbers 1 -2 ,  January- June 1987
