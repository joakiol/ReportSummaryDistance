Sentence-Internal Prosody Does not Help Parsing the Way Punctuation DoesMichelle L GregoryBrown Universitymgregory@cog.brown.eduMark JohnsonBrown UniversityMark Johnson@Brown.eduEugene CharniakBrown Universityec@cs.brown.eduAbstractThis paper investigates the usefulness ofsentence-internal prosodic cues in syntac-tic parsing of transcribed speech.
Intu-itively, prosodic cues would seem to pro-vide much the same information in speechas punctuation does in text, so we tried toincorporate them into our parser in muchthe same way as punctuation is.
We com-pared the accuracy of a statistical parseron the LDC Switchboard treebank corpusof transcribed sentence-segmented speechusing various combinations of punctua-tion and sentence-internal prosodic infor-mation (duration, pausing, and f0 cues).With no prosodic or punctuation informa-tion the parser?s accuracy (as measured byF-score) is 86.9%, and adding punctuationincreases its F-score to 88.2%.
However,all of the ways we have tried of addingprosodic information decrease the parser?sF-score to between 84.8% to 86.8%, de-pending on exactly which prosodic infor-mation is added.
This suggests that forsentence-internal prosodic information toimprove speech transcript parsing, eitherdifferent prosodic cues will have to usedor they will have be exploited in the parserin a way different to that used currently.1 IntroductionAcoustic cues, generally duration, pausing, andf0, have been demonstrated to be useful for auto-SINTJUHOh,,NPPRPIVPVBDlovedNPPRPit..Figure 1: A treebank style tree in which punctuationis coded with terminal and preterminal nodes.matic segmentation of natural speech (Baron et al,2002; Hirschberg and Nakatani, 1998; Neiman etal., 1998).
In fact, it is generally accepted thatprosodic information is a reliable tool in predict-ing topic shifts and sentence boundaries (Shriberget al, 2000).
Sentences are generally demarcatedby a major fall (or rise) in f0, lengthening of thefinal syllable, and following pauses.
However,the usefulness of prosodic information in sentence-internal parsing is less clear.
While assumed notto be a one-to-one mapping, there is evidencethat there is a strong correlation between prosodicboundaries and sentence-internal syntactic bound-aries (Altenberg, 1987; Croft, 1995).
For exam-ple, Schepman and Rodway (2000) have shown thatprosodic cues reliably predict ambiguous attach-ment of relative clauses within coordination con-structions.
Jansen et al (2001) have demonstratedthat prosodic breaks and an increase in pitch rangecan distinguish direct quotes from indirect quotes ina corpus of natural speech.This paper evaluates the accuracy of a statisticalparser whose input includes prosodic cues.
The pur-pose of this study to determine if prosodic cues im-prove parsing accuracy in the same way that punc-tuation does.
Punctuation is represented in the vari-ous Penn treebank corpora as independent word-liketokens, with corresponding terminal and pretermi-nal nodes, as shown in Figure 1 (Bies et al, 1995).Even though this seems linguistically highly un-natural (e.g., punctuation might indicate supraseg-mental prosodic properties), statistical parsers gen-erally perform significantly better when their train-ing and test data contains punctuation representedin this way than if the punctuation is stripped outof the training and test data (Charniak, 2000; En-gel et al, 2002; Johnson, 1998).
On the Switch-board treebank data set using the experimental setupdescribed below we obtained an F-score of 0.882when using punctuation and 0.869 when punctua-tion was stripped out, replicating previous experi-ments demonstrating the importance of punctuation.
(F-score is a standard measure of parse accuracy, seee.g., Manning and Schu?tze (1999) for details).This paper investigates how prosodic cues, whenencoded in the parser?s input in a manner similar tothe way the Penn treebanks encode punctuation, af-fect parser accuracy.
Our starting point is the ob-servation that the Penn treebank annotation of punc-tuation does significantly improve parsing accuracy.Coupled with the assumption that punctuation andprosody are encoding similar information, this ledus to try to encode prosodic information in a man-ner that was as similar as possible to the way thatpunctuation is encoded in the Penn treebanks.For example, commas in text and pauses in speechseem to convey similar information.
In fact, whentranscribing speech, commas are often used to de-note a pause.
Thus, given the correlation betweenthe two, and the fact that sentence-internal punctu-ation tends to be commas, we expected that pauseduration, coded in a way similar to punctuation,would improve parsing accuracy in the same waythat punctuation does.While it may be the case that the encoding ofprosodic information used in the experiments be-low is perhaps not optimal and the parser has notbeen tuned to use this information, note that exactlythe same objections could be made to the way thatpunctuation is encoded and used in modern statis-tical parsers, and punctuation does in fact dramati-cally improve parsing accuracy.We focus in this paper on parsing accuracy in amodern statistical parsing framework, but it is im-portant to remember that prosodic cues might helpparsing in other ways as well, even if they do not im-prove parsing accuracy.
No?th et al (2000) point outthat prosodic cues reduce parsing time and increaserecognition accuracy when parsing speech latticeswith the hand-crafted Verbmobil grammar.
Page 266of Kompe (1997) discusses the effect that incorpo-rating prosodic information has on parse quality inthe Verbmobil system using the TUG unificationgrammar parser: out of the 54 parses affected bythe addition of prosodic information, 33 were judged?better with prosody?, 14 were judged ?better with-out prosody?
and 7 were judged ?unclear?.
Ourexperiments below differ from the experiments ofNo?th and Kompe in many ways.
First, we usedspeech transcripts rather than speech recognizer lat-tices.
Second, we used a general-purpose broad-coverage statistical parser rather than a unificationgrammar parser with a hand-constructed grammar.2 MethodThe data used for this study is the transcribed ver-sion of the Switchboard Corpus as released bythe Linguistic Data Consortium.
The SwitchboardCorpus is a corpus of telephone conversations be-tween adult speakers of varying dialects.
The cor-pus was split into training and test data as de-scribed in Charniak and Johnson (2001).
The train-ing data consisted of all files in sections 2 and 3 ofthe Switchboard treebank.
The testing corpus con-sists of files sw4004.mrg to sw4153.mrg, while filessw4519.mrg to sw4936.mrg were used as develop-ment corpus.2.1 Prosodic variablesProsodic information for the corpus was ob-tained from forced alignments provided byHamaker et al (2003) and Ferrer et al (2002).Hamaker et al (2003) provided word alignmentsbetween the LDC parsed corpus and new alignmentsof the Switchboard Coprus.
Most of the differencesbetween the two alignments were individual lexicalitems.
In cases of differences, we kept the lexicalitem from the LDC version.
Ferrer et al (2002)provided very rich prosodic information includingduration, pausing, f0 information, and individualspeaker statistics for each word in the corpus.
Theinformation obtained from this corpus was alignedto the LDC corpus.It is not known exactly which prosodic vari-ables convey the information about syntactic bound-aries that is most useful to a modern syntacticparser, so we investigated many different com-binations of these variables.
We looked forchanges in pitch and duration that we expectedwould correspond to syntactic boundaries.
Whilewe tested many combinations of variables, theywere mainly based on the variables PAU DUR N,NORM LAST RHYME DUR, FOK WRD DIFF MNMN N,FOK LR MEAN KBASELN and SLOPE MEAN DIFF N inthe data provided by Ferrer et al (2002).While Ferrer (2002) should be consulted for fulldetails, PAU DUR N is pause duration normalized bythe speaker?s mean sentence-internal pause dura-tion, NORM LAST RHYME DUR is the duration of thephone minus the mean phone duration normalizedby the standard deviation of the phone duration foreach phone in the rhyme, FOK WRD DIFF MNMN NGis the log of the mean f0 of the current word,divided by the log mean f0 of the followingword, normalized by the speakers mean range,FOK LR MEAN KBASELN is the log of the mean f0of the word normalized by speaker?s baseline, andSLOPE MEAN DIFF N is the difference in the f0 slopenormalized by the speaker?s mean f0 slope.These variables all range over continuous values.Modern statistical parsing technology has been de-veloped assuming that all of the input variables arecategorical, and currently our parser can only usecategorical inputs.
Given the complexity of the dy-namic programming algorithms used by the parser,it would be a major research undertaking to developa statistical parser of the same quality as the oneused here that is capable of using both categoricaland continuous variables as input.In the experiments below we binned the contin-uous prosodic variables to produce the actual cate-gorical values used in our experiments.
Binning in-volves a trade-off, as fewer bins involve a loss ofinformation, whereas a large number of bins splitsthe data so finely that the statistical models used inthe parser fail to generalize.
We binned by first con-structing a histogram of each feature?s values, anddivided these values into bins in such a way that eachbin contained the same number of samples.
In runsin which a single feature is the sole prosodic featurewe divided that feature?s values into 10 bins, whileruns in which two or more prosodic features wereconjoined we divided each feature into 5 bins.While not reported here, we experimented with awide variety of different binning strategies, includ-ing using the bins proposed by Ferrer et al (2002).In fact the number of bins used does not affect theresults markedly; we obtained virtually the same re-sults with only two bins.We generated and inserted ?pseudo-punctuation?symbols based on these binned values that were in-serted into the parse input as described below.
Ingeneral, a pseudo-punctuation symbol is the con-junction of the binned values of all of the prosodicfeatures used in a particular run.
When map-ping from binned prosodic variables to pseudo-punctuation symbols, some of the binned valuescan be represented by the absence of a pseudo-punctuation symbol.Because we intend these pseudo-punctuationsymbols to be as similar as possible to normal punc-tuation, we generated pseudo-punctuation symbolsonly when the corresponding prosodic variable fallsoutside of its typical values.
The ranges are givenbelow, and were chosen so that they align withbin boundaries and result in each type of pseudo-punctuation symbol occuring on 40% of words.Thus when a prosodic feature is used alone only 4 ofits 10 bins are represented by a pseudo-punctuationsymbol.However, when two or more types of the prosodicpseudo-punctuation symbols are used at once thereis a larger number of different pseudo-punctuationsymbols and a greater number of words appear-ing with a following pseudo-punctuation symbol.For example, when P, R and S prosodic annota-tions are used together there are 89 distinct typesof prosodic pseudo-punctuation symbols in our cor-pus, and 54% of words are followed by a prosodicpseudo-punctuation symbol.The experiments below make use of the followingtypes of pseudo-punctuation symbols, either aloneor concatenated in combination.
See Figure 2 foran example tree with pseudo-punctuation symbolsinserted.Pb This is based on the bin b of the binnedPAU DUR N value, and is only generated whenthe PAU DUR N value is greater than 0.285.Rb This is based on the bin b of the binnedNORM LAST RHYME DUR value, and is onlygenerated that value is greater than -0.061.Wb This is based on the bin b of the binnedFOK WRD DIFF MNMN N value, and is only gen-erated when that value is less than -0.071 orgreater than 0.0814.Lb This is based on the bin b of theFOK LR MEAN KBASELN value, and is onlygenerated when that value is less than 0.157 orgreater than 0.391.Sb This is based on the bin b of theSLOPE MEAN DIFF N value, and is onlygenerated whenever that value is non-zero.In addition, we also created a binary version ofthe P feature in order to evaluate the effect of bina-rization.NP This is based on the PAU DUR N value, and isonly generated when that value is greater than0.285.We actually experimented with a much widerrange of binned variables, but they all produced re-sults similar to those described below.2.2 Parse corpus constructionWe tried to incorporate the binned prosodic informa-tion described in the previous subsection in a mannerthat corresponds as closely as possible to the waythat punctuation is represented in this corpus, be-cause previous experiments have shown that punc-tuation improves parser performance (Charniak andJohnson, 2001; Engel et al, 2002).
We deleted dis-fluency tags and EDITED subtrees from our trainingand test corpora.We investigated several combinations of prosodicpseudo-punctuation symbols.
For each of these wegenerated a training and test corpus.
The pseudo-punctuation symbols are dominated by a new preter-minal PROSODY to produce a well-formed tree.These prosodic local trees are introduced into thetree following the word they described, and are at-tached as high as possible in the tree, just as punc-tuation is in the Penn treebank.
Figure 2 depictsa typical tree that contains P R S prosodic pseudo-punctuation symbols inserted following the wordthey describe.We experimented with several other ways of in-corporating prosody into parse trees, none of whichgreatly affected the results.
For example, we also ex-perimented with a ?raised?
representation in whichthe prosodic pseudo-punctuation symbol also servesas the preterminal label.
The corresponding ?raised?version of the example tree is depicted in Figure 3.The motivation for raising is as follows.
The sta-tistical parser used for this research generates thesiblings of a head in a sequential fashion, first pre-dicting the category label of a sibling and later con-ditioning on that label to predict the remaining sib-lings.
?Raising?
should permit the generative modelto condition not just on the presence of a prosodicpseudo-punctuation symbol but also on its actualidentity.
If some but not all of the prosodic pseudo-punctuation symbols were especially indicative ofsome aspect of phrase structure, then the ?raising?structures should permit the parsing model to detectthis and condition on just those symbols.
Note thatin the Penn treebank annotation scheme, differenttypes of punctuation are given different preterminalcategories, so punctuation is encoded in the treebankusing a ?raised?
representation.The resulting corpora contain both prosodic andpunctuation information.
We prepared our actualtraining and testing corpora by selectively remov-ing subtrees from these corpora.
By removing allpunctuation subtrees we obtain corpora that containprosodic information but no punctuation, by remov-ing all prosodic information we obtain the originaltreebank data, and by removing both prosodic andpunctuation subtrees we obtain corpora that containneither type of information.2.3 EvaluationWe trained and evaluated the parser on the varioustypes of corpora described in the previous section.SINTJUHUhPROSODY*R4*,,NPPRPIPROSODY*R4*VPVBPdoRBntVPVBlivePPINinNPDTaPROSODY*R3*S2*NNhousePROSODY*S4*,,Figure 2: A tree with P R S prosodic pseudo-punctuation symbols inserted following the words they corre-spond to.
(No P prosodic features occured in this utterance).SINTJUHUh*R4**R4*,,NPPRPI*R4**R4*VPVBPdoRBntVPVBlivePPINinNPDTa*R3*S2**R3*S2*NNhouse*S4**S4*,,Figure 3: The same sentence as in Figure 2, but with prosodic pseudo-punctuation raised to the preterminallevel.Annotation unraised raisedpunctuation 88.212none 86.891L 85.632 85.361NP 86.633 86.633P 86.754 86.594R 86.407 86.288S 86.424 85.75W 86.031 85.681P R 86.405 86.282P W 86.175 85.713P S 86.328 85.922P R S 85.64 84.832Table 1: The F-score of the parser?s output whentrained and tested on corpora with varying prosodicpseudo-punctuation symbols.
The entry ?punc-tuation?
gives the parser?s performance on inputwith standard punctuation, while ?none?
gives theparser?s performance on input without any punctua-tion or prosodic pseudo-punctuation whatsoever.
(We always tested on the type of corpora that corre-sponded to the training data).
We evaluated parserperformance using the methodology described inEngel et al (2002), which is a simple adaptation ofthe well-known PARSEVAL measures in which punc-tuation and prosody preterminals are ignored.
Thisevaluation yields precision, recall and F-score valuesfor each type of training and test corpora.3 ResultsTable 1 presents the results of our experiments.
TheRAISED prosody entry corresponds to the raised ver-sion of the COMBINED corpora, as described above.We replicated previous results and showed thatpunctuation information does help parsing.
How-ever, none of the experiments with prosodic infor-mation resulted in improved parsing performance;indeed, adding prosodic information reduced perfor-mance by 2 percentage points in some cases.
This isa very large amount by the standards of modern sta-tistical parsers.
Notice that the general trend is thatperformance decreases as the amount and complex-ity of the prosodic annotation increased.4 Discussion and ConclusionSimple statistical tests show that there is in facta significant correlation between the location ofopening and closing phrase boundaries and all ofthe prosodic pseudo-punctuation symbols describedabove, so there is no doubt that these do con-vey information about syntactic structure.
How-ever, adding the prosodic pseudo-punctuation sym-bols uniformly decreased parsing accuracy relativeto input with no prosodic information.
There are anumber of reasons why this might be the case.While we investigated a wide range of prosodicfeatures, it is possible that different prosodic featuresmight improve parsing performance, and it would beinteresting to see if improved prosodic feature ex-traction would improve parsing accuracy.We suspect that the decrease in accuracy is dueto the fact that the addition of prosodic pseudo-punctuation symbols effectively excluded othersources of information from the parser?s statisti-cal models.
For example, as mentioned earlier theparser uses a mixture of n-gram models to predictthe sequence of categories on the right-hand sideof syntactic rules, backing off ultimately to a dis-tribution that includes just the head and the preced-ing sibling?s category.
Consider the effect of insert-ing a prosodic pseudo-punctuation symbol on sucha model.
The prosodic pseudo-punctuation symbolwould replace the true preceding sibling?s categoryin the model, thus possibly resulting in poorer over-all performance (note however that the parser alsoincludes a higher-order backoff distribution in whichthe next category is predicted using the precedingtwo sibling?s categories, so the true sibling?s cate-gory would still have some predictive value).The basic point is that inserting additional in-formation into the parse tree effectively splits theconditioning contexts, exacerbating the sparse dataproblems that are arguably the bane of all statisti-cal parsers.
Additional information only improvesparsing accuracy if the information it conveys is suf-ficient to overcome the loss in accuracy incurred bythe increase in data sparseness.
It seems that punctu-ation carries sufficient information to overcome thisloss, but that the prosodic categories we introduceddo not.It could be that our results reflect the fact that weare parsing speech transcripts in which the words(and hence their parts of speech) are very reliablyidentified, whereas our prosodic features were auto-matically extracted directly from the speech signaland hence might be noisier.
If the explanation pro-posed above is correct, it is perhaps not surprisingthat an accurate part of speech label would provemore useful in a conditioning context used by theparser than a noisy prosodic feature.
Note that thiswould not be the case when parsing from speech rec-ognizer output (since word identity would itself beuncertain), and it is possible that in such applicationsprosodic information would be more useful.Of course, there are many other ways prosodic in-formation might be exploited in a parser, and oneof those may yield improved parser performance.We chose to incorporate prosodic information intoour parser in a way that was similar to the waythat punctuation is annotated in the Penn treebanksbecause we assumed that punctuation carries infor-mation similar to prosody, and it had already beendemonstrated that punctuation annotated in the Penntreebank fashion does systematically improve pars-ing accuracy.But the assumption that prosody conveys infor-mation about syntactic structure in the same waythat punctuation does could be false.
It could also bethat even though prosody encodes information aboutsyntactic structure, this information is encoded ina manner that is too complicated for our parser toutilize.
For example, even though commas are of-ten used to indicate pauses, pauses have many otherfunctions in fluent speech.
Pauses of greater than200 ms are often associated with planning problems,which might be correlated with syntactic structurein ways too complex for the parser to exploit.
Whilenot reported here, we tried various techniques to iso-late different functions of pauses, such as exclud-ing pauses of greater than 200 ms.
However, all ofthese experiments produced results similar to thosereported here.Finally, there is another possible reason why ourassumption that prosody and punctuation are similarin their information content could be wrong.
Ourprosodic information was automatically extractedfrom the speech stream, while punctuation was pro-duced by human annotators who presumably com-prehended the utterances being annotated.
Giventhis, it is perhaps no surprise that our automaticallyextracted prosodic annotations proved less usefulthan human-produced punctuation.ReferencesBengt Altenberg.
1987.
Prosodic patterns in spoken En-glish: studies in the correlation between prosody andgrammar.
Lund University Press, Lund.Don Baron, Elizabeth Shriberg, and Andreas Stolcke.2002.
Automatic punctuation and disfluency detec-tion in multi-party meetings using prosodic and lex-ical cues.
In Proc.
Intl.
Conf.
on Spoken LanguageProcessing, volume 2, pages 949?952, Denver.Ann Bies, Mark Ferguson, Karen Katz, and Robert Mac-Intyre, 1995.
Bracketting Guideliness for Treebank IIstyle Penn Treebank Project.
Linguistic Data Consor-tium.Eugene Charniak and Mark Johnson.
2001.
Edit detec-tion and parsing for transcribed speech.
In Proceed-ings of the 2nd Meeting of the North American Chap-ter of the Association for Computational Linguistics,pages 118?126.Eugene Charniak.
2000.
A maximum-entropy-inspiredparser.
In The Proceedings of the North AmericanChapter of the Association for Computational Linguis-tics, pages 132?139.William Croft.
1995.
Intonation units and grammaticalstructure.
Linguistics, 33:839?882.Donald Engel, Eugene Charniak, and Mark Johnson.2002.
Parsing and disfluency placement.
In Proceed-ings of the 2002 Conference on Empirical Methods inNatural Language Processing, pages 49?54.Luciana Ferrer, Elizabeth Shriberg, and Andreas Stol-cke.
2002.
Is the speaker done yet?
faster and moreaccurate end-of-utterance detection using prosody inhuman-computer dialog.
In Proc.
Intl.
Conf.
on Spo-ken Language Processing, volume 3, pages 2061?2064, Denver.Luciana Ferrer.
2002.
Prosodic features for the switch-board database.
Technical report, SRI International,Menlo Park.Jon Hamaker, Dan Harkins, and Joe Picone.
2003.
Man-ually corrected switchboard word alignments.Julia Hirschberg and Christine Nakatani.
1998.
Acousticindicators of topic segmentation.
In Proc.
Intl.
Conf.on Spoken Language Processing, volume 4, pages1255?1258, Philadelphia.Wouter Jansen, Michelle L. Gregory, and Jason M. Bre-nier.
2001.
Prosodic correlates of directly reportedspeech: Evidence from conversational speech.
In Pro-ceedings of the ISCA Workshop on Prosody in SpeechRecognition and Understanding, pages 77?80, RedBanks, NJ.Mark Johnson.
1998.
PCFG models of linguis-tic tree representations.
Computational Linguistics,24(4):613?632.Ralf Kompe.
1997.
Prosody in speech understandingsystems.
Springer, Berlin.Chris Manning and Hinrich Schu?tze.
1999.
Foundationsof Statistical Natural Language Processing.
The MITPress, Cambridge, Massachusetts.Heinrich Neiman, Elmar Noth, Anton Batliner, JanBuckow, Florian Gallwitz, Richard Huber, and VolkarWarnke.
1998.
Using prosodic cues in spoken dialogsystems.
In Proceedings of the International Work-shop on Speech and Computer, pages 17?28, St. Pe-tersburg.Elmar No?th, Anton Batliner, Andreas Kie?ling, RalfKompe, and Heinrich Niemann.
2000.
Verbmobil:The use of prosody in the linguistic components of aspeech understanding system.
IEEE Transactions onSpeech and Auditory Processing, 8(5):519?532.Astrid Schepman and Paul Rodway.
2000.
Prosodyand on-line parsing in coordination structures.
TheQuarterly Journal of Experimental Psychology: A,53(2):377?396.Elizabeth Shriberg, Andreas Stolcke, Dilek Hakkani-Tur, and Gorkhan Tur.
2000.
Prosody-based auto-matic segmentation of speech into sentences and top-ics.
Speech Communication, 32(1-2):127?154.
