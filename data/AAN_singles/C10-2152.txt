Coling 2010: Poster Volume, pages 1327?1335,Beijing, August 2010MIEA: a Mutual Iterative Enhancement Approach for Cross-DomainSentiment ClassificationQiong Wu1,2, Songbo Tan1, Xueqi Cheng1 and Miyi Duan11Institute of Computing Technology, Chinese Academy of Sciences2 Graduate University of Chinese Academy of Sciences{wuqiong,tansongbo}@software.ict.ac.cnAbstractRecent years have witnessed a large body ofresearch works on cross-domain sentimentclassification problem, where most of the re-search endeavors were based on a supervisedlearning strategy which builds models fromonly the labeled documents or only the labeledsentiment words.
Unfortunately, such kind ofsupervised learning method usually fails touncover the full knowledge between docu-ments and sentiment words.
Taking account ofthis limitation, in this paper, we propose an it-erative reinforcement learning approach forcross-domain sentiment classification by si-multaneously utilizing documents and wordsfrom both source domain and target domain.Our new method can make full use of the rein-forcement between documents and words byfusing four kinds of relationships betweendocuments and words.
Experimental resultsindicate that our new method can improve theperformance of cross-domain sentiment classi-fication dramatically.1 IntroductionSentiment classification is the task of determin-ing the opinion (e.g., negative or positive) of agiven document.
In recent years, it has drawnmuch attention with the increasing reviewingpages and blogs etc., and it is very important formany applications, such as opinion mining andsummarization (e.g., (Ku et al, 2006; McDonaldet al, 2007)).In most cases, a variety of supervised classifi-cation methods can perform well in sentimentclassification.
This kind of methods requires acondition to guarantee the accuracy of classifica-tion: training data should have the same distribu-tion with test data so that test data could sharethe information got from training data.
So thelabeled data in the same domain with test data isconsidered as the most valuable resources for thesentiment classification.
However, such re-sources in different domains are very imbalanced.In some traditional domains or domains of con-cern, many labeled sentiment data are freelyavailable on the web, but in other domains, la-beled sentiment data are scarce and it involvesmuch human labor to manually label reliablesentiment data.
The challenge is how to utilizelabeled sentiment data in one domain (that is,source domain) for sentiment classification inanother domain (that is, target domain).
Thisraises an interesting task, cross-domain sentimentclassification (or sentiment transfer).
In this work,we focus on one typical kind of sentiment trans-fer problem, which utilizes only training datafrom source domain to improve sentimentclassification performance for target domain,without any labeled data for the target domain(e.g., (Andreevskaia and Bergler, 2008)).In recent years, some studies have been con-ducted to deal with sentiment transfer problems.However, most of the attempts rely on only thelabeled documents (Aue and Gamon, 2005; Tanet al, 2007; Tan et al, 2009; Wu et al, 2009) orthe labeled sentiment words (Gamon and Aue,2005) to improve the performance of sentimenttransfer, so this kind of methods fails to uncoverthe full knowledge between the documents andthe sentiment words.In fact, the opinion of a document can be de-termined by the interrelated documents as well asby the interrelated words, and this rule is alsotenable when determining the opinion of a sen-timent word.
This rule is based on the followingintuitive observations:(1)  A document strongly linked with other posi-tive (negative) documents could be consid-ered as positive (negative); in the same way,a word strongly linked with other positive(negative) words could be considered aspositive (negative).1327(2)  A document containing many positive (nega-tive) words could be considered as positive(negative); similarly, a word appearing inmany positive (negative) documents couldbe considered as positive (negative).Inspired by these observations, we aim to takeinto account all the four kinds of relationshipsamong documents and words (i.e.
the relation-ships between documents, the relationships be-tween words, the relationships between wordsand documents, and the relationships betweendocuments and words) in both source domainand target domain under a unified framework forsentiment transfer.In this work, we propose an iterative rein-forcement approach to implement the above idea.The proposed approach makes full use of all therelationships among documents and words fromboth source domain and target domain to transferinformation between domains.
In our approach,the opinion of a document (word) is reinforcedby the opinion of all its interrelated documentsand words; and the updated opinion of the docu-ment (word) will conversely reinforce the opin-ions of its interrelated documents and words.That is to say, it is an iterative reinforcementprocess until it converges to a final result.The contribution of our work is twofold.
First,we extend the traditional sentiment-transfermethods by utilizing the full knowledge betweeninterrelated documents and words.
Second, wepresent a reinforcement approach to get the opin-ions of documents by making use of graph-ranking algorithm.The proposed approach is evaluated on threedomain-specific sentiment data sets.
The experi-mental results show that our approach can dra-matically improve the accuracy when transferredto another target domain.
And we also conductextensive experiments to investigate the parame-ters sensitivity.
The results show that our algo-rithm is not sensitive to these parameters.2 Proposed Methods2.1 Problem DefinitionIn this paper, we have two document sets: thetest documents DU = {d1,?,dnd} where di is theterm vector of the ith text document and eachdi?DU(i = 1,?,nd) is unlabeled; the trainingdocuments DL = {dnd+1,?,dnd+md} where dj repre-sents the term vector of the jth text document andeach dj?DL(j = nd+1,?,nd+md) should have alabel from a category set C = {negative, posi-tive}.
We assume the training dataset DL is fromthe interrelated but different domain with the testdataset DU.
Also, we have two word sets: WU ={w1,?,wnw} is the word set of DU and eachwi?WU (i = 1,?,nw) is unlabeled; WL ={wnw+1,?,wnw+mw} is the word set of DL and eachwj?WL(j = nw+1,?,nw+mw) has a label from C.Our objective is to maximize the accuracy of as-signing a label in C to di?DU (i = 1,?,nd) utiliz-ing the training data DL and WL in another do-main.The proposed algorithm is based on the fol-lowing presumptions:(1) WL?WU??.
(2) The labels of documents appear both in thetraining data and the test data should be the same.2.2 OverviewThe proposed approach is inspired by graph-ranking algorithm whose idea is to give a nodehigh score if it is strongly linked with other high-score nodes.
Graph-ranking algorithm has beensuccessfully used in many fields (e.g.
PageRank(Brin et al 1999), LexRank (Erkan and Radev,2004)).
We can get the following thoughts basedon the ideas of PageRank and HITS (Kleinberg,1998):(1)   If a document is strongly linked with otherpositive (negative) documents, it tends to bepositive (negative); and if a word is stronglylinked with other positive (negative) words,it tends to be positive (negative).
(2)  If a document contains many positive (nega-tive) words, it tends to be positive (nega-tive); and if a word appears in many posi-tive (negative) documents, it tends to bepositive (negative).Given the data points of documents and words,there are four kinds of relationships in our prob-lem:z DD-Relationship: It denotes the relation-ships between documents, usually computedby their content similarity.z WW-Relationship: It denotes the relation-ships between words, usually computed byknowledge-based approach or corpus-basedapproach.z DW-Relationship: It denotes the relation-ships between documents and words, usu-1328ally computed by the relative importance ofa word in a document.z WD-Relationship: It denotes the relation-ships between words and documents, usu-ally computed by the relative importance ofa document to a word.Meanwhile, our problem refers to both sourcedomain and target domain, so our approach con-siders eight relationships altogether: DDO-Relationship (the relationships between DU andDL), DDN-Relationship (the relationships be-tween DU), WWO-Relationship (the relationshipsbetween WU and WL), WWN-Relationship (therelationships between WU and WU), DWO-Relationship (the relationships between DU andWL), DWN-Relationship (the relationships be-tween DU and WU), WDO-Relationship (the rela-tionships between WU and DL), WDN-Relationship (the relationships between WU andDU).
The first four relationships are used to com-pute the sentiment scores of the documents, andthe others are used to compute the sentimentscores of the words.The iterative reinforcement approach couldmake full use of all the relationships in a unifiedframework.
The framework of the proposed ap-proach is illustrated in Figure 1.Figure 1.
Framework of the proposed approachThe framework consists of a graph-buildingphase and an iterative reinforcement phase.
Inthe graph-building phase, the input includes boththe labeled data from source domain and theunlabeled data from target domain.
The proposedapproach builds four graphs based on these datato reflect the above relationships respectively.For source-domain data, we initialize everydocument and word a score (?1?
denotes positive,and ?-1?
denotes negative) to represent its degreeof sentiment orientation, and we call it sentimentscore; for target-domain data, we set the initialsentiment scores to 0.In the iterative reinforcement phase, our ap-proach iteratively computes the sentiment scoresof the documents and words based on the graphs.When the algorithm converges, all the documentsget their sentiment scores.
If its sentiment scoreis between 0 and 1, the document should be clas-sified as ?positive?.
The closer its sentimentscore is near 1, the higher the ?positive?
degreeis.
Otherwise, if its sentiment score is between 0and -1, the document should be classified as?negative?.
The closer its sentiment score is near-1, the higher the ?negative?
degree is.The algorithms of sentiment graph buildingand iterative reinforcement are described in de-tails in the next sections, respectively.2.3 Sentiment-Graph BuildingSymbol DefinitionIn this section, we build four graphs to reflecteight relationships, and the meanings of symbolsare shown in Table 1.Rela-tionshipSimilarity ma-trixNormal-ized form Neighbor matrixDDO UL=[ULij]ndxmd LU?
KndijLL UnUn ?= ][DDN UU=[UU ij]ndxnd UU?
KndijUU UnUn ?= ][WWO VL=[VLij]nwxmw LV?
KnwijLL VnVn ?= ][WWN VU=[VU ij]nwxnw UV?
KnwijUU VnVn ?= ][DWO ML=[MLij]ndxmw LM?
KndijLL MnMn ?= ][DWN MU=[MUij]ndxnw UM?
KndijUU MnMn ?= ][WDO NL=[NLij]nwxmd LN?
KnwijLL NnNn ?= ][WDN NU=[NUij]nwxnd UN?
KnwijUU NnNn ?= ][Table 1: Symbol definitionIn this table, the first column denotes the nameof the relationship; the second column denotes1329the similarity matrix to reflect the correspondingrelationship; in consideration of convergence, wenormalize the similarity matrix, and the normal-ized form is listed in the third column; in order tocompute sentiment scores, we find the neighborsof a document or a word and the neighbor matrixis listed in the fourth column.Document-to-Document GraphWe build an undirected graph whose nodes de-note documents in both DL and DU and edgesdenote the content similarities between docu-ments.
If the content similarity between twodocuments is 0, there is no edge between the twonodes.
Otherwise, there is an edge between thetwo nodes whose weight is the content similarity.The edges in this graph are divided into two parts:edges between DU and DL; edges between DUitself, so we build the graph in two steps.
(1) Create DU and DL EdgesThe content similarity between two documents iscomputed with the cosine measure.
We use anadjacency matrix UL to denote the similarity ma-trix between DU and DL.
UL=[ULij]ndxmd is definedas follows:mdjndiddddUndjindjiLij ,...,1,,...,1, ==?
?=++          (1)The weight associated with word w is com-puted with tfwidfw where tfw is the frequency ofword w in the document and idfw is the inversedocument frequency of word w, i.e.
1+log(N/nw),where N is the total number of documents and nwis the number of documents containing word w ina data set.In consideration of convergence, we normalizeUL to LU?
by making the sum of each row equal to1:?????
?= ??
==otherwiseUifUUUmdjLijmdjLijLijLij,00,?11              (2)In order to find the neighbors (in another word,the nearest documents) of a document, we sortevery row of LU?
to LU~ in descending order.
Thatis: ijLU~ ?
ikLU~  (i = 1,?,nd; j,k = 1,?,md; k?j).Then for di?DU (i = 1,?,nd), ijLU~ (j = 1,?,K )corresponds to K neighbors in DL.
We use a ma-trixKndijLL UnUn ?= ][  to denote the neighbors of DUin source domain, with ijLUn  corresponding to thejth nearest neighbor of di.
(2) Create DU and DU EdgesSimilarly, the edge weight between DU itself iscomputed by the cosine measure.
We get thesimilarity matrix UU=[UUij]ndxnd, the normalizedsimilarity matrix UU?
, and the neighbors of  DU intarget domain:KndijUU UnUn ?= ][ .Word-to-Word GraphSimilar to the Document-to-Document Graph,we build an undirected graph to reflect the rela-tionship between words in WL and WU, in whicheach node corresponds to a word and the edgeweight between any different words correspondsto their semantic similarity.
The edges in thisgraph are divided into two parts: edges betweenWU and WL; edges between WU itself, so we alsobuild the graph in two steps.
(1) Create WU and WL EdgesWe compute the semantic similarity using cor-pus-based approach which computes the similar-ity between words utilizing information fromlarge corpora.
There are many measures to iden-tify word semantic similarity, such as mutualinformation (Turney, 2001), latent semanticanalysis (Landauer et al, 1998) etc.
In this study,we compute word semantic similarity based onthe sliding window measure, that is, two wordsare semantically similar if they co-occur at leastonce within a window of maximum Kwin words,where Kwin is the window size.
We use an adja-cency matrix VL to denote the similarity matrixbetween WU and WL.
VL=[VLij]nwxmw is defined asfollows:?????
??
?= +++otherwisewwifwpwpwwpNV nwjinwjinwjiijL,0,)()(),(log(3)where N is the total number of words in DU; p(wi,wj) is the probability of the co-occurrence of wiand wj within a window, i.e.
num(wi, wj)/N,where num(wi, wj) is the number of the times wiand wj co-occur within the window; p(wi) andp(wj) are the probabilities of the occurrences ofwi and wj respectively, i.e.
num(wi)/N andnum(wj)/N, where num(wi) and num(wj) are the1330numbers of the times wi and wj occur.
We nor-malize VL to LV?
to make the sum of each rowequal to 1.
Then we sort every row of LV?
to LV~ indescending order, and we use a matrixKnwijLL VnVn ?= ][  to denote the neighbors of WU insource domain.
(2) Create WU and WU EdgesThen we also compute the edge weight betweenany different nodes which denote words in WUby the sliding window measure.
We get the simi-larity matrix VU=[VUij]nwxnw, the normalized simi-larity matrix UV?
, and the neighbors of  WU intarget domain:KnwijUU VnVn ?= ][ .Document-to-Word GraphWe can build a weighted directed bipartite graphfrom documents in DU and words in WL and WUin the following way: each node in the graph cor-responds to a document in DU or a word in WLand WU; if word wj appears in document di, wecreate an edge from di to wj.
The edges in thisgraph are divided into two parts: edges from DUto WL; edges from DU to WU, so we also build thegraph in two steps.
(1) Create DU to WL EdgesThe edge weight from a document in DU to aword in WL is proportional to the importance ofword wj in document di.
We use an adjacencymatrix ML to denote the similarity matrix fromDU to WL.
ML=[MLij]ndxmw is defined as follows:???
?= ++inwjnwjdwwwwwLij idftfidftfM                          (4)where w represents a unique word in di and tfw,idfw are respectively the term frequency in thedocument and the inverse document frequency.We normalize ML to LM?
to make the sum of eachrow equal to 1.
Then we sort every row of LM?
toLM~ in descending order, and we use a matrixKndijLL MnMn ?= ][  to denote the neighbors of DU inWL.
(2) Create DU to WU EdgesSimilarly, we can also compute the edge weightfrom a document in DU to a word in WU in thesame way.
We get the similarity matrixMU=[MUij]ndxnw, the normalized similarity matrixUM?
, and the neighbors of  DU in WU:KndijUU MnMn ?= ][ .Word-to-Document GraphIn this section, we build a weighted directedbipartite graph from words in WU and documentsin DL and DU in which each node in the graphcorresponds to a word in WU and a document inDL or DU; if word wj appears in document di, wecreate an edge from wj to di.
The edges in thisgraph are also divided into two parts: edges fromWU to DL; edges from WU to DU.
(1) Create WU to DL EdgesSimilar to 3.3.4, the edge weight from a word inWU to a document in DL is proportional to theimportance of word wi in document dj.
We use anadjacency matrix NL=[NLij]nwxmd to denote thesimilarity matrix from WU to DL.
We normalizeNL to LN?
to make the sum of each row equal to 1.Then we sort every row of LN?
to LN~ in descend-ing order, and we use a matrixKnwijLL NnNn ?= ][  todenote the neighbors of WU in DL.
(2) Create WU to DU EdgesWe can also compute the edge weight from aword in WU to a document in DU in the same way.We get the similarity matrix NU=[NUij]nwxnd, thenormalized similarity matrix UN?
, and theneighbors of  WU in DU:KnwijUU NnNn ?= ][ .2.4 Proposed MethodBased on the two thoughts introduced in Sec-tion 2.2, we fuse the eight relationships ab-stracted from the four graphs together to itera-tively reinforce sentiment scores, and we canobtain the iterative equation as follows:?????????????+?+?+?=iUiLiUiLMnrrirUMnllilLUnhhihUUnggigLiwsMwsMdsUdsUds)?()?()?()?(????(5)?????????????+?+?+?=jUjLjUjLNnrrjrUNnlljlLVnhhjhUVnggjgLjdsNdsNwsVwsVws)?()?()?()?(????
(6)where ?i  means the ith row of a matrix; Ds ={ds1,?,dsnd, dsnd+1,?, dsnd+md} represents thesentiment scores of DU and DL; Ws ={ws1,?,wsnw, wsnw+1,?, wsnw+mw} represents thesentiment scores of WU and WL; ?
and ?
show1331the relative contributions to the final sentimentscores from source domain and target domainwhen calculating DD-Relationship and WW-Relationship, and ?
+ ?
=1; ?
and?show therelative contributions to the final sentimentscores from source domain and target domainwhen calculating DW-Relationship and WD-Relationship, and ?
+?=1.For simplicity, we merge the relationshipsfrom source domain and target domain.
That is,for formula (5), we merge the first two items intoone, the last two items into one; for formula (6),we merge its first two items into one, its last twoitems into one.
Thus, (5) and (6) are transformedinto (7) and (8) as follows:????
????+?
?=ii MnllilUnggigi wsMdsUds )?()?
( ??
(7)????
????+?
?=jj VnlljlNnggjgj wsVdsNws )?()?
( ??
(8)where  ?
and ?
show the relative contributionsto the final sentiment scores from document setsand word sets, and ?+?=1.In consideration of the convergence, Ds andWs are normalized separately after each iterationas follows to make the sum of positive scoresequal to 1, and the sum of negative scores equalto -1:??????
?><?= ????0,0,)(iDjjiiDjjidsifdsdsdsifdsdsdsUposUnegi(9)??????
?><?= ???
?0,0,)(jWiijjWiijjwsifwswswsifwswswsUposUneg              (10)where UnegD andUposD denote the negative andpositive document set of DU respectively;UnegW andUposW denote the negative and positiveword set of WU respectively.Here is the complete algorithm:1.
Initialize the sentiment score vector dsiof di?DL (i = nd+1,?, nd+md) with 1 whendi is labeled ?positive?, and with -1 when diis labeled ?negative?, and initialize the sen-timent score vector wsi of wi?WL (i =nw+1,?, nw+mw) with 1 when wi is labeled?positive?, and with -1 when wi is labeled?negative?.
And we normalize dsi (i =nd+1,?, nd+md) (wsi (i = nw+1,?,nw+mw)) to make the sum of positive scoresof DL (WL) equal to 1, and the sum of nega-tive scores of DL (WL) equal to -1.
Also, theinitial sentiment scores of DU and WU are setto 0.2.
Alternate the following two steps untilconvergence:2.1.Compute and normalize dsi (i = 1,?,nd) using formula (7) and (9):2.2.Compute and normalize wsj (j=1,?,nw)using formula (8) and (10):where )(kids and)(kjws denote the ids and wsjat the kth iteration.3.
According to dsi?Ds (i = 1,?,nd), as-sign each di?DU (i = 1,?,nd) a label.
If dsifalls in the range [-1,0], assign di the label?negative?
; if dsi falls in the range [0,1], as-sign di the label ?positive?.3 ExperimentsIn this section, we evaluate our approach onthree different domains and compare it withsome state-of-the-art algorithms, and also evalu-ate the approach?s sensitivity to its parameters.Note that we conduct experiments on Chinesedata, but the main idea in the proposed approachis language-independent in essence.3.1 Data PreparationWe use three Chinese domain-specific data setsfrom on-line reviews, which are: Book Reviews1(B, www.dangdang.com/), Hotel Reviews 2  (H,www.ctrip.com/) and Notebook Reviews 3  (N,www.360buy.com/).
Each dataset has 4000 la-beled reviews (2000 positives and 2000 nega-tives).We use ICTCLAS (http://ictclas.org/), a Chi-nese text POS tool, to segment these Chinesereviews.
Then, utilizing the part-of-speech tag-ging function provided by ICTCLAS, we take alladjectives, adverbs and adjective-noun phrases ascandidate sentiment words.
After removing therepeated words and ambiguous words, we get alist of words in each domain.For the list of words in each domain, wemanually label every word as ?negative?, ?posi-1www.searchforum.org.cn/tansongbo/corpus/Dangdang_Book_4000.rar2www.searchforum.org.cn/tansongbo/corpus/Ctrip_htl_4000.rar3www.searchforum.org.cn/tansongbo/corpus/Jingdong_NB_4000.rar1332tive?
or ?neutral?, and we take those ?negative?and ?positive?
words as a sentiment word set.Note that we use the sentiment word set onlyfor source domain, while using the candidatesentiment words for target domain.Lastly, the documents are represented by vec-tor space model.
In this model, each document isconverted into bag-of-words presentation in theremaining term space.
We compute term weightwith the frequency of the term in the document.We choose one of the three data sets assource-domain data DL, and its correspondingsentiment word set as WL; we choose anotherdata set as target-domain data DU, and its corre-sponding candidate sentiment words as WU.3.2 Baseline MethodsIn this paper we compare our approach with thefollowing baseline methods:Proto: This method applies a traditional super-vised classifier, prototype classifier (Tan et al,2005), for the sentiment transfer.
And it onlyuses source domain documents as training data.LibSVM: This method applies a state-of-the-art supervised learning algorithm, Support Vec-tor Machine, for the sentiment transfer.
In detail,we use LibSVM (Chang and Lin, 2001) with alinear kernel and set al options as default.
Thismethod only uses source domain documents astraining data.TSVM:  This method applies transductiveSVM (Joachims, 1999) for the sentiment transferwhich is a widely used method for improving theclassification accuracy.
In our experiment, weuse Joachims?s SVM-light package(http://svmlight.joachims.org/) for TSVM.
Weuse a linear kernel and set al parameters as de-fault.
This method uses both source domain dataand target domain data.3.3 Overall PerformanceIn this section, we compare proposed approachwith the three baseline methods.
There are threeparameters in our algorithm, K, Kwin, ?
(?can becalculated by 1-?).
We set K to 50, and Kwin to 10respectively.
With different ?, our approach canbe considered as utilizing different relative con-tributions from document sets and word sets.
Inorder to identify the importance of both docu-ment sets and word sets for sentiment transfer,we separately set ?
to 0, 1, 0.5 to show the accu-racy of utilizing only word sets (referred to asWORD), only document sets (referred to asDOC), and both the document and word sets (re-ferred to as ALL).
It is thought that the algorithmachieves the convergence when the changingbetween the sentiment score dsi computed at twosuccessive iterations for any di?DU (i = 1,?,nd)falls below a given threshold, and we set thethreshold 0.00001 in this work.
The parameterswill be studied in parameters sensitivity section.Table 2 shows the accuracy of Prototype,LibSVM, TSVM and our algorithm when train-ing data and test data belong to different domains.As we can observe from Table 2, our algo-rithm produces much better performance thansupervised baseline methods.
Compared with thetraditional classifiers, our approach outperformsthem by a wide margin on all the six transfertasks.
The great improvement compared with thebaselines indicates that our approach performsvery effectively and robustly.Traditional Classifier Our ApproachProto LibSVMTSVMDOC WORD ALLB->H 0.735 0.747 0.749 0.772 0.734 0.763B->N 0.651 0.652 0.769 0.714 0.785 0.795H->B 0.645 0.675 0.614 0.671 0.668 0.703H->N 0.729 0.669 0.726 0.749 0.727 0.734N->B 0.612 0.608 0.622 0.638 0.667 0.726N->H 0.724 0.711 0.772 0.764 0.740 0.792Aver-age 0.683 0.677 0.709 0.718 0.720 0.752Table 2: Accuracy comparison of different methodsTable 2 shows the average accuracy of TSVMis higher than both traditional classifiers, since itutilizes the information of both source domainand target domain.
However, the proposed ap-proach outperforms TSVM: the average accuracyof the proposed approach is about 4.3% higherthan TSVM.
This is caused by two reasons.
First,TSVM is not dedicated for sentiment-transferlearning.
Second, TSVM requires the ratio be-tween positive and negative examples in the testdata to be close to the ratio in the training data,so its performance will be affected if this re-quirement is not met.Results of ?DOC?
and ?WORD?
are shown incolumn 4 and 5 of Table 2.
As we can observe,they produce better performance than all thebaselines.
This is caused by two reasons.
First,?DOC?
and ?WORD?
separately utilize the sen-1333timent information of documents and words.Second, both ?DOC?
and ?WORD?
involve aniterative reinforcement process to improve theirperformance.
The great improvement indicatesthat the iterative reinforcement approach is effec-tive for sentiment transfer.Besides, Table 2 also shows both documentsets and word sets are important for sentimenttransfer.
The approach ?ALL?
outperforms theapproaches ?DOC?
and ?WORD?
on almost allthe six transfer tasks except ?B->H?
and ?H->N?.The average increase of accuracy over all the sixtasks is 3.4% and 3.2% respectively.
The reasonis: at every iteration, the classification accuracyof documents and words is improved by eachother, and then the accuracy of sentiment transferis improved by the documents and words that areclassified more accurately.
As for ?B->H?
and?H->N?, the performance of utilizing onlydocument sets is so good that the word setscouldn?t improve the performance any more.
Theimprovement of the approach ?ALL?
convincesus that not a single one of the four relationshipscan be omitted.3.4 Parameters SensitivityThe proposed algorithm has an important pa-rameter, ?
(?can be calculated by 1-?).
In thissection, we conduct experiments to show that ouralgorithm is not sensitive to this parameter.To investigate the sensitivity of proposedmethod involved with the parameter ?, we set Kto 50, and Kwin to 10.
And we change ?
from 0 to1, an increase of 0.1 each.
We also evaluate ?
onthe six tasks mentioned in section 3.1, and theresults are shown in figure 2.00.10.20.30.40.50.60.70.80.90 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1?AccuracyB->H B->N H->B H->N N->B N->HFigure 2:  Accuracy for Different ?We can observe from Figure 2 that the accu-racy first increases and then decreases when ?
isincreased from 0 to 1.
The accuracy changesgradually when ?
is near 0 or 1, and it changesless when ?
is between 0.2 and 0.8.
It is easy toexplain this phenomenon.
When ?
is set to 0, thisindicates our algorithm only uses word sets to aidclassification, without the information of docu-ment sets.
And if ?
is set to 1, our algorithm onlyuses document sets to calculate sentiment score,without the help of word sets.
Both cases abovedon?t use all information of four relationships, sotheir accuracies are worse than to equal the con-tributions of both document and word sets.
Thisexperiment shows that the proposed algorithm isnot sensitive to the parameter ?
as long as ?
isnot 0 or 1.
We set ?
to 0.5 in our overall-performance experiment.3.5 ConvergenceOur algorithm is an iterative process that willconverge to a local optimum.
We evaluate itsconvergence on the six tasks mentioned above.Figure 3 shows the change of accuracy with re-spect to the number of iterations.
We can observefrom figure 3 that the curve rises sharply duringthe first 6 iterations, and it is very stable after 10iterations are performed.
This experiment indi-cates that our algorithm could converge veryquickly to get a local optimum.00.10.20.30.40.50.60.70.80.91 4 7 10 13 16 19 22 25 28 31 34 37 40IterationAccuracyB->H B->N H->B H->N N->B N->HFigure 3:  Performance for Iteration4 ConclusionsIn this paper, we propose a novel cross-domainsentiment classification approach, which is aniterative reinforcement approach for sentimenttransfer by utilizing all the relationships amongdocuments and words from both source domainand target domain to transfer information be-tween domains.
First, we build three graphs toreflect the above relationships respectively.
Then,1334we assign a score for every unlabelled documentto denote its extent to ?negative?
or ?positive?.We then iteratively calculate the score by makinguse of the graphs.
Finally, the final score for sen-timent classification is achieved when the algo-rithm converges, so we can label the target-domain data based on these scores.We conduct experiments on three domain-specific sentiment data sets.
The experimentalresults show that the proposed approach coulddramatically improve the accuracy when trans-ferred to a target domain.
To investigate the pa-rameter sensitivity, we conduct experiments onthe same data sets.
It is observed that our ap-proach is not very sensitive to its four parameters,and could converge very quickly to get a localoptimum.In this study, we employ only cosine measure,sliding window measure and vector measure tocompute similarity.
These are too general, andperhaps not so suitable for sentiment classifica-tion.
In the future, we will try other methods tocalculate the similarity.
Furthermore, we experi-ment our approach on only three domains, andwe will apply our approach to many more do-mains.5 AcknowledgmentsThis work was mainly supported by two funds,i.e., 60933005 & 60803085, and two another pro-jects, i.e., 2007CB311100 & 2007AA01Z441.ReferencesAlina Andreevskaia and Sabine Bergler.
2008.
WhenSpecialists and Generalists Work Together: Over-coming Domain Dependence in Sentiment Tagging.In Proceedings of ACL: 290-298.Anthony Aue and Michael Gamon.
2005.
Customiz-ing sentiment classifiers to new domains: a casestudy.
In Proceedings of RANLP.Sergey Brin, Lawrence Page, Rajeev Motwami, andTerry Winograd.
1999.
The PageRank citationranking: bringing order to the web.
Technical Re-port 1999-0120, Stanford, CA.Chinchung Chang and Chinjen Lin.
2001.
LIBSVM: alibrary for support vector machines.http://www.csie.ntu.edu.tw/~cjlin/libsvm.Gunes Erkan and Dragomir Radev.
2004.
LexRank:Graph-based Centrality as Salience in Text Sum-marization.
Journal of Artificial Intelligence Re-search, 22 (2004): 457-479.Michael Gamon and Anthony Aue.
2005.
Automaticidentification of sentiment vocabulary: exploitinglow association with known sentiment terms.
InProceedings of the ACL Workshop on Feature En-gineering for Machine Learning in NLP: 57-64.Songbo Tan, Xueqi Cheng, Moustafa Ghanem, BinWang, Hongbo Xu.
2005.
A novel refinement ap-proach for text categorization.
In Proceedings ofCIKM 2005: 469-476Thorsten Joachims.
1999.
Transductive inference fortext classification using support vector machines.In Proceedings of ICML.Jon Kleinberg.
1998.
Authoritative sources in a hyper-linked environment.
Journal of the ACM, 46(5):604-632.Lunwei Ku, Yuting Liang, and Hsinhsi Chen.
2006.Opinion extraction, summarization and tracking innews and blog corpora.
In Proceedings of AAAI.Thomas Landauer, Peter Foltz, and Darrell Laham.1998.
Introduction to latent semantic analysis.
Dis-course Processes 25: 259-284.Ryan McDonald, Kerry Hannan, Tyler Neylon, MikeWells, and Jeff Reynar.
2007.
Structured modelsfor fine-to-coarse sentiment analysis.
In Proceed-ings of ACL.Songbo Tan, Yuefen Wang, Gaowei Wu, and XueqiCheng.
2007.
A novel scheme for domain-transferproblem in the context of sentiment analysis.
InProceedings of CIKM.Songbo Tan, Xueqi Cheng, Yuefen Wang, andHongbo Xu.
2009.
Adapting Na?ve Bayes to Do-main Adaptation for Sentiment Analysis.
In Pro-ceedings of ECIR.Qiong Wu, Songbo Tan and Xueqi Cheng.
2009.Graph Ranking for Sentiment Transfer.
In Proceed-ings of ACL-IJCNLP.Peter Turney.
2001.
Mining the web for synonyms:PMI-IR versus LSA on TOEFL.
In Proceedings ofECML: 491-502.1335
