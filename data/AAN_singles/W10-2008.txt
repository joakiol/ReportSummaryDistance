Proceedings of the 2010 Workshop on Cognitive Modeling and Computational Linguistics, ACL 2010, pages 63?71,Uppsala, Sweden, 15 July 2010. c?2010 Association for Computational LinguisticsTowards a Data-Driven Model of Eye Movement Control in ReadingMattias NilssonDepartment of Linguistics and PhilologyUppsala Universitymattias.nilsson@lingfil.uu.seJoakim NivreDepartment of Linguistics and PhilologyUppsala Universityjoakim.nivre@lingfil.uu.seAbstractThis paper presents a data-driven modelof eye movement control in reading thatbuilds on earlier work using machinelearning methods to model saccade behav-ior.
We extend previous work by model-ing the time course of eye movements, inaddition to where the eyes move.
In thismodel, the initiation of eye movements isdelayed as a function of on-line process-ing difficulty, and the decision of where tomove the eyes is guided by past readingexperience, approximated using machinelearning methods.
In benchmarking themodel against held-out previously unseendata, we show that it can predict gaze dura-tions and skipping probabilities with goodaccuracy.1 IntroductionEye movements during reading proceed as an al-ternating series of fixations and saccades with con-siderable variability in fixation times and saccadelengths.
This variation reflects, at least to someextent, language-related processes during reading.Much psycholinguistic research, therefore, relieson measures of eye movements in reading to gainan understanding of human sentence processing.Eye tracking recordings are routinely used to studyhow readers?
eye movements respond to experi-mental manipulation of linguistic stimuli (Cliftonet al, 2007), and corpus-based analysis of eye-tracking data has recently emerged as a new wayto evaluate theories of human sentence process-ing difficulty (Boston et al, 2008; Demberg andKeller, 2008).More detailed accounts of the workings of theeye movement system during reading are offeredby computational models of eye movement con-trol (see Reichle (2006b), for an overview of re-cent models).
These models receive text as in-put and produce predictions for the placementand duration of fixations, in approximation to hu-man reading behavior.
Because eye movementsin reading rely on a coupled cognitive-motor sys-tem, such models provide detailed accounts forhow eye movements are controlled both by on-linelanguage processing and lower-level motor con-trol.
Current models such as E-Z Reader (Reichle,2006a; Pollatsek et al, 2006; Reichle et al, 2009)and SWIFT (Engbert et al, 2002; Engbert et al,2005) account for numerous of the known factsabout saccade behavior in reading.
This includesword frequency and predictability effects on fixa-tion times, word skipping rates, and preview andspillover effects.A recent approach to eye-movement model-ing, less tied to psychophysiological assumptionsabout the mechanisms that drive eye movements,is to build models directly from eye-tracking datausing machine learning techniques inspired by re-cent work in natural language processing.
Thus,Nilsson and Nivre (2009) show how a classifiercan be trained on authentic eye-tracking data andthen used to predict the saccade behavior of in-dividual readers on new texts.
Methodologicallythis differs from the standard approach in compu-tational modeling of eye movement control, wheremodel parameters are often fitted to data but modelpredictions are not evaluated on unseen data in or-der to assess the generalization error of these pre-dictions.
Without questioning the validity of thestandard approach, we believe that the strict sep-aration of training data and test data assumed inmachine learning may provide additional insightsabout the properties of these models.The model of Nilsson and Nivre (2009) is basedon a simple transition system for saccadic move-ments, a classifier that predicts where to fixate nextand a classifier-guided search algorithm to simu-late fixation sequences over sentences.63One obvious limitation of the model proposedby Nilsson and Nivre (2009) is that it does not atall capture the temporal aspects of eye movementbehavior.
Thus, for example, it says nothing aboutwhen eye movements are initiated or when the de-cision of where to fixate next is made during fixa-tions.
In this paper, we try to overcome this limita-tion by placing the machine-learning approach ina broader psychological context and detail a modelthat also accounts for the timing of fixations.
Moreprecisely, we present a model of the time course ofeye movements, where saccade timing is driven byon-line language processing and where-decisionsare driven by the experience readers have built upthrough years of reading practice.1It is not our intention in this paper to presenta full-fledged model of eye movement control inreading.
The model is limited in scope and doesnot address certain important aspects of eye move-ment control, such as within-word fixation lo-cations, refixations and regressions triggered byhigher-order processing.
In addition, the linguisticfeatures influencing timing (when-decisions) andtarget selection (where-decisions) are restricted tothe basic variables word length and frequency.
Inthis way, we hope to provide a baseline againstwhich richer models of language processing canbe evaluated.The rest of this paper is structured as follows.Section 2 provides a brief background on what isknown about the time course of eye movementsduring reading.
Here we introduce some com-mon notions that will be used later on.
In sec-tion 3, we first give an overview of the modeland then describe its component processes andhow these processes interrelate.
In section 4, wepresent an experimental evaluation of the modelusing data from the English section of the Dundeecorpus (Kennedy and Pynte, 2005).
Section 5 con-tains our conclusions and suggestions for futureresearch.2 The Timing of Eye MovementsThe average fixation duration in reading is about250 ms, and most fixations last between 200-300ms, although they may range from under 100 msto over 500 ms for a given reader (Rayner, 1998).Because eye movements are a motor response re-1This view of where-decisions being driven by experienceis similar in spirit to some earlier theories of saccade targetselection in reading, such as the probabilistic account of wordskipping proposed by Brysbaert and Vitu (1998).quiring preparation before execution, they are ini-tiated well before the end of the fixation.
Hence,there is a saccade latency of about 150-200 msfrom the time when a saccade is first initiated un-til the eye movement is actually executed (Beckerand J?rgens, 1979; McPeek et al, 2000).
Oncethe eye movement is executed, it takes about 25-45 ms before the eyes are fixated on a new wordagain, depending on the length of the movement.Given an average saccade latency of about 150-200 ms, and an average fixation duration of 250ms, it seems clear that eye movements are ofteninitiated within the first 100 ms of a fixation.
How-ever, as Reichle notes (Reichle et al, 2003), sincethe time it takes to identify words is on the orderof 150 - 300 ms, this suggests that there is notenough time for language processes to have anydirect on-line influence on eye movements.
Onekey observation to explain language influences oneye movements, however, is the finding that read-ers often start processing upcoming words beforethey are fixated.
Studies on parafoveal previewshow that the amount of time spent fixating aword depends, among other things, on how muchparafoveal preview of the word is available priorto the word being fixated (Balota et al, 1985; Pol-latsek et al, 1992).A further finding supporting the assumption thatlanguage processes can have an early effect oneye movements comes from the disappearing textstudies (Rayner et al, 1981; Rayner et al, 2003).In these studies, words become masked or disap-pear at a certain point during the fixation.
De-spite this, a word need only be on display for 50-60 ms in order for reading to proceed quite nor-mally.
More importantly, the time the eyes re-main fixated after a word disappears depends onthe frequency of the word.
Readers remain fix-ated on low-frequency words longer than on high-frequency words, even though the word that wasfixated has actually disappeared.
In summary,these studies suggest that there is a robust wordfrequency effect in reading as early as 60 ms afterthe onset of the fixation.3 A Model of Eye Movement Control3.1 General OverviewThe model we develop takes the basic time con-straints associated with language processing andmotor control as a starting point.
This means thatour model is driven by estimates of the time it64takes to process words, plan an eye movement, ex-ecute a saccade etc.
In line with cognitive con-trol models of eye movements in reading, suchas E-Z Reader, we assume that the cognitive pro-cessing of words is the ?engine?
that drives eyemovements.
That is, eye movements are initiatedin response to on-line language processing.
Un-like E-Z Reader, however, we do not presume atwo-stage lexical process where the completion ofa certain hypothesized first stage triggers an eyemovement.2 Instead, when the eyes move to a newword, an eye movement is initiated after some de-lay that is proportional to the amount of cognitivework left on the word.
Furthermore, in contrastto E-Z Reader we assume that saccade initiationis decoupled from the decision of where to movethe eyes.
In E-Z Reader, the initiation of a saccadeprogram is in effect a decision to start program-ming a saccade to the next word.
Here, instead,the target for the next saccade can be any of thewords in the forward perceptual span.
Another re-lated difference, with respect to previous cognitivecontrol models, is that we assume that the deci-sion of where to move the eyes is not directly in-fluenced by on-line language processing.
Instead,this decision is governed by an autonomous rou-tine, having its own dynamics automated throughyears of reading experience.
This experience isapproximated using machine learning methods onauthentic eye tracking data.The model is defined in terms of four processesthat we assume are operative during reading: lex-ical processing (L), saccade initiation delay (D),motor programming (M), and saccade execution(S).
These processes are defined in terms of a setof parameters that determine their duration.
Oncean ongoing process ends, a subsequent process isinitiated, for as long as reading continues.
As iscommonly assumed in most models of eye move-ment control, language-related processes and mo-tor control processes can run in parallel.
We willuse the notation wi to refer to the ith word in a textw1, .
.
.
, wn consisting of n words, and we will usesubscripted symbols Li, Di, Mi and Si to refer tothe lexical processing, the saccade initiation delay,the motor programming, and the saccade execu-tion associated with wi.In the following four subsections, we outline2In E-Z Reader, the first stage of lexical processing is anearly estimate of the word?s familiarity that provides the sig-nal to the eye movement system that lexical access is immi-nent and that a saccade should be planned.these processes in detail and discuss the generalassumptions underlying them.
We then concludethis section by summarizing how the processes dy-namically interact to produce eye movement be-havior.3.2 Lexical ProcessingThe time needed to process individual words inreading is certain to depend on numerous fac-tors related to a person?s prior reading experi-ence, word-level properties such as length and fre-quency, and higher-order language processes suchas syntactic and semantic processing.
However,since our goal in this paper is to validate a sim-ple model, with as few parameters as possible, wemake the simplifying assumption that the process-ing time of a word can be approximated by itslength (number of characters) and its frequency ofoccurrence in printed text.
In particular, we as-sume that the mean time required for processing aword wi is a linear function of its length and thenatural logarithm of its frequency:3t(Li) = b0+b1 length(wi)?b2 ln(freq(wi)) (1)In equation 1, b0 is the intercept representing thebase time needed to process a word while b1 andb2 are the respective slopes for the effect of lengthand frequency on the base processing time.
Again,we stress that equation 1 is by all accounts an over-simplification.
Thus, for example, it does not takeinto account any higher-level top-down influenceon processing time.Still, we believe equation 1 provides a reason-able first approximation.
A large part of the vari-ance in measures of reading time can be accountedfor by word frequency and word length.
At anyrate, our simple assumption with respect to pro-cessing time represents a methodological decisionrather than a theoretical one.
We want to keep themodel as simple as possible at this stage, and laterexplore the effect of including variables related tohigher-order processing.Once the time interval t(Li) has passed for agiven word wi, lexical processing begins on thenext word.
Thus, the completion of t(Li) resultsin the initiation of Li+1.
Because the processingof the next word does not start until the processingof the current word is finished, lexical processing3We use the logarithm of word frequency because hu-man response times, in lexical decision tasks for instance, arelinearly related to the natural logarithm of word frequency(Balota and Chumbley, 1984).65proceeds serially and no more than one word isprocessed at any given time.3.3 Saccade Initiation DelayWhen the eyes move to a new word wi, a motorprogram is initiated after some time.
We assumethat the time when a motor program is initiateddepends on the processing difficulty of the fixatedword wi.
In particular, the signal to initiate a sac-cade is deferred in proportion to how much pro-cessing remains on wi, or put differently, in pro-portion to how much work remains to be done onthat word.
This general routine serves to preventthe control system from making over-hasty sac-cades to new words.
The length of the saccade ini-tiation delay t(D) is proportional to the remainingprocessing time of word wi at fixation onset:t(Di) = d (t(Li)?
t(Ei)) (2)where d is a free parameter representing a pro-portion, t(Li) is the lexical processing time forthe fixated word, and t(Ei) denotes the interval oftime that has elapsed since the initiation of t(Li).More difficult words are associated with longerprocessing times and thus cause later initiation ofsaccade programs and therefore also longer fix-ation durations.
The free parameter d defines aproportion taking values in the range [0, 1].
Theextremes of this range can be interpreted as fol-lows.
If d is set equal to 0, a new saccade programis initiated immediately upon a new fixation.
Ifd instead is set equal to 1, the saccade programstarts only after the fixated word has been fullyprocessed.
More generally, a change of the valueof this parameter can be understood as a change ofthe amount of cognitive influence on fixation du-rations.
The higher its value, the more cognitivework must be carried out before a new saccadeprogram is started.
Once the time interval t(D)has passed, the planning of a new eye movementstarts, i.e., a motor program, M , is initiated.3.4 Motor ProgrammingThe time needed to plan and initiate an eye move-ment defines the saccade latency, or motor pro-gramming time t(M).
We assume that the dura-tion of this period is given by the free parameterm:t(Mi) = m (3)The following is worth noting.
Some influentialresearch suggests that motor programming is com-pleted in two stages (Becker and J?rgens, 1979).The first of these being a labile stage during whicha planned saccade can be canceled, e.g., in fa-vor of another saccade target.
The second stage,closer in time to the execution of the saccade, isnon-labile and once entered, a saccade underwaycan no longer be modified or canceled.
This divi-sion between labile and non-labile stages of motorprogramming is sometimes implemented in com-putational models, for example in E-Z Reader andSWIFT.
For now, however, our model does not op-erationalize the notion of saccade canceling andthus makes no useful distinction between labileand non-labile stages of motor programming.
Ouronly assumption with respect to these differentstages of motor programming is that their respec-tive durations sum up to m.An important function of motor programmingin our model, however, is to select a target for thesaccade.
Before discussing how this is achievedwe should point out that we make no claim asto how much time of motor programming is con-sumed by target selection.
It is only presupposedthat saccade target selection, in the normal courseof events, is initiated as soon as there is a decisionto make an eye movement (i.e., when motor pro-gramming starts), and that, whatever time remainsof motor programming once a target is selected,this time is spent on preparation of the physicalmovement to the selected target.
Once motor pro-gramming is finished, a saccade S is executed tothe target.Following Nilsson and Nivre (2009), we treattarget selection as a classification task.
In prac-tical terms, this means that we train a classifierto predict the most likely eye movement follow-ing any fixation.
An instance to be classified con-sists of a feature vector encoding feature informa-tion over the current fixated word and words inthe immediate context.
Given such feature rep-resentations and training data obtained from eye-tracking recordings, essentially any standard ma-chine learning algorithm can be applied to theclassification task.
The type of learning algorithmthat performs best on this task is, however, un-known.
Rather than speculate, we suggest that thisis a question for further research.The remaining assumptions we make are as fol-lows.
First, because there is a sharp drop-off inacuity of the human eye around the point of fix-ation, the number of words that can be discrim-inated in parafoveal vision on a given fixation islimited to a few.
Therefore, it is reasonable to as-66sume that the potential targets for a saccade onany given fixation are limited to the words avail-able within the range of effective vision.
4 Thisis supported empirically by the fact that the greatmajority of outgoing saccades tend to land in oneof the three words that follow the current fixation.Moreover, we assume that for these potential tar-gets, only rather coarse, visual information, suchas a gross appreciation of their length, can be ex-tracted on any given fixation.
The reason for thisis that target selection generally occurs relativelyearly on in a fixation, at a time when only low-level visual information can reasonably be gleanedfrom the parafovea.Secondly, we reason that target selection re-flects an autonomous process that has been au-tomated, through years of practice, to progressthrough the text and select targets in the defaultreading direction.
Hence, the possible targets fortarget selection, as construed here, is limited to thetargets within the forward field of effective vision.As a consequence, words to the left of the currentfixation are not fixated as a result of target selec-tion.Finally, we assume that target selection by de-fault is a mechanical routine, insensitive to ongo-ing lexical processing.
In the general case, then,the decision of where to move eyes is made in-dependently of processing considerations.
Mo-tor programs in general, however, may sometimesoverride the default target selection mechanismand be initiated, not in order to select a new target,but to correct for situations where motor controland ongoing language processing are threateningto desynchronize.
Such a corrective program maybe initiated, for instance, if a saccade is executedto wordi but lexical processing has not yet com-pleted on wordi?1, and so more lexical process-ing of wordi?1 is needed before moving on.
Inthis case, a corrective motor program is initiatedto wordi?1, subsequently resulting in a regressionto that word.
In this way, corrective motor pro-grams serve to synchronize the eyes with the cur-rent processing stream and for that reason they al-ways target the word being processed.
Moreover,because corrective saccade programs are launchedwith a fixed target, they do not trigger target selec-tion during motor programming.4The effective visual field (the perceptual span) extendsabout four characters to the left and 15 characters to the rightof the fixation for normal readers of left-to-right orthogra-phies (Rayner, 1998).3.5 Saccade ExecutionThe time to execute a saccade t(S) is determinedby the free parameter s:t(Si) = s (4)Once a saccade has been executed, the position ofthe eyes shifts to a new word and thus, in the nor-mal course of events, a new motor program is initi-ated after t(Di).
However, sometimes a saccade ismade ahead of the current processing stream, be-cause, as noted earlier, a word needs not be fullyprocessed before a saccade is executed to anotherword.
Likewise, a saccade may sometimes be ex-ecuted to a word that has already been fully pro-cessed, because target selection is an autonomousprocess, not influenced by ongoing processing.
Inthese situations, corrective saccade programs areinitiated.
Since corrective saccade programs serveonly to rapidly coordinate the eyes and the cur-rent processing stream, we assume that they canbe initiated immediately and hence that they arenot subject to saccade initiation delay.3.6 Eye Movement ControlHaving defined the respective component pro-cesses, we now consider how these processes arecoordinated to model eye movement control.
Lex-ical processing is always running in parallel withthe processes controlling saccade initiation delay,motor programming and saccade execution, whichare executed in sequence.
A simulation of read-ing is started by initiating lexical processing of thefirst word (L1), and the saccade initiation delayfor the first word (D1) (i.e., the first word is fix-ated).
Whenever one of the running processes ter-minates, new processes are initiated in the follow-ing way:?
If Li terminates, initiate Li+1.?
If Di terminates, initiate Mi and select newfixation target wj .?
If Mi terminates, initiate Si.?
If Si terminates and the ongoing lexical pro-cess is Lj :?
If i = j, initiate Di.?
If i 6= j, initiate Mj and set fixation tar-get to wjThe simulation terminates when all words havebeen lexically processed.674 Experimental Evaluation4.1 Experimental SetupIn order to estimate the performance of the modeldescribed in the previous section, some experi-ments were performed using data from the Englishsection of the Dundee corpus (Kennedy and Pynte,2005).In most evaluations of eye movement controlmodels, the model parameters are fitted againstone and the same corpus by searching the param-eter space to find the set of parameter values thatbest simulates the observed data.
This approachmakes it somewhat hard to appreciate how wella given model generalizes to new, previously un-seen data.
A more stringent evaluation, which af-fords an assessment of the generalization error ofmodel predictions, is to set the model parameterson some portion of the data and then test the modelon another held-out portion.
The results we reportin this paper were obtained this way.The Dundee corpus that was used in these ex-periments contains the eye tracking records of tensubjects reading editorials from The Independent,a UK broadsheet newspaper.
The data consist of20 texts that were read by all subjects, and close to2400 sentences.
We divided these texts into threesets: the first 16 for training (1911 sentences),17-18 for model development and validation (237sentences), and the last two texts, 19-20, for blindtesting of the model (231 sentences).
Model pa-rameters were fitted using only the training andvalidation set, prior to evaluating the model on theheld-out test set.Next we discuss how training was performed,both in terms of the training of the classifier fortarget selection and in terms of the estimation ofthe model?s process parameters on the trainingdata.
Before presenting the results, we also discusssome standard practice in benchmarking modelsof eye movement control.4.2 Training the ClassifierWe used the transition-based model outlined byNilsson and Nivre (2009) in combination with lo-gistic regression for training the target selectionclassifier.
The classifier was trained on a restrictednumber of features defined over words in the fixa-tion context.
The feature model we used for theseexperiments included information about the wordlength of the current fixation and upcoming words,as well as some historical information about re-cently made eye movements.
The history of pre-vious eye movements was represented in termsof the saccade distance (measured in number ofwords) that led up to recently made fixations (in-cluding the current fixation).
In this way, the fea-ture model contained information about, for in-stance, whether the saccade that led up to the cur-rent fixation skipped a word or two.In contrast to Nilsson and Nivre (2009) we didnot train one model for each individual subject inthe corpus.
Instead, we trained a single multiple-subject classifier on all ten readers in the trainingset.
The performance of this classifier was as-sessed in terms of how well, on average, it pre-dicted the observed saccade targets for any givenreader on the development set.
Moreover, in linewith the assumption that target selection is re-stricted to a limited number of candidate words inthe forward visual field, the classifier was trainedto select one of the three words following any fixa-tion as the target for a saccade.
This cross-subjectclassifier achieved an average prediction accuracyof 72% on the development set.4.3 Estimating Model ParametersBecause the model?s process parameters can notbe directly estimated from eye tracking data theyneed to be approximated in other ways.
The val-ues for the intercept and slope parameters for lexi-cal processing time t(Li) were obtained by fittinga linear regression of gaze duration on logarithmicword frequency and word length on the trainingdata.
The assumption that the gaze duration ona given word reflects the time required to processthe word is necessarily an oversimplification butis sometimes used in eye movement modeling.
Anumber of studies indicate that it is indeed a rea-sonable approximation (Engbert et al, 2002; Pol-latsek et al, 2006).The value for the parameter d in the equation fort(Di) was selected based on a simple parametersearch over the training data.
The best fitting valuewas assessed by calculating the root mean squareerror between predicted and observed values forgaze durations for different values of d rangingfrom 0 to 1 in 0.1 increments, while keeping otherparameter values unchanged.
To keep things sim-ple, the parameters that determine the mean dura-tion of motor programming, m, and saccade exe-cution, s, were fixed at 200 ms, and 25 ms, respec-tively.
These values are in good agreement with68Parameter Interpretation Valueb0 Intercept: base lexical processing time (ms) 165.5b1 Slope: effect of length on lexical processing time (ms) 13.5b2 Slope: effect of frequency on lexical processing time (ms) 3.2d Proportion of lexical processing time (determines saccade initiation delay) 0.5m Mean motor programming time (ms) 200s Mean saccade execution time (ms) 25Table 1: Model parameters, their interpretations and values, as estimated during training.estimated values in experimental studies.
Table 1lists the model?s six process parameters and theirvalues, obtained prior to testing the model.4.4 Benchmark EvaluationModels of eye movement control in reading aretypically benchmarked against a set of word-baseddependent eye movement measures which are av-eraged across subjects.
Two such measures aregaze duration and probability of skipping.
Gazeduration is defined as the sum duration of all fix-ations on a word prior to any saccade leavingthe word during first-pass reading.
Probability ofskipping is simply the mean probability (acrosssubjects) that a given word is skipped (not fixated)during first-pass reading.Because word frequency effects on eye move-ments during reading are robust and well-documented, one common benchmark practice isto evaluate models with respect to their capabil-ity of reproducing word frequency effects on fix-ation times and fixation probabilities.
Typically,averages of word-based measures are then brokendown into word-frequency classes.
This is a fairlysimple way to see how well a given model canpredict observed means for measures such as gazeduration and skipping probability for words of dif-ferent frequency classes.
The results we report arepresented this way.
We used frequency estimatesbased on word occurrences in the written part ofthe British National Corpus (BNC).
Frequencieswere normalized to occurrences per million wordsand then divided into five frequency classes, assuggested by Reichle et al (1998).In addition to the model we have outlined sofar, we also present results for two alternativeversions.
These models differ from the one wehave discussed only in positing a simpler func-tion for lexical processing time.
The alternativeversions model lexical processing time only as alinear function of either word length or logarith-mic word frequency.
Hence, we fitted two sepa-rate simple linear regressions of gaze duration firston word length, and then on logarithmic word fre-quency.
The regression coefficient and slope wereestimated to 132.5 and 16 for the model based onword length, and 284 and -11 for the model basedon frequency.4.5 Results and DiscussionTable 2 shows the observed (empirical) and pre-dicted (simulated) values of gaze durations andskipping probabilities for each of the five word fre-quency classes, both on the development set andon the held-out test set.
M1 and M2 represent theversions of the model in which lexical processingtime is a linear function of word length, and wordfrequency, respectively.
M3 represents the versionof the model where lexical processing time is alinear function of both variables.The results show that all three models, on thedevelopment set as well as on the test set, areable to reproduce the most important aspect ofthe observed data, namely, that mean gaze du-rations decrease and mean skipping probabilitiesincrease with increasing word frequency.
Over-all, M3 performs better than the two other modelsin predicting this relationship.
The model basedonly on word length, M1, performs worse than theother two models.
This is mainly due to the poorperformance of this model in simulating the pro-portions of skipped words in the upper frequencyclasses 4 and 5.
In comparison to both M2 and M3,M1 seriously underestimates the observed skip-ping probability for words belonging to these fre-quency classes, on both development and test data.With respect to gaze duration alone, the threemodels perform similarly, although M3 providesa somewhat better fit on both data sets.
The mod-els generally predict longer gaze durations than theobserved means, except for the most low-frequentwords.
In particular, gaze durations for higher-frequency words (class 4 and 5) are prolongedcompared to the means, giving an overall nar-69Gaze duration Probability of skippingDevelopment Test Development TestFrequency class Observed M1 M2 M3 Observed M1 M2 M3 Observed M1 M2 M3 Observed M1 M2 M31 290 282 280 285 286 278 280 284 0.17 0.15 0.18 0.13 0.16 0.14 0.19 0.142 257 271 259 272 261 273 260 275 0.19 0.18 0.20 0.16 0.19 0.15 0.22 0.173 229 254 252 249 235 257 254 252 0.24 0.19 0.24 0.20 0.22 0.19 0.25 0.204 208 240 238 237 210 244 238 237 0.52 0.23 0.36 0.43 0.53 0.24 0.34 0.405 198 238 236 228 195 239 237 230 0.65 0.34 0.51 0.54 0.67 0.32 0.52 0.51Table 2: Observed and predicted values of Gaze Durations (ms) and Skipping Probabilities on de-velopment and test set for five frequency classes of words.
M1: t(Li) = b0 + b1length(wi), Rootmean square error on development set = 0.48, Root mean square error on test set = 0.52; M2:t(Li) = b0 ?
b1 ln(freq(wi)), Root mean square error on development set = 0.33, Root mean squareerror on test set = 0.35; M3: t(Li) = b0 + b1length(wi) ?
b2 ln(freq(wi)), Root mean square error ondevelopment set = 0.21, Root mean square error on test set = 0.26; Frequency range: 1:1-10, 2:11-100,3:101-1000, 4:1001-10000, 5: 10001+rower range of mean values for the five frequencyclasses.The overall performance of each model, M1,M2 and M3 was estimated by calculating the rootmean square error (RMSE) between the mean ob-served and predicted gaze durations and probabil-ities of skipping.
The errors were normalized asdescribed in Reichle et al (1998).
In comparingthe results for both development and test data, thebest overall fit is provided by M3 on the develop-ment set, giving an RMSE of 0.21 (smaller val-ues indicate better fit).
The fit for the same modeldrops to 0.26 when evaluated on the held-out testdata.To provide some basis for comparison, the ear-liest version of E-Z Reader (Reichle et al, 1998)which was fitted to the same dependent measures,had an RMSE of 0.145.
It is important to pointout, however, that this result was based on fittingthe model parameters to a single sentence corpusof 48 sentences designed for experimental pur-poses.
This corpus contained relatively short (8-14 words) isolated sentences without any connect-ing discourse.
More generally, as noted by Re-ichle et al (2009), RMSD values lower than 0.5provide fits that are reasonably close to the ob-served means.
By this standard, the model M3 per-forms rather well in simulating the observed data.Moreover, this version of the model provides themost realistic estimates of the time it takes to iden-tify words.
Thus, for example, the mean time toidentify the most frequent word in English, ?the?
(frequency class 5), is estimated to be 171 ms,whereas the mean time to identify the word ?re-populate?, which is a low-frequency (frequencyclass 1) ten-letter word is estimated to be 301 ms.These estimates are in good agreement with ex-perimental estimates, which show that word iden-tification latencies range between 150 and 300 ms(Rayner and Pollatsek, 1989).5 ConclusionIn this paper we built on previous work using ma-chine learning methods to model saccade behaviorin reading and we extended this work by present-ing a data-driven model of eye movement controlthat provides detailed predictions for both whenand where the eyes move during reading.
The mostimportant principles of this model are (i) the initi-ation of eye movements is delayed as a functionof on-line processing difficulty, and (ii) the deci-sion of where to move the eyes is driven by anautonomous routine that has become automatedthrough years of practice in reading.
The modelwas trained on eye movements made over a largecorpus of natural text.
In benchmarking the modelagainst held-out data we showed that it is able toreproduce frequency effects on both gaze dura-tion and skipping probability with good accuracy(RMSE = 0.26).Looking ahead, we plan to extend the modelto account for more empirical data on eye move-ment behavior in reading.
One important stepto meet this goal is to develop a more informedmodel of language processing.
Current modelsof eye movement control in reading generally as-sume that influences from syntactic and higher-order processing occur too late in the process-ing stream to directly influence eye movements.This is, however, seemingly at odds with recent70findings in sentence processing research showingan influence of syntactic processing difficulty onboth early and late measures of eye movementsin reading (Demberg and Keller, 2008; Boston etal., 2008).
Hence, it is possible that a more ac-curate model of eye movements in reading willneed to allow for syntactic processing to influ-ence the early decisions that control the timing ofeye movements.
This and other issues will be ad-dressed in future work.ReferencesDavid.
A Balota and James.
I Chumbley.
1984.
Arelexical decisions a good measure of lexical access?the role of word frequency in the neglected decisionstage.
Journal of Experimental Psychology: Humanperception and Performace, 10:340?357.David.
A. Balota, Alexander Pollatsek, and KeithRayner.
1985.
The interaction of contextual con-straints and parafoveal visual information in reading.Cognitive Psychology, 17:364?390.W Becker and R J?rgens.
1979.
An analysis of thesaccadic system by means of double step stimuli.
Vi-sion Research, 19:967?983.Marisa F. Boston, John Hale, Reinhold Kliegl, UmeshPatil, and Shravan Vasishth.
2008.
Parsing costs aspredictors of reading difficulty: An evaluation usingthe potsdam sentence corpus.
Journal of Eye Move-ment Reasearch, 2:1?12.Marc Brysbaert and Fran?oise Vitu.
1998.
Word skip-ping: implications for theories of eye movementcontrol in reading.
In Geoffrey Underwood, edi-tor, Eye guidance in Reading and Scene Perception,pages 124?147.
Elsevier science Ltd.Charles Clifton, Adrian Staub, and Keith Rayner.2007.
Eye movements in reading words and sen-tences.
In Roger van Gompel, editor, Eye move-ments: A window on mind and brain, pages 341?372.
Amsterdam: Elsevier.Vera Demberg and Frank Keller.
2008.
Data from eye-tracking corpora as evidence for theories of syntacticprocessing complexity.
Cognition, 109:193?210.Ralf Engbert, Andr?
Longtin, and Reinhold Kliegl.2002.
A dynamical model of saccade generationin reading based on spatially distributed lexical pro-cessing.
Vision Research, 42:621?636.Ralf Engbert, Antje Nuthmann, Eike Richter, and Rein-hold Kliegl.
2005.
SWIFT: A dynamical model ofsaccade generation during reading.
PsychologicalReview, 112:777?813.Alan Kennedy and Jo?l Pynte.
2005.
Parafoveal-on-foveal effects in normal reading.
Vision research,45:153?168.R.
M. McPeek, A.
A. Skavenski, and K Nakayama.2000.
Concurrent processing of saccades in visualsearch.
Vision Research, 40:2499?2516.Mattias Nilsson and Joakim Nivre.
2009.
Learn-ing where to look: Modeling eye movements inreading.
In Proceedings of the Thirteenth Confer-ence on Computational Natural Language Learning(CoNLL-2009), pages 93?101.Alexander Pollatsek, Mary Lesch, Robin K. Morris,and Keith Rayner.
1992.
Phonological codesare used in integrating information across saccadesin word identification and reading.
ExperimentalPsychology: Human Perception and Performance,18:148?162.Alexander Pollatsek, Erik Reichle, and Keith Rayner.2006.
Tests of the E-Z Reader model: Exploringthe interface between cognition and eye movements.Cognitive Psychology, 52:1?56.Keith Rayner and Alexander Pollatsek.
1989.
The psy-chology of reading.
Englewood Cliffs, NJ: PrenticeHall.Keith Rayner, Albert W. Inhoff, Robert E. Morrison,Maria L. Slowiaczek, and James H. Bertera.
1981.Masking of foveal and parafoveal vision duringeye fixations in reading.
Journal of ExperimentalPsychology: Human Perception and Performance,7:167?179.Keith Rayner, Simon P. Liversedge, Sarah J.
White, andDorine Vergilino-Perez.
2003.
Reading disappear-ing text: cognitive control of eye movements.
Psy-chological science, 14:385?388.Keith Rayner.
1998.
Eye movements in reading andinformation processing: 20 years of research.
Psy-chological Bulletin, 124:372?422.Erik Reichle, Alexander Pollatsek, Donald Fisher, andKeith Rayner.
1998.
Toward a model of eye move-ment control in reading.
Psychological Review,105:125?157.Erik Reichle, Keith Rayner, and Alexander Pollatsek.2003.
The E-Z Reader model of eye-movement con-trol in reading: Comparisons to other models.
Be-havioral and Brain Sciences, 26:445?476.Erik Reichle, Tessa Warren, and Kerry McConnell.2009.
Using E-Z Reader to model the effects ofhigher-level language processing on eye movementsduring reading.
Psychonomic Bulletin & Review,16:1?21.Eric Reichle, editor.
2006a.
Cognitive Systems Re-search.
7:1?96.
Special issue on models of eye-movement control in reading.Eric Reichle.
2006b.
Computational models of eyemovement control in reading: Theories of the ?eye-mind" link.
Cognitive Systems Research, 7:2?3.71
