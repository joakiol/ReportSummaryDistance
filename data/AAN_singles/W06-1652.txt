Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing (EMNLP 2006), pages 440?448,Sydney, July 2006. c?2006 Association for Computational LinguisticsFeature Subsumption for Opinion AnalysisEllen Riloff and Siddharth PatwardhanSchool of ComputingUniversity of UtahSalt Lake City, UT 84112{riloff,sidd}@cs.utah.eduJanyce WiebeDepartment of Computer ScienceUniversity of PittsburghPittsburgh, PA 15260wiebe@cs.pitt.eduAbstractLexical features are key to many ap-proaches to sentiment analysis and opin-ion detection.
A variety of representationshave been used, including single words,multi-word Ngrams, phrases, and lexico-syntactic patterns.
In this paper, we use asubsumption hierarchy to formally definedifferent types of lexical features and theirrelationship to one another, both in termsof representational coverage and perfor-mance.
We use the subsumption hierar-chy in two ways: (1) as an analytic toolto automatically identify complex featuresthat outperform simpler features, and (2)to reduce a feature set by removing un-necessary features.
We show that reduc-ing the feature set improves performanceon three opinion classification tasks, espe-cially when combined with traditional fea-ture selection.1 IntroductionSentiment analysis and opinion recognition are ac-tive research areas that have many potential ap-plications, including review mining, product rep-utation analysis, multi-document summarization,and multi-perspective question answering.
Lexi-cal features are key to many approaches, and a va-riety of representations have been used, includingsingle words, multi-word Ngrams, phrases, andlexico-syntactic patterns.
It is common for dif-ferent features to overlap representationally.
Forexample, the unigram ?happy?
will match all ofthe texts that the bigram ?very happy?
matches.Since both features represent a positive sentimentand the bigram matches fewer contexts than theunigram, it is probably sufficient just to have theunigram.
However, there are many cases wherea feature captures a subtlety or non-compositionalmeaning that a simpler feature does not.
For exam-ple, ?basket case?
is a highly opinionated phrase,but the words ?basket?
and ?case?
individuallyare not.
An open question in opinion analysis ishow often more complex feature representationsare needed, and which types of features are mostvaluable.
Our first goal is to devise a method toautomatically identify features that are represen-tationally subsumed by a simpler feature but thatare better opinion indicators.
These subjective ex-pressions could then be added to a subjectivity lex-icon (Esuli and Sebastiani, 2005), and used to gainunderstanding about which types of complex fea-tures capture meaningful expressions that are im-portant for opinion recognition.Many opinion classifiers are created by adopt-ing a ?kitchen sink?
approach that throws togethera variety of features.
But in many cases addingnew types of features does not improve perfor-mance.
For example, Pang et al (2002) found thatunigrams outperformed bigrams, and unigramsoutperformed the combination of unigrams plusbigrams.
Our second goal is to automatically iden-tify features that are unnecessary because similarfeatures provide equal or better coverage and dis-criminatory value.
Our hypothesis is that a re-duced feature set, which selectively combines un-igrams with only the most valuable complex fea-tures, will perform better than a larger feature setthat includes the entire ?kitchen sink?
of features.In this paper, we explore the use of a subsump-tion hierarchy to formally define the subsump-tion relationships between different types of tex-tual features.
We use the subsumption hierarchyin two ways.
First, we use subsumption as an an-440alytic tool to compare features of different com-plexities and automatically identify complex fea-tures that substantially outperform their simplercounterparts.
Second, we use the subsumption hi-erarchy to reduce a feature set based on represen-tational overlap and on performance.
We conductexperiments with three opinion data sets and showthat the reduced feature sets can improve classifi-cation performance.2 The Subsumption Hierarchy2.1 Text RepresentationsWe analyze two feature representations that havebeen used for opinion analysis: Ngrams and Ex-traction Patterns.
Information extraction (IE)patterns are lexico-syntactic patterns that rep-resent expressions which identify role relation-ships.
For example, the pattern ?<subj>ActVP(recommended)?
extracts the subject ofactive-voice instances of the verb ?recommended?as the recommender.
The pattern ?<subj>PassVP(recommended)?
extracts the subject ofpassive-voice instances of ?recommended?
as theobject being recommended.
(Riloff and Wiebe, 2003) explored the ideaof using extraction patterns to represent morecomplex subjective expressions that have non-compositional meanings.
For example, the expres-sion ?drive (someone) up the wall?
expresses thefeeling of being annoyed, but the meanings of thewords ?drive?, ?up?, and ?wall?
have no emotionalconnotations individually.
Furthermore, this ex-pression is not a fixed word sequence that can beadequately modeled by Ngrams.
Any noun phrasecan appear between the words ?drive?
and ?up?, soa flexible representation is needed to capture thegeneral pattern ?drives <NP> up the wall?.This example represents a general phenomenon:many expressions allow intervening noun phrasesand/or modifying terms.
For example:?stepped on <mods> toes?Ex: stepped on the boss?
toes?dealt <np> <mods> blow?Ex: dealt the company a decisive blow?brought <np> to <mods> knees?Ex: brought the man to his knees(Riloff and Wiebe, 2003) also showed that syn-tactic variations of the same verb phrase can be-have very differently.
For example, they found thatpassive-voice constructions of the verb ?ask?
hada 100% correlation with opinion sentences, butactive-voice constructions had only a 63% corre-lation with opinions.Pattern Type Example Pattern<subj> PassVP <subj> is satisfied<subj> ActVP <subj> complained<subj> ActVP Dobj <subj> dealt blow<subj> ActInfVP <subj> appear to be<subj> PassInfVP <subj> is meant to be<subj> AuxVP Dobj <subj> has position<subj> AuxVP Adj <subj> is happyActVP <dobj> endorsed <dobj>InfVP <dobj> to condemn <dobj>ActInfVP <dobj> get to know <dobj>PassInfVP <dobj> is meant to be <dobj>Subj AuxVP <dobj> fact is <dobj>NP Prep <np> opinion on <np>ActVP Prep <np> agrees with <np>PassVP Prep <np> is worried about <np>InfVP Prep <np> to resort to <np><possessive> NP <noun>?s speechFigure 1: Extraction Pattern TypesOur goal is to use the subsumption hierarchyto identify Ngram and extraction pattern featuresthat are more strongly associated with opinionsthan simpler features.
We used three types of fea-tures in our research: unigrams, bigrams, and IEpatterns.
The Ngram features were generated us-ing the Ngram Statistics Package (NSP) (Baner-jee and Pedersen, 2003).1 The extraction pat-terns (EPs) were automatically generated usingthe Sundance/AutoSlog software package (Riloffand Phillips, 2004).
AutoSlog relies on the Sun-dance shallow parser and can be applied exhaus-tively to a text corpus to generate IE patterns thatcan extract every noun phrase in the corpus.
Au-toSlog has been used to learn IE patterns for thedomains of terrorism, joint ventures, and micro-electronics (Riloff, 1996), as well as for opinionanalysis (Riloff and Wiebe, 2003).
Figure 1 showsthe 17 types of extraction patterns that AutoSloggenerates.
PassVP refers to passive-voice verbphrases (VPs), ActVP refers to active-voice VPs,InfVP refers to infinitive VPs, and AuxVP refers1NSP is freely available for use under the GPL fromhttp://search.cpan.org/dist/Text-NSP.
We discarded Ngramsthat consisted entirely of stopwords.
We used a list of 281stopwords.441to VPs where the main verb is a form of ?to be?or ?to have?.
Subjects (subj), direct objects (dobj),PP objects (np), and possessives can be extractedby the patterns.22.2 The Subsumption HierarchyWe created a subsumption hierarchy that definesthe representational scope of different types of fea-tures.
We will say that feature A representation-ally subsumes feature B if the set of text spansthat match feature A is a superset of the set of textspans that match feature B.
For example, the uni-gram ?happy?
subsumes the bigram ?very happy?because the set of text spans that match ?happy?includes the text spans that match ?very happy?.First, we define a hierarchy of valid subsump-tion relationships, shown in Figure 2.
The 2Gramnode, for example, is a child of the 1Gram nodebecause a 1Gram can subsume a 2Gram.
Ngramsmay subsume extraction patterns as well.
Ev-ery extraction pattern has at least one correspond-ing 1Gram that will subsume it.3.
For example,the 1Gram ?recommended?
subsumes the pattern?<subj> ActVP(recommended)?
because the pat-tern only matches active-voice instances of ?rec-ommended?.
An extraction pattern may alsosubsume another extraction pattern.
For exam-ple, ?<subj> ActVP(recommended)?
subsumes?<subj> ActVP(recommended) Dobj(movie)?.To compare specific features we need to for-mally define the representation of each type offeature in the hierarchy.
For example, the hierar-chy dictates that a 2Gram can subsume the pattern?ActInfVP <dobj>?, but this should hold only ifthe words in the bigram correspond to adjacentwords in the pattern.
For example, the 2Gram ?tofish?
subsumes the pattern ?ActInfVP(like to fish)<dobj>?.
But the 2Gram ?like fish?
should notsubsume it.
Similarly, consider the pattern ?In-fVP(plan) <dobj>?, which represents the infini-tive ?to plan?.
This pattern subsumes the pattern?ActInfVP(want to plan) <dobj>?, but it shouldnot subsume the pattern ?ActInfVP(plan to start)?.To ensure that different features truly subsumeeach other representationally, we formally defineeach type of feature based on words, sequential2However, the items extracted by the patterns are not ac-tually used by our opinion classifiers; only the patterns them-selves are matched against the text.3Because every type of extraction pattern shown in Fig-ure 1 contains at least one word (not including the extractedphrases, which are not used as part of our feature representa-tion).dependencies, and syntactic dependencies.
A se-quential dependency between words wi and wi+1means that wi and wi+1 must be adjacent, and thatwi must precede wi+1.
Figure 3 shows the formaldefinition of a bigram (2Gram) node.
The bigramis defined as two words with a sequential depen-dency indicating that they must be adjacent.Name = 2GramConstituent[0] = WORD1Constituent[1] = WORD2Dependency = Sequential(0, 1)Figure 3: 2Gram DefinitionA syntactic dependency between words wi andwi+1 means that wi has a specific syntactic rela-tionship to wi+1, and wi must precede wi+1.
Forexample, consider the extraction pattern ?NP Prep<np>?, in which the object of the preposition at-taches to the NP.
Figure 4 shows the definition ofthis extraction pattern in the hierarchy.
The pat-tern itself contains three components: the NP, theattaching preposition, and the object of the prepo-sition (which is the NP that the pattern extracts).The definition also includes two syntactic depen-dencies: the first dependency is between the NPand the preposition (meaning that the prepositionsyntactically attaches to the NP), while the seconddependency is between the preposition and the ex-traction (meaning that the extracted NP is the syn-tactic object of the preposition).Name = NP Prep <np>Constituent[0] = NPConstituent[1] = PREPConstituent[2] = NP EXTRACTIONDependency = Syntactic(0, 1)Dependency = Syntactic(1, 2)Figure 4: ?NP Prep <np>?
Pattern DefinitionConsequently, the bigram ?affair with?
will notsubsume the extraction pattern ?affair with <np>?because the bigram requires the noun and preposi-tion to be adjacent but the pattern does not.
For ex-ample, the extraction pattern matches the text ?anaffair in his mind with Countess Olenska?
but thebigram does not.
Conversely, the extraction pat-tern does not subsume the bigram either becausethe pattern requires syntactic attachment but thebigram does not.
For example, the bigram matches442<subj> ActVP<subj> ActInfVP<subj> ActVP Dobj<subj> PassVP<subj> PassInfVPInfVP <dobj>ActInfVP <dobj>PassInfVP <dobj>1Gram2Gram<possessive> NP<subj> AuxVP AdjP<subj> AuxVP DobjActVP <dobj>ActVP Prep <np>NP Prep <np>PassVP Prep <np>Subj AuxVP <dobj>3GramActVP Prep:OF <np>InfVP Prep <np>NP Prep:OF <np>PassVP Prep:OF <np>4GramInfVP Prep:OF <np>Figure 2: The Subsumption Hierarchythe sentence ?He ended the affair with a sense ofrelief?, but the extraction pattern does not.Figure 5 shows the definition of another ex-traction pattern, ?InfVP <dobj>?, which includesboth syntactic and sequential dependencies.
Thispattern would match the text ?to protest hightaxes?.
The pattern definition has three compo-nents: the infinitive ?to?, a verb, and the direct ob-ject of the verb (which is the NP that the patternextracts).
The definition also shows two syntac-tic dependencies.
The first dependency indicatesthat the verb syntactically attaches to the infinitive?to?.
The second dependency indicates that the ex-tracted NP syntactically attaches to the verb (i.e.,it is the direct object of that particular verb).The pattern definition also includes a sequen-tial dependency, which specifies that ?to?
must beadjacent to the verb.
Strictly speaking, our parserdoes not require them to be adjacent.
For exam-ple, the parser allows intervening adverbs to splitinfinitives (e.g., ?to strongly protest high taxes?
),and this does happen occasionally.
But split in-finitives are relatively rare, so in the vast major-ity of cases the infinitive ?to?
will be adjacent tothe verb.
Consequently, we decided that a bigram(e.g., ?to protest?)
should representationally sub-sume this extraction pattern because the syntac-tic flexibility afforded by the pattern is negligi-ble.
The sequential dependency link representsthis judgment call that the infinitive ?to?
and theverb are adjacent in most cases.For all of the node definitions, we used our bestjudgment to make decisions of this kind.
We triedto represent major distinctions between features,without getting caught up in minor differences thatwere likely to be negligible in practice.Name = InfVP <dobj>Constituent[0] = INFINITIVE TOConstituent[1] = VERBConstituent[2] = DOBJ EXTRACTIONDependency = Syntactic(0, 1)Dependency = Syntactic(1, 2)Dependency = Sequential(0, 1)Figure 5: ?InfVP <dobj>?
Pattern DefinitionTo use the subsumption hierarchy, we assigneach feature to its appropriate node in the hierar-chy based on its type.
Then we perform a top-down breadth-first traversal.
Each feature is com-pared with the features at its ancestor nodes.
Ifa feature?s words and dependencies are a supersetof an ancestor?s words and dependencies, then itis subsumed by the (more general) ancestor anddiscarded.4 When the subsumption process is fin-ished, a feature remains in the hierarchy only if4The words that they have in common must also be in thesame relative order.443there are no features above it that subsume it.2.3 Performance-based SubsumptionRepresentational subsumption is concerned withwhether one feature is more general than another.But the purpose of using the subsumption hier-archy is to identify more complex features thatoutperform simpler ones.
Applying the subsump-tion hierarchy to features without regard to per-formance would simply eliminate all features thathave a more general counterpart in the feature set.For example, all bigrams would be discarded iftheir component unigrams were also present in thehierarchy.To estimate the quality of a feature, we use In-formation Gain (IG) because that has been shownto work well as a metric for feature selection (For-man, 2003).
We will say that feature A be-haviorally subsumes feature B if two criteria aremet: (1) A representationally subsumes B, and (2)IG(A) ?
IG(B) - ?, where ?
is a parameter repre-senting an acceptable margin of performance dif-ference.
For example, if ?=0 then condition (2)means that feature A is just as valuable as fea-ture B because its information gain is the same orhigher.
If ?>0 then feature A is allowed to be a lit-tle worse than feature B, but within an acceptablemargin.
For example, ?=.0001 means that A?s in-formation gain may be up to .0001 lower than B?sinformation gain, and that is considered to be anacceptable performance difference (i.e., A is goodenough that we are comfortable discarding B infavor of the more general feature A).Note that based on the subsumption hierarchyshown in Figure 2, all 1Grams will always sur-vive the subsumption process because they cannotbe subsumed by any other types of features.
Ourgoal is to identify complex features that are worthadding to a set of unigram features.3 Data SetsWe used three opinion-related data sets for ouranalyses and experiments: the OP data set createdby (Wiebe et al, 2004), the Polarity data set5 cre-ated by (Pang and Lee, 2004), and the MPQA dataset created by (Wiebe et al, 2005).6 The OP andPolarity data sets involve document-level opinionclassification, while the MPQA data set involves5Version v2.0, which is available at:http://www.cs.cornell.edu/people/pabo/movie-review-data/6Available at http://www.cs.pitt.edu/mpqa/databaserelease/sentence-level classification.The OP data consists of 2,452 documents fromthe Penn Treebank (Marcus et al, 1993).
Metadatatags assigned by the Wall Street Journal define theopinion/non-opinion classes: the class of any doc-ument labeled Editorial, Letter to the Editor, Arts& Leisure Review, or Viewpoint by the Wall StreetJournal is opinion, and the class of documents inall other categories (such as Business and News)is non-opinion.
This data set is highly skewed,with only 9% of the documents belonging to theopinion class.
Consequently, a trivial (but useless)opinion classifier that labels all documents as non-opinion articles would achieve 91% accuracy.The Polarity data consists of 700 positive and700 negative reviews from the Internet MovieDatabase (IMDb) archive.
The positive and neg-ative classes were derived from author ratings ex-pressed in stars or numerical values.
The MPQAdata consists of English language versions of ar-ticles from the world press.
It contains 9,732sentences that have been manually annotated forsubjective expressions.
The opinion/non-opinionclasses are derived from the lower-level annota-tions: a sentence is an opinion if it contains a sub-jective expression of medium or higher intensity;otherwise, it is a non-opinion sentence.
55% of thesentences belong to the opinion class.4 Using the Subsumption Hierarchy forAnalysisIn this section, we illustrate how the subsump-tion hierarchy can be used as an analytic tool toautomatically identify features that substantiallyoutperform simpler counterparts.
These featuresrepresent specialized usages and expressions thatwould be good candidates for addition to a sub-jectivity lexicon.
Figure 6 shows pairs of features,where the first is more general and the second ismore specific.
These feature pairs were identifiedby the subsumption hierarchy as being representa-tionally similar but behaviorally different (so themore specific feature was retained).
The IGaincolumn shows the information gain values pro-duced from the training set of one cross-validationfold.
The Class column shows the class that themore specific feature is correlated with (the moregeneral feature is usually not strongly correlatedwith either class).The top table in Figure 6 contains examples forthe opinion/non-opinion classification task from444Opinion/Non-Opinion ClassificationID Feature IGain Class ExampleA1 line .0016 - .
.
.
issue consists of notes backed by credit line receivablesA2 the line .0075 opin ...lays it on the line; ...steps across the lineB1 nation .0046 - .
.
.
has 750,000 cable-tv subscribers around the nationB2 a nation .0080 opin It?s not that we are spawning a nation of ascetics .
.
.C1 begin .0006 - Campeau buyers will begin writing orders...C2 begin with .0036 opin To begin with, we should note that in contrast...D1 benefits .0040 - .
.
.
earlier period included $235,000 in tax benefits.DEP NP Prep(benefits to) .0090 opin .
.
.
boon to the rich with no proven benefits to the economyE1 due .0001 - .
.
.
an estimated $ 1.23 billion in debt due next springEEP ActVP Prep(due to) .0038 opin It?s all due to the intense scrutiny...Positive/Negative Sentiment ClassificationID Feature IGain Class ExampleF1 short .0014 - to make a long story short...F2 nothing short .0039 pos nothing short of spectacularG1 ugly .0008 - ...an ugly monster on a cruise linerG2 and ugly .0054 neg it?s a disappointment to see something this dumb and uglyH1 disaster .0010 - ...rated pg-13 for disaster related elementsHEP AuxVP Dobj(be disaster) .0048 neg .
.
.
this is such a confused disaster of a filmI1 work .0002 - the next day during the drive to work...IEP ActVP(work) .0062 pos the film will work just as well...J1 manages .0003 - he still manages to find time for his wifeJEP ActInfVP(manages to keep) .0054 pos this film manages to keep up a rapid paceFigure 6: Sample features that behave differently, as revealed by the subsumption hierarchy.
(1 ?
unigram; 2 ?
bigram; EP ?
extraction pattern)the OP data.
The more specific features are morestrongly correlated with opinion articles.
Surpris-ingly, simply adding a determiner can dramaticallychange behavior.
Consider A2.
There are manysubjective idioms involving ?the line?
(two areshown in the table; others include ?toe the line?and ?draw the line?
), while objective languageabout credit lines, phone lines, etc.
uses the deter-miner less often.
Similarly, consider B2.
Adding?a?
to ?nation?
often corresponds to an abstractreference used when making an argument (e.g.,?a nation of ascetics?
), whereas other instancesof ?nation?
are used more literally (e.g., ?the 6thlargest in the nation?).
21% of feature B1?s in-stances appear in opinion articles, while 70% offeature B2?s instances are in opinion articles.
?Begin with?
(C2) captures an adverbial phraseused in argumentation (?To begin with...?)
butdoes not match objective usages such as ?willbegin?
an action.
The word ?benets?
alone(D1) matches phrases like ?tax benets?
and ?em-ployee benets?
that are not opinion expressions,while DEP typically matches positive senses ofthe word ?benets?.
Interestingly, the bigram?benets to?
is not highly correlated with opin-ions because it matches infinitive phrases suchas ?tax benets to provide?
and ?health benetsto cut?.
In this case, the extraction pattern ?NPPrep(benefits to)?
is more discriminating than thebigram for opinion classification.
The extractionpattern EEP is also highly correlated with opin-ions, while the unigram ?due?
and the bigram?due to?
are not.The bottom table in Figure 6 shows featurepairs identified for their behavioral differences onthe Polarity data set, where the task is to distin-guish positive reviews from negative reviews.
F2and G2 are bigrams that behave differently fromtheir component unigrams.
The expression ?noth-ing short (of)?
is typically used to express posi-tive sentiments, while ?nothing?
and ?short?
bythemselves are not.
The word ?ugly?
is often usedas a descriptive modifier that is not expressinga sentiment per se, while ?and ugly?
appears inpredicate adjective constructions that are express-ing a negative sentiment.
The extraction patternHEP is more discriminatory than H1 because itdistinguishes negative sentiments (?the lm is adisaster!?)
from plot descriptions (?the disastermovie...?).
IEP shows that active-voice usages of?work?
are strong positive indicators, while theunigram ?work?
appears in a variety of both pos-itive and negative contexts.
Finally, JEP showsthat the expression ?manages to keep?
is a strongpositive indicator, while ?manages?
by itelf ismuch less discriminating.445These examples illustrate that the subsumptionhierarchy can be a powerful tool to better under-stand the behaviors of different kinds of features,and to identify specific features that may be desir-able for inclusion in specialized lexical resources.5 Using the Subsumption Hierarchy toReduce Feature SetsWhen creating opinion classifiers, people oftenthrow in a variety of features and trust the ma-chine learning algorithm to figure out how to makethe best use of them.
However, we hypothesizedthat classifiers may perform better if we can proac-tively eliminate features that are not necesary be-cause they are subsumed by other features.
In thissection, we present a series of experiments to ex-plore this hypothesis.
First, we present the resultsfor an SVM classifier trained using different setsof unigram, bigram, and extraction pattern fea-tures, both before and after subsumption.
Next, weevaluate a standard feature selection approach asan alternative to subsumption and then show thatcombining subsumption with standard feature se-lection produces the best results of all.5.1 Classification ExperimentsTo see whether feature subsumption can improveclassification performance, we trained an SVMclassifier for each of the three opinion data sets.We used the SVMlight (Joachims, 1998) packagewith a linear kernel.
For the Polarity and OP datawe discarded all features that have frequency < 5,and for the MPQA data we discarded features thathave frequency < 2 because this data set is sub-stantially smaller.
All of our experimental resultsare averages over 3-fold cross-validation.First, we created 4 baseline classifiers: a 1Gramclassifier that uses only the unigram features; a1+2Gram classifier that uses unigram and bigramfeatures; a 1+EP classifier that uses unigram andextraction pattern features, and a 1+2+EP classi-fier that uses all three types of features.
Next, wecreated analogous 1+2Gram, 1+EP, and 1+2+EPclassifiers but applied the subsumption hierar-chy first to eliminate unnecessary features be-fore training the classifier.
We experimented withthree delta values for the subsumption process:?=.0005, .001, and .002.Figures 7, 8, and 9 show the results.
The sub-sumption process produced small but consistentimprovements on all 3 data sets.
For example, Fig-ure 8 shows the results on the OP data, where allof the accuracy values produced after subsumption(the rightmost 3 columns) are higher than the ac-curacy values produced without subsumption (theBase[line] column).
For all three data sets, the bestoverall accuracy (shown in boldface) was alwaysachieved after subsumption.Features Base ?=.0005 ?=.001 ?=.0021Gram 79.81+2Gram 81.2 81.0 81.3 81.01+EP 81.7 81.4 81.4 82.01+2+EP 81.7 82.3 82.3 82.7Figure 7: Accuracies on Polarity DataFeatures Base ?=.0005 ?=.001 ?=.0021Gram 97.5 - - -1+2Gram 98.0 98.7 98.6 98.71+EP 97.2 97.8 97.9 97.91+2+EP 97.8 98.6 98.7 98.7Figure 8: Accuracies on OP DataFeatures Base ?=.0005 ?=.001 ?=.0021Gram 74.81+2Gram 74.3 74.9 74.6 74.81+EP 74.4 74.6 74.6 74.61+2+EP 74.4 74.9 74.7 74.6Figure 9: Accuracies on MPQA DataWe also observed that subsumption had a dra-matic effect on the F-measure scores on the OPdata, which are shown in Figure 10.
The OP dataset is fundamentally different from the other datasets because it is so highly skewed, with 91% ofthe documents belonging to the non-opinion class.Without subsumption, the classifier was conser-vative about assigning documents to the opinionclass, achieving F-measure scores in the 82-88range.
After subsumption, the overall accuracyimproved but the F-measure scores increased moredramatically.
These numbers show that the sub-sumption process produced not only a more ac-curate classifier, but a more useful classifier thatidentifies more documents as being opinion arti-cles.For the MPQA data, we get a very small im-provement of 0.1% (74.8% ?
74.9%) using sub-sumption.
But note that without subsumption theperformance actually decreased when bigrams and446Features Base ?=.0005 ?=.001 ?=.0021Gram 84.51+2Gram 88.0 92.5 92.0 92.31+EP 82.4 86.9 87.4 87.41+2+EP 86.7 91.8 92.5 92.3Figure 10: F-measures on OP Data97.697.89898.298.498.698.8991000  2000  3000  4000  5000  6000  7000  8000  9000  10000Accuracy(%)Top NBaselineSubsumption ?=0.002Feature SelectionSubsumption ?=0.002 + Feature SelectionFigure 11: Feature Selection on OP Dataextraction patterns were added!
The subsumptionprocess counteracted the negative effect of addingthe more complex features.5.2 Feature Selection ExperimentsWe conducted a second series of experiments todetermine whether a traditional feature selectionapproach would produce the same, or better, im-provements as subsumption.
For each feature, wecomputed its information gain (IG) and then se-lected the N features with the highest scores.7 Weexperimented with values of N ranging from 1,000to 10,000 in increments of 1,000.We hypothesized that applying subsumption be-fore traditional feature selection might also help toidentify a more diverse set of high-performing fea-tures.
In a parallel set of experiments, we exploredthis hypothesis by first applying subsumption toreduce the size of the feature set, and then select-ing the best N features using information gain.Figures 11, 12, and 13 show the results of theseexperiments for the 1+2+EP classifiers.
Eachgraph shows four lines.
One line corresponds tothe baseline classifier with no subsumption, andanother line corresponds to the baseline classifierwith subsumption using the best ?
value for thatdata set.
Each of these two lines corresponds to7In the case of ties, we included all features with the samescore as the Nth-best as well.7878.57979.58080.58181.58282.58383.51000  2000  3000  4000  5000  6000  7000  8000  9000  10000Accuracy(%)Top NBaselineSubsumption ?=0.002Feature SelectionSubsumption ?=0.002 + Feature SelectionFigure 12: Feature Selection on Polarity Data7272.57373.57474.57575.51000  2000  3000  4000  5000  6000  7000  8000  9000  10000Accuracy(%)Top NBaselineSubsumption ?=0.0005Feature SelectionSubsumption ?=0.0005 + Feature SelectionFigure 13: Feature Selection on MPQA Datajust a single data point (accuracy value), but wedrew that value as a line across the graph for thesake of comparison.
The other two lines on thegraph correspond to (a) feature selection for dif-ferent values of N (shown on the x-axis), and (b)subsumption followed by feature selection for dif-ferent values of N.On all 3 data sets, traditional feature selectionperforms worse than the baseline in some cases,and it virtually never outperforms the best classi-fier trained after subsumption (but without featureselection).
Furthermore, the combination of sub-sumption plus feature selection generally performsbest of all, and nearly always outperforms featureselection alone.
For all 3 data sets, our best ac-curacy results were achieved by performing sub-sumption prior to feature selection.
The best accu-racy results are 99.0% on the OP data, 83.1% onthe Polarity data, and 75.4% on the MPQA data.For the OP data, the improvement over baselinefor both accuracy and F-measure are statisticallysignificant at the p < 0.05 level (paired t-test).
Forthe MPQA data, the improvement over baseline is447statistically significant at the p < 0.10 level.6 Related WorkMany features and classification algorithms havebeen explored in sentiment analysis and opinionrecognition.
Lexical cues of differing complexi-ties have been used, including single words andNgrams (e.g., (Mullen and Collier, 2004; Pang etal., 2002; Turney, 2002; Yu and Hatzivassiloglou,2003; Wiebe et al, 2004)), as well as phrasesand lexico-syntactic patterns (e.g, (Kim and Hovy,2004; Hu and Liu, 2004; Popescu and Etzioni,2005; Riloff and Wiebe, 2003; Whitelaw et al,2005)).
While many of these studies investigatecombinations of features and feature selection,this is the first work that uses the notion of sub-sumption to compare Ngrams and lexico-syntacticpatterns to identify complex features that outper-form simpler counterparts and to reduce a com-bined feature set to improve opinion classification.7 ConclusionsThis paper uses a subsumption hierarchy offeature representations as (1) an analytic toolto compare features of different complexities,and (2) an automatic tool to remove unneces-sary features to improve opinion classificationperformance.
Experiments with three opiniondata sets showed that subsumption can improveclassification accuracy, especially when combinedwith feature selection.AcknowledgmentsThis research was supported by NSF Grants IIS-0208798 and IIS-0208985, the ARDA AQUAINTProgram, and the Institute for Scientific Comput-ing Research and the Center for Applied ScientificComputing within Lawrence Livermore NationalLaboratory.ReferencesS.
Banerjee and T. Pedersen.
2003.
The Design, Imple-mentation, and Use of the Ngram Statistics Package.In Proc.
Fourth Int?l Conference on Intelligent TextProcessing and Computational Linguistics.A.
Esuli and F. Sebastiani.
2005.
Determining the se-mantic orientation of terms through gloss analysis.In Proc.
CIKM-05.G.
Forman.
2003.
An Extensive Empirical Study ofFeature Selection Metrics for Text Classification.
J.Mach.
Learn.
Res., 3:1289?1305.M.
Hu and B. Liu.
2004.
Mining and summarizingcustomer reviews.
In Proc.
KDD-04.T.
Joachims.
1998.
Making Large-Scale SupportVector Machine Learning Practical.
In A. SmolaB.
Scho?lkopf, C. Burges, editor, Advances in Ker-nel Methods: Support Vector Machines.
MIT Press,Cambridge, MA.S-M. Kim and E. Hovy.
2004.
Determining the senti-ment of opinions.
In Proc.
COLING-04.M.
Marcus, B. Santorini, and M. Marcinkiewicz.
1993.Building a Large Annotated Corpus of English:The Penn Treebank.
Computational Linguistics,19(2):313?330.T.
Mullen and N. Collier.
2004.
Sentiment AnalysisUsing Support Vector Machines with Diverse Infor-mation Sources.
In Proc.
EMNLP-04.B.
Pang and L. Lee.
2004.
A sentimental education:Sentiment analysis using subjectivity summarizationbased on minimum cuts.
In Proc.
ACL-04.B.
Pang, L. Lee, and S. Vaithyanathan.
2002.
Thumbsup?
Sentiment Classification using Machine Learn-ing Techniques.
In Proc.
EMNLP-02.A-M. Popescu and O. Etzioni.
2005.
Extracting prod-uct features and opinions from reviews.
In Proc.HLT-EMNLP-05.E.
Riloff and W. Phillips.
2004.
An Introduction to theSundance and AutoSlog Systems.
Technical ReportUUCS-04-015, School of Computing, University ofUtah.E.
Riloff and J. Wiebe.
2003.
Learning Extraction Pat-terns for Subjective Expressions.
In Proc.
EMNLP-03.E.
Riloff.
1996.
An Empirical Study of AutomatedDictionary Construction for Information Extractionin Three Domains.
Artificial Intelligence, 85:101?134.P.
Turney.
2002.
Thumbs up or thumbs down?
Seman-tic orientation applied to unsupervised classificationof reviews.
In Proc.
ACL-02.C.
Whitelaw, N. Garg, and S. Argamon.
2005.
Us-ing appraisal groups for sentiment analysis.
In Proc.CIKM-05.J.
Wiebe, T. Wilson, R. Bruce, M. Bell, and M. Mar-tin.
2004.
Learning subjective language.
Computa-tional Linguistics, 30(3):277?308.J.
Wiebe, T. Wilson, and C. Cardie.
2005.
Annotatingexpressions of opinions and emotions in language.Language Resources and Evaluation, 39(2/3).H.
Yu and V. Hatzivassiloglou.
2003.
Towards an-swering opinion questions: Separating facts fromopinions and identifying the polarity of opinion sen-tences.
In Proc.
EMNLP-03.448
