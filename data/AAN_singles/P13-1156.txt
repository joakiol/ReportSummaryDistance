Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 1587?1596,Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational LinguisticsIntegrating Phrase-based Reordering Features into a Chart-basedDecoder for Machine TranslationThuyLinh NguyenLanguage Technologies InstituteCarnegie Mellon UniversityPittsburgh, PA 15213, USAthuylinh@cs.cmu.eduStephan VogelQatar Computing Research InstituteTornado TowerDoha, Qatarsvogel@qf.org.qaAbstractHiero translation models have two lim-itations compared to phrase-based mod-els: 1) Limited hypothesis space; 2) Nolexicalized reordering model.
We pro-pose an extension of Hiero called Phrasal-Hiero to address Hiero?s second problem.Phrasal-Hiero still has the same hypoth-esis space as the original Hiero but in-corporates a phrase-based distance costfeature and lexicalized reodering featuresinto the chart decoder.
The work consistsof two parts: 1) for each Hiero transla-tion derivation, find its corresponding dis-continuous phrase-based path.
2) Extendthe chart decoder to incorporate featuresfrom the phrase-based path.
We achievesignificant improvement over both Hieroand phrase-based baselines for Arabic-English, Chinese-English and German-English translation.1 IntroductionPhrase-based and tree-based translation model arethe two main streams in state-of-the-art machinetranslation.
The tree-based translation model, byusing a synchronous context-free grammar for-malism, can capture longer reordering betweensource and target language.
Yet, tree-based trans-lation often underperforms phrase-based transla-tion in language pairs with short range reorderingsuch as Arabic-English translation (Zollmann etal., 2008; Birch et al, 2009).We follow Koehn et al (2003) for our phrase-based system and Chiang (2005) for our Hiero sys-tem.
In both systems, the translation of a sourcesentence f is the target sentence e?
that maximizesa linear combination of features and weights:?e?,a??
= argmax?e,a?
?H(f)?m?M?mhm (e, f ,a) .
(1)where?
a is a translation path of f .
In the phrase-based system, aph represents a segmentationof e and f and a correspondance of phrases.In the Hiero system, atr is a derivation of aparallel parse tree of f and e, each nontermi-nal representing a rule in the derivation.?
H (f) is the hypothesis space of the sentencef .
We denote Hph (f) as the phrase-basedhypothesis space of f and Htr (f) as its tree-based hypothesis space.
Galley and Manning(2010) point out that due to the hard con-straints of rule combination, the tree-basedsystem does not have the same excessive hy-pothesis space as the phrase-based system.?
M is the set of feature indexes used in thedecoder.
Many features are shared betweenphrase-based and tree-based systems includ-ing language model, word count, and trans-lation model features.
Phrase-based systemsoften use a lexical reordering model in addi-tion to the distance cost feature.The biggest difference in a Hiero system and aphrase-based system is in how the reordering ismodeled.
In the Hiero system, the reordering de-cision is encoded in weighted translation rules, de-termined by nonterminal mappings.
For example,the rule X ?
ne X1 pas ; not X1 : w indicatesthe translation of the phrase between ne and pas tobe after the English word not with scorew.
Duringdecoding, the system parses the source sentenceand synchronously generates the target output.To achieve reordering, the phrase-based sys-tem translates source phrases out of order.
A re-ordering distance limit is imposed to avoid searchspace explosion.
Most phrase-based systems areequipped with a distance reordering cost featureto tune the system towards the right amount ofreordering, but then also a lexicalized reordering1587model to model the direction of adjacent sourcephrases reordering as either monotone, swap ordiscontinuous.There are two reasons to explain the shortcom-ings of the current Hiero system:1.
A limited hypothesis space because the syn-chronous context-free grammar is not appli-cable to non-projective dependencies.2.
It does not have the expressive lexicalized re-ordering model and distance cost features ofthe phrase-based system.When comparing phrase-based and Hiero trans-lation models, most of previous work on tree-based translation addresses its limited hypothesisspace problem.
Huck et al (2012) add new rulesinto the Hiero system, Carreras and Collins (2009)apply the tree adjoining grammar formalism to al-low highly flexible reordering.
On the other hand,the Hiero model has the advantage of capturinglong distance and structure reordering.
Galleyand Manning (2010) extend phrase-based trans-lation by allowing gaps within phrases such as?ne .
.
.
pas, not?, so the decoder still has the dis-criminative reordering features of phrase-based,but also uses on average longer phrases.
How-ever, these phrase pairs with gaps do not capturestructure reordering as do Hiero rules with non-terminal mappings.
For example, the rule X ?ne X1 pas ; not X1 explicitly places the transla-tion of the phrase between ne and pas behind theEnglish word not through nonterminal X1.
Thisis important for language pairs with strict reorder-ing.
In our Chinese-English experiment, the Hierosystem still outperforms the discontinuous phrase-based system.We address the second problem of the origi-nal Hiero decoder by mapping Hiero translationderivations to corresponding phrase-based paths,which not only have the same output but also pre-serve structure distortion of the Hiero translation.We then include phrase-based features into the Hi-ero decoder.A phrase-based translation path is the sequenceof phrase-pairs, whose source sides cover thesource sentence and whose target sides generatethe target sentence from left to right.
If we look atthe leaves of a Hiero derivation tree, the lexicalsalso form a segmentation of the source and targetsentence, thus also form a discontinuous phrase-based translation path.
As an example, let us lookat the translation of the French sentence je ne parlepas le franc?aise into English i don?t speak frenchin Figure 1.
The Hiero decoder translates the sen-tence using a derivation of three rules:?
r1 = X?
parle ; speak.?
r2 = X?
ne X1 pas ; don?t X1.?
r3 = X?Je X1 le Franc?ais ; I X1 french.From this Hiero derivation, we have a seg-mentation of the sentence pairs into phrasepairs according to the word alignments, asshown on the left side of Figure 1.
Or-dering these phrase pairs according the wordsequence on the target side, shown on theright side of Figure 1, we have a phrase-based translation path consisting of four phrasepairs: (je, i) , (ne .
.
.
pas, not) , (parle, speak) ,(lefrancaise, french) that has the same outputas the Hiero system.
Note that even though theHiero decoder uses a composition of three rules,the corresponding phrase-based path consists offour phrase pairs.
We name this new variant of theHiero decoder, which uses phrase-based features,Phrasal-Hiero.Our Phrasal-Hiero addresses the shortcommingof the original Hiero system by incorporatingphrase-based features.
Let us revisit machinetranslation?s loglinear model combination of fea-tures in equation 1.
We denote ph(a) as the corre-sponding phrase-based path of a Hiero derivationa, and MPh\H as the indexes of phrase-based fea-tures currently not applicable to the Hiero decoder.Our Phrasal-Hiero decoder seeks to find the trans-lation, which optimizes:?e?,a??
= argmax?e,a?
?Htr(f)( ?m?MH?mhm (e, f ,a) ++?m??MPh\H?m?hm?
(e, f , ph(a))).We focus on improving the modelling of re-ordering within Hiero and include discriminativereordering features (Tillmann, 2004) and a dis-tance cost feature, both of which are not modeledin the original Hiero system.
Chiang et al (2008)added structure distortion features into their de-coder and showed improvements in their Chinese-English experiment.
To our knowledge, Phrasal-Hiero is the first system, which directly integratesphrase-based and Hiero features into one model.1588Figure 1: Example of French-English Hiero Translation on the left and its corresponding discontinuousphrase-based translation on the right.Rules Alignments Phrase pairs & nonterminalsr1 = X?
parle ; speak.
0-0 (parle ; speak)r2 = X?
ne X1 pas ; don?t X1.
0-0 1-1 2-0 (ne .
.
.
pas ; don?t) ; X1r3 = X?
Je X1 le Francais ; I X1 French 0-0 1-1 3-2 (Je ; I) ; X1 ; (le Francais; french)r4 = X?
je X1 le X2 ; i X1 X2 0-0 1-1 3-2 Not ApplicableTable 1: Rules and their sequences of phrase pairs and nonterminalsPrevious work has attempted to weaken the con-text free assumption of the synchronous contextfree grammar formalism, for example using syn-tactic non-terminals (Zollmann and Venugopal,2006).
Our approach can be viewed as applyingsoft context constraint to make the probability ofsubstituting a nonterminal by a subtree dependingon the corresponding phrase-based reordering fea-tures.In the next section, we explain the model in de-tail.2 Phrasal-Hiero ModelPhrasal-Hiero maps a Hiero derivation into a dis-continuous phrase-based translation path by thefollowing two steps:1.
Training: Represent each rule as a sequenceof phrase pairs and nonterminals.2.
Decoding: Use the rules?
sequences ofphrase pairs and nonterminals to find thecorresponding phrase-based path of a Hieroderivation and calculate its feature scores.2.1 Map Rule to A Sequence of Phrase Pairsand NonterminalsWe segment the rules?
lexical items into phrasepairs.
These phrase pairs will be part of the phrase-based translation path in the decoding step.
Therules?
nonterminals are also preserved in the se-quence, during the decoding they will be substi-tuted by other rules?
phrase pairs.
We now explainhow to map a rule to a sequence of phrase pairsand nonterminals.Let r = X ?s0X1s1 .
.
.
Xksk ; t0X?
(1)t1 .
.
.
X?
(k)tk be a ruleof k nonterminals, ?(.)
defines the sequence ofnonterminals on the target.
si or ti , i = 0 .
.
.
kare phrases between nonterminals, they can beempty because nonterminals can be at the borderof the rule or two nonterminals are adjacent.
Forexample the rule X ?
ne X1 pas ; not X1has k = 1, s0 = ne, s1 = pas, t0 = not, t1 isan empty phrase because the target X1 is at therightmost position.Phrasal-Hiero retains both nonterminals andlexical alignments of Hiero rules instead of onlynonterminal mappings as in (Chiang, 2005).
A1589rule?s lexical alignment is the most frequent onein the training data.
We use the lexical alignmentsof a rule to decide how source phrases and tar-get phrases are connected.
In the rule r, a sourcephrase si is connected to a target phrase ti?
if atleast one word in si aligns to a target word in ti?
.
Inthe rule X?
Je X1 le Franc?ais ; I X1 frenchextract from sentence pair in Figure 1, the phrasele Franc?ais connects to the phrase french becausethe French word Franc?ais aligns with the Englishword french even though le is unaligned.We then group the source phrases and targetphrases into phrase pairs such that only phrasesthat are connected to each other are in the samephrase pair.
So phrase pairs still preserve the lexi-cal dependency of the rule.
Phrase pairs and non-terminals are then ordered according to the targetside of the rule.
Table 1 shows an example of rules,alignments and their sequences of phrase pairs andnonterminals on the last column.Figure 2: Alignment of a sentence pair.There are Hiero rules in which one of its sourcephrases or target phrases is not aligned.
For exam-ple in the rule r4 = X ?
je X1 le X2 ; i X1 X2extracted from the sentence pair in Figure 2, thephrase le is not aligned.
In our Arabic-Englishexperiment, rules without nonaligned phrases ac-count for only 48.54% of the total rules.
We com-pared the baseline Hiero translation from the fullset of rules and the translation from only ruleswithout nonaligned phrases.
The later translationis faster and Table 2 1 shows that it outperformsthe translation with the whole set of rules.
Wetherefore decided to not use rules with nonalignedphrases in Phrasal-Hiero.It is important to note that there are differentways to use all the rules and map rules with un-aligned phrases into a sequence of phrase pairs.1The dataset and experiment setting description are in sec-tion 4.Test set MT04 MT05 MT09All rules 48.17 47.85 42.37Phrasal Hiero 48.52 47.78 42.8Table 2: Arabic-English pilot experiment.
Com-pare BLEU scores of translation using all ex-tracted rules (the first row) and translation usingonly rules without nonaligned subphrases (the sec-ond row).For example, adding these unaligned phrases tothe previous phrase pair i.e.
the rule r4 has one dis-continuous phrase pair (je .
.
.
le, i) or treat theseunaligned phrases as deletion/insertion phrases.We started the work with Arabic-English transla-tion and decided not to use rules with nonalignedphrases in Phrasal-Hiero.
In the experiment sec-tion, we will discuss the impact of removingrules with nonaligned sub-phrases in our German-English and Chinese-English experiments.2.2 Training: Lexicalized Reordering TablePhrasal-Hiero needs a phrase-based lexicalized re-ordering table to calculate the features.
The lexi-calized reordering table could be from a discontin-uous phrase-based system.
To guarantee the lexi-calized reordering table to cover all phrase pairsof the rule table, we extract phrase-pairs and theirreordering directions during rule extraction.Let (s, t) be a sentence pair in the training dataand r = X?
s0X1s1 .
.
.
Xksk ; t0X1t1 .
.
.
Xktkbe a rule extracted from the sentence.
The lex-ical phrase pair corresponding to the rule r isph = (s0 .
.
.
s1 .
.
.
sk, t0 .
.
.
t1 .
.
.
tk), with non-terminals are replaced by the gaps.
Because thenonterminal could be at the border of the rule, thelexical phrase pair might have smaller coveragethan the rule.
For example, the training sentencepair in Figure 2 generates the rule r2 = X ?ne X1 pas ; don?t X1 spanning (1 .
.
.
3, 1 .
.
.
2)but its lexical phrase pair (ne .
.
.
pas, not) onlyspans (1 .
.
.
3, 1 .
.
.
1).Also, two different rules can have the samelexical phrase pairs.
In Phrasal-Hiero, each lex-ical phrase pair is only generated once for asentence.
Look at the example of the train-ing sentence pair in Figure 2, the rule X ?je ; I spanning (0 .
.
.
1, 0 .
.
.
1) and the rule X ?je X1 ; I X1 spanning (0 .
.
.
3, 0 .
.
.
2) are bothsharing the same lexical phrase pair (je, i) span-ning (0 .
.
.
1, 0 .
.
.
1).
But Phrasal-Hiero only gen-1590erates (je, i) once for the sentence.
Phrase pairsare generated together with phrase-based reorder-ing orientations to build lexicalized reordering ta-ble.3 DecodingChiang (2007) applied bottom up chart parsing toparse the source sentence and project on the tar-get side for the best translation.
Each chart cell[X, i, j, r] indicates a subtree with rule r at the rootcovers the translation of the i-th word upto the j-thword of the source sentence.
We extend the chartparsing, mapping the subtree to the equivalent dis-continuous phrase-based path and includes phrase-based features to the log-linear model.In Phrasal-Hiero, each chart cell [X, i, j, r] alsostores the first phrase pair and the last phrase pairof the phrase-based translation path covered the i-th to the j-th word of the source sentence.
Thesetwo phrase pairs are the back pointers to calcu-late reordering features of later larger spans.
Be-cause the distance cost feature and phrase-baseddiscriminative reordering feature calculation areboth only required the source coverage of two ad-jacent phrase pairs, we explain here the distancecost calculation.We will again use three rules r1, r2, r3 in Ta-ble 1 and the translation je ne parle pas le franc?aisinto I don?t speak French to present the technique.Table 3 shows the distance cost calculation.First, when the rule r has only terminals, therule?s sequence of phrase pairs and nonterminalsconsists of only a phrase pair.
No calculation isneeded, the first phrase pair and the last phrasepair are the same.
The chart cell X1 : 2 .
.
.
2 inTable 3 shows the translation with the rule r1 =X ?
parle ; speak.
The first phrase pair and thelast phrase pair point to the phrase (parle, speak)spanning 2 .
.
.
2 of the source sentence.When the translation rule?s right hand side hasnonterminals, the nonterminals in the sequencebelong to smaller chart cells that we already foundphrase-based paths and calculated their featuresbefore.
The decoder then substitute these pathsinto the rule?s sequence of phrase pairs and non-terminals to form the complete path for the currentspan.We now demonstrate finding the phrase basedpath and calculate distance cost of the chartcell X2 spanning 1 .
.
.
3.
The next phrase pairof (ne .
.
.
pas, don?t) is the first phrase pairof the chart cell X1 which is (parle, speak).The distance cost of these two phrase pairs ac-cording to discontinuous phrase-based model is|2?
3?
1| = 2.
The distance cost of thewhole chart cell X2 also includes the cost of thetranslation path covered by chart cell X1 whichis 0, therefore the distance cost for X2 is 2 +dist(X1) = 2.
We then update the first phrasepair and the last phrase pair of cell X2.
The firstphrase pair of X2 is (ne .
.
.
pas, don?t), the lastphrase pair is also the last phrase pair of cell X1which is (parle, speak).Similarly, finding the phrase-based path andcalculate its distortion features in the chart cellX3 include calculate the feature values for mov-ing from the phrase pair (je, I) to the firstphrase pair of chart cell X2 and also from lastphrase pair of chart cell X2 to the phrase pair(le franc?aise, french).4 Experiment ResultsIn all experiments we use phrase-orientation lex-icalized reordering (Galley and Manning, 2008)2which models monotone, swap, discontinuousorientations from both reordering with previousphrase pair and with the next phrase pair.
Thereare total six features in lexicalized reorderingmodel.We will report the impact of integrating phrase-based features into Hiero systems for three lan-guage pairs: Arabic-English, Chinese-English andGerman-English.4.1 System SetupWe are using the following three baselines:?
Phrase-based without lexicalized reoderingfeatures.
(PB+nolex)?
Phrase-based with lexicalized reordering fea-tures.(PB+lex)?
Hiero system with all rules extracted fromtraining data.
(Hiero)We use Moses phrase-based and chart decoder(Koehn et al, 2007) for the baselines.
The scoredifference between PB+nolex and PB+lex resultsindicates the impact of lexicalized reordering fea-tures on phrase-based system.
In Phrasal-Hiero we2Galley and Manning (2008) introduce three orientationmodels for lexicalized reordering: word-based, phrase-basedand hierarchical orientation model.
We apply phrase-basedorientation in all experiment using lexicalized reordering.1591Chart Cell Rule?s phrase pairs & NTs Distance First Phrase Pair Last Phrase PairX1 : 2 .
.
.
2 (parle, speak) ?
2 .
.
.
2 (parle, speak)X2 : 1 .
.
.
3 (ne .
.
.
pas, don?t) ; X1 2 + dist (X1) 1 .
.
.
3 2 .
.
.
2 (parle, speak)= 2 (ne .
.
.
pas, don?t)X3 : 0 .
.
.
5 (Je ; I) ; X2 ; 0 + dist (X2) 0 .
.
.
0 (je, I) 4 .
.
.
5(le Franc?ais; french) +1 = 3 (le Franc?ais; french)Table 3: Phrasal-Hiero Decoding Example: Calculate distance cost feature for the translation in Figure 1.will compare if these improvements still carry oninto Hiero systems.The original Hiero system with all rules ex-tracted from training data (Hiero) is the most rele-vant baseline.
We will evaluate the difference be-tween this Hiero baseline and our Phrasal-Hiero.To implement Phrasal-Hiero, we extentedMoses chart decoder (Koehn et al, 2007) to in-clude distance-based reordering as well as the lex-icalized phrase orientation reordering model.
Wewill report the following results for Phrasal-Hiero:?
Hiero translation results on the subset of ruleswithout unaligned phrases.
(we denote this inthe table scores as P.H.)?
Phrasal-Hiero with phrase-based distancecost feature (P.H.+dist).?
Phrasal-Hiero with phrase-based lexicalizedreordering features(P.H.+lex).?
Phrasal-Hiero with distance cost and lexical-ized reordering features(P.H.+dist+lex).4.2 Arabic-English ResultsThe Arabic-English system was trained from264K sentence pairs with true case English.
TheArabic is in ATB morphology format.
The lan-guage model is the interpolation of 5-gram lan-guage models built from news corpora of the NIST2012 evaluation.
We tuned the parameters onthe MT06 NIST test set (1664 sentences) and re-port the BLEU scores on three unseen test sets:MT04 (1353 sentences), MT05 (1056 sentences)and MT09 (1313 sentences).
All test sets have fourreferences per each sentence.The results are in Table 4.
The threerows in the first block are the baseline scores.Phrase-based with lexicalized reordering fea-tures(PB+lex) shows significant improvement onall test sets over the simple phrase-based systemwithout lexicalized reordering (PB+nolex).
On av-erage the improvement is 1.07 BLEU score (45.66MT04 MT05 MT09 Avg.PB+nolex 47.40 46.83 42.75 45.66PB+lex 48.62 48.07 43.51 46.73Hiero 48.17 47.85 42.37 46.13P.H.
48.52 47.78 42.80 46.37(48.54% rules)P.H.+dist 48.46 47.92 42.62 46.33P.H.
+lex 48.70 48.59 43.84 47.04P.H +lex+dist 49.35 49.07 43.40 47.27Improv.
over 0.73 1.00 0.34 0.54PB+lexImprov.
over 0.83 1.29 1.04 0.90P.H.Improv.
over 1.18 1.22 1.47 1.14HieroTable 4: Arabic-English true case translationscores in BLEU metric.
The three rows in the firstblock are the baseline scores.
The next four rowsin the second block are Phrasal-Hiero scores, thebest scores are in boldface.
The three rows in thelast block are the Phrasal-Hiero improvements.versus 46.73).
We make the same observation asZollmann et al (2008), i.e, that the Hiero baselinesystem underperforms compared to the phrase-based system with lexicalized phrase-based re-ordering for Arabic-English in all test sets, on av-erage by about 0.60 BLEU points (46.13 versus46.73).
This is because Arabic language has rel-ative free reordering, but mostly short distance,which is better captured by discriminative reorder-ing features.The next four rows in the second block of Ta-ble 4 show Phrasal-Hiero results.
The P.H.
line isthe result of Hiero experiment on only a subset ofrules without nonaligned phrases.
As mentionedin section 2.1, Phrasal-Hiero only uses 48.54% ofthe rules but achieves as good or even better per-formance (on average 0.24 BLEU points better)compared to the original Hiero system using thefull set of rules.We do not benefit from adding only the1592distance-based reordering feature (P.H+dist) to theArabic-English experiment but get significant im-provements when adding the six features of thelexicalized reordering (P.H+lex).
Table 4 showsthat the P.H.+lex system gains on average 0.67BLEU points (47.04 versus 46.37).
Even thoughthe baseline Hiero underperforms phrase-basedsystem with lexicalized reordering(P.B+lex), theP.H.+lex system already outperforms P.B+lex inall test sets (on average 47.04 versus 46.73).Adding both distance cost and lexicalized re-ordering features (P.H.+dist+lex) performs thebest.
On average P.H.+dist+lex improves 0.90BLEU points over P.H.
without new phrase-basedfeatures and 1.14 BLEU score over the base-line Hiero system.
Note that Hiero rules alreadyhave lexical context in the reordering, but addingphrase-based lexicalized reordering features to thesystem still gives us about as much improvementas the phrase-based system gets from lexicalizedreordering features, here 1.07 BLEU points.
Andour best Phrasal-Hiero significantly improves overthe best phrase-based baseline by 0.54 BLEUpoints.
This shows that the underperformance ofthe Hiero system is due to its lack of lexicalizedreordering features rather than a limited hypothe-sis space.4.3 Chinese-English ResultsThe Chinese-English system was trained on FBIScorpora of 384K sentence pairs, the English cor-pus is lower case.
The language model is the tri-gram SRI language model built from Xinhua cor-pus of 180 millions words.
We tuned the parame-ters on MT06 NIST test set of 1664 sentences andreport the results of MT04, MT05 and MT08 un-seen test sets.
The results are in Table 5.We also make the same observation as Zoll-mann et al (2008) on the baselines for Chinese-English translation.
Even though the phrase-based system benefits from lexicalized reordering,PB+lex on average outperforms PB+nolex by 1.16BLEU points (25.87 versus 27.03), it is the Hierosystem that has the best baseline scores across alltest sets, with and average of 27.70 BLEU points.Phrasal Hiero scores are given in the secondblock of Table 5.
It uses 84.19% of the total train-ing rules, but unlike the Arabic-English system,using a subset of the rules costs Phrasal-Hiero onall test sets and on average it loses 0.49 BLEUpoints (27.21 versus 27.70).
Similar to ChiangMT04 MT05 MT08 Avg.PB+nolex 29.99 26.4 21.23 25.87PB+lex 31.03 27.57 22.41 27.03Hiero 32.49 28.06 22.57 27.70P.H.
31.83 27.66 22.16 27.21(84.19% rules)P.H.+dist 32.18 28.25 22.46 27.63P.H.+lex 32.55 28.51 23.08 28.05P.H+lex+dist 33.06 28.78 23.23 28.35Improv.
over 2.03 1.21 0.82 1.32PB+lexImprov.
over 1.23 1.12 1.07 1.14P.H.Improv.
over 0.57 0.72 0.66 0.65HieroTable 5: Chinese-English lower case translationscores in BLEU metric.et al (2008) in their Chinese-English experiment,we benefit by adding the distance cost feature.PH.+dist outperforms P.H.
on all test sets.
Wehave better improvements when adding the six fea-tures of the lexicalized reordering model: P.H.+lexon average has 28.05 BLEU points, i.e.
gains0.84 over P.H..
The P.H.+lex system is even betterthan the best Hiero baseline using the whole set ofrules.We again get the best translation when addingboth the distance cost feature and the lexicalizedreordering features.
The P.H+dist+lex has the bestscore across all the test sets and on average gains1.14 BLEU points over P.H.
So adding phrase-based features to the Hiero system yields nearlythe same improvement as adding lexicalized re-ordering features to the phrase-based system.
Thisshows that a strong Chinese-English Hiero systemstill benefits from phrase-based features.
Furthermore, the P.H+dist+lex also outperforms the Hi-ero baseline using all rules from training data.4.4 German-English ResultsWe next consider German-English translation.The systems were trained on 1.8 million sentencepairs using the Europarl corpora.
The languagemodel is three-gram SRILM trained from the tar-get side of the training corpora.
We use WMT2010 (2489 sentences) as development set andreport scores on WMT 2008 (2051 sentences),WMT 2009 (2525 sentences), WMT 2011 (3003sentences).
All test sets have one reference pertest sentence.
The results are in Table 6.1593WMT test 08 09 11 Avg.PB+nolex 17.46 17.38 16.76 17.20PB+lex 18.16 17.85 17.18 17.73Hiero 18.20 18.23 17.46 17.96P.H.
18.24 18.15 17.39 17.92(80.54% rules)P.H.
+dist 18.19 17.97 17.41 17.85P.H.
+lex 18.59 18.46 17.69 18.24P.H.+lex+dist 18.70 18.53 17.81 18.34Improv.
over 0.54 0.68 0.63 0.61PB+lexImprov.
over 0.46 0.38 0.42 0.42P.H.Improv.
over 0.50 0.30 0.35 0.38HieroTable 6: German-English lower case translationscores in BLEU metric.The Hiero baseline performs on average 0.26BLEU points better than the phrase-based sys-tem with lexicalized reordering features (PB+lex).The hrasal-Hiero system used 80.54% of the totaltraining rules, but on average the P.H.
system hasthe same performance as the Hiero system usingall the rules extracted from training data.
Similarto the Arabic-English experiment, Phrasal-Hierodoes not benefit from adding the distance cost fea-ture.
We do, however, see improvements on alltest sets when adding lexicalized reordering fea-tures.
On average the P.H.+lex results are 0.32BLEU points higher than the P.H.
results.
Thebest scores are achieved with P.H+lex+dist.
TheGerman-English translations on average gain 0.38BLEU score by adding both distance cost and dis-criminative reordering features.4.5 Impact of segment rules into phrase pairsPhrasal Hiero is the first system using rules?
lexi-cal alignments.
If lexical alignments are not avail-able, we can not divide the rules?
lexicals intophrase pairs without losing their dependancies.
Analternative approach would be combining all lex-icals of a rule into one phrase pair.
We run anaddition experiment for this approach on Arabic-English dataset.
Table 7 shows the examples rulesand its new sequence of nonterminals and phrasepairs.
The rules r1 and r2 have the same se-quences as in Table 1.
Without segment rules intophrase pairs, the rule r3 has only one phrase pair:ph = (Je .
.
.
le Francaise ; I .
.
.
french) andph is repeated twice in r3?s sequence of phrasepairs and nonterminals.
The new experiment usesthe complete set of rules so the rule r4 is included.According to the new sequence of phrase pairsand nonterminals, during decoding the rule r3 hasdiscontinous translation directions on both fromphrase pair ph to the nonterminal X1 and fromX1 to ph.
But using lexical alignment and dividethe rule into phrase pairs as in section 2.1 , thesequence preserves the translation order of r3 astwo monotone translations from (je; I) to X1 andfrom X1 to (le Francaise ; french).AvgHiero 46.13Hiero+lex 46.45 ( +0.32)(no lex.
alignments)P.H 46.37P.H.+lex 47.04 (+0.67)(with lex.
alignments)Table 8: Average of Arabic-English translationscores in BLEU metric.
Compare the improve-ment of using rules?
lexical alignments (2ndblock) and not using rules?
lexical alignments (1stblock).Table 8 compares the two experiments results.The additional experiment is denoted as Hiero+lexin the table.
The first block shows an improvementof 0.32 BLEU score when adding discriminatedreordering features on Hiero (using the whole setof rules and no rule segmentation).
The secondblock is the impact of adding discriminated re-ordering features on Phrasal Hiero (using a sub-set of rules and segment rules into phrase pairs).Here the improvement of P.H+lex over P.H is 0.67BLEU score.
It shows the benefit of segment rulesinto phrase pairs.4.6 Rules without unaligned phrasesA-E C-E G-EHiero 46.13 27.70 17.96P.H.
46.36 27.21 17.92%Rules used 48.54% 84.19% 80.54%P.H.+lex+dist 47.27 28.35 18.34Table 9: The impact of using only rules withoutnonaligned phrases on Phrasal-Hiero results.Table 9 summarizes the impact of using onlyrules without nonaligned phrases on Phrasal-1594Rules Phrase pairs & nonterminalsr1 = X?
parle ; speak.
(parle ; speak)r2 = X?
ne X1 pas ; don?t X1.
(ne .
.
.
pas ; don?t) ; X1r3 = X?
Je X1 le Francais ; I X1 French (Je .
.
.
le Francais ; I .
.
.
french) ; X1 ;(Je .
.
.
le Francais ; I .
.
.
french)r4 = X?
je X1 le X2 ; i X1 X2 (je .
.
.
le ; i) ; X1 ; X2Table 7: Example of translation rules and their sequences of phrase pairs and nonterminals when lexicalalignments are not available.Hiero.
Using only rules without nonalignedphrases can get the same performance with trans-lation with full set of rules for Arabic-English andGerman-English experiments but underperformsfor the Chinese-English system.
We suggest thedifference might come from the linguistic diver-gences of source and target languages.Phrasal Hiero includes all lexical rules (ruleswithout nonterminal) therefore it still has the samelexical coverage as the original Hiero system.In the Arabic-English system, the Arabic is inATB format, therefore most English words shouldhave alignments in the ATB source, rules withnonaligned phrases could be the results of badalignments or non-informative rules, therefore wecould have better performance by using a subset ofrules in Phrasal-Hiero.As Chinese and English are highly divergent,we expect many phrases in one language correctlyunaligned in the other language.
So leaving outthe rules with nonaligned phrases could degradethe system.
Even though the current Phrasal-Hierowith extra phrase-based features outperforms theHiero baseline, future work for Phrasal-Hiero willfocus on including all rules extracted from trainingcorpora.4.7 Discontinuous Phrase-BasedC-E G-EPB+lex 27.03 17.73PB+lex+gap 27.11 17.55Hiero 27.70 17.96P.H.+lex+dist 28.35 18.34Table 10: Comparing Phrasal-Hiero with transla-tion with gap for Chinese-English and German-English.
The numbers are average BLEU scoresof all test sets.We compare Phrasal-Hiero with a discontinu-ous phrase-based system introduced by Galley andManning (2010) for Chinese-English and German-English system.
Table 10 shows the average re-sults.
We used Phrasal decoder (Cer et al, 2010)for phrase-based with gaps (PB+lex+gap) results.While we do not focus on the differences in thetoolkits, our Phrasal-Hiero still outperforms thephrase-based with gaps experiments.ConclusionWe have presented a technique to combine phrase-based features and tree-based features into onemodel.
Adding a distance cost feature, we onlyget better translation for Chinese-English transla-tion.
Phrasal-Hiero benefits from adding discrim-inative reodering features in all experiment.
Weachieved the best result when adding both distancecost and lexicalized reordering features.
Phrasal-Hiero currently uses only a subset of rules fromtraining data.
A future work on the model can in-clude complete rule sets together with word inser-tion/deletion features for nonaligned phrases.ReferencesA.
Birch, P. Blunsom, and M. Osborne.
2009.
AQuantitative Analysis of Reordering Phenomena.
InStatMT ?09: Proceedings of the Fourth Workshop onStatistical Machine Translation, pages 197?205.X.
Carreras and M. Collins.
2009.
Non-ProjectiveParsing for Statistical Machine Translation.
In Pro-ceedings of the 2009 Conference on Empirical Meth-ods in Natural Language Processing: Volume 1 -Volume 1, EMNLP ?09, pages 200?209.D.
Cer, M. Galley, D. Jurafsky, and C. Manning.
2010.Phrasal: A Statistical Machine Translation Toolkitfor Exploring New Model Features.
In Proceedingsof the NAACL HLT 2010 Demonstration Session,pages 9?12.
Association for Computational Linguis-tics, June.D.
Chiang, Y. Marton, and P. Resnik.
2008.
OnlineLarge-Margin Training of Syntactic and StructuralTranslation Features.
In Proceedings of the Con-ference on Empirical Methods in Natural Language1595Processing, pages 224?233.
Association for Com-putational Linguistics.D.
Chiang.
2005.
A Hierarchical Phrase-Based Modelfor Statistical Machine Translation.
In Proc.
of ACL.D.
Chiang.
2007.
Hierarchical phrase-based transla-tion.
Computational Linguistics, 33(2):201?228.M.
Galley and C. Manning.
2008.
A Simple and Effec-tive Hierarchical Phrase Reordering Model.
In Pro-ceedings of the 2008 Conference on Empirical Meth-ods in Natural Language Processing, pages 847?855, Honolulu, Hawaii, October.M.
Galley and C. D. Manning.
2010.
Accurate Non-Hierarchical Phrase-Based Translation.
In Proceed-ings of NAACL-HLT, pages 966?974.M.
Huck, S. Peitz, M. Freitag, and H. Ney.
2012.
Dis-criminative Reordering Extensions for HierarchicalPhrase-Based Machine Translation.
In EAMT, pages313?320.P.
Koehn, F. J. Och, and D. Marcu.
2003.
StatisticalPhrase-Based Translation.
In Proc.
of HLT-NAACL,pages 127?133.P.
Koehn, H. Hoang, A. Birch, C. Callison-Burch,M.
Federico, N. Bertoldi, B. Cowan, W. Shen,C.
Moran, R. Zens, C. Dyer, O. Bojar, A. Constantin,and E. Herbst.
2007.
Moses: Open source toolkitfor statistical machine translation.
In ACL demon-stration session.C.
Tillmann.
2004.
A Unigram Orientation Model forStatistical Machine Translation.
In Proceedings ofHLT-NAACL: Short Papers, pages 101?104.A.
Zollmann and A. Venugopal.
2006.
Syntax Aug-mented Machine Translation via Chart Parsing.
InProc.
of NAACL 2006 - Workshop on Statistical Ma-chine Translation.A.
Zollmann, A. Venugopal, F. Och, and J. Ponte.2008.
A Systematic Comparison of Phrase-Based,Hierarchical and Syntax-Augmented Statistical MT.In Proceedings of the Conference on ComputationalLinguistics (COLING).1596
