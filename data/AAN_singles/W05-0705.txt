Proceedings of the ACL Workshop on Computational Approaches to Semitic Languages, pages 31?38,Ann Arbor, June 2005. c?2005 Association for Computational Linguistics1Modifying a Natural Language Processing System forEuropean Languages to Treat Arabic in Information Processingand Information Retrieval ApplicationsGregory Grefenstette, Nasredine Semmar, Fa?za Elkateb-GaraMultilingual Multimedia Knowledge Engineering Laboratory (LIC2M)Commissariat ?
l?Energie Atomique, Laboratoire d?Int?gration des Syst?mes et des Technologies(CEA LIST)B.P.
6, 92265 Fontenay-aux-Roses Cedex, France{gregory.grefenstette,nasredine.semmar,faiza.gara}@cea.frAbstractThe goal of many natural language proc-essing platforms is to be able to somedaycorrectly treat all languages.
Each newlanguage, especially one from a new lan-guage family, provokes some modifica-tion and design changes.
Here we presentthe changes that we had to introduce intoour platform designed for European lan-guages in order to handle a Semitic lan-guage.
Treatment of Arabic wassuccessfully integrated into our cross lan-guage information retrieval system, whichis visible online.1 IntroductionWhen a natural language processing (NLP) systemis created in a modular fashion, it can be relativelyeasy to extend treatment to new languages (May-nard, et al 2003) depending on the depth andcompleteness desired.
We present here lessonslearned from the extension of our NLP system thatwas originally implemented for Romance andGermanic European1 languages to a member of theSemitic language family, Arabic.
Though our sys-tem was designed modularly, this new languageposed new problems.
We present our answers to1European languages from non indo-European families(Basque, Finnish and Hungarian) pose some of the same prob-lems that Arabic does.these problems encountered in the creation of anArabic processing system, and illustrate its integra-tion into an online cross language information re-trieval (CLIR) system dealing with documentswritten in Arabic, English French and Spanish.2 The LIMA natural language processorOur NLP system (Besan?on et al, 2003), calledLIMA2, was built using a traditional architectureinvolving separate modules for1.
Morphological analysis:a. Tokenization (separating the inputstream into a graph of words).b.
Simple word lookup (search forwords in a full form lexicon).c.
Orthographical alternative lookup(looking for differently accentedforms, alternative hyphenisation,concatenated words, abbreviationrecognition), which might alter theoriginal non-cyclic word graph byadding alternative paths.d.
Idiomatic expressions recognizer(detecting and considering them assingle words in the word graph).e.
Unknown word analysis.2.
Part-of-Speech and Syntactic analysis:a.
After the morphological analysis,which has augmented the originalgraph with as many nodes as there2LIMA stands for the LIC2M Multilingual Analyzer.312are interpretations for the tokens,part-of-speech analysis using lan-guage models from a hand-taggedcorpus reduces the number of pos-sible readings of the input.b.
Named entity recognizer.c.
Recognition of nominal and verbalchains in the graph.d.
Dependency relation extraction.3.
Information retrieval application:a. Subgraph indexing.b.
Query reformulation (monolingualreformulation for paraphrases andsynonymy; multilingual for crosslanguage information retrieval).c.
Retrieval scoring comparing par-tial matches on subgraphs and en-tities.Our LIMA NLP system (Besan?on et al, 2003)was first implemented for English, French, Germanand Spanish, with all data coded in UTF8.
Whenwe extended the system to Arabic, we found that anumber of modifications had to be introduced.
Wedetail these modifications in the next sections.3 Changes specific to Semitic languagesTwo new problems posed by Arabic (and commonto most Semitic languages) that forced us to alterour NLP system are the problem of incompletevowelization of printed texts3 and the problem ofagglutinative clitics.
We discuss how these newproblems influenced our lexical resources and lan-guage processing steps.Lexical ResourcesThe first task for introducing a new language is tocreate the lexical resources for this language.
SinceArabic presents agglutination of articles, preposi-tions and conjunctions at the beginning of words aswell as pronouns at the end of words, and thesephenomena were not treated in our existing Euro-3Since the headwords of our monolingual and cross-lingualreference dictionaries for Arabic possess voweled entries, wehope to attain greater precision by treating this problem.
Analternative but noisy approach (Larkey et al 2002) is to reduceto unvoweled text throughout the NLP application.pean languages4, we had to decide how this featurewould be handled in the lexicon.
Solutions to thisproblem have been proposed, ranging from genera-tion and storage of all agglutinated words forms(Debili and Zouari, 1985) to the compilation ofvalid sequences of proclitics, words and encliticsinto finite-state machines (Beesley, 1996).
Oursystem had already addressed the problem of com-pounds for German in the following way: if an in-put word is not present in the dictionary, acompound-searching module returns all completesequences of dictionary words (a list of possiblecompound joining "fogemorphemes" is passed tothis module) as valid decompositions of the inputword.
Though theoretically this method could beused to treat Arabic clitics, we decided against us-ing this existing process for two reasons:1.
Contrary to German, in which any nounmay theoretically be the first element ofa compound, Arabic clitics belong to asmall closed set of articles, conjunc-tions, prepositions and pronouns.
Al-lowing any word to appear at thebeginning or end of an agglutinatedword would generate unnecessary noise.2.
Storing all words with all possible cli-tics would multiply the size of lexiconproportionally to the number of legalpossible combinations.
We decided thatthis would take up too much space,though others have adopted this ap-proach as mentioned above.We decided to create three lexicons: two additional(small) lists of proclitic and enclitic combinations,and one large lexicon of full form5 voweled words(with no clitics), the creation of the large lexiconfrom a set of lemmas using classic conjugationrules did not require any modification of the exist-ing dictionary building and compilation compo-nent.
Since our NLP system already possessed amechanism for mapping unaccented words to ac-cented entries, and we decided to use this existing4Spanish, of course, possesses enclitic pronouns for someverb forms but these were not adequately treated until thesolution for Arabic was implemented in our system.5Our dictionary making process generates all full form ver-sions of non compound and unagglutinated words.
These are ethen compiled into a finite-state automaton.
Every node corre-sponding to a full word is flagged, and an index correspondingto the automaton path points to the lexical data for that word.323mechanism for later matching of voweled and un-voweled versions of Arabic words in applications.Thus the only changes for lexical resources involveadding two small clitic lexicons.Processing Steps: Morphological analysisGoing back to the NLP processing steps listed insection 2, we now discuss new processing changesneeded for treating Arabic.
Tokenization (1a) andsimple word lookup (2a) of the tokenized strings inthe dictionary were unchanged as LIMA wascoded for UTF8.
If the word was not found, anexisting orthographical alternative lookup (1c) wasalso used without change (except for the additionof the language specific correspondence table be-tween accented and unaccented characters) in orderto find lexical entries for unvoweled or partiallyvoweled words.
Using this existing mechanism fortreating the vowelization problem does not allowus to exploit partial vowelization as we explain in alater section.At this point in the processing, a word that containsclitics will not have been found in the dictionarysince we had decided not to include word formsincluding clitics.
We introduced, here, a new proc-essing step for Arabic: a clitic stemmer.
Thisstemmer uses the following linguistic resources:?
The full form dictionary, containing foreach word form its possible part-of-speechtags and linguistic features (gender, num-ber, etc.).
We currently have 5.4 millionentries in this dictionary6.?
The proclitic dictionary and the encliticdictionary, having the same structure ofthe full form dictionary with voweled andunvoweled versions of each valid combi-nation of clitics.
There are 77 and 65 en-tries respectively in each dictionary.The clitic stemmer proceeds as follows on tokensunrecognized after step 1c:?
Several vowel form normalizations areperformed (?
?
?
?
?
?
are removed,  ?
?are replaced by  ?
and  final  ?
?
?
or ?are replaced by  ?
??
??
or  ).6If we generated all forms including appended clitics, wewould generate an estimated 60 billion forms (Attia, 1999).?
All clitic possibilities are computed by us-ing proclitics and enclitics dictionaries.?
A radical, computed by removing theseclitics, is checked against the full formlexicon.
If it does not exist in the full formlexicon, re-write rules (such as those de-scribed in Darwish (2002)) are applied,and the altered form is checked against thefull form dictionary.
For example, considerthe token  ???
? and the included clitics (?,?), the computed radical ??
does not existin the full form lexicon but after applyingone of the dozen re-write rules, the modi-fied radical ??
is found the dictionary andthe input token is segmented into root andclitics as:  ? + ??
+ ?
= ???
? .?
The compatibility of the morpho-syntactictags of the three components (proclitic,radical, enclitic) is then checked.
Onlyvalid segmentations are kept and addedinto the word graph.
Table 1 gives someexamples of segmentations7 of words inthe sentence  ??
?
!
??!?
?????
?
&'()&* +,AgglutinatedwordSegmentations of the aggluti-nated word+,?
= ?,+ ?
+ +,&'()&* &'()&* =  -)&* +  &? ?!
?
?
!
+ ??
= ?
?
? ?!]
+ ?
+ ?
= [?
??
?? ?
?  + ??
= ?
2?? ] + ?
+ ?
= [?
256&34&?
56&34&?
?
5&34&?
+ ??
= ?,56&34&?
5&34&? ]
+ ?
+ ?
= [?,789  789] = 78 ] + ??
+ ??
??
?
???
= ?
+ ????
??
+ ?
= [?
+ [???
;<=) ;<=) = >=) +  Table 1: Segmentations of some agglutinated words.Producing this new clitic stemmer for Arabic al-lowed us to correctly treat a similar (but previouslyignored) phenomenon in Spanish in which verbforms can possess pronominal enclitics.
For exam-ple, the imperative form of ?give to me?
is writtenas ?dame?, which corresponds to the radical ?da?followed the enclitic ?me?.
Once we implementedthis clitic stemmer for Arabic, we created an en-7For example, the agglutinated word   ?!
?
has twosegmentations but only the segmentation:   ?!
+ ??
= ?
?
?will remain after POS tagging in step 2a334clitic dictionary for Spanish and then successfullyused the same stemmer for this European language.At this point, the treatment resumes as with Euro-pean languages.
The detection of idiomatic8 ex-pressions (step 1d) is performed after cliticseparation using rules associated with triggerwords for each expression.
Once a trigger is found,its left and right lexical contexts in the rule are thentested.
The trigger must be an entry in the full formlexicon, but can be represented as either a surfaceform or a lemma form combined with its morpho-syntactic tag.
Here we came across another prob-lem specific to Semitic languages.
Since Arabiclexicon entries are voweled and since input textsmay be partially voweled or unvoweled, we areforced to only use lemma forms to describe Arabicidiomatic expressions rules with the existingmechanism, or else enter all the possible partialvowelizations for each word in an idiomatic ex-pression.
Since, at this point after step 1c, eachrecognized word is represented with all its possiblevoweled lemmas in the analysis graph, we devel-oped 482 contiguous idiomatic voweled expressionrules.
For example one of the developed rules rec-ognizes in the text  ?
)&@?&(?
?
(January) as a wholeand tags the expression as a being a month.After idiomatic expression recognition, any nodesnot yet recognized are assigned (in step 1e) defaultlinguistic values based on features recognized dur-ing tokenization (e.g.
presence of uppercase ornumbers or special characters).
Nothing waschanged for this step of default value assignment inorder to treat Arabic, but since Semitic languagesdo not have the capitalization clues that Englishand French have for recognizing proper and sinceArabic proper names can often be decomposed intosimple words (much like Chinese names), the cur-rent implementation of this step with our currentlexical resources poses some problems.For example, consider the following sentence:+<)&?
?B ; ??!??
?
?, ?<CD EF<D&?
E=D5??
?&(,H I)?
4?=??
; ?&C?
Frank Lampard celebrates the score byChelsea and his team mate Eidur Gudjohnsenshares his elation.
The name  I)?
4  (Frank) is iden-8An idiom in our system is a (possibly non-contiguous se-quence) of known words that act as a single unit.
For example,made up in He made up the story on the spot.
Once anidiomatic expression is recognized the individual words nodesare joined into one node in the word graph.tified as such because it is found in the lexicon; thename  ?
?&(,H (Lampard) is not in the lexicon andincorrectly stemmed as  H +?
?&(,  (plural of the noun?
(, (grater)); the name ??!??
(Eidur) is incorrectlytagged as a verb; and  +<)&?
?B (Gudjohnsen), whichis not in the dictionary and for which the cliticstemmer does not produce any solutions receivesthe default tags adjective, noun, proper noun andverb, to be decided by the part-of-speech tagger.To improve this performance, we plan to enrich theArabic lexicon with more proper names, using ei-ther name recognition (Maloney and Niv, 1998) ora back translation approach after name recognitionin English texts (Al-Onaizan and Knight, 2002).Processing Steps: Part-of-speech analysisFor the succeeding steps involving part-of-speechtagging, named entity recognition, division intonominal and verbal chains, and dependency extrac-tion no changes were necessary for treating Arabic.After morphological analysis, as input to step 2a,part-of-speech tagging, we have the same type ofword graph for Arabic text as for European text:each node is annotated with the surface form, alemma and a part-of-speech in the graph.
If a wordis ambiguous, then more than one node appears inthe graph for that word.
Our part-of-speech tagginginvolves using a language model (bigrams and tri-grams of grammatical tags) derived from hand-tagged text to eliminate unattested or rare sub pathsin the graph of words representing a sentence.
ForArabic, we created a hand-tagged corpus, andwhere then able to exploit the existing mechanism.One space problem that has arisen in applyingthe existing processing designed for European lan-guages comes from the problem of vowelization.With our previous European languages, it was ex-tremely rare to have more than one possible lem-matization for a given pair: (surface form,grammatical part-of-speech tag)9.
But, in Arabicthis can be very common since an unvoweledstring can correspond to many different words,some with the same part-of-speech but differentlemmas.
The effect of this previously unseen typeof ambiguity on our data structures was to greatlyincrease the word graph size before and after part-of-speech tagging.
Since each combination of (sur-9One example from French is the pair (?taient, finite-verb)that can correspond to the two lemmas: ?tre and ?tayer.345face-form, part-of-speech-tag, and lemma) givesrise to a new node, the graph becomes larger, in-creasing the number of paths that all processingsteps must explore.
The solution to this for Arabicand other Semitic languages is simple, though wehave not yet implemented it.
We plan to modifyour internal data structure so that each node willcorrespond to the surface form, a part-of-speechtag, and a set of lemmas: (surface-form, part-of-speech-tag, {lemmas}).
The inclusion of a set ofpossible lemmas, rather than just one lemma, in anode will greatly reduce the number of nodes inthe graph and speed processing time.The next step in our NLP system, after part-of-speech tagging, is named entity recognition(Abuleil and Evans, 2004) using name triggers(e.g., President, lake, corporation, etc.).
Beyond theproblem mentioned above of distinguishing possi-ble proper nouns, here we had an additional prob-lem since our recognizer extracted the entity in itssurface form.
Since in Arabic, as in other Semiticlanguages, the input text is usually only partiallyvoweled, this gave rise to many different forms(corresponding to different surface forms) for thesame entity.
This minor problem was solved bystoring the fully voweled forms of the entities (forapplication such as information retrieval as shownbelow) rather than the surface form.After named entity recognition, our methods ofverbal and nominal chain recognition and depend-ency extraction did not require any modificationsfor Arabic.
But since the sentence graphs, as men-tioned above, are currently large, we have re-stricted the chains recognized to simple noun andverb chunks (Abney, 1991) rather than the morecomplex chains (Marsh, 1984) we recognize forEuropean languages.
Likewise, the only depend-ency relations that we extract for the moment arerelations between nominal elements.
We expectthat the reduction in sentence graph once lemmasare all collected in the same word node will allowus to treat more complex dependency relations.4 Integration in a CLIR applicationThe results of the NLP steps produce, for all lan-guages we treat, a set of normalized lemmas, a setof named entities and a set of nominal compounds(as well as other dependency relations for somelanguages).
These results can be used for any natu-ral language processing application.
For example,we have integrated LIMA as a front-end for a crosslanguage information retrieval system.
The inclu-sion of our Arabic language results into the infor-mation retrieval system did not necessitate anymodifications to this system.This information retrieval (IR) application in-volves three linguistic steps, as shown in section 2.First, in step 3a, subgraphs (compounds and theircomponents) of the original sentence graph arestored.
For example, the NLP analysis will recog-nize an English phrase such as ?management ofwater resources?
as a compound that the IR systemwill index.
This phrase and its sub-elements arenormalized and indexed (as well as simple words)in the following head-first normalized forms:?
management_water_resource?
resource_water?
management_resourceParallel head-first structures are created for differ-ent languages, for example, the French ?gestiondes ressource en eau?
generates:?
gestion_ressource_eau?
ressource_eau?
gestion_ressource.The corresponding Arabic phrase: , 6& ?????
???
?is likewise indexed with voweled forms:?
????????
_ ???
?LLL,?_ ?&,??
???
?LLL,?_ ?&,??
????????
_ ???
?LLL,?When a question is posed to our cross language IR(CLIR) system it undergoes the same NLP treat-ment as in steps 1a to 3a.
Then the query is refor-mulated using synonym dictionaries andtranslation dictionaries in step 3b.
For Arabic, wehave not yet acquired any monolingual synonymdictionaries, but we have purchased and modifiedcross-lingual transfer dictionaries between Arabicand English, Arabic and French, and Arabic andSpanish10.
When a compound is found in a query,it is normalized and its sub elements are extractedas shown above.
Using the reformulation dictionar-ies, variant versions of the compound are generated(monolingual, then cross-lingual versions) and at-10Lind?n and Piitulainen (2004) propose a method for extract-ing monolingual synonym lists from bilingual resources.356tested variants are retained as synonyms to theoriginal compound11 (Besan?on et al, 2003).
Tointegrate the Arabic version into our CLIR system,no modifications were necessary beyond acquiringand formatting the cross language reformulationdictionaries.The final NLP step (3c) involving in our CLIRsystem involves ranking relevant documents.
Con-trary to a bag of word system, which uses onlyterm frequency in queries and documents, our sys-tem (Besan?on et al, 2003) returns documents inranked weighted classes12 whose weightings in-volve the presence of named entities, the com-pleteness of the syntactic subgraphs matched, andthe database frequencies of the words and sub-graphs matched.ExampleAn online version of our cross language retrievalsystem involving our Arabic processing is visibleonline at a third party site: http://alma.oieau.fr.This base contains 50 non-parallel documentsabout sustainable development for each of the fol-lowing languages: English, Spanish, French andArabic.
The user can enter a query in natural lan-guage and specify the language to be used.
In theexample of the Figure 1, the user entered the query?
&6?????
,???
??
and selected Arabic as the languageof the query.Relevant documents are grouped into classes char-acterized by the same set of concepts (i.e., refor-mulated subgraphs) as the query contains.
Figure 2shows some classes corresponding to the query ?&6?????
,???
??.
The query term ???
_????
?,_&,  is aterm composed of three words:  &,, ??
?, and  ????
?.This compounds, its derived variants and their subelements are reformulated into English, French,and Spanish and submitted to indexed versions ofdocuments in each of these languages (as well asagainst Arabic documents).
The highest ranking11This technique will only work with translations which haveat least one subelement that is has a parallel between lan-guages, but this is often the case for technical terms.12This return to a mixed Boolean approach is found in currentresearch on Question Answering systems (Tellex et al, 2003).Our CLIR system resembles such systems, which return thepassage in which the answer is found, since we highlight themost significant passages of each retrieved document.classes (as seen in Figure 2 for this example)match the following elements:Class Query terms Number of retrieved documents1 ???_????
?,_ &,   142 ??
?,_&,  ?
???
_????
?,  183 ???_????
?,  ?
&,  9Terms of the query or the expansion of these termswhich are found in the retrieved documents arehighlighted as illustrated in Figures 2 and 3.5 ConclusionWe have presented here an overview of our naturallanguage processing system and its use in a CLIRsetting.
This article describes the changes that wehad to implement to extend this system, which wasinitially implemented for treating European lan-guages to the Semitic language, Arabic.
Every newlanguage possesses new problems for NLP sys-tems, but treating a language from a new languagefamily can severely test the original design.
Wefound that the major problems we encountered indealing with a language from the Semitic languagefamily involved the problems of dealing with par-tially voweled or unvoweled text (two differentproblems), and of dealing with clitics.
To treat theproblem of clitics, we introduced two new lexiconsand added an additional clitic stemming step at anappropriate place in our morphological analysis.For treating the problem of vowelization, we sim-ply used existing methods for dealing with unac-cented text, but this solution is not totallysatisfactory for two reasons: we do not adequatelyexploit partially voweled text, and our data struc-tures are not efficient for associating many differ-ent lemma (differing only in vowelization) with asingle surface form.
We are currently working onboth these aspects in order to improve our treat-ment of Arabic.
But the changes, that we describehere, involved in adding Arabic were not very ex-tensive, and we able to integrate Arabic languagetreatment into a cross language information re-trieval platform using one man-year of work afterhaving created the lexicon and training corpus.
Aversion of our CLIR is available online and illus-trated in this article.
We plan to more fully evalu-ate the performance of the CLIR system using theTREC 2001 and TREC 2002 in the coming year.367ReferencesSteven Abney.
Parsing by Chunks.
1991.
In R. C. Ber-wick, S. P. Abney, and C. Tenny, editors, Principle-Based Parsing: Computation and Psycholinguistics,Kluwer Academic Publishers, Boston.Saleem Abuleil, Martha Evens.
2004.
Named EntityRecognition and Classification for Text in Arabic.IASSE 2004, pp.
89-94Mohamed Attia.
1999.
A large-Scale ComputationalProcessor of Arabic Morpholofy, and Applications.M.S.
thesis in Computer Engineering, Cairo Univer-sity, pp.
28-32.Y.
Al-Onaizan and K. Knight.
2002.
Machine Translit-eration of Names in Arabic Text.
Proc.
of ACLWorkshop on Computational Approaches to SemiticLanguages, pp.
400-408Kenneth Beesley.
1996.
Arabic Finite-State Morpho-logical Analysis and Generation.
Proc.
of COLING-96, pp.
89-94.Romaric Besan?on, Ga?l de Chalendar, Olivier Ferret,Christian Fluhr, Olivier Mesnard, and Hubert Naets.2003.
Concept-Based Searching and Merging forMultilingual Information Retrieval: First Experi-ments at CLEF 2003.
CLEF-2003, pp.
174-184.K.
Darwish.
2002.
Building a Shallow Arabic Morpho-logical Analyzer in One Day.
In Proc.
ACL-02, pp.47-54Fathi Debili and Lotfi Zouari.
1985.
Analyse morpholo-gique de l?arabe ?crit voyell?
ou non fond?e sur laconstruction automatique d?un dictionnaire arabe,Cognitiva, Paris.Leah S. Larkey, Lisa Ballesteros, Margaret E. Connell.2002.
Improving stemming for Arabic informationretrieval: light stemming and co-occurrence analysis.Proc.
of SIGIR 2002, pp.
275-282Krister Lind?n and Jussi Piitulainen.
2004.
DiscoveringSynonyms and Other Related Words.
CompuTerm2004, Geneva, Switzerland, August 29.John Maloney and Michael Niv.
1998.
TAGARAB: AFast, Accurate Arabic Name Recogniser Using HighPrecision Morphological Analysis.
Proc.
of theWorkshop on Computational Approaches to SemiticLanguages.
Montreal, Canada.
August.Elain Marsh.
1984.
A Computational Analysis of Com-plex Noun Phrases in Navy Messages.
In Proc.
ofCOLING '84, Stanford, pp.
505-508.Diana Maynard, Valentin Tablan, Kalina Bontcheva,Hamish Cunningham.
2003.
Rapid Customization ofan Information Extraction System for a Surprise Lan-guage.
ACM Trans.
Asian Lang.
Inf.
Process.
2(3)pp.
295-300.Stefanie Tellex, Boris Katz, Jimmy Lin, Gregory Mar-ton, and Aaron Fernandes.
2003.
QuantitativeEvaluation of Passage Retrieval Algorithms forQuestion Answering.
Proc.
Of SIGIR 2003, pp.
41-47Figure 1: User interface for querying the database.
The user can choose between English, French, Spanish and Ara-bic as input language.
For best results, the query should be syntactically correct and not in telegraphic form.378Figure 2: Search results user interface.
Results can appear in many languages.Figure 3: Highlighting query terms in retrieved documents.38
