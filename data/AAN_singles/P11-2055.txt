Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pages 317?322,Portland, Oregon, June 19-24, 2011. c?2011 Association for Computational LinguisticsParaSense or How to Use Parallel Corpora for Word Sense DisambiguationEls Lefever1,2, Ve?ronique Hoste1,2,3 and Martine De Cock21LT3, Language and Translation Technology Team, University College GhentGroot-Brittannie?laan 45, 9000 Gent, Belgium2Dept.
of Applied Mathematics and Computer Science, Ghent UniversityKrijgslaan 281 (S9), 9000 Gent, Belgium3Dept.
of Linguistics, Ghent UniversityBlandijnberg 2, 9000 Gent, BelgiumAbstractThis paper describes a set of exploratory ex-periments for a multilingual classification-based approach to Word Sense Disambigua-tion.
Instead of using a predefined monolin-gual sense-inventory such as WordNet, we usea language-independent framework where theword senses are derived automatically fromword alignments on a parallel corpus.
We builtfive classifiers with English as an input lan-guage and translations in the five supportedlanguages (viz.
French, Dutch, Italian, Span-ish and German) as classification output.
Thefeature vectors incorporate both the more tra-ditional local context features, as well as bi-nary bag-of-words features that are extractedfrom the aligned translations.
Our resultsshow that the ParaSense multilingual WSDsystem shows very competitive results com-pared to the best systems that were evaluatedon the SemEval-2010 Cross-Lingual WordSense Disambiguation task for all five targetlanguages.1 IntroductionWord Sense Disambiguation (WSD) is the NLPtask that consists in selecting the correct sense ofa polysemous word in a given context.
Most state-of-the-art WSD systems are supervised classifiersthat are trained on manually sense-tagged corpora,which are very time-consuming and expensive tobuild (Agirre and Edmonds, 2006) .
In order to over-come this acquisition bottleneck (sense-tagged cor-pora are scarce for languages other than English),we decided to take a multilingual approach to WSD,that builds up the sense inventory on the basis ofthe Europarl parallel corpus (Koehn, 2005).
Usingtranslations from a parallel corpus implicitly dealswith the granularity problem as finer sense distinc-tions are only relevant as far as they are lexicalizedin the target translations.
It also facilitates the in-tegration of WSD in multilingual applications suchas multilingual Information Retrieval (IR) or Ma-chine Translation (MT).
Significant improvementsin terms of general MT quality were for the first timereported by Carpuat and Wu (2007) and Chan et al(2007).
Both papers describe the integration of adedicated WSD module in a Chinese-English statis-tical machine translation framework and report sta-tistically significant improvements in terms of stan-dard MT evaluation metrics.Several studies have already shown the validityof using parallel corpora for sense discrimination(e.g.
(Ide et al, 2002)), for bilingual WSD mod-ules (e.g.
(Gale and Church, 1993; Ng et al, 2003;Diab and Resnik, 2002; Chan and Ng, 2005; Da-gan and Itai, 1994)) and for WSD systems that usea combination of existing WordNets with multilin-gual evidence (Tufis?
et al, 2004).
The research de-scribed in this paper is novel as it presents a trulymultilingual classification-based approach to WSDthat directly incorporates evidence from four otherlanguages.
To this end, we build further on twowell-known research ideas: (1) the possibility touse parallel corpora to extract translation labels andfeatures in an automated way and (2) the assump-tion that incorporating evidence from multiple lan-guages into the feature vector will be more infor-mative than a more restricted set of monolingual orbilingual features.
Furthermore, our WSD systemdoes not use any information from external lexicalresources such as WordNet (Fellbaum, 1998) or Eu-roWordNet (Vossen, 1998).3172 Experimental SetupStarting point of the experiments was the six-lingualsentence-aligned Europarl corpus that was used inthe SemEval-2010 ?Cross-Lingual Word Sense Dis-ambiguation?
(CLWSD) task (Lefever and Hoste,2010b).
The task is a lexical sample task for twentyEnglish ambiguous nouns that consists in assign-ing a correct translation in the five supported tar-get languages (viz.
French, Italian, Spanish, Ger-man and Dutch) for an ambiguous focus word in agiven context.
In order to detect the relevant transla-tions for each of the twenty ambiguous focus words,we ran GIZA++ (Och and Ney, 2003) with its de-fault settings for all focus words.
This word align-ment output was then considered to be the label forthe training instances for the corresponding classi-fier (e.g.
the Dutch translation is the label that is usedto train the Dutch classifier).
By considering thisword alignment output as oracle information, we re-defined the CLWSD task as a classification task.To train our five classifiers (English as input lan-guage and French, German, Dutch, Italian and Span-ish as focus languages), we used the memory-basedlearning (MBL) algorithm implemented in TIMBL(Daelemans and Hoste, 2002), which has success-fully been deployed in previous WSD classificationtasks (Hoste et al, 2002).
We performed heuris-tic experiments to define the parameter settings forthe classifier, leading to the selection of the Jef-frey Divergence distance metric, Gain Ratio featureweighting and k = 7 as number of nearest neigh-bours.
In future work, we plan to use an optimizedword-expert approach in which a genetic algorithmperforms joint feature selection and parameter op-timization per ambiguous word (Daelemans et al,2003).For our feature vector creation, we combined a setof English local context features and a set of binarybag-of-words features that were extracted from thealigned translations.2.1 Training Feature Vector ConstructionWe created two experimental setups.
The firsttraining set incorporates the automatically generatedword alignments as labels.
We applied an automaticpost-processing step on these word alignments in or-der to remove leading and trailing determiners andprepositions.
In future work, we will investigateother word alignment strategies and measure the im-pact on the classification scores.
The second trainingset uses manually verified word alignments as labelsfor the training instances.
This second setup is thento be considered as the upper bound on the currentexperimental setup.All English sentences were preprocessedby means of a memory-based shallow parser(MBSP) (Daelemans and van den Bosch, 2005) thatperforms tokenization, Part-of-Speech tagging andtext chunking.
The preprocessed sentences wereused as input to build a set of commonly used WSDfeatures related to the English input sentence:?
features related to the focus word itself beingthe word form of the focus word, the lemma,Part-of-Speech and chunk information?
local context features related to a window ofthree words preceding and following the focusword containing for each of these words theirfull form, lemma, Part-of-Speech and chunk in-formationIn addition to these well known monolingual fea-tures, we extracted a set of binary bag-of-words fea-tures from the aligned translation that are not thetarget language of the classifier (e.g.
for the Dutchclassifier, we extract bag-of-words features from theItalian, Spanish, French and German aligned trans-lations).
In order to extract useful content words,we first ran Part-of-Speech tagging and lemmatisa-tion by means of the Treetagger (Schmid, 1994) tool.Per ambiguous focus word, a list of content words(nouns, adjectives, verbs and adverbs) was extractedthat occurred in the aligned translations of the En-glish sentences containing the focus word.
One bi-nary feature per selected content word was then cre-ated per ambiguous word: ?0?
in case the word doesnot occur in the aligned translation of this instance,and ?1?
in case the word does occur in the alignedtranslation of the training instance.2.2 Test Feature Vector ConstructionFor the creation of the feature vectors for the test in-stances, we follow a similar strategy as the one weused for the creation of the training instances.
Thefirst part of the feature vector contains the English318local context features that were also extracted forthe training instances.
For the construction of thebag-of-words features however, we need to adopt adifferent approach as we do not have aligned trans-lations for the English test instances at our disposal.We decided to deploy a novel strategy that usesthe Google Translate API1 to automatically gener-ate a translation for all English test instances in thefive supported languages.
Online machine transla-tions tools have already been used before to createartificial parallel corpora that were used for NLPtasks such as for instance Named Entity Recogni-tion (Shah et al, 2010).In a next step the automatically generated transla-tion was preprocessed in the same way as the train-ing translations (Part-of-Speech-tagged and lemma-tized).
The resulting lemmas were then used to con-struct the same set of binary bag-of-words featuresthat were stored for the training instances of the am-biguous focus word.3 EvaluationTo evaluate our five classifiers, we used the sense in-ventory and test set of the SemEval ?Cross-LingualWord Sense Disambiguation?
task.
The sense inven-tory was built up on the basis of the Europarl corpus:all retrieved translations of a polysemous word weremanually grouped into clusters, which constitute dif-ferent senses of that given word.
The test instanceswere selected from the JRC-ACQUIS MultilingualParallel Corpus2 and BNC3.
To label the test data,native speakers provided their top three translationsfrom the predefined clusters of Europarl translations,in order to assign frequency weights to the set ofgold standard translations.
A more detailed descrip-tion of the construction of the data set can be foundin Lefever and Hoste (2010a).As evaluation metrics, we used both the SemEvalBEST precision metric from the CLWSD task aswell as a straightforward accuracy measure.
TheSemEval metric takes into account the frequencyweights of the gold standard translations: transla-tions that were picked by different annotators geta higher weight.
For the BEST evaluation, systems1http://code.google.com/apis/language/2http://wt.jrc.it/lt/Acquis/3http://www.natcorp.ox.ac.uk/can propose as many guesses as the system believesare correct, but the resulting score is divided by thenumber of guesses.
In this way, systems that out-put a lot of guesses are not favoured.
For a moredetailed description of the SemEval scoring scheme,we refer to McCarthy and Navigli (2007).
Follow-ing variables are used for the SemEval precision for-mula.
Let H be the set of annotators, T the set of testitems and hi the set of responses for an item i ?
Tfor annotator h ?
H .
Let A be the set of items fromT where the system provides at least one answer andai : i ?
A the set of guesses from the system foritem i.
For each i, we calculate the multiset union(Hi) for all hi for all h ?
H and for each uniquetype (res) in Hi that has an associated frequency(freqres).Prec =?ai:i?APres?aifreqres|ai||Hi||A|(1)The second metric we use is a straightforward ac-curacy measure, that divides the number of correctanswers by the total amount of test instances.As a baseline, we selected the most frequent lem-matized translation that resulted from the automatedword alignment (GIZA++).
We also compare ourresults with the two winning SemEval-2 systemsfor the Cross-Lingual Word Sense Disambiguationtask, UvT-WSD (that only participated for Dutchand Spanish) and T3-COLEUR.
The UvT-WSD sys-tem (van Gompel, 2010), that also uses a k-nearestneighbor classifier and a variety of local and globalcontext features, obtained the best scores for Span-ish and Dutch in the SemEval CLWSD competi-tion.
Although we also use a memory-based learner,our method is different from this system in the waythe feature vectors are constructed.
Next to theincorporation of similar local context features, wealso include evidence from multiple languages inour feature vector.
For French, Italian and Ger-man however, the T3-COLEUR system (Guo andDiab, 2010) outperformed the other systems in theSemEval competition.
This system adopts a differ-ent approach: during the training phase a monolin-gual WSD system processes the English input sen-tence and a word alignment module is used to ex-tract the aligned translation.
The English senses to-gether with their aligned translations (and probabil-319ity scores) are then stored in a word sense transla-tion table, in which look-ups are performed duringthe testing phase.
This system also differs from theUvt-WSD and ParaSense systems in the sense thatthe word senses are derived from WordNet, whereasthe other systems do not use any external resources.The results for all five classifiers are listed in twotables.
Table 1 gives an overview of the SemEval-2010 weighted precision scores, whereas Table 2shows the more straightforward accuracy figures.Both tables list the scores averaged over all twentytest words for the baseline (most frequent wordalignment), the best SemEval system (for a givenlanguage) and the two ParaSense setups: one that ex-clusively uses automatically generated word align-ments, and one that uses the verified word alignmentlabels.
For both setups we trained three flavors ofthe ParaSense system (1: local context + translationfeatures, 2: translation features and 3: local contextfeatures).The classification results show that for both se-tups all three flavors of the ParaSense system easilybeat the baseline.
Moreover, the ParaSense systemclearly outperforms the winning SemEval systems,except for Spanish where the scores are similar.
Asall systems, viz.
the two SemEval systems as wellas the three flavors of the ParaSense system, weretrained on the same Europarl data, the scores illus-trate the potential advantages of using a multilingualapproach.
Although we applied a very basic strategyfor the selection of our bag-of-words translation fea-tures (we did not perform any filtering on the trans-lations except for Part-of-Speech information), weobserve that for three languages the full feature vec-tor outperforms the classifier that uses the more tra-ditional WSD local context features.
For Dutch, theclassifier that merely uses translation features evenoutperforms the classifier that uses the local contextfeatures.
In previous research (Lefever and Hoste,2011), we showed that the classifier using evidencefrom all different languages was constantly betterthan the ones using less or no multilingual evidence.In addition, the scores also degraded relatively to thenumber of translation features that was used.
As weused a different set of translation features for the lat-ter pilot experiments (we only used the translationsof the ambiguous words instead of the full bag-of-words features we used for the current setup), weneed to confirm this trend with more experimentsusing the current feature sets.Another important observation is that the classifi-cation scores degrade when using the automaticallygenerated word alignments, but only to a minor ex-tent.
This clearly shows the viability of our setup.Further experiments with different word alignmentsettings and symmetrisation methods should allowus to further improve the results with the automat-ically generated word alignments.
Using the non-validated labels makes the system very flexible andlanguage-independent, as all steps in the feature vec-tor creation can be run automatically.4 ConclusionWe presented preliminary results for a multilingualclassification-based approach to Word Sense Dis-ambiguation.
In addition to the commonly usedmonolingual local context features, we also incor-porate bag-of-word features that are built from thealigned translations.
Although there is still a lot ofroom for improvement on the feature base, our re-sults show that the ParaSense system clearly outper-forms state-of-the-art systems for all languages, ex-cept for Spanish where the results are very similar.As all steps are run automatically, this multilingualapproach could be an answer for the acquisition bot-tleneck, as long as there are parallel corpora avail-able for the targeted languages.
Although large mul-tilingual corpora are still rather scarce, we stronglybelieve there will be more parallel corpora availablein the near future (large companies and organiza-tions disposing of large quantities of parallel text,internet corpora such as the ever growing Wikipediacorpus, etc.).
Another line of research could be theexploitation of comparable corpora to acquire addi-tional training data.In future work, we want to run additional exper-iments with different classifiers (SVM) and applya genetic algorithm to perform joint feature selec-tion, parameter optimization and instance selection.We also plan to expand our feature set by includingglobal context features (content words from the En-glish sentence) and to examine the relationship be-tween the performance and the number (and nature)of languages that is added to the feature vector.
Inaddition, we will apply semantic analysis tools (such320French Italian Spanish Dutch GermanBaseline 20.71 14.03 18.36 15.69 13.16T3-COLEUR 21.96 15.55 19.78 10.71 13.79UvT-WSD 23.42 17.70Non-verified word alignment labelsParaSense1 (full feature vector) 24.54 18.03 22.80 18.56 16.88ParaSense2 (translation features) 23.92 16.77 22.58 17.70 15.98ParaSense3 (local context features) 24.09 19.89 23.21 17.57 16.55Verified word alignment labelsParaSense1 (full feature vector) 24.60 19.64 23.10 18.61 17.41ParaSense2 (translation features) 24.29 19.15 22.94 18.25 16.90ParaSense3 (local context features) 24.79 21.31 23.56 17.70 17.54Table 1: SemEval precision scores averaged over all twenty test wordsFrench Italian Spanish Dutch GermanBaseline 63.10 47.90 53.70 59.40 52.30T3-COLEUR 66.88 50.73 59.83 40.01 54.20UvT-WSD 70.20 64.10Non-verified word alignment labelsParaSense1 (full feature vector) 75.20 63.40 68.20 68.10 66.20ParaSense2 (translation features) 73.20 58.30 67.60 65.90 63.60ParaSense3 (local context features) 73.50 65.50 69.40 63.90 61.90Verified word alignment labelsParaSense1 (full feature vector) 75.70 63.20 68.50 68.20 67.80ParaSense2 (translation features) 74.70 61.30 68.30 66.80 66.20ParaSense3 (local context features) 75.20 67.30 70.30 63.30 66.10Table 2: Accuracy percentages averaged over all twenty test wordsas LSA) on our multilingual bag-of-words sets inorder to detect latent semantic topics in the multi-lingual feature base.
Finally, we want to evaluateto which extent the integration of our WSD outputhelps practical applications such as Machine Trans-lation or Information Retrieval.AcknowledgmentsWe thank the anonymous reviewers for their valu-able remarks.
This research was funded by the Uni-versity College Research Fund.ReferencesE.
Agirre and P. Edmonds, editors.
2006.
Word SenseDisambiguation.
Algorithms and Applications.
Text,Speech and Language Technology.
Springer, Dor-drecht.M.
Carpuat and D. Wu.
2007.
Improving statisticalmachine translation using word sense disambiguation.In Proceedings of the 2007 Joint Conference on Em-pirical Methods in Natural Language Processing andComputational Natural Language Learning (EMNLP-CoNLL), pages 61?72, Prague, Czech Republic.Y.S.
Chan and H.T.
Ng.
2005.
Scaling Up Word SenseDisambiguation via Parallel Texts.
In Proceedings ofthe 20th National Conference on Artificial Intelligence(AAAI 2005), pages 1037?1042, Pittsburgh, Pennsyl-vania, USA.Y.S.
Chan, H.T.
Ng, and D. Chiang.
2007.
Word sensedisambiguation improves statistical machine transla-tion.
In Proceedings of the 45th Annual Meeting of theAssociation of Computational Linguistics, pages 33?40, Prague, Czech Republic.W.
Daelemans and V. Hoste.
2002.
Evaluation of Ma-chine Learning Methods for Natural Language Pro-cessing Tasks.
In Proceedings of the third Interna-tional Conference on Language Resources and Eval-uation (LREC?02), pages 755?760.W.
Daelemans and A. van den Bosch.
2005.
Memory-based Language Processing.
Cambridge UniversityPress.W.
Daelemans, V. Hoste, F. De Meulder, and B. Naudts.2003.
Combined optimization of feature selection and321algorithm parameters in machine learning of language.Machine Learning, pages 84?95.I.
Dagan and A. Itai.
1994.
Word sense disambiguationusing a second language monolingual corpus.
Compu-tational Linguistics, 20(4):563?596.M.
Diab and P. Resnik.
2002.
An Unsupervised Methodfor Word Sense Tagging Using Parallel Corpora.
InProceedings of ACL, pages 255?262.C.
Fellbaum.
1998.
WordNet: An Electronic LexicalDatabase.
MIT Press.W.A.
Gale and K.W.
Church.
1993.
A program for align-ing sentences in bilingual corpora.
ComputationalLinguistics, 19(1):75?102.W.
Guo and M. Diab.
2010.
COLEPL and COLSLM: AnUnsupervised WSD Approach to Multilingual LexicalSubstitution, Tasks 2 and 3 SemEval 2010.
In Pro-ceedings of the 5th International Workshop on Seman-tic Evaluation, pages 129?133, Uppsala, Sweden.
As-sociation for Computational Linguistics.V.
Hoste, I. Hendrickx, W. Daelemans, and A. van denBosch.
2002.
Parameter Optimization for Machine-Learning of Word Sense Disambiguation.
NaturalLanguage Engineering, Special Issue on Word SenseDisambiguation Systems, 8:311?325.N.
Ide, T. Erjavec, and D. Tufis?.
2002.
Sense discrimi-nation with parallel corpora.
.
In ACL-2002 Workhopon Word Sense Disambiguation: Recent Successes andFuture Directions, pages 54?60, Philadelphia.Ph.
Koehn.
2005.
Europarl: a parallel corpus for statisti-cal machine translation.
In Tenth Machine TranslationSummit, pages 79?86, Phuket, Thailand.E.
Lefever and V. Hoste.
2010a.
Constructionof a Benchmark Data Set for Cross-Lingual WordSense Disambiguation.
In Nicoletta Calzolari, KhalidChoukri, Bente Maegaard, Joseph Mariani, Jan Odijk,Stelios Piperidis, and Daniel Tapias, editors, Proceed-ings of the seventh International Conference on Lan-guage Resources and Evaluation (LREC?10), Valletta,Malta, May.
European Language Resources Associa-tion (ELRA).E.
Lefever and V. Hoste.
2010b.
SemEval-2010 Task3: Cross-Lingual Word Sense Disambiguation.
InProceedings of the 5th International Workshop on Se-mantic Evaluation, ACL 2010, pages 15?20, Uppsala,Sweden.E.
Lefever and V. Hoste.
2011.
Examining the Validityof Cross-Lingual Word Sense Disambiguation.
In Pro-ceedings of the Conference on Computational Linguis-tics and Intelligent Text Processing (CICLing 2011),Tokyo, Japan.D.
McCarthy and R. Navigli.
2007.
SemEval-2007 Task10: English Lexical Substitution Task.
In Proceedingsof the 4th International Workshop on Semantic Eval-uations (SemEval-2007), pages 48?53, Prague, CzechRepublic.H.T.
Ng, B. Wang, and Y.S.
Chan.
2003.
Exploiting par-allel texts for word sense disambiguation: An empiri-cal study.
In 41st Annual Meeting of the Associationfor Computational Linguistics (ACL), pages 455?462,Sapporo, Japan.F.
J. Och and H. Ney.
2003.
A systematic comparison ofvarious statistical alignment models.
ComputationalLinguistics, 29(1):19?51.H.
Schmid.
1994.
Probabilistic part-of-speech taggingusing decision trees.
In Proceedings of the Interna-tional Conference on new methods in Language Pro-cessing, Manchester, UK.R.
Shah, B. Lin, A. Gershman, and R. Frederking.
2010.SYNERGY: A Named Entity Recognition System forResource-scarce Languages such as Swahili using On-line Machine Translation.
In Proceedings of theSecond Workshop on African Language Technology(AFLAT 2010), Valletta, Malt.D.
Tufis?, R. Ion, and N. Ide.
2004.
Fine-GrainedWord Sense Disambiguation Based on Parallel Cor-pora, Word Alignment, Word Clustering and AlignedWordnets.
In Proceedings of the 20th InternationalConference on Computational Linguistics (COLING2004), pages 1312?1318, Geneva, Switzerland, Au-gust.
Association for Computational Linguistics.M.
van Gompel.
2010.
UvT-WSD1: A Cross-LingualWord Sense Disambiguation System.
In Proceedingsof the 5th International Workshop on Semantic Evalu-ation, pages 238?241, Uppsala, Sweden.
Associationfor Computational Linguistics.P.
Vossen, editor.
1998.
EuroWordNet: a multilingualdatabase with lexical semantic networks.
Kluwer Aca-demic Publishers, Norwell, MA, USA.322
