Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 727?731,Dublin, Ireland, August 23-24, 2014.UMCC DLSI: Sentiment Analysis in Twitter using Polirity Lexicons andTweet SimilarityPedro Aniel S?anchez-Mirabal,Yarelis Ruano Torres,Suilen Hern?andez AlvaradoUniversity of Matanzas / Cubapedroasm@umcc.cuyara@umcc.cusuilen.alvarado@umcc.cuYoan Guti?errez,Andr?es Montoyo,Rafael Mu?nozUniversity of Alicante/Spainygutierrez@dlsi.ua.esmontoyo@dlsi.ua.esrafael@dlsi.ua.esAbstractThis paper describes a system sub-mitted to SemEval-2014 Task 4B:Sentiment Analysis in Twitter, by theteam UMCC DLSI Sem integrated byresearchers of the University of Matanzas,Cuba and the University of Alicante,Spain.
The system adopts a cascadeclassification process that uses two classi-fiers, K-NN using the lexical Levenshteinmetric and a Dagging model trained overattributes extracted from annotated cor-pora and sentiment lexicons.
Phrases thatfit the distance thresholds were automat-ically classified by the KNN model, theothers, were evaluated with the Daggingmodel.
This system achieved over 52.4%of correctly classified instances in theTwitter message-level subtask.1 IntroductionNowadays, one of the most important sources ofdata to extract useful and heterogeneous knowl-edge is Textual Information.
Daily, millionsof Tweets, SMS and blog comments increasethe huge volume of information available for re-searchers.
Texts can provide factual information,such as: descriptions, lists of characteristics, oreven instructions to opinion-based information,which would include reviews, emotions, or feel-ings (Guti?errez et al., 2013).
These facts havemotivated that dealing with the identification andextraction of opinions and sentiments in texts re-quires special attention.
Applications of Senti-ment Analysis are now more common than everin fields like politics and business.
More than 50This work is licensed under a Creative Commons At-tribution 4.0 International Licence.
Page numbers and pro-ceedings footer are added by the organisers.
Licence details:http://creativecommons.org/licenses/by/4.0/systems participating in this task, clearly indicatethe increase of interest in the scientific community.Twitter messages can be found among of themost used corpora nowadays for Sentiment Anal-ysis (SA).
This kind of messages involves an evi-dent informality which has been addressed in dif-ferent ways.
For example, there are some workslike (Guti?errez et al., 2013) that apply normali-sation textual tools to reduce the informality ofthe twitter messages.
Authors such as (Go et al.,2009), (Guti?errez et al., 2013), (Fern?andez et al.,2013) and others are focused on the applicationof preprocessing processes and feature reductionto be able to standardise twitter messages and re-duce different types of elements like hashtags, usernicks, urls, etc.In terms of those techniques that can be usedfor SA, we can cite (Pang et al., 2002) who builta lexicon with associated polarity value, startingwith a set of classified seed adjectives and usingconjunctions (and) disjunctions (or, but) to deducethe orientation of new words in a corpus.
This re-search was based on machine learning techniquesto address Sentiment Classification.
Other inter-esting research is (Turney, 2002), which classi-fies words according to their polarity based onthe idea that terms with similar orientation tendto co-occur in documents.
There are a large quan-tity of approaches to deal with SA, and basicallymost of them are based on word bags and/or an-notated corpora as knowledge base.
Based on thisinformation the SA systems are able to apply dif-ferent types of evaluation techniques such as ma-chine learning or statistic formulas to predict thecorrect classification.
As part of machine learn-ing approaches we would like to mention thoseworks such as (Go et al., 2009), (Mohammad etal., 2013) and others that were based on featurevectors and which cover a wide range settings ofSA.
As a starting point, we based this work onthe (Mohammad et al., 2013) approach, adding727new features extracted from the sentiment repos-itories Sentiment 1401and NRC-Hashtag Senti-ment (Mohammad and Turney, 2013).The remainder of this paper is structured as fol-lows: section 2 describes in detail the approachpresented.
In section 3 we explain the experimentswe carried out.
Finally in section 4 conclusionsand future works are expounded.2 System DescriptionIn this section we present our system in detailwhich is able to classify the polarity of tweets aspositive, negative, or neutral.The system is structured in two main stages.The first stage consists of classifying a giventweet.
For that, we first recovered all the tweetsfrom the training corpus that have a similarityvalue greater than a fixed threshold T .
The sec-ond stage consists of classifying using the K-NNrule (Coomans and Massart, 1982), considering asK all tweets recovered.
The process begins withT = 0.9 decreasing it until T = 0.6.
In section 3we will explain how these values were determined.As similarity metric we use the Levenshtein(Levenshtein, 1966) lexical distance.
In case thatwe cannot find any tweet fulfilling the condition,the tweet polarity is assigned using a second clas-sifier trained using Dagging which combines sev-eral Logistic classifiers set by WEKA as default.2.1 PreprocessingThe first step in our system is to pre-process alltweets.
The following operations were applied inthe given order.- Replacing emoticons: Each emoticon isreplaced by a word according to alexicon of emoticons.
The mean-ings of the emoticons were taken fromhttp://en.wikipedia.org/wiki/List_of_emoticons.- Replacing acronyms: Each acronym is re-placed by its meaning.
The meanings of theacronyms were taken from http://www.acronymfinder.com/.- Cleaning text: Remove not alphanumeric char-acters from the tweet.- Replacing abbreviations: Each abbrevia-tion is replaced by its respective words.1http://cs.stanford.edu/people/alecmgo/trainingandtestdata.zipThe abbreviations were taken fromhttp://en.wikipedia.org/wiki/Abbreviation.- Lemmatising: Each word is replaced by itslemma.
We use Freeling 3.0 (Padr?o andStanilovsky, 2012) for this purpose.
We onlyretain lemmas corresponding to adjectives,adverbs, interjections, nouns and verbs.- Expanding contractions: Each contractionis replaced by its respective word.
Thecontractions were taken from http://www.softschools.com/language_arts/grammar/contractions/contractions_list/.- Deleting punctuation marks.- Deleting stop words.
The stop wordswere taken from http://www.ranks.nl/stopwords.2.2 Recovering tweets from similarityAs it was explained before, in a first step we triedto classify tweets using the K-NN rule.
To recoverthe K similar tweets we used the Levenshtein met-ric (Levenshtein, 1966).
This measure allows tocompute the similarity of two strings of symbolscounting the minimum number of deletions, sub-stitutions and insertions necessary to transformone string into another.
In our case, each word inthe string is considered as a symbol.
In the futurewe plan to improve this metric using Levenshteinat word level and then at sentence level.
This met-ric is known as DLED (Double Levenshteins EditDistance) and will be taken from (Fern?andez et al.,2012).2.3 Features for Dagging classifierWe represented each tweet as a vector of featuresbased in (Mohammad et al., 2013) plus other newones.
Also we used the lexicons Sentiment 140and NRC-Hashtag Sentiment as it was definedby Mohammad.Also two new lexicons, named NRC EmotionLexicon 1.0 and NRC Emotion Lexicon 2.0 werederived from the NRC Emotion Lexicon (Mo-hammad and Turney, 2013).
In the first case weassociated to each word just the values in thecolumns positive and negative of NRC EmotionLexicon, thus, no sentiment score was computed.728For the second lexicon, the positive score was cal-culated as the sum of the values for the classifica-tions positive, anticipation, joy, surprise and trust.On the other hand, the negative score was com-puted as the sum of the values for the classifica-tions negative, anger, disgust, fear, sadness andtrust.In each case we computed the following at-tributes:- Pos: Sum of the positive scores of each tokenin the tweet over the number of tokens in thetweet.- Neg: Sum of the negative scores of each tokenin the tweet over the number of tokens in thetweet.- PercentPos:100?PosPos+Neg- MissNGram: Percent of tokens in the tweet thatwere not found in the lexicon.For the Sentiment 140 and NRC-Hashtag Sen-timent lexicons we also computed the feature:- SSE: Sum of the sentiment score of each tokenin the tweet over the number of tokens in thetweet.Based on the information involved into Senti-ment 140 and NRC-Hashtag Sentiment lexicons,unigrams, bigrams and pairs were tokenised in-volving any non-contiguous combination of theprevious n-grams.
With respect to the pairs extrac-tion were considered the following possibilities:unigram-unigram, unigram-bigram and bigram-bigram.
Similar to (Mohammad et al., 2013) dif-ferent set of attributes were generated for eachtype of token.
As result an initial set of 50 at-tributes were obtained.In the case of the new lexicons (NRC EmotionLexicon 1.0 and NRC Emotion Lexicon 2.0), onlyunigrams were considered.
Moreover, the featureSSE was not computed.
So, another 8 featureswere taken into account with respect to these lexi-cons.Finally we computed:- NCL: Percent of tokens in capital letters.- NoE: Number of emoticons in the tweet.- NoA: Number of acronyms in the tweet.In general the system works with a total of 61attributes.2.4 Classifier DesignAs training set, we joined the preprocessed tweetsfrom both the train and development sets pro-vided by the Task9B of Semeval-2014.
TheDagging classifier was trained using this setwith the following parameters -F 15 -S 1 -Wweka.classifiers.functions.Logistic ?
-R 1.0E-8 -M -1 using a 10 fold cross-validation as evaluationmethod.3 ExperimentsThe experiments were evaluated over the trainingdataset provided by Task 9: Sentiment Analysis inTwitter, subtask B.
Based on the explanation pro-vided in section 2 according to the initialisation ofthe threshold T to ensure that the K similar tweetsare in fact similar enough, we carried out an exper-iment for different values of T .
These experimentsrefer an analysis to know how the variation of Taffects the classification results.T % CCI0.9 86.70.8 83.30.7 74.10.6 67.20.5 61.10.4 55.00.3 56.0Table 1: Results of the K-NN classifier using Lev-enshtein metric.T % CCI0.9 81.20.8 83.30.7 74.10.6 66.70.5 63.10.4 60.60.3 54.2Table 2: Results of the K-NN classifier usingMatching Coefficient metric.The first stage of the system was applied tocompute the number of instances which have atleast one instance with a similarity value greaterthan T .
We computed the percent of instancescorrectly classified (%CCI).
Table 1 shows thebehaviour of the system when T changes.
Table2 shows the results of the K-NN classifier using729System LiveJournal2014 SMS2013 Twitter2013 Twitter2014 Twitter2014SarcasmBest result 74.8 70.3 72.1 71.0 58.2Average result 63.5 55.6 59.8 60.6 45.4UMCC-DLSI-Sem 53.1 50.0 52.0 55.4 42.8Worse result 29.3 24.6 34.2 33.0 29.0Table 3: Results in the SemEval-2014 Task 4B.Matching Coefficient metric (http://www.coli.uni-saarland.de/courses/LT1/2011/slides/stringmetrics.pdf).This metric counts the quantity of matchedsymbols (words in this case) between twosentences.Furthermore, we repeated this experiment usingthe Matching Coefficient similarity metric to bet-ter tunning the algorithm and to evaluate if the re-sults behave in a similar way when T changes.
Inboth cases, we use the implementation provided inthe SimMetrics library.As those results shows, when T decrease the ac-curacy decrease too.
In practice, for the values ofT lower than 0.6 the results are worse than 61.4%using the Dagging classifier in the 10 fold cross-validation.
For that reason, as was mentioned in 2,we only tried to apply the first stage for values ofT ?
0.6 .We evaluated our system in the challenge Task4B: Sentiment Analysis in Twitter, using the pro-vided training and test data of this challenge.Based on the classifier obtained in the training pro-cess we tested our system over the test datasetachieving values of %CCI up to 55.4.
Table 3show detailed results for each of the 5 differentsources.4 Conclusions and Future WorksOur system was based on an approach that followstwo stages to classify the polarity of tweets.
Re-gardless the fact that our system behaves worsethan the average, we consider that the approach issuitable to deal with SA, since our results are closeto the average.
As future works we will studyother approaches in order to encourage further de-velopments of this proposal.
Several issues couldbe adjusted, for example, other distances should betested and evaluated such as DLED (Double Lev-enshteins Edit Distance) (Fern?andez et al., 2012).Also, features that encode information about thepresence of negation and opposition words couldbe very useful.AcknowledgementsThis research work has been partially fundedby the University of Alicante, Generalitat Va-lenciana, Spanish Government and the EuropeanCommission through the projects, ?Tratamientointeligente de la informacin para la ayuda a la tomade decisiones?
(GRE12-44), ATTOS (TIN2012-38536-C03-03), LEGOLANG (TIN2012-31224),SAM (FP7-611312), FIRST (FP7-287607) andACOMP/2013/067.ReferencesD.
Coomans and D.L.
Massart.
1982.
Alternative k-nearest neighbour rules in supervised pattern recog-nition : Part 1. k-nearest neighbour classification byusing alternative voting rules.
Analytica ChimicaActa, 136(0):15?27.Antonio Fern?andez, Yoan Guti?errez, H?ector D?avila,Alexander Ch?avez, Andy Gonz?alez, Rainel Estrada,Yenier Casta?neda, Sonia V?azquez, Andr?es Montoyo,and Rafael Mu?noz.
2012.
Umcc dlsi: Multidimen-sional lexical-semantic textual similarity.
In *SEM2012: The First Joint Conference on Lexical andComputational Semantics ?
Volume 1: Proceedingsof the main conference and the shared task, and Vol-ume 2: Proceedings of the Sixth International Work-shop on Semantic Evaluation (SemEval 2012), pages608?616, Montr?eal, Canada, 7-8 June.
Associationfor Computational Linguistics.Javi Fern?andez, Yoan Guti?errez, Jos?e M G?omez, Patri-cio Mart?nez-Barco, Andr?es Montoyo, and RafaelMunoz.
2013.
Sentiment analysis of spanish tweetsusing a ranking algorithm and skipgrams.
Proc.
ofthe TASS workshop at SEPLN 2013.
IV CongresoEspa?nol de Inform?atica, pages 17?20.Alec Go, Richa Bhayani, and Lei Huang.
2009.
Twit-ter sentiment classification using distant supervision.Processing, pages 1?6.Yoan Guti?errez, Andy Gonz?alez, Roger P?erez, Jos?e I.Abreu, Antonio Fern?andez Orqu?
?n, Alejandro Mos-quera, Andr?es Montoyo, Rafael Mu?noz, and FrancCamara.
2013.
Umcc dlsi-(sa): Using a rankingalgorithm and informal features to solve sentimentanalysis in twitter.
In Second Joint Conference onLexical and Computational Semantics (*SEM), Vol-ume 2: Proceedings of the Seventh International730Workshop on Semantic Evaluation (SemEval 2013),pages 443?449, Atlanta, Georgia, USA, June.
Asso-ciation for Computational Linguistics.Vladimir Levenshtein.
1966.
Binary codes capa-ble of correcting deletions, insertions, and rever-sals.
Cybernetics and Control Theory, 10(8):707?710.
Original in Doklady Akademii Nauk SSSR163(4): 845?848 (1965).Saif M. Mohammad and Peter D. Turney.
2013.Crowdsourcing a word-emotion association lexicon.29(3):436?465.Saif M. Mohammad, Svetlana Kiritchenko, and Xiao-dan Zhu.
2013.
Nrc-canada: Building the state-of-the-art in sentiment analysis of tweets.
CoRR,abs/1308.6242.Llu?
?s Padr?o and Evgeny Stanilovsky.
2012.
Freeling3.0: Towards wider multilinguality.
In Proceedingsof the Language Resources and Evaluation Confer-ence (LREC 2012), Istanbul, Turkey, May.
ELRA.Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.2002.
Thumbs up?
: Sentiment classification usingmachine learning techniques.
In Proceedings of theACL-02 Conference on Empirical Methods in Natu-ral Language Processing - Volume 10, EMNLP ?02,pages 79?86, Stroudsburg, PA, USA.
Associationfor Computational Linguistics.Peter D. Turney.
2002.
Thumbs up or thumbs down?
:Semantic orientation applied to unsupervised classi-fication of reviews.
In Proceedings of the 40th An-nual Meeting on Association for Computational Lin-guistics, ACL ?02, pages 417?424, Stroudsburg, PA,USA.
Association for Computational Linguistics.731
