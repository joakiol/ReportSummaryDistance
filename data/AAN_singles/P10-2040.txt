Proceedings of the ACL 2010 Conference Short Papers, pages 215?219,Uppsala, Sweden, 11-16 July 2010. c?2010 Association for Computational LinguisticsSVD and Clustering for Unsupervised POS TaggingMichael Lamar*Division of Applied MathematicsBrown UniversityProvidence, RI, USAmlamar@dam.brown.eduYariv Maron*Gonda Brain Research CenterBar-Ilan UniversityRamat-Gan, Israelsyarivm@yahoo.comMark JohnsonDepartment of ComputingFaculty of ScienceMacquarie UniversitySydney, Australiamjohnson@science.mq.edu.auElie BienenstockDivision of Applied Mathematicsand Department of NeuroscienceBrown UniversityProvidence, RI, USAelie@brown.eduAbstractWe revisit the algorithm of Sch?tze(1995) for unsupervised part-of-speechtagging.
The algorithm uses reduced-ranksingular value decomposition followedby clustering to extract latent featuresfrom context distributions.
As imple-mented here, it achieves state-of-the-arttagging accuracy at considerably less costthan more recent methods.
It can alsoproduce a range of finer-grained tag-gings, with potential applications to vari-ous tasks.1 IntroductionWhile supervised approaches are able to solvethe part-of-speech (POS) tagging problem withover 97% accuracy (Collins 2002; Toutanova etal.
2003), unsupervised algorithms perform con-siderably less well.
These models attempt to tagtext without resources such as an annotated cor-pus, a dictionary, etc.
The use of singular valuedecomposition (SVD) for this problem was in-troduced in Sch?tze (1995).
Subsequently, anumber of methods for POS tagging without adictionary were examined, e.g., by Clark (2000),Clark (2003), Haghighi and Klein (2006), John-son (2007), Goldwater and Griffiths (2007), Gaoand Johnson (2008), and Gra?a et al (2009).The latter two, using Hidden Markov Models(HMMs), exhibit the highest performances todate for fully unsupervised POS tagging.The revisited SVD-based approach presentedhere, which we call ?two-step SVD?
or SVD2,has four important characteristics.
First, itachieves state-of-the-art tagging accuracy.Second, it requires drastically less computationaleffort than the best currently available models.Third, it demonstrates that state-of-the-art accu-racy can be realized without disambiguation, i.e.,without attempting to assign different tags to dif-ferent tokens of the same type.
Finally, with nosignificant increase in computational cost, SVD2can create much finer-grained labelings than typ-ically produced by other algorithms.
When com-bined with some minimal supervision in post-processing, this makes the approach useful fortagging languages that lack the resources re-quired by fully supervised models.2 MethodsFollowing the original work of Sch?tze (1995),we begin by constructing a right context matrix,R, and a left context matrix, L.  Rij counts thenumber of times in the corpus a token of wordtype i is immediately followed by a token ofword type j.
Similarly, Lij counts the number oftimes a token of type i is preceded by a token oftype j.
We truncate these matrices, including, inthe right and left contexts, only the w1 most fre-quent word types.
The resulting L and R are ofdimension Ntypes?w1, where Ntypes is the numberof word types (spelling forms) in the corpus, andw1 is set to 1000.
(The full Ntypes?
Ntypes contextmatrices satisfy R = LT.)* These authors contributed equally.215Next, both context matrices are factored usingsingular value decomposition:L = UL SL VLTR = UR SR VRT.The diagonal matrices SL and SR (each of rank1000) are reduced down to rank r1 = 100 by re-placing the 900 smallest singular values in eachmatrix with zeros, yielding SL* and SR*.
We thenform a pair of latent-descriptor matrices definedby:L* = UL SL*R* = UR SR*.Row i in matrix L* (resp.
R*) is the left (resp.right) latent descriptor for word type i.
We nextinclude a normalization step in which each rowin each of L* and R* is scaled to unit length,yielding matrices L** and R**.
Finally, we form asingle descriptor matrix D by concatenating thesematrices into D = [L** R**].
Row i in matrix D isthe complete latent descriptor for word type i;this latent descriptor sits on the Cartesian productof two 100-dimensional unit spheres, hereafterthe 2-sphere.We next categorize these descriptors intok1 = 500 groups, using a k-means clustering algo-rithm.
Centroid initialization is done by placingthe k initial centroids on the descriptors of the kmost frequent words in the corpus.
As the de-scriptors sit on the 2-sphere, we measure theproximity of a descriptor to a centroid by the dotproduct between them; this is equal to the sum ofthe cosines of the angles?computed on the leftand right parts?between them.
We update eachcluster?s centroid as the weighted average of itsconstituents, the weight being the frequency ofthe word type; the centroids are then scaled, sothey sit on the 2-sphere.
Typically, only a fewdozen iterations are required for full convergenceof the clustering algorithm.We then apply a second pass of this entireSVD-and-clustering procedure.
In this secondpass, we use the k1 = 500 clusters from the firstiteration to assemble a new pair of context ma-trices.
Now, Rij counts all the cluster-j (j=1?
k1)words to the right of word i, and Lij counts all thecluster-j words to the left of word i.
The new ma-trices L and R have dimension Ntypes ?
k1.As in the first pass, we perform reduced-rankSVD, this time down to rank r2 = 300, and weagain normalize the descriptors to unit length,yielding a new pair of latent descriptor matricesL** and R**.
Finally, we concatenate L** and R**into a single matrix of descriptors, and clusterthese descriptors into k2 groups, where k2 is thedesired number of induced tags.
We use the sameweighted k-means algorithm as in the first pass,again placing the k initial centroids on the de-scriptors of the k most frequent words in the cor-pus.
The final tag of any token in the corpus isthe cluster number of its type.3 Data and EvaluationWe ran the SVD2 algorithm described above onthe full Wall Street Journal part of the PennTreebank (1,173,766 tokens).
Capitalization wasignored, resulting in Ntypes = 43,766, with only aminor effect on accuracy.
Evaluation was doneagainst the POS-tag annotations of the 45-tagPTB tagset (hereafter PTB45), and against theSmith and Eisner (2005) coarse version of thePTB tagset (hereafter PTB17).
We selected thethree evaluation criteria of Gao and Johnson(2008): M-to-1, 1-to-1, and VI.
M-to-1 and 1-to-1 are the tagging accuracies under the best many-to-one map and the greedy one-to-one map re-spectively; VI is a map-free information-theoretic criterion?see Gao and Johnson (2008)for details.
Although we find M-to-1 to be themost reliable criterion of the three, we includethe other two criteria for completeness.In addition to the best M-to-1 map, we alsoemploy here, for large values of k2, a prototype-based M-to-1 map.
To construct this map, wefirst find, for each induced tag t, the word typewith which it co-occurs most frequently; we callthis word type the prototype of t. We then querythe annotated data for the most common gold tagfor each prototype, and we map induced tag t tothis gold tag.
This prototype-based M-to-1 mapproduces accuracy scores no greater?typicallylower?than the best M-to-1 map.
We discussthe value of this approach as a minimally-supervised post-processing step in Section 5.4 ResultsLow-k performance.
Here we present the per-formance of the SVD2 model when k2, the num-ber of induced tags, is the same or roughly thesame as the number of tags in the gold stan-dard?hence small.
Table 1 compares the per-formance of SVD2 to other leading models.
Fol-lowing Gao and Johnson (2008), the number ofinduced tags is 17 for PTB17 evaluation and 50for PTB45 evaluation.
Thus, with the exceptionof Gra?a et al (2009) who use 45 induced tagsfor PTB45, the number of induced tags is thesame across each column of Table 1.216The performance of SVD2 compares favora-bly to the HMM models.
Note that SVD2 is adeterministic algorithm.
The table shows, in pa-rentheses, the standard deviations reported inGra?a et al (2009).
For the sake of comparisonwith Gra?a et al (2009), we also note that, withk2 = 45, SVD2 scores 0.659 on PTB45.
The NVIscores (Reichart and Rappoport 2009) corres-ponding to the VI scores for SVD2 are 0.938 forPTB17 and 0.885 for PTB45.
To examine thesensitivity of the algorithm to its four parameters,w1, r1, k1, and r2, we changed each of these para-meters separately by a multiplicative factor ofeither 0.5 or 2; in neither case did M-to-1 accura-cy drop by more than 0.014.This performance was achieved despite thefact that the SVD2 tagger is mathematicallymuch simpler than the other models.
Our MAT-LAB implementation of SVD2 takes only a fewminutes to run on a desktop computer, in contrastto HMM training times of several hours or days(Gao and Johnson 2008; Johnson 2007).High-k performance.
Not suffering from thesame computational limitations as other models,SVD2 can easily accommodate high numbers ofinduced tags, resulting in fine-grained labelings.The value of this flexibility is discussed in thenext section.
Figure 1 shows, as a function of k2,the tagging accuracy of SVD2 under both thebest and the prototype-based M-to-1 maps (seeSection 3), for both the PTB45 and the PTB17tagsets.
The horizontal one-tag-per-word-typeline in each panel is the theoretical upper limitfor tagging accuracy in non-disambiguatingmodels (such as SVD2).
This limit is the fractionof all tokens in the corpus whose gold tag is themost frequent for their type.5 DiscussionAt the heart of the algorithm presented here isthe reduced-rank SVD method of Sch?tze(1995), which transforms bigram counts into la-tent descriptors.
In view of the present work,which achieves state-of-the-art performancewhen evaluation is done with the criteria now incommon use, Sch?tze's original work shouldrightly be praised as ahead of its time.
The SVD2model presented here differs from Sch?tze'swork in many details of implementation?not allof which are explicitly specified in Sch?tze(1995).
In what follows, we discuss the featuresof SVD2 that are most critical to its performance.Failure to incorporate any one of them signifi-Figure 1.
Performance of the SVD2 algo-rithm as a function of the number of inducedtags.
Top: PTB45; bottom: PTB17.
Eachplot shows the tagging accuracy under thebest and the prototype-based M-to-1 maps, aswell as the upper limit for non-disambiguating taggers.M-to-1 1-to-1 VIModel PTB17 PTB45 PTB17 PTB45 PTB17 PTB45SVD2 0.730 0.660 0.513 0.467 3.02 3.84HMM-EM  0.647 0.621 0.431 0.405 3.86 4.48HMM-VB  0.637 0.605 0.514 0.461 3.44 4.28HMM-GS  0.674 0.660 0.466 0.499 3.46 4.04HMM-Sparse(32) 0.702(2.2) 0.654(1.0) 0.495 0.445VEM (10-1,10-1) 0.682(0.8) 0.546(1.7) 0.528 0.460Table 1.
Tagging accuracy under the best M-to-1 map, the greedy 1-to-1 map, andVI, for the full PTB45 tagset and  the reduced PTB17 tagset.
HMM-EM, HMM-VBand HMM-GS show the best results from Gao and Johnson (2008); HMM-Sparse(32)and VEM (10-1,10-1) show the best results from Gra?a et al (2009).217cantly reduces the performance of the algorithm(M-to-1 reduced by 0.04 to 0.08).First, the reduced-rank left-singular vectors(for the right and left context matrices) arescaled, i.e., multiplied, by the singular values.While the resulting descriptors, the rows of L*and R*, live in a much lower-dimensional spacethan the original context vectors, they aremapped by an angle-preserving map (defined bythe matrices of right-singular vectors VL and VR)into vectors in the original space.
These mappedvectors best approximate (in the least-squaressense) the original context vectors; they have thesame geometric relationships as their equivalenthigh-dimensional images, making them goodcandidates for the role of word-type descriptors.A second important feature of the SVD2 algo-rithm is the unit-length normalization of the la-tent descriptors, along with the computation ofcluster centroids as the weighted averages oftheir constituent vectors.
Thanks to this com-bined device, rare words are treated equally tofrequent words regarding the length of their de-scriptor vectors, yet contribute less to the place-ment of centroids.Finally, while the usual drawback of k-means-clustering algorithms is the dependency of theoutcome on the initial?usually random?placement of centroids, our initialization of the kcentroids as the descriptors of the k most fre-quent word types in the corpus makes the algo-rithm fully deterministic, and improves its per-formance substantially: M-to-1 PTB45 by 0.043,M-to-1 PTB17 by 0.063.As noted in the Results section, SVD2 is fairlyrobust to changes in all four parameters w1, r1, k1,and r2.
The values used here were obtained by acoarse, greedy strategy, where each parameterwas optimized independently.
It is worth notingthat dispensing with the second pass altogether,i.e., clustering directly the latent descriptor vec-tors obtained in the first pass into the desirednumber of induced tags, results in a drop ofMany-to-1 score of only 0.021 for the PTB45tagset and 0.009 for the PTB17 tagset.Disambiguation.
An obvious limitation ofSVD2 is that it is a non-disambiguating tagger,assigning the same label to all tokens of a type.However, this limitation per se is unlikely to bethe main obstacle to the improvement of low-kperformance, since, as is well known, the theo-retical upper limit for the tagging accuracy ofnon-disambiguating models (shown in Fig.
1) ismuch higher than the current state-of-the-art forunsupervised taggers, whether disambiguating ornot.To further gain insight into how successfulcurrent models are at disambiguating when theyhave the power to do so, we examined a collec-tion of HMM-VB runs (Gao and Johnson 2008)and asked how the accuracy scores would changeif, after training was completed, the model wereforced to assign the same label to all tokens ofthe same type.
To answer this question, we de-termined, for each word type, the modal HMMstate, i.e., the state most frequently assigned bythe HMM to tokens of that type.
We then re-labeled all words with their modal label.
The ef-fect of thus eliminating the disambiguation ca-pacity of the model was to slightly increase thetagging accuracy under the best M-to-1 map forevery HMM-VB run (the average increase was0.026  for PTB17, and 0.015 for PTB45).
Weview this as a further indication that, in the cur-rent state of the art and with regards to taggingaccuracy, limiting oneself to non-disambiguatingmodels may not adversely affect performance.To the contrary, this limitation may actuallybenefit an approach such as SVD2.
Indeed, ondifficult learning tasks, simpler models often be-have better than more powerful ones (Geman etal.
1992).
HMMs are powerful since they can, intheory, induce both a system of tags and a systemof contextual patterns that allow them to disam-biguate word types in terms of these tags.
How-ever, carrying out both of these unsupervisedlearning tasks at once is problematic in view ofthe very large number of parameters to be esti-mated compared to the size of the training dataset.The POS-tagging subtask of disambiguationmay then be construed as a challenge in its ownright: demonstrate effective disambiguation in anunsupervised model.
Specifically, show that tag-ging accuracy decreases when the model's dis-ambiguation capacity is removed, by re-labelingall tokens with their modal label, defined above.We believe that the SVD2 algorithm presentedhere could provide a launching pad for an ap-proach that would successfully address the dis-ambiguation challenge.
It would do so by allow-ing a gradual and carefully controlled amount ofambiguity into an initially non-disambiguatingmodel.
This is left for future work.Fine-grained labeling.
An important feature ofthe SVD2 algorithm is its ability to produce afine-grained labeling of the data, using a numberof clusters much larger than the number of tags218in a syntax-motivated POS-tag system.
Suchfine-grained labelings can capture additional lin-guistic features.
To achieve a fine-grained labe-ling, only the final clustering step in the SVD2algorithm needs to be changed; the computation-al cost this entails is negligible.
A high-qualityfine-grained labeling, such as achieved by theSVD2 approach, may be of practical interest asan input to various types of unsupervised gram-mar-induction algorithms (Headden et al 2008).This application is left for future work.Prototype-based tagging.
One potentially im-portant practical application of a high-qualityfine-grained labeling is its use for languageswhich lack any kind of annotated data.
By firstapplying the SVD2 algorithm, word types aregrouped together into a few hundred clusters.Then, a prototype word is automatically ex-tracted from each cluster.
This produces, in acompletely unsupervised way, a list of only afew hundred words that need to be hand-taggedby an expert.
The results shown in Fig.
1 indicatethat these prototype tags can then be used to tagthe entire corpus with only a minor decrease inaccuracy compared to the best M-to-1 map?theconstruction of which requires a fully annotatedcorpus.
Fig.
1 also indicates that, with only a fewhundred prototypes, the gap left between the ac-curacy thus achieved and the upper bound fornon-disambiguating models is fairly small.ReferencesAlexander Clark.
2000.
Inducing syntactic categoriesby context distribution clustering.
In The FourthConference on Natural Language Learning.Alexander Clark.
2003.
Combining distributional andmorphological information for part of speech in-duction.
In 10th Conference of the European Chap-ter of the Association for Computational Linguis-tics, pages 59?66.Michael Collins.
2002.
Discriminative training me-thods for hidden markov models: Theory and expe-riments with perceptron algorithms.
In Proceedings ofthe ACL-02 conference on Empirical methods innatural language processing ?
Volume 10.Jianfeng Gao and Mark Johnson.
2008.
A comparisonof bayesian estimators for unsupervised HiddenMarkov Model POS taggers.
In Proceedings of the2008 Conference on Empirical Methods in NaturalLanguage Processing, pages 344?352.Stuart Geman, Elie Bienenstock and Ren?
Doursat.1992.
Neural Networks and the Bias/Variance Di-lemma.
Neural Computation,  4 (1), pages 1?58.Sharon Goldwater and Tom Griffiths.
2007.
A fullyBayesian approach to unsupervised part-of-speechtagging.
In Proceedings of the 45th Annual Meet-ing of the Association of Computational Linguis-tics, pages 744?751.Jo?o V. Gra?a, Kuzman Ganchev, Ben Taskar, andFernando Pereira.
2009.
Posterior vs. ParameterSparsity in Latent Variable Models.
In Neural In-formation Processing Systems Conference (NIPS).Aria Haghighi and Dan Klein.
2006.
Prototype-drivenlearning for sequence models.
In Proceedings ofthe Human Language Technology Conference ofthe NAACL, Main Conference, pages 320?327,New York City, USA, June.
Association for Com-putational Linguistics.William P. Headden, David McClosky, and EugeneCharniak.
2008.
Evaluating unsupervised part-of-speech tagging for grammar induction.
In Proceed-ings of the International Conference on Computa-tional Linguistics (COLING ?08).Mark Johnson.
2007.
Why doesn?t EM find goodHMM POS-taggers?
In Proceedings of the 2007Joint Conference on Empirical Methods in NaturalLanguage Processing and Computational NaturalLanguage Learning (EMNLP-CoNLL), pages 296?305.Marina Meil?.
2003.
Comparing clusterings by thevariation of information.
In Bernhard Sch?lkopfand Manfred K. Warmuth, editors, COLT 2003:The Sixteenth Annual Conference on LearningTheory, volume 2777 of Lecture Notes in Comput-er Science, pages 173?187.
Springer.Roi Reichart and Ari Rappoport.
2009.
The NVIClustering Evaluation Measure.
In Proceedings ofthe Thirteenth Conference on Computational Natu-ral Language Learning (CoNLL), pages 165?173.Hinrich Sch?tze.
1995.
Distributional part-of-speechtagging.
In Proceedings of the seventh conferenceon European chapter of the Association for Com-putational Linguistics, pages 141?148.Noah A. Smith and Jason Eisner.
2005.
Contrastiveestimation: Training log-linear models on unla-beled data.
In Proceedings of the 43rd AnnualMeeting of the Association for Computational Lin-guistics (ACL?05), pages 354?362.Kristina Toutanova, Dan Klein, Christopher D. Man-ning and Yoram Singer.
2003.
Feature-rich part-of-speech tagging with a cyclic dependency network.In Proceedings of HLT-NAACL 2003, pages 252-259.219
