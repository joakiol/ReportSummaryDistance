Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on SemanticEvaluation (SemEval 2013), pages 592?597, Atlanta, Georgia, June 14-15, 2013. c?2013 Association for Computational LinguisticsCeli: EDITS and Generic Text Pair ClassificationMilen KouylekovCeli S.R.L.via San Quintino 31Torino,10121, Italykouylekov@celi.itLuca DiniCeli S.R.L.via San Quintino 31Torino,10121, Italydini@celi.itAlessio BoscaCeli S.R.L.via San Quintino 31Torino,10121, Italyalessio.bosca@celi.itMarco TrevisanCeli S.R.L.via San Quintino 31Torino, Italytrevisan@celi.itAbstractThis paper presents CELI?s participation in theSemEval The Joint Student Response Anal-ysis and 8th Recognizing Textual EntailmentChallenge (Task7) and Cross-lingual TextualEntailment for Content Synchronization task(Task 8).1 IntroductionRecognizing an existing relation between two textfragments received a significant interest as NLP taskin the recent years.
A lot of the approaches werefocused in the filed of Textual Entailment(TE).
TEhas been proposed as as a comprehensive frame-work for applied semantics (Dagan and Glickman,2004), where the need for an explicit mapping be-tween linguistic objects can be, at least partially,bypassed through the definition of semantic infer-ences at the textual level.
In the TE framework, atext (T ) is said to entail the hypothesis (H) if themeaning of H can be derived from the meaning ofT .
Initially defined as binary relation between texts(YES/NO there is an entailment or there is not) theTE evolved in the third RTE3 (Giampiccolo et al2007) challenge into a set of three relations betweentexts: ENTAILMENT, CONTRADICTION andUNKNOWN.
These relations are interpreted as fol-lows:?
ENTAILMENT - The T entails the H .?
CONTRADICTION - The H contradicts the T?
UNKNOWN - There is no semantic connectionbetween T and H .With more and more applications available forrecognizing textual entailment the researches fo-cused their efforts in finding practical applicationsfor the developed systems.
Thus the Cross-LingualTextual Entailment task (CLTE) was created usingtextual entailment (TE) to define cross-lingual con-tent synchronization scenario proposed in (Mehdadet.
al., 2011), (Negri et.
al., 2011) (Negri et.
al.,2012).
The task is defined by the organizers as fol-lows: Given a pair of topically related text fragments(T1 and T2) in different languages, the CLTE taskconsists of automatically annotating it with one ofthe following entailment judgments:?
Bidirectional: the two fragments entail eachother (semantic equivalence)?
Forward: unidirectional entailment from T1 toT2?
Backward: unidirectional entailment from T2to T1?
No Entailment: there is no entailment betweenT1 and T2The textual entailment competition also evolved.In this year SEMEVAL The Joint Student ResponseAnalysis and 8th Recognizing Textual EntailmentChallenge - JRSA-RTE8 (Task7) the textual entail-ment was defined in three subtasks:5-way task , where the system is required to clas-sify the student answer according to one of the fol-lowing judgments:?
Correct, if the student answer is a complete andcorrect paraphrase of the reference answer;592?
Partially correct incomplete, if the student an-swer is a partially correct answer containingsome but not all information from the referenceanswer;?
Contradictory, if the student answer explicitlycontradicts the reference answer;?
Irrelevant, if the student answer is ?irrelevant?,talking about domain content but not providingthe necessary information;?
Non domain, if the student answer expresses arequest for help, frustration or lack of domainknowledge - e.g., ?I don?t know?, ?as the booksays?, ?you are stupid?.3-way task , where the system is required to clas-sify the student answer according to one of the fol-lowing judgments:?
correct?
contradictory?
incorrect, conflating the categories of par-tially correct incomplete, irrelevant ornon domain in the 5-way classification2-way task , where the system is required to clas-sify the student answer according to one of the fol-lowing judgments:?
correct?
incorrect, conflating the categories of contra-dictory and incorrect in the 3-way classifica-tion.Following the overall trend, we have decided toconvert our system for recognizing textual entail-ment EDITS from a simple YES/NO recognitionsystem into a generic system capable of recognizingmultiple semantic relationships between two texts.EDITS (Kouylekov and Negri, 2010) and(Kouylekov et.
al., 2011) is an open source pack-age for recognizing textual entailment, which offersa modular, flexible, and adaptable working environ-ment to experiment with the RTE task over differentdatasets.
The package allows to: i) create an en-tailment engine by defining its basic components ii)train such entailment engine over an annotated RTEcorpus to learn a model; and iii) use the entailmentengine and the model to assign an entailment judg-ments and a confidence score to each pair of an un-annotated test corpus.We define the recognition of semantic relationsbetween two texts as a classification task.
In thistask the system takes as an input two texts and clas-sifies them in one of a set of predefined relations.We have modified EDITS in order to handle the sodefined task.Having this in mind we have participated inJRSA-RTE8 (task 7) and CLTE2 (task 8) with thesame approach.
We have merged EDITS with somefeatures from the TLike system described in our lastparticipation in CLTE (Kouylekov et.
al., 2011).
Foreach of the tasks we have created a specialized com-ponents that are integrated in EDITS as one of thesystem?s modules.2 EDITS and Generic Text PairClassificationAs in the previous versions, the core of EDITS im-plements a distance-based framework.
Within thisframework the system implements and harmonizesdifferent approaches to distance computation be-tween texts, providing both edit distance algorithms,and similarity algorithms.
Each algorithm returnsa normalized distance score (a number between 0and 1).
Each algorithm algorithm depends on twogeneric modules defined by the system?s user:?
Matcher - a module that is used to align textfragments.
This module uses semantic tech-niques and entailment rules to find equivalenttextfragments.?
Weight Calculator - a module that is used togive weight to text fragments.
The weights areused to determine the importance of a text por-tion to the overall meaning of the text.In the previous versions of the system at the train-ing stage, distance scores calculated over annotatedT-H pairs are used to estimate a threshold that bestseparates positive (YES) from negative (NO) exam-ples.
The calculated threshold was used at a teststage to assign an entailment judgment and a con-fidence score to each test pair.
In the new version593of the system we used a machine learning classifierto classify the T-H pairs in the appropriate category.The overall architecture of the system is shown inFigure 1.The new architecture is divided in two sets ofmodules: Machine Learning and Edit Distance.
Inthe Edit Distance set various distance algorithms areused to calculate the distance between the two texts.Each of these algorithms have a custom matcher andweight calculator.
The distances calculated by eachof these algorithms are used as features for the clas-sifiers of the Machine Leaning modules.
The ma-chine learning modules are structured in two levels:?
Binary Classifiers - for each semantic relationwe create a binary classifier that distinguishesbetween the members of the relation and themembers of the other relations.
For example:For 3way task (Task 7) the system created 3 bi-nary classifiers one for each relation.?
Classifier - a module that makes final decisionfor the text pair taking the output (decision andconfidence) of the binary classifiers as an input.We have experimented with other configurationsof the machine leaning modules and selected thisone as the best performing on the available datasetsof the previous RTE competitions.
In the versionof EDITS avalble online other configurations of themachine leaning modules will be available using theflexibility of the system configuration.We have used the algorithms implemented inWEKA (Hall et al 2009) for the classification mod-ules.
The binary modules use SMO algorithm.
Thetop classifier uses NaiveBayes.The input to the system is a corpus of text pairseach classified with one semantic relation.
We haveused the format of the previous RTE competitionsin order to be compliant.
The goal of the system isto create classifier that is capable of recognizing thecorrect relation for an un-annotated pair of texts.The new version of EDITS package allows to:?
Create an Classifier by defining its basic com-ponents (i.e.
algorithms, matchers, and weightcalculators);?
Train such Classifier over an annotated corpus(containing T-H pairs annotated in terms of en-tailment) to learn a Model;?
Use the Classifier and the Model to assign anentailment judgment and a confidence score toeach pair of an un-annotated test corpus.3 ResourcesLike our participation in the 2012 SemEval Cross-lingual Textual Entailment for Content Synchroniza-tion task (Kouylekov et.
al., 2011), our approach isbased on four main resources:?
A system for Natural Language Processing ableto perform for each relevant language basictasks such as part of speech disambiguation,lemmatization and named entity recognition.?
A set of word based bilingual translation mod-ules.
(Employed only for Task 8)?
A semantic component able to associate a se-mantic vectorial representation to words.?
We use Wikipedia as multilingual corpus.NLP modules are described in (Bosca and Dini,2008), and will be no further detailed here.Word-based translation modules are composed bya bilingual lexicon look-up component coupled witha vector based translation filter, such as the one de-scribed in (Curtoni and Dini, 2008).
In the context ofthe present experiments, such a filters has been de-activated, which means that for any input word thecomponent will return the set of all possible transla-tions.
For unavailable pairs, we make use of trian-gular translation (Kraaij, 2003).As for the semantic component we experimentedwith a corpus-based distributional approach capableof detecting the interrelation between different termsin a corpus; the strategy we adopted is similar to La-tent Semantic Analysis (Deerwester et.
al., 1990)although it uses a less expensive computational solu-tion based on the Random Projection algorithm (Linet.
al., 2003) and (Bingham et.
al., 2001).
Differentworks debate on similar issues: (Turney, 2001) usesLSA in order to solve synonymy detection questionsfrom the well-known TOEFL test while the methodpresented by (Inkpen, 2001) or by (Baroni and Bisi,2001) proposes the use of the Web as a corpus to594Figure 1: EDITS Architecturecompute mutual information scores between candi-date terms.We use Wikipedia as a corpus for calculatingword statistics in different languages.
We have in-dexed using Lucene1 the English, Italian, French,German, Spanish distributions of the resource.The semantic component and the translation2modules are used as core components in the matchermodule.
IDF calculated on Wikipedia is used asweight for the words by the weight calculator model.4 JRSA-RTE8In the JRSA-RTE8 we consider the reference an-swers as T (text) and the student answer as H (hy-pothesis).
As the reference answers are often morethan one, we considered as input to the machinelearning algorithms the distance between the studentanswer and the closest reference answer.
We definethe closest reference answer as the reference answerwith minimum distance according to the distance al-gorithm.1http://lucene.apache.org2Translation module is used only for Task 8.4.1 SystemsWe have submitted two runs in the SemEval JRSA-RTE8 challenge (Task 7).
The systems were exe-cuted on each of the sub tasks of the main task.System 1 The distance algorithm used in the firstsystem is Word Overlap.
The algorithm tries to findthe words of a source text between the words of thetarget text.
We have created two features for eachbinary classifier: 1) Feature 1 - word overlap of Hinto T (words of H are matched by the words in T;2) Feature 2 - word overlap T into H (Words of T arematched by the words in H).System 2 In the second system the we have usedonly Feature 1.We have created separate models for the Beatledataset and the sciEntsBank dataset.
The results ob-tained are shown in Table 1.4.2 AnalysisThe results obtained are in line with our previousparticipations in the RTE challenges (Kouylekov et.al., 2011).
Of course as we described before in ourpapers (Kouylekov et.
al., 2011) the potential of theedit distance algorithm is limited.
Still it provides a595Task Beatle Q Beatle A sciEntsBank Q sciEntsBank A sciEntsBank D2wayrun 1 0.6400 0.6570 0.5930 0.6280 0.6160run 2 0.4620 0.4480 0.5560 0.5930 0.57103wayrun 1 0.5510 0.4950 0.5240 0.5780 0.5490run 2 0.4150 0.4400 0.4390 0.5030 0.47705wayrun 1 0.4830 0.4470 0.4130 0.4340 0.4170run 2 0.3850 0.4320 0.2330 0.2370 0.2540Table 1: Task 7 Results obtained.
(Accuracy)good performance and provides a solid potential forsome close domain tasks as described in (Negri andKouylekov, 2009).
We were quite content with thenew machine learning based core.
The selected con-figuration performed in an acceptable manner.
Theresults obtained were in line with the cross accuracyobtained by our system on the training set whichshows that it is not susceptible to over-training.5 CLTE5.1 SystemsWe have submitted two runs in the CLTE task (Task8).System 1 The distance algorithm used in the firstsystem is Word Overlap as we did for task 7.
Wehave created two features for each binary classifier:1) Feature 1 - word overlap of H into T (words of Hare matched by the words in T; 2) Feature 2 - wordoverlap T into H (Words of T are matched by thewords in H).System 2 In the second system we have made aslight modification of the matcher that handled num-bers.The matcher module for this task used the transla-tion modules defined in Section 3.
We have createda model for each language pair.The results obtained are shown in Table 2.5.2 AnalysisThe results obtained are quite disappointing.
Oursystem obtained on the test set of the last CLTE com-petition (CLTE1) quite satisfactory results (clte1-test).
All the results obtained for this competitionare near or above the medium of the best systems.Our algorithm did not show signs of over-training(the accuracy of the system on the test and on thetraining of CLTE1 were almost equal).
Having thisin mind we expected to obtain scores at least in themargins of 0.45 to 0.5.
This does not happen ac-cording us due to the fact that this year dataset hascharacteristics quite different than the last year.
Totest this hypothesis we have trained our system onhalf of the dataset (clte2-half-training) ,given for testthis year, and test it on the rest (clte-half-test).
Theresults obtained demonstrate that the dataset givenis more difficult for our system than the last yearsone.
The results also prove that our system is prob-ably too conservative when learning from examples.If the test set is similar to the training it performsin consistent manner on both, otherwise it demon-strates severe over-training problems.6 ConclusionsIn this paper we have presented a generic system fortext pair classification.
This system was evaluatedon task 7 and task 8 of Semeval 2013 and obtainedsatisfactory results.
The new machine learning mod-ule of the system needs improvement and we plan tofocus our future efforts in it.We plan to release the newly developed system asversion 4 of the open source package EDITS avail-able at http://edits.sf.net.AcknowledgmentsThis work has been partially supported by theECfunded project Galateas (CIP-ICT PSP-2009-3-250430).596Run Spanish Italian French Germanrun1 0.34 0.324 0.346 0.349run2 0.342 0.324 0.34 0.349clte2-half-training 0.41 0.43 0.40 0.44clte2-half-test 0.43 0.44 0.41 0.43clte1-test 0.52 0.51 0.54 0.55Table 2: Task 8.
Results obtained.
(Accuracy)ReferencesBaroni M., Bisi S. 2004.
Using cooccurrence statisticsand the web to discover synonyms in technical lan-guage In Proceedings of LREC 2004Bentivogli L., Clark P., Dagan I., Dang H, Giampic-colo D. 2011.
The Seventh PASCAL RecognizingTextual Entailment Challenge In Proceedings of TAC2011Bingham E., Mannila H. 2001.
Random projection indimensionality reduction: Applications to image andtext data.
In Knowledge Discovery and Data Mining,ACM Press pages 245250Bosca A., Dini L. 2008.
Query expansion via libraryclassification system.
In CLEF 2008.
Springer Verlag,LNCSCurtoni P., Dini L. 2006.
Celi participation at clef 2006Cross language delegated search.
In CLEF2006 Work-ing notes.Dagan I. and Glickman O.
2004.
Probabilistic TextualEntailment: Generic Applied Modeling of LanguageVariability.
Learning Methods for Text Understandingand Mining Workshop.Deerwester S., Dumais S.T., Furnas G.W., Landauer T.K.,Harshman R. 1990.
Indexing by latent semantic anal-ysis.
Journal of the American Society for InformationScience 41 391407Giampiccolo; Bernardo Magnini; Ido Dagan; Bill Dolan.2007.
The Third PASCAL Recognizing TextualEntailment Challenge.
Proceedings of the ACL-PASCAL Workshop on Textual Entailment and Para-phrasing.
June 2007, Prague, Czech RepublicHall M., Frank E., Holmes G., Pfahringer B., Reute-mann P., Witten I.
2009 The WEKA Data MiningSoftware: An Update; SIGKDD Explorations, Vol-ume 11, Issue 1.Inkpen D. 2007.
A statistical model for near-synonymchoice.
ACM Trans.
Speech Language Processing4(1)Kouylekov M., Negri M. An Open-Source Package forRecognizing Textual Entailment.
48th Annual Meet-ing of the Association for Computational Linguistics(ACL 2010) ,Uppsala, Sweden.
July 11-16, 2010Kouylekov M., Bosca A., Dini L. 2011.
EDITS 3.0 atRTE-7.
Proceedings of the Seventh Recognizing Tex-tual Entailment Challenge (2011).Kouylekov M., Bosca A., Dini L., Trevisan M. 2012.CELI: An Experiment with Cross Language TextualEntailment.
In Proceedings of the 6th InternationalWorkshop on Semantic Evaluation (SemEval 2012).Kouylekov M., Mehdad Y. and Negri M. 2011 Is it WorthSubmitting this Run?
Assess your RTE System with aGood Sparring Partner Proceedings of the TextInfer2011 Workshop on Textual EntailmentKraaij W. 2003.
Exploring transitive translation meth-ods.
In Vries, A.P.D., ed.
: Proceedings of DIR 2003.Lin J., Gunopulos D. 2003.
Dimensionality reductionby random projection and latent semantic indexing.
Inproceedings of the Text Mining Workshop, at the 3rdSIAM International Conference on Data Mining.Mehdad Y.,Negri M., Federico M.. 2011.
Using Paral-lel Corpora for Cross-lingual Textual Entailment.
InProceedings of ACL-HLT 2011.Negri M., Bentivogli L., Mehdad Y., Giampiccolo D.,Marchetti A.
2011.
Divide and Conquer: Crowd-sourcing the Creation of Cross-Lingual Textual Entail-ment Corpora.
In Proceedings of EMNLP 2011.Negri M., Kouylekov M., 2009 Question Answer-ing over Structured Data: an Entailment-Based Ap-proach to Question Analysis.
RANLP 2009 - Re-cent Advances in Natural Language Processing, 2009Borovets, BulgariaNegri M., Marchetti A., Mehdad Y., Bentivogli L., Gi-ampiccolo D. Semeval-2012 Task 8: Cross-lingualTextual Entailment for Content Synchronization.
InProceedings of the 6th International Workshop on Se-mantic Evaluation (SemEval 2012).
2012.Turney P.D.
2001.
Mining the web for synonyms: Pmi-ir versus lsa on toefl.
In EMCL 01: Proceedings ofthe 12th European Conference on Machine Learning,London, UK, Springer-Verlag pages 491502597
