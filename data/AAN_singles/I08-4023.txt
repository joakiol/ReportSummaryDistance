HMMand CRF Based Hybrid Model for Chinese Lexical Analysis						 !
"huangdg@dlut.edu.cn,suntian@gmail.com,jiaoshidou@gmail.com,computer@dlut.edu.cn,dingzhuoye@sina.com,wanrulove@sina.comAbstractThis paper presents the Chinese lexicalanalysis systems developed by NaturalLanguage Processing Laboratory at DalianUniversity of Technology, which wereevaluated in the 4th International ChineseLanguage Processing Bakeoff.
The HMMand CRF hybrid model, which combinescharacter-based model with word-basedmodel in a directed graph, is adopted insystem developing.
Both the closed andopen tracks regarding to Chinese wordsegmentation, POS tagging and ChineseNamed Entity Recognition are involved inour systems?
evaluation, and good per-formance are achieved.
Especially, in theopen track of Chinese word segmentationon SXU, our system ranks 1st.1 IntroductionChinese presents a significant challenge since it istypically written without separations betweenwords.
Word segmentation has thus long been thefocus of significant research because of its role as anecessary pre-processing phase for the tasks above.Meanwhile, the POS tagging and Chinese NamedEntity Recognition are also the basic steps in Chi-nese lexical analysis.
Several promising methodsare proposed by previous researchers.
In tradition,the Chinese word segmentation technologies canbe categorized into three types, rule-based, ma-chine learning, and hybrid.
Among them, the ma-chine learning-based techniques showed excellentperformance in many research studies (Peng et al,2004; Zhou et al, 2005; Gao et al, 2004).
Thismethod treats the word segmentation problem as asequence of word classification.
The classifieronline assigns either ?boundary?
or ?non-boundary?
label to each word by learning from thelarge annotated corpora.
Machine learning-basedword segmentation method is adopted in the wordsequence inference techniques, such as part-of-speech (POS) tagging, phrases chunking (Wu et al,2006a) and named entity recognition (Wu et al,2006b).
But there are some cost problems in suchmachine learning problems, and sometimes choosebetween word-based and character based is also adilemma.In our system, we present a hybrid model forChinese word segmentation, POS tagging andnamed entity recognition based on HMM and CRFmodel.
The core of the model is a directed segmen-tation graph based on the maximum matching andsecond-maximum matching model.
In the directedgraph, the HMM model and CRF model are com-bined, the HMM model is used to process theknown words (words in system dictionary); CRFmodel is adopted to process the unknown word, thecost problem can be solved.
Meanwhile, for theCRF model, the character-based CRF model andword-based model are integrated under the frame-work of the directed segmentation graph, so theintegrative CRF model can be more flexible to rec-ognize both the simple and complex ChineseNamed Entity with high precision.
With the di-rected segmentation graph, Chinese word segmen-tation, POS tagging and Chinese Named Entityrecognition can be accomplished simultaneously.133Sixth SIGHAN Workshop on Chinese Language Processing2 System DescriptionWith the maximum matching and second-maximum matching (MMSM) model, CRF model,and several post processing strategies, our systemsare established.
First the MMSM model is applied,based on the system dictionary the originaldirected segmentation graph is set up.
The directedgraph is composed by the known words from thesystem dictionary, which are regarded as thecandidate word of the segmentation result.
Thensome candidate Chinese Named EntityRecognition automata search the directed graph,and find out the candidate Chinese Named Entitiesinto the directed graph based on some generationrules.
Then the CRF is applied to the candidateChinese Named Entities to determine if they arereal Chinese Named Entities that should be addedinto the directed graph.
During this procedure, thecharacter-based CRF and word-based CRF arerespectively applied to the simple and complexChinese Named Entities recognition.In the following section, the Chinese word seg-mentation, POS tagging and Chinese named entityrecognition in open track will be mainly discussed.2.1 The maximum matching and second-maximum matching modelThe maximum matching and second-maximummatching(MMSM) model, which is a segmentationmethod that keeps the maximum and second-maximum segmentation result from a certain posi-tion in a sentence, and store the candidate segmen-tation results in a directed graph, then some decod-ing algorithm is adopted to find the best path in thedirected graph.
With the MMSM model, almost allthe possible segmentation paths and most lexicalinformation can be reserved for further use; littlespace cost is guaranteed by using the directedgraph to store the segmentation paths; the contextspaces are extended from single-dimension tomulti-dimension.2.2 Conditional Random FieldsConditional random field (CRF) was an extensionof both Maximum Entropy Model (MEMs) andHidden Markov Models (HMMs) that was firstlyintroduced by (Lafferty et al, 2001).
CRF definedconditional probability distribution P(Y|X) of givensequence given input sentence where Y is the?class label?
sequence and X denotes as theobservation word sequence.A CRF on (X,Y) is specified by a feature vector Fof local context and the corresponding featureweight ?.
The F can be treated as the combinationof state transition and observation value inconventional HMM.
To determine the optimallabel sequence, the CRF uses the followingequation to estimate the most probability.Conditional random fields (CRFs) are undirectedgraphical models trained to maximize a conditionalprobability (Lafferty et al, 2001).
A linear-chainCRF with parameters },,{ 21 L??=?
defines aconditional probability for a state sequenceTyyy K1= , given that and input sequenceTxxx K1= is?????
?= ??=?
?Tt kttkkxtxyyfZxyP11 ),,,(exp1)|( ?Where xZ is the normalization factor that makesthe probability of all state sequences sum to one;),,,( 1 txyyf ttk ?
is ofen a binary-valued featurefunction and k?
is its weight.
The featurefunctions can measure any aspect of a statetransition, tt yy ?
?1 , and the entire observationsequence, x, centered at the current time step, t.For example, one feature function might have thevalue 1 when yt-1 is the state B, yt is the state I, andxt is some Chinese character.2.3 Chinese Named Entity RecognitionFirst, we will introduce our Chinese Named EntityRecognition part for the Open track.
Several NERautomata are adopted to find out all the candidateNEs in the directed graph, then the CRF model isapplied to filter the candidate NEs to check if thespecified NE should be added into the graph.
Touse the CRF, first, we generate some lists from thetraining corpus.PSur: the surname of Person Name.PC: the frequency information of a character inPerson NamePPre: the prefix of Person NamePSuf: the suffix of Person NameLF: the frequency information of a character inLocal NameLC: the centre character of Local NameLPre: the prefix of Local Name134Sixth SIGHAN Workshop on Chinese Language ProcessingLSuf:the suffix of Local NameOF: the frequency information of a character inORG NameOC: the centre character of ORG NameOPre: the prefix of ORG NameOSuf: the suffix of ORG NameWe define the template as follows:PER: PSur(n)PC(n) PPre(n)PSuf(n), (n = -2, -1,0, +1, +2)LOC: LF(n)LC(n)LPre(n)LSuf(n), (n = -2, -1, 0,+1, +2)ORG: OF(n)OC(n)OPre(n)OSuf(n), (n = -2, -1,0, +1, +2)With the CRF we filter the candidate NEs.
Thecandidate NEs are filtered and added into the di-rected segmentation graph as new nodes with newedges.
The NEs includes personal name(PRE), lo-cation name(LOC) and organization name(ORG).The ?PER?,?LOC?
in open track is the same asin the close track except some external resources.The external resources include external lexicon,name list for word segmentation, and generatingthe features.In the ?ORG?
part, a different method is pro-posed.
We adopt an automatic recognition methodof Chinese organization name with the combina-tion of SVM and Maximum Entropy.
SVM modelis used to decide the latter boundary of a organiza-tion name, and then Maximum Entropy is used toconfirm the former boundary.First, a characteristic dictionary is collectedfrom the training corpus.
As for the words ap-peared in the characteristic dictionary, whether it isthe characteristic word of an organization nameshould be decided.
As a problem of two value cate-gorization, SVM is applied to complete this task.
Ifit is considered to be a characteristic word, then theformer boundary of an organization name is de-tected.
Maximum Entropy can combine differentkinds of text information, and solve the problem ofthe recognition of the more complex former wordsof the Chinese organization name, so the Maxi-mum Entropy is adopted to confirm the formerboundary of ORG.
During the NEs recognition andfiltering the word and POS tag as main featuresand adopt a context window of five words.Because of the complex construction of the Chi-nese Named Entity, one single statistical model cannot solve simple and complex NER simultaneously,such as the character-based CRF model makeslower recognition accuracy for complex NERs,meanwhile, the word-based CRF model will losemany useful features in processing simple NERs.Integrating the character-based and word-basedCRF model into one framework is the key to solveall the NERs simultaneously.In this paper, an integrative model based onCRF is proposed.
With the preliminary results ofthe segmentation and POS tagging, at the bottomof the system, character-based CRF is applied torecognized simple PERs, LOCs, and ORGs; Therecognition result will be transformed to the top ofthe system together with the segmentation andPOS tagging result.
At the top of system, word-based CRF is used to recognize the nested LOCsand ORGs.
The character-based model and wordbased model are integrated into one framework torecognition the NEs with different complexionssimultaneously.
The identification results of thebottom-level provide decision support for the high-level, the limitations of the separated character-based model and word-based model are avoided,and improves recognition accuracy of the system.2.4 Result from the directed graphAfter the recognition and filtering of the ChineseNamed Entity, the original segmentation directedgraph is now with the candidate Chinese NamedEntity nodes.
Some decoding algorithm is neededto find final path from the directed graph.
Here, werevised the Dijkstra minimum cost path algorithmto find out the minimum cost path from the di-rected graph.
The calculation of the cost of thenodes and edges in the directed graph can be foundin our related work(Degen Huang and Xiao Sun,2007).
The final path from the directed graph is theresult for the Chinese word segmentation, POStagging and Chinese Named Entity recognition.3 Evaluations and Experimental Results3.1 Result of Chinese word segmentationWe evaluated our Chinese word segmentationmodel in the open track on all the simple Chinesecorpus, such as University of Colorado, UnitedStates (CTB, 642246 tokens), State LanguageCommission of P.R.C.,Beijing(NCC, 917255 to-kens) and Shanxi University, Taiyuan (SXU528238 tokens).
The OOV-rate is 0.0555, 0.0474and 0.0512.135Sixth SIGHAN Workshop on Chinese Language ProcessingTheCTB open track is shown in the followingtable 1.
We get the third position in the CTB trackby the F result.Table 1.
CTB open track resultCTB R P FBase 0.8864 0.8427 0.8640Top 0.9710 0.9825 0.9767Our 0.9766 0.9721 0.9743IV-R IV-P IV-FBase 0.9369 0.8579 0.8956Top 0.9698 0.9832 0.9764Our 0.9805 0.9794 0.9800OOV-R OOV-P OOV-FBase 0.9920 0.9707 0.9812Top 0.0273 0.1858 0.0476Our 0.9089 0.8553 0.8813The NCC open track is shown in the followingtable 2.
In the NCC open track, we get the thirdposition track by the F result.Table 2.
NCC open track resultNCC R P FBase 0.9200 0.8716 0.8951Top 0.9735 0.9817 0.9776Our 0.9620 0.9496 0.9557IV-R IV-P IV-FBase 0.9644 0.8761 0.9181Top 0.9725 0.9850 0.9787Our 0.9783 0.9569 0.9675OOV-R OOV-P OOV-FBase 0.0273 0.1858 0.0476Top 0.9933 0.9203 0.9554Our 0.7109 0.7619 0.7355The SXU open track is shown in the followingtable 3.
In the SXU open track, we get the first twopositions by the F result.Table 3.
NCC open track resultNCC R P FBase 0.9238 0.8679 0.8949Top 0.9820 0.9867 0.9844Our 0.9768 0.9703 0.9735IV-R IV-P IV-FBase 0.9723 0.8789 0.9232Top 0.9813 0.9890 0.9851Our 0.9872 0.9767 0.9820OOV-R OOV-P OOV-FBase 0.0251 0.0867 0.0389Top 0.9942 0.9480 0.9705Our 0.7825 0.8415 0.8109We also participate in the close track in CTB,NCC and SXU corpus.
The result is shown in thefollowing table 4.Table 4.
Segmentation Result in close trackR P F Foov FivCTB 0.9505 0.9528 0.9517 0.7216 0.9659NCC 0.9387 0.9301 0.9344 0.5643 0.9524SXU 0.9594 0.9493 0.9543 0.6676 0.96973.2 Result of Chinese NERWe evaluated our named entity recognizer onthe SIGHAN Microsoft Research Asia(MSRA)corpus in both closed and open track.Table 5.
NER in MSRA closed track:Close R P FPER 90.29% 95.19% 92.68%LOC 81.85% 92.78% 86.97%ORG 70.16% 84.05% 76.48%Overall 80.58% 91.07% 85.5%Table 6.
NER in MSRA open track:Open R P FPER 92.06% 95.17% 93.59%LOC 83.62% 94.24% 88.62%ORG 74.04% 79.66% 75.65%Overall 82.38% 90.38% 86.19%3.3 Result of POS taggingThe POS tagging result of our system is shown inthe following table 7.Table 7.
POS tagging in close trackClose Total-A IV-R OOV-R MT-RCTB 0.9088 0.9374 0.4866 0.8805NCC 0.9313 0.9604 0.4080 0.8809PKU 0.9053 0.9451 0.2751 0.8758136Sixth SIGHAN Workshop on Chinese Language ProcessingTable8.
POS tagging in open trackOpen Total-A IV-R OOV-R MT-RCTB 91.2% 93.74% 53.61% 88.05%NCC 93.26% 96.04% 43.36% 88.09%PKU 93.29% 95.18% 63.32% 89.72%4 Conclusions and Future WorkIn this paper, the hybrid model in our system isdescribed, An integrative lexical analysis system isimplemented, which completes all the steps of thelexical analysis synchronously, by integrating thesegmentation, ambiguous resolution, POS tagging,unknown words recognition into one theoryframework.
The integrative mechanism reduces theconflicts between the steps of the lexical analysis.The experimental results demonstrate that, the in-tegrative model and its algorithm is effective.
Thesystem used the automata recognition and CRF-based hybrid model to process the Chinese NamedEntity.
The Chinese word segmentation, POS tag-ging and Chinese Named Entity recognition areintegrated; the character-based CRF and word-based CRF are integrated, the HMM, CRF andother statistic model are integrated under the samesegmentation framework.
With this model we par-ticipated in the ?The Fourth SIGHAN Bakeoff?and got good performance.ReferencesDegen, Huang and Xiao An Integrative Approach toChinese NamedEntity Recognition, In Proceedings ofthe 6th International Conference on Advanced Lan-guage Processing and Web Information Technology.Gao, J., Wu, A., Li, M., Huang, C. N., Li, H., Xia, X.,and Qin, H. 2004.
Adaptive Chinese word segmenta-tion.
In Proceedings the 41st Annual Meeting of theAssociation for Computational Linguistics, pp.
21-26.Lafferty, J., McCallum, A., and Pereira, F. 2001.
Condi-tional Random Field: Probabilistic models for seg-menting and labeling sequence data.
In Proceedingsof the International Conference on Machine Learn-ing.Lance A. Ramshaw and Mitchell P. Marcus.
1995.
Textchunking using transformation-based learning.
InProceedings of the 3rd Workshop on Very LargeCorpora, pages 82-94.
Nocedal, J., and Wright, S.1999.
Numerical optimization.
Springer.Peng, F., Feng, F., and McCallum, A.
2004.
Chinesesegmentation and new word detection using condi-tional random fields.
In Porceedings of the Computa-tional Linguistics, pp.
562-568.Shi, W. 2005.
Chinese Word Segmentation Based OnDirect Maximum Entropy Model.
In Proceedings ofthe Fourth SIGHAN Workshop on Chinese LanguageProcessing.Wu, Y. C., Chang, C. H. and Lee, Y. S. 2006a.
A gen-eral and multi-lingual phrase chunking model basedon masking method.
Lecture Notes in Computer Sci-ence (LNCS): Computational Linguistics and Intelli-gent Text Processing, 3878: 144-155.Wu, Y. C., Fan, T. K., Lee Y. S. and Yen, S. J.
2006b.Extracting named entities using support vector ma-chines," Lecture Notes in Bioinformatics (LNBI):Knowledge Discovery in Life Science Literature,(3886): 91-103.Wu, Y. C., Lee, Y. S., and Yang, J. C. 2006c.
The Ex-ploration of Deterministic and Efficient DependencyParsing.
In Proceedings of the 10th Conference onNatural Language Learning (CoNLL).137Sixth SIGHAN Workshop on Chinese Language Processing
