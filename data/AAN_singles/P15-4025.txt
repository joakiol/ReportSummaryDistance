Proceedings of ACL-IJCNLP 2015 System Demonstrations, pages 145?150,Beijing, China, July 26-31, 2015.c?2015 ACL and AFNLPNiuParser: A Chinese Syntactic and Semantic Parsing ToolkitJingbo Zhu Muhua Zhu?Qiang Wang Tong XiaoNatural Language Processing Lab.Northeastern Universityzhujingbo@mail.neu.edu.cn zhumuhua@gmail.comwangqiangneu@gmail.com xiaotong@mail.neu.edu.cnAbstractWe present a new toolkit - NiuParser -for Chinese syntactic and semantic anal-ysis.
It can handle a wide range of NaturalLanguage Processing (NLP) tasks in Chi-nese, including word segmentation, part-of-speech tagging, named entity recogni-tion, chunking, constituent parsing, depen-dency parsing, and semantic role label-ing.
The NiuParser system runs fast andshows state-of-the-art performance on sev-eral benchmarks.
Moreover, it is very easyto use for both research and industrial pur-poses.
Advanced features include the Soft-ware Development Kit (SDK) interfacesand a multi-thread implementation for sys-tem speed-up.1 IntroductionChinese has been one of the most popular worldlanguages for years.
Due to its complexity anddiverse underlying structures, processing this lan-guage is a challenging issue and has been clearlyan important part of Natural Language Processing(NLP).
Many tasks are proposed to analyze andunderstand Chinese, ranging from word segmen-tation to syntactic and/or semantic parsing, whichcan benefit a wide range of natural language ap-plications.
To date, several systems have beendeveloped for Chinese word segmentation, part-of-speech tagging and syntactic parsing (exam-ples include Stanford CoreNLP1, FudanNLP2, LT-P3and etc.)
though some of them are not opti-mized for Chinese.
?This work was done during his Ph.D. study in North-eastern University.1http://nlp.stanford.edu/software/corenlp.shtml2http://fudannlp.googlecode.com3http://www.ltp-cloud.com/intro/en/In this paper we present a new toolkit forChinese syntactic and semantic analysis (cal-l it NiuParser4).
Unlike previous systems, theNiuParser toolkit can handle most of Chineseparsing-related tasks, including word segmenta-tion, part-of-speech tagging, named entity recog-nition, chunking, constituent parsing, dependencyparsing, and semantic role labeling.
To the bestof our knowledge we are the first to report that allseven of these functions are supported in a singleNLP package.All subsystems in NiuParser are based on sta-tistical models and are learned automatically fromdata.
Also, we optimize these systems for Chinesein several ways, including handcrafted rules usedin pre/post-processing, heuristics used in variousalgorithms, and a number of tuned features.
Thesystems are implemented with C++ and run fast.On several benchmarks, we demonstrate state-of-the-art performance in both accuracy/F1 score andspeed.In addition, NiuParser can be fit into large-scaletasks which are common in both research-orientedexperiments and industrial applications.
Severaluseful utilities are distributed with NiuParser, suchas the Software Development Kit (SDK) inter-faces and a multi-thread implementation for sys-tem speed-up.The rest of the demonstration is organized asfollows.
Section 2 describes the implementationdetails of each subsystem, including statistical ap-proaches and some enhancements with handcraft-ed rules and dictionaries.
Section 3 represents theways to use the toolkit.
We also show the perfor-mance of the system in Section 4 and finally weconclude the demonstration and point out the fu-ture work of NiuParser in Section 5.4http://www.niuparser.com/index.en.html145WordSegmentationPOSTaggingConstituentParsingNamed EntityRecognitionDependencyParsingChunkingSemantic RoleLabelingNiuParser SubsystemsConditionalRandom FieldsAveragedPerceptronMaximumEntropyRecurrentNeural NetworksMachine Learning ModelsFigure 1: The system architecture of NiuParser.2 The NiuParser System2.1 What is NiuParserThe NiuParser system is a sentence-level syntacticand semantic parsing toolkit developed by Natu-ral Language Processing Laboratory in Northeast-ern University of China.
The system is designedspecifically to process the Chinese language.
Sub-systems of NiuParser include word segmentation,POS tagging, named entity recognition, shallowsyntactic parsing (chunking), constituent parsing,dependency parsing, and constituent parse-basedsemantic role labeling.
Figure 1 shows the archi-tecture of the NiuParser system.
As we can seefrom the figure, subsystems in NiuParser are orga-nized in a pipeline structure.
A given sentence isfirst segmented into a word sequence, each wordin which is assigned a POS tag by the POS tag-ging subsystem.
Based on the POS tagging result,we can choose to do named entity recognition orsyntactic parsing.
Finally, shallow semantic struc-tures are generated by semantic role labeling onthe base of constituent parsing.2.2 Statistical Approaches to Subsystems2.2.1 Sequence LabelingThe subsystems of word segmentation, POS tag-ging, named entity recognition, and chunking inNiuParser are based on statistical sequence label-ing models.
Specifically, we adopt linear-chainConditional Random Fields (CRF) (Lafferty et al.,2001) as the method for sequence labeling.
Givenan input sample X = x1, x2, .
.
.
, xLand its cor-responding sequence Y = y1, y2, .
.
.
, yL, Condi-tional Random Fields are defined as follows.Pw(Y |X) =1Zw(X)exp(WT?
(X,Y ))) (1)where Zw(X) denotes the normalization constantand ?
(X,Y ) are manually defined feature func-tions.
In the testing phase, the Viterbi algorithmis applied to find an optimal label sequence or ak-best list for a testing instance.With Conditional Random Fields, Chineseword segmentation is regarded as a character-based sequence labeling problem.
We adopt thescheme of six tags (B, B2, B3, I, E, O) to translate146between a segmented sentence and its correspond-ing label sequence (Zhao et al., 2005).
Specifical-ly, B, B2, B3 denotes the first, the second, and thethird character in a word, respectively.
I meansthat the character is inside in a word, and E meansthat the character is at the end of a word.
Finally,O denotes a single-character word.
Features in-clude the characters (and their combinations) in asliding window.As mentioned above, the NiuParser system uti-lizes the pipeline method to integrate all the sub-systems.
That is, POS tagging, named enti-ty recognition, and chunking take the output ofthe preceding subsystem as input.
For POS tag-ging, we obtain training data from Penn ChineseTreebank (CTB) (Xue et al., 2005), which has 32POS tags.
The named entity recognition subsys-tem takes the guideline of OntoNotes (Pradhan etal., 2007).
Named entities annotated in OntoNoteshave 18 entity types in total, including personnames, organization names, and events, etc.
Ta-ble 1 presents a complete list of the entity types inOntoNotes.
Chunking uses training data derivedfrom constituent parse trees in CTB.
In NiuParser,we consider phrase types including noun phrase(NP), verbal phrase (VP), quantifier phrase (QP),prepositional phrase (PP), adjective phrase (AD-JP), and classifier phrase (CLP), etc.
Features forthe three subsystems are words (and their combi-nations) in a sliding window.
Prefix and suffix ofwords are also used as features for better systemgeneralization.2.2.2 Transition-based ParsingSyntactic parsers can be grouped into two cate-gories according to decoding algorithms: dynam-ic programming-based and transition-based.
Forthe purpose of efficiency, we implement the con-stituent and two versions of dependency parsers inthe NiuParser system with transition-based meth-ods (Zhu et al., 2013; Zhang and Nivre, 2011;Chen and Manning, 2014).
Specifically, parser-s are variants of shift-reduce parsers, which startfrom an initial state and reach a final state by per-forming an action in each stage transition.
Fig-ure 2 and Figure 3 present an example parse of thetwo parsers, respectively.One version of the dependency parsers followsthe work in (Chen and Manning, 2014), regardingthe state transition process as a sequence of clas-sification decisions.
In each transition, a best ac-tion is chosen by a Neural Network classifier.
Theother parses (the constituent parser and the otherversion of dependency parser) utilize exactly thesame framework, where both training and decod-ing phases are formalized as a beam search pro-cess.
In the decoding phase, the candidate parsewith the highest score in the beam will be pickedas the parsing result once the beam search processterminates.
In the training phase, a beam search-based global online training method is adopted.The training process iterates through the wholetraining data by decoding the sentences sequent-ly.
On each sentence, parameters will be updatedimmediately once the gold parse is pruned off thebeam.
In the NiuParser system, we utilize aver-aged perceptron to learn parameters.2.2.3 Two-Stage ClassificationResearchers in semantic role labeling have ex-plored diverse syntactic structures (chunks, con-stituent parses, and dependency parses) as input.The semantic role labeling subsystem in NiuPars-er considers constituent parse trees as input.
Thesubsystem can recognize constituents in a parsetree as arguments with respect to a specified pred-icate (See Figure 4).
Here, semantic role labelingis formalized as a two-stage classification prob-lem.
The first stage (called identification) conduct-s a binary classification to decide whether a con-stituent in a parse tree is an argument.
After thefirst stage, a set of constituents is fed to the sec-ond stage (called classification) classifier which isa multi-class classifier, used for assigning each ar-gument an appropriate semantic label.The statistical model used in the semantic rolelabeling subsystem is Maximum Entropy (Berg-er et al., 1996), which provides classification de-cisions with corresponding probabilities.
Withsuch probabilities, the identification stage appliesthe algorithm of enforcing non-overlapping argu-ments (Jiang and Ng, 2006) to maximize the log-probability of the entire labeled parse tree.
In theclassification stage, the classifier assigns labels toarguments independently.2.3 Improvements and Advanced Features2.3.1 Word SegmentationIn Chinese sentences, words like dates, emailaddresses, and web page URLs are pervasive buttraining data for statistical methods is limitedin size to cover enough such words.
A purelystatistical approach often fails to recognize suchwords once the words do not appear in the training147PERSON peopel, including fictional NORP nationalities or religious or political groupsFACILITY building, airports, highways, etc.
ORGANIZATION companies, agencies, etc.GPE countries, cities, states LOCATION non-GPE, mountain ranges, bodies of waterPRODUCT vehicles, weapons, foods, etc.
EVENT named hurricanes, battles, wars, sports eventsWORD OF ART titles or books, songs, etc.
LAW named documents made into lawsLANGUAGE named language DATE absolute or relative dates or periodsTIME times smaller than a day PERCENT percentage *including ?%?MONEY monetary values, including unit QUANTITY measurements, as of weight or distancesORDINAL ?first?, ?second?
CARDINAL numerals that do not fall under another typeTable 1: Named entity types in OntoNotesIPVPVPVV??PPNPNR??P?NPNPNN???NN??NN??QPCLPM?OD?
?Figure 2: Example of constituent parsing in NiuParser.data.
Fortunately, such words generally have someregular patterns and can be recognized by regularexpressions.
The NiuParser system provides aregular expression engine to do preprocessing forthe CRF-based segmenter.Post-processing: Besides the word typeshandled in the preprocessing step, a CRF-basedsegmenter has a low accuracy in recogniz-ing out-of-vocabulary words.
The NiuParsersystem implements a double-array trie for post-processing.
Users can add entries (each entryis a string of characters and its correspondingsegments) into a dictionary.
String of charactersin the dictionary will be assured to be segmentedaccording to its corresponding segments.2.3.2 Named Entity RecognitionIn academics, named entity recognition often suf-fers from limited training data.
In contrast, practi-tioners generally seek to mine a large-vocabularyentity dictionary from the Web, and then use theentity dictionary to recognize entities as a maxi-mum matching problem.
This approach, howev-er, fails to resolve ambiguities.
The improvementhere is to combine dictionary-based methods andstatistical methods.We first use the forward maximum matching ap-proach to recognize entities in an input sentenceby using an entity dictionary.
The recognition re-sult is then sent to a CRF-based recognizer.
Hereeach word is assigned a label (start of an entity, in-side an entity, or end of an entity) according to themaximum matching result.
The labels are used asadditional features in the CRF-based recognizer.This approach is similar to the stacking method.2.3.3 System Speed-upIn addition to fast algorithms (e.g., shift-reduceparsing), NiuParser also supports a multithread-ing mode to make full advantage of computerswith more than one CPU or core.
In general, thespeed can be improved when multiple threads areinvolved.
However, it does not run faster when toomany threads are used (e.g., run with more than 8threads) due to the increased cost of scheduling.2.4 UsageThe NiuParser system supports three ways to usethe functionalities in the toolkit.First, users can use the toolkit as an executablefile in the command lines.
Model files and config-uration of the system are specified in a configura-tion file.
Input-output files and the functionality to148??
?
??
??
???
?
??
?
?OD M NN NN NN P NR VVROOTMNMODNMODNMODSBJVMODPOBJFigure 3: Example of dependency parsing in NiuParser.IPVPVPVV??PP???NP?????????
?Figure 4: Example of semantic role labeling in NiuParser.be used are specified as command line arguments.Second, all the functionalities in NiuParser canbe integrated into users?
own applications or busi-ness process by using the toolkit?s SDK interfaces.The SDK supports both Windows and Linux plat-forms.
In contrast to web services, SDK is moresuitable to be deployed in the server side.Third, a demo web page is provided for usersto view the analysis results intuitively.5All theanalysis results are presented graphically.3 ExperimentsWe ran our system on several benchmarks.
Specif-ically, we trained and tested word segmentation,POS tagging, chunking, and constituent parsing onCTB5.1: articles 001-270 and 440-1151 were usedfor training and articles 271-300 were used fortesting.
The performance of named entity recog-nition was reported on OntoNotes, where 49,011sentences were used for training and 1,340 sen-tences were used for testing.
For semantic rolelabeling, we adopted the same data set and split-ting as in (Xue, 2008).
Finally, the data set andsplitting in (Zhang and Clark, 2011) were used toevaluate the performance of dependency parsing.All results were reported on a machine with a5http://demo.niuparser.com/index.en.html800MHz CPU and 4GB memory.
See Table 2 forresults of acurracy/F1 scores, memory use, mod-el sizes and speed.
Note that we evaluated thespeed with a single thread and the accuracies wereachieved with statistical models only.From the results we can see that most of the sub-systems achieve state-of-the-art performance, (thechunking subsystem is an exception, whose accu-racy still have some room left for further improve-ments.).
In addition, the memory use of dependen-cy parsing is extremely heavy.
We will optimizethe implementation of dependency parsing in ourfuture work.4 Conclusions and Future WorkWe have presented the NiuParser Chinese syntac-tic and semantic analysis toolkit.
It can handleseveral parsing tasks for Chinese, including wordsegmentation, part-of-speech tagging, named enti-ty recognition, chunking, constituent parsing, de-pendency parsing, and constituent parser-based se-mantic role labeling.
The NiuParser system is fastand shows state-of-the-art performance on sever-al benchmarks.
Moreover, it supports several ad-vanced features, such as the Software Develop-ment Kit (SDK) interfaces and the multi-threadimplementation for system speed-up.In our future work, we will add more function-149Task Acurrary/F1 Memory Used Model Size Speed?word segmentation 97.3% 68M 57M 45KPOS tagging 93.5% 93M 185M 38.8Knamed entity recognition 88.1% 687M 708M 1.87Kchunking 81.1% 71.9MG 90M 18.8Kconstituent parsing 83.2% 0.98G 243M 583.3dependency parsing?82.4% 2.9G 116M 402.4dependency parsing?82.1% 597M 22M 13.5Ksemantic role labeling 68.4% 1.2M/0.9M 30M 494?Table 2: Evaluation of NiuParser on various tasks.
?beam search-based global training method.
?classification-based method with Neural Networks.
?characters per second.
?predicates per second.alities to NiuParser.
First of all, we will integrate anew subsystem which conducts dependency-basedsemantic role labeling.
In addition, we will de-velop a faster constituent parsers by using Recur-rent Neural Network.
According to the previouswork (Chen and Manning, 2014) (and its clonein the NiuParser system), this method reduces thecost of feature extraction and thus shows the ad-vantage in speed.
We expect the same approachcan be adapted to constituent parsing.AcknowledgesThis work was supported in part by the NationalScience Foundation of China (Grants 61272376,61300097, and 61432013).ReferencesAdam L. Berger, Stephen A. Della Pietra, and VincentJ.
Dealla Pietra.
1996.
A maximum entropy ap-proach to natural language processing.
Computa-tional Linguics, 22:39?71.Danqi Chen and Christopher D. Manning.
2014.
A fastand accurate dependency parser using neural net-works.
Proc.
of EMNLP 2014, pages 740?750.Zheng Ping Jiang and Hwee Tou Ng.
2006.
Seman-tic role labeling of nombank: a maximum entropyapproach.
Proc.
of EMNLP 2006, pages 138?145.John D. Lafferty, Andrew McCallum, and FernandoC.
N. Pereira.
2001.
Conditional random fields:Probabilistic models for segmenting and labeling se-quence data.
Proc.
of ICML 2001.Sameer S. Pradhan, Hovy Eduard, Mitch Mar-cus, Martha Palmer, Lance Ramshaw, and RalphWeischedel.
2007.
Ontonotes: A unified relation-al semantic representation.
Proc.
of ICSC 2007.Nianwen Xue, Fei Xia, Chiou Fu-Dong, and PalmerMartha.
2005.
The penn chinese treebank: Phrasestructure annotation of a large corpus.
Natural Lan-guage Engineering, 11:207?238.Nianwen Xue.
2008.
Labeling chinese predicates withsemantic roles.
Computational Linguistics, 32:225?255.Yue Zhang and Stephen Clark.
2011.
Syntactic pro-cessing using the generalized perceptron and beamsearch.
Computational Linguistics, 37:105?151.Yue Zhang and Joakim Nivre.
2011.
Transition-based dependency parsing with rich non-local fea-tures.
Proc.
of ACL 2011, pages 188?193.Hai.
Zhao, Chang-Ning Huang, and Mu Li.
2005.
Animproved chinese word segmentation system withconditional randome fileds.
Proc.
of SIGHAN 2006,pages 162?165.Muhua Zhu, Yue Zhang, Wenliang Chen, Min Zhang,and Jingbo Zhu.
2013.
A fast and accurate con-stituent parsing.
Proc.
of ACL 2013.150
