Proceedings of the 12th Conference of the European Chapter of the ACL, pages 585?593,Athens, Greece, 30 March ?
3 April 2009. c?2009 Association for Computational LinguisticsDiscovering Global Patterns in Linguistic Networks throughSpectral Analysis: A Case Study of the Consonant InventoriesAnimesh Mukherjee?Indian Institute of Technology, Kharagpuranimeshm@cse.iitkgp.ernet.inMonojit Choudhury and Ravi KannanMicrosoft Research India{monojitc,kannan}@microsoft.comAbstractRecent research has shown that languageand the socio-cognitive phenomena asso-ciated with it can be aptly modeled andvisualized through networks of linguisticentities.
However, most of the existingworks on linguistic networks focus onlyon the local properties of the networks.This study is an attempt to analyze thestructure of languages via a purely struc-tural technique, namely spectral analysis,which is ideally suited for discovering theglobal correlations in a network.
Appli-cation of this technique to PhoNet, theco-occurrence network of consonants, notonly reveals several natural linguistic prin-ciples governing the structure of the con-sonant inventories, but is also able to quan-tify their relative importance.
We believethat this powerful technique can be suc-cessfully applied, in general, to study thestructure of natural languages.1 IntroductionLanguage and the associated socio-cognitive phe-nomena can be modeled as networks, where thenodes correspond to linguistic entities and theedges denote the pairwise interaction or relation-ship between these entities.
The study of lin-guistic networks has been quite popular in the re-cent times and has provided us with several in-teresting insights into the nature of language (seeChoudhury and Mukherjee (to appear) for an ex-tensive survey).
Examples include study of theWordNet (Sigman and Cecchi, 2002), syntacticdependency network of words (Ferrer-i-Cancho,2005) and network of co-occurrence of conso-nants in sound inventories (Mukherjee et al, 2008;Mukherjee et al, 2007).
?This research has been conducted during the author?s in-ternship at Microsoft Research India.Most of the existing studies on linguistic net-works, however, focus only on the local structuralproperties such as the degree and clustering coef-ficient of the nodes, and shortest paths betweenpairs of nodes.
On the other hand, although it isa well known fact that the spectrum of a networkcan provide important information about its globalstructure, the use of this powerful mathematicalmachinery to infer global patterns in linguistic net-works is rarely found in the literature.
Note thatspectral analysis, however, has been successfullyemployed in the domains of biological and socialnetworks (Farkas et al, 2001; Gkantsidis et al,2003; Banerjee and Jost, 2007).
In the context oflinguistic networks, (Belkin and Goldsmith, 2002)is the only work we are aware of that analyzes theeigenvectors to obtain a two dimensional visualizeof the network.
Nevertheless, the work does notstudy the spectrum of the graph.The aim of the present work is to demonstratethe use of spectral analysis for discovering theglobal patterns in linguistic networks.
These pat-terns, in turn, are then interpreted in the light of ex-isting linguistic theories to gather deeper insightsinto the nature of the underlying linguistic phe-nomena.
We apply this rather generic techniqueto find the principles that are responsible for shap-ing the consonant inventories, which is a well re-searched problem in phonology since 1931 (Tru-betzkoy, 1931; Lindblom and Maddieson, 1988;Boersma, 1998; Clements, 2008).
The analysisis carried out on a network defined in (Mukherjeeet al, 2007), where the consonants are the nodesand there is an edge between two nodes u and vif the consonants corresponding to them co-occurin a language.
The number of times they co-occuracross languages define the weight of the edge.
Weexplain the results obtained from the spectral anal-ysis of the network post-facto using three linguis-tic principles.
The method also automatically re-veals the quantitative importance of each of these585principles.It is worth mentioning here that earlier re-searchers have also noted the importance of theaforementioned principles.
However, what wasnot known was how much importance one shouldassociate with each of these principles.
We alsonote that the technique of spectral analysis neitherexplicitly nor implicitly assumes that these princi-ples exist or are important, but deduces them auto-matically.
Thus, we believe that spectral analysisis a promising approach that is well suited to thediscovery of linguistic principles underlying a setof observations represented as a network of enti-ties.
The fact that the principles ?discovered?
inthis study are already well established results addsto the credibility of the method.
Spectral analysisof large linguistic networks in the future can possi-bly reveal hitherto unknown universal principles.The rest of the paper is organized as follows.Sec.
2 introduces the technique of spectral anal-ysis of networks and illustrates some of its ap-plications.
The problem of consonant inventoriesand how it can be modeled and studied within theframework of linguistic networks are described inSec.
3.
Sec.
4 presents the spectral analysis ofthe consonant co-occurrence network, the obser-vations and interpretations.
Sec.
5 concludes bysummarizing the work and the contributions andlisting out future research directions.2 A Primer to Spectral AnalysisSpectral analysis1 is a powerful tool capable ofrevealing the global structural patterns underly-ing an enormous and complicated environmentof interacting entities.
Essentially, it refers tothe systematic study of the eigenvalues and theeigenvectors of the adjacency matrix of the net-work of these interacting entities.
Here we shallbriefly review the basic concepts involved in spec-tral analysis and describe some of its applications(see (Chung, 1994; Kannan and Vempala, 2008)for details).A network or a graph consisting of n nodes (la-beled as 1 through n) can be represented by a n?nsquare matrix A, where the entry aij represents theweight of the edge from node i to node j.
A, whichis known as the adjacency matrix, is symmetric foran undirected graph and have binary entries for an1The term spectral analysis is also used in the context ofsignal processing, where it refers to the study of the frequencyspectrum of a signal.unweighted graph.
?
is an eigenvalue of A if thereis an n-dimensional vector x such thatAx = ?xAny real symmetric matrix A has n (possibly non-distinct) eigenvalues ?0 ?
?1 ?
.
.
.
?
?n?1, andcorresponding n eigenvectors that are mutually or-thogonal.
The spectrum of a graph is the set of thedistinct eigenvalues of the graph and their corre-sponding multiplicities.
It is usually representedas a plot with the eigenvalues in x-axis and theirmultiplicities plotted in the y-axis.The spectrum of real and random graphs dis-play several interesting properties.
Banerjee andJost (2007) report the spectrum of several biologi-cal networks that are significantly different fromthe spectrum of artificially generated graphs2.Spectral analysis is also closely related to Prin-cipal Component Analysis and MultidimensionalScaling.
If the first few (say d) eigenvalues of amatrix are much higher than the rest of the eigen-values, then it can be concluded that the rows ofthe matrix can be approximately represented aslinear combinations of d orthogonal vectors.
Thisfurther implies that the corresponding graph hasa few motifs (subgraphs) that are repeated a largenumber of time to obtain the global structure ofthe graph (Banerjee and Jost, to appear).Spectral properties are representative of an n-dimensional average behavior of the underlyingsystem, thereby providing considerable insightinto its global organization.
For example, the prin-cipal eigenvector (i.e., the eigenvector correspond-ing to the largest eigenvalue) is the direction inwhich the sum of the square of the projectionsof the row vectors of the matrix is maximum.
Infact, the principal eigenvector of a graph is used tocompute the centrality of the nodes, which is alsoknown as PageRank in the context of WWW.
Sim-ilarly, the second eigen vector component is usedfor graph clustering.In the next two sections we describe how spec-tral analysis can be applied to discover the orga-nizing principles underneath the structure of con-sonant inventories.2Banerjee and Jost (2007) report the spectrum of thegraph?s Laplacian matrix rather than the adjacency matrix.It is increasingly popular these days to analyze the spectralproperties of the graph?s Laplacian matrix.
However, for rea-sons explained later, here we will be conduct spectral analysisof the adjacency matrix rather than its Laplacian.586Figure 1: Illustration of the nodes and edges of PlaNet and PhoNet alng with their respective adjacencymatrix representations.3 Consonant Co-occurrence NetworkThe most basic unit of human languages are thespeech sounds.
The repertoire of sounds that makeup the sound inventory of a language are not cho-sen arbitrarily even though the speakers are ca-pable of producing and perceiving a plethora ofthem.
In contrast, these inventories show excep-tionally regular patterns across the languages ofthe world, which is in fact, a common point ofconsensus in phonology.
Right from the begin-ning of the 20th century, there have been a largenumber of linguistically motivated attempts (Tru-betzkoy, 1969; Lindblom and Maddieson, 1988;Boersma, 1998; Clements, 2008) to explain theformation of these patterns across the consonantinventories.
More recently, Mukherjee and his col-leagues (Choudhury et al, 2006; Mukherjee et al,2007; Mukherjee et al, 2008) studied this problemin the framework of complex networks.
Since herewe shall conduct a spectral analysis of the networkdefined in Mukherjee et al (2007), we briefly sur-vey the models and the important results of theirwork.Choudhury et al (2006) introduced a bipartitenetwork model for the consonant inventories.
For-mally, a set of consonant inventories is representedas a graph G = ?VL, VC , Elc?, where the nodes inone partition correspond to the languages (VL) andthat in the other partition correspond to the conso-nants (VC).
There is an edge (vl, vc) between alanguage node vl ?
VL (representing the languagel) and a consonant node vc ?
VC (representing theconsonant c) iff the consonant c is present in theinventory of the language l. This network is calledthe Phoneme-Language Network or PlaNet andrepresent the connections between the languageand the consonant nodes through a 0-1 matrix Aas shown by a hypothetical example in Fig.
1.
Fur-ther, in (Mukherjee et al, 2007), the authors definethe Phoneme-Phoneme Network or PhoNet as theone-mode projection of PlaNet onto the consonantnodes, i.e., a network G = ?VC , Ecc?
?, where thenodes are the consonants and two nodes vc andvc?
are linked by an edge with weight equal to thenumber of languages in which both c and c?
occurtogether.
In other words, PhoNet can be expressedas a matrixB (see Fig.
1) such thatB = AAT?Dwhere D is a diagonal matrix with its entries cor-responding to the frequency of occurrence of theconsonants.
Similarly, we can also construct theone-mode projection of PlaNet onto the languagenodes (which we shall refer to as the Language-Language Graph or LangGraph) can be expressedas B?
= ATA ?D?, where D?
is a diagonal ma-trix with its entries corresponding to the size of theconsonant inventories for each language.The matrix A and hence, B and B?
have beenconstructed from the UCLA Phonological Seg-ment Inventory Database (UPSID) (Maddieson,1984) that hosts the consonant inventories of 317languages with a total of 541 consonants foundacross them.
Note that, UPSID uses articulatory587features to describe the consonants and assumesthese features to be binary-valued, which in turnimplies that every consonant can be representedby a binary vector.
Later on, we shall use this rep-resentation for our experiments.By construction, we have |VL| = 317, |VC | =541, |Elc| = 7022, and |Ecc?
| = 30412.
Conse-quently, the order of the matrix A is 541 ?
317and that of the matrix B?
is 541 ?
541.
It has beenfound that the degree distribution of both PlaNetand PhoNet roughly indicate a power-law behaviorwith exponential cut-offs towards the tail (Choud-hury et al, 2006; Mukherjee et al, 2007).
Further-more, PhoNet is also characterized by a very highclustering coefficient.
The topological propertiesof the two networks and the generative modelexplaining the emergence of these properties aresummarized in (Mukherjee et al, 2008).
However,all the above properties are useful in characteriz-ing the local patterns of the network and providevery little insight about its global structure.4 Spectral Analysis of PhoNetIn this section we describe the procedure and re-sults of the spectral analysis of PhoNet.
We beginwith computation of the spectrum of PhoNet.
Af-ter the analysis of the spectrum, we systematicallyinvestigate the top few eigenvectors of PhoNetand attempt to characterize their linguistic signif-icance.
In the process, we also analyze the corre-sponding eigenvectors of LanGraph that helps usin characterizing the properties of languages.4.1 Spectrum of PhoNetUsing a simple Matlab script we compute thespectrum (i.e., the list of eignevalues along withtheir multiplicities) of the matrix B correspond-ing to PhoNet.
Fig.
2(a) shows the spectral plot,which has been obtained through binning3 with afixed bin size of 20.
In order to have a better visu-alization of the spectrum, in Figs.
2(b) and (c) wefurther plot the top 50 (absolute) eigenvalues fromthe two ends of the spectrum versus the index rep-resenting their sorted order in doubly-logarithmicscale.
Some of the important observations that onecan make from these results are as follows.First, the major bulk of the eigenvalues are con-centrated at around 0.
This indicates that though3Binning is the process of dividing the entire range of avariable into smaller intervals and counting the number ofobservations within each bin or interval.
In fixed binning, allthe intervals are of the same size.the order of B is 541 ?
541, its numerical rank isquite low.
Second, there are at least a few verylarge eigenvalues that dominate the entire spec-trum.
In fact, 89% of the spectrum, or the squareof the Frobenius norm, is occupied by the princi-pal (i.e., the topmost) eigenvalue, 92% is occupiedby the first and the second eigenvalues taken to-gether, while 93% is occupied by the first threetaken together.
The individual contribution of theother eigenvalues to the spectrum is significantlylower than that of the top three.
Third, the eigen-values on either ends of the spectrum tend to decaygradually, mostly indicating a power-law behavior.The power-law exponents at the positive and thenegative ends are -1.33 (the R2 value of the fit is0.98) and -0.88 (R2 ?
0.92) respectively.The numerically low rank of PhoNet suggeststhat there are certain prototypical structures thatfrequently repeat themselves across the consonantinventories, thereby, increasing the number of 0eigenvalues to a large extent.
In other words, allthe rows of the matrix B (i.e., the inventories) canbe expressed as the linear combination of a fewindependent row vectors, also known as factors.Furthermore, the fact that the principal eigen-value constitutes 89% of the Frobenius norm of thespectrum implies that there exist one very strongorganizing principle which should be able to ex-plain the basic structure of the inventories to a verygood extent.
Since the second and third eigen-values are also significantly larger than the restof the eigenvalues, one should expect two otherorganizing principles, which along with the basicprinciple, should be able to explain, (almost) com-pletely, the structure of the inventories.
In orderto ?discover?
these principles, we now focus ourattention to the first three eigenvectors of PhoNet.4.2 The First Eigenvector of PhoNetFig.
2(d) shows the first eigenvector componentfor each consonant node versus its frequency ofoccurrence across the language inventories (i.e., itsdegree in PlaNet).
The figure clearly indicates thatthe two are highly correlated (r = 0.99), which inturn means that 89% of the spectrum and hence,the organization of the consonant inventories, canbe explained to a large extent by the occurrencefrequency of the consonants.
The question arises:Does this tell us something special about the struc-ture of PhoNet or is it always the case for any sym-metric matrix that the principal eigenvector will588Figure 2: Eigenvalues and eigenvectors of B.
(a) Binned distribution of the eigenvalues (bin size = 20)versus their multiplicities.
(b) the top 50 (absolute) eigenvalues from the positive end of the spectrum andtheir ranks.
(c) Same as (b) for the negative end of the spectrum.
(d), (e) and (f) respectively representsthe first, second and the third eigenvector components versus the occurrence frequency of the consonants.be highly correlated with the frequency?
We as-sert that the former is true, and indeed, the highcorrelation between the principal eigenvector andthe frequency indicates high ?proportionate co-occurrence?
- a term which we will explain.To see this, consider the following 2n?
2n ma-trix XX =???????
?0 M1 0 0 0 .
.
.M1 0 0 0 0 .
.
.0 0 0 M2 0 .
.
.0 0 M2 0 0 .
.
.... ... ... ... ... .
.
.???????
?where Xi,i+1 = Xi+1,i = M(i+1)/2 for all oddi and 0 elsewhere.
Also, M1 > M2 > .
.
.
>Mn ?
1.
Essentially, this matrix represents agraph which is a collection of n disconnectededges, each having weights M1, M2, and so on.It is easy to see that the principal eigenvector ofthis matrix is (1/?2, 1/?2, 0, 0, .
.
.
, 0)>, whichof course is very different from the frequency vec-tor: (M1,M1,M2,M2, .
.
.
,Mn,Mn)>.At the other extreme, consider an n ?
n ma-trix X with Xi,j = Cfifj for some vector f =(f1, f2, .
.
.
fn)> that represents the frequency ofthe nodes and a normalization constant C. This iswhat we refer to as ?proportionate co-occurrence?because the extent of co-occurrence between thenodes i and j (which is Xi,j or the weight of theedge between i and j) is exactly proportionate tothe frequencies of the two nodes.
The principaleigenvector in this case is f itself, and thus, corre-lates perfectly with the frequencies.
Unlike thishypothetical matrix X, PhoNet has all 0 entriesin the diagonal.
Nevertheless, this perturbation,which is equivalent to subtracting f2i from the ithdiagonal, seems to be sufficiently small to preservethe ?proportionate co-occurrence?
behavior of theadjacency matrix thereby resulting into a high cor-relation between the principal eigenvector compo-nent and the frequencies.On the other hand, to construct the Lapla-cian matrix, we would have subtracted fi?nj=1 fjfrom the ith diagonal entry, which is a muchlarger quantity than f2i .
In fact, this operationwould have completely destroyed the correlationbetween the frequency and the principal eigen-vector component because the eigenvector corre-sponding to the smallest4 eigenvalue of the Lapla-cian matrix is [1, 1, .
.
.
, 1]>.Since the first eigenvector of B is perfectly cor-4The role played by the top eigenvalues and eigenvectorsin the spectral analysis of the adjacency matrix is compara-ble to that of the smallest eigenvalues and the correspondingeigenvectors of the Laplacian matrix (Chung, 1994)589related with the frequency of occurrence of theconsonants across languages it is reasonable toargue that there is a universally observed innatepreference towards certain consonants.
This pref-erence is often described through the linguisticconcept of markedness, which in the context ofphonology tells us that the substantive conditionsthat underlie the human capacity of speech pro-duction and perception renders certain consonantsmore favorable to be included in the inventory thansome other consonants (Clements, 2008).
We ob-serve that markedness plays a very important rolein shaping the global structure of the consonant in-ventories.
In fact, if we arrange the consonants in anon-increasing order of the first eigenvector com-ponents (which is equivalent to increasing orderof statistical markedness), and compare the set ofconsonants present in an inventory of size s withthat of the first s entries from this hierarchy, wefind that the two are, on an average, more than50% similar.
This figure is surprisingly high be-cause, in spite of the fact that ?s s ?
5412 , on anaverage s2 consonants in an inventory are drawnfrom the first s entries of the markedness hierarchy(a small set), whereas the rest s2 are drawn from theremaining (541?
s) entries (a much larger set).The high degree of proportionate co-occurrencein PhoNet implied by this high correlation be-tween the principal eigenvector and frequency fur-ther indicates that the innate preference towardscertain phonemes is independent of the presenceof other phonemes in the inventory of a language.4.3 The Second Eigenvector of PhoNetFig.
2(e) shows the second eigenvector componentfor each node versus their occurrence frequency.
Itis evident from the figure that the consonants havebeen clustered into three groups.
Those that havea very low or a very high frequency club around 0whereas, the medium frequency zone has clearlysplit into two parts.
In order to investigate the ba-sis for this split we carry out the following experi-ment.Experiment I(i) Remove all consonants whose frequency of oc-currence across the inventories is very low (< 5).
(ii) Denote the absolute maximum value of thepositive component of the second eigenvector asMAX+ and the absolute maximum value of thenegative component as MAX?.
If the absolutevalue of a positive component is less than 15% ofMAX+ then assign a neutral class to the corre-sponding consonant; else assign it a positive class.Denote the set of consonants in the positive classby C+.
Similarly, if the absolute value of a nega-tive component is less than 15% of MAX?
thenassign a neutral class to the corresponding conso-nant; else assign it a negative class.
Denote the setof consonants in the negative class by C?.
(iii) Using the above training set of the classifiedconsonants (represented as boolean feature vec-tors) learn a decision tree (C4.5 algorithm (Quin-lan, 1993)) to determine the features that are re-sponsible for the split of the medium frequencyzone into the negative and the positive classes.Fig.
3(a) shows the decision rules learnt fromthe above training set.
It is clear from these rulesthat the split into C?
and C+ has taken placemainly based on whether the consonants havethe combined ?dental alveolar?
feature (negativeclass) or the ?dental?
and the ?alveolar?
featuresseparately (positive class).
Such a combined fea-ture is often termed ambiguous and its presence ina particular consonant c of a language l indicatesthat the speakers of l are unable to make a distinc-tion as to whether c is articulated with the tongueagainst the upper teeth or the alveolar ridge.
Incontrast, if the features are present separately thenthe speakers are capable of making this distinc-tion.
In fact, through the following experiment,we find that the consonant inventories of almostall the languages in UPSID get classified based onwhether they preserve this distinction or not.Experiment II(i) Construct B?
= ATA ?
D?
(i.e., the adjacencymatrix of LangGraph).
(ii) Compute the second eigenvector of B?.
Onceagain, the positive and the negative componentssplit the languages into two distinct groups L+ andL?
respectively.
(iii) For each language l ?
L+ count the num-ber of consonants in C+ that occur in l. Sum upthe counts for all the languages in L+ and nor-malize this sum by |L+||C+|.
Similarly, performthe same step for the pairs (L+,C?
), (L?,C+) and(L?,C?
).From the above experiment, the values obtainedfor the pairs (i) (L+,C+), (L+,C?)
are 0.35, 0.08respectively, and (ii) (L?,C+), (L?,C?)
are 0.07,0.32 respectively.
This immediately implies thatalmost all the languages in L+ preserve the den-tal/alveolar distinction while those in L?
do not.590Figure 3: Decision rules obtained from the study of (a) the second, and (b) the third eigenvectors.
Theclassification errors for both (a) and (b) are less than 15%.4.4 The Third Eigenvector of PhoNetWe next investigate the relationship between thethird eigenvector components of B and the occur-rence frequency of the consonants (Fig.
2(f)).
Theconsonants are once again found to get clusteredinto three groups, though not as clearly as in theprevious case.
Therefore, in order to determine thebasis of the split, we repeat experiments I and II.Fig.
3(b) clearly indicates that in this case the con-sonants in C+ lack the complex features that areconsidered difficult for articulation.
On the otherhand, the consonants in C?
are mostly composedof such complex features.
The values obtained forthe pairs (i) (L+,C+), (L+,C?)
are 0.34, 0.06 re-spectively, and (ii) (L?,C+), (L?,C?)
are 0.19,0.18 respectively.
This implies that while there isa prevalence of the consonants from C+ in the lan-guages of L+, the consonants from C?
are almostabsent.
However, there is an equal prevalence ofthe consonants from C+ and C?
in the languagesof L?.
Therefore, it can be argued that the pres-ence of the consonants from C?
in a language can(phonologically) imply the presence of the conso-nants from C+, but not vice versa.
We do not findany such aforementioned pattern for the fourth andthe higher eigenvector components.4.5 Control ExperimentAs a control experiment we generated a set of ran-dom inventories and carried out the experimentsI and II on the adjacency matrix, BR, of the ran-dom version of PhoNet.
We construct these in-ventories as follows.
Let the frequency of occur-rence for each consonant c in UPSID be denotedby fc.
Let there be 317 bins each corresponding toa language in UPSID.
fc bins are then chosen uni-formly at random and the consonant c is packedinto these bins.
Thus the consonant inventoriesof the 317 languages corresponding to the binsare generated.
Note that this method of inventoryconstruction leads to proportionate co-occurrence.Consequently, the first eigenvector components ofBR are highly correlated to the occurrence fre-quency of the consonants.
However, the plots ofthe second and the third eigenvector componentsversus the occurrence frequency of the consonantsindicate absolutely no pattern thereby, resulting ina large number of decision rules and very highclassification errors (upto 50%).5915 Discussion and ConclusionAre there any linguistic inferences that can bedrawn from the results obtained through thestudy of the spectral plot and the eigenvectors ofPhoNet?
In fact, one can correlate several phono-logical theories to the aforementioned observa-tions, which have been construed by the past re-searchers through very specific studies.One of the most important problems in defin-ing a feature-based classificatory system is to de-cide when a sound in one language is differentfrom a similar sound in another language.
Ac-cording to Ladefoged (2005) ?two sounds in dif-ferent languages should be considered as distinctif we can point to a third language in which thesame two sounds distinguish words?.
The den-tal versus alveolar distinction that we find to behighly instrumental in splitting the world?s lan-guages into two different groups (i.e., L+ and L?obtained from the analysis of the second eigen-vectors of B and B?)
also has a strong classifi-catory basis.
It may well be the case that cer-tain categories of sounds like the dental and thealveolar sibilants are not sufficiently distinct toconstitute a reliable linguistic contrast (see (Lade-foged, 2005) for reference).
Nevertheless, by al-lowing the possibility for the dental versus alveo-lar distinction, one does not increase the complex-ity or introduce any redundancy in the classifica-tory system.
This is because, such a distinctionis prevalent in many other sounds, some of whichare (a) nasals in Tamil (Shanmugam, 1972) andMalayalam (Shanmugam, 1972; Ladefoged andMaddieson, 1996), (b) laterals in Albanian (Lade-foged and Maddieson, 1996), and (c) stops in cer-tain dialectal variations of Swahili (Hayward et al,1989).
Therefore, it is sensible to conclude that thetwo distinct groups L+ and L?
induced by our al-gorithm are true representatives of two importantlinguistic typologies.The results obtained from the analysis of thethird eigenvectors of B and B?
indicate that im-plicational universals also play a crucial role indetermining linguistic typologies.
The two ty-pologies that are predominant in this case con-sist of (a) languages using only those sounds thathave simple features (e.g., plosives), and (b) lan-guages using sounds with complex features (e.g.,lateral, ejectives, and fricatives) that automaticallyimply the presence of the sounds having sim-ple features.
The distinction between the simpleand complex phonological features is a very com-mon hypothesis underlying the implicational hier-archy and the corresponding typological classifi-cation (Clements, 2008).
In this context, Lockeand Pearson (1992) remark that ?Infants heavilyfavor stop consonants over fricatives, and thereare languages that have stops and no fricatives butno languages that exemplify the reverse pattern.
[Such] ?phonologically universal?
patterns, whichcut across languages and speakers are, in fact, thephonetic properties of Homo sapiens.?
(as quotedin (Vallee et al, 2002)).Therefore, it turns out that the methodology pre-sented here essentially facilitates the induction oflinguistic typologies.
Indeed, spectral analysis de-rives, in a unified way, the importance of theseprinciples and at the same time quantifies their ap-plicability in explaining the structural patterns ob-served across the inventories.
In this context, thereare at least two other novelties of this work.
Thefirst novelty is in the systematic study of the spec-tral plots (i.e., the distribution of the eigenvalues),which is in general rare for linguistic networks,although there have been quite a number of suchstudies in the domain of biological and social net-works (Farkas et al, 2001; Gkantsidis et al, 2003;Banerjee and Jost, 2007).
The second novelty isin the fact that there is not much work in the com-plex network literature that investigates the natureof the eigenvectors and their interactions to inferthe organizing principles of the system representedthrough the network.To summarize, spectral analysis of the com-plex network of speech sounds is able to providea holistic as well as quantitative explanation ofthe organizing principles of the sound inventories.This scheme for typology induction is not depen-dent on the specific data set used as long as it isrepresentative of the real world.
Thus, we believethat the scheme introduced here can be applied asa generic technique for typological classificationsof phonological, syntactic and semantic networks;each of these are equally interesting from the per-spective of understanding the structure and evolu-tion of human language, and are topics of futureresearch.AcknowledgementWe would like to thank Kalika Bali for her valu-able inputs towards the linguistic analysis.592ReferencesA.
Banerjee and J. Jost.
2007.
Spectral plots and therepresentation and interpretation of biological data.Theory in Biosciences, 126(1):15?21.A.
Banerjee and J. Jost.
to appear.
Graph spectra as asystematic tool in computational biology.
DiscreteApplied Mathematics.M.
Belkin and J. Goldsmith.
2002.
Using eigenvectorsof the bigram graph to infer morpheme identity.
InProceedings of the ACL-02 Workshop on Morpho-logical and Phonological Learning, pages 41?47.Association for Computational Linguistics.P.
Boersma.
1998.
Functional Phonology.
The Hague:Holland Academic Graphics.M.
Choudhury and A. Mukherjee.
to appear.
Thestructure and dynamics of linguistic networks.
InN.
Ganguly, A. Deutsch, and A. Mukherjee, editors,Dynamics on and of Complex Networks: Applica-tions to Biology, Computer Science, Economics, andthe Social Sciences.
Birkhauser.M.
Choudhury, A. Mukherjee, A. Basu, and N. Gan-guly.
2006.
Analysis and synthesis of the distribu-tion of consonants over languages: A complex net-work approach.
In COLING-ACL?06, pages 128?135.F.
R. K. Chung.
1994.
Spectral Graph Theory.
Num-ber 2 in CBMS Regional Conference Series in Math-ematics.
American Mathematical Society.G.
N. Clements.
2008.
The role of features in speechsound inventories.
In E. Raimy and C. Cairns, edi-tors, Contemporary Views on Architecture and Rep-resentations in Phonological Theory.
Cambridge,MA: MIT Press.E.
J. Farkas, I. Derenyi, A.
-L. Baraba?si, and T. Vic-seck.
2001.
Real-world graphs: Beyond the semi-circle law.
Phy.
Rev.
E, 64:026704.R.
Ferrer-i-Cancho.
2005.
The structure of syntac-tic dependency networks: Insights from recent ad-vances in network theory.
In Levickij V. and Altm-man G., editors, Problems of quantitative linguistics,pages 60?75.C.
Gkantsidis, M. Mihail, and E. Zegura.
2003.Spectral analysis of internet topologies.
In INFO-COM?03, pages 364?374.K.
M. Hayward, Y.
A. Omar, and M. Goesche.
1989.Dental and alveolar stops in Kimvita Swahili: Anelectropalatographic study.
African Languages andCultures, 2(1):51?72.R.
Kannan and S. Vempala.
2008.
Spec-tral Algorithms.
Course Lecture Notes:http://www.cc.gatech.edu/?vempala/spectral/spectral.pdf.P.
Ladefoged and I. Maddieson.
1996.
Sounds of theWorlds Languages.
Oxford: Blackwell.P.
Ladefoged.
2005.
Features and parameters fordifferent purposes.
In Working Papers in Phonet-ics, volume 104, pages 1?13.
Dept.
of Linguistics,UCLA.B.
Lindblom and I. Maddieson.
1988.
Phonetic univer-sals in consonant systems.
In M. Hyman and C. N.Li, editors, Language, Speech, and Mind, pages 62?78.J.
L. Locke and D. M. Pearson.
1992.
Vocal learn-ing and the emergence of phonological capacity.
Aneurobiological approach.
In Phonological devel-opment.
Models, Research, Implications, pages 91?129.
York Press.I.
Maddieson.
1984.
Patterns of Sounds.
CambridgeUniversity Press.A.
Mukherjee, M. Choudhury, A. Basu, and N. Gan-guly.
2007.
Modeling the co-occurrence principlesof the consonant inventories: A complex networkapproach.
Int.
Jour.
of Mod.
Phys.
C, 18(2):281?295.A.
Mukherjee, M. Choudhury, A. Basu, and N. Gan-guly.
2008.
Modeling the structure and dynamics ofthe consonant inventories: A complex network ap-proach.
In COLING-08, pages 601?608.J.
R. Quinlan.
1993.
C4.5: Programs for MachineLearning.
Morgan Kaufmann.S.
V. Shanmugam.
1972.
Dental and alveolar nasals inDravidian.
In Bulletin of the School of Oriental andAfrican Studies, volume 35, pages 74?84.
Universityof London.M.
Sigman and G. A. Cecchi.
2002.
Global organi-zation of the wordnet lexicon.
Proceedings of theNational Academy of Science, 99(3):1742?1747.N.
Trubetzkoy.
1931.
Die phonologischen systeme.TCLP, 4:96?116.N.
Trubetzkoy.
1969.
Principles of Phonology.
Uni-versity of California Press, Berkeley.N.
Vallee, L J Boe, J. L. Schwartz, P. Badin, andC.
Abry.
2002.
The weight of phonetic substance inthe structure of sound inventories.
ZASPiL, 28:145?168.593
