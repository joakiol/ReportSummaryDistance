DATR: A Language for Lexical KnowledgeRepresentationRoger Evans*University of BrightonGerald Gazdar tUniversity of SussexMuch recent research on the design of natural anguage lexicons has made use of nonmonotonicinheritance networks as originally developed for general knowledge representation purposes inArtificial Intelligence.
DATR is a simple, spartan language for defining nonmonotonic nher-itance networks with path~value equations, one that has been designed specifically for lexicalknowledge representation.
I  keeping with its intendedly minimalist character, it lacks manyof the constructs embodied either in general-purpose knowledge representation languages or incontemporary grammar formalisms.
The present paper shows that the language is nonethelesssufficiently expressive to represent concisely the structure of lexical information at a variety oflevels of linguistic analysis.
The paper provides an informal example-based introduction to DATRand to techniques for its use, including finite-state transduction, the encoding of DA Gs and lexicalrules, and the representation f ambiguity and alternation.
Sample analyses of phenomena suchas inflectional syncretism and verbal subcategorization are given that show how the language canbe used to squeeze out redundancy from lexical descriptions.1.
IntroductionIrregular lexemes are standardly regular in some respect.
Most are just like regularlexemes except hat they deviate in one or two characteristics.
What is needed is anatural way of saying "this lexeme is regular except for this property."
One obviousapproach is to use nonmonotonicity and inheritance machinery to capture such lexicalirregularity (and subregularity), and much recent research into the design of represen-tation languages for natural language lexicons has thus made use of nonmonotonicinheritance networks (or "semantic nets") as originally developed for more generalrepresentation purposes in Artificial Intelligence.
Daelemans, De Smedt, and Gazdar(1992) provide a rationale for, and an introduction to, this body of research and we willnot rehearse the content of that paper here, nor review the work cited there.
1DATRis a rather spartan nonmonotonic language for defining inheritance networks withpath/value quations.
In keeping with its intendedly minimalist character, it lacksmany of the constructs embodied either in general-purpose knowledge representationlanguages or in contemporary grammar formalisms.
But the present paper seeks to* Information Technology Research Institute, University of Brighton, Brighton BN2 4AT, U.K. E-mail:Roger.Evans@itri.brighton.ac.ukt Cognitive & Computing Sciences, University of Sussex, Brighton BN1 9QH, U.K. E-mail:Gerald.Gazdar@cogs.sussex.ac.uk1 Daelemans and Gazdar (1992) and Briscoe, de Paiva, and Copestake (1993) are collections that bringtogether much recent work on the application of inheritance networks to lexical description.
Otherrelevant recent work not found there includes Bouma (1993), Briscoe, Copestake, and Lascarides (1995),Calder (1994), Copestake (1992), Daelemans (1994), Daelemans and De Smedt (1994), Ide, Le Maitre,and V6ronis (1994), Lascarides et al (1996), Mellish and Reiter (1993), Mitamura and Nyberg (1992),Penn and Thomason (1994), Reiter and Mellish (1992), Young (1992), and Young and Rounds (1993).
(~) 1996 Association for Computational LinguisticsComputational Linguistics Volume 22, Number 2show that the language is nonetheless sufficiently expressive to represent conciselythe structure of lexical information at a variety of levels of language description.The development of DATR has been guided by a number of concerns, which wesummarize here.
Our objective has been a language that (i) has an explicit theory ofinference, (ii) has an explicit declarative semantics, (iii) can be readily and efficientlyimplemented, (iv) has the necessary expressive power to encode the lexical entriespresupposed by work in the unification grammar tradition, and (v) can express all theevident generalizations and subgeneralizations about such entries.
Our first publica-tions on DATR (Evans and Gazdar 1989a, 1989b) provided a formal theory of inference(i) and a formal semantics (ii) for DATR and we will not recapitulate hat material here.
2With respect o (iii), the core inference ngine for DATR can be coded in a pageof Prolog (see, e.g., Gibbon 1993, 50).
At the time of writing, we know of a dozendifferent implementations of the language, some of which have been used with largeDATR lexicons in the context of big NLP systems (e.g., Andry et al 1992; Cahill 1993a,1994; Cahill and Evans 1990).
We will comment further on implementation matters inSection 5, below.
However, the main purpose of the present paper is to exhibit the useof DATR for lexical description (iv) and the way it makes it relatively easy to capturelexical generalizations and subregularities at a variety of analytic levels (v).
We willpursue (iv) and (v) in the context of an informal example-based introduction to thelanguage and to techniques for its use, and we will make frequent reference to theDATR-based lexical work that has been done since 1989.The paper is organized as follows: Section 2 uses an analysis of English verbalmorphology to provide an informal introduction to DATR.
Section 3 describes thelanguage more precisely: its syntax, inferential and default mechanisms, and the useof abbreviatory variables.
Section 4 describes a wide variety of DATR techniques, in-cluding case constructs and parameters, Boolean logic, finite-state transduction, listsand DAGs, lexical rules, and ways to encode ambiguity and alternation.
Section 5explores more technical issues relating to the language, including functionality andconsistency, multiple-inheritance, modes of use, and existing implementations.
Sec-tion 6 makes some closing observations.
Finally, an appendix to the paper replies tothe points made in the critical literature on DATR.2.
DATR by ExampleWe begin our presentation of DATR with a partial analysis of morphology in theEnglish verbal system.
In DATR, information is organized as a network of nodes,where a node is essentially just a collection of closely related information.
In thecontext of lexical description, a node typically corresponds to a word, a lexeme, ora class of lexemes.
For example, we might have a node describing an abstract verb,another for the subcase of a transitive verb, another for the lexeme love, and still morefor the individual words that are instances of this lexeme (love, loves, loved, loving, etc.
).Each node has associated with it a set of path/value pairs, where a path is a sequenceof atoms (which are primitive objects), and a value is an atom or a sequence of atoms.We will sometimes refer to atoms in paths as attributes.For example, a node describing the present participle form of the verb love (andcalled perhaps Wordl) might contain the path/value pairs shown in Table 1.
The paths2 Note, however, that the definitions in the 1989 papers are not given in sufficient generality ocoverDATR equations with more than one (non-atomic) descriptor n the right hand side.
Keller (1995)effectively replaces our 1989 presentation f a semantics for DATR and his treatment is general enoughto cover descriptor sequences.168Evans and Gazdar Lexical Knowledge RepresentationTable 1Path/value pairs for present participle oflove.Path Valuesyn cat verbsyn type mainsyn form present participlemor form love ingin this example all happen to contain two attributes, and the first attribute can bethought of as distinguishing syntactic and morphological types of information.
Thevalues indicate appropriate linguistic settings for the paths for a present participleform of love.
Thus, its syntactic ategory is verb, its syntactic type is main (i.e., it isa main verb, not an auxiliary), its syntactic form is p resent  par t i c ip le  (a two-atomsequence), its morphological form is love ing (another two-atom sequence).
In DATRthis can be written as: 3Wordl:<syn cat> = verb<syn type> = main<syn form> = present part ic ip le<mor form> = love ing.Here, angle brackets (<...>) delimit paths.
Note that values can be atomic or they canconsist of sequences of atoms, as the two last lines of the example illustrate# As afirst approximation, odes can be thought of as denoting partial functions from paths(sequences of atoms) to values (sequences of atoms), sIn itself, this tiny fragment of DATR is not persuasive, apparently allowing onlyfor the specification of words by simple listing of path /va lue  statements for each one.It seems that if we wished to describe the passive form of love we would have to write:Word2:<syn cat> = verb<syn type> = main<syn form> = passive part ic ip le<mor form> = love ed.This does not seem very helpful: the whole point of a lexical description language is tocapture generalizations and avoid the kind of duplication evident in the specificationof Word1 and Word2.
And indeed, we shall shortly introduce an inheritance mechanismthat allows us to do just that.
But there is one sense in which this listing approach3 The syntax of DATR, like its name and its minimalist philosophy, owes more than a little to that of theunification grammar language PATR (Shieber 1986).
With hindsight his may have been a bad designdecision since similarity of syntax tends to imply a similarity of semantics.
And, as we shall see inSection 4.7 below, and elsewhere, there is a subtle but important semantic difference.4 Node names and atoms are distinct, but essentially arbitrary, classes of tokens in DATR.
In this paperwe shall distinguish them by a simple case convention--node names tart with an uppercase l tter,atoms do not.5 This is an approximation since it ignores the role of global contexts, ee Section 5.1, below.169Computational Linguistics Volume 22, Number 2is exactly what we want: it represents the actual information we generally wish toaccess from the description.
So in a sense, we do want all the above statements obe present in our description; what we want to avoid is repeated specification of thecommon elements.This problem is overcome in DATR in the following way: such exhaustively listedpath/value statements are indeed present in a description, but typically only implic-itly present.
Their presence is a logical consequence of a second set of statements,which have the concise, generalization-capturing properties we expect.
To make thedistinction sharp, we call the first type of statement extensional nd the second typedefinitional.
Syntactically, the distinction is made with the equality operator: for ex-tensional statements (as above), we use -, while for definitional statements we use ---=.And, although our first example of DATR consisted entirely of extensional statements,almost all the remaining examples will be definitional.
The semantics of the DATRlanguage binds the two together in a declarative fashion, allowing us to concentrateon concise definitions of the network structure from which the extensional "results"can be read off.Our first step towards a more concise account of Wordl and Word2 is simply tochange the extensional statements o definitional ones:Wordl:<syn cat> == verb<syn type> == main<syn form> == present part ic ip le<mor form> == love ing.Word2:<syn cat> == verb<syn type> == main<syn form> == pass ive part ic ip le<mor form> == love ed.This is possible because DATR respects the unsurprising condition that if at somenode a value is specifically defined for a path with a definitional statement, then thecorresponding extensional statement also holds.
So the statements we previously madeconcerning Wordl and Word2 remain true, but now only implicitly true.Although this change does not itself make the description more concise, it allowsus to introduce other ways of describing values in definitional statements, in additionto simply specifying them.
Such value descriptors will include inheritance specifica-tions that allow us to gather together the properties that Wordl and Word2 have solelyby virtue of being verbs.
We start by introducing a VERB node:VERB:<syn cat> == verb<syn type> == main.and then redefine Wordl and Word2 to inherit their verb properties from it.
A directencoding for this is as follows:Word1:<syn cat> == VERB:<syn cat><syn type> == VERB:<syn type><syn form> == present part ic ip le170Evans and Gazdar Lexical Knowledge Representation<mor  fo rm>Word2:<syn  cat><syn  type><syn  fo rm><mor  fo rm>== love ing.== VERB:<syn  cat>== VERB:<syn  type>== pass ive  par t i c ip le== love ed.In these revised definitions the right-hand side of the <syn cat> statement is not adirect value specification, but instead an inheritance descriptor.
This is the simplestform of DATR inheritance: it just specifies a new node and path from which to obtainthe required value.
It can be glossed roughly as "the value associated with <syncat> at Wordl is the same as the value associated with <syn cat> at VERB."
Thusfrom VERB:<syn  cat> == verb  it now follows that Word l :<syn  cat> == verb.
6However, this modification to our analysis seems to make it less concise, ratherthan more.
It can be improved in two ways.
The first is really just a syntactic trick: ifthe path on the right-hand side is the same as the path on the left-hand side, it can beomitted.
So we can replace VERB : <syn type>,  in the example above, with just VERB.We can also extend this abbreviation strategy to cover cases like the following, wherethe path on the right-hand side is different but the node is the same:Come:<mor  root> == come<mor  past  par t i c ip le> == Come:<mor  root>.In this case we can simply omit the node:Come:<mor  root> == come<mor  past  par t i c ip le> == <mor  root>.The other improvement introduces one of the most important features of DATR--specification by default.
Recall that paths are sequences of attributes.
If we understandpaths to start at their left-hand end, we can construct a notion of path extension: apath P2 extends a path P1 if and only if all the attributes of P1 occur in the sameorder at the left-hand end of P2 (so <a l  a2 a3> extends <>, <a l>,  <a l  a2>, and<a l  a2 a3>, but not <a2>, <a l  a3>, etc.).
If we now consider the (finite) set ofpaths occurring in definitional statements associated with some node, that set will notinclude all possible paths (of which there are infinitely many).
So the question arisesof what we can say about paths for which there is no specific definition.
For some pathP1 not defined at node N, there are two cases to consider: either P1 is the extensionof some path defined at N or it is not.
The latter case is easiest--there is simply nodefinition for P1 at N (hence N can be a partial function, as already noted above).
Butin the former case, where P1 extends ome P2 which is defined at N, P1 assumes adefinition "by default."
If P2 is the only path defined at N which P1 extends, then P1takes its definition from the definition of P2.
If P1 extends several paths defined atN, it takes its definition from the most specific (i.e., the longest) of the paths that itextends.In the present example, this mode of default specification can be applied as follows:6 And hence also the extensional version, Wordl :<syn cat> = verb.171Computational Linguistics Volume 22, Number 2We have two statements at Wordl that (after applying the abbreviation i troducedabove) both inherit from VERB:Word1:<syn cat> == VERB<syn type> == VERB.Because they have a common leading subpath <syn>, we can collapse them into asingle statement about <syn> alone:Wordl:<syn> == VERB.If this were the entire definition of Wordl, the default mechanism would ensure thatall extensions of <syn> (including the two that concern us here) would be given thesame definition--inheritance from VERB.
But in our example, of course, there are otherstatements concerning Word1.
If we add these back in, the complete definition lookslike this:Wordl:<syn> == VERB<syn form> == present participle<mor form> == love ing.The paths <syn type> and <syn cat> (and also many others, such as <syn catfoo>, <syn baz>) obtain their definitions from <syn> using the default mechanismjust introduced, and so inherit from VERB.
The path <syn form>, being explicitly de-fined, is exempt from this default behavior, and so retains its value definition, presentparticiple; any extensions of <syn form> obtain their definitions from <syn form>rather than <syn> (since it is a more specific leading subpath), and so will have thevalue present participle also.The net effect of this definition for Wordl can be glossed as "Wordl stipulates itsmorphological form to be love ing and inherits values for its syntactic features fromVERB, except for <syn form>, which is present participle."
More generally, thismechanism allows us to define nodes differentially: by inheritance from default spec-ifications, augmented by any nondefault settings associated with the node at hand.
Infact, the Wordl example can take this default inheritance one step further, by inheritingeverything (not just <syn>) from VERB, except for the specifically mentioned values:Wordl:<> == VERB<syn form> == present participle<mor form> == love ing.Here the empty path < > is a leading subpath of every path, and so acts as a "catchall"--any path for which no more specific definition at Word1 exists will inherit fromVERB.
Inheritance via the empty path is ubiquitous in real DATR lexicons but it shouldbe remembered that the empty path has no special formal status in the language.In this way, Word1 and Word2 can both inherit heir general verbal properties fromVERB.
Of course, these two particular forms have more in common than simply beingverbs--they are both instances of the same verb: love.
By introducing an abstract Love172Evans and Gazdar Lexical Knowledge Representationlexeme, we can provide a site for properties hared by all forms of love (in this simpleexample, just its morphological root and the fact that it is a verb).VERB:<syn cat> == verb<syn type> == main.Love:<> == VERB<mor root> == love.Wordl:<> == Love<syn form><mor form>Word2:<> == Love<syn form><mor form>== present  par t ic ip le== <mor root> ing.== pass ive par t ic ip le== <mor root> ed.So now Wordl irrherits from Love rather than VERB (but Love inherits from VERB, so thelatter's definitions are still present at Word1).
However, instead of explicitly includingthe atom love in the morphological form, the value definition includes the descriptor<mor root>.
This descriptor is equivalent o Wordl:<mor oot> and, since <morroot> is not defined at Wordl, the empty path definition applies, causing it to irtheritfrom Love : <mor root>,  and thereby return the expected value, love.
Notice here thateach element of a value can be defined entirely independently of the others; for <morform> we now have an irfl~eritance descriptor for the first element and a simple valuefor the second.Our toy fragment is beginning to look somewhat more respectable: a single nodefor abstract verbs, a node for each abstract verb lexeme, and then individual nodesfor each morphological form of each verb; but there is still more that can be done.Our focus on a single lexeme has meant that one class of redundancy has remainedhidden.
The line<mor form> == <mor root> ingwill occur in every present participle form of every verb, yet it is a completely genericstatement &at can be applied to all English present participle verb forms.
Can we notreplace it with a single statement in the VERB node?
Using the mechanisms we haveseen so far, the answer is no.
The statement would have to be (i), which is equivalentto (ii), whereas the effect we want is (iii):(i) VERB:<mor  form>( i i )  VERB:<mor form>( i i i )  VERB:<mor form>== <mor root> ing== VERB:<mor  root> ing== Word l :<mor  root> ingUsing (i) or (ii), we would end up with the same morphological root for every verb (ormore likely no value at all, since it is hard to imagine what value VERB: <mor root>might plausibly be given), rather than a different one for each.
2rod of course, wecannot simply use (iii) as it is, since it only applies to the particular word describedby Word1, namely loving.173Computational Linguistics Volume 22, Number 2The problem is that the inheritance mechanism we have been using is local, in thesense that it can only be used to inherit either from a specifically named node (and/orpath), or relative to the local context of the node (and/or  path) at which it is defined.What we need is a way of specifying inheritance relative to the the original node/pathspecification whose value we are trying to determine, rather than the one we havereached by following inheritance links.
We shall refer to this original specification asthe query we are attempting to evaluate, and the node and path associated with thisquery as the globa l  context.
7 Global inheritance, that is, inheritance relative to theglobal context, is indicated in DATR by using quoted (".
.
.")
descriptors, and we canuse it to extend our definition of VERB as follows:VERB:<syn cat> = =  verb<syn type> = =  main<mor form> == "<mor root>" ing.Here we have added a definition for <mor form> that contains the quoted path "<morroot>" .
Roughly speaking, this is to be interpreted as "inherit the value of <morroot> from the node originally queried."
With this extra definition, we no longerneed a <mor form> definition in Wordl, SO it becomes:Wordl:<> == Love<syn form> == present part ic iple.To see how this global inheritance works, consider the query Wordl : <mor form>.Since <mor form> is not defined at Wordl, it will inherit from VERB via Love.
Thisspecifies inheritance of <mot root> from the query node, which in this case is Wordl.The path <mor root> is not defined at Wordl but inherits the value love from Love.Finally, the definition of <mor form> at VERB adds an explicit ing, resulting in a valueof love ing for Wordl:<mor form>.
Had we begun evaluation at, say, a daughterof the lexeme Eat, we would have been directed from VERB : <mor form> back to theoriginal daughter of Eat to determine its <mor root>,  which would be inherited fromEat itself; we would have ended up with the value eat  ing.The analysis is now almost the way we would like it to be.
Unfortunately, bymoving <mor form> from Wordl to VERB, we have introduced a new problem: wehave specified the present participle as the (default) value of <mor form> for allverbs.
Clearly, if we want to specify other forms at the same level of generality, then<mor form> is currently misnamed: it should be <mor present  par t i c ip le>,  sothat we  can add <mor past participle>, <mor present tense>, etc.
If we  makethis change, then the VERB node will look like this:VERB:<syn cat> == verb<syn type> = =  main<mor past> == "<mor root>" ed<mor passive> == "<mot past>"7 Strictly speaking, the query node and path form just the initial global context, since as we shall see inSection 3.2.2 below, the global context can change during inheritance processing.174Evans and Gazdar Lexical Knowledge Representation<mor present> == "<mor root>"<mor present participle> == "<mor root>" ing<mor present tense sing three> == "<mor root>" s.In adding these new specifications, we have added a little extra structure as well.
Thepassive form is asserted to be the same as the past form--the use of global inheritancehere ensures that irregular or subregular past forms result in irregular or subregularpassive forms, as we shall see shortly.
The paths introduced for the present formsillustrate another use of default definitions.
We assume that the morphology of presenttense forms is specified with paths of five attributes, the fourth specifying number, thefifth, person.
Here we define default present morphology to be simply the root, andthis generalizes to all the longer forms, except the present participle and the thirdperson singular.For Love, given these changes, the following extensional statements hold, interalia:Love:<syn<syn<mor<mor<mor<mor<mor<mor<mor<mor<mor<mor<morcat> = verbtype> = mainpresent tense sing one> = lovepresent tense sing two> = lovepresent tense sing three> = love spresent tense plur> = lovepresent participle> = love ingpast tense sing one> = love edpast tense sing two> = love edpast tense sing three> = love edpast tense plur> = love edpast participle> = love edpassive participle> = love ed.There remains one last problem in the definitions of Wordl and Word2.
The mor-phological form of Word1 is now given by <mor present par t i c ip le>.
Similarly,Word2's morphological form is given by <mor passive par t i c ip le>.
There is nolonger a unique path representing morphological form.
This can be corrected by theaddition of a single statement to VERB:VERB :<mor form> == "<mor "<syn form>">".This statement employs a DATR construct, the evaluable path, which we have notencountered before.
The right-hand side consists of a (global) path specification, oneof whose component attributes is itself a descriptor that must be evaluated beforethe outer path can be.
The effect of the above statement is to say that <mor form>globally inherits from the path given by the atom mor followed by the global value of<syn form>.
For Wordl, <syn form> is present participle, so <mor form> inher-its from <mor present participle>.
But for Word2, <mor form> inherits from <morpassive participle>.
Effectively, <syn form> is being used here as a parameterto control which specific form should be considered the morphological form.
Evalu-able paths may themselves be global (as in our example) or local, and their evaluablecomponents may also involve global or local reference.175Evans and Gazdar Lexical Knowledge RepresentationSew:<mor  root> == mow.<> == EN VERB<mor  root> == sew.As noted above, the passive forms of these subregular verbs will be correct nowas well, because of the use of a global cross-reference to the past participle form in theVERB node.
For example, the definition of the passive form of sew is:Word3:<> == Sew<syn  fo rm> == pass ive  par t i c ip le .If we seek to establish the <mor  form> of Word3, we  are sent up the hierarchy ofnodes, first to Sew, then to EN_VERB, and then to VERB.
Here we encounter "<mot "<synform>" >", which resolves to "<mor pass ive  par t i c ip le>"  in virtue of the embed-ded global reference to <syn form> at Word3.
This means we now have to establishthe value of <mor pass ive  par t i c ip le> at Word3.
Again, we ascend the hierarchy toVERB and find ourselves referred to the global descriptor "<mor past  par t i c ip le>"This takes us back to Word3, from where we again climb, first to Sew, then to EN_VERB.Here, <mor past  par t i c ip le> is given as the sequence "<mor root>"  en.
This leadsus to look for the <mor root> of Word3, which we find at Sew, giving the result weseek:Word3:<mor  fo rm> = sew en.Irregularity can be treated as just the limiting case of subregularity, so, for example,the morphology of Do can be specified as follows: 1?Do :<> == VERB<mor  root> == do<mor  past> == d id<mor  past  par t i c ip le> == done<mor  present  tense  s ing  three> == does .Likewise, the morphology of Be can be specified as follows: nBe :<> == EN_VERB<mor  root> == be10 Orthographically, the form does could simply be treated as regular (from do s).
However, we havechosen to stipulate it here since, although the spelling appears regular, the phonology is not, so in alexicon that defined phonological forms it would need to be stipulated.11 In their default unification reconstruction f this DATR analysis of English verbal inflection, Bouma andNerbonne (1994, 48) invoke "a feature -SG3 to cover all agreement values other than third personsingular" in order "to avoid redundancy," but they do not explain how they would then account forthe first person singular present tense form of be without reintroducing the redundancy that they areseeking to avoid.
Moreover, the use of this purely morphological feature leads them to introduce a setof lexical rules in order to map the relevant information across from the (different) syntactic features.177Computational Linguistics Volume 22, Number 2<mor present tense sing one> == am<mor present tense sing three> == is<mor present tense plur> == are<mor past tense sing one> == <mor past tense sing three><mor past tense sing three> == was<mor past tense plur> == were.In this section, we have moved from simple attribute/value listings to a compact,generalization-capturing epresentation fora fragment of English verbal morphology.In so doing, we have seen examples of most of the important ingredients of DATR:local and global descriptors, definition by default, and evaluable paths.3.
The DATR Language3.1 SyntaxA DATR description consists of a sequence of sentences corresponding semantically toa set of statements.
Sentences are built up out of a small set of basic expression types,which themselves are built up out of sequences of lexical tokens, which we take to beprimitive.In the previous ection, we referred to individual lines in DATR definitions as state-ments.
Syntactically, however, a DATR description consists of a sequence of sentences,where each sentence starts with a node name and ends with a period, and containsone or more path equations relating to that node, each corresponding to a statementin DATR.
This distinction between sentences and statements is primarily for notationalconvenience (itwould be cumbersome torequire repetition of the node name for eachstatement) and statements are the primary unit of specification i DATR.
For the pur-poses of this section, where we need to be particularly clear about his distinction, weshall call a sentence containing just a single statement a simple sentence.3.1.1 Lexical Tokens.
The syntax of DATR distinguishes four classes of lexical token:nodes, atoms, variables, and reserved symbols.
The complete list of reserved symbolsis as follows:?
, ,  < > _ _ _  ' y ,#We have already seen the use of the first seven of these.
Single quotes can be usedto form atoms that would otherwise be ill-formed as such; Y, is used for end-of-linecomments, following the Prolog convention; #is used to introduce declarations andother compiler directives.
12The other classes, nodes, atoms, and variables, must be distinct, and distinct fromthe reserved symbols, but are otherwise arbitrary.
13For this discussion, we have al-ready adopted the convention that both nodes and atoms are simple words, with nodesstarting with uppercase l tters.
We extend this convention to variables, discussed morefully in Section 3.4 below, which we require to start with the character $.
And we takewhite space (spaces, new lines, tabs, etc.)
to delimit lexical tokens but otherwise to beinsignificant.12 Aside from their use in Section 3.4, we will completely ignore such directives in this paper.13 Formally, we require them to be finite classes, but this is not of great significance here.178Evans and Gazdar Lexical Knowledge Representation3.1.2 Right-hand-side Expressions.
The expressions that may appear as the right-handsides of DATR equations are sequences of zero or more descriptors.
14 Descriptors aredefined recursively, and come in seven kinds.
The simplest descriptor is just an atomor variable:atoml$varlThen there are three kinds of local inheritance descriptor: a node, an (evalu-able) path, and a node/path pair.
Nodes are primitive tokens, paths are descriptorsequences (defined below) enclosed in angle brackets and node/path pairs consist ofa node and a path, separated by a colon:Nodel<descl desc2 desc3 ...>Nodel:<descl desc2 desc3 ...>Finally there are three kinds of global inheritance descriptor, which are quotedvariants of the three local types just described:"Nodel""<descl desc2 desc3 ...>""Nodel:<descl desc2 desc3 ...>"A descriptor sequence is a (possibly empty) sequence of descriptors.
The recur-sive definition of evaluable paths in terms of descriptor sequences allows arbitrarilycomplex expressions to be constructed, such as: 15"Nodel : <"<atoml>" Node2 : <atom2>>""<"<"<Nodel:<atoml atom2> atom3>" Node2 "<atom4 atom5>" <> >">"But the value sequences determined by such definitions are fiat: they have no struc-ture beyond the simple sequence and in particular do not reflect he structure of thedescriptors that define them.We shall sometimes refer to descriptor sequences containing only atoms as simplevalues, and similarly, (unquoted) path expressions containing only atoms as simplepaths.3.1.3 Sentences.
DATR sentences represent the statements that make up a description.As we have already seen, there are two basic statement types, extensional nd defini-tional, and these correspond irectly to simple extensional nd definitional sentences,which are made up from the components introduced in the preceding section.14 DATR makes a distinction between a path not having a value (i.e., being undefined) and a path havingthe empty sequence as a value:NUM:<two> =:<one> == one .In this example, NUM: <one> has the value one, RUM: <two> has the empty sequence as its value, andIoJg: <three> is simply undefined.15 A descriptor containing an evaluable path may include nested descriptors that are either local or global.Our use of the local/global terminology always refers to the outermost descriptor of an expression.179Computational Linguistics Volume 22, Number 2Simple extensional sentences take the formNode:Path  = Ext.where Node is a node, Path is a simple path, and Ext is a simple value.
Extensionalsentences derivable from the examples given in Section 2 include:Do:<mor  past par t i c ip le> = done.Mow:<mor past tense s ing one> = mow ed.Love:<mor  present  tense s ing three> = love s.Simple definitional sentences take the formNode:Path  == Def.where Node and Path are as above and Def is an arbitrary descriptor sequence.
Deft-nitional sentences already seen in Section 2 include:Do:<mor  past> == did.VERB:<mor  form> == "<mor "<syn form>">".EN_VERB:<mor  past par t ic ip le> == "<mor root>" en.Each of these sentences corresponds directly to a DATR statement.
However  we extendthe notion of a sentence to include an abbreviatory convention for sets of statementsrelating to a single node.
The following single sentence:Node:Path1 == DeflPath2 == Def2PathN == DefN.abbreviates (and is entirely equivalent o):Node:Path1 == Def l .Node:Path2 == Def2.. .
?Node:PathN == DefN.Extensional statements, and combinations of definitional and extensional statements,may be similarly abbreviated, and the examples used throughout his paper  makeextensive use of this convention.
Such compound sentences correspond to a numberof individual (and entirely independent) DATR statements.Finally, it is worth reiterating that DATR descriptions correspond to sets of state-ments: the order of sentences, or of definitions within a compound sentence, is imma-terial to the relationships described.3.2 Inheritance in DATRDATR descriptions associate values with node/path  pairs.
This is achieved in one ofthree ways: a value is explicitly stated, or it is explicitly inherited, or it is implicitly180Evans and Gazdar Lexical Knowledge Representationspecified (stated or inherited) via the default mechanism.
We have already seen howvalues are explicitly stated; in this and the following subsections, we continue ourexposition by providing an informal account of the semantics of specification via in-heritance or by default.
The present subsection is only concerned with explicit (i.e.,nondefault) inheritance.
Section 3.3 deals with implicit specification via DATR's defaultmechanism.3.2.1 Local Inheritance.
The simplest ype of inheritance in DATR is the specificationof a value by local inheritance.
Such specifications may provide a new node, a newpath, or a new node and path to inherit from.
An example definition for the lexemeCome illustrates all three of these types:Come:<> == VERB<mor  root> == come<mor  past> == came<mor  past  par t i c ip le> == <mor  root><syn> == INTRANSIT IVE :<>.Here the empty path inherits from VERB so the value of Come:<> is equated tothat of VERB: <>.
And the past participle inherits from the root: Come:<mor pastpar t i c ip le> is equated to Come : <mor root )  (i.e., come).
In both these inheritances,only one node or path was specified: the other was taken to be the same as that foundon the left-hand side of the statement (<> and Come respectively).
The third type oflocal inheritance is illustrated by the final statement, in which both node and pathare specified: the syntax of Come is equated with the empty path at INTRANSITIVE, anabstract node defining the syntax of intransitive verbs} 6There is a natural procedural interpretation f this kind of inheritance, in whichthe value associated with the definitional expression is determined by "following" theinheritance specification and looking for the value at the new site.
So given a DATRdescription (i.e., a set of definitional statements) and an initial node/path query, welook for the node and path as the left-hand side of a definitional statement.
If thedefinitional statement for this pair provides a local descriptor, then we follow it, bychanging one or both of node or path, and then repeat he process with the resultingnode/path pair.
We continue until some node/path pair specifies an explicit value.
Inthe case of multiple expressions on the right-hand side of a statement, we pursue eachof them entirely independently of the others.
This operation is local in the sense thateach step is carried out without reference to any context wider than the immediatedefinitional statement a hand.Declaratively speaking, local descriptors simply express equality constraints be-tween definitional values for node/path pairs.
The statement:Node1 : Path1  == Node2 : Path2 .16 Bear inmindthat the fo l low ing  are not synonymousCome:<syn> == INTRANSIT IVE :<>.Come:<syn> == INTRANSIT IVE .since the latter is equivalent toCome:<syn> == INTRANSIT IVE :<syn>.181Computational Linguistics Volume 22, Number 2can be read approximately as"if the value for Node2 :Path2 is defined, then the valueof Nodel:Pathl is defined and equal to it."
There are several points to notice here.First, if Node2:Path2 is not defined, then Nodel:Pathl is unconstrained, so this isa weak directional equality constraint.
However, in practice this has no useful con-sequences, due to interactions with the default mechanism (see Section 5.1 below).Second, "defined" here means "defined by a definitional statement," that is, a "=="statement: local inheritance operates entirely with definitional statements, implicitlyintroducing new ones for Nodel :Path1 on the basis of those defined for Node2:Path2.Finally, as we shall discuss more fully in the next subsection, "value" here technicallycovers both simple values and global inheritance descriptors.3.2.2 Global Inheritance.
Like local inheritance, global inheritance comes in threetypes: node, path, and node/path pair.
However, when either the node or the pathis omitted from a global inheritance descriptor, ather than using the node or path ofthe left-hand side of the statement that contains it (the local context of the definition),the values of a global context are used instead.
This behavior is perhaps also moreeasily introduced procedurally rather than declaratively.
As we saw above, we canthink of local inheritance in terms of following descriptors tarting from the query.The local context is initially set to the node and path specified in the query.
Whena local descriptor is encountered, any missing node or path components are filled infrom the local context, and then control passes to the new context created (that is, welook at the definition associated with the new node/path pair).
In doing this, the localcontext also changes to be the new context.
Global inheritance operates in exactly thesame way: the global context is initially set to the node and path specified in the query.It is not altered when local inheritance descriptors are followed (it "remembers" wherewe started from), but when a global descriptor is encountered, it is the global contextthat is used to fill in any missing node or path components in the descriptor, andhence to decide where to pass control to.
In addition, both global and local contextsare updated to the new settings.
So global inheritance can be seen as essentially thesame mechanism as local inheritance, but layered on top of it--following lobal linksalters the local context oo, but not vice versa.For example, when a global path is specified, it effectively returns control to thecurrent global node (often the original query node) but with the newly given path.Thus in Section 2, above, we saw that the node VERB defines the default morphologyof present forms using global inheritance from the path for the morphological root:VERB:<mor present> == "<mor root>".The node from which inheritance occurs is that stored in the global context: a query ofLove : <mor  present> will result in inheritance f rom Love : <mor  root> (via VERB: <morpresent>), while a query of Do :<mor  present> will inherit f rom Do:<mor  root>.Similarly, a quoted node form accesses the globally stored path value, as in thefollowing example:Declensionl :<vocat ive> == -a<accusat ive> == -am.Declension2:<vocat ive> == "Declensionl"<accusat ive> == -um.Declension3:182Evans and Gazdar Lexical Knowledge Representation<vocat ive> == -e<accusat ive> == Declens ion2:<vocat ive>.Here, the value of Dec lens ion3:<accusat ive> inherits f rom Dec lens ion2:<voca-t i ve> and then f rom Declensionl  : <accusat ive>,  using the global path (in this casethe query path), rather than the local path (<vocative>) to fill out the specification.The resulting value is -am and not -a as it would have been if the descriptor inDeclension2 had been local, rather than global.We observed above that when inheritance through a global descriptor occurs, theglobal context is altered to reflect the new node/path pair.
Thus after Love:<morpresent> has inherited through "VERB: <mor root>",  the global path will be <morroot> rather than <mor present>.
When we consider quoted node/path pairs, itturns out that this is the only property that makes them useful.
Since a quotednode/path pair completely respecifies both node and path, its immediate inheritancecharacteristics are the same as the unquoted node/path pair.
However, because italso alters the global context, its effect on any subsequent global descriptors (in theevaluation of the same query) will be different:Declension1:<vocat ive> == "<nominat ive>"<nominat ive> == -a.Declension2:<vocat ive> == Declens ionl<nominat ive> == -u.Declension3:<nominat ive> == -i<accusat ive> == "Declens ion2:<vocat ive>".In this example, the value of Declension3 : <accusat ive> inherits from Declension2 :<vocative> and then from Declension1 : <vocative> and then from Declension2 :<nominative> (because the global node has changed from Declension3 to Declen-sion2) giving a value of -u and not - i  as it would have been if the descriptor inDeclension3 had been local, rather than global.There are a number of ways of understanding this global inheritance mechanism.The description we have given above amounts to a "global memory" model, in whicha DATR query evaluator is a machine quipped with two memories: one containingthe current local node and path, and another containing the current global node andpath.
Both are initialized to the query node and path, and the machine operates byrepeatedly examining the definition associated with the current local settings.
Localdescriptors alter just the local memory, while global descriptors alter both the localand global settings.This model is the basis of at least one implementation f DATR but it is not, ofcourse, declarative.
Nevertheless, the notion of global inheritance does have a declar-ative reading, very similar to local inheritance but, as we have already suggested,layered on top of it.
Recall that local inheritance establishes a network of weak equal-ity relationships among node/path pairs, and these equalities are used to distributevalues across this network.
Formally speaking, the local inheritance network controlsthe distribution ot only of simple values, but also of global descriptors, as we men-tioned above.
That is, to local inheritance, values and global descriptors are one andthe same, and are inherited through the network.
Indeed, this is the intuitive warrantfor the use of the quote notation: the quotes turn an inheritance descriptor into a (kind183Computational Linguistics Volume 22, Number 2of) value.
Consequently, global descriptors are also distributed through the local inher-itance network, and so are implicitly present at many node/path  pairs in addition tothose they are explicitly defined for.
In fact, a global descriptor is implicitly present atevery node/path  pair that could ever occur as the global context for evaluation of thedescriptor at its original, explicitly defined location.
This means that once distributedin this way, the global descriptors form a network of weak equality relationships justas the local descriptors do, and distribute the simple values (alone) in the same way.To see this interpretation i action, we consider an alternative analysis of the pastparticiple form of Come.
The essential elements of the analysis are as follows:BARE_VERB:<mor past part ic ip le> == "<mor root>".Come:<mor root> == come<mor past part ic ip le> == BARE_VERB.Local inheritance from BARE_VERB to Come implicitly defines the following statement(in addition to the above):Come:<mor past part ic ip le> == "<mor root>".Because we have now brought the global inheritance descriptor to the node corre-sponding to the global context for its interpretation, global inheritance can now oper-ate entirely locally--the required global node is the local node, Come, producing thedesired result:Come:<mor past part ic ip le> = come.Notice that, in this last example, the final statement was extensional, not def-initional.
So far in this paper we have almost entirely ignored the distinction weestablished between definitional and extensional statements, but with this declarativereading of global inheritance we can do so no longer.
Local inheritance uses definitionalinheritance statements o distribute simple values and global descriptors.
The simple-valued definitional statements hereby defined map directly to extensional statements,and global inheritance uses the global inheritance statements (now distributed), to fur-ther distribute these extensional statements about simple values.
The statements mustbe of a formally distinct type, to prevent local inheritance descriptors from distribut-ing them still further.
In practice, however, we need not be too concerned about thedistinction: descriptions are written as definitional statements, queries are read off asextensional statementsJ 7The declarative interpretation of global inheritance suggests an alternative proce-dural characterization to the one already discussed, which we outline here.
Startingfrom a query, local descriptors alone are used to determine ither a value or a globaldescriptor associated with the queried node/path  pair.
If the result is a global descrip-tor, this is used to construct a new query, which is evaluated in the same way.
The17 However, in principle, there is nothing to stop an extensional statement from being specified as part ofa DATR description directly.
Such a statement would respect global inheritance but not localinheritance, and might be useful to achieve some exotic effect.184Evans and Gazdar Lexical Knowledge Representationprocess repeats until a value is returned.
The difference between this and the earliermodel is one of perspective: When a global descriptor is encountered, one can eitherbring the global context o the current evaluation context (first model), or take thenew descriptor back to the global context and continue from there (second model).The significance of the latter approach is that it reduces both kinds of inheritance toa single basic operation with a straightforward declarative interpretation.
Thus wesee that DATR contains two instances of essentially the same declarative inheritancemechanism.
The first, local inheritance, is always pecified explicitly, while the second,global inheritance, is specified implicitly in terms of the first.Extending these inheritance mechanisms tothe more complex DATR expressions istraightforward.
Descriptors nested within definitional expressions are treated indepen-dent ly-as though each was the entire value definition rather than just an item in asequence.
In particular, global descriptors that alter the global context in one nesteddefinition have no effect on any others.
Each descriptor in a definitional sequence orevaluable path is evaluated from the same global state.
In the case of global evaluablepaths, once the subexpressions have been evaluated, the expression containing theresultant path is also evaluated from the same global state.3.3 Definition by DefaultThe other major component of DATR is definition by default.
This mechanism allowsa DATR definitional statement to be applicable not only for the path specified in itsleft-hand side, but also for any rightward extension of that path for which no morespecific definitional statement exists.
In effect, this "fills in the gaps" between pathsdefined at a node, on the basis that an undefined path takes its definition from thepath that best approximates it without being more specific.
TM Of course, to be effective,this "filling in" has to take place before the operation of the inheritance mechanismsdescribed in the previous ection.Consider for example, the definition of Do we gave above.Do :<> == VERB<mor  root> == do<mor  past> == d id<mor  past  par t i c ip le> == done<mor  present  tense  s ing  three> == does.Filling in the gaps between these definitions, we can see that many paths will beimplicitly defined only by the empty path specification.
Examples include:Do :<mor> == VERB<syn> == VERB<mor  present> == VERB<syn  cat> == VERB<syn  type> == VERB<mor  present  tense  s ing  one> == VERB.If there had been no definition for < >, then none of these example paths would have18 For formal discussion fthe semantics of the DATR default mechanism, see Keller (1995).185Computational Linguistics Volume 22, Number 2been defined at all, since there would have been no leading subpath with a definition.Note how <mor> itself takes its definition from <>, since all the explicitly defined<mor .
.
.> specifications have at least one further attribute.The definition for <mor past> overrides default definition from <> and in turnprovides a definition for longer paths.
However, <mor past  par t i c ip le> blocks de-fault definition from <mor past>.
Thus the following arise: 19Do :<mor past<mor past<mor past<mor past<mor pasttense> == didtense plur> == didtense sing three> == didparticiple plur> == doneparticiple sing one> == done.Similarly all the <mor present> forms inherit from VERB except for the explicitly cited<mor present tense sing three>.Definition by default introduces new DATR sentences, each of whose  left-hand-side paths is an extension of the left-hand-side paths of some explicit sentence.
Thispath extension carries over to any paths occurring on the right-hand side as well.
Forexample, the sentence:VERB:<mor present tense> == "<mor root>"<mor form> == <mor "<syn form>">.gives rise to the following, inter alia:VERB:<mor present tense sing> == "<mor root sing>"<mor present tense plur> == "<mor root plur>"<mor form present> == <mor "<syn form present>" present><mor form passive> == <mor "<syn form passive>" passive>.This extension occurs for all paths in the right-hand side, whether they are quoted orunquoted and/or  nested in descriptor sequences or evaluable paths.The intent of this path extension is to allow descriptors to provide not simply asingle definition for a path but a whole set of definitions for extensions to that path,without losing path information.
In some cases this can lead to gratuitous extensions topaths- -path attributes pecifying detail beyond any of the specifications in the overalldescription.
However, this does not generally cause problems ince such gratuitouslydetailed paths, being unspecified, will always take their value from the most specificpath that is specified; effectively, gratuitous detail is ignored.
2?
Indeed, DATR's ap-proach to default information always implies an infinite number of unwritten DATRstatements, with paths of arbitrary length.19 The past participle xtensions here are purely for the sake of the formal example---they have no role toplay in the morphological description of English (but cf.
French, where past participles inflect forgender and number).20 Thus, for example, the path <mor plur acc> is a gratuitous extension of the path <mor plur> forEnglish common ouns, since the latter are not differentiated for case.186Evans and Gazdar Lexical Knowledge Representation3.4 Abbreviatory VariablesThe default mechanism of DATR provides for generalization across sets of atoms bymeans of path extension, and is the preferred mechanism to use in the majority ofcases.
However,  to transduce atoms in the path domain to atoms in the value domain(see Section 4.3, below), it is extremely convenient to use abbreviatory variables overfinite sets of atoms.
This is achieved by declaring DATR variables whose use constitutesa kind of macro: they can always be eliminated by replacing the equations in whichthey occur with larger sets of equations that spell out each value of the variables.Conventionally, variable names begin with the S character and are declared in one ofthe following three ways:# vats  $Var l :# vars  $Var2:# vars  $Var3.Range 1 Range2 .
.
.
.Rangel Range2 .
.
.
- RangeA RangeB .
.
.
.Here, the first case declares a variable $Varl that ranges over the values Rangel,Range2 .
.
.
.
where each RangeN is either an atom or a variable name; the second casedeclares $Var2 to range over the same range, but excluding values in RangeA RangeB.
.
.
;  and the third declares SVar3 to range over the full (finite) set of atoms in thelanguage.
21 For example:# vars# vars# vats# varsSletters: a b c d e f g h i j k 1 m n o p q r s t u v w x y z.$vowels :  a e i o u.$consonants :  $1et ters  - $vowels .$net  z: S le t te rs  - z.# vars# vars# vars$odd: 1 3 5 7 9.Seven: 0 2 6 4 8.Sd ig i t :  Sodd Seven.Caution has to be exercised in the use of DATR variables for two reasons.
One isthat their use makes it hard to spot multiple conflicting definitions:# vars  $vowel :  a e i o u.D IPTHONG:<e> == e i <><$vowel> == $vowel  e <>.Here, <e> appears on the left hand side of two conflicting definitions.
Exactly whathappens to such an improper description in practice depends on the implementation,and usages of this kind can be the source of hard-to-locate bugs (see also Section 5.1,below).The other reason is that one can fall into the trap of using variables to expressgeneralizations that would be better expressed using the path extension mechanism.Here is a very blatant example:# vars  Snumber :  s ingu lar  p lu ra l .21 Undeclared variables are similarly assumed to range over the full set of atoms.
Some implementationsmay also include implicit definitions of more restricted variables, uch as $integer.187Evans and Gazdar Lexical Knowledge Representationextensional statements:Cat:<plural> = -s.Datum:<plural> = -a.Alumnus:<plural> = -i.We do not need to invoke an attribute called case to get this technique to work.For example, in Section 2, we gave the following definition of <mor form> in termsof <syn form>:VERB :<mor form> == <mor "<syn form>">.Here the feature <syn form> returns a value (such as passive participle or presenttense sing three) that becomes part of the path through which <mor form> inherits.This means  that nodes for surface word  forms need only state their parent lexeme and<syn form> feature in order for their <mor form> to be fully described, n So, as wesaw in Section 2 above, the passive participle form of sew is fully described by thenode definition for Word3.Word3 :<> == Sew<syn form> == passive participle.For finite forms, we  could use a similar technique.
F rom this:Word4 :<> == Sew<syn form> == present sing third.we would want to be able to infer this:Word4:<mor form> = sew sHowever, the components of <syn form>, present, sing, third are themselves valuesof features we probably want to represent independently.
One  way  to achieve this isto define a value for <syn form> which is itself parameterized from the values ofthese other features.
And  the appropriate place to do this is in the VERB node, thus:VERB :<syn form> == "<syn tense>" "<syn number>" "<syn person>".This says that the default value for the syntactic form of a verb is a finite form, butexactly which finite form depends on the settings of three other paths, <syn tense>,22 More generally, evaluable paths provide structured inheritance in the sense of Daelemans and DeSmedt (1994, 161-168).189Computational Linguistics Volume 22, Number 2<syn number>,  and  <syn  person>.
Now we can  express Word4 as:Word4:<> == Sew<syn tense> == present<syn  number> == s ing<syn  person> == th i rd .This approach has the advantage that the attribute ordering used in the <mor .
.
.
>paths is handled internally: the leaf nodes need not know or care about it.
234.2 Boolean LogicWe can, if we wish, use parameters in evaluable paths that resolve to t rue  or fa l se .We can then define standard truth tables over DATR paths:Boo lean:<> == fa l se<or> == t rue< i f> == t rue<not  fa l se> == t rue<and t rue  t rue> == t rue< i f  t rue  fa l se> == fa l se<or  fa l se  fa l se> == fa l se .This node defines the standard truth tables for all the familiar operators and connec-tives of the propositional calculus expressed in Polish order rather than infix order.
24Notice, in particular, how the DATR default mechanism completes most of the truthtable rows without explicit listing.
The definability of the propositional calculus mayappear, at first sight, to be a curiosity, one which has no relevance to real-life lexicalrepresentation.
But that is not so.
Consider a hypothetical language in which personalproper names have one of two genders, masculine or feminine.
Instead of the genderbeing wholly determined by the sex of the referent, the gender is determined partlyby sex and partly by the phonology.
Examples of this general type are quite commonin the world's languages.
2sIn our hypothetical example, the proper name will havefeminine gender either if it ends in a consonant and denotes a female or if it ends ina stop consonant but does not denote a female.
We can encode this situation in DATRas fo l lows:  26Persona l_name:<> == Boo lean<ends_ in_consonant> == "<ends_ in_s top>"23 Word3 remains unchanged, overriding the definition of <syn form> and so not requiring theseadditional features to be defined at all.24 We can, of course, use the same technique to define many-valued logics if we wish.25 For example, Fraser and Corbett (1995) use DATR to capture a range ofphonology/morphology/semantics i terdependencies in Russian.
And Brown and Hippisley (1994) dothe same for a Russian segmental phonology/prosody/morphology interdependency.
Butone can findsuch interdependencies in English also: see Ostler and Atkins (1992, 96-98).26 Note that complex expressions require path embedding.
Thus, for example, the well-formed negationof a conditional is <not <i f  .
.
.
>> rather than <not if ... >.190Evans and Gazdar Lexical Knowledge Representation<gender_ i s_ femin ine> ==<or  <and "<female_re ferent>"  "<ends_ in_consonant>"><and <not  "<female_re ferent>"> "<ends_ in_s top>">>.We can then list some example lexical entries for personal proper names: 27Taruz:<> == Persona l_name<female_re ferent> == t rue<ends_ in_consonant> == true.Turat :<> == Persona l_name<female_re ferent> == t rue<ends_ in_s top> == true.Tarud:<> == Persona l_name<ends_ in_s top> == true.Turas:<> == Persona l_name<ends_ in_consonant> == true.Note that both Turas and Tarud turn out not to denote females, given the generalfa l se  default in Boolea/1.
28 The genders of all four names can now be obtained astheorems:Taruz:Turat :Tarud:Turas:<gender_ i s_ femin ine> = true.<gender_ i s_ femin ine> = true.<gender_ i s_ femin ine> = true.<gender_ i s_ femin ine> = fa lse .4.3 Finite-state TransductionPerhaps surprisingly, DATR turns out to be an excellent language for defining finite-state transducers (FSTs).
29 A path carl be used as the input tape and a value as theoutput tape (recall that the DATR default mechanism means that extensions to left-hand-side paths are automatically carried over as extensions to right-hand-side paths,as discussed in Section 3.3, above).
Nodes can be used for states, or else states can beencoded in attributes that are prefixed to the current input path.
Here, for example, isa very simple DATR FST that will transduce a path such as <subj 1 sg fu t r  obj 227 For the sake of simplicity, we have assumed that the truth values of <ends_in_consonant> and<ends_in_stop> are just stipulated in the entries, and indeed the second efinition in Personal_namemeans that <ends_in_stop> implies <ends_in_consonant>.
But if the entries represented thephonology of the words in DATR also, then these predicates could be defined on the basis of thefeature composition of the stem-final segment.
As a number of researchers have shown, the highlydefaulty character of lexical phonology and morphophonology makes DATR a very suitable medium ofrepresentation (Bleiching 1992, 1994; Cahill 1993b; Gibbon 1990, 1992; Gibbon and Bleiching 1991;Reinhard 1990; Reinhard and Gibbon 1991).28 It is straightforward to add extra DATR code so as to derive <gender> = feminine when<gender_is_feminine> is true and <gender> ---- masculine when <gender_is_feminine> is false,or conversely.29 Cf.
Krieger, Pirker, and Nerbonne (1993), who  reconstruct finite-state automata in a feature descriptionlanguage.191Computational Linguistics Volume 22, Number 2sg l i ke> into the value ni ta  ku penda (Swahili for I will like you): 3?SI:$2:S3:$4:<subj  i sg> == ni  82 :<><subj  2 sg> == u S2 :<><subj  3 sg> == a $2 :<><subj  i p l> == tu $2 :<><subj  2 p l> == m $2:<><subj  3 p l> == wa $2:<>.<past> == l i  $3 :<><fut r> == ta  S3:<>.<obj i sg> == ni  S4 :<><obj 2 sg> == ku  $4 :<><obj 3 sg> == m S4:<><obj 1 p l> == tu  $4 :<><obj 2 p l> == wa $4:<><obj 3 p l> == wa $4:<>.< l ike> == penda.Although the example is trivial, the technique is both powerful and useful.
Gibbon(1990), for example, has made notably effective use of it in his treatments of Africantone systems.
31 Much of the computational phonology and morphology of the lastdecade and a half has depended on FSTs (Kaplan and Kay 1994).
Potential exicalapplications come readily to mind- - for  example, the orthographic spelling rules forEnglish suffixation (such as sky~skies).
We give below a small fragment of such an FSTin which + is used as a morpheme boundary marker.
Note the role of DATR variablesin giving concise expression to the rules:# vars  Sabc: a b c d e f g h i j k I m n o p q r s t u v w x y z.# vars  Svow: a e i o u.SPELL  :<> ==<+> == <><$abc> == Sabc  <><e + Svow> == Svow <>.These axioms then give rise to theorems uch as these:SPELL:< love> = l o v e< love+s> = l o v e s<i o v e + e d> = i o v e d<i o v e + e r> = 1 o v e r<i o v e + I y> = 1 o v e 1 y30 For clarity, this FST does not exploit default inheritance tocapture the 50% overlap between the subjectand object pronoun paradigms.
See Gazdar (1992) for a version that does.31 And see McFetridge and Villavicencio (1995) for a less exotic application.192Evans and Gazdar Lexical Knowledge Representation<i o v e + i n g> = 1 o v i n g<i o v e + a b 1 e> = 1 o v a b 1 e.4.4 Representing ListsDATR's foundation in path/value specifications means that many of the representa-tional idioms of unification formalisms transfer fairly directly.
A good example is theuse of f i r s t  and rest  attributes to represent list-structured features, such as syntacticarguments and subcategorized complements.
The following definitions could be usedto extend our verb fragment by introducing the path <syn args>, which determinesa list of syntactic argument specifications:NIL:<> == ni l<rest> == UNDEF<f i rst> == \[INDEF.VERB:<syn cat> == verb<syn args f i rst  syn cat> == np<syn args f irst syn case> == nominat ive<syn args rest> == NIL:<>.Here extensions of <syn args f i r s t> specify properties of the first syntactic argu-ment, while extensions of <syn args res t> specify the others (as a first/rest list).UNDEF is the name of a node that is not defined in the fragment, thus ensuring that<syn args rest f i rst>,  <syn  args rest rest>,  and  so forth, are all undefined.The  fragment above provides a default specification for <syn  args> for verbs con-sisting of just one argument, he subject NP.
Subclasses of verb may, of course, overrideany part of this default; for instance, transitive verbs add a second syntactic argumentfor their direct object:TR_VERB:<> == VERB<syn args rest f i rst  syn cat> == np<syn args rest f i rst  syn case> == accusat ive<syn args rest rest> == NIL:<>.The description can be improved by using a separate node, NP_ARG, to represent the(default) properties of noun-phrase arguments:NP_ARG:<f irst  syn cat> == np<first  syn case> == accusat ive<rest> == NIL:<>.VERB:<syn cat> == v<syn args> == NP_ARG:<><syn args f i rst  syn case> == nominat ive.TR_VERB:<> == VERB<syn args rest> == NP_ARG:<>.193Evans and Gazdar Lexical Knowledge Representation<syn args> == NP_ARG:<><syn args first syn case> == nominative.PASSIVE_VERB:<> == VERB<mor passive> == "<mor past>"<syn subcat rest> == "<syn args rest rest>".TR_VERB:<syn args rest> == NP_ARG:<><> == <<mood "<syn form>">><mood> == active<mood passive> == passive<active> == VERB:<><passive> == PASSIVE_VERB:<>.This example introduces everal new techniques.
Firstly, in TR_VERB we have a doubleparametrization on <syn form>: the value of <syn form> is evaluated and used tocreate a <mood> path; the value returned by this path is then used to route the in-heritance.
This allows us to employ the default mechanism to make the default moodactive (for arbitrary <syn form> values other than those that begin with the atompassive), and thus just pick out <syn form> passive (and its extensions) for verbsin the passive mood.
Secondly, <act ive> and <pass ive> path prefixes are providedfor the explicit purpose of controlling the inheritance route.
Thirdly, the example pre-supposes a distinction between the syntactic arguments list (<syn args>) associatedwith a lexeme and the subcategorization frame list (<syn subcat>) associated with aparticular syntactic form of a lexeme.
If the mood of the form is active (and the TR_VERBnode says that anything that is not passive is active), then the subcategorization frameis the same as the argument list.
But if the mood of the form is passive, then the partof the subcategorization frame that deals with objects and complements i  stripped ofits first item i.e., its direct object.
By default, this dependency of subcategorizationframe on mood will be inherited by all the descendants of TR_VERB, whether these beinstances of simple transitive verb lexemes or nodes defining specific types of tran-sitive verbs (ditransitives, object-plus-infinitive rbs, bet-class verbs, etc.)
and theirdescendants.
Thus, if we assume, for example, that the lexeme Donate is an instanceof DI_VERB as defined above, and that Word5 and Word6 are inflected tokens of Donate,then we will be able to derive the following theorems:Word5:<mor<syn<syn<syn<syn<syn<syn<syn<synWord6:<mot<syn<syn<synform> = donate edform> = past tensesubcat first syn cat> =npsubcatsubcatsubcatsubcatsubcatsubcatfirst syn case> = nominativerest first syn cat> =nprest first syn case> = accusativerest rest first syn cat> = pprest rest first syn pform> = torest rest rest> = nil.form> = donate edform> = passive participlesubcat first syn cat> =npsubcat first syn case> = nominative195Computational Linguistics Volume 22, Number 2<syn<syn<synsubcat rest f i rst  syn cat> = ppsubcat rest f i rst  syn pform> = tosubcat rest rest> = nil.Finally, notice that the equation that specifies passive morphology appears on thePASSIVE_VERB node.
This ensures that passive morphology is undefined for verbs notsyntactically passive.The techniques used in this rather simple treatment of passive can be readilyadapted for use in encoding other lexical rules and for grammatical frameworks otherthan that implicit in the PATRish syntax we have adopted in our example.
Thus, Evans,Gazdar, and Weir (1995) formulate various lexical rules for LTAG (see note 33).
Thesetechniques can also be readily adapted for use in the semantic domain and used, forexample, to implement he distinction between fixed and projective inheritance oflexical semantic information proposed by Pustejovsky (1991, 433-437).It is advantageous to express lexical rules in the same formal language as is usedto express the lexical hierarchy, since lexical rules themselves may well exhibit exactlythe kinds of defaulty relations, one to another, that lexical classes do.
36 Thus a lexicalrule for direct Wh-questions may be a variant of that for indirect Wh-questions: imilar,sharing components, but not identical.
With a suitable degree of abstraction, achievedby parameterization f the components, lexical rules can be reified in a language likeDATR, allowing one to inherit from another.4.6 Representing Ambiguity and AlternationDATR is a language that allows the lexicon writer to define sets of partial functionsfrom sequences of atoms to sequences of atoms.
That is actually all that it allowsthe lexicon writer to do.
Because DATR deals in functions, it does not embody anynotion of disjunction or any possibility of multiple values being associated with asingle node/path pair.
It might seem, at first glance, that such a language would bequite inappropriate to a domain such as the lexicon, where ambiguities are common.In practice, however, this turns out not to be the case.
Consider the homonymy ofbank:Bankl  :<> == NOUN<mor root> == bank<sem gloss> == side of river.Bank2 :<> == NOUN<mor root> == bank<sem gloss> == f inanc ia l  inst i tut ion.This is simply the traditional analysis of homonymy, encoded in DATR: there are twoentirely distinct lexemes, with unrelated meanings, that happen both to be nouns andto have indistinguishable mort~hological roots.Or consider the polysemy of cherry: 3736 Cf.
Krieger (1994, 279) who notes ome other advantages.37 The example isdue to Kilgarriff (1995) who shows that he kind of polysemy exhibited by cherryapplies generally to fruit trees and can thus be specified at a higher node in the lexical network,removing the need for stipulation (as in our example) at the Cherry node, the Apple node, and so on.Kilgarriff and Gazdar (1995) also present an extended example showing how DATR can be used to196Evans and Gazdar Lexical Knowledge RepresentationCherry:<> == NOUN<mor root> == cherry<sem gloss i> == sweet red berry  wi th  p ip<sem gloss 2> == tree bear ing <sem gloss i><sem gloss 3> == wood f rom <sem gloss 2>.Again, this is a rather traditional analysis.
There are (at least) three distinct but relatedsenses.
38 They are not freely interchangeable alternative values for a single attributeor path.
Instead, DATR allows their relatedness of meaning to be captured by usingthe definition of one in the definition of another.A very few words in English have alternative morphological forms for the samesyntactic specification.
An example noted by Fraser and Hudson (1990, 62) is the pluralof hoof which, for many English speakers, can appear as both hoofs and hooves.
39 DATRdoes not permit a theorem set such as the following to be derived from a consistentdescription:WordY:<syn number> = plura l<mor form> = hoof s<mor form> = hooves .But it is quite straightforward to define a description that will lead to the followingtheorem set:WordY:<syn number> = plura l<mor form> = hoof s<mor form a l ternant> = hooves .Or something like this:WordY:<syn number> = p lura l<mor forms> = hoof s I hoovesOr this:WordY:<syn number> = plura l<mor forms> = { hoof s , hooves  }.Of course, as far as DATR is concerned { hoof s , hooves  } is just a sequenceencode the regular and subregular polysemy associated with the crop, fiber, yarn, fabric, and garmentsenses of words like cotton and silk.
See also Copestake and Briscoe (1995) for related work on regularand subregular polyserny.38 For perspicuity, we provide these in DATR-augmented English ere.
But in a serious treatment theycould just as well be given in a DATR-encoding ofthe lambda calculus, as used in Cahill and Evans(1990), for example.39 See also the dreamt~dreamed v rb class discussed by Russell et al (1992, 330-331).197Computational Linguistics Volume 22, Number 2of seven atoms.
It is up to some component external to DATR that makes use of suchcomplex values to interpret it as a two-member set of alternative forms.
Likewise, ifwe have some good reason for wanting to put together the various senses of cherryinto a value returned by a single path, then we can write something like this:Cherry:<sem glosses> == { <sem gloss i> , <sem gloss 2> , <sem gloss 3> }.which will then provide this theorem:Cherry:<sem glosses> = { sweet red berry with pip ,tree bear ing sweet red berry with pip ,wood from tree bear ing sweet red berry with pip }.Also relevant here are the various techniques for reducing lexical disjunction dis-cussed in Pulman (forthcoming).4.7 Encoding DAGsAs a feature-based formalism with a syntax modeled on PATR, it would be reasonableto expect hat DATR can be used to describe directed acyclic graphs (DAGs) in aPATR-like fashion.
Consider an example such as the following:DAGI:<vp agr> == <v agr><v agr per> == 3<vp agr gen> == masc.This looks like simple re-entrancy, from which we would expect o be able to infer:DAGI:<vp agr per> = 3.And, indeed, this turns out to be valid.
But matters are not as simple as the examplemakes them appear: if DAG1 was really the DAG it purports to be, then we would alsoexpect o be able to infer:DAGI:<v agr gen> = masc.This, however, is not valid; in fact, <v agr gen> is undefined.
It might be tempting toconclude from this that the equality operator in DATR is very different from the corre-sponding operator in PATR, but this would be to misunderstand what has happenedin this example.
In fact, the semantics of the statementDAGI :<vp agr> == <v agr>.taken in isolation is very similar to the semantics of the corresponding PATR statement:both assert equality of values associated with the two paths.
The DATR statement is198Evans and Gazdar Lexical Knowledge Representationslightly weaker in that it allows the left-hand side to be defined when the right-handside is undefined, but, even in DATR, if both sides are defined they must be the same,so in principle, the value of the left-hand side does semantically constrain the valueof the right-hand side.
However, in a DATR description, specifying explicit values forextensions of the left-hand side of such an equality constraint overrides its effect, andthus does not influence the values on its right-hand side.Another difference lies in the fact that DATR subpaths and superpaths can havevalues of their own:DAG2:<v agr> == sing<v agr per> == 3.From this little description we can derive the following statements, inter alia:DAG2:<v agr> = s ing<v agr num>= sing<v agr per> = 3<v agr per num>= 3.From the perspective of a standard untyped DAG-encoding language like PATR, thisis strange.
In PATR, if <v agr per> has value 3, then neither <v agr> nor <v agrper num> can have (atomic) values.As these examples clearly show, DATR descriptions do not map trivially into (setsof) standard DAGs (although neither are they entirely dissimilar); but that does notmean that DATR descriptions cannot describe standard DAGs.
Indeed, there are a va-riety of ways in which this can be done.
An especially simple approach is possiblewhen the DAGs one is interested in are all built out of a set of paths whose identity isknown in advance (Kilbury, Naerger, and Renz 1991).
In this case, we can use DATRpaths as DAG paths, more or less directly:PRONOUN2:<referent> == '<' 'NP'She2:<> == PRONOUN2<case> == nominat ive<person> == th i rd<number> == singular.re ferent  '>'From this description, we can derive the following theorems:She2:<case> = nominat ive<person> = th i rd<number> = s ingular<referent> = < NP referent  >.We can also derive the following un-DAG-like consequences, of course:She2:199Computational Linguistics Volume 22, Number 2<case  person> = nominat ive<person  number> = th i rd<re ferent  re ferent  re ferent> = < NP re ferent  >.But these nonsensica l  theorems wil l  be of no concern to a DATR-invoking NLP systemthat is able to specify in advance which paths are of interest for DAG-construct ionand to ignore all the rest.
4?A more sophist icated approach uses DATR itself to construct a DAG descr ipt ion(in the notat ion of your  choice) as a value: 41IDEM:<> ==<$atom> == $atom <>.PATH:<> == '<' IDEM '>'LHS_EQ:<> == PATH '='.LHS_EQ_KHS:<> == LHS_EQ "<>".PRONOUNI :<dag> == \[ LHS_EQ_KHS:<case>LHS_EQ_KHS:<person>LHS_EQ_R/{S:<number>LHS_EQ:<re ferent> PATH:<'NP '  re ferent>Shel:<> == PKONOUNI<case> == nominat ive<person> == th i rd<number> == s ingu lar ..From this descript ion, we can derive the fo l lowing theorem:Shel:<dag> = \[ < case  > = nominat ive< person  > = th i rd< number  > = s ingu lar< re ferent  > = < NP re ferent  > \].The sequence of atoms on the r ight -hand side of this equat ion  is just  a sequence ofatoms as far as DATR is concerned.
But a grammar  or a parser that expects to seeDAGs represented as they are here can interpret  he DATR values as easily as it canthe contents of a file.
4240 In this connection, see the discussion of "closure definitions" in Andry et al (1992, 259-261).41 This approach is due to recent unpublished work by Jim Kilbury.
He has shown that the same DATRtheorems can have their values realized as conventional attribute-value matrix representations, Prologterms, or expressions ofa feature logic, simply by changing the fine detail of the transducer mployed.42 Indeed, it will be interpreting the contents of a file if DATR has been used to define a lexicon that hassubsequently been compiled out, rather than being accessed irectly by components of the NLP system(see Section 5.3, below).
We are not, of course, claiming that textual representations will standardlyprovide the optimal interface between an implementation of DATR and the larger NLP system inwhich it is embedded (cf., e.g., Duda and Gebhardi 1994).200Evans and Gazdar Lexical Knowledge Representation5.
Technical IssuesIn this section we briefly discuss a number of technical issues, relating both to DATRas a formal language, and also to practical aspects of DATR in use.5.1 FunctionalityMost DATR descriptions consist only of definitional statements, and include at mostone statement for each node/path  pair.
In this section we examine the significance ofthis observation from a formal perspective.
As noted in Section 2, DATR nodes can bethought of semantically as denoting partial functions from paths (sequences of atoms)to values (sequences of atoms).
43 Generalizing this view in the obvious way, wholeDATR descriptions can be thought of as denoting functions from nodes to (partial)functions from paths to values.
This semantic notion induces a notion of consistencyfor DATR descriptions: we say that a DATR description is consistent if and only if ithas a coherent interpretation asa function; that is, if the extensional sentences defined(explicitly or implicitly) for each node constitute a (partial) function from paths tovalues.The syntax of DATR does not itself prevent one from writing down inconsistentdescriptions:VERB:<syn cat> == verb<syn cat> == noun.However, such descriptions are of no utility and it would be desirable to find a me-chanical way of eliminating them.
In pursuit of this, we can define a syntactic notionof functionality over DATR descriptions as follows:A DATR description is functional if and only if (i) it contains onlydefinitional statements and (ii) those statements constitute a (partial)function from node/path  pairs to descriptor sequences.The significance of this syntactic notion arises from the following property: 44Every functional DATR description is consistent.To understand why this is, note first that the default extension process preserves func-tionality, since it only adds definitional statements about new node/path  pairs notalready present in the original description.
Local inheritance derives new statementsassociated with a node/path  pair, but at most one of these defines a value or globalinheritance descriptor (since local inheritance ceases at that point).
Thus although thelocal inheritance makes the description become syntactically nonfunctional, the spec-ification of values or global descriptors remains functional.
The value specificationsmap directly to extensional statements, while the global inheritance descriptors oper-ate just as the local ones, adding at most one further value statement for each global43 We continue to oversimplify matters here.
As Keller (1995) points out, the meaning of a node dependson the global context, and a node thus really denotes a function from global contexts o partialfunctions from paths to values.
Though important, his point is tangential to the issue addressed here.44 For simplicity here, we consider only the case of descriptor sequences oflength one--the general caseinvolves complications ot relevant to the main point.201Computational Linguistics Volume 22, Number 2inheritance statement, so that ultimately the consistency of the set of (extensional)value statements i assured.This theorem cannot be strengthened to a biconditional, however, since consistentbut nonfunctional DATR descriptions exist, as in the following examples:NONFUNCl:<a> == UNDEF<a> == 1.NONFUNC2:<a> == <b><a> == 1<b> == 1.NONFUNC3:<a> == <b><b> == <a><a> == i.In NONFUNC1, UNDEF is a node with no associated efinitions, so the first statementimposes no constraint on the value of <a>;  in NONFUNC2, two definitions for <a> areprovided, which happen to define the same value; in NONFUNC3, we establish a mutualdependence between <a> and <b>,  and then define a value for one (either) of them.However,  we have not encountered any examples of nonfunctional but consistent de-scriptions that are not better expressed by a straightforward functional counterpart.
4sIndeed, we suspect (but have no proof) that every consistent DATR description is exten-sionally equivalent to (that is, defines the same extensional sentences as) a functionalone.In the light of these considerations, we assume here, and elsewhere, that func-tionality is a reasonable restriction to place on DATR descriptions.
46The advantage ofthis is that to check the functionality of a DATR description, and hence guarantee itsconsistency, is completely trivial.
In other words, we can substitute a straightforwardsyntactic constraint on descriptions for the less tractable notion of semantic consis-tency, apparently without significant loss of expressive power.
Among other things,this means that implementations of DATR can either treat apparent violations of func-tionality as syntactic errors and require the user to eliminate them, or (more commonlyin existing implementations) treat them as intentional corrections and silently eraseearlier statements for the node and path for which a violation has been detected.5.2 Multiple InheritanceMult iple inheritance, in inheritance network terminology, describes any situationwhere a node in an inheritance network inherits information from more than oneother node in the network.
Wherever this phenomenon occurs there is the potentialfor conflicting inheritance, i.e., when the information inherited from one node is in-consistent with that inherited from another.
Because of this, the handling of multiple45 NONFUNC3 perhaps comes closest, but adding statements about extensions of either <a> or <b>quickly breaks the illusion that the two are in some sense "unified.
"46 This only applies to original source descriptions: as we mentioned above, the formal inferencemechanisms that implement inheritance necessarily add statements tomake a descriptionnonfunctional, but since these can always be automatically determined, they need never appearexplicitly in source descriptions.202Evans and Gazdar Lexical Knowledge Representationinheritance is an issue central to the design of any formalism for representing inheri-tance networks.For the formalism to be coherent, it must provide a way of avoiding or resolvingany conflict hat might arise.
This might be by banning multiple inheritance altogether,restricting it so that conflicts are avoided, providing some mechanism for conflictresolution as part of the formalism itself, or providing the user of the formalism withthe means to specify how the conflict should be resolved.
Putting aside considerationsof functionality for the moment, we see that, in DATR, both the second and third ofthese options are employed.
The "longest-defined-subpath-wins" principle amountsto conflict resolution built into the formalism; however, it does not deal with everycase.
Definitions uch as:Node3:<> == Node l<> == Node2.may result in unresolvable conflicts.
Such conflicts could, of course, just be ruled outby appealing to their inconsistency, which, following a logical tradition, is grounds forruling the description to be "improper.
"Touretzky (1986, 70ff) provides a formal description of a number of propertiesthat an inheritance network may have, and discusses their significance with respect tothe problem of multiple inheritance.
Tree-structured networks, as their name suggests,allow any node to inherit from at most one other node, so multiple inheritance conflictscannot arise.
Orthogonal networks allow a node to inherit from more than one othernode, but the properties it inherits from each must be disjoint, so that again, no conflictcan possibly arise.The basic descriptive f atures of DATR allow the specification ofsimple orthogonalnetworks imilar to Touretzky's.
For example, if we write:A:<a> == t rue .B:<b> == fa l se .C:<a> == A<b> == B.then we are specifying a network of three nodes (A B, and C), and two "predicates"(Boolean-valued attributes coded as DATR paths <a> and <b>), with C inheriting avalue for <a> from A, and for <b> from B.
The network is orthogonal, since <a> and<b> represent distinct (sets of) predicates.Orthogonal multiple inheritance (OMI) is a desirable property of lexical repre-sentation systems.
Consider an analysis in which we put the common properties ofverbs at a VERB node and the (disjoint) common properties of words that take nounphrase complements at an NP_ARG node.
A transitive verb (TR_VERB) is both a verband a word that takes an NP complement, thus it should inherit from both VERB andNP_ARG in this analysis.
In DATR, this might be expressed as follows:VERB:<cat> == verb .NP_ARG:203Evans and Gazdar Lexical Knowledge RepresentationTheory Query ValueConventional inference given given unknownReverse query given unknown givenTheory induction unknown given givenTable 2Possible inference tasks (adapted from Barg 1994).facts that provided our running example in Section 2, above.
The conventional infer-ence task presupposes that we have a description (such as that given in that section)and a query (such as Love: <mor past participle>): the task is to infer the appropri-ate value for this query, namely love ed.
This task is crucial to lexicon developmentand maintenance, since it provides lexicon developers with the means to check theempirical adequacy of their analyses.
It is also a task that is likely to figure in theon-line use of the lexicon in a language-processing system, once the relevant lexicalentry (i.e., the relevant DATR node) has been determined, to recover information as-sociated with the entry, and it is the task that does the compilation in systems thatuse a partially or fully compiled-out off-line lexicon (as in Andry et al 1992).The reverse query task again presupposes that we have a description availableto us, but instead of starting with a known query, we start instead with a knownvalue love ed, say, and the task is to infer what queries would lead to that value(Love: <mor past part ic iple>, Love: <mor past tense sing one>, etc.).
47 The abilityto perform this kind of inference may also be useful in lexicon development andmaintenance.
However, its most obvious application is to "bootstrap" lexical accessin language-processing systems that make direct use of an on-line lexicon: given asurface form (in analysis) or a semantic form (in generation), we need to identify alexical entry associated with that form by reverse query, and then access other lexicalinformation associated with the entry by conventional inference.
Langer (1994) givesan inference algorithm, based on the familiar chart data structure, for reverse queryingDATR lexicons; and Gibbon (1993) describes ?DQ\[ (Extended DATR Query Language)which permits quantification i to components of multisentence DATR queries.The final task is that of theory induction.
Here one starts with a set of knownquery-value pairs (Love: <mor past participle> = love ed., Love: <mor pres tensesing three> = love s., etc.)
and the task is to induce a description that has those pairsas theorems under the application of conventional inference.
In a world in which allthe relevant data was already clearly set out in descriptive linguistic work, an al-gorithm that efficiently achieved this kind of induction would be the philosopher'sstone to the construction of computational lexicons.
In the real world, such an al-gorithm would still be useful for domains like morphology (where the quality andclarity of extant descriptive linguistic work is very high), for bootstrapping lexicaldescriptions for subsequent manual development by humans, for updating lexiconsin the light of newly encountered lexical information, and for converting one kindof lexicon into a completely different kind of lexicon by inducing the latter from theoutput of the former.
The automatic induction of (symbolic) lexicons from data is avery new research area in computational linguistics: Kilbury (1993), Kilbury, Naerger,and Renz (1994), Light (1994), and Light, Reinhard, and Boyle-Hinrichs (1993) haveproposed a variety of incremental gorithms that take a partial exical hierarchy and47 An alternative formulation is to start with a known value and path, and the task is to infer theappropriate nodes.205Computational Linguistics Volume 22, Number 2elaborate it as necessary in the light of successively presented ata sets, while Barg(1994) has presented a non-incremental algorithm that induces full DATR hierarchiesfrom suitable data sets.Since DATR is no more than a language, it does not itself dictate how a DATRlexicon is to be used.
As it turns out, different researchers have used it very differently.Andry et al (1992), in the context of a speech recognition task involving the parsing of"extremely arge lattices of lexical hypotheses" (p. 248), opted for off-line compilationof their 2,000 word DATR lexicons into pairs of on-line lexicons, one of which wasencoded with bit-vectors for speed and compactness.
At the other extreme, Dudaand Gebhardi (1994) present an interface between a PATR-based parser and a DATRlexicon where the former is dynamically inked to the latter and able to query it freely,in both conventional nd reverse modes, without restriction.
Gibbon (1993) presents animplementation f a very flexible query language, EDQL, which allows quantificationover any constituents of (possibly complex) DATR queries.5.4 ImplementationsAs already noted, the inferential core of DATR is extremely simple to implement.
Weknow of the existence of approximately a dozen different implementations of the lan-guage but there may well be others that we do not know of.
The best known, andmost widely available are our own (Brighton/Sussex), which is written in Prolog andruns on most Unix platforms, Gibbon's (Bielefeld) DDATR Scheme and NODE SicstusProlog implementations, and Kilbury's (Duesseldorf) QDATR Prolog implementation,which runs (in compiled form) on PCs and on Sicstus Prolog under Unix.
All of theseare freely available on request, as is an extensive archive of over one hundred examplefragments, ome of which illustrate formal techniques and others of which are appli-cations of DATR to the lexical phonology, morphology, syntax, or semantics of a widevariety of different languages.
48 Other interesting implementations that we are familiarwith include the experimental reverse query implementation by Langer (Osnabrueck),Duda and Gebhardi's (Berlin) implementation that is dynamically inked to PATR, andBarg's (Duesseldorf) implementation f a system that induces DATR descriptions fromextensional data sets.6.
Concluding RemarksOur title for this paper is to be taken literally--DATR is a language for lexical knowledgerepresentation.
It is a kind of programming language, not a theoretical framework forthe lexicon (in the way that, say, HPSG is a theoretical framework for syntax).
Clearly,the language is well suited to lexical frameworks that embrace, or are consistent with,nonmonotonicity and inheritance of properties through networks of nodes.
But thosetwo dispositions hardly constitute a restrictive notion of suitability in the contextof contemporary NLP work, nor are they absolute requirements: it is, for example,entirely possible to write useful DATR fragments that never override inherited values(and so are monotonic) or that define isolated nodes with no inheritance.It is true, of course, that our examples, in this paper and elsewhere, reflect aparticular set of assumptions about how NLP lexicons can be best organized.
But,apart from the utility of inheritance and nonmonotonicity, we have been careful not48 Anonymous FTP to ftp.cogs.sussex.ac.uk nd directory/pub/nlp/DATR provides access to variousDATR implementations, the example archive, and some relevant papers and documentation.206Evans and Gazdar Lexical Knowledge Representationto build those assumptions into the DATR language itself.
There is, for example, nobuilt-in assumption that lexicons should be lexeme-based rather than, say, word- ormorpheme-based.Unlike some other NLP inheritance languages, DATR is not intended to providethe facilities of a particular syntactic formalism.
Rather, it is intended to be a lexical for-malism that can be used with any syntactic representation that can be encoded in termsof attributes and values.
Thus, at the time of writing, we know of nontrivial DATRlexicons written for GPSG, I_TAG, PATR, Unification Categorial Grammar, and WordGrammar.
Equally, the use of DATR does not commit one, in advance, to adopting anyparticular set of theoretical ssumptions with respect o phonology, morphology, orsemantics.
In phonology, for example, the language allows one to write transducersthat map strings of atomic phonemes to strings of atomic phones.
But it also allowsone to encode full-blown feature- and syllable-tree-based prosodic analyses.Unlike the formalisms typically proposed by linguists, DATR does not attempt toembody in its design any substantive and restrictive universal claims about the lex-icons of natural anguage.
That does not distinguish it from most NLP formalisms,of course.
However, we have also sought o ensure that its design does not embodyfeatures that would restrict its use to a single language (English, say) or to a particularclass of closely related languages (the Romance class, say).
The available vidence sug-gests that we have succeeded in the latter aim since, at the time of writing, nontrivialDATR fragments of the lexicons of Arabic, Arapesh, Czech, English, French, German,Gikuyu, Italian, Latin, Polish, Portuguese, Russian, and Spanish ave been developed.There are also smaller indicative fragments for Baoule, Dakota, Dan, Dutch, Japanese,Nyanja, Sanskrit, Serbo-Croat, Swahili, and Tem.Unlike most other languages proposed for lexical knowledge representation, DATRis not intended to be restricted in the levels of linguistic description to which it can sen-sibly be applied.
It is designed to be equally applicable at phonological, orthographic,morphological, syntactic, and semantic levels of description; but it is not intendedto replace existing approaches to those levels.
Rather, we envisage descriptions ofdifferent levels according to different heoretical frameworks being implementable inDATR: thus an NLP group might decide, for example, to build a lexicon with DRT-stylesemantic representations, H PSG-style syntactic representations, "item & arrangement"-style morphological representations and a KIMMO-style orthographic component, im-plementing all of these, including the HPSG lexical rules, in DATR.
DATR itself doesnot mandate any of the choices in this example, but equally, nor does it allow suchchoices to be avoided.
49 DATR cannot be (sensibly) used without a prior decision asto the theoretical frameworks in which the description is to be conducted: there is no"default" framework for describing morphological facts in DATR.
Thus, for example,Gibbon (1992) and Langer and Gibbon (1992) use DATR to implement their ILEX the-ory of lexical organization, Corbett and Fraser (1993) and Fraser and Corbett (in press)use DATR to implement their Network Morphology framework, and Gazdar (1992)shows how Paradigm Function Morphology analyses (Stump 1992) can be mappedinto DATR.
Indeed, it would not be entirely misleading to think of DATR as a kind ofassembly language for constructing (or reconstructing) higher-level theories of lexicalrepresentation.49 However, DATR's framework-agnosticism may make it a plausible candidate for the construction ofpolytheoretic lexicons.
For example, one that would allow either categorial or HPSG-stylesubcategorization specifications to be derived, depending on the setting of a parameter.207Computational Linguistics Volume 22, Number 2APPENDIX: The Critical Literature on DATR ReviewedSince DATR has been in the public domain for the last half-dozen years and beenwidely used in Europe during that period (by the standards of lexical knowledge rep-resentation languages), it is not surprising that it has attracted some critical attentionfrom others working in the field.
In this appendix, we consider and respond to thecritical material that has been published: Domenig and ten Hacken (1992), Bouma andNerbonne (1994), Nerbonne (1992), Krieger and Nerbonne (1993), and Daelemans andvan der Linden (1992).
Langer and Gibbon (1992) also respond to the last three pa-pers in the context of a thorough general review of appropriate evaluation criteria forlexical knowledge representation formalisms.
We are indebted to their discussion.Domenig and ten Hacken (1992) base part of their critique of DATR on an id-iosyncratic analysis of the English -s/-es suffix choice as a matter of pure morphology.This may be because they are considering DATR as a candidate "FMP"--formalism formorphological processing---even though, as they note "DATR is strictly speaking notan FMP" (p. 8) and "is not specifically geared to morphological processing" (p. 15).
Asthey point out, dealing with the choice morphologically leads to undermotivated in-flectional subclasses, obscures the role of phonology in the choice of form, and missesthe morphophonological generalization that unites nouns and verbs in respect of thechoice.
But their critique is based on the assumption that they have identified "themost natural way to express \[the choice\] in DATR" (p. 17).
Given the well-known factsof this phenomenon, 5?
their analysis eems to us to be about as unnatural as it couldbe.
Depending on the nature and purpose of one's lexicon, it would be much morenatural to deal with the choice orthographically with a DATR-coded FST of the kinddiscussed in Section 4.3, above, or morphophonologically using the kind of phonolog-ical representation adopted by Reinhard and Gibbon (1991), for example.Domenig and ten Hacken actually cite this latter paper in connection with Ger-man umlaut and suggest that the -s/-es alternation might be handled in the same way.However, they go on to claim, quite incorrectly, that "morphophonological generaliza-tions can actually not be expressed as such" in DATR because "they are represented asproperties of the individual lexemes" (pp.
23-24).
This claim appears to be based ona false assumption that DATR nodes are somehow restricted to the description of lex-emes.
This is an odd assumption to make given that the Reinhard and Gibbon paperpostulates nodes for vowels, syllables, stems, stem types, prefixes, plural inflection,and syntactic ategories, as well as lexemes.
But then they dismiss the analysis givenin that paper as "incomprehensible" (p. 24).A related straw man appears in their discussion of how alternation within a mor-phological paradigm might be represented in DATR (p. 22).
They once again postulatean analysis that proliferates nodes beyond necessity and fail to spot the possibility ofpath domain or value domain analyses uch as those sketched in Section 4.6, above.They go on to offer a "slightly speculative" evaluation of ways in which DATR mightbe able to represent word formation, concluding that they "do not see any possibilityof representing the rules involved in word formation" (p. 22).
This conclusion againappears to be based on their assumption that DATR nodes are somehow restrictedto the description of lexemes.
But DATR, of course, knows nothing about lexemes,affixes, vowels, words, lexical rules, or whatever.
These are higher-level notions thatthe analyst may choose to represent in a wide variety of ways.50 The orthographic alternation applies to the third person singular present tense forms of verbs and theplural forms of nouns.
The choice between the alternants is wholly governed by the phonology oftheverb or noun stem.208Evans and Gazdar Lexical Knowledge RepresentationFinally, Domenig and ten Hacken contend that lexical inheritance formalisms (andthus DATR) are unusable for the purpose for which they were designed because thehumans who have to work with them for lexicon development cannot keep track ofall the interactions.
They provide no evidence for this assertion and the widespreadadoption, development, and use of a variety of large inheritance lexicons in workingNLP systems over the last few years make the assertion seem somewhat implausible.They conclude that their evaluation of DATR has been "unfair" (p. 29) because theyfailed to consider the language in its natural environment.
We agree that their eval-uation is unfair, but ascribe the cause to the ways in which they attempted to applyDATR to their chosen tasks, slDaelemans and van der Linden (1992) review a number of approaches to lexi-cal knowledge representation, i cluding DATR, with respect o their notational ade-quacy and expressivity.
They argue that adequate approaches will allow (i) recursivepath formation; (ii) multiple inheritance, preferably orthogonal multiple inheritance;(iii) nonmonotonic nheritance; and require (iv) that irregular items take precedenceover regular ones without explicit coding (p. 61).
Since, as we have seen, and as Langerand Gibbon (1992) note, DATR has all four of these properties, one might expect it toemerge from their review with at least a low alpha grade--but in fact they find faultwith it on a number of grounds.The first of these is the use of double quotes to mark global inheritance in theconcrete syntax of DATR.
They claim that global inheritance is the normal kind ofinheritance in DATR and should thus not be marked in any special way, while (un-quoted) local inheritance is exceptional and should therefore have a special notation(like quotes) associated with it (p. 63).
52 The small example they give lends some plau-sibility to their claim.
However, the claim is nonetheless misleading.
Quoted paths (theonly instances of global inheritance to be found in their example fragment) are indeedubiquitous at the highest nodes of existing DATR fragments, but unquoted nodes, un-quoted paths, and unquoted node/path pairs all also occur very frequently in existingDATR fragments, while quoted nodes and quoted node/path pairs are hardly foundat all.
In some common applications of DATR, such as FSTs, no use at all may be madeof global inheritance.Their second objection is to the way path extension in DATR permits the derivationof theorems that have no interpretation i the domain being modeled (p. 63).
Thus,for example, a description that had (a) as a (sensible) theorem might also have (b) asone of an infinity of (silly) theorems:(a)(b)Parrot :<mor plur> = parrot s.Parrot :<mor plur past perfect> = parrot s.The issue here is that while DATR encourages abstraction away from the most specificlevel of detail wherever possible, it does not itself provide a built-in mechanism forstating what that most specific level is.
Our position is that this is part of the lexicalmetatheory, rather than the lexical description itself.
It needs to be known by anyone(or any system) wishing to access the lexicon properly, and it may be practically usefulto constrain access by checking for the well-formedness of queries according to sucha metatheory--this could be done quite straightforwardly in DATR as an adjunct tothe main lexicon if desired.
This notion, however, is external to, and independent of,51 For another critical discussion of the same Domenig and ten Hacken material, see Russell (1993).52 One of our referees comments that "the i ssue .
.
,  appears to be rather scholastic."
We agree.209Computational Linguistics Volume 22, Number 2the lexical description itself: the range of sensible queries only weakly constrains themanner in which their values are defined.Their third objection concerns multiple inheritance.
They draw attention to thefact that DATR's normal mode of multiple inheritance is orthogonal and complainthat prioritized multiple inheritance can only be expressed with additional DATR code(p. 63).
However, we agree with their earlier comment "that orthogonal multiple de-fault inheritance is at this stage the best solution for conflicts" (p. 61) and can seeno computational linguistic motivation for equipping DATR with a further primitiveinheritance mechanism, s3Their fourth objection consists of the claim that "it is not possible in DATR to havecomplex structured objects as values" (p. 64).
In one sense this is true, since DATR val-ues are simply sequences of atoms.
But although true, it does not provide support fora sound objection.
DATR can construct those sequences of atoms on the basis of a com-plex recursive description, and the atom sequences themselves can represent complexrecursive objects so far as NLP system components outside the lexicon are concerned.The sequences of atoms that DATR provides as values constitute an interface for thelexicon that is entirely neutral with respect o the representational requirements ofexternal components.
For what is intended to be a general-purpose lexical knowledgerepresentation language, not tied to any particular conceptions of linguistic structureor NLP formalism, this neutrality seems to us to be a feature, not a bug.In a fifth objection, they note correctly that the semantics of paths in DATR andPATR is different but then go on to claim that DATR paths "could be better describedas atomic attributes" that "do not correspond with a recursive structure" and whose"only function is to support prefix matching" (p. 64).
None of these latter claimsare true.
If DATR paths were atomic attributes then our Section 4.3, on finite-statetransducers, could not have been written; DATR paths are the same as PATR paths asfar as recursive structure is concerned; and, as we have seen throughout this paper,DATR paths have many functions in addition to prefix matching.In a final set of comments, they briefly raise various issues connected with theintegration of DATR lexicons with unification-based grammar (p. 64).
We have dealtwith these issues in earlier parts of the present paper and will not rehearse them here.
54Krieger and Nerbonne (1993) claim that "the basic insight of DATR" lies in itsuse in characterizing "the inflectional variants of a lexeme as alternative (disjunctive)realisations" (p. 135).
This claim confuses the basic insight of a very traditional ap-proach to inflectional morphology with the application of DATR in implementing thatapproach.
Elsewhere they note that "the fundamental idea in our characterisation isdue to the work in DATR, in which paradigms are treated as alternative further speci-fications of abstract lexemes" (p. 104).
Unfortunately, their own implementation f thisfundamental idea turns out to be significantly less satisfactory than that provided inthe DATR analysis to which they refer.
In order to reconstruct paradigms in their fea-ture language, they invoke distributed isjunctions (fixed-length term expressions), 5The descriptive problem with this approach, as they admit, is that "there is no wayto note that a single form in a paradigm is exceptional without respecifying the en-tire paradigm--the disjunction must be respecified as a whole .. .
there is no way to53 But see Daelemans and De Smedt (1994) for articulation ofthe methodological principle that underliesthe third objection.54 The issues are also discussed indetail by Langer and Gibbon (1992).55 Langer and Gibbon (1992) argue, at some length, that it is formally inappropriate oadd distributeddisjunction to a typed feature structure language of the kind otherwise assumed by Krieger andNerbonne.210Evans and Gazdar Lexical Knowledge Representationidentify a particular alternation within the distributed isjunction" (p. 107).
Anyonefamiliar with the way inflection works in Romance languages will immediately see thatthis is a very serious weakness.
In Latin, for example, there are many individual wordsand small subclasses of words that deviate from a major declension or conjugation injust one or two parts of the paradigm.
Under Krieger and Nerbonne's approach everysuch case will require one to "respecify the entire paradigmatic disjunction" (p. 107).This is exactly the kind of redundancy that the introduction of defaults is meant toeliminate.
56At the root of Krieger and Nerbonne's (1993) critique of DATR is a complaint hatit fails to provide all the resources of a modern, fully equipped unification grammarformalism (p. 90-91).
From our perspective, this is a bit like criticizing STANDARD MLon the grounds that it lacks the functionality provided in ADA.
Thus, for example,they complain that disjunction is missing from DATR and that nobody seems to betrying to add it to the language (p. 110).
They cite their own "extensive mploymentof \[distributed\] isjunction" (p. 110) as evidence for its utility in lexical description,apparently forgetting that their use of distributed isjunction to describe inflectionwas motivated by a desire to reconstruct a treatment of inflection that they had seenimplemented in DATR.
They provide no motivation for adding distributed isjunctionto DATR's (rather small) list of available descriptive resources because that list ofresources already allows better analyses of the phenomena they discuss than doestheir version of distributed isjunction, as noted above.They also object to the fact that use of a DATR lexicon will require an "interface"(p. 110) between the lexicon and a feature-based parser.
But, as we have seen in Sec-tion 4.7, above, such an interface will normally be trivial and required in any case(since Krieger and Nerbonne's parser must be able to access and read files that con-tain text descriptions of feature structures).
As it is, they seem happy to countenancean interface to a separate two-level morphophonemic processor (p. 103, n. 9) whereas,in DATR, the morphophonemics can be done entirely in the lexicon if one wishes.From remarks they make on pages 109 and 111 of their paper, Krieger and Ner-bonne appear to believe that it is impossible to implement a particular inflectionalanalysis of the passive in Latin in DATR.
They do not provide much of an argument,but what they do say suggests that the simple treatment of passive given in Section4.5, above, is likewise impossible.
This may be because they regard their own inter-pretation of lexical rules as "novel" (p. 113), although examples of that interpretationof lexical rules appear in earlier DATR work that they cite.Many of the points made in Nerbonne (1992) are repeated from the more accessi-ble Krieger and Nerbonne (1993) 57 and we have considered them in our discussion ofthe latter.
Some of the points from the 1992 and 1993 papers resurface in Bouma andNerbonne (1994).
Nerbonne appears to misconstrue Evans, Gazdar, and Moser (1993)as an attempt to augment DATR with re-entrancy and goes on to suggest that DATR issomehow forced to maintain that "all linguistic generalizations tend to follow the linesof morphological form" (p. 47) when, in fact, the attribute ordering used in a DATRtreatment of morphology is entirely independent of the use and ordering of those sameattributes elsewhere in the lexicon (see the discussion at the end of Section 4.1, above).Like Daelemans and van der Linden (1992), he makes some pessimistic omments56 Krieger and Nerbonne are not forced to use distributed disjunction todescribe inflectional paradigms.Their very well-equipped feature description language provides alternative analytical resources.
Whatpuzzles us is why they chose to use distributed disjunction for this purpose.
Bouma nd Nerbonne(1994) propose using lists of specified phonological forms instead.57 Although the joint 1993 paper has a later publication date, it appears to have been written first.211Computational Linguistics Volume 22, Number 2about the integration of a DATR lexicon with feature-based grammars.
Some of theseare effectively dealt with elsewhere in this paper, but two of them need to be notedhere.
He asserts that if a rich feature formalism is encoded in DATR then "distinctionsmust be lost."
It is not clear from the context exactly which distinctions he has in mindor what the basis for the claim is, but the expressions ofall existing feature formalismscan be represented by sequences of atoms (and thus by DATR values) and all existinglexicons for feature-based NLP systems use such representations.
We therefore findthe claim deeply implausible.
He also asserts that the fact that an atom may meanone thing in the semantics of DATR and something quite different in the semanticsof a feature formalism will lead to "massive redundancy" (p. 47) in lexical specifica-tions (the phrase gets repeated in Bouma and Nerbonne 1994).
Again, no argument insupport of this conclusion is offered.
And we cannot see how semantic overloadingof atoms gives rise, of itself, to any kind of redundancy, s8 Indeed, those who designprogramming languages normally introduce semantic overloading in order to achieveeconomy of expression.Finally, Bouma and Nerbonne (1994, 47) comment that "in spite of Kilgarriff's(1993) interesting work on modelling some derivational relations in the pure inher-itance machinery of DATR, we know of no work attempting to model potentiallyrecursive derivational relations, and we remain sceptical about relying on inheritancealone for this."
We are not sure what they mean by "the pure inheritance machineryof DATR" or why they think that someone attempting an analysis of recursive deriva-tion in DATR would want to do so using "pure inheritance" alone.
Here is a trivial(and linguistically rather pointless) DATR analysis of the more complex of their twoexamples:Word:<V> == "<>"<a f rom n> == <n> + a l<v  f rom a> == <a> + i ze<n f rom v> == <v> + t ion .Ins t i tu te :<> == Word<root> == ins t i tu te .From this description we can derive theorems like these:I ns t i tu te :<root> : ins t i tu te<n f rom v root> = ins t i tu te  + t ion<a f rom n f rom v root> =ins t i tu te  + t ion  + a l<v  f rom a f rom n f rom v root> =ins t i tu te  + t ion  + a l  + i ze<n f rom v f rom a f rom n f rom v root> =ins t i tu te  + t ion  + a l  + i ze  + t ion .Note the recursive reintroduction of the -tion suffix in the last theorem shown.58 Sacks (1973) makes interesting reading in this connection.212Evans and Gazdar Lexical Knowledge RepresentationAcknowledgmentsWe are grateful to the four ComputationalLinguistics referees for their criticisms andsuggestions; to Lynne Cahill, DafyddGibbon, Jim Kilbury and David Weir fortheir comments on an earlier draft of thepaper; and to Walter Daelemans and JohnNerbonne for their comments on the firstdraft of the appendix.
We thank Petra Barg,Lynne Cahill, Norman Fraser, DafyddGibbon, Elizabeth Jenkins, Jim Kilbury,Lionel Moser, and Ingrid Renz for theirrole(s) in the development of the DATRlanguage and the coding techniquesdiscussed above; Fernando Pereira for earlycritical comments that led directly to theintroduction of evaluable paths into thelanguage; and Bill Keller and David Weirfor much relevant recent interaction.
Thisresearch was supported by various grants tothe authors from ESRC (UK) andSERC/EPSRC (UK).ReferencesAndry, Francois, Norman Fraser, ScottMcGlashan, Simon Thornton, and NickYoud.
1992 Making DATR work forspeech: Lexicon compilation in SUNDIAl_.Computational Linguistics 18:245-267.Barg, Petra.
1994.
Automatic acquisition ofDATR theories from observations.Theories des Lexicons: Arbeiten desSonder forschungsbereichs 282,Heinrich-Heine University of Duesseldorf.Bleiching, Doris.
1992.
Prosodisches Wissenin Lexicon.
In G. Goerz, editor,Proceedings ofKONVENS-92, Berlin:Springer-Verlag, pages 59--68.Bleiching, Doris.
1994.
Integration vonMorphophonologie und Prosodie in einhierarchisches Lexicon.
In Harald Trost,editor, Proceedings ofKONVENS-94, pages32-41, Vienna: OesterreichischeGesellschaft uer Artificial Intelligence.Bouma, Gosse.
1993.
Nonmonotonicity andCategorial Unification Grammar.Proefschrift, Rijksuniversiteit Groningen.Bouma, Gosse and John Nerbonne.
1994.Lexicons for feature-based systems.
InHarald Trost, editor, Proceedings ofKONVENS-94, pages 42-51, Vienna:Oesterreichische G sellschaft uerArtificial Intelligence.Briscoe, Ted and Ann Copestake.
1991.Sense extensions as lexical rules.
InD.
Fass, E. Hinkelman & J. Martin,editors.
Computational approaches toNon-Literal Language, Proceedings oftheIJCAI Workshop, ages 12-20, Sydney.Briscoe, Ted, Ann Copestake, and AlexLascarides.
1995.
Blocking.
In PatrickSaint-Dizier & Evelyne Viegas, editors.Computational Lexical Semantics.Cambridge: Cambridge University Press,pages 272-302.Briscoe, Ted, Valeria de Paiva, and AnnCopestake, ditors.
1993.
Inheritance,Defaults, and the Lexicon, Cambridge:Cambridge University Press.Brown, Dunstan and Andrew Hippisley.1994.
Conflict in Russian genitive pluralassignment: A solution represented inDATR.
Journal of Slavic Linguistics,2(1):48-76.Cahill, Lynne.
1993a.
Some reflections onthe conversion of the TIC lexicon intoDATR.
In Ted Briscoe, Valeria de Paiva,and Ann Copestake, ditors.
Inheritance,Defaults, and the Lexicon.
Cambridge:Cambridge University Press, pages 47-57.Cahill, Lynne.
1993b.
Morphonology in thelexicon.
Sixth Conference ofthe EuropeanChapter of the Association for ComputationalLinguistics, pages 87-96.Cahill, Lynne.
1994.
An inheritance-basedlexicon for message understandingsystems.
Fourth ACL Conference on AppliedNatural Language Processing, pages211-212.Cahill, Lynne and Roger Evans.
1990.
Anapplication of DATR: The TIC lexicon.
InProceedings ofthe 9th European Conference onArtificial Intelligence, pages 120-125,Stockholm.Calder, Jo.
1994.
Feature-value logics: Somelimits on the role of defaults.
InC. J. Rupp, M. A. Rosner, & R. L. Johnson,editors.
Constraints, Language andComputation.
London: Academic Press,pages 205-222.Carpenter, Bob.
1991.
The generative powerof categorial grammars and head-drivenphrase structure grammars with lexicalrules.
Computational Linguistics 17:301-313.Carpenter, Bob.
1992.
Categorial grammars,lexical rules, and the English predicative.In Robert Levine, editor.
Formal Grammar:Theory and Implementation.
New York:Oxford University Press, pages 168-242.Copestake, Ann.
1992.
The representation flexical semantic information.
Ph.D.dissertation, University of Sussex,Cognitive Science Research Paper CSRP 280.Copestake, Ann and Ted Briscoe.
1992.Lexical operations in a unification basedframework.
In James Pustejovsky &Sabine Bergler, editors.
Lexical Semantics213Computational Linguistics Volume 22, Number 2and Knowledge Representation.
Berlin:Springer-Verlag, pages 101-119.Copestake, Ann and Ted Briscoe.
1995.Regular polysemy and semi-productivesense extension.
Journal of Semantics12:15--67.Corbett, Greville and Norman Fraser.
1993.Network Morphology: A DATR accountof Russian nominal inflection.
Journal ofLinguistics 29:113-142.Daelemans, Walter.
1994. Review ofInheritance, Defaults, and the Lexicon, by TedBriscoe, Valeria de Paiva & AnnCopestake, ditors.
ComputationalLinguistics 20(4):661-664.Daelemans, Walter and Koenraad De Smedt.1994.
Inheritance in an object-orientedrepresentation f linguistic categories.International Journal of Human-ComputerStudies 41(1/2):149-177.Daelemans, Walter, Koenraad De Smedt,and Gerald Gazdar.
1992.
Inheritance innatural anguage processing.Computational Linguistics 18(2):205-218.Daelemans, Walter and Gerald Gazdar,editors.
1992.
Computational Linguistics18(2) and 18(3), special issues oninheritance.Daelemans, Walter and Erik-Jan van derLinden.
1992.
Evaluation of lexicalrepresentation formalisms.
In Jan vanEijck & Wilfried Meyer, editors.Computational Linguistics in the Netherlands:Papers from the Second CLIN Meeting, pages54--67, Utrecht: OTS.Domenig, Marc and Pius ten Hacken.
1992.Word Manager: A System for MorphologicalDictionaries.
Hidesheim: Georg OlmsVerlag.Duda, Markus and Gunter Gebhardi.
1994.DUTR--A DATR-PATR interfaceformalism.
In Harald Trost, editor.Proceedings ofKONVENS-94, pages411-414, Vienna: OesterreichischeGesellschaft uer Artificial Intelligence.Evans, Roger and Gerald Gazdar.
1989a.Inference in DATR.
Fourth Conference oftheEuropean Chapter of the Association forComputational Linguistics, pages 66-71.Evans, Roger and Gerald Gazdar.
1989b.The semantics of DATR.
In Anthony G.Cohn, editor.
Proceedings ofthe SeventhConference ofthe Society for the Study ofArtificial Intelligence and Simulation ofBehaviour, pages 79-87, London:Pitman/Morgan Kaufmann.Evans, Roger, Gerald Gazdar, and LionelMoser.
1993.
Prioritised multipleinheritance in DATR.
In Ted Briscoe,Valeria de Paiva, and Ann Copestake,editors.
Inheritance, Defaults, and theLexicon.
Cambridge: CambridgeUniversity Press, pages 38-46.Evans, Roger, Gerald Gazdar, and DavidWeir.
1995.
Encoding lexicalized treeadjoining grammars with a nonmonotonicinheritance hierarchy.
33rd Annual Meetingof the Association for ComputationalLinguistics, pages 77-84.Flickinger, Daniel P. 1987.
Lexical Rules in theHierarchical Lexicon.
Ph.D. dissertation,Stanford University.Fraser, Norman and Greville Corbett.
1995.Gender, animacy, and declensional c assassignment: A unified account forRussian.
In Geert Booij & Jaap van Marle,editors.
Year Book of Morphology 1994.Dordrecht: Kluwer, pages 123-150.Fraser, Norman and Greville Corbett.
Inpress.
Gender assignment in Arapesh: ANetwork Morphology analysis.
Lingua.Fraser, Norman and Richard Hudson.
1990.Word Grammar: An inheritance-basedtheory of language.
In Walter Daelemans& Gerald Gazdar, editors.
Proceedings ofthe Workshop on Inheritance inNaturalLanguage Processing, pages 58-64, Tilburg:Institute for Language Technology.Gazdar, Gerald.
1992.
Paradigm functionmorphology in DATR.
In Lynne Cahill &Richard Coates, editors.
Sussex Papers inGeneral and Computational Linguistics.Brighton, University of Sussex, CognitiveScience Research Paper CSRP 239, pages43-53.Gibbon, Dafydd.
1990.
Prosodic associationby template inheritance.
In WalterDaelemans & Gerald Gazdar, editors.Proceedings ofthe Workshop on Inheritance inNatural Language Processing, pages 65-81,Tilburg: Institute for LanguageTechnology.Gibbon, Dafydd.
1992.
I/EX: A linguisticapproach to computational lexica.
InUrsula Klenk, editor.
Computatio Linguae:Aufsaze zur algorithmischen u dquantitativen Analyse der Sprache (Zeitschriftfur Dialektologie und Linguistik, Beiheft 73),Stuttgart: Franz Steiner Verlag, pages32-53.Gibbon, Dafydd.
1993.
Generalized DATRfor flexible lexical access: PROLOGspecification.
Bielefeld: Verbmobil Report 2.Gibbon, Dafydd and Doris Bleiching.
1991.An ILEX model for German compoundstress in DATR.
Proceedings oftheFORWISS-ASL Workshop on Prosody inMan-Machine Communication, pages 1-6.Ide, Nancy, Jacques Le Maitre, and JeanV4ronis.
1994.
Outline of a model forlexical databases.
In Antonio Zampolli,Nicoletta Calzolari, and Martha Palmer,214Evans and Gazdar Lexical Knowledge Representationeditors.
Current Issues in ComputationalLinguistics: In Honour of Don Walker.
Pisa:Kluwer, pages 283-320.Kaplan, Ronald M. and Martin Kay.
1994.Regular models of phonological rulesystems.
Computational Linguistics20(3):331-378.Keller, William.
1995.
DATR theories andDATR models.
33rd Annual Meeting of theAssociation for Computational Linguistics,pages 55-62.Kilbury, James.
1993.
Strict inheritance andthe taxonomy of lexical types in DATR.Unpublished manuscript, University ofDuesseldorf.Kilbury, James, Petra \[Barg\] Naerger, andIngrid Renz.
1991.
DATR as a lexicalcomponent for PATR.
Fifth Conference oftheEuropean Chapter of the Association forComputational Linguistics, pages 137-142.Kilbury, James, Petra \[Barg\] Naerger,.
andIngrid Renz.
1994.
Simulationlexicalischen Erwerbs.
In Sascha W. Felix,Christopher Habel, and Gert RickheitKognitive Linguistik: Repraesentation undProzesse.
Opladen: Westdeutscher Verlag,pages 251-271.Kilgarriff, Adam.
1993.
Inheriting verbalternations.
Sixth Conference oftheEuropean Chapter of the Association forComputational Linguistics, pages 213-221.Kilgarriff, Adam.
1995.
Inheriting polysemy.In Patrick Saint-Dizier & Evelyne Viegas,editors.
Computational Lexical Semantics.Cambridge: Cambridge University Press.Kilgarriff, Adam and Gerald Gazdar.
1995.Polysemous relations.
In E R. Palmer,editor.
Grammar and Meaning: Essays inHonour of Sir John Lyons.
Cambridge:Cambridge University Press, pages 1-25.Krieger, Hans-Ulrich.
1994.
Derivationwithout lexical rules.
In C. J. Rupp,M.
A. Rosner, and R. L. Johnson, editors.Constraints, Language and Computation.London: Academic Press, pages 277-313.Krieger, Hans-Ulrich and John Nerbonne.1993.
Feature-based inheritance networksfor computational lexicons.
In TedBriscoe, Valeria de Paiva, and AnnCopestake, ditors.
Inheritance, Defaults,and the Lexicon.
Cambridge: CambridgeUniversity Press, pages 90-136.Krieger, Hans-Ulrich, Hannes Pirker, andJohn Nerbonne.
1993.
Feature-basedallomorphy.
31st Annual Meeting of theAssociation for Computational Linguistics,pages 140-147.Langer, Hagen.
1994.
Reverse queries inDATR.
COLING-94, pages 1089-1095.Langer, Hagen and Dafydd Gibbon.
1992.DATR as a graph representation languagefor ILEX speech oriented lexica.
TechnicalReport ASL-TR-43-92/UBI, University ofBielefeld.Lascarides, Alex, Nicholas Asher, TedBriscoe, and Ann Copestake.Forthcoming.
Order independent andpersistent typed default unification.Linguistics & Philosophy 19(1):1-89.Light, Marc.
1994.
Classification ifeature-based default inheritancehierarchies.
In Harald Trost, editor.Proceedings ofKONVENS-94, pages220-229, Vienna: OesterreichischeGesellschaft fuer Artificial Intelligence.Light, Marc, Sabine Reinhard, and MarieBoyle-Hinrichs.
1993.
INSYST: Anautomatic inserter system for hierarchicallexica.
Sixth Conference ofthe EuropeanChapter of the Association for ComputationalLinguistics, page 471.McFetridge, Paul and Aline Villavicencio.1995.
A hierarchical description of thePortuguese verb.
Proceedings ofthe XIIthBrazilian Symposium on ArtificialIntelligence, pages 302-311.Mellish, Chris and Ehud Reiter.
1993.
Usingclassification as a programming language.IJCAI-93, pages 696-701.Mitamura, Teruko and Eric H. Nyberg III.1992.
Hierarchical lexical structure andinterpretive mapping in machinetranslation.
COLING-92 Vol.
IV, pages1254-1258.Nerbonne, John.
1992.
Feature-basedlexicons--an example and a comparisonto DATR.
In Dorothee Reimann, editor.Beitrage des ASL-Lexicon-Workshops.Wandtlitz, pages 36-49.Ostler, Nicholas and B. T. S. Atkins.
1992.Predictable meaning shift: Some linguisticproperties of lexical implication rules.
InJames Pustejovsky & Sabine Bergler,editors.
Lexical Semantics and KnowledgeRepresentation.
Berlin: Springer-Verlag,pages 87-100.Penn, Gerald and Richmond Thomason.1994.
Default finite state machines andfinite state phonology.
ComputationalPhonology: Proceedings ofthe 1st Meeting ofthe ACL Special Interest Group inComputational Phonology, pages 33-42.Pulman, Stephen G. Forthcoming.Unification encodings of grammaticalnotations.
To appear in ComputationalLinguistics.Pustejovsky, James.
1991.
The generativelexicon.
Computational Linguistics17(4):409-441.Pustejovsky, James and Branimir Boguraev.1993.
Lexical knowledge representationand natural anguage processing.
Artificial215Computational Linguistics Volume 22, Number 2Intelligence 63(1-2):193-223.Reinhard, Sabine.
1990.Verarbeitungsprobleme nichtlinearerMorphologien: Umlautbeschreibung ieinem hierarchischen Lexikon.
InBurghard Rieger & Burkhard SchaederLexikon und Lexikographie.
Hildesheim:Olms Verlag, 45--61.Reinhard, Sabine and Dafydd Gibbon.
1991.Prosodic inheritance and morphologicalgeneralisations.
Fifth Conference oftheEuropean Chapter of the Association forComputational Linguistics, pages 131-136.Reiter, Ehud and Chris Mellish.
1992.
Usingclassification to generate text.
30th AnnualMeeting of the Association for ComputationalLinguistics, pages 265-272.Ritchie, Graeme D., Graham J. Russell, AlanW.
Black, and Stephen G. Pulman.
1992.Computational Morphology.
Cambridge,MA: MIT Press.Russell, Graham.
1993. Review of WordManager: A Sys tern for MorphologicalDictionaries, by Marc Domenig & Pius tenHacken.
Computational Linguistics19(4):699-700.Russell, Graham, Afzal Ballim, John Carroll,and Susan Warwick-Armstrong.
1992.
Apractical approach to multiple defaultinheritance for unification-based lexicons.Computational Linguistics 183:311-337.Sacks, Harvey.
1973.
On some puns withsome intimations.
In Roger W. Shuy,editor.
Report of the 23rd Annual RoundtableMeeting on Linguistics and Language Studies.Washington D.C.: Georgetown UniversityPress, pages 135-144.Shieber, Stuart M. 1986.
An Introduction toUnification Approaches toGrammar.Stanford: CSLI/Chicago University Press.Stump, Greg.
1992.
On the theoretical statusof position class restrictions oninflectional affixes.
In Geert Booij & Jaapvan Marle, editors.
Year Book of Morphology1991.
Dordrecht: Kluwer, pages 211-241.Touretzky, David S. 1986.
The Mathematics ofInheritance Systems.
London/Los Altos:Pitman/Morgan Kaufmann.Young, Mark A.
1992.
Nonmonotonic sortsfor feature structures.
AAAI-92, pages596--601.Young, Mark A. and Bill Rounds.
1993.
Alogical semantics for nonmonotonic sorts.Proceedings ofthe 31st Annual Meeting of theACL, pages 209-215.216
