Keyword-based Document ClusteringSeung-Shik KangSchool of Computer Science, Kookmin University & AITrcChungnung-dong, Songbuk-gu, Seoul 136-702, Koreasskang@kookmin.ac.krAbstract1Document clustering is an aggregation ofrelated documents to a cluster based on thesimilarity evaluation task between documents andthe representatives of clusters.
Terms and theirdiscriminating features of terms are the clue tothe clustering and the discriminating features arebased on the term and document frequencies.Feature selection method on the basis offrequency statistics has a limitation to theenhancement of the clustering algorithm becauseit does not consider the contents of the clusterobjects.
In this paper, we adopt a content-basedanalytic approach to refine the similaritycomputation and propose a keyword-basedclustering algorithm.
Experimental results showthat content-based keyword weightingoutperforms frequency-based weighting method.Keywords: Document Clustering, WeightingScheme, Feature Selection1 IntroductionDocument clustering is an aggregation ofdocuments by discriminating the relevant documentsfrom the irrelevant documents.
The relevancedetermination criteria of any two documents is asimilarity measure and the representatives of thedocuments [1,2,3,4].
There are some similaritymeasures such as Dice coefficient, Jaccard?scoefficient, and cosine measure.
These similaritymeasures require that the documents are representedin document vectors and the similarity of twodocuments is calculated from the operation ofdocument vectors.In general, the representatives of a document or acluster are document vectors that consist of <term,weight> pairs and the document similarities aredetermined by the terms and their weighting valuesthat are extracted from the document [7,9].
In theprevious studies on the document clustering, wefocused on the clustering algorithm, but the documentThis work was supported by the Korea Science and EngineeringFoundation(KOSEF) through the Advanced InformationTechnology Research Center(AITrc).representation methodology was not the importantissue.
Document vectors are simply constructed fromthe term frequency (TF) and the inverted documentfrequency (IDF).
This representation of term weightingmethod starts from the precondition that terms orkeywords representing the document are calculated byTF-IDF.
Term weighting method by TF-IDF isgenerally used to construct a document vector, but wecannot say that it is the best way of representing adocument.
So, we suppose that there is a limitation toimprove the accuracy of the clustering system only byimproving the clustering algorithm without changingthe document/cluster representation method.Also, document clustering requires a large amount ofmemory spaces to keep the representatives ofdocuments/clusters and the similarity measures [6, 8,10].
Given N documents to be clustered, N ?
Nsimilarity matrix is needed to store document similaritymeasures.
Also, the recursive iteration of similaritycalculation and reconstructing the representative of theclusters need a huge number of computations.In this paper, we propose a new clustering methodthat is based on the keyword weighting approach.
Theclustering algorithm starts from the seed documentsand the cluster is expanded by the keyword relationship.The evolution of the cluster stops when no moredocuments are added to the cluster and irrelevantdocuments are removed from the cluster candidates.2 Keyword-based Weighting SchemeIn general, the construction of a document vectordepends on the term frequency and documentfrequency.
If keywords are determined by frequencyinformation of the document, we are apt to generate anerror that nouns are often used regardless of substanceof the document and the words of a high frequency areextracted.
The clustering method, which is focused onsimilarity calculation considers the whole words exceptstopwords as the representative of the document, andconstitutes a document vector that is calculated by theweight value from the term frequency and documentfrequency.It is common that terms and their weight valuesrepresent a document and <term, weight> pairs are theunique elements of the document vector.
When weconstruct a document vector, term frequency anddocument frequency are the most important features tocalculate the weight of a term.
As for the terms andtheir weight values, the weight value of a term meansa ranking score just as an importance factor to thedocument.
So, the term weighting can be seen as anevaluation of the term as a keyword or a stopword tothe document.
The weighting function w(t) from aterm to its weight is described in expression (1).w: term ?
weight       (1)w(t) = 0, if t is a stopword1, if t is a keyworda, otherwise  0 ?
a ?
1For the weighting scheme of terms, there are twopoints of views as the representation of a document:(1) a discriminative value that distinguishes orcharacterizes the document from others;(2) an importance measure as a keyword or astopword.Frequency-based term weighting (FBW) is astatistical measure of terms in an inter-documentrelationship.
This weighting scheme is a very efficientmethod for distinguishing and characterizing adocument from others, and it performs well for theapplications of document classification or clusteringin the information retrieval system.
The onlyevaluation measure to characterize a document infrequency-based weighting scheme is a frequencystatistics, but term frequencies are not the bestmeasures to characterize the document by terms.Another weighting scheme is a keyword-based termweighting (KBW) method that is based on thekeyword importance factors in a document.
It is ananalytic approach that analyses the contents of adocument to get a keyword list from the document.The weight value of a word is calculated by theimportance factors as a keyword in a document.
Theweight value of a word is a combination value ofkeyword-weighting factors and the terms are orderedby the keyword ranking score.
The ranking scores inthis weighting scheme are calculated from the analysisresults of the document.
Keyword-based termweighting will be a good solution to overcome thelimitation of the frequency-based weighting scheme.Keywords in a text are the terms that represent adocument and the candidate keywords are extractedfrom the analysis results of the document.
Keywordranking method depends on several factors of a termsuch as the type of a document, the location and therole of words in a sentence or a paragraph [5].Thematic words of a document are representativeterms for the document.
Thematic words are extractedfrom a text by analysing the contents of the text, butkeyword extraction depends on the type of text.Keywords are easily found in the title or an abstract ina research paper that consists of a title, abstract, body,experiment, and conclusion.
Also, newspaper articlecontains a keyword in the title or the first part of thetext.
There are some clues of determining a keywordand we may classify them as word level, sentence level,paragraph level, and text level features.
Word-levelfeatures are the type of part-of-speech and case-roleinformation.
The part-of-speech of Korean noun isdivided into common noun, compound noun, propernoun, and numeral.Syntactic or sentence-level features are the type of aphrase or a clause, sentence location, and sentence type.From the rhetoric word in a sentence, the importance ofthe sentence is computed and the terms in a sentenceare affected by the type of a sentence.
Also, theweighting scheme of a term in the subjective clause isnot the equal to the same term that appeared in anauxiliary clause or in a modifying clause.
Basic termweight is assigned by the type of a term andrecomputed by the features that it accompanies in thetext.
That is, the weight value of a term is alsodetermined by the characteristics of word, sentence,phrase, and clause where the term is extracted.3 Keyword-based Document ClusteringKeyword-based document clustering creates acluster by the keywords of each document.
Supposethat C is a set of clusters that is finally created by theclustering algorithm.
If n is the number of clusters in C,then C is a set of clusters , , ?
, C .
1C 2C nC = { C , , ?
, C } 1 2C nEach cluster  is initialised by document d that isnot assigned to the existing clusters, and d is a seeddocument of .
When a new cluster is created,expansion and reduction steps are repeated until itreaches a stable state from the start state.
In eachevolution steps for cluster ,  is the j-th state of.iCiCiCjiCiCjiC : the j-th state of a cluster C  iThe characteristic vector of a cluster is a set of<keyword, weight value> pairs that represents thecluster.
If  is a keyword set of a documentandiis a keyword set of cluster , theniis the j-th state of cluster .
Figure 1 shows akeyword-based clustering algorithm for the cluster .Given the keyword sets for each document, clusteris created by the self-expanding algorithm.DK DjCKiCiCCK iCiC3.1 Cluster InitialisationThe first step of the clustering algorithm is a creationand initialisation of a new cluster.
A document  isselected that does not belong to any other cluster, and itis assigned to a new cluster  that is an initial stateD0iCof cluster .
iC}D?=C=alls =(iffor+j0}{0 DCi =At this time, a document  that is the first documentin the new cluster is called a seed document (or aninitialisation document).
The seed document israndomly selected among the documents that do notbelong to the clusters  ~ .
Keyword setof a document D is a set of keywords kD1C0iC1?iCDK 1, k2,?,kn that are extracted from document .
The initialstate of keyword set  is initialised by .DK DKDC KK i =0DK  = { k | k is a keyword that is extracted from D }{0 DCi =0C KK i =1=iC  { Dx | document Dx, where   xDKk ?0for }  that suchiCKkk ?
?1=j{dojixDjC CDKK xi ?
where,jj+1iiCbegin for  xjiCD ?j),( Cx iKDsim)thresholds <C  }{11 xjiji DC ?= ++end1=j)()(} cumentisDeleteDowhilejii CC =Figure 1.
Keyword-based clustering algorithm3.2 Expanding the ClusterIn the initialisation step of the cluster, a newcluster , an initial state of cluster C , isestablished as the seed document, and the keyword setiis initialised by the key word set of the seeddocument.
In the expanding step of the cluster, thecluster is expanded by adding more related documentsto the cluster, that include the keywords of the seeddocument as the related documents of the seeddocument.
That is, adding the total documents thatappear each keyword ofi(the keyword extractedfrom the seed document) to the clusterC that is thenext state of cluster C  expands the cluster.iC i0CK0CK1ii}0iCjCjiCjiC1+i|xDK?jCKxD?0Cwhere,jijiCji{1   ,i KkkC ?=The cluster expansion is performed by the iterationof keyword expansion and cluster expansion.
Moredocuments are added to a cluster by the similarityevaluation between the keyword set and the document.If a new document is added to a cluster, then thekeywords in the added document are also added to thekeyword set of the cluster.
The first expansion isperformed by the keyword set extracted from the seeddocument.
The second expansion is performed by newkeywords that are added to a cluster as a result of thefirst expansion.
And the i-th expansion is performed bythe (i-1)-th state of the keyword set.The number of iterations is decided through theexperiment.
When a cluster is expanded from  to, the keyword setiis also expanded to a newkeyword setithat appears in the total documentsof the cluster .
The keyword setiof  is aunion of the total keyword sets of .0iCjiC1iC K1CK1iC KjiCxDiC DK xi ?=The keyword setiof the cluster  is used tocalculate the characteristic vector of each cluster.
Thecharacteristic vector is constituted the weight valuecalculated by term frequency (TF) and inverteddocument frequency (IDF) of the keywords and this isused to calculate the similarity measure between adocument and the cluster.3.3 Cluster Reduction and CompletionThis step is to produce a complete cluster byremoving the documents that are not related to thecluster.
For the cluster C , documents of a lowsimilarity to the cluster are removed, that are notrelated to a cluster C  through the similaritycomputation with the cluster .
The result of clusterreduction is a filtering of documents that are not relatedto the cluster, and the cluster  is generated as anext step of the cluster C .
Ultimately, the clusteris completed that consists of the related documentsafter filtering the non-related documents.
If a clusteris completed, the next cluster C  is createdthrough the same process.
Clustering is terminated ifall the documents are clustered or no more clusters arecreated.ji1+jiCiCiCFigure 2.
Overall architecture of keyword-based clustering4 Design and ImplementationThe structure of a keyword-based clustering systemis shown in Figure 2.
At first, keywords are extractedfrom each input document and the weight values ofthem are computed.
Keywords and their scores arestored in an inverted-file structure.
Inverted-filestructure is a good for the expansion of the cluster andadding the documents that includes a keyword to theinitial cluster.
Figure 3 shows an example of theoperation of the document clustering system:initialization, expansion, reduction, and completion ofclusters.A new cluster is created and it includes a seeddocument D. An initial set of keywords for the initialstate of a cluster is a keyword set KD of document D.KD = { T1,D, T2,D, ?, Ti,D ?, Tn,D }For the terms in KD, documents that contain the sameterm are added as a candidate document in the cluster.Let the candidate documents be D1a, D1b, ?
, D2a, D2b,?, Dna, Dnb, ?.
then Dxy, is a document that isexpanded by term Tx.
Keyword set of the cluster isreconstructed by new set of documents.In each step of the cluster expansion, the number ofkeywords that are used for the expansion, and thethreshold of the weight value are decided throughexperiments considering the maximum number ofdocument candidates in a cluster.
Also, <keyword,weight> pairs as an intermediate representative of thecluster are much important factor of the clusterexpansion.aaa DnDDTTT ,,2,1 ,, Lbbb DnDDTTT ,,2,1 ,,, Lzzz DnDDTTT ,,2,1 ,,, LInput DocumentKeyword Extractioncreate inverted-filecreate clusterCreate Inverted-FileInit.
Cluster Keyword setT1,D,T2,D,?Tn,D,DCreate a ClusterExpand Clusterexpand clusterReduce/Complete ClusterD1a, D1b, ?D2a, D2b, ?,,Dna, Dnb, ?,Clusterscomplete clusterresultD1A, D1B, ?D2A, D2B, ?,,DnA, DnB, ?Figure 3.
Example of keyword-basedclusteringNow, a new keyword set that is limited to the clustercandidates is constructed to get cluster documents.Through the similarity calculation between thedocument and the candidate centroid of the cluster,relevant documents are selected to be a member of thecluster.
Through the iterations on keyword selectionand the reconstruction of the related documents, a newcluster is completed that reaches in a stable status witha strong relationship between keyword set anddocument set.5 The ExperimentsWe implemented our clustering algorithm andapplied it to the clustering of similar documents.
Thetest documents for the experiment are collected fromthe three days of newspaper articles.
The total numberof articles is 383 and average 132 terms are extractedfrom the articles.
We performed a document clusteringby applying the difference criteria for term selection: 1)frequency-based term selection; 2) percentage-basedkeyword selection; and 3) keyword selection byabsolute number of keywords.
Figure 4 shows theresult of similarity clustering by frequency-based termselection.
In this experiment, three types of termselection are performed.- all terms are used to the clustering- terms with more than frequency 2- terms with more than frequency 3In each experiment, we varied the similarity decisionratio by the percentage of term matches.
Figure 4shows that term selection by frequency 2 or 3 is notgood for the representation of a document.0.60.70.80.940% 50% 60% 70% 80% 90%te rm  m a tc h  ra t iof-measure F req.
2 Freq.
3All termsFigure 4.
Frequency-based keyword selection0.60.70.80.940% 50% 60% 70% 80% 90%term match ratiof-measure10%20%30%40%50%60%70%80%90%100%Figure 5.
Percentage-based keywordselectionIn the experiment of percentage-based keywordselection, terms of high weight values are selected forthe similarity calculation of the document.
All thecurves in Figure 5 are a similar shape, except for 10 %selection.
In case of 10% selection, we guess that lessthan 10% of keywords are not sufficient for thesimilarity decision and auxiliary keywords are alsoneeded for the accuracy.
Another point in thisexperiment is that 30%~60% keyword selectionresulted better than the selection of all terms.We compared the F1-measure for the selection ofmaximum keywords.
All the experiments in Figure 6resulted better than the experiment of using all theterms in the document.
Also, 30~70 keywords with60%~70% match ratio resulted a good performance forthe comparison of document similarity.0.60.70.80.940% 50% 60% 70% 80% 90%term match ratiof-measure2030405060708090100Al termsFigure 6.
Keyword selection by maximum6 ConclusionIt is common that clustering algorithm is based onthe similarity computation by frequency-basedstatistics to aggregate the related documents.
Thismetric is an important factor for term weighting.
Weproposed a term weighting method that is based on thekeyword features and we tried to complement thedrawback of frequency-based metric.
Based on thekeyword weighting scheme, documents of the samekeywords are grouped into a cluster candidate and anew cluster is created by removing irrelevantdocuments.
We performed an experiment for theclustering of similar documents and the results showedthat keyword-based weighting scheme is better than thefrequency-based method.Our keyword-based algorithm is using 30%~60% ofterms for a clustering and the similarity matrix is not anecessity that it will be good for the clustering of ahuge number of documents.
We also expect that thisalgorithm will be good for the topic tracking of specialevents.
In the experiment, we randomly selected a seeddocument and it is a bit sensitive for the seed document.So, our next research will be focused on minimizingthe effect of the seed document by gettingrepresentative keywords before starting the clustering.References[1] Anderberg, M. R., ?Cluster Analysis for Applications?,New York: Academic, 1973.
[2] Can, F., and E. A. Ozkarahan, ?Dynamic ClusterMaintenance?, Information Processing & Management,Vol.
25, pp.275-291, 1989.
[3] Dubes, R., and A. K. Jain, ?Clustering Methodologies inExploratory Data Analysis?, Advances in Computers,Vol.
19, pp.113-227, 1980.
[4] Frakes, W. B. and R. Baeza-Yates, Information Retrieval,Prentice Hall, 1992.
[5] Kang, S. S., H. G. Lee, S. H. Son, G. C. Hong, and B. J.Moon, ?Term Weighting Method by Postposition andCompound Noun Recognition?, Proceedings of 13thConference on Korean Language Computing, pp.196-198, 2001.
[6] Murtagh, F., ?Complexities of Hierarchic ClusteringAlgorithms: State of the Art?, Computational StatisticsQuarterly, Vol.
1, pp.101-113, 1984.
[7] Perry, S. A., and P. Willett, ?A Review of the Use ofInverted Files for Best Match Searching in InformationRetrieval Systems?, Journal of Information Science, Vol.6, pp.59-66, 1983.
[8] Sibson, R. ?SLINK: an Optimally Efficient Algorithmfor the Single-Link Cluster Method?, Computer Journal,Vol.
16, pp.328-342, 1973.
[9] Willett, P., ?Document Clustering Using an Inverted FileApproach?, Journal of Information Science, Vol.
2,pp.223-231, 1980.
[10] Willett, P., ?Recent Trends in Hierarchic DocumentClustering: A Critical Review?, Information Processingand Management, Vol.
24, No.5, pp.577- 597, 1988.
