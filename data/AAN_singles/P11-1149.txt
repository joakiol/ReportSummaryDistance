Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 1486?1495,Portland, Oregon, June 19-24, 2011. c?2011 Association for Computational LinguisticsConfidence Driven Unsupervised Semantic ParsingDan Goldwasser ?
Roi Reichart ?
James Clarke ?
Dan Roth ?
?Department of Computer Science, University of Illinois at Urbana-Champaign{goldwas1,clarkeje,danr}@illinois.edu?Computer Science and Artificial Intelligence Laboratory, MITroiri@csail.mit.eduAbstractCurrent approaches for semantic parsing takea supervised approach requiring a consider-able amount of training data which is expen-sive and difficult to obtain.
This supervisionbottleneck is one of the major difficulties inscaling up semantic parsing.We argue that a semantic parser can be trainedeffectively without annotated data, and in-troduce an unsupervised learning algorithm.The algorithm takes a self training approachdriven by confidence estimation.
Evaluatedover Geoquery, a standard dataset for thistask, our system achieved 66% accuracy, com-pared to 80% of its fully supervised counter-part, demonstrating the promise of unsuper-vised approaches for this task.1 IntroductionSemantic parsing, the ability to transform NaturalLanguage (NL) input into a formal Meaning Repre-sentation (MR), is one of the longest standing goalsof natural language processing.
The importance ofthe problem stems from both theoretical and practi-cal reasons, as the ability to convert NL into a formalMR has countless applications.The term semantic parsing has been used ambigu-ously to refer to several semantic tasks (e.g., se-mantic role labeling).
We follow the most commondefinition of this task: finding a mapping betweenNL input and its interpretation expressed in a well-defined formal MR language.
Unlike shallow se-mantic analysis tasks, the output of a semantic parseris complete and unambiguous to the extent it can beunderstood or even executed by a computer system.Current approaches for this task take a data drivenapproach (Zettlemoyer and Collins, 2007; Wong andMooney, 2007), in which the learning algorithm isgiven a set of NL sentences as input and their cor-responding MR, and learns a statistical semanticparser ?
a set of parameterized rules mapping lex-ical items and syntactic patterns to their MR. Givena sentence, these rules are applied recursively to de-rive the most probable interpretation.Since semantic interpretation is limited to the syn-tactic patterns observed in the training data, in or-der to work well these approaches require consider-able amounts of annotated data.
Unfortunately an-notating sentences with their MR is a time consum-ing task which requires specialized domain knowl-edge and therefore minimizing the supervision ef-fort is one of the key challenges in scaling semanticparsers.In this work we present the first unsupervisedapproach for this task.
Our model compensatesfor the lack of training data by employing a selftraining protocol based on identifying high confi-dence self labeled examples and using them to re-train the model.
We base our approach on a sim-ple observation: semantic parsing is a difficult struc-tured prediction task, which requires learning a com-plex model, however identifying good predictionscan be done with a far simpler model capturing re-peating patterns in the predicted data.
We presentseveral simple, yet highly effective confidence mea-sures capturing such patterns, and show how to usethem to train a semantic parser without manually an-notated sentences.Our basic premise, that predictions with high con-fidence score are of high quality, is further used toimprove the performance of the unsupervised train-1486ing procedure.
Our learning algorithm takes an EM-like iterative approach, in which the predictions ofthe previous stage are used to bias the model.
Whilethis basic scheme was successfully applied to manyunsupervised tasks, it is known to converge to asub optimal point.
We show that by using confi-dence estimation as a proxy for the model?s pre-diction quality, the learning algorithm can identifya better model compared to the default convergencecriterion.We evaluate our learning approach and modelon the well studied Geoquery domain (Zelle andMooney, 1996; Tang and Mooney, 2001), consist-ing of natural language questions and their prologinterpretations used to query a database consistingof U.S. geographical information.
Our experimentalresults show that using our approach we are able totrain a good semantic parser without annotated data,and that using a confidence score to identify goodmodels results in a significant performance improve-ment.2 Semantic ParsingWe formulate semantic parsing as a structured pre-diction problem, mapping a NL input sentence (de-noted x), to its highest ranking MR (denoted z).
Inorder to correctly parametrize and weight the pos-sible outputs, the decision relies on an intermediaterepresentation: an alignment between textual frag-ments and their meaning representation (denoted y).Fig.
1 describes a concrete example of this termi-nology.
In our experiments the input sentences xare natural language queries about U.S. geographytaken from the Geoquery dataset.
The meaning rep-resentation z is a formal language database query,this output representation language is described inSec.
2.1.The prediction function, mapping a sentence to itscorresponding MR, is formalized as follows:z?
= Fw(x) = arg maxy?Y,z?ZwT?
(x,y, z) (1)Where ?
is a feature function defined over an inputsentence x, alignment y and output z.
The weightvector w contains the model?s parameters, whosevalues are determined by the learning process.We refer to the arg max above as the inferenceproblem.
Given an input sentence, solving this in-How many states does the Colorado river run through?count( state( traverse( river( const(colorado))))xzyFigure 1: Example of an input sentence (x), meaning rep-resentation (z) and the alignment between the two (y) forthe Geoquery domainference problem based on ?
and w is what com-promises our semantic parser.
In practice the pars-ing decision is decomposed into smaller decisions(Sec.
2.2).
Sec.
4 provides more details about thefeature representation and inference procedure used.Current approaches obtain w using annotateddata, typically consisting of (x, z) pairs.
In Sec.
3 wedescribe our unsupervised learning procedure, that ishow to obtain w without annotated data.2.1 Target Meaning RepresentationThe output of the semantic parser is a logical for-mula, grounding the semantics of the input sen-tence in the domain language (i.e., the Geoquerydomain).
We use a subset of first order logic con-sisting of typed constants (corresponding to specificstates, etc.)
and functions, which capture relationsbetween domains entities and properties of entities(e.g., population : E ?
N ).
The seman-tics of the input sentence is constructed via func-tional composition, done by the substitution oper-ator.
For example, given the function next to(x)and the expression const(texas), substitutionreplaces the occurrence of the free variable xwith the expression, resulting in a new formula:next to(const(texas)).
For further detailswe refer the reader to (Zelle and Mooney, 1996).2.2 Semantic Parsing DecisionsThe inference problem described in Eq.
1 selects thetop ranking output formula.
In practice this decisionis decomposed into smaller decisions, capturing lo-cal mapping of input tokens to logical fragments andtheir composition into larger fragments.
These deci-sions are further decomposed into a feature repre-sentation, described in Sec.
4.The first type of decisions are encoded directly bythe alignment (y) between the input tokens and theircorresponding predicates.
We refer to these as first1487order decisions.
The pairs connected by the align-ment (y) in Fig.
1 are examples of such decisions.The final output structure z is constructed bycomposing individual predicates into a completeformula.
For example, consider the formula pre-sented in Fig.
1: river( const(colorado))is a composition of two predicates river andconst(colorado).
We refer to the compositionof two predicates, associated with their respectiveinput tokens, as second order decisions.In order to formulate these decisions, we intro-duce the following notation.
c is a constituent in theinput sentence x and D is the set of all function andconstant symbols in the domain.
The alignment y isa set of mappings between constituents and symbolsin the domain y = {(c, s)} where s ?
D.We denote by si the i-th output predicate compo-sition in z, by si?1(si) the composition of the (i?1)-th predicate on the i-th predicate and by y(si) the in-put word corresponding to that predicate accordingto the alignment y.3 Unsupervised Semantic ParsingOur learning framework takes a self training ap-proach in which the learner is iteratively trained overits own predictions.
Successful application of thisapproach depends heavily on two important factors- how to select high quality examples to train themodel on, and how to define the learning objectiveso that learning can halt once a good model is found.Both of these questions are trivially answeredwhen working in a supervised setting: by using thelabeled data for training the model, and defining thelearning objective with respect to the annotated data(for example, loss-minimization in the supervisedversion of our system).In this work we suggest to address both of theabove concerns by approximating the quality ofthe model?s predictions using a confidence measurecomputed over the statistics of the self generatedpredictions.
Output structures which fall close to thecenter of mass of these statistics will receive a highconfidence score.The first issue is addressed by using examples as-signed a high confidence score to train the model,acting as labeled examples.We also note that since the confidence score pro-vides a good indication for the model?s predictionperformance, it can be used to approximate the over-all model performance, by observing the model?s to-tal confidence score over all its predictions.
Thisallows us to set a performance driven goal for ourlearning process - return the model maximizing theconfidence score over all predictions.
We describethe details of integrating the confidence score intothe learning framework in Sec.
3.1.Although using the model?s prediction score (i.e.,wT?
(x,y, z)) as an indication of correctness is anatural choice, we argue and show empirically, thatunsupervised learning driven by confidence estima-tion results in a better performing model.
Thisempirical behavior also has theoretical justification:training the model using examples selected accord-ing to the model?s parameters (i.e., the top rank-ing structures) may not generalize much further be-yond the existing model, as the training exampleswill simply reinforce the existing model.
The statis-tics used for confidence estimation are different thanthose used by the model to create the output struc-tures, and can therefore capture additional informa-tion unobserved by the prediction model.
This as-sumption is based on the well established idea ofmulti-view learning, applied successfully to manyNL applications (Blum and Mitchell, 1998; Collinsand Singer, 1999).
According to this idea if twomodels use different views of the data, each of themcan enhance the learning process of the other.The success of our learning procedure hingeson finding good confidence measures, whose confi-dence prediction correlates well with the true qualityof the prediction.
The ability of unsupervised confi-dence estimation to provide high quality confidencepredictions can be explained by the observation thatprominent prediction patterns are more likely to becorrect.
If a non-random model produces a predic-tion pattern multiple times it is likely to be an in-dication of an underlying phenomenon in the data,and therefore more likely to be correct.
Our specificchoice of confidence measures is guided by the intu-ition that unlike structure prediction (i.e., solving theinference problem) which requires taking statisticsover complex and intricate patterns, identifying highquality predictions can be done using much simplerpatterns that are significantly easier to capture.In the reminder of this section we describe our1488Algorithm 1 Unsupervised Confidence drivenLearningInput: Sentences {xl}Nl=1,initial weight vector w1: define Confidence : X ?
Y ?
Z ?
R,i = 0, Si = ?2: repeat3: for l = 1, .
.
.
, N do4: y?, z?
= arg maxy,zwT?
(xl,y, z)5: Si = Si ?
{xl, y?, z?
}6: end for7: Confidence = compute confidence statistics8: Sconfi = select from Si using Confidence9: wi ?
Learn(?iSconfi )10: i = i+ 111: until Sconfi has no new unique examples12: best = arg maxi(?s?SiConfidence(s))/|S|13: return wbestlearning approach.
We begin by introducing theoverall learning framework (Sec.
3.1), we then ex-plain the rational behind confidence estimation overself-generated data and introduce the confidencemeasures used in our experiments (Sec.
3.2).
Weconclude with a description of the specific learningalgorithms used for updating the model (Sec.
3.3).3.1 Unsupervised Confidence-Driven LearningOur learning framework works in an EM-likemanner, iterating between two stages: making pre-dictions based on its current set of parameters andthen retraining the model using a subset of the pre-dictions, assigned high confidence.
The learningprocess ?discovers?
new high confidence trainingexamples to add to its training set over multiple it-erations, and converges when the model no longeradds new training examples.While this is a natural convergence criterion, itprovides no performance guarantees, and in practiceit is very likely that the quality of the model (i.e., itsperformance) fluctuates during the learning process.We follow the observation that confidence estima-tion can be used to approximate the performance ofthe entire model and return the model with the high-est overall prediction confidence.We describe this algorithmic framework in detailin Alg.
1.
Our algorithm takes as input a set ofnatural language sentences and a set of parametersused for making the initial predictions1.
The algo-rithm then iterates between the two stages - predict-ing the output structure for each sentence (line 4),and updating the set of parameters (line 9).
Thespecific learning algorithms used are discussed inSec.
3.3.
The training examples required for learn-ing are obtained by selecting high confidence exam-ples - the algorithm first takes statistics over the cur-rent predicted set of output structures (line 7), andthen based on these statistics computes a confidencescore for each structure, selecting the top rankedones as positive training examples, and if needed,the bottom ones as negative examples (line 8).
Theset of top confidence examples (for either correct orincorrect prediction), at iteration i of the algorithm,is denoted Sconfi .
The exact nature of the confidencecomputation is discussed in Sec.
3.2.The algorithm iterates between these two stages,at each iteration it adds more self-annotated exam-ples to its training set, learning therefore convergeswhen no new examples are added (line 11).
The al-gorithm keeps track of the models it trained at eachstage throughout this process, and returns the onewith the highest averaged overall confidence score(lines 12-13).
At each stage, the overall confidencescore is computed by averaging over all the confi-dence scores of the predictions made at that stage.3.2 Unsupervised Confidence EstimationConfidence estimation is calculated over a batch ofinput (x) - output (z) pairs.
Each pair decomposesinto smaller first order and second order decisions(defined Sec.
2.2).
Confidence estimation is done bycomputing the statistics of these decisions, over theentire set of predicted structures.
In the rest of thissection we introduce the confidence measures usedby our system.Translation Model The first approach essentiallyconstructs a simplified translation model, capturingword-to-predicate mapping patterns.
This can beconsidered as an abstraction of the prediction model:we collapse the intricate feature representation into1Since we commit to the max-score output prediction, ratherthan summing over all possibilities, we require a reasonable ini-tialization point.
We initialized the weight vector using simple,straight-forward heuristics described in Sec.
5.1489high level decisions and take statistics over these de-cisions.
Since it takes statistics over considerablyless variables than the actual prediction model, weexpect this model to make reliable confidence pre-dictions.
We consider two variations of this ap-proach, the first constructs a unigram model over thefirst order decisions and the second a bigram modelover the second order decisions.
Formally, given aset of predicted structures we define the followingconfidence scores:Unigram Score:p(z|x) =|z|?i=1p(si|y(si))Bigram Score:p(z|x) =|z|?i=1p(si?1(si)|y(si?1), y(si))Structural Proportion Unlike the first approachwhich decomposes the predicted structure into in-dividual decisions, this approach approximates themodel?s performance by observing global propertiesof the structure.
We take statistics over the propor-tion between the number of predicates in z and thenumber of words in x.Given a set of structure predictions S, we com-pute this proportion for each structure (denoted asProp(x, z)) and calculate the average proportionover the entire set (denoted as AvProp(S)).
Theconfidence score assigned to a given structure (x,y)is simply the difference between its proportion andthe averaged proportion, or formallyPropScore(S, (x, z)) = AvProp(S)?Prop(x, z)This measure captures the global complexity of thepredicted structure and penalizes structures whichare too complex (high negative values) or too sim-plistic (high positive values).Combined The two approaches defined abovecapture different views of the data, a natural questionis then - can these two measures be combined to pro-vide a more powerful estimation?
We suggest a thirdapproach which combines the first two approaches.It first uses the score produced by the latter approachto filter out unlikely candidates, and then ranks theremaining ones with the former approach and selectsthose with the highest rank.3.3 Learning AlgorithmsGiven a set of self generated structures, the param-eter vector can be updated (line 9 in Alg.
1).
Weconsider two learning algorithm for this purpose.The first is a binary learning algorithm, whichconsiders learning as a classification problem, thatis finding a set of weights w that can best sepa-rate correct from incorrect structures.
The algo-rithm decomposes each predicted formula and itscorresponding input sentence into a feature vector?
(x,y, z) normalized by the size of the input sen-tence |x|, and assigns a binary label to this vector2.The learning process is defined over both positiveand negative training examples.
To accommodatethat we modify line 8 in Alg.
1, and use the con-fidence score to select the top ranking examples aspositive examples, and the bottom ranking examplesas negative examples.
We use a linear kernel SVMwith squared-hinge loss as the underlying learningalgorithm.The second is a structured learning algorithmwhich considers learning as a ranking problem, i.e.,finding a set of weights w such that the ?gold struc-ture?
will be ranked on top, preferably by a largemargin to allow generalization.The structured learn-ing algorithm can directly use the top ranking pre-dictions of the model (line 8 in Alg.
1) as trainingdata.
In this case the underlying algorithm is a struc-tural SVM with squared-hinge loss, using hammingdistance as the distance function.
We use the cutting-plane method to efficiently optimize the learningprocess?
objective function.4 ModelSemantic parsing as formulated in Eq.
1 is an in-ference procedure selecting the top ranked outputlogical formula.
We follow the inference approachin (Roth and Yih, 2007; Clarke et al, 2010) andformalize this process as an Integer Linear Program(ILP).
Due to space consideration we provide a briefdescription, and refer the reader to that paper formore details.2Without normalization longer sentences would have moreinfluence on binary learning problem.
Normalization is there-fore required to ensure that each sentence contributes equally tothe binary learning problem regardless of its length.14904.1 InferenceThe inference decision (Eq.
1) is decomposed intosmaller decisions, capturing mapping of input to-kens to logical fragments (first order) and their com-position into larger fragments (second order).
Weencode a first-order decision as ?cs, a binary vari-able indicating that constituent c is aligned with thelogical symbol s. A second-order decision ?cs,dt, isencoded as a binary variable indicating that the sym-bol t (associated with constituent d) is an argumentof a function s (associated with constituent c).
Weframe the inference problem over these decisions:Fw(x) = arg max?,?
?c?x?s?D?cs ?wT?1(x, c, s)+?c,d?x?s,t?D?cs,dt ?wT?2(x, c, s, d, t) (2)We restrict the possible assignments to the deci-sion variables, forcing the resulting output formulato be syntactically legal, for example by restrictingactive ?-variables to be type consistent, and forcethe resulting functional composition to be acyclic.We take advantage of the flexible ILP framework,and encode these restrictions as global constraintsover Eq.
2.
We refer the reader to (Clarke et al,2010) for a full description of the constraints used.4.2 FeaturesThe inference problem defined in Eq.
(2) uses twofeature functions: ?1 and ?2.First-order decision features ?1 Determining ifa logical symbol is aligned with a specific con-stituent depends mostly on lexical information.Following previous work (e.g., (Zettlemoyer andCollins, 2005)) we create a small lexicon, mappinglogical symbols to surface forms.3 Existing ap-proaches rely on annotated data to extend the lexi-con.
Instead we rely on external knowledge (Milleret al, 1990) and add features which measure the lex-ical similarity between a constituent and a logicalsymbol?s surface forms (as defined by the lexicon).3The lexicon contains on average 1.42 words per functionand 1.07 words per constant.Model DescriptionINITIAL MODEL Manually set weights (Sec.
5.1)PRED.
SCORE normalized prediction (Sec.
5.1)ALL EXAMPLES All top structures (Sec.
5.1)UNIGRAM Unigram score (Sec.
3.2)BIGRAM Bigram score (Sec.
3.2)PROPORTION Words-predicate prop (Sec.
3.2)COMBINED Combined estimators (Sec.
3.2)RESPONSE BASED Supervised (binary) (Sec.
5.1)SUPERVISED Fully Supervised (Sec.
5.1)Table 1: Compared systems and naming conventions.Second-order decision features ?2 Second orderdecisions rely on syntactic information.
We usethe dependency tree of the input sentence.
Givena second-order decision ?cs,dt, the dependency fea-ture takes the normalized distance between the headwords in the constituents c and d. In addition, a setof features indicate which logical symbols are usu-ally composed together, without considering theiralignment to the text.5 ExperimentsIn this section we describe our experimental evalua-tion.
We compare several confidence measures andanalyze their properties.
Tab.
1 defines the namingconventions used throughout this section to refer tothe different models we evaluated.
We begin by de-scribing our experimental setup and then proceed todescribe the experiments and their results.
For thesake of clarity we focus on the best performing mod-els (COMBINED using BIGRAM and PROPORTION)first and discuss other models later in the section.5.1 Experimental SettingsIn all our experiments we used the Geoquerydataset (Zelle and Mooney, 1996), consisting of U.S.geography NL questions and their correspondingProlog logical MR. We used the data split describedin (Clarke et al, 2010), consisting of 250 queries forevaluation purposes.
We compared our system toseveral supervised models, which were trained us-ing a disjoint set of queries.
Our learning systemhad access only to the NL questions, and the log-ical forms were only used to evaluate the system?sperformance.
We report the proportion of correctstructures (accuracy).
Note that this evaluation cor-1491responds to the 0/1 loss over the predicted structures.Initialization Our learning framework requires aninitial weight vector as input.
We use a straight for-ward heuristic and provide uniform positive weightsto three features.
This approach is similar in spiritto previous works (Clarke et al, 2010; Zettlemoyerand Collins, 2007).
We refer to this system as INI-TIAL MODEL throughout this section.Competing Systems We compared our system toseveral other systems:(1) PRED.
SCORE: An unsupervised frame-work using the model?s internal prediction score(wT?
(x,y, z)) for confidence estimation.
(2) ALL EXAMPLES: Treating all predicted struc-tures as correct, i.e., at each iteration the model istrained over all the predictions it made.
The re-ported score was obtained by selecting the model atthe training iteration with the highest overall confi-dence score (see line 12 in Alg.
1).
(3) RESPONSE BASED: A natural upper bound toour framework is the approach used in (Clarke et al,2010).
While our approach is based on assessingthe correctness os the model?s predictions accordingto unsupervised confidence estimation, their frame-work is provided with external supervision for thesedecisions, indicating if the predicted structures arecorrect.
(4) SUPERVISED: A fully supervised frameworktrained over 250 (x, z) pairs using structured SVM.5.2 ResultsOur experiments aim to clarify three key points:(1) Can a semantic parser indeed be trained with-out any form of external supervision?
this is ourkey question, as this is the first attempt to approachthis task with an unsupervised learning protocol.4 Inorder to answer it, we report the overall performanceof our system in Tab.
2.The manually constructed model INITIALMODELachieves a performance of 0.22.
We can expectlearning to improve on this baseline.
We com-pare three self-trained systems, ALL EXAMPLES,PREDICTIONSCORE and COMBINED, which differ4While unsupervised learning for various semantic tasks hasbeen widely discussed, this is the first attempt to tackle this task.We refer the reader to Sec.
6 for further discussion of this point.in their sample selection strategy, but all use con-fidence estimation for selecting the final seman-tic parsing model.
The ALL EXAMPLES approachachieves an accuracy score of 0.656.
PREDICTION-SCORE only achieves a performance of 0.164 us-ing the binary learning algorithm and 0.348 us-ing the structured learning algorithm.
Finally, ourconfidence-driven technique COMBINED achieved ascore of 0.536 for the binary case and 0.664 for thestructured case, the best performing models in bothcases.
As expected, the supervised systems RE-SPONSE BASED and SUPERVISED achieve the bestperformance.These results show that training the model withtraining examples selected carefully will improvelearning - as the best performance is achieved withperfect knowledge of the predictions correctness(RESPONSE BASED).
Interestingly the differencebetween the structured version of our system andthat of RESPONSE BASED is only 0.07, suggestingthat we can recover the binary feedback signal withhigh precision.
The low performance of the PRE-DICTIONSCORE model is also not surprising, and itdemonstrates one of the key principles in confidenceestimation - the score should be comparable acrosspredictions done over different inputs, and not thesame input, as done in PREDICTIONSCORE model.
(2) How does confidence driven sample selectioncontribute to the learning process?
Comparingthe systems driven by confidence sample-selectionto the ALL EXAMPLES approach uncovers an inter-esting tradeoff between training with more (noisy)data and selectively training the system with higherquality examples.
We argue that carefully select-ing high quality training examples will result in bet-ter performance.
The empirical results indeed sup-port our argument, as the best performing model(RESPONSE BASED) is achieved by sample selec-tion with perfect knowledge of prediction correct-ness.
The confidence-based sample selection system(COMBINED) is the best performing system out ofall the self-trained systems.
Nonetheless, the ALLEXAMPLES strategy performs well when comparedto COMBINED, justifying a closer look at that aspectof our system.We argue that different confidence measures cap-ture different properties of the data, and hypothe-1492size that combining their scores will improve the re-sulting model.
In Tab.
3 we compare the results ofthe COMBINED measure to the results of its individ-ual components - PROPORTION and BIGRAM.
Wecompare these results both when using the binaryand structured learning algorithms.
Results showthat using the COMBINED measure leads to an im-proved performance, better than any of the individ-ual measures, suggesting that it can effectively ex-ploit the properties of each confidence measure.
Fur-thermore, COMBINED is the only sample selectionstrategy that outperforms ALL EXAMPLES.
(3) Can confidence measures serve as a goodproxy for the model?s performance?
In the unsu-pervised settings we study the learning process maynot converge to an optimal model.
We argue thatby selecting the model that maximizes the averagedconfidence score, a better model can be found.
Wevalidate this claim empirically in Tab.
4.
We com-pare the performance of the model selected usingthe confidence score to the performance of the fi-nal model considered by the learning algorithm (seeSec.
3.1 for details).
We also compare it to the bestmodel achieved in any of the learning iterations.Since these experiments required running thelearning algorithm many times, we focused on thebinary learning algorithm as it converges consider-ably faster.
In order to focus the evaluation on theeffects of learning, we ignore the initial model gen-erated manually (INITIAL MODEL) in these exper-iments.
In order to compare models performanceacross the different iterations fairly, a uniform scale,such as UNIGRAM and BIGRAM, is required.
In thecase of the COMBINED measure we used the BI-GRAM measure for performance estimation, since itis one of its underlying components.
In the PRED.SCORE and PROPORTION models we used both theirconfidence prediction, and the simple UNIGRAMconfidence score to evaluate model performance (thelatter appear in parentheses in Tab.
4).Results show that the over overall confidencescore serves as a reliable proxy for the model perfor-mance - using UNIGRAM and BIGRAM the frame-work can select the best performing model, far betterthan the performance of the default model to whichthe system converged.Algorithm Supervision Acc.INITIAL MODEL ?
0.222SELF-TRAIN: (Structured)PRED.
SCORE ?
0.348ALL EXAMPLES ?
0.656COMBINED ?
0.664SELF-TRAIN: (Binary)PRED.
SCORE ?
0.164COMBINED ?
0.536RESPONSE BASEDBINARY 250 (binary) 0.692STRUCTURED 250 (binary) 0.732SUPERVISEDSTRUCTURED 250 (struct.)
0.804Table 2: Comparing our Self-trained systems withResponse-based and supervised models.
Results showthat our COMBINED approach outperforms all other un-supervised models.Algorithm AccuracySELF-TRAIN: (Structured)PROPORTION 0.6BIGRAM 0.644COMBINED 0.664SELF-TRAIN: (Binary)BIGRAM 0.532PROPORTION 0.504COMBINED 0.536Table 3: Comparing COMBINED to its components BI-GRAM and PROPORTION.
COMBINED results in a betterscore than any of its components, suggesting that it canexploit the properties of each measure effectively.Algorithm Best Conf.
estim.
DefaultPRED.
SCORE 0.164 0.128 (0.164) 0.134UNIGRAM 0.52 0.52 0.4BIGRAM 0.532 0.532 0.472PROPORTION 0.504 0.27 (0.504) 0.44COMBINED 0.536 0.536 0.328Table 4: Using confidence to approximate model perfor-mance.
We compare the best result obtained in any of thelearning algorithm iterations (Best), the result obtainedby approximating the best result using the averaged pre-diction confidence (Conf.
estim.)
and the result of us-ing the default convergence criterion (Default).
Resultsin parentheses are the result of using the UNIGRAM con-fidence to approximate the model?s performance.14936 Related WorkSemantic parsing has attracted considerable interestin recent years.
Current approaches employ variousmachine learning techniques for this task, such as In-ductive Logic Programming in earlier systems (Zelleand Mooney, 1996; Tang and Mooney, 2000) andstatistical learning methods in modern ones (Ge andMooney, 2005; Nguyen et al, 2006; Wong andMooney, 2006; Kate and Mooney, 2006; Zettle-moyer and Collins, 2005; Zettlemoyer and Collins,2007; Zettlemoyer and Collins, 2009).The difficulty of providing the required supervi-sion motivated learning approaches using weakerforms of supervision.
(Chen and Mooney, 2008;Liang et al, 2009; Branavan et al, 2009; Titov andKozhevnikov, 2010) ground NL in an external worldstate directly referenced by the text.
The NL input inour setting is not restricted to such grounded settingsand therefore we cannot exploit this form of supervi-sion.
Recent work (Clarke et al, 2010; Liang et al,2011) suggest using response-based learning proto-cols, which alleviate some of the supervision effort.This work takes an additional step in this directionand suggest an unsupervised protocol.Other approaches to unsupervised semantic anal-ysis (Poon and Domingos, 2009; Titov and Kle-mentiev, 2011) take a different approach to seman-tic representation, by clustering semantically equiv-alent dependency tree fragments, and identifyingtheir predicate-argument structure.
While these ap-proaches have been applied successfully to semantictasks such as question answering, they do not groundthe input in a well defined output language, an essen-tial component in our task.Our unsupervised approach follows a self trainingprotocol (Yarowsky, 1995; McClosky et al, 2006;Reichart and Rappoport, 2007b) enhanced with con-straints restricting the output space (Chang et al,2007; Chang et al, 2009).
A Self training proto-col uses its own predictions for training.
We esti-mate the quality of the predictions and use only highconfidence examples for training.
This selection cri-terion provides an additional view, different than theone used by the prediction model.
Multi-view learn-ing is a well established idea, implemented in meth-ods such as co-training (Blum and Mitchell, 1998).Quality assessment of a learned model output wasexplored by many previous works (see (Caruana andNiculescu-Mizil, 2006) for a survey), and appliedto several NL processing tasks such as syntacticparsing (Reichart and Rappoport, 2007a; Yates etal., 2006), machine translation (Ueffing and Ney,2007), speech (Koo et al, 2001), relation extrac-tion (Rosenfeld and Feldman, 2007), IE (Culotta andMcCallum, 2004), QA (Chu-Carroll et al, 2003)and dialog systems (Lin and Weng, 2008).In addition to sample selection we use confidenceestimation as a way to approximate the overall qual-ity of the model and use it for model selection.
Thisuse of confidence estimation was explored in (Re-ichart et al, 2010), to select between models trainedwith different random starting points.
In this workwe integrate this estimation deeper into the learningprocess, thus allowing our training procedure to re-turn the best performing model.7 ConclusionsWe introduced an unsupervised learning algorithmfor semantic parsing, the first for this task to the bestof our knowledge.
To compensate for the lack oftraining data we use a self-training protocol, drivenby unsupervised confidence estimation.
We demon-strate empirically that our approach results in a highpreforming semantic parser and show that confi-dence estimation plays a vital role in this success,both by identifying good training examples as wellas identifying good over all performance, used toimprove the final model selection.In future work we hope to further improve un-supervised semantic parsing performance.
Particu-larly, we intend to explore new approaches for confi-dence estimation and their usage in the unsupervisedand semi-supervised versions of the task.Acknowledgments We thank the anonymous re-viewers for their helpful feedback.
This materialis based upon work supported by DARPA underthe Bootstrap Learning Program and Machine Read-ing Program under Air Force Research Laboratory(AFRL) prime contract no.
FA8750-09-C-0181.Any opinions, findings, and conclusion or recom-mendations expressed in this material are those ofthe author(s) and do not necessarily reflect the viewof the DARPA, AFRL, or the US government.1494ReferencesA.
Blum and T. Mitchell.
1998.
Combining labeled andunlabeled data with co-training.
In COLT.S.R.K.
Branavan, H. Chen, L. Zettlemoyer, and R. Barzi-lay.
2009.
Reinforcement learning for mapping in-structions to actions.
In ACL.R.
Caruana and A. Niculescu-Mizil.
2006.
An empiri-cal comparison of supervised l earning algorithms.
InICML.M.
Chang, L. Ratinov, and D. Roth.
2007.
Guiding semi-supervision with constraint-driven learning.
In Proc.of the Annual Meeting of the ACL.M.
Chang, D. Goldwasser, D. Roth, and Y. Tu.
2009.Unsupervised constraint driven learning for transliter-ation discovery.
In NAACL.D.
Chen and R. Mooney.
2008.
Learning to sportscast: atest of grounded language acquisition.
In ICML.J.
Chu-Carroll, J. Prager K. Czuba, and A. Ittycheriah.2003.
In question answering, two heads are better thanon.
In HLT-NAACL.J.
Clarke, D. Goldwasser, M. Chang, and D. Roth.
2010.Driving semantic parsing from the world?s response.In CoNLL, 7.M.
Collins and Y.
Singer.
1999.
Unsupervised modelsfor named entity classification.
In EMNLP?VLC.A.
Culotta and A. McCallum.
2004.
Confidence estima-tion for information extraction.
In HLT-NAACL.R.
Ge and R. Mooney.
2005.
A statistical semantic parserthat integrates syntax and semantics.
In CoNLL.R.
Kate and R. Mooney.
2006.
Using string-kernels forlearning semantic parsers.
In ACL.Y.
Koo, C. Lee, and B. Juang.
2001.
Speech recogni-tion and utterance verification based on a generalizedconfidence score.
IEEE Transactions on Speech andAudio Processing, 9(8):821?832.P.
Liang, M. I. Jordan, and D. Klein.
2009.
Learningsemantic correspondences with less supervision.
InACL.P.
Liang, M.I.
Jordan, and D. Klein.
2011.
Deep compo-sitional semantics from shallow supervision.
In ACL.F.
Lin and F. Weng.
2008.
Computing confidence scoresfor all sub parse trees.
In ACL.D.
McClosky, E. Charniak, and Mark Johnson.
2006.Effective self-training for parsing.
In HLT-NAACL.G.
Miller, R. Beckwith, C. Fellbaum, D. Gross, and K.J.Miller.
1990.
Wordnet: An on-line lexical database.International Journal of Lexicography.L.
Nguyen, A. Shimazu, and X. Phan.
2006.
Seman-tic parsing with structured svm ensemble classificationmodels.
In ACL.H.
Poon and P. Domingos.
2009.
Unsupervised semanticparsing.
In EMNLP.R.
Reichart and A. Rappoport.
2007a.
An ensemblemethod for selection of high quality parses.
In ACL.R.
Reichart and A. Rappoport.
2007b.
Self-trainingfor enhancement and domain adaptation of statisticalparsers trained on small datasets.
In ACL.R.
Reichart, R. Fattal, and A. Rappoport.
2010.
Im-proved unsupervised pos induction using intrinsicclustering quality and a zipfian constraint.
In CoNLL.B.
Rosenfeld and R. Feldman.
2007.
Using corpus statis-tics on entities to improve semi?supervised relationextraction from the web.
In ACL.D.
Roth and W. Yih.
2007.
Global inference for entityand relation identification via a linear programmingformulation.
In Lise Getoor and Ben Taskar, editors,Introduction to Statistical Relational Learning.L.
Tang and R. Mooney.
2000.
Automated constructionof database interfaces: integrating statistical and rela-tional learning for semantic parsing.
In EMNLP.L.
R. Tang and R. J. Mooney.
2001.
Using multipleclause constructors in inductive logic programming forsemantic parsing.
In ECML.I.
Titov and A. Klementiev.
2011.
A bayesian model forunsupervised semantic parsing.
In ACL.I.
Titov and M. Kozhevnikov.
2010.
Bootstrappingsemantic analyzers from non-contradictory texts.
InACL.N.
Ueffing and H. Ney.
2007.
Word-level confidence es-timation for machine translation.
Computational Lin-guistics, 33(1):9?40.Y.W.
Wong and R. Mooney.
2006.
Learning for se-mantic parsing with statistical machine translation.
InNAACL.Y.W.
Wong and R. Mooney.
2007.
Learning syn-chronous grammars for semantic parsing with lambdacalculus.
In ACL.D.
Yarowsky.
1995.
Unsupervised word sense disam-biguation rivaling supervised method.
In ACL.A.
Yates, S. Schoenmackers, and O. Etzioni.
2006.
De-tecting parser errors using web-based semantic filters.In EMNLP.J.
M. Zelle and R. J. Mooney.
1996.
Learning to parsedatabase queries using inductive logic proramming.
InAAAI.L.
Zettlemoyer and M. Collins.
2005.
Learning tomap sentences to logical form: Structured classifica-tion with probabilistic categorial grammars.
In UAI.L.
Zettlemoyer and M. Collins.
2007.
Online learning ofrelaxed CCG grammars for parsing to logical form.
InCoNLL.L.
Zettlemoyer and M. Collins.
2009.
Learning context-dependent mappings from sentences to logical form.In ACL.1495
