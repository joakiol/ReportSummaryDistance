Proceedings of the Workshop on Textual Entailment and Paraphrasing, pages 131?136,Prague, June 2007. c?2007 Association for Computational LinguisticsSemantic Inference at the Lexical-Syntactic Level for Textual EntailmentRecognitionRoy Bar-Haim?,Ido Dagan?, Iddo Greental?, Idan Szpektor?
and Moshe Friedman?
?Computer Science Department, Bar-Ilan University, Ramat-Gan 52900, Israel?Linguistics Department, Tel Aviv University, Ramat Aviv 69978, Israel{barhair,dagan}@cs.biu.ac.il,greenta@post.tau.ac.il,{szpekti,friedmm}@cs.biu.ac.ilAbstractWe present a new framework for textual en-tailment, which provides a modular integra-tion between knowledge-based exact infer-ence and cost-based approximate matching.Diverse types of knowledge are uniformlyrepresented as entailment rules, which wereacquired both manually and automatically.Our proof system operates directly on parsetrees, and infers new trees by applying en-tailment rules, aiming to strictly generate thetarget hypothesis from the source text.
In or-der to cope with inevitable knowledge gaps,a cost function is used to measure the re-maining ?distance?
from the hypothesis.1 IntroductionAccording to the traditional formal semantics ap-proach, inference is conducted at the logical level.However, practical text understanding systems usu-ally employ shallower lexical and lexical-syntacticrepresentations, augmented with partial semanticannotations.
Such practices are typically partial andquite ad-hoc, and lack a clear formalism that speci-fies how inference knowledge should be representedand applied.
The current paper proposes a step to-wards filling this gap, by defining a principled se-mantic inference mechanism over parse-based rep-resentations.Within the textual entailment setting a system isrequired to recognize whether a hypothesized state-ment h can be inferred from an asserted text t.Some inferences can be based on available knowl-edge, such as information about synonyms and para-phrases.
However, some gaps usually arise and itis often not possible to derive a complete ?proof?based on available inference knowledge.
Such sit-uations are typically handled through approximatematching methods.This paper focuses on knowledge-based infer-ence, while employing rather basic methods for ap-proximate matching.
We define a proof systemthat operates over syntactic parse trees.
New treesare derived using entailment rules, which provide aprincipled and uniform mechanism for incorporat-ing a wide variety of manually and automatically-acquired inference knowledge.
Interpretation intostipulated semantic representations, which is oftendifficult to obtain, is circumvented altogether.
Ourresearch goal is to explore how far we can get withsuch an inference approach, and identify the scopein which semantic interpretation may not be needed.For a detailed discussion of our approach and relatedwork, see (Bar-Haim et al, 2007).2 Inference FrameworkThe main contribution of the current work is a prin-cipled semantic inference mechanism, that aims togenerate a target text from a source text using en-tailment rules, analogously to logic-based proof sys-tems.
Given two parsed text fragments, termedtext (t) and hypothesis (h), the inference system (orprover) determines whether t entails h. The proverapplies entailment rules that aim to transform t intoh through a sequence of intermediate parse trees.For each generated tree p, a heuristic cost function isemployed to measure the likelihood of p entailing h.131ROOTi rain VERBexpletivessffffffffff wha++XXXXXXXXXXit OTHER when PREPi see VERBobjqqccccccccccccccccccccbessffffffffffbymod++XXXXXXXXXXMary NOUNmod be VERB by PREPpcomp?nyesterday NOUNbeautiful ADJ John NOUNROOTi rain VERBexpletiverreeeeeeeeeee wha,,YYYYYYYYYYYit OTHER when PREPi see VERBsubjrreeeeeeeeeeeobjmod,,YYYYYYYYYYYJohn NOUN Mary NOUNmod yesterday NOUNbeautiful ADJSource: it rained when beautiful Mary was seen by John yester-dayDerived: it rained when John saw beautiful Mary yesterday(a) Application of passive to active transformationLV VERBobjssffffffffffbe by++XXXXXXXXXXRV VERBsubjssffffffffff obj++XXXXXXXXXXN1 NOUN be VERB by PREPpcomp?nN2 NOUN N1 NOUNN2 NOUN(b) Passive to active transformation (substitution rule).
The dotted arc represents alignment.Figure 1: Application of inference rules.
POS and relation labels are based on Minipar (Lin, 1998b)If a complete proof is found (h was generated), theprover concludes that entailment holds.
Otherwise,entailment is determined by comparing the minimalcost found during the proof search to some threshold?.3 Proof SystemLike logic-based systems, our proof system consistsof propositions (t, h, and intermediate premises),and inference (entailment) rules, which derive newpropositions from previously established ones.3.1 PropositionsPropositions are represented as dependency trees,where nodes represent words, and hold a set of fea-tures and their values.
In our representation thesefeatures include the word lemma and part-of-speech,and additional features that may be added during theproof process.
Edges are annotated with dependencyrelations.3.2 Inference RulesAt each step of the proof an inference rule gener-ates a derived tree d from a source tree s. A ruleis primarily composed of two templates, termed left-hand-side (L), and right-hand-side (R).
Templatesare dependency subtrees which may contain vari-ables.
Figure 1(b) shows an inference rule, whereV , N1 and N2 are common variables.
L specifiesthe subtree of s to be modified, and R specifies thenew generated subtree.
Rule application consists ofthe following steps:L matching The prover first tries to match L in s.L is matched in s if there exists a one-to-one nodemapping function f from L to s, such that: (i) Foreach node u, f(u) has the same features and featurevalues as u. Variables match any lemma value inf(u).
(ii) For each edge u ?
v in L, there is anedge f(u) ?
f(v) in s, with the same dependencyrelation.
If matching fails, the rule is not applicableto s. Otherwise, successful matching induces vari-132LROOTi RROOTi V1 VERBwha V2 VERBwhen ADJi V2 VERBFigure 2: Temporal clausal modifier extraction (in-troduction rule)able binding b(X), for each variableX in L, definedas the full subtree rooted in f(X) if X is a leaf, orf(X) alone otherwise.
We denote by l the subtreein s to which L was mapped (as illustrated in boldin Figure 1(a), left tree).R instantiation An instantiation of R, which wedenote r, is generated in two steps: (i) creating acopy of R; (ii) replacing each variable X with acopy of its binding b(X) (as set during L matching).In our example this results in the subtree John sawbeautiful Mary.Alignment copying the alignment relation be-tween pairs of nodes in L and R specifies whichmodifiers in l that are not part of the rule structureneed to be copied to the generated tree r. Formally,for any two nodes u in l and v in r whose matchingnodes in L and R are aligned, we copy the daugh-ter subtrees of u in s, which are not already part ofl, to become daughter subtrees of v in r. The boldnodes in the right part of Figure 1(b) correspond tor after alignment.
yesterday was copied to r due tothe alignment of its parent verb node.Derived tree generation by rule type Our for-malism has two methods for generating the derivedtree: substitution and introduction, as specified bythe rule type.
With substitution rules, the derivedtree d is obtained by making a local modification tothe source tree s. Except for this modification s andd are identical (a typical example is a lexical rule,such as buy ?
purchase).
For this type, d is formedby copying s while replacing l (and the descendantsof l?s nodes) with r. This is the case for the passiverule.
The right part of Figure 1(a) shows the derivedtree for the passive rule application.
By contrast, in-troduction rules are used to make inferences from asubtree of s, while the other parts of s are ignoredand do not affect d. A typical example is inferenceof a proposition embedded as a relative clause in s.In this case the derived tree d is simply taken to ber.
Figure 2 presents such a rule that derives propo-sitions embedded within temporal modifiers.
Notethat the derived tree does not depend on the mainclause.
Applying this rule to the right part of Figure1(b) yields the proposition John saw beautiful Maryyesterday.3.3 Annotation RulesAnnotation rules add features to parse tree nodes,and are used in our system to annotate negation andmodality.
Annotation rules do not have an R. In-stead, nodes of L may contain annotation features.If L is matched in a tree then the annotations arecopied to the matched nodes.
Annotation rules areapplied to t and to each inferred premise prior toany entailment rule application and these featuresmay block inappropriate subsequent rule applica-tions, such as for negated predicates.4 Rules for Generic Linguistic StructuresBased on the above framework we have manuallycreated a rule base for generic linguistic phenomena.4.1 Syntactic-Based RulesThese rules capture entailment inferences associ-ated with common syntactic structures.
They havethree major functions: (i) simplification and canon-ization of the source tree (categories 6 and 7 in Ta-ble 1); (ii) extracting embedded propositions (cate-gories 1, 2, 3); (iii) inferring propositions from non-propositional subtrees (category 4).4.2 Polarity-Based RulesConsider the following two examples:John knows that Mary is here?Mary is here.John believes that Mary is here;Mary is here.Valid inference of propositions embedded as verbcomplements depends on the verb properties, andthe polarity of the context in which the verb appears(positive, negative, or unknown) (Nairn et al, 2006).We extracted from the polarity lexicon of Nairn etal.
a list of verbs for which inference is allowed inpositive polarity context, and generated entailment133# Category Example: source Example: derived1 Conjunctions Helena?s very experienced and has played a longtime on the tour.?
Helena has played a long time on the tour.2 Clausal modi-fiersBut celebrations were muted as many Iranians ob-served a Shi?ite mourning month.?
Many Iranians observed a Shi?ite mourningmonth.3 RelativeclausesThe assailants fired six bullets at the car, which car-ried Vladimir Skobtsov.?
The car carried Vladimir Skobtsov.4 Appositives Frank Robinson, a one-time manager of the Indians,has the distinction for the NL.?
Frank Robinson is a one-time manager of theIndians.5 Determiners The plaintiffs filed their lawsuit last year in U.S.District Court in Miami.?
The plaintiffs filed a lawsuit last year in U.S.District Court in Miami.6 Passive We have been approached by the investment banker.
?
The investment banker approached us.7 GenitivemodifierMalaysia?s crude palm oil output is estimated tohave risen by up to six percent.?
The crude palm oil output of Malasia is esti-mated to have risen by up to six percent.8 Polarity Yadav was forced to resign.
?
Yadav resigned.9 Negation,modalityWhat we?ve never seen is actual costs comedown.What we?ve never seen is actual costs come down.
(;What we?ve seen is actual costs come down.
)Table 1: Summary of rule base for generic linguistic structures.rules for these verbs (category 8).
The list was com-plemented with a few reporting verbs, such as sayand announce, assuming that in the news domain thespeaker is usually considered reliable.4.3 Negation and Modality Annotation RulesWe use annotation rules to mark negation andmodality of predicates (mainly verbs), based on theirdescendent modifiers.
Category 9 in Table 1 illus-trates a negation rule, annotating the verb seen fornegation due to the presence of never.4.4 Generic Default RulesGeneric default rules are used to define default be-havior in situations where no case-by-case rules areavailable.
We used one default rule that allows re-moval of any modifiers from nodes.5 Lexical-based RulesThese rules have open class lexical components, andconsequently are numerous compared to the genericrules described in section 4.
Such rules are acquiredeither lexicographically or automatically.The rules described in the section 4 are appliedwhenever their L template is matched in the sourcepremise.
For high fan-out rules such as lexical-basedrules (e.g.
words with many possible synonyms),this may drastically increase the size of the searchspace.
Therefore, the rules described below are ap-plied only if L is matched in the source premise pand R is matched in h.5.1 Lexical RulesLexical entailment rules, such as ?steal ?
take?
and?Britain ?
UK?
were created based on WordNet(Fellbaum, 1998).
Given p and h, a lexical rulelemmap ?
lemmah may be applied if lemmapand lemmah are lemmas of open-class words ap-pearing in p and h respectively, and there is a pathfrom lemmah to lemmap in the WordNet ontology,through synonym and hyponym relations.5.2 Lexical-Syntactic RulesIn order to find lexical-syntactic paraphrases and en-tailment rules, such as ?X strike Y ?
X hit Y ?
and?X buy Y ?X own Y ?
that would bridge between pand h, we applied the DIRT algorithm (Lin and Pan-tel, 2001) to the first CD of the Reuters RCV1 cor-pus1.
DIRT does not identify the entailment direc-tion, hence we assumed bi-directional entailment.We calculate off-line only the feature vector of ev-ery template found in the corpus, where each pathbetween head nouns is considered a template in-stance.
Then, given a premise p, we first mark alllexical noun alignments between p and h. Next, forevery pair of alignments we extract the path betweenthe two nouns in p, labeled pathp, and the corre-sponding path between the aligned nouns in h, la-beled pathh.
We then on-the-fly test whether thereis a rule ?pathp ?
pathh?
by extracting the storedfeature vectors of pathp and pathh and measuring1http://about.reuters.com/researchandstandards/corpus/134their similarity.
If the score exceeds a given thresh-old2, we apply the rule to p.Another enhancement that we added to DIRT istemplate canonization.
At learning time, we trans-form every template identified in the corpus intoits canonized form3 using a set of morpho-syntacticrules, similar to the ones described in Section 4.
Inaddition, we apply nominalization rules such as ?ac-quisition of Y by X ?
X acquire Y ?, which trans-form a nominal template into its related verbal form.We automatically generate these rules (Ron, 2006),based on Nomlex (Macleod et al, 1998).At inference time, before retrieving feature vec-tors, we canonize pathp into pathcp and pathh intopathch.
We then assess the rule ?pathcp ?
pathch?,and if valid, we apply the rule ?pathp ?
pathh?
top.
In order to ensure the validity of the implicature?pathp ?
pathcp ?
pathch ?
pathh?, we canonizepathp using the same rule set used at learning time,but we apply only bi-directional rules to pathh (e.g.conjunct heads are not removed from pathh).6 Approximate MatchingAs mentioned in section 2, approximate matchingis incorporated into our system via a cost function,which estimates the likelihood of h being entailedfrom a given premise p. Our cost function C(p, h) isa linear combination of two measures: lexical cost,Clex(p, h) and lexical-syntactic cost ClexSyn(p, h):C(p, h) = ?ClexSyn(p, h)+ (1??
)Clex(p, h) (1)Let m?
() be a (possibly partial) 1-1 mapping of thenodes of h to the nodes of p, where each nodeis mapped to a node with the same lemma, suchthat the number of matched edges is maximized.An edge u ?
v in h is matched in p if m?
(u)and m?
(v) are both defined, and there is an edgem?
(u) ?
m?
(v) in p, with the same dependency rela-tion.
ClexSyn(p, h) is then defined as the percentageof unmatched edges in h.Similarly, Clex(p, h) is the percentage of un-matched lemmas in h, considering only open-classwords, defined as:Clex(p, h) = 1?
?l?h Score(l)#OpenClassWords(h)(2)2We set the threshold to 0.013The active verbal form with direct modifierswhere Score(l) is 1 if it appears in p, or if it isa derivation of a word in p (according to Word-Net).
Otherwise, Score(l) is the maximal Lindependency-based similarity score between l and thelemmas of p (Lin, 1998a) (synonyms and hyper-nyms/hyponyms are handled by the lexical rules).7 System ImplementationDeriving the initial propositions t and h from the in-put text fragments consists of the following steps:(i) Anaphora resolution, using the MARS system(Mitkov et al, 2002).
Each anaphor was replaced byits antecedent.
(ii) Sentence splitting, using mxter-minator (Reynar and Ratnaparkhi, 1997).
(iii) De-pendency parsing, using Minipar (Lin, 1998b).The proof search is implemented as a depth-firstsearch, with maximal depth (i.e.
proof length) of4.
If the text contains more than one sentence, theprover aims to prove h from each of the parsed sen-tences, and entailment is determined based on theminimal cost.
Thus, the only cross-sentence infor-mation that is considered is via anaphora resolution.8 EvaluationFull (run1) Lexical (run2)Dataset Task Acc.
Avg.P Acc.
Avg.PTest IE 0.4950 0.5021 0.5000 0.5379Official IR 0.6600 0.6174 0.6450 0.6539Results QA 0.7050 0.8085 0.6600 0.8075SUM 0.5850 0.6200 0.5300 0.5927All 0.6112 0.6118 0.5837 0.6093Dev.
All 0.6443 0.6699 0.6143 0.6559Table 2: Empirical evaluation - results.The results for our submitted runs are listed in Ta-ble 2, including per-task scores.
run1 is our full sys-tem, denoted F .
It was tuned on a random sampleof 100 sentences from the development set, result-ing in ?
= 0.6 and ?
= 0.6242 (entailment thresh-old).
run2 is a lexical configuration, denoted L, inwhich ?
= 0 (lexical cost only), ?
= 0.2375 andthe only inference rules used were WordNet Lexicalrules.
We found that the higher accuracy achievedby F as compared to L might have been merely dueto a lucky choice of threshold.
Setting the thresholdto its optimal value with respect to the test set re-sulted in an accuracy of 62.4% for F , and 62.9% for135L.
This is also hinted by the very close average pre-cision scores for both systems, which do not dependon the threshold.
The last row in the table showsthe results obtained for 7/8 of the development setthat was not used for tuning, denoted Dev, using thesame parameter settings.
Again, F performs bet-ter than L. F is still better when using an optimalthreshold (which increases accuracy up to 65.3% forF and 63.9% for L. Overall, F does not show yet aconsistent significant improvement over L.Initial analysis of the results (based on Dev) sug-gests that the coverage of the current rules is stillrather low.
Without approximate matching (h mustbe fully proved using the entailment rules) the re-call is only 4.3%, although the precision (92%) isencouraging.
Lexical-syntactic rules were appliedin about 3% of the attempted proofs, and in mostcases involved only morpho-syntactic canonization,with no lexical variation.
As a result, entailment wasdetermined mainly by the cost function.
Entailmentrules managed to reduce the cost in about 30% of theattempted proofs.We have qualitatively analyzed a subset of falsenegative cases, to determine whether failure to com-plete the proof is due to deficient components ofthe system or due to higher linguistic and knowl-edge levels.
For each pair, we assessed the reasoningsteps a successful derivation of h from t would take.We classified each pair according to the most de-manding type of reasoning step it would require.
Weallowed rules that are presently unavailable in oursystem, as long as they are similar in power to thosethat are currently available.
We found that whilethe single dominant cause for proof failure is lackof world knowledge, e.g.
the king?s son is a mem-ber of the royal family, the combination of miss-ing lexical-syntactic rules and parser failures equallycontributed to proof failure.9 ConclusionWe defined a novel framework for semantic infer-ence at the lexical-syntactic level, which allows aunified representation of a wide variety of inferenceknowledge.
In order to reach reasonable recall onRTE data, we found that we must scale our rule ac-quisition, mainly by improving methods for auto-matic rule learning.AcknowledgmentsWe are grateful to Cleo Condoravdi for making thepolarity lexicon developed at PARC available forthis research.
We also wish to thank Ruslan Mitkov,Richard Evans, and Viktor Pekar from University ofWolverhampton for running the MARS system forus.
This work was partially supported by ISF grant1095/05, the IST Programme of the European Com-munity under the PASCAL Network of ExcellenceIST-2002-506778, the Israel Internet Association(ISOC-IL) grant 9022 and the ITC-irst/University ofHaifa collaboration.ReferencesRoy Bar-Haim, Ido Dagan, Iddo Greental, and EyalShnarch.
2007.
Semantic inference at the lexical-syntactic level.
In AAAI (to appear).Christiane Fellbaum, editor.
1998.
WordNet: An Elec-tronic Lexical Database.
Language, Speech and Com-munication.
MIT Press.Dekang Lin and Patrik Pantel.
2001.
Discovery of infer-ence rules for question answering.
Natural LanguageEngineering, 4(7):343?360.Dekang Lin.
1998a.
Automatic retrieval and clusteringof similar words.
In Proceedings of COLING/ACL.Dekang Lin.
1998b.
Dependency-based evaluation ofminipar.
In Proceedings of the Workshop on Evalua-tion of Parsing Systems at LREC.C.
Macleod, R. Grishman, A. Meyers, L. Barrett, andR.
Reeves.
1998.
Nomlex: A lexicon of nominal-izations.
In EURALEX.Ruslan Mitkov, Richard Evans, and Constantin Orasan.2002.
A new, fully automatic version of Mitkov?sknowledge-poor pronoun resolution method.
In Pro-ceedings of CICLing.Rowan Nairn, Cleo Condoravdi, and Lauri Karttunen.2006.
Computing relative polarity for textual infer-ence.
In Proceedings of ICoS-5.Jeffrey C. Reynar and Adwait Ratnaparkhi.
1997.
Amaximum entropy approach to identifying sentenceboundaries.
In Proceedings of ANLP.Tal Ron.
2006.
Generating entailment rules based ononline lexical resources.
Master?s thesis, ComputerScience Department, Bar-Ilan University, Ramat-Gan,Israel.136
