RESEARCH IN NATURAL LANGUAGE PROCESSINGUniversity of PennsylvaniaDepartment of Computer and Information ScienceThis a brief reportpublications.FACULTYSTUDENTSFACILITIESsummarizing our work to date, our intermediate and long term goals, and a summary of some of ourAravind Joshi, Tim Finin, Dale Miller, Lokendra Shastri, and B?nnie WebberBrant Cheikes, John Dowding, Amy Felty, Ellen Hays, Robert Kass, Ron Katriel, Sitaram Lanka, MeganMoser, CGopalan Nadathur, MaryAngela Papalaskaris, Martha Pollack, Robert Rubinoff, Yves Schahes, EthelSchuster, Sunil Shende, Jill Smudski, Vijayshankar, David Weir, Blair WhitakerLINC (Langauge, Information, and Computation) laboratory, which consists of a dedicated VAX 11/785, I0Symbolics Lisp machines, 7 HP 68020 based AI workstations, a SUN workstation, several Macintoshes, anda laser printer.
These machines are networked together and to other esearch facilities in the department.MAJOR THRUSTNatural language interfaces providing support for many different communicative functions.?
Providing definitions of concepts* Recognizing and correcting user misconceptions* Providing explanations?
Offering to provide information later, when known?
Verifying and demonstrating understanding?
Exploiting and enriching the context of natural language discourse between user and system.WORK-TO-DATE?
Integration of RUS-TEXT-MUMBLE (RTM) - This effort involves integrating three natural anguage systemcomponents (BBN's RUS parser-interpreter, McKeown's TEXT system (developed at Penn), and McDonald'sMUMBLE system (received from U.
Mass in January 1985).
This integration of three independently developedsystems has required substantial effort.
The version of RTM (to be completed in May 1986) \[1\] accepts a limitednumber of English language requests for definitions of, descriptions of, or comparisions between terms in the ONRdatabase used by Kathy MeKeown in her development of TEXT; \[2\] formulates appropriate r ponses using TEXTand outputs those responses in English using MUMBLE; and \[3\] runs on a SYMBOLICS Lisp machine.
This workhas been done by Moser, Whitaker and Rubinoff.?
Initial work on incorporating a sense of relevance in monitor offers.
Mays' dissertation work on monitor offers waslimited to issues of competancy.
This work is being done by Cheikes and Schabes.?
Completion of McCoy's dissertation work on correcting certain types of object-related misconceptions andimplementation f a system called ROMPER which generates such corrections.
(MUMBLE is used as the tacticalgeneration component of this system as well.)?
Completion of Hirsehberg's dissertation work on scalar implicatures and their use in constructing non-misleadingresponses.?
Completion of Pollack's dissertation work on plan inference in which user's and system's beliefs about actions andplans is dccoupled.?
Continuation of work on integrating scalar-implicature-based r asoning within a general framework ofcircumscription-based non-monotonic reasoning.?
Development of methods for converting proofs in a system akin to first-order resolution into natural deduction (ND)?
proofs, which are then reorganized into cohesive paragraphs using Chester's 1976 algorithm.30?
Development of methods of converting modal resolution proofs into modal ND proofs and higher-order resolutionproofs into higher-order ND proofs.?
Initial development of domain-independant tools for expressing and reasoning about user models - in particular, fordefining hierachies of stereotypical users, representing individual users, and drawing inferences about hem using adefault logic.?
Continuation fbasic research on local coheLeuce of discourse using the notions of centering and syntax, semantics,and parsing of tree adjoining rammars.FUTURE PLANSHaving gained the experience of integrating three natural language systems and carrying out some of the basic research asdescribed in the previous ection, we have now developed the plan described below, which summarizes the near term and longterm goals.Near  Term Goa lsWe have three tangible goals for the next year:?
Completing the RTM demonstration system (using the existing domain and knowledge representation) andproducing a videotape which explains and demouslrates it.?
Developing TEXT into a more modular tool for defining and comparing terms, on the order of RUS and MUMBLE.This will eliminate its tie to a particular knowledge representation and increase its portability.?
Acquiring familiarity with the PENMAN approach to NL generation through acting as a beta-test ite for NIGEL.Long  Term Goa lsSuppor t  for NL  Def in i t ions  - Enr i ched  Knowledge  Representat ionIn our original proposal, we stated our intention of employing a richer knowle.xlge r presentation as the basis for our work on textgeneration, especially for constructing definitions.
Our original idea was to make use of BBN's NIKL systenx In the past yearthough, we have become aware of some of NIKL's limitations, which essentially make it non-optimal, even as a next step, forour text generation work.
On the other hand, we have identified several features with which a NIKL-like language could beenriched to make it more suitable for our work:?
associating non-definitional information with concepts in a way that maintains the underlying structure of thatinformation, without interferring with NIKL's automatic classification mechanism.?
associating "evidential" information with concepts, especially frequency information - how often the concept isknown to display particular features.?
allowing for what appears to be conflicting information coming down through inheritance - e.g., information that iscontrary to expectations grounded in an alternative perspective on a concept?
allowing mutual definition of concepts - each being defined with reference to the others in a set?
incorporating notions of time and change - allowing the defming properties and evidential properties of concepts toinclude how they change over time?
allowing assertions about usual relations between properties of subtypesWork on an enriched knowledge representation that includes all these features in a well-motivated way will take several years.However one that includes at least the first three of them can probably be developed over the next two years, with work onemploying it in text generation beginning after the first six months to a year after the start of that work.Suppor t  of  NL  Def in i t ions  - Use of  D iscourse  and  User  Mode lsThe TEXT system, as it is currently structured, will produce the same definition for a concept (or comparison between twoconcepts) whenever it is asked.
It does not take into account what the user may have already found out about he concept, or whatit is implicitly being contrasted with (e.g., some other concept the user has recently asked about), or what the user's goal is inmaking the request.
Hence, other directions in which we would like to take this definitional/clarificational capability is toincrease its sensitivity to (1) the discourse history, to avoid repetition and possibly to take advantage of the additional claritybrought by contrasting a new term to one explained before; (2) the user's level of expertise, to avoid either stating the obvious orgoing more deeply into a concept than the user can understand; and (33) the user's goals, to focus on those aspects of the conceptbeing defined (or concepts being compared) which are significant to the current asL (The latter is related to the notion of"perspective" used in Kathy McCoy's recent thesis here.)
For both these apects of user modelling (in contrast with the first point,which can be developed using the current discourse alone), we will draw on the other work being done here on domain-independent user-modelling mechanisms.
This proposed work must be done in a domain in which tasks can be characterized andrecognized.
Thus we plan to do this initially in investment advising dmnain that we have started to develop.
Work on31incorporating and using discourse history will involved about a one-year effort, once the knowledge base is built.
Work onincorporating and using a model of a user's expertise and goals will take more time, on the order of two to three years.Exp lanat ionsAgain in our original proposal, we proposed work on constructing atural language explanations - more specifically, on ways toloosen the current tight coupling between the form of the system's proof of some statement to the form of its explanation f whythe statement is true.
This coupling has kept systems which should be able to explain their reasoning from employing strongerproof methods which do not have a natural, understandable form of presentation to their human users.Our immediate goals involve:* developing a demonstration system which responds to NL queries posed to RUS by doing an efficient first-orderresolution-based proof, transforming that proof into an ND proof, organizing that proof according to an improvedversion of the Chester algorithm, and then producing an English version of the text using MUMBLE or NIGEL.?
abstracting from the three separate sets of proof conversion methods (noted under WORK-TO-DATE) into generalmethods of transforming any resolution-style proof in any logic into its corresponding ND proof.?
determining whether existing methods of organizing fwst-order ND proofs into paragraphs are applicable to NDproofs in these stronger logics or whether more must be done to produce high-quality, cohesive, understandable text.Our loog-term goals remain as stated in our original proposal - the production of explanations sensitive to users' beliefs,expertise, desired level of detail and expectations.
In this long-term research, we see taking expertise and desired level of detailinto account in determining how much of the ND proof is made explicit.
Of more interest is how users' beliefs and expectationsshould affect he explanations.
Work on scientific explanation has shown that central to the explanation of what is the case is aset of alternative situations which are not the case.
One explains what is in contrast to what is not.
However, this requiresadditional work.
to prove of each of the alternatives (which may be given explicitly by the user - "why this and not thatT - orinferred from the system's model of the user's expectations) that it is not true.
Our planned approach involves guiding the(failing) proof of each alternative against the successful prooL The point is that although there may be many failing proofs ofeach alternative, the most relevant of these in the current situation is the one which is analogous - up to the point of failure - tothe original successful proof not only should this technique provide relevant information, but is should also be efficient inreducing the search space.
We expect his work to take on the order of two to three years, provided we have enough resources topursue it in parallel with our more near-term goals.Natura l  Language Pars ing  and  Generat ionWhile continuing to use the RUS system, we will continue our work on tree adjoining rammar (TAG) both from the parsing andgeneration points of view.
TAGs lead to some attractive approaches to parallelizing parsing and also seem to provide naturalplanning units for generation.
This work will be integrated with our future work on parsing and generation.
Our first languagegenerator (used by TEXT) was one based on Kay's Functional Unification Grammar.
While theoretically elegant, it wasunacceptably slow (in its straightforward implementation), leading us last year to import the MUMBLE generator fromMcDonald at University of Massachusetts and adapt it to work with TEXT.
Using MUMBLE has produced a 60-fold speed-upin generation time.
However, adapting MUMBLE to work with TEXT and, independently, with two other systems has made usaware of MUMBLE's limitations, primarily its lack of knowledge of words or grammar.
EssentiaUy, MUMBLE's knowledge islimited to how to realize particular message units (i.e., to choose an acceptable one from an a priori specified set of choices),given constraints already imposed by message units that have already been realized.
The large amount of work that must beinvested in building aMUMBLE lexicon and the lack of inter-application portability of anything but the control structure comesfrom this fact - that one has to completely specify each set of choices beforehand for each message unit and the sets arecompletely application specific.
We propose to work on the development of a new architecture, including our work on tags, thatavoids these limitations by having more knowledge of syntax and words and hence is more portable between applications.
Thetime frame for this project is approximately three years.Anaphora  Reso lu t ionThe RUS parser/interpreter wereceived from BBN uses a limited method of resolving definite pronouns and noun phrases that isonly a bit more advanced than the one originally developed for BBN's LUNAR system back in 1971.
Since then, there have beenmajor theoretical dvances in our understanding of discourse anaphora (in the works of Grosz (at SRI), Joshi, Sidner (at BBN),Webber, and Weinstein), but these theoretical advances have not yet found their way into natural language understandingsystems.
We feel strongly qualified to undertake this work, having two of the major participants (Joshi and Webber) here at Pennalready, and want to do so.
For us, it is both of research interest and of practical importance, since it can mean a majorimprovement i  system's understanding abilities.
We will also integrate our work on tags with this effort as it relates to parsingand generation.
This work wiU also complement additional work being done here on a theoretical nd computational account ofanaphoric reference to actions and events.
We see this work as taking about wo to two and a half years.32User ModelingThe need for systems to model the knowledge and beliefs of their users has already been pointed out.
We plan to address anumber of issues which underly the succesful development and encorporation f explicit user models.
Our current domain-independent user-modelling system, GUMS, provides mechanisms for defining hierachies of stereotypical users, representingindividual users, and drawing inferences about hem using a rich default logic.
We will continue to develop this system as a toolwhich will support the user modeling needs of various applications.
We also plan to study the problem of bow new knowledge ofindividual users can be derived from their regular interaction - that is, how relevent information about users can be inferred fromtheir queries and responses.
In other situations itmay become necessary for the system to explicitly pose a few crucial questionsto the user to determine what he or she does and does not know.System IntegrationFinally, we plan to begin work on system integration.
In recent years, we have identified many types of behavior that interfaces todatabase systems and expert systems hould demonstrate.
Beginning with Kaplan's work on recognizing and responding toexistential presupposition failures in his COOP system, we have developed and produced several modules, each demonslratinganother type of desired behavior.
These include the ability to recognize and respond to type failures, the ability to respond toobject-related misconceptions, the ability to calculate and offer competant database monitors, the ability to use scalarimplicatures to convey additional information, and the ability to respond to a class of "inappropriate" queries, and variousparaphrase abilities.Following the publication of Kaplan's thesis, the features of his COOP system were soon incorporated into several databaseinterfaces (both natural slanguage and formal query language).
This gave the resulting systems the ability to give two types ofresponses: either a direct answer, ff there was one, or a statement concerning the abscnse of individuals atisfying somedescription i the given query.
Now we plan to tackle the more significant problem related to this:Given a system that is able to call upon a variety of response strategies, how does it decide what to do in a given circumstance?This is the issue we plan to explore by investigating the integration of multiple communicative b haviors.
Given a system withseveral different types of useful behaviors, which can be combined in various ways, can one efficiently and effectively coordinatea response that is better (i.e., more useful, more helpful and more understandable) than simply a (direct) answer.
While wespeculate that it will be the case that identifying what one might consider the best response might ake complex reasoning aboutthe user's goals, level of expertise and need-to-know with respect to what the answer (if any) actually is, we also plan to look athow, with more limited resuurees, we can still improve system behavior.This aspect of our future plans is the most long term, involving both the actual component integration itself (in which, in manycases, it is only the basic ideas that can be carried over, where the component must be re-programmed ntirely to fit into theintegrated system) and the development of that part of the total system that reasons about what kind of response(s) to give.
Thetime frame here is approximately four years.ArchitectureWe plan to investigate parallel and connectionist architectures and algorithms for realizing our systems, especially those forknowledge representation, reasoning, explanations, and integrated parsing and generation.Abstracts of Recent Technical ReportsINTERACTIVE CLASSIFICATION A Technique for the Aquisition and Maintenance ofKnowledge Bases, Tim Flnln andDavid Silverman, MS-CIS-84-17.The practical application of flame-based knowledge-based systems, such as in expert systems, requires the maintenance ofpotentially very large amounts of declarative knowledge stored in their knowledge bases (KBs).
As a KB grows in size andcomplexity, it becomes more difficult to maintain and extend.
Even someone who is familiar with the representation a d thecontents of the existing KB may introduce inconsistencies and errors whenever an addition or modification is made.This paper describes an approach to thisproblem based on a tool called an interactive classifier.
An interactive classifier uses thecontents of the existing KB and knowledge about its representation t  assist he person who is maintaining the KB in describingnew KB objects.
The interactive classifier will identify the ~ppmpriate axonomic location for the newly described object andadd it to the KB.
The new object is allowed to be a generalization f existing KB objects, enabling the system to learn moreabout existing objects.
The ideas have been tested in a system call KuBIC, for Knowledge Base Interactive Classifier, and arebeing extended to a more complete knowledge r presentation la guage.Correcting Object-Related Misconceptions: How Should The System Respond?, Kathleen F. McCoy, MS-CIS-84-1&This paper describes a computational method for correcting users' misconceptions concoming the objects modeled by a computersystem.
The method involves classifying object-related nnsconceptions according to the knowledge-base feature involved in..theincorrect information.
For each resulting class sub-types are identified, according to the structure of the knowledge base, wmcnindicate what information may be supporting the misconception a d, therefo.re, what informatio 9 to tnelufle .m the rysponse.Such a characterization, along with a model of what the user knows, enables IRe system to reason m a aomam-moepenoent wayabout how best o correct the user.33Default Reasoning in Interaction, Aravind Joshi, Bonnie Webber, and Ralph Welschedel, MS-CIS-84-58Nonmonotonic reasoning is usually studied in the context of a logical system in its own right or as reasoning done by an agent, inwhich the agent reasons about he world from partial information andhence may draw conclusions unsupported by traditionallogic.
The main point of departure here is looking at nonmonotonic reasoning in the context of interacting with another agent.This information is partial, in that the other agent neither will not can make everything explicit.
Knowing this, the agent mayattempt to derive more from the interaction than what has been made explicit, by.
reasoning by default about what has been m~?teexplicit (often by contrast with what he assumes would have been made explicit, were something else the case).
Thus there canbe rules for default reasoning that are operative m~'d~'~'~-ac~"~ situation Cinteractional defaults") that are not operative withonly a single agent.Preventing False Inferences, Aravind Josh\[, Bonnie Webber, and Ralph M.
Weischec~e!, MS..CIS.84-5~In cooperative man-machine interaction, it is taken as necessary that a system truthfully and informatively respond to a user'squestion.
It is not, however, sufficient.
In particular, if the system has reason to believe that its planned response might lead theuser to draw an inference that l~ows  to be false, then it must block it by modifying or adding to its response.
The problem isthat a system neither can nor should explore all conclusions a user might possibly draw: its re~oning must be constrained insome systematic and weU motivated way.Living Up To Expectations: Computing Expert Responses Aravind Josh\[, Bonnie Webber, and Ralph Weischedel,MS-CIS-84-60In cooperative man-machine interaction, it is necessary but not suJJiclent for a sustem to respond truthfully and informatively toa user's question.
In particular, if the system has reason to believe that its planned response might mislead the user, then it mustblock that conclusion by modifying its response.
This paper focusses on identifying and avoiding potentially misleadingresponses by acknowledging types of "informing behavior" usually expected of an expert.
We air.erupt to give a formal accountof several types of assertaUons that should be included in response to questions concerning the achievement of some goal (inaddition to the simple answer), lest the questioner otherwise be misled.A Modal Temporal Logic for Reasoning About Changing Databases with Applications to Natural Language QuestionAnswering, Eric Mays, Aravind Joshl, Bonnie Webber, MS-CIS-85-01.A database which models a changing world must evolve in correspondence to the world.
Previous work on natural languageUeStion answering systems for databases has largely ignored the issues which arise when the database is viewed as a dynamicather than a static) object.
We investigate he question answering behaviors that become possible with the ability to representand reason about hepossible evolution of a database.
These behaviors include offering to monitor for a possible future state ofthe database as an indirect response to a query, and directly answering questions about prior and futare possibility.
We apply apropositional modal temporal logic that captures possibility and temporality to represent and reason about dynamic databases,and present a sound axiomatization a d proof and proof procedure.Explaining Concepts in Expert Systems: The CLEAR System, Robert Rublnoff, MS-CIS-85-06, LINC LAB 02Existing expert systems provide limited explanatory ability.
They can explain the specific reasoning the system uses, but if theuser is confused about he concepts and terms the system is using, no help is available.
The CLEAR system allows users to askfor explanations of specific concepts.
The system generates the explanaU~ns by examining the rule base, selecting rules that arerelevant o the concept asked about.
These rules are then turned into Engfish by various simple translation schemes andpresented to the user, providing an explanation of how the concept is used by the system.The Linguistic Relevance of Tree Adjoining Grammars, Anthony S. Kroch, Department of Linguistics, and AravindK.
Joshl, Department of Computer and Information Science, MS-CIS-85-16, LINC LAB 03In this paper the linguistic significance of the Tree Adjoining Grammar (TAG) has been investigated.
An important property ofTAG is that it defines a constrained theory of syntactic embedding, one requiring that embedded structures be composed out ofelementary structures in a fixed way, and one which forces co-occurence r lations between elements that are separated in surfaceconstituent s ructures to be stated broadly as constraints on elementary trees in which those elements are copresent.
The extragenerative power of TAG beyond context-free grammar emerges as a corollary of factoring recursion and co-occurence r lations.The linguistic details pecifically discussed are raising constructions, passive, and WH-movements.A Computational Logic Approach to Syntax and Semantics Dale A. Miller and Gopalan Nadathur, MS-CIS-85-17It is well known that higher-order logics are very expensive, and for this reason have been used to represent many problems inmathematics and theoretical computer science.
In the latter domain, higher-order logics are often used to describe the semanticsof first-order logics, natural languages, or programs, since the formalization of such semantics needs a recourse to quantificationover the domain of functions and sets.
In these settings, higher-order logic has generally been limited to a descriptive role.
Oncethe formalization is made little has been made of it computationally, argely because there is abundant evidence that theoremproving in higher-order logics is very difficult.
In this paper we shall look at a sublogic of a particular higher-order logic that isderived from Church s Theory of Types, and examine its representational power and its computational tractability.
This sublogiccan also be described as Horn clauses logic extended with quantifications over function variables and R-contraction.
We shallpresent a sound and complete theorem prover for this logic, which uses higher-order unification and may be described as anextension of a unification procedure for the typed R-calculus.
There are at least three ways in which this logic is different fromthe first-order logic that it generalizes.
First l't possesses function variables which can be mstantiated with ~.-terms and evaluatedthrough ~.-contractions.
This provides the logic with a new source of computation.
Second, since Z-terms do not have mostgeneral unifiers, the process off'mding appropriate unifiers must branch, and hence involves real search.
This facet provides anew source of noncteterminism in specifying computations.
Finally, this log.ic can directly encode f'trst-order logic m its termstucture and can manipulate such terms in logically meaningful ways.
We illustrate this with examples taken from knowledgerepresentation a d natural language parsing.The Role of Perspective In Responding to Property Misconceptions, Kathleen F. McCoy, MS-CIS-85-31, May 1985In order to ad.ecluately respond to misconceptions involving an object's properties, we must have a ccontext-sensitive m thod fordetermining object similarity.
Such a method is intrnduced here.
Some of the necessary contextual information is captured by anew notion of object perspective It is shown how object perspective can be used to account for different responses to a given34misconception in different contexts.Some Computational Properties of Tree Adjoining Grammars, ViJayshenkar and Joshl, MS-CIS-85-07Tree Adjoining Grammar (TAG) is a formalism for natural language grammars.
Some of the basic notions of TAG's wereintroduced in \[Joshi,Levy, and Takahashi 1975\] and by \[Joshi, 1983\].
A detailed investigation of the linguistic relevance ofTAG's has been carried out in \[Kroch and Joshi,1985\].
In this paper, we will describe some new results for TAG's, especially inthe following areas: (1) parsing complexity of TAG's, (2) some closure results for TAG'S, and (3) the relationship to Headgrammars.Grammar, Phrase Structure, Aravtnd K. Josht, MS-CIS-85-45Phrase-slructure trees (phrase-markers) provide structural descriptions for sentences.
Phrase-structure trees can be generated byphrase-structure g ammars.
Phrase-structure trees can be shown to be appropriate to characterize structural descriptions forsentences, including those aspects which are usually characterized by transformational grammars, by making certain amendationsto CFG's, without increasing their power, or by generating them from elementary trees (phrase-markers) by a suitable rule ofcomposition, increasing the ~powcr only mildly beyond that of CFG's.
Structural descriptions provided by phrase-structure t esare used explicitly or implicltly in natural language processing systems.Uestion, Answer and Responses: Interacting with Knowledge Base Systems, Bonnie Lynn Webber, MS-CIS-85-50, LINCO4The purpose of this chapter is to examine the character of information-seeking interactions between a user and a knowledge basesystem (KBS).
In doing so, I advocate that a clear distinction be made between an answer to a c.luestion and a response.
Thechapter characterizes questions, answers, and responses, the role they play in effective information i terchanges, and what isinvolved in facilitating such interactions between user and KBS.A Theory Of Scalar Implicature,Julla Bell Hlrschberg, MS-CIS-85-56.The Relationship Between Tree Adjoining Grammars And Head Grammars, K. ViJay-Shanker, David J. Weir and AravindK.
Joshl, MS-CIS-86-01, LINC LAB 06Tree Adjoining Grammars (TAG) and Head Grammars (HG) were introduced to capture certain structural properties of naturallanguages.
These formalisms, which were developed independently, appear to be quite different notationaliy.
In this paper wediscuss the formal relationship between the class of languages generated by TAG's (TAL) and the class of languages generatedby HG's (HL).
In particular, we show that HL's are included in TAL's andthat TAG's are equivalent toa modification ofHG:scalled Modified Head Grammars (MHG's).
The inclusion of MHL in HI.,, and thus the equivalence of HG's and TAG's, in themost general case remains to be established.
We show that this relationship s very close both linguistically and formally, thedifference hinging on the status of heads of empty swings and whether one deals with heads directly or with the left and rightwrapping positions around the head.Natural Language Interactions With Artflcial Experts, Tim Finin, Aravlnd K. Jeshl and Bonnie Lynn Webber, MS-CIS-86-16, LINC LAB 08).The aim of this paper is to justify why Natural Language (NL) interaction, ofa very rich functionality, is critical to the effective] se of Expert Systems and to describe what is needed and what has been done to support such interaction.
Interactive functions iscussed here include defining terms, paraphrasing, correcting misconceptions, avoiding misconceptions and modifyingquestions.Higher.Order Logic Programming, Dale A. Miller and Gopalan Nadathur, MS-CIS-86-17In this paper we consider the problem of extending Prolog to include predicate and function variables and typed ~.-terms.
For thispurpose, we use a higher-order logic to describe a generalization to first-order Horn clauses.
We show that this extensionpossesses certain desirable computational properties.
Specifically, we show that the familiar operational nd least fixpointsemantics can be given to these clauses.
A language, ~.Prolong that is based on this generalization is then presented, and severalexamples of its use are provided.
We also discuss an interpreter for this language in which new sources of branching andbacktracking must be accommodated.
An experimental interpreter has been constructed for the language, and aLl the examples inthis paper have been tested using it.Some Uses of Higher.Order Logic in Computational Linguistics, Dale A. MiLler and Gopalan Nadathur, MS-CIS-86-31,LINC LAB 08Consideration of the question of meaning in the framework of linguistics often requires and allusion to sets and otherhigher-order notions.
The traditional approach to representing and reasoning about meaning in a computational setting has beento use knowledge representation systems that are either based on first-order logic or that use mechanisms whose formaljustifications are to be provided after the fact.
In this paper we shall consider the use of a higher-order logic for this task.
Wefirst present a version of definite clauses (positive Horn clauses) that is based on this logic.
Predicate and function variables mayoccur m such clauses the terms in the language are the typed/-terms.
Such term structures have a richness that may be exploitedin representing meanings.
We also describe a higher-order logic programming language, called /Prolog, which representsprograms as hijgher-order definite clauses and interprets them using a depth-first interpreter.
A virtue of this language is that it ispossible to write programs in it that integrate syntactic and semantic analyses into one computational paradigm.
This is to becont~'asted ~vith the more common pFactice of using two entirely different computation paradigms, such as DCGs or ATNs forparsing ann frames or semantic nets for semantic processing.
We illustrate such and integration i this language by considering astmple xample, and we claim that its use makes the task of providing formal justifications for the computations specified muchmore airect.
.Some Aspects Of Default Reasoning In Interactive Discourse, Aravlnd K. Joshl, Bonnie L. Webber and RalphM.
Weischedel, MS-CIS-86-27 (revised version of MS-CIS-84-58)In cooperative inter.action_, it is taken as necessary that a system truthfully and informatively respond to a user's question.
It isnot, however, sur.nClent.
In par~cuiar, ff the system has reason to befieve that its planned response might lead the user to draw aninference mat it knows to be false, then it must block it by modifying or adding to its response.
In this paper we investigateseveral aspects of such reasoning ininteractive discourse.35Adapting MUMBLE: Experience with N~tuml Language Generation, Robert Rublnoff, MS-CIS-86-32, LINC LAB 09}This paper describes the construction of a MUMBLE-based \[McDonald 83b tactical component for the TEXT textgeneration system \[McKeown 85\].
This new component, which produces fluent English sentences from the sequence ofstructured message units output from TEXT's strategic omponent, has produced a 60-fold speed-up in sentence production.Adapting MUMBLE required work on each of the three parts of the MUMBLE framework: the interpreter, the grammar, and thedictionary..
It also provided some insight into the generation process and the consequences of MUMBLE's commitment to adetermlmsttc model.GUMS 1 : A General User Modeling System, Tim Finin and David Drager, MS-CIS-86-35This paper describes a general architecture of a domain independent system for building and maintaining long term models ofindividual users.
The user modeling system is intended toprovide a well defined set of services for an application system whichis interacting with various users andhas a need to build andmaintain models of the-re.
As the application system interacts with auser, it can acquire knowledge of him and pass that knowledge on to the user model maintenance system for incorporation.
Wedescribe a prototype general user modeling system which we have implemented in Prolog.
This system satisfies some of thedesirable characteristics we discuss.Breaking the Primitive Concept Barrier, Robert Kass, Ron Katrlel, and Tim Finln, MS-CIS-86-36Building and maintaining a large knowledge base of general information requires a knowledge representation system with \]?recisesemantics and an easy knowledge acquisition procedure.
Systems uch as KL-ONE meet these criteria by using a classifier toinstall new concepts into a taxonomic sWacture.
These systems use a formal notion of a definition for concepts.
Unfortunately,many concepts do not seem to have such precise definittons, and end up represented as primitive concepts.
Primitive conceptsform a barrier to classification, forcing the user to manually classify a new concept with respect o all primitive concepts in theknowledge base.We propose an extension to ~NE which retains its soundness and greatly reduces the burden on the user during knowledgeacquisition.
This extension consists of adding an explicit definitional component to concepts and relaxing the strictness ofconcept definitions themselves.
The relaxed definition reduces the number primitive concepts in a knowledge base, enables theclassifier to handle concepts that do not have complete definitions and enhances the usefulness of an interactive classifier.36
