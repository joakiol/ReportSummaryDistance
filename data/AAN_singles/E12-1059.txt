Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 580?590,Avignon, France, April 23 - 27 2012. c?2012 Association for Computational LinguisticsUBY ?
A Large-Scale Unified Lexical-Semantic ResourceBased on LMFIryna Gurevych?
?, Judith Eckle-Kohler?, Silvana Hartmann?, Michael Matuschek?,Christian M. Meyer?
and Christian Wirth??
Ubiquitous Knowledge Processing Lab (UKP-DIPF)German Institute for Educational Research and Educational Information?
Ubiquitous Knowledge Processing Lab (UKP-TUDA)Department of Computer ScienceTechnische Universita?t Darmstadthttp://www.ukp.tu-darmstadt.deAbstractWe present UBY, a large-scale lexical-semantic resource combining a wide rangeof information from expert-constructedand collaboratively constructed resourcesfor English and German.
It currentlycontains nine resources in two lan-guages: English WordNet, Wiktionary,Wikipedia, FrameNet and VerbNet,German Wikipedia, Wiktionary andGermaNet, and multilingual OmegaWikimodeled according to the LMF standard.For FrameNet, VerbNet and all collabora-tively constructed resources, this is donefor the first time.
Our LMF model captureslexical information at a fine-grained levelby employing a large number of DataCategories from ISOCat and is designedto be directly extensible by new languagesand resources.
All resources in UBY canbe accessed with an easy to use publiclyavailable API.1 IntroductionLexical-semantic resources (LSRs) are the foun-dation of many NLP tasks such as word sensedisambiguation, semantic role labeling, questionanswering and information extraction.
They areneeded on a large scale in different languages.The growing demand for resources is met nei-ther by the largest single expert-constructed re-sources (ECRs), such as WordNet and FrameNet,whose coverage is limited, nor by collaborativelyconstructed resources (CCRs), such as Wikipediaand Wiktionary, which encode lexical-semanticknowledge in a less systematic form than ECRs,because they are lacking expert supervision.Previously, there have been several indepen-dent efforts of combining existing LSRs to en-hance their coverage w.r.t.
their breadth and depth,i.e.
(i) the number of lexical items, and (ii) thetypes of lexical-semantic information contained(Shi and Mihalcea, 2005; Johansson and Nugues,2007; Navigli and Ponzetto, 2010b; Meyer andGurevych, 2011).
As these efforts often targetedparticular applications, they focused on aligningselected, specialized information types.
To ourknowledge, no single work focused on modelinga wide range of ECRs and CCRs in multiple lan-guages and a large variety of information types ina standardized format.
Frequently, the presentedmodel is not easily scalable to accommodate anopen set of LSRs in multiple languages and the in-formation mined automatically from corpora.
Theprevious work also lacked the aspects of lexiconformat standardization and API access.
We be-lieve that easy access to information in LSRs iscrucial in terms of their acceptance and broad ap-plicability in NLP.In this paper, we propose a solution to this.
Wedefine a standardized format for modeling LSRs.This is a prerequisite for resource interoperabil-ity and the smooth integration of resources.
Weemploy the ISO standard Lexical Markup Frame-work (LMF: ISO 24613:2008), a metamodel forLSRs (Francopoulo et al 2006), and Data Cate-gories (DCs) selected from ISOCat.1 One of themain challenges of our work is to develop a modelthat is standard-compliant, yet able to express theinformation contained in diverse LSRs, and that inthe long term supports the integration of the vari-ous resources.The main contributions of this paper can be1http://www.isocat.org/580summarized as follows: (1) We present an LMF-based model for large-scale multilingual LSRscalled UBY-LMF.
We model the lexical-semanticinformation down to a fine-grained level of in-formation (e.g.
syntactic frames) and employstandardized definitions of linguistic informationtypes from ISOCat.
(2) We present UBY, a large-scale LSR implementing the UBY-LMF model.UBY currently contains nine resources in twolanguages: English WordNet (WN, Fellbaum(1998), Wiktionary2 (WKT-en), Wikipedia3 (WP-en), FrameNet (FN, Baker et al(1998)), andVerbNet (VN, Kipper et al(2008)); German Wik-tionary (WKT-de), Wikipedia (WP-de), and Ger-maNet (GN, Kunze and Lemnitzer (2002)), andthe English and German entries of OmegaWiki4(OW), referred to as OW-en and OW-de.
OW,a novel CCR, is inherently multilingual ?
its ba-sic structure are multilingual synsets, which are avaluable addition to our multilingual UBY.
Essen-tial to UBY are the nine pairwise sense alignmentsbetween resources, which we provide to enableresource interoperability on the sense level, e.g.by providing access to the often complementaryinformation for a sense in different resources.
(3)We present a Java-API which offers unified accessto the information contained in UBY.We will make the UBY-LMF model, the re-source UBY and the API freely available to theresearch community.5 This will make it easy forthe NLP community to utilize UBY in a variety oftasks in the future.2 Related WorkThe work presented in this paper concernsstandardization of LSRs, large-scale integrationthereof at the representational level, and the uni-fied access to lexical-semantic information in theintegrated resources.Standardization of resources.
Previous workincludes models for representing lexical informa-tion relative to ontologies (Buitelaar et al 2009;McCrae et al 2011), and standardized singlewordnets (English, German and Italian wordnets)in the ISO standard LMF (Soria et al 2009; Hen-rich and Hinrichs, 2010; Toral et al 2010).2http://www.wiktionary.org/3http://www.wikipedia.org/4http://www.omegawiki.org/5http://www.ukp.tu-darmstadt.de/data/ubyMcCrae et al(2011) propose LEMON, a con-ceptual model for lexicalizing ontologies as anextension of the LexInfo model (Buitelaar et al2009).
LEMON provides an LMF-implementationin the Web Ontology Language (OWL), whichis similar to UBY-LMF, as it also uses DCsfrom ISOCat, but diverges further from the stan-dard (e.g.
by removing structural elements suchas the predicative representation class).
Whilewe focus on modeling lexical-semantic informa-tion comprehensively and at a fine-grained level,the goal of LEMON is to support the linking be-tween ontologies and lexicons.
This goal entailsa task-targeted application: domain-specific lex-icons are extracted from ontology specificationsand merged with existing LSRs on demand.
As aconsequence, there is no available large-scale in-stance of the LEMON model.Soria et al(2009) define WordNet-LMF, anLMF model for representing wordnets used inthe KYOTO project, and Henrich and Hinrichs(2010) do this for GN, the German wordnet.These models are similar, but they still presentdifferent implementations of the LMF meta-model, which hampers interoperability betweenthe resources.
We build upon this work, but ex-tend it significantly: UBY goes beyond model-ing a single ECR and represents a large numberof both ECRs and CCRs with very heterogeneouscontent in the same format.
Also, UBY-LMFfeatures deeper modeling of lexical-semantic in-formation.
Henrich and Hinrichs (2010), forinstance, do not explicitly model the argumentstructure of subcategorization frames, since eachframe is represented as a string.
In UBY-LMF,we represent them at a fine-grained level neces-sary for the transparent modeling of the syntax-semantics interface.Large-scale integration of resources.
Mostprevious research efforts on the integration of re-sources targeted at world knowledge rather thanlexical-semantic knowledge.
Well known exam-ples are YAGO (Suchanek et al 2007), or DBPe-dia (Bizer et al 2009).Atserias et al(2004) present the Meaning Mul-tilingual Central Repository (MCR).
MCR inte-grates five local wordnets based on the Interlin-gual Index of EuroWordNet (Vossen, 1998).
Theoverall goal of the work is to improve word sensedisambiguation.
This work is similar to ours, as it581aims at a large-scale multilingual resource and in-cludes several resources.
It is however restrictedto a single type of resource (wordnets) and fea-tures a single type of lexical information (seman-tic relations) specified upon synsets.
Similarly,de Melo and Weikum (2009) create a multilin-gual wordnet by integrating wordnets, bilingualdictionaries and information from parallel cor-pora.
None of these resources integrate lexical-semantic information, such as syntactic subcate-gorization or semantic roles.McFate and Forbus (2011) present NULEX,a syntactic lexicon automatically compiled fromWN, WKT-en and VN.
As their goal is to cre-ate an open-license resource to enhance syntacticparsing, they enrich verbs and nouns in WN withinflection information from WKT-en and syntac-tic frames from VN.
Thus, they only use a smallpart of the lexical information present in WKT-en.Padro?
et al(2011) present their work on lex-icon merging within the Panacea Project.
Onegoal of Panacea is to create a lexical resource de-velopment platform that supports large-scale lex-ical acquisition and can be used to combine exist-ing lexicons with automatically acquired ones.
Tothis end, Padro?
et al(2011) explore the automaticintegration of subcategorization lexicons.
Theircurrent work only covers Spanish, and thoughthey mention the LMF standard as a potential datamodel, they do not make use of it.Shi and Mihalcea (2005) integrate FN, VN andWN, and Palmer (2009) presents a combination ofPropbank, VN and FN in a resource called SEM-LINK in order to enhance semantic role labeling.Similar to our work, multiple resources are in-tegrated, but their work is restricted to a singlelanguage and does not cover CCRs, whose pop-ularity and importance has grown tremendouslyover the past years.
In fact, with the excep-tion of NULEX, CCRs have only been consid-ered in the sense alignment of individual resourcepairs (Navigli and Ponzetto, 2010a; Meyer andGurevych, 2011).API access for resources.
An important factorto the success of a large, integrated resource is asingle public API, which facilitates the access tothe information contained in the resource.
Themost important LSRs so far can be accessed us-ing various APIs, for instance the Java WordNetAPI,6 or the Java-based Wikipedia API.7With a stronger focus of the NLP communityon sharing data and reproducing experimental re-sults these tools are becoming important as neverbefore.
Therefore, a major design objective ofUBY is a single API.
This is similar in spirit to themotivation of Pradhan et al(2007), who presentintegrated access to corpus annotations as a maingoal of their work on standardizing and integrat-ing corpus annotations in the OntoNotes project.To summarize, related work focuses either onthe standardization of single resources (or a singletype of resource), which leads to several slightlydifferent formats constrained to these resources,or on the integration of several resources in anidiosyncratic format.
CCRs have not been con-sidered at all in previous work on resource stan-dardization, and the level of detail of the model-ing is insufficient to fully accommodate differenttypes of lexical-semantic information.
API ac-cess is rarely provided.
This makes it hard forthe community to exploit their results on a largescale.
Thus, it diminishes the impact that theseprojects might achieve upon NLP beyond theiroriginal specific purpose, if their results were rep-resented in a unified resource and could easily beaccessed by the community through a single pub-lic API.3 UBY ?
Data modelLMF defines a metamodel of LSRs in the Uni-fied Modeling Language (UML).
It provides anumber of UML packages and classes for model-ing many different types of resources, e.g.
word-nets and multilingual lexicons.
The design ofa standard-compliant lexicon model in LMF in-volves two steps: in the first step, the structureof the lexicon model has to be defined by choos-ing a combination of the LMF core package andzero to many extensions (i.e.
UML packages).
Inthe second step, these UML classes are enrichedby attributes.
To contribute to semantic interop-erability, it is essential for the lexicon model thatthe attributes and their values refer to Data Cat-egories (DCs) taken from a reference repository.DCs are standardized specifications of the termsthat are used for attributes and their values, or inother words, the linguistic vocabulary occurring6http://sourceforge.net/projects/jwordnet/7http://code.google.com/p/jwpl/582in a lexicon model.
Consider, for instance, theterm lexeme that is defined differently in WN andFN: in FN, a lexeme refers to a word form, notincluding the sense aspect.
In WN, on the con-trary, a lexeme is an abstract pairing of mean-ing and form.
According to LMF, the DCs areto be selected from ISOCat, the implementationof the ISO 12620 Data Category Registry (DCR,Broeder et al(2010)), resulting in a Data Cate-gory Selection (DCS).Design of UBY-LMF.
We have designed UBY-LMF8 as a model of the union of various hetero-geneous resources, namely WN, GN, FN, and VNon the one hand and CCRs on the other hand.Two design principles guided our developmentof UBY-LMF: first, to preserve the informationavailable in the original resources and to uni-formly represent it in UBY-LMF.
Second, to beable to extend UBY in the future by further lan-guages, resources, and types of linguistic infor-mation, in particular, alignments between differ-ent LSRs.Wordnets, FN and VN are largely complemen-tary regarding the information types they provide,see, e.g.
Baker and Fellbaum (2009).
Accord-ingly, they use different organizational units torepresent this information.
Wordnets, such asWN and GN, primarily contain information onlexical-semantic relations, such as synonymy, anduse synsets (groups of lexemes that are synony-mous) as organizational units.
FN focuses ongroups of lexemes that evoke the same prototypi-cal situation (so-called semantic frames, Fillmore(1982)) involving semantic roles (so-called frameelements).
VN, a large-scale verb lexicon, is or-ganized in Levin-style verb classes (Levin, 1993)(groups of verbs that share the same syntactic al-ternations and semantic roles) and provides richsubcategorization frames including semantic rolesand a specification of semantic predicates.UBY-LMF employs several direct subclassesof Lexicon in order to account for the various or-ganization types found in the different LSRs con-sidered.
While the LexicalEntry class reflectsthe traditional headword-based lexicon organiza-tion, Synset represents synsets from wordnets,SemanticPredicate models FN semanticframes, and SubcategorizationFrameSetcorresponds to VN alternation classes.8See www.ukp.tu-darmstadt.de/data/ubySubcategorizationFrame is com-posed of syntactic arguments, whileSemanticPredicate is composed of se-mantic arguments.
The linking between syntacticand semantic arguments is represented by theSynSemCorrespondence class.The SenseAxis class is very important inUBY-LMF, as it connects the different sourceLSRs.
Its role is twofold: first, it links the cor-responding word senses from different languages,e.g.
English and German.
Second, it representsmonolingual sense alignments, i.e.
sense align-ments between different lexicons in the same lan-guage.
The latter is a novel interpretation ofSenseAxis introduced by UBY-LMF.The organization of lexical-semantic knowl-edge found in WP, WKT, and OW can be mod-eled with the classes in UBY-LMF as well.
WPprimarily provides encyclopedic information onnouns.
It mainly consists of article pages whichare modeled as Senses in UBY-LMF.WKT is in many ways similar to tradi-tional dictionaries, because it enumerates sensesunder a given headword on an entry page.Thus, WKT entry pages can be represented byLexicalEntries and WKT senses by Senses.OW is different from WKT and WP, as it is or-ganized in multilingual synsets.
To model OWin UBY-LMF, we split the synsets per languageand included them as monolingual Synsets inthe corresponding Lexicon (e.g., OW-en or OW-de).
The original multilingual information is pre-served by adding a SenseAxis between corre-sponding synsets in OW-en and OW-de.The LMF standard itself contains only few lin-guistic terms and does neither specify attributesnor their values.
Therefore, an important task indeveloping UBY-LMF has been the specificationof attributes and their values along with the properattachment of attributes to LMF classes.
In partic-ular, this task involved selecting DCs from ISO-Cat and, if necessary, adding new DCs to ISOCat.Extensions in UBY-LMF.
Although UBY-LMF is largely compliant with LMF, the task ofbuilding a homogeneous lexicon model for manyhighly heterogeneous LSRs led us to extend LMFin several ways: we added two new classes andseveral new relationships between classes.First, we were facing a huge variety of lexical-semantic labels for many different dimensions of583semantic classification.
Examples of such dimen-sions include ontological type (e.g.
selectional re-strictions in VN and FN), domain (e.g.
Biology inWN), style and register (e.g.
labels in WKT, OW),or sentiment (e.g.
sentiment of lexical units inFN).
Since we aim at an extensible LMF-model,capable of representing further dimensions of se-mantic classification, we did not squeeze the in-formation on semantic classes present in the con-sidered LSRs into existing LMF classes.
Instead,we addressed this issue by introducing a moregeneral class, SemanticLabel, which is an op-tional subclass of Sense, SemanticPredicate,and SemanticArgument.
This new class hasthree attributes, encoding the name of the label,its type (e.g.
ontological, register, sentiment), anda numeric quantification (e.g.
sentiment strength).Second, we attached the subclass Frequencyto most of the classes in UBY-LMF, in order toencode frequency information.
This is of partic-ular importance when using the resource in ma-chine learning applications.
This extension of thestandard has already been made in WordNet-LMF(Soria et al 2009).
Currently, the Frequencyclass is used to keep corpus frequencies for lex-ical units in FN, but we plan to use it for en-riching many other classes with frequency in-formation in future work, such as Senses orSubcategorizationFrames.Third, the representation of FN in LMF re-quired adding two new relationships betweenLMF classes: we added a relationship betweenSemanticArgument and Definition, in or-der to represent the definitions available for frameelements in FN.
In addition, we added a re-lationship between the Context class and theMonoLingualExternalRef, to represent thelinks to annotated corpus sentences in FN.Finally, WKT turned out to be hard to tackle,because it contains a special kind of ambiguity inthe semantic relations and translation links listedfor senses: the targets of both relations and trans-lation links are ambiguous, as they refer to lem-mas (word forms), rather than to senses (Meyerand Gurevych, 2010).
These ambiguous rela-tion targets could not directly be represented inLMF, since sense and translation relations aredefined between senses.
To resolve this, weadded a relationship between SenseRelationand FormRepresentation, in order to encodethe ambiguous WKT relation target as a wordform.
Disambiguating the WKT relation targetsto infer the target sense is left to future work.A related issue occurred, when we mapped WNto LMF.
WN encodes morphologically relatedforms as sense relations.
UBY-LMF representsthese related forms not only as sense relations (asin WordNet-LMF), but also at the morphologi-cal level using the RelatedForm class from theLMF Morphology extension.
In LMF, however,the RelatedForm class for morphologically re-lated lexemes is not associated with the corre-sponding sense in any way.
Discarding the WNinformation on the senses involved in a particularmorphological relation would lead to informationloss in some cases.
Consider as an example theWN verb buy (purchase) which is derivationallyrelated to the noun buy, while on the other handbuy (accept as true, e.g.
I can?t buy this story) isnot derivationally related to the noun buy.
We ad-dressed this issue by adding a sense attribute tothe RelatedForm class.
Thus, in extension ofLMF, UBY-LMF allows sense relations to refer toa form relation target and morphological relationsto refer to a sense relation target.Data Categories in UBY-LMF.
We encoun-tered large differences in the availability of DCsin ISOCat for the morpho-syntactic, lexical-syntactic, and lexical-semantic parts of UBY-LMF.
Many DCs were missing in ISOCat and wehad to enter them ourselves.
While this was feasi-ble at the morpho-syntactic and lexical-syntacticlevel, due to a large body of standardization re-sults available, it was much harder at the lexical-semantic level where standardization is still on-going.
At the lexical-semantic level, UBY-LMFcurrently allows string values for a number of at-tribute values, e.g.
for semantic roles.
We can eas-ily integrate the results of the ongoing standard-ization efforts into UBY-LMF in the future.4 UBY ?
Population with information4.1 Representing LSRs in UBY-LMFUBY-LMF is represented by a DTD (as suggestedby the standard) which can be used to automat-ically convert any given resource into the corre-sponding XML format.9 This conversion requiresa detailed analysis of the resource to be converted,followed by the definition of a mapping of the9Therefore, UBY-LMF can be considered as a serializa-tion of LMF.584concepts and terms used in the original resourceto the UBY-LMF model.
There are two majortasks involved in the development of an automaticconversion routine: first, the basic organizationalunit in the source LSR has to be identified andmapped, e.g.
synset in WN or semantic frame inFN, and second, it has to be determined, how a(LMF) sense is defined in the source LSR.A notable aspect of converting resources intoUBY-LMF is the harmonization of linguistic ter-minology used in the LSRs.
For instance, aWN Word and a GN Lexical Unit are mapped toSense in UBY-LMF.We developed reusable conversion routines forthe future import of updated versions of the sourceLSRs into UBY, provided the structure of thesource LSR remains stable.
These conversionroutines extract lexical data from the source LSRsby calling their native APIs (rather than process-ing the underlying XML data).
Thus, all lexicalinformation which can be accessed via the APIsis converted into UBY-LMF.Converting the LSRs introduced in the previ-ous section yielded an instantiation of UBY-LMFnamed UBY.
The LexicalResource instanceUBY currently comprises 10 Lexicon instances,one each for OW-de and OW-en, and one lexiconeach for the remaining eight LSRs.4.2 Adding Sense AlignmentsBesides the uniform and standardized representa-tion of the single LSRs, one major asset of UBYis the semantic interoperability of resources at thesense level.
In the following, we (i) describe howwe converted already existing sense alignments ofresources into LMF, and (ii) present a frameworkto infer alignments automatically for any pair ofresources.Existing Alignments.
Previous work on sensealignment yielded several alignments, such asWN?WP-en (Niemann and Gurevych, 2011),WN?WKT-en (Meyer and Gurevych, 2011) andVN?FN (Palmer, 2009).We converted these alignments into UBY-LMFby creating a SenseAxis instance for each pair ofaligned senses.
This involved mapping the senseIDs from the proprietary alignment files to thecorresponding sense IDs in UBY.In addition, we integrated the sense alignmentsalready present in OW and WP.
Some OW en-tries provide links to the corresponding WP page.Also, the German and English language editionsof WP and OW are connected by inter-languagelinks between articles (Senses in UBY).
We canexpect that these links have high quality, as theywere entered manually by users and are subjectto community control.
Therefore, we straightfor-wardly imported them into UBY.Alignment Framework.
Automatically creat-ing new alignments is difficult because of wordambiguities, different granularities of senses,or language specific conceptualizations (Navigli,2006).
To support this task for a large numberof resources across languages, we have designeda flexible alignment framework based on thestate-of-the-art method of Niemann and Gurevych(2011).
The framework is generic in order to al-low alignments between different kinds of entitiesas found in different resources, e.g.
WN synsets,FN frames or WP articles.
The only requirementis that the individual entities are distinguishableby a unique identifier in each resource.The alignment consists of the following steps:First, we extract the alignment candidates for agiven resource pair, e.g.
WN sense candidates fora WKT-en entry.
Second, we create a gold stan-dard by manually annotating a subset of candi-date pairs as ?valid?
or ?non-valid?.
Then, weextract the sense representations (e.g.
lemmatizedbag-of-words based on glosses) to compute thesimilarity of word senses (e.g.
by cosine similar-ity).
The gold standard with corresponding sim-ilarity values is fed into Weka (Hall et al 2009)to train a machine learning classifier, and in thefinal step this classifier is used to automaticallyclassify the candidate sense pairs as (non-)validalignment.
Our framework also allows us to trainon a combination of different similarity measures.Using our framework, we were able to re-produce the results reported by Niemann andGurevych (2011) and Meyer and Gurevych(2011) based on the publicly available evaluationdatasets10 and the configuration details reportedin the corresponding papers.Cross-Lingual Alignment.
In order to alignword senses across languages, we extended themonolingual sense alignment described above tothe cross-lingual setting.
Our approach utilizes10http://www.ukp.tu-darmstadt.de/data/sense-alignment/585Moses,11 trained on the Europarl corpus.
Thelemma of one of the two senses to be alignedas well as its representations (e.g.
the gloss) istranslated into the language of the other resource,yielding a monolingual setting.
E.g., the WNsynset {vessel, watercraft} with its gloss ?a craftdesigned for water transportation?
is translatedinto {Schiff, Wasserfahrzeug} and ?Ein Fahrzeugfu?r Wassertransport?, and then the candidate ex-traction and all downstream steps can take placein German.
An inherent problem with this ap-proach is that incorrect translations also lead toinvalid alignment candidates.
However, these aremost probably filtered out by the machine learn-ing classifier as the calculated similarity betweenthe sense representations (e.g.
glosses) should below if the candidates do not match.We evaluated our approach by creating a cross-lingual alignment between WN and OW-de, i.e.the concepts in OW with a German lexicaliza-tion.12 To our knowledge, this is the first study onaligning OW with another LSR.
OW is especiallyinteresting for this task due to its multilingual con-cepts, as described by Matuschek and Gurevych(2011).
The created gold standard could, for in-stance, be re-used to evaluate alignments for otherlanguages in OW.To compute the similarity of word senses, wefollowed the approach by Niemann and Gurevych(2011) while covering both translation directions.We used the cosine similarity for comparing theGerman OW glosses with the German translationsof WN glosses and cosine and personalized pagerank (PPR) similarity for comparison of the Ger-man OW glosses translated into English with theoriginal English WN glosses.
Note that PPR sim-ilarity is not available for German as it is basedon WN.
Thereby, we filtered out the OW con-cepts without a German gloss which left us with11,806 unique candidate pairs.
We randomly se-lected 500 WN synsets for analysis yielding 703candidate pairs.
These were manually annotatedas being (non-)alignments.
For the subsequentmachine learning task we used a simple threshold-based classifier and ten-fold cross validation.Table 1 summarizes the results of different sys-tem configurations.
We observe that translation11http://www.statmt.org/moses/12OmegaWiki consists of interlinked language-independent concepts to which lexicalizations in severallanguages are attached.Translation Similaritydirection measure P R F1EN > DE Cosine (Cos) 0.666 0.575 0.594DE > EN Cos 0.674 0.658 0.665DE > EN PPR 0.721 0.712 0.716DE > EN PPR + Cos 0.723 0.712 0.717Table 1: Cross-lingual alignment resultsinto English works significantly better than intoGerman.
Also, the more elaborate similarity mea-sure PPR yields better results than cosine similar-ity, while the best result is achieved by a combina-tion of both.
Niemann and Gurevych (2011) makea similar observation for the monolingual setting.Our F-measure of 0.717 in the best configurationlies between the results of Meyer and Gurevych(2011) (0.66) and Niemann and Gurevych (2011)(0.78), and thus verifies the validity of the ma-chine translation approach.
Therefore, the bestalignment was subsequently integrated into UBY.5 Evaluating UBYWe performed an intrinsic evaluation of UBY bycomputing a number of resource statistics.
Ourevaluation covers two aspects: first, it addressesthe question if our automatic conversion routineswork correctly.
Second, it provides indicators forassessing UBY in terms of the gain in coveragecompared to the single LSRs.Correctness of conversion.
Since we aim topreserve the maximal amount of information fromthe original LSRs, we should be able to replaceany of the original LSRs and APIs by UBY andthe UBY-API without losing information.
Asthe conversion is largely performed automatically,systematic errors and information loss could beintroduced by a faulty conversion routine.
In or-der to detect such errors and to prove the correct-ness of the automatic conversion and the result-ing representation, we have compared the orig-inal resource statistics of the classes and infor-mation types in the source LSRs to the cor-responding classes in their UBY counterparts.For instance, the number of lexical relations inWordNet has been compared to the number ofSenseRelations in the UBY WordNet lexi-con.1313For detailed analysis results see the UBY website.586Lexical SenseLexicon Entry Sense RelationFN 9,704 11,942 ?GN 83,091 93,407 329,213OW-de 30,967 34,691 60,054OW-en 51,715 57,921 85,952WP-de 790,430 838,428 571,286WP-en 2,712,117 2,921,455 3,364,083WKT-de 85,575 72,752 434,358WKT-en 335,749 421,848 716,595WN 156,584 206,978 8,559VN 3,962 31,891 ?UBY 4,259,894 4,691,313 5,300,941Table 2: UBY resource statistics (selected classes).Lexicon pair Languages SenseAxisWN?WP-en EN?EN 50,351WN?WKT-en EN?EN 99,662WN?VN EN?EN 40,716FN?VN EN?EN 17,529WP-en?OW-en EN?EN 3,960WP-de?OW-de DE?DE 1,097WN?OW-de EN?DE 23,024WP-en?WP-de EN?DE 463,311OW-en?OW-de EN?DE 58,785UBY All 758,435Table 3: UBY alignment statistics.Gain in coverage.
UBY offers an increasedcoverage compared to the single LSRs as reflectedin the resource statistics.
Tables 2 and 3 show thestatistics on central classes in UBY.
As UBY isorganized in several Lexicons, the number ofUBY lexical entries is the sum of the lexical en-tries in all 10 Lexicons.
Thus, UBY containsmore than 4.2 million lexical entries, 4.6 millionsenses, 5.3 million semantic relations betweensenses and more than 750,000 alignments.
Thesestatistics represent the total numbers of lexical en-tries, senses and sense relations in UBY withoutfiltering of identical (i.e.
corresponding) lexicalentries, senses and relations.
Listing the num-ber of unique senses would require a full align-ment between all integrated resources, which iscurrently not available.We can, however, show that UBY contains over3.08 million unique lemma-POS combinations forEnglish and over 860,000 for German, over 3.94million in total, see Table 4.
Therefore, we as-sessed the coverage on lemma level.
Table 4 alsoshows the number of lemmas with entries in oneor more than one lexicon, additionally split byPOS and language.
Lemmas occurring only oncein UBY increase the coverage at lemma level.
Forlemmas with parallel entries in several UBY lex-icons, new information becomes available in theform of additional sense definitions and comple-mentary information types attached to lemmas.Finally, the increase in coverage at sense levelcan be estimated for senses that are aligned acrossat least two UBY-lexicons.
We gain access toall available, partly complementary informationtypes attached to these aligned senses, e.g.
seman-tic relations, subcategorization frames, encyclo-pedic or multilingual information.
The numberof pairwise sense alignments provided by UBY isgiven in Table 3.
In addition, we computed howmany senses simultaneously take part in at leasttwo pairwise sense alignments.
For English, thisapplies to 31,786 senses, for which informationfrom 3 UBY lexicons is available.EN Lexicons noun verb adjective5 1 699 -4 1,630 1,888 4303 8,439 1,948 2,2712 53,856 4,727 12,2901 2,900,652 50,209 41,731?
(unique EN) 3,080,771DE Lexicons noun verb adjective4 1,546 - -3 10,374 372 3422 26,813 3,174 2,6431 803,770 6,108 7,737?
(unique DE) 862,879Table 4: Number of lemmas (split by POS and lan-guage) with entries in i UBY lexicons, i = 1, .
.
.
, 5.6 Using UBYUBY API.
For convenient access to UBY, weimplemented a Java-API which is built aroundthe Hibernate14 framework.
Hibernate allows toeasily store the XML data which results fromconverting resources into Uby-LMF into a corre-sponding SQL database.Our main design principle was to keep the ac-cess to the resource as simple as possible, despitethe rich and complex structure of UBY.
Another14http://www.hibernate.org/587important design aspect was to ensure that thefunctionality of the individual, resource-specificAPIs or user interfaces is mirrored in the UBYAPI.
This enables porting legacy applications toour new resource.
To facilitate the transition toUBY, we plan to provide reference tables whichlist the corresponding UBY-API operations for themost important operations in the WN API, someof which are shown in Table 5.WN function UBY functionDictionary UBYgetIndexWord(pos,lemma)getLexicalEntries(pos, lemma)IndexWord LexicalEntrygetLemma() getLemmaForm()Synset SynsetgetGloss() getDefinitionText()getWords() getSenses()Pointer SynsetRelationgetType() getRelName()Word SensegetPointers() getSenseRelations()Table 5: Some equivalent operations in WN API andUBY API.While it is possible to limit access to single re-sources by a parameter and thus mimic the behav-ior of the legacy APIs (e.g.
only retrieve Synsetsand their relations from WN), the true power ofUBY API becomes visible when no such con-straints are applied.
In this case, all imported re-sources are queried to get one combined result,while retaining the source of the respective in-formation.
On top of this, the information aboutexisting sense alignments across resources can beaccessed via SenseAxis relations, so that the re-turned combined result covers not only the lexi-cal, but also the sense level.Community issues.
One of the most importantreasons for UBY is creating an easy-to-use pow-erful LSR to advance NLP research and develop-ment.
Therefore, community building around theresource is one of our major concerns.
To this end,we will offer free downloads of the lexical dataand software presented in this paper under open li-censes, namely: The UBY-LMF DTD, mappingsand conversion tools for existing resources andsense alignments, the Java API, and, as far as li-censing allows,15 already converted resources.
Ifresources cannot be made available for download,the conversion tools will still allow users with ac-cess to these resources to import them into UBYeasily.
In this way, it will be possible for users tobuild their ?custom UBY?
containing selected re-sources.
As the underlying resources are subjectto continuous change, updates of the correspond-ing components will be made available on a regu-lar basis.7 ConclusionsWe presented UBY, a large-scale, standardizedLSR containing nine widely used resources in twolanguages: English WN, WKT-en, WP-en, FNand VN, German WP-de, WKT-de, and GN, andOW in English and German.
As all resourcesare modeled in UBY-LMF, UBY enables struc-tural interoperability across resources and lan-guages down to a fine-grained level of informa-tion.
For FN, VN and all of the CCRs in En-glish and German, this is done for the first time.Besides, by integrating sense alignments we alsoenable the lexical-semantic interoperability of re-sources.
We presented a unified framework foraligning any LSRs pairwise and reported on ex-periments which align OW-de and WN.
We willrelease the UBY-LMF model, the resource and theUBY-API at the time of publication.16 Due to theadded value and the large scale of UBY, as well asits ease of use, we believe UBY will boost the per-formance of NLP making use of lexical-semanticknowledge.AcknowledgmentsThis work has been supported by the EmmyNoether Program of the German Research Foun-dation (DFG) under grant No.
GU 798/3-1 andby the Volkswagen Foundation as part of theLichtenberg-Professorship Program under grantNo.
I/82806.
We thank Richard Eckart deCastilho, Yevgen Chebotar, Zijad Maksuti and TriDuc Nghiem for their contributions to this project.ReferencesJordi Atserias, Lu?
?s Villarejo, German Rigau, EnekoAgirre, John Carroll, Bernardo Magnini, and Piek15Only GermaNet is subject to a restricted license and can-not be redistributed in UBY format.16http://www.ukp.tu-darmstadt.de/data/uby588Vossen.
2004.
The Meaning Multilingual CentralRepository.
In Proceedings of the second interna-tional WordNet Conference (GWC 2004), pages 23?30, Brno, Czech Republic.Collin F. Baker and Christiane Fellbaum.
2009.
Word-Net and FrameNet as complementary resources forannotation.
In Proceedings of the Third Linguis-tic Annotation Workshop, ACL-IJCNLP ?09, pages125?129, Suntec, Singapore.Collin F. Baker, Charles J. Fillmore, and John B.Lowe.
1998.
The Berkeley FrameNet project.
InProceedings of the 36th Annual Meeting of the As-sociation for Computational Linguistics and 17thInternational Conference on Computational Lin-guistics (COLING-ACL?98, pages 86?90, Montreal,Canada.Christian Bizer, Jens Lehmann, Georgi Kobilarov,So?ren Auer, Christian Becker, Richard Cyganiak,and Sebastian Hellmann.
2009.
DBpedia A Crys-tallization Point for the Web of Data.
Journal ofWeb Semantics: Science, Services and Agents on theWorld Wide Web, (7):154?165.Daan Broeder, Marc Kemps-Snijders, Dieter Van Uyt-vanck, Menzo Windhouwer, Peter Withers, PeterWittenburg, and Claus Zinn.
2010.
A Data Cat-egory Registry- and Component-based MetadataFramework.
In Proceedings of the 7th InternationalConference on Language Resources and Evaluation(LREC), pages 43?47, Valletta, Malta.Paul Buitelaar, Philipp Cimiano, Peter Haase, andMichael Sintek.
2009.
Towards LinguisticallyGrounded Ontologies.
In Lora Aroyo, PaoloTraverso, Fabio Ciravegna, Philipp Cimiano, TomHeath, Eero Hyvo?nen, Riichiro Mizoguchi, EyalOren, Marta Sabou, and Elena Simperl, editors, TheSemantic Web: Research and Applications, pages111?125, Berlin/Heidelberg, Germany.
Springer.Gerard de Melo and Gerhard Weikum.
2009.
Towardsa universal wordnet by learning from combined ev-idence.
In Proceedings of the 18th ACM conferenceon Information and knowledge management (CIKM?09), CIKM ?09, pages 513?522, New York, NY,USA.
ACM.Christiane Fellbaum.
1998.
WordNet: An ElectronicLexical Database.
MIT Press, Cambridge, MA,USA.Charles J. Fillmore.
1982.
Frame Semantics.
In TheLinguistic Society of Korea, editor, Linguistics inthe Morning Calm, pages 111?137.
Hanshin Pub-lishing Company, Seoul, Korea.Gil Francopoulo, Nuria Bel, Monte George, Nico-letta Calzolari, Monica Monachini, Mandy Pet, andClaudia Soria.
2006.
Lexical Markup Framework(LMF).
In Proceedings of the 5th InternationalConference on Language Resources and Evaluation(LREC), pages 233?236, Genoa, Italy.Mark Hall, Eibe Frank, Geoffrey Holmes, BernhardPfahringer, Peter Reutemann, and Ian H. Witten.2009.
The WEKA Data Mining Software: AnUpdate.
ACM SIGKDD Explorations Newsletter,11(1):10?18.Verena Henrich and Erhard Hinrichs.
2010.
Standard-izing wordnets in the ISO standard LMF: Wordnet-LMF for GermaNet.
In Proceedings of the 23rd In-ternational Conference on Computational Linguis-tics (COLING), pages 456?464, Beijing, China.Richard Johansson and Pierre Nugues.
2007.
Us-ing WordNet to extend FrameNet coverage.
InProceedings of the Workshop on Building Frame-semantic Resources for Scandinavian and BalticLanguages, at NODALIDA, pages 27?30, Tartu, Es-tonia.Karin Kipper, Anna Korhonen, Neville Ryant, andMartha Palmer.
2008.
A Large-scale Classificationof English Verbs.
Language Resources and Evalu-ation, 42:21?40.Claudia Kunze and Lothar Lemnitzer.
2002.
Ger-maNet ?
representation, visualization, application.In Proceedings of the Third International Con-ference on Language Resources and Evaluation(LREC), pages 1485?1491, Las Palmas, Canary Is-lands, Spain.Beth Levin.
1993.
English Verb Classes and Alterna-tions.
The University of Chicago Press, Chicago,IL, USA.Michael Matuschek and Iryna Gurevych.
2011.Where the journey is headed: Collaboratively con-structed multilingual Wiki-based resources.
InSFB 538: Mehrsprachigkeit, editor, Hamburger Ar-beiten zur Mehrsprachigkeit, Hamburg, Germany.John McCrae, Dennis Spohr, and Philipp Cimiano.2011.
Linking Lexical Resources and Ontologieson the Semantic Web with Lemon.
In The Seman-tic Web: Research and Applications, volume 6643of Lecture Notes in Computer Science, pages 245?259.
Springer, Berlin/Heidelberg, Germany.Clifton J. McFate and Kenneth D. Forbus.
2011.NULEX: an open-license broad coverage lexicon.In Proceedings of the 49th Annual Meeting of theAssociation for Computational Linguistics: HumanLanguage Technologies: short papers - Volume 2,HLT ?11, pages 363?367, Portland, OR, USA.Christian M. Meyer and Iryna Gurevych.
2010.
Worthits Weight in Gold or Yet Another Resource ?A Comparative Study of Wiktionary, OpenThe-saurus and GermaNet.
In Alexander Gelbukh, ed-itor, Computational Linguistics and Intelligent TextProcessing: 11th International Conference, volume6008 of Lecture Notes in Computer Science, pages38?49.
Berlin/Heidelberg: Springer, Ias?i, Romania.Christian M. Meyer and Iryna Gurevych.
2011.
WhatPsycholinguists Know About Chemistry: Align-ing Wiktionary and WordNet for Increased Domain589Coverage.
In Proceedings of the 5th InternationalJoint Conference on Natural Language Processing(IJCNLP), pages 883?892, Chiang Mai, Thailand.Roberto Navigli and Simone Paolo Ponzetto.
2010a.BabelNet: Building a Very Large Multilingual Se-mantic Network.
In Proceedings of the 48th AnnualMeeting of the Association for Computational Lin-guistics, pages 216?225, Uppsala, Sweden, July.Roberto Navigli and Simone Paolo Ponzetto.
2010b.Knowledge-rich Word Sense Disambiguation Ri-valing Supervised Systems.
In Proceedings of the48th Annual Meeting of the Association for Com-putational Linguistics, pages 1522?1531, Uppsala,Sweden.Roberto Navigli.
2006.
Meaningful Clustering ofSenses Helps Boost Word Sense DisambiguationPerformance.
In Proceedings of the 21st Inter-national Conference on Computational Linguisticsand the 44th Annual Meeting of the Association forComputational Linguistics (COLING-ACL), pages105?112, Sydney, Australia.Elisabeth Niemann and Iryna Gurevych.
2011.
ThePeople?s Web meets Linguistic Knowledge: Auto-matic Sense Alignment of Wikipedia and WordNet.In Proceedings of the 9th International Conferenceon Computational Semantics (IWCS), pages 205?214, Oxford, UK.Muntsa Padro?, Nu?ria Bel, and Silvia Necsulescu.2011.
Towards the Automatic Merging of LexicalResources: Automatic Mapping.
In Proceedings ofthe International Conference on Recent Advancesin Natural Language Processing (RANLP), pages296?301, Hissar, Bulgaria.Martha Palmer.
2009.
Semlink: Linking PropBank,VerbNet and FrameNet.
In Proceedings of the Gen-erative Lexicon Conference (GenLex-09), pages 9?15, Pisa, Italy.Sameer S. Pradhan, Eduard Hovy, Mitch Mar-cus, Martha Palmer, Lance Ramshaw, and RalphWeischedel.
2007.
OntoNotes: A Unified Rela-tional Semantic Representation.
In Proceedings ofthe International Conference on Semantic Comput-ing, pages 517?526, Washington, DC, USA.Lei Shi and Rada Mihalcea.
2005.
Putting Pieces To-gether: Combining FrameNet, VerbNet and Word-Net for Robust Semantic Parsing.
In Proceedingsof the Sixth International Conference on IntelligentText Processing and Computational Linguistics (CI-CLing), pages 100?111, Mexico City, Mexico.Claudia Soria, Monica Monachini, and Piek Vossen.2009.
Wordnet-LMF: fleshing out a standardizedformat for Wordnet interoperability.
In Proceed-ings of the 2009 International Workshop on Inter-cultural Collaboration, pages 139?146, Palo Alto,CA, USA.Fabian M. Suchanek, Gjergji Kasneci, and GerhardWeikum.
2007.
Yago: A Core of Semantic Knowl-edge.
In Proceedings of the 16th International Con-ference on World Wide Web, pages 697?706, Banff,Canada.Antonio Toral, Stefania Bracale, Monica Monachini,and Claudia Soria.
2010.
Rejuvenating the ItalianWordNet: Upgrading, Standarising, Extending.
InProceedings of the 5th Global WordNet Conference(GWC), Bombay, India.Piek Vossen, editor.
1998.
EuroWordNet: A Multi-lingual Database with Lexical Semantic Networks.Kluwer Academic Publishers, Dordrecht, Nether-lands.590
