Proceedings of the 10th Workshop on Multiword Expressions (MWE 2014), pages 10?16,Gothenburg, Sweden, 26-27 April 2014.c?2014 Association for Computational LinguisticsA Supervised Model for Extraction of Multiword Expressions Based onStatistical Context FeaturesMeghdad FarahmandThe Computer Science CenterUniversity of GenevaSwitzerlandmeghdad.farahmand@unige.chRonaldo MartinsUNDL FoundationGeneva - Switzerlandr.martins@undl.chAbstractWe present a method for extracting Multi-word Expressions (MWEs) based on theimmediate context they occur in, using asupervised model.
We show some of thesecontextual features can be very discrim-inant and combining them with MWE-specific features results in a relatively ac-curate extraction.
We define context asa sequential structure and not a bag ofwords, consequently, it becomes muchmore informative about MWEs.1 IntroductionMultiword Expressions (MWEs) are an importantresearch topic in the area of Natural LanguageProcessing (NLP).
Efficient and effective extrac-tion and interpretation of MWEs is crucial in mostNLP tasks.
They exist in many types of text andcause major problems in all kinds of natural lan-guage processing applications (Sag et al., 2002).However, identifying and lexicalizing these im-portant but hard to identify structures need to beimproved in most major computational lexicons(Calzolari et al., 2002).
Jackendoff (1997) esti-mates that the number of MWEs is equal to thenumber of single words in a speaker?s lexicon,while Sag et al.
(2002) believe that the numberis even greater than this.
Moreover, as a lan-guage evolves, the number of MWEs consistentlyincreases.
MWEs are a powerful way of extendinglanguages?
lexicons.
Their role in language evolu-tion is so important that according to Baldwin andKim (2010), ?It is highly doubtful that any lan-guage would evolve without MWEs of some de-scription?.The efficient identification and extraction ofMWEs can positively influence many other NLPtasks, e.g., part of speech tagging, parsing,syntactic disambiguation, semantic tagging, ma-chine translation, and natural language generation.MWEs also have important applications outsideNLP.
For instance in document indexing, informa-tion retrieval (Acosta et al., 2011), and cross lin-gual information retrieval (Hull and Grefenstette,1996).In this paper we present a method of extractingMWEs which is relatively different from most ofthe state of the art approaches.
We characterizeMWEs based on the statistical properties of theimmediate context they occur in.
For each pos-sible MWE candidate we define a set of contex-tual features (e.g., prefixes, suffixes, etc.).
Thecontextual feature vector is then enriched with afew MWE-specific features such as the frequencyof its components, type frequency of the candi-date MWE, and the association between these two(which is learned by a supervised model).
Subse-quently the MWEhood of the extracted candidatesis predicted based on this feature representation,using a Support Vector Machine (SVM).
The sys-tem reaches a relatively high accuracy of predict-ing MWEs on unseen data.1.1 Previous WorkAttempts to extract MWEs are of different types.The most common techniques are primarily fo-cused on collocations.
Some of these techniquesare rule-based and symbolic e.g., (Seretan, 2011;Goldman et al., 2001; Nerima et al., 2003; Bald-win, 2005; Piao et al., 2003; McCarthy et al.,2003; Jacquemin et al., 1997).
Some rely on lexi-cons (Michiels and Dufour, 1998; Li et al., 2003)and (Pearce, 2001) that uses WordNet to evalu-ate the candidate MWE based on anti-collocations.Other approaches are hybrid in the sense thatthey benefit from both statistical and linguisticinformation.
For instance (Seretan and Wehrli,2006; Baldwin and Villavicencio, 2002; Piao andMcEnery, 2001; Dias, 2003).There are also fully statistical approaches.
Forinstance (Pecina, 2010; Evert, 2005; Lapata and10Lascarides, 2003; Smadja et al., 1996), or the earlywork Xtract (Smadja, 1993).Other approaches consider all types of MWEs(Zhang et al., 2006).
Some of these approachesbuild upon generic properties of MWEs, for in-stance semantic non-compositionality (Van deCruys and Moir?on, 2007).A different approach is presented in (Widdowsand Dorow, 2005).
The authors present a graph-based model to capture and assess fixed expres-sions in form of Noun and/or Noun.There are also bilingual models which aremostly based on the assumption that a translationof the MWE in a source language exists in a tar-get language.
For instance (de Medeiros Caseliet al., 2010; Ren et al., 2009), and (Moir?on andTiedemann, 2006) which measures MWEs candi-dates?
idiomaticity based on translational entropy.Another example is (Duan et al., 2009) which isa hybrid model that aims at extracting bilingual(English-Chinese) MWEs .
It combines Multi-ple Sequence Alignment Model with some filter-ing based on hard rules to obtain an improved ex-traction.A more generic model is presented in (Ramisch,2012) where the author develops a flexible plat-form that can accept different types of criteria(from statistical to deep linguistic) in order to ex-tract and filter MWEs.
However, in this work,as the author claims, the quality of the extractedMWEs is highly dependent on the level of deeplinguistic analysis, and thereby, the role of statisti-cal criterion is less significant.1.2 MotivationWe propose an original method to extract multi-word expressions based on statistical contextualfeatures, e.g., a set of immediate prefixes, suffixes,circumfixes, infixes to circumfixes, etc., (see Sec.2).
These features are used to form a feature repre-sentation, which together with a set of annotationstrain a supervised model in order to predict andextract MWEs from a large corpus.We observed some discriminant behavior incontextual features (such as prefixes, suffixes, cir-cumfixes, etc.)
of a set of manually selectedMWEs.
A supervised model is then applied tolearn MWEhood based on these features.In general, modeling lexical and syntactic (andnot semantic) characteristics of continuous MWEsis the focus of this paper.
In order for the MWE de-composability condition to hold, we consider bi-grams and above (up to size 4).
Idiomaticity atsome level is a necessary prerequisite of MWEs.Hereby, we consider idiomaticity at lexical, syn-tactic and statistical levels, and leave the semanticidiomaticity to the future work.Relatively similar models have been previouslyapplied to problems similar to MWEs, for instancenamed entity recognition (Nadeau and Sekine,2007; Ratinov and Roth, 2009).The focus on contextual features allows somedegree of generalization, i.e., we can apply thismodel to a family of languages.1However, thiswork focuses only on English MWEs.2 Proposed SystemWe prepared a corpus that comprises 100KWikipedia documents for each of the mentionedlanguages.1After cleaning and segmenting thecorpus, we extracted all possible n-grams (up tosize 7) and their token and type frequencies.
Thentwo basic statistical filters were applied in order tosystematically decrease the size of our immensen-gram set: (i) Frequency filter, where we filteran n-gram if its frequency is less than the ratiobetween tokens and types, where for a given sizeof n-grams, the total number of n-grams and thenumber of distinct n-grams of that size, are con-sidered tokens and types, respectively.
(ii) Redun-dancy filter where we consider an n-gram to beredundant if it is subsumed by any other n?-gram,where n?> n. This gives us a pruned set of n-grams which we refer to as the statistically signifi-cant set.
Table 1 presents a count-wise descriptionof the filtering results on the English corpus.raw frq flt rdund flt1-grams 1782993 64204 642042-grams 14573453 1117784 10857873-grams 38749315 3797456 33944144-grams 53023415 5409794 38509445-grams 53191941 2812650 23249126-grams 47249534 1384821 5686457-grams 39991254 757606 7576061We are adapting our model so that it can handle clustersof similar languages.
So far we have processed the following9 widely-spoken languages: English, German, Dutch, Span-ish, French, Italian, Portuguese, Polish, and Russian.
How-ever, to study the efficiency of the presented model applied tolanguages other than English, remains a future work.11Table 1: Number of extracted n-grams for EN.First column indicates raw data, second and thirdcolumns indicate the number of n-grams after fre-quency and redundancy filters respectively.For the set of significant n-grams a set of statis-tical features are extracted which will be describedshortly.
Fig.
1 illustrates the workflow of the sys-tem.removing tags,cleaning,segmentationLanguageModel100KWikipediadocsCorpuscleaning;extractionn-gramsfreq &redundancyFiltersstatisticallysignificantn-gramsindexingIndex(MWE candidate, {|f1|,|f2|,...)featureextractionThis%set%is%used%in%annotation%and%generation%of%test/training%data%Figure 1: Schematic of pre-processing, n-gram ex-traction and filtering.
Blended and plain nodesrepresent resources, and operations respectively.While studying the English corpus and differentMWEs therein, it was observed that often, MWEs(as well as some other types of syntactic units)are followed, preceded or surrounded by a lim-ited number of high frequency significant n-gramtypes.
Moreover, our manual evaluation and con-stituency tests reveal that generally when a fre-quent significant prefix co-occurs with a frequentsignificant suffix, they form a circumfix whose sig-nificant infixes are (i) many, (ii) can mostly be con-sidered syntactic unit, specifically when it comesto bi/trigrams.
Table 2 illustrates a randomly se-lected sample of infixes of such circumfix (the..of).Remarkably, the majority of them are idiomatic atleast at one level.franz liszt academy official listmost important albums closest relativesministry of commerce protestant churchexecutive vice president peak periodfamous italian architect manhattan schoolblessed virgin mary rise and fallworld cup winner former headTable 2: Examples of bi/trigrams surrounded bythe circumfix the..ofThe immediate proximity of these particular con-text features to MWEs keeps emerging while eval-uating similar circumfixes.
We believe it sug-gests the presence of a discriminant attribute thatwe model with features 5-8 (see Table 3) andlearn using a supervised model.
Nevertheless,the fact that MWEs share these features withother types of syntactic units encourages introduc-ing more MWE-specific features (namely, MWE?sfrequency, the frequency of its components, andtheir associations), then enforcing the learningmodel to recognize a MWE based on the combi-nation of these two types of features.
Note thatthe association between the type frequency of aMWE, and the frequency of its components is im-plicitly learned by the supervised model through-out the learning phase.
A candidate MWE can berepresented as:y = (x1, ..., xm, xm+1, ..., xn) ?
N0(1)Where x1, ..., xmare contextual, andxm+1, ..., xnare specific features (m = 8,and n = 11).
These features are described inTable 3.contextual featuresx1# set of all possible prefixes of yx2# set of distinct prefixes of yx3# set of all possible suffixes of yx4# set of distinct suffixes of yx5# set of all possible circumfixes of yx6# set of distinct circumfixes of y (C)x7# set of all possible infixes to members of Cx8# set of distinct infixes to members of Cspecific featuresx9the size of yx10number of occurrences of y in the corpusx11list of frequencies of the components of yTable 3: Description of the extracted features12A prefix of y is the longest n-gram immediatelybefore y, if any or the boundary marker #, other-wise.
A suffix of y is the longest n-gram imme-diately after y, if any or the boundary marker #,otherwise.
A circumfix (ci?
C) of y is the pair(p, s) where p and s are respectively the prefix andthe suffix of a given occurrence of y.
An Infix ofciis an n-gram that occurs between p and s.Components to generate candidate MWEs, fil-ter them and extract their relevant features werevery memory and CPU intensive.
To address theperformance issues we implemented parallel pro-grams and ran them on a high performance cluster.3 Experimental ResultsA set of ?
10K negative and positive EnglishMWE examples were annotated.
This set doesnot particularly belong in any specific genre, asthe examples were chosen randomly from acrossa general-purpose corpus.
This set comprises anequal number of positive and negative annotations.Part of it was annotated manually at UNDL foun-dation,2and part of it was acquired from the man-ually examined MWE lexicon presented in (Ner-ima et al., 2003).
The set of positive and negativeannotated n-grams is detailed in Table 4.
The biastoward bigrams is due to the fact that the majorityof manually verified MWEs that could be obtainedare bigrams.size + examples ?
examples2-grams 4, 632 5, 1733-grams 500 224-grams 68 15Table 4: Annotations?
statisticsThis set was divided into 1/3 test and 2/3 train-ing data, which were selected randomly but wereevenly distributed with respect to positive and neg-ative examples.
The test set remains completelyunseen to the model during the learning phase.
Wethen train a linear SVM:h(y) = w?y + b (2)Where h(y) is a discriminant hyperplane, w isthe weight vector, and y is a set of MWE exam-ples, where each example is defined as: yj=x1, ..., x11.
Table 5 shows the results of themodel?s multiple runs on five different pairs oftraining and test sets.2The Universal Networking Digital Language Founda-tion: http://www.undlfoundation.org/precision (%) recall (%) accuracy(%)run 1 84.8 96.8 89.7run 2 82.5 97.4 88.4run 3 83.6 97.8 89.3run 4 84.1 97.5 89.5run 5 83.4 97.1 88.9Table 5: Performance of the SVM which learns theMWEhood based on contextual and specific fea-tures (x1?
x11)Table 6 illustrates the trained model?s predic-tions on a set of randomly selected test examples.The overall performance of the model is shown inthe form of a precision-recall curve in Fig.
2.n-grams classified as MWEspend time genetically modifiedhijack a plane fish tanktop dog toy carfactory outlet motorcycle racingseason nine vintage carvideo conference chestnut treekill your entry feesafety precaution quantum leapversion shown make an appealflood damage drug dealerbargaining chip lung transplantgrant her tone likepostgraduate student make a phone callraise the price ozone layern-grams classified as non-MWEscore is and dartmouththe tabular capped aon sale clarified hisliver was the cancanthe regulating an endingthe rabi warns thethis manuscript a fewan exponential an institutionthe petal blades areor ended difficulties heand workmen the guidancethe eyelids the examinedthe vices the episodesthey work monument isTable 6: Sample SVM?s output on unseen data.A t-test ranks the significance of the defined fea-tures in classifying n-grams into MWE, and non-MWE classes, as illustrated in Fig.
3.
The most130 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 10.50.60.70.80.91RecallPrecisionPrecision?recall curveFigure 2: Precision-recall curveimportant features are the size of examples (x9),and the frequencies of their components (x11).The significance of x9is due to the fact that inthe training set majority of MWEs are bigrams.Therefore, by the SVM, being a bigram is consid-ered as a substantial feature of MWEs.
Neverthe-less since the number of negative and positive ex-amples which are bigrams are approximately thesame, the bias toward x9in discriminating MWEsfrom non-MWE balances out.
However its as-sociation with other features which is implicitlylearned still has an impact on discriminating thesetwo classes.
x7and x8are the next two importantfeatures, as we expected.
These two are the fea-tures whose magnitude suggests the presence orlack of contexts such as (the..of ).x1 x2 x3 x4 x5 x6 x7 x8 x9 x10        x11(avg rnk)05101520FeaturesRanksFigure 3: Ranks of the features that represent theirdiscriminant impact.The class separability of MWE (1), and non-MWE (?1) examples can be seen in Fig.
4, wherethe bidimentional projection of the examples oftwo classes is visualized.
A star plot of a sampleof 50 manually annotated examples is shown inFig.
5.
In many cases, but not always, non-MWEscan be discriminated from MWEs, in this elevendimensional visualization.
Same pattern was ob-served in the visualization of 500 examples (whichwould be hard to demonstrate in the present pa-per?s scale).0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1?3?2?10123 x 106tf(t)?11Figure 4: Andrews curve for the training exam-ples.
Bold line in the middle, and bold dottedline represent the median of MWE and non-MWEclasses respectively.4 Conclusions and Future WorkWe presented a method to extract MWEs basedon the immediate context they occur in, usinga supervised model.
Several contextual featureswere extracted from a large corpus.
The size ofthe corpus had a profound effect on the effective-ness of these features.
The presented MWE ex-traction model reaches a relatively high accuracyon an unseen test set.
In future work, the effi-ciency of this approach on languages other thanEnglish will be studied.
Furthermore, other fea-tures - specifically deep linguistic ones e.g., de-gree of constituency as described in (Ponvert etal., 2011) or POS tags, will be added to the fea-ture representation of MWE candidates.
Finallycontext-based probabilistic scores which are lin-guistically motivated can be investigated and com-pared with the supervised model.
Another inter-esting work would be to introduce kernels so thatwe can go from statistics of contextual features totraining the supervised model directly on the tex-tual context.14?1 1 ?1 1 1 ?1 ?1 11 ?1 1 ?1 ?1 ?1 1 11 1 ?1 ?1 1 ?1 1 ?1?1 ?1 1 ?1 ?1 ?1 ?1 ?1?1 1 1 ?1 1 1 1 1?1 ?1 ?1 ?1 ?1 1 ?1 ?1?1 1Figure 5: Star plot of 50 MWE (1), and non-MWE(?1) examplesReferencesOtavio Acosta, Aline Villavicencio, and Viviane Mor-eira.
2011.
Identification and treatment of multi-word expressions applied to information retrieval.Kordoni et al, pages 101?109.Timothy Baldwin and Su Nam Kim.
2010.
Multiwordexpressions.
Handbook of Natural Language Pro-cessing, second edition.
Morgan and Claypool.Timothy Baldwin and Aline Villavicencio.
2002.
Ex-tracting the unextractable: A case study on verb-particles.
In proceedings of the 6th conference onNatural language learning-Volume 20, pages 1?7.Association for Computational Linguistics.Timothy Baldwin.
2005.
Deep lexical acquisition ofverb?particle constructions.
Computer Speech &Language, 19(4):398?414.Nicoletta Calzolari, Charles J Fillmore, Ralph Gr-ishman, Nancy Ide, Alessandro Lenci, CatherineMacLeod, and Antonio Zampolli.
2002.
Towardsbest practice for multiword expressions in computa-tional lexicons.
In LREC.Helena de Medeiros Caseli, Carlos Ramisch, Maria dasGrac?as Volpe Nunes, and Aline Villavicencio.
2010.Alignment-based extraction of multiword expres-sions.
Language resources and evaluation, 44(1-2):59?77.Ga?el Dias.
2003.
Multiword unit hybrid extrac-tion.
In Proceedings of the ACL 2003 workshopon Multiword expressions: analysis, acquisition andtreatment-Volume 18, pages 41?48.
Association forComputational Linguistics.Jianyong Duan, Mei Zhang, Lijing Tong, and FengGuo.
2009.
A hybrid approach to improve bilin-gual multiword expression extraction.
In Advancesin Knowledge Discovery and Data Mining, pages541?547.
Springer.Stefan Evert.
2005.
The statistics of word cooccur-rences.
Ph.D. thesis, Dissertation, Stuttgart Univer-sity.Jean-Philippe Goldman, Luka Nerima, and EricWehrli.
2001.
Collocation extraction using a syn-tactic parser.
In Proceedings of the ACL Workshopon Collocations, pages 61?66.David A Hull and Gregory Grefenstette.
1996.
Query-ing across languages: a dictionary-based approachto multilingual information retrieval.
In Proceed-ings of the 19th annual international ACM SIGIRconference on Research and development in infor-mation retrieval, pages 49?57.
ACM.Ray Jackendoff.
1997.
The architecture of the lan-guage faculty.
Number 28.
MIT Press.Christian Jacquemin, Judith L Klavans, and EvelyneTzoukermann.
1997.
Expansion of multi-wordterms for indexing and retrieval using morphologyand syntax.
In Proceedings of the eighth conferenceon European chapter of the Association for Com-putational Linguistics, pages 24?31.
Association forComputational Linguistics.Mirella Lapata and Alex Lascarides.
2003.
Detect-ing novel compounds: The role of distributional ev-idence.
In Proceedings of the tenth conference onEuropean chapter of the Association for Computa-tional Linguistics-Volume 1, pages 235?242.
Asso-ciation for Computational Linguistics.Wei Li, Xiuhong Zhang, Cheng Niu, Yuankai Jiang,and Rohini Srihari.
2003.
An expert lexicon ap-proach to identifying english phrasal verbs.
In Pro-ceedings of the 41st Annual Meeting on Associa-tion for Computational Linguistics-Volume 1, pages513?520.
Association for Computational Linguis-tics.Diana McCarthy, Bill Keller, and John Carroll.2003.
Detecting a continuum of compositionalityin phrasal verbs.
In Proceedings of the ACL 2003workshop on Multiword expressions: analysis, ac-quisition and treatment-Volume 18, pages 73?80.Association for Computational Linguistics.Archibald Michiels and Nicolas Dufour.
1998.
Defi,a tool for automatic multi-word unit recognition,meaning assignment and translation selection.
InProceedings of the first international conference onlanguage resources & evaluation, pages 1179?1186.Begona Villada Moir?on and J?org Tiedemann.
2006.Identifying idiomatic expressions using automaticword-alignment.
In Proceedings of the EACL 2006Workshop on Multi-wordexpressions in a multilin-gual context, pages 33?40.David Nadeau and Satoshi Sekine.
2007.
A sur-vey of named entity recognition and classification.Lingvisticae Investigationes, 30(1):3?26.15Luka Nerima, Violeta Seretan, and Eric Wehrli.
2003.Creating a multilingual collocation dictionary fromlarge text corpora.
In Proceedings of the tenth con-ference on European chapter of the Association forComputational Linguistics-Volume 2, pages 131?134.
Association for Computational Linguistics.Darren Pearce.
2001.
Synonymy in collocation ex-traction.
In Proceedings of the Workshop on Word-Net and Other Lexical Resources, Second meeting ofthe North American Chapter of the Association forComputational Linguistics, pages 41?46.
Citeseer.Pavel Pecina.
2010.
Lexical association measuresand collocation extraction.
Language resources andevaluation, 44(1-2):137?158.Scott Songlin Piao and Tony McEnery.
2001.
Multi-word unit alignment in english-chinese parallel cor-pora.
In the Proceedings of the Corpus Linguistics2001, pages 466?475.Scott SL Piao, Paul Rayson, Dawn Archer, AndrewWilson, and Tony McEnery.
2003.
Extracting mul-tiword expressions with a semantic tagger.
In Pro-ceedings of the ACL 2003 workshop on Multiwordexpressions: analysis, acquisition and treatment-Volume 18, pages 49?56.
Association for Computa-tional Linguistics.Elias Ponvert, Jason Baldridge, and Katrin Erk.
2011.Simple unsupervised grammar induction from rawtext with cascaded finite state models.
In ACL, pages1077?1086.Carlos Ramisch.
2012.
A generic framework for mul-tiword expressions treatment: from acquisition toapplications.
In Proceedings of ACL 2012 StudentResearch Workshop, pages 61?66.
Association forComputational Linguistics.Lev Ratinov and Dan Roth.
2009.
Design challengesand misconceptions in named entity recognition.
InProceedings of the Thirteenth Conference on Com-putational Natural Language Learning, pages 147?155.
Association for Computational Linguistics.Zhixiang Ren, Yajuan L?u, Jie Cao, Qun Liu, and YunHuang.
2009.
Improving statistical machine trans-lation using domain bilingual multiword expres-sions.
In Proceedings of the Workshop on MultiwordExpressions: Identification, Interpretation, Disam-biguation and Applications, pages 47?54.
Associa-tion for Computational Linguistics.Ivan A Sag, Timothy Baldwin, Francis Bond, AnnCopestake, and Dan Flickinger.
2002.
Multiwordexpressions: A pain in the neck for NLP.
In Compu-tational Linguistics and Intelligent Text Processing,pages 1?15.
Springer.Violeta Seretan and Eric Wehrli.
2006.
Accurate col-location extraction using a multilingual parser.
InProceedings of the 21st International Conferenceon Computational Linguistics and the 44th annualmeeting of the Association for Computational Lin-guistics, pages 953?960.
Association for Computa-tional Linguistics.Violeta Seretan.
2011.
Syntax-based collocation ex-traction, volume 44.
Springer.Frank Smadja, Kathleen R McKeown, and VasileiosHatzivassiloglou.
1996.
Translating collocations forbilingual lexicons: A statistical approach.
Compu-tational linguistics, 22(1):1?38.Frank Smadja.
1993.
Retrieving collocations fromtext: Xtract.
Computational linguistics, 19(1):143?177.Tim Van de Cruys and Begona Villada Moir?on.
2007.Semantics-based multiword expression extraction.In Proceedings of the Workshop on a Broader Per-spective on Multiword Expressions, pages 25?32.Association for Computational Linguistics.Dominic Widdows and Beate Dorow.
2005.
Automaticextraction of idioms using graph analysis and asym-metric lexicosyntactic patterns.
In Proceedings ofthe ACL-SIGLEX Workshop on Deep Lexical Acqui-sition, pages 48?56.
Association for ComputationalLinguistics.Yi Zhang, Valia Kordoni, Aline Villavicencio, andMarco Idiart.
2006.
Automated multiword ex-pression prediction for grammar engineering.
InProceedings of the Workshop on Multiword Expres-sions: Identifying and Exploiting Underlying Prop-erties, pages 36?44.
Association for ComputationalLinguistics.16
