Assessing the Retrieval Effectiveness of a Speech:Retrieval System by Simulating Recognition ErrorsPeter Sch~uble, Ulrike GlavitschSwiss Federal Institute of Technology (ETH)CH-8092 Zurich, SwitzerlandABSTRACTWe show how the recognition performance of a speech recog-nition component in a speech retrieval system affects theretrieval effectiveness.
A speech retrieval system facilitatescontent-based retrieval of speech documents, i.e.
audiorecordings containing spoken text.
The speech retrieval pro-cess receives queries from users and for every query it ranksthe speech documents in decreasing order of their probabil-ities that they are relevant o the query.
The speech recog-nition component is an important part of a speech retrievalsystem, since it detects the occurrences of indexing featuresin the documents.
Because the recognition of indexing fea-tures in continuous peech is error prone, the question ariseshow much an error prone recognition of indexing features af-fects the retrieval effectiveness.
As an answer to this questionand main contribution of this paper we simulated the recog-nition of indexing features in speech documents on standardinformation retrieval test collections and show the resultingretrieval accuracies.1.
In t roduct ionWe show how the recognition performance of a speech recog-nition component in a speech retrieval system affects theretrieval effectiveness.
A speech retrieval system facilitatescontent-based retrieval of speech documents, i.e.
audiorecordings containing spoken text \[5\].
The speech retrievalprocess receives queries from users and for every query itranks the speech documents in decreasing order of their prob-abilities that they are relevant o the query.
These probabil-ities are derived from the occurrences of indexing featuresthat were identified in the speech documents by a speechrecognition component \[4\].
Because the recognition of index-ing features in continuous peech is error prone, the questionarises how much an error prone recognition of indexing fea-tures affects the retrieval effectiveness.The indexing features used in our speech retrieval systemare phonetically motivated subword units having an inter-mediate specificity.
The general pattern of an indexing fea-ture is a maximum sequence of consonants enclosed by twomaximum sequences of vowels at both ends.
We call theseindexing features VCV-features where C stands for the maxi-mum sequence of consonants and V stands for the maximumsequence of vowels.
As an example, the word INTERNA-T IONAL contains the VCV-features INTE, ERNA, ATIO,and IONA.
The indexing vocabulary is defined to be the setof those VCV-featutes ~,i whose inverse document frequen-cies idf(~oi) are between a lower bound id fmi ,  and an up-per bound idf, no,  such that the indexing features are neither370very specific nor very broad.
The lower bound guaranteesthe suitability for indexing and the upper bound guaranteesthe trainability, i.e.
there are enough examples to train the8MMs.
Experiments on standard information retrieval testcollections howed that when using an appropriate subset ofonly 1000 VCV-features we can achieve a retrieval effective-ness that is comparable to standard weighted retrieval whichis based on a much larger indexing vocabulary \[4\].
In additionto the VCV-features, we have also studied indexing vocab-ularies that have been extended by CV- and VC-features atthe word boundariesThe recognition of speech documents i carried out with stan-dard speech recognition technology, i.e.
a wordspotter \[6\],\[11\], \[14\] locates the occurrences of indexing features in doc-uments.
For each document in the collection we create adescription vector based on the number of occurrences ofeach feature and use a conventional retrieval function \[12\]to estimate the similarity between a document and a querydescription.Our indexing features consisting of VCV-features can be iden-tified in both text and speech documents.
As a consequence,the document collection may contain a mixture of text andspeech documents.
Furthermore, the query may also be en-tered as either text or speech.
The controlled indexing vocab-ulary consisting of selected VCV-features has the advantagethat the document description can be computed before thequery evaluation.
In particular, an access structure (e.g.
aninverted file) can be constructed to allow fast query evalua-tion.
Another important advantage of our indexing vocabu-lary for both text and speech retrieval is that speech retrievalcan simulated by using text collections as described in thesubsequent sections.Information Retrieval on audio documents has been investi-gated very little.
A wordspotting system for voice indexingwas developed by Wilcox and Bush \[14\] and an informationretrieval system that classifies peech messages was presentedby Rose, Chang, and Lippmann \[10\].
Recently a project forvideo mail retrieval using voice was proposed by Olivetti re-search Limited, Cambridge University Engineering Depart-ment, and Cambridge University Computer Laboratory \[7\].The effects of recognition errors on on the retrieval effective-ness has been studied in the context of OCR based Informa-tion Retrieval \[1\].
These results are not directly comparablebecause speech retrieval performance may be considerablyaffected by false alarms in contrast o OCR-based retrievalwhere false alarms can be ignored because the occur infre-quently.MEDLARS: average precision of the reference method: 0.534 (100%),.dr, f a 090% 0.539 (101%)80% 0.530 (99%)70% 0.487 (91%)60% 0.481 (90%)50% 0.431 (81%)40% 0.421 (79%)100.464 (87%)0.444 (83%)0.406 (76%)0.400 (75%)0.335 (63%)0.318 (60%)200.432 (81%)0.425 (80%)0.400 (75%)0.360 (67%)0.317 (59%)0.271 (51%)500.421 (79%)0.403 (75%)0.388 (73%)0.340 (64%)0.318 (60%)0.284 (53%)800.428 (80%)0.402 (75%)0.389 (73%)0.352 (66%)0.319 (60%)0.299 (56%)1100.412 (77%)0.413 (77%)0.349 (65%)0.335 (63%)0.285 (53%)0.269 (50%)CRANFIELD: average precision of the reference method: 0.408 (100%)dr, fa 090% 0.330 (81%)80% 0.324 (79%)70% 0.305 (75%)60% 0.297 (73%)50% 0.277 (68%)40% 0.259 (63%)I00.315 (77%)0.299 (73%)0.283 (69%)0.253 (62%)0.236 (58%)0.216 (53%)2O0.304 (75%)0.291 (71%)0.267 (65%)0.234 (57%)0.224 (55%)0.191 (47%)500.288 (71%)0.276 (68%)0.265 (65%)0.245 (60%)0.226 (55%)0.185 (45%)800.279 (68%)0.265 (65%)0.242 (59%)0.249 (61%)0.211 (52%)0.191 (47%)1100.264 (65%)0.253 (62%)0.249 (61%)0.224 (55%)0.206 (50%)0.175 (43%)CACM: average precision of the reference method: 0.257 (100%).dr, t .
i o90% i 0.132 (51%)80% 0.134 (52%)70% 0.124 (48%)60% 0.111 (43%)50% 0.113 (44%)40% 0.076 (30%)100.138 (54%)0.133 (52%)0.110 (43%)0.097 (38%)0.097 (38%)0.078 (30%)200.155 (60%)0.135 (53%)0.129 (50%)0.103 (40%)0.084 (33%)0.048 (19%)500.156 (61%)0.136 (53%)0.115 (45%)0.096 (37%)0.098 (38%)0.057 (22%)800.131 (51%)0.113 (44%)0.104 (40%)0.103 (40%)o.o91 (35%)0.079 (31%)1100.139 (54%)o.116 (45%)0.095 (37%)0.109 (42%)0.085 (33%)0.069 (27%)Table 1: Average precision values for detection rates within the range of 40% and 90% and false alaxms per indexing feature(key word) per hour within the range of 0 and 140.
The numbers in brackets represent the percentage of the average precisionof the reference method, i.e.
a standard text retrieval method.The main contribution of this paper is the conclusion thatspeech retrieval is feasible to some extent even when therecognition performance is poor.
A closer look reveals thatrecognition errors and occurrences of query features in thedocuments have different distributions and standard retrievalmethods are quite good in distinguishing these two distribu-tions.
The next two sections describe the test setting and theresults respectively.
Then, some conclusions are drawn.2.
Test  Set t ingThe experiments are performed by means of the the standardinformation retrieval text collections CRANFIELD, MED-LAtLS, and CACM \[2\].
The indexing vocabulary consists ofthe VCV-, CV-, and VC-features ~i whose inverse documentfrequencyn+l  1)  idf(~,) := log k df(~i) S ris between the lower bound idfmin := 1.6 and an upper boundidfma~ which is chosen such that the indexing vocabularyconsists of exactly 1000 features.
Every indexing feature ~iand every document dj is assigned a weightaij := ff(cPi, dj) * idf(~i).371Analogously, every indexing feature ~i is assigned a weightbi := ff(~i,q)*idf(~oi)with respect o a given query q.
As usual, the documentsare presented to the user in decreasing order of the RetrievalStatus Values RSV(q, dj) that are determined by the cosinemeasure.~ i  aid * bi RSV(q, d~) :=The recognition errors were simulated in three steps.
First,a parser converts a text document into a sequence of index-ing features by detecting VCV-, CV-, and VC-features thatbelong to the indexing vocabulary.
Second, the sequence ofindexing features i converted into another sequence of index-ing features by removing features as follows.
For every featurein the input sequence it is randomly determined whether it isrecognized or not.
If it is recognized, the feature is includedin the output sequence; otherwise, it is removed.
The prob-ability that a feature is recognized is equal to the specifieddetection rate.
Third, the reduced sequence of indexing fea-tures is converted into a final sequence by adding indexingfeatures as follows.
Assume that the original document con-sists of k occurrences of a word.
According to \[8\], an averagespeaker needs approximately k/170 minutes or At := k/1020hours for such a document with k word occurrences.
Wethen add!
fa * At occurrences of every indexing feature wheref a denolLes the specified false alarms per keltword per hour.For simplicity, every indexing feature is assumed to have thesame detection rate and false alarms.3.
ResultsTable 1 shows the average precision values for various detec-tion rates and false alarm rates.
The numbers in bracketsrepresent he percentage of a average precision of the ref-erence method.
The reference method represents a standardtext retrieval method which is based on words rather than onVCV-features.
In our case here, the reference method usesvan Rijsbergen's \[13\] stoplist to eliminate the high-frequencywords.
Furthermore, it uses the word reduction algorithm byPorter \[9\] to reduce different variants of a words to the samenormal form.
The term weights consist of simple t f  * idfweights and the retrieval status values are obtained by thecosine measure.Current wordspotting systems report high detection ratesand low false alarms for the recognition of entire words inspeech documents \[2\],\[3\],\[4\].
These systems, however, areusually evaluated on small tasks: the vocabulary of thespeech database is in the order of 1000 words and the num-ber of words spotted is small.
On the other hand, the task toidentify 1000 VCV-features in speech documents with an un-limited vocabulary is much more difficult and the correspond-ing false alarms are one to two orders of magnitude higher.We therefore consider detection rates within the range of 40%and 90% and false alarms per keyword (i.e.
per indexing fea~ture) per hour within the range of 0 and 140.4.
ConclusionsWe have shown that speech retrieval is feasible to some extenteven when the recognition performance is poor.
It should benoted that a retrieval effectiveness which is moderate becauseof recognition errors may well be in the range of the retrievaleffectiveness of the commonly used boolean retrieval method.In the case of MEDLARS, for instance, the boolean retrievalmethod achieves a retrieval effectiveness which correspondsto 40 % detection rate and 140 false alarms per indexingfeature per hour \[3\].
It seems that recognition errors and oc-currences of query features in the documents have differentdistributions and standard retrieval methods are quite goodin distinguishing these two distributions.
Further investiga-tions are needed to study the influence of the length of thequeries and the length of the documents.References1.
W. B. Croft, S. Harding, K. Taghva, and J. Borsack.An Evaluation of Information Retrieval Accuracy withSimulated OCR Output.
Journal of the ASIS, 1994.2.
E. A.
Fox.
Virginia Disc One.
Virginia Polytechnic In-stitute and State University, Department of ComputerScience, 1990.3.
E. A.
Fox and M. B. Koll.
Practical EnhancedBoolean Retrieval: Experiences with the SMART and372SIRE Systems.
Information Processing 0 Management,24(3):257-267, 1988.4.
U. Glavitsch and P. Schluble.
A System for RetrievingSpeech Documents.
In N. Belkin, P. Ingwersen, andA.
M. Pejtersen, editors, A CM SIGIR Conference onROD in Information Retrieval, pages 168-176, 1992.5.
U. Glavitsch and P. Schiuble.
Speech Retrieval ina Multimedia System.
In European Signal ProcessingConference (EUSIPCO), pages 295-298, 1992.6.
D. James and S.J.
Young.
A Fast Lattice-Based Ap-proach to Vocabulary-Independent Word Spotting.
InInternational Conference on Acoustics, Speech, and Sig-nal Processing, 1994.7.
K. Sparck Jones.
VMR-Video Mail retrieval UsingVoice.
Personal communication.8.
W. A. Lea.
Trends in Speech Recognition.
Prentice-Hall,Englewood Cliffs, N J, 1980.9.
M. F. Porter.
An Algorithm for Suffix Stripping.
Pro.gram, 14(3):130-137, 1980.10.
R. C. Rose, E. I. Chang, and R. Lippmann.
Techniquesfor Information Retrieval from Voice Messages.
In In-ternational Conference on Acoustics, Speech, and SignalProcessing, pages 317-320, 1991.11.
R. C. Rose and D. B. Paul.
A Hidden Markov ModelBased Keyword Recognition System.
In InternationalConference on Acoustics, Speech, and Signal Processing,pages 129-132, 1990.12.
G. Salton and C. Buckley.
Term Weighting Approachesin Automatic Text Retrieval.
Information Processing 0Management, 24(5):513-523, 1988.13.
C. J. van Rijsbergen.
Information Retrieval.
Butter-worths, London, second edition, 1979.14.
L. D. Wilcox and M. A. Bush.
HMM-Based Wordspot-ring for Voice Editing and Indexing.
In European Con-ference on Speech Communication a d Technology (EU-ROSPEECH}, pages 25-28, 1991.
