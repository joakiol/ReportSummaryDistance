Proceedings of the 5th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, pages 24?30,Baltimore, Maryland, USA.
June 27, 2014.c?2014 Association for Computational LinguisticsAspect-Level Sentiment Analysis in CzechJosef SteinbergerDepartment of ComputerScience and Engineering,Faculty of Applied Sciences,University of West Bohemia,Univerzitn??
8, 306 14 Plze?nCzech Republicjstein@kiv.zcu.czTom?a?s Brychc?
?nNTIS ?
New Technologiesfor the Information Society,Faculty of Applied Sciences,University of West Bohemia,Univerzitn??
8, 306 14 Plze?nCzech Republicbrychcin@kiv.zcu.czMichal KonkolNTIS ?
New Technologiesfor the Information Society,Faculty of Applied Sciences,University of West Bohemia,Univerzitn??
8, 306 14 Plze?nCzech Republickonkol@kiv.zcu.czAbstractThis paper presents a pioneering re-search on aspect-level sentiment analysisin Czech.
The main contribution of thepaper is the newly created Czech aspect-level sentiment corpus, based on data fromrestaurant reviews.
We annotated the cor-pus with two variants of aspect-level senti-ment ?
aspect terms and aspect categories.The corpus consists of 1,244 sentences and1,824 annotated aspects and is freely avail-able to the research community.
Further-more, we propose a baseline system basedon supervised machine learning.
Oursystem detects the aspect terms with F-measure 68.65% and their polarities withaccuracy 66.27%.
The categories are rec-ognized with F-measure 74.02% and theirpolarities with accuracy 66.61%.1 IntroductionThe interest in sentiment analysis (SA) is increas-ing with the amount of easily accessible content onthe web, especially from the social media.
Sen-timent polarity is one of the critical informationneeded for many analysis of the data.
Its useranges from analysing product reviews (Stepanovand Riccardi, 2011) to predicting sales and stockmarkets using social media monitoring (Yu et al.,2013).The majority of current approaches tries to de-tect the overall polarity of a sentence (or a docu-ment) regardless of the target entities (e.g., restau-rants, laptops) and their aspects (e.g., food, price,battery, screen).
By contrast, the aspect-drivensentiment analysis identifies the aspects of a giventarget entity and estimates the sentiment polarityfor each mentioned aspect.
This opens up com-pletely new possibilities how to analyse the data.The most of the research in automatic sentimentanalysis has been devoted to English.
There wereseveral attempts in Czech (Steinberger et al., 2011;Veselovsk?a, 2012; Habernal et al., 2013; Brychc?
?nand Habernal, 2013), but all were focused on theglobal (sentence- or document-level) sentiment.Although Czech is not a widely-spoken languageon the global scale, it is in many ways similarto other Slavic languages and their speakers al-together represent an important group.
The richmorphology and the free word order also makes itinteresting from the linguistic perspective.Our main goal is the creation of a aspect-levelcorpus as there is no such resource for Czech.We would like to support the beginning of aspect-level sentiment analysis for Czech and a human-annotated corpus is the first step in this direc-tion.
In addition, we want to provide results ofa baseline system (based on machine leaning tech-niques).
This creates an easily reproducible start-ing point and allows anyone to quickly join the re-search of this task.The rest of the paper is organised as follows.Section 2 is devoted to related work.
It covers theaspect-level SA and sentiment analysis in Czech.Then we introduce the aspect-level architecture(Section 3) used for both the annotation of the cor-pus (Section 4) and for the automatic supervisedapproach (Section 5).
In Section 6 we sumarizeour contribution and reveal our future plans.2 Related workThe impact of SA can be seen in many practicalapplications, The users?
opinions are mostly ex-tracted either on a certain polarity scale, or binary(positive, negative).
From the point of view ofthe granularity, the polarity has been assigned toa document or to a sentence.
However, classify-ing opinions at the document level or the sentencelevel is often insufficient for applications becausethey do not identify opinion targets or assign sen-timents to such targets (Liu, 2012).
Even if werecognize the target entity (as the entity-centered24approaches do (e.g.
Steinberger et al.
(2011)), apositive opinion about the entity does not meanthat the author has positive opinions about all as-pects of the entity.
Aspect-based sentiment analy-sis, which has been also called ?feature-based?
(Huand Liu, 2004), goes even deeper as it attempts toidentify (and assign the polarity to) aspects of thetarget entity within a sentence (Hajmohammadi etal., 2012).
Whenever we talk about an aspect,we must know which entity it belongs to.
In thefurther discussion, we often omit the entity as weanalysed restaurant reviews and thus our target en-tities are the reviewed restaurants.2.1 Aspect-based sentiment analysisThe aspect scenario can be decomposed into twotasks: aspect extraction and aspect sentiment clas-sification (Liu, 2012).2.1.1 Aspect extractionThe task of aspect extraction, which can also beseen as an information extraction task, is to detectaspects that have been evaluated.
For example, inthe sentence, The voice quality of this phone isamazing, the aspect is voice quality of the entityrepresented by this phone.The basic approach is finding frequent nounsand noun phrases.
In (Liu et al., 2005), a specificmethod based on a sequential learning method wasproposed to extract aspects from pros and cons,Blair-Goldensohn et al.
(2008) refined the frequentnoun and noun phrase approach by consideringmainly those noun phrases that are in sentiment-bearing sentences or in some syntactic patternswhich indicate sentiments.
Moghaddam and Ester(2010) augmented the frequency-based approachwith an additional pattern-based filter to removesome non-aspect terms.
Long et al.
(2010) ex-tracted aspects (nouns) based on frequency and in-formation distance.Using supervised learning is another option.Aspect extraction can be seen as a special caseof the general information extraction problem.The most dominant methods are based on sequen-tial learning.
Since these are supervised tech-niques, they need manually labeled data for train-ing.
One needs to manually annotate aspectsand non-aspects in a corpus.
The current state-of-the-art sequential learning methods are Hid-den Markov Models (HMM) (Rabiner, 2010) andConditional Random Fields (CRF) (Lafferty et al.,2001).The last group of methods use topic models(Mei et al., 2007; Titov and McDonald, 2008;Blei et al., 2003).
There are two main basic mod-els, pLSA (Probabilistic Latent Semantic Analy-sis) (Hofmann, 1999) and LDA (Latent Dirichletallocation) (Blei et al., 2003).
In the SA context,one can design a joint model to model both senti-ment words and topics at the same time, due to theobservation that every opinion has a target.2.1.2 Aspect sentiment classificationThis task is to determine whether the opinions ondifferent aspects are positive, negative, or neutral.The classification approaches can be divided tosupervised learning approaches and lexicon-basedapproaches.
Supervised learning performs bet-ter in a particular application domain but it hasdifficulty to scale up to a large number of do-mains.
Lexicon-based techniques often lose thefight against the learning but they are suitable foropen-domain applications (Liu, 2012).The key issue for learning methods is to de-termine the scope of each sentiment expression,i.e., whether it covers the aspect of interest in thesentence.
In (Jiang et al., 2011), a dependencyparser was used to generate a set of aspect de-pendent features for classification.
A related ap-proach was also used in (Boiy and Moens, 2009),which weights each feature based on the positionof the feature relative to the target aspect in theparse tree.Lexicon-based approaches use a list of senti-ment phrases as the core resource.
The methodin (Ding et al., 2008) has four steps to assigna polarity to an aspect: mark sentiment wordsand phrases, apply sentiment shifters, handle but-clauses and aggregate opinions using an aggrega-tion function (e.g.
Hu and Liu (2004)).2.2 Sentiment analysis for CzechPilot study of Czech sentiment analysis was shownin (Steinberger et al., 2012) where sentiment dic-tionaries for many languages (including Czech)were created using semi-automatic ?triangulation?method.Veselovsk?a (2012) created a small corpus con-taining polarity categories for 410 news sentencesand used the Naive Bayes and lexicon-based clas-sifiers.Three large labeled corpora (10k Facebookposts, 90k movie reviews, and 130k productreviews) were introduced in (Habernal et al.,252013).Authors also evaluate three different classi-fiers, namely Naive Bayes, SVM (Support VectorMachines) and Maximum Entropy on these data.Recently, Habernal and Brychc?
?n (2013) experi-mented with building word clusters, obtained fromsemantic spaces created on unlabeled data, as anadditional source of information to tackle the highflection issue in Czech.These results were later outperformed byanother unsupervised extension (Brychc?
?n andHabernal, 2013), where the global target contextwas shown to be very useful source of informa-tion.3 The task definitionThe aspect-level sentiment analysis firstly identi-fies the aspects of the target entity and then assignsa polarity to each aspect.
There are several waysto define aspects and polarities.
We use the defini-tion based on the Semeval2014?s Aspect-based SAtask, which distinguishes two types of aspect-levelsentiment ?
aspect terms and aspect categories.The task is decomposed into the following 4subtasks.
We briefly describe each subtask andgive some examples of source sentences and theexpected results of the subtask.3.1 Subtask 1: Aspect term extractionGiven a set of sentences with pre-identified enti-ties (e.g., restaurants), the task is to identify theaspect terms present in the sentence and return alist containing all the distinct aspect terms.
An as-pect term names a particular aspect of the targetentity.Examples:D?eti dostaly naprosto krvav?e maso.
(They brought a totally bloody meat to the kids.)?
{maso (meat)}Tla?cenka se rozpadla, pol?evka u?sla.
(The porkpie broke down, the soup was ok.)?
{Tla?cenka (porkpie), pol?evka (soup)}3.2 Subtask 2: Aspect term polarityFor a given set of aspect terms within a sentence,the task is to determine the polarity of each aspectterm: positive, negative, neutral or bipolar (i.e.,both positive and negative).Examples:D?eti dostaly naprosto krvav?e maso.
(They brought a totally bloody meat to the kids.)?
{maso (meat): negative}Tla?cenka se rozpadla, pol?evka u?sla.
(The porkpie broke down, the soup was ok.)?
{Tla?cenka (porkpie): negative, pol?evka (soup):positive}3.3 Subtask 3: Aspect category detectionGiven a predefined set of aspect categories (e.g.,price, food), the task is to identify the aspect cat-egories discussed in a given sentence.
Aspect cat-egories are typically coarser than the aspect termsof Subtask 1, and they do not necessarily occur asterms in the given sentence.For example, given the set of aspect categoriesfood, service, price, ambience:P?riv?
?tala n?as velmi p?r?
?jemn?a serv?
?rka, ale tak?em?
?stnost s o?sunt?el?ym n?abytkem.
(We found a very nice waitress but also a roomwith time-worn furniture.)?
{service, ambience}Tla?cenka se rozpadla, pol?evka u?sla.
(The porkpie broke down, the soup was ok.)?
{food}3.4 Subtask 4: Aspect category polarityGiven a set of pre-identified aspect categories(e.g., {food, price}), the task is to determine thepolarity (positive, negative, neutral or bipolar) ofeach aspect category.Examples:P?riv?
?tala n?as velmi p?r?
?jemn?a serv?
?rka, ale tak?em?
?stnost s o?sunt?el?ym n?abytkem.
(We found a very nice waitress but also a roomwith time-worn furniture.)?
{service: positive, ambience: negative}Tla?cenka se rozpadla, pol?evka u?sla.
(The porkpie broke down, the soup was ok.)?
{food: bipolar}4 Building the aspect-level corpusAspect-level annotations are strictly connected tothe analysed domain.
As our final goal is goingmultilingual, we work on the domains selected forthe Semeval2014?s Aspect-based SA task (restau-rants, laptop) which will allow us to compare ap-proaches for both English and Czech on the samedomains.We started with the restaurants and in the future,we would also like to cover the laptops.26We downloaded restaurant reviews from www.nejezto.cz.
Ten restaurants with the largestnumber of reviews were selected.
The reviewswere splitted into sentences.
Average number ofsentences per restaurant was 223.4.1 GuidelinesThe purpose of this annotation was to detect as-pects and their sentiment polarity within sen-tences.
The target entities were particular restau-rants.
For a given restaurant, the annotator hadfollowing tasks:1.
Identify irrelevant sentences: Sentencesthat do not contain any information rele-vant to the topic of restaurants.
They werelater filtered out of the corpus.
Example:Ur?a?zet n?ekoho pro jeho n?azor je ned?ustojn?edosp?el?eho ?clov?eka.
(Offencing somebody forhis opinion is discreditable for an adult.)2.
Identify aspect terms: Single or multiwordterms naming particular aspects of the targetentity.
These are either full nominal phrases(?sp?
?z a restovan?e brambory ?
skewer withfried potatoes) or verbs (stoj??
?
priced).
Ref-erences, names or pronouns should not be an-notated.3.
Aspect term polarity: Each aspect term hasto be assigned one of the following polaritiesbased on the sentiment that is expressed in thesentence about it: positive, negative, bipo-lar (both positive and negative sentiment) andneutral (neither positive nor negative senti-ment).4.
Aspect category: The task of the annotator isto identify the aspect categories discussed ina sentence given the following five aspect cat-egories: food, service, price, ambience, gen-eral (sentences mentioning the restaurant asa whole).
Example: Celkov?e doporu?cuji avr?at?
?m se tam ?
Overall I would recommendit and go back again.
?
general.5.
Aspect category polarity: Each aspect cat-egory discussed by a particular sentence hasto be assigned one of the following polaritiesbased on the sentiment that is expressed in thesentence about it: positive, negative, bipolar,neutral.4.2 Annotation statisticsThree native Czech speakers annotated in total1,532 sentences.
18.8% of the sentences weremarked as irrelevant, leaving 1,244 sentences forfurther analysis.
Their average agreement for thetask of aspect terms?
identification was 82.6%(measured by F-measure).
Only strict matcheswere considered correct.
In the case of identi-fying the categories, their average agreement (F-measure) was 91.8%.
The annotators agreed on85.5% (accuracy) in the task of assigning polarityto terms and on 82.4% (accuracy) in the case ofthe category polarity assignment.
It correspondsto Cohen?s  of 0.762, resp.
0.711, which rep-resents a substantial agreement level (Pustejovskyand Stubbs, 2013), therefore the task can be con-sidered as well-defined.There were several reasons of disagreement.The annotators did not always itentify the sameterms, mainly in the cases with general meaning.In the case of polarity, the annotators did not agreeon the most difficult cases to which bipolar classcould be assigned:Trochu p?resolen?a om?a?cka, ale jinak luxus.
(Too salted sauce, but luxury otherwise.)?
{food: bipolar vs. positive}The cases, on which the two annotators did notagree, were judged by the third super-annotatorand golden standard data were created.
The finaldataset1contains 1244 sentences.
The sentencescontain 1824 annotated aspect terms (679 positive,725 negative, 403 neutral, 17 bipolar) and 1365categories (521 positive, 569 negative, 246 neu-tral, 28 bipolar).5 Results of the supervised approach5.1 OverviewWe use machine learning approach in all subtasks.For aspect term extraction we use ConditionalRandom Fields (CRF).
For the other three taskswe use the Maximum Entropy classifier.
We usethe Brainy2implementation of these algorithms.During the data preprocessing, we use simpleword tokenizer based on regular expressions.
Alltokens are lowercased for tasks 3 and 4.
Due to thecomplex morphology of Czech we also use the un-1We will provide the dataset at http://liks.fav.zcu.cz/sentiment.2Available at http://home.zcu.cz/?konkol/brainy.php27supervised stemmer called HPS3, that has alreadyproved to be useful in sentiment analysis (Haber-nal et al., 2013; Habernal and Brychc?
?n, 2013;Brychc?
?n and Habernal, 2013).All particular subtasks share following features:?
Bag of words: The occurrence of a word.?
Bag of bigrams: The occurrence of a bigram.?
Bag of stems: The occurrence of a stem.?
Bag of stem bigrams: The occurrence of astem bigram.5.2 Aspect term extractionThe system for aspect term extraction is based onCRF.
The choice of CRF is based on a current stateof the art in named entity recognition (see for ex-ample (Konkol and Konop?
?k, 2013)) as it is a verysimilar task.
We use the BIO (Ramshaw and Mar-cus, 1999) model to represent aspect terms.
In ad-dition to the previously mentioned features we useaffixes and learned dictionaries.
Affixes are sim-ply prefixes and suffixes of length 2 to 4.
Learneddictionaries are phrases that are aspect terms in thetraining data.Our system achieved 58.14 precision, 83.80 re-call and 68.65 F-measure.5.3 Aspect term polarityDuring the detection of the aspect term polarities,the words affecting the sentiment of the aspectterm are assumed to be close in most of cases.Thus we use a small window (10 words in bothdirections) around the target aspect term.
We as-sume the further the word or bigram is from thetarget aspect term, the lower impact it has on sen-timent label.
To model this assumption we usea weight for each word and bigram feature takenfrom the Gaussian distribution according to dis-tance from aspect term.
The mean is set to 0 andvariance is optimized on training data.
The classi-fier uses only the features presented in section 5.1.The results are presented in table 1.5.4 Aspect category detectionAspect category detection is based on the Maxi-mum Entropy classifiers.
We use one binary clas-sifier for each category.
Each classifier then de-cides whether the sentence has the given category3Available at http://liks.fav.zcu.cz/HPS.Table 1: Aspect term polarity results.
P , R andFmdenote the precision, recall and F-measure.The results are expressed by percentages.label P [%] R[%] Fm[%]negative 76.41 63.31 69.25neutral 33.75 50.18 40.36positive 74.78 76.82 75.78Accuracy: 66.27%or not.
For this task we use only the bag of stemsand Tf-Idf features.Our system achieved 68.71 precision, 80.21 re-call and 74.02 F-measure.5.5 Aspect category polarityFor the category polarity detection we use thesame features as for aspect term polarity detec-tion.
However in this case, we always take thewhole sentence into account.
We cannot take alimited window as we do not know where exactlythe category is mentioned in the sentence.
More-over, it can be at several positions.
To distinguishbetween different categories we use multiple Max-imum Entropy classifiers, one for each category.The results are shown in table 2.Table 2: Aspect category polarity results.
P ,R and Fmdenote the precision, recall and F-measure.
The results are expressed by percent-ages.label P [%] R[%] Fm[%]negative 74.07 66.04 69.83neutral 37.80 46.73 41.80positive 72.12 75.30 73.67Accuracy: 66.61%5.6 DiscussionIn section 5 we described our system for aspect-level sentiment analysis and showed the results.We do not use any language-dependent features,everything is learned from the training data.
It isthus possible to say that our system is both lan-guage and domain independent, i.e.
the system isable to work for any domain or language, if thetraining data are provided.From another perspective, the already trainedmodel is language and domain dependent (i.e.
themodel trained on restaurant domain probably willnot perform well on laptop domain).
The depen-28dence on the domain has multiple reasons.
First,the categories are defined strictly for one domain(e.g.
food, price, etc.).
Second, many words canhave different sentiment polarity in different do-mains.In general, the sentiment analysis deals withmany problems.
These problems are much moreevident for Czech as a representative of languagewith rich morphology and also with almost freeword order.
Here are two examples, where oursystem wrongly estimate the sentiment label.Na nic si nejde st?e?zovat.
(There is nothing to complain about.)?
{general: positive}The sentence contains words that frequently oc-cur in negative reviews: nic - nothing, st?e?zovat -complain; but the sentence is positive.O t?ech labu?znick?ych a delikatesn?
?ch z?a?zitc?
?ch si?clov?ek pouze p?re?cte, ale realita je jin?a.
(One can only read about these gourmand and de-licious experiences, but the reality is completelydifferent.)?
{food: negative}Sentence contains words like labu?znick?ych -gourmand and delikatesn?
?ch - delicious that arestrictly positive, but in this context it is mentionednegatively.As we already said, this is the pilot study ofaspect-level sentiment analysis in Czech.
Severalstudies about sentence-level sentiment analysis ofCzech have been already published, and thus itis worth comparing how these two tasks differ interms of difficulty.
Note that the aspect-level sen-timent analysis has to deal with multiple aspectsand categories in a given sentence, and thus it isapparently a much more difficult task.We believe the results of (Brychc?
?n and Haber-nal, 2013) on Czech movie reviews dataset can bea comparable example of sentence-level sentimentanalysis as they also distinguish 3 sentiment labels(positive, negative and neutral) and the data aretaken from a closed domain (movies).
Their bestresult (given by the model with all extensions) is81.53%.
Our best results are 66.27% and 66.61%for aspect and category polarity detection, respec-tively.6 ConclusionThe aspect level sentiment analysis has not beenstudied for Czech yet.
The main reason for this isthe lack of annotated data.
In this paper, we createa high quality gold data for this task, we describeour approach to their annotation and discuss theirproperties.
Corpus is available for free at http://liks.fav.zcu.cz/sentiment.We also propose a baseline model based onstate-of-the-art supervised machine learning tech-niques.
Our system is language and domain inde-pendent, i.e.
it can be easily trained on data fromanother domain or language.
It achieved 68.65%F-measure in the aspect term detection, 74.02% F-measure in the aspect category assigning, 66.27%accuracy in the aspect term polarity classification,and 66.61% accuracy in the aspect category polar-ity classification.In the future, we would like to continue theaspect-level research direction in three ways.
Wewould like to extend the currently created restau-rant reviews?
corpus, to add the second (laptop?s)domain to the corpus, and finally, to experimentwith extensions to the baseline system.
As thecorpus for the Semeval2014 aspect-based SA taskcontains review sentences from the same domains,we will be able to compare the results of the sys-tem cross-lingually.AcknowledgmentsThis work was supported by grant no.
SGS-2013-029 Advanced computing and informationsystems, by the European Regional DevelopmentFund (ERDF), by project ?NTIS - New Tech-nologies for Information Society?, European Cen-tre of Excellence, CZ.1.05/1.1.00/02.0090, and byproject MediaGist, EU?s FP7 People Programme(Marie Curie Actions), no 630786.ReferencesSasha Blair-Goldensohn, Kerry Hannan, Ryan McDon-ald, Tyler Neylon, George Reis, and Jeff Reynar.2008.
Building a sentiment summarizer for lo-cal service reviews.
In Proceedings of WWW-2008workshop on NLP in the Information Explosion Era.David M. Blei, Andrew Y. Ng, and Michael I. Jordan.2003.
Latent dirichlet allocation.
Journal of Ma-chine Learning Research, 3:993?1022.Erik Boiy and Marie-Francine Moens.
2009.
Amachine learning approach to sentiment analysisin multilingual web texts.
Information retrieval,12(5):526?558.Tom?a?s Brychc?
?n and Ivan Habernal.
2013.
Unsuper-vised improving of sentiment analysis using global29target context.
In Proceedings of the InternationalConference Recent Advances in Natural LanguageProcessing RANLP 2013, pages 122?128, Hissar,Bulgaria, September.
Incoma Ltd. Shoumen, Bul-garia.Xiaowen Ding, Bing Liu, and Philip S. Yu.
2008.
Aholistic lexicon-based approach to opinion mining.In Proceedings of the Conference on Web Search andWeb Data Mining.Ivan Habernal and Tom?a?s Brychc??n.
2013.
Semanticspaces for sentiment analysis.
In Text, Speech andDialogue, volume 8082 of Lecture Notes in Com-puter Science, pages 482?489, Berlin Heidelberg.Springer.Ivan Habernal, Tom?a?s Pt?a?cek, and Josef Steinberger.2013.
Sentiment analysis in czech social media us-ing supervised machine learning.
In Proceedings ofthe 4th Workshop on Computational Approaches toSubjectivity, Sentiment and Social Media Analysis,pages 65?74, Atlanta, Georgia, June.
Associationfor Computational Linguistics.Mohammad Sadegh Hajmohammadi, Roliana Ibrahim,and Zulaiha Ali Othman.
2012.
Opinion mining andsentiment analysis: A survey.
International Journalof Computers & Technology, 2(3).Thomas Hofmann.
1999.
Probabilistic latent semanticindexing.
In Proceedings of Conference on Uncer-tainty in Artificial Intelligence.Minqing Hu and Bing Liu.
2004.
Mining and summa-rizing customer reviews.
In Proceedings of the tenthACM SIGKDD international conference on Knowl-edge discovery and data mining, KDD ?04, pages168?177, New York, NY, USA.
ACM.Long Jiang, Mo Yu, Ming Zhou, Xiaohua Liu, andTiejun Zhao.
2011.
Target-dependent twitter sen-timent classification.
In Proceedings of the 49th An-nual Meeting of the Association for ComputationalLinguistics.Michal Konkol and Miloslav Konop??k.
2013.
Crf-based czech named entity recognizer and consolida-tion of czech ner research.
In Ivan Habernal andV?aclav Matou?sek, editors, Text, Speech and Dia-logue, volume 8082 of Lecture Notes in ComputerScience, pages 153?160.
Springer Berlin Heidel-berg.John Lafferty, Andrew McCallum, and FernandoPereira.
2001.
Conditional random fields: Prob-abilistic models for segmenting and labeling se-quence data.
In Proceedings of International Con-ference on Machine Learning.Bing Liu, Minqing Hu, and Junsheng Cheng.
2005.Opinion observer: Analyzing and comparing opin-ions on the web.
In Proceedings of InternationalConference on World Wide Web.Bing Liu.
2012.
Sentiment Analysis and Opinion Min-ing.
Morgan & Claypool Publishers.Chong Long, Jie Zhang, and Xiaoyan Zhu.
2010.
Areview selection approach for accurate feature ratingestimation.
In Proceedings of Coling 2010: PosterVolume.Qiaozhu Mei, Xu Ling, Matthew Wondra, Hang Su,and ChengXiang Zhai.
2007.
Topic sentiment mix-ture: modeling facets and opinions in weblogs.
InProceedings of International Conference on WorldWide Web.Samaneh Moghaddam and Martin Ester.
2010.
Opin-ion digger: an unsupervised opinion miner fromunstructured product reviews.
In Proceeding ofthe ACM conference on Information and knowledgemanagement.James Pustejovsky and Amber Stubbs.
2013.
NaturalLanguage Annotation for Machine Learning.
OR-eilly Media, Sebastopol, CA 95472.Lawrence Rabiner.
2010.
A tutorial on hidden markovmodels and selected applications in speech recogni-tion.
In Proceedings of the IEEE, pages 257?286.Lance A Ramshaw and Mitchell P Marcus.
1999.
Textchunking using transformation-based learning.
InNatural language processing using very large cor-pora, pages 157?176.
Springer.J.
Steinberger, P. Lenkova, M. Kabadjov, R. Stein-berger, and E. van der Goot.
2011.
Multilingualentity-centered sentiment analysis evaluated by par-allel corpora.
In Proceedings of the 8th Interna-tional Conference Recent Advances in Natural Lan-guage Processing, RANLP?11, pages 770?775.J.
Steinberger, M. Ebrahim, Ehrmann M., A. Hur-riyetoglu, M. Kabadjov, P. Lenkova, R. Steinberger,H.
Tanev, S. Vzquez, and V. Zavarella.
2012.
Cre-ating sentiment dictionaries via triangulation.
Deci-sion Support Systems, 53:689?694.E.A.
Stepanov and G. Riccardi.
2011.
Detecting gen-eral opinions from customer surveys.
In Data Min-ing Workshops (ICDMW), 2011 IEEE 11th Interna-tional Conference on, pages 115?122.Ivan Titov and Ryan McDonald.
2008.
Modeling on-line reviews with multi-grain topic models.
In Pro-ceedings of International Conference on World WideWeb.Kate?rina Veselovsk?a.
2012.
Sentence-level sentimentanalysis in czech.
In Proceedings of the 2nd Interna-tional Conference on Web Intelligence, Mining andSemantics.
ACM.Liang-Chih Yu, Jheng-Long Wu, Pei-Chann Chang,and Hsuan-Shou Chu.
2013.
Using a contextual en-tropy model to expand emotion words and their in-tensity for the sentiment classification of stock mar-ket news.
Knowledge Based Syst, 41:89?97, March.30
