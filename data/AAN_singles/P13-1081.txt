Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 822?831,Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational LinguisticsEnlisting the Ghost: Modeling Empty Categories for Machine TranslationBing XiangIBM T. J. Watson Research Center1101 Kitchawan RdYorktown Heights, NY 10598bxiang@us.ibm.comXiaoqiang Luo *Google Inc.111 8th AveNew York, NY 10011xql@google.comBowen ZhouIBM T. J. Watson Research Center1101 Kitchawan RdYorktown Heights, NY 10598zhou@us.ibm.comAbstractEmpty categories (EC) are artificial ele-ments in Penn Treebanks motivated by thegovernment-binding (GB) theory to ex-plain certain language phenomena such aspro-drop.
ECs are ubiquitous in languageslike Chinese, but they are tacitly ignoredin most machine translation (MT) workbecause of their elusive nature.
In thispaper we present a comprehensive treat-ment of ECs by first recovering them witha structured MaxEnt model with a richset of syntactic and lexical features, andthen incorporating the predicted ECs intoa Chinese-to-English machine translationtask through multiple approaches, includ-ing the extraction of EC-specific sparsefeatures.
We show that the recoveredempty categories not only improve theword alignment quality, but also lead tosignificant improvements in a large-scalestate-of-the-art syntactic MT system.1 IntroductionOne of the key challenges in statistical machinetranslation (SMT) is to effectively model inher-ent differences between the source and the targetlanguage.
Take the Chinese-English SMT as anexample: it is non-trivial to produce correct pro-nouns on the target side when the source-side pro-noun is missing.
In addition, the pro-drop prob-lem can also degrade the word alignment qual-ity in the training data.
A sentence pair observedin the real data is shown in Figure 1 along withthe word alignment obtained from an automaticword aligner, where the English subject pronoun* This work was done when the author was with IBM.?that?
is missing on the Chinese side.
Conse-quently, ?that?
is incorrectly aligned to the secondto the last Chinese word ?De?, due to their highco-occurrence frequency in the training data.
Ifthe dropped pronoun were recovered, ?that?
wouldhave been aligned with the dropped-pro (cf.
Fig-ure 3), which is a much more sensible alignment.Figure 1: Example of incorrect word alignmentdue to missing pronouns on the Chinese side.In order to account for certain language phe-nomena such as pro-drop and wh-movement, a setof special tokens, called empty categories (EC),are used in Penn Treebanks (Marcus et al, 1993;Bies and Maamouri, 2003; Xue et al, 2005).
Sinceempty categories do not exist in the surface formof a language, they are often deemed elusive andrecovering ECs is even figuratively called ?chas-ing the ghost?
(Yang and Xue, 2010).In this work we demonstrate that, with the avail-ability of large-scale EC annotations, it is feasi-ble to predict and recover ECs with high accu-racy.
More importantly, with various approachesof modeling the recovered ECs in SMT, we areable to achieve significant improvements1.The contributions of this paper include the fol-lowing:?
Propose a novel structured approach to ECprediction, including the exact word-level lo-1Hence ?Enlisting the ghost?
in the title of this paper.822cation and EC labels.
Our results are sig-nificantly higher in accuracy than that of thestate-of-the-art;?
Measure the effect of ECs on automatic wordalignment for machine translation after inte-grating recovered ECs into the MT data;?
Design EC-specific features for phrases andsyntactic tree-to-string rules in translationgrammar;?
Show significant improvement on top of thestate-of-the-art large-scale hierarchical andsyntactic machine translation systems.The rest of the paper is organized as follows.
InSection 2, we present a structured approach to ECprediction.
In Section 3, we describe the integra-tion of Chinese ECs in MT.
The experimental re-sults for both EC prediction and SMT are reportedin Section 4.
A survey on the related work is con-ducted in Section 5, and Section 6 summarizes thework and introduces some future work.2 Chinese Empty Category PredictionThe empty categories in the Chinese Treebank(CTB) include trace markers for A?- and A-movement, dropped pronoun, big PRO etc.
Acomplete list of categories used in CTB is shownin Table 1 along with their intended usages.
Read-ers are referred to the documentation (Xue et al,2005) of CTB for detailed discussions about thecharacterization of empty categories.EC Meaning*T* trace of A?-movement* trace of A-movement*PRO* big PRO in control structures*pro* pro-drop*OP* operator in relative clauses*RNR* for right node raisingTable 1: List of empty categories in the CTB.In this section, we tackle the problem of recov-ering Chinese ECs.
The problem has been studiedbefore in the literature.
For instance, Yang andXue (2010) attempted to predict the existence ofan EC before a word; Luo and Zhao (2011) pre-dicted ECs on parse trees, but the position infor-mation of some ECs is partially lost in their repre-sentation.
Furthermore, Luo and Zhao (2011) con-ducted experiments on gold parse trees only.
Inour opinion, recovering ECs from machine parsetrees is more meaningful since that is what onewould encounter when developing a downstreamapplication such as machine translation.
In thispaper, we aim to have a more comprehensive treat-ment of the problem: all EC types along withtheir locations are predicted, and we will report theresults on both human parse trees and machine-generated parse trees.2.1 Representation of Empty CategoriesOur effort of recovering ECs is a two-step process:first, at training time, ECs in the Chinese Treebankare moved and preserved in the portion of the treestructures pertaining to surface words only.
Origi-nal ECs and their subtrees are then deleted withoutloss of information; second, a model is trained ontransformed trees to predict and recover ECs.Empty categories heavily depend on syntac-tic tree structure.
For this reason, we choose toproject them onto a parse tree node.
To facili-tate presentation, we first distinguish a solid vs.an empty non-terminal node.
A non-terminal nodeis solid if and only if it contains at least one childnode that spans one or more surface words (as op-posed to an EC); accordingly, an empty node is anon-terminal node that spans only ECs.
In the lefthalf of Figure 2, the NP node that is the immediatechild of IP has only one child node spanning anEC ?
(-NONE- *pro*), and is thus an emptynode; while all other non-terminal nodes have atleast one surface word as their child and are thusall solid nodes.We decide to attach an EC to its lowest solidancestor node.
That is, the EC is moved up to thefirst solid node in the syntactic tree.
After ECsare attached, all empty nodes and ECs are deletedfrom the tree.
In order to uniquely recover ECs,we also need to encode the position information.To this end, the relative child index of an EC isaffixed to the EC tag.
Take the NP node spanningthe *pro* in Figure 2 as an example, the *pro*is moved to the lowest solid ancestor, IP node,and its position is encoded by @1 since the deletedNP is the second child of the IP node (we use 0-based indices).
With this transformation, we areable to recover not only the position of an EC, butits type as well.
A special tag NULL is attachedto non-terminal nodes without EC.
Since an EC isintroduced to express the structure of a sentence,it is a good practice to associate it with the syn-823Figure 2: Example of tree transformation on training data to encode an empty category and its positioninformation.tactic tree, as opposed to simply attaching it to aneighboring word, as was done in (Yang and Xue,2010).
We believe this is one of the reasons whyour model has better accuracy than that of (Yangand Xue, 2010) (cf.
Table 7).In summary, a projected tag consists of an ECtype (such as *pro*) and the EC?s position in-formation.
The problem of predicting ECs is thencast into predicting an EC tag at each non-terminalnode.
Notice that the input to such a predictor isa syntactic tree without ECs, e.g., the parse treeon the right hand of Figure 2 without the EC tag*pro*@1 is such an example.2.2 A Structured Empty Category ModelWe propose a structured MaxEnt model for pre-dicting ECs.
Specially, given a syntactic tree, T ,whose ECs have been projected onto solid nodeswith the procedure described in Section 2.1, wetraverse it in post-order (i.e., child nodes are vis-ited recursively first before the current node is vis-ited).
Let T = t1t2 ?
?
?
tn be the sequence ofnodes produced by the post-order traversal, andei(i = 1, 2, ?
?
?
, n) be the EC tag associated withti.
The probabilistic model is then:P (en1 |T ) =n?i=1P (ei|T, ei?11 )=n?i=1exp(?k ?kfk(ei?11 , T, ei))Z(ei?11 , T )(1)Eq.
(1) is the familiar log linear (or MaxEnt)model, where fk(ei?11 , T, ei) is the feature func-tion andZ(ei?11 , T ) =?e?E exp(?k ?kfk(ei?11 , T, e))is the normalization factor.
E is the set of ECs to bepredicted.
In the CTB 7.0 processed by the proce-dure in Section 2.1, the set consists of 32 EC tagsplus a special NULL symbol, obtained by modulat-ing the list of ECs in Table 1 with their positions(e.g., *pro*@1 in Figure 2).Once the model is chosen, the next step is to de-cide a set of features {fk(ei?11 , T, ei)} to be usedin the model.
One advantage of having the rep-resentation in Section 2.1 is that it is very easy tocompute features from tree structures.
Indeed, allfeatures used in our system are computed from thesyntactic trees, including lexical features.There are 3 categories of features used in themodel: (1) tree label features; (2) lexical features;(3) EC features, and we list them in Table 2.
Inthe feature description column, all node positions(e.g., ?left?, ?right?)
are relative to the currentnode being predicted.Feature 1 to 10 are computed directly fromparse trees, and are straightforward.
We includeup to 2 siblings when computing feature 9 and 10.Feature 11 to 17 are lexical features.
Note that weuse words at the edge of the current node: fea-ture 11 and 12 are words at the internal boundaryof the current node, while feature 13 and 14 arethe immediately neighboring word external to thecurrent node.
Feature 15 and 17 are from headword information of the current node and the par-ent node.
Feature 18 and 19 are computed frompredicted ECs in the past ?
that?s why the modelin Eq.
(1) conditions on ei?11 .Besides the features presented in Table 2, wealso use conjunction features between the currentnode label with the parent node label; the cur-rent node label with features computed from childnodes; the current node label with features fromleft and sibling nodes; the current node label withlexical features.824No.
Tree Label Features1 current node label2 parent node label3 grand-parent node label4 left-most child label or POS tag5 right-most child label or POS tag6 label or POS tag of the head child7 the number of child nodes8 one level CFG rule9 left-sibling label or POS tag10 right-sibling label or POS tagLexical Features11 left-most word under the current node12 right-most word under the current node13 word immediately left to the span of thecurrent node14 word immediately right to the span of thecurrent node15 head word of the current node16 head word of the parent node17 is the current node head child of its parent?EC Features18 predicted EC of the left sibling19 the set of predicted ECs of child nodesTable 2: List of features.3 Integrating Empty Categories inMachine TranslationIn this section, we explore multiple approaches ofutilizing recovered ECs in machine translation.3.1 Explicit Recovery of ECs in MTWe conducted some initial error analysis on ourMT system output and found that most of the er-rors that are related to ECs are due to the missing*pro* and *PRO*.
This is also consistent withthe findings in (Chung and Gildea, 2010).
One ofthe other frequent ECs, *OP*, appears in the Chi-nese relative clauses, which usually have a Chi-nese word ?De?
aligned to the target side ?that?or ?which?.
And the trace, *T*, exists in bothChinese and English sides.
For MT we want to fo-cus on the places where there exist mismatches be-tween the source and target languages.
A straight-forward way of utilizing the recovered *pro* and*PRO* is to pre-process the MT training and testdata by inserting ECs into the original source text(i.e.
Chinese in this case).
As mentioned in theprevious section, the output of our EC predictoris a new parse tree with the labels and positionsencoded in the tags.
Based on the positional in-formation in the tags, we can move the predictedECs down to the surface level and insert them be-tween original source words.
The same predictionand ?pull-down?
procedure can be conducted con-sistently cross the MT training and test data.3.2 Grammar Extraction on AugmentedDataWith the pre-processed MT training corpus, an un-supervised word aligner, such as GIZA++, can beused to generate automatic word alignment, as thefirst step of a system training pipeline.
The ef-fect of inserting ECs is two-fold: first, it can im-pact the automatic word alignment since now it al-lows the target-side words, especially the functionwords, to align to the inserted ECs and fix someerrors in the original word alignment; second, newphrases and rules can be extracted from the pre-processed training data.
For example, for a hier-archical MT system, some phrase pairs and Hiero(Chiang, 2005) rules can be extracted with recov-ered *pro* and *PRO* at the Chinese side.In this work we also take advantages of the aug-mented Chinese parse trees (with ECs projectedto the surface) and extract tree-to-string grammar(Liu et al, 2006) for a tree-to-string MT system.Due to the recovered ECs in the source parsetrees, the tree-to-string grammar extracted fromsuch trees can be more discriminative, with an in-creased capability of distinguishing different con-text.
An example of an augmented Chinese parsetree aligned to an English string is shown in Figure3, in which the incorrect alignment in Figure 1 isfixed.
A few examples of the extracted Hiero rulesand tree-to-string rules are also listed, which wewould not have been able to extract from the orig-inal incorrect word alignment when the *pro*was missing.3.3 Soft Recovery: EC-Specific SparseFeaturesRecovered ECs are often good indicators of whathypothesis should be chosen during decoding.
Inaddition to the augmented syntax-based grammar,we propose sparse features as a soft constraint toboost the performance.
For each phrase pair, Hi-ero rule or tree-to-string rule in the MT system,a binary feature fk fires if there exists a *pro*on the source side and it aligns to one of its mostfrequently aligned target words found in the train-ing corpus.
We also fire another feature if *pro*825Figure 3: Fixed word alignment and examples ofextracted Hiero rules and tree-to-string rules.aligns to any other target words so the model canchoose to penalize them based on a tuning set.Similar features can fire for *PRO*.
The featureweights can be tuned on a tuning set in a log-linearmodel along with other usual features/costs, in-cluding language model scores, bi-direction trans-lation probabilities, etc.
The motivation for suchsparse features is to reward those phrase pairsand rules that have highly confident lexical pairsspecifically related to ECs, and penalize those whodon?t have such lexical pairs.Table 3 listed some of the most frequent Englishwords aligned to *pro* or *PRO* in a Chinese-English parallel corpus with 2M sentence pairs.Their co-occurrence counts and the lexical trans-lation probabilities are also shown in the table.
Intotal we use 15 sparse features for frequent lexicalpairs, including 13 for *pro* and 2 for *PRO*,and two more features for any other target wordsthat align to *pro* or *PRO*.Source Target Counts P (t|s)*pro* the 93100 0.11*pro* to 86965 0.10*pro* it 45423 0.05*pro* in 36129 0.04*pro* we 24509 0.03*pro* which 17259 0.02*PRO* to 195464 0.32*PRO* for 31200 0.05Table 3: Example of frequent word pairs used forsparse features.4 Experimental Results4.1 Empty Category PredictionWe use Chinese Treebank (CTB) v7.0 to train andtest the EC prediction model.
We partition thedata into training, development and test sets.
Thetraining set includes 32925 sentences from CTBfiles 0001-0325, 0400-0454, 0500-0542, 0600-0840, 0590-0596, 1001-1120, 2000-3000, cctv,cnn, msnbc, and phoenix 00-06.
The developmentset has 3033 sentences, from files 0549-0554,0900-0931, 1136-1151, 3076-3145, and phoenix10-11.
The test set contains 3297 sentences, fromfiles 0543-0548, 0841-0885, 1121-1135, 3001-3075, and phoenix 07-09.To measure the accuracy of EC prediction, weproject the predicted tags from the upper levelnodes in the parse trees down to the surface levelbased on the position information encoded in thetags.
The position index for each inserted EC,counted at the surface level, is attached for scor-ing purpose.
The same operation is applied onboth the reference and the system output trees.Such projection is necessary, especially when thetwo trees differ in structure (e.g.
gold trees vs.machine-generated trees).
We compute the pre-cision, recall and F1 scores for each EC on thetest set, and collect their counts in the referenceand system output.
The results are shown in Ta-ble 4, where the LDC gold parse trees are used toextract syntactic features for the model.
The firstrow in the table shows the accuracy for the placeswhere no EC should be inserted.
The predictorachieves 99.5% F1 score for this category, withlimited number of missing or false positives.
TheF1 scores for majority of the ECs are above 70%,except for ?
*?, which is relatively rare in the data.For the two categories that are interesting to MT,*pro* and *PRO*, the predictor achieves 74.3%and 81.5% in F1 scores, respectively.The results reported above are based on theLDC gold parse trees.
To apply the EC predic-tion to NLP applications, such as MT, it is impos-sible to always rely on the gold trees due to itslimited availability.
We parse our test set with amaximum entropy based statistical parser (Ratna-parkhi, 1997) first.
The parser accuracy is around84% on the test set.
Then we extract features basedon the system-generated parse trees, and decodewith the previously trained model.
The results areshown in Table 5.
Compared to those in Table 4,the F1 scores dropped by different degrees for dif-826Tag Ref Sys P R F1NULL 75159 75508 99.3 99.7 99.5*pro* 1692 1442 80.8 68.9 74.3*PRO* 1410 1282 85.6 77.8 81.5*T* 1851 1845 82.8 82.5 82.7*OP* 1721 1853 90.9 97.9 94.2*RNR* 51 39 87.2 66.7 75.6* 156 96 63.5 39.1 48.4Table 4: Prediction accuracy with gold parse trees,where NULL represents the cases where no ECsshould be produced.ferent types.
Such performance drop is expectedsince the system relies heavily on syntactic struc-ture, and parsing errors create an inherent mis-matching condition between the training and test-ing time.
The smallest drop among all types is onNULL, at about 1.6%.
The largest drop occurs for*OP*, at 27.1%, largely due to the parsing errorson the CP nodes.
The F1 scores for *pro* and*PRO* when using system-generated parse treesare between 50% to 60%.Tag Precision Recall F1NULL 97.6 98.2 97.9*pro* 51.1 50.1 50.6*PRO* 66.4 50.5 57.3*T* 68.2 59.9 63.8*OP* 66.8 67.3 67.1*RNR* 70.0 54.9 61.5* 60.9 35.9 45.2Table 5: Prediction accuracy with system-generated parse trees.To show the effect of ECs other than *pro*and *PRO*, we remove all ECs in the training dataexcept *pro* and *PRO*.
So the model onlypredicts NULL, *pro* or *PRO*.
The results onthe test set are listed in Table 6.
There is 0.8% and0.5% increase on NULL and *pro*, respectively.The F1 score for *PRO* drops by 0.2% slightly.As mentioned earlier, for MT we focus on re-covering *pro* and *PRO* only.
The modelgenerating the results in Table 6 is the one we ap-plied in our MT experiments reported later.In order to compare to the state-of-the-art mod-els to see where our model stands, we switch ourtraining, development and test data to those usedin the work of (Yang and Xue, 2010) and (Cai etTag Precision Recall F1NULL 98.5 98.9 98.7*pro* 51.0 51.1 51.1*PRO* 66.0 50.4 57.1Table 6: Prediction accuracy with system-generated parse trees, modeling *pro* and*PRO* only.al., 2011), for the purpose of a direct comparison.The training set includes CTB files 0081 through0900.
The development set includes files 0041 to0080, and the test set contains files 0001-0040 and0901-0931.
We merge all empty categories intoa single type in the training data before trainingour EC prediction model.
To compare the perfor-mance on system-generated parse trees, we alsotrain a Berkeley parser on the same training dataand parse the test set.
The prediction accuracyfor such single type on the test set with gold orsystem-generated parse trees is shown in Table 7,compared to the numbers reported in (Yang andXue, 2010) and (Cai et al, 2011).
The model weproposed achieves 6% higher F1 score than that in(Yang and Xue, 2010) and 2.6% higher than that in(Cai et al, 2011), which is significant.
This showsthe effectiveness of our structured approach.Model T P R F1(Yang and Xue, 2010) G 95.9 83.0 89.0Structured (this work) G 96.5 93.6 95.0(Yang and Xue, 2010) S 80.3 52.1 63.2(Cai et al, 2011) S 74.0 61.3 67.0Structured (this work) S 74.9 65.1 69.6Table 7: Comparison with the previous results, us-ing the same training and test data.
T: parse trees.G: gold parse trees.
S: system-generated parsetrees.
P: precision.
R: recall.4.2 MT ResultsIn the Chinese-to-English MT experiments, wetest two state-of-the-art MT systems.
One is an re-implementation of Hiero (Chiang, 2005), and theother is a hybrid syntax-based tree-to-string sys-tem (Zhao and Al-onaizan, 2008), where normalphrase pairs and Hiero rules are used as a backofffor tree-to-string rules.The MT training data includes 2 million sen-tence pairs from the parallel corpora released by827LDC over the years, with the data from UnitedNations and Hong Kong excluded 2.
The Chi-nese text is segmented with a segmenter trainedon the CTB data using conditional random field(CRF), followed by the longest-substring matchsegmentation in a second pass.
Our languagemodel (LM) training data consists of about 10 bil-lion English words, which includes Gigaword andother newswire and web data released by LDC,as well as the English side of the parallel train-ing corpus.
We train a 6-gram LM with modi-fied Kneser-Ney smoothing (Chen and Goodman,1998).
Our tuning set for MT contains 1275 sen-tences from LDC2010E30.
We test our systemon the NIST MT08 Newswire (691 sentences)and Weblog (666 sentences) sets.
Both tuningand test sets have 4 sets of references for eachsentence.
The MT systems are optimized withpairwise ranking optimization (Hopkins and May,2011) to maximize BLEU (Papineni et al, 2002).We first predict *pro* and *PRO* with ourannotation model for all Chinese sentences in theparallel training data, with *pro* and *PRO* in-serted between the original Chinese words.
Thenwe run GIZA++ (Och and Ney, 2000) to generatethe word alignment for each direction and applygrow-diagonal-final (Koehn et al, 2003), same asin the baseline.
We want to measure the impact onthe word alignment, which is an important step forthe system building.
We append a 300-sentenceset, which we have human hand alignment avail-able as reference, to the 2M training sentence pairsbefore running GIZA++.
The alignment accuracymeasured on this alignment test set, with or with-out *pro* and *PRO* inserted before runningGIZA++, is shown in Table 8.
To make a faircomparison with the baseline alignment, any tar-get words aligned to ECs are deemed as unalignedduring scoring.
We observe 1.2% improvement onfunction word related links, and almost the sameaccuracy on content words.
This is understand-able since *pro* and *PRO* are mostly alignedto the function words at the target side.
The pre-cision and recall for function words are shown inTable 9.
We can see higher accuracy in both pre-cision and recall when ECs (*pro* and *PRO*)are recovered in the Chinese side.
Especially, theprecision is improved by 2% absolute.2The training corpora include LDC2003E07,LDC2003E08, LDC2005T10, LDC2006E26, LDC2006G05,LDC2007E103, LDC2008G05, LDC2009G01, andLDC2009G02.System Function Content AllBaseline 51.7 69.7 65.4+EC 52.9 69.6 65.7Table 8: Word alignment F1 scores with or without*pro* and *PRO*.System Precision Recall F1Baseline 54.1 49.5 51.7+EC 56.0 50.1 52.9Table 9: Word alignment accuracy for functionwords only.Next we extract phrase pairs, Hiero rules andtree-to-string rules from the original word align-ment and the improved word alignment, and tuneall the feature weights on the tuning set.
Theweights include those for usual costs and also thesparse features proposed in this work specificallyfor ECs.
We test all the systems on the MT08Newswire and Weblog sets.The BLEU scores from different systems areshown in Table 10 and Table 11, respectively.
Wemeasure the incremental effect of prediction (in-serting *pro* and *PRO*) and sparse features.Pre-processing of the data with ECs inserted im-proves the BLEU scores by about 0.6 for newswireand 0.2 to 0.3 for the weblog data, compared toeach baseline separately.
On top of that, addingsparse features helps by another 0.3 on newswireand 0.2 to 0.4 on weblog.
Overall, the Hieroand tree-to-string systems are improved by about 1point for newswire and 0.4 to 0.7 for weblog.
Thesmaller gain on the weblog data could be due tothe more difficult data to parse, which affects theaccuracy of EC prediction.
All the results in Table10 and 11 marked with ?*?
are statistically signif-icant with p < 0.05 using the sign test describedin (Collins et al, 2005), compared to the baselineresults in each table.
Two MT examples are givenin Table 12, which show the effectiveness of therecovered ECs in MT.System MT08-nw MT08-wbHiero 33.99 25.40+prediction 34.62* 25.63+prediction+sparse 34.95* 25.80*Table 10: BLEU scores in the Hiero system.828System MT08-nw MT08-wbT2S+Hiero 34.53 25.80+prediction 35.17* 26.08+prediction+sparse 35.51* 26.53*Table 11: BLEU scores in the tree-to-string systemwith Hiero rules as backoff.5 Related WorkEmpty categories have been studied in recentyears for several languages, mostly in the con-text of reference resolution and syntactic process-ing for English, such as in (Johnson, 2002; Di-enes and Dubey, 2003; Gabbard et al, 2006).More recently, EC recovery for Chinese startedemerging in literature.
In (Guo et al, 2007),non-local dependencies are migrated from En-glish to Chinese for generating proper predicate-argument-modifier structures from surface contextfree phrase structure trees.
In (Zhao and Ng,2007), a decision tree learning algorithm is pre-sented to identify and resolve Chinese anaphoriczero pronouns.
and achieves a performance com-parable to a heuristic rule-based approach.
Similarto the work in (Dienes and Dubey, 2003), emptydetection is formulated as a tagging problem in(Yang and Xue, 2010), where each word in thesentence receives a tag indicating whether there isan EC before it.
A maximum entropy model isutilized to predict the tags, but different types ofECs are not distinguished.
In (Cai et al, 2011),a language-independent method was proposed tointegrate the recovery of empty elements into syn-tactic parsing.
As shown in the previous section,our model outperforms the model in (Yang andXue, 2010) and (Cai et al, 2011) significantly us-ing the same training and test data.
(Luo and Zhao,2011) also tries to predict the existence of an ECin Chinese sentences, but the ECs in the middle ofa tree constituent are lumped into a single positionand are not uniquely recoverable.There exists only a handful of previous work onapplying ECs explicitly to machine translation sofar.
One of them is the work reported in (Chungand Gildea, 2010), where three approaches arecompared, based on either pattern matching, CRF,or parsing.
However, there is no comparison be-tween using gold trees and automatic trees.
Therealso exist a few major differences on the MTpart between our work and theirs.
First, in ad-dition to the pre-processing of training data andinserting recovered empty categories, we imple-ment sparse features to further boost the perfor-mance, and tune the feature weights directly to-wards maximizing the machine translation met-ric.
Second, there is no discussion on the qualityof word alignment in (Chung and Gildea, 2010),while we show the alignment improvement on ahand-aligned set.
Last, they use a phase-basedsystem trained on only 60K sentences, while weconduct experiments on more advanced Hiero andtree-to-string systems, trained on 2M sentences ina much larger corpus.
We directly take advantageof the augmented parse trees in the tree-to-stringgrammar, which could have larger impact on theMT system performance.6 Conclusions and Future WorkIn this paper, we presented a novel structured ap-proach to EC prediction, which utilizes a max-imum entropy model with various syntactic fea-tures and shows significantly higher accuracy thanthe state-of-the-art approaches.
We also appliedthe predicted ECs to a large-scale Chinese-to-English machine translation task and achieved sig-nificant improvement over two strong MT base-829lines, i.e.
a hierarchical phase-based system anda tree-to-string syntax-based system.
More workremain to be done next to further take advantagesof ECs.
For example, the recovered ECs can beencoded in a forest as the input to the MT decoderand allow the decoder to pick the best MT outputbased on various features in addition to the sparsefeatures we proposed in this work.
Many promis-ing approaches can be explored in the future.AcknowledgmentsWe would like to acknowledge the supportof DARPA under Grant HR0011-12-C-0015 forfunding part of this work.
The views, opin-ions, and/or findings contained in this arti-cle/presentation are those of the author/presenterand should not be interpreted as representing theofficial views or policies, either expressed or im-plied, of the Defense Advanced Research ProjectsAgency or the Department of Defense.ReferencesAnn Bies and Mohamed Maamouri.
2003.Penn Arabic treebank guidelines.
Inhttp://www.ircs.upenn.edu/arabic/Jan03release/guidelines-TB-1-28-03.pdf.Shu Cai, David Chiang, and Yoav Goldberg.
2011.Language-independent parsing with empty ele-ments.
In Proceedings of the 49th Annual Meet-ing of the Association for Computational Linguis-tics:short papers, pages 212?216.Stanley F. Chen and Joshua Goodman.
1998.
An em-pirical study of smoothing techniques for languagemodeling.
In Technical Report TR-10-98, ComputerScience Group, Harvard University.David Chiang.
2005.
A hierarchical phrase-basedmodel for statistical machine translation.
In Pro-ceedings of the 43rd Annual Meeting of the Associa-tion for Computational Linguistics, pages 263?270,Ann Arbor, Michigan, June.Tagyoung Chung and Daniel Gildea.
2010.
Effectsof empty categories on machine translation.
In Pro-ceedings of the 2010 Conference on Empirical Meth-ods in Natural Language Processing, pages 636?645.Michael Collins, Philipp Koehn, and Ivona Kuc?erova?.2005.
Clause restructuring for statistical machinetranslation.
In Proceedings of the 43rd AnnualMeeting of the Association for Computational Lin-guistics, pages 531?540.Peter Dienes and Amit Dubey.
2003.
Deep syntacticprocessing by combining shallow methods.
In Pro-ceedings of the 41st Annual Meeting of the Associa-tion for Computational Linguistics.Ryan Gabbard, Seth Kulick, and Mitchell Marcus.2006.
Fully parsing the penn treebank.
In Pro-ceedings of the Human Language Technology Con-ference of the North American Chapter of the ACL.Yuqing Guo, Haifeng Wang, and Josef van Genabith.2007.
Recovering non-local dependencies for Chi-nese.
In Proceedings of the 2007 Joint Confer-ence on Empirical Methods in Natural LanguageProcessing and Computational Natural LanguageLearning (EMNLP-CoNLL).Mark Hopkins and Jonathan May.
2011.
Tuning asranking.
In Proceedings of the 2011 Conference onEmpirical Methods in Natural Language Process-ing, pages 1352?1362.Mark Johnson.
2002.
A simple pattern-matching al-gorithm for recovering empty nodes and their an-tecedents.
In Proceedings of the 40th Annual Meet-ing of the Association for Computational Linguis-tics.Philipp Koehn, Franz Och, and Daniel Marcu.
2003.Statistical phrase-based translation.
In Proceedingsof HLT-NAACL, pages 48?54.Yang Liu, Qun Liu, and Shouxun Lin.
2006.
Tree-to-string alignment template for statistical machinetranslation.
In Proceedings of the 21st InternationalConference on Computational Linguistics and 44thAnnual Meeting of the Association for Computa-tional Linguistics, pages 609?616.Xiaoqiang Luo and Bing Zhao.
2011.
A statisticaltree annotator and its applications.
In Proceedingsof the 49th Annual Meeting of the Association forComputational Linguistics: Human Language Tech-nologies, pages 1230?1238.Mitchell P. Marcus, Beatrice Santorini, and Mary AnnMarcinkiewicz.
1993.
Building a large annotatedcorpus of English: The Penn Treebank.
In Compu-tational Linguistics, volume 19(2), pages 313?330.Franz Josef Och and Hermann Ney.
2000.
Improvedstatistical alignment models.
In Proceedings of the38th Annual Meeting of the Association for Com-putational Linguistics, pages 440?447, Hong Kong,China, October.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
BLEU: a method for automaticevaluation of machine translation.
In Proceedings ofthe 40th Annual Meeting of the Association for Com-putational Linguistics, pages 311?318, Philadelphia,PA.Adwait Ratnaparkhi.
1997.
A linear observed time sta-tistical parser based on maximum entropy models.In Proceedings of Second Conference on Empirical830Methods in Natural Language Processing, pages 1?10.Nianwen Xue, Fei Xia, Fu dong Chiou, and MarthaPalmer.
2005.
The Penn Chinese Treebank: Phrasestructure annotation of a large corpus.
In NaturalLanguage Engineering, volume 11(2), pages 207?238.Yaqin Yang and Nianwen Xue.
2010.
Chasing theghost: Recovering empty categories in the Chi-nese Treebank.
In Proceedings of the 23rd Inter-national Conference on Computational Linguistics,pages 1382?1390, Beijing, China, August.Bing Zhao and Yaser Al-onaizan.
2008.
Generaliz-ing local and non-local word-reordering patterns forsyntax-based machine translation.
In Proceedings ofthe 2008 Conference on Empirical Methods in Nat-ural Language Processing, pages 572?581.Shanheng Zhao and Hwee Tou Ng.
2007.
Identifica-tion and resolution of Chinese zero pronouns: A ma-chine learning approach.
In Proceedings of the 2007Joint Conference on Empirical Methods in NaturalLanguage Processing and Computational NaturalLanguage Learning (EMNLP-CoNLL).831
