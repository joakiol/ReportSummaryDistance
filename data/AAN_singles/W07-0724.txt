Proceedings of the Second Workshop on Statistical Machine Translation, pages 185?188,Prague, June 2007. c?2007 Association for Computational LinguisticsNRC?s PORTAGE system for WMT 2007Nicola Ueffing, Michel Simard, Samuel LarkinInteractive Language Technologies GroupNational Research Council CanadaGatineau, Que?bec, Canadafirstname.lastname@nrc.gc.caHoward JohnsonInteractive Information GroupNational Research Council CanadaOttawa, Ontario, CanadaHoward.Johnson@nrc.gc.caAbstractWe present the PORTAGE statisticalmachine translation system which par-ticipated in the shared task of the ACL2007 Second Workshop on StatisticalMachine Translation.
The focus of thisdescription is on improvements whichwere incorporated into the system overthe last year.
These include adapted lan-guage models, phrase table pruning, anIBM1-based decoder feature, and rescor-ing with posterior probabilities.1 IntroductionThe statistical machine translation (SMT) sys-tem PORTAGE was developed at the NationalResearch Council Canada and has recently beenmade available to Canadian universities andresearch institutions.
It is a state-of-the-artphrase-based SMT system.
We will shortly de-scribe its basics in this paper and then high-light the new methods which we incorporatedsince our participation in the WMT 2006 sharedtask.
These include new scoring methods forphrase pairs, pruning of phrase tables basedon significance, a higher-order language model,adapted language models, and several new de-coder and rescoring models.
PORTAGE wasalso used in a joint system developed in coop-eration with Systran.
The interested reader isreferred to (Simard et al, 2007).Throughout this paper, let sJ1 := s1 .
.
.
sJ de-note a source sentence of length J , tI1 := t1 .
.
.
tIa target sentence of length I, and s?
and t?
phrasesin source and target language, respectively.2 BaselineAs baseline for our experiments, we used a ver-sion of PORTAGE corresponding to its state atthe time of the WMT 2006 shared task.
We pro-vide a basic description of this system here; formore details see (Johnson et al, 2006).PORTAGE implements a two-stage transla-tion process: First, the decoder generates N -best lists, using a basic set of models which arethen rescored with additional models in a sec-ond step.
In the baseline system, the decoderuses the following models (or feature functions):?
one or several phrase table(s), which modelthe translation direction p(s?
| t?).
They aregenerated from the training corpus via the?diag-and?
method (Koehn et al, 2003)and smoothed using Kneser-Ney smooth-ing (Foster et al, 2006),?
one or several n-gram language model(s)trained with the SRILM toolkit (Stolcke,2002); in the baseline experiments reportedhere, we used a trigram model,?
a distortion model which assigns a penaltybased on the number of source words whichare skipped when generating a new targetphrase,?
a word penalty.These different models are combined log-linearly.
Their weights are optimizedw.r.t.
BLEU score using the algorithm de-scribed in (Och, 2003).
This is done on theprovided development corpus.
The searchalgorithm implemented in the decoder is adynamic-programming beam-search algorithm.185After the decoding step, rescoring with addi-tional models is performed.
The baseline systemgenerates a 1,000-best list of alternative trans-lations for each source sentence.
These listsare rescored with the different models describedabove, a character penalty, and three differentfeatures based on IBM Models 1 and 2 (Brownet al, 1993) calculated in both translation di-rections.
The weights of these additional modelsand of the decoder models are again optimizedto maximize BLEU score.Note that we did not use the decision-tree-based distortion models described in (Johnsonet al, 2006) here because they did not improvetranslation quality.In the following subsections, we will describethe new models added to the system for ourWMT 2007 submissions.3 Improvements in PORTAGE3.1 Phrase translation modelsWhereas the phrase tables used in the baselinesystem contain only one score for each phrasepair, namely conditional probabilities calculatedusing Kneser-Ney smoothing, our current sys-tem combines seven different phrase scores.First, we used several types of phrase tablesmoothing in the WMT 2007 system becausethis proved helpful on other translation tasks:relative frequency estimates, Kneser-Ney- andZens-Ney-smoothed probabilities (Foster et al,2006).
Furthermore, we added normalized jointprobability estimates to the phrase translationmodel.
The other three scores will be explainedat the end of this subsection.We pruned the generated phrase tables fol-lowing the method introduced in (Johnson etal., 2007).
This approach considers all phrasepairs (s?, t?)
in the phrase table.
The count C(s?, t?
)of all sentence pairs containing (s?, t?)
is deter-mined, as well as the count of all source/targetsentences containing s?/t?.
Using these counts,Fisher?s exact test is carried out to calculatethe significance of the phrase pair.
The phrasetables are then pruned based on the p-value.Phrase pairs with low significance, i.e.
which areonly weakly supported by the training data, arepruned.
This reduces the size of the phrase ta-bles to 8-16% on the different language pairs.See (Johnson et al, 2007) for details.Three additional phrase scores were derivedfrom information on which this pruning is based:?
the significance level (or p-value),?
the number C(s?, t?)
of sentence pairs con-taining the phrase pair, normalized by thenumber of source sentences containing s?,?
C(s?, t?
), normalized by the number of targetsentences containing t?.For our submissions, we used the last threephrase scores only when translating the Eu-roParl data.
Initial experiments showed thatthey do not improve translation quality on theNews Commentary data.
Apart from this, thesystems for both domains are identical.3.2 Adapted language modelsConcerning the language models, we made twochanges to our system since WMT 2006.
First,we replaced the trigram language model by a 4-gram model trained on the WMT 2007 data.
Wealso investigated the use of a 5-gram, but thatdid not improve translation quality.
Second,we included adapted language models whichare specific to the development and test cor-pora.
For each development or test corpus, webuilt this language model using information re-trieval1 to find relevant sentences in the train-ing data.
To this end, we merged the train-ing corpora for EuroParl and News Commen-tary.
The source sentences from the develop-ment or test corpus served as individual queriesto find relevant training sentence pairs.
Foreach source sentence, we retrieved 10 sentencepairs from the training data and used their tar-get sides as language model training data.
Onthis small corpus, we trained a trigram lan-guage model, again using the SRILM toolkit.The feature function weights in the decoder andthe rescoring model were optimized using theadapted language model for the developmentcorpus.
When translating the test corpus, wekept these weights, but replaced the adapted1We used the lemur toolkit for querying, seehttp://www.lemurproject.org/186language model by that specific to the test cor-pus.3.3 New decoder and rescoring featuresWe integrated several new decoder and rescoringfeatures into PORTAGE.
During decoding, thesystem now makes use of a feature based on IBMModel 1.
This feature calculates the probabilityof the (partial) translation over the source sen-tence, using an IBM1 translation model in thedirection p(tI1 | sJ1 ).In the rescoring process, we additionally in-cluded several types of posterior probabilities.One is the posterior probability of the sentencelength over the N -best list for this source sen-tence.
The others are determined on the levelof words, phrases, and n-grams, and then com-bined into a value for the whole sentence.
Allposterior probabilities are calculated over theN -best list, using the sentence probabilities whichthe baseline system assigns to the translationhypotheses.
For details on the posterior prob-abilities, see (Ueffing and Ney, 2007; Zens andNey, 2006).
This year, we increased the lengthof the N -best lists from 1,000 to 5,000.3.4 Post-processingFor truecasing the translation output, we usedthe model described in (Agbago et al, 2005).This model uses a combination of statisti-cal components, including an n-gram languagemodel, a case mapping model, and a special-ized language model for unknown words.
Thelanguage model is a 5-gram model trained onthe WMT 2007 data.
The detokenizer which weused is the one provided for WMT 2007.4 Experimental resultsWe submitted results for six of the translationdirections of the shared task: French ?
English,German ?
English, and Spanish ?
English.Table 1 shows the improvements result-ing from incorporating new techniques intoPORTAGE on the Spanish ?
English EuroParltask.
The baseline system is the one describedin section 2.
Trained on the 2007 training cor-pora, this yields a BLEU score of 30.48.
Addingthe new phrase scores introduced in section 3.1yields a slight improvement in translation qual-ity.
This improvement by itself is not signifi-cant, but we observed it consistently across allevaluation metrics and across the different devel-opment and test corpora.
Increasing the orderof the language model and adding an adaptedlanguage model specific to the translation input(see section 3.2) improves the BLEU score by0.6 points.
This is the biggest gain we observefrom introducing a new method.
The incorpora-tion of the IBM1-based decoder feature causesa slight drop in translation quality.
This sur-prised us because we found this feature to bevery helpful on the NIST Chinese ?
Englishtranslation task.
Adding the posterior proba-bilities presented in section 3.3 in rescoring andincreasing the length of the N -best lists yieldeda small, but consistent gain in translation qual-ity.
The overall improvement compared to lastyear?s system is around 1 BLEU point.
The gainachieved from introducing the new methods bythemselves are relatively small, but they add up.Table 2 shows results on all six language pairswe translated for the shared task.
The trans-lation quality achieved on the 2007 test set issimilar to that on the 2006 test set.
The systemclearly performs better on the EuroParl domainthan on News Commentary.Table 2: Translation quality in terms ofBLEU[%] and NIST score on all tasks.
True-cased and detokenized translation output.test2006 test2007task BLEU NIST BLEU NISTEu D?E 25.27 6.82 26.02 6.91E?D 19.36 5.86 18.94 5.71S?E 31.54 7.55 32.09 7.67E?S 30.94 7.39 30.92 7.41F?E 30.90 7.51 31.90 7.68E?F 30.08 7.26 30.06 7.26NC D?E 20.23 6.19 23.17 7.10E?D 13.84 5.38 16.30 5.95S?E 31.07 7.68 31.08 8.11E?S 30.79 7.73 32.56 8.25F?E 24.97 6.78 26.84 7.47E?F 24.91 6.79 26.60 7.24187Table 1: Effect of integrating new models and methods into the PORTAGE system.
Translationquality in terms of BLEU and NIST score, WER and PER on the EuroParl Spanish?English 2006test set.
True-cased and detokenized translation output.
Best results printed in boldface.system BLEU[%] NIST WER[%] PER[%]baseline 30.48 7.44 58.62 42.74+ new phrase table features 30.66 7.48 58.25 42.46+ 4-gram LM + adapted LM 31.26 7.53 57.93 42.26+ IBM1-based decoder feature 31.18 7.51 58.13 42.53+ refined rescoring 31.54 7.55 57.81 42.245 ConclusionWe presented the PORTAGE system with whichwe translated six language pairs in the WMT2007 shared task.
Starting from the state ofthe system during the WMT 2006 evaluation,we analyzed the contribution of new methodswhich were incorporated over the last year indetail.
Our experiments showed that most ofthese changes result in (small) improvements intranslation quality.
In total, we gain about 1BLEU point compared to last year?s system.6 AcknowledgmentsOur thanks go to the PORTAGE team at NRCfor their contributions and valuable feedback.ReferencesA.
Agbago, R. Kuhn, and G. Foster.
2005.
True-casing for the Portage system.
In Recent Ad-vances in Natural Language Processing, pages 21?24, Borovets, Bulgaria, September.P.
F. Brown, S. A. Della Pietra, V. J. Della Pietra,and R. L. Mercer.
1993.
The mathematics of sta-tistical machine translation: Parameter estima-tion.
Computational Linguistics, 19(2):263?311,June.G.
Foster, R. Kuhn, and J. H. Johnson.
2006.Phrasetable smoothing for statistical machinetranslation.
In Proc.
of the Conf.
on Empir-ical Methods for Natural Language Processing(EMNLP), pages 53?61, Sydney, Australia, July.J.
H. Johnson, F. Sadat, G. Foster, R. Kuhn,M.
Simard, E. Joanis, and S. Larkin.
2006.Portage: with smoothed phrase tables and seg-ment choice models.
In Proc.
HLT/NAACLWorkshop on Statistical Machine Translation(WMT), pages 134?137, New York, NY, June.H.
Johnson, J. Martin, G. Foster, and R. Kuhn.2007.
Improving translation quality by discard-ing most of the phrasetable.
In Proc.
of theConf.
on Empirical Methods for Natural LanguageProcessing and Conf.
on Computational NaturalLanguage Learning (EMNLP-CoNLL), to appear,Prague, Czech Republic, June.P.
Koehn, F. J. Och, and D. Marcu.
2003.
Statisticalphrase-based translation.
In Proc.
of the HumanLanguage Technology Conf.
(HLT-NAACL), pages127?133, Edmonton, Canada, May/June.F.
J. Och.
2003.
Minimum error rate training in sta-tistical machine translation.
In Proc.
of the 41stAnnual Meeting of the Association for Computa-tional Linguistics (ACL), pages 160?167, Sapporo,Japan, July.M.
Simard, J. Senellart, P. Isabelle, R. Kuhn,J.
Stephan, and N. Ueffing.
2007.
Knowledge-based translation with statistical phrase-basedpost-editing.
In Proc.
ACL Second Workshop onStatistical Machine Translation (WMT), to ap-pear, Prague, Czech Republic, June.A.
Stolcke.
2002.
SRILM ?
an extensible languagemodeling toolkit.
In Proc.
Int.
Conf.
on SpokenLanguage Processing (ICSLP), volume 2, pages901?904, Denver, CO.N.
Ueffing and H. Ney.
2007.
Word-level confi-dence estimation for machine translation.
Com-putational Linguistics, 33(1):9?40, March.R.
Zens and H. Ney.
2006.
N-gram posteriorprobabilities for statistical machine translation.In Proc.
HLT/NAACL Workshop on StatisticalMachine Translation (WMT), pages 72?77, NewYork, NY, June.188
