A Quant i tat ive Evaluat ion of Linguist ic Tests forthe Automat ic  Predict ion of Semant ic  MarkednessVas i le ios  Hatz ivass i log lou  and  Kath leen  McKeownDepar tment  of Computer  Sc ience450 Computer  Sc ience Bu i ld ingCo lumbia  Un ivers i tyNew York ,  N.Y .
10027{vh, kathy}~cs, columbia, eduAbst ractWe present a corpus-based study of methodsthat have been proposed in the linguistics liter-ature for selecting the semantically unmarkedterm out of a pair of antonymous adjectives.Solutions to this problem are applicable to themore general task of selecting the positive termfrom the pair.
Using automatically collecteddata, the accuracy and applicability of eachmethod is quantified, and a statistical analysisof the significance of the results is performed.We show that some simple methods are indeedgood indicators for the answer to the problemwhile other proposed methods fail to performbetter than would be attributable to chance.In addition, one of the simplest methods, textfrequency, dominates all others.
We also ap-ply two generic statistical learning methodsfor combining the indications of the individualmethods, and compare their performance tothe simple methods.
The most sophisticatedcomplex learning method offers a small, butstatistically significant, improvement over theoriginal tests.1 In t roduct ionThe concept of markedness originated in the workof Prague School linguists (Jakobson, 1984a) andrefers to relationships between two complementaryor antonymous terms which can be distinguished bythe presence or absence of a feature (+A versus --A).Such an opposition can occur at various linguisticlevels.
For example, a markedness contrast can ariseat the morphology level, when one of the two wordsis derived from the other and therefore contains anexplicit formal marker such as a prefix; e.g., prof-itable-unprofitable.
Markedness contrasts also ap-pear at the semantic level in many pairs of grad-able antonymous adjectives, especially scalar ones(Levinson, 1983), such as tall-short.
The markedand unmarked elements of such pairs function in dif-ferent ways.
The unmarked adjective (e.g., tall) canbe used in how-questions to refer to the property de-scribed by both adjectives in the pair (e.g., height),but without any implication about the modified itemrelative to the norm for the property.
For exam-ple, the question How tall is Jack?
can be answeredequally well by four or seven feet.
In contrast, themarked element of the opposition cannot be usedgenerically; when used in a how-question, it impliesa presupposition of the speaker egarding the rela-tive position of the modified item on the adjectivalscale.
Thus, the corresponding question using themarked term of the opposition (How short is Jack?
)conveys an implication on the part of the speakerthat Jack is indeed short; the distinguishing featureA expresses this presupposition.While markedness has been described in terms ofa distinguishing feature A, its definition does notspecify the type of this feature.
Consequently, sev-eral different ypes of features have been employed,which has led into some confusion about the meaningof the term markedness.
Following Lyons (1977), wedistinguish between formal markedness where theopposition occurs at the morphology level (i.e., oneof the two terms is derived from the other throughinflection or affixation) and semantic markednesswhere the opposition occurs at the semantic levelas in the example above.
When two antonymousterms are also morphologically related, the formallyunmarked term is usually also the semantically un-marked one (for example, clear-unclear).
However,this correlation is not universal; consider the exam-ples unbiased-biased and independent-dependent.In any case, semantic markedness i the more in-teresting of the two and the harder to determine,both for humans and computers.Various tests for determining markedness in gen-eral have been proposed by linguists (see Section 3).However, although potentially automatic versions ofsome of these have been successfully applied to theproblem at the phonology level (Trubetzkoy, 1939;Greenberg, 1966), little work has been done on theempirical validation or the automatic application ofthose tests at higher levels (but see (Ku~era, 1982)for an empirical analysis of a proposed markednesstest at the syntactic level; some more narrowly fo-cused empirical work has also been done on marked-ness in second language acquisition).
In this paper197we analyze the performance ofseveral linguistic testsfor the selection of the semantically unmarked termout of a pair of gradable antonymous adjectives.We describe a system that automatically extractsthe relevant data for these tests from text corporaand corpora-based databases, and use this systemto measure the applicability and accuracy of eachmethod.
We apply statistical tests to determine thesignificance of the results, and then discuss the per-formance of complex predictors that combine the an-swers of the linguistic tests according to two generalstatistical learning methods, decision trees and log-linear regression models.2 Mot ivat ionThe goal of our work is twofold: First, we are inter-ested in providing hard, quantitative evidence on theperformance of markedness tests already proposedin the linguistics literature.
Such tests are basedon intuitive observations and/or particular theoriesof semantics, but their accuracy has not been mea-sured on actual data.
The results of our analysiscan be used to substantiate heories which are com-patible with the empirical evidence, and thus offerinsight into the complex linguistic phenomenon ofantonymy.The second purpose of our work is practical appli-cations.
The semantically unmarked term is almostalways the positive term of the opposition (Boucherand Osgood, 1969); e.g., high is positive, while low isnegative.
Therefore, an automatic method for deter-mining markedness values can also be used to deter-mine the polarity of antonyms.
The work reportedin this paper helps clarify which types of data andtests are useful for such a method and which are not.The need for an automatic orpus-based methodfor the identification of markedness becomes appar-ent when we consider the high number of adjectivesin unrestricted text and the domain-dependence ofmarkedness values.
In the MRC Psycholinguis-tic Database (Coltheart, 1981), a large machine-readable annotated word list, 25,547 of the 150,837entries (16.94%) are classified as adjectives, not in-cluding past participles; ifwe only consider regularlyused grammatical categories for each word, the per-centage of adjectives rises to 22.97%.
For compar-ison, nouns (the largest class) account for 51.28%and 57.47% of the words under the two criteria.In addition, while adjectives tend to have prevalentmarkedness and polarity values in the language atlarge, frequently these values are negated in spe-cific domains or contexts.
For example, healthy is inmost contexts the unmarked member of the opposi-tion healthy:sick; but in a hospital setting, sicknessrather than health is expected, so sick becomes theunmarked term.
The methods we describe are basedon the form of the words and their overall statisticalproperties, and thus cannot predict specific occur-fences of markedness reversals.
But they can predictthe prevalent markedness value for each adjective ina given domain, something which is impractical todo by hand separately for each domain.We have built a large system for the automatic,domain-dependent classification of adjectives ac-cording to semantic riteria.
The first phase of oursystem (Hatzivassiloglou and McKeown, 1993) sep-arates adjectives into groups of semantically relatedones.
We extract markedness values according tothe methods described in this paper and use them insubsequent phases of the system that further analyzethese groups and determine their scalar structure.An automatic method for extracting polarity in-formation would also be useful for the augmenta-tion of lexico-semantic databases such as WordNet(Miller et al, 1990), particularly when the methodaccounts for the specificities of the domain sublan-guage; an increasing number of NLP systems relyon such databases (e.g., (Resnik, 1993; Knight andLuk, 1994)).
Finally, knowledge of polarity can becombined with corpus-based collocation extractionmethods (Smadja, 1993) to automatically produceentries for the lexical functions used in Meaning-Text Theory (Mel'~uk and Pertsov, 1987) for textgeneration.
For example, knowing that hearty isa positive term enables the assignment of the col-location hearty eater to the lexical function entryMAGS( eater)=-hearty.
13 Tests  fo r  Semant ic  MarkednessMarkedness in general and semantic markedness inparticular have received considerable attention inthe linguistics literature.
Consequently, several testsfor determining markedness have been proposed bylinguists.
Most of these tests involve human judg-ments (Greenberg, 1966; Lyons, 1977; Waugh, 1982;Lehrer, 1985; Ross, 1987; Lakoff, 1987) and are notsuitable for computer implementation.
However,some proposed tests refer to comparisons betweenmeasurable properties of the words in question andare amenable to full automation.
These tests are:1.
Text frequency.
Since the unmarked term canappear in more contexts than the marked one,and it has both general and specific senses, itshould appear more frequently in text than themarked term (Greenberg, 1966).2.
Formal markedness.
A formal markedness re-lationship (i.e., a morphology relationship be-tween the two words), whenever it exists, shouldbe an excellent predictor for semantic marked-ness (Greenberg, 1966; Zwicky, 1978).3.
Formal complexity.
Since the unmarked word isthe more general one, it should also be morpho-logically the simpler (Jakobson, 1962; Battis-tella, 1990).
The "economy of language" prin-1MAGN stands for magnify.198ciple (Zipf, 1949) supports this claim.
Note thatthis test subsumes test (2).4.
Morphological produclivity.
Unmarked words,being more general and frequently used to de-scribe the whole scale, should be freer to com-bine with other linguistic elements (Winters,1990; Battistella, 1990).5.
Differentialion.
Unmarked terms should ex-hibit higher differentiation with more subdis-tinetions (Jakobson, 1984b) (e.g., the presenttense (unmarked) appears in a greater varietyof forms than the past), or, equivalently, themarked term should lack some subcategories(Greenberg, 1966).The first of the above tests compares the text fre-quencies of the two words, which are clearly mea-surable and easily retrievable from a corpus.
Weuse the one-million word Brown corpus of writtenAmerican English (Ku~era and Francis, 1967) forthis purpose.
The mapping of the remaining tests toquantifiable variables is not as immediate.
We usethe length of a word in characters, which is a rea-sonable indirect index of morphological complexity,for tests (2) and (3).
This indicator is exact for thecase of test (2), since the formally marked word isderived from the unmarked one through the additionof an affix (which for adjectives is always a prefix).The number of syllables in a word is another ea-sonable indicator of morphological complexity thatwe consider, although it is much harder to computeautomatically than word length.For morphological productivity (test (4)), we mea-sure several variables related to the freedom of theword to receive affixes and to participate in com-pounds.
Several distinctions exist for the definitionof a variable that measures the number of wordsthat are morphologically derived from a given word.These distinctions involve:Q Whether to consider the number of distinctwords in this category (types) or the total fre-quency of these words (tokens).?
Whether to separate words derived throughaffixation from compounds or combine thesetypes of morphological relationships.?
If word types (rather than word frequencies) aremeasured, we can select to count homographs(words identical in form but with different partsof speech, e.g., light as an adjective and light asa verb) as distinct ypes or map all homographsof the same word form to the same word type.Finally, the differentiation test (5) is the one gen-eral markedness test that cannot be easily mappedinto observable properties of adjectives.
Somewhatarbitrarily, we mapped this test to the number ofgrammatical categories (parts of speech) that eachword can appear under, postulating that the un-marked term should have a higher such number.The various ways of measuring the quantities com-pared by the tests discussed above lead to the consid-eration of 32 variables.
Since some of these variablesare closely related and their number is so high thatit impedes the task of modeling semantic marked-ness in terms of them, we combined several of them,keeping 14 variables for the statistical analysis.4 Data  Co l lec t ionIn order to measure the performance of the marked-ness tests discussed in the previous section, wecollected a fairly large sample of pairs of antony-mous gradable adjectives that can appear in how-questions.
The Deese antonyms (Deese, 1964) is theprototypical collection of pairs of antonymous adjec-tives that have been used for similar analyses in thepast (Deese, 1964; Justeson and Katz, 1991; Grefen-stette, 1992).
However, this collection contains only75 adjectives in 40 pairs, some of which cannot beused in our study either because they are primar-ily adverbials (e.g., inside-outside) or not gradable(e.g., alive-dead).
Unlike previous studies, the na-ture of the statistical analysis reported in this paperrequires a higher number of pairs.Consequently, we augmented the Deese set withthe set of pairs used in the largest manual previ-ous study of markedness in adjective pairs (Lehrer,1985).
In addition, we included all gradable adjec-tives which appear 50 times or more in the Browncorpus and have at least one gradable antonym;the antonyms were not restricted to belong to thisset of frequent adjectives.
For each adjective col-lected according to this last criterion, we included allthe antonyms (frequent or not) that were explicitlylisted in the Collins COBUILD dictionary (Sinclair,1987) for each of its senses.
This process gave us asample of 449 adjectives (both frequent and infre-quent ones) in 344 pairs.
2We separated the pairs on the basis of the how-testinto those that contain one semantically unmarkedand one marked term and those that contain twomarked terms (e.g., fat-lhin), removing the latter.For the remaining pairs, we identified the unmarkedmember, using existing designations (Lehrer, 1985)whenever that was possible; when in doubt, the pairwas dropped from further consideration.
We alsoseparated the pairs into two groups according towhether the two adjectives in each pair were mor-phologically related or not.
This allowed us to studythe different behavior of the tests for the two groupsseparately.
Table 1 shows the results of this cross-classification of the adjective pairs.Our next step was to measure the variables de-scribed in Section 3 which are used in the various2The collection method is similar to Deese's: He alsostarted from frequent adjectives but used human sub-jects to elicit antonyms instead of a dictionary.199One Bothunmarked markedMorphologically 211 54unrelatedMorphologically 68 3relatedTotal 279 57Total26571\[\[ 336Table 1: Cross-classification of adjective pairs ac-cording to morphological relationship and marked-ness status.tests for semantic markedness.
For these measure-ments, we used the MRC Psycholinguistic Database(Coltheart, 1981) which contains a variety of mea-sures for 150,837 entries counting different parts ofspeech or inflected forms as different words (115,331distinct words).
We implemented an extractor pro-gram to collect the relevant measurements for theadjectives in our sample, namely text frequency,number of syllables, word length, and number ofparts of speech.
All this information except thenumber of syllables can also be automatically ex-tracted from the corpus.
The extractor program alsocomputes information that is not directly stored inthe MRC database.
Affixation rules from (Quirk etal., 1985) are recursively employed to check whethereach word in the database can be derived from eachadjective, and counts and frequencies of such de-rived words and compounds are collected.
Overall,32 measurements are computed for each adjective,and are subsequently combined into the 14 variablesused in our study.Finally, the variables for the pairs are computedas the differences between the corresponding vari-ables for the adjectives in each pair.
The output ofthis stage is a table, with two strata correspondingto the two groups, and containing measurements on14 variables for the 279 pairs with a semanticallyunmarked member.5 Eva luat ion  o f  L ingu is t i c  TestsFor each of the variables, we measured how manypairs in each group it classified correctly.
A positive(negative) value indicates that the first (second) ad-jective is the unmarked one, except for two variables(word length and number of syllables) where the op-posite is true.
When the difference is zero, the vari-able selects neither the first or second adjective asunmarked.
The percentage of nonzero differences,which correspond to cases where the test actuallysuggests a choice, is reported as the applicability ofthe variable.
For the purpose of evaluating the accu-racy of the variable, we assign such cases randomlyto one of the two possible outcomes in accordancewith common practice in classification (Duda andHart, 1973).For each variable and each of the two groups, wealso performed a statistical test of the null hypoth-esis that its true accuracy is 50%, i.e., equal to theexpected accuracy of a random binary classifier.
Un-der the null hypothesis, the number of correct re-sponses follows a binomial distribution with param-eter p = 0.5.
Since all obtained measurements ofaccuracy were higher than 50%, any rejection of thenull hypothesis implies that the corresponding testis significantly better than chance.Table 2 summarizes the values obtained for someof the 14 variables in our data and reveals somesurprising facts about their performance.
The fre-quency of the adjectives i the best predictor in bothgroups, achieving an overall accuracy of 80.64% withhigh applicability (98.5-99%).
This is all the moreremarkable in the case of the morphologically relatedadjectives, where frequency outperforms length ofthe words; recall that the latter directly encodes theformal markedness relationship, so frequency is ableto correctly classify some of the cases where formaland semantic markedness values disagree.
On theother hand, tests based on the "economy of lan-guage" principle, such as word length and numberof syllables, perform badly when formal markednessrelationships do not exist, with lower applicabilityand very low accuracy scores.
The same can be saidabout the test based on the differentiation propertiesof the words (number of different parts of speech).
Infact, for these three variables, the hypothesis of ran-dom performance cannot be rejected even at the 5%level.
Tests based on the productivity of the words,as measured through affixation and compounding,tend to fall in-between: their accuracy is generallysignificant, but their applicability is sometimes low,particularly for compounds.6 P red ic t ions  Based  on  More  thanOne TestWhile the frequency of the adjectives is the bestsingle predictor, we would expect to gain accuracyby combining the answers of several simple tests.We consider the problem of determining semanticmarkedness as a classification problem with two pos-sible outcomes ("the first adjective is unmarked"and "the second adjective is unmarked").
To de-sign an appropriate classifier, we employed two gen-eral statistical supervised learning methods, whichwe briefly describe in this section.Dec is ion  t rees  (Quinlan, 1986) is the first statis-tical supervised learning paradigm that we explored.A popular method for the automatic onstructionof such trees is binary recursive partitioning, whichconstructs a binary tree in a top-down fashion.Starting from the root, the variable X which betterdiscriminates among the possible outcomes is se-lected and a test of the form X < consiant is as-200Test Morphologically UnrelatedP-ValueFrequencyApplicability99.05%Accuracy75.36% 8.4 .10  -14Number of syllables 58.29% 55.92% 0.098Word length 83.41% 52.13% 0.582Number of 71.09% 56.87% 0.054 homographsTotal number of 64.45% 61.14% 0.0015 compoundsUnique words derived 95.26% 66.35% 2.3.10 -6by affixationTotal frequency of 82.46% 66.35% 2.3 ?
10 -6derived wordsII Morphologically RelatedApplicability Accuracy P-Value98.53%95.59%100.00%97.06%92.65%95.59%< 10 -167 .7 .10  -144.4.10 -1666.18%14.71%98.53%83.82%79.41%60.29%94.12%91.18%i .
I  ?
i 0  - s0.1145.8.10 -158.2.10 -13Table 2: Evaluation of simple markedness tests.
The probability of obtaining by chance performance equalto or better than the observed one is listed in the P- Value column for each test.sociated with the root node of the tree.
All train-ing cases for which this test succeeds (fails) belongto the left (right) subtree of the decision tree.
Themethod proceeds recursively, by selecting a new vari-able (possibly the same as in the parent node) anda new cutting point for each subtree, until all thecases in one subtree belong to the same category orthe data becomes too sparse.
When a node can-not be split further, it is labeled with the locallymost probable category.
During prediction, a pathis traced from the root of the tree to a leaf, and thecategory of the leaf is the category reported.If the tree is left to grow uncontrolled, it will ex-actly represent the training set (including its pecu-liarities and random variations), and will not be veryuseful for prediction on new cases.
Consequently,the growing phase is terminated before the trainingsamples assigned to the leaf nodes are entirely ho-mogeneous.
A technique that improves the qualityof the induced tree is to grow a larger than optimaltree and then shrink it by pruning subtrees (Breimanet al, 1984).
In order to select the nodes to shrink,we normally need to use new data that has not beenused for the construction of the original tree.In our classifier, we employ a maximum likeli-hood estimator based on the binomial distributionto select the optimal split at each node.
During theshrinking phase, we optimally regress the probabili-ties of children nodes to their parent according to ashrinking parameter ~ (Hastie and Pregibon, 1990),instead of pruning entire subtrees.
To select the op-timal value for (~, we initially held out a part of thetraining data.
In a later version of the classifier,we employed cross-validation, separating our train-ing data in 10 equally sized subsets and repeatedlytraining on 9 of them and validating on the other.Log- l inear  regress ion  (Santner and Duffy,1989) is the second general supervised learningmethod that we explored.
In classical inear model-ing, the response variable y is modeled as y -- bTx+ewhere b is a vector of weights, x is the vector of thevalues of the predictor variables and e is an errorterm which is assumed to be normally distributedwith zero mean and constant variance, independentof the mean of y.
The log-linear egression modelgeneralizes this setting to binomial sampling wherethe response variable follows a Bernoulli distribution(corresponding to a two-category outcome); notethat the variance of the error term is not indepen-dent of the mean of y any more.
The resulting gen-eralized linear model (McCullagh and Nelder, 1989)employs a linear predictor y = bTx + e as before,but the response variable y is non-linearly related tothrough the inverse logit function,eY y - __1A-e"Note that y E (0, 1); each of the two ends of thatinterval is associated with one of the possible choices.We employ the iterative reweighted least squaresalgorithm (Baker and Nelder, 1989) to approximatethe maximum likelihood cstimate of the vector b,but first we explicitly drop the constant erm (in-tercept) and most of the variables.
The interceptis dropped because the prior probabilities of thetwo outcomes are known to be equal.
3 Several ofthe variables are dropped to avoid overfitting (Dudaand Hart, 1973); otherwise the regression model willuse all available variables, unless some of them arelinearly dependent.
To identify which variables weshould keep in the model, we use the analysis of de-viance method with iterative stepwise refinement ofthe model by iteratively adding or dropping one termif the reduction (increase) in the deviance compares3The order of the adjectives in the pairs is randomizedbefore training the model, to ensure that both outcomesare equiprobable.20112"10i?
?340% 50% 60% 70% 80% 90%AccuracyFigure 1: Probability densities for the accuracyof the frequency method (dotted line) and thesmoothed log-linear model (solid line) on the mor-phologically unrelated adjectives.favorably with the resulting loss (gain) in residualdegrees of freedom.
Using a fixed training set, sixof the fourteen variables were selected for modelingthe morphologically unrelated adjectives.
Frequencywas selected as the only component of the model forthe morphologically related ones.We also examined the possibility of replacing somevariables in these models by smoothing cubic B-splines (Wahba, 1990).
The analysis of deviance forthis model indicated that for the morphologicallyunrelated adjectives, one of the six selected variablesshould be removed altogether and another should bereplaced by a smoothing spline.7 Eva luat ion  o f  the  ComplexPred ic torsFor both decision trees and log-linear egression, werepeatedly partitioned the data in each of the twogroups into equally sized training and testing sets,constructed the predictors using the training sets,and evaluated them on the testing sets.
This pro-cess was repeated 200 times, giving vectors of esti-mates for the performance of the various methods.The simple frequency test was also evaluated in eachtesting set for comparison purposes.
From these vec-tors, we estimate the density of the distribution ofthe scores for each method; Figure 1 gives these den-sities for the frequency test and the log-linear modelwith smoothing splines on the most difficult case,the morphologically unrelated adjectives.Table 3 summarizes the performance of the meth-ods on the two groups of adjective pairs.
4 In orderto assess the significance of the differences between4The applicability of all complex methods was 100%in both groups.the scores, we performed a nonparametric sign test(Gibbons and Chakraborti, 1992) for each complexpredictor against he simple frequency variable.
Thetest statistic is the number of runs where the scoreof one predictor is higher than the other's; as is com-mon in statistical practice, ties are broken by assign-ing half of them to each category.
Under the nullhypothesis of equal performance of the two methodsthat are contrasted, this test statistic follows the bi-nomial distribution with p = 0.5.
Table 3 includesthe exact probabilities for obtaining the observed (ormore extreme) values of the test statistic.From the table, we observe that the tree-basedmethods perform considerably worse than frequency(significant at any conceivable level), even whencross-validation is employed.
Both the standardand smoothed log-linear models outperform the fre-quency test on the morphologically unrelated adjec-tives (significant at the 5% and 0.1% levels respec-tively), while the log-linear model's performance iscomparable to the frequency test's on the morpho-logically related adjectives.
The best predictor over-all is the smoothed log-linear model.
5The above results indicate that the frequency testessentially contains almost all the information thatcan be extracted collectively from all linguistic tests.Consequently, even very sophisticated methods forcombining the tests can offer only small improve-ment.
Furthermore, the prominence of one variablecan easily lead to overfitting the training data in theremaining variables.
This causes the decision treemodels to perform badly.8 Conc lus ions  and  Future  WorkWe have presented a quantitative analysis of the per-formance of measurable linguistic tests for the selec-tion of the semantically unmarked term out of a pairof antonymous adjectives.
The analysis hows that asimple test, word frequency, outperforms more com-plicated tests, and also dominates them in terms ofinformation content.
Some of the tests that havebeen proposed in the linguistics literature, notablytests that are based on the formal complexity anddifferentiation properties of the words; fail to giveany useful information at all, at least with the ap-proximations we used for them (Section 3).
On theother hand, tests based on morphological productiv-ity are valid, although not as accurate as frequency.Naturally, the validity of our results depends onthe quality of our measurements.
While for most ofthe variables our measurements are necessarily ap-sit should be noted here that the independence as-sumption of the sign test is mildly violated in these re-peated runs, since the scores depend on collections of in-dependent samples from a finite population.
This milddependence will increase somewhat the probabilities un-der the true null distribution, but we can be confidentthat probabilities such as 0.08% will remain significant.202Morphologically Morphologically OverallPredictor tested unrelated relatedAccuracy P-Value Accuracy P-Value Accuracy P-ValueFrequency 75.87% - 97.15% - 81.07% -Decision tree (no cross-validation) 64.99% 8.2.10 -53 94.40% 1.5.10 - l?
72.05% 1.7- 10 TMDecision tree 10-40 75.19% 7.2.10 -47 (cross validated) 69.13% 94.40% 1.5- 10 - l?Log-linear model(no smoothing) 76.52% 0 .0281 97.17% 1.00 81.55% 0.0228Log-linear model(with smoothing) 76.82% 0.0008 97.17% 1.00 81.77% 0.0008Table 3: Evaluation of the complex predictors.
The probability of obtaining by chance a difference inperformance r lative to the simple frequency test equal to or larger than the observed one is listed in theP- Value column for each complex predictor.proximate, we believe that they are nevertheless ofacceptable accuracy since (1) we used a representa-tive corpus; (2) we selected both a large sample ofadjective pairs and a large number of frequent ad-jectives to avoid sparse data problems; (3) the pro-cedure of identifying secondary words for indirectmeasurements based on morphological productivityoperates with high recall and precision; and (4) themapping of the linguistic tests to comparisons ofquantitative variables was in most cases straightfor-ward, and always at least plausible.The analysis of the linguistic tests and their com-binations has also led to a computational methodfor the determination f semantic markedness.
Themethod is completely automatic and produces ac-curate results at 82% of the cases.
We considerthis performance r asonably good, especially sinceno previous automatic method for the task has beenproposed.
While we used a fixed set of 449 adjec-tives for our analysis, the number of adjectives inunrestricted text is much higher, as we noted in Sec-tion 2.
This multitude of adjectives, combined withthe dependence of semantic markedness on the do-main, makes the manual identification ofmarkednessvalues impractical.In the future, we plan to expand our analy-sis to other classes of antonymous words, particu-larly verbs which are notoriously difficult to ana-lyze semantically (Levin, 1993).
A similar method-ology can be applied to identify unmarked (posi-tive) versus marked (negative) terms in pairs suchas agree: dissent.AcknowledgementsThis work was supported jointly by the AdvancedResearch Projects Agency and the Office of NavalResearch under contract N00014-89-J-1782, and bythe National Science Foundation under contractGER-90-24069.
It was conducted under the auspicesof the Columbia University CAT in High Perfor-mance Computing and Communications in Health-care, a New York State Center for Advanced Tech-nology supported by the New York State Science andTechnology Foundation.
We wish to thank JudithKlavans, Rebecca Passonneau, and the anonymousreviewers for providing us with useful comments onearlier versions of the paper.Re ferencesR.
J. Baker and J.
A. Nelder.
1989.
The GLIMSystem, Release 3: Generalized Linear InteractiveModeling.
Numerical Algorithms Group, Oxford.Edwin L. Battistella.
1990.
Markedness: The Eval-uative Superstructure of Language.
State Univer-sity of New York Press, Albany, NY.T.
Boucher and C. E. Osgood.
1969.
The Polyannahypothesis.
Journal of Verbal Learning and VerbalBehavior, 8:1-8.Leo Breiman, J. H. Friedman, R. Olshen, and C. J.Stone.
1984.
Classification and Regression Trees.Wadsworth International Group, Belmont, CA.M.
Coltheart.
1981.
The MRC Psycholinguis-tic Database.
Quarterly Journal of ExperimentalPsychology, 33A:497-505.James Deese.
1964.
The associative structure ofsome common English adjectives.
Journal of Ver-bal Learning and Verbal Behavior, 3(5):347-357.Richard O. Duda and Peter E. Hart.
1973.
PatternClassification and Scene Analysis.
Wiley, NewYork.Jean Dickinson Gibbons and Subhabrata Chak-raborti.
1992.
Nonparametric Statistical Infer-ence.
Marcel Dekker, New York, 3rd edition.203Joseph H. Greenberg.
1966.
Language Universals.Mouton, The Hague.Gregory Grefenstette.
1992.
Finding semantic simi-larity in raw text: The Deese antonyms.
In Prob-abilistic Approaches to Natural Language: Papersfrom the 1992 Fall Symposium.
AAAI.T.
Hastie and D. Pregibon.
1990.
Shrinking trees.Technical report, AT&T Bell Laboratories.Vasileios Hatzivassiloglou and Kathleen McKeown.1993.
Towards the automatic identification of ad-jectival scales: Clustering adjectives according tomeaning.
In Proceedings of the 31st Annual Meet-ing of the ACL, pages 172-182, Columbus, Ohio.Roman Jakobson.
1962.
Phonological Studies, vol-ume 1 of Selected Writings.
Mouton, The Hague.Roman Jakobson.
1984a.
The structure of the Rus-sian verb (1932).
In Russian and Slavic GrammarStudies 1931-1981, pages 1-14.
Mouton, Berlin.Roman Jakobson.
1984b.
Zero sign (1939).
InRussian and Slavic Grammar Studies 1931-1981,pages 151-160.
Mouton, Berlin.John S. Justeson and Slava M. Katz.
1991.
Co-occurrences of antonymous adjectives and theircontexts.
Computational Linguistics, 17(1):1-19.Kevin Knight and Steve K. Luk.
1994.
Buildinga large-scale knowledge base for machine transla-tion.
In Proceedings of the 12th National Confer-ence on Artificial Intelligence (AAAI-94).
AAAI.Henry KuSera and Winthrop N. Francis.
1967.Computational Analysis of Present-Day AmericanEnglish.
Brown University Press, Providence, RI.Henry Ku6era.
1982.
Markedness and frequency:A computational nalysis.
In Jan Horecky, edi-tor, Proceedings of the Ninth International Con-ference on Computational Linguistics (COLING-82), pages 167-173, Prague.
North-Holland.George Lakoff.
1987.
Women, Fire, and DangerousThings.
University of Chicago Press, Chicago.Adrienne Lehrer.
1985.
Markedness and antonymy.Journal of Linguistics, 31(3):397-429, September.Beth Levin.
1993.
English Verb Classes and Alter-nations: A Preliminary Investigation.
Universityof Chicago Press, Chicago.Stephen C. Levinson.
1983.
Pragmatics.
CambridgeUniversity Press, Cambridge, England.John Lyons.
1977.
Semantics, volume 1.
CambridgeUniversity Press, Cambridge, England.Peter McCullagh and John A. Nelder.
1989.
Gen-eralized Linear Models.
Chapman and Hall, Lon-don, 2nd edition.Igor A. Mel'~uk and Nikolaj V. Pertsov.
1987.
Sur-face Syntax of English: a Formal Model withinthe Meaning-Text Framework.
Benjamins, Ams-terdam and Philadelphia.George A. Miller, R. Beckwith, C. Fellbaum,D.
Gross, and K. J. Miller.
1990.
WordNet: Anon-line lexical database.
International Journal ofLexicography (special issue), 3(4):235-312.John R. Quinlan.
1986.
Induction of decision trees.Machine Learning, 1(1):81-106.Randolph Quirk, Sidney Greenbaum, GeoffreyLeech, and Jan Svartvik.
1985.
A ComprehensiveGrammar of the English Language.
Longman,London and New York.Philip Resnik.
1993.
Semantic lasses and syntacticambiguity.
In Proceedings of the ARPA Workshopon Human Language Technology.
ARPA Informa-tion Science and Technology Office.John R. Ross.
1987.
Islands and syntactic pro-totypes.
In B.
Need et ah, editors, Papersfrom the 23rd Annual Regional Meeting of theChicago Linguistic Society (Part I: The GeneralSession), pages 309-320.
Chicago Linguistic Soci-ety, Chicago.Thomas J. Santner and Diane E. Duffy.
1989.
TheStatistical Analysis of Discrete Data.
Springer-Verlag, New York.John Sinclair (editor in chief).
1987.
CollinsCOBUILD English Language Dictionary.
Collins,London.Frank Smadja.
1993.
Retrieving collocationsfrom text: XTRACT.
Computational Linguistics,19(1):143-177, March.Nikolai S. Trubetzkoy.
1939.
Grundzuger derPhonologic.
Travaux du Cercle Linguistique dePrague 7, Prague.
English translation i  (Trubet-zkoy, 1969).Nikolai S. Trubetzkoy.
1969.
Principles of Phonol-ogy.
University of California Press, Berkeley andLos Angeles, California.
Translated into Englishfrom (Trubetzkoy, 1939).Grace Wahba.
1990.
Spline Models for Observa-tional Data.
CBMS-NSF Regional Conference se-ries in Applied Mathematics.
Society for Indus-trial and Applied Mathematics (SIAM), Philadel-phia, PA.Linda R. Waugh.
1982.
Marked and unmarked: Achoice between unequals.
Semiotica, 38:299-318.Margaret Winters.
1990.
Toward a theory of syn-tactic prototypes.
In Savas L. Tsohatzidis, editor,Meanings and Prototypes: Studies in LinguisticCategorization, pages 285-307.
Routledge, Lon-don.George K. Zipf.
1949.
Human Behavior and thePrinciple of Least Effort: An Introduction to Hu-man Ecology.
Addison-Wesley, Reading, MA.A.
Zwicky.
1978.
On markedness in morphology.Die Spra'che, 24:129-142.204
