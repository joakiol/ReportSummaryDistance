BULK PROCESSING OF TEXT ON A MASSIVELYPARALLEL COMPUTERGary W. SabotThinking Machines Corporation245 First St.Cambridge~ MA 02142AbstractDictionary lookup is a computational activitythat can be greatly accelerated when performedon large amounts of text by a parallel computersuch as the Connection Machine TM Computer(CM).
Several algorithms for parallel dictionarylookup are discussed, including one that allowsthe CM to lookup words at a rate 450 times thatof lookup on a Symbolics 3600 Lisp Machine.1 An Overview of the Dict ionaryP rob lemThis paper will discuss one of the text processing prob-lems that was encountered during the implementation fthe CM-Indexer, a natural anguage processing programthat runs on the Connection Machine (CM).
The prob-lem is that of parallel dictionary lookup: given botha dictionary and a text consisting of many thousandsof words, how can the appropriate definitions be dis-tributed to the words in the text as rapidly as possible?A parallel dictionary lookup algorithm that makes ef-ficient use of the CM hardware was discovered and isdescribed in this paper.It is clear that there are many natural anguage pro-cessing applications in which such a dictionary algo-rithm is necessary.
Indexing and searching of databasesconsisting of unformatted natural language text is onesuch application.
The proliferation of personal comput-ers, the widespread use of electronic memos and elec-tronic mail in large corporations, and the CD-ROM areall contributing to an explosion in the amount of usefulunformatted text in computer eadable form.
Parallelcomputers and algorithms provide one way of dealingwith this explosion.2 The CM: Machine Descr ipt ionThe CM consists of a large number number of proces-sor/memory cells.
These cells are used to store datastructures.
In accordance with a stream of instructionsthat are broadcast from a single conventional host com-puter, the many processors can manipulate the data inthe nodes of the data structure in parallel.Each processor in the CM can have its own localvariables.
These variables are called parallel variables,or parallel fields.
When a host computer program per-forms a serial operation on a parallel variable, that op-eration is performed separately in each processor in theCM.
For example, a program might compare two paral-lel string variables.
Each CM processor would executethe comparison on its own local data and produce itsown local result.
Thus, a single command can result intens of thousands of simultaneous CM comparisons.In addition to their computation ability, CM pro-cessors can communicate with each other via a specialhardware communication network.
In effect, commu-nication is the parallel analog of the pointer-followingexecuted by a serial computer as it traverses the linksof a data structure or graph.3 Dict ionary AccessA dictionary may be defined as a mapping that takes aparticular word and returns a group of status bits.
Sta-tus bits indicate which sets or groups of words a partic-ular word belongs to.
Some of the sets that are useful innatural anguage processing include syntactic ategoriessuch as nouns, verbs, and prepositions.
Programs alsocan use semantic haracterization i formation.
For ex-ample, knowing whether a word is name of a famousperson (i.e.
Lincoln, Churchill), a place, an interjection,or a time or calendar term will often be useful to a textprocessing program.The task of looking up the definition of a word con-sists of returning a binary number that contains l 's only.in bit positions that correspond with the groups to whichthat word belongs.
Thus, the definition of "Lincoln"contains a zero in the bit that indicates a word can serveas a verb, but it contains a 1 in the famous person's namebit.While all of the examples in this paper involve onlya few words, it should be understood that the CM isefficient and cost effective only when large amounts of128Figure 1.
Simple B~ng Dic~onwy A~rn ,  marking fwnoL= namesFormat of Processor Dis~'am: \] Strinq - Processor # JFanlous-~t: ~Figure 2.
Sy~taci?
Pnoge?
Noun Loca=~Fotma~ of Processor D~agram: S~na - Processor # IPtoger-Noun-bit:Slac~ if Selected:a.
Select processors containing "Lincoln' :?
bouz.4 Mcnae~,mge=- 5 .-6b.
Mark seiected processors as famous names:c. Select processors containing "Michaetangelo":d. Mark Selected processors as famous names:\[;:: MI;: ; Jl :?Note: famous name is markeda.
Select processors with an upper case, alphabetic first characterb, Subselect  for processors not at start of sentence:c. Mark selected processors as proper nouns:Proper Noun Proper NounMa~ed Mad~edtext are to be processed.
One would use the dictionaryalgorithms described in this paper to look up all of thewords in an entire novel; one would not use them tolook up the ten words in a user's query to a questionanswering system.4 A Simple Broadcasting Dictio-nary AlgorithmOne way to implement a parallel dictionary is to seri-ally broadcast all of the words in a given set.
Processorsthat contain a broadcast word check off the appropriatestatus bits.
When all of the words in one set have beenbroadcast, the next set is then broadcast.
For exam-ple, suppose that the dictionary lookup program beginsby attempting to mark the words that are also famouslast names.
Figure 1 illustrates the progress of the algo-rithm as the words "Lincoln" and then "Michaelangelo"are broadcast.
In the first step, all occurrences of "Lin-coln" are marked as famous names.
Since that worddoes not occur in the sample sentence, no marking ac-tion takes place.
In the second step, all occurrences of"Michaelange\]o" are marked, including the one in thesample sentence.In step d, where all processors containing "Michae-langelo" are marked as containing famous names, theprogram could simultaneously mark the selected pro-cessors as containing proper nouns.
Such shortcuts willnot be examined at this time.After all of the words in the set of ,famous nameshave been broadcast, he algorithm would then begin tobroadcast he next set, perhaps the set containing thenames of the days of the week.In addition to using this broadcast algorithm, theCM-Indexer uses syntactic definitions of some of the dic-tionary sets.
For example, it defines a proper noun as acapitalized word that does not begin a sentence.
(Propernouns that begin a sentence are not found by this cap-italization based rule; this can be corrected by a moresophisticated rule.
The more sophisticated rule wouldmark the first word in a sentence as a proper noun if itcould find another capitalized occurrence of the word ina nearby sentence.)
Figure 2 illustrates the progress ofthis simple syntactic algorithm as it executes.The implementation f both the broadcast algorithmand the syntactic proper noun rule takes a total of lessthan 30 lines of code in the *Lisp (pronounced "star-lisp ~) programming language.
The entire syntactic rulethat finds all proper nouns executes in less than 5 mil-liseconds.
However, the algorithm that transmits word129F~ure 3.
Unique Wot~ls Dk:~ot~y Impk~ent~onFotma~ of ~ r  Diagram: I RTnn~ - ~r~e~nr mDefintbon Bits: BBBBOefinea-yet?
OBtack if Selected:Ia.
Select all processors where d?-O (not yet defined).
If no processorsare selected, then algorithm terminates.
Otherwise.
find theminimum of the selected processor's addresses.
'~Host  Machine quickly determines that the minimum address is 1b.
Host machine pulls out word in that minimum procesorand looks up its definition in its own serial dictionary/hash table,In this case, the definition of "the" is determined to t~e the bit sequence 001.
(The bits are the status bits discussed in the text.
)Next, the host machine selects all processors containing the word whosedefinition was just looked up:c. The entire looked up definition is assigned to all selected prOcessorsand all selected processors are marked as defined,d.
goto alists takes an average of more than 5 milliseconds perword to broadcast a list of words from the host to theCM.
Thus, since it takes time proportional to the num-ber of words in a given set, the algorithm becomes abottleneck for sets of more than a few thousand words.This means that the larger sets listed above (all nouns,all verbs, etc.)
cannot be transmitted.
The reason thatthis slow algorithm was used in the CM-Indexer was theease with which it could be implemented and tested.5 An Improved Broadcasting Dic-tionary AlgorithmOne improvement to the simple broadcasting algorithmwould be to broadcast entire definitions (i.e.
severalbits), rather than a single bit indicating membership na set.
This would mean that each word in the dictio-nary would only be broadcast once (i.e.
"fly" is botha noun and a verb).
A second improvement would beto broadcast only the words that are actually containedin the text being looked up.
Thus, words that rarelyoccur in English, which make up a large percentage ofthe dictionary, would rarely be broadcast.In summary, this improved ictionary broadcastingalgorithm will loop for the unique words that are con-tained in the text to be indexed, look up the definitionof each such word in a serial dictionary on the host ma-chine, and broadcast the looked-up definition to the en-tire CM.
Figure 3 illustrates how this algorithm wouldassign the definition of all occurrences of the word "the"in a sample text.
(Again, in practice the algorithm oper-ates on many thousands of words, not on one sentence.
)In order to select a currently undefined word to lookup, the host machine xecuting this algorithm must de-termine the address of a selected processor.
The figureindicates that one way to do this is to take the min-imum address of the processors that are currently se-lected.
This can be done in constant time on the CM.This improved dictionary lookup method is usefulwhen the dictionary is much larger than the number ofunique words contained in the text to be indexed.
How-ever, since the same basic operation is used to broadcastdefinitions as in the first algorithm, it is clear that thissecond implementation f a dictionary will not be fea-sible when a text contains more than a few thousandunique words.By analyzing a number of online texts ranging insize from 2,000 words to almost 60,000 words, it wasfound that as the size of the text approaches many tensof thousands of words, the number of unique words in-creased into the thousands.
Therefore, it can be con-cluded that the second implementation f the broad-casting dictionary algorithm is not feasible when thereare more than a few tens of thousands of words in thetext file to be indexed.6 Making Efficient Use of Paral-lel HardwareIn both of the above algorithms, the "heart" of the dic-tionary resided in the serial host.
In the first case, theheart was the lists that represented sets of words; in thesecond case, the heart was the call to a serial dictionarylookup procedure.
Perhaps if the heart of the dictionarycould be stored in the CM, alongside the words from thetext, the lookup process could be accelerated.7 Implementation of DictionaryLookup by Parallel HashingOne possible approach to dictionary lookup would be tocreate a hash code for each word in each CM processor inparallel.
The hash code represents he address of a dif-ferent processor.
Each processor can then send a lookuprequest to the processor at the hash-code address, where130Figure 4.
I\]lus~'atlon $ SorlFOml&t o~ Pt'oce.~.~r Oia~ri~m: \[ ~;tnnn.
pr~pq~nr J 1 fDefinition Bits: BBBBJO?~inaI-Address: NSla~ it Selected:a.
Select all processors, set original address field to bethe processor number :b.
Call sort with string as the key, and string and N asthe fields to copy.
The final result is:the definition of the word that hashes to that addresshas been stored in advance.
The processors that receiverequests would then respond by sending back the pre-stored definition of their word to the address containedin the request packet.One problem with this approach is that all  of theprocessors containing a given word will send a requestfor a definition to the same hashed address.
To some ex-tent, this problem can be ameliorated by broadcastinga list of the n (i.e.
200) most common words in English,before attempting any dictionary lookup cycles.
An-other problem with this approach is that the hash codeitself will cause collisions between different ext wordsthat hash to the same value.8 An Efficient Dictionary Algo-rithmThere is a faster and more elegant approach to buildinga dictionary than the hashing scheme.
This other ap-proach has the additional advantage that it can be builtfrom two generally useful submodules each of which hasa regular, easily debugged structure.The first submodule is the sort  function, the secondis the scan  function.
After describing the two submod-ules, a simple version of the fast dictionary algorithmwill be presented, along with suggestions for dealingwith memory and processor limitations.8 .1  Para l le l  Sor t ingA parallel sort is similar in function to a serial sort.
Itaccepts as arguments a parallel data field and a par-allel comparison predicate, and it sorts among the se-lected processors so that the data in each successive (byaddress) processor increases monotonically.
There areparallel sorting algorithms that execute in time propor-tional to the square of the logarithm of the number ofitems to be sorted.
One easily implemented sort, theenumerate-and-pack sort, takes about 1.5 millisecondsper bit to sort 64,000 numbers on the CM.
Thus, ittakes 48 milliseconds to sort 64,000 32-bit numbers.Figure 4 illustrates the effect a parallel sort has on asingle sentence.
Notice that pointers back to the originallocation of each word can be attached to words beforethe textual order of the words is scrambled by the sort.8 .2  Scan:  Spread ing  In fo rmat ion  in  Log-a r i thmic  T imeA scan algorithm takes an associative function of twoarguments, call it F, and quickly applies it to data fieldvalues in successive processors of:?
a*b?
C?
d?
eThe scan algorithm produces output" fields in thesame processors with the values:?
a?
Fia, b)?
F(r(a, b), c)?
F(F(F(a, b), c), d)?
etc.The key point is that a scan algorithm can take ad-vantage of the associative law and perform this task inlogarithmic time.
Thus, 16 applications of F are suf-ficient to scan F across 64,000 processors.
Figure 5shows one possible scheme for implementing scan.
Whilethe scheme in the diagram is based on a simple linkedlist structure, scan may also be implemented on binarytrees, hypercubes, and other graph data structures.
Thenature of the routing system of a particular parallel com-puter will select which data structures can be scannedmost rapidly and efficiently.131Figure 5.
Illustration of ScanFormat of processor Diagram: J StrJn~ - PrOCeSSOrFurcc~n va~e: F Backward pointer can be calculated(P is an proc admess= Fotwarclpoulter:P in constant time: all processors \[ ~=~ if se~aact: send their own addresses to the processors pointed to by P.f is any associative function of two argumentsa.
Select all processors, initialize function value to string, forward pointerto self address + 1 :b.
Get back pointer, get function value from processor at I~ack pointer,call this value 8F.
Replace the current function value, F, with f(BF,F):f(e,f) l(l,g) t(g,n)P: 71~ P: ~J P:C. Calculate a forward pointer that goes twice as far as the current forward pointer.This can be done as follows: Get the value of P at the processor pointed toby your own P, and replace your own P with that new value:d. ff any processor has a valid forward pointer, goto b(the next execution of b has the following effect on the first 4 processors:a f(a,o) f( a, f(b,c)) ~a.b) .
f(c,O)P: 3 P: 4 P: S P: 6Note that since f is associative,f(a, f(b, c)) is always equal to f(f(a,b), c),and f(f(a,b), f(c,d)) - f( f( f(a, b), c), d)When combined with an appropriate F, scan has ap-plications in a variety of contexts.
For example, scan isuseful in the parallel enumeration of objects and for re-gion labeling?
Just as the FFT can be used to efficientlysolve many problems involving polynomials, can can beused to create fficient programs that operate on graphs,and in particular on linked lists that contain atural, an-guage text.8 .3 App l i ca t ion  o f  Scan  and  Sor t  to  D ic -t ionary  LookupTo combine these two modules into a dictionary, we needto allocate a bit, DEFINED?, that is 1 only in processorsthat contain a valid definition of their word.
Initially, itis 1 in the processors that contain words from the dictio-nary, and 0 in processors that contain words that comefrom the text to be looked up.
The DEFINED?
bit willbe used by the algorithm as it assigns definitions to textwords.
As soon as a word receives its definition, it willhave its DEFINED?
bit turned on.
The word can thenbegin to serve as an additional copy of the dictionaryentry for the remainder of the lookup cycle.
(This is the"trick" that allows scan to execute in logarithmic time.
)First, an alphabetic sort is applied in parallel to allprocessors, with the word stored in each processor serv-ing as the primary key, and the DEFINED?
bit actingas a secondary key.
The result will be that all copies ofa given word are grouped together into sequential (byprocessor address) lists, with the single dictionary copyof each word immediately preceding any and all textcopies of the same word.The definitions that are contained in the dictionaryprocessors can then be distributed to all of the textwords in logarithmic time by scanning the processorswith the following associative function f:x and y are processors that have the fol lowingfields or parallel variables:STRING (a word)DEFINED?
(i if word contains a correct definition)ORIGINAL-ADDRESS (where word resided before sort)DEFINITION (initially correct only in dictionarywords)/.function f returns a variable containing the samefour fields.
This is a pseudo language; the actualprogram was written in *Lisp.function f(x,y):f.STRING = y. STRINGf.0RIGINAL-ADDRESS = y. ORIGINAL-ADDRESSif y. DEF INED?= 1 then{;; if y is defined, just return yf.DEFINED?
= 1f.DEFINITION = y.
DEFINITION}if x. STR ING= y.
STRING then{; ;  if words are"the same, take;; any definition that x may havef.DEFINED?
= x.
DEFINED?f.DEFINITION = x?DEFINITIDN}elsee lse;; no definition yetf.DEFINED?
= 0; ;  note  that  text  words  that  a re  not  found in  the; ;  d i c t ionary  cor rec t ly  end  up w i th  DEFINED?
= OThis function F will spread dictionary definitionsfrom a definition to all of the words following it (inprocessor address order), up until the next dictionaryword.
Therefore, each word will have its own copy ofthe dictionary definition of that word.
All that remainsis to have a single routing cycle that sends each def-inition back to the original location of its text word.?
Figure 6 illustrates the execution of the entire sort-scanalgorithm on a sample sentence.132Figure 6.
Illuswation of Sort-Scan AlgorithmFormal of Processor Diagram: J Sttmn.
Dr~o~nr ~J Oefmea?
D Definition Bits: BBB8 Black ~ Selected: OriginaYAddress: Na.
Both the dictionary words and the text words are stored in the CM:I I L  II IText Dictionaryb.
Peform an alphabetic sort: (Merge dictionary into text)c. Scan using\] the F described in the  text:Definition Definitionnot used not in dictionarySend definition back to original addressI i lText I Dictionary8.4  Improvements  to  the  Sor t -Scan  D ic -t ionary  A lgor i thmSince the CM is a bit serial Machine, string operationsare relatively expensive operation.
The dictionary func-tion F described above performs a string comparisonand a string copy operation each time it is invoked.
Ona full size CM, the function is invoked 16 times (log64K words).
A simple optimization can be made to thesort-scan algorithm that allows the string comparisonto be performed only once.
This allows a faster dictio-nary function that performs no string comparisons to beused.The optimization consists of two parts.
First, a newstage is inserted after the sorting step, before the scan-ning step.
In this new step, each word is compared tothe word to its left, and if it is different, it is marked asa "header."
Such words begin a new segment of iden-tical words.
All dictionary words are headers, becausethe sort places them before all occurrences of identicalwords.
In addition, the first word of each group of wordsthat does not occur in the dictionary is also marked asa header.Next, the following function creates the field thatwill be scanned:;; header-p is a parallel boolean variable that is;.
; true in headers, false otherwisefunction create-field-for-scan(header-p):;define a type for a large bit fieldvat FIELD : record;;most significant b i ts  contain; ;p rocessor  addressADDRESS;;least significant bits will;;contain the definitionDEFINITIONend;initialize to  address O, no definitionFIELD.ADDRESS = OFIELD.DEFINITION = O; next, the headers that are dictionary words store;; their definitions in the correct part of FIELD;; Non-dictionary headers (text words not found;; in dictionary) are given null definitions.i f  header{FIELD.DEFINITION = definition; ;  se l f -address  conta ins  each processor \ ' s; ;  own un ique  addressFIELD.ADDRESS = self-address}return(FIELD)Finally, instead of scanning the dictionary functionacross this field, the maximum function (which returnsthe maximum of two input numbers) is scanned acrossit.
Definitions will propagate from a header to all ofthe words within its segment, but they will not crosspast the next header.
This is because the next headerhas a greater self-address in the most significant bitsof the field being scanned, and the maximum functionselects it rather than the earlier headerg smaller fieldvalue.
If a header had no definition, because a word wasnot found in the dictionary, the null definition would bepropagated to all copies of that word.The process of scanning the maximum function acrossa field was determined to be generally useful.
As a re-sult, the max-scan function was implemented in an effi-cient pipelined, bit-serial manner by Guy Blelloch, andwas incorporated into the general ibrary of CM func-tions.133Figure 7.
I \ [ lu~n ot tmprovemenls ~ Soot-Scan Algo~flma.
After sort, detect the headers (words different from lef~ neighbor)b.
In headers only, set the A to the self address and the D to thedefinition, if there is one.c.
Scan the Maximum function across the A:D field.d.
Copy definition bits from D to B, and set D?
if defined.Etc.Figure 7 illustrates the creation of this field, and thescanning of the maximum function across it.
Note thatthe size of the field being scanned is the size of the def-inition (8 bits for the timings below) plus the size of aprocessor address (16 bits).
In comparison, the earlierdictionary function had to be scanned across the def-inition and the original address, along with the entirestring.
Scanning this much larger field, even if the dic-tionary function was as fast as the maximum function,would necessarily result in slower execution times.8 .5  Eva luat ion  o f  the  Sor t -Scan  D ic t io -nary  A lgor i thmThe improved sort-scan dictionary algorithm is muchmore efficient han the broadcasting algorithms describedearlier.
The algorithm was implemented and timed ona Connection Machine.In a bit-serial computer like the CM, the time neededto process astring grows linearly with the number of bitsused to store the string.
A string length of 8 charactersis adequete for the CM-Indexer.
Words longer than 8characters are represented by the simple concatenationof their first 4 and last 4 characters.
ASCII characterstherefore require 64 bits per word in the CM; 4 morebits are used for a length count.Because dictionary lookup is only performed on al-phabetic haracters, the 64 bits of ASCII data describedabove can be compacted without collision.
Each of thetwenty-six letters of the alphabet can be representedusing 5 bits, instead of 8, thereby reducing the lengthof the character field to 40 bits; 4 bits are still neededfor the length count.
Additional compression could beachieved, perhaps by hashing, although that would in-troduce the possibilitY of collisions.
No additional com-pression is performed in the prototype implementation.The timings given below assume that each processorstores an 8 character word using 44 bits.First of all, to sort a bit field in the CM currentlytakes about 1.5 milliseconds per bit.
Second, the func-tion that finds the header words was timed and tookless than 4 milliseconds to execute.
The scan of themax function across all of the processors completed inunder in 2 milliseconds.
The routing cycle to return thedefinitions to the original processors of the text tookapproximately one millisecond to complete.As a result, with the improved sort-scan algorithm,an entire machine full of 64,000 words can be lookedup in about 73 milliseconds.
In comparison to this, theoriginal sort-scan implementation requires an additional32 milliseconds (2milliseconds per invocation of the slowdictionary function), along with a few more millisecondsfor the inefficient communications pattern it requires.This lookup rate is approximately equivalent to aserial dictionary lookup of .9 words per microsecond.In comparison, a Symbolics Lisp Machine can look upwords at a rate of 1/500 words per microsecond.
(Thetiming was made for a lookup of a single bit of infor-mation about a word in a hash table containing 1500words).
Thus, the CM can perform dictionary lookupabout 450 times faster than the Lisp Machine.8 .6  Cop ing  w i th  L imi ted  Processor  Re-sourcesSince there are obviously more than 64,000 words in theEnglish language, a dictionary containing many wordswill have to be handled in sections.
Each dictionary pro-cessor will have to hold several dictionary words, andthe look-up cycle will have to be repeated several times.These adjustments will slow the CM down by a multi-plicative factor, but Lisp Machines also slow down whenlarge hash tables (often paged out to disk) are queried.There is an alternative way to view the above algo-rithm modifications: ince they are motivated by limitedprocessor esources, they should be handled by somesort of run time package, just as virtual memory is usedto handle the problem of limited physical memory re-sources on serial machines.
In fact, a virtual processorfacility is currently being used on the CM.1349 Further Appl icat ions of Scanto Bulk Processing of TextThe scan algorithm has many other applications in textprocessing.
For example, it can be used to lexicallyparse text in the form of 1 character per processor intothe form of 1 word per processor.
Syntactic rules couldrapidly determine which characters begin and end words.Scan could then be used to enumeral:e how many wordsthere are, and what position each character occupieswithin its word.
The processors could then use this in-formation to send their characters to the word-processorat which they belong.
Each word-processor would re-ceive the characters making up its word and would as-semble them into a string.Another application of scan, suggested by Guy L.Steele, Jr., would be as a regular expression parser, orlexer.
Each word in the CM is viewed as a transitionmatrix from one set of finite automata states to anotherset.
Scan is used, along with an F which would havethe effect of composing transition matrices, to apply afinite automata to many sentences in parallel.
After thisapplication of scan, the last word in each sentence con-tains the state that a finite automata parsing the stringwould reach.
The lexer's state transition function Fwould be associative, since string concatenation is asso-ciative, and the purpose of a lexer is to discover whichparticular strings/tokens were concatenated to create agiven string/file.The experience of actually implementing parallel nat-ural language programs on real hardware has clarifiedwhich operations and programming techniques are themost efficient and useful.
Programs that build upongeneral algorithms uch as sort and scan are far, easierto debug than programs that attempt a direct assault ona problem (i.e.
the hashing scheme discussed earlier; ora slow, hand-coded regular expression parser that I im-plemented).
Despite their ease of implementation, pro-grams based upon generally useful submodules often aremore efficient han specialized, hand-coded programs.AcknowledgementsI would like to thank Dr. David Waltz for his help in thisresearch and in reviewing a draft of this paper.
I wouldalso like to thank Dr. Stephen Omohundro, Cliff Lasser,and Guy Blelloch for their suggestions concerning theimplementation of the dictionary algorithm.ReferencesAkl, Selim G. Parallel Sorting Algorithms, 1985, Aca-demic Press, Inc.Feynman, Carl Richard, and Guy L. Steele Jr. Connec-tion Machine Maeroinstruction Set, REL 2.8, ThinkingMachines Corporation.
(to appear)Hillis, W. Daniel.
The Connection Machine, 1985, TheMIT Press, Cambridge, MA.Lasser, Clifford A., and Stephen M. Omohundro.
TheEssential *Lisp Manual, Thinking Machines Corpora-tion.
(to appear)Leiserson, Charles, and Bruce Maggs.
"Communication-Efficient Parallel Graph Algorithms," Laboratory forComputer Science, Massachusetts Institute of Technol-ogy.
(to appear) (Note: scan is a special case of thetreefix algorithm described in this paper.
)Omohundro, Steven M. "A Connection Machine Algo-rithms Primer," Thinking Machines Corporation.
(toappear)Resnikoff, Howard.
The Illusion of Reality, 1985, inpreparation.Waltz, David L. and Jordan B. Pollack.
"Massively Par-allel Parsing: A Strongly Interactive Model of NaturalLanguage Interpretation," Cognitive Science, Volume 9,Number 1, pp.
51-74, January-March, 1985.135
