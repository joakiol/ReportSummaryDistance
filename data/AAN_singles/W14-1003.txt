Proceedings of the 3rd Workshop on Hybrid Approaches to Translation (HyTra) @ EACL 2014, pages 7?14,Gothenburg, Sweden, April 27, 2014. c?2014 Association for Computational LinguisticsComparing CRF and template-matching in phrasing tasks within aHybrid MT systemGeorge TambouratzisILSP/Athena Res.
Centre6 Artemidos & Epidavrou,Paradissos Amaroussiou,Athens, GR-15125, Greece.giorg_t@ilsp.grAbstractThe present article focuses on improvingthe performance of a hybrid MachineTranslation (MT) system, namely PRE-SEMT.
The PRESEMT methodology isreadily portable to new language pairs,and allows the creation of MT systemswith minimal reliance on expensive re-sources.
PRESEMT is phrase-based anduses a small parallel corpus from whichto extract structural transformations fromthe source language (SL) to the targetlanguage (TL).
On the other hand, the TLlanguage model is extracted from largemonolingual corpora.
This article exam-ines the task of maximising the amountof information extracted from a very lim-ited parallel corpus.
Hence, emphasis isplaced on the module that learns to seg-ment into phrases arbitrary input text inSL, by extrapolating information from alimited-size parsed TL text, alleviatingthe need for an SL parser.
An establishedmethod based on Conditional RandomFields (CRF) is compared here to a muchsimpler template-matching algorithm todetermine the most suitable approach forextracting an accurate model.
Experimen-tal results indicate that for a limited-sizetraining set, template-matching generatesa superior model leading to higher qual-ity translations.1 IntroductionMost current MT systems translate sentences byoperating at a sub-sentential level on parallel cor-pora.
However, this frequently necessitates pars-ers for both SL and TL, which either (i) developmatched segmentations that give similar outputsin terms of phrasing over the SL and TL or (ii)for which a mapping is externally defined be-tween the two given segmentations.
Both alterna-tives limit portability to new languages, due tothe need for matching the appropriate tools.
An-other limitation involves the amount of paralleltexts needed.
Statistical MT (SMT) (Koehn,2010) generates high quality translations pro-vided that large parallel corpora (of millions ofwords) are available.
However, this places astrict constraint on the volume of data required tocreate a functioning MT system.
For this reason,a number of researchers involved in SMT haverecently investigated the extraction of informa-tion from monolingual corpora, including lexicaltranslation probabilities (Klementiev et al., 2012)and topic-specific information (Su et al., 2012).A related direction in MT research concernshybrid MT (HMT), where principles from multi-ple MT paradigms are combined, such as for in-stance SMT and RBMT (Rule-based MT).
HMTaims to combine the paradigms?
positive aspectsto achieve higher translation accuracy.
Wu (2009)has studied the trend of convergence of MT re-search towards hybrid systems.
Quirk et al.
(2007) have proposed an HMT system wherestatistical principles are combined with Example-Based MT (EBMT) to improve the performanceof SMT.The PRESEMT (www.presemt.eu) methodol-ogy (Tambouratzis et.
al, 2013) supports rapid7development of hybrid MT systems for new lan-guage pairs.
The hybrid nature of PRESEMTarises from the use of data-driven pattern recog-nition algorithms that combine EBMT tech-niques with statistical principles when modellingthe target language.
PRESEMT utilises a verysmall parallel corpus of a few hundred sentences,together with a large TL monolingual one to de-termine the translation.
The MT process encom-passes three stages:Stage 1: this pre-processes the input sentence,by tagging and lemmatising tokens and groupingthese tokens into phrases, preparing the actualtranslation.Stage 2: this comprises the main translationengine, which in turn is divided into two phases:Phase A: the establishment of the transla-tion structure in terms of phrase order;Phase B: the definition of word order andthe resolution of lexical ambiguities at an in-tra-phrase level.Stage 3: post-processing, where the appropri-ate tokens are generated from lemmas.In terms of resources, PRESEMT requires:(i) a bilingual lemma dictionary providingSL to TL lexical correspondences,(ii) an extensive TL monolingual corpus,compiled via web crawling to generate a lan-guage model,(iii) a very small bilingual corpus.The bilingual corpus provides examples of thestructural transformation from SL to TL.
In com-parison to SMT, the use of a small corpus re-duces substantially the need for locating parallelcorpora, whose procurement or development canbe extremely expensive.
Instead, a small parallelcorpus can be assembled with limited recourse tocostly human resources.
The small size of theparallel corpus unavoidably places additionalrequirements on the processing accuracy in orderto extract the necessary information.
The maintask studied here is to extract from a parallel cor-pus of 200 sentences appropriate structural in-formation to describe the transformation from SLto TL.
More specifically, a module needs to betrained to transfer a given TL phrasing scheme toSL, so that during translation the module seg-ments arbitrary input text into phrases in a man-ner compatible to the TL phrasing scheme.
Thequestion then is which method succeeds in ex-tracting from the parallel corpus the most accu-rate structural knowledge, to support an effectiveMT system.For transferring a TL phrasing scheme into SL,PRESEMT relies on word and phrase alignmentof the parallel corpus.
This alignment allows theextrapolation of a model that segments the SLtext.
The SL?side segmentation is limited tophrase identification, rather than a detailed syn-tactic analysis.The processing of a bilingual corpus and theelicitation of the corresponding SL-to-TL phras-ing information involves two PRESEMT mod-ules:(i) The Phrase aligner module (PAM), whichperforms text alignment at word and phrase levelwithin the parallel corpus.
This language-independent method identifies correspondingterms within the SL and TL sides of each sen-tence, and aligns the words between the two lan-guages, while at the same time creating phrasesfor the non-parsed side of the corpus (Sofi-anopoulos et al., 2012).
(ii) The Phrasing model generator (PMG),which elicits a phrasing model from this alignedparallel corpus.
PMG is trained on the alignedparallel SL ?
TL sentences incorporating thePAM output to generate a phrasing model.
Thismodel is then employed to segment user-specified text during translation.A number of studies relevant to this article in-volve the transfer of phrasing schemes from onelanguage to another.
These studies have focussedon extrapolating information from a resource-rich to a resource-poor language.
Yarowski et al.
(2001) have used automatically word-alignedraw bilingual corpora to project annotations.
Ochand Ney (2004) use a two-stage process via adynamic programming-type algorithm for align-ing SL and TL tokens.
Simard et al.
(2005) pro-pose a more advanced approach allowing non-contiguous phrases, to cover additional linguisticphenomena.
Hwa et al.
(2005) have created aparser for a new language based on a set of paral-lel sentences together with a parser in a fre-quently-used language, by transferring deepersyntactic structure and introducing fix-up rules.Smith et al.
(2009) create a TL dependencyparser by using bilingual text, a parser, andautomatically-derived word alignments.2 Basic functionality & design of phras-ing model generatorThe default PMG implementation (Tambouratziset al., 2011) adopts the CRF model (Lafferty atel., 2001, Wallach, 2004) to chunk each input8sentence into phrases.
Earlier comparative ex-periments have established that CRF results in ahigher accuracy of phrase detection than bothprobabilistic models (such as HMMs) and smallparsers with manually-defined parsing rules.CRF has been used by several researchers forcreating parsers (for instance Sha and Pereira,2003, Tsuruoka et al., 2009).Due to the expressiveness of the underlyingmathematical model, CRF requires a large num-ber of training patterns to extract an accuratemodel.
Of course, the volume of training patternsis directly dependent on the size of the parallelcorpus available.
A more accurate CRF wouldrequire the use of a large parallel corpus, thoughthis would compromise the portability to newlanguage pairs.
Even by moving from handlinglemmas/tokens to part-of-speech tags when train-ing the parser, to reduce the pattern space, it ishard to model accurately all possible phrasetypes via CRF (in particular for rarer PoS tags)via the small corpus.
On the contrary, a lowercomplexity PMG model (hereafter termed PMG-simple) may well be better suited to this data.The work presented here is aimed at investigat-ing whether a simpler PMG model can processmore effectively this limited-size parallel corpusof circa 200 parallel sentences.3 Detailed description of PMG-simple3.1 PMG-simple PrinciplesPMG-simple follows a learn-by-example concept,where, based on the appearance of phrase pat-terns, the system learns phrases that match ex-actly patterns it has previously encountered.
Thisapproach is based on the widely-used template-matching algorithm (Duda et al., 2001), wherethe aim is to match part of the input sentence to aknown phrase archetype.
PMG-simple (i) doesnot generate an elaborate high-order statisticalmodel for segmentation into phrases taking intoaccount preceding and ensuing tag sequences,and (ii) cannot revise decisions so as to reach aglobal optimum.
Instead, PMG-simple imple-ments a greedy search algorithm (Black, 2005),using an ordered list of known phrases.
Due to itssimple design, it suffers a number of potentialdisadvantages in comparison to CRF-type ap-proaches:?
PMG-simple only identifies exactmatches to specific patterns it has previouslyseen (with some exceptions, as discussed below).On the contrary, more sophisticated approachesmay extrapolate new knowledge.
For example,let us assume that ?Aj?, ?At?
and ?No?
representPoS tags for adjectives, articles and nouns re-spectively, while ?Ac?
indicates the accusativecase.
Then, if noun phrases (NP) [AjAc; AjAc;NoAc] and [AtAc; AjAc; NoAc] are seen intraining, the unseen pattern [AtAc; AjAc; AjAc;NoAc] may be identified as a valid NP by CRFbut not by PMG-simple.?
PMG-simple does not take into accountthe wider phrase environment in its decision.?
PMG-simple, as a greedy algorithm,does not back-track over earlier decisions andthus may settle to sub-optimal solutions.Conversely, PMG-simple has the followingadvantages:?
As it relies on a simple learn-by-exampleprocess, all segmentation decisions are easilyexplainable, in contrast to CRF.?
The template-matching model is trainedand operates much faster than CRF.?
Finally, modifications can be integratedto improve the base algorithm generalisation.These largely consist of incorporating linguisticknowledge to allow the template-matching ap-proach to improve language coverage and thusaddress specific problems caused by the limitedtraining data.3.2 PMG-simple StepsPMG-simple receives as input the SL-sidesentences of a bilingual corpus, segmented intophrases.
Processing consists of four main steps:?
Step 1-Accumulate & count: Each sen-tence of the bilingual corpus is scanned in turn,using the phrases of the SL-side as training pat-terns.
More specifically, all SL-side occurringphrases are recorded in a phrase table togetherwith their frequency-of-occurrence in the corpus.?
Step 2-Order: The table is ordered, basedon an ordering criterion so that phrases with ahigher likelihood of correct detection are placednearer the top of the phrase table.
As a conse-quence, matches are initially sought for thesephrases.?
Step 3-Generalise: Recorded phrases aregeneralised, to increase the phrase table cover-age.
Thus, new valid templates are incorporatedin the phrase table, which are missing from thelimited-size training corpus.
Currently, generali-9sation involves extending phrases for which alldeclinable words have the same case, to othercases.
For instance, if NP [AtAc; AjAc; NoAc],with all tokens in accusative exists in the phrasetable with a given score, NPs are also created fornominative, genitive and vocative cases ([AtNm;AjNm; NoNm] [AtGe; AjGe; NoGe] and [AtVo;AjVo; NoVo]), with the same score.?
Step 4-Remove: Phrases containing pat-terns which are grammatically incorrect are re-moved from the phrase table.
As an example ofthis step, phrases involving mixed cases are re-moved in the present implementation.Steps 3 and 4 allow the incorporation of lan-guage-specific knowledge to enhance the opera-tion of PMG-simple.
However, in the experi-ments reported in the present article, only limitedknowledge has been introduced, to evaluate howeffective this phrasing model is in a setup wherethe system is not provided with large amounts oflinguistic knowledge.
It is expected that by pro-viding more language-specific knowledge, thephrasing accuracy can be further increased overthe results reported here.When PMG-simple is trained, it is likely thatsome phrase boundaries are erroneously identi-fied in the training data.
The likelihood of suchan event is non-negligible as phrases are auto-matically transferred using the alignment algo-rithm from the TL-side to the SL-side.
Errorsmay be attributed to limited lexicon coverage oronly partial correspondence of SL-to-TL text.However, as a rule such errors can be expected tocorrespond mainly to infrequent phrases.A mechanism for screening such errors hasbeen introduced in PMG-simple.
This is imple-mented as a threshold imposed on the number ofoccurrences of a phrase within the training cor-pus, normalised over the occurrences in the en-tire corpus of the phrase tag sequence.
Thus,phrases identified very rarely in comparison tothe occurrences of their respective tag sequenceare penalised as unreliable.
They are retained inthe phrase table, but are demoted to much lowerpositions.
This processing of the phrase table isperformed after Step 4 and represents the op-tional final step (Step 5) of PMG-simple.3.3 Ordering CriteriaThe choice of template-ordering criterion dic-tates the order in which phrases are matched tothe input text.
Since PMG-simple performs nobacktracking, the actual ordering affects thesegmentation accuracy substantially.
A variety ofdifferent criteria have been investigated for es-tablishing the order of precedence with whichphrases are searched for.
Out of these, only aselection is presented here due to space restric-tions, focussing on the most effective criteria.These are depicted in Table 1.crit.1 If phrase_freq ?
freq_thres :Crit1 = {[(1000*(phrase_freq/tagseq_occur) + phrase_len*250] }If phrase_freq < freq_thres:Crit1 =  {[phrase_len *10] }crit.2 If phrase_freq ?
freq_thres :Crit2 ={(phrase_freq[p_index]) +phrase_len*10000}If phrase_freq < freq_thres:Crit2 = {phrase_len *10+floor(100*phrase_freq/ tagseq_occur)}crit.3 If phrase_freq ?
freq_thres :Crit3 = {phrase_freq +phrase_len*1000}If phrase_freq < freq_thres:Crit3 ={phrase_len +phrase_freq/tagseq_occur}crit.4 If phrase_freq ?
freq_thres :Crit4 = max {phrase_subfreq +phrase_len*100 }If phrase_freq < freq_thres:Crit4 = {phrase_len +phrase_subfreq/tagseq_occur}Table 1: Definitions of phrase-ordering criteria.Basically, the information according to whichphrases may be ordered in the phrase table con-sists of two types, (i) the frequency of occurrenceof a given phrase in the training corpus (denotedas phrase_freq) and (ii) the phrase length interms of tokens (denoted as phrase_len).
Bycombining these two sources of information, dif-ferent criteria are determined.
Parametertagseq_occur corresponds to the number of oc-currences of the phrase tag sequence within thetraining corpus.
Finally phrase_subfreq is equalto the occurrences of a tag sequence as either an10entire phrase or as a sub-part of a larger phrase.This takes into account in the frequency calcula-tions the instances of phrases which in turn areencapsulated within larger phrases, and is themain point of difference between criteria crit3and crit4.To summarise a series of earlier experimentsinvolving different criteria, criteria using onlyone source of information prove to be less effec-tive.
Also, criteria using non-linear combinationsof information types (i) and (ii) have been shownto be less effective and are not reported here.
Allcriteria studied in the present article combine thetwo aforementioned types of information in aweighted sum, but using different multiplicationfactors to emphasise one information type overthe other.
The actual factors may of course befurther optimised, as the values reported in Table1 are chosen to differ in terms of order of magni-tude.All criteria reported here implement Step 5, byhaving a secondary formulation when the occur-rences of a phrase fall below a threshold (pa-rameter freq_thres).
This results in assigning alower priority to very infrequent phrases.A mechanism has also been introduced for theproper handling of tokens with very infrequentpart-of-speech (PoS) tags, which typically have arate-of-appearance of less than 0.5% in the cor-pus.
For such tags, the likelihood of appearing inthe 200 parallel sentences is very low.
Hence, inorder to split them appropriately into phraseswhen they appear in input sentences, equivalenceclasses have been defined.
A limited number ofPoS equivalences are used, namely (i) abbrevia-tions and foreign words are considered equiva-lent to nouns, (ii) numerals are consideredequivalent to adjectives and (iii) pronouns areconsidered equivalent to nouns.
This informationis inserted in Step 3 of the phrase-ordering algo-rithm, allowing the generation of the appropriatephrases.
Though the improvement in translationaccuracy by introducing these PoS equivalencesis not spectacular (no more than 0.005 BLEUpoints) this generalisation information allows theappropriate handling of unseen tag sequencesduring translation, leading to a more robustphrasing method.It should be noted here that a non-greedy vari-ant of PMG-simple has also been examined.
Thiswas expected to be more effective, since it ex-tends the template matching approach to takeinto account a sentence-wide context.
However,it has turned out that the complexity of the non-greedy approach is too high.
By introducingbacktracking, it becomes extremely expensivecomputationally to run this method for sentenceslarger than 12 tokens without a substantial prun-ing of the search space.4 Experimental setup and results4.1 Experiment DefinitionTo evaluate the proposed phrasing generator, theoutput of the entire translation chain up to thefinal translation result is studied.
This allows thecontribution of different PMG models to bequantified using objective metrics.
For thepurposes of the present article, the language pairGreek-to-English (denoted as EL?EN) isemployed.
Since the SL phrasing generated byPMG is based on the TL phrasing scheme, thephrase labels of the resulting SL phrases areinherited from the TL ones.
In the experimentsreported here (with English as TL), theTreeTagger parser (Schmid, 1994) is used.
Thusthe SL-side phrase types include PC, VC, ADVCand ADJC.
As TreeTagger also allows for certainwords (such as conjunctions) to remain outsidephrases, it is possible that isolated words occur inSL too.
For the purposes of modelling suchoccurrences, these words form single-tokenphrases, denoted as ISC (i.e.
ISolated wordChunk).Both the parallel corpus and the evaluationdataset employed here have been established inthe PRESEMT project, and are available over theweb (cf.
www.presemt.eu/data).
The parallelcorpus has been retrieved from the web (from anEU website discussing the history of the Union),with an average size of 18 words per sentence,while the smallest sentence comprises 4 wordsand the largest 38 words.
Only minimal editingwas performed in the parallel corpus, to ensureparallelism between SL and TL.
The evaluationset comprises 200 isolated sentences, each with asingle reference translation (Sofianopoulos et al.,2012).
These sentences have been drawn fromthe internet via web crawling, being required tohave a length of between 7 and 40 tokens each.4.2 Experimental Results for PMG-simpleTable 2 contains the translation accuracy resultsobtained with PMG-simple using the criteria ofTable 1.
In all experiments, the results concernthe objective evaluation of the final translation,using four of the most widely used objective11evaluation metrics, namely BLEU, NIST, TERand METEOR (NIST, 2002, Papineni et al., 2002& Snover et al., 2006).
For TER a lower valueindicates a more successful translation while forother metrics, a higher value corresponds to abetter translation.
Since other components of theMT implementation do not change, this set ofmetrics provides an accurate end-to-endmeasurement of the effect of the phrasing modelon the translation process.
As can be seen fromTable 2, all four criteria result in translations of acomparable accuracy.
For instance, the variationbetween the lowest and highest BLEU scores isapproximately 1%, while for the other metricsthis variation is even lower.Criterion BLEU NIST METEOR TERcrit 1(14/out79) 0.3643 7.3153 0.4009 48.486crit 2(16/out87) 0.3679 7.2991 0.4009 48.590crit 3(17out88) 0.3667 7.2937 0.4002 48.730crit 4(148out89) 0.3637 7.2730 0.3980 48.834Table 2: Translation accuracy for EL?EN, usingPMG-simple with various criteria.cut-offfreq.BLEU NIST METEOR TER0 0.3637 7.2730 0.3980 48.8341 0.3637 7.2730 0.3980 48.8342 0.3732 7.3511 0.4017 48.1383 0.3660 7.2911 0.4007 48.590Table 3: Translation scores for EL?EN, usingPMG-simple with criterion 4 and various cut-offfrequencies.A potential for optimisation concerns the cut-off frequency (freq_thres) below which a phraseis considered exceptionally infrequent and ishandled differently.
Indicative results are shownfor the four metrics studied in Table 3.
As can beseen, the best results are obtained with a cut-offfrequency of 2, for the given parallel corpus.
Ofcourse, this value is to an extent dependent onthe training set.
However, based on detailedanalyses of the experimental results, it has beenfound that phrases that represent hapax legomena(i.e.
phrases which occur only once) are notreliable for chunking purposes.
Here, there aretwo possible explanations: (i) either such phrasesrepresent spurious chunkings resulting fromerrors in the automatic alignment or (ii) theyrepresent very infrequent phrases which againshould not bias the phrasing processdisproportionately.
In both cases, the activationof the cut-off frequency improves the translationaccuracy.4.3 Comparison of PMG-simple to CRFOf course it is essential to examine how PMG-simple translation results compare to those ob-tained when PRESEMT is run with the standardCRF-based phrasing model.
These results areshown in Table 4.
As can be seen the optimalperformance of PMG-simple leads to an im-proved translation accuracy over the best CRF-based approach, with a rise of more than 6.2% inthe BLEU score.
Similarly, the improvementsobtained for NIST and Meteor by introducingPMG-simple in PRESEMT are 2.1% and 2.5%,respectively.
Finally, in the case of TER, forwhich a lower score reflects a better translation,the score is reduced by circa 3.3%.
Thus, basedon the results quoted in Table 3, the performanceof PMG-simple is superior to that of the CRF-based system for all four metrics reported.
Thehigher performance of PMG-simple is in agree-ment to the observation that - as recently re-ported for other applications (Mao at al., 2013) -improvements over the performance of CRF andSVM are possible by appropriately weighingtemplates.PMG BLEU NIST METEOR TERPMG-simple(crit.4)0.3732 7.3511 0.4017 48.138CRF  0.3513 7.1966 0.3919 49.774Table 4: Translation accuracy for EL?EN, usingPMG-simple with crit.4 and using CRF.To evaluate in more detail the results of Table4, a preliminary statistical analysis was per-formed.
More specifically, the scores in BLEU,NIST and TER for each of the 200 test sentenceswere collected.
For each of these metrics, apaired T-test was performed comparing themeasurements obtained with (i) PMG-simpleusing criterion crit.4 and (ii) CRF, over each sen-tence.
It was found that the difference in meansbetween the BLEU populations was indeed sta-tistically significant at a 0.05 level.
In the cases12of TER and NIST measurements, though, therewas no statistically significant difference in thetwo populations.5 ConclusionsPMG-simple has been proposed as a straightfor-ward implementation to derive a phrasing modelfor SL text, based on template-matching.
Thisoperates on the same aligned corpus as the de-fault CRF model, but is faster to train and has amore transparent operation.
The results of PMG-simple have been compared to those of CRF,using the final PRESEMT translation output togauge the phrasing effectiveness.
The best resultsfor PMG-simple are comfortably superior tothose of CRF for all MT objective metrics used.This indicates that PMG-simple has a sufficientlyhigh functionality.
Though the modelling powerof CRF is higher, the template-matching ap-proach of PMG-simple is better harmonised tothe amount of training data available.
ThusPMG-simple appears to be the phrase generatorof choice for PRESEMT.One point that warrants further experimenta-tion (currently under way) concerns the scaling-up effect of larger parallel corpora on the com-parative performance of the models.
Preliminaryresults with bilingual corpora of approximately500 sentences have shown that the performanceusing PMG-simple remains superior to that withCRF, resulting in a difference of approx 0.02 forBLEU (equivalent to a 5%-6% improvementover the CRF baseline).
In addition, PMG-simplehas been shown to perform better than CRFwhen applied to the latest versions of PRESEMT,which are currently being tested and lie beyondthe scope of this article.Another topic of interest is to determinewhether new improved criteria can be established.This is the subject of ongoing research.In addition, an open question is whether theconclusions of this study are applicable to otherthematic areas.
In other words, could an ap-proach such as PMG-simple be preferable toCRF in other applications involving relativelysparse data?
It appears from the results summa-rised here that this could indeed be the case,though this remains the subject of future research.AcknowledgementsThe author wishes to acknowledge the invaluablehelp of Ms. Marina Vassiliou and Dr. SokratisSofianopoulos, both of ILSP/Athena R.C., inintegrating PMG-simple within the PRESEMTprototype and performing a number of experi-ments.The research leading to these results has receivedfunding from the POLYTROPON project(KRIPIS-GSRT, MIS: 448306).ReferencesPaul E. Black.
2005.
Dictionary of Algorithms andData Structures.
U.S. National Institute of Stan-dards and Technology (NIST).Richard O. Duda, Peter E. Hart and David G. Stork.2001.
Pattern Classification (2nd edition).
WileyInterscience, New York, U.S.A.Rebecca Hwa, Philip Resnik, Amy Weinberg, ClaraCabezas and Okan Kolak.
2005.
Bootstrappingparsers via Syntactic Projections across ParallelTexts.
Natural Language Engineering, Vol.
11, pp.311-325.Alexandre Klementiev, Ann Irvine, Chris Callison-Burch and David Yarowsky.
2012.
Towards Statis-tical Machine Translation without Parallel Corpora.In Proceedings of EACL-2012 Conference, Avi-gnon, France, 23-25 April, pp.
130-140.Philip Koehn.
2010.
Statistical Machine Translation.Cambridge University Press, Cambridge.John Lafferty, Andrew McCallum, and FernandoPereira.
2001.
Conditional Random Fields: Prob-abilistic Models for Segmenting and Labelling Se-quence Data, In Proceedings of ICML Conference,June 28-July 1, Williamstown, USA, pp.
282-289.Qi Mao, and Ivor Wai-Hung Tsang.
2013.
EfficientMultitemplate Learning for Structured Production.IEEE Transactions on Neural Networks and Learn-ing Systems, Vol.
24, No.
2, pp.
248-261.NIST 2002.
Automatic Evaluation of Machine Trans-lation Quality Using n-gram Co-occurrences Statis-tics.Franz Josef Och and Hermann Ney.
2004.
The Align-ment Template Approach to Statistical MachineTranslation.
Computational Linguistics, Vol.
30,No.
4, pp.
417-449.Kishore Papineni, Salim Roukos, Todd Ward, andWei-Jing Zhu.
2002.
BLEU: A Method for Auto-matic Evaluation of Machine Translation.
Proceed-ings of the 40th ACL Meeting, Philadelphia, USA,pp.
311-318.Chris Quirk and Arul Menezes.
2006.
DependencyTreelet Translation: The convergence of statisticaland example-based machine translation?
MachineTranslation, Vol.
20, pp.
43?65.13Helmut Schmid.
1994.
Probabilistic Part-of-SpeechTagging Using Decision Trees.
In Proceedings ofInternational Conference on New Methods in Lan-guage Processing, Manchester, UK, pp.
44-49.Fei Sha and Fernando C. N. Pereira.
2003.
ShallowParsing with Conditional Random Fields.
In Pro-ceedings of HLT-NAACL Conference, pp.
213-220.Michel Simard, Nicola Cancedda, Bruno Cavestro,Marc Dymetman, Eric Gaussier, Cyril Goutte,Kenji Yamada, Philippe Langlais, and ArneMauser.
2005.
Translating with Non-ContiguousPhrases.
In Proceedings of the Conferences onHuman Language Technology and on EmpiricalMethods in Language Processing, Vancouver,Canada, pp.
755-762.Matthew Snover, Bonnie Dorr, Richard Schwartz,Linnea Micciulla, and John Makhoul.
2006.
AStudy of Translation Edit Rate with Targeted Hu-man Annotation.
Proceedings of the 7th Confer-ence of the Association for Machine Translation inthe Americas, Cambridge, Massachusetts, USA,pp.
223-231.Sokratis Sofianopoulos, Marina Vassiliou, andGeorge Tambouratzis.
2012.
Implementing a lan-guage-independent MT methodology.
In Proceed-ings of the First Workshop on Multilingual Model-ing, held within the ACL-2012 Conference, Jeju,Republic of  Korea, 13 July, pp.1-10.Jinsong Su, Hua Wu, Haifeng Wang, Yidong Chen,Xiaodong Shi, Huailin Dong and Qun Liu.
2012.Translation Model Adaptation for Statistical Ma-chine Translation with Monolingual Topic Infor-mation.
In Proceedings of the 50th ACL Meeting,Jeju, Republic of Korea, pp.
459-468.George Tambouratzis, Fotini Simistira, Sokratis Sofi-anopoulos, Nikolaos Tsimboukakis, and MarinaVassiliou.
2011.
A resource-light phrase schemefor language-portable MT.
In Proceedings of the15th EAMT Conference, 30-31 May, Leuven, Bel-gium, pp.
185-192.George Tambouratzis, Michalis Troullinos, SokratisSofianopoulos, and Marina Vassiliou.
2012.
Accu-rate phrase alignment in a bilingual corpus forEBMT systems.
In Proceedings of the 5th BUCCWorkshop, held within the LREC-2012 Confer-ence, May 26, Istanbul, Turkey, pp.
104-111.George Tambouratzis, Sokratis Sofianopoulos, andMarina Vassiliou (2013) Language-independenthybrid MT with PRESEMT.
In Proceedings ofHYTRA-2013 Workshop, held within the ACL-2013 Conference, Sofia, Bulgaria, 8 August, pp.123-130.Yoshimasa Tsuruoka, Jun?ichi Tsujii and SophiaAnaniadou.
2009.
Fast Full Parsing by Linear-Chain Conditional Random Fields.
In Proceedingsof the 12th EACL Conference, Athens, Greece, 30March-3 April, pp.
790?798.Hanna M. Wallach.
2004.
Conditional RandomFields: An Introduction.
CIS Technical Report,MS-CIS-04-21.
24 February, University of Penn-sylvania.Dekai Wu.
2009.
Toward machine translation withstatistics and syntax and semantics.
In Proceedingsof the IEEE Workshop on Automatic Speech Rec-ognition & Understanding, 13-17 November, Mer-ano, Italy, pp.
12-21.David Yarowsky and Grace Ngai.
2001.
InducingMultilingual POS Taggers and NP Bracketers viaRobust Projection across Aligned Corpora.
InNAACL-2001 Conference Proceedings, pp.
200-207.14
