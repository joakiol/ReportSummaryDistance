PROSODY AND PARSINGP.
J. Pricet M. Ostendorf~ C.W.
Wightman~tSPd International ~Boston UniversityABSTRACTWe address the role of prosody as a potential information source for the assignment of syntactic structure.We consider the perceptual role of prosody in marking syntactic breaks of various kinds for human listeners,the automatic extraction of prosodic information, and its correlation with perceptual data.INTRODUCTIONProsodic information can mark lexical stress, identify phrasing breaks, and provide information useful forsemantic interpretation.
Each of these aspects of prosody can benefit a spoken language system (SLS).
Weconcentrate in this report on the use of prosody in parsing, through perceptual studies and through modelingthe correlation of duration patterns with stress patterns and with syntactic structures.It is rare that prosody alone disambiguates otherwise phonetically identical phrases.
However, it is alsorare that any one source of information (spectral or temporal) is the so/e feature that separates one phrasefrom all competitors.
We argue here that prosody can provide information useful to a parser.
TAkingadvantage of this information in parsing can make a spoken language system more accurate and moreefficient, if prosodic-syntactic mlnmatches, or unlikely matches, can be pruned out.
There is a vast literatureon the perception and production of prosodic information.
Our goal is to show that at least some of thisinformation can be automatically extracted and used to improve speech recognition and understanding.Figure represents a strategy for using prosody to improve speech understanding.
Prosodic featuresextracted from speech will be analysed by the prosody module which will communicate both with thespeech recognition component and with the language processin 8 component.
For example, phone durationsfrom the speech recognition module can be used by the prosodic module to hypothesise stress patterns andprosodic structure, which in turn can be checked in the speech recognition component for consistency withthe dictionary's lexical stress patterns and with the application of phonological rules in the hypothesizedword strings.
SimilArly, the consistency of syntactic, semantic and discourse structures from the languageprocessing component can be verified against he prosodic structures hypothesized.The complete integration of the prosodic module with speech and language components i  an ambitiousgoal.
Our strategy for atts~nin S this goal is to 1) assess the potential of various types of prosodic informationthrough perceptual experiments and thzough analysis of recognition and parsing errors, 2) for those aspectsof prosody that appear to have the greatest potential, develop computational models using linguistic theoryto help determine the units and structure of the models, and using statistical models to help account forvariability and to allow for automatic training, and 3) evaluate the models and algorithms by comparing themodel's output with hud  labels, by comparing human discrimination with the system's performance, andby assessing the accuracy and speed of an SLS with and without the prosodic module.
We report here on ourinitial experiments involving a) the perception of various types of syntactic structures marked by prosody,b) the coding of prosodic information for parsing, and c) the automatic labeling of prosodic structures.PERCEPTUAL EXPERIMENTSProsodic structure and syntactic structures are not, of course, completely identical.
Rhythmic structures andthe necessity of breathing influence the prosodic structure, but not the syntactic structure (Gee and Grosjean) word i candi ates ~SPEECH Speech, 1 ~L, Recognition J_ / /Prosody 1Language Processing \]Figare 1: Prosody in Speech Understanding1983, Cooper and Paccia-Cooper 1980 ).
Further, there are likely some types of syntactic structures that arenot typically marked prosodicslly.
In order to help focus our study on syntactic structures that correlate wellwith prosody, we designed a perceptual experiment involving phonetically-ambiguous, structurally-differentpairs of sentences.The sentence pairs were read by a professional radio announcer in disambiguating contexts.
In orderto discourage unnatural exaggerations of any differences between sentences, the materials were recorded indifferent sessions with several days in between.
In each session only one sentence of each pair occurred.Sixteen listeners heard the sentences without he dissmbiguatlng contexts and were asked to select whichcontext on the answer sheet was more likely for the sentence heard.
Listeners were also asked to put a checknext to contexts for which they were particularly confident of their judgments.
The listeners were all nativespeakers of English , naive with respect o the purpose of the study.
Again, two different listening sessionswith several weeks in between were used, and only one member of each sentence pair occurred in the samesession.Seven types of structural ambignity were investigated: 1)parentheticals, 2) apposition, 3) main-main vs.main subordinate clauses, 4) tags, 5) near vs. far attachment, 8) left vs. right attachment, and 7) particlesvs.
prepositions.
Each type of ambignity was represented by five pairs of sentences.
We list a samplefrom each class with their disambigusting contexts in the Appendix.
In each case, the "s" member of thesentence-pairs has st least one location with s mote major break than the corresponding location in the "b"version.The results in Table 1 show that, on the average, subjects did well above chance (86% correct) inassigning the sentences to their appropriate contexts, although subjects were confident of their judgmentsonly about 58% of the time.
In general, the sentences with the more major breaks ("a" versions) were morereliably identified (90% sccurate) compared to the "b" versions (83% accurate), though this difference didnot correspond to s difference in the subjects' confidence.
This suggests that breaks that are strongly markedprosodically may be relatively unambiguous, whereas locations where no break information is observed shouldnot rule out the possihility that a prosodically unmarked syntactic break may exist.The subjects were least able to identify the main-main vs. main-subordinate pairs (77% accurate, 41%Table 1: Perceptual experiment results for ambiguous sentence interpretation.Ambiguity1.
Parenthetical2.
Apposition3.
M-M VS. M-S4.
Tags5.
Nearlfar attach.6.
Leftlright attach.7.
Particle/Prep.Averageconfident) and the near vs. far attachment pairs (79% accurate, 38% confident), and were best at  the a pposition pairs (94% accurate, 75% confident) and the left vs. right attachment pairs (94% accurate, 74%confident).
The table alno indicates differences related to the "an and "bn versions by structural category.
Be-cause of significant differences across sentences even within a structural category, more perceptual judgmentsand productions of the same sentences by different speakers are required to assess these differences.Of particular interest for database query tasks are categories 3, 5, 6 and 7 (parenthetical expressions,apposition and tags may be rare in database queries).
These categories cover the range of observed accu-racies from worst to best.
We plan to concentrate in the future on prepositional phrases.
Prepositions arevery frequent (about 75% of the Resource Management sentences (Price et d. 1988 ) have one or moreprepositional phrases), and nearly all sentences with prepositional phrases are syntactically ambiguous.
Theperceptual results indicate that it may be possible to help resolve syntactic ambiguity on the basis of prosodicinformation.
One can expect structural ambiguity to pose even more of a problem for a parser when theinput is speech rather than text, because of the additional ambiguities of word identity and word boundaries.CODING PROSODIC INFORMATION FOR PARSINGA formalism has been devised for coding, or labeling, prosodic information in a form useful to a parser.Phrase boundary information M indicated by a "breakn index, a number which indicates by its relative sirethe degree of prosodic deeoupling of neighboring words.
The example below illustrates how phrase boundaryinformation can be used to distinguish particles and prepositions.a7aMarge 0 would 1 never 2 deal 0 in 2 any 0 guys 57b Marge 1 would 0 never 0 deal 3 in 0 any 0 guise 5% correct7198929882959190In addition, words with relatively high prominence can be marked with * (prominence) and ** (highprominence) following that word.
Another example illustrates that prominence information may providecues which disambiguate the sentences, even when phrase boundary information does not disambiguate thesentence.% confident4166507746705558b6a They 0 rose 2 early** 1 in 0 May 56b They 0 rose 2 early 1 in 0 May** 5% correct9391637875938483We found that we could reliably label these sentences with prominences and with break indices, with goodagreement within and across labelers.
In ten pairs of sentences examined from categories 5, 6, and 7, thesyntactic structures were all clearly disambiguated by the perceived (hand-labeled) phrase break indices in' % confident7372335 130776858total% correct8394778879948786% confident5975416538746 158all but one case.
The prominences u ually provided additional support for the syntactic structure, and in onecase ("they rose early in May") provided the sole support for disambiguation.
Because these initial resultswere encouraging, we began to search for acoustic orrelates of the perceptual results.AUTOMATIC  DETECT ION OF PROSODIC  CUESIn order to automatically abel phrase breaks, several sources of information will no doubt be useful, includingrelative duration, pausing phenomena, boundary tones and syntactic structure.
In our initial work, we haveinvestigated independent modeling and detection of these cues.
Later, the different algorithms will becombined in a statistical framework, for integration with the SRI spoken language system.
Algorithmsand experimental results for speaker-dependent de ection of breaks, lexical stress and boundary tones aredescribed here.
The results for the different algorithms are based on three databases - the ambiguoussentence database, a radio news story database, and the Resource Management database - according to thenature of the information being detected.
Other work in prosodic phrase "language modeling", based on adeterministic parser coupled with a Markov model, is described elsewhere (Veilleux eta/.
).Break LabelingOur main efforts have involved automatically generating break indices using phoneme duration, a verypowerful cue.
Phoneme durations were obtained from the SRI speaker-independent word recognition system(Weintraub eta/.
1980) by constraining the the recognizer so that the correct word sequence is recognized.The SRI recognition system is especially useful for this task, since the phonological rules allow for quite bushyword pronunciation networks.
This means that the alignments have a better chance of being highly accurate,and that the phonetic labels thus obtained can be used to independently assess the phonetic ambiguity ofthe sentences investigated.Word break indices were generated by normalizing phoneme duration according to estimated mean andvariance, and combining the average normalized uration factors of the final syllable coda consonants witha pause factor.
Let ~ : (d~ - pj)/o'j be the normalized uration of the ith phoneme in the coda, where/~j and o'j are the mesa and standard eviation of duration for phone j. d~, is the duration (in ms) of thepause following the word, if any.
A set of word break indices are computed for all the words in a sentenceas follows:= +  IT0I(The term d~/70 was actually hard-limited at 4, so as not to give pauses too much weight.)
The set .4 includesall coda consonants, but not the vowel nucleus unless the syllable nds in a vowel.
Although, the vowel nucleusprovides ome boundary cues, the lengthening associated with prominence can be confounded with boundarylengthening and the algorithm was slightly more reliable without using vowel nucleus information.
Theseindices n are normalized over the sentence, assuming known sentence boundaries, to range from zero to five.As an initial step in assessing the use of prosody in parsing, we have examined the differences betweenten of the phonetically ambiguous, minimal pair sentences described in the perceptual studies.
The ten pairsincluded the particle-preposition a d attachment smbignities.
These were chosen because these types ofambiguities seem to be relatively frequent in database queries.Word break indices were automatically generated using the algorithms described above, and the resultswere compared to perceptually abeled data.
In 19 of the 20 sentences, the largest automatically labeledbreak within a sentence occured at the location of the largest perceived break, which disambiguated thesentence.
In the other sentence, there was a large break (3 or 4) that correctly disambiguated the sentence,though not the largest break.
Hence, the duration model disambiguates sentences with 100% accuracy forthis small set.
The correlation coefficient between the hand-labeled break indices and the automaticallygenerated break indices is 0.85.Lexical Stress AssignmentDuration was also investigated as a cue for predicting lexicai stress.
Assuming known word segmentations,the lexical stress pattern for multi-syllabic words was estimated based on vowel durations normalized by awindow of three successive, neighboring vowels.
On a 25-sentence test set from the Resource Managementdatabase, this algorithm yielded 90% correct lexical stress pattern prediction.Breath  Detect ionFor speech that involves more than one sentence or long sentences, peakers typically take breaths.
Inaddition, breaths are highly correlated with major prosodic breaks.
We have studied the use of breaths inseveral minutes of radio news speech.
85% of sentence boundaries (break index 5) are marked by breathsand 53% of major phrase boundaries (break index 4) are also marked by breaths.
In addition, the acousticrealization of a breath is quite distinctive, indicating that a breath detection might provide a very reliablephrase break cue.A breath detection algorithm was developed based on a Gaussian classifier.
A fourteen-dimensional fullcovariance Gaussian distribution was estimated for cepstral features.
To compensate for session dependenteffects, the cepstral features were normalised by session mean and variance.
The classifier labeled successiveframes of speech according to a threshold chosen to constrain false detection rate.
A segment of speech waslabeled as a breath if 23 out of 25 sequential frames were labeled as "breath".The Gaussian distribution was estimated using data from three dilTerent 2-3 minute news stories (threesessions).
Separate data from the same stories was used to evaluate the algorithm.
The algorithm detected78 out of 83 breaths (93% correct detection) and inserted one breath.
The breaths labeled by the algorithmare within 50 ms of those labeled by hand 95% of the time.
In addition, the algorithm detected one breaththat was not detected perceptually by four listeners.Boundary  Tone  C lass i f i ca t ionBoundary tones are another important cue for phrase boundary detection and for semantic interpretation.The boundary tone study is based on a speaker-dependent radio news story database.The three news stories described above were perceptually abeled for two types of boundary tones atevery major phrase break: final fall and continuation rise.
A classifier for boundary tones in known finalphrase syllable locations was designed using hidden Markov models of intonation.
The classifier was based onearlier work with hidden Markov models of isolated intonation patterns (Butsberger, Ostendorf and Price).The classifier used as input only quantised F0 estimates.
Using a resubstitution error estimate, 76% of theboundary tones were correctly classified.
These results are encouraging because many of the boundary toneswere impossible to visually classify because of pitch tracking errors.CONCLUSIONSWe have shown through perceptual experiments hat several types of syntactic ambiguities can be resolvedwith prosodic information, we have developed a prosodic information codin 8 system suitable for a parser,and we have developed automatic algorithms for extraction of information that correlates well with perceivedprosodic phenomena.These initial results are very encouraging; we plan to test the algorithm on a larger set of sentencesby more talkers.
Changing from speech read by professional speakers to spontaneous speech from randomspeakers will no doubt require modification of the algorithms.
The next steps in this research will include I)further investigation of the relationship between prosody and syntax, including the different roles of phrasebreaks and prominences in marking syntactic structure; 2) improvement of the prosodic labeling algorithmby incorporating intonation and syntactic/semantic information; and 3) incorporating the automaticallylabeled information i  the parser of the SRI Spoken Language System (Moore, Pereira and Murveit 1989).We expect he prosodic information to resolve structural ambiguities, and also to increase the speed of theparser by eliminating prosodicaJJy inconsistent hypotheses.
The tighter the integration scheme between theacoustic information and the syntactic information, the more potential gain we can expect from prosody.AcknowledgementsThis work was supported jointly by NSF and DARPA under NSF grant number IRI-8905249.
There weresevers/other researchers involved in this effort.
The authors wish to thank Stefanie Shattuck-Hufnagel (MIT)for help with data collection and numerous conversations on prosody, John Butsberger (BU) for help withdata collection and boundary tone recognition, Cynthia Fong (BU) for help with the perceptual experiments,Hy Murveit (SRI) for help in generating the phoneme alignments, and John Bear (SRI) for work and insightson integration of prosodic information with a parser.References\[1\] J. Butsberger, M. Ostendorf, P. Price, "Isolated Intonation Recognition Using Hidden Markov Models,"submitted to the 1990 Inter.
Conf.
on Acoustics, Speech and Signal Processing.\[2\] Cooper, W. and J. Paccia-Cooper, Syntaz and Speech, Harvard University Press, Cambridge, MA, 1980.\[3\] J. P. Gee and F. Grosjean, "Performance Structures: A Psycholinguistic and Linguistic Appraisal,"Cognitive Psychology, Vol.
15, pp.
411-458, 1983.\[4\] It.
Moore, F. Pereira and H. Murveit, "integrating Speech and Natural-Language Processing," in Pro-ceedings of the DARPA Speech and Natural Language Wor~hop, pages 243-247, February 1989.\[5\] P. Price, W.M.
Fisher, J. Berustein, and D.S.
Pallett, "The DARPA 1000-word resource managementdatabase for continuous peech recognition," In IEEE Int.
Conf.
Acoust., Speech, Signal Processing,pages 651-654, New York, NY, April 1988.\[6\] N. Veilleux, M. Ostendorf, P. Price, S. Shattuck-Hufnagel, "Markov Modeling of Prosodic Phrase Struc-ture," submitted to the 1990 Inter.
Conf.
on Acoustics, Speech and Signs/Processing.\[7\] M. Weintraub, H. Murveit, M. Cohen, P. Price, J. Bernstein, G. Baldwin and D. Bell, "LinguisticConstraints in Hidden Markov Model Based Speech Recognition," in Pro?.
IEEE Int.
Conf.
Acoust.,Speech, Signal Processing, pages 699-702, Glasgow, Scotland, May 1989.EXAMPLES OF AMBIGUOUS SENTENCE PAIRSI.
Parentheticals:(a) MAry leaves on Tuesday.
She will have no problem Europe.
Mary \]mowa many \]anguagea, you know.
(b) Mary and you have similar backgrounds and have both learned many languages.
Mary knowm many\]anguagem you \]mow.2.
Apposition:(a) The Smiths didn't know what to do with their time while their television was broken.
The neighbor, whomluad|y read, the Daleya, were amm;ed.
(b) There was a funny Doonesbury today in all the local papers.
The neighbo~'a who uaua\]\]y read the dai\]ieawere atoned.103.
l~-ma,  bz vs. main-subordinate c laws:(a) ms mother and father cud not have the same reaction when he announced he wu going to become ahs, irdreeser.
JI/r6rlf w~ amazed and Dewey w~ anon'/.
(h) 1VbLry couldn't beUeve anyone would object to s~ch a harmlees prank.
Mot'it was amazed Ann Dewey wasGnU.4.
Tap:(a) Dave is always very angry, but it's futile to uk  him why.
Dame mill never know why hera enraged, will he.
~(h) Dave can be obnoxious without realisins it.
He just insulted Willy and is puseled by his a,nger.
Dave wii!never/mow wh I he'e enraged Will1.5.
Attachment of final phruse:(a) You'll never believe whet she had on when she eloped.
Laura ran away m/th ~e man wem'/ni/a greenrobe.
(h) Which man did L~usqs run away with?
Lure  ran awal/m~th the man wearing a green robe.6.
Attachment of middle phr~e:(s) In spring there wu always more work to do on the farm.
~y  wu the hardest month.
Their rome earlgin/l(alF.
(b) Bears sleep all winter long, usually comJn4~ out of hibernation in late April, but this year they were a littleslow.
Their roee em'il!
in Mal/.7.
Particles and prepoeitious:(a) /vfsrse lmres cards but she refuses to deal.
We would often try to trick her into doing it, but it neverworked.
Jl(arge wos/d never deal in onl  ~ruue.
(b) ~ is a real card shark ~ adores dealJnl poker, but she will only play with women.
We wouldsometimes try to set her to let one of ou: m,l~ friends int the galnej but she always refused.
~arge wouldneve1, deal/n any Is1#.11
