In: Proceedings o/CoNLL-2000 and LLL-2000, pages 111-114, Lisbon, Portugal, 2000.Minimal Commitment  and Full Lexical Disambiguation:Balancing Rules and Hidden Markov ModelsPat r i ck  Ruch  and Rober t  Baud and P ie r re t te  Bou i l lon  and G i lber t  Rober t*Medical Informatics Division, University Hospital of GenevaISSCO, University of Geneva{ruch, baud}@dim.hcuge.ch, {bouillon, robert}@issco.unige.caAbst ractIn this paper we describe the construction ofa part-of-speech tagger both for medical doc-ument retrieval purposes and XP extraction.Therefore we have designed a double system: forretrieval purposes, we rely on a rule-based ar-chitecture, called minimal commitment, whichis likely to be completed by a data-driven tool(HMM) when full disambiguation is necessary.1 I n t roduct ionNowadays, most medical information is storedin textual documents 1, but such large amountof data may remain useless if retrieving the rel-evant information in a reasonable time becomesimpossible.
Although some large-scale informa-tion retrieval (IR) evaluations, made on unre-stricted corpora (Hersh and al., 1998), and onmedical texts (Hersh, 1998), are quite criticaltowards linguistic engineering, we believe thatnatural anguage processing is the best solutionto face two major problems of text retrieval en-gines: expansion of the query and lexical dis-ambiguation.
Disambiguation can be separatedbetween MS (morpho-syntactic, i.e.
the part-of-speech (POS) and some other features) and WS(word-sense) disambiguation.
Although we aimat developing a common architecture for pro-cessing both the MS and the WS disambigua-tion (Ruch and al., 1999), this paper focuses onthe MS tagging.?
We would like to thank Thierry Etchegoyhen and ErikTjong Kim Sang for their helpful assistance while writingthis paper.
The Swiss National Fundation supported thepresent study.1While our studies were made on French corpora, theexamples are provided in English -when possible- for thesake of clarity.2 BackgroundBefore starting to develop our own MS tagger,some preliminary studies on general availablesystems were conducted; if these studies go farbeyong the scope of this paper, we would liketo report on the main conclusions.
Both statis-tical taggers (HMM) and constraint-based sys-tems were assessed.
Two guidelines were fram-ing the study: performances and minimal com-mitment.
We call minimal commitment 2 theproperty of a system, which does not attemptto solve ambiguities when it is not likely to solveit well!
Such property seems important for IRpurposes, where we might prefer noise ratherthan silence in the recall process.
However, itmust remain optional, as some other tasks (suchas the NP extraction, or the phrase chunking(Abney, 1991)) may need a full disambiguation.2.1 Data -dr iven  too lsWe adapted the output of our morphologicalanalyser for tagging purposes (Bouillon et al,1999).
We trained and wrote manual biasesfor an HMM tagger, but results were never farabove 97% (i.e.
about 3% of error); with an av-erage ambiguity level of around 16%, it meansthat almost 20% of the ambiguities were at-tributed a wrong tag!
We attempted to seta confidence threshold, so that for similarlyweighted transitions, the system would keep theambiguity, as in (Weischedel and al., 1993), butresults were not satisfying.2.2 Const ra in t -based  sys temsWe also looked at more powerful principle-based parsers, and tests were conducted on2The first one using this expression was maybe M.Marcus, lately we can find a quite similar idea in Sil-berztein (1997).111Token Lemma Lexical tag(s)fast a fastsection section nc\[s\]face/tofaceof of spthe the dadinternal internal afaces ~nToken Lexical tags Disambiguated tagfast a asection nc\[s\] nc\[s\]of sp spthe dad dadinternal a afaces nc\[p\]/v\[s03\] nc\[p\]Table 1: Tag-like representation f MS lexicalfeaturesFIPSTAG 3 (a Government and Binding chart-parser (Wehrli, 1992)).
Although this systemperformed well on general texts, with about0.7% of errors, its results on medical textswere about the same as stochastic taggers.
Aswe could not adapt our medical morphologicalanalyser on this very integrated system, it hadto cope with several unknown words.3 MethodsIn order to assess the system, we selected acorpus (40000 tokens) based equally on threetypes of documents: reports of surgery, dis-charge summaries and follow-up notes.
This adhoc corpus is split into 5 equivalent sets.
Thefirst one (set A, 8520 words) will serve to writethe basic rules of the tagger, while the other sets(set B, 8480 tokens, C, 7447 tokens, D, 7311tokens, and E, 8242 tokens), will be used forassessment purposes and incremental improve-ments of the system.3.1 Lexicon, morphological  analysisand guesserThe lexicon, with around 20000 entries, coversexhaustively the whole ICD-10.
The morpho-logical analyser ismorpheme-based (Baud et al,1998), it maps each inflected surface form of aword to its canonical lexical form, followed bythe relevant morphological features.
Words ab-sent from the lexicon follow a two-step guess-ing process.
First, the unknown token is anal-ysed regarding its respective morphemes, if thisfirst stage fails then a last attempt is made toguess the hypothetical MS tags of the token.The first stage is based on the assumption thataFor a MULTEXT-like description of the FIP-STAG tagset see Ruch P, 1997: Table de cot-respondance GRACE/FIPSTAG, available athttp://latl.unige.ch/doc/etiquettes.psTable 2: Example of taggingunknown words in medical documents axe verylikely to belong to the medical jargon, the sec-ond one supposed that neologisms follow regularinflectional patterns.
If regarding the morpho-syntax, both stages are functionally equivalent,as each one provides a set of morpho-syntacticinformation, they radically behave differentlyregarding the WS information.
For guessingWS categories only the  first stage guesser isrelevant, as inflectional patterns are not suffi-cient for guessing the semantic of a given token.Thus, the ending able characterises very proba-bly an adjective, but does not provide any se-mantic information 4 on it.Let us consider two examples of words absentfrom the lexicon.
First, allomorph: the prefixpart allo, and the suffix part, morph, are listedin the lexicon, with all the MS and the WS fea-tures, therefore it is recognized by the first-stageguesser.
Second, allocution, it can not be splitinto any affix, as cution is not a morpheme, butthe ending tion refers to some features (noun,singular) in the second-stage guesser.
As theunderlying objective of the project is to retrievedocuments, the main and most complete infor-mation is provided by the first-stage guesser,and the second-stage is only interesting for MStagging, as in (Chanod and Tapanainen, 1995).Finally (tab.
1), some of the morpho-syntacticfeatures provided by the lemmatizer are ex-pressed into the MS tagset 5, to be processedby the tagger (tab.
2).4A minimal set of lexical semantic types, based onthe UMLS, has been defined in (Ruch and al., 1999).5The MS tagset ends to follow the MULTEXT lexi-cal description for French, modified within the GRACEaction (http://www.limsi.fr/TLP/grace/doc/GTR-3-2.1.tex).
However, it is not always possible, as thisdescription does not allow any morpheme annotation.112Evaluation 1-Set B 2-Set C 3-Set D 4-Set ETokens with lexical ambiguitiesTokens correctly tagged1178 (13.9)8243 (97.2)1273 (17.1)7177 (96.4)1132 (15.5)7137 (97.6)1221 (14.8)8082 (98.1)Tokens still ambiguous, with GC 161 (1.9) 183 (2.5) 136 (1.9) 101 (1.2)Tokens ambiguous, without GC 9 (0.1) 2 (0) i 9 (0.1)Tokens incorrectly tagged 76 (0.9) i 78 (1.0) 36 (0.5) i 51 (0.6)Table 3: Results for each evaluation (GC stands for good candidates)Statistical evaluation on the residual ambiguity MFT HMMTokens correctly tagged 8136 (98.7) 8165 (99.1)Tokens incorrectly tagged 107 (1.3) 78 (0.9)Table 4: Processing the residual ambiguity3.2 Studying the ambiguitiesOur first investigations aimed at assessing theoverall ambiguity of medical texts.
We foundthat 1227 tokens (14.4% of the whole sample 6)were ambiguous in set A, and 511 tokens (6.0%)were unknown.
We first decided not to careabout unknown words, therefore they were nottaking into account in the first assessment (cf.Performances).
However, some frequent wordswere missing, so that together with the MSguesser, we would improve the guessing score byadding some lexemes.
Thus, adding 232 entriesin the lexicon and linking it with the Swiss com-pendium (for drugs and chemicals) provides anunknown word rate of less than 3%.
This resultincludes also the pre-processing of patients andphysicians names (Ruch and al., 2000).
Con-cerning the ambiguities, we found that 5 to-kens were responsible for half of the ambiguities,while in unrestricted corpora this number seemsaround 16 (Chanod and Tapanainen, 1995).3.2.1 Local  rulesWe separated the set A in 8 subsets of about1000 tokens, in order to write the rules.
Wewrote around 50 rules (which generated morethan 150 operative rules) for the first subset,while for the 8th, only 12 rules were necessaryto reach a score close to 100% on set A. Theserules are using intermediate symbols (such asthe Kleene star) in order to ease and improvethe rule-writing process, these symbols are re-placed when the operative rules are generated.6For comparison, the average ambiguity rate is about25-30% in unrestricted corpora.Here is an example of a rule:prop\[**\];v\[**\]/nc\[**\] ---+ prop\[**\];v\[**\]This rule says 'if a token is ambiguous be-tween (/) a verb (v), whatever (**) features ithas (3rd or lst /2nd person, singular or plural),and a common noun, whatever (**) features ithas, and such token is preceded by a personalpronoun (prop), whatever (**) features this pro-noun has (3rd or lst /2nd person), then the am-biguous token can be rewritten as a verb, keep-ing its original features (**)'.4 Per fo rmances4.1 Maximizing the minimalcommitmentFour successive evaluations were conducted(tab.
3); after each session, the necessary ruleswere added in order to get a tagging score closeto 100%.
In parallel, words were entered intothe lexicon, and productive ndings were addedinto the MS guesser.
The second, third, andfourth evaluations were performed with activat-ing the MS guesser.
Let us note that translationphenomena (Paroubek and al., 1998), whichturn the lexical category of a word into anotherone, seem rare in medical texts (only 3 caseswere not foreseen in the lexicon).A success rate of 98% (tab.
3, evaluation4) is not a bad result for a tagger, but themain result concerns the error rate, with lessthan 1% of error, the system seems particularlyminimally committed 7.
Another interesting re-sult concerns the residual ambiguity (tokens tillrLet us note that in the assessment 1, he system had113ambiguous, with GC): in the set E, at least halfof these ambiguities could be handled by writ-ing more rules.
However some of these ambigui-ties are clearly untractable with such contextualrules, and would demand more lexical informa-tion, as in le patient prdsente une douleur ab-dominale brutale et diffuse (the patient showsan acute and diffuse abdominal pain/the pa-tient shows an acute abdominal pain and dis-tributes*S), where diffuse could be adjective orverb.4.2 Max imiz ing  the  success  ra teA last experiment is made: on the set E, whichhas been disambiguated by the rule-based tag-ger, we decided to apply two more disambigua-tions, in order to handle the residual ambi-guity.
First, we apply the most frequent tag(MFT) model, as baseline, then the HMM.
Boththe MFT and the HMM transitions are calcu-lated on the set B-t-C?D, tagged manually, butwithout any manual improvement (bias) of themodel.Table 4 shows that for the residual ambiguity,i.e.
the ambiguity, which remained untractableby the rule-based tagger, the HMM provides aninteresting disambiguation accuracy 9.5 Conc lus ionWe have presented a rule-based tagger for elec-tronic medical records.
The first target ofthis tool is the disambiguation for IR purposes,therefore we decided to design a system with-out any heuristics.
As second target, the systemwill be used for conducting NP extraction tasksand shallow parsing: the system must be ableto provide a fully disambiguated output; there-fore we used the HMM tool for completing thedisambiguation task.Re ferencesAbney, Steven.
1991.
Parsing by chunks.
In R.Berwick and S. Abney and C. Tenny, editors,Principle-based parsing, pages 257-278.
Kluwer.Robert Baud, C. Lovis, and AM.
Rassinoux.
1998.Morpho-semantic parsing of medical expressions.about 1000 operative rules, while the assessment 4 wasconducted with more than 2000 rules.SThe lexical information on the valence + OBJECTis necessary for disambiguating the verb form of diffuse.9The accuracy of the HMM tagger, on the fully am-biguous version of set E, was 96.3%, while the MFT per-formed about 93.5%.In Proceedings ofAMIA '1998, pages 760-764, Or-lando.Pierrette Bouillon, R Baud, G Robert, and P Ruch.1999.
Indexing by statistical tagging.
In Proceed-ings of the JADT'2000, pages 35-42, Lausanne.Jean-Pierre Chanod and Pasi Tapanainen.
1995.Tagging french: comparing a statistical anda constraint-based method.
In Proceedings ofEACL'95, pages 149-156, Dublin.William, Hersh and S. Price and D. Kraemer andB.
Chan and L. Sacherek and D. Olson.
1998.A large-scale comparison of boolean vs. naturallanguage searching for the trec-7 interactive track.In TREC 1998, pages 429-438.William Hersh.
1998.
Information retrieval at themillenium.
In Proceedings of AMIA'1998, pages38-45, Lake Buena Vista, FL.Paroubek, Patrick and G. Adda and J. Mariani andJ.
Lecomte and M. Rajman.
1998.
The GRACEfrench part-of-speech tagging evaluation task.
InProceedings of LREC'1998, Granada.Ruch, Patrick and J. Wagner and P. Bouillon and R.Baud and A.-M. Rassinoux and G. Robert.
1999.Medtag: Tag-like semantics for medical documentindexing.
In Proceedings of AMIA '99, pages 35-42, Washington.Ruch, Patrick and R. Baud and A.-M. Rassinouxand P. Bouillon and G. Robert 2000.
Medicaldocument anonymization with a semantic lexicon.In Proceedings of AMIA '2000, Los Angeles.Max Silberztein.
1997.
The lexical analysis of nat-ural languages.
In Emmanuel Roche and YvesShabes, editors, Finite-State Language Process-ing, pages 176-205.
MIT Press.Eric Wehrli.
1992.
The IPS system.
In ProceedingsCOLING-92, pages 870-874.Weischedel, Ralph and M. Meeler and R. Shwartzand L. Ramshaw and J. Palmucci, 1993.
Cop-ing with ambiguity and unknown words throughprobabilistic models.
Computational Linguistics,19(2):359-382.114
