Proceedings of the First Workshop on Metaphor in NLP, pages 36?44,Atlanta, Georgia, 13 June 2013. c?2013 Association for Computational LinguisticsAutomatic Metaphor Detection using Large-Scale Lexical Resources and Conventional Metaphor Extraction   Yorick Wilks, Lucian Galescu, James Allen, Adam Dalton Florida Institute for Human and Machine Cognition 15, SE Osceola Ave Ocala, FL, 34471, USA {ywilks,lgalescu,jallen,adalton}@ihmc.us     Abstract The paper presents an experimental algorithm to detect conventionalized metaphors implicit in the lexical data in a resource like WordNet, where metaphors are coded into the senses and so would never be detected by any algorithm based on the violation of preferences, since there would always be a constraint satisfied by such senses.
We report an implementation of this algorithm, which was implemented first the preference constraints in VerbNet.
We then derived in a systematic way a far more extensive set of constraints based on WordNet glosses, and with this data we reimplemented the detec-tion algorithm and got a substantial improvement in recall.
We suggest that this technique could contribute to improve the performance of existing metaphor detec-tion strategies that do not attempt to detect convention-alized metaphors.
The new WordNet-derived data is of wider significance because it also contains adjective constraints, unlike any existing lexical resource, and can be applied to any language with a semantic parser (and WN) for it.
1 Introduction Metaphor is ubiquitous in standard language; it is not a fringe or add-on phenomenon.
The work de-scribed concerns detecting and interpreting meta-phor on a large scale in corpora.
If metaphor is ubiquitous, then locating and interpreting it must be central to any NLP project that aims to under-stand general language.
This paper focuses on the initial phase of detection: the identification in text of conceptual combinations that might be deemed metaphoric by a pre-theoretic observer, e.g., ?Bra-zil has economic muscle?, ?Tom is a brick?, or ?The unions have built a fortress round their pen-sions?.
There is a long cultural tradition of de-scribing and interpreting such phenomena but our goal here is computational: to provide criteria for automatically detecting such cases as candidates for further analysis and interpretation.
The key fact is that metaphors are sometimes new and fresh but can be immediately understood: producing them is often the role of poets, creative journalists and writers of all kinds.
But many are simply part of the history of the language, and are novel only to those who do not happen to know them already: for example ?Tom is a brick?
?
taken to mean that he is a reliable man, but which cannot be literally true ?
is actually encoded as a sense of brick in WordNet (WN) (Miller, 1995) even though it is more familiar to UK than US English speakers.
This means that lexical resources already con-tain conventionalized metaphors.
We propose a simple method for locating and extracting these into the metaphor candidate pool, even when they are not indicated as such in resources like WN (which marks figurative senses very infrequently, unlike some traditional dictionaries).
However, we believe these implicit metaphors in WN ?
a re-source we intend to use as a semantic/lexical data-base, though transformed as we shall show below ?
can be extracted by a simple algorithm, and with-out any need for a priori distinction of literal ver-sus metaphorical.
That distinction, as we noted, depends to a large degree on the temporal snapshot of a language; e.g., no one now would think ?tak-ing a decision?
was metaphor, even though deci-sions are not literally taken anywhere.
In this paper, we shall present an algorithm for conventionalized metaphor detection, and show results over a standard corpus of examples that36demonstrate a possible useful gain in recall of metaphors, our original aim.
The algorithm is de-scribed in two implementations (or pipelines) cor-responding, respectively, to the use of WN and VerbNet (Kipper et al 2000; Kipper et al 2008) as semantic knowledge-bases, and to their re-placement by our automatically recomputed form of WN, which enables predictions about the pref-erence behavior (see below) of English verbs and adjectives to be better founded than in VerbNet (VN) and on a much larger scale.
2 Background on Metaphor Detection us-ing Preference Violation as Cue In early work on metaphor detection, long preced-ing access to large-scale or annotated corpora, it was suggested as sufficient a criterion for being a metaphor that a ?semantic preference?
of a verb or adjective was violated (Wilks, 1978).
So, for ex-ample, one might say that the verb drink had a preference for animate agents and liquid objects, in which case ?My car drinks gasoline?
violates its subject preference, which might then be a cue to look for metaphor at that point.
Similarly, in the ?economic muscle?
case mentioned earlier one might say that economic has a preference for ab-stract entities as objects, as in ?economic value?, and muscle is not an abstract entity.
There was discussion in those early days of syntac-tic-semantic interface cases like ?John ran a mile?
where a mile might be said to violate the prefer-ence of the (intransitive) verb for a zero object and so again trigger a metaphor.
The preference notion was not initially intended to detect metaphor but to semantically disambiguate candidates at those sites by preferring those conceptual entities that did not violate such restrictions.
In early work, preferences were largely derived by intuition and sometimes ordered by salience.
Later (e.g.
Resnik, 1997) there was a range of work on deriving such preferences from corpora; however, in VN the semantic prefer-ences of verbs were again largely intuitive in ori-gin.
Early work linking preference violation to metaphor detection (summarised in Fass and Wilks, 1983, also Martin 1990) worked with hand-crafted resources, but by 1995 Dolan had noted (Dolan, 1995) that large-scale lexical resources would have implications for metaphor detection, and WN was used in conjunction with corpora, by(Peters and Wilks, 2003) using symbolic methods and by Mason (2004) and Krishnakumaran and Zhu (2007) using a combination of WN and statis-tical methods.
Mason also acquires preferences automatically from corpora, and the latter two pa-pers treat metaphor as a form of anomaly based on rare combinations of surface words and of WN-derived hypernyms, a notion that appears in (Guthrie et al 2007) but based only on corpus sparsity and not WN codings.
Other work on the automatic acquisition of preferences (McCarthy and Carrol, 2003) for WSD has also its considered extension to the detection of classes of metaphor.
More recently, work by Shutova (Shutova et al 2010) has shown that the original preference viola-tion insight can be combined with large-scale in-vestigations, using notions of machine learning and large-scale resources like WN.
Our approach is smaller scale and does not involve machine learn-ing: it simply seeks access to implicit metaphors built into the structure of WN by its creators, and which a preference-violation detection criterion cannot, by definition, access.
Thus, we view our contribution as complementary to larger efforts on metaphor and interpretation detection, rather than a competing approach.
We have not made compari-sons here with the work of (Li and Sporleder, 2010), which is explicitly concerned with idioms, nor with (Markert and Nissim, 2009) which is fo-cused on metonymy.
3 The Conventional Metaphor Detection Hypotheses Where WN codes conventionalized metaphors as senses, as in the initial cases described, then the senses expressing these will NOT violate prefer-ences and so will not be detected by any metaphor-as-violation hypothesis.
For example, in ?Jane married a brick?
this will not be a preference vio-lation against WN senses because WN explicitly codes brick as a reliable person, though we would almost certainly want to say this sentence contains a metaphor to be detected.
The hypothesis we propose is simply this: if we have a word whose main (usually first) sense in WN fails the main preference for the sentence slot it fills, but has a lower, less frequent, sense that satisfies that preference, then we declare that lower sense a metaphorical one.
In the case of brick, whose main sense is a PHYSICAL OBJECT, one37which clearly fails the equivalence to Tom in the example ?Tom is a brick?.
Yet the less frequent listed sense for a reliable person does satisfy the same preference.
The work at this stage is not con-cerned with the metaphor-metonymy distinction and this criterion may well capture both, their dis-tinction being, as is well known (e.g.
in Fass and Wilks, 1983) hard to establish in the limit.
Ours is a purely empirical hypothesis and will work or not, and we argue that it does to a reasonable degree.
It does not rest on any assumption of strict ordering of WN senses, only on a tendency (from literal to metaphorical) which is plainly there for any ob-server.
4 Metaphor Detection Experiments We have implemented two versions of conven-tional metaphor detection, using two different lexi-cal resources.
We were thus able to divide the hypothesis into two parts, essentially one making use of VN and one within WN only.
In this first pipeline, we use WN together with the verb prefer-ences provided by VN even though those give only patchy coverage of common verbs.
At the outset this was the only lexical resource for verb prefer-ences available.
VN includes classes of verbs that map members to specific WN senses.
VN also provides a hierarchy of verb object/subject inclu-sions, which we use for assessing whether one sen-tence object/subject type appears below another in this simple inclusion hierarchy, and so can be said to be semantically included in it.
The selectional restrictions, however, are not linked to any lexi-cons so a mapping was constructed in order to al-low for automated detection of preference violations.
Our first experiment utilizes WN, VN, and the Stanford Parser (de Marneffe et al 2006) and Named Entity Recognizer (Finkel et al 2005).
The Stanford Parser identifies the verbs, as well as their corresponding subjects and direct objects.
The Stanford Named Entity Recognizer was used to replace sequences of text representing names with WN senses whose hypernyms exist in the se-lectional restriction hierarchy.
The first step in determining whether a sentence contains a metaphor is to extract all verbs along with the subject and direct object arguments for each verb.
The Stanford Parser dependencies used to describe the relationships between verbs andtheir arguments include agent, nsubj, and xsubj for subjects and dobj and nsubjpass for direct objects.
The parser also handles copular and prepositional verbs but additional steps are required to link these verbs to their arguments.
Once verbs have been extracted and parameter-ized from the sentence, each is checked for prefer-ence violations.
A preference is violated if a selectional restriction on one of the thematic roles of a VN class is not satisfied for all VN classes the verb is a member of.
In order for a VN class's preferences to be satisfied, there must be a WN sense for the argument of a verb such that either itself or its hypernym matches the WN senses al-lowed by the selectional restriction in VN class, where the terms in the VN hierarchy have been hand-matched to WN senses.
If a sentence contains a verb that does not exist in VN then we must as-sume that it is not violated.
5 Conventionalized Metaphor Detection Closer inspection of false negatives revealed that many of the verbs and the arguments that satisfied their selectional restrictions were unannotated con-ventionalized metaphors.
5.1 Conventionalized Verbs In our approach, a conventionalized verb occurs when two VN Classes have the same member, but one maps to a lower WN sense (in the WN order-ing, which can be taken roughly to mean less fre-quent) than the other.
If the VN Class mapped to the lower sense is satisfied in a sentence, but the other VN Class is not, we say that the verb is used in a conventionalized sense.
The verb pour  is a member of four VN classes.
Three of those classes, Pour-9.5, Preparing-26.3-2, and Sub-stance_Emission-43.4 all map to first sense of the word which means to cause to run.
The fourth VN class of pour, Weather-57, maps to the sixth WN sense of the verb, which means to rain heavily.
If we take the example sentence ?Bisciotti has poured money into the team?, we determine that all VN classes that map to the primary WN sense of pour are violated in some way.
According to our semantic role labeling heuristic, Pour-9.5 expects money to be a substance, Preparing-26.3-2 ex-pects the team to be an animate, and Sub-stance_Emission-43.4 is violated because Bisciotti is animate.
The only Verb Class that is satisfied is38Weather-57, and that class maps to the sixth sense of pour.
Interestingly, there is no VN class mem-ber that maps to the fifth WN sense (supply in large amounts or quantities).
The pseudocode for detecting conventional metaphors used as verbs is as follows: ?
for each VN Class ?
for each member of that class ?
for each WN sense of that member with Verb POS ?
get the sense number of the WN sense ?
associate the sense number to the verb member and selectional re-strictions for the Verb Class ?
given a verb in a sentence, decide that the verb is conventionalized if: ?
it satisfies the selectional re-strictions of one Verb Class V1 but?
?
it violates the selectional restric-tions of another Verb Class V2 and?
?
the sense number of the verb member in V2 is above the sense number of the verb member in V1  5.2 Conventionalized Nouns Let us look again at the example of brick, where the primary sense of the noun is the building mate-rial most are familiar with and the secondary sense refers to a reliable person.
For this reason, the noun brick will satisfy any VN class that requires a hu-man or animate.
Without the ability to detect con-ventional metaphors in noun arguments, She married a brick would pass through without detec-tion by preference violation.
Here are the WN en-tries for the two senses: ?
brick#1 (brick%1:06:00::) (rectangular block of clay baked by the sun or in a kiln; used as a build-ing or paving material)  ?
brick#2 (brick%1:18:00::) (a good fellow; helpful and trustworthy)  Less obvious are more abstract words such as zone: ?
zone#1 (zone%1:15:00::) (a locally circumscribed place characterized by some distinctive features) ?
zone#2 (zone%1:15:02::), geographical zone#1 (geographical_zone%1:15:00::) (any of the re-gions of the surface of the Earth loosely divided ac-cording to latitude or longitude)  ?
zone#3 (zone%1:15:01::) (an area or region dis-tinguished from adjacent parts by a distinctive fea-ture or characteristic)  ?
zone#4 (zone%1:08:00::), zona#1 (zona%1:08: 00::) ((anatomy) any encircling or beltlike struc-ture)  Zone's primary sense, again, is the anticipated con-cept of circumscribed space.
However, the fourth sense deals with anatomy, and therefore is a hypo-nym of body part.
Body part is capable of satisfy-ing any thematic role restricted to animate arguments.Figure 1.
Conventionalized verb metaphor detection using WordNet senses  and VerbNet selectional restrictionsVerbNet WordNetParserNamed EntityRecognizerInterfaceMetaphorDetectorExtract verbsand argumentsIs sentencea metaphor?Replace named enittiesGet WordNet hypernym sets for argumentsFind all VerbNet Classes for each verbWhich WordNet sensessatisfy SelectionalRestrictions[None]Sentence containsa metaphor[One or more]Set of senses that satisfy selectional restrictionsDoes the member ofthe Verb Classessatisfied map to theprimary sense?
[Yes]No metaphor[No]Conventionalized Metaphor39The pseudocode for detecting conventional metaphors used as nouns is as follows: ?
determine if verbs?
subjects and di-rect objects satisfy the restriction ?
if not, it is a Preference Violation metaphor ?
if they do: ?
determine if the sense of the sat-isfying word is the primary sense in WN ?
if not, it is a conventional metaphor ?
otherwise, it is not a metaphor Thus, our overall hypothesis is intended to locate in the very broad WN sense sets those that are ac-tually conventionalized metaphors: we determine that only the first sense, hopefully literal, should be able to satisfy any restriction.
If a lower sense sat-isfies a verb, but the primary sense does not, we classify the satisfaction as being conventionalized, but a metaphor nonetheless.
6 Deriving Preferences and an Ontology from WordNet To date, VerbNet is the most extensive resource for verb roles and restrictions.
It provides a rich semantic role taxonomy with some selectional re-strictions.
Still, VN has entries for less than 4000 verbs.
PropBank (Palmer et al 2005) has addi-tional coverage, but uses a more surface oriented role set with no selectional restrictions.
On the other hand, WordNet has many more verb entries but they lack semantic role information.
However, we believe it is possible to extract automatically a comprehensive lexicon of verbs with semantic roles and selectional restrictions from WN by processing definitions in WN using deep under-standing techniques.
Specifically, each verb in WN comes with a gloss that defines the verb sense, and there we can find clues about the semantic roles and their selectional restrictions.
Thus, we are test-ing the hypothesis that the semantic roles of the verb being defined are inherited from the roles in its definition, though roles in the latter may be elided or fully specified.
For example, consider this entry from WN for one of the senses of the verb kill: S: (v) kill (cause to die; put to death, usually inten-tionally or knowingly) ?This man killed several people when he tried to rob the bank?
; ?the farmer killed a pig for the holidays?
Let us assume we already know that the verb cause takes three roles, say, a CAUSER, an AFFECTED and an EFFECT role; this leads us to hypothesize that kill would take the same roles.
However, the EFFECT role from cause is not inherited by kill as it is fully specified in the definition.
The proof ofFigure 2.
Conventionalized noun metaphor detection using WordNet senses  and VerbNet selectional restrictions40this hypothesis is ultimately in how well it predicts the role set.
But intuitively, any role in the defini-tion verb (i.e., cause) that is fully filled in the defi-nition has no ?space?
for a new argument for that role.
Therefore, we conclude that kill takes two roles, filling the CAUSER and AFFECTED roles in the definition.
We can now derive selectional restrictions for kill by looking at inherited restrictions from the definition, as well as those that can be derived from the examples.
From the definition, the verb cause puts little to no restriction on what the CAUSER role might be.
For instance, an animal may cause something, but natural forces cause things as well.
Likewise, cause puts little con-straint on what the PATIENT role might be, as one can cause the temperature to rise, or an idea to fade.
The restriction from the verb die in the com-plement, however, suggests a restriction of some living object (if we can derive this constraint from die).
We also look at the examples to find more informative restrictions.
In the definition of kill, we have two examples of a CAUSER, namely a man and a farmer.
Given the hypernym hierarchy of nouns in WordNet, we could look for the most specific subsuming concept in the hierarchy for the concepts MAN and FARMER, finding it to be person%1:03:00.
The fillers for the AFFECTED role in the examples are PEOPLE and PIG, with the most specific WN node being organ-ism%1:03:00).
Putting all this together, we pro-duce an entry for kill as follows: kill:  ACTOR/person%1:03:00  PATIENT/organism%1:03:00 To implement this idea we need a number of capa-bilities.
First, semantic roles do not appear out of the ether, so we need an initial seed of semanticrole information.
In addition, to process the glosses we need a parser that can build a semantic repre-sentation, including the handling of elided argu-ments.
As a start, we use the TRIPS parser (Allen et al 2008).
The TRIPS lexicon provides informa-tion on semantic roles, and the parser can construct the required semantic structures.
TRIPS has been shown to be successful at parsing WN glosses in order to build commonsense knowledge bases (Al-len et al 2011).
With around 3000 types, TRIPS offers a reasonable upper-level ontology to serve as the seed for semantic roles.
We also use the TRIPS selectional restrictions to bootstrap the process of determining the restrictions for new words.
To attain broad lexical coverage, the TRIPS parser uses input from a variety of external re-sources.
This includes a subsystem, Wordfinder, for unknown word lookup that accesses WN when an unknown word is encountered.
The WN senses have mappings to semantic types in the TRIPS on-tology, although sometimes at a fairly abstract level.
When faced with an unknown word, the parser looks up the possible senses in WordNet, maps these to the TRIPS ontology and then uses the verb entries in the TRIPS lexicon associated with these types to suggest possible subcatgoriza-tion frames with mappings to roles.
Thus, Word-finder uses the combined information from WN and the TRIPS lexicon and ontology to dynami-cally build lexical entries with approximate seman-tic and syntactic structures for words not in the core lexicon.
This process may produce a range of different possibilities based on the different senses and possible subcategorization frames for the verbs that share the same TRIPS type.
We feed all of these to the parser and let it determine the entries that best match the definition and examples.
While WordNet may have multiple fine-grained senses for a given word, we set a parameter that has the system use only the most frequent sense(s) of the word (cf.
McCarthy et al2004).
We use TRIPS to parse the definitions and glosses into a logical form.
Figure 3 shows the logical form produced for the definition cause to die.
We then search the logical form for structures that signal a potential argument that would fill a role.
Besides looking for gaps, we found some other devices that serve the same purpose and oc-cur frequently in WordNet:Figure 3: Abstracted Logical Form for ?cause to die?
(F CAUSE-MAKE)(IMPRO LSUBJ)(IMPRO DOBJ)(F DIE)CAUSEAFFECTEDEFFECTEXPERIENCER41?
elided arguments (an IMPRO in the logical form); ?
indefinite pronouns (e.g., something, some-one); ?
prepositional/adverbial forms containing an IMPRO or an indefinite pronoun (e.g., give a benediction to); ?
a noun phrase in parentheses (e.g., to re-move (people) from a building).
The final condition is probably a WN specific de-vice, and was discovered when working on a 10-verb development set, and occurred twice in that set.
Once these arguments are identified, we have a candidate set of roles for the verb.
We identify candidate selectional restrictions as described above.
Here are a few examples of verbs and their automatically derived roles and restrictions, as computed by our system (here we indicate Word-Net entries by their sense index rather than their sense key, since the index is used in the conven-tional metaphor detection strategy ?
see below): bend.v.06: AGENT/being.n.02     PATIENT/physical_entity.n.01 collect.v.03: AGENT /person.n.01     PATIENT/object.n.01 drive.v.01:  AGENT/person.n.01     PATIENT/motor_vehicle.n.01 play.v.13: CAUSE/instrumentality.n.03     EFFECT/music.n.01 walk.v.08: AGENT/being.n.02     GOAL/location.n.01 The techniques described in this section have been used to provide a set of roles with selectional re-strictions for the second IHMC pipeline, described below.
The current system takes a list of verbs from a corpus and returns the role names and se-lectional restrictions for every sense of those words in WordNet.
The transformations described here all equally able to produce preferences for adjectives, as would be needed to detect ?economic muscle?
as a metaphor, which is a form of lexical information not present in any existing database, and the whole process can be applied to any language that pos-sesses a WordNet type lexical resource, and for which we have a capable semantic parser.
Hence, these techniques are amenable to being used for detecting metaphorical usage in constructions otherthan just verb-subject and verb-object, as we do here.
7 Conventional Metaphor Detection based on WordNet-Derived Preferences The preferences and ontology derived from WN definitions greatly improve the mapping between selectional restrictions and WN sense keys.
This allows us to replace VN with a new lexical re-source that both improves performance, and re-duces the complexity of discovering preference violations.
In the new pipeline, we can reuse the capabilities developed to extract verbs and their parameters from a sentence.
We also reuse the tie-ins to WN that allow us to determine if one WN sense exists within another's hypernym set.
It is the selectional restriction lookup that is greatly simpli-fied in the new lexicon, where verbs are mapped directly to WN senses.
The conventional metaphor detection is also simplified because the WN senses are included in the responses to the looked up verbs, allowing us to quickly determine if a satis-fied verb is conventionalized or is satisfied with conventionalized arguments.
8 Results and Conclusion Figure 4 shows the results obtained in a metaphor detection task over a small corpus of 122 sen-tences.
Half of these sentences have metaphors and half do not.
Of the half that do, approximately half are metaphors about Governance and half are other metaphors.
This is not any sort of principled cor-pus but a seed set chosen to give an initial leverage and in a domain chosen by the sponsor (Govern-ance); the selection and implicit annotation were?
Pipeline?1?(VerbNet?SRs)?
Pipeline?2?
(WordNet?SRs)?TP 24 50 FP 23 37 TN 48 24 FN 37 11 Precision 0.649 0.575 Recall 0.393 0.82 F1 0.49 0.676  Figure 4.
Performance comparison between the first pipeline using VerbNet selectional restrictions (SRs) and the second pipeline using WordNet-derived se-lectional restrictions42done by consensus by a large group of twenty or so collaborators.
The notion of baseline is irrelevant here, since the choice for every sentence is simply whether it contains a metaphor or not, and could thus be said to be 50% on random assignment of those categories.
From the figures above, it can be seen that the second pipeline does give significant improvement of recall over the first implementation above, even though there is some loss of precision, probably because of the loss of the information in VN.
One possibility for integrating a conventional metaphor extraction pipeline like ours with a general meta-phor detection pipeline (including, for example, pattern-based methods and top-down recognition from stored Conceptual Metaphors) would be to OR these two pipelines together and to hope to gain the benefits of both, taking anything as a metaphor that was deemed one by either.
However, that is not our aim here: our purpose is only to test the hypothesis that using knowledge derived from existing lexical resources, in combi-nation with some form of the conventionalized metaphor hypothesis, we can achieve good recall performance.
On this point we think we have shown the value of the technique.
Acknowledgements This work was supported in part by the Intelligence Advanced Research Projects Activity (IARPA) via Department of Defense US Army Research Labo-ratory contract number W911NF-12-C-0020, and NSF grant IIS 1012205.
The U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes notwithstanding any copy-right annotation thereon.
Disclaimer: The views and conclusions contained herein are those of the authors and should not be interpreted as necessar-ily representing the official policies or endorse-ments, either expressed or implied, of IARPA, DoD/ARL, or the U.S. Government.
References James Allen, William de Beaumont, Nate Blaylock, George Ferguson, Jansen Orfan, and Mary Swift.
2011.
Acquiring commonsense knowledge for a cog-nitive agent.
In Proceedings of the AAAI Fall Sympo-sium on Advances in Cognitive Systems (ACS 2011), Arlington, Virginia.James Allen, Mary Swift, and Will de Beaumont.
2008.
Deep semantic analysis of text.
In Proceedings of the 2008 Conference on Semantics in Text Processing (STEP '08), Venice, Italy.
pp.
343-354.
Marie-Catherine de Marneffe, Bill MacCartney and Christopher D. Manning.
2006.
Generating Typed Dependency Parses from Phrase Structure Parses.
In Proceedings of the 5th International Conference on Language Resources and Evaluation (LREC 2006), pp.
449-454.
William B. Dolan.
1995.
Metaphor as an emergent property of machine-readable dictionaries.
In Pro-ceedings of the AAAI 1995 Spring Symposium Series: Representation and Acquisition of Lexical Knowl-edge: Polysemy, Ambiguity and Generativity, pp.
27?32.
Dan Fass and Yorick Wilks.
1983.
Preference seman-tics, ill-formedness, and metaphor.
American Journal of Computational Linguistics, 9(3):178?187.
Jenny Rose Finkel, Trond Grenager, and Christopher Manning.
2005.
Incorporating Non-local Information into Information Extraction Systems by Gibbs Sam-pling.
In Proceedings of the 43nd Annual Meeting of the Association for Computational Linguistics (ACL 2005), pp.
363-370.
David Guthrie, Louise Guthrie, Ben Allison and Yorick Wilks.
2007.
Unsupervised Anomaly Detection.
In Proceedings of the 20th international joint confer-ence on Artifical intelligence (IJCAI'07), San Fran-cisco, CA, pp.
1624-1628.
Karin Kipper, Hoa Trang Dang, and Martha Palmer.
2000.
Class-based construction of a verb lexicon.
In Proceedings of the 17th National Conference on Arti-ficial Intelligence, Austin, Texas.
pp.
691-696.
Karin Kipper, Anna Korhonen, Neville Ryant, and Mar-tha Palmer.
2008.
A large-scale classification of Eng-lish verbs.
Language Resources and Evaluation 42(1):21-40.
Saisuresh Krishnakumaran and Xiaojin Zhu, 2007.
Hunting Elusive Metaphors Using Lexical Re-sources, Proceedings of the Workshop on Computa-tional Approaches to Figurative Language, pp.
13-20.
Linlin Li and Caroline Sporleder.
2010.
Linguistic Cues for Distinguishing Literal and Non-Literal Usage.
In Proceedings of the 23rd International Conference on Computational Linguistics (COLING 2010), Beijing, China, pp.
683-691.
Katia Markert and  Nissim Malvina.
2009.
Data and Models for Metonymy Resolution.
In Language Re-sources and Evaluation, 43(2):123-138.
James Martin.
1990.
A Computational Model of Meta-phor Interpretation.
Academic Press.
Zachary J. Mason.
2004.
Cormet: A computational, cor-pus-based conventional metaphor extraction sys- tem.
Computational Linguistics, 30(1):23?44.43Diana McCarthy and John Carrol.
2003.
Disambiguat-ing nouns, verbs and adjectives using automatically acquired selectional preferences.
Computational Lin-guistics.
29(4): 639-654.
Diana McCarthy, Rob Koeling, Julie Weeds, and John Carroll.
2004.
Finding predominant word senses in untagged text.
In Proceedings of the 42nd Annual Meeting on Association for Computational Linguis-tics (ACL '04), Barcelona, Spain.
pp.
280-287.
George Miller.
1995.
Wordnet: A lexical database for English.
Communications of the ACM, 38(11):39-41.
Martha Palmer, Dan Gildea, and Paul Kingsbury.
2005.
The Proposition Bank: An Annotated Corpus of Se-mantic Roles.
Computational Linguistics, 31(1):71-106.
Wim Peters and Yorick Wilks.
2003.
Data-Driven De-tection of Figurative Language Use in Electronic Language Resources, Metaphor and Symbol, 18(3): 161-174.
Philip Resnik, 1997.
Selectional preference and sense disambiguation.
In Proceedings of the ACL SIGLEX Workshop on Tagging Text with Lexical Semantics: Why, What and How?, Washington, DC, pp.
52-57.
Ekaterina Shutova, Li-ping Sun and Anna Korhonen.
2010.
Metaphor Identification Using Verb and Noun Clustering.
In Proceedings of the 23rd International Conference on Computational Linguistics (COLING 2010), Beijing, China, pp.
1002-1010.
Yorick Wilks, 1978.
Making Preferences More Active.
Artificial Intelligence, 11(3):197-223.44
