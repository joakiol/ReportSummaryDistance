Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 315?323,Suntec, Singapore, 2-7 August 2009. c?2009 ACL and AFNLPA Syntax-Driven Bracketing Model for Phrase-Based TranslationDeyi Xiong, Min Zhang, Aiti Aw and Haizhou LiHuman Language TechnologyInstitute for Infocomm Research1 Fusionopolis Way, #21-01 South Connexis, Singapore 138632{dyxiong, mzhang, aaiti, hli}@i2r.a-star.edu.sgAbstractSyntactic analysis influences the way inwhich the source sentence is translated.Previous efforts add syntactic constraintsto phrase-based translation by directlyrewarding/punishing a hypothesis when-ever it matches/violates source-side con-stituents.
We present a new model thatautomatically learns syntactic constraints,including but not limited to constituentmatching/violation, from training corpus.The model brackets a source phrase asto whether it satisfies the learnt syntac-tic constraints.
The bracketed phrases arethen translated as a whole unit by the de-coder.
Experimental results and analy-sis show that the new model outperformsother previous methods and achieves asubstantial improvement over the baselinewhich is not syntactically informed.1 IntroductionThe phrase-based approach is widely adopted instatistical machine translation (SMT).
It segmentsa source sentence into a sequence of phrases, thentranslates and reorder these phrases in the target.In such a process, original phrase-based decod-ing (Koehn et al, 2003) does not take advan-tage of any linguistic analysis, which, however,is broadly used in rule-based approaches.
Sinceit is not linguistically motivated, original phrase-based decoding might produce ungrammatical oreven wrong translations.
Consider the followingChinese fragment with its parse tree:Src: [?
[[7?
11?
]NP [??
[?
[??
?
]NP]PP ]VP ]IP ]VPRef: established July 11 as Sailing Festival dayOutput: [to/?
[?
[set up/??
[for/?
naviga-tion/??]]
on July 11/7?11??
knots/?
]]The output is generated from a phrase-based sys-tem which does not involve any syntactic analy-sis.
Here we use ?[]?
(straight orientation) and????
(inverted orientation) to denote the commonstructure of the source fragment and its transla-tion found by the decoder.
We can observe thatthe decoder inadequately breaks up the second NPphrase and translates the two words ????
and???
separately.
However, the parse tree of thesource fragment constrains the phrase ???
?
?to be translated as a unit.Without considering syntactic constraints fromthe parse tree, the decoder makes wrong decisionsnot only on phrase movement but also on the lex-ical selection for the multi-meaning word ??
?1.To avert such errors, the decoder can fully respectlinguistic structures by only allowing syntacticconstituent translations and reorderings.
This, un-fortunately, significantly jeopardizes performance(Koehn et al, 2003; Xiong et al, 2008) because byintegrating syntactic constraint into decoding as ahard constraint, it simply prohibits any other use-ful non-syntactic translations which violate con-stituent boundaries.To better leverage syntactic constraint yet stillallow non-syntactic translations, Chiang (2005)introduces a count for each hypothesis and ac-cumulates it whenever the hypothesis exactlymatches syntactic boundaries on the source side.On the contrary, Marton and Resnik (2008) andCherry (2008) accumulate a count whenever hy-potheses violate constituent boundaries.
Theseconstituent matching/violation counts are used asa feature in the decoder?s log-linear model andtheir weights are tuned via minimal error ratetraining (MERT) (Och, 2003).
In this way, syn-tactic constraint is integrated into decoding as asoft constraint to enable the decoder to reward hy-potheses that respect syntactic analyses or to pe-1This word can be translated into ?section?, ?festival?,and ?knot?
in different contexts.315nalize hypotheses that violate syntactic structures.Although experiments show that this con-stituent matching/violation counting featureachieves significant improvements on variouslanguage-pairs, one issue is that matching syn-tactic analysis can not always guarantee a goodtranslation, and violating syntactic structure doesnot always induce a bad translation.
Marton andResnik (2008) find that some constituency typesfavor matching the source parse while othersencourage violations.
Therefore it is necessary tointegrate more syntactic constraints into phrasetranslation, not just the constraint of constituentmatching/violation.The other issue is that during decoding we aremore concerned with the question of phrase co-hesion, i.e.
whether the current phrase can betranslated as a unit or not within particular syntac-tic contexts (Fox, 2002)2, than that of constituentmatching/violation.
Phrase cohesion is one ofthe main reasons that we introduce syntactic con-straints (Cherry, 2008).
If a source phrase remainscontiguous after translation, we refer this type ofphrase bracketable, otherwise unbracketable.
Itis more desirable to translate a bracketable phrasethan an unbracketable one.In this paper, we propose a syntax-driven brack-eting (SDB) model to predict whether a phrase(a sequence of contiguous words) is bracketableor not using rich syntactic constraints.
We parsethe source language sentences in the word-alignedtraining corpus.
According to the word align-ments, we define bracketable and unbracketableinstances.
For each of these instances, we auto-matically extract relevant syntactic features fromthe source parse tree as bracketing evidences.Then we tune the weights of these features us-ing a maximum entropy (ME) trainer.
In this way,we build two bracketing models: 1) a unary SDBmodel (UniSDB) which predicts whether an inde-pendent phrase is bracketable or not; and 2) a bi-nary SDB model(BiSDB) which predicts whethertwo neighboring phrases are bracketable.
Similarto previous methods, our SDB model is integratedinto the decoder?s log-linear model as a feature sothat we can inherit the idea of soft constraints.In contrast to the constituent matching/violationcounting (CMVC) (Chiang, 2005; Marton andResnik, 2008; Cherry, 2008), our SDB model has2Here we expand the definition of phrase to include bothsyntactic and non-syntactic phrases.the following advantages?
The SDB model automatically learns syntac-tic constraints from training data while theCMVC uses manually defined syntactic con-straints: constituency matching/violation.
Inour SDB model, each learned syntactic fea-ture from bracketing instances can be consid-ered as a syntactic constraint.
Therefore wecan use thousands of syntactic constraints toguide phrase translation.?
The SDB model maintains and protects thestrength of the phrase-based approach in abetter way than the CMVC does.
It is able toreward non-syntactic translations by assign-ing an adequate probability to them if thesetranslations are appropriate to particular syn-tactic contexts on the source side, rather thanalways punish them.We test our SDB model against the baselinewhich doest not use any syntactic constraints onChinese-to-English translation.
To compare withthe CMVC, we also conduct experiments using(Marton and Resnik, 2008)?s XP+.
The XP+ ac-cumulates a count for each hypothesis wheneverit violates the boundaries of a constituent with alabel from {NP, VP, CP, IP, PP, ADVP, QP, LCP,DNP}.
The XP+ is the best feature among all fea-tures that Marton and Resnik use for Chinese-to-English translation.
Our experimental results dis-play that our SDB model achieves a substantialimprovement over the baseline and significantlyoutperforms XP+ according to the BLEU metric(Papineni et al, 2002).
In addition, our analysisshows further evidences of the performance gainfrom a different perspective than that of BLEU.The paper proceeds as follows.
In section 2 wedescribe how to learn bracketing instances froma training corpus.
In section 3 we elaborate thesyntax-driven bracketing model, including featuregeneration and the integration of the SDB modelinto phrase-based SMT.
In section 4 and 5, wepresent our experiments and analysis.
And we fi-nally conclude in section 6.2 The Acquisition of BracketingInstancesIn this section, we formally define the bracket-ing instance, comprising two types namely binarybracketing instance and unary bracketing instance.316We present an algorithm to automatically ex-tract these bracketing instances from word-alignedbilingual corpus where the source language sen-tences are parsed.Let c and e be the source sentence and thetarget sentence, W be the word alignment be-tween them, T be the parse tree of c. Wedefine a binary bracketing instance as a tu-ple ?b, ?
(ci..j), ?
(cj+1..k), ?(ci..k)?
where b ?
{bracketable, unbracketable}, ci..j and cj+1..kare two neighboring source phrases and ?
(T, s)(?
(s) for short) is a subtree function which returnsthe minimal subtree covering the source sequences from the source parse tree T .
Note that ?
(ci..k)includes both ?
(ci..j) and ?(cj+1..k).
For the twoneighboring source phrases, the following condi-tions are satisfied:?eu..v, ep..q ?
e s.t.?
(m,n) ?
W, i ?
m ?
j ?
u ?
n ?
v (1)?
(m,n) ?
W, j + 1 ?
m ?
k ?
p ?
n ?
q (2)The above (1) means that there exists a targetphrase eu..v aligned to ci..j and (2) denotes a tar-get phrase ep..q aligned to cj+1..k. If eu..v andep..q are neighboring to each other or all words be-tween the two phrases are aligned to null, we setb = bracketable, otherwise b = unbracketable.From a binary bracketing instance, we derive aunary bracketing instance ?b, ?
(ci..k)?, ignoringthe subtrees ?
(ci..j) and ?
(cj+1..k).Let n be the number of words of c. If we ex-tract all potential bracketing instances, there willbe o(n2) unary instances and o(n3) binary in-stances.
To keep the number of bracketing in-stances tractable, we only record 4 representa-tive bracketing instances for each index j: 1) thebracketable instance with the minimal ?
(ci..k), 2)the bracketable instance with the maximal ?
(ci..k),3) the unbracketable instance with the minimal?
(ci..k), and 4) the unbracketable instance with themaximal ?
(ci..k).Figure 1 shows the algorithm to extract brack-eting instances.
Line 3-11 find all potential brack-eting instances for each (i, j, k) ?
c but only keep4 bracketing instances for each index j: two min-imal and two maximal instances.
This algorithmlearns binary bracketing instances, from which wecan derive unary bracketing instances.1: Input: sentence pair (c, e), the parse tree T of c and theword alignment W between c and e2: < := ?3: for each (i, j, k) ?
c do4: if There exist a target phrase eu..v aligned to ci..j andep..q aligned to cj+1..k then5: Get ?
(ci..j), ?
(cj+1..k), and ?
(ci..k)6: Determine b according to the relationship betweeneu..v and ep..q7: if ?
(ci..k) is currently maximal or minimal then8: Update bracketing instances for index j9: end if10: end if11: end for12: for each j ?
c do13: < := < ?
{bracketing instances from j}14: end for15: Output: bracketing instances <Figure 1: Bracketing Instances Extraction Algo-rithm.3 The Syntax-Driven Bracketing Model3.1 The ModelOur interest is to automatically detect phrasebracketing using rich contextual information.
Weconsider this task as a binary-class classificationproblem: whether the current source phrase s isbracketable (b) within particular syntactic contexts(?(s)).
If two neighboring sub-phrases s1 and s2are given, we can use more inner syntactic con-texts to complete this binary classification task.We construct the syntax-driven bracketingmodel within the maximum entropy framework.
Aunary SDB model is defined as:PUniSDB(b|?
(s), T ) =exp(?i ?ihi(b, ?
(s), T )?b exp(?i ?ihi(b, ?
(s), T )(3)where hi ?
{0, 1} is a binary feature functionwhich we will describe in the next subsection, and?i is the weight of hi.
Similarly, a binary SDBmodel is defined as:PBiSDB(b|?
(s1), ?
(s2), ?
(s), T ) =exp(?i ?ihi(b, ?
(s1), ?
(s2), ?
(s), T )?b exp(?i ?ihi(b, ?
(s1), ?
(s2), ?
(s), T )(4)The most important advantage of ME-basedSDB model is its capacity of incorporating morefine-grained contextual features besides the binaryfeature that detects constituent boundary violationor matching.
By employing these features, wecan investigate the value of various syntactic con-straints in phrase translation.317jingfangpoliceyifengsuoblocklebaozhabombxianchangsceneNNNNNPVPASVVADNNADVPVPNPIPss1s2Figure 2: Illustration of syntax-driven featuresused in SDB.
Here we only show the features forthe source phrase s. The triangle, rounded rect-angle and rectangle denote the rule feature, pathfeature and constituent boundary matching featurerespectively.3.2 Syntax-Driven FeaturesLet s be the source phrase in question, s1 and s2be the two neighboring sub-phrases.
?(.)
is theroot node of ?(.).
The SDB model exploits varioussyntactic features as follows.?
Rule Features (RF)We use the CFG rules of ?
(s), ?
(s1) and?
(s2) as features.
These features capturesyntactic ?horizontal context?
which demon-strates the expansion trend of the sourcephrase s, s1 and s2 on the parse tree.In figure 2, the CFG rule ?ADVP?AD?,?VP?VV AS NP?, and ?VP?ADVPVP?
are used as features for s1, s2 and srespectively.?
Path Features (PF)The tree path ?(s1)..?
(s) connecting ?
(s1)and ?
(s), ?(s2)..?
(s) connecting ?
(s2)and ?
(s), and ?(s)..?
connecting ?
(s) andthe root node ?
of the whole parse tree areused as features.
These features providesyntactic ?vertical context?
which shows thegeneration history of the source phrases onthe parse tree.
(a)(b)(c)Figure 3: Three scenarios of the relationship be-tween phrase boundaries and constituent bound-aries.
The gray circles are constituent boundarieswhile the black circles are phrase boundaries.In figure 2, the path features are ?ADVPVP?, ?VP VP?
and ?VP IP?
for s1, s2 and srespectively.?
Constituent Boundary Matching Features(CBMF)These features are to capture the relationshipbetween a source phrase s and ?
(s) or?
(s)?s subtrees.
There are three differentscenarios3: 1) exact match, where s exactlymatches the boundaries of ?
(s) (figure 3(a)),2) inside match, where s exactly spans asequence of ?
(s)?s subtrees (figure 3(b)), and3) crossing, where s crosses the boundariesof one or two subtrees of ?
(s) (figure 3(c)).In the case of 1) or 2), we set the value ofthis feature to ?
(s)-M or ?
(s)-I respectively.When s crosses the boundaries of the sub-constituent ?l on s?s left, we set the value to?
(?l)-LC; If s crosses the boundaries of thesub-constituent ?r on s?s right, we set thevalue to ?
(?r)-RC; If both, we set the valueto ?(?l)-LC-?
(?r)-RC.Let?s revisit the Figure 2.
The sourcephrase s1 exactly matches the constituentADVP, therefore CBMF is ?ADVP-M?.
Thesource phrase s2 exactly spans two sub-treesVV and AS of VP, therefore CBMF is?VP-I?.
Finally, the source phrase s crossboundaries of the lower VP on the right,therefore CBMF is ?VP-RC?.3.3 The Integration of the SDB Model intoPhrase-Based SMTWe integrate the SDB model into phrase-basedSMT to help decoder perform syntax-drivenphrase translation.
In particular, we add a3The three scenarios that we define here are similar tothose in (Lu?
et al, 2002).318new feature into the log-linear translation model:PSDB(b|T, ?(.)).
This feature is computed by theSDB model described in equation (3) or equation(4), which estimates a probability that a sourcespan is to be translated as a unit within partic-ular syntactic contexts.
If a source span can betranslated as a unit, the feature will give a higherprobability even though this span violates bound-aries of a constituent.
Otherwise, a lower proba-bility is given.
Through this additional feature, wewant the decoder to prefer hypotheses that trans-late source spans which can be translated as a unit,and avoids translating those which are discontinu-ous after translation.
The weight of this new fea-ture is tuned via MERT, which measures the extentto which this feature should be trusted.In this paper, we implement the SDB model in astate-of-the-art phrase-based system which adaptsa binary bracketing transduction grammar (BTG)(Wu, 1997) to phrase translation and reordering,described in (Xiong et al, 2006).
Whenever aBTG merging rule (s ?
[s1 s2] or s ?
?s1 s2?
)is used, the SDB model gives a probability to thespan s covered by the rule, which estimates theextent to which the span is bracketable.
For theunary SDB model, we only consider the featuresfrom ?(s).
For the binary SDB model, we use allfeatures from ?
(s1), ?
(s2) and ?
(s) since the bi-nary SDB model is naturally suitable to the binaryBTG rules.The SDB model, however, is not only limitedto phrase-based SMT using BTG rules.
Since itis applied on a source span each time, any otherhierarchical phrase-based or syntax-based systemthat translates source spans recursively or linearly,can adopt the SDB model.4 ExperimentsWe carried out the MT experiments on Chinese-to-English translation, using (Xiong et al, 2006)?ssystem as our baseline system.
We modified thebaseline decoder to incorporate our SDB mod-els as descried in section 3.3.
In order to com-pare with Marton and Resnik?s approach, we alsoadapted the baseline decoder to their XP+ feature.4.1 Experimental SetupIn order to obtain syntactic trees for SDB modelsand XP+, we parsed source sentences using a lex-icalized PCFG parser (Xiong et al, 2005).
Theparser was trained on the Penn Chinese Treebankwith an F1 score of 79.4%.All translation models were trained on the FBIScorpus.
We removed 15,250 sentences, for whichthe Chinese parser failed to produce syntacticparse trees.
To obtain word-level alignments, weran GIZA++ (Och and Ney, 2000) on the remain-ing corpus in both directions, and applied the?grow-diag-final?
refinement rule (Koehn et al,2005) to produce the final many-to-many wordalignments.
We built our four-gram languagemodel using Xinhua section of the English Gi-gaword corpus (181.1M words) with the SRILMtoolkit (Stolcke, 2002).For the efficiency of MERT, we built our de-velopment set (580 sentences) using sentences notexceeding 50 characters from the NIST MT-02 set.We evaluated all models on the NIST MT-05 setusing case-sensitive BLEU-4.
Statistical signif-icance in BLEU score differences was tested bypaired bootstrap re-sampling (Koehn, 2004).4.2 SDB TrainingWe extracted 6.55M bracketing instances from ourtraining corpus using the algorithm shown in fig-ure 1, which contains 4.67M bracketable instancesand 1.89M unbracketable instances.
From ex-tracted bracketing instances we generated syntax-driven features, which include 73,480 rule fea-tures, 153,614 path features and 336 constituentboundary matching features.
To tune weights offeatures, we ran the MaxEnt toolkit (Zhang, 2004)with iteration number being set to 100 and Gaus-sian prior to 1 to avoid overfitting.4.3 ResultsWe ran the MERT module with our decoders totune the feature weights.
The values are shownin Table 1.
The PSDB receives the largest featureweight, 0.29 for UniSDB and 0.38 for BiSDB, in-dicating that the SDB models exert a nontrivial im-pact on decoder.In Table 2, we present our results.
Like (Mar-ton and Resnik, 2008), we find that the XP+ fea-ture obtains a significant improvement of 1.08BLEU over the baseline.
However, using allsyntax-driven features described in section 3.2,our SDB models achieve larger improvementsof up to 1.67 BLEU.
The binary SDB (BiSDB)model statistically significantly outperforms Mar-ton and Resnik?s XP+ by an absolute improvementof 0.59 (relatively 2%).
It is also marginally betterthan the unary SDB model.319FeaturesSystem P (c|e) P (e|c) Pw(c|e) Pw(e|c) Plm(e) Pr(e) Word Phr.
XP+ PSDBBaseline 0.041 0.030 0.006 0.065 0.20 0.35 0.19 -0.12 ?
?XP+ 0.002 0.049 0.046 0.044 0.17 0.29 0.16 0.12 -0.12 ?UniSDB 0.023 0.051 0.055 0.012 0.21 0.20 0.12 0.04 ?
0.29BiSDB 0.016 0.032 0.027 0.013 0.13 0.23 0.08 0.09 ?
0.38Table 1: Feature weights obtained by MERT on the development set.
The first 4 features are the phrasetranslation probabilities in both directions and the lexical translation probabilities in both directions.
Plm= language model; Pr = MaxEnt-based reordering model; Word = word bonus; Phr = phrase bonus.BLEU-n n-gram PrecisionSystem 4 1 2 3 4 5 6 7 8Baseline 0.2612 0.71 0.36 0.18 0.10 0.054 0.030 0.016 0.009XP+ 0.2720** 0.72 0.37 0.19 0.11 0.060 0.035 0.021 0.012UniSDB 0.2762**+ 0.72 0.37 0.20 0.11 0.062 0.035 0.020 0.011BiSDB 0.2779**++ 0.72 0.37 0.20 0.11 0.065 0.038 0.022 0.014Table 2: Results on the test set.
**: significantly better than baseline (p < 0.01).
+ or ++: significantlybetter than Marton and Resnik?s XP+ (p < 0.05 or p < 0.01, respectively).5 AnalysisIn this section, we present analysis to perceive theinfluence mechanism of the SDB model on phrasetranslation by studying the effects of syntax-drivenfeatures and differences of 1-best translation out-puts.5.1 Effects of Syntax-Driven FeaturesWe conducted further experiments using individ-ual syntax-driven features and their combinations.Table 3 shows the results, from which we have thefollowing key observations.?
The constituent boundary matching feature(CBMF) is a very important feature, whichby itself achieves significant improvementover the baseline (up to 1.13 BLEU).
Bothour CBMF and Marton and Resnik?s XP+feature focus on the relationship between asource phrase and a constituent.
Their signifi-cant contribution to the improvement impliesthat this relationship is an important syntacticconstraint for phrase translation.?
Adding more features, such as path featureand rule feature, achieves further improve-ments.
This demonstrates the advantage ofusing more syntactic constraints in the SDBmodel, compared with Marton and Resnik?sXP+.BLEU-4Features UniSDB BiSDBPF + RF 0.2555 0.2644*@@PF 0.2596 0.2671**@@CBMF 0.2678** 0.2725**@RF + CBMF 0.2737** 0.2780**++@@PF + CBMF 0.2755**+ 0.2782**++@?RF + PF + CBMF 0.2762**+ 0.2779**++Table 3: Results of different feature sets.
* or **:significantly better than baseline (p < 0.05 or p <0.01, respectively).
+ or ++: significantly betterthan XP+ (p < 0.05 or p < 0.01, respectively).@?
: almost significantly better than its UniSDBcounterpart (p < 0.075).
@ or @@: significantlybetter than its UniSDB counterpart (p < 0.05 orp < 0.01, respectively).?
In most cases, the binary SDB is constantlysignificantly better than the unary SDB, sug-gesting that inner contexts are useful in pre-dicting phrase bracketing.5.2 Beyond BLEUWe want to further study the happenings after weintegrate the constraint feature (our SDB modeland Marton and Resnik?s XP+) into the log-lineartranslation model.
In particular, we want to inves-tigate: to what extent syntactic constraints changetranslation outputs?
And in what direction thechanges take place?
Since BLEU is not sufficient320System CCM Rate (%)Baseline 43.5XP+ 74.5BiSDB 72.4Table 4: Consistent constituent matching rates re-ported on 1-best translation outputs.to provide such insights, we introduce a new sta-tistical metric which measures the proportion ofsyntactic constituents 4 whose boundaries are con-sistently matched by decoder during translation.This proportion, which we call consistent con-stituent matching (CCM) rate , reflects the ex-tent to which the translation output respects thesource parse tree.In order to calculate this rate, we output transla-tion results as well as phrase alignments found bydecoders.
Then for each multi-branch constituentcji spanning from i to j on the source side, wecheck the following conditions.?
If its boundaries i and j are aligned to phrasesegmentation boundaries found by decoder.?
If all target phrases inside cji ?s target span 5are aligned to the source phrases within cjiand not to the phrases outside cji .If both conditions are satisfied, the constituent cjiis consistently matched by decoder.Table 4 shows the consistent constituent match-ing rates.
Without using any source-side syntac-tic information, the baseline obtains a low CCMrate of 43.53%, indicating that the baseline de-coder violates the source parse tree more than itrespects the source structure.
The translation out-put described in section 1 is actually generated bythe baseline decoder, where the second NP phraseboundaries are violated.By integrating syntactic constraints into decod-ing, we can see that both Marton and Resnik?sXP+ and our SDB model achieve a significantlyhigher constituent matching rate, suggesting thatthey are more likely to respect the source struc-ture.
The examples in Table 5 show that the de-coder is able to generate better translations if it is4We only consider multi-branch constituents.5Given a phrase alignment P = {cgf ?
eqp}, if the seg-mentation within cji defined by P is cji = cj1i1 ...cjkik , andcjrir ?
evrur ?
P, 1 ?
r ?
k, we define the target span of cjias a pair where the first element is min(eu1 ...euk ) and thesecond element is max(ev1 ...evk ), similar to (Fox, 2002).CCM Rates (%)System <6 6-10 11-15 16-20 >20XP+ 75.2 70.9 71.0 76.2 82.2BiSDB 69.3 74.7 74.2 80.0 85.6Table 6: Consistent constituent matching rates forstructures with different spans.faithful to the source parse tree by using syntacticconstraints.We further conducted a deep comparison oftranslation outputs of BiSDB vs. XP+ with re-gard to constituent matching and violation.
Wefound two significant differences that may explainwhy our BiSDB outperforms XP+.
First, althoughthe overall CCM rate of XP+ is higher than thatof BiSDB, BiSDB obtains higher CCM rates forlong-span structures than XP+ does, which areshown in Table 6.
Generally speaking, viola-tions of long-span constituents have a more neg-ative impact on performance than short-span vio-lations if these violations are toxic.
This explainswhy BiSDB achieves relatively higher precisionimprovements for higher n-grams over XP+, asshown in Table 3.Second, compared with XP+ that only punishesconstituent boundary violations, our SDB modelis able to encourage violations if these violationsare done on bracketable phrases.
We observed inmany cases that by violating constituent bound-aries BiSDB produces better translations than XP+does, which on the contrary matches these bound-aries.
Still consider the example shown in section1.
The following translations are found by XP+and BiSDB respectively.XP+: [to/?
?
[set up/??
[for the/?
[naviga-tion/??
section/?]]]
on July 11/7?11??
]BiSDB: [to/?
?
[[set up/??
a/?]
[marine/??festival/?]]
on July 11/7?11??
]XP+ here matches all constituent boundaries whileBiSDB violates the PP constituent to translate thenon-syntactic phrase ???
??.
Table 7 showsmore examples.
From these examples, we clearlysee that appropriate violations are helpful and evennecessary for generating better translations.
Byallowing appropriate violations to translate non-syntactic phrases according to particular syntac-tic contexts, our SDB model better inherits thestrength of phrase-based approach than XP+.321Src: [[?
[???????
]NP ]PP [??
[??
]NP [????
]NP ]VP ]VPRef: show their loving hearts to people in the Indian Ocean disaster areasBaseline: ?love/??
[for the/?
?[people/??
[to/??
[own/??
a report/??]]]?
?in/??
the Indian Ocean/????
]?XP+: ?[contribute/??
[its/??
[part/??
love/??]]]
[for/?
?the people/??
?in/??
the Indian Ocean/?????
]?BiSDB: ?[[[contribute/??
its/??]
part/??]
love/??]
[for/?
?the people/??
?in/??
the Indian Ocean?????
]?Src: [????
[?
]ADVP [??
[[???
]QP ??
]NP [???
]PP]VP]IP [?
]PU [????...
]IPRef: The Pentagon has dispatched 20 airplanes to South Asia, including...Baseline: [[The Pentagon/????
has sent/???]
[?[to/?
[[South Asia/??
,/?]
including/????]]
[20/??
plane/???]?
]]XP+: [The Pentagon/????
[has/?
[sent/??
[[20/??
planes/???]
[to/?
South Asia/??]]]]]
[,/?[including/????...
]]BiSDB: [The Pentagon/????
[has sent/???
[[20/??
planes/???]
[to/?
South Asia/??]]]
[,/?
[in-cluding/????...
]]Table 5: Translation examples showing that both XP+ and BiSDB produce better translations than thebaseline, which inappropriately violates constituent boundaries (within underlined phrases).Src: [[?
[[[????????
]NP [??
]ADJP [??
]NP]NP ?
]LCP]PP ??
]VPRef: said after a brief discussion with Powell at the US State DepartmentXP+: [?after/?
??
[a brief/??
meeting/??]
[with/?
Powell/??]?
[in/?
the US State Department/?????]?
said/??
]BiSDB: ?said after/???
?
[a brief/??
meeting/??]
?
with Powell/???
[at/?
the State Department of theUnited States/?????]??
?Src: [?
[[??
[??????
]NP]VP]IP]PP [???
[??????
]NP]VPRef: took a key step towards building future democratic politicsXP+: ?[a/?
[key/???
step/???]]
?forward/??
[to/?
[a/??
[future/??
political democracy/????]]]?
?BiSDB: ?
[made a/???
[key/???
step/???]]
[towards establishing a/???
?democratic politics/????
in the future/???
]?Table 7: Translation examples showing that BiSDB produces better translations than XP+ via appropriateviolations of constituent boundaries (within double-underlined phrases).6 ConclusionIn this paper, we presented a syntax-driven brack-eting model that automatically learns bracketingknowledge from training corpus.
With this knowl-edge, the model is able to predict whether sourcephrases can be translated together, regardless ofmatching or crossing syntactic constituents.
Weintegrate this model into phrase-based SMT toincrease its capacity of linguistically motivatedtranslation without undermining its strengths.
Ex-periments show that our model achieves substan-tial improvements over baseline and significantlyoutperforms (Marton and Resnik, 2008)?s XP+.Compared with previous constituency feature,our SDB model is capable of incorporating moresyntactic constraints, and rewarding necessary vi-olations of the source parse tree.
Marton andResnik (2008) find that their constituent con-straints are sensitive to language pairs.
In the fu-ture work, we will use other language pairs to testour models so that we could know whether ourmethod is language-independent.ReferencesColin Cherry.
2008.
Cohesive Phrase-based Decodingfor Statistical Machine Translation.
In Proceedingsof ACL.David Chiang.
2005.
A Hierarchical Phrase-basedModel for Statistical Machine Translation.
In Pro-ceedings of ACL, pages 263?270.David Chiang, Yuval Marton and Philip Resnik.
2008.Online Large-Margin Training of Syntactic andStructural Translation Features.
In Proceedings ofEMNLP.Heidi J.
Fox 2002.
Phrasal Cohesion and StatisticalMachine Translation.
In Proceedings of EMNLP,pages 304?311.Philipp Koehn, Franz Joseph Och, and Daniel Marcu.2003.
Statistical Phrase-based Translation.
In Pro-ceedings of HLT-NAACL.322Philipp Koehn.
2004.
Statistical Significance Tests forMachine Translation Evaluation.
In Proceedings ofEMNLP.Philipp Koehn, Amittai Axelrod, Alexandra BirchMayne, Chris Callison-Burch, Miles Osborne andDavid Talbot.
2005.
Edinburgh System Descrip-tion for the 2005 IWSLT Speech Translation Eval-uation.
In International Workshop on Spoken Lan-guage Translation.Yajuan Lu?, Sheng Li, Tiezhun Zhao and Muyun Yang.2002.
Learning Chinese Bracketing KnowledgeBased on a Bilingual Language Model.
In Proceed-ings of COLING.Yuval Marton and Philip Resnik.
2008.
Soft SyntacticConstraints for Hierarchical Phrase-Based Transla-tion.
In Proceedings of ACL.Franz Josef Och and Hermann Ney.
2000.
ImprovedStatistical Alignment Models.
In Proceedings ofACL 2000.Franz Josef Och.
2003.
Minimum Error Rate Trainingin Statistical Machine Translation.
In Proceedingsof ACL 2003.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
Bleu: a Method for AutomaticallyEvaluation of Machine Translation.
In Proceedingsof ACL.Andreas Stolcke.
2002.
SRILM - an Extensible Lan-guage Modeling Toolkit.
In Proceedings of Interna-tional Conference on Spoken Language Processing,volume 2, pages 901-904.Dekai Wu.
1997.
Stochastic Inversion TransductionGrammars and Bilingual Parsing of Parallel Cor-pora.
Computational Linguistics, 23(3):377-403.Deyi Xiong, Shuanglong Li, Qun Liu, Shouxun Lin,Yueliang Qian.
2005.
Parsing the Penn ChineseTreebank with Semantic Knowledge.
In Proceed-ings of IJCNLP, Jeju Island, Korea.Deyi Xiong, Qun Liu and Shouxun Lin.
2006.
Max-imum Entropy Based Phrase Reordering Model forStatistical Machine Translation.
In Proceedings ofACL-COLING 2006.Deyi Xiong, Min Zhang, Aiti Aw, and Haizhou Li.2008.
Linguistically Annotated BTG for StatisticalMachine Translation.
In Proceedings of COLING2008.Le Zhang.
2004.
Maximum Entropy Model-ing Tooklkit for Python and C++.
Available athttp://homepages.inf.ed.ac.uk/s0450736/maxent toolkit.html.323
