Proceedings of the 8th International Natural Language Generation Conference, pages 95?98,Philadelphia, Pennsylvania, 19-21 June 2014. c?2014 Association for Computational LinguisticsGenerating Summaries of Line GraphsPriscilla Moraes, Gabriel Sina, Kathleen McCoy and Sandra CarberryDepartment of Computer and Information SciencesUniversity of Delaware, Newark, Delaware, USA[pmoraes | gsina | mccoy | carberry]@udel.eduAbstractThis demo presents a Natural Language Gener-ation (NLG) system that generates summariesof informational graphics, specifically simpleline graphs, present in popular media.
The sys-tem is intended to capture the high-levelknowledge conveyed by the graphic and its out-standing visual features.
It comprises a contentselection phase that extracts the most importantcontent of the graphic, an organization phase,which orders the propositions in a coherentmanner, and a realization phase that uses thetext surrounding the article to make decisionson the choice of lexical items and amount of ag-gregation applied to the propositions to gener-ate the summary of the graphic.1 IntroductionMultimodal documents from online popular me-dia often contain information graphics that aug-ment the information found in the text.
Thesegraphics, however, are inaccessible for visuallyimpaired users or in environments where the im-age cannot be processed/displayed.
Our systemcaptures the high-level content of the graphic andproduces a textual summary that conveys it.
Fig-ure 1 shows the system architecture.The first step is the identification of the pres-ence of a graphical image in the web page by aBrowser Helper Object (BHO) (Elzer et al., 2007).If a graphic is present on the web page, the Graph-ical Information Extraction Module (VEM)(Chester & Elzer, 2005) is triggered by the BHOin order to extract the data from the image.
TheVEM then produces an XML representation of thegraphic that is used by the Intention RecognitionModule (IRM) for simple bar charts (Elzer,Green, Carberry, & Hoffman, 2006), simple linegraphs (Wu, Carberry, Elzer, & Chester, 2010)and grouped bar charts (R. Burns, Carberry, &Elzer, 2010; R. Burns, Carberry, & Schwartz,2013; R. J. Burns, 2013).
The XML representation1 http://ir.cis.udel.edu/~moraes/udgraphsof the graphic, along with the intended messageidentified by the IRM, is sent to the GenerationModule (GM), which produces a textual summaryof the most important content presented in thegraphic.
The system produces an initial summaryand follow-up responses for simple bar charts(Demir, Carberry, & Elzer, 2009; Demir,Carberry, & McCoy, 2008) and this demo pre-sents the GM for simple line graphs.This demo focuses on presenting the generationphase of the system.
For that, we will demonstratethe generation of summaries in the context of adigital library that is available online 1 and thatcontains information graphics collected fromonline popular media, along with the articles con-taining the graphics.
In addition, we have includedhand-generated XML representations for thegraphics (the current VEM is not fully robust).
Foreach article that contains a graph, the user canchoose to have access to the generated summaryby clicking on the ?Generate summary?
button(highlighted in Figure 2).
Figure 2 shows a screen-shot on which the graph shown in Figure 3 has itsarticle featured.For accessibility projects that may use our sys-tem (applications developed for visually impairedusers, for example), the application might use acombination of key strokes to allow user interac-tion.
The module of the system that is the focus ofthis demo is the Generation Module.Figure 1: System Architecture95Figure 2: Digital library screenshot where we have added summary generation functionality.2 Generation ModuleFor generating summaries of line graphs, the firststep is the selection of content.
In order to selectthe most important features of the line graph thatshould be conveyed in the summary, the systemrepresents the intended message and the visualfeatures identified by a human subject experiment(Greenbacker, Carberry, & McCoy, 2011) using agraph.
A centrality-based algorithm, which is anadapted version of PageRank (Page, Brin,Motwani, & Winograd, 1999), is then imple-mented to select the most important information(represented as nodes in the graph).
This imple-mentation allows semantic relationships betweenpropositions to be represented on the edges of thegraph.
The core of the content selection frame-work is to detect present outstanding visual fea-tures in the graphic, along with its intended mes-sage, in order to select nodes.
Details in the con-tent selection phase are available in the work pre-sented at (P. S. Moraes, Carberry, & McCoy,2013).The next phase is the organization of the se-lected content.
The organization phase works byordering the selected propositions such that thedelivered summary is fluent and coherent.
Thesummaries are organized having an introductionsection, a detailed section and a conclusion.
Theintroduction consists of overall information aboutthe line graph (the type of the graph, the entity be-ing measured, the volatility of the graph and itsintended message).
The identified trends are de-scribed in the detail section.
For this part of thesummary, pieces of the graphic that outstand dueto its visual features may be described first, beingfollowed by other trends.
Finally, the conclusionsection of the summary presents computationalinformation about the graphic (overall value andrate change, time span of the graphic, maximumand minimum points and dates when they occur).The strategies on organizing the summaries aredescribed in (P. Moraes, McCoy, & Carberry,2014).The last step of the Generation Module is theaggregation of propositions into more complexsentences.
This decision is usually left to the de-signer?s choice on how much aggregation to per-form when generating text.
Some systems are de-signed to generate simple text for people with lowreading abilities (Williams & Reiter, 2005a).
Asstated by (Williams & Reiter, 2005b), most NLGsystems available generate text for high-skilledusers.
Our system generates line graph summariesthat fit the reading level of the article in which theline graph appears.
We contend that users gener-ally read articles from venues they feel comforta-ble with reading.
In this manner, we intrinsicallyassess the user?s reading level without needing toactively survey it.Figure 3: A line graph present in popular media.96The first step of the aggregation phase is to as-sess the reading level of the article?s text.
There isa myriad of techniques to measure the readinglevel of text.
Much of them use machine learningtechniques in order to learn text constructions andlexicalization used in different grade levels.
Aspresented in (P. Moraes et al., 2014), simpler andwell established reading level measurement tech-niques suffice for our scenario.
The work showsthat Flesh-Kincaid (Kincaid, Fishburne, Rogers,& Chissom, 1975) and SMOG (Laughlin, 1969)provide the set of information needed by the sys-tem in order to make decisions of syntactical textcomplexity.After assessing the reading level of the article,the system then uses the text plan that applies tothe identified reading level.
Text plans definerules on Noun Phrase (NP) density and lexicalchoice.
When describing an entity, attributes ofthis entity can be added to the NP as modifiers us-ing either adjectives e.g.
?a highly volatile risingtrend?, conjunctions e.g., ?the rising trend is vol-atile and steep?
or relative clauses e.g.
?a risingtrend, which is highly volatile?.
When the modi-fier of an NP is a Verb Phrase (VP), it is combinedusing a relative clause e.g., ?the line graph, whichpresents the number of jackets sold in 2013...?VPs can be modified by adverbs e.g., ?the fallingtrend is very steep?.
The text plans apply ruleswithin sets of propositions that are grouped hier-archically.
The system then uses the appropriatelexical items (highly volatile vs ups and downs;conveys vs shows) and applies the appropriateamount of aggregation in order to realize sen-tences.Figure 4: Pop up window with the resulting sum-mary generated by the system.Figure 4 and Figure 5 display the summariesgenerated for a user whose reading level is 11th-13th grade and 5th-7th grade respectively.
Fromthese one can see the different aggregation andlexical choice decisions made for the differentreading levels.
The system also includes appropri-ate pronominalization in order to avoid repetitionof the referring expressions (P. Moraes et al.,2014).Figure 5: Example of a summary adapted to thereading level of grades 5 to 7.For the surface realization phase we useFUF/SURGE (Elhadad & Robin, 1999) to createthe templates for realization.
The template are cre-ated based on the text plans defined for a givenreading level, as described above.3 ConclusionThis paper presents the demonstration of the gen-eration module of SIGHT.
For the demo, the gen-eration module works on a digital library that ar-chives informational graphics collected from pop-ular media available online.
The aggregationphase of the generation module tailors the syntac-tical complexity of the generated text to that of thearticle?s text in which the graphic appears.An evaluation of the text summaries generatedat different reading level is presented at (P.Moraes et al., 2014).
It shows that, indeed, differ-ent users have different preferences regarding dif-ferent text designs.4 Future WorkA more automated way of defining a text plan fora given reading level is under investigation.
Wewill explore techniques for learning how differenttext constructions can affect reading measures andthen using these learned models when choosing an97adjective over a relative clause for increasing theNP density and use of passive voice, for example.Choosing lexical items that are classified byage is another possibility.
We plan on investigat-ing how the usage of word frequency by age/gradelevel (Carroll, 1972) might influence the overallgenerated summaries.5 AcknowledgementGabriel Sina was supported by the Coor-dena?
?o de Aperfei?oamento de Pessoal de N?velSuperior from Brazil CAPES ?
in Portuguese.ReferencesBurns, R., Carberry, S., & Elzer, S. (2010).
Visual andspatial factors in a bayesian reasoningframework for the recognition of intendedmessages in grouped bar charts.
Paperpresented at the Proceedings of the AAAIWorkshop on Visual Representations andReasoning.Burns, R., Carberry, S., & Schwartz, S. E. (2013).Modeling a Graph Viewer's Effort inRecognizing Messages Conveyed by GroupedBar Charts.
Paper presented at the UMAP.Burns, R. J.
(2013).
Automated intention recognition ofgrouped bar charts in multimodal documents.University of Delaware, Ann Arbor.Retrieved fromhttp://search.proquest.com/docview/1318643227?accountid=10457Carroll, J.
B.
(1972).
A New Word Frequency Book.Elementary English, 49(7), pp.
1070-1074.Chester, D., & Elzer, S. (2005).
Getting computers tosee information graphics so users do not haveto.
Paper presented at the the Proceedings ofthe 15th International Symposium onMethodologies for Intelligent Systems.Demir, S., Carberry, S., & Elzer, S. (2009).
Issues inRealizing the Overall Message of a Bar Chart.In N. Nicolov, G. Angelova & R.
Mitkov(Eds.
), Recent Advances in Natural LanguageProcessing V (pp.
311-320): John Benjamins.Demir, S., Carberry, S., & McCoy, K. F. (2008).Generating textual summaries of bar charts.Paper presented at the Proceedings of theFifth International Natural LanguageGeneration Conference, Stroudsburg, PA,USA.Elhadad, M., & Robin, J.
(1999).
SURGE: acomprehensive plug-in syntactic realizationcomponent for text generation.Computational Linguistics.Elzer, S., Green, N., Carberry, S., & Hoffman, J.(2006).
A Model of Perceptual Task Effort forBar Charts and its Role in RecognizingIntention.
International Journal on UserModeling and User-Adapted Interaction,16(1), 1-30.Elzer, S., Schwartz, E., Carberry, S., Chester, D.,Demir, S., & Wu, P. (2007).
A BrowserExtension For Providing Visually ImpairedUsers Access To The Content Of Bar ChartsOn The Web.
Paper presented at the theProceedings of the International Conferenceon Web Information Systems andTechnologies.Greenbacker, C., Carberry, S., & McCoy, K. (2011,July).
A Corpus of Human-written Summariesof Line Graphs.
Paper presented at theProceedings of the UCNLG+Eval: LanguageGeneration and Evaluation Workshop,Edinburgh, Scotland.Kincaid, J. P., Fishburne, R. P., Rogers, R. L., &Chissom, B. S. (1975).
Derivation of NewReadability Formulas (AutomatedReadability Index, Fog Count and FleschReading Ease Formula) for Navy EnlistedPersonnel.Laughlin, G. H. M. (1969).
SMOG Grading-a NewReadability Formula.
Journal of Reading,12(8), pp.
639-646.Moraes, P., McCoy, K., & Carberry, S. (2014).Adapting Graph Summaries to the Users?Reading Levels.
Paper presented at theProceedings of the 8th International NaturalLanguage Generation Conference.Moraes, P. S., Carberry, S., & McCoy, K. (2013).Providing access to the high-level content ofline graphs from online popular media.
Paperpresented at the Proceedings of the 10thInternational Cross-Disciplinary Conferenceon Web Accessibility, Rio de Janeiro, Brazil.Page, L., Brin, S., Motwani, R., & Winograd, T.(1999).
The PageRank Citation Ranking:Bringing Order to the Web: Stanford InfoLab.Williams, S., & Reiter, E. (2005a).
AppropriateMicroplanning Choices for Low-SkilledReaders.
Paper presented at the IJCAI.Williams, S., & Reiter, E. (2005b).
Generatingreadable texts for readers with low basicskills.
Paper presented at the Proceedings ofthe 10th European Workshop on NaturalLanguage Generation (EWNLG 2005).Wu, P., Carberry, S., Elzer, S., & Chester, D. (2010).Recognizing the intended message of linegraphs.
Paper presented at the Proceedings ofthe 6th international conference onDiagrammatic representation and inference,Berlin, Heidelberg.98
