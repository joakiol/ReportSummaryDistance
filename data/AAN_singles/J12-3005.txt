Modeling Regular Polysemy: A Study on theSemantic Classification of Catalan AdjectivesGemma Boleda?Universitat Pompeu FabraSabine Schulte im Walde?
?University of StuttgartToni Badia?Universitat Pompeu FabraWe present a study on the automatic acquisition of semantic classes for Catalan adjectives fromdistributional and morphological information, with particular emphasis on polysemous adjec-tives.
The aim is to distinguish and characterize broad classes, such as qualitative (gran ?big?
)and relational (pulmonar ?pulmonary?)
adjectives, as well as to identify polysemous adjectivessuch as econo`mic (?economic | cheap?).
We specifically aim at modeling regular polysemy, thatis, types of sense alternations that are shared across lemmata.
To date, both semantic classes foradjectives and regular polysemy have only been sparsely addressed in empirical computationallinguistics.Two main specific questions are tackled in this article.
First, what is an adequate broadsemantic classification for adjectives?
We provide empirical support for the qualitative andrelational classes as defined in theoretical work, and uncover one type of adjective that hasnot received enough attention, namely, the event-related class.
Second, how is regular polysemybest modeled in computational terms?
We present two models, and argue that the second one,which models regular polysemy in terms of simultaneous membership to multiple basic classes,is both theoretically and empirically more adequate than the first one, which attempts to identifyindependent polysemous classes.
Our best classifier achieves 69.1% accuracy, against a 51%baseline.1.
IntroductionAdjectives are one of the most elusive parts of speech with respect to meaning.
Forexample, it is very difficult to establish a broad classification of adjectives into semanticclasses, analogous to a broad ontological classification of nouns (Raskin and Nirenburg?
Department of Translation and Language Sciences, Universitat Pompeu Fabra, Roc Boronat 138, 08018Barcelona, Spain.
E-mail: gemma.boleda@upf.edu.??
E-mail: schulte@ims.uni-stuttgart.de.?
E-mail: toni.badia@upf.edu.Submission received: 10 December 2008; revised submission received: 16 July 2011; accepted for publication:5 September 2011.
Part of the work reported in this article was done while the first author was a postdoctoralscholar at U. Polite`cnica de Catalunya and a visiting researcher at U.
Stuttgart.?
2012 Association for Computational LinguisticsComputational Linguistics Volume 38, Number 31998).
This article tackles precisely this task, that is, the semantic classification of adjectives,for Catalan.
We aim at automatically inducing the semantic class for an adjective givenits linguistic properties, as extracted from corpora and other resources.The acquisition of semantic classes has been widely studied for verbs (Dorr andJones 1996; McCarthy 2000; Korhonen, Krymolowski, and Marx 2003; Lapata and Brew2004; Schulte im Walde 2006; Joanis, Stevenson, and James 2008) and, to a lesser extent,for nouns (Hindle 1990; Pereira, Tishby, and Lee 1993), but, with very few exceptions(Bohnet, Klatt, and Wanner 2002; Carvalho and Ranchhod 2003), not for adjectives.
Fur-thermore, we cannot rely on a well-established classification for adjectives.
The classesthemselves are subject to experimentation.
We will test two different classifications,analyzing the empirical properties of the classes and the problems in their definition.Another significant challenge is posed by polysemy, or the fact that one and thesame adjective can have multiple senses.
Different senses may fall into different classes,such that it is no longer possible to identify one single semantic class per adjective.Moreover, many adjectives exhibit similar sense alternations, in a phenomenon knownas regular or systematic polysemy (Apresjan 1974; Copestake and Briscoe 1995).
A specialfocus of the research presented, therefore, is on modeling regular polysemy.
As anexample of regular polysemy, take for instance the sense alternation for the adjectiveecono`mic exemplified in Example (1).
Econo`mic, derived from economia (?economy?
), canbe translated as ?economic, of the economy?, as in Example (1a), or as ?cheap?, as inExample (1b).
As we will see, each of these senses corresponds to a different semanticclass in our classifications.
(1) a. recuperacio?recoveryecono`micaeconomySUFFIX?recovery of the economy?b.
pantalonstrousersecono`micseconomySUFFIX?cheap trousers?Other adjectives exhibit similar sense alternations; for example, familiar (derivedfrom fam?
?lia, ?family?)
and amoro?s (derived from amor, ?love?
), as shown in Example (2).
(2) a. reunio?meetingfamiliarfamilySUFFIX//facecarafamilySUFFIXfamiliar?family meeting / familiar face?b.
problemaproblemamoro?sloveSUFFIX//boynoiloveSUFFIXamoro?s?love problem / lovely boy?The first senses in Examples (1) and (2) have a transparent relation to the denotation ofthe deriving noun, as witnessed by the fact that they are translated as nouns in English(economy, family, love), whereas the other senses are translated as adjectives (cheap, famil-iar, lovely).
For each of these adjectives, there is a relationship between the two senses,such that the sense alternations seem to correspond to a productive semantic processalong the lines of Example (3) (Raskin and Nirenburg 1998, schema (43), page 173).
(3) PERTAINING TO [noun meaning]?
CHARACTERISTIC OF [noun meaning]576Boleda, Schulte im Walde, and Badia Modeling Regular Polysemy in Catalan AdjectivesBecause of the systematic semantic relationship between the two senses of these adjec-tives, they constitute an instance of regular polysemy.
In this article, therefore, we notonly address the acquisition of semantic classes, but also the acquisition of polysemy: Ourgoal is to determine, for a given adjective, whether it is monosemous or polysemous,and to which class(es) it belongs.
Note that we are not dealing with individual sensealternations, as related work on sense induction does (Schu?tze 1998; McCarthy et al2004; Brody and Lapata 2009), but with sense alternation types, that systematically holdacross different lemmata.
Thus, the present research is at the crossroad between senseinduction and lexical acquisition.Regularities in sense alternations are pervasive in human languages, and theyare probably favored by the properties of human cognition (Murphy 2002).
Regularpolysemy has been studied in theoretical linguistics (Apresjan 1974; Pustejovsky 1995)and in symbolic approaches to computational semantics (Copestake and Briscoe 1995).It has received little attention in empirical computational semantics, however.
Thisis surprising, given the amount of work devoted to sense-related tasks such as WordSense Disambiguation (WSD).
In WSD (see Navigli [2009] for an overview) senseambiguities are almost exclusively modeled for each individual lemma, despite theensuing sparsity problems (Ando [2006] is an exception).
Properly modeling regularpolysemy, therefore, promises to improve computational semantic tasks such as WSDand sense discrimination.This article has the goal of finding a computational model that responds to thetheoretical and empirical properties of regular polysemy.
In this direction, we test twoalternative approaches.
We first model polysemy in terms of independent classes to beseparately acquired (e.g., an adjective with two senses ai and bi belongs to a class ABdefined independently of classes A and B), and show that this model is not adequate.A second approach, which posits that polysemous adjectives simultaneously belong tomore than one class (e.g., an adjective with two senses ai and bi belongs to both classA and class B), is more successful.
Our best classifier achieves 69.1% accuracy against a51% baseline, which is satisfactory, considering that the estimated upper bound (humanagreement) for this task is 68%.
We discuss pros and cons of the two models describedand ways to overcome their limitations.In the following, we first review related work (Section 2) and linguistic aspectsof adjective classification (Section 3), then present the two acquisition experiments(Sections 4 and 5), and finish with a general discussion (Section 6) and some conclusionsand directions for future research (Section 7).2.
Related WorkAs mentioned in the Introduction, there has been very little research in the semanticclassification of adjectives.
We know of only two articles on specifically this topic:Carvalho and Ranchhod (2003) used adjective classes similar to the ones explored hereto disambiguate between nominal and adjectival readings in Portuguese.
Adjectiveinformation, manually coded, served to establish constraints in a finite-state transducerpart-of-speech tagger.
Actually, POS tagging was also the initial motivation for thepresent research, as adjective?noun and adjective?verb (participle) ambiguities causemost difficulties to both humans and machines in languages such as English, German,and Catalan (Marcus, Santorini, and Marcinkiewicz 1993; Brants 2000; Boleda 2007).Bohnet, Klatt, and Wanner (2002) also has similar goals to the present research, as itis aimed at automatically classifying German adjectives.
However, the classification577Computational Linguistics Volume 38, Number 3used is not purely semantic, polysemy is not taken into account, and the evidence andtechniques used are more limited than the ones used here.Other research on adjectives within computational linguistics is oriented towarddifferent goals than ours.
Yallop, Korhonen, and Briscoe (2005) tackle syntactic, notsemantic classification, akin to the acquisition of subcategorization frames for verbs.Another relevant line of research pursues WSD.
Justeson and Katz (1995) and Chaoand Dyer (2000) showed that adjectives are a very useful cue for disambiguating thesense of the nouns they modify.
Adjective classes could be further exploited in WSDin at least two respects: (1) to establish an inventory of adjective senses (if polysemousinstances are correctly detected; this is where sense induction and our own work fitsin), and (2) to exploit class-based properties for the disambiguation, similar to relatedwork on verb classes (Resnik 1993; Prescher, Riezler, and Rooth 2000; Kohomban andLee 2005).The application where adjectives have received most attention, however, is OpinionMining and Sentiment Analysis (Pang and Lee 2008), as adjectives are known to conveymuch of the evaluative and subjective information in language (Wiebe et al 2004).The typical goal of this kind of study has been to identify subjective adjectives andtheir orientation (positive, neutral, negative).
This type of research, from pioneeringwork by Hatzivassiloglou and colleages (Hatzivassiloglou and McKeown 1993, 1997;Hatzivassiloglou andWiebe 2000) to current research (de Marneffe, Manning, and Potts2010), has thus focused on scalar adjectives, that is, adjectives like good and bad, which canbe translated into values that can be ordered along a scale.
These adjectives typicallyenter into antonymy relations (the semantic relation between good and bad), and in factantonymy is the main organizing criterion for adjectives in WordNet (Miller 1998), themost widely used semantic resource in NLP.
However, when examining a large scalelexicon, it becomes immediately apparent that there are many other types of adjectivesthat do not easily fit in a scale-based or antonymy-based view of adjectives (Alongeet al 2000).
Some examples are pulmonary, former, and foldable.
It is not clear, for in-stance, whether it makes sense to ask for an antonym of pulmonary, or to establish a?foldability?
scale for foldable.
These adjectives need a different treatment, and they aretreated in terms of different semantic classes in this article.The semantic properties of adjectives can also be exploited in advanced NLP tasksand applications such as Question Answering, Dialog Systems, Natural Language Gen-eration, or Information Extraction.
For instance, from a sentence like This maimai is roundand sweet, we can quite safely infer that the (invented) object maimai is a physical object,probably edible.
This type of process could be exploited in, for instance, InformationExtraction and ontology population, although to our knowledge this possibility hasreceived but little attention (Malouf 2000; Almuhareb and Poesio 2004).As for polysemy, previous approaches to the automatic acquisition of semanticclasses have mostly disregarded the problem, by biasing the experimental materialto include monosemous words only, or by choosing an approach that ignorespolysemy (Hindle 1990; Merlo and Stevenson 2001; Schulte im Walde 2006; Joanis,Stevenson, and James 2008).
There are a few exceptions to this tradition, such as Pereira,Tishby, and Lee (1993), Rooth et al (1999), and Korhonen, Krymolowski, and Marx(2003), who used soft clustering methods for multiple assignment to verb semanticclasses (see Section 4.5).There is very little related work in empirical computational semantics in modelingregular polysemy.
A pioneering piece of research is Buitelaar (1998), which tried toaccount for regular polysemy with the CoreLex resource.
CoreLex, building on theGenerative Lexicon theory (Pustejovsky 1995), groups WordNet senses into 39 ?basic578Boleda, Schulte im Walde, and Badia Modeling Regular Polysemy in Catalan Adjectivestypes?
(broad ontological categories).
In CoreLex, each word is associated to a polysemyclass, that is, the set of all basic types its synsets belong to.
Some of these polysemyclasses constitute instances of regular polysemy, as recently explored in Utt and Pado?
(2011).Lapata (2000, 2001) also addresses regular polysemy in the Generative Lexiconframework.
This work attempts to establish all the possible meanings of adjective-nouncombinations, and rank them using information gathered from the British NationalCorpus (Burnage and Dunlop 1992).
This information should indicate that an easyproblem is usually equivalent to problem that is easy to solve (as opposed to, for example,easy text, that is usually equivalent to text that is easy to read).
Thus, the focus is onthe meaning of adjective-noun combinations, not on that of adjectives alone as in thepresent research.3.
Basis for a Semantic Classification of AdjectivesAdjective classes in our definition are broad classes of lexical meaning.
We will presentlexical acquisition experiments in which, given the evidence found in corpora and otherlexical resources, a semantic class can be assigned to a given adjective.
For this purpose,two preconditions are required:(a) a classification that establishes the number and characteristics of the targetsemantic classes;(b) a stable relation between observable features and each semantic class.There is no established semantic classification for adjectives in computational linguisticsthat we can use and, therefore, one subgoal of the research is to establish the clas-sification in the first place, addressing (a), and exploiting the morphology?semanticsand syntax?semantics interfaces for acquisition, addressing (b).
We are thus facinga highly exploratory endeavor, and we do not regard the classifications we use asfinal.
We test two different classifications: an initial classification, based on the lit-erature, for the experiments reported in Section 4, and an alternative classification,for the experiments reported in Section 5.
We next turn to presenting the two testedclassifications.3.1 Initial ClassificationIn the acquisition experiments reported in Section 4, we distinguish between qualita-tive, intensional, and relational adjectives, which have the following properties (Miller1998; Raskin and Nirenburg 1998; Picallo 2002; Demonte 2011).Qualitative adjectives.
These are prototypical adjectives like gran (?big?)
or dolc?
(?sweet?
),including scalar adjectives, which denote attributes or properties of objects.
Adjectivesin this class tend to be gradable and comparable (see Examples (4a?4b)).
They are char-acterized by exhibiting the greatest variability with respect to their syntactic behavior:In Catalan, they can act as predicates in copular sentences and other constructions(Examples (4c?4d)), and they can typically act as both pre- and post-nominal modifiers(Examples (4e?4f)).
When an adjective modifies a head noun in pre-nominal position,579Computational Linguistics Volume 38, Number 3the interpretation is usually nonrestrictive, as shown by the fact that they can modifyproper nouns (Example (4e)).
(4) a.
TaulaTablemoltverygranbig//grand?
?ssimabigSUPERLATIVE?Very big table?b.
AquestaThistaulatablee?sisme?smoregranbigquethanaquellathat?This table is bigger than that one?c.
AquestaThistaulatablee?sisgranbig?This table is big?d.
AquestaThistaulatablelaitOBJ-CL-FEMveigseepres?1stp?sgmassatoogranbig?This table seems to me to be too big?e.
LaThegrangreatDianaDianavaPAST-AUXseguircontinuecantantsinging.
?Great Diana continued singing.?f.
VanPAST-AUXportarbringunaataulatablegranbig?They brought in a big table?Intensional adjectives.
These are adjectives like presumpte (?alleged?)
or antic (?former?
),which according to formal semantics denote second-order properties (Montague 1974,and subsequent work).
Most intensional adjectives modify nouns in pre-nominal posi-tion only (Example (5a)), and they cannot functionally act as predicates (Example (5b)).They are also typically not gradable (Example (5c)).
(5) a.
ElTheJoanJoane?siselthepresumpteallegedassass?
?murderer?Joan is the alleged murderer?b.
#ElTheJoanJoane?sispresumptealleged?#Joan is alleged?c.
#Me?sMorepresumpteallegedassass??murderer//#presumpt??ssimallegedSUPERLATIVEassass?
?murderer?#More/very alleged murderer?Intensional adjectives like presumpte may appear in any order with respect toqualitative adjectives, as in Example (6).
The order, however, affects interpretation:Example (6a) entails that the referent of the noun phrase is young, whereas Example(6b) does not (McNally and Boleda 2004).
(6) a. jove presumpte assass??
?young alleged murderer?580Boleda, Schulte im Walde, and Badia Modeling Regular Polysemy in Catalan Adjectivesb.
presumpte jove assass??
?alleged young murderer?Relational adjectives.
Adjectives such as pulmonar, estacional, bota`nic (?pulmonary, sea-sonal, botanical?)
denote a relationship to an object (in the mentioned examples, LUNG,SEASON, and PLANT objects).
Most of them are denominal (e.g., pulmonar is derivedfrom pulmo?, ?lung?)
and can only modify nouns post-nominally (see Example (7a)).Also, contrary to qualitative adjectives, they are not gradable (Example (7b)) and actas predicates only under very restricted circumstances (Example (7c) vs. (7d)).
If otheradjectives or modifiers co-occur with relational adjectives, these occur after the adjective(Example (7e)).
We will say relational adjectives are adjacent to the head noun.
(7) a. TeniaHadunaamalaltiadiseasepulmonarpulmonary//#pulmonarpulmonarymalaltiadisease?He/she had a pulmonary disease?b.
#MalaltiaDiseasemoltverypulmonarpulmonary//pulmonar?
?ssimapulmonarySUPERLATIVE#?Very pulmonary disease?c.
LaThedecisio?decisioneuropeaEuropean???
?AquestaThisdecisio?decisione?siseuropeaEuropean?The European decision?
?
?This decision is European?d.
LaThetuberculosituberculosepotcanserbepulmonarpulmonary?Tuberculose can be pulmonary?e.
inflamacio?inflamationpulmonarpulmonarygreuserious//#inflamacio?inflamationgreuseriouspulmonarpulmonary?serious pulmonary inflammation?Table 1 summarizes the properties just explained.
Our goal is to use these propertiesto induce the semantic class of adjectives.
For instance, if an adjective is denominal,appears almost exclusively in postnominal position, and is strictly adjacent to the headnoun, we predict that it is relational.
In the experiments reported in Sections 4 and 5, weTable 1Initial classification: Linguistic properties of qualitative, intensional, and relational adjectives.Qualitative Intensional Relationalgran (?big?)
presumpte (?alleged?)
pulmonar ?pulmonary?Propertypredicative + ?
restrictedgradable/comparable + ?
?position with respect to head noun both pre-nom.
post-nom.adjacent ?
?
+denominal ?
?
+581Computational Linguistics Volume 38, Number 3extract data related to these and other properties of adjectives from linguistic resources,and use them as features in machine learning experiments.3.2 Alternative ClassificationIn the acquisition experiments reported in Section 5, we distinguish between qualitative,relational, and event-related adjectives.
The classification presented in Section 3.1 isthus altered in two ways: (1) The intensional class is dropped.
(2) A new class, thatof event-related adjectives, is added to the classification.
The reasons for these changeswill become clear in the discussion of the experiments in Section 4.
Here, we describethe new class and provide a summary table of the alternative classification.Event-related adjectives.
Adjectives such as exportador, prome`s, resultant (?exporting,promised, resulting?)
denote a relationship to an event, in this case, EXPORT, PROMISE,and RESULT events, respectively.
Most of them are deverbal.
Like relational adjectives,they are typically nongradable (see Example (8a)) and prefer the postnominal positionwhen modifying nouns (Example (8b)).
Like qualitative adjectives, they typically canact as predicates (Example (8c)).
(8) a.
E?sIsunapa?
?scountry{exportador{exporting//#moltveryexportador}exporting}deofpetrolioil?It is an oil exporting / #very exporting country?b.
#exportador pa?
?s?exporting country?c.
AquestThispa?
?scountrye?sisexportadorexporting?This is an exporting country?Table 2 summarizes the properties of the alternative classification (for a morethorough discussion of previous research on the semantics of adjectives and moremotivation for the classification, see Boleda [2007]).
For comparison, we will brieflyoutline the treatment of adjectives in WordNet (Miller 1998; Alonge et al 2000).
AsTable 2Alternative classification: Linguistic properties of qualitative, event-related, and relationaladjectives.Qualitative Event-related Relationalgran (?big?)
exportador (?exporting?)
pulmonar ?pulmonary?Propertypredicative + + restrictedgradable/comparable + typically not ?position with respect to both post-nom.
post-nom.head nounadjacent ?
?
+derivational type non-derived deverbal denominal582Boleda, Schulte im Walde, and Badia Modeling Regular Polysemy in Catalan Adjectivesmentioned in Section 2, the main semantic relation around which adjectives are or-ganized in WordNet is antonymy.
Also as explained, however, not all adjectives haveantonyms.
This is solved in WordNet by the use of indirect antonyms (e.g., swift andslow are indirect antonyms, through the semantic similarity between swift and fast).
Still,indirect antonymy only applies to a small subset of the adjectives in WordNet (slightlyover 20% in WordNet 1.5).
Therefore, some kinds of adjectives receive a differentiatedtreatment.Specifically, twomain kinds of adjectives are distinguished inWordNet: (1) Descrip-tive adjectives, akin to our qualitative adjectives, which are organized around antonymy(descriptive adjectives, however, include intensional adjectives).
(2) Relational adjec-tives, as defined in this article, for which two different solutions are adopted.
If a suit-able antonym can be found for a given relational adjective (antonym in a broad sense;in Miller [1998, page 60], physical and mental are considered antonyms), it is treated inthe same way as a descriptive adjective.
Otherwise, it is linked through a PERTAIN-TOpointer to the related noun.
In addition, a subclass of descriptive adjectives, havingthe form of past or present participles, is distinguished, and also receives a hybridtreatment.
Those that can be accommodated to antonymy are treated as descriptiveadjectives (laughing?unhappy, through the similarity between laughing and happy).
Thosewhich cannot are linked to the source verb through a PRINCIPAL-PART-OF pointer.
Ourevent-related class includes not only past and present participles, but other types ofdeverbal adjectives.
Thus, most of the classes used in this article are to some extentbacked up by the organization of adjectives in WordNet.3.3 The Role of PolysemyAs explained in the Introduction, some adjectives are polysemous such that each sensefalls into a different class of the classifications just presented.
Consider for instancethe adjective econo`mic in Example (1), repeated here as Example (9) for convenience.The two main senses of econo`mic instantiate the relational (sense in Example (9a))and the qualitative class (sense in Example (9b)), respectively.
(9) a. ana`lisi econo`mica?economic analysis?b.
pantalons econo`mics?cheap trousers?Crucially for our purposes, in each of the senses the adjective exhibits the propertiesof each of the associated classes.
When used as a relational adjective, it is not gradableand cannot be used in a pre-nominal position (Example (10)).When used as a qualitativeadjective, it is gradable and it can be used predicatively (see Example (11)).
In theexperiments that follow, we aim at capturing this hybrid behavior.
(10) a.
#L?ana`lisiThe-analysismoltveryecono`micaeconomicdeoflesthedadesdata?#The very economic analysis of the data?b.
#Va?PAST-AUXdurbringatotermetermunaanecono`micaeconomicana`lisianalysis?#He/she carried out an economic analysis?583Computational Linguistics Volume 38, Number 3(11) AquestsThesepantalonstrousersso?naremoltveryecono`mics!economic!
?These trousers are very cheap!
?Cases of regular polysemy between the intensional and qualitative classes also exist,as illustrated in Examples (12) and (13).
Antic has two major senses, a qualitative one(equivalent to ?old, ancient?)
and an intensional one (equivalent to ?former?).
Note againthat, when used in the intensional sense, it exhibits properties of the intensional class: Itappears pre-nominally (Example (13a)) and is not gradable (Example (13b)).
(12) a. edificibuildinganticancient?ancient building?b.
edificibuildingmoltveryanticancient?very ancient building?
(13) a. anticancientpresidentpresident?former president?b.
#moltveryanticancientpresidentpresident?#very former president?The new class in the alternative classification, that of event-related adjectives, alsointroduces regular polysemy, specifically, between event-related and qualitative adjec-tives, as illustrated in Examples (14) and (15).
The participial adjective sabut (?known?
)has an event-related sense, corresponding to the verb saber (?know?
), and a qualitativesense that can be translated as ?wise?.
Likewise, the deverbal adjective cridaner derivedfrom cridar (?to shout?)
alternates between an event-related sense and a qualitative sense.
(14) problemaproblemsabutknown//homemansabutknown?known problem / wise man?
(15) noiboycridanershoutSUFFIX//shirtcamisaattention-gainingcridanera?boy who shouts a lot / attention-gaining shirt?Examples (14) and (15) represent cases of regular polysemy because, as can be drawnfrom the translations, there is a systematic shift from a transparent relation with theevent to a quality that bears a more distant relation to the event.
In the case of sabut therelation is clear (if a man knows a lot, he is wise); in the case of cridaner, a shirt qualifiesfor the adjective if it is for instance loud-colored or has an eccentric cut, such that it gainsthe attention of people, as shouting does.In this article, we only consider types of polysemy that cut across the classificationpursued.
Other kinds of polysemy that have traditionally been tackled in the literaturewill not be considered.
For instance, we will not be concerned with the polysemyillustrated in Example (16), which arguably has more to do with the semantics of the584Boleda, Schulte im Walde, and Badia Modeling Regular Polysemy in Catalan Adjectivesmodified noun than that of the adjective (Pustejovsky 1995).
Both of the uses of trist(?sad?)
illustrated in Example (16) fall into the qualitative class, so, contrary to the workby Lapata (2000, 2001) cited previously, we do not treat the adjective as polysemous inthe context of the present experiments.
(16) noiboytristsad//pel?l?
?culafilmtristasad?sad boy / sad film?4.
First Model: Polysemous Adjectives Constitute Independent ClassesGiven the hybrid behavior of polysemous adjectives explained in Section 3, we canexpect that they behave differently from adjectives in the basic classes.
For instance,adjectives polysemous between a qualitative and a relational use should exhibit moreevidence for gradability than pure relational adjectives, but less than pure qualitativeadjectives.
In this view, polysemous adjectives belong to a class, for instance, thequalitative-relational class, that is distinct from both the qualitative and the relationalclasses, typically exhibiting feature values that are in between those of the basic classes.In this section, we report on experiments testing precisely this model for regularpolysemy.
We will therefore distinguish between five types of adjectives: qualitative,intensional, relational, polysemous between a qualitative and an intensional reading(intensional-qualitative), and polysemous between a qualitative and a relational reading(qualitative-relational).
There is one polysemous class missing (intensional-relational).No cases of polysemy between intensional and relational adjectives were observed inour data.Recall from the previous sections that we cannot reuse an established classification,and that there is virtually no previous work on the automatic semantic classification ofadjectives.
The present experiments also aim at testing the overall enterprise of inducingsemantic classes from distributional properties for adjectives.
Given the exploratorynature of the experiment, we use clustering, an unsupervised technique, to uncovernatural groupings of adjectives and test to what extent these correspond to the classesdescribed in the literature.4.1 Data and Gold StandardThe experiments reported in this section are based on an eight million word fragmentof the CTILC corpus (Corpus Informatitzat de la Llengua Catalana; Rafel 1994), developedat the Institut d?Estudis Catalans.
Each word is associated with its lemma, part of speech,and inflectional features, as well as syntactic function.
Lemma and morphological in-formation have been manually checked.
We automatically added syntactic informationwith CatCG (Alsina et al 2002).
CatCG is a shallow parser that assigns one or moresyntactic functions to each word.
In the case of the adjective, CatCG distinguishesbetween (1) predicate of a copular sentence; (2) predicate in another construction; (3)pre-nominal modifier; (4) post-nominal modifier.
As no full dependencies are indicated,the head noun can only be identified with heuristics.In the experiments, we cluster all adjectives occurring more than ten times in thecorpus (a total of 3,521 lemmata), and analyze the results using a subset of the data.This is a randomly chosen 101-lemma gold standard (available in the Appendix).
Fifty585Computational Linguistics Volume 38, Number 3lemmata were chosen token-wise and 50 type-wise to balance high-frequency and low-frequency adjectives (one lemma was chosen with both methods, so the repetition wasremoved).
Two lemmata were added in a post-hoc fashion, as explained subsequently.The lemmatawere annotated by four doctoral students in computational linguistics.The task of the judges was to assign each lemma to one of the five classes (qualitative,intensional, relational, qualitative-intensional, and qualitative-relational).
The instruc-tions for the judges included information about all linguistic characteristics discussedin Section 3, including syntactic and semantic characteristics.The judges had a moderate degree of agreement, comparable to that obtained inother tasks on semantics or discourse, inter-annotator scores ranging between ?
= 0.54and 0.64 (see Artstein and Poesio [2008] for a discussion of agreement measures forcomputational linguistics).
For comparison, Ve?ronis (1998) reported a mean pair-wiseweighted ?
= 0.43 for a word sense tagging task in French; and Merlo and Stevenson(2001) obtained ?
= 0.53?0.66 for the task of classifying English verbs as unergative,unaccusative, or object-drop.
Poesio and Artstein (2005) report ?
values of 0.63?0.66(0.45?0.50 if a trivial category is dropped) for the tagging of anaphoric relations.
Ourjudges reported difficulties in tagging particular kinds of adjectives, such as deverbaladjectives.
This issue will be retaken in Section 4.5.No intensional adjectives were identified in the data by the judges, and onlyone intensional-qualitative adjective was identified.
Two intensional lemmata weremanually added to be able to minimally track the class.
This is clearly insufficient fora quantitative approach, however, so the intensional class is dropped in the alternativeclassification.
It is striking that intensional adjectives, which have traditionally been thefocus of formal semantic approaches to the semantics of adjectives, constitute a verysmall class (less than a dozen lemmata are mentioned in the reviewed literature).4.2 FeaturesWe use two sets of distributional features to model adjective behavior: on the one hand,theoretically motivated features (theoretical features for short); on the other hand,features that encode the part-of-speech distribution of a four-word window around theadjective (POS features).
The former provide a theoretically informed model of adjec-tives, because they are cues to the properties of each class as described in the literature.The latter are meant to provide a theory-independent representation of adjectives, totest to what extent the structures obtained with theoretical and POS features are similar.Both sets of features take a narrow context into account (at most five words to each sideof the adjective), because of the limited syntactic behavior of adjectives.4.2.1 Theoretical Features.
Theoretical features model the syntactic and semantic proper-ties of the classes described in Section 3.
The features used, together with their meanand standard deviation values (computed on all 3,521 adjectives), are summarized inTable 3.
A feature value va,i for an adjective lemma a and a feature i corresponds to theproportion of the occurrences in which i is observed for adjective a over all occurrencesof a (see Equation (1); f stands for absolute frequency).va,i =f (a, i)f (a)(1)586Boleda, Schulte im Walde, and Badia Modeling Regular Polysemy in Catalan AdjectivesTable 3 is the translation of Table 1 into shallow cues that can be extracted froma corpus.
The mean values in Table 3 are very low, which points to the sparseness oftheoretically defined properties such as predicativity or gradability, at least in writtentexts (oral corpora would presumably yield different values).
Also note that standarddeviations are higher than mean values, which indicates a high variability in the featurevalues, something that will be exploited for classification.From the discussion in Section 3, the following predictions with respect to thesemantic features can be made.
(1) In comparison with the other classes, qualitative adjectives should havehigher values for features gradable, comparable, copular, predicative, middlevalues for feature prenominal, and low values for feature adjacent.
(2) Relational adjectives should have an almost opposite distribution, withvery low values for all features except for adjacent.
(3) Intensional adjectives should exhibit very low values for all featuresexcept for pre-nominal, for which a very high value is expected.
(4) With respect to polysemous adjectives, it can be foreseen that their featurevalues will be in between those of the basic classes.
For instance, anadjective that is polysemous between a qualitative and a relational readingshould exhibit a higher value for feature gradable than a monosemousrelational adjective, but a lower value than a monosemous qualitativeadjective.Figure 1 shows that the predictions just outlined are met to a large extent, showing thatthe empirical (corpus) data support the theoretical predictions.
This graph representsthe value distribution of each feature in the form of boxplots.
In the boxplots, therectangles have three horizontal lines, representing the first quartile, the median, andthe third quartile, respectively.
The dotted line at each side of the rectangle stretches tothe minimum andmaximum values, at most 1.5 times the length of the rectangle.
Valuesthat are outside this range are represented as points and termed outliers (Verzani 2005).Note that the scale in Figure 1 does not range from 0 to 1; this is because the data arestandardized, as will be explained subsequently.Table 3Theoretical features.
The mean and SD values are computed on all clustered adjectives.
Featurecopular accounts for predicative constructions with the copula verbs ser, estar (?be?).
Featurepredicative accounts for other predicative constructions, such as Example (4d).Feature Textual correlate Mean SDgradable degree adverbs, degree suffixation 0.04 0.08comparable comparative constructions 0.03 0.07copular copular predicate syntactic tag 0.06 0.10predicative predicate syntactic tag 0.03 0.06pre-nom pre-nominal modifier syntactic tag 0.04 0.08adjacent first adjective in a series of two or more 0.03 0.05587Computational Linguistics Volume 38, Number 3Figure 1Theoretical features: Feature value distribution in the gold standard.
Class labels: I = intensional;IQ = polysemous between intensional and qualitative; Q = qualitative; QR = polysemousbetween qualitative and relational; R = relational.The differences in value distributions, although significant,1 are not sharp, as mostof the ranges in the boxes overlap.
This affects mainly polysemous classes: Althoughthey show the tendency predicted?exhibiting values that are in between those of thebasic classes?they do not present clearly distinct values.
The clustering results will beaffected by this distribution, as will be discussed in Section 4.5.4.2.2 POS Features.
POS features encode the part-of-speech distribution of a four-wordwindow around the adjective, providing a theory-independent representation of thelinguistic behavior of adjectives.
To avoid data sparseness, we encode possible POS foreach position as a different feature.
For instance, for an occurrence of alta (?tall?)
as in Ex-ample (17a), the representation would be as in Example (17b).
In the example, the targetadjective is in boldface, and the relevant word window is in italics.
Negative numbers1 Tested by one-way ANOVA tests on each of the features (factor: Classes), excluding items in the I andIQ classes because not enough observations are available.
The test yields p-values lower than 0.05(predicative), 0.01 (comparable, pre-nominal, adjacent), and 0.001 (gradable, copular), respectively.588Boleda, Schulte im Walde, and Badia Modeling Regular Polysemy in Catalan AdjectivesTable 4POS features.
The mean and SD values are computed on all clustered adjectives.Feature Mean SD Feature Mean SD?1 noun 0.52 0.25 ?2 preposition 0.13 0.09+1 punctuation 0.42 0.15 ?1 adverb 0.10 0.11?2 determiner 0.39 0.20 ?1 verb 0.08 0.11+2 determiner 0.24 0.13 ?1 determiner 0.06 0.10+1 preposition 0.21 0.15 +1 noun 0.06 0.10indicate positions to the left, positive ones positions to the right.
The representation inExample (17b) corresponds to the parts of speech of e?s, me?s, que, and la, respectively.
(17) a. latheBrunaBrunae?sisme?smorealtatallquethanl?Angelinathe-Angelina?Bruna is taller than Angelina?b.
-2 verb, -1 adverb, +1 conjunction, +2 determinerFeature values are defined as in theoretical features (see Equation (1)).
The tenfeatures with the overall highest mean value in our data (among a total of 36 features)are listed in Table 4.
Note that the mean values are much higher for the POS features(Table 4) than for the theoretical features (Table 3), as theoretical features are muchsparser.4.3 Clustering Algorithm and ParametersWe use the k-means clustering algorithm (see Kaufman and Rousseeuw [1990] andEveritt, Landau, and Leese [2001] for comprehensive introductions to clustering).2 Thisis a classical algorithm, conceptually simple and computationally efficient, which hasbeen used in related work, such as the induction of German semantic verb classes(Schulte imWalde 2006) and the syntactic classification of Catalan verbs (Mayol, Boleda,and Badia 2005).
Also, it performs hard clustering, which is adequate for our purposes(recall from Section 4.1 that wemodel polysemy in terms of separate classes).
Additionalexperiments with other clustering methods yielded similar results: We tested two hier-archical and one flat algorithm, one of them agglomerative and the other two partitional,with several clustering criteria, always using the cosine distance measure.K-means is a flat, partitional algorithm that aims at minimizing the overall distancefrom objects to their centroids (mean vectors of each cluster), which favors globularcluster structures.
An initial random partition into k clusters is performed on the data.The centroids (mean vectors) of each cluster are computed, and each object is re-assigned to the cluster with the nearest centroid.
The centroids are recomputed, and theprocess is iterated until no further changes take place, or a pre-specified number of times(20 in our case).
Equation (2) shows the formula for the clustering criterion, where k isthe total number of clusters and l are the lemmata in each cluster c1, .
.
.
, ck.
To avoid the2 More specifically, because we are using the cosine measure, the algorithm is spherical k-means (Dhillonand Modha 2001).
All the experiments were performed with the CLUTO toolkit (Karypis 2002).589Computational Linguistics Volume 38, Number 3influence of the initial partition on the final structure, the whole experiment is repeatedseveral times (25 in our case) with different random partitions, and the partition thatbetter satisfies the clustering criterion is chosen.minimize?i?k?l?cicos(l, centroid(ci)) (2)We experimented with two representations of the feature values: raw and stan-dardized proportions.
In clustering, features with higher mean and standard deviationvalues tend to dominate over more sparse features.
Standardization smooths the differ-ences in the strengths of features.
We standardize to z-scores, so that all features havemean 0 and standard deviation 1.
As the most interpretable results were obtained withstandardized values, we will restrict the discussion in the next section to the resultsobtained with standardized values.4.4 ResultsThe discussion focuses on the cluster analyses with three and five clusters becauseour basis is three classes (intensional, qualitative, and relational) and we consider atotal of five classes (basic classes plus polysemous classes: intensional-qualitative andqualitative-relational).
A higher number of clusters introduces more noise (in the formof small clusters with no clear content).The contingency tables of the clustering results with three clusters are depicted inTable 5.
Part A of the table depicts the solution obtained with theoretical features, whilePart B represents the solution obtained with POS features.
Rows are gold standardclasses and columns are clusters, labeled with the cluster number provided by thealgorithm.
The ordering of the cluster numbers corresponds to the quality of the cluster,measured in terms of the clustering criterion (see Equation (2)), 0 representing thecluster with the highest quality.
In each cell Cij of Table 5, the number of adjectivesTable 5First model: Three-way solution contingency tables for theoretical and POS features.
Rows aregold standard classes, columns are clusters.
Row TotalGS shows the number of Gold Standardlemmata and row Totalcl the total number of lemmata contained in each cluster.
Note that thecolumn labeled Total represents the row sum for each part (as the number of items per classis identical).A: Theoretical B: POSCluster 0 1 2 0 1 2 Totalintensional (I) 0 0 2 0 2 0 2intensional-qualitative (IQ) 0 0 1 0 1 0 1qualitative (Q) 4 13 35 10 37 5 52qualitative-relational (QR) 3 5 3 7 2 2 11relational (R) 21 13 1 20 5 10 35TotalGS 28 31 42 37 47 17 101Totalcl 834 1,287 1,400 1,234 1,754 533 3,521590Boleda, Schulte im Walde, and Badia Modeling Regular Polysemy in Catalan Adjectivesof class i that are assigned to cluster j by the algorithm is given.
The largest value foreach class is highlighted (see gray cells).A striking feature of Table 5 is that results in the two parts (A and B) are very similar.The following can be observed:(1) There is one cluster (cluster 0 in both solutions) that contains the majorityof relational adjectives in the gold standard.
This is the most compactcluster according to the clustering criterion.
(2) Another cluster (2 in solution A, 1 in solution B) contains the majority ofqualitative adjectives in the gold standard, as well as all intensional andIQ adjectives.
(3) The remaining cluster contains a mixture of qualitative and relationaladjectives in both solutions.
(4) Adjectives that are polysemous between a qualitative and a relationalreading (QR) are scattered through all the clusters, although they show atendency to be ascribed to the relational cluster in solution B (cluster 0).The five-way results are depicted in Table 6.
On the one hand, the table shows thatthe five-way structure found by the clustering algorithm is very similar to the three-way structure in Table 5.
This means that the three clusters in A and B have basicallybeen replicated by the three first clusters in C and D, respectively.
On the other hand,the differences between the structures obtained using theoretical versus POS featuresare more obvious in the five-way solutions.
From the set-up of the experiment, wehad expected one cluster per class, plus QR and IQ adjectives isolated in a cluster oftheir own.
This is clearly not borne out in Table 6.
What we find instead is that (a)the mixed clusters persist and score high in the clustering criterion (see clusters 0 insolution C and 0?1 in solution D, with a mixture of Q, QR, and R adjectives), and (b)two additional small clusters are created (clusters 3 and 4 in both solutions) with noclear interpretation, suggesting that the three-way set-up matches better the structureuncovered by the clustering algorithm.From the discussion of Tables 5 and 6 we conclude that the three-way clusteringmeets the target classification better than the five-way clustering, and that polysemousadjectives are not identified as a separate class.
These results suggest that modelingTable 6First model: Five-way solution contingency tables.
Information presented as in Table 5.C: Theoretical D: POSCluster 0 1 2 3 4 0 1 2 3 4 TotalI 0 0 2 0 0 0 0 2 0 0 2IQ 0 0 1 0 0 0 0 1 0 0 1Q 7 4 35 4 2 3 7 37 2 3 52QR 5 3 3 0 0 6 1 2 1 1 11R 12 21 1 0 1 11 9 5 7 3 35TotalGS 24 28 42 4 3 20 17 47 10 7 101Totalcl 857 854 1462 156 192 828 406 1,754 275 258 3,521591Computational Linguistics Volume 38, Number 3polysemous adjectives in terms of additional, complex classes is not an adequate strat-egy (we return to this point subsequently).Recall that we defined theoretical and POS features to compare the structuresobtained using theoretically informed and theory-independent features.
Further featureanalysis, not reported here for space reasons, reveals a high correlation between themost descriptive features of solutions A and B.3 This highlights the correspondencebetween the two feature representations with respect to the clustering results: ThePOS features elicited as most discriminative by the clustering algorithm are preciselythose that correspond to the theoretical features.
This correspondence explains theresemblance between the solutions obtained with the two types of representation andat the same time provides support for the present definition of the theoretical features.Last but not least, note that we do not assign a score to each clustering solution.Evaluation of clustering is very problematic when there is no one-to-one correspon-dence between classes and clusters (Hatzivassiloglou and McKeown 1993), as is ourcase.
Schulte imWalde (2006) provides a thorough discussion of this issue and proposesdifferent metrics and types of evaluation.
We defer numerical evaluation until Section 5.4.5 Discussion4.5.1 Classification.
The experiments presented provide feedback to the question, what isan appropriate broad semantic classification for adjectives?
The clustering experimentsprovide empirical support for the qualitative and relational classes, as is particularlyevident in the three-way solution (Table 5).
These are classes that have traditionally beentaken into account in descriptive grammar (Bally 1944; Picallo 2002) and computationalresources such as WordNet (Miller 1998; Alonge et al 2000), so we consider them to bequite stable and keep them in our classification.Intensional and IQ adjectives, in contrast, are grouped together with qualitativeadjectives in all solutions, because they do not exhibit distinctive enough distributionalproperties to differentiate them, a fact aggravated by the small size of the intensionalclass.
From the point of view of NLP, it is reasonable to encode intensional adjectivesby hand, given their limited number.
For these reasons, we include the intensionalclass in the qualitative class in what follows (remember that, as mentioned in Sec-tion 3, WordNet alo includes intensional adjectives in the qualitative?in their terms,descriptive?class).?Hybrid?
clusters, that is, clusters that contain adjectives from several semanticclasses, play an interesting role in our cluster analyses.
Such clusters seem to be coherentand stable, as they appear in all examined solutions (A, B, and also C and D in Tables 5and 6) and have good scores in the clustering criterion.
Significantly, however, most ofthe adjectives that are problematic for humans are assigned to hybrid clusters, whereproblematic means that they are not assigned to the same class by all four judges.Conversely, most adjectives in the hybrid clusters are problematic.
Thus, hybrid clustersare useful to signal problems in the proposed classification.
As an example, considercluster 0 in Part C of Table 6: 17 out of the 24 (70.1%) gold standard adjectives in thishybrid cluster are problematic for humans.
This cluster contrasts with the qualitativecluster (cluster 2 of Table 6), where only 10 out of its 42 (23.8%) lemmata are problematic.Two kinds of adjectives crop up among problematic adjectives: so-called ethnicadjectives (alemany ?German?, menorqu??
?Menorcan?, sud-africa` ?South African?, xine`s3 Descriptive features are defined here as those that are among the three features with highest or lowestmean values for at least three clusters in the five-way solution.592Boleda, Schulte im Walde, and Badia Modeling Regular Polysemy in Catalan Adjectives?Chinese?
), and deverbal adjectives (indicador ?indicating?, parlant ?speaking?, protector?protecting, protective?, salvador ?savior?).
Ethnic adjectives can act as predicates ofcopular sentences in a much more natural way than typical relational adjectives,and seem to be vague between a relational and a qualitative reading in theirsemantics (Raskin and Nirenburg 1998, page 173).
This kind of adjective will mainly betreated as polysemous in the experiments reported in Section 5.As for deverbal adjectives, they are clearly neither relational (they do not expressa relationship to an object) nor intensional.
They are also not typically qualitative,however, because they trigger a relationship to an event instead of denoting a simpleproperty.
For instance, protector triggers a relationship with a stable event of protectingin Example (18): A person named Serra belongs to the kind of associates who have as aprimary role to protect the association.
(18) SerraSerra.
.
.
Era.
.
.wassociassociateprotectorprotectingdeofl?Associacio?the-Associationdeofconcertsconcerts?Serra was a protecting associate of the Association of concerts?These considerations motivate the addition of a class of event-related adjectivesin the overall classification.
Event-related adjectives have not received much attentionin the linguistic literature, except for one particular subtype, namely, adjectival uses ofthe participle (Bresnan 1982; Levin and Rappaport 1986; Bresnan 1995).
As for compu-tational resources, the English WordNet, as explained in Section 3, only distinguishessome participial adjectives.
In the Italian WordNet, however, other event-related adjec-tives receive a specific treatment, through the encoding of the lexical relations CAUSESand LIABLE-TO, as exemplified in Example (19) (Alonge et al 2000):(19) a. depuratorio ?depurative, purifying?
CAUSES depurare ?to depurate/purify?.b.
giudicabile ?triable?
LIABLE-TO giudicare ?to judge?.To sum up, the results of the experiments reported in this section motivate a three-way classification between qualitative, event-related, and relational adjectives.
Notethat, in the revised classification proposed in this section, classes are uniformly definedaccording to the ontological type of their denotation: Qualitative adjectives denote at-tributes or properties, relational adjectives denote relationships to objects, and event-related adjectives denote relationships to events.
The classes correspond to the threemajor types of entities in an ontology (attributes, objects, events), more specifically, tothe way adjectives participate from those entities.
In this view, relational and event-related adjectives denote properties, just as qualitative adjectives do, but they are aspecific type of property involving a relationship with either an object or an event.The classification is in fact similar to the one proposed in the Ontological Semanticsframework (Raskin and Nirenburg 1998; Nirenburg and Raskin 2004).Also note that the revised semantic classification bears a prominent relationshipto morphology: In the default case, qualitative adjectives are not derived, event-related adjectives are deverbal, and relational adjectives are denominal.
However, thecorrespondence between semantic classes and derivational type is not a one-to-onemapping.
Although most event-related adjectives are deverbal, not only strictlydeverbal adjectives evoke events: For instance, tangible ?tangible?
evokes an event oftouching, but there is no verb *tangir in Catalan (tangible is built on the Latin verbtango?, ?touch?).
Raskin and Nirenburg (1998, page 187) cite examples for English593Computational Linguistics Volume 38, Number 3such as audible or ablaze.
Similarly, some object adjectives are not denominal (such asbota`nic ?botanical?).
Conversely, some denominal or deverbal adjectives are qualitative:vergonyo?s ?shy?
(from vergonya ?shyness?
), amable (literally ?suitable to be loved?
; hasevolved to ?kind, friendly?).
We will empirically check the correspondence betweenmorphology and semantic class in Section 5.5.4.5.2 Regular Polysemy.
Our first series of experiments also provides feedback to thequestion, what is an adequate computational model for regular polysemy?
Specifically,we have shown that the treatment of regular polysemy in terms of independent classesis not adequate.
Remember that the motivation for the experiments presented in thissection was the hypothesis that polysemous adjectives exhibit a linguistic behaviorthat participates from the basic classes involved in the regular polysemy, thus yieldingfeature values that are in between those of the basic classes (cf.
Figure 1).
Thus, we hadexpected that polysemous adjectives form a homogeneous group of lexical items, char-acterized precisely by the fact that they exhibit properties from each class to a certaindegree.
However, this expectation is not borne out in the results of the experiments.To this respect, it is striking that QR adjectives (polysemous between a qualitativeand a relational reading) are spread throughout all the clusters in all solutions.
Theyare not identified as a homogeneous group, nor as distinct from the rest.
Crucially, aspointed out in Section 4.2, the differences between the feature values of polysemousadjectives and those of the basic classes are not strong enough to motivate a separatecluster.We believe that the reason for these results is the fact that polysemous adjectives donot in fact have a homogeneous, differentiated profile: In a given corpus, most adjec-tives are used predominantly in one of their senses, corresponding to one of the basicclasses, and thus the ?hard?
classification with three clusters fits better.
For instance, thequalitative-relational adjective iro`nic (?ironic?)
is mainly used as a qualitative adjectivein the corpus.
Accordingly, it always appears in the qualitative clusters.
Conversely,militar (?military?)
is mostly used as a relational adjective, and is consistently assignedto one of the relational clusters in all solutions.
Thus, although polysemous adjectiveson average do show a mixed behavior, each lexical item tends to pattern with one of thebasic classes.
An alternative conceptualization of regular polysemy and experimentaldesign is called for, and this will be the topic of the next section.5.
Second Model: Polysemous Adjectives Simultaneously Belong toDifferent ClassesThe experiments presented in the previous section pursued two goals: on the one hand,to test the initial classification proposal; on the other, to test a model of regular polysemythat treats polysemous adjectives in terms of separate classes.
With respect to the firstgoal, the experiments in this section rely on the results of the previous experiments, anduse the alternative classification described in Section 3.2.
The alternative classificationhas in addition been supported by a clustering experiment not reported here for spacereasons (see Boleda, Badia, and Batlle [2004] for details and discussion).With respect to the second goal, we have shown that the first model is not suc-cessful at modeling regular polysemy.
Furthermore, the analysis of feature valuesin the previous section suggests that the lack of success is not related to the spe-cific technique used in the initial experiment, but to the properties of polysemous594Boleda, Schulte im Walde, and Badia Modeling Regular Polysemy in Catalan Adjectivesadjectives: the fact that they are used predominantly in one of their senses, and thefact that the feature distributions of ?polysemous classes?
largely overlap with those ofthe basic classes.In the present experiments, we develop an alternative approach to regular poly-semy that is based on the perspective that polysemous adjectives belong to more thanone semantic class, in the framework of multi-label classification.
A typical exampleof a multi-label classification task is Text Categorization (Schapire and Singer 2000),where a document can be described via more than one label (e.g., Health and Local), sothat it effectively belongs to more than one of the target classes.
The motivation for thisnew approach is the fact that polysemous adjectives exhibit properties of all the classesinvolved (see Section 3.3).
The hypothesis is that the evidence found for a polysemousadjective that is polysemous between, say, a relational and a qualitative use should bestrong enough for the adjective to be assigned to both the relational and the qualitativeclasses.
Note that by assigning the adjective to the two classes independently, we makean implicit classification of the adjective as polysemous.
The success of the approach willdepend on whether the different senses are sufficiently represented in the data, and itwill be especially challenging to distinguish between noise and evidence for a givenclass.5.1 Data and Gold StandardThe experiments reported in this section are based on a 16 million word fragment ofthe CTILC corpus (see Section 4.1).
We additionally use an adjective database (Sanroma`and Boleda 2010) with manually coded information about all adjectives occurring morethan 50 times in the corpus (2,296 lemmata).
The database codes the derivational type(deverbal, denominal, participial, non-derived) and suffix of each adjective.A gold standard of 210 adjective lemmata (available in the Appendix) was selectedfrom this database for the experiments.
The lemmata were randomly sampled in astratified fashion, balancing three factors of variability: frequency, morphological type,and suffix.
Thus, the gold standard contains an equal number of adjectives from threefrequency bands (low, medium, high), from the four derivational types, and from aseries of suffixes within each type.
This samplingmethod is aimed at achieving semanticvariability.Three experts assigned each of the 210 lemmata to one or two of the classes in thealternative classification, namely, event-related, qualitative, or relational.
The decisionswere reached by consensus and were based on expert knowledge together with theexamination of the information in the database, corpus examples, and the judgmentsprovided by 322 naive subjects in a large-scale annotation experiment.4Table 7 shows the distribution of adjectives in the gold standard into classes ac-cording to the three experts.
These are the data used in the experiments presented inthis section.
The proportion of polysemous adjectives is quite high, over 17%, withqualitative-relational being the most frequent type of polysemy.
Also note that 51%of the adjectives are qualitative; this will be the baseline for the machine learningexperiments presented subsequently.4 For details on the annotation experiment, see Boleda, Schulte imWalde, and Badia (2008).
The experimentyielded low inter-coder agreement scores (estimated ?
0.31?0.45, observed agreement 0.62-0.70).
Notethat the consensus classification is sub-optimal in the sense that its replicability cannot be estimated.595Computational Linguistics Volume 38, Number 3Table 7Gold standard classification: Distribution and examples.Class Label Example # %qualitative Q tenac?, ?tenacious?
107 51.0event E informatiu, ?informative?
37 17.6relational R crania`, ?cranial?
30 14.3qualitative-relational QR familiar, ?familiar?
23 11.0qualitative-event QE sabut, ?known?
7 3.3event-relational ER comptable, ?countable?
6 2.9Total 210 100Table 8Feature sets.
From left to right, each column depicts, for each feature set, an identifier, adescription of the type of information used, the total number of features, and one examplefeature.
Feature set morph contains two categorical features that are transformed into 25 ifbinarization is applied; the remaining feature sets are numerical.Feature set Description # Examplemorph morphological (derivational) properties 2 (25) suffixfunc syntactic function of the adjective 4 post-nom.
modifieruni uni-gram POS (1 word to left or to right) 24 ?1nounbi bi-gram POS (1 word to left and 1 to right) 50 ?1noun+1adjtheor distributional cues of theoretical properties 18 gradableTotal 98 (121)5.2 Features5.2.1 Feature Definition.We define five feature sets based on different types of linguisticinformation, to gain further insight into the properties of each class.
In particular, weare interested in the properties of event-related adjectives, for which we do not have adescription in the linguistic literature.
Table 8 summarizes the properties of the featuresets used for the present experiments.Feature set morph represents derivational properties of adjectives, as encoded inthe adjective database.
We include this type of information because of the relevanceof morphology for the new classification (see Section 4.5).
Func encodes the syntacticfunctions of the adjectives in the corpus, as explained in Section 4.1.
Uni (for unigram)and bi (for bigram) encode the distribution of the adjective in the corpus in terms ofthe parts of speech of the surrounding words.
Feature analysis of the first experimentshowed that the word preceding and following the target were the most informative,so in the present experiment only a one-word window is taken into account.
Theunigram distribution (uni) encodes each part of speech separately, as was done in thefirst experiment, and the bigram distribution (bi) takes the left and right word jointly,to avoid feature correlation effects.
In the latter feature set, only the 50 most frequentbigrams are considered, to avoid features that are too sparse.55 For a more detailed explanation of the information encoded in feature sets uni and bi, see Boleda (2007,section 5.2.2).596Boleda, Schulte im Walde, and Badia Modeling Regular Polysemy in Catalan AdjectivesTable 9New or revised features in feature set theor.
Each row lists the property we aim to capture andthe features through which the property is encoded.
The information relies on the informationin the corpus, which does not include full syntactic structure.Property Featurestype of determiner NP headed by definite/indefinite/no determineragreement properties gender and number of the NPsyntactic function of head noun subject, object, complement to a prepositioncomplement-bearing adjective followed by a prepositiondistance to the head linear distance (number of words)Finally, feature set theor (for theoretical) generalizes and adds to the theoreticalproperties used in the first experiment (Table 3 in Section 4.2).
Upon inspection ofthe clustering solutions (not reported here for space reasons), some further potentiallyrelevant distributional pieces of information cropped up that were included in thetheor features of the present experiment.
The new features, summarized in Table 9,cover several aspects of the noun phrases (NPs) in which adjectives occur: The typeof determiner of the NP, agreement properties (as these can correlate with semanticproperties), the syntactic function of the head noun, and the presence of a potentialadjective complement.
The latter are usually headed by prepositions (El Joan esta` gelo?sd?en Pere, ?Joan is jealous of Pere?).
Finally, feature distance to the head is a reformulationof feature adjacent from Section 4.2.
It encodes the mean distance of the adjective tothe head, in number of words, as this is a more general definition that alleviates datasparseness.As for feature values, they are computed as in the first experiment (see Equation (1)),with the following exceptions: (1) morph features are of categorical type, so their valuesare not numerical; (2) the two first features in Table 9, due to data sparseness consider-ations, are computed as proportions over the use of the adjective as a nominal modifier(see Equation (3), where amod is the number of occurrences of the adjective as modifier);(3) the values for feature distance to the head, also in Table 9, do not range from 0 to 1 asthe other feature values, because they correspond to the mean distance to the head innumber of words.
The data set used for the present experiments is available at the ACLrepository.6va,i =f (amod, i)f (amod)(3)5.2.2 Feature Tuning.
We test the effects of feature selection in the performance of theclassifiers.
The features are selected according to their performance within the machinelearning algorithm used for classification.
Accuracy for a given subset of features isestimated by cross-validation over the training data.
Because the number of subsets in-creases exponentially with the number of features, this method is computationally veryexpensive, so we use a best-first search strategy.
We also experiment with binarizationof the two categorical features (suffix, derivational type).6 http://aclweb.org/aclwiki/index.php?title=Database_of_Catalan_Adjectives_(Repository).597Computational Linguistics Volume 38, Number 35.3 MethodThe classification task is approached with a two-level architecture.1.
The decision on the class of the adjective is decomposed into three binarydecisions: Is it qualitative or not?
Is it event-related or not?
Is it relationalor not?2.
A complete classification is achieved by merging the results of the binarydecisions.
A consistency check is applied by which (a) if all decisionsare negative, the adjective is assigned to the qualitative class (themost frequent one; this was the case for a mean of 4.6% of the classassignments); (b) if all decisions are positive, we randomly discardone (three-way polysemy is not foreseen in our classification; this wasthe case for a mean of 0.6% of the class assignments).This is the standard architecture for multi-label classification tasks (Schapire and Singer2000; Ghamrawi and McCallum 2005), and it has also been applied to NLP problemssuch as entity extraction and noun-phrase chunking (McDonald, Crammer, and Pereira2005).Note that in the present experiments we change both the classification and theapproach (unsupervised vs. supervised) with respect to the first set of experimentspresented in Section 4, which can be seen as a sub-optimal technical choice.
Afterthe first series of experiments that required a more exploratory analysis, however, webelieve that we have now reached a more stable classification, which we can test bysupervised methods.
In addition, we need a one-to-one correspondence between goldstandard classes and clusters for the approach to work, which we cannot guaranteewhen using an unsupervised approach that outputs a certain number of clusters withno mapping to the gold standard classes.We test two types of classifiers.
The first type are Decision Tree classifiers trainedon different types of linguistic information coded as feature sets.
Decision Trees are oneof the most widely machine learning techniques (Quinlan 1993), and they have beenused in related work (Merlo and Stevenson 2001).
They have relatively few parametersto tune (a requirement with small data sets such as ours) and provide a transparentrepresentation of the decisions made by the algorithm, which facilitates the inspectionof results and the error analysis.
We will refer to these Decision Tree classifiers as simpleclassifiers, in opposition to the ensemble classifiers, which are complex, as explainednext.The second type of classifier we use are ensemble classifiers, which have receivedmuch attention in the machine learning community (Dietterich 2000).
When buildingan ensemble classifier, several class proposals for each item are obtained from multiplesimple classifiers, and one of them is chosen on the basis of majority voting, weightedvoting, or more sophisticated decision methods.
It has been shown that in mostcases, the accuracy of the ensemble classifier is higher than the best individualclassifier (Freund and Schapire 1996; Dietterich 2000; Breiman 2001).
The main reasonfor the general success of ensemble classifiers is that they are more robust towardsthe biases particular to individual classifiers: A bias shows up in the data in the form598Boleda, Schulte im Walde, and Badia Modeling Regular Polysemy in Catalan Adjectivesof ?strange?
class assignments made by one single classifier, which are thereforeoverridden by the class assignments of the remaining classifiers.7For the evaluation, 100 different estimates of accuracy are obtained for each featureset using 10-run, 10-fold cross-validation (10x10 cv for short).
In this schema, 10-foldcross-validation is performed 10 times, that is, 10 different random partitions of thedata (runs) are made, and 10-fold cross-validation is carried out for each partition.
Toavoid the inflated Type I error probability when reusing data (Dietterich 1998), thesignificance of the differences between accuracies is tested with the corrected resampledt-test as proposed by Nadeau and Bengio (2003).85.4 Results5.4.1 Simple Classifiers.
The accuracies for the simple classifiers are shown in Table 10.Part A of the table lists the results for each of the binary decisions (qualitative/non-qualitative, event/non-event, relational/non-relational).
The accuracy for each de-cision is computed independently.
For instance, a qualitative-event adjective is judgedcorrect within the qualitative class iff the decision is qualitative; correct within the eventclass iff the decision is event; and correct within the relational class iff the decision isnon-relational.Part B reports the accuracies for the overall, merged class assignments, takingpolysemy into account (qualitative vs. qualitative-event vs. qualitative-relational vs.event, etc.
).9 In Part B, we report two accuracy measures: full and partial.
Full accuracyrequires the class assignments to be identical (an assignment of qualitative for an adjec-tive labeled as qualitative-relational in the gold standardwill count as an error), whereaspartial accuracy only requires some overlap in the classification of the machine learningalgorithm and the gold standard for a given class assignment (a qualitative assignmentfor a qualitative-relational adjective will be counted as correct).
The motivation forreporting partial accuracy is that a class assignment with some overlap with the goldstandard is more useful than a class assignment with no overlap.
The figures in thediscussion that follow refer to full accuracy unless otherwise stated.For the qualitative and relational classes, taking into account distributional infor-mation allows for an improvement over the default morphology?semantics mappingoutlined in Section 4.5: Feature set al, containing all the features, achieves 75.5% accu-racy for qualitative adjectives; feature set theor, with carefully defined features, achieves86.4% for relational adjectives.
In contrast, morphology seems to act as a ceiling for7 The experiments discussed in this section were carried out with the Weka software package (Wittenand Frank 2011), version 3.6.
The Decision Tree algorithm used is J48, the latest open source version ofC4.5 (Quinlan 1993), with default parameters (binary splits = False, confidence factor for pruning = 0.25,minimum number of instances per leaf = 2, reduced-error pruning = False, subtree raising = True, unpruned =False, use Laplace = False).
AdaBoost has also been used with default parameters (base classifier = DecisionStump, number of iterations = 10, random seed = 1, use resampling instead of reweighting = False, weightthreshold = 100).
For Attribute Bagging, we used the Random Subspace algorithm, with J48 as baseclassifier (parameters as before), bag size = 1/3, and random seed = 1.
We experimented with differentvalues for the number of iterations (see Section 5.4.2).8 Note that the corrected resampled t-test can only compare accuracies obtained under two conditions(algorithms or, as is our case, feature sets); ANOVA would be more adequate.
In the field of machinelearning, there is no established correction for ANOVA for the purposes of testing differences inaccuracy (Bouckaert 2004).
Therefore, we use multiple t-tests instead, which increases the overallerror probability of the results for the significance tests.9 Note that, for each adjective, only 10 different full classification proposals are obtained in each featureset, because each adjective is only used once per run for testing.
Therefore, while the per-class accuracyfor each feature set is assessed from 100 estimates (obtained via 10x10 cv), the accuracy of the differentfeature sets for full classification is assessed comparing 10 accuracies.
This holds for Tables 10 and 11.599Computational Linguistics Volume 38, Number 3Table 10Second model: Results with simple classifiers using different feature sets.
The frequencybaseline (first row) is marked in italics.
The last row, headed by all, shows the accuracyobtained when using all features together for tree construction.
The remaining rows follow thenomenclature in Table 8; a FS subscript indicates that automatic feature selection is used asexplained in Section 4.2.
For each feature set, we record the mean and the standard deviation(marked by ?)
of the accuracies.
Best and second best results are boldfaced.
Significantimprovements over the baseline are marked as follows: *p < 0.05; **p < 0.01; ***p < 0.001.A: Per-class accuracy B: Overall accuracyQualitative Event Relational Full Partialbaseline 65.2 ?
11.1 76.2 ?
9.9 71.9 ?
9.6 51.0 ?
0.0 65.2 ?
0.0morph 68.2 ?
11.1 87.3** ?
6.3 85.2*** ?
7.2 59.9*** ?
2.2 84.7*** ?
0.7morphFS 72.5* ?
7.9 89.1** ?
6.0 84.2*** ?
7.5 60.6*** ?
1.3 87.8*** ?
0.4func 75.1** ?
9.0 76.1 ?
9.8 82.8** ?
7.5 56.0*** ?
1.9 80.6*** ?
1.8uni 64.2 ?
10.8 68.4 ?
12.0 82.1** ?
9.0 42.8 ?
2.7 74.8*** ?
2.6uniFS 66.0 ?
9.3 75.1 ?
10.6 82.2** ?
7.5 52.9 ?
1.9 77.0*** ?
2.0bi 63.8 ?
9.9 66.2 ?
9.8 78.2* ?
8.2 46.1 ?
2.3 77.8*** ?
1.8biFS 67.4 ?
10.6 72.3 ?
10.2 83.0*** ?
8.3 52.3 ?
1.7 76.7*** ?
1.0theor 71.8 ?
10.0 74.1 ?
9.9 86.4*** ?
7.6 54.8*** ?
1.7 81.8*** ?
1.8all 75.5** ?
9.0 86.5** ?
6.4 86.0*** ?
6.5 62.5*** ?
2.5 87.6*** ?
2.5event-related adjectives: The best result, 89.1%, is obtained with morphological featuresusing feature selection.
As will be shown in Section 5.5, event-related adjectives do notexhibit a differentiated distributional profile from qualitative adjectives, which accountsfor the failure of distributional features to capture this class.
As could be expected,the best overall result is obtained with feature set al, that is, by taking all featuresinto account: 62.5% full accuracy is a highly significant improvement over the baseline,51.0%.
The second best results are obtained with morphological features using featureselection (60.6%), due to the high performance of morphological information with eventadjectives.Also note that the POS feature sets, uni and bi, are not able to beat the baseline forfull accuracy: Results are 42.8% and 46.1%, respectively, jumping to 52.9% and 52.3%when feature selection is used, still not enough to achieve a significant improvementover the baseline.
Thus, for this task and this set-up, it is necessary to use well motivatedfeatures.
In this respect, it is also remarkable that feature selection actually decreased per-formance for themotivated distributional feature sets (func, sem, all; results not shown inthe table), and only slightly improved over morph (59.9% to 60.6% accuracy).
Carefullydefined features are of high quality and therefore do not benefit from automatic featureselection.
Actually, Witten and Frank (2011, page 308) state that ?the best way to selectrelevant attributes is manually, based on a deep understanding of the learning problemand what the [features] actually mean.
?In the partial evaluation condition, however, all feature sets achieve a highly signif-icant improvement over the baseline (p < 0.001).
Therefore, the classifications obtainedwith any of the feature sets are more useful than the baseline, in the sense that theypresent more overlap with the gold standard.5.4.2 Ensemble Classifiers.
Error analysis on the results using simple classifiers (notreported for space reasons) revealed that the errors made by the different classifiers,using different feature sets, are qualitatively quite different.
This motivated the use600Boleda, Schulte im Walde, and Badia Modeling Regular Polysemy in Catalan AdjectivesFigure 2Accuracy of the Attribute Bagging classifier as a function of the number of random partitions i.Increasing i leads to a rapid increase of accuracy up to i = 30; after that, accuracy stabilizes andexperiences only a slight increase.of Attribute Bagging (Ho 1998; Bryll, Gutierrez-Osuna, and Quek 2003), an ensembleclassifier (EC) in which the class assignments are obtained by majority voting overrandomly sampled feature subsets.10 Attribute Bagging has two main parameters: thebag size (number of features used for each classification; it was set to 1/3 given resultsreported in the literature, although varying this parameter did not affect the resultsmuch), and the number of iterations i (we tested 3, 4, 5, 6, 10, 20, 30, 40, 50, 60, 70, 80, 90,100; note that our total feature size is 121, see Table 8).
Figure 2 shows that increasing ileads to a rapid increase of accuracy up to i = 30; with higher i, accuracy experimentsonly a slight increase.Table 11 shows the results of Attribute Bagging, compared to the best simple clas-sifier and human agreement (observed agreement, in percentage).
The results obtainedwith AdaBoost (a standard EC; default parameters) are also included as a sanity check.The best results with Attribute Bagging, reported in the table, were obtained usingboth feature selection and binarization (binarization did not improve results for theremaining classifiers in Tables 10 and 11).The Attribute Bagging EC with i = 5 achieves comparable accuracy to AdaBoostwith default parameters.
Full accuracy results with the Attribute Bagging classifier withi = 100 (69.1%) are significantly higher than those of the best simple classifier (62.5%; p <0.0001) and the AdaBoost classifier (p = 0.01; recall however that we did not optimizeAdaBoost?s parameters).
Ensemble classifiers are thus helpful for our task.The best classifier in our experiments (Att.
Bagg.FS,bin,i = 100) obtains 69.1% full and89.0% partial accuracy.
This is comparable to the agreement between the expert anno-tation of the gold standard and naive subjects participating in a large-scale annotationexperiment (po = 0.68, or 68%, and ?
= 0.55 for full accuracy, po = 0.85, or 85%, and ?
=0.72 for overlapping accuracy; see Boleda, Schulte imWalde, and Badia [2008] for detailson the comparison).
If we view human agreement as an upper bound, we have reached10 Grouping subsets according to linguistic considerations (i.e., building an EC over the feature subsetslisted in Table 8) improved upon the best simple classifier, but not upon Attribute Bagging.601Computational Linguistics Volume 38, Number 3Table 11Second model: Results of the ensemble classifiers, compared to the best simple classifier (firstrow) and to the human agreement on the gold standard (last row).
Att.
Bagg.
stands for AttributeBagging, and i corresponds to the number of iterations.
Percentage human agreement is includedin the last row.
An FS subscript indicates feature selection, and bin binarization.
Columns as inTable 10.
Best and second best results are boldfaced.
Significant improvements over the bestsimple classifier are marked as follows: *p < 0.05, **p < 0.01, ***p < 0.001.A: Per-class accuracy B: Overall accuracyQualitative Event Relational Full Partialbest simple (all) 75.5 ?
9.0 86.5 ?
6.4 86.0 ?
6.5 62.5 ?
2.5 87.6 ?
2.5AdaBoost 82.0* ?
8.6 85.6 ?
7.1 88.0 ?
6.7 66.0* ?
1.9 89.9* ?
1.3Att.
Bagg.FS,bin,i=5 77.0 ?
8.7 85.8 ?
7.1 89.0 ?
6.5 66.3* ?
1.1 87.0 ?
1.5Att.
Bagg.FS,bin,i=100 81.0 ?
8.8 86.1 ?
6.9 90.1* ?
5.3 69.1*** ?
1.0 89.0 ?
1.0Human agreement ?
?
?
68 85the maximum accuracy that could be obtained via machine learning for the present task.Further improvements will need to be preceded by an improvement in the agreementscores of human judges, that is, by a better definition of the classes and the classifyingtask.Finally, Table 11 shows that the best results are obtained for the relational class(90.1%), followed by the event class (86.5%), and the qualitative class has the lowestscores (at most 82%).
The qualitative class contains attribute-denoting adjectives, but inthe present definition it is also populated with adjectives that simply do not fit into theother classes (such as intensional adjectives, as explained earlier).
Also, whereas someadjectives in the class are prototypical qualitative adjectives such as gros ?big?
or llarg?long?, others are unprototypical types of properties (subaltern ?subordinate?, subsidiari?subsidiary?).
This factor brings heterogeneity into the class, which justifies the relativelypoor performance of the classifier on this task.
Significantly, also, ECs do not improveupon simple classifiers for the event class; again, morphological information acts asa ceiling and no combination of information serves to go beyond that ceiling, as willbecome clear in the error analysis explained next.5.5 Error AnalysisTable 12 depicts the contingency table of the classifications by the experts (rows) andone randomly chosen run of the Attribute Bagging classifier with i = 100 (columns).
Thetable shows that there are two major sources of errors: First, the confusion between thequalitative and event classes, which is responsible for 14 errors (see dark-gray shadedcells in the table; also note that the related Q?QE and E?QE misclassifications accountfor another 14 errors).
To compare, note that the confusion between the qualitative andrelational classes only accounts for six of the errors, and there are no cases of confusionbetween event and relational adjectives.The second major source of errors is the overgeneration of polysemous adjectives(see medium-gray shaded cells): there are 26 adjectives tagged as monosemous by theexperts and assigned a polysemous class by the system.
To compare, the opposite case(i.e., tagging polysemous adjectives as monosemous) accounts for 13 errors only (seelight-gray shaded cells).
We next examine the two main types of errors in more detail.602Boleda, Schulte im Walde, and Badia Modeling Regular Polysemy in Catalan AdjectivesTable 12Contingency table comparing the gold standard (rows) against run 2 of the Attribute Baggingclassifier with i = 100 (columns).
Dark-gray cells highlight the confusion between the qualitativeand event classes; medium-gray cells highlight the overgeneration of polysemous adjectives;light-gray cells highlight the opposite case, that is, the generation of monosemous adjectivesthat should have been tagged as polysemous.Q E R QR QE ER TotalQ 90 4 2 3 8 0 107E 10 17 0 1 6 3 37R 4 0 20 4 0 2 30QR 5 0 4 13 0 1 23QE 1 1 0 0 5 0 7ER 0 0 2 1 0 3 6Total 110 22 28 22 19 9 2105.5.1 Distinguishing between Qualitative and Event Adjectives.
Table 12 suggests that thereare difficulties in distinguishing event-related from qualitative adjectives.
Feature anal-ysis confirms that the distinction between these two classes is only partially possibleon morphological grounds, but not on distributional grounds.
As for morphologicalinformation, Figure 3 shows that most event-related adjectives are deverbal or participleadjectives, although the reverse is not true: 14 deverbal and two participle adjectives arequalitative.In fact, the class distribution varies with the suffix (see Table 13): Some types, suchas -or and the participle, show a clear predominance of the event class (see dark-grayshaded cells); other types, such as -ble, -iu, or -nt, are more spread in their distribution(see light-gray shaded cells).
Thus, the suffix seems to influence the resulting readings,with some active-like suffixes building a much more transparent relation to theevent (creador ?creating?, exportador ?exporting?, recomanat ?recommended?
), and somepassive-like or stative suffixes being more prone to creating a stative meaning(contingent ?contingent?, formidable ?formidable | terrific?, significatiu ?significant?).
Theaspectual class of the deriving verb (Vendler 1957) also plays a role: For instance,although the meaning of abundant (?abundant?)
is related to that of the verb abundar(?abound?
), it clearly has a more stative (property-like) meaning than many of the otherevent adjectives, due to the fact that the deriving verb is stative.
Correspondingly,Figure 3Derivational types in the qualitative (Q) and event-related (E) classes.
The bars represent theclasses, and the colors the derivational types, as shown in the legend.603Computational Linguistics Volume 38, Number 3Table 13Contingency table of the most frequent deverbal suffixes (rows) and classification (columns).Dark-gray cells highlight suffixes that mostly create event-related adjectives, and light-gray cellsindicate suffixes with a more spread class distribution.Q E R QR QE ER Total-ble 3 6 0 0 1 1 11-iu 3 1 1 2 0 4 11-nt 4 6 0 0 0 1 11-or 1 10 0 0 0 0 11participle 2 8 0 0 5 0 15Total 16 36 3 2 7 6 70abundant is classified as qualitative by the Attribute Bagging algorithm.
This variation inthe morphology?semantics interface is also mirrored in the feature value distributions,as will be shown subsequently.As for distributional information, Figure 4 depicts the feature value distributionfor nine selected features across basic classes qualitative (Q), event-related (E), andrelational (R), excluding polysemous adjectives.
The figure clearly shows that, whereasrelational adjectives tend to have a differentiated value distribution for many ofthe features, the values for the event-related class in general overlap with those ofthe qualitative class.
In fact, of the 18 theoretically motivated features defined for theexperiments, only two exhibit statistically significant differences in the distributionof the qualitative and event-related class according to a two-tailed t-test (?
= 0.01; noequality of variance assumed).
These are pre-nominal and complement-bearing (graphs Aand I in Figure 4; df = 108.9/54.6, t = 3.56/?3.09, p-value = 0.0005/0.003, respectively).These two features show that in general event-related adjectives appear less often thanqualitative adjectives in pre-nominal position and tend to bear more complements.Both differences are presumably due to the fact that many event adjectives inheritthe argument structure of the deriving verb, with arguments expressed via PPs,constituting heavier constituents that are placed after the head noun.
This is but a slighttendency and it is not homogeneous through the class, however.The remaining features do not show differences between event and qualitativeadjectives, but rather properties of relational adjectives.
In addition to the propertiesthat were already known, the figure shows that relational adjectives appear more oftenin definite NPs acting as preposition complements (graphs E and H).
Thus, the typicalsyntactic context for a relational adjective is preposition + definite determiner + noun +relational adjective).
This type of adjective also appears slightly more often with femininehead nouns, which could be due to the fact that, in Catalan, many abstract nouns ( f?
?sica?physics?, capacitat ?ability?)
are feminine, for morphological reasons.
These nouns areoften modified by relational adjectives to select for subtypes of the class of objectsdenoted by the nouns (McNally and Boleda 2004).Another difficulty in the distributional characterization of the event class is thefact that it is quite heterogeneous, due to the variation at the morphology?semanticsinterface discussed earlier.
This can be traced in Figure 4 by the fact that for most ofthe features, the box of the event class is larger than the box of the other two classes,meaning that there is more variation within the event class than within the other twoclasses.604Boleda, Schulte im Walde, and Badia Modeling Regular Polysemy in Catalan AdjectivesFigure 4Feature value distribution across classes qualitative (Q), event-related (E), and relational (R) fornine selected features (see Section 5.2 for the definition of these features).To sum up, morphological features can quite reliably spot event-related adjectives,but distributional information cannot.
As a result, in the cases where morphology givesthewrong prediction, nothing can be done on the distributional side to remedy this.
Thisresults in the confusion of event-related and qualitative adjectives shown in Table 12.5.5.2 Detecting Polysemous Adjectives.
Recall from Table 12 that the system overgeneratespolysemous adjectives: There are 26 monosemous adjectives assigned to a polysemousclass.
One of the reasons for this overgeneration is the procedure followed.
The proce-dure treats the decision on each of the basic classes as if they were all independent.Thus, the probability for an adjective being polysemous amounts to the product ofthe probabilities of the adjective belonging to each of the basic classes, as expressedin Equation (4) for two arbitrary given classes, A and B.p(AB) = p(A) ?
p(B) (4)Table 14 shows that the distribution of polysemous items predicted by Equation (4)is more similar to the distribution obtained with the best machine learning classifier605Computational Linguistics Volume 38, Number 3Table 14Distribution of polysemous items and absolute numbers, according to the prediction(Equation (4); first column), in the machine learning (ML) results shown in Table 12(second column), and in the gold standard (GS; third column).Predicted ML GSQR 15 22 23QE 19 19 7ER 5 9 6(ML) than to the distribution of polysemous items in the gold standard (GS) for the QEcases.
The distribution is estimated from the frequency over the 210 adjectives in thegold standard, and shown as absolute numbers.Both Equation (4) and the ML classifier assign 19 adjectives to the QE polysemytype, although the gold standard contains only 7 QE adjectives.
The equation predictsfewer QR adjectives than observed in the data, but in this case the classifier produces asimilar number of QR adjectives than attested (22 vs. 23).
Finally, the classifier producesmore ER adjectives than observed and also than predicted by Equation (4), but inthis case the numbers are so small that no clear tendencies can be observed.
Thus,the procedure followed can be said to cause the overgeneration of items for the QEpolysemy type, but it does not account for the other two polysemous classes.Further qualitative analysis on the overgenerated polysemous adjectives (corre-sponding to the middle-gray cells in Table 12; not reported because of space concerns)showed that different types of evidence motivate the inclusion of monosemous adjec-tives in two classes, causing them to be considered polysemous.
This suggests that,because polysemous adjectives exhibit only partial or limited evidence of each class,the threshold for positive assignment to a class is lowered, resulting in the observedovergeneration.
Recall that at the beginning of this section, when introducing themodel,we warned that it would be specially challenging to distinguish between noise andevidence for a given class.
We have indeed found this to be a challenge.
The mentionedeffect is amplified by the procedure followed, which assumes that the class assignmentsare independent, thus not adequately enough modeling the empirical distribution ofpolysemy.6.
Discussion: Towards a Model for Regular PolysemyThe acquisition experiments presented in Sections 4 and 5 correspond to two differ-ent underlying models of regular polysemy.
Figure 5 represents the two models in asimplified scenario with just two basic classes (A and B).
The first model (Figure 5(a);experiments in Section 4) treats polysemous words in terms of independent classes.
Thesecond model (Figure 5(b); experiments in Section 5) treats polysemous words alike tothose of the basic classes: Polysemous assignments result frommembership in two basicclasses.As can be seen in the figure, there are two main differences between the models.First, the number of classes considered: Whereas the second model only considers nclasses, in the general case the first model will need to considern+(n2)606Boleda, Schulte im Walde, and Badia Modeling Regular Polysemy in Catalan AdjectivesFigure 5The two models of regular polysemy tested in this article, assuming a simplified scenario withjust two basic classes (A and B).
The rows represent three different cases: one monosemousadjective of class A (MonosemousA), one monosemous adjective of class B (MonosemousB), andone polysemous adjective (PolysemousAB).
The columns represent the classes assumed in eachmodel: Three classes (a), or only two (b).
The correct class assignments for each case are shownas dashed rectangles.classes (n monosemous classes plus(n2)polysemous classes, all the possible two-combinations of the monosemous classes).
This formula assumes that only two-wayregular polysemy is allowed, as in this article; polysemy across three or more classeswould make the explosion of classes even worse.
It is clear that the second model iseasier to learn.The second difference concerns the way class assignments to polysemous wordsare carried out.
In the first model, polysemous words are assigned to one single, inde-pendent class, whereas in the second they are assigned to each of the two basic classesthat give rise to the regular polysemy.
Recall that the motivation for the first model wasthat?given that regularly polysemous adjectives show a particular hybrid behavior?we could expect that polysemous adjectives could be characterized as differentiatedclasses.
This expectation has clearly not been borne out.
A further problemwith the firstmodel it that it in principle allows for a polysemous class AB whose properties do notnecessarily have anything to do with those of the basic classes A and B.
The secondmodel, in contrast, enforces that polysemous adjectives exhibit properties of each of theclasses they participate in, which is both theoretically and empirically more adequate.For these reasons, we believe that the secondmodel is more suitable to represent regularpolysemy than the first model.The second model is also not completely satisfactory, however.
As discussed in theprevious section, in the current implementation of the model the class assignments areassumed to be independent (though this need not be the case in other instantiations ofthe model).
Also, in a way, it is at the opposite end of the scale with respect to the firstmodel: Whereas in the first model polysemous adjectives do not need to have anythingin common with the basic classes, in the second model a polysemous word is assumedto be just like any other word in each of the basic classes.
For instance, a qualitative-relational adjective is assumed to function both as a full-fledged qualitative adjectiveand a full-fledged relational adjective.
By their very nature, polysemous words willshow only some evidence for each of the classes, as their occurrences (and thus theirproperties) will be distributed across the two classes.
Therefore, they will be untypicalmembers of at least one of the intervening classes.607Computational Linguistics Volume 38, Number 3An alternative instantiation of the second model could use soft clustering (Pereira,Tishby, and Lee 1993; Rooth et al 1999; Korhonen, Krymolowski, andMarx 2003), whichassigns a probability to each of the classes and is thus not bound to a hard yes/nodecision, as our approach does.
From a theoretical point of view (and for many practicalpurposes such as dictionary construction), however, a distinction betweenmonosemousand polysemous words is desirable, which adds a further parameter to be optimizedin a soft clustering setting.
Overlapping clustering (Banerjee et al 2005), which allowsfor membership in multiple clusters, avoids this difficulty.
Both methods have theadvantage that they do not assume independence of the decisions.
The most seriousproblem for the experiments presented in this article, however, would presumably alsobe a problem for these settings: The fact that the skewed sense distribution of manywords makes it difficult to distinguish evidence for a particular class from noise.
Inthe soft clustering setting, for instance, it would be hard to distinguish whether 10%evidence for class A and 90% for class B corresponds to polysemy with a skeweddistribution, to noise in the data, or simply to an untypical instance.To sum up, the main problem for the models presented in this article is that nei-ther model can capture the distributional connection between P(AB) and P(A), eitherbecause AB and A are seen as unrelated atoms in the first place (first model), or becauseAB is diluted into A and B (second model).
A more refined statistical approach that canmodel this interdependency is needed for further progress.
Such a model should takeinto account both the differences of polysemous adjectives with respect to the otheradjectives in the basic classes (first model) and their similarities (second model), thusdirectly capturing their hybrid behavior.7.
ConclusionThis article has tackled the automatic induction of semantic classes for Catalan ad-jectives, with a special emphasis on regular polysemy.
To our knowledge, this is thefirst time that such an endeavor has been carried out, as (1) related work on lexicalacquisition has focused on verbs (and, to a lesser extent, nouns) and onmajor languagessuch as English and German; and (2) polysemy in general has been largely ignored inlexical acquisition, and regular polysemy has only been sparsely addressed in empiricalcomputational semantics.We have explored the relationship between observable cues and semantic proper-ties for adjectives, and, specifically, the morphology?semantics and syntax?semanticsinterfaces.
We have showed that there is a systematic relation between the type ofdenotation of an adjective and its morphological and distributional properties.
Ourexperiments have furthermore related the linguistic properties of adjectives as describedin the literature to the information that can be extracted from linguistic resources, suchas corpora or lexical databases.
The presented results and analyses provide empiricalsupport for the qualitative and relational classes, defined in theoretical work, and bringevent-related adjectives into focus, a type of adjective that has been largely neglected inthe literature.This article has focused on Catalan as a case study, but most of the propertiesdiscussed (predicativity, gradability, complementation patterns), as well as the typesof polysemy explored, are relevant for a broader range of languages, specially Indo-European languages (Dixon and Aikhenvald 2004).
The approach does not requiredeep-processing resources (full parsing, semantic tagging, semantic role labeling),which makes it useful for lesser-researched languages.608Boleda, Schulte im Walde, and Badia Modeling Regular Polysemy in Catalan AdjectivesThe experiments show that a major bottleneck for our purposes is the definition ofthe classification itself: The machine learning results obtained have reached an upperbound, as the best classifier has achieved 69.1% accuracy (against a 51.0% baseline), andthe human agreement is 68%.
Thus, improvements in the computational task will needto be preceded by improvements in the agreement scores, that is, by a better and clearerdefinition of the classification and the classification task.
We have shown that this isby no means a trivial issue.
In fact, low inter-coder agreement scores are a problem formachine learning approaches to semantic and discourse-related phenomena in general.This is in contrast to tasks such as POS tagging or syntactic parsing, where relativelyhigh inter-coder agreement scores are achieved.
This state of affairs is probably due tothe fact that semantic and pragmatic phenomena are much less well understood thanmorphological or syntactic phenomena.Our experiments have highlighted a number of problems with the current classifi-cation proposal.
First, the distinction between event-related and qualitative adjectives.The event class cannot be distinguished from the qualitative class with the distributionalinformation used in this article, and its members are not homogeneous.
We have shownthat factors such as the aspectual class of the deriving verb or the suffix of the deverbaladjective play a role in the semantic and syntactic behavior of these adjectives thatshould be further explored.
Also, a crucial type of evidence remains to be explored,namely, the selectional preferences of adjectives.
These may be a relevant clue to the dif-ferences between qualitative and event-related adjectives.
The second main problem isthe fact that the qualitative class contains adjectives that do not fit into the other classes,constituting a sort of ?catch-all?
class.
A natural extension for the work presented inthis article would be to define a finer-grained categorization including the problematiccases discussed earlier.
For instance, adjectives deriving from stative verbs could bedistinguished from those deriving from active verbs, and different types of qualitativeadjectives could be treated as different classes.As for regular polysemy, we have shown that polysemous adjectives exhibit ahybrid behavior, with properties from all the classes involved in each type of regularpolysemy.
We have empirically tested two models of the phenomenon aimed atexploiting this hybrid behavior.
The first model treats polysemous words in termsof independent classes, and we have argued that it is not adequate, neither froma theoretical nor from an empirical perspective.
The second model assumes thatpolysemous words belong to each of the basic classes participating in the regularpolysemy.
This model is more adequate than the first one, as it accounts for theproperties of the basic classes found in polysemous words, but it fails to account for thedifferences between polysemous and monosemous words.
To improve on the modelingof regular polysemy, we plan to move to token-based (word-in-context) models(Schu?tze 1998; Erk and Pado?
2010), as opposed to type-based models as we have donein this article.
This should in turn shed light into the problem of distinguishing betweenevidence for a particular class from noise, discussed previously.Finally, at a methodological level, we have illustrated how the broad coverage,large-scale, radically empirical approaches developed in computational linguistics canbe of use to uncover phenomena and facts that are relevant for the study of language,providing complementary evidence to the analytic tools traditionally used by linguists.Most prominently, we have shown that (1) by randomly sampling the set of words to beanalyzed, new or neglected phenomena emerge; (2) the feature representation typicallyused by machine learning algorithms provides an empirical handle to the linguisticproperties of words that can be explored in different ways (e.g., to test hypothesesabout the morphology-syntax and semantics-syntax interfaces); (3) machine learning609Computational Linguistics Volume 38, Number 3experiments provide a framework for the systematic evaluation of different modelsof the phenomenon under study (in our case, both adjective classification and regularpolysemy).
Computational linguistic studies are also inherently limited in severalaspects, such as the type of evidence that can be used or the ways in which it can beused.
Despite these limitations, we believe that empirical computational linguisticsapproaches are a gold mine of new knowledge about language.Appendix: Gold Standard DataIn the following, we include the lemmata that were manually classified for the first andsecond set of experiments, respectively (Sections 4 and 5).
For details on the classes andthe methodology, see the body of the article.
The translation of the adjectives has beencarried out with the help of the Spanish?English/English?Spanish Collins Dictionary(3rd edition) and Google Translator.11 Different senses are separated with a vertical bar(?|?
), different translations of the same sense with a comma (?,?).
Whenever possible,we have included adjective equivalents; many of the relational adjectives, however, areequivalent to attributive uses of nouns.
Such nominal translations have been markedwith (attr.
).Recall that the gold standard for the second experiment, together with its featurevalues, is available at the ACL repository (see URL in footnote 6).Gold standard for the experiments with the first model (Section 4). intensional (I): mer ?mere?, presumpte ?alleged?. qualitative (Q): accidental ?accidental?, accidentat ?uneven, rough | injured?,alienant ?alienating?, anticlerical ?anticlerical?, avergonyit ?ashamed?, bastard?bastard?, benigne ?benign?, caracurt ?short-faced?, coherent ?coherent?,colpidor ?striking?, contradictori ?contradictory?, cosmopolita ?cosmopolitan?,destructor ?destructive?, diversificador ?diversifying?, duratiu ?durative?,esca`pol ?fleeing?, esfere?
?dor ?terrifying?, evident ?evident?, exempt ?exempt?,expeditiu ?expeditious?, fortu?
?t ?fortuitous?, gradual ?gradual?, grandio?s?grand?, gratu?
?t ?free | gratuitous?, honest ?honest?, implacable ?implacable?,infrequ?ent ?infrequent?, innoble ?ignoble?, inquiet ?anxious | restless?,insalvable ?insuperable?, inservible ?useless?, invers ?inverse?, irreductible?unyielding?, laber?
?ntic ?labyrinthine?, llaminer ?sweet-toothed | appetising?,malalt ?ill?, morat ?purple?, negatiu ?negative?, nombro?s ?numerous?, peno?s?distressing?, preeminent ?pre-eminent?, preponderant ?preponderant?,raonable ?reasonable?, real ?real?, representatiu ?representative?, sobrenatural?supernatural?, subsidiari ?subsidiary?, supraracional ?supra-rational?, trivial?trivial?, uniforme ?uniform?, usual ?usual?, uto`pic ?Utopian?, vitalista?vitalist(ic)?. relational (R): adquisitiu ?acquisitive?, alfabe`tic ?alphabetical?, carbo`nic?carbonic?, cervical ?neck (attr.
), cervical?, climatolo`gic ?climatologic?,col?laborador ?collaborating?, curatiu ?curative?, diofa`ntic ?diophantic?,formatiu ?formative?, freudia` ?Freudian?, governatiu ?governmental?,indicador ?indicating?, onoma`stic ?name (attr.
), onomastic?, parlant ?talking?,11 http://translate.google.com.610Boleda, Schulte im Walde, and Badia Modeling Regular Polysemy in Catalan Adjectivespenitenciari ?penitentiary, prison (attr.
)?, periglacial ?periglacial?, pesquer?fishing?, petri ?stony?, preescolar ?preschool (attr.
)?, protector ?protecting?,salvador ?rescueing?, sociocultural ?sociocultural?, sud-africa` ?South African?,ta`ctil ?tactile?, terciari ?tertiary?, terminolo`gic ?terminological?, topogra`fic?topographic(al)?, tora`cic ?thoracic?, vaginal ?vaginal?, valencianoparlant?Valencian-speaking?, ventral ?ventral?, veterinari ?veterinary?, voca`lic?vocalic, vowel (attr.
)?, xine`s ?Chinese?. intensional-qualitative (IQ): antic ?ancient | former?. qualitative-relational (QR): alemany ?German?, celest ?celestial | sky blue?,contaminant ?pollutant?, cultural ?cultural?, femen??
?female (attr.)
| feminine?,iro`nic ?irony (attr.)
| ironic?, menorqu??
?Menorcan?, militar ?war (attr.)
|military?, sonor ?sound (attr.)
| sonorous?, triomfal ?triumphal | triumphant?,viril ?man (attr.)
| virile, manly?.Gold standard for the experiments with the second model (Section 5). qualitative (Q): absort ?absorbed?, aleatori ?random?, altiu ?haughty?, ample?wide?, animal ?animal?, ano`mal ?anomalous?, baix ?low?, benigne ?benign?,bord ?infertile (plant) | stroppy (person)?, caduc ?deciduous?, calb ?bald?,capac?
?able?, cardinal ?cardinal?, caut ?cautious?, ce`lebre ?famous?, concret?concrete?, conservador ?conservative?, contingent ?contingent?, cru ?raw |crude?, curull ?full?, decisiu ?decisive?, deficient ?deficient, defective?, delicio?s?delicious?, desproporcionat ?disproportionate?, dificulto?s ?difficult?, esquerre?left?, excels ?sublime?, exquisit ?exquisite?, fluix ?weak | loose?, foll ?crazy?,formidable ?formidable | terrific?, franc ?frank?, fresc ?fresh?, gros ?big?, gruixut?thick?, humil ?humble?, igual ?equal, alike?, imperfecte ?imperfect?, impropi?improper?, incomplet ?incomplet?, inhuma` ?inhuman?, insuficient?insufficient?, integral ?integral | wholegrain?, ?
?ntegre ?entire?, intel?ligent?intelligent?, intern ?intern?, l?
?quid ?liquid?, llarg ?long?, llis ?smooth?, mal?bad?, ma`xim ?maximum?, menor ?minor | smaller | younger?, m?
?nim?minimum?, moll ?wet?, morat ?purple?, mutu ?mutual?, notori ?notorious?,ocult ?hidden?, opac ?opaque?, paradoxal ?paradoxical?, peculiar ?peculiar?,perillo?s ?dangerous?, pertinent ?pertinent?, pessimista ?pessimistic?, pla`cid?placid?, precoc?
?precocious?, predilecte ?favorite?, primari ?primary?, primitiu?primitive?, propens ?prone?, pro`sper ?prosperous?, prudent ?prudent?,punxegut ?sharp-pointed?, quadrat ?square?, reaccionari ?reactionary?, recent?recent?, rec?
?proc ?reciprocal?, remarcable ?remarkable?, responsable?responsible?, r?
?gid ?rigid?, roent ?burning?, sant ?saint?, semicircular?semicircular?, serio?s ?serious?, significatiu ?significant?, silencio?s ?silent?,similar ?similar?, simplista ?simplistic?, subaltern ?subordinate?, sublim?sublime?, subsidiari ?subsidiary?, subterrani ?underground?, superflu?superfluous?, tenac?
?tenacious?, terrible ?terrible?, t?
?pic ?typical?, titular?titular, official?, tort ?bent?, total ?total?, tou ?soft?, triangular ?triangular?,vague ?vague?, ver ?true?, vicio?s ?vicious?, vigoro?s ?vigorous?, viril ?virile?,vulgar ?vulgar?. event-related (E): abundant ?abundant?, abundo?s ?plentiful?, acompanyat?accompanied?, admirable ?admirable?, contradictori ?contradictory?,convincent ?convincing?, creador ?creative?, divergent ?divergent?, encarregat611Computational Linguistics Volume 38, Number 3?in charge?, exigent ?demanding?, exportador ?exporting?, immutable?immutable?, imperceptible ?imperceptible?, informatiu ?informative?, irat?angry?, matiner ?who gets up early?, motor ?motor?, oblidat ?forgotten?,orientat ?oriented?, picat ?pricked |minced | offended?, preferible ?preferable?,productor ?producing?, prome`s ?promised?, protector ?protecting, protective?,receptor ?receiving?, recomanat ?recommended?, regulador ?regulating?,resultant ?resulting?, revelador ?revealing?, salvador ?savior?, satisfactori?satisfactory?, sospito?s ?suspicious | suspect?, temible ?fearsome?, treballador?working?, variable ?variable?, victorio?s ?victorious?, vivent ?living?. relational: america` ?American?, angular ?angular?, ato`mic ?atomic?, barcelon??
?Barcelonian?, calcari ?calcareous?, causal ?causal?, ciutada` ?city (attr.
)?,conflictiu ?conflict (attr.
)?, corporatiu ?corporate?, crania` ?skull (attr.
)?, diari?daily?, ele`ctric ?electric(al)?, epistemolo`gic ?epistemological?, esce`nic ?scenic?,estacional ?seasonal?, fango?s ?muddy?, imperial ?imperial?, lleidata` ?Leridan?,manresa` ?Manresan?, marxia` ?Marx (attr.
)?, melo`dic ?melodic?, mercantil?mercantile?, obrer ?working-class, labour (attr.
)?, ontolo`gic ?ontological?,pasqual ?paschal?, peninsular ?peninsular?, renaixentista ?Renaissance (attr.
)?,respiratori ?respiratory?, terrestre ?terrestrial?, viari ?road (attr.
)?. event-qualitative (EQ): animat ?animate | lively?, cridaner ?who usuallyshouts | loud-colored?, embolicat ?wrapped up |messy?, encantat ?charmed |happy?, obert ?opened | open?, raonable ?that can be reasoned on |reasonable, fair?, sabut ?known | wise?. event-relational (ER): comptable ?countable | account (attr.
)?, cooperatiu?cooperative | cooperative (attr.
)?, digestiu ?digestive | digestion (attr.
)?,docent ?teaching | educational?, nutritiu ?nutritive | nutritional?, vegetatiu?vegetative | vegetation (attr.
)?. qualitative-relational (QR): alegre ?cheerful?, amoro?s ?lovely | love (attr.
)?,anarquista ?anarchistic | anarchist?, capitalista ?capitalistic | capitalist?,catalanista ?Catalanistic | Catalanist?, comunista ?communistic | communist?,diu?rn ?diurnal, day (attr.
)?, ero`tic ?erotic | love (attr.
)?, familiar ?familiar |family (attr.
)?, feminista ?feminist | feminism (attr.
)?, huma` ?humane |human?, infantil ?childish | child (attr.
)?, intu?
?tiu ?intuitive | intuition (attr.
)?,local ?local | place (attr.
)?, nocturn ?nocturnal, night (attr.
)?, poe`tic ?poetic,idealized | poetry (attr.
)?, professional ?
(worker) who works well |professional, job (attr.
)?, revolucionari ?revolutionary | revolution (attr.
)?,sensitiu ?sensitive | sensation (attr.
)?, socialista ?socialistic | socialist?, tur?
?stic?touristy | tourist (attr.
)?, unitari ?unitary | union (attr.
)?, utilitari ?utilitarian |utility (attr.
)?.AcknowledgmentsThe authors wish to thank A`ngel Gil,Laia Mayol, Mart??
Quixal, and RoserSanroma` for participating in the annotationof the gold standards; David Farwell,Louise McNally, Sebastian Pado?, and Mart?
?Quixal for comments and discussion onprevious versions of this article; JosepMaria Boleda, Montse Cuadros, and EdgarGonza`lez for technical help; and theanonymous reviewers for their constructivecriticism, which has greatly helped improvethe article.
This work has been supportedvia Ph.D. grants to the first author by theGeneralitat de Catalunya (2001FI 00582), theFundacio?n Caja Madrid, and the UniversitatPompeu Fabra; also by the Ministry of612Boleda, Schulte im Walde, and Badia Modeling Regular Polysemy in Catalan AdjectivesEducation and the Ministry of Science andTechnology of Spain under contractsFFI2010-09464-E (REDISIM), FFI2010-15006(OntoSem 2), TIN2009-14715-C04-04(KNOW2), and JCI2007-57-1479; and bythe European Union via the EU PASCAL2Network of Excellence (FP7-ICT-216886).The second author was funded by the DFGCollaborative Research Center 732.ReferencesAlmuhareb, Abdulrahman and MassimoPoesio.
2004.
Attribute-based andvalue-based clustering: An evaluation.In Proceedings of EMNLP 2004,pages 158?165, Barcelona.Alonge, Antonietta, Francesca Bertagna,Nicoletta Calzolari, Adriana Roventini,and Antonio Zampolli.
2000.
Encodinginformation on adjectives in a lexical-semantic net for computationalapplications.
In Proceedings of the 1stNorth American Chapter of the Associationfor Computational Linguistics Conference,NAACL ?00, pages 42?49, San Francisco, CA.Alsina, A`lex, Toni Badia, Gemma Boleda,Stefan Bott, A`ngel Gil, Mart??
Quixal,and Oriol Valent??n.
2002.
CATCG: ageneral purpose parsing tool applied.
InProceedings of Third International Conferenceon Language Resources and Evaluation,volume III, pages 1130?1135, Las Palmas.Ando, Rie Kubota.
2006.
Applyingalternating structure optimization to wordsense disambiguation.
In Proceedings of theTenth Conference on Computational NaturalLanguage Learning, pages 77?84, New YorkCity, NY.Apresjan, Juri D. 1974.
Regular polysemy.Linguistics, 142:5?32.Artstein, Ron and Massimo Poesio.
2008.Inter-coder agreement for computationallinguistics.
Computational Linguistics,34(4):555?596.Bally, Charles.
1944.
Linguistique ge?ne?rale etlinguistique franc?aise.
A. Francke, Berne.Banerjee, Arindam, Chase Krumpelman,Joydeep Ghosh, Sugato Basu, andRaymond J. Mooney.
2005.
Model-basedoverlapping clustering.
In Proceedingsof the Eleventh ACM SIGKDD InternationalConference on Knowledge Discovery in DataMining, KDD ?05, pages 532?537,New York, NY.Bohnet, Berndt, Stefan Klatt, and LeoWanner.
2002.
An approach to automaticannotation of functional information toadjectives with an application to German.In Proceedings of the 3rd LREC Conference,Workshop: Linguistic Knowledge Acquisitionand Representation, pages 24?33,Las Palmas.Boleda, Gemma.
2007.
Automatic Acquisitionof Semantic Classes for Adjectives.
Ph.D.thesis, Pompeu Fabra University.Boleda, Gemma, Toni Badia, and Eloi Batlle.2004.
Acquisition of semantic classes foradjectives from distributional evidence.In Proceedings of the 20th InternationalConference on Computational Linguistics(COLING-04), pages 1119?1125,Morristown, NJ.Boleda, Gemma, Sabine Schulte im Walde,and Toni Badia.
2008.
Analysis ofagreement on adjective semanticclassification.
Research on Languageand Computation, 6(3):247?271.Bouckaert, Remco R. 2004.
Estimatingreplicability of classifier learningexperiments.
In Proceedings of theTwenty-first International Conferenceon Machine Learning, ICML ?04,pages 15?23, New York, NY.Brants, Thorsten.
2000.
Inter-annotatoragreement for a German newspapercorpus.
In Second International Conferenceon Language Resources and Evaluation,LREC ?02, Athens.Breiman, Leo.
2001.
Random forests.MachineLearning, 45:5?23.Bresnan, Joan.
1982.
The passive in lexicaltheory.
In Joan Bresnan, editor, The MentalRepresentation of Grammatical Relations.The MIT Press, Cambridge, MA,pages 3?86.Bresnan, Joan.
1995.
Lexicality and argumentstructure.
Invited talk at the Paris Syntaxand Semantics Conference.
12 October.Brody, Samuel and Mirella Lapata.
2009.Bayesian word sense induction.
InProceedings of the 12th Conference of theEuropean Chapter of the Association forComputational Linguistics, EACL ?09,pages 103?111, Stroudsburg, PA.Bryll, Robert K., Ricardo Gutierrez-Osuna,and Francis K. H. Quek.
2003.
Attributebagging: Improving accuracy of classifierensembles by using random featuresubsets.
Pattern Recognition,36(6):1291?1302.Buitelaar, Paul.
1998.
CoreLex: An ontologyof systematic polysemous classes.In Proceedings of Formal Ontologies inInformation Systems, pages 221?235,Amsterdam.Burnage, Gavin and Dominic Dunlop.
1992.Encoding the British National Corpus.
In613Computational Linguistics Volume 38, Number 3English Language Corpora: Design, Analysisand Exploitation.
Papers from the ThirteenthInternational Conference on English LanguageResearch on Computerized Corpora,pages 79?95, Amsterdam.Carvalho, Paula and Elisabete Ranchhod.2003.
Analysis and disambiguation ofnouns and adjectives in Portuguese byFST.
In Proceedings of the Workshop onFinite-State Methods for Natural LanguageProcessing at EACL-03, pages 105?112,Budapest.Chao, Gerald and Michael G. Dyer.2000.
Word sense disambiguation ofadjectives using probabilistic networks.In Proceedings of the 18th Conference onComputational Linguistics (COLING-00),pages 152?158, Morristown, NJ.Copestake, Ann and Ted Briscoe.
1995.Semi-productive polysemy and senseextension.
Journal of Semantics, 12:15?67.de Marneffe, Marie-Catherine,Christopher D. Manning, andChristopher Potts.
2010.
?Was it good?
Itwas provocative.?
Learning the meaningof scalar adjectives.
In Proceedings of the48th Annual Meeting of the Association forComputational Linguistics, ACL ?10,pages 167?176, Stroudsburg, PA.Demonte, Violeta.
2011.
Adjectives.In Klaus von Heusinger, ClaudiaMaienborn, and Paul Portner, editors,Semantics: An International Handbook ofNatural Language Meaning, volume 2.Mouton de Gruyter, Berlin,pages 1314?1340.Dhillon, Inderjit S. and Dharmendra S.Modha.
2001.
Concept decompositions forlarge sparse text data using clustering.Machine Learning, 42:143?175.Dietterich, Thomas G. 1998.
Approximatestatistical tests for comparing supervisedclassification learning algorithms.
NeuralComputation, 10(7):1895?1924.Dietterich, Thomas G. 2000.
An experimentalcomparison of three methods forconstructing ensembles of decision trees:Bagging, boosting, and randomization.Machine Learning, 40:5?23.Dixon, Robert M. W. and Alexandra Y.Aikhenvald, editors.
2004.
AdjectiveClasses.
Oxford University Press, Oxford.Dorr, Bonnie J. and Douglas Jones.
1996.
Roleof word sense disambiguation in lexicalacquisition: Predicting semantics fromsyntactic cues.
In Proceedings of the 16thInternational Conference on ComputationalLinguistics (COLING-96), pages 322?333,Morristown, NJ.Erk, Katrin and Sebastian Pado?.
2010.Exemplar-based models for word meaningin context.
In Proceedings of the ACL 2010Conference Short Papers, ACLShort ?10,pages 92?97, Stroudsburg, PA.Everitt, Brian S., Sabine Landau, andMorven Leese.
2001.
Cluster Analysis.Arnold, London, 4th edition.Freund, Yoav and Robert E. Schapire.1996.
Experiments with a new boostingalgorithm.
In Proceedings of the ThirteenthInternational Conference on MachineLearning, ICML ?96, pages 148?156,San Francisco, CA.Ghamrawi, Nadia and Andrew McCallum.2005.
Collective multi-label classification.In Proceedings of the 14th ACM InternationalConference on Information and KnowledgeManagement, CIKM ?05, pages 195?200,New York, NY.Hatzivassiloglou, Vasileios and Kathleen R.McKeown.
1993.
Towards the automaticidentification of adjectival scales:Clustering adjectives according tomeaning.
In Proceedings of the 31st AnnualMeeting of the Association for ComputationalLinguistics (ACL?93), pages 172?182,Morristown, NJ.Hatzivassiloglou, Vasileios and Kathleen R.McKeown.
1997.
Predicting the semanticorientation of adjectives.
In Proceedingsof the Eighth Conference of the EuropeanChapter of the Association for ComputationalLinguistics (EACL?97), pages 174?181,Morristown, NJ.Hatzivassiloglou, Vasileios and Janyce M.Wiebe.
2000.
Effects of adjectiveorientation and gradability on sentencesubjectivity.
In Proceedings of the 18thInternational Conference on ComputationalLinguistics (COLING-00), pages 299?305,Morristown, NJ.Hindle, Donald.
1990.
Noun classificationfrom predicate-argument structures.
InProceedings of the 28th Annual Meeting of theAssociation for Computational Linguistics,ACL ?90, pages 268?275, Stroudsburg, PA.Ho, Tin Kam.
1998.
The random subspacemethod for constructing decision forests.IEEE Transactions on Pattern Analysis andMachine Intelligence, 20:832?844.Joanis, Eric, Suzanne Stevenson, and DavidJames.
2008.
A general feature space forautomatic verb classification.
NaturalLanguage Engineering, 14(03):337?367.Justeson, John S. and Slava M. Katz.
1995.Principled disambiguation: Discriminatingadjective senses with modified nouns.Computational Linguistics, 21(1):1?27.614Boleda, Schulte im Walde, and Badia Modeling Regular Polysemy in Catalan AdjectivesKarypis, George.
2002.
CLUTO?AClustering Toolkit.
Technical Report TR02-017, Department of Computer Scienceand Engineering, University of Minnesota,Minneapolis, MN.Kaufman, Leonard and Peter J. Rousseeuw.1990.
Finding Groups in Data: AnIntroduction to Cluster Analysis.John Wiley, New York.Kohomban, Upali S. and Wee Sun Lee.2005.
Learning semantic classes forWord Sense Disambiguation.
InProceedings of the 43rd Annual Meeting of theAssociation for Computational Linguistics,pages 34?41, Ann Arbor, MI.Korhonen, Anna, Yuval Krymolowski, andZvika Marx.
2003.
Clustering polysemicsubcategorization frame distributionssemantically.
In Proceedings of the41st Annual Meeting of the Association forComputational Linguistics - Volume 1,ACL ?03, pages 64?71, Stroudsburg, PA.Lapata, Maria.
2001.
A corpus-basedaccount of regular polysemy: The case ofcontext-sensitive adjectives.
In Proceedingsof the Second Meeting of the North AmericanChapter of the Association for ComputationalLinguistics on Language Technologies,NAACL ?01, pages 1?8, Stroudsburg, PA.Lapata, Mirella.
2000.
The Acquisition andModeling of Lexical Knowledge: A Corpus-based Investigation of Systematic Polysemy.Ph.D.
thesis, University of Edinburgh.Lapata, Mirella and Chris Brew.
2004.
Verbclass disambiguation using informativepriors.
Computational Linguistics,30(2):45?73.Levin, Beth and Malka Rappaport.
1986.
Theformation of adjectival passives.
LinguisticInquiry, 17:623?661.Malouf, Robert.
2000.
The order ofprenominal adjectives in naturallanguage generation.
In Proceedings ofthe 38th Annual Meeting of the Associationfor Computational Linguistics, ACL ?00,pages 85?92, Stroudsburg, PA.Marcus, M., B. Santorini, andM.
Marcinkiewicz.
1993.
Building a largeannotated corpus of English: The PennTreebank.
Computational Linguistics,19:313?330.Mayol, Laia, Gemma Boleda, and Toni Badia.2005.
Automatic acquisition of syntacticverb classes with basic resources.
LanguageResources and Evaluation, 39(4):295?312.McCarthy, Diana.
2000.
Using semanticpreferences to identify verbalparticipation in role switching alternations.In Proceedings of the 1st North AmericanChapter of the Association for ComputationalLinguistics Conference, NAACL ?00,pages 256?263, San Francisco, CA.McCarthy, Diana, Rob Koeling, Julie Weeds,and John Carroll.
2004.
Findingpredominant word senses in untaggedtext.
In Proceedings of the 42nd AnnualMeeting of the Association for ComputationalLinguistics, ACL ?04, pages 279?286,Stroudsburg, PA.McDonald, Ryan, Koby Crammer, andFernando Pereira.
2005.
Flexible textsegmentation with structured multilabelclassification.
In Proceedings of theConference on Human Language Technologyand Empirical Methods in Natural LanguageProcessing, HLT ?05, pages 987?994,Stroudsburg, PA.McNally, Louise and Gemma Boleda.
2004.Relational adjectives as properties ofkinds.
Empirical Issues in Syntax andSemantics, 5:179?196.Merlo, Paola and Suzanne Stevenson.
2001.Automatic verb classification based onstatistical distributions of argumentstructure.
Computational Linguistics,27(3):373?408.Miller, Katharine J.
1998.
Modifiers inWordNet.
In Christiane Fellbaum, editor,WordNet: an Electronic Lexical Database.The MIT Press, Cambridge, MA,pages 47?67.Montague, Richard.
1974.
English as aformal language.
In Richmond H.Thomason, editor, Formal Philosophy:Selected Papers of Richard Montague.
YaleUniversity Press, New Haven, CT,chapter 6, pages 188?221.Murphy, Gregory L. 2002.
The Big Book ofConcepts.
The MIT Press, Cambridge, MA.Nadeau, Claude and Yoshua Bengio.
2003.Inference for the generalization error.Machine Learning, 52(3):239?281.Navigli, Roberto.
2009.
Word sensedisambiguation: A survey.
ACMComputing Surveys, 41:10:1?10:69.Nirenburg, Sergei and Victor Raskin.
2004.Ontological Semantics.
The MIT Press,Cambridge, MA.Pang, Bo and Lillian Lee.
2008.
Opinionmining and sentiment analysis.Foundations and Trends in InformationRetrieval, 2(1-2):1?135.Pereira, Fernando, Naftali Tishby, andLillian Lee.
1993.
Distributional clusteringof English words.
In Proceedings ofthe 31st Annual Meeting of the Associationfor Computational Linguistics, ACL ?93,pages 183?190, Stroudsburg, PA.615Computational Linguistics Volume 38, Number 3Picallo, Carme.
2002.
L?adjectiu i el sintagmaadjectival.
In Joan Sola`, editor, Grama`ticadel catala` contemporani.
Empu?ries,Barcelona, pages 1643?1688.Poesio, Massimo and Ron Artstein.
2005.The reliability of anaphoric annotation,reconsidered: Taking ambiguity intoaccount.
In Proceedings of the Workshop onFrontiers in Corpus Annotations II: Pie inthe Sky, CorpusAnno ?05, pages 76?83,Stroudsburg, PA.Prescher, Detlef, Stefan Riezler, and MatsRooth.
2000.
Using a probabilisticclass-based lexicon for lexical ambiguityresolution.
In Proceedings of the 18thConference on Computational Linguistics -Volume 2, COLING ?00, pages 649?655,Stroudsburg, PA.Pustejovsky, James.
1995.
The GenerativeLexicon.
The MIT Press, Cambridge, MA.Quinlan, Ross.
1993.
C4.5: Programs forMachine Learning.
Morgan Kaufmann,San Francisco, CA.Rafel, Joaquim.
1994.
Un corpus general derefere`ncia de la llengua catalana.
Caplletra,17:219?250.Raskin, Victor and Sergei Nirenburg.1998.
An applied ontological semanticmicrotheory of adjective meaning fornatural language processing.MachineTranslation, 13(2-3):135?227.Resnik, Philip.
1993.
Selection and Information:A Class-Based Approach to LexicalRelationships.
Ph.D. thesis, Departmentof Computer and Information Science,University of Pennsylvania.Rooth, Mats, Stefan Riezler, Detlef Prescher,Glenn Carroll, and Franz Beil.
1999.Inducing a semantically annotatedlexicon via em-based clustering.In Proceedings of the 37th Annual Meetingof the Association for ComputationalLinguistics, ACL ?99, pages 104?111,Stroudsburg, PA.Sanroma`, Roser and Gemma Boleda.
2010.The database of Catalan adjectives.
InProceedings of the Seventh Conference onInternational Language Resources andEvaluation, LREC ?10, Valletta.Schapire, Robert E. and Yoram Singer.
2000.Boostexter: A boosting-based system fortext categorization.Machine Learning,39(2-3):135?168.Schulte im Walde, Sabine.
2006.
Experimentson the automatic induction of Germansemantic verb classes.
ComputationalLinguistics, 32(2):159?194.Schu?tze, Hinrich.
1998.
Automatic wordsense discrimination.
ComputationalLinguistics, 24(1):97?123.Utt, Jason and Sebastian Pado?.
2011.Ontology-based distinction betweenpolysemy and homonymy.
In Proceedingsof the Ninth International Conference onComputational Semantics, IWCS ?11,pages 265?274, Stroudsburg, PA.Vendler, Zeno.
1957.
Verbs and times.The Philosophical Review, 66:143?60.Ve?ronis, Jean.
1998.
A study of polysemyjudgements and inter-annotatoragreement.
In Programme and AdvancedPapers of the Senseval Workshop, pages 2?4,Herstmonceux Castle.Verzani, John.
2005.
Using R for IntroductoryStatistics.
Chapman & Hall/CRC,Boca Raton, FL.Wiebe, Janyce M., Theresa Wilson,Rebecca Bruce, Matthew Bell, andMelanie Martin.
2004.
Learning subjectivelanguage.
Computational Linguistics,30(3):277?308.Witten, Ian H. and Eibe Frank.
2011.
DataMining: Practical Machine Learning Toolsand Techniques with Java Implementations.Morgan Kaufmann, Amsterdam,3rd edition.Yallop, Jeremy, Anna Korhonen, and TedBriscoe.
2005.
Automatic acquisition ofadjectival subcategorization from corpora.In Proceedings of the 43rd Annual Meeting ofthe Association for Computational Linguistics,ACL ?05, pages 614?621, Stroudsburg, PA.616
