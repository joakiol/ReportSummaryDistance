Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 148?157,MIT, Massachusetts, USA, 9-11 October 2010. c?2010 Association for Computational LinguisticsA Hybrid Morpheme-Word Representationfor Machine Translation of Morphologically Rich Languages?Minh-Thang Luong Preslav Nakov Min-Yen KanDepartment of Computer ScienceNational University of Singapore13 Computing DriveSingapore 117417{luongmin,nakov,kanmy}@comp.nus.edu.sgAbstractWe propose a language-independent approachfor improving statistical machine translationfor morphologically rich languages using ahybrid morpheme-word representation wherethe basic unit of translation is the morpheme,but word boundaries are respected at all stagesof the translation process.
Our model extendsthe classic phrase-based model by meansof (1) word boundary-aware morpheme-levelphrase extraction, (2) minimum error-ratetraining for a morpheme-level translationmodel using word-level BLEU, and (3) jointscoring with morpheme- and word-level lan-guage models.
Further improvements areachieved by combining our model with theclassic one.
The evaluation on English toFinnish using Europarl (714K sentence pairs;15.5M English words) shows statistically sig-nificant improvements over the classic modelbased on BLEU and human judgments.1 IntroductionThe fast progress of statistical machine translation(SMT) has boosted translation quality significantly.While research keeps diversifying, the word remainsthe atomic token-unit of translation.
This is fine forlanguages with limited morphology like English andFrench, or no morphology at all like Chinese, butit is inadequate for morphologically rich languageslike Arabic, Czech or Finnish (Lee, 2004; Goldwaterand McClosky, 2005; Yang and Kirchhoff, 2006).
?This research was sponsored in part by CSIDM (grant #200805) and by a National Research Foundation grant entitled?Interactive Media Search?
(grant # R-252-000-325-279).There has been a line of recent SMT researchthat incorporates morphological analysis as part ofthe translation process, thus providing access to theinformation within the individual words.
Unfortu-nately, most of this work either relies on language-specific tools, or only works for very small datasets.Below we propose a language-independent ap-proach to SMT of morphologically rich lan-guages using a hybrid morpheme-word representa-tion where the basic unit of translation is the mor-pheme, but word boundaries are respected at allstages of the translation process.
We use unsuper-vised morphological analysis and we incorporate itsoutput into the process of translation, as opposed torelying on pre-processing and post-processing onlyas has been done in previous work.The remainder of the paper is organized as fol-lows.
Section 2 reviews related work.
Sections 3and 4 present our morphological and phrase mergingenhancements.
Section 5 describes our experiments,and Section 6 analyzes the results.
Finally, Section 7concludes and suggests directions for future work.2 Related WorkMost previous work on morphology-aware ap-proaches relies heavily on language-specific tools,e.g., the TreeTagger (Schmid, 1994) or the Buck-walter Arabic Morphological Analyzer (Buckwal-ter, 2004), which hampers their portability toother languages.
Moreover, the prevalent methodfor incorporating morphological information is byheuristically-driven pre- or post-processing.
Forexample, Sadat and Habash (2006) use differentcombinations of Arabic pre-processing schemes148for Arabic-English SMT, whereas Oflazer and El-Kahlout (2007) post-processes Turkish morpheme-level translations by re-scoring n-best lists with aword-based language model.
These systems, how-ever, do not attempt to incorporate their analysis aspart of the decoding process, but rather rely on mod-els designed for word-token translation.We should also note the importance of the trans-lation direction: it is much harder to translate from amorphologically poor to a morphologically rich lan-guage, where morphological distinctions not presentin the source need to be generated in the target lan-guage.
Research in translating into morphologicallyrich languages, has attracted interest for languageslike Arabic (Badr et al, 2008), Greek (Avramidisand Koehn, 2008), Hungarian (Nova?k, 2009; Koehnand Haddow, 2009), Russian (Toutanova et al,2008), and Turkish (Oflazer and El-Kahlout, 2007).These approaches, however, either only succeed inenhancing the performance for small bi-texts (Badret al, 2008; Oflazer and El-Kahlout, 2007), or im-prove only modestly for large bi-texts1.3 Morphological EnhancementsWe present a morphologically-enhanced version ofthe classic phrase-based SMT model (Koehn et al,2003).
We use a hybrid morpheme-word representa-tion where the basic unit of translation is the mor-pheme, but word boundaries are respected at allstages of the translation process.
This is in con-trast with previous work, where morphological en-hancements are typically performed as pre-/post-processing steps only.In addition to changing the basic translation tokenunit from a word to a morpheme, our model extendsthe phrase-based SMT model with the following:1. word boundary-aware morpheme-level phraseextraction;2. minimum error-rate training for a morpheme-level model using word-level BLEU;3. joint scoring with morpheme- and word-levellanguage models.We first introduce our morpheme-level represen-tation, and then describe our enhancements.1Avramidis and Koehn (2008) improved by 0.15 BLEU overa 18.05 English-Greek baseline; Toutanova et al (2008) im-proved by 0.72 BLEU over a 36.00 English-Russian baseline.3.1 Morphological RepresentationOur morphological representation is based on theoutput of an unsupervised morphological analyzer.Following Virpioja et al (2007), we use Morfessor,which is trained on raw tokenized text (Creutz andLagus, 2007).
The tool segments words into mor-phemes annotated with the following labels: PRE(prefix), STM (stem), SUF (suffix).
Multiple prefixesand suffixes can be proposed for each word; wordcompounding is allowed as well.
The output can bedescribed by the following regular expression:WORD = ( PRE* STM SUF* )+For example, uncarefully is analyzed asun/PRE+ care/STM+ ful/SUF+ ly/SUFThe above token sequence forms the input to oursystem.
We keep the PRE/STM/SUF tags as partof the tokens, and distinguish between care/STM+and care/STM.
Note also that the ?+?
sign is ap-pended to each nonfinal tag so that we can distin-guish word-internal from word-final morphemes.3.2 Word Boundary-aware Phrase ExtractionThe core translation structure of a phrase-basedSMT model is the phrase table, which is learnedfrom a bilingual parallel sentence-aligned corpus,typically using the alignment template approach(Och and Ney, 2004).
It contains a set of bilingualphrase pairs, each associated with five scores: for-ward and backward phrase translation probabilities,forward and backward lexicalized translation proba-bilities, and a constant phrase penalty.The maximum phrase length n is normally limitedto seven words; higher values of n increase the tablesize exponentially without actually yielding perfor-mance benefit (Koehn et al, 2003).
However, thingsare different when translating with morphemes, fortwo reasons: (1) morpheme-token phrases of lengthn can span less than n words; and (2) morpheme-token phrases may only partially span words.The first point means that morpheme-tokenphrase pairs span fewer word tokens, and thus covera smaller context, which may result in fewer totalextracted pairs compared to a word-level approach.Figure 1 shows a case where three Finnish wordsconsist of nine morphemes.
Previously, this issuewas addressed by simply increasing the value of nwhen using morphemes, which is of limited help.149SRC = theSTM newSTM , unPRE+ democraticSTM immigrationSTM policySTMTGT = uusiSTM , ep?PRE+ demokraatSTM+ tSUF+ iSUF+ sSUF+ enSUF maahanmuuttoPRE+ politiikanSTM(uusi=new  ,  ep?demokraattisen=undemocratic    maahanmuuttopolitiikan=immigration policy)Figure 1: Example of English-Finnish bilingual fragments morphologically segmented by Morfessor.
Solid linksrepresent IBM Model 4 alignments at the morpheme-token level.
Translation glosses for Finnish are given below.The second point is more interesting: morpheme-level phrases may span words partially, making thempotentially usable in translating unknown inflectedforms of known source language words, but alsocreates the danger of generating sequences of mor-phemes that are not legal target language words.For example, let us consider the phrase in Fig-ure 1: unPRE+ democraticSTM.
The originalalgorithm will extract the spurious phrase epa?PRE+demokraatSTM+ tSUF+ iSUF+ sSUF+, besidethe correct one that has enSUF appended at theend.
Such a spurious phrase does not generally helpin translating unknown inflected forms, especiallyfor morphologically-rich languages that feature mul-tiple affixes, but negatively affects the translationmodel in terms of complexity and quality.We solve both problems by modifying the phrase-pair extraction algorithm so that morpheme-tokenphrases can extend longer than n, as long as theyspan n words or less.
We further require thatword boundaries be respected2, i.e., morpheme-token phrases span a sequence of whole words.
Thisis a fair extension of the morpheme-token systemwith respect to a word-token one since both are re-stricted to span up to n word-tokens.3.3 Morpheme-Token MERT OptimizingWord-Token BLEUModern phrase-based SMT systems use a log-linearmodel with the following typical feature functions:language model probabilities, word penalty, distor-tion cost, and the five parameters from the phrase ta-ble.
Their weights are set by optimizing BLEU score(Papineni et al, 2001) directly using minimum errorrate training (MERT), as suggested by Och (2003).In previous work, phrase-based SMT systemsusing morpheme-token input/output naturally per-2This means that we miss the opportunity to generate newwordforms for known baseforms, but removes the problem ofproposing nonwords in the target language.formed MERT at the morpheme-token level as well.This is not optimal since the final expected systemoutput is a sequence of words, not morphemes.
Themain danger is that optimizing a morpheme-tokenBLEU score could lead to a suboptimal weight forthe word penalty feature function: this is becausethe brevity penalty of BLEU is calculated with re-spect to the number of morphemes, which may varyfor sentences with an identical number of words.This motivates us to perform MERT at the word-token level, although our input consists of mor-phemes.
In particular, for each iteration of MERT,as soon as the decoder generates a morpheme-tokentranslation for a sentence, we convert it into a word-token sequence, which is used to calculate BLEU.We thus achieve MERT optimization at the word-token level while translating a morpheme-token in-put and generating a morpheme-token output.3.4 Scoring with Twin Language ModelsAn SMT system that takes morpheme-token inputand generates morpheme-token output should natu-rally use a morpheme-token language model (LM).This has the advantage of alleviating the problem ofdata sparseness, especially when translating into amorphologically rich language, since the LM wouldbe able to handle some new unseen inflected formsof known words.
On the negative side, a morpheme-token LM spans fewer word-tokens and thus has amore limited word ?horizon?
compared to one op-erating at the word level.
As with the maximumphrase length, mechanically increasing the order ofthe morpheme-token LM has a limited impact.In order to address the issue in a more princi-pled manner, we enhance our model with a secondLM that works at the word-token level.
This LM isused together with the morpheme-token LM, whichis achieved by using two separate feature functionsin the log-linear SMT model: one for each LM.
Wefurther had to modify the Moses decoder so that150uusiSTM  , ep?PRE+ demokraatSTM+ tSUF+ iSUF+ sSUF+ enSUF maahanmuuttoPRE+ politiikanSTM?
Score: ?sSUF+ enSUF maahanmuuttoPRE+?
;  ?enSUF maahanmuuttoPRE+ politiikanSTM ??
Concatenate: uusi , ep?demokraattisen maahanmuuttopolitiikan?
Score: ?, ep?demokraattisen maahanmuuttopolitiikan?Previous hypotheses Current hypothesis(i)(ii)(iii)Figure 2: Scoring with twin LMs.
Shown are: (i) The current state of the decoding process with the target phrasescovered by the current partial hypotheses.
(ii, iii) Scoring with 3-gram morpheme-token and 3-gram word-token LMs,respectively.
For the word-token LM, the morpheme-token sequence is concatenated into word-tokens before scoring.it can be enhanced with an appropriate word-token?view?
on the partial morpheme-level hypotheses3.The interaction of the twin LMs is illustrated inFigure 2.
The word-token LM can capture muchlonger phrases and more complete contexts suchas ?, epa?demokraattisen maahanmuuttopolitiikan?compared to the morpheme-token LM.Note that scoring with two LMs that see the out-put sequence as different numbers of tokens is notreadily offered by the existing SMT decoders.
Forexample, the phrase-based model in Moses (Koehnet al, 2007) allows scoring with multiple LMs, butassumes they use the same token granularity, whichis useful for LMs trained on different monolingualcorpora, but cannot handle our case.
While the fac-tored translation model (Koehn and Hoang, 2007) inMoses does allow scoring with models of differentgranularity, e.g., lemma-token and word-token LMs,it requires a 1:1 correspondence between the tokensin the different factors, which clearly is not our case.Note that scoring with twin LMs is conceptu-ally superior to n-best re-scoring with a word-tokenLM, e.g., (Oflazer and El-Kahlout, 2007), since it istightly integrated into decoding: it scores partial hy-potheses and influenced the search process directly.4 Enriching the Translation ModelAnother general strategy for combining evidencefrom the word-token and the morpheme-token rep-resentations is to build two separate SMT systemsand then combine them.
This can be done as apost-processing system combination step; see (Chenet al, 2009a) for an overview of such approaches.3We use the term ?hypothesis?
to collectively refer to thefollowing (Koehn, 2003): the source phrase covered, the cor-responding target phrase, and most importantly, a reference tothe previous hypothesis that it extends.However, for phrase-based SMT systems, it is theo-retically more appealing to combine their phrase ta-bles since this allows the translation models of bothsystems to influence the hypothesis search directly.We now describe our phrase table combinationapproach.
Note that it is orthogonal to the work pre-sented in the previous section, which suggests com-bining the two (which we will do in Section 5).4.1 Building a Twin Translation ModelFigure 3 shows a general scheme of our twin trans-lation model.
First, we tokenize the input at differ-ent granularities: (1) morpheme-token and (2) word-token.
We then build separate phrase tables (PT) forthe two inputs: a word-token PTw and a morpheme-token PTm.
Second, we re-tokenize PTw at themorpheme level, thus obtaining a new phrase tablePTw?m, which is of the same granularity as PTm.Finally, we merge PTw?m and PTm, and we inputthe resulting phrase table to the decoder.GIZA++DecodingWord alignment Morpheme alignmentWord MorphemePTmPTw?mPTwMorphologicalsegmenta"onPhrase Extrac"onPT mergingPhrase Extrac"onGIZA++Figure 3: Building a twin phrase table (PT).
First, sep-arate PTs are generated for different input granularities:word-token and morpheme-token.
Second, the word-token PT is retokenized at the morpheme-token level.
Fi-nally, the two PTs are merged and used by the decoder.1514.2 Merging and Normalizing Phrase TablesBelow we first describe the two general phrase ta-ble combination strategies used in previous work:(1) direct merging using additional feature func-tions, and (2) phrase table interpolation.
We thenintroduce our approach.Add-feature methods.
The first line of researchon phrase table merging is exemplified by (Niehueset al, 2009; Chen et al, 2009b; Do et al, 2009;Nakov and Ng, 2009).
The idea is to select one ofthe phrase tables as primary and to add to it all non-duplicating phrase pairs from the second table to-gether with their associated scores.
For each entry,features can be added to indicate its origin (whetherfrom the primary or from the secondary table).
Laterin our experiments, we will refer to these baselinemethods as add-1 and add-2, depending on howmany additional features have been added.
The val-ues we used for these features in the baseline aregiven in Section 5.4; their weights in the log-linearmodel were set in the standard way using MERT.Interpolation-based methods.
A problem withthe above method is that the scores in the mergedphrase table that correspond to forward and back-ward phrase translation probabilities, and forwardand backward lexicalized translation probabilitiescan no longer be interpreted as probabilities sincethey are not normalized any more.
Theoretically,this is not necessarily a problem since the log-linearmodel used by the decoder does not assume that thescores for the feature functions come from a normal-ized probability distribution.
While it is possible tore-normalize the scores to convert them into prob-abilities, this is rarely done; it also does not solvethe problem with the dropped scores for the dupli-cated phrases.
Instead, the conditional probabilitiesin the two phrase tables are often interpolated di-rectly, e.g., using linear interpolation.
Representa-tive work adopting this approach is (Wu and Wang,2007).
We refer to this method as interpolation.Our method.
The above phrase merging ap-proaches have been proposed for phrase tables de-rived from different sources.
This is in contrast withour twin translation scenario, where the morpheme-token phrase tables are built from the same trainingdataset; the main difference being that word align-ments and phrase extraction were performed at theword-token level for PTw?m and at the morpheme-token level for PTm.
Thus, we propose differentmerging approaches for the phrase translation prob-abilities and for the lexicalized probabilities.In phrase-based SMT, phrase translation probabil-ities are computed using maximum likelihood (ML)estimation ?(f?
|e?)
= #(f?
,e?)?f?
#(f?
,e?
), where #(f?
, e?)
isthe number of times the pair (f?
, e?)
is extracted fromthe training dataset (Koehn et al, 2003).
In order topreserve the normalized ML estimations as much aspossible, we refrain from interpolation.
Instead, weuse the raw counts for the two models #m(f?
, e?)
and#w?m(f?
, e?)
directly as follows:?(f?
, e?)
= #m(f?
, e?)
+ #w?m(f?
, e?)?f?
#m(f?
, e?)
+?f?
#w?m(f?
, e?
)For lexicalized translation probabilities, we wouldlike to use simple interpolation.
However, we noticethat when a phrase pair belongs to only one of thephrase tables, the corresponding lexicalized scorefor the other table would be zero.
This might causesome good phrases to be penalized just because theywere not extracted in both tables, which we want toprevent.
We thus perform interpolation from PTmand PTw according to the following formula:lex(f?
|e?)
= ?
?
lexm(f?m|e?m)+ (1?
?)?
lexw(f?w|e?w)where the concatenation of f?m and e?m into word-token sequences yields f?w and e?w, respectively.If both (f?m, e?m) and (f?w, e?w) are present in PTmand PTw, respectively, we have a simple interpola-tion of their corresponding lexicalized scores lexmand lexw.
However, if one of them is missing, wedo not use a zero for its corresponding lexicalizedscore, but use an estimate as follows.For example, if only the entry (f?m, e?m) is presentin PTm, we first convert (f?m,e?m) into a word-tokenpair (f?m?w,e?m?w), and then induce a correspond-ing word alignment from the morpheme-token align-ment of (f?m,e?m).
We then estimate a lexicalizedphrase score using the original formula given in(Koehn et al, 2003), where we plug this inducedword alignment and word-token lexical translationprobabilities estimated from the word-token datasetThe case when (f?w, e?w) is present in PTw, but(f?m, e?m) is not, is solved similarly.1525 Experiments and Evaluation5.1 DatasetsIn our experiments, we use the English-Finnish datafrom the 2005 shared task (Koehn and Monz, 2005),which is split into training, development, and testportions; see Table 1 for details.
We further splitthe training dataset into four subsets T1, T2, T3, andT4 of sizes 40K, 80K, 160K, and 320K parallel sen-tence pairs, which we use for studying the impact oftraining data size on translation performance.Sent.
Avg.
words Avg.
morph.en fi en fiTrain 714K 21.62 15.80 24.68 26.15Dev 2K 29.33 20.99 33.40 34.94Test 2K 28.98 20.72 33.10 34.47Table 1: Dataset statistics.
Shown are the number ofparallel sentences, and the average number of words andMorfessor morphemes on the English and Finnish sidesof the training, development and test datasets.5.2 Baseline SystemsWe build two phrase-based baseline SMT systems,both using Moses (Koehn et al, 2007):w-system: works at the word-token level, extractsphrases of up to seven words, and uses a 4-gramword-token LM (as typical for phrase-based SMT);m-system: works at the morpheme level, tok-enized using Morfessor4 and augmented with ?+?
asdescribed in Section 3.1.Following Oflazer and El-Kahlout (2007) and Vir-pioja et al (2007), we use phrases of up to 10morpheme-tokens and a 5-gram morpheme-tokenLM.
None of the enhancements described previ-ously is applied yet.
After decoding, morphemes areconcatenated back to words using the ?+?
markers.To evaluate the translation quality, we computeBLEU (Papineni et al, 2001) at the word-tokenlevel.
We further introduce a morpheme-token ver-sion of BLEU, which we call m-BLEU: it first seg-ments the system output and the reference trans-lation into morpheme-tokens and then calculates aBLEU score as usual.
Table 2 shows the baseline re-sults.
We can see that the m-system achieves much4We retrained Morfessor for Finnish/English on theFinnish/English side of the training dataset.w-system m-systemBLEU m-BLEU BLEU m-BLEUT1 11.56 45.57 11.07 49.15T2 12.95 48.63 12.68 53.78T3 13.64 50.30 13.32 54.40T4 14.20 50.85 13.57 54.70Full 14.58 53.05 14.08 55.26Table 2: Baseline system performance (on the testdataset).
Shown are word BLEU and morpheme m-BLEU scores for the w-system and m-system.higher m-BLEU scores, indicating that it may havebetter morpheme coverage5.
However, the m-systemis outperformed by the w-system on the classic word-token BLEU, which means that it either does notperform as well as the w-system or that word-tokenBLEU is not capable of measuring the morpheme-level improvements.
We return to this question later.5.3 Adding Morphological EnhancementsWe now add our three morphological enhancementsfrom Section 3 to the baseline m-system:phr (training) allow morpheme-token phrases toget potentially longer than seven morpheme-tokensas long as they cover no more than seven words;tune (tuning) MERT for morpheme-token trans-lations while optimizing word-token BLEU;lm (decoding) scoring morpheme-token transla-tion hypotheses with a 5-gram morpheme-token anda 4-gram word-token LM.The results are shown in Table 3 (ii).
As we cansee, each of the three enhancements yields improve-ments in BLEU score over the m-system, both forsmall and for large training corpora.
In terms of per-formance ranking, tune achieves the best absoluteimprovement of 0.66 BLEU points on T1 and of 0.47points on the full dataset, followed by lm and phr.Table 3 (iii) further shows that using phr andlm together yields absolute improvements of 0.70BLEU points on T1 and 0.50 points on the full train-ing dataset.
Further incorporating tune, however,only helps when training on T1.Overall, the morphological enhancements are onpar with the w-system baseline, and yield sizable im-5Note that these morphemes were generated automaticallyand thus many of them are erroneous.153System T1 (40K) Full (714K)(i) w-system (w) 11.56 14.58m-system (m) 11.07 14.08(ii)m+phr 11.44+0.37 14.43+0.35m+tune 11.73+0.66 14.55+0.47m+lm 11.58+0.51 14.53+0.45(iii) m+phr+lm 11.77+0.70 14.58+0.50m+phr+lm+tune 11.90+0.83 14.39+0.31Table 3: Impact of the morphological enhancements(on test dataset).
Shown are BLEU scores (in %) fortraining on T1 and on the full dataset for (i) baselines,(ii) enhancements individually, and (iii) combined.
Su-perscripts indicate absolute improvements w.r.t m-system.provements over the m-system baseline: 0.83 BLEUpoints on T1 and 0.50 on the full training dataset.5.4 Combining Translation TablesFinally, we investigate the effect of combiningphrase tables derived from a word-token and amorpheme-token input, as described in Section 4.We experiment with the following merging methods:add-1: phrase table merging using one table asprimary and adding one extra feature6;add-2: phrase table merging using one table asprimary and adding two extra features7;interpolation: simple linear interpolation withone parameter ?
;ourMethod: our interpolation-like mergingmethod described in Section 4.2.Parameter tuning.
We tune the parameters of theabove methods on the development dataset.T1 (40K) Full (714K)PTm is primary 11.99 13.45PTw?m is primary 12.26 14.19Table 4: Effect of selection of primary phrase table foradd-1 (on dev dataset): PTw?m, derived from a word-token input, vs. PTm, from a morpheme-token input.Shown is BLEU (in %) on T1 and the full training dataset.For add-1 and add-2, we need to decide which(PTw?m or PTm) phrase table should be consid-6The feature values are e1, e2/3 or e1/3 (e=2.71828...);when the phrase pair comes from both tables, from the primarytable only, and from the secondary table only, respectively.7The feature values are (e1, e1), (e1, e0) or (e0, e1) whenthe phrase pair comes from both tables, from the primary tableonly, and from the secondary table only, respectively.ered the primary table.
Table 4 shows the resultswhen trying both strategies on add-1.
As we can see,using PTw?m as primary performs better on T1 andon the full training dataset; thus, we will use it asprimary on the test dataset for add-1 and add-2.For interpolation-based methods, we need tochoose a value for the interpolation parameters.
Dueto time constraints, we use the same value for thephrase translation probabilities and for the lexical-ized probabilities, and we perform grid search for?
?
{0.3, 0.4, 0.5, 0.6, 0.7} using interpolate on thefull training dataset.
As Table 5 shows, ?
= 0.6turns out to work best on the development dataset;we will use this value in our experiments on the testdataset both for interpolate and for ourMethod8.?
0.3 0.4 0.5 0.6 0.7BLEU 14.17 14.49 14.6 14.73 14.52Table 5: Trying different values for interpolate (on devdataset).
BLEU (in %) is for the full training dataset.Evaluation on the test dataset.
We integrate themorphologically enhanced system m+phr+lm andthe word-token based w-system using the four merg-ing methods above.
The results for the full train-ing dataset are shown in Table 6.
As we can see,add-1 and add-2 make little difference compared tothe m-system baseline.
In contrast, interpolation andourMethod yield sizable absolute improvements of0.55 and 0.74 BLEU points, respectively, over them-system; moreover, they outperform the w-system.Merging methods Full (714K)(i) m-system 14.08w-system 14.58(ii) add-1 14.25+0.17add-2 13.89?0.19(iii) interpolation 14.63+0.55ourMethod 14.82+0.74Table 6: Merging m+phr+lm and w-system (on testdataset).
BLEU (in %) is for the full training dataset.
Su-perscripts indicate performance gain/loss w.r.t m-system.6 DiscussionBelow we assess the significance of our results basedon micro-analysis and human judgments.8Note that this might put ourMethod at disadvantage.1546.1 Translation Model ComparisonWe first compare the following three phrase ta-bles: PTm of m-system, maximum phrase length of10 morpheme-tokens; PTw?m of w-system, maxi-mum phrase length of 7 word-tokens, re-segmentedinto morpheme-tokens; and PTm+phr ?
morpheme-token input using word boundary-aware phrase ex-traction, maximum phrase length of 7 word-tokens.Full (714K)(i)PTm 43.5MPTw?m 28.9MPTm+phr 22.5M(ii) PTm+phr?PTm 21.4MPTm+phr?PTw?m 10.7MTable 7: Phrase table statistics.
The number of phrasepairs in (i) individual PTs and (ii) PT overlap, is shown.PTm+phr versus PTm.
Table 7 shows thatPTm+phr is about half the size of PTm.
Still, asTable 3 shows, m+phr outperforms the m-system.Moreover, 95.07% (21.4M/22.5M) of the phrasepairs in PTm+phr are also in PTm, which confirmsthat boundary-aware phrase extraction selects goodphrase pairs from PTm to be retained in PTm+phr.PTm+phr versus PTw?m.
These two tablesare comparable in size: 22.5M and 28.9M pairs,but their overlap is only 47.67% (10.7M/22.5M) ofPTm+phr.
Thus, enriching the translation modelwith PTw?m helps improve coverage.6.2 Significance of the ResultsTable 8 shows the performance of our system com-pared to the two baselines: m-system and w-system.We achieve an absolute improvement of 0.74 BLEUpoints over the m-system, from which our systemevolved.
This might look modest, but note thatthe baseline BLEU is only 14.08, and thus the rel-ative improvement is 5.6%, which is not trivial.Furthermore, we outperform the w-system by 0.24points (1.56% relative).
Both improvements are sta-tistically significant with p < 0.01, according toCollins?
sign test (Collins et al, 2005).In terms of m-BLEU, we achieve an improvementof 2.59 points over the w-system, which suggest oursystem might be performing better than what stan-dard BLEU suggests.
Below we test this hypothesisBLEU m-BLEUourSystem 14.82 55.64m-system 14.08 55.26w-system 14.58 53.05Table 8: Our system vs. the two baselines (on the testdataset): BLEU and m-BLEU scores (in %).by means of micro-analysis and human evaluation.Translation Proximity Match.
We performedautomatic comparison based on correspondingphrases between the translation output (out) and thereference (ref), using the source (src) test dataset asa pivot.
The decoding log gave us the phrases usedto translate src to out, and we only needed to findcorrespondences between src and ref, which we ac-complished by appending the test dataset to trainingand performing IBM Model 4 word alignments.We then looked for phrase triples (src, out, ref ),where there was a high character-level similarity be-tween out and ref, measured using longest commonsubsequence ratio with a threshold of 0.7, set ex-perimentally.
We extracted 16,262 triples: for 6,758of them, the translations matched the references ex-actly, while in the remaining triples, they were closewordforms9.
These numbers support the hypothesisthat our approach yields translations close to the ref-erence wordforms but unjustly penalized by BLEU,which only gives credit for exact word matches10.Human Evaluation.
We asked four nativeFinnish speakers to evaluate 50 random test sen-tences.
Following (Callison-Burch et al, 2009), weprovided them with the source sentence, its refer-ence translation, and the outputs of three SMT sys-tems (m-system, w-system, and ourSystem), whichwere shown in different order for each example andwere named sys1, sys2 and sys3 (by order of ap-pearance).
We asked for three pairwise judgments:(i) sys1 vs. sys2, (ii) sys1 vs. sys3, and (iii) sys2 vs.sys3.
For each pair, a winner had to be designated;ties were allowed.
The results are shown in Table 10.We can see that the judges consistently preferred9Examples of such triples are (constitutionalstructure, perustuslaillinen rakenne, perustuslaillisempirakenne) and (economic and social, taloudellisia jasosiaalisia, taloudellisten ja sosiaalisten)10As a reference, the w-system yielded 15,673 triples, and6,392 of them were exact matches.
Compared to our system,this means 589 triples and 366 exact matches less.155src: as a conservative , i am incredibly thrifty with taxpayers ?
money .ref: maltillisen kokoomuspuolueen edustajana suhtaudun erittain saastavaisesti veronmaksajien rahoihin .our: konservatiivinen , olen erittain saastavaisesti veronmaksajien rahoja .w : konservatiivinen , olen aarettoman tarkeaa kanssa veronmaksajien rahoja .m : kuten konservatiivinen , olen erittain saastavaisesti veronmaksajien rahoja .Comment: our  m  w. our uses better paraphrases, from which the correct meaning could be inferred.
The part?aarettoman tarkeaa kanssa?
in w does not mention the ?thriftiness?
and replaces it with ?important?
(tarkeaa), whichis wrong.
m introduces ?kuten?, which slightly alters the meaning towards ?like a conservative, ...?.src: we were very constructive and we negotiated until the last minute of these talks in the hague .ref: olimme erittain rakentavia ja neuvottelimme haagissa viime hetkeen saakka .our: olemme olleet hyvin rakentavia ja olemme neuvotelleet viime hetkeen saakka naiden neuvottelujen haagissa .w : olemme olleet hyvin rakentavia ja olemme neuvotelleet viime tippaan niin naiden neuvottelujen haagissa .m : olimme erittain rakentavan ja neuvottelimme viime hetkeen saakka naiden neuvotteluiden haagissa .Comment: our  m  w. In our, the meaning is very close to ref with only a minor difference in tense at thebeginning.
m only gets the case wrong in ?rakentavan?, and the correct case is easily guessable.
For w, the ?viimetippaan?
is in principle correct but somewhat colloquial, and the ?niin?
is extra and somewhat confusing.src: it would be a very dangerous situation if the europeans were to become logistically reliant on russia .ref: olisi eritta?in vaarallinen tilanne , jos eurooppalaiset tulisivat logistisesti riippuvaisiksi vena?ja?sta?
.our: olisi eritta?in vaarallinen tilanne , jos eurooppalaiset tulee logistisesti riippuvaisia vena?ja?n .w : se olisi eritta?in vaarallinen tilanne , jos eurooppalaisten tulisi logistically riippuvaisia vena?ja?n .m : se olisi hyvin vaarallinen tilanne , jos eurooppalaiset haluavat tulla logistisesti riippuvaisia vena?ja?n .Comment: our  w  m. our is almost correct except for the wrong inflections at the end.
w is inferior since itfailed to translate ?logistically?.
?haluavat tulla?
in m suggests that the Europeans would ?want to become logisticallydependent?, which is not the case.
The ?se?
(it), and ?hyvin?
(a synonym of ?eritta?in?)
are minor mistakes/differences.Table 9: English-Finnish translation examples.
Shown are the source (src), the reference (ref), and the transla-tions of three systems (our, w, m).
Text in bold indicates matches with respect to the ref, while italics show where asystem was judged inferior to the rest, as judged by native Finnish speakers.
(1) ourSystem to the m-system, (2) ourSystem to thew-system, (3) w-system to the m-system.
These pref-erences are statistically significant, as found by thesign test.
Comparing to Table 8, we can see thatBLEU correlates with human judgments better thanm-BLEU; we plan to investigate this in future work.our vs. m our vs. w w vs. mJudge 1 25 18 19 12 21 19Judge 2 24 16 19 15 25 14Judge 3 27?
12 17 11 27?
15Judge 4 25 20 26?
12 22 22Total 101?
66 81?
50 95?
70Table 10: Human judgments: ourSystem (our) vs. m-system (m) vs. w-system (w).
For each pair, we showthe number of times each system was judged better thanthe other one, ignoring ties.
Statistically significant dif-ferences are marked with ?
(p < 0.05) and ?
(p < 0.01).Finally, Table 9 shows some examples demon-strating how our system improves over the w-systemand the m-system.7 Conclusion and Future WorkIn the quest towards a morphology-aware SMT thatonly uses unannotated data, there are two key chal-lenges: (1) to bring the performance of morpheme-token systems to a level rivaling the standard word-token ones, and (2) to incorporate morphologicalanalysis directly into the translation process.This work satisfies the first challenge: we haveachieved statistically significant improvements inBLEU for a large training dataset of 714K sentencepairs and this was confirmed by human evaluation.We think we have built a solid framework for thesecond challenge, and we plan to extend it further.AcknowledgementsWe thank Joanna Bergstro?m-Lehtovirta (HelsinkiInstitute for Information Technology), Katri Haveri-nen (University of Turku and Turku Centre for Com-puter Science), Veronika Laippala (University ofTurku), and Sampo Pyysalo (University of Tokyo)for judging the Finnish translations.156ReferencesEleftherios Avramidis and Philipp Koehn.
2008.
Enrich-ing morphologically poor languages for statistical ma-chine translation.
In ACL-HLT.Ibrahim Badr, Rabih Zbib, and James Glass.
2008.
Seg-mentation for English-to-Arabic statistical machinetranslation.
In ACL-HLT.Tim Buckwalter.
2004.
Buckwalter Arabic Morphologi-cal Analyzer Version 2.0.
Linguistic Data Consortium,Philadelphia?.Chris Callison-Burch, Philipp Koehn, Christof Monz,and Josh Schroeder.
2009.
Findings of the 2009Workshop on Statistical Machine Translation.
InEACL.Boxing Chen, Min Zhang, Haizhou Li, and Aiti Aw.2009a.
A comparative study of hypothesis alignmentand its improvement for machine translation systemcombination.
In ACL-IJCNLP.Yu Chen, Michael Jellinghaus, Andreas Eisele, Yi Zhang,Sabine Hunsicker, Silke Theison, Christian Feder-mann, and Hans Uszkoreit.
2009b.
Combining multi-engine translations with Moses.
In EACL.Michael Collins, Philipp Koehn, and Ivona Kuc?erova?.2005.
Clause restructuring for statistical machinetranslation.
In ACL.Mathias Creutz and Krista Lagus.
2007.
Unsupervisedmodels for morpheme segmentation and morphologylearning.
ACM Trans.
Speech Lang.
Process., 4(1):3.Thi Ngoc Diep Do, Viet Bac Le, Brigitte Bigi, LaurentBesacier, and Eric Castelli.
2009.
Mining a compa-rable text corpus for a Vietnamese-French statisticalmachine translation system.
In EACL.Sharon Goldwater and David McClosky.
2005.
Improv-ing statistical MT through morphological analysis.
InHLT.Philipp Koehn and Barry Haddow.
2009.
Edinburgh?ssubmission to all tracks of the WMT2009 shared taskwith reordering and speed improvements to Moses.
InEACL.Philipp Koehn and Hieu Hoang.
2007.
Factored transla-tion models.
In EMNLP-CoNLL.Philipp Koehn and Christof Monz.
2005.
Shared task:Statistical machine translation between European lan-guages.
In WPT.Philipp Koehn, Franz Josef Och, and Daniel Marcu.2003.
Statistical phrase-based translation.
In NAACL.Philipp Koehn, Hieu Hoang, Alexandra Birch Mayne,Christopher Callison-Burch, Marcello Federico,Nicola Bertoldi, Brooke Cowan, Wade Shen, Chris-tine Moran, Richard Zens, Chris Dyer, Ondrej Bojar,Alexandra Constantin, and Evan Herbst.
2007.Moses: Open source toolkit for statistical machinetranslation.
In ACL, Demonstration Session.Philipp Koehn.
2003.
Noun phrase translation.
Ph.D.thesis, University of Southern California, Los Angeles,CA, USA.Young-Suk Lee.
2004.
Morphological analysis for sta-tistical machine translation.
In HLT-NAACL.Preslav Nakov and Hwee Tou Ng.
2009.
Improved statis-tical machine translation for resource-poor languagesusing related resource-rich languages.
In EMNLP.Jan Niehues, Teresa Herrmann, Muntsin Kolss, and AlexWaibel.
2009.
The Universita?t Karlsruhe translationsystem for the EACL-WMT 2009.
In EACL.Attila Nova?k.
2009.
MorphoLogic?s submission for theWMT 2009 shared task.
In EACL.Franz Josef Och and Hermann Ney.
2004.
The align-ment template approach to statistical machine transla-tion.
Computational Linguistics, 30(4):417?449.Franz Josef Och.
2003.
Minimum error rate training instatistical machine translation.
In ACL.Kemal Oflazer and Ilknur El-Kahlout.
2007.
Exploringdifferent representational units in English-to-Turkishstatistical machine translation.
In StatMT.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2001.
Bleu: a method for automatic evalua-tion of machine translation.
In ACL.Fatiha Sadat and Nizar Habash.
2006.
Combination ofArabic preprocessing schemes for statistical machinetranslation.
In ACL.Helmut Schmid.
1994.
Probabilistic part-of-speech tag-ging using decision trees.
In International Conferenceon New Methods in Language Processing.Kristina Toutanova, Hisami Suzuki, and Achim Ruopp.2008.
Applying morphology generation models tomachine translation.
In ACL-HLT.Sami Virpioja, Jaakko J. Vyrynen, Mathias Creutz, andMarkus Sadeniemi.
2007.
Morphology-aware statisti-cal machine translation based on morphs induced in anunsupervised manner.
In Machine Translation SummitXI.Hua Wu and Haifeng Wang.
2007.
Pivot languageapproach for phrase-based statistical machine transla-tion.
Machine Translation, 21(3):165?181.Mei Yang and Katrin Kirchhoff.
2006.
Phrase-basedbackoff models for machine translation of highly in-flected languages.
In EACL.157
