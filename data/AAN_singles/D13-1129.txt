Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1303?1313,Seattle, Washington, USA, 18-21 October 2013. c?2013 Association for Computational LinguisticsSemi-supervised Feature Transformation for Dependency ParsingWenliang Chen?, Min Zhang?
?, and Yue Zhang?
?School of Computer Science and Technology, Soochow University, China?Singapore University of Technology and Design, Singapore{wlchen, mzhang}@suda.edu.cnyue zhang@sutd.edu.sgAbstractIn current dependency parsing models, con-ventional features (i.e.
base features) definedover surface words and part-of-speech tagsin a relatively high-dimensional feature spacemay suffer from the data sparseness problemand thus exhibit less discriminative power onunseen data.
In this paper, we propose anovel semi-supervised approach to address-ing the problem by transforming the base fea-tures into high-level features (i.e.
meta fea-tures) with the help of a large amount of au-tomatically parsed data.
The meta features areused together with base features in our finalparser.
Our studies indicate that our proposedapproach is very effective in processing un-seen data and features.
Experiments on Chi-nese and English data sets show that the fi-nal parser achieves the best-reported accuracyon the Chinese data and comparable accuracywith the best known parsers on the Englishdata.1 IntroductionIn recent years, supervised learning models haveachieved lots of progress in the dependency pars-ing task, as can be found in the CoNLL sharedtasks (Buchholz and Marsi, 2006; Nivre et al2007).
The supervised models take annotated dataas training data, utilize features defined over surfacewords, part-of-speech tags, and dependency trees,and learn the preference of features via adjustingfeature weights.
?Corresponding authorIn the supervised learning scenarios, many previ-ous studies explore rich feature representation thatleads to significant improvements.
McDonald andPereira (2006) and Carreras (2007) define second-order features over two adjacent arcs in second-order graph-based models.
Koo and Collins (2010)use third-order features in a third-order graph-basedmodel.
Bohnet (2010) considers information ofmore surrounding words for the graph-based mod-els, while Zhang and Nivre (2011) define a setof rich features including the word valency andthe third-order context features for transition-basedmodels.
All these models utilize richer and morecomplex feature representations and achieve betterperformance than the earlier models that utilize thesimpler features (McDonald et al 2005; Yamadaand Matsumoto, 2003; Nivre and Scholz, 2004).However, the richer feature representations result ina high-dimensional feature space.
Features in such aspace may suffer from the data sparseness problemand thus have less discriminative power on unseendata.
If input sentences contain unknown featuresthat are not included in training data, the parsers canusually give lower accuracy.Several methods have been proposed to alleviatethis problem by using large amounts of unannotateddata, ranging from self-training and co-training (Mc-Closky et al 2006; Sagae and Tsujii, 2007) to morecomplex methods that collect statistical informationfrom unannotated sentences and use them as addi-tional features (Koo et al 2008; Chen et al 2009).In this paper, we propose an alternative approachto semi-supervised dependency parsing via featuretransformation (Ando and Zhang, 2005).
More1303specifically, we transform base features to a higher-level space.
The base features defined over surfacewords, part-of-speech tags, and dependency treesare high dimensional and have been explored in theabove previous studies.
The higher-level features,which we call meta features, are low dimensional,and newly defined in this paper.
The key idea be-hind is that we build connections between knownand unknown base features via the meta features.From another viewpoint, we can also interpret themeta features as a way of doing feature smoothing.Our feature transfer method is simpler than that ofAndo and Zhang (2005), which is based on splittingthe original problem into multiple auxiliary prob-lems.
In our approach, the base features are groupedand each group relates to a meta feature.
In the firststep, we use a baseline parser to parse a large amountof unannotated sentences.
Then we collect the basefeatures from the parse trees.
The collected featuresare transformed into predefined discrete values via atransformation function.
Based on the transformedvalues, we define a set of meta features.
Finally, themeta features are incorporated directly into parsingmodels.To demonstrate the effectiveness of the proposedapproach, we apply it to the graph-based parsingmodels (McDonald and Nivre, 2007).
We conductexperiments on the standard data split of the PennEnglish Treebank (Marcus et al 1993) and the Chi-nese Treebank Version 5.1 (Xue et al 2005).
Theresults indicate that the approach significantly im-proves the accuracy.
In summary, we make the fol-lowing contributions:?
We define a simple yet useful transformationfunction to transform base features to meta fea-tures automatically.
The meta features buildconnections between known and unknown basefeatures, and relieve the data sparseness prob-lem.?
Compared to the base features, the number ofmeta features is remarkably small.?
We build semi-supervised dependency parsersthat achieve the best accuracy on the Chinesedata and comparable accuracy with the bestknown systems on the English data.The rest of this paper is organized as follows.
Sec-tion 2 introduces the graph-based parsing model.Section 3 describes the meta features and metaparser.
Section 4 describes the experiment settingsand reports the experimental results on English andChinese data sets.
Section 5 discusses related work.Finally, in Section 6 we summarize the proposed ap-proach.2 Baseline parserIn this section, we introduce a graph-based pars-ing model proposed by McDonald et al(2005) andbuild a baseline parser.2.1 Graph-based parsing modelGiven an input sentence, dependency parsing isto build a dependency tree.
We define X asthe set of possible input sentences, Y as theset of possible dependency trees, and D =(x1, y1), ..., (xi, yi), ..., (xn, yn) as a training set ofn pairs of xi ?
X and yi ?
Y .
A sentence is de-noted by x = (w0, w1, ..., wi, ..., wm), where w0 isROOT and does not depend on any other word andwi refers to a word.In the graph-based model, we define ordered pair(wi, wj) ?
y as a dependency relation in tree y fromword wi to word wj (wi is the head and wj is thedependent), Gx as a graph that consists of a set ofnodes Vx = {w0, w1, ..., wi, ..., wm} and a set ofarcs (edges) Ex = {(wi, wj)|i ?= j, wi ?
Vx, wj ?(Vx?{w0})}.
The parsing model of McDonald et al(2005) is to search for the maximum spanning tree(MST) in graph Gx.
We denote Y (Gx) as the setof all the subgraphs of Gx that are valid dependencytrees (McDonald and Nivre, 2007) for sentence x.We define the score of a dependency tree y ?Y (Gx) to be the sum of the subgraph scores,score(x, y) =?g?yscore(x, g) (1)where g is a spanning subgraph of y, which can be asingle arc or adjacent arcs.
In this paper we assumethe dependency tree to be a spanning projective tree.The model scores each subgraph using a linear rep-resentation.
Then scoring function score(x, g) is,score(x, g) = f(x, g) ?
w (2)where f(x, g) is a high-dimensional feature vectorbased on features defined over g and x and w refersto the weights for the features.1304The maximum spanning tree is the highest scoringtree in Y (Gx).
The task of decoding algorithms inthe parsing model for an input sentence x is to findy?, wherey?
= argmaxy?Y (Gx)score(x, y)= argmaxy?Y (Gx)?g?yscore(x, g)= argmaxy?Y (Gx)?g?yf(x, g) ?
w (3)In our system, we use the decoding algorithmproposed by Carreras (2007), which is a second-order CKY-style algorithm (Eisner, 1996) and fea-ture weights w are learned during training using theMargin Infused Relaxed Algorithm (MIRA) (Cram-mer and Singer, 2003; McDonald et al 2005).2.2 Base featuresPrevious studies have defined different sets of fea-tures for the graph-based parsing models, such asthe first-order features defined in McDonald et al(2005), the second-order parent-siblings features de-fined in McDonald and Pereira (2006), and thesecond-order parent-child-grandchild features de-fined in Carreras (2007).
Bohnet (2010) explorersa richer set of features than the above sets.
We fur-ther extend the features defined by Bohnet (2010)by introducing more lexical features as the base fea-tures.
The base feature templates are listed in Table1, where h, d refer to the head, the dependent re-spectively, c refers to d?s sibling or child, b refersto the word between h and d, +1 (?1) refers to thenext (previous) word, w and p refer to the surfaceword and part-of-speech tag respectively, [wp] refersto the surface word or part-of-speech tag, d(h, d) isthe direction of the dependency relation between hand d, and d(h, d, c) is the directions of the relationamong h, d, and c. We generate the base featuresbased on the above templates.2.3 Baseline parserWe train a parser with the base features as the Base-line parser.
We define fb(x, g) as the base featuresand wb as the corresponding weights.
The scoringfunction becomes,score(x, g) = fb(x, g) ?
wb (4)3 Meta featuresIn this section, we propose a semi-supervised ap-proach to transform the features in the base featurespace (FB) to features in a higher-level space (FM )with the following properties:?
The features in FM are able to build connec-tions between known and unknown features inFB and therefore should be highly informative.?
The transformation should be learnable basedon a labeled training set and an automaticallyparsed data set, and automatically computablefor the test sentences.The features in FM are referred to as meta fea-tures.
In order to perform the feature transformation,we choose to define a simple yet effective mappingfunction.
Based on the mapped values, we definefeature templates for generating the meta features.Finally, we build a new parser with the base andmeta features.3.1 Template-based mapping functionWe define a template-based function for mappingthe base features to predefined discrete values.
Wefirst put the base features into several groups andthen perform mapping.We have a set of base feature templates TB .
Foreach template Ti ?
TB , we can generate a set ofbase features Fi from dependency trees in the parseddata, which is automatically parsed by the Baselineparser.
We collect the features and count their fre-quencies.
The collected features are sorted in de-creasing order of frequencies.
The mapping functionfor a base feature fb of Fi is defined as follows,?
(fb) =??????
?Hi if R(fb) ?
TOP10Mi if TOP10 < R(fb) ?
TOP30Li if TOP30 < R(fb)Oi Otherswhere R(fb) is the position number of fb in thesorted list, ?Others?
is defined for the base featuresthat are not included in the list, and TOP10 and TOP30 refer to the position numbers of top 10% and top30% respectively.
The numbers, 10% and 30%, aretuned on the development sets in the experiments.For a base feature generated from template Ti, wehave four possible values: Hi, Mi, Li, and Oi.
In1305(a) First-order standardh[wp], d[wp], d(h,d)h[wp], d(h,d)dw, dp, d(h,d)d[wp], d(h,d)hw, hp, dw, dp, d(h,d)hp, hw, dp, d(h,d)hw, dw, dp, d(h,d)hw, hp, d[wp], d(h,d)(b) First-order Linearhp, bp, dp, d(h,d)hp, h+1p, d?1p, dp, d(h,d)h?1p, hp, d?1p, dp, d(h,d)hp, h+1p, dp, d+1p, d(h,d)h?1p, hp, dp, d+1p, d(h,d)(c) Second-order standardhp, dp, cp, d(h,d,c)hw, dw, cw, d(h,d,c)hp, c[wp], d(h,d,c)dp, c[wp], d(h,d,c)hw, c[wp], d(h,d,c)dw, c[wp], d(h,d,c)(d) Second-order Linearh[wp], h+1[wp], c[wp], d(h,d,c)h?1[wp], h[wp], c[wp], d(h,d,c)h[wp], c?1[wp], c[wp], d(h,d,c)h[wp], c[wp], c+1[wp], d(h,d,c)h?1[wp], h[wp], c?1[wp], c[wp], d(h,d,c)h[wp], h+1[wp], c?1[wp], c[wp], d(h,d,c)h?1[wp], h[wp], c[wp], c+1[wp], d(h,d,c)h[wp], h+1[wp], c[wp], c+1[wp], d(h,d,c)d[wp], d+1[wp], c[wp], d(h,d,c)d?1[wp], d[wp], c[wp], d(h,d,c)d[wp], c?1[wp], c[wp], d(h,d,c)d[wp], c[wp], c+1[wp], d(h,d,c)d[wp], d+1[wp], c?1[wp], c[wp], d(h,d,c)d[wp], d+1[wp], c[wp], c+1[wp], d(h,d,c)d?1[wp], d[wp], c?1[wp], c[wp], d(h,d,c)d?1[wp], d[wp], c[wp], c+1[wp], d(h,d,c)Table 1: Base feature templatestotal, we have 4?N(TB) possible values for all thebase features, where N(TB) refers to the number ofthe base feature templates, which is usually small.We can obtain the mapped values of all the collectedfeatures via the mapping function.3.2 Meta feature templatesBased on the mapped values, we define meta fea-ture templates in FM for dependency parsing.
Themeta feature templates are listed in Table 2, wherefb is a base feature of FB , hp refers to the part-of-speech tag of the head and hw refers to the sur-face word of the head.
Of the table, the first tem-plate uses the mapped value only, the second andthird templates combine the value with the head in-formation.
The number of the meta features is rel-atively small.
It has 4 ?
N(TB) for the first type,4 ?
N(TB) ?
N(POS) for the second type, and4 ?N(TB) ?N(WORD) for the third one, whereN(POS) refers to the number of part-of-speechtags, N(WORD) refers to the number of words.We remove any feature related to the surface formif the word is not one of the Top-N most frequentwords in the training data.
We used N=1000 for theexperiments for this paper.
This method can reducethe size of the feature sets.
The empirical statisticsof the feature sizes at Section 4.2.2 shows that thesize of meta features is only 1.2% of base features.[?(fb)][?
(fb)], hp[?
(fb)], hwTable 2: Meta feature templates3.3 Generating meta featuresWe use an example to demonstrate how to gener-ate the meta features based on the meta feature tem-plates in practice.
Suppose that we have sentence ?Iate the meat with a fork.?
and want to generate themeta features for the relation among ?ate?, ?meat?,and ?with?, where ?ate?
is the head, ?meat?
is thedependent, and ?with?
is the closest left sibling of?meat?.
Figure 1 shows the example.We demonstrate the generating procedure usingtemplate Tk = ?hw, dw, cw, d(h, d, c)?
(the secondtemplate of Table 1-(c) ), which contains the sur-face forms of the head, the dependent, its sibling,and the directions of the dependencies among h,d, and c. We can have a base feature ?ate, meat,with, RIGHTSIB?, where ?RIGHTSIB?
refers to theparent-siblings structure with the right direction.
Inthe auto-parsed data, this feature occurs 200 timesand ranks between TOP10 and TOP30.
Accord-1306I ate the meat with a fork!!!!
!!!!
!!!!
!!!!
!!!!
!!!!
!!!
!.Tk:!hw,!dw,!cw,!d(h,d,c)Fb:!ate,!meat,!with,!RIGHTSIB" (fb)=Mk[Mk];![Mk],!VV;!
[Mk],!ateFigure 1: An example of generating meta featuresing to the mapping function, we obtain the mappedvalue Mk.
Finally, we have the three meta features?
[Mk]?, ?
[Mk], V V ?, and ?
[Mk], ate?, where V V isthe part-of-speech tag of word ?ate?.
In this way,we can generate all the meta features for the graph-based model.3.4 Meta parserWe combine the base features with the meta featuresby a new scoring function,score(x, g) = fb(x, g) ?
wb + fm(x, g) ?
wm (5)where fb(x, g) refers to the base features, fm(x, g)refers to the meta features, and wb and wm aretheir corresponding weights respectively.
The fea-ture weights are learned during training using MIRA(Crammer and Singer, 2003; McDonald et al2005).
Note that wb is also retrained here.We use the same decoding algorithm in the newparser as in the Baseline parser.
The new parser isreferred to as the meta parser.4 ExperimentsWe evaluated the effect of the meta features for thegraph-based parsers on English and Chinese data.4.1 Experimental settingsIn our experiments, we used the Penn Treebank(PTB) (Marcus et al 1993) for English and theChinese Treebank version 5.1 (CTB5) (Xue et al2005) for Chinese.
The tool ?Penn2Malt?1 was used1http://w3.msi.vxu.se/?nivre/research/Penn2Malt.htmlto convert the data into dependency structures withthe English head rules of Yamada and Matsumoto(2003) and the Chinese head rules of Zhang andClark (2008).
We followed the standard data splitsas shown in Table 3.
Following the work of Koo etal.
(2008), we used a tagger trained on training datato provide part-of-speech (POS) tags for the devel-opment and test sets, and used 10-way jackknifing togenerate part-of-speech tags for the training set.
Weused the MXPOST (Ratnaparkhi, 1996) tagger forEnglish and the CRF-based tagger for Chinese.
Weused gold standard segmentation in the CTB5.
Thedata partition of Chinese were chosen to match pre-vious work (Duan et al 2007; Li et al 2011; Hatoriet al 2011).train dev testPTB 2-21 22 23(sections)CTB5 001-815 886-931 816-885(files) 1001-1136 1148-1151 1137-1147Table 3: Standard data splitsFor the unannotated data in English, we used theBLLIP WSJ corpus (Charniak et al 2000) contain-ing about 43 million words.2 We used the MXPOSTtagger trained on the training data to assign part-of-speech tags and used the Baseline parser to processthe sentences of the Brown corpus.
For the unanno-tated data in Chinese, we used the Xinhua portionof Chinese Gigaword3 Version 2.0 (LDC2009T14)(Huang, 2009), which has approximately 311 mil-lion words.
We used the MMA system (Kruengkraiet al 2009) trained on the training data to performword segmentation and POS tagging and used theBaseline parser to parse the sentences in the Giga-word data.In collecting the base features, we removed thefeatures which occur only once in the English dataand less than four times in the Chinese data.
Thefeature occurrences of one time and four times arebased on the development data performance.We measured the parser quality by the unlabeledattachment score (UAS), i.e., the percentage of to-2We ensured that the text used for building the meta featuresdid not include the sentences of the Penn Treebank.3We excluded the sentences of the CTB data from the Giga-word data.1307kens (excluding all punctuation tokens) with the cor-rect HEAD.We also reported the scores on completedependency trees evaluation (COMP).4.2 Feature selection on development setsWe evaluated the parsers with different settings onthe development sets to select the meta features.4.2.1 Different models vs meta featuresIn this section, we investigated the effect of dif-ferent types of meta features for the models trainedon different sizes of training data on English.There are too many base feature templates to testone by one.
We divided the templates into severalcategories.
Of Table 1, some templates are only re-lated to part-of-speech tags (P), some are only re-lated to surface words (W), and the others containboth part-of-speech tags and surfaces (M).
Table 4shows the categories, where numbers [1?4] refer tothe numbers of words involved in templates.
For ex-ample, the templates of N3WM are related to threewords and contain the templates of W and M. Basedon different categories of base templates, we havedifferent sets of meta features.4Category ExampleN1P hp, d(h, d)N1WM hw, d(h, d); hw, hp, d(h, d)N2P hp, dp, d(h, d)N2WM hw, dw, d(h, d);hw, dp, d(h, d)N3P hp, dp, cp, d(h, d, c)N3WM hw, dw, cw, d(h, d, c);dw, d+1p, cp, d(h, d, c)N4P hp, h+1p, cp, c+1p, d(h, d, c)N4WM hw, h+1w, cw, c+1w, d(h, d, c);hw, h+1p, cp, c+1p, d(h, d, c)Table 4: Categories of base feature templatesWe randomly selected 1% and 10% of the sen-tences respectively from the training data.
Wetrained the POS taggers and Baseline parsers onthese small training data and used them to processthe unannotated data.
Then, we generated the metafeatures based on the newly auto-parsed data.
The4We also tested the settings of dividing WM into two sub-types: W and M. The results showed that both two sub-typesprovided positive results.
To simplify, we merged W and Minto one category WM.meta parsers were trained on the different subsetsof the training data with different sets of meta fea-tures.
Finally, we have three meta parsers: MP1,MP10, MPFULL, which were trained on 1%, 10%and 100% of the training data.MP1 MP10 MPFULLBaseline 82.22 89.50 93.01+N1P 82.42 89.48 93.08+N1WM 82.80 89.42 93.19+N2P 81.29 89.01 93.02+N2WM 82.69 90.10 93.23+N3P 83.32 89.73 93.05+N3WM 84.47 90.75 93.80+N4P 82.73 89.48 93.01+N4WM 84.07 90.42 93.67OURS 85.11 91.14 93.91Table 5: Effect of different categories of meta featuresTable 5 shows the results, where we add each cat-egory of Table 4 individually.
From the table, wefound that the meta features that are only related topart-of-speech tags did not always help, while theones related to the surface words were very helpful.We also found that MP1 provided the largest relativeimprovement among the three settings.
These sug-gested that the more sparse the base features were,the more effective the corresponding meta featureswere.
Thus, we built the final parsers by addingthe meta features of N1WM, N2WM, N3WM, andN4WM.
The results showed that OURS achievedbetter performance than the systems with individualsets of meta features.4.2.2 Different meta feature typesIn Table 2, there are three types of meta featuretemplates.
Here, the results of the parsers with dif-ferent settings are shown in Table 6, where CORErefers to the first type, WithPOS refers to the sec-ond one, and WithWORD refers to the third one.The results showed that with all the types the parser(OURS) achieved the best.
We also counted thenumbers of the meta features.
Only 327,864 (or1.2%) features were added into OURS.
Thus, weused all the three types of meta features in our finalmeta parsers.1308System NumOfFeat UASBaseline 27,119,354 93.01+CORE +498 93.84+WithPOS +14,993 93.82+WithWORD +312,373 93.27OURS +327,864 93.91Table 6: Numbers of meta features4.3 Main results on test setsWe then evaluated the meta parsers on the Englishand Chinese test sets.4.3.1 EnglishThe results are shown in Table 7, where Meta-Parser refers to the meta parser.
We found that themeta parser outperformed the baseline with an ab-solute improvement of 1.01 points (UAS).
The im-provement was significant in McNemar?s Test (p< 10?7 ).UAS COMPBaseline 92.76 48.05MetaParser 93.77 51.36Table 7: Main results on English4.3.2 ChineseUAS COMPBaseline 81.01 29.71MetaParser 83.08 32.21Table 8: Main results on ChineseThe results are shown in Table 8.
As in the ex-periment on English, the meta parser outperformedthe baseline.
We obtained an absolute improvementof 2.07 points (UAS).
The improvement was signif-icant in McNemar?s Test (p < 10?8 ).In summary, Tables 7 and 8 convincingly showthe effectiveness of our proposed approach.4.4 Different sizes of unannotated dataHere, we considered the improvement relative to thesizes of the unannotated data used to generate themeta features.
We randomly selected the 0.1%, 1%,and 10% of the sentences from the full data.
TableEnglish ChineseBaseline 92.76 81.01TrainData 91.93 80.40P0.1 92.82 81.58P1 93.14 82.23P10 93.48 82.81FULL 93.77 83.08Table 9: Effect of different sizes of auto-parsed data9 shows the results, where P0.1, P1, and P10 corre-spond to 0.1%, 1%, and 10% respectively.
From thetable, we found that the parsers obtained more ben-efits as we used more raw sentences.
We also triedgenerating the meta features from the training dataonly, shown as TrainData in Table 9.
However, theresults shows that the parsers performed worse thanthe baselines.
This is not surprising because onlythe known base features are included in the trainingdata.4.5 Comparison with previous work4.5.1 EnglishTable 10 shows the performance of the previ-ous systems that were compared, where McDon-ald06 refers to the second-order parser of McDon-ald and Pereira (2006), Koo10 refers to the third-order parser with model1 of Koo and Collins (2010),Zhang11 refers to the parser of Zhang and Nivre(2011), Li12 refers to the unlabeled parser of Li etal.
(2012), Koo08 refers to the parser of Koo et al(2008), Suzuki09 refers to the parser of Suzuki et al(2009), Chen09 refers to the parser of Chen et al(2009), Zhou11 refers to the parser of Zhou et al(2011), Suzuki11 refers to the parser of Suzuki et al(2011), and Chen12 refers to the parser of Chen etal.
(2012).The results showed that our meta parser out-performed most of the previous systems and ob-tained the comparable accuracy with the best resultof Suzuki11 (Suzuki et al 2011) which combinedthe clustering-based word representations of Koo etal.
(2008) and a condensed feature representation.However, our approach is much simpler than theirsand we believe that our meta parser can be furtherimproved by combining their methods.1309Type System UAS COMPSupMcDonald06 91.5Koo10 93.04 -Zhang11 92.9 48.0Li12 93.12 -Our Baseline 92.76 48.05SemiKoo08 93.16Suzuki09 93.79Chen09 93.16 47.15Zhou11 92.64 46.61Suzuki11 94.22 -Chen12 92.76 -MetaParser 93.77 51.36Table 10: Relevant results for English.
Sup denotes thesupervised parsers, Semi denotes the parsers with semi-supervised methods.4.5.2 ChineseTable 11 shows the comparative results, whereLi11 refers to the parser of Li et al(2011), Hatori11refers to the parser of Hatori et al(2011), and Li12refers to the unlabeled parser of Li et al(2012).
Thereported scores on this data were produced by thesupervised learning methods and our Baseline (su-pervised) parser provided the comparable accuracy.We found that the score of our meta parser for thisdata was the best reported so far and significantlyhigher than the previous scores.
Note that we usedthe auto-assigned POS tags in the test set to matchthe above previous studies.System UAS COMPLi11 80.79 29.11Hatori11 81.33 29.90Li12 81.21 -Our Baseline 81.01 29.71MetaParser 83.08 32.21Table 11: Relevant results for Chinese4.6 AnalysisHere, we analyzed the effect of the meta features onthe data sparseness problem.We first checked the effect of unknown featureson the parsing accuracy.
We calculated the numberof unknown features in each sentence and computedthe average number per word.
The average num-bers were used to eliminate the influence of variedsentence sizes.
We sorted the test sentences in in-creasing orders of these average numbers, and di-vided equally into five bins.
BIN 1 is assigned thesentences with the smallest numbers and BIN 5 iswith the largest ones.
Figure 2 shows the averageaccuracy scores of the Baseline parsers against tothe bins.
From the figure, we found that for bothtwo languages the Baseline parsers performed worsewhile the sentences contained more unknown fea-tures.7075808590951001 2 3 4 5AccuracyBINEnglishChineseFigure 2: Accuracies relative to numbers of unknown fea-tures (average per word) by Baseline parsersThen, we investigated the effect of the meta fea-tures.
We calculated the average number of ac-tive meta features per word that were transformedfrom the unknown features for each sentence.
Wesorted the sentences in increasing order of the av-erage numbers of active meta features and dividedthem into five bins.
BIN 1 is assigned the sen-tences with the smallest numbers and BIN 5 is withthe largest ones.
Figures 3 and 4 show the results,where ?Better?
is for the sentences where the metaparsers provided better results than the baselines and?Worse?
is for those where the meta parsers pro-vided worse results.
We found that the gap between?Better?
and ?Worse?
became larger while the sen-tences contain more active meta features for the un-known features.
The gap means performance im-provement.
This indicates that the meta features arevery effective in processing the unknown features.5 Related workOur approach is to use unannotated data to generatethe meta features to improve dependency parsing.1310010203040501 2 3 4 5PercentageBINBetterWorseFigure 3: Improvement relative to numbers of active metafeatures on English (average per word)010203040501 2 3 4 5PercentageBINBetterWorseFigure 4: Improvement relative to numbers of active metafeatures on Chinese (average per word)Several previous studies relevant to our approachhave been conducted.Koo et al(2008) used a word clusters trained on alarge amount of unannotated data and designed a setof new features based on the clusters for dependencyparsing models.
Chen et al(2009) extracted sub-tree structures from a large amount of data and rep-resented them as the additional features to improvedependency parsing.
Suzuki et al(2009) extended aSemi-supervised Structured Conditional Model (SS-SCM) of Suzuki and Isozaki (2008) to the depen-dency parsing problem and combined their methodwith the word clustering feature representation ofKoo et al(2008).
Chen et al(2012) proposed an ap-proach to representing high-order features for graph-based dependency parsing models using a depen-dency language model and beam search.
In futurework, we may consider to combine their methodswith ours to improve performance.Several previous studies used co-training/self-training methods.
McClosky et al(2006) presenteda self-training method combined with a reranking al-gorithm for constituency parsing.
Sagae and Tsujii(2007) applied the standard co-training method fordependency parsing.
In their approaches, some au-tomatically parsed sentences were selected as newtraining data, which was used together with the orig-inal labeled data to retrain a new parser.
We are ableto use their approaches on top of the output of ourparsers.With regard to feature transformation, the workof Ando and Zhang (2005) is similar in spirit to ourwork.
They studied semi-supervised text chunkingby using a large projection matrix to map sparse basefeatures into a small number of high level features.Their project matrix was trained by transforming theoriginal problem into a large number of auxiliaryproblems, obtaining training data for the auxiliaryproblems by automatically labeling raw data and us-ing alternating structure optimization to estimate thematrix across all auxiliary tasks.
In comparison withtheir approach, our method is simpler in the sensethat we do not request any intermediate step of split-ting the prediction problem, and obtain meta fea-tures directly from self-annotated data.
The trainingof our meta feature values is highly efficient, requir-ing the collection of simple statistics over base fea-tures from huge amount of data.
Hence our methodcan potentially be useful to other tasks also.6 ConclusionIn this paper, we have presented a simple but effec-tive semi-supervised approach to learning the metafeatures from the auto-parsed data for dependencyparsing.
We build a meta parser by combining themeta features with the base features in a graph-basedmodel.
The experimental results show that the pro-posed approach significantly improves the accuracy.Our meta parser achieves comparable accuracy withthe best known parsers on the English data (PennEnglish Treebank) and the best accuracy on the Chi-nese data (Chinese Treebank Version 5.1) so far.Further analysis indicate that the meta features arevery effective in processing the unknown features.The idea described in this paper is general and canbe applied to other NLP applications, such as part-1311of-speech tagging and Chinese word segmentation,in future work.AcknowledgmentsThis study was started when Wenliang Chen andMin Zhang were members of the Department ofHuman Language Technology, Institute for Info-comm Research, Singapore.
Wenliang Chen wasfunded partially by the National Science Founda-tion of China (61203314) and Yue Zhang was sup-ported by MOE grant 2012-T2-2-163.
We wouldalso thank the anonymous reviewers for their de-tailed comments, which have helped us to improvethe quality of this work.ReferencesR.K.
Ando and T. Zhang.
2005.
A high-performancesemi-supervised learning method for text chunking.ACL.Bernd Bohnet.
2010.
Top accuracy and fast dependencyparsing is not a contradiction.
In Proceedings of the23rd International Conference on Computational Lin-guistics (Coling 2010), pages 89?97, Beijing, China,August.
Coling 2010 Organizing Committee.S.
Buchholz and E. Marsi.
2006.
CoNLL-X sharedtask on multilingual dependency parsing.
In Proc.
ofCoNLL-X.
SIGNLL.Xavier Carreras.
2007.
Experiments with a higher-orderprojective dependency parser.
In Proceedings of theCoNLL Shared Task Session of EMNLP-CoNLL 2007,pages 957?961, Prague, Czech Republic, June.
Asso-ciation for Computational Linguistics.Eugene Charniak, Don Blaheta, Niyu Ge, Keith Hall,John Hale, and Mark Johnson.
2000.
BLLIP 1987-89 WSJ Corpus Release 1, LDC2000T43.
LinguisticData Consortium.Wenliang Chen, Jun?ichi Kazama, Kiyotaka Uchimoto,and Kentaro Torisawa.
2009.
Improving dependencyparsing with subtrees from auto-parsed data.
In Pro-ceedings of EMNLP 2009, pages 570?579, Singapore,August.Wenliang Chen, Min Zhang, and Haizhou Li.
2012.
Uti-lizing dependency language models for graph-baseddependency parsing models.
In Proceedings of ACL2012, Korea, July.Koby Crammer and Yoram Singer.
2003.
Ultraconser-vative online algorithms for multiclass problems.
J.Mach.
Learn.
Res., 3:951?991.Xiangyu Duan, Jun Zhao, and Bo Xu.
2007.
Probabilis-tic models for action-based chinese dependency pars-ing.
In Proceedings of ECML/ECPPKDD, Warsaw,Poland.J.
Eisner.
1996.
Three new probabilistic models for de-pendency parsing: An exploration.
In Proceedings ofCOLING1996, pages 340?345.Jun Hatori, Takuya Matsuzaki, Yusuke Miyao, andJun?ichi Tsujii.
2011.
Incremental joint pos tag-ging and dependency parsing in chinese.
In Proceed-ings of 5th International Joint Conference on Natu-ral Language Processing, pages 1216?1224, ChiangMai, Thailand, November.
Asian Federation of Natu-ral Language Processing.Chu-Ren Huang.
2009.
Tagged Chinese Gigaword Ver-sion 2.0, LDC2009T14.
Linguistic Data Consortium.Terry Koo and Michael Collins.
2010.
Efficient third-order dependency parsers.
In Proceedings of ACL2010, pages 1?11, Uppsala, Sweden, July.
Associationfor Computational Linguistics.T.
Koo, X. Carreras, and M. Collins.
2008.
Simplesemi-supervised dependency parsing.
In Proceedingsof ACL-08: HLT, Columbus, Ohio, June.Canasai Kruengkrai, Kiyotaka Uchimoto, Jun?ichiKazama, Yiou Wang, Kentaro Torisawa, and HitoshiIsahara.
2009.
An error-driven word-character hybridmodel for joint Chinese word segmentation and POStagging.
In Proceedings of ACL-IJCNLP2009, pages513?521, Suntec, Singapore, August.
Association forComputational Linguistics.Zhenghua Li, Min Zhang, Wanxiang Che, Ting Liu, Wen-liang Chen, and Haizhou Li.
2011.
Joint models forchinese pos tagging and dependency parsing.
In Pro-ceedings of EMNLP 2011, UK, July.Zhenghua Li, Min Zhang, Wanxiang Che, and Ting Liu.2012.
A separately passive-aggressive training algo-rithm for joint pos tagging and dependency parsing.In Proceedings of the 24rd International Conferenceon Computational Linguistics (Coling 2012), Mumbai,India.
Coling 2012 Organizing Committee.Mitchell P. Marcus, Beatrice Santorini, and Mary AnnMarcinkiewicz.
1993.
Building a large annotated cor-pus of English: the Penn Treebank.
ComputationalLinguisticss, 19(2):313?330.D.
McClosky, E. Charniak, and M. Johnson.
2006.Reranking and self-training for parser adaptation.
InProceedings of Coling-ACL, pages 337?344.R.
McDonald and J. Nivre.
2007.
Characterizing theerrors of data-driven dependency parsing models.
InProceedings of EMNLP-CoNLL, pages 122?131.Ryan McDonald and Fernando Pereira.
2006.
On-line learning of approximate dependency parsing algo-rithms.
In Proceedings of EACL 2006, pages 81?88.1312Ryan McDonald, Koby Crammer, and Fernando Pereira.2005.
Online large-margin training of dependencyparsers.
In Proceedings of ACL 2005, pages 91?98.Association for Computational Linguistics.Joakim Nivre and Mario Scholz.
2004.
Determinis-tic dependency parsing of English text.
In Proc.
ofthe 20th Intern.
Conf.
on Computational Linguistics(COLING), pages 64?70.J.
Nivre, J.
Hall, S. Ku?bler, R. McDonald, J. Nilsson,S.
Riedel, and D. Yuret.
2007.
The CoNLL 2007shared task on dependency parsing.
In Proceedingsof the CoNLL Shared Task Session of EMNLP-CoNLL2007, pages 915?932.Adwait Ratnaparkhi.
1996.
A maximum entropy modelfor part-of-speech tagging.
In Proceedings of EMNLP1996, pages 133?142.K.
Sagae and J. Tsujii.
2007.
Dependency parsing anddomain adaptation with LR models and parser ensem-bles.
In Proceedings of the CoNLL Shared Task Ses-sion of EMNLP-CoNLL 2007, pages 1044?1050.Jun Suzuki and Hideki Isozaki.
2008.
Semi-supervisedsequential labeling and segmentation using Giga-wordscale unlabeled data.
In Proceedings of ACL-08: HLT,pages 665?673, Columbus, Ohio, June.
Associationfor Computational Linguistics.Jun Suzuki, Hideki Isozaki, Xavier Carreras, andMichaelCollins.
2009.
An empirical study of semi-supervisedstructured conditional models for dependency parsing.In Proceedings of EMNLP2009, pages 551?560, Sin-gapore, August.
Association for Computational Lin-guistics.Jun Suzuki, Hideki Isozaki, and Masaaki Nagata.
2011.Learning condensed feature representations from largeunsupervised data sets for supervised learning.
In Pro-ceedings of the 49th Annual Meeting of the Associa-tion for Computational Linguistics: Human LanguageTechnologies, pages 636?641, Portland, Oregon, USA,June.
Association for Computational Linguistics.Nianwen Xue, Fei Xia, Fu dong Chiou, and MarthaPalmer.
2005.
Building a Large Annotated ChineseCorpus: the Penn Chinese Treebank.
Journal of Natu-ral Language Engineering, 11(2):207?238.Hiroyasu Yamada and Yuji Matsumoto.
2003.
Statisticaldependency analysis with support vector machines.
InProceedings of IWPT 2003, pages 195?206.Y.
Zhang and S. Clark.
2008.
A tale of two parsers: In-vestigating and combining graph-based and transition-based dependency parsing.
In Proceedings of EMNLP2008, pages 562?571, Honolulu, Hawaii, October.Yue Zhang and Joakim Nivre.
2011.
Transition-baseddependency parsing with rich non-local features.
InProceedings of ACL-HLT2011, pages 188?193, Port-land, Oregon, USA, June.
Association for Computa-tional Linguistics.Guangyou Zhou, Jun Zhao, Kang Liu, and Li Cai.
2011.Exploiting web-derived selectional preference to im-prove statistical dependency parsing.
In Proceedingsof ACL-HLT2011, pages 1556?1565, Portland, Ore-gon, USA, June.
Association for Computational Lin-guistics.1313
