Proceedings of the Third ACL Workshop on Innovative Use of NLP for Building Educational Applications, pages 53?61,Columbus, Ohio, USA, June 2008. c?2008 Association for Computational LinguisticsLearner Characteristics and Feedback in Tutorial DialogueKristy ElizabethBoyeraRobertPhillipsabMichael D.WallisabMladen A.VoukaJames C.LesteraaDepartment of Computer Science, North Carolina State UniversitybApplied Research Associates, Inc.Raleigh, North Carolina, USA{keboyer, rphilli, mdwallis, vouk, lester}@ncsu.eduAbstractTutorial dialogue has been the subject of in-creasing attention in recent years, and it hasbecome evident that empirical studies of hu-man-human tutorial dialogue can contributeimportant insights to the design of computa-tional models of dialogue.
This paper reportson a corpus study of human-human tutorialdialogue transpiring in the course of problem-solving in a learning environment for intro-ductory computer science.
Analyses suggestthat the choice of corrective tutorial strategymakes a significant difference in the outcomesof both student learning gains and self-efficacy gains.
The findings reveal that tuto-rial strategies intended to maximize studentmotivational outcomes (e.g., self-efficacygain) may not be the same strategies thatmaximize cognitive outcomes (i.e., learninggain).
In light of recent findings that learnercharacteristics influence the structure of tuto-rial dialogue, we explore the importance ofunderstanding the interaction between learnercharacteristics and tutorial dialogue strategychoice when designing tutorial dialogue sys-tems.1 IntroductionProviding intelligent tutoring systems (ITSs) withthe ability to engage learners in rich natural lan-guage dialogue has been a goal of the ITS commu-nity since the inception of the field.
Tutorialdialogue has been studied in the context of a num-ber of systems devised to support a broad range ofconversational phenomena.
Systems such asCIRCSIM (Evens and Michael 2006), BEETLE (Zinnet al 2002), the Geometry Explanation Tutor(Aleven et al 2003), Why2/Atlas (VanLehn et al2002), ITSpoke (Litman et al 2006), SCOT (Pon-Barry et al 2006), ProPL (Lane and VanLehn2005) and AutoTutor (Graesser et al 2003) supportresearch that has begun to the see the emergence ofa core set of foundational requirements for mixed-initiative natural language interaction that occurs inthe kind of tutorial dialogue investigated here.Moreover, recent years have witnessed the appear-ance of corpus studies empirically investigatingspeech acts in tutorial dialogue (Marineau et al2000), dialogues?
correlation with learning(Forbes-Riley et al 2005, Core et al 2003, Ros?
etal.
2003, Katz et al 2003), student uncertainty indialogue (Liscombe et al 2005, Forbes-Riley andLitman 2005), and comparing text-based and spo-ken dialogue (Litman et al 2006).Recent years have also seen the emergence of abroader view of learning as a complex process in-volving both cognitive and affective states.
Toempirically explore these issues, a number of ITSssuch as AutoTutor (Jackson et al 2007), Betty?sBrain (Tan and Biswas 2006), ITSpoke (Forbes-Riley et al 2005), M-Ecolab (Rebolledo-Mendezet al 2006), and MORE (del Soldato and Boulay1995) are being used as platforms to investigate theimpact of tutorial interactions on affective and mo-tivational outcomes (e.g., self-efficacy) along withpurely cognitive measures (i.e., learning gains).
Acentral problem in this line of investigation is iden-53tifying tutorial strategies (e.g., Graesser et al1995) that can appropriately balance the tradeoffsbetween cognitive and affective student outcomes(Lepper et al 1993).
While a rich set of cognitiveand affective tutorial strategies is emerging (e.g.,Porayska-Pomsta et al 2004), the precise nature ofthe interdependence between these types of strate-gies is not well understood.
In addition, it may bethe case that different populations of learners en-gage in qualitatively different forms of dialogue.Students with particular characteristics may havespecific dialogue profiles, and knowledge of suchprofiles could inform the design of tutorial systemswhose strategies leverage the characteristics of thetarget population.
The extent to which differenttutorial strategies, and specific instances of them incertain contexts, may be used to enhance tutorialeffectiveness is an important question to designersof ITSs.Given that human-human tutorial dialogue of-fers a promising model for effective communica-tion (Chi et al 2001), our methodology is to studynaturally occurring tutorial dialogues in a task-oriented learning environment to investigate therelationship between the structure of tutorial dia-logue, the characteristics of learners, and the im-pact of cognitive and motivational correctivetutorial strategies on learning and self-efficacy(Boyer et al in press).
A text-based dialogue inter-face was incorporated into a learning environmentfor introductory computer science.
In the envi-ronment, students undertook a programming taskand conversed with human tutors while designing,implementing, and testing Java programs.The results of the study suggest that the choiceof corrective tutorial strategy has a significant im-pact on the learning gains and self-efficacy of stu-dents.
These findings reinforce those of otherstudies (e.g., Lepper et al 1993, Person et al 1995,Keller et al 1983) that indicate that some cognitiveand motivational goals may be at odds with oneother because a tutorial strategy designed to maxi-mize one set of goals (e.g., cognitive goals) cannegatively impact the other.
We contextualize ourfindings in light of recent results that learner char-acteristics such as self-efficacy influence the struc-ture of task-oriented tutorial dialogue (Boyer et al2007), and may therefore produce important inter-action effects when considered alongside tutorialstrategy.This paper is organized as follows.
Section 2describes the corpus study, including experimentaldesign and tagging of dialogue and student prob-lem-solving actions.
Section 3 presents analysisand results.
Discussion and design implicationsare considered in Section 4, and concluding re-marks follow in Section 5.2 Corpus StudyThe corpus was gathered by logging text-baseddialogues between tutors and novice computer sci-ence students.
The learning task was to complete aJava programming problem that required studentsto apply fundamental concepts such as iteration,modularization, and sequential-access data struc-tures.
This study was conducted to compare theimpact of certain corrective cognitive and motiva-tional tutorial strategies on student learning andself-efficacy in human-human tutoring.
Specifi-cally, the study considered the motivational strate-gies of praise and reassurance (Lepper et al 1993)and the category of informational tutorial utter-ances termed cognitive feedback (Porayska-Pomstaet al 2004, Tan and Biswas 2006) that followedquestionable student problem-solving action.
Fol-lowing the approach of Forbes-Riley (2005) andothers (Marineau et al 2000), utterances from acorpus of human-human tutorial dialogues wereannotated with dialogue acts.
Then, adopting theapproach proposed by Ohlsson et al (2007), statis-tical modeling techniques were employed to quan-tify the relative impact of these different tutorialstrategies on the outcomes of interest (in this case,learning and self-efficacy gains).2.1 Experimental DesignSubjects were students enrolled in an introductorycomputer science course and were primarilyfreshman or sophomore engineering majors in dis-ciplines such as mechanical, electrical, and com-puter engineering.The corpus was gathered from tutor-studentinteractions between 43 students and 14 tutors dur-ing a two-week study.
Tutors and students werecompletely blind to each other?s characteristics asthey worked together remotely from separate labs.Tutors observed student problem-solving actions54(e.g., programming, scrolling, executing programs)in real time.
Tutors had varying levels of tutoringexperience, and were not instructed about specifictutorial strategies.Subjects first completed a pre-survey includingitems about self-efficacy, attitude toward computerscience, and attitude toward collaboration.
Sub-jects then completed a ten item pre-test over spe-cific topic content.
The tutorial session wascontrolled at 55 minutes for all subjects, afterwhich subjects completed a post-survey and post-test containing variants of the items on the pre-versions.2.2 Problem-Solving TaggingThe raw corpus contains 4,864 dialogue moves:1,528 student utterances and 3,336 tutor utterances.As a chronology of tutorial dialogue interleavedwith student problem-solving (programming) ac-tions that took place during the tutoring sessions,the corpus contains 29,996 programming key-strokes and 1,277 periods of scrolling ?
all per-formed by students.
Other problem-solvingactions, such as opening and closing files or run-ning the program, were sparse and were thereforeeliminated from the analyses.
Of the 3,336 tutorutterances, 1,243 occur directly after ?question-able?
student problem-solving action.
(The notionof ?questionable?
is defined below.)
This subset oftutorial utterances serves as the basis for the tuto-rial strategy comparison.Student problem-solving actions were loggedthroughout tutoring sessions.
Two actions wereunder consideration for the analysis:  typing in theprogramming interface and scrolling in the pro-gram editor window.
To interpret the raw loggedstudent problem-solving actions, these events wereautomatically tagged using a heuristic measure forcorrectness: if a problem-solving action was a pro-gramming keystroke (character) that survived untilthe end of the session, this event was tagged prom-ising, to indicate it was probably correct.
If a prob-lem-solving act was a programming keystroke(character) that did not survive until the end of thesession, the problem-solving act was tagged ques-tionable.
Both these heuristics are based on theobservation that in this tutoring context, studentssolved the problem in a linear fashion and tutorsdid not allow students to proceed past a step thathad incorrect code in place.
Finally, periods ofconsecutive scrolling were also marked question-able because in a problem whose entire solutionfits on one printed page, scrolling was almost uni-formly undertaken by a student who was confusedand looking for answers in irrelevant skeleton codeprovided to support the programming task.2.3 Dialogue Act TaggingBecause utterances communicate through twochannels, a cognitive channel and a motiva-tional/affective channel, each utterance wasannotated with both a required cognitive dialoguetag (Table 1) and an optional motiva-tional/affective dialogue tag (Table 2).
While nosingle standardized dialogue act tag set has beenidentified for tutorial dialogue, the tags appliedhere were drawn from several schemes in the tuto-rial dialogue and broader dialogue literature.
Acoding scheme for tutorial dialogue in the domainof qualitative physics influenced the creation of thetag set (Forbes-Riley et al 2005), as did the four-category scheme (Marineau et al 2000).
A moreexpansive general dialogue act tag set alo contrib-uted commonly occurring acts (Stolcke et al2000).
The motivational tags were drawn fromwork by Lepper (1993) on motivational strategiesof human tutors.Table 1 displays the cognitive subset of thisdialogue act tag set, while Table 2 displays the mo-tivational/affective tags.
It should be noted that acognitive tag was required for each utterance,while a motivational/affective tag was applied onlyto the subset of utterances that communicated inthat channel.
If an utterance constituted a strictlymotivational/affective act, its cognitive channelwas tagged with EX (EXtra-domain) indicatingthere was no relevant cognitive content.
On theother hand, some utterances had both a cognitivecomponent and a motivational/affective compo-nent.
For example, a tutorial utterance of, ?Thatlooks great!?
would have been tagged as positivefeedback (PF) in the cognitive channel, and aspraise (P) in the motivational/affective channel.
Incontrast, the tutorial move ?That?s right,?
would betagged as positive feedback (PF) in the cognitivechannel and would not be annotated with a motiva-tional/affective tag.
Table 3 shows an excerptfrom the corpus with dialogue act tags applied.55The entire corpus was tagged by a single humanannotator, with a second tagger marking 1,418 ofthe original 4,864 utterances.
The resulting kappastatistics were 0.76 in the cognitive channel and0.64 in the motivation channel.3 Analysis and ResultsOverall, these tutoring sessions were effective:they yielded learning gains (difference betweenposttest and pretest) with mean 5.9% and median7.9%, which were statistically significant(p=0.038), and they produced self-efficacy gainsTable 1:  Cognitive Channel Dialogue Acts56(difference between pre-survey and post-surveyscores) with mean 12.1% and median 12.5%,which were also statistically significant(p<0.0001).
Analyses revealed that statisticallysignificant relationships hold between tutorialstrategy and learning, as well as between tutorialstrategy and self-efficacy gains.3.1 AnalysisFirst, the values of learning gain and self-efficacygain were grouped into binary categories (?Low?,?High?)
based on the median value.
We then ap-plied multiple logistic regression with the gaincategory as the predicted value.
Tutorial strategy,incoming self-efficacy rating, and pre-test scorewere predictors in the model.
The binarizationapproach followed by multiple logistic regressionwas chosen over multiple linear regression on acontinuous response variable because the learninginstruments (10 items each) and self-efficacy ques-tionnaires (5 items each) yielded few distinct val-ues of learning gain, meaning the response variable(learning gain and self-efficacy gain, respectively)would not have been truly continuous in nature.Logistic regression is used for binary responsevariables; it computes the odds of a particular out-come over another (e.g., ?Having high learninggain versus low learning gain?)
given one value ofthe predictor variable over another (e.g., ?The cor-rective tutorial strategy chosen was positive cogni-tive feedback instead of praise?
).Table 2:  Motivational/Affective Channel Dialogue Acts573.2 ResultsAfter accounting for the effects of pre-test scoreand incoming self-efficacy rating (both of whichwere significant in the model with p<0.001), ob-servations containing tutorial encouragement were56% less likely to result in high learning gain thanobservations without explicit tutorial encourage-ment (p=0.001).
On the other hand, an analogousmodel of self-efficacy gain revealed that tutorialencouragement was 57% more likely to result inhigh self-efficacy gain compared to tutorial re-sponses that had no explicit praise or reassurance(p=0.054).
These models suggested that the pres-ence of tutorial encouragement in response toquestionable student problem-solving action mayenhance self-efficacy gain but detract from learn-ing gain.Another significant finding was that observa-tions in which the tutor used cognitive feedbackplus praise were associated with 40% lower likeli-hood of high learning gain than observations inwhich the tutor used purely cognitive feedback.No impact was observed on self-efficacy gain.These results suggest that in response to question-able student problem-solving action, to achievelearning gains, purely cognitive feedback is pre-ferred over cognitive feedback plus praise, whileself-efficacy gain does not appear to be impactedeither way.Among students with low incoming self-efficacy, observations in which the tutor employeda standalone motivational act were 300% as likelyto be in the high self-efficacy gain group as obser-vations in which the tutor employed a purely cog-nitive statement or a cognitive statement combinedwith encouragement (p=0.039).
In contrast, amongstudents with high initial self-efficacy, a purelymotivational tactic resulted in 90% lower odds ofbeing in the high self-efficacy gain group.
Theseresults suggest that standalone praise or reassur-ance may be useful for increasing self-efficacygain among low initial self-efficacy students, butmay decrease self-efficacy gain in high initial self-efficacy students.Considering strictly cognitive feedback, posi-tive feedback resulted in 190% increased odds ofhigh student self-efficacy gain compared to theother cognitive strategies (p=0.0057).
Positivecognitive feedback did not differ significantly fromother types of cognitive strategies in a Chi-squarecomparison with respect to learning gains(p=0.390).
The models thus suggest when dealingwith questionable student problem-solving action,positive cognitive feedback is preferable to othertypes of cognitive feedback for eliciting self-efficacy gains, but this type of feedback is notTable 3:  Dialogue Excerpts58found to be better or worse than other cognitivefeedback for effecting learning gains.4 DiscussionThe study found that the presence of direct tutorialpraise or encouragement in response to question-able student problem-solving action increased theodds that the student reported high self-efficacygain while lowering the odds of high learning gain.The study also found that, with regard to learninggains, purely cognitive feedback was preferable tocognitive feedback with an explicitly motivationalcomponent.
These empirical findings are consis-tent with theories of Lepper et al (1993) whofound that some cognitive and affective goals intutoring are ?at odds.?
As would be predicted, theresults also echo recent quantitative results fromother tutoring domains such as qualitative physics(Jackson et al 2007) and river ecosystems (Tanand Biswas 2006) that, in general, overt motiva-tional feedback contributes to motivation but cog-nitive feedback matters more for learning.Of the corrective tutorial strategies that wereexhibited in the corpus, positive cognitive feed-back emerged as an attractive approach for re-sponding to plausibly incorrect student problem-solving actions.
Responding positively (e.g.,?Right?)
to questionable student actions is an ex-ample of indirect correction, which is recognizedas a polite strategy (e.g., Porayska-Pomsta et al2004).
A qualitative investigation of this phe-nomenon revealed that in the corpus, tutors gener-ally followed positive feedback in this context withmore substantive cognitive feedback to address thenature of the student?s error.
As such, the positivefeedback approach seems to have an implicit, yetperceptible, motivational component while retain-ing its usefulness as cognitive feedback.This study found that explicit motivational acts,when applied as corrective tutorial approaches, haddifferent impacts on different student subgroups.Students with low initial self-efficacy appeared tobenefit more from praise and reassurance than stu-dents with high initial self-efficacy.
In a prior cor-pus study to investigate the impact of learnercharacteristics on tutorial dialogue (Boyer et al2007), we also found that learners from differentpopulations exhibited significantly different dia-logue profiles.
For instance, high self-efficacystudents made more declarative statements, or as-sertions, than low self-efficacy students.
In addi-tion, tutors paired with high self-efficacy studentsgave more conversational acknowledgments thantutors paired with low self-efficacy students, de-spite the fact that tutors were not made aware ofany learner characteristics before the tutoring ses-sion.
Additional dialogue profile differencesemerged between high and low-performing stu-dents, as well as between males and females.
To-gether these two studies suggest that learnercharacteristics influence the structure of tutorialdialogue, and that the choice of tutorial strategymay impact student subgroups in different ways.5 ConclusionThe work reported here represents a first step to-ward understanding the effects of learner charac-teristics on task-oriented tutorial dialogue and theuse of feedback.
Results suggest that positive cog-nitive feedback may prove to be an appropriatestrategy for responding to questionable studentproblem-solving actions in task-oriented tutorialsituations because of its potential for addressingthe sometimes competing cognitive and affectiveneeds of students.
For low self-efficacy students, itwas found that direct standalone encouragementcan be used to bolster self-efficacy, but care mustbe used in correctly diagnosing student self-efficacy because the same standalone encourage-ment does not appear helpful for high self-efficacystudents.
These preliminary findings highlight theimportance of understanding the interaction be-tween learner characteristics and tutorial strategyas it relates to the design of tutorial dialogue sys-tems.Several directions for future work appear prom-ising.
First, it will be important to explore the in-fluence of learner characteristics on tutorialdialogue in the presence of surface level informa-tion about students?
utterances.
This line of inves-tigation is of particular interest given recent resultsindicating that lexical cohesion in tutorial dialoguewith low-performing students is found to be highlycorrelated with learning (Ward and Litman 2006).Second, while the work reported here has consid-ered a limited set of motivational dialogue acts,namely praise and reassurance, future work shouldtarget an expanded set of affective dialogue acts to59facilitate continued exploration of motivational andaffective phenomena in this context.
Finally, thecurrent results reflect human-human tutoringstrategies that proved to be effective; however, itremains to be seen whether these same strategiescan be successfully employed in tutorial dialoguesystems.
Continuing to identify and empiricallycompare the effectiveness of alternative tutorialstrategies will build a solid foundation for choos-ing and implementing strategies that considerlearner characteristics and successfully balance thecognitive and affective concerns surrounding thecomplex processes of teaching and learningthrough tutoring.AcknowledgmentsThe authors wish to thank Scott McQuiggan andthe members of the Intellimedia Center for Intelli-gent Systems for their ongoing intellectual contri-butions, and the Realsearch Group at NC StateUniversity for extensive project development sup-port.
This work was supported in part by the Na-tional Science Foundation through Grant REC-0632450, an NSF Graduate Research Fellowship,and the STARS Alliance Grant CNS-0540523.Any opinions, findings, conclusions or recommen-dations expressed in this material are those of theauthor(s) and do not necessarily reflect the viewsof the National Science Foundation.
Support wasalso provided by North Carolina State Universitythrough the Department of Computer Science andthe Office of the Dean of the College of Engineer-ing.ReferencesKristy Elizabeth Boyer, Robert Phillips, Michael Wallis,Mladen Vouk, and James Lester.
In press.
Balanc-ing cognitive and motivational scaffolding in tutorialdialogue.
To appear in Proceedings of the 9th Inter-national Conference on Intelligent Tutoring Systems.Kristy Elizabeth Boyer, Mladen Vouk, and James Les-ter.
2007.
The influence of learner characteristics ontask-oriented tutorial dialogue.
Proceedings ofAIED, pp.
127-134.
IOS Press.Vincent Aleven, Kenneth R. Koedinger, and OctavPopescu.
2003.
A tutorial dialog system to supportself-explanation: Evaluation and open questions.Proceedings of the 11th International Conference onArtificial Intelligence in Education, pp.
39-46.
Am-sterdam.
IOS Press.Vincent Aleven, Bruce McLaren, Ido Roll, and KennethKoedinger.
2004.
Toward tutoring help seeking:Applying cognitive modeling to meta-cognitiveskills.
J. C. Lester, R. M. Vicari, and F.
Paragua?u(Eds.
), Proceedings of the 7th International Confer-ence on Intelligent Tutoring Systems, pp.
227-239.Berlin: Springer Verlag.Albert Bandura.
2006.
Guide for constructing self-efficacy scales.
T. Urdan and F. Pajares (Eds.
): Self-Efficacy Beliefs of Adolescents, pp.
307-337.
Infor-mation Age Publishing, Greenwich, Connecticut.Michelene T. H. Chi, Nicholas De Leeuw, Mei-HungChiu, and Christian LaVancher.
1994.
Eliciting self-explanations improves understanding.
Cognitive Sci-ence, 18:439-477.Michelene T. H. Chi, Stephanie A. Siler, HeisawnJeong, Takashi Yamauchi, and Robert G. Hausmann.2001.
Learning from human tutoring.
Cognitive Sci-ence, 25(4):471-533.Mark G. Core, Johanna D. Moore, and Claus Zinn.2003.
The role of initiative in tutorial dialogue.
Pro-ceedings of the Tenth Conference on EuropeanChapter of the Association for Computational Lin-guistics, pp.
67-74.Teresa del Soldato and Benedict du Boulay.
1995.
Im-plementation of motivational tactics in tutoring sys-tems.
Journal of Artificial Intelligence in Education,6(4):337-378.
Association for the Advancement ofComputing in Education, USA.Martha Evens and Joel Michael.
2006.
One-on-OneTutoring by Humans and Computers.
Mahwah, NewJersey: Lawrence Erlbaum Associates.Kate Forbes-Riley and Diane Litman.
2005.
Usingbigrams to identify relationships between student cer-tainness states and tutor responses in a spoken dia-logue corpus.
Proceedings of the 6th SIGdialWorkshop on Discourse and Dialogue.
Lisbon, Por-tugal.Kate Forbes-Riley, Diane Litman, Alison Huettner, andArthur Ward.
2005.
Dialogue-learning correlationsin spoken dialogue tutoring.
Looi, C-k., Mccalla, G.,Bredeweg, B., Breuker, J.
(Eds.
): Proceedings ofAIED, pp.
225-232.
IOS Press.Arthur C. Graesser, George T. Jackson, Eric Mathews,Heather H. Mitchell, Andrew Olney, Mathew Ven-tura, Patrick Chipman, Donald R. Franceschetti,Xiangen Hu, Max M. Louwerse, Natalie K. Person,and the Tutoring Research Group.
2003.Why/AutoTutor: A test of learning gains from aphysics tutor with natural language dialog.
Proceed-ings of the Twenty-Fifth Annual Conference of theCognitive Science Society, pp.
474-479.Arthur C. Graesser, Natalie K. Person, and Joseph P.Magliano.
1995.
Collaborative dialogue patterns innaturalistic one-to-One tutoring.
Applied CognitivePsychology, 9(6):495-522.
John Wiley & Sons, Ltd.60G.
Tanner Jackson and Art Graesser.
2007.
Contentmatters: An investigation of feedback categorieswithin an ITS.
Luckin, R., Koedinger, K. R., Greer,J.
(Eds.
): Proceedings of AIED 2007, 158:127-134.IOS Press.Sandra Katz, David Allbritton, and John Connelly.2003.
Going beyond the problem given: How humantutors use post-solution discussions to support trans-fer.
International Journal of Artificial Intelligence inEducation, 13:79-116.John M. Keller.
1983.
Motivational design of instruc-tion.
Reigeluth, C.M.
(Ed.
): Instructional-DesignTheories and Models: An Overview of Their CurrentStatus, pp.
383-429.
Lawrence Erlbaum Associates,Inc., Hillsdale, NJ.H.
Chad Lane and Kurt VanLehn.
2005.
Teaching thetacit knowledge of programming to novices withnatural language tutoring.
Computer Science Educa-tion, 15:183-201.Mark R. Lepper, Maria Woolverton, Donna L. Mumme,and Jean-Luc Gurtner.
1993.
Motivational tech-niques of expert human tutors: Lessons for the designof computer-based tutors.
Lajoie, S.P., Derry, S.
J.(Eds.
): Computers as Cognitive Tools, pp.
75-105.Lawrence Erlbaum Associates, Inc., Hillsdale NJ.Jackson Liscombe, Julia Hirschberg, and Jennifer J.Venditti.
2005.
Detecting certainness in spoken tu-torial dialogues.
Proceedings of Interspeech, 2005.Diane J. Litman, Carolyn P.
Ros?, Kate Forbes-Riley,Kurt VanLehn, Dumisizwe Bhembe, and Scott Silli-man.
2006.
Spoken versus typed human and com-puter dialogue tutoring.
International Journal ofArtificial Intelligence in Education, 16:145-170.Johanna Marineau, Peter Wiemer-Hastings, DerekHarter, Brent Olde, Patrick Chipman, Ashish Kar-navat, Victoria Pomeroy, Sonya Rajan, Art Graesser,and the Tutoring Research Group.
2000.
Classifica-tion of speech acts in tutorial dialog.
Proceedings ofthe Workshop on Modeling Human Teaching Tacticsand Strategies of ITS 2000, pp.
65-71.
Montreal,Canada.Stellan Ohlsson, Barbara Di Eugenio, Bettina Chow,Davide Fossati, Xin Lu, and Trina C. Kershaw.2007.
Beyond the code-and-count analysis of tutor-ing dialogues.
Luckin, R., Koedinger, K. R., Greer,J.
(Eds.
): Proceedings of AIED 2007, 158:349-356.IOS Press.Natalie K. Person, Roger J. Kreuz, Rolf A. Zwaan, andArthur C. Graesser.
1995.
Pragmatics and peda-gogy: Conversational rules and politeness strategiesmay inhibit effective tutoring.
Cognition and In-struction, 13(2):161-188.
Lawrence Erlbaum Asso-ciates, Inc., Hillsdale, NJ.Heather Pon-Barry, Karl Schultz, Elizabeth Owen Bratt,Brady Clark, and Stanley Peters.
2006.
Respondingto student uncertainty in spoken tutorial dialogue sys-tems.
International Journal of Artificial Intelligencein Education, 16:171-194.Ka?ka Porayska-Pomsta and Helen Pain.
2004.
Provid-ing cognitive and affective scaffolding through teach-ing strategies:  Applying linguistic politeness to theeducational context.
J.C. Lester, Vicari, R. M., Para-gua?u, F.
(Eds.
): Proceedings of ITS 2004, LNCS3220:77-86.
Springer-Verlag Berlin / Heidelberg.Genaro Rebolledo-Mendez, Benedict du Boulay, andRosemary Luckin.
2006.
Motivating the learner: anempirical evaluation.
Ikeda, M., Ashlay, K. D., Chan,T.-W.
(Eds.
): Proceedings of ITS 2006,  LNCS4053:545-554.
Springer Verlag Berlin / Heidelberg.Carolyn P.
Ros?, Dumisizwe Bhembe, Stephanie Siler,Ramesh Srivastava, and Kurt VanLehn.
2003.
Therole of why questions in effective human tutoring.Hoppe, U., Verdejo, F., Kay, J.
(Eds.
): Proceedingsof AIED 2003, pp.
55-62.
IOS Press.Andreas Stolcke, Klaus Ries, Noah Coccaro, ElizabethShriberg, Rebecca Bates, Daniel Jurafsky, Paul Tay-lor, Rachel Martin, Carol Van Ess-Dykema, andMarie Meteer.
Dialogue act modeling for automatictagging and recognition of conversational speech.2000.
Computational Linguistics, 26:339-373.Jason Tan and Gautam Biswas.
2006.
The role of feed-back in preparation for future learning:  A case studyin learning by teaching environments.
Ikeda, M.,Ashley, K., Chan, T.-W.
(Eds.
): Proceedings of ITS2006, LNCS 4053:370-381.
Springer-Verlag Berlin /Heidelberg.Kurt VanLehn, Pamela W. Jordan, Carolyn P. Ros?,Dumisizwe Bhembe, Michael Bottner, Andy Gaydos,Maxim Makatchev, Umarani Pappuswamy, MichaelRingenberg, Antonio Roque, Stephanie Siler, andRamesh Srivastava.
2002.
The architecture ofWhy2-Atlas: A coach for qualitative physics essaywriting.
Proceedings of the 6th International Con-ference on Intelligent Tutoring Systems, LNCS2363:158-167.Arthur Ward and Diane Litman.
2006.
Cohesion andlearning in a tutorial spoken dialog system.
Proceed-ings of the 19th International FLAIRS (Florida Artifi-cial Intelligence Research Society) Conference.Melbourne Beach, FL.Claus Zinn, Johanna D. Moore, and Mark G. Core.2002.
A 3-tier planning architecture for managingtutorial dialogue.
Intelligent Tutoring Systems, SixthInternational Conference.
LNCS 2363:574-584.Springer-Verlag, London, UK.61
