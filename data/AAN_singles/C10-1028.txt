Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 241?249,Beijing, August 2010Automated Translation of Semantic RelationshipsDmitry DavidovICNCHebrew University of JerusalemAri RappoportInstitute of Computer ScienceHebrew University of Jerusalemarir@cs.huji.ac.ilAbstractWe present a method for translating se-mantic relationships between languageswhere relationships are defined as patternclusters.
Given a pattern set which rep-resents a semantic relationship, we usethe web to extract sample term pairs ofthis relationship.
We automatically trans-late the obtained term pairs using multi-lingual dictionaries and disambiguate thetranslated pairs using web counts.
Finallywe discover the set of most relevant tar-get language patterns for the given rela-tionship.
The obtained pattern set can beutilized for extraction of new relationshipexamples for the target language.We evaluate our method on 11 diverse tar-get languages.
To assess the quality ofthe discovered relationships, we use an au-tomatically generated cross-lingual SATanalogy test, WordNet relationships, andconcept-specific relationships, achievinghigh precision.
The proposed frameworkallows fully automated cross-lingual rela-tionship mining and construction of mul-tilingual pattern dictionaries without rely-ing on parallel corpora.1 IntroductionAcquiring and understanding semantic relation-ships is crucial for many NLP applications.
Inmany cases, we would like to know if a giventerm pair participates in a specified semantic re-lationship or if two different term pairs encodethe same (possibly unspecified) type of relation-ship.
Beyond the well-known major relationshiptypes such as hyponymy (is-a) and meronymy(part-of), there is a huge number of other rela-tionships between objects and concepts.
Exam-ples include general relations such as larger-than,contained-in, liked-by and domain specific onessuch as country-language, product-manufacturer,product-seller, drug-disease etc.The vast majority of NLP research is done ina few languages for which extensive corpora (in-cluding the web) are available.
As a result, mostrelationship retrieval studies and lexical databasecompilation efforts target only a few languages.However, due to the substantial growth of the mul-tilingual web1 and a growing demand for NLPapplication coverage for less common languages,there is a need for relationship data in many lessstudied languages.In this paper we address the task of translatingrelationships between languages, which has twoobvious benefits.
First, it can directly help appli-cations such as machine translation, cross-lingualinformation retrieval, cross-lingual web miningand the construction and enrichment of seman-tic databases.
Second, it can assist applicationsin a single language, especially when compensat-ing for a relative scarcity of resources in that lan-guage.
We focus on relations between two enti-ties, which are the most common type.When discussing the translation of relation-ships, it is important to define how these are rep-resented and in what way the task differs fromMT.
While there is wide agreement on the def-inition and representation of major relationshiptypes such as hypernymy and (to a lesser extent)meronymy, there is no single accepted method (or1http://www.internetworldstats.com/stats7.htm241resources) for other less common relationships.Among the methods that have been proposed forspecifying lexical relationships are natural lan-guage description and rules (Girju et al, 2007),distributional means (Turney, 2005), sample termpairs (Pasca et al 2006), relationship instances(Banko et al, 2007) and pattern clusters (Davi-dov and Rappoport, 2008a).In this paper we utilize the last definition.
Fol-lowing (Davidov and Rappoport, 2008a) each se-mantic relationship can be defined and repre-sented by a set of lexical patterns such that therepresented relation holds between entities fillingthe patterns?
slots.
We focus on pattern clusters re-lationship definition due to several reasons.
First,as opposed to natural language descriptions, pat-tern clusters are formal.
Second, as opposed tothe other methods above, pattern clusters providea ?generative?
model for the represented relation-ship ?
it is possible to obtain from them relation-ship instances and term pairs, as we indeed uti-lize in this paper.
Third, pattern clusters can bemined in a fully unsupervised manner, or in afocused manner when the relationship desired isknown.
Finally, pattern methods have proven tobe highly efficient and effective for lexical acqui-sition tasks (Pantel et al 2004; Davidov and Rap-poport, 2006).The proposed framework comprises the follow-ing stages.
First, given a set of patterns defining arelationship in a source language, we obtain fromthe web a set of corresponding term pairs.
Next,for each of the terms in the obtained term pairs,we retrieve sets of their translations to the targetlanguage using available multilingual dictionar-ies.
Now that we have a set of translations foreach term in each pair, we retrieve search enginesnippets with the translated term pairs.
We thenselect appropriate word senses using web counts,and extract a set of patterns which connect thesedisambiguated terms.
As a result we get a setof relation-specific target language patterns, ef-fectively obtaining the desired relationship defi-nition.
We can optionally use the retrieved patternsets to obtain term pairs of target language rela-tionships from the web.We performed a thorough evaluation for var-ious relationships involving 11 languages.
Wetested our framework on major relationships likemeronymy, specific relationships like country-capital and unspecified unsupervisedly discoveredEnglish relationships.
The obtained relationshipswere manually verified by human judges usingcross-lingual SAT analogy questions, and a fewspecific factual relationships were evaluated usinga gold standard.Our main contribution is a novel frameworkfor automated relationship translation across lan-guages, where relationships are defined as patternclusters or as term pairs.
This framework allowsfully automated cross-lingual relationship miningand construction of multilingual pattern dictionar-ies without relying on parallel corpora.In Section 2 we discuss related work.
Section 3details the algorithm.
Section 4 describes the eval-uation, and Section 5 concludes.2 Related workRecently, with the development of practical appli-cations which utilize WN-like databases in dozensof languages, great effort has been made to manu-ally construct and interconnect such databases fordifferent languages (Pease et al 2008; Charoen-porn et al, 2007).
Some studies (e.g., (Amasyali,2005)) use semi-automated methods based onlanguage-specific heuristics and dictionaries.At the same time, much work has been doneon automated lexical acquisition for a single lan-guage, and in particular, on the web-based ac-quisition of various types of semantic relation-ships.
There is a substantial amount of relatedstudies which deal with the discovery of vari-ous relationship types represented in useful re-sources such as WordNet, including hypernymy(Pantel et al 2004; Snow et al, 2006), synonymy(Davidov and Rappoport, 2006; Widdows andDorow, 2002) and meronymy (Berland and Char-niak, 1999; Girju et al 2006).
Since namedentities are very important in NLP, many studiesdefine and discover relations between named en-tities (Hassan et al, 2006).
Work was also doneon relations between verbs (Chklovski and Pan-tel, 2004).
There is growing research on relationsbetween nominals (Girju et al, 2007).While the majority of studies focus on extract-ing pre-specified semantic relationships, several242recent studies were done on the automated discov-ery of unspecified relationship types.
Thus Tur-ney (2006) provided a pattern distance measurethat allows a fully unsupervised measurement ofrelational similarity between two pairs of wordson the same language.
Banko et al (2007) andRosenfeld and Feldman (2007) find relationshipinstances where the relationships are not speci-fied in advance.
(Davidov and Rappoport, 2008a)introduced the idea that salient semantic relation-ships can be defined as pattern clusters, confirm-ing it with SAT analogy test.
As explained above,we use this definition in the present study.
Wealso use pattern clusters given by (Davidov andRappoport, 2008a) as input in our evaluation.Most of the relationship acquisition studieswere done in a single language.
Those that ex-periment in several languages usually treat eachlanguage separately, while we extract a relation-ship definition for one language using the pro-vided definition for the other language.Our study is related to cross-language infor-mation retrieval (CLIR) frameworks.
Both dealwith multilingual information extracted from theWeb.
However, the majority of CLIR stud-ies pursue different targets.
Thus, one of themain CLIR goals is the retrieval of documentsbased on explicit queries, when the documentlanguage is not the query language (Volk andBuitelaar, 2002).
These frameworks usually de-velop language-specific tools and algorithms in-cluding parsers, taggers and morphology analyz-ers in order to integrate multilingual queries anddocuments (Jagarlamudi and Kumaran, 2007).Our goal is to develop and evaluate a language-independent algorithm for the cross-lingual trans-lation of relationship-defining structures.
Whileour targets are different from those of CLIR, CLIRsystems can greatly benefit from our framework,since we can translate the relationships in CLIRqueries and subsequently check if the same rela-tionships are present in the retrieved documents.Another field indirectly related to our researchis Machine translation (MT).
Many MT tasks re-quire automated creation or improvement of dic-tionaries (Koehn and Knight, 2001).
However,MT mainly deals with translation and disambigua-tion of words at the sentence or document level,while we translate relationship structures as a setof patterns, defined independently of contexts.We also perform pattern-set to pattern-set trans-lation rather than the pattern-to-pattern or pair-to-pair translation commonly explored in MT stud-ies.
This makes it difficult to perform meaning-ful comparison to existing MT frameworks.
How-ever, the MT studies benefit from the proposedframework by enhancement and verification oftranslated relationship instances.In (Davidov and Rappoport, 2009), we pro-posed a framework for automated cross-lingualconcept mining.
We incorporate several princi-ples from this study including concept extensionand disambiguation of query language (See Sec-tion 3.3).
However our goals here are differentsince we target cross-lingual acquisition of rela-tionship structures rather then concept term lists.3 Relationship Translation FrameworkOur framework has the following stages: (1) givena set of patterns in a source language definingsome lexical relationship, we use the web to ob-tain source language term pairs participating inthis relationship; (2) we automatically translatethe obtained terms in each pair to the target lan-guage using available multilingual dictionaries;(3) we retrieve web snippets where these transla-tions co-appear, disambiguating translations withweb counts and extracting the corresponding pat-terns.
As an optional final stage, the translatedpattern cluster can be used to extract and extenda set of target language term pairs.
Now we de-scribe each of these stages in detail.3.1 Acquisition of representative term pairsWe are provided with a pattern cluster, a set of pat-terns representing a specific lexical relationship insome language.
The goal of the first stage is todiscover the most representative term pairs for thiscluster and language from the web.
If the relation-ship is already specified by a representative set ofterm pairs, we skip this stage and continue to thenext stage.
Note that the method described be-low can also be used at the final stage to obtainrepresentative target language term pairs once weobtain a target language pattern cluster.The input lexical patterns are surface patterns243which include several fixed words or punctuationsymbols and two slots for content words, e.g.
?the[X] of the [Y],?.
Given a cluster of patterns defin-ing a semantic relationship, we would like to ob-tain from the web the most representative and fre-quent examples of the represented relationship.In order to do that we construct search enginequeries2 from the given patterns using wildcardsymbols to represent pattern slots.
For example,given a pattern ?the [X] of the [Y],?
we constructqueries such as ?the * of the?
; ?the * * of the?3.We collect all the retrieved search engine snip-pets and extract the appropriate term pairs foundin these snippets.Now we would like to select the most useful ofthe extracted pairs.
Since the obtained pairs areonly useful if we can translate them into the tar-get language, we dismiss all pairs in which one orboth terms have no translations to the target lan-guage in our dictionaries (see Section 3.2).
Sinceeach particular pattern can be ambiguous, we alsodismiss pairs which were found for only a singlepattern in the given cluster.For the remaining term pairs we would liketo estimate their specificity for the given patterncluster.
For each pattern, we retrieve and use twoweb hit counts: Fterms(p, T1, T2), a hit count forco-appearance of the pair in a way similar to thatin the pattern, and Fall(p, T1, T2), the hit countof the full pattern instance.For example, if for the pattern p=?the * ofthe?
we obtain a term pair (CEO, company), thenFall(p)=Hits(?the CEO of the company?)
andFterms(CEO, company)= Hits(?CEO * * com-pany?).
Given a pattern cluster C with patterns{p1 .
.
.
pn} ?
C, we estimate the specificity ofa term pair (T1, T2) using the following simpleprobabilistic metric, giving to all patterns in thecluster an equal weight:Spec(T1, T2) = 1n?pi?CFall(pi, T1, T2)Fterms(pi, T1, T2)We select the top 15 pairs with the highest speci-ficity and use them in the next stage.2We use Yahoo!
Boss.3Since the search engine API doesn?t allow punctuation,we omit the punctuation in queries, but require a properpunctuation when processing the obtained snippet data.3.2 Translation of the term pairsAfter the previous stage we have a good represen-tative set of term pairs for the desired source lan-guage relationship.
Now we would like to trans-late the words in these pairs to the target language.In order to do that we use an extensive set of1067 multilingual dictionaries developed for Star-Dict4, including Wikipedia cross-language linksand Wiktionary.
For each term we obtain a setof its translations to the target language.
If weget more than five different translations, we selectthe five having the highest number of dictionarieswhere this translation appears.As discussed in Section 3.1, we dismissedterms for which no translation was found in any ofthe available dictionaries, so each term in each ofthe obtained pairs has at least a single translationto the target language.
However, in many cases theavailable translations represent the wrong wordsense, since both the source terms and their trans-lations can be ambiguous.
Thus at this stage manyof the obtained term translations are irrelevant forthe given relationship and require disambiguation.3.3 Web mining for translation contextsFor this stage, we need to restrict web miningto specific target languages.
This restriction isstraightforward if the alphabet or term translationsare language-specific or if the search API supportsrestriction to this language.
In case where there isno such natural restrictions, we attempt to detectand add to our queries a few language-specific fre-quent words.
Following (Davidov and Rappoport,2009), we use our dictionaries to find 1?3 of the15 most frequent words in a desired language5 thatare unique to that language and ?and?
them withthe queries to ensure proper language selection.This allows applying our algorithm to more than60 diverse languages.
The only data required foreach language is at least a partial coverage of theobtained term pairs by some available dictionary.Given a term pair (T1, T2) we obtain a setof translations (T1?i?1...n, T2?j?1...m).
For eachcombination T1?i, T2?j of the obtained term trans-lations, we construct and execute the following4http://stardict.sourceforge.net/5We estimated the word frequencies from text availablein the corresponding multilingual dictionaries.244four queries: {?T1?i ?
T2?j?, ?T2?j ?
T1?i?,?T1?i ?
?
T2?j?, ?T2?j ?
?
T1?i?}6.
SinceY ahoo!Boss allows retrieval of up to the 1000first results, we can collect up to four thousandsnippets for each combination.
However, the ma-jority of these combinations return no snippets atall, effectively generating an average of a dozensnippets per query.3.4 Pattern extractionNow for each pair of term translations we wouldlike to extract from the snippets all surface pat-terns which connect the terms in this pair.
We usethe basic two-slot meta-pattern type:[Prefix] X [Infix] Y [Postfix]X and Y should be the translated terms, Infix maycontain punctuation, spaces, and up to four words(or up to eight symbols in languages withoutspace-separated words like Chinese).
Prefix andPostfix are limited to contain one or zero punctu-ation characters and/or up to two words.
We donot allow empty Infix, Prefix of Postfix.
If thereare several possible combinations of Prefix andPostfix we generate a pattern set for all possiblecombinations (e.g., if we retrieve a snippet .
.
.
?,consider using [plexiglass] for [kitchen].?.
.
.
, wecreate patterns ?using X for Y.?, ?consider usingX for Y.?
and ?, consider using X for Y.?
).Now we would like to find the patterns repre-senting the relationship in the target language.
Wedo this in two stages.
First we would like to detectthe most common patterns for the given relation-ship.
Let Sk be the union set of all patterns ob-tained for all combinations of the extracted trans-lations for a specific source language term pairk ?
1 .
.
.K.
Let Salience(p) = 1K |{k|p ?
Sk}|be the portion of source language term pairs whichlead to detection of the target language patternp.
We compute salience for each pattern, andselect a subset of salient patterns, defined to bethose whose Salience exceeds a predefined thresh-old (we used 1/3).
If one salient pattern is a sub-string of another salient pattern, we only select thelonger one.6These are Yahoo!
queries where enclosing words in ?
?means searching for an exact phrase and ?*?
means a wild-card for exactly one arbitrary word.In our salience estimation we mix data fromall combinations of translations including incor-rect senses and wrong translations of ambiguousterms.
Now we would like to select a single cor-rect target language pair for each source languagepair in order to find more refined relationship rep-resenting patterns.
For each source language termpair, we select the target language translated pairwhich captured the highest number of salient pat-terns.
In case there are several pairs with the samenumber of salient patterns, we select a pair withthe greatest web hit count.
We drop term pairswith zero salient patterns.Finally we would like to enhance the obtainedset of salient patterns with more precise and rep-resentative relationship-specific patterns.
Sincewe disambiguated the translated pairs, target lan-guage patterns captured by the remaining termpairs should be more trusted.
We compare thetarget language pattern sets obtained for differ-ent remaining term pairs, and collect all patternsthat were captured by at least three different termpairs.
As before, if one pattern is a substring ofanother we retain only the longer one.
As a resultwe get a comprehensive target language patterncluster for the desired relationship.3.5 Retrieval of target language term pairsAs an optional final stage, we can utilize the re-trieved target language pattern clusters in order todiscover target language term pairs for the desiredrelationship.
We do this by utilizing the strategydescribed in Section 3.1 on the obtained targetlanguage pattern clusters.
We do not dismiss ob-tained terms having no available dictionary trans-lations, and we do not limit our search to the 15terms with highest specificity.
Instead we eitherselect N term pairs with top specificity (where Nis provided by user as in our evaluation), or weselect all term pairs with specificity above somethreshold.4 EvaluationIn order to test the quality of the translated pat-tern clusters and the corresponding translated termpairs, we need to check both flexibility and cor-rectness.
Flexibility measures how well the re-trieval works well across languages and for many245types of semantic relationships.
To do that, wetested our framework on both generic and specificrelationships for 11 languages.
Correctness ver-ifies that the retrieved set of target language pat-terns and the corresponding term pairs representthe same semantic relationship as the given setof source language term pairs or patterns.
To dothat, we used both manual cross-lingual analogy-based correctness evaluation and evaluation basedof factual data.4.1 Languages and relationshipsOne of the main goals in this research was to pro-vide a fully automated and flexible framework,which requires minimal modifications when ap-plied to different languages and relationships.We examined an extensive set of target lan-guages using English as a source language.
Ta-ble 1 shows 11 languages used in our experiments.We included west European languages, Slavic lan-guages like Russian, Semitic languages like He-brew, and Asian languages such as Chinese.
Wedeveloped a set of tools for automatic off-line ac-cess to an extensive set of 1067 multilingual dic-tionaries created for the StarDict platform.
Thesedictionaries include recent dumps of Wikipediacross-language links and Wiktionary data.In our experiments we used three sets of rela-tionships: (1) Generic: 15 unsupervisedly dis-covered English pattern clusters representing var-ious generic relationships.
(2) H-M-C: Thethree most studied relationships: hypernymy,meronymy and co-hyponymy.
(3) Specific: Threefactual relationships: country-capital, country-language and dog breed-origin.
Below we de-scribe the evaluation of each of these sets in de-tail.
Note that our framework allows two ways ofspecifying a source language relationship ?
a pat-tern cluster and a set of term pairs.4.2 Evaluation of generic pattern clustersIn our Generic evaluation setting, we utilized asinput a random sample of 15 automatically dis-covered relationship definitions.
We started froma set of 508 English pattern clusters, unsuper-visedly discovered using the method of (Davidovand Rappoport, 2008a).
Each of these clustersis assumed to represent a distinct semantic rela-tionship.
We randomly selected 15 pattern clus-ters from this set and executed our framework onthese clusters to obtain the corresponding targetlanguage pattern clusters for each of the 11 testedlanguages.
An example of a partial set of patternsin a cluster is: ?this [X] was kept in [Y],?
;?the X that hekept in [Y],?
;?the [X] in the [Y] and?
;?the [Y] containingthe [X]?.
.
.
.We then used the term pair selection algorithmdescribed in Section 3.1 to select the most spe-cific term pair for each of the 15 source languageclusters and 10 pairs for each of the correspondingtranslated target language clusters.
Thus for eachof the 15 pattern clusters and for each of the 11languages we produced a single source languageterm pair and up to 10 corresponding target lan-guage term pairs.In order to check the correctness of transla-tion of an unspecified semantic relationship weneed to compare source and target language rela-tionships.
Comparison of relationships is a chal-lenging task, since there are no relationship re-sources for most relationship types even in a sin-gle language, and certainly so for their trans-lations across languages.
Thus various studiesdefine and split generic relationships differentlyeven when describing relatively restricted rela-tionship domains (e.g., relationships holding be-tween parts of noun phrases (Nastase and Sz-pakowicz, 2003; Moldovan et al, 2004)).
In orderto compare generic relationships we used a man-ual cross-lingual SAT-like analogy human judg-ment evaluation7.
This allowed us to assess thequality of the translated pattern clusters, in a sim-ilar way as (Davidov and Rappoport, 2008a) didfor testing clusters in a single language.For each of the 15 clusters we constructed across-lingual analogy question in the followingmanner.
The header of the question was a termpair obtained for the source language pattern clus-ter.
The six multiple choice items included: (1)one of the 10 discovered translated term pairs ofthe same cluster (the ?correct?
answer)8; (2) three7Using Amazon?s Mechanical Turk.8We avoid selection of the target language pairs whichwere obtained through direct translation of the source lan-guage pair given at the header of the question.
This is crucialso that subjects will not judge correctness of translation butcorrectness of the relationship.246of the translated pairs of the other clusters amongthe 15; (3) a pair constructed by randomly select-ing terms from different translated clusters; (4) the6th option states that either the given options in-clude broken words or incorrect language, or noneof the presented pairs even remotely exemplifiesthe relationship in question.
An example questionfor English-Italian:The English pair: (kennel, dog); (1) ?correct?
pair: (ac-quario, pesce ); (2)-(4) ?wrong?
pairs: (topo, orecchio),(mela, rossa), (occhio, grande); (5) ?random?
: (scodella,scatola); (6) Pairs comprise non-Italian/broken words or nopair exemplifies the relationshipIn order to check the English proficiency of thesubjects we added 5 ?easy?
monolingual EnglishSAT analogy questions.
We also added a singlehand-crafted cross-lingual question of an obviousanalogy case, making a total of 16 cross-lingualquestions.
Subjects who failed more than one ofthe easy English SAT questions or failed the obvi-ous cross-lingual question were rejected from theevaluation.
Finally we have three subjects for eachof the tested languages.
We also asked the sub-jects to assign a confidence score from 0 (worst)to 10 (best) to express how well the selected termpair represents the source language relationship inquestion.Language P % 6th Scorec ScorewChinese 71 9 9.1 1.8Czech 73 9 8.3 2.0French 80 10 8.4 1.9German 68 9 8.3 1.5Greek 72 11 8.7 2.0Hebrew 69 11 9.0 2.5Hindi 62 12 7.4 1.9Italian 70 10 8.5 1.5Russian 75 8 9.0 1.6Turkish 61 13 9.1 2.0Ukrainian 73 11 9.3 2.3Average 70 10 9.1 1.9Table 1: Averaged results for manual evaluation of 15 pat-tern clusters.
P: precision (% of correct answers); % 6th: per-centage of 6th selection; Scorec: averaged confidence scorefor correct selections; Scorew: confidence score for wrongselections.We computed accuracy and agreement for thegiven answers (Table 1).
We can see that for alllanguages above 61% of the choices were cor-rect (comparing to 75% reported by (Davidovand Rappoport, 2008a) for a similar monolingualanalogy test for the same set of pattern clusters).While the results are obviously lower than the cor-responding single-language test, they are signifi-cantly above the random baseline of 20%9.
Alsonote that as reported in (Turney, 2006), an aver-age single-language highschool SAT grade is 57,which is lower than the scores obtained for ourcross-lingual test.
We can also see that for the cor-rectly selected pairs the confidence score was veryhigh, while the score for wrongly selected pairswas significantly lower.4.3 Evaluation of the H-M-C relationshipsIn order to test how well our algorithm performson the most common and useful relationships, hy-pernymy, meronymy and co-hyponymy, we au-tomatically sampled from WordNet a set of 10source language term pairs for each of these re-lationships and applied our framework to extractup to 100 target language term pairs for each ofthe three relationships as done above.For each of the tested languages we presentedto three human subjects for each language a shortEnglish definition of hypernymy, meronymy andco-hyponymy, along with the corresponding ran-domly selected 10 of 100 extracted pairs, andasked them to rank how well (0 (worst) to 10(best)) each pair represents the described relation-ship.
In order to reduce possible bias, we mixed ineach set 3 randomly selected term pairs obtainedfor the other two relationships.
Table 2 shows theaverage scores for this task.Language Hypernymy Meronymy Co-hyponymy RandomChinese 8.0 7.1 8.1 1.9Czech 8.4 7.0 8.5 2.3French 8.1 7.5 8.4 1.8German 8.4 7.1 8.6 2.4Greek 8.7 7.5 8.6 1.8Hebrew 8.6 7.9 8.3 1.6Hindi 7.5 7.1 7.8 2.2Italian 7.9 7.8 8.2 1.5Russian 8.6 8.1 8.9 1.7Turkish 8.3 7.2 8.6 1.7Ukrainian 8.2 7.7 8.2 1.7Average 8.3 7.5 8.4 1.9Table 2: Averaged results for hypernymy, meronymy andco-hyponymy translations.
The three first columns show av-erage scores for hypernymy, meronymy and co-hyponymyrelationships.
The last column shows scores for the randombaseline.We can see that our algorithm successfully de-tects the common relationships, achieving highscores.
Also the results indicate that the patterns9A reasonable random baseline omits the 6th option.247are sufficiently precise to extract at least 100 ofthe instances for the given salient relationships.4.4 Evaluation of the specific relationshipsTo check how well our algorithm performs onsome specific relationships, we examined its per-formance on three specific relationships exploredin previous studies.
We provided it with 10 sourcelanguage (English) term pair examples for eachof the (country, capital), (country, language) and(dog breed, origin) relationships.
For each ofthese relationships we have factual informationfor every tested target language available throughWikipedia list articles.
This allows us to performan unbiased automated evaluation of the quality ofthe obtained target language data.We applied our framework on these examplesand generated 30 target language pairs with high-est specificity for each of these relationships andlanguages.
We compared the retrieved pairs to thefactual data.
Table 3 shows the precision of theresults obtained for these patterns.Language Capital Language Dog breedChinese 0.87 0.83 0.8Czech 0.93 0.83 0.77French 0.97 0.9 0.87German 0.93 0.9 0.83Greek 0.87 0.83 0.77Hebrew 0.83 0.8 0.8Hindi 0.83 0.8 0.77Italian 0.93 0.87 0.83Russian 0.97 0.9 0.87Turkish 0.87 0.83 0.83Ukrainian 0.93 0.87 0.8Average 0.9 0.85 0.81Table 3: Precision for three specific relationshiptypes: (country, capital), (country, language) and (dogbreed,origin).The precision observed for this task is compara-ble to precision obtained for Country-Capital andCountry-Language in a previous single-languageacquisition study (Davidov et al, 2007)10.
Thehigh precision observed for this task indicates thatthe obtained translated patterns are sufficientlygood as a seed for pattern-based mining of spe-cific relationships.10It should be noted however that unlike previous work,we only examine the first 30 pairs and we do not use addi-tional disambiguating words as input.5 ConclusionWe proposed a framework which given a set ofpatterns defining a semantic relationship in a spe-cific source language uses multilingual dictionar-ies and the web to discover a corresponding pat-tern cluster for a target language.
In the evaluationwe confirmed the applicability of our method fordifferent languages and relationships.The obtained set of target language pattern clus-ters can be used for acquisition of relationship in-stances as shown in our evaluation.
An interest-ing direction for future work is to use the discov-ered target language pattern clusters in NLP taskslike textual entailment which require distinguish-ing between semantic relationships.Applying our framework to the set of unsuper-visedly discovered relationships allows a fully au-tomated construction of a relationship dictionary,where pattern clusters in one language correspondto patten clusters in many other languages.
Un-like the majority of existing machine translationsystems, construction of this dictionary does notrequire parallel corpora.
Such a dictionary can beuseful for machine translation, cross-lingual tex-tual entailment and query translation, to name justa few applications.
In the future we plan to createa multilingual pattern cluster dictionary which in-terconnects pattern clusters from many languagesand allows cross-lingual definition of lexical rela-tionships.ReferencesAmasyali Fatih, 2005.
Automatic Construction ofTurkish Wordnet.
Signal Processing and Commu-nications Applications Conference.Mishele Banko, Michael Cafarella , Stephen Soder-land, Matt Broadhead, Oren Etzioni, 2007.
Openinformation extraction from the Web.
IJCAI ?07.Matthew Berland, Eugene Charniak, 1999.
Findingparts in very large corpora.
ACL ?99.Thatsanee Charoenporn, Virach Sornlertlamvanich,Chumpol Mokarat, and Hitoshi Isahara, 2008.Semi-automatic Compilation of Asian WordNet.Proceedings of the 14th NLP-2008, University ofTokyo, Komaba Campus, Japan.Timothy Chklovski, Patrick Pantel, 2004.
VerbOcean:248mining the web for fine-grained semantic verb rela-tions.
EMNLP ?04.Dmitry Davidov, Ari Rappoport, 2006.
Effi-cient unsupervised discovery of word categories us-ing symmetric patterns and high frequency words.COLING-ACL ?06.Dmitry Davidov, Ari Rappoport and Moshe Koppel,2007.
Fully Unsupervised Discovery of Concept-Specific Relationships by Web Mining.
ACL ?07.Dmitry Davidov, Ari Rappoport.
2008a.
Unsuper-vised Discovery of Generic Relationships UsingPattern Clusters and its Evaluation by AutomaticallyGenerated SAT Analogy Questions.
ACL ?08.Dmitry Davidov and Ari Rappoport, 2008b.
Classifi-cation of relationships between nominals using pat-tern clusters.
ACL ?08.Dmitry Davidov and Ari Rappoport, 2009.
Transla-tion and Extension of Concepts Across Languages.EACL ?09.Roxana Girju, Adriana Badulescu, and Dan Moldovan,2006.
Automatic discovery of part-whole relations.Computational Linguistics, 32(1).Roxana Girju, Marthy Hearst, Preslav Nakov, ViviNastase, Stan Szpakowicz, Peter Turney and Yuret,D., 2007.
Task 04: Classification of semantic re-lations between nominal at SemEval 2007.
4th Intl.Workshop on Semantic Evaluations (SemEval ?07),in ACL ?07.Hany Hassan, Ahmed Hassan and Ossama Emam,2006.
Unsupervised information extraction ap-proach using graph mutual reinforcement.
EMNLP?06.Jagadeesh Jagarlamudi, A Kumaran, 2007 Cross-Lingual Information Retrieval System for IndianLanguages Working Notes for the CLEF 2007Workshop.Philipp Koehn and Kevin Knight.
2001.
Knowledgesources for word-level translation models.
EMNLP?01.Dan Moldovan, Adriana Badulescu, Marta Tatu,Daniel Antohe, and Roxana Girju, 2004.
Mod-els for the semantic classification of noun phrases.HLT-NAACL ?04 Workshop on Computational Lexi-cal Semantics.Vivi Nastase, Stan Szpakowicz, 2003.
Exploringnoun-modifier semantic relations.
In Fifth Intl.Workshop on Computational Semantics (IWCS-5).Patrick Pantel, Deepak Ravichandran, Eduard Hovy,2004.
Towards terascale knowledge acquisition.COLING ?04.Marius Pasca, Dekang Lin, Jeffrey Bigham, AndreiLifchits, Alpa Jain, 2006.
Names and similari-ties on the web: fact extraction in the fast lane.COLING-ACL 06.Adam Pease, Christiane Fellbaum, Piek Vossen, 2008.Building the Global WordNet Grid.
CIL18.Benjamin Rosenfeld , Ronen Feldman, 2007.
Cluster-ing for unsupervised relation identification.
CIKM?07.Rion Snow, Daniel Jurafsky, Andrew Ng, 2006.
Se-mantic taxonomy induction from heterogeneous ev-idence.
COLING-ACL ?06.Peter Turney, 2005.
Measuring semantic similarity bylatent relational analysis, IJCAI ?05.Peter Turney, 2006.
Expressing implicit semantic re-lations without supervision.
COLING-ACL ?06.Martin Volk, Paul Buitelaar, 2002 A Systematic Eval-uation of Concept-Based Cross-Language Informa-tion Retrieval in the Medical Domain.
In: Proc.
of3rd Dutch-Belgian Information Retrieval Workshop.Leuven.Dominic Widdows, Beate Dorow, 2002.
A graphmodel for unsupervised Lexical acquisition.
COL-ING ?02.249
