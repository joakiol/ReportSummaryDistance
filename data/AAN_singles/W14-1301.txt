Proceedings of the 5th Workshop on Language Analysis for Social Media (LASM) @ EACL 2014, pages 1?7,Gothenburg, Sweden, April 26-30 2014.c?2014 Association for Computational LinguisticsMining Lexical Variants from Microblogs: An Unsupervised MultilingualApproachAlejandro MosqueraUniversity of AlicanteSan Vicente del Raspeig s/n - 03690Alicante, Spainamosquera@dlsi.ua.esPaloma MoredaUniversity of AlicanteSan Vicente del Raspeig s/n - 03690Alicante, Spainmoreda@dlsi.ua.esAbstractUser-generated content has become a re-current resource for NLP tools and ap-plications, hence many efforts have beenmade lately in order to handle the noisepresent in short social media texts.
Theuse of normalisation techniques has beenproven useful for identifying and replac-ing lexical variants on some of the mostinformal genres such as microblogs.
Butannotated data is needed in order to trainand evaluate these systems, which usu-ally involves a costly process.
Until now,most of these approaches have been fo-cused on English and they were not takinginto account demographic variables suchas the user location and gender.
In this pa-per we describe the methodology used forautomatically mining a corpus of variantand normalisation pairs from English andSpanish tweets.1 IntroductionUser-generated content (UGC), and specially themicroblog genre, has become an interesting re-source for Natural Language Processing (NLP)tools and applications.
Many are the advantagesof exploiting this real-time stream of multilingualtextual data.
Popular applications such as Twit-ter has an heterogeneous user base of almost 600million users that generate more than 60 millionnew tweets every day.
For this reason, Twitterhas become one of the most used sources of tex-tual data for NLP with several applications suchas sentiment analysis (Tumasjan et al., 2010) orrealtime event detection (Sakaki et al., 2010).
Re-cent advances on machine translation or informa-tion retrieval systems have been also making anextensive use of UGC for both training and evalu-ation purposes.
However, tweets can be very noisyand sometimes hard to understand for both hu-mans (Mosquera et al., 2012) and NLP applica-tions (Wang and Ng, 2013), so an additional pre-processing step is usually required.There have been different perceptions regard-ing the lexical quality of social media (Rello andBaeza-Yates, 2012) (Baldwin et al., 2013) andeven others suggested that 40% of the messagesof Twitter were ?pointless babble?
(PearAnalyt-ics, 2009).
Most of the out of vocabulary (OOV)words present in social media texts can be cata-logued as lexical variants (e.g.
?See u 2moro?
?
?See you tomorrow?
), that are words lexically re-lated with their canonic form.The use of text normalisation techniques hasbeen proven useful in order to clean short and in-formal texts such as tweets.
However, the eval-uation of these systems requires annotated data,which usually involves costly human annotations.There are previous works about automatically con-structing normalisation dictionaries, but until now,most of these approaches have been focused onEnglish and they were not taking into account de-mographic variants.
In this paper we describe themethodology used for automatically mining lexi-cal variants from English and Spanish tweets as-sociated to a set of headwords.
These formal andinformal pairs can be later used to train and eval-uate existing social media text normalisation sys-tems.
Additional metadata from Twitter such asgeographic location and user gender is also col-lected, opening the possibility to model and anal-yse gender or location-specific variants.This paper is organised as follows.
We describethe related work in Section 2.
We then describeour variant mining methodology in Section 3.
Theobtained results are presented in Section 4.
Sec-tion 5, draws the conclusions and future work.12 Related WorkOne way to handle the performance drop of NLPtools on user-generated content (Foster et al.,2011) is to re-train existing models on these in-formal genres (Gimpel et al., 2011), (Liu et al.,2011b).
Another approaches make use of pre-processing techniques such as text normalisationin order to minimise the social media textual noise(Han et al., 2013), (Mosquera and Moreda, 2012)where OOV words were first identified and thensubstituted using lexical and phonetic edit dis-tances.
In order to enhance both precision andrecall both OOV detection and translation dic-tionaries were used.
Moreover, the creative na-ture of informal writing and the low availabilityof manually-annotated corpora can make the im-provement and evaluation of these systems chal-lenging.Motivated by the lack of annotated data and thelarge amount of OOV words contained in Twitter,several approaches for automatically construct-ing a lexical normalisation dictionary were pro-posed; In (Gouws et al., 2011) a normalisationlexicon is generated based on distributional andstring similarity (Lodhi et al., 2002) from Twit-ter.
Using a similar technique, a wider-coveragedictionary is constructed in (Han et al., 2012)based on contextually-similar (OOV, IV) pairs.More recently, (Hassan and Menezes, 2013) intro-duced another context-based approach using ran-dom walks on a contextual similarity graph.Distributional-based methods can have somedrawbacks: they rely heavily on pairwise com-parisons that make them computationally expen-sive, and as the normalisation candidates are se-lected based on context similarity they can be sen-sitive to domain-specific variants that share similarcontexts.
Moreover, these approaches were focus-ing on extracting English lexical variants from so-cial media texts, but due the heterogeneity of itsusers, lexical distributions can be influenced bygeographical factors (Eisenstein et al., 2010) oreven gender (Thomson and Murachver, 2001).To the best of our knowledge, there are notmultilingual approaches for mining lexical vari-ants from short, noisy texts that also take into ac-count demographic variables.
For this reason, wepresent an unsupervised method for mining En-glish and Spanish lexical variants from Twitter thatcollects demographic and contextual information.These obtained pairs can be later used for trainingand evaluating text normalisation and inverse textnormalisation systems.3 Lexical Variant MiningLexical variants are typically formed from theirstandard forms through regular processes (Thur-low and Brown, 2003) and these can be mod-elled by using a set of basic character transfor-mation rules such as letter insertion, deletion orsubstitution (Liu et al., 2011a) e.g.
(?tmrrw?
??2morrow?)
and combination of these (?2moro?
).The relation between formal and informal pairs isnot always 1-to-1, two different formal words canshare the same lexical variant (?t?
in Spanish canrepresent ?te?
or ?t?u?)
and one formal word canhave many different variants (e.g.
?see you?
uscommonly shortened as ?c ya?
or ?see u?).
Asa difference with previous approaches based oncontextual and distributional similarity, we havechosen to model the generation of variant candi-dates from a set of headwords using transforma-tion rules.
These candidates are later validatedbased on their presence on a popular microblogservice, used in this case as a high-coverage cor-pus.3.1 Candidate GenerationWe have defined a set of 6 basic transforma-tion rules (see Table 1) in order to automati-cally generate candidate lexical variants from the300k most frequent words of Web 1T 5-gram (En-glish) (Brants and Franz, 2006) and SUBTLEX-SP (Spanish) (Cuetos et al., 2011) corpora.Rule Examplea) Character duplication ?goal??
?gooal?b) Number transliteration ?cansados??
?cansa2?c) Character deletion ?tomorrow??
?tomrrw?d) Character replacement ?friend??
?freend?e) Character transposition ?maybe??
?mabye?f) Phonetic substitution ?coche??
?coxe?g) Combination of above ?coche??
?coxeee?Table 1: Transformation rules.As modelling some variants may need morethan one basic operation, and lexically-relatedvariants are usually in an edit distance t wheret <= 3 (Han et al., 2013), the aforementionedrules were implemented using an engine based onstacked transducers with the possibility to apply amaximum of three concurrent transformations:(a) Character duplication: For words with ncharacters, while n>19 each character were2duplicated n times (?
n>0, n<4), generatingn3candidate variants.
(b) Number transliteration: Words and num-bers are transliterated following the languagerules defined in Table 2.Rule Lang.?uno??
?1?
SP?dos??
?2?
SP?one??
?1?
EN?two??
?2?
EN?to??
?2?
EN?three??
?3?
EN?for??
?4?
EN?four??
?4?
EN?eight??
?8?
EN?be??
?b?
EN?a??
?4?
EN?e??
?3?
EN?o??
?0?
EN?s??
?5?
EN?g??
?6?
EN?t??
?7?
EN?l??
?1?
ENTable 2: Transliteration table for English andSpanish.
(c) Character deletion: The candidate variantsfrom all possible one character deletion com-binations plus the consonant skeleton of theword will be generated.
(d) Character replacement: Candidate variantsare generated by replacing n characters (?n>0, n<7) by their neighbours taking intoaccount a QWERTY keyboard and an editdistance of 1.
(e) Character transposition: In order to generatecandidate lexical variants the position of ad-jacent characters are exchanged.
(f) Phonetic substitution: A maximum of threecharacter n-grams are substituted for char-acters that sound similar following differentrules for Spanish (Table 3) and English (Ta-ble 4).3.2 Candidate SelectionWe have explored several approaches for filteringcommon typographical errors and misspellings, asthese are unintentional and can not be technicallyconsidered lexical variants, in order to do thiswe have used supervised machine learning tech-niques.
Also, with aim to filter uncommon orRule?b??[?v?
or ?w?]?c??[?k?]?s??[?z?]?z??[?s?]?c??[?s?]?x??[?s?]??n??[?ni?]?ch??[?x?]?gu??[?w?]?qu??[?k?]?ll??[?y?]?ge??[?je?]?gi??[?ji?]?ll??[?i?]?hue??[?we?
]Table 3: Phonetic substitution table for Spanish.low quality variants, the Rovereto Twitter corpus(Herdagdelen, 2013) was initially used in orderto rank the English candidates present in the cor-pus by their frequencies.
The 38% of the variantsgenerated by one transformation were successfullyfound, however, performing direct Twitter searchAPI queries resulted to have better coverage thanusing a static corpus (90% for English variants).3.2.1 Intentionality FilteringGiven an OOV word a and its IV version b we haveextracted character transformation rules from a tob using the longest common substring (LCS) algo-rithm (See Table 5).
These lists of transformationswere encoded as a numeric array where the num-ber each transformation counts were stored.
Wehave used NLTK (Bird, 2006) and the Sequence-Matcher Python class in order to extract those setsof transformations taking into account also the po-sition of the character (beginning, middle or at theend of the word).A two-class SVM (Vapnik, 1995) model hasben trained using a linear kernel with a corpuscomposed by 4200 formal-variant pairs extractedfrom Twitter1, SMS2and a corpus of the 4200most common misspellings3.
In table 6 we showthe k-fold cross-validation results (k=10) of themodel, obtaining a 87% F1.
This model has beenused in order to filter the English candidate vari-ants classified as not-intentional.To the best of our knowledge there are not simi-lar annotated resources for Spanish, so this clas-sifier was developed only for English variants.However, would be possible to adapt it to work for1http : //ww2.cs.mu.oz.au/ hanb/emnlp.tgz2http : //www.cel.iitkgp.ernet.in/ monojit/sms3http : //aspell.net/test/common?
all/3Rule?i??[?e?]?o??[?a?]?u??[?o?]?s??[?z?]?f??[?ph?]?j??[?ge?
or ?g?]?n??[?kn?
or ?gn?]?r??[?wr?]?z??[?se?
or ?s?]?ea??[?e?]?ex??[?x?]?ae??[?ay?
or ?ai?
or ?a?]?ee??[?ea?
or ?ie?
or ?e?]?ie??[?igh?
or ?y?
or ?i?]?oe??[?oa?
or ?ow?
or ?o?]?oo??[?ou?
or ?u?]?ar??[?a?]?ur??[?ir?
or ?er?
or ?ear?
or ?or?]?or??[?oor?
or ?ar?]?au??[?aw?
or ?a?]?er??[?e?]?ow??[?ou?]?oi??[?oy?]?sh??[?ss?
or ?ch?]?ex??[?x?]?sh??[?ss?
or ?ch?]?ng??[?n?]?air??[?ear?
or ?are?]?ear??[?eer?
or ?ere?
]Table 4: Phonetic substitution table for English.another languages if the adequate corpora is pro-vided.
Because of the lack of this intentionalitydetection step, the number of generated candidatevariants for Spanish was filtered by taking into ac-count the number of transformations, removing allthe variants generated by more than two opera-tions.3.2.2 Twitter SearchThe variants filtered during the previous step weresearched on the real time Twitter stream for a pe-riod of two months by processing more than 7.5million tweets.
Their absolute frequencies n wereused as a weighting factor in order to discard notused words (n > 0).
Additionally, variants presentin another languages rather than English or Span-ish were ignored by using the language identifica-tion tags present in Twitter metadata.There were important differences between thefinal number of selected candidates for Spanish,with 6 times less variant pairs and English (see Ta-ble 7).
Spanish language uses diacritics that arecommonly ignored on informal writing, for thisreason there is a higher number of possible com-binations for candidate words that would not gen-erate valid or used lexical variants.Formal/Informal pair Transf.
Pos.house ?
h0use o ?
0 middlecampaign ?
campaing n ?
?
end?
?
n middlehappy ?
:) happy ?
:) middleembarrass ?
embarass r?
?
middleacquaintance ?
??
q middleaqcuaintance q ?
?
middlevirtually ?
virtualy l?
?
middlecats ?
catz s?
z endTable 5: Example of formal/informal pairs and theextract transformations.Method Precision Recall F1SVM 0.831 0.824 0.827SVM+Pos.
0.878 0.874 0.876Formal/Informal pair Verdictyou ?
yu intentionalaccommodate ?
acommodate unintentionalbusiness ?
bussiness unintentionaldoing ?
doin intentionalacquaintance ?
aqcuaintance unintentionalbasically ?
basicly unintentionalrules ?
rulez intentionalTable 6: Cross-validation results of intentionalityclassification with examples.4 ResultsBesides the original message and the context ofthe searched variant, additional metadata has beencollected from each tweet such as the gender andthe location of the user.
In Twitter the gender is notexplicitly available, for this reason we applied anheuristic approach based on the first name as it isreported in the user profile.
In order to do this, twolist of male and female names were used: the 1990US census data4and popular baby names fromthe US Social Security Administration?s statisticsbetween 1960 and 20105.We have analysed the gender and language dis-tribution of the 6 transformation rules across themined pairs (see Figure 1).
On the one hand, lex-ical variants generated by duplicating characterswere the most popular specially between female4census.gov/genealogy/www/data/1990surnames5ssa.gov/cgi?
bin/popularnames.cgi4Candidates Selected Lang.2456627 48550 EN1374078 8647 SPTable 7: Number of generated and selected vari-ants after Twitter search.Figure 1: Transformation trends by gender.users with a 5% more than their male counter-parts.
On the other hand, variants generated bycharacter replacement and deletion were found a2% more on tweets from male users.
The differ-ences between English and Spanish were notable,mostly regarding the use of transliterations, thatwere not found on Spanish tweets, and phoneticsubstitutions, ten times less frequent than in En-glish tweets.For the distribution of transformations acrossgeographic areas, we have just taken into accountthe countries where the analysed languages havean official status.
Lexical variants found in Tweetsfrom another areas are grouped into the ?Non-official?
label (see Figure 2).
The biggest dif-ferences were found on the use of translitera-tions (higher in UK and Ireland with more thana 5%) and phonetic substitutions (higher in Pak-istani users with more than a 22%).
Transforma-tion frequencies from non-official English speak-ing countries were very similar as the ones regis-tered for users based on United States and Canada.Spanish results were less uniform and showedmore variance respect the use of character dupli-cation (57% in Argentina), character replacement(more than 24% in Mexico and Guatemala) andcharacter transposition (with more than a 19% forusers from Cuba, Colombia and Mexico) (see Fig-ure 3).5 Conclusions and Future WorkIn this paper we have described a multilingualand unsupervised method for mining English andSpanish lexical variants from Twitter with aim toclose the gap regarding the lack of annotated cor-pora.
These obtained pairs can be later used forthe training and evaluation of text normalisationsystems without the need of costly human anno-tations.
Furthermore, the gathered demographicand contextual information can be used in order tomodel and generate variants similar to those thatcan be found on specific geographic areas.
Thishas interesting applications in the field of inversetext normalisation, that are left to a future work.We also intend to explore the benefits of featureengineering for the detection and categorisationof lexical variants using machine learning tech-niques.AcknowledgmentsThis research is partially funded by the Eu-ropean Commission under the Seventh (FP7 -2007- 2013) Framework Programme for Re-search and Technological Development throughthe FIRST project (FP7-287607).
This pub-lication reflects the views only of the author,and the Commission cannot be held responsi-ble for any use which may be made of the in-formation contained therein.
Moreover, it hasbeen partially funded by the Spanish Govern-ment through the project ?An?alisis de Tenden-cias Mediante T?ecnicas de Opini?on Sem?antica?
(TIN2012-38536-C03-03) and ?T?ecnicas de De-construcci?on en la Tecnolog?
?as del Lenguaje Hu-mano?
(TIN2012-31224).ReferencesTimothy Baldwin, Paul Cook, Marco Lui, AndrewMacKinlay, and Li Wang.
2013.
How noisy socialmedia text, how diffrnt social media sources.
In Pro-ceedings of the Sixth International Joint Conferenceon Natural Language Processing, pages 356?364.Steven Bird.
2006.
Nltk: the natural languagetoolkit.
In Proceedings of the COLING/ACL on In-teractive presentation sessions, COLING-ACL ?06,pages 69?72, Stroudsburg, PA, USA.
Associationfor Computational Linguistics.Thorsten Brants and Alex Franz.
2006.
Web 1T 5-gram corpus version 1.
Technical report, GoogleResearch.5Figure 2: Transformation trends by English-speaking countries.Figure 3: Transformation trends by Spanish-speaking countries.Fernando Cuetos, Maria Glez-Nosti, Anala Barbn, andMarc Brysbaert.
2011.
Subtlex-esp: Spanish wordfrequencies based on film subtitles.
Psicolgica,32(2).Jacob Eisenstein, Brendan O?Connor, Noah A. Smith,and Eric P. Xing.
2010.
A latent variable modelfor geographic lexical variation.
In Proceedings ofthe 2010 Conference on Empirical Methods in Natu-ral Language Processing, EMNLP ?10, pages 1277?1287, Stroudsburg, PA, USA.
Association for Com-putational Linguistics.Jennifer Foster,?Ozlem C?etinoglu, Joachim Wagner,Joseph Le Roux, Stephen Hogan, Joakim Nivre,Deirdre Hogan, and Josef van Genabith.
2011.#hardtoparse: Pos tagging and parsing the twitter-verse.
In Analyzing Microtext, volume WS-11-05 ofAAAI Workshops.
AAAI.Kevin Gimpel, Nathan Schneider, Brendan O?Connor,Dipanjan Das, Daniel Mills, Jacob Eisenstein,Michael Heilman, Dani Yogatama, Jeffrey Flanigan,and Noah A. Smith.
2011.
Part-of-speech taggingfor twitter: annotation, features, and experiments.In Proceedings of the 49th Annual Meeting of theAssociation for Computational Linguistics: HumanLanguage Technologies: short papers - Volume 2,HLT ?11, pages 42?47, Stroudsburg, PA, USA.
As-sociation for Computational Linguistics.S.
Gouws, D. Hovy, and D. Metzler.
2011.
Unsuper-vised mining of lexical variants from noisy text.
InProceedings of the First workshop on UnsupervisedLearning in NLP, page 82?90.Bo Han, Paul Cook, and Timothy Baldwin.
2012.
Au-tomatically constructing a normalisation dictionaryfor microblogs.
In Proceedings of the 2012 JointConference on Empirical Methods in Natural Lan-guage Processing and Computational Natural Lan-guage Learning (EMNLP-CoNLL 2012), pages 421?432, Jeju Island, Korea.Bo Han, Paul Cook, and Timothy Baldwin.
2013.
Lex-ical normalization for social media text.
ACM Trans.Intell.
Syst.
Technol., 4(1):5:1?5:27, February.Hany Hassan and Arul Menezes.
2013.
Social textnormalization using contextual graph random walks.In Proceedings of the 51st Annual Meeting of theAssociation for Computational Linguistics (Volume1: Long Papers), pages 1577?1586, Sofia, Bulgaria,August.
Association for Computational Linguistics.Ama Herdagdelen.
2013.
Twitter n-gram corpus withdemographic metadata.
Language Resources andEvaluation, 47(4):1127?1147.Fei Liu, Fuliang Weng, Bingqing Wang, and Yang Liu.2011a.
Insertion, deletion, or substitution?
: Nor-malizing text messages without pre-categorization6nor supervision.
In Proceedings of the 49th AnnualMeeting of the Association for Computational Lin-guistics: Human Language Technologies: Short Pa-pers - Volume 2, HLT ?11, pages 71?76, Strouds-burg, PA, USA.
Association for Computational Lin-guistics.Xiaohua Liu, Shaodian Zhang, Furu Wei, and MingZhou.
2011b.
Recognizing named entities in tweets.In Proceedings of the 49th Annual Meeting of theAssociation for Computational Linguistics: HumanLanguage Technologies - Volume 1, HLT ?11, pages359?367, Stroudsburg, PA, USA.
Association forComputational Linguistics.Huma Lodhi, Craig Saunders, John Shawe-Taylor,Nello Cristianini, and Chris Watkins.
2002.
Textclassification using string kernels.
J. Mach.
Learn.Res., 2:419?444, March.Alejandro Mosquera and Paloma Moreda.
2012.Tenor: A lexical normalisation tool for spanish web2.0 texts.
In Text, Speech and Dialogue - 15th Inter-national Conference (TSD 2012).
Springer.Alejandro Mosquera, Elena Lloret, and PalomaMoreda.
2012.
Towards facilitating the accessibil-ity of web 2.0 texts through text normalisation.
InProceedings of the LREC workshop: Natural Lan-guage Processing for Improving Textual Accessibil-ity (NLP4ITA) ; Istanbul, Turkey., pages 9?14.PearAnalytics.
2009.
Twitter study.
In Retrieved De-cember 15, 2009 from http://pearanalytics.com/wp-content/uploads/2009/08/Twitter-Study-August-2009.pdf.Luz Rello and Ricardo A Baeza-Yates.
2012.
Socialmedia is not that bad!
the lexical quality of socialmedia.
In ICWSM.Takeshi Sakaki, Makoto Okazaki, and Yutaka Matsuo.2010.
Earthquake shakes twitter users: Real-timeevent detection by social sensors.
In Proceedingsof the 19th International Conference on World WideWeb, WWW ?10, pages 851?860, New York, NY,USA.
ACM.Robert Thomson and Tamar Murachver.
2001.
Pre-dicting gender from electronic discourse.Thurlow and Brown.
2003.
Generation txt?
the soci-olinguistics of young people?s text-messaging.A.
Tumasjan, T.O.
Sprenger, P.G.
Sandner, and I.M.Welpe.
2010.
Predicting elections with twitter:What 140 characters reveal about political senti-ment.
In Proceedings of the Fourth InternationalAAAI Conference on Weblogs and Social Media,pages 178?185.Vladimir N. Vapnik.
1995.
The nature of statisticallearning theory.
Springer-Verlag New York, Inc.,New York, NY, USA.Pidong Wang and Hwee Tou Ng.
2013.
A beam-searchdecoder for normalization of social media text withapplication to machine translation.
In HLT-NAACL,pages 471?481.7
