Computing with Features as FormulaeMark Johnson*Brown UniversityThis paper extends the approach to feature structures developed in Johnson (1991a), which usesSchO'nfinkel-Bernays' formulae to express feature structure constraints.
These are shown to be adisjunctive generalization of Datalog clauses, as used in database theory.
This paper provides afixed-point characterization f the minimal models of these formulae that serves as the theoreticalfoundation of a forward-chaining algorithm for determining their satisfiability.
This algorithm,which generalizes the standard attribute-value unification algorithm, is also recognizable as anondeterministic variant of the semi-naive bottom-up algorithm for evaluating Datalog programs,further strengthening the connection between the theory of feature structures and databases.1.
IntroductionDespite their simplicity, a surprisingly wide range of linguistic phenomena can be de-scribed in terms of simple equality constraints on values in attribute-value structures,which are a particularly simple kind of feature structure (see Shieber 1986; Johnson1988; Uszkoreit 1986; and Bresnan 1982 for examples of some of these analyses).
Butsome phenomena do not seem to be able to be described in such a pure 'unification'framework.
For example, the analysis of conjunctions in LFG (Kaplan and Maxwell1988b) and the formalizations of Discourse Representation Theory (Kamp 1981) pre-sented in Johnson and Klein (1986) and Johnson and Kay (1990) require additionalmechanisms for representing and manipulating aggregates or sets of values in waysthat are beyond the capability of such "pure" attribute-value systems.
Further, sortalconstraints (which also cannot be expressed as simple equality constraints) can be usedto formulate simpler and more comprehensible grammars (Carpenter 1992; Carpenterand Pollard 1991; Pollard and Sag 1987, 1992).Versions of both of these kinds of constraint, as well as the familiar attribute-valueconstraints, can be expressed as Scho'nfinkel-Bernays'formulae (as demonstrated in John-son 1991a, 1991b), so that the problem of determining the satisfiability of a system ofsuch constraints i reduced to the satisfiability problem for the corresponding formula.This class of formulae (defined in Section 3.1) seems to be expressive nough for mostlinguistic purposes when used with an external phrase-structure backbone.
That is,these formulae are used as annotations on phrase structure rules in the manner de-scribed in, e.g., Kaplan and Bresnan (1982), Shieber (1986), and Johnson (1988).
Thispaper extends the author's previous paper on the topic (Johnson 1991a) by sketch-ing several other linguistic applications of Sch6nfinkel-Bernays' formulae (including aversion of D-theory \[Marcus, Hindle, and Fleck 1983; Vijay-Shanker 1992\]), and pre-senting a least-fixed-point theorem that serves as the theoretical basis for a "forward-chaining" algorithm for determining satisfiability of Sch6nfinkel-Bernays' formulae.Interestingly, this algorithm can be viewed both as a straightforward generalization* Cognitive and Linguistic Sciences, Box 1978, Brown University, Providence, RI.
E-mail:Mark_Johnson@brown.eduQ 1994 Association for Computational LinguisticsComputational Linguistics Volume 20, Number 1of the standard attribute-value nification algorithm and also as a nondeterministicvariant of the semi-naive valuation method for Datalog clauses.Several extended "unification-based" constraint formalisms have been developed.In this paper, the term "feature structure" denotes any kind of structured entity used asa component of a category label.
An attribute-value structure is a particularly simplekind of feature structure of the kind used in "pure" unification-based frameworks(Shieber 1986).
Some extensions tothe basic attribute-value framework are rather weak,e.g., allowing disjunctive and negative constraints and preserving decidability.
1 Suchsystems require an "off-line" phrase structure backbone to which these constraints areattached.
It seems that most of the constraints hat can be expressed in these formalismscan be expressed as Sch6nfinkel-Bernays' formulae, the constraint formalism describedbelow.A second class of extended constraint formalisms has been devised to be capableof expressing the entire grammar as systems of constraints and as far as I know, for allof these systems the problem of determining the satisfiabihty of an arbitrary systemof constraints that they can express is undecidable.
2 This is because the recognitionproblem for an arbitrary "unification-based" grammar is undecidable unless the sizeof the phrase structure tree is constrained somehow, e.g., by the offiine parsabilityconstraint (Johnson 1988; Kaplan and Bresnan 1982; Pereira 1982; Shieber 1992), butthere seems to be no natural way to impose such constraints in these systems becausethe encoding of the phrase structure tree in the feature structure is not distinguishedfrom other features.
3 Thus in order to maintain decidability the system describedhere is not designed to be capable of expressing phrase structure constraints directly,and must be used with an external phrase-structure component, as in LFG (Bresnan1982).
(However, Bob Carpenter \[p.c.\] points out that one can impose a bound on thesize of the feature structure that can serve as an analysis \[say, some polynomial ofthe length of the input\], and so ensure decidability.)
Interestingly, a first-order logic-based approach similar to the one presented in this paper can also be developed forextended constraint formalisms capable of expressing the entire grammar, but this isnot discussed further here; see Johnson (in press b) for details.In the approach developed here Sch6nfinkel-Bernays' formulae are used to expressa variety of feature structure constraints.
Previous work has shown that these formulaeare expressive nough to define arbitrary disjunctions and negations of constraints(Johnson 1990a, 1990b), a kind of 'set-valued' entity (Johnson 1991a), and they can beused to impose useful sort constraints (Johnson 1991b).
The expression of D-theoryconstraints on nodes in trees is discussed in this paper.This paper extends the ideas in these earlier papers with theoretical results thatsuggest a forward-chaining algorithm for determining the satisfiability of an arbi-trary Sch6nfinkel-Bernays' formula.
This generalizes the standard feature-graph uni-fication algorithm and is closely related to the semi-naive bottom-up algorithm usedin database theory.1 For examples of this approach see Dawar and Vijay-Shanker (1990), D6rre and Eisele (1990), Johnson(1988, 1990a, 1990b, 1991a, 1991b, in press a), Karttunen (1984), Kasper (1987a, 1987b, 1988), Kasper andRounds (1986, 1990), Langholm (1989), Pereira (1987), and Smolka (1992).2 Examples of this approach are Carpenter, Pollard, and Franz (1991), D6rre (1991), D6rre and Eisele(1991), Johnson (in press b), Kay (1979, 1985a, 1985b), Pollard and Sag (1987), Rounds andManaster-Ramer (1987), Smolka (1988), and Zajac (1992).3 While it may well be that the universal recognition and parsing problems for natural anguage areundecidable (Chomsky \[1986, 1988\] points out that there is no contrary evidence), I know of noevidence that this is actually the case.
It seems reasonable then to also investigate formalisms that canonly express decidable systems of constraints (and for which there exist satisfiability-testing al orithms)if linguistically adequate systems can be found.2Mark Johnson Computing with Features as FormulaeSpecifically, it is shown that the satisfying Herbrand models of an arbitrary Sch6n-finkel-Bernays' formula are the fix points of certain functions, and that the least fixedpoints of these functions are all of the models of the formula that are "minimal" ina certain sense.
This leads to a forward-chaining algorithm for computing all of theatomic consequences of a Sch6nfinkel-Bernays' formula; the fixed-point theorem showsthat this suffices to determine the satisfiability of an arbitrary Sch6nfinkel-Bernays'formula.2.
Constraints, Partial Information, and Feature StructuresThis approach exploits the fact that constraints on well-formed linguistic structures(e.g., well-formedness constraints imposed by the grammar) do not need to be isomor-phic to the structures that satisfy them.
Although the distinction between constraintsand structures that satisfy them might seem too obvious to warrant comment, it is notmade in most work on feature structures.A common view holds that feature structures are inherently "partially specified"entities, which "unify" or merge with other feature structures to yield more instan-tiated feature structures in an "information-preserving" way (Shieber 1986).
If twofeature structures contain "contradictory information," then it is impossible to mergethem to produce a consistent object; unification is then said to fail.
The feature struc-ture for an utterance is the result (if one exists) of unifying all of the feature structuresfor the lexical entries and syntactic rules in appropriate ways.
Thus in this view fea-ture structures play two roles; not only do they serve as linguistic structures, but theyare also used to encode constraints that the linguistic structures must satisfy (see Sec-tion 2.10 of Johnson (1988) for an extended iscussion).That is, under this view feature structures erve not only as linguistic structuresthat may or may not satisfy a constraint, but are also interpreted as 'representing' or'describing' all of the feature structures that they subsume.
Given this dual role forfeature structures, it is important in this approach that if a feature structure S satis-fies a constraint o~, then every feature structure subsumed by S should also satisfy o~(Pereira 1987).
If this "upward closure" property holds, then the set of feature struc-tures satisfying any constraint can be represented by the set of its "minimal models.
"Unfortunately, many useful constraints do not have this property.
For example, un-der a classical interpretation, the set of feature structures atisfying negated featurestructure constraints are not upward-closed (Moshier and Rounds 1987).The work described in this paper pursues a different approach.
Following Kaplanand Bresnan (1982), feature structures are only (components of) linguistic structures,and not partial descriptions of (other) linguistic structures.
As such, a feature struc-ture either does or does not satisfy any particular set of constraints.
An utterance iswell-formed just in case there is some linguistic structure that satisfies all of the con-straints imposed by the grammar and has the phonological form of that utterance asits phonological form (which itself is just another constraint hat the structure mustsatisfy).
Since the relationship between a feature structure and a constraint that it satis-fies is essentially the same as the relationship between an interpretation and a formulathat is true under that interpretation, it seems natural to conceive of a constraint asa kind of formula (in a format that allows efficient computational manipulation) thathas feature structures as its intended interpretations.This approach is more general in that it does not rely on the upward-closureproperty, and it allows constraints on feature structures to have a structure quitedifferent from the feature structures that they constrain.
The subsumption relation onComputational Linguistics Volume 20, Number 1feature structures plays no special role in this approach; specifically, it is not requiredthat the set of structures that satisfy a constraint be upward-closed.In general, a linguistic structure S must satisfy several constraints, say oaT... ~ o~,~,in order to be well formed, so in order to solve the recognition and parsing problems,all we need do is determine if there are any S that satisfy oq~... ~ O~n, and if so, describethem somehow.It is convenient to devise a language for expressing constraints, so that the o~iare well-formed formulae of this language, and its satisfaction relation is exactly thesatisfaction relation mentioned above.
Viewed from this perspective, the problem ofdetermining if there is a structure S that satisfies the constraints o~1~ .
.
.~  O~n is the sameas the problem of determining if the formula c~ is satisfiable, where o~ is Oq A " ' "  /X O~ nand conjunction is given the standard interpretation.
Algorithms for deciding the sat-isfiability of arbitrary formulae in this language (if they exist) can therefore be used todetermine the satisfiability of the linguistic constraints.
Moreover, if o~ ~ c~  then o / i sa true description of every model of c~, i.e., the logical consequences of o~ are descrip-tions of every well-formed linguistic structure that satisfies the constraints.
Thus thelogic of the constraint language provides in principle all the necessary tools for deter-mining if a set of constraints are satisfiable, and if they are, providing descriptions ofthe satisfying structures.From this perspective, an "information state" is a kind of formula, and "unify-ing" two such information states is accomplished by conjoining them and simplifyingthe resulting formula, not by some manipulation of their models.
Partial informationstates are those that are satisfied by more than one interpretation.
The consequencerelation corresponds to the subsumption relation of traditional unification grammar (aformula o~ "contains more information" than formula o/ i f f  o~ ~ a'), and unsatisfiabilitycorresponds to unification failure.3.
Languages for Expressing Feature Structure ConstraintsThere are many different possible constraint languages.
Specialized languages can beconstructed specifically for the task of expressing feature structure constraints (suchas Kasper and Rounds's FDL \[Kasper and Rounds 1990\] and Johnson's attribute-valuelanguages \[Johnson 1988\]).
Alternatively, the constraints may be able to be expressedin some standard language, so that the satisfiability problem for linguistic constraintsis reduced to the satisfiability problem for that language, as is done here.
4Johnson (1990a), following a suggestion first made in Kaplan and Bresnan (1982),showed how attribute-value constraints could be formalized in the quantifier-free sub-set of first-order logic, while later work (Johnson 1991a, 1991b) proposed a differentformalization in the Sch6nfinkel-Bernays' subset of first-order formulae.
5Roughly speaking, there is a trade-off between the expressive power of a languageand its computational tractability.
For example, the satisfiability problem for the lan-guage consisting of conjunctions of equalities and inequalities of first-order terms can4 A third approach, developed by Smolka (1992), is to define a specialized language tailored forexpressing attribute-value constraints and note its translation i to some standard language, in this case,also the Sch6nfinkel-Bernays' class.5 Of course, there is no a priori reason for these subsets of first-order logic to be optimally suited forexpressing feature structure constraints.
Kasper and Rounds (1990) and more recently Blackburn (1991)and Blackburn and Spaan (1992) have suggested that it may be useful to express feature structureconstraints ina special kind of modal ogic.
Johnson (1991b) also discusses the application of generalfirst-order logic and nonmonotic logics to the specification f more complex constraints on featurestructures.4Mark Johnson Computing with Features as Formulaebe decided in quasi-linear time using the congruence-closure algorithm, but this lan-guage can only express conjunctions of feature-value equalities and inequalities.
Ifthis language is extended to allow disjunctions ( o that disjunctive feature-value con-straints can be expressed), the satisfiability problem becomes NP-complete (Gallier1986; Kasper and Rounds 1990; Nelson and Oppen 1980).Since disjunctive constraints seem to be a practical necessity for describing naturallanguages (Barton, Berwick, and Ristad 1987; Karttunen 1984), most practical featurestructure systems will probably have NP-hard satisfiability problems.
Given that wehave to solve an NP-hard problem anyway, it seems reasonable toinvestigate he mostexpressive f ature structure constraint language that has an NP-complete satisfiabilityproblem.
The Sch6nfinkel-Bernays' class, used in the manner described here, appearsto be the most expressive language for feature structure constraints proposed in theliterature so far whose satisfiability problem is no harder than NP.3.1 The SchSnfinkel-Bernays' ClassThe Sch6nfinkel-Bernays' class (hereafter SB) is the class of first-order closed prenexformulae without function symbols in which no existential quantifier occurs in thescope of any universal quantifier.
That is, a formula is in SB iff it has no free variablesand is of the form3Vl  .
.
.
3Vm VX1 .
.
.
VXnOL,where a contains no quantifier symbols or function symbols.
SB formulae are a propersubset of first-order formulae, and they are interpreted in exactly the same way as first-order formulae.
The body a may contain boolean connectives (including negation),which can be used to express arbitrary boolean combinations of constraints.Unlike the satisfiability problem for full first-order logic, which is undecidable(co-recursively enumerable), the satisfiability problem for SB is decidable; in fact it isPSPACE-complete (Lewis and Papadimitriou 1981).
Further, if SBn is the class of SBformulae with n or fewer universal quantifiers, then for any fixed n the satisfiabilityproblem for SBn is NP-complete (Lewis 1980).
In the applications described here, thenumber of universal quantifiers i fixed (i.e., it does not vary with the utterance or evenwith the grammar), so the corresponding satisfiability problems are all NP-complete.The class of SB formulae is interesting for other easons besides its ability to expressa wide range of linguistic constraints.
As shown below, the class of SB formulae inclausal form constitute an extension of Datalog that allows disjunctive consequents.3.2 Formalizing Attribute-Value Structures Using SBSB is both simple and expressive nough that grammar designers might choose tostate linguistic constraints directly in SB, rather than in terms of attributes and val-ues.
Nevertheless, it is important to understand how the properties of attribute-valuestructures can be stated in SB, since many of the techniques used to formalize themcan be applied to other linguistically interesting structures as well.In fact there are several ways of formalizing attribute-value structures in SB, all ofwhich seem to be linguistically equivalent.
What follows is a formalization i SB thatallows values to be used as attributes and allows attributes to be quantified over (thisis handy for stating "sort constraints"), but no special claims are made for it over andabove any other SB formalization.Following Johnson (1991b), attribute-value f ature structures can be specified inSB in the following way.
We can conceptualize of attribute-value arcs as instances ofComputational Linguistics Volume 20, Number 1a three-p lace re lat ion arc, where  arc(x, a~ y) means  that there is an arc leav ing node  xlabe led a po in t ing  to node  y.6Of course,  not  all in terpretat ions  qual i fy  as at t r ibute-va lue structures;  e.g., thosewh ich  satisfy both arc(x~ a~ y) and arc(x~ a~ z) for some y ~ z v io late the requ i rementthat there is at most  one arc w i th  any  g iven label leav ing any  node.
We can expressthis requ i rement  as an SB fo rmula  that is t rue in the in tended interpretat ions  (namelyat t r ibute-va lue  f ature structures).Vx Va Vy Vz arc(x~a~y) Aarc (x ,a ,z )  ~ y = z.
(1)Similarly, we  can express the proper t ies  of the "at t r ibute-va lue  constants"  w i th  SBformulae.
Let con be a proper ty  (i.e., a one-p lace relat ion) true of the "at t r ibute-va lueconstant"  e lements.
These e lements  are requ i red  to have no arcs leav ing them.
Thefo l lowing fo rmula  expresses this requi rement .VxVa Vy ~,, (con(x)Aarc(x~a~y)) .
(2)Note  that the word  "constant"  in the name "at t r ibute-va lue  constant"  is mis lead inghere, s ince in this f ramework  not  all SB constant  symbo ls  wi l l  denote  at t r ibute-va lue"constants."
More  precisely, be ing  an 'a t t r ibute-va lue  constant '  is a p roper ty  of anind iv idua l  in an interpretat ion  (i.e., an e lement  of a feature structure),  whereas  be inga constant  is a proper ty  of a symbo l  in a formula.
Constants  can be used  to denotecomplex  at t r ibute-va lue  entit ies as wel l  as at t r ibute-va lue  constants.Finally, we  require that the names  of a t t r ibute-va lue  constants  denote  d ist incta t t r ibute-va lue  constants.
We reserve a f inite subset  N of the constants  of our  languagefor use as the names  of a t t r ibute-va lue  constants,  and  require that they sat isfy thefo l lowing schemata.
7For  each c in N, con(c).
(3)For  each dist inct  pa i r  Cl, c2 in N, cl ~ C2.
(4)Schema (3) requires each symbol  in N to denote  an at t r ibute-va lue  constant,  andschema (4) enforces d ist inctness in essent ia l ly  the same manner  as that used  in thespeci f icat ion systems of a lgebra ic  data - type  theory  (Kapur  and  Musser  1987).Formulas  (1) and (2) and  the instances of schemata  (3) and  (4) can be regardedas defining att r ibute-va lue  feature structures.
These ax ioms are quite permiss ive:  in6 Johnson (1991a) and Smolka (1992) propose that an attribute-value arc labeled a from x to y beconceptualized as an instance of a two-place relation a(x, y).
For most applications there is littlesubstantive difference between these two approaches; the approach taken here allows attributes to bequantified over, e.g., to state sortal constraints, and permits values to be used as attributes, as in e.g.,LFG (Kaplan and Bresnan 1982); for discussion and linguistic applications see also Johnson (1988).7 As Patrick Blackburn (p.c.)
points out, one consequence of this is that every model of these constraintswill contain individuals corresponding to each attribute-value constant (since each constant symbolwill be assigned a denotation).
Whether this is desirable or problematic is debatable, but as he pointedout, it is easy to devise a conceptualization n which each attribute-value constant ci is conceptualizedas a one-place predicate ci(.)
that is true of at most one element.
Under such a conceptualization(which can be formalized in SB as shown below) attribute-value constants would be the uniquemembers of one-element sorts.
(i) For each c in N, Vx Vy c(x) A c(y) ~ x = y.
(Uniqueness)(ii) For each c in N, Vx c(x) ~ con(x).
(Constant property)(iii) For each distinct pair cl, c2 in N, Vx ~ (cl (x) A c2 (x)).
(Disjointness)Mark Johnson Computing with Features as Formulaearc(n,al,bl) arc(n,al,n') ^ arc(n,a2,n')n nall ax~ a2b!
n'arc(n,a2,b2)nb2Figure 1Three constraints expressed as formulae and also depicted graphically.addition to the usual finite acyclic feature structures, they allow infinite structures,cyclic structures, structures in which complex values serve as attributes, etc.
Whileruled out by fiat in standard treatments, admitting these additional structures causesno linguistic difficulties that I am aware of (in fact, some analyses crucially dependon their existence, as described in section 2.1.3 of Johnson \[1988\]), so in the interestsof parsimony additional constraints that forbid them are not stipulated.In fact, because SB formulae possess the finite model property (i.e., if an SB formulahas a model, then it has a finite model), restricting attention to finite models does notchange the set of satisfiable SB formulae.
Therefore it could have no effect on the set ofwell-formed utterances.
Cyclic feature structures can be prohibited with a constraintformalizable in SB, as described in Johnson (1991b), and one can express a constraintin SB that requires that all attributes are "attribute-value constants" (even though thereappears to be no linguistic motivation for such a constraint, and indeed, some analysescrucially depend on this not being the case, as pointed out in Johnson \[1988\]).To summarize, the simplest SB axioms defining attribute-value structures are quitepermissive, allowing a wider range of structures to count as attribute-value structuresthan many other formalizations.
However, all of the major restrictions on attribute-value structures discussed in the literature ither have no effect whatsoever in thisframework, or else can be directly stated as additional SB constraints.3.3 Expressing Feature Structure Constraints with SBIn this approach, simple attribute-value constraints are represented by quantifier-freeatomic formulae.
For example, a constraint that the value of n's al arc is bl would berepresented by the atom arc(n,al,bl), a constraint that the value of n's a2 arc is b2 isrepresented by arc(n, a2, b2), and a constraint hat the value of n's al arc is the sameas the value of its a2 arc is represented by the conjunction arc(n, all n') A arc(n, a2~ n')(n ~ is the single value of both arcs).
These three constraints are depicted graphically inFigure 1.
Note that the graphs in this figure are (depictions of) formulae, not attribute-value feature structures.Attribute-value "unification" is the conjunction and simplification of the formu-lae expressing the constraints to be unified.
If all three constraints in the example ofFigure 1 are conjoined together with axioms (1-3) above, then by (1) it follows thatbl = n ~ = b2.
Further, if bl and b2 are distinct constant symbols in N (thus they nameattribute-value constants), then bl ~ b2 is an instance of (4), and the conjunction istherefore unsatisfiable.
For further examples and a discussion of how the disjunc-tion and negation of attribute-value constraints are transparently representable as SBformulae, see Johnson (1991a, 1991b).Computational Linguistics Volume 20, Number 1A major motivation for using SB is that a wide variety of constraints, in addi-tion to standard attribute-value constraints, can be expressed using it.
This allows agrammar developer to introduce a wide variety of "designer features" with possiblyidiosyncratic, ustomized properties, while guaranteeing that the composite system isdecidable (usually in NP-time, as noted above).For example, suppose we want to impose sort restrictions of the following kind.To abbreviate the lexical entries of verbs we might introduce the one-place predicate3rd-sg, where 3rd-sg(x) indicates that the value of x's person attribute is 3rd and x'snumber attribute is singular.
This constraint can be expressed using the following SBformula.Vx 3rd-sg(x) ~ arc(x, person, 3rd) A arc(x, number, singular).
(5)Similarly, constraints that restrict he possible values of certain attributes can be im-posed.
For example, one might want to require that the value of every arc labelednumber is either singular or plural.
This constraint can be expressed as the followingSB formula.Vx Vy arc(x, number, y) ~ y = singular V y = plural.
(6)These examples demonstrate only a small fraction of the variety of the feature structureconstraints hat can be expressed in SB.
Even though all of these examples are basedon attribute-value features, other sorts of features can be described in SB as well.
Forexample, Johnson (1991a) shows how to formulate a variety of constraints on 'set-valued' features in SB.3.4 Expressing Tree Structure Constraints with SB FormulaeInspired by the work on description theory or 'D-theory' (Marcus, Hindle, and Fleck1983; Vijay-Shanker 1992), this section shows how some elementary constraints onprecedence and dominance in a tree can be expressed as SB formulae.
It differs fromthat work in that different kinds of constraints are expressible (Vijay-Shanker wasconcerned with the formalization of a different kind of grammar), and that all of theconstraints expressible in the system described below are decidable (this follows fromthe fact that they are defined and expressed using Sch6nfinkel-Bernays' formulae).These constraints are intended to appear as annotations on phrase structure rules (inthe same way that attribute-value constraints do) and could be used to enforce a va-riety of "long-distance" relationships, uch as the co- and contra-indexing constraintsof binding theory (i.e., equality and inequality constraints on the values of index at-tributes).The axiomatization begins by defining the primitive tree structure relations precedesand dominates.
Once these primitive tree structure relations are defined, they can beused to approximate more complex relationships such as c-commands, as describedbelow.
All of these axioms are in the Sch6nfinkel-Bernays' class, so the satisfiability ofarbitrary boolean combinations of such constraints i decidable.First, note that the standard efinition of trees in terms of the binary relations< (linear precedence) and D (domination) can be expressed irectly as Sch6nfinkel-Bernays' formulae.
The axioms presented below are just the definitions of trees givenin Partee, ter Meulen, and Wall (1990) and Wall (1972) using the syntax of first-orderlogic.
Axioms (7a-c) require that < is a strict partial order, and axioms (8a-c) requireMark Johnson Computing with Features as Formulaethat D is a weak partial order over the nodes in a tree.
In what follows, N(x) isinterpreted as meaning that x is a tree node.VX "~X K XVx Vy x < y ~ ~y < xVxVyVzx  < yAy  <z-+x <zVx D(x, x) +-+ N(x)Vx Vy D(x,y) A D(y,x) ~ x = yVx Vy Vz D(x, y) A D(y,z) ~ D(x,z)(irreflexivity) (7a)(asymmetry) (7b)(transitive closure) (7c)(reflexivity) (8a)(antisymmetry) (8b)(transitive closure) (8c)Axiom (9) requires that there is a node that dominates all other nodes, and axiom(10) requires that for each pair of nodes either one precedes the other or one dominatesthe other.
Axiom (11) enforces the "no tangling" constraint.3 x X(x) A Vy X(y) + D(x, y)Vx Vy X(x) A X(y) + ((x < y v y < x)-~(D(x, y) v D(y, x)))Vw Vx Vy Vz w < xA D(w,y) AD(x,z)  ~ y < z(single root condition) (9)(exclusivity) (10)(nontangling condition) (11)Finally, the following axioms (implicit in the standard treatments cited above)require the precedence and dominance relations to range over tree nodes.vx Vy x < y + X(x) A X(y) (12a)Vx Vy D(x, y) -~ N(x) A N(y) (12b)This concludes the specification of linear precedence and dominance relations overnodes.
We now turn to the specification of other relations in terms of these.
The properdominance relation P can be defined in terms of dominance as follows.Vx Vy p(x, y) ~ x # y A D(x, y).
(13)However, many interesting linguistic relations cannot be defined by Sch6nfinkel-Ber-nays' axioms.
For example, the c-commands relation C is defined by the followingformula (which says that x c-commands y iff x does not dominate y, and every nodez that properly dominates x also properly dominates y).Vx vy C(x, y) ~ ~D(x, y) A Vz e(z, x) ~ P(z, y).
(14)It is easy to see that this definition is not equivalent to a Sch6nfinkel-Bernays' for-mula by expanding the equivalence into two implications and moving the embeddedquantifier out.Vx Vy Vz C(x,y) + (-~D(x,y) A (P(z,x) ~ P(z,y))).
(14a)Vx Vy 3z (~D(x, y) A P(z, x) ~ P(z, y) ) ~ C(x, y).
(14b)Formula (14b) is not in SB because it contains an existential quantifier inside the scopeof a universal quantifier.
There are a number of ways to respond to this problem.First, we can abandon the attempt to work within the Sch6nfinkel-Bernays' class,and work with some other language.
Rounds (1988) describes uch a language calledLFP, whose decidability follows from the fact that the domain of quantification isComputational Linguistics Volume 20, Number 1restricted (just as in SB).
However, it seems to be difficult to devise a decidable systemcapable of simultaneously expressing both tree structure and the variety of featurestructure constraints that the SB approach described here can.
Blackburn, Gardent,and Meyer-viol (1993) introduce a modal language LT for describing trees decoratedwith feature structures, whose satisfiability problem is undecidable.
In the long run,such specialized "designer logics" may provide the most satisfying integration of treestructure and feature structure constraints.Second, the 'one-sided' approximation (14a) can be used in place of the correctaxiom (14).
The effect of using such one-sided approximations was investigated inJohnson (1991a).
It was shown there that if ~ is a formula such as the one in (14) and~/is the one-sided approximation (14a), then for any formula ~+(C) in which C onlyappears positively, ~ A ~+ (C) is satisfiable iff ~' A ~+ (C) is satisfiable.
That is, if we areconcerned only with positively occurring constraints, we can simplify (14) to (14a),i.e., ignore (14b), without affecting constraint satisfiability.Third, we can regard formulae such as (14) as the "macro" (15), used to expandconstraints at the interface between the syntactic rules and the constraint solver.
This"macro expansion" rewrites c-commands constraints into boolean combinations of con-straints that the constraint solver can handle.C(x,y) ~ -@(x~y) A vz p(z~x) ~ P(z~y).
(15a)-~C(x~y) ~ D(x~y) v 3z (P(z~x) A -~P(z~y)).
(15b)The second and the third approaches differ in important ways.
In the second ap-proach, c-commands i a relation that is "understood" by the constraint solver (albeitonly in its one-sided form), so it can be used to define other relations.
In the thirdapproach, c-commands constraints are not primitive constraints, o relations defined interms of c-commands must also be expressible in terms of "macro expansion."
In thesecond approach, constraints are quantifier-free formulae (quantifiers appear only inthe axioms), so the satisfiability problem is in NP.
But in the third approach, macroexpansion produces formulae that contain additional quantifiers, so the satisfiabilityproblem may be PSPACE-complete.3.5 Limitat ions on Constraints Expressible wi th  SB FormulaeOf course, SB is not as expressive as full first-order logic.
It is incapable of expressingfunctional relationships, ince these require an existential quantifier inside the scope ofa universal quantifier.
This means, among other things, that it is impossible to state aconstraint in SB requiring that a certain node must exist (as was noted in the discussionof c-command in the previous ection) or that all nodes possess certain attributes.
Thusfor example, the following constraint, which requires that every tensed entity possessnumber and person attributes, is a first-order formula that is not in SB, since it requiresa functional relationship between entities with tense attributes and the values of theirnumber and person attributes.Vx Vy arc(x~ tensG y) ~ (3z arc(x~ number~ z)) A (3z arc(x~ person~ z)) (16)Similarly, a number of other extensions to the basic attribute-value framework dis-cussed in the literature cannot be formalized in SB.
Subsumption constraints, used inthe treatment of (natural anguage) conjunction, are not expressible as SB formulaebecause the satisfiability problem for conjunctions of subsumption and attribute-valueconstraints is undecidable (D6rre and Rounds 1992).
Positively occurring functional10Mark Johnson Computing with Features as Formulae(El) Vxx=x.
(E2) VxVyx=y~y=x.
(E3) Vx0.
.
.
VXn xj = x 0 A P (X l~.
.
.
~ xj~...~ xn) ~ P(Xl~...~ Xo~...~ Xn)for j = 1~...~ n, for every predicate symbol P appearing in ~.
(E4) VXo...VXn xj =x0 --~ f(xl~...~Xj~...~Xn) =f(Xl~...~Xo~...~Xn)for j = 1~...~ n, for every function symbol f appearing in ~.Figure 2Equality axiom schemata for a first-order formula ~.uncertainty constraints, used in the LFG treatment of long-distance dependencies (Kap-lan and Zaenen 1989) appear to have a decidable satisfiability problem (Kaplan andMaxwell 1988a), but the satisfiability problem for arbitrary boolean combinations offunctional uncertainty constraints i undecidable (Keller 1991), so these cannot be ex-pressed using SB formulae either (since the quantifier-free subclass of SB is closedunder boolean operations).3.6 The Equality RelationIn this paper the intended interpretation f the equality relation is identity; i.e., a = bif and only if a and b denote the same individual.
However, for some purposes (e.g.,in the least-fixed-point characterization f minimal models given below) this "special"interpretation f the equality complicates matters, and it is more convenient to treatthe equality relation as a "normal" relation that is defined by a set of axioms E.The idea is that E has the property that a formula ~ is satisfiable under the identityinterpretation of equality if and only if {9~} U E is satisfiable in an interpretation iwhich equality is not given any special treatment.
In effect, the axioms E requirethat the equality relation denotes an equivalence r lation, and permit he substitutionof equals for equals.
Together these imply that no predicate can distinguish equalindividuals.
This means that in terms of satisfiability and the consequence r lation,exactly the same results are obtained irrespective of whether equality is treated asidentity or defined by the axioms E.Such treatments of equality in first-order logic are well known and described instandard texts.
For example, Chang and Lee (1973) give the axiom schemata inFigure 2,which generates syntactic equality axioms E for a first-order formula 9~, and prove thatE has the properties just described, sWhat is important here is that for an SB formula ~ the instances of the axiomschemata re all SB formulae, and there are only finitely many instances of theseschemata.This means that for an arbitrary SB formula ~ there is another SB formula ~ suchthat ~ is satisfiable with respect o an identity interpretation f equality if and only ifA ~ is satisfiable with respect to an interpretation in which equality is treated like anyother elation.
Thus a method for determining the satisfiability of SB formulae withoutequality can be used to determine satisfiability of SB formulae in which equality isinterpreted as identity.8 Of course, (E4) has no instances if ~ is an SB formula, since SB formulae do not contain functionsymbols.11Computational Linguistics Volume 20, Number 1(17) Vx x = x.
(18) Vx Vy x = y ~ y = x.
(19) Vx Va Vy VXl x -~ Xl /X arc(x, a, y) ~ arc(x1, a, y).
(20) Vx Va Vy Val a = al A arc(x, a, y) ~ arc(x, al, y).
(21) Vx Va Vy Vyl  y = yl Aarc(x,a,y) ~ arc(x,a,yl).
(22) VCl Vc2 c = Cl A con(c) ~ con(c1).
(23) Vx Vy x = y A 3rd-sg(x) ~ 3rd-sg(y).Figure 3The equality axioms for arc, con, and 3rd-sg predicates.For example, consider the SB formulae in (1-4) and (5-16).
These contain thethree-place relation symbol arc and the one-place relation symbols con and 3rd-sg.
Theequality axioms obtained from schemata (El-E4) for any system of constraints thatmention just these relations are given in Figure 3.4.
Clausal Form and Disjunctive DatalogIt is technically easier to work with a syntactically restricted class of SB formulaewhere the body of each formula has a particular syntactic form known as clausal formor Skolem standard form.DefinitionA clause is a formula of the form ,-~ o~1 V ?
?
?
V ~-, c~m V fll V ?
?
?
V ft,, where each oq andfly is an atomic formula (i.e., is of the form p(h , .
.
.
,  tn)), and m, n > 0.
A formula ~ isin clausal form iff it is a conjunction of clauses.The ,-~ ai are called negative literals and the fj are called positive literals.
A clausefor which m = 0 (i.e., one that consists solely of positive literals) is called a positiveclause, and one for which n = 0 (i.e., one that consists solely of negative literals) iscalled a negative clause.
A clause for which n = 1 is called a definite clause.
A Hornclause is a clause for which n < 1, i.e., either a negative clause or a definite clause.Abusing notation somewhat, a formula ~ in clausal form will sometimes also betreated as the set of the clauses that make up the conjunction ~.
Similarly, becauseclauses are used as rewriting rules below, the clause ~-, o~1 V -.. V ,-~ o~ m V f l  V .
.
.
V finwill sometimes be written as the equivalent implication oz I A ..-/x o~ m ~ fll V .-.
V fin.A formula ~ in clausal form does not contain any quantifier symbols.
As is stan-dard, all variables in ~ are treated as implicitly universally quantified at the clausallevel.
Existentially quantified variables in SB formulae are inessential, in that they canalways be directly replaced by Skolem constants.Restricting attention to SB formulae in clausal form imposes no real restriction onthe class of constraints expressible.
Standard procedures for transforming first-orderformulae into clausal form, such as the ones described in Chang and Lee (1973), Duffy12Mark Johnson Computing with Features as Formulae(1991), or Genesereth and Nilsson (1987), transform SB formulae into SB formulae inclausal form.Interestingly, clausal form SB formulae correspond one-to-one with an extensionto Datalog (Ullman 1988) that allows disjunctive "heads" or consequences.
In notationborrowed from disjunctive logic programming (Kowalski 1979; Lobo, Minker, andRajasekar 1992; Loveland 1987), the clauses above would be written as listed in theappendix.
While the connection between logic programming and feature structures iwell known (Ait-Kaci 1984; Ait-Kaci and Podelski 1993; Carpenter 1991, 1992; H6hfeldand Smolka 1988; Pereira 1987; Shieber 1992; Smolka 1992), this shows that the theoryof feature structure constraints i also related to database theory as well.Negative clauses correspond to Datalog integrity constraints, and clauses with asingle positive literal are definite clauses.
Simple assertions, e.g., about the existenceof arcs, consisting of exactly one positive literal are Datalog atomic clauses.
Clauseswith two or more positive literals cannot be expressed in Datalog itself, but requirethe disjunctive extension of Datalog.
The appendix displays all of the SB formulaementioned in this paper so far in clausal form in Datalog notation; (6'), (10 ~) and(7") are expressed in the disjunctive xtension to Datalog.
In fact, the axioms definingattribute-value structures (1-4) and syntactic equality (El-E3) are all Horn Datalogclauses; i.e., the disjunctive xtension is not needed for defining attribute-value f aturestructures.5.
Determining the Satisfiability of SB FormulaeThis section describes a forward-chaining algorithm for determining the satisfiability ofSB formulae in clausal form.
This algorithm is a nondeterministic variant of the semi-naive evaluation method for Datalog clauses in which the union-find algorithm is usedto efficiently maintain equivalence classes of equal terms.
It is also recognizable as ageneralization of the standard unification algorithm for feature structures to arbitraryHorn SB constraints.
9 The treatment is informal because the goal of the section isto point out several important standard implementation techniques rather than toadvance a totally new algorithm.The key intuition behind the algorithm is this.
To demonstrate the satisfiability ofa set S of clauses, it is sufficient o exhibit a set A of ground atoms drawn from theHerbrand base of S such that the following conditions hold (the next section provesthis assertion).
(a)(b)(c)' ~ of any negative clause in S are For no ground instance ~ o~ 1V .-.
V ~ o  mt in A.
(If they were, then that clause would be falsified all of c~1,..., c%by A.
)For each ground instance fl~ V ?
.. v fl~ of a positive clause in S, at leastone of the fl\[ is in A.
'A .
A ' ~f l~V.
.
-V f l~ofan impl i ca t ion in  For each ground instance ch .. o~ m!
S, if all of the o~, .
.
.
,  o~ m are in A then so is at least one of the f l ( , .
.
.
,  fl~.
(In fact, the other two conditions are just special cases of this condition.
)9 It is a generalization f the algorithm described inHegner (1991), which treats Horn combinations ofattribute-value constraints.13Computational Linguistics Volume 20, Number 15.1 Naive EvaluationOne could attempt to find such a set A in the following manner.
First, one nondeter-ministically selects a fl~ from each of the ground instances of the positive clauses inS and adds these to A.
Then one attempts to close A with respect o condition (c); if' ' of some (ground instance of an) implication are in A, all of the antecedents oq,.
.
.
,  olmthen one of the consequents fl~,..., fl~ is nondeterministically selected and added toA, unless at least one of them is already present.
(Of course, all such nondeterministicpaths might have to be investigated.)
Periodically, condition (a) is checked; if it failsto hold, then this nondeterministic path on the search for A must be abandoned.
Non-determinism arises solely from the presence of disjunction in consequents of clauses;if S is a set of Horn clauses then the fixed-point calculation proceeds deterministically.Ignoring the checking of condition (a), the method is essentially computing a fixed-point of the nonnegative clauses in S via a kind of iterative approximation known asnaive evaluation.
Naive evaluation is unnecessarily computationally inefficient.
Oncethe set A is large enough to require an atom o~ to be added to A, naive evaluation"rediscovers" this requirement on all subsequent passes.5.2 Semi-Naive EvaluationSemi-naive valuation avoids rediscovering the same fact in the same way by insistingthat each time a clause is applied at least one of the antecedents was just discoveredon the previous round (Ullman 1988, 1989).
This is done by maintaining two setsof atoms, A and &A, where A is the set of atoms discovered one or more iterationsago, and &A is the set of atoms discovered at the last iteration.
The nondeterministicsemi-naive algorithm for computing a set A (if it exists) is sketched in Figure 4.
Inthat algorithm choose is a "function" that nondeterministically picks one member fromits set argument; it can be implemented using, e.g., backtracking.
Ullman describesmethods of matching clauses in S against he sets A and &A that avoids calculatingall of the ground instances of the clauses in S.The semi-naive algorithm can be used directly with the syntactic equality axiomsgiven in Section 3.4 as a decision procedure for SB formulae, and hence for systemsof feature structure constraints.
However, the resulting system is inefficient becausethe equality axioms, specifically the instances of schemata (E2) and (E3), cause the"copying" of any atom containing an argument that appears in an equality atom toall members of the equivalence class containing that argument.For example, if p(a), q(b) and a = b are atoms in A, then instances of (E2) and (E3)ensure that p(b),q(a) and b = a will be added to &A and thence to A.
In general, if itis discovered that n constants al , .
.
,  an are equal, then A will ultimately contain the n 2equalities ai = aj, 1 < i < n, 1 < j <_ n, as well as at least n "copies" of any predicatecontaining any ai.5.3 Union-Find and EqualityAs noted above, the equality axioms ensure that the relation that the equality symboldenotes i an equivalence r lation and the substitutivity ofequals for equals.
In general,the union-find algorithm (Corman, Leiserson, and Rivest 1990; Gallier 1986; Nelsonand Oppen 1980) maintains the equivalence classes of the equality relation far moreefficiently than an approach that uses the syntactic equality axioms.The equivalence classes are encoded by associating each constant with a pointerthat is either null or points to another constant, where a points to b only if a = b. Thesepointer correspond exactly to the "invisible pointers" used in standard implementa-tions of the attribute-value nification algorithm.14Mark Johnson Computing with Features as FormulaeInput: A set of SB clauses S.Output: A set of ground clauses A iff S is satisfiable.A : - -0 ,&A := {choose({fl~,... fl~}) : fl~ V .
.
.
V fl~ is a ground instance of a positive clausein S},until &A := 0 doA :=AU&A,' V .. ?
V N ' is a ground instance of a negative if {o~,.
.
.
,  oz~} C A, where ~, oL1 ozmclause in S and at least one of the o~; is in &A,then fail,aA := {choose({fl~,..., fl~}) : o~ A .
.
.
A olin ~ fl~ V .
.
.
V fl~ is a ground instance, .
.
.
,  ~ is in &A of an implication in S such that {oL~ Oq'n} C A, at least one of the o  iand no flj~ is in A},return A.Figure 4The semi-naive algorithm for computing A.The find operation dereferences its argument, i.e., it follows these pointers until itreaches a constant with a null pointer, which is the equivalence classes' representative.Just as in the standard attribute-value unification algorithm, all arguments are alwaysdereferenced before they are used.The union operation, called whenever an atom a = b is added to the set A, mergestheir equivalence classes by redirecting the pointer associated with the representativeof one of them to point to the representative of the other.
1?In this approach, only atoms that contain the redirected constant need to be addedto &A and thence to A.
For example, if p(a) and q(b) are atoms in A and the equalitya = b is discovered, causing a to be redirected to b, then only p(b) is added to &A,and thence to A.
Further, the "original" atom p(a) is no longer required; indeed, thenew atom p(b) is exactly an argument-dereferenced variant of the old atom, so it isnot necessary to copy the atom at all.
In general, equalities between n items are repre-sented by n - 1 nonnull pointers, and copying of atoms can be avoided by argumentdereferencing.5.4 An ExampleThis section presents a very simple example that demonstrates the semi-naive algo-r ithm and the union-find techniques.
The clauses used are the attribute-value axiomschemata (1-4) and the axioms defining the sort 3rd-sg (5), as well as the additional10 The union-find algorithm achieves quasi-linear running time when it incorporates path compressionand union by rank (Corman, Leiserson, and Rivest 1990).15Computational Linguistics Volume 20, Number 1s I3rd-sg(u), arc(u, number, v), v # sg,Vx Va Vy Vz arc(x, a, y) A arc(x, a, z) ~ y = z,Vx Va Vy ,-~ con(x)V ~ arc(x,a,y),con(sg), con(pl), con(3rd),sg # pl, sg # 3rd, pl # 3rd,Vx 3rd-sg(x) ~ arc(x, person, 3rd),Vx 3rd-sg(x) ~ arc(x, number, sg)constraintsAV axiomssort defn.Figure 5Input clauses.constraints 3rd-sg(u), arc(u, number, v) and v ~ sg.
These latter constraints assert theexistence of an entity (denoted by u) with the property 3rd-sg and with a number arcwhose value v is something other than pl.
The complete set of clauses is given inFigure 5.
In practice the attribute-value axioms would probably not be explicitly enu-merated but "built in," so that appropriate instances are generated only when needed.Now we proceed to iteratively calculate the sets &A and A using the algorithm inFigure 4.
We calculate the first initial set of new atoms, &A0.
A0 = 0, of course.&Ao = {3rd-sg(u), arc(u, number, v), con(sg), con(pl), con(3rd)}On the first iteration we note that the antecedents of both clauses defining the sort3rd-sg are satisfied (with x bound to u), so &A1 is given as follows.A1 = {3rd-sg(u),arc(u,number~ v),con(sg),con(pl),con(3rd)}&A1 = {arc(u,person~3rd),arc(u, number, sg)}In the second iteration the antecedents of the first attribute-value axiom are satisfied,so &A2 contains an equality atom.3rd-sg(u), arc(u, number, v), con(sg), con(pl), con(3rd), IA2 = arc(u, person,3rd),arc(u, number, sg) J&A2 = {v = sg}The equality atom causes v to be redirected to sg, and at this stage the inconsistencyof the derived atom v = sg in &A2 with the input constraint v ~ sg in S is detected.
(Itmay be helpful to think of the constraint v ~ sg as the equivalent clause v = sg ~ false).The algorithm therefore returns with failure, indicating that the set S is unsatisfiable.At the point at which the inconsistency is detected, the set A contains the followingatoms, where v =~ sg indicates that v is redirected to sg.
{ 3rd-sg(u)~ arc(u, number, v), con(sg), con(pl), con( 3rd),A 3 ~- arc(u, person, 3rd), arc(u, number, sg),v ~ sgThe correspondence of this procedure to the standard attribute-value unification algo-rithm is quite strong.
In this procedure, the attribute-value axiom (1) detects ituationsin which some node has two arcs with the same label pointing to, say, y and z.
If such16Mark Johnson Computing with Features as Formulaea situation arises, the equality y = z is inferred, which results in y being redirectedto z and causes all of the arcs leaving y to be added to &A, where they will be com-pared with the arcs leaving z.
The other attribute-value axiom schemata (2--4) detectconstant-constant and constant-complex clashes, causing failure if one is found.Efficient processing demands that the atoms in A be indexed by their argumentsto speed up the matching atoms with the antecedents of clauses.
One way of doingthis is to store on each constant a list of the atoms in which that constant appears.
Suchan index has the same structure as the standard graph encoding of feature structureconstraints.6.
A Fixed-Point TheoremWe now turn to the theoretical justification of the bottom-up forward-chaining proce-dures sketched in the last section, and show that such methods will find a model fora set of SB formulae in clausal form if one exists.
This section demonstrates that anSB formula in clausal form is satisfiable if and only if a bottom-up forward-chainingprocedure finds a deductively closed set of atoms A.
A similar theorem for the casein which all the clauses are Horn clauses is presented in Lloyd (1984); this sectionextends that work to arbitrary clauses.It presents a characterization f the models of an arbitrary first-order formula 9~in clausal form in terms of the least-fixed points of a set {T~, X} of partial functionsfrom Herbrand interpretations to Herbrand interpretations.
These functions have theproperty that A is a Herbrand interpretation that satisfies ~ if and only if the least-fixedpoint of at least one of them is a submodel of A.For SB formulae this set of functions is finite and the least-fixed points are reachedin a finitely bounded number of iterations.
Since the procedures described in thelast section calculate the least-fixed points of these functions, they can be used todetermine the satisfiability of an arbitrary SB formula as well as all of its groundatomic consequences.The functions T~, x play a similiar r61e here to one that the transformation Tp playsin the least-fixed-point semantics of Horn clause programs.
Informally, each functionin the set {T~,x} corresponds to one whole sequence of nondeterministic choices ofdisjuncts in non-Horn clauses that could be made during an iterative approximationof the least-fixed point.
This section is based on Sections 5 and 6 of Chapter I of Lloyd(1984), to which the reader should turn for further details.The fixed-point heorem holds for arbitrary first-order formulae in clausal form,but the set {T~,x} is finite if and only if ~ does not contain any function symbols, i.e.,is an SB formula.
Equality is not treated specially, so the formula 9~ must containappropriate quality axioms, as mentioned above.Let U be the Herbrand universe with respect o ~ (i.e., the set of all terms thatcan be constructed using the constant and function symbols appearing in ~),11 and letB~ be the set of all ground atoms that can be formed using the predicate symbols of9~ with elements of U as arguments.
A Herbrand interpretation A is a subset of B~.Note that the set of Herbrand interpretations 2 B~ partially ordered by the subsetrelation forms a complete lattice.
Further, U and hence B~ are finite iff ~ is an SBformula.
(If ~ is in clausal form but is not an SB formula then it must contain afunction symbol, so its Herbrand universe U is infinite.
)11 As is standard, if 9~ has no constant symbols then it is necessary totake U to be a set consisting of asingle constant, say {a}.
See, e.g., Chang and Lee (1973) for details.17Computational Linguistics Volume 20, Number 1DefinitionA Herbrand interpretation A trivial ly falsifies a set of clauses ~ iff there is a ground' ' of a negative clause ,-~ al V - .
.V  ,-~ am in 9~ such that instance ,-, o~1 v - - .
v ,~ a mc A.That is, a Herbrand interpretation trivially falsifies a set of clauses ~ just in case somenegative clause in ~ is false in that interpretation.
Clearly, any such interpretationcannot satisfy ~, but the converse does not hold: there are interpretations that do nottrivially falsify 9~ but still do not satisfy ~ because they do not satisfy one or more ofthe nonnegative clauses in ~.We turn now to the nonnegative clauses in ~.
The idea is that even if A does notIA -  A t / I satisfy a ground instance a 1 "" am ~ f l  V ..- V fin of some nonnegative clausein ~, we can extend A so that it does so by adding one of the f;.
The chief technicaldifficulty here is caused by the nondeterminism involved in deciding which of the f\[ toadd, and a device called a "choice function" is introduced to choose, for each groundinstance of a clause, which of the atoms in its consequent will be added to A if itsantecedent is contained in A.
A choice function for a clause al A. .
,  A am ~ f l  V .
.
.
V finis therefore a function from all possible ways of grounding that clause to one of the fli.DefinitionA choice function for a clause c = (al A .. .
A am ~ fa V .
.
.
V ft,) is any function in(Vc -+ U) ~ \[1, .
.
.
,  n\], where Vc is the set of variables in the clause c.That is, a choice function for a clause is a function from variable assignments to aninteger representing one of the clause's consequents.
It is so named because for eachvariable assignment (i.e., each way of grounding the variables in ~) it "chooses" anatom from the consequent of the clause.
Horn clauses have only one choice function,and negative clauses have no choice functions at all.
Note that since U is finite for SBformulae, there are a finite number  of variable assignment functions for any SB clauseand hence only a finite number  of choice functions for any SB clause.A choice function X for a set of clauses ~ is a function from 9~ to choice functionssuch that for each nonnegative clause c in ~, X(c) is a choice function for c (the valuethat X takes on negative clauses is ignored).
Clearly, a choice function exists for everyset of clauses.Given a set of clauses ~ and a choice function X for ~o, we define a function F~, xfrom Herbrand interpretations to Herbrand interpretations a  follows.DefinitionF~, x is a function in 2 B* ~ 2 B* that is defined as follows.= {0( f i )  : for all nonnegative clausesC= (a l  A " ' "  A otto ---~ f l l  V " ' "  V f ln )  inand for all variable assignments 0 : Vc ~ U such that0 (a , ) , .
.
.
,0 (a , )  E A and i=  X(c)(O)}Intuitively, F~, x corresponds to one nondeterministic step in the 'bottom-up'  construc-tion of a Herbrand model  for ~ described in the previous section.
If A makes theantecedent of some ground instance of some clause in 9~ true, then we use the choicefunction X to pick an atom in the consequent of that ground clause and add it to theinterpretation.
Different choice functions X represent different sequences of nondeter-ministic choices, and result in the construction of possibly different interpretations.18Mark Johnson Computing with Features as FormulaeThe following lemma, based directly on proposition 6.3 of Lloyd (1984), notes thecontinuity (and therefore the monotonicity) of F~, x.Lemma 1The function F~, x is continuous.
That is, if X is a directed subset of 2 B~ (i.e., everyfinite subset of X has an upper bound in X) then F~,x(lub(X)) = lub(F~,x(X)).ProofLet X be any directed subset of 2 B~.
Then {al,... ,am} G lub(X) if and only if{a l , .
.
.
,am} C A for some A E X. Thenfl E F~,x(lub(X))iff c = (al A-.- A am ~ fll V .
.
.
V fl,) is a nonnegative clause in ~{0(al) , .
.
.
,  (an)} G lub(X), and fl = 0(flx(c)(o))iff c = (al A ...  A am ~ fll V .. .
V fin) is a nonnegative clause in ~,{0(al) , .
.
.
,0(a,)} C A for some A E X, and fl = 0(flx(c)(O))iff fl E F~, x(A) for some A E Xiff fl E lub(F~,x(X)).
\[\]The continuity of F~, x immediately implies the convergence of the sequence (F/~,x (O));the value that it converges to is called the least-fixed point of F~, x, written Ifp(F~,x).Note that if ~ is in SB then there is an integer k such that lfp(F~,x) = Fk~,x(O); thisfollows directly from the monotonicity of F~, x and the finiteness of B~.The function F~, x and a condition requiring that the interpretation produced oesnot trivially falsify the set of clauses ~ together define the partial function T~, x.DefinitionT~, x is a partial function in 2 B~ --~ 2 B~ that is defined as follows.T~,x(A ) = F~,x(A ) if F~,x(A ) does not trivially falsify 9~, and is undefined other-wise.Note that if the sequence (T/~,x(A)) is defined for all i then (T/~,x(A)) = i (F~, x (A)).
T~, xenjoys the following kind of monotonicity.Lemma 2Suppose A c A'.
Then T~, x (A) is defined if T~, x (A') is defined, and T~, x (A) c T~, x (A').ProofIf A trivially falsifies ~ then A ~ does too, so T~,x(A ) is defined if T~,x(A' ) is defined.If T~,x(A' ) is defined then T~,x(A ) = F~,x(A ) _C F~,x(A' ) = T~,x(A' ).
\[\]The following lemma shows that Herbrand models of 9~ contain fixed points of T~, xfor some choice function X for 9~-Lemma 3For all Herbrand interpretations A, A ~ 9~ iff there exists a choice function X for 9~such that T?, x (A) _C A.19Computational Linguistics Volume 20, Number 1ProofWe begin first with the left-to-right component of the proof.
If A ~ 9~, then A does nottrivially falsify ~, so T~, x (A) is defined.
Now we show how to find for each satisfyinginterpretation A a choice function X such that T~x(A ) = A.
Since A satisfies ~, forevery nonnegative clause c = (o~1 A.. -A O~m ~ fll V. .
.
V fin) in 9~ and for every variableassignment function 0 for the variables in c, if 0(o~1)~...~ 0(o~n) E A, then by the truthconditions for implication and disjunction, some O(fli) E A as well.
Thus, for all 0 suchthat 0(oq)~... ~O(C~n) E A let X(c)(0) be any i such that O(fli) E A, and let X(c)(0) takeany permissible value otherwise.
Hence T~, x (A) = F~, x (A) = A.Now suppose T~,x(A ) C A.
Since T~,x(A ) is defined, A does not trivially falsifyany negative clause in ~.
Let c = (o~1 A ... A O~m ~ fll V ".. V fin) be any nonnegativeclause in ~, and let ~ E V~ ~ U be any variable assignment function for the variablesin c. If 0(o~1)~... ~0(O~n) E A then O(fli) E T~,x(A ) C A as well, where i = X(c)(0), soA ~ c and hence A ~ 9~.
\[\]The following theorem shows that a formula is satisfiable if and only if the least-fixedpoint of at least one of the T~, x exists.
It justifies the decision procedures presented inthe previous section, which operate by searching for such least-fixed points.The proof actually establishes something stronger, viz., that every Herbrand modelof ~ is an extension of the least-fixed points of one or more of the T~ x.
Thus anenumeration of all of the least-fixed points of the T~, x yields all of the "minimalmodels" of ~ (although it is not clear that these are in fact necessary for recognitionor parsing, as discussed above).Theoremis satisfiable if and only if there exists a choice function X for ~ such that lfp(T~,x)exists.ProofIf Ifp(T~,x) exists then by Lemma 3, lfp(T~,x) = ~.
Now suppose A is a Herbrandinterpretation that satisfies 9~- Lemma 3 asserts the existence of a choice function Xsuch that T~,x(A ) exists and T~,x(A ) G A.
By Lemma 2 and the fixed point propertynoted above lfp(T~,x) exists, since lfp(T~,x) = T~x(O ) C T~x(A ) C A.
\[\]It is important to recognize that these "minimal models" are in general not upward-closed: an extension A' of a model A can trivially falsify ~ even though A does not.
Thisis essentially Moshier's (1988) and Pereira's (1987) observation that in the presence ofnegation the set of models is not upwardly closed.We conclude this section with the observation that the positive consequences of aformula 9~ can be "read off" its least-fixed points.Corollaryis satisfiable iff for some choice function X for ~, lfp(T~,x) exists.
Moreover, if fl =fll V ...  V fin is any disjunction of ground atoms, 9~ ~ fl iff for all choice functions Xfor ~ such that lfp(T~,x) exists, at least one of the fli is in lfp(T~,x).7.
ConclusionThe main goal of this paper was to demonstrate from a computational perspectivethat Sch6nfinkel-Bernays' formulae are a natural generalization of (boolean combina-20Mark Johnson Computing with Features as Formulaetions of) attribute-value f ature structure constraints.
From a computational complexityperspective we noted that the satisfiability problem for SB formulae with a boundednumber of quantifiers is NP-complete, so it is no harder than the satisfiability problemfor disjunctive attribute-value constraints.From a more practical perspective, a semi-naive bottom-up evaluation strategyusing union-find methods to handle equality generalizes the standard attribute-value"unification" algorithm to arbitrary SB constraints in clausal form.
Because it treatsstandard attribute-value constraints in approximately the same way as the standardunification algorithm, and because it can incorporate the same kinds of indexing thatthe latter algorithm employs, the generalized algorithm should be able to determinethe satisfiability of attribute-value constraints with approximately the same efficiencyas the standard attribute-value unification algorithm.In generalizing attribute-value constraints to SB formulae, we noted that in clausalform the SB formulae constitute a disjunctive xtension to Datalog, and that the stan-dard attribute-value nification algorithm is closely related to a version of semi-naiveevaluation algorithm used to evaluate Datalog clauses.
This offers another perspectiveon feature structure constraints; they can be seen as kinds of databases containinginformation about the linguistic structures they describe.Perhaps the greatest weakness of this work is the lack of an efficient methodfor treating disjunctive constraints.
The backtracking strategy suggested in the bodyof the paper can be extremely inefficient, even with 'toy' grammars.
This problemis not unique to this approach; rather, it is endemic to most complex feature-basedapproaches to natural anguage processing, as evidenced by the volume of literatureon the subject.As discussed in Section 3, the satisfiability problem for SB formula with a fixednumber of universal quantifiers is NP-hard, so all known algorithms require exponen-tial time in the worst case, and unless P=NP no tractable general-purpose algorithm fordetermining the satisfiability of SB formulae exists.
With present echnology, the bestwe can hope for is an algorithm that performs adequately on the types of problemsthat we actually encounter.Sometimes disjunctive constraints can be (automatically) transformed into nondis-junctive ones, thus avoiding the problem entirely.
For example, Alshawi (1992) de-scribes a technique attributed to Colmerauer for transforming disjunctions of finite-domain feature-value constraints into conjunctions.
Kasper (1988) and Hegner (1991)point out that Horn clauses, although technically disjunctions, can be handled con-siderably more efficiently than general disjunctive constraints.
The forward-chainingmechanisms that they propose for treating these constraints appear to be special casesof the semi-naive algorithm sketched in this paper.Unfortunately, I know of no general adequate method for handling the disjunc-tive constraints that arise in real grammars with acceptable efficiency.
The techniquesdiscussed by Maxwell and Kaplan (1991, 1992) seem most directly compatible withthe approach described in this paper, and the methods described by Kasper (1987b),Eisele and D6rre (1988), and Emele (1991) might have important applications as well.AcknowledgmentI would like to thank Johan van Benthem,Bob Carpenter, Stephen Hegner, RonaldM.
Kaplan, Edward Stabler and theparticipants of the feature structuresseminar at the Institut f/Jr maschinelleSprachverarbeitung, Universitat Stuttgart,for their suggestions and comments.
Allresponsibility for errors rests with me, ofcourse.ReferencesAit-Kaci, Hassan (1984).
A lattice theoreticapproach to computation based on a calculus of21Computational Linguistics Volume 20, Number 1partially ordered type structures.
Doctoraldissertation, University of Pennsylvania.Ait-Kaci, Hassan, and Podelski, Andreas(1993).
"Towards a meaning of LIFE."
TheJournal of Logic Programming 16(3,4),195-234.Alshawi, Hiyan (1992).
"Categories andrules."
In The Core Language Engine, editedby Hiyan Alshawi, 41-60.
MIT Press.Barton, G. Edward; Berwick, Robert C.; andRistad, Eric S. (1987).
ComputationalComplexity and Natural Language.
MITPress.Blackburn, Patrick (1991).
"Modal logic andattribute-value structures."
In Modal LogicColloquium '91, edited by Maarten deRijke.
Dutch Project for Language, Logicand Information, Amsterdam.Blackburn, Patrick, and Spaan, Edith (1992).
"A modal perspective on thecomputational complexity of attributevalue grammar."
Logic Group PreprintSeries No.
77, Department of Philosophy,University of Utrecht.Blackburn, Patrick; Gardent, Claire; andMeyer-viol, Wilfried (1993).
"Talkingabout trees."
In Proceedings, 6th EuropeanMeeting of the Asssociation for ComputationalLinguistics.
Utrecht, Holland.Bresnan, Joan (1982).
The MentalRepresentation f Grammatical Relations.
MITPress.Carpenter, Bob (1991).
"Typed featurestructures: A generalization f first-orderterms."
In Logic Programming, Proceedingsof the 1991 International Symposium, editedby Vijay Saraswat and Kazunori Ueda,187-201.
MIT Press.Carpenter, Bob (1992).
The Logic of TypedFeature Structures.
Cambridge Tracts inTheoretical Computer Science 32.Cambridge University Press, Cambridge,England.Carpenter, Bob, and Pollard, Carl (1991).
"Inclusion, disjointness and choice: Thelogic of linguistic classification."
InProceedings, 29th Annual Meeting of theAssociation for Computational Linguistics,9-16.
Berkeley, CA.Carpenter, Bob; Pollard, Carl; and Franz,Alex (1991).
"The specification andimplementation f constraint-basedunification grammars."
In Proceedings,Second International Workshop on ParsingTechnologies.
Cancun, Mexico.Chang, Chin-Liang, and Lee, RichardChar-Tung (1973).
Symbolic Logic andMechanical Theorem Proving.
AcademicPress.Chomsky, Noam (1986).
Knowledge ofLanguage, Its Nature, Origins and Use.Praeger.Chomsky, Noam (1988).
Some Notes onEconomy of Derivation andRepresentation.
ms. MassachusettsInstitute of Technology.Corman, Thomas H.; Leiserson, Charles E.;and Rivest, Ronald L. (1990).
Introductionto Algorithms.
MIT Press.Dawar, Anuj, and Vijay-Shanker, K.
(1990).
"An interpretation f negation in featurestructures."
Computational Linguistics 16(1),11-21.D6rre, Jochen (1991).
"The language ofSTUF."
In Text Understanding in LILOG:Integrating Computational Linguistics andArtificial Intelligence, dited by OttheinHerzog and Claus-Rainer Rollinger,39-50.
Springer-Verlag.D6rre, Jochen, and Eisele, Andreas (1990).
"Feature logic with disjunctiveunification."
In Proceedings, 13thInternational Conference on ComputationalLinguistics (COLING-90), 100-105.Helsinki, Finland.D6rre, Jochen, and Eisele, Andreas (1991).
"A comprehensive unification-basedgrammar formalism."
DYANADeliverable R3.1B, ESPRIT Basic ResearchAction BR3175.D6rre, Jochen, and Rounds, William C.(1992).
"On subsumption andsemiunification i  feature algebras.
"Journal of Symbolic Computation 13, 441-461.Duffy, David (1991).
Principles of AutomatedTheorem Proving.
John Wiley and Sons.Eisele, A., and D6rre, J.
(1988).
"Unificationof disjunctive feature descriptions."
InProceedings, 26th Annual Meeting of theAssociation for Computational Linguistics,286-294.
Buffalo, New York.Emele, Martin (1991).
"Unification with lazynon-redundant copying."
In Proceedings,29th Annual Meeting of the Association forComputational Linguistics, 323-330.Berkeley, CA.Gallier, J. H. (1986).
Logic for ComputerScience.
Harper and Row.Genesereth, M., and Nilsson, N. (1987).Logical Foundations of Artificial Intelligence.Morgan Kaufmann.Hegner, Stephen J.
(1991).
"Horn extendedfeature structures: Fast unification withnegation and limited disjunction."
InProceedings, Fifth Conference ofthe EuropeanChapter of the Association for ComputationalLinguistics, 33-38.
Berlin.H6hfeld, Markus, and Smolka, Gert.
(1988).
"Definite relations over constraintlanguages."
LILOG Report No.
53, IBMDeutschland.Johnson, Mark (1988).
Attribute-Value Logic22Mark Johnson Computing with Features as Formulaeand the Theory of Grammar.
CSLI LectureNotes Series.
University of Chicago Press.Johnson, Mark (1990a).
"Expressingdisjunctive and negative featureconstraints with classical first-orderlogic."
In Proceedings, 28th Annual Meetingof the Association for ComputationalLinguistics, 173-179.
Pittsburgh, PA.Johnson, Mark (1990b).
"Features, framesand quantifier-free formulae."
In Logic andLogic Grammars for Language Processing,edited by Patrick Saint-Dizier and StanSzpakowicz, 94-107.
Ellis Horwood.Johnson, Mark (1991a).
"Features andformulae."
Computational Linguistics 17(2),131-152.Johnson, Mark (1991b).
"Logic and featurestructures."
In Proceedings, InternationalJoint Conference on Artificial Intelligence.Sydney.Johnson, Mark (in press a) "Attribute-valuelogic and natural anguage processing.
"In Unification in Grammar, edited byJfirgen Wedekind and Christian Rohrer.MIT Press.Johnson, Mark (in press b) "Two ways offormalizing rammars."
Linguistics andPhilosophy.Johnson, Mark, and Kay, Martin (1990).
"Semantic operators and anaphora."
InProceedings, 13th International Conference onComputational Linguistics (COLING-90),17-27.
Helsinki.Johnson, Mark, and Klein, Ewan (1986).
"Discourse, parsing and anaphora."
InProceedings, I1th International Conference onComputational Linguistics.
Bonn.Kamp, Hans (1981).
"A theory of truth andsemantic representation."
In FormalMethods in the Study of Language, dited byJ.
A. G. Groenendijk, T. M. V. Janssem,and M. B. J. StokhoL 277-322.Mathematical Centre Tracts, Amsterdam.Kaplan, Ronald M., and Bresnan, Joan(1982).
"Lexical-functional grammar, aformal system for grammaticalrepresentation."
In The MentalRepresentation f Grammatical Relations,edited by Joan Bresnan, 173-281.
MITPress.Kaplan, Ronald M., and Maxwell John T.(1988a).
"An algorithm for functionaluncertainty."
In Proceedings, 12thInternational Conference on ComputationalLinguistics, 297-302.
Budapest, Hungary.Kaplan, Ronald M., and Maxwell, John T.(1988b).
"Constituent coordination ilexical-functional grammar."
InProceedings, 12th International Conference onComputational Linguistics, 297-302.Budapest, Hungary.Kaplan, Ronald M., and Zaenen, Annie.(1989).
"Long-distance dependencies,constituent s ructure and functionaluncertainty."
In Alternative Conceptions ofPhrase Structure, edited by Mark Baltinand Anthony Krock, 17-42.
ChicagoUniversity Press.Kapur, D., and Musser, D. R. (1987).
"Proofby consistency."
Artificial Intelligence 31,125-157.Karttunen, Lauri (1984).
"Features andvalues."
In Proceedings, InternationalConference on Computational Linguistics(COLING-1984), 28-33.
StanfordUniversity.Kasper, Robert T. (1987a).
Feature structures:A logical theory with application to languageanalysis.
Doctoral dissertation, Universityof Michigan.Kasper, Robert T. (1987b).
"A unificationmethod for disjunctive featurestructures."
In Proceedings, 25th AnnualMeeting of the Association for ComputationalLinguistics, 235-242.
Stanford University.Kasper, Robert T. (1988).
"Conditionaldescriptions in functional unificationgrammar."
In Proceedings, 26th AnnualMeeting of the Association for ComputationalLinguistics, 233-240.
Buffalo, N.Y.Kasper, Robert T., and Rounds, William C.(1986).
"A logical semantics for featurestructures."
In Proceedings, 24th AnnualMeeting of the Association for ComputationalLinguistics, 257-266.
Columbia University,New York.Kasper, Robert T., and Rounds, William C.(1990).
"The logic of unification ingrammar."
Linguistics and Philosophy 13(1),35-58.Kay, Martin (1979).
"Functional unificationgrammar."
In Proceedings, Fifth AnnualMeeting of the Berkeley LinguisticsAssociation.
Berkeley, CA.Kay, Martin (1985a).
"Parsing in functionalunification grammar."
In Natural LanguageParsing, edited by D. R. Dowty,L.
Karttunen, and A. M. Zwicky.Cambridge University Press.Kay, Martin (1985b).
"Unification ingrammar."
In Natural LanguageUnderstanding and Logic Programming,edited by V. Dahl and P. Saint-Dizier,233-240.
North Holland.Keller, Bill (1991).
Feature logics, infinitarydescriptions and the logical treatment ofgrammar.
Doctoral dissertation, Universityof Sussex.Kowalski, Robert (1979).
Logic for ProblemSolving.
North Holland.Langholm, Tore (1989).
"How to say nowith feature structures."
COSMOS Report23Computational Linguistics Volume 20, Number 1No.
13, Department of Mathematics,University of Oslo.Lewis, Harry (1980).
"Complexity results forclasses of quantificational formulae."
JCSS21, 317-353.Lewis, Harry, and Papadimitriou, Christos(1981).
Elements of the Theory ofComputation.
Prentice-Hall, NJ.Lloyd, John W. (1984).
Foundations ofLogicProgramming.
Springer-Verlag.Lobo, Jorge; Minker, Jack; and Rajasekar,Arcot (1992).
Foundations of DisjunctiveLogic Programming.
MIT Press.Loveland, D. W. (1987).
"Near-HornProlog."
In Logic Programming: Papers forthe Fourth International Conference on LogicProgramming, edited by Jean-Louis Lassez,456-469.
MIT Press.Marcus, Mitch; Hindle, Donald; and Fleck,Margaret M. (1983).
"D-theory--talkingabout talking about trees."
In Proceedings,21st Annual Meeting of the Association forComputational Linguistics, 129-136.Cambridge, MA.Maxwell, John T., and Kaplan, Ronald M.(1991).
"A method for disjunctiveconstraint satisfaction."
In Current Issuesin Parsing Technology, edited by MasaruTomita, 173-190.
Kluwer AcademicPublishers.Maxwell, John T., and Kaplan, Ronald M.(1992).
"The interface between phrasaland functional constraints."
ComputationalLinguistics 19(4), 571-590.Moshier, M. Drew (1988).
Extensions tounification grammar for the description ofprogramming languages.
Doctoraldissertation, University of Michigan.Moshier, M. Drew, and Rounds, William C.(1987).
"A logic for partially specifieddata structures."
In The ACM Symposiumon the Principles of Programming Languages.Association for Computing Machinery,Munich, Germany.Nelson, G., and Oppen, D. C. (1980).
"Fastdecision procedures based on congruenceclosure."
J. ACM 27(2), 245-257.Partee, Barbara H.; ter Meulen, Alice; andWall, Robert E. (1990).
MathematicalMethods in Linguistics.
Kluwer AcademicPublishers.Pereira, Fernando C. N. (1982).
Logic fornatural anguage analysis.
Doctoraldissertation, University of Edinburgh.Pereira, Fernando C. N. (1987).
"Grammarsand logics of partial information."
InProceedings, International Conference on LogicProgramming, 989-1013.
Melbourne,Australia.Pollard, Carl, and Sag, Ivan A.
(1987).Information-Based Syntax and Semantics.CSLI Lecture Notes Series.
ChicagoUniversity Press.Pollard, Carl, and Sag, Ivan A.
(1992).Head-Driven Phrase Structure Grammar.CSLI Lecture Notes Series.
ChicagoUniversity Press.Rounds, William C. (1988).
"LFP: A logic forlinguistic descriptions and an analysis ofits complexity."
Computational Linguistics14(4), 1-9.Rounds, William C., and Manaster-Ramer,Alexis (1987).
"A logical version offunctional grammar."
In Proceedings, 25thAnnual Meeting of the Association forComputational Linguistics, 89-96.
Stanford,CA.Shieber, Stuart M. (1986).
An Introduction toUnification-Based Approaches toGrammar.CSLI Lecture Notes Series.
University ofChicago Press.Shieber, Stuart M. (1992).
Constraint-BasedGrammar Formalisms: Parsing~ and TypeInference for Natural and ComputerLanguages.
MIT Press.Smolka, Gert.
(1988).
"A feature logic withsubsorts."
LILOG Report No.
33, IBMDeutschland GmbH.Smolka, Gert.
(1992).
"Feature constraintlogics for unification grammars."
TheJournal of Logic Programming 12(1,2), 51-87.Ullman, Jeffrey D. (1988).
Principles ofDatabase and Knowledge-Base Systems, Vol.
I.Computer Science Press.Ullman, Jeffrey D. (1989).
Principles ofDatabase and Knowledge-Base Systems,Vol.
II: The New Technologies.
ComputerScience Press.Uszkoreit, Hans (1986).
"Categorialunification grammar."
In Proceedings, 11thInternational Conference on ComputationalLinguistics, 187-194.
Bonn.Vijay-Shanker, K. (1992).
"Using descriptionsof trees in a tree adjoining grammar.
"Computational Linguistics 18(4), 481-517.Wall, Robert (1972).
Introduction toMathematical Linguistics.
Prentice-Hall.Zajac, R6mi (1992).
"Inheritance andconstraint-based grammar formalisms.
"Computational Linguistics 18(2), 159-182.24Mark Johnson Computing with Features as FormulaeAppendix A: SB Formulae in Disjunctive Datalog Format(1')(2')(3')(4')(5')(5")(5'")(6')(7a')(Tb')(7c')(Sa')Y = Z : -arc(X, A, Y), arc(X, A, Z).
:- con(X), arc(X, A, Y).con(c) .
(for each c in N):-  cl = c2.
(for each distinct pair ci, c2 in N)arc(X, person, 3rd) : -3 rd  sg(X).arc(X, number, singular) :-3rd_sg(X).3rd sg(X) : -arc(X, person, 3rd), arc(X, number, singular).Y = singular; Y = plural :- arc(X, number, Y).
: -X<X.
:- X < Y, Y < X.X < Z :- X < Y, Y < Z.d(X, X) :- n(X).
(Sa") n(X) :- d(X, X).
(Sb')(8c')(9')(9")(10')(10")(10"')(12a')(12a")(12b')(12b")(7')(7")(7")(14')(14")(17')(18')(19')(2o')(21')(22')(23')X = Y : -d(X,  Y), d(Y, X).d(X, Z) : -d(X,  Y), d(Y, Z).n (root) .d(root, Y) :- n(Y).X < Y; Y < X; d(X, Y); d(Y, X) : -n(X),  n(Y).
: -n(X),  n(Y), X < Y, d(X, Y).
: -n(X),  n(Y), X < Y, d(Y, X).n(X) :- X < Y.n(Y) :- X < Y.n(X) :- d(X, Y).n(Y) :- d(X, Y).d(X, Y) : -p(X,  Y).
:- p(X, Y), X = Y.p(X, Y); X = Y : -d(X,  Y).
:- c(X, Y), d(X, Y).p(Z, Y) :- c(X, Y), p(Z, X).X=X.Y=X : -X=Y.arc(Xl, A, Y) : -X  = Xl, arc(X, A, Y).arc(X, At, Y) : -A  = Ai, arc(X, A, Y).arc(X, A, Yi) : -Y  = Yi, arc(X, A, Y).con(C1) :- C = Ci, con(C).3rd sg(Y) :- X = Y, 3rd_sg(X).25
