Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 328?334,New York, June 2006. c?2006 Association for Computational LinguisticsLearning Morphological Disambiguation Rules for TurkishDeniz YuretDept.
of Computer EngineeringKoc?
UniversityIstanbul, Turkeydyuret@ku.edu.trFerhan Tu?reDept.
of Computer EngineeringKoc?
UniversityIstanbul, Turkeyfture@ku.edu.trAbstractIn this paper, we present a rule basedmodel for morphological disambiguationof Turkish.
The rules are generated by anovel decision list learning algorithm us-ing supervised training.
Morphologicalambiguity (e.g.
lives = live+s or life+s)is a challenging problem for agglutinativelanguages like Turkish where close to halfof the words in running text are morpho-logically ambiguous.
Furthermore, it ispossible for a word to take an unlimitednumber of suffixes, therefore the numberof possible morphological tags is unlim-ited.
We attempted to cope with theseproblems by training a separate model foreach of the 126 morphological featuresrecognized by the morphological analyzer.The resulting decision lists independentlyvote on each of the potential parses of aword and the final parse is selected basedon our confidence on these votes.
Theaccuracy of our model (96%) is slightlyabove the best previously reported resultswhich use statistical models.
For compari-son, when we train a single decision list onfull tags instead of using separate modelson each feature we get 91% accuracy.1 IntroductionMorphological disambiguation is the task of select-ing the correct morphological parse for a given wordin a given context.
The possible parses of a wordare generated by a morphological analyzer.
In Turk-ish, close to half the words in running text are mor-phologically ambiguous.
Below is a typical word?masal??
with three possible parses.masal+Noun+A3sg+Pnon+Acc (= the story)masal+Noun+A3sg+P3sg+Nom (= his story)masa+Noun+A3sg+Pnon+Nom?DB+Adj+With(= with tables)Table 1: Three parses of the word ?masal?
?The first two parses start with the same root,masal (= story, fable), but the interpretation of thefollowing +?
suffix is the Accusative marker in onecase, and third person possessive agreement in theother.
The third parse starts with a different root,masa (= table) followed by a derivational suffix +l?
(= with) which turns the noun into an adjective.
Thesymbol ?DB represents a derivational boundary andsplits the parse into chunks called inflectional groups(IGs).1We will use the term feature to refer to individualmorphological features like +Acc and +With; theterm IG to refer to groups of features split by deriva-tional boundaries (?DB), and the term tag to refer tothe sequence of IGs following the root.Morphological disambiguation is a useful firststep for higher level analysis of any language but itis especially critical for agglutinative languages likeTurkish, Czech, Hungarian, and Finnish.
These lan-guages have a relatively free constituent order, and1See (Oflazer et al, 1999) for a detailed description of themorphological features used in this paper.328syntactic relations are partly determined by morpho-logical features.
Many applications including syn-tactic parsing, word sense disambiguation, text tospeech synthesis and spelling correction depend onaccurate analyses of words.An important qualitative difference between partof speech tagging in English and morphological dis-ambiguation in an agglutinative language like Turk-ish is the number of possible tags that can be as-signed to a word.
Typical English tag sets includeless than a hundred tag types representing syntac-tic and morphological information.
The number ofpotential morphological tags in Turkish is theoret-ically unlimited.
We have observed more than tenthousand tag types in our training corpus of a mil-lion words.
The high number of possible tags posesa data sparseness challenge for the typical machinelearning approach, somewhat akin to what we ob-serve in word sense disambiguation.One way out of this dilemma could be to ignorethe detailed morphological structure of the word andfocus on determining only the major and minor partsof speech.
However (Oflazer et al, 1999) observesthat the modifier words in Turkish can have depen-dencies to any one of the inflectional groups of aderived word.
For example, in ?mavi masal?
oda?
(=the room with a blue table) the adjective ?mavi?
(=blue) modifies the noun root ?masa?
(= table) eventhough the final part of speech of ?masal??
is an ad-jective.
Therefore, the final part of speech and in-flection of a word do not carry sufficient informationfor the identification of the syntactic dependenciesit is involved in.
One needs the full morphologicalanalysis.Our approach to the data sparseness problem isto consider each morphological feature separately.Even though the number of potential tags is un-limited, the number of morphological features issmall: The Turkish morphological analyzer we use(Oflazer, 1994) produces tags that consist of 126unique features.
For each unique feature f , we takethe subset of the training data in which one of theparses for each instance contain f .
We then split thissubset into positive and negative examples depend-ing on whether the correct parse contains the featuref .
These examples are used to learn rules using theGreedy Prepend Algorithm (GPA), a novel decisionlist learner.To predict the tag of an unknown word, first themorphological analyzer is used to generate all itspossible parses.
The decision lists are then used topredict the presence or absence of each of the fea-tures contained in the candidate parses.
The resultsare probabilistically combined taking into accountthe accuracy of each decision list to select the bestparse.
The resulting tagging accuracy is 96% on ahand tagged test set.A more direct approach would be to train a singledecision list using the full tags as the target classifi-cation.
Given a word in context, such a decision listassigns a complete morphological tag instead of pre-dicting individual morphological features.
As such,it does not need the output of a morphological ana-lyzer and should be considered a tagger rather thana disambiguator.
For comparison, such a decisionlist was built, and its accuracy was determined to be91% on the same test set.The main reason we chose to work with decisionlists and the GPA algorithm is their robustness to ir-relevant or redundant features.
The input to the deci-sion lists include the suffixes of all possible lengthsand character type information within a five wordwindow.
Each instance ends up with 40 attributes onaverage which are highly redundant and mostly irrel-evant.
GPA is able to sort out the relevant featuresautomatically and build a fairly accurate model.
Ourexperiments with Naive Bayes resulted in a signif-icantly worse performance.
Typical statistical ap-proaches include the tags of the previous words asinputs in the model.
GPA was able to deliver goodperformance without using the previous tags as in-puts, because it was able to extract equivalent infor-mation implicit in the surface attributes.
Finally, un-like most statistical approaches, the resulting modelsof GPA are human readable and open to interpreta-tion as Section 3.1 illustrates.The next section will review related work.
Sec-tion 3 introduces decision lists and the GPA trainingalgorithm.
Section 4 presents the experiments andthe results.2 Related WorkThere is a large body of work on morphological dis-ambiguation and part of speech tagging using a va-riety of rule-based and statistical approaches.
In the329rule-based approach a large number of hand craftedrules are used to select the correct morphologicalparse or POS tag of a given word in a given context(Karlsson et al, 1995; Oflazer and Tu?r, 1997).
Inthe statistical approach a hand tagged corpus is usedto train a probabilistic model which is then used toselect the best tags in unseen text (Church, 1988;Hakkani-Tu?r et al, 2002).
Examples of statisti-cal and machine learning approaches that have beenused for tagging include transformation based learn-ing (Brill, 1995), memory based learning (Daele-mans et al, 1996), and maximum entropy models(Ratnaparkhi, 1996).
It is also possible to train sta-tistical models using unlabeled data with the ex-pectation maximization algorithm (Cutting et al,1992).
Van Halteren (1999) gives a comprehensiveoverview of syntactic word-class tagging.Previous work on morphological disambiguationof inflectional or agglutinative languages includeunsupervised learning for of Hebrew (Levingeret al, 1995), maximum entropy modeling for Czech(Hajic?
and Hladka?, 1998), combination of statisticaland rule-based disambiguation methods for Basque(Ezeiza et al, 1998), transformation based taggingfor Hungarian (Megyesi, 1999).Early work on Turkish used a constraint-based ap-proach with hand crafted rules (Oflazer and Kuruo?z,1994).
A purely statistical morphological disam-biguation model was recently introduced (Hakkani-Tu?r et al, 2002).
To counter the data sparsenessproblem the morphological parses are split acrosstheir derivational boundaries and certain indepen-dence assumptions are made in the prediction ofeach inflectional group.A combination of three ideas makes our approachunique in the field: (1) the use of decision lists anda novel learning algorithm that combine the statis-tical and rule based techniques, (2) the treatment ofeach individual feature separately to address the datasparseness problem, and (3) the lack of dependenceon previous tags and relying on surface attributesalone.3 Decision ListsWe introduce a new method for morphological dis-ambiguation based on decision lists.
A decision listis an ordered list of rules where each rule consistsof a pattern and a classification (Rivest, 1987).
Inour application the pattern specifies the surface at-tributes of the words surrounding the target such assuffixes and character types (e.g.
upper vs. lowercase, use of punctuation, digits).
The classificationindicates the presence or absence of a morphologicalfeature for the center word.3.1 A Sample Decision ListWe will explain the rules and their patterns using thesample decision list in Table 2 trained to identify thefeature +Det (determiner).Rule Class Pattern1 1 W=?c?ok R1=+DA2 1 L1=?pek3 0 W=+AzI4 0 W=?c?ok5 1 ?Table 2: A five rule decision list for +DetThe value in the class column is 1 if word Wshould have a +Det feature and 0 otherwise.
Thepattern column describes the required attributes ofthe words surrounding the target word for the ruleto match.
The last (default) rule has no pattern,matches every instance, and assigns them +Det.This default rule captures the behavior of the ma-jority of the training instances which had +Det intheir correct parse.
Rule 4 indicates a commonexception: the frequently used word ?c?ok?
(mean-ing very) should not be assigned +Det by default:?c?ok?
can be also used as an adjective, an adverb,or a postposition.
Rule 1 introduces an exception torule 4: if the right neighbor R1 ends with the suffix+DA (the locative suffix) then ?c?ok?
should receive+Det.
The meanings of various symbols in the pat-terns are described below.When the decision list is applied to a window ofwords, the rules are tried in the order from the mostspecific (rule 1) to the most general (rule 5).
The firstrule that matches is used to predict the classificationof the center word.
The last rule acts as a catch-all;if none of the other rules have matched, this rule as-signs the instance a default classification.
For exam-ple, the five rule decision list given above classifiesthe middle word in ?pek c?ok alanda?
(matches rule330W target word A [ae]L1, L2 left neighbors I [?iuu?
]R1, R2 right neighbors D [dt]== exact match B [bp]=?
case insensitive match C [cc?
]=+ is a suffix of K [kgg?
]Table 3: Symbols used in the rule patterns.
Capitalletters on the right represent character groups usefulin identifying phonetic variations of certain suffixes,e.g.
the locative suffix +DA can surface as +de, +da,+te, or +ta depending on the root word ending.1) and ?pek c?ok insan?
(matches rule 2) as +Det,but ?insan c?ok daha?
(matches rule 4) as not +Det.One way to interpret a decision list is as a se-quence of if-then-else constructs familiar from pro-gramming languages.
Another way is to see the lastrule as the default classification, the previous rule asspecifying a set of exceptions to the default, the rulebefore that as specifying exceptions to these excep-tions and so on.3.2 The Greedy Prepend Algorithm (GPA)To learn a decision list from a given set of trainingexamples the general approach is to start with a de-fault rule or an empty decision list and keep addingthe best rule to cover the unclassified or misclassi-fied examples.
The new rules can be added to theend of the list (Clark and Niblett, 1989), the front ofthe list (Webb and Brkic, 1993), or other positions(Newlands and Webb, 2004).
Other design decisionsinclude the criteria used to select the ?best rule?
andhow to search for it.The Greedy Prepend Algorithm (GPA) is a variantof the PREPEND algorithm (Webb and Brkic, 1993).It starts with a default rule that matches all instancesand classifies them using the most common class inthe training data.
Then it keeps prepending the rulewith the maximum gain to the front of the grow-ing decision list until no further improvement can bemade.
The algorithm can be described as follows:GPA(data)1 dlist ?
NIL2 default -class ?
MOST-COMMON-CLASS(data)3 rule ?
[if TRUE then default -class ]4 while GAIN(rule , dlist , data) > 05 do dlist ?
prepend(rule , dlist)6 rule ?
MAX-GAIN-RULE(dlist , data)7 return dlistThe gain of a candidate rule in GPA is definedas the increase in the number of correctly classifiedinstances in the training set as a result of prepend-ing the rule to the existing decision list.
This isin contrast with the original PREPEND algorithmwhich uses the less direct Laplace preference func-tion (Webb and Brkic, 1993; Clark and Boswell,1991).To find the next rule with the maximum gain, GPAuses a heuristic search algorithm.
Candidate rulesare generated by adding a single new attribute to thepattern of each rule already in the decision list.
Thecandidate with the maximum gain is prepended tothe decision list and the process is repeated until nomore positive gain rules can be found.
Note that ifthe best possible rule has more than one extra at-tribute compared to the existing rules in the decisionlist, a suboptimal rule will be selected.
The origi-nal PREPEND uses an admissible search algorithm,OPUS, which is guaranteed to find the best possiblecandidate (Webb, 1995), but we found OPUS to betoo slow to be practical for a problem of this scale.We picked GPA for the morphological disam-biguation problem because we find it to be fast andfairly robust to the existence of irrelevant or redun-dant attributes.
The average training instance has40 attributes describing the suffixes of all possiblelengths and character type information in a five wordwindow.
Most of this information is redundant orirrelevant to the problem at hand.
The number ofdistinct attributes is on the order of the number ofdistinct word-forms in the training set.
NeverthelessGPA is able to process a million training instancesfor each of the 126 unique morphological featuresand produce a model with state of the art accuracyin about two hours on a regular desktop PC.22Pentium 4 CPU 2.40GHz3314 Experiments and ResultsIn this section we present the details of the data,the training and testing procedures, the surface at-tributes used, and the accuracy results.4.1 Training Datadocuments 2383sentences 50673tokens 948404parses 1.76 per tokenIGs 1.33 per parsefeatures 3.29 per IGunique tokens 111467unique tags 11084unique IGs 2440unique features 126ambiguous tokens 399223 (42.1%)Table 4: Statistics for the training dataOur training data consists of about 1 millionwords of semi-automatically disambiguated Turkishnews text.
For each one of the 126 unique morpho-logical features, we used the subset of the trainingdata in which instances have the given feature in atleast one of their generated parses.
We then split thissubset into positive and negative examples depend-ing on whether the correct parse contains the givenfeature.
A decision list specific to that feature is cre-ated using GPA based on these examples.Some relevant statistics for the training data aregiven in Table 4.4.2 Input AttributesOnce the training data is selected for a particularmorphological feature, each instance is representedby surface attributes of five words centered aroundthe target word.
We have tried larger window sizesbut no significant improvement was observed.
Theattributes computed for each word in the windowconsist of the following:1.
The exact word string (e.g.
W==Ali?nin)2.
The lowercase version (e.g.
W=?ali?nin) Note:all digits are replaced by 0?s at this stage.3.
All suffixes of the lowercase version (e.g.W=+n, W=+In, W=+nIn, W=+?nIn, etc.)
Note:certain characters are replaced with capital let-ters representing character groups mentioned inTable 3.
These groups help the algorithm rec-ognize different forms of a suffix created by thephonetic rules of Turkish: for example the loca-tive suffix +DA can surface as +de, +da, +te, or+ta depending on the ending of the root word.4.
Attributes indicating the types of characters atvarious positions of the word (e.g.
Ali?ninwould be described with W=UPPER-FIRST,W=LOWER-MID, W=APOS-MID, W=LOWER-LAST)Each training instance is represented by 40 at-tributes on average.
The GPA procedure is responsi-ble for picking the attributes that are relevant to thedecision.
No dictionary information is required orused, therefore the models are fairly robust to un-known words.
One potentially useful source of at-tributes is the tags assigned to previous words whichwe plan to experiment with in future work.4.3 The Decision ListsAt the conclusion of the training, 126 decision listsare produced of the form given in Table 2.
The num-ber of rules in each decision list range from 1 to6145.
The longer decision lists are typically for partof speech features, e.g.
distinguishing nouns fromadjectives, and contain rules specific to lexical items.The average number of rules is 266.
To get an esti-mate on the accuracy of each decision list, we splitthe one million word data into training, validation,and test portions using the ratio 4:1:1.
The train-ing set accuracy of the decision lists is consistentlyabove 98%.
The test set accuracies of the 126 deci-sion lists range from 80% to 100% with the averageat 95%.
Table 5 gives the six worst features with testset accuracy below 89%; these are the most difficultto disambiguate.4.4 Correct Tag SelectionTo evaluate the candidate tags, we need to combinethe results of the decision lists.
We assume that thepresence or absence of each feature is an indepen-dent event with a probability determined by the testset accuracy of the corresponding decision list.
Forexample, if the +P3pl decision list predicts YES,we assume that the +P3pl feature is present with33287.89% +Acquire To acquire (noun)86.18% +PCIns Postposition subcat.85.11% +Fut Future tense84.08% +P3pl 3. plural possessive80.79% +Neces Must79.81% +Become To become (noun)Table 5: The six features with the worst test set ac-curacy.probability 0.8408 (See Table 5).
If the +Fut deci-sion list predicts NO, we assume the +Fut feature ispresent with probability 1 ?
0.8511 = 0.1489.
Toavoid zero probabilities we cap the test set accura-cies at 99%.Each candidate tag indicates the presence of cer-tain features and the absence of others.
The prob-ability of the tag being correct under our indepen-dence assumption is the product of the probabilitiesfor the presence and absence of each of the 126 fea-tures as determined by our decision lists.
For effi-ciency, one can neglect the features that are absentfrom all the candidate tags because their contribu-tion will not effect the comparison.4.5 ResultsThe final evaluation of the model was performed ona test data set of 958 instances.
The possible parsesfor each instance were generated by the morpholog-ical analyzer and the correct one was picked manu-ally.
40% of the instances were ambiguous, whichon the average had 3.9 parses.
The disambiguationaccuracy of our model was 95.82%.
The 95% confi-dence interval for the accuracy is [0.9457, 0.9708].An analysis of the mistakes in the test data showthat at least some of them are due to incorrect tagsin our training data.
The training data was semi-automatically generated and thus contained some er-rors.
Based on hand evaluation of the differences be-tween the training data tags and the GPA generatedtags, we estimate the accuracy of the training data tobe below 95%.
We ran two further experiments tosee if we could improve on the initial results.In our first experiment we used our original modelto re-tag the training data.
The re-tagged trainingdata was used to construct a new model.
The result-ing accuracy on the test set increased to 96.03%, nota statistically significant improvement.In our second experiment we used only unam-biguous instances for training.
Decision list trainingrequires negative examples, so we selected randomunambiguous instances for positive and negative ex-amples for each feature.
The accuracy of the result-ing model on the test set was 82.57%.
The problemwith selecting unambiguous instances is that certaincommon disambiguation decisions are never repre-sented during training.
More careful selection ofnegative examples and a sophisticated bootstrappingmechanism may still make this approach workable.Finally, we decided to see if our decision listscould be used for tagging rather than disambigua-tion, i.e.
given a word in a context decide on the fulltag without the help of a morphological analyzer.Even though the number of possible tags is unlim-ited, the most frequent 1000 tags cover about 99%of the instances.
A single decision list trained withthe full tags was able to achieve 91.23% accuracyusing 10000 rules.
This is a promising result andwill be explored further in future work.5 ContributionsWe have presented an automated approach to learnmorphological disambiguation rules for Turkish us-ing a novel decision list induction algorithm, GPA.The only input to the rules are the surface attributesof a five word window.
The approach can be gener-alized to other agglutinative languages which sharethe common challenge of a large number of poten-tial tags.
Our approach for resolving the data sparse-ness problem caused by the large number of tags isto generate a separate model for each morphologi-cal feature.
The predictions for individual featuresare probabilistically combined based on the accu-racy of each model to select the best tag.
We wereable to achieve an accuracy around 96% using thisapproach.AcknowledgmentsWe would like to thank Kemal Oflazer of Sabanc?University for providing us with the Turkish mor-phological analyzer, training and testing data for dis-ambiguation, and valuable feedback.333ReferencesBrill, E. (1995).
Transformation-based error-drivenlearning and natural language processing: A casestudy in part-of-speech tagging.
Computational Lin-guistics, 21(4):543?565.Church, K. W. (1988).
A stochastic parts program andnoun phrase parser for unrestricted text.
In Proceed-ings of the Second Conference on Applied NaturalLanguage Processing, pages 136?143.Clark, P. and Boswell, R. (1991).
Rule induction withCN2: Some recent improvements.
In Kodratoff,Y., editor, Machine Learning ?
Proceedings of theFifth European Conference (EWSL-91), pages 151?163, Berlin.
Springer-Verlag.Clark, P. and Niblett, T. (1989).
The CN2 induction al-gorithm.
Machine Learning, 3:261?283.Cutting, D., Kupiec, J., Pedersen, J., and Sibun, P. (1992).A practical part-of-speech tagger.
In Proceedings ofthe 3rd Conference on Applied Language Processing,pages 133?140.Daelemans, W. et al (1996).
MBT: A memory-basedpart of speech tagger-generator.
In Ejerhead, E. andDagan, I., editors, Proceedings of the Fourth Workshopon Very Large Corpora, pages 14?27.Ezeiza, N. et al (1998).
Combining stochastic and rule-based methods for disambiguation in agglutinative lan-guages.
In Proceedings of the 36th Annual Meeting ofthe Association for Computational Linguistics (COL-ING/ACL98), pages 379?384.Hajic?, J. and Hladka?, B.
(1998).
Tagging inflective lan-guages: Prediction of morphological categories for arich, structured tagset.
In Proceedings of the 36thAnnual Meeting of the Association for ComputationalLinguistics (COLING/ACL98), pages 483?490, Mon-treal, Canada.Hakkani-Tu?r, D. Z., Oflazer, K., and Tu?r, G. (2002).Statistical morphological disambiguation for aggluti-native languages.
Computers and the Humanities,36:381?410.Karlsson, F., Voutialinen, A., Heikkila?, J., and Anttila, A.(1995).
Constraint Grammar - A Language Indepen-dent System for Parsing Unrestricted Text.
Mouton deGruyter.Levinger, M., Ornan, U., and Itai, A.
(1995).
Learningmorpho-lexical probabilities from an untagged corpuswith an application to hebrew.
Computational Lin-guistics, 21(3):383?404.Megyesi, B.
(1999).
Improving brill?s pos tagger for anagglutinative language.
In Pascale, F. and Joe, Z., ed-itors, Proceedings of the Joing SIGDAT Conferenceon Empirical Methods in Natural Language and VeryLarge Corpora, pages 275?284, College Park, Mary-land, USA.Newlands, D. and Webb, G. I.
(2004).
Alternative strate-gies for decision list construction.
In Proceedings ofthe Fourth Data Mining Conference (DM IV 03), pages265?273.Oflazer, K. (1994).
Two-level description of turkishmorphology.
Literary and Linguistic Computing,9(2):137?148.Oflazer, K., Hakkani-Tu?r, D. Z., and Tu?r, G. (1999).Design for a turkish treebank.
In Proceedings ofthe Workshop on Linguistically Interpreted Corpora,EACL 99, Bergen, Norway.Oflazer, K. and Kuruo?z, I?.
(1994).
Tagging and morpho-logical disambiguation of turkish text.
In Proceedingsof the 4th Applied Natural Language Processing Con-ference, pages 144?149.
ACL.Oflazer, K. and Tu?r, G. (1997).
Morphological disam-biguation by voting constraints.
In Proceedings of the35th Annual Meeting of the Association for Computa-tional Linguistics (ACL97, EACL97), Madrid, Spain.Ratnaparkhi, A.
(1996).
A maximum entropy model forpart-of-speech tagging.
In Proceedings of the Confer-ence on Empirical Methods in Natural Language Pro-cessing.Rivest, R. L. (1987).
Learning decision lists.
MachineLearning, 2:229?246.van Halteren, H., editor (1999).
Syntactic Wordclass Tag-ging.
Text, Speech and Language Technology.
KluwerAcademic Publishers.Webb, G. I.
(1995).
Opus: An efficient admissible algo-rithm for unordered search.
JAIR, 3:431?465.Webb, G. I. and Brkic, N. (1993).
Learning decision listsby prepending inferred rules.
In Proceedings of the AI93 Workshop on Machine Learning and Hybrid Sys-tems, pages 6?10, Melbourne.334
