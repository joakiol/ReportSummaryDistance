Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 1002?1010,Beijing, August 2010Metaphor Identification Using Verb and Noun ClusteringEkaterina Shutova, Lin Sun and Anna KorhonenComputer Laboratory, University of Cambridgees407,ls418,alk23@cam.ac.ukAbstractWe present a novel approach to auto-matic metaphor identification in unre-stricted text.
Starting from a small seed setof manually annotated metaphorical ex-pressions, the system is capable of har-vesting a large number of metaphors ofsimilar syntactic structure from a corpus.Our method is distinguished from previ-ous work in that it does not employ anyhand-crafted knowledge, other than theinitial seed set, but, in contrast, capturesmetaphoricity by means of verb and nounclustering.
Being the first to employ un-supervised methods for metaphor identifi-cation, our system operates with the pre-cision of 0.79.1 IntroductionBesides enriching our thought and communica-tion with novel imagery, the phenomenon ofmetaphor also plays a crucial structural role in ouruse of language.
Metaphors arise when one con-cept is viewed in terms of the properties of theother.
Below are some examples of metaphor.
(1) How can I kill a process?
(Martin, 1988)(2) Inflation has eaten up all my savings.
(Lakoffand Johnson, 1980)(3) He shot down all of my arguments.
(Lakoffand Johnson, 1980)(4) And then my heart with pleasure fills,And dances with the daffodils.1In metaphorical expressions seemingly unrelatedfeatures of one concept are associated with an-other concept.
In the computer science metaphor1?I wandered lonely as a cloud?, William Wordsworth,1804.in (1) the computational process is viewed assomething alive and, therefore, its forced termi-nation is associated with the act of killing.
Lakoffand Johnson (1980) explain metaphor as a system-atic association, or a mapping, between two con-cepts or conceptual domains: the source and thetarget.
The metaphor in (3) exemplifies a map-ping of a concept of argument to that of war.
Theargument, which is the target concept, is viewedin terms of a battle (or a war), the source concept.The existence of such a link allows us to talk aboutarguments using the war terminology, thus givingrise to a number of metaphors.Characteristic to all areas of human activity(from poetic to ordinary to scientific) and, thus,to all types of discourse, metaphor becomes animportant problem for natural language process-ing (NLP).
In order to estimate the frequency ofthe phenomenon, Shutova and Teufel (2010) con-ducted a corpus study on a subset of the BritishNational Corpus (BNC) (Burnard, 2007) repre-senting various genres.
They manually anno-tated metaphorical expressions in this data andfound that 241 out of 761 sentences contained ametaphor, whereby in 164 phrases metaphoricitywas introduced by a verb.
Due to such a high fre-quency of their use, a system capable of recog-nizing and interpreting metaphorical expressionsin unrestricted text would become an invaluablecomponent of any semantics-oriented NLP appli-cation.Automatic processing of metaphor can beclearly divided into two subtasks: metaphoridentification (distinguishing between literal andmetaphorical language in text) and metaphorinterpretation (identifying the intended literalmeaning of a metaphorical expression).
Both ofthem have been repeatedly attempted in NLP.To date the most influential account ofmetaphor identification is that of Wilks (1978).1002According to Wilks, metaphors represent a viola-tion of selectional restrictions in a given context.Consider the following example.
(5) My car drinks gasoline.
(Wilks, 1978)The verb drink normally takes an animate subjectand a liquid object.
Therefore, drink taking a caras a subject is an anomaly, which may as well in-dicate metaphorical use of drink.This approach was automated by Fass (1991)in his met* system.
However, Fass himself in-dicated a problem with the method: it detectsany kind of non-literalness or anomaly in lan-guage (metaphors, metonymies and others), i.e.,it overgenerates with respect to metaphor.
Thetechniques met* uses to differentiate betweenthose are mainly based on hand-coded knowledge,which implies a number of limitations.
In a sim-ilar manner manually created knowledge in theform of WordNet (Fellbaum, 1998) is employedby the system of Krishnakumaran and Zhu (2007),which essentially differentiates between highlylexicalized metaphors included in WordNet, andnovel metaphorical senses.Alternative approaches (Gedigan et al, 2006)search for metaphors of a specific domain defineda priori (e.g.
MOTION metaphors) in a specifictype of discourse (e.g.
Wall Street Journal).
Incontrast, the scope of our experiments is the wholeof the British National Corpus (BNC) (Burnard,2007) and the domain of the expressions we iden-tify is unrestricted.
However, our technique is alsodistinguished from the systems of Fass (1991) andKrishnakumaran and Zhu (2007) in that it doesnot rely on any hand-crafted knowledge, but rathercaptures metaphoricity in an unsupervised way bymeans of verb and noun clustering.The motivation behind the use of clusteringmethods for metaphor identification task lies inthe nature of metaphorical reasoning based on as-sociation.
Compare, for example, the target con-cepts of marriage and political regime.
Havingquite distinct meanings, both of them are cogni-tively mapped to the source domain of mecha-nism, which shows itself in the following exam-ples:(6) Our relationship is not really working.
(7) Diana and Charles did not succeed in mend-ing their marriage.
(8) The wheels of Stalin?s regime were well oiledand already turning.We expect that such relatedness of distinct tar-get concepts should manifest itself in the exam-ples of language use, i.e.
target concepts that areassociated with the same source concept shouldappear in similar lexico-syntactic environments.Thus, clustering concepts using grammatical rela-tions (GRs) and lexical features would allow us tocapture their relatedness by association and har-vest a large number of metaphorical expressionsbeyond our seed set.
For example, the sentencein (6) being part of the seed set should enable thesystem to identify metaphors in both (7) and (8).In summary, our system (1) starts from a seedset of metaphorical expressions exemplifying arange of source?target domain mappings; (2) per-forms unsupervised noun clustering in order toharvest various target concepts associated with thesame source domain; (3) by means of unsuper-vised verb clustering creates a source domain verblexicon; (4) searches the BNC for metaphoricalexpressions describing the target domain conceptsusing the verbs from the source domain lexicon.We tested our system starting with a collectionof metaphorical expressions representing verb-subject and verb-object constructions, where theverb is used metaphorically.
We evaluated the pre-cision of metaphor identification with the help ofhuman judges.
In addition to this we comparedour system to a baseline built upon WordNet,whereby we demonstrated that our method goesfar beyond synonymy and captures metaphors notdirectly related to any of those seen in the seed set.2 Experimental Data2.1 Seed PhrasesWe used the dataset of Shutova (2010) as a seedset.
Shutova (2010) annotated metaphorical ex-pressions in a subset of the BNC sampling vari-ous genres: literature, newspaper/journal articles,essays on politics, international relations and his-tory, radio broadcast (transcribed speech).
Thedataset consists of 62 phrases that are single-word1003metaphors representing verb-subject and verb-object relations, where a verb is used metaphor-ically.
The seed phrases include e.g.
stir ex-citement, reflect enthusiasm, accelerate change,grasp theory, cast doubt, suppress memory, throwremark (verb - direct object constructions) andcampaign surged, factor shaped [..], tensionmounted, ideology embraces, changes operated,approach focuses, example illustrates (subject -verb constructions).2.2 CorpusThe search space for metaphor identification wasthe British National Corpus (BNC) that wasparsed using the RASP parser of Briscoe et al(2006).
We used the grammatical relations out-put of RASP for BNC created by Andersen et al(2008).
The system searched the corpus for thesource and target domain vocabulary within a par-ticular grammatical relation (verb-object or verb-subject).3 MethodStarting from a small seed set of metaphorical ex-pressions, the system implicitly captures the as-sociations that underly their production and com-prehension.
It generalizes over these associationsby means of unsupervised verb and noun clus-tering.
The obtained clusters then represent po-tential source and target concepts between whichmetaphorical associations hold.
The knowledgeof such associations is then used to annotatemetaphoricity in a large corpus.3.1 Clustering MotivationAbstract concepts that are associated with thesame source domain are often related to eachother on an intuitive and rather structural level,but their meanings, however, are not necessarilysynonymous or even semantically close.
The re-sults of previous research on corpus-based lexi-cal semantics suggest that the linguistic environ-ment in which a lexical item occurs can shed lighton its meaning.
A number of works have shownthat it is possible to automatically induce seman-tic word classes from corpus data via clustering ofcontextual cues (Pereira et al, 1993; Lin, 1998;Schulte im Walde, 2006).
The consensus is thatthe lexical items exposing similar behavior in alarge body of text most likely have the same mean-ing.
However, the concepts of marriage and po-litical regime, that are also observed in similarlexico-syntactic environments, albeit having quitedistinct meanings are likewise assigned by suchmethods to the same cluster.
In contrast to con-crete concepts, such as tea, water, coffee, beer,drink, liquid, that are clustered together due tomeaning similarity, abstract concepts tend to beclustered together by association with the samesource domain.
It is the presence of this associ-ation that explains the fact that they share com-mon contexts.
We exploit this idea for identifi-cation of new target domains associated with thesame source domain.
We then use unsupervisedverb clustering to collect source domain vocab-ulary, which in turn allows us to harvest a largenumber of new metaphorical expressions.3.2 Verb and Noun ClusteringSince Levin (1993) published her classification,there have been a number of attempts to automati-cally classify verbs into semantic classes using su-pervised and unsupervised approaches (Lin, 1998;Brew and Schulte im Walde, 2002; Korhonen etal., 2003; Schulte im Walde, 2006; Joanis et al,2008; Sun and Korhonen, 2009).
Similar methodswere also applied to acquisition of noun classesfrom corpus data (Rooth et al, 1999; Pantel andLin, 2002; Bergsma et al, 2008).We adopt a recent verb clustering approach ofSun and Korhonen (2009), who used rich syntac-tic and semantic features extracted using a shallowparser and a clustering method suitable for the re-sulting high dimensional feature space.
When Sunand Korhonen evaluated their approach on 204verbs from 17 Levin classes, they obtained 80.4F-measure (which is high in particular for an un-supervised approach).
We apply this approach to amuch larger set of 1610 verbs: all the verb formsappearing in VerbNet (Kipper et al, 2006) withthe exception of highly infrequent ones.
In addi-tion, we adapt the approach to noun clustering.3.2.1 Feature ExtractionOur verb dataset is a subset of VerbNet com-piled as follows.
For all the verbs in VerbNet we1004extracted their occurrences (up to 10,000) fromthe raw corpus data collected originally by Korho-nen et al (2006) for construction of VALEX lexi-con.
Only the verbs found in this data more than150 times were included in the experiment.For verb clustering, we adopted the best per-forming features of Sun and Korhonen (2009):automatically acquired verb subcategorizationframes (SCFs) parameterized by their selectionalpreferences (SPs).
We obtained these features us-ing the SCF acquisition system of Preiss et al(2007).
The system tags and parses corpus datausing the RASP parser and extracts SCFs from theresulting GRs using a rule-based classifier whichidentifies 168 SCF types for English verbs.
It pro-duces a lexical entry for each verb and SCF com-bination occurring in corpus data.
We obtainedSPs by clustering argument heads appearing in thesubject and object slots of verbs in the resultinglexicon.Our noun dataset consists of 2000 most fre-quent nouns in the BNC.
Following previousworks on semantic noun classification (Pantel andLin, 2002; Bergsma et al, 2008), we used GRs asfeatures for noun clustering.
We employed all theargument heads and verb lemmas appearing in thesubject, direct object and indirect object relationsin the RASP-parsed BNC.The feature vectors were first constructed fromthe corpus counts, and subsequently normalizedby the sum of the feature values before applyingclustering.3.2.2 Clustering AlgorithmWe use spectral clustering (SPEC) for bothverbs and nouns.
This technique has proved to beeffective in previous verb clustering works (Brewand Schulte im Walde, 2002; Sun and Korhonen,2009) and in related NLP tasks involving high di-mensional data (Chen et al, 2006).
We use theMNCut algorithm for SPEC which has a wide ap-plicability and a clear probabilistic interpretation(Meila and Shi, 2001).The task is to group a given set of words W ={wn}Nn=1 into a disjoint partition of K classes.SPEC takes a similarity matrix as input.
Weconstruct it using the Jensen-Shannon divergence(JSD) as a measure.
The JSD between two featurevectors w and w?
is djsd(w, w?)
= 12D(w||m) +12D(w?||m) where D is the Kullback-Leibler di-vergence, and m is the average of the w and w?.The similarity matrix S is constructed whereSij = exp(?djsd(w, w?)).
In SPEC, the simi-larities Sij are viewed as weights on the edgesij of a graph G over W .
The similarity matrixS is thus the adjacency matrix for G. The de-gree of a vertex i is di = ?Nj=1 Sij .
A cut be-tween two partitions A and A?
is defined to beCut(A, A?)
=?m?A,n?A?
Smn.The similarity matrix S is then transformed intoa stochastic matrix P .P = D?1S (1)The degree matrix D is a diagonal matrix whereDii = di.It was shown by Meila and Shi (2001) that if Phas the K leading eigenvectors that are piecewiseconstants2 with respect to a partition I?
and theireigenvalues are not zero, then I?
minimizes themultiway normalized cut (MNCut):MNCut(I) = K ?
?Kk=1 Cut(Ik,Ik)Cut(Ik,I)Pmn can be interpreted as the transition probabil-ity between the vertexes m, n. The criterion canthus be expressed as MNCut(I) = ?Kk=1(1 ?P (Ik ?
Ik|Ik)) (Meila, 2001), which is the sumof transition probabilities across different clusters.This criterion finds the partition where randomwalks are most likely to happen within the samecluster.
In practice, the leading eigenvectors ofP are not piecewise constants.
However, we canextract the partition by finding the approximatelyequal elements in the eigenvectors using a cluster-ing algorithm, such as K-Means.Since SPEC has elements of randomness, we ranthe algorithm multiple times and the partition thatminimizes the distortion (the distances to clustercentroid) is reported.
Some of the clusters ob-tained as a result of applying the algorithm to ournoun and verb datasets are demonstrated in Fig-ures 1 and 2 respectively.
The noun clusters rep-resent target concepts that we expect to be asso-ciated with the same source concept (some sug-gested source concepts are given in Figure 1, al-though the system only captures those implicitly).2An eigenvector v is piecewise constant with respect to Iif v(i) = v(j)?i, j ?
Ik and k ?
1, 2...K1005Source: MECHANISMTarget Cluster: consensus relation tradition partnershipresistance foundation alliance friendship contact reserveunity link peace bond myth identity hierarchy relation-ship connection balance marriage democracy defensefaith empire distinction coalition regime divisionSource: STORY; JOURNEYTarget Cluster: politics practice trading reading occupa-tion profession sport pursuit affair career thinking lifeSource: LOCATION; CONTAINERTarget Cluster: lifetime quarter period century succes-sion stage generation decade phase interval futureSource: LIVING BEING; ENDTarget Cluster: defeat fall death tragedy loss collapse de-cline disaster destruction fateFigure 1: Clustered target conceptsSource Cluster: sparkle glow widen flash flare gleamdarken narrow flicker shine blaze bulgeSource Cluster: gulp drain stir empty pour sip spill swal-low drink pollute seep flow drip purify ooze pump bub-ble splash ripple simmer boil treadSource Cluster: polish clean scrape scrub soakSource Cluster: kick hurl push fling throw pull drag haulSource Cluster: rise fall shrink drop double fluctuatedwindle decline plunge decrease soar tumble surge spiralboomFigure 2: Clustered verbs (source domains)The verb clusters contain coherent lists of sourcedomain vocabulary.3.3 Selectional Preference Strength FilterFollowing Wilks (1978), we take metaphor to rep-resent a violation of selectional restrictions.
How-ever, not all verbs have an equally strong capacityto constrain their arguments, e.g.
remember, ac-cept, choose etc.
are weak in that respect.
Wesuggest that for this reason not all the verbs wouldbe equally prone to metaphoricity, but only theones exhibiting strong selectional preferences.
Wetest this hypothesis experimentally and expect thatplacing this criterion would enable us to filter outa number of candidate expressions, that are lesslikely to be used metaphorically.We automatically acquired selectional pref-erence distributions for Verb-Subject andVerb-Object relations from the BNC parsedby RASP.
We first clustered 2000 most frequentnouns in the BNC into 200 clusters using SPECas described in the previous section.
The ob-tained clusters formed our selectional preferenceclasses.
We adopted the selectional preferencemeasure proposed by Resnik (1993) and success-fully applied to a number of tasks in NLP includ-ing word sense disambiguation (Resnik, 1997).Resnik models selectional preference of a verb inprobabilistic terms as the difference between theposterior distribution of noun classes in a partic-ular relation with the verb and their prior distri-bution in that syntactic position regardless of theidentity of the predicate.
He quantifies this dif-ference using the relative entropy (or Kullback-Leibler distance), defining the selectional prefer-ence strength (SPS) as follows.SR(v) = D(P (c|v)||P (c)) =?cP (c|v) log P (c|v)P (c) ,(2)where P (c) is the prior probability of the nounclass, P (c|v) is the posterior probability of thenoun class given the verb and R is the gram-matical relation in question.
SPS measures howstrongly the predicate constrains its arguments.We use this measure to filter out the verbs withweak selectional preferences.
The optimal SPSthreshold was set experimentally on a small held-out dataset and approximates to 1.32.
We ex-cluded expressions containing the verbs with pref-erence strength below this threshold from the setof candidate metaphors.4 Evaluation and DiscussionIn order to prove that our metaphor identificationmethod generalizes well over the seed set and goesfar beyond synonymy, we compared its output tothat of a baseline taking WordNet synsets to repre-sent source and target domains.
We evaluated thequality of metaphor tagging in terms of precisionwith the help of human judges.4.1 Comparison against WordNet BaselineThe baseline system was implemented using syn-onymy information from WordNet to expand onthe seed set.
Assuming all the synonyms of theverbs and nouns in seed expressions to representthe source and target vocabularies respectively,the system searches for phrases composed of lex-ical items belonging to those vocabularies.
Forexample, given a seed expression stir excitement,the baseline finds phrases such as arouse fervour,1006stimulate agitation, stir turmoil etc.
However, it isnot able to generalize over the concepts to broadsemantic classes, e.g.
it does not find other feel-ings such as rage, fear, anger, pleasure etc., whichis necessary to fully characterize the target do-main.
The same deficiency of the baseline systemmanifests itself in the source domain vocabulary:the system has only the knowledge of direct syn-onyms of stir, as opposed to other verbs charac-teristic to the domain of liquids, e.g.
pour, flow,boil etc., successfully identified by means of clus-tering.To compare the coverage achieved by unsuper-vised clustering to that of the baseline in quanti-tative terms, we estimated the number of Word-Net synsets, i.d.
different word senses, in themetaphorical expressions captured by the two sys-tems.
We found that the baseline system coversonly 13% of the data identified using clusteringand does not go beyond the concepts present inthe seed set.
In contrast, most metaphors taggedby our method are novel and represent a con-siderably wider range of meanings, e.g.
giventhe seed metaphors stir excitement, throw remark,cast doubt the system identifies previously unseenexpressions swallow anger, hurl comment, sparkenthusiasm etc.
as metaphorical.4.2 Comparison with Human JudgementsIn order to access the quality of metaphor identifi-cation by both systems we used the help of humanannotators.
The annotators were presented witha set of randomly sampled sentences containingmetaphorical expressions as annotated by the sys-tem and by the baseline.
They were asked to markthe tagged expressions that were metaphorical intheir judgement as correct.The annotators were encouraged to rely on theirown intuition of metaphor.
However, we also pro-vided some guidance in the form of the followingdefinition of metaphor3:1.
For each verb establish its meaning in con-text and try to imagine a more basic meaningof this verb on other contexts.
Basic mean-ings normally are: (1) more concrete; (2) re-3taken from the annotation procedure of Shutova andTeufel (2010) that is in turn partly based on the work of Prag-glejaz Group (2007).CKM 391 Time and time again he would stare at theground, hand on hip, if he thought he had received a badcall, and then swallow his anger and play tennis.AD9 3205 He tried to disguise the anxiety he felt whenhe found the comms system down, but Tammuz wasnearly hysterical by this stage.AMA 349 We will halt the reduction in NHS servicesfor long-term care and community health services whichsupport elderly and disabled patients at home.ADK 634 Catch their interest and spark their enthu-siasm so that they begin to see the product?s potential.K2W 1771 The committee heard today that gangs regu-larly hurled abusive comments at local people, makingan unacceptable level of noise and leaving litter behindthem.Figure 3: Sentences tagged by the system(metaphors in bold)lated to bodily action; (3) more precise (asopposed to vague); (4) historically older.2.
If you can establish the basic meaning thatis distinct from the meaning of the verb inthis context, the verb is likely to be usedmetaphorically.We had 5 volunteer annotators who were all na-tive speakers of English and had no or sparse lin-guistic knowledge.
Their agreement on the taskwas 0.63 in terms of ?
(Siegel and Castellan,1988), whereby the main source of disagreementwas the presence of highly lexicalized metaphors,e.g.
verbs such as adopt, convey, decline etc.We then evaluated the system performance againsttheir judgements in terms of precision.
Precisionmeasures the proportion of metaphorical expres-sions that were tagged correctly among the onesthat were tagged.
We considered the expressionstagged as metaphorical by at least three annota-tors to be correct.
As a result our system identi-fies metaphor with the precision of 0.79, whereasthe baseline only attains 0.44.
Some examples ofsentences annotated by the system are shown inFigure 3.Such a striking discrepancy between the per-formance levels of the clustering approach andthe baseline can be explained by the fact that alarge number of metaphorical senses are includedin WordNet.
This means that in WordNet synsetssource domain verbs are mixed with more abstractterms.
For example, the metaphorical sense ofshape in shape opinion is part of the synset (de-1007termine, shape, mold, influence, regulate).
Thisresults in the baseline system tagging literal ex-pressions as metaphorical, erroneously assumingthat the verbs from the synset belong to the sourcedomain.The main source of confusion in the output ofour clustering method was the conventionality ofsome metaphorical expressions, e.g.
hold views,adopt traditions, tackle a problem.
The systemis capable of tracing metaphorical etymology ofconventional phrases, but their senses are highlylexicalized.
This lexicalization is reflected in thedata and affects clustering in that conventionalmetaphors are sometimes clustered together withliterally used terms, e.g.
tackle a problem and re-solve a problem, which may suggest that the lat-ter are metaphorical.
It should be noted, however,that such errors are rare.Since there is no large metaphor-annotated cor-pus available, it was impossible for us to reli-ably evaluate the recall of the system.
How-ever, the system identified a total number of 4456metaphorical expressions in the BNC starting witha seed set of only 62, which is a promising result.5 Related WorkOne of the first attempts to identify and inter-pret metaphorical expressions in text automati-cally is the approach of Fass (1991).
Fass devel-oped a system called met*, capable of discrimi-nating between literalness, metonymy, metaphorand anomaly.
It does this in three stages.
First,literalness is distinguished from non-literalnessusing selectional preference violation as an in-dicator.
In the case that non-literalness is de-tected, the respective phrase is tested for be-ing a metonymic relation using hand-coded pat-terns (such as CONTAINER-for-CONTENT).
Ifthe system fails to recognize metonymy, it pro-ceeds to search the knowledge base for a rele-vant analogy in order to discriminate metaphor-ical relations from anomalous ones.
E.g., thesentence in (5) would be represented in thisframework as (car,drink,gasoline), which doesnot satisfy the preference (animal,drink,liquid),as car is not a hyponym of animal.
met*then searches its knowledge base for a triplecontaining a hypernym of both the actual ar-gument and the desired argument and finds(thing,use,energy source), which represents themetaphorical interpretation.Birke and Sarkar (2006) present a sen-tence clustering approach for non-literal lan-guage recognition implemented in the TroFi sys-tem (Trope Finder).
This idea originates froma similarity-based word sense disambiguationmethod developed by Karov and Edelman (1998).The method employs a set of seed sentences,where the senses are annotated, computes simi-larity between the sentence containing the wordto be disambiguated and all of the seed sentencesand selects the sense corresponding to the anno-tation in the most similar seed sentences.
Birkeand Sarkar (2006) adapt this algorithm to performa two-way classification: literal vs. non-literal,and they do not clearly define the kinds of tropesthey aim to discover.
They attain a performanceof 53.8% in terms of f-score.The method of Gedigan et al (2006) discrimi-nates between literal and metaphorical use.
Theytrained a maximum entropy classifier for this pur-pose.
They obtained their data by extracting thelexical items whose frames are related to MO-TION and CURE from FrameNet (Fillmore et al,2003).
Then they searched the PropBank WallStreet Journal corpus (Kingsbury and Palmer,2002) for sentences containing such lexical itemsand annotated them with respect to metaphoric-ity.
They used PropBank annotation (argumentsand their semantic types) as features to train theclassifier and report an accuracy of 95.12%.
Thisresult is, however, only a little higher than the per-formance of the naive baseline assigning majorityclass to all instances (92.90%).
These numberscan be explained by the fact that 92.00% of theverbs of MOTION and CURE in the Wall StreetJournal corpus are used metaphorically, thus mak-ing the dataset unbalanced with respect to the tar-get categories and the task notably easier.Both Birke and Sarkar (2006) and Gedigan etal.
(2006) focus only on metaphors expressed bya verb.
As opposed to that the approach of Kr-ishnakumaran and Zhu (2007) deals with verbs,nouns and adjectives as parts of speech.
Theyuse hyponymy relation in WordNet and word bi-gram counts to predict metaphors at the sentence1008level.
Given an IS-A metaphor (e.g.
The world isa stage4) they verify if the two nouns involved arein hyponymy relation in WordNet, and if this isnot the case then this sentence is tagged as con-taining a metaphor.
Along with this they con-sider expressions containing a verb or an adjec-tive used metaphorically (e.g.
He planted goodideas in their minds or He has a fertile imagi-nation).
Hereby they calculate bigram probabil-ities of verb-noun and adjective-noun pairs (in-cluding the hyponyms/hypernyms of the noun inquestion).
If the combination is not observed inthe data with sufficient frequency, the system tagsthe sentence containing it as metaphorical.
Thisidea is a modification of the selectional prefer-ence view of Wilks.
However, by using bigramcounts over verb-noun pairs as opposed to verb-object relations extracted from parsed text Kr-ishnakumaran and Zhu (2007) loose a great dealof information.
The authors evaluated their sys-tem on a set of example sentences compiled fromthe Master Metaphor List (Lakoff et al, 1991),whereby highly conventionalized metaphors (theycall them dead metaphors) are taken to be neg-ative examples.
Thus, they do not deal with lit-eral examples as such: essentially, the distinc-tion they are making is between the senses in-cluded in WordNet, even if they are conventionalmetaphors, and those not included in WordNet.6 Conclusions and Future DirectionsWe presented a novel approach to metaphor iden-tification in unrestricted text using unsupervisedmethods.
Starting from a limited set of metaphor-ical seeds, the system is capable of capturing theregularities behind their production and annotat-ing a much greater number and wider range ofpreviously unseen metaphors in the BNC.Our system is the first of its kind and it is capa-ble of identifying metaphorical expressions with ahigh precision (0.79).
By comparing its coverageto that of a WordNet baseline, we proved that ourmethod goes far beyond synonymy and general-izes well over the source and target domains.
Al-though at this stage we tested our system on verb-subject and verb-object metaphors only, we are4William Shakespeareconvinced that the described identification tech-niques can be similarly applied to a wider rangeof syntactic constructions.
Extending the systemto deal with more parts of speech and types ofphrases is part of our future work.One possible limitation of our approach is thatit is seed-dependent, which makes the recall of thesystem questionable.
Thus, another important fu-ture research avenue is the creation of a more di-verse seed set.
We expect that a set of expres-sions representative of the whole variety of com-mon metaphorical mappings, already described inlinguistics literature, would enable the system toattain a very broad coverage of the corpus.
Mas-ter Metaphor List (Lakoff et al, 1991) and otherexisting metaphor resources could be a sensiblestarting point on a route to such a dataset.AcknowledgmentsWe are very grateful to our anonymous reviewersfor their useful feedback on this work and the vol-unteer annotators for their interest, time and help.This research is funded by generosity of Cam-bridge Overseas Trust (Katia Shutova), DorothyHodgkin Postgraduate Award (Lin Sun) and theRoyal Society, UK (Anna Korhonen).ReferencesAndersen, O. E., J. Nioche, E. Briscoe, and J. Carroll.2008.
The BNC parsed with RASP4UIMA.
In Pro-ceedings of LREC 2008, Marrakech, Morocco.Bergsma, S., D. Lin, and R. Goebel.
2008.
Discrimi-native learning of selectional preference from unla-beled text.
In Proceedings of the EMNLP.Birke, J. and A. Sarkar.
2006.
A clustering approachfor the nearly unsupervised recognition of nonlit-eral language.
In In Proceedings of EACL-06, pages329?336.Brew, C. and S. Schulte im Walde.
2002.
Spectralclustering for German verbs.
In Proceedings ofEMNLP.Briscoe, E., J. Carroll, and R. Watson.
2006.
The sec-ond release of the rasp system.
In Proceedings ofthe COLING/ACL on Interactive presentation ses-sions, pages 77?80.Burnard, L. 2007.
Reference Guide for the BritishNational Corpus (XML Edition).1009Chen, J., D. Ji, C. Lim Tan, and Z. Niu.
2006.
Un- Lin, D. 1998.
Automatic retrieval and clustering ofsupervised relation disambiguation using spectral similar words.
In Proceedings of the 17th inter-clustering.
In Proceedings of COLING/ACL.
national conference on Computational linguistics,pages 768?774.Fass, D. 1991. met*: A method for discriminatingmetonymy and metaphor by computer.
Computa- Martin, J. H. 1988.
Representing regularities in thetional Linguistics, 17(1):49?90.
metaphoric lexicon.
In Proceedings of the 12th con-ference on Computational linguistics, pages 396?Fellbaum, C., editor.
1998.
WordNet: An Electronic 401.Lexical Database (ISBN: 0-262-06197-X).
MITPress, first edition.
Meila, M. and J. Shi.
2001.
A random walks view ofspectral segmentation.
In AISTATS.Fillmore, C. J., C. R. Johnson, and M. R. L. Petruck.2003.
Background to FrameNet.
International Meila, M. 2001.
The multicut lemma.
Technical re-Journal of Lexicography, 16(3):235?250.
port, University of Washington.Gedigan, M., J. Bryant, S. Narayanan, and B. Ciric.
Pantel, P. and D. Lin.
2002.
Discovering word2006.
Catching metaphors.
In In Proceedings of the senses from text.
In Proceedings of the eighth ACM3rd Workshop on Scalable Natural Language Un- SIGKDD international conference on Knowledgederstanding, pages 41?48, New York.
discovery and data mining, pages 613?619.
ACM.Joanis, E., S. Stevenson, and D. James.
2008.
A gen- Pereira, F., N. Tishby, and L. Lee.
1993.
Distribu-eral feature space for automatic verb classification.
tional clustering of English words.
In ProceedingsNatural Language Engineering, 14(3):337?367.
of ACL-93, pages 183?190, Morristown, NJ, USA.Karov, Y. and S. Edelman.
1998.
Similarity-based Pragglejaz Group.
2007.
MIP: A method for iden-word sense disambiguation.
Computational Lin- tifying metaphorically used words in discourse.guistics, 24(1):41?59.
Metaphor and Symbol, 22:1?39.Kingsbury, P. and M. Palmer.
2002.
From TreeBank Preiss, J., T. Briscoe, and A. Korhonen.
2007.
A sys-to PropBank.
In Proceedings of LREC-2002, Gran tem for large-scale acquisition of verbal, nominalCanaria, Canary Islands, Spain.
and adjectival subcategorization frames from cor-pora.
In Proceedings of ACL-2007, volume 45, pageKipper, K., A. Korhonen, N. Ryant, and M. Palmer.
912.2006.
Extensive classifications of English verbs.In Proceedings of the 12th EURALEX International Resnik, P. 1993.
Selection and Information: A Class-Congress.
based Approach to Lexical Relationships.
Ph.D.thesis, Philadelphia, PA, USA.Korhonen, A., Y. Krymolowski, and Z. Marx.
2003.Clustering polysemic subcategorization frame dis- Resnik, P. 1997.
Selectional preference and sense dis-tributions semantically.
In Proceedings of ACL ambiguation.
In ACL SIGLEX Workshop on Tag-2003, Sapporo,Japan.
ging Text with Lexical Semantics, Washington, D.C.Korhonen, A., Y. Krymolowski, and T. Briscoe.
2006.
Rooth, M., S. Riezler, D. Prescher, G. Carroll, andA large subcategorization lexicon for natural lan- F. Beil.
1999.
Inducing a semantically annotatedguage processing applications.
In Proceedings of lexicon via EM-based clustering.
In Proceedings ofLREC 2006.
ACL 99, pages 104?111.Krishnakumaran, S. and X. Zhu.
2007.
Hunting elu- Schulte im Walde, S. 2006.
Experiments on the au-sive metaphors using lexical resources.
In Proceed- tomatic induction of German semantic verb classes.ings of the Workshop on Computational Approaches Computational Linguistics, 32(2):159?194.to Figurative Language, pages 13?20, Rochester,NY.
Shutova, E. and S. Teufel.
2010.
Metaphor corpusannotated for source - target domain mappings.
InLakoff, G. and M. Johnson.
1980.
Metaphors We Live Proceedings of LREC 2010, Malta.By.
University of Chicago Press, Chicago.
Shutova, E. 2010.
Automatic metaphor interpretationLakoff, G., J. Espenson, and A. Schwartz.
1991.
The as a paraphrasing task.
In Proceedings of NAACLmaster metaphor list.
Technical report, University 2010, Los Angeles, USA.of California at Berkeley.
Siegel, S. and N. J. Castellan.
1988.
NonparametricLevin, B.
1993.
English Verb Classes and Alterna- statistics for the behavioral sciences.
McGraw-Hilltions.
University of Chicago Press, Chicago.
Book Company, New York, USA.1010
