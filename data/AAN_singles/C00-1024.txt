A Multilingual News SummarizerIlsin-Hsi Chenl)epartlnent of Computer Science andInformation EngineeringNational Taiwan UniversityTaipei, TAIWAN, R.O.C.hh chen @csie.ntu.edu.twChuan-Jie LinDefmltment of Computer Science andInformation EngineeringNational Taiwan UniversityTaipei, TAIWAN, R.O.C.cjli n @ nlg2.csie.ntu.edu.twAbstractHuge multilingual news articles are reportedand disseminated on the Internet.
ltow toextract the kcy information and savc thereading time is a crucial issue.
This paperproposes architecture of multilingual newssumlnarizer, including monolingual andmultilingual clustering, similarity measureamong lneaningful ullits, and presentation ofsummarization results.
Translation anlongnews stories, idiosyncrasy among languages,itnplicit information, and user preference areaddressed.IntroductionToday many web sites on the lnternet provideonline news services.
Multilingual news articlesare reported periodically, and across geographicbarrier to disseminate to readers.
Readers canaccess the news stories conveniently, but it takesmuch time l'or people to read all tile news.
Thispaper will present a personal news secretariat thathelps on-line readers absorb news informationfrom multiple sources in different languages.Such a news secretariat eliminates the redundantinformation in tile news articles, reorganizes tilenews for readers, and helps them resolve thelanguage barriers.Reorganization of news is sonic sort ofdocument summarization, which creates a shortversion of original document.
Recently, manypapers touch on single document summarization(ltovy and Marcu, 1998a).
Only a few touch onmultiple document sulnmarization (Chen andHuang, 1999; Mani and Bloedorn, 1997; Radevand McKeown, 1998) and multilingual documentsummarization (Hovy and Marcu, 1998b).
Formultilingual multiple news summarization, severalissues have to be addressed:(1) Translation among news stories indifferent languagesThe basic idea in multiple doculnentsulnmarizations i  to identify which paris of newsarticles present similar reports.
Because thenews stories are in different languages, seine kindof Iranslation is required, e.g., term translation.Besides the problem of translation ambiguity,different news sites often use difl'erent names torefer tile same entity.
The translation o1' namedentities, which are usually ttnknown words, isanother probleln.
(2) Idiosyncrasy among languages1)ifferent languages have their own specificfeatures.
For example, a Chinese sentence iscomposed of characters without word boundary.Word segmentation is indispensable for Chinese.Besides, Chinese writers often assign l~unctuationntarks at randonl, how to determine a mealfingfulunit for similarity checking is a crucial issue.Thus seine tasks may be done for specificlanguages during SUlnmarization.
(3) hnplicit information in news reportsSome information is ilnplicit in news stories.For example, the name of a country is usually notmentioned in a news article reporting an event thathappened in that country.
On the contrary, thecountry name is important in foreign news.Besides, time zone is used to specify date/timeimplicitly in the news.
(4) User preferenceWhen users want to read documents in theirfamiliar languages, news fragments in some1599 ANt r:::Nl.lnlnlary N illllmal'y Sullllllary ,~ 11111111 al'yltlr l 'venl 1 for l ivent 2 for l ivem 3 for Event mFigure 1.
Architecture ofOur Multilingual Sunmmrization Systemlanguages are preferred to those in other languages.Even machine translation should be introduced totranslate news fragments.
Besides, if a userprefers the news from tile view of his country, ormore precisely, of some news sites, we shouldmeet his need.Figure 1 shows the architecture of amultilingual summarization system, which is usedto sulnmarize the news from multiple sources indifferent languages.
It is composed of threem~tior components: several monolingual newsclusterers, a multilingual news clusterer, and anews summarizer.
Tile monolingual newsclusterer receives a news stream from multiple on.-line newspapers in its respective language, anddirects them into several output news streams byusing events.
The multilingual news clustererthen matches and merges the news streams of thesame event but in different languages in a cluster.The news summarizer summarizes the newsstories for each event.The possible tasks for each componentdepend on the languages used.
Some major tasksof a monolingual clusterer are listed below.
(1) identifying word boundaries for Chineseand Japanese sentences,(2) Extracting named entities like people,place, organization, time, date and monetaryexpressions,(3) Clustering news streams based onpredefined topic set and named entities.The task for the multilingual clusterer is toalign the news clusters in the same topic set, but indifferent languages.
It is similar to documentalignment in comparable corpus.
Named entitiesare also useful cues.The major tasks for the news summarizer areshown as follows.
(1) Partitioning a news story into severalmeaningful units (MUs),(2) Linking the lneaningful units, denotingthe salne thing, from different news reports,(3) Displaying the summarization resultsunder the consideration of language type usersprefer, information decay and views of reporters.1.
Clustering1.1 Monolingual ClusteringWe adopt a two-level approach to cluster thenews t)o111 multiple sources.
At first, news isclassified on the basis of a predefined topic set.Then, tile news articles in the same topic set arepartitioned into several clusters according tonamed emities.
Classification is necessary.
Oiltile one hand, a famous person may appear inmany kinds of news stories.
For example,President Clinton may make a public speech(political news), join an international meeting(international news), or even just show up in theopening of a baseball game (sports news).
Onthe other hand, a common name is flequently seenbut denotes different persons.
Classificationreduces the ambiguity introduced by famouspersons and/or common names.An event in a news story is characterized byfive basic entities such as people, affairs, time,places and things.
These entities form importantcues during clustering.
Systems for named entityextraction in a famous lnessage understandingcompetition (MUC, 1998) demonstrate promisingperformances for English, Japanese and Chinese.In our multilingual summarization system, wefocus on English and Chinese.
Gazetteerapproach is adopted to deal with English newsarticles.
Comparatively, Chinese news articlesare segmented at first.
Then, several types ofinforlnation fiom character, sentence and textlevels are employed to extract Chinese named160entities.
These tasks are similar to tileapproaches ill tile papers (Chen and Lee, 1996;Chen, el al., 1998a).1.2 Multilingual ClusteringTile multilingual clusterer takes input fromthe lnonolingual clusterers, and determines whichnews clusters ill which languages talk about tilesame story.
Recall that a news cluster consists ofseveral news articles reporting tile same event, andone news cluster exists lbr one event arielmonolingual clustering.
Ill this way, there is atmost one corresponding news cluster ill anotherlanguage.
Therefore, the main task of themultilingual news clusterer is to lind tilematchings among tile clusters ill differentlanguages.
Figure 2 shows an example, illTopic !, cluster cHl is aligned to c itr, and clusterCil 2 is aligned to c.ili.
Clusters cii~z arid cjl 2 areleft unaligned.
That means the denoted eventsarc reported ill only one language.Similarity of two clusters is measured basedon verbs, named entities, and the other nouns.Because Chinese words are less anibiguolls tMnEnglish ones (Chen, Bian anti Lin, 1999), wetranslate nouns and verbs in the Chinese newsarticles into English.
If a word Ms more thanone translation, we select high fl-equent Englishtranslation.
For tile named enlities not listed illtile lexicon, name transliteration similar to tilealgoritlnn (Chen, el al., 1998b) is introduced formatching in non-alpMbetic (e.g., Clfinese) andalphabetic languages (e.g., English).Alignment is made under the same topic.
Anews chlster c i is aligried to another cluster cj iftheir similarity is above a threshold, and is tilehighest between q and the other clusters.
If tilesimilarity of q and the other clusters is less than agiven threshold, ci is not aligned.
It is possiblebecause local news is reported only ill tilerestricted areas.2.
Similarity Analysis2.1 Meauingful UnitsThe basic idea during smnmarization is to tellwhich parts of the news articles are similar in thesame event.
The basic unit tbr similaritymeasure may be a paragraph or a sentence.
ForLanguage l.,Language 1iTopic I Topic iITopic I Topic tFigure 2.
Matching among tile Clustersin Two Languagestile t'ormer, text segmentation is necessary fordocuments without paragraph markers (Chcn andChen, 1995).
For the latter, text segmentation isnecessary ibr languages like Chinese.
UnlikeEnglish writers, Chinese writers often assignpunctuat ion marks at random (Chen, 1994).Thus the sentence boundary is not clear.Consider the following Chinese example (C l):(Central News Agency, 1999.12.02)(Although they were undeterred by mass arrestsand a police crackdown, anti free-trade protestersstill marched on downtown Seattle today.
Theprotesters, carrying signs and chanting, opposedlhc global trade liberalization being worked on ata meeting of h+ade lninisters flom tile World TradeOrgani zat ion.
)It is composed of four sentence segmentsseparated by commas.
11' a sentence segment isregarded as a unit for similarity checking, it maycontain too little information.
On tile contrary, ifa sentence is regarded as a unit, it may contain toomuch M'ormation.
Here we consider ameaningful unit (MU) as a basic unit formeasurement.
A MU is composed of severalsentence segments and denotes a completemeaning.
We will find two MUs shown asfollows for (C 1):(Although they were undeterred by mass arrestsand a police crackdown, anti free-trade protestersstill marched on downtown Seattle today.
)161-~.~ .e- ~ 4-/5,-- " 5,(The protesters, carrying signs and chanting,opposed the global trade liberalization beingworked on at a meeting of trade ministers fl'om theWorld Trade Organization.
)In our summarization system, an Englishsentence itself is an MU.
Comparatively, it is alittle harder to identify Chinese MUs.
Threekinds of linguistic kuowledge- punctuation marks,linking elements and topic chaius, are proposed.
(1) Punctuation marksThere are fourteen marks in Chinese (Yang, 1981).Only period, question mark, exclamation mark,comma, semicolon and caesura mark areemployed.
The former three are sentenceterminators, and the latter three are segmentseparators.
(2) Linking elementsThere are three kinds of linking elements (Li andThompson, 1981): forward-linking elements,backward-linking elements, and couple-linkingelements.
A segment with a forward-linking(backward-linking) elemeut is linked with its next(previous) segment.
A couple-linking element isa pair of words that exist in two segments.Apparently, these two segments are joinedtogether.
Examples (C4)-(C6) show each ldnd oflinkings.
(C4) T~,~:-~,,..,-~ ' q~&d# g#~ ?
(After school, I wanted to see a movie.
)(I wanted to see a movie, but I couldn't get aticket.
)(C6) N -h&a-~ ~.
~'; g ' ,~a.rx & a_~-.-24 "~d:V4 o(Because I couldfft get a ticket, (so) 1 didn'tsee a movie.
)(3) Topic chainsThe topic of a clausal segment is usually deletedunder the identity with a topic in its precedingsegment.
The result of such a deleting process isa topic chain.
We employ part of speechinformation to predict if a subject of a verb ismissing.
If it does, we postulate that it mustappear in the previous segment and the twosegments are connected to form a larger unit.Consider example (C1).
The word "f'$ @"(although) is a forward linking element.
Thusthe first two segments are connected together (C2).The last segment does not have ally subject, sothat it is connected to the previous one by topicchain (C3).
In summary, two MUs are formed.2.2 Similarity ModelTile next step is to find the similarity amongMUs in the news articles reporting the same event,and to link the similar MUs together.
Weanalyze the news stories within the same language,and then the news stories among differentlanguages.
The key idea is similar at these twosteps.
That is, predicate argument structureforms the kernel of a sentence, thus verbs andnouns are regarded as important cues for similaritymeasures.
The difference between these twosteps is that we have to translate nouns and verbsin one language into another language.
Theapproach of select-high-frequent translation andname transliteration shown in Section 1.2 isadopted here too.
Consider (MUI) - (MU3).The former two are in Chinese and the last one isin English.
They denote a similar event"Seattle's Curfew Hours".
Each noun (verb) isenclosed by parentheses and assigned an index.There are 9 common terms between (MUI) and(MU2); 10 common terms between (MUI) and(MU3); and 8 common terms between (MU2) and(MU3).
Note the time zones used in (MU2) and(MUI) are different, so are (MU2) and (MU3).
(MU 1 ) .g (1 ~-J 5J~ N )(2 ~ ~ )(3 ~'~ ~ )(4 ~ )~I ~- ) ~'~ (52-~-(11~)~%) ( 12"qc2 }\]~)(13~\]~)(14>J" ;~v)"~ ' kl5 ;~G}I~"(16.T-.~")(,7,{g'a~) 1" (,s'?O" fl" '~) o(Chinatimes, 1999.12.02)(MU2) (, N~IflN)(2~-~v)(4Gdff), ~(5"1~)(6~}.~/N,~)(7(Formosa Television, 1999.12.02)(MU3) GSeattle) (2Mayor) (2sPaul) (3Schell) hasGdeclared) a (sState) of (scivil) (Temergency) and(13imposed) a (m7 p.m.) to (267:30 a.m) ((2v10 p.m.)EST - (2s10:30 a.m.) EST) (,4curfew) on(2,downtown) (29areas) of the (30city).
(Reuters)162(s2)(s3)($4)once .
(ss)Several strategies lnay be considered insimilarity measure:(SI) Nouns in one MU are matched to nouns inanother MU, so are verbs.The operations in (1) are exact matches.Thesauri are employed tu-ing matching.Each term specified in (S 1) is matched onlyTile order of llOUllS and verbs in MU is notconsidered.
($6) 'File order of nouns and verbs in MU iscritical, but it is relaxed within a window.
(S7) When continuous terms are matched, anextra score is added.
($8) When tile object o1: transitive verbs arc notmatched, a score is subtracled.
($9) When date/time xpressions and monetaryand percentage xpressions are matched, an extrascore is added.l;ive models shown below are collstrtlctedunder different combinations of tile strategiesspecified in tile above.
(M t) (S 1)+($3)+($4)+($5)(M2) (S 1)+($3)+($4)+($6)(M3) (S 1)+(S3)+(S4)+(S5)+($7)+($8)(M4) (S 1)+($3)+($4)+($5)+($7)+($8)+($9)(M5) (S I )+($2)+($4)+($5)+($7)+($8)+($9)3.
Experiments3.1 l ' reparat ion el'Testing CorpusSix events selected from Central l)aily News,China I)aily Newspaper, China Times Interactive,and FTV News Online in Taiwan arc used tolneasure tile performance of each lnodel.
Theyare shown as follows:(1) military service: 6 articles(2) construction permit: 4 articles(3) landslide in Shah Jr: 6 articles(4) Buslfs sons: 4 articles(5) Typhoon Babis: 3 articles(6) stabilization fund: 5 articlesThe news events are selected from differenteditions, including social edition, economicedition, international edition, political edition, etc.An annotator eads all tile news articles, andconnects tile MUs that discuss the same story.Because each MU is assigned a unique ID, thelinks among MUs form the answer keys for theperformance evaluation.Table I. Perf iwmance of Similarity of MUsModelM IM2M 3M4M5Precision Rate0.50000.48710.50800.51640.5243Recall Rate0.54340.3905(/.58880.61980.55793.2 ResullsTraditional precision and recall are computed.Table 1 lists the perfornmnce of these five models.M I is regarded as a baseline model.
M2 isdifferent l'ronl M1 in that the matching order ofnouns itl\](l verbs are kept conditionally.
It tries toconsider the subject-verl>object sequence.
Theexperiment shows that tile performance is worse.The major reason is that we c~ltl express the samemeaning using different syntactic structures.Movement ransformation may affect tile order ofsulkiest-verb-object.
Thus in M3 we give up theorder criterion, but we add an extra score whencontinuous terms are matched, l ind  subtract somescore when tile object of a transitive verb is notmatched.
Compared with M1, the precision is alittle higher, and tile recall is improved about 4.5%.If we further consider some special named entitiessuch as date/time xpressions and monetary andpercentage expressions in M4, tile recall isincreased about 7.6% at no expense of precision.M5 tries Io estimate tile function of tile thesauri.It uses exact matching.
Tile precision is a littlehigher but the recall is decreased abollt G%compared with M4.Several m~\ior errors affect tile overallperformance.
Using nouns and verbs to find thesimilar MUs is not always workable.
Tile samemeaning may not be expressed in terms of thesame words or synonymous words.
Besides, wecan use different format to express monetary andpercentage xpressions.
Word segmentation isanother source of errors.
Two sentencesdenoting tile similar meaning may be segmenteddifferently clue to tile segmentation strategies.Unknown words generate many single-characterwords.
After tagging, these words tend to benOUllS and verbs, which are used in computing tilescores for similarity measure.
Thus errors maybe introduced.1634.
Presentation ModelTwo models, i.e., focusing inodel andbrowsing model, are proposed to display thesumlnarization results.
In the focusing model, aSUlnlnarization is presented by voting fi'omreporters.
For each event, a reporter ecords anews story from his own viewpoint.
Recall thata news article is composed of several MUs.Those MUs that are similar in a specific event areCOlnmon focuses of different reporters.
In otherwords, they are worthy of reading.
In the currentilnplementation, the MUs that are reported morethan once are our target.
For readability, theoriginal sentences that cover the MUs are selected.For each set of similar MUs, the longest sentencein user-preferred language is displayed.
Thedisplay order of the selected sentences isdetermined by relative position in the originalnews articles.In the browsing lnodel, the news articles arelisted by information decay.
The first newsarticle is shown to the user in its whole content.In the latter shown news articles, the MUsdenoting the inforlnation mentioned before areshadowed (or eliminated), so that the reader canfocus on the new information.
The alnount ofinformation in a news article is lneasured in termsof the number of MUs, so that the article thatcontains lnore MUs is displayed before the others.For readability, a sentence is a display unit.
Inthis model, users can read both the COlnmon viewsand different views of reporters.
It saves thereading time by listing the colnlno11 view onlyonce.5.
Evaluation of Sumnmrization ResultsThe same six events specified in Section 3.1are used to measure the performance of the twosummarization models.
Three kinds of metricsare considered - say, the document reduction rate,the reading-tilne reduction rate, and theinforlnation carried.
The higher the documentreduction rate is, the more time the reader maysave, but the higher possibility the ilnportantinformation may be lost.
Tables 2 and 3 list thedocument reduction rates for focusing andbrowsing summarization, respectively.
Onlyfocuses are displayed in focusing sutnmarization,Table 2.
Reduction Rates forFocusing SummarizationEvent Name l)ocl,en Sum Len Sum/l)oc \[ Reductionmililary service 7658 2402 0.3137 68.63%construction permit 4182 1226 0.2932 70.68%laMslide in Shah ,It" 5491 1823 0.3320 66.80%Busies sons 6186 924 0.1494 85.06%Typhoon Babis 4068 1460 0.3589 64.
I 1%stabilization ftmd 8434 2243 0.2659 73.41%Average 36019 10078 0.2798 72.02%Table 3.
Reduction Ratesfor Browsing SummarizationEvent Name Doc Len Sum Len + Sum/l)oc Reductionmilitary service 7658 2716 0.3547 64.53%construclion permit 4182 2916 0.6973 30.27%landslide in Shah Jr 5491 2946 0.5365 46.35%Buslfs sons 6186 5098 0.8241 17.59%Typhoon Babis 4068 2270 0.5580 44.20%stabilization fund 8434 4299 0.5(197 49.03%Average 36(/19 20245 0 .5621 43.79%Table 4.
Assessors' EvaluationEvent Name Document Question- Reading-TimeReduction Answering ReductionRate Correct Rate Ratemilitary service 64.53% 10(1% 45.24%3/I.27% 33.33% 33.54% construction permitlandslide in Shah J|" 46.35% 80% I 10.28%gush's oils 17.59% 100% I 36.49%Typhoon Babis 44.20% 100% 35.10%stabilization fund 49.03% 100% 18.49~Average 43.79% 88.46% 3(/.86%so that the average doculnent reduction rate ishigher than that of browsing summarization.Besides the document reduction rate, we alsomeasure the correct rate of question-answering,and reading-time reduction rate.
Assessors readthe highlight parts only in the browsingsummarization, and answer 3 to 5 questions.Table 4 lists the evaluation results of the sixevents.
The average doculnent reduction rate is43.79%.
On the average, the summary saves30.86% of reading time.
While reading thesummary only, the correct rate of question-answering task is 88.46%.ConclusionThis paper sketches architecture formultilingual news summarizer.
In multilingualclustering, lnatching all pairs of news clusters inall languages is time-exhaustive.
Because onlyEnglish and Chinese news articles are consideredin this paper, it is not a problem.
In general, an164effective way is to predefine a sequence oflanguage pairs according to the degree oftranslation ambiguity.
The hmguage pair of lessambiguity is tried first.To discuss which fi'agments of multilingualnews stories denote the salne things, this paperdefines the concept of MUs.
Punctuation marks,linking elements and topic chains are cues toidentify MUs for Chinese.
Select-high-frequentEnglish translation and name transliteration areadopted to transhtte Chinese MUs into L;nglish.Five models are proposed to link the similar MUstogether.
Different formats used in time, dateand monetary expressions, e.g., implicit time zone,affect the performance of linking.
It should bestudied in the fllture.In presentation o1' summarization results, theinformation decay strategy helps reduce theredundancy, and the user can get al theinformation provided by the news sites.However, the news sequence is not presentedaccording to the importance.
The user may quitreading and miss the information not shown yet.The voting strategy from reporters gives a shortersummarization in terlnS of user-preferredlanguages.
However, it also misses some uniqueinformation reported only by one site.
A hybridstrategy should be developed in the future to meetall the requirements.ReferencesChen, H.H.
(1994) "The Contextual Analysis ofChinese Sentences with Punctuation Marks," Litelwlaud Linguistic Computing, Oxford University Press,9(4), 1994, pp.
281-289.Chen, H.H; et al (1998a) "Descriplion of the NTUSystem Used for MET2."
Proceedings of 7 a'Message Undel:s'tanding Conference, 1998.Chen, H.H.
; et al (1998b) "Proper Name Translation inCross-Language Information Retrieval," Proceedingsof COLING-A CL98, 1998, pp.
232-236.Chen, H.H.
; Bian, G.W.
and Lin, W.C. (1999)"Resolving Translation Ambiguily and TargetPolysemy in Cross-Language Inli)rmation Retriewd,"PJweeedings of 37 'l' Auroral Meeting of theAssociation./'or Conqmtational Linguistics, 1999, pp.215-222.Chert, K.H.
and Chert, H.H.
(1995)"A Corpus-BasedApproach to Text Partition," Pivceedings ofInternational Col!/'erenee of Recent Advances onNatural Language Processing, Tzigov Chark,Bulgaria, 1995, pp.
152-160.Chen, ILH.
and Huang, S.J.
(1999) "A SunnnarizationSystem for Chinese News from Multiple Sources,"Proceedings of 4 't' International Workshop onlqformation Retrieval with Asia l~nguages, 1999, pp.1-7.Chert, H.H.
and Lee, J.C. (1996) "Identification andClassification of Proper Nouns in Chinese Texts,"Proceedings" of 16th International Conference onComputational Linguistics, 1996, pp.
222-229.Hovy, E. and Mareu, D. (1998a) Automated TextSmmnaHzation, Tutorial in 17 'h ACL attd 36 '~'COLING, Montreal, Quebec, Canada, 1998.Hovy, E. and Marcu, D. (1998b) Multilingual TextSummarization, Tutorial in AMTA-98, 1998.IA, C.N.
and Thompson, S.A. (1981) MandarinChinese: A Functional Re\[erence Giwmmar,University of California Press, 1981.Mani, I. and Bloedorn, E. (1997) "Multi-documenlSummarizalion by Graph Search and Matching,"Proceedings of the Fourteenth National Con.lisrenceoil Arti/icial Intelligence, Providence, RI, pp.
622-628.MUC (1998) Ptvceedings of 7 ~1' Message{hMet:s'tanding Cot!ferenc.e, http://www.muc.saic.corn/proceedings/proceedings index.broil.P, adev, I).P,.
and McKeown, K.R.
(1998)"GeneratingNatural Language Summaries from Multiple On-LineSources," Computational Linguistics, Vol.
24, No.
3,pp.
469-500.Yang, Y.
(1981) The Research on lhmetuation Marks,Tian-iian Publishing Company, ltong Kong, 1981.165
