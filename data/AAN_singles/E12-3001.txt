Proceedings of the EACL 2012 Student Research Workshop, pages 1?10,Avignon, France, 26 April 2012. c?2012 Association for Computational LinguisticsImproving Pronoun Translation for Statistical Machine TranslationLiane GuillouSchool of InformaticsUniversity of EdinburghEdinburgh, UK, EH8 9ABL.K.Guillou@sms.ed.ac.ukAbstractMachine Translation is a well?establishedfield, yet the majority of current systemstranslate sentences in isolation, losing valu-able contextual information from previ-ously translated sentences in the discourse.One important type of contextual informa-tion concerns who or what a coreferringpronoun corefers to (i.e., its antecedent).Languages differ significantly in how theyachieve coreference, and awareness of an-tecedents is important in choosing the cor-rect pronoun.
Disregarding a pronoun?s an-tecedent in translation can lead to inappro-priate coreferring forms in the target text,seriously degrading a reader?s ability to un-derstand it.This work assesses the extent to whichsource-language annotation of coreferringpronouns can improve English?Czech Sta-tistical Machine Translation (SMT).
Aswith previous attempts that use this method,the results show little improvement.
Thispaper attempts to explain why and to pro-vide insight into the factors affecting per-formance.1 IntroductionIt is well-known that in many natural languages,a pronoun that corefers must bear similar featuresto its antecedent.
These can include similar num-ber, gender (morphological or referential), and/oranimacy.
If a pronoun and its antecedent occur inthe same unit of translation (N-gram or syntactictree), these agreement features can influence thetranslation.
But this locality cannot be guaranteedin either phrase-based or syntax-based StatisticalMachine Translation (SMT).
If it is not within thesame unit, a coreferring pronoun will be trans-lated without knowledge of its antecedent, mean-ing that its translation will simply reflect local fre-quency.
Incorrectly translating a pronoun can re-sult in readers/listeners identifying the wrong an-tecedent, which can mislead or confuse them.There have been two recent attempts to solvethis problem within the framework of phrase-based SMT (Hardmeier & Federico, 2010; LeNagard & Koehn, 2010).
Both involve anno-tation projection, which in this context meansannotating coreferential pronouns in the source-language with features derived from the transla-tion of their aligned antecedents, and then build-ing a translation model of the annotated forms.When translating a coreferring pronoun in a newsource-language text, the antecedent is identifiedand its translation used (differently in the two at-tempts cited above) to annotate the pronoun priorto translation.The aim of this work was to better understandwhy neither of the previous attempts achievedmore than a small improvement in translationquality associated with coreferring pronouns.Only by understanding this will it be possible toascertain whether the method of annotation pro-jection is intrinsically flawed or the unexpectedlysmall improvement is due to other factors.Errors can arise when:1.
Deciding whether or not a third person pro-noun corefers;2.
Identifying the pronoun antecedent;3.
Identifying the head of the antecedent, whichserves as the source of its features;4.
Aligning the source and target texts at thephrase and word levels.1Factoring out the first two decisions wouldshow whether the lack of significant improvementwas simply due to imperfect coreference resolu-tion.
In order to control for these errors severaldifferent manually annotated versions of the PennWall Street Journal corpus were used, each pro-viding different annotations over the same text.The BBN Pronoun Coreference and Entity Typecorpus (Weischedel & Brunstein, 2005) was usedto provide coreference information in the source-language and exclude non-referential pronouns.It also formed the source-language side of theparallel training corpus.
The PCEDT 2.0 cor-pus (Hajic?
et al 2011), which contains a closeCzech translation of the Penn Wall Street Journalcorpus, provided reference translations for test-ing and the target-language side of the parallelcorpus for training.
To minimise (although notcompletely eliminate) errors associated with an-tecedent head identification (item 3 above), theparse trees in the Penn Treebank 3.0 corpus (Mar-cus et al 1999) were used.
The gold stan-dard annotation provided by these corpora al-lowed me to assume perfect identification of core-ferring pronouns and coreference resolution andnear?perfect antecedent head noun identification.These assumptions could not be made if state-of-the-art methods had been used as they cannot yetachieve sufficiently high levels of accuracy.The remainder of the paper is structured as fol-lows.
The use of pronominal coreference in En-glish and Czech and the problem of anaphora res-olution are described in Section 2.
The worksof Le Nagard & Koehn (2010) and Hardmeier& Federico (2010) are discussed in Section 3,and the source-language annotation projectionmethod is described in Section 4.
The results arepresented and discussed in Section 5 and futurework is outlined in Section 6.2 Background2.1 Anaphora ResolutionAnaphora resolution involves identifying the an-tecedent of a referring expression, typically a pro-noun or noun phrase that is used to refer to some-thing previously mentioned in the discourse (itsantecedent).
Where multiple referring expres-sions refer to the same antecedent, they are said tobe coreferential.
Anaphora resolution and the re-lated task of coreference resolution have been thesubject of considerable research within NaturalLanguage Processing (NLP).
Excellent surveysare provided by Strube (2007) and Ng (2010).Unresolved anaphora can add significant trans-lation ambiguity, and their incorrect translationcan significantly decrease a reader?s ability to un-derstand a text.
Accurate coreference in trans-lation is therefore necessary in order to produceunderstandable and cohesive texts.
This justifiesrecent interest (Le Nagard & Koehn, 2010; Hard-meier & Federico, 2010) and motivates the workpresented in this paper.2.2 Pronominal Coreference in EnglishWhilst English makes some use of case, it lacksthe grammatical gender found in other languages.For monolingual speakers, the relatively few dif-ferent pronoun forms in English make sentenceseasy to generate: Pronoun choice depends on thenumber and gender of the entity to which they re-fer.
For example, when talking about ownershipof a book, English uses the pronouns ?his/her?to refer to a book that belongs to a male/femaleowner, and ?their?
to refer to one with multi-ple owners (irrespective of their gender).
Onesource of difficulty is that the pronoun ?it?
hasboth a coreferential and a pleonastic function.
Apleonastic pronoun is one that is not referential.For example, in the sentence ?It is raining?, ?it?does not corefer with anything.
Coreference res-olution algorithms must exclude such instances inorder to prevent the erroneous identification of anantecedent when one does not exist.2.3 Pronominal Coreference in CzechCzech, like other Slavic languages, is highly in-flective.
It is also a free word order language, inwhich word order reflects the information struc-ture of the sentence within the current discourse.Czech has seven cases and four grammatical gen-ders: masculine animate (for people and animals),masculine inanimate (for inanimate objects), fem-inine and neuter.
(With feminine and neuter gen-ders, animacy is not grammatically marked.)
InCzech, a pronoun must agree in number, genderand animacy with its antecedent.
The morpho-logical form of possessive pronouns depends notonly on the possessor but also the object in pos-session.
Moreover, reflexive pronouns (both per-sonal and possessive) are commonly used.
In ad-dition, Czech is a pro-drop language, whereby an2explicit subject pronoun may be omitted if it is in-ferable from other grammatical features such asverb morphology.
This is in contrast with En-glish which exhibits relatively fixed Subject-Verb-Object (SVO) order and only drops subject pro-nouns in imperatives (e.g.
?Stop babbling?)
andcoordinated VPs.Differences between the choice of coreferringexpressions used in English and Czech can beseen in the following simple examples:1.
The dog has a ball.
I can see it playing out-side.2.
The cow is in the field.
I can see it grazing.3.
The car is in the garage.
I will take it to work.In each example, the English pronoun ?it?refers to an entity that has a different gender inCzech.
Its correct translation requires identifyingthe gender (and number) of its antecedent and en-suring that the pronoun agrees.
In 1 ?it?
refers tothe dog (?pes?, masculine, animate) and shouldbe translated as ?ho?.
In 2, ?it?
refers to the cow(?kra?va?, feminine) and should be translated as?ji?.
In 3, ?it?
refers to the car (?auto?, neuter)and should be translated as ?ho?.In some cases, the same pronoun is used forboth animate and inanimate masculine genders,but in general, different pronouns are used.
Forexample, with possessive reflexive pronouns inthe accusative case:English: I admired my (own) dogCzech: Obdivoval jsme sve?ho psaEnglish: I admired my (own) castleCzech: Obdivoval jsme svu?j hradHere ?sve?ho?
is used to refer to a dog (mascu-line animate, singular) and ?svu?j?
to refer to a cas-tle (masculine inanimate, singular), both of whichbelong to the speaker.Because a pronoun may take a large numberof morphological forms in Czech and becausecase is not checked in annotation projection, themethod presented here for translating coreferringpronouns does not guarantee their correct form.3 Related WorkEarly work on integrating anaphora resolutionwith Machine Translation includes the rule-basedapproaches of Mitkov et al(1995) and Lappin &Leass (1994) and the transfer-based approach ofSaggion & Carvalho (1994).
Work in the 1990?sculminated in the publication of a special issueof Machine Translation on anaphora resolution(Mitkov, 1999).
Work then appears to have beenon hold until papers were published by Le Na-gard & Koehn (2010) and Hardmeier & Federico(2010).
This resurgence of interest follows ad-vances since the 1990?s which have made new ap-proaches possible.The work described in this paper resembles thatof Le Nagard & Koehn (2010), with two main dif-ferences.
The first is the use of manually anno-tated corpora to extract coreference informationand morphological properties of the target trans-lations of the antecedents.
The second lies in thechoice of language pair.
They consider English-French translation, focussing on gender-correcttranslation of the third person pronouns ?it?
and?they?.
Coreference is more complex in Czechwith both number and gender influencing pronounselection.
Annotating pronouns with both num-ber and gender further exacerbates the problem ofdata sparseness in the training data, but this can-not be avoided if the aim is to improve their trans-lation.
This work also accommodates a widerrange of English pronouns.In contrast, Hardmeier & Federico (2010) focuson English-German translation and model coref-erence using a word dependency module inte-grated within the log-linear SMT model as an ad-ditional feature function.Annotation projection has been used elsewherein SMT.
Gimpel & Smith (2008) use it to capturelong?distance phenomena within a single sen-tence in the source-language text via the extrac-tion of sentence-level contextual features, whichare used to augment SMT translation models andbetter predict phrase translation.
Projection tech-niques have also been applied to multilingualWord Sense Disambiguation whereby the senseof a word may be determined in another language(Diab, 2004; Khapra et al 2009).4 Methodology4.1 OverviewI have followed Le Nagard & Koehn (2010) in us-ing a two-step approach to translation, with anno-tation projection incorporated as a pre-processing3It stands on a hill.The castle is old.
Hrad je star?.It stands on a hill.The castle is old.Hrad je star?.It.mascin.sg stands on a hill.Masculine inanimate, singularTranslate:Translate:Input:The castle is old.
It stands on a hill.
(1) Identification ofcoreferential pronoun(2) Identification ofantecedent head(3) English ?
Czech mappingof antecedent head(4) Extraction of numberand gender of Czech word(5) Annotation of English pronoun withnumber and gender of Czech wordFigure 1: Overview of the Annotation Processtask.
In the first step, pronouns are annotated inthe source-language text before the text is trans-lated by a phrase-based SMT system in the secondstep.
This approach leaves the translation pro-cess unaffected.
In this work, the following pro-nouns are annotated: third person personal pro-nouns (except instances of ?it?
that are pleonasticor that corefer with clauses or VPs), reflexive per-sonal pronouns and possessive pronouns, includ-ing reflexive possessives.
Relative pronouns areexcluded as they are local dependencies in bothEnglish and Czech and this work is concernedwith the longer range dependencies typically ex-hibited by the previously listed pronoun types.Annotation of the English source-languagetext and its subsequent translation into Czech isachieved using two phrase-based translation sys-tems.
The first, hereafter called the Baseline sys-tem, is trained using English and Czech sentence?aligned parallel training data with no annotation.The second system, hereafter called the Annotatedsystem, is trained using the same target data, butin the source-language text, each coreferring pro-noun has been annotated with number, gender andanimacy features.
These are obtained from theexisting (Czech reference) translation of the headof its English antecedent.
Word alignment of En-glish and Czech is obtained from the PCEDT 2.0alignment file which maps English words to theircorresponding t-Layer (deep syntactic, tectogram-matical) node in the Czech translation.
Startingwith this t-Layer node the annotation layers of thePCEDT 2.0 corpus are traversed and the numberand gender of the Czech word are extracted fromthe morphological layer (m-Layer).The Baseline system serves a dual purpose.
Itforms the first stage of the two-step translationprocess, and as described in Section 5, it providesa baseline against which Annotated system trans-lations are compared.The annotation process used here is shownin Figure 1.
It identifies coreferential pronounsand their antecedents using the annotation in theBBN Pronoun Coreference and Entity Type cor-pus, and obtains the Czech translation of the En-glish antecedent from the translation producedby the Baseline system.
Because many an-tecedents come from previous sentences, thesesentences must be translated before translating thecurrent sentence.
Here I follow Le Nagard &Koehn (2010) in translating the complete source-language text using the Baseline system and thenextracting the (here, Czech) translations of the En-glish antecedents from the output.
This providesa simple solution to the problem of obtaining theCzech translation prior to annotation.
In contrastHardmeier & Federico (2010) translate sentenceby sentence using a process which was deemedto be more complex than was necessary for thisproject.The English text is annotated such that allcoreferential pronouns whose antecedents have anidentifiable Czech translation are marked with thenumber and gender of that Czech word.
The out-put of the annotation process is thus the same En-glish text that was input to the Baseline system,with the addition of annotation of the coreferen-tial pronouns.
This annotated English text is thentranslated using the Annotated translation system,the output of which is the final translation.4Training Dev.
FinalParallel Sentences 47,549 280 540Czech Words 955,018 5,467 10,110English Words 1,024,438 6,114 11,907Table 1: Sizes of the training and testing datasets4.2 Baseline and Annotated systemsBoth systems are phrase-based SMT models,trained using the Moses toolkit (Hoang et al2007).
They share the same 3-gram languagemodel constructed from the target-side text ofthe parallel training corpus and the Czech mono-lingual 2010 and 2011 News Crawl corpora1.The language model was constructed using theSRILM toolkit (Stolcke, 2002) with interpolatedKneser-Ney discounting (Kneser & Ney, 1995).In addition, both systems are forced to use thesame word alignments (constructed using Giza++(Och & Ney, 2003) in both language pair direc-tions and using stemmed training data in whichwords are limited to the first four characters) inorder to mitigate the effects of Czech word in-flection on word alignment statistics.
This helpsto ensure that the Czech translation of the headof the antecedent remains constant in both stepsof the two-step process.
If this were to change itwould defeat the purpose of pronoun annotationas different Czech translations could result in dif-ferent gender and/or number.The Baseline system was trained using thePenn Wall Street Journal corpus with no anno-tation, while the Annotated system was trainedwith an annotated version of the same text (seeTable 1), with the target-language text being thesame in both cases.
The Penn Wall Street Journalcorpus was annotated using the process describedabove, with the number and gender of the Czechtranslation of the antecedent head obtained fromthe PCEDT 2.0 alignment file.4.3 Processing test filesTwo test files were used (see Table 1) ?
one called?Final?
and the other, ?Development?
(Dev).
A testfile is first translated using the Baseline systemwith a trace added to the Moses decoder.
Eachcoreferential English pronoun is then identifiedusing the BBN Pronoun Coreference and EntityType corpus and the head of its antecedent is ex-1Provided for the Sixth EMNLP Workshop on StatisticalMachine Translation (Callison-Burch et al 2011)tracted from the annotated NPs in the Penn Tree-bank 3.0 corpus.
The sentence number and wordposition of the English pronoun and its antecedenthead noun(s) are extracted from the input Englishtext and used to identify the English/Czech phrasepairs that contain the Czech translations of the En-glish words.
Using this information together withthe phrase alignments (output by the Moses de-coder) and the phrase-internal word alignmentsin the phrase translation table, a Czech transla-tion is obtained from the Baseline system.
Num-ber, gender and animacy (if masculine) featuresof the Czech word identified as the translationof the head of the antecedent are extracted froma pre-built morphological dictionary of Czechwords constructed from the PCEDT 2.0 corpusfor the purpose of this work.
A copy of theoriginal English test file is then constructed, witheach coreferential pronoun annotated with the ex-tracted Czech features.The design of this process reflects two assump-tions.
First, the annotation of the Czech wordsin the m-Layer of the PCEDT 2.0 corpus is bothaccurate and consistent.
Second, as the Base-line and Annotated systems were trained using thesame word alignments, the Czech translation ofthe head of the English antecedent should be thesame in the output of both.
Judging by the verysmall number of cases in which the antecedenttranslations differed (3 out of 458 instances), thisassumption was proved to be reasonable.
Thesedifferences were due to the use of different phrasetables for each system as a result of training ondifferent data (i.e.
the annotation of English pro-nouns or lack thereof).
This would not be an is-sue for single-step translation systems such as thatused by Hardmeier & Federico (2010).4.4 EvaluationNo standard method yet exists for evaluating pro-noun translation in SMT.
Early work focussed onthe development of techniques for anaphora reso-lution and their integration within Machine Trans-lation (Lappin & Leass, 1994; Saggion & Car-valho, 1994; Mitkov et al 1995), with little men-tion of evaluation.
In recent work, evaluationhas become much more important.
Both Le Na-gard & Koehn (2010) and Hardmeier & Federico(2010) consider and reject BLEU (Papineni et al2002) as ill-suited for evaluating pronoun transla-tion.
While Hardmeier & Federico propose and5use a strict recall and precision based metric forEnglish?German translation, I found it unsuitablefor English?Czech translation, given the highlyinflective nature of Czech.Given the importance of evaluation to the goalof assessing the effectiveness of annotation pro-jection for improving the translation of corefer-ring pronouns, I carried out two separate typesof evaluation ?
an automated evaluation whichcould be applied to the entire test set, and an in-depth manual assessment that might provide moreinformation, but could only be performed on asubset of the test set.
The automated evaluationis based on the fact that a Czech pronoun mustagree in number and gender with its antecedent.Thus one can count the number of pronouns in thetranslation output for which this agreement holds,rather than simply score the output against a sin-gle reference translation.
To obtain these figures,the automated evaluation process counted:1.
Total pronouns in the input English test file.2.
Total English pronouns identified as corefer-ential, as per the annotation of the BBN Pro-noun Coreference and Entity Type corpus.3.
Total coreferential English pronouns that areannotated by the annotation process.4.
Total coreferential English pronouns that arealigned with any Czech translation.5.
Total coreferential English pronouns trans-lated as any Czech pronoun.6.
Total coreferential English pronouns trans-lated as a Czech pronoun corresponding toa valid translation of the English pronoun.7.
Total coreferential English pronouns trans-lated as a Czech pronoun (that is a validtranslation of the English pronoun) agreeingin number and gender with the antecedent.The representation of valid Czech translationsof English pronouns takes the form of a list pro-vided by an expert in Czech NLP, which ignorescase and focusses solely on number and gender.In contrast, the manual evaluation carried outby that same expert, who is also a native speakerof Czech, was used to determine whether devi-ations from the single reference translation pro-vided in the PCEDT 2.0 corpus were valid alter-natives or simply poor translations.
The followingjudgements were provided:1.
Whether the pronoun had been translatedcorrectly, or in the case of a dropped pro-noun, whether pro-drop was appropriate;2.
If the pronoun translation was incorrect,whether a native Czech speaker would stillbe able to derive the meaning;3.
For input to the Annotated system, whetherthe pronoun had been correctly annotatedwith respect to the Czech translation of itsidentified antecedent;4.
Where an English pronoun was translateddifferently by the Baseline and Annotatedsystems, which was better.
If both translatedan English pronoun to a valid Czech transla-tion, equal correctness was assumed.In order to ensure that the manual assessorwas directed to the Czech translations alignedto the English pronouns, additional markup wasautomatically inserted into the English and Czechtexts: (1) coreferential pronouns in both Englishand Czech texts were marked with the headnoun of their antecedent (denoted by *), and(2) coreferential pronouns in the English sourcetexts were marked with the Czech translationof the antecedent head, and those in the Czechtarget texts were marked with the original Englishpronoun that they were aligned to:English text input to the Baseline system: the u.s., claiming some success in its trade diplomacy , ...Czech translation output by the Baseline system:usa , tvrd??
ne?kter???
jej??
(its) obchodn??
u?spe?ch v diplo-macii , ...English text input to the Annotated system: theu.s.
* , claiming some success in its(u.s.,usa).mascin.pltrade diplomacy , ...Czech translation output by the Annotated sys-tem: usa ,* tvrd??
ne?kter???
u?spe?chu ve sve?(its.mascin.pl)obchodn??
diplomacii , ...5 Results and Discussion5.1 Automated EvaluationAutomated evaluation of both ?Development?and ?Final?
test sets (see Table 2) shows that evenfactoring out the problems of accurate identifica-tion of coreferring pronouns, coreference resolu-tion and antecedent head?finding, does not im-prove performance of the Annotated system muchabove that of the Baseline.6Dev.
FinalBaseline Annotated Baseline AnnotatedTotal pronouns in English file 156 156 350 350Total pronouns identified as coreferential 141 141 331 331Annotated coreferential English pronouns ?
117 ?
278Coreferential English pronouns aligned with any Czech translation 141 141 317 317Coreferential English pronouns translated as Czech pronouns 71 75 198 198Czech pronouns that are valid translations of the English pronouns 63 71 182 182Czech pronouns that are valid translations of the English pronounsand that match their antecedent in number and gender44 46 142 146Table 2: Automated Evaluation Results for both test setsCriterion Baseline System Better Annotated System Better Systems EqualOverall quality 9/31 (29.03%) 11/31 (35.48%) 11/31 (35.48%)Quality when annotation is correct 3/18 (16.67%) 9/18 (50.00%) 6/18 (33.33%)Table 3: Manual Evaluation Results: A direct comparison of pronoun translations that differ between systemsTaking the accuracy of pronoun translation tobe the proportion of coreferential English pro-nouns having a valid Czech translation that agreesin both number and gender with their antecedent,yields the following on the two test sets:Baseline system:Development ?
44/141 (31.21%)Final ?
142/331 (42.90%)Annotated system:Development ?
46/141 (32.62%)Final ?
146/331 (44.10%)There are, however, several reasons for not tak-ing this evaluation as definitive.
Firstly, it relieson the accuracy of the word alignments output bythe decoder to identify the Czech translations ofthe English pronoun and its antecedent.
Secondly,these results fail to capture variation between thetranslations produced by the Baseline and Anno-tated systems.
Whilst there is a fairly high de-gree of overlap, for approximately 1/3 of the ?De-velopment?
set pronouns and 1/6 of the ?Final?set pronouns, the Czech translation is different.Since the goal of this work was to understandwhat is needed in order to improve the transla-tion of coreferential pronouns, manual evaluationwas critical for understanding the potential capa-bilities of source-side annotation.5.2 Manual EvaluationThe sample files provided for manual evaluationcontained 31 pronouns for which the translationsprovided by the two systems differed (differences)and 72 for which the translation provided by thesystems was the same (matches).
Thus, the sam-ple comprised 103 of the 472 coreferential pro-nouns (about 22%) from across both test sets.
Ofthis sample, it is the differences that indicate therelative performance of the two systems.
Of the31 pronouns in this set, 16 were 3rd-person pro-nouns, 2 were reflexive personal pronouns and 13were possessive pronouns.The results corresponding to evaluation crite-rion 4 in Section 4.4 provide a comparison of theoverall quality of pronoun translation for both sys-tems.
These results for the ?Development?
and?Final?
test sets (see Table 3) suggest that the per-formance of the Annotated system is comparablewith, and even marginally better than, that of theBaseline system, especially when the pronoun an-notation is correct.An example of where the Annotated systemproduces a better translation than the Baselinesystem is:Annotated English: he said mexico could be one of thenext countries to be removed from the priority list because ofits.neut.sg efforts to craft a new patent law .Baseline translation: r?ekl , z?e mexiko by mohl by?t jedenz dals??
?ch zem??
, aby byl odvola?n z prioritou seznam , protoz?ejej??
snahy podpor?it nove?
patentovy?
za?kon .Annotated translation: r?ekl , z?e mexiko by mohl by?t je-den z dals??
?ch zem??
, aby byl odvola?n z prioritou seznam ,protoz?e jeho snahy podpor?it nove?
patentovy?
za?kon .In this example, the English pronoun ?its?,which refers to ?mexico?
is annotated as neuterand singular (as extracted from the Baseline trans-lation).
Both systems translate ?mexico?
as?mexiko?
(neuter, singular) but differ in theirtranslation of the pronoun.
The Baseline systemtranslates ?its?
incorrectly as ?jej???
(feminine, sin-gular), whereas the Annotated system produces7the more correct translation: ?jeho?
(neuter, sin-gular), which agrees with the antecedent in bothnumber and gender.An analysis of the judgements on the remain-ing three evaluation criteria (outlined in Section4.4) for the 31 differences provides further infor-mation.
The Baseline system appears to be moreaccurate, with 19 pronouns either correctly trans-lated (in terms of number and gender) or appro-priately dropped, compared with 17 for the An-notated system.
Of those pronouns, the meaningcould still be understood for 7/12 for the Baselinesystem compared with 8/14 for the Annotated sys-tem.
On the surface this may seem strange but itappears to be due to a small number of cases inwhich the translations produced by both systemswere incorrect but those produced by the Anno-tated system were deemed to be marginally better.Due to the small sample size it is difficult to forma complete picture of where one system may per-form consistently better than the other.
The anno-tation of both number and gender was accurate for18 pronouns.
Whilst this accuracy is not particu-larly high, the results (see Table 3) suggest thattranslation is more accurate for those pronounsthat are correctly annotated.Whilst pro-drop in Czech was not explicitlyhandled in the annotation process, manual evalu-ation revealed that both systems were able to suc-cessfully ?learn?
a few (local) scenarios in whichpro-drop is appropriate.
This was unexpected butfound to be due to instances in which there areshort distances between the pronoun and verb inEnglish.
For example, many of the occurrencesof ?she?
in English appear in the context of ?shesaid...?
and are translated correctly with the verbform ?...r?ekla...
?.An example of where the Annotated systemcorrectly drops a pronoun is:Annotated English: ?
this is the worst shakeout ever inthe junk market , and it could take years before it.fem.sg ?s over , ?
says mark bachmann , a senior vice president atstandard & poor ?
s corp .
, a credit rating company .Baseline translation: ?
je to nejhors???
krize , kdy na trhus rizikovy?mi obligacemi , a to mu?z?e trvat roky , nez?
je to pryc?, ?
r???ka?
mark bachmann , hlavn??
viceprezident spolec?nostistandard & poor ?s corp .
, u?ve?rovy?
rating spolec?nosti .Annotated translation: ?
je to nejhors???
krize , kdy natrhu s rizikovy?mi obligacemi , a to mu?z?e trvat roky , nez?je !!
pryc?
, ?
r???ka?
mark bachmann , hlavn??
viceprezidentspolec?nosti standard & poor ?s corp .
, u?ve?rovy?
ratingspolec?nosti .In this example, the Baseline system trans-lates ?it?
incorrectly as the neuter singular pro-noun ?to?, whereas the Annotated system cor-rectly drops the subject pronoun (indicated by !!)?
this is a less trivial example than ?she said?.
Inthe case of the Baseline translation ?to?
could beinterpreted as referring to the whole event, whichwould be correct, but poor from a stylistic pointof view.An example of where the Annotated systemfails to drop a pronoun is:Annotated English: taiwan has improved its.mascin.sg*standing with the u.s. by initialing a bilateral copyrightagreement , amending its.mascin.sg** trademark law andintroducing legislation to protect foreign movie producersfrom unauthorized showings of their.mascan.pl films .Annotated translation: tchaj-wan zleps?en??
sve?postaven??
s usa o initialing bilatera?ln?
?ch autorsky?ch pra?v najeho obchodn??
dohody , u?prava za?kona a zaveden??
za?konana ochranu zahranic?n??
filmove?
producenty z neopra?vne?ne?showings svy?ch filmu?
.Reference translation: tchaj-wan zleps?il svou reputaciv usa , kdyz?
podepsal bilatera?ln??
smlouvu o autorsky?chpra?vech , pozme?nil !!
za?kon o ochranny?ch zna?mka?ch azavedl legislativu na ochranu zahranic?n?
?ch filmovy?ch produ-centu?
proti neautorizovane?mu prom??ta?n??
jejich filmu?
.In this example, the English pronoun ?its?,which refers to ?taiwan?
is annotated as mascu-line inanimate and singular.
The first occurrenceof ?its?
is marked by * and the second occurrenceby ** in the annotated English text above.
Thesecond occurrence should be translated either asa reflexive pronoun (as the first occurrence is cor-rectly translated) or it should be dropped as in thereference translation (!!
indicates the position ofthe dropped pronoun).In addition to the judgements, the manual as-sessor also provided feedback on the evalua-tion task.
One of the major difficulties encoun-tered concerned the translation of pronouns insentences which exhibit poor syntactic structure.This is a criticism of Machine Translation as awhole, but of the manual evaluation of pronountranslation in particular, since the choice of core-ferring form is sensitive to syntactic structure.Also the effects of poor syntactic structure arelikely to introduce an additional element of sub-jectivity if the assessor must first interpret thestructure of the sentences output by the transla-tion systems.5.3 Potential Sources of ErrorRelated errors that may have contributed to theAnnotated system not providing a significant im-provement over the Baseline include: (1) incor-8rect identification of the English antecedent headnoun, (2) incorrect identification of the Czechtranslation of the antecedent head noun in theBaseline output due to errors in the word align-ments, and (3) errors in the PCEDT 2.0 align-ment file (affecting training only).
While ?per-fect?
annotation of the BBN Pronoun Coreferenceand Entity Type, the PCEDT 2.0 and the PennTreebank 3.0 corpora has been assumed, errors inthese corpora cannot be completely ruled out.6 Conclusion and Future WorkDespite factoring out three major sources of er-ror ?
identifying coreferential pronouns, findingtheir antecedents, and identifying the head of eachantecedent ?
through the use of manually anno-tated corpora, the results of the Annotated systemshow only a small improvement over the Baselinesystem.
Two possible reasons for this are that thestatistics in the phrase translation table have beenweakened in the Annotated system as a result ofincluding both number and gender in the anno-tation and that the size of the training corpus isrelatively small.However, more significant may be the avail-ability of only a single reference translation.
Thisaffects the development and application of au-tomated evaluation metrics as a single referencecannot capture the variety of possible valid trans-lations.
Coreference can be achieved without ex-plicit pronouns.
This is true of both English andCzech, with sentences that contain pronouns hav-ing common paraphrases that lack them.
For ex-ample,the u.s. , claiming some success in its tradediplomacy , ...can be paraphrased as:the u.s. , claiming some success in trade diplo-macy , ...A target-language translation of the formermight actually be a translation of the latter, andhence lack the pronoun shown in bold.
Given therange of variability in whether pronouns are usedin conveying coreference, the availability of onlya single reference translation is a real problem.Improving the accuracy of coreferential pro-noun translation remains an open problem in Ma-chine Translation and as such there is great scopefor future work in this area.
The investigation re-ported here suggests that it is not sufficient to fo-cus solely on the source-side and further opera-tions on the target side (besides post-translationapplication of a target-language model) need alsobe considered.
Other target?side operations couldinvolve the extraction of features to score multi-ple candidate translations in the selection of the?best?
option ?
for example, to ?learn?
scenar-ios in which pro-drop is appropriate and to selecttranslations that contain pronouns of the correctmorphological inflection.
This requires identifica-tion of features in the target side, their extractionand incorporation in the translation process whichcould be difficult to achieve within a purely sta-tistical framework given that the antecedent of apronoun may be arbitrarily distant in the previousdiscourse.The aim of this work was to better understandwhy previous attempts at using annotation projec-tion in pronoun translation showed less than ex-pected improvement.
Thus it would be beneficialto conduct an error analysis to show the frequencyof the errors described in Section 5.3 appear.I will also be exploring other directions re-lated to problems identified during the course ofthe work completed to date.
These include, butare not limited to, handling pronoun dropping inpro-drop languages, developing pronoun-specificautomated evaluation metrics and addressing theproblem of having only one reference translationfor use with such metrics.
In this regard, I will beconsidering the use of paraphrase techniques togenerate synthetic reference translations to aug-ment an existing reference translation set.
Ini-tial efforts will focus on adapting the approach ofKauchak & Barzilay (2006) and back?translationmethods for extracting paraphrases (Bannard &Callison-Burch, 2005) to the more specific prob-lem of pronoun variation.AcknowledgementsI would like to thank Bonnie Webber (Univer-sity of Edinburgh) who supervised this projectand Marke?ta Lopatkova?
(Charles University) whoprovided the much needed Czech language assis-tance.
I am very grateful to Ondr?ej Bojar (CharlesUniversity) for his numerous helpful suggestionsand to the Institute of Formal and Applied Lin-guistics (Charles University) for providing thePCEDT 2.0 corpus.
I would also like to thankWolodja Wentland and the three anonymous re-viewers for their feedback.9ReferencesColin Bannard and Chris Callison-Burch.
2005.
Para-phrasing with Bilingual Parallel Corpora.
In Pro-ceedings of the 43rd Annual Meeting of the ACL,pages 597?604.Chris Callison-Burch, Philipp Koehn, Christof Monzand Omar Zaidan.
2011.
Findings of the 2011Workshop on Statistical Machine Translation.
InProceedings of the Sixth Workshop on StatisticalMachine Translation, pages 22?64.Mona Diab.
2004.
An Unsupervised Approach forBootstrapping Arabic Sense Tagging.
In Proceed-ings of the Workshop on Computational Approachesto Arabic Script-based Languages, pages 43?50.Kevin Gimpel and Noah A. Smith.
2008.
RichSource-Side Context for Statistical Machine Trans-lation.
In Proceedings of the Third Workshop onStatistical Machine Translation, pages 9?17.Barbara J. Grosz, Scott Weinstein and Aravind K.Joshi.
1995.
Centering: A Framework for Mod-eling the Local Coherence Of Discourse.
Computa-tional Linguistics, 21(2):203?225.Christian Hardmeier and Marcello Federico.
2010.Modelling Pronominal Anaphora in Statistical Ma-chine Translation.
In Proceedings of the 7th In-ternational Workshop on Spoken Language Trans-lation, pages 283?290.Philipp Koehn, Hieu Hoang, Alexandra Birch,Chris Callison-Burch, Marcello Federico, NicolaBertoldi, Brooke Cowan, Wade Shen, ChristineMoran, Richard Zens.
Chris Dyer, Ondr?ej Bojar,Alexandra Constantin and Evan Herbst.
2007.Moses: Open Source Toolkit for Statistical Ma-chine Translation.
In Proceedings of the 45th An-nual Meeting of the ACL on Interactive Poster andDemonstration Sessions, pages 177?180.Jerry R. Hobbs.
1978.
Resolving Pronominal Refer-ences.
Lingua, 44:311?338.Jan Hajic?, Eva Hajic?ova?, Jarmila Panevova?, Petr Sgall,Silvie Cinkova?, Eva Fuc??
?kova?, Marie Mikulova?,Petr Pajas, Jan Popelka, Jir???
Semecky?, JanaS?indlerova?, Jan S?te?pa?nek, Josef Toman, Zden?kaUres?ova?
and Zdene?k Z?abokrtsky?.
2011.
PragueCzech-English Dependency Treebank 2.0.
Instituteof Formal and Applied Linguistics.
Prague, CzechRepublic.David Kauchak and Regina Barzilay.
2006.
Para-phrasing For Automatic Evaluation.
In Proceedingsof the Main Conference on Human Language Tech-nology Conference of the NAACL, June 5?7, NewYork, USA, pages 455?462.Mitesh M. Khapra, Sapan Shah, Piyush Kedia andPushpak Bhattacharyya.
2009.
Projecting Param-eters for Multilingual Word Sense Disambiguation.In Proceedings of the 2009 Conference on Empiri-cal Methods in Natural Language Processing, Au-gust 6?7, Singapore, pages 459?467.Reinhard Kneser and Hermann Ney.
1995.
Im-proved Backing-Off for M-gram Language Model-ing.
IEEE International Conference on Acoustics,Speech, and Signal Processing, May 9?12, Detroit,USA, 1:181?184.Shalom Lappin and Herbert J. Leass.
1994.
An Algo-rithm for Pronominal Anaphora Resolution.
Com-putational Linguistics, 20:535?561.Ronan Le Nagard and Philipp Koehn.
2010.
Aid-ing Pronoun Translation with Co-reference Resolu-tion.
In Proceedings of the Joint Fifth Workshop onStatistical Machine Translation and MetricsMATR,pages 252?261.Vincent Ng.
2010.
Supervised Noun Phrase Corefer-ence Research: The first 15 years.
In Proceedingsof the 48th Meeting of the ACL, pages 1396?1411.Mitchell P. Marcus, Beatrice Santorini, Mary A.Marcinkiewicz and Ann Taylor.
1999.
Penn Tree-bank 3.0 LDC Calalog No.
: LDC99T42.
LinguisticData Consortium.Ruslan Mitkov, Sung-Kwon Choi and Randall Sharp.1995.
Anaphora Resolution in Machine Transla-tion.
In Proceedings of the Sixth International Con-ference on Theoretical and Methodological Issuesin Machine Translation, July 5-7, Leuven, Belgium,pages 5?7.Ruslan Mitkov.
1999.
Introduction: Special Issue onAnaphora Resolution in Machine Translation andMultilingual NLP.
Machine Translation, 14:159?161.Franz J. Och and Hermann Ney.
2003.
A SystematicComparison of Various Statistical Alignment Mod-els.
Computational Linguistics, 29(1):19?51.Kishore Papineni, Salim Roukos, Todd Ward and Wei-Jing Zhu.
2002.
BLEU: a method for automaticevaluation of machine translation.
In Proceedingsof the 40th Annual Meeting of the ACL, pages 311?318.Horacio Saggion and Ariadne Carvalho.
1994.Anaphora Resolution in a Machine Translation Sys-tem.
In Proceedings of the International Con-ference on Machine Translation: Ten Years On,November, Cranfield, UK, 4.1-4.14.Andreas Stolcke.
2002.
SRILM ?
An ExtensibleLanguage Modeling Toolkit.
In Proceedings of In-ternational Conference on Spoken Language Pro-cessing, September 16-20, Denver, USA, 2:901?904.Michael Strube.
2007.
Corpus-based and Ma-chine Learning Approaches to Anaphora Resolu-tion.
Anaphors in Text: Cognitive, Formal andApplied Approaches to Anaphoric Reference, JohnBenjamins Pub Co.Ralph Weischedel and Ada Brunstein.
2005.
BBNPronoun Coreference and Entity Type Corpus LDCCalalog No.
: LDC2005T33.
Linguistic Data Con-sortium.10
