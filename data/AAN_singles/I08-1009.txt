A More Discerning and Adaptable Multilingual Transliteration Mechanismfor Indian LanguagesHarshit SuranaLanguage Tech.
Research CentreIIIT, Hyderabad, Indiasurana.h@gmail.comAnil Kumar SinghLanguage Tech.
Research CentreIIIT, Hyderabad, Indiaanil@research.iiit.ac.inAbstractTransliteration is the process of transcribingwords from a source script to a target script.These words can be content words or propernouns.
They may be of local or foreign ori-gin.
In this paper we present a more dis-cerning method which applies different tech-niques based on the word origin.
The tech-niques used also take into account the prop-erties of the scripts.
Our approach does notrequire training data on the target side, whileit uses more sophisticated techniques on thesource side.
Fuzzy string matching is used tocompensate for lack of training on the targetside.
We have evaluated on two Indian lan-guages and have achieved substantially bet-ter results (increase of up to 0.44 in MRR)than the baseline and comparable to the stateof the art.
Our experiments clearly show thatword origin is an important factor in achiev-ing higher accuracy in transliteration.1 IntroductionTransliteration is a crucial factor in Cross LingualInformation Retrieval (CLIR).
It is also importantfor Machine Translation (MT), especially when thelanguages do not use the same scripts.
It is the pro-cess of transforming a word written in a source lan-guage into a word in a target language without theaid of a resource like a bilingual dictionary.
Wordpronunciation is usually preserved or is modified ac-cording to the way the word should be pronouncedin the target language.
In simple terms, it meansfinding out how a source word should be written inthe script of the target languages such that it is ac-ceptable to the readers of the target language.One of the main reasons of the importance oftransliteration from the point of view of Natural Lan-guage Processing (NLP) is that Out Of Vocabulary(OOV) words are quite common since every lexi-cal resource is very limited in practical terms.
Suchwords include named entities, technical terms, rarelyused or ?difficult?
words and other borrowed words,etc.
The OOV words present a challenge to NLP ap-plications like CLIR and MT.
In fact, for very closelanguages which use different scripts (like Hindi andUrdu), the problem of MT is almost an extension oftransliteration.A substantial percentage of these OOV wordsare named entities (AbdulJaleel and Larkey, 2003;Davis and Ogden, 1998).
It has also been shownthat cross language retrieval performance (averageprecision) reduced by more than 50% when namedentities in the queries were not transliterated (Larkeyet al, 2003).Another emerging application of transliteration(especially in the Indian context) is for building in-put methods which use QWERTY keyboard for peo-ple who are more comfortable typing in English.The idea is that the user types Roman letters butthe input method transforms them into letters of In-dian language (IL) scripts.
This is not as simpleas it seems because there is no clear mapping be-tween Roman letters and IL letters.
Moreover, theoutput word should be a valid word.
Several com-mercial efforts have been started in this directiondue to the lack of a good (and familiar) input mech-64anism for ILs.
These efforts include the GoogleTransliteration mechanism1 and Quilpad2.
(Rathodand Joshi, 2002) have also developed more intuitiveinput mechanisms for phonetic scripts like Devana-gari.Our efforts take into account the type of the word,the similarities among ILs and the characteristics ofthe Latin and IL scripts.
We use a sophisticated tech-nique and machine learning on the source language(English) side, while a simple and light technique onthe target (IL) side.
The advantage of our approachis that it requires no resources except unannotatedcorpus (or pages crawled from the Web) on the ILside (which is where the resources are scarce).
Themethod easily generalizes to ILs which use Brahmiorigin scripts.
Our method has been designed suchthat it can be used for more conventional applica-tions (MT, CLIR) as well as for applications likebuilding an input mechanism.Much of the work for transliteration in ILs hasbeen done from one Indian script to another.
Oneof the major work is of Punjabi machine transliter-ation (Malik, 2006).
This work tries to address theproblem of transliteration for Punjabi language fromShahmukhi (Arabic script) to Gurmukhi using a setof transliteration rules (character mappings and de-pendency rules).
Om transliteration scheme (Gana-pathiraju et al, 2005) also provides a script repre-sentation which is common for all Indian languages.The display and input are in human readable Romanscript.
Transliteration is partly phonetic.
(Sinha,2001) had used Hindi Transliteration used to handleunknowns in MT.naukri (A popular domain name) 722,000nokri (domain name) 19,800naukari 10,500naukary (domain name) 5,490nokari 665naukarii 133naukaree 102Table 1: Variations of a Hindi Word nOkarI (job).The numbers are pages returned when searching onGoogle.1www.google.co.in/press/pressrel/news transliteration.html2www.quillpad.comAswani et.
al (Aswani and Gaizauskas, 2005)have used a transliteration similarity mechanism toalign English-Hindi parallel texts.
They used char-acter based direct correspondences between Hindiand English to produce possible transliterations.Then they apply edit distance based similarity to se-lect the most probable transliteration in the Englishtext.
However, such method can only be appropriatefor aligning parallel texts as the number of possiblecandidates is quite small.The paper is structured as follows.
In Section-2, we discuss the problem of a high degree of vari-ation in Indian words, especially when written inLatin script.
In Section-3, we explain the idea ofusing information about the word origin for improv-ing transliteration.
Then in Section-4 we describethe method that we use for guessing the word origin.Once the word origin is guessed, we can apply oneof the two methods for transliteration depending onthe word origin.
These two methods are described inSection-5 and Section-6, respectively.
Fuzzy stringmatching, which plays an important role in our ap-proach, is described in Section-7.
In Section-8 weput together all the elements covered in the pre-ceding sections and explain the Discerning Adapt-able Transliteration Mechanism.
Section-9 presentsthe evaluation of our approach in comparison withtwo baseline methods, one of which uses knowledgeabout word origin.
Finally, in Section-10 we presentthe conclusions.2 Variation in Indian Words in LatinScriptSince the purpose of our work is not only to translit-erate named entities but to be useful for applicationslike input mechanisms, we had to consider someother issues too which may not be considered di-rectly related to transliteration.
One of these is thatthere is a lot of spelling variation in ILs.
This vari-ation is much more when the IL words are writtenusing the Latin script (Table-1).
In other words,the amount of ambiguity is very high when we tryto build a system that can be used for purposeslike designing input mechanisms, instead of just fortransliteration of NEs etc.
for MT or CLIR.
Onereason for very high variation in the latter case isthat unlike Romaji for Japanese (which is taught in65schools in Japan), there is no widely adopted translit-eration scheme using the Latin script, although thereare a number of standard schemes, which are notused by common users.
At present the situation isthat most Indians use Indian scripts while writing inILs, but use the Latin script when communicatingonline.
ILs are rarely used for official communica-tion, except in government offices in some states.3 Word Origin and Two Ways ofTransliterationPrevious work for other languages has shown thatword origin plays a part in how the word shouldbe transliterated(Oh and Choi, 2002; May et al,2004).
Llitjos and Black (Llitjos and Black, 2001)had shown that the knowledge of language origincan substantially improve pronunciation generationaccuracy.
This information has been used to get bet-ter results (Oh and Choi, 2002).
They first checkedwhether the word origin is Greek or not before se-lecting one of the two methods for transliteration.This approach improved the results substantially.However, they had used a set of prefixes and suffixesto identify the word origin.
Such an approach is notscalable.
In fact, in a large number of cases, wordorigin cannot be identified by using list of affixes.For ILs, we also define two categories of words:words which can be roughly considered Indian andthose which can be roughly considered foreign.Note that ?Indian?
and ?foreign?
are just loose labelshere.
Indian words, which include proper nouns andalso common vocabulary words, are more relevant inapplications like input methods.
Two different meth-ods are used for transliterating, as explained later.4 Disambiguating Word OriginPreviously (Llitjos and Black, 2001) used probabili-ties of all trigrams to belong to a particular languageas an measure to disambiguate word origins.
Weuse a more sophisticated method that has been suc-cessfully used for language and encoding identifica-tion (Singh, 2006a).We first prepare letter based 5-gram models fromthe lists of two kinds of words (Indian and foreign).Then we combine n-grams of all orders and rankthem according to their probability in descending or-der.
Only the top N n-grams are retained and therest are pruned.
Now we have two probability dis-tributions which can be compared by a measure ofdistributional similarity.
The measure used is sym-metric cross entropy or SCE (Singh, 2006a).Since the accuracy of identification is low if testdata is very low, which is true in our case because weare trying to identify the class of a single word, wehad to extend the method used by Singh.
One ma-jor extension was that we add word beginning andending markers to all the words in training as wellas test data.
This is because n-grams at beginning,middle and end of words should be treated differ-ently if we want to identify the ?language?
(or class)of the word.For every given word, we get a probability aboutits origin based on SCE.
Based on this probabilitymeasure, transliteration is performed using differenttechniques for different classes (Indian or foreign).In case of ambiguity, transliteration is performed us-ing both methods and the probabilities are used toget the final ranking of all possible transliterations.5 Transliteration of Foreign WordsThese words include named entities (George Bush)and more common nouns (station, computer) whichare regularly used in ILs.
To generate translitera-tion candidates for such words, we first try to guessthe word pronunciation or use a lookup dictionary (ifavailable) to find it.
Then we use some simple man-ually created mappings, which can be used for all In-dian languages.
Note that these mappings are veryfew in number (Figure-1 and Figure-2) and can beeasily created by non-linguistically trained people.They play only a small role in the method becauseother steps (like fuzzy string matching) do most ofthe work.For our experiments, we used the CMU speechdictionary as the lookup, and also to train pronunci-ation estimation.
If a word is not in the CMU dic-tionary, we estimate the word pronunciation, as ex-plained later.We directly map from English phonemes to IL let-ters.
This is based on our observation that a foreignword is usually transliterated in almost the same wayas it is pronounced.
Almost all English phonemescan be roughly mapped to specific letters (repre-senting phonemes, as IL scripts are phonetic in na-66ture) in ILs.
Similar observations have been madeabout Hindi by Su-Youn Yoon, Kyoung-Young Kimand Richard Sproat (Yoon et al, 2007).
We haveprepared our own mappings with help from nativespeakers of the languages concerned, which is rel-atively quite a simple task since the letters in Indicscripts correspond closely with phonemes.6 Transliteration of Indian WordsThese words include (mainly Indian) named enti-ties of (e.g.
Taj Mahal, Manmohan Singh) andcommon vocabulary words (common nouns, verbs)which need to be transliterated.
They also includewords which are spelled similar to the way Indianwords are spelled when written in Latin (e.g.
Bagh-dad, Husain).
As stated earlier, this class of wordsare much more relevant for an input method using aQWERTY keyboard.Since words of Indian origin usually have pho-netic spellings when they are written in English(Latin), the issue of pronunciation estimation orlookup is not important.
However, there can bemany possible vowel and consonant segments whichcan be formed out of a single word.
For example?ai?
can be interpreted as a single vowel with soundAE (as in Husain), or as two vowels AA IH (as inRai).
To perform segmentation, we have a simpleprogram which produces candidates for all possiblesegments.
This program uses a few rules definingthe possible consonant and vowel combinations.Now we simply map these segments to their near-est IL letters (or letter combinations).
This is alsodone using a simple set of mappings, which do notcontain any probabilities or contexts.
This step gen-erates transliteration candidates.
These are then fil-tered and ranked using fuzzy string matching.7 Fuzzy String MatchingThe initial steps use simpler methods to generatetransliteration candidates on the source as well asthe target side.
They also use no resources on thetarget (IL) side.
The step of fuzzy string matchingcompensates for the lack of more language specificknowledge during the earlier phase.
The transliter-ation candidates are matched with the words in thetarget language corpus (actually, words in the wordlist extracted from the corpus).
The fuzzy stringFigure 1: Mappings for foreign words.
The threecolumns are for Roman, Devanagari and Telugumatching algorithm we use is finely tuned for IndianLanguages and performs much better than languageindependent approaches like edit distance (Singh etal., 2007).
This method can be used for all the lan-guages which use Abugida scripts, e.g.
Hindi, Ben-gali, Telugu, Amharic, Thai etc.
It uses characteris-tics of a writing system for fuzzy search and is ableto take care of spelling variation, which is very com-mon in these languages.
This method shows an im-provement in F-measure of up to 30% over scalededit distance.The method for fuzzy string matching is basedon the Computational Phonetic Model of Scriptsor CPMS (Singh, 2006b), which models scripts(specifically Indic scripts) in terms of phonetic (ar-ticulatory) and orthographic features.
For calculat-ing the distance between two letters it uses a SteppedDistance Function (SDF).
Each letter is representedas a vector of features.
Then, to calculate the dis-tance between two strings, it uses an adapted ver-sion of the Dynamic Time Warping algorithm (My-67Figure 2: Mappings for Indian Wordsers, 1980).
In the fuzzy string matching method thatwe use (Singh et al, 2007), an akshar (roughly asyllable) is used as the unit, instead of a letter.8 Discerning Adaptable TransliterationMechanism (DATM)We use the above mentioned steps to transliterate agiven word based on its origin.
In case of ambigu-ity of word origin both methods are used, and pos-sible transliterations are ranked.
Based on the classof the word, the possible pronunciations (for foreignwords) and the possible segmentations (for Indianwords) are generated.
Then, for foreign words, En-glish phonemes are mapped to IL segments.
For In-dian words, Latin segments are mapped to IL seg-ments.Now, the transliteration candidates are matchedwith target language words, using the fuzzy textsearch method (Singh et al, 2007).
Possible translit-erations are ranked based on three parameters: wordfrequency, text search cost and the probability ofthe word belonging to the class through which itForeignWords Indian WordsWord Class IdentifierPronounciationGuesserWordSegmentationEnglish Phonemes toIL Segments MapsLatin Segments toIL Segments MapsPossiblePronounciationsPossibleSegmentationsFuzzy String MatchingTransliterationCandidatesRankedTransliterationsFigure 3: Block Diagram of the Discerning AdaptiveTransliteration Method (DATM)is transliterated.
A block diagram describing themethod is shown in Figure-3.
The ranks are obtainedon the basis of a score which is calculated using thefollowing formula:Tt =log(ft) ?
p(C | s)cost(c, t) + K (1)where Tt is the transliteration score for the tar-get word t, ft is the frequency of t in the target lan-guage corpus, C is the word class (foreign or In-dian), s is the source word, c is a transliteration can-didate which has been generated depending on thepredicted class C , p(C|s) is the probability of theclass C given s, cost(c, t) is the cost of fuzzy stringmatching between c and t, and finally K is a con-stant which determines how much weight is given tothe cost of fuzzy string matching.9 EvaluationWe evaluate our method for two major languages ofIndia: Hindi and Telugu.
We compare our resultswith a very commonly used method (Oh and Choi,2006) based on bilingual dictionary to learn translit-68Language ?
English-Hindi English-TeluguMethod ?
MRR Pr MRR PrDATM 0.87 80% 0.82 71%DBL 0.56 47% 0.53 46%BL 0.43 35% 0.43 37%DATM: Discerning Adaptive Transliteration MechanismDBL: Discerning Baseline MethodBL: Baseline MethodMRR: Mean Reciprocal RankPr: PrecisionTable 2: Evaluation on English-Hindi and English-Teluguerations.
As there are no bilingual transliterationdictionaries available for ILs, we had to create ourown resources.9.1 Experimental SetupWe created 2000-word lists which consisted of bothforeign and Indian words written in Latin scriptand their transliterations in Hindi and Telugu.
Thisdictionary was created by people with professionalknowledge in both English and the respective In-dian language.
We only use this list for trainingthe baseline method, as our method does not needtraining data on the target side.
The size of bilingualword lists that we are using is less than those usedfor experiments by some other researchers.
But ourapproach focuses on developing transliterations forlanguages with resource scarcity.
This setup is moremeaningful for languages with scarce resources.Since, normal transliteration mechanisms do notconsider word origin, we train the baseline usingthe set of 2000 words containing both foreign andIndian words.
Alignments from English to respec-tive Indian languages were learned by aligning theselists using GIZA++.
The alignments obtained werefed into a maximum entropy classifier with a con-text window size of 2 (3 is generally consideredbetter window size, but because the training sizeis not huge, a context window of 3 gave substan-tially worse results).
This method is similar tothe grapheme based model as described by Oh andChoi (Oh and Choi, 2006).
However, unlike intheir approach, the candidate pairs are matched withwords in the target language and are ranked basedon edit distance (BL).For our method (DATM), we have used CMU dic-tionary and a collection of Indian named entities(written in Latin) extracted from web to train thelanguage identification module.
We have consid-ered n-grams of order 5 and pruned them by 3500frequency.
In case the foreign word is not found inCMU Speech dictionary, we guess its pronunciationusing the method described by Oh and Choi.
How-ever, in this case, the context window size is 3.We also use another method (DBL) to check thevalidity of our assumptions about word origin.
Weuse the same technique as BL, but in this case wetrain two models of 1000 words each, foreign andIndian.
To disambiguate which model to use, weuse the same language identification method as inDATM.9.2 ResultsTo evaluate our method we have created word listsof size 200 which were doubly checked by two indi-viduals.
These also contain both Indian and Foreignwords.
We use both precision and mean reciprocalrank (MRR) to evaluate our method against base-line (BL) and discerning baseline (DBL).
MRR isa measure commonly used in information retrievalwhen there is precisely one correct answer (Kandorand Vorhees, 2000).
Results can be seen in Table-2.
The highest scores were obtained for Hindi usingDATM.
The MRR in this case was 0.87.One important fact that comes out from the re-sults is that determining the class of a word and thenusing an appropriate method can lead to significantincrease in performance.
This is clear from the re-sults for BL and DBL.
The only difference between69English-Hindi0204060801001201401601801 2 3 4 5RankNumberofWordsDATMDBLBLEnglish-Telugu0204060801001201401601 2 3 4 5RankNumberofWordsDATMDBLBLFigure 4: Number of Correct Words vs. Rank.
A significantly higher percentage of correct words occurat rank 1 for the DATM method, as compared to BL and DBL methods.
This percentage indicates a morepractical view of the accuracy transliteration algorithm.these two was that two different models were trainedfor the two classes.
Then the class of the word wasidentified (in DBL) and the model trained for thatclass was used for transliteration.It should be noted that Yoon et al (Yoon et al,2007) have also reported MRR score on Hindi.
Theyhave used a number of phonetic and pseudo features,and trained their algorithm on a winnow classifier.They tested their algorithm only for named entities.They have considered a relatively limited number ofcandidate words on the target language side (1,500)which leads to 150k pairs on which they have eval-uated their method.
They have reported the resultsas 0.91 and 0.89 under different test conditions.
Incase of our evaluation, we do not restrict the candi-date words on the target side except that it shouldbe available in the corpus.
Because of this formula-tion, there are over 1000k words for Hindi and over1800k words from Telugu.
This leads to a extremelyhigh number of pairs possible.
But such an approachis also necessary as we want our algorithm to bescalable to bigger sizes and also because there areno high quality tools (like named entity recogniz-ers) for Indian languages.
This is one of the reasonfor relatively (compared to figures reported by otherresearchers) low baseline scores.
Despite all theseissues, our simpler approach yields similar results.Figure-4 shows how the number of correct wordsvaries with the rank.Two possible issues are the out of vocabulary(OOV) words and misspelled or foreign words inthe IL corpus.
The OOV words are not handledright now by our method, but we plan to extend ourmethod to at least partially take care of such words.The second issue is mostly resolved by our use offuzzy string matching, although there is scope forimprovement.10 Conclusions and Further WorkWe presented a more general and adaptable methodfor transliteration which is especially suitable for In-dian languages.
This method first identifies the class(foreign or Indian) of the word on the source side.Based on the class, one of the two methods is usedfor transliteration.
Easily creatable mapping tablesand a fuzzy string matching algorithm are then usedto get the target word.
Our evaluations shows thatthe method performs substantially better than thetwo baselines we tested against.
The results are bet-ter in terms of both MRR (up to 0.44) and precision(45%).
Our method is designed to be used for otherapplications like tolerant input methods for Indianlanguages and it uses no resources on the target lan-guages side except an unannotated corpus.
The re-sults can be further improved if we consider contextinformation too.We have also shown that disambiguating wordorigin and applying an appropriate method could be70critical in getting good transliterations.
Currently weare assuming that the word to be transliterated is inthe target language corpus.
We plan to extend themethod so that even those words can be transliter-ated which are not in the target language corpus.
Weare also working on using this method for buildinga tolerant input method for Indian languages and onintegrating the transliteration mechanism as well asthe input method with an open source NLP friendlyeditor called Sanchay Editor (Singh, 2008).ReferencesN.
AbdulJaleel and L.S.
Larkey.
2003.
Statisticaltransliteration for english-arabic cross language infor-mation retrieval.
Proceedings of the twelfth interna-tional conference on Information and knowledge man-agement, pages 139?146.N.
Aswani and R. Gaizauskas.
2005.
A hybrid approachto align sentences and words in English-Hindi paral-lel corpora.
Proceedings of the ACL Workshop on?Building and Exploiting Parallel Texts.M.W.
Davis and W.C. Ogden.
1998.
Free resourcesand advanced alignment for cross-language text re-trieval.
Proceedings of the 6th Text Retrieval Confer-ence (TREC-6), pages 385?402.M.
Ganapathiraju, M. Balakrishnan, N. Balakrishnan,and R. Reddy.
2005.
OM: One Tool for Many (In-dian) Languages.
ICUDL: International Conferenceon Universal Digital Library, Hangzhou.L.
Larkey, N. AbdulJaleel, and M. Connell.
2003.What?s in a Name?
Proper Names in Arabic Cross-Language Information Retrieval.
Technical report,CIIR Technical Report, IR-278.A.
Llitjos and A.
Black.
2001.
Knowledge of languageorigin improves pronunciation of proper names.
Pro-ceedings of EuroSpeech-01, pages 1919?1922.M.G.A.
Malik.
2006.
Punjabi Machine Transliteration.Proceedings of the 21st International Conference onComputational Linguistics and the 44th annual meet-ing of the ACL, pages 1137?1144.J.
May, A. Brunstein, P. Natarajan, and R. Weischedel.2004.
Surprise!
What?s in a Cebuano or Hindi Name?ACM Transactions on Asian Language InformationProcessing (TALIP), 2(3):169?180.C.
S. Myers.
1980.
A Comparative Performance Study ofSeveral Dynamic Time Warping Algorithms for SpeechRecognition.
Ph.D. thesis, M.I.T., Cambridge, MA,Feb.
http://gate.ac.uk.J.H.
Oh and K.S.
Choi.
2002.
An English-Koreantransliteration model using pronunciation and contex-tual rules.
Proceedings of the 19th international con-ference on Computational linguistics-Volume 1, pages1?7.J.H.
Oh and K.S.
Choi.
2006.
An ensemble of translit-eration models for information retrieval.
InformationProcessing and Management: an International Jour-nal, 42(4):980?1002.A.
Rathod and A. Joshi.
2002.
A Dynamic Text Inputscheme for phonetic scripts like Devanagari.
Proceed-ings of Development by Design (DYD).Anil Kumar Singh, Harshit Surana, and Karthik Gali.2007.
More accurate fuzzy text search for languagesusing abugida scripts.
In Proceedings of ACM SI-GIR Workshop on Improving Web Retrieval for Non-English Queries, Amsterdam, Netherlands.Anil Kumar Singh.
2006a.
Study of some distance mea-sures for language and encoding identification.
In Pro-ceedings of ACL 2006 Workshop on Linguistic Dis-tance, Sydney, Australia.Anil Kumar Singh.
2006b.
A computational phoneticmodel for indian language scripts.
In Constraints onSpelling Changes: Fifth International Workshop onWriting Systems, Nijmegen, The Netherlands.Anil Kumar Singh.
2008.
A mechanism to providelanguage-encoding support and an nlp friendly editor.In Proceedings of the Third International Joint Con-ference on Natural Language Processing, Hyderabad,India.RMK Sinha.
2001.
Dealing with unknowns in machinetranslation.
Systems, Man, and Cybernetics, 2001IEEE International Conference on, 2.S.Y.
Yoon, K.Y.
Kim, and R. Sproat.
2007.
MultilingualTransliteration Using Feature based Phonetic Method.Proceedings of the 45th Annual Meeting of the Associ-ation of Computational Linguistics, pages 112?119.71
