Proceedings of the Demonstrations at the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 53?56,Gothenburg, Sweden, April 26-30 2014.c?2014 Association for Computational LinguisticsFinding Terms in Corpora for Many Languages with the Sketch EngineAdam KilgarriffLexical Computing Ltd., United Kingdomadam.kilgarriff@sketchengine.co.ukMilo?s Jakub??
?cek and Vojt?ech Kov?a?r and Pavel Rychl?y and V?
?t SuchomelMasaryk University, Czech RepublicLexical Computing Ltd., United Kingdom{xjakub, xkovar3, pary, xsuchom2}@fi.muni.cz1 OverviewTerm candidates for a domain, in a language,can be found by?
taking a corpus for the domain, and a refer-ence corpus for the language?
identifying the grammatical shape of a termin the language?
tokenising, lemmatising and POS-taggingboth corpora?
identifying (and counting) the items in eachcorpus which match the grammatical shape?
for each item in the domain corpus, compar-ing its frequency with its frequency in therefence corpus.Then, the items with the highest frequency in thedomain corpus in comparison to the reference cor-pus will be the top term candidates.None of the steps above are unusual or innova-tive for NLP (see, e. g., (Aker et al., 2013), (Go-jun et al., 2012)).
However it is far from trivialto implement them all, for numerous languages,in an environment that makes it easy for non-programmers to find the terms in a domain.
Thisis what we have done in the Sketch Engine (Kil-garriff et al., 2004), and will demonstrate.
In thisabstract we describe how we addressed each of thestages above.2 The reference corpusLexical Computing Ltd. (LCL) has been build-ing reference corpora for over a decade.
Corporaare available for, currently, sixty languages.
Theywere collected by LCL from the web.
For theworld?s major languages (and some others), theseare in the billions of words, gathered using Spider-Ling (Suchomel and Pomik?alek, 2012) and form-ing the TenTen corpus family (Jakub??
?cek et al.,2013).3 The domain corpusThere are two situations: either the user alreadyhas a corpus for the domain they are interested in,or they do not.
In the first case, there is a web in-terface for uploading and indexing the corpus inthe Sketch Engine.
In the second, we offer Web-BootCaT (Baroni et al., 2006), a procedure forsending queries of ?seed terms?
to a commercialsearch engine; gathering the pages that the searchengine identifies; and cleaning, deduplicating andindexing them as a corpus (Baroni and Bernardini,2004).
(The question ?how well does it work?
?is not easy to answer, but anecdotal evidence overten years suggests: remarkably well.
)4 Grammatical shapeWe make the simplifying assumption that termsare noun phrases (in their canonical form, withoutleading articles: the term is base station, not thebase stations.)
Then the task is to write a nounphrase grammar for the language.5 Tokenising, lemmatising, POS-taggingFor each language, we need processing tools.While many in the NLP world make the case forlanguage-independent tools, and claim that theirtools are usable for any, or at least many, lan-guages, we are firm believers in the maxim ?nevertrust NLP tools from people who don?t speak thelanguage?.
While we use language-independentcomponents in some cases (in particular TreeTag-ger,1RFTagger2and FreeLing3), we collaboratewith NLP experts in the language to ascertain whatthe best available tools are, sometimes to assist1http://www.cis.uni-muenchen.de/?schmid/tools/TreeTagger/2http://www.cis.uni-muenchen.de/?schmid/tools/RFTagger/3http://nlp.lsi.upc.edu/freeling/53in obtaining and customising them, and to verifythat they are producing good quality output.
Inmost cases these collaborators are also the peoplewho have written the sketch grammar and the termgrammar for the language.46 Identifying and counting candidatesWithin the Sketch Engine we already have ma-chinery for shallow parsing, based on a ?SketchGrammar?
of regular expressions over part-of-speech tags, written in CQL (Corpus Query Lan-guage, an extended version of the formalism de-veloped in Stuttgart in the 1990s (Schulze andChrist, 1996)).
Our implementation is mature, sta-ble and fast, processing million-word corpora inseconds and billion-word corpora in a few hours.The machinery has most often been used to find<grammatical-relation, word1, word2> triples forlexicography and related research.
It was straight-forward to modify it to find, and count, the itemshaving the appropriate shape for a term.7 Comparing frequenciesThe challenge of identifying the best candidateterms for the domain, given their frequency inthe domain corpus and the reference corpus, is avariant on the challenge of finding the keywordsin a corpus.
As argued in (Kilgarriff, 2009), agood method is simply to take the ratio of the nor-malised frequency of the term in the domain cor-pus to its normalised frequency in a reference cor-pus.
Before taking the ratio, we add a constant,the ?simple maths parameter?, firstly, to addressthe case where the candidate is absent in the refer-ence corpus (and we cannot divide by zero), andsecondly, because there is no one right answer:depending on the user needs and on the natureof the corpora, the constant can be raised to givea list with more higher-frequency candidates, orlowered to give more emphasis to lower-frequencyitems.Candidate terms are then presented to the userin a sorted list, with the best candidates ?
thosewith the highest domain:reference ratio ?
at thetop.
Each item in the list is clickable: the user canclick to see a concordance for the term, in eitherthe domain or the reference corpus.4Collaborators are typically credited on the ?info?
pagefor a reference corpus on the Sketch Engine website.
Thecollaborations are also often agreeable and fruitful in researchterms, resulting in many joint publications.Figure 2: Term finding results for Japanese, WIPO format.8 Current statusLanguages currently covered by the terminolo-gy finding system are sumarized in Table 1.Language POS tagger Ref.
corpusChinese simp.
Stanford NLP zhTenTen11Chinese trad.
Stanford NLP zhTenTen11English TreeTagger enTenTen08French TreeTagger frTenTen12German RFTagger deTenTen10Japanese MeCab+Comainu jpTenTen11Korean HanNanum koTenTen12Portuguese Freeling ptTenTen11Russian RFTagger ruTenTen11Spanish Freeling esTenTen11Table 1: Terminology support for languages in Sketch En-gine in January 2014.
POS tagger is mentioned as an im-portant part of the corpus processing chain.
The last columnshows the corresponding default reference corpus.The display of term finding results is shownin Figure 1 for English, for a bootcatted climate-change corpus.
Figure 2 shows a result set forJapanese in the mobile telecommunications do-main, prepared for the first users of the sys-temm, the World Intellectual Property Organisa-tion (WIPO), using their patents data, with theirpreferred display format.The user can modify various extraction relatedoptions: Keyword reference corpus, term refer-ence corpus, simple maths parameter, word lengthand other word properties, number of top resultsto display.
The form is shown in Figure 3.9 Current challenges9.1 Canonical form: lemmas and word formsIn English one (almost) always wants to presenteach word in the term candidate in its canonical,54Figure 1: Term finding result in the Sketch Engine ?
keywords on the left, multiword terms on the right.
The values in paren-theses represent keyness score and frequency in the focus corpus.
The green coloured candidates were used in a WebBootCaTrun to build the corpus.
The tickboxes are for specifying seed terms for iterating the corpus-building process.Figure 3: Term finding settings formdictionary form.
But in French one does not.
Thetop term candidate in one of our first experiments,using a French volcanoes corpus, was nu?ee ar-dente.
The problem here is that ardente is thefeminine form of the adjective, as required by thefact that nu?ee is a feminine noun.
Simply tak-ing the canonical form of each word (masculinesingular, for adjectives) would flout the rule ofadjective-noun gender agreement.
A gender re-specting lemma turns out necessary in such cases.Noun lemmas beginning with a capital letterand gender respecting ending of adjectives had tobe dealt with to correctly extract German phrases.In most of the languages we have been work-ing on, there are also some terms which should begiven in the plural: an English example is currentaffairs.
This is a familiar lexicographic puzzle: forsome words, there are distinct meanings limited tosome part or parts of the paradigm, and this needsnoting.
We are currently exploring options for this.9.2 Versions of processing chainsIf the version of the tools used for the referencecorpus is not identical to the version used on the55domain corpus, it is likely that the candidate listwill be dominated by cases where the two versionstreated the expression differently.
Thus the twoanalyses of the expression will not match and (insimple cases), one of the analyses will have fre-quency zero in each corpus, giving one very highand one very low ratio.
This makes the tool unus-able if processing chains are not the same.The reference corpus is processed in batchmode, and we hope not to upgrade it more thanonce a year.
The domain corpus is processedat runtime.
Until the development of the term-finding function, it did not greatly matter if dif-ferent versions were used.
For term-finding, wehave had to look carefully at the tools, separatingeach out into an independent module, so that wecan be sure of applying the same versions through-out.
It has been a large task.
(It also means thatsolutions based on POS-tagging by web services,where we do not control the web service, are notviable, since then, an unexpected upgrade to theweb service will break our system.
)10 EvaluationWe have undertaken a first evaluation using theGENIA corpus (Kim et al., 2003), in which allterms have been manually identified.5First, a plain-text version of GENIA was ex-tracted and loaded into the system.
Keyword andterm extraction was performed to obtain the top2000 keywords and top 1000 multi-word terms.Terms manually annotated in GENIA as well asterms extracted by our tool were normalized be-fore comparison (lower case, spaces and hyphensremoved) and then GENIA terms were looked upin the extraction results.
61 of the top 100 GE-NIA terms were found by the system.
The termsnot found were not English words: most wereacronyms, e.g.
EGR1, STAT-6.Concerning the domain corpus size: Althoughthe extraction method works well even with verysmall corpora (e.g.
the sample environmental cor-pus in 1 consists of 100,000 words), larger cor-pora should be employed to cover more terms.
Anearly version of this extraction tool was used tohelp lexicographers compile environment protec-tion related terminology.
A 50 million words cor-pus was sufficient in that case.
(Avinesh et al.,2012) report 30 million words is enough.5GENIA has also been used for evaluating term-findingsystems by (Zhang et al., 2008).11 ConclusionWe have built a system for finding terms in adomain corpus.
It is currently set up for nine lan-guages.
In 2014 we shall extend the coverage oflanguages and improve the system according tofurther feedback from users.AcknowledgementThis work has been partly supported by theMinistry of Education of CR within the LINDAT-Clarin project LM2010013.References[Aker et al.2013] A. Aker, M. Paramita, andR.
Gaizauskas.
2013.
Extracting bilingual ter-minologies from comparable corpora.
In Proc.ACL, pages 402?411.
[Avinesh et al.2012] PVS Avinesh, D. McCarthy,D.
Glennon, and J. Pomik?alek.
2012.
Domainspecific corpora from the web.
In Proc.
EURALEX.
[Baroni and Bernardini2004] M. Baroni and S. Bernar-dini.
2004.
Bootcat: Bootstrapping corpora andterms from the web.
In Proc.
LREC.
[Baroni et al.2006] M. Baroni, A. Kilgarriff,J.
Pomik?alek, and P. Rychl?y.
2006.
Webboot-cat: instant domain-specific corpora to supporthuman translators.
In Proc.
EAMT, pages 247?252.
[Gojun et al.2012] A. Gojun, U. Heid, B. Weissbach,C.
Loth, and I. Mingers.
2012.
Adapting and evalu-ating a generic term extraction tool.
In Proc.
LREC,pages 651?656.[Jakub??
?cek et al.2013] M.
Jakub??
?cek, A. Kilgarriff,V.
Kov?a?r, P. Rychl?y, and V. Suchomel.
2013.
Thetenten corpus family.
In Proc.
Corpus Linguistics.
[Kilgarriff et al.2004] A. Kilgarriff, P. Rychl?y, P. Smr?z,and D. Tugwell.
2004.
The sketch engine.
Proc.EURALEX, pages 105?116.
[Kilgarriff2009] A. Kilgarriff.
2009.
Simple maths forkeywords.
In Proc.
Corpus Linguistics.
[Kim et al.2003] J-D. Kim, T. Ohta, Y. Tateisi, andJ.
Tsujii.
2003.
Genia corpusa semantically an-notated corpus for bio-textmining.
Bioinformatics,19(suppl 1):i180?i182.
[Schulze and Christ1996] B. M. Schulze and O. Christ.1996.
The CQP user?s manual.
Univ.
Stuttgart.
[Suchomel and Pomik?alek2012] V. Suchomel andJ.
Pomik?alek.
2012.
Efficient web crawling forlarge text corpora.
In Proc.
WAC7, pages 39?43.
[Zhang et al.2008] Z. Zhang, J. Iria, C. A. Brewster, andF.
Ciravegna.
2008.
A comparative evaluation ofterm recognition algorithms.
In Proc.
LREC, pages2108?2113.56
