Proceedings of the 6th Workshop on Building and Using Comparable Corpora, pages 59?68,Sofia, Bulgaria, August 8, 2013. c?2013 Association for Computational LinguisticsScientific registers and disciplinary diversification:a comparable corpus approachElke TeichUniversita?t des Saarlandese.teich@mx.uni-saarland.deStefania Degaetano-OrtliebUniversita?t des Saarlandess.degaetano@mx.uni-saarland.deHannah KermesUniversita?t des Saarlandesh.kermes@mx.uni-saarland.deEkaterina Lapshinova-KoltunskiUniversita?t des Saarlandese.lapshinova@mx.uni-saarland.deAbstractWe present a study on linguistic con-trast and commonality in English scien-tific discourse on the basis of a mono-lingually comparable corpus.
The focusis on selected scientific disciplines at theboundaries to computer science (compu-tational linguistics, bioinformatics, digitalconstruction, microelectronics).
The databasis is the English Scientific Text Cor-pus (SCITEX) which covers a time rangeof roughly thirty years (1970/80s to early2000s).
In particular, we investigate thedisciplinary diversification/relatedness ofscientific research articles in terms of reg-ister.
Our results are relevant for researchon multilingually comparable corpora asused in machine translation and related re-search, since they shed new light on thenotion of ?comparablity?.1 Introduction: Motivation and GoalsIn the context of statistical machine translation,comparable corpora are typically bilingual, the-matically similar corpora being utilized to extracttranslation equivalents to enrich translation mod-els.
These have proved to be useful, especially fortechnically specialized texts or for low resourcelanguages where parallel corpora are rare (Chiaoand Zweigenbaum (2002); Babych et al(2007)).The overarching goal of the paper is to provideevidence that the notion of comparability com-monly used in that context is rather coarse andmisses important aspects of linguistic variation.We report on a set of experiments in which amonolingually comparable corpus is studied.
Thecorpus contains specialized, technical texts fromnine scientific disciplines, related to each other by?interdisciplines?
(such as computer science - lin-guistics - computational linguistics) (cf.
Section 2for details).
Our study establishes the linguisticdifferences and commonalities between the disci-plines considered on the basis of the concept ofregister, i.e., language variation according to situ-ational context.
Situational context is convention-ally described in terms of field, tenor and mode ofdiscourse (Quirk et al 1985).
It has been shownin numerous corpus-linguistic studies that particu-lar situational settings have specific linguistic cor-relates at the level of lexico-grammar in the senseof clusters of lexico-grammatical features that oc-cur non-randomly (see notably the work by Biberand colleagues, e.g., Biber (1988, 1993); Biberet al(1999); Biber (2006, 2012)).
Collectively,the linguistic features associated with field, tenorand mode then give rise to registers.
More specif-ically, field of discourse relates to the topic of adiscourse and is realized lexico-grammatically infunctional verb classes (e.g., activity, communica-tion, etc.)
with corresponding arguments (e.g., Ac-tor, Goal, Medium, etc.)
and adjunct types (e.g.,Time, Place, Manner, etc.).
Tenor of discourse re-lates to the roles and attitudes of the participants ina discourse and is realized lexico-grammaticallyin mood, modality as well as stance expressions.Mode of discourse relates to the presentationalfunction of language and is realized in Theme-Rheme and Given-New constellations.
A registeris then characterized by particular distributions oflexico-grammatical features according to a givencontextual configuration.Apart from exhibiting differences in field, tenorand mode, scientific texts are associated with par-ticular discourse ?styles?
such as technicality, ab-stractness or informational density, which mayagain be linguistically realized in different waysand to different degrees across disciplines.
Fur-thermore, in a highly dynamic social domain, suchas the scientific one, both registers and discoursestyles are relatively versatile and subject to change(cf.
Ure (1971, 1982)).
This may, for instance,59affect conventional phraseology.
Finally, registerand stylistic features may be distributed unevenlyacross document parts, thus giving rise to varia-tion according to document structure.
In order toarrive at a comprehensive picture of the linguisticconstrual of disciplinarity, we thus need to con-sider the linguistic encodings according to registerand the linguistic realization of discursive styles aswell as take into account the inherently dynamicnature of scientific discourse.Relating this back to the notion of comparabil-ity, the concept of register may thus provide thebasis for a fine-grained description of comparabil-ity, as it acknowledges the multi-dimensional na-ture of linguistic variation.Our methodology is informed by three sources:corpus linguistics, linguistic theory and data min-ing.
Standard corpus methods are employed forthe quantification of instances of linguistic fea-tures that are considered to be relevant indicatorsof variation across scientific disciplines and maybe expected to significantly contribute to differ-ences in language use across disciplines.
The the-oretical basis is provided by Systemic FunctionalLinguistics (SFL; Halliday (2004)).
The reasonfor choosing SFL to inform analysis is its modelof association of contextual variables with lexico-grammatical domains (cf.
above on the notion ofregister).In contrast to other corpus-based studies on reg-ister, our goal is not to uncover dimensions of vari-ation or to discover text classes (as e.g.
in Biber etal?s work).
The texts in our corpus are taken from38 journals from nine disciplines (for details seeSection 2) and the text classes are thus extrinsi-cally defined.
We can then think of analysis as atask of text classification, where we test whetherthe extrinsically defined classes have distinctivelinguistic correlates and if so, how well the classesare distinguished linguistically and which featurescontribute most to their distinction.
To this end,we employ data mining techniques, in particularautomatic text classification (see Section 3 for de-tails).
A similar approach to the one developedhere, also working on linguistic variation in thescientific domain, has been proposed earlier byArgamon et al(2008).
There is related workin translation studies by Baroni and Bernardini(2006) and Volansky et al(2011), which uses au-tomatic text classification to describe the specificproperties of translations (?translationese?).
Theearliest work, to our knowledge, combining SFLwith text classification is Whitelaw and Patrick?swork on spam detection (Whitelaw and Patrick,2004).2 Corpus2.1 Corpus Design and Pre-processingWe have built a corpus composed of English sci-entific research articles ?
the English ScientificText Corpus (SCITEX; cf.
Teich and Fankhauser(2010) and Degaetano-Ortlieb et al(forthcom-ing)) ?
that covers nine scientific domains andamounts to approx.
34 million tokens, drawn from38 sources.
SCITEX contains full journal arti-cles from two time periods, the 1970s/early 1980s(SASCITEX) and the early 2000s (DASCITEX).
Weselected at least two different journals for each dis-cipline in both time slices.
As our focus is on se-Figure 1: Scientific disciplines in the SCITEX cor-puslected scientific domains at the boundaries to com-puter science and some other discipline, SCITEXhas a three-way partition: (1) A-subcorpus: com-puter science, (2) B-subcorpus: computational lin-guistics, bioinformatics, digital construction andmicroelectronics, and (3) C-subcorpus: linguis-tics, biology, mechanical engineering and elec-trical engineering, as shown in Figure 1.
In thepresent paper, we are mainly interested in the lin-guistic evolution of the inter-/transdisciplinary do-mains represented by the B-subcorpus, as theseare the ones that have emerged in the given timeframe (1970s/80s to present).
We term these do-mains contact disciplines, since they have comeabout through contact between two existing dis-60ciplines (here: computer science and another es-tablished discipline represented in the A and Csubcorpora, which we term seed disciplines).
Themain question we are interested in is whether theseed and contact disciplines have clearly distin-guishable linguistic correlates in terms of register.The text sources for SCITEX are full academicarticles in the form of PDF files.
These files wereconverted to plain text using an existing commer-cial software including optical character recogni-tion (OCR).In further processing we follow the commonpractices in corpus linguistics by (a) accountingfor relevant metadata (e.g., author, title, jour-nal, year of publications) and document structure(e.g., abstract, conclusion), and (b) using stan-dard tools for preprocessing (e.g., tokenization,tagging, lemmatization, etc.).
For corpus query,we employ the Corpus Query Processor (CQP)(CWB; Evert, 2004) which works on the basis ofregular expressions.
Utilities of CQP allow for theextraction of distributional information accordingto the annotated metadata and document structure.3 Methods of AnalysisWe carry out a diachronic analysis comparing thetwo time slices (1970s/80s vs. 2000s) representedin the SCITEX corpus, aiming to provide answersto the following questions:1.
How well are the individual disciplines dis-tinguished?2.
How distinct are the contact disciplines fromtheir seed disciplines?Thus, analysis involves comparisons along thetemporal and the disciplinary dimensions.The hypothesis we have about the outcomes ofour analysis is that disciplines will be better dis-tinguished from one another over time, includingthe contact disciplines, reflecting a process of di-versification within scientific writing over time.3.1 Feature SelectionIn the first step of analysis we need to determinewhich features to investigate.
These should be fea-tures that bring out relevant and significant con-trasts along the dimensions considered (time, dis-cipline).
For the choice of features potentiallydistinguishing individual (scientific) registers, wedraw on SFL?s model of register variation in whichthe contextual parameters of field, tenor and modeare associated with particular lexico-grammaticaldomains.
Since we want to cover all three con-textual parameters, we choose at least one fea-ture for each.
For field, we analyze functionalverb classes as well as PoS-patterns that are poten-tially terminology-forming (e.g.
noun-noun struc-tures); for tenor, we analyze modal verbs and formode we analyze theme type as well as conjunc-tive cohesive relations.
As another feature, we an-alyze n-grams on the basis of PoS combinations(rather than words), since we have seen in a previ-ous study that they may be involved in processesof conventionalization (Kermes and Teich, 2012).Additionally, on an abstract level, scientificwriting is a highly informational production that ischaracterized by technicality, information densityand abstractness (cf.
Halliday and Martin (1993)).Among the linguistic features realizing these prop-erties are a relatively low type-token ratio (techni-cality), a relatively high lexical density and lowgrammatical intricacy (information density) andthe frequent use of nominal categories (nouns, ad-jectives) (abstractness).Table 1 displays the features considered in theanalysis together with their associated contextualvariables and/or abstract discourse properties theyinstantiate.
Features are extracted from the cor-pus with CQP.
For example, simple queries com-bine part-of-speech and concrete lemmas (e.g.,[pos=?MD?
& lemma=?must|should?
]; for modalverbs).
More complex queries work with posi-tional attributes, linguistic annotations and lists(e.g., < s>[conj & lemma!=$modal-adverbs]... aspart of the extraction of textual Theme, which isrealized in English as the first constituent in theclause).3.2 Feature EvaluationWe employ statistical and machine learning meth-ods to measure (a) how much individual featurescontribute to a possible distinction and (b) howwell corpora are distinguished by these features.We employ classification techniques by using fea-ture ranking (Information Gain) to determine therelative discriminatory force of features, and su-pervised machine learning (decision trees and sup-port vector machines) to distinguish between thescientific registers in SCITEX.
For these steps weuse the WEKA data mining platform (Witten andEibe, 2005).61contextual parameter/ feature category feature subcategoryabstract discourse propertyFIELDterm patterns NN-of-NN, N-N, ADJ-Nverb classesactivity (e.g., make, show)aspectual (e.g., start, end)causative (e.g., let, allow)communication (e.g., note, describe)existence (e.g., exist, remain)mental (e.g., see, know)occurrence (e.g., change, grow)TENOR modalityobligation/necessity (e.g., must)permission/possibility/ability (e.g., can)volition/prediction (e.g., will)MODEthemeexperiential theme (e.g, The algorithm...)interpersonal theme (e.g., Interestingly...)textual theme (e.g., But...)additive (e.g., and, furthermore)conjunctive adversative (e.g., nonetheless, however)cohesive relations causal (e.g., thus, for this reason)temporal (e.g., then, at this point)TECHNICALITY type-token ratio STTRlexical vs. function words no.
of lexical PoS categoriesINFORMATION DENSITYlexical density lexical items per clause/sentencegrammatical intricacyclauses per sentencewh-words per sentencesentence lengthABSTRACTNESS PoS distribution no.
of nominal vs. verbal categoriesCONVENTIONALIZATIONn-grams on PoS basis 2-to-6-grams overall/per sectionlength of sections tokens per sectionTable 1: Features used in analysis4 Results and InterpretationOur analysis addresses the question of how dis-tinctive the subcorpora in SCITEX are comparingthe productions of the 1970/80s with those of theearly 2000s.
Considering the diachronic perspec-tive, we expect to encounter a clearer separation ofindividual disciplines overall reflecting a processof diversification within scientific writing.The analysis has two parts: First, we calculateInformation Gain of the top twenty features, to seewhich features are the most discriminatory onesacross disciplines.
Second, we apply automaticclassification, to see how well the subcorpora aredistinguished on the basis of these features.Table 2 shows the twenty most discriminatoryfeatures for the 70/80s across all subcorpora.
Thefive highest ranking features are associated withfield (NN: IGain 0.39, LEX: IGain 0.36, commu-nication verbs: IGain 0.31) and mode (WL: IGain0.33, LEX/C: IGain 0.32).
In the mid range, wefind some tenor features and in the lower rangesome other field features as well as documentstructure features.When we compare these results with the onesfor the early 2000s (see Table 3), three main ob-servations can be made.
First, features becomemuch more pronounced, the IGain values risingsubstantially for the top 20 features (1970s/80sare in the range of 0.23 to 0.39, 2000s are inthe range of 0.31 to 3.1).
This includes the ninefeatures that are identical across SASCITEX andDASCITEX: existence and communication verbsas well as adj-n term pattern for field, obliga-tion modals for tenor, word and sentence lengthas well as lexical words per clause for mode, bi-grams for conventionalization, and length of mainpart for document structure, all become more pro-nounced in DASCITEX (higher IGains) and thuscontribute more to the distinction between disci-plines.
The second observation is that while inSASCITEX only bi-grams ranges among the top 20features, in DASCITEX we encounter an increasein the contribution of gram-based features to theDASCITEX-internal distinction.1 This may pointto the greater role of conventionalized language inthe distinction between disciplines over time.
Ter-minological studies based on n-grams might indi-cate a thematic comparability of disciplines.
Con-sider one of the key concepts in computer science,?algorithm?.
The distribution (per million) acrossthe nine disciplines in DASCITEX varies greatly:1Note again that in our analysis, n-grams are based onparts-of-speech, not words.62feature IGain contextual parameter discourse propertyNN 0.3931 field technicality, abstractnessLEX 0.3647 field technicalitycommunication 0.3119 fieldmental 0.2526 fieldexistence 0.2372 fieldADV 0.2282 field abstractnessadj-n pattern 0.2253 field technicalityvolition 0.3184 tenorpermission 0.2709 tenorMD 0.2679 tenorobligation 0.249 tenorWL 0.3326 mode information densityLEX/C 0.3238 mode information densitySL 0.2974 mode information densityclauses/S 0.287 mode information densityadditive 0.2574 modeWH/S 0.2504 mode information densitybi-grams 0.2382 conventionalizationmain 0.2301 document structureintroduction 0.2257 document structureTable 2: Feature ranking for the 70/80s (SASCITEX): Top 20 featuresfeature IGain contextual parameter discourse propertyexistence 0.3987 fieldactivity 0.3677 fieldcommunication 0.3636 fieldSTTR 0.3582 field technicalityadj-n pattern 0.3441 field technicalityobligation 0.3548 tenorLEX/C 3.0803 mode information densitySL 0.5567 mode information densityWL 0.51 mode information densityexperiential-theme 0.344 modecausal 0.3302 modemain 0.5324 document structureabstract 0.4981 document structuren-grams main 0.4925 conventionalizationbi-grams 0.3886 conventionalizationn-grams 0.3706 conventionalizationn-grams abstr 0.3609 conventionalizationn-grams 4 0.3287 conventionalizationn-grams 3 0.3209 conventionalizationn-grams intro 0.3115 conventionalizationTable 3: Feature ranking for the early 2000s (DASCITEX): Top 20 featurescomputer science (3427), microelectronics (1965),bioinformatics (1913), digital construction (1735),computational linguistics (1124), electrical engi-neering (955), mechanical engineering (129), bi-ology (59) and linguistics (51).
When we look atthe top frequent token n-grams in which algorithmparticipates, we find, for example, ?approximationalgorithm?
which is mostly shared between com-puter science, the contact discipines and electricalengineering, ?learning algorithms?
appears prac-tically everywhere, and ?alignment algorithm?
isalmost only mentioned in computational linguis-tics and bioinformatics (with a few occurrencesin computer science and one in biology).
Thestylistics across the disciplines is also notewor-thy: pure stylistic tri-grams, such as the highlyfrequent ?in order to?, ?the number of?, ?based onthe?, ?as shown in?, etc., are also good discrimi-nators between different disciplines (cf.
Kermesand Teich (2012)).
Finally, at the levels of con-textual and discourse properties, it can be notedthat features associated with information densitybecome better discriminators between disciplinesin the 2000s having high IGain values, while tenorfeatures step back decreasing in number, tendingtowards greater uniformity (only one tenor feature(obligation modals) in the top 20 features in the2000s compared to four in the 70s/80s).To see how these data are reflected according todisciplines, we perfom classification for both cor-63A B1 B2 B3 B4 C1 C2 C3 C4 total accuracy in %A 108 2 11 25 1 0 4 6 45 202 53.47B1 3 22 22 19 7 26 4 9 13 125 17.60B2 10 21 142 55 30 8 60 60 71 457 31.07B3 16 24 52 121 32 7 17 37 55 361 33.52B4 1 4 32 27 91 4 36 45 32 272 33.46C1 2 24 16 8 1 154 4 6 4 219 70.32C2 3 6 70 16 22 2 358 30 28 535 66.92C3 10 10 60 45 44 6 37 137 39 388 35.31C4 52 25 60 49 39 2 25 24 248 524 47.33A: Computer Science, B1: Computational Linguistics, B2: Bioinformatics, B3: Digital Construction, B4: Microelectronics,C1: Linguistics, C2: Biology, C3: Mechanical Engineering, C4: Electrical EngineeringTable 4: Confusion matrix with decision tree for the 70/80s (SASCITEX)A B1 B2 B3 B4 C1 C2 C3 C4 total accuracy in %A 156 0 3 4 0 1 1 0 37 202 77.23B1 1 26 23 11 7 27 3 12 15 125 20.80B2 2 2 274 47 13 4 32 37 46 457 59.96B3 8 1 72 156 21 3 16 24 60 361 43.21B4 0 1 14 8 158 1 49 26 15 272 58.09C1 2 11 12 0 0 183 0 5 6 219 83.56C2 2 0 28 4 12 0 463 9 17 535 86.54C3 3 4 53 18 22 2 40 213 33 388 54.90C4 30 2 41 25 12 1 24 12 377 524 71.95A: Computer Science, B1: Computational Linguistics, B2: Bioinformatics, B3: Digital Construction, B4: Microelectronics,C1: Linguistics, C2: Biology, C3: Mechanical Engineering, C4: Electrical EngineeringTable 5: Confusion matrix with SVM for the 70/80s (SASCITEX)A B1 B2 B3 B4 C1 C2 C3 C4 total accuracy in %A 201 1 0 9 7 1 0 2 9 230 87.39B1 4 97 4 19 1 8 1 0 3 137 70.80B2 5 0 269 14 6 0 18 6 1 319 84.33B3 5 3 8 168 8 0 6 30 14 242 69.42B4 2 2 10 17 156 0 8 9 1 205 76.10C1 1 11 6 3 0 90 0 0 0 111 81.08C2 0 0 7 2 2 1 335 3 1 351 95.44C3 4 1 7 23 6 0 15 229 18 303 75.58C4 18 2 3 42 7 0 4 34 113 223 50.67A: Computer Science, B1: Computational Linguistics, B2: Bioinformatics, B3: Digital Construction, B4: Microelectronics,C1: Linguistics, C2: Biology, C3: Mechanical Engineering, C4: Electrical EngineeringTable 6: Confusion matrix with SVM for the early 2000s (DASCITEX)pora (SASCITEX and DASCITEX), first, with deci-sion trees, as they are based on Information Gain,and second, with support vector machines (SVMs),as they are used for text categorization tasks withmany relevant features achieving very good results(cf.
Joachims (1998)).
Classification is performedon all features with 10 fold cross-validation.
Ta-ble 4 shows the confusion matrix for all subcor-pora for the 70/80s and classification accuracy foreach subcorpus achieved by decision tree.
Theoverall accuracy is 44.79% only, the correctly clas-sified texts lying on the main diagonal of the ma-trix.The confusion matrix produced by SVM isshown in Table 5, with an overall accuracy of65.07%.
Apart from computational linguistics(B1), accuracy goes up by about 10% for digi-tal contruction (B3) and linguistics (C1) and about25-30% for the other subcorpora compared to de-cision tree.
Accuracy with SVM for the contactdisciplines (B1-B4) ranges from 20-60% and ismuch lower than the accuracy achieved for theseed disciplines (A and C1-C4) with around 54-86%.
Thus, the contact disciplines are not clearlyseparated from the seed disciplines.
Considering,for instance the triple A-B1-C1, we can see thatmore texts belonging to computational linguistics(B1) are classified into linguistics (C1) than intocomputational linguistics (27 texts in C1 vs. 26 inB1), i.e., texts in B1 seem to be quite similar to64B1 vs A B2 vs A B3 vs A B4 vs AWL 0.629 WL 0.501 WL 0.399 LEX 0.883STTR 0.509 LEX 0.355 LEX 0.331 WL 0.763LEX 0.372 causal 0.334 n-grams 6 0.265 STTR 0.574ADJ 0.261 n-grams 6 0.306 STTR 0.258 causal 0.560VV 0.230 STTR 0.303 clauses/S 0.202 NN 0.458n-grams 6 0.205 n-grams 4 0.284 adj-n-n 0.168 additive 0.440causal 0.187 temporal 0.283 causal 0.160 temporal 0.433types 0.174 n-grams 5 0.282 NN 0.13 mental 0.416adj-c-adj-n 0.145 ADJ 0.273 n-grams 4 0.118 commun.
0.379introduction 0.129 causative 0.197 ADJ 0.114 n-grams 4 0.364B1 vs C1 B2 vs C2 B3 vs C3 B4 vs C4clauses/S 0.230 NN 0.269 LEX/S 0.260 LEX 0.469ADV 0.204 MD 0.264 main 0.146 VV 0.311LEX/C 0.196 WH 0.198 n-grams main 0.132 WL 0.309NN 0.179 permission 0.178 introduction 0.127 main 0.153WH/S 0.122 volition 0.166 causative 0.114 NN 0.148LEX 0.120 WL 0.147 exper-theme 0.113 introduction 0.142occurrence 0.119 SL 0.145 obligation 0.087 LEX/S 0.115commun.
0.112 WH/S 0.137 n-grams intro 0.086 n-grams main 0.096MD 0.110 LEX 0.104 aspectual 0.081 causal 0.093n-grams abstr 0.108 LEX/C 0.098 LEX/C 0.077 n-grams intro 0.088A: Computer Science, B1: Computational Linguistics, B2: Bioinformatics, B3: Digital Construction, B4: Microelectronics,C1: Linguistics, C2: Biology, C3: Mechanical Engineering, C4: Electrical EngineeringTable 7: Feature ranking with IGain for the 70/80s (SASCITEX): Top 20 features contact vs seed disci-plinesB1 vs A B2 vs A B3 vs A B4 vs AWL 0.694 WL 0.701 WL 0.567 WL 0.791STTR 0.631 main 0.680 causal 0.488 STTR 0.615SL 0.441 STTR 0.678 STTR 0.385 VV 0.289types 0.402 n-grams main 0.634 temporal 0.347 main 0.233causal 0.237 causal 0.621 n-grams 4 0.345 causal 0.230n-grams 6 0.217 n-grams 4 0.577 n-grams 0.319 LEX 0.21n-n 0.192 n-grams 0.552 n-grams 5 0.318 mental 0.196adj-n 0.171 abstract 0.537 n-grams main 0.282 temporal 0.190adversative 0.128 bi-grams 0.521 LEX 0.280 n-of-n 0.189adj-c-adj-n 0.125 introduction 0.487 bi-grams 0.262 aspectual 0.144B1 vs C1 B2 vs C2 B3 vs C3 B4 vs C4occurrence 0.264 SL 0.566 WL 0.156 VV 0.436adj-adj-n 0.193 abstract 0.518 VV 0.139 WL 0.410ADV 0.189 n-grams abstr 0.505 obligation 0.100 LEX/C 0.329ADJ 0.137 main 0.412 LEX/C 0.100 ADV 0.243NN 0.128 introduction 0.353 n-grams 5 0.097 n-grams 3 0.181types 0.123 n-grams main 0.344 MD 0.088 LEX/S 0.162LEX/C 0.123 n-grams intro 0.321 ADJ 0.075 activity 0.154main 0.118 WH 0.204 aspectual 0.064 n-grams 0.147commun.
0.107 MD 0.202 SL 0.061 STTR 0.135abstract 0.107 WH/S 0.192 LEX/S 0.059 abstract 0.127A: Computer Science, B1: Computational Linguistics, B2: Bioinformatics, B3: Digital Construction, B4: Microelectronics,C1: Linguistics, C2: Biology, C3: Mechanical Engineering, C4: Electrical EngineeringTable 8: Feature ranking with IGain for the early 2000s (DASCITEX): Top 20 features contact vs seeddisciplinestexts in C1 in terms of the features investigated.In order to check the separation of disciplinesover time, we need to compare classification re-sults across SASCITEX and DASCITEX.
We againapply SVM, which returns an overall accuracy of78.17%.2 Comparing the values for the individual2Decision tree performed poorly again in comparisonsubcorpora across SASCITEX and DASCITEX, wecan observe that accuracies are now much higherfor all subcorpora.
Considering the contact disci-plines, they have clearly gained distinctiveness inthe 2000s in comparison to the 1970/80s, as textsin B1-B4 are classified correctly 69% to 84% ofachieving an accuracy of 57.24% only.65the time (instead of 20-60% in the 1970/80s).In summary, the classification results match theresults obtained by feature ranking, which haveshown that the top 20 features increased discrim-inatory force over time.
This is reflected by ahigher classification accuracy overall and for thesubcorpora.3 The discriminatory force of featuresin the 1970s/80s instead, was not strong enough toclearly separate disciplines.To see whether there are any particular featuresinvolved in the differentiation of the contact dis-ciplines in particular vis a` vis computer scienceon the one hand and the other seed disciplineson the other hand, we inspect the confusion ma-trix as well as the IGains of each B vs. A andeach B vs. the respective C, both for SASCITEXand DASCITEX.
In the comparison to computerscience (A), we can see that the confusion ma-trixes produced with SVM (cf.
Table 5 and 6)show few texts that are misclassified from the con-tact disciplines (Bs) into computer science (A) forboth time slices.
Thus, the features employed dis-tinguish Bs from A quite well.
Considering theIGain values (see Table 7 and 8 for the top 10 fea-tures), besides computational linguistics (B1; rel-atively low classification accuracy of 20% in the70/80s), the contact disciplines have the followingfeatures in common: word length (WL), STTR,causal verbs in the top 10 as well as four-grams,lexical words (LEX) and temporal conjunctions inthe top 20 features.
Except lexical words (LEX),all features have a higher IGain in the 2000s.
Inthe comparison to the other seed discipines (Cs),the confusion matrixes show more misclassifica-tions of Bs into Cs.
Considering the IGain val-ues there are no tendencies uniformly applying tothe contact disciplines (Bs).
They rather showindividual tendencies for each pair (B1 vs. C1,B2 vs. C2, B3 vs. C3, B4 vs. C4).
Featuresthat contribute to a better classification diachroni-cally lie in the following parameters: (a) field (oc-currence, term-patterns, ADV) for computationallinguistics (B1), (b) document structure (abstract,main, intro), information density (SL) and conven-tionalization (n-grams abstract) for bioinformatics(B2), (c) information density (WL) and technical-ity (VV) for digital construction (B3) and micro-electronics (B4).3There are only two exceptions: C1 (linguistics) goesslightly down (around 2.5%), C4 (electrical engineering)goes down by over 20% to 50.67% accuracy, i.e., it is notreally distinguishable any more.5 Summary and ConclusionsWe have looked at disciplinary linguistic diversifi-cation in English scientific writing in terms of reg-ister, discourse styles and document structure.
Theresults of our analysis provide evidence of majormotifs of development in scientific writing overtime, showing dynamicity over a time span of onlythirty years.
Diversification over time is clearlyborne out for the contact disciplines but is also truefor most of the other disciplines.Considering the contact disciplines we haveseen that (1) they can be distinguished quite wellfrom computer science with the same features be-ing involved in better classification results, (2)they show individual feature constellations in theirdistinction from their seed disciplines.
Moreover,n-grams have gained discriminatory force overtime and are ranked relatively high among our fea-tures in the 2000s subcorpus.
As they are also rel-evant in terms of terminology, they give an insightin the relatedness of disciplines.In terms of methods, we have combined state-of-the-art corpus processing with techniques ofdata analysis as developed in data mining.
As suchtechniques become more accessible to linguistic,literary and cultural analysis, the repertoire ofmethods for such analysis will be greatly enhancedin that sounder empirical evidence can be soughtin text-based socio-cultural and historical studiesat large (cf.
Jockers (2013)).
The crucial factorin employing such methods is the motivation ofthe features to be used in analysis.
Here, we havedeliberately not relied on word-based features butinstead mainly employed lexico-grammatical pat-terns.
While bags-of-words are strong discrim-inators between texts/text classes, they can onlytell us something about lexical variation (e.g., asan indicator of text topic).
However, when reg-ister or style rather than topicality are in the fo-cus (such as e.g.
the linguistic construal of techni-cal, dense or abstract discourse or the expressionof field, tenor or mode relations), it will not be suf-ficient to study lexical word distributions (cf.
Co-hen et al(2010); Teich and Fankhauser (2010) forsome other studies).
Instead, one needs to identifylexico-grammatical patterns that are potential in-dicators of the more abstract discoursive and con-textual properties that are in focus.The insight to be gained from our study for mul-tilingually comparable corpora is that more elab-orate definitions of ?comparability?
might be re-66quired.
Our approach offers such a definition ofcomparability by being firmly based on an estab-lished model of linguistic variation, which has alsobeen widely applied in multilingual contexts, suchas for example, automatic text generation (seee.g., Matthiessen and Bateman (1991); Bateman(1997); Kruijff et al(2000)).
The parameters ofvariation we employ (register: field, tenor, mode;discourse styles; time) provide a fine-grained gridof features involved in linguistic variation, whichcan be applied to other languages as well.
For ex-ample, we can extract and analyze field features,such as term patterns (as produced for German byWeller et al(2011)), tenor features, such as modalverbs, as well as the other features investigatedusing the same tools applied here (part-of-speechtagger, CQP, R-scripts and WEKA modules) withonly little adaptations (e.g., tag sets, query formu-lation).
Overall, we would expect that applyingthe concept of register to the problem of compara-bility will enable finer-tuned comparable corporaand thus contribute to their fuller potential for mul-tilingual language technology.AcknowledgmentsWe wish to thank the anonymous reviewers fortheir helpful comments.
We are especially grate-ful to Peter Fankhauser for critically assessing ourdata and to Noam Ordan for valuable suggestionsregarding the structure of the paper.ReferencesShlomo Argamon, Jeff Dodick, and Paul Chase.Language use reflects scientific methodology:A corpus-based study of peer-reviewed journalarticles.
Scientometrics, 75(2):203?238, 2008.Bogdan Babych, Anthony Hartley, and SergeSharoff.
Translating from under-resourced lan-guages: Comparing direct transfer against pivottranslation.
In Proceedings of the MT Sum-mit XI, pages 412?418, Copenhagen, Denmark,2007.Marco Baroni and Silvia Bernardini.
A new ap-proach to the study of translationese: Machine-learning the difference between original andtranslated text.
Literary and Linguistic Com-puting, 21(3):259?274, 2006.John A. Bateman.
Enabling technology formultilingual natural language generation: TheKPML development environment.
Journalof Natural Language Engineering, 3(1):15?55,1997.Douglas Biber.
Variation Across Speech and Writ-ing.
Cambridge University Press, Cambridge,1988.Douglas Biber.
The multi-dimensional approachto linguistic analyses of genre variation: Anoverview of methodology and findings.
Com-puters and the Humanities, 26(5-6):331?345,1993.Douglas Biber.
University Language: A Corpus-based Study of Spoken And Written Regis-ters, volume 23 of Studies in Corpus Lin-guistics.
John Benjamins Publishing, Amster-dam/Philadelphia, 2006.Douglas Biber.
Register as a predictor of linguis-tic variation.
Corpus Linguistics and LinguisticTheory, 8(1):9?37, 2012.Douglas Biber, Stig Johansson, and GeoffreyLeech.
Longman Grammar of Spoken and Writ-ten English.
Longman, Harlow, 1999.Yun-Chuang Chiao and Pierre Zweigenbaum.Looking for candidate translational equivalentsin specialized, comparable corpora.
In Pro-ceedings of the 19th international Conferenceon Computational Linguistics (COLING), Vol.2, pages 1?5, Taipei, Taiwan, 2002.Kevin Bretonnel Cohen, Helen Johnson, KarinVerspoor, Christophe Roeder, and LawrenceHunter.
The structural and content aspects ofabstracts versus bodies of full text journal arti-cles are different.
BMC bioinformatics, 11(1):492, 2010.CWB.
The IMS Open Corpus Workbench, 2010.http://www.cwb.sourceforge.net.Stefania Degaetano-Ortlieb, Kermes Hannah,Ekaterina Lapshinova-Koltunski, and TeichElke.
SciTex a diachronic corpus for analyz-ing the development of scientific registers.
InPaul Bennett, Martin Durrell, Silke Scheible,and Richard J. Whitt, editors, New Methods inHistorical Corpus Linguistics, Corpus Linguis-tics and Interdisciplinary Perspectives on Lan-guage (CLIP), Vol.
3.
Narr, Tu?bingen, forth-coming.Stefan Evert.
The Statistics of Word Cooccur-rences: Word Pairs and Collocations.
PhD the-sis, IMS, University of Stuttgart, 2004.67M.A.K.
Halliday.
An Introduction to FunctionalGrammar.
Arnold, London, 2004.M.A.K.
Halliday and J.R. Martin.
Writing sci-ence: Literacy and discursive power.
FalmerPress, London, 1993.Thorsten Joachims.
Text categorization with sup-port vector machines: Learning with many rel-evant features.
Machine Learning: ECML-98,pages 137?142, 1998.Matthew L. Jockers.
Macroanalysis: DigitalMethods and Literary History.
University ofIllinois Press, 2013.Hannah Kermes and Elke Teich.
Formulaic ex-pressions in scientific texts: Corpus design, ex-traction and exploration.
Lexicographica, 28(1):99?120, 2012.Geert-Jan Kruijff, Elke Teich, John Bateman,Ivana Kruijff-Korbayova?, Hana Skoumalova?,Serge Sharoff, Lena Sokolova, Tony Hartley,Kamenka Staykova, and Jir???
Hana.
Multilin-guality in a text generation system for threeSlavic languages.
In Proceedings of the 18th in-ternational Conference on Computational Lin-guistics (COLING), Vol.
1, pages 474?480,Saarbru?cken, Germany, 2000.Christian M.I.M.
Matthiessen and John A. Bate-man.
Text generation and systemic-functionallinguistics: Experiences from English andJapanese.
Communication in Artificial Intelli-gence Series.
Pinter, 1991.Randolph Quirk, Sidney Greenbaum, GeoffreyLeech, and Jan Svartvik.
A ComprehensiveGrammar of the English Language.
Longman,London, 1985.Elke Teich and Peter Fankhauser.
Exploring acorpus of scientific texts using data mining.In S. Gries, S. Wulff, and M. Davies, editors,Corpus-linguistic applications: Current stud-ies, new directions, pages 233?247.
Rodopi,Amsterdam and New York, 2010.Jean Ure.
Lexical density and register differentia-tion.
In G. E. Perren and J. L. M. Trim, editors,Applications of Linguistics.
Selected papers ofthe Second International Congress of AppliedLinguistics, Cambridge 1969, pages 443?452.Cambridge University Press, 1971.Jean Ure.
Introduction: Approaches to the studyof register range.
International Journal of theSociology of Language, 35:5?23, 1982.Vered Volansky, Noam Ordan, and Shuly Wintner.More human or more translated?
Original textsvs.
human and machine translations.
In Pro-ceedings of the 11th Bar-Ilan Symposium on theFoundations of AI with Israeli Seminar on Com-putational Linguistics (ISCOL), Ramat Gan, Is-rael, 2011.Marion Weller, Helena Blancafort, Anita Gojun,and Ulrich Heid.
Terminology extraction andterm variation patterns: a study of French andGerman data.
In Proceedings of the GSCL:German Society for Computational Linguisticsand Language Technology, Hamburg, Germany,2011.Casey Whitelaw and Jon Patrick.
Selecting sys-temic features for text classification.
In AshAsudeh, Ce?cile Paris, and Stephen Wan, edi-tors, Proceedings of the Australasian LanguageTechnology Workshop, pages 93?100, Sydney,Australia, 2004.Ian H. Witten and Frank Eibe.
Data Mining: Prac-tical Machine Learning Tools and Techniques.Elsevier, Morgan Kaufmann Publishers, Ams-terdam, Boston, second edition, 2005.68
