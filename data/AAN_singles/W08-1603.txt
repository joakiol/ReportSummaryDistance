Coling 2008: Proceedings of the workshop on Knowledge and Reasoning for Answering Questions, pages 17?24Manchester, August 2008Know-Why Extraction from Textual Data for Supporting WhatQuestionChaveevan PechsiriDept.
of InformationTechnology,DhurakijPundit University,Bangkok, Thailanditdpu@hotmail.comPhunthara SroisonDept.
of InformationTechnology,DhurakijPundit University,Bangkok, Thailandphunthara@it.dpu.ac.thU.
JanviriyasopakEastern Industry Co.ltd.Bangkok, Thailanduraiwanjan@hotmail.com1AbstractThis research aims to automatically ex-tract Know-Why from documents on thewebsite to contribute knowledge sourcesto support the question-answering sys-tem, especially What-Question, for dis-ease treatment.
This paper is concernedabout extracting Know-Why based onmultiple EDUs (Elementary DiscourseUnits).
There are two problems in ex-tracting Know-Why: an identificationproblem and an effect boundary determi-nation problem.
We propose using Na?veBayes with three verb features, a causa-tive-verb-phrase concept set, a supportingcausative verb set, and the effect-verb-phrase concept set.
The Know-Why ex-traction results show the success rate of85.5% precision and 79.8% recall.1 IntroductionAutomatically Know -Why extraction is essentialfor providing the rational knowledge source, tothe society through question answering system,especially in herbal medicines when assisting thelocals to understand more about herbs.According to Jana Trnkova and WolfgangTheilmann (2004) Know-Why is the knowing ofthe reason of why something is the way it is.Therefore, Know-Why has to involve the causalrelation which is ?an irreflexive, transitive andasymmetrical?
relation that contains theproperties of ?productivity (effect is ?produced?by the cause) and locality (it obeys the markov?
2008.
Licensed under the Creative Commons Attri-bution-Noncommercial-Share Alike 3.0 Unportedlicense (http://creativecommons.org/licenses/by-nc-sa/3.0/).
Some rights reserved.condition, for model A B  C, if there is noB, then A does not cause C)?
( Lemeire J. et al(2004)).
Wolff P. (2007) stated that the causalrelation can be decomposed into 2 majorapproaches, the dependency model and thephysicalist models.
The dependency model canbe represented by using statistical dependencymodel whereas in recent physicalist models arebased on the concepts of force dynamic modelsconsisting of 2 force entities in certain events;the agonist and the antagonist (Talmy, 2000).Later, the agonist form (Wolff P., 2007) can beviewed as the ?effect?
and the antagonist as the?cause?.
According to Talmy (2000), if there is asituation where the antagonist is stronger, whichcan be expressed as ?event X happens because ofevent Y?
(Y contains the antagonist.
), it is a formof causation.
Moreover, the causal relation canpivot on the distinction between causality andcausation (Lehmann J. et al 2004) whereascausality is ?a law-like relation between causeevents and effect events?
and causation is ?theactual causal relation that holds betweenindividual events?.
For example:?Because a bird sings a song at a window, Therock is thrown at the window.
?Causality: ?An object vibrates.
An objectmoves.
?Causation: ?A bird sings.
The rock is thrown?This research focuses only on ?causal relation?
toprovide both ?causality?
for extracting Know-Why from the herbal medicine domain and?causation?
for answering What-question, sincewhat questions contain ambiguities (Girju R. andMoldovan D., 2002) for example:Know-Why: ?  /Abasil leaf is used as a medicine releasing gas.
[The leaf] stops nausea.
[The leaf] stops painingthe abdomen.?
(where the [..] symbol meansellipsis.
)17Know-Why concept:  ?A herb organ is used asbeing a carminative drug.
[The organ] is antinausea,  [The organ] is anti stomachache.
?Question: ?/What herb is usedfor stopping nausea??
From this example, ?Abasil leaf is used as a medicine releasing gas?
isthe causation and the concept is the causality.There are various forms of causal-relation expression such as in the form of intra-NP, inter-NP, and inter-sentence (Chang andChoi,2004).
According to our research, weseparated this relation into 2 main forms basedon the elementary discourse unit (EDU) asdefined by (Carlson et al, 2003) as a simplesentence or clause.
We defined the intra-causalEDU as an expression within one simple EDUbeing equivalent to either the intra-NP form orthe inter-NP form (Chang and Choi,2004).
Theinter-causal EDU is defined as an expressionwithin more than one simple EDU which isequivalent to the inter-sentences of Chang andChoi (2004).
However, this paper works on onlythe inter-causal EDU extraction because somecause-effect relation from the herbal web sitesare expressed in the form of the EDU containingan EDU-like name entity with the causativeaction followed by some effect EDUs.Several techniques (Marcu and Echihabi,2002;Torisawa  2003; Inui and et al,2004; Pechsiriand Kawtrakul, 2007)   have been used to extractcause-effect knowledge varying  from  twoadjacent sentences to multiple sentences.
Ourwork aimed at mining and extracting Know-Whyfrom Thai documents of herbal medicines.
Thaihas several specific characteristics, such as theexistence of sentence-like name entity, zeroanaphora or the implicit noun phrase.
All ofthese characteristics are involved in the two mainproblems of Know-Why extraction: the firstproblem is how to identify the interestingcausality events expressed by an EDU- like nameentity from documents, and the second one ishow to identify the effect boundary, where Theproblem of implicit delimiter of the boundary isinvolved.
From all of these problems, we neededto develop a framework which combineedLanguage Processing and the machine learningtechnique as Na?ve Bayes to learn features ofthree verb sets, a causative concept verb set, asupporting causative verb set, and an effectconcept verb set, for solving those problems.In conclusion, unlike other methods (Marcuand Echihabi ,2002; Torisawa  2003; Inui and etal.,2004) where the emphasis is based on twoadjacent sentences, this paper is based onmultiple  EDU extraction.
Our research wasseparated into 5 sections.
In section 2, relatedwork was summarized.
Problems in causalitymining from Thai documents will be described insection 3 and in section 4 our framework forcausality extraction was explained.
In section 5,we evaluated and concluded our proposed model.2 Related WorkSeveral strategies such as those done by Marcuand Echihabi ,2002, Torisawa( 2003), Inui and etal.
(2004), and  Pechsiri and Kawtrakul (2007)have been proposed to extract and discoverknowledge from the textual data.Marcu and Echihabi (2002) presented theunsupervised approach to recognize the discourserelations by using word pair probabilitiesbetween two adjacent sentences for classifyingthe rhetorical relations, such as Contrast, Cause-Explanation, Condition, and Elaboration,between two adjacent sentences by using Na?veBayes classifier to the BLIPP corpus (Charniak,2000).
They determined the word pairs in thecartesian product from the sentence pairsconnected with or without discourse marker orconnective marker , i.e.
?because?
?but?
?then?, toclassify the causal relation from other rhetoricalrelations.
The result showed an accuracy of 75%of inter-sentence causality extraction from thecorpus size of more than a million sentences forlearning whereas our corpus size is 3000sentences for learning.
Therefore, our approachis the supervised approach with the statisticalmethod because our corpus size is small.Inui?s work (Inui and et al,2004) proposed amethod of extraction and classification of causalknowledge.
The method of extraction wasaccomplished under two adjacent sentences byusing explicit connective markers; e.g.
?because??since?
?if..then?
?as the result?
etc..  SVM wasused for the classification process in (Inui and etal.,2004).
Four types of causal relations arestudied, including the following: cause,precondition, mean, effect relations.
Inui?swork?s precision is high: 90% but the recall islow: 30%, because of unresolved anaphora.However, in our work, we extract multiple EDUswith some implicit discourse markers.Torisawa( 2003)?
s work in extracting the verbphrase pair from the news corpus worked on theassumption that if two events share a commonparticipant (is specified by a noun) then the twoevents are likely to have a logical relation ascausal relation.
For example ?A man drank18liquor and was intoxicated by the liquor.?
(acommon participant is ?liquor?).
However,  thisassumption can not be applied in our researchbecause most of our causality expression doesnot share a common participant; e. g.  ?  !
"/Ginger is used as being laxativemedicine.
[The ginger] stops constipation.Pechsiri and Kawtrakul (2007), proposedverb-pair rules learned by two different machinelearning techniques (NB and SVM) to extractcausality with multiple EDUs of a causative unitand multiple EDUs of an effect unit with theproblems of the discourse marker ambiguity andthe implicit discourse marker.
This verb-pairrule has been represented by the following equa-tion (1) (Pechsiri and Kawtrakul, 2007) where Vcis the causative verb concept set, Ve is the effectverb concept set , C is the Boolean variables ofcausality and non-causality, and a causative verbconcept (vc , where vcVc) and an effect verbconcept (ve , where veVe) are referred to Word-Net (http://wordnet.princeton.edu/) and the pre-defined plant disease information from Depart-ment of Agriculture (http://www.doa.go.th/).CausalityFunction:  Vc  Ve  C    (1)They also proposed using Vc and Ve to solvethe boundary of the causative unit and using theCentering theory along with Ve to solve theboundary of the effect unit.
The outcomes oftheir research were the verb-pair rule, Vc, Ve, andthe multiple EDUs of causality (extracted fromtextual data) was at their highest precision of89% and their highest recall of 76%.
The cor-rectness of the causality-boundary determinationis 88% on average.
However, our causative unitconsisted of only one EDU containing an EDU-like name entity as a cause, and this EDU wasfollowed by several effect EDUs.In our current work, we aimed at extractingthe Know-Why in Natural Language descriptioninstead of visualizing only associations ofconcepts, by applying both language processingand learning technique by Na?ve Bayes toidentify the causality expression.3 Problem of Know-Why ExtractionTo extract the cause-effect expressions, thereare two main problems that must be solved.
Thefirst problem is how to identify interesting cause-effect relations from the documents.
The secondproblem is how to determine the effect boundary.There is also the problem of implicit nounphrase.3.1 Causality IdentificationThe problem involves the word level and the sen-tence level.
For the word level, the medicinalname entity may express in the form of a sen-tence like name entity or an EDU- like name en-tity which explains the medicinal action as thecausative action of medicine, and medical char-acteristic.
The problem of this level is how toidentify the causative name entity.
For example:a)  ?/A basil leaf  #is used as #medicine #releases #gas?where ?a medicine releases gas?
is an EDU-like name entity with the causative action,?release?.b)  ?$%#Nicolson stem &#is used formaking #medicine #soaks in '#liquor?where ?a medicine soaks in liquor?
is anEDU-like name entity with the characteristicof medicine being preserved in the alcohol.The above examples, a) and b), contain anEDU-like name entity which is a cause in a) anda non cause in b).For the sentence level, the EDU containing anEDU-like name entity with the causative actionmay be followed by an effect EDU(s) to form thecause-effect or causality relation between theEDU like name entity and that followingEDU(s).
For example:CausalityEDU1 ?
('/Lemon grass is used as#medicine )contracts ,"#a uterus?
(where ?a medicine contracts a uterus.?
is theEDU-like name entity with concept of ?themedicine causes uterus to contract?.
)EDU2 ?
[The plant ] /discharges %&#period.?
(=The plant discharges period.
)Non causalityEDU1 ?/A basil leaf  #is used as#medicine #releases #gas.?
(where ?amedicine releases gas?
is the causative EDU-like name entity.
)19EDU2 ?
[the basil leaf]*#relieves !#ulcer#in'#stomach.?
(= [The basil leaf re-lives ulcer in a stomach.
)Where in this example, EDU 1 is the causeand EDU2 is the effect3.2 Effect Boundary DeterminationThere are two problems of an implicit effectboundary cue and the effect EDU containing in-terrupts.3.2.1  Implicit Effect Boundary CueSome cause-effect relations from the herbal websites are expressed in the form of the EDU con-taining an EDU like name entity with the causa-tive action followed by some effect EDUs with-out any cue of ending effect boundary, e.g.
?and?.
For example:EDU1 ?A basil leaf is used as #medicine #releases #gas?
(=A basil leaf isused as a medicine releasing gas.
)EDU2 ?
[The basil leaf ] #stops # nau-seate.?
(=The basil leaf stop being nausea.
)EDU3 ?
[And the leaf ]#stops /pain #abdomen.?
(= [And the leaf] stops painingabdomen.
)Where in this example, EDU 1 is the causeand EDU 2 & EDU3 are the effects.
EDU 2and EDU3 help us to determine the boundary.3.2.2 Effect EDU Containing InterruptsThere are some effect EDUs containing inter-rupts as shown in the following example:EDU1 ?'
#A red onion is used as #medicine +$ /be laxztive?
(=A red onion isused as a laxative medicine.
)EDU2 ?
[And the red onion ] #stops !
"#being constipation?
(= [And the red onion]stops being  constipation.
)EDU3 ?
[The red onion ] /discharges ,/urine.?
(= [The red onion] discharges urine.
)EDU4 ?
[The red onion makes a patient] % -'/be appetite.?
(= [The red onion] makes apatient] be appetite.
)Where the EDU-like name entity in EDU1 is acause with EDU2 and EDU4 as its effects.
TheEDU3 is an interrupt.
Although EDU3 is the ef-fect of red onions, but EDU 3 is not the effect oflaxatives.4 A Framework for Know-Why Extrac-tionFigure 1.
System OverviewThere are three steps in our framework.
First isthe corpus preparation step followed by causalitylearning, and causality recognition steps (asshown in figure 1).4.1 Corpus PreparationThere are two steps of pre-annotation and Cau-sality annotation.4.1.1  Pre-annotationThis step is the preparation of the corpus in theform of EDU from the text.
The step involvesusing Thai word segmentation tools to solve aboundary of a Thai word and tagging its part ofspeech (Sudprasert and Kawtrakul, 2003).
Thisprocess includes Name entity (Chanlekha andKawtrakul, 2004), and word-formation recogni-tion (Pengphom, et al2002) to solve the bound-ary of Thai Name entity and Noun phrase.After the word segmentation is achieved, EDUsegmentation is dealt with.
According to Charo-ensuk et al (2005), this process segments plaintext into units of EDUs by using the rule basedand the machine learning technique of C4.5(Mitchell T.M., 1997).
These generated EDUswill be kept as an EDU corpus.
This corpus willcontain 4500 EDUs and will be separated into 2parts, one part is 3500 EDUs for causality learn-ing and the other part of 1000 EDUs for causalityrecognition and extraction.4.1.2 Causality AnnotationDue to the problems in the causality identifica-tion, verbs from three EDUs (with one EDU asan EDU-like name entity) in the EDU corpus areused in this process to learn for extracting causal-ity.
Word ambiguity will be solved through theCorpus prepa-rationTextWord netKnow-WhyCausality learningCausality recognitionCausalityrelationCausality modelCausalityidentificationEffect bound-ary det.20finding of word concepts from Wordnet.
SinceThai Wordnet does not exist, we need to translatefrom Thai to English, using Lexitron (the Thai-English dictionary)( http://lexitron.nectec.or.th/),before using Wordnet(http://wordnet.princeton.edu/obtain).
In this process, we manually anno-tate the causality EDUs by annotating the EDUcontaining the causative EDU-like name entity asthe causative EDU.
We annotate a verb phrasein the causative EDU-like name entity to be acausative-verb-phrase concept (referred toWordnet).
The verb from EDU which containsthe causative EDU-like name entity is annotatedwith a concept and we call this verb as ?support-ing causative verb?.
We also annotate the effect-verb-phrase concept(referred to Wordnet andhttp://www.ars-grin.gov/duke/ethnobot.html)from effect EDUs following the EDU containingthe causative EDU-like name, as shown in Figure2)4.2 Causality LearningThe aim of this step was to learn cause-effectrelation between causative events and effectevents from annotating an EDU corpus.4.2.1 Feature ExtractionAll annotated verb features from the previousstep are extracted into database table (in Table 1)including surface forms of verb features alongwith their concepts used for probability determi-nation in the next step.NP1 NP1 Concept Vs Vs Concept VPcVPcconcept VPe VPe Concept ClassNaringicrenulataherb use ascurepoisonbe-antipyretic	relieve musclepain nAsiaticPennyworthherb leaf use asapplyexternallyapplytopically  heal wound y!red onion herbis"#excrete be-lexative 		!
$stop beingconstipation y!red onion herbis"#excrete be-lexative%&'' discharge urine n!red onion herbis"#excrete be-lexative(  be appetite y%)curcumin herbis*#)antiseptic be-antiseptic+,!cure skindisease y	!SoianumindicumLinnherb -make as)-.reducebloodsugarbalanceblood sugarlevel	/ stop coughing nBasil herb leaf use as%releasegasbecarminative 	,'	relieve nausea yBasil herb leaf use as%releasegasbecarminative		!stop painingan abdomen y%!ginger herb use as%releasegasbecarminative 	,'	relieve nausea y$bergamotleafherb leaf use as%releasegasbecarminative 	,'	relieve nausea y?
?
?
?
?
?
?
?
?Table 1.
The extracted features from the annotated corpus<C id=1><EDU type =cause><NP1 concept=a herb organ>.
'A basil leaf</NP1><VS concept=use#1>#is used as</VS><EDU-Like-NE  ><NP2 concept=drug>#medicine</NP2><CVC concept= be carminative/ eliminate gas from a body>#releases # gas</CVC></EDU-Like-NE></EDU></C><R id=1><EDU type=effect><EVC concept= stop nausea/ be anti nausea>#stops # nauseate.</EVC></EDU><EDU type=effect><EVC concept=stop paining an abdomen/ relieve abdominal pain>#stops /pain # abdomen</EVC></EDU></R>EDU= EDU, EDU-Like-NE= EDU-like name entity tag,C=cause tag, R=result or effect tag, VS= supporting verb tag ,CVC=causative verb concept tag, EVC=effect verb concept tagNP1 NP2= noun phrase tagFigure 2.
Causality Annotation Tag21Vs concept causalitynoncausality	0useas 0.27619 0.290323Be 0.561905 0.612903-0makeas 0.009524 0.032258	0-0use for making as 0.066667 0.053763?
?
?VPc concept causalitynoncausality?%+/release-gas?
0.371901 0.192661?	+//anti coughing?
0.024793 0.045872?/apply?
0.140496 0.009174?%/be-bitter?
0.041322 0.009174?%+&''/discharge-urine?
0.057851 0.06422?%+' /be expectorant?
0.041322 0.06422?1+$/contractuterus/oxytocic?
0.041322 0.027523?+ /be antidiabetic?
0.008264 0.027523?
?
?VPe concept causalitynoncausality?	++	!/stop-stomachach/relieve abdominalpain?
0.035714 0.007813?	+,'	/stop-naucea/be antinausea?
0.035714 0.007813?	+	!	!23/stop-flatulence/relieve indigestion?
0.15 0.007813?	+/stop-rash/ be antiurti-caria?
0.035714 0.023438?
/%	/reduce-fever?
0.021429 0.039063?%+/eliminate-placenta?
0.007143 0.054688?(+ /increase appetite?
0.092857 0.007813?%+!/release-sweat/be dia-phoretic?
0.007143 0.070313Table 2.
Show probability of Vs concept, VPcconcept and VPe concept4.2.2 Probability DeterminationAfter we had obtained the extracted verb features,we then determined the probability of causal andnon causal from the occurrences of the cartesianproducts of three verb feature concepts , shownin Table2, by using Weka  which is a softwaretool for machine learning (http://www.cs.
wai-kato.ac.nz/ml/weka/ ).4.3 Causality Recognition and ExtractionThe objective of this step was to recognize andextract the cause-effect relation from the testingEDU corpus.
In order to start the causality rec-ognition process, Na?ve Bayes Classifer shown inequation (2) is applied with the feature probabili-ties in Table 2, where EDUs class is determinedby class1 (causality EDUs) and class0 (non  cau-sality EDUs).Therefore, Causality Recognition can be sepa-rated into 2 steps: causality identification andeffect boundary determination.4.3.1 Causality IdentificationThis step was to determine the interesting loca-tions that are cause-effect relations by searchingany EDU which consists of a verb matching to averb in the supporting causative concept set, Vs,and an EDU-like name entity containing a causa-tive-verb-phrase concept as vpc (where vpcVPc).4.3.2 Effect Boundary DeterminationThe effect EDU and the effect boundary weredetermined at the same time by checking all se-quence  EDUs right after the EDU containing vpcin the EDU-like name entity.
If a verb phrasefrom the sequence of checked EDUs is not inVPe, the possible effect boundary is end.
Af-ter the possible boundary is determined, vs_inEDU1,vpc_inEDU1 and vpe_inEDU2..vpe_inEDUn (where n>2)will be used to determine the causality class fromthe Na?ve Bayes Classifier equation (2) as shownin Figure 3.
The actual effect boundary is deter-mined from the last class1 in the sequence ofEDU2.. EDUn.Furthermore, where the implicit noun phraseoccurs as the subject of the current EDU, this hasto be solved in this step by using the heuristicrule which is that the noun phrase as a subject ofthe previous EDU will be the subject of the cur-rent EDU.      setconceptPhraseVerbEffectaisVPwhereVPvpsetconceptPhraseVerbCausativeaisVPwhereVPvpsetconceptVerbCausativeSupportingaisVwhereVvclassPclassvpPclassvpPclassvPvpvpvclassPEDUclasseeecccsssecsClassclassecsClassclass)(|||maxarg,,|maxarg(2)225 Evaluation and ConclusionThe Thai corpora used to evaluate the proposedcausality extraction algorithm consist of about1,000 EDUs collected from several herbal websites.
The evaluation of the causality extractionperformance of this research methodology is ex-pressed in terms of the precision and the recallas shown below, where R is the causality relation:##of samples correctly extracted as RPrecisionof all samples output asbeing R(3)##of samples correctly extracted as RRecallof all samples holding the target relation R(4)The results of precision and recall are evalu-ated by three expert judgments with max winvoting.
The precision of the extracted causality85.5% with 79.8% recall.
The correctness of oureffect boundary determination by these expertjudgments is 86%.
These research results can beincreased if we use a larger corpus.
However,our methodology will be very beneficial for con-tribute the causality knowledge for supportingWhat-question with the concept of causal rela-tion from a web page by inference method ofbackward chaining, for example:Extracted causality: ?.
'  /A basil leaf is used for a gas releasedmedicine.
[The leaf] stops nausea.
[The leaf]stop stomachache.?
????
?.The above extracted causality can be repre-sented by the following predication.a) x   be_herb(x) ^ be_herb_medicine(y) ^be_carminative (y) ^  use_as(x,y) stop(x, z) ^be_nausea(z)b) x   be_herb(x) ^ be_herb_medicine(y) ^be_carminative (y) ^use_as(x,y) stop(x, z) ^be_abdominal pain(z)Where x  X,{?	/basil leaf?
?/ginger??
/black pepper?
?	/bergamot leaf?..
},and X is the extracted NP1 set from EDUs con-taining the causative EDU-like name entitiesand being followed by the effect EDUs , e.g.
(stop(x, z) ^ be_nausea(z)), (stop(x, z) ^ be_stomachache(z)).Question: ?#use #herb #what #stop#nausea (What kind of herb is used for stopnausea?
)The backward chaining from the above questionand the extracted causality in a) is shown in thefollowingstop(x, z) ^ be_nausea(z) be_herb(x) ^be_herb_medicine(y) ^  be_carminative (y) ^use_as(x,y)where  x  is  ?	/basil leaf?, ?/ginger?,?
/black pepper?, or ?	/bergamot leaf?ReferencesCarlson L., Marcu D., and Okurowski M. E. 2003.Building a Discourse-Tagged Corpus in theFramework of Rhetorical Structure Theory.
In Cur-rent Directions in Discourse and Dialogue.
pp.85-112.Chanlekha H. and Kawtrakul A.
2004.
Thai NamedEntity Extraction by incorporating Maximum En-tropy Model with Simple Heuristic Information.IJCNLP?
2004.Chareonsuk J ., Sukvakree T., and Kawtrakul A.2005.
Elementary Discourse unit Segmentation forAssume that each EDU is represented by (np vp)L is a list of EDUVPC is a causative-verb-phrase concept set, VPE /VPe is a effect-verb-phrase concept setVS is a supporting causative verb concept setCAUSALITY_EXTRACTION ( L, VC, VE, Vs )1 i  1, R 2 while i  length[L] do3 begin_while14CA  , EC  5if  (vpi  VS)  (vpi_in_NE  VPC) then6        begin_ifCA  CA 	 {i}, i  i + 1    /*CA is causative EDU7while (vpi  VPE) do8            begin_while29 res       )(|||maxarg),(cPcvpPcvpPcvP ecsnoyesc10            if  res=yes11EC  EC 	 {i},    /*EC is effectEDU12               i  i + 113              end_while214            endif15if res = yes  CA <>  then16R = R 	 { (CA,EC) }17 end_while118return RFigure3.
Show Causality Extraction algorithm forthe EDU containing the causative EDU-like nameentity, and followed by multiple effect EDUs .23Thai using Discourse Cue and Syntactic Informa-tion.
NCSEC 2005.Chang D.S.
and Choi K.S.
2004.
Causal Relation Ex-traction Using Cue Phrase and Lexical Pair Prob-abilities.
IJCNLP.
pp.
61 ?
70.Charniak, E. 2000.
A maximum-entropy-inspiredparser.
Proc.
of NAACL, pp.132-130.Girju R. and Moldovan D. 2002.
Mining answers forcausation questions.
AAAI Symposium on MiningAnswers from Texts and Knowledge Bases.Inui T., Inui K., and Matsumoto Y.
2004.
Acquiringcausal knowledge from text using the connectivemarkers.
Journal of the information processing so-ciety of Japan 45(3), pp.
919-993.Lemeire, J., S. Maes and E. Dirkx.
2004.
CausalModels for Parallel Performance Analysis.
FourthPA3CT-Symposium, Edegem, Belgium, Septem-ber.Marcu D. and Echihabi A.
2002.
An UnsupervisedApproach to Recognizing Discourse Relations.
inProceedings of the 40th Annual Meeting of the As-sociation for Computational Linguistics Confer-ence.
pp.
368 ?
375.Pechsiri C., Kawtrakul A. and Piriyakul R. 2005.Mining Causality Knowledge From  Text for Ques-tion Answering System.
IEICE Transactions on In-formation and Systems, Vol.E90-D, No.10 :1523-1533.Pengphon N., Kawtrakul A., and Suktarachan M.2002.
Word Formation Approach to Noun PhraseAnalysis for Thai.
SNLP.Mitchell T.M.
1997.
Machine Learning.
TheMcGraw-Hill Companies Inc. and MIT Press, Sin-gapore.Sudprasert S. and Kawtrakul A.
2003.
Thai WordSegmentation based on Global and Local Unsuper-vised Learning.
NCSEC?2003.Talmy, L. 2000.
Toward a Cognitive Semantics Con-cept Structuring Systems ?
Vol.
1.
The MIT Press.Torisawa K. 2003.
Automatic Extraction of Common-sense Inference Rules from Corpora.
In Proc.
OfThe 9th Annual Meeting of The Association forNatural Language Proceeding.
pp.
318-321.Trnkova, Jana, Wolfgang Theilmann.
2004.
Author-ing processes for Advanced Learning Strategies.Telecooperation Research Group,TU Darmstadt,and SAP Research, CEC Karlsruhe.
Germany.Wolff, P. 2007.
Representing Causation.
Journal ofexperimental psychology: General 2007 Vol.
136No.1 82-111.
USA.24
