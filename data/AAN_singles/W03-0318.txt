Input Sentence Splitting and TranslatingTakao Doi,  Eiichiro SumitaATR Spoken Language Translation Research Laboratories2-2-2 Hikaridai, Kansai Science City, Kyoto, 619-0288 Japan{takao.doi, eiichiro.sumita}@atr.co.jpAbstractWe propose a method to split and translateinput sentences for speech translation in orderto overcome the long sentence problem.
Thisapproach is based on three criteria used tojudge the goodness of translation  results.The criteria utilize the output of an MT sys-tem only and assumes neither a particular lan-guage nor a particular MT approach.
In anexperiment with an EBMT system, in whichprior methods cannot work or work badly, theproposed split-and-translate method achievesmuch better results in translation  quality.1 IntroductionTo achieve translation technology that is adequate forspeech translation, the possibilities of several corpus-based approaches are being investigated.
Among thesemethods, DP-match Driven transDucer (D3) has beenproposed as an Example-Based Machine Translation(EBMT).
When D3 is adapted to Japanese-to-Englishtranslation in a travel conversation domain, the methodcan achieve a high translation quality (Sumita, 2001 and2002).
On the other hand, the translation method is sen-sitive to the long sentence problem, where longer inputsentences make it more difficult for a machine transla-tion (MT) system to perform good translation.
To over-come this problem, the technique of splitting an inputsentence 1  and translating the split sentences appearspromising.The methods of previous studies related to this ap-proach can be roughly classified into two types: onesplits sentences before translation and the other splitsthem in the parsing phase of translation.
We?ll call theformer pre-process-splitting, the latter parse-time-1 Strictly speaking, this isn't necessarily a sentence but anutterance including sentences.
In this paper, we use the termsentence without strictly defining it to simplify discussion.splitting, and translation with any splitting split-and-translate.In previous research on pre-process-splitting, such asTakezawa (1999), many methods have been basedon word-sequence characteristics.
Some research effortshave achieved high performance in recall and precisionagainst correct splitting positions.
Despite such a highperformance, from the view point of translation, MTsystems are not always able to translate the split sen-tences well.In some research works  on parse-time-splitting,such as Furuse (1998 and 2001), sentences have beensplit based on parsing trees under construction.
Partlyconstructed trees are combined and translated.
A sen-tences is split according to the sub-trees.
The split sen-tences can be translated because an internal parsingmechanism guarantees their fitness.
However, parse-time-splitting technique cannot be adapted, or can beadapted only as pre-process-splitting by using an exter-nal parsing system, to MT systems that deal with noparsing tree, such as D3 and Statistical MT.In this paper, we propose another split-and-translatetechnique in which splitting and translation act in har-mony.
This technique depends on no particular MTmethod, therefore can be applied to D3.
In order toprove the effect for translation quality, our proposedsplit-and-translate method and, for the purpose of com-parison, a pre-process-splitting technique are evaluated.For convenience, we'll call the two split-and-translatemethods in our experiments as follows.method-T: Our proposed method based on partial Trans-lation results, described in section 2.method-N: Before translation, splitting an input sen-tence with the pre-process-splitting method  basedon N-gram, described in section 3.The following sections describe the two methods, theMT system, D3 that the methods are applied to, and ex-periments.2 Proposed Split-and-Translate: Method-TAn MT system sometimes fails to translate an input, forexample, due to failure in parsing a sentence or retriev-ing examples.
Such a failure occurs particularly whenan input is longer.
In such a case, by splitting the input,translation may be successfully performed for each por-tion.
Therefore, one idea is to arrange the translations ofsplit portions in the same order as in the source sentenceand to consider the arrangement as a translation of theentire input sentence.
Particularly in a dialogue, sen-tences tend not to have complicated nested structures,and many long sentences can be split into mutually in-dependent portions.
Therefore, if splitting positions andtranslations of split portions are adequate, the possibilitythat this simple arrangement of the translations can pro-vide an adequate translation of the complete input isrelatively high.In the example below, a Japanese sentence (1-j) haspotentially adequate splitting positions such as (1-j').The arrangement of the English translations of the por-tions (1-e) is an adequate translation.
(1-j) sou desu ka ee kekkou desu jaa tsuin de o negai shimasu2(1-j?)
sou desu ka | ee | kekkou desu | jaa | tsuin de onegai shi masu(1-e) i see | yes | that's fine | then | a twin please2.1 CriteriaWhen you split-and-translate a sentence, some por-tions can be translated while others cannot.
We call thecount of words in the portions that cannot be translatedthe fault-length.
It is natural to consider (X) as a crite-rion to judge the goodness of split-and-translate results.
(X) The smaller the fault-length is,  the better the resultis.Let the term partial-translation be the translation of aportion that can be translated.
In a split-and-translateresult, there can be some partial-translations.
Partial-translation-count expresses the number of partial-translations.
(Y) is also a natural criterion to judge thegoodness of a split-and-translate result.
(Y) The smaller the partial-translation-count is, thebetter the result is.Many current MT methods produce not only target sen-tences but also scores.
The meaning of a score, depend-2 Its English translation is ?I see.
Then, fine, we?ll take atwin.?
in a corpusing on the translation method, can be parsing cost, dis-tance between sentences, word correspondence prob-ability, or other meanings or combinations of the above.If there is a correlation between the score and the trans-lation quality, we can make use of this score as a confi-dence factor of translation.
We can use the confidencefactor as another criterion for split-and-translate results.In order to ensure reliability for the complete result ofsplit-and-translate procedures from confidence factors,the scores of all partial-translations are combined.
Wecall this combined score the combined-reliability.
Howto combine scores depends on the mathematical charac-teristics of the scores.
Therefore the third criterion (Z) isadded.
(Z) The higher the combined-reliability is, the better theresult is.From the above considerations, the proposed methodutilizes these criteria to judge the goodness of split-and-translate results with the priority as follows.1.
The smaller the fault-length is, the better the resultis.2.
Unless judged with criterion-1, the smaller thepartial-translation-count is, the better the result is.3.
Unless judged with criterion-1 or criterion-2, thehigher the combined-reliability is, the better theresult is.The case where translation can be performed withoutsplitting meets these criteria.
In this case, the fault-length is 0, the partial-translation-count is 1, and thecombined-reliability equals the score of the completetranslation that must be utilized by the MT system;therefore, this result is the best.Criterion-3 has a low priority.
Unless an MT systemhas a confidence factor, only criteria-1-2 are used.These three criteria are based on the output of anMT system, that is, how well the MT system can trans-late portions.
Split portions are translated, and the par-tial-translation results are evaluated to select the bestsplit positions (the algorithm is discussed in section 6).As the proposed split-and-translate method is based onthese criteria only, this method assumes no parsingprocess and depends on neither a particular languagenor a particular MT method.2.2 ExampleBelow, we show an example of selecting a resultfrom candidates based on criteria-1-2.
(2-j) hai wakari mashi ta sore to ne choushoku na n desukedomo dou nat teru n deshou ka3(2-j') hai | wakari mashi ta | sore to ne | choushoku na ndesu kedomo | dou nat teru n deshou kaFor a Japanese input (2-j), there are many candidates ofsplitting points such as (2-j?).
We consider three split-tings: (2-a), (2-b) and (2-c).
(2-a) hai wakari mashi ta | sore to ne choushoku na ndesu kedomo dou nat teru n deshou ka(2-b) hai wakari mashi ta sore to ne choushoku na ndesu kedomo | dou nat teru n deshou ka(2-c) hai wakari mashi ta | sore to ne choushoku na ndesu kedomo | dou nat teru n deshou kaSuppose the partial translations corresponding to thesecandidates are as follows, where fault-lengths and par-tial-translation-counts are calculated.(2-a?
)hai wakari mashi ta => yes i seesore to ne cyoushoku na n desu kedomo dou nat terun deshou ka=> and what about breakfastfault-length = 0partial-translation-count = 2(2-b?
)hai wakari mashi ta sore to ne choushoku na n desukedomo => FAILdou nat teru n deshou ka => what happened to itfault-length = 12partial-translation-count = 1(2-c?
)hai wakari mashi ta => yes i seesore to ne choushoku na n desu kedomo => and ibreakfastdou nat teru n deshou ka => what happened to itfault-length = 0partial-translation-count = 3(2-a) and (2-c) are better than (2-b) based on criterion-1,and (2-a) is better than (2-c) based on criterion-2, so therank is (2-a), (2-c), (2-b).3 Pre-Process-Splitting for Method-NFor splitting input sentences as a pre-process of MTsystems, we consider a previous study of pre-process-splitting.
Many pre-process-splitting methods are basedon word-sequence characteristics.
Among them, we usethe method of Takezawa (1999), a pre-process-splittingbased on the N-gram of part-of-speech subcategories.3 Its English translation is ?I see.
And also how about break-fast??
in a corpusThis method is derived from that of Lavie (1996) andmodified especially for Japanese.The function of this method is to infer where split-ting positions are.
Splitting positions are defined as po-sitions at which we can put periods.
For each position,to calculate the plausibility that the position is a splittingposition, we consider the previous two words and thefollowing one word, three words in total.
Part-of-speechand conjugation-type are considered as word character-istics.
When the plausibility is higher than a giventhreshold, the position is regarded as a splitting position.The threshold is manually selected to tune the perform-ance for a training set.
Equation [1] shows how to calcu-late the plausibility~F .
[1]            32213221321~wwCwwCwwCwwCwwwF,where~F ([w1w2 w3]) is the plausibility that the posi-tion after a word sequence w1w2  and before a word w3is a splitting position,   [wlwm] is a bigram, [wlwmwn] isa trigram,   indicates a boundary of sentences, andC(N-gram) means the appearance count of the N-gramin a training set.It has also been reported that, for Japanese, threeheuristics for Japanese part-of-speech and conjugation-type improve the performance.
The heuristics indicatethat the positions before and after particular part-of-speeches with particular conjugation types must or mustnot be splitting positions.4 Applying Split-and-Translate to MTSystemsWe apply the two split-and-translate methods to an MTsystem, D3.
To apply method-N to an MT system isstraightforward.
When applying method-T, we considerthe confidence factor of the MT system for criterion-3,rather as an optional criterion.4.1 D3 OverviewD3 (Sumita, 2001) is an EBMT whose language re-sources are [i] a bilingual corpus, in which sentences arealigned beforehand; [ii] a bilingual dictionary, which isused for word alignment and generating target sen-tences; and [iii] thesauri of both languages, which areused for aiding word alignment and incorporating thesemantic distance between words into the word se-quence distance.D3 retrieves the most similar source sentence of exam-ples from a bilingual corpus.
For this purpose, DP-matching is used, which tells us the distance betweenword sequences, dist, while giving us the matched por-tions between the input and the example.
dist is calcu-lated as equation [2].
The counts of Insertion (I),Deletion (D), and substitution operations are summed.Then, this total is normalized by the sum of the lengthsof the source and example sequences.
Substitution isconsidered the semantic distance between two substi-tuted words, or SEMDIST, which is defined using a the-saurus and ranges from 0 to 1.
[2]exampleinput LLSEMDISTDIdist2The characteristics of D3, especially in comparison withmost EBMT proposals, are a) D3 does not assume syn-tactic parsing and bilingual tree-banks; b) D3 generatestranslation patterns on the fly according to the input andthe retrieved translation examples as needed; c) D3 usesexamples sentence-by-sentence and does not combineexamples.Because of c), D3's result is pretty good when a simi-lar example is retrieved, but very bad otherwise.
There-fore, we usually decide a threshold.
If there is noexample whose dist is within the given threshold, wemust give up performing translation.In an experiment using Basic Travel Expression Corpus(BTEC, described as BE-corpus in Takezawa, 2002),D3?s translation quality is very high.
The experimentalso shows a clear correlation between dist and the qual-ity of translation.
In other words, the accuracy decreasesas the dist increases.
In particular, the longer input sen-tences are, the more difficult for D3 to find exampleswith a small dist.4.2 Applying Method-T to D3As there is a correlation between dist and the translationquality, we can make use of dist as a confidence factor.To make the combined-reliability, each partial transla-tion is weighted with its source word's number.
That is,for each partial translation, its dist is multiplied by itssource portion's length, and the resulting values aresummed.
[3] combined reliability portionportion LdistAdapting to D3, criterion-3 is instantiated by the com-bined-reliability defined in equation [3].5 Experiment5.1 PreliminaryTarget SystemsWe investigated the two split-and-translate methodsusing D3 in Japanese-to-English translation.
We used aJapanese-and-English bilingual corpus, BTEC as thetraining set for D3 and the Japanese part of BTEC asthat for pre-process-splitting method for method-N.BTEC is a collection of Japanese sentences and theirEnglish translations usually found in phrase-books forforeign tourists.
The statistics of the corpus is shown inTable 1.Regarding D3, the threshold for dist is 1/3.For the pre-process-splitting method of method-N,the combinations of the parameters were used:  1)whether the heuristics for Japanese are used or not; 2)the threshold of splitting plausibility.
The best resultswere selected from among the combinations in subsec-tions 5.3 and 5.5.Table 1.
Corpus StatisticsJapanese English# of sentences 152,172# of words 1,039,482 890,466Vocabulary size 18,098 11,690Average sen-tence length 6.83 5.85EvaluationThe target is Japanese-to-English translation in this ex-periment.
We extracted a test set from Bilingual TravelConversation Corpus of Spoken Language (TC-corpus,Takezawa, 2002).
All of the contents of TC-corpus aretranscriptions of spoken dialogues between Japaneseand English speakers through human interpreters.
Thetest set of this experiment is 330 Japanese sentencesfrom TC-corpus including no sentences spoken by theinterpreters.
The average length of the sentences in thetest set is 11.4 (words).
Therefore, the test sentencesused in this experiment are much longer than the sen-tences in the training set, BTEC.In this experiment, each translation result is gradedinto one of four ranks (described below) by a bilingualhuman translator who is a native speaker of the targetlanguage, American English:(A) Perfect: no problem in either information orgrammar;(B) Fair: easy-to-understand with some unimportantinformation missing or flawed grammar;(C) Acceptable: broken but understandable with effort;(D)  Nonsense: important information has been trans-lated incorrectly (Sumita, 1999).Adding to the four ranks, we use FAIL, or F, to indicatethat there is no output sentence.5.2 Translation without SplittingTranslations of the test set by D3 without splitting wereperformed.
The coverage of the output is lower.
For 127sentences, D3 cannot yield results.
The average length ofthe 127 sentences is 15.6.
Afterward, we used these 127sentences as the test set for split-and-translate methods.5.3 Pre-Process-Splitting QualityBefore evaluating translation qualities of split-and-translate methods, we calculated the quality of the pre-process-splitting method of method-N on the 127 sen-tences.
The positions where periods were manually in-serted were regarded as the correct splitting positions.
Inthe manual splitting process, they put periods at posi-tions considered both grammatically and semanticallyadequate.
There were 60 splitting positions, and 79 sen-tences, accounting for 62% of the 127 sentences, had nosplitting position.
Table 2 shows the numbers of sen-tences corresponding to those of splitting positions in asentence.Table 2.
Number of splitting positions in asentence vs. total number of sentences# of split positions 0 1 2 3# of sentences 79 37 10 1The evaluation measure is based on how closely theresult of the method corresponds to the correct solution,that is, recall and precision.
We got a good result.
Thecount of inferred positions is 65 in total, in which 55positions are correct and 10 are incorrect, that is, recallis 91.7% and precision is 84.6%.We also conducted an experiment on method-T as amethod for only splitting sentences, extracting partial-translation boundaries.
The result was bad: The count ofinferred positions is 277 in total, in which 28 positionsare correct and 249 are incorrect, that is, recall is 46.7%and precision is 10.1%.
Although a smaller number ofsplittings is preferred with method-T, when most of thetranslations of long portions fail, method-T results inover-splitting.The results show that the performance of method-Nis much better than that of method-T when the target isonly to split sentences.5.4 Translation Quality of Method-TApplying method-T to D3, we performed translations ofthe 127 sentences by D3.
Table 3 shows the results, thenumber of each evaluation rank and the rate of the totalnumber for each rank and better ranks than itself.
Asshown in the table, the rate of output is 100%, and therate of success, which means that the rank is A, B or C,is 42.5%.Table 3.
Number and percentage of each Rank(Method-T)A(A)B(A+B)C(A+B+C)D(A+B+C+D)F4(3.1%)16(15.7%)34(42.5%)73(100%)0There are correlations between quality ranks and fault-length or partial-translation-count.
When the ratio ofthe fault-length to the entire input length is greater than40% or the partial-translation-count is greater than 4,no result is successful.Figure 1.
Success rate and dist-in-splittingFurthermore, we can observe a correlation between suc-cess rate and dist-in-splitting in Figure 1. dist-in-splitting is defined by equation [4], an extension of dist,and ranges from 0 to 1.
These correlations can give us aconfidence factor on split-and-translate results.
[4] dist in splittinginputportionportionLLdist  ,where 0.1portiondist  when the portion cannot betranslated.dist-in-splitting <0204060801000.10.15 0.20.25 0.30.35 0.40.45 0.50.55 0.60.65 0.70.75 0.8A+B+C(%)5.5 Translation Quality of Method-NApplying method-N to D3, we performed translations ofthe 127 sentences by D3.
Table 4 shows the results,which give the largest rate of success among the combi-nations of the parameters.Table 4.
Number and percentage of eachRank (Method-N)A(A)B(A+B)C(A+B+C)D(A+B+C+D)F4(3.1%)7(8.7%)16(21.3%)85(88.2%)15The condition that is good for sentence splitting qualityis not good for split-and-translate quality.
On the condi-tion of the parameters that gave the recall of 91.7% andthe precision of 84.6%, the rate of output was 41.7%and that of success 6.3%.
According to the correct split-ting solution, among the 127 sentences that D3 fails totranslate without splitting, 79 sentences have no split-ting position.
Therefore, a good splitting for recall andprecision has low probabilities for the rate of output andthat of success.
Put simply, when the threshold issmaller, although precision is worse, the rate of outputand that of success are larger.
However, the rates aremuch lower than those of method-T?s results.5.6 Summary of ExperimentsTable 5.
Splitting Quality and Split-and-TranslateQualitySplitting Split-and-Translaterecall precision successrateoutputrateMethod-T 46.7% 10.1% 42.5% 100.0%Method-N 91.7% 84.6% 21.3% 88.2%Table 5 shows the summary of experiments.
Thoughmethod-N is better in sentence splitting quality, method-T is better in split-and-translate quality.6 Concluding RemarksWe have proposed a split-and-translate method andshown its effect through experiments.
However, muchmore work remains to be accomplished.To Improve AccuracyThe proposed method is based on three criteria.
Al-though we have shown one combination of the criteria,there may be better combinations.
Another possibilitymight be to integrate our method with another pre-process-splitting method, for example, by giving higherpriorities to splitting positions as the latter method im-plies, which can be also used to improve the efficiencydiscussed below.For EfficiencyLet N be the length of an input sentence, a naive imple-mentation must search the solution in 2N-1 combinations,while trying (N+1)N/2 kinds of partial translations.However, there are several ways to optimize the algo-rithm.
For example, it can be regarded as a shortest pathproblem, where each portion is an arc and portionswithout translations have high costs.
There are effectivealgorisms for a shortest path problem.
In addition, whenthe quality of translation has correlations with fault-length, partial-translation-count, and dist-in-splitting,as observed in subsection 5.4, candidates can be prunedby placing constraints on these factors.AcknowledgementsThe research reported here was supported in part by acontract with the Telecommunications AdvancementOrganization of Japan entitled, ?A study of speech dia-logue translation technology based on a large corpus?.ReferencesTakezawa, T. et al 2002.
Toward a Broad-coverageBilingual Corpus for Speech Translation of TravelConversations in the Real World, Proc.
of  LREC-2002Sumita, E. et al 1999 Solutions to Problems Inherent inSpoken-language Translation: The ATR-MATRIXApproach, Proc.
of MT Summit VIIBerger, A.L.
et al 1996.
A Maximum Entropy Ap-proach to Natural Language Processing, Associationfor Computatial LinguisticsLavie, A. et al 1996.
Input Segmentation of Spontane-ous Speech in JANUS: a Speech-to-speech Transla-tion System, Proc.
of ECAI-96 Workshop onDialogue Processing in Spoken Language SystemsTakezawa, T. et al 1999.
Transformation into Meaning-ful Chunks by Dividing or Connecting UtteranceUnits, Journal of Natural Language Processing, Vol.
6No.
2 (in Japanese)Nakajima, H. et al 2001.
The Statistical LanguageModel for Utterance Splitting in Speech Recognition,Transactions of IPSJ, Vol.
42 No.
11 (in Japanese)Kim, Y.
B. et al 1994.
An Automatic Sentence Break-ing and Subject Supplement Method for J/E MachineTranslation, Transactions of IPSJ, Vol.
35 No.
6 (inJapanese)Furuse, O. et al 1998.
Splitting Long or Ill-formed In-put for Robust Spoken-language Translation, Proc.
ofCOLING-ACL?98, pp.
421-427Furuse, O. et al 2001.
Splitting Ill-formed Input forRobust Multi-lingual Speech Translation, Transac-tions of IPSJ, Vol.
42 No.
5 (in Japanese)Wakita, Y. et al 1997.
Correct parts extraction fromspeech recognition results using semantic distancecalculation, and its application to speech translation.Proc.
of ACL/EACL Workshop on Spoken LanguageTranslation, pp.
24-31Sumita, E. 2001 Example-based machine translationusing DP-matching between word sequences, Proc.
ofDDMT Workshop of 39th ACLSumita, E. 2002.
Corpus-Centered Computation, ACL-02 Workshop on Speech-to-speech Translation, pp.
1-8
