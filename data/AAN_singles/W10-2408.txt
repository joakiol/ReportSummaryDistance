Proceedings of the 2010 Named Entities Workshop, ACL 2010, pages 57?61,Uppsala, Sweden, 16 July 2010. c?2010 Association for Computational LinguisticsLanguage Independent Transliteration Mining System Using Finite StateAutomata FrameworkSara Noeman and Amgad MadkourHuman Language Technologies GroupIBM Cairo Technology Development CenterP.O.Box 166 El-Haram, Giza, Egypt{noemans,amadkour}@eg.ibm.comAbstractWe propose a Named Entities translitera-tion mining system using Finite State Au-tomata (FSA).
We compare the proposedapproach with a baseline system that uti-lizes the Editex technique to measure thelength-normalized phonetic based edit dis-tance between the two words.
We sub-mitted three standard runs in NEWS2010shared task and ranked first for Englishto Arabic (WM-EnAr) and obtained an F-measure of 0.915, 0.903, and 0.874 re-spectively.1 IntroductionNamed entities transliteration is a crucial task inmany domains such as cross lingual informationretrieval, machine translation, and other naturallanguage processing applications.
In the previousNEWS 2009 transliteration task, we introduced astatistical approach for transliteration generationonly using the bilingual resources (about 15k par-allel names) provided for the shared task.
ForNEWS2010, the shared task focuses on acquisi-tion of a reasonably sized, good quality namescorpus to complement the machine transliterationtask.
Specifically, the task focuses on mining theWikipedia paired entities data (inter-wiki-links) toproduce high-quality transliteration data that maybe used for transliteration generation tasks.2 Related WorkFinite state Automata is used to tackle many Nat-ural Language Processing challenges.
Hassan(2008) et al proposed the use of finite state au-tomata for language-independent text correction.It consists of three phases : detecting misspelledwords, generating candidate corrections for themand ranking corrections.
In detecting the mis-pelled words, they compose the finite state au-tomaton representation of the dictionary with theinput string.
Onaizan (2002) et al proposedthe use of probabilistic finite state machines formachine transliteration of names in Arabic text.They used a hybrid approach between phonetic-based and spelling-based models.
Malik (2008)et al proposed a Hindi Urdu machine translit-eration system using finite state machines.
Theyintroduced UIT (universal intermediate transcrip-tion) on the same pair according to thier phoneticproperties as a means of representing the languageand created finite state transducers to representthem.
Sherif (2007) proposed the use of memo-ryless stochastic transducer for extracting translit-eration through word similarity metrics.Other approaches for transliteration includetranslation of names through mining or throughusing machine translation systems resources.
Has-san (2007) et al proposed a framework for extrac-tion of named entity translation pairs.
This is donethrough searching for candidate documents pairsthrough an information retrieval system and thenusing a named entity matching system which re-lies on the length-normalized phonetic based editdistance between the two words.
They also usea phrase-based translation tables to measure simi-larity of extracted named entities.
Noeman (2009)also used a phrase based statistical machine trans-lation (PBSMT) approach to create a substringbased transliteration system through the generatedphrase table, thus creating a language indepen-dent approach to transliteration.
Other resourceshave been used to perform transliteration.
Chang(2009) et.
al proposed the use of a romanizationtable in conjunction with an unsupervised con-straint driven learning algorithm in order to iden-tify transliteration pairs without any labelled data.3 System architectureThe approach consists of three main phases whichare (1) Transliteration model learning, (2) Fi-57Figure 1: Transliteration table learning in PBSMTnite State machine formalization of the generatedtransliteration model and (3) Generating Candi-date transliterations.
Figure (1) illustrates Translit-eration table learning in PBSMT framework.
Adetailed description of each phase is given in thefollowing sections.3.1 Transliteration model learningThe objective of NEWS2010 shared task is to de-velop a system for mining single word translitera-tion pairs from the standard Wikipedia paired top-ics (Wikipedia Inter-Language Links, or WIL1),using a seed data of only 1000 parallel names.
Theaim is to learn one-to-many character sequencemappings on both directions.We propose the use of MOSES framework1 forPBSMT training which was applied on the 1k par-allel seed data.
The proposed approach depends onthe formulation of the transliteration problem us-ing the PBSMT approach used in Machine trans-lation.
Giza++ Hidden Markov Model (HMM)aligner2 proposed by Och (1999) was also usedover the parallel character sequences.
Heuristicswere used to extend substring to substring map-pings based on character-to-character alignment.This generated a substring to substring translationmodel such as in Koehn (2003).
The phrase ?sub-string?
table was filtered out to obtain all possi-ble substrings alignment of each single characterin the language alphabet in both directions.
Thismeans that for each character in the source lan-guage (English) alphabet, substrings mapped to itare filtered with a threshold.
Also for each char-acter in the target language (Arabic) alphabet, allEnglish substrings mapped to it are filtered witha threshold.
These two one-to-many alignmentswere intersected in one ?Transliteration Arabic-to-English mapping?.
We obtained a character align-ment table which we refer to as ?Ar2En list?.
Fig-ure(2) illustrates a sample one-to-many alignmentmapping.1MOSES Framework: http://www.statmt.org/moses/2GIZA++ Aligner: http://fjoch.com/GIZA++.htmlFigure 2: One to Many Alignment Mapping1a:a/0b:b/02/0.25<epsilon>:a/0<epsilon>:b/0a:<epsilon>/0a:b/0b:<epsilon>/0b:a/03a:b/04b:a/0a:a/0b:b/0b:a/0a:b/0Figure 3: Edit distance 1 FSM3.2 FSM formalization of TransliterationModelThe proposed method makes use of the finite stateautomaton representation for the Ar2En characteralignment list, where the input is the source char-acter and the output is the target character.
We re-fer to this finite state transducer (FST) as ?Ar2EnFST?.
For each source word, we build a FiniteState Acceptor (FSA), such that each candidatesource word FSA is composed with the ?Ar2EnFST?.
For the target words list, we build a finitestate acceptor (FSA) that contains a path for eachword in the target Wiki-Link.3.3 Generating Candidate transliterationsThe task of generating candidate transliterationsat edit distance k from initial source candidatetransliterations using Levenshtein transducer canbe divided into two sub tasks: Generating a list ofwords that have edit distance less than or equal kto the input word, and selecting the words inter-581a:a/0b:b/02/0.25<epsilon>:a/0<epsilon>:b/0a:<epsilon>/0a:b/0b:<epsilon>/0b:a/04a:b/05b:a/0a:a/0b:b/03/0.5<epsilon>:a/0<epsilon>:b/0a:<epsilon>/0a:b/0b:<epsilon>/0b:a/06a:b/07b:a/0b:a/0a:b/0a:a/0b:b/0b:a/0a:b/0Figure 4: Edit distance 2 FSMsecting with the target inter-wiki-link words.
Thisis similar to the spelling correction technique thatused FSM which was introduced by Hassan (2008)et.
al.
In the spelling correction task , after gener-ating the list of words within edit distance k to theinput word, the system selects a subset of thosewords that exist in a large dictionary.
In order toaccomplish this same scenario, we created a sin-gle transducer (Levenshtein transducer) that whencomposed with an FSM representing a word gen-erates all words within an edit distance k from theinput word.
We then compose the resulting FSMwith an FSA (finite state acceptor) of all words inthe target inter-wiki-link.
The Levenshtein trans-ducer is language independent and is built onlyusing the alphabet of the target language.
Figure(3) and Figure (4) illustrate the Levenshtein trans-ducer for edit distance 1 and 2 over a limited set ofvocabulary (a, b).4 Data and Resources ProcessingAfter revising the training data (inter-wiki-links)released, we discovered that English and Arabicwords contained many stress marks and non nor-malized characters.
We therefore applied normal-ization on Arabic and English characters to in-crease source target matching probability, thus in-creasing the recall of data mining.
We also nor-malized Arabic names, removing all diacritics andkashida.
Kashida is a type of justification used insome cursive scripts such as Arabic.
Also we nor-malized Alef () with hamza and madda to go to?bare Alef?.Figure 5: Using Levenshtein edit-1 FST5 Standard runsWe submitted 6 runs derived from 3 experiments.For each experiment, we submitted 2 runs, onewith normalized Arabic and English characters,and the other with the stress marks and specialcharacters.
It is important to note that we run themining in the Arabic to English direction, thus theArabic side is the source and the English side isthe target.5.1 Using Levenshtein edit distance 1 FSTFigure (5) illustrates the algorithm used to con-duct the first experiment.
We subjected all sourcewords to be composed with Levenshtein edit dis-tance 1.
For each Wiki-Link, we build a finitestate acceptor (FSA) that contains a path for eachword in the Arabic Wiki-Link.
We refer to it asFSA[@ArWords].
Similarly, for the English namecandidates we build a finite state acceptor (FSA)that contains a path for each word in the EnglishWiki-Link.
We refer to it as FSA[@EnWords].The generated @ArWords and @EnWords are thelists of words in the Arabic and English wiki-linksrespectively.
The result of this experiment was re-ported as Standard-3 ?normalized characters?
andStandard-4 ?without normalized characters?.5.2 Using Levenshtein up to edit distance 2FSTFigure (6) illustrates the algorithm used to conductthe second experiment.
We use a threshold on thenumber of characters in a word to decide whetherit will be subjected for ?composed with?
edit dis-59Figure 6: Using Levenshtein edit-2 FSTtance 0 or 1 or 2.
We use a threshold of 3 foredit distance 1 and a threshold of 7 for edit dis-tance 2.
The threshold values are set based on ourprevious experience from dealing with Arabic textand could be derived from the data we obtained.If word length is less than or equal 3 letters, thenit is not composed with Levenshtein FSTs, and ifword length is between 4 to 7 letters, we composeit with edit distance 1 FST.
Longer words are com-posed with edit distance 2 FST.
The result of theexperiment was reported in two submitted runs:Standard-5 ?normalized characters?
and Standard-6 ?without normalized characters?.5.3 BaselineWe use a length-normalized phonetic edit distanceto measure the phonetic similarity between thesource and target Named Entities in the inter-wiki-links.
We use the Editex technique Zobel (1996)that makes use of the phonetic characteristics ofindividual characters to estimate their similarity.Editex measures the phonetic distance betweenpairs of words by combining the properties ofedit distances with a letter grouping strategy thatgroups letters with similar pronunciations.
The re-sult of this experiment was reported in two submit-ted runs: Standard-1 ?normalized characters?
andSubmission F-Score Precision RecallStandard-6 0.915 0.887 0.945Standard-4 0.903 0.859 0.952Standard-2 0.874 0.923 0.830Standard-5 0.723 0.701 0.747Standard-3 0.716 0.681 0.755Standard-1 0.702 0.741 0.666Table 1: Shared Task ResultsStandard-2 ?without normalized characters?.6 ResultsTable (1) illustrates the results of the shared taskgiven on the runs we submitted.Our baseline run (Standard-2) reports highestprecision of 0.923 and lowest recall of 0.830 (low-est F-score = 0.874).
The reason is that Editextechnique measures the edit distance based on let-ter grouping strategy which groups letters withsimilar pronunciations.
It operates on character tocharacter level.
Letters that are mapped to multi-characters will suffer a large edit distance and mayexceed the matching threshold used.The two runs Standard-4 and Standard-6 areimplemented using edit-distance FSM matchingbetween source and target.
They cover one-to-many character mapping.
We notice that Standard-6 run reports higher precision of 0.887 comparedto 0.859 for Standard-4 run.
This reflects the ef-fect of using variable edit-distance according tothe source word length.
The Standard-6 reportsa Recall of 0.945 producing our best F-Score of0.915.
Standard-6 recall degrades only 0.7% fromStandard-4 Recall (0.952).7 ConclusionWe proposed a language independent transliter-ation mining system that utilizes finite state au-tomaton.
We demonstrated how statistical tech-niques could be used to build a language indepen-dent machine transliteration system through uti-lizing PBMT techniques.
We performed 3 stan-dard experiments each containing two submis-sions.
FSM edit distance matching outperformedEditex in F-Score and Recall.
The proposed ap-proach obtained the highest F-Score of 0.915 anda recall of 0.945 in the shared task.60ReferencesAhmed Hassan, Haytham Fahmy, Hany Hassan 2007.Improving Named Entity Translation by ExploitingComparable and Parallel Corpora.
AMML07Ahmed Hassan, Sara Noeman, Hany Hassan 2008.Language Independent Text Correction using FiniteState Automata.
IJCNLP08.Franz Josef Och, Christoph Tillmann, and HermannNey 1999.
Improved Alignment Models for Statisti-cal Machine Translation.
EMNLP.Justin Zobel and Philip Dart 1996.
Phonetic stringmatching: Lessons from information retrieval.
InProceedings of the Annual ACM References Con-ference on Research and Development in Informa-tion Retrieval (SIGIR).M.
G. Abbas Malik, Christian Boitet, Pushpak Bhat-tacharyya 2008.
Hindi Urdu Machine Transliter-ation using Finite-state Transducers.
Proceedingsof the 22nd International Conference on Computa-tional Linguistics (Coling 2008), pages 537544Ming-Wei Chang, Dan Goldwasser, Dan Roth,Yuancheng Tu 2009.
Unsupervised ConstraintDriven Learning For Transliteration Discovery.Proceedings of Human Language Technologies: The2009 Annual Conference of the North AmericanChapter of the Association for Computational Lin-guistics.Philipp Koehn, Franz Josef Och, Daniel Marc 2003.Statistical Phrase-Based Translation.
Proc.
Of theHuman Language Technology Conference, HLT-NAACL2003, May.Sara Noeman 2009.
Language Independent Transliter-ation system using PBSMT approach on substrings.Proceedings of the 2009 Named Entities Workshop:Shared Task on Transliteration.Tarek Sherif, Grzegorz Kondrak 2007.
Bootstrappinga Stochastic Transducer for Arabic-English Translit-eration Extraction.
Proceedings of the 45th AnnualMeeting of the Association of Computational Lin-guistics, pages 864871Yasser Al-Onaizan, Kevin Knight 2002.
MachineTransliteration of Names in Arabic Text.
ACLWorkshop on Comp.
Approaches to Semitic Lan-guages.61
