A Psychol inguist ical ly Motivated Parser for CCGMichae l  Niv*Techn ion  - Israel  Ins t i tu te  of Techno logyHaifa,  IsraelIn ternet :  n iv@l inc .c i s .upenn.eduAbst ractConsidering the speed in which humans resolve syn-tactic ambiguity, and the overwhelming evidencethat syntactic ambiguity is resolved through selec-tion of the analysis whose interpretation is the most'sensible', one comes to the conclusion that inter-pretation, hence parsing take place incrementally,just about every word.
Considerations ofparsimonyin the theory of the syntactic processor lead one toexplore the simplest of parsers: one which repre-sents only analyses as defined by the grammar andno other information.Toward this aim of a simple, incremental parserI explore the proposal that the competence gram-mar is a Combinatory Categorial Grammar (CCG).I address the problem of the proliferating analysesthat stem from CCG's associativity of derivation.My solution involves maintaining only the max-imally incremental analysis and, when necessary,computing the maximally right-branching analysis.I use results from the study of rewrite systems toshow that this computation is efficient.1 In t roduct ionThe aim of this paper is to work towards a compu-tational model of how humans yntactically processthe language that they hear and read.
The endpointof this enterprise is a precise characterization f theprocess that humans follow, getting details such astiming and garden pathing exactly right.
*The research reported here was conducted as partof my Ph.D. thesis work at the University of Pennsyl-vania and supported by the following grants: DARPAN00014-90-J-1863, ARO DAAL03-89-C-0031, NSF IRI90-16592, Ben Franklin 91S.3078C-1.
Preparation ofthis paper was supported by a postdoctoral fellowshipat the Technion in Israel.
I am grateful to Mark Hepple,Mitch Marcus, Mark Steedman, VM Tannen, and HenryThompson for helpful suggestions, and to Jeff Siskindfor help with typesetting CCG derivations.
Any errorsare my own.1.1 Ambigu i ty  Resolut ionRecently, a great deal of evidence has accumu-lated that humans resolve syntactic ambiguity byconsidering the meaning of the available analysesand selecting the 'best' one.
Various criteria forgoodness of meaning have been advanced in thepsycholinguistic literature: e.g.
thematic compat-ibility and lexical selection (Trueswell and Tanen-haus 1994), discourse felicity of definite expressions(Altmann et al 1994), temporal coherence in dis-course (Trueswell and Tanenhaus 1991), grammati-cal function vis avis given/new status (Niv 1993b),and general world-knowledge (Kawamoto and Far-rar 1993).Many of the works cited above consider the tim-ing of the ambiguity resolution decision.
The evi-dence is overwhelming that ambiguity is resolvedwithin a word or two of the arrival of disambiguat-ing information--  that is, when there is a meaning-based criterion which militates toward one or an-other syntactically available analysis, that analysisis selected.
Should the other analysis turn out to bethe ultimately correct analysis, a garden path willresult.
Given that the various analyses available arecompared on various criteria of sensibleness, it fol-lows that these analyses are constructed and main-tained in parallel until disambiguating informationarrives.
Indeed, there is psycholinguistic evidencethat the processor maintains the various analysesin parallel (Nicol and Pickering 1993; MacDonlandet al 1992).Our parser, therefore, must be able to build andmaintain analyses in parallel.
It must also extractfrom the developing parse in a prompt fashion allof the semantically relevant syntactic ommitments(e.g.
predicate-argument relations) in order to allowthe interpretation module that it feeds to make ac-curate evaluations of the meaning.
Recovery fromgarden paths is not addressed in this paper.1251.2 Parser  and GrammarLet us adopt the widely held position that humansposses a representation of grammatical competencewhich is independent of any process (e.g.
produc-tion, perception, acquisition) that uses it.
Steed-man (1994) argues that if two theories of the gram-mar and processor package have identical empiricalcoverage, but one has a more complex parser, thenthe other is preferred.
This preference is not juston philosophical grounds of cleanliness of one's the-ories, but stems from consideration of the evolutionof the human linguistic capacity: A theory whosegrammar requires a complex parser in order to be ofany use would entail a more complex or less likelyevolutionary path which the parser and grammartook together than would a theory whose gram-mar requires little specialized apparatus by way ofa parser, and could thus have evolved gradually.So what is the simplest parser one can con-struct?
In other words, what is the minimal ad-dition of computational apparatus to the compe-tence grammar necessary to make it parse?
Fromthe argument in section 1.1, this addition must in-clude a mechanism for maintaining analyses in par-allel.
Minimally, nothing else is necessary - -  thedata structure which resides in each parallel slot inthe parser is a direct representation of an analysisas defined by the competence machinery.Suppose the grammatical competence is onethat always divides an English clause into a subjectand a predicate (VP henceforth).
Suppose also thatthe primary operations of the grammar are puttingconstituents together.
Could the minimal parserfor such a grammar account for the minimal pair in(1)?
(1) a.
The doctor sent for the patient arrived.b.
The flowers sent for the patient arrived.
(1)a is a garden path.
In (1)b the garden path isavoided because flowers are not good senders.
Thedifference between (1)a and b indicates that wellbefore the word 'arrived' is encountered, the proces-sor has already resolved the ambiguity introducedby the word 'sent'.
That is, in the main-verb anal-ysis of 'sent', the interpreter is aware of the relationbetween the subject the verb before the end of theVP.
But the minimal parser cannot put the subjecttogether with 'sent' or 'sent for the' because thelatter are not a complete VP!There are two possible solutions to this prob-lem, each relaxes one of the two suppositions above:Steedman (1994) argues for a grammatical theory(CCG) which does not always make the subject-predicate juncture the primary division point of aclause.
Shieber and Johnson (1993) on the otherhand, argue that there is no need to assume that aconstituent has to be complete before it is combinedwith its sister(s).
At this time, neither approachis sufficiently developed to be evaluable (e.g.
theyboth lack broad coverage grammar) so either one isviable.
In this paper, I develop the first.2 P re l iminar iesCCG is a lexicalized grammar formalism - -  a lexi-con assigns each word to one or more grammaticalcategories.
Adjacent constituents can combine byone of a small number of combinatory rules.
Theuniverse of grammatical categories contains a col-lection of basic categories (e.g.
atomic symbols uchas n, np, s, etc.
or Prolog terms such np(3,sg)) andis closed under the category-forming connectives /and \.
Intuitively a constituent of category X/Y(resp.
X\Y) is something of category X which ismissing something of category Y to its right (resp.left).
The combinatory rules are listed 1 in table 1.They formalize this intuition.
A combinatory rulemay be qualified with a predicate over the variablesX, Y, and Z1.. .Zn.A derivation is a binary tree whose leaves areeach a single-word constituent, and whose internalnodes are each a constituent which is derived fromits children by an application of one of the com-binatory rules.
A string w is grammatical just incase there exists a derivation whose frontier is w. Iequivocate between a derivation and the constituentat its root.
An analysis of a string w is a sequenceof derivations uch that the concatenation of theirfrontiers is w.3 The  S imples t  ParserLet us consider the simplest conceivable parser.
Itsspecification is "find all analyses of the string sofar."
It has a collection of slots for maintainingone analysis each, in parallel.
Each slot maintainsan analysis of the string seen so far - -  a sequenceof one or more derivations.
The parser has twooperations, as shown in figure 1.This parser succeeds in constructing the incre-mental analysis (2) necessary for solving the prob-lem in (1).1Two common combinatory rules, type-raising andsubstitution are not listed here.
The substitution rule(Steedman 1987) is orthogonal to the present discussionand can be added without modification.
The rule fortype-raising (see e.g.
Dowty 1988) can cause difficultiesfor the parsing scheme advocated here (Hepple 1987)and is therefore assumed to apply in the lexicon.
Soa proper name, for example, would be have two cate-gories: np and s/(s\np).126Forward combinat ion rule nameX/Y  Y X >0X/Y  YIZ X\[Z >1X/Y  Y\]-Z11Z2 X~z \[Z2 >2Backward Combination rule nameX/Y  YIZ1.
.
.
IZ.
X IZ I .
.
.
\ [Z .
>nY X \Y  , X <0YIZ x \Y  , xlz <1Y\]-Z, \[Z2 X\Y  ~ X\]-ZIIZ2 " <2Y\[Z1... \[Zn X\Y  ' X\[Z1... \[Zn <nIZ stands for e i ther /Z  or \Z.
Underlined regions in a rule must match.Table 1: The combinatory rules?
scanget the next word from the input streamfor each analysis a in the parser's memoryempty the slot containing afor each lexical entry e of the wordmake a copy a ~ of aadd the leaf derivation e to the right of a ~add a ~ as a new analysis?
combinefor each analysis a in the parser's memoryif a contains more than one constituentand some rule can combine the rightmosttwo constituents in athen make a copy a ~ of areplace the two constituents of a ~ bytheir combinationadd a / as a new analysisFigure 1: Parser operationsthe flowers sent (2) s/(s\np)/, n >0s\np/pps/(s\np)>I s/ppBut this parser is just an unconstrained shift-reduce parser that simulates non-determinism viaparallelism.
It suffers from a standard problem ofsimple bottom-up arsers: it can only know when acertain substring has a derivation, but in case a sub-string does not have a derivation, the parser cannotyet know whether or not a larger string containingthe substring will have a derivation.
This meansthat when faced with a string such as(3) The insults the new students shouted atthe teacher were appalling.the parser will note the noun-verb ambiguity of 'in-sults', but will be unable to use the information that'insults' is preceded by a determiner to rule out theverb analysis in a timely fashion.
It would only no-tice the difficulty with the verb analysis after it hadcome to the end of the string and failed to find aderivation for it.
This delay in ruling out doomedanalyses means that the parser and the interpreterare burdened with a quickly proliferating collectionof irrelevant analyses.Standard solution to this problem (e.g.
Earley's1970 parser; LR parsing, Aho and Johnson 1974)consider global properties of the competence gram-mar to infer that no grammatical string will be-gin with a determiner followed by a verb.
Thesesolutions exact a cost in complicating the designof the parser: new data structures uch as dottedrules or an LR table must be added to the parser.The parser is no longer a generic search algorithmfor the competence grammar.
Given the flexibil-ity of CCG derivations, one may consider impos-ing a very simple constraint on the parser: everyprefix of a grammatical string must have a deriva-tion.
But such a move it too heavy-handed.
IndeedCCG often gives left-branching derivations, but it isnot purely left-branching.
For example, the deriva-tion of a WH-dependency requires leaving the WH-filler constituent uncombined until the entire gap-containing constituent is completed, as in (4).
(4)whose cat did Fred findn s/s s/(s\np) >i s\np/np q/(s/np)/n >0q/(s/np) s/(s\np)s/np >I>04 The  V iab le  Ana lys i s  Cr i te r ionGiven the desideratum to minimize the complexityof the biologically specified parser, I propose thatthe human parser is indeed as simple as the scan-combine algorithm presented above, and that theability to rule out analyses uch as determiner+verbis not innate, but is an acquired skill.
This 'skill' isimplemented as a criterion which an analysis mustmeet in order to survive.
An infant starts out withthis criterion completely permissive.
Consequentlyit cannot process any utterances longer than a fewwords without requiring excessively many parser127slots.
But as the infant observes the various analy-ses in the parser memory and tracks their respectiveoutcomes, it notices that certain sequences of cate-gories never lead to a grammatical overall analysis.After observing an analysis failing a certain numberof times and never succeeding, the child concludesthat it is not a viable analysis and learns to discardit.
The more spurious analyses are discarded, thebetter able the child is to cope with longer strings.The collection of analyses that are maintainedby the parser is therefore filtered by two indepen-dent processes: The Viable Analysis Criterion is apurely syntactic filter which rules out analyses inde-pendently of ambiguity.
The interpreter considersthe semantic information of the remaining analysesin parallel and occasionally deems certain analysesmore sensible than their competitors, and discardsthe latter.Given that English sentences rarely requiremore than two or three CCG constituents at anypoint in their parse, and given the limited rangeof categories that arise in English, the problemof learning the viable analysis criterion from datapromises to be comparable to other n-gram learn-ing tasks.
The empirical validation of this proposalawaits the availability of a broad coverage CCG forEnglish, and other languages.
25 CCG and f lex ib le  der ivat ion5.1 The  Prob lemCCG's distinguishing characteristic is its deriva-tional flexibility - -  the fact that one string is po-tentially assigned many truth-conditionally equiva-lent analyses.
This feature is crucial to the presentapproach of incremental parsing (as well as for arange of grammatical phenomena, see e.g.
Steed-man 1987, 1994; Dowty 1988).
But the additionalambiguity, sometimes referred to as 'spurious', isalso a source of difficulty for parsing.
For example,the truth-conditionally unambiguous string 'Johnwas thinking that Bill had left' has CCG deriva-tions corresponding to each of the 132 different bi-nary trees possible for seven leaves.
The fact thatthis sentence makes no unusual demands on hu-mans makes it clear that its exponentially prolif~crating ambiguous analyses are pruned somehow.The interpreter, which can resolve many kinds ofambiguity, cannot be used to for this task: it hasno visible basis for determining, for example, thatthe single-constituent analysis 'John was thinking'2In addition to the category-ambiguity problem in(3), the viable analysis criterion solves other problems,analogous to shift-reduce ambiguities, which are omit-ted here for reasons of space.
The interested reader isreferred to Niv (1993a) for a comprehensive discussionand an implementation f the parser proposed here.somehow makes more sense (in CCG) than the two-constituent analysis ' John'+'was thinking'.Note that the maximMly left-branching deriva-tion is the one which most promptly identifies yn-tactic relations, and is thus the preferred erivation.It is possible to extend the viable analysis criterionto encompass this consideration ofefficiency as well.The infant learns that it is usually most efficientto combine whenever possible, and to discard ananalysis in which a combination is possible, but nottaken.
3.While this left-branching criterion eliminatesthe inefficiency due to flexibility of derivation, itgives rise to difficulties with (5).John loves Mary madly(5) s/vp vp/np np vp\vpIn (5), it is precisely the non-left-branchingderivation of 'John loves Mary' which is necessaryin order to make the VP constituent available forcombination with the adverb.
(See Pareschi andSteedman 1987.
)5.2 P rev ious  ApproachesFollowing up on the work of Lambek (1958) whoproposed that the process of deriving the grammat-icality of a string of categories be viewed as a proof,there have been quite a few proposals put forthfor computing only normal forms of derivations orproofs (KSnig 1989; Hepple and Morrill 1989; Hep-ple 1991; inter alia).
The basic idea with all of theseworks is to define 'normal forms' - -  distinguishedmembers of each equivalence class of derivations,and to require the parser to search this smallerspace of possible derivations.
But none of the pro-posed methods result in parsing systems which pro-ceed incrementally through the string.
4Karttunen (1989) and others have proposedchart-based parsers which directly address thederivational ambiguity problem.
For the presentpurpose, the principal feature of chart parsing - -the factoring out of constituents from analyses - -turns out to create an encumberance: The inter-preter cannot compare constituents, or arcs, for thepurposes of ambiguity resolution.
It must compareanalyses of the entire prefix so far, which are awk-ward to compute from the developing chart.3 Discussion of the consequences of this move on theprocessing of picture noun extractions and ambiguity-related filled-gap effects is omitted for lack of space.
SeeNiv (1993a).4In the case of Hepple's (1991) proposal, a left-branching normal form is indeed computed.
But itscomputation must be delayed for some words, so itdoes not provide the interpreter with timely informa-tion about the incoming string.128Pareschi and Steedman (1987) propose the fol-lowing strategy: (which can be taken out of thechart-parsing context of their paper) constructonly maximally left-branching derivations, but al-low a limited form of backtracking when a locallynon-left-branching derivation turns out to havebeen necessary.
For example, when parsing (5),Pareschi and Steedman's algorithm constructs theleft branching analysis for 'John loves Mary'.
Whenit encounters 'madly', it applies >0 in reverse tosolve for the hidden VP constituent 'loves Mary'by subtracting the s/vp category 'John' from the scategory 'John loves Mary':John loves Mary(6) s/vp vp/nP>l  nps/npvpvpmadlyvp\vp>0reveal >0<0>0The idea with this 'revealing' operation is to ex-ploit the fact that the rules >n and <n, when viewedas three-place relations, are functional in all threearguments.
That is, knowledge any two of {left con-stituent, right constituent, result), uniquely deter-mines the third.
There are many problems with thecompleteness and soundness Pareschi and Steed-man's proposal (Hepple 1987; Niv 1993a).
For ex-ample, in (7), the category b\c cannot be revealedafter it had participated in two combinations ofmixed direction: <0 and >0.
(7)a/b  c d\C<ob\d b\c\(b\c)d <0b >0a stuck6 A Proposa lPareschi and Steedman's idea of lazy parsing isvery attractive in the present setting.
I proposeto replace their unification-based revealing opera-tion with a normal-form based manipulation of thederivation history.
The idea is to construct andmaintain the maximally incremental, left-branchingderivations.
(see section 4.)
When a constituentsuch as the VP 'loves Mary' in (5) may be nec-essary, e.g.
whenever the right-most constituent inan analysis is of the form X\Y, the next-to-right-most derivation is rewritten to its equivalent right-branching derivation by repeated application thelocal transformations , defined in (8) and (9).The right frontier of the rewritten derivation owprovides all the grammatically possible attachmentsites.
(8)W/X x \ [Y I ' ' ' IYm-~/YmW \[Yz'.'
lYre-1/Y,~Ym \[Zl"" \[Z,~>m>nWIYz ' - ' IYm- I lZ I ' ' - IZ~W/X X\[Y1.. .
\ [Ym_I/Ym Ym IZl ' ' ' \ ]ZnX lYe.-.
\[Ym-~ IZ~... IZ,~~n~m+n-1(9)W IY1.-.
Wm-~lZ~"'' IZ,Y.~ \[Z1-..lZn X \[Ya' ' ' IY,~-I \Ym W\X<n x IYz""" IY,,,-a Iza..- IZ,WIYI- .
- IYm_I IZI ' .
.
IZn.._.._4<m+n-IYm IZ~'--IZ.
XIY1.-.
IY.~_I\Ym W\X<mW \[Y1-.. IY.~-~ \Ym<nW WI""  \[Y~-I \[Za'.- \[Z,Results from the study of rewrite systems (seeKlop (1992) for an overview) help determine thecomputational complexity of this operation:6.1 A Rewri te System for DerivationsIf x is a node in a binary tree let A(x) (resp.
p(x))refer to its left (right) child.Any subtree of a derivation which matches theleft-hand-side of either (8) or (9) is called a redez.The result of replacing a redex by the correspondingright-hand-side of a rule is called the eontractum.
Aderivation is in normal form (NF) if it contains noredexes.
In the following I use the symbol --~ toalso stand for the relation over pairs of derivationssuch that the second is derived from the first byone application of ,7.
Let ~--  be the converseof---*.
Let ( , be ~ U ~---.
Let ,~ be thereflexive transitive closure of --~ and similarly,the reflexive transitive closure of ~---, and , ,, thereflexive transitive closure of ~ ,.
Note that .
.
.
.is an equivalence relation.A rewrite system is strongly normalizing (SN)iff every sequence of applications of ~ is finite.Theorem 1 ---* is SN 5proo f  Every derivation with n internal nodes isassigned a positive integer score.
An application ofis guaranteed to yield a derivation with a lower5Hepple and Morrill (1989) Proved SN for a slightvariant of ---*.
The present proof provides a tighterscore function, see lemma 1 below.129Figure 2: Schema for one redex in DRSscore.
This is done by defining functions # andfor each node of the derivation as follows:(~  if x is a leaf node#(x)  = + #(A(x))  + #(p(x)) otherwisef0  if x is a leaf node~(x) = ~?r(A(x)) + ~(p(x)) + #(A(x))  otherwiseEach application of ---+ decreases a, the scoreof the derivation.
This follows from the monotonicdependency of the score of the root of the derivationupon the scores of each sub-derivation, and from thefact that locally, the score of a redex decreases when---+ is applied: In figure 2, a derivation is depictedschematically with a redex whose sub-constituentsare named a, b, and c. Applying ~ reduces ~(e),hence the score of the whole derivation.in redex:#(d) -=- #(a) - t -#(b)+Icr(d) = or(a) + ~(b) + #(a)~(~) = ~(d) + ~(c) + #(d)= c~(a) + q(b) + q(c) + #(b) + 2-~t(a) + 1in contractum:~( f )  = a(b) + ~(c) +#(b)~(~') = ~(~) + ~( f )  + #0)= ~(~) + ~(b) + ~(c) + #0)  + #(~)< ~(~) + ~(b) + ~(0 + #0)  + 2.
#(~) + 1\[\]Observe that #(x)  is the number of internal nodesin x.Lemma I Given a derivation x, let n = #x.  Ev-ery sequence of applications of ---+ is of length atmost n(n - 1)/2.
6p roo f  By induction on n:Base case: n = 1; 0 applications are necessary.Induction: Suppose true for all derivations of fewerthan n internal nodes.
Let m = #A(x).
So 0 <6Niv (1994) shows by example that this bound istight.m_<n- -1  and#p(x)=n-m-1 .~(~) - n(n - 1)/2 == a(A(x)) + a(p(x)) + #(A(x))  - n(n - 1)/2< ~( .~-~)  ( ,~-~- i ) ( ,~- ,~-2)  ~(n-1)- 2 + 2 + m -  2= (m + 1)(rn - (n - 1))_< 0 recalling that 0 _< m _< n - 1\[\]So far I have shown that every sequence of ap-plications of ----+ is not very long: at most quadraticin the size of the derivation.
I now show that whenthere is a choice of redex, it makes no differencewhich redex one picks.
That  is, all redex selectionstrategies result in the same normal form.A rewrite system is Church-Rosser (CR)just incasew,  y .
(z  ,, ,, y ~ 3z .
(z - - -~ z ^ y ,, z))A rewrite system is Weakly Church-Rosser(WCR) just in easew,  ~, w .
(w~ ~ ^  w~ y) ~ 3z .
( ,  ~ z ^ y ,, z)Lemma 2 ---, is WCR.p roo f  Let w be a derivation with two distinct re-dexes x and y, yielding the two distinct derivationsw I and w" respectively.
There are a few possibili-ties:case 1: x and y share no internal nodes.
There arethree subcases: x dominates y (includes y as asubconstituent), x is dominated by y, or z and yare incomparable with respect o dominance.
Ei-ther way, it is clear that the order of applicationof ---+ makes no difference.case 2: x and y share some internal node.
Withoutloss of generality, y does not dominate x. Thereexists a derivation z such that w~----~ zAw"---~ z.This is depicted in figure 3.
(Note that all threeinternal nodes in figure 3 are of the same ruledirection, either > or <.
)\[\]Lemma 3 (Newman) WCR A SN D CR.Theorem 2 ~ is CR.p roo f  From theorem 1 and lemmas 2 and 3.
\[\]Therefore any maximal sequence of applica-tions of ~ will lead to the normal form 7.
Weare free to select the most efficient redex selectionscheme.
From lemma 1 the worst case is quadratic.Niv (1994) shows that the optimal strategy, of ap-plying --+ closest as possible to the root, yields ---+applications equences of at most n steps.7Assuming, as is the case with extant CCG accounts,that constraints on the applicability of the combinatoryrules do not present significant roadblocks to the deriva-tion rewrite process.130d cc ?
/ ~ a x ~  ~ a d cb  aa b aArrows are annotated by the substrucureto which they are appliedFigure 3: Why --~ is weakly Church-RosserNote that all that was said in this section gen-eralizes beyond CCG derivations to any associativealgebra.6.2 Discuss ionGiven the rightmost subconstituent recovered us-ing the normal form technique above, how shouldparsing proceed?
Obviously, if the leftward lookingcategory which precipitated the normal form com-putation is a modifier, i.e.
of the form X\X, thenit ought to be combined with the recovered con-stituent in a form analogous to Chomsky adjunc-tion.
But what if this category is not of the formX\X?
For example, should the parser compute thereanalysis n (10)?
(lO)a/b b/C>lC/d s\(a/b)\(b/d)a/c>1 a/da/b b/c c/d>lS\(a/b)\(b/d )b/d<0 s\(a/b)<0SAscribing the same non-garden-path status tothe reanalysis n (10) that we do to (6) would consti-tute a very odd move: Before reanalysis, the deriva-tion encoded the commitment that the /b of thefirst category is satisfied by the b of the b/c in thesecond category.
This commitment is undone in thereanalysis.
This is an undesirable property to havein a computational model of parsing commitment,as it renders certain revisions of commitments eas-ier than others, without any empirical justification.Furthermore, given the possibility that the parserchange its mind about what serves as argument towhat, the interpreter must be able to cope withsuch non-monotonic updates to its view of the anal-ysis so far - -  this would surely complicate the de-sign of the interpreter, s Therefore, constituents onthe right-frontier ofa right-normal-form should onlycombine with 'endocentric' categories to their right.The precise definition of 'endocentric' depends onthe semantic formalism used - -  it certainly includespost-head modifiers, and might also include coordi-nation.Stipulating that certain reanalyses are impos-sible immediately makes the parser 'incomplete' inthe sense that it cannot find the analysis in (10).From the current perspective of identifying ardenpaths, this incompleteness i  adesirable, ven a nec-essary property.
In (10), committing to the compo-sition of a/b and b/c is tantamount to being leddown the garden path.
In a different sense, thecurrent parser is complete: it finds all analyses ifthe Viable Analysis Criterion and the interpreternever discard any analyses.7 Conc lus ionThe current proposal shifts some of the burden tra-ditionally associated with the parser to other com-ponents of the human cognitive faculty: the inter-preter esolves ambiguity, and an acquired skill re-moves 'garbage' analyses from the parser's mem-ory - -  solving the so-called spurious ambiguityproblem, as well as effectively applying rammar-global constraints traditionally computed by top-down techniques or grammar compilation.
The re-sultant parser adheres to the desideratum that itbe a generic search algorithm for the grammar for-malism, provided the definition of CCG explicitlyincludes the notion of 'derivation' and explicates thetruth-conditional equivalence r lation.
Such inclu-sions have indeed been proposed (Steedman 1990).B ib l iographyAho, Alfred and S. C. Johnson.
1974.
LR Parsing.ACM Computing Surveys 6(2):99-124.Altmann, Gerry T., Alan Garnham, and Judith A.Henstra.
1994.
Effects of syntax in human sen-tence parsing: Evidence against a structure-based proposal mechanism.
Journal of Ex-perimental Psychology: Learning, Memory andCognition 20(1):1-8.Dowty, David.
1988.
Type Raising, FunctionalComposition, and Non-Constituent Conjunc-tion.
In Richard T. Oehrle, Emmon Bach, andsI am indebted to Henry Thompson for a discussionof monotonicity.131Deirdre Wheeler (Eds.
), Categorial Grammarsand Natural Language Structures.
Reidel.Earley, Jay.
1970.
An Efficient Context-Free Pars-ing Algorithm.
Communications of the Asso-ciation for Computing Machinery 13:94-102.Hepple, Mark R. 1987.
Methods for Parsing Combi-natory Grammars and the Spurious AmbiguityProblem.
Master's thesis, University of Edin-burgh.Hepple, Mark R. 1991.
Efficient Incremental Pro-cessing with Categorial Grammar.
In Proceed-ings of the 29th Annual Meeting of the Associ-ation for Computational Linguistics, 79-86.Hepple, Mark R. and Glyn V. Morrill.
1989.
Pars-ing and Derivational Equivalence.
In Proceed-ings of the Annual Meeting of the EuropeanChapter of the Association for ComputationalLinguistics.Karttunen, Lauri.
1989.
Radical Lexicalism.
InMark Baltin and Anthony S. Kroch (Eds.
), Al-ternative Conceptions of Phrase Structure, 43-65.
Chicago: University of Chicago Press.Kawamoto, Alan and William Farrar.
1993.
TheReturn of Visiting Relatives: Pragmatic Ef-fects in Sentence Processing.
Quarterly Jour-nal of Experimental Psychology 46A(3):463 -487.Klop, Jan W. 1992.
Term Rewrite Systems.In Samson Abramsky, Dov M. Gabbay, andT.
S. E. Maibaum (Eds.
), Handbook of Logicin Computer Science, Vol.
2, 1 - 116.
Oxford:Clarendon Press.KSnig, Esther.
1989.
Parsing as Natural Deduction.In Proceedings of the g7th Annual Meeting ofthe Association for Computational Linguistics,272-279, June.Lambek, Joachim.
1958.
The Mathematics ofSentence Structure.
American MathematicalMonthly 65:154-169.MacDonland, Maryellen, Adam Just, and Patri-cia Carpenter.
1992.
Working Memory Con-straints on the Processing of Syntactic Ambi-guity.
Cognitive Psychology 24:56-98.Nicol, Janet L. and Martin J. Pickering.
1993.
Pro-cessing Syntactically Ambiguous Sentences:Evidence from Semantic Priming.
Journal ofPsycholinguistic Research.Niv, Michael.
1993a.
A Computational Model ofSyntactic Processing: Ambiguity Resolutionfrom Interpretation.
PhD thesis, University ofPennsylvania.
(ftp://ftp.cis.upenn.edu/pub/-ircs/tr/93-27.ps).Niv, Michael.
1993b.
Resolution of Syntactic Am-biguity: the Case of New Subjects.
In Proceed-ings of the 15th Annual Conference of the Cog-nitive Science Society, Hillsdale, NJ.
LawrenceErlbaum Associates.Niv, Michael.
1994.
The complexity of normalform rewrite sequences for Associativity.
Tech-nical Report LCL 94-6, Computer ScienceDepartment, Technion.
(ftp://ftp.cis.upenn.-edu/pub/niv/rewrite.ps).Pareschi, Remo and Mark a. Steedman.
1987.
ALazy Way to Chart Parse with CombinatoryGrammars.
In Proceedings of the 25th AnnualMeeting of the Association for ComputationalLinguistics.Shieber, Stuart M. and Mark Johnson.
1993.
Vari-ations on Incremental Interpretation.
Journalof Psycholinguistic Research.
(to appear).Steedman, Mark J.
1987.
Combinatory Gram-mars and Parasitic Gaps.
Natural Languageand Linguislic Theory 5:403-439.Steedman, Mark J.
1990.
Gapping as Con-stituent Coordination.
Linguistics and Philos-ophy 13:207-264.Steedman, Mark J.
1994.
Grammars and Proces-sors.
In Hans Kamp and Christian Rohrer(Eds.
), Aspects of Computational Linguistics.Springer Verlag.
(to appear).Trueswell, John C. and Michael K. Tanenhaus.1991.
Tense, Temporal Context and SyntacticAmbiguity Resolution.
Language and Cogni-tive Processses 6:303-338.Trueswell, John C. and Michael K. Tanenhaus.1994.
Toward a Lexicalist Framework ofConstraint-Based Syntactic Ambiguity Reso-lution.
In Charles Clifton, Lyn Frazier, andKeith Rayner (Eds.
), Perspectives on SentenceProcessing.
Hillsdale, NJ: Lawrence ErlbaumAssociates.132
