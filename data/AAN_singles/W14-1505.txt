Proceedings of the 2nd Workshop on Continuous Vector Space Models and their Compositionality (CVSC) @ EACL 2014, pages 40?47,Gothenburg, Sweden, April 26-30 2014.c?2014 Association for Computational LinguisticsInvestigating the Contribution of Distributional Semantic Information forDialogue Act ClassificationDmitrijs MilajevsQueen Mary University of Londond.milajevs@qmul.ac.ukMatthew PurverQueen Mary University of Londonm.purver@qmul.ac.ukAbstractThis paper presents a series of experimentsin applying compositional distributionalsemantic models to dialogue act classifica-tion.
In contrast to the widely used bag-of-words approach, we build the meaning ofan utterance from its parts by composingthe distributional word vectors using vec-tor addition and multiplication.
We inves-tigate the contribution of word sequence,dialogue act sequence, and distributionalinformation to the performance, and com-pare with the current state of the art ap-proaches.
Our experiment suggests thatthat distributional information is useful fordialogue act tagging but that simple mod-els of compositionality fail to capture cru-cial information from word and utterancesequence; more advanced approaches (e.g.sequence- or grammar-driven, such as cat-egorical, word vector composition) are re-quired.1 IntroductionOne of the fundamental tasks in automatic dia-logue processing is dialogue act tagging: labellingeach utterance with a tag relating to its functionin the dialogue and effect on the emerging con-text: greeting, query, statement etc (see e.g.
(Core,1998)).
Although factors such as intonation alsoplay a role (see e.g.
(Jurafsky et al., 1998)), oneof the most important sources of information inthis task is the semantic meaning of an utterance,and this is reflected in the fact that people usesimilar words when they perform similar utteranceacts.
For example, utterances which state opinion(tagged sv in the standard DAMSL schema, seebelow) often include words such as ?I think?, ?Ibelieve?, ?I guess?
etc.
Hence, a similarity-basedmodel of meaning ?
for instance, a distributionalsemantic model ?
should provide benefits overa purely word-based model for dialogue act tag-ging.
However, since utterances generally con-sist of more than one word, one has to be ableto extend such similarity-based models from sin-gle words to sentences and/or complete utterances.Hence, we consider here the application of compo-sitional distributional semantics for this task.Here, we extend bag-of-word models com-mon in previous approaches (Serafin et al., 2003)with simple compositional distributional opera-tions (Mitchell and Lapata, 2008) and examine theimprovements gained.
These improvements sug-gest that distributional information does improveperformance, but that more sophisticated compo-sitional operations such as matrix multiplication(Baroni and Zamparelli, 2010; Grefenstette andSadrzadeh, 2011) should provide further benefits.The state of the art is a supervised methodbased on Recurrent Convolutional Neural Net-works (Kalchbrenner and Blunsom, 2013).
Thismethod learns both the sentence model and thediscourse model from the same training corpus,making it hard to understand how much of thecontribution comes from the inclusion of distribu-tional word meaning, and how much from learn-ing patterns specific to the corpus at hand.
Here,in contrast, we use an external unlabeled resourceto obtain a model of word meaning, composingwords to obtain representations for utterances, andrely on training data only for discourse learningfor the tagging task itself.We proceed as follows.
First, we discuss relatedwork by introducing distributional semantics anddescribe common approaches for dialogue act tag-ging in Section 2.
Section 3 proposes several mod-els for utterance representation based on the bag ofwords approach and word vector composition.
Wedescribe the experiment and discuss the result inSection 4.
Finally, Section 5 concludes the work.402 Related workDistributional semantics The aim of naturallanguage semantics is to provide logical represen-tations of meaning for information in textual form.Distributional semantics is based on the idea that?You shall know a word by the company it keeps?
(Firth, 1957) ?
in other words, the meaning of aword is related to the contexts it appears in.
Fol-lowing this idea, word meaning can be representedas a vector where its dimensions correspond to theusage contexts, usually other words observed toco-occur, and the values are the co-occurrence fre-quencies.
Such a meaning representation is easyto build from raw data and does not need rich an-notation.Methods based on this distributional hypothe-sis have recently been applied to many tasks, butmostly at the word level: for instance, word sensedisambiguation (Zhitomirsky-Geffet and Dagan,2009) and lexical substitution (Thater et al., 2010).They exploit the notion of similarity which corre-lates with the angle between word vectors (Turneyet al., 2010).
Compositional distributional seman-tics goes beyond the word level and models themeaning of phrases or sentences based on theirparts.
Mitchell and Lapata (2008) perform com-position of word vectors using vector addition andmultiplication operations.
The limitation of thisapproach is the operator associativity, which ig-nores the argument order, and thus word order.
Asa result, ?John loves Mary?
and ?Mary loves John?get assigned the same meaning.To capture word order, various approacheshave been proposed.
Grefenstette and Sadrzadeh(2011) extend the compositional approach by us-ing non-associative linear algebra operators asproposed in the theoretical work of (Coecke etal., 2010).
Socher et al.
(2012) present a recur-sive technique to build compositional meaning ofphrases from their constituents, where the non-linear composition operators are learned by NeuralNetworks.Dialogue act tagging There are many ways toapproach the task of dialogue act tagging (Stol-cke et al., 2000).
The most successful approachescombine intra-utterance features, such as the (se-quences of) words and intonational contours used,together with inter-utterance features, such as thesequence of utterance tags being used previously.To capture both of these aspects, sequence modelssuch as Hidden Markov Models are widely used(Stolcke et al., 2000; Surendran and Levow, 2006).The sequence of words is an observable variable,while the sequence of dialogue act tags is a hiddenvariable.However, some approaches have shown com-petitive results without exploiting features of inter-utterance context.
Webb et al.
(2005) concentrateonly on features found inside an utterance, identi-fying ngrams that correlate strongly with particu-lar utterance tags, and propose a statistical modelfor prediction which produces close to the state ofthe art results.The current state of the art (Kalchbrenner andBlunsom, 2013) uses Recurrent ConvolutionalNeural Networks to achieve high accuracy.
Thismodel includes information about word identity,intra-utterance word sequence, and inter-utterancetag sequence, by using a vector space model ofwords with a compositional approach.
The wordsvectors are not based on distributional frequenciesin this case, however, but on randomly initialisedvectors, with the model trained on a specific cor-pus.
This raises several questions: what is the con-tribution of word sequence and/or utterance (tag)sequence; and might further gains be made by ex-ploiting the distributional hypothesis?As our baseline, we start with an approachwhich uses only word information, and excludesword sequence, tag sequence and word distribu-tions.
Serafin et al.
(2003) use Latent SemanticAnalysis for dialogue act tagging: utterances arerepresented using a bag-of-words representationin a word-document matrix.
The rows in the ma-trix correspond to words, the columns correspondto documents and each cell in the matrix containsthe number of times a word occurs in a document.Singular Value Decomposition (SVD) is then ap-plied to reduce the number of rows in the matrix,with the number of components in the reducedspace set to 50.
To predict the tag of an unseenutterance, the utterance vector is mapped to the re-duced space and the tag of the closest neighbor isassigned to it (using cosine similarity as a similar-ity measure).
The reported accuracy on the Span-ish Call Home corpus for predicting 37 differentutterance tags is 65.36%.3 Utterance modelsIn this paper, we investigate the extent to whichdistributional representations, word order infor-41mation, and utterance order information can im-prove this basic model, by choosing different waysto represent an utterance in a vector space.
We de-sign three basic models.
The first model is baseddirectly on the bag-of-words model which servesas the baseline in our experiment, following (Ser-afin et al., 2003); and extends this to investigate theeffect of word order information by moving fromword unigrams to bigrams.
The second modelinvestigates distributional information, by calcu-lating word vector representations from a generalcorpus, and obtaining utterance representations bycomposing the word vectors using simple opera-tors.
The third model extends this idea to inves-tigate the role of utterance order information, byincluding the information about the previous ut-terance.Bag of words The first model represents an ut-terance as a vector where each component corre-sponds to a word.
The values of vector compo-nents are the number of times the correspondingwords occured in the utterance.
The model is sim-ilar to (Serafin et al., 2003), but the matrix is trans-posed.
We refer to it as bag of unigrams in Table 1.However, this bag of words approach does notpreserve any word order information.
As it hasbeen said previously, for the dialogue act taggingword order may be crucial.
Consider these utter-ances:?
John, are there cookies?
John, there are cookiesOne of the utterances is a question (or request)while the other is a statement.
However, the bagof words model will extract the same vector repre-sentation for both.To overcome this problem we also represent anutterance as a bag of bigrams.
When bigrams areused in place of single words, the utterance rep-resentation will differ.
The question contains thebigram ?are there?, while the statement containsthe bigram ?there are?.Simple composition Our second model ex-ploits the distributional hypothesis, by represent-ing words not as atomic types (i.e.
individual di-mensions in the utterance matrix, as above), butas vectors encoding their observed co-occurrencedistributions.
We estimate these from a large cor-pus of general written English (the Google BooksNgrams corpus ?
see below).However, this raises the question of how tocompose these word vectors into a single repre-sentation for an utterance.
Various approaches tocompositional vector space modelling have beensuccessfully applied to capture the meaning of aphrase in a range of tasks (Mitchell and Lapata,2008; Grefenstette and Sadrzadeh, 2011; Socheret al., 2013).
In this work, we follow (Mitchell andLapata, 2008) and apply vector addition and point-wise multiplication to obtain the vector of an ut-terance from the words it consists of.
This has theadvantage of simplicity and domain-generality, re-quiring no sentence grammar (problematic for thenon-canonical language in dialogue) or training ona specific corpus to obtain the appropriate compo-sitionality operators or associative model; but hasthe disadvantage of losing word order information.The corresponding models are referred as additionand multiplication in Table 1 and Table 2.Previous utterance A conversation is a se-quence of utterances, and the tag of an utter-ance often depends on the previous utterance(e.g.
answers tend to follow questions).
Hid-den Markov Models (Surendran and Levow, 2006;Stolcke et al., 2000) are often used to cap-ture these dependencies; Recurrent ConvolutionalNeural Networks (Kalchbrenner and Blunsom,2013) have been used to simultaneously capturethe intra-utterance sequence of words and theinter-utterance sequence of dialog tags in a con-versation.In this model, we are interested specifically inthe effect of inter-utterance (tag) sequence.
Weprovide previous addition and previous multipli-cation models as simple attempts to capture thisphenomenon: the vector of an utterance is the con-catenation of its vector obtained in the correspond-ing compositional model (addition or multiplica-tion) and the vector of the previous utterance.4 Predicting dialogue acts4.1 The resourcesThis section describes the resources we use toevaluate and compare the proposed models.Switchboard corpus The Switchboard corpus(Godfrey et al., 1992) is a corpus of telephone con-versations on selected topics.
It consists of about2500 conversations by 500 speakers from the U.S.The conversations in the corpus are labeled with42 unique dialogue act tags and split to 1115 train42A o : Okay.
/A qw : {D So, }B qy?d: [ [I guess, +A + : What kind of experience[ do you, + do you ] have,then with child care?
/B + : I think, ] + {F uh, }I wonder if that worked.
/(a) A conversation with interrupted utterances.A o : Okay.A qw : So What kind of experiencedo you do you have thenwith child care?B qy?d: I guess I think uh I wonderif that worked.
(b) A preprocessed conversation.Figure 1: A example of interrupted utterances from Switchboard and their transformation.and 19 test conversations (Jurafsky et al., 1997;Stolcke et al., 2000).In addition to the dialog act tags, utterancesinterrupted by the other speaker (and thus splitinto two or more parts) have their continuationsmarked with a special tag ?+?.
Tag prediction ofone part of an interrupted utterance in isolation isa difficult task even for a human; for example, itwould not be clear why the utterance ?So,?
shouldbe assigned the tag qw (wh-question) in Figure 1awithout the second part ?What kind of experiencedo you have [.
.
.
]?.
Following (Webb et al., 2005)we preprocess Switchboard by concatenating theparts of an interrupted utterance together, givingthe result the tag of the first part and putting it inits place in the conversation sequence.
We alsoremove commas and disfluency markers from theraw text.
Figure 1b illustrates the transformationwe do as preprocessing.We split the utterances between training andtesting as suggested in (Stolcke et al., 2000).Google Books Ngram Corpus The GoogleBooks Ngram Corpus (Lin et al., 2012) is a col-lection of n-gram frequencies over books writtenin 8 languages.
The English part of the corpus isbased on more than 4.5 million books and containsmore than four thousand billion tokens.
The re-source provides frequencies of n-grams of length1 to 5.
For our experiments we use 5-grams fromthe English part of the resource.4.2 Word vector spacesIn distributional semantics, the meanings of wordsare captured by a vector space model based on aword co-occurrence matrix.
Each row in the ma-trix represents a target word, and each column rep-resents a context word; each element in the matrixis the number of times a target word co-occuredwith a corresponding context word.
The frequencycounts are typically normalized, or weighted us-ing tf-idf or log-likelihood ratio to obtain better re-sults, see (Mitchell and Lapata, 2008; Agirre et al.,2009) for various approaches.
It is also commonto apply dimensionality reduction to get higherperformance (Dinu and Lapata, 2010; Baroni andZamparelli, 2010).As target words we select all the words in our(Switchboard) training split.
As context wordswe choose the 3000 most frequent words in theGoogle Ngram Corpus, excluding the 100 mostfrequent.
To obtain co-occurrence frequenciesfrom ngrams we sum up the frequency of a 5-gramover the years, treat the word in the middle as atarget, and the other words as its contexts.For normalization, we experiment with a vec-tor space based on raw co-occurrences; a vectorspace where frequencies are weighted using tf-idf;and another one with the number of dimensionsreduced to 1000 using Non-negative Matrix Fac-torization (NMF) (Hoyer, 2004).We use the NMF and tf-idf implementationsprovided by scikit-learn version 0.14 (Pe-dregosa et al., 2011).
For tf-idf, the term vectorsare L2normalized.
For NMF, NNDSVD initial-ization (Boutsidis and Gallopoulos, 2008) is used,and the tolerance value for stopping conditions isset to 0.001.
The co-occurrence matrix is line-normalized, so the sum of the values in each rowis 1 before applying NMF.14.3 EvaluationTo evaluate these possible models we follow (Ser-afin et al., 2003).
Once we have applied a modelto extract features from utterances and build a vec-tor space, the dimensionality of the vector spaceis reduced using SVD to 50 dimensions.
Then ak-nearest neighbours (KNN) classifier is trainedand used for utterance tag prediction.
In contrastto (Serafin et al., 2003), we use Euclidean dis-tance as a distance metric and choose the most1The co-occurrence matrix and the information about thesoftware used in the experiment are available athttp://www.eecs.qmul.ac.uk/?dm303/cvsc14.html43Method Accuracy(Kalchbrenner and Blunsom, 2013) 0.739(Webb et al., 2005) 0.719(Stolcke et al., 2000) 0.710(Serafin et al., 2003) 0.654Bag of unigrams 0.602Bag of bigrams 0.621Addition 0.639Multiplication 0.572Previous addition 0.569Previous multiplication 0.497Table 1: Comparison with previous work.
Notethat (Serafin et al., 2003) do not use Switchboardand therefore their results are not directly compa-rable to others.frequent label among the 5 closest neighbors.The SVD and KNN classifier implementations inscikit-learn are used.Baseline In our experiments, the bag of uni-grams model accuracy of 0.602 is lower than theaccuracy of 0.654 reported in (Serafin et al., 2003),see Table 1.
The lower performance may be dueto the differences between Switchboard and Call-Home37 corpora, in particular the tag distribu-tion.2In CallHome37, 42.7% of utterances are la-beled with the most frequent dialogue act, whilethe figure in Switchboard is 31.5%; the more evendistribution in Switchboard is likely to make over-all average accuracy levels lower.Word order As Table 1 shows, the bag of bi-grams model improves over unigrams.
This con-firms that word order provides important informa-tion for predicting dialogue act tags.Distributional models Performance of compo-sitional distributional models depends both oncompositional operator and weighting.
Table 2demonstrates accuracy of the models.
We instan-tiate 3 vector spaces from Google Ngrams: onespace with raw co-occurrence frequencies, a tf-idfweighted space and a reduced space using NMF.Addition outperforms multiplication in our ex-periments, although for other tasks multiplicationhas been shown to perform better (Grefenstetteand Sadrzadeh, 2011; Mitchell and Lapata, 2008).Lower multiplication performance here might be2The CallHome37 corpus is not currently available to us.SpaceModel Raw tf-idf NMFAddition without SVD 0.592Addition 0.610 0.639 0.620Multiplication 0.572 0.568 0.525Previous addition 0.569Previous multiplication 0.497Table 2: Accuracy results for different composi-tional models and vector spaces.due to the fact that some utterances are rather long(for example, more than 70 tokens), and the result-ing vectors get many zero components.Selection of the optimal weighting methodcould be crucial for overall model performance.The 3 weighting schemes we use give a broad va-riety of results; more elaborate weighting and con-text selection might give higher results.Figure 2 illustrates dialog tag assignment us-ing addition and the tf-idf weighted vector space.As we do not use any inter-utterance features, thefirst two statements, which consist only of theword Okay, got assigned wrong tags.
However,the Wh-question in the conversation got classifiedas a Yes-No-question, probably because what didnot influence the classification decision stronglyenough and could have been classified correctlyusing only intra-utterance features.
Also, the ex-ample shows how important grammatical featuresare: the verb think appears in many different con-text, and its presence does not indicate a certaintype of an utterance.In addition, we observed that SVD improvesclassification accuracy.
The accuracy of KNNclassification without prior dimensionality reduc-tion drops from 0.610 to 0.592 for vector additionon the raw vector space.Utterance sequence To solve the issue of utter-ances that can be tagged correctly only by consid-ering inter-utterance features, we included previ-ous utterance.
However, in our experiment, suchinclusion by vector concatenation does not im-prove tagging accuracy (Table 2).
The reason forthis could be that after concatenation the dimen-sionality of the space doubles, and SVD can nothandle it properly.
We evaluated only dimension-ally reduced spaces because of the memory limit.44B**(b) : Okay.A b?m (b) : Okay.B qw (qy): Well what do you think about the idea of uh kids having to do publicservice work for a year?B qy (sd): Do you think it?s a <breathing>A sv (sv): Well I I think it?s a pretty good idea.A sv (sd): I think they should either do that or or afford some time to the militaryor or helping elderly people.B aa (aa): YesB aa (b) : yesB % (%) : defA sv (sv): I I you know I think that we have a bunch of elderly folks in the countrythat could use some helpFigure 2: The beginning of the conversation 2151 from the test split of Switchboard.
In brackets thetags predicted using vector addition as a composition method on the tf-idf space are given.
We markfo o fw " by bc as**.Summary Our accuracy is lower compared toother work.
Webb et al.
(2005)?s method, basedonly on intra-utterance lexical features, but incor-porating longer ngram sequences and feature se-lection, yields accuracy of 0.719.
Advanced treat-ment of both utterance and discourse level featuresyields accuracy of 0.739 (Kalchbrenner and Blun-som, 2013).
However, our experiments allow us toevaluate the contribution of various kinds of infor-mation: vector spaces based on word bigrams andon co-occurrence distributions both outperformedthe bag of words approach; but incorporation ofprevious utterance information did not.5 Conclusions and future workIn this work we evaluated the contribution ofword and utterance sequence, and of distributionalinformation using simple compositional vectorspace models, for dialogue act tagging.
Our exper-iments show that information about intra-utteranceword order (ngrams), and information about wordco-occurence distributions, outperforms the bag ofwords models, although not competitive with thestate of the art given the simplistic compositionalapproach used here.
Information about utterancetag sequence, on the other hand, did not.The usage of an external, large scale resource(here, the Google Ngram Corpus) to model wordsenses improves the tagging accuracy in compari-son to the bag of word model, suggesting that thedialogue act tag of an utterance depends on its se-mantics.However, the improvements in performance ofthe bag of bigrams model in comparison to bag ofunigrams, and the much higher results of Webb etal.
(2005)?s intra-utterance approach, suggest thatthe sequence of words inside an utterance is cru-cial for the dialogue act tagging task.
This sug-gests that our simplistic approaches to vector com-position (addition and multiplication) are likelyto be insufficient: more advanced, sequence- orgrammar-driven composition, such as categoricalcomposition (Coecke et al., 2010), might improvethe tagging accuracy.In addition, our results show that the perfor-mance of distributional models depends on manyfactors, including compositional operator selec-tion and weighting of the initial co-occurrence ma-trix.
Our work leaves much scope for improve-ments in these factors, including co-occurrencematrix instantiation.
For example, the windowsize of 2, which we used to obtain co-occurrencecounts, is lower than the usual size of 5 (Dinu andLapata, 2010), or the sentence level (Baroni andZamparelli, 2010).
Word representation in a vec-tor space using neural networks might improve ac-curacy as well (Mikolov et al., 2013).Previous approaches to dialogue act tagginghave shown utterance/tag sequence to be a use-ful source of information for improved accuracy(Stolcke et al., 2000).
We therefore conclude thatthe lower accuracy we obtained using models thatinclude information about the previous utteranceis due again to our simplistic method of compo-sition (vector concatenation); models which re-flect dialogue structure or sequence explicitly arelikely to be more suited.
Kalchbrenner and Blun-som (2013) give one way in which this can beachieved by learning from a specific corpus, andthe question of possible alternatives and more gen-eral models remains for future research.45AcknowledgmentsWe thank Mehrnoosh Sadrzadeh for her helpfuladvice and valuable discussion.
We would liketo thank anonymous reviewers for their effectivecomments.
Milajevs is supported by the EP-SRC project EP/J002607/1.
Purver is supportedin part by the European Community?s SeventhFramework Programme under grant agreement no611733 (ConCreTe).ReferencesEneko Agirre, Enrique Alfonseca, Keith Hall, JanaKravalova, Marius Pas?ca, and Aitor Soroa.
2009.A study on similarity and relatedness using distribu-tional and wordnet-based approaches.
In Proceed-ings of Human Language Technologies: The 2009Annual Conference of the North American Chap-ter of the Association for Computational Linguistics,pages 19?27.
Association for Computational Lin-guistics.Marco Baroni and Roberto Zamparelli.
2010.
Nounsare vectors, adjectives are matrices: Representingadjective-noun constructions in semantic space.
InProceedings of the 2010 Conference on EmpiricalMethods in Natural Language Processing, pages1183?1193.
Association for Computational Linguis-tics.Christos Boutsidis and Efstratios Gallopoulos.
2008.Svd based initialization: A head start for nonneg-ative matrix factorization.
Pattern Recognition,41(4):1350?1362.Bob Coecke, Mehrnoosh Sadrzadeh, and StephenClark.
2010.
Mathematical foundations for a com-positional distributional model of meaning.
CoRR,abs/1003.4394.Mark Core.
1998.
Analyzing and predicting patternsof damsl utterance tags.
In Proceedings of the AAAIspring symposium on Applying machine learning todiscourse processing.G.
Dinu and M. Lapata.
2010.
Measuring distribu-tional similarity in context.
In Proceedings of the2010 Conference on Empirical Methods in NaturalLanguage Processing, pages 1162?1172.
Associa-tion for Computational Linguistics.John R. Firth.
1957.
A Synopsis of Linguistic Theory,1930-1955.
Studies in Linguistic Analysis, pages 1?32.John J Godfrey, Edward C Holliman, and Jane Mc-Daniel.
1992.
Switchboard: Telephone speech cor-pus for research and development.
In Acoustics,Speech, and Signal Processing, 1992.
ICASSP-92.,1992 IEEE International Conference on, volume 1,pages 517?520.
IEEE.Edward Grefenstette and Mehrnoosh Sadrzadeh.
2011.Experimental support for a categorical composi-tional distributional model of meaning.
In Proceed-ings of the Conference on Empirical Methods in Nat-ural Language Processing, pages 1394?1404.
Asso-ciation for Computational Linguistics.Patrik O Hoyer.
2004.
Non-negative matrix factor-ization with sparseness constraints.
The Journal ofMachine Learning Research, 5:1457?1469.Daniel Jurafsky, Elizabeth Shriberg, and Debra Biasca.1997.
Switchboard swbd-damsl shallow-discourse-function annotation coders manual, draft 13.
Tech-nical Report 97-02, University of Colorado, Boul-der.
Institute of Cognitive Science.Daniel Jurafsky, Elizabeth Shriberg, Barbara Fox, andTraci Curl.
1998.
Lexical, prosodic, and syn-tactic cues for dialog acts.
In Proceedings of theACL-COLING Workshop on Discourse Relationsand Discourse Markers.Nal Kalchbrenner and Phil Blunsom.
2013.
Recurrentconvolutional neural networks for discourse compo-sitionality.
In Proceedings of the Workshop on Con-tinuous Vector SpaceModels and their Composition-ality, pages 119?126, Sofia, Bulgaria, August.
Asso-ciation for Computational Linguistics.Yuri Lin, Jean-Baptiste Michel, Erez Lieberman Aiden,Jon Orwant, Will Brockman, and Slav Petrov.
2012.Syntactic annotations for the Google Books ngramcorpus.
In Proceedings of the ACL 2012 SystemDemonstrations, pages 169?174.
Association forComputational Linguistics.Tomas Mikolov, Kai Chen, Greg Corrado, and Jef-frey Dean.
2013.
Efficient estimation of wordrepresentations in vector space.
arXiv preprintarXiv:1301.3781.Jeff Mitchell and Mirella Lapata.
2008.
Vector-basedmodels of semantic composition.
In Proceedingsof ACL-08: HLT, pages 236?244.
Association forComputational Linguistics.F.
Pedregosa, G. Varoquaux, A. Gramfort, V. Michel,B.
Thirion, O. Grisel, M. Blondel, P. Pretten-hofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Pas-sos, D. Cournapeau, M. Brucher, M. Perrot, andE.
Duchesnay.
2011.
Scikit-learn: Machine learn-ing in Python.
Journal of Machine Learning Re-search, 12:2825?2830.Riccardo Serafin, Barbara Di Eugenio, and MichaelGlass.
2003.
Latent semantic analysis for dia-logue act classification.
In Proceedings of the 2003Conference of the North American Chapter of theAssociation for Computational Linguistics on Hu-man Language Technology: companion volume ofthe Proceedings of HLT-NAACL 2003?short papers-Volume 2, pages 94?96.
Association for Computa-tional Linguistics.46Richard Socher, Brody Huval, Christopher D Manning,and Andrew Y Ng.
2012.
Semantic compositional-ity through recursive matrix-vector spaces.
In Pro-ceedings of the 2012 Joint Conference on Empiri-cal Methods in Natural Language Processing andComputational Natural Language Learning, pages1201?1211.
Association for Computational Linguis-tics.Richard Socher, John Bauer, Christopher D Manning,and Andrew Y Ng.
2013.
Parsing with composi-tional vector grammars.
In In Proceedings of theACL conference.
Citeseer.Andreas Stolcke, Klaus Ries, Noah Coccaro, Eliza-beth Shriberg, Rebecca Bates, Daniel Jurafsky, PaulTaylor, Carol Van Ess-Dykema, Rachel Martin, andMarie Meteer.
2000.
Dialogue act modeling forautomatic tagging and recognition of conversationalspeech.
Computational Linguistics, 26(3):339?373.Dinoj Surendran and Gina-Anne Levow.
2006.
Dialogact tagging with support vector machines and hiddenmarkov models.
In INTERSPEECH.Stefan Thater, Hagen F?urstenau, and Manfred Pinkal.2010.
Contextualizing semantic representations us-ing syntactically enriched vector models.
In Pro-ceedings of the 48th Annual Meeting of the Associa-tion for Computational Linguistics, ACL ?10, pages948?957, Stroudsburg, PA, USA.
Association forComputational Linguistics.Peter D Turney, Patrick Pantel, et al.
2010.
Fromfrequency to meaning: Vector space models of se-mantics.
Journal of artificial intelligence research,37(1):141?188.Nick Webb, Mark Hepple, and Yorick Wilks.
2005.Dialogue act classification based on intra-utterancefeatures.
In Proceedings of the AAAI Workshop onSpoken Language Understanding.
Citeseer.M.
Zhitomirsky-Geffet and I. Dagan.
2009.
Bootstrap-ping distributional feature vector quality.
Computa-tional Linguistics, 35(3):435?461.47
