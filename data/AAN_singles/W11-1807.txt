Proceedings of BioNLP Shared Task 2011 Workshop, pages 46?50,Portland, Oregon, USA, 24 June, 2011. c?2011 Association for Computational LinguisticsRobust Biomedical Event Extraction with Dual Decomposition and MinimalDomain AdaptationSebastian Riedel Andrew McCallumDepartment of Computer ScienceUniversity of Massachusetts, Amherst{riedel,mccallum}@cs.umass.eduAbstractWe present a joint model for biomedical eventextraction and apply it to four tracks of theBioNLP 2011 Shared Task.
Our model de-composes into three sub-models that concern(a) event triggers and outgoing arguments, (b)event triggers and incoming arguments and(c) protein-protein bindings.
For efficient de-coding we employ dual decomposition.
Ourresults are very competitive: With minimaladaptation of our model we come in secondfor two of the tasks?right behind a versionof the system presented here that includes pre-dictions of the Stanford event extractor as fea-tures.
We also show that for the InfectiousDiseases task using data from the Genia trackis a very effective way to improve accuracy.1 IntroductionThis paper presents the UMass entry to the BioNLP2011 shared task (Kim et al, 2011a).
We introducea simple joint model for the extraction of biomedicalevents, and show competitive results for four tracksof the competition.
Our model subsumes threetractable sub-models, one for extracting event trig-gers and outgoing edges, one for event triggers andincoming edges and one for protein-protein bind-ings.
Fast and accurate joint inference is provided bycombining optimizing methods for these three sub-models via dual decomposition (Komodakis et al,2007; Rush et al, 2010).
Notably, our model con-stitutes the first joint approach that explicitly pre-dicts which protein should share the same bindingevent.
So far this has either been done through post-processing heuristics (Bj?rne et al, 2009; Riedel etal., 2009; Poon and Vanderwende, 2010), or througha local classifier at the end of a pipeline (Miwa et al,2010).Our model is very competitive.
For Genia (GE)Task 1 (Kim et al, 2011b) we achieve the second-best results.
In addition, the best-performing FAUSTsystem (Riedel et al, 2011) is a variant of the modelpresented here.
Its advantage stems from the factthat it uses predictions of the Stanford system (Mc-Closky et al, 2011a; McClosky et al, 2011b), andhence performs model combination.
The same holdsfor the Infectious Diseases (ID) track (Pyysalo et al,2011), where we come in as second right behindthe FAUST system.
For the Epigenetics and Post-translational Modifications (EPI) track (Ohta et al,2011) we achieve the 4th rank, partly because we didnot aim to extract speculations, negations or cellularlocations.
Finally, for Genia Task 2 we rank 3rd?with the 1st rank achieved by the FAUST system.In the following we will briefly describe ourmodel and inference algorithm, as far as this is pos-sible in limited space.
Then we show our results onthe three tasks and conclude.
Note we will assumefamiliarity with the task, and refer the reader to theshared task overview paper for more details.2 Biomedical Event ExtractionOur goal is to extract biomedical events as shownin figure 1a).
To formulate the search for suchstructures as an optimization problem, we representstructures through a set of binary variables.
Our rep-resentation is inspired by previous work (Riedel etal., 2009; Bj?rne et al, 2009) and based on a projec-tion of events to a labelled graph over tokens in the46... phosphorylation of TRAF2 inhibits binding to the CD40 ...PhosphorylationRegulationBindingThemeCauseThemeThemeThemeRegulation BindingPhosphorylationThemeCauseThemeThemeThemeSame Binding2 34 5 6 7 8 9b4,9e2,Phos.a6,9,Theme(a)(b)Figure 1: (a) sentence with target event structure; (b) pro-jection to labelled graph.sentence, as seen figure 1b).We will first present some basic notation to sim-plify our exposition.
For each sentence x we havea set candidate trigger words Trig (x), and a set ofcandidate proteins Prot (x).
We will generally usethe indices i and l to denote members of Trig (x), theindices p, q for members of Prot (x) and the index jfor members of Cand (x) def= Trig (x) ?
Prot (x).We label each candidate trigger i with an eventType t ?
T (with None ?
T ), and use the binaryvariable ei,t to indicate this labeling.
We use binaryvariables ai,l,r to indicate that between i and l thereis an edge labelled r ?
R (with None ?
R).The representation so far has been used in previ-ous work (Riedel et al, 2009; Bj?rne et al, 2009).Its shortcoming is that it does not capture whethertwo proteins are arguments of the same bindingevent, or arguments of two binding events with thesame trigger.
To overcome this problem, we intro-duce binary ?same Binding?
variables bp,q that areactive whenever there is a binding event that hasboth p and q as arguments.
Our inference algorithmwill also need, for each trigger i and protein pair p, q,a binary variable ti,p,q that indicates that at i there isa binding event with arguments p and q.
All ti,p,q aresummarized in t.Constructing events from solutions (e,a,b) canbe done almost exactly as described by Bj?rne et al(2009).
However, while Bj?rne et al (2009) grouparguments according to ad-hoc rules based on de-pendency paths from trigger to argument, we simplyquery the variables bp,q.3 ModelWe use the following objective to score the struc-tures we like to extract:s (e,a,b) def=?ei,t=1sT (i, t) +?ai,j,r=1sR (i, j, r)+?bp,q=1sB (p, q)with local scoring functions sT (i, t)def=?wT, fT (i, t)?, sR (i, j, r)def= ?wR, fR (i, j, r)?and sB (p, q)def= ?wB, fB (p, q)?.Our model scores all parts of the structure in isola-tion.
It is a joint model due to the three types of con-straints we enforce.
The first type acts on trigger la-bels and their outgoing edges.
It includes constraintssuch as ?an active label at trigger i requires at leastone active outgoing Theme argument?.
The secondtype enforces consistency between trigger labels andtheir incoming edges.
That is, if an incoming edgehas a label that is not None, the trigger must not belabelled None either.
The third type of constraintsensures that when two proteins p and q are part ofthe same binding (as indicated by bp,q = 1), thereneeds to be a binding event at some trigger i thathas p and q as arguments.
We will denote the set ofstructures (e,a,b) that satisfy all above constraintsas Y .To learn w we choose the passive-aggressiveonline learning algorithm (Crammer and Singer,2003).
As loss function we apply a weighted sum offalse positives and false negative labels and edges.The weighting scheme penalizes false negatives 3.8times more than false positives.3.1 FeaturesFor feature vector fT (i, t) we use a collection ofrepresentations for the token i: word-form, lemma,POS tag, syntactic heads, syntactic children; mem-bership in two dictionaries used by Riedel et al(2009).For fR (a; i, j, r) we use representations ofthe token pair (i, j) inspired by Miwa et al (2010) .They contain: labelled and unlabeled n-gram depen-dency paths; edge and vertex walk features (Miwa etal., 2010), argument and trigger modifiers and heads,words in between (for close distance i and j).
ForfB (b; p, q) we use a small subset of the token pairrepresentations in fR.47Algorithm 1 Dual Decomposition.require:R: max.
iteration, ?t: stepsizest?
0 ??
0??
0repeat(e?, a?)?
bestIncoming (??)(e,a)?
bestOutgoing (cout (?,?
))(b, t)?
bestBinding(cbind (?
))?i,t ?
?i,t ?
?t (ei,t ?
e?i,t)?i,j,r ?
?i,j,r ?
?t (ai,j,r ?
a?i,j,r)?trigi,j,k ?
[?trigi,j,k ?
?t (ei,Bind ?
ti,j,k)]+?arg1i,j,k ?
[?arg1i,j,k ?
?t (ai,j,Theme ?
ti,j,k)]+?arg2i,j,k ?
[?arg2i,j,k ?
?t (ai,k,Theme ?
ti,j,k)]+t ?
t + 1until no ?, ?
changed or t > Rreturn(e,a,b)3.2 InferenceInference in our model amounts to solvingarg max(e,a,b)?Ys (e,a,b) .
(1)Our approach to finding the maximizer is dual de-composition (Komodakis et al, 2007; Rush et al,2010), a technique that allows us to exploit effi-cient search algorithms for tractable substructuresof our problem.
We divide the problem into threesub-problems: (1) finding the highest-scoring trig-ger labels and edges (e,a) such that constraints ontriggers and their outgoing edges are fulfilled; (2)finding the highest-scoring trigger labels and edges(e?, a?)
such that constraints on triggers and their in-coming edges are fulfilled; (3) finding the highest-scoring pairs of proteins b to appear in the samebinding, and make binding event trigger decisionst for these.
Due to space constraints we only statethat the first two problems can be solved exactly inO(n2 + nm)time while the last needs O(m2n).Here n is the number of trigger candidates and mthe number of proteins.The subroutines to solve these three sub-problemsare combined in algorithm 1?an instantiation ofsubgradient descent on the dual of an LP relaxationof problem 1.
In the first three steps in the mainloop of this algorithm, the individual sub-problemsare solved.
Note that to each subroutine a parame-ter is passed.
For example, when finding the struc-ture (e?, a?)
that maximizes the objective under theincoming edge constraints, we pass the parameter??.
This parameter represents a set of penalties tobe added to the objective used for the subproblem.In this case we have penalties ?
?i,e to be added tothe scores of trigger-label pairs (i, e), and penalties?
?i,j,r to be added for labelled edges ir?
j.One way to understand dual decomposition is asiterative tuning of the penalties such that eventu-ally all individual solutions are consistent with eachother.
In our case this would mean, among otherthings, that the solutions (e,a) and (e?, a?)
are iden-tical.
This tuning happens in the second part of themain loop which updates the dual variables?
and?.We see, for example, how the penalties ?i,e are de-creased by ei,e?
e?i,e scaled by a step-size ?t.
Effec-tively this change to ?i,e will decrease the score ofe?i,e within bestIn (??)
by ?t if e?i,e was true whileei,e was false in the current solutions.1 If e?i,e wasfalse but ei,e was true, the score is increased by ?t.If both agree, no change is needed.Consistency between solutions also means thatthe binding decisions in b and t are consistentwith the rest of the solution.
This is achieved inalgorithm 1 through tuning of the dual variables?
but we omit details for brevity.
For complete-ness we state how the penalties used for solvingthe other subproblems are set based on the dualvariables ?
and ?.
We set couti,t (?,?
)def= ?i,t +?t,Bind?p,q ?trigi,p,q; for the case that j ?
Prot (x) weget couti,j,r (?,?
)def= ?i,j,r +?p ?arg1i,j,p +?q ?arg2i,q,j ,otherwise couti,j,r (?,?
)def= ?i,j,r .
For bestBind (c)we set cbindi,p,q (?)
= ?
?trigi,p,q ?
?arg1i,,p,q ?
?arg2i,,p,q.3.3 PreprocessingAfter basic tokenization and sentence segmentation,we generate a set of protein head tokens Prot (x)for each sentence x based on protein span defi-nitions from the shared task.
To ensure tokenscontain not more than one protein we split themat protein boundaries.
Parsing is performed usingthe Charniak-Johnson parser (Charniak and John-son, 2005) with the self-trained biomedical parsing1We refer to Koo et al (2010) for details on how to set ?t.48SVT BIND REG TOTTask 1 73.5 48.8 43.8 55.2Task 1 (abst.)
71.5 50.8 45.5 56.1Task 1 (full) 79.2 44.4 40.1 53.1Task 2 71.4 38.6 39.1 51.0Table 1: Results for the GE track, task 1 and 2;abst.=abstract; full=full text.model of McClosky and Charniak (2008).
Finally,based on the set of trigger words in the training data,we generate a set of candidate triggers Trig (x).4 ResultsWe apply the same model to the GE, ID and EPItracks, with minor modifications in order to dealwith the different event type sets T and role sets Rof each track.
Training and testing together took be-tween 30 (EPI) to 120 (GE) minutes using a single-core implementation.4.1 GeniaOur results for GE task 1 and 2 can be seen in table1.
We also show results for abstracts only (abst.
),and for full text only (full).
Note that binding events(BIND) and general regulation events (REG) seemto be harder to extract in full text.
Somewhat surpris-ingly, for simple events (SVT) the opposite holds.We also like to point out that for full text extrac-tion we rank first?the second best FAUST systemachieves an F1 score of 52.67.4.2 Infectious DiseasesThe Infectious Diseases track differs from the Geniatrack in two important ways.
First, it introduces theevent type Process that is allowed to have no ar-guments at all.
Second, it comes with significantlyless training data (152 vs 908 documents).
We canaccommodate the first difference by making simplechanges in our inference algorithms.
For example,for Process events we do not force the algorithm topick a Theme argument.To compensate for the lack of training data wesimply add data from the GE track.
This is reason-able because annotations overlap quite significantly.In table 2 we show the impact of mixing differentamounts of ID data (I) and GE data (G) into thetraining set.
We point out that adding the ID trainingI/G BIND REG PRO TOTDEV 1/0 18.6 27.1 34.3 41.5DEV 0/1 18.2 26.8 0.00 35.5DEV 1/1 20.0 33.1 49.3 47.2DEV 2/1 20.0 34.5 52.0 48.5TEST 2/1 34.6 46.4 62.3 53.4Table 2: ID results for different amounts of ID (I) and (G)training data.set twice, and the GENIA set once, leads to the bestperformance (I/G=2/1).
Remarkably, the F1 scorefor Process increases by including data, althoughthis data does not include any such events.
This maystem from a shared model of None arguments that isimproved with more data.4.3 Epigenetics and Post-translationalModificationsFor this track a different set of events is to be pre-dicted.
However, it is straightforward to adapt ourmodel and algorithms to this setting.
For brevity weonly report our total results here and omit a tablewith details.
The first metric (ALL) includes nega-tion, speculation and cellular location targets.
Weomitted these in our model and hence our result of33.52 F1 is relatively weak.
For the metric that ne-glects these aspects (CORE), we achieve 64.15 F1and come in 4th.
Note that in this metric the FAUSTsystem, based on the model presented here, comesin as very close second.5 ConclusionWe have presented a robust joint model for eventextraction from biomedical text that performs wellacross all tasks.
Remarkably, no feature set or pa-rameter tuning was necessary to achieve this.
Wealso show substantial improvements for the ID taskby adding GENIA data into the training set.AcknowledgementsThis work was supported in part by the Center for Intelli-gent Information Retrieval.
The University of Massachusettsgratefully acknowledges the support of Defense Advanced Re-search Projects Agency (DARPA) Machine Reading Programunder Air Force Research Laboratory (AFRL) prime contractno.
FA8750-09-C-0181.
Any opinions, findings, and conclu-sion or recommendations expressed in this material are thoseof the authors and do not necessarily reflect the view of theDARPA, AFRL, or the US government.49ReferencesJari Bj?rne, Juho Heimonen, Filip Ginter, Antti Airola,Tapio Pahikkala, and Tapio Salakoski.
2009.
Extract-ing complex biological events with rich graph-basedfeature sets.
In Proceedings of the Natural LanguageProcessing in Biomedicine NAACL 2009 Workshop(BioNLP ?09), pages 10?18, Morristown, NJ, USA.Association for Computational Linguistics.Eugene Charniak and Mark Johnson.
2005.
Coarse-to-fine n-best parsing and maxent discriminative rerank-ing.
In Proceedings of the 43rd Annual Meeting of theAssociation for Computational Linguistics (ACL ?05),pages 173?180.Koby Crammer and Yoram Singer.
2003.
Ultraconserva-tive online algorithms for multiclass problems.
Jour-nal of Machine Learning Research, 3:951?991.Jin-Dong Kim, Sampo Pyysalo, Tomoko Ohta, RobertBossy, and Jun?ichi Tsujii.
2011a.
Overviewof BioNLP Shared Task 2011.
In Proceedings ofthe BioNLP 2011 Workshop Companion Volume forShared Task, Portland, Oregon, June.
Association forComputational Linguistics.Jin-Dong Kim, Yue Wang, Toshihisa Takagi, and Aki-nori Yonezawa.
2011b.
Overview of the Genia Eventtask in BioNLP Shared Task 2011.
In Proceedingsof the BioNLP 2011 Workshop Companion Volume forShared Task, Portland, Oregon, June.
Association forComputational Linguistics.Nikos Komodakis, Nikos Paragios, and Georgios Tziri-tas.
2007.
Mrf optimization via dual decomposition:Message-passing revisited.
In In ICCV.Terry Koo, Alexander M. Rush, Michael Collins, TommiJaakkola, and David Sontag.
2010.
Dual decompo-sition for parsing with non-projective head automata.In Proceedings of the 2010 Conference on EmpiricalMethods in Natural Language Processing (EMNLP).David McClosky and Eugene Charniak.
2008.
Self-training for biomedical parsing.
In Proceedings of the46rd Annual Meeting of the Association for Computa-tional Linguistics (ACL ?08).David McClosky, Mihai Surdeanu, and Chris Manning.2011a.
Event extraction as dependency parsing.
InProceedings of the Association for Computational Lin-guistics: Human Language Technologies 2011 Con-ference (ACL-HLT?11), Main Conference (to appear),Portland, Oregon, June.David McClosky, Mihai Surdeanu, and Christopher D.Manning.
2011b.
Event extraction as dependencyparsing in BioNLP 2011.
In BioNLP 2011 SharedTask.Makoto Miwa, Rune Saetre, Jin-Dong D. Kim, andJun?ichi Tsujii.
2010.
Event extraction with com-plex event classification using rich features.
Journal ofbioinformatics and computational biology, 8(1):131?146, February.Tomoko Ohta, Sampo Pyysalo, and Jun?ichi Tsujii.
2011.Overview of the Epigenetics and Post-translationalModifications (EPI) task of BioNLP Shared Task2011.
In Proceedings of the BioNLP 2011 WorkshopCompanion Volume for Shared Task, Portland, Oregon,June.
Association for Computational Linguistics.Hoifung Poon and Lucy Vanderwende.
2010.
Joint Infer-ence for Knowledge Extraction from Biomedical Lit-erature.
In Human Language Technologies: The 2010Annual Conference of the North American Chapter ofthe Association for Computational Linguistics, pages813?821, Los Angeles, California, June.
Associationfor Computational Linguistics.Sampo Pyysalo, Tomoko Ohta, Rafal Rak, Dan Sul-livan, Chunhong Mao, Chunxia Wang, Bruno So-bral, Jun?ichi Tsujii, and Sophia Ananiadou.
2011.Overview of the Infectious Diseases (ID) task ofBioNLP Shared Task 2011.
In Proceedings ofthe BioNLP 2011 Workshop Companion Volume forShared Task, Portland, Oregon, June.
Association forComputational Linguistics.Sebastian Riedel, Hong-Woo Chun, Toshihisa Takagi,and Jun?ichi Tsujii.
2009.
A markov logic approach tobio-molecular event extraction.
In Proceedings of theNatural Language Processing in Biomedicine NAACL2009 Workshop (BioNLP ?09), pages 41?49.Sebastian Riedel, David McClosky, Mihai Surdeanu,Christopher D. Manning, and Andrew McCallum.2011.
Model combination for event extraction inBioNLP 2011.
In BioNLP 2011 Shared Task.Alexander M. Rush, David Sontag, Michael Collins, andTommi Jaakkola.
2010.
On dual decomposition andlinear programming relaxations for natural languageprocessing.
In In Proc.
EMNLP.50
