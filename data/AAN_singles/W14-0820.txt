Proceedings of the 10th Workshop on Multiword Expressions (MWE 2014), pages 114?123,Gothenburg, Sweden, 26-27 April 2014. c?2014 Association for Computational LinguisticsUnsupervised Construction of a Lexicon and a Repository of VariationPatterns for Arabic Modal Multiword ExpressionsRania Al-Sabbagh?, Roxana Girju?, Jana Diesner?
?Department of Linguistics and Beckman Institute?School of Library and Information ScienceUniversity of Illinois at Urbana-Champaign, USA{alsabba1, girju, jdiesner}@illinois.eduAbstractWe present an unsupervised approach to builda lexicon of Arabic Modal MultiwordExpressions (AM-MWEs) and a repository oftheir variation patterns.
These novel resourcesare likely to boost the automatic identificationand extraction  of AM-MWEs1.1 IntroductionArabic Modal Multiword Expressions (AM-MWEs) are complex constructions that conveymodality senses.
We define seven modalitysenses, based on Palmer's (2001) cross-lingualtypology, which are (un)certainty, evidentiality,obligation, permission, commitment, ability andvolition.AM-MWEs range from completely fixed,idiomatic and sometimes semantically-opaqueexpressions, to morphologically, syntacticallyand/or lexical productive constructions.
As aresult, the identification and extraction of AM-MWEs have to rely on both a lexicon and arepository of their variation patterns.
To-date andto the best of our knowledge, neither resource isavailable.
Furthermore, AM-MWEs are quiteunderstudied despite the extensive research ongeneral-purpose Arabic MWEs.To build both the lexicon and the repository,we design a four-stage unsupervised method.Stage 1, we use Log-Likelihood Ratio and aroot-based procedure to extract candidate AM-MWEs from large Arabic corpora.
Stage 2, weuse token level features with k-means clusteringto construct two clusters.
Stage 3, from theclustering output we extract patterns thatdescribe the morphological, syntactic andsemantic variations of AM-MWEs, and store1 Both resources are available athttp://www.rania-alsabbagh.com/am-mwe.htmlthem in the pattern repository.
Stage 4, we usethe most frequent variation patterns to bootstraplow-frequency and new AM-MWEs.
The finallexicon and repository are manually inspected.Both resources are made publicly available.The contributions of this paper are: (1) weaddress the lack of lexica and annotatedresources for Arabic linguistic modality; andhence, we support NLP applications and domainsthat use modality  to identify (un)certainty (Diabet al.
2009), detect power relations (Prabhakaranand Rambow 2013), retrieve politeness markers(Danescu-Niculescu-Mizil et al.
2013), extractand reconstruct storylines (Pareti et al.
2013) andclassify request-based emails (Lampert et al.2010); (2) we provide both a lexicon and arepository of variation patterns to help increaserecall while keeping precision high for theautomatic identification and extraction ofproductive AM-MWEs; and (3) we explore themorphological, syntactic and lexical properties ofthe understudied AM-MWEs.For the rest of this paper, Section 2 definesAM-MWEs.
Section 3 outlines related work.Sections 4 describes our unsupervised method.Section 5 describes manual verification and thefinal resulting resources.2 What are AM-MWEs?AM-MWEs are complex constructions thatconvey (un)certainty, evidentiality, obligation,permission, commitment, ability and volition.Based on their productivity, we define five typesof AM-MWEs:Type 1 includes idiomatic expressions like  ?????????
HtmA wlAbd (must), ???
????
lEl wEsY(maybe) and ????
????
fymA ybdw (seemingly).Type 2 covers morphologically productiveexpressions such as ????
??
yrgb fy (he wants to)and ????
??
wAvq mn (sure about).
They inflect114AM-MWEs Unigram Synonym(s) English GlossArabic Transliteration Arabic Transliteration????
?????
???
Eqdt AlEzm ElY  ????-????
Ezmt - nwyt I intended (to)??
??????
??
fy AmkAny An ??????
ymknny I can/I have the ability to???
??????
???
ldy AEtqAd bAn ?????
AEtqd I think????
??????
???
hnAk AHtmAl bAn ?????????
yuHotamal possibly/there is a possibility thatTable 1: Example AM-MWEs and their unigram synonymsfor gender, number, person, and possibly fortense, mood and aspect.
Neither the head wordnor the preposition is replaceable by a synonym.In the literature of MWEs, Type 2 is referred toas phrasal verbs.
In the literature of modality, itis referred to as quasi-modals (i.e.
modals thatsubcategorize for prepositions).Type 3 comprises lexically productiveexpressions whose meanings rely on the headnoun, adjective or verb.
If the head word isreplaced by another of the same grammaticalcategory but a different meaning, the meaning ofthe entire expression changes.
Hence, if wereplace the head adjective ???????
AlDrwry(necessary) in ??
??
???????
mn AlDrwry An (itis necessary to) with ??????
Almmkn (possible),the meaning changes from obligation touncertainty.Type 4 comprises syntactically productiveexpressions.
It is similar to Type 3 except thatthe head words are modifiable and theirarguments, especially indirect objects, can beincluded within the boundaries of the MWE.Thus, the same expression from Type 3 can bemodified as in ??
???
??
???????
mn AlDrwry jdAAn (it is very necessary to).
Furthermore, we canhave an inserted indirect object as in ??
?????????
????????
mn AlDrwry llmSryyn An (it isnecessary for Egyptians to).Type 5 includes morphologically, lexicallyand syntactically productive expressions like  ???????
??
ldy yqyn An (I have faith that).Morphologically, the object pronoun in ???
ldy (Ihave) inflects for person, gender and number.Syntactically, the head noun can be modified byadjectives as in ??
???
????
????
ldy yqyn rAsx An(I have a strong faith that).
Lexically, themeaning of the expression relies on the headnoun ????
yqyn (faith) which is replaceable forother modality-based nouns such as ??
???
???
ldynyp An (I have an intention to).Despite the semantic transparency and themorpho-syntactic and lexical productivity of theexpressions in Types 3-5, we have three reasonsto consider them as AM-MWEs:First, although the head words in thoseexpressions are transparent and productive, theother components, including prepositions,relative adverbials and verbs, are fixed andconventionalized.
In ??
???????
??
mn AlDrwryAn (literally: from the necessary to; gloss: it isnecessary to), the preposition ??
mn (from)cannot be replaced by any other preposition.
In??????
???
????
hnAk AHtmAl bAn (there is apossibility that), the relative adverbial ????
hnAk(there is) cannot be replaced by another relativeadverbial such as ???
hnA (there is).
In  ?????
????????
??
yHdwny AlAml fy An (hope derives me to),the head is the noun ?????
AlAml (the hope).Therefore, the lexical verb ??????
yHdwny (drivesme) cannot be replaced by other synonymousverbs such as ??????
yqwdqny (leads me) or ?????
?ydfEny (pushes/drives me).Second, each of those expressions has a strictlyfixed word order.
Even for expressions that allowthe insertion of modifiers and verb/nounarguments, the inserted elements hold fixedplaces within the boundaries of the expression.Complex constructions that adhere to strictconstraints on word order but undergo lexicalvariation are classified by Sag et al.
(2002) assemi-fixed MWEs.Finally, each expression of those types islexically perceived as a one linguistic unit thatcan be replaced in many contexts by a unigramsynonym as illustrated in Table 1.
According toStubbs (2007) and Escart?n et al.
(2013), theperception of complex constructions as singlelinguistic units is characteristic of MWEs.3 Related WorkThere is a plethora of research on general-purpose Arabic MWEs.
Yet, no prior work hasfocused on AM-MWEs.
Hawwari et al.
(2012)describe the manual construction of a repositoryfor Arabic MWEs that classifies them based ontheir morpho-syntactic structures.115Corpus Token # Types # DescriptionAjdir 113774517 2217557 a monolingual newswire corpus of Modern Standard ArabicLDC ISI 28880558 532443 an LDC parallel Arabic-English corpus (Munteanu & Marcu 2007)YADAC 6328248 457361 a dialectal Arabic corpus of Weblogs and tweets (Al-Sabbagh & Girju 2012)Tashkeel 6149726 358950 a vowelized corpus of Classical and Modern Standard Arabic booksTotal 41472307 3566311Table 2: Statistics for the extraction corporaAttia et al.
(2010) describe the construction ofa lexicon of Arabic MWEs based on (1)correspondence asymmetries between ArabicWikipedia titles and titles in 21 differentlanguages, (2) English MWEs extracted fromPrinceton WordNet 3.0 and automaticallytranslated into Arabic, and (3) lexical associationmeasures.Bounhas and Slimani (2009) use syntacticpatterns and Log-Likelihood Ratio to extractenvironmental Arabic MWEs.
They achieveprecision rates of 0.93, 0.66 and 0.67 forbigrams, trigrams and quadrigrams, respectively.Al-Sabbagh et al.
(2013) manually build alexicon of Arabic modals with a small portion ofMWEs and quasi-modals.
In this paper, quasi-modals are bigram AM-MWEs.
Hence, theirlexicon has 1,053 AM-MWEs.Nissim and Zaninello (2013) build a lexiconand a repository of variation patterns for MWEsin the morphologically-rich Romance languages.Similar to our research, their motivation torepresent the productivity of Romance MWEsthrough variation patterns is to boost theirautomatic identification and extraction.
Anothersimilarity is that we define variation patterns aspart-of-speech sequences.
The  differencebetween their research and ours is that ourvariation patterns have a wider scope because wecover both the morpho-syntactic and lexicalvariations of AM-MWEs, whereas their variationpatterns deal with morphological variation only.4 The Unsupervised Method4.1 Extracting AM-MWEs4.1.1 Extraction ResourcesTable 22 shows the token and type counts as wellas the descriptions of the corpora used forextraction.
For corpus preprocessing, (1) htmlmark-up and diacritics are removed.
(2) Meta-2Ajdir: http://aracorpus.e3rab.com/Tashkeel: http://sourceforge.net/projects/tashkeela/linguistic information such as document andsegment IDs, section headers, dates and sources,as well as English data are removed.
(3)Punctuation marks are separated from words.
(4)Words in Roman letters are removed.
(5)Orthographical normalization is done so that allalef-letter variations are normalized to A, theelongation letter (_) and word lengthening areremoved.
(6) Finally, the corpus is tokenized andPart-of-Speech (POS) tagged by MADAMIRA(Pasha et a.
2014); the latest version of state-of-the-art Arabic tokenizers and POS taggers.4.1.2 Extraction Set-up and ResultsWe restrict the size of AM-MWEs in this paperto quadrigrams.
Counted grams include functionand content words but not affixes.
Working onlonger AM-MWEs is left for future research.The extraction of candidate AM-MWEs isconducted in three steps:Step 1: we use root-based information toidentify the words that can be possiblederivations of modality roots.
For modality roots,we use the Arabic Modality Lexicon from Al-Sabbagh et al.
(2013).In order to identify possible derivations ofmodality roots, we use RegExps.
For instance,we use the RegExp (\w*)m(\w*)k(\w*)n(\w*) toidentify words such as ??????
Almmkn (thepossible), ?????
Atmkn (I manage) and ??????
?bAmkAny (I can) which convey modality.This RegExp-based procedure can result innoise.
For instance, the aforementioned RegExpalso returns the word ?????????
AlAmrykAn(Americans) which happens to have the samethree letters of the root in the same orderalthough it is not one of its derivations.
Yet, theprocedure still filters out many irrelevant wordsthat have nothing to do with the modality roots.Step 2: for the resulting words from Step 1, weextract bigrams, trigrams and quadrigrams giventhe frequency thresholds of 20, 15 and 10,respectively.116In previous literature on MWEs with corporaof 6-8M words, thresholds were set to 5, 8 and10 for MWEs of different sizes.
Given the largesize of our corpus, we decide to use higherthresholds.Step 3: for the extracted ngrams we use theLog-Likelihood Ratio (LLR) to measure thesignificance of association between the ngramwords.
LLR measures the deviation between theobserved data and what would be expected if thewords within the ngram were independent.
Itsresults are easily interpretable: the higher thescore, the less evidence there is in favor ofconcluding that the words are independent.LLR is computed as  in Eq.
1 where Oij and Eijare the observed and expected frequencies,respectively3.
LLR is not, however, the onlymeasure used in the literature of MWEs.Experimenting with more association measuresis left for future work.Eq.
1: LLR = 2 ?
O logTable 3 shows the unique type counts of theextracted ngrams.
The extracted ngrams includeboth modal and non-modal MWEs.
For instance,both ??
??????
???
??
mn Almmkn lnA An (it ispossible for us to) and ??
????
???
????
fy Aqrbwqt mmkn (as soon as possible) are extracted asvalid quadrigrams.
Both have the word ???
?mmkn (possible) derived from the root m-k-n.Both are frequent enough to meet the frequencythreshold.
The words within each quadrigram arefound to be significantly associated according toLLR.
Nevertheless, mn Almmkn lnA An is anAM-MWE according to our definition in Section2, but fy Aqrb wqt mmkn is not.
This is becausethe former conveys the modality sense ofpossibility; whereas the latter does not.Therefore, we need the second clustering stage inour unsupervised method to distinguish modalfrom non-modal MWEs.Ngram size Unique TypesBigrams 86645Trigrams 43397Quadrigrams 25634Total 96031Table 3: Statistics for the extracted MWEs3 We use Banerjee and Pedersen's (2003) Perlimplementation of ngram association measures.4.2 Clustering AM-MWEsClustering is the second stage of ourunsupervised method to build the lexicon of theAM-MWEs and the repository of their variationpatterns.
This stage takes as input the extractedngrams from the first extraction stage; and aimsto distinguish between the ngrams that conveymodality senses and the ngrams that do not.4.2.1 Clustering Set-upThe clustering feature set includes token levelmorphological, syntactic, lexical and positionalfeatures.
It also has a mixture of nominal andcontinuous-valued features as we explain in thesubsequent sections.4.2.1.1 Morphological  FeaturesRoots used to guide the extraction of candidateAM-MWEs in Section 4.1.2 are used asclustering morphological features.
The reason isthat some roots have more modal derivationsthan others.
For instance, the derivations of theroot ?-?-?
D-r-r include ?????
Drwry(necessary), ????????
bAlDrwrp (necessarily),and ????
yDTr (he has to); all of which conveythe modality sense of obligation.
Consequently,to inform the clustering algorithm that a givenngram was extracted based on the root D-r-rindicates that it is more likely to be an AM-MWE.4.2.1.2 Syntactic FeaturesIn theoretical linguistics, linguists claim thatArabic modality triggers (i.e.
words and phrasesthat convey modality senses) subcategorize forclauses, verb phrases, to-infinitives and deverbalnouns.
For details, we refer the reader to Mitchelland Al-Hassan (1994), Brustad (2000), Badawiet al.
(2004) and Moshref (2012).These subcategorization frames can bepartially captured at the token level.
Forexample, clauses can be marked bycomplementizers, subject and demonstrativepronouns and verbs.
To-infinitives in Arabic aretypically marked by ??
An (to).
Even deverbalnouns can be detected with some POS tagsetssuch as Buckwalter's (2002) that labels them asNOUN.VN.Based on this, we use the POS informationaround the extracted ngrams as contextualsyntactic features for clustering.
We limit the117window size of the contextual syntactic featuresto ?1 words.Furthermore, as we mentioned in Section 2, wedefine AM-MWEs as expressions with fixedword order.
That is, the sequence of the POS tagsthat represent the internal structure of theextracted ngrams can be used as syntacticfeatures to distinguish modal from non-modalMWEs.4.2.1.3 Lexical FeaturesAs we mentioned in Section 2, except for thehead words of the AM-MWEs, other componentsare usually fixed and conventionalized.Therefore, the actual lexical words of theextracted ngrams can be distinguishing featuresfor AM-MWEs.4.2.1.4 Positional FeaturesAM-MWEs, especially trigrams and quadrigramsthat scope over entire clauses, are expected tocome in sentence-initial positions.
Thus we use@beg (i.e.
at beginning) to mark whether theextracted ngrams occur at sentence-initialpositions.4.2.1.5 Continuous FeaturesExcept for nominal morphological and lexicalfeatures, other features are continuous.
They arenot extracted per ngram instance, but are definedas weighted features across all the instances of atarget ngram.Thus, @beg for ngrami is the probability ofngrami to occur in a sentence-initial position.
Itis computed as the frequency of ngramioccurring at a sentence-initial positionnormalized by the total number n of ngrami inthe corpus.Similarly, POS features are continuous.
Forinstance, the probability that ngrami is followedby a deverbal noun is the frequency of its POS+1tagged as a deverbal noun normalized by thetotal number n of ngrami in the corpus.4.2.2 Clustering ResourcesAs we mentioned earlier, the extracted ngramsfrom the extraction stage are the input for thisclustering stage.
The root features are the sameroots used for extraction.
The POS features areextracted based on the output of MADAMIRA(Pasha et al.
2014) that is used to preprocess thecorpus - Section 4.1.1.
The positional featuresare determined based on the availability ofpunctuation markers for sentence boundaries.We implement k-means clustering with k set totwo and the distance metric set to the Euclideandistance4.
The intuition for using k-meansclustering is that we want to identify AM-MWEsagainst all other types of MWEs based on theirmorpho-syntactic, lexical and positional features.Thus the results of k-means clustering with k setto two will be easily interpretable.
Otherclustering algorithms might be considered forfuture work.4.2.3 Clustering Evaluation and Results4.2.3.1 Evaluation MethodologyWe use precision, recall and F1-score asevaluation metrics, with three gold sets: BiSet,TriSet and QuadSet, for bigrams, trigrams andquadrigrams, respectively.
Each gold set has1000 positive data points (i.e.
AM-MWEs).The gold sets are first compiled from multipleresources, including Mitchell and Al-Hassan(1994), Brustad (2000), Badawi et al.
(2004) andMoshref (2012).
Second, each compiled gold setis further evaluated by two expert annotators.They are instructed to decide whether a givenngram is an AM-MWE or not according to thefollowing definitions of AM-MWEs:?
They convey modality senses - Section 1?
They have unigram synonyms?
They have fixed word orders?
Their function words are fixedInter-annotator kappa ?
scores for the BiSet,TriSet and QuadSet are 0.93, 0.95 and 0.96,respectively.
Most disagreement is attributed tothe annotators' failure to find unigram synonyms.The positive BiSet includes (1) phrasal verbssuch as ?????
??
ytmkn mn (he manages to),  ??????
yEjz En (he fails to) and ????
?
yHlm be (helongs for), (2) prepositional phrases such as ????????
mn Almmkn (it is possible that) and ?????????
fy AlHqyqp (actually), (3) nominal phrasessuch as ????
??
Amly hw (my hope is to) and (4)AM-MWEs subcategorizing forcomplementizers such as ????
???
ySrH bAn (hedeclares that) and ????
??
yErf An (he knowsthat).4 We use the k-means clustering implementation fromOrange toolkit http://orange.biolab.si/118The positive TriSet includes verb phrases like????
??
??
yf$l fy An (he fails to) and prepositionalphrases like ??
????????
??
mn AlmstHyl An (it isimpossible to) and ????
?????
???
Endy AymAn bAn(I have faith that).The positive QuadSet includes verb phrasessuch as  ??
????????
?????
yHdwny AlAml fy An(hope drives me to) and prepositional phrasessuch as ??
???
???????
??
mn gyr Almqbwl An (it isunacceptable to).With these gold sets, we first decide on thebest cluster per ngram size.
We use an all-or-nothing approach; that is, for the two clusterscreated for bigrams, we select the cluster withthe highest exact matches with the BiSet to bethe best bigram cluster.
We do the same thing forthe trigram and quadrigram clusters.
Withinformation about the best cluster per ngramsize, our actual evaluation starts.To evaluate clustered bigram AM-MWEs, weconsider the output of best bigram, trigram andquadrigram clusters to allow for evaluatingbigrams with gaps.
We also toleratemorphological differences in terms of differentconjugations for person, gender, number, tense,mood and aspect.For example, true positives for the bigramAM-MWE ?????
??
ytmkn mn (he manages to)include its exact match and the morphologicalalternations of ?????
??
Atmkn mn (I manage to)and ?????
??
ntmkn mn (we manage to), amongothers.
In other words, if the output of the bigramclustering has Atmkn mn or ntmkn mn but theBiSet has only ytmkn mn, we consider this as atrue positive.The bigram ytmkn mn can have a (pro)nounsubject after the verb ytmkn: ytmkn ((pro)noungap) mn.
Thus, we consider the output of thetrigram best cluster.
If we find instances such as?????
??????
??
ytmkn Alt}ys mn (the presidentmanages to) or ?????
???
??
ntmkn nHn mn (wemanages to), we consider them as true positivesfor the bigram ytmkn mn as long as the trigramhas the two defining words of the bigram,namely the verb ytmkn in any of its conjugationsand the preposition mn.The same bigram - ytmkn mn - can have twogaps after the head verb ytmkn as in  ?????
????????????
??
ytmkn Alr}ys AlmSry mn (theEgyptian president manages to).
For that reason,we consider the best quadrigram cluster.
If wefind ytmkn ((pro)noun gap) ((pro)noun gap) mn,we consider this as a true positive for  the bigramytmkn mn as long as the two boundaries of thebigrams are represented.
We could not go anyfurther with more than two gaps because we didnot cluster beyond quadrigrams.False positives for the bigram ytmkn mn wouldbe the bigrams ?????
??????
ytmkn Alr}ys (thepresident manages) and ??????
??
Alr}ys mn (thepresident to) in the bigram cluster where one ofthe bigram's components - either the verb or thepreposition - is missing.False negatives of bigrams would be thosebigrams that could not be found in any of thebest clusters whether with or without gaps.Similar to evaluating bigrams, we consider theoutput of the trigram and quadrigram bestclusters to evaluate trigram AM-MWEs.
We alsotolerate morphological productivity.For instance, the trigram ?????
?????
???
EndnAAymAn bAn (we have faith that) conjugated forthe first person plural is a true positive for thegold set trigram ????
?????
???
Endy AymAn bAn(I have faith that), that is conjugated for the firstperson singular.The same trigram Endy AymAn bAn can havetwo types of gaps.
The first can be a noun-basedindirect object after the preposition End.
Thus,we can have ???
?????
?????
???
End AlnAs AymAnbAn (people have faith that).
The second can bean adjective after the head noun AymAn.
Thus wecan have ????
?????
????
???
Endy AymAn mTlqbAn (I have a strong faith that).Consequently, in the output of the quadrigrambest cluster, if we find matches to Endy AymAn(adjective gap) bAn in any conjugations of Endy,or if we find any matches for End (noun gap)AymAn bAn, we consider them as true positivesfor the trigram Endy AymAn bAn .If the pronoun in End is replaced by a nounand the adjective gap is filled, we will have apentagram like ???
?????
?????
????
???
End AlnAsAymAn mTlq bAn (people have a strong faiththat).
Since we do not extract pentagrams, weconsider chunks such as ???
?????
?????
End AlnAsAymAn (people have faith) and ?????
????
??
?AymAn mTlq bAn (strong faith that) as falsepositive trigrams.
This is because the formermisses the complementizer ???
bAn (in that), andthe latter misses the first preposition ???
End(literally: in; gloss: have).119Since we do not cluster pentagrams, we couldnot tolerate gaps in the output of thequadrigrams.
We, however, toleratemorphological variation.
As a result,  ??????
???????
??
yHdwnA AlAml fy An (hope drives us to) isconsidered as a true positive for ??????
?????
??
?
?yHdwny AlAml fy An (hope derives me to).It is important to note that we do not considerthe next best cluster of the larger AM-MWEsunless we do not find any true positives in theAM-MWE's original cluster.
For example, we donot search for bigrams' true positives in thetrigram and quadrigram clusters, unless there arenot any exact matches of the gold-set bigrams inthe bigrams' best cluster itself.
The same thingapplies when evaluating trigram AM-MWEs.4.2.3.2 Clustering Results and Error AnalysisTable 4 shows the evaluation results for bigrams,trigrams and quadrigrams.
We attribute the goodresults to our evaluation methodology in the firstplace because it allows counting true positivesacross clusters of different ngram sizes toaccount for gaps and tolerates morphologicalvariations.
Our methodology captures themorphological productivity of AM-MWEs whichis expected given that Arabic is morphologically-rich.
It also accounts for the syntacticproductivity in terms of insertion.Precision Recall F1Bigrams 0.663 0.776 0.715Trigrams 0.811 0.756 0.783Quadrigrams 0.857 0.717 0.780Table 4: Clustering evaluation resultsLong dependencies are a source of errors at therecall level.
Clustering could not capture suchinstances as ???????
??????
????
?????
???
SrHAlr}ys AlmSry Hsny mbArk b (the Egyptianpresident Hosni Mubarak declared to) becausethey go beyond our quadrigram limit.Another type of recall errors results from AM-MWEs that do not meet the extraction frequencythreshold despite the large size of our corpus.Our positive gold sets are sampled fromtheoretical linguistics studies in which theincluded illustrative examples are not necessarilyfrequent.
For example, we could not findinstances for the volitive ????
???
ytwq Aly (helongs for).Precision errors result from the fact that ourRegExp-based procedure to guide the firstextraction stage is noisy.
For instance, theRegExp (\w*)t(\w*)w(\w*)q(\w*) that wassupposed to extract the volitive ????
ytwq (helongs) did not return any instances for theintended modal but rather instances for ????
?ytwqf (he stops) which interestinglysubcategorizes for a preposition and acomplementizer as in ?????
??
??
ytwqf En An(literally: stops from to).
This subcategorizationframe is the same for modals such as ????
??
?
?yEjz En An (literally: unable from to).Consequently, ?????
??
??
ytwqf En An (he stopsfrom to) has been clustered as a trigram AM-MWE although it does not convey any modalitysenses.
This highlights another reason forprecision errors.
The subcategorization framesand hence the syntactic features used forclustering are not always distinctive for AM-MWEs.The @beg feature was the least informativeamong all features.
In the case of bigrams, theyare mostly lexical verbs that do not occur insentence initial positions.
Meanwhile,punctuation inconsistencies do not enable us toreliably mark @beg for many ngrams.4.3 Identifying Variation PatternsOur target is to build a lexicon and a repositoryof the variation patterns for AM-MWEs to boosttheir automatic identification and extraction,given their morpho-syntactic and lexicalproductivity.In order to identify variation patterns, we useas input the best clusters from the previousclustering stage and follow these steps:?
We keep all function words as is with theirlexical and POS representations?
We collapse all morphological tags forgender, number, person, tense, mood, aspectand case?
We add a HEAD tag to the head words (i.e.words whose roots were used for extraction)?
We add a GAP tag for adverbs, pronouns andother gap fillers to explicitly mark gaplocationsAn example pattern for the root  ?-?-?
T-m-H(wish) is  ((HEAD/*IV*) + (AlY/PREP) +(An/SUB_CONJ)) which reads as follows: a120trigram AM-MWE whose head is a verb in anyconjugation followed by the preposition AlY (to)and the subordinate conjunction An (that; to).Another pattern that results from theaforementioned steps for the same root of T-m-His ((HEAD/*IV*) + (ADV/GAP) + (AlY/PREP) +(An/SUB_CONJ)).
It means that an adverb can beinserted in-between the HEAD and the prepositionAlY (to).4.4 Bootstrapping AM-MWEsWe use the patterns identified in the previousstage in two ways: first, to extract low-frequencyAM-MWEs whose HEADs have the same roots asthe pattern's HEAD; and second, to extract AM-MWEs that have the same lexical, POS patternsbut are not necessarily derived from the modalityroots we used in extraction.For example, from the previous section weused ((HEAD/*IV*) + (AlY/PREP) +(An/SUB_CONJ)) to extract the third personfeminine plural conjugation of the root T-m-H inthe trigram ???
???
????
yTmHn AlY An (theywish for) that occurred only once in the corpus.We used the same pattern to extract ????
???
?
?ySbw AlY An (he longs for) that has the samepattern but whose HEAD'S root S-b-b was not inour list of modality roots.Among the new extracted AM-MWEs are theexpressions ??
??????
??
mn AlmwADH An (it isclear that) and ??
???????
??
mn AlTbyEy An (it isnormal that) that share the same pattern with  ????????
??
mn Almmkn An (it is possible that).
Wedecide to consider those expressions as AM-MWEs although they are not epistemic in theconventional sense.
That is, they do not evaluatethe truth value of their clause-based propositions,but rather presuppose the proposition as true, andexpress the speakers' sentiment towards it.This bootstrapping stage results in 358 AM-MWEs.
They are inspected during manualverification.5 Manual Verification and Final ResultsWe manually verify the best clusters, thebootstrapped AM-MWEs and the constructedpatterns before including them in the finallexicon and repository to guarantee accuracy.Besides, we manually add modality senses to thelexicon entries.
We also manually complete themorphological paradigms of the morphologicallyproductive AM-MWEs.
That is, if we only havethe bigram ????
??
yrgb fy (he longs for)conjugated for the third singular masculineperson, we manually add the rest of theconjugations.The final lexicon is represented in XML and isorganized by modality senses and then rootswithin each sense.
The lexicon comprises 10,664entries.
The XML fields describe: the Arabicstring, the size of the AM-MWE, the corpusfrequency and the pattern ID.
The pattern ID isthe link between the lexicon and the repositorybecause it maps each lexicon entry to its lexical,POS pattern in the repository.Roots Senses SizesA-m-l 710 Epistemic 4233 Bigrams 4806A-k-d 693 Evidential 811 Trigrams 3244r-g-b 396 Obligative 748 Quadrigrams 2614$-E-r 378 Permissive 755H-s-s 370 Commissive 111q-n-E 312 Abilitive 676E-q-d 293 Volitive 3330Total: 10,664Table 5: Statistics for the AM-MWE lexicon for thetop 7 roots and the distributions of modality sensesand AM-MWE sizesIf a lexicon entry is manually added, the tagMANUAL is used for the corpus frequency field.Table 5 gives more statistics about the lexicon interms of modality senses, AM-MWE sizes andthe top 7 frequent modality roots.The XML repository is given in the three  POStagsets supported by MADAMIRA.
The XMLfields describe: the pattern's ID, the POS of thehead and the pattern itself with the HEADs andGAPs marked.
Appendices A and B givesnapshots of the lexicon and the repository inBuckwalter's POS tagset.6 Conclusion and OutlookWe described the unsupervised construction of alexicon and a repository of variation patterns forAM-MWEs to boost their automaticidentification and extraction.
In addition to thecreation of novel resources, our research givesinsights about the morphological, syntactic andlexical properties of such expressions.
We alsopropose an evaluation methodology that accountsfor the productive insertion patterns of AM-MWEs and their morphological variations.For future work, we will work on larger AM-MWEs to cover insertion patterns that we could121not cover in this paper.
We will experiment withdifferent association measures such as point-wisemutual information.
We will also try differentclustering algorithms.AcknowledgementThis work was supported by grant NPRP 09-410-1-069 of the Qatar National Research Fund.
Wewould also like to thank the four anonymousreviewers for their constructive comments.ReferencesRania Al-Sabbagh and Roxana Girju.
2012.
YADAC:Yet another Dialectal Arabic Corpus.
Proc.
ofLREC'12, Istanbul, Turkey, May 23-25 2012Rania Al-Sabbagh, Jana Diesner and Roxana Girju.2013.
Using the Semantic-Syntactic Interface forReliable Arabic Modality Annotation.
Proc.
ofIJCNLP'13, Nagoya, Japan, October 14-18 2013Mohammed Attia, Antonio Toral, Lamia Tounsi,Pavel Pecina and Josef van Genbith.
2010.Automatic Extraction of Arabic MultiwordExpressions.
Proc.
of the Workshop on MWE 2010,Beijing, August 2010Elsaid Badawi, M.G.
Carter and Adrian Gully.
2004.Modern Written Arabic: A ComprehensiveGrammar.
UK: MPG Books LtdSatanjeev Banerjee and Ted Pedersen.
2003.
TheDesign, Implementation, and Use of the NgramStatistic Package.
Proc.
of CiCling'03,  MexicoCity, USAIbrahim Bounhas and Yahya Slimani.
2009.
A HybridApproach for Arabic Multi-Word Term Extraction.Proceedings of NLP-KE 2009, Dalian, China,September 24-27 2009Kristen E. Brustad.
2000.
The Syntax of SpokenArabic: A Comparative Study of Moroccan,Egyptian, Syrian and Kuwaiti Dialects.Georgetown Uni.
Press, Washington DC, USATim Buckwalter.
2002.
Arabic MorphologicalAnalyzer.
Technical Report, Linguistic DataConsortium, PhiladelphiaCristian Danescu-Niculescu-Mizil, Moritz Sudhof,Dan Jurafsky, Jure Leskovec and Christopher Potts.2013.
A Computational Approach to Politenesswith Application to Social Factors.
Proc.
of the 51stACL, , Sofia, Bulgaria, August 4-9  2013Mona Diab, Lori Levin, Teruko Mitamura, OwenRambow, Vinodkumar Prabhakaran, and WeiweiGuo.
2009.
Committed Belief Annotation andTagging.
Proc.
of the 3rd LAW Workshop, ACL-IJCNLP'09, pp.
68-73, SingaporeCarla Parra Escart?n, Gyri Sm?rdal Losnegaard, GunnInger Lyse Samdal and Pedro Pati?o Garc?a.
2013.Representing Multiword Expressions in Lexical andTerminological Resources: An Analysis for NaturalLanguage Processing Purposes.
Proc.
of eLex 2013,pages 338-357, Tallinn, Estonia, October 17-192013Abdelati Hawwari, Kfir Bar and Mona Diab.
2012.Building an Arabic Multiword ExpressionsRepository.
Proc.
of the 50th ACL, pages 24-29,Jeju, Republic of Korea, July 12 2012Andrew Lampert, Robert Dale and Cecile Paris.
2010,Detecting Emails Containing Requests for Action.Proc.
of the 2010 ACL, pages 984-992, LosAngeles, California, June 2010F.
Mitchell and S. A. Al-Hassan.
1994.
Modality,Mood and Aspect in Spoken Arabic with SpecialReference to Egypt and the Levant.
London andNY: Kegan Paul InternationalOla Moshref.
2012.
Corpus Study of Tense, Aspect,and Modality in Diglossic Speech in CaireneArabic.
PhD Thesis.
University of Illinois atUrbana-ChampaignDragos Stefan Munteanu and Daniel Marcu.
2007.
ISIArabic-English Automatically Extracted ParallelText, Linguistic Data Consortium, PhiladelphiaMalvin Nissim and Andrea Zaninello.
2013.
ARepository of Variation Patterns for MultiwordExpressions.
Proc.
of the 9th Workshop of MWE,pp.
101-105, Atlanta, Georgia, June 13-14 2013Frank R. Palmer.
2001.
Mood and Modality.
2ndEdition.
Cambridge University Press, Cambridge,UKSilvia Pareti, Tim O'Keefe, Ioannis Konstas, James R.Curran and Irena Koprinska.
2013.
AutomaticallyDetecting and Attributing Indirect Quotations.Proc.
of the 2013 EMNLP, pages.
989-1000,Washington, USA, October 18-21 2013Arfath Pasha, Mohamed Al-Badrashiny, Ahmed ElKholy, Ramy Eskander, Mona Diab, Nizar Habash,Manoj Pooleery, Owen Rambow and Ryan Roth.2014.
MADAMIRA: A Fast, Comprehensive Toolfor Morphological Analysis and Disambiguation ofArabic.
Proc.
of the 9th International Conferenceon Language Resources and Evaluation, Reykjavik,Iceland, May 26-31 2014Vinodkumar Prabhakaran and Owen Rambow.
2013.Written Dialog and Social Power: Manifestations ofDifferent Types of Power in Dialog Behavior.Proceedings of the 6th IJCNLP, pp.
216-224,Nagoya, Japan, October 14-18  2013Ivan Sag, Timothy Baldwin, Francis Bond, AnnCopestake and Dan Flickinger.
2002.
MultiwordExpressions: A Pain in the Neck for NLP.Proceedings of CiCling 2002, pages 1-15, MexicoCity, MexicoMichael Stubbs.
2007.
An Example of FrequentEnglish Phraseology: Distributions, Structures and122Functions.
Language and Computers: CorpusLinguistics 25 Years on, pages 89-105, (17)Appendix A: A snapshot of the XML lexicon<lexicon name="AM-MWE Lexicon v1.0"><modality sense="abilitive"><head root="q-d-r"><am-mwe string="????
???"
len="2" freq="283" patternID="23"> </am-mwe><am-mwe string="????
??????
???"
len="3" freq="7" patternID="45"> </am-mwe>...</head></modality><modality sense="epistemic"><head root="g-l-b"><am-mwe string="??
??????"
len="2" freq="122" patternID="15"> </am-mwe>...</head><head root="H-w-l"><am-mwe string="??????
??"
len="2" freq="70" patternID="10"> </am-mwe>...</head><head root="n-Z-r"><am-mwe string="??
???????
????
?? "
len="4" freq="38" patternID="50"> </am-mwe>...</head></modality></lexicon>Appendix B: A snapshot of the XML repository<repository name="AM-MWE Variation Patterns v1.0"><tagset name="Buckwalter" pos-tagger="MADAMIRA v1.0">...<pattern ID="10" head-pos="*+IV+*" pos="(HEAD)+ (An/SUB_CONJ)"></pattern>...<pattern ID="15" head-pos="DET+NOUN+*" pos="(fy/PREP)+(HEAD)"></pattern>...<pattern ID="23" head-pos="ADJ+*" pos="(HEAD)+(ElY/PREP)"> </pattern>...<pattern ID="45" head-pos="DET+NOUN+*" pos="(lyd/NOUN)+(PRON*/GAP)*+(HEAD)+(ElY/PREP)"></pattern>...<pattern ID="50" head-pos="DET+NOUN+*" pos="(mn/PREP)+(HEAD)+(ADV/GAP)*+(An/SUB_CONJ)"></pattern>....</tagset></repository>123
