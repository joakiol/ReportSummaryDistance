Proceedings of the Joint Conference on EMNLP and CoNLL: Shared Task, pages 71?75,Jeju Island, Korea, July 13, 2012. c?2012 Association for Computational LinguisticsICT: System Description for CoNLL-2012Hao Xiong and Qun LiuKey Lab.
of Intelligent Information ProcessingInstitute of Computing TechnologyChinese Academy of SciencesP.O.
Box 2704, Beijing 100190, China{xionghao, liuqun}@ict.ac.cnAbstractIn this paper, we present our system de-scription for the CoNLL-2012 coreferenceresolution task on English, Chinese andArabic.
We investigate a projection-basedmodel in which we first translate Chineseand Arabic into English, run a publiclyavailable coreference system, and then usea new projection algorithm to map thecoreferring entities back from English in-to mention candidates detected in the Chi-nese and Arabic source.
We compare toa baseline that just runs the English coref-erence system on the supplied parses forChinese and Arabic.
Because our methoddoes not beat the baseline system on thedevelopment set, we submit outputs gen-erated by the baseline system as our finalsubmission.1 IntroductionModeling multilingual unrestricted coreference inthe OntoNotes data is the shared task for CoNLL-2012.
This is an extension of the CoNLL-2011 shared task and would involve automaticanaphoric mention detection and coreference res-olution across three languages ?
English, Chineseand Arabic ?
using OntoNotes v5.0 corpus, giv-en predicted information on the syntax, proposi-tion, word sense and named entity layers.
Au-tomatic identification of coreferring entities andevents in text has been an uphill battle for sev-eral decades, partly because it can require worldknowledge which is not well-defined and partlyowing to the lack of substantial annotated data.Figure 1: The overall process of our system, wherewe use Google Translator to translate Chinese andArabic into English.For more details, readers can refer to (Pradhan etal., 2012).Before this year?s task, researchers proposed t-wo typical novel methods to address the prob-lem of natural language processing across multiplelanguages: projection and joint learning (Rahmanand Ng, 2012).
Specific to this year?s coreferenceresolution task, for projection based method, wecould first develop a strong resolver or utilize apublicly available system on English, and trans-late other languages into English, eventually, wecould project the coreferring entities resolved onEnglish back into other language sides.
General-ly, a projection method is easier to develop sinceit doesn?t need sentence alignment across multiplelanguages.
Thus, in this year?s task, we investigatea translation based model to resolve coreferenceon English, Chinese and Arabic.
The whole pro-cess is illustrated in figure 1, in which we first useGoogle Translator to translate Chinese and Ara-bic into English, and we then employ a strong En-glish coreference resolver to generate coreferringentities, after mapping entities from English into71Chinese and Arabic mention candidates, we couldobtain coreferring entities for these languages.Intuitively, the performance of coreference re-solver on English should perform better than thaton Chinese and Arabic since we have substantialcorpus for English and coreference resolution onEnglish is well studied compared to another twolanguages.
Thus we could imagine that projectingthe results from English into Chinese and Arabicshould still beats the baseline system using mono-lingual resolution method.
However, in our exper-iments, we obtain negative results on developingset that means our projection based model perfor-m worse than the baseline system.
According toour experimental results on developing set, final-ly, we submit results of baseline system in order toobtain better ranking.The rest of this paper is organized as follows, insection 2, we will introduce our method in details,and section 3 is our experimental results, we drawconclusion in section 4.2 Projection based ModelAs the last section mentioned, we propose to usea projection based model to resolve coreferenceon multiple languages.
The primary proceduresof our method could be divided into three steps:first step is translation, where Google Translator isemployed to translate Chinese and Arabic into En-glish, second is coreference resolution for English,last is the projection of coreferring entities.
Sincethe first step is clear that we extract sentences fromChinese and Arabic documents and translate theminto English using Google Translator, hence in thissection we will mainly describe the configurationof our English resolver and details of projectionmethod.2.1 English ResolverIn last year?s evaluation task, the StandfordNatural Language Processing Group ranked thefirst position and they also open their toolkit forresearch community, namely Standford CoreNLP(Lee et al, 2011) 1, better yet, their toolkit is op-timized for CoNLL task.
Thus we could use theirtoolkit as our English resolver and concentrateon bettering the projection of coreferring entities.1http://nlp.stanford.edu/software/corenlp.shtmlFigure 2: A minimum cost and maximum flowstructure is used to solve the problem that map-ping coreferring entities into each mention candi-dates with highest probability.We use the basic running script that is ?java -cpjoda-time.jar:stanford-corenlp.jar:stanford-corenlp-models.jar:xom.jar -Xmx3g e-du.stanford.nlp.pipeline.StanfordCoreNLP-filelist filelist.txt?
to resolve the resolution,where ?filelist?
involves all documents need to beperformed coreference resolution.2.2 Projection of Coreferring EntitiesAfter generating coreferring entities on English,the key step of our system is how to map them intomention candidates detected on Chinese and Ara-bic.
For instance, assuming we translate Chinesedocuments into English and obtain coreferring en-tities e1, e2, ei,.., eE on translated English doc-uments through aforementioned step, meanwhile,we consider all noun phrases(NP) in original Chi-nese documents and generate mention candidatesm1, m2, mj ,.., mM .
Therefore, our task is to mapeach ei into one mention candidate mj with high-est probability, and it can be obtained by the max-72Algorithm 1 Algorithm for computing similaritybetween two phrases in different languages.1: Input: we1 , .., wen , wc1 , .., wcm , Phrase TablePT2: s[n] = [0,?
inf, ..,?
inf]3: for i?
1..n do4: for j ?
0..10 do5: s[i + j] = max(s[i + j], s[i ?
1] +p(i, i + j))6: Output: s[n]Vimization of the following formula,P?
=?ei?E,mj?M{a(i, j)b(j, i)p(i, j)} (1)with constrains?i,j{a(i, j)} = 1 and?i,j{b(j, i)} = 1, where p(i, j) is the prob-ability of ei mapping into mj and a(i, j) aswell as b(i, j) are integers guaranteeing eachcoreferring entity map into one mention and eachmention has only one entity to be mapped into.To solve this problem, we reduce it as a CostFlow problem since it is easier to understandand implement compared to other methods suchas integer linear programming.
Note that thenumber of mention candidates is theoreticallylarger than that of coreferring entities, thus thisproblem couldn?t be reduced as the bipartite graphmatching problem since it needs equal number ofnodes in two parts.Figure 2 shows the graph structure designed tosolve this problem, where the symbols labeled oneach edge is a two tuples(Cost,Flow), indicatingthe cost and flow for each edge.
Since object ofCost Flow problem is to minimize the cost whilemaximizing the flows, thus we compute the c(i, j)as 1 ?
p(i, j) in order to be consistent with theequation 1.
To satisfy two constraints aforemen-tioned, we set up two dummy nodes ?Start?
and?End?, and connect ?Start?
to each entity ei withcost 0 and flow 1 ensuring each entity is availableto map one mention.
We also link each mentioncandidate mj to node ?End?
with the same val-ue ensuring each mention could be mapped intoby only one entity.
Clearly, there is an edge withtuple (1?p(i, j), 1) between each entity end men-tion indicating that each entity could map into anymention while with different probabilities.
Thus,solving this Cost-Flow problem is equal to maxi-mizing the equation 1 with two constraints.
SinceCost-Flow problem is well studied, thus some al-gorithm can solve this problem in polynomial time(Ahuja et al, 1993).
One may argue that we canmodify translation decoder to output alignmentsbetween Chinese and translated English sentence,unfortunately, Google Translator API doesn?t sup-ply these information while its translation qualityis obviously better than others for translating doc-uments in OntoNotes, moreover, it is impossible tooutput alignment for each word since some trans-lation rules used for directing translation includesome unaligned words, thus an algorithm to mapeach entity into each mention is more applicable.Clearly, another problem is how to computep(i, j) for each edge between entity and mentioncandidate.
This problem could be casted as howto compute similarity of phrases across multiplelanguages.
Formally, given an English phraseswe1 , .., wen and a Chinese phrase wc1 , .., wcm , theproblem is how to compute the similar score S be-tween them.
Although we could compute lexical,syntactic or semantic similar score to obtain ac-curate similarity, here for simplicity, we just com-pute the lexical similarity using the phrase tableextracted by a phrased-based machine translationdecoder (Koehn et al, 2003).
Phrase table is a richresource that contains probability score for phrasein one language translated into another language,thus we could design a dynamic algorithm shownin Algorithm 1 to compute the similar score.
E-quation in line 5 is used to reserve highest simi-lar score for its sub-phrases, and p(i, i + j) is thesimilar score between sub-phrases wi, .., wi+j andits translation.
When we compute the score of thesub-phrases wi, .., wi+j , we literately pick one ptifrom PT and check whether wc1 , .., wcm involvespti?s target side, if that we record its score un-til we obtain a higher score obtained by anotherptj and then update it.
For instance, assuming theChinese input sentence is ???????????
??
?
??
?
??
??
?
?, and theGoogle translation of this sentence is ?The world?s fifth Disneyland will soon open to the public .?.
Following the aforementioned steps, we utilizeEnglish resolver to find a coreferring entity: ?Theworld ?s fifth Disneyland?, and find two translationrules involving the former English phrase from the73bilingual phrase table: ?The world ?s fifth Disney-land => ???????????
(probabili-ty=0.6) ?
and ?The world ?s fifth Disneyland =>??????????
(probability=0.4)?.
S-ince the Chinese translation of both rules all con-tain the noun phrase ???
??
?
???
???
in the original Chinese input, we thus add thisnoun phrase into the coreferring entities as the En-glish resolve finding with the probability 0.6.3 Experiments3.1 English ResultsIn this section, we will report our experimental re-sults in details.
We use Standford CoreNLP toolkitto generate results for English.
Table 1 lists the F-score obtained on developing set.3.2 Chinese and Arabic ResultsAs last section mentioned, we first translateChinese and Arabic into English and then useCoreNLP to resolve coreference on English.
Toobtain high translation quality, we use GoogleTranslator Toolkit 2.
And to compute similarityscore, we run Giza++(Och and Ney, 2003) 3, anopen source toolkit for word alignment, to perfor-m word alignment.
For Chinese, we use 1 millionbilingual corpus provided by NIST MT evaluationtask to extract phrase table, and for Arabic its sizeis 2 million.
Note that, we extract phrase tablefrom English to Chinese and Arabic with maxi-mum phrase length 10.
The reason is that our al-gorithm check English phrase whose length is lessthan 10 tokens.
To compare our results, we al-so use CoreNLP to generate results for Chineseand Arabic.
Since CoreNLP use some syntac-tic knowledge to resolving coreference, it can al-so output coreferring entities for other languages.From table 2 we find that although CoreNLP is notdesigned for other languages, it still obtain accept-able scores and beat our projection based mod-el.
The main reason is that our method is coarseand obtain lower precision for mention detection,while CoreNLP use some manually written rulesto detect mention candidates.
Another explana-tion is that projection based model is hard to map2http://www.google.cn/url?source=transpromo&rs=rsmf&q=http://translate.google.com/toolkit3http://code.google.com/p/giza-pp/some phrases back into original languages, suchas ?that, it, this?.
Moreover, translation quality forsome corpus like web corpus is far from perfect,translation errors will surely affect the precision ofcoreference resolution.
Thus, for the final testingset, we run the CoreNLP to generate the results.3.3 Testing ResultsSince CoreNLP beats our system in Chinese andArabic, thus we run CoreNLP for all three lan-guages.
Table 3 lists the final results, and we alsogive results using golden parse tree for predictionin table 4.
From these two tables, we find that forany language, the system using golden parse treeshow better performance than the one using pre-dicted system in term of each metric.
The reasonis that the CoreNLP resolve coreference on parsetree and employ some parse features to corefer.
Onthe other hand, we could also see that the improve-ment is slight, because parsing errors affect lit-tle on finding mention candidates benefiting fromhigh precision on noun phrase prediction.
Final-ly, since we use an open source toolkit to generateresults, unfortunately, we have no ranking in thistask.4 ConclusionIn this paper, we present a projection based mod-el for coreference resolution.
We first translateChinese and Arabic into English, and then em-ploy a strong English resolver to generate core-ferring entities, after that a projection algorithm isdesigned to map coreferring entities into mentioncandidates detected in Chinese and Arabic.
How-ever, since our approach is coarse and due to limittime preparing for this task, the output generateby CoreNLP beats our results in three languages,thus we submit results generated by CoreNLP asour final submission.AcknowledgmentsThe authors were supported by National ScienceFoundation of China, Contracts 90920004, andHigh-Technology R&D Program (863) Project No2011AA01A207 and 2012BAH39B03.
We thankorganizers for their generous supplied resourcesand arduous preparation.
We also thank anony-mous reviewers for their thoughtful suggestions.74Mention MUC BCUB CEAFECoreNLP 73.68% 64.58% 70.60% 46.64Table 1: Experimental results on developing set(F-score) for English.Mention MUC BCUB CEAFECoreNLP-Chinese 52.15% 38.16% 60.38% 34.58Projection-Chinese 48.51% 32.31% 63.77% 24.72CoreNLP-Arabic 52.97% 27.88% 60.75% 40.52Projection-Arabic 42.68% 22.39% 62.18% 32.83Table 2: Experimental results on developing set(F-score) for Chinese and Arabic using CoreNLP andour system.Mention MUC BCUB CEAFECoreNLP-Chinese 49.82% 37.83% 60.30% 34.93CoreNLP-Arabic 53.89% 28.31% 61.83% 42.97CoreNLP-English 73.69% 63.82% 68.52% 45.36Table 3: Experimental results on testing set(F-score) using predicted parse tree.Mention MUC BCUB CEAFECoreNLP-Chinese 53.42% 40.60% 60.37% 35.75CoreNLP-Arabic 55.17% 30.54% 62.36% 43.03CoreNLP-English 75.58% 66.14% 69.55% 46.54Table 4: Experimental results on testing set(F-score) using golden parse tree.ReferencesR.K.
Ahuja, T.L.
Magnanti, and J.B. Orlin.
1993.
Net-work flows: theory, algorithms, and applications.1993.P.
Koehn, F.J. Och, and D. Marcu.
2003.
Statisticalphrase-based translation.
In Proceedings of the 2003Conference of the North American Chapter of theAssociation for Computational Linguistics on Hu-man Language Technology-Volume 1, pages 48?54.Association for Computational Linguistics.H.
Lee, Y. Peirsman, A. Chang, N. Chambers, M. Sur-deanu, and D. Jurafsky.
2011.
Stanford?s multi-pass sieve coreference resolution system at the conll-2011 shared task.
In Proceedings of the FifteenthConference on Computational Natural LanguageLearning: Shared Task, pages 28?34.
Associationfor Computational Linguistics.F.J.
Och and H. Ney.
2003.
A systematic comparisonof various statistical alignment models.
Computa-tional linguistics, 29(1):19?51.Sameer Pradhan, Alessandro Moschitti, Nianwen Xue,Olga Uryupina, and Yuchen Zhang.
2012.
CoNLL-2012 shared task: Modeling multilingual unrestrict-ed coreference in OntoNotes.
In Proceedings ofthe Sixteenth Conference on Computational NaturalLanguage Learning (CoNLL 2012), Jeju, Korea.Altaf Rahman and Vincent Ng.
2012.
Translation-based projection for multilingual coreference reso-lution.
In NAACL 2012.75
