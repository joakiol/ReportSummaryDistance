Proceedings of the ACL Interactive Poster and Demonstration Sessions,pages 121?124, Ann Arbor, June 2005. c?2005 Association for Computational LinguisticsReformatting Web Documents via Header TreesMinoru Yoshida and Hiroshi NakagawaInformation Technology Center, University of Tokyo7-3-1, Hongo, Bunkyo-ku, Tokyo 113-0033, JapanCREST, JSTmino@r.dl.itc.u-tokyo.ac.jp, nakagawa@dl.itc.u-tokyo.ac.jpAbstractWe propose a new method for reformat-ting web documents by extracting seman-tic structures from web pages.
Our ap-proach is to extract trees that describe hier-archical relations in documents.
We devel-oped an algorithm for this task by employ-ing the EM algorithm and clustering tech-niques.
Preliminary experiments showedthat our approach was more effective thanbaseline methods.1 IntroductionThis paper proposes a novel method for reformat-ting (i.e., changing visual representations,) of webdocuments.
Our final goal is to implement the sys-tem that appropriately reformats layouts of web doc-uments by separating semantic aspects (like XML)from layout aspects (like CSS) of web documents,and changing the layout aspects while retaining thesemantic aspects.We propose a header tree, which is a reasonablechoice as a semantic representation of web docu-ments for this goal.
Header trees can be seen as vari-ants of XML trees where each internal node is not anXML tag, but a header which is a part of documentthat can be regarded as tags annotated to other partsof the document.
Titles, headlines, and attributes areexamples of headers.
The left part of Figure 1 showsan example web document.
In this document, theheaders are About Me, which is a title, and NAMEand AGE, which are attributes.
(For example, NAMEcan be seen as a tag annotated to John Smith.
)Figure 2 shows a header tree for the example docu-ment.
It should be noted that each node is labeledwith parts of HTML pages, not abstract categoriessuch as XML tags.About Me* NAME *John Smith* AGE *25Back to Home Page...<h1>About Me</h1><center><br><br>* NAME *<br>...[ About,  Me,  NAME,  John,  Smith, ?
]</h1><center><br><br>*Web PageHTML SourceList of BlocksSeparatorFigure 1: An Example Web Document and Conver-sion from HTML Documents to Block Lists.Therefore, the required task is to extract headertrees from given web documents.
Web documentscan be reformatted by converting their header treesinto various forms including Powerpoint-like in-dented lists, HTML tables1, and Tree-class objectsof Java.
We implemented the system that producesthese representations by extracting header trees fromgiven web documents.One application of such reformatting is a webbrowser on small devices that shows extractedheader trees regardless of original HTML visual ren-dering.
Trees can be used as compact representa-tions of web documents because they show internalstructures of web documents concisely, and they canbe further augmented with open/close operations oneach node for the purpose of closing unnecessarynodes, or sentence summarization on leaf nodes con-taining long sentences.
Another application is a lay-out changer, which change a layout (i.e., HTML tagusage) of one web page to another, by aligning ex-tracted header trees of two web documents.
Otherapplications include HTML to XML transformationand audio-browsable web content (Mukherjee et al,2003).1For example, the first column represents the root, the sec-ond column represents its children, etc.121About MeNAMEJohn SmithAGE25Back to Home PageFigure 2: A Header Tree for the Example Web Doc-ument1.1 Related WorkSeveral studies have addressed the problem of ex-tracting logical structures from general HTML doc-uments without labeled training examples.
Oneof these studies used domain-specific knowledge toextract information used to organize logical struc-tures (Chung et al, 2002).
However, their ap-proach cannot be applied to domains for whichany knowledge is not provided.
Another type ofstudy employed algorithms to detect repeated pat-terns in a list of HTML tags and texts (Yang andZhang, 2001; Nanno et al, 2003), or more struc-tured forms (Mukherjee et al, 2003; Crescenzi etal., 2001; Chang and Lui, 2001) such as DOMtrees.
This approach might be useful for certaintypes of web documents, particularly those withhighly regular formats such as www.yahoo.comand www.amazon.com.
However, in many cases,HTML tag usage does not have so much regularity,and, there are even the case where headers do notrepeat at all.
Therefore, this type of algorithm maybe inadequate for the task of header extraction fromarbitrary web documents.The remainder of this paper is organized as fol-lows.
Section 2 defines the terms used in this paper.Section 3 provides the details of our algorithm.
Sec-tion 4 lists the experimental results and Section 5concludes this paper.2 Definitions2.1 Definition of TermsOur system decomposes an HTML document into alist of blocks.
A block is defined as the part of aweb document that is separated by a separator.
Aseparator is a sequence of HTML tags and symbols.Symbols are defined as characters in texts that areneither numbers nor letters.
Figure 1 shows an ex-ample of the conversion of an HTML document to alist of blocks.
[ [About Me, [NAME, John Smith], [AGE, 25] ], Back to HomePage] ]Figure 3: A List Representation of the Example WebDocumentA header is defined as a block that modifies sub-sequent blocks.
In other words, a block that can bea tag annotated to subsequent blocks is defined as aheader.
Some examples of headers are Titles (e.g.,?About Me?
), Headlines (e.g., ?Here is my pro-file:?
), Attributes (e.g., ?Name?, ?Age?, etc.
), andDates.2.2 Definition of the TaskThe system produces header trees for given webdocuments.
A header tree can be seen as an indentedlist of blocks where the level of each node?s indentis equal to the depth of the node, as shown in Figure2.
Therefore, the main part of our task is to give adepth to each block in a given web document.
Afterthat, some heuristic rules are employed to constructheader trees from a list of depths.
In the next sec-tion, we discuss the task of assigning a depth to eachblock.
Therefore, an input to the system is a list ofblocks and the output is a list of depths.The system also produces nested-list representa-tion of header trees for the purpose of evaluation.
Innested-list representation, each node that has chil-dren is represented by the list whose first elementrepresents the parent and remaining elements repre-sent the children.
Figure 3 shows list representationof the tree in Figure 2.3 Header Extraction AlgorithmIn this section, we describe our algorithm that re-ceives a list of blocks and returns a list of depths.3.1 Basic ConceptsThe algorithm proceeds in two steps: separator cat-egorization and block clustering.
The first stepestimates local block relations (i.e., relations be-tween neighboring blocks) via probabilistic modelsfor characters and tags that appear around separa-tors.
The second step supplements the first by ex-tracting the undetermined relations between blocksby focusing on global features, i.e., regularities inHTML tag sequences.
We employed a clusteringframework to implement a flexible regularity detec-tion system that is robust to noise.3.2 STEP 1: Separator CategorizationThe algorithm classifies each block relation into oneof three classes: NON-BOUNDARY, RELATING,122[ About,  Me,  NAME,  John,  Smith, AGE, ?
]List of BlocksNON-BOUNDARY RELATING UNRELATINGNON-BOUNDARYRELATINGFigure 4: An Example of Separator Categorization.and UNRELATING.
Both RELATING and UNRE-LATING can be considered to be boundaries; how-ever, blocks that sandwich RELATING separatorsare regarded to consist of a header and its modifiedblock.
Figure 4 shows an example of separator cate-gorization for the list of blocks in Figure 1.The left block of a RELATING separator must bein the smaller depth than the right block.
Figure 2shows an example.
In this tree, NAME is in a smallerdepth than John.
On the other hand, both the leftand right blocks in a NON-BOUNDARY separatormust be in the same depth in a tree representation,for example, John and Smith in Figure 2.3.2.1 Local ModelWe use a probabilistic model that assumes the lo-cality of relations among separators and blocks.
Inthis model, each separator   and the strings aroundit,  and , are modeled by means of the hidden vari-able , which indicates the class in which   is cate-gorized.
We use the character zerogram, unigram, orbigram (changed according to the number of appear-ances2) for  and  to avoid data sparseness prob-lems.For example, let us consider the following part ofthe example document:NAME: John Smith.In this case, : is a separator, ME is the left string andJo is the right string.Assuming the locality of separator appearances,the model for all separators in a given document setis defined as              where   is avector of left strings,  is a vector of separators, and is a vector of right strings.The joint probability of obtaining ,  , and  is                    assuming that  and  depend only on : a class ofrelation between the blocks around  .342This generalization is performed by a heuristic algorithm.The main idea is to use a bigram if its number of appearances isover a threshold, and unigrams or zerograms otherwise.3If the frequency for     is over a threthold,       isused instead of        .4If the frequency for  is under a threthold,  is replaced byits longest prefix whose frequency is over the threthold.Based on this model, each class of separators isdetermined as follows:                The hidden parameters     ,    , and   , are estimated by the EM algorithm (Demp-ster et al, 1977).
Starting with arbitrary initial pa-rameters, the EM algorithm iterates E-STEPs andM-STEPs in order to increase the (log-)likelihoodfunction            .To characterize each class of separators, we use aset of typical symbols and HTML tags, called rep-resentatives from each class.
This constraint con-tributes to give a structure to the parameter space.3.3 STEP 2: Block ClusteringThe purpose of block clustering is to take advantageof the regularity in visual representations.
For exam-ple, we can observe regularity between NAME andAGE in Figure 1 because both are sandwiched by thecharacter * and preceded by a null line.
This visualrepresentation is described in the HTML source as,for example,... <br><br>* NAME *<br> ...... <br><br>* AGE *<br> ...Our idea is to define the similarities between (con-text of) blocks based on the similarities betweentheir surrounding separators.
Each separator is rep-resented by the vector that consist of symbols andHTML tags included in it, and the similarity be-tween separators are calculated as cosine values.The algorithm proceeds in a bottom-up manner byexamining a given block list from tail to head, find-ing the block that is the most similar to the currentblock, and collecting them into the same cluster.
Af-ter that, all blocks in the same cluster is assigned thesame depth.4 Preliminary ExperimentsWe used a training data that consists of 1,418 webdocuments5 of moderate file size6 that did not have?src?
or ?script?
tags7.
The former criteria is basedon the observation that too small or too large doc-uments are hard to use for measuring performanceof algorithms, and the latter criteria is caused by thefact our system currently has no module to handleimage files as blocks.We randomly selected 20 documents as test doc-uments.
Each test document was bracketed by hand5They are collected by retrieving all user pages on one serverof a Japanese ISP.6from 1,000 to 10,000 bytes7Src tags indicate inclusion of image files, java codes, etc123Algorithm Recall Precision F-measureOUR ALGORITHM 0.477 0.266 0.329NO-CL 0.178 0.119 0.139NO-EM 0.389 0.211 0.265PREV 0.144 0.615 0.202Table 1: Macro-Averaged Recall, Precision, and F-measure on Test Documentsto evaluate machine-made bracketings.
The per-formance of web-page structuring algorithms canbe evaluated via the nested-list form of tree bybracketed recall and bracketed precision (Goodman,1996).
Recall is the rate that bracketing given byhand are also given by machine, and precision is therate that bracketing given by machine are also givenby hand.
F-measure is a harmonic mean of recall andprecision that is used as a combined measure.
Recalland precision were evaluated for each test documentand they were averaged across all test documents.These averaged values are called macro-average re-call, precision, and f-measure (Yang, 1999).We implemented our algorithm and the followingthree ones as baselines.NO-CL does not perform block clustering.NO-EM does not perform the EM-parameter-estimation.
Every boundary but representativesis defined to be categorized as ?UNRELAT-ING?.PREV performs neither the EM-learning nor theblock clustering.
Every boundary but represen-tatives is defined to be categorized as ?NON-BOUNDARY?8.
It uses the heuristics that ?ev-ery block depends on its previous block.
?Table 1 shows the result.
We observed that use ofboth the EM-learning and block clustering resultedin the best performance.
NO-EM performs the bestamong the three baselines.
It suggests that only rely-ing on HTML tag information is not a so bad strat-egy when the EM-training is not available becauseof, for example, the lack of a sufficient number oftraining examples.Results on the documents that were rich in HTMLtags with highly coherent layouts were better thanthose on the others like the documents with poorseparators such as only one space character or oneline feed.
Some of the current results on the doc-uments with such poor visual cues seemed difficultfor use in practical systems, which indicates our sys-tem still leaves room for improvement.8This strategy is based on the fact that it maximized the per-formance in a preliminary investigation.5 Conclusions and Future WorkThis paper proposed a method for reformatting webdocuments by extracting header trees that give hi-erarchical structures of web documents.
Prelimi-nary experiments showed that the proposed algo-rithm was effective compared with some baselinemethods.
However, the performance of the algo-rithm on some of the test documents was not suf-ficient for practical use.
We plan to improve theperformance by, for example, using larger amountof training examples.
Finding other reformattingstrategies in addition to the ones proposed in this pa-per is also important future work.ReferencesChia-Hui Chang and Shao-Chen Lui.
2001.
IEPAD: In-formation extraction based on pattern discovery.
InProceedings of WWW2001, pages 681?688.Christina Yip Chung, Michael Gertz, and Neel Sundare-san.
2002.
Reverse engineering for web data: Fromvisual to semantic structures.
In ICDE.Valter Crescenzi, Giansalvatore Mecca, and Paolo Meri-aldo.
2001.
ROADRUNNER: Towards automatic dataextraction from large web sites.
In Proceedings ofVLDB ?01, pages 109?118.A.P.
Dempster, N.M. Laird, and D.B.
Rubin.
1977.
Max-imum likelihood from incomplete data via the EM al-gorithm.
Journal of Royal Statistical Society: SeriesB, 39:1?38.Joshua Goodman.
1996.
Parsing algorithms and metrics.In Proceedings of ACL96, pages 177?183.Saikat Mukherjee, Guizhen Yang, Wenfang Tan, and I.V.Ramakrishnan.
2003.
Automatic discovery of seman-tic structures in HTML documents.
In Proceedings ofICDAR 2003.Tomoyuki Nanno, Suguru Saito, and Manabu Okumura.2003.
Structuring web pages based on repetition ofelements.
In Proceedings of WDA2003.Yudong Yang and Hongjiang Zhang.
2001.
HTML pageanalysis based on visual cues.
In Proceedings of IC-DAR01.Yiming Yang.
1999.
An evaluation of statistical ap-proaches to text categorization.
INRT, 1:69?90.124
