Language Generation for Multimedia Healthcare BriefingsKath leen  R .
McKeownSh imei  Pan  and James  ShawDept.
of Computer  ScienceColumbia UniversityNew York, NY 10027, USAkathy, pan, shaw?cs, columbia, eduAbst rac tThis paper identifies issues for languagegeneration that arose in developing amultimedia interface to healthcare datathat includes coordinated speech, textand graphics.
In order to produce briefspeech for time-pressured caregivers, thesystem both combines related informa-tion into a single sentence and uses ab-breviated references in speech when anunambiguous textual reference is alsoused.
Finally, due to the temporal natureof the speech, the language generationmodule needs to communicate informa-tion about the ordering and duration ofreferences to other temporal media, suchas graphics, in order to allow for coordi-nation between media.1 In t roduct ionIn a hospital setting it can be difficult for care-givers to obtain needed information about patientsin a timely fashion.
In a Cardiac Intensive CareUnit (ICU), communication regarding patient sta-tus is critical during the hour immediately follow-ing a coronary arterial bypass graft (CABG).
Itis at this critical point, when care is being trans-ferred from the Operating Room (OR) to the ICUand monitoring is at a minimum, that the pa-tient is most vulnerable to delays in treatment.During this time, there are a number of care-givers who need information about patient statusand plans for care, including the ICU nurses whomust prepare for patient arrival, the cardiologistwho is off-site during the operation, and residentsand attendings who will aid in determining post-operative care.
The only people who can providethis information are those who were present dur-ing surgery and they are often too busy attendingDesmond A .
Jo rdan*Bar ry  A.  Al len**Dept.
of Anesthesiology* andMedical Informatics Dept.
**College of Physicians and SurgeonsColumbia UniversityNew York, NY 10032to the patient o communicate much detail.To address this need, we are developing a mul-timedia briefing system, MAGIC (Multimedia Ab-stract Generation for Intensive Care), that takesas input online data collected uring the surgicaloperation as well as information stored in the maindatabases atColumbia Presbyterian Medical Cen-ter (Roderer and Clayton, 1992).
MAGIC gener-ates a multimedia briefing that integrates speech,text, and animated graphics to provide an updateon patient status (Dalal et al, 1996a).
In this pa-per, we describe the issues that arise for languagegeneration i this context:?
Conciseness: The generation process mustmake coordinated use of speech and text toproduce an overview that is short enough fortime pressured caregivers to follow, but un-ambiguous in meaning.?
Media specific tailoring: Generation musttake into account that one output medium isspeech, as opposed to the more usual writ-ten language, producing wording and sen-tence structure appropriate for spoken lan-guage.?
Coordination with other media: The lan-guage generation process must produceenough information so that speech and textcan be coordinated with the accompanyinggraphics.In the following sections, we first provide anoverview of the full MAGIC architecture and thendescribe the specific language generation issuesthat we address.
We close with a discussion ofour current directions.2 System OverviewMAGIC's architecture is shown in Figure 1.MAGIC exploits the extensive online data avail-277DatabaseMedzcal ~,~: \ [~ .
.
.
.
.
~, ~ .... ~ ~ l ,  ;:',~::!
~:~:..::~:~*~.Figure 1: MAGIC system architecture.able through Columbia Presbyterian Medical Cen-ter (CPMC) as its source of content for its brief-ing.
Operative vents during surgery are moni-tored through the LifeLog database system (Mod-ular Instruments Inc.), which polls medical de-vices (ventilators, pressure monitors and alike) ev-ery minute from the start of the case to the endrecording information such as vital signs.
In ad-dition, physicians (anesthesiologist and anesthe-sia residents) enter data throughout the course ofthe patient's urgery, including start of cardiopul-monary bypass and end of bypass as well as sub-jective clinical factors such as heart sounds andbreath sounds that cannot be retrieved by med-ical devices.
In addition, CPMC main databasesprovide information from the online patient record(e.g., medical history).From this large body of information, the datafilter selects information that is relevant o thebypass surgery and patient care in the ICU.MAGIC's content planner then uses a multimediaplan to select and partially order information forthe presentation, taking into account the caregiverthe briefing is intended for (nurse or physician).The media allocator allocates content o media,and finally, the media specific generators realizecontent in their own specific media (see (Zhou andFeiner, 1997) for details on the graphics genera-tor).
A media coordinator is responsible for en-suring that spoken output and animated graphicsare temporally coordinated.Within this context, the speech generator re-ceives as input a partially ordered conceptual rep-resentation of information to be communicated?I mThe generator includes a micro-planner, which isresponsible for ordering and grouping informationinto sentences.
Our approach to micro-planningintegrates a variety of different types of operatorsfor aggregation i formation within a single sen-tence.
Aggregation using semantic operators isenabled through access to the underlying domainhierarchy, while aggregation using linguistic op-erators (e.g., hypotactic operators, which add in-formation using modifiers uch as adjectives, andparatactic operators which create, for example,conjunctions) is enabled through lookahead to thelexicon used during realization.The speech generator also includes a re-alization component, implemented using theFUF/SURGE sentence generator (Elhadad, 1992;Robin, 1994), which produces the actual anguageto be spoken as well as textual descriptions thatare used as labels in the visual presentation?
Itperforms lexical choice and syntactic realization?Our version of the FUF/SURGE sentence gener-ator produces entences annotated with prosodicinformation and pause durations.
This output issent to a speech synthesizer in order to producefinal speech.
(Currently, we are using AT&T BellLaboratories' Text To Speech System).Our use of speech as an output medium pro-vides an eyes-free nvironment that allows care-givers the opportunity to turn away from the dis-play and continue carrying out tasks involving pa-tient care.
Speech can also clarify graphical con-ventions without requiring the user to look awayfrom the graphics to read an associated text.
Cur-rently, communication between OR caregivers and278ICU caregivers is carried out orally in the ICUwhen the patient is brought in.
Thus, the useof speech within MAGIC models current practice.Future planned evaluations will examine caregiversatisfaction with the spoken medium versus text.3 Issues for Language GenerationIn the early stages of system development, a pri-mary constraint on the language generation pro-cess was identified during an informal evalua-tion with ICU nurses and residents (Dalai et al,1996a).
Due to time constraints in carrying outtasks, nurses, in particular, noted that speechtakes time and therefore, spoken language outputshould be brief and to the point, while text, whichis used to annotate the graphical illustration, mayprovide unambiguous references to the equipmentand drugs being used.
In the following sections,we show how we meet this constraint both in thespeech content planner, which organizes the con-tent as sentences, and in the speech sentence gen-erator, which produces actual language.In all of the language generation components,the fact that spoken language is the outputmedium and not written language, influences howgeneration is carried out.
We note this influenceon the generation process throughout the section.An example showing the spoken output for agiven patient and a screen shot at a single pointin the briefing is shown in Figure 3.In actual output, sentences are coordinatedwith the corresponding part of the graphical illus-tration using highlighting and other graphical ac-tions.
In the paper, we show the kinds of modifica-tions that it was necessary to make to the languagegenerator in order to allow the media coordinatorto synchronize speech with changing raphics.3.1 Speech  Micro-PlannerThe speech micro-planner is given as input a setof information that must be conveyed.
In order toensure that speech is brief and yet still conveys thenecessary information, the speech micro-plannerattempts to fit more information into individualsentences, thereby using fewer words.Out of the set of propositions given as input,the micro-planner selects one proposition to startwith.
It attempts to include as many other propo-sitions as it can as adjectives or other modifiersof information already included.
To do this, fromthe remaining propositions, it selects a propositionwhich is related to one of the propositions alreadyselected via its arguments.
It then checks whetherit can be lexicalized as a modifier by looking ahead~.
JonesMRN: 4455667 Hiztory':Ilyl~e\[tev.sk, n S~rgean: Dr,.
'~mtlhAge: $0 D iab~ Op~r~,ti~: CABGGoader: F~m~a|cVoice: Ms. Jones is an 80 year old, hypertensive, dia-betic, female patient of Dr. Smith undergoing CABG.Presently, she is 30 minutes post-bypass and will ar-rive in the unit shortly.
The existing infusion linesare two IVs, an arterial ine, and a Swan-Ganz withCordis.
The patient has received massive vasotonictherapy, massive cardiotonic therapy, and massive-volume blood-replacement therapy.
Drips in proto-col concentrations are nitroglycerin, levophed, dobu-tamine, epinephrine, and inocor...Figure 2: Multimedia presentation generated byMAGICto the lexicon used by the lexical chooser to deter-mine if such a choice exists.
The syntactic con-straint is recorded in the intermediate form, butthe lexical chooser may later decide to realize theproposition by any word of the same syntactic at-egory or transform a modifier and a noun into asemantic equivalent noun or noun phrase.The micro-planner uses information from thelexicon to determine how to combine the propo-sitions together while satisfying grammatical andlexical constraints.
Semantic aggregation is thefirst category of operators applied to the set of re-lated propositions in order to produce concise ex-pressions, as shown in lower portion of Fig.
1.
Us-ing ontological and lexical information, it can re-duce the number of propositions by replacing themwith fewer propositions with equivalent meanings.While carrying out hypotactic aggregation opera-tors, a current central proposition is selected andthe system searches through the un-aggregatedpropositions to find those that can be realizedas adjectives, prepositional phrases and relativeclauses, and merges them in.
After hypotactic ag-gregation, the un-aggregated propositions are thencombined using paratactic operators, such as ap-positions or coordinations.279X i s  a pat ient .X has proper ty  las t  name = Jones .X has proper ty  age = 80 years  o ld .X has proper ty  h i s to ry  = hyper tens ion  property .X has proper ty  h i s to ry  = d iabetes  proper ty .X has proper ty  gender  - female .X has proper ty  surgery  = CABG.X has proper ty  doctor  = Y.Y has  proper ty  las t  name = Smi th .Figure 3: propositions for the first sentenceIn the first sentence of the example output, themicro-planner has combined the 9 input proposi-tions shown above in Figure 3 into a single sen-tence: Ms Jones is an 80 year old hypertensive,diabetic female patient of Dr. Smith undergoingCABG.
In this example this is possible, in part be-cause the patient's medical history (diabetes andhypertension) can be realized as adjectives.
Inanother example, "Mr. Smith is a 60 year oldmale patient of Dr. Jordan undergoing CABG.He has a medical history of transient ischemicattacks, pulmonary hypertension, and peptic ul-cers.
", the medical history can only be realizedas noun phrases, thus requiring a second sentenceand necessarily, more words.3.2 Speech  Sentence  GeneratorThe speech sentence generator also contributes tothe goal of keeping spoken output brief, but in-formative.
In particular, through its lexical choicecomponent, it selects references to medical con-cepts that are shorter and more colloquial thanthe text counterpart.
As long as the text labelon the screen is generated using the full, unam-biguous reference, speech can use an abbreviatedexpression.
For example, when referring to the de-vices which have been implanted, speech can usethe term "pacemaker" so long as the textual abelspecifies it as "ventricular pacemaker".
Similarly,MAGIC uses "balloon pump" in speech insteadof "intra-aortic balloon pump", which is alreadyshown on the screen.In order to do this, lexical choice in both me-dia must be coordinated.
Lexical choice for textalways selects the full reference, but lexical choicefor speech must check what expression the textgenerator is using.
Basically, the speech texicalchooser must check what attributes the text gen-erator includes in its reference and omit those.Finally, we suspect hat the syntactic structureof sentences generated for spoken output should besimpler than that generated for written language.This hypothesis i in conflict with our criteria forgenerating as few sentences as possible, which of-ten results in more complex sentences.
This isin part acceptable due to the fact that MAGIC'soutput is closer to formal speech, such as onemight find in a radio show, as opposed to infor-mal conversation.
It is, after all, a planned one-way presentation.
In order to make the generatedsentences more comprehensible, however, we havemodified the lexical chooser and syntactic gener-ator to produce pauses at complex constitutionsto increase intelligibility of the output.
Currently,we are using a pause prediction algorithm whichutilizes the sentence's semantic structure, syntac-tic structure as well as the linear phrase lengthconstraint to predict the pause position and rela-tive strength.
Our current work involves modify-ing the FUF/SURGE language generation packageso that it can produce prosodic and pause infor-mation needed as input to a speech synthesizer, toproduce a generic spoken language sentence gen-erator.3.3 Producing Information for MediaCoordinationLanguage generation in MAGIC is also affectedby the fact that language is used in the contextof other media as well.
While there are specificmodules in MAGIC whose task is concerned withutilizing multiple media, media coordination af-fects the language generation process also.
In par-ticular, in order to produce a coordinated presen-tation, MAGIC must temporally coordinate spo-ken language with animated graphics, both tem-poral media.
This means that spoken referencesmust be coordinated with graphical references tothe same information.
Graphical references mayinclude highlighting of the portion of the illustra-tion which refers to the same information as speechor appearance of new information on the screen.Temporal coordination i volves two problems: en-suring that ordering of spoken references to infor-mation is compatible with spatial ordering of thegraphical actions and synchronizing the durationof spoken and graphical references (Dalai et al,1996b).In order to achieve this, language generationmust provide a partial ordering of spoken refer-ences at a fairly early point in the generation pro-cess.
This ordering indicates its preference for howspoken references are to be ordered in the outputlinear speech in accordance with both graphicaland presentation constraints.
For example, in thefirst sentence of the example shown in Figure 3,the speech components have a preference for med-ical history (i.e., "hypertensive, diabetic") to be280presented before information about he surgeon, asthis allows for more concise output.
It would bepossible for medical history to be presented afterall other information in the sentence by generat-ing a separate sentence (e.g., "She has a historyof hypertension and diabetes.")
but this is lesspreferable from the language point of view.
In ourwork, we have modified the structure of the lexicalchooser so that it can record its decisions about or-dering, using partial ordering for any grammaticalvariation that may happen later when the finalsyntactic structure of the sentence is generated.These are then sent to the media coordinator fornegotiating with graphics an ordering that is com-patible to both.
Details on the implementationof this negotiation are presented in (Dalal et al,1996b) and (Pan and McKeown, 1996).In order to synchronize duration of the spo-ken and graphical references, the lexical chooserinvokes the speech synthesizer tocalculate the du-ration of each lexical phrase that it generates.
Bymaintaining a correspondence b tween the refer-ential string generated and the concepts that thosereferential ctions refer to, negotiation with graph-ics has a common basis for communication.
Inorder to provide for more flexible synchronization,the speech sentence generator includes facilities formodifying pauses if conflicts with graphics dura-tions arise (see (Pan and McKeown, 1996) for de-tails).4 Related WorkThere is considerable interest in producing fluentand concise sentences.
EPICURE (Dale, 1992),PLANDOC(Kukich et al, 1994; Shaw, 1995), andsystems developed by Dalianis and Hovy (Dalia-nis and Hovy, 1993) all use various forms of con-junction and ellipsis to generate more concise sen-tences.
In (Horacek, 1992) aggregation is per-formed at text-structure level.
In addition to con-joining VP and NPs, FLowDoc(Passonneau etal., 1996) uses ontological generalization to com-bine descriptions of a set of objects into a moregeneral description.
Based on a corpus analy-sis in the basketball domain, (Robin, 1994) cat-alogued a set of revision operators uch as adjoinand nominalization i his system STREAK.
Un-like STREAK, MAGIC does not use revision tocombine information i  a sentence.Generating spoken language from meanings orconcepts (Meaning to Speech, MTS) is a new topicand only a few such systems were developed inrecent years.
In (Prevost, 1995) and (Steedman,1996), they explore a way to generate spoken lan-guage with accurate contrastive stress based on in-formation structure and carefully modeled omainknowledge.
In (Davis and Hirschberg, 1988), spo-ken directions are generated with richer intonationfeatures.
Both of these systems took advantage ofthe richer and more precise semantic informationthat is available during the process of Meaning toSpeech production.5 Conclusions and CurrentDirectionsThe context of multimedia briefings for access tohealthcare data places new demands on the lan-guage generation process.
Language generation iMAGIC addresses its user's needs for a brief, yetunambiguous, briefing by coordinating spoken lan-guage with the accompanying textual references inthe graphical i lustration and by combining infor-mation into fewer sentences.
It also must explicitlyrepresent its decisions as it generates a sentence inorder to provide information to the media coordi-nator for negotiation with graphics.Our development of MAGIC is very much anongoing research project.
We are continuing towork on improved coordination of media, use ofthe syntactic and semantic structure of generatedlanguage to improve the quality of the synthesizedspeech, and analysis of a corpus of radio speech toidentify characteristics of formal, spoken language.6 AcknowledgmentsMAGIC is a joint project which involves the Nat-ural Language Processing roup (the authors),the Graphics and User Interface group (SteveFeiner, Michelle Zhou and Tobias Hollerer), theKnowledge Representation group (Mukesh Dalaland Yong Feng) in the Department of Com-puter Science of Columbia University and Dr.Desmond Jordan and Prof. Barry Allen at theColumbia College of Physicians and Surgeons (au-thors).
This work is supported by DARPA Con-tract DAAL01-94-K-0119, the Columbia Univer-sity Center for Advanced Technology in HighPerformance Computing and Communications inHealthcare (funded by the New York State Sci-ence and Technology Foundation) and NSF GrantsGER-90-2406.281ReferencesM.
Dalai, S. Feiner, K. McKeown, D. Jordan,B.
Allen, and Y. alSafadi.
1996a.
Magic: Anexperimental system for generating multimediabriefings about post-bypass patient status.
InProceedings of American Medical InformaticsAssociation 1996 Fall.M.
Dalal, S. Feiner, K. McKeown, S. Pan,M.
Zhou, T. Hollerer, J. Shaw, Y. Feng, andJ.
Fromer.
1996b.
Negotiation for automatedgeneration of temporal multimedia presenta-tions.
In Proceedings of A CM Multimedia '96.R.
Dale.
1992.
Generating Referring Expressions:Constructing Descriptions in a Domain of Ob-jects and Processes.
MIT Press, Cambridge,MA.H.
Dalianis and E. Hovy.
1993.
Aggregation innatural language generation.
In Proceedingsof the Fourth European Workshop on NaturalLanguage Generation, pages 67-78, Pisa, Italy.J.
Davis and J. Hirschberg.
1988.
Assigning in-tonational features in synthesized spoken dis-course.
In Proceedings of the 26th AnnualMeeting of the Association for ComputationalLinguistics, pages 187-193, Buffalo, New York.M.
Elhadad.
1992.
Using argumentation to con-trol lexical choice: A functional unification-based approach.
Ph.D. thesis, Computer Sci-ence Department, Columbia University.H.
Horacek.
1992.
An integrated view of textplanning.
In Aspects of Automated NaturalLanguage Generation, pages 29-44.
Springer-Verlag.K.
Kukich, K. McKeown, and J. Shaw.
1994.Practical issues in automatic documentationgeneration.
In Proceedings of the 4th ACLConference on Applied Natural Language Pro-cessing, pages 7-14, Stuttgart.S.
Pan and K. McKeown.
1996.
Spoken languagegeneration i  a multimedia system.
In Proceed-ings of ICSLP 96, volume 1, pages 374-377,Philadelphia, PA.R.
Passonneau, K. Kukich, V. Hatzivassiloglou,L.
Lefkowitz, and H. Jing.
1996.
Gener-ating summaries of work flow diagrams.
InProceedings of the International Conference onNatural Language Processing and IndustrialApplications, pages 204-210, New Brunswick,Canada, June.
Univeristy of Moncton.S.
Prevost.
1995.
A Semantics of Contrast and In-formaiton Structure for Specifying Intonationin Spoken Language Generation.
Ph.D. thesis,University of Pennsylvania.J.
Robin.
1994.
Revision-Based Generation ofNatural Language Summaries Providing His-torical Background.
Ph.D. thesis, ComputerScience Department, Columbia University.N.
Roderer and P. Clayton.
1992.
Iaims atcolumbia presbyterian medical center: Accom-plishments and challenges.
In Bull.
Am.
Med.Lib.
Assoc., pages 253-262.J.
Shaw.
1995.
Conciseness through aggregationin text generation.
In Proceedings of the 33rdA CL (Student Session), pages 329-331.M.
Steedman.
1996.
Representing discourse in-formationn for spoken dialogue generation.
InProceedings of ISSD 96, pages 89-92, Philadel-phia, PA.M.
Zhou and S. Feiner.
1997.
Top-down hier-archical planning of coherent visual discourse.In Proc.
IUI '97 (1997 Int.
Conf.
on IntelligentUser Interfaces), Orlando, FL, January 6-9.282
