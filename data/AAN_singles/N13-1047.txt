Proceedings of NAACL-HLT 2013, pages 445?449,Atlanta, Georgia, 9?14 June 2013. c?2013 Association for Computational LinguisticsBetter Twitter Summaries?Joel Judd & Jugal KalitaDepartment of Computer ScienceUniversity of ColoradoColorado Springs, ColoradoEmail: {jjudd2,jkalita}@uccs.eduAbstractThis paper describes an approach to improvesummaries for a collection of Twitter posts cre-ated using the Phrase Reinforcement (PR) Al-gorithm (Sharifi et al 2010a).
The PR algo-rithm often generates summaries with excesstext and noisy speech.
We parse these sum-maries using a dependency parser and use thedependencies to eliminate some of the excesstext and build better-formed summaries.
Wecompare the results to those obtained using thePR Algorithm.1 IntroductionMillions of people use the Web to express themselvesand share ideas.
Twitter is a very popular microblogging site.
According to a recent study approxi-mately 340 million Tweets are sent out every day1.People mostly upload daily routines, fun activitiesand other words of wisdom for readers.
There is alsoplenty of serious information beyond the personal;according to a study approximately 4% of posts onTwitter have relevant news data2.
Topics that maybe covered by reputable new sources like CNN (Ca-ble News Network) were considered relevant.
A topicis simply a keyword or key phrase that one may useto search for Twitter posts containing it.
It is pos-sible to gather large amounts of posts from Twitteron many different topics in short amounts of time.Obviously, processing all this information by humanhands is impossible.
One way to extract informationfrom Twitter posts on a certain topic is to automat-ically summarize them.
(Sharifi et al 2010a; Sharifiet al 2010b; Sharifi et al 2010c) present an al-gorithm called the Phrase Reinforcement Algorithmto produces summaries of a set of Twitter posts on1http://blog.twitter.com/2012/03/twitter-turns-six.htm2http://www.pearanalytics.com/blog/wp-content/uploads/2010/05/Twitter-Study-August-2009.pdfa certain topic.
The PR algorithm produces goodsummaries for many topics, but for sets of posts oncertain topics, the summaries become syntacticallymalformed or too wordy.
This is because the PRAlgorithm does not pay much attention to syntacticwell-formedness as it constructs a summary sentencefrom phrases that occur frequently in the posts itsummarizes.
In this paper, we attempt to improveTwitter summaries produced by the PR algorithm.2 The PR Algorithm RevisitedGiven a number of Twitter posts on a certain topic,the PR algorithm starts construction of what iscalled a word graph with a root node containing thetopic phrase.
It builds a graph showing how wordsoccur before and after the phrase in the root node,considering all the posts on the topic.
It builds asubgraph to the left of the topic phrase and anothersubgraph to its right in a similar manner.
To con-struct the left graph, the algorithm starts with theroot node and obtains the set of words that occurimmediately before the current node?s phrase.
Foreach of these unique words, the algorithm adds themto the graph as nodes with their associated countsto the left of the current node.
The algorithm con-tinues this process recursively for each node addedto the graph until all the potential words have beenadded to the left-hand side of the graph.
The al-gorithm repeats these steps symmetrically to con-struct the right subgraph.
Once the full graph isthere, the algorithm weights individual nodes.
Theweights are initialized to the same values as theirfrequency counts.
Then, to account for the fact thatsome phrases are naturally longer than others, theypenalize nodes that occur farther from the root nodeby an amount that is proportional to their distance.To generate a summary, the algorithm looks for themost overlapping phrases within the graph.
Sincethe nodes?
weights are proportional to their overlap,the algorithm searches for the path within the graph445with the highest cumulative weight.
The sequence ofwords in this path becomes the summary.3 Problem DescriptionWe start by making some observations on the phrase-reinforcement algorithm.
Certain topics do not pro-duce well-formed summaries, while others yield verygood summaries.
For the posts that have a well-centered topic without a huge amount of variationamong the posts, the algorithm works well and cre-ates good summaries.
Here is an example summaryproduced by the PR algorithm.Phillies defeat Dodgers to take the NationalLeague Championship series.
(Sharifi et al 2010a; Sharifi et al 2010b; Sharifiet al 2010c) provide additional examples.
The PRalgorithm limits the length of the summary to ap-proximately 140 characters, the maximum length ofa Twitter post.
However, often the summary sen-tence produced has extraneous parts that appear dueto the fact that they appear frequently in the postsbeing summarized, but these parts make the sum-mary malformed or too wordy.
An example withsome wordiness is given below.today is day for vote obama this election daySome ?raw?
PR summaries are a lot more wordythan the one above.
The goal we address in thispaper is to create grammatically better formed sum-maries by processing the ?raw?
summaries formed bythe PR Algorithm.
We drop this excess text and thephrases or extract pieces of text which make sensegrammatically to form the final summary.
This usu-ally produces a summary with more grammatical ac-curacy and less noise in between the words.
This getsthe main point of the summary across better.4 ApproachThe idea behind creating the desired summary isto parse the ?raw?
summary and build dependen-cies between the dependent and governor words ineach summary.
We perform parts of speech taggingand obtain lists of governing and dependent words.This data forms the basis for creating a valid sum-mary.
For example given the Twitter post, todayis day for vote obama this election day, a depen-dency parser produces the governor-dependent rela-tionships as given in Table 1.
Figure 1 also showsthe same grammatical dependencies between wordsin the phrases.We believe that a word which governs many wordsis key to the phrase as a whole, and dependent wordsTable 1: Governor and Dependent Words for today isday1 for vote obama this election day2Governor Dependentday1 todayisforday2obama votefor obamaday2 thiselectionAlgorithm 1 Algorithm to Fix ?Raw?
PRA Sum-mariesI.
For each word, check grammatical compatibil-ity with words before and after the word beingchecked.II.
If a word has no dependencies immediately be-fore or after it, drop the word.III.
After each word has been checked, check forthe words that form a grammatical phrase.IV.
Write out the summary without the droppedwords and without phrases with only two words.V.
If needed, go back to step III, because thereshouldn?t be any more single words with no de-pendencies to check, and repeat as many times asnecessary.which are closely related, or in other words, lay closeto each other in the phrase should be left in the or-der they appear.
Conceptually, our approach worksas follows: look at every word and see if it makessense with the word before and after it.
This buildsdependencies between the word in question with thewords around it.
If a word before or after the wordbeing analyzed does not make sense grammatically,it can be removed from that grammatically correctphrase.
Dependent words that are not close to eachother may not be as important as words that layclose to each other and have more dependencies, andthus may be thrown out of the summaries.
Throughthis process grammatically correct phrases can beformed.The dependencies are built by tagging each wordas a part of speech and seeing if it relates to otherwords.
For example, it checks whether or not theconjunction ?and?
is serving its purpose of combin-ing a set of words or ideas, in other words, if thosedependencies exist.
If dependencies exist with thenearby words, that given collection of words can beset aside as a grammatically correct phrase until itreaches words with no dependencies, and the process446Figure 1: Dependency Parse for today is day1 for vote obama this election day2today is day for vote obama this election daydepc o pp r e pnsubjpobjn ndetn ncan continue.
The phrases with few words can bedropped, as well as single words.
These new phrasescan be checked for grammatical accuracy in the sameway as the previous phrases, and if they pass, canremain combined forming a longer summary thatshould be grammatically correct.
The main stepsare given in Algorithm 1.Now, take the example summary produced by thePR Algorithm for the election Twitter posts.
Look-ing at this summary, we, as humans, may makechanges and make the summary grammatically cor-rect.
Two potential ideal summaries would be thefollowing.today is the day to vote for obamavote for obama this election dayThe actual process used in the making of the gram-matical summaries is as follows.
Two main lists arecreated from lists of governor and dependent words,one with the governor words and another with thedependent words.
The governor words are checkedto see how many dependent words are linked to them.The governing words with the highest number of de-pendent words are kept for later.
For example usingthe above phrase about the elections, the word ?day?was the governing word with the highest amount ofdependent words and was thus kept for the final sum-mary.
The superscripts on the word ?day?
differen-tiate its two occurrences.
The dependent words arekept in groups of closely linked dependent words.Using the same example about the election, an in-termediate list of closely related dependent words is?today,?
?is,?
?for,?
?vote,?
?obama,?
?this,?
?elec-tion,?
and ?day.?
And the final list of closely relateddependent words is ?for,?
?vote,?
?obama,?
?this,??election?
and ?day.?
After these two lists are in thefinal stages the lists are merged placing the words inproper order.5 Experiments and ResultsTo begin, the Twitter posts were collected manu-ally and stored in text files.
The topics we chose toTable 2: ROUGE-L without Stopwords, BeforeTask Recall Precision F-scoreTask 1 0.667 0.343 0.453Task 2 1.000 0.227 0.370Task 3 0.353 0.240 0.286Task 4 0.800 0.154 0.258Task 5 1.000 0.185 0.313Task 6 0.667 0.150 0.245Task 7 0.889 0.125 0.219Task 8 0.636 0.125 0.209Task 9 0.500 0.300 0.375Task 10 0.455 0.100 0.164Average 0.696 0.195 0.289focus on important current events and some pop cul-ture.
Approximately 100 posts were collected on tendifferent topics.
These topics are ?The Avengers,?
?Avril Lavigne,?
?Christmas,?
?the election,?
?Elec-tion Day,?
?Iron Man 3,?
?president 2012,?
?Hurri-cane Sandy,?
?Thanksgiving,?
and ?vote.
?The collections of posts were passed on to threevolunteers to produce short accurate summaries thatcapture the main idea from the posts.
The collectionsof posts were also first run through the PR Algorithmand then through the process described in this paperto try and refine the summaries output by the PRAlgorithm.
The Stanford CoreNLP parser3 was usedto build the lists of governor and dependent words.We use ROUGE evaluation metrics (Lin 2004)just like (Sharifi et al 2010a; Sharifi et al 2010b;Sharifi et al 2010c), who evaluated summaries ob-tained with the PR Algorithm.
Specifically, we useROUGE-L, which uses the longest common subse-quence (LCS) to compare summaries.
As the LCS ofthe two summaries in comparison increases in length,so does the similarity of the two summaries.We now discuss results using ROUGE-L on thesummaries we produce.
Tables 2 through 5 showthe results of four different ROUGE-L evaluations,comparing them to the results found using the PR3http://nlp.stanford.edu/software/corenlp.shtml447Table 3: ROUGE-L without Stopwords, AfterTask Recall Precision F-scoreTask 1 0.667 0.480 0.558Task 2 0.400 0.500 0.444Task 3 0.000 0.000 0.000Task 4 0.400 0.333 0.363Task 5 0.900 0.600 0.720Task 6 0.389 0.350 0.368Task 7 0.556 0.250 0.345Task 8 0.545 0.500 0.522Task 9 0.417 0.417 0.417Task 10 0.363 0.200 0.258Average 0.464 0.363 0.400Algorithm, and Table 6 shows the comparisons of theaveraged scores to the scores (Sharifi et al 2010a)obtained using the PR Algorithm.
Table 2 shows theregular ROUGE-L scores, meaning the recall, pre-cision and F-scores for each task and the averageoverall scores, for the collection of posts before usingthe dependency parser to refine the summaries.
Ta-ble 3 displays the results after using the dependencyparser on the summaries formed by the PR Algo-rithm.
One of the options in ROUGE is to show the?best?
result, for each task.
Table 4 has this resultfor the PR Algorithm results.
Table 5 shows the re-sults of the ?best?
scores, after running it throughthe dependency parser.
Table 6 shows the averagesfrom Tables 3 and 5, using the dependency parser,compared to Sharifi et als results using the PR Al-gorithm.
Stopwords were not removed in our exper-iments.Table 4: ROUGE-L Best without Stopwords, BeforeRecall Precision F-scoreTask 1 1.000 0.429 0.600Task 2 1.000 0.227 0.370Task 3 0.500 0.200 0.286Task 4 1.000 0.154 0.267Task 5 1.000 0.167 0.286Task 6 1.000 0.200 0.333Task 7 1.000 0.125 0.222Task 8 1.000 0.071 0.133Task 9 1.000 0.400 0.571Task 10 1.000 0.100 0.182Average 0.950 0.207 0.325As one can see, the use of our algorithm on thesummaries produced by the PR Algorithm improvesthe F-score values, at least in the example cases wetried.
In almost every case, there is substantial risein the F-score.
As previously mentioned, some col-Table 5: ROUGE-L Best without Stopwords, AfterRecall Precision F-scoreTask 1 1.000 0.600 0.750Task 2 0.400 0.500 0.444Task 3 0.000 0.000 0.000Task 4 0.500 0.333 0.400Task 5 1.000 0.600 0.750Task 6 0.600 0.600 0.600Task 7 0.667 0.400 0.500Task 8 1.000 0.333 0.500Task 9 1.000 0.667 0.800Task 10 1.000 0.250 0.400Average 0.718 0.428 0.515Table 6: ROUGE-L Averages after applying our algo-rithm vs. Sharifi et alRecall Precision F-scoreSharifi (PRA) 0.31 0.34 0.33Rouge-L after re-construction0.46 0.36 0.40Rouge-L best afterreconstruction0.72 0.43 0.52lections of Tweets do not produce good summaries.Task 3 had some poor scores in all cases, so one candeduce that the posts on that topic (Christmas) werewidely spread, or they did not have a central theme.6 ConclusionThe PR Algorithm is not a pure extractive algo-rithm.
It creates summaries of Twitter posts by piec-ing together the most commonly occurring words andphrases in the entire set of tweets, but keeping theorder of constituents as close to the order in whichthey occur in the posts, collectively speaking.
Aswe noted in this paper, the heuristic method usingwhich the PR Algorithm composes a summary sen-tence out of the phrases sometimes leads to ungram-matical sentences or wordy sentences.
This papershows that the ?raw?
summaries produced by thePR Algorithm can be improved by taking into ac-count governor-dependency relationships among theconstituents.
There is nothing in this clean-up algo-rithm that says that it works only with summaries oftweets.
The same approach can potentially be usedto improve grammaticality of sentences written byhumans in a sloppy manner.
In addition, given sev-eral sentences with overlapping content (from mul-tiple sources), the same process can potentially beused to construct a grammatical sentence out of allthe input sentences.
This problem often arises ingeneral multi-document summarization.
We believe448that a corrective approach like ours can be used to-gether with a sentence compression approach, suchas (Knight and Marcu 2002), to produce even bet-ter summaries in conjunction with the PR or othersummarization algorithms that work with socially-generated texts which are often malformed and short.We have shown in this paper that simply focusingon grammatical dependency tends to make the fi-nal summaries more grammatical and readable com-pared to the raw summaries.
However, we believethat more complex restructuring of the words andconstituents would be necessary to improve the qual-ity of the raw summaries, in general.ReferencesKnight, K. and Marcu, D. 2004.
Summarization beyondsentence extraction: A probabilistic approach to sen-tence compression, Artificial Intelligence, Vol.
139, No.1, pp.
91?107.Lin, C.Y.
2004.
Rouge: A package for automatic evalua-tion of summaries, Text Summarization Branches Out:Proceedings of the ACL-04 Workshop, pp.
74?81.Sharifi, Beaux, Mark-Anthony Hutton, and Jugal Kalita.2010.
Summarizing Microblogs Automatically, AnnualConference of the National Association for Advance-ment of Computational Linguistics-Human LanguageTechnology (NAACL-HLT), pp.
685-688, Los Angeles.Sharifi, Beaux, Mark-Anthony Hutton, and Jugal Kalita.2010.
Experiments in Microblog Summarization, Sec-ond IEEE International Conference on Social Comput-ing (SocialCom 2010), pp.
49-56, Minneapolis.Sharifi, Beaux, Mark-Anthony Hutton and Jugal Kalita.2010.
Automatic Summarization of Twitter Topics,National Workshop on Design and Analysis of Algo-rithms, NWDAA 10, Tezpur University, Assam, India.449
