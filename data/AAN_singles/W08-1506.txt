Coling 2008: Proceedings of the workshop on Speech Processing for Safety Critical Translation and Pervasive Applications, pages 32?35Manchester, August 2008The 2008 MedSLT SystemManny Rayner1, Pierrette Bouillon1, Jane Brotanek2, Glenn Flores2Sonia Halimi1, Beth Ann Hockey3, Hitoshi Isahara4, Kyoko Kanzaki4Elisabeth Kron5, Yukie Nakao6, Marianne Santaholma1Marianne Starlander1, Nikos Tsourakis11 University of Geneva, TIM/ISSCO, 40 bvd du Pont-d?Arve, CH-1211 Geneva 4, Switzerland{Emmanuel.Rayner,Pierrette.Bouillon,Nikolaos.Tsourakis}@issco.unige.ch{Sonia.Halimi,Marianne.Santaholma,Marianne.Starlander}@eti.unige.ch2 UT Southwestern Medical Center, Children?s Medical Center of Dallas{Glenn.Flores,Jane.Brotanek}@utsouthwestern.edu3 Mail Stop 19-26, UCSC UARC, NASA Ames Research Center, Moffett Field, CA 94035?1000bahockey@ucsc.edu4 NICT, 3-5 Hikaridai, Seika-cho, Soraku-gun, Kyoto, Japan 619-0289{isahara,kanzaki}@nict.go.jp5 3 St Margarets Road, Cambridge CB3 0LT, Englandelisabethkron@yahoo.co.uk6 University of Nantes, LINA, 2, rue de la Houssinie`re, BP 92208 44322 Nantes Cedex 03yukie.nakao@univ-nantes.frAbstractMedSLT is a grammar-based medicalspeech translation system intended foruse in doctor-patient diagnosis dialogues,which provides coverage of several dif-ferent subdomains and multiple languagepairs.
Vocabulary ranges from about 350 to1000 surface words, depending on the lan-guage and subdomain.
We will demo threedifferent versions of the system: an any-to-any multilingual version involving thelanguages Japanese, English, French andArabic, a bidirectional English ?
Span-ish version, and a mobile version run-ning on a hand-held PDA.
We will alsodemo the Regulus development environ-ment, focussing on features which sup-port rapid prototyping of grammar-basedspeech translation systems.c?
2008.
Licensed under the Creative CommonsAttribution-Noncommercial-Share Alike 3.0 Unported li-cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).Some rights reserved.1 IntroductionMedSLT is a medium-vocabulary grammar-basedmedical speech translation system built on top ofthe Regulus platform (Rayner et al, 2006).
It isintended for use in doctor-patient diagnosis dia-logues, and provides coverage of several subdo-mains and a large number of different language-pairs.
Coverage is based on standard examina-tion questions obtained from physicians, and fo-cusses primarily on yes/no questions, though thereis also support for WH-questions and elliptical ut-terances.Detailed descriptions of MedSLT can be foundin earlier papers (Bouillon et al, 2005; Bouil-lon et al, 2008)1.
In the rest of this note, wewill briefly sketch several versions of the systemthat we intend to demo at the workshop, each ofwhich displays new features developed over thelast year.
Section 2 describes an any-language-to-any-language multilingual version of the system;Section 3, a bidirectional English ?
Spanish ver-sion; Section 4, a version running on a mobile PDA1All MedSLT publications are available on-lineat http://www.issco.unige.ch/projects/medslt/publications.shtml.32platform; and Section 5, the Regulus developmentenvironment.2 A multilingual versionDuring the last few months, we have reorganisedthe MedSLT translation model in several ways2.
Inparticular, we give a much more central role to theinterlingua; we now treat this as a language in itsown right, defined by a normal Regulus grammar,and using a syntax which essentially amounts toa greatly simplified form of English.
Making theinterlingua into another language has made it easyto enforce tight constraints on well-formedness ofinterlingual semantic expressions, since checkingwell-formedness now just amounts to performinggeneration using the interlingua grammar.Another major advantage of the scheme is thatit is also possible to systematise multilingual de-velopment, and only work with translation fromsource language to interlingua, and from interlin-gua to target language; here, the important pointis that the human-readable interlingua surface syn-tax makes it feasible in practice to evaluate transla-tion between normal languages and the interlingua.Development of rules for translation to interlinguais based on appropriate corpora for each sourcelanguage.
Development of rules for translatingfrom interlingua uses a corpus which is formed bymerging together the results of translating each ofthe individual source-language corpora into inter-lingua.We will demonstrate our new capabilities ininterlingua-based translation, using a version ofthe system which translates doctor questions in theheadache domain from any language to any lan-guage in the set {English, French, Japanese, Ara-bic}.
Table 1 gives examples of the coverage of theEnglish-input headache-domain version, and Ta-ble 2 summarises recognition performance in thisdomain for the three input languages where wehave so far performed serious evaluations.
Differ-ences in the sizes of the recognition vocabulariesare primarily due to differences in use of inflec-tion.3 A bidirectional versionThe system from the preceding section is unidi-rectional; all communication is in the doctor-to-patient direction, the expectation being that the pa-2The ideas in the section are described at greater length in(Bouillon et al, 2008).Language Vocab WER SemEREnglish 447 6% 11%French 1025 8% 10%Japanese 422 3% 4%Table 2: Recognition performance for English,French and Japanese headache-domain recognis-ers.
?Vocab?
= number of surface words in sourcelanguage recogniser vocabulary; ?WER?
= WordError Rate for source language recogniser, on in-coverage material; ?SemER?
= semantic error ratefor source language recogniser, on in-coveragematerial.tient will respond non-verbally.
Our second demo,an early version of which is described in (Bouillonet al, 2007), supports bidirectional translation forthe sore throat domain, in the English ?
Spanishpair.
Here, the English-speaking doctor typicallyasks WH-questions, and the Spanish-speaking pa-tient responds with elliptical utterances, which aretranslated as full sentence responses.
A short ex-ample dialogue is shown in Table 3.Doctor: Where is the pain?
?Do?nde le duele?Patient: En la garganta.I experience the pain in my throat.Doctor: How long have you had a painin your throat?
?Desde cua?ndo le duele la garganta?Patient: Ma?s de tres d?
?as.I have experienced the pain in mythroat for more than three days.Table 3: Short dialogue with bidirectional English?
Spanish version.
System translations are in ital-ics.4 A mobile platform versionWhen we have shown MedSLT to medical profes-sionals, one of the most common complaints hasbeen that a laptop is not an ideal platform for usein emergency medical situations.
Our third demoshows an experimental version of the system us-ing a client/server architecture.
The client, whichcontains the user interface, runs on a Nokia LinuxN800 Internet Tablet; most of the heavy process-ing, including in particular speech recognition, ishosted on the remote server, with the nodes com-municating over a wireless network.
A picture of33Where?
Is the pain above your eye?When?
Have you had the pain for more than a month?How long?
Does the pain typically last a few minutes?How often?
Do you get headaches several times a week?How?
Is it a stabbing pain?Associated symptoms?
Do you vomit when you get the headaches?Why?
Does bright light make the pain worse?What helps?
Does sleep make the pain better?Background?
Do you have a history of sinus disease?Table 1: Examples of English MedSLT coveragethe tablet, showing the user interface, is presentedin Figure 1.
The sentences appearing under theback-translation at the top are produced by an on-line help component, and are intended to guide theuser into the grammar?s coverage (Chatzichrisafiset al, 2006).The architecture is described further in(Tsourakis et al, 2008), which also gives perfor-mance results for another Regulus applications.These strongly suggest that recognition perfor-mance in the client/server environment is noworse than on a laptop, as long as a comparablemicrophone is used.5 The development environmentOur final demo highlights the new Regulus devel-opment environment (Kron et al, 2007), which hasover the last few months acquired a large amountof new functionality designed to facilitate rapidprototyping of spoken language applications3 .
Thedeveloper initially constructs and debugs her com-ponents (grammar, translation rules etc) in a textview.
As soon as they are consistent, she is ableto compile the source-language grammar into arecogniser, and combine this with other compo-nents to run a complete speech translation systemwithin the development environment.
Connectionsbetween components are defined by a simple con-fig file.
Figure 2 shows an example.ReferencesBouillon, P., M. Rayner, N. Chatzichrisafis, B.A.Hockey, M. Santaholma, M. Starlander, Y. Nakao,K.
Kanzaki, and H. Isahara.
2005.
A generic multi-lingual open source platform for limited-domainmedical speech translation.
In Proceedings of the10th Conference of the European Association for3This work is presented in a paper currently under review.Machine Translation (EAMT), pages 50?58, Bu-dapest, Hungary.Bouillon, P., G. Flores, M. Starlander,N.
Chatzichrisafis, M. Santaholma, N. Tsourakis,M.
Rayner, and B.A.
Hockey.
2007.
A bidirectionalgrammar-based medical speech translator.
In Pro-ceedings of the ACL Workshop on Grammar-basedApproaches to Spoken Language Processing, pages41?48, Prague, Czech Republic.Bouillon, P., S. Halimi, Y. Nakao, K. Kanzaki, H. Isa-hara, N. Tsourakis, M. Starlander, B.A.
Hockey, andM.
Rayner.
2008.
Developing non-european trans-lation pairs in a medium-vocabulary medical speechtranslation system.
In Proceedings of LREC 2008,Marrakesh, Morocco.Chatzichrisafis, N., P. Bouillon, M. Rayner, M. Santa-holma, M. Starlander, and B.A.
Hockey.
2006.
Eval-uating task performance for a unidirectional con-trolled language medical speech translation system.In Proceedings of the HLT-NAACL InternationalWorkshop on Medical Speech Translation, pages 9?16, New York.Kron, E., M. Rayner, P. Bouillon, and M. Santa-holma.
2007.
A development environment for build-ing grammar-based speech-enabled applications.
InProceedings of the ACL Workshop on Grammar-based Approaches to Spoken Language Processing,pages 49?52, Prague, Czech Republic.Rayner, M., B.A.
Hockey, and P. Bouillon.
2006.Putting Linguistics into Speech Recognition: TheRegulus Grammar Compiler.
CSLI Press, Chicago.Tsourakis, N., M. Georghescul, P. Bouillon, andM.
Rayner.
2008.
Building mobile spoken dialogueapplications using regulus.
In Proceedings of LREC2008, Marrakesh, Morocco.34Figure 1: Mobile version of the MedSLT system, running on a Nokia tablet.Figure 2: Speech to speech translation from the development environment, using a Japanese to Arabictranslator built from MedSLT components.
The user presses the Recognise button (top right), speaks inJapanese, and receives a spoken translation in Arabic together with screen display of various processingresults.
The application is defined by a config file which combines a Japanese recogniser and analy-sis grammar, Japanese to Interlingua and Interlingua to Arabic translation rules, an Arabic generationgrammar, and recorded Arabic wavfiles used to construct a spoken result.35
