Model-based Analysis of Messages about EquipmentRalph Grishman, Tomasz Ksiezyk, and Ngo Thanh NhanDepartment of Computer ScienceCourant Institute of Mathematical SciencesNew York UniversityABSTRACTThe aim of PROTEUS -- a system for the analysis of short technical texts -- is to increase thereliability of the analysis process through the integration of syntactic and semanticconstraints, domain knowledge, and knowledge of discourse structure.
This system isinitially being applied to the analysis of messages describing the failure, diagnosis, and repairof selected pieces of equipment.
This has required us to develop a detailed model of thestructure and function of the equipment involved.
We focus in this paper on the nature ofthis model and the roles it plays in the syntactic and semantic analysis of the text.73I .
In t roduct ionConsiderable progress has been made in developing systems which understand shortpassages of technical text.
Several prototypes have been developed,  for such domains aspatient medical records \[Sager 1978\], equipment failure reports \[Marsh 1984\], andintelligence messages \ [Montgomery 1983\].
Except for very narrow domains such as weatherreports,  however,  none of these systems seem tO be robust enough for operational use.Typical success rates - where any are reported - are in the range of 70 to 80% of sentencescorrectly analyzed; substantially better rates are very hard to obtain,  even with careful systemtuning'.Our objective in developing PROTEUS (the PROtotype  TExt  Understanding System) isto see if this rate can be substantially improved for a domain of moderate complexity.
Inorder to achieve this improvement ,  we must bring to bear on the language analysis task thevarious syntactic, semantic, and discourse constraints, along with a fairly detailed knowledgeof the domain of discourse.
Our system is initially being applied to equipment failure reports( "CASREPs")  for selected equipment on board Navy ships (initially, the equipment in thestarting air system); a sample message is shown in Figure 1.
In this case, the domainknowledge is the knowledge of the structure and function of these pieces of equipment.In this paper we first present an overview of the PROTEUS system.
We then focus onthe domain information: how it is represented,  how it is integrated with the languageprocessing, and how it serves to resolve ambiguities in the input text.2.
Pr ior  workNew York University has been involved in the automated analysis and structuring oftechnical text for over  a decade.
Most of this work has been on medical records \[Sager 1978,Hirschman 1982\], but we have also been involved with the Naval Research Laboratory on asystem for CASREP 's  \[Marsh 1984\].
These systems used domain-specif ic frame-l ike targetstructures, and employed selectional constraints to weed out bad parses, but did notincorporate detailed domain models.
Our experience with these systems - in particular, thedifficulty of obtaining success rates (% of sentences correctly analyzed) much above 75% -led us to our work on PROTEUS.The use of detailed domain models in language processing systems is, of course, notnew.
Script-based systems, and some of the f rame-based language analysis systems, havebeen motivated by a desire to incorporate detailed domain knowledge.
The task we confront ,however,  differs in several regards from those of earl ier systems.
One is the matter of scale;our initial set of equipment - the starting air system for a gas turbine - includes severalhundred separately nameable components (and many lesser components ,  such as bolts andDURING NORMAL START CYCLE OF 1A GAS TURBINE,  APPROX 90 SECAFTER CLUTCH ENGAGEMENT,  LOW LUBE OIL  AND FA IL  TO ENGAGEALARM WERE RECEIVED ON THE ACC.
(ALL  CONDIT IONS WERENORMAL IN IT IALLY) .
SAC WAS REMOVED AND METAL  CHUNKSFOUND IN OIL  PAN.
LUBE OIL  PUMP WAS REMOVED AND WAS FOUNDTO BE SE IZED.
DRIVEN GEAR WAS SHEARED ON PUMP SHAFT.Figure 1.
A sample CASREP about a starting air compressor  (SAC).
:: ~Substantially better rates have been cited for strongly expectation-based parsers, which are consideredsuccessful if they locate all the expected items within an input text.74gear teeth, without specific names).
While not raising any intrinsic difficulties, a domain ofthis size clearly provides a more rigorous test of our ability to acquire and organize domainknowledge than did many earlier "toy" domains.Another unusual aspect is the nature of the domain information.
Scripts, for example,encode essentially procedural information (how to perform complex actions).
Theinformation for our domain, in contrast, is primarily structural (part-whole relationships,interconnections, etc.)
and to a lesser degree functional.
This difference is reflected indifferences in the way the information is used - in particular, in-the analysis of noun phrases,as we shall see below.
Our domain information bears greater resemblance to that used insome equipment simulation packages (e.g., STEAMER \[Honan 1984\]) and diagnosispackages \[Cantone 1983\] than it does to that conventionally seen in natural language systems.The domain knowledge plays a role in many phases of the language processing task: inthe recovery of implicit operands and intersentential relations, in the analysis of noun-phrasereference, and in the determination of syntactic and semantic structure.
In particular, weshall consider below its role in the processing of compound nominals, which appearfrequently in such technical domains.
There have been several prior studies of the processingof such compounds.
The work both of Brachman \[1978\] and of McDonald and Hayes-Roth\[McDonald 1978\] emphasized the use of search procedures within semantic networks toidentify the wide variety of implicit relations possible with compound nominals.
We havealso used network search techniques, although of a more directed sort.
However ,  their workcited isolated examples from a variety of areas to show the generality of their approach,while we have been concerned with achieving detailed and thorough coverage within anarrower domain.
Finin \[1980, 1986\] has sought to develop, within a sublanguage, generalsemantic ategories for the relations and consituents involved in compounds.
Although thereare some similarities to our classification efforts, he also has aimed at providing a relativelybroad and loose set of constraints.
In contrast, the detailed knowledge in our equipmentmodel -- provided for several purposes, of which noun phrase interpretation is only one --make possible much tighter constraints in our system.3.
System overviewThe PROTEUS system has three major components:  a syntactic analyzer, a semanticanalyzer, and a discourse analyzer.
The syntactic analyzer parses the input and regularizesthe clausal syntactic structure.
The semantic analyzer converts this to a "logical form"specifying states and actions with reference to specific components of the equipment.
Thediscourse component establishes temporal and causal links between these states and actions.Initial implementations have been completed of the syntactic and semantic omponents,so that we are able to generate semantic representations of individual sentences.
Thediscourse component is still under development,  and so will not be discussed further here.The syntactic analyzer uses an augmented-context-free grammar and an.
active chartparser.
The grammar is generally based on linguistic string theory and the Linguistic StringProject English Grammar \[Sager 1981\] and includes extensions to handle the various sentencefragment forms found in these messages \[Marsh 1983\]; it is written in a modif ied form of theRestriction Language used by the NYU Linguistic String Parser \[Sager 1975\].
Syntacticregularization maps the various forms of clauses (active, passive, relative, reduced relative,fragmentary) into a canonical form (verb operandi, operand2...) The regularization isperformed by a set of interpretation rules which are associated with the individualproductions and which build the regularized syntactic structure compositionally.
2z The parser and syntactic regularization procedures were developed by Jean Mark Gawron.
Theregtllarization procedures were modeled after those developed for a GPSG parser \[Gawron 1982\], although thegenerated structures are quite different.75The semantic analysis component consists of two parts: clause semantics and noun phrasesemantics.
The clause semantics maps a clause (a verb plus operands which include syntacticcase labels) into a predicate auith arguments representing a state or action.
Each verb andoperand belongs to one or more semantic lasses.
Clause semantics relys on a set of pattern-action rules to perform the translation, with one pattern for each valid combination of verband operand classes.
Noun phrase semantics maps a noun phrase into the identifier of theequipment component specified by that phrase.
Noun phrase semantics depends heavily onthe equipment model, and so will be discussed further in a later section.
(The division between the two parts of semantic analysis is not quite so neat as theforegoing would suggest.
Some noun phrases are nominalizations representing states oractions; these are processed by clause semantics.
In many noun phrases, some modifiersidentify the object and the remainder describe its state.
For example, in "broken hub ringgear", hub and ring identify the gear, broken describes its state.
We return to this problem inour description of noun phrase semantics below.
)Our long-term objective is to dynamically schedule among the three analysiscomponents (syntax, semantics, and discourse), as is done in some blackboard models.
Forprogram development, however, we have found it better to use a sequential organization(first syntax, then semantics, then discourse).
In order to have syntactic hoices influencedby semantics and discourse, and semantic choices influenced by discourse, each componentmay generate multiple analyses, some of which are rejected by later stages.
Sometime thesemultiple analyses are transmitted explicitly, as a list of alternatives.
More often, however,they are transmitted using a representation neutral with respect to particular features.
Theoutput of syntactic analysis is neutral with respect o quantif ier scope.
It is also neutral withrespect to the distribution of modifiers in conjoined noun phrases (for example, in "filterchange and adjustment of pressure regulator," whether filter modifies adjustment and ofpressure regulator modifies change).
Furthermore,  it does not assign structure to prenominaladjectives and nouns (so for example, in the phrase "low lube oil pressure alarm" it does notdecide whether low modifies lube, oil, pressure, or alarm).This system development has been conducted in close Cooperation with a group at theSystem Development Corp., Paoli, PA. Their  system, PUNDIT  \[Palmer 1986\], is written inPROLOG but has many points of commonality with PROTEUS in terms of overall structure,grammar,  and semantic representation.
They are involved in future development of severalareas, including semantic representation, time analysis, and anaphora resolution, for both thePUNDIT  and PROTEUS systems.4.
The equipment modelThe equipment model currently serves three functions within our system:object identification.
The noun phrases in the message are matched against the model (by aprocedure outlined in the next section) in order to identify the objects referenced in themessage.
This is important both for syntactic disambiguation and as a prelude to applyingdomain-specific nferences.identification of intersentential relations.
The identification of these relations (temporal,causal, and others) is important both for disambiguation (of adjuncts and anaphoricreferences, in particular) and for establishing the meaning of the message as a whole.
Muchof the information needed for this process - information on the structure of the equipmentand the function of its components - is recorded in the equipment model.display of equipment structure and status.
In order to provide some feedback to indicatewhether the text was correctly understood, our system displays a structural diagram of theequipment at several levels of detail.
Objects mentioned in the text, and changes in76equipment status described in the message, can be shown on the display.
The informationfor generating these displays (positions, shapes, etc.)
is stored with the equipment model.The messages refer to relatively low-level components,  such as individual gears within the aircompressor.
We therefore had to constuct a relatively detailed model of the equipmentinvolved.
Our model has been developed through a study of the Navy manuals for thisequipment.The model is basically organized as two hierarchies: a type-instance hierarchy and apart-whole hierarchy.
The leaves of the part-whole hierarchy are called basic parts; theinternal nodes (composite objects) are called systems.
We record for each system the primarymedium which it provides, conveys, or transforms; in our starting air system, the three mediaare compressed air, lubricating oil, and mechanical rotation.
We have organized our part-whole hierarchy in part along functional lines (rather than purely on physical proximity),grouping together parts which are connected together and operate on the same medium.Since some parts are identified by their physical location, we provide a location field inboth basic part and system nodes.
Both types of nodes also have a function field, whichindicates the effect of this part on the media or other parts.
Nodes of specific types mayhave additional fields; for example, some mechanical components have a speed field.All of the fields just mentioned record permanent characteristics of the parts.
Inaddition, each node has an operational-status field, which holds information about a partwhich is reported in a message.The model contains a lot of information about equipment structure which is specific to aparticular piece of equipment.
Some information, however, is more general: for example,that gears have teeth,or that impellors have blades.
It would be most uneconomic to have aseparate instance of tooth for each gear in the model.
Instead we create an instance of theteeth for a specific gear when it is referenced in the text.
Such very-low-level objects, whichare instantiated ynamically as needed, are called components.The equipment model has been implemented using flavors on a Symbolics LISPMachine.
Types of objects are represented by flavors; instances of objects are represented byinstances of flavors.
The part-whole hierarchy and other fields are stored in instancevariables.
The structure display is performed by procedures associated with the flavors.
Theequipment model, and its use in the system, are described in more detail in \[Ksiezyk 1986\].5.
Noun phrase analysisThe syntactic analysis component analyzes the clause structure and delimits the nounphrases, but does not assign any structure to the pre-nominal modifiers.
The noun phraseanalyzer within the semantic omponent therefore has a dual role: to determine the structureof the pre-nominal modifiers and to identify the instance in the equipment model named bythe noun phrase (or the set of instances, if this phrase could be applied to any of severalparts).
(Although there are a limited number of instances, it is not possible to record a singlename for each part and then interpret noun phrases by simply looking the name up in a table.A single part can be named in many different ways -- depending in part on prior context -- soa full-fledged interpretation procedure is required.
)The noun phrase is analyzed bottom-up using a set of reduction rules.
Each reductionrule combines the head of a phrase with some of its modifiers to form a larger constituent.By reference to the model, each rule also determines the set of instances which can be namedby the constituent; if the set is empty, the application of the rule is rejected.
Reductions areperformed repeatedly until the entire phrase is reduced to a single constituent.
If no suchreduction is possible, the syntactic analysis is rejected; in this way noun phrase semantics canweed out some incorrect syntactic analyses.77The applicable reductions are determined by the dictionary entries for the words in thenoun phrase.
Each word is assigned two propert ies,  its model class and its semantic class.The model class indicates how the word can be related to some entity in the domain model.One value of model class is instance, specifying that the word names a set of instances in themodel;  this set is also included in the dictionary entry.
Examples are "pump",  "shaft","gear",  etc.
Larger constituents built while analyzing the noun phrase are also considered tobe of type instance.
One reduction rule allows us to combine two instances:instance ~- ins tance-  instancefor example,  "LO" + "PUMP" - "LO PUMP",  "SAC" + ("LO PUMP")  - "SAC LOPUMP".
The set of model instances for the result consists of those instances of the secondconstituent which can be linked through some path in the model to some instance of the firstconstituent.
The types of links traversed in the search are a function of the semantic class of-the first constituent; for example,  "SAC" has the semantic class machinery, so we search thepart/whole links, the location links, and the from/to links (which tie together components  ofthe same system).There are several other model classes and corresponding reduction rules.
The classslot-filler is used for words which are values of features of instances, but are not themselvesinstances (for example,  "LUBE" in the phrase "LUBE OIL") .
The class slot-name is used forwords which correspond to feature names,  such as "SPEED" in "H IGH SPEEDASSEMBLY".
The class component is used for parts which (as explained in the previoussection) are not instantiated in the permanent  equipment model but can be instantiateddynamical ly as needed.Modifiers describing the state of a part, such as "cracked" or "sheared",  are handleddifferently.
If noun phrase semantics gets the input "sheared ring gear" it will look for aninstance of ring gear with the operational-state "sheared".
Such an instance would be presentif a previous sentence had mentioned that a gear was sheared.
If  such an instance is found, itis identified as the correct referent; noun phrase semantics has in effect done anaphoraresolution.
If no instance is found, noun phrase semantics returns the instances of "ringgear" and the left-over modif ier "sheared".
Clause semantics (which invokes noun phrasesemantics) then treats this like a clause "ring gear was sheared"; later in the processing of thissentence, this will cause "sheared" to be assigned as the operational-state of ring gear.A related technique can be used to handle some of the ambiguit ies in cojoined nounphrases.
For example,  in the sentence ' . '
INVEST IGAT ION REVEALED STRIPPED LOPUMP DRIVE  AND HUB R ING GEAR" ,  syntax alone cannot determine which of themodif iers "STRIPPED" ,  "LO", "PUMP",  or "DRIVE"  also modify "HUB R ING GEAR" .
Sosyntax marks these as possibly applicable to "HUB R ING GEAR"  and passes the phrase tosemantics.
If semantics finds that some of these modif iers cannot be integrated into the nounphrase, they will be ignored, thus implicitly resolving the syntactic ambiguity.6.
ConclusionWe have described a new text-processing system, PROTEUS,  for analyzing messagesabout  equipment failure.
We have focussed on its equipment model  and the role of thismodel  in the process of interpreting of noun phrases.
This process is part of semanticanalysis but also plays a role in syntactic analysis and discourse analysis.In addition to the elaboration of the existing components,  substantial work will berequired in at least two areas before we can hope to obtain a robust text processing system.First, we are developing a discourse component  to identify temporal  and plausible causallinks between sentences.
This information is needed not only for some of the applications(e~g., message summarizat ion) but also to resolve some of the syntactic and semanticambiguities in the messages.
Second, we will need to move from a pass/fail strategy forenforcing our constraints to a best-fit strategy.
Because of imperfect ions in the input, and the78inevitable omissions in a model as complex as ours, we must expect that many messages willviolate one or another constraint; by employing a rich set of constraints, however,  andselecting the analysis which violates the fewest constraints, we beleive that we will be able toidentify the intended reading for most sentences.The initial motivation for the system has been the conversion of a stream of messages toa data base for subsequent querying, summarizat ion,  and trend analysis.
However ,  the useof a detailed equipment model,  similar to that employed in simulation and diagnosticsystems, suggests that it may be equally useful as an interface for such systems.
A diagnosticsystem, for example,  would then be able to accept initial observations in the form of a brieftextual summary rather than force the user to go through an elaborate questionnaire; thismay be a substantial advantage for broad-coverage diagnostic systems, which must be able toaccept a wide variety of d i f ferent symptoms.AcknowledgementThis research was supported in part by the Defense Advanced Research ProjectsAgency under contract N00014-85-K-0163 from the office of Naval Research, and by theNational Science Foundation under grant DCR-85-01843.79REFERENCES\[Brachman 19781 Brach6aan, R. A.
A structured paradigm for representing knowledge.Tech.
Rep. No.
3605, Bolt Beranek and Newman Inc., Cambridge, MA.\[Cantone 1983\] Cantone, R., Pipitone, F., Lander, W. B., and Marrone, M. Model-based probabilistic reasoning for electronics troubleshooting.
Proc.
Eighth Intl.
Joint Conf.Artificial Intelligence, Karlsruhe, West Germany.\[Finin 1980\] Finin, T. The semantic interpretation f compound nominals.
Proc.
FirstNational Conf.
on Artificial Intelligence.
Stanford, CA., Am.
Assn.
of Artificial Intelligence.\[Finin 1986\] Finin, T. Nominal compounds in a limited context.
In Analyzing Languagein Restricted Domains, R. Grishman and R. Kittredge, Eds.
Lawrence Erlbaum Assoc.,Hillsdale,'NJ.\[Gawron 1982\] Gawron, J. M., King, J. J., Lamping, J., Loebner, E. E., Paulson, E.A., Pullum, G. K., Sag, I.
A., and Wasow, T. A.
Processing English with a generalizedphrase structure grammar.
Proc.
20th Annual Meeting Assn.
Computational Linguistics,Toronto, Canada.\[Hirschman 1982\] Hirschman, L., and Sager, N. Automatic information formatting of amedical sublanguage.
In Sublanguage: Studies of Language in Restricted Domains, R.Kittredge and J. Lehrberger, Eds.
Walter de Gruyter, Berlin.\[Hollan 1984\] Hollan, J., Hutchins, E., and Weitzman, L. STEAMER: an interactiveinspectable simulation-based training system.
AI Magazine, Summer 1984, 15-27.\[Ksiezyk 1986\] Ksiezyk, T. An equipment model and its role in noun phraseinterpretation.
Submitted to ACM Conf.
on Object Oriented Programming Systems, Languages,and Applications, Portland, OR.\[Marsh 1983\] Marsh, E. Utilizing domain-specific information for processing compacttext.
Proc.
Conf.
Applied Natural Language Processing, Santa Monica, CA.\[Marsh 1984\] Marsh, E., Hamburger, H., and Grishman, R. A production rule systemfor message summarization.
Proc.
1984 National Conf.
on Artificial Intelligence, Austin, TX,Am.
Assn.
of Artificial Intellgience.\[McDonald 19781 McDonald, D., and Hayes-Roth, F. Inferential searches ofknowledge networks as an approach to extensible language understanding systems.
InPattern-directed inference systems, Waterman and Hayes-Roth, Eds.
Academic Press, NewYork.\[Montgomery 1983\] Montgomery, C. Distinguishing fact from opinion and events fromrecta-events.
Proc.
Conf.
Applied Natural Language Processing, Santa Monica, CA.\[Palmer 1986\] Palmer, M., Dahl, D., Schiffman, R., Hirschman, L., Linebarger, M.,and Dowding, J. Recovering implicit information.
To appear in Proc.
1986Annl.
Conf.Assn.
Computational Linguistics, New York, NY.\[Sager 1975\] Sager, N., and Grishman, R. The restriction language for computergrammars of natural language.
Comm.
Assn.
Computing Machinery 18, 390-400.\[Sager 1978\] Sager, N. Natural language information formatting: the automaticconversion of texts to a structured ata base.
Advances in Computers 17, 89-162.\[Sager 1981\] Sager, N. Natural Language Information Processing.
Addison-Wesley,Reading, MA.80
