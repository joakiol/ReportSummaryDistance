Segmentation of Chinese Long Sentences Using CommasMei xun Jin1, Mi-Young Kim2, Dongil Kim3 and Jong-Hyeok Lee4Graduate School for Informa-tion Technology1,Div.
of Electrical andComputer Engineering24,Pohang University of Science and TechnologyAdvanced Information Technology Research Center(Altrc){meixunj1,colorful2,jhlee4}@postech.ac.krLanguage Engineering Institute3Div.
of Computer, Electronicsand TelecommunicationsYanbian University of Scienceand Technologydongil@ybust.edu.cnAbstractThe comma is the most common form ofpunctuation.
As such, it may have thegreatest effect on the syntactic analysis of asentence.
As an isolate language, Chinesesentences have fewer cues for parsing.
Theclues for segmentation of a long Chinesesentence are even fewer.
However, the av-erage frequency of comma usage in Chi-nese is higher than other languages.
Thecomma plays an important role in longChinese sentence segmentation.
This paperproposes a method for classifying commasin Chinese sentences by their context, thensegments a long sentence according to theclassification results.
Experimental resultsshow that accuracy for the comma classifi-cation reaches 87.1 percent, and with oursegmentation model, our parser?s depend-ency parsing accuracy improves by 9.6 per-cent.1 IntroductionChinese is a language with less morphology andno case marker.
In Chinese, a subordinate clause orcoordinate clause is sometimes connected withoutany conjunctions in a sentence.
Because of thesecharacteristics, Chinese has a rather different set ofsalient ambiguities from the perspective of statisti-cal parsing (Levy and Manning, 2003).
In addition,the work for clause segmentation is also rather dif-ferent compared with other languages.However, in written Chinese, the comma is usedmore frequently (Lin, 2000).
In English, the averageuse of comma per sentence is 0.869 (Jones, 1996a)1~1.04(Hill, 1996), and in Chinese it is 1.792, whichis one and a half to two more times as it is used inEnglish.
In Korean, the comma is used even lessthan it is in English (Lin, 2000).Since Chinese has less morphology and no casemarker, and the comma is frequently used, thecomma becomes an important cue for long Chinesesentence parsing.
Because more commas may ap-pear in longer sentences, the necessity of analyzingthe comma also increases.Some handbooks about standard Chinese gram-mars list ten to twenty uses of the comma, accord-ing to the context.
Among these uses, is occurrenceat the end of a clause3 in a sentence (Lin, 2000).About 30% of commas are used to separate theclause from its main sentence or neighbor clause(s).If the comma appears at the end of a clause, theposition can naturally be set as the clause segmen-tation point.This paper proposes Chinese long sentencesegmentation by classifying the comma.
In section2, related work in clause segmentation and punc-tuation processing is presented.
Comma classifica-tion criteria are then introduced, and theclassification model follows.
Afterwards, someexperimental results show how the proposedcomma classification and long sentence segmenta-tion are effective in Chinese parsing.
Finally, aconclusion will be given.1 The frequency of comma per sentence is calculated as = Total frequency ofcommas/(Total frequency of full stop + Total frequency of Question mark),based on the punctuation statistics of Jone?s Phd.
thesis P56,57.2 The calculation is based on People?s Daily Corpus?98.3 Clause in this paper, is a predicate with its full complements, subject, object(s).According to the type of a predicate and the context, subject or object may ormay not appear.
Adjunct of the predicate may or may not be included in theclause.????????????
?Figure1: example of a dependency relation??????????????????
?Figure2: example of a dependency relation???????????????
?Figure 3: example of a dependency relationExamples:(1) ????????????
?They have class in the morning and do experiments inthe afternoon.
(2) ??????????????????
?Several years ago,  BeiHai City was only an unknownsmall fishing village.
(3) ???????????????
?The students prefer young and beautiful teachers.
(4) ?????????????
?Xiao Ming is doing homework and his mom isknitting.
(5) ?????????????
?Though he studies very hard, his score is not satisfiable.
(6) ?????????????????????????
?The change of domestic economic development inRussia has promoted the trade exchange between twocountries.
(7) ???????????????????
?Bank of China invited a Japanese company as its con-soler last October.
(8) ????????????????????
?He is a good leader in the company as well as a gooddaddy at home.
(9) ??????????????????????
?The quick transfer of the scientific research achieve-ment to industry is the characteristic of this develop-ment district.
(10) ??????????????
?The students happily come to the playground.
(11) ???????????????????????????????
?The investment from Korea to DaLian city has grownfor three years, and all Korean investment companiesin DaLian  receive preferential treatment.
(12) ???????????????????
?The statistics show that the exportation from DaLian toKorea is reach to USD100,000,000.
(13) ???????????????????????
?In 1994, TongYong Company purchased goods worthyof more than  USD40,000,000.
(14) ???????????????
?She gets up early, and does physical exercise everymorning.
(15) ??????????????????????
?The occupation of the first products is less than 3/10and the portion of the second ones is more than 7/10.2 Related Work2.1 Related Work for Clause Segmenta-tionSyntactic ambiguity problems increase drasti-cally as the input sentence becomes longer.
Longsentence segmentation is a way to avoid the prob-lem.
Many studies have been made on clause seg-mentation (Carreras and Marquez, 2002, Leffa, 1998,Sang and Dejean,2001).
In addition, many studiesalso have been done on long sentences segmenta-tion by certain patterns (Kim and Zhang, 2001, Li andPei, 1990, Palmer and Hearst, 1997).However, some researchers merely ignore punc-tuation, including the comma, and some research-ers use a comma as one feature to detect thesegmentation point, not fully using the informationfrom the comma.2.2 Related Work for Punctuation Proc-essingSeveral researchers have provided descriptivetreatment of the role of punctuations: Jones (1996b)determined the syntactic function of the punctua-tion mark.
Bayraktar and Akman (1998) classifiedcommas by means of the syntax-patterns in whichthey occur.
However, theoretical forays into thesyntactic roles of punctuation were limited.Many researchers have used the punctuationmark for syntactic analysis and insist that punctua-tion indicates useful information.
Jones (1994) suc-cessfully shows that grammar with punctuationoutperforms one without punctuation.
Briscoe andCarroll 1995) also show the importance of punc-tuation in reducing syntactic ambiguity.
Collins(1999), in his statistical parser, treats a comma as animportant feature.
Shiuan and Ann (1996) separatecomplex sentences with respect to the link word,including the comma.
As a result, their syntacticparser performs an error reduction of 21.2% in itsaccuracy.
(Say (1997) provides a detailed introduction to us-ing punctuation for a variety of other natural lan-guage processing tasks.All of these approaches prove that punctuationanalyses improve various natural language process-ing performance, especially in complex sentencesegmentation.3 Types of CommasThe comma is the most common punctuation,and the one that might be expected to have thegreatest effect on syntactic parsing.
Also, it seemsnatural to break a sentence at the comma positionin Chinese sentences.
The procedure for syntacticanalysis of a sentence, including the segmentationpart, is as follows:1st step: segment the sentence at a comma2nd step: do the dependency analysis for eachsegment3rd step: set the dependency relation betweensegment pairsIn Chinese dependency parsing, not all commasare proper as segmentation points.First, segmentation at comma in some sentences,will cause some of the words fail to find their heads.Figure 2 shows, in example (2), there are twowords, ??
(BeiHai City)  and ?
(preposition)from the left segment have dependency relationwith the word ?
(is) of the right segment.
So, thesegmentation at comma , will cause two of  words??
(BeiHai City)  and ?
(preposition) in the leftsegment, cannot find their head in the second stepof syntactic parsing stage.Second, segmentation at commas can causesome words to find the wrong head.
Example (3) offigure 3 shows two pairs of words with dependencyrelations.
For each pair, one word is from the leftsegment, and one word is from the right segment :??
(like) from the left segment and ??
(teacher)from the right, ??
(young) from the left and ?
(of) from the right.
Segmentation at the commawill cause the word ??
(young) to get the word ??
(like) as its head, which is wrong.Example (2) and (3) demonstrate improper sen-tence segmentation at commas.
In figure 2 and fig-ure 3, there are two dependency lines that crossover the commas for both sentences.
We call thesekinds of commas mul_dep_lines_cross comma(multiple lines cross comma).
In figure 1, there isonly one dependency line cross over the comma.We call these kinds of commas one_dep_line_crosscomma.Segmentation at one_dep_line_cross comma ishelpful for reducing parsing complexity and cancontribute to accurate parsing results.
However, weshould avoid segmenting at the position ofmul_dep_lines_cross comma.
It is necessary tocheck each comma according to its context.3.1 Delimiter Comma and SeparatorCommaNunberg (1990) classified commas in Englishinto two categories, as a delimiter comma and aseparator comma, by whether the comma is used toseparate the elements of the same type 4  or not.While a delimiter comma is used to separate differ-ent syntactic types, a separator comma is used toseparate members of conjoined elements.
Thecommas in Chinese can also be classified into thesetwo categories.
The commas in example (3) and (4)are separators, while those in (2) and (5), aredelimiters.However, both delimiter comma and separatorcommas can be mul_dep_line_cross commas.
Inexample (2), the comma is a delimiter comma aswell as a mul_dep_line_cross comma.
As a separa-tor comma, the comma in example (3), is also amul_dep_line_cross comma.
Nunberg?s classifica-tion cannot help to identify mul_dep_line_crosscommas.We therefore need a different kind of classifica-tion of comma.
Both delimiter comma and separa-tor comma can occur within a clause or at the endof a clause.
Commas that appear at the end of aclause are clearly one_dep_line_cross commas.The segmentation at these kinds of comma is valid.4 Same type means that it has the same syntactic role in the sentence, it can be acoordinate phrase or coordinate clause.3.2 Inter-clause Comma and Intra-clauseCommaCommas occurring within a clause are herecalled intra-clause commas.
Similarly, commas atthe end of a clause will be called inter-clausecommas.
Example  (2), (3) include intra-clausecommas, and example (4), (5) include inter-clausecommas.3.2.1 Constituents of the Two SegmentsAdjoining a CommaA segment is a group of words between twocommas or a group of words from the beginning(or end) of a sentence to its nearest comma.To identify whether a comma is an inter-clausecomma or an intra-clause comma, we assign valuesto each comma.
These values reflect the nature ofthe two segments next to the comma.
Either the leftor right segment of a comma, can be deduced as aphrase5, or several non-overlapped phrases, or aclause.
(see examples (6)~(15)).
The value we as-sign to a comma is a two-dimensional value(left_seg, right_seg).
The value of left_seg andright_seg can be p(hrase) or c(lause), therefore theassigned value for each comma can be (p,p), (p,c),(c,p) or (c,c).Commas with (p,p) as the assigned value, in-clude the case when the left and right segment ofthe comma can be deduced as one phrase, as shownin example (6) or several non-overlapped phrases,as described in example (7).We can assign the value of (c,p) to commas inexample (8), (9) and (10),  indicating the left ad-joining segment is a clause and the right one is aphrase or several non-overlapped phrases.
In asimilar way, commas in example (11)~(13) arecase of (p,c).If a comma has (c,c) as the assigned value, boththe left segment and the right segment can be de-duced as a clause.
The relation between the twoclauses can be coordinate (example (14)) or subor-dinate (example (15)).5 Phrase is the group of words that can be deduced as the phrase in Chinese PennTree Bank 2.0.
A phrase may contain an embedded clause as its adjunct orcomplement.
(a), ???????????
(b) ????????
?In example (a) ,the PP has the embedded clause as its complement.
And inexample (b), the embedded clause is the adjunct of the NP.3.2.2 Syntactic Relation between Two Ad-joining SegmentsA word (some words) in the left segment and aword (some words) in the right segment of acomma may or may not have a dependency rela-tion(s).
For a comma, if at least one word from theleft segment has a dependency relation with a wordfrom the right segment, we say the left segment andthe right segment have a syntactic relation.
Other-wise the two segments adjoining the comma haveno syntactic relations.
Rel() functions are definedin table-1.Table 1: functions Rel(), Dir() and Head()Rel()?
To check if any words of the left segment has adependency relation with the word of the rightsegment.?
If there is, Rel()=1Otherwise Rel()=0.Dir()?
To indicate how many direction(s) of the de-pendency relations the left and right segmenthave.
when Rel()=1.?
For one_dep_line_cross comma, Dir()=1.?
For mul_dep_line_cross comma, if the directionsof the dependency relations are the same,Dir()=1, else Dir()=2.Head()?
To indicate which side of segment contains thehead of any words of the other side, whenRel()=1.?
When Dir()=1, if the left segment contains anyword as the head of a word of the right, Head() =left; Otherwise Head()=right.?
When Dir()=2,1.
According to the direction of dependencyrelation of these two segments, to find theword which has no head.2.
If the word is on the left, Head()=left, other-wise, Head()=right.For the one_dep_line_cross comma, the left andright segments have syntactic relation, and onlyone word from a segment has a dependency rela-tion with a word from the other segment.
Formul_dep_line_cross comma, at least two pairs ofwords from each segment have dependency rela-tions.
We then say that the left and right segmentsadjacent to the comma have multiple dependencyrelations.
The directions of each relation may differor not.
We define a function Dir() as follows : if allthe directions of the relations are the same, get 1 asits value, else 2 for its value.
This is in table-1.
Wealso define function Head() to indicate whether theleft segment or the right segment contains the headword of the other when the two segments have syn-tactic relation.
This is also shown in table 1.In example (3) as figure 3 shows, Rel()=1,Dir()=2 and Head()=left.3.2.3 Inter-clause Comma and Intra-clause CommaFor commas assigned values  (p,p) or (c,c), thefunction Rel() is always 1.
Commas with values (c,p) or (p,c) can be further divided into two sub-cases.Table 2 shows the sub-case of (c,p), and table 3shows the sub-cases of (p,c).Rel() =0 The 2nd comma of Example (8);Example (9);Head() =right = p(c,p)-IRel()=1 Example (10);Head() = left=c(c,p)-IITable 2: sub-cases of commas with value of (c,p)Rel()=0 Example (11);Example (12);Head() =left = p(p,c)-IRel()=1 Example (13);Head() = right=c(p,c)-IITable3: sub-cases of commas with value of (p,c)Commas with the value of (p,p), (c,p)-II and(p,c)-II are used to connect coordinate phrases or toseparate two constituents of a clause.
These com-mas are intra-clause commas.Commas with (c,c), (c,p)-I and (p,c)-I are usedas a clause boundaries.
These are inter-clausecommas.An inter-clause comma joins the clauses togetherto form a sentence.
The commas that belong to aninter-clause category are safe as segmentationpoints (Kim, 2001).4 Feature SelectionTo identify the inter-clause or intra-clause roleof a comma, we need to estimate the right and leftsegment conjuncts to the comma, using informa-tion from both segments.
Any information to iden-tify a segment as a clause or a phrase or phrases isuseful.
Carreras and Marquez (2001) prove thatusing features containing relevant informationabout a clause leads to more efficient clause identi-fication.
Their system outperforms all other sys-tems in CoNLL?01 clause identification shared task(Sang & Dejean, 2001).
Given this consideration, weselect two categories of features as follows.
(1) Direct relevant feature category: predicateand its complements.
(2) Indirect relevant feature category: auxiliarywords or adverbials or prepositions or clausalconjunctions.Directly relevant featuresVC: if a copula ?
appearsVA: if an adjective appearsVE: if ?
as the main verb appearsVV: if a verb appearsCS: if a subordinate conjunction appearsTable 4: feature types for classificationIndirectly relevant featuresAD: if an adverb appearsAS: if an aspect marker appearsP: if a preposition appearsDE: if ?
appearsDEV:if ?
appearsDER: if ?
appearsBA_BEI: if ?
or ?
appearsLC: if a localizer appearsFIR_PR : if the first word is a pronounLAS_LO: if the last word is a localizerLAS_T : if the last word is a timeLAS_DE_N : if the last word is a noun that follows ?No_word : if the length of a word is more than 5no_verb: if no verb(including VA)DEC: if there is relative clauseONE: if the segment has only one wordTo detect whether a segment is a clause orphrase, the verbs are important.
However, Chinesehas no morphological paradigms and a verb takesvarious syntactic roles besides the predicate, with-out any change of its surface form.
This means thatinformation about the verb is not sufficient, in itself,to determine whether segment is a clause.When the verb takes other syntactic roles besidesthe predicate, it?s frequently accompanied by func-tion words.
For example, a verb can be used as thecomplement of the auxiliary word ?
or ?
(Xia,2000), to modify the following verb or noun.
Inthese cases, the auxiliary words are helpful for de-ciding the syntactic role of the verb.
Other functionwords around the verb also help us to estimate thesyntactic role of the verb.
Under this consideration,we employ all the function words as features,where they are composed as the indirect relevantfeature category.Table 4 gives the entire feature set.
The label ofeach feature type is same as the tag set of ChinesePenn Treebank 2.0 (see Xia (2000) for more de-tailed description).
If the feature appears at the leftsegment, we label it as L_feature type, and if it ison the right, it?s labeled as R_ feature type, wherefeature type is the feature that is shown on table 4.The value for each feature is either 0 or 1.
Whenextracting features of a sentence, if any feature inthe table 4, appears in the sentence, we assign thevalue as 1 otherwise 0.
The features of example (12)are extracted as table 5 describes.
All of these val-ues are composed as an input feature vector forcomma classification.Table 5: the extracted features of example (12)5 ExperimentsFor training and testing, we use the ChinesePenn Treebank 2.0 corpus based on 10-fold valida-tion.
First, using bracket information, we extractthe type (inter-clause comma or intra-clausecomma) for each comma, as we defined.
The ex-tracted information is used as the standard answersheet for training and testing.We extract the feature vector for each comma,and use support vector machines (SVM) to performthe classification work.Performances are evaluated by the followingfour types of measures: accuracy, recall, F?=1/2 forinter-clause and intra-clause comma respectively,and total accuracy.
Each evaluation measure is cal-culated as follows.Inter(or intra)-clause comma accuracy6 =identifiedofnumbertheidentifiedcorrectlyofnumbertheInter(or intra)-clause comma recall  =classtheofnumbertotalidentifiedcorrectlyofnumbertheInter(or intra)-clause comma F ?=1/2 =recall) comma clauseintra)inter(orprecision comma clauseintra)(inter(or)recallcommaclauseintra)inter(orprecisioncommaclauseintra)inter(or (2?+????
?Total accuracy =commasofnumbertotalidentifiedcorrectlyofnumbertotal5.1 Classification Using SVMSupport vector machines (SVM) are one of thebinary classifiers based on maximum margin strat-egy introduced by Vapnik (Vapnik, 1995).
For manyclassification works, SVM outputs a state of the artperformance.L_VC =0 L_VA =0 L_VE =0R_VC = 0 R_VA =0 R_VE =0L_VV = 0 L_CS =0 L_AD =0R_VV =1 R_CS =0 R_AD =0L_AS =0 L_P =0  L_DE =0R_AS =1 R_P =0 R_DE =1L_DEV =0 L_DER = 0 L_BA_BEI =0R_DEV =0 R_DER =0 R_BA_BEI=0L_LC =0 L_DEC = 0 L_FIR_PR  =0R_LC =0 R_DEC =0 R_FIR_PR=0L_LAS_LO =0 L_LAS_T =1 L_LAS_DE_N=0R_LAS_LO=0 R_LAS_T=0 R_LAS_DE_N=1L_No_word=0 L_no_verb =1 L_ONE = 0R_No_word =1 R_no_verb =0 R_ONE =0There are two advantages in using SVM for clas-sification:(1) High generalization performance in high di-mensional feature spaces.
(2) Learning with combination of multiple fea-tures is possible via various kernel functions.Because of these characteristics, many research-ers use SVM for natural language processing andobtain satisfactory experimental results (Yamada,2003).In our experiments, we use SVMlight (Joachims,1999) as a classification tool.5.2 Experimental ResultsFirst, we set the entire left segment and rightsegment as an input window.
Table 6 gives the per-formance with different kernel functions.
The RBFkernel function with ?
=1.5 outputs the best per-formance.
Therefore, in the following experiments,we use this kernel function only.Next, we perform several experiments on howthe selection of word window affects performance.First, we select the adjoining 3 words of the rightand left segment each, indicated as win-3 in table 7.6 The inter-clause comma precision is abbreviated  as inter-P.
Same way, Inter-Rfor inter-clause comma recall, ..etc.Second, we select the first 2 words and last 3 wordsof the left segment and the first 3 and last 2 of theright segment, indicated as win 2-3 in table 7.
Fi-nally, we use the part of speech sequence as input.As the experimental results show, the part ofspeech sequence is not a good feature.
The featureswith clausal relevant information obtain a betteroutput.
We also find that the word window of first2-last 3 obtains the best total precision, better thanusing the entire left and right segments.
From this,we conclude that the words at the beginning andend of the segment reveal segment clausal informa-tion more effectively than other words in the seg-ment.5.3 Comparison of Parsing Accuracy withand without Segmentation ModelThe next experiment tests how the segmentationmodel contributes to parsing performance.
We usea Chinese dependency parser, which was imple-mented with the architecture presented by Kim(2001) presents.After integrating the segmentation model, theparsing procedure is as follows:- Part of speech tagging.- Long sentence segmentation by comma.- Parsing based on segmentation.Table 9 gives a comparison of the results of theoriginal parser with the integrated parser.5.4 Comparison with Related WorkShiuan and Ann?s (1996) system obtains theclues for segmenting a complex sentence in Eng-lish by disambiguating the link words, includingthe comma.
The approach to find the segmentationpoint by analyzing the specific role of the commain the sentence seems similar with our approach.However, our system differs from theirs as follows:(1) Shiuan and Ann?s system sieves out just tworoles for the comma, while ours gives ananalysis for the complete usages of thecomma.
(2) Shiuan and Ann?s system also analyzes theclausal conjunction or subordinating preposi-tion as the segmentation point.Although the language for analysis is different,and the training and testing data also differ, themotivation of the two systems is the same.
In addi-tion, both systems are evaluated by integrating theoriginal parser.
The average accuracy of commadisambiguation in Shiuan and Ann?s is 93.3% thatis higher than ours by 6.2%.
However, for parsingaccuracy, Shiuan and Ann?s system improves by4%(error reduction of 21.2%), while ours improvesby 9.6 percent.Kernelfunction Inter-P Inter-R Intra-P Intra-R Inter-F Intra-F Total-Plinear74.22%77.87%72.52%70.61%76.00%71.56%73.14%Polynomiald=279.84%81.15%84.51%83.77%80.49%84.14%82.86%Polynomiald=378.57%81.15%88.39%86.84%79.84%87.61%84.86%RBF    ?
= 0.5 78.46% 83.61% 88.64% 85.53% 80.95% 87.05% 84.86%RBF  ?
= 1.5 78.69% 78.69% 89.04% 89.04% 78.69% 89.04% 85.43%RBF  ?
= 2.5 80.62% 85.25% 88.24% 85.53% 82.87% 86.86% 85.43%RBF ?
= 3.5 79.41% 88.52% 85.05% 79.82% 83.72% 82.35% 82.86%Table 6: experimental results withdifferent kernel functionsWord Win-dow Inter-P Inter-R Intra-P Intra-R Inter-F Intra-F Total-PWin380.45%87.70%84.33%80.26%83.92%82.25%82.86%Win2-385.60%87.70%88.00%86.84%86.64%87.42%87.14%Table 7: experimental results forword window sizeInter-P Inter-R Intra-P Intra-R Inter-F Intra-F Total-PPOSsequence75.42%72.95%80.60%82.02%74.17%81.30%78.86%Table 8: experimental results for usingpart of speech sequenceOriginalparserIntegratedparserAverage dependency pars-ing accuracy773.8% 83.4%Average complete sentenceaccuracy23.8% 25.4%Table 9: comparison of parsing accuracy of theoriginal parser with the integrated parser7 The evaluation measures are used as it is defined in Kim (2001).6 ConclusionIn this paper, we propose a method to segment aChinese sentence by classification of the comma.We define the criteria for classification, and ac-cording to the criteria, a model for classification ofthe comma is given.
The segmentation at thecomma position seems to be efficient for improv-ing the accuracy of dependency parsing by9.6percent.
Moreover, since commas more fre-quently appear in Chinese language, we expect ourapproach including salient and refined analysis ofcomma usages provides feasible solutions for seg-mentation.However, the accuracy for the segmentation isnot yet satisfactory.
Since erroneous segmentationmay cause a parsing failure for the entire sentence,errors can be serious.
Further research should bedone to improve the performance and reduce sideeffects for parsing the entire sentence.AcknowledgmentsThis work was supported by the KOSEF throughthe Advanced Information Technology ResearchCenter (AITrc), and by the BK21 Project.ReferencesM.
Bayparktar,  B.
Say and V. Akman 1998, An analysisof English punctuation: the special case of comma,International Journal of Corpus Linguistics, 1998X.
Carreras, L. Marquez, V. Punyakanok, and D. Roth2002, Learning and inference for clause identification,Proceeding of 13th European Conference on MachineLearning, Finland, 2002R.L.
Hill 1996, A comma in parsing: A study into theinfluence of punctuation (commas) on contextuallyisolated "garden-path" sentences.
M.Phil disseration,Dundee University, 1996T.Joachims 1999, Making large-Scale SVM LearningPractical.
Advances in Kernel Methods - SupportVector Learning, B. Sch?lkopf and C. Burges and A.Smola (ed.
), MIT-Press, 1999B.
Jones 1994, Exploring the role of punctuation in pars-ing natural text, Proceedings of COLING-94, pages421-425B.
Jones 1996a, What?s the point?
A (computational)theory of punctuation, PhD Thesis, Centre for Cogni-tive Science, University of Edinburgh, Edinburgh,UK, 1996B.
Jones 1996b, Towards testing the syntax of punctua-tion, Proceeding of 34th ACL, 1996M.Y.Kim, S.J.
Kang, J.H.
Lee 2001, Resolving ambigu-ity in Inter-chunk dependency parsing, Proceedingsof the sixth Natural Language Processing Pacific RimSymposium, Tokyo, Japan, 2001S.
Kim, B.Zhang and Y. Kim 2001, Learning-basedintrasentence segmentation for efficient translation oflong sentences, Machine Translation, Vol.16, no.3,2001Roger Levy and Christopher Manning.
2003.
Is it harderto parse Chinese, or the Chinese Treebank?
InProceeding of ACL-2003.V.J.
Leffa 1998, clause processing in complex sentences,Proceeding of 1st International Conference on Lan-guage Resources and Evaluation, Spain,1998W.C.
Li, T.Pei, B.H.
Lee and Chiou, C.F.
1990, Parsinglong English sentences with pattern rules, Proceedingof 13th International Conference on ComputationalLinguistics, Finland, 1990Shui-fang Lin 2000. study and application of punctua-tion(??????????).
People?s Publisher,P.R.China.
(in Chinese)Geoffrey Nunberg 1990. the linguistics of punctua-tion .CSLI lecture notes.
18, Stanford, California.D.D.
Palmer and M.A.
Hearst 1997, Adaptive multilin-gual sentence boundary disambiguation, Computa-tional Linguistics, Vol.27, 1997E.F.T.K.
Sang and H.Dejean.
2001, Introduction to theCoNLL-2001 shared task: clause identification, Pro-ceeding of CoNLL-2001B.
Say and V. Akman 1997, current approaches topunctuation in computational linguistics, Computersand the Humanities, 1997P.L.
Shiuan and C.T.H.
Ann 1996, A divide-and-conquer strategy for parsing, Proceedings of theACL/SIGPARSE 5th international workshop on pars-ing technologies, Santa Cruz, USA, pp57-66Fei Xia 2000, The bracketing Guidelines for the PennChinese Treebank(3.0)Vladimir N Vapnik 1995 The nature of statistical learn-ing theory.
New York, 1995
