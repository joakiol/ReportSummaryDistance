ABSTRACTSpoken user interfaces are conventionally either dialogue-based or menu-based.
In this paper we propose a thirdapproach, in which the task of invoking responses from thesystem is treated as one of retrieval from the set of all possi-ble responses.
Unlike conventional spoken user interfacesthat return a unique response to the user, the proposed inter-face returns a shortlist of possible responses, from whichthe user must make the final selection.
We refer to suchinterfaces as Speech-In List-Out or SILO interfaces.
Exper-iments show that SILO interfaces can be very effective, arehighly robust to degraded speech recognition performance,and can impose significantly lower cognitive load on theuser as compared to menu-based interfaces.KeywordsSpeech interfaces, information retrieval, spoken query1.
INTRODUCTIONSpoken input based user interfaces can be broadly cate-gorized as dialogue-based interfaces and menu-selectioninterfaces.
In dialogue-based interfaces, the system engagesin a dialogue with the user in an attempt to determine theuser?s intention.
In menu-based interfaces users traverse atree of menus, each node of which presents a list of possiblechoices for the user.
In both kinds of interfaces, the speechrecognizer must typically convert the user?s speech to anunambiguous text string, which is then used by the UI todetermine the action it must take next.
Both kinds of inter-faces eventually respond to the user with a unique output.In this paper we advocate a third, and different approachto spoken user interfaces.
We note that in a majority ofapplications for which speech interfaces may be used, thegoal of the interaction between the user and the system is toevoke a specific response from a limited set of possibleresponses.
In our approach, we view the set of possibleresponses as documents in an index, and the task of obtain-ing a specific response as that of retrieval from the set.
Spo-ken input from the user is treated as a query, which is usedto retrieve a list of potentially valid responses that are dis-played to the user.
The user must then make the final selec-tion from the returned list.
We call spoken user interfacesbased on this approach ?Speech-In List-Out?
or SILO inter-faces.While much has been written on text-based retrieval ofspoken or multimedia documents, the topic of informationretrieval (IR) using spoken queries has not been addressedmuch.
The usual approach to spoken query based IR hasbeen to use the recognizer as a speech-to-text convertor thatgenerates a text string (Chang et.
al, 2002; Chen et.
al.,2000) or a phoneme sequence (Kupiec et.
al.
1994) which isused to query the index.
This approach is critically depen-dent on accurate recognition of the spoken query.In our system, however, we do not require direct con-version of the spoken input to an unambiguous text string.Instead, the spoken query is converted to a probabilisticallyscored ?bag of words?
derived from the entire hypothesisspace of the recognizer, that serves as the query to theindex.
This system is able to perform effectively even whenthe actual text string output by the recognizer is erroneous.The proposed SILO approach has several advantagesover dialogue-based or menu-based interfaces.
The latterrequire users to know or guess what to say at each stage inan interaction.
Interactions typically follow a sequence ofsteps, and the allowed responses from the user vary withthe state of the interaction.
On the other hand, since theSILO interface essentially performs information retrievalbased on the query, restrictions on the allowed language arefew, if any.
Additionally, the SILO interface responds in asingle step to the user, without requiring repeated refine-ment of the request.
This simplicity of operation makes theSILO interface measurably simpler to use than menu-basedinterfaces.Speech recognition systems often make mistakes, espe-cially under noisy recording conditions.
Recognition errorscan result in incorrect responses from user interfaces.
Toimprove the robustness of the UI to recognition errors, dia-logue and menu-based systems use various techniques suchas rejection, confirmatory responses and error-correctingdialogues.
SILO interfaces do not use such techniques, andare more reliant on getting the responses right in the firstplace.
This is possible in SILO interfaces because the spo-ken query based IR technique used in them is inherentlyrobust to recognition errors.The rest of this paper is arranged as follows: in Section2 we describe the basic operation of the SILO interface.
InSection 3 we describe the spoken query based IR algorithmused by the SILO interface.
In Section 4 we describe someexample applications that use the SILO interface andpresent experiments evidence of the effectiveness of SILO.Finally in Section 5 we present our conclusions.2.
THE OPERATION OF THE SILO INTERFACEFigure 1. demonstrates the difference between the con-ventional spoken user interfaces and the SILO interface.Figure 1a.
shows the typical operation of a conventionaldialog or menu-based interface.
The user initiates the inter-action typically using a push-to-talk or press-to-talk button.Thereafter the system goes through a cycle of processingA Speech-In List-Out Approach to Spoken User InterfacesVijay Divi1, Clifton Forlines2, Jan Van Gemert2, Bhiksha Raj2, Bent Schmidt-Nielsen2, Kent Wittenburg2, JosephWoelfel2, Peter Wolf2, Fang-Fang Zhang21.
Massachussetts Institute of Tehcnology, Cambridge, MA, USA2.
Mitsubishi Electric Research Laboratories, Cambridge, MA, USAvdivi@mit.edu, {forlines, gemert, bent, wittenburg, woelfel, wolf, fzhang}@merl.comthe user?s spoken input, and responding to it in some man-ner, either with a menu, or some intermediate response of adialogue.
After a number of cycles through this loop, thesystem eventually responds with the desired action.Conventional interfaces are predicated on the theorythat it is advantageous to obtain information about thedesired final response in an incremental manner, throughcontrolled exchanges in which the number of possible inter-pretations of the user?s input is limited.
In addition, dia-logue-based interfaces also attempt to make the interactionbetween the user and the system conversational.The design of the SILO interface, on the other hand, isbased on the following premises: a) when the set of possi-ble responses by the system is limited and can be enumer-ated, simple information retrieval techniques are sufficientto shortlist the possible final responses to the user.
Theshortlist may bear no resemblance to the structured lists thatare derived by a menu or dialogue-based system, but willnevertheless contain the desired response provided the IRtechnique used is sufficiently robust.
b) It is best to push thefinal choice of response from such a list back to the user.Figure 1b.
shows the operation of the SILO interface.The user initiates the interaction using a push-to-talk but-ton.
The system then records the user?s spoken input andreturns a ranked list of plausible responses based on theinput.
The user finally selects the desired response througha secondary selection, which may be performed using but-tons, or even by voice.
The entire operation is performed intwo steps, one in which the system retrieves a list ofchoices, and the other in which the user selects from thelist.3.
INFORMATION RETRIEVAL IN SILO USING SPOKENQUERIESAt the heart of the SILO interface is the MERL Spoken-Query information retrieval engine (Wolf and Raj, 2002).The standard approach to spoken query based IRrequires the unambiguous conversion of the spoken input totext by the recognizer, and is likely to fail if the recognizermakes errors, especially in recognizing keywords that iden-tify the desired documents.
The SpokenQuery IR engineused in the SILO interface, however, does not requireunambiguous speech-to-text conversion.
Spoken queriesProcessSpoken InputRespond toInputInitiateInteractionDesiredActionSpoken querybased InformationRetrievalInitiateInteractionspeechspeech(a) Menu or dialogbased spoken userinterface(b) SILODesiredActionListSelectionFigure  1.
Operation of spoken user interfaces.
(a) Conven-tional dialog or menu-based interfaces.
(b) SILO.need not conform to any grammar and are permitted to befree form.Textual descriptions of the responses required from thesystem are stored as documents in a document index.
Thedescriptions must uniquely identify the response.
For exam-ple, in a digital music retrieval system, the documentsmight be the descriptive meta data associated with themusic.
For a command and control system, they might be atext description of possible actions to be taken by the appli-cation.Documents are represented in this index as word-countvectors.
Each entry in the vector represents the frequency ofoccurrence of a specific word in the document.
This repre-sentation ignores the order in which words occur in the doc-uments, retaining information only about their frequency ofoccurrence.
This particular representation is related to theabsence of linguistic constraints applied to spoken queries.Since queries are permitted to be free form, word order can-not be a consideration in the formation of the query, andconsequently in the document index.Spoken queries are converted to a data structure that issimilar to the structures used to represent documents in theindex.
The query structure is a vector of normalizedexpected word counts in the spoken query.
The expectedcount for a word is simply the statistical expectation of thenumber of times the word occurred in the spoken query andis computed from the entire set of word sequence hypothe-ses considered by the recognizer, not just the single textstring finally output by the recognizer.The recognizer represents the set of all consideredhypotheses as a graph that is commonly known as a wordlattice.
Nodes in the graph represent words and arcs repre-sent valid transitions between words.
The scores associatedwith nodes and arcs are the probabilities of the correspond-ing words and transitions.
The best-choice transcript gener-ated by the recognizer is the most likely path through thislattice (i.e.
the path with the best score).The a posteriori probability of any node in the word lat-tice is the ratio of the total probability scores of all pathsthrough the lattice that pass through that node, to the totalprobability of all paths through the lattice and can be com-puted through a forward-backward algorithm.
Multiplenodes in the word lattice may represent the same word.
Thenormalized expected count for a word is simply the total ofthe a posteriori probabilities of all instances of that word inthe lattice.
We call these ?normalized?
counts since theexpected counts of all words sum to 1.0.A useful feature of speech recognition systems is thatthe actual words spoken by the user are usually included inthe recognition lattice for the utterance, often with highprobability, even when they are not included in the recog-nizer?s final output.
As a result, the true query word usuallyhave non-zero, and often relatively high, expected wordcounts, regardless of their inclusion in the final recognizeroutput.For retrieval, the dot product of the document word-count vectors and the expected word count vectors derivedfrom the spoken query is computed.
The output of theretrieval system is a list of the documents sorted by thisvalue.Figure 2 shows the overall system architecture for theSpokenQuery information retrieval system in SILO.The vocabulary of the speech recognizer used for queryconstruction minimally includes all keywords in the docu-ments.
In addition to these, the recognizer may include allthe rest of the words in the documents as well, or mayreplace them with a smaller set of garbage words.
Sincequeries may be free form, the recognizer cannot use con-strained grammars that impose strict restrictions on wordorder.
Instead, it uses an N-gram language model that high-lights the keywords and key phrases, but does not strictlydisallow any particular sequence of words.4.
EXAMPLE SILO APPLICATIONS AND EXPERIMENTSIn this section we describe some applications for whichwe have implemented SILO interfaces, and report threeexperiments that evaluate different aspects of the SILOinterface.
The targeted aspects are: a) the effectiveness ofthe spoken input based IR technique used in the SILO inter-face, b) the effectiveness of the SILO interface and c)whether the SILO interface provides any advantage overconventional UIs.Document retrieval with spoken queriesSince the main component of the SILO interface is theproposed SpokenQuery IR engine, our first applicationdemonstrates the effectiveness of the proposed IR methodon a conventional document retrieval task.
This applicationis exactly the same as normal IR (e.g.
Google, AltaVista,etc.)
except that the user speaks instead of types.
As withnormal IR, the user may say any word that he/she judges tospecify the information.
There is no grammar to memorize.It is intended that the returned list of documents containappropriate documents near the top, however, as with anyIR engine, there is no guarantee that all returned documentswill be pertinent to the query.For the experimental evaluation, a database of 262 tech-nical reports from our laboratory formed the documentindex.
A total of 75 spoken queries were recorded from anumber of users.
In order to establish ground truth, the truerelevance of each of the 262 documents to each of the que-ries was judged by a team of humans.
For each query, docu-ments were assigned a relevance score of 0 (irrelevant), 1(somewhat relevant), or 2 (definitely relevant).
All querieswere evaluated by every evaluator and their average score,scaled to lie between 1 and 10, was deemed to be theground truth.Figure 3 shows the average relevance of the first 30documents retrieved, for retrieval using a text transcriptionof the queries, with the recognizer?s best output, and theSpokenQuery IR engine respectively.
The text transcriptionis not affected by noise.
For retrieval based on spokeninput, however, SpokenQuery is found to be significantlybetter than retrieval based on the recognizer?s single bestoutput.
While performance on noisy speech is generallypoor, the proposed method is observed to result in an equiv-alent of 5dB improvement in noise level over retrievalbased on the recognizer?s output.MediaFinder: retrieving music with spoken queriesWe now evaluate the effectiveness of SILO as a userinterface.
A UI is effective if the user is able to obtain thedesired response from the system in a small number ofsteps.
Since the SILO based UI returns lists of possibleresponses, the interaction may be considered successful, ifthe returned list contains the desired response.
Further, wedeem it more effective if the desired response is rankedhigher in the list, since the user has to spend less time scan-ning the list.
If the returned list does not contain the desiredresponse, the user must repeat the interaction, and theexchange is considered a failure.The MediaFinder application is a spoken interface forretrieving music from digital collections, and represents agood example of an application where SILO can make asignificant difference in the effectiveness of the UI.
Hand-held mp3 players can hold thousands of songs, yet the inter-face provided on these devices is usually minimal,consisting of a small screen and some buttons.
Users mustaccess music by navigating a hierarchy of menus with thebuttons.
An effective spoken user interface can improve theusability of such devices greatly.MP3 files contain extensive metadata (ID3) thatdescribe their contents.
In the case of music files, theseThe Internetprovidesworldwideaccess to ahuge numberThe Internetprovides hugenumber ofpubliclyavailablemulti-mediaComputewordcertaintiesSpoken queryRecognitionLatticeSpeechrecognizerComputeWordCountsDocumentWord-Count VectorSearch bycomparingvectorsQuery Word-ProbabiltyVectorDocument indexDocumentsSortedListFigure  2.
A block diagram representation of the Spoken-Query IR engine.
The document indexer computes wordcount vectors for documents and stores them in an index.For retrieval, spoken queries are converted to a recognitionlattice by a recognizer.
Normalized expected word countvectors are computed from the lattice.
Documents areranked by the dot product of their word count vectors andthe query vector, and retrieved in the order of their ranking.0501001502002500 5 10 15TxtBPSQOverallPerformanceSNR(dB)Figure  3.
Average ranking of documents retrieved using i)text transcriptions of spoken queries, ii) the text output of arecognizer and iii) the proposed spoken query IR method.would include the title of the album, the name of the singeror composer, and often other details such as the musicalgenre.
This meta-data text is used to index MP3 files.
Tosearch for a song, the user speaks a description of thedesired music.
The description may include a combinationof words from the name of the song, the artist, the album, orthe genre in any order.
A list of songs that match the spokenquery most closely are displayed on the screen.
Using up,down and select buttons, the user scrolls through thereturned list, and selects the desired song.
If the requestedsong is not in the displayed list, the speaker must repeat thequery, perhaps trying different words.We conducted two different experiments on Medi-aFinder: one to evaluate the ability of users to successfullyobtain the desired response from the application - in thiscase the playback of a desired piece of music, and a secondto determine if there is any advantage to the SILO interfaceover conventional interfaces.In the first experiment users attempted to retrieve adesired piece of music from collections of different sizes.MediaFinder returns a list of up to 10 songs in response to aquery.
A score of 100 is given to the interaction if thedesired song is at the top of the list.
The score decreases lin-early if the required response is lower in the list.
If therequired response is not in the returned list, the score for theinteraction is 0.
Figure 4 shows the average score for aninteraction, as a function of the size of the collection fromwhich songs are to be retrieved.
Each point in the plot rep-resents an average score across 100 queries from two users.We note that the average score is greater than 90 in allcases, indicating that the desired music is not onlyretrieved, but is typically near the very top of the list in amajority of the cases.
This shows that the SILO interfacecan indeed be used effectively for such tasks, and may eveneffectively substitute other more complex interfaces.In the second experiment we compared the cognitiveload imposed by the MediaFinder SILO interface to thatimposed by a conventional graphical menu-based interfacefor the same task - selection of music from a digital collec-tion in an automobile.
We note here that digital music play-ers are becoming increasingly common in automobiles, andhaving an effective UI that imposes minimal cognitive loadis of tantamount importance in such devices.Experiments were conducted using a simple drivingsimulator that mimicked two important facets of driving:steering and braking.
Subjects steered, braked, and con-trolled the searching interfaces with a steering wheel and itsgas and brake pedals.
Steering was measured with a pursuittracking task in which the subject used the wheel to closelyframe a moving target.
Braking was measured by recordingsubjects?
reaction time to circles that appeared on screen atrandom intervals.
The tests were conducted on fourteensubjects (8 male, 6 female, 18-37 years old).
Four werenon-native speakers and all but one were regular automo-bile drivers.The study shows that a) subjects made an average of20.7% less steering error when using the SILO interface,and b) Subjects took an average of 28.6% less time toretrieve songs using the SILO interface.
Both interfaces hadthe same effect on braking response.
The results indicatethat the SILO interface does indeed impose a significantlylower cognitive load on the user, at least for such tasks.It must be mentioned, however, that subjects were muchbetter at both steering and braking when they did notattempt to retrieve music at all (suggesting, perhaps, thatwhen driving an automobile, people must simply justdrive).5.
DISCUSSIONS AND CONCLUSIONThe SILO interface presents a different approach to userinterfaces, that treats the problem of obtaining a particularfinal response from a system as one of retrieving one of theelements from the set of all possible responses from thesystem.
The experiments demonstrate that the SILO inter-face can be effectively used in applications where theresponses of the system can be enumerated, and textuallydescribed, and that it can actually be easier to use in somesituations.REFERENCES1.
Chang, E., Seide, F., Meng, H., Chen, Z. Shi, Y., Li, Y.A system for spoken query information retrieval onmobile devices.
IEEE Trans.
on Speech and Audio Pro-cessing, 10:8, pp.
531-541.
November 2002.2.
Chen, B., Want, H.M., Lee, L.S.
Retrieval of broadcastnews speech in Mandarin Chinese collected in Taiwanusing syllable-level statistical characteristics.
Proc.IEEE Intl.
Conf.
on Acoustics Speech and Signal Pro-cessing (ICASSP2000).
Istanbul, Turkey.
2000.3.
Kupiec, J., Kimber, D., Balasubramanian, V. Speech-based retrieval using semantic co-occurrence filtering,Proc.
Human Language Technology Conf.
1994.4.
Wolf, P. and Raj, B.
The MERL SpokenQuery Informa-tion Retrieval System: A System for Retrieving Perti-nent Documents from a Spoken Query.
Proc.
IEEEConference and Multimedia Expo (ICME2003).
Lau-sanne, Switzerland.
August 2002.909192939495969798991006828 3414 1707 854 427 214 107 54Index SizeAveragescoreText OnlySILOFigure  4.
Average ranking of the correct response in a listof responses returned by SILO, as a function of the size ofthe index.
A score of 0 indicates that the desired responsewas not returned.
100 indicates that it was returned at thetop of the list.
