Coling 2010: Poster Volume, pages 409?417,Beijing, August 2010Recognizing Relation Expression between Named Entities based onInherent and Context-dependent Features of Relational wordsToru Hirano?, Hisako Asano?, Yoshihiro Matsuo?, Genichiro Kikui?
?NTT Cyber Space Laboratories, NTT Corporation?Innovative IP Architecture Center, NTT Communications Corporationhirano.tohru@lab.ntt.co.jphisako.asano@ntt.com{matsuo.yoshihiro,kikui.genichiro}@lab.ntt.co.jpAbstractThis paper proposes a supervised learn-ing method to recognize expressions thatshow a relation between two named en-tities, e.g., person, location, or organiza-tion.
The method uses two novel fea-tures, 1) whether the candidate words in-herently express relations and 2) how thecandidate words are influenced by the pastrelations of two entities.
These featurestogether with conventional syntactic andcontextual features are organized as a treestructure and are fed into a boosting-basedclassification algorithm.
Experimental re-sults show that the proposed method out-performs conventional methods.1 IntroductionMuch attention has recently been devoted to us-ing enormous amount of web text covering an ex-ceedingly wide range of domains as a huge knowl-edge resource with computers.
To use web texts asknowledge resources, we need to extract informa-tion from texts that are merely sequences of wordsand convert them into a structured form.
Althoughextracting information from texts as a structuredform is difficult, relation extraction is a way thatmakes it possible to use web texts as knowledgeresources.The aim of relation extraction is to extract se-mantically related named entity pairs, X and Y ,and their relation, R, from a text as a struc-tured form [X , Y , R].
For example, the triple[Yukio Hatoyama, Japan, prime minister] wouldbe extracted from the text ?Yukio Hatoyama is theprime minister of Japan?.
This extracted tripleprovides important information used in informa-tion retrieval (Zhu et al, 2009) and building anontology (Wong et al, 2010).It is possible to say that all named entity pairsthat co-occur within a text are semantically relatedin some way.
However, we define that named en-tity pairs are semantically related if they satisfyeither of the following rules:?
One entity is an attribute value of the other.?
Both entities are arguments of a predicate.Following the above definition, explicit and im-plicit relations should be extracted.
An explicit re-lation means that there is an expression that showsthe relation between a named entity pair in a giventext, while an implicit relation means that there isno such expression.
For example, the triple [YukioHatoyama, Kunio Hatoyama, brother] extractedfrom the text ?Yukio Hatoyama, the DemocraticParty, is Kunio Hatoyama?s brother?
is an explicitrelation.
In contrast, the triple [Yukio Hatoyama,the Democratic Party, member] extracted from thesame text is an implicit relation because there isno expression showing the relation (e.g.
member)between ?Yukio Hatoyama?
and ?the DemocraticParty?
in the text.Extracting triples [X , Y , R] from a text in-volves two tasks.
One is detecting semanticallyrelated pairs from named entity pairs that co-occurin a text and the other is determining the rela-tion between a detected pair.
For the former task,various supervised learning methods (Culotta andSorensen, 2004; Zelenko et al, 2003; Hirano etal., 2007) and bootstrapping methods (Brin, 1998;Pantel and Pennacchiotti, 2006) have been ex-plored to date.
In contrast, for the latter task,409only a few methods have been proposed so far(Hasegawa et al, 2004; Banko and Etzioni, 2008;Zhu et al, 2009).
We therefore addressed theproblem of how to determine relations between agiven pair.We used a three-step approach to address thisproblem.
The first step is to recognize an expres-sion that shows explicit relations between a givennamed entity pair in a text.
If no such expressionis recognized, the second step is to estimate therelationship that exists between a given named en-tity pair that has an implicit relation.
The last stepis to identify synonyms of the relations that arerecognized or estimated in the above steps.
In thispaper, we focus on the first step.
The task is se-lecting a phrase from the text that contains a re-lation expression linking a given entity pair andoutputting the expression as one showing the rela-tionship between the pair.In our preliminary experiment, it was foundthat using only structural features of a text, suchas syntactic or contextual features, is not goodenough for a number of examples.
For instance,the two Japanese sentences shown in Figure 1have the same syntactic structure but (a) contains arelation expression and (b) does not.
We thereforeassume there are clues for recognizing relationexpressions other than conventional syntactic andcontextual information.
In this paper, we proposea supervised learning method that includes twonovel features of relational words as well as con-ventional syntactic and contextual features.
Thenovel features of our method are:Inherent Feature: Some words are able to ex-press the relations between named entitiesand some are not.
Thus, it would be useful toknow the words that inherently express theserelations.Context-dependent Feature: There are a num-ber of typical relationships that change astime passes, such as ?dating?
?
?engage-ment?
?
?marriage?
between persons.
Fur-thermore, present relations are influenced bythe past relations of a given named entitypair.
Thus, it would be useful to know thepast relations between a given pair and howthe relations change as time passes.In the rest of this paper, Section 2 references re-lated work, Section 3 outlines our method?s mainfeatures and related topics, Section 4 describes ourexperiments and experimental results, and Section5 briefly summarizes key points and future workto be done.2 Related WorkThe ?Message Understanding Conference?
and?Automatic Content Extraction?
programs havepromoted relational extraction.
The task was stud-ied so as to extract predefined semantic relationsof entity pairs in a text.
Examples include thesupervised learning method cited in (Kambhatla,2004; Culotta and Sorensen, 2004; Zelenko et al,2003) and the bootstrapping method cited in (Pan-tel and Pennacchiotti, 2006; Agichtein and Gra-vano, 2000).
Recently, open information extrac-tion (Open IE), a novel domain-independent ex-traction paradigm, has been suggested (Banko andEtzioni, 2008; Hasegawa et al, 2004).
The task isto detect semantically related named entity pairsand to recognize the relation between them with-out using predefined relations.Our work is a kind of open IE, but our approachdiffers from that of previous studies.
Banko(2008) proposed a supervised learning method us-ing conditional random fields to recognize the re-lation expressions from words located between agiven pair.
Hasegawa (2004) also proposed a rule-based method that selects all words located be-tween a given pair as a relation expression if agiven named entities appear within ten words.
Thepoint of these work is that they selected relationexpressions only from the words located betweenOsaka Fucho01-nosaka ucho01-noKacho02-noacho02-noYumei04-desu.u ei04-desu.Suzuki03-san-wauzuki03-san- aDDDOsaka Fucho05-nosaka ucho05-noSoumukyoku06-noou ukyoku06-noYumei08-desu.u ei08-desu.Suzuki07-san-wauzuki07-san- aDDD(a)Mr.Suzuki03, a manager02of Osaka Prefectural Government01, is famous04.
(b)Mr.Suzuki07, administration office06in Osaka PrefecturalGovernment05, is famous08.
(a) (b)Figure 1: Same syntactic examples410given entities in the text, because as far as Englishtexts are concerned, 86% of the relation expres-sions of named entity pairs appear between thepair (Banko and Etzioni, 2008).
However, our tar-get is Japanese texts, in which only 26% of entitypair relation expressions appear between the pair.Thus, it is hard to incorporate previous approachesinto a Japanese text.To solve the problem, our task was to select aphrase from the entire text that would include arelation expression for connecting a given pair.3 Recognizing Relation Expressionsbetween Named EntitiesTo recognize the relation expression for a givenpair, we need to select a phrase that includes anexpression that shows the relation between a givenentity pair from among all noun and verb phrasesin a text.
Actually, there are two types of candi-date phrases in this case.
One is from a sentencethat contains a given pair (intra-sentential), andthe other is from a sentence that does not (inter-sentential).
For example, the triple [Miyaji21,Ishii22, taiketsu12] extracted from the followingtext is inter-sentential.
(S-1) Chumokoku11-no taiketsu12-gamamonaku13 hajimaru14.
(The showcase11 match12 will start14 soon13.
)(S-2) Ano Miyaji21-to Ishii22-toiukanemochi23-niyoru yume24-nokikaku25.
(The dream24 event25 between the rich mens23,Miyaji21 and Ishii22.
)According to our annotated data shown in Ta-ble 2, 53% of the semantically-related named en-tity pairs are intra-sentential and 12% are inter-sentential.
Thus, we first select a phrase fromthose in a sentence that contains a given pair, andif no phrase is selected, select one from the rest ofthe sentences in a text.We propose a supervised learning method thatuses two novel features of relational words aswell as conventional syntactic and contextual fea-tures.
These features are organized as a tree struc-ture and are fed into a boosting-based classifica-tion algorithm (Kudo and Matsumoto, 2004).
Thehighest-scoring phrase is then selected if the scoreexceeds a given threshold.
Finally, the head of theselected phrase is output as the relation expressionof a given entity pair.The method consists of four parts: preprocess-ing (POS tagging and parsing), feature extraction,classification, and selection.
In this section, wedescribe the idea behind using our two novel fea-tures and how they are implemented to recognizethe relation expressions of given pairs.
Beforethat, we will describe our proposed method?s con-ventional features.3.1 Conventional FeaturesSyntactic featureTo recognize the intra-sentential relation ex-pressions for a given pair, we assume that thereis a discriminative syntactic structure that consistsof given entities and their relation expression.
Forexample, there is a structure for which the com-mon parent phrase of the given pair, X = ?Ha-toyama Yukio32?
and Y = ?Hatoyama Kunio33?,has the relation expression, R = ?ani34?
in theJapanese sentence S-3.
Figure 2 shows the depen-dency tree of sentence S-3.
(S-3) Minshuto31-no Hatoyama Yukio32-waHatoyama Kunio33-no ani34-desu.
(Yukio Hatoyama32, the Democratic Party31,is Kunio Hatoyama33?s brother34.
)To use a discriminative structure for each can-didate, we make a minimum tree that consists ofgiven entities and the candidate where each phraseis represented by a case marker ?CM?, a depen-dency type ?DT?, an entity class, and the stringand POS of the candidate (See Figure 3).Minshuto31-noinshuto31-noHatoyama Yukio32-waatoya a ukio32- aAni34-desu.ni34-desu.Hatoyama Kunio33-noatoya a unio33-noDD DFigure 2: Dependency tree of sentence S-3411X:person:personPhrasehrasePhrasehraseCandidateandidatePhrasehraseY:person:personCM:wa: a DT:D:STR:Ani34: ni34POS:Noun: ounCM:?
: DT:O:CM:no:no DT:D: Inh:1Inh:1Crank:1rank:1Cprob:0.23prob:0.23Figure 3: Intra-sentential feature treeContextual FeatureTo recognize the inter-sentential relation ex-pressions for a given pair, we assume that thereis a discriminative contextual structure that con-sists of given entities and their relation expression.Here, we use a Salient Referent List (SRL) to ob-tain contextual structure.
The SRL is an empiricalsorting rule proposed to identify the antecedentof (zero) pronouns (Nariyama, 2002), and Hirano(2007) proposed a way of applying SRL to rela-tion detection.
In this work, we use this way toapply SRL to recognize inter-sentential relationexpressions.We applied SRL to each candidate as follows.First, from among given entities and the candi-date, we choose the one appearing last in the textas the root of the tree.
We then append nounphrases, from the chosen one to the beginning ofthe text, to the tree depending on case markers,?wa?
(topicalised subject), ?ga?
(subject), ?ni?
(indirect object),?wo?
(object), and ?others?, withthe following rules.
If there are nodes of the samecase marker already in the tree, the noun phraseis appended as a child of the leaf node of them.In other cases, the noun phrase is appended as achild of the root node.
For example, we get theSRL tree shown in Figure 4 with the given entitypair, X = ?Miyaji21?
and Y = ?Ishii22?, and thecandidate, ?taiketsu12?, with the text (S-1, S-2).To use a discriminative SRL structure, we makea minimum tree that consists of given entities andthe candidate where each phrase is represented byan entity class, and the string and POS of the can-didate (See Figure 5).
In this way, there is a prob-lem when the candidate is a verb phrase, becausega: Taiketsu12ga: aiketsu12Ishii22Ishii22others: Miyaji21others: iyaji21others: Chumoku11others: hu oku11Figure 4: Salient referent list treeonly noun phrases are appended to the SRL tree.If the candidate is a verb phrase, we cannot makea minimum tree that consists of given entities andthe candidate.To solve this problem, a candidate verb phraseis appended to the feature tree using a syntacticstructure.
In a dependency tree, almost all verbphrases have some parent or child noun phrasesthat are in the SRL tree.
Thus, candidate verbphrases are appended as offspring of these nounphrases represented syntactically as ?parent?
or?child?.
For example, when given the entity pair,X = ?Miyaji21?
and Y = ?Ishii22?, and the can-didate, ?hajimaru14?
from the text (S-1, S-2), afeature tree cannot be made because the candi-date is not in an SRL tree.
By extending the waythe syntactic structure is used, ?hajimaru14?
has achild node ?taiketsu12?, which is in an SRL tree,and this makes it possible to make the feature treeshown in Figure 6.3.2 Proposed FeaturesTo recognize intra-sentential or inter-sentential re-lation expressions for given pairs, we assumethere are clues other than syntactic and contex-tual information.
Thus, we propose inherent andSRL:gaL:ga CandidateandidateY:person:personX:person:personSRL:othersL:othersSTR:Taiketsu12: aiketsu12POS:Noun: ounInh:1Inh:1 Crank:1rank:1 Cprob:0.23prob:0.23Figure 5: Inter-sentential feature tree412SRL:gaL:gaDep:Childep: hild CandidateandidateY:person:person X:person:personSRL:othersL:othersSTR:Hajimaru14: aji aru14POS:Verb: erbInh:0Inh:0 Crank:2rank:2 Cprob:0.00prob:0.00Figure 6: Extended inter-sentential feature treecontext-dependent features of relational words.Inherent Feature of Relational wordsSome words are able to express the relations be-tween named entities and some are not.
For exam-ple, the word ?mother?
can express a relation, butthe word ?car?
cannot.
If there were a list of wordsthat could express relations between named enti-ties, it would be useful to recognize the relationexpression of a given pair.
As far as we know,however, no such list exists in Japanese.
Thus,we estimate which words are able to express rela-tions between entities.
Here, we assume that al-most all verbs are able to express relations, andaccordingly we focus on nouns.When the relation expression, R, of an entitypair, X and Y , is a noun, it is possible to say ?Y isR of X?
or ?Y is X?s R?.
Here, we can say nounR takes an argument X .
In linguistics, this kindof noun is called a relational noun.
Grammaticallyspeaking, a relational noun is a simple noun, butbecause its meaning describes a ?relation?
ratherthan a ?thing?, it is used to describe relations justas prepositions do.
To estimate which nouns areable to express the relations between named enti-ties, we use the characteristics of relational nouns.In linguistics, many researchers describe the rela-tionship between possessives and relational nouns(Chris, 2008).
Thus, we use the knowledge thatin the patterns ?B of A?
or ?A?s B?, if word B isa relational noun, the corresponding word A be-longs to a certain semantic category.
In contrast,if word B is not a relational noun, the correspond-ing word A belongs to many semantic categories(Tanaka et al, 1999).
Figure 7 shows scatteringof the semantic categories of ?mother?
and ?car?Semantic categoriesRelativeFrequencySemantic categoriesRelativeFrequencyFigure 7: Scattering of semantic category of?mother?
(left) and ?car?
(right).acquired by the following way.First, we acquired A and B using the patterns?A no B?1 from a large Japanese corpus, thenmapped words A into semantic categories C= {c1, c2, ?
?
?
, cm } using a Japanese lexicon (Ikeharaet al, 1999).
Next, for each word B, we calcu-lated a scattering score Hc(B) using the semanticcategory of corresponding words A.
Finally, weestimated whether a word is a relational noun byusing k-NN estimation with positive and negativeexamples.
As estimated results, ?Inh:1?
showsthat it is a relational noun and ?Inh:0?
shows thatit is not.
In both cases, the result is appended tothe feature tree as a child of the candidate node(See Figure 3, 5, or 6).Hc(B) = ?
?c?CP (c|B)logmP (c|B)P (c|B) = freq(c,B)freq(B)In our experiments, we acquired 55,412,811pairs of A and B from 1,698,798 newspaper ar-ticles and 10,499,468 weblog texts.
As trainingdata, we used the words of relation expressions aspositive examples and other words as negative ex-amples.Context-dependent Feature of RelationalwordsThere are a number of typical relationships thatchange as time passes, such as ?dating?
?
?en-gagement?
?
?marriage?
between persons.
Fur-thermore, present relations are affected by the pastrelations of a given named entity pair.
For in-stance, if the past relations of a given pair are ?dat-ing?
and ?engagement?
and one of the candidatesis ?marriage?, ?marriage?
would be selected as therelation expression of the given pair.
Therefore, if1?B of A?
or ?A?s B?
in English.413Pair of entity class rm rn PT (rn|rm) Count(rm, rn)dating 0.050 102?person,person?
dating marriage 0.050 101engagement 0.040 82marriage 0.157 786?person,person?
engagement engagement 0.065 325wedding 0.055 276president 0.337 17,081?person,organization?
vice president vice president 0.316 16,056CEO 0.095 4,798fellow 0.526 61?person,organization?
researcher manager 0.103 12member 0.078 9alliance 0.058 8,358?organization,organization?
alliance accommodated 0.027 3,958acquisition 0.027 3,863mutual consultation 0.022 2,670?location,location?
neighbour support 0.015 1,792visit 0.012 1,492war 0.077 78,170?location,location?
war mutual consultation 0.015 15,337support 0.010 10,226Table 1: Examples of calculated relation trigger model between entity classes defined by IREXwe know the past relations of the given pair andthe typical relational change that occurs as timepasses, it would be useful to recognize the rela-tion expression of a given pair.In this paper, we represent typical relationalchanges that occur as time passes by a simple re-lation trigger model PT (rn|rm).
Note that rmis a past relation and rn is a relation affected byrm.
This model disregards the span between rnand rm.
To make the trigger model, we automat-ically extract triples [X , Y , R] from newspaperarticles and weblog texts, which have time stampsof the document creation.
Using these triples withtime stamps for each entity pair, we sort rela-tions in order of time and count pairs of presentand previous relations.
For example, if we ex-tract ?dating?
occurring for an entity pair on Jan-uary 10, 1998, ?engagement?
occurring on Febru-ary 15, 2001, and ?marriage?
occurring on De-cember 24, 2001, the pairs ?dating, engagement?,?dating, marriage?, and ?engagement, marriage?are counted.
The counted score is then summedup by the pair of entity class and the trigger modelis calculated by the following formula.PT (rn|rm) =Count(rm, rn)?rn Count(rm, rn)For the evaluation, we extracted triples bynamed entity recognition (Suzuki et al, 2006), re-lation detection (Hirano et al, 2007), and the pro-posed method using the inherent features of rela-tional words described in Section 3.2.
A total of10,463,232 triples were extracted from 8,320,042newspaper articles and weblog texts with timestamps made between January 1, 1991 and June30, 2006.
As examples of the calculated relationtrigger model, Table 1 shows the top three proba-bility relations rn of several relations rm betweenJapanese standard named entity classes definedin the IREX workshop2.
For instance, the rela-tion ?fellow?
has the highest probability of beingchanged from the relation ?researcher?
betweenperson and organization as time passes.2http://nlp.cs.nyu.edu/irex/414To obtain the past relations of a given pair inthe input text, we again used the triples with timestamps extracted as above.
The only relations weuse as past relations, Rm = {rm1 , rm2 , ?
?
?
, rmk},are those of a given pair whose time stamps areolder than the input text.
Finally, we calcu-lated probabilities with the following formula us-ing the past relations Rm and the trigger modelPT (rn|rm).PT (rn|Rm) = max{PT (rn|rm1),PT (rn|rm2), ?
?
?
, PT (rn|rmk)}Using this calculated probability, we rankedcandidates and appended the rank ?Crank?
andthe probability score ?Cprob?
to the feature treeas a child of the candidate node (See Figure 3,5, or 6).
For example, if the past relations Rmwere ?dating?
and ?engagement?
and candidateswere ?marriage?, ?meeting?, ?eating?, or ?drink-ing?, the candidates probabilities were calculatedand ranked as ?marriage?
(Cprob:0.15, Crank:1),?meeting?
(Cprob:0.08, Crank:2), etc.3.3 Classification AlgorithmsSeveral structure-based learning algorithms havebeen proposed so far (Collins and Duffy, 2002;Suzuki et al, 2003; Kudo and Matsumoto, 2004).The experiments tested Kudo and Matsumoto?sboosting-based algorithm using sub-trees as fea-tures, which is implemented as a BACT system.Given a set of training examples each of whichis represented as a tree labeling whether the can-didate is the relation expression of a given pair ornot, the BACT system learns that a set of rulesis effective in classifying.
Then, given a test in-stance, the BACT system classifies using a set oflearned rules.4 ExperimentsWe conducted experiments using texts fromJapanese newspaper articles and weblog texts totest the proposed method for both intra- and inter-sentential tasks.
In the experiments, we comparedthe following methods:Conventional Features: trained by conventionalsyntactic features for intra-sentential tasks asRelation Types #Explicit Intra-sentential 9,178Inter-sentential 2,058Implicit 5,992Total 17,228Table 2: Details of the annotated datadescribed in Section 3.1, and contextual fea-tures for inter-sentential tasks as described inSection 3.1.+Inherent Features: trained by conventionalfeatures plus inherent features of relationalwords described in Section 3.2.++Context-dependent FeaturesTM: trainedby conventional and inherent features pluscontext-dependent features of relationalwords with the trigger model described inSection 3.2.++Context-dependent FeaturesCM: trainedby conventional and inherent featuresplus context-dependent features of rela-tional words with a cache model.
Weevaluated this method to compare it withContext-dependent FeaturesTM to show theeffectiveness of the proposed trigger model.The cache model is a simple way to use pastrelations in which the probability PC(rcand)calculated by the following formula and therank based on the probability is appended toevery candidate feature tree.PC(rcand) =|rcand in past relations||past relations|4.1 SettingsWe used 6,200 texts from Japanese newspapersand weblogs dated from January 1, 2004 to June30, 2006, manually annotating the semantic rela-tions between named entities for experiment pur-poses.
There were 17,228 semantically-relatedentity pairs as shown in Table 2.
In an intra-sentential experiment, 17,228 entity pairs weregiven, but only 9,178 of them had relation expres-sions.
In contrast, in an inter-sentential experi-ment, 8,050 entity pairs excepted intra-sentential415Precision Recall FConventional Features 63.5?
(3,436/5,411) 37.4?
(3,436/9,178) 0.471+Inherent Features 67.2?
(4,036/6,001) 43.9?
(4,036/9,178) 0.531++Context-dependent FeaturesTM 70.7?
(4,460/6,312) 48.6?
(4,460/9,178) 0.576++Context-dependent FeaturesCM 67.5?
(4,042/5,987) 44.0?
(4,042/9,178) 0.533Table 3: Experimental results of intra-sententialPrecision Recall FConventional Features 70.1?
(579/825) 28.1?
(579/2,058) 0.401+Inherent Features 77.1?
(719/932) 34.9?
(719/2,058) 0.480++Context-dependent FeaturesTM 75.2?
(794/1,055) 38.5?
(794/2,058) 0.510++Context-dependent FeaturesCM 74.3?
(732/985) 35.5?
(732/2,058) 0.481Table 4: Experimental result of inter-sententialwere given, but only 2,058 of them had relationexpressions.We conducted five-fold cross-validation over17,228 entity pairs so that sets of pairs from a sin-gle text were not divided into the training and testsets.
In the experiments, all features were auto-matically acquired using a Japanese POS tagger(Fuchi and Takagi, 1998) and dependency parser(Imamura et al, 2007).4.2 ResultsTables 3 and 4 show the performance of severalmethods for intra-sentential and inter-sentential.Precision is defined as the percentage of cor-rect relation expressions out of recognized ones.Recall is the percentage of correct relation ex-pressions from among the manually annotatedones.
The F measure is the harmonic mean ofprecision and recall.A comparison with the Conventional Fea-tures and Inherent Features method for intra-/inter-sentential tasks indicates that the proposedmethod using inherent features of relational wordsimproved intra-sentential tasks F by 0.06 pointsand inter-sentential tasks F by 0.08 points.
Us-ing a statistical test (McNemar Test) demonstrablyshowed the proposed method?s effectiveness.A comparison with the Inherent Features andContext-dependent FeaturesTM method showedthat the proposed method using context-dependentfeatures of relational words improved intra-/inter-sentential task performance by 0.045 and 0.03points, respectively.
McNemar test results alsoshowed the method?s effectiveness.To further compare the usage of context-dependent features, trigger models, and cachemodels, we also used Context-dependentFeaturesCM method for comparison.
Tables3 and 4 show that our proposed trigger modelperformed better than the cache model, andMcNemar test results showed that there was asignificant difference between the models.
Thereason the trigger model performed better thanthe cache model is that the trigger model correctlyrecognized the relation expressions that did notappear in the past relations of a given pair.
Thus,we can conclude that using typical relationshipsthat change as time passes helps to recognizerelation expressions between named entities.5 ConclusionWe proposed a supervised learning method thatemploys inherent and context-dependent featuresof relational words and uses conventional syntac-tic or contextual features to improve both intra-and inter-sentential relation expression recogni-tion.
Our experiments demonstrated that themethod improves the F measure and thus helpsto recognize relation expressions between namedentities.In future work, we plan to estimate implicit re-lations between named entities and to identify re-lational synonyms.416ReferencesAgichtein, Eugene and Luis Gravano.
2000.
Snow-ball: Extracting relations from large plain-text col-lections.
In Proceedings of the 5th ACM conferenceon Digital libraries, pages 85?94.Banko, Michele and Oren Etzioni.
2008.
The tradeoffsbetween open and traditional relation extraction.
InProceedings of the 46th Annual Meeting on Associ-ation for Computational Linguistics: Human Lan-guage Technologies, pages 28?36.Brin, Sergey.
1998.
Extracting patterns and rela-tions from the world wide web.
In WebDB Work-shop at 6th International Conference on ExtendingDatabase Technology, pages 172?183.Chris, Barker, 2008.
Semantics: An internationalhandbook of natural language meaning, chap-ter Possessives and relational nouns.
Walter DeGruyter Inc.Collins, Michael and Nigel Duffy.
2002.
Convolutionkernels for natural language.
Advances in NeuralInformation Processing Systems, 14:625?632.Culotta, Aron and Jeffrey Sorensen.
2004.
Depen-dency tree kernels for relation extraction.
In Pro-ceedings of the 42nd Annual Meeting on Associationfor Computational Linguistics, pages 423?429.Fuchi, Takeshi and Shinichiro Takagi.
1998.
Japanesemorphological analyzer using word co-occurrence- jtag.
In Proceedings of the 36th Annual Meet-ing of the Association for Computational Linguis-tics and 17th International Conference on Compu-tational Linguistics, volume 1, pages 409?413.Hasegawa, Takaaki, Satoshi Sekine, and Ralph Grish-man.
2004.
Discovering relations among namedentities from large corpora.
In Proceedings of the42nd Annual Meeting on Association for Computa-tional Linguistics, pages 415?422.Hirano, Toru, Yoshihiro Matsuo, and Genichiro Kikui.2007.
Detecting semantic relations between namedentities in text using contextual features.
In Pro-ceedings of the 45th Annual Meeting on Associationfor Computational Linguistics, pages 157?160.Ikehara, Satoru, Masahiro Miyazaki, Satoru Shirai,Akio Yoko, Hiromi Nakaiwa, Kentaro Ogura, Masa-fumi Oyama, and Yoshihiko Hayashi.
1999.
Ni-hongo Goi Taikei (in Japanese).
Iwanami Shoten.Imamura, Kenji, Genichiro Kikui, and Norihito Ya-suda.
2007.
Japanese dependency parsing using se-quential labeling for semi-spoken language.
In Pro-ceedings of the 45th Annual Meeting on Associationfor Computational Linguistics, pages 225?228.Kambhatla, Nanda.
2004.
Combining lexical, syntac-tic, and semantic features with maximum entropymodels for extracting relations.
In Proceedings ofthe 42nd Annual Meeting on Association for Com-putational Linguistics, pages 178?181.Kudo, Taku and Yuji Matsumoto.
2004.
A boostingalgorithm for classification of semi-structured text.In Proceedings of the 2004 Conference on Empiri-cal Methods in Natural Language Processing, pages301?308.Nariyama, Shigeko.
2002.
Grammar for ellipsis res-olution in japanese.
In Proceedings of the 9th In-ternational Conference on Theoretical and Method-ological Issues in Machine Translation, pages 135?145.Pantel, Patrick and Marco Pennacchiotti.
2006.Espresso: Leveraging generic patterns for automat-ically harvesting semantic relations.
In Proceed-ings of the 21st International Conference on Com-putational Linguistics and the 44th annual meetingof the Association for Computational Linguistics,pages 113?120.Suzuki, Jun, Tsutomu Hirao, Yutaka Sasaki, andEisaku Maeda.
2003.
Hierarchical directed acyclicgraph kernel: Methods for structured natural lan-guage data.
In Proceedings of the 41st AnnualMeeting on Association for Computational Linguis-tics, pages 32?39.Suzuki, Jun, Erik McDermott, and HIdeki Isozaki.2006.
Training conditional random fields with mul-tivariate evaluation measures.
In Proceedings of the43th Annual Meeting on Association for Computa-tional Linguistics.Tanaka, Shosaku, Yoichi Tomiura, and Toru Hitaka.1999.
Classification of syntactic categories ofnouns by the scattering of semantic categories (injapanese).
Transactions of Information ProcessingSociety of Japan, 40(9):3387?3396.Wong, Wilson, Wei Liu, and Mohammed Bennamoun.2010.
Acquiring semantic relations using the webfor constructing lightweight ontologies.
In Proceed-ings of the 13th Pacific-Asia Conference on Knowl-edge Discovery and Data Mining.Zelenko, Dmitry, Chinatsu Aone, and AnthonyRichardella.
2003.
Kernel methods for relation ex-traction.
Journal of Machine Learning Research,3:1083?1106.Zhu, Jun, Zaiqing Nie, Xiaojing Liu, Bo Zhang, andJi-Rong Wen.
2009.
Statsnowball: a statistical ap-proach to extracting entity relationships.
In Pro-ceedings of the 18th international conference onWorld Wide Web, pages 101?110.417
