Using a Probabil istic Class-Based Lexiconfor Lexical Ambiguity ResolutionDet le f  P rescher  and Ste fan  R iez le r  and Mats  RoothInst i tut  fiir Maschinelle S1)rachvcrarbeitungUniversitSt Stuttgart ,  GermanyAbst ractThis paper presents the use of prot)abilistieclass-based lexica tbr dismnbiguati(m in target-woxd selection.
Our method emlfloys nfinimal1)llt; precise contextual information for disam-biguation.
That is, only information providedby the target-verb, enriched by the condensedinformation of a probabilistic class-based lexi-con, is used.
Induction of classes and fine-tuningto verbal arguments i done in an unsupervisedmanner by EM-lmsed clustering techniques.
Themethod shows pronlising results in an evaluationon real-world translations.1 I n t roduct ionDisambiguation of lexical ambiguities in nat-urally oceuring free text is considered a hardtask for computational linguistics.
For instance,word sense disa.inbiguatiol~ is concerned with theprotflem of assigning sense labels to occurrencesof an ambiguous word.
Resolving such ambi-guil;ies is useful in constraining semantic inter-pretation.
A related task is target-word isam-biguation in machine translation.
Here a deci-sion has to be made which of a set of alterna-tive target-language words is the most appro-priate translation of a source-language word.
Asohltion to this disambiguation problem is di-rectly applicable in a machine translation sys-tem which is able to propose the translation al-ternatives.
A further problem is the resolutionof attachment ambiguities in syntactic parsing.Here the decision of verb versus argunlent at-ta&ment of noun phrases, or the choice for verbphrase versus noun phrase attachment of prepo-sitional phrases Call build upon a resolution ofthe related lexical mnbiguities.Statistical approaches have been applied suc-cessfully to these 1)roblems.
The great advantageof statistical methods over symbolic-linguisticmethods has been deemed to be their effec-tive exploitation of minimal linguist;it knowl-edge.
However, the best performing statisti-cal approaches to lexical ambiguity resolutionl;lmmselves rely on complex infornmtion sourcessuch as "lemmas, inflected forms, parts of speechand arbitrary word classes If-.. \] local and dis-tant collocations, trigram sequences, a.nd predi-cate m'gument association" (Yarowsky (1995), p.190) or large context-windows up to 1000 neigh-boring words (Sch/itze, 1992).
Unfortmmtely, inmany applications uch information is not read-ily available.
For instance, in incremental ma-chine translation, it may be desirable to decidefor the most probable translation of the argu-ments of a verb with only the translation of theverb as information source lint no large windowof sun'ounding translations available.
In parsing,the attachment of a nolninal head nlay haa~e tobe resolved with only information al)out the se-mmltic roles of the verb but no other predi('ateargument associations at; hand.The aim of this paper is to use only nfinimal,but yet precise information fbr lexical ambiguityresolution.
We will show that good results areobtainable by employing a simple and naturallook-up in a probabilistic lass-labeled lexiconfor disambiguation.
The lexicon provides a prob-ability distribution on semantic selection-classeslabeling the slots of verbal subcategorizationframes.
Induction of distributions on frames andclass-labels is accomplished in an unsupervisedmanner by applying the EM Mgorittnn.
Disam-biguation then is done by a simple look-up in theprobabilistie lexicon.
We restrict our attentionto a definition of senses as alternative transla-tions of source-words.
Our approach provides avery natural solution for such a target-languagedisambiguation task--look for the most fl'equenttarget-noun whose semantics fits best with the649Class  19PROB 0 .02350 .06290 .03860 .03210 .02360 .02260 .02140 .01730 .01360 .01320 .01260 .01240 .01150 .01130 .01080 .00090 .00860 .00850 .00820 .00820 .0082enter .aso :ocover .aso :oca l l .aso :oi nc lude .aso :ol 't l lh &SO ; Oa t tend .aso :ocross .aso :odominate .aso :ohave .aso :sat t rac t .aso :soccupy .aso :oinc lude .aso :sCOllt aJ n,  ~-'~s o :SbeCOlne,g8:Sfo rn l .aso :oco l lapse .as :scre l~te.aso:oprov ide .aso :so rga l l i ze .aso :oo f fe r .aso :sd c:; c5 d d d d d d d d d d d d ~ d c; d c:; d d d c5 d d d d c:; 6?
?
??
?
??
??
?
??
?
?o?
?
??
?
?
?
?
?
* ?
??
?
?
?
?
?
?
?
?
el ?
?
??
?
?
?
?
?
?
?
?
??
?
?
?
?
?
?
?
?
??
?
?
?
?
?
?
?
?
?
?
??
?
?
?
?
?
?
?
?
?
?
?Figure 1: Class 19: "locative action".
At the top are listed the 20 most t:)robable nouns in thepLc(n119 ) distribution and their probabilities, and at leg are tile 30 most probable verbs in thepLC(V 119) distribution.
19 is the class index.
Those verb-noun pairs which were seen in the trainingdata appear with a dot in the class matrix.
Verbs with suffix .as : s indicate the subject slot of anactive intransitive.
Similarily .aso : s denotes the subject slot of an active transitive, and .aso : odenotes the object slot of an active transitive.semantics required by the target-verb.
We eval-uated this simple method on a large number ofreal-world translations and got results compara-ble to related approaches such as that of Daganand Itai (1994) where much more selectional in-t!ormation is used.2 Lex icon  Induct ion  v ia EM-BasedC lus ter ing2.1 EM-Based ClusteringFor clustering, we used the method describedin Rooth et al (1999).
There classes are de-rived from distributional data a sample ofpairs of verbs and nouns, gathered by parsingan unannotated corpus and extracting tile fillersof grammatical relations.
The semanticallysmoothed probability of a pair (v,n) is calcu-lated in a latent class (LC) model as pLC(V, n) =~<cPLC(C, v,'n).
The joint distribution is de-fined by PLC(C, v, n) = PLC(C)PLc(V\[C)PLC(nIC ).By construction, conditioning of v and n oneach other is solely made through the classesc.
The parameters PLC(C), PLC(V\[C), PLC(n\[c)are estilnated by a particularily silnple versionof tile EM algorithm for context-free models.Input to our clustering algorithm was a train-ing corpus of 1,178,698 tokens (608,850 types)of verb-noun pairs participating in the gram-matical relations of intransitive and transitiveverbs and their subject- and object-fillers.
Fig.1 shows an induced class froln a model with 35classes.
Induced classes often have a basis in lex-ical semantics; class 19 can be interpreted aslocative, involving location nouns "room", "are?
',and "world" and verbs as "enter" and "cross".2.2 Probabil ist ic Labeling with LatentClasses using EM-est imat ionTo induce latent classes tbr the object slot; of afixed transitive verb v, another statistical infer-ence step was performed.
Given a latent classmodal PLC(') Ibr verb-noun pairs, and a sam-ple n l , .
.
.
,  nM of objects for a fixed transitiveverb, we calculate tile probability of ml arbitraryobject noun ,I, I~ N by p(n) = ~<cP(C,  ~;,) =~<c P(c)pLc(n'Ic)" This fine-tuning of the classparameters p(c) to tile sample of objects for afixed verb is formalized again as a simple in-stance of the EM algorithm.
In an experimentwith English data, we used a clustering modelwith 35 classes.
From the maximum probabil-650ity pm:ses derived fl)r the British National Cor-pus with the head-lexicalized parser of Carrolland Rooth (1.998), we extracted frequency ta-bles tbr transitive verb-noun pairs.
These tableswere used to induce a small class-labeled lexicon(336 verbs).cross.aso:o 19 0.692mind 74.2road 30.3line 28.11)ridge 27.5room 20.5t)order 17.8l)oundary 16.2river 14.6street 11.5atlantic 9.9mobilize.aso:o 6 0.386h)rce 2.00t)eoi)le 1.95army 1.46sector 0.90society 0.90worker 0.90meinber 0.88company 0.86majority 0.85party 0.80lID 160867) Es gibt einigc alte Passvorschriften, die.
be-sagen, dass man cinch Pass habcn muss, wcnn man dicGrenze iiberschreitct.
There are some old provisions re-ga.rding passports which state that people crossing the{border/ frontier/ boundary/ limit/ periphery/edge} shoukI have their 1)assl)ort on them.lID 201946) Es 9ibt sehlie.sslich keinc L5sung ohnedie Mobilisierung der bii~yerlichen Gesellschaft unddie Solidaritiit dcr Dcmok,nten in der 9anzcn Welt.Ttmrc can be no solution, tinally, mflcss civilian {com-pany/  society/companionship/party/associate}is mobilized and solidarity demonstrated bydemocratsthroughout the world.Figure 3: Exami)les for target-word ambiguitiesFigure 2: Estinmted fl:equencies of the objectsof' the transitive verbs cross and mobi l izeFig.
2 shows the topmost parts of the lexicalentries for the transitive verbs cross and mo-bilize.
Class 19 is the most prol)abh ~,class-labelfor the ol)jeet-slot of cross (prol)al)ility 0.692);tl~e objects of mobi l ize belong with prol)ability0.386 to class 16, which is the most probable(:lass for this slot.
Fig.
2 shows for each verb thete l l  llOllllS 'It with highest estimated frequencies.l',,('n,) = f (n)p(cln), where .
f lu) is the fre(\]ll(~.ll(:yof n in the sample v,l, ?
?
?
, 'n,M.
For example, theDequency of seeing mind as object of c,ro.ss isestimated as 74.2 times, and the most fl'equentobject of mobi l ize  is estimated to be force.3 Disambiguat ion  w i th  P robab i l i s t i cC lus ter -Based  Lex iconsIi:t the following, we will des(:ril)e the simt}leand natural lexicon look-up mechanism whichis eml)loyed in our disambiguation at)t)roach.Consider Fig.
3 which shows two bilingual sen-tences taken from our evaluation corlms (seeSect.
4).
The source-words and their correspond-ing target-words are highlighted in bo ld  thee.The correct translation of the source-noun (e.g.Gre.nzc) as deternfined by the actual trmlslatorsis replaced by the set of alterlmtive translations(e.g.
{ border, frontier, b(mndary, limit, peril)h-cry, edge }) as proposed by the word-to-worddictionary of Fig.
5 (see Sect.
LI).The prol)lem to be solved is to lind a correctl;ranslation of the source-word using only min-imal contextual intbrmation.
In our apt)roach ,the decision between alternative target-nouns idone by llSillg only int'ormal,ion provided by thegoverning target-verb.
The key idea is to backup this nfinimal information with the condensedand precise information of a probabilistic lass-based lexicon.
The criterion for choosing an al-terlmtive target-noun is thus the best fit of thelexical and semantic information of the target:-noun to the semantics of the argument-slot ofthe target-verb.
This criterion is checked by asilnple lexicon look-up where the target-nounwith highest estinmted class-based fl'equeney isdetermined.
Fornmlly, choose l;11(; tm'get-nom~ gt,(and a class ~?)
such thatj& , , )=   .ax'nC N~c~Cwhere L-(-.)
= f ( - , )v(d- . )
is the estimated fre-quency of 'n, in tile sample of objects of afixed target-verb, p(cl,n ) is the class-melnbershi t)probability of'n in c as determined by the proba-bilistic lexicon, and f (n)  is the frequency of n inthe combined sample of objects and trmlslationalternatives1.Consider example ID 160867 fron, Fig.
3.
Themnbiguity to be resolved concerns the direct ob-jects of the verb cross  whose lexical entry ispartly shown in Fig.
2.
Class 19 and the nounborder is the pair yielding a higher estimatedtrequency than any other combination of a classand an alternative translation such as boundary.Similarly, for example ID 301946, the pair of the1Note that p(8) = max p(c) in most, but l lOt all cases.c E C  - -651target-noun society and class 6 gives highest es-timated frequency of the objects of mobilize.4 Evaluat ionWe evaluated our resolution methods on apseudo-disambiguation ask sinlilar to that usedin Rooth et al (1999) for evaluating clusteringmodels.
We used a test set of 298 (v, n, n ~) tripleswhere (v, n) is chosen randomly from a test cor-pus of pairs, and n ~ is chosen randomly accord-ing to the marginal noun distribution for the testcorpus.
Precision was calculated as the nmnberof times the disambiguation method decided forthe non-random target noun (f~.
= n).As shown in Fig.
4, we obtained 88 % pre-cision for the class-based lexicon (ProbLex),which is a gain of 9 % over the best cluster-ing model and a gain of 15 % over the hmnanbaseline 2 .human clustering ProbLex mnt)iguity baseline2 73.5 % 79.0 % 88.3 % IFigure 4: Evaluation on pseudo-disambiguationtask for noun-ambiguityThe results of the pseudo-disambiguationcould be confirmed in a fllrther evaluation on alarge number of randonfly selected examples ofa real-world bilingual corpus.
The corpus con-sists of sentence-aligned debates of the Euro-pean parliament (mlcc = multilingual corpusfor cooperation) with ca.
9 million tokens forGerman and English.
From this corpus we pre-pared a gold standard as follows.
We gatheredword-to-word translations from online-availabledictionaries and eliminated German nouns fbrwhich we could not find at least two Englishtranslations in the mice-corpus.
The resulting35 word dictionary is shown in Fig.
5.
Based onthis dictionary, we extracted all bilingual sen-tence pairs from the corpus which included boththe source-noun and the target-noun.
We re-stricted the resulting ca.
10,000 sentence pairsto those which included a source-noun from this2Similar esults for pseudo-dismnbiguation were ob-tained for a simpler approach which avoids an-other EM application for probabilistic lass labeling.Here ~ (and ~) was chosen such that f~(v,~) =max((fLc (v, n) + 1)pcc (el v, n)).
However, the sensitivityto class-parmnetcrs was lost in this approach.dictionary in the object position of a verb.
Fm'-therniore, the target-object was required to beincluded in our dictionary mid had to appearin a similar verb-object position as the source-object fbr an acceptable English translation ofthe German verb.
We marked the German nounn q in the source-sentence, its English translationne as appearing in the corpus, and the Englishlexical verb re.
For the 35 word dictionary ofFig.
5 this senti-automatic procedure resultedill a test corpus of 1,340 examples.
The aver-age ambiguity in this test corpus is 8.63 trans-lations per source-word.
Furthermore, we tookthe semantically most distant ranslations for 25words which occured with a certain fi'equencyin the ew~luation corpus.
This gave a corpus of814 examples with an average ambiguity of 2.83translations.
The entries belonging to this dic-tionary are highlighted in bo ld  face in Fig.
5.The dictionaries and the related test corpora areavailable on the web 3.We believe that an evaluation on these testcorpora is a realistic simulation of the hard taskof target-language disambiguation i  real-wordmachine translation.
The translation alterna-tives are selected fl'om online dictionaries, cor-rect translations are deternfined as the actualtranslations found in the bilingual corpus, noexamples are omitted, the average ambiguity ishigh, and the translations are often very closeto each other.
In constrast o this, most otherevaluations are based on frequent uses of onlytwo clearly distant senses that were deternfinedas interesting by the experimenters.Fig.
6 shows the results of lexical ambigu-ity resolution with probabilistic lcxica in com-parison to simpler methods.
The rows showthe results tbr evaluations on the two corporawith average ambiguity of 8.63 and 2.83 respec-tively.
Colunm 2 shows the percentage of cor-rect translations found by disambiguation byrandom choice.
Column 3 presents as anotherbaseline disambiguation with the major sense,i.e., always choose the most frequent target-noun as translation of the source-noun.
In col-unto 4, the empirical distribution of (v, n) pairsin the training corpus extracted from the BNCis used as disambiguator.
Note that this methodyields good results in terms of precision (P -#correct / $correct + $incorrect), but is much3http ://www.
ims .uni-stuttgart.
de/proj ekt e/gramot ron/652Angrif \[A r tAu fgabeAuswahlBegriffBodenE in r i cht  ungErwe i t  e rungFeh lerGcnehmigungC leseh ichteGesd lschaf tO| -e l |zeGrundKar teLageMangelMengePr f i fungSchwler igke l tSe i teS icherhe i tS thnme' rer l l l in"Vet'blnd ungVerbotVerp f l i ch t  u ng"~'et't ra l len"Wahl"lgVegWiders tandZeiehenZielZ \[isaln 111 e llll aliaZust lmmungaggression, assault,  oll)2nce, onset, onsbmght,  attack , charge, raid, whammy, inroadform~ type ,  way ,  fashion, lit, kind, wise, lllallller, species, mode, sort, wtrietyabandonment~ otIieo~ task ,  exercise, lesson, giveup, jot) , 1)roblcm, taxeligibility, selection, choice, wwlty, assortment,  extract,  range, sampleconcept, item, notion, ideaground,  land,  soi l ,  floor, bottomar rangement ,  ins t i tu t ion ,  const itut ion,  cstablishlnellt,  feature, instal lation, construction, setup, adjustment,  composit ion,organizat ionampl i f i ca t ion ,  extens ion ,  enhancement,  expansion, di latat ion,  upgr~ding, add-on, incrementerror~ shor tcoming ,  blemish, I)lunder, bug, defect, demeri t ,  failure, fault, flaw, mistake,  trouble, slip, blooper, lapsuspernlission, approval, COllSellt, acceptance, al)l)robation , author izat ionhlstory~ s tory ,  tale, saga, str ipcompany~ soc ie ty ,  COmlmnionshil), party, associateborder ,  f ront ie r ,  boundary, Ihnl t ,  periphery, edgenlaster~ n lat ter~ reasoll~ base, catlse, grOlllld~ bottoli i  rootcard ,  map,  ticket, chartsite, s i tuat ion,  position, bearing, layer, tierdeficiency, lack, pr ivation, want, shortage, shortcoming,  absence, dearth,  demerit ,  des ideratum, insufticimlcy, paucity, scarcenessalnol lnt~ deal ,  lot,  Illass I mtlltitttde, l)lenty, qtlalltity, quiverful~ vOhlllle 1 abull(latlce, aplellty 1assemblage , crowd, batch, crop, heal), lashings, scores, set, loads, I)ulkexaminat lon ,  sc rut iny ,  ver i f i ca t ion ,  ordeal, test, trial,  inspection, tryout,assay, canvass, check, inquiry~ perusal, reconsideration, scrut ingdifficttlty~ trol l l l le  1 problenl, severity, ar(lotlSlleSS 1heavinesspage~ party~ s lde,  point, aspectcer ta in ty ,  guarantee ,  sa fe ty ,  immunity,  security , collateral , doubtlessness, ureness, depositvoice~ vote ,  toneselate, deadl ine~ meethtg ,  appointment,  t ime, termassoc la t ion ,  contact ,  link~ cha\[ll, ColIjtlnCtlOll~ COlll/ectioll~ fllSiOll, joint , conlpOtlll(l~ all iance, cl~tenation, tie, lllllOIl I t)Olld~interface, liaison, touch, relation, incorporat ionban, interdiction, I)rohibition, forbiddanceeomin i tment :  ob l igat ion ,  under tak ing ,  duty, indebtedness , onus, debt, engagement,  liability, bondCOllfidence~ re l lance ,  trl lst~ faith, asstlrance~ dependence,  pr ivate, secrete lec t ion ,  opt ion ,  choice , ballot, alternagive, poll , listpath~ road ,  way ,  alley, route, laneresistance, opposit ion, dragcharacter,  icon, Sigll I sigllal, Syllll)ol, lllark, tokell~ figure, olneilahn ,  des t inat ion ,  end ,  designation, target,  goal, object, objective, sightings, intent imb promptcoherence, context~ COlltlgtllty, connectloliagree inent~ approvaI~ assont ,  accordance, approbat ion,  consent, af I innation, allowance, compliance, comi)Iiancy, acclamationFigure 5: Dictionaries extracted from online resourcesambiguity random major emlfirical sense distrib, clusl;ering ProbLexP: 46.1%8.63 14.2 % 31.9 % E: 36.2 % 43.3 % 49.4 %P: 60.8 %2.83 35.9 % 45.5 % E: 49.4 % 61.5 % 68.2 %Figure 6: Disambig, mtion results for clustering versus probabilistic lexicon methodsworse in terms of effectiveness (E //corre(-t/ \]/-correct q #:incorrect \]/:don't know).
Thereason for this is that even if the distribution(ff (v,n) pairs is estimated quite precisely forthe pairs in the large training corpus, there arestill many pairs which receive the same or nopositive probability at all.
These effects can'beovercome by a clustering approach to disam-biguation (column 5).
Here the class-smoothedprobability of a (v, n) pair is used to decide be-tween alternative target-nouns.
Since the clus-tering model assigns a more fine-grained prob-ability to nearly every pair in its domain, thereare no don't know cases for comparable preci-sion values.
However, the senmntically smoothedprobability of the clustering models is still toocoarse-grained when compared to a disambigua-tion with a prot)abilistic lexicon.
Here ~ fllrthergain in precision and equally effectiveness of ca.7 % is obtained on both corpora (column 6).We conjecture that this gain (:an be attrilmtedto the combination of Dequency iilformation ofthe nouns and the fine-tuned istribution on theselection classes of the the nominal argumentsof the verbs.
We believe that including the setof translation alternatives in the ProbLex dis-tribution is important for increasing efficiency,because it gives the dismnbiguation model theopportunity to choose among unseen alterna-tives.
Furthermore, it seems that the higher pre-cision of ProbLex can not be attributed to fillingin zeroes in the empirical distribution.
Rather,we speculate that ProbLex intelligently filtersthe empirical distribution by reducing maximal653counts for observations which do not fit intoclasses.
This might help in cases where the em-pirical distribution has equal values for two al-ternatives.source targetSeiteSicherheitVerbindungVerpflichtungZieloverall precisionpagesideguaranteesafetycommctionlinkcommitmentobligationobjectivetargetFigure 7: Precision for finding correct and ac-ceptable translations by lexicon look-upFig.
7 shows the results for disambiguationwith probabilistic lexica for five sample wordswith two translations each.
For this dictionary,a test corpus of 219 sentences was extracted, 200of which were additionally labeled with accept-able translations.
Precision is 78 % for findingcorrect translations and 90 % for finding accept-able translations.Furthermore, in a subset of 100 test itemswith average ambiguity 8.6, a lmnlan judge hav-ing access only to the English verb and the set ofcandidates for the targel,-lloun, i.e.
the informa-tion used by the model, selected anlong transla-tions.
On this set;, human precision was 39 %.5 D iscuss ionFig.
8 shows a comparison of our approadlto state-of-the-art unsupervised algorithlns forword sense disambiguation.
Column 2 shows thenumber of test examples used to evaluate thevarious approaches.
The range is from ca.
100examples to ca.
37,000 examples.
Our methodwas evaluated on test corpora of sizes 219, 814,and 1,340.
Column 3 gives the average numberof senses/eranslations for the different disam-biguation methods.
Here the range of the ambi-guity rate is from 2 to about 9 senses 4.
Column 44The mnbiguity factor 2.27 attributed to Dagan andItai's (1994) experiment is calculated by dividing theiraverage of 3.27 alternative translations by their averageof 1.44 correct translations.
Furthermore, we calculatedthe ambiguity factor 3.51 for Resnik's (1997) experimentshows the rmldom baselines cited for the respec-tive experiments, ranging t'rom ca.
11% to 50 %.Precision values are given in column 5.
In orderto compare these results which were computedfor different ambiguity factors, we standardizedthe measures to an evaluation for binary ambi-guity.
This is achieved by calculal;ing pl/log2 arabfor precision p and ambiguity factor arab.
Theconsistency of this "binarization" can be seen bya standardization of the different random base-lines which yields a value of ca.
50 % for allapproaches 5.
The standardized precision of ourapproach is ca.
79 % on all test corpora.
Themost direct point of comparison is the methodof Dagan and Itai (1994) whirl1 gives 91.4 % pre-cision (92.7 % standardized) and 62.1% effec-tiveness (66.8 % standardized) on 103 test; exam-ples for target word selection in the transfer ofHebrew to English.
However, colnpensating thishigh precision measure for the low effectivenessgives values comparable to our results.
Daganand Itai's (1994) method is based on a large vari-ety of gramnmtieal relations tbr verbal, nominal,and adjectival predicates, but no class-based in-fornmtion or slot-labeling is used.
I{esnik (1997)presented a disambiguation method which yields44.3 % precision (63.8 % standardized) tbr atest set of 88 verb-object tokens.
His approach iscoral)arable to ours in terlns of infbrmedness ofthe (tisambiguator.
Hc also uses a class-based se-lection measure, but based on WordNet classes.However, the task of his evaluation was to se-lect WordNet-senses tbr the objects rather thanthe objects themselves, so the results cannotbe compared directly.
The stone is true for theSENSEVAL evaluation exelcise (Kilgarriff andRosenzweig, 2000)--there word senses from theHECTOl~-dictionary had to be disambiguated.The precision results for the ten unsupervisedsystems taking part in the comt)etitive valu-ation ranged Kern 20-65% at efficiency valuesfrom 3-54%.
The SENSEVAL '~tan(lard is clearlybeaten by the earlier results of Yarowsky (1995)(96.5 % precision) and Schiitze (1992) (92 %precision).
However, a comparison to these re-from his random baseline 28.5 % by taking 100/28.5; re-versely, Dagan and Itai's (1994) random baseline can becalculated as 100/2.27 = 44.05.
Tile ambiguity t;'~ctor forSENSEVAL is calculated for tile llOUll task in the EnglishSENSEVAL test set.5Note that  we are guaranteed to get exactly 50 %standardized random 1)aseline if random, arab = 100 %.654disambiguation corlms random precisionmethod size aml)iguity random 1)recision (standardized) (standardized))robLex 1 340 8.63 14.2 % 49.4 % 53.4 % 79.7 %814 2.83 35.9 % 68.2 % 50.5 % 77.5 %219 2 50.0 % 78.0 % 50.0 % 78.0 %)agan, Itai 94{esnik 97;ENSEVAL 00(m'owsky 95',chiitze 92103882 75637 0003 0002.273.519.172244.1%28.5 %10.9 %50.0 %50.0 %P: 91.4 %E: 62.1%44.3 %P: 20-65 %E: 3-54 %96.5 %92.0 %50.0 %50.0 %50.0 %50.0 %50.0 %P: 92.7 %E: 66.8 %63.8 %P: 60-87 %E: 33-83 %96.5 %92.0 %Figure 8: Comparison of unsupervised lexical disambiguation methods.sults is again somewhat difficult.
Firstly, theseat)proaches were ewfluated on words with twoclearly (tistmlt senses which were de/;el'nfined bythe experimenters.
In contrast, our method wasevalutated on randonfly selected actual transla-tions of a large t)ilingual cortms.
Furthermore,these apl)roaches use large amounts of infbrma-tion in terms of linguistic ca.tegorizations, largecontext windows, or even 1111nual interventionsuch as initial sense seeding (hqtrowsky, 1995).Such information is easily obtainabh;, e.g., in I1\].at)tflications , but often burdensome to gather orsim.i)ly uslavail~bh'~ in situations such as incre-mental parsing O1' translation.6 Conc lus ionThe disanfl3iguation method presented in thispa.per delibera.tely is restricted to the limitedmnomlt of information provided by a proba-bilistic class-based lexicon.
This intbrmation yetproves itself accurate nough to yield good em-pirical results, e.g., in target-language disam-biguation.
The t)rol)al)ilistic class-based lexicaare induced in an unsupervised manner fl'omlarge mmnnotated corpora.
Once the lexica areconstructed, lexical mnbiguity resolution can bedone by a simple lexicon look-up.
I51 target-word selection, the nlOSt fl'equent target-nounwhose semantics fits best to tit(; semantics of theargument-slot of the target-verb is chosen.
Weevaluated our method on randomly selected ex-amities Dora real-world bilingual corpora whichconstitutes a realistic hard task.
Dismnbiguationbased on probabilistie lexica perfornmd satisfim-'tory for this |;ask.
The lesson lem'ned tYom ourexperimental results is that hybrid models con>bining fi:equency information and class-basedt)robabilities outlmrtbnn both pure fl'equency-based models and pure clustering models.
1'511"-ther improvements are to be expected fromextended lexica including, e.g., adjectival andprepositional predicates.ReferencesGleml Carroll mid Mats F\[ooth.
1998.
Valenceinduction with a head-lexicalized PCFG.
InP'roceediugs o.f EMNLP-,7, Granada.Ido l)agan and Ahm Itai.
1994:.
Word sense dis-ambiguation using a second language 1110510-linguaJ corlms.
Computational Linguistics,20:563 596.Adam Kilgarriff and Joseph lq.osenzweig.
2000.English SENSEVAIA I-{.el)ol't and results.
InProceedings of LR\]';C 2000.Philip l{csnik.
1997.
Selectional preference andsense dis~mfl)iguation, l\[ll Proceedings of theANLP'97 Workshop: Tagging Tc:ct 'with Lezi-cal Semantics: Why, What, and How?, V~:ash-ington, D.C.Mats l\].ooth, Stefan I{iezler, Detlef Prescher,Glenn Carroll, and Franz Bell.
1999.
Induc-ing a semantically annotated lexicon via EM-based clustering.
In Proceedings of the 37thAnnual Meeting of th, c Assoc.iation .for Com,-putational Linguistics (A CL '99), Maryland.Ilinrieh Schfitze.
1992.
Dimensions of meaning.151 Proceedings of S'upercomlnd.ing '92.David Yarowsky.
1995.
Unsupervised wordsense dismnbiguation rivaling supervisedmethods.
In Proceedings of the 33rd AnnualMeeting of th, c Association for Compv, tationalLinguistics (ACL'95), Cambridge, MA.655
