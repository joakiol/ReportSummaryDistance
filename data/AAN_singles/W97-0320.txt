An Empirical Approach to Temporal Reference ResolutionJ anyce  Wiebe ,  Tom O'Hara ,  Kenneth  McKeever ,  and  Thors ten  Ohrs t rSm-SandgrenDept.
of Computer  Science and the Comput ing Research LaboratoryNew Mexico State UniversityLas Cruces, NM 88003wiebe, t omohara, kmckeeve, t s andgre@c s. nmsu.
eduAbst rac tThis paper presents the results of an em-pirical investigation of temporal referenceresolution in scheduling dialogs.
The algo-rithm adopted is primarily a linear-recencybased approach that does not include amodel of global focus.
A fully automaticsystem has been developed and evaluatedon unseen test data with good results.
Thispaper presents the results of an intercoderreliability study, a model of temporal refer-ence resolution that supports linear ecencyand has very good coverage, the results ofthe system evaluated on unseen test data,and a detailed analysis of the dialogs as-sessing the viability of the approach.1 In t roduct ionTemporal information is often a significant part ofthe meaning communicated in dialogs and texts, butis often left implicit, to be recovered by the listeneror reader from the surrounding context.
Determin-ing all of the temporal information that is beingconveyed can be important for many interpretationtasks.
For instance, in machine translation, know-ing the temporal context is important in translatingsentences with missing information.
This is partic-ularly useful when dealing with noisy data, as withspoken input (Levin et al 1995).
In the followingexample, the third utterance could be interpreted inthree different ways.sl: (Ahora son las once y diez)Now it is eleven tensl: (Qu4 tal a las doce)How about twelvesl: (Doce ados)Twelve to twoor  The twelfth to the secondor  The twelfth at twoBy maintaining the temporal context (i.e., the 5thof March 1993 at 12:00), the system will know that"12:00 to 2:00" is a more probable interpretationthan "the 12th at 2:00".In addition, maintaining the temporal contextwould be useful for information extraction tasksdealing with natural language texts such as memosor meeting notes.
For instance, it can be used toresolve relative time expressions, so that absolutedates can be entered in a database with a uniformrepresentation.This paper presents the results of an empiri-cal investigation of temporal reference resolution inscheduling dialogs (i.e., dialogs in which participantsschedule a meeting with one another).
This workthus describes how to identify temporal informationthat is missing due to ellipsis or anaphora, and itshows how to determine the times evoked by deicticexpressions.
In developing the algorithm, our ap-proach was to start with a straightforward, ecency-based approach and add complexity as needed toaddress problems encountered in the data.
The al-gorithm does not include a mechanism for handlingglobal focus (Grosz & Sidner 1986), for centeringwithin a discourse segment (Sidner 1979; Grosz et al1995), or for performing tense and aspect interpreta-tion.
Instead, the algorithm processes anaphoric ref-erences with respect o an Attentional State (Grosz& Sidner 1986) structured as a linear list of all timesmentioned so far in the current dialog.
The list isordered by recency, no entries are ever deleted fromthe list, and there is no restriction on access.
The al-gorithm decides among candidate antecedents basedon a combined score reflecting recency, a priori pref-erences for the type Of anaphoric relation(s) estab-lished, and plausibility of the resulting temporal ref-erence.
In determining the candidates from whichto choose the antecedent, for each type of anaphoricrelation, the algorithm considers only the most re-cent antecedent for which that relationship can be174established.The algorithm was primarily developed on a cor-pus of Spanish dialogs collected under the JANUSproject (Shum et al 1994) (referred to hereafter asthe "CMU dialogs") and has also been applied to acorpus of Spanish dialogs collected under the Art-work project (Wiebe et al 1996) (hereafter referredto as the "NMSU dialogs").
In both cases, subjectswere told that they were to set up a meeting basedon schedules given to them detailing their commit-ments.
The CMU protocol is akin to a phone conver-sation between people who do not know each other.Such strongly task-oriented ialogs would arise inmany useful applications, uch as automated infor-mation providers and automated phone operators.The NMSU data are face-to-face dialogs betweenpeople who know each other well.
These dialogsare also strongly task-oriented, but only in these,not in the CMU dialogs, do the participants traysignificantly from the scheduling task.
In addition,the data sets are challenging in that they both in-clude negotiation, both contain many disfluencies,and both show a great deal of variation in how datesand times are discussed.To support he computational work, the temporalreferences in the corpus were manually annotated ac-cording to explicit coding instructions.
In addition,we annotated the seen training dialogs for anaphoricchains, to support analysis of the data.A fully automatic system has been developed thattakes as input the ambiguous output of a semanticparser (Lavie ~ Tomita 1993, Levin et al 1995).The system performance on unseen, held-out testdata is good, especially on the CMU data, showingthe usefulness of our straightforward approach.
Theperformance on the NMSU data is worse but sur-prisingly comparable, given the greater complexityof the data and the fact that the system was primar-ily developed on the simpler data.Rose et al (1995), Alexandersson et al (1997),and Busemann et al (1997) describe other recentNLP systems that resolve temporal expressions inscheduling dialogs as part of their overall process-ing, but they do not give results of system perfor-mance on any temporal interpretation tasks.
Kamp& Reyle (1993) address many representational andprocessing issues in the interpretation of temporalexpressions, but they do not attempt coverage of adata set or present results of a working system.
Toour knowledge, there are no other published resultson unseen test data of systems performing the sametemporal resolution tasks.The specific contributions of this paper are thefollowing.
The results of an intercoder eliabil-ity study involving naive subjects are presented(in section 2) as well as an abstract presenta-tion of a model of temporal reference resolution(in section 3).
In addition, the high-level algo-rithm is given (in section 4); the fully refined al-gorithm, which distinguishes many more subcasesthan can be presented here, is available onlineat http :/ / crl.nmsu.edu / Research/ Projects/ artwork.Detailed results of an implemented system are alsopresented (in section 5), showing the success of thealgorithm.
In the final part of the paper, we abstractaway from matters of implementation and analyzethe challenges presented by the dialogs to an algo-rithm that does not include a model of global focus(in section 6).
We found surprisingly few such chal-lenges.2 The Corpus and IntercoderReliability StudyConsider this passage from the corpus (translatedinto English):Preceding time: Thursday 19 Augustsl 1 On Thursday I can only meet after two pm2 From two to four3 Or two thirty to four thirty4 Or three to fives2 5 Then how does from two thirty tofour thirty seem to you6 On Thursdaysl 7 Thursday the thirtieth of SeptemberAn example of temporal reference resolution isthat (2) refers to 2-4pm Thursday 19 August.
Al-though related, this problem is distinct from tenseand aspect interpretation i discourse (as addressedin, e.g., Webber 1988, Song & Cohen 1991, Hwang& Schubert 1992, Lascarides et al 1992, andKameyama et al 1993).Because the dialogs are centrally concerned withnegotiating an interval of time in which to hold ameeting, our representations are geared toward suchintervals.
Our basic representational unit is given infigure 1.
To avoid confusion, we refer to this basicunit throughout as a Temporal Unit (TU).The time referred to in, for example, "From 2 to4, on Wednesday the 19th of August" is representedas :((August, 19th, Wednesday, 2, pm)(August, 19th, Wednesday, 4, pm))Thus, the information from multiple noun phrasesis often merged into a single representation of theunderlying interval evoked by the utterance.175((start-month, start-date, start-day-of-week, start-hourSzminute, start-time-of-day) \](end-month, end-date, end-day-of-week, end-hour&minute, end-time-of-day))Figure 1: Temporal UnitsAn utterance such as "The meeting starts at 2" isrepresented as an interval rather than as a point intime, reflecting the orientation of the coding schemetoward intervals.
Another issue this kind of utter-ance raises is whether or not a speculated endingtime of the interval should be filled in, using knowl-edge of how long meetings usually last.
In the CMUdata, the meetings all last two hours.
However, sothat the instructions will be applicable to a widerclass of dialogs, we decided to be conservative withrespect o filling in an ending time, given the startingtime (or vice versa), leaving it open unless omethingin the dialog explicitly suggests otherwise.There are cases in which times are considered aspoints (e.g., "It is now 3pm").
These are representedas Temporal Units with the same starting and end-ing times (as in Allen (1984)).
If just one endingpoint is represented, all the fields of the other arenull.
And, of course, all fields are null for utter-ances that do not contain temporal information.
Inthe case of an utterance that refers to multiple, dis-tinct intervals, the representation is a list of Tempo-ral Units.A Temporal Unit is also the representation usedin the evaluation of the system.
That is, the sys-tem's answers are mapped from its more complexinternal representation (an I LT ,  see section 4.1) intothis simpler vector representation before evaluationis performed.As in much recent empirical work in discourse pro-cessing (e.g., Arhenberg et al 1995; Isard & Carletta1995; Litman & Passonneau 1995; Moser & Moore1995; Hirschberg & Nakatani 1996), we performedan intercoder eliability study investigating agree-ment in annotating the times.
The goal in devel-oping the annotation instructions is that they canbe used reliably by non-experts after a reasonableamount of training (cf.
Passonneau & Litman 1993,Condon & Cech 1995, and Hirschberg & Nakatani1996), where reliability is measured in terms of theamount of agreement among annotators.
High re-liability indicates that the encoding scheme is re-producible given multiple labelers.
In addition, theinstructions serve to document the annotations.The subjects were three people with no previousinvolvement in the project.
They were given theoriginal Spanish and the English translations.
How-ever, as they have limited knowledge of Spanish, inessence they annotated the English translations.The subjects annotated two training dialogs ac-cording to the instructions.
After receiving feed-back, they annotated four unseen test dialogs.
Inter-coder reliability was assessed using Cohen's Kappastatistic (~?)
(Siegel & Castellan 1988, Carletta1996).is calculated as follows, where the numerator isthe average percentage agreement among the anno-tators (Pa) less a term for chance agreement (Pc),and the denominator is 100% agreement less thesame term for chance agreement (Pe):Pa  - Re1 - Pe(For details on calculating Pa and Pe see Siegel &Castellan 1988).
As discussed in (Hays 1988), J?
willbe 0.0 when the agreement is what one would ex-pect under independence, and it will be 1.0 whenthe agreement is exact.
A ~?
value of 0.8 or greaterindicates ahigh level of reliability among raters, withvalues between 0.67 and 0.8 indicating only moder-ate agreement (Hirschberg ~ Nakatani 1996; Car-letta 1996).In addition to measuring intercoder reliability, wecompared each coder's annotations to the evaluationTemporal Units used to assess the system's perfor-mance.
These evaluation Temporal Units were as-signed by an expert working on the project.The agreement among coders (a) is shown in table1.
In addition, this table shows the average pairwiseagreement ofthe coders and the expert (~a~g), whichwas assessed by averaging the individual ~ scores(not shown).
There is a moderate or high level ofagreement among annotators in all cases except heending time of day, a weakness we are investigating.Similarly, there are reasonable levels of agreementbetween our evaluation Temporal Units and the an-swers the naive coders provided.Busemann et al (1997) also annotate temporalinformation i  a corpus of scheduling dialogs.
How-ever, their annotations are at the level of individ-ual expressions rather than at the level of TemporalUnits, and they do not present he results of an in-tercoder eliability study.176startMonth .96 .51 .93 .94Date .95 .50 .91 .93WeekDay .96 .52 .91 .92HourMin .98 .82 .89 .92TimeDay .97 .74 .87 .74endMonth .97 .51 .93 .94Date .96 .50 .92 .94WeekDay .96 .52 .92 .92HourMin .99 .89 .90 .88TimeDay .95 .85 .65 .52Table 1: Agreement among Coders (kappa coefficients by field)3 Mode lThis section presents our model of temporal ref-erence in scheduling dialogs.
The treatment ofanaphora in this paper is as a relationship between aTemporal Unit representing a time evoked in the cur-rent utterance, and one representing a time evokedin a previous utterance.
The resolution of theanaphor is a new Temporal Unit that represents heinterpretation f the contributing words of the cur-rent utterance.Fields of Temporal Units are partially ordered asin figure 2, from least to most specific.In all cases below, after the resolvent has beenformed, it is subjected to highly accurate, trivial in-ference to produce the final interpretation (e.g., fill-ing in the day of the week given the month and thedate).The cases of non-anaphorie r ference:1.
A deictic expression is resolved into a time in-terpreted with respect o the dialog date (e.g.,"Tomorrow", "last week").
(See rule NA1 insection 4.2.)2.
A forward time is calculated by using the dialogdate as a frame of reference.Let F be the most specific field in TUcurrentabove the level of time-of-day.Resolvent: The next F after the dialog date,augmented with the fillers of the fields inTUeurrent at or below the level of time-of-day.
(See rule NA2.
)For both this and anaphoric relation (3), thereare subcases for whether the starting and/orending times are involved.
Note that tense caninfluence the choice of whether to calculate aforward or a backward time from a frame ofreference (Kamp & Reyle 1993), but we do notaccount for this in our model due to the lack oftense variation in the corpora.Ex: Dialog date is Mon, 19th, Aug"How about Wednesday at 2?
"interpreted as 2 pm, Wed 21 AugThe cases of anaphora considered:1.
The utterances evoke the same time, or the sec-ond is more specific than the first.Resolvent: the union of the information i  thetwo Temporal Units.
(See rule A1.
)Ex: "How is Tuesday, January 30th?
""How about 2?
"(See also (1)-(2) of the corpus example.)2.
The current utterance vokes a time that in-cludes the time evoked by a previous time, andthe current ime is less specific.
(See rule A2.
)Let F be the most specific field in TUg,trent.Resolvent: All of the information i TUpre~iouafrom F on up.Ex: "How about Monday at 2?
"resolved to 2pm, Mon 19 Aug"Ok, well, Monday sounds good.
"(See also (5)-(6) in the corpus example.)3.
This is the same as non-anaphoric case (2)above, but the new time is calculated with re-spect to TUpr~viou, instead of the dialog date.
(See rule A3.
)177monthweekdaydatetime of day hourSJminuteFigure 2: Specificity OrderingEx: "How about the 3rd week in August?
""Let's see, Monday sounds good.
"interpreted as Mon, 3rd week in AugEx: "Would you like to meet Wed, Aug 2nd?
""No, how about Friday at 2.
"interpreted as Fri, Aug 4 at 2pm4.
The current ime is a modification of the previ-ous time; the times are consistent down to somelevel of specificity X and differ in the filler of X.Resolvent: The information i TUpr~iou~ abovelevel X together with the information inTUeurrent at and below level X.
(See ruleA4.
)Ex: "Monday looks good.
"resolved to Mon 19 Aug"How about 2?
"resolved to 2pm Mon 19 Aug"Hmm, how about 4?
"resolved to 4pm Mon 19 Aug(See also (3)-(5) in the example from the cor-pus.
)Although we found domain knowledge and task-specific linguistic conventions most useful, we ob-served in the NMSU data some instances of poten-tially exploitable syntactic information to pursue infuture work (Grosz et al 1995, Sidner 1979).
Forexample, "until" in the following suggests that thefirst utterance specifies an ending time."...
could it be until around twelve?
""12:30 there"A preference for parallel syntactic roles might beused to recognize that the second utterance speci-fies an ending time too.4 The AlgorithmThis section presents our algorithm for tempo-ral reference resolution.
After a brief overview,the rule-application architecture is described andthen the rules composing the algorithm are given.As mentioned earlier, this is a high-level algo-rithm.
Description of the complete algorithm,including a specification of the normalized inputrepresentation (see section 4.1), can be obtainedfrom a report available at the project web page(http://crl.nmsu.edu/Research/Projects/artwork).There is a rule for each of the relations presentedin section 3.
Those for the anaphoric relations in-volve various applicability conditions on the currentutterance and a potential antecedent.
For the cur-rent not-yet-resolved Temporal Unit, each rule is ap-plied.
For the anaphoric rules, the antecedent con-sidered is the most recent one meeting the condi-tions.
All consistent maximal mergings of the resultsare formed, and the one with the highest score is thechosen interpretation.4.1 ArchitectureFollowing (Qu et al 1996) and (Shum et al 1994),the representation f a single utterance is called anILT (for InterLingual Text).
An ILT, once it hasbeen augmented by our system with temporal (andspeech-act) information, is called an augmented ILT(an AILT).
The input to our system, produced by asemantic parser (Shum et al 1994; Lavie & Tomita1993), consists of multiple alternative ILT repre-sentations of utterances.
To produce one ILT, theparser maps the main event and its participants intoone of a small set of case frames (for example, a meetframe or an is busy frame) and produces a surfacerepresentation f any temporal information, which isfaithful to the input utterance.
Although the eventsand states discussed in the NMSU data are oftenoutside the coverage of this parser, the temporal in-formation generally is not.
Thus, the parser pro-vides us with a sufficient input representation forour purposes on both sets of data.
This parser isproprietary, but it would not be difficult o producejust the portion of the temPOral information thatour system requires.Because the input consists of alternative s quencesof ILTs, the system resolves the ambiguity inbatches.
In particular, for each input sequence ofILTs, it produces a sequence of AILTs and thenchooses the best sequence for the corresponding ut-terances.
In this way, the input ambiguity isresolvedas a function of finding the best temporal interpreta-178tions of the utterance sequences in context (as sug-gested in Qu et al 1996).A focus list keeps track of what has been discussedso far in the dialog.
After a final AILT has beencreated for the current utterance, the AILT and theutterance are placed together on the focus list (wherethey are now referred to as a discourse entity, orDE).
In the case of utterances that evoke more thanone Temporal Unit, a separate ntity is added foreach to the focus list in order of mention.Otherwise, the system architecture is similar to astandard production system, with one major excep-tion: rather than choosing the results of just one ofthe rules that fires (i.e., conflict resolution), multipleresults can be merged.
This is a flexible architec-ture that accommodates sets of rules targeting dif-ferent aspects of interpretation, allowing the systemto take advantage of constraints hat exist betweenthem (for example, temporal and speech act rules).Step 1.
The input ILT is normalized.
In the in-put ILT, different pieces of information about thesame time might be represented separately in orderto capture relationships among clauses.
Our sys-tem needs to know which pieces of information areabout the same time (but does not need to knowabout the additional relationships).
Thus, we mapfrom the input representation into a normalized formthat shields the reasoning component from the id-iosyncracies of the input representation.
After thenormalization process, highly accurate, obvious in-ferences are made and added to the representation.Step 2.
All rules are applied to the normalized in-put.
The result of a rule application isa partial AILT(PAILT)--information this rule would contribute tothe interpretation of the utterance.
This informa-tion includes a certainty factor representing an apriori preference for the type of anaphoric or non-anaphoric relation being established.
In the caseof anaphoric relations, this factor gets adjusted bya term representing how far back on the focus listthe antecedent is (in rules A1-A4 in section 4.2, theadjustment is represented by distance factor in thecalculation of the certainty factor CF).
The result ofthis step is the set of PAILTs produced by the rulesthat fired (i.e., those that succeeded).Step 3.
All maximal mergings of the PAILTs arecreated.
Consider a graph in which the PAILTsare the vertices, and there is an edge between twoPAILTs iff the two PAILTs are compatible.
Then,the maximal cliques of the graph (i.e., the maxi-mal complete subgraphs) correspond to the maximalmergings.
Each maximal merging is then mergedwith the normalized input ILT, resulting in a set ofAILTs.Step 4.
The AILT chosen is the one with the high-est certainty factor.
The certainty factor of an AILTis calculated as follows.
First, the certainty factorsof the constituent PAILTs are summed.
Then, crit-ics are applied to the resulting AILT, lowering thecertainty factor if the information is judged to beincompatible with the dialog state.The merging process might have yielded addi-tional opportunity for making obvious inferences, sothat process is performed again, to produce the finalAILT.4.2 Temporal Resolution RulesThe rules described in this section (see figure 3) ap-ply to individual temporal units and return eithera more-fully specified TU or an empty structure toindicate failure.Many of the rules calculate temporal informationwith respect to a frame of reference, using a separatecalendar utility.
The following describe these andother functions assumed by the rules below, as wellas some conventions used.next(TimeValue, RF): returns the nexttimeValue that follows reference frame RF.next(Monday, \[...Friday, 19th,...\]) = Monday,22nd.resolve_deictic(DT, RF): resolves thedeictic term DT with respect o the referenceframe RF.merge(TU1, TU2): if temporal units TU1 andTU2 contain o conflicting field fillers, returns atemporal unit containing all of the informationin the two; otherwise returns {}.merge_upper(TU1, TU2): like the previous func-tion, except includes only those field fillers fromTU1 that are of the same or less specificity asthe most specific field filler in TU2.specificity(TU): returns the specificity of the mostspecific field in TU.starting..fields(TU): returns a list of starting fieldnames for those in TU having non-null values.structure--~component: returns the named com-ponent of the structure.conventions: Values are in bold face and vari-ables are in italics.
TU is the current emporM179unit being resolved.
TodaysDate is a represen-tation of the dialog date.
FocusList is the list ofdiscourse ntities from all previous utterances.The algorithm does not cover a number of sub-cases of relations concerning the ending times.
Forinstance, rule NA2 covers only the starting-timecase of non-anaphoric relation 2.
An example of anending-time case that is not handled is the utterance"Let ' smeet  until Thursday," under the meaningthat they should meet from today through Thurs-day.
This is an area for future work.5 ResultsAs mentioned in section 2, the main results are basedon comparisons against human annotation of theheld out test data.
The results are based on straightfield-by-field comparisons of the Temporal Unit rep-resentations introduced in section 2.
Thus, to beconsidered as correct, information must not only beright, but it has to be in the right place.
Thus, forexample, "Monday" correctly resolved to Monday,19th of August, but incorrectly treated as a startingrather than an ending time, contributes 3 errors ofomission and 3 errors of commission (and no creditis given for recognizing the date).Detailed results for the test sets are presentednext, starting with results for the CMU data (seetable 2).
Accuracy measures the degree to whichthe system produces the correct answers, while pre-cision measures the degree to which the system's an-swers are correct (see the formulas in the tables).
Foreach component of the extracted temporal structure,counts were maintained for the number of correctand incorrect cases of the system versus the taggedfile.
Since null values occur quite often, these twocounts exclude cases when one or both of the val-ues are null.
Instead, additional counts were usedfor those possibilities.
Note that each test set con-tains three complete dialogs with an average of 72utterances per dialog.These results show that the system is performingwith 81% accuracy overall, which is significantly bet-ter than the lower bound (defined below) of 43%.
Inaddition, the results show a high precision of 92%.In some of the individual cases, however, the resultscould be higher due to several factors.
For exam-ple, our system development was inevitably focussedmore on some types of slots than others.
An obviousarea for improvement is the time-of-day handling.Also, note that the values in the Missing columnare higher than those in the Extra column.
This re-flects the conservative coding convention, mentionedin section 2, for filling in unspecified end points.A system that produces extraneous values is moreproblematic than one that leaves entries unspecified.Table 3 contains the results for the system on theNMSU data.
This shows that the system performsrespectably, with 69% accuracy and 88% precision,on this less constrained set of data.
The precisionis still comparable, but the accuracy is lower sincemore of the entries were left unspecified.
Further-more, the lower bound for accuracy (29%) is almost15% lower than the one for the CMU data (43%),supporting the claim that this data set is more chal-lenging.More details on the lower bounds for the test datasets are shown next (see table 4).
These values werederived by disabling all the rules and just evaluat-ing the input as is (after performing normalization,so the evaluation software could be applied).
Since'null' is the most frequent value for all the fields, thisis equivalent to using a naive algorithm that selectsthe most frequent value for a given field.
The right-most column shows that there is a small amount oferror in the input representation.
This figure is 1minus the precision of the input representation (af-ter normalization).
Note, however, that this is aclose but not entirely direct measure of the error inthe input, because there are a few cases of the nor-malization process committing errors and a few ofit correcting them.
Recall that the input is ambigu-ous; the figures in table 4 are based on the systemselecting the first ILT in each case.
Since the parserorders the ILTs based on a measure of acceptability,this choice is likely to have the relevant emporalinformation.Since the above results are for the system tak-ing ambiguous emantic representations a input,the evaluation does not isolate focus-related errors.Therefore, two tasks were performed to aid in de-veloping the analysis presented in section 6.
First,anaphoric hains and competing discourse entitieswere manually annotated in all of the seen data.Second, to aid in isolating errors due to focus issues,the system was evaluated on unambiguous, partiallycorrected input for all the seen data (the test setswere retained as unseen test data).The overall results are shown in the table 5.
Thisincludes the results described earlier to facilitatecomparisons.
Among the first, more constraineddata, there are twelve dialogs in the training dataand three dialogs in a held out test set.
The averagelength of each dialog is approximately 65 utterances.Among the second, less constrained ata, there arefour training dialogs and three test dialogs.As described in the next section, our approachhandles focus effectively.
In both data sets, there180Rules for non-anaphoric relationsRule  NA I :  All cases of non-anaphoric relation 1.if there is a deictic term, DT, in TU thenreturn {\[when, resolve_deictic(DT, odaysDate)\], [certainty, 0.9\]}Ru le  NA2:  The starting-time cases of non-anaphoric relation 2.if (most.specific(starting_fields(TU)) < time_of_day) thenLet f be the most specific field in starting_fields(TU)return {\[when, next(TU-rf, TodaysDate)\], [certainty, 0.4\]}Rules for anaphoric relationsRule  h l :  All cases of anaphoric relation 1.for each non-empty temporal unit TUII from FocusList (starting with most recent)if specificity(TU11) < specificity(TU) and not empty merge(TUlt, TU) thenCF = 0.8 - distance_factor(TUlt , FocusList)return {\[when, merge(TUlt , TU)\], \[certainty, CF\]}Rule  A2: All cases of anaphoric relation 2.for each non-empty temporal unit TUft from FocusList (starting with most recent)if specificity(TU/t) > specificity(TU) and not empty merge_upper(TUft, TU) thenCF = 0.5 - distance_factor(TUft, FocusList)return {\[when, merge_upper(TUlt , TU)\], \[certainty, eel}Rule  A3: Starting-time case of anaphoric relation 3.if (most.specific(starting_fields(TU)) < time_of_day) thenfor each non-empty temporal unit TUI~ from FocusList (starting with most recent)if specificity(TU) > specificity(TU1~) thenLet f be the most specific field in starting_fields(TU)CF = 0.6 - distance_factor(TUlt , FocusList)return {\[when, next(TV--+ f, TUlt---~start_date)\] , \[certainty, CF\]}Rule  A4: All cases of anaphoric relation 4.for each non-empty temporal unit TUIt from FocusList (starting with most recent)if specificity(TU) > specificity(TUfl ) thenTUternp = TUltfor each {f  I f -> most specific field in TU}TUte,np~f = nullif not empty merge(TUtemp, TU) thenCF = 0.5 - distance_factor(TUlt, FocusList)return {\[when, merge(TUtemp, TU)\], \[certainty, CF\]}Figure 3: Main Temporal Resolution Rules181Label Cot Inc Mis Ext NulstartMonth 49 3 7 3 0Date 48 4 7 3 0WeekDay 46 6 7 3 0HourMin 18 0 7 0 37TimeDay 9 0 18 0 35endMonth 48 3 7 1 3Date 47 5 6 3 1WeekDay 45 7 6 3 1HourMin 9 0 9 0 44TimeDay 4 0 13 1 44overall 323 28 87 17 165LegendCor(rect):Inc(orrect):Mis(sing):Ext(ra):Nul(l):Acc(uracy)LB:Acc(uracy):AccLB0.3380.4030.2420.8590.6150.0770.0480.0770.8620.7380.428Acc0.8310.8140.7800.8870.7100.8360.8140.7800.8550.7870.809System and key agree on non-null valueSystem and key differ on non-null valueSystem has null value for non-null keySystem has non-null value for null keyBoth System and key give null answeraccuracy lower boundpercentage ofkey values matched correctlyPrec0.8910.8730.8361.0001.0000.9270.8570.8211.0000.9800.916(Correct + Null)/(Correct + Incorrect + Missing + Null)Prec(ision): percentage ofSystem answers matching the key(Correct + Null)/(Correct + Incorrect + Extra + Null)Table 2: Evaluation of System on CMU Test DataLabelstartMonth 55 0 23Date 49 6 23WeekDay 52 3 23HourMin 34 3 7TimeDay 18 8 31endMonth 55 0 23Date 49 6 23WeekDay 52 3 23HourMin 28 2 13TimeDay 9 2 32overall 401 33 221i .....Table 3:5 3 0.060 0.716 0.9215 3 0.060 0.642 0.8255 3 0.085 0.679 0.8736 36 0.852 0.875 0.8862 27 0.354 0.536 0.8185 3 0.060 0.716 0.9215 3 0.060 0.642 0.8255 3 0.060 0.679 0.8731 42 0.795 0.824 0.9595 38 0.482 0.580 0.87044 161 0.286 0.689 0.879Evaluation of System on NMSU Test DataSetc m un m s uCor Inc Mis Ext Nul Acc Input Error84 6 360 10 190 0.428 0.05565 3 587 4 171 0.286 0.029Table 4: Lower Bounds for both Test Sets182seen/ emu/unseen nmsuseen cmuseen cmuunseen cmuseen nmsuseen nmsuunseen nmsuAmbiguous/ #dialogs\] #utterances Accuracy Precisionunambiguousambiguous 12 659 0.883 0.918unambiguous 12 659 0.914 0.957ambiguous 3 193 0.809 0.916ambiguous 4 0.679unambiguousambiguous3583582360.7790.689Table 5: Results on Corrected Input (to isolate focus issues)0.7460.8500.879are noticeable gains in performance on the seen datagoing from ambiguous to unambiguous input, espe-cially for the NMSU data.
Therefore, the ambiguityin the dialogs contributes much to the errors.The better performance on the unseen, ambigu-ous NMSU data over the seen, ambiguous, NMSUdata is due to several reasons.
For instance, there isvast ambiguity in the seen data.
Also, numbers aremistaken by the input parser for dates (e.g., phonenumbers are treated as dates).
In addition, a tensefilter, to be discussed below in section 6, was imple-mented to heuristically detect subdialogs, improv-ing the performance of the seen NMSU ambiguousdialogs.
This filter did not, however, significantlyimprove the performance for any of the other data,suggesting that the targeted kinds of subdialogs donot occur in the unseen data.The errors remaining in the seen, unambiguousNMSU data are overwhelmingly due to parser er-ror, errors in applying the rules, errors in mistakinganaphoric references for deictic references (and viceversa), and errors in choosing the wrong anaphoricrelation.
As will be shown in the next section, veryfew errors can be attributed to the wrong entities be-ing in focus due to not handling subdialogs or "mul-tiple threads" (Ros6 et al 1995).6 G loba l  FocusThe algorithm is conspicuously lacking in any mech-anism for recognizing the global structure of the dis-course, such as in Grosz ~ Sidner (1986), Mann& Thompson (1988), Allen & Perranlt (1980), andtheir descendants.
Recently in the literature, Walker(1996) has argued for a more linear-recency basedmodel of Attentional State (though not that dis-course structure need not be recognized), while Rosdet al (1995) argue for a more complex model of At-tentional State than is represented in most currentcomputational theories of discourse.Many theories that address how Attentional Stateshould be modeled have the goal of performing inten-tion recognition as well.
We investigate performingtemporal reference resolution directly, without alsoattempting torecognize discourse structure or inten-tions.
We assess the challenges the data present oour model when only this task is attempted.We identified how far back on the focus list onemust go to find an antecedent that is appropriateaccording to the model.
Such an antecedent eednot be unique.
(We also allow antecedents for whichthe anaphoric relation would be a trivial extensionof one of the relations in the model.
)The results are striking.
Between the two setsof data, out of 215 anaphoric references, there arefewer than 5% for which the immediately precedingtime is not an appropriate antecedent.
Going backan additional time covers the remaining cases.The model is geared toward allowing the most re-cent Temporal Unit to be an appropriate antecedent.For example, in the example for anaphoric relation 4,the second utterance (as well as the first) is a possi-ble antecedent of the third.
A corresponding speechact analysis might be that the speaker is suggestinga modification of a previous suggestion.
Consider-ing the most recent antecedent as often as possiblesupports robustness, in the sense that more of thedialog is considered.There are subdialogs in the NMSU data (butnone in the CMU data) for which our recency algo-rithm fails because it lacks a mechanism for recog-nizing subdialogs.
There are five temporal referenceswithin subdialogs that recency either incorrectly in-terprets to be anaphoric to a time mentioned beforethe subdialog or incorrectly interprets to be the an-tecedent of a time mentioned after the subdialog.Fewer than 25 cumulative rrors result from theseprimary areas.
In the case of one of the primary er-rors, recency commits a "self-correcting" error; with-out this luck, the remainder of the dialog would haverepresented additional cumulative error.In a departure from the algorithm, the system usessimple heuristic for ignoring subdialogs: a time is183ignored if the utterance voking it is in the simplepast or past perfect.
This prevents a number of theabove errors and suggests that changes in tense, as-pect, and modality are promising clues to explorefor recognizing subdialogs in this kind of data (cf.,e.g., Grosz & Sidner 1986; Nakhimovsky 1988).
TheCMU data has very little variation in tense and as-pect, the reason a mechanism for interpreting themwas not incorporated into the Mgorithm.Ros@ et al (1995) report that "multiple threads",when the participants are negotiating separatetimes, pose challenges to a stack-based iscoursemodel on both the intentional nd attentional levels.They posit a more complex representation f Atten-tional State to meet these challenges.
They reportimproved results on speech-act resolution i  a corpusof scheduling dialogs.Here, we focus on just the attentionM level.
Thestructure relevant for the task addressed in this pa-per is the following, corresponding to their figure2.
There are four Temporal Units mentioned in theorder TU1, TU2, TU3, TU4 (other times could bementioned in between).
The (attentional) multiplethread case is when TU1 is required to be an an-tecedent of TU3, but TU2 is also needed to interpretTU4.
Thus, TU2 cannot be simply thrown away orignored once we are done interpreting TUs.
Thisstructure would definitely pose a difficult problemfor our algorithm, but there are no realizations, interms of our model, of this structure in the data weanalyzed.The different findings might be due to the factthat different problems are being addressed.
Hav-ing no intentional state, our model does not distin-guish times being negotiated from other times.
Itis possible that another structure is relevant for theintentional level: Ros@ et al (1995) do not specifywhether or not this is so.
The different findings mayalso be due to differences in the data: although theirscheduling dialogs were collected under similar pro-tocols, their protocol is like a radio conversation iwhich a button must be pressed in order to trans-mit, resulting in less dynamic interaction and longerturns (Villa 1994).An important discourse feature of the dialogs isthe degree of redundancy of the times mentioned(Walker 1996).
This limits the ambiguity of thetimes specified, and it also leads to a higher level ofrobustness, ince additional DE's with the same timeare placed on the focus list.
These "backup" DE'smight be available in case the rule applications failon the most recent DE.
Table 6 presents measuresof redundancy.
For illustration, the redundancy isbroken down into the case where redundant plus ad-ditional information is provided ("redundant") ver-sus the case where the temporM information is justrepeated ("reiteration").
This shows that roughly25% of the CMU utterances with temporal informa-tion contain redundant temporal references, while20% of the NMSU ones do.7 Conc lus ionsThis paper presented an intercoder reliability studyshowing strong reliability in coding the temporal in-formation targeted in this work.
A model of tem-poral reference resolution in scheduling dialogs waspresented which supports linear recency and hasvery good coverage; and, an algorithm based on themodel was described.
The analysis of the detailed re-sults showed that the implemented system performsquite well (for instance, 81% accuracy vs. a lowerbound of 43% on the unseen CMU test data).We also assessed the challenges presented by thedata to a method that does not recognize discoursestructure, based on an extensively annotated corpusand our experience developing a fully automatic sys-tem.
In an overwhelming number of cases, the lastmentioned time is an appropriate antecedent withrespect o our model, in both the more and the lessconstrained data.
In the less constrMned ata, someerror occurs due to subdialogs, so an extension tothe approach isneeded to handle them.
But in noneof these cases would subsequent errors result if, uponexiting the subdialog, the offending information werepopped off a discourse stack or otherwise made in-accessible.
Changes in tense, aspect, and modalityare promising clues for recognizing subdialogs in thisdata, which we plan to explore in future work.8 AcknowledgementsThis research was supported in part by the Depart-ment of Defense under grant number 0-94-10.
Anumber of people contributed to this work.
Wewant to especially thank David Farwell, Daniel Villa,Carol Van Ess-Dykema, Karen Payne, Robert Sin-clair, Rocio Guill~n, David Zarazua, Rebecca Bruce,Gezina Stein, Tom Herndon, and CMU's Enthusiastproject members, whose cooperation greatly aidedour project.Re ferencesAlexandersson, Jan, Reithinger,Norbert, & Maier,Elisabeth (1997).
Insights into the dialogue pro-cessing of VERBMOBIL.
In Proc.
5th Conferenceon Applied Natural Language Processing, Wash-ington D.C., pp.
33-40.184Dialog Set Temporal Utterancescmu 210nmsu 122Redundant Reiteration36 2011 13Table 6: Redundancy in the Training Dialogs%261719.7Allen, J.F.
(1984).
Toward a general theory of actionand time.
Artificial Intelligence 23: 123-154.Allen, J.F.
& Perrault, C.R.
(1980).
Analyzing inten-tion in utterances.
Artificial Intelligence 15: 143-178.Arhenberg, L., Dahlb~ick, N., & JSnsson, A.
(1995).Coding schemes for natural language dialogues.
InWorking Notes of AAAI Spring Symposium: Em-pirical Methods in Discourse Interpretation andGeneration, pp.
8-13.Busemann, Stephan, Declerck, Thierry, Diagne, Ab-del Kader, Dini, Luca, Klein, Judith, & Schmeier,Sven (1997).
Natural anguage dialogue service forappointment scheduling agents.
In Proc.
5th Con-ference on Applied Natural Language Processing,Washington D.C., pp.
25-32.Carletta, J.
(1996).
Assessing agreement on classifi-cation tasks: the kappa statistic.
ComputationalLinguistics 22(2): 249-254.Condon S. & Cech C. (1995).
Problems for reliablediscourse coding schemes.
In Proc.
AAAI SpringSymposium on Empirical Methods in DiscourseInterpretation and Generation, pp.
27-33.Grosz, B., Joshi, A., & Weinstein, S. (1995).
Cen-tering: A Framework for Modeling the Local Co-herence of Discourse.
Computational Linguistics21(2): 203-225.Grosz, B.
& Sidner, C. (1986).
Attention, inten-tion, and the structure of discourse.
Computa-tional Linguistics 12(3): 175-204.Hays, W. L. (1988) Statistics.
Fourth Edition.
Holt,Rinehart, and Winston.Hirschberg, J.
& Nakatani, C. (1996).
A prosodicanalysis of discourse segments in direction-givingmonologues.
In Proc.
3Jth Annual Meeting of theAssociation for Computational Linguistics, SantaCruz, CA., pp.
286-293.Hwang, C.H.
~ Schubert, L. (1992).
Tense trees asthe "fine structure" of discourse.
In Proc.
30thAnnual Meeting of the Association for Computa-tional Linguistics, Newark, DE., pp.
232-240.Isard, A.
& Carletta, J.
(1995).
Replicability oftransaction and action coding in the map taskcorpus.
In Working Notes of AAAI Spring Sympo-sium: Empirical Methods in Discourse Interpreta-tion and Generation, pp.
60-66.Kameyama, M., Passonneau, R., ~ Poesio, M.(1993).
Temporal centering.
In Proc.
of the 31stAnnual Meeting of the Association for Computa-tional Linguistics, Columbus, Ohio, pp.
70-77.Kamp, Hans, & Reyle, Uwe (1993).
From Discourseto Logic, Studies in Linguistics and Philosophy,Volume 42, part 2, (Dordrecht, The Netherlands: -Kluwer Academic Publishers).Lascarides, A., Asher, N., & Oberlander, J.
(1992)Inferring discourse relations in context.
In Proc.30th Annual Meeting of the Association for Com-putational Linguistics, Newark, DE., pp.
1-8.Lavie, A.
& Tomita, M. (1993).
GLR* - An efficientnoise skipping parsing algorithm for context freegrammars.
In Proc.
3rd International Workshopon Parsing Technologies.
Tilburg, The Nether-lands.Levin, L., Glickman, O., Qu, Y., Gates, D., Lavie,A, Rosd, C.P., Van Ess-Dykema, C., & Waibel,A.
(1995).
Using context in the machine trans-lation of Spoken Language.
In Proc.
Theoreticaland Methodological Issues in Machine Transla-tion, (TMI-95).Litman, D. & Passonneau, R. (1995).
Combiningmultiple knowledge sources for discourse segmen-tation.
In Proc.
33rd Annual Meeting of the Asso-ciation for Computational Linguistics, MIT, pp.130-143.Mann, W. & Thompson, S. (1988).
Rhetorical Struc-ture Theory: Toward a functional theory of textorganization.
Text 8(3): 243-281.Moser, M. & Moore, J.
(1995).
Investigating cue se-lection and placement in tutorial discourses.
InProc.
33rd Annual Meeting of the Association forComputational Linguistics, MIT, pp.
130-143.Nakhimovsky, A.'
(1988).
Aspect, aspectual class,and the temporal structure of narrative.
Compu-tational Linguistics 14(2): 29-43.Passonneau, R.J. & Litman, D.J.
(1993).
Intention-based segmentation: human reliability and cor-relation with linguistic ues.
In Proc.
of the 31st185Annual Meetin 9 of the Association for Computa-tional Linguistics, pp.
148-155.Qu, Y., Di Eugenio, B., Lavie, A., Levin, L., & RosS,C.P.
(1996).
Minimizing cumulative rror in dis-course context.
In ECAI Workshop Proceedings onDialogue Processing in Spoken Language Systems.RosS, C.P., Di Eugenio, B., Levin, L., & Van Ess-Dykema, C. (1995).
Discourse processing of dia-logues with multiple threads.
In Proc.
33rd An-nual Meeting of the Association for Computa-tional Linguistics, pp.
31-38.Shum, B., Levin, L., Coccaro, N., Carbonell, J.,Horiguchi, K., Isotani, H., Lavie, A., Mayfield,L., RosE, C.P., Van Ess-Dykema, C., & Waibel,A.
(1994).
Speech-language integration i  a multi-lingual speech translation system.
In Proceedingsof the AAAI Workshop on Integration of NaturalLanguage and Speech Processing.Sidner, C. (1979).
Towards a Computational Theoryof Definite Anaphora Comprehension in EnglishDiscourse.
Doctoral dissertation, Artificial Intelli-gence Laboratory, MIT, Cambridge, MA.
Techni-cal Report 537.Siegel, S., & Castellan, Jr. N. J.
(1988).
Nonparamet-ric Statistics for the Behavioral Sciences.
Secondedition.
(New York: McGraw-Hill).Song, F. & Cohen, R. (1991).
Tense interpretationin the context of narrative.
In Proc.
9th NationalConference on Artificial Intelligence (AAAI-91),pp.
131-136.Villa, D. (1994).
Effects of protocol on discourse in-ternal and external illocutionary markers in span-ish dialogs.
Presented at Linguistic Association ofthe Southwest Conference XXIII, Houston, TX,October 21-23, 1994.Walker, L. (1996).
Limited attention and discoursestructure.
Computational Linguistics 22(2): 255-264.Webber, B.L.
(1988).
Tense as discourse anaphor.Computational Linguistics 14(2): 61-73.Wiebe, J., Farwell, D., Villa, D., Chen, J-L, Sin-clair, R., Sandgren, T., Stein, G., Zarazua, D., &O'Hara, T. (1996).
ARTWORK: Discourse pro-cessing in machine translation of dialog.
Technicalreport MCCS-96-294, Computing Research Labo-ratory, New Mexico State University.186
