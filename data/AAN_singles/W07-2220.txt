Proceedings of the 10th Conference on Parsing Technologies, pages 168?170,Prague, Czech Republic, June 2007. c?2007 Association for Computational LinguisticsData-Driven Dependency Parsing across Languages and Domains:Perspectives from the CoNLL 2007 Shared TaskJoakim NivreVa?xjo?
University, School of Mathematics and Systems EngineeringUppsala University, Department of Linguistics and PhilologyE-mail: nivre@msi.vxu.seAbstractThe Conference on Computational NaturalLanguage Learning features a shared task, inwhich participants train and test their learn-ing systems on the same data sets.
In 2007,as in 2006, the shared task has been devotedto dependency parsing, this year with both amultilingual track and a domain adaptationtrack.
In this paper, I summarize the mainfindings from the 2007 shared task and tryto identify major challenges for the parsingcommunity based on these findings.1 IntroductionThe annual Conference on Computational NaturalLanguage Learning (CoNLL) has for the past nineyears organized a shared task, where participantstrain and test their learning systems on the samedata sets.
In 2006, the shared task was multilin-gual dependency parsing, where participants had totrain and test a parser on data from thirteen differ-ent languages (Buchholz and Marsi, 2006).
In 2007,the task was extended by adding a second track for(monolingual) domain adaptation.The CoNLL 2007 shared task on dependencyparsing featured two tracks:?
In the multilingual track, the task was to train aparser using labeled data from Arabic, Basque,Catalan, Chinese, Czech, English, Greek, Hun-garian, Italian, and Turkish.?
In the domain adaptation track, the task wasto adapt a parser for English news text to otherdomains using unlabeled data from the targetdomains: biomedical and chemical abstracts,parent-child dialogues.1 In the closed class, thebase parser had to be trained using the Englishtraining set for the multilingual track and noexternal resources were allowed.
In the openclass, any base parser could be used and anyexternal resources were allowed.Both tracks used the same column-based format forlabeled data with six input columns and two outputcolumns for each word of a sentence:?
Input: word-id, word form, lemma, coarse partof speech, fine part-of-speech, morphosyntacticfeatures.?
Output: head (word-id), dependency label.The main evaluation metric for both tracks was thelabeled attachment score (LAS), i.e., the percentageof words that have been assigned the correct headand dependency label.
For more information aboutthe setup, see Nivre et al (2007)In this paper, I will summarize the main findingsfrom the CoNLL 2007 shared task, starting witha characterization of the different approaches used(section 2), and moving on to the most interestingresults in the multilingual track (section 3) and thedomain adaptation track (section 4).
Finally, basedon these findings, I will try to identify some im-portant challenges for the wider parsing community(section 5).1The biomedical domain was the development domain,which means that a small labeled development set was availablefor this domain.
The final testing was only done on chemicalabstracts and (optionally) parent-child dialogues.1682 ApproachesIn total, test runs were submitted for twenty-threesystems in the multilingual track, and ten systems inthe domain adaptation track (six of which also par-ticipated in the multilingual track).
The majority ofthese systems used models belonging to one of thetwo dominant approaches in data-driven dependencyparsing in recent years (McDonald and Nivre, 2007):?
In graph-based models, every possible depen-dency graph for a given input sentence is givena score that decomposes into scores for the arcsof the graph.
The optimal parse can be foundusing a spanning tree algorithm (Eisner, 1996;McDonald et al, 2005).?
In transition-based models, dependency graphsare modeled by sequences of parsing actions(or transitions) for building them.
The searchfor an optimal parse is often deterministic andguided by classifiers (Yamada and Matsumoto,2003; Nivre, 2003).The majority of graph-based parsers in the sharedtask were based on what McDonald and Pereira(2006) call the first-order model, where the scoreof each arc is independent of every other arc, butthere were also attempts at exploring higher-ordermodels, either with exact inference limited to pro-jective dependency graphs (Carreras, 2007), or withapproximate inference (Nakagawa, 2007).
Anotherinnovation was the use of k-best spanning tree algo-rithms for inference with a non-projective first-ordermodel (Hall et al, 2007b).For transition-based parsers, the trend was clearlyto move away from deterministic parsing by addinga probability model for scoring a set of candidateparses typically derived using a heuristic searchstrategy.
The probability model may be either con-ditional (Duan et al, 2007) or generative (Titov andHenderson, 2007).An interesting way of combining the two mainapproaches is to use a graph-based model to buildan ensemble of transition-based parsers.
This tech-nique, first proposed by Sagae and Lavie (2006), wasused in the highest scoring system in both the mul-tilingual track (Hall et al, 2007a) and the domainadaptation track (Sagae and Tsujii, 2007).3 Multilingual ParsingThe ten languages involved in the multilingual trackcan be grouped into three classes with respect to thebest parsing accuracy achieved:?
Low (LAS = 76.3?76.9):Arabic, Basque, Greek?
Medium (LAS = 79.2?80.2):Czech, Hungarian, Turkish?
High (LAS = 84.4?89.6):Catalan, Chinese, English, ItalianTo a large extent, these classes appear to be definablefrom typological properties.
The class with the high-est top scores contains languages with a rather im-poverished morphology.
Medium scores are reachedby the two agglutinative languages, Hungarian andTurkish, as well as by Czech.
The most difficult lan-guages are those that combine a relatively free wordorder with a high degree of inflection.
Based onthese characteristics, one would expect to find Czechin the last class.
However, the Czech training setis four times the size of the training set for Arabic,which is the language with the largest training setof the difficult languages.
On the whole, however,training set size alone is a poor predictor of parsingaccuracy, which can be seen from the fact that theItalian training set is only about half the size of theArabic one and only one sixth of Czech one.
Thus,there seems to be a need for parsing methods thatcan cope better with richly inflected languages.4 Domain AdaptationOne result from the domain adaptation track thatmay seem surprising at first was the fact that thebest closed class systems outperformed the bestopen class systems on the official test set containingchemical abstracts.
To some extent, this may be ex-plained by the greater number of participants in theclosed class (eight vs. four).
However, it also seemsthat the major problem in adapting existing, oftengrammar-based, parsers to the new domain was notthe domain as such but the mapping from the nativeoutput of the parser to the kind of annotation pro-vided in the shared task data sets.
In this respect,the closed class systems had an advantage by havingbeen trained on exactly this kind of annotation.
This169result serves to highlight the fact that domain adapta-tion, as well as the integration of grammar-based anddata-driven methods, often involves transformationsbetween different kinds of linguistic representations.The best performing (closed class) system in thedomain adaptation track used a combination of co-learning and active learning by training two differentparsers on the labeled training data, parsing the un-labeled domain data with both parsers, and addingparsed sentences to the training data only if the twoparsers agreed on their analysis (Sagae and Tsujii,2007).
This resulted in a LAS of 81.1 on the test setof chemical abstracts, to be compared with 89.0 forthe English test set in the multilingual track.5 ConclusionBased on the results from the CoNLL 2007 sharedtask, it is clear that we need to improve our methodsfor parsing richly inflected languages.
We also needto find better ways of integrating parsers developedwithin different frameworks, so that they can bereused effectively for, among other things, domainadaptation.
More generally, we need to increase ourknowledge of the multi-causal relationship betweenlanguage characteristics, syntactic representations,and parsing and learning methods.
In order to dothis, perhaps we also need a shared task at the Inter-national Conference on Parsing Technologies.AcknowledgmentsI want to thank my fellow organizers of the sharedtask, Johan Hall, Sandra Ku?bler, Ryan McDonald,Jens Nilsson, Sebastian Riedel, and Deniz Yuret,who are also co-authors of the longer paper on whichthis paper is partly based (Nivre et al, 2007).
I amalso indebted to all the people who have contributedto the shared task by providing data or participating.ReferencesS.
Buchholz and E. Marsi.
2006.
CoNLL-X sharedtask on multilingual dependency parsing.
In Proc.
ofCoNLL, 149?164.X.
Carreras.
2007.
Experiments with a high-order pro-jective dependency parser.
In Proc.
of EMNLP-CoNLL(Shared Task).X.
Duan, J. Zhao, and B. Xu.
2007.
Probabilistic parsingaction models for multi-lingual dependency parsing.In Proc.
of EMNLP-CoNLL (Shared Task).J.
M. Eisner.
1996.
Three new probabilistic models fordependency parsing: An exploration.
In Proc.
of COL-ING, 340?345.J.
Hall, J. Nilsson, J. Nivre, G. Eryigit, B. Megyesi,M.
Nilsson, and M. Saers.
2007a.
Single malt orblended?
A study in multilingual parser optimization.In Proc.
of EMNLP-CoNLL (Shared Task).K.
Hall, J. Havelka, and D. Smith.
2007b.
Log-linearmodels of non-projective trees, k-best MST parsingand tree-ranking.
In Proc.
of EMNLP-CoNLL (SharedTask).R.
McDonald and J. Nivre.
2007.
Characterizing theerrors of data-driven dependency parsing models.
InProc.
of EMNLP-CoNLL.R.
McDonald and F. Pereira.
2006.
Online learning ofapproximate dependency parsing algorithms.
In Proc.of EACL, 81?88.R.
McDonald, F. Pereira, K. Ribarov, and J. Hajic?.
2005.Non-projective dependency parsing using spanningtree algorithms.
In Proc.
of HLT/EMNLP, 523?530.T.
Nakagawa.
2007.
Multilingual dependency parsingusing gibbs sampling.
In Proc.
of EMNLP-CoNLL(Shared Task).J.
Nivre and J. Nilsson.
2005.
Pseudo-projective depen-dency parsing.
In Proc.
of ACL, 99?106.J.
Nivre, J.
Hall, S. Ku?bler, R. McDonald, J. Nils-son, S. Riedel, and D. Yuret.
2007.
The CoNLL2007 shared task on dependency parsing.
In Proc.
ofEMNLP-CoNLL (Shared Task).J.
Nivre.
2003.
An efficient algorithm for projective de-pendency parsing.
In Proc.
of IWPT, 149?160.K.
Sagae and A. Lavie.
2006.
Parser combination byreparsing.
In Proc.
of HLT-NAACL (Short Papers),129?132.K.
Sagae and J. Tsujii.
2007.
Dependency parsing anddomain adaptation with LR models and parser ensem-bles.
In Proc.
of EMNLP-CoNLL (Shared Task).I.
Titov and J. Henderson.
2007.
Fast and robust mul-tilingual dependency parsing with a generative latentvariable model.
In Proc.
of EMNLP-CoNLL (SharedTask).H.
Yamada and Y. Matsumoto.
2003.
Statistical depen-dency analysis with support vector machines.
In Proc.of IWPT, 195?206.170
