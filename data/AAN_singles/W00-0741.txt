In: Proceedings of CoNLL-2000 and LLL-2000, pages 194-198, Lisbon, Portugal, 2000.Learning from Parsed Sentences with INTHELEXF.
Espos i to  and S. Feri l l i  and N. Fanizz i  and G. SemeraroDipartimento di InformaticaUniversit?
di Barivia E. Orabona, 4 - 70126 Bari - Italia{esposito, ferilli, fanizzi, semeraro}~di.uniba.itAbst ractIn the context of language l arning, we address alogical approach to information extraction.
Thesystem INTHELEX, used to carry out this task,requires a logic representation f sentences torun the learning algorithm.
Hence, the needfor parsers to produce structured representa-tions from raw text.
This led us to develop aprototypical Italian language parser, as a pre-processor in order to obtain the structured rep-resentation of sentences required for the sym-bolic learner to work.
A preliminary exper-imentation proved that the logic approach tolearning from language is able to capture thesemantics underlying the kind of sentences thatwere processed, even if a comparison with clas-sical methods as regards efficiency has still tobe done.1 In t roduct ionLanguage learning has gained growing attentionin the last years.
Statistical approaches, o farextensively used - -  see (Saitta and Neri, 1997)for an overview of the research in this area --,have severe limitations, whereas the flexibilityand expressivity of logical representations makethem highly suitable for natural anguage anal-ysis (Cussens, 1999).
Indeed, logical approachesmay have a relevant impact at the level of se-mantic interpretation, where a logical represen-tation of the meaning of a sentence is importantand useful (Mooney, 1999).Logical approaches have been already em-ployed in Text Categorization and/or Informa-tion Extraction.
Yet they try to use an expres-sive representation language such as first-orderlogic to define simple properties about tex-tual sources, regarded, for instance, as bags ofwords (Junker et al, 1999) or as semi-structuredtexts (Freitag, 2000).
These properties are of-ten loosely related with the grammar of theunderlying language, often relying on extra-grammatical features (Cohen, 1996).
We intendto exploit a logic representation for exploitingthe grammatical structure of texts, as it couldbe detected using a proper parser.
Indeed, amore knowledge intensive technique is likely toperform better applied on the tasks mentionedabove.When no background knowledge about thelanguage structure is assumed to be available,one of the fundamental problems with the adop-tion of logic learning techniques i  that a struc-tured representation of sentences is requiredon which the learning algorithm can be run.Thus, the need arises for parsers that are ableto discover such a structure starting from raw,unstructured text.
Research in this field hasproduced a variety of tools and techniques forEnglish, that cannot be applied to other lan-guages, such as Italian, because of the differ-ent, and sometimes much more complex, gram-matical structure.
Such considerations led us todevelop a prototypical Italian language parser,that could serve as a pre-processor f texts inorder to obtain the structured representation fsentences that is needed for the symbolic learnerto work.
It is fundamental to note that the fo-cus of this paper is not the parser, that does notadopt sophisticated NLP techniques.
The aimhere is investigating the feasibility of learningsemantic definitions for some kinds of sentences.Even more so, the availability of a professionalparser will further enhance the performance ofthe whole process.Further problems in applying relational learn-ing to language are due to the intrinsic compu-tational complexity of these methods, as a draw-194back of the expressive power gained through re-lations.
Moreover, another weakness of our ap-proach could be the dependence on the qualityof the data coming from the preprocessing step:it is possible that noise coming from wronglyparsed sentences be present, thus having a neg-ative influence towards the model to be induced.After briefly presenting in Section 2 theparser performance, in order to establish the de-gree of reliability of the data on which the learn-ing step is performed, Section 3 shows the re-sults of applying the first-order learning systemINTHELEX (Esposito et al, 2000) for the in-ference of some simple events related to foreigncommerce.
Lastly, Section 4 draws some prelim-inary conclusions on this research and outlinesfuture work issues to be addressed.2 A S t ra t i f i ed  Parser  for I ta l ianLanguageThis section presents a parser for the Italianlanguage, based on context-free grammars anddesigned to manage texts having a simple andstandard phrase structure (e.g., foreign com-merce texts as opposed to poetry texts).
Itis composed by 12 parsing levels and 106 pro-duction rules, and uses the longest-match tech-nique, which complies with the typical ambigu-ity of Italian language.
Syntactic lookahead isused to overcome ambiguity and to prevent heparsing from stopping in case of grammaticallywrong input.The text is segmented in progressively argersyntactic constructs.
Subject, main verb, di-rect or indirect object and clauses referring tothem are identified.
Nested syntactic onstructsat the same abstraction level (e.g., expressionsincluding a sentence in parentheses) are sup-ported.Plain text documents are provided to a lexicalanalyzer and a noun-recognizer (XEROX MUL-TEXT), whose output is the document exttagged with parts of speech to be fed to theparser.
Since Italian grammar is very differ-ent from the English one, some terms do nothave an English equivalent and, hence, cannotbe translated.The parser was validated on a set of 72sentences drawn from a corpus of articles onforeign commerce available on the Internet,and the results obtained were evaluated withParsing Phase Precision RecallNoun Groups 0.984 0.992lst-level NPs 0.994 0.9942nd level NPs 0.983 0.983PPs 0.951 0.951Clauses 0.840 0.840Refined clauses 0.913 0.913Sentences 0.736 0.736Table 1: Summary of parser validation results(Precision/Recall)Parsing Phase Errorl  Error2Noun Groups 0.787% 0.793%1st level NPs 0.596% 0.596%2nd level NPs 1.666% 1.666%PPs 4.918% 4.918%Clauses 15.941% 15.941%Refined clauses 8.695% 8.695%Sentences 26.384% 26.384%Table 2: Summary of parser validation results(Errorl/Error2)respect o precision, recall (reported in Table 1)and two measures about error ratio:Errorl = # errors/# total constituents extractedError2 = # errors/# total correct constituents expected(see Table 2).3 In fo rmat ion  ext rac t ionThe grammar above was used to parse Italiantexts downloaded from the Internet, and con-cerning foreign commerce.
Through such pre-processing, the aim was to obtain some struc-ture for those texts that could then be trans-lated in the input language of the learning sys-tem INTHELEX (Esposito et al, 2000) in orderto make it learn simple events concerning thatdomain.INTHELEX (INcremental THEory Learnerfrom EXamples) is a fully incremental, multi-conceptual closed loop learning system for theinduction of hierarchical theories from exam-ples.
In detail, full incrementality avoids theneed of a previously generated version of thetheory to be available, so that learning can startfrom an empty theory and from the first exam-195ple; multi-conceptual means that it ,:an learn si-multaneously various concepts, possibly relatedto each other; a closed loop system is a systemin which the learned theory is checked to bevalid on any new example available, and in caseof failure a revision process is activated on it,in order to restore the completeness and consis-tency properties.Incremental learning is necessary when eitherincomplete information is available at the timeof initial theory generation, or the nature of theconcepts evolves dynamically.
The latter situ-ation is the most difficult to handle since timeevolution needs to be considered.
In any case,it is useful to consider learning as a closed loopprocess, where feedback on performance is usedto activate the theory revision phase.INTHELEX learns theories, from positive andnegative examples described in the same lan-guage.
It adopts a full memory storage strategy- -  i.e., it retains all the available xamples, thusthe learned theories are guaranteed to be validon the whole set of known examples.In the formal representation of texts, we usedthe following descriptors:?
sent  (e l ,e2)  e2 is a sentence fi:om el?
subj  (e l ,e2)  e2 is the subject of el?
obj (e l ,e2)  e2 is the (direct) object of el?
i nd i rec t_ob j  (e l  ,e2) e2 is an indirect ob-ject of el?
re l _sub j  (e l ,e2)  e2 is a clause related tothe subject el?
re l _ob j (e l ,e2)  e2 is a clause related tothe object el?
verb(e l ,e2)  e2 is the verb of el?
lemma(e2) word e2 has lemma lemma?
i n f in i te (e2)  verb e2 is in an infinitemood?
f in i te  (e2) verb e2 is in a finite mood?
a f f i rmat ive(e2)  verb e2 is in an affirma-tive mood?
negat ive(e2)  verb e2 is in a negativemood?
np(e l ,e2)  e2 is a 2nd level NP of el?
pp(e l ,e2)  e2 is a PP  of elwhere lemma is a meta-predicate.
This allowsthe system to exploit information about wordlemmas in generalizations/specializations, a din the recognition of higher level concepts ofwhich lemma is an instance.Thus, the following Horn clause is an instanceof an example:imports (example) ~--sent (example ,el),subj (example, e2),np(e2,e3),impresa(e3),rel_subj (el ,e4),verb (e4, e5),specializzare (e5),infinite (e5),affirmative (e5),pp(e4,e6),distrubuzione (e6),componente (e6),verb(el,eT),interessare (e7),finite (eT),affirmative (eT),indirect_obj (el, e8),pp(e8,e9),importazione (eg),macchina(e9) ,produzione (e9),ombrello (eg).A first experiment aimed at learning the con-cept of specialization (of someone in some field).The system was run on 40 examples, 24 posi-tive and 16 negative.
The resulting theory wasmade up by 5 clauses, some of which differ justin one literal (e.g., the lemma of the word in thesubject).
By exploiting the background knowl-edge that terms 'impresa', 'societY', 'ditta' and'agenzia' are all instances of the concept 'per-sona giuridica', i.e.
clauses:persona_g iur id ica  (X) +-d i t ta (X) .persona_g iur id ica  (X) +--soc ie ta (X) .persona_g iur id ica (X)  ~-impresa(X) .persona_g iur id ica (X)  +-agenz ia (X) .196the theory becomes more compact, yieldingthe following rules:specialization(A)~-sent(A,B),subj(B,C), np(C,D),persona_giuridica(D),verb(B,E),specializzare(E),finite(E),affirmative(E),indirect_obj(B,F),pp(F,_).specialization(A)~-sent(A,B),subj(B,C), np(C,D),persona_giuridica(D),rel_subj(B,E),verb(E,F),specializzare(F),affirmative(F),pp(E,_), verb(B,_).Another experiment aimed at learning theconcept of "imports".
INTHELEX was runstarting from the empty theory, and was fedwith a total of 67 examples (39 positive and 28negative).
It should be noted that not all posi-tive examples explicitly use verb 'importare' (toimport): e.g., in the sentence "Societ& belga,specializzata nella lavorazione del legno, cercafornitori di legname" the imports event is char-acterized by the noun 'societ&' (society) as thesentence subject, by the verb 'cercare' (to lookfor) and by the object including the noun 'for-nitore' (provider).
We obtained the followingresults (in which the above background knowl-edge was used to compress more rules into one,too):imports(A) ~- sent(A,B),subj(B,C), np(C,D),persona_giuridica(D),verb(B,E),cercare(E),finite(E),affirmative(E),obj(B,F), np(F,G),fornitore(G).imports(A) ~-sent(A,B),subj(B,C), np(C,D),persona_giuridica(D),societa(D),verb(B,E),cercare(E),finite(E),affirmative(E),obj(B,F), np(F,G),distributore(G).imports(A) ~-sent(A,B),subj(B,C), np(C,D),persona_giuridica(D),verb(B,E),interessare(E),finite(E),affirmative(E),indirect_obj(B,F),pp(F,G),importazione(G).imports(A) ~-sent (A ,B) ,subj(B,C),  np(C,D),persona_giur id ica(D) ,verb(B,E) ,acqu is tare (E) ,f in i te (E ) ,a f f i rmat ive(E) .imports(A) ~-sent(A,B),subj(B,C), np(C,D),persona_giuridica(D),impresa(D),verb(B,E),importare(E),finite(E),affirmative(E).For instance, the third clause means: "Text Adeals with imports if it contains a sentence witha subject composed by a NP containing a per-sona giuridica, the verb of the main sentenceis interessare (to interest) in finite affirmativemood, and the indirect object consists of a PPcontaining the word importazione".
Note that,by exploiting a background knowledge that rep-resents a more complex ontology than the cur-rent one, it would be possible to further mergeconceptual descriptors and, as a consequence,clauses in the theory.
For example, 'fornitore'(provider) and 'distributore' (distributor) couldbe recognized as instances of a common higherlevel concept; the same applies to 'acquistaxe'(to buy) and 'importare' (to import).1974 Conc lus ions  & Future  WorkWe have addressed the problem of learning logictheories for information extraction so to bene-fit by the semantic interpretation provided bya logical approach.
This has required struc-tured sentences in a logic representation onwhich to run our learning algorithms.
Hence,we needed a parser to produce structured repre-sentations from raw unstructured text.
Thoughmany techniques have been developed for En-glish, they cannot be applied to other languages,such as Italian, because of the different gram-matical structure.
This has led us to develop aprototypical Italian language parser, as a pre-processor in order to obtain the structured rep-resentation ofsentences needed for the symboliclearner to work.Future work will concern a more extensive ex-perimentation, an empirical evaluation of ourapproach, and application of the same kind ofexperiments on English parsed texts.
If goodresults will be obtained, it is possible thinkingto carry out experiments hat take advantagealso from the structure of semi-structured doc-uments.
Indeed, we are involved in the projectCDL (Esposito et al, 1998; Costabile et al,1999), that could profit by this kind of tech-niques as regard semantic indexing of the storeddocuments (cf.
(Chanod, 1999)).Re ferencesJ.-P. Chanod.
1999.
Natural language processingand digital libraries.
In M.T.
Pazienza, editor,Information Extraction, volume 1714 of LectureNotes in Artificial Intelligence Tutorial, pages 17-31.
Springer.W.
Cohen.
1996.
Learning to classify english textwith ilp methods.
In Luc de Raedt, editor, Ad-vances in Inductive Logic Programming, pages124-143.
IOS Press, Amsterdam, NL.M.F.
Costabile, F. Esposito, G. Semeraro, andN.
Fanizzi.
1999.
An adaptive visual environmentfor digital libraries.
International Journal of Dig-ital Libraries, 2:124-143.J.
Cussens, editor.
1999.
Learning Language inLogic.
Workshop on Learning Language in Logic,Workshop Notes.F.
Esposito, D. Malerba, G. Semeraro, N. Fanizzi,and S. Ferilli.
1998.
Adding machine learningand knowledge intensive techniques to a digitallibrary service.
International Journal of DigitalLibraries, 2(1):3-19.F.
Esposito, G. Semeraro, N. Fanizzi, and S. Ferilli.2000.
Multistrategy Theory Revision: Inductionand abduction in INTHELEX.
Machine Learn-ing, 38(1/2):133-156.D.
Freitag.
2000.
Machine learning for informationextraction i  informal domains.
Machine Learn-ing, 39(2/3):169-202.M.
Junker, M. Sintek, and M. Rinck.
1999.
Learningfor text categorization a d information extractionwith ILP.
In James Cussens, editor, Proceedingsof the First International Workshop on LearningLanguage in Logic - LLL99.R.
Mooney.
1999.
Learning for semantic interpre-tation: Scaling up without dumbing down.
InCussens (Cussens, 1999), pages 7-15.
Workshopon Learning Language in Logic, Workshop Notes.L.
Saitta and F. Neff.
1997.
Machine learning forinformation extraction.
In M.T.
Pazienza, editor,Information Extraction, volume 1299 of LectureNotes in Artificial Intelligence Tutorial, pages171-191.
Springer.198
