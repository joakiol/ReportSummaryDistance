Proceedings of the ACL-2012 Special Workshop on Rediscovering 50 Years of Discoveries, pages 13?21,Jeju, Republic of Korea, 10 July 2012. c?2012 Association for Computational LinguisticsTowards a Computational History of the ACL: 1980?2008Ashton AndersonStanford Universityashtona@stanford.eduDan McFarlandStanford Universitydmcfarla@stanford.eduDan JurafskyStanford Universityjurafsky@stanford.eduAbstractWe develop a people-centered computationalhistory of science that tracks authors over top-ics and apply it to the history of computa-tional linguistics.
We present four findingsin this paper.
First, we identify the topicalsubfields authors work on by assigning auto-matically generated topics to each paper in theACL Anthology from 1980 to 2008.
Next, weidentify four distinct research epochs wherethe pattern of topical overlaps are stable anddifferent from other eras: an early NLP pe-riod from 1980 to 1988, the period of USgovernment-sponsored MUC and ATIS eval-uations from 1989 to 1994, a transitory perioduntil 2001, and a modern integration periodfrom 2002 onwards.
Third, we analyze theflow of authors across topics to discern howsome subfields flow into the next, forming dif-ferent stages of ACL research.
We find that thegovernment-sponsored bakeoffs brought newresearchers to the field, and bridged early top-ics to modern probabilistic approaches.
Last,we identify steep increases in author retentionduring the bakeoff era and the modern era,suggesting two points at which the field be-came more integrated.1 IntroductionThe rise of vast on-line collections of scholarly pa-pers has made it possible to develop a computationalhistory of science.
Methods from natural languageprocessing and other areas of computer science canbe naturally applied to study the ways a field andits ideas develop and expand (Au Yeung and Jatowt,2011; Gerrish and Blei, 2010; Tu et al, 2010; Aris etal., 2009).
One particular direction in computationalhistory has been the use of topic models (Blei et al,2003) to analyze the rise and fall of research top-ics to study the progress of science, both in general(Griffiths and Steyvers, 2004) and more specificallyin the ACL Anthology (Hall et al, 2008).We extend this work with a more people-centeredview of computational history.
In this framework,we examine the trajectories of individual authorsacross research topics in the field of computationallinguistics.
By examining a single author?s papertopics over time, we can trace the evolution of heracademic efforts; by superimposing these individualtraces over each other, we can learn how the entirefield progressed over time.
One goal is to investi-gate the use of these techniques for computationalhistory in general.
A second goal is to use the ACLAnthology Network Corpus (Radev et al, 2009) andthe incorporated ACL Anthology Reference Corpus(Bird et al, 2008) to answer specific questions aboutthe history of computational linguistics.
What is thepath that the ACL has taken throughout its 50-yearhistory?
What roles did various research topics playin the ACL?s development?
What have been the piv-otal turning points?Our method consists of four steps.
We first runtopic models over the corpus to classify papers intotopics and identify the topics that people author in.We then use these topics to identify epochs by cor-relating over time the number of persons that topicsshare in common.
From this, we identify epochs assustained patterns of topical overlap.Our third step is to look at the flow of authors be-tween topics over time to detect patterns in how au-thors move between areas in the different epochs.We group topics into clusters based on when au-thors move in and out of them, and visualize the flow13of people across these clusters to identify how onetopic leads to another.Finally, in order to understand how the field growsand declines, we examine patterns of entry and exitwithin each epoch, studying how author retention(the extent to which authors keep publishing in theACL) varies across epochs.2 Identifying TopicsOur first task is to identify research topics withincomputational linguistics.
We use the ACL Anthol-ogy Network Corpus and the incorporated ACL An-thology Reference Corpus, with around 13,000 pa-pers by approximately 11,000 distinct authors from1965 to 2008.
Due to data sparsity in early years, wedrop all papers published prior to 1980.We ran LDA on the corpus to produce 100 genera-tive topics (Blei et al, 2003).
Two senior researchersin the field (the third author and Chris Manning) thencollaboratively assigned a label to each of the 100topics, which included marking those topics whichwere non-substantive (lists of function words or af-fixes) to be eliminated.
They produced a consensuslabeling with 73 final topics, shown in Table 1 (27non-substantive topics were eliminated, e.g.
a pro-noun topic, a suffix topic, etc.
).Each paper is associated with a probability distri-bution over the 100 original topics describing howmuch of the paper is generated from each topic.
Allof this information is represented by a matrix P ,where the entry Pij is simply the loading of topicj on paper i (since each row is a probability distri-bution,?j Pij = 1).
For ease of interpretation, wesparsify the matrix P by assigning papers to topicsand thus set al entries to either 0 or 1.
We do thisby choosing a threshold T and setting entries to 1 ifthey exceed this threshold.
If we call the new ma-trix Q, Qij = 1 ??
Pij ?
T .
Throughout allour analyses we use T = 0.1.
This value is approx-imately two standard deviations above P , the meanof the entries in P .
Most papers are assigned to 1or 2 topics; some are assigned to none and some areassigned to more.This assignment of papers to topics also inducesan assignment of authors to topics: an author is as-signed to a topic if she authored a paper assignedto that topic.
Furthermore, this assignment is natu-rally dynamic: since every paper is published in aparticular year, authors?
topic memberships changeover time.
This fact is at the heart of our methodol-ogy ?
by assigning authors to topics in this princi-pled way, we can track the topics that authors movethrough.
Analyzing the flow of authors through top-ics enables us to learn which topics beget other top-ics, and which topics are related to others by the peo-ple that author across them.3 Identifying EpochsWhat are the major epochs of the ACL?s history?
Inthis section, we seek to partition the years spannedby the ACL?s history into clear, distinct periods oftopical cohesion, which we refer to as epochs.
Ifthe dominant research topics people are working onsuddenly change from one set of topics to another,we view this as a transition between epochs.To identify epochs that satisfy this definition, wegenerate a set of matrices (one for each year) de-scribing the number of people that author in everypair of topics during that year.
For year y, let Nybe a matrix such that Nyij is the number of peoplethat author in both topics i and j in year y (whereauthoring in topic j means being an author on a pa-per p such that Qpj = 1).
We don?t normalize bythe total number of people in each topic, thus pro-portionally representing bigger topics since they ac-count for more research effort than smaller topics.Each matrix is a signature of which topic pairs haveoverlapping author sets in that year.From these matrices, we compute a final matrixC of year-year correlations.
Cij is the Pearson cor-relation coefficient between N i and N j .
C capturesthe degree to which years have similar patterns oftopic authorship overlap, or the extent to which aconsistent pattern of topical research is formed.
Wevisualize C as a thermal in Figure 1.To identify epochs in ACL?s history, we ran hier-archical complete link clustering on C. This resultedin a set of four distinct epochs: 1980?1988, 1989?1994, 1995?2001, and 2002?2008.
For three ofthese periods (all except 1995?2001), years withineach of these ranges are much more similar to eachother than they are to other years.
During the thirdperiod (1995?2001), none of the years are highlysimilar to any other years.
This is indicative of a14Number Name Topics1 Big DataNLPStatistical Machine Translation (Phrase-Based): bleu, statistical, source, target, phrases, smt, reorderingDependency Parsing: dependency/ies, head, czech, depen, dependent, treebankMultiLingual Resources: languages, spanish, russian, multilingual, lan, hindi, swedishRelation Extraction: pattern/s, relation, extraction, instances, pairs, seedCollocations/Compounds: compound/s, collocation/s, adjectives, nouns, entailment, expressions, MWEsGraph Theory + BioNLP: graph/s, medical, edge/s, patient, clinical, vertex, text, report, diseaseSentiment Analysis: question/s, answer/s, answering, opinion, sentiment, negative, positive, polarity2 ProbabilisticMethodsDiscriminative Sequence Models: label/s, conditional, sequence, random, discriminative, inferenceMetrics + Human Evaluation: human, measure/s, metric/s, score/s, quality, reference, automatic, correlation, judgesStatistical Parsing: parse/s, treebank, trees, Penn, Collins, parsers, Charniak, accuracy, WSJngram Language Models: n-gram/s, bigram/s, prediction, trigram/s, unigram/s, trigger, show, baselineAlgorithmic Efficiency: search, length, size, space, cost, algorithms, large, complexity, pruningBilingual Word Alignment: alignment/s, align/ed, pair/s, statistical, source, target, links, BrownReRanking: score/s, candidate/s, list, best, correct, hypothesis, selection, rank/ranking, scoring, top, confidenceEvaluation Metrics: precision, recall, extraction, threshold, methods, filtering, extract, high, phrases, filter, f-measureMethods (Experimental/Evaluation): experiments, accuracy, experiment, average, size, 100, baseline, better, per, setsMachine Learning Optimization: function, value/s, parameter/s, local, weight, optimal, solution, criterion, variables3 LinguisticSupervisionBiomedical Named Entity Recognition: biomedical, gene, term, protein, abstracts, extraction, biologicalWord Segmentation: segment/ation, character/s, segment/s, boundary/ies, token/izationDocument Retrieval: document/s, retrieval, query/ies, term, relevant/ance, collection, indexing, searchSRL/Framenet: argument/s, role/s, predicate, frame, FrameNet, predicates, labeling, PropBankWordnet/Multilingual Ontologies: ontology/ies, italian, domain/s, resource/s, i.e, ontological, conceptsWebSearch + Wikipedia: web, search, page, xml, http, engine, document, wikipedia, content, html, query, GoogleClustering + Distributional Similarity: similar/ity, cluster/s/ing, vector/s, distance, matrix, measure, pair, cosine, LSAWord Sense Disambiguation: WordNet, senses, disambiguation, WSD, nouns, target, synsets, YarowskyMachine Learning Classification: classification, classifier/s, examples, kernel, class, SVM, accuracy, decisionLinguistic Annotation: annotation/s/ed, agreement, scheme/s, annotators, corpora, tools, guidelinesTutoring Systems: student/s, reading, course, computer, tutoring, teaching, writing, essayChunking/Memory Based Models: chunk/s/ing, pos, accuracy, best, memory-based, DaelemansNamed Entity Recognition: entity/ies, name/s/d, person, proper, recognition, location, organization, mentionDialog: dialogue, utterance/s, spoken, dialog/ues, act, interaction, conversation, initiative, meeting, state, agentSummarization: topic/s, summarization, summary/ies, document/s, news, articles, content, automatic, stories4 Discourse Multimodal (Mainly Generation): object/s, multimodal, image, referring, visual, spatial, gesture, reference, descriptionText Categorization: category/ies, group/s, classification, texts, categorization, style, genre, authorMorphology: morphological, arabic, morphology, forms, stem, morpheme/s, root, suffix, lexiconCoherence Relations: relation, rhetorical, unit/s, coherence, texts, chainsSpell Correction: error/s, correct/ion, spelling, detection, rateAnaphora Resolution: resolution, pronoun, anaphora, antecedent, pronouns, coreference, anaphoricQuestion Answering Dialog System: response/s, you, expert, request, yes, users, query, question, call, databaseUI/Natural Language Interface: users, database, interface, a71, message/s, interactive, access, displayComputational Phonology: phonological, vowel, syllable, stress, phonetic, phoneme, pronunciationNeural Networks/Human Cognition: network/s, memory, acquisition, neural, cognitive, units, activation, layerTemporal IE/Aspect: event/s, temporal, tense, aspect, past, reference, before, stateProsody: prosody/ic, pitch, boundary/ies, accent, cues, repairs, phrases, spoken, intonation, tone, duration5 EarlyProbabilityLexical Acquisition Of Verb Subcategorization: class/es, verb/s, paraphrase/s, subcategorization, framesProbability Theory: probability/ies, distribution, probabilistic, estimate/tion, entropy, statistical, likelihood, parametersCollocations Measures: frequency/ies, corpora, statistical, distribution, association, statistics, mutual, co-occurrencesPOS Tagging: tag/ging, POS, tags, tagger/s, part-of-speech, tagged, accuracy, Brill, corpora, tagsetMachine Translation (Non Statistical + Bitexts): target, source, bilingual, translations, transfer, parallel, corpora6 Automata Automata Theory: string/s, sequence/s, left, right, transformation, matchTree Adjoining Grammars : trees, derivation, grammars, TAG, elementary, auxiliary, adjoiningFinite State Models (Automata): state/s, finite, finite-state, regular, transition, transducerClassic Parsing: grammars, parse, chart, context-free, edge/s, production, CFG, symbol, terminalSyntactic Trees: node/s, constraints, trees, path/s, root, constraint, label, arcs, graph, leaf, parent7 ClassicLinguisticsPlanning/BDI: plan/s/ning, action/s, goal/s, agent/s, explanation, reasoningDictionary Lexicons: dictionary/ies, lexicon, entry/ies, definition/s, LDOCE,Linguistic Example Sentences: John, Mary, man, book, examples, Bill, who, dog, boy, coordination, clauseSyntactic Theory: grammatical, theory, functional, constituent/s, constraints, LFGFormal Computational Semantics: semantics, logic/al, scope, interpretation, meaning, representation, predicateSpeech Acts + BDI: speaker, utterance, act/s, hearer, belief, proposition, focus, utterancePP Attachment: ambiguity/ies/ous, disambiguation, attachment, preference, prepositionNatural Language Generation: generation/ing, generator, choice, generated, realization, contentLexical Semantics: meaning/s, semantics, metaphor, interpretation, object, roleCategorial Grammar/Logic: proof, logic, definition, let, formula, theorem, every, iff, calculusSyntax: clause/s, head, subject, phrases, object, verbs, relative, nouns, modifierUnification Based Grammars: unification, constraints, structures, value, HPSG, default, headConcept Ontologies / Knowledge Rep: concept/s, conceptual, attribute/s, relation, base8 Government MUC-Era Information Extraction: template/s, message, slot/s, extraction, key, event, MUC, fill/sSpeech Recognition: recognition, acoustic, error, speaker, rate, adaptation, recognizer, phone, ASRATIS dialog: spoken, atis, flight, darpa, understanding, class, database, workshop, utterances9 Early NLU 1970s-80s NLU Work: 1975-9, 1980-6, computer, understanding, syntax, semantics, ATN, Winograd, Schank, Wilks, lispCode Examples: list/s, program/s, item/s, file/s, code/s, computer, line, output, index, field, data, formatSpeech Parsing And Understanding: frame/s, slot/s, fragment/s, parse, representation, meaningTable 1: Results of topic clustering, showing some high-probability representative words for each cluster.15Figure 1: Year-year correlation in topic authoringpatterns.
Hotter colors indicate high correlation,colder colors denote low correlation.state of flux in which authors are constantly chang-ing the topics they are in.
As such, we refer tothis period as a transitory epoch.
Thus our analysishas identified four main epochs in the ACL corpusbetween 1980 and 2008: three focused periods ofwork, and one transitory phase.These epochs correspond to natural eras in theACL?s history.
During the 1980?s, there were co-herent communities of research on natural languageunderstanding and parsing, generation, dialog, uni-fication and other grammar formalizations, and lex-icons and ontologies.The 1989?1994 era corresponds to a number ofimportant US government initiatives: MUC, ATIS,and the DARPA workshops.
The Message Under-standing Conferences (MUC) were an early initia-tive in information extraction, set up by the UnitedStates Naval Oceans Systems Center with the sup-port of DARPA, the Defense Advanced ResearchProjects Agency.
A condition of attending the MUCworkshops was participation in a required evalua-tion (bakeoff) task of filling slots in templates aboutevents, and began (after an exploratory MUC-1 in1987) with MUC-2 in 1989, followed by MUC-3(1991), MUC-4 (1992), MUC-5 (1993) and MUC-6 (1995) (Grishman and Sundheim, 1996).
TheAir Travel Information System (ATIS) was a taskfor measuring progress in spoken language under-standing, sponsored by DARPA (Hemphill et al,1990; Price, 1990).
Subjects talked with a systemto answer questions about flight schedules and air-line fares from a database; there were evaluationsin 1990, 1991, 1992, 1993, and 1994 (Dahl et al,1994).
The ATIS systems were described in pa-pers at the DARPA Speech and Natural LanguageWorkshops, a series of DARPA-sponsored worksh-sop held from 1989?1994 to which DARPA granteeswere strongly encouraged to participate, with thegoal of bringing together the speech and natural lan-guage processing communities.After the MUC and ATIS bakeoffs and theDARPA workshops ended, the field largely stoppedpublishing in the bakeoff topics and transitioned toother topics; participation by researchers in speechrecognition also dropped off significantly.
From2002 onward, the field settled into the modern eracharacterized by broad multilingual work and spe-cific areas like dependency parsing, statistical ma-chine translation, information extraction, and senti-ment analysis.In summary, our methods identify four majorepochs in the ACL?s history: an early NLP period,the ?government?
period, a transitory period, and amodern integration period.
The first, second, andfourth epochs are periods of sustained topical co-herence, whereas the third is a transitory phase dur-ing which the field moved from the bakeoff work tomodern-day topics.4 Identifying Participant FlowsIn the previous section, we used topic co-membership to identify four coherent epochs in theACL?s history.
Now we turn our attention to a finer-grained question: How do scientific areas or move-ments arise?
How does one research area developout of another as authors transition from a previousresearch topic to a new one?
We address this ques-tion by tracing the paths of authors through topicsover time, in aggregate.4.1 Topic ClusteringWe first group topics into clusters based on how au-thors move through them.
To do this, we group yearsinto 3-year time windows and consider adjacent timeperiods.
We aggregate into 3-year windows because16the flow across adjacent single years is noisy and of-ten does not accurately reflect shifts in topical fo-cus.
For each adjacent pair of time periods (for ex-ample, 1980?1982 and 1983?1985), we construct amatrix S capturing author flow between each topicpair, where the Sij entry is the number of authorswho authored in topic i during the first time periodand authored in topic j during the second time pe-riod.
These matrices capture people flow betweentopics over time.Next we compute similarity between topics.
Werepresent each topic by its flow profile, which is sim-ply the concatenation of all its in- and out-flows inall of the S matrices.
More formally, let Fi be the re-sulting vector after concatenating the i-th row (trans-posed into a column) and i-th column of every Smatrix.
We compute a topic-topic similarity matrixT where Tij is the Pearson correlation coefficientbetween Fi and Fj .
Two topics are then similarif they have similar flow profiles.
Note that topicsdon?t need to share authors to be similar ?
authorsjust need to move in and out of them at roughly thesame times.
Through this approach, we identify top-ics that play similar roles in the ACL?s history.To find a grouping of topics that play similar roles,we perform hierarchical complete link clustering onthe T matrix.
The goal is to identify clusters oftopics that are highly similar to each other but aredissimilar from those in other clusters.
Hierarchi-cal clustering begins with every topic forming a sin-gleton cluster, then iteratively merges the two mostsimilar clusters at every step until there is only onecluster of all topics remaining.
Every step givesa different clustering solution, so we assess clus-ter fitness using Krackhard and Stern?s E-I index,which measures the sum of external ties minus thesum of internal ties divided by the sum of all ties.Given T as an input, the E-I index optimizes iden-tical profiles as clusters (i.e., topic stages), not dis-crete groups.
The optimal solution we picked usingthe E-I index entails 9 clusters (shown in Table 1),numbered roughly backwards from the present to thepast.
We?ll discuss the names of the clusters in thenext section.4.2 Flows Between Topic ClustersNow that we have grouped topics into clusters byhow authors flow in and out of them, we can com-pute the flow between topics or between topic clus-ters over time.
First we define what a flow betweentopics is.
We use the same flow matrix used in theabove topic clustering: the flow between topic i inone time period and topic j in the following time pe-riod is simply the number of authors present in bothat the respective times.
Again we avoid normaliz-ing because the volume of people moving betweentopics is relevant.Now we can define flow between clusters.
Let Abe the set of topics in cluster C1 and let B be the setof topics in cluster C2.
We define the flow betweenC1 and C2 to be the average flow between topics inA and B:f(C1, C2) =?A?A,B?B f(A,B)|A| ?
|B|(where f(A,B) represents the topic-topic flowdefined above).
We also tried defining cluster-cluster flow as the maximum over all topic-topicflows between the clusters, and the results werequalitatively the same.Figure 2 shows the resulting flows between clus-ters.
Figure 2a shows the earliest period in our(post-1980) dataset, where we see reflections of ear-lier natural language understanding work by Schank,Woods, Winograd, and others, quickly leading intoa predominance of what we?ve called ?Classic Lin-guistic Topics?.
Research in this period is charac-terized by a more linguistically-oriented focus, in-cluding syntactic topics like unification and catego-rial grammars, formal syntactic theory, and preposi-tional phrase attachments, linguistic semantics (bothlexical semantics and formal semantics), and BDIdialog models.
Separately we see the beginnings ofa movement of people into phonology and discourseand also into the cluster we?ve called ?Automata?,which at this stage includes (pre-statistical) Parsingand Tree Adjoining Grammars.In Figure 2b we see the movement of peopleinto the cluster of government-sponsored topics: theATIS and MUC bakeoffs, and speech.In Figure 2c bakeoff research is the dominanttheme, but people are also beginning to move in andout of two new clusters.
One is Early ProbabilisticModels, in which people focused on tasks like Partof Speech tagging, Collocations, and Lexical Acqui-1787 Classic Ling.9 Early NLU6Automata4Discourse52316.92.60.81.01.71.40.60.80.60.7(a) 1980?1983 ?
1984?19888Gov?t79 Early NLU6Automata4Discourse52313.11.81.60.70.71.21.00.91.8(b) 1986?1988 ?
1989?199187Classic Ling.9Early NLU6Automata45Early Prob.2Prob.
Methods3119.63.12.62.82.72.12.72.42.32.1(c) 1989?1991?1992?199487Classic Ling.96Automata45Early Prob.23Ling.
Supervision13.71.22.71.51.81.11.03.40.90.9(d) 1992?1994?1995?1998879645Early Prob.2Prob.
Methods3 Ling.
Supervision1 Big Data NLP6.73.33.23.73.62.65.74.22.92.7(e) 2002?2004?2005?2007Figure 2: Author flow between topic clusters in five key time periods.
Clusters are sized according to howmany authors are in those topics in the first time period of each diagram.
Edge thickness is proportional tovolume of author flow between nodes, relative to biggest flow in that diagram (i.e.
edge thicknesses in arenot comparable across diagrams).18sition of Verb Subcategorization.
People also beginto move specifically from the MUC Bakeoffs into asecond cluster we call Probabilistic Methods, whichin this very early stage focused on Evaluations Met-rics and Experimental/Evaluation Methods.
Peopleworking in the ?Automata?
cluster (Tree AdjoiningGrammar, Parsing, and by this point Finite StateMethods) continue working in these topics.By Figure 2d, the Early Probability topics arevery central, and probabilistic terminology and earlytasks (tagging, collocations, and verb subcategoriza-tion) are quite popular.
People are now movinginto a new cluster we call ?Linguistic Supervised?, aset of tasks that apply supervised machine learning(usually classification) to tasks for which the gold la-bels are created by linguists.
The first task to appearin this area was Named Entity Recognition, popu-lated by authors who had worked on MUC, and thecore methods topics of Machine Learning Classifi-cation and Linguistic Annotation.
Other tasks likeWord Sense Disambiguation soon followed.By Figure 2e, people are leaving Early Probabil-ity topics like part of speech tagging, collocations,and non-statistical MT and moving into the Linguis-tic Supervised (e.g., Semantic Role Labeling) andProbabilistic Methods topics, which are now verycentral.
In Probabilistic Methods, there are largegroups of people in Statistical Parsing and N-grams.By the end of this period, Prob Methods is sendingauthors to new topics in Big Data NLP, the biggest ofwhich are Statistical Machine Translation and Sen-timent Analysis.In sum, the patterns of participant flows revealhow sets of topics assume similar roles in the his-tory of the ACL.
In the initial period, authors movemostly between early NLP and classic linguisticstopics.
This period of exchange is then transformedby the arrival of government bakeoffs that draw au-thors into supervised linguistics and probabilistictopics.
Only in the 2000?s did the field mature andbegin a new period of cohesive exchange across avariety of topics with shared statistical methods.5 Member Retention and Field IntegrationHow does the ACL grow or decline?
Do authorscome and go, or do they stay for long periods?
Howmuch churn is there in the author set?
How do these1980 1985 1990 1995 2000 2005First year of time frame0.20.30.40.50.60.7AuthorretentionFigure 3: Overlap of authors in successive 3-yeartime periods over time.
The x-axis indicates thefirst year of the 6-year time window being consid-ered.
Vertical dotted lines indicate epoch bound-aries, where a year is a boundary if the first timeperiod is entirely in one epoch and the second is en-tirely in the next.trends align with the epochs we identified?
To ad-dress these questions, we examine author retentionover time ?
how many authors stay in the field ver-sus how many enter or exit.In order to calculate membership churn, we cal-culate the Jaccard overlap in the sets of people thatauthor in adjacent 3-year time periods.
This met-ric reflects the author retention from the first periodto the second, and is inherently normalized by thenumber of authors (so the growing number of au-thors over time doesn?t bias the trend).
We use 3-year time windows since it?s not unusual for authorsto not publish in some years while still remaining ac-tive.
We also remove the bulk of one-time authors byrestricting the authors under consideration to thosewho have published at least 10 papers, but the ob-served trend is similar for any threshold (includingno threshold).
The first computation is the Jaccardoverlap between those who authored in 1980?1982and those who authored in 1983?1985; the last isbetween the author sets of the 2003?2005 and 2006?2008 time windows.
The trend is shown in Figure 3.The author retention curve shows a clear align-ment with the epochs we identified.
In the first19epoch, the field is in its infancy: authors are work-ing in a stable set of topics, but author retention isrelatively low.
Once the bakeoff epoch starts, au-thor retention jumps significantly ?
people stay inthe field as they continue to work on bakeoff pa-pers.
As soon as the bakeoffs end, the overlap inauthors drops again.
The fact that author retentionrocketed upwards during the bakeoff epoch is pre-sumably caused by the strong external funding in-centive attracting external authors to enter and re-peatedly publish in these conferences.To understand whether this drop in overlap of au-thors was indeed indicative of authors who enteredthe field mainly for the bakeoffs, we examined au-thors who first published in the database in 1989.
Ofthe 50 most prolific such authors (those with morethan 8 publications in the database), 25 (exactlyhalf) were speech recognition researchers.
Of those25 speech researchers, 16 exited (never publishedagain in the ACL conferences) after the bakeoffs.But 9 (36%) of them remained, mainly by adaptingtheir (formerly speech-focused) research areas to-ward natural language processing topics.
Together,these facts suggest that the government-sponsoredperiod led to a large influx of speech recognitionresearchers coming to ACL conferences, and thatsome fraction of them remained, continuing withnatural language processing topics.Despite the loss of the majority of the speechrecognition researchers at the end of the bakeoffperiod, the author retention curve doesn?t descendto pre-bakeoff levels: it stabilizes at a consistentlyhigher value during the transitory epoch.
This maypartly be due to these new researchers colonizingand remaining in the field.
Or it may be due to theincreased number of topics and methods that weredeveloped during the government-sponsored period.Whichever it is, the fact that retention didn?t returnto its previous levels suggests that the governmentsponsorship that dominated the second epoch had alasting positive effect on the field.In the final epoch, author retention monotonicallyincreases to its highest-ever levels; every year therate of authors publishing continuously rises, as doesthe total number of members, suggesting that theACL community is coalescing as a field.
It is plau-sible that this final uptick is due to funding ?
gov-ernmental, industrial, or otherwise ?
and it is an in-teresting direction for further research to investigatethis possibility.In sum, we observe two epochs where memberretention increases: the era of government bakeoffs(1989?1994) and the more recent era where NLPhas received significantly increased industry interestas well as government funding (2002?2008).
Theseeras may thus both be ones where greater externaldemand increased retention and cohesion.6 ConclusionWe offer a new people-centric methodology forcomputational history and apply it to the AAN toproduce a number of insights about the field of com-putational linguistics.Our major result is to elucidate the many waysin which the government-sponsored bakeoffs andworkshops had a transformative effect on the fieldin the early 1990?s.
It has long been understood thatthe government played an important role in the field,from the early support of machine translation to theALPAC report.
Our work extends this understand-ing, showing that the government-supported bake-offs and workshops from 1989 to 1994 caused an in-flux of speech scientists, a large percentage of whomremained after the bakeoffs ended.
The bakeoffsand workshops acted as a major bridge from earlylinguistic topics to modern probabilistic topics, andcatalyzed a sharp increase in author retention.The significant recent increase in author overlapalso suggests that computational linguistics is in-tegrating into a mature field.
This integration hasdrawn on modern shared methodologies of statisticalmethods and their application to large scale corpora,and may have been supported by industry demandsas well as by government funding.
Future work willbe needed to see whether the current era is one muchlike the bakeoff era with an outflux of persons oncefunding dries up, or if it has reached a level of matu-rity reflective of a well-established discipline.AcknowledgmentsThis research was generously supported by the Of-fice of the President at Stanford University and theNational Science Foundation under award 0835614.Thanks to the anonymous reviewers, and to StevenBethard for creating the topic models.20ReferencesA.
Aris, B. Shneiderman, V. Qazvinian, and D. Radev.2009.
Visual overviews for discovering key papers andinfluences across research fronts.
Journal of the Amer-ican Society for Information Science and Technology,60(11):2219?2228.C.
Au Yeung and A. Jatowt.
2011.
Studying how thepast is remembered: towards computational historythrough large scale text mining.
In Proceedings ofthe 20th ACM international conference on Informationand knowledge management, pages 1231?1240.
ACM.S.
Bird, R. Dale, B.J.
Dorr, B. Gibson, M. Joseph, M.Y.Kan, D. Lee, B. Powley, D.R.
Radev, and Y.F.
Tan.2008.
The acl anthology reference corpus: A refer-ence dataset for bibliographic research in computa-tional linguistics.
In Proc.
of the 6th InternationalConference on Language Resources and EvaluationConference (LREC?08), pages 1755?1759.D.
M. Blei, A. Y. Ng, and M. I. Jordan.
2003.
LatentDirichlet alocation.
Journal of Machine Learning Re-search, 3(5):993?1022.D.A.
Dahl, M. Bates, M. Brown, W. Fisher, K. Hunicke-Smith, D. Pallett, C. Pao, A. Rudnicky, andE.
Shriberg.
1994.
Expanding the scope of the atistask: The atis-3 corpus.
In Proceedings of the work-shop on Human Language Technology, pages 43?48.Association for Computational Linguistics.S.
Gerrish and D.M.
Blei.
2010.
A language-based ap-proach to measuring scholarly impact.
In Proceed-ings of the 26th International Conference on MachineLearning.T.L.
Griffiths and M. Steyvers.
2004.
Finding scien-tific topics.
Proceedings of the National Academy ofSciences of the United States of America, 101(Suppl1):5228.R.
Grishman and B. Sundheim.
1996.
Message under-standing conference-6: A brief history.
In Proceedingsof COLING, volume 96, pages 466?471.David Hall, Daniel Jurafsky, and Christopher D. Man-ning.
2008.
Studying the history of ideas using topicmodels.
In Proceedings of EMNLP 2008.C.T.
Hemphill, J.J. Godfrey, and G.R.
Doddington.
1990.The atis spoken language systems pilot corpus.
In Pro-ceedings of the DARPA speech and natural languageworkshop, pages 96?101.P.
Price.
1990.
Evaluation of spoken language systems:The atis domain.
In Proceedings of the Third DARPASpeech and Natural Language Workshop, pages 91?95.
Morgan Kaufmann.D.R.
Radev, P. Muthukrishnan, and V. Qazvinian.
2009.The acl anthology network corpus.
In Proceedings ofthe 2009 Workshop on Text and Citation Analysis forScholarly Digital Libraries, pages 54?61.
Associationfor Computational Linguistics.Y.
Tu, N. Johri, D. Roth, and J. Hockenmaier.
2010.
Ci-tation author topic model in expert search.
In Proceed-ings of the 23rd International Conference on Compu-tational Linguistics: Posters, pages 1265?1273.
Asso-ciation for Computational Linguistics.21
