Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 65?72,Sydney, July 2006. c?2006 Association for Computational LinguisticsDiscriminative Word Alignment with Conditional Random FieldsPhil Blunsom and Trevor CohnDepartment of Software Engineering and Computer ScienceUniversity of Melbourne{pcbl,tacohn}@csse.unimelb.edu.auAbstractIn this paper we present a novel approachfor inducing word alignments from sen-tence aligned data.
We use a Condi-tional Random Field (CRF), a discrimina-tive model, which is estimated on a smallsupervised training set.
The CRF is condi-tioned on both the source and target texts,and thus allows for the use of arbitraryand overlapping features over these data.Moreover, the CRF has efficient trainingand decoding processes which both findglobally optimal solutions.We apply this alignment model to bothFrench-English and Romanian-Englishlanguage pairs.
We show how a largenumber of highly predictive features canbe easily incorporated into the CRF, anddemonstrate that even with only a few hun-dred word-aligned training sentences, ourmodel improves over the current state-of-the-art with alignment error rates of 5.29and 25.8 for the two tasks respectively.1 IntroductionModern phrase based statistical machine transla-tion (SMT) systems usually break the translationtask into two phases.
The first phase induces wordalignments over a sentence-aligned bilingual cor-pus, and the second phase uses statistics over thesepredicted word alignments to decode (translate)novel sentences.
This paper deals with the first ofthese tasks: word alignment.Most current SMT systems (Och and Ney,2004; Koehn et al, 2003) use a generative modelfor word alignment such as the freely availableGIZA++ (Och and Ney, 2003), an implementa-tion of the IBM alignment models (Brown et al,1993).
These models treat word alignment as ahidden process, and maximise the probability ofthe observed (e, f) sentence pairs1 using the ex-pectation maximisation (EM) algorithm.
After themaximisation process is complete, the word align-ments are set to maximum posterior predictions ofthe model.While GIZA++ gives good results when trainedon large sentence aligned corpora, its generativemodels have a number of limitations.
Firstly,they impose strong independence assumptions be-tween features, making it very difficult to incor-porate non-independent features over the sentencepairs.
For instance, as well as detecting that asource word is aligned to a given target word,we would also like to encode syntactic and lexi-cal features of the word pair, such as their parts-of-speech, affixes, lemmas, etc.
Features such asthese would allow for more effective use of sparsedata and result in a model which is more robustin the presence of unseen words.
Adding thesenon-independent features to a generative modelrequires that the features?
inter-dependence bemodelled explicitly, which often complicates themodel (eg.
Toutanova et al (2002)).
Secondly, thelater IBM models, such as Model 4, have to re-sort to heuristic search techniques to approximateforward-backward and Viterbi inference, whichsacrifice optimality for tractability.This paper presents an alternative discrimina-tive method for word alignment.
We use a condi-tional random field (CRF) sequence model, whichallows for globally optimal training and decod-ing (Lafferty et al, 2001).
The inference algo-1We adopt the standard notation of e and f to denote thetarget (English) and source (foreign) sentences, respectively.65rithms are tractable and efficient, thereby avoid-ing the need for heuristics.
The CRF is condi-tioned on both the source and target sentences,and therefore supports large sets of diverse andoverlapping features.
Furthermore, the model al-lows regularisation using a prior over the parame-ters, a very effective and simple method for limit-ing over-fitting.
We use a similar graphical struc-ture to the directed hidden Markov model (HMM)from GIZA++ (Och and Ney, 2003).
This mod-els one-to-many alignments, where each targetword is aligned with zero or more source words.Many-to-many alignments are recoverable usingthe standard techniques for superimposing pre-dicted alignments in both translation directions.The paper is structured as follows.
Section2 presents CRFs for word alignment, describingtheir form and their inference techniques.
Thefeatures of our model are presented in Section 3,and experimental results for word aligning bothFrench-English and Romanian-English sentencesare given in Section 4.
Section 5 presents relatedwork, and we describe future work in Section 6.Finally, we conclude in Section 7.2 Conditional random fieldsCRFs are undirected graphical models which de-fine a conditional distribution over a label se-quence given an observation sequence.
We usea CRF to model many-to-one word alignments,where each source word is aligned with zero orone target words, and therefore each target wordcan be aligned with many source words.
Eachsource word is labelled with the index of itsaligned target, or the special value null, denot-ing no alignment.
An example word alignmentis shown in Figure 1, where the hollow squaresand circles indicate the correct alignments.
In thisexample the French words une and autre wouldboth be assigned the index 24 ?
for the Englishword another ?
when French is the source lan-guage.
When the source language is English, an-other could be assigned either index 25 or 26; inthese ambiguous situations we take the first index.The joint probability density of the alignment,a (a vector of target indices), conditioned on thesource and target sentences, e and f , is given by:p?
(a|e, f) =exp?t?k ?khk(t, at?1, at, e, f)Z?
(e, f)(1)where we make a first order Markov assumptiontheyareconstrainedbylimitswhichareimposedinordertoensurethatthefreedomofonepersondoesnotviolatethatofanother..autreunedecellesurpasempi?tenepersonneunedelibert?laquegarantirpourfix?es?t?ontquilimitescertainesparrestreintssontilsFigure 1.
A word-aligned example from the CanadianHansards test set.
Hollow squares represent gold stan-dard sure alignments, circles are gold possible align-ments, and filled squares are predicted alignments.over the alignment sequence.
Here t ranges overthe indices of the source sentence (f ), k rangesover the model?s features, and ?
= {?k} are themodel parameters (weights for their correspond-ing features).
The feature functions hk are pre-defined real-valued functions over the source andtarget sentences coupled with the alignment labelsover adjacent times (source sentence locations),t. These feature functions are unconstrained, andmay represent overlapping and non-independentfeatures of the data.
The distribution is globallynormalised by the partition function, Z?
(e, f),which sums out the numerator in (1) for every pos-sible alignment:Z?
(e, f) =?aexp?t?k?khk(t, at?1, at, e, f)We use a linear chain CRF, which is encoded inthe feature functions of (1).The parameters of the CRF are usually esti-mated from a fully observed training sample (wordaligned), by maximising the likelihood of thesedata.
I.e.
?ML = argmax?
p?
(D), where D ={(a, e, f)} are the training data.
Because max-imum likelihood estimators for log-linear mod-els have a tendency to overfit the training sam-ple (Chen and Rosenfeld, 1999), we define a priordistribution over the model parameters and de-rive a maximum a posteriori (MAP) estimate,?MAP = argmax?
p?(D)p(?).
We use a zero-mean Gaussian prior, with the probability densityfunction p0(?k) ?
exp(??2k2?2k).
This yields alog-likelihood objective function of:L =?
(a,e,f)?Dlog p?
(a|e, f) +?klog p0(?k)66=?
(a,e,f)?D?t?k?khk(t, at?1, at, e, f)?
logZ?
(e, f)?
?k?2k2?2k+ const.
(2)In order to train the model, we maximize (2).While the log-likelihood cannot be maximised forthe parameters, ?, in closed form, it is a con-vex function, and thus we resort to numerical op-timisation to find the globally optimal parame-ters.
We use L-BFGS, an iterative quasi-Newtonoptimisation method, which performs well fortraining log-linear models (Malouf, 2002; Shaand Pereira, 2003).
Each L-BFGS iteration re-quires the objective value and its gradient withrespect to the model parameters.
These are cal-culated using forward-backward inference, whichyields the partition function, Z?
(e, f), requiredfor the log-likelihood, and the pair-wise marginals,p?
(at?1, at|e, f), required for its derivatives.The Viterbi algorithm is used to find the maxi-mum posterior probability alignment for test sen-tences, a?
= argmaxa p?
(a|e, f).
Both theforward-backward and Viterbi algorithm are dy-namic programs which make use of the Markovassumption to calculate efficiently the exactmarginal distributions.3 The alignment modelBefore we can apply our CRF alignment model,we must first specify the feature set ?
the func-tions hk in (1).
Typically CRFs use binary indica-tor functions as features; these functions are onlyactive when the observations meet some criteriaand the label at (or label pair, (at?1, at)) matchesa pre-specified label (pair).
However, in our modelthe labellings are word indices in the target sen-tence and cannot be compared readily to labellingsat other sites in the same sentence, or in other sen-tences with a different length.
Such naive featureswould only be active for one labelling, thereforethis model would suffer from serious sparse dataproblems.We instead define features which are functionsof the source-target word match implied by a la-belling, rather than the labelling itself.
For exam-ple, from the sentence in Figure 1 for the labellingof f24 = de with a24 = 16 (for e16 = of ) wemight detect the following feature:h(t, at?1, at, f , e) ={1, if eat = ?of?
?
ft = ?de?0, otherwiseNote that it is the target word indexed by at, ratherthan the index itself, which determines whetherthe feature is active, and thus the sparsity of theindex label set is not an issue.3.1 FeaturesOne of the main advantages of using a conditionalmodel is the ability to explore a diverse range offeatures engineered for a specific task.
In ourCRFmodel we employ two main types of features:those defined on a candidate aligned pair of words;and Markov features defined on the alignment se-quence predicted by the model.Dice and Model 1 As we have access to only asmall amount of word aligned data we wish to beable to incorporate information about word associ-ation from any sentence aligned data available.
Acommon measure of word association is the Dicecoefficient (Dice, 1945):Dice(e, f) =2?
CEF (e, f)CE(e) + CF (e)where CE and CF are counts of the occurrencesof the words e and f in the corpus, while CEF istheir co-occurrence count.
We treat these Dice val-ues as translation scores: a high (low) value inci-dates that the word pair is a good (poor) candidatetranslation.However, the Dice score often over-estimatesthe association between common words.
For in-stance, the words the and of both score highlywhen combined with either le or de, simply be-cause these common words frequently co-occur.The GIZA++ models can be used to provide bettertranslation scores, as they enforce competition foralignment beween the words.
For this reason, weused the translation probability distribution fromModel 1 in addition to the DICE scores.
Model 1is a simple position independent model which canbe trained quickly and is often used to bootstrapparameters for more complex models.
It modelsthe conditional probability distribution:p(f ,a|e) =p(|f |||e|)(|e|+ 1)|f |?|f |?t=1p(ft|eat)where p(f |e) are the word translation probabili-ties.We use both the Dice value and the Model 1translation probability as real-valued features foreach candidate pair, as well as a normalised score67over all possible candidate alignments for each tar-get word.
We derive a feature from both the Diceand Model 1 translation scores to allow compe-tition between sources words for a particular tar-get algnment.
This feature indicates whether agiven alignment has the highest translation scoreof all the candidate alignments for a given tar-get word.
For the example in Figure 1, the wordsla, de and une all receive a high translation scorewhen paired with the.
To discourage all of theseFrench words from aligning with the, the best ofthese (la) is flagged as the best candidate.
This al-lows for competition between source words whichwould otherwise not occur.Orthographic features Features based onstring overlap allow our model to recognisecognates and orthographically similar translationpairs, which are particularly common betweenEuropean languages.
Here we employ a numberof string matching features inspired by similarfeatures in Taskar et al (2005).
We use an indica-tor feature for every possible source-target wordpair in the training data.
In addition, we includeindicator features for an exact string match, bothwith and without vowels, and the edit-distancebetween the source and target words as a real-valued feature.
We also used indicator features totest for matching prefixes and suffixes of lengththree.
As stated earlier, the Dice translationscore often erroneously rewards alignments withcommon words.
In order to address this problem,we include the absolute difference in word lengthas a real-valued feature and an indicator featuretesting whether both words are shorter than 4characters.
Together these features allow themodel to disprefer alignments between wordswith very different lengths ?
i.e.
aligning rare(long) words with frequent (short) determiners,verbs etc.POS tags Part-of-speech tags are an effectivemethod for addressing the sparsity of the lexi-cal features.
Observe in Figure 2 that the noun-adjective pair Canadian experts aligns with theadjective-noun pair spe?cialistes canadiens: thealignment exactly matches the parts-of-speech.Access to the words?
POS tags will allow simplemodelling of such effects.
POS can also be usefulfor less closely related language pairs, such as En-glish and Japanese where English determiners arenever aligned; nor are Japanese case markers.For our French-English language pair we POStagged the source and target sentences with Tree-Tagger.2 We created indicator features over thePOS tags of each candidate source and target wordpair, as well as over the source word and targetPOS (and vice-versa).
As we didn?t have access toa Romanian POS tagger, these features were notused for the Romanian-English language pair.Bilingual dictionary Dictionaries are anothersource of information for word alignment.
Weuse a single indicator feature which detects whenthe source and target words appear in an entry ofthe dictionary.
For the English-French dictionarywe used FreeDict,3 which contains 8,799 Englishwords.
For Romanian-English we used a dictio-nary compiled by Rada Mihalcea,4 which containsapproximately 38,000 entries.Markov features Features defined over adja-cent aligment labels allow our model to reflect thetendency for monotonic alignments between Eu-ropean languages.
We define a real-valued align-ment index jump width feature:jump width(t?
1, t) = abs(at ?
at?1 ?
1)this feature has a value of 0 if the alignment labelsfollow the downward sloping diagonal, and is pos-itive otherwise.
This differs from the GIZA++ hid-den Markov model which has individual parame-ters for each different jump width (Och and Ney,2003; Vogel et al, 1996): we found a single fea-ture (and thus parameter) to be more effective.We also defined three indicator features overnull transitions to allow the modelling of the prob-ability of transition between, to and from null la-bels.Relative sentence postion A feature for theabsolute difference in relative sentence position(abs( at|e| ?t|f |)) allows the model to learn a pref-erence for aligning words close to the alignmentmatrix diagonal.
We also included two conjunc-tion features for the relative sentence position mul-tiplied by the Dice and Model 1 translation scores.Null We use a number of variants on the abovefeatures for alignments between a source word andthe null target.
The maximum translation scorebetween the source and one of the target words2http://www.ims.uni-stuttgart.de/projekte/corplex/TreeTagger3http://www.freedict.de4http://lit.csci.unt.edu/?rada/downloads/RoNLP/R.E.tralex68model precision recall f-score AERModel 4 refined 87.4 95.1 91.1 9.81Model 4 intersection 97.9 86.0 91.6 7.42French?
English 96.7 85.0 90.5 9.21English?
French 97.3 83.0 89.6 10.01intersection 98.7 78.6 87.5 12.02refined 95.7 89.2 92.3 7.37Table 1.
Results on the Hansard data using all featuresmodel precision recall f-score AERModel 4 refined 80.49 64.10 71,37 28.63Model 4 intersected 95.94 53.56 68.74 31.26Romanian?
English 82.9 61.3 70.5 29.53English?
Romanian 82.8 60.6 70.0 29.98intersection 94.4 52.5 67.5 32.45refined 77.1 68.5 72.6 27.41Table 2.
Results on the Romanian data using all fea-turesis used as a feature to represent whether there isa strong alignment candidate.
The sum of thesescores is also used as a feature.
Each source wordand POS tag pair are used as indicator featureswhich allow the model to learn particular wordsof tags which tend to commonly (or rarely) align.3.2 SymmetrisationIn order to produce many-to-many alignments wecombine the outputs of two models, one for eachtranslation direction.
We use the refined methodfrom Och and Ney (2003) which starts from theintersection of the two models?
predictions and?grows?
the predicted alignments to neighbouringalignments which only appear in the output of oneof the models.4 ExperimentsWe have applied our model to two publicly avail-able word aligned corpora.
The first is theEnglish-French Hansards corpus, which consistsof 1.1 million aligned sentences and 484 word-aligned sentences.
This data set was used forthe 2003 NAACL shared task (Mihalcea and Ped-ersen, 2003), where the word-aligned sentenceswere split into a 37 sentence trial set and a 447 sen-tence testing set.
Unlike the unsupervised entrantsin the 2003 task, we require word-aligned trainingdata, and therefore must cannibalise the test set forthis purpose.
We follow Taskar et al (2005) by us-ing the first 100 test sentences for training and theremaining 347 for testing.
This means that our re-sults should not be directly compared to those en-trants, other than in an approximate manner.
Weused the original 37 sentence trial set for featureengineering and for fitting a Gaussian prior.The word aligned data are annotated with bothsure (S) and possible (P ) alignments (S ?
P ; Ochand Ney (2003)), where the possible alignmentsindicate ambiguous or idiomatic alignments.
Wemeasure the performance of our model usingalignment error rate (AER), which is defined as:AER(A,S, P ) = 1?|A ?
S|+ |A ?
P ||A|+ |S|where A is the set of predicted alignments.The second data set is the Romanian-Englishparallel corpus from the 2005 ACL shared task(Martin et al, 2005).
This consists of approxi-mately 50,000 aligned sentences and 448 word-aligned sentences, which are split into a 248 sen-tence trial set and a 200 sentence test set.
Weused these as our training and test sets, respec-tively.
For parameter tuning, we used the 17 sen-tence trial set from the Romanian-English corpusin the 2003 NAACL task (Mihalcea and Pedersen,2003).
For this task we have used the same testdata as the competition entrants, and therefore candirectly compare our results.
The word alignmentsin this corpus were only annotated with sure (S)alignments, and therefore the AER is equivalentto the F1 score.
In the shared task it was foundthat models which were trained on only the firstfour letters of each word obtained superior resultsto those using the full words (Martin et al, 2005).We observed the same result with our model onthe trial set and thus have only used the first fourletters when training the Dice and Model 1 trans-lation probabilities.Tables 1 and 2 show the results when all featuretypes are employed on both language pairs.
We re-port the results for both translation directions andwhen combined using the refined and intersectionmethods.
The Model 4 results are from GIZA++with the default parameters and the training datalowercased.
For Romanian, Model 4 was trainedusing the first four letters of each word.The Romanian results are close to the best re-ported result of 26.10 from the ACL shared task(Martin et al, 2005).
This result was from a sys-tem based on Model 4 plus additional parameterssuch as a dictionary.
The standard Model 4 imple-mentation in the shared task achieved a result of31.65, while when only the first 4 letters of eachword were used it achieved 28.80.55These results differ slightly our Model 4 results reportedin Table 2.69(ii)(a)ThreevehicleswillbeusedbysixCanadianexpertsrelatedtotheprovisionoftechnicalassistance..techniqueaidedeprestationladecadreledanscanadienssp?cialistes6parutilis?sserontv?hicules3)a)ii((a) With Markov features(ii)(a)ThreevehicleswillbeusedbysixCanadianexpertsrelatedtotheprovisionoftechnicalassistance..techniqueaidedeprestationladecadreledanscanadienssp?cialistes6parutilis?sserontv?hicules3)a)ii((b) Without Markov featuresFigure 2.
An example from the Hansard test set, showing the effect of the Markov features.Table 3 shows the effect of removing each of thefeature types in turn from the full model.
The mostuseful features are the Dice and Model 1 valueswhich allow the model to incorporate translationprobabilities from the large sentence aligned cor-pora.
This is to be expected as the amount of wordaligned data are extremely small, and therefore themodel can only estimate translation probabilitiesfor only a fraction of the lexicon.
We would expectthe dependence on sentence aligned data to de-crease as more word aligned data becomes avail-able.The effect of removing the Markov features canbe seen from comparing Figures 2 (a) and (b).
Themodel has learnt to prefer alignments that followthe diagonal, thus alignments such as 3 ?
threeand prestation ?
provision are found, and miss-alignments such as de ?
of, which lie well off thediagonal, are avoided.The differing utility of the alignment word pairfeature between the two tasks is probably a resultof the different proportions of word- to sentence-aligned data.
For the French data, where a verylarge lexicon can be estimated from the millionsentence alignments, the sparse word pairs learnton the word aligned sentences appear to lead tooverfitting.
In contrast, for Romanian, where moreword alignments are used to learn the translationpair features and much less sentence aligned dataare available, these features have a significant im-pact on the model.
Suprisingly the orthographicfeatures actually worsen the performance in thetasks (incidentally, these features help the trialset).
Our explanation is that the other features(eg.
Model 1) already adequately model these cor-respondences, and therefore the orthographic fea-feature group Rom?
Eng Fre?
EngALL 27.41 7.37?orthographic 27.30 7.25?Dice 27.68 7.73?dictionary 27.72 7.21?sentence position 28.30 8.01?POS ?
8.19?Model 1 28.62 8.45?alignment word pair 32.41 7.20?Markov 32.75 12.44?Dice & ?Model 1 35.43 14.10Table 3.
The resulting AERs after removing individualgroups of features from the full model.tures do not add much additional modelling power.We expect that with further careful feature engi-neering, and a larger trial set, these orthographicfeatures could be much improved.The Romanian-English language pair appearsto offer a more difficult modelling problem thanthe French-English pair.
With both the transla-tion score features (Dice and Model 1) removed?
the sentence aligned data are not used ?
theAER of the Romanian is more than twice that ofthe French, despite employing more word aligneddata.
This could be caused by the lack of possi-ble (P) alignment markup in the Romanian data,which provide a boost in AER on the French dataset, rewarding what would otherwise be consid-ered errors.
Interestingly, without any featuresderived from the sentence aligned corpus, ourmodel achieves performance equivalent to Model3 trained on the full corpus (Och and Ney, 2003).This is a particularly strong result, indicating thatthis method is ideal for data-impoverished align-ment tasks.704.1 Training with possible alignmentsUp to this point our Hansards model has beentrained using only the sure (S) alignments.
Asthe data set contains many possible (P) alignments,we would like to use these to improve our model.Most of the possible alignments flag blocks ofambiguous or idiomatic (or just difficult) phraselevel alignments.
These many-to-many align-ments cannot be modelled with our many-to-onesetup.
However, a number of possibles flag one-to-one or many-to-one aligments: for this experi-ment we used these possibles in training to inves-tigate their effect on recall.
Using these additionalalignments our refined precision decreased from95.7 to 93.5, while recall increased from 89.2 to92.4.
This resulted in an overall decrease in AERto 6.99.
We found no benefit from using many-to-many possible alignments as they added a signifi-cant amount of noise to the data.4.2 Model 4 as a featurePrevious work (Taskar et al, 2005) has demon-strated that by including the output of Model 4 asa feature, it is possible to achieve a significant de-crease in AER.
We trained Model 4 in both direc-tions on the two language pairs.
We added twoindicator features (one for each direction) to ourCRF which were active if a given word pair werealigned in the Model 4 output.
Table 4 displaysthe results on both language pairs when these ad-ditional features are used with the refined model.This produces a large increase in performance, andwhen including the possibles, produces AERs of5.29 and 25.8, both well below that of Model 4alone (shown in Tables 1 and 2).4.3 Cross-validationUsing 10-fold cross-validation we are able to gen-erate results on the whole of the Hansards test datawhich are comparable to previously published re-sults.
As the sentences in the test set were ran-domly chosen from the training corpus we can ex-pect cross-validation to give an unbiased estimateof generalisation performance.
These results aredisplayed in Table 5, using the possible (P) align-ments for training.
As the training set for each foldis roughly four times as big previous training set,we see a small improvement in AER.The final results of 6.47 and 5.19 with andwithout Model 4 features both exceed the perfor-mance of Model 4 alone.
However the unsuper-model precision recall f-score AERRom?
Eng 79.0 70.0 74.2 25.8Fre?
Eng 97.9 90.8 94.2 5.49Fre?
Eng (P) 95.5 93.7 94.6 5.29Table 4.
Results using features from Model 4 bi-directional alignments, training with and without thepossible (P) alignments.model precision recall f-score AERFre?
Eng 94.6 92.2 93.4 6.47Fre?
Eng (Model 4) 96.1 93.3 94.7 5.19Table 5.
10-fold cross-validation results, with and with-out Model 4 features.vised Model 4 did not have access to the word-alignments in our training set.
Callison-Burch etal.
(2004) demonstrated that the GIZA++ mod-els could be trained in a semi-supervised manner,leading to a slight decrease in error.
To our knowl-edge, our AER of 5.19 is the best reported result,generative or discriminative, on this data set.5 Related workRecently, a number of discriminative word align-ment models have been proposed, however theseearly models are typically very complicated withmany proposing intractable problems which re-quire heuristics for approximate inference (Liu etal., 2005; Moore, 2005).An exception is Taskar et al (2005) who pre-sented a word matching model for discriminativealignment which they they were able to solve opti-mally.
However, their model is limited to only pro-viding one-to-one alignments.
Also, no featureswere defined on label sequences, which reducedthe model?s ability to capture the strong monotonicrelationships present between European languagepairs.
On the French-English Hansards task, usingthe same training/testing setup as our work, theyachieve an AER of 5.4 with Model 4 features, and10.7 without (compared to 5.29 and 6.99 for ourCRF).
One of the strengths of the CRF MAP es-timation is the powerful smoothing offered by theprior, which allows us to avoid heuristics such asearly stopping and hand weighted loss-functionsthat were needed for the maximum-margin model.Liu et al (2005) used a conditional log-linearmodel with similar features to those we have em-ployed.
They formulated a global model, withoutmaking a Markovian assumption, leading to theneed for a sub-optimal heuristic search strategies.Ittycheriah and Roukos (2005) trained a dis-71criminative model on a corpus of ten thousandword aligned Arabic-English sentence pairs thatoutperformed a GIZA++ baseline.
As with otherapproaches, they proposed a model which didn?tallow a tractably optimal solution and thus had toresort to a heuristic beam search.
They employeda log-linear model to learn the observation proba-bilities, while using a fixed transition distribution.Our CRF model allows both the observation andtransition components of the model to be jointlyoptimised from the corpus.6 Further workThe results presented in this paper were evaluatedin terms of AER.
While a low AER can be ex-pected to improve end-to-end translation quality,this is may not necessarily be the case.
There-fore, we plan to assess how the recall and preci-sion characteristics of our model affect translationquality.
The tradeoff between recall and precisionmay affect the quality and number of phrases ex-tracted for a phrase translation table.7 ConclusionWe have presented a novel approach for induc-ing word alignments from sentence aligned data.We showed how conditional random fields couldbe used for word alignment.
These models al-low for the use of arbitrary and overlapping fea-tures over the source and target sentences, makingthe most of small supervised training sets.
More-over, we showed how the CRF?s inference and es-timation methods allowed for efficient processingwithout sacrificing optimality, improving on pre-vious heuristic based approaches.On both French-English and Romanian-Englishwe showed that many highly predictive featurescan be easily incorporated into the CRF, anddemonstrated that with only a few hundred word-aligned training sentences, our model outperformsthe generativeModel 4 baseline.
When no featuresare extracted from the sentence aligned corpus ourmodel still achieves a low error rate.
Furthermore,when we employ features derived from Model 4alignments our CRF model achieves the highestreported results on both data sets.AcknowledgementsSpecial thanks to Miles Osborne, Steven Bird,Timothy Baldwin and the anonymous reviewersfor their feedback and insightful comments.ReferencesP.
F. Brown, S. A. Della Pietra, V. J. Della Pietra, and R. L.Mercer.
1993.
The mathematics of statistical machinetranslation: Parameter estimation.
Computational Lin-guistics, 19(2):263?311.C.
Callison-Burch, D. Talbot, and M. Osborne.
2004.
Statis-tical machine translation with word- and sentence-alignedparallel corpora.
In Proceedings of ACL, pages 175?182,Barcelona, Spain, July.S.
Chen and R. Rosenfeld.
1999.
A survey of smoothingtechniques for maximum entropy models.
IEEE Transac-tions on Speech and Audio Processing, 8(1):37?50.L.
R. Dice.
1945.
Measures of the amount of ecologic asso-ciation between species.
Journal of Ecology, 26:297?302.A.
Ittycheriah and S. Roukos.
2005.
A maximum entropyword aligner for Arabic-English machine translation.
InProceedings of HLT-EMNLP, pages 89?96, Vancouver,British Columbia, Canada, October.P.
Koehn, F. J. Och, and D. Marcu.
2003.
Statistical phrase-based translation.
In Proceedings of HLT-NAACL, pages81?88, Edmonton, Alberta.J.
Lafferty, A. McCallum, and F. Pereira.
2001.
Conditionalrandom fields: Probabilistic models for segmenting andlabelling sequence data.
In Proceedings of ICML, pages282?289.Y.
Liu, Q. Liu, and S. Lin.
2005.
Log-linear models for wordalignment.
In Proceedings of ACL, pages 459?466, AnnArbor.R.
Malouf.
2002.
A comparison of algorithms for maximumentropy parameter estimation.
In Proceedings of CoNLL,pages 49?55.J.
Martin, R. Mihalcea, and T. Pedersen.
2005.
Word align-ment for languages with scarce resources.
In Proceed-ings of the ACL Workshop on Building and Using ParallelTexts, pages 65?74, Ann Arbor, Michigan, June.R.
Mihalcea and T. Pedersen.
2003.
An evaluation exer-cise for word alignment.
In Proceedings of HLT-NAACL2003 Workshop, Building and Using Parrallel Texts: DataDriven Machine Translation and Beyond, pages 1?6, Ed-monton, Alberta.R.
C. Moore.
2005.
A discriminative framework for bilin-gual word alignment.
In Proceedings of HLT-EMNLP,pages 81?88, Vancouver, Canada.F.
Och and H. Ney.
2003.
A systematic comparison of vari-ous statistical alignment models.
Computational Linguis-tics, 29(1):19?52.F.
Och and H. Ney.
2004.
The alignment template approachto statistical machine translation.
Computational Linguis-tics, 30(4):417?449.F.
Sha and F. Pereira.
2003.
Shallow parsing with con-ditional random fields.
In Proceedings of HLT-NAACL,pages 213?220.B.
Taskar, S. Lacoste-Julien, and D. Klein.
2005.
A discrimi-native matching approach to word alignment.
In Proceed-ings of HLT-EMNLP, pages 73?80, Vancouver, BritishColumbia, Canada, October.K.
Toutanova, H. Tolga Ilhan, and C Manning.
2002.
Ex-tentions to HMM-based statistical word alignment mod-els.
In Proceedings of EMNLP, pages 87?94, Philadel-phia, July.S.
Vogel, H. Ney, and C. Tillmann.
1996.
HMM-based wordalignment in statistical translation.
In Proceedings of 16thInt.
Conf.
on Computational Linguistics, pages 836?841.72
