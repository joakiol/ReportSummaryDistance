Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers,pages 1752?1763, Dublin, Ireland, August 23-29 2014.A Novel Distributional Approach to Multilingual Conceptual MetaphorRecognitionMichael Mohler and Bryan Rink and David Bracewell and Marc TomlinsonLanguage Computer Corp.Richardson, Texas, USA{michael,bryan,david,marc}@languagecomputer.comAbstractWe present a novel approach to the problem of multilingual conceptual metaphor recognition.Our approach extends recent work in conceptual metaphor discovery by combining a complexmethodology for facet-based concept induction with a distributional vector space model of lin-guistic and conceptual metaphor.
In the evaluation of our system in English, Spanish, Russian,and Farsi, we experiment with several state-of-the-art vector space models and demonstrate aclear benefit to the fine-grained concept representation that forms the basis of our methodologyfor conceptual metaphor recognition.1 IntroductionThe role of metaphor in language has been defined by Lakoff et al.
(1980; 1993) as a cognitive phe-nomenon which operates at the level of mental processes, whereby one concept or domain is viewedsystematically in terms of another.
For example, the phrase ?to cure poverty?
is a metaphor which subtlyconveys a wide variety of information to the listener.
In order to mentally process this phrase, we mustfirst recognize that a metaphor is being used and that ?cure?
(as a medical term) is being used figura-tively.
Then, we assume some relationship between ?poverty?
and ?things that can be medically cured?which leads to the conceptual mapping ?POVERTY as DISEASE.?
This conceptual mapping enables thelistener to transfer a variety of properties and associations between the two concepts, such as their as-sociation with a feeling of helplessness, the existence of sustained efforts to end them, the potential forthem to spread, and their mutual relationship with ill-health and death.
Therefore, by identifying the con-ceptual domains associated with this linguistic metaphor, we are able to reason about the target domain(POVERTY) using concepts and terms associated with the source domain (DISEASE).Any natural language processing system capable of processing metaphor in text with human-levelcompetence must, therefore, overcome three problems in sequence:1. the identification of metaphorical expressions (also known as linguistic metaphors (LMs))2. the discovery of a conceptual domain mapping or conceptual metaphor (CM) which consists of(a) the conceptual domain of the metaphor target (e.g., POVERTY); and(b) the conceptual domain of the metaphor source (e.g., DISEASE)3. the real-world interpretation of the metaphorical text which uses the conceptual metaphor frame-work to transfer knowledge between the source and target domains.While a significant amount of recent work has presented interesting and promising methodologies formultilingual LM identification (Shutova and Sun, 2013; Wilks et al., 2013; Strzalkowski et al., 2013),the work presented in this paper is focused on (2), the problem of multilingual CM recognition, whichwill be made to serve as the foundation for a more fine-grained interpretation of metaphor.This work is licenced under a Creative Commons Attribution 4.0 International License.
Page numbers and proceedings footerare added by the organizers.
License details: http://creativecommons.org/licenses/by/4.0/1752We cast the CM recognition process as a two-part methodology which (a) selects the target domainassociated with a particular LM that has been detected; and (b) determines the source domain to whichit should be mapped in order to produce a satisfactory interpretation.
In this work, we assume that thetarget domains are known and belong to one of the following conceptual spaces: POVERTY, WEALTH, orTAXATION.
Pragmatically speaking, research in CM recognition presupposes some methodology for LMidentification, and to this end, we have employed an existing state-of-the-art LM identification systemwhich has been developed to detect linguistic metaphors in four languages: English, Spanish, Russian,and Farsi (Bracewell et al., 2014).In order to generate a CM which can serve as the basis for an interpretation of an LM, we havedeveloped an approach that is based on the following hypotheses:CONCEPTUAL HYPOTHESIS: When an LM has been identified as a pair of lexical items thatrepresent the source (e.g., ?cure?)
and the target (e.g., ?poverty?
), we can generate a conceptualmapping by selecting the conceptual domains that are, a priori, the most likely for the source andtarget lexemes.1DISTRIBUTIONAL HYPOTHESIS: It is possible to decide which conceptual space better repre-sents a given lexeme by1.
expanding the lexical space with additional terms (which we call ?grammatical co-occurrents?
)that are strongly associated with the lexeme through grammatical relations such as AGENT,PATIENT, INSTRUMENT, and ATTRIBUTE;2. using these lexical expansions to produce distributional vectors; and3.
uncovering the selectional constraints of particular domain facets by clustering the distribu-tional vectors within a semantic space.DOMAIN HYPOTHESIS: The grammatical co-occurrents of the LM are themselves very likely tobelong to the same conceptual domain as the lexeme (e.g., ?cure patient?, ?cured of AIDS?, and?doctor cured?
).MAPPING HYPOTHESIS: The semantic space representations of both the LM source and its gram-matically associated terms can be used to produce mappings into a high dimensional space in whichsource domains are known to exist.While other computational linguistics research in metaphor has made use of the CONCEPTUAL andDISTRIBUTIONAL hypotheses, to our knowledge the DOMAIN and MAPPING hypotheses have notyet been explored in combination with a distributional approach.The remainder of this work is organized as follows.
In Section 2, we discuss related work in the fieldof metaphor interpretation and unsupervised concept induction.
In Section 3, we introduce the overallarchitecture of our CM recognition system.
In Section 4, we describe our method for representing lexicalitems and conceptual metaphors in a distributional vector space.
Then, in Section 5, we explain ourmethodology for creating and ranking clusters of LM co-occurrents which are then mapped to conceptualmetaphors within our vector space.
In Section 6, we describe our experimental setup and provide theresults of our experiments.
Finally, in Section 7 we present our conclusions.2 Related WorkResearch in metaphor processing can broadly be divided into two categories: metaphor identification andmetaphor interpretation.
Although some recent work on metaphor interpretation has skirted the issue ofconceptual metaphor entirely by casting the problem of metaphor interpretation as an instance of lexicalparaphrase (Shutova, 2010; Bollegala and Shutova, 2013) or textual entailment (Mohler et al., 2013), themapping and modeling of conceptual metaphors has historically served as an important foundation for1If the target domains are pre-selected, this hypotheses is reduced to selecting only the most likely source domain.1753more robust interpretation of metaphor.
Indeed, a significant amount of research in metaphor interpreta-tion has been concentrated on the development of highly-structured, manually curated representations ofboth the CM source and CM target domains.
Notable in this regard are the KARMA system (Feldmanand Narayanan, 2004) which was designed to simulate neurological modeling of verbs ?
both abstractand metaphorical ?
and the ISOMETA system (Beust et al., 2003) which made use of differential tablesof CM domain lexical items to drive their metaphor interpretation process.
The CorMet system (Ma-son, 2004) sought to model conceptual metaphors by detecting individual source-target mappings thatprovide evidence for a known CM by quantifying the overlap between clusters of terms with a strongselectional preference to the most representative verbs within the source and target domains.
After a man-ual inspection of the source/target cluster pairs across domains, the directionality and the systematicityof these underlying conceptual mappings were quantified in order to produce an overall confidence inthe mapping.
As part of their development of the Hamburg Metaphor Database (HMD), Reining andL?onneker-Rodman (2007) performed a a manual categorization of lexical items into conceptual sourcedomains with a facet-level granularity and enriched their domains using a WordNet-based lexical expan-sion.
In the same vein, Chung et al.
(2005) chose to model source domains by expanding their lexicalitems by exploiting the links between WordNet glosses and the SUMO ontology.In recent years, however, research has focused on automating the modeling and classification of con-ceptual metaphors as much as possible in order to encourage the scaling up of metaphor research ingeneral.
Veale and Hao (2008), as part of the Talking Points system, developed what they refer to as aSlipnet which defines linked chains of meaning that connect a source to a target through shared (or re-lated) attributes and actions.
As a step in this process, they combined WordNet relations with pragmaticrelations extracted from text and clustered nouns according to their relation (and attribute) similarity inorder to define a weak conceptual mapping within the clusters.
In a similar way, Shutova et al.
(2010),beginning with a seed set of noun/verb linguistic metaphor pairs, performed spectral clustering on a largeset of nouns and verbs in order to predict metaphors which participate in the same conceptual metaphormapping.
In particular, she modeled verbs according to their subcategorization frames parameterized bya model of their selectional preferences, while nouns were modeled according to the verbs with whichthey frequently co-occurred in a dependency relation.More recently, Gandy et al.
(2013) approached the CM discovery problem as a set covering problem.For a given nominal target lexeme, they began by finding all facets (i.e., verbs/adjectives) that sharea positive PMI with the target.
Then, they would find the set of nouns that also have a positive PMIwith those facets, compute their confidence in each association, and heuristically select pairs of concepts(defined as rooted WordNet synset trees) which subsume a large percentage of those nouns and cover alarge portion of the overlapping facets.
Similarly, Shutova and Sun (2013) detect conceptual mappings byperforming hierarchical graph factorization clustering on a graph in which the vertices are defined to benouns (i.e., concepts) and the edges are weighted using Jensen-Shannon Divergence.
For a given inputLM source, its likely conceptual metaphors are then discovered by determining its non-literal clustermembership.
Finally, Strzalkowski et al.
(2013) discovered terms (literal and metaphoric) which oftenco-occur with an LM source in a corpus and clustered those terms using WordNet and corpus statisticsto form ?ProtoSources?
which could be further inspected to define CM source concepts.Two vector-based approaches to concept representation are of particular interest in understanding thepresent work.
In the first of these, Sch?utze (1998) described an approach to word sense identificationusing second-order co-occurrence vectors which were used to cluster first-order vectors of the in-contextterms into senses.2Lin (1998), in developing a methodology for evaluating the quality of thesauri,defined a word vector space that moved beyond simple co-occurrence by integrating information aboutthe relations between the word and its co-occurrents.
In particular, a word?s vector was defined by thenumber of times that word occurred within a set of (word, relation, word) tuples.
Our DepVec spacerepresents an extension to Lin?s space insofar as we incorporate additional information about relational(i.e., selectional) preference.2While context is critical in word sense disambiguation, we hasten to point out that one mark of metaphoricity is its discon-nect from the surrounding literal context.1754Figure 1: The architecture of our conceptual metaphor recognition system.
This system takes a linguisticmetaphor as input, induces potential concepts using vector-space clustering, and maps these clusters ontoa conceptual metaphor domain.3 A New Methodology for Conceptual Metaphor RecognitionFigure 1 shows the overall flow of our metaphor processing architecture.
We begin with a set of doc-uments gathered from a variety of online news-wire sources.
These documents are fed to our state-of-the-art LM detection system which employs a binary logistic regression classifier using a variety offeature modules including imageability and concreteness estimation, topicality modeling, pattern match-ing, semantic categorization, selectional preference violation, and source/target vector space similarity.The methodology used in this system is beyond the scope of this work, but it is described in detail byBracewell et al.
(2014).
The LMs provided by the detection system are validated by a group of native-language experts before being sent for CM recognition system for concept-level interpretation.Once the LMs have been collected and validated, the CM recognition system begins by extracting,weighting, and clustering the common grammatical contexts of the LM source term.
By grammaticalcontext, we refer to the syntactic relations (along with their arguments) which have been found to fre-quently co-occur with the LM source term in open text.
In order to model this grammatical context, wehave syntactically parsed a wide collection of documents in each of our focus languages: English, Span-ish, Russian, and Farsi.
From these parsed documents, we have extracted the most common grammaticalco-occurrents of each word in the corpus along with the relation that connects them and the numberof times they are connected by that relation.
For a given word, we refer to the set of its grammaticalco-occurrents as the ?concept candidates?
associated with that word, as they represent potential conceptswithin the same conceptual domain as the given word (the DOMAIN HYPOTHESIS).
For example,grammatical co-occurrents of the noun ?battle?
would include many WAR concepts such as ?fought?,?died in?, ?waged?, ?naval?, and ?losing?.Since a conceptual domain is made up of several interacting concepts, we perform a clustering overthe grammatical co-occurrents to produce groups of terms which are likely to represent individual con-cepts within a domain.
The clustering is performed within a high-dimensional, distributional vectorspace which we describe in Section 4.
The clusters are then merged and aligned with a set of 51 pre-defined source concept domains (see Table 1) that have been found to occur frequently in conceptualmetaphors about POVERTY, WEALTH, or TAXATION.
For each of these known conceptual domains, wehave amassed a collection of lexical items for the purpose of modeling the domains and aligning themto our automatically discovered domains.
The collection of lexical items associated with each domainhave been further partitioned into three to five facets which provide a more fine-grained representation ofthe domain.
For instance, the conceptual domain of ABYSS as been subdivided into facets representing1755Full Source Concept ListA GOD COMPETITION ENSLAVEMENT LIGHT NATURAL PHYSICAL FORCE PORTALA RIGHT CONFINEMENT FOOD LOW POINT OBESITY RESOURCEABYSS CRIME FORCEFUL EXTRACTION MACHINE PARASITE SCHISMACCIDENT CROP GAME MAZE PATHWAY STRUGGLEADDICTION DARKNESS GEOGRAPHIC FEATURE MEDICINE PHYSICAL BURDEN VERTICAL SCALEANIMAL DESTROYER GOAL DIRECTED MONSTER PHYSICAL HARM VISIONBLOOD SYSTEM DISEASE HIGH POINT MORAL DUTY PHYSICAL LOCATIONBODY OF WATER ENABLER HUMAN BODY MOVEMENT PHYSICAL OBJECTBUILDING ENERGY IMPURITY MOVEMENT ON A VERTICAL SCALE PLANTSample Lexical ItemsANIMAL bite, bark, claw, bird, beaver MEDICINE dosage, prescription, healENSLAVEMENT servant, oppression, ruler STRUGGLE enemy, fight, combat, attackTable 1: The 51 source conceptual domains along with some sample English lexical items for a subsetof them.DEPTH (e.g., ?deep?, ?bottomless?
), ENTRANCE (e.g., ?plunged into?, ?falling into?
), and EXIT (e.g.,?climb out of?
).3.1 Motivating ExampleTable 2 shows a sample of the concept candidates associated with the word ?cure?
along with the relationthat connects them.
Our methodology for extracting these terms is discussed in Section 5.1.nsubjNIH, WHO, therapist, doctor, vaccine,prep ofcancer, AIDS, HIV, malaria, influenza,drug, medicine, chef, butcher seizures, allergiesdobjcancer, polio, Goji Berries, man,prep bybone marrow transplant, spleen cells,genetic defects, aging, infant, woman, acupuncture, smoking, salting,depression, meat, fish, garlic doxycycline, drying, burying, dippingprep withoutsurgery, operation, suppuration, saltprep to?1need, project, brine, mineral,chemotherapy, injections coalition, run, walk, salt, nitriteprep inmice, children, baby, spices, salt,prep forgrinding, smoking, voyages, lox,monkeys, drug trial, breakthrough, transportation, preservation, jerky,brine, smokehouse, basement, fridge sausages, bacon, saleTable 2: Terms that are frequently a part of the grammatical context of ?cure?
along with their associatedrelationsIt is clear from the concept candidates shown that there are at least two coarse-grained senses of?cure?
present ?
corresponding to the domains of MEDICINE and FOOD.
Table 3 shows a sampleresult of clustering these concept candidates.
These clusters are organized according to their domainwith MEDICINE-related clusters in the left grouping, FOOD-related clusters in the top-right grouping,and clusters not strongly related to either domain in the bottom-right grouping.
Each row of the tablerepresents a single cluster.
In addition, it can be observed that these clusters correspond to particularsemantic facets of the conceptual domain.
For instance, there is a cluster that defines ?procedures whichresult in medical cures?
(?acupuncture?, ?surgery?, ?operation?, etc.
), one that defines ?individuals whocure food products?
(?chef?, ?butcher?
), and one that defines ?diseases that can (potentially) be cured?
(?cancer?, ?polio?, ?AIDS?, etc.).
Our methodology for automatically inducing such clusters is describedin Section 5.2.Once the clusters have been identified, they can be used to define a mapping from the original LM(?cure?)
onto a pre-defined set of CM source domains (the MAPPING HYPOTHESIS).
In particular,individual concept candidates are mapped to CM domains by calculating the distance between the can-didate and one or more vectors representing each domain in a high-dimensional distributional vectorspace.4 Distributional RepresentationsOur method for identifying conceptual metaphor domains relies on determining when multiple wordsshould be grouped as belonging to the same conceptual class (the DISTRIBUTIONAL HYPOTHESIS).Previous work in semantic similarity has shown two types of approaches to work well: (a) hand-codedknowledge such as WordNet or SUMO, and (b) distributional approaches which rely on statistics of1756NIH, WHO, therapist, doctor chef, butchervaccine, drug, medicine, doxycycline project, coalitionspleen cells, bone marrow transplant meat, fish, sausages, jerky, bacon, loxacupuncture, surgery, operation garlic, Goji Berrieschemotherapy, injections, suppuration smoking, salting, drying, dippingHIV, malaria, influenza buryingcancer, polio, AIDS salt, brine, spices, nitrite, mineralgenetic defects, aging, depression smokehouse, basement, fridgeseizures, allergies run, walkdrug trial, breakthrough voyages, transportationinfant, man, woman, children, baby mice, monkeysTable 3: Terms from Table 2 grouped into conceptual clusters ?
one per line.
These clusters are organizedaccording to their domain association: MEDICINE (left), FOOD (top-right), unclear (bottom-right).word usage in corpora.
We adopt the distributional approach in order to facilitate research in languages(such as Farsi) for which coverage of existing knowledge bases is limited.
The only requirements for ourapproach are a corpus with documents written in that language and a syntactic parser for the language.We use the Malt dependency parser to obtain syntactic parses for web documents in each language.Table 2 of Section 3.1 shows some of the words which participate regularly with the word ?cure?in a dependency relation.
These syntactic contexts of the word ?cure?
form the basis for one semanticrepresentation we use to find other similar words, which we will call DepVec.
All of the dependencyrelations for a word are used to form a vector-based distributional representation for that word.
Thisrepresentation projects words which are semantically similar to one another onto vectors which are nearto each other in the vector space.
In the following subsection, we describe DepVec along with LSA andword2vec which are alternative vector space models of word meaning.
These vector spaces are then usedto calculate similarities between words in order to cluster them and to align them with lexicons whichmodel our existing conceptual spaces.4.1 Dependency Vectors (DepVec) spaceIn our DepVec vector space model, each word is represented by a vector whose elements correspondto syntactic contexts of the word.
Each element of the vector for word w corresponds to the fre-quency of a unique dependency relation (w, r, w?)
seen in the corpus.
For example, if the relation(whale, nsubj?1, swim) is extracted once, then the vector for ?whale?
contains a 1 in the elementfor (nsubj?1, swim) , and the vector for ?swim?
contains a 1 for the element (nsubj, whale).
Thisrepresentation corresponds that proposed by Lin (1998).However, the use of raw frequency counts in these vectors leads to a situation in which words thatare more frequent in the corpus (e.g., ?of?, ?the?, ?one?)
will have higher frequencies in the vectors bychance alone, and so a high co-occurrence count for those words is not indicative of a significant relationto the word.
We overcome this limitation by replacing the raw frequency counts in each vector with theircorresponding G-test scores.
The G-test is a measure of statistical significance for proportions, similar tothe Chi-square test, which measures the degree to which a particular triple (w, r, w?)
was found to occurmore frequently than expected given all relations (w?
?, r, w?).
If w?occurs far more often with w thanit does with other words, then it will receive a high G-test score for w. In particular, the G-test score iscomputed according to the following equation:G = 2?iOi?
ln(Oi/Ei)where the index i ranges over the four cells of a 2x2 contingency table, Oiis the observed count in celli, and Eiis the expected count in the same cell.1757Language Source # Documents Language Source # DocumentsEnglish ClueWeb 13,361,743 Spanish ClueWeb 3,682,478Russian ruWac 1,173,590 Farsi Online news sites 835,588Table 4: Statistics of the corpora used to construct the vector space models4.2 Latent Semantic Analysis (LSA)While the DepVec model provides information about the immediate contexts a word can be expectedto occur in, it does not directly capture information about the broader contexts typical of that word,such as topical information.
Latent Semantic Analysis (LSA) is a well-studied model (Landauer andDumais, 1997) which does capture such topical information.
The LSA model utilizes a singular valuedecomposition of a TF-IDF weighted matrix representation of the term-document co-occurrences.
Termsand documents are then represented in a reduced dimensionality space using only the information fromthe eigenvectors with the k largest eigenvalues.4.3 Continuous skip-gram model (W2V)Mikolov et al.
(2013) recently presented a new method for determining distributional word representa-tions based on a shallow neural network model.
The values of the latent vector for each word are trainedto optimize prediction of the words within a 10 token window.
This prediction is performed using theterm?s latent vector as the input to a series of log-linear classifiers with outputs which correspond toprobability distributions over the tokens within the context window.
Each position in the context windowis assigned its own classifier weights, so that the model used for making predictions about words imme-diately following the input term is different than the model which makes predictions about the words twotokens after the term, and so on.
Because these latent vector representations are in a low dimensionalityspace (300 dimensions in our case), the training process will tend to move the representations for similarwords closer together in this space in order to maximize the predictive accuracy of their contexts.One benefit of the continuous skip-gram model is that it creates representations which capture somelocal context as in the DepVec model, which is required to make predictions about the previous and nexttokens.
However, it must also encode some topical knowledge in order to make accurate predictionsabout the words seven tokens away.
Therefore, using the latent term representations from the continuousskip-gram model as a vector space puts it in a convenient position in between the two others we presented.4.4 Corpus ProcessingThe vector models described above were developed using web-scale corpora collected from a combina-tion of frequently used NLP corpora and web crawls on news websites.
Table 4 indicates the number ofdocuments used for each language along with their source.
These corpora were part-of-speech taggedwith in-house POS taggers for English and Spanish, TreeTagger3for Russian, and hunpos4for Farsi.
Theopen-source MaltParser was used to produce dependency parses for all four languages (Nivre, 2003).
De-pendency counts for all words occurring fewer than 40 times and for triples occurring fewer than threetimes were discarded to minimize noise.5 Concept Induction and CM RecognitionIn Section 4, we described our DepVec representation of terms as vectors in a high-dimensional dis-tributional space.
These vector representations encode both the dominant grammatical contexts of aterm as well as the selectional preference information associated with it in the form of G-test scores.
Inthis section, we describe our methodology for inducing conceptual domains for a linguistic metaphorby adapting techniques for unsupervised word-sense induction (Erk and Pad?o, 2008; Korkontzelos andManandhar, 2010; Hope and Keller, 2013).
In particular, we induce conceptual domains in an uncon-strained manner by extracting the grammatical co-occurrents of an LM source term (i.e., the ?conceptcandidates?)
and clustering them into semantically-related concept clusters.
Both the clusters and our3http://www.cis.uni-muenchen.de/?schmid/tools/TreeTagger/4http://code.google.com/p/hunpos/1758given source domains are then mapped into a distributional vector space, allowing us to compute cluster-to-domain scores.
Finally, each source domain is assigned a score based on its affinity to each individualcluster with these affinity scores weighted according to cluster quality.
This results in an overall weightedranking of the given source conceptual domains for the linguistic metaphor.5.1 Extracting Concept CandidatesGiven a linguistic metaphor which consists of a metaphor source, s (e.g., ?cure?
), and a metaphor target,t (e.g., ?poverty?
), our system extracts a set of terms (i.e., ?concept candidates?)
from the typical gram-matical contexts of s as found in the web-scale corpus described in Section 4.4.
In order to extract thesecandidates, we first determine the syntactic relation, r, which exists between s and t. This relation is thekey point of interaction between the domains of the source and the target for the given LM and, as such,it provides an indication of which terms will contribute the most to our understanding of the underly-ing conceptual mapping.
In addition, we make use of a predefined set of relations that are semanticallymeaningful ?
specifically the subjects and objects of verbs (i.e., ?nsubj?, ?nsubjpass?, and ?dobj?
),5at-tributes and verbs associated with nouns (i.e., ?amod?, ?dobj?1?, ?nsubj?1?, and ?nsubjpass?1?
), theterms modified by adjectives or adverbs (i.e., ?advmod?1?
and ?amod?1?
), and prepositional relations(e.g., ?prep by?, ?prep of?, ?prep for?).
Using this set of relations, R, we extract the set of candidateterms, X , that have been found to co-occur with the term s within some relation ri?
R in the prepro-cessed, web-scale corpus described in Section 4.4 such that X = {x|(s, ri, x)exists in the corpus}.To improve the quality of our extracted candidates, we apply three criteria to isolate those that bestexemplify the underlying non-metaphorical senses of s. First, we anticipate that any term in X whichdoes not co-occur with s at least k times will not be informative,6and so we remove such terms fromfurther processing.
Next, we predict that poorly imageable terms (i.e., highly abstract terms) are likely torepresent metaphorical usages of s and so are unlikely to be integral to a given literal source domain, sothese are filtered out as well.7Finally, to improve our ability to map these candidates into a conceptualdomain, we remove terms that are not significantly related to any of our provided source domains (i.e.,those that are off-topic) along with terms that are strongly related to multiple source domains (i.e., thosethat are ambiguous) as these provide little evidence to distinguish the most appropriate concept for thegiven LM.8We determine the relatedness of a term to a source domain by measuring the similarity ofthe term and domain vectors in our distributional space as described in Section 5.3.5.2 Clustering Concept CandidatesOnce the candidates have been extracted, they are clustered using a hierarchical agglomerative clusteringalgorithm with the distance metric defined as the cosine distance between the vectors within one of ourdistributional vector spaces.
Each cluster is then assigned a quality score based on its size (to prefer largeclusters with a large amount of semantic evidence), average internal distance (to prefer tighter clusters),and co-occurrence frequency with the LM source (to prefer more closely related terms).
Formally, wedefine the weight associated with a given cluster using the following equation:w(C) = (1?
IDIST (C)) ?
(S2(C) + FREQ(C) ?
(1 + S2(C)))S2(C) =max(SIZE(C)2, k)kwhere IDIST (C) represents the average vector distance between all pairs of terms in cluster C,FREQ(C) represents the total co-occurrence frequency of the terms in C with the original LM,5These dependency relation types come from the MaltParser.6We empirically set k to 3.7We estimate candidate imageability by combining the scores of the candidate?s most distributionally similar words forwhich an imageability score is available in the MRC psycholinguistics database (Coltheart, 1981) using the ranked weightingmethodology described in Mohler et al.
(2014).8Note that filtering by conceptual domain relatedness is only necessary when mapping the induced concepts to a predefinedset of source concepts.1759SIZE(C) represents the number of unique terms in C, and k is a tuning parameter meant to favorlarge clusters.9Singleton clusters are discarded.5.3 Assigning Domain Scores to Concept CandidatesWe propose two methods for calculating domain scores for candidates ?
one which attempts to comparecandidate vectors to a source domain directly, and and another which attempts to compare them to indi-vidual facets of the domain.
These two methods rely on representing sources [CentS], or facets [CentF],as centroids which take the average of the vectors of each the lexemes assigned to that source (or facet).Our three vector spaces ?
DepVec, W2V, and LSA ?
along with our two methods for mapping terms todomains ?
CentS and CentF ?
correspond to six approaches to modeling a CM domain in some vectorspace.In each case, the result for a given candidate is a distribution over all source domain scores.
Thisdistribution is then normalized by subtracting the mean score between the candidate vector and any ofthe source concepts.
Formally, we define the normalized distribution for concept candidate x as:S(x,Dy) = (1?DIST (x,Dy))?
?Dk?D(1?DIST (x,Dk))|D|where D is defined as the set of all known source domains and DIST (x, d) is the cosine distance fromx to a CM domain d in one of our vector spaces.5.3.1 Assigning Domain Scores to ClustersWithin a given cluster (found as described in Section 5.2), the individual concept domain scores can thenbe combined to produce cluster-level domain scores.
For a given cluster Cx, the score associated with aparticular source domain Dyis defined as follows:S(Cx, Dy) =N?i=1S(Cxi, Dy)?iwhere N represents the number of concepts in Cxwith a positive score for the domain Dy, Cxiis thei-th highest score associated with any candidate in the cluster, and ?
is a tuning parameter which boundsthe growth of the cluster-level score.10Any cluster with a maximum domain score that does not exceeda threshold is discarded as being weakly related to any CM source domain.5.3.2 Assigning Domain Scores to the Linguistic MetaphorWe then sum the cluster-level source domain scores, scaling each by its associated cluster quality weightw(c) as computed in Section 5.2.
By scaling cluster domain scores in this way, we ensure that the mostpure and discriminating clusters contribute the most to the overall LM domain scores.
The final resultmeasuring the association between the given LM and the source domain Dyis then defined as:S(Dy) =?Cx?Cw(Cx) ?
S(Cx, Dy)Applied across all known domains, we therefore produce a ranked and scored list of CM source do-mains (i.e., a mapping) that are associated with the given linguistic metaphor and can be used to drivemore robust interpretation of the metaphor.6 EvaluationWe evaluate two aspects of our end-to-end CM recognition system.
First, we analyze the impact of ourchoice of vector space.
Specifically, we compare the use of our DepVec space to link concept candidates9In our experiments, k is set to 5.10We have used a value of ?
= 2 which ensures that the result remains within the bounds [0.0,1.0].1760with source domains against two off-the-shelf vector space models ?
the continuous skip-gram model[W2V] (Mikolov et al., 2013)11and latent semantic analysis [LSA] (Landauer and Dumais, 1997).
Bothalternative models were trained over the same corpus as in our DepVec space using a predefined numberof dimensions (300 for W2V; 400 for LSA).
Second, we have experimented with two different metrics forcalculating the distance between a vector and a source concept ?
the cosine distance to the source-levelcentroid (CentS) and the cosine distance to the facet-level centroid (CentF).Our evaluation dataset consists of a held out, unseen set of documents taken from a variety of newsarticles, opinion pages, and blogs on the open web.
These documents consist of 3 to 5 sentences eachand cover four of our focus languages.12They were then annotated by two native-proficiency speakers inthe following way.
For each LM, they were instructed to choose the most closely related source conceptfrom our list of 51 provided.
Any source concepts selected by at least one annotator were consideredcorrect.
Since our CM recognition system produces a ranked list of source concepts, we report both theaccuracy associated with our top-ranked concept and the accuracy of the system when allowed to selecttwo.Cluster LinkingEnglish Spanish Russian FarsiVector Space Distance Acc@1 Acc@2 Acc@1 Acc@2 Acc@1 Acc@2 Acc@1 Acc@2DepVec CentS 28.0% 44.1% 33.3% 43.4% 24.4% 32.6% 16.5% 27.5%CentF 25.8% 40.9% 33.3% 49.4% 25.6% 34.9% 26.4% 40.7%LSA CentS 34.4% 45.2% 31.0% 41.4% 27.9% 41.9% 22.0% 27.5%CentF 38.7% 54.9% 27.6% 46.0% 29.1% 47.7% 31.9% 44.0%W2V CentS 24.7% 36.6% 42.5% 55.2% 31.4% 43.0% 25.3% 34.1%CentF 28.0% 44.1% 46.0% 58.6% 34.9% 48.8% 35.2% 48.4%Table 5: The accuracy of our conceptual interpretation system.
We experiment with three vector spaces(LSA, W2V, and DepVec) and two source concept centroid representations ?
source-level (CentS) andfacet-level (CentF).These results indicate that the continuous skip-gram vector space [W2V] is well suited to the task ofcluster-level concept mapping, consistently and significantly outperforming both the LSA space and theDepVec space in every language but English.
We believe that this is a result of its probabilistic represen-tation of local context which implicitly collects many of the same relations as the DepVec model whileincorporating the advantages associated with dimensionality reduction which has not been incorporatedinto our DepVec model.13We further observe an unmistakable dominance of the facet-level centroidrepresentation over the source-level representation.
Based on these results, we believe that we have suc-cessfully demonstrated the contribution of our system?s vector-space clustering component which groupsconcept candidates at a facet-level granularity.7 ConclusionIn this paper, we have presented a novel approach to the problem of multilingual conceptual metaphorrecognition which combines facet-based concept induction with a distributional vector space represen-tation of metaphor.
We have experimentally demonstrated the advantage of our fine-grained conceptinduction approach within a variety of vector space models, including our novel DepVec space.
Takentogether, we hypothesize that a facet-level conceptual model represented in a relational context vec-tor space will serve as a reliable foundation enabling high-quality metaphoric interpretation in futuremetaphor research.
Future work includes expanding the set of concept candidates through higher-orderdependency contexts, improved clustering techniques, and evaluating the induced clusters directly.11We make use of the implementation included as part of the gensim python package: http://radimrehurek.com/gensim/12This dataset consists of the following counts of documents: English (92), Spanish (86), Russian (85), Farsi (90).13During our pilot experiments, we applied singular value decomposition (SVD) to the DepVec space without any significantimprovement to system performance.1761AcknowledgmentsThis research is supported by the Intelligence Advanced Research Projects Activity (IARPA) via De-partment of Defense US Army Research Laboratory contract number W911NF-12-C-0025.
The U.S.Government is authorized to reproduce and distribute reprints for Governmental purposes notwithstand-ing any copyright annotation thereon.
Disclaimer: The views and conclusions contained herein are thoseof the authors and should not be interpreted as necessarily representing the official policies or endorse-ments, either expressed or implied, of IARPA, DoD/ARL, or the U.S. Government.ReferencesPierre Beust, St?ephane Ferrari, Vincent Perlerin, et al.
2003.
NLP model and tools for detecting and interpretingmetaphors in domain-specific corpora.
In Proceedings of the Corpus Linguistics 2003 conference, volume 16,pages 114?123.
Citeseer.Danushka Bollegala and Ekaterina Shutova.
2013.
Metaphor interpretation using paraphrases extracted from theweb.
PloS one, 8(9):e74304.D.
Bracewell, M. Tomlinson, M. Mohler, and B. Rink.
2014.
A tiered approach to the recognition of metaphor.
InComputational Linguistics and Intelligent Text Processing.Siaw-Fong Chung, Kathleen Ahrens, and Chu-Ren Huang.
2005.
Source domains as concept domainsin metaphorical expressions.
International Journal of Computational Linguistics and Chinese LanguageProcessing, 10(4):553?570.Max Coltheart.
1981.
The MRC psycholinguistic database.
The Quarterly Journal of Experimental Psychology,33(4):497?505.Katrin Erk and Sebastian Pad?o.
2008.
A structured vector space model for word meaning in context.
InProceedings of the Conference on Empirical Methods in Natural Language Processing, pages 897?906.
As-sociation for Computational Linguistics.J.
Feldman and S. Narayanan.
2004.
Embodied meaning in a neural theory of language.
Brain and language,89(2):385?392.Lisa Gandy, Nadji Allan, Mark Atallah, Ophir Frieder, Newton Howard, Sergey Kanareykin, Moshe Koppel, MarkLast, Yair Neuman, and Shlomo Argamon.
2013.
Automatic identification of conceptual metaphors with limitedknowledge.
In Twenty-Seventh AAAI Conference on Artificial Intelligence.David Hope and Bill Keller.
2013.
MaxMax: a graph-based soft clustering algorithm applied to word senseinduction.
In Computational Linguistics and Intelligent Text Processing, pages 368?381.
Springer.Ioannis Korkontzelos and Suresh Manandhar.
2010.
UoY: Graphs of unambiguous vertices for word sense in-duction and disambiguation.
In Proceedings of the 5th international workshop on semantic evaluation, pages355?358.
Association for Computational Linguistics.G.
Lakoff and M. Johnson.
1980.
Metaphors we live by, volume 111.
Chicago London.G.
Lakoff.
1993.
The contemporary theory of metaphor.
Metaphor and thought, 2:202?251.T.K.
Landauer and S.T.
Dumais.
1997.
A solution to Plato?s problem: The latent semantic analysis theory of acqui-sition, induction, and representation of knowledge.
Psychological Review; Psychological Review, 104(2):211.Dekang Lin.
1998.
Automatic retrieval and clustering of similar words.
In Proceedings of the 17th internationalconference on Computational linguistics-Volume 2, pages 768?774.
Association for Computational Linguistics.Z.J.
Mason.
2004.
CorMet: A computational, corpus-based conventional metaphor extraction system.Computational Linguistics, 30(1):23?44.Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean.
2013.
Efficient estimation of word representations invector space.
arXiv preprint arXiv:1301.3781.Michael Mohler, Marc Tomlinson, and David Bracewell.
2013.
Applying textual entailment to the interpretationof metaphor.
In IEEE Seventh International Conference on Semantic Computing (ICSC), pages 118?125.
IEEE.1762Michael Mohler, Marc Tomlinson, David Bracewell, and Bryan Rink.
2014.
Semi-supervised methods for expand-ing psycholinguistics norms by integrating distributional similarity with the structure of WordNet.
LanguageResources and Evaluation Conference 2014.Joakim Nivre.
2003.
An efficient algorithm for projective dependency parsing.
In Proceedings of the 8thInternational Workshop on Parsing Technologies (IWPT.
Citeseer.Astrid Reining and Birte L?onneker-Rodman.
2007.
Corpus-driven metaphor harvesting.
In Proceedings of theWorkshop on Computational Approaches to Figurative Language, pages 5?12.
Association for ComputationalLinguistics.Hinrich Sch?utze.
1998.
Automatic word sense discrimination.
Computational linguistics, 24(1):97?123.Ekaterina Shutova and Lin Sun.
2013.
Unsupervised metaphor identification using hierarchical graph factorizationclustering.
In Proceedings of NAACL-HLT, pages 978?988.E.
Shutova, L. Sun, and A. Korhonen.
2010.
Metaphor identification using verb and noun clustering.
InProceedings of the 23rd International Conference on Computational Linguistics, pages 1002?1010.
Associa-tion for Computational Linguistics.Ekaterina Shutova.
2010.
Automatic metaphor interpretation as a paraphrasing task.
In Human LanguageTechnologies: The 2010 Annual Conference of the North American Chapter of the Association forComputational Linguistics, pages 1029?1037.
Association for Computational Linguistics.Tomek Strzalkowski, George Aaron Broadwell, Sarah Taylor, Laurie Feldman, Boris Yamrom, Samira Shaikh,Ting Liu, Kit Cho, Umit Boz, Ignacio Cases, et al.
2013.
Robust extraction of metaphors from novel data.Meta4NLP 2013, page 67.T.
Veale and Y. Hao.
2008.
A fluid knowledge representation for understanding and generating creative metaphors.In Proceedings of the 22nd International Conference on Computational Linguistics-Volume 1, pages 945?952.Association for Computational Linguistics.Yorick Wilks, Lucian Galescu, James Allen, and Adam Dalton.
2013.
Automatic metaphor detection using large-scale lexical resources and conventional metaphor extraction.
Meta4NLP 2013, page 36.1763
