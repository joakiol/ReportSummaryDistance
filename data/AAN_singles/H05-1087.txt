Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural LanguageProcessing (HLT/EMNLP), pages 692?699, Vancouver, October 2005. c?2005 Association for Computational LinguisticsMaximum Expected F-Measure Training of Logistic Regression ModelsMartin JanscheCenter for Computational Learning SystemsColumbia UniversityNew York, NY 10027, USAjansche@acm.orgAbstractWe consider the problem of training logis-tic regression models for binary classifi-cation in information extraction and infor-mation retrieval tasks.
Fitting probabilis-tic models for use with such tasks shouldtake into account the demands of the task-specific utility function, in this case thewell-known F-measure, which combinesrecall and precision into a global measureof utility.
We develop a training proce-dure based on empirical risk minimiza-tion / utility maximization and evaluate iton a simple extraction task.1 IntroductionLog-linear models have been used in many areas ofNatural Language Processing (NLP) and InformationRetrieval (IR).
Scenarios in which log-linear modelshave been applied often involve simple binary clas-sification decisions or probability assignments, asin the following three examples: Ratnaparkhi et al(1994) consider a restricted form of the prepositionalphrase attachment problem where attachment deci-sions are binary; Ittycheriah et al (2003) reduce en-tity mention tracking to the problem of modelingthe probability of two mentions being linked; andGreiff and Ponte (2000) develop models of proba-bilistic information retrieval that involve binary de-cisions of relevance.
What is common to all threeapproaches is the application of log-linear models tobinary classification tasks.1 As Ratnaparkhi (1998,1These kinds of log-linear models are also known among theNLP community as ?maximum entropy models?
(Berger et al,p.
27f.)
points out, log-linear models of binary re-sponse variables are equivalent to, and in fact merenotational variants of, logistic regression models.In this paper we focus on binary classificationtasks, and in particular on the loss or utility associ-ated with classification decisions.
The three prob-lems mentioned before ?
prepositional phrase at-tachment, entity mention linkage, and relevance ofa document to a query ?
differ in one crucial aspect:The first is evaluated in terms of accuracy or, equiva-lently, symmetric zero?one loss; but the second andthird are treated as information extraction/retrievalproblems and evaluated in terms of recall and preci-sion.
Recall and precision are combined into a singleoverall utility function, the well-known F-measure.It may be desirable to estimate the parameters of alogistic regression model by maximizing F-measureduring training.
This is analogous, and in a cer-tain sense equivalent, to empirical risk minimiza-tion, which has been used successfully in relatedareas, such as speech recognition (Rahim and Lee,1997), language modeling (Paciorek and Rosenfeld,2000), and machine translation (Och, 2003).The novel contribution of this paper is a trainingprocedure for (approximately) maximizing the ex-pected F-measure of a probabilistic classifier basedon a logistic regression model.
We formulate avector-valued utility function which has a well-defined expected value; F-measure is then a rationalfunction of this expectation and can be maximizednumerically under certain conventional regularizingassumptions.1996; Ratnaparkhi, 1998).
This is an unfortunate choice ofterminology, because the term ?maximum entropy?
does notuniquely determine a family of models unless the constraintssubject to which entropy is being maximized are specified.692We begin with a review of logistic regression(Section 2) and then discuss the use of F-measurefor evaluation (Section 3).
We reformulate F-measure as a function of an expected utility (Sec-tion 4) which is maximized during training (Sec-tion 5).
We discuss the differences between our pa-rameter estimation technique and maximum likeli-hood training on a toy example (Section 6) as wellas on a real extraction task (Section 7).
We concludewith a discussion of further applications and gener-alizations (Section 8).2 Review of Logistic RegressionBernoulli regression models are conditional proba-bility models of a binary response variable Y givena vector ~X of k explanatory variables (X1, .
.
.
,Xk).We will use the convention2 that Y takes on a valuey ?
{?1,+1}.Logistic regression models (Cox, 1958) are per-haps best viewed as instances of generalized linearmodels (Nelder and Wedderburn, 1972; McCullaghand Nelder, 1989) where the the response variablefollows a Bernoulli distribution and the link func-tion is the logit function.
Let us summarize this first,before expanding the relevant definitions:Y ?
Bernoulli(p)logit(p) = ?0 + x1 ?1 + x2 ?2 + ?
?
?+ xk ?kWhat this means is that there is an unobserved quan-tity p, the success probability of the Bernoulli distri-bution, which we interpret as the probability that Ywill take on the value +1:Pr(Y = +1 |~X = (x1,x2, .
.
.
,xk),~?)
= pThe logit (log odds) function is defined as follows:logit(p) = ln(p1?
p)The logit function is used to transform a probabil-ity, constrained to fall within the interval (0,1), intoa real number ranging over (??,+?).
The inversefunction of the logit is the cumulative distribution2The natural choice may seem to be for Y to range over theset {0,1}, but the convention adopted here is more common forclassification problems and has certain advantages which willbecome clear soon.function of the standard logistic distribution (alsoknown as the sigmoid or logistic function), whichwe call g:g(z) =11+ exp(?z)This allows us to writep = g(?0 + x1 ?1 + x2 ?2 + ?
?
?+ xk ?k).We also adopt the usual convention that ~x =(1,x1,x2, .
.
.
,xk), which is a k + 1-dimensional vec-tor whose first component is always 1 and whoseremaining k components are the values of the k ex-planatory variables.
So the Bernoulli probability canbe expressed asp = g(k?j=0x j ?
j)= g(~x ?~?
).The conditional probability model then takes thefollowing abbreviated form, which will be usedthroughout the rest of this paper:Pr(+1 |~x,~?)
= 11+ exp(?~x ?~?
)(1)A classifier can be constructed from this probabil-ity model using the MAP decision rule.
This meanspredicting the label +1 if Pr(+1 |~x,~?)
exceeds 1/2,which amounts to the following:ymap(~x) = argmaxyPr(y |~x,~?)
= sgn(~x ?~?
)This illustrates the well-known result that a MAPclassifier derived from a logistic regression modelis equivalent to a (single-layer) perceptron (Rosen-blatt, 1958) or linear threshold unit.3 F-MeasureSuppose the parameter vector ?
of a logistic regres-sion model is known.
The performance of the re-sulting classifier can then be evaluated in terms ofthe recall (or sensitivity) and precision of the classi-fier on an evaluation dataset.
Recall (R) and preci-sion (P) are defined in terms of the number of truepositives (A), misses (B), and false alarms (C) of theclassifier (cf.
Table 1):R =AA+BP =AA+C693predicted+1 ?1 totaltrue+1 A B npos?1 C D nnegtotal mpos mneg nTable 1: Schema for a 2?2 contingency tableThe F?
measure ?
familiar from Information Re-trieval ?
combines recall and precision into a singleutility criterion by taking their ?-weighted harmonicmean:F?
(R,P) =(?
1R+(1??)
1P)?1The F?
measure can be expressed in terms of thetriple (A,B,C) as follows:F?
(A,B,C) =AA+?
B+(1??
)C (2)In order to define A, B, and C formally, we use thenotation JpiK to denote a variant of the Kroneckerdelta defined like this, where pi is a Boolean expres-sion:JpiK ={1 if pi0 if ?piGiven an evaluation dataset (~x1,y1), .
.
.
,(~xn,yn) thecounts of hits (true positives), misses, and falsealarms are, respectively:A =n?i=1qymap(~xi) = +1yJyi = +1KB =n?i=1qymap(~xi) =?1yJyi = +1KC =n?i=1qymap(~xi) = +1yJyi =?1KNote that F-measure is seemingly a global measureof utility that applies to an evaluation dataset as awhole: while the F-measure of a classifier evaluatedon a single supervised instance is well defined, theoverall F-measure on a larger dataset is not a func-tion of the F-measure evaluated on each instancein the dataset.
This is in contrast to ordinary loss/utility, whose grand total (or average) on a datasetcan be computed by direct summation.4 Relation to Expected UtilityWe reformulate F-measure as a scalar-valued ratio-nal function composed with a vector-valued utilityfunction.
This allows us to define notions of ex-pected and average utility, setting up the discussionof parameter estimation in terms of empirical riskminimization (or rather, utility maximization).Define the following vector-valued utility func-tion u, where u(y?
| y) is the utility of choosing thelabel y?
if the true label is y:u(+1 |+1) = (1,0,0)u(?1 |+1) = (0,1,0)u(+1 |?1) = (0,0,1)u(?1 |?1) = (0,0,0)This function indicates whether a classification deci-sion is a hit, miss, or false alarm.
Correct rejectionsare not counted.Expected values are, of course, well-defined forvector-valued functions.
For example, the expectedutility isE[u] = ?
(~x,y)u(ymap(~x) | y) Pr(~x,y).In empirical risk minimization we approximate theexpected utility of a classifier by its average utilityUS on a given dataset S = (~x1,y1), .
.
.
,(~xn,yn):E[u]?US =1nn?i=1u(ymap(~xi) | yi)=1nn?i=1u(+1 | yi)qymap(~xi) = +1y+u(?1 | yi)qymap(~xi) =?1yNow it is easy to see that US is the following vector:US =1n????????
?n?i=1qymap(~xi) = +1yJyi = +1Kn?i=1qymap(~xi) =?1yJyi = +1Kn?i=1qymap(~xi) = +1yJyi =?1K?????????
(3)So US = n?1 (A,B,C) where A, B, and C are as de-fined before.
This means that we can interpret the694F-measure of a classifier as a simple rational func-tion of its empirical average utility (the scaling fac-tor 1/n in (3) can in fact be omitted).
This allowsus to approach the parameter estimation task as anempirical risk minimization or utility maximizationproblem.5 Discriminative Parameter EstimationIn the preceding two sections we assumed that theparameter vector ~?
was known.
Now we turn tothe problem of estimating ~?
by maximizing the F-measure formulated in terms of expected utility.
Wemake the dependence on ~?
explicit in the formula-tion of the optimization task:~?
?
= argmax~?F?(A(~?),B(~?),C(~?
)),where (A(~?),B(~?),C(~?))
=US(~?)
as defined in (3).We encounter the usual problem: the basic quan-tities involved are integers (counts of hits, misses,and false alarms), and the optimization objective isa piecewise-constant functions of the parameter vec-tor ~?
, due to the fact that ~?
occurs exclusively insideKronecker deltas.
For example:qymap(~x) = +1y=rPr(+1 |~x,~?)
> 0.5zIn general, we can setrPr(+1 |~x,~?)
> 0.5z?
Pr(+1 |~x,~?
), (4)and in the case of logistic regression this arises as aspecial case of approximating the limitrPr(+1 |~x,~?)
> 0.5z= lim???g(?
~x ?~?
)with a fixed value of ?
= 1.
The choice of ?
doesnot matter much.
The important point is that we arenow dealing with approximate quantities which de-pend continuously on ~?
.
In particular A(~?)?
?A(~?),where?A(~?)
=n?i=1yi=+1g(?
~xi ?~?).
(5)Since the marginal total of positive instances npos(cf.
Table 1) does not depend on~?
, we use the identi-ties ?B(~?)
= npos?
?A(~?)
and m?pos(~?)
= ?A(~?
)+ ?C(~?
)to rewrite the optimization objective as ?F?
:?F?(~?)
=?A(~?)?
npos +(1??)
m?pos(~?
), (6)where ?A(~?)
is given by (5) and m?pos(~?)
ism?pos(~?)
=n?i=1g(?
~xi ?~?
).Maximization of ?F as defined in (6) can be car-ried out numerically using multidimensional opti-mization techniques like conjugate gradient search(Fletcher and Reeves, 1964) or quasi-Newton meth-ods such as the BFGS algorithm (Broyden, 1967;Fletcher, 1970; Goldfarb, 1970; Shanno, 1970).
Thisrequires the evaluation of partial derivatives.
The jthpartial derivative of ?F is as follows:?
?F(~?)??
j= h ??A(~?)??
j?h2 ?A(~?)(1??)?
m?pos(~?)??
jh = 1?
npos +(1??)
m?pos(~?)?
?A(~?)??
j=n?i=1yi=+1g?(?
~xi ?~?)?
xi j?
m?pos(~?)??
j=n?i=1g?(?
~xi ?~?)?
xi jg?
(z) = g(z)(1?g(z))One can compute the value of ?F(~?)
and its gradient?
?F(~?)
simultaneously at a given point ~?
in O(nk)time and O(k) space.
Pseudo-code for such an al-gorithm appears in Figure 1.
In practice, the innerloops on lines 8?9 and 14?18 can be made more ef-ficient by using a sparse representation of the rowvectors x[i].
A concrete implementation of this al-gorithm can then be used as a callback to a multi-dimensional optimization routine.
We use the BFGSminimizer provided by the GNU Scientific Library(Galassi et al, 2003).
Important caveat: the func-tion ?F is generally not concave.
We deal with thisproblem by taking the maximum across several runsof the optimization algorithm starting from randominitial values.
The next section illustrates this pointfurther.695x y0 +11 ?12 +13 +1Table 2: Toy dataset6 Comparison with Maximum LikelihoodA comparison with the method of maximum like-lihood illustrates two important properties of dis-criminative parameter estimation.
Consider the toydataset in Table 2 consisting of four supervised in-stances with a single explanatory variable.
Thus thelogistic regression model has two parameters andtakes the following form:Pr toy(+1 | x,?0,?1) =11+ exp(??0?
x?1)The log-likelihood function L is simplyL(?0,?1) = logPr toy(+1 |0,?0,?1)+ logPr toy(?1 |1,?0,?1)+ logPr toy(+1 |2,?0,?1)+ logPr toy(+1 |3,?0,?1).A surface plot of L is shown in Figure 2.
Ob-serve that L is concave; its global maximum occursnear (?0,?1) ?
(0.35,0.57), and its value is alwaysstrictly negative because the toy dataset is not lin-early separable.
The classifier resulting from maxi-mum likelihood training predicts the label +1 for alltraining instances and thus achieves a recall of 3/3and precision 3/4 on its training data.
The F?=0.5measure is 6/7.Contrast the shape of the log-likelihood functionL with the function ?F?
.
Surface plots of ?F?=0.5 and?F?=0.25 appear in Figure 3.
The figures clearly illus-trate the first important (but undesirable) property of?F , namely the lack of concavity.
They also illustratea desirable property, namely the ability to take intoaccount certain properties of the loss function dur-ing training.
The ?F?=0.5 surface in the left panel ofFigure 3 achieves its maximum in the right cornerfor (?0,?1)?
(+?,+?).
If we choose (?0,?1) =(20,15) the classifier labels every instance of thetraining data with +1.fdf(?
):1: m?
02: A?
03: for j?
0 to k do4: dm[ j]?
05: dA[ j]?
06: for i?
1 to n do7: p?
08: for j?
0 to k do9: p?
p+ x[i][ j]??
[ j]10: p?
1/(1+ exp(?d))11: m?
m+ p12: if y[i] = +1 then13: A?
A+ p14: for j?
0 to k do15: t?
p?
(1?
p)?
x[i][ j]16: dm[ j]?
dm[ j]+ t17: if y[i] = +1 then18: dA[ j]?
dA[ j]+ t19: h?
1/(?
?npos +(1??
)?m)20: F ?
h?A21: t?
F?
(1??
)22: for j?
0 to k do23: dF[ j]?
h?
(dA[ j]?
t?dm[ j])24: return (F,dF)Figure 1: Algorithm for computing ?F and ?
?FL(?0, ?1)-25-20-15-10-5051015?0-20 -15-10 -50  510  1520?1-180-160-140-120-100-80-60-40-200Figure 2: Surface plot of L on the toy datasetObserve the difference between the ?F?=0.5 surfaceand the ?F?=0.25 surface in the right hand panel ofFigure 3: ?F?=0.25 achieves its maximum in the backcorner for (?0,?1)?
(??,+?).
If we set (?0,?1) =(?20,15) the resulting classifier labels the first two696F0.5(?0, ?1)-25-20-15-10-5051015?0-20 -15-10 -50  510  1520?100.10.20.30.40.50.60.70.80.91F0.25(?0, ?1)-25-20-15-10-5051015?0-20 -15-10 -50  510  1520?100.10.20.30.40.50.60.70.80.91Figure 3: Surface plot of ?F?=0.5 (left) and ?F?=0.25 (right) on the toy datasetinstances (x = 0 and x = 1) as ?1 and the last twoinstances (x = 2 and x = 3) as +1.The classifier trained according to the ?F?=0.5 cri-terion achieves an F?=0.5 measure of 6/7 ?
0.86,compared with 4/5 = 0.80 for the classifier trainedaccording to the ?F?=0.25 criterion.
Conversely, thatclassifier achieves an F?=0.25 measure of 8/9?
0.89compared with 4/5 = 0.80 for the classifier trainedaccording to the ?F?=0.5 criterion.
This demonstratesthat the training procedure can effectively take infor-mation from the utility function into account, pro-ducing a classifier that performs well under a givenevaluation criterion.
This is the result of optimizinga task-specific utility function during training, notsimply a matter of adjusting the decision thresholdof a trained classifier.7 Evaluation on an Extraction ProblemWe evaluated our discriminative training procedureon a real extraction problem arising in broadcastnews summarization.
The overall task is to summa-rize the stories in an audio news broadcast (or in theaudio portion of an A/V broadcast).
We assume thatstory boundaries have been identified and that eachstory has been broken up into sentence-like units.
Asimple way of summarizing a story is then to classifyeach sentence as either belonging into a summary ornot, so that a relevant subset of sentences can be ex-tracted to form the basis of a summary.
What makesthe classification task hard, and therefore interesting,is the fact that reliable features are hard to come by.Existing approaches such as Maskey and Hirschberg2005 do well only when combining diverse featuressuch as lexical cues, acoustic properties, structural/positional features, etc.The task has another property which renders itproblematic, and which prompted us to developthe discriminative training procedure described inthis paper.
Summarization, by definition, aims forbrevity.
This means that in any dataset the numberof positive instances will be much smaller than thenumber of negative instances.
Given enough data,balance could be restored by discarding negative in-stances.
This, however, was not an option in ourcase: a moderate amount of manually labeled datahad been produced and about one third would havehad to be discarded to achieve a balance in the dis-tribution of class labels.
This would have eliminatedprecious supervised training data, which we werenot prepared to do.The training and test data were prepared byMaskey and Hirschberg (2005), who performed thefeature engineering, imputation of missing values,and the training?test split.
We used the data un-changed in order to allow for a comparison betweenapproaches.
The dataset is made up of 30 fea-tures, divided into one binary response variable, andone binary explanatory variable plus 28 integer- andreal-valued explanatory variables.
The training por-tion consists of 3 535 instances, the test portion of408 instances.We fitted logistic regression models in three dif-ferent ways: by maximum likelihood ML, by ?F?=0.5maximization, and by ?F?=0.75 maximization.
Each697Method R P F?=0.5 F?=0.75ML 24/99 24/33 0.3636 0.2909ML?
85/99 85/229 0.5183 0.6464?F?=0.5 85/99 85/211 0.5484 0.6693?F?=0.75 95/99 95/330 0.4429 0.6061Table 3: Evaluation resultsclassifier was evaluated on the test dataset and its re-call (R), precision (P), F?=0.5 measure, and F?=0.75measure recorded.
The results appear in Table 3.The row labeled ML?
is special: the classifier usedhere is the logistic regression model fitted by maxi-mum likelihood; what is different is that the thresh-old for positive predictions was adjusted post hoc tomatch the number of true positives of the first dis-criminatively trained classifier.
This has the sameeffect as manually adjusting the threshold parameter?0 based on partial knowledge of the test data (viathe performance of another classifier) and is thusnot permissible.
It is interesting to note, however,that the ML trained classifier performs worse thanthe ?F?=0.5 trained classifier even when one param-eter is adjusted by an oracle with knowledge of thetest data and the performance of the other classifier.Fitting a model based on ?F?=0.75, which gives in-creased weight to recall compared with ?F?=0.5, ledto higher recall as expected.
However, we also ex-pected that the F?=0.75 score of the ?F?=0.75 trainedclassifier would be higher than the F?=0.75 score ofthe ?F?=0.5 trained classifier.
This is not the case, andcould be due to the optimization getting stuck in alocal maximum, or it may have been an unreason-able expectation to begin with.8 ConclusionsWe have presented a novel estimation procedurefor probabilistic classifiers which we call, by aslight abuse of terminology, maximum expected F-measure training.
We made use of the fact that ex-pected utility computations can be carried out in avector space, and that an ordering of vectors can beimposed for purposes of maximization which canemploy auxiliary functions like the F-measure (2).This technique is quite general and well suited forworking with other quantities that can be expressedin terms of hits, misses, false alarms, correct rejec-tions, etc.
In particular, it could be used to find apoint estimate which provides a certain tradeoff be-tween specificity and sensitivity, or operating point.A more general method would try to optimize sev-eral such operating points simultaneously, an issuewhich we will leave for future research.The classifiers discussed in this paper are logisticregression models.
However, this choice is not cru-cial.
The approximation (4) is reasonable for binarydecisions in general, and one can use it in conjunc-tion with any well-behaved conditional Bernoullimodel or related classifier.
For Support Vector Ma-chines, approximate F-measure maximization wasintroduced by Musicant et al (2003).Maximizing F-measure during training seems es-pecially well suited for dealing with skewed classes.This can happen by accident, because of the natureof the problem as in our summarization exampleabove, or by design: for example, one can expectskewed binary classes as the result of the one-vs-allreduction of multi-class classification to binary clas-sification; and in multi-stage classification one maywant to alternate between classifiers with high recalland classifiers with high precision.Finally, the ability to incorporate non-standardtradeoffs between precision and recall at trainingtime is useful in many information extraction andretrieval applications.
Human end-users often createasymmetries between precision and recall, for goodreasons: they may prefer to err on the side of caution(e.g., it is less of a problem to let an unwanted spamemail reach a user than it is to hold back a legitimatemessage), or they may be better at some tasks thanothers (e.g., search engine users are good at filteringout irrelevant documents returned by a query, but arenot equipped to crawl the web in order to look forrelevant information that was not retrieved).
In theabsence of methods that work well for a wide rangeof operating points, we need training procedures thatcan be made sensitive to rare cases depending on theparticular demands of the application.AcknowledgementsI would like to thank Julia Hirschberg, SameerMaskey, and the three anonymous reviewers forhelpful comments.
I am especially grateful to698Sameer Maskey for allowing me to use his speechsummarization dataset for the evaluation in Sec-tion 7.
The usual disclaimers apply.ReferencesAdam L. Berger, Vincent J. Della Pietra, andStephen A. Della Pietra.
1996.
A maximumentropy approach to natural language processing.Computational Linguistics, 22(1):39?71.C.
G. Broyden.
1967.
Quasi-Newton methods andtheir application to function minimisation.
Math-ematics of Computation, 21(99):368?381.D.
R. Cox.
1958.
The regression analysis of binarysequences.
Journal of the Royal Statistical Soci-ety, Series B (Methodological), 20(2):215?242.R.
Fletcher.
1970.
A new approach to variablemetric algorithms.
The Computer Journal,13(3):317?322.
doi:10.1093/comjnl/13.3.317.R.
Fletcher and C. M. Reeves.
1964.
Func-tion minimization by conjugate gradients.The Computer Journal, 7(2):149?154.doi:10.1093/comjnl/7.2.149.Mark Galassi, Jim Davies, James Theiler, BrianGough, Gerard Jungman, Michael Booth, andFabrice Rossi.
2003.
GNU Scientific LibraryReference Manual.
Network Theory, Bristol,UK, second edition.Donald Goldfarb.
1970.
A family of variable-metricmethods derived by variational means.
Mathe-matics of Computation, 24(109):23?26.Warren R. Greiff and Jay M. Ponte.
2000.The maximum entropy approach and prob-abilistic IR models.
ACM Transactionson Information Systems, 18(3):246?287.doi:10.1145/352595.352597.Abraham Ittycheriah, Lucian Lita, Nanda Kamb-hatla, Nicolas Nicolov, Salim Roukos, andMargo Stys.
2003.
Identifying and trackingentity mentions in a maximum entropy frame-work.
In HLT/NAACL 2003.
ACL AnthologyN03-2014.Sameer Maskey and Julia Hirschberg.
2005.
Com-paring lexical, acoustic/prosodic, structural anddiscourse features for speech summarization.
InInterspeech 2005 (Eurospeech).P.
McCullagh and J.
A. Nelder.
1989.
GeneralizedLinear Models.
Chapman & Hall/CRC, BocaRaton, FL, second edition.David R. Musicant, Vipin Kumar, and Aysel Ozgur.2003.
Optimizing F-measure with Support Vec-tor Machines.
In FLAIRS 16, pages 356?360.J.
A. Nelder and R. W. M. Wedderburn.
1972.
Gen-eralized linear models.
Journal of the Royal Sta-tistical Society, Series A (General), 135(3):370?384.Franz Josef Och.
2003.
Minimum error rate train-ing in statistical machine translation.
In ACL 41.ACL Anthology P03-1021.Chris Paciorek and Roni Rosenfeld.
2000.
Mini-mum classification error training in exponentiallanguage models.
In NIST/DARPA Speech Tran-scription Workshop.Mazin Rahim and Chin-Hui Lee.
1997.
String-based minimum verification error (SB-MVE)training for speech recognition.
Computer,Speech and Language, 11(2):147?160.Adwait Ratnaparkhi.
1998.
Maximum EntropyModels for Natural Language Ambiguity Reso-lution.
Ph.D. thesis, University of Pennsylvania,Computer and Information Science.Adwait Ratnaparkhi, Jeff Reynar, and SalimRoukos.
1994.
A maximum entropy modelfor prepositional phrase attachment.
In ARPAHuman Language Technology Workshop, pages250?255.
ACL Anthology H94-1048.Frank Rosenblatt.
1958.
The perceptron: A prob-abilistic model for information storage and or-ganization in the brain.
Psychological Review,65(6):386?408.D.
F. Shanno.
1970.
Conditioning of quasi-Newtonmethods for function minimization.
Mathematicsof Computation, 24(111):647?656.699
