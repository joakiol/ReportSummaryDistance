Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 1052?1061,Baltimore, Maryland, USA, June 23-25 2014.c?2014 Association for Computational LinguisticsA Provably Correct Learning Algorithm for Latent-Variable PCFGsShay B. CohenSchool of InformaticsUniversity of Edinburghscohen@inf.ed.ac.ukMichael CollinsDepartment of Computer ScienceColumbia Universitymcollins@cs.columbia.eduAbstractWe introduce a provably correct learningalgorithm for latent-variable PCFGs.
Thealgorithm relies on two steps: first, the useof a matrix-decomposition algorithm ap-plied to a co-occurrence matrix estimatedfrom the parse trees in a training sample;second, the use of EM applied to a convexobjective derived from the training sam-ples in combination with the output fromthe matrix decomposition.
Experiments onparsing and a language modeling problemshow that the algorithm is efficient and ef-fective in practice.1 IntroductionLatent-variable PCFGs (L-PCFGs) (Matsuzaki etal., 2005; Petrov et al, 2006) give state-of-the-artperformance on parsing problems.
The standardapproach to parameter estimation in L-PCFGs isthe EM algorithm (Dempster et al, 1977), whichhas the usual problems with local optima.
Re-cent work (Cohen et al, 2012) has introduced analternative algorithm, based on spectral methods,which has provable guarantees.
Unfortunately thisalgorithm does not return parameter estimates forthe underlying L-PCFG, instead returning the pa-rameter values up to an (unknown) linear trans-form.
In practice, this is a limitation.We describe an algorithm that, like EM, re-turns estimates of the original parameters of an L-PCFG, but, unlike EM, does not suffer from prob-lems of local optima.
The algorithm relies on twokey ideas:1) A matrix decomposition algorithm (sec-tion 5) which is applicable to matrices Q of theform Qf,g=?hp(h)p(f | h)p(g | h) wherep(h), p(f | h) and p(g | h) are multinomial dis-tributions.
This matrix form has clear relevanceto latent variable models.
We apply the matrixdecomposition algorithm to a co-occurrence ma-trix that can be estimated directly from a trainingset consisting of parse trees without latent anno-tations.
The resulting parameter estimates give ussignificant leverage over the learning problem.2) Optimization of a convex objective functionusing EM.
We show that once the matrix decom-position step has been applied, parameter estima-tion of the L-PCFG can be reduced to a convexoptimization problem that is easily solved by EM.The algorithm provably learns the parameters ofan L-PCFG (theorem 1), under an assumption thateach latent state has at least one ?pivot?
feature.This assumption is similar to the ?pivot word?
as-sumption used by Arora et al (2013) and Arora etal.
(2012) in the context of learning topic models.We describe experiments on learning of L-PCFGs, and also on learning of the latent-variablelanguage model of Saul and Pereira (1997).
A hy-brid method, which uses our algorithm as an ini-tializer for EM, performs at the same accuracy asEM, but requires significantly fewer iterations forconvergence: for example in our L-PCFG exper-iments, it typically requires 2 EM iterations forconvergence, as opposed to 20-40 EM iterationsfor initializers used in previous work.While this paper?s focus is on L-PCFGs, thetechniques we describe are likely to be applicableto many other latent-variable models used in NLP.2 Related WorkRecently a number of researchers have developedprovably correct algorithms for parameter esti-mation in latent variable models such as hiddenMarkov models, topic models, directed graphicalmodels with latent variables, and so on (Hsu etal., 2009; Bailly et al, 2010; Siddiqi et al, 2010;Parikh et al, 2011; Balle et al, 2011; Arora etal., 2013; Dhillon et al, 2012; Anandkumar etal., 2012; Arora et al, 2012; Arora et al, 2013).Many of these algorithms have their roots in spec-tral methods such as canonical correlation analy-sis (CCA) (Hotelling, 1936), or higher-order ten-sor decompositions.
Previous work (Cohen et al,2012; Cohen et al, 2013) has developed a spec-tral method for learning of L-PCFGs; this methodlearns parameters of the model up to an unknown1052linear transformation, which cancels in the inside-outside calculations for marginalization over la-tent states in the L-PCFG.
The lack of direct pa-rameter estimates from this method leads to prob-lems with negative or unnormalized probablities;the method does not give parameters that are in-terpretable, or that can be used in conjunction withother algorithms, for example as an initializer forEM steps that refine the model.Our work is most directly related to the algo-rithm for parameter estimation in topic models de-scribed by Arora et al (2013).
This algorithmforms the core of the matrix decomposition algo-rithm described in section 5.3 BackgroundThis section gives definitions and notation for L-PCFGs, taken from (Cohen et al, 2012).3.1 L-PCFGs: Basic DefinitionsAn L-PCFG is an 8-tuple (N , I,P,m, n, pi, t, q)where: N is the set of non-terminal symbols in thegrammar.
I ?
N is a finite set of in-terminals.P ?
N is a finite set of pre-terminals.
We as-sume that N = I ?
P , and I ?
P = ?.
Hencewe have partitioned the set of non-terminals intotwo subsets.
[m] is the set of possible hiddenstates.1[n] is the set of possible words.
Forall (a, b, c) ?
I ?
N ?
N , and (h1, h2, h3) ?
[m] ?
[m] ?
[m], we have a context-free rulea(h1) ?
b(h2) c(h3).
The rule has an associ-ated parameter t(a?
b c, h2, h3| a, h1).
For alla ?
P , h ?
[m], x ?
[n], we have a context-freerule a(h)?
x.
The rule has an associated param-eter q(a ?
x | a, h).
For all a ?
I, h ?
[m],pi(a, h) is a parameter specifying the probabilityof a(h) being at the root of a tree.A skeletal tree (s-tree) is a sequence of rulesr1.
.
.
rNwhere each riis either of the form a ?b c or a ?
x.
The rule sequence forms atop-down, left-most derivation under a CFG withskeletal rules.A full tree consists of an s-tree r1.
.
.
rN, to-gether with values h1.
.
.
hN.
Each hiis the valuefor the hidden variable for the left-hand-side ofrule ri.
Each hican take any value in [m].For a given skeletal tree r1.
.
.
rN, define aitobe the non-terminal on the left-hand-side of ruleri.
For any i ?
[N ] such that riis of the forma?
b c, define h(2)iand h(3)ias the hidden state1For any integer n, we use [n] to denote the set{1, 2, .
.
.
n}.value of the left and right child respectively.
Themodel then defines a distribution asp(r1.
.
.
rN, h1.
.
.
hN) =pi(a1, h1)?i:ai?It(ri, h(2)i, h(3)i| ai, hi)?i:ai?Pq(ri| ai, hi)The distribution over skeletal trees isp(r1.
.
.
rN) =?h1...hNp(r1.
.
.
rN, h1.
.
.
hN).3.2 Definition of Random VariablesThroughout this paper we will make referenceto random variables derived from the distributionover full trees from an L-PCFG.
These randomvariables are defined as follows.
First, we selecta random internal node, from a random tree, asfollows: 1) Sample a full tree r1.
.
.
rN, h1.
.
.
hNfrom the PMF p(r1.
.
.
rN, h1.
.
.
hN); 2) Choosea node i uniformly at random from [N ].
We thengive the following definition:Definition 1 (Random Variables).
If the rule riforthe node i is of the form a?
b c, we define ran-dom variables as follows: R1is equal to the rule ri(e.g., NP?
D N).
A,B,C are the labels for node i,the left child of node i, and the right child of nodei respectively.
(E.g., A = NP, B = D, C = N.) T1is the inside tree rooted at node i. T2is the insidetree rooted at the left child of node i, and T3is theinside tree rooted at the right child of node i. O isthe outside tree at node i. H1, H2, H3are the hid-den variables associated with node i, the left childof node i, and the right child of node i respectively.E is equal to 1 if node i is at the root of the tree(i.e., i = 1), 0 otherwise.If the rule rifor the selected node i isof the form a ?
x, we have random vari-ables R1, T1, H1, A1, O,E as defined above, butH2, H3, T2, T3, B, and C are not defined.4 The Learning Algorithm for L-PCFGsOur goal is to design a learning algorithm for L-PCFGs.
The input to the algorithm will be a train-ing set consisting of skeletal trees, assumed to besampled from some underlying L-PCFG.
The out-put of the algorithm will be estimates for the pi,t, and q parameters.
The training set does notinclude values for the latent variables; this is themain challenge in learning.This section focuses on an algorithm for recov-ery of the t parameters.
A description of the al-gorithms for recovery of the pi and q parametersis deferred until section 6.1 of this paper; these1053steps are straightforward once we have derived themethod for the t parameters.We describe an algorithm that correctly recov-ers the parameters of an L-PCFG as the size of thetraining set goes to infinity (this statement is mademore precise in section 4.2).
The algorithm relieson an assumption?the ?pivot?
assumption?thatwe now describe.4.1 Features, and the Pivot AssumptionWe assume a function ?
from inside trees to a fi-nite set F , and a function ?
that maps outside treesto a finite set G. The function ?
(t) (?
(o)) can bethought of as a function that maps an inside treet (outside tree o) to an underlying feature.
Asone example, the function ?
(t) might return thecontext-free rule at the root of the inside tree t;in this case the set F would be equal to the setof all context-free rules in the grammar.
As an-other example, the function ?
(o) might return thecontext-free rule at the foot of the outside tree o.In the more general case, we might have K sep-arate functions ?
(k)(t) for k = 1 .
.
.K mappinginside trees to K separate features, and similarlywe might have multiple features for outside trees.Cohen et al (2013) describe one such feature def-inition, where features track single context-freerules as well as larger fragments such as two orthree-level sub-trees.
For simplicity of presenta-tion we describe the case of single features ?
(t)and ?
(o) for the majority of this paper.
The exten-sion to multiple features is straightforward, and isdiscussed in section 6.2; the flexibility allowed bymultiple features is important, and we use multiplefeatures in our experiments.Given functions ?
and ?, we define additionalrandom variables: F = ?
(T1), F2= ?
(T2), F3=?
(T3), and G = ?
(O).We can now give the following assumption:Assumption 1 (The Pivot Assumption).
Underthe L-PCFG being learned, there exist values ?
>0 and ?
> 0 such that for each non-terminal a,for each hidden state h ?
[m], the following state-ments are true: 1) ?f ?
F such that P (F =f | H1= h,A = a) > ?
and for all h?6= h,P (F = f | H1= h?, A = a) = 0; 2) ?g ?
Gsuch that P (G = g | H1= h,A = a) > ?
andfor all h?6= h, P (G = g | H1= h?, A = a) = 0.This assumption is very similar to the assump-tion made by Arora et al (2012) in the con-text of learning topic models.
It implies that foreach (a, h) pair, there are inside and outside treefeatures?which following Arora et al (2012) werefer to as pivot features?that occur only2in thepresence of latent-state value h. As in (Arora etal., 2012), the pivot features will give us consider-able leverage in learning of the model.4.2 The Learning AlgorithmFigure 1 shows the learning algorithm for L-PCFGs.
The algorithm consists of the followingsteps:Step 0: Calculate estimates p?(a?
b c | a),p?
(g, f2, f3| a?
b c) and p?
(f, g | a).
Theseestimates are easily calculated using counts takenfrom the training examples.Step 1: Calculate values r?
(f | h, a) and s?
(g |h, a); these are estimates of p(f | h1, a) andp(g | h1, a) respectively.
This step is achieved us-ing a matrix decomposition algorithm, describedin section 5 of this paper, on the matrix?Qawithentries [?Qa]f,g= p?
(f, g | a).Step 2: Use the EM algorithm to find?t valuesthat maximize the objective function in Eq.
1 (seefigure 1).
Crucially, this is a convex optimizationproblem, and the EM algorithm will converge tothe global maximum of this likelihood function.Step 3: Rule estimates are calculated using anapplication of the laws of probability.Before giving a theorem concerning correctnessof the algorithm we introduce two assumptions:Assumption 2 (Strict Convexity).
If we have theequalities s?
(g | h1, a) = P (G = g | H1=h1, A = a), r?
(f2| h2, b) = P (F2= f2| H2=h2, B = b) and r?
(f3| h3, c) = P (F3= f3|H2= h3, C = c), then the function in Eq.
1 (fig-ure 1) is strictly concave.The function in Eq.
1 is always concave; thisassumption adds the restriction that the functionmust be strictly concave?that is, it has a uniqueglobal maximum?in the case that the r?
and s?
es-timates are exact estimates.Assumption 3 (Infinite Data).
After running Step0 of the algorithm we havep?(a?
b c | a) = p(a?
b c | a)p?
(g, f2, f3| a?
b c) = p(g, f2, f3| a?
b c)p?
(f, g | a) = p(f, g | a)where p(.
.
.)
is the probability under the underly-ing L-PCFG.2The requirements P (F = f | H1= h?, A = a) = 0and P (G = g | H1= h?, A = a) = 0 are almost certainlyoverly strict; in theory and practice these probabilities shouldbe able to take small but strictly positive values.1054We use the term ?infinite data?
because understandard arguments, p?(.
.
.)
converges to p(.
.
.)
asM goes to?.The theorem is then as follows:Theorem 1.
Consider the algorithm in figure 1.Assume that assumptions 1-3 (the pivot, strongconvexity, and infinite data assumptions) hold forthe underlying L-PCFG.
Then there is some per-mutation ?
: [m] ?
[m] such that for alla?
b c, h1, h2, h3,?t(a?
b c, h2, h3| a?
b c, h1)= t(a?
b c, ?
(h2), ?
(h3) | a?
b c, ?
(h1))where?t are the parameters in the output, and t arethe parameters of the underlying L-PCFG.This theorem states that under assumptions 1-3, the algorithm correctly learns the t parametersof an L-PCFG, up to a permutation over the la-tent states defined by ?.
Given the assumptions wehave made, it is not possible to do better than re-covering the correct parameter values up to a per-mutation, due to symmetries in the model.
As-suming that the pi and q parameters are recoveredin addition to the t parameters (see section 6.1),the resulting model will define exactly the samedistribution over full trees as the underlying L-PCFG up to this permutation, and will define ex-actly the same distribution over skeletal trees, soin this sense the permutation is benign.Proof of theorem 1: Under the assumptions ofthe theorem,?Qaf,g= p(f, g | a) =?hp(h |a)p(f | h, a)p(g | h, a).
Under the pivot assump-tion, and theorem 2 of section 5, step 1 (the matrixdecomposition step) will therefore recover valuesr?
and s?
such that r?
(f | h, a) = p(f | ?
(h), a) ands?
(g | h, a) = p(g | ?
(h), a) for some permuta-tion ?
: [m] ?
[m].
For simplicity, assume that?
(j) = j for all j ?
[m] (the argument for otherpermutations involves a straightforward extensionof the following argument).
Under the assump-tions of the theorem, p?
(g, f2, f3| a?
b c) =p(g, f2, f3| a?
b c), hence the function beingoptimized in Eq.
1 is equal to?g,f2,f3p(g, f2, f3| a?
b c) log ?
(g, f2, f3)where?
(g, f2, f3) =?h1,h2,h3(?t(h1, h2, h3| a?
b c)?p(g | h1, a)p(f2| h2, b)p(f3| h3, c))Now consider the optimization problem in Eq.
1.By standard results for cross entropy, the maxi-mum of the function?g,f2,f3p(g, f2, f3| a?
b c) log q(g, f2, f3| a?
b c)with respect to the q values is achieved atq(g, f2, f3| a?
b c) = p(g, f2, f3| a?
b c).
Inaddition, under the assumptions of the L-PCFG,p(g, f2, f3| a?
b c)=?h1,h2,h3(p(h1, h2, h3| a?
b c)?p(g | h1, a)p(f2| h2, b)p(f3| h3, c))Hence the maximum of Eq.
1 is achieved at?t(h1, h2, h3| a?
b c) = p(h1, h2, h3| a?
b c)(2)because this gives ?
(g, f2, f3) = p(g, f2, f3|a?
b c).
Under the strict convexity assump-tion the maximum of Eq.
1 is unique, hence the?t values must satisfy Eq.
2.
Finally, it followsfrom Eq.
2, and the equality p?(a?
b c | a) =p(a?
b c | a), that Step 3 of the algorithm gives?t(a?
b c, h2, h3| a, h1) = t(a?
b c, h2, h3|a, h1).We can now see how the strict convexity as-sumption is needed.
Without this assumption,there may be multiple settings for?t that achieve?
(g, f2, f3) = p(g, f2, f3| a?
b c); the values?t(h1, h2, h3| a?
b c) = p(h1, h2, h3| a?
b c)will be included in this set of solutions, but other,inconsistent solutions will also be included.As an extreme example of the failure of thestrict convexity assumption, consider a feature-vector definition with |F| = |G| = 1.
Inthis case the function in Eq.
1 reduces tolog?h1,h2,h3?t(h1, h2, h3| a?
b c).
This func-tion has a maximum value of 0, achieved at all val-ues of?t.
Intuitively, this definition of inside andoutside tree features loses all information aboutthe latent states, and does not allow successfullearning of the underlying L-PCFG.
More gener-ally, it is clear that the strict convexity assumptionwill depend directly on the choice of feature func-tions ?
(t) and ?
(o).Remark: The infinite data assumption, andsample complexity.
The infinite data assump-tion deserves more discussion.
It is clearly astrong assumption that there is sufficient data for1055Input: A set ofM skeletal trees sampled from some underlying L-PCFG.
The count[.
.
.]
function counts the number of timesthat event .
.
.
occurs in the training sample.
For example, count[A = a] is the number of times random variableA takes valuea in the training sample.Step 0: Calculate the following estimates from the training samples:?
p?(a?
b c | a) = count[R1= a?
b c]/count[A = a]?
p?
(g, f2, f3| a?
b c) = count[G = g, F2= f2, F3= f3, R1= a?
b c]/count[R1= a?
b c]?
p?
(f, g | a) = count[F = f,G = g,A = a]/count[A = a]?
?a ?
I, define a matrix?Qa?
Rd?d?where d = |F| and d?= |G| as [?Qa]f,g= p?
(f, g | a).Step 1: ?a ?
I, use the algorithm in figure 2 with input?Qato derive estimates r?
(f | h, a) and s?
(g | h, a).Remark: These quantities are estimates of P (F1= f | H1= h,A = a) and P (G = g | H = h,A = a) respectively.
Notethat under the independence assumptions of the L-PCFG,P (F1= f | H1= h,A = a) = P (F2= f | H2= h,A2= a) = P (F3= f | H3= h,A3= a).Step 2: For each rule a?
b c, find?t(h1, h2, h3| a?
b c) values that maximize?g,f2,f3p?
(g, f2, f3| a?
b c) log?h1,h2,h3?t(h1, h2, h3| a?
b c)s?
(g | h1, a)r?
(f2| h2, b)r?
(f3| h3, c) (1)under the constraints?t(h1, h2, h3| a?
b c) ?
0, and?h1,h2,h3?t(h1, h2, h3| a?
b c) = 1.Remark: the function in Eq.
1 is concave in the values?t being optimized over.
We use the EM algorithm, which converges toa global optimum.Step 3: ?a?
b c, h1, h2, h3, calculate rule parameters as follows:?t(a?
b c, h2, h3| a, h1) =?t(a?
b c, h1, h2, h3| a)/?b,c,h2,h3?t(a?
b c, h1, h2, h3| a)where?t(a?
b c, h1, h2, h3| a) = p?(a?
b c | a)?
?t(h1, h2, h3| a?
b c).Output: Parameter estimates?t(a?
b c, h2, h3| a, h1) for all rules a?
b c, for all (h1, h2, h3) ?
[m]?
[m]?
[m].Figure 1: The learning algorithm for the t(a?
b c, h1, h2, h3| a) parameters of an L-PCFG.the estimates p?
in assumption 3 to have convergedto the correct underlying values.
A more detailedanalysis of the algorithm would derive samplecomplexity results, giving guarantees on the sam-ple size M required to reach a level of accuracy in the estimates, with probability at least 1 ?
?,as a function of , ?, and other relevant quantitiessuch as n, d, d?,m, ?, ?
and so on.In spite of the strength of the infinite data as-sumption, we stress the importance of this resultas a guarantee for the algorithm.
First, a guar-antee of correct parameter values in the limit ofinfinite data is typically the starting point for asample complexity result (see for example (Hsuet al, 2009; Anandkumar et al, 2012)).
Sec-ond, our sense is that a sample complexity resultcan be derived for our algorithm using standardmethods: specifically, the analysis in (Arora etal., 2012) gives one set of guarantees; the remain-ing optimization problems we solve are convexmaximum-likelihood problems, which are alsorelatively easy to analyze.
Note that several piecesof previous work on spectral methods for latent-variable models focus on algorithms that are cor-rect under the infinite data assumption.5 The Matrix Decomposition AlgorithmThis section describes the matrix decompositionalgorithm used in Step 1 of the learning algorithm.5.1 Problem SettingOur goal will be to solve the following matrix de-composition problem:Matrix Decomposition Problem (MDP) 1.
De-sign an algorithm with the following inputs, as-sumptions, and outputs:1056Inputs: Integers m, d and d?, and a matrix Q ?Rd?d?such that Qf,g=?mh=1pi(h)r(f | h)s(g |h) for some unknown parameters pi(h), r(f | h)and s(g | h) satisfying:1) pi(h) ?
0,?mh=1pi(h) = 1;2) r(f | h) ?
0,?df=1r(f | h) = 1;3) s(g | h) ?
0,?d?g=1s(g | h) = 1.Assumptions: There are values ?
> 0 and ?
>0 such that the r parameters of the model are ?-separable, and the s parameters of the model are?-separable.Outputs: Estimates p?i(h), r?
(f | h) and s?
(g | h)such that there is some permutation ?
: [m]?
[m]such that ?h, p?i(h) = pi(?
(h)), ?f, h, r?
(f |h) = r(f | ?
(h)), and ?g, h, s?
(g | h) = s(g |?
(h)).The definition of ?-separability is as follows (?-separability for s(g | h) is analogous):Definition 2 (?-separability).
The parametersr(f | h) are ?-separable if for all h ?
[m], thereis some j ?
[d] such that: 1) r(j | h) ?
?
; and 2)r(j | h?)
= 0 for h?6= h.This matrix decomposition problem has clearrelevance to problems in learning of latent-variable models, and in particular is a core step ofthe algorithm in figure 1.
When given a matrix?Qawith entries?Qaf,g=?hp(h | a)p(f | h, a)p(g |h, a), where p(.
.
.)
refers to a distribution derivedfrom an underlying L-PCFG which satisfies thepivot assumption, the method will recover the val-ues for p(h | a), p(f | h, a) and p(g | h, a) up to apermutation over the latent states.5.2 The Algorithm of Arora et al (2013)This section describes a variant of the algorithm ofArora et al (2013), which is used as a componentof our algorithm for MDP 1.
One of the proper-ties of this algorithm is that it solves the followingproblem:Matrix Decomposition Problem (MDP) 2.
De-sign an algorithm with the following inputs, as-sumptions, and outputs:Inputs: Same as matrix decomposition problem 1.Assumptions: The parameters r(f | h) of themodel are ?-separable for some value ?
> 0.Outputs: Estimates p?i(h) and r?
(f | h) such that??
: [m] ?
[m] such that ?h, p?i(h) = pi(?
(h)),?f, h, r?
(f | h) = r(f | ?
(h)).This is identical to Matrix Decomposition Prob-lem 1, but without the requirement that the valuess(g | h) are returned by the algorithm.
Thus analgorithm that solves MDP 2 in some sense solves?one half?
of MDP 1.For completeness we give a sketch of the algo-rithm that we use; it is inspired by the algorithmof Arora et al (2012), but has some important dif-ferences.
The algorithm is as follows:Step 1: Derive a function ?
: [d?]
?
Rlthatmaps each integer g ?
[d?]
to a representation?
(g) ?
Rl.
The integer l is typically much smallerthan d?, implying that the representation is of lowdimension.
Arora et al (2012) derive ?
as a ran-dom projection with a carefully chosen dimensionl.
In our experiments, we use canonical correlationanalysis (CCA) on the matrixQ to give a represen-tation ?
(g) ?
Rlwhere l = m.Step 2: For each f ?
[d], calculatevf= E[?
(g) | f ] =d?
?g=1p(g | f)?
(g)where p(g | f) = Qf,g/?gQf,g.
It follows thatvf=d?
?g=1m?h=1p(h | f)p(g | h)?
(g) =m?h=1p(h | f)whwhere wh?
Rlis equal to?d?g=1p(g | h)?
(g).Hence the vfvectors lie in the convex hull of aset of vectors w1.
.
.
wm?
Rl.
Crucially, for anypivot word f for latent state h, we have p(h | f) =1, hence vf= wh.
Thus by the pivot assump-tion, the set of points v1.
.
.
vdincludes the ver-tices of the convex hull.
Each point vjis a convexcombination of the vertices w1.
.
.
wm, where theweights in this combination are equal to p(h | j).Step 3: Use the FastAnchorWords algo-rithm of (Arora et al, 2012) to identify m vectorsvs1, vs2, .
.
.
vsm.
The FastAnchorWords algo-rithm has the guarantee that there is a permutation?
: [m]?
[m] such that vsi= w?
(i)for all i. Thisalgorithm recovers the vertices of the convex hulldescribed in step 2, using a method that greedilypicks points that are as far as possible from thesubspace spanned by previously picked points.Step 4: For each f ?
[d] solve the problemarg min?1,?2,...,?m||?h?hvsh?
vf||2subject to ?h?
0 and?h?h= 1.
We use thealgorithm of (Frank and Wolfe, 1956; Clarkson,2010) for this purpose.
Set q(h | f) = ?h.1057Return the final quantities:p?i(h) =?fp(f)q(h|f) r?
(f |h) =p(f)q(h|f)?fp(f)q(h|f)where p(f) =?gQf,g.5.3 An Algorithm for MDP 1Figure 2 shows an algorithm that solves MDP 1.In steps 1 and 2 of the algorithm, the algorithmof section 5.2 is used to recover estimates r?
(f |h) and s?
(g | h).
These distributions are equal top(f | h) and p(g | h) up to permutations ?
and?
?of the latent states respectively; unfortunatelythere is no guarantee that ?
and ?
?are the samepermutation.
Step 3 estimates parameters t(h?|h) that effectively map the permutation implied byr?
(f | h) to the permutation implied by s?
(g | h);the latter distribution is recalculated as?h??t(h?|h)s?
(g | h?
).We now state the following theorem:Theorem 2.
The algorithm in figure 2 solves Ma-trix Decomposition Problem 1.Proof: See the supplementary material.Remark: A natural alternative to the algorithmpresented would be to run Step 1 of the originalalgorithm, but to replace steps 2 and 3 with a stepthat finds s?
(g | h) values that maximize?f,gQf,glog?hr?
(h | f)s?
(g | h)This is again a convex optimization problem.
Wemay explore this algorithm in future work.6 Additional Details of the Algorithm6.1 Recovery of the pi and q ParametersThe recovery of the pi and q parameters relies onthe following additional (but benign) assumptionson the functions ?
and ?
:1) For any inside tree t such that t is a unaryrule of the form a ?
x, the function ?
is definedas ?
(t) = t.32) The set of outside tree features G contains aspecial symbol 2, and g(o) = 2 if and only if theoutside tree o is derived from a non-terminal nodeat the root of a skeletal tree.3Note that if other features on unary rules are desired,we can use multiple feature functions ?1(t) .
.
.
?K(t), where?1(t) = t for inside trees, and the functions ?2(t) .
.
.
?K(t)define other features.Inputs: As in Matrix Decomposition Problem 1.Assumptions: As in Matrix Decomposition Problem 1.Algorithm:Step 1.
Run the algorithm of section 5.2 on the matrix Qto derive estimates r?
(f | h) and p?i(h).
Note that underthe guarantees of the algorithm, there is some permutation?
such that r?
(f | h) = r(f | ?(h)).
Definer?
(h | f) =r?
(f | h)p?i(h)?hr?
(f | h)p?i(h)Step 2.
Run the algorithm of section 5.2 on the matrix Q>to derive estimates s?
(g | h).
Under the guarantees of thealgorithm, there is some permutation ?
?such that s?
(g | h) =s(g | ??(h)).
Note however that it is not necessarily the casethat ?
= ?
?.Step 3.
Find?t(h?| h) for all h, h??
[m] that maximize?f,gQf,glog?h,h?r?
(h | f)?t(h?| h)s?
(g | h?)
(3)subject to?t(h?| h) ?
0, and ?h,?h?
?t(h?| h) = 1.Remark: the function in Eq.
3 is concave in the?t parame-ters.
We use the EM algorithm to find a global optimum.Step 4.
Return the following values:?
p?i(h) for all h, as an estimate of pi(?
(h)) for somepermutation ?.?
r?
(f | h) for all f, h as an estimate of r(f | ?
(h)) forthe same permutation ?.??h?
?t(h?| h)s?
(g | h?)
as an estimate of s(f | ?
(h))for the same permutation ?.Figure 2: The algorithm for Matrix Decomposition Problem 1Under these assumptions, the algorithm in fig-ure 1 recovers estimates p?i(a, h) and q?
(a ?
x |a, h).
Simply setq?(a?
x | a, h) = r?
(f | h, a) where f = a?
xand p?i(a, h) = p?
(2, h, a)/?h,ap?
(2, h, a) wherep?
(2, h, a) = g?
(2 | h, a)p?
(h | a)p?(a).
Note thatp?
(h | a) can be derived from the matrix decompo-sition step when applied to?Qa, and p?
(a) is easilyrecovered from the training examples.6.2 Extension to Include Multiple FeaturesWe now describe an extension to allowK separatefunctions ?
(k)(t) for k = 1 .
.
.K mapping insidetrees to features, and L feature functions ?
(l)(o)for l = 1 .
.
.
L over outside trees.The algorithm in figure 1 can be extended asfollows.
First, Step 1 of the algorithm (the matrix1058decomposition step) can be extended to provideestimates r?
(k)(f(k)| h, a) and s?
(l)(g(l)| h, a).In brief, this involves running CCA on a matrixE[?
(T )(?
(O))>| A = a] where ?
and ?
are in-side and outside binary feature vectors derived di-rectly from the inside and outside features, usinga one-hot representation.
CCA results in a low-dimensional representation that can be used in thesteps described in section 5.2; the remainder of thealgorithm is the same.
In practice, the addition ofmultiple features may lead to better CCA repre-sentations.Next, we modify the objective function in Eq.
1to be the following:?i,j,k?gi,fj2,fk3p(gi, fj2, fk3| a?
b c) log ?i,j,k(gi, fj2, fk3)where?i,j,k(gi, fj2, fk3)=?h1,h2,h3(?t(h1, h2, h3| a?
b c)?s?i(gi| h1, a)r?j(fj2| h2, b)r?k(fk3| h3, c))Thus the new objective function consists of a sumofL?M2terms, each corresponding to a differentcombination of inside and outside features.
Thefunction remains concave.6.3 Use as an Initializer for EMThe learning algorithm for L-PCFGs can be usedas an initializer for the EM algorithm for L-PCFGs.
Two-step estimation methods such asthese are well known in statistics; there are guar-antees for example that if the first estimator is con-sistent, and the second step finds the closest localmaxima of the likelihood function, then the result-ing estimator is both consistent and efficient (interms of number of samples required).
See forexample page 453 or Theorem 4.3 (page 454) of(Lehmann and Casella, 1998).7 Experiments on ParsingThis section describes parsing experiments usingthe learning algorithm for L-PCFGs.
We use thePenn WSJ treebank (Marcus et al, 1993) for ourexperiments.
Sections 2?21 were used as trainingdata, and sections 0 and 22 were used as develop-ment data.
Section 23 was used as the test set.The experimental setup is the same as describedby Cohen et al (2013).
The trees are bina-rized (Petrov et al, 2006) and for the EM algo-rithm we use the initialization method describedsec.
22 sec.
23m 8 16 24 32EM86.694088.323088.353088.562087.76Spectral 85.60 87.77 88.53 88.82 88.05Pivot 83.56 86.00 86.87 86.40 85.83Pivot+EM86.83288.14688.64288.55288.03Table 1: Results on the development data (section 22) andtest data (section 23) for various learning algorithms for L-PCFGs.
For EM and pivot+EM experiments, the second linedenotes the number of iterations required to reach the givenoptimal performance on development data.
Results for sec-tion 23 are used with the best model for section 22 in the cor-responding row.
The results for EM and spectral are reportedfrom Cohen et al (2013).in Matsuzaki et al (2005).
For the pivot algo-rithm we use multiple features ?1(t) .
.
.
?K(t) and?1(o) .
.
.
?L(o) over inside and outside trees, us-ing the features described by Cohen et al (2013).Table 1 gives the F1 accuracy on the develop-ment and test sets for the following methods:EM: The EM algorithm as used by Matsuzaki etal.
(2005) and Petrov et al (2006).Spectral: The spectral algorithm of Cohen et al(2012) and Cohen et al (2013).Pivot: The algorithm described in this paper.Pivot+EM: The algorithm described in this pa-per, followed by 1 or more iterations of theEM algorithm with parameters initialized by thepivot algorithm.
(See section 6.3.
)For the EM and Pivot+EM algorithms, we givethe number of iterations of EM required to reachoptimal performance on the development data.The results show that the EM, Spectral, andPivot+EM algorithms all perform at a very similarlevel of accuracy.
The Pivot+EM results show thatvery few EM iterations?just 2 iterations in mostconditions?are required to reach optimal perfor-mance when the Pivot model is used as an ini-tializer for EM.
The Pivot results lag behind thePivot+EM results by around 2-3%, but they areclose enough to optimality to require very few EMiterations when used as an initializer.8 Experiments on the Saul and Pereira(1997) Model for Language ModelingWe now describe a second set of experiments, onthe Saul and Pereira (1997) model for languagemodeling.
Define V to be the set of words in thevocabulary.
For any w1, w2?
V , the Saul andPereira (1997) model then defines p(w2| w1) =?mh=1r(h | w1)s(w2| h) where r(h | w1) and1059Brown NYTm 2 4 8 16 32 128 256 test 2 4 8 16 32 128 256 testEM73714599144881946812430103889365836492636733395624242033361382843526532267bi-KN +int.
408 415 271 279tri-KN+int.
386 394 150 158pivot 852 718 605 559 537 426 597 560 1227 1264 896 717 738 782 886 715pivot+EM758258235022425137413101327135789820754145531344115394102791929212281Table 2: Language model perplexity with the Brown corpus and the Gigaword corpus (New York Times portion) for the secondhalf of the development set, and the test set.
With EM and Pivot+EM, the number of iterations for EM to reach convergence isgiven below the perplexity.
The best result for each column (for each m value) is in bold.
The ?test?
column gives perplexityresults on the test set.
Each perplexity calculation on the test set is done using the best model on the development set.
bi-KN+intand tri-KN+int are bigram and trigram Kneser-Ney interpolated models (Kneser and Ney, 1995), using the SRILM toolkit.s(w2| h) are parameters of the approach.
Theconventional approach to estimation of the param-eters r(h | w1) and s(w2| h) from a corpus isto use the EM algorithm.
In this section we com-pare the EM algorithm to a pivot-based method.It is straightforward to represent this model as anL-PCFG, and hence to use our implementation forestimation.In this special case, the L-PCFG learning al-gorithm is equivalent to a simple algorithm, withthe following steps: 1) define the matrix Qwith entries Qw1,w2= count(w1, w2)/N wherecount(w1, w2) is the number of times that bi-gram (w1, w2) is seen in the data, and N =?w1,w2count(w1, w2).
Run the algorithm of sec-tion 5.2 on Q to recover estimates s?
(w2| h); 2)estimate r?
(h | w1) using the EM algorithm to op-timize the function?w1,w2Qw1,w2log?hr?
(h |w1)s?
(w2| h) with respect to the r?
parameters;this function is concave in these parameters.We performed the language modeling experi-ments for a number of reasons.
First, because inthis case the L-PCFG algorithm reduces to a sim-ple algorithm, it allows us to evaluate the coreideas in the method very directly.
Second, it al-lows us to test the pivot method on the very largedatasets that are available for language modeling.We use two corpora for our experiments.
Thefirst is the Brown corpus, as used by Bengio etal.
(2006) in language modeling experiments.
Fol-lowing Bengio et al (2006), we use the first 800Kwords for training (and replace all words that ap-pear once with an UNK token), the next 200Kwords for development, and the remaining data(165,171 tokens) as a test set.
The size of thevocabulary is 24,488 words.
The second corpuswe use is the New York Times portion of the Gi-gaword corpus.
Here, the training set consists of1.31 billion tokens.
We use 159 million tokens fordevelopment set and 156 million tokens for test.All words that appeared less than 20 times in thetraining set were replaced with the UNK token.The size of the vocabulary is 235,223 words.
Un-known words in test data are ignored when calcu-lating perplexity (this is the standard set-up in theSRILM toolkit).In our experiments we use the first half of eachdevelopment set to optimize the number of itera-tions of the EM or Pivot+EM algorithms.
As be-fore, Pivot+EM uses 1 or more EM steps with pa-rameter initialization from the Pivot method.Table 2 gives perplexity results for the differ-ent algorithms.
As in the parsing experiments, thePivot method alone performs worse than EM, butthe Pivot+EM method gives results that are com-petitive with EM.
The Pivot+EM method requiresfewer iterations of EM than the EM algorithm.On the Brown corpus the difference is quite dra-matic, with only 1 or 2 iterations required, as op-posed to 10 or more for EM.
For the NYT cor-pus the Pivot+EM method requires more iterations(around 10 or 20), but still requires significantlyfewer iterations than the EM algorithm.On the Gigaword corpus, with m = 256, EMtakes 12h57m (32 iterations at 24m18s per itera-tion) compared to 1h50m for the Pivot method.
OnBrown, EM takes 1m47s (8 iterations) comparedto 5m44s for the Pivot method.
Both the EM andpivot algorithm implementations were highly op-timized, and written in Matlab.
Results at othervalues of m are similar.
From these results thePivot method appears to become more competitivespeed-wise as the data size increases (the Giga-word corpus is more than 1,300 times larger thanthe Brown corpus).9 ConclusionWe have described a new algorithm for parameterestimation in L-PCFGs.
The algorithm is provablycorrect, and performs well in practice when usedin conjunction with EM.1060ReferencesA.
Anandkumar, R. Ge, D. Hsu, S. M. Kakade, andM.
Telgarsky.
2012.
Tensor decompositions forlearning latent-variable models.
arXiv:1210.7559.S.
Arora, R. Ge, and A. Moitra.
2012.
Learningtopic models?going beyond SVD.
In Proceedingsof FOCS.S.
Arora, R. Ge, Y. Halpern, D. M. Mimno, A. Moitra,D.
Sontag, Y. Wu, and M. Zhu.
2013.
A practicalalgorithm for topic modeling with provable guaran-tees.
In Proceedings of ICML.R.
Bailly, A. Habrar, and F. Denis.
2010.
A spectralapproach for probabilistic grammatical inference ontrees.
In Proceedings of ALT.B.
Balle, A. Quattoni, and X. Carreras.
2011.
A spec-tral learning algorithm for finite state transducers.
InProceedings of ECML.Y.
Bengio, H. Schwenk, J.-S. Sen?ecal, F. Morin, andJ.-L. Gauvain.
2006.
Neural probabilistic languagemodels.
In Innovations in Machine Learning, pages137?186.
Springer.K.
L. Clarkson.
2010.
Coresets, sparse greedy ap-proximation, and the Frank-Wolfe algorithm.
ACMTransactions on Algorithms (TALG), 6(4):63.S.
B. Cohen, K. Stratos, M. Collins, D. F. Foster, andL.
Ungar.
2012.
Spectral learning of latent-variablePCFGs.
In Proceedings of ACL.S.
B. Cohen, K. Stratos, M. Collins, D. P. Foster, andL.
Ungar.
2013.
Experiments with spectral learn-ing of latent-variable PCFGs.
In Proceedings ofNAACL.A.
Dempster, N. Laird, and D. Rubin.
1977.
Maxi-mum likelihood estimation from incomplete data viathe EM algorithm.
Journal of the Royal StatisticalSociety B, 39:1?38.P.
Dhillon, J. Rodu, M. Collins, D. P. Foster, and L. H.Ungar.
2012.
Spectral dependency parsing with la-tent variables.
In Proceedings of EMNLP.M.
Frank and P. Wolfe.
1956.
An algorithm forquadratic programming.
Naval research logisticsquarterly, 3(1-2):95?110.H.
Hotelling.
1936.
Relations between two sets ofvariates.
Biometrika, 28(3/4):321?377.D.
Hsu, S. M. Kakade, and T. Zhang.
2009.
A spectralalgorithm for learning hidden Markov models.
InProceedings of COLT.R.
Kneser and H. Ney.
1995.
Improved backing-offfor m-gram language modeling.
In Proceedings ofICASSP.E.
L. Lehmann and G. Casella.
1998.
Theory of PointEstimation (Second edition).
Springer.M.
P. Marcus, B. Santorini, and M. A. Marcinkiewicz.1993.
Building a large annotated corpus of En-glish: The Penn treebank.
Computational Linguis-tics, 19:313?330.T.
Matsuzaki, Y. Miyao, and J. Tsujii.
2005.
Proba-bilistic CFG with latent annotations.
In Proceedingsof ACL.A.
Parikh, L. Song, and E. P. Xing.
2011.
A spectralalgorithm for latent tree graphical models.
In Pro-ceedings of ICML.S.
Petrov, L. Barrett, R. Thibaux, and D. Klein.
2006.Learning accurate, compact, and interpretable treeannotation.
In Proceedings of COLING-ACL.L.
Saul and F. Pereira.
1997.
Aggregate and mixed-order markov models for statistical language pro-cessing.
In Proceedings of EMNLP.S.
Siddiqi, B.
Boots, and G. Gordon.
2010.
Reduced-rank hidden markov models.
Journal of MachineLearning Research, 9:741?748.1061
