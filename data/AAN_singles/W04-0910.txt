Paraphrastic GrammarsClaire GardentCNRS-LORIA, NancyFranceClaire.Gardent@loria.frMarilisa AmoiaComputational LinguisticsUniversity of SaarbrueckenGermanyamoia@coli.uni-sb.deEvelyne JacqueyCNRS-ATILF, NancyFranceEvelyne.Jacquey@atilf.frAbstractArguably, grammars which associate natural lan-guage expressions not only with a syntactic butalso with a semantic representation, should do so ina way that capture paraphrasing relations betweensentences whose core semantics are equivalent.
Yetexisting semantic grammars fail to do so.
In this pa-per, we describe an ongoing project whose aim isthe production of a ?paraphrastic grammar?
that is,a grammar which associates paraphrases with iden-tical semantic representations.
We begin by propos-ing a typology of paraphrases.
We then show howthis typology can be used to simultaneously guidethe development of a grammar and of a testsuite de-signed to support the evaluation of this grammar.1 IntroductionA salient feature of natural language is that it allowsparaphrases that is, it allows different verbalisationsof the same content.
Thus although the various ver-balisations in (1) may have different pragmatic orcommunicative values (with respect for instance totopicalisation, presuppositions or focus/ground par-titioning), they all share a core semantic content, thecontent approximated by a traditional montagoviancompositional semantics.
(1) a.
La croisie`re cou?te cher.Lit.
the cruse is expensiveb.
Le cou?t de la croisie`re est e?leve?.Lit.
the cost of the cruse is highc.
La croisie`re a un cou?t e?leve?Lit.
the cruse has a high costLinguists have long noticed the pervasiveness ofparaphrases in natural language and attempted tocaracterise it.
Thus for instance Chomsky?s ?trans-formations?
capture the relation between one coremeaning (a deep structure in Chomsky?s terms) andseveral surface realisations (for instance, betweenthe passive and the active form of the same sen-tence) while (Mel?c?uk, 1988) presents sixty para-phrastic rules designed to account for paraphrasticrelations between sentences.More recently, work in information extraction(IE) and question answering (QA) has triggered arenewed research interest in paraphrases as IE andQA systems typically need to be able to recognisevarious verbalisations of the content.
Because of thelarge, open domain corpora these systems deal with,coverage and robustness are key issues and much onthe work on paraphrases in that domain is based onautomatic learning techniques.
For instance, (Linand Pantel, 2001) acquire two-argument templates(inference rules) from corpora using an extendedversion of the distributional analysis in which pathsin dependency trees that have similar arguments aretaken to be close in meaning.
Similarly, (Barzi-lay and Lee, 2003) and (Shinyanma et al, 2002)learn sentence level paraphrase templates from acorpus of news articles stemming from differentnews source.
And (Glickman and Dagan, 2003) useclustering and similarity measures to identify sim-ilar contexts in a single corpus and extract verbalparaphrases from these contexts.Such machine learning approaches have knownpros and cons.
On the one hand, they produce largescale resources at little man labour cost.
On theother hand, the degree of descriptive abstraction of-fered by the list of inference or paraphrase rules theyoutput is low.We chose to investigate an alternative research di-rection by aiming to develop a ?paraphrastic gram-mar?
that is, a grammar which captures the para-phrastic relations between linguistic structures1 .Based on a computational grammar that associatesnatural language expressions with both a syntacticand a semantic representation, a paraphrastic gram-1As we shall briefly discuss in section 4, the grammar is de-veloped with the help of a meta-grammar (Candito, 1999) thusensuring an additional level of abstraction.
The metagrammaris an abstract specification of the linguistic properties (phrasestructure, valency, realisation of grammatical functions etc.
)encoded in the grammar basic units.
This specification is thencompiled to automatically produce a specific grammar.mar is a grammar that moreover associates para-phrases with the same semantic representation.
Thatis, contrary to machine learning based approacheswhich relate paraphrases via sentence patterns, theparaphrastic grammar approach relates paraphrasesvia a common semantic representation.
In this way,the paraphrastic approach provides an interesting al-ternative basis for generation from conceptual rep-resentations and for the inference-based, deep se-mantic processing of the kind that is ultimatelyneeded for high quality question answering.Specifically, we aim at developing a paraphras-tic grammar for French, based on the Tree Adjoin-ing Grammar (TAG) developed for this language byAnne Abeille?
(Abeille?, 2002).The paper is structured as follows.
We startby proposing a typology of the paraphrastic meansmade available by natural language.
We then showhow this typology can be used to develop a testsuitefor developing and evaluating a paraphrastic gram-mar.
Finally, we highlight some of the issues arisingwhen developing a paraphrastic grammar.2 Classifying paraphrasesA paraphrastic grammar should capture the vari-ous means made available by natural language tosupport paraphrasing.
But what are those means?We distinguish here between three main classesnamely, parallel, shuffling and definitional para-phrastic means.Parallel paraphrastic means.
A parallel para-phrase can hold either between two non predica-tive lexical units (words or multi word expressions)modulo negation or between two predicative unitsof identical arity.
If it holds between predicativeunits, the mapping linking grammatical functions(subject, objects, etc.)
and thematic roles (agent,theme, etc.)
must be the same.
Depending onwhether or not negation is involved, semantic equiv-alence will futhermore obtain either through syn-onymy or through antonymy.As illustrated in Figure 1, synonymy can be fur-ther divided in a number of cases depending on var-ious morphological and syntactic criteria.
The clas-sification criteria used involve :?
Syntactic category: Do the synonyms have thesame syntactic category??
Morphological relatedness: Do the synonymscontain words that are morphologically re-lated??
Form: Are the synonyms simple lexical unitsor multi word expressions?As for antonymy, we distinguish between transand intracategorial antonymy:(2) Jean est lent/Jean n?est pas rapide.Jean is slow/Jean is not fast.lent/rapide, intracategorialJean a cesser de fumer/Jean ne fume plus.Jean has stopped smoking/Jean smokes nomore.cesse de/ne .
.
.
plus, transcategorialShuffling paraphrastic means.
When a seman-tic equivalence holds between predicative units withdistinct grammatical functions/thematic role link-ing, we speak of shuffling paraphrases.
Such para-phrases can be realised either by means of argumentpreserving alternations (in the sense of Beth Levin,cf.
(4)) or using a converse construction (cf.
3)2.
(3) a Jean donne un livre a` Marie.Jean gives a book to Marie.Marie rec?oit un livre de JeanJean receives a book from Marie.b Jean est le parent de Marie.Jean is the parent of Marie.Marie est l?enfant de Jean.Marie is the child of Jean.
(4) a. Cette cle?
ouvre le coffre fortThis key opens the safe.Le coffre fort s?ouvre avec cette cle?The safe opens with this key.b.
Jean mange une pommeJean eats an apple.une pomme est mange?e par JeanAn apple is eaten by Jean.Il a e?te?
mange?
une pomme par Jean.There has been an apple eaten by Jean.c.
L?eau remplit la crucheThe water fills the jug .La cruche se remplit d?eauThe jug fills with water.On remplit la cruche d?eauOne fills the jug with water.d.
Le laboratoire fusionne avec l?entrepriseThe laboratory merges with the firm.le laboratoire et l?entreprise fusionnentThe laboratory and the firm merge.e.
Jean frappe le mur avec un batonJean hit the wall with a stick.2Obviously, the english translations do not reflect the ac-ceptability of the french equivalent.Same synt.
Same morph.
Form Examplecategories familyyes no word/word policier, flicyes yes word/mwe conseiller, donner conseilyes no word/mwe s?exprimer sur, donner son avis suryes no mwe/mwe donner carte blanche a`, laisser tout pouvoirno yes word/word construire, constructionno no word/word candidature a`, briguerFigure 1: SynonymyJean frappe le baton sur le mur.Jean hit the stick on the wall.f.
Je fournis des livres a` JeanI provide books to Jean.Je fournis Jean en livreI provide Jean with books.Definitional paraphrastic means.
Third, we call?definitional paraphrases?
semantic equivalencesthat hold between a lexical unit and a phrase con-sisting of more than one lexical unit.
The phrasein this case, defines the meaning of the lexical unit.Since definitions are notoriously difficult to decideupon, we restrict ourselves here to such definitionsas can be given by derivational morphology that is,definitions based on a word that is morphologicallylinked to the definiendum (cf.
5).
(5) a.
Le conducteur de la BMW est chauveThe driver of the BMW is bald.La personne qui conduit la BMW estchauveThe person who drives the BMW is bald.b.
Cet outil est parame?trableThis tool is parameterisable.Cet outil peut e?tre parame?tre?This tool can be parameterised.3 Developing a paraphrase testsuiteBased on the above typology, we can systematicallyconstruct a testsuite for developing and evaluatinga paraphrastic grammar.
Indeed, when developinga grammar, it is necessary to have some means ofassessing both the coverage of the grammar (doesit generate all the sentences of the described lan-guage?)
and its degree of overgeneration (does itgenerate only the sentences of the described lan-guage?)
While corpus driven efforts along the PAR-SEVAL lines (Black et al, 1991) are good at givingsome measure of a grammar coverage, they are notsuitable for finer grained analysis and in particular,for progress evaluation, regression testing and com-parative report generation.
Another known methodconsists in developing and using a test suite that is,a set of negative and positive items against whichthe grammar can be systematically tested.
For en-glish, there is for instance the 15 year old Hewlett-Packard test suite, a simple text file listing test sen-tences and grouping them according to linguisticsphenomena (Flickinger et al, 1987); and more re-cently, the much more sophisticated TSNLP (TestSuite for Natural Language Processing) which in-cludes some 9500 test items for English, French andGerman, each of them being annotated with syntac-tic and application related information (Oepen andFlickinger, 1998).Yet because they do not take into account the se-mantic dimension, none of these tools are adequatefor evaluating the paraphrastic power of a gram-mar.
To remedy this, we propose to develop a para-phrase test suite based on the paraphrase typologydescribed in the previous section.
In such a testsuite,test items pair a semantic representation with a setof paraphrases verbalising this semantics.
The con-struction and annotation of the paraphrases reflectsthe paraphrase typology.
In a first phase, we concen-trate on simple, non-recursive predicate/argumentstructure.
Given such a structure, the constructionand annotation of a test item proceeds as follows.First, a ?canonical verbalisation?
is produced inwhich the predicate is realised by the ?canonicalverb?
for the given concept3 and the arguments bythe canonical nouns.Next variants are produced by systematically try-ing to create parallel, shuffling and definitional para-phrases.
Each of the variant is furthermore anno-tated with labels caracterising the type of paraphras-ing involved.
Here is an example.
Suppose the inputsemantics is:apply(e), agent(e,jean), theme(e,job), failure(e)for which the canonical verbalisation is:(6) Jean a candidate?
sans succe`s sur le posteJean has applied in vain for the job.3Like in a thesaurus, we assume that amongst a set of syn-onyms, one lexical unit is ?canonical?
and the others not.
Thecanonical unit is sometimes called a descriptor.The parallel synonyms4 that can be used are thefollowing:5candidater candidature +pred-Nposer sa +pred-vsupVcandidaturebriguer +pred-Vsans succe`s e?chouer +mod-Ve?tre sans succe`s +mod-beAdvne pas e?tre retenu +mod-VantonFor shuffling synonymy, two alternations areavailable: the active/passive alternation for ?poser?and the active/locative one for ?e?chouer?.
There isno converse construction.
Neither is there any defi-nition given by derivational morphology for any ofthe terms occurring in the canonical verbalisation.Based on these facts, the following variants and an-notations can be constructed.
(7) a. Jean a brigue?
le poste sans succe`sJean has asked for the job in vain.+pred-Vsynb.
Jean a pose?
sa candidature sur le poste sanssucce`sJean has submitted his application for thejob in vain.+pred-vsupNc.
La candidature pose?e par Jean sur le postea e?te?
sans succe`sThe application submitted by Jean for thejob was in vain.+pred-partAdj, +mod-beAdvd.
La candidature pose?e par Jean sur le postea e?choue?The application submitted by Jean for thejob failed.+pred-partAdj, +mod-Ve.
La candidature de Jean sur le poste a e?te?sans succe`sJean?s application for the job was in vain.+pred-N, +mod-beAdvf.
La candidature de Jean sur le poste n?a pase?te?
retenue4As has been abundantly argued by linguists, real synonymsare extremely rare.
By synonyms, we in fact refer here to thenotion of quasi-synonyms used for instance in WordNet that is,words that are interchangeable in a restricted set of contexts.5The labels are the ones used for annotation.
They carac-terise variations with respect to the canonical realisation.
Forinstance, +pref-N indicates that the main predicate (realised bya verb in the canonical verbalisation) is realised as a noun.Jean?s application for the job was not suc-cessful.+pred-N, +mod-Vantong.
La candidature de Jean sur le poste ae?choue?Jean?s application for the job failed.+pred-N, +mod-Vh.
Jean a e?choue?
dans sa candidature sur leposte.Jean failed in his application for the job.+pred-N, +mod-V-altLocThus the typology of paraphrastic means helpguide the construction of the various paraphrasescontained in a single item.
There remains the ques-tion of how to choose the particular items of thetestsuite.
In other words: which semantic repre-sentations should we use to populate the test suiteand on the basis of which criteria?
The basic aimhere is to cover the various types of possible seman-tic combinations and the constraints they are sub-ject to at the syntactic (realisation) level.
If, as BethLevin argues, syntax is a reflex of semantic proper-ties, then different semantic contents should be sub-ject to varying syntactic constraints and the test suiteought to cover these various types of interactions.Accordingly test items are constructed whose mainpredicate vary along the following dimensions :(1) WordNet Verb Family; (2) Aspect; (3) Arite?That is, items are constructed for each word-Net family (the french WordNet counts roughly 170such families).
Within a given family, we attemptto find examples with distinct aspectual categories(state, accomplishment and process).
Finally, givena WN family and an aspectual category, items willvary with respect to the arity of the main predicateand the types of their arguments e.g., predicates ofarity one (run, cost, sleep), of arity two with nonpropositional arguments (eat, hit, dug), of arity twowith a propositional argument (say, promise etc.
),etc.4 A paraphrastic grammar?Semantic grammars?
already exist which describenot only the syntax but also the semantics of nat-ural language.
Thus for instance, (Copestake andFlickinger, 2000; Copestake et al, 2001) describesa Head Driven Phrase Structure Grammar (HPSG)which supports the parallel construction of a phrasestructure (or derived) tree and of a semantic repre-sentation and (Dalrymple, 1999) show how to equipLexical Functional grammar (LFG) with a glue se-mantics.These grammars are both efficient and large scalein that they cover an important fragment of the nat-ural language they describe and can be processed byparsers and generators in almost real time.
For in-stance, the LFG grammar parses sentences from theWall Street Journal and the ERG HPSG grammarwill produce semantic representations for about 83per cent of the utterances in a corpus of some 10000 utterances varying in length between one andthirty words.
Parsing times vary between a few msfor short sentences and several tens of seconds forlonger ones.Nonetheless, from a semantics viewpoint, thesegrammars fail to yield a clear account of the para-phrastic relation.
Here is a simple example illustrat-ing this shortcoming.
Suppose we parse the follow-ing paraphrases where a lexical definition (driver ?person who drives) is involved:(8) a.
The person who drives the car is mad.b.
The driver of the car is mad.When given these sentences, the LKB systembased on the ERG HPSG grammar returns semanticrepresentations which can be sketched as follows6:(9) a. the(x, person(x) ?
the(y, car(y) ?drive(e,x,y) ?
mad(x)))a. the(y, car(y) ?
the(x, driver(x,y) ?
of(x,y))?
mad(x))In other words, the grammar associates withthese paraphrases semantic representations whichare very different.
It could be argued of coursethat although these representations are syntacticallydistinct, they can be inferred, given the appropri-ate knowledge, to be semantically equivalent.
Buta solution that avoids placing such extra burden onthe inferencing component is obviously better.
Inshort, one important shortcoming of existing largescale semantic grammars is that they do not assignsemantically equivalent sentences, the same seman-tic representation.By contrast, we propose to develop a grammarwhich whereever possible assigns identical seman-tic representations to paraphrases and whose devel-6These semantic representations have been simplified forbetter readibility.
The real representations output by the LKBare the following:prpstn(def(x,person(x)?prpstn(def(y,car(y),drive(e1,v1,x,y,v2),v3)), mad(e2,x,v4),v5)prpstn(def(x,person(x)?prpstn(def(y,car(y),drive(e1,v1,x,y,v2),v3)), mad(e2,x,v4),v5)prpstn(def(y,car(y)?prpstn(def(x, driver(x,y) ?
of(e1,x,y,v1),mad(e2,x,v2,v3)))))opment is based both on semantic and syntactic con-siderations.4.1 Linguistic frameworkOur grammar is couched within the Feature-BasedTree Adjoining grammar (FTAG) formalism.
AnFTAG consists of a set of (auxiliary or initial) ele-mentary trees and two tree composition operations:substitution and adjunction.
Substitution is the stan-dard tree operation used in phrase structure gram-mars while adjunction is an operation which insertsan auxiliary tree into a derived tree.
To account forthe effect of these insertions, two feature structures(called top and bottom) are associated with eachtree node in FTAG.
The top feature structure en-codes information that needs to be percolated up thetree should an adjunction take place.
In contrast, thebottom feature structure encodes information thatremains local to the node at which adjunction takesplace.The language chosen for semantic representa-tion is a flat semantics along the line of (Bos,1995; Copestake et al, 1999; Copestake et al,2001).
However because we are here focusing onparaphrases rather than fine grained semantic dis-tinctions, the underspecification and the descrip-tion of the scope relations permitted by these se-mantics will here be largely ignored and flat se-mantics will be principally used as a convenientway of describing predicate/arguments and modi-fiers/modified relationships.
Thus the semantic rep-resentations we assume are simply set of literals ofthe form P n(x1, .
.
.
, xn) where P n is a predicateof arity n and xi is either a constant or a unifica-tion variable whose value will be instantiated duringprocessing.Semantic construction proceeds from the derivedtree (Gardent and Kallmeyer, 2003) rather than ?as is more common in TAG ?
from the derivationtree.
This is done by associating each elementarytree with a semantic representation and by deco-rating relevant tree nodes with unification variablesand constants occuring in associated semantic rep-resentation.
The association between tree nodes andunification variables encodes the syntax/semanticsinterface ?
it specifies which node in the tree pro-vides the value for which variable in the final se-mantic representation.As trees combine during derivation, (i) variablesare unified ?
both in the tree and in the associatedsemantic representation ?
and (ii) the semantics ofthe derived tree is constructed from the conjunctionof the semantics of the combined trees.
A simpleexample will illustrate this.NPjJohnname(j,john)SNP?x1 VPV NP?x2 NPmloves Marylove(x1,x2) name(m,mary)Figure 2: ?John loves Mary?Suppose the elementary trees for ?John?, ?loves?and ?Mary?
are as given in Fig.
2 where a downar-row (?)
indicates a substitution node and Cx/Cx ab-breviate a node with category C and a top/bottomfeature structure including the feature-value pair {index : x}.
On substitution, the root node of the treebeing substituted in is unified with the node at whichsubstitution takes place.
Further, when derivationends, the top and bottom feature structures of eachnode in the derived tree are unified.
Thus in thiscase, x1 is unified with j and x2 with m. Hence, theresulting semantics is:love(j, m), name(j, john), name(m, mary)4.2 The signature of the semanticrepresentation languageLet us now come back to the paraphrases given inexample 1.
To produce an identical semantic rep-resentation of these three sentences, we first need toensure that synonyms be assigned the same concept.That is, we need to fix a concept inventory and touse this inventory in a consistent way in particular,by assigning synonyms the same concept.For non predicative units, we use WordNet synsetnumbers or when working within a restricted do-main with a well defined thesaurus, the descriptorsof that thesaurus.To represent the semantics of predicative units,we use FrameNet inventory of frames and frame el-ements (C.Johnson et al, 2002).
FrameNet is an on-line lexical resource for English based on the prin-ciples of Frame Semantics.
In this approach, a wordevokes a frame i.e., a simple or a complex event, andeach frame is associated with a number of frame el-ements that is, a number of participants fulfilling agiven role in the frame.
Finally each frame is as-sociated with a set of target words, the words thatevoke that frame.Thus FrameNet associates synonyms with anidentical concept namely, the frame evoked by thosesynonyms.
We make use of this feature and insteadof choosing our own semantic predicates and re-lations, draw on FrameNet frames and frame ele-ments.
For instance, the paraphrases in example 1are taken to evoke the FrameNet COMMERCE frameand to instantiate two of its frame elements namely,GOODS and MONEY.
The semantic representationthey will be assigned will therefore be the follow-ing:commerce(e,g,m), cruise(g), goods(e,g), high(m),money(e,m)4.3 Capturing paraphrastic relationsGiven the basic signature provided by FrameNet(and any extension of it that will prove necessaryto account for the data), the grammar must thenspecify a compositional semantics which will de-rive identical representations for the types of para-phrases captured by our typology.
In essence, thisimplies assigning the same semantic representationsto synonyms, converses and alternations.
Con-cretely, this involves two different subtasks : first,a modeling of the synonymic relation between syn-tactically divergent constructs (e.g., between a pred-icative noun, a support verb construction and a verb)and second, the identification of the synonymic sets(which are the words and multi word expressionsthat stand in a parallel, shuffling or definitional para-phrastic relation?
).Modeling intercategorial synonymic links.
Afirst investigation of Anne Abeille?
?s TAG for Frenchsuggests that modeling the synonymic relationsacross syntactic constructs is reasonably straightfor-ward.
For instance, as Figures 3, 4 and 5 show, theFTAG trees assigned on syntactic grounds by AnneAbeille?
FTAG to predicative nouns, support verbconstructions and transitive verbs can be equipedwith a flat semantics in such a way as to assignthe three sentences in 1 a unique semantic rep-resentation namely the one given above.
Gener-ally, the problem is not so much to state the cor-respondances between synonymic but syntacticallydifferent constructs as to do this in a general waywhile not overgeneralising.
To address this prob-lem, we are currently working on developing ametagrammar in the sense of (Candito, 1999).
Thismetagrammar allows us to factorise both syntac-tic and semantic information.
Syntactic informa-tion is factorised in the usual way.
For instance,there will be a class NOVN1 which groups togetherall the initial trees representing the possible syntac-tic configurations in which a transitive verb withtwo nominal arguments can occur.
But addition-nally there will be semantic classes such as, ?bi-nary predicate of semantic type X?
which will beassociated with the relevant syntactic classes for in-stance, NOVN1 (the class of transitive verbs withnominal arguments), BINARY NPRED (the class ofbinary predicative nouns), NOVSUPNN1 , the classof support verb constructions taking two nominalarguments.
By further associating semantic units(e.g., ?cost?)
with the appropriate semantic classes(e.g., ?binary predicate of semantic type X?
), wecan in this way capture both intra and intercategorialparaphrasing links in a general way.Constructing paraphrastic sets.
Depending onthe type of paraphrastic means involved, construct-ing a paraphrastic set (the set of all lexical items re-lated by a paraphrastic link be it parallel, shufflingor definitional) is more or less easy as resources forthat specific means may or may not be readily avail-able.Cases of intracategorial synonymy are relativelystraigthtforward as several electronic synonym dic-tionnaries for french are available (Ploux, 1997).Multi word expressions however remain a problemas they are often not or only partially included insuch dictionnaries.
For these or for a specific do-main, basic synonymic dictionaries can be comple-mented using learning methods based on distribu-tional similarity (Pereira et al, 1993; Lin, 1998).techniques.For intercategorial synonymy involving a deriva-tional morphology link, some resources are avail-able which however are only partial in that they onlystore morphological families that is, sets of itemsthat are morphologically related.
Lexical semanticsinformation still need to be included.Intercategorial synonymy not involving a deriva-tional morphology link has been little studied andresources are lacking.
However as for other typesof synonymy, distributional analysis and clusteringtechniques can be used to develop such resources.For shuffling paraphrases, french alternations arepartially described in (Saint-Dizier, 1999) and a re-source is available which describes alternation andthe mapping verbs/alternations for roughly 1 700verbs.
For complementing this database and forconverse constructions, the LADL tables (Gross,1975) can furthermore be resorted to, which listdetailed syntactico-semantic descriptions for 5 000verbs and 25 000 verbal expressions.
In particu-lar, (Gross, 1989) lists the converses of some 3 500predicative nouns.SGNG ?
V GAdvM ?couteGNX S:Commerce GAdvYD NX ?
(S,G):goods cherla (S,M):money Y:HighNXcroisiereX:CruiseFigure 3: La croisie`re cou?te cherSGNG ?
VSup?
GNa D?
NGMGNXcoutD NX ?
D S:Commercela un (S,M):moneyNX (S,G):goodscroisiere NX:Cruise ?
NY AdjeleveY:HighFigure 4: La croisie`re a un cou?t e?leve?5 ConclusionBesides the development and evaluation of a coreparaphrastic testsuite and grammar for French, weplan to investigate two main issues.
First, how pre-cisely should a metagrammar be structured to bestdescribe a paraphrastic grammar?
And second: isit possible to extract from the kind of inferencerules automatically derived in machine learning ap-proach, information that can be used to specify thismetagrammar?6 Acknowledgments.This paper is based upon work suppported in part bythe project ?Des connaissances a` leurs re?alisation enlangue?
within the CNRS funded TCAN program.SGNY ?
Cop GAdjY ?GNY est eleveD NY ?
Y:HighleNMN GPcout P?
GNG ?S:Commerce(S,M):money P GNX(S,G):goods de D NXla croisiereX:CruiseFigure 5: Le cou?t de la croisie`re est e?leve?ReferencesA.
Abeille?.
2002.
Une Grammaire Electronique duFranais.
CNRS Editions.R.
Barzilay and L. Lee.
2003.
Learning toparaphrase: an unsupervised approahc usingmutliple-sequence alignment.
In Proceedings ofNAACL-HLT.A.
Black, S. Abney, D. Flickinger, C. Gdaniec,R.
Grishman, P. Harrison, D. Hindel, R. INgria,F.
Jelinek, F. Klaavans, M. Liberman, M. Mar-cus, S. Roukos, B. Santorini, and T. Strzalkowski.1991.
A procedure for quantitatively comparingthe syntactic coverage of english grammars.
InProceedings of teh 4th DARPA Speech and Natu-ral Language Workshop.J.
Bos.
1995.
Predicate logic unplugged.
In PaulDekker and Martin Stokhof, editors, Proceedingsof the 10th Amsterdam Colloquium, pages 133?142.M.H Candito.
1999.
Un outil multilingue de gener-ation de ltag : application au francais et a l?italien.TAL, 40(1).C.Johnson, C. Fillmore, M. Petruckand C. Baker,M.
Ellsworth, and J. Ruppenhofer.
2002.Framenet: Theory and practice.
Technical report,Berkeley.Ann Copestake and Dan Flickinger.
2000.
An opensource grammar development environment andbroad-coverage English grammar using HPSG.In Proceedings of the 2nd International Con-ference on Language Resources and Evaluation,Athens, Greece.A.
Copestake, D. Flickinger, I.
Sag, and C. Pollard.1999.
Minimal Recursion Semantics.
An Intro-duction.
Manuscript, Stanford University.A.
Copestake, A. Lascarides, and D. Flickinger.2001.
An algebra for semantic construction inconstraint-based grammars.
In Proceedings ofthe 39th Annual Meeting of the Association forComputational Linguistics, Toulouse, France.M.
Dalrymple.
1999.
Semantics and syntax in lexi-cal functional grammar.
MIT Press.D.
Flickinger, J. Nerbonne, I.
Sag, and T. Wasow.1987.
Towards evaluation of nlp systems.
Tech-nical report, Hewlett-Packard Laboratories.C.
Gardent and L. Kallmeyer.
2003.
Semantic con-struction in ftag.
In Proceedings of EACL, Bu-dapest, Hungary.O.
Glickman and I. Dagan.
2003.
Identifying lexi-cal paraphrases from a single corpus: a case studyfor verbs.
In Proceedings of Recent Advances inNatural Language Processing.M.
Gross.
1975.
Me?thodes en syntase.
Masson,Paris.G.
Gross.
1989.
Les constructions converses dufrancais.
CNRS Editions.Dekang Lin and Patrick Pantel.
2001.
Discovery ofinference rules for question answering.
NaturalLanguage Engineering.D.
Lin.
1998.
Automatic retrieval and clustering ofsimilar words.
In Proceedings of ACL/COLING,pages 768?774.I.
Mel?c?uk.
1988.
Paraphrase et lexique dans lathorie linguistique sens-texte.
Lexique, 6:13?54.S.
Oepen and D. Flickinger.
1998.
Towards sys-tematic grammar profiling.
test suite technology10 years after.
Computer Speech and Language,12:411?435.F.
Pereira, N. Tishby, and L. Lee.
1993.
Distribu-tional clustering of english words.
In Proceed-ings of the ACL, pages 183?190.S.
Ploux.
1997.
Modlisation et traitement infor-matique de la synonymi.
Linguisticae Investiga-tiones, XXI(1).P.
Saint-Dizier, 1999.
Alternations and Verb Se-mantic Classes for French: analysis and classformation, chapter 5.
Kluwer.Y.
Shinyanma, S. Sekine, K. Sudo, and R. Grish-man.
2002.
Automatic paraphrase acquisitionfrom news articles.
In Proceedings of HLT.
