Proceedings of the Second Workshop on Natural Language Processing for Social Media (SocialNLP), pages 38?43,Dublin, Ireland, August 24 2014.Multi-Lingual Sentiment Analysis of Social Data Based onEmotion-Bearing PatternsCarlos ArguetaNational Tsing Hua UniversityNo.
101, Section 2, Kuang-Fu RoadHsinchu, Taiwankid.a.rgueta@gmail.comYi-Shin ChenNational Tsing Hua UniversityNo.
101, Section 2, Kuang-Fu RoadHsinchu, Taiwanyishin@gmail.comAbstractSocial networking sites have flooded the Internet with posts containing shared opinions, moods,and feelings.
This has given rise to a new wave of research to develop algorithms for emotiondetection and extraction on social data.
As the desire to understand how people feel about certainevents/objects across countries or regions grows, the need to analyze social data in different lan-guages grows with it.
However, the explosive nature of data generated around the world bringsa challenge for sentiment-based information retrieval and analysis.
In this paper, we propose amultilingual system with a computationally inexpensive approach to sentiment analysis of so-cial data.
The experiments demonstrate that our approach performs an effective multi-lingualsentiment analysis of microblog data with little more than a 100 emotion-bearing patterns.1 IntroductionWeb 2.0 and the rise of social networking platforms such as microblogs have brought new ways toshare opinions in a global setting.
Microblogging sites represent a new way to share information abouteverything, such as new products, places of interest or popular culture in some ways replacing traditionalword-of-mouth communication.
Those sites have become rich repositories of opinions from audiencesdiverse in culture, race, location, and language.
They represent, for people and businesses, a potentialopportunity to understand what the global community thinks about them, helping them to make betterinformed decisions when improving their image and products.
They may also offer the general public away to find useful information and opinions before purchasing a product or service.Vast swathes of the global population have access to nearly the same products and services.
Forthat reason, being aware of opinions from around the world, regardless of the languages, is no longerambitious but necessary.
Systems which are able to aggregate opinionated data in multiple languagescould highlight a global trend around a target query.
This is desirable as targets may have differentimpacts depending on the area.
The possibilities are huge but the challenges are many.
As in every majorendeavor, it is necessary to start with the basics, such as language detection and sentiment analysis.With the explosive nature of subjective data in the Web, several patterns analysis techniques such asthe ones bye Yi et al.
(2003) and Davidov et al.
(2010) have been proposed to extract opinionated andemotion-bearing data.
Most works have focused on English language, except the technique proposedin (Sascha Narr and Albayrak, 2012) which utilizes n-grams as language independent features to classifytweets by their polarity in 4 different languages.
However, since this technique relies solely on frequencystatistics, it would need large training datasets.In this paper, we propose a language independent approach to emotion-bearing patterns retrieval inmicroblog data.
Each extracted pattern and its related words can also be considered as n-grams, however,selected in a way that makes them more semantically related to the domain of sentiment and emotionanalysis.
The proposed multi-lingual framework consists of two stages: Filter and Refine approach.
Inthe Filter stage, the language and a hint of the polarity of a microblog post are detected based on theThis work is licenced under a Creative Commons Attribution 4.0 International License.
Page numbers and proceedings footerare added by the organizers.
License details: http://creativecommons.org/licenses/by/4.0/38n-gram classification approach.
Our approach is different from the one proposed in (Sascha Narr andAlbayrak, 2012) in that the n-grams are used at the character-level instead of the word-level.In the Refine stage, language-independent emotion-bearing words and patterns (using an adaptationof extraction methods by Davidov and Rappoport (2006)) are employed.
Our approach differs from themethod of Davidov et al.
(2010) in that we use words belonging to empirically defined psychological andstructural categories (emotion, cognition, etc.)1.
These words are used as seeds to restrict the featuresextracted to emotion bearing patterns and words.Our experimental results show that our approach can extract relevant patterns.
With only about 100patterns employed of about 31,500 n-gram candidates, the approach presented in this paper outperformsa state-of-the-art classifier for the French language.
These results validate the potential of the proposedtechnique.2 Related WorkPatterns have been extensively used for many Information Retrieval tasks.
Pantel and Pennacchiotti(2006) extract semantic relations using generic patterns (with broad coverage but low precision).
Thekey assumption is that in very large corpora like the Web, correct instances generated by a generic pat-tern will be instantiated by some reliable patterns, where reliable patterns are patterns that have highprecision but often very low recall.
Wang et al.
(2007) propose a topical n-gram (TNG) model that au-tomatically determines unigram words and phrases based on context, and assigns a mixture of topics toboth individual words and n-gram phrases.
They present an Information Retrieval (IR) application withbetter performance on an ad-hoc retrieval task over a TREC collection.
Davidov and Rappoport (2006)have proposed an approach to unsupervised discovery of word categories based on symmetric patterns.A symmetric pattern is one in which co-occurring words can potentially belong to the same semanticcategory.With the speed at which subjective data is generated on the Web, and its potential usage, patternshave also been applied to extract opinionated data.
Yi et al.
(2003) use a Sentiment Pattern Databaseto match sentiment phrases related to a subject from online texts.
The system was verified using onlineproduct review articles.
Dave et al.
(2003) tried statistical and linguistic substitutions to transform specificpatterns into more general ones.
They also used an algorithm based on suffix trees to determine substringsthat provide optimal classification.
The extracted features were applied to opinion extraction of productreviews.
In their work, Davidov et al.
(2010) use their pattern definition (Davidov and Rappoport, 2006)to identify diverse sentiment types in short microblog texts.Most of the work with patterns for sentiment extraction has focused on English language.
Although,a few studies have identified patterns as a tool for bridging the gap between languages.
Cui et al.
(2011)automatically extracted different types of word level patterns (denoted emotion tokens), and labeledtheir sentiment polarities with an unsupervised propagation algorithm.
Sascha Narr and Albayrak (2012)utilized n-grams as language independent features to classify tweets by their polarity in 4 different lan-guages.The main drawback of features such as n-grams is that, to capture the semantics of a specific domain,they rely solely on frequency statistics.
This impacts less when large training data is available, but canbe a considerable disadvantage when the data is scarce.
Another drawback of such features is the largenumber of n-grams that need to be included in the features set.
Larger feature spaces have a big impacton the efficiency of systems.3 MethodologyThe objective of this work is to propose an effective multi-lingual emotion-bearing patterns extractionapproach.
To test the relevance of the extracted features, a multi-lingual sentiment analysis system formicroblog data is defined.
The proposed framework illustrated in Figure 1 consists of two stages: theFilter stage and the Refine stage.
Given a set of microblog posts containing a query term, the Filter stageutilizing n-gram patterns first detects the language of all the microblog posts.
Then it obtains the polarity1See the study by James W. Pennebaker and Booth (2007) and Tausczik and Pennebaker (2010)39(negative, positive) by utilizing a classifier trained with n-gram features at the character level.
The Refinestage utilizing symmetric patterns performs a finer analysis of the posts to classify the ones that the Filterstage left out.
It utilizes extracted emotion-bearing patterns as described in Section 3.1 and related wordsas features.Microblog DatabaseQueryFilter ModuleN-gram patternsRefine ModuleSubjective postsQuery EngineEmotion patternsConf.
> THpolConf.
< THpolFigure 1: System Overview3.1 Candidate Emotion-Bearing Surface Patterns ConstructionThe intuition of the construction method is based on psychological studies (James W. Pennebaker andBooth, 2007) proposing that emotional cues can be found in a person?s utterances and texts, providingwindows into their emotional and cognitive worlds.
Based on this idea, the following method that cancapture the textual emotion cues in the form of patterns and words is introduced.The proposed extraction technique in this paper adapted the unsupervised word categories discoverytechnique introduced by Davidov and Rappoport (2006).
To guarantee that the retrieved features arerelevant to the sentiment analysis task here presented, the proposed emotion-bearing pattern extractiontechnique requires the following adaptations.Other than the HW and CW word types introduced by Davidov and Rappoport (2006), the psycho-logical word type (PW) is introduced as seeds for extracting more emotion-related patterns.
Words inPW are content-bearing, and pertain to psychological categories related to emotion, cognition, affection,social, perception, etc.
The PW set should include words like, ?peace?, ?abandon?, and ?dream?.
By thesymmetric nature of the patterns, the PW words can be naturally expanded from the extraction dataset .In order to drive the extraction towards more emotion-related patterns, it is also enforced that at least oneof the CW words of a pattern contains a word from the PW set.
For example, ?peace is a dream?
is aninstance of a pattern ?CW HW HW CW?.The result of the extraction is a large list of word subsequences related to different emotion-bearingpatterns.
There are two main reasons not to employ all extracted subsequences from a large corpusas features.
First, the current list is usually huge (around 150,000 unique subsequences found in theexperiments with English data), making the training process inefficient.
Second, it is necessary to accountfor the fact that the dataset used for features extraction may be completely different from the training, andtesting sets.
Additionally, the PW set can also vary greatly in size and psychological categories included.This can potentially impact the coverage/accuracy due to unseen words.3.2 Graph-Based Relevant Patterns SelectionThe following reduction method based on the graph representation for patterns described in (Davidovand Rappoport, 2006) is introduced to reduce the features space, and to account for unseen words.
First,infrequent subsequences are ignored.
Then, the subsequences are grouped by pattern based on their HWwords.
Subsequences having the same HW word in the same positions are grouped together and theirCW words are replaced by ?
*?.2Finally, as proposed by Davidov and Rappoport (2006), the directed2?*?
is a wild card that matches any word40graph G(p) = (V(G),E(G)) for each pattern p is constructed.
For example, subsequences ?love my niece?and ?hate my boss?
from the meta-pattern ?CW HW CW?
are both grouped together as part of the pattern?
* my *?.Two different scores are proposed to measure the degree of emotion expressed by each pattern.
Theintuition of the following definitions is, the higher the proportion of PW words appearing in subsequencesbelonging to a given pattern, the higher the degree of emotion of this pattern.Definition 1 (SC1)The number of out-links of the vertex with max.
number of out-links in the graph for pattern p.SC1 = max(|{(x, y)|x ?
V (G(p)}|) (1)Definition 2 (SC2)The number of in-links of the vertex with max.
number of in-links in the graph for pattern p.SC2 = max(|{(x, y)|y ?
V (G(p)}|) (2)Patterns with high SC1 and SC2 scores ensure a good coverage as they capture more PW words fromthe corpus.
For each score, a ranked list of patterns is obtained.
Patterns in top THtopin at least onelist and not in bottom THbottomin any list are retained.
The final list of features is composed of allthe retained patterns, and all the CWs it captured from the corpus through its related subsequences.This approach significantly reduces the features space by using only the relevant patterns, and not thesubsequences (n-grams) as features.
It also helps the coverage, as unseen words can still be captured bya pattern through the ?
* ?
wild card.3.3 Multi-lingual Sentiment Analysis on Microblog DataThe following Filter and Refine approach is employed to determine the polarity of posts from microblogdata.
Given a post, the Filter stage firsts detects its language.
It does so by training language modelsusing n-grams at the character-level.
Next, the corresponding polarity models are used to determine thepolarity of the post.
The polarity models are also constructed with the same method.A confidence value is obtained as follows.Conf(p) =????(Freqpositive(ng)?
Freqnegative(ng))???
(3)where ng is an n-gram entry and Freq gets its frequency count in a polarity model.We define experimentally two thresholds THpolfor pol ?
{positive, negative}.
For a given detectedclass pol we say the post has that polarity only if Conf (p) > THpolelse we send the post to the Refinestage.The posts not classified by the Filter stage are processed by the Refine stage, which is based on aMultinomial Na?
?ve Bayes classifier.
The classifier uses the emotion-patterns and words extracted usingthe methods described in 3.1 and 3.2 as binary features.
Each pattern is used as a regular expression tolook for matching subsequences in a post.
If a match exists, the corresponding value in the vector is setto 1 and to 0 otherwise.
The same process applies for word features.4 Experiments4.1 Experimental SetupTwo experiments were performed to validate the approach introduced in this paper.
Datasets in threetarget languages (English, Spanish, and French) were utilized to test the approach.
To avoid favoringthe proposed method by having similar data characteristics in both training and testing stages, differentdatasets are employed in the experiments.The larger set, SetHT, was collected using emotion-bearing hashtags as noisy labels.
This set is usedduring the training process.
The second set, SetEmo, was collected using positive and negative emoticonsas queries to the Twitter Search API.
From the collected tweets, 500 positive and 500 negative were41manually annotated for each language by 2 volunteers.
The third set SetRW, released by Sascha Narrand Albayrak (2012), contains 739 positive and 488 negative manually annotated English tweets, and159 positive and 160 negative French tweets.To obtain more emotion-related patterns during the extraction phase, the psychological words (PW)were obtained from psychological categories in a text analysis application called Linguistic Inquiry andWord Count (LIWC) (James W. Pennebaker and Booth, 2007).4.2 Experimental ResultFilter Refine Filter + RefineEnglish 8 4.78 81.54 83.18Spanish 82.01 82.99 82.40French 9 1.72 83.98 85.100.0010.0020.0030.0040.0050.0060.0070.0080.0090.00100.00 Best performance for Filter and RefineFigure 2: Filter + Refine performance with SetEmotesting setThe first experiment evaluated the proposed approach using the SetEmotesting set.
The results inFigure 2 show that overall accuracies of over 80% can be obtained for all languages.
Keep in mind thatneither Filter nor Refine stages process all the posts, hence the reported individual accuracies are onlyover the portion of posts analyzed by each, with only the Filter+Refine result being over the totality ofthe posts.
Due to time limitations, the approach used to combine the results from Filter and Refine isbasic and treats both classifications as independent processes.
A more elaborated approach may improvethe results further.Method Lang Patterns Training Tweets AccuracyNarr en N.A.
?
500K 81.3 %F+R en 145 100K 79.0 %Narr fr N.A.
?
100K 74.9 %F+R fr 100 50K 75.6 %Table 1: Filter + Refine (F+R) compared to the related work (Narr).Language n-grams patternsEnglish 141,981 145Spanish 85,683 -French 31,428 100Table 2: Number of the extracted subsequences (n-grams), compared to the final number of patterns used in the comparisonbetween Filter + Refine and Narr.Finally, an experiment similar to the previous one was performed using SetRWas the testing set.Table 1 shows that using a significantly lower number of features (the number of unigrams used by Narris not available but must be large) and a smaller training set, the performance of the introduced approachsurpasses the one reported by Narr for French and is just slightly lower for English.
This is possiblethanks to the effective reduction approach used to obtain relevant patterns from extracted subsequences,which is one of the main contributions of this paper (See Table 2).
The training sizes used by Filter+ Refine were limited due to data availability.
More data would have probably helped Filter + Refinesurpass the results reported by Narr for English.425 Conclusion and Future WorkTwo main types of language-independent features were studied in this paper: character-level n-grams,and emotion-bearing patterns.
Character-level n-grams represent a useful tool for a preliminary sentimentclassifier such as Filter.
Emotion-bearing patterns can capture the emotional cues embedded in a person?swriting.
Such features can help identify subjectivity and determine the polarity of microblog posts acrosssignificantly different datasets in ways that regular patterns based purely on frequency wouldn?t.
It isbelieved that such emotion-bearing patterns can be used to perform a more complex analysis such asambiguity and sarcasm identification, and to model other social and psychological characteristics ofhuman behavior.This paper contributes the introduction of emotion-bearing patterns as language independent featuresfor multi-lingual sentiment analysis, and the efficient reduction approach used during their extraction.Sentiment analysis methods could benefit from such an approach during the training phases.
Moreover,since the features obtained are very relevant to the classification task, less training examples are required,reducing the number of features significantly.
Finally, the approach here presented is highly configurable,with both Filter and Refine relying on different thresholds.
Several experiments with different sets ofvalues can be performed to find the optimal set for a given language and show the full potential of theapproach.As a future work, it is planned to study the applicability of the presented approach to Asian languagessuch as Chinese and Vietnamese.
Additionally, a deeper analysis of the patterns will be performed toextend the classification from the classic binary approach to a multi-class approach (using 8 differentemotions).
More difficult tasks such as detecting ambiguity and sarcasm will also be addressed.ReferencesAnqi Cui, Min Zhang, Yiqun Liu, and Shaoping Ma.
2011.
Emotion tokens: bridging the gap among multilingualtwitter sentiment analysis.
In Proceedings of the 7th Asia conference on Information Retrieval Technology,AIRS?11, pages 238?249, Berlin, Heidelberg.
Springer-Verlag.Kushal Dave, Steve Lawrence, and David M. Pennock.
2003.
Mining the peanut gallery: opinion extraction andsemantic classification of product reviews.
In WWW ?03: Proceedings of the 12th international conference onWorld Wide Web, pages 519?528, New York, NY, USA.
ACM.Dmitry Davidov and Ari Rappoport.
2006.
Efficient unsupervised discovery of word categories using symmetricpatterns and high frequency words.
In Proceedings of the 21st International Conference on ComputationalLinguistics and the 44th annual meeting of the Association for Computational Linguistics, ACL-44, pages 297?304, Stroudsburg, PA, USA.
Association for Computational Linguistics.Dmitry Davidov, Oren Tsur, and Ari Rappoport.
2010.
Enhanced sentiment learning using twitter hashtags andsmileys.
In Proceedings of the 23rd International Conference on Computational Linguistics: Posters, COLING?10, pages 241?249, Stroudsburg, PA, USA.
Association for Computational Linguistics.Molly Ireland Amy Gonzales James W. Pennebaker, Cindy K. Chung and Roger J. Booth.
2007.
The developmentand psychometric properties of liwc2007.Patrick Pantel and Marco Pennacchiotti.
2006.
Espresso: Leveraging generic patterns for automatically harvestingsemantic relations.
In Proc.
of the International Conference on Computational Linguistics/Association, pages113?120, Sydney, Australia, 17th-21st July.
ACL Press.Michael Hulfenhaus Sascha Narr and Sahin Albayrak.
2012.
Language-independent twitter sentiment analysis.
InWorkshop on Knowledge Discovery, Data Mining and Machine Learning.Yla R. Tausczik and James W. Pennebaker.
2010.
The psychological meaning of words: Liwc and computerizedtext analysis methods.Xuerui Wang, Andrew McCallum, and Xing Wei.
2007.
Topical n-grams: Phrase and topic discovery, with anapplication to information retrieval.
In ICDM, pages 697?702.
IEEE Computer Society.Jeonghee Yi, Tetsuya Nasukawa, Razvan Bunescu, and Wayne Niblack.
2003.
Sentiment analyzer: Extractingsentiments about a given topic using natural language processing techniques.
In Proceedings of the IEEEInternational Conference on Data Mining (ICDM).43
