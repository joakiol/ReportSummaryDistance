Category-Based PseudowordsPreslav I. NakovEECS, UC BerkeleyBerkeley, CA 94720nakov@cs.berkeley.eduMarti A. HearstSIMS, UC BerkeleyBerkeley, CA 94720hearst@sims.berkeley.eduAbstractA pseudoword is a composite comprised of twoor more words chosen at random; the individualoccurrences of the original words within a textare replaced by their conflation.
Pseudowordsare a useful mechanism for evaluating the im-pact of word sense ambiguity in many NLPapplications.
However, the standard methodfor constructing pseudowords has some draw-backs.
Because the constituent words are cho-sen at random, the word contexts that surroundpseudowords do not necessarily reflect the con-texts that real ambiguous words occur in.
Thisin turn leads to an optimistic upper bound onalgorithm performance.
To address these draw-backs, we propose the use of lexical categoriesto create more realistic pseudowords, and eval-uate the results of different variations of thisidea against the standard approach.1 IntroductionIn order to evaluate a word sense disambiguation (WSD)algorithm in a new language or domain, a sense-taggedevaluation corpus is needed, but this is expensive to pro-duce manually.
As an alternative, researchers often usepseudowords.
To create a pseudoword, two or morerandomly-chosen words (e.g., banana and door) are se-lected and their individual occurrences are replaced bytheir conflation (e.g., banana-door).
Since their introduc-tion (Gale et al, 1992; Schuetze, 1992), pseudowordshave been accepted as an upper bound of the true accu-racy of algorithms that assign word sense distinctions.In most cases, constituent words are chosen entirelyrandomly.
When used to evaluate a real WSD system onthe SENSEVAL1 corpus, pseudowords were found to beoptimistic in their estimations compared to real ambigu-ous words with the same distribution (Gaustad, 2001).Real ambiguous words often have senses that are similarin meaning, and thus difficult to distinguish (as measuredby low inter-annotator agreement), while pseudowords,because they are randomly chosen, are highly likely tocombine semantically distinct words.
Another drawbackis that the results produced using pseudowords are dif-ficult to characterize in terms of the types of ambiguitythey model.To create more plausibly-motivated pseudoword pair-ings, we introduce the use of lexical category member-ship for pseudoword generation.
The main idea is to takenote of the relative frequencies at which pairs of lexi-cal categories tend to represent real ambiguous words,and then use unambiguous words drawn from those cate-gories to generate pseudowords.
In the remainder of thispaper we describe the category-based pseudoword gener-ation process and evaluate the results against the standardmethods and against a real word sense disambiguationtask.2 MeSH and MedlineIn this paper we use the MeSH (Medical Subject Head-ings) lexical hierarchy1, but the approach should beequally applicable to other domains using other thesauriand ontologies.
In MeSH, each concept is assigned oneor more alphanumeric descriptor codes correspondingto particular positions in the hierarchy.
For example,A (Anatomy), A01 (Body Regions), A01.456 (Head),A01.456.505 (Face), A01.456.505.420 (Eye).
Eye isambiguous according to MeSH and has a second code:A09.371 (A09 represents Sense Organs).In the studies reported here, we truncate the MeSHcode at the first period.
This allows for generalizationover different words; e.g., for eye, we discriminate be-tween senses represented by A01 and A09.
This trun-cation reduces the average number of senses per tokenfrom 2.12 to 1.39, and the maximum number of ambigu-ity classes for a given word to 7; 71.18% of the tokenshave a single class and 22.14% have two classes.
Froma collection of 180,226 abstracts from Medline 20032,1http://www.nlm.nih.gov/mesh2235 MB of plain text, after XML removal, from files med-Ambig.
pair Pair freq.
Class 1 freq.
Class 2 freq{A11,A15} 16127 49350 3417{A12,A15} 13662 7403 3417{D12,D24} 12608 28805 17064{E05,H01} 11753 17506 40744{I01,N03} 6988 7721 11046{A02,A10} 6834 4936 14083Table 1: Most frequent ambiguous 2-category pairs.training was done on 2/3 of the abstracts (120,150) andtesting on the remaining 1/3 (60,076).3 Pseudoword GenerationFor the creation of pseudowrods with two-sense ambigui-ties, we first determined which ambiguous words fall intoexactly two MeSH categories and built a list L of pairs(see Table 1).
We then generated pseudowords with thefollowing characteristics:?
The two possible pseudoword categories represent apair that is really seen in the testing corpus and thusneeds to be disambiguated;?
The number of pseudowords drawn from a particularpair is proportional to its frequency;?
Multi-word concepts can be used as pseudowordelements: e.g., ion-exchange chromatographyand long-term effects can be conflated as ion-exchange chromatography long-term effects?
Only unambiguous words are used as pseudowordconstituents.An important aspect of pseudoword creation is the rel-ative frequencies of the underlying words.
Since the stan-dard baseline for a WSD algorithm is to always choosethe most frequent sense, a baseline that is evaluated onwords whose senses are evenly balanced will be expectedto do more poorly than one tested against words that areheavily skewed towards one sense (Sanderson & van Ri-jsbergen, 1999).In naturally occurring text, the more frequent sense forthe two-sense distinction is reported to occur 92% of thetime on average; this result has been found both on theCACM collection and on the WordNet SEMCOR sense-tagged corpus (Sanderson & van Rijsbergen, 1999).However, the challenge for WSD programs is to work onthe harder cases, and the artificially constructed SENSE-VAL1 corpus has more evenly distributed senses (Gaus-tad, 2001).In these experiments, we explicitly compare pseu-dowords whose underlying word frequencies are evenline03n0201.xml through med-line03n0209.xml.w1 w2 pair #w1 #w2artifact triton {E05,H01} 55 40humerus mucus memb.
{A02,A10} 51 38lovastatin palmitic acid {D04,D10} 35 54child abuse Minnesota {I01,Z01} 39 45thumb pupils {A01,A09} 56 38haptoglobin hla antigens {D12,D24} 46 53Table 2: Sample pseudowords.against those that are skewed.
To generate pseudowordswith more uniform underlying distributions, we first cal-culate the expected testing corpus frequency of thosewords wi that have been unambiguously mapped toMeSH and whose class is used in at least one pair in L. Inthis collection the expected frequency was E = 45.21 witha standard deviation of 451.19.
We then built a list W ofall MeSH concepts mapped in the text that have a classused in a pair in L and whose frequency is in the interval[E/2;3E/2], i.e.
[34;56].
This yields a list of concepts thatcould potentially be combined in 64,596 pseudowords forevaluation of the WSD algorithm performance over theclasses in L.We then generated a random subset of 1,000 pseu-dowords (88,758 instances) out of the possible 64,596 byapplying the following importance sampling procedure:1) Select a category pair c1,c2 from L by samplingfrom a multinomial distribution whose parameters areproportional to the frequencies of the elements of L.2) Sample uniformly to draw two random distinctwords w1 and w2 from W whose classes correspond tothe classes selected in step 1).3) If the word pair w1,w2 has been sampled already, goto step 1) and try again.Table 2 shows a random selection of pseudowords gen-erated by the algorithm.
Note that the more unusual pair-ings come from the less frequent category pairs, whereasthose in which word senses are closer in meaning aredrawn from more common category pairs.4 ResultsFor the experiments reported below, we trained an un-supervised Naive Bayes classifier using the categories asboth targets and as context features.
For example, an oc-currence of the word haptoglobin in the context surround-ing the word to be disambiguated will be replaced by itscategory label D12.
Only unambiguous context wordswere used.
The result of the disambiguation step is a cat-egory name, standing as a proxy for the word sense.Table 3 reports accuracies for several experiments interms of macroaverages (average over the individual ac-curacies for each pseudoword).
Baseline refers to choos-CW Base.
Pess.
Real.
Abbrev.
Opt.10 53.24 62.93 64.60 70.37 71.3520 53.24 66.80 68.90 73.83 76.3640 53.24 69.92 73.28 76.46 80.03300 53.24 72.79 75.34 77.99 81.88Table 3: Accuracies (in %?s) of Baseline, Pessimistic, Re-alistic, Abbreviation, and Optimistic datasets for differentcontext window (CW) sizes.AAP: acetaminophen D02auricular acupuncture E02GST: general systems theory H01glutathione s-transferase D08ED: eating disorders F03endogenous depression F03elemental diet J02Table 4: Sample category mappings for abbreviations.ing the most frequent sense3.
Pessimistic refers to theevenly distributed category-based pseudowords, gener-ated by requiring the word frequency to fall in the interval[E/2;3E/2].
In the column labeled Realistic, the require-ment for evenly distributed senses is dropped, althoughthe component words must have a frequency of at least5.
The column labeled Optimistic refers to the resultswhen the pseudowords are generated the standard way:the words are selected at random rather than according tothe category sets.We expected the Realistic pseudowords to producea better lower-bound estimate of the performance of aWSD algorithm on real word senses than Optimistic.
Totest this hypothesis we followed a method suggested byLiu et al (2002) and evaluated the classifier on a set of217 two-sense abbreviations (see Table 4).Abbreviations are real ambiguous words, but they arealso artificial in a sense.
Many homonyms are similar inmeaning as well as spelling because they derive etymo-logically from the same root.
By contrast, similar spellingin abbreviations is often simply an accident of shared ini-tial characters in compound nouns.
Thus abbreviationsoccupy an intermediate position between entirely randompseudowords and standard real ambiguous words.We extracted 98,841 unique abbreviation-expansionpairs4 using code developed by Schwartz & Hearst(2003), and retained only those abbreviations whose ex-pansions could be fully and unambiguously mapped toa single truncated MeSH category.
The different expan-sions of each abbreviation were required to correspond3The baseline is dependent on the (pseudo)words used.
Theone shown is the baseline for the abbreviations collection.4From med-line03n0210.xml to med-line03n0229.xml.to exactly two distinct categories (with overlap allowedwhen there were more than two expansions for a givenabbreviation).The question we wanted to explore is how well doesthe classifier do on category-based pseudowords versusabbreviations.
As can be seen from Table 3, the ac-curacies for the abbreviations (evaluated on 332,020 in-stances) fall between the Realistic and Optimistic pseu-dowords, as expected.5 ConclusionsWe have shown that creating pseudowords based on dis-tributions from lexical category co-occurrence can pro-duce a more accurate lower-bound for WSD systemsthat use pseudowords than the standard approach.
Thismethod allows for the detailed study of a particular senseambiguity set since many different pseudowords can begenerated from one category pair.
Additionally, thismethod provides a better-motivated basis for the groupingof words into pseudowords, since they more realisticallymodel the meaning similarity patterns of real ambiguouswords than do randomly paired words.Acknowledgements Special thanks to BarbaraRosario for the discussions and valuable suggestionsand to Ariel Schwartz for providing the abbreviationextraction code.
This work was supported by a gift fromGenentech and an ARDA Aquaint contact.ReferencesWilliam A. Gale, Kenneth W. Church and DavidYarowsky.
1992.
Work on statistical methods for wordsense disambiguation., In R. Goldman et al (Eds.
),Working Notes of the AAAI Fall Symposium on Prob-abilistic Approaches to Natural Language, 54-60.Tanja Gaustad.
2001.
Statistical Corpus-Based WordSense Disambiguation: Pseudowords vs. Real Am-biguous Words., Proc.
39th Annual Meeting of ACL(ACL/EACL 2001) - Student Research Workshop.Hongfang Liu, Stephen B. Johnson and Carol Friedman.2002.
Automatic Resolution of Ambiguous TermsBased on Machine Learning and Conceptual Relationsin the UMLS, JAMIA 2002.Mark Sanderson and Keith van Rijsbergen.
1999.
Theimpact on retrieval effectiveness of skewed frequencydistributions., TOIS 17(4): 440-465.Hinrich Schuetze.
1992.
Context space., In R. Goldmanet al (Eds.
), Working Notes of the AAAI Fall Sym-posium on Probabilistic Approaches to Natural Lan-guage, 54-60.Ariel Schwartz and Marti Hearst.
2003.
A SimpleAlgorithm for Identifying Abbreviation Definitions inBiomedical Text., In Proceedings of the Pacific Sympo-sium on Biocomputing (PSB 2003) Kauai, Jan 2003.
