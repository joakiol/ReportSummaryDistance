Proceedings of the 9th Conference on Computational Natural Language Learning (CoNLL),pages 33?39, Ann Arbor, June 2005. c?2005 Association for Computational LinguisticsAbstractTraditionally, word sense disambiguation(WSD) involves a different context classifi-cation model for each individual word.
Thispaper presents a weakly supervised learningapproach to WSD based on learning a wordindependent context pair classificationmodel.
Statistical models are not trained forclassifying the word contexts, but for classi-fying a pair of contexts, i.e.
determining if apair of contexts of the same ambiguous wordrefers to the same or different senses.
Usingthis approach, annotated corpus of a targetword A can be explored to disambiguatesenses of a different word B.
Hence, only alimited amount of existing annotated corpusis required in order to disambiguate the entirevocabulary.
In this research, maximum en-tropy modeling is used to train the word in-dependent context pair classification model.Then based on the context pair classificationresults, clustering is performed on word men-tions extracted from a large raw corpus.
Theresulting context clusters are mapped ontothe external thesaurus WordNet.
This ap-proach shows great flexibility to efficientlyintegrate heterogeneous knowledge sources,e.g.
trigger words and parsing structures.Based on Senseval-3 Lexical Sample stan-dards, this approach achieves state-of-the-artperformance in the unsupervised learningcategory, and performs comparably with thesupervised Na?ve Bayes system.1 IntroductionWord Sense Disambiguation (WSD) is one of thecentral problems in Natural Language Processing.The difficulty of this task lies in the fact that con-text features and the corresponding statistical dis-tribution are different for each individual word.Traditionally, WSD involves training the contextclassification models for each ambiguous word.
(Gale et al 1992) uses the Na?ve Bayes method forcontext classification which requires a manuallyannotated corpus for each ambiguous word.
Thiscauses a serious Knowledge Bottleneck.
The bot-tleneck is particularly serious when considering thedomain dependency of word senses.
To overcomethe Knowledge Bottleneck, unsupervised or weaklysupervised learning approaches have been pro-posed.
These include the bootstrapping approach(Yarowsky 1995) and the context clustering ap-proach (Sch?tze 1998).The above unsupervised or weakly supervisedlearning approaches are less subject to the Knowl-edge Bottleneck.
For example, (Yarowsky 1995)only requires sense number and a few seeds foreach sense of an ambiguous word (hereafter calledkeyword).
(Sch?tze 1998) may only need minimalannotation to map the resulting context clustersonto external thesaurus for benchmarking and ap-plication-related purposes.
Both methods are basedon trigger words only.This paper presents a novel approach based onlearning word-independent context pair classifica-tion model.
This idea may be traced back to(Sch?tze 1998) where context clusters based ongeneric Euclidean distance are regarded as distinctword senses.
Different from (Sch?tze 1998), weobserve that generic context clusters may not al-ways correspond to distinct word senses.
There-fore, we used supervised machine learning tomodel the relationships between the context dis-tinctness and the sense distinctness.Although supervised machine learning is usedfor the context pair classification model, our over-all system belongs to the weakly supervised cate-gory because the learned context pair classificationWord Independent Context Pair Classification Model for WordSense DisambiguationCheng Niu, Wei Li, Rohini K. Srihari, and Huifeng LiCymfony Inc.600 Essjay Road, Williamsville, NY 14221, USA.
{cniu, wei, rohini,hli}@cymfony.com33model is independent of the keyword for disam-biguation.
Our system does not need human-annotated instances for each target ambiguousword.
The weak supervision is performed by usinga limited amount of existing annotated corpuswhich does not need to include the target word set.The insight is that the correlation regularity be-tween the sense distinction and the context distinc-tion can be captured at Part-of-Speech categorylevel, independent of individual words or wordsenses.
Since context determines the sense of aword, a reasonable hypothesis is that there is somemechanism in the human comprehension processthat will decide when two contexts are similar (ordissimilar) enough to trigger our interpretation of aword in the contexts as one meaning (or as twodifferent meanings).
We can model this mecha-nism by capturing the sense distinction regularityat category level.In the light of this, a maximum entropy model istrained to determine if a pair of contexts of thesame keyword refers to the same or different wordsenses.
The maximum entropy modeling is basedon heterogeneous context features that involveboth trigger words and parsing structures.
To en-sure the resulting model?s independency of indi-vidual words, the keywords used in training aredifferent from the keywords used in benchmarking.For any target keyword, a collection of contexts isretrieved from a large raw document pool.
Contextclustering is performed to derive the optimal con-text clusters which globally fit the local contextpair classification results.
Here statistical annealingis used for its optimal performance.
In benchmark-ing, a mapping procedure is required to correlatethe context clusters with external ontology senses.In what follows, Section 2 formulates the maxi-mum entropy model for context pair classification.The context clustering algorithm, including theobject function of the clustering and the statisticalannealing-based optimization, is described in Sec-tion 3.
Section 4 presents and discusses bench-marks, followed by conclusion in Section 5.2 Maximum Entropy Modeling for Con-text Pair ClassificationGiven n  mentions of a keyword, we first introducethe following symbols.
iC  refers to the i -th con-text.
iS  refers to the sense of the i -th context.jiCS ,  refers to the context similarity between thei -th context and the j -th context, which is a subsetof the predefined context similarity features.
?frefers to the ?
-th predefined context similarityfeature.
So jiCS ,  takes the form of { }?f .In this section, we study the context pair classi-fication task, i.e.
given a pair of contexts iC andjC  of the same target word, are they referring tothe same sense?
This task is formulated as compar-ing the following conditional probabilities: ( )jiji CSSS ,Pr =  and ( )jiji CSSS ,Pr ?
.
Unliketraditional context classification for WSD wherestatistical model is trained for each individualword, our context pair classification model istrained for each Part-of-speech (POS) category.The reason for choosing POS as the appropriatecategory for learning the context similarity is thatthe parsing structures, hence the context represen-tation, are different for different POS categories.The training corpora are constructed using theSenseval-2 English Lexical Sample training cor-pus.
To ensure the resulting model?s independencyof individual words, the target words used forbenchmarking (which will be the ambiguous wordsused in Senseval-3 English Lexicon Sample task)are carefully removed in the corpus constructionprocess.
For each POS category, positive and nega-tive instances are constructed as follows.Positive instances are constructed using contextpairs referring to the same sense of a word.
Nega-tive instances are constructed using context pairsthat refer to different senses of a word.For each POS category, we have constructedabout 36,000 instances, half positive and half nega-tive.
The instances are represented as pairwise con-text similarities, taking the form of { }?f .Before presenting the context similarity featureswe used, we first introduce the two categories ofthe involved context features:i) Co-occurring trigger words within a prede-fined window size equal to 50 words to bothsides of the keyword.
The trigger words arelearned from a TIPSTER document pool con-taining ~170 million words of AP and WSJnews articles.
Following (Sch?tze 1998), ?2 isused to measure the cohesion between thekeyword and a co-occurring word.
In our ex-34periment, all the words are first sorted basedon its ?2 with the keyword, and then the top2,000 words are selected as trigger words.ii) Parsing relationships associated with thekeyword automatically decoded by a broad-coverage parser, with F-measure (i.e.
the pre-cision-recall combined score) at about 85%(reference temporarily omitted for the sake ofblind review).
The logical dependency rela-tionships being utilized are listed below.Noun:  subject-of,object-of,complement-of,has-adjective-modifier,has-noun-modifier,modifier-of,possess,possessed-by,appositive-ofVerb:   has-subject,has-object,has-complement,has-adverb-modifier,has-prepositional-phrase-modifierAdjective: modifier-of,has-adverb-modifierBased on the above context features, the follow-ing three categories of context similarity featuresare defined:(1)  VSM-based (Vector Space Model based)trigger word similarity: the trigger wordsaround the keyword are represented as a vec-tor, and the word i in context j is weighted asfollows:)(log*),(),( idfDjitfjiweight =where ),( jitf  is the frequency of word i inthe j-th context; D is the number of docu-ments in the pool; and )(idf  is the number ofdocuments containing the word i.
D and)(idf are estimated using the document poolintroduced above.
The cosine of the angle be-tween two resulting vectors is used as thecontext similarity measure.
(2)  LSA-based (Latent Semantic Analysis based)trigger word similarity: LSA (Deerwester etal.
1990) is a technique used to uncover theunderlying semantics based on co-occurrencedata.
The first step of LSA is to constructword-vs.-document co-occurrence matrix.Then singular value decomposition (SVD) isperformed on this co-occurring matrix.
Thekey idea of LSA is to reduce noise or insig-nificant association patterns by filtering theinsignificant components uncovered by SVD.This is done by keeping only the top k singu-lar values.
By using the resulting word-vs.-document co-occurrence matrix after the fil-tering, each word can be represented as a vec-tor in the semantic space.In our experiment, we constructed the originalword-vs.-document co-occurring matrix asfollows: 100,000 documents from theTIPSTER corpus were used to construct theco-occurring matrix.
We processed thesedocuments using our POS tagger, and se-lected the top n most frequently mentionedwords from each POS category as basewords:top 20,000 common nounstop 40,000 proper namestop 10,000 verbstop 10,000 adjectivestop 2,000 adverbsIn performing SVD, we set k (i.e.
the numberof nonzero singular values) as 200, followingthe practice reported in (Deerwester et al1990) and (Landauer & Dumais, 1997).Using the LSA scheme described above, eachword is represented as a vector in the seman-tic space.
The co-occurring trigger words arerepresented as a vector summation.
Then thecosine of the angle between the two resultingvector summations is computed, and used asthe context similarity measure.
(3) LSA-based parsing relationship similarity:each relationship is in the form of )(wR?
.Using LSA, each word w  is represented as a35semantic vector ( )wV .
The similarity between)( 1wR?
and )( 2wR?
is represented as the co-sine of the angle between ( )1wV  and ( )2wV .Two special values are assigned to two excep-tional cases: (i) when no relationship ?R  isdecoded in both contexts; (ii) when the rela-tionship ?R is decoded only for one context.In matching parsing relationships in a contextpair, if only exact node match counts, very fewcases can be covered, hence significantly reducingthe effect of the parser in this task.
To solve thisproblem, LSA is used as a type of synonym expan-sion in matching.
For example, using LSA, thefollowing word similarity values are generated:similarity(good, good)   1.00similarity(good, pretty) 0.79similarity(good, great) 0.72?
?Given a context pair of a noun keyword, supposethe first context involves a relationship has-adjective-modifier whose value is good, and thesecond context involves the same relationship has-adjective-modifier with the value pretty, then thesystem assigns 0.79 as the similarity value for thisrelationship pair.To facilitate the maximum entropy modeling inthe later stage, all the three categories of the result-ing similarity values are discretized into 10 inte-gers.
Now the pairwise context similarity isrepresented as a set of similarity features, e.g.
{VSM-Trigger-Words-Similairty-equal-to-2,LSA-Trigger-Words-Similarity-equal-to-1,LSA-Subject-Similarity-equal-to-2}.In addition to the three categories of basic con-text similarity features defined above, we also de-fine induced context similarity features bycombining basic context similarity features usingthe logical and operator.
With induced features, thecontext similarity vector in the previous example isrepresented as{VSM-Trigger-Word-Similairty-equal-to-2,LSA- Trigger-Word-Similarity-equal-to-1,LSA-Subject-Similarity-equal-to-2,[VSM-Similairty-equal-to-2 andLSA-Trigger-Word-Similarity-equal-to-1],[VSM-Similairty-equal-to-2 andLSA-Subject-Similarity-equal-to-2],???
[VSM-Trigger-Word-Similairty-equal-to-2and LSA-Trigger-Word-Similarity-equal-to-1and LSA-Subject-Similarity-equal-to-2]}The induced features provide direct and fine-grained information, but suffer from less samplingspace.
Combining basic features and induced fea-tures under a smoothing scheme, maximum en-tropy modeling may achieve optimal performance.Using the context similarity features definedabove, the training corpora for the context pairclassification model is in the following format:Instance_0 tag=?positive?
{VSM-Trigger-Word-Similairty-equal-to-2, ?
}Instance_1 tag=?negative?
{VSM-Trigger-Word-Similairty-equal-to-0, ?}????
?where positive tag denotes a context pair associ-ated with same sense, and negative tag denotes acontext pair associated with different senses.The maximum entropy modeling is used to com-pute the conditional probabilities ( )jiji CSSS ,Pr =  and ( )jiji CSSS ,Pr ?
: once thecontext pair jiCS ,  is represented as }{ ?f , the con-ditional probability is given as( ){ }??=?
?ffftwZft ,1}{Pr         (1)where { }jiji SSSSt ?=?
, , Z is the normaliza-tion factor, ftw ,  is the weight associated with tag tand feature f .
Using the training corpora con-structed above, the weights can be computed basedon Iterative Scaling algorithm (Pietra etc.
1995)The exponential prior smoothing scheme (Good-man 2003) is adopted in the training.363 Context Clustering based on ContextPair Classification ResultsGiven n  mentions { }iC of a keyword, we use thefollowing context clustering scheme.
The discov-ered context clusters correspond to distinct wordsenses.For any given context pair, the context similarityfeatures defined in Section 2 are computed.
With nmentions of the same keyword, 2)1( ?nn  contextsimilarities [ ] [ )( )ijniCS ji ,1,,1 , ??
are computed.Using the context pair classification model, eachpair is associated with two scores ( )( )jijiji CSSSsc ,0, Prlog ==  and( )( )jijiji CSSSsc ,1, Prlog ==  which correspond tothe probabilities of two situations: the pair refers tothe same or different word senses.Now we introduce the symbol { }MK ,  which re-fers to the final context cluster configuration,where K refers to the number of distinct sense, andM represents the many-to-one mapping (from con-texts to a sense) such that( ) K].
[1,j n],[1,i j,iM ?
?= Based on the pairwisescores { } 0, jisc and  { } 1, jisc , WSD is formulated assearching for { }MK , which maximizes the follow-ing global scores:{ }( ) ( )[ ][ )MK,c,1,n1,i,,?
?=ijjikjiscs  (2)where ( ) ( ) ( )== otherwisejMiMifjik      ,1,0,Similar clustering scheme has been used success-fully for the task of co-reference in (Luo etc.2004), (Zelenko, Aone and Tibbetts, 2004a) and(Zelenko, Aone and Tibbetts, 2004b).In this paper, statistical annealing-based optimi-zation (Neal 1993) is used to search for { }MK ,which maximizes Expression (2).The optimization process consists of two steps.First, an intermediate solution { }0, MK  is com-puted by a greedy algorithm.
Then by setting{ }0, MK as the initial state, statistical annealing isapplied to search for the global optimal solution.The optimization algorithm is as follows.1.
Set the initial state { }MK , as nK = , and[ ]n1,i  ,)( ?= iiM ;2.
Select a cluster pair for merging thatmaximally increases{ }( ) ( )[ ][ )MK,c,1,n1,i,,??=ijjikjiscs3.
If no cluster pair can be merged to in-crease { }( ) ( )[ ][ )MK,c,1,n1,i,,?
?=ijjikjiscs , output{ }MK , as the intermediate solution;otherwise, update { }MK ,  by the mergeand go to step 2.Using the intermediate solution { }0, MK of thegreedy algorithm as the initial state, the statisticalannealing is implemented using the followingpseudo-code:Set { } { }0,, MKMK = ;for( 1.01?*;??
;??
final0 =<= ){iterate pre-defined number of times{set { } { }MKMK ,, 1 = ;update { }1, MK  by randomly changingcluster number and cluster contents;set { }( ){ }( )MK,cMK,c 1ssx =if(x>=1){set { } { }1,, MKMK =}else{set { } { }1,, MKMK =  with probability?x .
}if { }( ) { }( )0MK,cMK,c ss >then set { } { }MKMK ,, 0 =}}output { }0, MK  as the optimal state.374 BenchmarkingCorpus-driven context clusters need to map to aword sense standard to facilitate performancebenchmark.
Using Senseval-3 evaluation stan-dards, we implemented the following procedure tomap the context clusters:i) Process TIPSTER corpus and the origi-nal unlabeled Senseval-3 corpora (in-cluding the training corpus and thetesting corpus) by our parser, and saveall the parsing results into a repository.ii) For each keyword, all related contexts inSenseval-3 corpora and up-to-1,000 re-lated contexts in TIPSTER corpus areretrieved from the repository.iii) All the retrieved contexts are clusteredbased on the context clustering algo-rithm presented in Sect.
2 and 3.iv) For each keyword sense, three annotatedcontexts from Senseval-3 training cor-pus are used for the sense mapping.
Thecontext cluster is mapped onto the mostfrequent word sense associated with thecluster members.
By design, the contextclusters correspond to distinct senses,therefore, we do not allow multiple con-text clusters to be mapped onto onesense.
In case multiple clusters corre-spond to one sense, only the largestcluster is retained.v) Each context in the testing corpus istagged with the sense to which its con-text cluster corresponds to.As mentioned above, Sensval-2 English lexicalsample training corpora is used to train the contextpair classification model.
And Sensval-3 Englishlexical sample testing corpora is used here forbenchmarking.
There are several keyword occur-ring in both Senseval-2 and Senseval-3 corpora.The sense tags associated with these keywords arenot used in the context pair classification trainingprocess.In order to gauge the performance of this newweakly supervised learning algorithm, we havealso implemented a supervised Na?ve Bayes sys-tem following (Gale et al 1992).
This system istrained based on the Senseval-3 English LexicalSample training corpus.
In addition, for the pur-pose of quantifying the contribution from the pars-ing structures in WSD, we have run our newsystem with two configurations: (i) using onlytrigger words; (ii) using both trigger words andparsing relationships.
All the benchmarking is per-formed using the Senseval-3 English Lexical Sam-ple testing corpus and standards.The performance benchmarks for the two sys-tems in three runs are shown in Table 1, Table 2and Table 3.
When using only trigger words, thisalgorithm has 8 percentage degradation from thesupervised Na?ve Bayes system (see Table 1 vs.Table 2).
When adding parsing structures, per-formance degradation is reduced, with about 5 per-centage drop (see Table 3 vs. Table 2).
ComparingTable 1 with Table 3, we observe about 3% en-hancement due to the contribution from the parsingsupport in WSD.
The benchmark of our algorithmusing both trigger words and parsing relationshipsis one of the best in unsupervised category of theSenseval-3 Lexical Sample evaluation.Table 1.
New Algorithm Using Only Trigger WordsAccuracyCategory Fine grain (%) Coarse grain (%)Adjective (5) 46.3 60.8Noun (20) 54.6 62.8Verb (32) 54.1 64.2Overall  54.0 63.4Table 2.
Supervised Na?ve Bayes SystemAccuracyCategory Fine grain (%) Coarse grain (%)Adjective (5) 44.7 56.6Noun (20) 66.3 74.5Verb (32) 58.6 70.0Overall 61.6 71.5Table 3.
New Algorithm Using Both Trigger Words andParsingAccuracyCategory Fine grain (%) Coarse grain (%)Adjective (5) 49.1 64.8Noun (20) 57.9 66.6Verb (32) 55.3 66.3Overall 56.3 66.438It is noted that Na?ve Bayes algorithm has manyvariation, and its performance has been greatlyenhanced during recent research.
Based on Sen-seval-3 results, the best Na?ve Bayse system out-perform our version (which is implemented basedon Gale et al 1992) by 8%~10%.
So the best su-pervised WSD systems output-perform our weaklysupervised WSD system by 13%~15% in accuracy.5 ConclusionWe have presented a weakly supervised learningapproach to WSD.
Statistical models are nottrained for the contexts of each individual word,but for context pair classification.
This approachovercomes the knowledge bottleneck that chal-lenges supervised WSD systems which need la-beled data for each individual word.
It captures thecorrelation regularity between the sense distinctionand the context distinction at Part-of-Speech cate-gory level, independent of individual words andsenses.
Hence, it only requires a limited amount ofexisting annotated corpus in order to disambiguatethe full target set of ambiguous words, in particu-lar, the target words that do not appear in the train-ing corpus.The weakly supervised learning scheme cancombine trigger words and parsing structures insupporting WSD.
Using Senseval-3 English Lexi-cal Sample benchmarking, this new approachreaches one of the best scores in the unsupervisedcategory of English Lexical Sample evaluation.This performance is close to the performance forthe supervised Na?ve Bayes system.In the future, we will implement a new schemeto map context clusters onto WordNet senses byexploring WordNet glosses and sample sentences.Based on the new sense mapping scheme, we willbenchmark our system performance using SensevalEnglish all-words corpora.ReferencesDeerwester, S., S. T. Dumais, G. W. Furnas, T. K.Landauer, and R. Harshman.
1990.
Indexing byLatent Semantic Analysis.
In Journal of theAmerican Society of Information ScienceGale, W., K. Church, and D. Yarowsky.
1992.
AMethod for Disambiguating Word Senses in aLarge Corpus.
Computers and the Humanities,26.Goodman, J.
2003.
Exponential Priors for Maxi-mum Entropy Models.
In Proceedings of HLT-NAACL 2004.Landauer, T. K., & Dumais, S. T. 1997.
A solutionto Plato's problem: The Latent Semantic Analy-sis theory of the acquisition, induction, and rep-resentation of knowledge.
PsychologicalReview, 104, 211-240, 1997.Luo, X., A. Ittycheriah, H. Jing, N. Kambhatla andS.
Roukos.
A Mention-Synchronous Corefer-ence Resolution Algorithm Based on the BellTree.
In The Proceedings of ACL 2004.Neal, R.M.
1993.
Probabilistic Inference UsingMarkov Chain Monte Carlo Methods.
TechnicalReport, Univ.
of Toronto.Pietra, S. D., V. D. Pietra, and J. Lafferty.
1995.Inducing Features Of Random Fields.
In IEEETransactions on Pattern Analysis and MachineIntelligence.Sch?tze, H. 1998.
Automatic Word Sense Disam-biguation.
Computational Linguistics, 23.Yarowsky, D. 1995.
Unsupervised Word SenseDisambiguation Rivaling Supervised Methods.In Proceedings of ACL 1995.Zelenko, D., C. Aone and J.
2004.
Tibbetts.Coreference Resolution for Information Extrac-tion.
In Proceedings of ACL 2004 Workshop onReference Resolution and its Application.Zelenko, D., C. Aone and J.
2004.
Tibbetts.
BinaryInteger Programming for Information Extrac-tion.
In Proceedings of ACE 2004 EvaluationWorkshop.39
