Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations, pages 7?12,Baltimore, Maryland USA, June 23-24, 2014.c?2014 Association for Computational LinguisticsVisualization, Search, and Error Analysis for Coreference AnnotationsMarkus G?artner Anders Bj?orkelund Gregor Thiele Wolfgang Seeker Jonas KuhnInstitute for Natural Language ProcessingUniversity of Stuttgart{thielegr,seeker,gaertnms,anders,kuhn}@ims.uni-stuttgart.deAbstractWe present the ICARUS Coreference Ex-plorer, an interactive tool to browse andsearch coreference-annotated data.
It candisplay coreference annotations as a tree,as an entity grid, or in a standard text-based display mode, and lets the userswitch freely between the different modes.The tool can compare two different an-notations on the same document, allow-ing system developers to evaluate errors inautomatic system predictions.
It featuresa flexible search engine, which enablesthe user to graphically construct searchqueries over sets of documents annotatedwith coreference.1 IntroductionCoreference resolution is the task of automaticallygrouping references to the same real-world entityin a document into a set.
It is an active topic in cur-rent NLP research and has received considerableattention in recent years, including the 2011 and2012 CoNLL shared tasks (Pradhan et al., 2011;Pradhan et al., 2012).Coreference relations are commonly repre-sented by sets of mentions, where all mentionsin one set (or coreference cluster) are consideredcoreferent.
This type of representation does notsupport any internal structure within the clusters.However, many automatic coreference resolversestablish links between pairs of mentions whichare subsequently transformed to a cluster by tak-ing the transitive closure over all links, i.e., placingall mentions that are directly or transitively classi-fied as coreferent in one cluster.
This is particu-larly the case for several state-of-the-art resolvers(Fernandes et al., 2012; Durrett and Klein, 2013;Bj?orkelund and Kuhn, 2014).
These pairwise de-cisions, which give rise to a clustering, can be ex-ploited for detailed error analysis and more fine-grained search queries on data automatically an-notated for coreference.We present the ICARUS Coreference Explorer(ICE), an interactive tool to browse and searchcoreference-annotated data.
In addition to stan-dard text-based display modes, ICE features twoother display modes: an entity-grid (Barzilay andLapata, 2008) and a tree view, which makes useof the internal pairwise links within the clusters.ICE builds on ICARUS (G?artner et al., 2013), aplatform for search and exploration of dependencytreebanks.1ICE is geared towards two (typically) distinctusers: The NLP developer who designs corefer-ence resolution systems can inspect the predic-tions of his system using the three different dis-play modes.
Moreover, ICE can compare the pre-dictions of a system to a gold standard annotation,enabling the developer to inspect system errors in-teractively.
The second potential user is the cor-pus linguist, who might be interested in brows-ing or searching a document, or a (large) set ofdocuments for certain coreference relations.
Thebuilt-in search engine of ICARUS now also allowssearch queries over sets of documents in order tomeet the needs of this type of user.2 Data RepresentationICE reads the formats used in the 2011 and 2012CoNLL shared tasks as well as the SemEval 2010format (Recasens et al., 2010).2Since these for-mats cannot accommodate pairwise links, an aux-iliary file with standoff annotation can be pro-vided, which we call allocation.
An allocation is alist of pairwise links between mentions.
Multiple1ICE is written in Java and is therefore platform indepen-dent.
It is open source (under GNU GPL) and we provideboth sources and binaries for download on http://www.ims.uni-stuttgart.de/data/icarus.html2These two formats are very similar tabular formats, butdiffer slightly in the column representations.7allocations can be associated with a single docu-ment and the user can select one of these for dis-play or search queries.
An allocation can also in-clude properties on mentions and links.
The setof possible properties is not constrained, and theuser can freely specify properties as a list of key-value pairs.
Properties on mentions may include,e.g., grammatical gender or number, or informa-tion status labels.
Additionally, a special propertythat indicates the head word of a mention can beprovided in an allocation.
The head property en-ables the user to access head words of mentionsfor display or search queries.The motivation for keeping the allocation fileseparate from the CoNLL or SemEval files is two-fold: First, it allows ICE to work without hav-ing to provide an allocation file, thereby making iteasy to use with the established formats for coref-erence.
The user is still able to introduce addi-tional structure by the use of the allocation file.Second, multiple allocation files allow the user toswitch between different allocations while explor-ing a set of documents.
Moreover, as we will seein Section 3.3, ICE can also compare two differentallocations in order to highlight the differences.In addition to user-specified allocations, ICEwill always by default provide an internal structurefor the clusters, in which the correct antecedentof every mention is the closest coreferent mentionwith respect to the linear order of the document(this is equivalent to the training instance creationheuristic proposed by Soon et al.
(2001)).
There-fore, the user is not required to define an allocationon their own.3 Display ModesIn this section we describe the entity grid and treedisplay modes by means of screenshots.
ICE addi-tionally includes a standard text-based view, sim-ilar to other coreference visualization tools.
Theexample document is taken from the CoNLL 2012development set (Pradhan et al., 2012) and weuse two allocations: (1) the predictions output byBj?orkelund and Kuhn (2014) system (predicted)and (2) a gold allocation that was obtained byrunning the same system in a restricted setting,where only links between coreferent mentions areallowed (gold).
The complete document can beseen in the lower half of Figure 1.3.1 Entity gridBarzilay and Lapata (2008) introduce the entitygrid, a tabular view of entities in a document.Specifically, rows of the grid correspond to sen-tences, and columns to entities.
The cells of the ta-ble are used to indicate that an entity is mentionedin the corresponding sentence.
Entity grids pro-vide a compact view on the distribution of men-tions in a document and allow the user to see howthe description of an entity changes from mentionto mention.Figure 1 shows ICE?s entity-grid view for theexample document using the predicted allocation.When clicking on a cell in the entity grid the im-mediate textual context of the cell is shown in thelower pane.
In Figure 1, the cell with the bluebackground has been clicked, which correspondsto the two mentions firms from Taiwan and they.These mentions are thus highlighted in the lowerpane.
The user can also right-click on a cell andjump straight to the tree view, centered around thesame mentions.3.2 Label PatternsThe information that is displayed in the cells ofthe entity grid (and also on the nodes in the treeview, see Section 3.3) can be fully customized bythe user.
The customization is achieved by defin-ing label patterns.
A label pattern is a string thatspecifies the format according to which a mentionwill be displayed.
The pattern can extract infor-mation on a mention according to three axes: (1)at the token- level for the full mention, extracting,e.g., the sequence of surface forms or the part-of-speech tags of a mention; (2) at the mention- level,extracting an arbitrary property of a mention as de-fined in an allocation; (3) token-level informationfrom the head word of a mention.Label patterns can be defined interactivelywhile displaying a document and the three axes arereferenced by dedicated operators.
For instance,the label pattern $form$ extracts the full surfaceform of a mention, whereas #form# only extractsthe surface form of the head word of a mention.All properties defined by the user in the allocation(see Section 2) are accessible via label patterns.For example, the allocations we use for Fig-ure 1 include a number of properties on thementions, most of which are internally com-puted by the coreference system: The TYPE ofa mention, which can take any of the values8Figure 1: Entity grid over the predicted clustering in the example document.
{Name, Common, Pronoun} and is inferred fromthe part- of-speech tags in the CoNLL file; Thegrammatical NUMBER of a mention, which is as-signed based on the number and gender data com-piled by Bergsma and Lin (2006) and can takethe values {Sin, Plu, Unknown}.
The label pat-tern for displaying the number property associatedwith a mention would be %Number%.The label pattern used in Figure 1 is definedas ("$form$" - %Type% - %Number%).
This pat-tern accesses the full surface form of the mentions($form$), as well as the TYPE (%Type%) and gram-matical NUMBER (%Number%) properties definedin the allocation file.Custom properties and label patterns can beused for example to display the entity grid in theform proposed by Barzilay and Lapata (2008): Inthe allocation, we assign a coarse-grained gram-matical function property (denoted GF) to everymention, where each mention is tagged as eithersubject, object, or other (denoted S, O, X, respec-tively).3The label pattern %GF% then displays thegrammatical function of each mention in the entitygrid, as shown in Figure 2.3.3 Tree viewPairwise links output by an automatic coreferencesystem can be treated as arcs in a directed graph.Linking the first mention of each cluster to an ar-tificial root node creates a tree structure that en-codes the entire clustering in a document.
Thisrepresentation has been used in coreference re-3The grammatical function was assigned by convertingthe phrase-structure trees in the CoNLL file (which lackgrammatical function information) to Stanford dependencies(de Marneffe and Manning, 2008), and then extracting thegrammatical function from the head word in each mention.Figure 2: Example entity grid, using the labels byBarzilay and Lapata (2008).solvers (Fernandes et al., 2012; Bj?orkelund andKuhn, 2014), but ICE uses it to display links be-tween mentions introduced by an automatic (pair-wise) resolver.Figure 3 shows three examples of the tree viewof the same document as before: The gold allo-cation (3a), the predicted allocation (3b), as wellas the differential view, where the two allocationsare compared (3c).
Each mention corresponds toa node in the trees and all mentions are directly ortransitively dominated by the artificial root node.Every subtree under the root constitutes its owncluster and a solid arc between two mentions de-notes that the two mentions are coreferent accord-ing to a coreference allocation.
The informationdisplayed in the nodes of the tree can be cus-tomized using label patterns.In the differential view (Figure 3c), solid arcscorrespond to the predicted allocation.
Dashednodes and arcs are present in the gold allocation,but not in the prediction.
Discrepancies betweenthe predicted and the gold allocations are marked9(a) Tree representing the gold allocation.
(b) Tree representing the predicted allocation.
(c) Differential view displaying the difference between the gold and predicted allocations.Figure 3: Tree view over the example document (gold, predicted, differential).with different colors denoting different types of er-rors.
The example in Figure 3c contains two errorsmade by the system:1.
A false negative mention, denoted by thedashed red node Shangtou.
In the goldstandard (Figure 3a) this mention is clus-tered with other mentions such as Shantou ?s,Shantou City, etc.
The dashed arc betweenShantou ?s and Shangtou is taken from thegold allocation, and indicates what the sys-tem prediction should have been like.42.
A foreign antecedent, denoted by the solidorange arc between Shantou ?s new high leveltechnology development zone and Shantou.In this case, the coreference system erro-neously clustered these two mentions.
Thecorrect antecedent is indicated by the dashedarc that originates from the document root.4This error likely stems from the fact that Shantou isspelled two different ways within the same document whichcauses the resolver?s string-matching feature to fail.This error is particularly interesting since thesystem effectively merges the two clusterscorresponding to Shantou and Shantou?
s newhigh level technology development zone.
Thetree view, however, shows that the error stemsfrom a single link between these two men-tions, and that the developer needs to addressthis.Since the tree-based view makes pairwise de-cisions explicit, the differential view shown inFigure 3c is more informative to NLP develop-ers when inspecting errors by automatic systemthan comparing a gold standard clustering to a pre-dicted one.
The problem with analyzing the erroron clusterings instead of trees is that the clusterswould be merged, i.e., it is not clear where the ac-tual mistake was made.Additional error types not illustrated by Fig-ure 3c include false positive mentions, wherethe system invents a mention that is not partof the gold allocation.
When a false positivemention is assigned as an antecedent of another10mention, the corresponding link is marked as aninvented antecedent.
Links that erroneously starta new cluster when it is coreferent with other men-tions to the left is marked as false new.4 SearchingThe search engine in ICE makes the annotationsin the documents searchable for, e. g., a corpus lin-guist who is interested in specific coreference phe-nomena.
It allows the user to express queries overmentions related through the tree.
Queries can ac-cess the different layers of annotation, both fromthe allocation file and the underlying document,using various constructs such as, e.g., transitivity,regular expressions, and/or disjunctions.
The usercan construct queries either textually (through aquery language) or graphically (by creating nodesand configuring constraints in dialogues).
For afurther discussion of the search engine we refer tothe original ICARUS paper (G?artner et al., 2013).Figure 4 shows a query that matches cataphoricpronouns, i.e., pronouns that precede their an-tecedents.
The figure shows the query expressedas a subgraph (on the left) and the correspondingresults (right) obtained on the development set ofthe English CoNLL 2012 data using the manualannotation represented in the gold allocation.The query matches two mentions that are di-rectly or transitively connected through the graph.The first mention (red node) matches mentions ofthe type Pronoun that have to be attached to thedocument root node.
In the tree formalism weadopt, this implies that it must be the first men-tion of its cluster.
The second mention (greennode) matches any mention that is not of the typePronoun.
(a)(b)Figure 4: Example search query and correspond-ing results.The search results are grouped along two axes:the surface form of the head word of the first (red)node, and the type property of the second mention(green node), indicated by the special groupingoperator <*> inside the boxes.
The correspond-ing results are shown in the right half of Figure 4,where the first group (surface form) runs verti-cally, and the second group (mention type) runshorizontally.
The number of hits for each configu-ration is shown in the corresponding cell.
For ex-ample, the case that the first mention of a chain isthe pronoun I and the closest following coreferentmention that is not a pronoun is of type Common,occurs 6 times.
By clicking on a cell, the user canjump straight to a list of the matches, and browsethem using any of the three display modes.5 Related WorkTwo popular annotation and visualization toolsfor coreference are PAlinkA (Or?asan, 2003) andMMAX2 (M?uller and Strube, 2006), which fo-cus on a (customizable) textual visualization withhighlighting of clusters.
The TrED (Pajas and?St?ep?anek, 2009) project is a very flexible multi-level annotation tool centered around tree-basedannotations that can be used to annotate and vi-sualize coreference.
It also features a powerfulsearch engine.
Recent annotation tools include theweb-based BRAT (Stenetorp et al., 2012) and itsextension WebAnno (Yimam et al., 2013).
A ded-icated query and exploration tool for multi-levelannotations is ANNIS (Zeldes et al., 2009).The aforementioned tools are primarily meantas annotation tools.
They have a tendency of lock-ing the user into one type of visualization (tree- ortext-based), while often lacking advanced searchfunctionality.
In contrast to them, ICE is not meantto be yet another annotation tool, but was designedas a dedicated coreference exploration tool, whichenables the user to swiftly switch between differ-ent views.
Moreover, none of the existing toolsprovide an entity-grid view.ICE is also the only tool that can graphicallycompare predictions of a system to a gold standardwith a fine-grained distinction on the types of dif-ferences.
Kummerfeld and Klein (2013) presentan algorithm that transforms a predicted corefer-ence clustering into a gold clustering and recordsthe necessary transformations, thereby quantify-ing different types of errors.
However, their algo-rithm only works on clusterings (sets of mentions),not pairwise links, and is therefore not able to pin-point some of the mistakes that ICE can (such asthe foreign antecedent described in Section 3).116 ConclusionWe presented ICE, a flexible coreference visual-ization and search tool.
The tool complementsstandard text-based display modes with entity-gridand tree visualizations.
It is also able to dis-play discrepancies between two different corefer-ence annotations on the same document, allow-ing NLP developers to debug coreference sys-tems in a graphical way.
The built-in search en-gine allows corpus linguists to construct complexsearch queries and provide aggregate result viewsover large sets of documents.
Being based on theICARUS platform?s plugin-engine, ICE is extensi-ble and can easily be extended to cover additionaldata formats.AcknowledgmentsThis work was funded by the German FederalMinistry of Education and Research (BMBF) viaCLARIN-D, No.
01UG1120F and the GermanResearch Foundation (DFG) via the SFB 732,project D8.ReferencesRegina Barzilay and Mirella Lapata.
2008.
Model-ing Local Coherence: An Entity-Based Approach.Computational Linguistics, 34(1):1?34.Shane Bergsma and Dekang Lin.
2006.
Bootstrappingpath-based pronoun resolution.
In COLING-ACL,pages 33?40, Sydney, Australia, July.Anders Bj?orkelund and Jonas Kuhn.
2014.
LearningStructured Perceptrons for Coreference Resolutionwith Latent Antecedents and Non-local Features.
InACL, Baltimore, MD, USA, June.Marie-Catherine de Marneffe and Christopher D. Man-ning.
2008.
The stanford typed dependenciesrepresentation.
In COLING Workshop on Cross-framework and Cross-domain Parser Evaluation.Greg Durrett and Dan Klein.
2013.
Easy Victo-ries and Uphill Battles in Coreference Resolution.In EMNLP, pages 1971?1982, Seattle, Washington,USA, October.Eraldo Fernandes, C?
?cero dos Santos, and Ruy Milidi?u.2012.
Latent Structure Perceptron with Feature In-duction for Unrestricted Coreference Resolution.
InEMNLP-CoNLL: Shared Task, pages 41?48, Jeju Is-land, Korea, July.Markus G?artner, Gregor Thiele, Wolfgang Seeker, An-ders Bj?orkelund, and Jonas Kuhn.
2013.
ICARUS?
An Extensible Graphical Search Tool for Depen-dency Treebanks.
In ACL: System Demonstrations,pages 55?60, Sofia, Bulgaria, August.Jonathan K. Kummerfeld and Dan Klein.
2013.
Error-Driven Analysis of Challenges in Coreference Res-olution.
In EMNLP, pages 265?277, Seattle, Wash-ington, USA, October.Christoph M?uller and Michael Strube.
2006.
Multi-level annotation of linguistic data with MMAX2.
InCorpus Technology and Language Pedagogy: NewResources, New Tools, New Methods, pages 197?214.
Peter Lang.Constantin Or?asan.
2003.
PALinkA: A highly cus-tomisable tool for discourse annotation.
In AkiraKurematsu, Alexander Rudnicky, and Syun Tutiya,editors, Proceedings of the Fourth SIGdial Work-shop on Discourse and Dialogue, pages 39?43.Petr Pajas and Jan?St?ep?anek.
2009.
System forQuerying Syntactically Annotated Corpora.
In ACL-IJCNLP: Software Demonstrations, pages 33?36,Suntec, Singapore.Sameer Pradhan, Lance Ramshaw, Mitchell Marcus,Martha Palmer, Ralph Weischedel, and NianwenXue.
2011.
CoNLL-2011 Shared Task: ModelingUnrestricted Coreference in OntoNotes.
In CoNLL:Shared Task, pages 1?27, Portland, Oregon, USA,June.Sameer Pradhan, Alessandro Moschitti, Nianwen Xue,Olga Uryupina, and Yuchen Zhang.
2012.
CoNLL-2012 Shared Task: Modeling Multilingual Unre-stricted Coreference in OntoNotes.
In EMNLP-CoNLL: Shared Task, pages 1?40, Jeju Island, Ko-rea, July.Marta Recasens, Llu?
?s M`arquez, Emili Sapena,M.
Ant`onia Mart?
?, Mariona Taul?e, V?eronique Hoste,Massimo Poesio, and Yannick Versley.
2010.Semeval-2010 task 1: Coreference resolution inmultiple languages.
In Proceedings of the 5th Inter-national Workshop on Semantic Evaluation, pages1?8, Uppsala, Sweden, July.Wee Meng Soon, Hwee Tou Ng, and DanielChung Yong Lim.
2001.
A machine learning ap-proach to coreference resolution of noun phrases.Computational Linguistics, 27(4):521?544.Pontus Stenetorp, Sampo Pyysalo, Goran Topi?c,Tomoko Ohta, Sophia Ananiadou, and Jun?ichi Tsu-jii.
2012. brat: a Web-based Tool for NLP-AssistedText Annotation.
In EACL: Demonstrations, pages102?107, April.Seid Muhie Yimam, Iryna Gurevych, RichardEckart de Castilho, and Chris Biemann.
2013.WebAnno: A Flexible, Web-based and VisuallySupported System for Distributed Annotations.
InACL: System Demonstrations, pages 1?6, August.Amir Zeldes, Julia Ritz, Anke L?udeling, and ChristianChiarcos.
2009.
ANNIS: a search tool for multi-layer annotated corpora.
In Proceedings of CorpusLinguistics.12
