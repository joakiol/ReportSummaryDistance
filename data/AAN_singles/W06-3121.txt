Proceedings of the Workshop on Statistical Machine Translation, pages 146?149,New York City, June 2006. c?2006 Association for Computational LinguisticsPhramer - An Open Source Statistical Phrase-Based TranslatorMarian Olteanu, Chris Davis, Ionut Volosen and Dan MoldovanHuman Language Technology Research InstituteThe University of Texas at DallasRichardson, TX 75080{marian,phoo,volosen,moldovan}@hlt.utdallas.eduAbstractThis paper describes the open-sourcePhrase-Based Statistical Machine Transla-tion Decoder - Phramer.
The paper alsopresents the UTD (HLTRI) system buildfor the WMT06 shared task.
Our goal wasto improve the translation quality by en-hancing the translation table and by pre-processing the source language text1 IntroductionDespite the fact that the research in StatisticalMachine Translation (SMT) is very active, thereisn?t an abundance of open-source tools availableto the community.
In this paper, we presentPhramer, an open-source system that embeds aphrase-based decoder, a minimum error rate train-ing (Och, 2003) module and various tools relatedto Machine Translation (MT).
The software is re-leased under BSD license and it is available athttp://www.phramer.org/.We also describe our Phramer-based systemthat we build for the WMT06 shared task.2 PhramerPhramer is a phrase-based SMT system written inJava.
It includes:?
A decoder that is compatible with Pharaoh(Koehn, 2004),?
A minimum error rate training (MERT) mod-ule, compatible with Phramer?s decoder, withPharaoh and easily adaptable to other SMTor non-SMT tasks and?
various tools.The decoder is fully compatible with Pharaoh1.2 in the algorithms that are implemented, inputfiles (configuration file, translation table, languagemodels) and command line.
Some of the advantagesof Phramer over Pharaoh are: (1) source codeavailability and its permissive license; (2) it is veryfast (1.5?3 times faster for most of the configura-tions); (3) it can work with various storage layers forthe translation table (TT) and the language models(LMs): memory, remote (access through TCP/IP),disk (using SQLite databases1).
Extensions for otherstorage layers can be very easily implemented; (4) itis more configurable; (5) it accepts compressed datafiles (TTs and LMs); (6) it is very easy to extend; anexample is provided in the package ?
part-of-speechdecoding on either source language, target languageor both; support for POS-based language models;(7) it can internally generate n-best lists.
Thus noexternal tools are required.The MERT module is a highly modular, efficientand customizable implementation of the algorithmdescribed in (Och, 2003).
The release has imple-mentations for BLEU (Papineni et al, 2002), WERand PER error criteria and it has decoding interfacesfor Phramer and Pharaoh.
It can be used tosearch parameters over more than one million vari-ables.
It offers features as resume search, reuse hy-potheses from previous runs and various strategiesto search for optimal ?
weight vectors.1http://www.sqlite.org/146The package contains a set of tools that include:?
Distributed decoding (compatible with bothPhramer and Pharaoh) ?
it automaticallysplits decoding jobs and distributes them toworkers and assembles the results.
It is compat-ible with lattice generation, therefore it can alsobe used during weights search (using MERT).?
Tools to process translation tables ?
filter theTT based on the input file, flip TT to reuse itfor English-to-Foreign translation, filter the TTby phrase length, convert the TT to a database.3 WMT06 Shared TaskWe have assembled a system for participation in theWMT 2006 shared task based on Phramer andother tools.
We participated in 5 subtasks: DE?EN,FR?EN, ES?EN, EN?FR and EN?ES.3.1 Baseline system3.1.1 Translation table generationTo generate a translation table for each pair of lan-guages starting from a sentence-aligned parallel cor-pus, we used a modified version of the Pharaohtraining software 2.
The software also requiredGIZA++ word alignment tool(Och and Ney, 2003).We generated for each phrase pair in the trans-lation table 5 features: phrase translation probabil-ity (both directions), lexical weighting (Koehn et al,2003) (both directions) and phrase penalty (constantvalue).3.1.2 DecoderThe Phramer decoder was used to translate thedevtest2006 and test2006 files.
We accelerated thedecoding process by using the distributed decodingtool.3.1.3 Minimum Error Rate TrainingWe determined the weights to combine the mod-els using the MERT component in Phramer.
Be-cause of the time constrains for the shared task sub-mission3, we used Pharaoh + Carmel4 as the de-2http://www.iccs.inf.ed.ac.uk/?pkoehn/training.tgz3After the shared task submission, we optimized a lot ourdecoder.
Before the optimizations (LM optimizations, fixingbugs that affected performance), Phramer was 5 to 15 timesslower than Pharaoh.4http://www.isi.edu/licensed-sw/carmel/coder for the MERT algorithm.3.1.4 PreprocessingWe removed from the source text the words thatdon?t appear either in the source side of the train-ing corpus (thus we know that the translation tablewill not be able to translate them) or in the lan-guage model for the target language (and we esti-mate that there is a low chance that the untranslatedword might actually be part of the reference transla-tion).
The purpose of this procedure is to minimizethe risk of inserting words into the automatic trans-lation that are not in the reference translation.We applied this preprocessing step only when thetarget language was English.3.2 Enhancements to the baseline systemsOur goal was to improve the translation quality byenhancing the the translation table.The following enhancements were implemented:?
reduce the vocabulary size perceived by theGIZA++ and preset algnment for certainwords?
?normalize?
distortion between pairs of lan-guages by reordering noun-adjective construc-tionsThe first enhancement identifies pairs of tokens inthe parallel sentences that, with a very high proba-bility, align together and they don?t align with othertokens in the sentence.
These tokens are replacedwith a special identifier, chosen so that GIZA++ willlearn the alignment between them easier than beforereplacement.
The targeted token types are propernouns (detected when the same upper-cased tokenwere present in both the foreign sentence and theEnglish sentence) and numbers, also taking into ac-count the differences between number representa-tion in different languages (i.e.
: 399.99 vs. 399,99).Each distinct proper noun to be replaced in the sen-tence was replaced with a specific identifier, distinctfrom other replacement identifiers already used inthe sentence.
The same procedure was applied alsofor numbers.
The specific identifiers were reused inother sentences.
This has the effect of reducing thevocabulary, thus it provides a large number of in-stances for the special token forms.
The change in147yoIwastherapporteuronromaniafortheparliamentaryassemblyofthecounciloffuiponentedela asambleaparlamentariadelconsejode europapararuman?a..europeyoIwastherapporteuronromaniafortheparliamentaryassemblyofthecounciloffuiponentedela asambleaparlamentariadelconsejode europapararuman?a..europebefore reordering after reorderingFigure 1: NN-ADJ reorderingCorpus Before AfterDE 195,290 184,754FR 80,348 70,623ES 102,885 92,827Table 1: Vocabulary size change due to forced align-mentthe vocabulary size is shown in Table 1.
To simplifythe process, we limited the replacement of tokensto one-to-one (one real token to one special token),so that the word alignment file can be directly usedtogether with the original parallel corpus to extractphrases required for the generation of the translationtable.
Table 2 shows an example of the output.The second enhancement tries to improve thequality of the translation by rearranging the words inthe source sentence to better match the correct wordorder in the target language (Collins et al, 2005).We focused on a very specific pattern ?
based on thepart-of-speech tags, changing the order of NN-ADJphrases in the non-English sentences.
This processwas also applied to the input dev/test files, when thetarget language was English.
Figure 1 shows the re-ordering process and its effect on the alignment.The expected benefits are:?
Better word alignment due to an alignmentcloser to the expected alignment (monotone).?
More phrases extracted from the word alignedcorpus.
Monotone alignment tends to generatemore phrases than a random alignment.?
Higher mixture weight for the monotone dis-tortion model because of fewer reordering con-straints during MERT, thus the value of themonotone distortion model increases, ?tighten-ing?
the translation.3.3 Experimental SetupWe implemented the first enhancement on ES?ENsubtask by part-of-speech tagging the Spanish textusing TreeTagger5 followed by a NN-ADJ inver-sion heuristic.The language models provided for the task wasused.We used the 1,000 out of the 2,000 sentencesin each of the dev2006 datasets to determineweights for the 8 models used during decoding (onemonotone distortion mode, one language model,five translation models, one sentence length model)through MERT.
The weights were determined in-dividually for each pair of source-target languages.5http://www.ims.uni-stuttgart.de/projekte/corplex/TreeTagger/DecisionTreeTagger.html148There are 145 settlements in the West Bank , 16 in Gaza , 9 in East Jerusalem ; 400,000 people live in them .Existen 145 asentamientos en Cisjordania , 16 en Gaza y 9 en Jerusaln Este ; en ellos viven 400.000 personas .There are [x1] settlements in the West Bank , [x2] in [y1] , [x3] in East Jerusalem ; [x4] people live in them .Existen [x1] asentamientos en Cisjordania , [x2] en [y1] y [x3] en Jerusaln Este ; en ellos viven [x4] personas .Table 2: Forced alignment exampleOOV forced NN-ADJ BLEUSubtask filtering alignment inversion scoreDE?EN??
?
25.45?
??
25.53FR?EN??
?
30.70?
??
30.70ES?EN??
?
30.77?
??
30.84?
?
?30.92EN?FR ?
?
?
31.67???
31.79EN?ES ?
?
?
30.17???
30.11Table 3: Results on the devtest2006 filesSubtask BLEU 1/2/3/4-gram precision (bp)DE?EN 22.96 58.8/28.8/16.5/9.9 (1.000)FR?EN 27.78 61.8/33.6/21.0/13.7 (1.000)ES?EN 29.93 63.5/36.0/23.0/15.2 (1.000)EN?FR 28.87 60.0/34.7/22.7/15.2 (0.991)EN?ES 29.00 62.9/35.8/23.0/15.1 (0.975)Table 4: Results on the test2006 filesUsing these weights, we measured the BLEU scoreon the devtest2006 datasets.
Based on the modelchosen, we decoded the test2006 datasets using thesame weights as for devtest2006.3.4 ResultsTable 3 presents the results on the devtest2006 filesusing different settings.
Bold values represent theresult for the settings that were also chosen for thefinal test.
Table 4 shows the results on the submittedfiles (test2006).3.5 ConclusionsThe enhancements that we proposed provide smallimprovements on the devtest2006 files.
As expected,when we used the NN-ADJ inversion the ratio ?D?LMincreased from 0.545 to 0.675.
The LM is the onlymodel that opposes the tendency of the distortionmodel towards monotone phrase order.Phramer delivers a very good baseline system.Using only the baseline system, we obtain +0.68 onDE?EN, +0.43 on FR?EN and -0.18 on ES?ENdifference in BLEU score compared to WPT05?sbest system (Koehn and Monz, 2005).
This fact iscaused by the MERT module.
This module is capa-ble of estimating parameters over a large develop-ment corpus in a reasonable time, thus it is able togenerate highly relevant parameters.ReferencesMichael Collins, Philipp Koehn, and Ivona Kucerova.2005.
Clause restructuring for statistical machinetranslation.
In Proceedings of the 43rd Annual Meet-ing of the Association for Computational Linguis-tics (ACL?05), pages 531?540, Ann Arbor, Michigan,June.
Association for Computational Linguistics.Philipp Koehn and Christof Monz.
2005.
Shared task:Statistical machine translation between European lan-guages.
In Proceedings of the ACL Workshop onBuilding and Using Parallel Texts, pages 119?124,Ann Arbor, Michigan, June.
Association for Compu-tational Linguistics.Philipp Koehn, Franz Josef Och, and Daniel Marcu.2003.
Statistical phrase-based translation.
In Proceed-ings of HLT/NAACL 2003, Edmonton, Canada.Philipp Koehn.
2004.
Pharaoh: A beam search decoderfor phrase-based statistical machine translation mod-els.
In Proceedings of AMTA.Franz Josef Och and Hermann Ney.
2003.
A system-atic comparison of various statistical alignment mod-els.
Computational Linguistics, 29(1):19?51.Franz Josef Och.
2003.
Minimum error rate trainingin statistical machine translation.
In Erhard Hinrichsand Dan Roth, editors, Proceedings of the 41st AnnualMeeting of the Association for Computational Linguis-tics, pages 160?167.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
Bleu: a method for automatic evalua-tion of machine translation.
In Proceedings of the 40thAnnual Meeting of the Association for ComputationalLinguistics (ACL), pages 311?318.149
