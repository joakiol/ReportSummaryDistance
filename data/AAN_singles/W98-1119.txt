A Statistical Approach to Anaphora ResolutionNiyu  Ge, John  Hale and Eugene Charn iakDept.
of Computer Science,Brown University,\[nge I j th \[ ec\] ~cs.
brown, eduAbst ractThis paper presents an algorithm for identi-fying pronominal anaphora and two experi-ments based upon this algorithm.
We incorpo-rate multiple anaphora resolution factors intoa statistical framework - -  specifically the dis-tance between the pronoun and the proposedantecedent, gender/number/animaticity of theproposed antecedent, governing head informa-tion and noun phrase repetition.
We combinethem into a single probability that enables usto identify the referent.
Our first experimentshows the relative contribution of each sourceOf information and demonstrates a uccess rateof 82.9% for all sources combined.
The secondexperiment investigates a method for unsuper-vised learning of gender/number/animaticityinformation.
We present some experiments il-lustrating the accuracy of the method and notethat with this information added, our pronounresolution method achieves 84.2% accuracy.1 In t roduct ionWe present a statistical method for determin-ing pronoun anaphora.
This program differsfrom earlier work in its almost complete lack ofhand-crafting, relying instead on a very smallcorpus of Penn Wall Street Journal Tree-banktext (Marcus et al, 1993) that has been markedwith co-reference information.
The first sectionsof this paper describe this program: the proba-bilistic model behind it, its implementation, andits performance.The second half of the paper describes amethod for using (portions of) t~e aforemen-tioned program to learn automatically the typi-cal gender of English words, information that isitself used in the pronoun resolution program.In particular, the scheme infers the gender of areferent from the gender of the pronouns that161refer to it and selects referents using the pro-noun anaphora program.
We present some typ-ical results as well as the more rigorous resultsof a blind evaluation of its output.2 A Probabi l i s t ic  Mode lThere are many factors, both syntactic and se-mantic, upon which a pronoun resolution sys-tem relies.
(Mitkov (1997) does a detailed studyon factors in anaphora resolution.)
We first dis-cuss the training features we use and then derivethe probability equations from them.The first piece of useful information we con-sider is the distance between the pronounand the candidate antecedent.
Obviously thegreater the distance the lower the probability.Secondly, we look at the syntactic situation inwhich the pronoun finds itself.
The most wellstudied constraints are those involving reflexivepronouns.
One classical approach to resolvingpronouns in text that takes some syntactic fac-tors into consideration is that of Hobbs (1976).This algorithm searches the parse tree in a left-to-right, breadth-first fashion that obeys themajor reflexive pronoun constraints while giv-ing a preference to antecedents hat are closerto the pronoun.
In resolving inter-sententialpronouns, the algorithm searches the previoussentence, again in left-to-right, breadth-first or-der.
This implements the observed preferencefor subject position antecedents.Next, the actual words in a proposed noun-phrase antecedent give us information regardingthe gender, number, and animaticity of the pro-posed referent.
For example:Mar ie  Giraud carries historical sig-nificance as one of the last women tobe ezecuted in France.
She  becamean abortionist because it enabled her tobuy jam, cocoa and other war-rationedgoodies.Here it is helpful to recognize that "Marie" isprobably female and thus is unlikely to be re-ferred to by "he" or "it".
Given the words in theproposed antecedent we want to find the prob-ability that it is the referent of the pronoun inquestion.
We collect these probabilities on thetraining data, which are marked with referencelinks.
The words in the antecedent sometimesalso let us test for number agreement.
Gener-ally, a singular pronoun cannot refer to a pluralnoun phrase, so that in resolving such a pro-noun any plural candidates should be ruled out.However a singular noun phrase can be the ref-erent of a plural pronoun, as illustrated by thefollowing example:"I think if I tell Viacom I need moretime, they will take 'Cosby' across thestreet," says the general manager ol anetwork a~liate.It is also useful to note the interaction be-tween the head constituent of the pronoun pand the antecedent.
For example:A Japanese company might make tele-vision picture tubes in Japan, assem-ble the TV  sets in Malaysia and extortthem to Indonesia.Here we would compare the degree to whicheach possible candidate antecedent (A Japanesecompany, television picture tubes, Japan, TVsets, and Malaysia in this example) could serveas the direct object of "export".
These proba-bilities give us a way to implement selectionalrestriction.
A canonical example of selectionalrestriction is that of the verb "eat", which se-lects food as its direct object.
In the case of"export" the restriction is not as clearcut.
Nev-ertheless it can still give us guidance on whichcandidates are more probable than others.The last factor we consider is referents' men-tion count.
Noun phrases that are mentionedrepeatedly are preferred.
The training corpus ismarked with the number of times a referent hasbeen mentioned up to that point in the story.Here we are concerned with the probability thata proposed antecedent is correct given that ithas been repeated a certain number of times.162In effect, we use this probability information toidentify the topic of the segment with the beliefthat the topic is more likely to be referred to bya pronoun.
The idea is similar to that used inthe centering approach (Brennan et al, 1987)where a continued topic is the highest-rankedcandidate for pronominalization.Given the above possible sources of informartion, we arrive at the following equation, whereF(p) denotes a function from pronouns to theirantecedents:F(p) = argmaxP( A(p) = alp, h, l~', t, l, so, d~ A~')where A(p) is a random variable denoting thereferent of the pronoun p and a is a proposedantecedent.
In the conditioning events, h is thehead constituent above p, l~ r is the list of candi-date antecedents o be considered, t is the typeof phrase of the proposed antecedent (alwaysa noun-phrase in this study), I is the type ofthe head constituent, sp describes the syntacticstructure in which p appears, dspecifies the dis-tance of each antecedent from p and M" is thenumber of times the referent is mentioned.
Notethat 17r ", d'~ and A~ are vector quantities in whicheach entry corresponds to a possible antecedent.When viewed in this way, a can be regarded asan index into these vectors that specifies whichvalue is relevant o the particular choice of an-tecedent.This equation is decomposed into pieces thatcorrespond to all the above factors but are morestatistically manageable.
The decompositionmakes use of Bayes' theorem and is based oncertain independence assumptions discussed be-low.P( A(p) = alp, h, fir, t, l, sp, d~ .Q')= P(alA~)P(p,h, fir, t,l, sp,~a, 2~) (1)P(p, h, fir, t, t, sp, diM )o?
PCalM)P(p, h, fir, t, l, sp, ~a, .Q') (2)= P(a\[:Q)P(.%, ~a, :~'I)P(p,h, fir, t, l la,~,sp, i) (3)= P(all~)P(sp, d~a,.Q )PCh, t, Zla, ~'0", so, i)PC.. ~la,  .~', so, d, h, t, l) (4)oc P(a\]l~)P(So,~a,M')P(p, 14tin, \]Q, s o, d, h, t, I) (5)= P(al.Q)P(sp, d~a, 3~r)P(ffrla, I~, s o, d, h, t, I).
(6)P(pla.
l~, sf,, d. h, t, l, l~)cx P(a163P(dttla)P(ff' lh, t, I, a)P(plw?)
(7)Equation (1) is simply an application of Bayes'rule.
The denominator is eliminated in theusual fashion, resulting in equation (2).
Selec-tively applying the chain rule results in equa-tions (3) and (4).
In equation (4), the termP(h. t, lla, .~, So, d) is the same for every an-tecedent and is thus removed.
Equation (6)follows when we break the last component of(5) into two probability distributions.
In equa-tion (7) we make the following independence as-sumptions:?
Given a particular choice of the antecedentcandidates, the distance is independent ofdistances of candidates other than the an-tecedent (and the distance to non-referentscan be ignored):P(so, d~a, 2~) o?
P(so, dola , IC4)?
The syntnctic structure st, and the distancefrom the pronoun da are independent of thenumber of times the referent is mentioned.ThusP(sp, dola, M) = P(sp, d.la)Then we combine sp and de into one vari-able dIt, Hobbs distance, since the Hobbsalgorithm takes both the syntax and dis-tance into account.The words in the antecedent depend onlyon the parent constituent h, the type of thewords t, and the type of the parent I. Hencee(ff'la, M, sp, ~, h, t, l) = P (~ lh ,  t, l, a)?
The choice pronoun depends only on thewords in the antecedent, i.e.P{pla, M, sp, d, h, t, l, ~ = P(pla, W)163?
If we treat a as an index into the vector 1~,then (a, I.V') is simply the ath candidate inthe list ffz.
We assume the selection of thepronoun is independent of the candidatesother than the antecedent.
HenceP(pla, W) = P(plw,~)Since I~" is a vector, we need to normal-ize P(ff'lh, t,l, a) to obtain the probability ofeach element in the vector.
It is reason-able to assume that the antecedents in W areindependent of each other; in other words,P(wo+llwo, h,t , l ,a) = P(wo+llh, t,l,a}.
Thus,wherenP(ff ' lh, t, l, a) = 1 I  P(wil h, t, l, a)i= lP(wdh, t, l, a) = P(wilt) if i # aandP(wdh, t, l ,a) = P(wolh.
t,l) if i = aThen we have,P(ff'lh, t,l, a) = P(wt l t ) .
.
.P(wolh,  t , l ) .
.
.
P (w,  lt)To get the probability for each candidate, wedivide the above product by:f ( I~lh,  t, l ,a)P(wllt) .
.
.P(wolh, t, l) .
.
.P(w,  ltJOCe(w~lt) .
.
.P(w~lt) .
.
.P (w,  lt)P(w~lh, t,t)P(w?lt)Now we arrive at the final equation for comput-ing the probability of each proposed antecedent:P(A(p) = Wo) (S)P{dHIa)P(plw.)
P ~  l )p(a lm.
)We obtain P(dH\[a) by running the Hobbs al-gorithm on the training data.
Since the train-ing corpus is tawed with reference informa-tion, the probability P(plWo) is easily obtained.In building a statistical parser for the PennTree-bank various statLstics have been collected(Charniak, 1997), two of which are P(w~lh, t, l)and P(w~lt , l).
To avoid the sparse-data prob-lem, the heads h are clustered according to howthey behave in P(w~lh, t, l).
The probability ofwe is then computed on the basis of h's clus-ter c(h).
Our corpus also contains referewts'repetition information, from which we can di-rectly compute P(alrna ).
The four componentsin equation (8) can be estimated in a reason-able fashion.
The system computes this productand returns the antecedent t0o for a pronoun pthat maximizes this probability.
More formally,we want the program to return our antecedentfunction F(p), whereF(p)= arg maax P(A(p) = alp, h, 1~, t, l, sp, d: M)= argmaxP(dH\[a)P(plwa)112ae(walh, t,t) e(almo )P(wolt, t)3 The  Implementat ionWe use a small portion of the Penn Wall StreetJournal Tree-bank as our training corpus.
Fromthis data, we collect the three statistics detailedha the following subsections.3.0.1 The  Hobbs a lgor i thmThe Hobbs algorithm makes a few assumptionsabout the syntactic trees upon which it operatesthat are not satisfied by the tree-bank trees thatform the substrate for our algorithm.
Most no-tably, the Hobbs algorithm depends on the ex-istence of an/~" parse-tree node that is absentfrom the Penn Tree-bank trees.
We have im-plemented a slightly modified version of Hobbsalgorithm for the Tree-bank parse trees.
Wealso transform our trees under certain condi-tions to meet Hobbs' assumptions as much aspossible.
We have not, however, been able toduplicate exactly the syntactic structures as-sumed by Hobbs.Once we have the trees in the proper form(to the degree this is possible) we run Hobbs'algorithm repeatedly for each pronoun until ithas proposed n (= 15 in our experiment) can-didates.
The ith candidate is regarded as oc-curring at "Hobbs distance" dH = i.
Then theprobability P(dH = ila) is simply:P(du -= ila)164I correct antecedent at Hobbs distance i i\[ correct antecedents 1We use \[ z \[ to denote the number of times z isobserved in our training set.3.1 The  gender /an imat ic i ty  stat ist icsAfter we have identified the correct antecedentsit is a simple counting procedure to computeP(p\[wa) where wa is in the correct antecedentfor the pronoun p (Note the pronouns aregrouped by their gender):\[ wain the antecedent for p \[P(pl o) =When there are multiple relevant words in theantecedent we apply the likelihood test designedby Dunning (1993) on all the words in the candi-date NP.
Given our limited data, the Dunningtest tells which word is the most informative,call it w i, and we then use P(p\[wi).3.1.1 The  ment ion  count  stat ist icsThe referents range from being mentioned onlyonce to begin mentioned 120 times in the train-hag examples.
Instead of computing the proba-bUity for each one of them we group them into"buckets", so that rrt a iS the bucket for the num-ber of times that a is mentioned.
We also ob-serve that the position of a pronoun in a storyinfluences the mention count of its referent.
Inother words, the nearer the end of the story apronoun occurs, the more probable it is thatits referent has been mentioned several times.We measure position by the sentence number,j .
The method to compute this probability is:\[ a is antecedent, rna, j IP(alm~, j) = I ms, j l(We omitted j from equations (1-7) to reducethe notational load.
)3.2 Resolv ing PronounsAfter collecting the statistics on the training ex-anaples, we run the program on the test data.For any pronoun we collect n(= 15 in the ex-periment) candidate antecedents proposed byHobbs' algorithm.
It is quite possible that aword appears in the test data that the programnever saw in the training data and low which ithence has no P(plwo) probability.
In this caseProbabilityModelP(dH)P(plwa)P(w lh, t,l)P(alm.
)PercentCorrect65.3%75.7%77.9%82.9%StandardDeviationSignifi-canceLevel0.0610.039 < 0.0050.046 > 0.10.042 > 0.01< 0.025Table 1: Cross-validation: incremental resultswe simply use the prior probability of the pro-noun P(p).
From the parser project mentionedearlier, we obtain the probability e(Wolh,tJ/ Fi- P(w, It,t) "nally, we extract he mention count number as-sociated with each candidate NP, which is usedto obtain P(alrn,).
The four probabilities aremultiplied together.
The procedure is repeatedfor each proposed NP in l~" and the one withthe highest combined probability is selected asthe antecedent.4 The  Exper imentThe algorithm has two modules.
One collectsthe statistics on the training corpus required byequation (8) and the other uses these probabil-ities to resolve pronouns in the test corpus.Our data consists of 93,931 words (3975 sen-tences) and contains 2477 pronouns, 1371 ofwhich are singular (he, she and it).
The corpusis manually tagged with reference indices andreferents" repetition numbers.
The result pre-sented here is the accuracy of the program infinding antecedents for he, she, and it and theirvarious forms (e.g.
him, his, himself, etc.)
Thecases where "it" is merely a dummy subject ina cleft sentence (example 1) or has conventionalunspecified referents (example 2) are excludedfrom computing the precision:?
Example 1: It is very hard to justify payinga silly price for Jaguar if an out-and-outbidding war were to start now.?
Example 2: It is raining.We performed a ten-way cross-validation wherewe reserved 10% of the corpus for testing andused the remaining 90% for training.
Our pre-liminary results are shown in the last line ofTable 1.We are also interested in finding the relativeimportance of each probability (i.e.
each of thefour factors in equation (8) in pronoun resolu-tion.
To this end, we ran the program "incre-mentally", each time incorporating one moreprobability.
The results are shown in Table 1(all obtained from cross-validation).
The lastcolumn of Table i contains the p-values for test-ing the statistical significance of each improve-ment.Due to relatively large differences betweenTree:bank parse trees and Hobbs' trees, ourHobbs' implementation does not yield as highan accuracy as it would have if we had hadperfect Hobbs' tree representations.
Since theHobbs' algorithm serves as the base of ourscheme, we expect the accuracy to be muchhigher with more accurately transformed trees.We also note that the very simple model thatignores syntax and takes the last mentionednoun-phrase as the referent performs quite abit worse, about 43% correct.
This indicatesthat syntax does play a very important role inanaphora resolution.We see a significant improvement after theword knowledge is added to the program.
TheP(plw,d probability gives the system informa-tion about gender and animaticity.
The con-tribution of this factor is quite significant, asca/n be seen from Table 1.
The impact of thisprobability can be seen more clearly from an-other experiment in which we tested the pro-gram (using just Hobbs distance and gender in-formation) on the training data.
Here the pro-gram can be thought of having "perfect" gen-der/animaticity knowledge.
We obtained a suc-cess rate of 89.3%.
Although this success rateoverstates the effect, it is a clear indication thatknowledge of a referent's gender and animatic-ity is essential to anaphora resolution.We hoped that the knowledge about the gov-erning constituent would, like gender and an-imaticity, make a large contribution.
To oursurprise, the improvement is only about 2.2%.This is partly because selection restrictions arenot clearcut in many cases.
Also, some headverbs are too general to restrict he selection ofany NP.
Examples are "is" and "has", whichappear frequently in Wall Street Journal: theseverbs are not "selective" enough and the associ-ated probability is not strong enough to rule out165erroneous candidates.
Sparse data also causesa problem in this statistic.
Consequently, weobserve a relatively small enhancement to thesystem.The mention information gives the sys~emsome idea of the story's focus.
The more fre-quently an entity is repeated, the more likely itis to be the topic of the story and thus to bea candidate for pronominalization.
Our resultsshow that this is indeed the case.
Referencesby pronouns are closely related to the topic orthe center of the discourse.
NP repetition isone simple way of approximately identifying thetopic.
The more accurately the topic of a seg-ment can be identified, the higher the successrate we expect an anaphora resolution systemcan achieve.5 Unsuperv ised  Learn ing  o f  GenderIn fo rmat ionThe importance of gender information as re-vealed in the previous experiments caused us toconsider automatic methods for estimating theprobability that nouns occurring in a large cor-pus of English text deonote inanimate, mascu-line or feminine things.
The method describedhere is based on simply counting co-occurrencesof pronouns and noun phrases, and thus canemploy any method of analysis of the textstream that results in referent/pronoun pairs(cf.
(Hatzivassiloglou and McKeown, 1997)for another application in which no explicitindicators are available in the stream).
Wepresent two very simple methods for findingreferent/pronoun pairs, and also give an appli-cation of a salience statistic that can indicatehow confident we should be about the predic-tions the method makes.
Following this, weshow the results of applying this method to the21-million-word 1987 Wall Street Journal cor-pus using two different pronoun reference strate-gies of varying sophistication, and evaluate theirperformance using honorifics as reliable genderindicators.The method is a very simple mechanismfor harvesting the kind of gender informationpresent in discourse fragments like "Kim slept.She slept for a long time."
Even if Kim's genderwas unknown before seeing the first sentence,after the second sentence, it is known.The probability that a referent is in a partic-166ular gender class is just the relative frequencywith which that referent is referred to by a pro-noun p that is part of that gender class.
That is,the probability of a referent ref being in genderclass gc~ isP(re/ E gci)= I refs to refwith p e gci I (9)E l  refs to re /w i th  p E gcj IJIn this work we have considered only threegender classes, masculine, feminine and inani-mate, which are indicated by their typical pro-nouns, HE, SHE, and IT.
However, a variety ofpronouns indicate the same class: Plural pro-pronoun gender classhe,himself, him,his HEshe,herself, her,hers SHEit,itself, its ITnouns like "they" and "us" reveal no gender in-formation about their referent and consequentlyaren't useful, although this might be a way tolearn pluralization in an unsupervised manner.In order to gather statistics on the gender ofreferents in a corpus, there must be some wayof identifying the referents.
In attempting tob.ootstrap lexical information about referents'gender, we consider two strategies, both com-pletely blind to any kind of semantics.One of the most naive pronoun referencestrategies i the "previous noun" heuristic.
Onthe intuition pronouns closely follow their refer-ents, this heuristic simply keeps track of the lastnoun seen and submits that noun as the refer-ent of any pronouns following.
This strategy iscertainly simple-minded but, as noted earlier, itachieves an accuracy of 43%.In the present system, a statistical parser isused (see (Charniak, 1997)) simply as a tag-ger.
This apparent parser overkill is a controlto ensure that the part-of-speech tags assignedto words are the same when we use the previ-ous noun heuristic and the Hobbs algorithm, towhich we wish to compare the previous nounmethod.
In fact, the only part-of-speech tagsnecessary are those indicating nouns and pro-nouns .Obviously a much superior strategy wouldbe to apply the anaphora-resolution strategyfrom previous sections to finding putative ref-erents.
However, we chose to use only theHobbs distance portion thereof.
We do notuse the "mention" probabilities P(alma), asthey are not given in the unmarked text.
Nordo we use the gender/animiticity informationgathered from the much smaller hand-markedtext, both because we were interested in seeingwhat unsupervised learning could accomplish,and because we were concerned with inherit-ing strong biases from the limited hand-markeddata.
Thus our second method of finding thepronoun/noun co-occurrences is simply to parsethe text and then assume that the noun-phraseat Hobbs distance one is the antecedent.Given a pronoun resolution method and a cor-pus, the result is a set of pronoun/referent pairs.By collating by referent and abstracting awayto the gender classes of pronouns, rather thanindividual pronouns, we have the relative fre-quencies with which a given referent is referredto by pronouns of each gender class.
We willsay that the gender class for which this relativefrequency is the highest is the gender class towhich the referent most probably belongs.However, any syntax-only pronoun resolutionstrategy will be wrong some of the time - thesemethods know nothing about discourse bound-aries, intentions, or real-world knowledge.
Wewould like to know, therefore, whether the pat-tern of pronoun references that we observe fora given referent is the result of our supposed"hypothesis about pronoun reference" - that is,the pronoun reference strategy we have provi-sionally adopted in order to gather statistics -or whether the result of some other unidentifiedprocess.This decision is made by ranking the refer-ents by log-likelihood ratio, termed salience, foreach referent.
The likelihood ratio is adaptedfrom Dunning (1993, page 66) and uses the rawfrequencies of each pronoun class in the cor-pus as the null hypothesis, Pr(gc0i) as well asPr(ref E gci) from equation 9.salience(re/)= -2  logMaking the unrealistic simplifying assumptionthat references of one gender class are com-pletely independent of references for anotherclasses 1, the likelihood function in this case isjust the product over all classes of the probabil-ities of each class of reference to the power ofthe number of observations of this class.6 Eva luat ionWe ran the program on 21 million words of WallStreet Journal text.
One can judge the pro-gram informally by simply examining the re-sults and determining if the program's genderdecisions are correct (occasionally ooking at thetext for difficult cases).
Figure 1 shows the 43noun phrases with the highest salience figures(run using the Hobbs algorithm).
An examina-tion of these show that all but three are correct.
(The three mistakes are "husband," wife," and"years."
We return to the significance of thesemistakes later.
)As a measure of the utility of these results, wealso ran our pronoun-anaphora program withthese statistics added.
This achieved an accu-racy rate of 84.2%.
This is only a small improve-ment over what was achieved without the data.We believe, however, that there are ways to im-prove the accuracy of the learning method andthus increase its influence on pronoun anaphoraresolution.Finally we attempted a fully automatic di-rect test of the accuracy of both pronoun meth-ods for gender determination.
To that end, wedevised a more objective test, useful only forscoring the subset of referents that are namesof people.
In particular, we assume that anynoun-phrase with the honorifics "Mr.".
"Mrs."or "Ms." may be confidently assigned to genderclasses HE, SHE, and SHE, respectively.
Thus wecompute precision as follows:precision =\ [ ra t t r ib .
asHEA Mr. E r l+\ [ ra t t r ib .
asSHEA Mrs. or Ms. E r \ [I Mr., Mrs., or Ms. E r \]Here r varies over referent ypes, not tokens.The precision score computed over all phrasescontaining any of the target honorifics are 66.0%l In effect, this is the same as admi t t ing  that  a ref-erent  can be in different gender  classes across differentobservations.167Word count(salience) p(he) p(she) p(it)COMPANY 7052(1629.39) 0.0764 0.0060 0.9174WOMAN 250(368.267) 0.172 0.708 0.12PRESIDENT 93:\[(356.539) 0.8206 0.0139 0.1654GROUP 1096(287.319) 0.0602 0.0054 0.9343MR.
REAGAN 53,t(270.8) .882022 0.0037 0.1142MAN 441(202.102) 0.8480 0.0385 0.1133PRESIDENT REAGAN 455(194.928) 0.8439 0.0043 0.1516GOVERNMENT 1220(194.187) 0.1172 0.0122 0.8704U.S.
969(188.468) 0.1021 0.0041 0.8937BANK 81(5(161.23) 0.0955 0.0073 0.8970MOTHER 113(161.204) 0.3008 0.6548 0.0442COL.
NORTH 258(158.692) 0.9263 0.0077 0.0658MOODY 383(152.405) 0.0078 0.0052 0.9869SPOKESWOMAN 139(145.627) 0.1223 0.5827 0.2949MRS.
AQUINO 73(142.223) 0.0958 0.8356 0.0684MRS.
THATCHER 68(128.306) 0.0735 0.8235 0.1029GM 513(119.664) 0.0779 0.0038 0.9181PLAN 514(111.134) 0.0856 0.0058 0.9085MR.
GORBACHEV 205(108.776) 0.8926 0.0048 0.1024JUDGE BORK 212(108.746) 0.8820 0 0.1179HUSBAND 91(107.438) 0.3626 0.5714 0.0659JAPAN 450(100.727) 0.0755 0.0111 0.9133AGENCY 476(97.4016) 0.0840 0.0147 0.9012WIFE 153(93.7485) 0.6143 0.2875 0.0980DOLLAR 621(90.8963) 0.1304 0.0096 0.8599STANDARD POOR 200(90.1062) 0 0 1FATHER 146(89.4178-) 0.8082 0.1438 0.0479UTILITY 242(87.1821) 0.0247 0 0.9752MR.
TRUMP 129(86.5345) 0.9457 0.0077 0.0465MR.
BAKER 187(84.2796) 0.8556 0.0053 0.1390IBM 316(82.4361) 0.0696 0 0.9303MAKER 224(82.252) 0.0223 0 0.9776YEARS 1055(82.1632) 0.5298 0.0815 0.3886MR.
MEESE 166(82.1007) 0.8734 0 0.1265BRAZIL 285(79.7311) 0.0596 0 0.9403SPOKESMAN 665(78.3441) 0.6075 0.0045 0.3879MR.
SIMON 105(72.6446) 0.9523 0 0.0476DAUGHTER 47(71.3863) 0.2340 0.7021 0.0638FORD 249(71.3603) 0.0562 0 0.9437MR.
GREENSPAN 120(68.7807) 0.9083 0 0.0916AT&T 198(67.9668) 0.0252 0.0050 0.9696MINISTER 125(67.7475) 0.864 0.064 0.072JUDGE - 239(67.5899) 0.7154 0.0836 0.2008Figure 1: Top 43 noun phrases according to salience168oo~ol .O -0.8-0 .5 -U?
?
0 ?0? "
' ' ' "1  " " " ' ' ' " |10 100Number of referencesO ?Figure 2: Precision using honorific scoringscheme with syntactic Hobbs algorithmfor the last-noun method and 70.3% for theHobbs method.There are several things to note about theseresults.
First, as one might expect given the al-ready noted superior performance of the Hobbsscheme over last-noun, Hobbs also performs bet-ter at determining ender.
Secondly, at firstglance,the 70.3% accuracy of the Hobbs methodis disappointing, only slightly superior to the65.3% accuracy of Hobbs at finding correct ref-erents.
It might have been hoped that thestatistics would make things considerably moreaccurate.In fact, the statistics do make things consid-erably more accurate.
Figure 2 shows averageaccuracy as a function of number of referencesfor a given referent.
It can be seen that there isa significant improvement with increased refer-ent count.
The reason that the average over allreferents is so low is that the counts on referentsobey Zipf's law, so that the mode ~f the distri-bution on counts is one.
Thus the 70.3% overallaccuracy is a mix of relatively high accuracy forreferents with counts greater than one, and rel-atively low accuracy for referents with counts ofexactly one.7 Prev ious  WorkThe literature on pronoun anaphora is too ex-tensive to summarize, so we concentrate here oncorpus-based anaphora research.Aone and Bennett (1996) present an ap-proach to an automatically trainable anaphoraresolution system.
They use Japanese newspa-per articles tagged with discourse informationas training examples for a machine-learning al-gorithm which is the C4.5 decision-tree algo-rithm by Quinlan (1993).
They train their de-cision tree using (anaphora, antecedent) pairstogether with a set of feature vectors.
Amongthe 66 features are lexical, syntactic, seman-tic, and positional features.
Their MachineLearning-based Resolver (MLR) is trained us-ing decision trees with 1971 anaphoras (exclud-ing those referring to multiple discontinuous an-tecedents) and they report an average successrate of 74.8%.Mitkov (1997) describes an approach thatuses a set of factors as constraints and prefer-ences.
The constraints rule out implausible can-didates and the preferences mphasize the selec-tion of the most likely antecedent.
The systemis not entirely "statistical" in that it consists ofvarious types of rule-based knowledge -- syn-tactic, semantic, domain, discourse, and heuris-tic.
A statistical approach is present in the dis-course module only where it is used to deter-mine the probability that a noun (verb) phraseis the center of a sentence.
The system also con-tains domain knowledge including the domainconcepts, specific list of subjects and verbs, andtopic headings.
The evaluation was conductedon 133 paragraphs of annotated Computer Sci-ence text.
The results show an accuracy of 83%for the 512 occurrences of it.Lappin and Leass (1994) report on a (essen-tially non-statistical) approach that relies onsalience measures derived from syntactic struc-ture and a dynamic model of attentional state.The system employs various constraints for NP-pronoun non-coreference within a sentence.
Italso uses person, number, and gender featuresfor ruling out anaphoric dependence of a pro-noun on an NP.
The algorithm has a sophisti-cated mechanism for assigning values to severalsalience parameters and for computing globalsalience values.
A blind test was conductedon manual text containing 360 pronoun occur-169rences; the algorithm successfully identified theantecedent of the pronoun in 86% of these pro-noun occurrences.
The addition of a modulethat contributes tatistically measured lexJcalpreferences to the range of factors the algorithmconsiders improved the performance by 2%.8 Conc lus t ion  and  Future  ResearchWe have presented a statistical method forpronominal anaphora that achieves an accuracyof 84.2%.
The main advantage of the method isits essential simplicity.
Except for implementingthe Hobbs referent-ordering algorithm, all othersystem knowledge is imbedded in tables givingthe various component probabilities used in theprobability model.We believe that this simplicity of method willtranslate into comparative simplicity as we im-prove the method.
Since the research describedherein we have thought of other influences onanaphora resolution and their statistical corre-lates.
We hope to include some of them in futurework.Also, as indicated by the work on unsuper-vised learning of gender information, there is agrowing arsenal of learning techniques to be ap-plied to statistical problems.
Consider again thethree high-salience words to which our unsuper-vised learning program assigned incorrect gen-der: "husband", "wife", and "years."
We sus-pect that had our pronoun-assignment methodbeen able to use the topic information used inthe complete method, these might well havebeen decided correctly.
That is, we suspectthat "husband", for example, was decided in-correctly because the topic of the article was thewoman, there was a mention of her "husband,"but the article kept on talking about the womanand used the pronoun "she."
While our simpleprogram got confused, a program using betterstatistics might not have.
This too is a topic forfuture research.9 AcknowledgementsThe authors would like to thank Mark Johnsonand other members of the Brown NLP groupfor many useful ideas and NSF and ONR forsupport (NSF grants IRI-9319516 and SBR-9720368, ONR grant N0014-96-1-0549).170ReferencesChinatsu Aone and Scott William Bennett,1996.
Evaluating Automated and Manual Ac-quisition off Anaphora Resolution Strategies,pages 302-315.
Springer.Susan E. Brennan, Marilyn Walker Friedman,and Carl J. Pollard.
1987.
A centering ap-proach to pronouns.
In Proc.
25th AnnualMeeting of the A CL, pages 155-162.
Associa-tion of Computational Linguistics.Eugene Charniak.
1997.
Statistical parsingwith a context-free grammar and word statis-tics.
In Proceedings of the 14th National Con-ference on Artificial Intelligence, Menlo Park,CA.
AAAI Press/MIT Press.Ted Dunning.
1993.
Accurate methods for thestatistics of surprise and coincidence.
Com-putational Linguistics, 19(1), March.Vasileios Hatzivassiloglou and Kathleen R.McKeown.
1997.
Predicting the semantic ori-entation of adjectives.
In Proc.
35th AnnualMeeting of the ACL, pages 174-181.
Associa-tion of Computational Linguistics.Jerry R. Hobbs.
1976.
Pronoun resolution.Technical Report 76-1, City College, NewYork.Shalom Lappin and Herbert J. Leass.
1994.
Analgorithm for pronominal anaphora resolu-tion.
Computational Linguistics, pages 535-"561.Mitchell P. Marcus, Beatrice Santorini, andMary Ann Marcinkiewicz.
1993.
Buildinga large annotated corpus of english: thepenn treebank.
Computational Linguistics,19:313-330.Ruslan Mitkov.
1997.
Factors in anaphora res-olution: they are not the only things thatmatter, a case study based on two differ-ent approaches.
In Proceedings of the A CL'g7/EA CL 'g7 Workshop on Operational Fac-tors in Practical, Robust Anaphora Resolu-tion.J.
Ross Quinlan.
1993.
C~.5 Programs for Ma-chine Learning.
Morgan Kaufmann Publish-ers.
