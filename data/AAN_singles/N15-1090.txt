Human Language Technologies: The 2015 Annual Conference of the North American Chapter of the ACL, pages 892?900,Denver, Colorado, May 31 ?
June 5, 2015.c?2015 Association for Computational LinguisticsOptimizing Multivariate Performance Measuresfor Learning Relation Extraction ModelsGholamreza Haffari2Faculty of IT, Monash Universitygholamreza.haffari@monash.eduAjay Nagesh1,2,31IITB-Monash Research Academyajaynagesh@cse.iitb.ac.inGanesh Ramakrishnan3Dept.
of CSE, IIT Bombayganesh@cse.iitb.ac.inAbstractWe describe a novel max-margin learn-ing approach to optimize non-linear perfor-mance measures for distantly-supervised re-lation extraction models.
Our approach canbe generally used to learn latent variablemodels under multivariate non-linear perfor-mance measures, such as F?-score.
Ourapproach interleaves Concave-Convex Pro-cedure (CCCP) for populating latent vari-ables with dual decomposition to factorizethe original hard problem into smaller inde-pendent sub-problems.
The experimental re-sults demonstrate that our learning algorithmis more effective than the ones commonly usedin the literature for distant supervision of in-formation extraction models.
On several dataconditions, we show that our method outper-forms the baseline and results in up to 8.5%improvement in the F1-score.1 IntroductionRich models with latent variables are popular formany problems in natural language processing.
Ininformation extraction, for example, one needs topredict the relation labels y that an entity-pair x canhave based on the hidden relation mentions h, i.e.,the relation labels for occurrences of the entity-pairin a given corpus.
However, these models are oftentrained by optimizing performance measures (suchas conditional log-likelihood or error rate) that arenot directly related to the task-specific non-linearperformance measure, e.g., the F1-score.
However,better models may be trained by optimizing the task-specific performance measure while allowing latentvariables to adapt their values accordingly.We present a large-margin method to learn pa-rameters of latent variable models for a widerange of non-linear multivariate performance mea-sures such as F?.
Our method can be appliedto learning graphical models that incorporate inter-dependencies among the output variables either di-rectly, or indirectly through hidden variables.Large-margin methods have been shown to be acompelling approach to learn rich models detailingthe inter-dependencies among the output variables,via optimizing loss functions decomposable over thetraining instances (Taskar et al, 2003; Tsochan-taridis et al, 2004) or non-decompasable loss func-tions (Ranjbar et al, 2013; Tarlow and Zemel, 2012;Rosenfeld et al, 2014; Keshet, 2014).
They havealso been shown to be powerful when applied to la-tent variable models when optimizing for decompos-able loss functions (Wang and Mori, 2011; Felzen-szwalb et al, 2010; Yu and Joachims, 2009).Our large-margin method learns latent variablemodels via optimizing non-decomposable loss func-tions.
It interleaves the Concave-Convex Procedure(CCCP) (Yuille and Rangarajan, 2001) for populat-ing latent variables with dual decomposition (Ko-modakis et al, 2011; Rush and Collins, 2012).The latter factorizes the hard optimization problem(encountered in learning) into smaller independentsub-problems over the training instances.
We thenpresent linear programming and local search meth-ods for effective optimization of the sub-problemsencountered in the dual decomposition.
Our localsearch algorithm leads to a speed up of 7,000 timescompared to the exhaustive search used in the liter-ature (Joachims, 2005; Ranjbar et al, 2012).Our work is the first to make use of max-margintraining in distant supervision of relation extractionmodels.
We demonstrate the effectiveness of ourproposed method compared to two strong baselinesystems which optimize for the error rate and con-ditional likelihood, including a state-of-the-art sys-tem by Hoffmann et al (2011).
On several data con-ditions, we show that our method outperforms thebaseline and results in up to 8.5% improvement inthe F1-score.892Figure 1: Graphical model instantiated for entity pair x :=(Barack Obama, United States)2 Preliminaries2.1 Distant Supervision for Relation ExtractionOur framework is motivated by distant supervisionfor learning relation extraction models (Mintz et al,2009).
The goal is to learn relation extraction mod-els by aligning facts in a database to sentences ina large unlabeled corpus.
Since the individual sen-tences are not hand labeled, the facts in the databaseact as ?weak?
or ?distant?
labels, hence the learningscenario is termed as distantly supervised.Prior work casts this problem as a multi-instancemulti-label learning problem (Hoffmann et al,2011; Surdeanu et al, 2012).
It is multi-instancesince for a given entity-pair, only the label of the bagof sentences containing both entities (aka mentions)is given.
It is multi-label since a bag of mentionscan have multiple labels.
The inter-dependenciesbetween relation labels and (hidden) mention labelsare modeled by a Markov Random Field (Figure 1)(Hoffmann et al, 2011).
The learning algorithmsused in the literature for this problem optimize the(conditional) likelihood, but the evaluation measureis commonly the F -score.Formally, the training data isD := {(xi,yi)}Ni=1where xi?
X is the entity-pair, yi?
Y denotesthe relation labels, and hi?
H denotes the hid-den mention labels.
The possible relation labels forthe entity pair are observed from a given knowledge-base.
If there are L candidate relation labels in theknowledge-base, then yi?
{0, 1}L, (e.g.
yi,`is 1 ifthe relation ` is licensed by the knowledge-base forthe entity-pair) and hi?
{1, .., L, nil}|xi|(i.e.
eachmention realizes one of the relation labels or nil).Notation.
In the rest of the paper, we denote thecollection of all entity-pairs {xi}Ni=1by X ?
X :=X ?
.. ?
X , the collection of mention relations{hi}Ni=1by H ?H := H?..
?H, and the collectionof relation labels {yi}Ni=1by Y ?
Y := Y ?
..?Y .The aim is to learn a parameter vector w ?
Rdbywhich the relation labels for a new entity-pair x canbe predictedfw(x) := arg maxymaxhw ?
?
(x,h,y) (1)where ?
?
Rdis a feature vector defined accordingto the Markov Random Field, modeling the inter-dependencies between x and y through h (Figure 1).In training, we would like to minimize the loss func-tion ?
by which the model will be assessed at testtime.
For the relation extraction task, the loss can beconsidered to be the negative of the F?score:F?=1?Precision+1?
?Recall(2)where ?
= 0.5 results in optimizing against F1-score.
Our proposed learning method optimizesthose loss functions ?
which cannot be decomposedover individual training instances.
For example, F?depends non-linearly on Precision and Recall whichin turn require the predictions for all the entity pairsin the training set, hence it cannot be decomposedover individual training instances.2.2 Structured Prediction LearningThe goal of our learning problem is to find w ?
Rdwhich minimizes the expected loss, aka risk, over a893new sample D?of size N?:R?fw:=??
((fw(x?1), .., fw(x?N?
)),(y?1, ..,y?N?))dPr(D?
)(3)Generally, the loss function ?
cannot be decom-posed into a linear combination of a loss function?
over individual training samples.
However, mostdiscriminative large-margin learning algorithms as-sume for simplicity that the loss function is decom-posable and the samples are i.i.d.
(independent andidentically distributed), which simplifies the samplerisk R?fwas:R?fw:=??(fw(x?),y?)dPr(x?,y?)
(4)Often learning algorithms make use of the empiricalrisk as an approximation of the sample risk:?R?fw:=1NN?i=1?
(fw(xi),yi) (5)For non-decomposable loss functions, such as F?,?
cannot be expressed in terms of instance-specificloss function ?
to construct the empirical risk of thekind in Eq.
(5).
Instead, we need to optimize theempirical risk constructed based on the sample loss:?R?fw:= ?
((fw(x1), .., fw(xN)),(y1, ..,yN))(6)or equivalently?R?fw:= ?
(fw(X),Y) (7)where fw(X) := (fw(x1), .., fw(xN)).Having defined the empirical risk in Eq (7), weformulate the learning problem as a structured pre-diction problem.
Instead of learning a mappingfunction fw: X ?
Y from an individual instancex ?
X to its label y ?
Y , let us learn a mappingfunction f : X ?
Y from all instances X ?
X totheir labels Y ?
Y .
We then define the best labelingusing a linear discriminant function:f(X) := arg maxY?
?YmaxH?H{w ??(X,H,Y?
)}(8)where ?(X,H,Y?)
:=?Ni=1?(xi,hi,y?i).
Basedon the margin re-scaling formulation of structuredprediction problems (Tsochantaridis et al, 2004),the training objective can be written as the follow-ing unconstrained optimization problem:minw12||w||22+ C maxY?
{maxHw ??(X,H,Y?
)?maxHw ??
(X,H,Y) + ?
(Y?,Y)}(9)which is similar to the training objective for the la-tent SVMs (Yu and Joachims, 2009), with the differ-ence that instance-dependent loss function ?
is re-placed by the sample loss function ?.
Learning wby optimizing the above objective function is chal-lenging, and is the subject of the next section.3 Optimizing the Training ObjectiveIn this section we present our method to learn latentSVMs with non-decomposable loss functions.
Ourtraining objective is Eq (9), which can be equiva-lently expressed as:minw12||w||22+ C maxy?1,..,y?N{?
((y1, ..,yN), (y?1, ..,y?N))+N?i=1maxhw ?
?
(xi,h,y?i)?N?i=1maxhw ?
?
(xi,h,yi)}(10)The training objective is non-convex, since it is thedifference of two convex functions.
In this sectionwe make use of the CCCP to populate the hiddenvariables (Yu and Joachims, 2009; Yuille and Ran-garajan, 2001), and interleave it with dual decompo-sition (DD) to solve the resulting intermediate loss-augmented inference problems (Ranjbar et al, 2012;Rush and Collins, 2012; Komodakis et al, 2011).3.1 Concave-Convex Procedure (CCCP)The CCCP (Yuille and Rangarajan, 2001) givesa general iterative method to optimize those non-convex objective functions which can be written asthe difference of two convex functions g1(w) ?g2(w).
The idea is to iteratively lowerbound g2witha linear function g2(w(t)) + v ?
(w?w(t)), and takethe following step to update w:w(t+1):= arg minw{g1(w)?w ?
v(t)}(11)In our case, the training objective Eq (10) is the dif-ference of two convex functions, where the secondfunction g2isC?Ni=1maxh{w??(xi,h,yi)}.
The894Algorithm 1 The Training Algorithm (Optimizing Eq 10)1: procedure OPT-LATENTSVM(X,Y)2: Initialize w(0)and set t = 03: repeat4: for i := 1 to N do5: h?i:= arg maxhw(t)?
?
(xi,h,yi)// Optimizing Eq 126: w(t+1):= optSVM(X,H?,Y)7: t := t+ 18: until some stopping condition is met9: return w(t)lowerbound of g2(w) involves populating the hid-den variables by:h?i:= arg maxh{w(t)?
?
(xi,h,yi)}.Therefore, in each iteration of our CCCP-based al-gorithm we need to optimize Eq (12), which is rem-iniscent of the standard structural SVM without la-tent variables:minw12||w||22+ C maxy?1,..,y?N{?
((y1, ..,yN), (y?1, ..,y?N))+N?i=1maxhw ?
?
(xi,h,y?i)?N?i=1w ?
?
(xi,h?i,yi)}(12)The above objective function can be optimized us-ing the standard cutting-plane algorithms for struc-tural SVM (Tsochantaridis et al, 2004; Joachims,2005).
The cutting-plane algorithm in turn needsto solve the loss-augmented inference, which is thesubject of the next sub-section.
The CCCP-basedtraining algorithm is summarized in Algorithm 1.3.2 Loss-Augmented InferenceTo be able to optimize the training objective Eq (12)encountered in each iteration of Algorithm 1, weneed to solve (the so-called) loss-augmented infer-ence:maxy?1,..,y?N?
((y1, ..,yN), (y?1, ..,y?N))+N?i=1maxhw ?
?
(xi,h,y?i) (13)We make use of the dual decomposition (DD) tech-nique to decouple the two terms of the above ob-jective function, and efficiently find an approximatesolution.
DD is shown to be an effective techniquefor loss-augmented inference in structured predic-tion models without hidden variables (Ranjbar et al,2012).To apply DD to the loss-augmented inference(13), let us rewrite it as a constrained optimizationproblem:maxy?1,...,y?N,y??1,...,y??N?
((y1, .
.
.
,yN), (y?1, .
.
.
,y?N))+N?i=1maxhw ?
?(xi,h,yi??
)subject to?i ?
{1, .
.
.
, N},?` ?
{1, .
.
.
, L}, y?i,`= y?
?i,`Introduction of the new variables (y?
?1, ..,y?
?N) de-couples the two terms in the objective function, andas we will see, leads to an effective optimization al-gorithm.
After forming the Lagrangian, the dual ob-jective function is derived as:L(?)
:= maxY??(Y,Y?)
+?i?`?i(`)y?i,`+maxY?
?N?i=1maxhw ?
?(xi,h,yi??)??i?`?i(`)y?
?i,`where ?
:= (?1, ..,?N), and ?iis a vector of La-grange multipliers for L binary variables each ofwhich represent a relation label.
The two optimiza-tion problems involved in the dual L(?)
are inde-pendent and can be solved separately.
The dual is anupperbound on the loss-augmented objective func-tion for any value of ?
; therefore, we can find thetightest upperbound as an approximate solution:min?L(?
)The dual is non-differentiable at those points ?where either of the two optimisation problems hasmultiple optima.
Therefore, it is optimized using thesubgradient descent method:?
(t):= ?(t?1)?
?(t)(Y???Y???
)where ?
(t)=1?tis the step size1, andY??
:= arg maxY??(Y,Y?)
+?i?`?(t?1)i(`)y?i,`(14)Y???
:= arg maxY?
?N?i=1maxhw ?
?(xi,h,yi??)??i?`?(t?1)i(`)y?
?i,`(15)1Other (non-increasing) functions of the iteration number tare also plausible, as far as they satisfy the following condi-tions (Komodakis et al, 2011) needed to guarantee the conver-gence to the optimal solution in the subgradient descent method:?(t)?
0, limt???
(t)= 0,??t=1?
(t)=?895Algorithm 2 Loss-Augmented Inference1: procedure OPT-LOSSAUG(w,X,Y)2: Initialize ?
(0)and set t = 03: repeat4: Y??
:= opt-LossLag(?,Y) // Eq (14)5: Y???
:= opt-ModelLag(?,X) // Eq (15)6: if Y?
?= Y??
?then7: return Y?
?8: for i := 1 to N do9: for ` := 1 to L do10: ?
(t+1)i(`) := ?(t)i(`)?
?(t)(y?i,`?
y?
?i,`)11: until some stopping condition is met12: return Y?
?The DD algorithm to compute the loss-augmentedinference is outlined in Algorithm 2.
Now the chal-lenge is how to solve the above two optimizationproblems, which is the subject of the following sec-tion.3.3 Effective Optimization of the DualThe two optimization problems involved in the dualare hard in general.
More specifically, the optimiza-tion of the affine-augmented model score (in Eq.
15)is as difficult as the MAP inference in the underlyinggraphical model, which can be challenging for loopygraphs.
For the graphical model underlying distantsupervision of relation extraction (Fig 1), we formu-late the inference as an ILP (integer linear program).Furthermore, we relax the ILP to LP to speed up theinference, in the expense of trading exact solutionswith approximate solutions2.Likewise, the optimization of the affine-augmented multivariate loss (in Eq.
14) is difficult.This is because we have to search over the entirespace of Y??
Y , which is exponentially largeO(2N?L).
However, if the loss term ?
can beexpressed in terms of some aggregate statisticsover Y?, such as false positives (FPs) and falsenegatives (FNs), the optimization can be performedefficiently.
This is due to the fact that the numberof FPs can range from zero to the size of negativelabels, and the number of FNs can range from zeroto the number of positive labels.
Therefore, the lossterm can take O(N2L2) different values which can2We observed in our experiments that relaxing the ILP toLP does not hurt the performance, but significantly speeds upthe inference.Algorithm 3 Finding Y??
: Local Search1: procedure OPT-LOSSLAG(?,Y)2: (idxn1.
.
.
idxn#neg)?
Sort ?
(?i(`)) // FPs3: (idxn1.
.
.
idxn#pos)?
Sort ?
(?i(`)) // FNs4: Initialise (fp, fn) on the grid5: repeat6: for ((fp?, fn?)
?
Neigbours(fp, fn) do7: loss(fp?,fn?
)= ?
(fp?, fn?)
+ ?sorted38: loss(fp??,fn??
)= arg max(fp?,fn?)loss(fp?,fn?
)9: if loss(fp,fn)> loss(fp??,fn??
)then10: break11: else12: (fp, fn) = (fp?
?, fn??
)13: until loss(fp,fn)?
loss(fp??,fn??
)14: return {Y?corresponding to (fp, fn) }be represented on a two-dimensional grid.
FixingFPs and FNs to a grid point, ?
?
Y?is maximizedwith respect to Y?.
The grid point which has thebest value for ?(Y,Y?)
+ ?
?Y?will then give theoptimal solution for Eq (14).Exhaustive search in the space of all possible gridpoints is not efficient as soon as the grid becomeslarge.
Therefore, we have to adapt the techniquesproposed in previous work (Ranjbar et al, 2012;Joachims, 2005).
We propose a simple but effectivelocal search strategy for this purpose.
The procedureis outlined in Algorithm 3.
We start with a randomgrid point, and move to the best neighbour.
We keephill climbing until there is no neighbour better thanthe current point.
We define the neighbourhood bya set of exponentially-spaced points in all directionsaround the current point, to improve the explorationof the search space.
We present some analysis on thebenefits of using this search strategy vis-a-vis the ex-haustive search in the Experiments section.4 ExperimentsDataset: We use the challenging benchmark datasetcreated by Riedel et al (2010) for distant supervi-sion of relation extraction models.
It is created byaligning relations from Freebase4with the sentencesin New York Times corpus (Sandhaus, 2008).
Thelabels for the datapoints come from the Freebase3For a given (fp, fn), we set y?by picking the sorted unaryterms that maximize the score according to y.4www.freebase.com896database but Freebase is incomplete (Ritter et al,2013).
So a data point is labeled nil when either norelation exists or the relation is absent in Freebase.To avoid this ambiguity we train and evaluate thebaseline and our algorithms on a subset of thisdataset which consists of only non-nil relationlabeled datapoints (termed as positive dataset).For the sake of completeness, we do report theaccuracies of the various approaches on the entireevaluation dataset.Systems and Baseline: Hoffmann et al (2011)describe a state-of-the-art approach for this task.They use a perceptron-style parameter updatescheme adapted to handle latent variables; theirtraining objective is the conditional likelihood.Out of the two implementations of this algorithm,we use the better5of these two6, as our baseline(denoted by Hoffmann).
For a fair comparison,the training dataset and the set of features definedover it are common to all the experiments.We discuss the results of two of our approaches.One, is the LatentSVM max-margin formulationwith the simple decomposable Hamming lossfunction which minimizes the error rate (denoted byMM-hamming).
The other is the LatentSVM max-margin formulation with the non-decomposable lossfunction which minimizes the negative of F?score(denoted by MM-F-loss)7.Evaluation Measure: The performance mea-sure is F?which can be expressed in terms of falsepositives (FP) and false negatives (FN) as:F?=Np?
FN?
(FP ?
FN) +Npwhere ?
is the weight assigned to precision (and1?
?
to recall).
FP , FN and Npare defined as :FP =?i?`y?i,`(1?
yi,l)FN =?i?`yi,`(1?
y?i,l)Np=?i?`yi,`5It is not quite clear why the performance of the two imple-mentations are different.6nlp.stanford.edu/software/mimlre.shtml7We use a combination of F1 loss and hamming loss, as us-ing only F1-loss overfits the training dataset, as observed fromthe experiments.Figure 2: Experiments on 10% Riedel datasets.Precision Recall F1Hoffmann 65.93 47.22 54.91MM-Hamming 59.74 53.81 56.32MM-F-loss 64.81 61.63 63.44Table 1: Average results on 10% Riedel datasets.We use 1?F?as the expression for the multivariate-loss.4.1 Training on Sub-samples of DataWe performed a number of experiments using differ-ent randomized subsets of the Riedel dataset (10%of the positive dataset) for training the max-marginapproaches.
This was done in order to empiricallydetermine a good set of parameters for training.We also compare the results of the approaches withHoffmann trained on the same sub-samples.Comparison with the Baseline: We report the aver-age over 15 subsets of the dataset with a 90% confi-dence interval (using student-t distribution).
The re-sults of these experiments are shown in Figure 2 andTable 1.
We observe that both MM-hamming andMM-F-loss have higher F1-score compared to thebaseline.
There is a significant improvement in F1-score to the tune of 8.52% for the multivariate per-formance measure over Hoffmann.
There is alsoan improvement of F1-score of 7.12% compared toMM-Hamming.
This highlights the importance ofusing non-linear loss functions compared to simpleloss functions like error rate during training.However, Hoffmann has a marginally higherprecision of about 1.13%.
We noticed that this was897Figure 3: Weighting of Precision and Recall (?
= 0.833)due to over-fitting the data, as the performance onthe training datasets were very high.
One moreinteresting observation of MM-F-loss is that it isfairly balanced w.r.t both precision and recall whichthe other approaches do not exhibit.Tuning towards Precision/Recall: Often wecome across situations where either precision orrecall is important for a given application.
Thisis modeled by the notion of F?
(van Rijsbergen,1979).
One of the main advantages of using anon-decomposable loss function like F?is theability to vary the learning algorithm to factor suchsituations.
For instance we can tune the objective tofavor precision more than recall by ?up-weighting?precision in the F?-score.For instance, in the previous case we observedthat MM-F-loss has a marginally poorer precisioncompared to Hoffmann.
Suppose we increasethe weight of precision, ?
= 0.833, we observea dramatic increase in precision from 65.83% to86.59%.
As expected, due to the precision-recalltrade-off, we observe a decrease in recall.
Theresults are shown in Figure 3.Local vs. Exhaustive Grid Search: As wedescribed in Section 3.3, we devise a simple yetefficient local search strategy to search the spaceof (FP, FN) grid-points.
This enables a speedup of three orders of magnitude in solving thedual-optimization problem.
In Table 2, we comparethe average time per iteration and the F1-scorewhen each of these techniques is used for trainingon a sub-sample dataset.
We observe that thereFigure 4: Overall accuracies Riedel datasetavg.
time per iter.
F1Local Search 0.09s 58.322Exhaustive Search 630s 58.395Table 2: Local vs. Exhaustive Search.is a significant decrease in training time when weuse local search (almost 7000 times faster), with anegligible decrease in F1-score (0.073%).4.2 The Overall ResultsFigure 4 and Table 3 present the overall results ofour approaches compared to the baseline on the pos-itive dataset.
We observe that MM-F-loss has anincrease in F1-score to the tune of ?8% comparedto the baseline.
This confirms our observation onthe sub-sample datasets we saw earlier.By assigning more weight to precision, we areable to improve over the precision of Hoffmannby ?1.6% (Table 4).
When precision is tuned witha higher weight during training of MM-F-loss, wesee an improvement in precision without much dipin recall.Precision Recall F1Hoffmann 75.436 46.615 57.623MM-Hamming 76.839 50.462 60.918MM-F-loss 65.991 65.211 65.598Table 3: Overal results on the positive dataset.898Precision Recall F?Hoffmann 75.44 46.62 57.62MM-F-loss-wt 77.04 53.44 63.11Table 4: Increasing weight on Precision in F?.4.3 DiscussionSo far we have discussed the performance of var-ious approaches on the positive evaluation dataset.Our approach is shown to improve overall F?-scorehaving better recall than the baseline.
By suitablytweaking the F?we show an improvement in preci-sion as well.The performance of the approaches when evalu-ated on the entire test dataset (consisting of both niland non-nil datapoints) is shown in Table 5.
Max-margin based approaches generally perform wellwhen trained only on the positive dataset comparedto Hoffmann.
However, our F1-scores are ?8%less when we train on the entire dataset consistingof both nil and non-nil datapoints.Trained On?
entire dataset positive datasetHoffmann 23.14 3.269MM-Hamming 13.20 16.26MM-F-loss 13.94 21.93Table 5: F1-scores on the entire test set.In a recent work, Xu et al (2013) provide somestatistics about the incompleteness of the Riedeldataset.
Out of the sampled 1854 sentences fromNYTimes corpus most of the entity pairs expressinga relation in Freebase correspond to false negatives.This is one of the reasons why we do not consider nillabeled datapoints during training and evaluation.MIMLRE (Surdeanu et al, 2012) is another state-of-the-art system which is based on the EM algo-rithm.
Since that system uses an additional set offeatures for the relation variables y, it is not our pri-mary baseline.
On the positive dataset, our modelMM-F-loss achieves a F1-score of 65.598% com-pared to 65.341% of MIMLRE.
As part of the futurework, we would like to incorporate the additionalfeatures present in MIMLRE into our approach.5 ConclusionIn this paper, we described a novel max-marginapproach to optimize non-linear performance mea-sures, such as F?, in distant supervision of infor-mation extraction models.
Our approach is generaland can be applied to other latent variable modelsin NLP.
Our approach involves solving the hard-optimization problem in learning by interleavingConcave-Convex Procedure with dual decomposi-tion.
Dual decomposition allowed us to solve thehard sub-problems independently.
A key aspectof our approach involves a local-search algorithmwhich has led to a speed up of 7,000 times in our ex-periments.
We have demonstrated the efficacy of ourapproach in distant supervision of relation extrac-tion.
Under several conditions, we have shown ourtechnique outperforms very strong baselines, and re-sults in up to 8.5% improvement in F1-score.For future work, we would like to maximize otherperformance measures, such as area under the curve,for information extraction models.
Furthermore, wewould like to explore our approach for other latentvariable models in NLP, such as those in machinetranslation.AcknowledgementsGholamreza Haffari is grateful to National ICT Aus-tralia (NICTA) for their generous funding, as partof the Machine Learning Collaborative ResearchProjects.
Ajay Nagesh acknowledges Xerox Re-search Centre India (XRCI) for their travel supportin the form of International Student Travel grant.ReferencesPedro F. Felzenszwalb, Ross B. Girshick, David A.McAllester, and Deva Ramanan.
2010.
Object detec-tion with discriminatively trained part-based models.IEEE Trans.
Pattern Anal.
Mach.
Intell., 32(9):1627?1645.Raphael Hoffmann, Congle Zhang, Xiao Ling, LukeZettlemoyer, and Daniel S. Weld.
2011.
Knowledge-based weak supervision for information extraction ofoverlapping relations.
In Proceedings of the 49th An-nual Meeting of the Association for ComputationalLinguistics: Human Language Technologies - Volume1, HLT ?11, pages 541?550, Stroudsburg, PA, USA.Association for Computational Linguistics.899T.
Joachims.
2005.
A support vector method for multi-variate performance measures.
In International Con-ference on Machine Learning (ICML), pages 377?384.Joseph Keshet.
2014.
Optimizing the measure of per-formance in structured prediction.
In Jeremy JancsarySebastian Nowozin, Peter V. Gehler and Christoph H.Lampert, editors, Advanced Structured Prediction.The MIT Press.Nikos Komodakis, Nikos Paragios, and Georgios Tziri-tas.
2011.
Mrf energy minimization and beyond viadual decomposition.
IEEE Transactions on PatternAnalysis and Machine Intelligence, 33(3):531?552.Mike Mintz, Steven Bills, Rion Snow, and Dan Jurafsky.2009.
Distant supervision for relation extraction with-out labeled data.
In Proceedings of the Joint Confer-ence of the 47th Annual Meeting of the ACL and the 4thInternational Joint Conference on Natural LanguageProcessing of the AFNLP: Volume 2 - Volume 2, ACL?09, pages 1003?1011, Stroudsburg, PA, USA.
Asso-ciation for Computational Linguistics.Mani Ranjbar, Arash Vahdat, and Greg Mori.
2012.Complex loss optimization via dual decomposition.
In2012 IEEE Conference on Computer Vision and Pat-tern Recognition, Providence, RI, USA, June 16-21,2012, pages 2304?2311.Mani Ranjbar, Tian Lan, Yang Wang, Stephen N. Robi-novitch, Ze-Nian Li, and Greg Mori.
2013.
Opti-mizing nondecomposable loss functions in structuredprediction.
IEEE Trans.
Pattern Anal.
Mach.
Intell.,35(4):911?924.Sebastian Riedel, Limin Yao, and Andrew McCallum.2010.
Modeling relations and their mentions with-out labeled text.
In Proceedings of the 2010 Europeanconference on Machine learning and knowledge dis-covery in databases: Part III, ECML PKDD?10, pages148?163, Berlin, Heidelberg.
Springer-Verlag.Alan Ritter, Luke Zettlemoyer, Mausam, and Oren Et-zioni.
2013.
Modeling missing data in distant super-vision for information extraction.
TACL, 1:367?378.Nir Rosenfeld, Ofer Meshi, Amir Globerson, and DanielTarlow.
2014.
Learning structured models with theauc loss and its generalizations.
In Proceedings ofthe 17th International Conference on Artificial Intel-ligence and Statistics (AISTATS).Alexander M. Rush and Michael Collins.
2012.
A tuto-rial on dual decomposition and lagrangian relaxationfor inference in natural language processing.
J. Artif.Intell.
Res.
(JAIR), 45:305?362.E.
Sandhaus.
2008.
The new york times annotated cor-pus.Mihai Surdeanu, Julie Tibshirani, Ramesh Nallapati, andChristopher D. Manning.
2012.
Multi-instance multi-label learning for relation extraction.
In Proceed-ings of the 2012 Joint Conference on Empirical Meth-ods in Natural Language Processing and Computa-tional Natural Language Learning, EMNLP-CoNLL?12, pages 455?465, Stroudsburg, PA, USA.
Associa-tion for Computational Linguistics.Daniel Tarlow and Richard S Zemel.
2012.
Structuredoutput learning with high order loss functions.
In Pro-ceedings of the 15th Conference on Artificial Intelli-gence and Statistics.Benjamin Taskar, Carlos Guestrin, and Daphne Koller.2003.
Max-margin markov networks.
In NIPS.I.
Tsochantaridis, T. Hofmann, T. Joachims, and Y. Altun.2004.
Support vector machine learning for interde-pendent and structured output spaces.
In InternationalConference on Machine Learning (ICML), pages 104?112.C.
J. van Rijsbergen.
1979.
Information retrieval.
But-terworths, London, 2 edition.Yang Wang and Greg Mori.
2011.
Hidden part mod-els for human action recognition: Probabilistic versusmax margin.
IEEE Trans.
Pattern Anal.
Mach.
Intell.,33(7):1310?1323.Wei Xu, Raphael Hoffmann, Le Zhao, and Ralph Gr-ishman.
2013.
Filling knowledge base gaps for dis-tant supervision of relation extraction.
In Proceed-ings of the 51st Annual Meeting of the Association forComputational Linguistics (Volume 2: Short Papers),pages 665?670, Sofia, Bulgaria, August.
Associationfor Computational Linguistics.Chun-Nam John Yu and Thorsten Joachims.
2009.Learning structural svms with latent variables.
In Pro-ceedings of the 26th Annual International Conferenceon Machine Learning, ICML 2009, Montreal, Quebec,Canada, June 14-18, 2009, page 147.Alan L. Yuille and Anand Rangarajan.
2001.
Theconcave-convex procedure (cccp).
In NIPS, pages1033?1040.900
