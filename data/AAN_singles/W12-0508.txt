Proceedings of the Workshop on Innovative Hybrid Approaches to the Processing of Textual Data (Hybrid2012), EACL 2012, pages 52?60,Avignon, France, April 23 2012. c?2012 Association for Computational LinguisticsA Joint Named Entity Recognition and Entity Linking SystemRosa Stern,1,2 Beno?
?t Sagot1 and Fre?de?ric Be?chet31Alpage, INRIA & Univ.
Paris Diderot, Sorbonne Paris Cite?
/ F-75013 Paris, France2AFP-Medialab / F-75002 Paris, France3Univ.
Aix Marseille, LIF-CNRS / Marseille, FranceAbstractWe present a joint system for named entityrecognition (NER) and entity linking (EL),allowing for named entities mentions ex-tracted from textual data to be matched touniquely identifiable entities.
Our approachrelies on combined NER modules whichtransfer the disambiguation step to the ELcomponent, where referential knowledgeabout entities can be used to select a correctentity reading.
Hybridation is a main fea-ture of our system, as we have performedexperiments combining two types of NER,based respectively on symbolic and statis-tical techniques.
Furthermore, the statisti-cal EL module relies on entity knowledgeacquired over a large news corpus using asimple rule-base disambiguation tool.
Animplementation of our system is described,along with experiments and evaluation re-sults on French news wires.
Linking ac-curacy reaches up to 87%, and the NER F-score up to 83%.1 Introduction1.1 Textual and Referential Aspects ofEntitiesIn this work we present a system designed for theextraction of entities from textual data.
Namedentities (NEs), which include person, location,company or organization names1 must thereforebe detected using named entity recognition (NER)techniques.
In addition to this detection basedon their surface forms, NEs can be identified bymapping them to the actual entity they denote,in order for these extractions to constitute use-ful and complete information.
However, because1The set of possible named entities varies from restric-tive, as in our case, to wide definitions; it can also includedates, event names, historical periods, etc.of name variation, which can be surfacic or en-cyclopedic, an entity can be denoted by severalmentions (e.g., Bruce Springsteen, Springsteen,the Boss); conversely, due to name ambiguity, asingle mention can denote several distinct entities(Orange is the name of 22 locations in the world;in French, M. Obama can denote both the USpresident Barack Obama (M. is an abbreviation ofMonsieur ?Mr?)
or his spouse Michelle Obama; inthis case ambiguity is caused by variation).
Evenin the case of unambiguous mentions, a clear linkshould be established between the surface men-tion and a uniquely identifiable entity, which isachieved by entity linking (EL) techniques.1.2 Entity Approach and Related WorkIn order to obtain referenced entities from rawtextual input, we introduce a system based onthe joint application of named entity recognition(NER) and entity linking (EL), where the NER out-put is given to the linking component as a set ofpossible mentions, preserving a number of am-biguous readings.
The linking process must there-after evaluate which readings are the most proba-ble, based on the most likely entity matches in-ferred from a similarity measure with the context.NER has been widely addressed by symbolic,statistical as well as hybrid approaches.
Its majorpart in information extraction (IE) and other NLPapplications has been stated and encouraged byseveral editions of evaluation campaigns suchas MUC (Marsh and Perzanowski, 1998),the CoNLL-2003 NER shared task(Tjong Kim Sang and De Meulder, 2003) orACE (Doddington et al, 2004), where NERsystems show near-human performances forthe English language.
Our system aims atbenefitting from both symbolic and statisticalNER techniques, which have proven efficient52but not necessarily over the same type of dataand with different precision/recall tradeoff.
NERconsiders the surface form of entities; sometype disambiguation and name normalizationcan follow the detection to improve the resultprecision but do not provide referential infor-mation, which can be useful in IE applications.EL achieves the association of NER results withuniquely identified entities, by relying on anentity repository, available to the extractionsystem and defined beforehand in order to serveas a target for mention linking.
Knowledge aboutentities is gathered in a dedicated knowledge base(KB) to evaluate each entity?s similarity to a givencontext.
After the task of EL was initiated withWikipedia-based works on entity disambiguation,in particular by Cucerzan (2007) and Bunescuand Pasca (2006), numerous systems have beendeveloped, encouraged by the TAC 2009 KBpopulation task (McNamee and Dang, 2009).Most often in EL, Wikipedia serves both as anentity repository (the set of articles referring toentities) and as a KB about entities (derived fromWikipedia infoboxes and articles which containtext, metadata such as categories and hyperlinks).Zhang et al (2010) show how Wikipedia, byproviding a large annotated corpus of linkedambiguous entity mentions, pertains efficientlyto the EL task.
Evaluated EL systems at TACreport a top accuracy rate of 0.80 on English data(McNamee et al, 2010).Entities that are unknown to the referencedatabase, called out-of-base entities, are also con-sidered by EL, when a given mention refers toan entity absent from the available Wikipedia ar-ticles.
This is addressed by various methods,such as setting a threshold of minimal similarityfor an entity selection (Bunescu and Pasca, 2006),or training a separate binary classifier to judgewhether the returned top candidate is the actualdenotation (Zheng et al, 2010).
Our approachof this issue is closely related to the method ofDredze et al in (2010), where the out-of-base en-tity is considered as another entry to rank.Our task differs from EL configurations out-lined previously, in that its target is entity extrac-tion from raw news wires from the news agencyAgence France Presse (AFP), and not only link-ing relying on gold NER annotations: the inputof the linking system is the result of an auto-matic NER step, which will produce errors of var-ious kinds.
In particular, spans erroneously de-tected as NEs will have to be discarded by our ELsystem.
This case, which we call not-an-entity,contitute an additional type of special situations,together with out-of-base entities but specific toour setting.
This issue, as well as others of ourtask specificities, will be discussed in this paper.In particular, we use resources partially based onWikipedia but not limited to it, and we experimenton the building of a domain specific entity KB in-stead of Wikipedia.Section 2 presents the resources used through-out our system, namely an entity repository andan entity KB acquired over a large corpus of newswires, used in the final linking step.
Section 3states the principles on which the NER compo-nents of our system relies, and introduces the twoexisting NER modules used in our joint architec-ture.
The EL component and the methodology ap-plied are presented in section 4.
Section 5 illus-trates this methodology with a number of experi-ments and evaluation results.2 Entity ResourcesOur system relies on two large-scale resourceswhich are very different in nature:?
the entity database Aleda, automaticallyextracted from the French Wikipedia andGeonames;?
a knowledge base extracted from a large cor-pus of AFP news wires, with distributionaland contextual information about automati-cally detected entites.2.1 AledaThe Aleda entity repository2 is the result of an ex-traction process from freely available resources(Sagot and Stern, 2012).
We used the FrenchAleda databased, extracted the French Wikipedia3and Geonames4.
In its current development, it pro-vides a generic and wide coverage entity resourceaccessible via a database.
Each entity in Aleda isassociated with a range of attributes, either refer-ential (e.g., the type of the entity among Person,Location, Organization and Company, the popu-lation for a location or the gender of a person, etc.
)2Aleda is part of the Alexina project and freely availableat https://gforge.inria.fr/projects/alexina/.3www.fr.wikipedia.org4www.geonames.org53or formal, like the entity?s URI from Wikipedia orGeonames; this enables to uniquely identify eachentry as a Web resource.Moreover, a range of possible variants (men-tions when used in textual content) are associ-ated to entities entries.
Aleda?s variants includeeach entity?s canonical name, Geonames locationlabels, Wikipedia redirection and disambiguationpages aliases, as well as dynamically computedvariants for person names, based in particular ontheir first/middle/last name structure.
The FrenchAleda used in this work comprises 870,000 entityreferences, associated with 1,885,000 variants.The main informative attributes assigned toeach entity in Aleda are listed and illustrated byexamples of entries in Tab.
1.
The popularity at-tribute is given by an approximation based on thelength of the entity?s article or the entity?s popu-lation, from Wikipedia and Geonames entries re-spectively.
Table 1 also details the structure ofAleda?s variants entries, each of them associatedwith one or several entities in the base.Unlike most EL systems, Wikipedia is not theentity base we use in the present work; rather,we rely on the autonomous Aleda database.
Thecollect of knowledge about entities and their us-age in context will also differ in that our targetdata are news wires, for which the adaptability ofWikipedia can be questioned.2.2 Knowledge Acquisition over AFP newsThe linking process relies on knowledge about en-tities, which can be acquired from their usage incontext and stored in a dedicated KB.
AFP newswires, like Wikipedia articles, have their ownstructure and formal metadata: while Wikipediaarticles each have a title referring to an entity, ob-ject or notion, a set of categories, hyperlinks, etc.,AFP news wires have a headline and are taggedwith a subject (such as Politics or Culture) andseveral keywords (such as cinema, inflation orG8), as well as information about the date, timeand location of production.
Moreover, the distri-bution of entities over news wires can be expectedto be significantly different from Wikipedia, inparticular w.r.t.
uniformity, since a small set ofentities forms the majority of occurrences.
Ourparticular context can thus justify the need for adomain specific KB.As opposed to Wikipedia where entities areidentifiable by hyperlinks, AFP corpora provideno such indications.
Wikipedia is in fact a corpuswhere entity mentions are clearly and uniquelylinked, whereas this is what we aim at achiev-ing over AFP?s raw textual data.
The acquisi-tion of domain specific knowledge about enti-ties from AFP corpora must circumvent this lackof indications.
In this perspective we use animplementation of a naive linker described in(Stern and Sagot, 2010).
For the main part, thissystem is based on heuristics favoring popular en-tities in cases of ambiguities.
An evaluation ofthis system showed good accuracy of entity link-ing (0.90) over the subset of correctly detected en-tity mentions:5 on the evaluation data, the result-ing NER reached a precision of 0.86 and a recallof 0.80.
Therefore we rely on the good accuracyof this system to identify entities in our corpus,bearing in mind that it will however include casesof false detections, while knowledge will not beavailable on missed entities.
It can be observedthat by doing so, we aim at performing a form ofco-training of a new system, based on supervisedmachine learning.
In particular, we aim at pro-viding a more portable and systematic method forEL than the heuristics-based naive linker whichis highly dependent on a particular NER system,SXPipe/NP, described later on in section 3.2.The knowledge acquisition was conducted overa large corpus of news wires (200,000 news itemsof the years 2009, 2010 and part of 2011).
Foreach occurrence of an entity identified as such bythe naive linker, the following features are col-lected, updated and stored in the KB at the en-tity level: (i) entity total occurrences and occur-rences with a particular mention; (ii) entity oc-currence with a news item topics and keywords,most salient words, date and location; (iii) entityco-occurrence with other entity mentions in thenews item.
These features are collected for bothentities identified by the naive linker as Aleda?sentities and mentions recognized by NER pat-tern based rules; the latter account for out-of-base entities, approximated by a cluster of allmentions whose normalization returns the samestring.
For instance, if the mentions John Smithand J. Smith were detected in a document but notlinked to an entity in Aleda, it would be assumed5This subset is defined by a strict span and type correctdetection, and among the sole entities for which a match inAleda or outside of it was identified; the evaluation data ispresented in section 5.1.54EntitiesID Type CanonicalName Popularity URI20013 Loc Kingdom of Spain 46M geon:251076910063 Per Michael Jordan 245 wp:Michael Jordan20056 Loc Orange (California) 136K geon:537951310039 Comp Orange 90 wp:Orange (entreprise)VariantsID Variant FirstName MidName LastName20013 Espagne ?
?
?10063 Jordan ?
?
Jordan10029 George Walker Bush George Walker Bush10039 Orange ?
?
?20056 Orange ?
?
?Table 1: Structure of Entities Entries and Variants in Aledathat they co-refer to an entity whose normalizedname would be John Smith; this anonymous en-tity would therefore be stored and identified viathis normalized name in the KB, along with its oc-currence information.3 NER Component3.1 PrinciplesOne challenging subtask of NER is the correct de-tection of entity mentions spans among severalambiguous readings of a segment.
The other usualsubtask of NER consists in the labeling or classi-fication of each identified mention with a type; inour system, this functionality is used as an indica-tion rather than a final attribute of the denoted en-tity.
The type assigned to each mention will in theend be the one associated with the matching en-tity.
The segment Paris Hilton can for instance besplit in two consecutive entity mentions, Paris andHilton, or be read as a single one.
Whether onereading or the other is more likely can be inferredfrom knowledge about entities possibly denotedby each of these three mentions: depending on theconsidered document?s topic, it can be more prob-able for this segment to be read as the mentionParis Hilton, denoting the celebrity, rather thanthe sequence of two mentions denoting the cap-ital of France and the hotel company.
Based onthis consideration, our system relies on the abilityof the NER module to preserve multiple readingsin its output, in order to postpone to the linker theappropriate decisions for ambiguous cases.
TwoNER systems fitted with this ability are used in ourarchitecture.Figure 1: Ambiguous NER output for the segmentParis Hilton in SXPipe/NP3.2 Symbolic NER: SXPipe/NPNP is part of the SXPipe surface processing chain(Sagot and Boullier, 2008).
It is based on a se-ries of recognition rules and on a large coveragelexicon of possible entity variants, derived fromthe Aleda entity repository presented in section2.1.
As an SXPipe component, NP formalizes thetext input in the form of directed acyclic graphs(DAGs), in which each possible entity mentionis represented as a distinct transition, as illus-trated in Figure 1.
Possible mentions are labeledwith types among Person, Location, Organizationand Company, based on the information availableabout the entity variant in Aleda and on the typeof the rule applied for the recognition.Figure 1 also shows how an alternative transi-tion is added to each mention reading of a seg-ment, in order to account for a possible non-entityreading (i.e., for a false match returned by theNER module).
When evaluating the adequacy ofeach reading, the following EL module will infact consider a special not-an-entity candidate asa possible match for each mention, and select itas the most probable if competing entity readingsprove insufficiently adequate w.r.t.
the consideredcontext.553.3 Statistical NER: LIANEThe statistical NER system LIANE(Bechet and Charton, 2010) is based on (i) agenerative HMM-based process used to predictpart-of-speech and semantic labels among Per-son, Location, Organization and Product for eachinput word6, and (ii) a discriminative CRF-basedprocess to determine the entity mentions?
spansand overall type.
The HMM and CRF modelsare learnt over the ESTER corpus, consisting inseveral hundreds of hours of transcribed radiobroadcast (Galliano et al, 2009), annotated withthe BIO format (table 2).
The output of LIANEinvestiture NFS Oaujourd?hui ADV B-TIMEa` PREPADE OBamako LOC B-LOCMali LOC B-LOCTable 2: BIO annotation for LIANE trainingconsists in an n-best lists of possible entitymentions, along with a confidence score assignedto each result.
Therefore it also provides severalreadings of some text segments, with alternativesof entity mention readings.As shown in (Bechet and Charton, 2010), thelearning model of LIANE makes it particularlyrobust to difficult conditions such as non capital-ization and allows for a good recall rate on varioustypes of data.
This is in opposition with manuallyhandcrafted systems such as SXPipe/NP, whichcan reach high precision rates over the develop-ment data but prove less robust otherwise.
Theseconsiderations, as well as the benefits of a coop-erations between these two types of systems areexplored in (Be?chet et al, 2011).By coupling LIANE and SXPipe/NP to performthe NER step of our architecture, we expect tobenefit from each system?s best predictions andimproving the precision and recall rates.
Thisis achieved by not enforcing disambiguation ofspans and types at the NER level but by transfer-ring this possible source of errors to the linkingstep, which will rely on entity knowledge ratherthan mere surface forms to determine the bestreadings, along with the association of mentionswith entity references.6For the purpose of type consistency across both NERmodules, the NP type Company is merged with Organiza-tion, and the LIANE mentions typed as Product are ignoredsince they are not yet supported by the overall architecture.Figure 2: Possible readings of the segment ParisHilton and ordered candidates4 Linking Component4.1 Methodology for Best Reading SelectionAs previously outlined, the purpose of our jointarchitecture is to infer best entity readings fromcontextual similarity between entities and docu-ments rather than at the surface level during NER.The linking component will therefore process am-biguous NER outputs in the following way, illus-trated by Fig.
2.1.
For each mention returned by the NER mod-ule, we aim at finding the best fitting entityw.r.t.
the context of the mention occurrence,i.e., at the document level.
This results ina list of candidate entities associated witheach mention.
This candidates set alays in-cludes the not-an-entity candidate in order toaccount for possible false matches returnedby the NER modules.2.
The list of candidates is ordered using apointwise ranking model, based on the max-imum entropy classifier megam.7 The bestscored candidate is returned as a match forthe mention; it can be either an entity presentin Aleda, i.e., a known entity, or an anony-mous entity, seen during the KB acquisitionbut not resolved to a known reference andidentified by a normalized name, or the spe-cial not-an-entity candidate, which discardsthe given mention as an entity denotation.3.
Each reading is assigned a score dependingon the best candidates?
scores in the reading.The key steps of this process are the selectionof candidates for each mention, which must reacha sufficient recall in order to ensure the referenceresolution, and the building of the feature vec-tor for each mention/entity pair, which will beevaluated by the candidate ranker to return the7http://www.cs.utah.edu/?hal/megam/56most adequate entity as a match for the mention.Throughout this process, the issues usually raisedby EL must be considered, in particular the abilityfor the model to learn cases of out-of-base enti-ties, which our system addresses by forming a setof candidates not only from the entity referencebase (i.e., Aleda), but also from the dedicated KBwhere anonymous entities are also collected.
Fur-thermore, unlike the general configuration of ELtasks, such as the TAC KB population task (sec-tion 1.2), our input data does not consist in men-tions to be linked but in multiple possibilities ofmention readings, which adds to our particularcase the need to identify false matches among thequeries made to the linker module.4.2 Candidates SelectionFor each mention detected in the NER output, themention string or variant is sent as a query tothe Aleda database.
Entity entries associated withthe given variant are returned as candidates.
Theset of retrieved entities, possibly empty, consti-tutes the candidate set for the mention.
Becausethe knowledge acquisition included the extractionof unreferenced entities identified by normalizednames (section 2.2), we can send the normaliza-tion of the mention as an additional query to ourKB.
If a corresponding anonymous entity is re-turned, we can create an anonymous candidateand add it to the candidate set.
Anonymous candi-dates account for the possibility of an out-of-baseentity denoted by the given mention, with respec-tively some and no information about the potentialentity they might stand for.
Finally, the set is aug-mented with the special not-an-entity candidate.4.3 Features for Candidates RankingFor each pair formed by the considered mentionand each entity from the candidate set, we com-pute a feature vector which will be used by ourmodel for assessing the probability that it repre-sents a correct mention/entity linking.
The vec-tor contains attributes pertaining to the mention,the candidate and the document themselves, andto the relations existing between them.Entity attributes Entity attributes present inAleda and the KB are used as features: Aleda pro-vides the entity type, a popularity indication andthe number of variants associated with the entity.We retrieve from the KB the entity frequency overthe corpus used for knowledge acquisition.Mention attributes At the mention level, thefeature set considers the absence or presence ofthe mention as a variant in Aleda (for any en-tity), its occurrence frequency in the document,and whether similar variants, possibly indicatingname variation of the same entity, are present inthe document (similar variants can have a stringequal to the mention?s string, longer or shorterthan the mention?s string, included in the men-tion?s string or including it).
In the case of amention returned by LIANE, the associated con-fidence score is also included in the feature set.Entity/mention relation The comparison be-tween the surface form of the entity?s canonicalname and the mention gives a similarity rate fea-ture.
Also considered as features are the relativeoccurrence frequency of the entity w.r.t.
the wholecandidate set, the existence of the mention as avariant for the entity in Aleda, the presence ofthe candidate?s type (retrieved from Aleda) in thepossible mention types provided by the NER.
TheKB indicates frequency of its occurrences with theconsidered mention, which adds another feature.Document/entity similarity Document metadata(in particular topics and keywords) are inheritedby the mention and can thus characterize the en-tity/mention pair.
Equivalent information was col-lected for entities and stored in the KB, which al-lows to compute a cosine similarity between thedocument and the candidate.
Moreover, the mostsalient words of the document are compared to theones most frequently associated with the entity inthe KB.
Several atomic and combined features arederived from these similarity measures.Other features pertain to the NER output con-figuration, as well as possible false matches:NER combined information One of the twoavailable NER modules is selected as the baseprovider for entity mentions.
For each mentionwhich is also returned by the second NER mod-ule, a feature is instanciated accordingly.Non-entity features In order to predict cases ofnot-an-entity readings of a mention, we use ageneric lexicon of French forms (Sagot, 2010)where we check for the existence of the mention?svariant, both with and without capitalization.
Ifthe mention?s variant is the first word of the sen-tence, this information is added as a feature.These features represent attributes of the en-tity/mention pair which can either have a booleanvalue (such as variant presence or absence in57Aleda) or range throughout numerical values(e.g., entity frequencies vary from 0 to 201,599).In the latter case, values are discretized.
All fea-tures in our model are therefore boolean.4.4 Best Candidate SelectionGiven the feature vector instanciated for an (can-didate entity, mention) pair, our model assigns it ascore.
All candidates in the subset are then rankedaccordingly and the first candidate is returned asthe match for the current mention/entity linking.Anonymous and not-an-entity candidates, as de-fined earlier and accounting respectively for po-tential out-of-base entity linking and NER falsematches, are included in this ranking process.4.5 Ranking of ReadingsThe last step of our task consists in the rankingof multiple readings and has yet to be achieved inorder to obtain an output where entity mentionsare linked to adequate entities.
In the case of areading consisting in a single transition, i.e., a sin-gle mention, the score is equal to the best candi-date?s score.
In case of multiple transitions andmentions, the score is the minimum among thebest candidates?
scores, which makes a low entitymatch probability in a mention sequence penaliz-ing for the whole reading.
Cases of false matchesreturned by the NER module can therefore be dis-carded as such in this step, if an overall non-entityreading of the whole path receives a higher scorethan the other entity predictions.5 Experiments and Evaluation5.1 Training and Evaluation DataWe use a gold corpus of 96 AFP news items in-tended for both NER and EL purposes: the manualannotation includes mention boundaries as well asan entity identifier for each mention, correspond-ing to an Aleda entry when present or the normal-ized name of the entity otherwise.
This allows forthe model learning to take into account cases ofout-of-base entities.
This corpus contains 1,476mentions, 437 distinct Aleda?s entries and 173 en-tities absent from Aleda.
All news items in thiscorpus are dated May and June 2009.In order for the model to learn from cases ofnot-an-entity, the training examples were aug-mented with false matches from the NER step, as-sociated with this special candidate and the pos-itive class prediction, while other possible candi-dates were associated with the negative class.
Us-ing a 10-fold cross-validation, we used this corpusfor both training and evaluation of our joint NERand EL system.It should be observed that the learning step con-cerns the ranking of candidates for a given men-tion and context, while the final purpose of oursystem is the ranking of multiple readings of sen-tences, which takes place after the application ofour ranking model for mention candidates.
Thusour system is evaluated according to its ability tochoose the right reading, considering both NER re-call and precision and EL accuracy, and not onlythe latter.5.2 Task SpecificitiesAs outlined in section 1.2, the input for the stan-dard EL task consists in sets of entity mentionsfrom a number of documents, sent as queries to alinking system.
Our current task differs in that weaim at both the extraction and the linking of enti-ties in our target corpus, which consists in unan-notated news wires.
Therefore, the results of oursystem are comparable to previous work whenconsidering a setting where the NER output is infact the gold annotation of our evaluation data,i.e., when all mention queries should be linked toan entity.
Without modifying the parameters ofour system (i.e., no deactivation of false matchespredictions), we obtain an accuracy of 0.76, incomparison with a TAC top accuracy of 0.80 anda median accuracy of 0.70 on English data.8It is important to observe that our data con-sists only in journalistic content, as opposed to theTAC dataset which included various types of cor-pora.
This difference can lead to unequally diffi-culty levels w.r.t.
the EL task, since NER and ELin journalistic texts, and in particular news wires,tend to be easier than on other types of corpora.This comes among other things from the fact thata small number of popular entities constitute themajority of NE mention occurrences.In most systems, EL is performed over noisy8As explained previously, these figures, as well as theones presented later on, cannot be compared with the 0.90score obtained by the naive linker which we used for the en-tity KB acquisition.
This score is obtained only on mentionsidentified by the SXPipe/NP system with the correct span andtype, whereas our system does not consider the mention typeas a contraint for the linking process, and on correct identifi-cation of a match in or outside of Aleda.58Setting NER EL Joint NER+ELPrecision Recall f-measure Accuracy Precision Recall f-measureSXPipe/NP 0.849 0.768 0.806 0.871 0.669 0.740 0.702LIANE 0.786 0.891 0.835 0.820 0.730 0.645 0.685SXPipe/NP- NL 0.775 0.726 0.750 0.875 0.635 0.678 0.656LIANE- NL 0.782 0.886 0.831 0.818 0.725 0.640 0.680SXPipe/NP & 2 0.812 0.747 0.778 0.869 0.649 0.705 0.676LIANE & SXPipe/NP 0.803 0.776 0.789 0.859 0.667 0.689 0.678Table 3: Joint NER and EL results.
Each EL accuracy covers a different set of correctly detected mentionsNER output and participates to the final decisionsabout NEs extractions.
Therefore the ability ofour system to correctly detect entity mentions innews content is estimated by computing its pre-cision, recall and f-measure.9 The EL accuracy,i.e., the rate of correctly linked mentions, is mea-sured over the subset of mentions whose readingwas adequately selected by the final ranking.
Theevaluation of our system has been conducted overthe corpus described previously with settings pre-sented in the next section.5.3 Settings and resultsWe used each of the two available NER modulesas a provider for entity mentions, either on itsown or together with the second system, usedas an indicator.
For each of these settings, wetried a modified setting in which the predictionof the naive linker (NL) used to build the en-tity KB (section 2.2) was added as a feature toeach mention/candidate pair (settings SXPipe/NP-NL and LIANE-NL).
These experiments?
resultsare reported in Table 3 and are given in terms of:?
NER precision, recall and f-measure;?
EL accuracy over correctly recognized enti-ties; therefore, the different figures in col-umn EL Accuracy are not directly compara-ble to one another, as they are not obtainedover the same set of mentions;?
joint NER+EL precision, recall and f-measure; the precision/recall is computed asthe product of the NER precision/recall by theEL accuracy.9Only mention boundaries are considered for NER evalu-ation, while other settings require correct type identificationfor validating a fully correct detection.
In our case, NER isnot a final step, and entity typing is derived from the entitylinking result.As expected, SXPipe/NP performs better as faras NER precision is concerned, and LIANE per-forms better as far as NER recall is concerned.However, the way we implemented hybridationat the NER level does not seem to bring improve-ments.
Using the output of the naive linker as afeature leads to similar or slightly lower NER pre-cision and recall.
Finally, it is difficult to drawclear-cut comparative conclusions at this stageconcerning the joint NER +EL task.6 Conclusion and Future WorkWe have described and evaluated various settingsfor a joint NER and EL system which relies on theNER systems SXPipe/NP and LIANE for the NERstep.
The EL step relies on a hybrid model, i.e., astatistical model trained on a manually annotatedcorpus.
It uses features extracted from a large cor-pus automatically annotated and where entity dis-ambiguations and matches were computed usinga basic heuristic tool.
The results given in the pre-vious section show that the joint model allows forgood NER results over French data.
The impact ofthe hybridation of the two NER modules over theEL task should be further evaluated.
In particu-lar, we should investigate the situations where anmention was incorrectly detected (e.g., the span isnot fully correct) although the EL module linked itwith the correct entity.
Moreover, a detailed eval-uation of out-of-base linkings vs. linking in Aledaremains to be performed.In the future, we aim at exploring various addi-tional features in the EL system, in particular morecombinations of the current features.
The adapta-tion of our learning model to NER combinationsshould also be improved.
Finally, a larger set oftraining data should be considered.
This shall be-come possible with the recent manual annotationof a half-million word French journalistic corpus.59ReferencesF.
Bechet and E Charton.
2010.
Unsupervised knowl-edge acquisition for extracting named entities fromspeech.
In 2010 IEEE International Conference onAcoustics, Speech and Signal Processing.R.
Bunescu and M. Pasca.
2006.
Using encyclope-dic knowledge for named entity disambiguation.
InProceedings of EACL, volume 6, pages 9?16.F.
Be?chet, B. Sagot, and R. Stern.
2011.Coope?ration de me?thodes statistiques et sym-boliques pour l?adaptation non-supervise?e d?unsyste`me d?e?tiquetage en entite?s nomme?es.
In Actesde la Confe?rence TALN 2011, Montpellier, France.S.
Cucerzan.
2007.
Large-scale named entity disam-biguation based on wikipedia data.
In Proceedingsof EMNLP-CoNLL, volume 2007, pages 708?716.G.
Doddington, A. Mitchell, M. Przybocki,L.
Ramshaw, S. Strassel, and R. Weischedel.2004.
The automatic content extraction (ace)program-tasks, data, and evaluation.
In Proceed-ings of LREC - Volume 4, pages 837?840.M.
Dredze, P. McNamee, D. Rao, A. Gerber, andT.
Finin.
2010.
Entity disambiguation for knowl-edge base population.
In Proceedings of the 23rdInternational Conference on Computational Lin-guistics, pages 277?285.S.
Galliano, G. Gravier, and L. Chaubard.
2009.
TheEster 2 Evaluation Campaign for the Rich Tran-scription of French Radio Broadcasts.
In Inter-speech 2009.E.
Marsh and D. Perzanowski.
1998.
Muc-7 eval-uation of ie technology: Overview of results.
InProceedings of the Seventh Message UnderstandingConference (MUC-7) - Volume 20.P.
McNamee and H.T.
Dang.
2009.
Overview of thetac 2009 knowledge base population track.
In TextAnalysis Conference (TAC).P.
McNamee, H.T.
Dang, H. Simpson, P. Schone, andS.M.
Strassel.
2010.
An evaluation of technologiesfor knowledge base population.
Proc.
LREC2010.B.
Sagot and P. Boullier.
2008.
SXPipe 2 : ar-chitecture pour le traitement pre?syntaxique de cor-pus bruts.
Traitement Automatique des Langues(T.A.L.
), 49(2):155?188.B.
Sagot and R. Stern.
2012.
Aleda, a free large-scale entity database for French.
In Proceedings ofLREC.
To appear.B.
Sagot.
2010.
The Lefff , a freely available andlarge-coverage morphological and syntactic lexiconfor French.
In Proceedings of the 7th LanguageResources and Evaluation Conference (LREC?10),Vallette, Malta.R.
Stern and B. Sagot.
2010.
De?tection et re?solutiond?entite?s nomme?es dans des de?pe?ches d?agence.In Actes de la Confe?rence TALN 2010, Montre?al,Canada.E.
F. Tjong Kim Sang and F. De Meulder.
2003.
In-troduction to the conll-2003 shared task: Language-independent named entity recognition.
In Proceed-ings of CoNLL, pages 142?147, Edmonton, Canada.W.
Zhang, J. Su, C.L.
Tan, and W.T.
Wang.
2010.
En-tity linking leveraging: automatically generated an-notation.
In Proceedings of the 23rd InternationalConference on Computational Linguistics, pages1290?1298.Z.
Zheng, F. Li, M. Huang, and X. Zhu.
2010.
Learn-ing to link entities with knowledge base.
In HumanLanguage Technologies: The 2010 Annual Confer-ence of the North American Chapter of the Associa-tion for Computational Linguistics, pages 483?491.60
