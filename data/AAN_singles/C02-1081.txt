Data-driven Classification of Linguistic Styles in Spoken DialoguesThomas PortelePhilips Reseach Laboratories AachenThomas.Portele@philips.comAbstractLanguage users have individual linguistic styles.
A spo-ken dialogue system may benefit from adapting to thelinguistic style of a user in input analysis and output gen-eration.
To investigate the possibility to automaticallyclassify speakers according to their linguistic style threecorpora of spoken dialogues were analyzed.
Several nu-merical parameters were computed for every speaker.These parameters were reduced to linguistically inter-pretable components by means of a principal componentanalysis.
Classes were established from these compo-nents by cluster analysis.
Unseen input was classified bytrained neural networks with varying error rates depend-ing on corpus type.
A first investigation in using speciallanguage models for speaker classes was carried out.1 MotivationWithin spoken dialogues the participants make individ-ual use of the linguistics of the pertinent language.
Onone hand, each participant has a linguistic style as animportant element of his/her personality (Pieper, 1979;Walker et al, 1997).
The quantitative analysis of lin-guistic style (counting and comparing) has been used inlinguistics and literature for a long time to determine au-thorship of written texts (Mendenhall, 1887).
Lehmanand Carbonell (1989) describe a system for written natu-ral language queries that tries to adapt to the user?s gram-mar by starting from a simple basic grammar and relax-ing and augmenting it if a user provides uninterpretableinput.
They found significant differences among the ac-tive linguistic patterns generated by different users, buteach user was fairly consistent across sessions spanningseveral days.
For spoken dialogue systems, this aspect ofstyle can be important to optimize the analysis of a user?sinput.On the other hand, social bonding is performed byadapting to a common interaction style (Brown andLevinson, 1987; Okada et al, 1999).
It has been shownthat stylistic elements of one participant are adopted byother participants (Fais and Loken-kim, 1995; Gustafsonet al, 1997).
Studies have indicated that variations be-tween conversations is high but low within conversations(Brennan, 1996) because people mark their shared con-ceptualizations by using the same term, lexical entrain-ment.
A spoken dialogue system can use stylistic infor-mation to adapt its output behavior.Further determiners of style are the domain or genre(Karlgren and Cutting, 1994; Wolters and Kirsten, 1999),the modalities (speech only vs. speech and visual inter-faces) (Fais et al, 1996; Oviatt et al, 1994), and the de-gree of interactivity (Oviatt and Cohen, 1991) which aremore or less determined by the application scenario of aspoken dialogue system.One specific aspect of spoken input is its larger ir-regularity.
For written texts, robust parsers can be em-ployed to obtain style?relevant information (Karlgren,1994; Paiva, 2000), while for spontaneous speech sim-pler measurements have to be used like part?of?speechtags (Ries, 1999).Klarner (1997) investigated stylistic differences ofspeakers in the Verbmobil dialogue corpus in order to im-prove speech recognition by using speaker?type depen-dent language models.
The achieved reduction in per-plexity, however, is relatively low.For the research project SmartKom funded by the Ger-man ministry of research (BMBF) (Wahlster et al, 2001)a module is being developed that constructs and main-tains a model of human?computer interaction.
One partmodels the interaction style of the user (experience withthe system, experience with the task, preferred modal-ities for input and output), the other part the linguisticstyle.
Both parts are supposed to make use of stereotypes(Rich, 1979).The experiments described below explore the possibil-ity to consistently extract linguistic parameters from spo-ken dialogues, to use these parameters in order to groupspeakers into several classes, and to train learning algo-rithms that classify users by their parameter values.2 CorporaThe task of a spoken dialogue system is to engage inspoken human?computer interaction.
It is well knownthat spoken human?computer interaction differs from itshuman?human counterpart in various dimensions (Doranet al, 2001) including linguistic complexity.
For the pur-pose of this investigation three sources were exploited:a corpus of task?dependent human?human interactions(negotiation dialogues), a corpus of free human?humanconversations, and a corpus of human?computer interac-tions.
For all corpora the part?of?speech information foreach word was automatically annotated by the IMS treetagger (Schmid, 1994) using the STTS tagset (Schiller etal., 1995).Verbmobil The Verbmobil (VM) corpus (Wahlster,1993) is one of the largest spoken dialogue cor-pora available for German.
It contains spontaneousspeech human?human dialogues in the appointmentnegotiation and travel planning domain.
The corpusused for this investigation has data from 837 speak-ers (24569 turns with 448737 words, av.
29.35 turnsper speaker).CallHome The CallHome (CH) corpus (Linguistic DataConsortium, 1997) contains 80 dialogues of 10 min-utes unconstrained conversation between two hu-mans over the telephone.
The corpus has utterancesfrom 160 speakers (17744 turns with 145552 words,av.
110.9 turns per speaker).TABA The TABA corpus contains human?computer di-alogues in the domain of train timetable information(Aust et al, 1995).
The transcription was done au-tomatically by the speech recognizer of the dialoguesystem.
As the recognizer can only recognize wordspresent in the pertinent recognition lexicon and maybe subject to errors it is likely that the corpus some-times does not contain the actual words uttered bythe speaker contrary to the other corpora.
The cor-pus consists of 5200 dialogues (33568 turns with90377 words, av.
6.45 turns per speaker).3 Method and Results3.1 Parameter valuesFor each turn a set of parameter values was computed.The STTS tagset consists of more than 50 different tags.In order to obtain reasonable results the STTS tagsetwas collapsed to a set with 12 classes.
Their frequencydistributions (henceforth Cxxx, e.g.
CART for the fre-quency of articles) indicate the differences between thecorpora (Figure 1).
While the TABA corpus mainly con-tains nouns, prepositions, and particles, the two human?human corpora have many pronouns (pronominal refer-encing is possible due to longer contexts), verbs (varyingtasks need task names, sentences in longer utterances areless likely to be elliptic), and adverbs (an utterance isput in relation to its context).
The TABA corpus featuresnearly no interjections, while the number of numerals inthe CH corpus is rather low (in the other corpora timesand dates were explicit elements of the tasks).
The lengthdistributions (Lxxx) are similar with the exception of nu-merals in the VM corpus (dates are quite long in Ger-man, e.g.
?zweiundzwanzigster?
(22nd)).
An additionalset of parameters is the relative frequency of the differentclasses in phrase?final position (Fxxx) (Klarner, 1997).Tag Meaning VM CH TABAADJ adjectives 4.7 5.00 2.2ADV adverbs 15.9 17.4 6.6PRP prepositions 9.5 4.9 22.3ART articles 5.5 5.6 1.2NUM numerals 5.3 0.9 7.3ITJ interjections 3.4 2.0 0.1KON conjunctions 4.0 6.9 1.1NOM nouns 15.4 12.2 31.8PRO pronouns 17.5 18.0 4.0PTK particles 2.2 7.3 16.9VRB verbs 16.5 19.8 6.4Figure 1: Relative frequencies of the tags in the differentcorpora.3.2 Compute speaker valuesApart from frequency and average length of words in aclass, several other parameters were computed and aver-aged for every speaker (Figure 2).
Important differencesexist in the length of the turns, and also in the numberof words per sentence.
An average VM turn has morethan 6 times as many words as an average TABA turn.While the length of a phrase is fairly equal between VMand CH, the number of phrases (and, thus, words) persentence is higher for VM.
Neither casual nor formal ad-dressing are present in the TABA corpus (talking to amachine) while the VM setting (negotiation of businessappointments) evokes formal speech.
The CH dialoguesare mostly between family members and close friends(Linguistic Data Consortium, 1997), and casual address-ings are frequent.
Variations in the number of commonwords can be related to the list of common words used,which was based on the VM corpus.
The larger num-ber of different words per speaker in the TABA corpusresults from less words per speaker with less chance forrepetition.
Average word length and density are similarin all three corpora.The correlation coefficients between parameters werecomputed for the three corpora.
Those parameters thatcorrelated well with another parameter (correlation coef-ficient   0.6) were omitted from the pertinent corpus.The correlation coefficients between WIP and WISare strong for CH and moderate for VM, while thosebetween PIS and WIS are moderate for CH and strongfor VM.
This indicates that longer sentences have longerphrases in the CH corpus but more phrases in the VMcorpus.
Different annotation styles and guidelines mayhave caused this phenomenon.3.3 Principal component analysisTo normalize for the different ranges of the speaker-specific parameters the z scores (subtraction of the mean,division by standard deviation) are computed as input forthe principal component analysis (PCA).
The PCA wasdone with singular value decomposition on the data ma-trix.
This is the preferred method for numerical accuracyPar.
Meaning VM CH TABASIT sentences per turn (sen-tence end is markedby a question mark orcolon in the VM andCH corpora, in theTABA corpus no sen-tence boundaries are la-beled)2.0 1.1 1.0PIT phrases per turn (in theTABA corpus no phraseboundaries are labeled)4.3 1.9 1.0WIT words per turn 18.5 8.1 2.5PIS phrases per sentence 2.1 1.7 1.0WIS words per sentence 9.0 7.0 2.5WIP words per phrases 4.2 4.0 2.5AWL average word length 4.8 4.2 5.0CAS casual addressing 0.0 13.0 0.0FOR formal addressing 7.0 5.0 0.0DEN ratio of ?dense?
words(Pieper, 1979) (attribu-tive adjectives, nouns,and finite verbs)0.3 0.3 0.3DFW ratio of different words 0.4 0.4 0.8CWD ratio of ?common?words (words compris-ing 50 % of the VMcorpus)0.5 0.4 0.3Figure 2: Average values of speaker-specific parametersfor each corpus.
Displayed are the values for the firstquartile, the median, and the third quartile.
(Mardia et al, 1979).The PCA results were used to assess the importanceof the parameters.
The important parameters (those thatachieve high loads on the most important principal com-ponents) should not change much in dependence of theinput set.
Changes between the different corpora arelikely regarding their structural differences, but ideallya stable set of parameters emerges that contains parame-ters important for all corpora.The input partition was varied by changing the num-ber of minimal words per speaker in order to check forthe stability of the components and for the influence ofthe interaction length.
Figure 3 displays some results.
Itcan be seen that the important parameters for a corpusdo not change much if the input set is varied.
The prin-cipal components also show strong similarities within acorpus.An interpretation of the components is always to betreated with caution.
However, to ease further discus-sions, a tentative interpretation is given in Figure 4 forsome of the principal components shown in Figure 3where the interpretative labels can be motivated as fol-lows:adverbs: An adverb can take the position of a preposi-tional phrase or verb phrase, if an appropriate entityis present in the previous discourse context.
Thus,VM-1 100+ words, 816 speakersPC 1 PC 2 PC 3 PC 4CPRP 0.35 LVRB -0.35 WIT -0.35 CPRO -0.51CNOM 0.35 AWL -0.29 WIP -0.30 CART 0.35CADV -0.32 FOR -0.29 DFW 0.29 LNOM 0.32CNUM 0.30 CKON -0.28 FNUM -0.27 LART 0.31VM-2 400+ words, 410 speakersPC 1 PC 2 PC 3 PC 4AWL -0.33 LVRB -0.34 WIT 0.38 CPRO 0.41CPRP -0.31 CVRB -0.34 WIP 0.35 CKON -0.38CNOM -0.31 FOR -0.31 CWD 0.35 FPRO 0.29CITJ 0.30 LPRO -0.31 CPRO 0.29 CADV -0.28VM-3 800+ words, 148 speakersPC 1 PC 2 PC 3 PC 4AWL 0.32 CNUM -0.35 CPRO 0.40 CKON -0.44CPRP 0.29 FNUM -0.34 DFW -0.30 CADV -0.32CNOM 0.29 CVRB 0.32 WIP 0.29 CAS 0.29WIP 0.27 FVRB 0.31 WIT 0.27 WIT -0.29CH-1 100+ words, 159 speakersPC 1 PC 2 PC 3 PC 4WIT 0.35 CNOM 0.38 CADJ 0.36 CADV -0.44WIS 0.35 CPRO -0.34 FADJ 0.29 CVRB 0.39AWL 0.33 CART 0.31 LART 0.29 FADV -0.30CITJ -0.30 FPRO -0.27 FART -0.28 LART 0.29CH-2 400+ words, 150 speakersPC 1 PC 2 PC 3 PC 4WIS 0.35 CNOM 0.34 CVRB 0.41 LART -0.38WIT 0.35 CART 0.32 CADV -0.36 DFW -0.36AWL 0.33 CPRO -0.31 CPRO 0.33 FART 0.33CPTK -0.32 FART 0.30 CADJ -0.32 FADV 0.30CH-3 800+ words, 106 speakersPC 1 PC 2 PC 3 PC 4AWL -0.38 CNOM -0.41 CVRB 0.38 FART -0.41WIS -0.36 CPRP -0.30 CPRO 0.34 LART 0.39WIT -0.34 FADJ 0.29 CADJ -0.30 DFW 0.32CPTK 0.33 CADJ 0.29 FPRO 0.29 FADV -0.28TABA-1 30+ words, 780 speakersPC 1 PC 2 PC 3 PC 4CPRO -0.41 CWD -0.52 AWL 0.43 LITJ 0.42CVRB -0.38 CART -0.30 LADJ 0.40 CITJ 0.41WIT -0.36 AWL 0.29 CITJ -0.30 CADJ 0.35CNOM 0.28 CNOM 0.29 CPTK -0.30 LADJ 0.28TABA-2 40+ words, 409 speakersPC 1 PC 2 PC 3 PC 4CPRO -0.39 CWD 0.50 LITJ 0.53 LADJ 0.41WIT -0.35 AWL -0.39 CITJ 0.52 AWL 0.39CVRB -0.34 CPTK 0.32 CADJ 0.30 CART 0.33DFW -0.29 CNOM -0.30 LADJ 0.27 CITJ -0.31TABA-3 60+ words, 129 speakersPC 1 PC 2 PC 3 PC 4CPRO -0.38 AWL -0.50 CITJ 0.44 LADJ -0.39CVRB -0.35 CPTK 0.39 LITJ 0.42 CADJ -0.34WIT -0.35 CNOM -0.36 CART -0.34 CWD -0.30DFW -0.29 LADJ -0.35 CNUM 0.33 LNUM -0.30Figure 3: Component loads for the four most impor-tant principal components (PC) with varying input forthe three corpora.the number of adverbs/adjectives loads inversely tothe number of prepositions and nouns (VM-1 PC 1,VM-3 PC 4, CH-1 PC 4, CH-2 PC 3, CH-3 PC 2).pronouns: A pronoun or a noun can refer to a discourseentity, if that entity satisfies certain conditions.
Thenumber of pronouns loads inversely to the numberof articles and nouns (VM-1 PC 4, CH-1 PC 2, CH-2 PC 2) and adverbs/adjectives (VM-2 PC 4, CH-3 PC 2).
Pronominalization is only possible if thereferred entity is mentioned in the very recent dis-course context, ideally in the same turn; thus, longerturns favor pronominalization (VM-3 PC 3).ellipses: Ellipses are incomplete sentences where redun-dant information is omitted (often verbs, VM-2 PC2, VM-3 PC 2).
Final articles, adverbs, and adjec-tives can indicate elliptic utterances (CH-1 PC 3,CH-2 PC 4, CH-3 PC 4).turn complexity: Turns with pronouns and verbs arelong and very likely contain a complete sentence(TABA-1 PC 1, TABA-2 PC 1, TABA-3 PC 1).content words: The ratio of content words (less com-mon words) is high (TABA-1 PC 2, TABA-2 PC 2).Corpus PC 1 PC 2 PC 3 PC 4VM-1 adverbs wordlengthturnlengthpronounsVM-2 wordlengthellipses turnlengthpronounsVM-3 wordlengthellipses pronouns adverbsCH-1 turn/wordlengthpronouns ellipses adverbsCH-2 turn/wordlengthpronouns adverbs ellipsesCH-3 turn/wordlengthadverbs pronouns ellipsesTABA-1 turn com-plexitycontentwordswordlengthinterjectionsTABA-2 turn com-plexitycontentwordsinterjections wordlengthTABA-3 turn com-plexitywordlengthinterjections adjectivesFigure 4: Interpretation of the principal components dis-played in Figure 3.interjections: Interjections are rare in the TABA cor-pus.
An interjection may, therefore, distinguishspeakers (with interjections) from others (with-out interjections) (TABA-1 PC 4, TABA-2 PC 4,TABA-3 PC 3).While some of these components are corpus?specific(e.g.
interjections), others are important for all corpora(e.g.
word length or ellipses / turn complexity) or, atleast, for the syntactically complex human?human cor-pora (e.g.
pronouns and adverbs).The stability of the components was further checkedby forming four subsets of speakers and applying thePCA to all 16 combinations of these subsets.
A highernumber of observations (speakers) results in higher sta-bility.
For VM-1 and TABA-1 with 800 observations,all four components appear in every subset.
For VM-2and TABA-2 with 400 observations, three common com-ponents exist while the fourth (least important compo-nent) varies.
For CH-1 and VM-3 with approximately160 speakers, two common components are found in allsubsets.3.4 ClusteringIf a limited set of linguistically interpretable componentsexist, as has been argued for in the previous section, thequestion is whether speaker groups can be established,and whether unseen speakers can be reliably assigned thecorrect group.To establish classes the k?means algorithm was em-ployed.
This algorithm works by repeatedly moving allcluster centers to the mean of their Voronoi sets.
Thealgorithm stops, if no cluster center has changed duringthe last iteration or the maximum number of iterations isreached (Hartigan and Wong, 1979).
The initial clustercenters are randomly assigned, thus, slightly different re--4-3-2-101234-4 -3 -2 -1 0 1 2 3 4PC2PC 1Figure 5: Cluster center distribution in the plane spannedby the first two components for five runs with varied in-put values.sults are possible.
The algorithm results in a predefinednumber of speaker clusters (Doux et al, 1997) that canbe used to train automatic classifiers.If a specific interpretation of the clusters for a giventask is desired the clustering can be done by hand (i.e.by explicitly constructing borders between classes).
Inthe data-driven approach taken here, however, such hand-crafted constraints were avoided (the same holds for thePCA which could also be replaced by explicit rules).Figure 5 shows a distribution of cluster centers for fivedifferent runs on the same data but with different initialcluster centers.
The distribution displayed here in theplane of the first two components is fairly stable.The four most important principal components (mea-sured by their eigenvalue) computed for each speakerwere used as input for the subsequent tests.
This choicewas motivated by the results of the component stabilityexperiments described above.
The current set of speak-ers does not support a more fine?grained distinction.
Fur-thermore, it is unlikely that more dimensions will be use-ful for applications.3.5 ClassificationA correct classification of individual linguistic styles de-scribed by the parameter set used in this experimentmeans that a speaker is put into the same class by thecluster analysis and the automatic classification.
To testthis hypothesis the turns for each speaker were alter-nately divided into two sets of the same size.
The firstset was used for the training of the classifier (calculatePCA, estimate clusters to obtain classes).
The second setserved as a test set.
If the error rate (different classifica-tions for the training set and the test set) is substantiallylower than chance one can state that the parameters canbe used to reliably discriminate between speaker classes.Neural networks were used for automatic classifica-tion.
For training, two sets of input vectors were gen-erated from the original training set.
Every  -th patternbecame part of a development set (  is 5 for all experi-ments described here).
The output of the nets consistedof  output values (one for each class which is either 0or 1).
Fully connected feed forward nets with standardback propagation were trained until the error averagedover the last three runs on the development set begins toincrease (overtraining).
The net topology had one inputlayer, one output layer, and one hidden layer with thesame number of nodes as the input layer.The speaker specific values for the test set and thevalues for the principal components were computed andused as input for the neural network.
The classificationof the network was judged correct for one speaker, if thecluster determined by the cluster analysis on the trainingset was equal to the class predicted by the neural networkon the test set.The results are displayed in Figures 6 and 7.
Whilethe results for the TABA corpus are only slightly abovechance level (25 %), the results for the VM and CH cor-pora indicate that for human-human corpora a speakercan be fairly reliably classified.
If not enough turns orwords are available the result decreases.
The result de-creases also if the number of speakers is too small (below30, results are not shown here).4 DiscussionThese results indicate that style classification in a spo-ken dialogue system is only feasible if the number ofinteractions (turns) is sufficiently high and linguisticallyrich.
If this is the case, however, speakers can be classi-fied according to simple part-of-speech distribution andturn length parameters which can be computed automat-ically (Section 3.1), which can be automatically com-bined to components interpretable as linguistic style in-dicators (Section 3.3), that can be employed to automati-cally group speakers into classes (Section 3.4), which, inturn, can be used by automatic learning methods to clas-sify unseen turns from one speaker into the same classas the reference turns from the same speaker used duringthe training (Section 3.5).5 ApplicationsSeveral possible applications for linguistic style informa-tion exist in a spoken dialogue system.
Among these are style?specific language models, style?specific grammars, input to a general user model (certain elements oflinguistic style can be related to paradigm or taskknowledge, e.g.
turn length, number of contentwords), influencing the style of a language generation mod-ule.An exploratory experiment was undertaken for the firstapplication.Classification rate for the Verbmobil corpus02040608010053VM-a52VM-b57VM-c57VM-d% correctClassification rate for the CallHome corpus02040608010070CH-a75CH-b66CH-c66CH-d% correctClassification rate for the TABA corpus02040608010027TABA-a42TABA-b25TABA-c35TABA-d% correctFigure 6: Rate of correct classifications for the differentcorpora, displayed for varying input sets (see Figure 7for a description).5.1 Material and MethodThe three corpora described above were used for the in-vestigation.
For the CH and VM corpora all speakerswith more that 100 words were used; this threshold wasset to 40 for the TABA corpus.
The clustering methoddescribed above based on the results of a PCA was em-ployed to group the speakers into 2 to 4 clusters based on2 to 4 factors.
The k?means clustering algorithm with afixed set of clusters is initialized by random cluster cen-ters.
Thus, two subsequent runs give slightly differentresults.
Therefore, each run was performed twice.The four corpora plus their combination were dividedTask min.
Words min.
Turns Speakers Class.VM-a 100 20 188 53VM-b 100 30 109 52VM-c 400 20 125 57VM-d 400 30 87 57CH-a 100 40 144 70CH-b 100 60 60 75CH-c 400 40 99 66CH-d 400 60 47 66TABA-a 30 6 158 27TABA-b 30 8 65 42TABA-c 40 6 123 25TABA-d 40 8 53 34Figure 7: Data sets used in the classification task withminimal number of words and turns per single speaker asconstraints, and the resulting speaker number and classi-fication rate.into 10 sets for a ten?fold cross?validation.
One setserved as development set for parameter optimization,another set was the test set, and the remaining eight setswere used to train the language models.
In each run fivestandard bigram language models were trained, one foreach speaker-specific corpus and one for their combina-tion.
The perplexity was calculated for the pertinent testsets.In a subsequent step for each speaker?specific corpusthe general and the specific language models were lin-early interpolated; the interpolation factor was iteratedover the values 0, 0.2, 0.4, 0.6, 0.8, and 1.0.
The inter-polation factor which gave the best results (smallest per-plexity) for the development set was taken to computethe perplexity on the test set.5.2 ResultsWhen interpreting the results one has to keep a few thingsin mind: The assumption that the correct style class of aspeaker is known in advance is not likely to be truein real systems.
A few turns have to be analyzed inorder to perform a reasonable classification. The parameters used for classification (distributionsof part?of?speech items, length parameters etc.)
areonly very loosely related to the probability of wordsequences. The classes are not optimized to yield maximal gainin perplexity. The language models are rather simple.The global results are displayed in Figure 8.
The gen-eral model (with 4 times the training material than thespecial models) gives better results, except for the TABAcorpus which is probably sufficiently constrained andsimply structured to make up for the decrease in trainingmaterial.
This is in line with results described in Klarner(1997).
The interpolated model has a significantly lowerperplexity than the general model alone, but the gain isCorpus General Special Sig.
Interpol.
Sig.CallHome 215.1 236.4 yes 210.3 yesVerbmobil 106.2 115.0 yes 103.5 yesTABA 26.1 24.8 yes 23.1 yesFigure 8: Mean perplexity values for all comparisonruns (n=324) between style?specific and general lan-guage models (top) and between interpolated and generallanguage models (bottom).
Significance was calculatedby the paired t-test (one-sided, , ).so small that it is unlikely to improve recognition results.With all the caveats listed above one can conclude thatdetermination of linguistic style in the way described inthis document does not dramatically improve recognitionresults.6 ConclusionThis investigation showed that numerical parameter values can be computed forspeakers in spoken dialogue corpora, these parameters can be reduced to linguistically in-terpretable factors by means of a PCA, stable classes can be constructed from these factorsby cluster analysis, unseen class members can be reliably classified bytrained neural networks if the data is linguisticallyrich, style?specific language models reduce perplexityonly marginally.This process has been applied to three different corpora.It has been shown that it works in principle.
Further im-provements may be obtained by optimizing the proce-dure according to specific needs (e.g.
very quick classifi-cation, recognizing a speaker from a small set of possiblespeakers) which depend on the application.The methods can not only be applied to classify speak-ers according to their style, but also to recognize textgenre or speech act types.7 AcknowledgmentThis research was conducted within the SmartKomproject and partly funded by the German ministry of Re-search and Technology.ReferencesHarald Aust, Martin Oerder, Frank Seide, and Volker Steinbiss.1995.
The Philips automatic train timetable information sys-tem.
Speech Communication, 17:249?262.Susan E. Brennan.
1996.
Lexical entrainment in spontaneousdialog.
In Proc.
ISSD 96, pages 41?44.Penelope Brown and Stephen C. Levinson.
1987.
Politeness:some universals in language usage.
Cambridge UniversityPress, Cambridge.Christine Doran, John Aberdeen, Laurie Damianos, andLynette Hirschman.
2001.
Comparing several aspects ofhuman-computer and human-human dialogues.
In Proc.Second SIGDial Workshop on Discourse and Dialogue, Aal-borg.Anne-Claude Doux, Jean-Philippe Laurent, and Jean-PierreNadal.
1997.
Symbolic data analysis with the k?means al-gorithm for user profiling.
In User Modeling: Proccedingsof the UM 97, pages 359?361.Laurel Fais and Kyung Ho Loken-kim.
1995.
Lexical acom-modation in human-interpreted and machine-interpreteddual-language interactions.
In Proc.
ESCA Workshop onSpoken Dialogue Systems, page 69, Vigs?, Denmark.Laurel Fais, Kyung-Ho Loken-Kim, and Tsuyoshi Morimoto.1996.
How Many Words is a Picture Really Worth?
InProc.
ICSLP?96, Philadelphia, USA.Joakim Gustafson, Anette Larsson, Rolf Carlson, and K. Hell-man.
1997.
How do system questions influence lexicalchoices in user answers?
In Proc.
Eurospeech ?97, pages2275?2278, Rhodes, Greece, September.J.
A. Hartigan and M. A. Wong.
1979.
A k-means clusteringalgorithm.
Applied Statistics, 28:100?108.Jussi Karlgren and Douglas Cutting.
1994.
Recognizing textgenres with simple metrics using discriminant analysis.
InProc.
Coling 94, Kyoto.Jussi Karlgren.
1994.
Stylistic variation in an information re-trieval experiment.
In Proceedings of NEMLAP-2.Martin Klarner.
1997.
Klassifikation von Sprechstilen mitlinguistischem Wissen.
Master?s thesis, IMMD, Friedrich-Alexander-Universita?t, Erlangen.Jill Fain Lehman and Jaime G. Carbonell.
1989.
Learning theuser?s language: A step towards automated creation of usermodels.
In Alfred Kobsa and Wolfgang Wahlster, editors,User Models in Dialog Systems.
Springer Verlag, Berlin?New York.Linguistic Data Consortium.
1997.
Callhome transcript corpusof German telephone speech.K.
V. Mardia, J. T. Kent, and J. M. Bibby.
1979.
MultivariateAnalysis.
Academic Press, London.T.
C. Mendenhall.
1887.
The characteristic curves of compo-sition.
Science, 9(214):237?249.Michio Okada, Noriko Suzuki, and Masaaki Date.
1999.
So-cial bonding in talking with social autonomous creatures.In Proc.
Eurospeech 99, volume 4, pages 1731?1734, Bu-dapest.Sharon L. Oviatt and Philip R. Cohen.
1991.
Discourse struc-ture and performance efficiency in interactive and non?interactive spoken modalities.
Computer Speech and Lan-guage, 5:297?326.Sharon L. Oviatt, Philip R. Cohen, and Micelle Wang.
1994.Toward interface design for human language technology:Modality and structure as determinants of linguistic com-plexity.
Speech Communication, 15:283?300.Daniel Paiva.
2000.
Investigating style in a corpus of phar-maceutical leaflets: Results of a factor analysis.
In Proc.Annual Meeting of the ACL, Student Session, pages 52?59,Hong Kong.Ursula Pieper.
1979.
?Uber die Aussagekraft statistischer Meth-oden fu?r die linguistische Stilanalyse.
Narr, Tu?bingen.Elaine M. Rich.
1979.
User modeling via stereotypes.
Cogni-tive Science, 3:329?354.Klaus Ries.
1999.
Towards the detection and description oftextual meaning indicators in spontaneous conversations.In Proc.
Eurospeech 99, volume 3, pages 1415?1418, Bu-dapest.Anne Schiller, Simone Teufel, Christine Thielen, and Chris-tine Sto?ckert.
1995.
Vorla?ufige guidelines fu?r das taggendeutscher textcorpora mit stts.
Technical report, IMS, Uni-versita?t Stuttgart.Helmut Schmid.
1994.
Probabilistic part-of-speech taggingusing decision trees.
In International Conference on NewMethods in Language Processing, Manchester, UK, Septem-ber.W.
Wahlster, N. Reithinger, and A. Blocher.
2001.
Smartkom:Multimodal communication with a life-like character.
InProceedings of the Eurospeech 2001, pages 1547?1550,Aalborg, Denmark.Wolfgang Wahlster.
1993.
VERBMOBIL?translation of face-to-face dialogs.
In Otthein Herzog, Thomas Christaller, andDieter Schu?tt, editors, Grundlagen und Anwendungen derKu?nstlichen Intelligenz.
17.
Fachtagung fu?r Ku?nstliche In-telligenz, pages 393?402, Berlin, Heidelberg, New York.Springer.
Informatik Aktuell.Marilyn A. Walker, Janet E. Cahn, and Stephen J. Whittaker.1997.
Improvising linguistic style: Social and affectivebases of agent personality.
In W. Lewis Johnson and Bar-bara Hayes-Roth, editors, Proceedings of the 1st Interna-tional Conference on Autonomous Agents, pages 96?105,New York, February 5?8.
ACM Press.Maria Wolters and Mathias Kirsten.
1999.
Exploring the useof linguistic features in domain and genre classification.
InProc.
EACL 99, Bergen.
