Proceedings of the 43rd Annual Meeting of the ACL, pages 597?604,Ann Arbor, June 2005. c?2005 Association for Computational LinguisticsParaphrasing with Bilingual Parallel CorporaColin Bannard Chris Callison-BurchSchool of InformaticsUniversity of Edinburgh2 Buccleuch PlaceEdinburgh, EH8 9LW{c.j.bannard, callison-burch}@ed.ac.ukAbstractPrevious work has used monolingual par-allel corpora to extract and generate para-phrases.
We show that this task can bedone using bilingual parallel corpora, amuch more commonly available resource.Using alignment techniques from phrase-based statistical machine translation, weshow how paraphrases in one languagecan be identified using a phrase in anotherlanguage as a pivot.
We define a para-phrase probability that allows paraphrasesextracted from a bilingual parallel corpusto be ranked using translation probabili-ties, and show how it can be refined totake contextual information into account.We evaluate our paraphrase extraction andranking methods using a set of manualword alignments, and contrast the qual-ity with paraphrases extracted from auto-matic alignments.1 IntroductionParaphrases are alternative ways of conveying thesame information.
Paraphrases are useful in a num-ber of NLP applications.
In natural language gen-eration the production of paraphrases allows for thecreation of more varied and fluent text (Iordanskajaet al, 1991).
In multidocument summarization theidentification of paraphrases allows information re-peated across documents to be condensed (McKe-own et al, 2002).
In the automatic evaluation ofmachine translation, paraphrases may help to alle-viate problems presented by the fact that there areoften alternative and equally valid ways of translat-ing a text (Pang et al, 2003).
In question answering,discovering paraphrased answers may provide addi-tional evidence that an answer is correct (Ibrahim etal., 2003).In this paper we introduce a novel method for ex-tracting paraphrases that uses bilingual parallel cor-pora.
Past work (Barzilay and McKeown, 2001;Barzilay and Lee, 2003; Pang et al, 2003; Ibrahim etal., 2003) has examined the use of monolingual par-allel corpora for paraphrase extraction.
Examplesof monolingual parallel corpora that have been usedare multiple translations of classical French novelsinto English, and data created for machine transla-tion evaluation methods such as Bleu (Papineni etal., 2002) which use multiple reference translations.While the results reported for these methods areimpressive, their usefulness is limited by the scarcityof monolingual parallel corpora.
Small data setsmean a limited number of paraphrases can be ex-tracted.
Furthermore, the narrow range of text gen-res available for monolingual parallel corpora limitsthe range of contexts in which the paraphrases canbe used.Instead of relying on scarce monolingual paralleldata, our method utilizes the abundance of bilingualparallel data that is available.
This allows us to cre-ate a much larger inventory of phrases that is appli-cable to a wider range of texts.Our method for identifying paraphrases is anextension of recent work in phrase-based statisti-cal machine translation (Koehn et al, 2003).
Theessence of our method is to align phrases in a bilin-gual parallel corpus, and equate different Englishphrases that are aligned with the same phrase in theother language.
This assumption of similar mean-597Emma burst into tears and he tried to comforther, saying things to make her smile.Emma cried, and he tried to console her, adorn-ing his words with puns.Figure 1: Using a monolingal parallel corpus to ex-tract paraphrasesing when multiple phrases map onto a single for-eign language phrase is the converse of the assump-tion made in the word sense disambiguation work ofDiab and Resnik (2002) which posits different wordsenses when a single English word maps onto differ-ent words in the foreign language (we return to thispoint in Section 4.4).The remainder of this paper is as follows: Section2 contrasts our method for extracting paraphraseswith the monolingual case, and describes how werank the extracted paraphrases with a probabilityassignment.
Section 3 describes our experimentalsetup and includes information about how phraseswere selected, how we manually aligned parts of thebilingual corpus, and how we evaluated the para-phrases.
Section 4 gives the results of our evalua-tion and gives a number of example paraphrases ex-tracted with our technique.
Section 5 reviews relatedwork, and Section 6 discusses future directions.2 Extracting paraphrasesMuch previous work on extracting paraphrases(Barzilay and McKeown, 2001; Barzilay and Lee,2003; Pang et al, 2003) has focused on finding iden-tifying contexts within aligned monolingual sen-tences from which divergent text can be extracted,and treated as paraphrases.
Barzilay and McKeown(2001) gives the example shown in Figure 1 of howidentical surrounding substrings can be used to ex-tract the paraphrases of burst into tears as cried andcomfort as console.While monolingual parallel corpora often haveidentical contexts that can be used for identifyingparaphrases, bilingual parallel corpora do not.
In-stead, we use phrases in the other language as piv-ots: we look at what foreign language phrases theEnglish translates to, find all occurrences of thoseforeign phrases, and then look back at what otherEnglish phrases they translate to.
We treat the otherEnglish phrases as potential paraphrases.
Figure 2 il-lustrates how a German phrase can be used as a pointof identification for English paraphrases in this way.Section 2.1 explains which statistical machine trans-lation techniques are used to align phrases withinsentence pairs in a bilingual corpus.A significant difference between the present workand that employing monolingual parallel corpora, isthat our method frequently extracts more than onepossible paraphrase for each phrase.
We assign aprobability to each of the possible paraphrases.
Thisis a mechanism for ranking paraphrases, which canbe utilized when we come to select the correct para-phrase for a given context .
Section 2.2 explains howwe calculate the probability of a paraphrase.2.1 Aligning phrase pairsWe use phrase alignments in a parallel corpus aspivots between English paraphrases.
We find thesealignments using recent phrase-based approaches tostatistical machine translation.The original formulation of statistical machinetranslation (Brown et al, 1993) was defined as aword-based operation.
The probability that a foreignsentence is the translation of an English sentence iscalculated by summing over the probabilities of allpossible word-level alignments, a, between the sen-tences:p(f |e) =?ap(f ,a|e)Thus Brown et al decompose the problem of de-termining whether a sentence is a good translationof another into the problem of determining whetherthere is a sensible mapping between the words in thesentences.More recent approaches to statistical translationcalculate the translation probability using largerblocks of aligned text.
Koehn (2004), Tillmann(2003), and Vogel et al (2003) describe variousheuristics for extracting phrase alignments from theViterbi word-level alignments that are estimated us-ing Brown et al (1993) models.
We use the heuris-tic for phrase alignment described in Och and Ney(2003) which aligns phrases by incrementally build-ing longer phrases from words and phrases whichhave adjacent alignment points.11Note that while we induce the translations of phrases from598what is more, the relevant cost dynamic is completely under controlim ?brigen ist die diesbez?gliche kostenentwicklung v?llig  unter kontrollewe owe it to the taxpayers to keep in checkthe costswir sind es den steuerzahlern die kosten zu habenschuldig  unter kontrolleFigure 2: Using a bilingual parallel corpus to extract paraphrases2.2 Assigning probabilitiesWe define a paraphrase probability p(e2|e1) in termsof the translation model probabilities p(f |e1), thatthe original English phrase e1 translates as a partic-ular phrase f in the other language, and p(e2|f), thatthe candidate paraphrase e2 translates as the foreignlanguage phrase.
Since e1 can translate as multipleforeign language phrases, we sum over f :e?2 = arg maxe2 6=e1p(e2|e1) (1)= arg maxe2 6=e1?fp(f |e1)p(e2|f) (2)The translation model probabilities can be com-puted using any standard formulation from phrase-based machine translation.
For example, p(e|f)can be calculated straightforwardly using maximumlikelihood estimation by counting how often thephrases e and f were aligned in the parallel corpus:p(e|f) =count(e, f)?e count(e, f)(3)Note that the paraphrase probability defined inEquation 2 returns the single best paraphrase, e?2, ir-respective of the context in which e1 appears.
Sincethe best paraphrase may vary depending on informa-tion about the sentence that e1 appears in, we extendthe paraphrase probability to include that sentenceS:e?2 = arg maxe2 6=e1p(e2|e1, S) (4)word-level alignments in this paper, direct estimation of phrasaltranslations (Marcu and Wong, 2002) would also suffice for ex-tracting paraphrases from bilingual corpora.a million, as far as possible, at work, big business,carbon dioxide, central america, close to, concen-trate on, crystal clear, do justice to, driving force,first half, for the first time, global warming, greatcare, green light, hard core, horn of africa, last re-sort, long ago, long run, military action, militaryforce, moment of truth, new world, noise pollution,not to mention, nuclear power, on average, only too,other than, pick up, president clinton, public trans-port, quest for, red cross, red tape, socialist party,sooner or later, step up, task force, turn to, undercontrol, vocational training, western sahara, worldbankTable 1: Phrases that were selected to paraphraseS allows us to re-rank the candidate paraphrasesbased on additional contextual information.
The ex-periments in this paper employ one variety of con-textual information.
We include a simple languagemodel probability, which would additionally ranke2 based on the probability of the sentence formedby substiuting e2 for e1 in S. A possible extensionwhich we do not evaluate might be permitting onlyparaphrases that are the same syntactic type as theoriginal phrase, which we could do by extending thetranslation model probabilities to count only phraseoccurrences of that type.3 Experimental DesignWe extracted 46 English phrases to paraphrase(shown in Table 1), randomly selected from thosemulti-word phrases in WordNet which also occuredmultiple times in the first 50,000 sentences of ourbilingual corpus.
The bilingual corpus that we used599Alignment Tool.kontrolleunterv?lligkostenentwickl...diesbez?glichedieist?brigenim.controlundercompletelyisdynamiccostrelevantthe,moreiswhat(a) Aligning the English phrase to be paraphrasedhabenzukontrolleunterkostendieschuldigsteuerzahlerndenessindwir.checkincoststhekeeptotaxpayersthetoitoweweAlignment Tool(b) Aligning occurrences of its German translationFigure 3: Phrases highlighted for manual alignmentwas the German-English section of the Europarl cor-pus, version 2 (Koehn, 2002).
We produced auto-matic alignments for it with the Giza++ toolkit (Ochand Ney, 2003).
Because we wanted to test ourmethod independently of the quality of word align-ment algorithms, we also developed a gold standardof word alignments for the set of phrases that wewanted to paraphrase.3.1 Manual alignmentThe gold standard alignments were created by high-lighting all occurrences of the English phrase toparaphrase and manually aligning it with its Ger-man equivalent by correcting the automatic align-ment, as shown in Figure 3a.
All occurrences ofits German equivalents were then highlighted, andaligned with their English translations (Figure 3b).The other words in the sentences were left with theirautomatic alignments.3.2 Paraphrase evaluationWe evaluated the accuracy of each of the para-phrases that was extracted from the manuallyaligned data, as well as the top ranked paraphrasesfrom the experimental conditions detailed below inSection 3.3.
Because the acccuracy of paraphrasescan vary depending on context, we substituted eachUnder controlThis situation is in check in terms of security.This situation is checked in terms of security.This situation is curbed in terms of security.This situation is curb in terms of security.This situation is limit in terms of security.This situation is slow down in terms of security.Figure 4: Paraphrases substituted in for the originalphraseset of candidate paraphrases into between 2?10 sen-tences which contained the original phrase.
Figure 4shows the paraphrases for under control substitutedinto one of the sentences in which it occurred.
Wecreated a total of 289 such evaluation sets, with atotal of 1366 unique sentences created through sub-stitution.We had two native English speakers producejudgments as to whether the new sentences pre-served the meaning of the original phrase and as towhether they remained grammatical.
Paraphrasesthat were judged to preserve both meaning andgrammaticality were considered to be correct, andexamples which failed on either judgment were con-sidered to be incorrect.In Figure 4 in check, checked, and curbed were600under control checked, curb, curbed, in check, limit, slow downsooner or later at some point, eventuallymilitary force armed forces, defence, force, forces, military forces, peace-keeping personnellong ago a little time ago, a long time, a long time ago, a lot of time, a while ago, a while back,far, for a long time, for some time, for such a long time, long, long period of time, longterm, long time, long while, overdue, some time, some time agogreen light approval, call, go-ahead, indication, message, sign, signal, signals, formal go-aheadgreat care a careful approach, greater emphasis, particular attention, special attention, specificattention, very carefulfirst half first six monthscrystal clear absolutely clear, all clarity, clear, clearly, in great detail, no mistake, no uncertain,obvious, obviously, particularly clear, perfectly clear, quite clear, quite clearly, quiteexplicitly, quite openly, very clear, very clear and comprehensive, very clearly, verysure, very unclear, very wellcarbon dioxide co2at work at the workplace, employment, held, holding, in the work sphere, operate, organised,taken place, took place, workingTable 2: Paraphrases extracted from a manually word-aligned parallel corpusjudged to be correct and curb, limit and slow downwere judged to be incorrect.
The inter-annotatoragreement for these judgements was measured at?
= 0.605, which is conventionally interpreted as?good?
agreement.3.3 ExperimentsWe evaluated the accuracy of top ranked paraphraseswhen the paraphrase probability was calculated us-ing:1.
The manual alignments,2.
The automatic alignments,3.
Automatic alignments produced over multiplecorpora in different languages,4.
All of the above with language model re-ranking.5.
All of the above with the candidate paraphraseslimited to the same sense as the original phrase.4 ResultsWe report the percentage of correct translations (ac-curacy) for each of these experimental conditions.
Asummary of these can be seen in Table 3.
This sec-tion will describe each of the set-ups and the scorereported in more detail.4.1 Manual alignmentsTable 2 gives a set of example paraphrases extractedfrom the gold standard alignments.
The italicizedparaphrases are those that were assigned the highestprobability by Equation 2, which chooses a singlebest paraphrase without regard for context.
The 289sentences created by substituting the italicized para-phrases in for the original phrase were judged to becorrect an average of 74.9% of the time.Ignoring the constraint that the new sentences re-main grammatically correct, these paraphrases werejudged to have the correct meaning 84.7% of thetime.
This suggests that the context plays a moreimportant role with respect to the grammaticalityof substituted paraphrases than with respect to theirmeaning.In order to allow the surrounding words in the sen-tence to have an influence on which paraphrase wasselected, we re-ranked the paraphrase probabilitiesbased on a trigram language model trained on theentire English portion of the Europarl corpus.
Para-phrases were selected from among all those in Table2, and not constrained to the italicized phrases.
Inthe case of the paraphrases extracted from the man-ual word alignments, the language model re-rankinghad virtually no influence, and resulted in a slightdip in accuracy to 71.7%601Paraphrase Prob Paraphrase Prob & LM Correct MeaningManual Alignments 74.9 71.7 84.7Automatic Alignments 48.9 55.3 64.5Using Multiple Corpora 55.0 57.4 65.4Word Sense Controlled 57.0 61.9 70.4Table 3: Paraphrase accuracy and correct meaning for the different data conditions4.2 Automatic alignmentsIn this experimental condition paraphrases were ex-tracted from a set of automatic alignments producedby running Giza++ over a set of 1,036,000 German-English sentence pairs (roughly 28,000,000 words ineach language).
When the single best paraphrase (ir-respective of context) was used in place of the orig-inal phrase in the evaluation sentence the accuracyreached 48.9% which is quite low compared to the74.9% of the manually aligned set.As with the manual alignments it seems that weare selecting phrases which have the correct mean-ing but are not grammatical in context.
Indeed ourjudges thought the meaning of the paraphrases tobe correct in 64.5% of cases.
Using a languagemodel to select the best paraphrase given the con-text reduces the number of ungrammatical examplesand gives an improvement in quality from 48.9% to55.3% correct.These results suggest two things: that improvingthe quality of automatic alignments would lead tomore accurate paraphrases, and that there is roomfor improvement in limiting the paraphrases by theircontext.
We address these points below.4.3 Using multiple corporaWork in statistical machine translation suggests that,like many other machine learning problems, perfor-mance increases as the amount of training data in-creases.
Och and Ney (2003) show that the accuracyof alignments produced by Giza++ improve as thesize of the training corpus increases.Since we used the whole of the German-Englishsection of the Europarl corpus, we could not tryimproving the alignments by simply adding moreGerman-English training data.
However, there isnothing that limits our paraphrase extraction methodto drawing on candidate paraphrases from a sin-gle target language.
We therefore re-formulated theparaphrase probability to include multiple corpora,as follows:e?2 = arg maxe2 6=e1?C?f in Cp(f |e1)p(e2|f) (5)where C is a parallel corpus from a set of parallelcorpora.For this condition we used Giza++ to alignthe French-English, Spanish-English, and Italian-English portions of the Europarl corpus in additionto the German-English portion, for a total of around4,000,000 sentence pairs in the training data.The accuracy of paraphrases extracted over mul-tiple corpora increased to 55%, and further to 57.4%when the language model re-ranking was included.4.4 Controlling for word senseAs mentioned in Section 1, the way that we extractparaphrases is the converse of the methodology em-ployed in word sense disambiguation work that usesparallel corpora (Diab and Resnik, 2002).
The as-sumption made in the word sense disambiguationwork is that if a source language word aligns withdifferent target language words then those wordsmay represent different word senses.
This can beobserved in the paraphrases for at work in Table 2.The paraphrases at the workplace, employment, andin the work sphere are a different sense of the phrasethan operate, held, and holding, and they are alignedwith different German phrases.When we calculate the paraphrase probability wesum over different target language phrases.
There-fore the English phrases that are aligned with the dif-ferent German phrases (which themselves maybe in-dicative of different word senses) are mingled.
Per-formance may be degraded since paraphrases thatreflect different senses of the original phrase, andwhich therefore have a different meaning, are in-cluded in the same candidate set.602We therefore performed an experiment to seewhether improvement could be had by limiting thecandidate paraphrases to be the same sense as theoriginal phrase in each test sentence.
To do this,we used the fact that our test sentences were drawnfrom a parallel corpus.
We limited phrases to thesame word sense by constraining the candidate para-phrases to those that aligned with the same targetlanguage phrase.
Our basic paraphrase calculationwas therefore:p(e2|e1, f) = p(f |e1)p(e2|f) (6)Using the foreign language phrase to identify theword sense is obviously not applicable in monolin-gual settings, but acts as a convenient stand-in for aproper word sense disambiguation algorithm here.When word sense is controlled in this way, theaccuracy of the paraphrases extracted from the au-tomatic alignments raises dramatically from 48.9%to 57% without language model re-ranking, and fur-ther to 61.9% when language model re-ranking wasincluded.5 Related WorkBarzilay and McKeown (2001) extract both single-and multiple-word paraphrases from a monolingualparallel corpus.
They co-train a classifier to iden-tify whether two phrases were paraphrases of eachother based on their surrounding context.
Two dis-advantages of this method are that it requires iden-tical bounding substrings, and has bias towards sin-gle words.
For an evaluation set of 500 paraphrases,they report an average precision of 86% at identi-fying paraphrases out of context, and of 91% whenthe paraphrases are substituted into the original con-text of the aligned sentence.
The results of our sys-tems are not directly comparable, since Barzilay andMcKeown (2001) evaluated their paraphrases with adifferent set of criteria (they asked judges whetherto judge paraphrases based on ?approximate con-ceptual equivalence?).
Furthermore, their evaluationwas carried out only by substituting the paraphrasein for the phrase with the identical context, and notin for arbitrary occurrences of the original phrase, aswe have done.Lin and Pantel (2001) use a standard (non-parallel) monolingual corpus to generate para-phrases, based on dependancy graphs and distribu-tional similarity.
One strong disadvantage of thismethod is that their paraphrases can also have op-posite meanings.Ibrahim et al (2003) combine the two approaches:aligned monolingual corpora and parsing.
Theyevaluated their system with human judges who wereasked whether the paraphrases were ?roughly inter-changeable given the genre?, scored an average of41% on a set of 130 paraphrases, with the judgesall agreeing 75% of the time, and a correlation of0.66.
The shortcomings of this method are that it isdependent upon parse quality, and is limited by therareness of the data.Pang et al (2003) use parse trees over sentences inmonolingual parallel corpus to identify paraphrasesby grouping similar syntactic constituents.
Theyuse heuristics such as keyword checking to limitthe over-application of this method.
Our alignmentmethod might be an improvement of their heuris-tics for choosing which constituents ought to begrouped.6 Discussion and Future WorkIn this paper we have introduced a novel method forextracting paraphrases, which we believe greatly in-creases the usefulness of paraphrasing in NLP ap-plications.
The advantages of our method are thatit:?
Produces a ranked list of high quality para-phrases with associated probabilities, fromwhich the best paraphrase can be chosen ac-cording to the target context.
We have shownhow a language model can be used to select thebest paraphrase for a particular context fromthis list.?
Straightforwardly handles multi-word units.Whereas for previous approaches the evalua-tion has been performed over mostly singleword paraphrases, our results are reported ex-clusively over units of between 2 and 4 words.?
Because we use a much more abundant sourceof data, our method can be used for a muchwider range of text genres than previous ap-proaches, namely any for which parallel datais available.603One crucial thing to note is that we have demon-strated our paraphrases to be of higher quality whenthe alignments used to produce them are improved.This means that our method will reap the benefitsof research that improvements to automatic align-ment techniques (Callison-Burch et al, 2004), andwill further improve as more parallel data becomesavailable.In the future we plan to:?
Investigate whether our re-ranking can be fur-ther improved by using a syntax-based lan-guage model.?
Formulate a paraphrase probability for senten-tial paraphrases, and use this to try to identifyparaphrases across documents in order to con-dense information for multi-document summa-rization.?
See whether paraphrases can be used to in-crease coverage for statistical machine trans-lation when translating into ?low-density?
lan-guages which have small parallel corpora.AcknowledgmentsThe authors would like to thank Beatrice Alex,Marco Kuhlmann, and Josh Schroeder for their valu-able input as well as their time spent annotating andcontributing to the software.ReferencesRegina Barzilay and Lillian Lee.
2003.
Learning toparaphrase: An unsupervised approach using multiple-sequence alignment.
In Proceedings of HLT/NAACL.Regina Barzilay and Kathleen McKeown.
2001.
Extract-ing paraphrases from a parallel corpus.
In Proceedingsof ACL.Peter Brown, Stephen Della Pietra, Vincent Della Pietra,and Robert Mercer.
1993.
The mathematics of ma-chine translation: Parameter estimation.
Computa-tional Linguistics, 19(2):263?311, June.Chris Callison-Burch, David Talbot, and Miles Osborne.2004.
Statistical machine translation with word- andsentence-aligned parallel corpora.
In Proceedings ofACL.Mona Diab and Philip Resnik.
2002.
An unsupervisedmethod for word sense tagging using parallel corpora.In Proceedings of ACL.Ali Ibrahim, Boris Katz, and Jimmy Lin.
2003.
Extract-ing structural paraphrases from aligned monolingualcorpora.
In Proceedings of the Second InternationalWorkshop on Paraphrasing (ACL 2003).Lidija Iordanskaja, Richard Kittredge, and Alain Polge?re.1991.
Lexical selection and paraphrase in a meaning-text generation model.
In Ce?cile L. Paris, William R.Swartout, and William C. Mann, editors, Natural Lan-guage Generation in Artificial Intelligence and Com-putational Linguistics.
Kluwer Academic.Philipp Koehn, Franz Josef Och, and Daniel Marcu.2003.
Statistical phrase-based translation.
In Proceed-ings of HLT/NAACL.Philipp Koehn.
2002.
Europarl: A multilingual corpusfor evaluation of machine translation.
UnpublishedDraft.Philipp Koehn.
2004.
Pharaoh: A beam search decoderfor phrase-based statistical machine translation mod-els.
In Proceedings of AMTA.Dekang Lin and Patrick Pantel.
2001.
DIRT - discov-ery of inference rules from text.
In Proceedings ofACM SIGKDD Conference on Knowledge Discoveryand Data Mining.Daniel Marcu and William Wong.
2002.
A phrase-based,joint probability model for statistical machine transla-tion.
In Proceedings of EMNLP.Kathleen R. McKeown, Regina Barzilay, David Evans,Vasileios Hatzivassiloglou, Judith L. Klavans, AniNenkova, Carl Sable, Barry Schiffman, and SergeySigelman.
2002.
Tracking and summarizing news ona daily basis with Columbia?s Newsblaster.
In Pro-ceedings of the Human Language Technology Confer-ence.Franz Josef Och and Hermann Ney.
2003.
A system-atic comparison of various statistical alignment mod-els.
Computational Linguistics, 29(1):19?51, March.Bo Pang, Kevin Knight, and Daniel Marcu.
2003.Syntax-based alignment of multiple translations: Ex-tracting paraphrases and generating new sentences.
InProceedings of HLT/NAACL.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
Bleu: A method for automatic evalu-ation of machine translation.
In Proceedings of ACL.Christoph Tillmann.
2003.
A projection extension algo-rithm for statistical machine translation.
In Proceed-ings of EMNLP.Stephan Vogel, Ying Zhang, Fei Huang, Alicia Trib-ble, Ashish Venugopal, Bing Zhao, and Alex Waibel.2003.
The CMU statistical machine translation sys-tem.
In Proceedings of MT Summit 9.604
