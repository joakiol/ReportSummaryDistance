Workshop on Computational Linguistics and Clinical Psychology: From Linguistic Signal to Clinical Reality, pages 107?117,Baltimore, Maryland USA, June 27, 2014.c?2014 Association for Computational LinguisticsToward Macro-Insights for Suicide Prevention:Analyzing Fine-Grained Distress at ScaleChristopher M. Homan1Ravdeep Johar1Tong Liu1Megan Lytle2Vincent Silenzio2Cecilia O. Alm31Golisano College of Computing and Information Sciences, Rochester Institute of Technology2Department of Psychiatry, University of Rochester Medical Center3College of Liberal Arts, Rochester Institute of Technology{cmh?| rsj7209$| tl8313$| Megan Lytle?| Vincent Silenzio?| coagla$}?@cs.rit.edu$@rit.edu?
@urmc.rochester.eduAbstractSuicide is a leading cause of death in theUnited States.
One of the major chal-lenges to suicide prevention is that thosewho may be most at risk cannot be re-lied upon to report their conditions to clin-icians.
This paper takes an initial steptoward the automatic detection of suici-dal risk factors through social media ac-tivity, with no reliance on self-reporting.We consider the performance of annota-tors with various degrees of expertise insuicide prevention at annotating microblogdata for the purpose of training text-basedmodels for detecting suicide risk behav-iors.
Consistent with crowdsourcing liter-ature, we found that novice-novice anno-tator pairs underperform expert annotatorsand outperform automatic lexical analysistools, such as Linguistic Inquiry and WordCount.1 IntroductionSuicide is among the leading causes of death forindividuals 10?44 years of age in the United States(Heron and Tejada-Vera, 2009).
Indeed, whilemortality rates for most illnesses decreased be-tween 2008 and 2009, the rate of suicide increasedby 2.4% (Heron and Tejada-Vera, 2009).
The life-time prevalence for suicidal ideation is 5.6?14.3%in the general population, and as high as 19.8?24.0% among youth (Nock et al., 2008).The first step toward suicide prevention is toidentify, ideally in consultation with clinical ex-perts, the risk factors associated with suicide.
Dueto social stigma among other sociocultural fac-tors (Crosby et al., 2011), individuals at risk forcommitting suicide may not always reach out toprofessionals or, if they do, provide them withaccurate information.
They may not even real-ize their own level of suicide risk before it is toolate.
Self-reporting, then, is not an entirely reliablemeans of detecting and assessing suicide risk, andresearch on suicide prevention can benefit fromalso exploring other channels for assessing risk.For instance, individuals may be more inclinedto seek support from informal resources, such associal media, instead of seeking treatment (Crosbyet al., 2011; Bruffaerts et al., 2011; Ryan et al.,2010).
Evidence suggests that youth and emerg-ing adults usually prefer to seek help from theirfriends and families; however, higher levels ofsuicidal ideation are associated with lower levelsof help-seeking from both formal or informal re-sources (Deane et al., 2001).These patterns in help-seeking behavior sug-gest that social media might be an impor-tant channel for discovering those at risk for?and even preventing?suicide.
Internet- andtelecommunications-driven activity is revolution-izing the social sciences by providing data, muchof it publicly available, on human activity in situ,at volumes and a level of time and space granu-larity never before approached.
Can such data im-prove clinical preventative study and measures byproviding access to at-risk individuals who wouldotherwise go undetected, and by leading to betterscience about suicide risk behaviors?The stress-diathesis model for suicidal behav-ior (Mann et al., 1999) suggests that they might.
Itsays that (1) objective states, such as depression orlife events, as well as subjective states and traits,such as substance abuse or family history of de-pression, suicide, or substance abuse, are amongthe risk factors that contribute to suicidal ideationand (2) the presence of these factors could even-tually lead to either externalizing (e.g., interper-107sonal violence) or internalizing aggression (e.g.,attempting suicide).Since the stress-diathesis model was developedusing risk factors for suicidal behavior, and be-cause it makes a connection between internalizedand externalized acts, it is a suitable framework foranalyzing publicly available linguistic data fromsocial media outlets such as Twitter.
Data from so-cial media can be seen as a kind of natural exper-iment on depression and suicidal ideation that isunburdened by such sample biases as the willing-ness of individuals to take part in research and/orseek out formal sources of support.
Moreover, thisapproach may provide information about individ-uals who are unlikely to engage in formal help-seeking behaviors, or may inform effective meth-ods of natural helping.
Thus, this macro-level ap-proach to monitoring suicidal behaviors may havefuture implications not only for identifying indi-viduals who have a higher prevalence for suicidalbehaviors but it could eventually lead to additionalmethods for enhancing protective factors againstsuicide.In this paper, we take steps toward the auto-matic detection of suicide risk among individualsvia social media.
Suicide ideation is a complex be-havior and its connection to suicide itself remainspoorly understood.
We focus on a particular aspectof suicidality, namely distress.
While not equiva-lent to suicide ideation, according to Nock et al.
(2010) distress is an important risk factor in sui-cide, and one that is observable from microblogtext, though admittedly observing suicide risk be-havior is a subjective and noisy venture.Lehrman et al.
(2012) conducted an early studyon the computational modeling of distress basedon short forum texts, yet left many areas wide openfor continued study.
For example, analysis at scaleis one such open issue.
More specifically, Pestianand colleagues (Matykiewicz et al., 2009; Pestianet al., 2008) used computational methods to under-stand suicide notes.
However, when it comes topreventive contexts, such data are less insightful.For preventive health, access to real-time health-related data that dynamically evolve can allow usto address macro-level analysis.
Social media pro-vide an additional opportunity to model the phe-nomena of interest at scale.We use methods that take advantage of lexicalanalysis to retrieve microblog posts (tweets) fromTwitter and compare the performance of humanannotators?one being an expert, and others not?to rate the level of distress of each tweet.Clinical expert annotation, rather than general-purpose tools for content and sentiment analy-sis such as LIWC (Linguistic Inquiry and WordCount) by Pennebaker et al.
(2001), provides a ba-sis for text-based statistical modeling.
We showthat expertise-based keyword retrieval, departingfrom knowledge about contributing risk factors,results in better interannotator agreement in bothnovice-novice and novice-expert annotation whenthe keywords reflect the task at hand.2 Related WorkData on suicide traditionally comes from health-care organizations, large-scale studies, or self re-porting (Crosby et al., 2011; Horowitz and Bal-lard, 2009).
These sources are limited by sociocul-tural barriers (Crosby et al., 2011), such as stigmaand shame.
Moreover, data on suicide is never par-ticularly reliable because suicide is a fundamen-tally subjective, complex phenomenon with a lowbase rate.
For these reasons, many researcherstend to focus on the relationship between risk fac-tors and suicidal behavior, without relying heavilyon theoretical models (Nock et al., 2008).Approximately one-third of all individuals whoreported suicidal ideation in their lifetime made aplan to commit suicide.
Nearly three-quarters ofthose who reported making a suicide plan actu-ally attempted.
The odds of attempting suicide in-creased exponentially when individuals endorsedthree or more risk factors, e.g., having a mood orsubstance abuse disorder (Kessler et al., 1999).Demographics, previous suicide attempts, men-tal health concerns (i.e., depression, substanceabuse, suicidal ideation, self-harm, or impulsiv-ity), family history of suicide, interpersonal con-flicts (i.e., family violence or bullying), and meansfor suicidal behavior (e.g., firearms), are com-monly cited risk factors for suicidal behavior(Nock et al., 2008; Crosby et al., 2011; Gayneset al., 2004; Harriss and Hawton, 2005; Shaffer etal., 2004; Brown et al., 2000).Regarding the use of annotation for predictivemodeling, evidence suggests that when it comesto judgments that involve clinical phenomena, ex-perts and novices behave differently (Li et al.,2012; Womack et al., 2012).
Such distinctions in-tuitively make sense, as the learning of medicaldomain knowledge requires advanced education in108conjunction with substantial practical field experi-ence.In a task such as medical image inspection, thesubtle cues that point an observer to evidence thatallow them to identify a clinical condition, whileaccessible to experts with training and perceptualexpertise to guide their exploration, are likely to bemissed by novices who lack that background andclinical understanding.
Such expertise can then beintegrated into human-centered health-IT systems(Guo et al., 2014), in order to introduce novel waysto retrieve medical images and take advantage ofan understanding of which information is useful.It is reasonable to assume that this knowledge gapalso applies to other knowledge-intensive clinicaldomains such as mental health.
In this study, weexplore this question and study if novice vs. ex-pert annotation makes a difference for identifyingdistress in social media texts, as well as what theimpact of expert vs. novice annotation is for subse-quent computational modeling with the annotateddata.Affect in language is a phenomenon that hasbeen studied in the speech and text analysis do-mains, and in many others (Calvo and D?Mello,2010).
Clearly, emotion is a key element in thehuman experience, but it is notoriously difficultto pin down and scholars in the affective scienceslack a single agreed-upon definition for emotion.Accordingly, different theoretical constructs havebeen proposed to describe affect and affect-relatedbehaviors (Picard, 1997).
In addition, research onaffect in language has shown that such phenom-ena tend to be subjective, lack real ground truth(often resulting in moderate kappa scores), andhave particularly fuzzy semantics in the gray zonewhere neutrality and emotion meet (Alm, 2008).These kinds of problem characteristics bring withthem their own set of demanding challenges froma computational perspective (Alm, 2011).
Yet, thenature of such problems make them incredibly im-portant to study, despite the challenges involved.Sentiment analysis has been widely studied ina number of computational settings, including onvarious social networking sites.
A rather substan-tial body of work already exists on the use ofTwitter to study emotion (Bollen et al., 2011b;Dodds et al., 2011; Wang et al., 2012; Pfitzner etal., 2012; Kim et al., 2012; Bollen et al., 2011a;Pfitzner et al., 2012; Bollen et al., 2011c; Moham-mad, 2012; Golder and Macy, 2011; De Choud-hury et al., 2012a; De Choudhury et al., 2012b;De Choudhury et al., 2013; De Choudhury andCounts, 2013; Hannak et al., 2012; Thelwall etal., 2011; Pak and Paroubek, 2010).
For in-stance, Golder and and Macy study aggregateglobal trends in ?mood,?
and show, among otherthings, that people wake up in a relatively goodmood that decays as the day progresses (Golderand Macy, 2011).
Bollen et al.
(2011c) show thattweets from users who took a standard diagnos-tic instrument for mood are often tied to currentevents, such as elections and holidays.Relatively little of this work has focused on sui-cide or related psychological conditions.
Masudaet al.
(2013) study suicide on mixi (a Japanesesocial networking service).
Cheng et al.
(2012)consider the ethical and political implicationsof online data collection for suicide prevention.Jashinsky et al.
(2013) show correlations betweenfrequency in tweets related to suicide and ac-tual suicide in the 50 United States of Amer-ica.
Sadilek et al.
(2014) study depression onTwitter.
De Choudhury and collaborators studieddepression?in general and post-partum?in Twit-ter (De Choudhury et al., 2012a; De Choudhury etal., 2012b; De Choudhury et al., 2013; De Choud-hury and Counts, 2013) and Facebook (De Choud-hury et al., 2014).
Homan et al.
(2014) investigatedepression in TrevorSpace.
A number of socialtheories of suicide have been proposed (Wray etal., 2011), but most of this work was with respectto offline social systems.3 MethodsOur methods involve four main phases: (1) We fil-tered a corpus, obtained from Sadilek et al.
(2012),of approximately 2.5 million tweets from 6,237unique users in the New York City area that weresent during a 1-month period between May andJune, 2010, into a set of 2,000 tweets that are rela-tively likely to be centered around suicide risk fac-tors.
(2) We annotated each of these 2,000 tweetswith their level of distress, and also analyzed theannotations in detail.
(3) We then trained sup-port vector machines and topic models with theannotated data, except for a held-out subset of 200tweets.
(4) Finally, we assessed the effectivenessof these methods on the held-out data.109SourcetweetsNumber of tweets 2,535,706Unique geo-active users 6,237?Follows?
relationships 102,739?Friends?
relationships 31,874FilteredtweetsNumber of tweets 2,000Unique users 1,467Unique unigrams 1,714,167Unique bigrams 9,246,715Unique trigrams 1,306,1142CategoriesdistributionLIWC sad 1,370Depressive feeling 283Suicide ideation 123Depression symptoms 72Self harm 67Family violence/discord 47Bullying 10Gun ownership 10Drug abuse 6Impulsivity 6Prior suicide attempts 2Suicide around individual 2Psychological disorders 2Table 1: Summary statistics and thematic cate-gory distributions of the collected dataset.
Thedata were collected from NYC.
Geo-active usersare those who geo-tag (i.e., automatically post theGPS location of) their tweets relatively frequently(more than 100 times per month).3.1 Filtering tweetsIn order to facilitate the discovery of distress-related tweets, we first (a) converted all text tolower case; (b) stripped out punctuation and spe-cial characters; and (c) mapped informal terms(such as abbreviations and netspeak) to more stan-dard ones, based on the noslang dictionary.1We then used two different methods to filtertweets that are relatively likely to center on sui-cide risk factors.
We used LIWC to capture 1,370tweets by sampling randomly from among the2,000 tweets with the highest LIWC sad score.LIWC has been widely used to estimate emotionin online social networks, and specifically to moodon Twitter.
This slight amount of randomness infiltering tweets this way was intended to avoid se-lecting obvious false positives, such as the use of?sad?
in nicknames.Next, we adopted a collection of inclusivesearch terms/phrases from Jashinsky et al.
(2013),which was designed specifically for capturingtweets related to suicide risk factors, and appliedthem to our source corpus.
We added to thesemore terms, from (Crosby et al., 2011) (see Ta-ble 2).
These terms yielded 630 tweets.1http://www.noslang.com/dictionarydepressivefeelingtired of living, leave this world,wanna die, hate my job,feeling guilty, deserve to die,desire to end own life,feeling ignored,tired of everything, feeling blue,have bluesdepressionsymptomssleeping pill, have insomnia,sleep forever, sleep disorderdrugabuseclonazepam, drug overdose,imipramineprior suicideattemptstried suicidesuicideideationcommit suicide,committing suicide,feeling suicidal, want to suicide,shoot myself, a gun to head,hang myself, intention to dieselfharmhurt myself, cut myselfpsychologicaldisorderssleep apneafamilyviolencediscordlost my friend,argument with wife,argument with husband,shouted at each otherTable 2: Filtering terms added to thosefrom Jashinsky et al.
(2013).3.2 Novice and Expert Tweet AnnotationWe then divided the resulting set of 2,000 fil-tered tweets (1,370 from the LIWC sad dimensionand 630 from suicide-specific search terms), intotwo randomized sets of 1,000 tweets each.
Bothsets had the same proportion of LIWC-filtered andsuicide-specific-filtered tweets.
A novice anno-tated the first set and a counseling psychologistwith experience in suicide related research anno-tated the second set.
A second novice annotateda subset of 250 tweets of the first set, to revealinterannotator agreement between novices, as onemight expect a novice without training to be lesssystematic.
(The annotators were among the au-thors.)
Each tweet in each set was rated on a four-point scale (H, ND, LD, HD) according to the levelof distress evident (Table 3).Each tweet to be annotated was provided withcontext in the form of the three tweets before andafter the tweet to be annotated that the tweetermade, along with the timestamp of those tweetsand the thematic categories to which the tweet be-longed, based on the filtering process (Figure 1).3.3 ModelingWe then mapped each tweet to a feature spacecomposed of the unigrams, bigrams, and trigramsin the corpus.
For example, a simple tweet ?I am110978: Date: XXXX-3: dat man on maury is overreacting!
!he juss doin dat cuz he ontv [-0:24:39]-2: @XXXX cedes!!!
[-0:21:25]-1: yesssss!
da weatherman was wronqno rainy ass prom days!!
yesssprom is 2day guys!!
classof 2010!
[-0:02:56]>>> @XXXX awwww thanks trae-trae1: rt @XXXX: abt 2 hop in a kabto skool i wouldn?t dare spendover 2 dollars to get somewherei dnt wanna be n da firstplace!
[+0:00:57]2: @XXXX yeaa [+0:03:59]3: @XXXX wassup?
[+0:05:28]Msg_id: XXXX [Distress: ND, LIWC Sad: No]Figure 1: Example input for annotator.
The tweetto be annotated is indicated by >>>.
Annotatorswere given context in the form of the three tweetsimmediately preceding?and the three tweets im-mediately following?the tweet to be annotatedthat the tweeter made, along with the relative timeat which each tweet was made.
Each numerical la-bel denotes one of these context tweets.
(Tweeterinformation has been blanked out.
)Code Distress LevelH happyND no distressLD low distressHD high distressTable 3: Distress-related categories used to anno-tate the tweets.so happy?
was represented as the following featurevector: {I, am, so, happy, I am, am so, so happy,I am so, am so happy}.
Each feature is associatedwith its tf-idf score (Manning et al., 2008).We performed topic modeling on our dataset.
Atopic is a set of lexical items that are likely to occurin the same tweet.
Topic models are capable of as-sociating words with similar meanings and distin-guishing among the different meanings of a singleword.
We used latent Dirichlet allocation (LDA)(Blei et al., 2003) to create these topics.
Beforedoing so, we removed stop words and words thatoccur only once in the dataset.
We then appliedLDA algorithm on the data to discover three top-ics using 100 iterations.We used support vector machines (SVMs)(Joachims, 1998), a machine learning method thatis used to train a classification model that can as-sign class labels to previously unseen tweets, toassess the power of our annotations.
SVMs treateach tweet as a point in an extremely high dimen-sional space (one dimension per uni-, bi-, and tri-gram in the corpus).
SVMs are a form of linearseparator that can also distinguish between non-linearly separable classes of data by warping thefeature space (though in our case we perform nosuch warping, or kernelization).
They have provento be an extremely effective tool in classifying textin numerous settings, including Twitter.4 ResultsFigure 2: Distribution of distress level annota-tions on the tweets annotated by Novices 1 and 2(N=250, identical set).Figure 3: Distribution of distress level annota-tions from Novice 1 and Expert.
Note the thesetwo datasets are disjoint (N = 1000 tweets, respec-tively).Figure 2 shows the distribution of annotation la-bels for the subset of tweets that Novices 1 and 2both annotated, and Figure 3 compares the over-all annotation distributions between Novice 1 andthe Expert.
Interestingly, the novices are relativelyconservative, compared to the expert, in assign-ing distressed labels, whereas the expert exhibitsa higher sensitivity toward low distress than eitherof the novices.
This suggests that it is important inthis domain not to rely too much on novice judg-111ments, as novices are not trained to pick up on sub-tle cues?in contrast to the clinically trained eye.Note that there are very few happy tweets,which confirms that our filtering was effective inremoving tweets of the opposite polarity.Filtering method KappaLIWC sad 0.4Thematic suicide risk factors 0.6Both 0.5Table 4: Cohen kappa interannotator agreementbetween Novice 1 and 2.H ND LD HDH 0 2 0 0ND 1 85 2 1LD 0 22 9 0HD 0 1 0 2Table 5: Confusion matrix between Novices 1 and2 on annotations of the LIWC-sad-based filteredtweets.H ND LD HDH 4 6 0 0ND 0 55 12 1LD 0 12 22 5HD 0 1 3 4Table 6: Confusion matrix between Novices 1 and2 on annotations of tweets filtered by Jashinsky etal.
(2013)?s thematic suicide risk factors inclusionterms.Table 4 shows the Cohen kappa score betweenNovices 1 and 2, when high and low distress vs.no distress and happy, are grouped in a single cate-gory and Tables 5?7 show the confusion matricesbetween Novices 1 and 2.
In all cases the kappascore is moderate.
However, it clearly improveswhen annotation is restricted to just those tweetsfiltered using the suicide-thematic inclusion termsof Jashinsky et al.
(2013).
This again seems topoint to the usefulness of including clinical expertsinto the training process.Due to their sensitive nature, we decided not toprovide examples of high distress tweets.
Here aretwo examples of tweets labeled as low distress bytwo annotators.?
insomnia night#56325897521365!
!sheesh can?t deal w/ this shit!i have class in the morning gotdammit....H ND LD HDH 4 8 0 0ND 1 140 14 2LD 0 34 31 5HD 0 2 3 6Table 7: Confusion matrix between Novices 1 and2 on annotations of all common tweets betweenthe two annotators.?
@XXXX i?m still sad thoo.
i feelneglected!
and i miss XXXXAnd here are two examples of tweets labeled asno distress by two annotators.?
i did mad push-ups tryna get thatcut up look, then look at myselfafter a shower ... #plandidntwork;thats #whyiaintgotomiami?
my son is gonna have blues eyes andnappy hair!
yes yes yesThe above examples are rather clear cut, how-ever in many cases the tweets were more ambigu-ous, even when annotators had the preceding andsucceeding three tweets from the user of the tweetto be annotated to rely on for context.
While con-text and time offset information was useful for an-notators, distress annotation is clearly a challeng-ing task, as the confusion matrices in Tables 5?6reveal.
The lower agreement levels, and particu-larly the fuzzy border between ?no distress?
and?low distress?
are completely in line with priorresearch, discussed above, on affective languagephenomena.Another filtering and annotation challenge in-volves tweets with mixed emotion, such as:?
as much as i hate my job some of thepeople i work with are amazing.Beyond the targeted annotation categories ofdistress level, there were emerging themes ofaggression, privilege and oppression, and dailystruggles, among others.
For instance, jobs werea popular source of distress:?
i friggin hate these bastards myjob grimey ass bastards knew iwanted the day off and tell me somenext shit?
hate my job wit a passion!
hateevery1 there.. they better dosumthin about it, or im out!Personal bias may have impacted annotation de-cisions.
For instance, numerous tweets contained112irony and dark humor, which may result in anno-tators underestimating or overlooking actual dis-tress.
In addition, by pulling data from Twitter,any non-Twitter context behind the tweets is lost.For example, a few individuals retweeted in a sar-castic manner about what individuals should sayto someone who is considering suicide:?
you wish!!!
rt @XXXX: i thinksuicide is funny.
especially oncemy mom does it?
rt @XXXX: what do i say to a personthats asking me for advice becuzthey thinking bout committingsuicide when i see there point?lmaoWithout knowing the circumstances of the originalmessage (beyond the provided context window) itis difficult to classify such tweets.Finally, a number of tweets seemed to showcompassion or empathy for others experiencingstress.
This suggests to us the profound role thatsocial support places in well-being and depression,that one?s friends and associates can also provideclues into one?s emotional state, and that socialmedia can reveal such behavior.?
rt @XXXX: damn now what do i do?
ifeel empty as f$% damit!!
breatheocho,*tears*from liberty city to(cont) http://XXXX?
@XXXX that?s just sad i feel for youHigh Distress Randomfeel like, wanna cry, gethurt, miss 2, ima miss, winlose, tired everything, brokebitches, gun range, onepersongood morning, lastnight, happy birthday,look like, bout 2, can?twait, video , know(cont), chris brown, jusgotcommit suicide, miss you!,miss baby, feel empty,committing suicide, tiredliving, sleep forever, lostphone, left alone, :( missfeel like, let know,make sure, bout go,time get, don?t get, watsgood, .
., don?t want,jus sawhate job, feel sad, tummyhurts, lost friend, feelhelpless, leave alone, don?twanna, worst feeling, leaveworld, don?t letdon?t know, let?s go,looks like, what?s good,go sleep, even tho, hellyea, new single, r u?,don?t wannaTable 8: Topic analysis on bigrams of tweets la-beled as high distress vs. randomly selected tweetsfrom the larger, unlabeled dataset.
The high dis-tress tweets clearly convey strong negative affect.Table 8 shows the results of a 3-category topicmodel on bigrams.
The first column is taken justfrom tweets labeled high distress by any one ofthe three annotators (72 tweets total).
The sec-ond column comes from a randomly-chosen sam-ple of 2000 tweets from the 2.3 million tweet cor-pus.
These results show that the lexical contentsof the annotated tweets are recognizeably differ-ent from the random sample.
By our judgement,the topical groupings in the rows of the high dis-tress column are all clearly marked by strong neg-ative affect, and additionally they could arguablybe labeled?from top to bottom?as: ?failure anddefeat,?
?loss,?
and ?loneliness.?
The rows of thesecond column are less clear cut, and appear toreflect a much broader scope of topics.
One inter-esting aspect of the second, random column is thatrecording artist Chris Brown had released a newalbum during the collection period, which seemsto explain why his name appeared.Training Testing Precision Recall F-MeasureN1 N1 0.53 0.63 0.58N1 E 0.58 0.27 0.37E E 0.59 0.71 0.64E N1 0.34 0.85 0.48N1 + E N1 + E 0.33 0.41 0.37Table 9: Performance of SVM-based classificationwhen the training and testing sets are alternatelyNovice 1 (N1) or the Expert (E).
Because we fo-cus on distress classification, we report precision,recall and F-measure for the distress class, whichcombines LD and HD into a single class with re-spect to binary (distress vs. non-distress) classifi-cation.
In each case, a held-out set of 100 ran-domly selected tweets compose the test set andthe remaining 900 tweets from that annotator com-pose the training set.
The last row shows when thetwo training sets (respectively, test sets) are com-bined into a single set of 1800 (respectively, 200)tweets.For classification, because we are most inter-ested in being able to separate distressed fromnon-distressed tweets, we combine low distressand high distress into a single distress class, andno distress and happy into a non-distress class.
Ta-ble 9 shows the performance of the SVM-basedclassifier when trained and tested on the Expertand Novice 1 training sets.
Four themes emerge:(1) the SVM classifier is much more accurate (interms of F-measure) when the testing and trainingdata come from the same annotator (test and train-ing data are disjoint), and the best performancecomes from the expert-annotated data.
(2) When113testing and training data are from different anno-tators, the F-measure performance of the SVMis lower when the training set is from the novicerather than the expert.
(3) When testing and train-ing data are from different annotators, the SVMhas lower recall and higher precision when thetraining set is from the novice rather than the ex-pert.
This is in part because the Expert was moresensitive to distress than Novice 1.
It is prematureto draw conclusions from this observation, but per-haps this shows that training with expert-labeledannotations is preferable to using novice-labeleddata, espectially when our goal is to discover dis-tressful tweets for the purpose of identifying at-risk individuals and err on the side of caution (highrecall).
(4) Integrating more but mixed data doesnot improve performance.5 DiscussionAs previously mentioned, many of the risk fac-tors for suicidal behavior may be linked to otherexpressions of distress, such as aggression andinterpersonal violence (Mann et al., 1999).
Thegoal of this study is to determine the feasibilityof classifying distress to enable further study ofexpressed suicidal behaviors.
Consistent with thestress diathesis model for suicidal behavior, ag-gression was an emerging theme that arose fromthe data.
Here are some examples:?
@XXXX i don?t feel sad 4 him.
hegets pissed n says wat he wants thensends out fony apologies?
@XXXX cuz he?s n a relationshipwith that horseface bitch &amp; helied 2 me &amp; i feel so used &amp;worthless nowSome individuals tweeted about feeling empty,hopeless, angry, frustrated, and alone.
Behaviorsindicating bullying and schadenfreude were alsoobserved.
While these are all risk factors for inter-nalizing aggression (i.e., suicidal behavior), theyare also associated with externalized aggression.In addition to overt expressions of anger and vi-olence, many of the humorous, ironic tweets alsohad an aggressive undertone.5.1 LimitationsAs ground truth, we rely on tweets hand-annotatedby expert and novice for classification.
However,the mental state of another individual, observedfrom a few lines of text often written in an in-formal register is necessarily hard to discern and,even under less noisy conditions, extremely sub-jective; even the observers?
personal understand-ings of such concepts as ?distress?
may differdrastically.
This makes annotation quite a chal-lenge, and does not reveal in an objective fashion atweeter?s true mental state.
As we have mentionedearlier, self-reporting has its own limitations, yetit is often regarded as the gold standard for groundtruth about emotional state.
Part of the problem inassessing the effectiveness of self-reporting is therelative rareness by which suicide occurs, and bythe inherent subjectivity of the act, which makesany data on suicide fuzzy.
We hope to explore infuture work the relationship between clinical ob-servation in both on- and off-line settings and self-reporting, including the integration of natural lan-guage data of patients from clinical settings.
Wealso hope to explore distress annotation from dif-ferent perspectives and levels of context.Higher levels of suicidal ideation have an in-verse relationship with all types of help-seekingand a positive correlation with the decision to notseek support (Deane et al., 2001).
Thus, we wouldexpect suicidal individuals to generally be less ac-tive on social media than those who are not.
Nev-ertheless, a number of studies have shown a posi-tive correlation between online social network useand negative mood.
Perhaps this means in part thatindividuals who are depressed are slower to disen-gage on- rather than off-line.6 ConclusionWe studied the performance of different ap-proaches to training systems to detect evidenceof suicide risk behavior in microblog data.
Weshowed that both the methods used to automat-ically collect training sets, as well as the ex-pertise level of the annotator affect greatly theperformance of automatic systems for detectingsuicide risk factors.
In general, our study andits results?from filtering via data annotation toclassification?confirmed the critical importanceof bringing clinical expertise into the computa-tional modeling loop.AcknowledgmentsThis work was supported by a grant of the KodakEndowed Chair Fund from the Golisano Collegeof Computing and Information Sciences at RITand NSF award SES-1111016.114ReferencesCecilia Ovesdotter Alm.
2008.
Affect in Text andSpeech.
Ph.D. thesis, University of Illinois at Ur-bana Champaign.Cecilia Ovesdotter Alm.
2011.
Subjective naturallanguage problems: Motivations, applications, char-acterizations, and implications.
In Proceedings of49th Annual Meeting of the Assoc.
for Computa-tional Linguistics: Human Language Technologies,Portland, OR, pages 107?112.David M. Blei, Andrew Y. Ng, and Michael I. Jordan.2003.
Latent Dirichlet allocation.
Journal Mach-ince Learning Research, 3:993?1022, March.Johan Bollen, Bruno Gonc?alves, Guangchen Ruan, andHuina Mao.
2011a.
Happiness is assortative in on-line social networks.
Artificial Life, 17(3):237?251.Johan Bollen, Huina Mao, and Xiaojun Zeng.
2011b.Twitter mood predicts the stock market.
Journal ofComputational Science, 2(1):1?8.Johan Bollen, Alberto Pepe, and Huina Mao.
2011c.Modeling public mood and emotion: Twitter senti-ment and socio-economic phenomena.
In Proceed-ings of the Fifth International AAAI Conference onWeblogs and Social Media, pages 450?453.Gregory K Brown, Aaron T Beck, Robert A Steer, andJessica R Grisham.
2000.
Risk factors for sui-cide in psychiatric outpatients: A 20-year prospec-tive study.
Journal of Consulting and Clinical Psy-chology, 68(3):371.Ronny Bruffaerts, Koen Demyttenaere, Irving Hwang,Wai-Tat Chiu, Nancy Sampson, Ronald C Kessler,Jordi Alonso, Guilherme Borges, Giovanni de Giro-lamo, Ron de Graaf, et al.
2011.
Treatment of suici-dal people around the world.
The British Journal ofPsychiatry, 199(1):64?70.Rafael A. Calvo and Sidney D?Mello.
2010.
Affectdetection: An interdisciplinary review of models,methods, and their applications.
IEEE Transactionson Affective Computing, 1(1):18?37.Qijin Cheng, Shu-Sen Chang, and Paul SF Yip.2012.
Opportunities and challenges of online datacollection for suicide prevention.
The Lancet,379(9830):e53?e54.Alex E Crosby, LaVonne Ortega, and Cindi Melanson.2011.
Self-directed violence surveillance: Uniformdefinitions and recommended data elements.
Cen-ters for Disease Control and Prevention, NationalCenter for Injury Prevention and Control, Divisionof Violence Prevention.Munmun De Choudhury and Scott Counts.
2013.
Un-derstanding affect in the workplace via social media.In 16th ACM Conference on Computer SupportedCooperative Work and Social Media (CSCW 2013),pages 303?316.
ACM.Munmun De Choudhury, Scott Counts, and MichaelGamon.
2012a.
Not all moods are created equal!Exploring human emotional states in social media.In 6th International AAAI Conference on Weblogsand Social Media.Munmun De Choudhury, Michael Gamon, and ScottCounts.
2012b.
Happy, nervous or surprised?
Clas-sification of human affective states in social media.In 6th International AAAI Conference on Weblogsand Social Media.Munmun De Choudhury, Scott Counts, and EricHorvitz.
2013.
Major life changes and behavioralmarkers in social media: case of childbirth.
In Pro-ceedings of the 2013 conference on Computer sup-ported cooperative work, pages 1431?1442.
ACM.Munmun De Choudhury, Scott Counts, Eric J Horvitz,and Aaron Hoff.
2014.
Characterizing and pre-dicting postpartum depression from shared facebookdata.
In Proceedings of the 17th ACM conferenceon Computer Supported Cooperative Work & SocialComputing, pages 626?638.
ACM.Frank P Deane, Coralie J Wilson, and Joseph Ciarrochi.2001.
Suicidal ideation and help-negation: Not justhopelessness or prior help.
Journal of Clinical Psy-chology, 57:901?914.Peter Sheridan Dodds, Kameron Decker Harris, Is-abel M Kloumann, Catherine A Bliss, and Christo-pher M Danforth.
2011.
Temporal patterns of hap-piness and information in a global social network:Hedonometrics and twitter.
PloS one, 6(12):e26752.Bradley N Gaynes, Suzanne L West, Carol A Ford,Paul Frame, Jonathan Klein, and Kathleen N Lohr.2004.
Screening for suicide risk in adults: A sum-mary of the evidence for the US Preventive Ser-vices Task Force.
Annals of Internal Medicine,140(10):822?835.S.A.
Golder and M.W.
Macy.
2011.
Diurnal and sea-sonal mood vary with work, sleep, and daylengthacross diverse cultures.
Science, 333(6051):1878?1881.Xuan Guo, Rui Li, Cecilia Ovesdotter Alm, Qi Yu, JeffPelz, Pengcheng Shi, and Anne Haake.
2014.
Infus-ing perceptual expertise and domain knowledge intoa human-centered image retrieval system: A proto-type application.
In Proceedings of the Symposiumon Eye Tracking Research and Applications, pages275?278.
ACM.Aniko Hannak, Eric Anderson, Lisa Feldman Barrett,Sune Lehmann, Alan Mislove, and Mirek Riede-wald.
2012.
Tweetin in the rain: Exploring societal-scale effects of weather on mood.
In Proceedings ofthe 6th International AAAI Conference on Weblogsand Social Media (ICWSM12).Louise Harriss and Keith Hawton.
2005.
Suicidal in-tent in deliberate self-harm and the risk of suicide:The predictive power of the suicide intent scale.Journal of Affective Disorders, 86(2):225?233.115Melonie Heron and Betzaida Tejada-Vera.
2009.Deaths: Leading causes for 2005.
National VitalStatistics Reports: From the Centers for DiseaseControl and Prevention, National Center for HealthStatistics, National Vital Statistics System, 58(8):1?97.Christopher M Homan, Naiji Lu, Xin Tu, Megan C Ly-tle, and Vincent Silenzio.
2014.
Social structureand depression in TrevorSpace.
In Proceedings ofthe 17th ACM Conference on Computer SupportedCooperative Work & Social Computing, pages 615?625.
ACM.Lisa M Horowitz and Elizabeth D Ballard.
2009.
Sui-cide screening in schools, primary care and emer-gency departments.
Current Opinion in Pediatrics,21(5):620?627.Jared Jashinsky, Scott H Burton, Carl L Hanson, JoshWest, Christophe Giraud-Carrier, Michael D Barnes,and Trenton Argyle.
2013.
Tracking suicide riskfactors through Twitter in the US.
Crisis, pages 1?9.T.
Joachims.
1998.
Text categorization with supportvector machines: Learning with many relevant fea-tures.
In European Conference on Machine Learn-ing (ECML), pages 137?142, Berlin.
Springer.Ronald C Kessler, Guilherme Borges, and Ellen E Wal-ters.
1999.
Prevalence of and risk factors for life-time suicide attempts in the national comorbiditysurvey.
Archives of General Psychiatry, 56(7):617?626.Suin Kim, J Bak, and Alice Oh.
2012.
Do you feelwhat I feel?
Social aspects of emotions in Twitterconversations.
In Proceedings of the AAAI Interna-tional Conference on Weblogs and Social Media.Michael Lehrman, Cecilia Ovesdotter Alm, and RubenProano.
2012.
Detecting distressed vs. non-distressed affect state in short forum texts.
In Pro-ceedings of the Workshop on Language in SocialMedia (LSM 2012) at the Conference of the NorthAmerican Chapter of the Association for Compu-tational Linguistics-Human Language Technologies,Montreal, Canada, pages 9?18.Rui Li, Jeff Pelz, Pengcheng Shi, and Anne Haake.2012.
Learning image-derived eye movementpatterns to characterize perceptual expertise.
InCogSci, pages 1900?1905.J John Mann, Christine Waternaux, Gretchen L Haas,and Kevin M Malone.
1999.
Toward a clinicalmodel of suicidal behavior in psychiatric patients.American Journal of Psychiatry, 156(2):181?189.Christopher D. Manning, Prabhakar Raghavan, andHinrich Sch?utze.
2008.
Introduction to InformationRetrieval.
Cambridge University Press, New York,NY, USA.Naoki Masuda, Issei Kurahashi, and Hiroko Onari.2013.
Suicide ideation of individuals in online so-cial networks.
PloS one, 8(4):e62262.Pawel Matykiewicz, Wlodzislav Duch, and John P.Pestian.
2009.
Clustering semantic spaces of sui-cide notes and newsgroup articles.
In Proceedings ofthe Workshop on BioNLP, Boulder, Colorado, pages179?184.Saif M Mohammad.
2012.
# Emotional tweets.
InProceedings of the First Joint Conference on Lexicaland Computational Semantics-Volume 1: Proceed-ings of the main conference and the shared task, andVolume 2: Proceedings of the Sixth InternationalWorkshop on Semantic Evaluation, pages 246?255.Association for Computational Linguistics.Matthew K Nock, Guilherme Borges, Evelyn J Bromet,Christine B Cha, Ronald C Kessler, and Sing Lee.2008.
Suicide and suicidal behavior.
EpidemiologicReviews, 30(1):133?154.Matthew K Nock, Jennifer M Park, Christine T Finn,Tara L Deliberto, Halina J Dour, and Mahzarin RBanaji.
2010.
Measuring the suicidal mind implicitcognition predicts suicidal behavior.
PsychologicalScience, 21(4):511?517.Alexander Pak and Patrick Paroubek.
2010.
Twitteras a corpus for sentiment analysis and opinion min-ing.
In Proceedings of Conference on Language Re-sources and Evaluation.James W Pennebaker, Martha E Francis, and Roger JBooth.
2001.
Linguistic inquiry and word count:Liwc 2001.
Mahway: Lawrence Erlbaum Asso-ciates, 71:2001.John P. Pestian, Pawel Matykiewicz, and JacquelineGrupp-Phelan.
2008.
Using natural language pro-cessing to classify suicide notes.
In BioNLP 2008:Current Trends in Biomedical Natural LanguageProcessing, Columbus, Ohio, pages 96?97.Ren?e Pfitzner, Antonios Garas, and Frank Schweitzer.2012.
Emotional divergence influences informationspreading in twitter.
Proceedings of the 6th Inter-national AAAI Conference on Weblogs and SocialMedia (ICWSM12), pages 2?5.Rosalind W. Picard.
1997.
Affective Computing.
MITPress, Cambridge, MA, USA.Megan L Ryan, Ian M Shochet, and Helen M Stallman.2010.
Universal online interventions might engagepsychologically distressed university students whoare unlikely to seek formal help.
Advances in Men-tal Health, 9(1):73?83.Adam Sadilek, Henry A Kautz, and Vincent Silenzio.2012.
Predicting disease transmission from geo-tagged micro-blog data.
In Association for the Ad-vancement of Articial Intelligence.116Adam Sadilek, Christopher Homan, Walter S. Lasecki,Vincent Silenzio, and Henry Kautz.
2014.
Mod-eling fine-grained dynamics of mood at scale.
InWSDM 2014 Workshop on Diffusion Networks andCascade Analytics.David Shaffer, Michelle Scott, Holly Wilcox, CareyMaslow, Roger Hicks, Christopher P Lucas, RobinGarfinkel, and Steven Greenwald.
2004.
TheColumbia SuicideScreen: Validity and reliability ofa screen for youth suicide and depression.
Journal ofthe American Academy of Child & Adolescent Psy-chiatry, 43(1):71?79.Mike Thelwall, Kevan Buckley, and Georgios Pal-toglou.
2011.
Sentiment in Twitter events.
Journalof the American Society for Information Science andTechnology, 62(2):406?418.Wenbo Wang, Lu Chen, Krishnaprasad Thirunarayan,and Amit P Sheth.
2012.
Harnessing Twit-ter ?Big Data?
for automatic emotion identifica-tion.
In Privacy, Security, Risk and Trust (PASSAT),2012 International Conference on and 2012 Inter-national Confernece on Social Computing (Social-Com), pages 587?592.
IEEE.Kathryn Womack, Wilson McCoy, Cecilia Ovesdot-ter Alm, Cara Calvelli, Jeff B. Pelz, PengchengShi, and Anne Haake.
2012.
Disfluencies asextra-propositional indicators of cognitive process-ing.
In Proceedings of the Workshop on Extra-Propositional Aspects of Meaning in ComputationalLinguistics, pages 1?9.
Association for Computa-tional Linguistics.Matt Wray, Cynthia Colen, and Bernice Pescosolido.2011.
The sociology of suicide.
Annual Review ofSociology, 37:505?528.117
