Generation i the LOLITA system" An engineering approach.Mark H. Smith, Roberto Garigliano, Richard G. MorganLaboratory for Natural Language Engineering,University of DurhamE-marl: m.h.smith@durham.ac.uk1 Introduct ionThis short paper Will outline NLG work in the LOLITA(Large-scale Object-based Linguistic Interactor Transla-tor and Analyser) system.
Section 2 will provide back-ground into the natural anguage ngineering principlesemployed in the development of the system together witha brief overview of LOLITA itself.
Section 3 will thenprovide an overview of the generation process and outlinetwo specific stages in this process: abstract ransforma-tions and realisation.2 Background2.1 Natural Language EngineeringNL research at Durham University is concerned with nat-ural language ngineering (NLE) rather than the moretraditional computational linguistics (CL).
A lot of CLorientated NLP (including NLG) has concentrated onei-ther trying to formulate universal theories that cover allaspects of languagh or developing very restricted theorieswhich model smal!
areas.
The utilisation or expansion ofthese ideas to realistic systems which are not highly re-stricted by their t~k  or domain has proved a great prob-lem.
Problems associated with other engineering disci-plines which have to be considered in NL are:Scale: The size of systems (e.g., grammar coverage, vo-cabulary size, word senses) must be sufficient for realisticlarge-scale applications.Integration: Components of a system must not makeunreasonable assumptions about other parts.
This is of-ten the case when specific NLP problems are tackled inisolation.
Components should be designed and imple-mented so that they assist other components.Flexibility: The ability to modify systems for differenttasks in different domains.Feasibility: For example, hardware requirements mustaot be too great and execldtion speeds must be accept-able.
This process I incorporates making the system andits components efficient.Maintainabil ity:: How useful the system is over a longperiod of time.
The maintenance of a large system hasproved to be an important aspect of the software life-cycle \[6\].Usability: The system must be able to support he ap-plications end users want and be user-friendly.Robustness: This is a critical aspect of large-scale sys-tems.
To quote \[1\] "while it \[robustness\] may not be aserious problem for any individual application, it has tobe faced up to in general".
This aspect concerns not onlythe linguistic scope of the system but how it deals withinput which falls outside of this scope.The fact that there are a large number of systems andprojects with very restrictive aims and few that can claimto successfully address these issues uggest that they haveassociated intrinsic research problems of their own.The NLE method has foundations in the belief thatit is not necessary to wait for complete linguistic theo-ries covering all the problems associated with NL (whichdo not exist at present) before large, realistic and use-ful NL systems can be built.
Instead a full array of AItechniques i  employed ranging from using well-developedlinguistic and logic global theories (where they exist) tomore localised theories, corpora, knowledge based heuris-tics, adaptive techniques and at the lowest level ad-hocrules.
Incorporating this wide range of methods meansthat the development of the system does not get stuckdue to the difficulty in following a particular logical or lin-guistic theory while the benefits of such well establishedtheories can still be enjoyed.
The result is a practical,working solution.2.2 The LOLITA systemThe LOLITA system has been developed over the lasteight years at Durham University.
It belongs to only asmall group of systems which can claim to have addressedmost of the properties required of large engineered sys-tems as described above.
The rarity of systems uchas LOLITA is exemplified by the fact that NL systemterminology defined in \[1\] has to be extended to defineLOLITA's status; it is more than a generic system as itis not restricted to a single task type, but it is not, asit stands, a general purpose machine which can be usedfor any task in any domain.
We extend the terminologyby defining LOLITA as a general purpose base.
Althoughdemonstration prototypes have been built using LOLITA2417th International Generation Workshop ?
Kennebunkport, Maine ?
June 21-24, 1994for various tasks and domains (e.g., template building,dialogue analysis and generation, interactive query, ma-chine translation, chinese tutoring \[2\]), no polished finalapplication has yet been developed.
This is because ourresearch resources have been concentrated on the 'base'of the system and thus the task-dependent developmenthas not resulted in such systems.LOLITA is built around an original kind of conceptualgraph (a logically precise form of semantic network, seefor example \[12\]) which is accessed, modified and manip-ulated by the other system components (including thegenerator).
This representation, which holds world infor-mation and data as well as some of its linguistic data, cur-rently comprises over 30,000 nodes (capable of more than100,000 inflected word forms).
It is presently being inte-grated with Princeton's WordNet \[11\] which will increaseits size to more than 70,000 nodes.
LOLITA can parsetext, semantically and pragmatically analyse its meaningand add relevant information to the semantic network.
Ithas been built to cope with full and serious text \[1\] (e.g.newspaper articles), as well as text containing errors.LOLITA is implemented in the functional languageHaskell.
It comprises a total of approximately 32000 linesof Haskell code (corresponding to about 300,000 lines of,e.g., 'C').3 Generat ionA lot of work in the area of NLG has suffered from theproblem of poor integration.
Some generators have beenbuilt for specific tasks in specific domains and cannot eas-ily be transported to others (that is they have poor flexi-bility).
Other generators have been used as an interface toa variety of applications (e.g, Penman \[3\] \[8\], Spokesman\[10\]) but have been designed and built in isolation as sep-arate components.
This approach as led to researchersmaking some unlikely assumptions a to the input to theirgenerators.
For example, some generators assume the ex-istence of a set of clause-size predicates from which thegenerator must choose, organise and realise \[3\].The LOLITA generator has been developed as a partof a complete NL system.
It has been built in tandemwith the semantic network representation from which itgenerates and each component has influenced the devel-opment of the other (e.g.
the recent improvement in thesemantic representation f time and location was imple-mented with the requirements of the generator modulein mind).
This highly integrated approach prevents theproblem of lack of expressibility found in other systems\[10\].
Workers have found that the input representationthey use or assume is not isomorphic with the linguisticrealisation resources they employ.
This 'generation gap'problem does not arise in LOLITA as the semantic net-work representation is always expressible in surface NL.Although pieces of semantic network are always di-rectly realisable, the generation allows flexibility and highusability by performing transformations on the represen-tation to allow generation to be tailored for differenttasks.
Parameters dependent on the particular applica-tion, the context, the required style and analysis of thedialogue situation \[5\] are used to guide the control and ef-fect of these transformations on the final text.
Of course,control of variation is a difficult problem and research intothis area is still very much on-going.The transformations can be roughly categorised intothe common planning and realisation divisions but again,the high integration of the generator and semantic rep-resentation avoids some problems encountered by oth-ers.
For example, the organisation of clauses accordingto some discourse structure relations \[7\] (particularly theideational relations) is already explicit in the semanticrepresentation a d does not have to be achieved by thegenerator.
Of course, the problem of how and when tomake these relations explicit in the final text is a genera-tion task.The generator is largely description directed (or pro-cedural) \[9\]: the content of the semantic network to beexpressed plays a large part in the control of the genera-tor.
This method is usually more efficient han grammardirected control (e.g., functioned unification is inherentlynon-deterministic).
Thefeasibilityofthe g nerator isveryacceptable: it does not require extensive memory and op-erates in real time.Because the semantic network is large and contains avast amount of linguistic knowledge (e.g.
after the in-corporation of WordNet) the generator is very large scalewith respect to lexical information.
The grammatical cov-erage of the generator, however, is not particularly good.This problem is closely linked with that of maintainabil-ity.
While so far the coverage of grammar has been in-creased relatively easily, it is expected that because of thelack of a separate grammar, this may be a future prob-lem.
This lack of coverage caused by poor maintainabilityis not as paramount to a similar problem in, for example,parsing: a portion of semantic network can always be re-alised and so robustness i not affected.
The separation ofthe grammar is to be investigated in the near future andit is believed that this will improve the maintainabilityand grammatical coverage of the generator.A full description of the LOLITA generator cannot bepresented here but, by way of example, two transforma-tions which operate on the semantic network during thegeneration process are now outlined.2427th International Generation Workshop ?
Kennebunkport, Maine ?
June 21-24, 1994KEY: ~:~ o:Ot~a:t ~Acliol * D im~ .
.
.
.
.
.
.
.
.
?
J~ l~Figure 1: Example of a verb/instrument specialisationtransform3.1 Abst rac t  T rans format ionsII ~ ~ " n  /~ ~ I ( -===~Figure 2: Simplified portion of semantic network for therealisation exampleAbstract transformations are low-level transformationswhich act on the :semantic network immediately beforerealisation.
Associated with each abstract transformationare theoretical issUes on why particular normal forms arechosen, rules which allow us to move away from thesenormal forms and' effects the transform has on the finalutterance (apart from the obvious one that variations aremore natural).Abstract ransformations can act on and produce varia-tions for events with, for example, antonym verbs, copulaverbs, complemented verbs, verbs which have de-lexicalstructures, verbs which can be either specialised or gen-eralised and events with multiple subjects.
In each casethe procedure is tO disconnect arcs from particular nodesand reconnect hem to different ones (which might al-ready exist or have to be constructed in the network).Figure 1 is an example network portion showing how averb specialisation: transform can be applied.
The verbin the original sentence 'Jack wounded Jill with a gun'may be specialised: into 'shot' because firearms (of whichguns are specialisa~ions) usually wound by shooting.
Fur-thermore as 'guns' are considered to be the most commonspecialisation of firearms, the instrument clause can (as-suming no special Context or high precision flag is set) bedropped leaving 'Jack shot Jill'.
This abstract ransfor-mation relies on a certain amount of plausible inference:if a high precision flag has been set (according to the re-quired style of output) then the output may be modified,e.g., 'It is likely that Jack shot Jill'.As in the LOLITA system, Jacob's KING generator\[4\] uses a knowledge intensive semantic network to movefrom normal forms of representation to alternative forms.However Jacob's method requires special entries in thesemantic network (e.g., a special entry representing 'huggiving' is required to produce the delexical structure 'togive a hug').3 .2  Rea l i sa t ionRealisation is the final step in the generation hierarchyand involves the traversal of the semantic network to pro-duce sentences.
Higher levels in the generation module(planning and dialogue analysis) pass down instructionswhich indicate which events and relations hould be in-cluded in the utterance (i.e the content).
The textualorganisation of the utterance has to be decided by .the re-alisation module using the constraints passed down fi'omabove.
The general operation of the realiser module is tofollow the arcs starting from the input node to find fur-ther nodes and their associated information.
Accordingto the type of these nodes (e.g., if this node is itself anevent node with many links) this process may be contin-ued recursively.The realiser combines both the deep and surface re-alisation of the network.
Choices between, for example,passive and active, or dative and non-dative, sentencesare passed to the realiser as parameters.
In a sense the2437th International Generation Workshop ?
Kennebunkport, Maine ?
June 21-24, 1994grammar of the output is hardwired into the code, butvariation and flexibilty is allowed through the use of theseparameters.
This setup has proved sufficient for all theapplications for which prototypes have been built.Figure 2 shows a (much simplified) portion of the se-mantic network containing an example event El.
Therealiser operates by following arcs (e.g., subject, action,object etc) from this event o other nodes in the networkand recursively generating expressions for these nodes.
Ifthe default parameters are being used the events will begenerated in the active voice and the default rhythm isto allow one relative clause for each object.
The outputproduced in this example is "If Roberto knew that thewoman whom he loves owned the big fast motorbike thatI gave him then he would like it."
An umsimplified por-tion of the semantic network will of course be more richlypopulated.
There may, for example, be many more arcsfrom the node representing Roberto which link to moreinformation about him.
If planning instructions indicatethat this information should be expressed it is likely thatthe realiser will have to split the utterance into separatesentences.
Events which are encountered by the realiserwhich cannot be immediately expressed (because the re-sulting sentence will be too long) are placed on a stack sothat they cg.n be expressed as separate sentences.
Heuris-tics are used to order this stack of events o that coher-ent focus and decipherable anaphoric references are main-tained (the development of these heuristics is ongoing).Stylistic variations can be produced by alteringthe realiser parameter settings and passing differentnodes to the realiser so the text is realised froma different angle.
Example parameter switches arePassive/Active, Dative/Non-Dative, Colour, Rhythm,Length, De-lexical transformations, Copula transforma-tions, Complement transformations, Synonyms transfor-mations, Verb Antonym transformations, Verb Speciali-sation, Verb Generalisation.4 Conc lus ionThis paper has given a brief outline of the LOLITA sys-tem and some aspects of its generation component.
Be-cause of the commercial value of the LOLITA project,the system is not publicly available.
However, we are ex-tremely keen to give demonstrations of the system: forany information on the LOLITA project, please contactthe authors.Referencesport 291, Computer Laboratory, University of Cam-bridge, 1993.\[2\] R. Garigliano, R. Morgan, et al The LOLITAProject: The First Seven Years.
Under negotiationwith Afterhurst Ltd., forthcoming, 1994.\[3\] E. ItI.
Hovy.
Unresolved issues in paragraph planning.In R. Dale, C. Mellish, and M. Zock, editors, CurrentResearch in Natural Language Generation, pages 17-45.
Academic Press, New York, 1990.\[4\] P. S. Jacobs.
Knowledge-intensive natural anguagegeneration.
Artificial Intelligence, 33(3):325-378,November 1987.\[5\] C. Jones and R. Garigliano.
Dialogue analysis andgeneration: A theory for modelling natural englishdialogue.
In EUROSPEECH '93 volume 2, pages951-954, September 1993.\[6\] B. Lientz and E. Swanson.
Software MaintenanceManagement.
Addison-Wesley, 1980.\[7\] E. Mater and E. H. Hovy.
Organising discoursestructure relations using metafunctions.
In H. Ho-racek and M. Zock, editors, New concepts in Natu-ral Language Generation: Planning, Realization, andSystems, pages 69-86.
Pinter Publishers, New York,1993.\[8\] W. C. Mann.
An overview of the Penman text gen-eration system.
In Proceedings of the Third Na-tional Conference on Artificial Intelligence (AAAI-83), pages 261-265, Washington, DC, August 22-26,1983.\[9\] D. D. McDonald, M. M. Meteer, and J. D. Puste-jovsky.
Factors contributing to efficiency in naturallanguage generation.
In G. Kempen, editor, Natu-ral Language Generation: New Results in Artificialbztelligence, Psychology and Linguistics, NATO ASISeries - 135, pages 159-182.
Martinus Nijhoff Pub-lishers, Boston, Dordrecht, 1987.\[10\] M. Meteer.
Expressibility and the Problem of Effi-cient Text Planning.
Francis Pinter Publishers, Lon-don, 1993.\[11\] G. Miller.
Wordnet: An on-line lexical database.btternational Journal of Lexicography, 3(4), 1990.\[12\] J. Sowa.
Conceptual Structures (Information Pro-cessing in Mind aT~d Machine).
Addison-Wesley,1984.\[1\] J. Galliers and K. Sparck-Jones.
Evaluating nat-ural langauge processing systems.
Technical Re-244
