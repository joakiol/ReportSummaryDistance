Proceedings of the Fifth SIGHAN Workshop on Chinese Language Processing, pages 56?63,Sydney, July 2006. c?2006 Association for Computational LinguisticsCluster-based Language Model for Sentence Retrieval in ChineseQuestion AnsweringYouzheng Wu                               Jun Zhao                               Bo XuNational Laboratory of Pattern RecognitionInstitute of Automation Chinese Academy of SciencesNo.95 Zhongguancun East Road, 100080, Beijing, China(yzwu, jzhao,boxu)@nlpr.ia.ac.cnAbstractSentence retrieval plays a very importantrole in question answering system.
In thispaper, we present a novel cluster-basedlanguage model for sentence retrieval inChinese question answering which is mo-tivated in part by sentence clustering andlanguage model.
Sentence clustering isused to group sentences into clusters.Language model is used to properly rep-resent sentences, which is combined withsentences model, cluster/topic model andcollection model.
For sentence clustering,we propose two approaches that are One-Sentence-Multi-Topics and One-Sentence-One-Topic respectively.
Fromthe experimental results on 807 Chinesetesting questions, we can conclude thatthe proposed cluster-based languagemodel outperforms over the standard lan-guage model for sentence retrieval inChinese question answering.1 IntroductionTo facilitate the answer extraction of questionanswering, the task of retrieval module is to findthe most relevant passages or sentences to thequestion.
So, the retrieval module plays a veryimportant role in question answering system,which influences both the performance and thespeed of question answering.
In this paper, wemainly focus on the research of improving theperformance of sentence retrieval in Chinesequestion answering.Many retrieval approaches have been pro-posed for sentence retrieval in English questionanswering.
For example, Ittycheriach [Ittycheriah,et al 2002] and H. Yang [Hui Yang, et al 2002]proposed vector space model.
Andres [Andres, etal.
2004] and Vanessa [Vanessa, et al 2004] pro-posed language model and translation model re-spectively.
Compared to vector space model,language model is theoretically attractive and apotentially very effective probabilistic frame-work for researching information retrieval prob-lems [Jian-Yun Nie.
2005].However, language model for sentence re-trieval is not mature yet, which has a lot of diffi-cult problems that cannot be solved at present.For example, how to incorporate the structuralinformation, how to resolve data sparsenessproblem.
In this paper, we mainly focus on theresearch of the smoothing approach of languagemodel because sparseness problem is more seri-ous for sentence retrieval than for document re-trieval.At present, the most popular smoothing ap-proaches for language model are Jelinek-Mercermethod, Bayesian smoothing using Dirichlet pri-ors, absolute discounting and so on [C. Zhai, et al2001].
The main disadvantages of all thesesmoothing approaches are that each documentmodel (which is estimated from each document)is interpolated with the same collection model(which is estimated from the whole collection)through a unified parameter.
Therefore, it doesnot make any one particular document moreprobable than any other, on the condition thatneither the documents originally contains thequery term.
In other word, if a document is rele-vant, but does not contain the query term, it isstill no more probable, even though it may betopically related.As we know, most smoothing approaches ofsentence retrieval in question answering arelearned from document retrieval without manyadaptations.
In fact, question answering has some56characteristics that are different from traditionaldocument retrieval, which could be used to im-prove the performance of sentence retrieval.These characteristics lie in:1.
The input of question answering is naturallanguage question which is more unambiguousthan query in traditional document retrieval.For traditional document retrieval, it?s difficultto identify which kind of information the userswant to know.
For example, if the user submitthe query {?
?/invent, ?
?/telephone}, searchengine does not know what information isneeded, who invented telephone, when telephonewas invented, or other information.
On the otherhand, for question answering system, if the usersubmit the question {??????
?/who in-vented the telephone?
}, it?s easy to know that theuser want to know the person who invented thetelephone, but not other information.2.
Candidate answers extracted according tothe semantic category of the question?s answercould be used for sentence clustering of questionanswering.Although the first retrieved sentences are re-lated to the question, they usually deal with oneor more topics.
That is, relevant sentences for aquestion may be distributed over several topics.Therefore, treating the question?s words in re-trieved sentences with different topics equally isunreasonable.
One of the solutions is to organizethe related sentences into several clusters, wherea sentence can belong to about one or more clus-ters, each cluster is regarded as a topic.
This issentence clustering.
Obviously, cluster and topichave the same meaning and can be replaced eachother.
In the other word, a particular entity typewas expected for each question, and every spe-cial entity of that type found in a retrieved sen-tence was regarded as a cluster/topic.In this paper, we propose two novel ap-proaches for sentence clustering.
The main ideaof the approaches is to conduct sentence cluster-ing according to the candidate answers which arealso considered as the names of the clusters.For example, given the question {??????
?/who invented telephone?
}, the top ten re-trieved sentences and the corresponding candi-date answers are shown as Table 1.
Thus, we canconduct sentence clustering according to thecandidate answers, that are, {?
?/Bell, ??
?/Siemens, ???/Edison,?
?/Cooper, ??
?/Stephen}.ID Top 10 Sentences Candidate AnswerS1 1876?
3?
10??????
?/Bell invented telephone on Oct. 3th, 1876.
??/BellS2???????????????????????
?/ Bell, Siemens and Edison invented telephone, electromo-tor and electric light respectively.??
?/ Siemens??/Bell??
?/ EdisonS3???
???????
???????????
?/Recently, the public paid a great deal of attention to Cooperwho is Father of Mobile Phone.?
?/CooperS4 1876 ?????????????
/In 1876, Bell in-vented telephone.
??/BellS5??
?1876 ??????????????
?1879 ??????????????
?/Subsequently, Americanscientist Bell invented the phone in 1876; Edison inventedthe electric light in 1879.??/Bell??
?/EdisonS6 1876 ?
3 ?
7 ??????????????
?/On March 7th, 1876, Bell became the patentee of telephone.
??/BellS7??????????????????????????
?/Bell not only invented telephone, but also estab-lished his own company for spreading his invention.??/BellS8???????????
30 ??????????????????????????
?/Thirty years afterthe invention of first mobile phone, Cooper still anticipatedthe date of the realization of future phone?s technology.??/Cooper57S9??????????????????????????????????????????????????
?/Cooper said, he was surprised at the speed that theconsumers switched to mobile phones; but the populariza-tion of mobile phone isn?t omnipresent, which made him alittle bit disappointed.??/CooperS10??????????????????????????????????
?/England inventor Stephen de-signed the paper-clicked CMOS chip which included allelectronic components.??
?/StephenTable 1 The Top 10 Retrieved Sentences and its Candidate AnswersBased on the above analysis, this paper pre-sents cluster-based language model for sentenceretrieval of Chinese question answering.
It dif-fers from most of the previous approachesmainly as follows.
1.
Sentence Clustering is con-ducted according to the candidate answers ex-tracted from the top 1000 sentences.
2.
The in-formation of the cluster of the sentence, which isalso called as topic, is incorporated into languagemodel through aspect model.
For sentence clus-tering, we propose two novel approaches that areOne-Sentence-Multi-Topics and One-Sentence-One-Topic respectively.
The experimental resultsshow that the performances of cluster-based lan-guage model for sentence retrieval are improvedsignificantly.The framework of cluster-based languagemodel for sentence retrieval is shown as Figure 1.Figure 1 The Framework of Cluster-based Language Model for Sentence Retrieval2 Language Model for Information Re-trievalLanguage model for information retrieval is pre-sented by Ponte & Croft in 1998[J. Ponte, et al1998] which has more advantages than vectorspace model.
After that, many improved modelsare proposed like J.F.
Gao [J.F Gao, et al 2004],C. Zhai [C. Zhai, et al 2001], and so on.
In 1999,Berger & Lafferty [A. Berger, et al 1999] pre-sented statistical translation model for informa-tion retrieval.The basic approach of language model for in-formation retrieval is to model the process ofgenerating query Q.
The approach has two steps.1.
Constructing document model for each docu-ment in the collection; 2.
Ranking the documentsaccording to the probabilities p(Q|D).
A classicalunigram language model for IR could be ex-pressed in equation (1).
( ) ( )?QwiiD|wpD|Qp?=                                   (1)where, wi is a query term, p(wi|D) is documentmodel which represents terms distribution overdocument.
Obviously, estimating the probabilityp(wi|D) is the key of document model.
To solvethe sparseness problem, Jelinek-Mercer is com-monly used which could be expressed by equa-tion (2).
( ) ( ) ( ) ( )C|wp?1D|wp?D|wp MLML ?+?= -   (2)where, pML(w|D) and pML(w|C) are documentmodel and collection model respectively esti-mated via maximum likelihood.QuestionDocumentRetrievalSentenceSplitterCandidate An-swer ExtractionLanguage Modelfor Sentence Re-trievalSentence Clus-teringResultsCluster-based Lan-guage Model forSentence RetrievalQuestionAnalyzer58As described above, the disadvantages ofstandard language model is that it does not makeany one particular document any more probablethan any other, on the condition that neither thedocuments originally contain the query term.
Inthe other word, if a document is relevant, butdoes not contain the query term, it is still nomore probable, even though it may be topicallyrelated.
Thus, the smoothing approaches basedon standard language model are improper.
In thispaper, we propose a novel cluster-based lan-guage model to overcome it.3 Cluster-based Language Model forSentence RetrievalNote that document model p(w|D) in documentretrieval is replace by p(w|S) called sentencemodel in sentence retrieval.The assumption of cluster-based languagemodel for retrieval is that topic-related sentencestend to be relevant to the same query.
So, incor-porating the topic of sentences into languagemodel can improve the performance of sentenceretrieval based on standard language model.The proposed cluster-based language model isa mixture model of three components, that aresentence model pML(w|S), cluster/topic modelp_topicML(w|T) and collection model pML(w|C).We can formulate our model as equation (3).
( ) ( ) ( )( ) ( ) ( )( )Cwp?1Twp_topic??1Swp?S|wpMLMLML|?+|?
?+|?=--          (3)In fact, the cluster-based language model canalso be viewed as a two-stage smoothing ap-proach.
The cluster model is first smoothed usingthe collection model, and the sentence model isthen smoothed with the smoothed cluster model.In this paper, the cluster model is in the formof term distribution over cluster/topic, associatedwith the distribution of clusters/topics over sen-tence, which can be expressed by equation (4).
( ) ( ) ( )?
?TtStptwpTwp_topic ||=|                     (4)where, T is the set of clusters/topics.
p_topic(w|T)is cluster model.
p(t|S) is topic sentence distribu-tion which means the distribution of topic oversentence.
And p(w|t) is term topic distributionwhich means the term distribution over topics.Before estimating the sentence model p(w|S),topic-related sentences should be organized intoclusters/topics to estimate p(t|S) and p(w|t) prob-abilities.
For sentence clustering, this paper pre-sents two novel approaches that are One-Sentence-Multi-Topics and One-Sentence-One-Topic respectively.3.1 One-Sentence-Multi-TopicsThe main idea of One-Sentence-Multi-Topicscan be summarized as follows.1.
If a sentence includes M different candidateanswers, then the sentence consists of M differenttopics.For example, the sentence S5 in Table 1 includestwo topics which are ??????
?/Bell in-vented telephone?
and ???????
?/Edisoninvented electric light?
respectively.2.
Different sentences have the same topic if twocandidate answers are same.For example, the sentence S4 and S5 in Table 1have the same topic ???????
/Bell in-vented telephone?
because both of sentenceshave the same candidate answer ??
?/Bell?.Based on the above ideas, the result of sen-tence clustering based on One-Sentence-Multi-Topics is shown in Table 2.Name of Clusters Sentences?
?/Bell S1 S2 S4 S5 S6 S7 S8??
?/Siemens S2??
?/Edison S2 S5?
?/Cooper S3 S8 S9??
?/Stephen S10Table 2 The Result of One-Sentence-Multi-Topics Sentence ClusteringSo, we could estimate term topic distributionusing equation (5).
( ) ( )( )?w't,w'ntwntwp,=|                                         (5)Topic sentence distribution can be estimatedusing equation (6) and (7).
( )?
//=|tststkl1kl1Stp                                            (6)( ) ( ) ( )( )?w MLMLMLst t|wpswplogs|wptsKLkl|?=||=    (7)where, klst means the Kullback-Leibler diver-gence between the sentence with the cluster/topic.k denotes the number of cluster/topic.
The mainidea of equation (6) is that the closer the Kull-back-Leibler divergence, the larger the topic sen-tence probability p(t|S).3.2 One-Sentence-One-TopicThe main idea of One-Sentence-One-Topic alsocould be summarized as follows.591.
A sentence only has one kernel candidate an-swer which represents the kernel topic no matterhow many candidate answers is included.For example, the kernel topic of sentence S5 inTable 1 is ??????
?/Bell invented tele-phone?
though it includes three different candi-date answers.2.
Different sentences have the same topic if twokernel candidate answers are same.For example, the sentence S4 and S5 in Table 1have the same topic ???????
/Bell in-vented telephone?.3.
The kernel candidate answer has shortest av-erage distance to all query terms.Based on the above ideas, the result of sen-tence clustering based on One-Sentence-One-Topic is shown in Table 3.Name of Clusters Sentences?
?/Bell S1 S2 S4 S5 S6 S7?
?/Cooper S3 S8 S9??
?/Stephen S10Table 3 The Result of One-Sentence-One-TopicSentence ClusteringEquation (8) and (9) can be used to estimatethe kernel candidate answer and the distances ofcandidate answers respectively.
Term topic dis-tribution in One-Sentence-One-Topic can be es-timated via equation (5).
And topic sentence dis-tribution is equal to 1 because a sentence onlybelongs to one cluster/topic.
{ }iiaa*i SemDis  a argmin=                               (8)( )Nq,aSemDisSemDis jjiai?=(9)( )ji qaji PositionPositionqaSemDis -=,           (10)where, ai* is the kernel candidate answer.
ai isthe i-th candidate answer,iaSemDis is the averagedistance of i-th candidate answer.
qj is the j-thquery term, N is the number of all query terms.jqPosition and iaPosition  mean the position ofquery term qj and candidate answer ai.4 Experiments and AnalysisResearch on Chinese question answering, is stillat its early stage.
And there is no public evalua-tion platform for Chinese question answering.
Soin this paper, we use the evaluation environmentpresented by [Youzheng Wu, et al 2004] whichis similar to TREC question answering track[Ellen.
M. Voorhees.
2004].
The documents col-lection is downloaded from Internet which size is1.8GB.
The testing questions are collected viafour different approaches which has 7050 Chi-nese questions currently.In this section, we randomly select 807 testingquestions which are fact-based short-answerquestions.
Moreover, the answers of all testingquestions are named entities identified by[Youzheng Wu, et al 2005].
Figure 2 gives thedetails.
Note that, LOC, ORG, PER, NUM andTIM denote the questions which answer typesare location, organization, person, number andtime respectively, SUM means all question types.165311281681350100200300400PER LOC ORG TIM NUMFigure 2 The Distribution of Various QuestionTypes over Testing QuestionsChinese question answering system is to re-turn a ranked list of five answer sentences perquestion and will be strictly evaluated (unsup-ported answers counted as wrong) using meanreciprocal rank (MRR).4.1 Baseline: Standard Language Model forSentence RetrievalBased on the standard language model for infor-mation retrieval, we can get the baseline per-formance, as is shown in Table 4, where ?
is theweight of document model.?
0.6 0.7 0.8 0.9LOC 49.95 51.50 52.63 54.54ORG 53.69 51.01 50.12 51.01PER 63.10 64.42 65.94 65.69NUM 48.43 49.86 51.78 53.26TIM 56.97 58.38 58.77 61.49SUM 53.98 55.28 56.40 57.93Table 4 The Baseline MRR5 Performance60In the following chapter, we conduct experi-ments to answer two questions.1.
Whether cluster-based language model forsentence retrieval could improve the perform-ance of standard language model for sentenceretrieval?2.
What are the performances of sentence clus-tering for various question types?4.2 Cluster-based Language Model for Sen-tence RetrievalIn this part, we will conduct experiments to vali-date the performances of cluster-based languagemodels which are based on One-Sentence-Multi-Topics and One-Sentence-One-Topic sentenceclustering respectively.
In the following experi-ments, ?
= 0.9.4.2.1 Cluster-based Language Model Basedon One-Sentence-Multi-TopicsThe experimental results of cluster-based lan-guage model based on One-Sentence-Multi-Topics sentence clustering are shown in Table 5.The relative improvements are listed in thebracket.?
0.6 0.7 0.8 0.9LOC 55.57 (+11.2)55.61(+7.98)56.59(+7.52)57.70(+5.79)ORG 59.05 (+9.98)59.46(+16.6)59.46(+18.6)59.76(+17.2)PER 67.73 (+7.34)68.03(+5.60)67.71(+2.68)67.45(+2.68)NUM 52.79 (+9.00)53.90(+8.10)54.45(+5.16)55.51(+4.22)TIM 60.17 (+5.62)60.63(+3.85)62.33(+6.06)61.68(+0.31)SUM 58.14 (+7.71)58.63(+6.06)59.30(+5.14)59.54(+2.78)Table 5 MRR5 Performance of Cluster-basedLanguage Model Based on One-Sentence-Multi-TopicsFrom the experimental results, we can findthat by integrating the clusters/topics of the sen-tence into language model, we can achieve muchimprovement at each stage of ?.
For example, thelargest and smallest improvements for all typesof questions are about 7.7% and 2.8% respec-tively.
This experiment shows that the proposedcluster-based language model based on One-Sentence-Multi-Topics is effective for sentenceretrieval in Chinese question answering.4.2.2 Cluster-based Language Model Basedon One-Sentence-One-TopicThe performance of cluster-based languagemodel based on One-Sentence-One-Topic sen-tence clustering is shown in Table 6.
The relativeimprovements are listed in the bracket.?
0.6 0.7 0.8 0.9LOC 53.02 (+6.15)54.27(+5.38)56.14(+6.67)56.28(+3.19)ORG 58.75 (+9.42)58.75(+17.2)59.46(+18.6)59.46(+16.6)PER 66.57 (+5.50)67.07(+4.11)67.44(+2.27)67.29(+2.44)NUM 49.95 (+3.14)50.87(+2.02)52.15(+0.71)53.51(+0.47)TIM 59.75 (+4.88)60.65(+3.89)62.71(+6.70)62.20(+1.15)SUM 56.48 (+4.63)57.65(+4.29)58.82(+4.29)59.22(+2.23)Table 6 MRR5 Performance of Cluster-basedLanguage Model Based on One-Sentence-One-TopicIn Comparison with Table 5, we can find thatthe improvement of cluster-based languagemodel based on One-Sentence-One-Topic isslightly lower than that of cluster-based languagemodel based on One-Sentence-Multi-Topics.
Thereasons lie in that Clusters based on One-Sentence-One-Topic approach are very coarseand much information is lost.
But the improve-ments over baseline system are obvious.Table 7 shows that MRR1 and MRR20 scoresof cluster-based language models for all questiontypes.
The relative improvements over the base-line are listed in the bracket.
This experiment isto validate whether the conclusion based on dif-ferent measurements is consistent or not.One-Sentence-Multi-TopicsOne-Sentence-One-Topic?
MRR1 MRR20 MRR1 MRR200.6 50.00 (+14.97)59.60(+7.66)48.33(+10.37)57.70(+4.23)0.7 50.99 (+13.36)60.03(+6.12)49.44(+9.92)58.62(+3.62)0.8 51.05 (+8.99)60.68(+5.06)51.05(+8.99)60.01(+3.90)0.9 51.92 (+5.81)61.05(+2.97)51.30(+4.54)60.25(+1.62)Table 7 MRR1 and MRR20 Performances ofTwo Cluster-based Language Models61Table 7 also shows that the performances oftwo cluster-based language models are higherthan that of the baseline system under differentmeasurements.
For MRR1 scores, the largestimprovements of cluster-based language modelsbased on One-Sentence-Multi-Topics and One-Sentence-One-Topic are about 15% and 10%respectively.
For MRR20, the largest improve-ments are about 7% and 4% respectively.Conclusion 1: The experiments show that theproposed cluster-based language model can im-prove the performance of sentence retrieval inChinese question answering under the variousmeasurements.
Moreover, the performance ofclustering-based language model based on One-Sentence-Multi-Topics is better than that basedon One-Sentence-One-Topic.4.3 The Analysis of Sentence Clustering forVarious Question TypesThe parameter ?
in equation (3) denotes the bal-ancing factor of the cluster model and the collec-tion model.
The larger ?, the larger contributionof the cluster model.
The small ?, the larger con-tribution of the collection model.
If the perform-ance of sentence retrieval decreased with the in-creasing of ?, it means that there are many noisesin sentence clustering.
Otherwise, sentence clus-tering is satisfactory for cluster-based languagemodel.
So the task of this experiment is to findthe performances of sentence clustering for vari-ous question types, which is helpful to select themost proper ?
to obtain the best performance ofsentence retrieval.With the change of ?
and the fixed ?
(?
= 0.9),the performances of cluster-based languagemodel based on One-Sentence-Multi-Topics areshown in Figure 3.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.90.50.520.540.560.580.60.620.640.660.68SUMLOCORGPERNUMTIMFigure 3 MRR5 Performances of Cluster-basedLanguage Model Based on One-Sentence-Multi-Topics with the Change of ?In Figure 3, the performances of TIM andNUM type questions decreased with the increas-ing of the parameter ?
(from 0.6 to 0.9), whilethe performances of LOC, PER and ORG typequestions increased.
This phenomenon showedthat the performance of sentence clustering basedon One-Sentence-Multi-Topics for TIM andNUM type questions is not as good as that forLOC, PER and ORG type questions.
This is infact reasonable.
The number and time words fre-quently appeared in the sentence, which does notrepresent a cluster/topic when they appear.
WhilePER, LOC and ORG entities can represent atopic when they appeared in the sentence.Similarly, with the change of ?
and the fixed ?
(?=0.9), the performances of cluster-based lan-guage model based on One-Sentence-One-Topicare shown in Figure 4.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.90.50.520.540.560.580.60.620.640.660.68SUMLOCORGPERNUMTIMFigure 4 MRR5 Performance of Cluster-basedLanguage Model Based on One-Sentence-One-Topic with the Change of ?In Figure 4, the performances of TIM, NUM,LOC and SUM type questions decreased with theincreasing of ?
(from 0.6 to 0.9).
This phenome-non shows that the performances of sentenceclustering based on One-Sentence-One-Topic arenot satisfactory for most of question types.
But,compared to the baseline system, the cluster-based language model based on this kind of sen-tence clustering can still improve the perform-ances of sentence retrieval in Chinese questionanswering.Conclusion 2: The performance of the pro-posed sentence clustering based on One-Sentence-Multi-Topics for PER, LOC and ORGtype questions is higher than that for TIM andNUM type questions.
Thus, for PER, LOC andORG questions, we should choose the larger ?value (about 0.9) in cluster-based languagemodel based on One-Sentence-Multi-Topics.While for TIM and NUM type questions, the62value of ?
should be smaller (about 0.5).
But, theperformance of sentence clustering based onOne-Sentence-One-Topic for all questions is notideal, so the value for cluster-based languagemodel based on One-Sentence-One-Topic shouldbe smaller (about 0.5) for all questions.5 Conclusion and Future WorkThe input of a question answering system isnatural language question which contains richerinformation than the query in traditional docu-ment retrieval.
Such richer information can beused in each module of question answering sys-tem.
In this paper, we presented a novel cluster-based language model for sentence retrieval inChinese question answering which combines thesentence model, the cluster/topic model and thecollection model.For sentence clustering, we presented two ap-proaches that are One-Sentence-Multi-Topicsand One-Sentence-One-Topic respectively.
Theexperimental results showed that the proposedcluster-based language model could improve theperformances of sentence retrieval in Chinesequestion answering significantly.However, we only conduct sentence clusteringfor questions, which have the property that theiranswers are named entities in this paper.
In thefuture work, we will focus on all other type ques-tions and improve the performance of the sen-tence retrieval by introducing the structural, syn-tactic and semantic information into languagemodel.ReferenceJ.
Ponte, W. Bruce Croft.
A Language Modeling Ap-proach to Information Retrieval.
In the Proceedingsof ACM SIGIR 1998, pp 275-281, 1998.C.
Zhai, J. Lafferty.
A Study of Smoothing Tech-niques for Language Modeling Applied to ad hocInformation Retrieval.
In the Proceedings of theACM SIGIR Conference on Research and Devel-opment in Information Retrieval, 2001.Ittycheriah, S. Roukos.
IBM's Statistical QuestionAnswering System-TREC 11.
In the Eleventh TextRetrieval Conference (TREC 2002), Gaithersburg,Maryland, November 2002.Hui Yang, Tat-Seng Chua.
The Integration of LexicalKnowledge and External Resources for QuestionAnswering.
In the Proceedings of the EleventhText REtrieval Conference (TREC?2002), Mary-land, USA, 2002, page 155-161.Andres Corrada-Emmanuel, W.Bruce Croft, VanessaMurdock.
Answer Passage Retrieval for QuestionAnswering.
In the Proceedings of the 27th AnnualInternational Conference on Research and Devel-opment in Information Retrieval, pp.
516 ?
517,2004.Ellen M. Voorhees.
Overview of the TREC 2004Question Answering Track.
In Proceedings of theTwelfth Text REtrieval Conference (TREC 2004),2004.Vanessa Murdock, W. Bruce Croft.
Simple Transla-tion Models for Sentence Retrieval in FactoidQuestion Answering.
In the Proceedings of theSIGIR 2004 Workshop on Information Retrievalfor Question Answering, pp.31-35, 2004.Thomas Hofmann.
Probabilistic Latent Semantic In-dexing.
In the Proceedings of the Twenty-SecondAnnual International SIGIR Conference on Re-search and Development in Information Retrieval,1999.A.
Berger and J. Lafferty.
Information Retrieval asStatistical Translation.
In the Proceedings of ACMSIGIR-1999, pp.
222?229, Berkeley, CA, August1999.A.
Echihabi and D.Marcu.
A noisy-channel approachto question answering.
In the Proceeding of the41st Annual Meeting of the Association for Com-putational Linguistics, Sappora, Japan, 2003.Leif Azzopardi, Mark Girolami and Keith vanRijsbergen.
Topic Based Language Models for adhoc Information Retrieval.
In the Proceeding ofIJCNN 2004 & FUZZ-IEEE 2004, July 25-29,2004, Budapest, Hungary.Jian-Yun Nie.
Integrating Term Relationships intoLanguage Models for Information Retrieval.
Re-port at ICT-CAS.Jianfeng Gao, Jian-Yun Nie, Guangyuan Wu andGuihong Cao.
2004b.
Dependence language modelfor information retrieval.
In SIGIR-2004.
Sheffield,UK, July 25-29.Youzheng Wu, Jun Zhao, Bo Xu.
Chinese NamedEntity Recognition Model Based on Multiple Fea-tures.
In the Proceeding of HLT/EMNLP 2005,Vancouver, B.C., Canada, pp.427-434, 2005.Youzheng Wu, Jun Zhao, Xiangyu Duan  and Bo Xu.Building an Evaluation Platform for Chinese Ques-tion Answering Systems.
In Proceeding of the FirstNational Conference on Information Retrieval andContent Security.
Shanghai, China, December,2004.
(In Chinese)63
