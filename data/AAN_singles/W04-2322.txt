A Rule Based Approach to Discourse ParsingLivia Polanyi, Chris Culy, Martin van den Berg, Gian Lorenzo Thione, David Ahn1FX Palo Alto Laboratory3400 Hillview Avenue, Bldg 4Palo Alto CA 94304{polanyi|culy|vdberg|thione}@fxpal.com ; ahn@science.uva.nlAbstractIn this paper we present an overview ofrecent developments in discourse the-ory and parsing under the LinguisticDiscourse Model (LDM) framework, asemantic theory of discourse structure.We give a novel approach to the prob-lem of discourse segmentation basedon discourse semantics and sketch alimited but robust approach to sym-bolic discourse parsing based on syn-tactic, semantic and lexical rules.
Todemonstrate the utility of the system ina real application, we briefly describethe architecture of the PALSUMM sys-tem, a symbolic summarization systembeing developed at FX Palo Alto Labo-ratory that uses discourse structuresconstructed using the theory outlinedto summarize written English prosetexts.
11 IntroductionIn this paper we present an overview of recenttheoretical and computational developments indiscourse theory and parsing under the LinguisticDiscourse Model (LDM) framework, a semanticaccount of discourse structure.
In Section 2, we1 Current address:Language and Inference Technology Group,ILLC, University of Amsterdam,Nieuwe Achtergracht 166,1018 WV Amsterdam, The Netherlandspresent an overview of what we will term theClassical LDM (C-LDM) and identify criticalproblems encountered in implementing themodel: the difficulty in segmenting complexsentences within a text and calculating the at-tachment site and relationship of an incomingunit to an appropriate node in a developing Dis-course Tree.
In Sections 3 and 4 we introduce theUnified Linguistic Discourse Model (U-LDM)that incorporates solutions to these problems.Specifically, in Section 3 we describe a novelapproach to discourse segmentation based on therelationship of sentential syntax to discoursesemantics.
In Section 4, a limited but robust ap-proach to symbolic discourse processing basedon syntactic, semantic and lexical rules is given.In Section 5, we sketch the architecture of thePALSUMM system, a summarization systembeing developed at FX Palo Alto Laboratory thatuses algorithms operating on discourse represen-tations generated by a U-LDM parser to summa-rize written English prose texts.
In Section 6 wepresent our conclusions and suggest directionsfor future research.2 The Classical Linguistic Dis-course Model (C-LDM)Unlike the Discourse Structures Model (DSM) ofGrosz and Sidner (1986), a pragmatic and psy-chological theory that aims to clarify the rela-tionship between speakers?
intentions and theirfocus of attention in discourse, or the rhetoricalmodel of Rhetorical Structures Theory (Mannand Thompson, 1988) that is designed to identifythe coherence relations between segments oftext, the Linguistic Discourse Model (LDM)(Polanyi and Scha, 1984; Polanyi, 1988; Polanyiand van den Berg, 1996) is a syntactically in-formed, semantically driven model developed toprovide proper semantic interpretation for everyutterance in a discourse despite the apparent dis-continuities that are present even in well struc-tured written texts.
In its focus on understandingdiscourse meaning, the LDM is close in spirit toStructured Discourse Representation Theory (S-DRT) (Asher, 1993).
While S-DRT attempts toaccount for discourse structure purely semanti-cally, the LDM framework is concerned to main-tain a separation between discourse ?syntactic?structure, on the one hand, and discourse inter-pretation on the other.
Therefore, like DSM andRST, the LDM incorporates an explicit treestructured model of relationships between dis-course segments as its model of discourse ?syn-tax?.
In discourse parsing under the LDM, anyattachment to the developing discourse tree of atextual unit is treated as an instruction to updatean appropriate semantic representation.
We con-struct dynamic semantic representations (DSRs),similar to the Discourse Representation Struc-tures (Kamp, 1981; Kamp and Reyle, 1993) usedin S-DRT as its model of discourse semantics.The DSRs correspond to the contexts relative towhich subsequent segments can be interpreted.The analysis of intra-sentential structure isdone by sentential syntax which identifies thesyntactic and semantic structures within the sen-tence and makes the resulting analysis availablefor discourse processing.2.1 Overview of the Classic LDMIn the Linguistic Discourse Model (LDM) dis-course is formed through the recursive combina-tion of discourse constituent units (DCUs).
Thestructure of a discourse is represented by an openright tree of DCUs.
Basic discourse units(BDUs), resulting from a segmentation of thediscourse according to rules of discourse seg-mentation, form the content of the leaves of thetree.
Once a text has been segmented into BDUs,an open right tree representing the structure ofthe discourse is built up.
The completed treeshows, for any given point in the discourse,which discourse units (DCUs) remain availablefor continuation and which DCUs are no longeravailable.
Because discourse anaphora resolutionis critically constrained by discourse structure,the tree representation makes clear the domain inwhich the antecedent for a given anaphoric refer-ential expression is to be found.
Antecedentsmust be available at a node along the right edgeof the discourse tree.
(Polanyi, 1985; Grosz andSidner 1986; Webber, 1991)The LDM posits three structural relations be-tween discourse units:1. discourse coordinationa.
Units related by bearing a similar rela-tionship to an existing or newly formedcommon parent in the tree (lists, narra-tives).b.
Available at the C-node is informationcommon to all child nodes.2.
discourse subordinationa.
Units related by an elaboration relation-ship in which the subordinated unit pro-vides more information about an entityor situation described in the subordinat-ing unit.b.
Units unrelated to existing units avail-able on the right edge of the tree,viewed as intrusions or interruptions.c.
Available at the S-node is informationspecific only to the subordinating ordominant constituent (usually the leftchild).3. n-ary constructionsa.
Units related by logical or rhetorical,genre or interactional conventions spe-cific to a given language.b.
Preposed modifier, sentence initial ad-verbial, ?cue word?, (reported speech)attribution phrase.c.
Available at N-nodes is informationabout each constituent and the relation-ship connecting them.Although we believe that the general approach todiscourse structure captured by the ClassicalLDM is essentially sound, there are three criticalproblems with the existing framework:1.
Segmenting the incoming text into BDUs2.
Determining the existing or new node atwhich to attach an incoming BDU3.
Determining the relationship between theincoming BDU and the attachment nodeAlthough very difficult challenges associatedwith each of these discourse parsing tasks re-main, in developing the Unified Linguistic Dis-course Model (U-LDM) we have madesignificant progress recently on solving them.These are discussed in Sections 3 and 4 below.3 Discourse SegmentationThe problem of segmenting discourse into theelementary units appropriate for building up thestructure of the discourse is an extremely diffi-cult one.
Each discourse theory must specifyhow ?segments?
should be identified in light ofthe questions the theory is set up to answer.Models based on Grosz and Sidner?s 1986 work,especially those which form the basis of spokenlanguage systems, define segments in terms ofthe intentions of the speaker: when the speaker?sintention shifts, the segment associated with thatintention ends and immediately following talk isincluded in new (or resumed) segments.
Whilevery useful in dealing with task oriented talkwhere speakers move between asking questions,informing others and giving commands, thismodel is less applicable to determining discoursesegments within a sentence.
The problem is anacute one for the analysis of written texts be-cause often a subsequent, not necessarily adja-cent, segment will continue the development ofmaterial introduced in a sub-sentential, oftensubordinate, constituent.
Construction of theappropriate representation of the rhetorical orsemantic structure of discourse must thereforekeep sub-sentential units available for attach-ment at independent nodes on the tree along.
Theentire sentence or sentential main constituentmust also be available to be continued after anycontinuation on sub-sentential units has beencompleted.
As reported by Carlson et al (2003),under RST2, lexical and syntactic informationused to segment discourse into Elementary Dis-course Units (EDUs) is based on verbal constitu-ents including clauses and infinitives.3As we show below, the approach taken tosegmentation under the U-LDM, while it in-cludes as segments (and non-segments) many ofthe constructions currently used in RST, pro-vides a rationalization for the choice of units.Rather than posit which syntactic objects func-tion as discourse segments, we started by estab-lishing the semantic basis for functioning as asegment and then identified which syntactic con-structions carry the semantic information neededfor discourse segment status.
We then identifiedas Basic Discourse Units (BDUs) segments thathave the potential to independently establish ananchor point for future continuation.
We thendrew a further distinction between BDUs as aclass of syntactic structures with the potential to2  Under S-DRT, no explicit structural tree isconstructed and no explicit segmentation criteriahave been proposed in the literature.3 Although some clauses are not treated as ele-mentary units and ?a small number of phrasal EDUsare allowed, provided that the phrase begins with astrong discourse marker.
?establish anchor points and the actual BDUs in agiven sentence which can function as indexicalanchor points in a specific discourse.
We believethese distinctions, while cumbersome, are neces-sary for both theoretical and practical text analy-sis.3.1 Discourse Segments under the U-LDMAs a semantic theory, the U-LDM must accountfor the interpretation of utterances.
Specifically,we must account for the availability for update ofappropriate discourse contexts or sub-contextsintroduced in earlier text.
In order to do so, wemust be able to match incoming discourse utter-ances with their target contexts, some of whichmay have been introduced in syntactically sub-ordinated positions within a sentence.
Therefore,in designing U-LDM discourse segmentation, wehave identified the syntactic reflexes of the se-mantic content of the linguistic or paralinguisticphenomena making up discourse.Since elementary discourse units are neededto build up discourse structure recursively, wehave identified as discourse segments the syntac-tic constructions that encode a minimum unit ofmeaning and/or discourse function interpretablerelative to a set of contexts.
We understand aminimum unit of meaning to communicate in-formation about not more than one ?event?,?event-type?
or state of affairs in a ?possibleworld?
of some type4.
Clauses, and many otherverb based structures, carry indexical informa-tion that ties the content to the context in whichit is to be interpreted.
Minimal functional units,on the other hand encode information about howpreviously occurring (or possibly subsequent)linguistic gestures relate structurally, semanti-cally, interactionally or rhetorically to other unitsin the discourse or to information in the contextin which the discourse takes place5.Examples of discourse segments are given inTable 1.
Note that while discourse segments un-der the U-LDM are the syntactic reflex of a lin-guistically realized semantic ?gesture?interpreted relative to context, they need not becontiguous, but may completely surround an-other segment (e.g.
an appositive, or non-restrictive relative clause.)
Discontinuous seg-4  Roughly speaking an ?elementary proposi-tion?, ?event-type predicate?
etc.
In a Davidsonianstyle semantics, quantification over an event vari-able signals a separate unit of meaning.5 Greetings, discourse PUSH/POP markers andother ?cue phrases?, connectives etc.
are all func-tional segments.ments occur when there is overt material on bothsides of the intervening segment.
With fragmen-tary segments, the full interpretation remainsunrecoverable from surrounding context.
Forexample: a single word answer to a question is acomplete segment, whereas the same word ut-tered but ?left hanging?
would be an un-interpretable fragment.
(See Appendix for exten-sive example of a segmented text.
)3.2 Basic Discourse UnitsAn important contrast between the U-LDM andother approaches to segmentation concerns thedistinction made in the U-LDM between dis-course segments such as those we have identifiedabove and Basic Discourse Units (BDUs).
Whileall BDUs under the U-LDM are segments, notall segments are BDUs.
BDUs, under this model,are discourse segments of a type that can be in-dependently continued: operator segments areone example of non-BDU segments.
Other verbbases constituents that might be expected to besegments are not because they do not establishan interpretation context independent of othersegments that can be updated by subsequentunits.
In general, these ?notable non-segments?,summarized in Table 2, are heavily integratedinto other nominal or verbal constructions andcannot be accessed for independent continuation.Non-segments ExamplesGerunds [Singing is fun.
]Nominalizations [Rationalization is useless.
]Auxiliary andmodal verbs[I might have succeeded.
]Clefts [It was the tiger that we liked best.
]Table 2. Notable non-segments (underlined).
66 In answer to a reviewer who asked if in "Sing-ing is fun", singing should not be an independentIn order to account for continuation in specificsentences, we further identify one class of in-stances of BDU: Active BDUs (A-BDUs) areBDUs on the right edge of a discourse tree.
Themain clause of any sentence will be an A-BDUand, depending on the deployment of BDU seg-ments within a given sentence, other BDUs mayalso be accessible for continuation.
(See Section4 below.
)4 Discourse Parsing with theU-LDMAscertaining the relationship of a BDU to thediscourse is a complex parsing process involvinglexical, semantic, structural and syntactic infor-mation7.
For the case of written prose we areconcentrating on here, the unit of analysis is thesentence (or sentence fragment).
Sentences areattached to the DPT of the text as a unit8.
Dis-course attachment of the sentence involves twodecisions: where along the right edge to attach,and what is the relationship to the attachmentpoint.
The process, which includes constructing aBDU tree of the sentence, can be summarized asfollows:segment, we would answer that this sentences con-cerns one eventuality (something being fun), not two.Since any noun can be referred to by a pronoun inthe next sentence simply referring to the noun is notequivalent to referring to the eventuality in whichthe referent of the noun is a participant.7 Although the linguistic (and lexical) informa-tion we discuss could be augmented with processesrelying upon high level world knowledge and infer-ence, we believe that it is extremely significant tosee how far one can get with discourse parsing with-out invoking non-linguistic information.8 See discussion of MBDU below.Segments Common realizations ExamplesContent segmentsClauses: main, subordinate [I heard the dog] [that was barking.
]Predication [California elected Schwarzenegger] [governor]Participial modifiers [The donkey [braying next door] was annoying.
]Eventualities (activities orstates) and their participants.Infinitival modifiers [We persuaded them] [to leave.
][They left] [to get the tickets.
]Parentheticals [The show [(and what a show it was)] lasted 4 hours.
]Appositives [The building, [an example of the Mozarabic style,] wasrecently restored.
]InterpolationsInterruptions [They were [?
Stop that!
?]
leaving at 8:00.
]Fragments Section headings [4.
Discussion]List items [e.g., [hydrogen,] [helium]]?Restarted?
material [My dog,] [no,] [my cat ran away.
]Operator SegmentsConjunction Conjunctions [We arrived] [and] [got seats.
]Discourse operators ?scene-setting?
preposed modifi-ers[On Tuesday,] [we will see the sites.]?cue?
words  [Anyway,] [we did get there on time.
]Table 1.
Examples of Discourse Segments, Unlabelled bracketing is used to indicate segments.?
Identify potential BDUs within sentenceusing sentential syntax?
Construct a BDU-tree from the segments ofthe sentence, using sentential syntactic in-formation and discourse rules to map seg-ments and relationships among them.
ThisBDU-tree is itself an Open Right Tree domi-nated by the node corresponding to the Mainclause of sentence9.
(This is the Main BDUor MBDU).?
Attach the BDU-tree as a unit to the Dis-course Parse Tree by computing the rela-tionship of MBDU and preposed modifiers,if any, to accessible DCUs aligned along theright edge of the tree using rules of dis-course relations (See Section 4.1 below).Lexical information used for attachment de-cisions can come from anywhere in theBDU tree.?
Once the BDU-tree is attached, its terminalleaves are terminal nodes of the DiscourseParse Tree (DPT) and any terminal or inter-mediary nodes on the right edge of the BDUtree are DCUs on the DPT accessible for at-tachment in the next iteration of the process.In order to determine which accessible DCUs arecandidates for M-BDU attachment and what re-lationship obtains between the incoming unit andthe selected DCU, a number of distinct types ofevidence are used, including:1) lexical informationreuse somewhere in the BDU tree of thesame lexeme, synonym/antonym, hypernym,or participation in the same lexical frame or?semantic field?
as item in target node.2) syntactic informationparallel syntactic structure; topic/focus andcentering information, syntactic status of re-used lexemes, pre-posed adverbial constitu-ents, etc.3) semantic informationrealis status, genericity, tense, aspect, pointof view etc.
in the MBDU9 This process is too complex to describe in de-tail here but it involves looking at both the F-structure of the sentential parsing information re-turned by the XLE and applying discourse rules tothe BDUs identified.
Soricut and Marcu (2003) alsobuild up RST sentential trees to use in discourseparsing.
Both the information and methods used toconstruct RST trees as well as the trees themselvesdiffer from ours.4) constituents of incomplete n-ary construc-tions on the right edgeQuestions, initial greetings, genre-internalunits like sections and sub-sections, etc.5) structure of both the local attachmentpoint and the BDU-treeWhile we are still experimenting with under-standing the complexities involved in attach-ment, we believe that different types of evidencehave different weights10 and that the combinedweight of evidence determines the attachmentpoint.
We have noted, however even at this stageof our investigations, that the weight given toeach type of information differs for attachmentsite selection and relationship determination.Lexical information, for example, is often veryimportant in determining site, while semanticand syntactic information is most relevant indetermining relationship.
In the remainder of thissection we will give a small set of robust rulesfor determining the attachment site and relation-ship of an incoming BDU-tree to the existingparse tree of the discourse.4.1 Rules for Determining DiscourseAttachment Site Candidates andAttachment RelationsBoth the attachment site choice and the actualattachment process rely on partially ordered setsof hybrid rules, each of which are conditioned ona set of constraints.
Constraints for rules used inattachment site selection are primarily lexicalconstraints, although other information is alsorelevant.All types of evidence play a role in choosingthe attachment relation.
A rule is a pair: Rule<C, O> where C is the set of constraints thatenable the rule and O is the associated operation.The operation associated with a rule can there-fore be either the markup of a DCU as a possibleattachment site, or an actual discourse relation,such as Subordination, Coordination or N-ary.
Arule is enabled when all sub-conditions in C aresatisfied and no other rules having priority areenabled.
Rules may combine different sources ofevidential information (semantic, syntactic,structural and lexical).
If more than one rule isenabled at the same time, ambiguous parses areproduced11.
Some rules are listed in Table 3.10 We assign weights heuristically at this point.11 At this stage in our research, we rely only on apartial order among the rules.
In future work, wewill investigate (1) how evidence is weighed andcombined in order to make better attachment deci-The parsing process at the Discourse ParseTree (DPT) level works as follows.
When aBDU-Tree has been constructed and is ready tobe attached to the right edge of the DPT, eachDCU along the right edge is examined and thelexical information in the right-edge DPT nodesare compared with the lexical evidence retrievedsions and (2) the extent to which discourse ambigu-ity generated in this fashion is legitimate and how toreduce grammar overgeneration by more efficienthandling of interactions among rules and the weigh-ing of the linguistic evidence.from the incoming BDU-Tree.
This process,guided by the set of discourse rules, produces anordered set of active DCUs, representing thepossible attachment points in order of likelihood.The set can then be pruned of its n lowest scor-ing constituents, according to an appropriatepolicy such as a threshold.In a second stage, each attachment rule ischecked against possible attachment sites.
Rulesthat fire successfully attach the BDU-Tree to theDPT at the chosen site with the relationshipspecified by the rule.
Local semantic, lexical andsyntactic information is then percolated up to theAttachment Relation Sub ConditionsNary-AttachmentFrame(AP,MBDU) matches genre-specific constructionGreetings, Argument, Question/Answer, Speech Event,Genre Meta Structure(Story, Technical Paper, Lecture, etc..)Reported speech/reporting clauseSubordination M-BDU Realis status differs from Status of AP (MBDU is Irrealis; AP is Realis OR MBDU is Realis; AP is Irrealis)Nary-Attachment(intrasentential)Tense(AP) = pastTense(MBDU) = pluperfectAP is time-reference for MBDUNary-Attachment(intrasentential)VerbClass(AP)=?SpeechAct?Type(MBDU) = ADJUNCTNary-Attachment(intrasentential)Tense(AP) = presentTense(MBDU) = pastAP is time-reference for MBDUCoordinateParent(AP) is CoordinationParent(AP) would coordinate with MBDUAP would coordinate with MBDUSubordinationTense(AP) = pastGenericty(AP) = specificTense(MBDU) = presentGenericty(MBDU) = genericSubordination M-BDU genericity status differs from Status of AP (MBDU is specific; AP is generic OR MBDU is generic; AP is specific)Subordination SUBJ(MBDU) = OBJ(AP)Subordination SUBJ(MBDU) = XCOMP(AP)Subordination MBDU/Lexeme is a subcase of AP/Lexeme Role(AP/Lexeme) = Role(MBDU/Lexeme)Right Headed Subordination(intrasentential)Type(AP) = ADJUNCTType(MBDU) = SNary-Attach(intrasentential)PRED(ADJUNCT(AP)) = ?if?AP is IrrealisMBDU is RealisNary-Attachment(intrasentential) AP and MBDU related by logical connective (cf Webber& Joshi, 1998; Forbes (2003)Subordination  Tense(AP) = past Tense(MBDU) = pluperfectSubordination Tense(AP) = present Tense(MBDU) = pastSubordinate AP is Bottom of DPT M-BDU is Footnote or ParentheticalCoordinate AP is Narrative( = Specific, punctual ,event) MBDU is NarrativeCoordinate Tense(AP) = Tense(MBDU) Aspect(AP) = Aspect(MBDU)Coordinate MBDU/Lexeme is synonym or antonym of AP/Lexeme Role(AP/Lexeme) = Role(MBDU/Lexeme)Subordinate AP is Bottom of DPTTable 3.
Discourse Attachment Rules ordered to express priority of the rules.
AP denotes (potential)attachment point.DCU consisting of the parent of both attachmentpoint and incoming MBDU according to con-straints of the discourse relation selected.
If mul-tiple attachments at different sites are possible,ambiguous parses are generated; less preferredattachments are discarded and the remainingattachment choices generate valid parse trees.5 PALSUMM Text SummarizationSo far, we have described the U-LDM only as atheoretical approach to discourse parsing.
Wenow turn briefly to describe a computationalimplementation of these methods.
ThePALSUMM Text Summarization System is adomain independent symbolic sentence extrac-tion system that produces high level readablesummaries that preserve the language and styleof the original text and eliminate problems withunresolved or incorrect reference.
Our system iscurrently used to summarize a corpus of 300technical reports produced by our laboratory.
12The PALSUMM System relies on the XeroxLinguistic Environment (XLE) to parse the sen-tences of our source texts.
The f-structure outputof the XLE parser is segmented into units ac-cording to the criteria identified above.
The seg-ments are then combined into a BDU-tree.
Usingsyntactic information about syntactic coordina-tion and subordination relations, lexical onto-logical information taken from WordNet and acustomized lexical domain ontology as well asdiscourse rules, the M-BDU of the sentencealong with any other BDUs that must be accessi-ble along the right edge of the discourse tree toaccommodate possible continuations are identi-fied, Both the site of attachment and the attach-ment relation are then computed using discourseattachment rules of the type presented above.Text summarization algorithms are then appliedto the resulting tree.Running in purely symbolic mode, the tree ispruned at a given level of embeddedness to pro-duce a summary of a desired length or degree ofsummarization.13 Because the resulting summa-12 For illustration purposes, we present in Ap-pendix A a summary of a document that was handcoded using the rules given and then summarizedautomatically using the PALSUMM tree pruning al-gorithm.
The PALSUMM Summaries were judgedto be significantly more readable than summariesproduced by MEAD in a small comparative study.In Appendix B, we present a diagram of thePALSUMM system.13 Although closely related to methods reportedby Marcu (1999, 2000) for summarization usingries may be longer than desired, alternatively wealso use statistical methods to identify salientinformation (see discussion and references inMarcu 2003) and then construct a partial dis-course tree that includes only information identi-fied as most salient and the text at all nodesdominating that salient information.6 Conclusions and Directions forfuture workThe U-LDM discussed in this paper represents asignificant advance in the theoretical understand-ing of the nature of discourse structure.
The ex-plicit rules for discourse segmentation based onthe syntactic reflexes of semantic structures al-low analysts for the first time to relate the se-mantics underlying the syntactic structure ofsentences to the discourse segments needed toaccount for continuity.
In order to adapt the rulesto other languages which may have differentsyntactic reflexes of semantic information, un-derstanding the semantic justification for thechoice of segments is important.
In addition, therules for discourse attachment for the first timemake clear the principles of discourse continuityfor ?coherent?
discourse.
In the future, we planto deepen our understanding of the rules for dis-course attachment and, in particular, begin toapply machine learning techniques to increaseour understanding of the complex interrelation-ship that obtain among them.While full implementation of the principlesof discourse organization outlined here are be-yond the state of the art in some respects (i.e.determining that a sentence is generic in Englishis non-trivial in many instances although ma-chine learning techniques might be useful in thisregard), we believe that the PALSUMM Systemdemonstrates the practicality of symbolic dis-course parsing using the U-LDM Model.
Theinfrastructure for this system has been success-fully applied to the task of summarizing docu-ments without a complex semantic component,extensive world knowledge and inference or asubjectively annotated corpus.
We believe thatthe U-LDM parsing methods discussed here canbe used for all other complex NLP tasks inwhich symbolic parsing is appropriate, especiallyRST trees, our basic algorithm is essentially simplerbecause RST trees are dependency trees over a largeset of different link types, whereas LDM trees areconstituent trees over effectively two basic nodetypes: subordinations and non-subordinations.those involving high value document collectionswhere precision is critical.
In addition, the struc-tures generated through symbolic parsing by thesystem will be invaluable for training statisticaland probabilistic systems.ReferencesNicholas Asher.
1993.
Reference to AbstractObjects in English: A Philosophical Seman-tics for Natural Language Metaphysics.
Klu-wer Academic Publishers.Lynn Carlson, Daniel Marcu, and Mary EllenOkurowski.
To appear.
Building a Discourse-Tagged Corpus in the Framework of Rhetori-cal Structure Theory.
In Current Directions inDiscourse and Dialogue, Jan van Kuppeveltand Ronnie Smith eds.
Kluwer AcademicPublishers.Katherine M. Forbes, Eleni Miltsakaki, RashmiPrasad, Anoop Sarkar, Aravind Joshi andBonnie Webber.
2003.
D-LTAG System -Discourse Parsing with a Lexicalized Tree-Adjoining Grammar, Journal of Language,Logic and Information, 12(3).Barbara Grosz and Candace Sidner.
1986.
Atten-tion, Intention and the Structure of Discourse.Computational Linguistics 12:175-204..Hans Kamp.
1981.
A theory of truth and seman-tic representation.?
In Formal Methods in theStudy of Language.
Jeroen A. G. Groenendijk,Theo Janssen, and Martin Stokhof (eds.).
Am-sterdam: Mathematisch Centrum, 277-322.Hans Kamp and Uwe Reyle.
1993.
From Dis-course to Logic: Introduction to Model-theoretic Semantics of Natural Language,Formal Logic and Discourse RepresentationTheory.
Kluwer Academic Publishers,Dordrecht, The Netherlands.William C. Mann and Sandra A. Thompson.1988.
Rhetorical Structure Theory: Towards aFunctional Theory of Text Organization.
Text8(3)243-281.Daniel Marcu.
1999.
Discourse trees are goodindicators of importance in text.
In Advancesin Automatic Text Summarization.
I. Mani andMark Maybury (Eds.
), 123-136, The MITPress.Daniel Marcu.
2000.
The Theory and Practice ofDiscourse Parsing and Summarization.
TheMIT Press.
Cambridge, MA.Daniel Marcu.
2003.
Automatic Abstracting,Encyclopedia of Library and Information Sci-ence, 245-256, 2003.Livia Polanyi.
1988.
A Formal Model of Dis-course Structure.
Journal of Pragmatics 12:601-639.Livia Polanyi and Martin van den Berg.
1996.Discourse Structure and Discourse Interpreta-tion.
In Proceedings of the 10th AmsterdamColloquium on Formal Semantics.
Universityof Amsterdam.Livia Polanyi and Remko Scha.
1984.
A syntac-tic approach to discourse semantics.
In Pro-ceedings of COLING 6.
Stanford, CA.
413-419.Dragomir Radev, Timothy Allison, Sasha Blair-Goldensohn, and John Blitzer, Arda ?elebi,Elliott Drabek, Wai Lam, Danyu Liu, HongQi, Horacio Saggion, Simone Teufel, MichaelTopper, Adam Winkel.
2003.
?The MEADMultidocument Summarizer?.http://www.summarization.com/mead/Radu Soricut and Daniel Marcu.
2003.
SentenceLevel Discourse Parsing using Syntactic andLexical Information.
In Proceedings ofHLT/NAACL?03, May 27-June 1, Edmonton,CanadaBonnie Webber.1991.
Structure and Ostension inthe Interpretation of discourse Deixis.
In Lan-guage and Cognitive Processes, 6(2):107-135.Bonnie Webber and Aravind Joshi.
1998.
An-choring a Lexicalized Tree-Adjoining Gram-mar for Discourse.
ACL/COLING Workshopon Discourse Relations and Discourse Mark-ers, Montreal, Canada.Alec Wilkinson.
2003.
Talk of the Town, Sep-tember 26, 2003, New YorkerAPPENDIX A. PALSUMM ExampleThe text below, taken from a recent issue of TheNew Yorker magazine (Alec Wilkinson, 2003)14,has been analyzed by hand using the segmenta-tion and discourse structure construction rulesgiven in Sections 3 and 4 above, resulting in theDiscourse Parse Tree given in Figure 1.
Thesummary of the text was automatically generatedusing the automatic summarization algorithmmentioned in Section 5 and a Genre Specific rulefor stories in which stories are treated as consist-ing of an Orientation, Narrative and Coda.
Thefirst specific, non-habitual eventive clause closesthe Orientation and begins the Narrative Section.The function of a Coda is to make the point of astory explicit.
This is often done, as in the pre-sent case, by using an anaphor that refers to anentire section of text (Webber, 1991)15.
(1) In the spring of 1947, (2)William Katavolosis the solitary occupant of the Ram?s Head Inn,(3) on Ram Island,(4) off eastern Long Island.
(5) Katavolos is twenty-three.
(6) His father hasleased the inn.
(7) Katavolos has returned fromthe war (8) and (9) wants a place (10) where hecan paint (11) and (12) be left alone.
(13) Thehotel is reached by a causeway from Shelter Is-land, (14) and the causeway sometimes floods,(15) leaving Katavolos as isolated as a light-house keeper.
(16) To amuse himself one evening,(17) he puts some water in a glass, (18) coversthe rim of the glass with waxed paper, (19) thenpresses the paper into the water (20) to create avacuum.
(21) He secures the paper to the glasswith a rubber band, (22) then turns the glassupside down.
(23) The water fills the vacuum,(24) preserving the dome (25) ?
it looks like thebottom of a wine bottle.
(26) Then he begins towonder (27) what would happen (28) if he re-peated the experiment on a larger scale.
(29) Afew days later, (30) he throws a tarpaulin over asection of Gardiners Bay (31) He weights downthe edges (32) so that no air can get beneath thetarpaulin, (33) then he swims underneath it.
(34)Using two oars, (35) he raises the center of thetarpaulin.
(36) The water fills the cavity (37) and14 Alec Wilkinson.
2003.
Talk of the Town, Sep-tember 26, 2003, New Yorker15 Bonnie Webber.1991.
Structure and Ostensionin the Interpretation of discourse Deixis.
In Lan-guage and Cognitive Processes, 6(2):107-135.he swims into it, (38) floating above sea level,(39) which, (40) he says later, (41) ?fascinatedthe hell out of me.?
(42) This is the beginning of(43) what Katavolos will call hydronics, (44) thepractice of making buildings from soft plasticforms (45) filled with water.
(46) In 1949, (47)Katavolos gives up painting (48) to design furni-ture (49) ?
his chairs are in the collections ofthe Museum of Modern Art, the MetropolitanMuseum, and the Louvre?
(50) and, (51) in1960, (52) he begins teaching architecture at thePratt Institute, (54) in Brooklyn, (55) where hewill become the co-director of the Center forExperimental Structures.
(56) In 1970, (57) in acourtyard at Pratt, (58) he builds the first hy-dronic structure (59) ?
a plastic dome filledwith water (60) and supported by a plastic cylin-der, (61) also filled with water.
(62) The plasticis like Saran Wrap, (63) only thicker.
(64) Eachyear after that, (65) he builds a new structure(66) He calls the structures (67) liquid villas.
(68) They consist of columns, arches, and vaults.
(69) The elements, (70) that is (71) of classicalarchitecture.Summary 152/363 = 42%In the spring of 1947, William Katavolos is thesolitary occupant of the Ram?s Head Inn,Katavolos is twenty-three.
To amuse himself oneevening, he puts some water in a glass, coversthe rim of the glass with waxed paper, thenpresses the paper into the water.
He secures thepaper to the glass with a rubber band, then turnsthe glass upside down.
A few days later, hethrows a tarpaulin over a section of GardinersBay.He weights down the edges then he swimsunderneath it.
Using two oars, he raises the cen-ter of the tarpaulin.
The water fills the cavity,This is the beginning of what Katavolos will callhydronics.
In 1949, Katavolos gives up paintingand in 1960 he begins teaching architecture atthe Pratt Institute.
In 1970, in a courtyard atPratt, he builds the first hydronic structure.
Eachyear after that, he builds a new structure.Figure 1.
Discourse Parse Tree of the New Yorker text.APPENDIX B.
System DiagramWordNetLookupFlatOntologyFilesDAMLEncodedOntologyHTMLdocumentXLE ServerXLEParserSegmentationWebserviceLexical Ontology ServerOntologyWebserviceLexicalOntologyLookupEnglishGrammarLiveTreeSentenceBreakerSentenceLevelDiscourseParserTextLevelDiscourseParserDiscoursetreeXMLXMLdocumentHybridSummarizerMEAD Statistical SummarizerWebserviceSentenceLevelDiscourseSegmenterSentenceLevelDiscourseGrammarTextLevelDiscourseGrammarLDMEngineTEXT XMLXMLSOAPFigure 2.
Diagram of the PALSUMM system, a symbolic summarization system currently being devel-oped at FX Palo Alto Laboratory.
