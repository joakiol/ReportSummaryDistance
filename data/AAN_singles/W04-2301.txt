Usability and Acceptability Studies of Conversational Virtual HumanTechnologyCurry Guinn1, Robert Hubal1, Geoffrey Frank1, Henry Schwetzke1, James Zimmer1,Sarah Backus1, Robin Deterding2, Michael Link1, Polly Armsby1, Rachel Caspar1,Laura Flicker1, Wendy Visscher1, Amanda Meehan1, Harvey Zelon11 RTI International, Research Triangle Park, NC2 University of Colorado Health Sciences Center, Denver, COAbstractAcceptance, accessibility, and usability datafrom a series of studies of a series of applica-tions suggest that most users readily accept re-sponsive virtual characters as validconversational partners.
By responsive virtualcharacters we mean full-body animated, con-versant, realistic characters with whom theuser interacts via natural language and whoexhibit emotional, social, gestural, and cogni-tive intelligence.
We have developed applica-tions for medical clinicians interviewingpediatric patients, field interviewers learningabout in-formed consent procedures, and tele-phone interviewers seeking to obtain coopera-tion from respondents on federally-fundedsurveys.
Usage data from informational kiosksusing the same underlying technology (e.g., atconference exhibits) provide additional cor-roboration.
Our evidence suggests the tech-nology is both sufficient to actively engageusers and appropriate for consideration of usein training, assessment, and marketing envi-ronments.1 IntroductionAn ?accessible?
user interface is one that is easy to learnand easy to use, and can result in measurable goals suchas decreased learning time and greater user satisfaction(i.e., acceptance) [28].
Characteristics of easy to learnand easy to use interfaces have been de-scribed as hav-ing navigational and visual consistency, clear communi-cation between the user and application, appropriaterepresentations, few and non-catastrophic errors, tasksupport and feedback, and user control [15,20,21,28].As part of our Technology Assisted Learning (TAL)initiative, we have been particularly interested in howaccessible responsive virtual human technology(RVHT) applications are.
Usability testing, commonlyconducted for commercial software to ensure that itmeets the needs of the end user, is likewise vital to cre-ating effective training and assessment software em-ploying innovative technologies.
This paper presentsfindings from a series of studies investigating how usersaccept and evaluate RVHT applications.1.1 Background on RVHT and TALSince approximately 1996, we have worked on a seriesof PC-based applications in which the user interactswith responsive virtual characters.
Applications haveranged from trauma patient assessment [13] to learningtank maintenance diagnostic skills [9] to gaining skillsin avoiding non-response during field interviews [3].
Inthese applications, which we collectively categorize asinvolving RVHT, the PC simulates a person?s behaviorin response to user input.
Users interact with the virtualcharacters via voice, mouse, menu, and/or keyboard.We are certainly not alone in developing training, as-sessment, marketing, and other RVHT applications (see,e.g., [2,4,7,16,17,19,22,24,25]), but the breadth acrossdo-mains and combination of technologies is unusual.The RVHT applications are representative of thosedeveloped in our TAL division.
We define TAL as?proactively applying the benefits of technology to helppeople train more safely, learn better, retain skillslonger, and achieve proficiency less expensively?.
Wedevelop TAL applications for jobs requiring compli-cated knowledge and skills, complex or expensiveequipment or work material, a high cost of on-the-jobtraining or failure on the job, jobs where safety or spa-tial awareness is essential, and for large studentthroughput requirements [6,12].Practicing skills in a safe and supportive environ-ment allows the student to learn flexible approaches.Flexibility is critical for interaction skills [8] and forperforming well under time constraint, information-poor, and other difficult conditions [4,14].
The consis-tency that is gained by repeating this practice in virtualenvironments leads directly to good decisions on the job[24].
By practicing skills in safe, computer-generatedsettings, students have the opportunity through repeti-tion to develop practical experience and skills whichwould otherwise be difficult to acquire.
Practice alsoleads to increased confidence prior to the first real on-the-job experience.1.2 RVHT ArchitectureWe have developed a PC-based architecture, Avatalk,that enables users to engage in unscripted conversationswith virtual humans and see and hear their realistic re-sponses [10].
Among the components that underlie thearchitecture are a Language Processor and a BehaviorEngine.
The Language Processor accepts spoken inputand maps this input to an under-lying semantic repre-sentation, and then functions in reverse, mapping se-mantic representations to gestural and speech output.Our applications variously use spoken natural languageinteraction [9], text-based inter-action, and menu-basedinteraction.
The Behavior Engine maps Language Proc-essor output and other environmental stimuli to virtualhuman behaviors.
These behaviors include decision-making and problem solving, performing actions in thevirtual world, and spoken dialog.
The Behavior Enginealso controls the dynamic loading of contexts andknowledge for use by the Language Processor.
The vir-tual characters are rendered via a Visualization Enginethat performs gesture, movement, and speech actions,through morphing of vertices of a 3D model and playingof key-framed animation files (largely based on motioncapture data).
Physical interaction with the virtual char-acter (e.g., using medical instruments) is realized viaobject-based and instrument-specific selection maps[29].
These interactions are controlled by both the Be-havior Engine and Visualization Engine.We keep track of domain knowledge via state vari-able settings and also by taking advantage of the plan-ning structure inherent in our architecture [11].
Ourvirtual humans reason about social roles and conven-tions (what can be stated or asked at any point in thedialog) [23] and grammar definitions (how it gets statedor asked).
The architecture was designed to al-low ap-plication creators flexibility in assigning general anddomain-specific knowledge.
Hence, our virtual humansdiscuss relevant concerns or excuses based on specificsetup variables indicating knowledge level and initialemotional state.
Our personality mod-els and emotionreasoning are based on well-accepted theories that guiderealistic emotional behavior [1,4,23,24,26].
After userinput, we update emotional state based on lexical, syn-tactic, and semantic analyses [11].1.3 Overview of PaperWe present findings from studies of four differentapplications.
The applications are, in order of presenta-tion, a virtual pediatric standardized patient, a trainer forpracticing informed consent procedures, a telephonesurveys interview trainer, and two implementations of atradeshow booth marketing product.
For each we brieflydescribe the application, the participants, and the results,concentrating on results that get at accessibility, en-gagement, and usability.
We tie the results together in alessons learned section.2 Virtual Pediatric PatientTraining and assessment in pediatrics is complicated bythe poor reliability of children to behave in a consistentmanner.
Consequently, curriculum is difficult to de-velop, performance assessment is restricted, and prac-tice opportunities are limited.
Our goals using RVHThave been to develop specific interactive training ses-sions using virtual pediatric characters and to explorerelated educational issues [10].Figure 1.
Virtual Pediatric PatientOne educational issue in pediatric medicine is in-struction.
Medical students rotating through pediatricshave limited exposure to children and are given limitedone-on-one faculty observation time, hence the curricu-lar material is mostly passive, while on-the-job learninginvolves variable experiences with behaviors or prob-lems and dispersed learners.
Another educational needin pediatric medicine is associated with assessment,since there is no reliable or valid authentic assessmentin young children (it is currently text-based or multime-dia videos) as is possible with standardized patients foradults, and since interaction skills with children may notbe valued by the student.Our use of virtual pediatric patients follows modelsof experiential learning, where abstract conceptualiza-tion leads to active engagement and experimentation,which leads to concrete experience, which leads to re-flective observation, which leads back to the beginningof the cycle [15,21].
By adding virtual characters, weare adding experiential learning to the traditional class-room, discussions, and rounds.Our work supports training and assessment not onlyof verbal interaction skills, but also of medical diagnos-tic skills, dealing with the spectrum of behavioral re-sponses, and other types of high-level problem solving.2.1 MethodsThree specific interactive pediatric scenarios have beendeveloped to date in our virtual pediatric standardizedpatient (VPSP) application.
In one scenario, the clini-cian is tasked with obtaining an ear exam in a veryyoung girl.
The girl may be helpful if she is healthy butwhiny if she has an ear infection.
In another scenario,the clinician is asked to examine the lungs of a pre-teenboy.
In the last scenario, the clinician must obtain ahigh-risk behavior history from a teenage girl.Educational issues that we are addressing includedefining ?
and identifying ?
pediatric interactive strate-gies, program validity, scoring performance, and pro-viding feedback.
Our goal is to provide information fora ?gold-standard?
setting language acquisition to im-prove the robust nature of the interaction, and to addressface, content, and construct validity.
We hypothesizethat expert and novice users will provide valuable de-velopment information about language and strategies inthese scenarios, and the differences will exist basedupon expertise with children and technology experience.2.2 ResultsInteractive pediatric scenarios were created and shownto content and educational experts.
The first rounds offeedback from experts, on the girl and boy scenarios,came at exhibits sessions at the Association of Ameri-can Medical Colleges annual meeting in November2002 and the Medicine Meets Virtual Reality confer-ence in January 2003.
From comments at these sessionswe revised the scenarios and added the adolescent sce-nario.
The latest round of feedback, and the results de-scribed here, came from the Council on Medical StudentEducation in Pediatrics (COMSEP) annual meeting inApril 2003.Fourteen attendees at the COMSEP meeting wererecruited to use the VPSP application.
The attendeeswere first given a questionnaire asking about their ex-perience with completing ear exams, lung exams, andadolescent social history, and also about their comput-ing experience.
They were then given brief instructionson how to use the application, told to choose whicheverof the scenarios they wanted, and handed headphones toavoid distraction.
Finally, they were given a question-naire asking their perceptions of the realism of the ap-plication in comparison to clinical experience.In a way, this was the toughest group of all we?vetested.
These participants were true experts, unaware ofthe technology (until a debriefing at the end of eachsession), and presented with an application prototype.Given this rationalization, the data are acceptable.
Onaverage, these participants rated the realism of the re-sponse time and the realism of the objections, concerns,and questions posed by the virtual characters as ?some-what?
realistic.
They rated the realism of the overallconversation as a little better than ?not very?
realistic.However, somewhat surprisingly, when asked to com-pare the simulated clinical experience with real clinicalexperience, the participants rated the comparison assomewhat challenging, that is, the comparison is rea-sonable.
Four of the participants even found the simu-lated experience ?moderately?
or ?extremely?challenging.
Analysis of the participants?
log filesshows they spent an average of almost 4 1/2 minutes inthe scenarios, taking eight conversational turns, andcollectively covering 32 topics (of a possible 130 topicsacross all scenarios, and with no prompting).
The par-ticipants were observed to take the cases seriously, ask-ing strategic questions to get the virtual character tocooperate, and becoming frustrated when their questionswere misinterpreted.
(We are pleased by frustration, asit implies engagement, though anxious, too, to make theapplication work better.)
We take these data as encour-aging, but fully understand the need to revise in depththe language and behavior of the virtual characters tosatisfy acceptance criteria.3 Practice on Informed Consent3.1 MethodsUnder grant funds to enhance our IRB program, wecreated a virtual reality simulation for teaching properinformed consent procedures.
In the application, a po-tential survey respondent poses questions regarding thesurvey, the sponsor, confidentiality, privacy, compensa-tion, and contact information [27].In November 2003, we presented the trainer to agroup of five experienced telephone or field interview-ers who were being trained for a study intended to betterunderstand the health effects of exposure to smoke,dust, and debris from the collapse of the World TradeCenter.
We observed the participants and also had them,after completing the interactions, fill out a short ques-tionnaire on their familiarity with computers and theirimpressions of the application.3.2 ResultsThe application forced the respondents to touch on allaspects of informed consent before finishing.
The onlyway an interaction could be cut short was if the partici-pant replied incorrectly to a question (e.g., giving thewrong sponsor name, or indicating that participationwas mandatory rather than voluntary).
Participants in-teracted no fewer than three times with the virtual char-acter and up to six times.Figure 2.
Informed Consent TrainingThe results were generally positive, particularly inthe subjects?
assessment of usability and enjoyment.The realism of the character was consistently rated bythe participants as moderately realistic (average of 5.2on a 7 point scale), a decent rating given the virtualcharacter?s relatively few body movements and facialgestures.
Ease of use (5.8), enjoyment (5.6), and effec-tiveness (5.4) were all rated moderately to very easy,enjoyable, or effective.
An observer also rated the levelof engagement of the interaction.
Engagement, verbali-zation, and information seeking were all moderately orhighly demonstrated.
Participants were judged eitherrelaxed or amused by the interaction, they responded ina moderate amount of time, and they appeared to com-prehend what was being asked.
As would be expected,they were also judged to find the interaction not at allprovocative and needed very little negotiation.4 Telephone Survey InterviewerOne of the most difficult skills for a telephone in-terviewer to learn is gaining cooperation from samplemembers and avoiding refusals.
In telephone inter-viewing in particular, the first half-minute on the tele-phone with a sample member is crucial.
Samplemembers almost automatically turn to common phrasesto avoid taking part in surveys: ?How long will thistake??
?How was I selected??
?I don?t do surveys.?
?Idon?t have time.?
?I?m just not interested.?
?What is thesurvey about??
Non-response research suggests that thebest approach to obtaining participa-tion is for theinterviewer to immediately reply with an appropriate,informative, tailored response [2,9].We tested an RVHT application designed to simu-late the first 30-60 seconds of a telephone interview[21].
Interviewers begin with an introduction and thenneed to respond to a series of objections or questionsraised by the virtual respondent.
Ultimately, the virtualcharacter ends the conversation by either granting theinterview or hanging-up the telephone.
The emotionalstate of the virtual respondent varies from scenario toscenario.
A total of six basic objections were recordedin four different tones of voice for both a male and fe-male virtual respondent.Figure 3.
Telephone Survey User Interface4.1 MethodsThe assessment provided here of the interviewer train-ing module is based on researcher/instructor observa-tions, and user debriefings in the form of aquestionnaire.
Empirical data were collected on users?observed ability to interact with the application as wellas their perception of the interaction.
The training appli-cation was tested with a group of 48 novice telephoneinterviewers during Spring 2002.To evaluate the accessibility of the application wefocused on the users?
understanding of the application?sbasic features, their ability to complete each task, andcapabilities shown by different users (e.g., based onethnicity, job level, and education level.
To evaluateacceptance of the application by the trainees, we de-briefed participants using a structured questionnaire andmoderator-facilitated focus groups to gauge reactionsand engagement in the application.
We were interestedin the virtual humans?
realism, speed and accuracy ofthe speech recognition, and detection of changes in theemotive states of the virtual human.Finally, each training session was observed by eitherthe researchers or training instructors, who made notesof their observations.
These observations are included aspart of the analysis.4.2 ResultsEase of Use: Users of the RVHT application found itvery accessible, with 84 percent indicating the softwarewas either extremely easy or very easy to use (52% ex-tremely, 31% very, 13% somewhat, 4% not too, 0% notat all).
Only eight (17%) of the 48 trainees indicated thatthey required additional assistance to use the trainingsoftware (after the initial training received by all train-ees).Realism of the Training Environment: The prom-ise of RVHT-based training tools is that they can simu-late a real environment, thereby allowing traineesrepetitive practice in conditions that are as close as pos-sible to what they will encounter on the job.
For thisparticular application, the virtual respondent needed tomirror the behaviors and emotions of real respondentsencountered when doing live interviewing.
This meansdelivering an array of objections to the trainees in dif-ferent tones of speech and emotional levels in a fast-paced manner.
Interviewers were asked a series of ques-tions to try to assess how well they accepted the virtualenvironment as a substitute for real work conditions.The answer is somewhat mixed.
In general, traineesdid not find the virtual environment to be realistic andthey cited two primary reasons: the slowness of the re-sponse of the virtual respondent and the limited numberof different objections/questions offered by the virtualrespondent.
They did, however, find the responses thatwere offered to be realistic and stated that they coulddetect and respond to changes in tone and emotionalcues offered by the virtual respondents.
A majority ofthe trainees also indicated that they felt the sessionshelped them to improve their skills needed at the outsetof an interview either ?somewhat?
or ?a lot?.When asked how realistic they found the overallconversation with the virtual respondent, 17 percent ofparticipants said they thought it was ?extremely?
or?very?
realistic, and 44 percent said it was ?somewhat?realistic.
Slowness of the virtual respondents in replying(due to the lag caused by the speech recognizer as itinterpreted the interviewer?s responses and determinedthe next script to launch) was the primary problem citedby interviewers.
Over three-quarters (77%) of the usersfelt the response time was too slow (4% felt it was toofast and 19% indicated the speed was just right).The trainees were, however, more positive whenevaluating the realism of the objections and questionsoffered by the virtual respondent.
A plurality (48%)indicated that the content of what was said was either?extremely?
or ?very?
realistic, with 40 percent sayingit was ?somewhat?
realistic.
They also felt it was rela-tively easy to determine the emotional state of the vir-tual respondent based on the tone of voice they heard(23% ?extremely?
easy, 44% ?very?
easy, 29% ?some-what?
easy, and 4% ?not too?
easy).
Likewise, the con-tent of the speech used by the virtual character was alsoa good cue to trainees as to the virtual human?s emo-tional state (8% ?extremely?
easy to tell, 54% ?very?easy, 27% ?somewhat?
easy, 10% ?not too?
easy).Being able to recognize changes in the emotionalstate of the virtual respondent changed how the inter-viewer approached the situation.
Nearly 60 percent indi-cated that they behaved differently in the practicescenario based on the tone of the virtual respondent?svoice.
Thus, the content of the objections raised by thevirtual respondent and the emotional behavior of thevirtual human were generally accepted by the traineesand caused them to react differently within the varioustraining scenarios.
It appears, however, that while theinterviewers do recognize and react to emotional cues,they do not necessarily process these as being very dis-tinct.
They focus more on the actual content of the ar-gument (regardless of the tone of voice or gender) whenconsidering how diverse the scenarios offered are.Enjoyment and Reuse: An effective training tool isalso one that trainees should enjoy using, would useagain, and recommend to others.
Approximately two-thirds (65%) of the users said that they found using theRVHT software to be fun and enjoyable.
Nearly three-quarters (73%) said they would like to use the softwareagain.
In addition, 83 percent said they would recom-mend the program as a training tool for other interview-ers.
In open-ended responses, a number of interviewersindicated that it would be a very good practice vehiclefor new or less experienced interviewers.5 ExhibitAR Applications5.1 MethodsUsing earlier versions of the same underlying technol-ogy we created a product called ExhibitAR that waspositioned as a virtual tradeshow attendant.
It was putinto operation as a kiosk, drawing attention to the booth,augmenting the sales and marketing staff, and providingengaging dialog with visitors regarding the companyand company products.
We report on user data collectedat three particular venues, the Exhibitor Show held inFebruary 1999, the Space Congress held in April 1999,and the American Society for Training and Develop-ment (ASTD) International Conference & Expositionheld in May 1999.5.2 ResultsThe ExhibitAR product did attract visitors to the boothsand answered visitors?
questions, a definite advantageon the competitive tradeshow floor.
At the Space Con-gress show, in front of a reasonably technical audienceover four days, the application attracted 335 visitors,who conversed with the virtual characters an average of61.4 seconds with five conversational turns.
At ASTD,with less technical attendees, over three days, 197 visi-tors spoke with the virtual characters for an average of28.4 seconds and 2.6 conversational turns.Figure 4.
Virtual Tradeshow AttendantWe analyzed not only the number of visitors andtheir conversations, but also the content of the conversa-tions.
For ASTD, every single one of the 63 topics ofconversation was covered at least once.
The average pertopic was almost nine occurrences (i.e., nine differentvisitors asked about the topic).
For Space Congress,again every topic was covered, the average number oftimes per topic for the 39 topics was 35 occurrences.The most common topics for both applications were agreeting, asking about the company and its associates,asking what to do or say, asking how the technologyworked, and asking the current date or time, but topicsspecific to each application were also discussed.The Exhibitor data are less telling, but this was theshow at which ExhibitAR was introduced, and this wasthe only venue where the visitor was not at allprompted.
The application attracted 45 visitors over2 1/2 days, each visitor averaging 2.5 turns and 21.4seconds.
Though each of the 25 topics was covered atleast once, the only topic that was covered considerablymore often than any other was a request for assistance.
(This led us to devise a prompting feature.
)Visitor data from RVHT marketing applications arenot conclusive of usability or acceptability, but sugges-tive.
Even at the time these data were collected (fiveyears ago), less technical users were sufficiently en-gaged to converse with the virtual characters for justunder half a minute, and more technical users for justover a minute.
Given prompting, the users covered therange of topics designed into the applications.
It is im-portant that these users had never before seen the appli-cations, had no training or practice time, had to learn touse the applications at that moment, yet stuck with theconversation for a significant period of time.It is only anecdotal data, but RVHT continues to at-tract visitors to exhibit booths.
The various applicationsdescribed in earlier sections, and others, have beenshown since 1999 at least a dozen times to audiencesvarying from educators to medical practitioners to pub-lic health workers to military service personnel.
Visitorsare increasingly less surprised (skeptical?)
to encountervirtual characters, and more impressed with the state ofthe art.
They appear willing to accept virtual charactersas sensible for training, assessment, and marketing uses.6 Conclusions and Lessons LearnedIn this paper we describe usability and acceptance dataderived from a number of studies using a number ofdifferent RVHT applications.
No data suggest that ourapplications are completely accessible yet to these users,but the data in aggregate suggest we are moving in theright direction.The different studies involved various user groups,from experts (medical clinicians) to novices (field andtelephone survey interviewers) to ?common folk?
(ex-hibit visitors) in greatly different domains.
A commonfinding was for our participants to suggest additionalpotential audiences, also ranging from novice to expert.Further, the majority of participants said they enjoyedusing the applications ?
and/or were observed to be en-gaged with the virtual characters ?
despite technicalobstacles, prototype-stage content, and conspicuouspresence of the investigators.Some specific lessons learned include:?
It is critical in applications to be able to detectand respond appropriately to ?bad?
or inappro-priate input.
In all our applications, users (oftenbut not always intentionally) spoke utterancesthat were outside the range of what was expectedin the context of the dialog.
This occurred mostfrequently in the tradeshow exhibit applicationwhere users would try to test the limits of thesystem.
But we even found that in the trainingapplications that users would often express frus-tration by cursing or otherwise verbally mistreat-ing the virtual character.?
Without explicit prompting by the virtual charac-ter, users often seemed lost as to what to saynext.
We found that explicit statements or ques-tions by the virtual character helped to supply theuser with the necessary context.
This also helpedto prune the language processing space.
.
In theExhibitAR domain, a subset of possible relevantquestions was always present on the screen.?
Because of shortcomings in speech recognitiontechnology, we found that typed input was oftenneeded to overcome the limitations of largegrammars.
This was particularly true in the moreopen-ended pediatric trainer.
We also foundtyped input to be invaluable in developmentstage even in applications that were ultimatelygoing to be speech-driven.
The typed inputs indevelopment helped us to derive grammars thatwe could later use to improve the speech recog-nizer.?
Our greatest difficulties in understanding the sys-tem occurred when the user replied with verycomplex compound sentences, multiple sentence,and even paragraph long utterances.
This phe-nomenon led us to set user expectations in thetraining environment prior to their using the sys-tem.?
Anecdotally we found that pre-recorded speechwas much more acceptable than any currentlyavailable speech synthesizer.
This effect seemedto be less noticeable the longer the user spokewith the system.
We would like to conduct astudy comparing the use of the two technologies.?
Ultimately, because of the limitations in lan-guage understanding, the user would adapt toenvironment, adjusting the manner in which theyspoke.We are encouraged by results so far, but feel it isimportant to continue to investigate more robust andeffective RVHT models and more efficient means ofcreating the models, to better understand user prefer-ences and acceptance of RVHT, and to determine howbest to use RVHT in combination with other approachesto produce cost-effective training, assessment, and otherapplications.
We propose several areas of active re-search:?
Usability and acceptability studies across differ-ent populations.
Are there differences in accep-tance of virtual characters across boundaries ofage, gender, education level, and cultural di-vides??
Usability and acceptability studies with variedinput modes.
What are the tradeoffs between us-ing a typed natural language interface versus aspoken interface?
We found that a typed inter-face improved the computer's ability to compre-hend the user which leads to more cohesivedialog.
On the other hand, a typed interface re-duces the naturalness of the dialog, the believ-ability of the character, and the usability of thesystem.?
Usability and acceptability studies with varieddegrees of visual realism.
How realistic do vir-tual characters have to be in order to receive highratings of acceptability by users?
What is thecontrast in user impressions between video of ac-tual humans versus more cartoon-like animatedcharacters??
Usability and acceptability studies with multi-modal input.
Currently our systems make no at-tempt to use the user's vocal affect, facialexpressions, eye movement, body gesture, orother physiological input (such as galvanic skinresponse) in interpreting the user's emotionalstate and intentions.
We would like to introducethese elements into our systems to assesswhether such input can create more realisticcharacters.AcknowledgementsThe studies described here were performed under awards #290-00-0021 from the Agency for Healthcare Research andQuality, # 1-S07-RR18257-01 from the National Institutes ofHealth, and # R9898-002 from the Research Triangle Institute.Preparation of this paper was supported under award # EIA-0121211 from the National Science Foundation.
Points ofview in this document are those of the authors, and do notnecessarily represent the official position of any of the above-listed agencies.ReferencesAndr?, E., Klesen, M., Gebhard, P., Allen, S., & Rist, T.(2000).
Exploiting Models of Personality and Emo-tions to Control the Behavior of Animated InterfaceAgents.
Proceedings of the International Conferenceon Autonomous Agents (pp.
3-7).
Barcelona, Spain.Andr?, E., Rist, T., & M?ller, J.
(1999).
Employing AIMethods to Control the Behavior of Animated Inter-face Agents.
International Journal of Applied Artifi-cial Intelligence, 13 (4-5), 415-448.Camburn, D.P., Gunther-Mohr, C., & Lessler, J.T.(1999).
Developing New Models of InterviewerTraining.
Proceedings of the International Confer-ence on Survey Nonresponse.
Portland, OR.Dahlb?ck, N., J?nsson, A., & Ahrenberg, L. (1993).Wizard of Oz Studies ?
Why and How.
Knowledge-based Systems, 6(4), 258-266.Frank, G.A., Guinn, C.I., Hubal, R.C., Stanford, M.A.,Pope, P., & Lamm-Weisel, D. (2002).
JUST-TALK:An Application of Responsive Virtual Human Tech-nology.
Proceedings of the Interservice/IndustryTraining, Simulation and Education Conference.
Or-lando, FL.Frank, G.A., Helms, R., & Voor, D. (2000).
Determin-ing the Right Mix of Live, Virtual, and ConstructiveTraining, Proceedings of the Interservice/IndustryTraining Systems and Education Conference.
Or-lando, FL.Graesser, A., Wiemer-Hastings, K., Wiemer-Hastings,P., Kreuz, R., & the Tutoring Research Group(2000).
AutoTutor: A simulation of a human tutor.Journal of Cognitive Systems Research, 1, 35-51.Groves, R., & Couper, M. (1998).
Nonresponse inHousehold Interview Surveys.
New York, NY: JohnWiley & Sons, Inc.Guinn, C.I., & Montoya, R.J. (1998).
Natural LanguageProcessing in Virtual Reality.
Modern Simulation &Training, 6, 44-45.Hubal, R.C., Deterding, R.R., Frank, G.A., Schwetzke,H.F., & Kizakevich, P.N.
(2003).
Lessons Learned inModeling Pediatric Patients.
In J.D.
Westwood, H.M.Hoffman, G.T.
Mogel, R. Phillips, R.A. Robb, & D.Stredney (Eds.)
NextMed: Health Horizon (pp.
127-130).
Amsterdam, Holland: IOS Press.Hubal, R.C., Frank, G.A., & Guinn, C.I.
(2003).
Les-sons Learned in Modeling Schizophrenic and De-pressed Responsive Virtual Humans for Training.Proceedings of the Intelligent User Interface Confer-ence.
Miami, FL.Hubal, R.C., & Helms, R.F.
(1998).
Advanced LearningEnvironments.
Modern Simulation & Training, 5, 40-45.Kizakevich, P.N., McCartney, M.L., Nissman, D.B.,Starko, K., & Smith, N.T.
(1998).
Virtual MedicalTrainer: Patient Assessment and Trauma Care Simu-lator.
In J.D.
Westwood, H.M. Hoffman, D. Stred-ney, & S.J.
Weghorst (Eds.
), Art, Science,Technology: Healthcare (R)evolution (pp.
309-315).Amsterdam, Holland: IOS Press.Klein, G. (1998).
Sources of Power.
Cambridge, MA:MIT Press.Kolb, D.A.
(1984).
Experiential Learning.
EnglewoodCliffs, NJ: Prentice Hall.Lester, J., Converse, S., Kahler, S., Barlow, S., Stone,B., & Bhogal, R. (1997).
The Persona Effect: Affec-tive Impact of Animated Pedagogical Agents.
Pro-ceedings of the Human Factors in ComputingSystems Conference, (pp.
359-366).
New York, NY:ACM Press.Lindheim, R., & Swartout, W. (2001).
Forging a NewSimulation Technology at the ICT.
Computer, 34 (1),72-79.Link, M., Armsby, P.P., Hubal, R., & Guinn, C.I.(2002).
A Test of Responsive Virtual Human Tech-nology as an Interviewer Skills Training Tool.
Pro-ceedings of the American Statistical Association,Survey Methodology Section.
Alexandria, VA:American Statistical Association.Lundeberg, M., & Beskow, J.
(1999).
Developing a 3D-Agent for the August Dialogue System.
Proceedingsof the Auditory-Visual Speech Processing Confer-ence.
Santa Cruz, CA.Nielsen, J.
(1993).
Usability Engineering.
Boston: Aca-demic Press.Norman, D.A.
(1993).
Things That Make Us Smart.Reading, MA: Addison-Wesley.Olsen, D.E.
(2001).
The Simulation of a Human forInterpersonal Skill Training.
Proceedings of the Of-fice of National Drug Control Policy InternationalTechnology Symposium.
San Diego, CA.Ortony, A., Clore, G.L., & Collins, A.
(1988).
The Cog-nitive Structure of Emotions.
Cambridge, England:Cambridge University Press.Rickel, J., & Johnson, W.L.
(1999).
Animated Agentsfor Procedural Training in Virtual Reality: Percep-tion, Cognition, and Motor Control.
Applied Artifi-cial Intelligence, 13, 343-382.Rousseau, D., & Hayes-Roth, B.
(1997).
Improvisa-tional Synthetic Actors with Flexible Personalities.KSL Report #97-10, Stanford University..Russell, J.A.
(1997).
How Shall an Emotion Be Called?In R. Plutchik & H.R.
Conte (Eds.
), CircumplexModels of Personality and Emotions (pp.
205-220).Washington, DC: American Psychological Associa-tion.Sugarman, J., McCrory, D.C., Powell, D., Krasny, A.,Adams, B., Ball, E., & Cassell, C. (1999).
EmpiricalResearch on Informed Consent: An Annotated Bibli-ography.
Hastings Center Report.
January-February1999; Supplement: S1-S42.Weiss, E. (1993).
Making Computers People-Literate.San Francisco: Jossey-Bass.Zimmer, J., Kizakevich, P., Heneghan, J., Schwetzke,H., & Duncan, S. (2003).
The Technology BehindFull Body 3D Patients.
Poster presented at the Medi-cine Meets Virtual Reality Conference.
NewportBeach, CA.
Available athttp://www.rvht.info/publications.cfm.
