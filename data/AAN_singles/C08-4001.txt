Coling2008:EducationalNaturalLanguageProcessing?TutorialnotesManchester,August2008Educational Natural Language ProcessingTutorial at COLING?08Iryna Gurevych, Delphine BernhardEducational Natural Language Processing17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  2/206Iryna Gurevych Delphine BernhardPresenters17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  3/206Technische Universit?t Darmstadt17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  4/206Quality ineLearningAmbient learning// University 2020Serious GamesE-DidacticsUbiquitous Knowledge ProcessingSemantics-based know-ledge acquis.CRE?E-Learning?Graduate School Research UnitResearch UnitCenter of Research Excellence eLearning 2.0117.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  5/206UKP Lab Research TopicsText MiningNatural Language Processing / SemanticsSemantic Information ManagementWeb 2.0 \ ServiceseLearning 2.0User-generated DiscourseDarmstadt Knowledge Processing Repository WikiMining17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  6/206Profession 3Profession 1Profession 2Profession ...QueryProfession ...Profession ...Profession ...Semantic Information Retrieval (SIR)AQUASentiment Analysis in User Generated Discourse (SentAL)Internet der Dienste (THESEUS) ?Semantic Question Answer-ing for eLearning 2.0 (QA-EL)Self-Improving WikisWikis 2.0Wiki-Mining NLPWikiDarmstadt Knowledge Processing RepositoryData exportProject specific analysisSemantic analysisSyntactic analysisMorphological analysisLinguistic preprocessingData importResearch Projects and eLearning17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  7/206Introduction: eLearning and NLPAutomatic generation of exercisesAssessment of learner generated discourse  Reading and writing assistanceTutoring systemsWeb 2.0 and computer supported collaborative learningExample e-NLP application: electronic career guidanceOutline17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  8/206Educational Natural Language ProcessingeLearning NLPComputer-assisted learning / instruction Analysis and use of language by machinese-NLP217.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  9/206Field of research exploring the use of NLP techniques in educational contextsDefinition17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  10/206Web 2.0 & eLearning 2.017.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  11/206?
Creation of large repositories with user generated discourse and user generated metadata?
Using repositories to create structured knowledge bases to improve NLP?
Repositories need advanced information management and NLP to be efficiently accessedSome Observations17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  12/206Content creationSemantic knowledge Wikis,Blogs,...NLP eLearning2.0Intuitive accessFeedback Loop: NLP & eLearning 2.0317.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  13/206Introduction: eLearning and NLPAutomatic generation of exercisesAssessment of learner generated discourse  Reading and writing assistanceTutoring systemsWeb 2.0 and computer supported collaborative learningExample e-NLP application: electronic career guidanceOutline17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  14/206Computer-based Testing?
Definition: All forms of assessment delivered with the help of computers?
Also called: ?
Computer Assisted/Aided Assessment (CAA)?
Adequate question types for CAA (McKenna & Bull, 1999):?
Multiple choice questions (MCQs)?
True/False questions?
Matching questions?
Ranking questions?
Sequencing questions?
etc.17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  15/206Question Types?
Objective test items?
constrained answer, to be selected among a set of alternatives?
short answer (word or phrase) in response to a question ?
objective and impartial scoring?
Examples:?
Fill-in-the-blanks questions?
Multiple-choice questions?
Matching questions?
Subjective test items?
original answer?
variable length?
biased scoring?
Examples:?
Short-answer essays?
Extended-response essays17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  16/206Role of Test Items in Learning?
Summative assessment?
"Assessment of learning"?
Measuring student achievement?
Formative assessment?
"Assessment for learning"?
Active learning: encourage learners to practice and apply newly acquired knowledge by answering test items417.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  17/206NLP for CAA?
Generation of questions and exercises?Writing test questions, especially objective test items, is an extremely difficult and time consuming task for teachers?
Use of NLP to automatically generate objective test items, esp.
for language learning?
Assessment and evaluation of answers to subjective test items?
Use of NLP to automatically:?
Diagnose errors in short-answer essays?
Grade essays17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  18/206Automatic Generation of Test Items?
Source data?
Corpora: texts should be chosen according to?
the learner model (level, mastered vocabulary)?
the instructor model (target language, word category)?
Lexical semantic resources, e.g.
WordNet?
Tools?
Tokeniser and sentence splitter?
Lemmatiser?
Conjugation and declension tools?
POS tagger?
Parser and chunker17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  19/206Multiple-Choice Questions (MCQ)?
Choose the correct answer among a set of possible answers?
Example (Mitkov et al, 2006)Who was voted the best international footballer for 2004?
(a) Henry(b) Beckham(c) Ronaldinho(d) Ronaldo?
Usually 3 to 5 alternative answersStemKeyDistractors /Distracters17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  20/206Distractors?
Distractors (also distracters) are the incorrect answers presented as a choice in a multiple-choice test?
Generation of "good" distractors (McKenna & Bull, 1999; Duvall)?
Ensure that there is only one correct response for single response MCQ?
The key should not always occur at the same position in the list of answers?
Distractors should be grammatically parallel with each other and approximately equal in length?
Distractors should be plausible and attractive?
However, distractors should not be too close to the correct answer and risk confusing students517.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  21/206Automatic Generation of MCQs1.
Selection of the key?
Unknown words that appear in a reading (Heilman & Eskenazi, 2007)?
Domain-specific terms:?
Automatically extracted (Mitkov et al, 2006)?
Present in a thesaurus , e.g.
UMLS (Karamanis et al, 2006)2.
Generation of the stem?
Constrained patterns (Heilman & Eskenazi, 2007):Which set of words are most related in meaning to "reject"??
Transformation of source clauses to stems, using transformation and agreement rules (Mitkov et al, 2006):Transitive verbs require objects ?
Which kind of verbs require objects?17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  22/206Automatic Generation of MCQs3.
Generation of the distractors   ?WordNet concepts which are semantically close to the key , e.g.
hypernyms and co-hyponyms (Mitkov et al, 2006; Karamanis et al, 2006)Stem: "Which part of speech serves as the most central element in a clause?
"Key: "verb", Distractors: "noun", "adjective", "preposition"?
Thesaurus-based and distributional similarity measures (Mitkov et al, 2006)?
Other NPs with the same head as the key, retrieved from a corpus (Mitkov et al, 2006)Key: "verb", Distractors: "modal verbs", "phrasal verbs", "active verbs"17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  23/206Fill-in-the-Blank Questions (FIB)?
Also called cloze test?
Technique which dates from 1953 (Wilson Taylor)?
Consists of a portion of text with certain words removed ?
The student is asked to "fill in the blanks"?
Objective cloze items = multiple-choice cloze items, i.e.
students are given a list of words to use in a cloze?
Subjective cloze items = students can choose the words?
Challenges:?
Phrase the question so that only one correct answer is possible?
Spelling errors in objective cloze items17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  24/206Fill-in-the-Blank Examples?
Blank = preposition (Source: http://www.purl.org/net/WERTI)?
Blank = verb to be conjugated (Source: http://www.nonstopenglish.com/exercise.asp?exid=915)617.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  25/206Fill-in-the-Blank Question Generation1.
Selection of an input corpus2.
POS tagging 3.
Selection of the blanks in the input corpus4.
Where needed, provide some information about the word in the blank, e.g.
verb lemma when the test targets verb conjugation (Aldabe et al, 2006)17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  26/206Selection of the Blanks?
Every "n-th" (e.g.
fifth or eighth) word in the text (Coniam, 1997)?
Words in specified frequency ranges, e.g.
only high frequency or low frequency words (Coniam,1997)?
Words belonging to a given grammatical category (Coniam, 1997; Aldabe et al, 2006)?
Open-class words, given their POS, and possibly targeted word sense (Liu et al, 2005; Brown et al, 2005)?
Using machine learning, based on a pool of input questions used as training data (Hoshino & Nakawaga, 2005)17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  27/206Objective Multiple-choice Cloze Itemshttp://www.wordlearner.comCombination of a cloze item with multiple-choice answers17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  28/206Generation of the Distractors?
Randomly chosen in the text from which the question was generated (Hoshino & Nakagawa, 2005)?
Same POS (Coniam, 1997)?
Similar frequency range (Coniam, 1997)?
For grammar questions, use a declension or a conjugation tool to generate different forms of the key, e.g.
change case, number, person, mode, tense, etc.
(Aldabe et al, 2006, Chen et al, 2006)?
Common student errors in the given context (Lee & Seneff, 2007)?
Collocations: frequent co-occurrence with either the left or the right context (Lee & Seneff, 2007)?
Open class words: semantic similarity based on distributional similarity (Smith et al, 2008) or a thesaurus (Sumita et al, 2005)717.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  29/206The Frequency Heuristic(Coniam, 1997)17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  30/206Verification of the Distractors?
Basic verifications:?
there must be enough distractors?
there must be no duplicated distractors (Aldabe et al, 2006)?
Collocations: choose distractors that do not collocate with important words in the target sentence (Liu et al, 2005; Smith et al, 2008)?
Use of the web: if the sentence/phrase containing the distractor is frequent on the web, then the distractor should be rejected (Sumita et al, 2005)The child's misery would move even the most  ____ heart.
(a) torpid hits("the most torpid heart") = 4(b) invidious hits("the most invidious heart") = 0(c) stolid hits("the most stolid heart") = 6(d) obdurate hits("the most obdurate heart") = 1 240 Good distractorsbecause infrequent17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  31/206Student Project in the e-NLP Course (Gurevych & Bernhard)?
Based on "Automatic generation of cloze items for prepositions" (Lee & Seneff, 2007)?
Example:If you don't have anything planned for this evening, let's go __ a movie.
(a) to  (b) of   (c) on   (d) null?
Tasks:?
INPUT: sentence + key, OUTPUT: list of three distractors?
The three distractors must each be generated taking a different approach?
baseline: word frequencies?
collocations?
"creative" method:?
Conclusion: a motivating and interesting project for students 17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  32/206Matching Test Items?
Task: match items on the left column with response items on the right column?
Kinds of elements matched:?Word ?
Synonym?
Definition ?
term?Word ?
antonym?
Hypernym ?
hyponym?
Historical event ?
date?
etc.
?Matching test items assess a learner's understanding of relationships817.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  33/206Matching Test Itemshttp://www.thefreedictionary.com17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  34/206Matching Test Items for Vocabulary Assessment (Brown et al, 2005)Glosses for specific word senses in WordNet17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  35/206Error Detection Questions?
Aim: detect and possibly correct errors, which can be marked or not?
Example (Chen et al, 2006)Although maple trees are among the most colorful varieties        (A)in the fall, they lose its leaves sooner than oak trees.
(B)      (C) (D)?Wrong statements are produced by the distractor generator17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  36/206Evaluation of Generated Questions?
Student evaluation ?
Difficulty and response time?
Comparison with results obtained for manually generated tests (Heilman & Eskenazi, 2007)?
Instructor evaluation?
Usability: "all distractors result in an inappropriate sentence" (Liu et al, 2005; Lee & Seneff, 2007)?
Post-editing: count how many test items are accepted, rejected or revised by instructors during post-editing (Aldabe et al, 2006; Mitkov et al, 2006)917.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  37/206Pre-requisites for Student Evaluation?
External assessment?
Evaluate the linguistic and / or factual knowledge of the students before they take the test , e.g.
Nelson-Denny Reading Test, the Raven's Matrices Test, the Lexical Knowledge Battery (Brown et al, 2005)?
Self-assessment?
Have the students assess whether they know the key or not (Heilman & Eskenazi, 2007)"Do you know the word 'w'?
"17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  38/206Item Analysis?
Investigate the quality of the test items (Zurawski, 1998)?
Quantitative item analysis:?
Facility / Difficulty index (p): number of test takers who answered the item correctly divided by the total number of students who answered the item?
Discrimination index (D): "does the test item differentiate those who did well on the exam overall from those who did not?"
?
Divide the students in two groups: high-scoring and low-scoring (above and below the median)?
Compute the item difficulty separately for both groups: pupper and plower?
Discrimination index D = pupper - plower17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  39/206Item Analysis?
ExampleThe child's misery would move even the most  ____ heart.
(a) torpid chosen by 7  students(b) invidious chosen by 1  students(c) stolid chosen by 3  students(d) obdurate chosen by 15  students#Students: 26?
Difficulty index: 15 / 26 = 0.58 ?
neither too difficult nor too simple (recommended score: 0.5)?
Discrimination index?
9 out of 12 students in the high group found the correct answer?
6 out of 14 students in the low group found the correct answer?
D = 9/12 ?
6/14 = 0.75 ?
0.43 = 0.32 ?
The test item is a quite good discriminator 17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  40/206Item Analysis?
Item distractor analysis: examine the percentage of students who select each incorrect alternative, to determine if the distractors are functioning wellWell-designed itemPossibly miskeyedCandidate for removalCandidate for revision1017.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  41/206Efficiency of the Automatic Generation of Test Items?
Even though automatically generated test items have to be post-edited, this is still a lot faster than writing new test items from scratch.
?Mitkov et al (2006) report the following figures:?
an average of 1 minute and 40 seconds was needed to post-edit a test item in order to produce a worthy item?
an average of 6 minutes was needed to manually produce a test item17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  42/206Summary?
The generation of questions and exercises is actually semi-automatic: the system's output has to be verified and modified by an instructor?
However, NLP-based systems considerably reduce the time spent by instructors to write test items, even if they have to manually correct the generated test items?
A great variety of NLP technologies and resources have been successfully used so far:?
POS tagging and parsing?WSD?
Term extraction?
...17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  43/206Introduction: eLearning and NLPAutomatic generation of exercisesAssessment of learner generated discourse  Reading and writing assistanceTutoring systemsWeb 2.0 and computer supported collaborative learningExample e-NLP application: electronic career guidanceOutline17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  44/206?
Types of learner generated discourse:?Emerging in institutional settings, e.g.
solutions to exercises?Emerging in informal settings, e.g.
discussions in forums?
Language forms: written or spoken?
Relevant NLP technologies:?Automatic essay grading?Detecting meaning errors?Plagiarism detection?Quality assessmentAssessment of Learner Generated Discourse1117.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  45/206?
Feedback to the student about her level of knowledge?
Feedback to the instructor about the progress of students?
learning?
Incentive to study certain things, to study them in certain ways, to master certain skills?
Formal data to determine the grade and/or making a pass/fail decisionImportance of Institutional eAssessment17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  46/206?
Advantages over traditional multiple-choice assessments (Bennett & Ward, 1993)?Major obstacle is the large cost and effort required for scoring?
Automatic systems:?
Reduce these costs?
Facilitate extended feedback to studentsImportance of Free-Text Assessments17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  47/206?
Proposed in the context of language learning, but applicable  to different topics?We will focus on essay gradingLearning Exercise Spektrum Model(Bailey & Meurers 2008)17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  48/206?
A major part of formal education?
Secondary students are taught structured essay formats to improve their writing skills?
Often used by universities in selecting applicants, e.g.
admission essays?
Used to judge the mastery and comprehension of material?
Students are asked to explain, comment on, or assess a topic of studyWhat is an Essay?1217.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  49/206?
Descriptive prompt ?
?Imagine that you have a pen pal from another country.
Write a descriptive essay explaining how your school looks and sounds, and how your school makes you feel.?
?
Persuasive prompt ?
?Some people think the school year should be lengthened at the expense of vacations.
What is your opinion?
Give specific reasons to support your opinion.
?Source: Y. Attali and J. Burstein.
Automated essay scoring with e-rater v.2.
The Journal of Technology, Learning, and Assessment, 4(3), February 2006.Essay Prompts17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  50/206Source: Marti A. Hearst, The Debate on Automated Essay Grading, IEEE Intelligent Systems, IEEE Educational Activities Department, 2000, 15, 22-37.Research Development in Writing Evaluation17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  51/206?
Intelligent Essay Assessor (Landauer, Foltz & Laham, 1998)?
Based on a statistical technique for summarizing the relations between words in a document, i.e.
every word is a ?mini-feature??
Intellimetric (Elliot, 2001)?
Based on hundreds of undisclosed features?
Project Essay Grade (PEG, Page, 1994)?
Based on dozens of mostly undisclosed features?
E-Rater (Burstein et al, 1998)?
The 1st version used more than 60 features?
E-rater 2.0 uses a small set of featuresMost Prominent Systems17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  52/206?
Humans evaluate various intrinsic variables of interest ?
essay score:?
Content adequacy?
Structure?
Argumentation?
Diction?
Fluency?
Correct language use?Machines use approximations or possible correlates of intrinsic variables ?
scoring modelHow Do Humans and Machines Rate Essays?1317.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  53/206How is a Scoring Model Created??
Analyze a few hundred essays: ?Written on a specific prompt?
Pre-scored by as many human raters as possible?
Identify most useful approximations (classification features) out of those available to the system?
Employ a statistical modeling procedure to combine the features and produce a machine-generated score17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  54/206Validating the Meaning of Scores (Yang et al 2002)?
Relationship between human and machine scores of the same prompt:?
Compare the machine-human and human-human agreement (Burstein et al, 1998; Elliot, 2001; Landauer et al, 2001)?
Estimate a true score as the one assigned by multiple raters (Page, 1966)?
Relationship between test scores and other similar measures:?
Compare automatic scores with multiple-choice test results and teacher judgments (Powers et al, 2002)?
Understanding the scoring process, i.e.
relative importance of different writing dimensions:?
Most commonly used features in scoring models (Burstein et al, 1998)?
The most important component is content (Landauer et al, 2001)17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  55/206Skepticism and Criticism (Page and Petersen, 1995)?
Three general objectives:?
Humanistic ?
never understand or appreciate an essay as a human?
Use automatic scoring as a second rater?
Defensive ?
playful or hostile students produce "bad faith" essays?
a study by Powers et al (2001), a lot of data needed?
Construct ?
computer-measured variables is not what is really important for an essay?
an improved ability to additionally provide diagnostic feedback17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  56/206Features Used by e-Rater 2.0?Measures of:?
Grammar, usage, typos?
Style?
Organization & development?
Lexical complexity?
Prompt-specific vocabulary usage?
Implemented in different writing analysis tools?
Based on an NLP foundation that provides instructional feedback to students in the web-based Criterion system1417.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  57/206Writing Analysis Tools: Correctness?
Identify five main types of grammar, usage and mechanics errors:?
Agreement and verb formation errors, wrong word use, missing punctuation, typographical errors?
Corpus-based approach:?
Train the system on a large corpus of edited text?
Extract and count bigrams of words and POS?
Search for bigrams in essay that occur much less often (Chodorow & Leacock, 2000)17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  58/206Writing Analysis Tools: Aspects of Style?
The writer may wish to revise:?
The use of passive sentences?
Very long or very short sentences?
Overly repetitious words (Burstein & Wolska, 2003)17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  59/206Writing Analysis Tools: Organization & Development?
Discourse elements present or absent in the essay (Burstein, Marcu and Knight, 2003)?
A linear representation of text as a sequence of:?
Introductory material?
A thesis statement?
Main ideas?
Supporting ideas?
A conclusion?
Train a system on a large corpus of human annotated essays to identify "good" sequences?
Mandatory parts, > 3 main ideas, ?17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  60/206Essay Annotated with Discourse ElementsSource: Y. Attali and J. Burstein.
Automated essay scoring with e-rater v.2.
The Journal of Technology, Learning, and Assessment, 4(3), February 2006.1517.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  61/206Writing Analysis Tools: Lexical Complexity?
Related to word-specific characteristics?
A measure of vocabulary-level, based on Breland, Jones and Jenkins (1994) Standardized Frequency Index across the words in an essay?
The  average word length in characters in an essay17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  62/206Writing Analysis Tools: Prompt-Specific Vocabulary Usage?
Intuition: good essays resemble each other in their word choice, as will poor essays (within the same prompt)?
Idea: compare an essay to a sample of essays from each score category (usually 1-6)?
Each essay and a set of training essays from each score category is converted to a vector?
Some function words are removed?
Each vector element is a weight based on a word frequency function?
Six cosine correlations are computed between the essay and each score category to determine the similarity17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  63/206Scoring in e-Rater 2.0?
Input: all features of all writing analysis tools?
Grammar, usage, mechanics, style (4 features)?
Organization & development (2 features)?
Lexical complexity (2 features)?
Prompt-specific vocabulary usage (2 features)?
Straightforward:?
Apply a linear transformation on feature values to achieve a desired scale?
A weighted average of the standardized feature values17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  64/206Future Directions?
Better standardization of scoring - a single scoring model for all prompts of a program or assessment?
Better understanding and control over the automated scores?
Cover more aspects of writing quality, devise new features?
Prefer features providing useful instructional feedback?
Detection of anomalous and bad-faith essays?
Characterize different types of anomalies?
Detect off-topic essays (Higgins, Burstein and Attali, 2006)1617.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  65/206?Plagiarism is representing the words or ideas of someone else as your own.
Examples include, but are not limited to, failing to properly cite direct quotes and failing to give credit for someone else's ideas?.
University of Miami Honor Council, Honor Code?Plagiarize: To practice plagiarism upon; to take and use as one's own the thoughts, writings, or inventions of another.
(With the thing, rarely the person, as object.)?
Oxford English Dictionary OnlinePlagiarism17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  66/206?
Clearly define plagiarism to the students and use explicit examples?
Educate the students about the honor code and the ramifications if it is violated?
Create assignments that make plagiarism difficult?
Make sure the students are familiar with online resources?
Have the students submit evidence of the research process as well as the paper?
Avoid repeat assignments and paper topics?
Inform the students you are Internet savvy and you know about the paper mills (visit the sites with the students to evaluate the quality of the work)?
Inform the students that you use plagiarism detection softwareFrom ?Plagiarism in the 21st century?
Carrie Leslie.
Lunch & Learn.
2004.
Otto G. Richter LibraryHow to Avoid it?17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  67/206?
"Copy" work:?
From another student (intra-corpal)?
From a source outside the corpus of submissions (extra-corpal)?
Self-plagiarism?
The Internet makes it easier than ever:?
Download a term paper?
Fail to give proper credit to the source of an idea?
Copy extensive passages without attribution?
Inserting someone else?s phrases or sentences (minimally paraphrased) into your own prose and forget to supply a set of quotation marksMain Ways of Plagiarism17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  68/206?
Replacing odd or unusual words ?
Changing formatting ?
Adding filler words or phrases ?
Changing headings ?
Rephrasing sentences ?
Removing or re-ordering sections ?
Changing spelling (usually from American English to British English, if the document is plagiari[s|z]ed from the Web) ?
Producing consistency by find-and-replace (as an example, if some papers refer to the World Wide Web, some to the WWW, some to the Web, a student may perform a global find-and-replace to ensure consistency within the plagiarised document) ?
In programming, changing variable names and comments The use of electronic tools to support plagiarism detection: http://www.comp.leeds.ac.uk/hannah/CandIT/plagiarism.htmlTypes of Techniques Used to Conceal Copying1717.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  69/206(1) Word-for-word plagiarism: direct copying of phrases or passages from a published text without quotation or acknowledgement.
(2) Paraphrasing plagiarism: when words or syntax are changed (rewritten), but the source text can still be recognised.
(3) Plagiarism of secondary sources: when original sources are referenced or quoted, but obtained from a secondary source text without looking up the original.
(4) Plagiarism of the form of a source: the structure of an argument in a source is copied (verbatim or rewritten)(5) Plagiarism of ideas: the reuse of an original thought from a source text without dependence on the words or form of the source(6) Plagiarism of authorship: the direct case of putting your own name to someone else?s workBased on Martin (1994) and Clough (2003)Forms of Plagiarism17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  70/206?
Use of advanced or technical vocabulary beyond that expected of the writer?
A large improvement in writing style compared to previous submitted work?
Inconsistencies within the written text itself, e.g.
changes in vocabulary, style or quality?
Incoherent text where the flow is not consistent or smooth, which may signal that a passage has been cut-and-pasted from an existing electronic source?
A large degree of similarity between the content of two or more submitted texts.
This may include similarity of style as well as content?
Shared spelling mistakes or errors between texts?
Dangling references, e.g.
a reference appears in the text, but not in the bibliography?
Use of inconsistent referencing in the bibliography suggesting cut-and-pasteBased on Clough (2003)Typical Plagiarism Indicators17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  71/206?Most popular plagiarism detection scheme:?
Finding the overlap of matching subsequences and substrings (consecutive tokens) of length ?
n (where n is derived empirically)?
The longer n becomes, the more unlikely it is that the same sequence of n tokens (words or characters) will appear in the same order in independently written texts?
A similarity function is used to capture the degree of overlap between the two texts represented by the sets of n-grams and a chosen threshold above which texts are deemed plagiarised?
Problem: larger N-grams are rare, difficult to define thresholdsString Matching Algorithms17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  72/206?
Figures taken from 769 texts in the METER corpus:Uniqueness of N-grams (from Clough 2003)1817.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  73/206?
Greedy String Tiling (or GST: see, e.g.
(Wise,1993)), an algorithm which computes a 1:1 mapping between the tokens in a text pair in such a way that as much of one text as possible is covered with maximal non-overlapping substrings (called tiles) from the other.
?
This algorithm computes the longest common substrings (greater than length n) between two texts without having to define an n-gram size a priori.
?
Figure 1 represents a tiling of two sentences after running GST (tiles are highlighted) with a minimum match length of 1 word.Longest Common SubstringsComputed between Two Sentences17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  74/206?
The output of GST algorithm is a set of maximal matches between the text pair: [for two years], [driver who], [into the], [a], [queen], [was] and [banned].
?
Different quantitative measures to detect plagiarism, e.g.:?
the minimum and maximum tile length?
the average tile length?
the dispersion of tile lengths?
a similarity score based on tile length (similar to that for n-gram containment).
?
The challenge is to capture these tiling patterns such that derived and non-derived texts are distinguishable.Longest Common SubstringsComputed between Two Sentences17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  75/206Example of Tiling for Derived and Non-Derived Text (from Clough 2003)?
It has been empirically found that: ?
derived texts (top) share longer matching substrings?
both the tiling for a derived and non-derived text pair are in most cases apparently different17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  76/206?
Combining evidence from various sources, e.g.
?
use a Na?ve Bayes probabilistic classifier to combine evidence from several measures of similarity taken from a GST tiling and make a decision: derived or not-derived?
Supervised learning: training data required (texts which have already been classified as plagiarised or not)?
Unsupervised learning: can also be helpful in grouping together texts which exhibit similar characteristics (e.g.
clustering)Machine Learning in Plagiarism Detection1917.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  77/206Preserving longer matching n-grams and tile lengths to make the approach resistant to simple edits?
Allow small gaps to represent token deletion?
Detect simple word substitution (using WordNet)?
The insertion of certain words such as domain-specific terminology and function words (e.g.
conjunctions)?
Simple reordering of tokens (e.g.
transposition)Relaxing the Approach17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  78/206?
Existing work involves minimal natural language processing (NLP)?
Areas of NLP that could aid plagiarism detection, particularly in identifying texts which exhibit similarity in semantics, structure or discourse, but differ in lexical overlap and syntax?
NLP methods include: ?
morphological analysis, part-of-speech tagging, anaphora resolution, parsing (syntactic and semantic), co-reference resolution, word sense disambiguation, and discourse processing?
Future work:?
several similarity scores based on lexical overlap, syntax, semantics, discourse and other structural featuresNLP in Plagiarism Detection17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  79/206Online Internet Plagiarism Services?
Plagiarism.org www.plagiarism.org?
The largest online plagiarism service available?
IntegriGuard www.integrigaurd.com?
EVE2 www.canexus.com/eve/abouteve.shtml?
None of the services details their implementation details?
All of them are commercial, but plagiarism.org allows free trial17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  80/206?
Automatic scoring ?
Essays (e-Rater, Burstein and Chodorow, 1999)?
Longer texts (AutoTutor, Wiemer-Hastings et al, 1999)?
Automatic diagnosis, i.e.
content assessment (CAM) on learner data?
Language learning (Bailey and Meurers, 2008)?
Error detection in C-rater (Leacock, 2004)?
85% accuracyAssessing Short Textual Answers2017.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  81/206?Measures student understanding with little regard to writing skills?
Example question (4th grade math question used in the National Assessment for Educational Progress (NAEP)):C-Rater (Chodorow 2004)17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  82/206Technology of c-Rater?
Content expert develops a scoring guide?
Gold standard responses?
Recognizing the equivalence of the response to the correct answers?
Essentially paraphrase recognition?
Analysis in terms of: ?
predicate argument structure?
resolving the referent of any pronouns in the response ?
regularizing over morphological variation?
matching on synonyms or similar words?
resolving the spelling of unrecognized words?
Mapping canonical representations to those of the gold standard responses?
Rule-based?
11th grade reading comprehension items?
Exact agreement with human scorers 84%17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  83/206?
Analysis of responses to short-answer comprehension tests?
1-3 sentences in length?
Error codes:?
Necessary concepts left out of learner response?
Response with extraneous, incorrect concepts?
An incorrect blend/substitution (correct concept missing, incorrect one present)?
Multiple incorrect concepts?
Human disagreement in 12%, eliminated from the evaluation dataDetecting Meaning Errors (Bailey and Meuerers, 2008)17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  84/206?
Input:?
Learner?s response, one+ target responses, question, source reading passage?
String-based analysis filter?
Linguistic analysis: annotation, alignment, diagnosisTechnology of CAM2117.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  85/206?
Alignment maps new concepts from  learner's response to those in target?
Token level (abstraction from string to lemma, semantic type (e.g.
date, location)?
Chunk level?
Relation level?
Diagnosis analyzes if the learner's response contains content errors?
Evaluation?
Hand-written rules 81% on the development data, 63% on the test data?
Machine learning (TiMBL), 88% accuracy on the test data for binary semantic error detection task?
Viable resultsTechnology of CAM17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  86/206?
Non-native speech scoring (Bernstein 1999; Zechner and Bejar, 2006, Zechner et al, 2007)?
SET-10 (Bernstein 1999) focuses on the lower entropy language aspects?
Tasks such as ?reading?
or ?repetition??
Highly predictable word sequences?
TOEFL Practice Online Speaking test (Zechner et al, 2007)?
Focus on spontaneous, high-entropy responses?
Test with Heterogeneous Tasks (THT) (Zechner and Xi, 2008)?
Ranges from reading speech to opinion giving?
Assess communicative competenceAutomatically Scoring Speech17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  87/206?
Dimensions of assessement:?
Comprehensibility, accuracy, clarity, coherence, appropriateness?
Evident through:?
Speaker?s pronunciation, fluency, use of grammar and vocabulary, development of ideas, sensitivity to communicative contextTest with Heterogeneous Tasks17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  88/2061.
Reading aloud2.
Picture description (medium-entropy)?
Describe a picture in detail?
Rated on the combined impact of delivery, use of structures, vocabulary, content relevance and fullness (3-point scale)3.
Open-end short-answer questions4.
Constrained short-answer questions5.
Respond to a voice mail6.
Opinion task (high-entropy)?
State an opinion on an issue and support its with reasons, examples, arguments, etc.?
Rated on the combined impact of fluency, pronunciation, intonation and stress, grammar, vocabulary, content relevance, and cohesion and ides progression (5-point scale)THT Task Types2217.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  89/206?
Adapt a non-native English speech recognizer (trained on TOEFL Practice Online data) to transcribed THT task responses?
Compute a set of relevant speech features based on the recognition output?
Build a scoring model using a subset of features to predict human scoresTechnology of SpeechRater17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  90/206?
Human agreement (kappa): around 0.50 (Picture) and 0.72 (Opinion)?
Opinion task ?
multiple regression employing Equal, Expert, or Optimal Weights; picture task ?
CART 5.0 (classificaiton trees)Evaluation17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  91/206Introduction: eLearning and NLPAutomatic generation of exercisesAssessment of learner generated discourse  Reading and writing assistanceTutoring systemsWeb 2.0 and computer supported collaborative learningExample e-NLP application: electronic career guidanceOutline17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  92/206Readability?
"Readability is what makes some texts easier to read than others" (DuBay, 2004)?
A text's readability can be estimated with readability formulas, which provide an objective prediction of text difficulty?
Aims: ?
match reading materials with the abilities of the readers?
support authors in writing clearly understandable texts2317.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  93/206Traditional Readability MeasuresFormula Date Features Example values1948Fog index 1952SMOG grading 1969 - # words with more than 3 syllablesFlesch index - average # syllables / word- average sentence length - 30 = "very difficult"- 70 = "easy"- # words with more than 2 syllables- average sentence length - 5 = comic books- 10 = newspapers                    - 0 to 6 =  low-literate- 19+ = post-graduate17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  94/206Readability Statistics?
Computed using the style commandRotk?ppchen17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  95/206Statistical Models for Reading Difficulty?
Based on statistical models representing norms, specific populations and individuals (Brown & Eskenazi, 2004)?
Different models are created for each level of reading difficulty?
Features:?
Lexical features: word unigrams (Collins-Thompson & Callan, 2005; Heilman et al, 2008)?
Grammatical features: frequency of specific grammatical constructions (Heilman et al, 2007)17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  96/206Document Retrieval for Reading Practice?
Reading proficiency is a widespread problem?
Only 29% of high school seniors in public schools across the USA were proficient in reading according to a 2005 NCES study (Miltsakaki & Troutt, 2008)?
Low reading proficiency may have dramatic consequences (DuBay, 2004):?
The strongest risk factor for injury in a traffic accident is the improper use of child safety seats?
79 to 94% of car seats are used improperly?
Installation instructions are too difficult to read for 80% adult readers in the US?
Use readability measures to identify suitable and authentic documents, given a reader profile / reading grade2417.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  97/206Vygotsky's Zone of Proximal Development?Materials for assisted reading should be harder than the reader's tested reading level, but within the zone of proximal development?Materials for unassisted reading , e.g.
medicine inserts, instructions, should be as easy as possiblehttp://www.education.vic.gov.au/17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  98/206Read-X (Miltsakaki & Troutt, 2008)?
http://net-read.blogspot.com/KeywordsTextsReadingLevelYahoo!
Internet searchText extractionReadability analysisText classification17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  99/206REAP search (Heilman et al, 2008)17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  100/206Text Simplification?
The readability of a text can be improved by transforming it into a simpler text?
Characteristics of manually simplified texts (Petersen & Ostendorf, 2007) :?
shorter sentences?
fewer and shorter phrases?
fewer adjectives, adverbs and coordinating conjunctions?
nouns are less often replaced with pronounsOriginal text: Congress gave Yosemite the money to repair damage from the 1997 flood.Abridged text: Congress gave the money after the 1997 flood2517.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  101/206Automatic Text Simplification?
Related techniques: summarisation and sentence compression?
Syntactic simplification:?
Removal or replacement of difficult syntactic structures, using hand-built transformational rules applied to dependency and parse trees (Carroll et al, 1999; Inui et al, 2003)?
Lexical simplification:?
Goal: replace difficult words with simpler ones (Carroll et al, 1999; Lal & R?ger, 2002)?
Difficult words are identified using the number of syllables and/or frequency counts in a corpus?
Choose the simplest synonym for difficult words in WordNet17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  102/206Vocabulary Assistance for Reading?
Overall goal: support vocabulary acquisition during reading for:?
children, who learn to read (Aist, 2001)?
foreign language learners, who read texts in a foreign language?
Problem: a word's context may not provide enough information about its meaning?
Aim: augment documents with dynamically generated annotations about (problematic) words17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  103/206Selection of Target Words?
All words are annotated?
Annotate selected words?
Manually selected target words?
Automatically selected target words?
(Aist, 2001):?
Words with few senses in WordNet (to avoid WSD)?
Not a trivially easy word: three or more letters long, not in a stop list of function words, not a number?
Not a proper noun?
Socially acceptable , e.g.
no secondary slang meanings?
(Mihalcea & Csomai, 2007): keyword extraction methods17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  104/206Resources for Vocabulary Assistance?WordNet (Aist, 2001):?
Extraction of comparison words for a target word: antonym, hypernym, synonym?
Generation of factoids:?
eggshell can be a kind of natural covering?
Problems: ?
some of the automatically generated factoids are too obscure or do not match the sense of the word used in the original text?
some of the comparison words may be harder to understand than the target word?
hypernyms do not always capture the key elements of the meaning of a word2617.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  105/206Resources for vocabulary assistance?
Collaborative and online resources, e.g.
Wikipedia, Wiktionaryhttp://lingro.com/17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  106/206Wikipedia and Wiktionary as Lexical-Semantic Resources+This image is licensed under the GFDL.
It is based on Bild:Foerderturm-Kamen.jpg.?
Structure Mining?
Content Mining?
Usage Mining= Lexical semantic resources17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  107/206Wikipedia Article PageFirst paragraph?
First paragraph?
Definition / Gloss17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  108/206Wikipedia  ?
Redirect Pages?
Synonyms?
Pope Benedict XVI?
Joseph Ratzinger?
Joseph Cardinal Ratzinger?
Spelling variations?
Benedict the Sixteenth?
Benedict the 16th?
Benedict 16th?
Benedict 16?
Benedict XVI?
Benedict xvi?
Misspellings?
Josef Ratzinger (instead of Joseph)?
Abbreviations?
PB162717.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  109/206Wikipedia ?
Categories?
Articles?
HierarchyEngines Energy conversionPiston enginesAircraft piston enginePiston Engine ConfigurationsAutomobile engines17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  110/206JWPL ?
Wikipedia API?
Freely available for research purposes?http://www.ukp.tu-darmstadt.de/software/CategoryGraphPageCategoryWikipediaParsedPage SectionParagraphLinkTable...MetaData17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  111/206Wiktionary as Lexical-Semantic Resource?
Language?
Etymology?
Pronunciation?
Part-of-speech?
Word senses?
Synonyms?
Derived Terms?
Translations?
Abbreviations, Antonyms, Categories, Collocations, Examples, Glosses, Hypernyms, Hyponyms, Morphology, Quotations, Related terms, Troponyms 17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  112/206JWKTL ?
Wiktionary APILanguageWiktionaryWordPoSWiktionarySense SynonymsTranslationsEtymologyPronunciation...??
Freely available for research purposes?http://www.ukp.tu-darmstadt.de/software/2817.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  113/206Wikify!
(Mihalcea & Csomai, 2007)?
Aim: link keywords (important concepts) in a document to the corresponding Wikipedia page?
Keywords extraction?
Ranking: tf.idf, ?2 independence test, keyphraseness?Word Sense Disambiguation to identify the target Wikipedia page:?
Lesk algorithm: measure of contextual overlap between the Wikipedia page of the ambiguous word / phrase and the context where the ambiguous word / phrase occurs?
Machine Learning classifier17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  114/206Spelling Error Detection and Correction?
Aim: identify and correct spelling errors?
Types of spelling errors:?
Non-word spelling errorsoccured instead of occurredater instead of after, later, alter, water, ate?Word conflation or splitting?
ofthe, understandhme?
sp ent, th ebook?
Malapropisms: real-word spelling errors in open-class wordsdiary ?
dairythere ?
their ?
they're17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  115/206Research Problems (Kukich, 1992)?
Non-word error detection?
From the early 1970s to the early 1980s?
Focus on efficient pattern-matching and string comparison techniques?
Isolated-word error correction?
Started in the early 1960s?
Context-dependent word correction?
Started in the early 1980s?
Use of statistical language modelsTextbook overviews: (Jurafsky & Martin, 2008; Manning, Raghavan and Sch?tze, 2008)17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  116/206Non-word Error Detection?
n-gram analysis: ?
n-gram = n-letter sub-sequences of words or strings?
examine each letter n-gram in an input string?
find the n-gram in a table of n-gram statistics compiled from a corpus of text?
highly infrequent n-grams indicate probable misspellings?
especially useful for optical character recognition devices?
Dictionary lookup:?
check if an input string appears in a dictionary of acceptable words?
techniques: hash tables, tries, finite-state automata, Aho-Corasick algorithm, ternary search trees2917.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  117/206Isolated Word Error Correction1) Detection of errors in single words, out of context2) Generation of candidate corrections?
Distance/Proximity metric between the correct word and the erroneous word?
Minimum edit distance: minimum number of editing operations (i.e., insertions, deletions, and substitutions) needed to transform one string into another"=" Match; "o" Substitution; "+" Insertion; "-" Deletion3) Ranking of candidate corrections based on the distance/proximity metric or occurrence countsDistance = 4(c) www.levenshtein.net17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  118/206Isolated Word Error CorrectionProblem: even humans do not achieve 100% accuracy levels, given isolated misspelled strings (Kukich, 1992):?
vver ?
over, ever, very??
wekk ?
week, well, weak?17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  119/206Context-dependent Error Correction?
Also called context-sensitive spelling correction?
Aim: correct real-word spelling errors, which cannot be identified by dictionary lookup?
Between 25% and 40% of spelling errors are valid English words (Kukich, 1992)?
Use the context to help detect and correct spelling errors?
Based on language models17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  120/206Spelling Correction for Foreign Language Learners (Heift & Rimrott, 2007)?
80% of the mispellings produced by non-native writers of German are due to insufficient command of the foreign language:Metz for Fleisch (from Metzger)tanzed for tanzte (from danced)?
These errors are difficult to correct for generic spell checkers ?
need for rules that are geared towards common L2 errors?
Importance of feedback: learners are more likely to correct a mistake if the feedback contains explicit information on the error and correction suggestions3017.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  121/206Grammar Checking?
Tasks:?
Grammatical error detection: identify sentences which are grammatically ill-formed?
Grammatical error correction: correct grammatically ill-formed sentences?Methods:?
Rule-based checking: use of manually written rules?
Syntax-based checking: use the output of a parser?
Statistics-based: use statistical information about n-gram frequencies?
The methods usually focus on a specific part-of-speech17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  122/206Grammatical Error Types?
According to (Nicholls, 1999):?
Insertion of an unnecessary word: *affect to their emotions?
Deletion of a word: *opportunity of job?Word or phrase that needs replacing: *every jobs?Word use in the wrong form: *knowledges?
Grammatical difficulties for ESL learners:?
Prepositions: *arrive to the town, *most of people, *He is fond this book (Chodorow et al, 2007)?
Verb forms: I can't *skiing well, I don't want *have a baby (Lee & Seneff, 2008)?
Articles17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  123/206Rule-based Grammar Checking?
Analyse errors in a corpus and write rules to identify and correct these errors, based on POS information?
Rule patterns should not occur in correct sentences?
Examples:?
Language Tool (Naber, 2003)?
Open Source language checker?
Rules are defined in XML configuration files and include feedback messages?
GRANSKA (Eeg-Olofsson & Knutsson, 2003)?
Rules expressed in a specific rule language17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  124/206Syntax-based Grammar Checking?
Template-matching on parse trees (Lee & Seneff, 2008)?
Automatic introduction of verb form errors in a corpus?
Parsing of the corpus?
Identification of templates in the "disturbed" parse trees3117.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  125/206Statistics-based Grammar Checking?
Detection of unfrequent sequences of words and/or POS tags:?
POS bigrams (Atwell, 1987)?
POS tags and function words n-grams (Chodorow & Leacock, 2000)?Machine learning:?
Maximum entropy model trained with contextual features and rule-based filters (Chodorow et al, 2007)?
Machine learning model based on automatically labelled sequential patterns (Sun et al, 2007)17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  126/206The Tip of the Tongue ProblemWriters may want to look for words that express a given concept and are appropriate in a given contextProblem: in order to access words in a traditional dictionary, you have to know the word you are looking for17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  127/206Dictionary Lookup (Ferret & Zock, 2006)?
Tip of the tongue problem: ?
domesticated animal, producing milk suitable for making cheese?
NOT (cow, buffalo, sheep)??
goat?
The mental lexicon is a huge network of interconnected words and concepts?
The network is entered through the first word that comes to mind and the target word is retrieved thanks to connecting links17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  128/206Internal Representation3217.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  129/206Wikipedia Graph17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  130/206Introduction: eLearning and NLPAutomatic generation of exercisesAssessment of learner generated discourse  Reading and writing assistanceTutoring systemsWeb 2.0 and computer supported collaborative learningExample e-NLP application: electronic career guidanceOutline17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  131/206?
Developed during last 25 years, typically the domains of e.g.
mathematics, science and technology?
Goal: the ability to engage learners in rich natural language dialogue?
Significant learning gains beyond classroom environments:?
Learning gains from computer tutors by approximately .3 to 1.0 grade unit (Corbett et al 1999)?
Learning gains from human tutors by .4 to 2.3 grade units, though ?
modest domain knowledge?
no training in pedagogy?
rare use of sophisticated tutoring strategiesIntelligent Tutoring Systems with Conversational Dialogue17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  132/206?
System presents problems and questions to learners?
Learner types in / utters answers in natural language?
Lengthy multi-turn dialogues as complete solutions / answers evolveInteraction with Intelligent Tutoring Systems3317.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  133/206?
CIRCSIM (Evens and Michael 2006)?
BEETLE (Zinn et al 2002) ?
Geometry Explanation Tutor (Aleven et al 2003) ?
Why2/Atlas (VanLehn et al 2002) ?
students explain physical systems?
ITSpoke (Litman et al 2006) ?
builds upon Why2, spoken language based?
SCOT (Pon-Barry et al 2006) ?
ProPL (Lane and VanLehn 2005) ?
AutoTutor (Graesser et al 2003) ?
students answer deep questions about computer technology?
a core set of foundational requirements for mixed-initiative natural language interaction in tutorial dialogueResearch on ITS17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  134/206?
Speech acts in tutorial dialogue (Marineau et al 2000)?
Dialogue acts' correlation with learning (Forbes-Riley et al 2005, Core et al 2003, Ros?
et al 2003, Katz et al 2003)?
Student uncertainty in dialogue (Liscombe et al 2005, Forbes-Riley and Litman 2005)?
Comparing text-based and spoken dialogue (Litman et al 2006)Corpus-Based Studies17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  135/206Cognitive and Affective States in Learning?
ITS as platforms to investigate the impact of tutorial interactions on affective and motivational outcomes (e.g.
self-efficacy) along with cognitive measures (i.e.
learning gains)?
Goal: identifying tutorial strategies that balance the tradeoff between cognitive and affective learning outcomes?Widespread methodology: investigate human-human tutorial dialogues (e.g.
Boyer et al 2008)17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  136/206?
By dialogue initiative:?
System initiative?
Mixed-initiative?
By interaction modality:?
Text-based?
Speech-basedITS Interaction Style3417.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  137/206?
Tutoring Research Group at the University of Memphis (e.g.
Graesser et al, 1999)?
Intended for college students who take an introductory course in computer literacy ?
Fundamentals of computer hardware, operating system and the Internet?
Goals:?
To comprehend student contributions ?
To simulate dialogue moves of normal (unskilled) or sophisticated tutorsAutoTutor17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  138/206Screenshot of AutoTutor(Graesser et al, 2001)17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  139/206?Major problem is printed at the top of the screen?Major questions are generated from a curriculum script:?
Questions invite lengthy explanations and deep reasoning?Why, how and what-if questions?
Deep reasoning rather than short snippets of shallow knowledge?
10 to 30 turns for a single question from a curriculum script?
Learner?s contributions are typed inInterface Description17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  140/206Example Tutorial Dialogue(AutoTutor: Graesser et al, 2001)3517.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  141/206?
The answer is not graded (good / bad / score)?Multi-turn conversation to extract more information from the student?
Students learn by constructing explanations and elaborations of the material (e.g.
Chi et al, 1994)Information Delivery versus Knowledge Construction17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  142/206System Architecture1.
Animated agent?Tree-dimensional2.
Curriculum script?
Important concepts, questions, cases, and problems3.
Speech act classifier?Segmenting, parsing student?s response, rule-based utterance classification4.
Latent semantic analysis (LSA)?Evaluating the quality of students?
contributions5.
Dialogue move generator?Can include question answering, repeating the question, encouraging 6.
Dialogue Advancer Network?Uses speech act and LSA to select next dialogue move and discourse marker7.
Question answering tool17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  143/206?
Dialogue moves:?
E.g.
open-ended pumps, e.g.
What else??
Tutors have a set of expectations about what to include into the answer?
Expectation-1?
Expectation-2?
AutoTutor decides what expectation to handle next and selects a dialogue move?
Hints (indirect)?
Prompts (in-between)?
Assertions (direct)?
Exit the cycle when the student articulated the expected answerHow to Engage the Student in Conversation?17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  144/206?Match students utterances to expectations?
Statistical, corpus-based measure of representing knowledge?
Latent Semantic Analysis (LSA)?max function considering the current utterance and all combinations with previous learner?s utterances?
An expectation is considered covered if it exceeds some threshold valueHow to Evaluate the Quality of the Answer?3617.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  145/206?
Use LSA in conjunction with various criteria?
Use next expectation with the highest score below threshold (zone of proximal development)?
Use next expectation with the highest LSA overlap with the previous covered expectation (coherence)?
Further constraints to advance the agenda in an optimal wayHow to Select the Next Expectation to Cover?17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  146/206?
Three channels of feedback:?
Backchannel ?
acknowledge the learner?s input, based on important nouns, e.g.
uh-huh?
Pedagogical feedback on the learner?s previous turn, based on LSA scores?
Negative, e.g.
not really?
Neutral negative, e.g.
okay?
Neutral positive, e.g.
okay?
Positive, e.g.
right?
Corrective feedback ?
repair bugs and misconceptions?
Need to be explicitly anticipatedHow to Give Feedback to a Student?17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  147/206?
Dialogue advancer network (DAN), mixed-initiative dialogue?
Formally an augmented state transition network?
Selection of dialogue move on turn N+1 is sensitive a large set of parameters computed from dialogue history?
Student: What does X mean?Tutor: answer by giving definition from a glossary?
Student: gives an assertionTutor: evaluate the quality and give short evaluative feedbackDialogue Management17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  148/206?
Pump?
Hint?
Splice?
Prompt?
Prompt response?
Elaboration?
Summary?
Five forms of immediate short-feedbackTypes of Dialogue Moves3717.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  149/206?
Organizes the content of topics covered in the dialogue?
Each topic is associated with:?
A set of expectations?
A set of hints and prompts for each expectation?
A set of anticipated bugs/misconceptions and their corrections?
(optinally) pictures or animationsCurriculum Script17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  150/206?
Create an LSA space?
Identify a corpus of documents on the domain knowledge?
Lesson planner?
Create a curriculum script with deep reasoning questions and problems?
Compute LSA vectors on the content of curriculum scripts?
Prepare glossary of important terms and their definitionsAuthoring Tools17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  151/2061.
Glossary of terms and definitions  (metacognition)2.
LSA space for conceptual physics (comprehension)3.
Curriculum script with deep reasoning questions and associated answers (production)?
Most labour-intensiveDomain AdaptationLevels:17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  152/206Why2 (http://www.pitt.edu/~vanlehn/why2000.html)?
Chi et al found that having students explain physical systems qualitatively positively correlated with learning outcomes?
Explanations can be done on formal and graphical languages, but also in natural languages?Why2 targets to coach students explain physical systems in natural language?
Idea: ask the student to type in an explanation for a simple physical situation3817.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  153/206Example dialogue17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  154/206?
Student's utterance is analyzed to detect any misconceptions?
If a misconception is detected, a knowledge construction dialogue is initiated (KCD)?Misconceptions are anticipated by collecting and analyzing a corpus of explanations from studentsDialogue Management17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  155/206?
A speech-enabled version of Why2-Atlas tutoring system?Workflow:?
The student?s essay is parsed?
A set of dialogue topics concerning misconceptions or incomplete explanations is extracted ?
ITSpoke than engages student in a dialogue that covers these topics?
Therefore, the student revises the essay?
End the tutoring problem?
Cause another round of dialogue/essay revisionITSpoke (Intelligent Tutoring SPOKEn dialogue system)17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  156/206?
Back-end is Why2-Atlas system (VanLehn et al 2002)3917.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  157/206?
Back-end is Why2-Atlas system (VanLehn et al 2002) 17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  158/206?
Back-end is Why2-Atlas system (VanLehn et al 2002)17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  159/206?
Sphinx speech recognizer (Huang et al, 1993)?
Trained with example user utterances?
Domain adaptation by human-computer typed corpus ?
Language model enhancement by human-human spoken language corpus?
Festival speech synthesizer (Black and Taylor, 1997)?
Sentence-level syntactic and semantic analysis modules (Ros?, 2000)?
Discourse and domain level processors (Makatchev et al, 2002)System Architecture17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  160/206ITSpoke Annotated Dialogue Excerpt4017.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  161/206Benefits of Spoken Interaction?
Benefits of human-human tutoring through spoken interacton (Lemke, 1990; Chi et al 1994)?
Spontaneous self-explanantion occurs more frequently in spoken tutoring (Hausmann and Chi, 2002)?
Speech contains prosodic and acoustic information to predict emotional states (Ang et al, 2002; Batliner et al, 2000) ?
Connection between learning and emotion (Coles, 1999)17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  162/206Introduction: eLearning and NLPAutomatic generation of exercisesAssessment of learner generated discourse  Reading and writing assistanceTutoring systemsWeb 2.0 and computer supported collaborative learningExample e-NLP application: electronic career guidanceOutline17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  163/206Characteristics of Web 2.0?
Collective intelligence?
Huge amount of data?
Fast growing?
Noise?
Duplicates?
Content of different quality17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  164/206eLearning 2.0?Main characteristics:?Worldwide learning community?
Educational material produced both by students and teachers?
Tools:?Wikis?
Blogs?
Podcasts?Widgets?
...4117.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  165/206"CALL 2.0"17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  166/206Widgets for CALL17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  167/206Use of Web 2.0 Resources17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  168/206Community-rule-based Grammar Checking?
A new paradigm?
http://community.languagetool.org4217.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  169/206Motivation: Information overload in E-LearningQA-ELQuestion Answering for E-Learning17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  170/206QA-ELQuestion Answering for E-Learning17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  171/206Social Q&A Sites?
Solution to the problem of automatically answering learners' questions: use repositories of already answered questions (Bernhard & Gurevych, 2008)17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  172/206What is actually the Quality of Web 2.0 Resources??Wikipedia:?
Open edit policy, yet high quality articles (Giles, 2005)?
42 entries tested by experts?
average science entry in Wikipedia contained around four inaccuracies?
average science entry in Encyclopaedia Britannica contained around three inaccuracies?
Automatic assessment of the quality of these ressources:?
Social Q&A sites (Jeon et al, 2006; Agichtein et al, 2008)?Wikipedia (Druck et al, 2008)?
Forums (Weimer et al, 2007; Weimer & Gurevych, 2007)4317.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  173/206?Web 2.0 leads to massive amounts of data?
Users need content of good quality?
Current approach?
Users label the data for quality?
Labels are used for filtering?
Problems:?
Happens rarely?
New item problem?
Premature negative consent (Lampe and Resnick, 2004)Quality Assessment of User Generated Discourse17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  174/206Markus Weimer and Iryna Gurevych.
2007.
Predicting the Perceived Quality of Web Forum Posts.
RANLP, Borovetz, Bulgaria.Goal: Develop a system to automatically assess the perceived quality of forum postsCase Study17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  175/206?
Essay scoring?
Established in systems like e-Rater (Attali and Burstein, 2006)?
Very specialized approach: It is known what a ?good?
essay is?
Input on which features to use?
Automatically assessing review helpfulness (Kim et al, 2006)?
Goal: predict the helpfulness of product reviews on Amazon.com?
Also very specialized:?
The rating task is clearly defined: helpful / not helpful for buying decision?
Dominant feature is metadata-dependent: star rating of the productRelated Work on Quality Assessment17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  176/206?
Adapt to the quality standards of a user community?
Be independent of metadata-based features?
Apply the system to forums from different domainsRequirements4417.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  177/206Approach in Weimer and Gurevych (2007)17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  178/206?
Surface?
Length in tokens?
Question Frequency?
Exclamation Frequency?
Capital WORD Frequency?
Lexical?
Spelling Error Frequency?
Swear Word Frequency?
Syntactic?
Part of speech distribution?
Form Specific?
IsHTML?
IsMail?
Quote Fraction?
URL Count?
Path Count?
Similarity?
Cosine between the post unigram and the forum unigramClassification Features17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  179/206?
Provided by Nabble.com?
Preprocessing of the data:?
Removal Non-English posts?
Removal of posts with a rating of exactly 3 stars?
Binarization of the data into good/bad posts?
Three data sets:?
ALL: All the posts?
SOFT: Posts from the software category at Nabble.com?
MISC: Posts from the other categories?
Data available upon requestData17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  180/206Descriptive Statistics4517.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  181/206?
Stratified tenfold cross validation with different feature sets?
Evaluation measure: mean average precision?
Features were extracted using Apache UIMA?
Classifier:?
LibSVM?
Gauss Kernel?
Parameters C = 10,  ?
= 0.1?
No model selection was performed?
Baseline: Majority class classifierExperiments: Setup17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  182/206Results77,5 74,1 69,2 74,146,564,753,589,1 85,1 82,6 71,8 62,0 61,8 61,872,0 66,0 66,7 66,0 66,0 71,3 66,00,022,545,067,590,0All Forum Specific Syntactic Lexical Similarity Surface BaselineALLSOFTMISC17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  183/206true good true bad sumpred.
good 1517 456 1973pred.
bad 312 1133 1445sum 1829 1589 3418true good true bad sumpred.
good 490 72 562pred.
bad 95 875 970sum 585 947 1532true good true bad sumpred.
good 1231 516 1747pred.
bad 13 126 139sum 1244 642 1886ALLSOFTMISCError Analysis: Confusion Matrix17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  184/206?
Automatically generated mails?
Can be filtered out in preprocessing?
Non-textual content?
May be used as a feature, e.g.
code examples in a software developer?s forum?
Very short posts?
Might be improved through metadata about the user or thread information?
Opinion based ratings?
Ratings based on domain knowledge?
Probably form the upper bound for our approachError Analysis: Typical Errors4617.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  185/206> Thank You for the fast response, but I?m not> sure if I understand you right.
INTERRUPTs can> be interrupted (by other interrupts or signals) and> SIGNALS not.Yup.
And I responded faster than my brain couldshift gears and got my INTERRUPT and SIGNAL crossed.> All my questions still remain!Believe J"org addressed everything in full.
That thecompiler simply can?t know that other routines haveleft zero reg alone and the compiler expects tofind zero there.As for SREG, no telling what another routine wasdoing with the status bits so it too has to be savedand restored before any of its contents possibly getmodified.
CISC CPUs do this for you when stackingthe IRQ, and on RTI.Human rating: -System rating: +Ratings Based on Domain Knowledge17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  186/206> But you would impose US law even in a country> where smoking weed is legalGiven that most of our users and most significant press coverage is American, yes.
That is why I drew the line there.Yes, I know it isn?t perfect.
But it?s better than anything else I?ve seen.
Human rating:  -System rating: +Opinion Based Ratings17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  187/206?
Quality assessment is machine learnable?
The system performs best with forum specific features (~90%)?
Even without forum specific features, the system gives satisfactory result (~82%)?
Further experiments needed on:?
different data sets ?
types of user-generated discourse?
New classification features:?
structure of the forum?
lexical semantic featuresConclusions17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  188/206Introduction: eLearning and NLPAutomatic generation of exercisesAssessment of learner generated discourse  Reading and writing assistanceTutoring systemsWeb 2.0 and computer supported collaborative learningExample e-NLP application: electronic career guidanceOutline4717.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  189/206The SIR project:Semantic Information Retrieval for Electronic Career Guidancefunded by the German Research Foundation17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  190/206Information RetrievalDescriptions of professionsDocuments1.
...2.
..3. ?
Ranked List of ProfessionsEssay about professional interestsQueryElectronic Career Guidance17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  191/206Profession 3Profession 1Profession 2Profession ...EssayProfession ...Profession ...Profession ...Semantic RelatednessI like baking cakes......pastries......confectioner... ...food processing industryVocabulary Mismatch Problem17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  192/206?
Semantic relatedness (SR) as measure for document relevanceLexical-Semantic KnowledgeSemantic Relatedness MeasureInformation Retrieval SystemSemantic IR Models4817.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  193/206Lexical Semantic Knowledge?
GermaNet: German lexical-semantic wordnet ?
Nouns, verbs, adjectives?
27,824 noun synsets, 8,810 verb synsets, 5,141 adjective synsets?
60,646 words in synsets?Wikipedia ?
Free online collaboratively constructed encyclopedia?
Articles, links, categories (Zesch, Gurevych &M?hlh?user, 2007)?Wiktionary?
Free online collaboratively constructed dictionary?Words, categories, semantic relations?
http://www.ukp.tu-darmstadt.de/software/WikipediaAPI17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  194/206Semantic Relatedness Measures?
Path length (PL)?
Pseudo glosses based (Gurevych, 2005)?
Information content based?
Resnik (1995)?
Jiang & Conrath (1997)?
Lin (1998)?
Explicit semantic analysis (Gabrilovich & Markovitch, 2007)17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  195/206Experiments in Information Retrieval A ?Andererseits arbeite ich besonders gerne am Computer, kann programmieren in C, Python und VB und k?nnte mir deshalb auch vorstellen in der Software-Entwicklung zu arbeiten.??
Topics - 30 essays of human subjects about professional interests?
Queries:- Nouns, Verbs, Adjectives- Nouns- Keywords (set of 41 keywords)Profession 3Profession 1Profession 2Profession ...QueryProfession ...Profession ...Profession ...17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  196/206?
Provided by the German Federal Labour Office?
Descriptions of 4,000 professions and 1,800 vocational trainings?
Prepared by professionals?
Evaluation on 529 descriptions of vocational trainings?
Using parts which describe profession itself, but not training or administrative detailsDocument Collection4917.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  197/206?
41 keywords in 3 categories?
Ranked list of professions for each topic ?
Automatically extracted from knowledge base?
Used for creating relevance judgments"Gold Standard"17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  198/20641 Keywords educate, use/program computer, office, outside, animals/plants, ...Essay Profes-sion 1 Profes-sion 2 Profes-sion 3Human AnnotationScoringProfes-sion 1Profes-sion 2 Profes-sion 31.
2.
3. irrelevantrelevantRelevance Judgments17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  199/206?
Standard IR measures using relevance judgements?
Precision ?
recall diagrams?
Mean average precision?
Rank correlation with knowledge-based ranked list?
Spearman?s Rank Correlation Coefficient?
Parameters:?
Pre-processing configurations?
Semantic relatedness measures?
Lexical-semantic knowledge sourcesEvaluation17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  200/206Pre-processing Configurations & Measures, Precision-Recall5017.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  201/206Pre-processing Configurations & MeasuresSpearman?s Rank Correlation00,10,20,30,40,50,6N, V, A Nouns KeywordsEBEB+SYNEB+HypoLINESA-WordESA-Text17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  202/206ESA-Text tf.idf with Different Lexical-Semantic ResourcesNouns,Verbs,Adjectives Nouns Keywords00.050.10.150.20.250.30.350.40.450.50.550.60.65 Mean Average PrecisionWikipediaGermaNet HyperGermaNet RadialWiktionary17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  203/206?
Opportunity for NLP and e-NLP??
Remove knowledge acquisition bottleneck?
New forms of eLearning?
Excellent playground for NLP??
eLearning 2.0 discourse types almost not studied?
Can we actually learn from BioNLP?Some Thoughts on eLearning 2.0?17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  204/206?
Establish an international community?
ACL-associated meeting series (e.g.
ACL-BEA Workshop 2008)?
Related Tutorials?
Resources:?
Bibliography?
Research groups?
Projects?
Annotated corpora?
ToolsHow to Promote e-NLP?5117.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  205/206?A lot more research is done on:?Computer-Assisted Language Learning?
Intelligent Tutoring Systems?
Information search for eLearning?Educational blogging?Annotations and social tagging?Analyzing collaborative learning processes automatically?
Learner?s corpora and resources?
eLearning standards, e.g.
SCORMWhat the tutorial has not covered?17.08.08 |  Computer Science Department | Ubiquitous Knowledge Processing Lab  |  206/206Thank you!
http://www.ukp.tu-darmstadt.de/52
