1.
The numbe r o f  a l l  the poss ib le  s t ruc tures  as afunct ion  o f  the le r~th  o f  the sentenceAe soon as practical applications are coneideredthe efficiency of the parsing method is of fundamentalimportance whether natural or programming languagee areto be proceesed.
The problem of efficiency arises becausethe relationship between the length of e string of symbolsand the number of structures that may in theory beassigned to the string is far from linear, the growingnumber o f  symbols entails a much more rapidly growingnumber of possible structures.For CF ~ s  it is comparatively easy to determinehow the number of structures depends on the length of thestring.
Considering binary branchings only and excludingthe possibilities that arise from having different labelsattached to one node~ i i  ~n- l /is the number of different trees that can be assiEned toa linear string of n elements \[I\].
This means that for ai0 element strin E the number of different trees is slightlyless than 5000, for a 20 element string this numberIbecomes more than 1.75 milliard.To include non-binary branchings as well I suggestthe following recursive formulag/ i f= ~21= 1g/n/= 2 g/21 ~',~I + g/31 j=l ~'jl + ...2... + g/n-2/ j~= g/j/ + F/n-I/ ~ \ ]  + Iwhere n is the number of elements in the string.Accordingly, more than I00 000 different structures canbe assigned to a I0 element string, and 1.6 x 1012different structures to a 20 element s~ ing .Let us stress again that what we have calculatedhere is the number of the essentially differentderivations, i.e.
the number of those yielding differentresults.
The number of possible derivational paths for I0elements is 18 times larger than the number of thedifferent results, for 20 elements the number of pathsis 750 times larger than that of the different structures2.
Syntactic ambiguitiesNatural languages utilize but a small fraction ofthese possibilities.
As to the number of possible stru-ctures of concrete sentences, the syntactic restrictionsare very strong yet far from sufficient ~o yield inform-a~ion for unambiguous assignement.
The number of stru-ctures allowed by the formal syntactic rules is in mostcases definitely larger than the number of structures ahuman being becomes aware of in the course of speech.A well-known point is that unambiguity cannot al-ways be ensured by grammatical means even for artificiallanguages whose structure is immensely less complicated\[2\].
It is worth mentioning that the authors of ALGOL-68decided to let some ambiguities remain in the languageas it could have been eliminated but by making the gram-mar a lot more complicated \[3\].Where does the majority of syntactic ambiguitiesin natural languages come from?I.
There is a number of words with varying scopesand vice versa: some words may fall within thescope of several different words and it cannot bedetermined by formal syntactic means - nor yetby semantic ones at times - whose soope they reallyfall within.
These two things often combine, espe-cially in complex genitive constructions.A fine Russian specimen of which is asloll ows:.
.
.
soze~oTBxe Xpyr-,x SaXoHos ooxl)aweHxa wO000euHoOTell saazuoxeMo~Bzs lao~'x~.
.
.The corresponding string of symbols:Pr g Ag Ng Ng E Ng Ng NgThe rules of reductions:It' _ + - l~g  / i /  Ag MPgliil = NPg/ i v /  ~ + = CIApparently a number of different structures can bedetermined by changing the order of rule epplloatlon.2.
Another source of syntactic ambiguities is thatnot even the string of symbols /categories/ canalways be unambiguously assigned to the sentence,i.e.
homor~ve~ may often appear on  the morphologicallevel.
Homon~m~ arises either because formal diffe-rentiation between parts of speech is absent /e.g.in English/ or because the correspondence of thefunctions of words and the morphological means ofexpressing them is ambiguous, the morphologicalfunctions are not unambiguously expressed/e.g, inRussian/.
Completely independent words with or with-out af f toea .
too  can of course agree in form.Still one seldom comes across a sentence that couldbe assigned several entirely different structures.
Sen-tences of this type are usually puns or grammaticalexamples /cf.
"Time flies like an arrow"/.
It is theso-called local syntactic ambiAnaity that normally troublesus, i.e.
a part of the sentence that can be assignedseveral different part-structures without influencing theremainder  o f  the sentence-s t ruc ture .
Now i f  there  areseveral locally ambiguous parts in the sentence and theyare independent from each other, the number of ambiguitiesfor the whole sentence will considerably increase: it willbe the  ar i thmet ic  product  o f  the numbers o f  independentloca l  ambiguities.3.
~uest ions of tacti.c9The above numeric data c lear ly  show how hops-less it is to simple proceed by checking on all the theo-retically possible structures.
But it is also apparentthat syntax-directed parsing systems will fsil in a con-siderable number of cases just because the sentencestructure is syntactically undetermined E4~.
The develop-ment of an effective analyzer is at least as much amathematical as a linguistic problem.The most important demands a parsing algorithmshould meet are as follows-/i/ It should be able to determine all the conceiv-able parsinge that a given sentence is assigned by aparticular grammar./ii/ It should be consistent in the sense that oneparsing could not be arrived at but in one single way./It should be a 'one-to-one algorithm'.//iii/ In some way or other it should counterbalancethe immense growth of the number of possible structures.The purpose to be strived for is a linear relationshipbetween the steps to be taken and the length of thesentence.The efficiency of the algorithm depends considerablyon factors that are independent of the particular methodone has chosen to apply.
These problems arise with anyalgorithm even if in different forms.
The most important'tactical' questions of this type are as follows:/i/ Aesumin~ a large set of rules how does thealgorithm select the rules that are /possibly/ to beapplied?/ii/ How does it check for the conditions ofapplylnE them?/iii/ How does it recognize 'blind alleys' i.e.illegal paths /if any/?/iv/ How does it return from the illegal path tothe legal one /or to the one that has not proved tobe illegsl as yet/?Some of the well-known methods for solving /i/ areas follows:/a/ Each rule is explicitly assigned the set of rulesby which it could be continued.
But ehoosing thie methodfor s complicated grammar with a large number of possi-bilities one might fsce troubles./b/ The rules are divided into several groups on thebasis of different characteristics such as the number orthe character of the symbols within the rule etc.Searching is then carried out within a comparatively smallset of rules.7/c/ Each symbol is assigned a set of all the rulesthis particular symbol appears in.
Assignment can be doneaccording to the position numbers rithin the rules.
Theso called initial symbols, i.e.
symbols in first position~play then a distinguished role in the rule selection.Whatever method one applies one may choose one ofthe several possible ways of practical realization.
Incase of /c/ the choice made will be of immense importance/e.g.
rules aITanged in matrix form, chainlikerepresentation etc./.Problems /i/ and /ii/ are strongly interconnected.How are we to decide whether the conditions of applying arule are met?In the case of CF grammars checking could be carriedout quite easily.
For top-to-bottom analysis all we haveto do is the identification of the left-hand s idesymbol  ofthe rule.Yo~ bottom-to-top analysis based on normal form CFrules /i.e.
binary branchings/ only, once again it is nottoo difficult to check a twodimensional table for thepossibilities of connecting a pair of symbols.If general form CF or CS grammars are applied, theproblem is not trivial at all, it turns out to be that ofidentifvin~ strir~s of symbols.
It could of course besolved in a trivial way but this would require an awfullot of work to do.
B. DS~ik i  has developed a mostelegant method that would examine a whole series of rulesat ones,.
The checking is performed on Boolean vectors,end the point DSmSlki has made an excellent use of is thatcomputers carry out logical operations on ell the bits ofa machine word at the same time \[Sj.Two subproblems connected with checking rules shouldbe discussed:/a/ When should it start at all?
Suppose that thesymbol string is processed in sequential order/left-to-right or right-to-left/ and a possibly applicablerule or a given context should be checked for.
Then wecould either go back to symbols that have already beenexamined /and check them repeatedly when checking for theapplicability of various ru le~ or have already begun andcompleted certain examinations so that we finishedchecking by the time its result is needed.
/The secondsolution could of course be applied only if an appropriatemechanism automatically provides the checking fo r  theconceivable conditions and the /gradual/ cancelling of thenon-realizable possibilities.//b/ Is some kind of an additional examinationnecessary before the checking is completed?
Namely it mightturn out that the whole checking was superfluous becauseits result cannot be used later on or it will not lead toa correct result.We have come very near to /iii/, i.e.
to how theoccasional impasses /blind alleys/ could be recognized inthe course of the analysis?
This is a cardinal problemconcerning the efficiency of automatic analysis.
Thegrowing length of the sentence /symbol string/ entails notonly a growing number of possible structures but thenumber of inappropriate part-structures growing as well.These 'torsoes' correspond to certain parts of the sentencebut are incompatible with the remainder of it.
What ismore, the longer a sentence the more levels it ma~ havei.e.
the deeper its structure can be.
This holds for theblind alleys as well: the longer the sentence the deeperthe blind alley can be, the more branches and the morevalid elements it m8~ contain.
Sentences that aremonosemantic thoug~ syntactically ambiEuous could hethought of as bottomless blind alleys not yet exploredwhose exploration needs either a wider context or the useof interrelationships not contained in the text.The problem once again becomes twofold:8/ What is the criteriu~ of having got into a blindalley?b/ How could we prevent getting into a blind alleyat least in some cases?The answer to these questions ms~7 be different, ofcourse, for each algorithm and plays a subordinate thonghextremely important role regarding the "strate~" applied.I0Just to give an example I would like to mention amost elegant method of defining end "calculating" thecriterium of blind alleys using an algorithm built up interms of logical vectors.
DSmSlki \[5\] -- who condenses theinformation related to the hypothetically accepted partstructure and to the given symbol string under processinginto s state vector defined recursively -- applies thefollowing criteria to determine the impossibility ofcontinuing the analysis along the given line( , (Q0V B)A H \[xt?
~ = 0Accordingly the new symbol xt+ 1 to be processed mayneither continue the paths the previous vector of statecontained that have proved possible so far, i.e.T(Qt) A H \[Xt?l\] = O, nor begin a new rule, i.e.B^.
=o.The only handleap of DSm51ki's method is that impassescan be recognized only after the algorithm has got intothem -- the algorithm cannot pick out the paths that willlead into an impasse later on.
So we have modified thealgorithm and instead of using DSmSlki~s vector B - thatwould'activate ~ the first position of each of the rules -we let only those of the rules become active that provide/direct or indirect/ continuation of the paths that havealready proved to be legal \[6\].IIExperience so far shows three practical methods of atleast partial avoidance of impasses: #i/ taking intoconsideration the context; /ii/ making use of thetransitive connectivity of the rules; /iii/ checkingahead the number of symbols not yet processed.Taking into consideration the context means makinguse - if possible -- of only one direction of the con-text to avoid the repetition of the tests performed.Today such analyzing grammars play an important role inthe analysis of artificial languages \[TJ.In m~ opinion making use of the transitive joiningof rules has yet mar~y important possibilitiem to offer.P.
Z. Ingerman's analysis is a good example o f  experimentsin this direction \[aj.Taking into consideration the number of symbols notyet processed, saves the analysis mmly unnecessary tests.There have been attempts at doing a preliminary globalanalysis of the complete symbol string on this basis toassess in advance the possibilities of each path of theanalysis \[9\].Finally let us mention the question as the last ofthe questions of tactics:/iv/ How to find the way from an' illegal path backto a legal one?12This is the task that must somehow be solved by theparsing algorithm.
So it is not enough to give a sign or~flag" at the points where the decision may perhaps be afailure.
/i/ It must be ensured that the state prior tocommltt i~ the error is reconstructed.
/ii/ It would beadvantageous to return to the state immediately prior tocommitting the error thus avoiding unnecessary delays.Hever%heless9 there exist fine algorithms with noassurance that every error could be corrected.
One of themis the well-known 'compiler compiler' that would neverreinterpret a part of the symbol string if the part hasonce been accepted, consequently it is unable to recognizecertain structures.
)One of the possible solutions to the problem inquestion is to have the "current state" of the analysisstored whilst proceeding so that it could be accessedlater on.
What we have termed "current state" here mayinclude all the half-finished and abandoned ruleapplications that could be continued only after otherrules have been applied.
Whenever reaching back fora previous "current state" the possibilities that haveceased to exist in the meantime can always be cancelled./The techniques followed for practical realization mayvary depending on the amount of information to be stored,on the msmor~ area available for the working fields~ etc.
(In most cases some kind of a push down store is applied.)134.
The strate~iy of anal~sis I.The problems mentioned so far are common in varyingdegrees for all parsing systems, the ways they are solvedhave no decisive influenc~ o,1 the whole flow of analysis/though they are of decisive importance as far as efficiencyis concerned/.T.V.
Griffiths and S.R.
Petrick base the determinationof the types of parsing systems on two considerations EI~/whilst stressing that 'some procedures are described inthese terms only with difficulty' and 'others seem toallow no such classification'/:/i/ In what direction does the parsing proceed -is it a top-to-bottom or a bottom-to-top analysis?/The third type mentioned - 'direct substitutionalgorithms' - is a subclass of the bottom-to-topalgorithms.//ii/ Does the algorithm apply any means of a preven-tive reduction of the number of blind alleys, i.e.for increasing the 'selectivity' of the algorithm?Their most important findings concerning the effi-ciency of the different types of algorithms are as follows:/a/ Algorithms proceeding from top to bottom -I .
.especially those of the direct substxtutlon type -are the more efficient ones./b/ Methods of increasing selectivity are of nospecial importance in the case of top-to-bottom14analyses but they do considerably increase theefficiency in the case of bottom-to-top analyses./c/ Efficiency is demonetratably influenced by theasymmetxT/left-branching or right-branching/ ofthe structure to be analyzed.
In the case ofanalysis proceeding from top to bottom it is in-fluenced in the reverse direction if comparedwith the analysis proceeding from the bottom up-wards.
/We assume that the analysis proceedseither from right to left in both cases or fromleft to right in both cases./They considered the parsing time of the followingsentence types:ab n anb a% n abncdleft- right- embedding compoun dbranching branching/left-branching/'regressive' /'progressive' with respect toin Yngve's term/ in Yngve's term/ recursivity/+Parsing time as a function of sentence length in-creases - according to Griffiths' and Patrick's date -as follows:*The grammar given would have allowed right recursivityas well /abncdm/ but in the measurements only the aboverestrictions of grammar are dealt with.ab n i ' .... top-to- non-select.
I selective 1bottom q u a d a t i cbottom- I i n e a r Ito-top ~.
Ia%non-select, selectivel inearexponential linear/IaSA / \b/ \ba/S\~/ \8 ".\Btop-to-bottombottom-to-topanb n abncdnon-select, selectivel inearexp?
linearnon-select, selectiveexponent ia lexp.
cubica/~\ba S b/ \a bA/ \  B/ \  I\~A bB?
.
\  b in  A" bIa16According to GrifTiths's and Patrick's data it isthe bottom-to-top selective parser alone that is able toanalyze sentences of the last, comparatively simple typegrammar with a better than exponential efficiency.What are the underlying reasons for the resultsobtained by Griffiths and Petrick?/I/ Bottom-to-top algorithms are characterized by thefact that they take their start from what actually existsinstead of looking for what "could be" ~llJ.In the case of exceedingly extensive ATsm~ars thetop-to-bottom analysis must work with a huge number ofpotential possibilities and the elements of the symbolstring to be analyzed will but slowly filter out thepossibilities that may not be realized./ii/ Selectivity, in the sense Oriffiths and Petrickuse the term, does not influence all this to any degree asthe :filtering on the basis of a precedence-matrix extendsonly to testiv~ the first element.
It will be shown lateron that selectivity can be considerably increased and,going even further, it could be made the basis of thestrategy of the analysis./iii/ In the case of bottom-to-top analysis thesituation is entirely different.
Here the seeminglyidentical apparatus works with a much greater efficiency.t/ /the nook  ead" condition s ested by  etian17/i.e.
the possiblli~y of the resultant symbol aohlevingits aim oheok~ the uompatlblllty/ one level higher up andthe  d i s tanoe  from the  top  i s  so muoh less .
/b /  Here on17euoh ru les  a re  to  be rea l i sed  in  whioh a l l  the  oomponentsoan be found,  the  o thers  a re  omi t ted  in  the  oourse  o f  theru le  oont ro l s .
I t  i s  out  o f  the  quest ion  there for  to  regardth i s  ee leot iv i~y  as  ana logoue w i th  the  top- to -bot tom se -leetlvi~y that is based on the flret ~ i  of the lowestlevel./iv/ Griffiths'e and Patrick's measurements of theeffect of the asymmetry of sentences on the efficiency ofthe analysis are a practical justification of an observationI made in 1964.
In an article about Yngve's hypothesis ~13jI developed the idea that for lar~uages that have mostly"progressive" /right-branching/ structures it is the right-to-left analysis that is more effective in the case of ana-lysis from bottom to top.
/The right-to-left analysis isequivalent of course with a left-to-right analysis in esystem that is a mirror image of the original./In case of pure structures the explanation of thephenomenon is simple: In a right-branching structure thenumber of erroneous linkinge is started at the end of asentence.
Let us take the example from the above mentionedarticle of mine:8HasTe  \ ]~opo TeopeM o l lpe~ezez .18Its processing from right to left is very simple:8HeeTe lmoPo Teopex  o npexe laxJJ\]If, however, the analysis is started from thebeginning of the sentence we get erroneous /or incomplete/linkages again and again:\]~K BHeeTeaHaeTe ~OrOMsoro ~eope~In the case of complex structures the situation ismore complicated.
In this case the effectivity greatlydepends on the method used for eliminating the impasses./On the disadvantages of vertical analysis see thenext para~rraph.
/195o The strategy of ~s is  II.When determining the type of analysis apart from itsstarting point it is also very important to know alongwhat paths the analysis proceeds towards its goal, or inother words in what sequence the tests are carried outtogether with the inseparable question of in what form orstructure the part-results su'e stored.On the basis of these considerations there are twobasic types of Parsers.In theory this classification isindependent of the fact whether the analysis proceeds fromthe bottom upwards or from the top downwards./i/ Those parsezs that proceed with "msxim~ width"from level to level working on the full symbol string,first produce all the reductions that may be achieved byapplying a single rule~ than those that may be obtained byapplying two rules and so on until the part-structu_~es thusobtained are &Tadually linked.
/In the analysis thatproceeds from top downwards, these correspond to thederivations produced by applying two, there, ... rules,followed by the comparison of the terminal symbols thusobtained with the symbol string being analyse~.//ii/ The ps.rse~sthat proceed with a "minimum width"and the "steepest slope', while gradually extending the20elements of the symbol string take the first opportunityto apply a rule and will not extend the analysis to a newsymbol until there are new rules that could be built onthe rules applied so far.We could mention as an example for the first methodthe ~kai-Nagao algorithm \[14\] \[15\] the Cocks algorithm\[16\] or its application by Kuno to context sensitivelanguages \[17\]/the same strategy is applied by Vsuquois inhis analysis of Russian/.
The algorithms by Woods \[18\] byBoracsev \[19\] and the DSmalki-Varga algorithms \[5\] \[6\] areexnmples of the second method.Both methods have their advantages and disadvantages;perhaps it may be :useful to draw the attention to them.The great advantage of the analysis that proceedsfrom level to level is the ease with which in case ofappropriate storage the part-analyses that could becontinued alon E the same line, are contracted /seeGriffiths-Petrick: "Merging similar sections of different\[ =ing  aohine\] pathsV.Its disadvantage is the fact thata/ relatively large number of independent part structureshas to be stored,b/ it needs relatively lengthy tests to detemine whetherthe individual part structures are compatible.21The strategy of "maximal hierarchization" is moreadvantageous beyond doubt as far as econom~ in storage isconcerned because in this case s single push down storewill suffice to store the results and all the paths thathave proved incorrect may be removed once and for all fromthe push down store together with all the derivations.
Thisprinciple may be formalized as follows.Let us denote according to inverse Polish notationthe result of the rule applied to the elements8 k ak+l.., ak.
r with the result B m asra k ak+ I... ak+ r B m ?
In other words let %heelements of the symbol string that we applied the ruleremain in the symbol string and let us simply add to theend of the string the symbol obtained as the result of therule application.Accordingly the resulting symbol string will bemini al'''ai ~ i  r l&  iafter applying the first applicable rule,Let us suppose that there are a% most m-I moreapplicable rules following the first one while no newsymbol is read /m- ~ O/The symbol string will becomerl rm i%...a i ... Bm.
rj- m 122~Fnile continuing the application of this principlethe symbol string will be increased by new terminal andnon-terminal symbols:r m r .al.." ai i .. Bm ai+l aj o rain sin max j m i .
.
.
.
;~I  r rj Brm+l r nmaXn mini maxm minl 81"'" ai "''Bin m ai+l'''aj m+l BnIf the analysis gets into an impasse and cannot continue,rthen we have to return to the symbol BsS last applied,remove it and continue the analysis applying the aboveprinciple.
/First an attempt is made at applying anotherpermissible rule in the same place and only if this failsshall we take a new a t symbol end continue the analysis./The return from an impasse always means the deletionof the last non-terminal symbol and the reconstruction ofthe symbol string following it.
/We would like to mentionthat this principle of analysis may be quite easily adoptedto analyze context sensitive languages as well/.This undoubtedly elegant principle of applicationproduces the first possible analysis relatively rapidly,in its canonic form.The increased selectivity of the analysis gives us aprocedure that could be very well used in practicalapplications.
Going further, having obtained the first23analysis if the analysis is continued on the same principles/just as if the first correct analysis were in an impasse/all the other analysis ms,V be likewise produced.The disadvantages of the applied strategy of analysisare as follows:/a/ If right at the beginning of the analysis we havetaken an incorrect path, then the correction of this errormay only be done after all the following and in partindependent applications of the rules have been ideleSad.
Thismeans that the correct, or perhaps the only possible part-results are lost: after putting the error right they haveto  be re-generated./b/ The position is somewhat similar as far as theerroneous part-results are concerned: the analysis may getinto a "local" impasse several times./c/ A new, different system of storage and searchingmust be provided if we wish to ensure a newer generationof the Identloalcontinuations -- supposing that previouslysome kind of a change took place in the determinedstructure.246.
A new strateKy su~j~ested for analyzin~CF lanAmaKesThe exponential increase in the time of analysis invarious systems of analysis is obviously due to theincrease in the number and depth of impasses, to theirvarious branches-- in short to their dangerousnessincreasing with the length of the symbol string.This is the dangerous point I tried to dodge byelaborating a parsing system that applies selectivity notas an additional device for increasing the efficiency ofsome method but as an independent method itself.The linesrity of the increase in the process ofanalysis may be best achieved if the symbol string to beanalyzed can be segmented in accordance with the highestlevel rules applicable and these parts could be analyzedsepsratedly.
If several parsings can be assigned to any ofthese segments /cf.
what we have said about homor~ym~ on p.5/the structures corresponding to the whole sentence can beproduced from the local part-results by combinatoricalmeans.Segmentation requires the following apparatus:/i/ the transitive Initial matrix of the rulesIBla, n/l/ii/ the transitive continuation matrix of the rules/c/a,n//25/iii/ the transitive end matrix of the rules /E/a,n///ivy/ the transitive Initial matrix of the i thru le  component /Bila,n//Ivl/ the transitive continuation matrix of the i thcomponent /Ci/a,n///vii/ the transitive end matrix of the i th component/Ei/a,n///vii/ the matrix of the number of rule components/Vii ~n/lThe structure of the transitive initial ma?rix ofthe rules is almost the same as that of the so calledprecedence /or complete connectivity/ matrix.
Thedifferences show up in two fao%s,namelya/ the lines correspond to the terminal elements onlyand not to all the elements of the vocabulary V;b/ the columns are assigned to rules of the grammarand not to the symbols.Thus it is a Boolean matrix B/a,n/; its elementB/a,n/ is a truth function whose value is t if and onlyif the grammar allows the terminal symbol ~ to be the ?firstelement of the terminal rewritin~ of the n th rule.The transitive continuation matrix of the rulesC_/a,n/ is a Boolean matrix whose element C/a,D/ is t if endonly if the terminal symbol a is whichever but not thefirst element of the terminal strings of the n th rule.The value of an element E/a,rg of the transitive end26matrix of the rules is t if and only if the terminalsymbol a can be the last element of the terminal stringsof the n th rule.It follows from the definition thatB/ap,n/ = E/ap,n/ and C/aq,n/ = E/aq,n/may occur but B /~,n /  = E/ap,n/ = C/sp,n/ may not.The Initial, continuation and end matrices of therule components can be defined in s similar way, so itwill be sufficient to give the definition of the init ialmatrix of the i th rule component:The value of an element B i /a,n/ of the in i t ia lmatrix of the i th rule component B i /a,n/ is t if andonly if the non-terminal symbol a ms~v be first elementof the terminal strings of the i th direct component ofthe n th rule.The line of thought of the algorithm is as follows:Tests ape carried out on two levels: on the level ofinter-Pule linkages /from top downwards/ and on the levelof inter-terminal-symbol linkages /from left to right/.
Ineach successive step of the test the individual componentsof the rules are made to correspond in the sequence of thecomponents to a certain series of the terminal symbols ofwhich the given component may be built up.
By continuingthis process finally either we arrive st the terminal endingin case of all oomponents or the given segmentation is found27to be incorrect.In case of incorrect segmentation first thepermissible branches of the latest segmentation are testedby the algorithm.
In our experience the selectivity of thesystem is considerable.
Therefore even the storage ofrelatively small quantity of information allows a rapidexamination of all the possibilities.During segmentation we apply a "principle ofsegmentation" that is analogous "4;o the principlediscussed in connection with the "maximum hierarchization":the shortest component that is nearest to the beginning ofthe seEment or to the end of the previous component, istaken and used until it becomes evident that for somereason the given segmentation is not applicable.
In thiscase an attempt is made at solving the situation byshifting the last border of segmentation to the right: onlyif this leads to no result, is the previous border ofsegmentation changed.
The outstanding effectivity of themethod applied is due to8/ making best use of the bottle-neck for thereduction in analyzing t im;h/ the fact that the tests for the possibilities ofvarious part-segmentations can be quick lyperformed;c/ the possibility of testin~ each segment incomplete separation from all the other segments;d/ the fact that the twoaided approach leads to muchfewer unnecessqry pert results than either Cock'sor the well-known top-to-bottom algorithms.28BiblioEraph~1 Berge, C. Th~orie des graphes et see applications,Dunod, Paris, 1958.M Ginsburg, S. The Mathematical Theory of Context-FreeLanguages, McGraw Hill, New York, 1966.3 Algol-68.
MR 95.
/mimeographed/4 Shrejder, Ju.
A. Teorija tolerantnosti, Nauchno-Texnieheskaja Informacija, Ssro 25 DSmSlki, B. Voprosy sintaksicheekogo analiza dljsformal'nyx jazykov, Computational Linguistics 5,pp.
41-93.6 Varga, D. Problems of Machine Analysis, LinguisticaAntverpiensia If.
pp.
415-428.7 Knuth, D.E.
On the Translation of Languages fromLeft to Right, Information and Control Vol.
8,NO 6, pp.
607-639.Kaufman, V. Sh.
0 raspoznavanii nekotoryx svojstvkontekstno-svobodnyx grammatik, l-ya Vsssojuznajakonferencija po programmirovaniju, Kiev, 1968.8 Ir~erman, P.Z.
A Syntax-Oriented Translator, AcademicPress, New York, 1966.9 Unger, S.H.
A Global Parser for Context-Free PhraseStructure Grammars, Comm.
ACM, Vol.
ii, No 4, pp.240-247.I0 Griffiths, T.V., Petrick, S.R.
On the RelativeEfficiencies of Context-Free Grammar Recognizers,Comm.
ACM, Vol.
8.
No 5, pp.
289-300?ii Cf.
Vakulovskaja, G.V., Kulagina, O.S.
Ob odnom al-gori1~e sintaksicheskogo analiza russkix tekstov,Proble~ kibernetiki 18, p. 218.12 Bast ian ,  L. A Phrase-St ructure  La~uage Trans la tor ,AFCRL Rep. 62-549, AF Cambridge Research Labs.
,Bedford, Aug. 1962.13 rares , D. Yr~ve's Hypothesis and Some Problems ofthe Mechanical Analys is ,  Computational L ingu is t i cs3, pP.
47-72.14 Sakai ,  I .
Syntax  inUn iversa l  T rans la t ion ,  PrOeo1961 In ternat .
conf.
on MT of  LanguaEes andApplied Language Analysis, London, 1962, pp.
59~-608o15 NeEao, M. Studies on LanEuaEe Analysis Procedure endCharectel- Recognition, Eyoto University, 1965.16 Cf?
Hsys, D.G.
Automatic ~e-Data  Processing,Computer Appllcatlons in the Behsviorel Sciences tPrentice-He11, Englewood Cliffs, N.J., 1962, pp.394-421.17 Kuno, S?
A Context-Sensitive Reco~ition Procedure,NSF-18, &u~.
1967.
VII-I-28o18 Woods~ W.A.
Context-Sensitlve ReeoEnition~ NSF-18??ug?
1967.
VIII-I-23.19 Borsceev, V.B?, Efimova, E.N., 0 sokreshchenil pete-bore prl sinteksicheskom anallze, Neuchno-Texni-cheskaje Informacija, 1967, No I0, pp.
27-33.
