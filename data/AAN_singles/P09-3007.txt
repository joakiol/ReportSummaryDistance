Proceedings of the ACL-IJCNLP 2009 Student Research Workshop, pages 54?62,Suntec, Singapore, 4 August 2009.c?2009 ACL and AFNLPAccurate Learning for Chinese Function Tags from Minimal FeaturesCaixia Yuan1,2, Fuji Ren1,2and Xiaojie Wang21The University of Tokushima, Tokushima, Japan2Beijing University of Posts and Telecommunications, Beijing, China{yuancai,ren}@is.tokushima-u.ac.jpxjwang@bupt.edu.cnAbstractData-driven function tag assignment hasbeen studied for English using Penn Tree-bank data.
In this paper, we addressthe question of whether such method canbe applied to other languages and Tree-bank resources.
In addition to simplyextend previous method from English toChinese, we also proposed an effectiveway to recognize function tags directlyfrom lexical information, which is eas-ily scalable for languages that lack suf-ficient parsing resources or have inher-ent linguistic challenges for parsing.
Weinvestigated a supervised sequence learn-ing method to automatically recognizefunction tags, which achieves an F-scoreof 0.938 on gold-standard POS (Part-of-Speech) tagged Chinese text ?
a statisti-cally significant improvement over exist-ing Chinese function label assignment sys-tems.
Results show that a small numberof linguistically motivated lexical featuresare sufficient to achieve comparable per-formance to systems using sophisticatedparse trees.1 IntroductionFunction tags, such as subject, object, time, loca-tion, etc.
are conceptually appealing by encodingan event in the format of ?who did what to whom,where, when?, which provides useful semantic in-formation of the sentences.
Lexical semantic re-sources such as Penn Treebank (Marcus et al,1994) have been annotated with phrase tree struc-tures and function tags.
Figure 1 shows the parsetree with function tags for a sample sentence formthe Penn Chinese Treebank 5.01(Xue et al, 2000)(file 0043.fid).1released by Linguistic Data Consortium (LDC) catalogNO.
LDC2005T01Figure 1: Simplified parse tree with function tags(in black bold) for example sentence.When dealing with the task of function tagassignment (or function labeling thereafter), onebasic question that must be addressed is whatfeatures can be extracted in practice for distin-guishing different function tag types.
In answer-ing this question, several pieces of work (Blahetaand Charniak, 2000; Blaheta, 2004; Merlo andMusillo, 2005; Gildea and Palmer, 2002) havealready been proposed.
(Blaheta and Charniak,2000; Blaheta, 2004) described a statistical sys-tem trained on the data of Penn Treebank to au-tomatically assign function tags for English text.The system first passed sentences through an au-tomatic parser, then extracted features from theparse trees and predicted the most plausible func-tion label of constituent from these features.
Not-ing that parsing errors are difficult or even impos-sible to recover at function tag recognition stage,the alternative approaches are obtained by assign-ing function tags at the same time as producingparse trees (Merlo and Musillo, 2005), throughlearning deeper syntactic properties such as finer-grained labels, features from the nodes to the leftof the current node.Through all that research, however, success-fully addressing function labeling requires accu-rate parsing model and training data, and the re-54sults of them show that the performance ceil-ing of function labeling is limited by the parsersthey used.
Given the imperfection of existingautomatic parsers, which are far from producinggold-standard results, function tags output by suchmodels cannot be satisfactory for practical use.The limitation is even more pertinent for the lan-guages that do not have sophisticated parsing re-sources, or languages that have inherent linguisticchallenges for parsing (like Chinese).
It is there-fore worthwhile to investigate alternatives to func-tion labeling for languages under the parsing bot-tleneck, both in terms of features used and effec-tive learning algorithms.In current study, we focused on the use ofparser-independent features for function labeling.Specifically, our proposal is to classify functiontypes directly from lexical features like words andtheir POS tags and the surface sentence informa-tion like the word position.
The hypothesis thatunderlies our proposal is that lexical features areinformative for different function types, and cap-ture fundamental properties of the semantics thatsometimes can not be concluded from the glanceof parse structure.
Such cases come when distin-guishing phrases of the same structure that differby just one word ?
for instance, telling ?3??
(in Shanghai)?, which is locative, from ?3?(in May)?, which is temporal.At a high level, we can say that class-based dif-ferences in function labels are reflected in statisticsover the lexical features in large-scale annotatedcorpus, and that such knowledge can be encodedby learning algorithms.
By exploiting lexical in-formation collected from Penn Chinese Treebank(CTB) (Xue et al, 2000), we investigate a super-vised sequence learning model to test our core hy-pothesis ?
that function tags could be guessed pre-cisely through informative lexical features and ef-fective learning methods.
At the end of this pa-per, we extend previous function labeling meth-ods from English to Chinese.
The result proves, atleast for Chinese language, our proposed methodoutperforms previous ones that utilize sophisti-cated parse trees.In section 2 we will introduce the CTB re-sources and function tags used in our study.
Insection 3, we will describe the sequence learn-ing algorithm in the framework of maximum mar-gin learning, showing how to approximate func-tion tagging by simple lexical statistics.
Section 4Table 1: Complete set of function labels in Chi-nese Treebank and function labels used in our sys-tem (selected labels).type labels in CTB selected labelsclause types IMP imperativeQ question(function/form)ADV adverbial?discrepanciesgrammatical roles EXT extent?FOC focus?IO indirect object?OBJ direct object?PRD predicate?SBJ subject?TPC topic?adverbials BNF beneficiary?CND condition?DIR direction?IJ interjective?LGS logic subject?LOC locative?MNR manner?PRP purpose/reason?TMP temporal?VOC vocative?miscellaneous APP appositiveHLN headlinePN proper namesSHORT short formTTL titleWH wh-phrasegives a detailed discussion of our experiment andcomparison with pieces of related work.
Some fi-nal remarks will be given in Section 5.2 Chinese Function TagsThe label such as subject, object, time, location,etc.
are named as function tags2in Penn Chi-nese Treebank (Xue et al, 2000), a complete listof which is shown in Table 1.
Among the 5 cat-egories, grammatical roles such as SBJ, OBJ areuseful in recovering predicate-argument structure,while adverbials are actually semantically orientedlabels (though not true for all cases, see (Merloand Palmer, 2006)) that carry semantic role infor-mation.As for the task of function parsing, it is reason-able to ignore the IMP and Q in Table 1 since theydo not form natural syntactic or semantic classes.In addition, we regard the miscellaneous labels asan ?O?
label (out of any function chunks) like la-beling constituents that do not bear any function2The annotation guidelines of Penn Chinese Treebank talkof function tags.
We will use the term function labels andfunction tags identically, and hence make no distinction be-tween function labeling and function tagging throughout thispaper.
Also, the term function chunk signifies a sequence ofwords that are decorated with the same function label.55tags.
Punctuation marks like comma, semi-colonand period that separate sentences are also denotedas ?O?.
But the punctuation that appear within onesentence like double quotes are denoted with thesame function labels with the content they quote.In the annotation guidelines of CTB (Xue et al,2000), the function tag ?PRD?
is assigned to non-verbal predicate.
Since VP (verb phrase) is alwayspredicate, ?PRD?
is assumed and no function tagis attached to it.
We make a slight modification tosuch standard by calling this kind of VP ?verbalpredicates?, and assigning them with function la-bel ?TAR (target verb)?, which is grouped into thesame grammar roles type with ?PRD?.To a large extent, PP (preposition phrase) al-ways plays a functional role in sentence, like ?PP-MNR?
in Figure 1.
But there are many such PPsbare of any function type in CTB resources.
Likein the sentence ?'c?
?O 25% (increaseby 25% over the same period of last year)?, ?'c??
(over the same period of last year)?
is la-beled as ?PP?
in CTB without any function labelsattached, thus losing to describe the relationshipwith the predicate ?O (increases)?.
In order tocapture various relationships related to the predi-cate, we assign function label ?ADT (adjunct)?
forthis scenario, and merge it with other adverbialsto form adverbials category.
There are 1,415 suchcases in CTB resources, which account for a largeproportion of adverbials types.After the modifications discussed above, in ourfinal system we use 20 function labels3(18 origi-nal CTB labels shown in Table 2 and two newlyadded labels) that are grouped into two types:grammatical roles and adverbials.We calculate the frequency (the number of timeseach tag occurs) and average length (the averagenumber of words each tag covers) of each func-tion category in our selected sentences, which arelisted in Table 2.
As can be seen, the frequency ofadverbials is much smaller than that of grammati-cal roles.
Furthermore, the average length of mostadverbials are somewhat larger than 4.
Such datadistribution is likely to be one cause of the loweridentification accuracy of adverbials as we will seein the experiments.From the layer of function labeling, sentences3ADV includes ADV and ADVP in CTB recourses,grouped into adverbials.
In function labeling level, EXT thatsignifies degree, amount of the predicates should be groupedinto adverbials like in the work of (Blaheta and Charniak,2000) and (Merlo and Musillo, 2005).Table 2: Categories of function tags with their rel-ative frequencies and average length.Function Labels Frequency Average Lengthgrammatical roles 99507 2.62FOC 133 1.89IO 126 1.26OBJ 25834 4.15PRD 4428 5.20SBJ 23809 3.02TPC 676 3.51TAR 44501 1.25adverbials 33287 2.11ADT 1415 4.51ADV 21891 1.32BNF 465 4.66CND 68 3.15DIR 1558 4.68EXT 1048 1.99IJ 1 1.00LGS 204 5.42LOC 2051 4.27MNR 1053 4.48PRP 224 4.91TMP 3309 2.25in CTB are described with the structure of ?SV?which indicates a sentence is basically composedof ?subject + verb?.
But in order to identify objectsand complements of predicates, we express sen-tence by ?SVO?
framework in our system, whichregards sentence as a structure of ?subject + verb +object?.
The structure transformation is obtainedthrough a preprocessing procedure, by upgradingOBJs and complements (EXT, DIR, etc.)
whichare under VP in layered brackets.3 Learning Function LabelsFunction labeling deals with the problem of pre-dicting a sequence of function tags y = y1, ..., yT,from a given sequence of input words x =x1, ..., xT, where yi?
?.
Therefore the functionlabeling task can be formulated as a stream of se-quence learning problem.
The general approachis to learn a w-parameterized mapping functionF : X?Y ?
< based on training sample of input-output pairs and to maximize F (x, y;w) over theresponse variable to make a prediction.There has been several algorithms for label-ing sequence data including hidden Markov model(Rabiner, 1989), maximum entropy Markov model(Mccallum et al, 2000), conditional random fields(Lafferty et al, 2001) and hidden Markov supportvector machine (HM-SVM) (Altun et al, 2003;Tsochantaridis et al, 2004), among which HM-SVM shows notable advantages by its learning56non-linear discriminant functions via kernel func-tion, the properties inherited from support vec-tor machines (SVMs).
Furthermore, HM-SVMretains some of the key advantages of Markovmodel, namely the Markov chain dependencystructure between labels and an efficient dynamicprogramming formulation.In this paper we investigate the application ofthe HM-SVM model to Chinese function labelingtask.
In order to keep the completeness of paper,we here address briefly the HM-SVM algorithm,more details of which could be founded in (Altunet al, 2003; Tsochantaridis et al, 2004), then wewill concentrate on the techniques of applying it toour specific task.3.1 Learning ModelThe framework from which HM-SVM are derivedis a maximum margin formulation for joint fea-ture functions in kernel learning setting.
Given nlabeled examples (x1, y1), ..., (xn, yn), the notionof a separation margin proposed in standard SVMsis generalized by defining the margin of a train-ing example with respect to a discriminant func-tion F (x, y;w), as:?i= F (xi, yi;w)?maxy/?yiF (xi, y;w).
(1)Then the maximum margin problem can be de-fined as finding a weight vector w that maxi-mizes mini?i.
By fixing the functional margin(maxi?i?
1) like in the standard setting of SVMswith binary labels, we get the following hard-margin optimization problem with a quadratic ob-jective:minw12||w||2, (2)with constraints,F (xi, yi;w)?
F (xi, y;w) ?
1,?ni=1,?y 6=yi.In the particular setting of SVM, F is as-sumed to be linear in some combined featurerepresentation of inputs and outputs ?
(x, y), i.e.F (x, y;w) = ?w,?
(x, y)?.
?
(x, y) can bespecified by extracting features from an obser-vation/label sequence pair (x, y).
Inspired byHMMs, we propose to define two types of fea-tures, interactions between neighboring labelsalong the chain as well as interactions between at-tributes of the observation vectors and a specificlabel.
For instance, in our function labeling task,we might think of a label-label feature of the form?
(yt?1, yt) = [[yt?1= SBJ ?
yt= TAR]], (3)that equals 1 if a SBJ is followed by a TAR.
Anal-ogously, a label-observation feature may be?
(xt, yt) = [[yt= SBJ ?
xtis a noun]], (4)which equals 1 if x at position t is a noun and la-beled as SBJ.
The described feature map exhibitsa first-order Markov property and as a result, de-coding can be performed by a Viterbi algorithm inO(T |?|2).All the features extracted at location t are sim-ply stacked together to form ?
(x, y; t).
Finally,this feature map is extended to sequences (x, y) oflength T in an additive manner as?
(x, y) =T?t=1?
(x, y; t).
(5)3.2 FeaturesIt deserves to note that features in HM-SVMmodel can be easily changeable regardless of de-pendency among them.
In this prospect, featuresare very far from independent can be cooperatedin the model.By observing the particular property of functionstructure in Chinese sentences, we design severalsets of label-observation features which are inde-pendent of parse trees, namely:Words and POS tags: The lexical context is ex-tremely important in function labeling, as indi-cated by their importance in related task of phrasechunking.
Due to long-distance dependency offunction structure, intuitively, more wider con-text window will bring more accurate prediction.However, the wider context window is more likelyto bring sparseness problem of features and in-crease computation cost.
So there should be aproper compromise among them.
In our experi-ment, we start from a context of [-2, +2] and thenexpand it to [-4, 4], that is, four words (and POStags) around the word in question, which is closestto the average length of most function types shownin Table 2.Bi-gram of POS tags: Apart from POS tags them-selves, we also try on the bi-gram of POS tags.
Weregard POS tag sequence as an analog to function57chains, which reveals somewhat the dependent re-lations among words.Verbs: Function labels like subject and objectspecify the relations between verb and its argu-ments.
As observed in English verbs (Levin,1993), each class of verb is associated with a setof syntactic frames.
Similar criteria can also befound in Chinese.
In this sense, we can rely onthe surface verb for distinguishing argument rolessyntactically.
Besides the verbs themselves, wealso take into account the special words sharingcommon property with verbs in Chinese language,which are active voice ?r(BA)?
and passive voice?(BEI)?.
The verb we refer here is supposed tobe the last verb if it happens in a consecutive verbsequence, thus actually not the head verb of sen-tence.POS tags of verbs: according to CTB annota-tion guideline, verbs are labeled with four kindsof POS tags (VA, VC, VE, VV), along with BA(for ?r?
), LB and SB (for ??).
This featuresomewhat notifies the coarse class of verbs talkedin (Levin, 1993) and is taken into account as fea-ture candidates.Position indicators: It is interesting to notice thatwhether the constituent to be labeled occurs beforeor after the verb is highly correlated with gram-matical function, since subjects will generally ap-pear before a verb, and objects after, at least forChinese language.
This feature may overcome thelack of syntactic structure that could be read fromthe parse tree.In our experiment, all feature candidates are in-troduced to the training instances incrementally bya feature inducing procedure, then we use a gain-driven method to decide whether a feature shouldbe reserved or deleted according to the increase ordecrease of the predication accuracy.
The proce-dure are described in Figure 2.Figure 2: Pseudo-code of feature introducing pro-cedure.1: initialize feature superset C={all feature candidates},feature set c is empty2: repeat3: for each feature ci?
C do4: construct training instances using ci?
cexperiment on k-fold cross-validation data5: if accuracy increases thenci?
c6: end if7: end for8: until all features in C are traversed4 Experiment and DiscussionIn this section, we turn to our computational ex-periments that investigate whether the statisticalindicators of lexical properties that we have devel-oped can in fact be used to classify function labels,and demonstrate which kind of feature contributesmost in identifying function types, at least for Chi-nese text.As in the work of (Ramshaw and Marcus,1995), each word or punctuation mark within asentence is labeled with ?IOB?
tag together withits function type.
The three tags are sufficient forencoding all constituents since there are no over-laps among different function chunks.
The func-tion tags in this paper are limited to 20 types, re-sulting in a total of |?| = 41 different outputs.We use three measures to evaluate the modelperformance: precision, which is the percentageof detected chunks that are correct; recall, whichis the percentage of chunks in the data that arefound by the tagger; and F-score which is equal to2?precision?recall/(precision+recall).
Un-der the ?IOB?
tagging scheme, a function chunkis only counted as correct when its boundaries andits type are both identified correctly.
Furthermore,sentence accuracy is used in order to observe theprediction correctness of sentences, which is de-fined as the percentage of sentences within whichall the constituents are assigned with correct tags.As in the work of (Blaheta and Charniak, 2000)and (Merlo and Musillo, 2005), to avoid calcu-lating excessively optimistic values, constituentsbearing the ?O?
label are not counted in for com-puting overall precision, recall and F-score.We derived 18,782 sentences from CTB 5.0with about 497 thousands of words (includingpunctuation marks).
On average, each sentencecontains 26.5 words with 2.4 verbs.
We followed5-fold cross-validation method in our experiment.The numbers reported are the averages of the re-sults across the five test sets.4.1 Evaluation of Different Features andModelsIn pilot experiments on a subset of the features,we provide a comparison of HM-SVM with othertwo learning models, maximum entropy (Max-Ent) model (Berger et al, 1996) and SVM model(Kudo, 2001), to test the effectiveness of HM-SVM on function labeling task, as well as thegenerality of our hypothesis on different learning58Table 3: Features used in each experiment round.FT1 word & POS tags within [-2,+2]FT2 word & POS tags within [-3,+3]FT3 word & POS tags within [-4,+4]FT4 FT3 plus POS bigrams within [-4,+4]FT5 FT4 plus verbsFT6 FT5 plus POS tags of verbsFT7 FT6 plus position indicatorsmodels.In our experiment, SVMs and HM-SVM train-ing are carried out with SVMstructpackages4.
Themulti-class SVMs model is realized by extend-ing binary SVMs using pairwise strategy.
Weused a first-order of transition and emission depen-dency in HM-SVM.
Both SVMs and HM-SVMare trained with the linear kernel function and thesoft margin parameter c is set to be 1.
The MaxEntmodel is implemented based on Zhang?s MaxEnttoolkit5and L-BFGS (Nocedal, 1999) method toperform parameter estimation.Figure 3: Sentence accuracy achieved by differentmodels using different feature combinations.We use sentence accuracy to compare perfor-mances of three models with different featurecombinations shown in Table 3.
The learningcurves in Figure 3 illustrate feature combinationFT7 gains the best results for all three modelswe considered.
As we have expected, the perfor-mance improves as the context window expandedfrom 2 to 4 (from FT1 to FT3 in Figure 3).
Thesentence accuracy increases significantly when thefeatures include verbs and position indicators, giv-4http://svmlight.joachims.org/s vm multiclass.html5http://homepages.inf.ed.ac.uk/s0450736/maxent toolkit.htmling some indication of the complexity of the struc-ture intervening between focus word and the verb.However, at a high level, we can simply say thatany further information would help for identifyingfunction types, so we believe that the features wedeliberated on currently are by no means the solelyoptimal feature set.As observed in Figure 3, the structural sequencemodel HM-SVM outperforms multi-class SVMs,meanwhile, they both perform slightly better thanMaxEnt model, demonstrating the benefit of max-imum margin based approach.
In the experimentbelow, we will use feature FT7 and HM-SVMmodel to illustrate our method.4.2 Results with Gold-standard POS TagsBy using gold-standard POS tags, this experimentis to view the performance of two types of func-tion labels - grammatical roles and adverbials, andfine-grained function types belonging to them.
Wecite the average precision, recall and F-score of5-fold cross validation data output by HM-SVMmodel to discuss this facet.Table 4: Average performance for individual cat-egories, using HM-SVM model with feature FT7and gold-standard POS tags.Precision Recall F-scoreOverall 0.934 0.942 0.938grammatical roles 0.949 0.960 0.955FOC 0.385 0.185 0.250IO 0.857 0.286 0.429OBJ 0.960 0.980 0.970PRD 0.985 0.988 0.987SBJ 0.869 0.912 0.890TPC 0.292 0.051 0.087TAR 0.986 0.990 0.990adverbials 0.887 0.887 0.887ADT 0.690 0.663 0.676ADV 0.956 0.955 0.956BNF 0.729 0.869 0.793CND 0.000 0.000 0.000DIR 0.741 0.812 0.775EXT 0.899 0.820 0.857LGS 0.563 0.659 0.607LOC 0.712 0.721 0.716MNR 0.736 0.783 0.759PRP 0.656 0.404 0.500TMP 0.821 0.808 0.814Table 4 details the results of individual functiontypes.
On the whole, grammatical roles outper-form adverbials.
It seems to reflect the fact that59syntactic constituents can often be guessed basedon POS tags and high-frequency lexical words,largely avoiding sparse-data problems.
This is ev-ident particularly for ?OBJ?
that reaches aggres-sively 0.970 in F-score.
One exception is ?TPC?,whose precision and recall draws to the lowestamong grammatical roles.
In CTB resources,?TPC?
marks elements that appear before the sub-ject in a declarative sentence, and, it always consti-tutes a noun phrase together with the subject of thesentence.
As an illustrating example, in the sen-tence ?U9??
(J?q (The industrialstructure of Tianjin and Taiwan is similar)?, ?U9? (Tianjin and Taiwan)?
is labeled with?TPC?, while ??
( (The industrial struc-ture)?
with ?SBJ?.
In such settings, it is difficult todistinguish between them even for human beings.Overall, there are three possible explanationsfor the lower F-score of adverbials.
One is thattags characterized by much more semantic infor-mation always have flexible syntactic construc-tions and diverse positions in sentence, whichmakes it difficult to capture their uniform char-acteristics.
Second one is likely that the long-distance dependency and sparseness problem de-grade the performance of adverbials greatly.
Thiscan be viewed from the statistics in Table 2, wheremost of the adverbials are longer than 4, while thefrequency of them is significantly lower than thatof grammatical roles.
The third possible explana-tion is that there is vagueness among different ad-verbials.
An instance to state such case is the dis-pute between ?ADV?
and ?MNR?
like the phrase?
?XU?m?\ (with the deepening of re-form and opening-up)?, which are assigned with?ADV?
and ?MNR?
in two totally the same con-texts in our training data.
Noting that word se-quences for some semantic labels carry severallimited formations (e.g., most of ?DIR?
is prepo-sition phrase beginning with ?from, to?
), we willtry some linguistically informed heuristics to de-tect such patterns in future work.4.3 Results with Automatically Assigned POSTagsParallel to experiments on text with gold-standardPOS tags, we also present results on automaticallyPOS-tagged text to quantify the effect of POS ac-curacy on the system performance.
We adopt auto-matic POS tagger of (Qin et al, 2008), which gotthe first place in the forth SIGHAN Chinese POStagging bakeoff on CTB open test, to assign POStags for our data.
Following the approach of (Qinet al, 2008), we train the automatic POS taggerwhich gets an average accuracy of 96.18% in our5-fold cross-validation data.
Function tagger takesraw text as input, then completes POS tagging andfunction labeling in a cascaded way.
As shown inTable 5, the F-score of AutoPOS is slightly lowerthan that of GoldPOS.
However, the small gap isstill within our first expectation.Table 5: Performance separated for grammaticalroles and adverbials, of our models GoldPOS (us-ing gold-standard POS tags), GoldPARSE (usinggold-standard parse trees), AutoPOS (using auto-matically labeled POS tags).grammatical roles adverbialsP R F P R FGoldPOS 0.949 0.960 0.955 0.887 0.887 0.887AutoPOS 0.921 0.948 0.934 0.872 0.867 0.869GoldPARSE 0.936 0.967 0.951 0.911 0.884 0.8974.4 Results with Gold-standard ParserA thoroughly different way for function labelingis deriving function labels together with parsing.The work of (Blaheta and Charniak, 2000; Bla-heta, 2004; Merlo and Musillo, 2005) has ap-proved its effectiveness in English text.
Amongthem, the work of Merlo and Musillo (Merlo andMusillo, 2005) achieved a state-of-the-art F1 scorefor English function labeling (0.964 for grammat-ical roles and 0.863 for adverbials).
In order to ad-dress the question of whether such method can besuccessfully applied to Chinese text and whetherthe simple method we proposed is better than orat least equivalent to it, we used features collectedfrom hand-crafted parse trees in CTB resources,and did a separate experiment on the same text.The features we used are borrowed from featuretrees described in (Blaheta and Charniak, 2000).A trivial difference is that in our system the headfor prepositional phrases is defined as the preposi-tions themselves (not the head of object of preposi-tional phrases (Blaheta and Charniak, 2000)), be-cause we think that the preposition itself is a moredistinctive attribute for different semantic mean-ings.Results in Table 5 show that the parser treedoesn?t help a lot in Chinese function labeling.One reason for this may be sparseness problem ofparse tree features ?
For instance, in one of the 5-60fold data, 34% of syntactic paths in test instancesare unseen in training data.
For sentences withthe average length of more than 40 words, thissparseness becomes even severe.
Another possi-ble reason is that some functional chunks are morelocal and less prone to structured parse trees, asobserved in examples listed at the beginning ofthe paper.
In Table 5, although the performanceof adverbials grows really huge when using fea-tures from the gold-standard parse trees, the per-formance of grammatical roles drops as introduc-ing such features.
As mentioned above, in facteven the simple position feature can give a betterexplanation to word?s grammatical role than com-plicated syntactic path.Although the experimental setup is strictly notthe same for the present paper and (Blahetaand Charniak, 2000; Blaheta, 2004; Merlo andMusillo, 2005), we observe that the proposedmethod yields better results with deliberately de-signed but simple features at lexical level, whileattempts in (Blaheta and Charniak, 2000; Blaheta,2004; Merlo and Musillo, 2005) optimized func-tion labeling together with parsing, which is amore complex task and difficult to realize for lan-guages that lack sufficient parse resources.The work of (Blaheta and Charniak, 2000; Bla-heta, 2004; Merlo and Musillo, 2005) reveal thatthe performance of parser used sets upper boundon the performance of function labeling.
However,the best Chinese parser ever reported (Wang et al,2006) achieves 0.882 F-score for sentences withless than 40 words, we therefore conclude that theway using auto-parser for Chinese function label-ing is not the optimal choice.4.5 Error AnalysisIn the course of our experiment, we wanted to at-tain some understanding of what sort of errors thesystem was making.
While still working on thegold-standard POS-tagged text, we randomly tookone output from the 5-fold cross-validation testsand examined each error.
But when observing the1,550 wrongly labeled function chunks (26,593 intotal), we can distinguish three types of errors.The first and widest category of errors arecaused when the lexical construction of the chunkis similar to other chunk types.
A typical exampleis ?PRP (purpose)?
and ?BNF (beneficiary)?, bothof which are mostly prepositional phrases begin-ning with ??,?
(for, in order to)?.The second type of errors are found when thechunk is too long, like more than 8 words.
Nor-mally it is not easy to eliminate this kind of errorsthrough local lexical features.
In Chinese, the longchunks are mainly composed of ? (DE)?
struc-ture that can be translated into attributive clausein English.
The ? (DE)?
structures are usuallynested component and used as a modifier of nounphrases, thus this kind of errors can be partly re-solved by accurately recognition of such structure.The third type of errors concern the sentencewith some special structure, like intransitive sen-tence, elliptical sentence (left out of subject or ob-ject), and so on.
The errors of ?IO?
with wrongtag ?OBJ?, and errors of ?EXT?
with wrong tag?OBJ?
fall into the third categories.
It is interest-ing to notice that, when using GoldPARSE (seeTable 5), suggesting that features from the treesare helpful when disambiguating function labelsthat related with sentence structures.5 Conclusion and Future WorkWe have presented the first experimental results onChinese function labeling using Chinese Treebankresources, and shown that Chinese function la-beling can be reached with considerable accuracygiven a small number of lexical features.
Eventhough our experiments using hand-crafted parsetrees yield promising initial results, this methodwill be hampered when using fully automaticparser due to the imperfection of Chinese parser,which is our core motivation to assign function la-bels by exploiting the underlining lexical insightsinstead of parse trees.
Experimental results sug-gest that our method for Chinese function label-ing is comparable with the English state-of-the-artwork that utilizes complicated parse trees.We believe that we have not settled on an ?opti-mal?
set of features for Chinese function labeling,hence, more language-specific customization isnecessary in the future work.
Although there havebeen speculations and trails on things that func-tion labels might help with, it remains to be im-portant to discover how function labels contributeto other NLP applications, such as the Japanese-Chinese machine translation system we have beenworking on.ReferencesAltun, Y., Tsochantaridis, I., Hofmann, T. 2003.
Hid-den Markov Support Vector Machines.
In: Pro-61ceedings of ICML 2003, pages 172-188, Washing-ton, DC, USA.Berger, A., Pietra, D. S., Pietra, D. V. 1996.
A Max-imum Entropy Approach to Natural Language Pro-cessing.
Computational Linguistics, 22(1):39-71.Blaheta, D. 2004.
Function Tagging.
Ph.D. thesis, De-partment of Computer Science, Brown University.Blaheta, D., Charniak, E. 2000.
Assigning FunctionTags to Parsed Text.
In: Proceedings of the 1stNAACL, pages 234-240, Seattle, Washington.Chrupala, G., Stroppa, N., Genabith, J., Dinu, G. 2007.Better Training for Function Labeling.
In: Proceed-ings of RANLP2007, Borovets, Bulgaria.Gildea, D., Palmer, M. 2002.
The Necessity of Parsingfor Predicate Argument Recognition.
In: Proceed-ings of the 40th ACL, pages 239-246, Philadelphia,USA.Iida, R., Komachi, M., Inui, K., Matsumoto, Y.
2007.Annotating a Japanese Text Corpus with Predicate-argument and Coreference Relations.
In: Proceed-ings of ACL workshop on the linguistic annotation,pages 132-139, Prague, Czech Republic.Jijkoun, V., Rijke D. M. 2004.
Enriching the Out-put of a Parser Using Memory-based Learning.In: Proceedings of the 42nd ACL, pages 311-318,Barcelona, Spain.Kiss, T., Strunk, J.
2006.
Unsupervised MultilingualSentence Boundary Detection.
Computational Lin-guistics, 32(4):485-525.Kudo, T., Matsumoto, Y.
2001.
Chunking withSupport Vector Machines.
In: Proceedings of theNAACL 2001, pages 1-8, Pittsburgh, USA.Nocedal, J., Wright, S. J.
1999.
Numerical Optimiza-tion.
Springer.Lafferty, J., McCallum, A., Pereira, F. 2001.
Condi-tional Random Fields: Probabilistic Models for Seg-menting and Labeling Sequence Data.
In: Proceed-ings of ICML 2001, pages 282-289, Williamstown,USA.Levin, B.
1993.
English Verb Classes and Alterna-tions: A preliminary Investigation.
The Universityof Chicago Press, USA.Marcus, M., Kim, G., Marcinkiewicz, A. M., Macin-tyre, R., Bies, A., Ferguson, M., Katz, K., Schas-berger, B.
1994.
The Penn Treebank: AnnotatingPredicate Argument Structure.
In: Proceedings ofARPA Human Language Technology Workshop, SanFrancisco, USA.Mccallum, A., Freitag, D., Pereira, F. 2000.
MaximumEntropy Markov Models for Information Extractionand Segmentation.
In: Proceedings of ICML 2000,pages 591-598, Stanford University, USA.Merlo, P., Ferrer, E. E. 2006.
The Notion of Argumentin Prepositional Phrase Attachment.
ComputationalLinguistics, 32(3):341-378.Merlo, P., Musillo, G. 2005.
Accurate Function Pars-ing.
In: Proceedings of EMNLP 2005, pages 620-627, Vancouver, Canada.Qin, Y., Yuan, C., Sun, J., Wang, X.
2008.
BUPTSystems in the SIGHAN Bakeoff 2007.
In: Pro-ceedings of the Sixth SIGHAN Workshop on ChineseLanguage Processing, pages 94-97, Hyderabad, In-dia.Rabiner, L. 1989.
A Tutorial on Hidden Markov Mod-els and Selected Applications in Speech Recogni-tion.
In: Proceedings of the IEEE, 77(2):257-286.Ramshaw, L., Marcus, M. 1995.
Text Chunking UsingTransformation Based Learning.
In: Proceedings ofACL Third Workshop on Very Large Corpora, pages82-94, Cambridge MA, USA.Swier, R., Stevenson, S. 2004.
Unsupervised SemanticRole Labelling.
In: Proceedings of EMNLP-2004,pages 95-102, Barcelona, Spain.Tsochantaridis, T., Hofmann, T., Joachims, T., Altun,Y.
2004.
Support Vector Machine Learning forInterdependent and Structured Output Spaces.
In:Proceedings of ICML 2004, pages 823-830, Banff,Canada.Wang, M., Sagae, K., Mitamura, T. 2006.
A Fast,Accurate Deterministic Parser for Chinese.
In: Pro-ceedings of the 44th ACL, pages 425-432, Sydney,Australia.Xue, N., Xia, F., Huang, S., Kroch, T. 2000.
TheBracketing Guidelines for the Chinese Treebank.IRCS Tech., rep., University of Pennsylvania.Zhao, Y., Zhou, Q.
2006.
A SVM-based Model forChinese Functional Chunk Parsing.
In: Proceed-ings of the Fifth SIGHANWorkshop on Chinese Lan-guage Processing, pages 94-10, Sydney, Australia1.Zhou, Q., Zhan, W., Ren, H. 2001.
Building a Large-scale Chinese Chunkbank (in Chinese).
In: Pro-ceedings of the 6th Joint Conference of Computa-tional Linguistics of China, Taiyuan, China.62
