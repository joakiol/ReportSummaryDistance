Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, pages 313?316,Suntec, Singapore, 4 August 2009. c?2009 ACL and AFNLPGeneralizing Dependency Features for Opinion MiningMahesh Joshi1 and Carolyn Penstein-Rose?1,21Language Technologies Institute2Human-Computer Interaction InstituteCarnegie Mellon University, Pittsburgh, PA, USA{maheshj,cprose}@cs.cmu.eduAbstractWe explore how features based on syntac-tic dependency relations can be utilized toimprove performance on opinion mining.Using a transformation of dependency re-lation triples, we convert them into ?com-posite back-off features?
that generalizebetter than the regular lexicalized depen-dency relation features.
Experiments com-paring our approach with several other ap-proaches that generalize dependency fea-tures or ngrams demonstrate the utility ofcomposite back-off features.1 IntroductionOnline product reviews are a crucial source ofopinions about a product, coming from the peo-ple who have experienced it first-hand.
However,the task of a potential buyer is complicated by thesheer number of reviews posted online for a prod-uct of his/her interest.
Opinion mining, or sen-timent analysis (Pang and Lee, 2008) in productreviews, in part, aims at automatically processinga large number of such product reviews to identifyopinionated statements, and to classify them intohaving either a positive or negative polarity.One of the most popular techniques used foropinion mining is that of supervised machinelearning, for which, many different lexical, syntac-tic and knowledge-based feature representationshave been explored in the literature (Dave et al,2003; Gamon, 2004; Matsumoto et al, 2005; Nget al, 2006).
However, the use of syntactic fea-tures for opinion mining has achieved varied re-sults.
In our work, we show that by alteringsyntactic dependency relation triples in a partic-ular way (namely, ?backing off?
only the headword in a dependency relation to its part-of-speechtag), they generalize better and yield a significantimprovement on the task of identifying opinionsfrom product reviews.
In effect, this work demon-strates a better way to utilize syntactic dependencyrelations for opinion mining.In the remainder of the paper, we first discussrelated work.
We then motivate our approach anddescribe the composite back-off features, followedby experimental results, discussion and future di-rections for our work.2 Related WorkThe use of syntactic or deep linguistic features foropinion mining has yielded mixed results in the lit-erature so far.
On the positive side, Gamon (2004)found that the use of deep linguistic features ex-tracted from phrase structure trees (which includesyntactic dependency relations) yield significantimprovements on the task of predicting satisfac-tion ratings in customer feedback data.
Mat-sumoto et al (2005) show that when using fre-quently occurring sub-trees obtained from depen-dency relation parse trees as features for machinelearning, significant improvement in performanceis obtained on the task of classifying movie re-views as having positive or negative polarity.
Fi-nally, Wilson et al (2004) use several differentfeatures extracted from dependency parse trees toimprove performance on the task of predicting thestrength of opinion phrases.On the flip side, Dave et al (2003) foundthat for the task of polarity prediction, addingadjective-noun dependency relationships as fea-tures does not provide any benefit over a sim-ple bag-of-words based feature space.
Ng et al(2006) proposed that rather than focusing on justadjective-noun relationships, the subject-verb andverb-object relationships should also be consid-ered for polarity classification.
However, they ob-served that the addition of these dependency re-lationships does not improve performance over afeature space that includes unigrams, bigrams andtrigrams.313One difference that seems to separate the suc-cesses from the failures is that of using the en-tire set of dependency relations obtained from adependency parser and allowing the learning al-gorithm to generalize, rather than picking a smallsubset of dependency relations manually.
How-ever, in such a situation, one critical issue might bethe sparseness of the very specific linguistic fea-tures, which may cause the classifier learned fromsuch features to not generalize.
Features based ondependency relations provide a nice way to enablegeneralization to the right extent through utiliza-tion of their structural aspect.
In the next section,we motivate this idea in the context of our task,from a linguistic as well as machine learning per-spective.3 Identifying Opinionated SentencesWe focus on the problem of automatically identi-fying whether a sentence in a product review con-tains an opinion about the product or one of itsfeatures.
We use the definition of this task as for-mulated by Hu and Liu (2004) on Amazon.comand CNet.com product reviews for five differentproducts.
Their definition of an opinion sentenceis reproduced here verbatim: ?If a sentence con-tains one or more product features and one ormore opinion words, then the sentence is called anopinion sentence.?
Any other sentence in a reviewthat does not fit the above definition of an opinionsentence is considered as a non-opinion sentence.In general, these can be expected to be verifiablestatements or facts such as product specificationsand so on.Before motivating the use of dependency rela-tions as features for our task, a brief overviewabout dependency relations follows.3.1 Dependency RelationsThe dependency parse for a given sentence is es-sentially a set of triplets or triples, each of which iscomposed of a grammatical relation and the pair ofwords from the sentence among which the gram-matical relation holds ({reli, wj, wk}, where reliis the dependency relation among words wjandwk).
The set of dependency relations is specificto a given parser ?
we use the Stanford parser1 forcomputing dependency relations.
The word wjisusually referred to as the head word in the depen-1http://nlp.stanford.edu/software/lex-parser.shtmldency triple, and the word wkis usually referredto as the modifier word.One straightforward way to use depen-dency relations as features for machinelearning is to generate features of the formRELATION HEAD MODIFIER and use them in astandard bag-of-words type binary or frequency-based representation.
The indices of the head andmodifier words are dropped for the obvious reasonthat one does not expect them to generalize acrosssentences.
We refer to such features as lexicalizeddependency relation features.3.2 Motivation for our ApproachConsider the following examples (these are made-up examples for the purpose of keeping the dis-cussion succinct, but still capture the essence ofour approach):(i) This is a great camera!
(ii) Despite its few negligible flaws, this reallygreat mp3 player won my vote.Both of these sentences have an adjectival mod-ifier (amod) relationship, the first one havingamod camera great) and the second one hav-ing amod player great).
Although both ofthese features are good indicators of opinion sen-tences and are closely related, any machine learn-ing algorithm that treats these features indepen-dently will not be able to generalize their rela-tionship to the opinion class.
Also, any new testsentence that contains a noun different from either?camera?
or ?player?
(for instance in the reviewof a different electronic product), but is participat-ing in a similar relationship, will not receive anyimportance in favor of the opinion class ?
the ma-chine learning algorithm may not have even seenit in the training data.Now consider the case where we ?back off?the head word in each of the above features to itspart-of-speech tag.
This leads to a single feature:amod NN great.
This has two advantages: first,the learning algorithm can now learn a weight for amore general feature that has stronger evidence ofassociation with the opinion class, and second, anynew test sentence that contains an unseen noun in asimilar relationship with the adjective ?great?
willreceive some weight in favor of the opinion class.This ?back off?
operation is a generalization ofthe regular lexicalized dependency relations men-tioned above.
In the next section we describe allsuch generalizations that we experimented with.3144 MethodologyComposite Back-off Features: The idea behindour composite back-off features is to create moregeneralizable, but not overly general back-off fea-tures by backing off to the part-of-speech (POS)tag of either the head word or the modifier word(but not both at once, as in Gamon (2004) andWil-son et al (2004)) ?
hence the description ?compos-ite,?
as there is a lexical part to the feature, comingfrom one word, and a POS tag coming from theother word, along with the dependency relation it-self.The two types of composite back-off featuresthat we create from lexicalized dependency triplesare as follows:(i) h-bo: Here we use features of the form{reli, POSj, wk}where the head word is replacedby its POS tag, but the modifier word is retained.
(ii) m-bo: Here we use features of the form{reli, wj, POSk}, where the modifier word is re-placed by its POS tag, but the head word is re-tained.Our hypothesis is that the h-bo features willperform better than purely lexicalized dependencyrelations for reasons mentioned in Section 3.2above.
Although m-bo features also generalizethe lexicalized dependency features, in a relationsuch as an adjectival modifier (discussed in Sec-tion 3.2 above), the head noun is a better candi-date to back-off for enabling generalization acrossdifferent products, rather than the modifier adjec-tive.
For this reason, we do not expect their per-formance to be comparable to h-bo features.We compare our composite back-off featureswith other similar ways of generalizing depen-dency relations and lexical ngrams that have beentried in previous work.
We describe these below.Full Back-off Features: Both Gamon (2004)and Wilson et al (2004) utilize features based onthe following version of dependency relationships:{reli, POSj, POSk}, where they ?back off?
boththe head word and the modifier word to their re-spective POS tags (POSjand POSk).
We referto this as hm-bo.NGram Back-off Features: Similar to Mc-Donald et al (2007), we utilize backed-off ver-sions of lexical bigrams and trigrams, where allpossible combinations of the words in the ngramare replaced by their POS tags, creating featuressuch as wjPOSk, POSjwk, POSjPOSkforeach lexical bigram and similarly for trigrams.
Werefer to these as bi-bo and tri-bo features respec-tively.In addition to these back-off approaches, wealso use regular lexical bigrams (bi), lexical tri-grams (tri), POS bigrams (POS-bi), POS trigrams(POS-tri) and lexicalized dependency relations(lexdep) as features.
While testing all of our fea-ture sets, we evaluate each of them individually byadding them to the basic set of unigram (uni) fea-tures.5 Experiments and ResultsDetails of our experiments and results follow.5.1 DatasetWe use the extended version of the Amazon.com /CNet.com product reviews dataset released by Huand Liu (2004), available from their web page2.We use a randomly chosen subset consisting of2,200 review sentences (200 sentences each for11 different products)3.
The distribution is 1,053(47.86%) opinion sentences and 1,147 (52.14%)non-opinion sentences.5.2 Machine Learning ParametersWe have used the Support Vector Machine (SVM)learner (Shawe-Taylor and Cristianini, 2000) fromthe MinorThird Toolkit (Cohen, 2004), along withthe ?-squared feature selection procedure, wherewe reject features if their ?-squared score is notsignificant at the 0.05 level.
For SVM, we usethe default linear kernel with all other parametersalso set to defaults.
We perform 11-fold cross-validation, where each test fold contains all thesentences for one of the 11 products, and the sen-tences for the remaining ten products are in thecorresponding training fold.
Our results are re-ported in terms of average accuracy and Cohen?skappa values across the 11 folds.5.3 ResultsTable 1 shows the full set of results from our ex-periments.
Our results are comparable to those re-ported by Hu and Liu (2004) on the same task;as well as those by Arora et al (2009) on a sim-ilar task of identifying qualified vs. bald claimsin product reviews.
On the accuracy metric, thecomposite features with the head word backed off2http://www.cs.uic.edu/?liub/FBS/sentiment-analysis.html3http://www.cs.cmu.edu/?maheshj/datasets/acl09short.html315Features Accuracy Kappauni .652 (?.048) .295 (?.049)uni+bi .657 (?.066) .304 (?.089)uni+bi-bo .650 (?.056) .299 (?.079)uni+tri .655 (?.062) .306 (?.077)uni+tri-bo .647 (?.051) .287 (?.075)uni+POS-bi .676 (?.057) .349 (?.083)uni+POS-tri .661 (?.050) .317 (?.064)uni+lexdep .639 (?.055) .268 (?.079)uni+hm-bo .670 (?.046) .336 (?.065)uni+h-bo .679 (?.063) .351 (?.097)uni+m-bo .657 (?.056) .308 (?.063)Table 1: Shown are the average accuracy and Co-hen?s kappa across 11 folds.
Bold indicates statis-tically significant improvements (p < 0.05, two-tailed pairwise T-test) over the (uni) baseline.are the only ones that achieve a statistically signif-icant improvement over the uni baseline.
On thekappa metric, using POS bigrams also achievesa statistically significant improvement, as do thecomposite h-bo features.
None of the other back-off strategies achieve a statistically significant im-provement over uni, although numerically hm-bocomes quite close to h-bo.
Evaluation of thesetwo types of features by themselves (without un-igrams) shows that h-bo are significantly betterthan hm-bo at p < 0.10 level.
Regular lexical-ized dependency relation features perform worsethan unigrams alone.
These results thus demon-strate that composite back-off features based ondependency relations, where only the head word isbacked off to its POS tag present a useful alterna-tive to encoding dependency relations as featuresfor opinion mining.6 Conclusions and Future DirectionsWe have shown that for opinion mining in prod-uct review data, a feature representation based ona simple transformation (?backing off?
the headword in a dependency relation to its POS tag) ofsyntactic dependency relations captures more gen-eralizable and useful patterns in data than purelylexicalized dependency relations, yielding a statis-tically significant improvement.The next steps that we are currently workingon include applying this approach to polarity clas-sification.
Also, the aspect of generalizing fea-tures across different products is closely relatedto fully supervised domain adaptation (Daume?
III,2007), and we plan to combine our approach withthe idea from Daume?
III (2007) to gain insightsinto whether the composite back-off features ex-hibit different behavior in domain-general versusdomain-specific feature sub-spaces.AcknowledgmentsThis research is supported by National ScienceFoundation grant IIS-0803482.ReferencesShilpa Arora, Mahesh Joshi, and Carolyn Rose?.
2009.Identifying Types of Claims in Online Customer Re-views.
In Proceedings of NAACL 2009.William Cohen.
2004.
Minorthird: Methods for Iden-tifying Names and Ontological Relations in Text us-ing Heuristics for Inducing Regularities from Data.Hal Daume?
III.
2007.
Frustratingly Easy DomainAdaptation.
In Proceedings of ACL 2007.Kushal Dave, Steve Lawrence, and David Pennock.2003.
Mining the Peanut Gallery: Opinion Ex-traction and Semantic Classification of Product Re-views.
In Proceedings of WWW 2003.Michael Gamon.
2004.
Sentiment Classification onCustomer Feedback Data: Noisy Data, Large Fea-ture Vectors, and the Role of Linguistic Analysis.
InProceedings of COLING 2004.Minqing Hu and Bing Liu.
2004.
Mining and Summa-rizing Customer Reviews.
In Proceedings of ACMSIGKDD 2004.Shotaro Matsumoto, Hiroya Takamura, and ManabuOkumura.
2005.
Sentiment Classification UsingWord Sub-sequences and Dependency Sub-trees.
InProceedings of the 9th PAKDD.Ryan McDonald, Kerry Hannan, Tyler Neylon, MikeWells, and Jeff Reynar.
2007.
StructuredModels forFine-to-Coarse Sentiment Analysis.
In Proceedingsof ACL 2007.Vincent Ng, Sajib Dasgupta, and S. M. Niaz Arifin.2006.
Examining the Role of Linguistic KnowledgeSources in the Automatic Identification and Classi-fication of Reviews.
In Proceedings of the COL-ING/ACL 2006.Bo Pang and Lillian Lee.
2008.
Opinion Mining andSentiment Analysis.
Foundations and Trends in In-formation Retrieval, 2(1?2).John Shawe-Taylor and Nello Cristianini.
2000.Support Vector Machines and Other Kernel-basedLearning Methods.
Cambridge University Press.Theresa Wilson, Janyce Wiebe, and Rebecca Hwa.2004.
Just How Mad Are You?
Finding Strongand Weak Opinion Clauses.
In Proceedings of AAAI2004.316
