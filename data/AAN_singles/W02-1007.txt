Parsing and Disuency PlacementDonald Engelyand Eugene Charniakzand Mark JohnsonzDepartment of Physics, University of PennsylvaniayBrown Laboratory for Linguistic Information ProcessingzBrown UniversityAbstractIt has been suggested that some forms of speechdisuencies, most notable interjections and par-entheticals, tend to occur disproportionally atmajor clause boundaries [6] and thus mightserve to aid parsers in establishing these bound-aries.
We have tested a current statistical parser[1] on Switchboard text with and without inter-jections and parentheticals and found that theparser performed better when not faced withthese extra phenomena.
This suggest that forcurrent parsers, at least, interjection and paren-thetical placement does not help in the parsingprocess.1 IntroductionIt is generally recognized that punctuationhelps in parsing text.
For example, Roark [5]nds that removing punctuation decreases hisparser's accuracy from 86.6% to 83.8%.
Ourexperiments with the parser described in [1]show a similar fallo.
Unfortunately spokenEnglish does not come with punctuation, andeven when transcriptions add punctuation, as inthe Switchboard [4] corpus of transcribed (andparsed) telephone calls, it's utility is small [5]For this and other reasons there is considerableinterest in nding other aspects of speech thatmight serve as a replacement.One suggestion in this vein is that the place-ment of some forms of speech errors mightencode useful linguistic information.
Speech,of course, contains many kinds of errors thatcan make it more di?cult to parse than text.Roughly speaking the previously mentionedSwitchboard corpus distinguishes three kinds oferrors: interjections (lled pauses) | \I, um, wantto leave" parentheticals | \I, you know, want toleave" speech repairs | \I can, I want to leave"Of these, speech repairs are the most injuriousto parsing.
Furthermore, even if one's parsercan parse the sentence as it stands, that is notsu?cient.
For example, in \I can, I want toleave", it is not necessarily the case that thespeaker believes that he or she can, in fact,leave, only that he or she wants to leave.
Thusin [2] speech repairs were rst detected in a sep-arate module, and deleted before handing theremaining text to the parser.
The parser thenproduced a parse of the text without the re-paired section.The other two kinds of errors, interjec-tions, and parentheticals, (henceforth INTJsand PRNs) are less problematic.
In particular,if they are left in the text either their seman-tic content is compatible with the rest of theutterance or there is no semantic content at all.For example, Table 1 gives the 40 most commonINTJs, which comprise 97% of the total.
(Un-listed INTJs comprise the remaining 3%.)
Theyare easily recognized as not carrying much, ifany, content.PRNs are more diverse.
Table 2 lists the 40most common PRNs.
They only comprise 65%of all cases, and many do contain semanticscontent.
In such cases, however, the semanticcontent is compatible with the rest of the sen-tence, so leaving them in is perfectly acceptable.Thus [2], while endeavoring to detect and re-move speech repairs, left interjections and par-entheticals in the text for the parser to copewith.Indeed [6] nds that both interjections andparentheticals tend to occur at major sentenceboundaries.
Also [7] suggest that this prop-Association for Computational Linguistics.Language Processing (EMNLP), Philadelphia, July 2002, pp.
49-54.Proceedings of the Conference on Empirical Methods in NaturalPhrase Num.
of PercentINTJsuh 17609 27.44yeah 11310 17.62uh-huh 7687 11.97well 5287 8.238um 3563 5.552oh 2935 4.573right 2873 4.477like 1772 2.761no 1246 1.941okay 1237 1.927yes 982 1.530so 651 1.014oh yeah 638 0.994huh 558 0.869now 410 0.638really 279 0.434sure 276 0.430oh okay 269 0.419see 261 0.406oh really 260 0.405huh-uh 185 0.288wow 174 0.271bye-bye 174 0.271exactly 156 0.243all right 146 0.227yep 115 0.179boy 111 0.172oh no 102 0.158bye 98 0.152well yeah 91 0.141gosh 91 0.141oh gosh 88 0.137oh yes 84 0.130hey 75 0.116uh yeah 71 0.110anyway 71 0.110oh uh-huh 70 0.109say 63 0.098oh goodness 61 0.095uh no 56 0.087Table 1: The 40 Most Common InterjectionsPhrase Num.
of PercentPRNsyou know 431 37.02I mean 105 9.020I think 86 7.388I guess 67 5.756You know 44 3.780I don't know 38 3.264let's see 11 0.945I I mean 10 0.859I 'd say 9 0.773I 'm sure 7 0.601excuse me 6 0.515what is it 6 0.515I would say 5 0.429you you know 5 0.429let 's say 5 0.429I think it 's 4 0.343I 'm sorry 4 0.343so to speak 3 0.257I guess it 's 3 0.257I don't think 3 0.257I think it was 3 0.257I would think 3 0.257it seems 3 0.257I guess it was 2 0.171I know 2 0.171I I I mean 2 0.171seems like 2 0.171Shall we say 2 0.171I guess you could say 2 0.171You're right 2 0.171I believe 2 0.171I think it was uh 2 0.171I say 2 0.171What I call 2 0.171I don't know what part ofNew Jersey you're in but 2 0.171I should say 2 0.171I guess not a sore thumb 1 0.085I 'm trying to think 1 0.085And it's hard to dragher away 1 0.085I don't know what youcall that 1 0.085Table 2: The 40 Most Common Parentheticalserty accounts for their observation that remov-ing these disuencies does not help in languagemodeling perplexity results.
This strongly sug-gests that INTJ/PRN location information inspeech text might in fact, improve parsing per-formance by helping the parser locate con-stituent boundaries with high accuracy.
That is,a statistic parser such as [1] or [3] when trainedon parsed Switchboard text with these phenom-ena left in, might learn the statistical correla-tions between them and phrase boundaries justas they are obviously learning the correlationsbetween punctuation and phrase boundaries inwritten text.In this paper then we wish to determine if thepresence of INTJs and PRNs do help parsing, atleast for one state-of-the-art statistical parser[1].2 Experimental DesignThe experimental design used was more com-plicated than we initially expected.
We had an-ticipated that the experiments would be con-ducted analogously to the \no punctuation" ex-periments previously mentioned.
In those ex-periments one removes punctuation from all ofthe corpus sentences, both for testing and train-ing, and then one reports the results before andafter this removal.
(Note that one must removepunctuation from the training data as well sothat it looks like the non-punctuated testingdata it receives.)
Parsing accuracy was mea-sured in the usual way, using labeled precisionrecall.
Note, however, and this is a criticalpoint, that precision and recall are only mea-sured on non-preterminal constituents.
That is,if we have a constituent(PP (IN of)(NP (DT the) (NN book)))our measurements would note if we correctlyfound the PP and the NP, but not the preter-minals IN, DT, and NN.
The logic of this isto avoid confusing parsing results with part-of-speech tagging, a much simpler problem.Initially we conducted similarly designed ex-periments, except rather than removing punc-tuation, we removed INTJs and PRNs and com-pared before and after precision/recall numbers.These numbers seemed to conrm the antici-pated results: the \after" numbers, the numberswithout INTJ/PRNs were signicantly worse,suggesting that the presence of INTJ/PRNshelped the parser.Unfortunately, although ne for punctuation,this experimental design is not su?cient formeasuring the eects of INTJ/PRNs on parsing.The dierence is that punctuation itself is notmeasured in the precision-recall numbers.
Thatis, if we had a phrase like(NP (NP (DT a) (NN sentence))(, ,)(ADJP (JJ like)(NP (DT this) (DT one))))we would measure our accuracy on the threeNP's and the ADJP, but not on the pretermi-nals, and it is only at the preterminal level thatpunctuation appears.The same cannot be said for INTJ/PRNs.Consider the (slightly simplied) Switchboardparse for a sentence like \I, you know, want toleave":(S (NP I)(PRN , you know ,)(VP want (S to leave)))The parenthetical PRN is a full non-terminaland thus is counted in precision/recall measure-ments.
Thus removing preterminals is chang-ing what we wish to measure.
In particu-lar, when our initial results showed that re-moval of INTJ/PRNs lowered precision/recall weworried that it might be that INTJ/PRNs areparticularly easy to parse, and thus removingthem made things worse, not because of col-lateral damage on our ability to parse otherconstituents, but simply because we removeda body of easily parseable constituents, leavingthe more di?cult constituents to be measured.The above tables of INTJs and PRNs lends cre-dence to this concern.Thus in the experiments below all measure-ments are obtained in the following fashion:1.
The parser is trained on switchboard datawith/without INTJ/PRNs or punctuation,creating eight congurations: 4 for neither,both, just INTJs, and just PRNs, timestwo for with and without punctuation.
Wetested with and without punctuation toconrm Roark's earlier results showing thatthey have little inuence in Switchboardtext.2.
The parser reads the gold standard testingexamples and depending on the congura-tion INTJs and/or PRNS are removed fromthe gold standard parse.3.
Finally the resulting parse is comparedwith the gold standard.
However, any re-maining PRNs or INTJs are ignored whencomputing the precision and recall statis-tics for the parse.To expand a bit on point (3) above, for anexperiment where we are parsing with INTJs,but not PRNs, the resulting parse will, of course,contain INTJs, but (a) they are not counted aspresent in the gold standard (so we do not aectrecall statistics), and (b) they are not evaluatedin the guessed parse (so if one were labeled, say,an S, it would not be counted against the parse).The intent, again, is to not allow the results tobe inuenced by the fact that interjections andparentheticals are much easier to nd than most(if not) all other kinds of constituents.3 Experimental ResultsAs in [2] the Switchboard parsed/merged cor-pus directories two and three were used fortraining.
In directory four, les sw4004.mrgto sw4153.mrg were used for testing, andsw4519.mrg to sw4936 for development.
Toavoid confounding the results with problems ofedit detection, all edited nodes were deletedfrom the gold standard parses.The results of the experiment are given intable 3.
We have shown results separatelywith and without punctuation.
A quick lookat the data indicates that both sets show thesame trends but with punctuation helping per-formance by about 1.0% absolute in both pre-cision and recall.
Within both groups, as is al-ways the case, we see that the parser does betterwhen restricted to shorter sentences (40 wordsand punctuation or less).
We see that removingPRNs or INTJs separately both improve parsingaccuracy (e.g., from 87.201% to 87.845|thatthe eect of removing both is approximatelyadditive (e.g., from 87201% to 88.863%, againon the with-punctuation data).
Both with andwithout punctuation results hint that removingPunc.
PRN INTJ Sentences Sentences 40  100+ + + 88.93 87.20+ + - 89.44 87.85+ - + 89.13 87.99+ - - 90.00 88.86- + + 87.40 86.23- + - 88.0 86.8- - + 88.41 87.45- - - 89.13 88.30Table 3: Average of labeled precision/recalldata for parsing with/without parentheti-cals/interjectionsparentheticals was usually more helpful than re-moving interjections.
However in one case thereverse was true (with-punctuation, sentences 40) and in all cases the dierences are at orunder the edge of statistical reliability.
In con-trast, the dierences between removing neither,removing one, or removing both INJs and PRNsare quite comfortably statistically reliable.4 DiscussionBased upon Tabel 3 our tentative conclusion isthat the information present in parentheticalsand interjections does not help parsing.
Thereare, however, reasons that this is a tentative con-clusion.First, in our eort to prevent the ease ofrecognizing these constructions from giving anunfair advantage to the parser when they arepresent, it could be argued that we have giventhe parser an unfair advantage when they areabsent.
After all, even if these constructions areeasily recognized, the parser is not perfect onthem.
While our labeled precision/recall mea-surements are made in such a way that a mis-take in the label of, say, an interjection, wouldnot eect the results, a mistake on it's positiontypically would have an eect because the po-sitions of constituents either before or after itwould be made incorrect.
Thus the parser hasa harder task set for it when these constituentsare left in.It would be preferable to have an experimen-tal design that would somehow equalize things,but we have been unable to nd one.
Fur-thermore it is instructive to contrast this situ-ation with that of punctuation in Wall StreetJournal text.
If we had found that parsingwithout punctuation made things easier a sim-ilar argument could be made that the without-punctuation case was given an unfair advantagesince it had a lot fewer things to worry about.But punctuation in well-edited text containsmore than enough information to overcome thedisadvantage.
This does not seem to be the casewith INTJs and PRNs.
Here the net informationcontent here seems to be negative.A second, and in our estimation more serious,objection to our conclusion is that we have onlydone the experiment with one parser.
Perhapsthere is something specic to this parser thatsystematically underestimates the usefulness ofINTJ/PRN information.
While we feel reason-ably condent that any other current parserwould nd similar eects, it is at least possi-ble to imagine that quite dierent parsers mightnot.
Statistical parsers condition the probabil-ity of a constituent on the types of neighbor-ing constituents.
Interjections and parenthet-icals have the eect of increasing the kinds ofneighbors one might have, thus splitting thedata and making it less reliable.
The same istrue for punctuation, of course, but it seemsplausible that well edited punctuation is su?-ciently regular that this problem is not too bad,while spontaneous interjections and parentheti-cals would not be so regular.
Of course, ndinga parser design that might overcome this prob-lem (assuming that this is the problem) is farfrom obvious.5 ConclusionWe have tested a current statistical parser [1] onSwitchboard text with and without interjectionsand parentheticals and found that the parserperforms better when not faced with these ex-tra phenomena.
This suggest that for currentparsers, at least, interjection and parentheticalplacement does not help in the parsing process.This is, of course, a disappointing result.
Thephenomena are not going to go away, and whatthis means is that there is probably no silverlining.We should also note that the idea that theymight help parsing grew from the observationthat interjections and parentheticals typicallyoccur at major clause boundaries.
One mightthen ask if our results cast any doubt on thisclaim as well.
We do not think so.
Interjectionsand parentheticals do tend to identify clauseboundaries.
The problem is that many otherthings do so as well, most notably normal gram-matical word ordering.
The question is whetherthe information content of disuency placementis su?cient to overcome the disruption of wordordering that it entails.
The answer, for currentparsers at least, seems to be "no".6 AcknowledgementsWe would like to acknowledge the members ofthe Brown Laboratory for Linguistic Informa-tion Processing, This research has been sup-ported in part by NSF grants IIS 0085940, IIS0112435, and DGE 9870676.References1.
Charniak, E. A maximum-entropy-inspired parser.
In Proceedings of the 2000Conference of the North American Chapterof the Association for Computational Lin-guistics.
ACL, New Brunswick NJ, 2000,132{139.2.
Charniak, E. and Johnson, M. Edit De-tection and Parsing for Transcribed Speech.In Proceedings of the North American As-socation for Computational Linguistics 2001.2001, 118{126.3.
Collins, M. J.
Three generative lexical-ized models for statistical parsing.
In Pro-ceedings of the 35th Annual Meeting of theACL.
1997, 16{23.4.
Godfrey, J. J., Holliman, E. C. andMcDaniel, J. SWITCHBOARD: Tele-phone speech corpus for research anddevelopment.
.
In Proceedings IEEE Con-ference on Acoustics, Speech and SignalProcessing .
San Francisco, 1992, 517{520 .5.
Roark, B.
Robust Probabilistic PredictiveSyntactic Processing: Motivations, Models,and Applications.
In Ph.D. thesis.
Depart-ment of Cognitive Science, Brown University,Providence, RI, 2001.6.
Shriberg, E. E. Preliminaries to a The-ory of Speech Disuencies.
In Ph.D. Disser-tation.
Department of Psychology, Universityof California-Berkeley, 1994.7.
Stolcke, A. and Shriberg, E. Auto-matic linguistic segmantation of conversa-tional speech.
In Proceedings of the 4th In-ternational Conference on Spoken LanguageProcessing (ICSLP-96).
1996.
