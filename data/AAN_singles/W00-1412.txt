:Incr en ntal, Event- oneeptua fization.
:andNatural Language Generation in Monitoring EnvironmentsMarkus GUHE, Christopher HABEL, Heike TAPPEResearch Group Knowledge and Language Processing (WSV),Department of Informatics, University of HamburgVogt-KGlln-Strage 30. .
.
.
.
.
.
.
.
.
.
:225.27..iJamburg,.Gerrna~ay, D,22527 -{guhe, habel, tappe}@informatik.uni-hamburg.deAbstractIn this paper we present a psycholinguisticallymotivated architecture and its prototypicalimplementation for an incremental conceptu-alizer, which monitors dynamic hanges in theworld and simultaneously generates warningsfor (possibly) safety-critical developments.
Itdoes so by conceptualizing events and build-ing up a hierarchical knowledge representa-tion of the perceived states of affairs.
If itdetects a safety problem, it selects suitableelements from the representation for a warn-ing, brings them into an appropriate order, andgenerates incremental preverbal messages(propositional structures) from them, whichcan be taken by a subsequent component toencode them linguistically.1 IntroductionSystems that generate natural language descrip-tions of what happens in a dynamically changingworld can be improved substantially by workingincrementally.
Incrementality enhances the overallquality of the systems for three reasons: (1) Thedynamic nature of a continuous stream of input in-formation can be handled more directly and, there-fore, easier.
(2) Incremental systems are capableof producing fluent speech, i.e.
speech without ar-tificial auditory gaps.
(3) Parallelism that comeswith incrementality makes better use of the avail-able resources.Furthermore, Reiter (1994), who reviews the?
architecture of some models of natural languagegeneration, shows that psycholinguistic and engi-neering approaches often result in systems, whichare similar in crucial respects.
In this paper weground on two of these common aspects, namelythe distinction between what-to-say and how-to-say (De Smedt, Horacek & Zock, 1996) and theuse of a pipeline architecture, which divides thegeneration process "into multiple modules, withinformation flowing in a 'pipeline' fashion fromone module to the next" (Reiter, 1994).
Reiterstates that these architectures do not require mod-ules to work in parallel; if parallelism is used onehas an incremental model, cf.
De Smedt & Kern-pen (I 987), Ferreira (1996).The primary research topic of the ConcEv ~project is the what-to-say component, in which thecontent of utterances i planned (Reiter's contentplanning, in contrast to the language specific sen-tence planning component).
We use the terminol-ogy of Levelt (1989), who calls the firstcomponent the conceptualizer, the second theformulator.
These modules interact via preverbalmessages, which are propositional, non-verbalrepresentations of the utterance built up by theconceptualizer.
They are transformed by the for-mulator into linguistic structures for spoken orwritten output.
Besides considering high levelcommunicative goals (macroplanning), which arein the focus of most computational pproaches tothe what-to-say component, e.g.
De Smedt &Kempen (1987), McKeown (1985), Hovy (1993),Chu-Carroll & Carberry (1998), Radev & McKe-own (1998), the type of information to be verbal-ized also determines the processes ofconceptualization the level of microplanning,cf.
Levelt (1989).
Thus, the traditional top-downapproaches have to be combined with bottom-updata-driven approaches of text planning (Marcu,1997~.
The conceptualizer that is described in de-tail in section 3 fits the pipeline architecture on acoarse level, but integrates on finer levels theideas of functional modules (Cahill et al, 1999).In the present paper we focus on the task ofI ConcEv (Conceptualizing Events) is supported by theDFG (German Science Foundation) in the priority pro-gram 'Language Production' under grant Ha-1237/10to Christopher Habel.85generating verbal descriptions of  continuously in-.coming input from a changing physical world (seesection 2, for similar settings cf.
Neumann & No-vak (1983) and Andr6, Herzog & Rist (1988)).This specific task requires an incremental pipelinearchitecture--as there are certain steps that haveto be carried out in a specific order--and, addi-tionally, these steps can be organized in such a.... insights .into _psy.cho.lJnguistic.aspects _of naturallanguage processing.
Our implementation thussimulates aspects of behavior, e.g.
the effects dif-fering time pressure has on verbalizations.2 Conceptual iz ing EventsIf the system has to produce descriptions aboutwhat it 'sees', the main conceptual task is buildingway that a sequence of clear-cut modules arises,in aralle\[ .P~allel rocessin has up conceptual entities representing spatio-?
.which can work ..p .
.
.
.
.
:~  " " " g -~ ......... ~eml6oral- constellations -of'theexternai world, i:e.the advantage that several tasks can be done si-multaneously; thus, while utterances are generatedfor some input, subsequent input can already betaken in and processed.Simultaneous conceptualization can be used asthe basis of systems producing verbal messageswhen they detect a (possibly) safety-critical de-velopment while monitoring a safety-critical sys-tem, like intensive care units, nuclear powerplants, or airports.
A module for the generation ofnatural language can be an effective nhancementfor monitoring for mainly two reasons: first, inmost cases operators are busy observing manydisplays.
Here the auditory presentation of  infor-mation can make use of idle cognitive resources ofthe operators and, thus, reduce their workload indirecting their attention to a development that maylead to hazardous ituations.
2 Second, the essentialpiece of information can be extracted from ahighly complex set of multimodal information andpresented by the system in a crisp way.
Languageis the best conceivable means to transfer informa-tion as pointedly as possible.
Moreover, taking thedynamics of the permanently changing world intoaccount has the advantage that safety-criticalsituations can be anticipated earlier and muchmore reliably.
Conventional systems, in contrast,just compare actual measurements with allowedvalues and give a warning or an alarm when aviolation occurs.
But it is more useful, e.g.
for anurse if the system tells her that a patient's bloodpressure is rapidly dropping than that his bloodpressure is already dangerously low.We see the proposed implementation of an in=cremental conceptualizer also as a means to gain2 The multimodal monitoring environment proposedhere reflects the division of labor between the compo-nents in working memory (Baddeley, 1986), especiallybetween the visuospatial sketchpad (VSSP) and thephonological loop.
Since the observation of multipledisplay units puts a heavy strain on the VSSP, spokennatural anguage as input of critical information woulduse that subcomponent of working memory, namely thephonological loop, which is less strained.event conceptualization.
Events emerge from dy-namic input data, which are segmented by theconceptual system into meaningful units (Avra-hami & Kareev, 1994).
They are therefore internalrepresentations rather than external entities: "\[...\]events arise in the perception of observers"(Zacks, 1997).
Consequently, a language produc-tion system designed for verbalizing what thesystem perceives has to deal with informationstemming from multiple modalities, e.g.
auditoryand spatial.
In particular, a continuous multimodal'perceptual stream' has to be translated into dis-crete propositional output (preverbal messages)that can be encoded linguistically, cf.
Levelt(1989).
To meet such demands, three subtaskshave to be solved: (1) The input stream has to besubdivided into 'perceptual units'; (2)conceptualrepresentations have to be built up from these'percepts', which (3) have to be combined to pre-verbal messages.
For the time being, we take theinput stream to be strictly sequential, but later ver-sions of our model will compute simultaneousevents, as well.According to Habel & Tappe (1999) the func-tion of the conceptualizer can be subdivided intothe following processes: segmentation & group-ing, structuring, selection, and linearization.
Thefirst process operates on the (perceptual) input thatis segmented into meaningful basic units (seg-mentation), and-- i f  possible--two or more ofthese units are grouped together to form morecomplex entities (grouping).
The structuring pro-cess builds .up multilevel hierarchical structuresfrom these meaningful basic units.To exemplify these steps we use the scenarioo,f: monitoring the :taxiing of an aircraft, ~iz.
themovements of an aircraft from the terminal to itsassigned runway and vice versa.
Air traffic con-trollers who guide the movements of aircraft onthe ground (surface movement controllers, SMC)have to rely mainly on visual information---eitherlooking out of the window of the control tower orgetting information from a airfield control moni-86?
:tor--and on communicatiom.with ,.the.,aircraft .......... e.vent,,~,and,:on,-,the.,other~,hand of  some~groupings..:crews.
Yet, in some conditions, e.g.
in low- The movement from position B to position C, forvisibility, this method is not failsafe (although re- example, contains--at least--three sub-phasesliable).
It forces the crews to decrease speed--and corresponding to a straight, a curved and a secondsuch increases number and duration of  de- straight section of the trajectory.
These threelays--but it also results in greater safety risks) A phases can be distinguished by segmentation, butsupporting system that monitors the occurrences are combined by a grouping.
Furthermore, theon the taxiway can mitigate these effects., structuring process has to build up the different?
phases to form the.TAXI event, cf.
Figure 3.J .2r._.
Lc.L:_,~J-.28.
L_: ........
~".-..The:,~:third,of:~he ~,above.~mentioned: sub-c@ @D Echo processes, selection, has two functions: first, it-'--\],~,!
detects that there is a conflict or a (possibly)safety-critical development or situation and de-cides that a warning has to be generated.
Second,it selects the required information for a suitable- - -~A warning or alert.
Since the verbal warning can begiven on different levels of detail, it is necessaryto select appropriate vents from the event hierar-chy for further verbalization.
On the one hand, itFigure I.
Monitoring theTaxiingofanAircrafl: Phases of a would not be adequate to produce a generalComplex Eventwarning like "Taxiing problem"--except erhapsWe will demonstrate the workings of our when there is not enough time or no more infor-model of an incremental conceptualizer, which mation available at that moment---on the otherproduces natural anguage messages for the SMC, hand, it would not be suitable to give an in-depthwith the example depicted in Figure 1.
The flight description of each part of the taxiing.
Finally, thewith the number CK-314 shall taxi from the ter- selected items are brought into an appropriate or-minal via taxiway Echo to runway 27.
The initial de r by the forth process, linearization.position of the airplane is A.
It then starts to move Before we describe the internal structure of theuntil it reaches position 13 right before a junction conceptualizer in section 3, we want to discuss thewhere it has to stop and wait until the way is clear core idea of 'event conceptualization' in morebefore moving on.
It then starts again and contin- detail.
The first question to be answered is how aues (C) but its velocity is too high at point D. continuous (perceptual) input stream can be seg-Consequently the plane might not be able to mented into separate vents.
According to the cutbranch off at the junction, where it is supposed to hypothesis of Avrahami and Kareev (1994, p.turn left into runway 27.
At that point the moni- 239), "A sub-sequence of stimuli is cut out of atoring system generates a warning that the plane is sequence to become a cognitive entity if it hasin danger of missing the junction.
(If the plane in- been experienced many times in different con-deed misses the junction, an alert is generated, but texts."
This segmentation takes place in the 'eyeour example does not include this.)
of the observer'.
Hence, event conceptualizationFor this task two kinds of information have to partly depends on individual as well as on con-be available: the planned movements of the plane textual factors.and its actual movements.
While the former in- The idea of the cut hypothesis implies the ex-formation could be handleddirectly by the con- istence of basic events, which ,are the buildingceptualizer because they are inherently discrete, blocks in our experience used to trigger segmen-the latter are information about a continuously tation.
They are minimal conceptual entities hu-changing world.
Here the perpetual continuous in- ?
: ~ .man observers ~ascribe a-beginning and,an:end to.put stream has to be transformed into discrete Thus, they are perceptual wholes--although t eyitems.
This process consists, on the one hand, of may have an internal structure--, and are there-segmentations into discrete units, e.g.
a STOP fore the basis for the interface between perceptionand cognition.
Basic events can be grouped to-gether to form complex events, e.g.
assuming that3 The reports of incidents and accidents of the Austra- the four basic events GRIP THE HANDLE OF Alian Bureau of Air Safety.
Investigation is a rich sourceof occurrences that should not happen in civil aircraft WINDOW, TURNING THE HANDLE, PULL, and LEToperations.
GO THE HANDLE are perceived, the complex event87OPENING A WINDOW.
can-b?
.bu i i taap .
Furthermore,subsequent events of opening all windows of aroom can be grouped to AIRING.
But events cannot only be grouped but also segmented: if theevent OPENING A WINDOW iS perceived, it can besegmented into the respective sub-events.
We as-sume that hierarchical event structures, which arebased on knowledge about he internal structure ofprototypical events, e.g.
in the format of scripts:Schank & Abeison (1977)?are.~exepresentationalbackbone of event conceptualization, cf Habel &Tappe (I 999).3 An Incremental ConceptualizerIncremental processing is the 'piecemeal' and par-allel processing of a sequential informationstream.
It is a specific kind of parallel processingin that the processes have a fixed order, which DeSmedt & Kempen (1987) describe as a 'cascade ofprocesses', in analogy to a water cascade.
Thismetaphor means that, for example, the grammati-cal encoding--including lexical access--of  anutterance segment cannot take place until the in-formation 'splashes down' from the conceptualencoding process.
Figure 2 sketches uch a cas-cade of dependent parallel processes in our modelof the conceptualizer: The cascade consists of theprocesses construction, selection, linearization,and pvm-generation (preverbal-message-genera-tion).
These processes also constitute a pipeline inReiter's (1994) sense, but they do work in parallel.One central parameter of incremental process-ing, which is highly relevant for the format of pre-verbal messages, is the size of the increments.Assume that a description (no warning this time)of the turning of the flight number CK-314 intotaxiway Echo shall be given.
This could be doneby a proposition like turn(ok314, goal(tw-echo)),which is a potential increment for a preverbalmessage.
Yet, such a proposition would have to bebuilt up completely, before the subsequent com-ponents can begin forming it into a sentence like'Flight CK 314 turns into taxiway Echo.'
Hencethe formulator coulcL not start processing the firstelement, say turn, as soon as it is received fromthe conceptualizer.
In:contrast tothis, we opt foran architecture, in which the selection of appropri-ate lemmas from the lexicon can start for parts ofa preverbal message, before other entities are builtup on the preverbal message level.As a consequence, the dynamics in incrementalprocessing demands a modified notion of prever-bal messages.
We conceive of them no longer as-.,eomplete,.propositions~as~:i,s~mosfly t.he~.oase.
inapproaches combining Levelt's ideas with con-ceptual semantics--but as sequences of well-formed propositional structures~on a.sub-proposi-tional level; in logical terminology: predicatesymbols, functional expressions, terms, etc.
Theincremental formulator SYNPHONICS,  which takesspecific .well-formed parts of propositions as in-put, follows these principles (Abb et al 1996).~ .
.
J  \[ Chanoe ~ - -  ~SearchI ~ in CCR r I .
.
.
.
.
.I Add ~ Chanqei .
.
.
.
II '~  I RpJ~_c:tic~n \] Traveme i uoncem .... .
.
.
.
.
.
.
JI CCR: ~ { PVM-Generation \] .
.
.
.
.
.
.  "
,Azcess to 1,J ElementTravevze Preverbal MessaqesFigure 2.
Model of  an Incremental Conceptualizer3.1 Coarse ArchitectureIn short, our conceptualizer performs the task'Give warnings about (possibly) safety-criticaldevelopments and situations!'
It operates on twodifferent input streams: a discrete one, whichcontains the plans for the movements of the air-craft on the ground, and a continuous one, whichoriginates in the sensors distributed over the taxi-way.
Since the conceptualizer cannot directly op-erate on the continuous input stream, these inputinformation must be converted into a stream ofdiscrete basic entities, which are basic events inthis case.
In our example a basic event is inducedby sensoric data sent to the monitoring system.e.g.
that a particular aircraft passes its position.Since the other input stream is already discrete, itsimply has to be adapted to the required inputformat of the conceptualizer, i.e.
it has to be con-vetted into basic events, as well.
We will neglectthis process and concentrate on the continuous in-put stream...... Based-on Habel :&-T~appe ~(1999) we propose amodel of the conceptualizer as depicted in Fig-ure 2.
It consists mainly of four incremental (cas-caded) processes that work on the blackboard-likecurrent conceptual structure (CCR).
At first sight,the use of a data structure, to which more than oneprocess has access, seems to collide with the no-tion of a cascaded information stream.
These88-processes are interdependent,in ~sucha ~way,.
how,ever, that they indeed behave incrementally; e.g.the selection process cannot select anything thathas not been inserted into the CCR (constructed).The CCR can be seen as a shared memory unitwith a common data structure.
A third kind of in-formation is needed for a representation f thestate of affairs: the constellation.of the terminals,taxiways, runways, and the participating object(s),:are: .
( 1 ) construction(2) selection(3) linearization(4) pyre-generationThe first process comprises the processes eg-mentation & grouping as well as structuring ofHabel & Tappe (1999), apart from the segmenta-tions that are already done in.
the pre-processingor, more generally:~the.,spatial~arrmngement,of theworld and information about objects in it.
For ex-ample, there is one node that stands for flight CK-314, and all the nodes shown in Figure 3 arelinked to it via an actor relation.
Since this type ofinformation is not in the focus of the present pa-per, we will not discuss it the following.In addition to the cascaded processes there is aconcept lexicon, accessible via a concept matcher:these modules, which are called by the construc-tion process, find best matches for structures thatcan either be subsumed by a more complex con-cept or may represent still incomplete concepts.The first is necessary to build up hierarchicalstructures at all.
The second is needed for the gen-eration of expectations about developments in thenear future.
When, for example, flight CK-314 isat position D, the expectation is generated that itwill go on straight at the next junction or that itwill be unable to turn left at the next junctionwhen keeping the current velocity.
4 On the otherhand, after the two nodes STARTi and CHPOS~(Figure 3) are constructed, these are given to theconcept matcher for a subsumption test, whichconsists of trying to match the nodes onto morecomplex concepts.
This yields that they can bejoined together to a MOVE node (MOVEr).
Thus, itinforms the construction process that a STOP event(STOPs) will probably occur in the near future,which illustrates the second function of thematcher: the generation of expectations.
(Even thelast MOVE of a sequence of MOVE events containsa STOP event, because aircraft stop at the begin-ning of the runway, which is the last event of thetaxiing, before they commence the takeoff.)
Theconstruction process inserts these two new nodestogether with the information .that he.
STOPi nodeis just a hypothesis up to now, nothing actuallyperceived.The four cascaded processes that constitute the'heart' of the conceptualizer and that will be de-scribed in more detail in the following sections4 The computation of the velocity is easily, done fromthe sensoric data........ step: ~hes~lectiorr.and thet  inearization processescorrelate to the ones in Habel & Tappe (1999),thus, the first selects nodes for verbalizations,while the second brings them into an appropriateorder.
The pyre-generation is an additional proc-ess and guarantees that the selection as well as thelinearization have some time to change (the orderof) the selected nodes, before they are passed onto the formulator.
We call this time span the la-tency time.For the implementation f this architecture and(a first version of) the algorithms we use a for-malism called referential nets (Habel, 1986),which was developed to represent linguistic aswell as common sense knowledge.
Entities arerepresented by referential objects (refOs), whichcan be connected via relations, so that a networkstructure arises.
The basic entities the pre-proces-sing component produces already contain some in-formation about what attributes (e.g.
which sort)have to be ascribed to a refO.
In the following weuse symbolic onstants to refer to refOs.
These arejust arbitrary labels; the important point is that therefOs can be related to suitable refOs of subse-quent processes, which, for example, stand forlexical items.3.2 ConstructionThe construction process takes basic entities asinput and builds up a hierarchical knowledge rep-resentation of the perceived states of affairs in theCCR.
In the domain we discuss here, three rela-tions are especially relevant for the representationof events: (temporal) inclusion.
(_), temporalprecedence (-<), and the match of planned eventsonto actual events (g).
For the example described.
.
.
.
above::the sub-net- of  the:a'eferential: :net ~that con-tains the actual events (the ones that have sort A-Event) is depicted in Figure 3 (the velocity prob-lem is just detected).
MOVE2, for example, is tem-porally included in the event TAXI (MOVE2 ETAXI), the event MOVEt is the temporal predeces-sor of  MOVE2 (MOVEi -< MOVE?
), a matching be-tween a planned and an actual event is p.(MOVE~,?
MOVErs), where MOVt!~ stands for the planned89TAXl= JMOVE 1_.................STARTi _ CHPOS~ -- SSTOPi - START2 ~, ~CHPOS2 ~ ~ _..~SqOP2 /F b-'..
I FSl S2 $3  S4  $5 $6' S7  S8 59 SIO-SII -SI2 S13 S14 SIS SI6 SI7 518-.< -< .< -< -< -< -'< .K -< "< "< -K '< -< < -< -.KFigure 3.
The Knowledge Representation f r the Example (STOP2 is only expected)movement from position A to B.MOVE is a label for complex events that con-sists o f  maximal ly  three sub-events,  namelySTART, CHPOS (CHANGE OF POSITION), and STOP,where the first and the last sub-event are optionaland the middle event can be any kind o f  move-ment along a trajectory.
START, CHPOS, and STOPnodes contain the sensor data nodes S. Temporalinclusion relates also TAXI and the basic eventsand MOVE and basic events, but are left: out in thefigure to keep it readable.
The precedence rela-tion, though, exists explicitly only between nodesof  the same granularity, i.e.
between the basicevents and between the nodes of  each intermediatelevel, e.g.
CHPOS~ -< STOPi '< START2; the implicitprecedences have to be derived from these.
The Itrelation is not included in Figure 3.
We use foursorts to subdivide the CCR into four sub-nets,each consisting of  refOs of  one sort: planned event(P-Event), actual  event  (A-Event), problem(Problem), and real-world object (R-Object).The construction process, which builds up therepresentation f the actually registered events andto detect problems, can be realized by the follow-ing algorithm1.
Generate a new node for the basic entity that is pro-vided by the pre-processing unit.
Link it to othernodes according to the information (i.e., attributes)coming with the basic entity.2.
Take the new node, possibly with related nodes--especially those that stand in the ~ relation to thisone--and hand them over to the concept matcher tofind the best matching complex concept hat con-tains these nodes--if there is any~and to find (pos-sible) problems.3.
In case there is a problem, create a new node for it,and link it to the involved nodes.
Continue with step2.
(In step 2 the 'new' node is the 'old" one, not theproblem node!)
In case of a complex concept, createa new node for it, together with the simpler nodesthat are still lacking (generation of expectations),and link it to the basic nodes it subsumes.4.
Tr3.'
to find relations to other complex nodes withwhich links can be established.5.
Continue with step 2 to try to find more complexconcepts and problems, until the next new basic en-tity enters the system or until there are no morecomplex concepts.
Then proceed with step 1.In the following application o f  this algorithm tothe example, the It relation is left out until theproblem is identified.
Up to that point, each node,except for the S nodes, has a corresponding one inthe sub-structure of  planned events, related by It.a.
s l is read by the construction process as a basicevent and inserted into the (up to now empty)knowledge representation.
(step 1)b.
This node is handed over to the concept matcher(there are no related nodes, yet), which respondsthat this is a START event.
(2)c. STARTi is generated and linked via E to s~.
(3)d. Steps 4 and 5 yield no results.e.
$2, the next basic event, is inserted.
A .< relationbetween the two s nodes is established.
(1)f. Because of their temporal vicinity the two s nodesare taken and given to the concept matcher, whichcomputes a CHPOS event.
(2)g. CHPOSt iS generated and linked via .G to S2.
(3) (Itwould equally be possible to take $2 and S~ to beparts of CHPOSt.
The only reason we chose this pos-sibility is that it preserves the tree structure--atleast for the moment.)h.
STARTi and CHPOSi are linked by -<.
(4)i.
Now STARTi and CHPOS~ are given to the conceptmatcher, which joins them together in a complexevent MOVE (5, 2).MOVE1 and.the 'expectation' .
ode STOPi are gener-ated and MOVEi iS linked via m to its elements (3).Step 4 yields no result..MOVE1 is just,part o f  a-more:complex vent TAXI.
(5, 2)TAXI is inserted and linked via E to MOVEi.
(3)Node Ss is read and subsumed to CHPOS~.
In thisstep the attributes of CHPOS~ are updated.
(Espe-cially interesting for our example: the velocity at-tribute.)o.
Nodes 54 to s7 are integrated and subsumed toCHPOS~.j,k.Lnl .n.90.essary changes(replacements)in the ,traverse, be-cause the pvm-generation already took the ele-ments that would otherwise have been replaced.After the latency time of a node is elapsed thepvm-generation passes it on to the subsequentprocess of the formulator.
This means--as we ar-gued above--that propositions exist only 'piece-: .
.
.
.
.
._ wise'.
Complete propositions exist, then, on ahigher level of abstraction.
When the PROBLEMvSOCCER, 449-4,54.
P rac.
of the 8tttECAL Munich.Australian Bureau of Air Safety Investigation.http://www.basi.gov.auAvrahami, J.
& Kareev, Y.
(1994) The emergence ofevents.
Cognition, 53,239-261.Baddeley, A.
(!
986) Working Memory.
Oxford: OxfordUniversity Press.Cahill, L.; Doran, Ch.
; Evans, R.; Mellish, Ch.
; Pava,D.
; Reape, M.; Scott, D. & Tipper, N. (1999) Insearch of a reference architecture-for NLG systems.EWNLG-1999, Toulouse.node is sel ected.as~ a pr~.x~er.bal ~'messages~informa~ ~,~v.:.~.~:~3hu~Catrolk.
J:t~O.~(2arberazy:,.
:S,.~( 1998 ) ~o|taborative.
re-tion about what is the problematic event (movingtoo fast), the object involved (the aircraft with theflight number CK-314) and about the location ofthe movement (taxiway Echo) have to be con-veyed.
This is done by handing on not only thePROBLEMv node but also further nodes that containinformation about he event (in the CHPOS2 node),the flight (in a FLIGHT node), and about the loca-tion (in a TW-ECHO node).
Thus, the pvm-generation considers ome important relations toother nodes before the PROBLEMv node is passedon, and checks what other nodes are needed forthe verbalization and passes them on, as well.The formulator can establish interrelationsbetween the refOs by the ascribed relations, e.g.the PROBLEMv node contains an actor relation tothe FLIGHT node, which enables the formulator tolook up all necessary information at the relevantnodes.
Taken together they are now equivalent toa proposition like problem(ck-314, veloc-ity(tooHigh), tw-Echo, goal(rw27).4 ConclusionWe presented a psycholinguistically motivated ar-chitecture of an incremental conceptualizer to-gether with some remarks on its prototypicalimplementation a d how this implementation canbe used for monitoring purposes.
The conceptual-izer watches dynamic changes in the world andgenerates on-line propositional, preverbal struc-tures that can serve as input to a subsequent com-ponent, which encodes these structures linguisti-cally.ReferencesAbb, B.; Gfinther, C.; Herweg, M.; Lebeth, K:; Maien-born, M. & Schopp, A.
(1996) Incremental gram-matical encoding--an outline of the SYNPHONICSformulator.
In G. Adorni & M. Zock, eds., Trends innatural language generation: An artificial intelli-gence perspective, 277-299, Berlin: Springer.Andr6, E.; Herzog, G. & Rist, T. (1988) On the simul-taneous interpretation f real world image sequencesand-their natural anguage description: The systemsponse generation i  planning dialogues.
Computa-tional Linguistics, 24, 355-400.De Smedt, K.; Horacek, H. & Zock, M. (1996) Archi-tectures for natural anguage generation: Problemsand perspectives.
In G. Adorni & M. Zock, eds.,Trends in natural language generation, Berlin:Springer.De Smedt, K. & Kempen, G. (1987) Incremental sen-tence production: Self-correction and coordination.In G. Kempen, ed., Natural language generation,365-76, Boston: Martinus Nijhoff.Ferreira, F. (1996) Is it better to give than donate?Syntactic flexibility in language production.
Journalof Memory and Language, 35,724-755.Habel, Ch.
(1986) Prinzipien der Referentialitdt: Un-tersuchungen zur propositionalen Reprdsentationyon Wissen.
Berlin: Springer.Habel, Ch.
& Tappe, H. (1999) Processes of segmenta-tion and linearization i describing events.
In R. Kla-bunde & C. von Stutterheim, eds., Representationsand Processes in Language Production, 117-153,Wiesbaden: Deutscher Universit~ts-Verlag.Hovy, E. H. (1993) Automated iscourse generationusing discourse structure relations.
Artoqcial Intelli-gence, 63,341-385.Levelt, W.J.M.
(1989) Speaking: From intention to ar-ticulation.
Cambridge, MA: MIT Press.Marcu, D. (1997) From local to global coherence: Abottom-up approach to text planning.
Proc.
AAAI 97,629-635.McKeown, K. (1985) Text generation.
Cambridge:Cambridge University Press.Neumann, B.
& Novak, H. -J.
(1983).
Event models forrecognition and natural language.
IJCAI-83,724-726.Radev, D. R. & McKeown, K. (1998) Generating natu-ral language summaries from multiple on-linesources.
Computational Linguistics, 24,469-500.Reiter E. (1994) Has a consensus NL generation archi-tecture appeared, and is it psycholinguistically p au-sible?
IWNLG-1994, J63-170,Kennebunkport, ME.Reithinger, N. (1992) The Performance of an incre-mental generation component for multi-modal dialogcontributions.
In: R. Dale, E. Hovy, D. R6sner & O.Stock, eds.~ Aspects of automated-natural languagegeneration, 263-276, Berlin: Springer.Schank, R. C. & Abelson, R. P. (1977) Scripts, plans,goals and understanding: An inquit T into humanknowledge structures.
Hitlsdale: Lawrence Erlbaum.Zacks, J.
(1997) Seeing the structure in events.
Manu-script, Stanford University.92
