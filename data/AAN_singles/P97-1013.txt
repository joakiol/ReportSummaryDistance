The Rhetorical Parsing of Natural Language TextsDaniel MarcuDepar tment  of  Computer  ScienceUnivers i ty of  TorontoToronto,  Ontar ioCanada M5S 3G4marcu~cs, toronto, eduAbstractWe derive the rhetorical structures of textsby means of two new, surface-form-basedalgorithms: one that identifies discourseusages of cue phrases and breaks sen-tences into clauses, and one that producesvalid rhetorical structure trees for unre-stricted natural language texts.
The algo-rithms use information that was derivedfrom a corpus analysis of cue phrases.1 IntroductionResearchers of natural language have repeatedly ac-knowledged that texts are not just a sequence of wordsnor even a sequence of clauses and sentences.
However,despite the impressive number of discourse-related theo-ries that have been proposed so far, there have emergedno algorithms capable of deriving the discourse struc-ture of an unrestricted text.
On one hand, efforts suchas those described by Asher (1993), Lascarides, Asher,and Oberlander (1992), Kamp and Reyle (1993), Groveret al (1994), and Pr0st, Scha, and van den Berg (1994)take the position that discourse structures can be builtonly in conjunction with fully specified clause and sen-tence structures.
And Hobbs's theory (1990) assumesthat sophisticated knowledge bases and inference mech-anisms are needed for determining the relations betweendiscourse units.
Despite the formal elegance of theseapproaches, they are very domain dependent and, there-fore, unable to handle more than a few restricted exam-pies.
On the other hand, although the theories describedby Grosz and Sidner (1986), Polanyi (1988), and Mannand Thompson (1988) are successfully applied manually,they ,are too informal to support an automatic approachto discourse analysis.In contrast with this previous work, the rhetoricalparser that we present builds discourse trees for unre-stricted texts.
We first discuss the key concepts on whichour approach relies (section 2) and the corpus analysis(section 3) that provides the empirical data for our rhetor-ical parsing algorithm.
We discuss then an algorithm thatrecognizes discourse usages of cue phrases and that de-termines clause boundaries within sentences.
Lastly, wepresent the rhetorical parser and an example of its opera-tion (section 4).2 FoundationThe mathematical foundations of the rhetorical parsingalgorithm rely on a first-order formalization of valid textstructures (Marcu, 1997).
The assumptions of the for-malization are the following.
1.
The elementary unitsof complex text structures are non-overlapping spans oftext.
2.
Rhetorical, coherence, and cohesive relationshold between textual units of various sizes.
3.
Rela-tions can be partitioned into two classes: paratactic andhypotactic.
Paratactic relations are those that hold be-tween spans of equal importance.
Hypotactic relationsare those that hold between a span that is essential for thewriter's purpose, i.e., a nucleus, and a span that increasesthe understanding of the nucleus but is not essential forthe writer's purpose, i.e., a satellite.
4.
The abstractstructure of most texts is a binary, tree-like structure.
5.If a relation holds between two textual spans of the treestructure of a text, that relation also holds between themost important units of the constituent subspans.
Themost important units of a textual span are determined re-cursively: they correspond to the most important unitsof the immediate subspans when the relation that holdsbetween these subspans i paratactic, and to the most im-portant units of the nucleus subspan when the relationthat holds between the immediate subspans i hypotactic.In our previous work (Marcu, 1996), we presented acomplete axiomatization of these principles in the con-text of Rhetorical Structure Theory (Mann and Thomp-son, 1988) and we described an algorithm that, startingfrom the set of textual units that make up a text andthe set of elementary rhetorical relations that hold be-tween these units, can derive all the valid discourse treesof that text.
Consequently, if one is to build discoursetrees for unrestricted texts, the problems that remain tobe solved are the automatic determination of the tex-tual units and the rhetorical relations that hold betweenthem.
In this paper, we show how one can find and ex-ploit approximate solutions for both of these problemsby capitalizing on the occurrences ofcertain lexicogram-matical constructs.
Such constructs can include tense96and aspect (Moens and Steedman, 1988; Webber, 1988;Lascarides and Asher, 1993), certain patterns of pronom-inalization and anaphoric usages (Sidner, 1981; Groszand Sidner, 1986; Sumita et al, 1992; Grosz, Joshi, andWeinstein, 1995),/t-clefts (Delin and Oberlander, 1992),and discourse markers or cue phrases (Ballard, Conrad,and Longacre, 1971; Halliday and Hasan, 1976; VanDijk, 1979; Longacre, 1983; Grosz and Sidner, 1986;Schiffrin, 1987; Cohen, 1987; Redeker, 1990; Sanders,Spooren, and Noordman, 1992; Hirschberg and Litman,1993; Knott, 1995; Fraser, 1996; Moser and Moore,1997).
In the work described here, we investigate how farwe can get by focusing our attention only on discoursemarkers and lexicogrammatical constructs that can bedetected by a shallow analysis of natural language texts.The intuition behind our choice relies on the followingfacts:?
Psycholinguistic and other empiricalresearch (Kintsch, 1977; Schiffrin, 1987; Segal,Duchan, and Scott, 1991; Cahn, 1992; Sanders,Spooren, and Noordman, 1992; Hirschberg andLitman, 1993; Knott, 1995; Costermans andFayol, 1997) has shown that discourse markersare consistently used by human subjects both ascohesive ties between adjacent clauses and as"macroconnectors" between larger textual units.Therefore, we can use them as rhetorical indica-tors at any of the following levels: clause, sen-tence, paragraph, and text.?
The number of discourse markers in a typicaltext - -  approximately one marker for every twoclauses (Redeker, 1990) - -  is sufficiently large toenable the derivation of rich rhetorical structuresfor texts.?
Discourse markers are used in a manner that isconsistent with the semantics and pragmatics ofthe discourse segments that they relate.
In otherwords, we assume that the texts that we pro-cess are well-formed from a discourse perspec-tive, much as researchers in sentence parsing as-sume that they are well-formed from a syntacticperspective.
As a consequence, we assume thatone can bootstrap the full syntactic, semantic, andpragmatic analysis of the clauses that make upa text and still end up with a reliable discoursestructure for that text.Given the above discussion, the immediate objectionthat one can raise is that discourse markers are doublyambiguous: in some cases, their use is only sentential,i.e., they make a semantic ontribution to the interpre-tation of a clause; and even in the cases where markershave a discourse usage, they are ambiguous with respectto the rhetorical relations that they mark and the sizes ofthe textual spans that they connect.
We address now eachof these objections in turn.Sentential and discourse usages of cue phrases.Empirical studies on the disambiguation of cuephrases (Hirschberg and Litman, 1993) have shown thatjust by considering the orthographic environment inwhich a discourse marker occurs, one can distinguishbetween sentential nd discourse usages in about 80% ofcases.
We have taken Hirschberg and Litman's researchone step further and designed a comprehensive corpusanalysis that enabled us to improve their results and cov-erage.
The method, procedure, and results of our corpusanalysis are discussed in section 3.Discourse markers are ambiguous with respect o therhetorical relations that they mark and the sizes of theunits that they connect.
When we began this research,no empirical data supported the extent o which this am-biguity characterizes natural anguage texts.
To betterunderstand this problem, the corpus analysis described insection 3 was designed so as to also provide informationabout he types of rhetorical relations, rhetorical statuses(nucleus or satellite), and sizes of textual spans that eachmarker can indicate.
We knew from the beginning that itwould be impossible to predict exactly the types of rela-tions and the sizes of the spans that a given cue marks.However, given that the structure that we are trying tobuild is highly constrained, such a prediction proved tobe unnecessary: the overall constraints on the structure ofdiscourse that we enumerated in the beginning of this sec-tion cancel out most of the configurations of elementaryconstraints hat do not yield correct discourse trees.Consider, for example, the following text:(1) \[Although discourse markers are ambiguous, l\]\[one can use them to build discourse trees forunrestricted texts: 2\] \[this will lead to many newapplications in natural language processing)\]For the sake of the argument, assume that we are able tobreak text (1) into textual units as labelled above andthat we are interested now in finding rhetorical rela-tions between these units.
Assume now that we caninfer that Although marks a CONCESSIVE relation be-tween satellite 1 and nucleus either 2 or 3, and the colon.all ELABORATION between satellite 3 and nucleus either1 or 2.
If we use the convention that hypotactic rela-tions are represented asfirst-order predicates having theform rhet_rel(NAME, satellite, nucleus) and that paratac-tic relations are represented aspredicates having the formrhet_rel(NAME, nucleust, nucleus2), a correct representa-tion for text (1) is then the set of two disjunctions givenin (2):rhet_rel(CONCESSlON, 1,2) Vrhet_rel( CONCESSION, 1,3)(2) rhet_rel(ELABORATION, 3, 1)Vrhet_rel(ELABORATION, 3, 2)Despite the ambiguity of the relations, the over-all rhetorical structure constraints will associate onlyone discourse tree with text (1), namely the treegiven in figure 1: any discourse tree configura-tion that uses relations rhet_rel(CONCESSlON, 1,3) andrhet-reI(ELABORATION, 3, 1) will be ruled out.
For ex-ample, relation rhet_reI(ELABORATION, 3, 1) will be ruled97LABORATION1 2Figure 1: The discourse tree of text (1).out because unit I is not an important unit for span \[1,2\]and, as mentioned at the beginning of this section, arhetorical relation that holds between two spans of a validtext structure must also hold between their most impor-tant units: the important unit of span \[1,2\] is unit 2, i.e.,the nucleus of the relation rhet_rel(CONCESSlON, 1,2).3 A corpus analysis of discourse markers3.1 MaterialsWe used previous work on cue phrases (Halliday andHasan, 1976; Grosz and Sidner, 1986; Martin, 1992;Hirschberg and Litman, 1993; Knott, 1995; Fraser, 1996)to create an initial set of more than 450 potential dis-course markers.
For each potential discourse marker, wethen used an automatic procedure that extracted from theBrown corpus aset of text fragments.
Each text fragmentcontained a "window" of approximately 200 words andan emphasized occurrence of a marker.
On average, werandomly selected approximately 19 text fragments permarker, having few texts for the markers that do not occurvery often in the corpus and up to 60 text fragments formarkers uch as and, which we considered to be highlyambiguous.
Overall, we randomly selected more than7900 texts.All the text fragments associated with a potential cuephrase were paired with a set of slots in which an ana-lyst described the following.
1.
The orthographic en-vironment that characterizes the usage of the potentialdiscourse marker.
This included occurrences of periods,commas, colons, semicolons, etc.
2.
The type of usage:Sentential, Discourse, or Both.
3.
The position of themarker in the textual unit to which it belonged: Begin-ning, Medial, or End.
4.
The right boundary of the textualunit associated with the marker.
5.
The relative positionof the textual unit that the unit containing the marker wasconnected to: Before or After.
6.
The rhetorical relationsthat the cue phrase signaled.
7.
The textual types of theunits connected by the discourse marker: from Clauseto Multiple_Paragraph.
8 The rhetorical status of eachtextual unit involved in the relation: Nucleus or Satel-lite.
The algorithms described in this paper ely on theresults derived from the analysis of 1600 of the 7900 textfragments.3.2 ProcedureAfter the slots for each text fragment were filled, theresults were automatically exported into a relationaldatabase.
The database was then examined semi-automatically with the purpose of deriving proceduresthat a shallow analyzer could use to identify discourseusages of cue phrases, break sentences into clauses, andhypothesize rhetorical relations between textual units.For  each discourse usage of a cue phrase, we derivedthe following:?
A regular expression that contains an unambigu-ous cue phrase instantiation and its orthographicenvironment.
A cue phrase is assigned a regu-lar expression if, in the corpus, it has a discourseusage in most of its occurrences and if a shallowanalyzer can detect it and the boundaries of thetextual units that it connects.
For example, theregular expression "\[,\] although" identifies ucha discourse usage.?
A procedure that can be used by a shallow ana-lyzer to determine the boundaries of the textualunit to which the cue phrase belongs.
For exam-ple, the procedure associated with "\[,\] although"instructs the analyzer that the textual unit thatpertains to this cue phrase starts at the marker andends at the end of the sentence or at a position tobe determined by the procedure associated withthe subsequent discourse marker that occurs inthat sentence.?
A procedure that can be used by a shallow ana-lyzer to hypothesize the sizes of the textual unitsthat the cue phrase relates and the rhetorical re-lations that may hold between these units.
Forexample, the procedure associated with "\[,\] al-though" will hypothesize that there xists a CON-CESSION between the clause to which it belongsand the clause(s) that went before in the samesentence.
For most markers this procedure makesdisjunctive hypotheses of the kind shown in (2)above.3.3 ResultsAt the time of writing, we have identified 1253 occur-rences of cue phrases that exhibit discourse usages andassociated with each of them procedures that instructa shallow analyzer how the surrounding text should bebroken into textual units.
This information is used by analgorithm that concurrently identifies discourse usages ofcue phrases and determines the clauses that a text is madeof.
The algorithm examines a text sentence by sentenceand determines a set of potential discourse markers thatoccur in each sentence, It then applies left to fight theprocedures that are associated with each potential marker.These procedures have the following possible ffects:?
They can cause an immediate breaking of the cur-rent sentence into clauses.
For example, whenan "\[,\] although" marker is found, a new clause,whose right boundary is just before the occur-rence of the marker, is created.
The algorithm isthen recursively applied on the text that is found98TextText.2.3.'TotalNo.
ofsentences1.
2422.
803.
19Total 341No.
of discoursemarkers identifiedmanually1746338275No.
of discoursemarkers identifiedby the algorithm1695524248No.
of discourse Recall Precisionmarkers identifiedcorrectlyby the algorithm150 86.2% 88.8%49 77.8% 89.1%23 63.2% 95.6%222 80.8% 89.5%Table 1: Evaluation of the marker identification procedure.No.
of clauseboundaries identifiedmanuallyo42815161640No.
of clauseboundaries identifiedby the algorithm41612337576No.
of clauseboundaries identifiedcorrectlyby the algorithm37111336520Table 2: Evaluation of the clause boundary identification procedure.Recall Precision86.7% 89.2%74.8% 91.8%59.0% 97.3%81.3% 90.3%between the occurrence of"\[,\] although" and theend of the sentence.?
They can cause the setting of a flag.
For example,when an "Although " marker is found, a flag isset to instruct he analyzer to break the currentsentence at the first occurrence of a comma.?
They can cause a cue phrase to be identified ashaving a discourse usage.
For example, when thecue phrase "Although" is identified, it is also as-signed adiscourse usage.
The decision of whethera cue phrase is considered to have a discourse us-age is sometimes based on the context in whichthat phrase occurs, i.e., it depends on the occur-rence of other cue phrases.
For example, an "and"will not be assigned adiscourse usage in most ofthe cases; however, when it occurs in conjunctionwith "although", i.e., "and although", it will beassigned such a role.The most important criterion for using a cue phrase inthe marker identification procedure is that the cue phrase(together with its orthographic neighborhood) is used asa discourse marker in at least 90% of the examples thatwere extracted from the corpus.
The enforcement ofthis criterion reduces on one hand the recall of the dis-course markers that can be detected, but on the otherhand, increases significantly the precision.
We chose thisdeliberately because, during the corpus analysis, we no-ticed that most of the markers that connect large textualunits can be identified by a shallow analyzer.
In fact,the discourse marker that is responsible for most of ouralgorithm recall failures is and.
Since a shallow analyzercannot identify with sufficient precision whether an oc-currence of and has a discourse or a sentential usage, mostof its occurrences are therefore ignored.
It is true that,in this way, the discourse structures that we build losesome potential finer granularity, but fortunately, from arhetorical analysis perspective, the loss has insignificantglobal repercussions: the vast majority of the relationsthat we miss due to recall failures of and are JOINT andSEQUENCE relations that hold between adjacent clauses.Evaluation.
To evaluate our algorithm, we randomlyselected three texts, each belonging to a different genre:1. an expository text of 5036 words from ScientificAmerican;2. a magazine article of 1588 words from 7~me;3. a narration of 583 words from the Brown Corpus.Three independent judges, graduate students in computa-tional inguistics, broke the texts into clauses.
The judgeswere given no instructions about he criteria that they hadto apply in order to determine the clause boundaries;rather, they were supposed to rely on their intuition andpreferred efinition of clause.
The locations in texts thatwere labelled as clause boundaries by at least two of thethree judges were considered to be "valid clause bound-aries".
We used the valid clause boundaries assigned byjudges as indicators of discourse usages of cue phrasesand we determined manually the cue phrases that sig-nalled a discourse relation.
For example, if an "and" wasused in a sentence and if the judges agreed that a clauseboundary existed just before the "and", we assigned that"and" a discourse usage.
Otherwise, we assigned it asentential usage.
Hence, we manually determined alldiscourse usages of cue phrases and all discourse bound-aries between elementary units.We then applied our marker and clause identificationalgorithm on the same texts.
Our algorithm found 80.8%of the discourse markers with a precision of 89.5% (see99INPUT: a text T.1.
Determine the set D of all discourse markers andthe set Ur of elementary textual units in T.2.
Hypothesize a set of relations R between theelements of Ur.3.
Use a constraint satisfaction procedure to determineall the discourse trees of T.4.
Assign a weight o each of the discourse trees anddetermine the tree(s) with maximal weight.Figure 2: Outline of the rhetorical parsing algorithmtable 1), a result that outperforms Hirschberg and Lit-man's (1993).
The same algorithm identified correctly81.3 % of the clause boundaries, with a precision of 90.3 %(see table 2).
We are not aware of any surface-form-basedalgorithms that achieve similar esults.4 Building up discourse trees4.1 The rhetorical parsing algorithmThe rhetorical parsing algorithm is outlined in figure 2.In the first step, the marker and clause identification algo-rithm is applied.
Once the textual units are determined,the rhetorical parser uses the procedures derived fromthe corpus analysis to hypothesize rhetorical relationsbetween the textual units.
A constraint-satisfaction pro-cedure similar to that described in(Marcu, 1996) then de-termines all the valid discourse trees (see (Marcu, 1997)for details).
The rhetorical parsing algorithm has beenfully implemented in C++.Discourse is ambiguous the same way sentences are:more than one discourse structure isusually produced fora text.
In our experiments, we noticed, at least for En-glish, that he "best" discourse trees are usually those thatare skewed to the right.
We believe that the explanationof this observation is that text processing is, essentially,a left-to-rightprocess.
U ually, people write texts o thatthe most important ideas go first, both at the paragraphand at the text level) The more text writers add, the morethey elaborate on the text that went before: as a conse-quence, incremental discourse building consists mostlyof expansion of the right branches.
In order to deal withthe ambiguity of discourse, the rhetorical parser com-putes a weight for each valid discourse tree and retainsonly those that are maximal.
The weight function reflectshow skewed to the right a tree is.4.2 The rhetorical parser in operationConsider the following text from the November 1996issue of Scientific American (3).
The words in italicsdenote the discourse markers, the square brackets denotel In fact, journalists axe trained to employ this "pyramid"approach to writing consciously (Cumming and McKercher,1994).the boundaries of elementary textual units, and the curlybrackets denote the boundaries of parenthetical textualunits that were determined by the rhetorical parser (seeMarcu (1997) for details); the numbers associated withthe square brackets are identification labels.
(3) \[With its distant orbit {-- 50 percent far-ther from the sun than Earth --}and slim at-mospheric blanket, 1\] \[Mars experiences frigidweather conditions.
2\] \[Surface t mperatures typ-ically average about -60 degrees Celsius ( -76degrees Fahrenheit) at the equator and can dipto -123 degrees C near the poles)\] \[Only themidday sun at tropical latitudes i  warm enoughto thaw ice on occasion:\] [but any liquid wa-ter formed in this way would evaporate al-most instantly 5\] \[because of the low atmosphericpressure.
6 \]\[Although the atmosphere holds a smallamount of water, and water-ice clouds ometimesdevelop, 7\] \[most Martian weather involves blow-ing dust or carbon dioxide)\] [Each winter,for ex-ample, a blizzard of frozen carbon dioxide ragesover one pole, and a few meters of this dry-ice snow accumulate as previously frozen carbondioxide vaporates from the opposite polar cap.
9\]\[Yet even on the summer pole, { where the sun re-mains in the sky all day long,} temperatures neverwarm enough to melt frozen water) ?\]Since parenthetical information is related only to the el-ementary unit that it belongs to, we do not assign it anelementary textual unit status.
Such an assignment willonly create problems at the formal evel as well, becausethen discourse structures can no longer be represented asbinary trees.On the basis of the data derived from the corpus ,anal-ysis, the algorithm hypothesizes the following set of re-lations between the textual units:rhet_rel(JUSTIFICATION, 1 2) Vrhet..rel(CONDITION, 1,2)rhet_rel(ELABORATION, 3, \[1,2\]) Vrhet_reI(ELABORATION, \[3, 6\], \[ 1,2\])rhet_rel(El_ABOgATlON, \[4, 6\], 3) Vrhet_ret(ELABOr~YlON, \[4  6\], \[1, 3\])rhet_rel(CONTRAST, 4, 5)(4) rhet_rel(EVIDENCE, 6, 5)rhet_reI(ELABORATION, \[7, 10\], \[1,6\])rhet_rel(CONCESSION, 7, 8)rhet_rel(EXAMPLE, 9 \[7, 8\]) Vrhet_rel(EXAMPLE, \[9, 10\], \[7, 8\])rhet_rel(ANTITHESlS, 9, 10) Vrhet_rel(ANTITHESlS, \[7,9\], 10)The algorithm then determines all the valid discoursetrees that can be built for elementary units 1 to 10, giventhe constraints in (4).
In this case, the algorithm con-structs 8 different trees.
The trees are ordered accordingto their weights.
The "best" tree for text (3) has weight3 and is fully represented in figure 3.
The PostScript filecorresponding to figure 3 was automatically generated by100: Exempl i f icat ion ??
(, fo rexample , )  '.
.
.
.
.
.
I" .
.
.
.
?.
.
.
.
.
.
.
.
!
- .
.
.DJustificalion.Co~lion , C .
.
.
.
ion \[ " "~n; i t~ is  :.
'(wth) .
'~,~,~o,:, ."
~th.g i ~  : (wt)/ , - .
.
.
.
%.?
. '
?
/ ??
/ "Each winter,ex~mxple, a bli~atd "N~?
- -o -T  of ~ , .
.
~n  \ t .... &oxide rages over' \[ Surfaos ?I tm~r,u~,s  .
.
.
.
.
.
.
.
.
. '
.
.
\[ typically avenge ...... ;\[ about -60 dag l~ :atmo~herehokk~a mostMattian I onepole, andafew Yetevenonthe \[Withil.ldhllant Mm~exl~tien?~l \[ eclairs(-76 " "'  .
.
.
.
.
smal l J~ountof ~athetthvolve~ I melelnofthia \ [sumn~rpole-P-teml~raml~n~et \]?tbit 'P" and sl~m frigid weather \[ dagr- -  Fahzenheit) "C?nmut " ' 1 - \] I ta~osphcafiCblanket, oonthlion3.
I'g at tl~ eq .
.
.
.
.
d i !
,but ) :  water-icewal~r' andclouds blowing du~ orcarbon  dioxide.
\[ accemnlttedl~'i .
.
.
.
.
.
.
.
.
 fa~n gh to n~ltwat~.
(I) .
(2) l \[ ?an dip to .123 t ~"  ~meti~esdevelop,.
(8) previotLslyfrozen (10).
.
.
.
.
.
.
.
.
.
.
\[ aegr~s C n~ tl~ / \ (7) ~ carbon ,~oxi,t-poles. '
.
.
.
.
.
.
.
.
.
.
.
evaporates from the(3) !
op pc,~li t.. polar cap.
(9)' \Only  the midday sun I- 50 ~rc~nt at Izopical ___ ~1farther from the latitudes b warm \[ Evidence .
where the sun r~.~ml in the skySUla I~lm Earth - enough to thaw ice \[ ( becanse ) all day long,on ~on.............
!.
'2 ............. / ""?
'.but any liquid \[ .
.
.
.
: .
.
.
.
.
.water formed in \[ , because ofthe lowthis way would \[ " atmo~het~cevaporate almo~ \[ ?
ppe~sure.instantly \[ : (6)P?__ I " .
.
.
.
.
.
.
.
.
.Figure 3: The discourse tree of maximal weight that can be associated with text (3).a back-end ,algorithm that uses "dot", a preprocessor fordrawing directed graphs.
The convention that we use isthat nuclei are surrounded by solid boxes and satellitesby dotted boxes; the links between a node and the subor-dinate nucleus or nuclei are represented by solid arrows,and the links between a node and the subordinate satel-lites by dotted lines.
The occurrences of parentheticalinformation are marked in the text by a -P -  and a uniquesubordinate satellite that contains the parenthetical infor-mation.4.3  Discussion and evaluationWe believe that there are two ways to evaluate the cor-rectness of the discourse trees that an automatic processbuilds.
One way is to compare the automatically derivedtrees with trees that have been built manually.
Anotherway is to evaluate the impact hat the discourse trees thatwe derive automatically have on the accuracy of othernatural anguage processing tasks, such as anaphora res-olution, intention recognition, or text summarization.
Inthis paper, we describe valuations that follow both theseavenues.Unfortunately, the linguistic community has not yetbuilt a corpus of discourse trees against which our rhetor-ical parser can be evaluated with the effectiveness thattraditional parsers are.
To circumvent this problem, twoanalysts manually built the discourse trees for five textsthat ranged from 161 to 725 words.
Although there weresome differences with respect o the names of the rela-tions that the analysts used, the agreement with respect tothe status assigned to various units (nuclei and satellites)and the overall shapes of the trees was significant.In order to measure this agreement we associated animportance score to each textual unit in a tree and com-puted the Spearman correlation coefficients between theimportance scores derived from the discourse trees builtby each analyst?
The Spearman correlation coefficient2The Spearman rank correlation coefficient is an alternativeto the usual correlation coefficient.
It is based on the ranks ofthe data, and not on the data itself, and so is resistant to outliers.The null hypothesis tested by Spearman is that two variables101between the ranks assigned for each textual unit on thebases of the discourse trees built by the two analysts wasvery high: 0.798, atp < 0.0001 level of significance.
Thedifferences between the two analysts came mainly fromtheir interpretations of two of the texts: the discoursetrees of one analyst mirrored the paragraph structure ofthe texts, while the discourse trees of the other mirroreda logical organization of the text, which that analyst be-lieved to be important.The Spearman correlation coefficients with respect tothe importance of textual units between the discoursetrees built by our program and those built by each analystwere 0.480, p < 0.0001 and 0.449, p < 0.0001.
Theselower correlation values were due to the differences inthe overall shape of the trees and to the fact that thegranularity of the discourse trees built by the programwas not as fine as that of the trees built by the analysts.Besides directly comparing the trees built by the pro-gram with those built by analysts, we also evaluated theimpact that our trees could have on the task of sum-marizing text.
A summarization program that uses therhetorical parser described here recalled 66% of the sen-tences considered important by 13 judges in the same fivetexts, with a precision of 68%.
In contrast, a random pro-cedure recalled, on average, only 38.4% of the sentencesconsidered important by the judges, with a precision of38.4%.
And the Microsoft Office 97 summarizer recalled41% of the important sentences with a precision of 39%.We discuss at length the experiments from which the datapresented above was derived in (Marcu, 1997).The rhetorical parser presented in this paper uses onlythe structural constraints that were enumerated in sec-tion 2.
Co-relational constraints, focus, theme, anaphoriclinks, and other syntactic, semantic, and pragmatic fac-tors do not yet play a role in our system, but we neverthe-less expect hem to reduce the number of valid discoursetrees that can be associated with a text.
We also ex-pect that other obust methods for determining coherencerelations between textual units, such as those describedby Harabagiu and Moldovan (1995), will improve theaccuracy of the routines that hypothesize the rhetoricalrelations that hold between adjacent units.We are not aware of the existence of any other hetor-ical parser for English.
However, Sumita et ,'d.
(1992)report on a discourse analyzer for Japanese.
Even if oneignores some computational "bonuses" that can be eas-ily exploited by a Japanese discourse analyzer (such asco-reference and topic identification), there are still somekey differences between Sumita's work and ours.
Partic-ularly important isthe fact that he theoretical foundationsof Sumita et al's analyzer do not seem to be able to ac-commodate he ambiguity of discourse markers: in theiraxe independent of each other, against the alternative hypothesisthat he rank of a variable is correlated with the rank of anothervariable.
The value of the statistic ranges from -1, indicatingthat high ranks of one variable occur with low ranks of theother variable, through 0, indicating no correlation between tilevariables, to + 1, indicating that high ranks of one variable occurwith high ranks of the other variable.system, discourse markers are considered unambiguouswith respect to the relations that they signal.
In contrast,our system uses a mathematical model in which this am-biguity is acknowledged and appropriately treated.
Also,the discourse trees that we build are very constrainedstructures ( ee section 2): as a consequence, we do notovergenerate invalid trees as Sumita et al do.
Further-more, we use only surface-based methods for determin-ing the markers and textual units and use clauses as theminimal units of the discourse trees.
In contrast, Sumitaet al use deep syntactic and semantic processing tech-niques for determining the markers and the textual unitsand use sentences as minimal units in the discourse struc-tures that they build.
A detailed comparison of our workwith Sumita et al's and others' work is given in (Marcu,1997).5 ConclusionWe introduced the notion of rhetorical parsing, i.e., theprocess through which natural anguage texts are au-tomatically mapped into discourse trees.
In order tomake rhetorical parsing work, we improved previous al-gorithms for cue phrase disambiguation, and proposednew algorithms for determining the elementary textualunits and for computing the valid discourse trees of atext.
The solution that we described is both general androbust.Acknowledgements.
This research would have notbeen possible without the help of Graeme Hirst; thereare no fight words to thank him for it.
I am gratefulto Melanie Baljko, Phil Edmonds, and Steve Green fortheir help with the corpus analysis.
This research wassupported by the Natural Sciences and Engineering Re-search Council of Canada.ReferencesAsher, Nicholas.
1993.
Reference to Abstract Objects inDiscourse.
Kluwer Academic Publishers, Dordrecht.Ballard, D. Lee, Robert Conrad, and Robert E. Longacre.1971.
The deep and surface grammar of interclausalrelations.
Foundations of language, 4:70-118.Cahn, Janet.
1992.
An investigation i to the correlationof cue phrases, unfilled pauses and the structuring ofspoken discourse.
In Proceedings of the IRCS Work-shop on Prosody in Natural Speech, pages 19-30.Cohen, Robin.
1987.
Analyzing the structure of argu-mentative discourse.
Computational Linguistics, 13 (1-2): 11-24, January-June.Costermans, Jean and Michel Fayol.
1997.
Processinglnterclausal Relationships.
Studies in the Productionand Comprehension f Text.
Lawrence Erlbaum Asso-ciates, Publishers.Cumming, Carmen and Catherine McKercher.
1994.The Canadian Reporter: News writing and reporting.Hartcourt Brace.102Delin, Judy L. and Jon Oberlander.
1992.
Aspect-switching and subordination: the role of/t-clefts in dis-course.
In Proceedings of the Fourteenth InternationalConference on Computational Linguistics (COLING-92), pages 281-287, Nantes, France, August 23-28.Fraser, Bruce.
1996.
Pragmatic markers.
Pragmatics,6(2): 167-190.Grosz, Barbara J., Aravind K. Joshi, and Scott Weinstein.1995.
Centering: A framework for modeling the localcoherence of discourse.
Computational Linguistics,21 (2):203-226, June.Grosz, Barbara J. and Candace L. Sidner.
1986.
Atten-tion, intentions, and the structure of discourse.
Compu-tational Linguistics, 12(3): 175-204, July-September.Grover, Claire, Chris Brew, Suresh Manandhar, and MarcMoens.
1994.
Priority union and generalization in dis-course grammars.
In Proceedings of the 32nd AnnualMeeting of the Association for ComputationalLinguis-tics (ACL-94), pages 17-24, Las Cruces, June 27-30.HaUiday, Michael A.K.
and Ruqaiya Hasan.
1976.
Co-hesion in English.
Longman.Harabagiu, Sanda M. and Dan I. Moldovan.
1995.
Amarker-propagation algorithm for text coherence.
InWorking Notes of the Workshop on Parallel Process-ing in Artificial Intelligence, pages 76-86, Montreal,Canada, August.Hirschberg, Julia and Diane Litman.
1993.
Empiricalstudies on the disambiguation f cue phrases.
Compu-tational Linguistics, 19(3):501-530.Hobbs, Jerry R. 1990.
Literature and Cognition.
CSLILecture Notes Number 21.Kamp, Hand and Uwe Reyle.
1993.
From Discourseto Logic: Introduction to ModelTheoretic Semanticsof Natural Language, Formal Logic and DiscourseRepresentation Theory.
Kluwer Academic Publishers,London, Boston, Dordrecht.
Studies in Linguistics andPhilosophy, Volume 42.Kintsch, Walter.
1977.
On comprehending stories.
InMarcel Just and Patricia Carpenter, editors, Cognitiveprocesses in comprehension.
Erlbaum, Hillsdale, NewJersey.Knott, Alistair.
1995.
A Data-Driven Methodology forMotivating aSet of Coherence Relations.
Ph.D. thesis,University of Edinburgh.Lascarides, Alex and Nicholas Asher.
1993.
Temporalinterpretation, discourse relations, and common senseentailment.
Linguistics and Philosophy, 16(5):437-493.Lascarides, Alex, Nicholas Asher, and Jon Oberlander.1992.
Inferring discourse relations in context.
In Pro-ceedings of the 30th Annual Meeting of the Associationfor Computational Linguistics (ACL-92), pages 1-8.Longacre, Robert E. 1983.
The Grammar of Discourse.Plenum Press, New York.Mann, William C. and Sandra A. Thompson.
1988.Rhetorical structure theory: Toward a functional the-ory of text organization.
Text, 8(3):243-281.Marcu, Daniel.
1996.
Building up rhetorical structuretrees.
In Proceedings of the Thirteenth National Con-ference on Artificial intelligence (AAA1-96 ), volume 2,pages 1069-1074, Portland, Oregon, August 4-8,.Marcu, Daniel.
1997.
The rhetorical parsing, sum-marization, and generation of natural anguage texts.Ph.D.
thesis, Department of Computer Science, Uni-versity of Toronto, Forthcoming.Martin, James R. 1992.
English Text.
System and Struc-ture.
John Benjamin Publishing Company, Philadel-phia/Amsterdam.Moens, Marc and Mark Steedman.
1988.
Temporal on-tology and temporal reference.
Computational Lin-guistics, 14(2): 15-28.Moser, Megan and Johanna D. Moore.
1997.
On thecorrelation of cues with discourse structure: Resultsfrom a corpus tudy.
Submitted for publication.Polanyi, Livia.
1988.
A formal model of the structure ofdiscourse.
Journal of Pragmatics, 12:601-638.Pr0st, H., R. Scha, and M. van den Berg.
1994.
Discoursegrammar and verb phrase anaphora.
Linguistics andPhilosophy, 17(3):261-327, June.Redeker, Gisela 1990.
Ideational and pragmatic markersof discourse, structure.
Journal ofPragmatics, 14:367-381.Sanders, Ted J.M., Wilbert P.M. Spooren, and Leo G.M.Noordman.
1992.
Toward a taxonomy of coherencerelations.
Discourse Processes, 15:1-35.Schiffrin, Deborah.
1987.
Discourse Markers.
Cam-bridge University Press.Segal, Erwin M., Judith F. Duchan, and Paula J. Scott.1991.
The role of interclausal connectives in narrativestructuring: Evidence from adults' interpretations ofsimple stories.
Discourse Processes, 14:27-54.Sidner, Candace L. 1981.
Focusing for interpretation fpronouns.
Computational Linguistics, 7(4):217-231,October-December.Sumita, K., K. Ono, T. Chino, T. Ukita, and S. Amano.1992.
A discourse structure analyzer for Japanese text.In Proceedings of the International Conference onFifth Generation Computer Systems, volume 2, pages1133-1140.Van Dijk, Teun A.
1979.
Pragmatic connectives.
Journalof Pragmatics, 3:447-456.Webber, Bonnie L. 1988.
Tense as discourse anaphor.Computational Linguistics, 14(2):61-72, June.103
