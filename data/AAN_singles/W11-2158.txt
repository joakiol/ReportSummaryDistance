Proceedings of the 6th Workshop on Statistical Machine Translation, pages 464?469,Edinburgh, Scotland, UK, July 30?31, 2011. c?2011 Association for Computational LinguisticsLIUM?s SMT Machine Translation Systems for WMT 2011Holger Schwenk, Patrik Lambert, Lo?
?c Barrault,Christophe Servan, Haithem Afli, Sadaf Abdul-Rauf and Kashif ShahLIUM, University of Le Mans72085 Le Mans cedex 9, FRANCEFirstName.LastName@lium.univ-lemans.frAbstractThis paper describes the development ofFrench?English and English?French statisti-cal machine translation systems for the 2011WMT shared task evaluation.
Our main sys-tems were standard phrase-based statisticalsystems based on the Moses decoder, trainedon the provided data only, but we also per-formed initial experiments with hierarchicalsystems.
Additional, new features this year in-clude improved translation model adaptationusing monolingual data, a continuous spacelanguage model and the treatment of unknownwords.1 IntroductionThis paper describes the statistical machine trans-lation systems developed by the Computer Sciencelaboratory at the University of Le Mans (LIUM) forthe 2011 WMT shared task evaluation.
We onlyconsidered the translation between French and En-glish (in both directions).
The main differenceswith respect to previous year?s system (Lambert etal., 2010) are as follows: use of more training dataas provided by the organizers, improved translationmodel adaptation by unsupervised training, a con-tinuous space language model for the translationinto French, some attempts to automatically inducetranslations of unknown words and first experimentswith hierarchical systems.
These different points aredescribed in the rest of the paper, together with asummary of the experimental results showing theimpact of each component.2 Resources UsedThe following sections describe how the resourcesprovided or allowed in the shared task were used totrain the translation and language models of the sys-tem.2.1 Bilingual dataOur system was developed in two stages.
First,a baseline system was built to generate automatictranslations of some of the monolingual data avail-able.
These automatic translations were then useddirectly with the source texts to create additional bi-texts.
In a second stage, these additional bilingualdata were incorporated into the system (see Sec-tion 5 and Tables 4 and 5).The latest version of the News-Commentary (NC)corpus and of the Europarl (Eparl) corpus (version6) were used.
We also took as training data a sub-set of the French?English Gigaword (109) corpus.We applied the same filters as last year to select thissubset.
The first one is a lexical filter based on theIBM model 1 cost (Brown et al, 1993) of each sideof a sentence pair given the other side, normalisedwith respect to both sentence lengths.
This filter wastrained on a corpus composed of Eparl, NC, and UNdata.
The other filter is an n-gram language model(LM) cost of the target sentence (see Section 3), nor-malised with respect to its length.
This filter wastrained with all monolingual resources available ex-cept the 109 data.
We generated two subsets, bothby selecting sentence pairs with a lexical cost infe-rior to 4, and an LM cost respectively inferior to 2.3(1091, 115 million English words) and 2.6 (1092, 232million English words).4642.2 Use of Automatic TranslationsAvailable human translated bitexts such as the Eu-roparl or 109 corpus seem to be out-of domain forthis task.
We used two types of automatically ex-tracted resources to adapt our system to the task do-main.First, we generated automatic translations of theprovided monolingual News corpus and selected thesentences with a normalised translation cost (re-turned by the decoder) inferior to a threshold.
Theresulting bitext contain no new translations, sinceall words of the translation output come from thetranslation model, but it contains new combinations(phrases) of known words, and reinforces the prob-ability of some phrase pairs (Schwenk, 2008).
Thisyear, we improved this method in the following way.In the original approach, the automatic translationsare added to the human translated bitexts and a com-plete new system is build, including time consumingword alignment with GIZA++.
For WMT?11, wedirectly used the word-to-word alignments producedby the decoder at the output instead of GIZA?s align-ments.
This speeds-up the procedure and yields thesame results in our experiments.
A detailed compar-ison is given in (Lambert et al, 2011).Second, as in last year?s evaluation, we automat-ically extracted and aligned parallel sentences fromcomparable in-domain corpora.
We used the AFPand APW news texts since there are available in theFrench and English LDC Gigaword corpora.
Thegeneral architecture of our parallel sentence extrac-tion system is described in detail by Abdul-Rauf andSchwenk (2009).
We first translated 91M wordsfrom French into English using our first stage SMTsystem.
These English sentences were then used tosearch for translations in the English AFP and APWtexts of the Gigaword corpus using information re-trieval techniques.
The Lemur toolkit (Ogilvie andCallan, 2001) was used for this purpose.
Searchwas limited to a window of ?5 days of the date ofthe French news text.
The retrieved candidate sen-tences were then filtered using the Translation Er-ror Rate (TER) with respect to the automatic trans-lations.
In this study, sentences with a TER below75% were kept.
Sentences with a large length differ-ence (French versus English) or containing a largefraction of numbers were also discarded.
By thesemeans, about 27M words of additional bitexts wereobtained.2.3 Monolingual dataThe French and English target language modelswere trained on all provided monolingual data.
Inaddition, LDC?s Gigaword collection was used forboth languages.
Data corresponding to the develop-ment and test periods were removed from the Giga-word collections.2.4 Development dataAll development was done on newstest2009, andnewstest2010 was used as internal test set.
The de-fault Moses tokenization was used.
However, weadded abbreviations for the French tokenizer.
Allour models are case sensitive and include punctua-tion.
The BLEU scores reported in this paper werecalculated with the tool multi-bleu.perl and are casesensitive.3 Architecture of the SMT systemThe goal of statistical machine translation (SMT) isto produce a target sentence e from a source sen-tence f .
Our main system is a phrase-based system(Koehn et al, 2003; Och and Ney, 2003), but wehave also performed some experiments with a hier-archical system (Chiang, 2007).
Both use a log lin-ear framework in order to introduce several modelsexplaining the translation process:e?
= argmax p(e|f)= argmaxe{exp(?i?ihi(e, f))} (1)The feature functions hi are the system modelsand the ?i weights are typically optimized to maxi-mize a scoring function on a development set (Ochand Ney, 2002).
The phrase-based system uses four-teen features functions, namely phrase and lexicaltranslation probabilities in both directions, sevenfeatures for the lexicalized distortion model, a wordand a phrase penalty and a target language model(LM).
The hierarchical system uses only 8 features:a LM weight, a word penalty and six weights for thetranslation model.Both systems are based on the Moses SMT toolkit(Koehn et al, 2007) and constructed as follows.465First, word alignments in both directions are cal-culated.
We used a multi-threaded version of theGIZA++ tool (Gao and Vogel, 2008).1 This speedsup the process and corrects an error of GIZA++ thatcan appear with rare words.Phrases, lexical reorderings or hierarchical rulesare extracted using the default settings of the Mosestoolkit.
The parameters of Moses were tuned onnewstest2009, using the ?new?
MERT tool.
We re-peated the training process three times, each with adifferent seed value for the optimisation algorithm.In this way we have an rough idea of the error intro-duced by the tuning process.4-gram back-off LMs were used.
The word listcontains all the words of the bitext used to train thetranslation model and all words that appear at leastten times in the monolingual corpora.
Words of themonolingual corpora containing special charactersor sequences of uppercase characters were not in-cluded in the word list.
Separate LMs were build oneach data source with the SRI LM toolkit (Stolcke,2002) and then linearly interpolated, optimizing thecoefficients with an EM procedure.
The perplexitiesof these LMs were 99.4 for French and 129.7 forEnglish.
In addition, we build a 5-gram continuousspace language model for French (Schwenk, 2007).This model was trained on all the available Frenchtexts using a resampling technique.
The continu-ous space language model is interpolated with the4-gram back-off model and used to rescore n-bestlists.
This reduces the perplexity by about 8% rela-tive.4 Treatment of unknown wordsFinally, we propose a method to actually add newtranslations to the system inspired from (Habash,2008).
For this, we propose to identity unknownwords and propose possible translations.Moses has two options when encountering an un-known word in the source language: keep it as it isor drop it.
The first option may be a good choicefor languages that use the same writing system sincethe unknown word may be a proper name.
The sec-ond option is usually used when translating betweenlanguage based on different scripts, e.g.
translating1The source is available at http://www.cs.cmu.edu/?qing/Source language Source language Target languageFrench stemmed form Englishfinies fini finishedefface?s efface?
erasedhawaienne hawaien Hawaiian... ... ...Table 1: Example of translations from French to Englishwhich are automatically extracted from the phrase-tablewith the stemmed form.from Arabic to English.
Alternatively, we propose toinfer automatically possible translations when trans-lating from a morphologically rich language, to asimpler language.
In our case, we use this approachto translate from French to English.Several of the unknown words are actually adjec-tives, nouns or verbs in a particular form that itselfis not known, but the phrase table would contain thetranslation of a different form.
As an example wecan mention the French adjective finies which is inthe female plural form.
After stemming we may beable to find the translation in a dictionary which isautomatically extracted from the phrase-table (seeTable 1).
This idea was already outlined by (Bo-jar and Tamchyna, 2011) to translate from Czech toEnglish.First, we automatically extract a dictionary fromthe phrase table.
This is done, be detecting all 1-to-1entries in the phrase table.
When there are multi-ple entries, all are kept with their lexical translationsprobabilities.
Our dictionary has about 680k uniquesource words with a total of almost 1M translations.source segment les travaux sont finistarget segment works are finisstemmed word found finitranslations found finished, endedsegment proposed works are finishedworks are endedsegment kept works are finishedTable 2: Example of the treatment of an unknown Frenchword and its automatically inferred translation.The detection of unknown words is performed bycomparing the source and the target segment in orderto detect identical words.
Once the unknown wordis selected, we are looking for its stemmed form inthe dictionary and propose some translations for theunknown word based on lexical score of the phrasetable (see Table 2 for some examples).
The snowball466Bitext #Fr Words PT size newstest2009 newstest2010(M) (M) BLEU BLEU TER METEOREparl+NC 56 7.1 26.74 27.36 (0.19) 55.11 (0.14) 60.13 (0.05)Eparl+NC+1091 186 16.3 27.96 28.20 (0.04) 54.46 (0.10) 60.88 (0.05)Eparl+NC+1092 323 25.4 28.20 28.57 (0.10) 54.12 (0.13) 61.20 (0.05)Eparl+NC+news 140 8.4 27.31 28.41 (0.13) 54.15 (0.14) 61.13 (0.04)Eparl+NC+1092+news 406 25.5 27.93 28.70 (0.24) 54.12 (0.16) 61.30 (0.20)Eparl+NC+1092+IR 351 25.3 28.07 28.51 (0.18) 54.07 (0.06) 61.18 (0.07)Eparl+NC+1092+news+IR 435 26.1 27.99 28.93 (0.02) 53.84 (0.07) 61.46 (0.07)+larger beam+pruned PT 435 8.2 28.44 29.05 (0.14) 53.74 (0.16) 61.68 (0.09)Table 4: French?English results: number of French words (in million), number of entries in the filtered phrase-table(in million) and BLEU scores in the development (newstest2009) and internal test (newstest2010) sets for the differentsystems developed.
The BLEU scores and the number in parentheses are the average and standard deviation over 3values (see Section 3)corpus newstest2010 subtest2010number of sentences 2489 109number of words 70522 3586number of UNK detected 118 118nbr of sentences containing UNK 109 109BLEU Score without UNK process 29.43 24.31BLEU Score with UNK process 29.43 24.33TER Score without UNK process 53.08 58.54TER Score with UNK process 53.08 58.59Table 3: Statistics of the unknown word (UNK) process-ing algorithm on our internal test (newstest2010) and itssub-part containing only the processed sentences (sub-test2010).stemmer2 was used.
Then the different hypothesisare evaluated with the target language model.We processed the produced translations with thismethod.
It can happen that some words are transla-tions of themselves, e.g.
the French word ?duel?
canbe translated by the English word ?duel?.
If theseswords are present into the extracted dictionary, wekeep them.
If we do not find any translation in ourdictionary, we keep the translation.
By these meanswe hope to keep named entities.Several statistics made on our internal test (new-stest2010) are shown in Table 3.
Its shows that theinfluence of the detected unknown words is minimal.Only 0.16% of the words in the corpus are actuallyunknown.
However, the main goal of this processis to increase the human readability and usefulnesswithout degrading automatic metrics.
We also ex-pect a larger impact in other tasks for which we have2http://snowball.tartarus.org/smaller amounts of parallel training data.
In futureversions of this detection process, we will try to de-tect unknown words before the translation processand propose alternatives hypothesis to the Moses de-coder.5 Results and DiscussionThe results of our SMT system for the French?English and English?French tasks are summarizedin Tables 4 and 5, respectively.
The MT metricscores are the average of three optimisations per-formed with different seeds (see Section 3).
Thenumbers in parentheses are the standard deviationof these three values.
The standard deviation givesa lower bound of the significance of the differencebetween two systems.
If the difference between twoaverage scores is less than the sum of the standarddeviations, we can say that this difference is not sig-nificant.
The reverse is not true.
Note that most ofthe improvements shown in the tables are small andnot significant.
However many of the gains are cu-mulative and the sum of several small gains makes asignificant difference.Baseline French?English SystemThe first section of Table 4 shows results of the de-velopment of the baseline SMT system, used to gen-erate automatic translations.Although no French translations were generated,we did similar experiments in the English?Frenchdirection (first section of Table 5).467Bitext #En Words newstest2009 newstest2010(M) BLEU BLEU TEREparl+NC 52 26.20 28.06 (0.22) 56.85 (0.08)Eparl+NC+1091 167 26.84 29.08 (0.12) 55.83 (0.14)Eparl+NC+1092 284 26.95 29.29 (0.03) 55.77 (0.19)Eparl+NC+1092+news 299 27.34 29.56 (0.14) 55.44 (0.18)Eparl+NC+1092+IR 311 27.14 29.43 (0.12) 55.48 (0.06)Eparl+NC+1092+news+IR 371 27.32 29.73 (0.21) 55.16 (0.20)+rescoring with CSLM 371 27.46 30.04 54.79Table 5: English?French results: number of English words (in million) and BLEU scores in the development (new-stest2009) and internal test (newstest2010) sets for the different systems developed.
The BLEU scores and the numberin parentheses are the average and standard deviation over 3 values (see Section 3.
)In both cases the best system is the one trainedon the Europarl, News-commentary and 1092 cor-pora.
This system was used to generate the auto-matic translations.
We did not observe any gainwhen adding the United Nations data, so we dis-carded this data.Impact of the Additional BitextsWith the baseline French?English SMT system (seeabove), we translated the French News corpus togenerate an additional bitext (News).
We also trans-lated some parts of the French LDC Gigaword cor-pus, to serve as queries to our IR system (see section2.2).
The resulting additional bitext is referred to asIR.
The second section of Tables 4 and 5 summarizethe system development including the additional bi-texts.With the News additional bitext added toEparl+NC, we obtain a system of similar perfor-mance as the baseline system used to generate theautomatic translations, but with less than half ofthe data.
Adding the News corpus to a larger cor-pus, such as Eparl+NC+1092, has less impact butstill yields some improvement: 0.1 BLEU point inFrench?English and 0.3 in English?French.
Thus,the News bitext translated from French to Englishmay have more impact when translating from En-glish to French than in the opposite direction.
Thiseffect is studied in detail in a separate paper (Lam-bert et al, 2011).
With the IR additional bitext addedto Eparl+NC+1092, we observe no improvement inFrench to English, and a very small improvementin English to French.
However, added to the base-line system (Eparl+NC+1092) adapted with the Newsdata, the IR additional bitexts yield a small (0.2BLEU) improvement in both translation directions.Final SystemIn both translation directions our best system was theone trained on Eparl+NC+1092+News+IR.
We fur-ther achieved small improvements by pruning thephrase-table and by increasing the beam size.
Toprune the phrase-table, we used the ?sigtest-filter?available in Moses (Johnson et al, 2007), more pre-cisely the ??
 filter3.We also build hierarchical systems on the varioushuman translated corpora, using up to 323M words(corpora Eparl+NC+1092).
The systems yielded sim-ilar results than the phrase-based approach, but re-quired much more computational resources, in par-ticular large amounts of main memory to performthe translations.
Running the decoder was actuallyonly possible with binarized rule-tables.
Therefore,the hierarchical system was not used in the evalua-tion system.3The p-value of two-by-two contingency tables (describingthe degree of association between a source and a target phrase)is calculated with Fisher exact test.
This probability is inter-preted as the probability of observing by chance an associationthat is at least as strong as the given one, and hence as its sig-nificance.
An important special case of a table occurs when aphrase pair occurs exactly once in the corpus, and each of thecomponent phrases occurs exactly once in its side of the paral-lel corpus (1-1-1 phrase pairs).
In this case the negative log ofthe p-value is ?
= logN (N is number of sentence pairs in thecorpus).
?
?
 is the largest threshold that results in all of the1-1-1 phrase pairs being included.4686 Conclusions and Further WorkWe presented the development of our statistical ma-chine translation systems for the French?Englishand English?French 2011 WMT shared task.
In theofficial evaluation the English?French system wasranked first according to the BLEU score and theFrench?English system second.AcknowledgmentsThis work has been partially funded by the Euro-pean Union under the EuroMatrixPlus project ICT-2007.2.2-FP7-231720 and the French governmentunder the ANR project COSMAT ANR-09-CORD-004.ReferencesSadaf Abdul-Rauf and Holger Schwenk.
2009.
On theuse of comparable corpora to improve SMT perfor-mance.
In Proceedings of the 12th Conference of theEuropean Chapter of the ACL (EACL 2009), pages 16?23, Athens, Greece.Ondr?ej Bojar and Ales?
Tamchyna.
2011.
Forms Wanted:Training SMT on Monolingual Data.
Abstract atMachine Translation and Morphologically-Rich Lan-guages.
Research Workshop of the Israel ScienceFoundation University of Haifa, Israel, January.Peter F. Brown, Stephen A. Della Pietra, Vincent J.Della Pietra, and Robert L. Mercer.
1993.
The mathe-matics of statistical machine translation: Parameter es-timation.
Computational Linguistics, 19(2):263?311.David Chiang.
2007.
Hierarchical phrase-based transla-tion.
Computational Linguistics, 33(2):201?228.Qin Gao and Stephan Vogel.
2008.
Parallel implemen-tations of word alignment tool.
In Software Engi-neering, Testing, and Quality Assurance for NaturalLanguage Processing, pages 49?57, Columbus, Ohio,June.
Association for Computational Linguistics.Nizar Habash.
2008.
Four techniques for online handlingof out-of-vocabulary words in arabic-english statisticalmachine translation.
In ACL 08.Howard Johnson, Joel Martin, George Foster, and RolandKuhn.
2007.
Improving translation quality by dis-carding most of the phrasetable.
In Proceedings of the2007 Joint Conference on Empirical Methods in Nat-ural Language Processing and Computational Natu-ral Language Learning (EMNLP-CoNLL), pages 967?975, Prague, Czech Republic.Philipp Koehn, Franz Josef Och, and Daniel Marcu.2003.
Statistical phrased-based machine translation.In HLT/NACL, pages 127?133.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran, RichardZens, Chris Dyer, Ondrej Bojar, Alexandra Con-stantin, and Evan Herbst.
2007.
Moses: Open sourcetoolkit for statistical machine translation.
In ACL,demonstration session.Patrik Lambert, Sadaf Abdul-Rauf, and Holger Schwenk.2010.
LIUM SMT machine translation system forWMT 2010.
In Proceedings of the Joint Fifth Work-shop on Statistical Machine Translation and Metrics-MATR, pages 121?126, Uppsala, Sweden, July.Patrik Lambert, Holger Schwenk, Christophe Servan, andSadaf Abdul-Rauf.
2011.
Investigations on translationmodel adaptation using monolingual data.
In SixthWorkshop on SMT, page this volume.Franz Josef Och and Hermann Ney.
2002.
Discrimina-tive training and maximum entropy models for statisti-cal machine translation.
In Proc.
of the Annual Meet-ing of the Association for Computational Linguistics,pages 295?302.Franz Josef Och and Hermann Ney.
2003.
A systematiccomparison of various statistical alignement models.Computational Linguistics, 29(1):19?51.Paul Ogilvie and Jamie Callan.
2001.
Experiments usingthe Lemur toolkit.
In In Proceedings of the Tenth TextRetrieval Conference (TREC-10), pages 103?108.Holger Schwenk.
2007.
Continuous space languagemodels.
Computer Speech and Language, 21:492?518.Holger Schwenk.
2008.
Investigations on large-scale lightly-supervised training for statistical machinetranslation.
In IWSLT, pages 182?189.A.
Stolcke.
2002.
SRILM: an extensible language mod-eling toolkit.
In Proc.
of the Int.
Conf.
on Spoken Lan-guage Processing, pages 901?904, Denver, CO.469
