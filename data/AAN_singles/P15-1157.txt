Proceedings of the 53rd Annual Meeting of the Association for Computational Linguisticsand the 7th International Joint Conference on Natural Language Processing, pages 1629?1638,Beijing, China, July 26-31, 2015.c?2015 Association for Computational LinguisticsA Frame of Mind: Using Statistical Models for Detection of Framing andAgenda Setting CampaignsOren TsurHarvard University& Northeastern Universityorentsur@seas.harvard.eduDan CalacciNortheastern Universitydcalacci@ccs.neu.eduDavid LazerNortheastern University& Harvard Universityd.lazer@neu.eduAbstractFraming is a sophisticated form of dis-course in which the speaker tries to in-duce a cognitive bias through consis-tent linkage between a topic and a spe-cific context (frame).
We build on po-litical science and communication theoryand use probabilistic topic models com-bined with time series regression analy-sis (autoregressive distributed-lag models)to gain insights about the language dy-namics in the political processes.
Pro-cessing four years of public statements is-sued by members of the U.S. Congress,our results provide a glimpse into the com-plex dynamic processes of framing, atten-tion shifts and agenda setting, commonlyknown as ?spin?.
We further provide newevidence for the divergence in party disci-pline in U.S. politics.1 IntroductionLanguage is one of the main tools used by politi-cians to promote their agenda, gain popularity, winelections and drive societal change (Luntz, 2007).The growing availability of online archives of po-litical data such as public statements, bill pro-posals, floor speeches, interviews or social me-dia streams allows computational analysis of manyaspects of the political process.
The analysisperformed can increase transparency, facilitate abetter educated constituency and improve under-standing of the political process.In this paper we propose a framework for au-tomatic analysis of a large collection of politicaltexts.
Specifically, we demonstrate how the useof Bayesian methods and time series analysis cap-tures the different ways in which political partiescontrol the political discourse.
We show that topicownership and framing strategies can be inferredusing topic models.
Moreover, we demonstratehow the models learned are used to construct timeseries of expressed agendas.
These time series arefitted using autoregressive distributive-lag modelsin order to learn the partisan temporal relations be-tween topics and expressed agendas.This framework could also be applied in otherdomains such as ideology divergence in onlineforums of radical groups or for measuring thechanges in public sentiment toward commercialbrands.Contribution (i) To the best of our knowledgethis is the first work to analyze framing strategieson large scale in an unsupervised manner1.
(ii)we combine topic models with regression analy-sis in recovering longitudinal trends.
(iii) We fur-ther provide evidence for the dynamics of framingcampaigns, commonly known as ?political spin2?.Finally, (iv) we show how this framework can shednew light on the broad scholarship on the diver-gence of party discipline.2 Related Work2.1 Political Communication TheorySome of the theoretical constructs employed byPolitical Science scholars to describe features ofthe political communication mechanism include:topic ownership, framing, and agenda setting.
Un-derstanding these theoretical concepts is necessaryin laying the ground for our computational ap-proach.
This subsection provides the key defini-tions and a brief survey of the relevant literature.Topic/Issue Ownership We say that a candi-date, a representative or a party owns a topic if thistopic, set of ideas or the competence in handlingspecific issues are strongly associated with her/the1We do use some meta data such as the speaker?s partyand its timestamp for the time series analysis.2?Political spin?
may also refer to fact twisting and factualdistractions promoted using various media outlets.
We do notrefer to these types of spin in this work.1629party (Petrocik, 1991; Petrocik, 1996; Damore,2004).
For example, environmental issues are tra-ditionally associated with specific parties and notothers (e.g.
in U.S. politics, environmental issuesare mostly associated with the Democratic party(Dunlap et al, 2001)).Framing Framing is the psychological schemawe use in order to organize and process our ex-periences.
Politicians can use different contextualframes when referring to a specific topic, givingthe public very different views on the topic at hand(Goffman, 1974; Gamson, 1989; Entman, 1993;Chong and Druckman, 2007).
A notable exampleis the divisive partisan rhetoric used by U.S. politi-cians when referring to the legality of abortion.Democratic and Republican positions, framed as?pro choice?
and ?pro life?, respectively, spin theabortion discourse as an issue of values of individ-ual freedom (pro-choice) or validating the sanctityof life (pro-life).
Similarly, Republicans refer tothe inheritance tax by the overwhelmingly nega-tive coinage ?death tax?, while Democrats use ?es-tate tax?.Framing strategies, however, go beyond the useof fixed phrases such as ?death tax?
and ?pro-choice?.
The Affordable Care Act (ACA) andthe debate over raising the minimum wage can beframed as an issue of social justice or in the con-text of the economic burden it incurs on tax payersand by potential job loss.Agenda Setting and shifting Agenda setting isachieved by framing and by increased or decreasedattention (attention shifts) in order to set or changethe political, media or public agenda (McCombsand Shaw, 1972; Scheufele and Tewksbury, 2007).Some examples of agenda setting campaigns arethe repeated comments about the importance ofchild vaccination, highlighting the need for equalpay in the 2015 State of the Union Presidential Ad-dress, or, more broadly, repeatedly addressing theneed for affordable healthcare.2.2 Computational Analysis of Political DataThe availability of archives and streams of polit-ical data is driving a growing number of compu-tational works that address a wide array of Polit-ical Science questions.
Methods vary from sim-ple word matching to more sophisticated Bayesianmodels and deep learning techniques.Slant in news articles has been modeled by(Gentzkow and Shapiro, 2010) and (Lee, 2013),comparing word tokens and n-grams to prede-fined lists extracted from labeled data.
HiddenMarkov Models are used by (Sim et al, 2013) inorder to measure ideological proportions in polit-ical speech, and (Iyyer et al, 2014) use recursiveneural networks for a similar task.Topic models have been used to detect connec-tions between contributions and political agendasas expressed in microblogging platforms (Yano etal., 2013) and for reconstructing voting patternsbased on the language in congressional bills (Ger-rish and Blei, 2012).
The flow of policy ideas hasbeen modeled via measuring text reuse in differentversions of bill proposals (Wilkerson et al, 2013).Nguyen et al (2013) use supervised hierarchi-cal topic regression to improve prediction of polit-ical affiliation and sentiment.Expressed agendas in press releases issued byU.S.
Senators have been modeled by Grimmer us-ing author topic models (Grimmer, 2010).
It isimportant to point to some key differences be-tween our work and Grimmer?s work.
While themodel used by Grimmer allows attribution of asingle topic per document, we are interested in amixed membership model as we hypothesize pos-sible correspondence between topics and frames.Moreover, while we are interested in partisan dy-namics, Grimmer is interested in the expressedagendas of individuals thus focusing on an au-thorship model.
Finally, unlike Grimmer, we alsointroduce autoregressive distributed-lag models inorder to capture temporal dynamics between top-ics and parties as reflected in the data.Another line of work can be found in the moretraditional Political Science scholarship.
The suc-cess of framing strategies is studied by the analysisof real time reactions to political debates (Boyd-stun et al, 2014).
Autoregressive models are usedfor analyzing adjustment of issue positions withrespect to news items during the Dutch nationalelection campaign of 2006 (Kleinnijenhuis and deNooy, 2013).
This approach is based on manualannotation of data.Logistic regression on manually coded cam-paign advertisements is used in order to learn thedynamics of issue ownership by individual candi-dates (Damore, 2004).While some of the works above address relatedresearch questions (agenda setting, topic own-ership) or use similar computational approaches(topic models, regression models), our work is the1630Figure 1: Examples of a public statement released on March 10, 2010 by Republican minority leader ?
Congressman JohnBoehner (now speaker of the U.S. House of Representatives).
The highlighted sequences illustrate the different topics/framesused - health care (green), economy/budget (yellow) and corruption (orange).first to offer a complete framework for automaticdetection of topic ownership and attention shiftingon a large scale.
Additionally, our partisan analy-sis provides a model for longitudinal partisan com-munication strategies without the need for encod-ing of external events and specific campaigns.3 DataA brief overview of the U.S. Congress TheAmerican political system is a bicameral legisla-ture composed of the Senate (100 senators, twofrom each state) and the House of Representatives(435 voting members plus 6 non-voting represen-tatives, number depends on the population of eachstate).
Election is held every two years, in whichone third of the Senators and all members of theHouse face reelection.
Members are typically af-filiated with either the Democratic Party or the Re-publican Party.
Congressional election and Presi-dential election coincide every four years.The Corpus We use a corpus of public state-ments released by members of Congress in boththe Senate and The House of Representatives, col-lected by Project Vote Smart3.
An example of apublic statement is presented in Figure 1.In this work we use all individual statementsand press releases in a span of four years (2010-2013), a total of 134000 statements made by641 representatives.
This time span encompassestwo Congressional elections (November 2010 and2012).
Table 1 gives the number of Demo-cratic and Republican representatives in the threeCongress terms (111-113) covered in our data.3http://votesmart.org/Chamber PartyCongress Term111th 112th 113thSenateDEM 57 51 53REP 41 47 45HouseDEM 257 193 199REP 178 242 234Table 1: Majority shifts in the House in the 111-113 Congressterms.
Independent representatives are omitted.Figure 2: Monthly average number of statements by party.While the administration was Democratic duringall four years of our data, notice the Democraticloss of majority in the 112th Congress.
We focuson the years 2010-2013 since Project Vote Smarthas better coverage of the political discourse after2009.It is interesting to note that while the total num-ber of statements per month reflects the changeof majority in the November 2010 and 2012 elec-tions (Table 1 and Figure 2), accounting for thenumber of seats per party it appears that the av-erage Democrat is consistently more ?productive?with ?
= 6.24 , ?2= 2.1 (Dem) and ?
= 5.5 ,1631?2= 1.5 (Rep) statements per month.
We hencereport all results after normalization by the num-ber of seats each party posses at each timestamp.4 Computational FrameworkIn order to automatically discover the correlateddynamics of attention shifts, we take a layered ap-proach, consisting of the stages described below.4.1 Topic InferenceIn the first stage, we use topic models in orderto learn topic distribution over words and identifythe set of topics addressed in the corpus.
TopicModeling describes a general algorithmic frame-work for unsupervised discovery of a set of top-ics expressed in a collection of documents.
Theframework is based on the assumption that doc-uments are generated by mixtures of k topics.
Itis therefore assumed that documents are gener-ated by the following process: for each word ina document, we choose a topic from a given topicdistribution, then choose a word from the distri-bution over words that the chosen topic specifies.Latent Dirichlet Allocation (LDA), the frameworkemployed here, assumes that the distribution overtopics has a Dirichlet prior.
In practice, we as-sume a Dirichlet prior on topics and use varia-tional Bayes (VB) optimization to infer topic dis-tributions over words (Blei et al, 2003).
In orderto considerably improve efficiency, we use an on-line variational Bayes inference algorithm, shownto perform similarly to batch LDA (Hoffman etal., 2010).
It is important to note that our goalsand assumptions about the data do not lend them-selvse to the use of dynamic or correlated topicmodels (Blei and Lafferty, 2006a; Blei and Laf-ferty, 2006b)4.4.2 Topic Assignment and UnificationThe distribution of ranked topics over documentspresents a ?long tailed?
distribution in which a fewtopics achieve a significant coverage of a docu-ment.
This is a result of the mixed membership?generative?
approach and the bag-of-words as-sumption.
In a more realistic setting the number oftopics per document is restricted.
We wish to re-strict the number of topics per document while stillconforming to the mixture model assumption.
We4We are interested in the change of the proportions of top-ics over time and not in the change of the word distributionwithin topics and we don?t assume inherent correlation oftopics.therefore reassign topics to each document (state-ment) d in the following manner:1.
Assign a topic to each word based on distri-bution of topics over words infferred in theprevious stage.2.
Find a set T?of k?topics (k?< k) that coverq% of the document in a greedy way.
Thetopic assingment for document d will then bed?
T?.4.3 Data SlicingWe slice the data according to four parameters:topic (or topical cluster), time, party and document(statement).
These slicing parameters allow us theflexibility required to thoroughly analyze the data.In the time parameter, we have four settings: noslicing (all data is treated as if it were producedsimultaneously), monthly slicing, weekly slicingand daily slicing, each gives different granularityof ownership patterns.4.4 Autoregressive-Distributed-Lag ModelsA linear function b + wTX = b +?jwTjXjisa simple yet robust method for testing dependencybetween X and Y .
Ordinary least square regres-sion finds the coefficients that minimize the meansquare error of Y = b+?jwTjXjgiven (X,Y ).In our case (X,Y ) are time series.
We argue thata lagged dependency between two time series sug-gests a framing or attention shifting campaign.Regression analysis of time series assumes in-dependence between error terms.
This key statis-tical property is often violated in real world dataas ytoften depends on yt?1thus the time seriesresiduals tend to correlate.
The consequences ofviolating the independence of errors are threefold:i) Statistical tests of significance are uninforma-tive and cannot be used to prove dependency be-tween the model parameters, ii) The coefficientslearned lose accuracy, and iii) error terms are cor-related, and hence contain information that is lostin analysis instead of used to leverage the predic-tion power of the model.
The importance of con-trolling for autoregressive properties and for sea-sonality effects was recently demonstrated in theerror analysis of the Google Flu Trends algorithm(Lazer et al, 2014).In order to control for error dependency we addthe auto regressing component ?TYnto the ordi-nary regression, as shown in Equation 1:yt= ?+ ?TXm+ ?TYn+ t(1)1632Cluster Topic ID Top WordsHealth30health care law will obamacare insurance repeal affordable americans costs new re-form people president healthcare act coverage mandate american obama51medicare seniors program social medicaid benefits fraud payments security programscost services costs billion payment beneficiaries waste year savings millionEnergy38project pipeline president obama keystone jobs climate energy xl construction statechange permit administration approval oil will canada environmental create69oil alaska gulf coast spill drilling offshore bp murkowski begich markey resourcesnoaa said industry moratorium mexico gas administration senSecurity34day nation country today americans us american war world people america lives willhonor families years men many th attacks89nuclear united iran international israel foreign president states security weapons peo-ple world syria nations sanctions regime must government peaceEconomy68budget spending debt president cuts fiscal government deficit will plan trillion obamahouse congress year federal cut economy washington billion88jobs small businesses business job economy economic create will new growth workamerican america help creation act manufacturing can sectorTable 2: Top twenty words in selected topics in four topical clusters.where, ?TXmindicates the distributed-lag terms:?TXm=m?i=0?ixt?i(2)and ?TYnindicates the autoregressive componentdescribed by:?TYn=n?j=1?jyt?j(3)for some n 6 t (notice that i ranges from 0 whilej ranges from 1).In order to control for seasonality (such as holi-days and recess?)
we add a set of categorical vari-ables indicating the weekday and the week-in-yearof a statement, so the autoregressive model is:yt= ?+ ?TXm+ ?TYn+?lWTlIl(t) + t(4)Where l ?
{day, week} thus Il(t) is the identitymatrix with the dimension of the seasonal granu-larity, in our case Iday= I7?7for each day ofthe week and Iweek= I52?52for the week of theyear.
Ili,i= 1 iff t timestamp falls in the i-th day-of-week/week-in-year.Finally, in practice it is usually sufficient re-strict the autoregressive term to one parameterwith j = 1 (accounting to the y value at the pre-vious time stamp), this is consistent with the 24hours news cycle reported by (Leskovec et al,2009) among others.
Since our goal is to findcorrelated attention shifts we can substitute thesummation distributed-lag term by a single laggedterm.
Thus, we aim to minimize the MSE in thefollowing model:yt= ?+ ?xt?+ ?ynt?1+?lWTlIl(t) + t(5)Where t?= t?i and i ?
{0, 1, 2, ..., 28} indicatingno lag, one day lag, 2 days lag, a week?s lag, etc.5 Results5.1 Topical Ownership and Framing5.1.1 Inferred TopicsAs an input for the topic modeling module (stage 1of the system) we use a lexicon of the 10000 mostfrequent words in the corpus.
We use k = 100as the number of topics.
Experiments with k ?
{30, 50, 500, 1000} produced topics that were ei-ther too general or too incoherent.
Once the topic-word distributions were inferred, topics were val-idated by two annotators examining the top 50words for each topic.
Annotators used hierarchi-cal labels ?
an energy related topic ticould be an-notated energy / clean-tech, while another topic tjcould be annotated energy / economy / keystone-xl.
Annotations were consolidated to unify thecoding5.
After consolidation annotators agreed onall topic annotations.
Some examples of topicslabels are ?health?, ?energy?, ?economy?, ?boiler-plate?, ?political process?, ?local?
and a few ?ran-dom?
topics.After topic assignment as described in Section4.2 each document is associated with only 2?6 top-ics.
In this work we focus on the 14 most salient(concise, general and frequent) topics in the cor-pus.
These 14 topics fall under four topical clus-ters - Health, Energy, Army/Security and Econ-omy/Budget.
Table 2 contains examples of topwords and labels for some of the topics from fourtopical clusters.5For example, if topic tiwas labeled energy, cleantech byone annotator and energy, green by the other, the annotatorswould agree to use either cleantech or green consistently.1633(a) (b)Figure 3: Seasonality effect: average number of statements issued per day of week (a) and per week in year (b).
(a) All statements (b) Republican statements (c) Democrat statementsFigure 4: Normalized Pointwise Mutual Information (PMI) of topic cooccurrence of 14 topics of four topical clusters Health(30, 51, 80), Energy (38, 69,71), securtity (34, 74, 89) and Budget & Economy (68, 23, 8, 88, 52)Cluster Topic DEM REP DEM REP30 1679 4622Health 51 746 233 3169 538680 898 43738 128 255Energy 69 1102 948 4042 341571 2859 211934 6239 5121Security 74 3875 3071 12393 1114089 3807 413868 12260 1991623 5221 3742Economy 8 6981 2456 31604 3170688 12845 1113952 3479 1154Table 3: Total number of statements by party in four topicalclusters.
DEM indicates the Democrat party, REP indicatesthe Republican party.5.1.2 Partisan Topic OwnershipTable 3 shows the partisan ownership by provid-ing the number of statements issued by each partyon each topic and for topical clusters.
It also il-lustrates that different topical granularities portraydifferent ownership patterns.
For example, whileit seems like the health cluster is owned by theRepublican party (Table 3, cluster level), a closerlook at specific topics in the cluster reveals a morecomplex picture ?
the Republicans actually ownonly topic 30, which turns to be the most dominanttopic in the cluster.
Similarly, while the statementCluster Topic DEM REP DEM* REP*30 46 154 2 79Health 51 151 22 34 180 157 27 37 238 47 43 2 6Energy 69 114 56 18 571 144 52 43 534 141 63 52 9Security 74 144 46 34 889 80 113 10 2268 32 174 7 12723 151 49 60 9Economy 8 205 2 165 088 137 68 63 1752 190 12 123 0Table 4: Number of weeks each party ?owned?
a topic byissuing more statements (DEM, REP) and number of weeksthe party owned the topic with statistical significance p <0.05 (DEM*, REP*).counts in the Economy cluster are quite balanced(31604 vs. 31706), the counts of the individualtopics in the cluster are polarized.
Remember thatthese topical classes were all inferred by the LDAin an unsupervised way.
These partisan ownershippatterns were also confirmed by domain experts.Longevity is a crucial factor in topic ownership.A weekly ownership of a topic is achieved by aparty Q if it issued more statements on the topicthan party R in that particular week.
We computethe significance of the ownership assuming a nullhypothesis that statements are issued by the parties1634by two Bernoulli processes with the same param-eters.
Table 4 provides the number of weeks eachparty owned each topic and the number of weeksit had a significant ownership (p < 0.05)6.Topic 30 illustrates the different perspectives.The total statement count (see Table 3) revealsa clear ownership by the Republican party, is-suing 73% of the statements.
While turning toweekly ownership (Table 4) we get similar num-ber (Republicans control 77% of the weeks); as-suming only significance ownership, Republicanssignificantly own the discourse for 79 weeks whileDemocrats have significant ownership in only 2weeks which means the Republicans own 97% ofthe significantly owned weeks.5.1.3 Topic CooccurrenceTopic cooccurrence could approximate the waytopics are framed.
A heatmap of within state-ment topic cooccurrence based on Pointwise Mu-tual Information (PMI) (Church and Hanks, 1990)is presented in Figure 4.
The topical clusters arecharacterized by blocks along the diagonal.
Theblocks structure is to be expected due to the inher-ent topical similarity within clusters.
It is inter-esting to see the inter-cluster differences in PMIbetween the two parties.
At the cluster level, Re-publicans tend to use the Budget & Economy top-ics with topics in all other topical clusters, evidentby the stronger colors in the five bottom (left) rows(columns) in 4b comparing to 4c.A notable example is the way Republicansframe the controversial Keystone XL project (En-ergy, topic 38) with the impact on the job marketand small businesses (Budget & Economy, topic88), a topic traditionally owned by Democrats (seetop topical words in Table 2 and topic ownershipat Table 4).5.2 Partisan DisciplineParty discipline is of great interest for political sci-entists (Crook and Hibbing, 1985; Bowler et al,1999; Krehbiel, 2000; McCarty, 2001) .
Typically,party discipline is examined by analysis of roll callvotes on bills.
Discipline, however can be alsomeasured by adherence to party lines in talkingpoints and agenda setting campaigns.
Discipline,therefore, can be captured by conformity of lan-6The numbers do not necessarily add up to 208 (the num-ber of weeks in four years) due to weeks with no significantownership , e.g.
the parties issued a similar number of state-ments (usually zero) on that topic.Figure 5: Average number of n-grams owned by each partyon all topics (top), in Republican owned topics (middle) andin Democrat owned topics (bottom).guage in public statements.
While it is ?commonknowledge?
among political scientists that Repub-licans are more adherent to ?talking points?
?
tothe best of our knowledge there are no large scalestudies that support (or refute) that.In the absence of official lists of ?talkingpoints?, repeated use of similar phrases (n-grams)can provide an indication for the level of party dis-cipline.
In each topic, we looked at all n-grams(n ?
{2, ..., 14}) that were used by more than fivemembers of the Congress.
For example, the tri-gram ?the American people?
(topic 38) appears in81 statements made by 54 members of congress,only two of them were Democrats.
Similarly, thetri-gram ?social security benefits?
(topic 51) ap-pears in 123 statements, issued by 89 members,71 of which were Democrats.
Examining ?own-ership?
of n-grams (per n-gram, per topic) revealsthat that Republicans do tend to stick to talkingpoints more than Democrats do.Figure 5 provides the average number of n-grams owned by each party over all topics (top),over Republican owned topics (middle) and overDemocratic owned topics (bottom).
While on av-erage Democrats own more n-grams than Repub-licans (Figure 5, top), the difference is marginaland is attributed to the fact that Democrats ownmore topics than the Republicans (10 vs. 4, see Ta-ble 3).
Comparison between n-gram ownership inDemocratic owned topics and Republican ownedtopics (Figure 5, middle and bottom) shows thatwhile each party owns more n-grams in the top-ics it owns, Republicans present stronger owner-ship over the n-grams in their owned topics thanDemocrats in their respective owned topics.
More-over, Republicans present relative discipline even1635in Democratic owned topics.Manually looking at some sampled n-grams itappears that mid-length n-grams are shared ?talk-ing points?
and longer n-grams are full citationsfrom bill proposals and committee reports.
Thesefindings are in line with textual sharing semantics(Lin et al, 2015).5.3 Time Series AnalysisTo this end we create two time series for eachtopic c ?
T : SCDc?
daily normalized counts forDemocrats and SCRc?
daily normalized counts forRepublicans.
Normalization of counts is needed inorder to account for the bias introduced by the dif-ference in the number of seats each party holds andthe changes in that number in the different termsas apparent from Table 1.Our data exhibit two strong seasonality effects:a weekly cycle with the lowest point on the week-end and peaking on Thursday (Figure 3a), and ayearly cycle with low points at the weeks of 4th ofJuly, Thanksgiving, August recess and Christmas(Figure 3b).
These seasonality effects are capturedby the added terms in Equation 4.After time series are constructed we apply first-difference detrending (Enders, 2008) in order totransform the time series to stationary series andavoid trend-incurred correlations.We fit autoregressive-distributed-lag models forall pairs in {X = Sc,l, Y = Sc?
}, where c, c??
T(topics), l ?
{0, 1, 2, 3, ..., 7, 14, ..., 28}.In this setting we fit 5153 pairs of time seriesof which 718 pairs had a significant coefficient forX (p < 0.05).
Artificial significance due to abun-dance of fitted models was accounted to by apply-ing the strict Bonferroni correction (Dunn, 1961)on the significance level.
The correction resultedin 103 significant correlations, most of them withlag of up to 3 days.
Table 5 gives the number of in-tra/inter significant correlation for lags l ?
0, 1, 2.One example for such correlation is the Repub-licans ?responding?
to Democratic topic 88 withwith topic 8 (intra-cluster) in one and two days lag.We interpret this as a different spin on the budgetissue.
Another example is the Democratic partycorresponds to Republican topic 30 with topic 88(inter-cluster) on the same day (no lag).
We in-terpret this as a way to place the Acordable CareAct in a specific economic frame.
We note thatwhile the lagged correlated time series do not im-ply a responsive pattern, a significance of laggedCluster DependentSignificantCorrelationsl = 0 l = 1 l = 2Intra-clusterDEM 28 1 1REP 26 4 5Inter-clusterDEM 15 2 0REP 17 0 0Table 5: Number of statistically significant (p < .05, Bonfer-roni corrected) daily lagged correlations between cross-partytime series.correlation may suggest such a pattern.
We pro-vide some evidence in the qualitative analysis inthe next section.5.4 Discussion and Qualitative AnalysisInter and intra-cluster correlations can be inter-preted as manifestations of different types of fram-ing strategies and campaigns for attention shifts.
Adetailed analysis of the interplay between the dif-ferent frames is beyond the scope of this paper andis left for political scientists.The majority of the significant correlations werefound with no lag.
It is important to note that thesecorrelations are found significant even after ac-counting to autoregressive patterns.
Zero-lag cor-relations could be interpreted in a number of ways.Two probable interpretations are (i) daily time se-ries are too crude to model lag patterns, and (ii)the parties respond to some external event at thesame time.
While we cannot address (i) due tosparseness and noise7, we can sample statementsand examine them manually.
Manual examina-tion reveals a strong responsive pattern in peak-ing trends.
One typical example is the Republicanspike in topic 30 on March 10.
The statement atFigure 1 is very illustrative as it explicitly refersto a statement by President Obama.
Explicit ref-erences to statements made by the other side arefound more frequently in Republican statementsand reveal a clear responsive pattern that also sug-gest a strong party discipline, in line with the re-sults in Section 5.2.
This small scale qualitativeanalysis complements the quantitative results re-ported in Section 5.3 and provide evidence for aresponsive pattern even in zero lag series.6 ConclusionWe presented a statistical framework for the anal-ysis of framing strategies and agenda setting cam-paigns in the political sphere.
Combining topicmodels and time series analysis, we modeled topic7The exact timestamp is sometimes missing, set to mid-night or affected by external factors.1636ownership and party discipline and analyzed re-sponsive patterns in an unsupervised way and withno prior knowledge of the political system.
Ourwork draws from political science theory, validat-ing some theoretical constructs and shedding newlight on others.
The proposed framework and theresults could be further used and interpreted by po-litical scientists and communication scholars.7 AcknowledgmentsWe thank Ryan Kennedy, Navid Dianati, Kather-ine Ognyanova, Stefan Vojcik and Shahar Even-Dar Mandel for fruitful discussions.
We thank theanonymous reviewers for their helpful comments.This work was supported by the following grants:MURI #504026 and ARO #50433.ReferencesDavid Blei and John Lafferty.
2006a.
Correlated topicmodels.
Advances in neural information processingsystems, 18:147.David M Blei and John D Lafferty.
2006b.
Dynamictopic models.
In Proceedings of the 23rd interna-tional conference on Machine learning, pages 113?120.
ACM.David M Blei, Andrew Y Ng, and Michael I Jordan.2003.
Latent dirichlet alocation.
the Journal of ma-chine Learning research, 3:993?1022.Shaun Bowler, David M Farrell, and Richard S Katz.1999.
Party cohesion, party discipline, and parlia-ments.
Party discipline and parliamentary govern-ment, pages 3?22.Amber E Boydstun, Rebecca A Glazier, Matthew TPietryka, and Philip Resnik.
2014.
Real-time reac-tions to a 2012 presidential debate a method for un-derstanding which messages matter.
Public OpinionQuarterly, 78(S1):330?343.Dennis Chong and James N Druckman.
2007.
Fram-ing theory.
Annu.
Rev.
Polit.
Sci., 10:103?126.Kenneth Ward Church and Patrick Hanks.
1990.
Wordassociation norms, mutual information, and lexicog-raphy.
Computational linguistics, 16(1):22?29.Sara Brandes Crook and John R Hibbing.
1985.
Con-gressional reform and party discipline: The effectsof changes in the seniority system on party loyaltyin the us house of representatives.
British Journal ofPolitical Science, 15(02):207?226.David F Damore.
2004.
The dynamics of issue own-ership in presidential campaigns.
Political ResearchQuarterly, 57(3):391?397.Riley E Dunlap, Chenyang Xiao, and Aaron M Mc-Cright.
2001.
Politics and environment in amer-ica: Partisan and ideological cleavages in public sup-port for environmentalism.
Environmental politics,10(4):23?48.Olive Jean Dunn.
1961.
Multiple comparisons amongmeans.
Journal of the American Statistical Associa-tion, 56(293):52?64.Walter Enders.
2008.
Applied econometric time series.John Wiley & Sons.Robert M Entman.
1993.
Framing: Toward clarifica-tion of a fractured paradigm.
Journal of communi-cation, 43(4):51?58.William A Gamson.
1989.
News as framing.
Ameri-can Behavioral Scientist, 33(2):157?161.Matthew Gentzkow and Jesse M. Shapiro.
2010.
Whatdrives media slant?
evidence from u.s. daily news-papers.
Econometrica, 78:35?71.Sean Gerrish and David M. Blei.
2012.
How theyvote: Issue-adjusted models of legislative behavior.In Neural Information Processing Systems (NIPS),pages 2762?2770.Erving Goffman.
1974.
Frame analysis: An essay onthe organization of experience.
Harvard UniversityPress.Justin Grimmer.
2010.
A bayesian hierarchical topicmodel for political texts: Measuring expressed agen-das in senate press releases.
Political Analysis,18(1):1?35.Matthew Hoffman, Francis R Bach, and David M Blei.2010.
Online learning for latent dirichlet alocation.In advances in neural information processing sys-tems, pages 856?864.Mohit Iyyer, Peter Enns, Jordan Boyd-Graber, andPhilip Resnik.
2014.
Political ideology detectionusing recursive neural networks.
In Proceedings ofthe 52nd meeting of the Association for Computa-tional Linguistics.Jan Kleinnijenhuis and Wouter de Nooy.
2013.
Ad-justment of issue positions based on network strate-gies in an election campaign: A two-mode networkautoregression model with cross-nested random ef-fects.
Social Networks, 35(2):168?177.Keith Krehbiel.
2000.
Party discipline and measures ofpartisanship.
American Journal of Political Science,pages 212?227.David M Lazer, Ryan Kennedy, Gary King, andAlessandro Vespignani.
2014.
The parable ofgoogle flu: Traps in big data analysis.
Science Mag-azine (AAAS).Han Soo Lee.
2013.
Do national economic and politi-cal conditions affect ideological media slant?
Polit-ical Communication, 30:395?418.1637Jure Leskovec, Lars Backstrom, and Jon Kleinberg.2009.
Meme-tracking and the dynamics of the newscycle.
In Proceedings of the 15th ACM SIGKDD in-ternational conference on Knowledge discovery anddata mining, pages 497?506.
ACM.Y.
Lin, D. Margolin, and D Lazer.
2015.
Uncover-ing social semantics from textual traces: A theory-driven approach and evidence from public state-ments of u.s. members of congress.
Journal of theAssociation for Information Science and Technol-ogy, page (forthcoming).Frank I. Luntz.
2007.
Words That Work: It?s Not WhatYou Say, It?s What People Hear.
Hyperion.Nolan McCarty.
2001.
The hunt for party disciplinein congress.
In American Political Science Associ-ation, volume 95, pages 673?687.
Cambridge UnivPress.Maxwell E McCombs and Donald L Shaw.
1972.
Theagenda-setting function of mass media.
Public opin-ion quarterly, 36(2):176?187.Viet-An Nguyen, Jordan Boyd-Graber, and PhilipResnik.
2013.
Lexical and hierarchical topic regres-sion.
In Neural Information Processing Systems.John R Petrocik.
1991.
Divided government: Is it all inthe campaigns?
The politics of divided government,pages 13?38.John R Petrocik.
1996.
Issue ownership in presidentialelections, with a 1980 case study.
American journalof political science, pages 825?850.Dietram A Scheufele and David Tewksbury.
2007.Framing, agenda setting, and priming: The evolu-tion of three media effects models.
Journal of com-munication, 57(1):9?20.Yanchuan Sim, Brice Acree, Justin H Gross, andNoah A Smith.
2013.
Measuring ideological pro-portions in political speeches.
In Proceedings ofEMNLP.John Wilkerson, David A. Smith, and Nick Stramp.2013.
Tracing the flow of policy ideas in legisla-tures: A text reuse approach.
In New Directions inAnalyzing Text as Data, September.Tae Yano, Dani Yogotama, and Noah A. Smith.
2013.A penny for your tweets: Campaign contributionsand capitol hill microblogs.
In International AAAIConference on Weblogs and Social Media (ICWSM),July.1638
