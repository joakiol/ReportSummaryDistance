Proceedings of the 2nd Workshop on Computational Approaches to Subjectivity and Sentiment Analysis, ACL-HLT 2011, pages 28?36,24 June, 2011, Portland, Oregon, USA c?2011 Association for Computational LinguisticsCreating Sentiment Dictionaries via TriangulationJosef Steinberger,Polina Lenkova, Mohamed Ebrahim,Maud Ehrmann, Ali Hurriyetoglu,Mijail Kabadjov, Ralf Steinberger,Hristo Tanev and Vanni ZavarellaEC Joint Research Centre21027, Ispra (VA), ItalyName.Surname@jrc.ec.europa.euSilvia Va?zquezUniversitat Pompeu FabraRoc Boronat, 13808018 Barcelonasilvia.vazquez@upf.eduAbstractThe paper presents a semi-automatic approachto creating sentiment dictionaries in many lan-guages.
We first produced high-level gold-standard sentiment dictionaries for two lan-guages and then translated them automaticallyinto third languages.
Those words that canbe found in both target language word listsare likely to be useful because their wordsenses are likely to be similar to that of thetwo source languages.
These dictionaries canbe further corrected, extended and improved.In this paper, we present results that verifyour triangulation hypothesis, by evaluating tri-angulated lists and comparing them to non-triangulated machine-translated word lists.1 IntroductionWhen developing software applications for senti-ment analysis or opinion mining, there are basi-cally two main options: (1) writing rules that assignsentiment values to text or text parts (e.g.
names,products, product features), typically making use ofdictionaries consisting of sentiment words and theirpositive or negative values, and (2) inferring rules(and sentiment dictionaries), e.g.
using machinelearning techniques, from previously annotated doc-uments such as product reviews annotated with anoverall judgment of the product.
While movie orproduct reviews for many languages can frequentlybe found online, sentiment-annotated data for otherfields are not usually available, or they are almostexclusively available for English.
Sentiment dictio-naries are also mostly available for English only or,if they exist for other languages, they are not com-parable, in the sense that they have been developedfor different purposes, have different sizes, are basedon different definitions of what sentiment or opinionmeans.In this paper, we are addressing the resource bot-tleneck for sentiment dictionaries, by developinghighly multilingual and comparable sentiment dic-tionaries having similar sizes and based on a com-mon specification.
The aim is to develop such dic-tionaries, consisting of typically one or two thou-sand words, for tens of languages, although in thispaper we only present results for eight languages(English, Spanish, Arabic, Czech, French, German,Italian and Russian).
The task raises the obviousquestion how the human effort of producing this re-source can be minimized.
Simple translation, be itusing standard dictionaries or using machine trans-lation, is not very efficient as most words have two,five or ten different possible translations, dependingon context, part-of-speech, etc.The approach we therefore chose is that of trian-gulation.
We first produced high-level gold-standardsentiment dictionaries for two languages (Englishand Spanish) and then translated them automaticallyinto third languages, e.g.
French.
Those words thatcan be found in both target language word lists (EnFr and Es Fr) are likely to be useful because theirword senses are likely to be similar to that of thetwo source languages.
These word lists can then beused as they are or better they can be corrected, ex-tended and improved.
In this paper, we present eval-uation results verifying our triangulation hypothesis,by evaluating triangulated lists and comparing them28to non-triangulated machine-translated word lists.Two further issues need to be addressed.
Thefirst one concerns morphological inflection.
Auto-matic translation will yield one word form (often,but not always the base form), which is not suffi-cient when working with highly inflected languages:A single English adjective typically has four Spanishor Italian word forms (two each for gender and fornumber) and many Russian word forms (due to gen-der, number and case distinctions).
The target lan-guage word lists thus need to be expanded to coverall these morphological variants with minimal effortand considering the number of different languagesinvolved without using software, such as morpho-logical analysers or generators.
The second issuehas to do with the subjectivity involved in the humanannotation and evaluation effort.
First of all, it is im-portant that the task is well-defined (this is a chal-lenge by itself) and, secondly, the inter-annotatoragreement for pairs of human evaluators working ondifferent languages has to be checked in order to getan idea of the natural variation involved in such ahighly subjective task.Our main field of interest is news opinion min-ing.
We would like to answer the question how cer-tain entities (persons, organisations, event names,programmes) are discussed in different media overtime, comparing different media sources, media indifferent countries, and media written in differentlanguages.
One possible end product would be agraph showing how the popularity of a certain en-tity has changed over time across different languagesand countries.
News differs significantly from thosetext types that are typically analysed in opinion min-ing work, i.e.
product or movie reviews: While aproduct review is about a product (e.g.
a printer)and its features (e.g.
speed, price or printing qual-ity), the news is about any possible subject (newscontent), which can by itself be perceived to be pos-itive or negative.
Entities mentioned in the news canhave many different roles in the events described.If the method does not specifically separate positiveor negative news content from positive or negativeopinion about that entity, the sentiment analysis re-sults will be strongly influenced by the news context.For instance, the automatically identified sentimenttowards a politician would most likely to be low ifthe politician is mentioned in the context of nega-tive news content such as bombings or disasters.
Inour approach, we therefore aim to distinguish newscontent from sentiment values, and this distinctionhas an impact on the sentiment dictionaries: unlikein other approaches, words like death, killing, awardor winner are purposefully not included in the sen-timent dictionaries as they typically represent newscontent.The rest of the paper is structured as follows: thenext section (2) describes related work, especiallyin the context of creating sentiment resources.
Sec-tion 3 gives an overview of our approach to dic-tionary creation, ranging from the automatic learn-ing of the sentiment vocabulary, the triangulationprocess, the expansion of the dictionaries in sizeand regarding morphological inflections.
Section 4presents a number of results regarding dictionarycreation using simple translation versus triangula-tion, morphological expansion and inter-annotatoragreement.
Section 5 summarises, concludes andpoints to future work.2 Related WorkMost of the work in obtaining subjectivity lexiconswas done for English.
However, there were someauthors who developed methods for the mapping ofsubjectivity lexicons to other languages.
Kim andHovy (2006) use a machine translation system andsubsequently use a subjectivity analysis system thatwas developed for English.
Mihalcea et al (2007)propose a method to learn multilingual subjectivelanguage via cross-language projections.
They usethe Opinion Finder lexicon (Wilson et al, 2005)and two bilingual English-Romanian dictionaries totranslate the words in the lexicon.
Since word am-biguity can appear (Opinion Finder does not markword senses), they filter as correct translations onlythe most frequent words.
The problem of translat-ing multi-word expressions is solved by translatingword-by-word and filtering those translations thatoccur at least three times on the Web.
Another ap-proach in obtaining subjectivity lexicons for otherlanguages than English was explored in Banea et al(2008b).
To this aim, the authors perform three dif-ferent experiments, with good results.
In the firstone, they automatically translate the annotations ofthe MPQA corpus and thus obtain subjectivity an-29notated sentences in Romanian.
In the second ap-proach, they use the automatically translated entriesin the Opinion Finder lexicon to annotate a set ofsentences in Romanian.
In the last experiment, theyreverse the direction of translation and verify the as-sumption that subjective language can be translatedand thus new subjectivity lexicons can be obtainedfor languages with no such resources.
Finally, an-other approach to building lexicons for languageswith scarce resources is presented in Banea et al(2008a).
In this research, the authors apply boot-strapping to build a subjectivity lexicon for Roma-nian, starting with a set of seed subjective entries,using electronic bilingual dictionaries and a trainingset of words.
They start with a set of 60 words per-taining to the categories of noun, verb, adjective andadverb obtained by translating words in the Opin-ion Finder lexicon.
Translations are filtered using ameasure of similarity to the original words, based onLatent Semantic Analysis (Landauer and Dumais,1997) scores.
Wan (2008) uses co-training to clas-sify un-annotated Chinese reviews using a corpusof annotated English reviews.
He first translatesthe English reviews into Chinese and subsequentlyback to English.
He then performs co-training usingall generated corpora.
Banea et al (2010) translatethe MPQA corpus into five other languages (somewith a similar ethimology, others with a very differ-ent structure).
Subsequently, they expand the fea-ture space used in a Naive Bayes classifier using thesame data translated to 2 or 3 other languages.
Theirconclusion is that expanding the feature space withdata from other languages performs almost as wellas training a classifier for just one language on alarge set of training data.3 Approach OverviewOur approach to dictionary creation starts with semi-automatic way of colleting subjective terms in En-glish and Spanish.
These pivot language dictionariesare then projected to other languages.
The 3rd lan-guage dictionaries are formed by the overlap of thetranslations (triangulation).
The lists are then man-ually filtered and expanded, either by other relevantterms or by their morphological variants, to gain awider coverage.3.1 Gathering Subjective TermsWe started with analysing the available Englishdictionaries of subjective terms: General Inquirer(Stone et al, 1966), WordNet Affect (Strapparavaand Valitutti, 2004), SentiWordNet (Esuli and Se-bastiani, 2006), MicroWNOp (Cerini et al, 2007).Additionally, we used the resource of opinion wordswith associated polarity from Balahur et al (2009),which we denote as JRC Tonality Dictionary.
Thepositive effect of distinguishing two levels of inten-sity was shown in (Balahur et al, 2010).
We fol-lowed the idea and each of the emloyed resourceswas mapped to four categories: positive, negative,highly positive and highly negative.
We also gotinspired by the results reported in that paper andwe selected as the base dictionaries the combinationof MicroWNOp and JRC Tonality Dictionary whichgave the best results.
Terms in those two dictionar-ies were manually filtered and the other dictionar-ies were used as lists of candidates (their highly fre-quent terms were judged and the relevant ones wereincluded in the final English dictionary).
Keeping inmind the application of the dictionaries we removedat this step terms that are more likely to describe bador good news content, rather than a sentiment to-wards an entity.
In addition, we manually collectedEnglish diminishers (e.g.
less or approximately), in-tensifiers (e.g.
very or indeed) and invertors (e.g.not or barely).
The English terms were translated toSpanish and the same filtering was performed.
Weextended all English and Spanish lists with the miss-ing morphological variants of the terms.3.2 Automatic Learning of Subjective TermsWe decided to expand our subjective term lists byusing automatic term extraction, inspired by (Riloffand Wiebe, 2003).
We look at the problem of ac-quisition of subjective terms as learning of seman-tic classes.
Since we wanted to do this for two dif-ferent languages, namely English and Spanish, themultilingual term extraction algorithm Ontopopulis(Tanev et al, 2010) was a natural choice.Ontopopulis performs weakly supervised learningof semantic dictionaries using distributional similar-ity.
The algorithm takes on its input a small set ofseed terms for each semantic class, which is to belearnt, and an unannotated text corpus.
For example,30if we want to learn the semantic class land vehicles,we can use the seed set - bus, truck, and car.
Thenit searches for the terms in the corpus and finds lin-ear context patterns, which tend to co-occur imme-diately before or after these terms.
Some of thehighest-scored patterns, which Ontopopulis learnedabout land vehicles were driver of the X, X wasparked, collided with another X, etc.
Finally, thealgorithm searches for these context patterns in thecorpus and finds other terms which tend to fill theslot of the patterns (designated by X).
Consideringthe land vehicles example, new terms which the sys-tem learned were van, lorry, taxi, etc.
Ontopop-ulis is similar to the NOMEN algorithm (Lin et al,2003).
However, Ontopopulis has the advantage tobe language-independent, since it does not use anyform of language-specific processing, nor does it useany language-specific resources, apart from a stopword list.In order to learn new subjective terms for eachof the languages, we passed the collected subjectiveterms as an input to Ontopopulis.
For English, wedivided the seed set in two classes: class A ?
verbsand class B ?
nouns and adjectives.
It was necessarybecause each of these classes has a different syn-tactic behaviour.
It made sense to do the same forSpanish, but we did not have enough Spanish speak-ers available to undertake this task, therefore we puttogether all the subjective Spanish words - verbs, ad-jectives and nouns in one class.
We ran Ontopopulisfor each of the three classes - the class of subjectiveSpanish words and the English classes A and B. Thetop scored 200 new learnt terms were taken for eachclass and manually reviewed.3.3 Triangulation and ExpansionAfter polishing the pivot language dictionaries weprojected them to other languages.
The dictionarieswere translated by Google translator because of itsbroad coverage of languages.
The overlapping termsbetween English and Spanish translations formedthe basis for further manual efforts.
In some casesthere were overlapping terms in English and Span-ish translations but they differed in intensity.
Therewas the same term translated from an English posi-tive term and from a Spanish very positive term.
Inthese cases the term was assigned to the positive cat-egory.
However, more problematic cases arose whenthe same 3rd language term was assigned to morethan one category.
There were also cases with dif-ferent polarity.
We had to review them manually.However, there were still lots of relevant terms in thetranslated lists which were not translated from theother language.
These complement terms are a goodbasis for extending the coverage of the dictionaries,however, they need to be reviewed manually.
Even ifwe tried to include in the pivot lists all morpholog-ical variants, in the triangulation output there wereonly a few variants, mainly in the case of highly in-flected languages.
To deal with morphology we in-troduced wild cards at the end of the term stem (*stands for whatever ending and for whatever char-acter).
This step had to be performed carefully be-cause some noise could be introduced.
See the Re-sults section for examples.
Although this step wasperformed by a human, we checked the most fre-quent terms afterwards to avoid irrelavant frequentterms.4 Results4.1 Pivot dictionariesWe gathered and filtered English sentiment termsfrom the available corpora (see Section 3.1).
Thedictionaries were then translated to Spanish (byGoogle translator) and filtered afterwards.
By ap-plying automatic term extraction, we enriched thesets of terms by 54 for English and 85 for Spanish,after evaluating the top 200 candidates suggested bythe Ontopolulis tool for each language.
The resultsare encouraging, despite the relevance of the terms(27% for English and 42.5% for Spanish wheresome missing morphological variants were discov-ered) does not seem to be very high, considering thefact that we excluded the terms already containedin the pivot lists.
If we took them into account, theprecision would be much better.
The initial step re-sulted in obtaining high quality pivot sentiment dic-tionaries for English and Spanish.
Their statisticsare in table 1.
We gathered more English terms thanSpanish (2.4k compared to 1.7k).
The reason forthat is that some translations from English to Span-ish have been filtered.
Another observation is thatthere is approximately the same number of negativeterms as positive ones, however, much more highlynegative than highly positive terms.
Although the31Language English SpanishHN 554 466N 782 550P 772 503HP 171 119INT 78 62DIM 31 27INV 15 10TOTAL 2.403 1.737Table 1: The size of the pilot dictionaries.
HN=highlynegative terms, N=negative, P=positive, HP=highly posi-tive, INV=invertors, DIM=diminishers, INV=invertors.frequency analysis we carried out later showed thateven if there are fewer highly positive terms, they aremore frequent than the highly negative ones, whichresults in almost uniform distribution.4.2 Triangulation and ExpansionAfter running triangulation to other languages theresulted terms were judged for relevance.
Nativespeakers could suggest to change term?s category(e.g.
negative to highly negative) or to remove it.There were several reasons why the terms couldhave been marked as ?non-sentiment?.
For instance,the term could tend to describe rather negative newscontent than negative sentiment towards an entity(e.g.
dead, quake).
In other cases the terms weretoo ambiguous in a particular language.
Examplesfrom English are: like or right.Table 2 shows the quality of the triangulated dic-tionaries.
In all cases except for Italian we had onlyone annotator assessing the quality.
We can see thatthe terms were correct in around 90% cases, how-ever, it was a little bit worse in the case of Russianin which the annotator suggested to change categoryvery often.Terms translated from English but not from Span-ish are less reliable but, if reviewed manually, thedictionaries can be expanded significantly.
Table 3gives the statistics concerning these judgments.
Wecan see that their correctness is much lower than inthe case of the triangulated terms - the best in Italian(54.4%) and the worst in Czech (30.7%).
Of course,the translation performance affects the results here.However, this step extended the dictionaries by ap-proximately 50%.When considering terms out of context, the mostcommon translation error occurs when the originalword has several meanings.
For instance, the En-glish word nobility refers to the social class of no-bles, as well as to the quality of being morally good.In the news context we find this word mostly in thesecond meaning.
However, in the Russian triangu-lated list we have found dvoryanstvo , which refersto a social class in Russian.
Likewise, we need tokeep in mind that a translation of a monosemanticword might result polysemantic in the target lan-guage, thereby leading to confusion.
For example,the Italian translation of the English word championcampione is more frequently used in Italian newscontext in a different meaning - sample, thereforewe must delete it from our sentiment words list forItalian.
Another difficulty we might encounter es-pecially when dealing with inflectional languages isthe fact that a translation of a certain word might behomographic with another word form in the targetlanguage.
Consider the English negative word ban-dit and its Italian translation bandito, which is morefrequently used as a form of the verb bandire (to an-nounce) in the news context.
Also each annotatorhad different point of view on classifying the bor-derline cases (e.g.
support, agreement or difficult).Two main reasons are offered to explain the lowperformance in Arabic.
On the one hand, it seemsthat some Google translation errors will be repeatedin different languages if the translated words havethe same etymological root.
For example both words?
the English fresh and the Spanish fresca ?
aretranslated to the Arabic as YKYg.
meaning new.
TheOther reason is a more subtle one and is related tothe fact that Arabic words are not vocalized and tothe way an annotator perceive the meaning of a givenword in isolation.
To illustrate this point, considerthe Arabic word ?
J.
?AJ ??
@ , which could be usedas an adjective, meaning appropriate, or as a noun,meaning The occasion.
It appears that the annotatorwould intuitively perceive the word in isolation as anoun and not as an adjective, which leads to disre-garding the evaluative aspects of a given word.We tried to include in the pivot dictionaries allmorphological variants of the terms.
However, inhighly inflected languages there are much more vari-ants than those translated from English or Spanish.32We manually introduced wild cards to capture thevariants.
We had to be attentive when compilingwild cards for languages with a rich inflectional sys-tem, as we might easily get undesirable words in theoutput.
To illustrate this, consider the third personplural of the Italian negative word perdere (to lose)perdono, which is also homographic with the wordmeaning forgiveness in English.
Naturally, it couldhappen that the wildcard captures a non-sentimentterm or even a term with a different polarity.
For in-stance, the pattern care% would capture either care,careful, carefully, but also career or careless.
Thatis way we perform the last manual checking aftermatching the lists expanded by wildcards against alarge number of texts.
The annotators were unableto check all the variants, but only the most frequentterms, which resulted in reviewing 70-80% of theterm mentions.
This step has been performed foronly English, Czech and Russian so far.
Table 5gives the statistics.
By introducing the wildcards,the number of distinct terms grew up significantly- 12x for Czech, 15x for Russian and 4x for En-glish.
One reason why it went up also for Englishis that we captured compounds like: well-arranged,well-balanced, well-behaved, well-chosen by a sin-gle pattern.
Another reason is that a single pat-tern can capture different POSs: beaut% can cap-ture beauty, beautiful, beautifully or beautify.
Notall of those words were present in the pivot dictio-naries.
For dangerous cases like care% above wehad to rather list all possible variants than using awildcard.
This is also the reason why the numberof patterns is not much lower than the number ofinitial terms.
Even if this task was done manually,some noise was added into the dictionaries (92-94%of checked terms were correct).
For example, highlypositive pattern hero% was introduced by an anno-tator for capturing hero, heroes, heroic, heroical orheroism.
If not checked afterwards heroin wouldscore highly positively in the sentiment system.
An-other example is taken from Russian: word meaningto steal ukra% - might generate Ukraine as one mostfrequent negative word in Russian.4.3 How subjective is the annotation?Sentiment annotation is a very subjective task.
In ad-dition, annotators had to judge single terms withoutany context: they had to think about all the senses ofMetric Percent Agreement KappaHN 0.909 0.465N 0.796 0.368P 0.714 0.281HP 0.846 0N+HN 0.829 0.396P+HP 0.728 0.280ALL 0.766 0.318Table 6: Inter-annotator agreement on checking the trian-gulated list.
In the case of HP all terms were annotated ascorrect by one of the annotators resulting in Kappa=0.Metric Percent Agreement KappaHN 0.804 0.523N 0.765 0.545P 0.686 0.405HP 0.855 0.669N+HN 0.784 0.553P+HP 0.783 0.559ALL 0.826 0.614Table 7: Inter-annotator agreement on checking the can-didates.
In ALL diminishers, intensifiers and invertorsare included as well.the term.
Only if the main sense was subjective theyagreed to leave it in the dictionary.
Another sub-jectivity level was given by concentrating on distin-guishing news content and news sentiment.
Definingthe line between negative and highly negative terms,and similarly with positive, is also subjective.
In thecase of Italian we compared judgments of two anno-tators.
The figures of inter-annotator agreement ofannotating the triangulated terms are in table 6 andthe complement terms in table 7.
Based on the per-cent agreement the annotators agree a little bit lesson the triangulated terms (76.6%) compared to thecomplement terms (82.6%).
However, if we look atKappa figures, the difference is clear.
Many termstranslated only from English were clearly wrongwhich led to a higher agreement between the annota-tors (0.318 compared to 0.614).
When looking at thedifference between positive and negative terms, wecan see that there was higher agreement on the neg-ative triangulated terms then on the positive ones.33Language Triangulated Correct Removed Changed categoryArabic 926 606 (65.5%) 316 (34.1%) 4 (0.4%)Czech 908 809 (89.1%) 68 (7.5%) 31 (3.4%)French 1.085 956 (88.1%) 120 (11.1%) 9 (0.8%)German 1.053 982 (93.3%) 50 (4.7%) 21 (2.0%)Italian 1.032 918 (89.0%) 36 (3.5%) 78 (7.5%)Russian 966 816 (84.5%) 49 (5.1%) 101 (10.4%)Table 2: The size and quality of the triangulated dictionaries.
Triangulated=No.
of terms coming directly from triangu-lation, Correct=terms annotated as correct, Removed=terms not relevant to sentiment analysis, Change category=termsin wrong category (e.g., positive from triangulation, but annotator changed the category to highly positive).Language Terms Correct Removed Changed categoryCzech 1.092 335 (30.7%) 675 (61.8%) 82 (7.5%)French 1.226 617 (50.3%) 568 (46.3%) 41 (3.4%)German 1.182 548 (46.4%) 610 (51.6%) 24 (2.0%)Italian 1.069 582 (54.4%) 388 (36.3%) 99 (9.3%)Russian 1.126 572 (50.8%) 457 (40.6%) 97 (8.6%)Table 3: The size and quality of the candidate terms (translated from English but not from Spanish).
Terms=No.
ofterms translated from English but not from Spanish, Correct=terms annotated as correct, Removed=terms not relevantto sentiment analysis, Change category=terms in wrong category (e.g., positive in the original list, but annotatorchanged the category to highly positive).Language Terms Correct Removed Changed categoryCzech 2.000 1.144 (57.2%) 743 (37.2%) 113 (5.6%)French 2.311 1.573 (68.1%) 688 (29.8%) 50 (2.1%)German 2.235 1.530 (68.5%) 660 (29.5%) 45 (2.0%)Italian 2.101 1.500 (71.4%) 424 (20.2%) 177 (8.4%)Russian 2.092 1.388 (66.3%) 506 (24.2%) 198 (9.5%)Table 4: The size and quality of the translated terms from English.
Terms=No.
of (distinct) terms translated from En-glish, Correct=terms annotated as correct, Removed=terms not relevant to sentiment analysis, Change category=termsin wrong category (e.g., positive in the original list, but annotator changed the category to highly positive).Language Initial terms Patterns Matched termsCount Correct CheckedCzech 1.257 1.063 15.604 93.0% 74.4%English 2.403 2.081 10.558 93.8% 81.1%Russian 1.586 1.347 33.183 92.2% 71.0%Table 5: Statistics of introducing wild cards and its evaluation.
Initial terms=checked triangulated terms extended byrelevant translated terms from English, Patterns=number of patterns after introducing wildcards, Matched terms=termsmatched in the large corpus - their count and correctness + checked=how many mentions were checked (based on thefact that the most frequent terms were annotated).344.4 Triangulation vs. TranslationTable 4 present the results of simple translation fromEnglish (summed up numbers from tables 2 and 3).We can directly compare it to table 2 where onlyresults of triangulated terms are reported.
The per-formance of triangulation is significantly better thanthe performance of translation in all languages.
Thehighest difference was in Czech (89.1% and 57.2%)and the lowest was in Italian (89.0% and 71.4%).As a task-based evaluation we used the triangu-lated/translated dictionaries in the system analysingnews sentiment expressed towards entities.
The sys-tem analyses a fixed word window around entitymentions.
Subjective terms are summed up and theresulting polarity is attached to the entity.
Highlynegative terms score twice more than negative, di-minishers lower and intensifiers lift up the score.
In-vertors invert the polarity but for instance invertedhighly positive terms score as only negative pre-venting, for instance, not great to score as worst.The system searches for the invertor only two wordsaround the subjective term.We ran the system on 300 German sentencestaken from news gathered by the Europe MediaMonitor (EMM)1.
In all these cases the system at-tached a polarity to an entity mention.
We ran it withthree different dictionaries - translated terms fromEnglish, raw triangulated terms (without the man-ual checking) and the checked triangulated terms.This pilot experiment revealed the difference in per-formance on this task.
When translated terms wereused there were only 41.6% contexts with correctpolarity assigned by the system, with raw triangu-lated terms 56.5%, and with checked triangulatedterms 63.4%.
However, the number does not containneutral cases that would increase the overall perfor-mance.
There are lots of reasons why it goes wronghere: the entity may not be the target of the sub-jective term (we do not use parser because of deal-ing with many languages and large amounts of newstexts), the system can miss or apply wrongly an in-vertor, the subjective term is used in different sense,and irony is hard to detect.1http://emm.newsbrief.eu/overview.html4.5 State of progressWe finished all the steps for English, Czech and Rus-sian.
French, German, Italian and Spanish dictio-naries miss only the introduction of wild cards.
InArabic we have checked only the triangulated terms.For other 7 languages (Bulgarian, Dutch, Hungarian,Polish, Portuguese, Slovak and Turkish) we haveonly projected the terms by triangulation.
However,we have capabilities to finish all the steps also forBulgarian, Dutch, Slovak and Turkish.
We haven?tinvestigated using more than two pivot languages fortriangulation.
It would probably results in more ac-curate but shortened dictionaires.5 ConclusionsWe presented our semi-automatic approach and cur-rent state of work of producing multilingual senti-ment dictionaries suitable of assessing the sentimentin news expressed towards an entity.
The triangula-tion approach works significantly better than simpletranslation but additional manual effort can improveit a lot in both recall and precision.
We believe thatwe can predict the sentiment expressed towards anentity in a given time period based on large amountsof data we gather in many languages even if the per-case performance of the sentiment system as on amoderate level.
Now we are working on improvingthe dictionaries in all the discussed languages.
Wealso run experiments to evaluate the system on vari-ous languages.AcknowledgmentsWe thank Alexandra Balahur for her collaborationand useful comments.
This research was partly sup-ported by a IULA-Universitat Pompeu Fabra grant.35ReferencesAlexandra Balahur, Ralf Steinberger, Erik van der Goot,and Bruno Pouliquen.
2009.
Opinion mining fromnewspaper quotations.
In Proceedings of the Work-shop on Intelligent Analysis and Processing of WebNews Content at the IEEE / WIC / ACM InternationalConferences on Web Intelligence and Intelligent AgentTechnology (WI-IAT).A.
Balahur, R. Steinberger, M. Kabadjov, V. Zavarella,E.
van der Goot, M. Halkia, B. Pouliquen, andJ.
Belyaeva.
2010.
Sentiment analysis in the news.In Proceedings of LREC?10.C.
Banea, R. Mihalcea, and J. Wiebe.
2008a.
A boot-strapping method for building subjectivity lexicons forlanguages with scarce resources.
In Proceedings ofLREC.C.
Banea, R. Mihalcea, J. Wiebe, and S. Hassan.2008b.
Multilingual subjectivity analysis using ma-chine translation.
In Proceedings of EMNLP.C.
Banea, R. Mihalcea, and J. Wiebe.
2010.
Multilingualsubjectivity: Are more languages better?
In Proceed-ings of COLING.S.
Cerini, V. Compagnoni, A. Demontis, M. Formentelli,and G. Gandini.
2007.
Micro-WNOp: A gold stan-dard for the evaluation of automatically compiled lex-ical resources for opinion mining.
In Andrea Sanso`,editor, Language resources and linguistic theory: Ty-pology, second language acquisition, English linguis-tics.
Franco Angeli, Milano, IT.A.
Esuli and F. Sebastiani.
2006.
SentiWordNet: A pub-licly available resource for opinion mining.
In Pro-ceeding of the 6th International Conference on Lan-guage Resources and Evaluation, Italy, May.S.-M. Kim and E. Hovy.
2006.
Extracting opinions,opinion holders, and topics expressed in online newsmedia text.
In Proceedings of the ACL Workshop onSentiment and Subjectivity in Text.T.
Landauer and S. Dumais.
1997.
A solution to plato?sproblem: The latent semantic analysis theory of the ac-quisition, induction, and representation of knowledge.Psychological Review, 104:211?240.W.
Lin, R. Yangarber, and R. Grishman.
2003.
Boot-strapped learning of semantic classes from positiveand negative examples.
In Proceedings of the ICML-2003 Workshop on The Continuum from Labeled toUnlabeled Data, Washington DC.R.
Mihalcea, C. Banea, and J. Wiebe.
2007.
Learningmultilingual subjective language via cross-lingual pro-jections.
In Proceedings of ACL.E.
Riloff and J. Wiebe.
2003.
Learning extraction pat-terns for subjective expressions.
In Proceeding ofthe Conference on Empirical Methods in Natural Lan-guage Processing.P.J.
Stone, D.C. Dumphy, M.S.
Smith, and D.M.
Ogilvie.1966.
The general inquirer: a computer approach tocontent analysis.
M.I.T.
studies in comparative poli-tics, M.I.T.
Press, Cambridge, MA.C.
Strapparava and A. Valitutti.
2004.
WordNet-Affect:an affective extension of wordnet.
In Proceeding of the4th International Conference on Language Resourcesand Evaluation, pages 1083?1086, Lisbon, Portugal,May.H.
Tanev, V. Zavarella, J. Linge, M. Kabadjov, J. Pisko-rski, M. Atkinson, and R.Steinberger.
2010.
Exploit-ing machine learning techniques to build an event ex-traction system for portuguese and spanish.
Lingua-matica: Revista para o Processamento Automatico dasLinguas Ibericas.X.
Wan.
2008.
Co-training for cross-lingual sentimentclassification.
In Proceedings of the Joint Confer-ence of the 47th Annual Meeting of the Associationfor Computational Linguistics and 4th InternationalJoint Conference on Natural Language Processing ofthe Asian Federation of Natural Language Processing.T.
Wilson, J. Wiebe, and P. Hoffman.
2005.
Recognizingcontextual polarity in phrase-level sentiment analysis.In Proceedings of HLT-EMNLP.36
