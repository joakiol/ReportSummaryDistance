Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 243?246,New York, June 2006. c?2006 Association for Computational LinguisticsA Hybrid Approach to Biomedical Named Entity Recognition andSemantic Role LabelingRichard Tzong-Han TsaiDepartment of Computer Science and Information EngineeringNational Taiwan UniversityNankang, Taipei, Taiwan, 115thtsai@iis.sinica.edu.twAbstractIn this paper, we describe our hybrid ap-proach to two key NLP technologies:biomedical named entity recognition(Bio-NER) and (Bio-SRL).
In Bio-NER,our system successfully integrates linguis-tic features into the CRF framework.
Inaddition, we employ web lexicons andtemplate-based post-processing to furtherboost its performance.
Through thesebroad linguistic features and the nature ofCRF, our system outperforms state-of-the-art machine-learning-based systems,especially in the recognition of proteinnames (F=78.5%).
In Bio-SRL, first, weconstruct a proposition bank on top of thepopular biomedical GENIA treebank fol-lowing the PropBank annotation scheme.We only annotate the predicate-argumentstructures (PAS?s) of thirty frequentlyused biomedical verbs (predicates) andtheir corresponding arguments.
Second,we use our proposition bank to train abiomedical SRL system, which uses amaximum entropy (ME) machine-learning model.
Thirdly, we automaticallygenerate argument-type templates, whichcan be used to improve classification ofbiomedical argument roles.
Our experi-mental results show that a newswire Eng-lish SRL system that achieves an F-scoreof 86.29% in the newswire English do-main can maintain an F-score of 64.64%when ported to the biomedical domain.By using our annotated biomedical corpus,we can increase that F-score by 22.9%.Adding automatically generated templatefeatures further increases overall F-scoreby 0.47% and adjunct (AM) F-score by1.57%, respectively.1 IntroductionThe volume of biomedical literature available onthe Web has experienced unprecedented growth inrecent years, and demand for efficient methods toprocess this material has increased accordingly.Lately, there has been a surge of interest in miningbiomedical literature.
To this end, more and moreinformation extraction (IE) systems using naturallanguage processing (NLP) technologies have beendeveloped for use in the biomedical field.
Keybiomedical IE tasks include named entity (NE)recognition (NER), such as the recognition of pro-tein and gene names; and relation extraction, suchas the extraction of protein-protein and gene-geneinteractions.NER identifies named entities from natural lan-guage texts and classifies them into specific classesaccording to a defined ontology or classification.In general, biomedical NEs do not follow any no-menclature and may comprise long compoundwords and short abbreviations.
Some NEs containvarious symbols and other spelling variations.
Onaverage, an NE has five synonyms (Tsai et al,2006a), and it may belong to multiple categoriesintrinsically.
Since biomedical language and vo-243cabulary are highly complex and evolving rapidly,Bio-NER is a very challenging problem, whichraises a number of difficulties.The other main focus of Bio-IE is relation ex-traction.
Most systems only extract the relationtargets (e.g., proteins, genes) and the verbs repre-senting those relations, overlooking the many ad-verbial and prepositional phrases and words thatdescribe location, manner, timing, condition, andextent.
However, the information in such phrasesmay be important for precise definition and clarifi-cation of complex biological relations.This problem can be tackled by using semanticrole labeling (SRL) because it not only recognizesmain roles, such as agents and objects, but alsoextracts adjunct roles such as location, manner,timing, condition, and extent.
(Morarescu et al,2005) has demonstrated that full-parsing and SRLcan improve the performance of relation extraction,resulting in an F-score increase of 15% (from 67%to 82%).
This significant result leads us to surmisethat SRL may also have potential for relation ex-traction in the biomedical domain.
Unfortunately,no SRL system for the biomedical domain exists.In this paper, we tackle the problems of bothbiomedical SRL and NER.
Our contributions are (1)employing web lexicons and template-based post-processing to boost the performance of Bio-NER;(2) constructing a proposition bank on top of thepopular biomedical GENIA treebank following thePropBank annotation scheme and developing aBiomedical SRL system.
We adapt an SRL systemtrained the World Street Journal (WSJ) corpus tothe biomedical domain.
On adjunct arguments,especially those relevant to the biomedical domain,the performance is unsatisfactory.
We, therefore,develop automatically generated templates foridentifying these arguments.2 Biomedical Named Entity RecognitionOur Bio-NER system uses the CRF model(Lafferty et al, 2001), which has proven its effec-tiveness in several sequence tagging tasks.2.1 Features and Post-ProcessingOrthographical FeaturesIn our experience, ALLCAPS, CAPSMIX, andINITCAP are more useful than others.
The detailsare listed in (Tsai et al, 2006a).Context FeaturesWords preceding or following the target word maybe useful for determining its category.
In our ex-perience, a suitable window size is five.Part-of-speech FeaturesPart-of-speech information is quite useful for iden-tifying NEs.
Verbs and prepositions usually indi-cate an NE?s boundaries, whereas nouns not foundin the dictionary are usually good candidates fornamed entities.
Our experience indicates that fiveis also a suitable window size.
The MBT POS tag-ger is used to provide POS information.
We trainedit on GENIA 3.02p and achieved 97.85% accuracy.Word Shape FeaturesAs NEs in the same category may look similar(e.g., IL-2 and IL-4), we have to find a simple wayto normalize all similar words.
According to ourmethod, capitalized characters are all replaced by?A?, digits are all replaced by ?0?, non-Englishcharacters are replaced by ?_?
(underscore), andnon-capitalized characters are replaced by ?a?.
Tofurther normalize these words, we reduce consecu-tive strings of identical characters to one character.Affix FeaturesSome affixes can provide good clues for classify-ing named entities (e.g., ?ase?).
In our experience,an acceptable affix length is 3-5 characters.Lexicon FeaturesDepending on the quality of a given dictionary, oursystem uses one of two different lexicon features toestimate the possibility of a token in a biomedicalnamed entity.
The first feature determines whethera token is part of a multi-word NE in the dictionary,while the second feature calculates the minimumdistance between the given token and a dictionary.In our experience, the first feature is effective for adictionary containing high-quality items, for ex-ample, human-curated protein dictionaries.
Thesecond feature is effective for a dictionary that hasa large number of items that are not very accurate,for example, web or database lexicons.
Details canbe found in (Tsai et al, 2006a).Post-ProcessingWe count the number of occurrences of a word xappearing in the rightmost position of all NEs ineach category.
Let the maximum occurrence be n,244and the corresponding category be c. The totalnumber of occurrences of x in the rightmost posi-tion of an NE is T; c/T is the consistency rate of x.According to our analysis of the training set of theJNLPBA 2004 data, 75% of words have a consis-tency rate of over 95%.
We record this 75% ofwords and their associated categories in a table.After testing, we crosscheck all the rightmostwords of NEs found by our system against this ta-ble.
If they match, we overwrite the NE categorieswith those from the table.2.2 Experiments and SummaryWe perform 10-fold cross validation on theGENIA V3.02 corpus (Kim et al, 2003) to com-pare our CRF-based system with other biomedicalNER systems.
The experimental results are re-ported in Table 1.
Our system  outperforms othersystems in protein names by an F-score of at least2.6%.
For DNA names, our performance is veryclose to that of the best system.BioNER System Protein DNAOur System (Tsai et al, 2006a) 78.4 66.3HMM (Zhou et al, 2004) 75.8 63.3Two Phase SVM (Lee et al, 2003) 70.6 66.4Table 1.
Performance of protein and DNA namerecognition on the GENIA V3.02 corpusWe have made every effort to implement a vari-ety of linguistic features in our system?s CRFframework.
Thanks to these features and the natureof CRF, our system outperforms state-of-the-artmachine-learning-based systems, especially in therecognition of protein names.Our system still has difficulty recognizing long,complicated NEs and coordinated NEs and distin-guishing between overlapping NE classes, e.g.,cell-line and cell-type.
This is because biomedicaltexts have complicated sentence structures and in-volve more expert knowledge than texts from thegeneral newswire domain.
Since pure machinelearning approaches cannot model long contextualphenomena well due to context window size limi-tations and data sparseness, we believe that tem-plate-based methods, which exploit long templatescontaining different levels of linguistic information,may be of help.
Certain errors, such as incorrectboundary identification, are more tolerable if themain purpose is to discover relations between NEs(Tsai et al, 2006c).
We shall exploit more linguis-tic features, such as composite features and exter-nal features, in the future.
However, machineleaning approaches suffer from a serious problemof annotation inconsistency, which confuses ma-chine learning models and makes evaluation diffi-cult.
In order to reduce human annotation effortand alleviate the scarcity of available annotatedcorpora, we shall learn from web corpora to de-velop machine learning techniques in differentbiomedical domains.3 Biomedical Semantic Role LabelingIn this section, we describe the main steps in build-ing a biomedical SRL system: (1) create semanticroles for each biomedical verb; (2) construct abiomedical corpus, annotated with verbs and theircorresponding semantic roles; (3) build an auto-matic semantic interpretation model, using the an-notated text as a training corpus for machinelearning.
However, on adjunct arguments, espe-cially on those highly relevant to the biomedicaldomain, such as AM-LOC (location), the perform-ance is not satisfactory.
We therefore develop atemplate generation method to create templatesthat are used as features for identifying these ar-gument types.3.1 Biomedical Proposition Bank -- BioPropOur biomedical proposition bank, BioProp, isbased on the GENIA Treebank (Yuka et al, 2005),which is a 491-abstract corpus annotated with syn-tactic structures.
The semantic annotation in Bio-Prop is added to the proper constituents in asyntactic tree.Basically, we adopt the definitions in PropBank(Palmer et al, 2005).
For the verbs not in Prop-Bank, such as ?phosphorylate?, we define theirframesets.
Since the annotation is time-consuming,we adopt a semi-automatic approach.
We adapt anSRL system trained on PropBank (Wall StreetJournal corpus) to the biomedical domain.
We firstuse this SRL system to automatically annotate ourcorpus, and then human annotators to double checkthe system?s results.
Therefore, human effort isgreatly reduced.3.2 Biomedical SRL System -- SEROW245Following (Punyakanok et al, 2004), we formulateSRL as a constituent-by-constituent (C-by-C) tag-ging problem.
We use BioProp to train our bio-medical SRL system, SEROW (Tsai et al, 2006b),which uses a maximum entropy (ME) machine-learning model.
We use the basic features de-scribed in (Xue & Palmer, 2004).
In addition, weautomatically generate templates which can beused to improve classification of biomedical argu-ment types.
The details of SEROW system are de-scribed in (Tsai et al, 2005) and (Tsai et al,2006b).3.3 Experiment and SummaryOur experimental results show that a newswireEnglish SRL system that achieves an F-score of86.29% can maintain an F-score of 64.64% whenported to the biomedical domain.
By using SE-ROW, we can increase that F-score by 22.9%.Adding automatically generated template featuresfurther increases overall F-score by 0.47% and ad-junct (AM) F-score by 1.57%, respectively.4 ConclusionNER and SRL are two key topics in biomedicalNLP.
For NER, we find broad linguistic featuresand integrate them into our CRF framework.
Oursystem outperforms most machine learning-basedsystems, especially in the recognition of proteinnames (78.4% of F-score).
In the future, templatesthat can match long contextual relations and coor-dinated NEs may be applied to NER post-processing.
Web corpora may also be used to en-hance unknown NE detection.
In Bio-SRL, ourcontribution is threefold.
First, we construct a bio-medical proposition bank, BioProp, on top of thepopular biomedical GENIA treebank following thePropBank annotation scheme.
We employ semi-automatic annotation using an SRL system trainedon PropBank thereby significantly reducing anno-tation effort.
Second, we construct SEROW, whichuses BioProp as its training corpus.
Thirdly, wedevelop a method to automatically generate tem-plates that can boost overall performance, espe-cially on location, manner, adverb, and temporalarguments.
In the future, we will expand BioPropto include more biomedical verbs and will alsointegrate a parser into SEROW.ReferencesKim, J.-D., Ohta, T., Teteisi, Y., & Tsujii, J. i.
(2003).Genia corpus - a semantically annotated corpus forbio-textmining.
Bioinformatics, 19(suppl.
1).Lafferty, J., McCallum, A., & Pereira, F. (2001).
Condi-tional random fields: Probabilistic models for seg-menting and labeling sequence data.
Paper presentedat the ICML-01.Lee, K.-J., Hwang, Y.-S., & Rim, H.-C. (2003).
Twophase biomedical ne recognition based on svms.
Pa-per presented at the ACL-03 Workshop on NaturalLanguage Processing in Biomedicine.Morarescu, P., Bejan, C., & Harabagiu, S. (2005).
Shal-low semantics for relation extraction.
Paper presentedat the IJCAI-05.Palmer, M., Gildea, D., & Kingsbury, P. (2005).
Theproposition bank: An annotated corpus of semanticroles.
Computational Linguistics, 31(1).Punyakanok, V., Roth, D., Yih, W., & Zimak, D. (2004).Semantic role labeling via integer linear program-ming inference.
Paper presented at the 20th Interna-tional Conference on Computational Linguistics(COLING-04).Tsai, R. T.-H., Chou, W.-C., Wu, S.-H., Sung, T.-Y.,Hsiang, J., & Hsu, W.-L. (2006a).
Integrating lin-guistic knowledge into a conditional random fieldframework to identify biomedical named entities.Expert Systems with Applications, 30(1), 117-128.Tsai, R. T.-H., Lin, W.-C. C. Y.-C., Ku, W., Su, Y.-S.,Sung, T.-Y., & Hsu, W.-L. (2006b).
Serow: Adaptingsemantic role labeling for biomedical verbs: An ex-ponential model coupled with adapting semantic rolelabeling for biomedical verbs: An exponential modelcoupled with automatically generated template fea-tures.
To appear in BioNLP-2006.Tsai, R. T.-H., Wu, C.-W., Lin, Y.-C., & Hsu, W.-L.(2005).
Exploiting full parsing information to labelsemantic roles using an ensemble of me and svm viainteger linear programming.
Paper presented at theCoNLL-2005.Tsai, R. T.-H., Wu, S.-H., Chou, W.-C., Lin, Y.-C., He,D., Hsiang, J., et al (2006c).
Various criteria in theevaluation of biomedical named entity recognition.BMC Bioinformatics, 7(92).Xue, N., & Palmer, M. (2004).
Calibrating features forsemantic role labeling.
Paper presented at theEMNLP 2004.Yuka, T., Yakushiji, A., Ohta, T., & Tsujii, J.
(2005).Syntax annotation for the genia corpus.Zhou, G., Zhang, J., Su, J., Shen, D., & Tan, C. (2004).Recognizing names in biomedical texts: A machinelearning approach.
Bioinformatics, 20, 1178-1190.246
