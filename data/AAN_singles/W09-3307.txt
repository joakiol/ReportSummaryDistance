Proceedings of the 2009 Workshop on the People?s Web Meets NLP, ACL-IJCNLP 2009, pages 42?50,Suntec, Singapore, 7 August 2009. c?2009 ACL and AFNLPConstruction of Disambiguated Folksonomy Ontologies Using WikipediaNoriko Tomuro and Andriy ShepitsenDePaul University, College of Digital Media243 S. Wabash, Chicago, IL USAtomuro@cs.depaul.edu, ashepits@cdm.depaul.eduAbstractOne of the difficulties in using Folk-sonomies in computational systems is tagambiguity: tags with multiple meanings.This paper presents a novel method forbuilding Folksonomy tag ontologies inwhich the nodes are disambiguated.
Ourmethod utilizes a clustering algorithmcalled DSCBC, which was originally de-veloped in Natural Language Processing(NLP), to derive committees of tags, eachof which corresponds to one meaning ordomain.
In this work, we use Wikipediaas the external knowledge source for thedomains of the tags.
Using the commit-tees, an ambiguous tag is identified as onewhich belongs to more than one commit-tee.
Then we apply a hierarchical agglom-erative clustering algorithm to build an on-tology of tags.
The nodes in the derivedontology are disambiguated in that an am-biguous tag appears in several nodes inthe ontology, each of which correspondsto one meaning of the tag.
We evaluate thederived ontology for its ontological den-sity (how close similar tags are placed),and its usefulness in applications, in par-ticular for a personalized tag retrieval task.The results showed marked improvementsover other approaches.1 IntroductionIn recent years, there has been a rapid growth insocial tagging systems ?
so-called Folksonomieswhere users assign keywords or tags to categorizeresources.
Typically, the sources of folksonomiesare web resources, and virtually any kind of infor-mation available on the Internet, ranging from webpages (e.g.
Delicious (delicious.com)), scientific ar-ticles (e.g.
Bibsonomy (www.bibsonomy.org)) to me-dia resources (e.g.
Flickr (www.flickr.com), Last.fm(www.last.fm)).
Although tags in folksonomies areessentially semantic concepts, they have distinctcharacteristics as compared to conventional se-mantic resources which are often used in Natu-ral Language Processing (NLP), such as WordNet(Miller, 1990).
First, folksonomy tags are unre-stricted ?
users are free to choose any words orset of characters to formulate tags.
One significantproblem arising from such free-formedness is tagambiguity: tags that have several meanings (e.g.?Java?
as coffee or a programming language or anisland in Indonesia).
Second, folksonomy tags areunstructured ?
tags assigned to a given resourceare simply enumerated in a list (although often-times using a varying font size to indicate popu-larity), and no special organization or categoriza-tion of the tags is made (by the Folksonomy site).There have been several work recently which ex-tracted structures from folksonomy tags and con-structed ontologies (e.g.
(Clough et al, 2005),(Schmitz, 2006)).
However, most of them evalu-ate the effect of the extracted structures only in thecontext of specific applications, for instance gen-erating user recommendations (e.g.
(Shepitsen etal., 2008)).In this work, we develop a novel method forconstructing ontologies from folksonomy tags.In particular, we employ a clustering algorithmcalled Domain Similarity Clustering By Commit-tee (DSCBC) (Tomuro et al, 2007).
DSCBC is anextension of an algorithm called CBC (Pantel andLin, 2002), and was originally developed for lexi-cal semantics in NLP to automatically derive sin-gle/unambiguous word meanings (as committees)from ambiguous words.
In this work, DSCBC iseffectively adopted to derive disambiguated folk-sonomy tag committees, where a committee in thiscontext is a cluster of tags in which the membersshare the same or very similar concept in one oftheir meanings.
By using DSCBC, an ambiguoustag is identified as one which belongs to more than42one committee.
One of the key ideas in DSCBC isthe notion of feature domain similarity: the sim-ilarity between the features themselves, obtaineda priori from sources external to the dataset usedat hand.
For example, if data instances x and yare represented by features f1 and f2, the featuredomain similarity refers to the similarity betweenf1 and f2 (not between x and y).
DSCBC uti-lizes this feature domain similarity to derive clus-ters whose domains are ?close?, thereby produc-ing unambiguous committees.
In this work, we in-corporate Wikipedia as the external knowledge re-source, and use the similarity between Wikipediaarticles to derive the committees of disambiguatedtags.
Finally using the tag committees derived byDSCBC, we build an ontology of tags by using amodified hierarchical agglomerative clustering al-gorithm.
Ambiguous tags are mapped to severalnodes in this ontology.Note that in this paper, we refer to the structurederived by the hierarchical clustering algorithm asan ?ontology?
instead of a ?taxonomy?.
That is be-cause, in the algorithm, the parent-child relation isdetermined by a similarity measure only, thereforesometimes does not correspond to the subsump-tion relation in the strict sense.For evaluation, we construct an ontology fromthe Delicious tags, and measure the quality (onto-logical density) of the derived ontology by com-paring with the ontologies obtained without usingWikipedia.
We also use the derived ontology ina personalized information retrieval task.
The re-sults show that our method achieved marked im-provements over other approaches.2 Related WorkSeveral efforts have been made recently which fo-cused on extracting structures from folksonomies.Clough (Clough et al, 2005) and Schmitz(Schmitz, 2006) derived hierarchical structuresfrom image folksonomies (St. Andrew collection(specialcollections.st-and.ac.uk/photcol.htm) and Flickr,respectively).
In addition to the hierarchi-cal relation, they also derived other relationssuch as ?type of?, ?aspect of?, ?same-as?, etc.Mika (Mika, 2007) and Heymann (Heymann andGarcia-Molina, 2006) proposed an automatic cre-ation of tags in folksonomy networks based onthe tag co-occurrences among resources and users.They then used a graph clustering algorithm toconnect tags which were used by the same usersand for the same resources to identify tag ?clouds?and communities of like-minded users.
However,none of those work used NLP techniques, nor didthey deal with the tag ambiguity problem; Often-times, highly ambiguous tags are even removedfrom the data.In our previous work (Shepitsen et al, 2008),we used a standard hierarchical agglomerativeclustering algorithm to build a tag hierarchy.
Wealso considered only the most popular sense of anambiguous tag and ignored all other senses.Wikipedia has been attracting much atten-tion in the recent NLP research.
For exam-ple, Wikipedia as a lexical resource was ex-ploited for thesauri construction (Milne et al,2006) and for word sense disambiguation (Mi-halcea and Csomai, 2007).
Other NLP tasks inwhich Wikipedia was utilized to provide contex-tual and domain/encyclopedia knowledge includequestion-answering (Ahn et al, 2004) and infor-mation extraction (Culotta et al, 2006).
In a simi-lar vein, (Gabrilovich and Markovitch, 2006) alsoused Wikipedia to improve the accuracy for textcategorization.
An interesting text retrieval appli-cation was done by Gurevych (Gurevych et al,2007), in whichWikipedia was utilized to improvethe retrieval accuracy in matching the professionalinterests of job applicants with the descriptions ofprofessions/careers.The work presented in this paper applies anNLP technique (the DSCBC algorithm), which in-corporates the domain knowledge (Wikipedia) asa critical component, to the task of extracting se-mantic structure, in particular an ontology, fromfolksonomies.
Our method is novel, and the ex-perimental results indicate that the derived ontol-ogy was of high semantic quality.3 Deriving Unambiguous TagCommitteesThe DSCBC algorithm, which we had developedin our previous work (Tomuro et al, 2007), isan extension of CBC Clustering (Pantel and Lin,2002), modified to produce unambiguous clusterswhen the data contained ambiguous instances.
As-suming the instances are represented by vectors offeatures/domains, consider the following data:a b c dx: 1 1 0 0y: 1 0 1 0z: 1 0 0 143where x, y, z are data instances, and a, b, c, dare features.
In most clustering algorithms, fea-tures are assumed to be independent to each other,or their dependencies are ignored.
So in the ex-ample, x is equally likely clustered with y or z,because the similarity between x and y, and x andz are the same (based on the Euclidean distance,for example).
However if we have a priori, gen-eral knowledge about the features that b?s domainis more similar to that of c than to d, it is betterto cluster x and y instead of x and z, because the{x, y} cluster is ?tighter?
than the {x, z} clusterwith respect to the domains of the features.3.1 Feature Domain SimilarityIn DSCBC, the general knowledge about the fea-tures is incorporated as a measure called Fea-ture Domain Similarity: the similarity betweenthe features themselves, obtained a priori fromsources external to the dataset used at hand.
In thiswork, we used Wikipedia as the external knowl-edge source, and as the features to represent thefolksonomy tags.
To this end, we first obtained themost recent dump of Wikipedia and clustered thearticles to reduce the size of the data.
We call sucha cluster of Wiki articles a Wiki concept.
Cluster-ing was based on the similarity of the terms whichappeared in the articles.
Detailed descriptions ofthe Wikipedia data and this clustering process aregiven in section 5.1.
Then given a set of folkson-omy tags T , a set of folksonomy resources R anda set of Wiki concepts W , we defined a matrix Mof size |T | ?
|W |, where the rows are tags and thecolumns/features are Wiki concepts.
Each entryin this matrix, for a tag t ?
T and a Wiki con-cept w ?
W , was computed as the cosine betweentwo term vectors: one for t where the features areterms used in (all of) the resources in R to whicht was assigned (by the folksonomy users), and an-other for w where the features are terms used in(all of) the Wiki articles in w. Thus, the matrixM contains the similarity values for a given tagto all Wikipedia concepts, thereby identifying the(Wikipedia) domains of the tag.Using the matrix M , we define the feature do-main similarity between two tags f and g, denotedfdSim(f, g), as:fdSim(f, g) =?i?j fi ?
gj ?
cos(wi, wj)?
?i f2i ?
?i g2iwhere fi is the similarity of the tag f to the ithWiki concept (and likewise for g), and cos(wi, wj)is the cosine (thus similarity) between the ith andjth Wiki concepts.
In this formula, the domainknowledge is incorporated not only through theway a tag is represented (as a vector of Wiki con-cepts), but also directly by cos(wi, wj), the simi-larity between Wiki concepts themselves.In addition to Feature Domain Similarity, wealso incorporated a measure of reference tight-ness for folksonomy tags and Wiki concepts.
Thismetric measures and takes advantage of the linkstructure in the folksonomy system as well asWikipedia.
For example, when a tag was assignedto several web pages in the folksonomy system,some of those pages may be reachable from eachother through hyperlinks ?
in which case, we canconsider the tag?s domains are tight.
Likewise forWiki concepts, if a folksonomy tag is ?similar?to several Wiki concepts (for which the similar-ity value is above some threshold), some of thoseWiki concepts may be reachable in the Wikipediastructure ?
then we can consider the tag?s domainsare tight as well.
Furthermore, based on the notionof reference tightness within a set of resources, wedefine the connectedness between two sets of re-sources as the fraction of the resources (web pagesorWiki concepts) in one set which are reachable toresources in another set.
We define the referencetightness between two sets of resources S and U ,denoted srt(S, U), as follows.srt(S, U) =?s?S,u?U reach(s, u) + reach(u, s)?s?S nRef(s) +?u?U nRef(u)where nRef(k) is the number of outgoing refer-ence links in the resource k, and reach(a, b) is anindicator function which returns 1 if any referencelink from the resource in a is reachable from anyresource in b or 0 otherwise.
There are two termsin the numerator because the reachability relationis directional.3.2 The DSCBC AlgorithmUsing the notions of feature domain similarity andreference tightness, we define the similarity be-tween two tags f and g as follows.dsSim(f, g) = ?
?
fdSim(f, g)+(1 ?
?)
?
srt(Rf , Rg)where Rf is the set of references from all webpages to which the tag f is assigned, srt(Rf , Rg)is the reference tightness between Rf and Rg, and44?
is a weighting coefficient.
In our experiments(discussed in section 5), we set ?
to be 0.8 basedon the results of the preliminary runs.The DSCBC algorithm is shown in Algo-rithm 1.
DSCBC is an unsupervised clusteringalgorithm which automatically derives a set ofcommittees.
A committee is a group of folkson-omy tags which are very similar to each other.
InPhase I, a set of preliminary tag clusters are firstcreated.
In Phase II, some of those tag clusters areselected as committees ?
those which are dissimi-lar/orthogonal to all other committees selected sofar.
Then in Phase III, each tag is assigned to com-mittees which are similar to the tag.
The dsSimfunction is used in Phase I and II to measurethe similarity between clusters and committeesrespectively.
In Phase III, an ambiguous tag isassigned to one of more committees, where eachtime the features of the assigned committee areremoved from the tag.
Thus, ambiguous tags areidentified as those which belong to more than onecommittee.4 Building Folksonomy Tag OntologyAfter obtaining the committees by DSCBC, we or-ganize the tags into a ontology by using a modifiedhierarchical agglomerative clustering algorithm.1We first compute the pair-wise similarity betweenany two tags and sort those pairs according to thesimilarity values.
Then we take the most similarpair and create the first cluster.
Afterwards, we it-erate through the whole tag/cluster pairs and sub-stitute all instances in which either tag is a mem-ber, if the tag is not ambiguous, by the obtainedcluster, and repeat the process until the list of pairsis empty.
The committees derived by DSCBC areutilized to identify ambiguous tags ?
when a tagbelonged to more than one committee.
When weprocess an ambiguous tag, we first find its ?coremeaning?
by finding the committee to which thetag is most similar, then remove all (non-zero) fea-tures that are encoded in committee from all in-stances left in the dataset.
With this scheme, wecan cover all senses of an ambiguous tag, for allsuch tags, during ontology generation.
The simi-larity is computed using the dsSim function de-scribed in the previous section; the only differencethat, if one member of a pair is a cluster, it is rep-1Our algorithm is essentially a modification of theAverage-Link Clustering by (OConnor andHerlocker, 2001).Input: Set of tags T. Tuning coefficients:n - number of the most similar tags chosen forthe target tagq - number of features for finding the centroid?
- similarity threshold for adding tags tocommittees?
- similarity threshold for assigning tags tocommitteesOutput: Set of committees C. Set of tags Twhere each t ?
T is assigned tocommittees in C.Phase I.
Finding set of clusters Lforeach ti ?
T doSelect a set k of n most similar tj : i 6= jadd k to L if it is not already in L.endPhase II.
Find Communities Cforeach c ?
L doFind the centroid of c using only qfeatures shared by most of tags in theclusterAdd c to C if its similarity to every othercluster is lower than ?endPhase III.
Assign tags to committeesforeach t ?
T doAssign t to committee c in C if thesimilarity is higher than ?endAlgorithm 1: Clustering tags using DSCBC45resented by its centroid.
Figure 1 shows an exam-ple folksonomy ontology.
The modified hierarchi-cal agglomerative clustering algorithm is shown inAlgorithm 2.SportChess Fitness SoccerFisher_genRussion_books66_games Iceland SpasskyGym_complexLoosing_weightPoolsTrade_mealsFigure 1: Example Folksonomy OntologyInput: Set of tags T. Set of Committees C.Output: An ontology of folksonomy tags.L is a list containing pairs of tag/clusters withassociated similarity, initially empty.foreach ti ?
T doCompute the similarity to all other tags tj(i 6= j), and add a pair ?ti, tj?
in L.endwhile L is not empty do1.
Sort L by the similarity of the pairs.2.
Pop the pair with the highest similarityfrom L. Let it ?ti, ??.
?
can be a singletag or a cluster of tags.3.
Make ti the parent of ?.4.
Join ti with ?, and create a new cluster?.if ti belongs to more than one committeein C then1.
Find the committee c which is themost similar to ti.2.
Remove all features intersectingwith c from ti.endelse1.
Substitute all instances of ti in thepairs in L by ?.endendAlgorithm 2: Ontology Construction Algorithm5 Experimental EvaluationsWe applied our proposed algorithm to data froma real-world social tagging system Delicious andderived a tag ontology.
Then we evaluated the de-rived ontology on two aspects: the density of theontology, and the usefulness of the ontology in apersonalized Information Retrieval (IR) task.
Notethat in the experiments, we determined the valuesfor all tuning coefficients in the algorithms duringthe preliminary test runs.5.1 DatasetsWe first crawled the Delicious site and ob-tained data consisting of 29,918 users, 6,403,442resources and 1,035,177 tags.
In this data,47,184,492 annotations were made by just oneuser, or for one resource, or by one tag.
This dis-tribution followed the Zipf?s law ?
small numbersof tags were in frequent use and large numbers oftags were rarely used.
Our intuitions were that theeffect of using the semantic/encyclopedia knowl-edge from Wikipedia would probably be better re-flected in the low frequency ?long tail?
part ofthe Zipf?s distribution rather than the high fre-quency part.
Likewise for users, we have dis-covered in our previous research that search per-sonalization algorithms often produce different re-sults for users with rich profiles and for users whohave sparse profiles.
This problem is known as the?Cold Start?
problem in search personalization: anew user has very little information/history in theprofile, therefore the system cannot reliably inferhis/her interests.
Since our experiments includeda personalized IR task, we decided to extract twosubsets from the data: one set containing high fre-quency tags assigned by users with rich profiles(randomly selected 1,000 most frequent tags en-tered by 100 high profile users), and another con-taining low frequency tags assigned by users withsparse profiles (randomly selected 1,000 least fre-quent tags entered by 100 sparse profile users).
Werefer to the former set as the ?Frequent Set?
andthe latter set as the ?Long Tail Set?.
The totalnumber of resources in each dataset was 16,635and 3,356 respectively.Then for both datasets, we applied a part-of speech tagger to all resources and extractedall nouns (and discarded all other parts ofspeech).
We also applied the Porter Stemmer(tartarus.org/?martin/PorterStemmer) to eliminate termswith inflectional variations.
Finally, we repre-46sented each resource page as a vector of stemmedterms, and the values were term frequencies.As for Wikipedia, we used its Englishversion available from BitTorrent Network(www.bittorrent.com).
The original data (the mostrecent dump, as of 24 July, 2008) contained13,916,311 pages.
In order to reduce the sizeto make the computation feasible, we randomlychose 75,000 pages (which contained at least 50words) and applied the Maximal Complete Linkclustering algorithm to further reduce the size.After clustering, we obtained a total of 43,876clusters, most of which contained one or twoWikiarticles, but some of which had several articles.We call such a Wiki article cluster Wiki concept.As with the tag datasets, for each Wiki articlewe applied the Porter Stemmer to reduce the num-ber of the terms.
Then we represented each Wikiconcept page as a vector of stemmed terms, andthe values were term frequencies.5.2 Evaluation 1: Ontological DensityFor the first evaluation, we evaluated the derivedDelicious tag ontology directly by measuring thetopological closeness of similar semantic conceptsin the ontology.
To that end, we developed a no-tion of ontological density: all tags assigned to aspecific resource should be located close to eachother in the ontology.
For instance, a web resourcejava.sun.com in Delicious is assigned with varioustags such as ?Java?, ?Programming?
and ?Technol-ogy?.
Those tags should be concentrated in oneplace rather than scattered over various sections inthe ontology.
By measuring the distance as thenumber of edges in the ontology between tags as-signed to a specific resource, we can obtain an es-timate of the ontology density for the resource.Then finding the average density of all resourcescan give us an approximation of the overall den-sity of the ontology?s quality.But here a difficulty arises for ambiguous tags?
when a tag is ambiguous and located in severalplaces in the ontology.
In those cases, we chosethe sense (an ontology node) which is the clos-est to the unambiguous tags assigned to the sameresource.
For example, Figure 2 shows a part ofthe ontology where an ambiguous tag ?NLP?
(withtwo senses) is mapped: 1) Natural Language Pro-cessing (the left one in the figure), and 2) Neuro-linguistic programming (the right one in the fig-ure).
The target web resource is tagged with threetags: two unambiguous tags ?POS?
and ?Porter?,and an ambiguous tag ?NLP?.
To identify the senseof ?NLP?
for this resource, we count the numberof edges from the two unambiguous tags (?POS?,?Porter?)
to both ?NLP?
tag nodes, and select theone which has the shortest distance.
In the figure,the first sense has the total distance of 4 (= 2 edgesfrom ?Pos?
+ 2 edges from ?Porter?
), while the sec-ond sense has the distance 10 (= 5 edges from?Pos?
+ 5 edges from ?Porter?).
Therefore, weselect the first sense (?Natural Language Process-ing?)
as the meaning of ?NLP?
for this resource.CommunicResearchPsychologyMindLinguisticsLanguageDictionaryNLPTwitterNLP POS PorterPOS Porter NLPWeb-resourceWeb2.0 MediaFigure 2: Example of Ambiguous Tags in the On-tologyFormally we define the density of the ontologyT for the set of resourcesR, denotedDens(T, R),as the average density over all resources in R, asfollows.Dens(T, R) = 1|R|?r?Rdensity(r, T )where density(r, T ) denotes the density for thegiven resource r for the ontology T , defined as:density(r, T ) = nTags(r) ?
1argmini,j dist(node(i, T ), node(j,T ))and nTags(r) is the number of tags assigned tor, node(k, T ) is the node in T for the kth tag (as-signed to r), and dist(n1, n2) is the number ofedges between nodes n1 and n2 in T .
So thedensity for the given resource is essentially theinverse of the minimum distance among the tagsassigned to it.
We computed the density valuefor the ontology derived by our approach (?On-tology Enhanced with Wiki Concepts?)
and com-pared with the ontologies obtained by using onlythe resources (where a tag vector is presented by47the stemmed terms in the resources to which thetag is assigned), and only the tags (where a tagvector is presented by the resource to which theywere assigned).
Figures 3 and 4 show the results,for the two datasets.
For both datasets, the dif-ferences between the three ontologies were statis-tically significant (at p=0.05), indicating that theencyclopedia knowledge obtained from Wikipediawas indeed effective in deriving a semanticallydense ontology.Here, one observation is that the relative im-provement was more significant for the ?FrequentSet?
than the ?Long Tail Set?.
The reason is be-cause frequent tags are generally more ambigu-ous than less frequent tags (as with words in gen-eral), therefore the effect of tag disambiguation byDSCBC was more salient, relatively, for the fre-quent tags.0,0350,0370,0390,0410,0430,045DensityOntology EnhancedwithWiki ConceptsOntology Enhancedby ResourcesOntology Basedon TagsFigure 3: Ontological Density for ?Frequent Set?Ontology Enhancedwith Wiki ConceptsOntology Enhancedby ResourcesOntology Basedon Tags0,10,050,150,20,250,3DensityFigure 4: Ontological Density for ?Long Tail Set?5.3 Evaluation 2: Personalized InformationRetrievalFor the second evaluation, we used the derived De-licious ontology in an IR task and measured itsutility.
In particular, we personalized the searchresults for a given user by utilizing the tag ontol-ogy as a way to present the user profile and inferhis/her information needs.Using the derived ontology, we search in the on-tology for the query tag entered by a specific user.We first match the ontology with the user?s profileand derive a score distribution for the nodes in thetree which reflects the user?s general interest.
Todo so, we take each tag in the user?s profile as theinitial activation point, then spread the activationup and down the ontology tree, for all tags.To spread activation from a given node, weuse two parameters: decay factor, which deter-mines the amount of the interest to be transferedto the parent/child of the current node; and damp-ing threshold - if the interest score becomes lessthan this value we stop further iteration.
Thus theresulting score distributionof the tree is effectivelypersonalized to the user?s general interest.Using the obtained score distribution of a givenuser, we search the tree for a query tag (of thisuser).
In the same way as the tags in the profile, wespread activation over the ontology from the nodeto which the tag belongs, but this time we add aweight to emphasize the relative importance of thequery tag compared to the tags from the profile,because the query reflects the user?s current infor-mation needs.
Finally we feed the preference vec-tor to the modified FolkRank algorithm (Hotho etal., 2006) to retrieve and rank the relevant web re-sources which reflect the user-specific preferences.Figure 5 shows the overall scheme of the person-alized ranked retrieval using an ontological userprofile.SportChess Fitness SoccerFisher_genRussion_books66_games Iceland SpasskyGym_complexLoosing_weightPoolsTrade_mealsSportChess Fitness SoccerFisher_genRussion_books66_games Iceland SpasskyGym_complexLoosing_weightPoolsTrade_mealsTnSpasskiy Loosing_weightUsersTagsPreference vectorRanked ResoursesResourses...User ProfilesSpreadingActivationFigure 5: Ranked Retrieval in Folksonomies usingOntological User ProfileWe evaluated the retrieval results by 5-foldcross validation.
Given a test user profile, we used48the leave-one-out method for tags ?
we removed atarget tag from the user profile and treated it as aquery.
All resources which the user assigned withthat tag was the relevant set.
For the final results,we computed the F-score, which is defined as stan-dard:F = 2 ?
Precision ?
RecallPrecision + RecallFigure 6 and 7 show the F-scores for the twodatasets.
Note that ?TopN?
indicates the top Nretrieved resources.
As you can see, the ontol-ogy enhanced with the Wiki concepts was able tobetter reflect the users?
interest and produced sig-nificant improvements compared to the ontologiesbuilt only with the Delicious resources.
Moreover,the improvements were much more significant forthe ?Long Tail Set?
than the ?Frequent Set?, asconsistent with our intuitions ?
Wikipedia?s en-cyclopedia knowledge helped enhance the infor-mation about the less-frequent tags (assigned bythe users with sparse profiles), thereby overcom-ing the ?Cold Start?
problem in search personal-ization.00 10 150,050,030,080,10,130,15TopNF-value20 25 30 35 40 45 50 60 65 70 75 80 85 90 95 10055OntologyEnhancedby ResourcesOntology Basedon TagsOntology Enhancedwith Wiki ConceptsFigure 6: F-score of the Ontology for ?FrequentSet?TopNOntology Enhancedby ResourcesOntology Basedon TagsOntology Enhancedwith Wiki Concepts00 10 150,10,050,150,20,250,30,350,40,450,520 25 30 35 40 45 50 60 65 70 75 80 85 90 95 10055F-valueFigure 7: F-score of the Ontology for ?Long TailSet?6 Conclusions and Future WorkIn this paper, we presented a novel method for dis-ambiguating tags and incorporating encyclopediaknowledge from Wikipedia in building folkson-omy ontologies for social tagging systems.
Weapplied our method to the data from Delicious andshowed that, not only was the derived ontology se-mantically more dense (i.e., similar tags/conceptsare clustered in close proximity), it also proved tobe very effective in a search personalization taskas well.For future work, we are planning on investigat-ing different ways of incorporating the link struc-tures of Wikipedia and web pages in the tag sim-ilarity function (in DSCBC).
Possible ideas in-clude adding different weights on various types oflinks (or links appearing in various sections of apage/article), and using distance in the reachabil-ity relation, for example using the work done inWikipedia Mining (Nakayama et al, 2008).Finally, we are planning on applying informa-tion extraction or summarization techniques onWikipedia articles to focus on sentences whichprovide relevant and important information aboutthe subject.ReferencesD.
Ahn, V. Jijkoun, G. Mishene, K. Muller, M. DeR-ijke, and S. Schlobach.
2004.
Using Wikipedia atthe TREC QA Track.
In Proceedings of the 13thText Retrieval Conference (TREC 2004).P.
Clough, H. Joho, and M. Sanderson.
2005.
Auto-matically Organizing Images Using Concept Hier-archies.
In Proceedings of the SIGIR Workshop onMultimedia Information Retrieval.A.
Culotta, A. Mccallum, and J.Betz.
2006.
Integrat-ing Probabilistic Extraction Models and Data Min-ing to Discover Relations and Patterns in Text.
InProceedings of the Human Language TechnologyConference.E.
Gabrilovich and S. Markovitch.
2006.
Over-coming the Brittleness Bottleneck UsingWikipedia:Enhancing Text Categorization with EncyclopedicKnowledge.
In Proceedings of the National Con-ference on Artificial Intelligence.I.
Gurevych, C. Muler, and T. Zesch.
2007.
What tobe?
- Electronic Career Guidance Based on Seman-tic Relatedness.
In Proceedings of the 45th AnnualMeeting of the Association for Computational Lin-guistics.P.
Heymann and H. Garcia-Molina.
2006.
Collab-orative Creation of Communal Hierarchical Tax-onomies in Social Tagging Systems.
Technical Re-port 2006-10, Computer Science Department, April.49A.
Hotho, R. Jaschke, C. Schmitz, and G. Stumme.2006.
Folkrank: A Ranking Algorithm for Folk-sonomies.
In Proceedings of the FGIR.R.
Mihalcea and A. Csomai.
2007.
Wikify!
: LinkingDocuments to Encyclopedic Knowledge.
In Pro-ceedings of the sixteenth ACM conference on Con-ference on information and knowledge management.P.
Mika.
2007.
Ontologies Are Us: A Unified Modelof Social Networks and Semantics.
Web Semantics:Science, Services and Agents on the World WideWeb, 5(1).G.
Miller.
1990.
WordNet: An Online LexicalDatabase.
International Journal of Lexicography,3(4).D.
Milne, O. Medelyan, and I. Witten.
2006.
MiningDomain-Specific Thesauri from Wikipedia: A CaseStudy.
In Proceedings of the 2006 IEEE/WIC/ACMInternational Conference on Web Intelligence.K.
Nakayama, T. Hara, and S. Nishio.
2008.Wikipedia Mining - Wikipedia as a Corpus forKnowledge Extraction.
In Proceedings of AnnualWikipedia Conference (Wikimania).M.
OConnor and J. Herlocker.
2001.
ClusteringItems for Collaborative Filtering.
In Proceedings ofSIGIR-2001 Workshop on Recommender Systems.P.
Pantel and D. Lin.
2002.
Discovering Word Sensesfrom Text.
In Proceedings of the 8th ACM Con-ference on Knowledge Discovery and Data Mining(KDD-02).P.
Schmitz.
2006.
Inducing Ontology From FlickrTags.
In Proceedings of the CollaborativeWeb Tag-ging Workshop (WWW 06).A.
Shepitsen, J. Gemmell, B. Mobasher, and R. Burke.2008.
Personalized Recommendation in Social Tag-ging Systems UsingHierarchical Clustering.
InPro-ceedings of the 2008 ACM conference on Recom-mender Systems.N.
Tomuro, S. Lytinen, K. Kanzaki, and H. Isahara.2007.
Clustering Using Feature Domain Similarityto Discover Word Senses for Adjectives.
In Pro-ceedings of the 1st IEEE International Conferenceon Semantic Computing (ICSC-2007).50
