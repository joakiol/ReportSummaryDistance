Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: System Demonstrations,pages 95?99, Dublin, Ireland, August 23-29 2014.What or Who is Multilingual Watson?Keith CortisIBM Irelandkeithcor@ie.ibm.comUrvesh BhowanIBM IrelandURVESHBH@ie.ibm.comRonan Mac an tSaoirIBM Irelandronan.mcateer@ie.ibm.comD.J.
McCloskeyIBM Irelanddj_mccloskey@ie.ibm.comMikhail SogrinIBM IrelandSOGRIMIK@ie.ibm.comRoss CadoganIBM IrelandROSSCADO@ie.ibm.comAbstractIBM Watson is an intelligent open-domain question answering system capable of an-swering questions posed in natural language.
However, the system originally developedto compete against human players on Jeopardy!
is heavily reliant on English languagecomponents, such as the English Slot Grammar parser, which impacts multilingual ex-tensibility and scalability.
This paper presents a working prototype for a multilingualWatson, introducing the major challenges encountered and their proposed solutions.1 IntroductionIBMWatson is an intelligent open-domain question answering (QA) system capable of answeringquestions posed in natural language (Ferrucci, 2012).
The open-domain QA problem is one ofthe most challenging in computer science and artificial intelligence, as it touches on aspects ofinformation retrieval, Natural Language Processing (NLP), knowledge representation, machinelearning and reasoning.
Since Jeopardy!
in 2011 (Ferrucci et al., 2010), Watson has been appliedsuccessfully to other domains, such as healthcare, finance and customer engagement.
However,like Jeopardy!, these application areas deal exclusively with English data.
The system is thereforeheavily reliant on English NLP components, in particular, the rule-based English Slot Grammar(ESG) parser used throughout.
While the ESG parser performs well and has limited multilingualcapabilities, the required grammar or slot rules are language-specific, impacting scalability anddeployment speed.
This paper presents some of the major challenges and proposed solutions toextend Watson to support any natural languag.
We introduce a robust cross-lingual method foridentifying crucial characteristics in a question (such as the Lexical Answer Type), which showssimilar expressiveness to the hand-crafted English-based implementation.
We outline a systemfor detecting the same named entities across text in multiple languages, and our current effortto train a multilingual Watson system using Wikipedia data for demonstration at Coling 2014.The demo setup and a brief discussion of results is also presented.2 Overview of Watson ArchitectureThis section presents an overview of the DeepQA architecture for multilingual Watson.
InQues-tion Analysis a detailed syntactic and semantic analysis is performed on the input question.Unstructured text is converted to structured information for use in later components.
This pro-cess uses a series of NLP technologies, such as a statistically trained natural language parser, andcomponents for named entity recognition, anaphora resolution and relation extraction.
The Lex-ical Answer Type and Focus are important examples, described later.
The Hypothesis Gen-eration phase produces all possible candidate answers for a given question.
Watson searchesits corpora for relevant content.
Example sources include unstructured knowledge, such asWikipedia and structured resources including DBpedia and PRISMATIC.
Potential answers tothe question are generated from the retrieved content as unscored hypotheses.
In SupportingEvidence Retrieval, the system gathers additional supporting evidence for each hypothesisby searching for occurrences of the candidate answer in the context of analysed question data.95Hypothesis and Evidence Scoring uses many scoring algorithms to determine the relevanceof retrieved candidate answers.
Each scorer, whether context dependent or independent, pro-duces a measure of how well the evidence supports a candidate answer for a question.
TheFinal Merging and Ranking phase merges equivalent candidate answers and uses a machinelearning model to rank the final merged set of answers accordingly.3 NLP and Parsing in Multilingual WatsonSyntactic parsing plays an important role throughout the major stages in Watson architecture,from question analysis, to primary search and answer scoring.
We aim to investigate the impactof deep syntactic parsing compared to shallow methods for named entities, temporal and geo-graphic references, etc.
It is thought that accurate determination of the roles these aspects playrequires a deeper analysis of sentence structure.
For example, in the original system, the ruleswhich detect the question focus and LAT are heavily dependent on the deep syntactical parse.Our experiments have show comparable results in this task with shallow methods.
However,in corpus ingestion aspects such as building syntactic frames in order to learn axioms, suchas ?is _a(liquid, fluid)?
and vice-versa, the subject-verb-object directionality of a statement isparamount.Watson uses the rule-based ESG parser (McCord et al., 2012), which performs exceptionallywell in terms of parse quality and throughput, and defines our parsing benchmark.
The XSGformalism underpinning ESG supports new languages through the generation of language-specificgrammar or slot rules.
This activity requires significant effort from highly skilled linguists foreach new language.
As the system further evolves for new domains and use-cases, such rulesmust be revised and extended, resulting in a long term requirement for this specialised skillset.To address this skill requirement and enable a more scalable approach, a move towards statisticalparsing methods is being investigated.
We identified the following attributes of our ideal parsingtechnology.
It should be multilingually capable, fast (compared to XSG, currently 2 orders ofmagnitude faster than current statistical parsers); highly accurate (comparable with XSG);easily extensible to new languages with low effort (relative to XSG); easy (and fast) to train ona new language or domain; memory efficient; robust to noisy/ungrammatical input; support arich set of annotation features (ESG has 70+); facilitate overriding of biases in training data.Our investigations indicate that meeting all of these requirements will be a challenge in anysingle parsing formalism.
Statistical dependency parsing allowing for non-projective trees ap-pears to be a good fit for the variation in language structure that we will need to support(McDonald et al., 2013).
Experiments with MSTParser and the Eisner algorithm in Italian haveshown promise from a quality point of view.
We have also identified a language-independent for-mal representation of a parse.
McDonald et al.
(2013) present a harmonized set of dependencylabels for multilingual parsing which has been adapted for other typologically diverse languages,such as Chinese and Finnish and encourages convergence for reuse.
Our initial investigationsusing this set for English, Spanish, French, Brazilian Portugese and German text, suggest min-imal modification is required to adapt for use in question answering.
Modification of existingpipeline components to a more streamlined dependency structure than the XSG formalism, willform part of ongoing research.Treebanks of parse data with part-of-speech and dependency labels will be required in orderto train the chosen parser.
There are several examples of existing Treebanks for the chosenlanguages, such as the IULA Spanish LSP Treebank1.
However, the context of the data includedis very rarely representative of question-answering scenarios.
For example, in the IULA corpus,there are less than 10 questions.
We will therefore be supplementing this training data withour own hand-annotated corpora, in order to increase the validity of the trained parser foruse in question answering.
As mentioned previously, we will also be adapting these resourcesto use the UniPos and UniDep part-of-speech and dependency label sets.
In parallel to the1http://www.iula.upf.edu/recurs01_tbk_uk.htm96investigations for multilingual parsing, we have also considered the requirements of a parser-independent system which can leverage shallow parse data in order to perform reasonably wellat the same task.
The multilingual LAT detection component which builds on part-of-speechdata to identify noun phrases and associated head words and modifiers, may be additionallyused to generate a simple linked parse structure without dependency labels.
As the number ofsupported languages in the system grows, it is important to have a meaningful baseline uponwhich to build, even while a parser or appropriate training data for the new language is stillbeing prepared.
The parser-independent capability will be particularly useful in this context.4 Other Challenges Faced in Multilingual Watson4.1 Multilingual Lexical Answer Type (LAT)For the Jeopardy!
challenge, one of the most critical elements in the system design was therecognition of what is termed the LAT (Ferrucci et al., 2010).
This is typically a noun ornoun-phrase in the question which identifies the type of answer required, without any attemptto evaluate its semantics.
Similarly influential, the Focus is the part of the sentence that, ifreplaced with the answer, makes the question a standalone statement.
For example, in thequestion ?What countries share a border with China?
?, the LAT is ?countries?, and the Focusis ?What countries?.
Replacing this piece of text with the answer becomes a valid standalonestatement, such as ?Russia, Mongolia, India, .
.
.
, share a border with China?.
Ferrucci et al.
(2010) found that identifying a candidate answer as an instance of a LAT is an important partof the answer scoring mechanism, and a common source of critical errors.In the original system, a Prolog component was used to match specific English languagepatterns for various purposes including LAT detection.
In a multilingual context, we require amore robust method that retains the same potential expressiveness and performance of a goodProlog implementation, while facilitating cross-lingual pattern recognition.
Our multilingualprototype uses lexical features, such as part-of-speech and lemma.
Pattern matching rulesover these features were developed using the IBM LanguageWare2rules engine which providesa comparable level of expression with standard Prolog implementations.
While maintainingpipeline accuracy for English, this prototype was also 4 times faster than the original Prologmodules.
A statistical method that was originally used in the Jeopardy!
pipeline is also beingadapted for use in a multilingual context.
This approach will reduce the dependency on hard-coded language-specific parsing rules.
The use of harmonized Stanford dependencies (McDonaldet al., 2013) will further enhance these efforts.4.2 Detecting Concepts across Multiple LanguagesOne of the most challenging aspects of multilingual NLP is the recognition of identical conceptsacross text in multiple languages.
Wikipedia and Wiktionary provide translations of wordsfrom one language to another, however they do not establish language-independent identifiersfor concepts.
Open Multilingual Wordnet (OMW) project3links WordNet style structuredresources, in up to 150 languages, to the Princeton Wordnet of English4.
While PrincetonWordnet is made specifically for English, its numeric ID system is in fact a set of language-independent identifiers, and may be used to relate concepts and words.
The OMW projectprovides links to the same IDs from words in other languages.
The Extended version of theOMW dataset additionally links Wiktionary data with these WordNet structured resources,thus greatly improving coverage of vocabulary.In the multilingual Watson system, we can perform semantic analysis using domain knowledgeirrespective of the language of the question, or the domain.
This is enabled by a process ofconcept identification that maps instances of concepts in natural language text to a set of2http://www-01.ibm.com/software/globalization/topics/languageware/3http://compling.hss.ntu.edu.sg/omw/4http://wordnet.princeton.edu/97language-independent identifiers.
Our implementation takes inspiration from efforts, such asthe OMW and the Unstructured Medical Language System5in the biomedical domain, whichuse alphanumeric labels to identify individual semantic concepts, irrespective of the forms theseconcepts take in any language.
In addition to these unique identifiers, our design incorporatesfully qualified URI namespaces for these instances, as proposed by the W3C Semantic WebStandard, in order to distinguish between instances of a concept in various contexts.In parallel with this concept ID system, we have developed a lexicon expansion frameworkthat incorporates pluggable transformation modules to generate alternative forms for lexiconentries.
This facilitates the increased coverage of semantic concepts in the chosen domain text,which remain linked to their respective namespace-qualified unique identifiers.4.3 Machine Learning ChallengesThe original Watson system uses a cascade of multiple trained machine-learning models todecide if a candidate answer is correct.
In each cascade, questions are categorised and routed tomodels trained for different types of English Jeopardy!
questions.
Training these models requiresquestions with known answers for the different question types.
However, the same Jeopardy!style question characteristics may not apply or be evident in different languages.
To addressthis, we simplified the hand-crafted model routing in the multilingual system to make no apriori assumptions about the question type.
While this requires good model generalisation overa potentially broad range of questions, this is offset by the smaller but highly-focused feature setused in this multilingual system.
Initial features were chosen by ranking scorers whose outputshowed the highest correlation to the correct class on experiments with English questions.5 Multilingual Watson on Wikipedia-based Questions5.1 Searching over WikipediaIngestion is the process of transforming documents for use by Watson.
Raw Wikipedia XMLdocuments6are transformed into the TREC standard7.
These TREC files must conform tothe UTF-8 character encoding scheme.
The TREC-formatted documents are then transformedinto Lucene8search indices.
During the TREC transformation process, text normalisation andcharacter replacement was being conducted for English text.
All corpora text in Unicode wasnormalised to ASCII, e.g., for the term Jap?n, the accent was stripped from the ?
character,thus normalising to Japon.
In addition, characters with particular ISO8859 codes, were replaced,such as pi with the character n. Since the Jeopardy!
pipeline handles only ASCII characterencoding, this prevents the system from generating correct answers which contain non-ASCIIcharacters, dramatically lowering recall on multilingual questions.
These issues are resolved inthe multilingual Watson system, which uses Unicode in the Normalisation Form CompatibilityComposition.5.2 Wikipedia-based Questions and AnswersWe used 3732 English questions with known answers (originally gathered by the Watson team) asour question base (split into 3359 training and 373 test questions).
These questions were machinetranslated to Spanish, French and Brazilian Portugese using IBM?s n.Fluent Translation service9.
The test set was manually reviewed to correct any translation errors, and questions deemedunanswerable (where Watson had no means of retrieving the correct answer from the sourceWikipedia corpus) were removed.
To assist in identifying which questions are unanswerable,the MediaWiki API10(an open web API service providing access to Wikipedia meta-data) was5http://www.nlm.nih.gov/research/umls/6Obtained from: http://dumps.wikimedia.org/7For the Text REtrieval Conference (TREC) standard see: http://trec.nist.gov/8http://lucene.apache.org/9http://www-03.ibm.com/press/us/en/pressrelease/28887.wss10http://www.mediawiki.org/wiki/API98used to filter questions whose answers could not be mapped to an article title in the Wikipediasource corpus.The MediaWiki API also has a cross-language aspect which provides useful redirectinformation between Wikipedia article titles, which we used to supplement our answers, e.g.,?JFK?
in English redirects to ?John F. Kennedy?
in Spanish.
The manual curation of thetranslated English questions for English, Spanish, French and Brazilian Portuguese ensure thatthe same question set is used across the different languages, and that these common questionsare all answerable with respect to their respective Wikipedia corpus.6 Demo Setup and Discussion of ResultsThe setup of the demo will include a multilingual QA system (for several languages, such asEnglish, Spanish, French, Brazilian Portuguese, etc.).
The participants attending the Colingconference will be able to ask the multilingual Watson QA system a question via its web userinterface.
The system will then attempt to answer the question in real-time, and will return alist of the five top-ranked candidate answers and their confidence scores.
The confidence scorefor each candidate answer represents the likeliness that it is correct, based on the analysis of allsupporting evidence gathered by the system.
Any supporting evidence can also be examined fora given answer, such as the passage or document hits from the search process.For disclosure purposes we are unable to provide details on our multilingual experimentalresults.
Therefore, we will briefly discuss our initial baseline results and the improvementsmade in our current system.
Our initial baseline is based on the results using the English testquestions, which achieved very high (near perfect) recall and high accuracy rates.
In terms ofmultilingual Watson, our initial recall results were very low compared to English.
As a result,recall became the primary focus of our multilingual investigation.
Recall was improved by around6% with the full Unicode text normalisation support and parser-independent changes (discussedin Sections 3 and 5.1 respectively).
In addition, the answer curation discussed in Section 5.2improved recall by 9%.
Other language specific improvements and customisation to the primarysearch components in multilingual Watson, in particular, the Lucene analyser and search query,resulted in a further 29% increase in recall.
These combined efforts produced comparable recallrates for Spanish, French and Brazilian Portuguese test questions to the English questions.
Thenext area of our investigation will be focused on accuracy improvements.ReferencesDavid A. Ferrucci, Eric W. Brown, Jennifer Chu-Carroll, James Fan, David Gondek, Aditya Kalyanpur,Adam Lally, J. William Murdock, Eric Nyberg, John M. Prager, Nico Schlaefer, and Christopher A.Welty.
2010.
Building Watson: An Overview of the DeepQA Project.
AI Magazine, 31(3):59?79.David A. Ferrucci.
2012.
Introduction to "this is watson".
IBM Journal of Research and Development,56(3):235?249.Michael C. McCord, J. William Murdock, and Branimir Boguraev.
2012.
Deep parsing in watson.
IBMJournal of Research and Development, 56(3):3.Ryan T. McDonald, Joakim Nivre, Yvonne Quirmbach-Brundage, Yoav Goldberg, Dipanjan Das, KuzmanGanchev, Keith B.
Hall, Slav Petrov, Hao Zhang, Oscar T?ckstr?m, Claudia Bedini, N?ria BertomeuCastell?, and Jungmee Lee.
2013.
Universal dependency annotation for multilingual parsing.
In ACL(2), pages 92?97.
The Association for Computer Linguistics.99
