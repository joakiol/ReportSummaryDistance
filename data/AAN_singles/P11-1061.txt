Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 600?609,Portland, Oregon, June 19-24, 2011. c?2011 Association for Computational LinguisticsUnsupervised Part-of-Speech Taggingwith Bilingual Graph-Based ProjectionsDipanjan Das?Carnegie Mellon UniversityPittsburgh, PA 15213, USAdipanjan@cs.cmu.eduSlav PetrovGoogle ResearchNew York, NY 10011, USAslav@google.comAbstractWe describe a novel approach for inducingunsupervised part-of-speech taggers for lan-guages that have no labeled training data, buthave translated text in a resource-rich lan-guage.
Our method does not assume anyknowledge about the target language (in par-ticular no tagging dictionary is assumed),making it applicable to a wide array ofresource-poor languages.
We use graph-basedlabel propagation for cross-lingual knowl-edge transfer and use the projected labelsas features in an unsupervised model (Berg-Kirkpatrick et al, 2010).
Across eight Eu-ropean languages, our approach results in anaverage absolute improvement of 10.4% overa state-of-the-art baseline, and 16.7% overvanilla hidden Markov models induced withthe Expectation Maximization algorithm.1 IntroductionSupervised learning approaches have advanced thestate-of-the-art on a variety of tasks in natural lan-guage processing, resulting in highly accurate sys-tems.
Supervised part-of-speech (POS) taggers,for example, approach the level of inter-annotatoragreement (Shen et al, 2007, 97.3% accuracy forEnglish).
However, supervised methods rely on la-beled training data, which is time-consuming andexpensive to generate.
Unsupervised learning ap-proaches appear to be a natural solution to this prob-lem, as they require only unannotated text for train-?This research was carried out during an internship at GoogleResearch.ing models.
Unfortunately, the best completely un-supervised English POS tagger (that does not makeuse of a tagging dictionary) reaches only 76.1% ac-curacy (Christodoulopoulos et al, 2010), making itspractical usability questionable at best.To bridge this gap, we consider a practically mo-tivated scenario, in which we want to leverage ex-isting resources from a resource-rich language (likeEnglish) when building tools for resource-poor for-eign languages.1 We assume that absolutely no la-beled training data is available for the foreign lan-guage of interest, but that we have access to paralleldata with a resource-rich language.
This scenario isapplicable to a large set of languages and has beenconsidered by a number of authors in the past (Al-shawi et al, 2000; Xi and Hwa, 2005; Ganchev etal., 2009).
Naseem et al (2009) and Snyder et al(2009) study related but different multilingual gram-mar and tagger induction tasks, where it is assumedthat no labeled data at all is available.Our work is closest to that of Yarowsky and Ngai(2001), but differs in two important ways.
First,we use a novel graph-based framework for project-ing syntactic information across language bound-aries.
To this end, we construct a bilingual graphover word types to establish a connection betweenthe two languages (?3), and then use graph labelpropagation to project syntactic information fromEnglish to the foreign language (?4).
Second, wetreat the projected labels as features in an unsuper-1For simplicity of exposition we refer to the resource-poor lan-guage as the ?foreign language.?
Similarly, we use Englishas the resource-rich language, but any other language with la-beled resources could be used instead.600vised model (?5), rather than using them directly forsupervised training.
To make the projection practi-cal, we rely on the twelve universal part-of-speechtags of Petrov et al (2011).
Syntactic universals area well studied concept in linguistics (Carnie, 2002;Newmeyer, 2005), and were recently used in similarform by Naseem et al (2010) for multilingual gram-mar induction.
Because there might be some contro-versy about the exact definitions of such universals,this set of coarse-grained POS categories is definedoperationally, by collapsing language (or treebank)specific distinctions to a set of categories that ex-ists across all languages.
These universal POS cat-egories not only facilitate the transfer of POS in-formation from one language to another, but alsorelieve us from using controversial evaluation met-rics,2 by establishing a direct correspondence be-tween the induced hidden states in the foreign lan-guage and the observed English labels.We evaluate our approach on eight European lan-guages (?6), and show that both our contributionsprovide consistent and statistically significant im-provements.
Our final average POS tagging accu-racy of 83.4% compares very favorably to the av-erage accuracy of Berg-Kirkpatrick et al?s mono-lingual unsupervised state-of-the-art model (73.0%),and considerably bridges the gap to fully supervisedPOS tagging performance (96.6%).2 Approach OverviewThe focus of this work is on building POS taggersfor foreign languages, assuming that we have an En-glish POS tagger and some parallel text betweenthe two languages.
Central to our approach (seeAlgorithm 1) is a bilingual similarity graph builtfrom a sentence-aligned parallel corpus.
As dis-cussed in more detail in ?3, we use two types ofvertices in our graph: on the foreign language sidevertices correspond to trigram types, while the ver-tices on the English side are individual word types.Graph construction does not require any labeleddata, but makes use of two similarity functions.
Theedge weights between the foreign language trigramsare computed using a co-occurence based similar-ity function, designed to indicate how syntactically2See Christodoulopoulos et al (2010) for a discussion of met-rics for evaluating unsupervised POS induction systems.Algorithm 1 Bilingual POS InductionRequire: Parallel English and foreign languagedata De and Df , unlabeled foreign training data?f ; English tagger.Ensure: ?f , a set of parameters learned using aconstrained unsupervised model (?5).1: De?f ?
word-align-bitext(De,Df )2: D?e ?
pos-tag-supervised(De)3: A ?
extract-alignments(De?f , D?e)4: G?
construct-graph(?f ,Df ,A)5: G??
graph-propagate(G)6: ??
extract-word-constraints(G?
)7: ?f ?
pos-induce-constrained(?f ,?
)8: Return ?fsimilar the middle words of the connected trigramsare (?3.2).
To establish a soft correspondence be-tween the two languages, we use a second similar-ity function, which leverages standard unsupervisedword alignment statistics (?3.3).3Since we have no labeled foreign data, our goalis to project syntactic information from the Englishside to the foreign side.
To initialize the graph wetag the English side of the parallel text using a su-pervised model.
By aggregating the POS labels ofthe English tokens to types, we can generate labeldistributions for the English vertices.
Label propa-gation can then be used to transfer the labels to theperipheral foreign vertices (i.e.
the ones adjacent tothe English vertices) first, and then among all of theforeign vertices (?4).
The POS distributions over theforeign trigram types are used as features to learn abetter unsupervised POS tagger (?5).
The follow-ing three sections elaborate these different stages ismore detail.3 Graph ConstructionIn graph-based learning approaches one constructsa graph whose vertices are labeled and unlabeledexamples, and whose weighted edges encode thedegree to which the examples they link have thesame label (Zhu et al, 2003).
Graph constructionfor structured prediction problems such as POS tag-ging is non-trivial: on the one hand, using individ-ual words as the vertices throws away the context3The word alignment methods do not use POS information.601necessary for disambiguation; on the other hand,it is unclear how to define (sequence) similarity ifthe vertices correspond to entire sentences.
Altunet al (2005) proposed a technique that uses graphbased similarity between labeled and unlabeled partsof structured data in a discriminative framework forsemi-supervised learning.
More recently, Subra-manya et al (2010) defined a graph over the cliquesin an underlying structured prediction model.
Theyconsidered a semi-supervised POS tagging scenarioand showed that one can use a graph over trigramtypes, and edge weights based on distributional sim-ilarity, to improve a supervised conditional randomfield tagger.3.1 Graph VerticesWe extend Subramanya et al?s intuitions to ourbilingual setup.
Because the information flow inour graph is asymmetric (from English to the foreignlanguage), we use different types of vertices for eachlanguage.
The foreign language vertices (denoted byVf ) correspond to foreign trigram types, exactly asin Subramanya et al (2010).
On the English side,however, the vertices (denoted by Ve) correspond toword types.
Because all English vertices are goingto be labeled, we do not need to disambiguate themby embedding them in trigrams.
Furthermore, we donot connect the English vertices to each other, butonly to foreign language vertices.4The graph vertices are extracted from the differ-ent sides of a parallel corpus (De, Df ) and an ad-ditional unlabeled monolingual foreign corpus ?f ,which will be used later for training.
We use two dif-ferent similarity functions to define the edge weightsamong the foreign vertices and between verticesfrom different languages.3.2 Monolingual Similarity FunctionOur monolingual similarity function (for connectingpairs of foreign trigram types) is the same as the oneused by Subramanya et al (2010).
We briefly re-view it here for completeness.
We define a sym-metric similarity function K(ui, uj) over two for-4This is because we are primarily interested in learning foreignlanguage taggers, rather than improving supervised Englishtaggers.
Note, however, that it would be possible to use ourgraph-based framework also for completely unsupervised POSinduction in both languages, similar to Snyder et al (2009).Description FeatureTrigram + Context x1 x2 x3 x4 x5Trigram x2 x3 x4Left Context x1 x2Right Context x4 x5Center Word x3Trigram ?
Center Word x2 x4Left Word + Right Context x2 x4 x5Left Context + Right Word x1 x2 x4Suffix HasSuffix(x3)Table 1: Various features used for computing edgeweights between foreign trigram types.eign language vertices ui, uj ?
Vf based on theco-occurrence statistics of the nine feature conceptsgiven in Table 1.
Each feature concept is akin to arandom variable and its occurrence in the text corre-sponds to a particular instantiation of that randomvariable.
For each trigram type x2 x3 x4 in a se-quence x1 x2 x3 x4 x5, we count how many timesthat trigram type co-occurs with the different instan-tiations of each concept, and compute the point-wisemutual information (PMI) between the two.5 Thesimilarity between two trigram types is given bysumming over the PMI values over feature instan-tiations that they have in common.
This is similar tostacking the different feature instantiations into long(sparse) vectors and computing the cosine similaritybetween them.
Finally, note that while most featureconcepts are lexicalized, others, such as the suffixconcept, are not.Given this similarity function, we define a near-est neighbor graph, where the edge weight for the nmost similar vertices is set to the value of the simi-larity function and to 0 for all other vertices.
We useN (u) to denote the neighborhood of vertex u, andfixed n = 5 in our experiments.3.3 Bilingual Similarity FunctionTo define a similarity function between the Englishand the foreign vertices, we rely on high-confidenceword alignments.
Since our graph is built from aparallel corpus, we can use standard word align-ment techniques to align the English sentences De5Note that many combinations are impossible giving a PMIvalue of 0; e.g., when the trigram type and the feature instanti-ation don?t have words in common.602and their foreign language translations Df .6 Labelpropagation in the graph will provide coverage andhigh recall, and we therefore extract only intersectedhigh-confidence (> 0.9) alignments De?f .Based on these high-confidence alignments wecan extract tuples of the form [u ?
v], where u isa foreign trigram type, whose middle word alignsto an English word type v. Our bilingual similarityfunction then sets the edge weights in proportion tothese tuple counts.3.4 Graph InitializationSo far the graph has been completely unlabeled.
Toinitialize the graph for label propagation we use a su-pervised English tagger to label the English side ofthe bitext.7 We then simply count the individual la-bels of the English tokens and normalize the countsto produce tag distributions over English word types.These tag distributions are used to initialize the labeldistributions over the English vertices in the graph.Note that since all English vertices were extractedfrom the parallel text, we will have an initial labeldistribution for all vertices in Ve.3.5 Graph ExampleA very small excerpt from an Italian-English graphis shown in Figure 1.
As one can see, only thetrigrams [suo incarceramento ,], [suo iter ,] and[suo carattere ,] are connected to English words.
Inthis particular case, all English vertices are labeledas nouns by the supervised tagger.
In general, theneighborhoods can be more diverse and we allow asoft label distribution over the vertices.
It is worthnoting that the middle words of the Italian trigramsare nouns too, which exhibits the fact that the sim-ilarity metric connects types having the same syn-tactic category.
In the label propagation stage, wepropagate the automatic English tags to the alignedItalian trigram types, followed by further propaga-tion solely among the Italian vertices.6We ran six iterations of IBM Model 1 (Brown et al, 1993),followed by six iterations of the HMM model (Vogel et al,1996) in both directions.7We used a tagger based on a trigram Markov model (Brants,2000) trained on the Wall Street Journal portion of the PennTreebank (Marcus et al, 1993), for its fast speed and reason-able accuracy (96.7% on sections 22-24 of the treebank, butpresumably much lower on the (out-of-domain) parallel cor-pus).
[ suo iter , ][ suo incarceramento , ][ suo fidanzato , ][ suo carattere , ][ imprisonment ][ enactment ][ character ][ del fidanzato , ][ il fidanzato , ]NOUNNOUNNOUN[ al fidanzato e ]Figure 1: An excerpt from the graph for Italian.
Three ofthe Italian vertices are connected to an automatically la-beled English vertex.
Label propagation is used to propa-gate these tags inwards and results in tag distributions forthe middle word of each Italian trigram.4 POS ProjectionGiven the bilingual graph described in the previoussection, we can use label propagation to project theEnglish POS labels to the foreign language.
We uselabel propagation in two stages to generate soft la-bels on all the vertices in the graph.
In the first stage,we run a single step of label propagation, whichtransfers the label distributions from the Englishvertices to the connected foreign language vertices(say, V lf ) at the periphery of the graph.
Note thatbecause we extracted only high-confidence align-ments, many foreign vertices will not be connectedto any English vertices.
This stage of label propa-gation results in a tag distribution ri over labels y,which encodes the proportion of times the middleword of ui ?
Vf aligns to English words vy taggedwith label y:ri(y) =?vy#[ui ?
vy]?y?
?vy?#[ui ?
vy?
](1)The second stage consists of running traditionallabel propagation to propagate labels from these pe-ripheral vertices V lf to all foreign language vertices603in the graph, optimizing the following objective:C(q) =?ui?Vf\V lf ,uj?N (ui)wij?qi ?
qj?2+ ?
?ui?Vf\V lf?qi ?
U?2s.t.
?yqi(y) = 1 ?uiqi(y) ?
0 ?ui, yqi = ri ?ui ?
Vlf (2)where the qi (i = 1, .
.
.
, |Vf |) are the label distribu-tions over the foreign language vertices and ?
and?
are hyperparameters that we discuss in ?6.4.
Weuse a squared loss to penalize neighboring verticesthat have different label distributions: ?qi ?
qj?2 =?y(qi(y)?qj(y))2, and additionally regularize thelabel distributions towards the uniform distributionU over all possible labels Y .
It can be shown thatthis objective is convex in q.The first term in the objective function is the graphsmoothness regularizer which encourages the distri-butions of similar vertices (large wij) to be similar.The second term is a regularizer and encourages alltype marginals to be uniform to the extent that is al-lowed by the first two terms (cf.
maximum entropyprinciple).
If an unlabeled vertex does not have apath to any labeled vertex, this term ensures that theconverged marginal for this vertex will be uniformover all tags, allowing the middle word of such anunlabeled vertex to take on any of the possible tags.While it is possible to derive a closed form so-lution for this convex objective function, it wouldrequire the inversion of a matrix of order |Vf |.
In-stead, we resort to an iterative update based method.We formulate the update as follows:q(m)i (y) =??
?ri(y) if ui ?
V lf?i(y)?iotherwise(3)where ?ui ?
Vf \ V lf , ?i(y) and ?i are defined as:?i(y) =?uj?N (ui)wijq(m?1)j (y) + ?
U(y) (4)?i = ?
+?uj?N (ui)wij (5)We ran this procedure for 10 iterations.5 POS InductionAfter running label propagation (LP), we com-pute tag probabilities for foreign word types x bymarginalizing the POS tag distributions of foreigntrigrams ui = x?
x x+ over the left and right con-text words:p(y|x) =?x?,x+qi(y)?x?,x+,y?qi(y?
)(6)We then extract a set of possible tags tx(y) by elimi-nating labels whose probability is below a thresholdvalue ?
:tx(y) ={1 if p(y|x) ?
?0 otherwise(7)We describe how we choose ?
in ?6.4.
This vectortx is constructed for every word in the foreign vo-cabulary and will be used to provide features for theunsupervised foreign language POS tagger.We develop our POS induction model based onthe feature-based HMM of Berg-Kirkpatrick et al(2010).
For a sentence x and a state sequence z, afirst order Markov model defines a distribution:P?
(X = x,Z = z) = P?
(Z1 = z1)?
?|x|i=1 P?
(Zi+1 = zi+1 | Zi = zi)?
??
?transition?P?
(Xi = xi | Zi = zi)?
??
?emission(8)In a traditional Markov model, the emission distri-bution P?
(Xi = xi | Zi = zi) is a set of multinomi-als.
The feature-based model replaces the emissiondistribution with a log-linear model, such that:P?
(X = x | Z = z) =exp ?>f(x, z)?x?
?Val(X)exp ?>f(x?, z)(9)where Val(X) corresponds to the entire vocabulary.This locally normalized log-linear model can look atvarious aspects of the observation x, incorporatingoverlapping features of the observation.
In our ex-periments, we used the same set of features as Berg-Kirkpatrick et al (2010): an indicator feature based604on the word identity x, features checking whether xcontains digits or hyphens, whether the first letter ofx is upper case, and suffix features up to length 3.All features were conjoined with the state z.We trained this model by optimizing the followingobjective function:L(?)
=N?i=1log?zP?
(X = x(i),Z = z(i))?C??
?22 (10)Note that this involves marginalizing out all possiblestate configurations z for a sentence x, resulting ina non-convex objective.
To optimize this function,we used L-BFGS, a quasi-Newton method (Liu andNocedal, 1989).
For English POS tagging, Berg-Kirkpatrick et al (2010) found that this direct gra-dient method performed better (>7% absolute ac-curacy) than using a feature-enhanced modificationof the Expectation-Maximization (EM) algorithm(Dempster et al, 1977).8 Moreover, this route ofoptimization outperformed a vanilla HMM trainedwith EM by 12%.We adopted this state-of-the-art model because itmakes it easy to experiment with various ways ofincorporating our novel constraint feature into thelog-linear emission model.
This feature ft incor-porates information from the smoothed graph andprunes hidden states that are inconsistent with thethresholded vector tx.
The function ?
: F ?
Cmaps from the language specific fine-grained tagsetF to the coarser universal tagset C and is describedin detail in ?6.2:ft(x, z) = log(tx(y)), if ?
(z) = y (11)Note that when tx(y) = 1 the feature value is 0and has no effect on the model, while its value is??
when tx(y) = 0 and constrains the HMM?sstate space.
This formulation of the constraint fea-ture is equivalent to the use of a tagging dictionaryextracted from the graph using a threshold ?
on theposterior distribution of tags for a given word type(Eq.
7).
It would have therefore also been possible touse the integer programming (IP) based approach of8See ?3.1 of Berg-Kirkpatrick et al (2010) for more detailsabout their modification of EM, and how gradients are com-puted for L-BFGS.Ravi and Knight (2009) instead of the feature-HMMfor POS induction on the foreign side.
However, wedo not explore this possibility in the current work.6 Experiments and ResultsBefore presenting our results, we describe thedatasets that we used, as well as two baselines.6.1 DatasetsWe utilized two kinds of datasets in our experiments:(i) monolingual treebanks9 and (ii) large amounts ofparallel text with English on one side.
The availabil-ity of these resources guided our selection of foreignlanguages.
For monolingual treebank data we re-lied on the CoNLL-X and CoNLL-2007 shared taskson dependency parsing (Buchholz and Marsi, 2006;Nivre et al, 2007).
The parallel data came from theEuroparl corpus (Koehn, 2005) and the ODS UnitedNations dataset (UN, 2006).
Taking the intersectionof languages in these resources, and selecting lan-guages with large amounts of parallel data, yieldsthe following set of eight Indo-European languages:Danish, Dutch, German, Greek, Italian, Portuguese,Spanish and Swedish.Of course, we are primarily interested in apply-ing our techniques to languages for which no la-beled resources are available.
However, we neededto restrict ourselves to these languages in order tobe able to evaluate the performance of our approach.We paid particular attention to minimize the numberof free parameters, and used the same hyperparam-eters for all language pairs, rather than attemptinglanguage-specific tuning.
We hope that this will al-low practitioners to apply our approach directly tolanguages for which no resources are available.6.2 Part-of-Speech Tagset and HMM StatesWe use the universal POS tagset of Petrov et al(2011) in our experiments.10 This set C consistsof the following 12 coarse-grained tags: NOUN(nouns), VERB (verbs), ADJ (adjectives), ADV(adverbs), PRON (pronouns), DET (determiners),ADP (prepositions or postpositions), NUM (numer-als), CONJ (conjunctions), PRT (particles), PUNC9We extracted only the words and their POS tags from the tree-banks.10Available at http://code.google.com/p/universal-pos-tags/.605(punctuation marks) and X (a catch-all for othercategories such as abbreviations or foreign words).While there might be some controversy about theexact definition of such a tagset, these 12 categoriescover the most frequent part-of-speech and exist inone form or another in all of the languages that westudied.For each language under consideration, Petrov etal.
(2011) provide a mapping ?
from the fine-grainedlanguage specific POS tags in the foreign treebankto the universal POS tags.
The supervised POS tag-ging accuracies (on this tagset) are shown in the lastrow of Table 2.
The taggers were trained on datasetslabeled with the universal tags.The number of latent HMM states for each lan-guage in our experiments was set to the number offine tags in the language?s treebank.
In other words,the set of hidden states F was chosen to be the fineset of treebank tags.
Therefore, the number of finetags varied across languages for our experiments;however, one could as well have fixed the set ofHMM states to be a constant across languages, andcreated one mapping to the universal POS tagset.6.3 Various ModelsTo provide a thorough analysis, we evaluated threebaselines and two oracles in addition to two variantsof our graph-based approach.
We were intentionallylenient with our baselines:?
EM-HMM: A traditional HMM baseline, withmultinomial emission and transition distribu-tions estimated by the Expectation Maximiza-tion algorithm.
We evaluated POS tagging ac-curacy using the lenient many-to-1 evaluationapproach (Johnson, 2007).?
Feature-HMM: The vanilla feature-HMM ofBerg-Kirkpatrick et al (2010) (i.e.
no ad-ditional constraint feature) served as a sec-ond baseline.
Model parameters were esti-mated with L-BFGS and evaluation again useda greedy many-to-1 mapping.?
Projection: Our third baseline incorporatesbilingual information by projecting POS tagsdirectly across alignments in the parallel data.For unaligned words, we set the tag to the mostfrequent tag in the corresponding treebank.
Foreach language, we took the same number ofsentences from the bitext as there are in its tree-bank, and trained a supervised feature-HMM.This can be seen as a rough approximation ofYarowsky and Ngai (2001).We tried two versions of our graph-based approach:?
No LP: Our first version takes advantage ofour bilingual graph, but extracts the constraintfeature after the first stage of label propagation(Eq.
1).
Because many foreign word types arenot aligned to an English word (see Table 3),and we do not run label propagation on the for-eign side, we expect the projected informationto have less coverage.
Furthermore we expectthe label distributions on the foreign to be fairlynoisy, because the graph constraints have notbeen taken into account yet.?
With LP: Our full model uses both stagesof label propagation (Eq.
2) before extractingthe constraint features.
As a result, we areable to extract the constraint feature for all for-eign word types and furthermore expect theprojected tag distributions to be smoother andmore stable.Our oracles took advantage of the labeled treebanks:?
TB Dictionary: We extracted tagging dictio-naries from the treebanks and and used them asconstraint features in the feature-based HMM.Evaluation was done using the prespecifiedmappings.?
Supervised: We trained the supervised modelof Brants (2000) on the original treebanks andmapped the language-specific tags to the uni-versal tags for evaluation.6.4 Experimental SetupWhile we tried to minimize the number of free pa-rameters in our model, there are a few hyperparam-eters that need to be set.
Fortunately, performancewas stable across various values, and we were ableto use the same hyperparameters for all languages.We used C = 1.0 as the L2 regularization con-stant in (Eq.
10) and trained both EM and L-BFGSfor 1000 iterations.
When extracting the vector606Model Danish Dutch German Greek Italian Portuguese Spanish Swedish AvgbaselinesEM-HMM 68.7 57.0 75.9 65.8 63.7 62.9 71.5 68.4 66.7Feature-HMM 69.1 65.1 81.3 71.8 68.1 78.4 80.2 70.1 73.0Projection 73.6 77.0 83.2 79.3 79.7 82.6 80.1 74.7 78.8our approachNo LP 79.0 78.8 82.4 76.3 84.8 87.0 82.8 79.4 81.3With LP 83.2 79.5 82.8 82.5 86.8 87.9 84.2 80.5 83.4oraclesTB Dictionary 93.1 94.7 93.5 96.6 96.4 94.0 95.8 85.5 93.7Supervised 96.9 94.9 98.2 97.8 95.8 97.2 96.8 94.8 96.6Table 2: Part-of-speech tagging accuracies for various baselines and oracles, as well as our approach.
?Avg?
denotesmacro-average across the eight languages.tx used to compute the constraint feature from thegraph, we tried three threshold values for ?
(seeEq.
7).
Because we don?t have a separate develop-ment set, we used the training set to select amongthem and found 0.2 to work slightly better than 0.1and 0.3.
For seven out of eight languages a thresh-old of 0.2 gave the best results for our final model,which indicates that for languages without any val-idation set, ?
= 0.2 can be used.
For graph prop-agation, the hyperparameter ?
was set to 2 ?
10?6and was not tuned.
The graph was constructed using2 million trigrams; we chose these by truncating theparallel datasets up to the number of sentence pairsthat contained 2 million trigrams.6.5 ResultsTable 2 shows our complete set of results.
As ex-pected, the vanilla HMM trained with EM performsthe worst.
The feature-HMM model works better forall languages, generalizing the results achieved forEnglish by Berg-Kirkpatrick et al (2010).
Our ?Pro-jection?
baseline is able to benefit from the bilingualinformation and greatly improves upon the mono-lingual baselines, but falls short of the ?No LP?model by 2.5% on an average.
The ?No LP?
modeldoes not outperform direct projection for Germanand Greek, but performs better for six out of eightlanguages.
Overall, it gives improvements rangingfrom 1.1% for German to 14.7% for Italian, for anaverage improvement of 8.3% over the unsupervisedfeature-HMM model.
For comparison, the com-pletely unsupervised feature-HMM baseline accu-racy on the universal POS tags for English is 79.4%,and goes up to 88.7% with a treebank dictionary.Our full model (?With LP?)
outperforms the un-supervised baselines and the ?No LP?
setting for alllanguages.
It falls short of the ?Projection?
base-line for German, but is statistically indistinguish-able in terms of accuracy.
As indicated by bolding,for seven out of eight languages the improvementsof the ?With LP?
setting are statistically significantwith respect to the other models, including the ?NoLP?
setting.11 Overall, it performs 10.4% betterthan the hitherto state-of-the-art feature-HMM base-line, and 4.6% better than direct projection, when wemacro-average the accuracy over all languages.6.6 DiscussionOur full model outperforms the ?No LP?
settingbecause it has better vocabulary coverage and al-lows the extraction of a larger set of constraint fea-tures.
We tabulate this increase in Table 3.
For alllanguages, the vocabulary sizes increase by severalthousand words.
Although the tag distributions ofthe foreign words (Eq.
6) are noisy, the results con-firm that label propagation within the foreign lan-guage part of the graph adds significant quality forevery language.Figure 2 shows an excerpt of a sentence from theItalian test set and the tags assigned by four differentmodels, as well as the gold tags.
While the first threemodels get three to four tags wrong, our best modelgets only one word wrong and is the most accurateamong the four models for this example.
Examin-ing the word fidanzato for the ?No LP?
and ?WithLP?
models is particularly instructive.
As Figure 1shows, this word has no high-confidence alignmentin the Italian-English bitext.
As a result, its POS tagneeds to be induced in the ?No LP?
case, while the11A word level paired-t-test is significant at p < 0.01 for Dan-ish, Greek, Italian, Portuguese, Spanish and Swedish, andp < 0.05 for Dutch.607Gold:si          trovava          in           un          parco          con          il            fidanzato         Paolo        F.     ,     27    anni       ,   rappresentanteEM-HMM:Feature-HMM:No LP:With LP:CONJ NOUN DET DET NOUN ADP DET NOUN .NOUN.NUM NOUN .NOUNPRON VERB ADP DET NOUN CONJ DET NOUN NOUNNOUN.ADP NOUN .VERBPRON VERB ADP DET NOUN ADP DET NOUN NOUNNOUN.NUM NOUN .NOUNVERB VERB ADP DET NOUN ADP DET ADJ NOUNADJ.NUM NOUN .NOUNVERB VERB ADP DET NOUN ADP DET NOUN NOUNNOUN.NUM NOUN .NOUNFigure 2: Tags produced by the different models along with the reference set of tags for a part of a sentence from theItalian test set.
Italicized tags denote incorrect labels.Language# words with constraints?No LP?
?With LP?Danish 88,240 128, 391Dutch 51,169 74,892German 59,534 107,249Greek 90,231 114,002Italian 48,904 62,461Portuguese 46,787 65,737Spanish 72,215 82,459Swedish 70,181 88,454Table 3: Size of the vocabularies for the ?No LP?
and?With LP?
models for which we can impose constraints.correct tag is available as a constraint feature in the?With LP?
case.7 ConclusionWe have shown the efficacy of graph-based labelpropagation for projecting part-of-speech informa-tion across languages.
Because we are interested inapplying our techniques to languages for which nolabeled resources are available, we paid particularattention to minimize the number of free parame-ters and used the same hyperparameters for all lan-guage pairs.
Our results suggest that it is possible tolearn accurate POS taggers for languages which donot have any annotated data, but have translationsinto a resource-rich language.
Our results outper-form strong unsupervised baselines as well as ap-proaches that rely on direct projections, and bridgethe gap between purely supervised and unsupervisedPOS tagging models.AcknowledgementsWe would like to thank Ryan McDonald for numer-ous discussions on this topic.
We would also like tothank Amarnag Subramanya for helping us with theimplementation of label propagation and ShankarKumar for access to the parallel data.
Finally, wethank Kuzman Ganchev and the three anonymousreviewers for helpful suggestions and comments onearlier drafts of this paper.ReferencesHiyan Alshawi, Srinivas Bangalore, and Shona Douglas.2000.
Head-transducer models for speech translationand their automatic acquisition from bilingual data.Machine Translation, 15.Yasemin Altun, David McAllester, and Mikhail Belkin.2005.
Maximum margin semi-supervised learning forstructured variables.
In Proc.
of NIPS.Taylor Berg-Kirkpatrick, Alexandre B.
Co?te?, John DeN-ero, and Dan Klein.
2010.
Painless unsupervisedlearning with features.
In Proc.
of NAACL-HLT.Thorsten Brants.
2000.
TnT - a statistical part-of-speechtagger.
In Proc.
of ANLP.Peter F. Brown, Vincent J. Della Pietra, Stephen A. DellaPietra, and Robert L. Mercer.
1993.
The mathemat-ics of statistical machine translation: parameter esti-mation.
Computational Linguistics, 19.Sabine Buchholz and Erwin Marsi.
2006.
CoNLL-Xshared task on multilingual dependency parsing.
InProc.
of CoNLL.Andrew Carnie.
2002.
Syntax: A Generative Introduc-tion (Introducing Linguistics).
Blackwell Publishing.Christos Christodoulopoulos, Sharon Goldwater, andMark Steedman.
2010.
Two decades of unsupervisedPOS induction: How far have we come?
In Proc.
ofEMNLP.Arthur P. Dempster, Nan M. Laird, and Donald B. Ru-bin.
1977.
Maximum likelihood from incomplete datavia the EM algorithm.
Journal of the Royal StatisticalSociety, Series B, 39.Kuzman Ganchev, Jennifer Gillenwater, and Ben Taskar.2009.
Dependency grammar induction via bitext pro-jection constraints.
In Proc.
of ACL-IJCNLP.608Mark Johnson.
2007.
Why doesn?t EM find good HMMPOS-taggers?
In Proc.
of EMNLP-CoNLL.Philipp Koehn.
2005.
Europarl: A parallel corpus forstatistical machine translation.
In MT Summit.Dong C. Liu and Jorge Nocedal.
1989.
On the limitedmemory BFGS method for large scale optimization.Mathematical Programming, 45.Mitchell P. Marcus, Mary Ann Marcinkiewicz, and Beat-rice Santorini.
1993.
Building a large annotated cor-pus of English: the Penn treebank.
ComputationalLinguistics, 19.Tahira Naseem, Benjamin Snyder, Jacob Eisenstein, andRegina Barzilay.
2009.
Multilingual part-of-speechtagging: Two unsupervised approaches.
JAIR, 36.Tahira Naseem, Harr Chen, Regina Barzilay, and MarkJohnson.
2010.
Using universal linguistic knowledgeto guide grammar induction.
In Proc.
of EMNLP.Frederick J. Newmeyer.
2005.
Possible and ProbableLanguages: A Generative Perspective on LinguisticTypology.
Oxford University Press.Joakim Nivre, Johan Hall, Sandra Ku?bler, Ryan McDon-ald, Jens Nilsson, Sebastian Riedel, and Deniz Yuret.2007.
The CoNLL 2007 shared task on dependencyparsing.
In Proceedings of CoNLL.Slav Petrov, Dipanjan Das, and Ryan McDonald.
2011.A universal part-of-speech tagset.
ArXiv:1104.2086.Sujith Ravi and Kevin Knight.
2009.
Minimized modelsfor unsupervised part-of-speech tagging.
In Proc.
ofACL-IJCNLP.Libin Shen, Giorgio Satta, and Aravind Joshi.
2007.Guided learning for bidirectional sequence classifica-tion.
In Proc.
of ACL.Benjamin Snyder, Tahira Naseem, and Regina Barzilay.2009.
Unsupervised multilingual grammar induction.In Proc.
of ACL-IJCNLP.Amar Subramanya, Slav Petrov, and Fernando Pereira.2010.
Efficient graph-based semi-supervised learningof structured tagging models.
In Proc.
of EMNLP.UN.
2006.
ODS UN parallel corpus.Stephan Vogel, Hermann Ney, and Christoph Tillmann.1996.
HMM-based word alignment in statistical trans-lation.
In Proc.
of COLING.Chenhai Xi and Rebecca Hwa.
2005.
A backoffmodel for bootstrapping resources for non-Englishlanguages.
In Proc.
of HLT-EMNLP.David Yarowsky and Grace Ngai.
2001.
Inducing multi-lingual POS taggers and NP bracketers via robust pro-jection across aligned corpora.
In Proc.
of NAACL.Xiaojin Zhu, Zoubin Ghahramani, and John D. Lafferty.2003.
Semi-supervised learning using gaussian fieldsand harmonic functions.
In Proc.
of ICML.609
