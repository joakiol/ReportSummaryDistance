ANALYZING TELEGRAPHIC MESSAGESRalph  Gr i shmanJohn  Ster l ingNew York  Un ivers i tyMost people have little difficulty reading telegraphic-style messages such asSHIPMENT GOLD BULLION ARRIVING STAGECOACH JAN. 7 3 PMeven though lots of material has been omitted which would be required in "standard English", such asarticles, prepositions, and verbs.
Our concern in this paper is how to process such messages by computer.Even though people don't send many telegrams anymore, this problem is still of importance because manymilitary messages are written in this telegraphic style:2 FLARES SIGHTED 230704Z6 SOUTH APPROX 5 MI SPA ESTABLISHED(here 230704Z6 is the time, and SPA is the Submarine Probability Area).Alternative StrategiesThe particular class of messages which we have studied are a set of Navy tactical messages called RAINFORM(ship) sighting messages \[8\].
Several other researchers have previously constructed systems to analyze thesemessages.
In the NOMAD system \[1\] the knowledge was principally realized as procedures associated withindividual words.
This made it difficult to extend the system, as Granger has noted \[1\].
Some of theshortcomings of the internal knowledge representation were remedied in a later system named VOX \[5\]which used a conceptual grammar, mixing syntactic and semantic onstraints.
However, the power of thegrammar was still quite limited when compared to grammars traditionally used in computational linguisticsapplications.In the development of our system, in contrast, we have taken as our starting point a relatively broadcoverage grammar of standard English.
More generally, it has been our goal to use, to the extent possible,system components which would be appropriate to a general-purpose English language analyzer.
We seeseveral benefits to such an approach:?
Using general-purpose components minimizes the labor in porting the system to a new domain.?
Using a standard English grammar makes it easier to analyze the complex constructions (involvingsubordinating and coordinating conjunctions, for example) which occur with some frequency in thesemessages.?
Starting from a standard grammar clarifies the ways in which these messages differ from standardEnglish.This approach is in keeping with earlier work at NYU, on medical records and equipment failure reports\[4,3\], and more recent work at UNISYS, primarily on equipment failure reports \[6,2\].In the next section, we briefly describe the overall structure of the message understanding system.
In thetwo sections which follow, we focus on the two core problems of analyzing such telegraphic text: first, theproblem of analyzing the structure of the text ("parsing"); second, the problem of recovering the argumentswhich are omitted in the telegraphic text.204System structureThe text processing system is organized as a pipeline consisting of the following modules:1.
A parser using an augmented context-free grammar consisting of context-free rules plus proceduralrestrictions.
The grammar is modeled after the Linguistic String Project English Grammar \[7\]; theparser is based on a chart parsing algorithm.. A syntactic regularizer whose primary function is to convert all clauses into a standard operator-argument form.
The regularizer is organized as a set of Montague-style translation rules associatedwith the individual productions of the parsing grammar.3.
A semantic analyzer which checks semantic lass requirements for arguments of verbs, and whichtranslates clauses and nominalizations into domain predicates.4.
Simplification rules, which perform certain simplifications on the output of the semantic analyzer (forexample, conduct an attack ~ attack).5.
Reference resolution, which resolves anaphoric references.6.
Discourse analysis, which identifies implicit relations between events in the text.The control structure is not strictly sequential.
In particular, the parser, regularizer, and the checkingfunctions of the semantic analyzer are run in parallel.
Also, reference resolution and discourse analysis maybe interleaved using a priority-based scheme (discussed below).The entire system has been run successfully on 25 messages drawn from the set of I~AINFORM sightingmessages in \[8\].
These messages are, on average, roughly 25 words long.Analyz ing sentence structureAn noted above, we began our work on message analysis with a relatively broad coverage grammar ofstandard English.
Furthermore, we generally followed the approach of Sager and Marsh \[4,3\] in treatingthe deviations not as instances of ill-formedness but rather as constructions specific to such telegraphicsublanguages.
In our analysis of the RAINFORMs, we found two types of omissions.
The first, which hadbeen previously characterized by Sager and Marsh (in their analysis of medical reports and equipment failuremessages), involved the omission of top-level sentence lements, such as sentence subjects ("\[We\] conductedattack at close range.")
and the verb "be" ("Results \[are\] unknown at this time.").
The second class canbe generally characterized as function words which mark particular cases and types of complements.
Theseinclude prepositions uch as "of" and "at" ("Hydrophone ffects \[at\] bearing \[of\] 173degt \[were\] classified\[as\] surface combatant ..."), "as", and "to" in infinitival strings ("Intend \[to\] make sweep of area ...").Modifying the grammar to allow for these omissions was quite straightforward: several definitions wereadded for sentence fragments, and prepositions, "as", and "to" were allowed to be empty.
What made thetask less than trivial was controlling these omissions.
Adding the definitions for sentence fragments alone(following Sager and Marsh) increased syntactic ambiguity, but a sequential nalysis (first syntactic analysis,then semantic filtering) was still feasible.
However, when the grammar was extended to include functionword omission and run-on sentences, the degree of syntactic ambiguity became much greater.
If you considerthat, in the grammar, each noun can be a sentence fragment or a prepositional phrase (with a deletedpreposition), and add the fact that run-on sentences with no punctuation are frequent:Sighted periscope an asroc \[anti-submarine rocket\] fired proceeded on to station visual contactlost, constellation helo hovering in vicinity.205you can imagine the explosion in parses which would occur.
Such telegraphic input is understandable,however, only because of the strong semantic lues which are available.
~Ve take advantage of these semanticconstraints by applying basic semantic hecks on the semantic lasses of arguments and modifiers each timea noun phrase or a clause is completed uring parsing.In addition, we associate a score with each partial and complete parse, and use a best-first search forparsing, l~oughly speaking, we associate a lower score with analyses which imply the existence of a largernumber of omitted elements.
The scoring mechanism serves to focus the search and thus greatly reducethe parsing time.
In addition, it provides a means for preferring one analysis over another in some cases ofsyntactic ambiguity.
For example, the "sentence"Two cats drinking milk two cats eating fish.would get, in addition to the analysis as a run-on sentence, Two cats \[are\] drinking milk \[.\] Two cats \[are\]eating fish., the analysis as a single sentence with missing main verb "be", Two cats \[who are\] drinkingmilk \[are\] two cats \[who are\] eating fish.. We have experimented with several scoring schemes; our currentscheme xacts a constant penalty for each omitted preposition, "to", and "as", and for each clause (includingreduced relative clauses) and sentence fragment in the analysis.
This scheme produces the correct analysisfor the example just above.One further modification is required to handle zeroed prepositions.
The semantic checks mentionedearlier operate from a set of case frames, one or more for each verb.
Each case frame specifies a list ofarguments and modifiers, and for each argument or modifier the case marker (such as subject or object or alist of prepositions) and the semantic lass of the argument/modifier.
An omitted preposition is marked inthe analysis by the symbol prep and the semantic hecking routine has been modified to accept prep in placeof a particular preposition (but not to match positional markers uch as subject or object).Recovering omitted and anaphoric argumentsThe second major task in analyzing the telegraphic messages i recoving the missing arguments.
In the caseframes, certain arguments are marked as essential; if they are omitted from the text, reference resolutionattempts to fill them in.
It does so using essentially the same mechanism employed for anaphora resolution.This commonality of mechanism has been previously noted by UNISYS \[6,2\].The basic anaphora resolution mechanism is quite simple, and is based on a hierarchy of semantic lassesfor the objects and events in the domain.
If an argument is omitted, the case frame indicates the semanticclass of the argument which was expected.
If an argument is present and corresponds to a semantic lassmore specific than that required by the case frame, we take the semantic lass of the argument.
Referenceresolution searches for the most recently mentioned entity or event of the same semantic lass.
For example,in analyzingFired 2 missiles on Barsuk.
Results of attack unknown.we would recognize firing as a type of attack and thus link attack in the second sentence to the event relatedby the first sentence.This mechanism is in fact too simple.
Component (part/whole) relationships are sometimes needed inorder to link anaphor and antecedent.
Thus, to resolve My attacks in the messageExchange missile fire with Kynda .
.
.
.
My attacks successful.we must recognize that exchange involves two activities, my firing at Kynda and Kynda's firing at me.
Wecan then resolve My attacks with the first of these activities and thus determine that it was my attacks onKynda which were successful.Most of the anaphoric references in these messages can be correctly resolved using this combinationof type and component relationships.
In some cases, however, we need to make use of richer contextualinformation, about the relationship of the events in the message to one another.
For example, in206Three missiles fired at Kobchic.
One missile hit.reference resolution first uses the general rule that the omitted subject in a sentence fragment is "us" (theship sending the message), in effect expanding the first sentence to "Three missiles fired \[by us\] at Kobchic.
"It is then faced with the problem, in the second sentence, of whom the missiles hit, us or Kobchic, since bothantecedents are salient at this point.
To resolve this problem we use a set of discourse coherence rules, whichcapture the cause/effect and precondition/action relationships between the events in the domain.
Referenceresolution generates the alternate readings, and then discourse analysis scores a reading which matches thecoherence rules higher than one which does not.
In this case we have a rule that relates firing at a ship withhitting that ship, so the system prefers the analysis where Kobchic was hit.Both component information and contextual relationships are needed to processVisual sighting of periscope followed by attack .
.
.
.First we fill in "us" as the implicit subject of "sighting".
There is no antecedent for attack, so we proceedto fill in the essential arguments of attack.
The object of attack must be a ship.
The two salient entities atthis point are "us" and the periscope.
Reference resolution finds a link, through the part-whole hierarchy,between periscope and submarine, a type of ship, so it creates a submarine ntity.
It then proposes "us" andthis submarine as the possible objects of attack.
In this domain, we are hunting for enemy ships, so sightinga vessel is typically followed by attacking it.
We have included a coherence rule to that effect, so that the"attack on sub" reading is preferred.
In other environments, we might flag this passage as ambiguous.SummaryWe have shown how highly telegraphic messages can be analyzed through straightforward extensions of themechanisms employed for the syntactic and semantic analysis of standard English text.We have extended previous work on the grammatical analysis of telegraphic messages by allowing forthe omission of function words as well as major sentence constituents.
This substantially increases yntacticambiguity, but we have found that this ambiguity can be controlled by applying semantic onstraints duringparsing and by using a "best-first" parser in which lower scores are associated with analyses which assumeomitted function words.To recover missing arguments from telegraphic text, we have adopted a strategy in which such omittedarguments are treated as anaphoric elements.
In order to resolve anaphoric ambiguities, we have extendedthe anaphora resolution procedure to take account of the implicit causal and enablement relations in thetext.
We generate alternative resolutions of anaphoric reference and then select the text analysis with thehighest "coherence": the analysis for which we can identify the greater number of intersentential relations.Acknowledgements  This research was supported by the Defense Advanced Research Projects Agencyunder contract N00014-85-K-0163 from the Office of Naval Research.
Most of the modifications to the parserrequired for these messages were programmed and tested by Mahesh Chitrao.References\[1\] Richard H. Granger.
The NOMAD system: expectation-based detection and correction of errors duringunderstanding of syntactically and semantically ill-formed text.
American Journal of ComputationalLinguistics, 9(3-4):188-196, July-December 1983.\[2\] Marcia C. Linebarger, Deborah A. Dahl, Lynette Hirschman, and Rebecca J. Passonneau.
Sentence frag-ments regular structures.
In Proceedings o/the 26th Annual Meeting o/the Association/or ComputationalLinguistics, Buffalo, NY, June 1988.207\[3\] Elaine Marsh.
Utilizing domain-specific information for processing compact ext.
In Proceedings of theConference on Applied Natural Language Processing, pages 99-103, Santa Monica, CA, February 1983.\[4\] Elaine Marsh and Naomi Sager.
Analysis and processing of compact texts.
In J. Horecky, editor, COLING82: Proceedings of the Ninth International Conference on Computational Linguistics, pages 201-206,North-Holland, Amsterdam, 1982.\[5\] A. Meyers.
VOX--an extensible natural language processor.
In Proceedings of IJCAI-85, pages 821-825,Los Angeles, CA, 1985.\[6\] Martha S. Palmer, Deborah A. Dahl, Rebecca J.
\[Schiffman\] Passonneau, Lynette Hirschman, MarciaLinebarger, and John Dowding.
Recovering implicit information.
In Proceedings of the 24th AnnualMeeting of the Association for Computational Linguistics, Columbia University, New York, August 1986.\[7\] Naomi Sager.
Natural Language Information Processing: A Computer Grammar of English and ItsApplications.
Addison-Wesley, 1981.\[8\] B. M. Sundheim and R. A. Dillard.
Navy Tactical Messages: Examples for Text- Understanding Technol-ogy.
Technical Document 1060, Naval Ocean Systems Center, February 1987.208
