Proceedings of the 2012 Workshop on Biomedical Natural Language Processing (BioNLP 2012), pages 146?154,Montre?al, Canada, June 8, 2012. c?2012 Association for Computational LinguisticsExploring Label Dependency in Active Learning for Phenotype MappingShefali Sharma1, Leslie Lange2, Jose Luis Ambite1, Yigal Arens1, Chun-Nan Hsu1,31Information Sciences Institute, University of Southern California, Marina del Rey, CA 90292, USA2Department of Genetics, University of North Carolina, Chaple Hills, NC 27599, USA3Institute of Information Sciences, Academia Sinica, Taipei 115, Taiwanchunnan@isi.eduAbstractMany genetic epidemiological studies of hu-man diseases have multiple variables relatedto any given phenotype, resulting from dif-ferent definitions and multiple measurementsor subsets of data.
Manually mapping andharmonizing these phenotypes is a time-consuming process that may still miss themost appropriate variables.
Previously, a su-pervised learning algorithm was proposed forthis problem.
That algorithm learns to de-termine whether a pair of phenotypes is inthe same class.
Though that algorithm ac-complished satisfying F-scores, the need tomanually label training examples becomes abottleneck to improve its coverage.
Hereinwe present a novel active learning solutionto solve this challenging phenotype-mappingproblem.
Active learning will make pheno-type mapping more efficient and improve itsaccuracy.1 IntroductionPhenotypes are observable traits of an individual or-ganism resulting from the presence and interactionof its genotype with the environment.
Phenotypespotentially related to human health are of interest ingenetics and epidemiology, including common clin-ical conditions, inheritance disorders, as well as var-ious risk factors such as diet.
Substantial amountsof genomic data, including genome-wide genotyp-ing from GWAS (Genome-Wide Association Stud-ies) (Hardy and Singleton, 2009; Consortium, 2007)and sequencing, are being produced in conjunctionwith the collection of carefully defined and mea-sured phenotypes to study the role of genetic vari-ations in a wide variety of inherited traits and disor-ders for many decades.Recently, there is an emerging need to re-usethese valuable phenotype-genotype association datato boost the statistical power and improve sensitiv-ity and specificity of the search of associations be-tween various disorders and genetic variations.
Newparadigms of genomic studies may be fostered oncea map of related phenotypes is easily accessible.
Infact, one of such new paradigms, PheWAS (Phe-nome Wide Association Studies), has been devel-oped and producing interesting findings (Denny etal., 2010; Pendergrass et al, 2011) with the helpof phenotype mapping and harmonization.
UnlikeGWAS, which focus on calculating the associationbetween the variation of hundreds of thousands ofgenotyped single nucleotide polymorphisms (SNPs)and a single or small number of phenotypes, Phe-WAS uses an extensive range of detailed pheno-typic measurements for comprehensively exploringthe association between genetic variations and phe-notypes.
The investigation of a broad range of phe-notypes has the potential to identify pleiotropy, re-veal novel mechanistic insights, generate new hy-potheses, and define a more complete picture of ge-netic variations and their impact on human diseases.To facilitate integration of genomic data sets, theresearch community needs to categorize compara-ble phenotype measurements and match them acrossmultiple genomic studies to identify data sets ofinterest as well as potential future collaborations.While the naming strategy for genetic variants is146largely standardized across studies (e.g.
rs numbersfor single nucleotide polymorphisms or SNPs), thisis often not the case for phenotype variables.
Dueto the lack of a standardized terminologies or othercontrolled vocabularies, it becomes increasingly dif-ficult to find studies with comparable phenotypes asthe genomic data accumulate.
A researcher search-ing for the availability of comparable phenotypesacross multiple studies is confronted with a veritablemountain of variables to sift through.
Even withina study, there are often numerous versions of se-mantically equivalent phenotypic variables.
Manu-ally mapping and harmonizing these phenotypes is atime-consuming process that may still miss the mostappropriate variables.Previously, (Hsu et al, 2011) have developed asupervised learning algorithm that learns to deter-mine whether a pair of phenotypes is semanticallyrelated from their descriptors.
Though that algo-rithm accomplished satisfying F-scores, the need tomanually label training examples becomes a bottle-neck to improve its coverage.
Moreover, the algo-rithm treats each pair independently, but pairs thatconsist of common phenotypes are not independent.Exploring this dependency may potentially improveits performance.
In this paper, we investigate howto apply active learning to solve this challengingphenotype-mapping problem.
Application of effec-tive active learning techniques will make pheno-type mapping more efficient and improve its accu-racy and, along with intuitive phenotype query tools,would provide a major resource for researchers uti-lizing these genomic data.Active learning queries a user for labels of unla-beled phenotypes that may improve the learning ofphenotype mapping the most and thereby reduce theneed of labeling efforts.
To select the most usefultraining examples to query, different selection strate-gies have been proposed in the past (Settles, 2010):?
Uncertainty Sampling In this strategy, an ac-tive learner chooses an instance that is the mostuncertain for the current model to label (Lewisand Catlett, 1994).?
Query-By-committee This strategy (Seung etal., 1992) is also known as maximum dis-agreement (Ayache and Que?not, 2007; Di andCrawford, 2011) because the idea is to choosean instance for which a committee of modelsdisagrees the most among its members aboutits label.?
Expected Model Change The general princi-ple of this strategy is to choose an instance toquery when if its label is available, the modelwill be changed the most (Settles and Craven,2008).?
Expected Error Reduction Active learning isuseful when the selected instance reduce the er-ror the most and this strategy looks for an in-stance that can achieve this ultimate goal di-rectly.?
Variance Reduction Inspired by the bias-variance analysis of the generalization perfor-mance, the variance reduction principle seeksto query for instances that reduce the varianceof the model the most.
A similar approach isapplied in the optimal experimental design instatistics (Federov, 1972).
However, usuallythis also requires to solve expensive optimiza-tion problems.?
Density-Weighted Methods By consideringthe distribution of the instances, this strategyaddresses an issue of uncertainty sampling andquery-by-committee where outliers are likelyto be selected but contribute limitedly to im-proving the learning (Fujii et al, 1998; Das-gupta and Hsu, 2008).The method reported here basically followsthe maximum disagreement principle of query-by-committee to select unlabeled pairs of phenotypesto query.
A committee must be formed in order forthis strategy to be applied, but it has been shown thateven a small committee works well in practice.
Vari-ous approaches can be applied to create committees.For example, co-testing (Muslea et al, 2006) appliesthis principle by combining forward and backwardparsing models for information extraction.
A key tothe success of this strategy is that member modelsin the committee complement strengths and weak-nesses.The idea of our method is to compare the match-or-not assignments by the model trained by super-vised learning and the class assignments derived147from exploring linkages of the labeled and unlabeledphenotypes.
The most useful pairs to query are thosewhose assignments from the two different sourcesdisagree with the highest confidence.Exploring linkages may improve classifier learn-ing when the classes of instances depend on eachother.
This idea has been studied in the contextof classification of network data, such as pages onthe Web, co-reference resolution, word sense disam-biguation, and statistical relational learning (see e.g.,(Macskassy, 2007; McCallum and Wellner, 2005;Popescul et al, 2003)).In this paper, we present an algorithm that im-plement our idea.
This algorithm can be dividedinto two major steps.
The first step of the algo-rithm explores the linkages and the second step pri-oritizes pairs of phenotypes to query.
By identify-ing maximum disagreement pair instances betweenthe model classification results and exploring link-ages between labeled and unlabeled phenotype vari-ables, our active learner queries users for labels ofunlabeled phenotypes that may improve the map-ping the most and therefore will reduce the need oflabeling efforts.
Our experimental results show thatexploring linkages can perfectly infer the match-or-not labels for a large number of pairs, and that ac-tive learning from maximum disagreement pairs im-proves the performance faster than from randomlyselected pairs, suggesting that active learning by ex-ploring linkages is a promising approach to the prob-lem of phenotype mapping.2 Phenotype Mapping2.1 Problem DefinitionPhenotype mapping is a task of searching for alldatabases of participating studies to find a set of phe-notype variables that match a requested variable thatthe researcher is interested in.
This is similar to thedefinition given in (Hsu et al, 2011) where the taskis defined as the assignment of every phenotype vari-able from each participating study to one of a setcategories, or classes, which corresponds to the ?re-quested variable.
?Table 1 shows a fragment of the phenotype map-ping results of the phenotype variables that wematched manually from a consortium of cohort stud-ies for a set of 70 requested variables.
In this frag-ment, we show the phenotype variables assigned toone of the requested variables, the phenotype class?hypertension?.
The real ID of a phenotype ina Cohort is given in column Variable.
In this ex-ample, seven cohort studies have a total of 13 phe-notype measurements related to hypertension.Column Description is the main clue for au-tomatic matching.
The variable descriptions usu-ally contain less than 10 words.
As we can seein Table 1, the description contains abbreviations(e.g., ?HTN?, ?HBP?,dx), aliases (e.g., ?HighBlood Pressure?
vs.
Hypertension), mea-surement criteria (e.g., DBP>90 MMHG, sys GE140, per JNC7, JNC VI), and tokens irrelevantto our task.
As a result, word-by-word string sim-ilarity or sophisticated edit-distance based metricscan only match a small number of them.
These ex-amples are phenotypes that share similar semanticsand are manually mapped to the same classes buttheir descriptions contain few or no common words.It is impossible for a model solely using the givendescriptions to figure out that they refer to relatedphenotypes without bringing to bear additional in-formation.Other challenges of the phenotype problem in-clude: not knowing in advance how many classesthere are, unavailability of comprehensive catego-rization of phenotypes, and that the solution shouldscale well for a large number of phenotypes.2.2 Supervised Learning for PhenotypeMappingHere, we review the supervised learning method de-scribed in (Hsu et al, 2011), where phenotype map-ping was casted as a pair matching problem and ap-plied supervised learning to learn to tag a pair as amatch or not.
A pair of phenotypes are considered asa match if they are assigned to the same class, other-wise it is not.
13 phenotype variables in Table 1 willyield 78 pairs of positive examples of matched pairs.A maximum entropy classifier (MaxEnt) (Hastie etal., 2009) was used as the model to estimate theprobability that a pair is a match.
Two types of fea-tures were considered.
The first type is based onstring similarity metrics to combine the strength ofa variety of string similarity metrics to measure theedit distance between the descriptions of a pair ofphenotypes and use the result to determine if they148RequestedCohort Variables Variable DescriptionARIC Hypertension HYPERT06 HYPERTENSION, DEFINITION 6CARDIA Hypertension Y01DBP HYPERTENSION BASED ON DBP> 90 MMHGCARDIA Hypertension Y01HTN HIGH BLOOD PRESSURECARDIA Hypertension Y01HTNTP TYPE OF HYPERTENSIONCFS Hypertension htn HTN: abnormal bp (sys GE 140 or dia GE 90) or medsCFS Hypertension htndx HTN: self report of MD dx of HTNCHS Hypertension HYPER CALCULATED HTN STATUSFHS Hypertension A70 HISTORY OF HYPERTENSIONFHS Hypertension B373 HYPERTENSION-ON TREAT OR ELEVATED BPFHS Hypertension C332 HBP statusJHS Hypertension HTN017 Hypertension Status Per JNC7MESA Hypertension HIGHBP1 HYPERTENSION: SELF-REPORTMESA Hypertension HTN1C Hypertension by JNC VI (1997) criteriaTable 1: Example variables of phenotype class ?hypertension?match each other.
The other type is the weightedJaccard where appearence of tokens and bi-gramsin both or one of the descriptions of a given phe-notype pair is used as the features.
The training al-gorithm for MaxEnt will virtually assign to each to-ken or bi-gram a weight when it appears in the de-scriptions of an input phenotype pair.
Weighted Jac-card is superior to string similarity features becausestring similarity metrics treat all tokens equally andthe information provided by these metrics is limited.Therefore weighted jaccard was shown to outper-form string similarity features by a large margin inthe experimental evaluation.Before the feature extraction step, descriptionswill be augmented with the definitions given in theMerriam-Webster Medical Dictionary (2006)1.
Forexample, ?hypertension?
will be augmentedwith its definition in the dictionary ?abnormallyhigh arterial blood pressure?
andconverted into ?hypertension abnormallyhigh arterial blood pressure?.
Aug-mented ?hypertension?
will have many sharedtokens with ?high blood pressure?.
Thisaugmentation step was proven to be effective inboosting recall, as semantically equivalent pairsdescribed by totally different sets of tokens can bematched.
(Hsu et al, 2011) also reported a transitive in-ference method to take advantage of the transitiverelationship of matched phenotype pairs.
The ideais that if v1 and v2 are a match, so are v2 and v3,1www.m-w.com/browse/medical/a.htmthen v1 and v3 must be a match, too.
Applying tran-sitive inference did improve the performance, butwhen all possible transitive relations are explored,the performance degraded because false positivesaccumulated.
The transitive inference method doesnot fully explore the dependency between pairs thatshare common phenotype variables.
A more sophis-ticated approach is required.3 MethodsFigure 1 illustrates our active learning idea.
The ideais that, given a training set of phenotype variablesX manually matched with class labels and a test setof unlabeled phenotype variables, the first step is toinfer the class of each unlabeled variable by explor-ing the pairwise match scores assigned by the modeltrained by the training set.
When we obtain a plausi-ble class assignment to each unlabeled variable, wecan classify each pair of unlabeled variables v1 andv2 by the trained model again to determine if theyare a match or not and compare the result with theirplausible class assignments.If it turns out that the results agree with each other,we will move the pair to a set called sure pairs, oth-erwise, we will move the pair to a queue which willbe sorted in descreasing order by how much the re-sults disagree.
Then we can query for true labels ofthe pairs in the queue to add to the training set themost useful examples and thus accomplish the activelearning.149Figure 1: Inferernce of match between unlabeled pheno-type variables by exploring their linkages to labeled pairs3.1 Assigning Phenotype CategoriesProcedure LabelA is to assign a class label to eachunlabeled test variable by matching them to labeledtraining variables.
Let A denote the set of all pairsbetween a test variable and a training variable.
Foreach variable, the output contains an element of thevariable, its assigned class label (may be null) anda score (log-likelihood).
Function I(.)
in line 2 isthe indicator function that returns 1 if its parameteris true and 0 otherwise.
H is the model learned bycalling the supervised training procedure.
In line 7,PHvx is the probability that variables v and x are amatch estimated by H .
In line 8, LabelA assigns vto a class c, which is the class of the training variablex that maximizes PHvx.
That is to assign the class ofx as that of v if PHvx is the largest.
Other selectioncan be used.
For example, for each class c, we canestimate PHvx for all training variables x in c, and se-lect c as the class of v if 1n?logPHvx, the geometricmean of the probabilities, is the largest.
These selec-tion criteria are based on different assumptions andwe will empirically compare which one is a betterchoice.
In fact, any type of average can potentiallybe considered here.3.2 Prioritizing Unlabeled PairsProcedure LabelB orders pairs of test variables toquery for match-or-not and class labels.
Let B bethe set of all pairs of test variables.
LabelB alsogenerates a set called SurePairs.
For each pairin B, LabelB checks if the model H considers thepair as a match (PHvx ?
0.5) or not, and then checksif the pair is assigned by LabelA to the same classAlgorithm 1 Procedure LabelA1: Initialization?
Training variables X with their class anno-tated class(x) = c ?
C,?x ?
X?
Test variables V with unknown classclass(v),?v ?
V2: H ?
Train({(x1, x2,m)|x1, x2 ?
X,m =I(class(x1) = class(x2))})3: A?
{(v, x)|v ?
V ?
x ?
X}4: procedure LABELA(A,H)5: Output?
?6: for v ?
V do7: ?x ?
X,PHvx ?
H(v, x)8: c?
argmaxc(PHvx)9: LHvx ?
maxC(logPHvx)10: if LHvx < ?2 then11: c?
null,12: s?
log(1?
2LHvx)13: else14: s?
LHvx15: end if16: Add (v, c, s) to Output17: end for18: Return Output19: end procedureor not.
If it is a match and assigned to the same class,or not a match and assigned to different classes, thatis, if H and LabelA agree, then the pair will bemoved to SurePairs, otherwise, the pair will bemoved to Queue.
For a disagreed pair, LabelBalso estimate the degree of disagreement by the sumof the log-probabilities of the class assignments (LHc1and LHc2) and the match-or-not by the model (PHv1v2).SurePairs can then be used for training.We can then query for true labels of pairs inQueue.
We can either query whether a pair is amatch or not or query for their class label.
After acertain number of queries, we can repeat the pro-cedure to compute a new set of SurePairs andQueue, until all phenotypes are correctly assignedto a class.150Algorithm 2 Procedure LabelB1: Initialization2: H,A as in LabelA3: B ?
{(v1, v2)|v1, v2 ?
V }4: SurePairs?
?
; Queue?
?5: ?v1, v2 ?
V, PHv1v2 ?
H(v1, v2)6: (v, class(v), LHc ),?v ?
V ?
LabelA(A,H)7: procedure LABELB(B,A,H)8: for (v1, v2) ?
B do9: if PHv1,v2 ?
0.5 then10: if c1 = c2 then11: Add (v1, v2, 1) to SurePairs12: else13: s?
LHc1 +LHc2 + log(1?PHv1v2)14: Add (v1, v2, s) to Queue15: end if16: else17: if c1 = c2 then18: s?
LHc1 + LHc2 + logPHv1v219: Add (v1, v2, s) to Queue20: else21: Add (v1, v2, 0) to SurePairs22: end if23: end if24: end for25: Sort (v1, v2,m) in Queue by m26: Return Queue and SurePairs27: end procedure4 Results4.1 DataWe manually selected 1,177 phenotype variablesfrom a total of 35,041 in the databases of seven co-hort studies as shown in Table 1 and assigned themto one of 70 requested variables that are commontrait classes related to a large consortium study ofcardiovascular disorders.
These seven cohorts in-clude ARIC (the Atherosclerosis Risk In Communi-ties study www.cscc.unc.edu/aric/), CAR-DIA (the Coronary Artery Risk In Young Adultsstudy www.cardia.dopm.uab.edu), CFS (theCleveland Family study dceweb1.case.edu/serc/collab/project_family.shtml),CHS (the Cardiovascular Heart Study www.chs-nhlbi.org/), FHS (Framingham HeartStudy www.framinghamheartstudy.org/),Method / Model Precision Recall F-scoreString similarityMaxEnt 0.5557 0.0660 0.1179Weighted JaccardMaxEnt 0.8791 0.4848 0.6250w/ dictionary 0.9200 0.6104 0.7339w/ transitive infer.
0.7735 0.6612 0.7129w/ both 0.7728 0.8402 0.8051Table 2: Performance results of supervised learningJHS (Jackson Heart Study jhs.jsums.edu/jhsinfo/), and MEC (the Multi-Ethnic Cohortwww.crch.org/multiethniccohort/,www.uscnorris.com/mecgenetics/).From these 1,177 phenotypes, 21,886 pairs areconsidered matches, that is, they are positive pairswith both phenotype variables in the same class.670,190 pairs are negatives.4.2 Result of Supervised LearningWe divided all pairs in our data set by half into train-ing and test sets and evaluate different options of thesupervised learning algorithm with different optionsas described in (Hsu et al, 2011).
The results asshown in Table 2 are consistent with the conclusionsgiven in (Hsu et al, 2011).
That is, weighted Jaccardfeatures with dictionary augmentation plus transitiveinference yields the best performance.We also performed a split-by-variable test, wherethe set of all variables is divided into three equalparts.
Two of them are used for training and theother for testing.
This is closer to the realistic appli-cation scenario and provides a better estimation ofthe generalization performance of a trained model.The results are given as the first two rows in Table 3.4.3 Result of Active LearningWe implemented the two algorithms and evalu-ate the performance.
We still applied split-by-variable to divide the data with 13 for testing and23for training.
We measured the performance whenSurePairs produced by procedure LabelB wasadded to the training set, and then increasingly addmore pairs in Queue, also produced by LabelB,to the training set, and measured the performanceof the trained models to simulate an active learning151Method/Model Precision Recall F-scorew/o dictionary 0.8344 0.4106 0.5504w/ dictionary 0.6310 0.5287 0.5753Test on A 0.7956 0.5243 0.6321GM SurePairs(62622) 0.8772 0.5909 0.7061Model (62622) 0.9577 0.2936 0.4494MP SurePairs(74229) 0.8845 0.6196 0.7287Model (74229) 0.9660 0.2875 0.4431Table 3: Performance results of splitting by variables.Numbers in the parentheses show the number of pairs inSurePairs.query sequence.To ensure a fair comparison, we always use the setA, the pairs between a labeled and unlabeled pheno-type variables, as the hold-out set for testing in allperformance evaluations.
Note that pairs in the set Anever appear in either SurePairs or Queue, be-cause pairs in SurePairs or Queue are selectedfrom the set B, which contains the pairs betweenunlabeled phenotype variables.
The third row of Ta-ble 3 shows the performance of the model testedonly on A.We implemented two versions of procedureLabelA that are different in the methods they usedto assign a class to an unlabeled variable.
The first,MP, is to use the maximum probability and the other,GM, is to use the maximum geometric mean of theprobabilities (see Section 3.1).We start by evaluating the quality ofSurePairs.
GM produced 62,622 pairs (1,642positives) while MP had 74,229 pairs (1,816positives).
The match-or-not labels assigned byLabelB for both methods turn out to be perfectlycorrect, suggesting that combining model trainingand linkage exploration can effectively infer thematch-or-not labels.Adding SurePairs to the training set boosts F-scores, as shown in Table 3, which also shows that,in contrast, if we add the same number of pairs tothe training set, but assign them match-or-not labelswith the trained model, they will degrade F-scores.Next, we added pairs in Queue to the trainingset, 280 pairs at a time, and measured the F-scoresachieved by the resulting model.
Figure 2 showsthe learning curves of three different ways to orderQueue produced with GM: descreasing, increasing,and random scores.
The decreasing-score one per-formed the best by improving F-scores the fastest,confirming that higher-scored pairs are more useful.The end points of the three curves do not meet be-cause we have not exhausted all training examples.Similarly, we evaluated decreasing and randomordering of Queue produced by applying MP.We note that MP already produced a large set ofSurePairs.
As a result, less pairs are in Queuecompared to that by GM.
Therefore, after 9 passes, allpairs are exhausted and no obvious difference can beobserved between decreasing and random orderingin the end.Figure 2: Learning curves of active learning: class as-signment by maximum geometric mean of probabilitiesFigure 3: Learning curves of active learning: class as-signment by maximum probabilities5 Conclusions and Future WorksDespite the vast amounts of genomic data availablein repositories, identification of relevant datasets canbe challenging for researchers interested in specific152phenotypic measures.
This paper presents our ac-tive learning approach that will be implemented as acomponent of new informatics tools for the researchcommunity to categorize phenotype measurementsfrom genomic studies.We show that comparing class assignment by ex-ploring linkages and by the model can be effectivein both improving the match-or-not assignments andordering unlabeled pairs as queries for active learn-ing.
It is interesting that when two sources of classassignment agree, the pairs?
match-or-not assign-ments are perfectly correct.
How generalizable forthis result deserves further investigation.
We notethat in order to perform a fair comparison, no pairbetween labeled and unlabeled phenotype variablesare used for training.
In a real application, they canbe added to either SurePairs or Queue by ex-tending procedure LabelB to include them.AcknowledgmentsWe thank Cheng-Ju Kuo and Congxing Cai for theirhelp in producing the results reported in Section 4.2.This research is supported by NHLBI-NIH grant1UH2HL108780-01.ReferencesSte?phane Ayache and Georges Que?not.
2007.
Evaluationof active learning strategies for video indexing.
SignalProcessing: Image Communication, 22(78):692 ?
704.Special Issue on Content-Based Multimedia Indexingand Retrieval.The Wellcome Trust Case Control Consortium.
2007.Genome-wide association study of 14,000 cases ofseven common diseases and 3,000 shared controls.Nature, 447(7145):661?678, June.Sanjoy Dasgupta and Daniel Hsu.
2008.
Hierarchicalsampling for active learning.
In Machine Learning,Proceedings of the Twenty-Fifth International Confer-ence on Machine Learning (ICML-08), pages 208?215.Joshua C. Denny, Marylyn D. Ritchie, Melissa A. Bas-ford, Jill M. Pulley, Lisa Bastarache, Kristin Brown-Gentry, Deede Wang, Dan R. Masys, Dan M. Ro-den, and Dana C. Crawford.
2010.
Phewas: demon-strating the feasibility of a phenome-wide scan todiscover gene-disease associations.
Bioinformatics,26(9):1205?1210.Wei Di and Melba M. Crawford.
2011.
View gen-eration for multiview maximum disagreement basedactive learning for hyperspectral image classification.Geoscience and Remote Sensing, IEEE Transactionson, PP(99):1 ?13.Valerii?
V. Federov.
1972.
Theory of Optimal Experi-ments.
Academic Press.Atsushi Fujii, Takenobu Tokunaga, Kentaro Inui, andHozumi Tanaka.
1998.
Selective sampling forexample-based word sense disambiguation.
Compu-tational Linguistics, 24(4):573?597.John Hardy and Andrew Singleton.
2009.
Genomewideassociation studies and human disease.
New EnglandJournal of Medicine, 360(17):1759?1768.Trevor Hastie, Robert Tibshirani, and Jerome H. Fried-mann.
2009.
The Elements of Statistical Learning(2nd Edition).
Springer-Verlag, New York, NY, USA.Chun-Nan Hsu, Cheng-Ju Kuo, Congxing Cai, Sarah A.Pendergrass, Marylyn D. Ritchie, and Jose Luis Am-bite.
2011.
Learning phenotype mapping for integrat-ing large genetic data.
In Proceedings of BioNLP 2011Workshop, BioNLP ?11, pages 19?27, Portland, OR,USA.
Association for Computational Linguistics.David D. Lewis and Jason Catlett.
1994.
Heterogeneousuncertainty sampling for supervised-learning.
In Pro-ceedings of the International Conference on MachineLearning (ICML-94), pages 148?156.Sofus A. Macskassy.
2007.
Improving learning in net-worked data by combinng explicit and mined links.
InProceedings of the National Conference on ArtificialIntelligence (AAAI-07), page 590.Andrew McCallum and Ben Wellner.
2005.
Conditionalmodels of identity uncertainty with application to nouncoreference.
In Lawrence K. Saul, Yair Weiss, andLe?on Bottou, editors, Advances in Neural InformationProcessing Systems 17, pages 905?912.
MIT Press,Cambridge, MA.Merriam-Webster.
2006.
Medical Dictionary.
Merriam-Webster, Springfield, MA, USA.Ion Muslea, Steve Minton, and Craig A. Knoblock.
2006.Active learning with multiple views.
Journal of Artifi-cial Intelligence Research, 27:203?233.S.
A. Pendergrass, K. Brown-Gentry, S. M. Dudek, E. S.Torstenson, J. L. Ambite, C. L. Avery, S. Buyske,C.
Cai, M. D. Fesinmeyer, C. Haiman, G. Heiss,L.
A. Hindorff, C. N. Hsu, R. D. Jackson, C. Kooper-berg, L. Le Marchand, Y. Lin, T. C. Matise, L. More-land, K. Monroe, A. P. Reiner, R. Wallace, L. R.Wilkens, D. C. Crawford, and M. D. Ritchie.
2011.The use of phenome-wide association studies (phewas)for exploration of novel genotype-phenotype relation-ships and pleiotropy discovery.
Genetic Epidemiol-ogy, 35(5):410?422.Alexandrin Popescul, Rin Popescul, and Lyle H. Ungar.2003.
Statistical relational learning for link prediction.153In In Workshop on Learning Statistical Models fromRelational Data at the International Joint Conferenceon Articial Intelligence (IJCAI-2003).Burr Settles and Mark Craven.
2008.
An analysis ofactive learning strategies for sequence labeling tasks.In Proceedings of the Conference on Empirical Meth-ods in Natural Language Processing (EMNLP), pages1069?1078.
ACL Press.Burr Settles.
2010.
Active learning literature survey.Computer Science Technical Report 1648, Universityof Wisconsin-Madison, January.H.
Sebastian Seung, Manfred Opper, and Haim Som-polinsky.
1992.
Query by committee.
In Proceed-ings of the Fifth Annual Workshop on ComputationalLearning Theory (COLT?92), pages 278?294.154
