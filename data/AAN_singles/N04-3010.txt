A THAI SPEECH TRANSLATION SYSTEM  FOR MEDICAL DIALOGSTanja Schultz, Dorcas Alexander, Alan W Black, Kay Peterson, Sinaporn Suebvisai, Alex WaibelLanguage Technologies Institute, Carnegie Mellon UniversityE-mail: tanja@cs.cmu.edu1.
IntroductionIn this paper we present our activities towards a ThaiSpeech-to-Speech translation system.
We investigated inthe design and implementation of a prototype system.
Forthis purpose we carried out research on bootstrapping aThai speech recognition system, developing a translationcomponent, and building an initial Thai synthesis systemusing our existing tools.2.
Speech RecognitionThe language adaptation techniques developed in our lab[5] enables us to rapidly bootstrap a speech recognitionsystem in a new target language given very limited amountof training data.
The Thailand?s National Electronics andTechnology Center gave us the permission to use theirThai speech data collected in the hotel reservation domain.They provided us with a 6 hours text and speech databaserecorded from native Thai speakers.
We divided the datainto three speaker disjoint sets, 34 speakers were used fortraining, 4 speakers for development, and another 4speakers for evaluation.
The provided transcriptions weremanually pre-segmented and given in Thai script.
Wetransformed the Thai script into a Roman scriptrepresentation by concatenating the phonemerepresentation of the Thai word given in the pronunciationdictionary.
The motivation for this romanization step wasthreefold: (1) it makes it easier for non-Thai researchers towork with the Roman representation like in the grammardevelopment, (2) the romanized output basically providesthe pronunciation which makes things easier for the speechsynthesis component, and (3) our speech engine currentlydoes not handle Thai characters.In our first Thai speech engine we decided to disregard thetone information.
Since tone is a distinctive feature in theThai language, disregarding the tone increases the numberof homographs.
In order to limit this number, wedistinguished those word candidates by adding a tag thatrepresents the tone.
The resulting dictionary consists of734 words which cover the given 6-hours database.Building on our earlier studies which showed thatmultilingual seed models outperform monolingual ones[5], we applied phonemes taken from seven languages,namely Chinese, Croatian, French, German, Japanese,Spanish, and Turkish as seed models for the Thai phoneset.
Table 1 describes the performance of the Thai speechrecognition component for different acoustic model sizes(context-independent vs. 500 and 1000 tri-phone models).The results indicate that a Thai speech recognition enginecan be built by using the bootstrapping approach with areasonable amount of speech data.
Even the very initialsystem bootstrapped from multilingual seed models givesa performance above 80% word accuracy.
The goodperformance might be an artifact from the very limiteddomain with a compact and closed vocabulary.System Dev Test Eval TestContext-Independent 85.62% 83.63%Context-Dependent (500) 86.99% 84.44%Context-Dependent (1000) 84.63% 82.71%Table1: Word accuracy [%] in Thai language3.
Machine TranslationThe Machine Translation (MT) component of our currentThai system is based on an interlingua called theInterchange Format (IF).
The IF developed by CMU hasbeen expanded and now encompasses concepts in both thetravel and medical domains, as well as many general-useor cross-domain concepts in many different languages [4].Interlingua-based MT has several advantages, namely: (1)it abstracts away from variations in syntax acrosslanguages, providing potentially deep analysis of meaningwithout relying on information pertinent only to oneparticular language pair, (2) modules for analysis andgeneration can be developed monolingually, withadditional reference only to the second "language" of theinterlingua, (3) the speaker can be given a paraphrase inhis or her own language, which can help verify theaccuracy of the analysis and be used to alert the listener toinaccurate translations, and (4) translation systems can beextended to new languages simply by hooking up newmonolingual modules for analysis and/or generation,eliminating the need to develop a completely new systemfor each new language pair.Thai has some particular characteristics which weaddressed in IF and appear in the grammars as follows:1) The use of a term to indicate the gender of the person:Thai: zookhee kha1Eng: okay (ending)s[acknowledge] (zookhee *[speaker=])2) An affirmation that means more than simply "yes.
"Thai: saap khrapEng: know (ending)s[affirm+knowledge](saap *[speaker=])3) The separation from the main verb of terms forfeasibility and other modalities.Thai: rvv khun ca paj dooj thxksiikyydaajEng: or you will go by taxi [can too]s[give-information+feasibility+trip](*DISC-RHET [who=] ca paj[locomotion=] [feasibility=])4.
Language GenerationFor natural language generation from interlingua for Thaiand English, we are currently investigating two options: aknowledge-based generation with the pseudo-unificationbased GenKit generator developed at CMU, whichemploys manually written semantic/syntactic grammarsand lexicons, and a statistical generation operating on atraining corpus of aligned interlingua and natural languagecorrespondences.
Performance tests as well as the amountand quality of training data will decide which approachwill be pursued in the future.5.
Speech SynthesisFirst, we built a limited domain Thai voice in the FestivalSpeech Synthesis System [1].
Limited Domain voices canachieve very high quality voice output [2], and can be easyto construct if the domain is constrained.
Our initial voicetargeted the Hotel Reservation domain and we constructed235 sentence that covered the aspects of our immediateinterest.
Using the tools provided in FestVox [1], werecorded, auto-labeled, and built a synthetic voice.In supporting any new language in synthesis, a number oflanguage specific issues first had to be addressed.
As withour other speech-to-speech translation projects we sharethe phoneme set between the recognizer and thesynthesizer.
The second important component is thelexicon.
The pronunciation of Thai words from Thai scriptis not straightforward, but there is a stronger relationshipbetween the orthography and pronunciation than inEnglish.
For this small set of initial words we constructedan explicit lexicon by hand with the output vocabulary of522 words.
The complete Thai limited domain voice usesunit selection concatenative synthesis.
Unlike our otherlimited domain synthesizers, where they have a limitedvocabulary, we tag each phone with syllable and toneinformation in selection making the result more fluent, anda little more general.Building on our previous Thai work in pronunciation ofThai words [3], we have used the lexicon and statisticallytrained letter to sound rules to bootstrap the required wordcoverage.
With a pronunciation model we can selectsuitable phonetically balanced text (both general and in-domain) from which we are able to record and build amore general voice.6.
Demonstration Prototype SystemOur current version is a two-way speech-to-speechtranslation system between Thai and English for dialogs inthe medical domain where the English speaker is a doctorand the Thai speaker is a patient.
The translated speechinput will be spoken using the built voice.
At the moment,the coverage is very limited due to the simplicity of theused grammars.
The figure shows the interface of ourprototype system.AcknowledgementsThis work was partly funded by LASER-ACTD.
Theauthors thank Thailand?s National Electronics andComputer Technology Center for giving the permission touse their database and dictionary for this task.References[1] Black, A. and Lenzo, K. (2000) "Building Voices in theFestival Speech Synthesis System", http://festvox.org[2] Black, A. and Lenzo, K. (2000) "Limited Domain Synthesis",ICSLP2000, Beijing, China.
[3] Chotmongkol, A. and Black, A.
(2000) "Statistically trainedorthographic to sound models for Thai", ICSLP2000,Beijing, China.
[4] Lavie A. and Levin L. and Schultz T. and Langley C. andHan B., Tribble, A., Gates D., Wallace D. and Peterson K.(2001) ?Domain Portability in Speech-to-speechTranslation?,  HLT, San Diego, March 2001.
[5] Schultz, T. and Waibel, A.
(2001) ?Language Independentand Language Adaptive Acoustic Modeling for SpeechRecognition?, Speech Communication, Volume 35, Issue 1-2, pp.
31-51, August 2001.
