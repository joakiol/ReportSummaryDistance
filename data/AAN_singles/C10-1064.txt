Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 564?571,Beijing, August 2010A Cross-lingual Annotation Projection Approachfor Relation DetectionSeokhwan Kim?, Minwoo Jeong?, Jonghoon Lee?, Gary Geunbae Lee?
?Department of Computer Science and Engineering,Pohang University of Science and Technology{megaup|jh21983|gblee}@postech.ac.kr?Saarland Universitym.jeong@mmci.uni-saarland.deAbstractWhile extensive studies on relation ex-traction have been conducted in the lastdecade, statistical systems based on su-pervised learning are still limited becausethey require large amounts of training datato achieve high performance.
In this pa-per, we develop a cross-lingual annota-tion projection method that leverages par-allel corpora to bootstrap a relation detec-tor without significant annotation effortsfor a resource-poor language.
In order tomake our method more reliable, we intro-duce three simple projection noise reduc-tion methods.
The merit of our method isdemonstrated through a novel Korean re-lation detection task.1 IntroductionRelation extraction aims to identify semantic re-lations of entities in a document.
Many rela-tion extraction studies have followed the Rela-tion Detection and Characterization (RDC) taskorganized by the Automatic Content Extractionproject (Doddington et al, 2004) to make multi-lingual corpora of English, Chinese and Ara-bic.
Although these datasets encourage the de-velopment and evaluation of statistical relationextractors for such languages, there would be ascarcity of labeled training samples when learn-ing a new system for another language such asKorean.
Since manual annotation of entities andtheir relations for such resource-poor languagesis very expensive, we would like to consider in-stead a weakly-supervised learning technique inorder to learn the relation extractor without sig-nificant annotation efforts.
To do this, we proposeto leverage parallel corpora to project the relationannotation on the source language (e.g.
English)to the target (e.g.
Korean).While many supervised machine learning ap-proaches have been successfully applied to theRDC task (Kambhatla, 2004; Zhou et al, 2005;Zelenko et al, 2003; Culotta and Sorensen, 2004;Bunescu and Mooney, 2005; Zhang et al, 2006),few have focused on weakly-supervised relationextraction.
For example, (Zhang, 2004) and (Chenet al, 2006) utilized weakly-supervised learningtechniques for relation extraction, but they didnot consider weak supervision in the context ofcross-lingual relation extraction.
Our key hypoth-esis on the use of parallel corpora for learningthe relation extraction system is referred to ascross-lingual annotation projection.
Early stud-ies of cross-lingual annotation projection were ac-complished for lexically-based tasks; for exam-ple part-of-speech tagging (Yarowsky and Ngai,2001), named-entity tagging (Yarowsky et al,2001), and verb classification (Merlo et al, 2002).Recently, there has been increasing interest in ap-plications of annotation projection such as depen-dency parsing (Hwa et al, 2005), mention de-tection (Zitouni and Florian, 2008), and semanticrole labeling (Pado and Lapata, 2009).
However,to the best of our knowledge, no work has reportedon the RDC task.In this paper, we apply a cross-lingual anno-tation projection approach to binary relation de-tection, a task of identifying the relation betweentwo entities.
A simple projection method propa-gates the relations in source language sentences to564word-aligned target sentences, and a target rela-tion detector can bootstrap from projected annota-tion.
However, this automatic annotation is unre-liable because of mis-classification of source textand word alignment errors, so it causes a criticalfalling-off in annotation projection quality.
To al-leviate this problem, we present three noise reduc-tion strategies: a heuristic filtering; an alignmentcorrection with dictionary; and an instance selec-tion based on assessment, and combine these toyield a better result.We provide a quantitive evaluation of ourmethod on a new Korean RDC dataset.
In ourexperiment, we leverage an English-Korean par-allel corpus collected from the Web, and demon-strate that the annotation projection approach andnoise reduction method are beneficial to build aninitial Korean relation detection system.
For ex-ample, the combined model of three noise reduc-tion methods achieves F1-scores of 36.9% (59.8%precision and 26.7% recall), favorably comparingwith the 30.5% shown by the supervised base-line.1The remainder of this paper is structured as fol-lows.
In Section 2, we describe our cross-lingualannotation projection approach to relation detec-tion task.
Then, we present the noise reductionmethods in Section 3.
Our experiment on the pro-posed Korean RDC evaluation set is shown in Sec-tion 4 and Section 5, and we conclude this paperin Section 6.2 Cross-lingual Annotation Projectionfor Relation DetectionThe annotation projection from a resource-richlanguage L1 to a resource-poor language L2 isperformed by a series of three subtasks: annota-tion, projection and assessment.The annotation projection for relation detectioncan be performed as follows:1) For a given pair of bi-sentences in parallel cor-pora between a resource-rich language L1 anda target language L2, the relation detection taskis carried out for the sentence in L1.1The dataset and the parallel corpus are available on theauthor?s website,http://isoft.postech.ac.kr/?megaup/research/resources/.2) The annotations obtained by analyzing the sen-tence in L1 are projected onto the sentence inL2 based on the word alignment information.3) The projected annotations on the sentence inL2 are utilized as resources to perform the re-lation detection task for the language L2.2.1 AnnotationThe first step to projecting annotations from L1onto L2 is obtaining annotations for the sentencesin L1.
Since each instance for relation detectionis composed of a pair of entity mentions, the in-formation about entity mentions on the given sen-tences should be identified first.
We detect theentities in the L1 sentences of the parallel cor-pora.
Entity identification generates a number ofinstances for relation detection by coupling twoentities within each sentence.
For each instance,the existence of semantic relation between entitymentions is explored, which is called relation de-tection.
We assume that there exist available mod-els or systems for all annotation processes, includ-ing not only an entity tagger and a relation de-tector themselves, but also required preprocessorssuch as a part-of-speech tagger, base-phrase chun-ker, and syntax parser for analyzing text in L1.Figure 1 shows an example of annotation pro-jection for relation detection of a bitext in En-glish and Korean.
The annotation of the sentencein English shows that ?Jan Mullins?
and ?Com-puter Recycler Incorporated?
are entity mentionsof a person and an organization, respectively.
Fur-thermore, the result indicates that the pair of en-tities has a semantic relationship categorized as?ROLE.Owner?
type.2.2 ProjectionIn order to project the annotations from the sen-tences in L1 onto the sentences in L2, we utilizethe information of word alignment which playsan important role in statistical machine transla-tion techniques.
The word alignment task aimsto identify translational relationships among thewords in a bitext and produces a bipartite graphwith a set of edges between words with transla-tional relationships as shown in Figure 1.
In thesame manner as the annotation in L1, entities are565????????(keom-pyu-teo-ri-sa-i-keul-reo)?(ui)??(sa-jang)?(eun)?
??(ra-go)???
(mal-haet-da)Mullins, owner of Incorporated said that ...?(jan)???
(meol-rin-seu)Jan Computer RecyclerROLE.OwnerPER ORGORG PERROLE.OwnerFigure 1: An example of annotation projection for relation detection of a bitext in English and Koreanconsidered as the first units to be projected.
We as-sume that the words of the sentences in L2 alignedwith a given entity mention in L1 inherit the infor-mation about the original entity in L1.After projecting the annotations of entity men-tions, the projections for relational instances fol-low.
A projection is performed on a projected in-stance in L2 which is a pair of projected entitiesby duplicating annotations of the original instancein L1.Figure 1 presents an example of projection of apositive relational instance between ?Jan Mullins?and ?Computer Recycler Incorporated?
in theEnglish sentence onto its translational counter-part sentence in Korean.
?Jan meol-rin-seu?
and?keom-pyu-teo-ri-sa-i-keul-reo?
are labeled as en-tity mentions with types of a person?s name and anorganization?s name respectively.
In addition, theinstance composed of the two projected entities isannotated as a positive instance, because its orig-inal instance on the English sentence also has asemantic relationship.As the description suggests, the annotation pro-jection approach is highly dependant on the qual-ity of word alignment.
However, the results of au-tomatic word alignment may include several noisyor incomplete alignments because of technical dif-ficulties.
We present details to tackle the problemby relieving the influence of alignment errors inSection 3.2.3 AssessmentThe most important challenge for annotation pro-jection approaches is how to improve the robust-ness against the erroneous projections.
The noiseproduced by not only word alignment but alsomono-lingual annotations in L1 accumulates andbrings about a drastic decline in the quality of pro-jected annotations.The simplest policy of utilizing the projectedannotations for relation detection in L2 is to con-sider that all projected instances are equivalentlyreliable and to employ entire projections as train-ing instances for the task without any filtering.
Incontrast with this policy, which is likely to be sub-standard, we propose an alternative policy wherethe projected instances are assessed and only theinstances judged as reliable by the assessment areutilized for the task.
Details about the assessmentare provided in Section 3.3 Noise Reduction StrategiesThe efforts to reduce noisy projections are consid-ered indispensable parts of the projection-basedrelation detection method in a resource-poor lan-guage.
Our noise reduction approach includes thefollowing three strategies: heuristic-based align-ment filtering, dictionary-based alignment correc-tion, and assessment-based instance selection.3.1 Heuristic-based Alignment FilteringIn order to improve the performance of annotationprojection approaches, we should break the bottle-neck caused by the low quality of automatic wordalignment results.
As relation detection is carriedout for each instance consisting of two entity men-tions, the annotation projection for relation detec-tion concerns projecting only entity mentions and566their relational instances.
Since this is differentfrom other shallower tasks such as part-of-speechtagging, base phrase chunking, and dependencyparsing which should consider projections for allword units, we define and apply some heuristicsspecialized to projections of entity mentions andrelation instances to improve robustness of themethod against erroneous alignments, as follows:?
A projection for an entity mention shouldbe based on alignments between contiguousword sequences.
If there are one or moregaps in the word sequence in L2 alignedwith an entity mention in the sentence inL1, we assume that the corresponding align-ments are likely to be erroneous.
Thus, thealignments of non-contiguous words are ex-cluded in projection.?
Both an entity mention in L1 and its projec-tion in L2 should include at least one basenoun phrase.
If no base noun phrase oc-curs in the original entity mention in L1, itmay suggest some errors in annotation forthe sentence in L1.
The same case for theprojected instance raises doubts about align-ment errors.
The alignments between wordsequences without any base noun phrase arefiltered out.?
The projected instance in L2 should sat-isfy the clausal agreement with the originalinstance in L1.
If entities of an instanceare located in the same clause (or differ-ent clauses), its projected instance should bein the same manner.
The instances withoutclausal agreement are ruled out.3.2 Dictionary-based Alignment CorrectionThe errors in word alignment are composed ofnot only imprecise alignments but also incompletealignments.
If an alignment of an entity amongtwo entities of a relation instance is not providedin the result of the word alignment task, the pro-jection for the corresponding instance is unavail-able.
Unfortunately, the above-stated alignmentfiltering heuristics for improving the quality ofprojections make the annotation loss problemsworse by filtering out several alignments likely tobe noisy.In order to solve this problem, a dictionary-based alignment correction strategy is incorpo-rated in our method.
The strategy requires a bilin-gual dictionary for entity mentions.
Each entry ofthe dictionary is a pair of entity mention in L1 andits translation or transliteration in L2.
For eachentity to be projected from the sentence in L1,its counterpart in L2 is retrieved from the bilin-gual dictionary.
Then, we seek the retrieved entitymention from the sentence in L2 by finding thelongest common subsequence.
If a subsequencematched to the retrieved mention is found in thesentence in L2, we make a new alignment betweenit and its original entity on the L1 sentence.3.3 Assessment-based Instance SelectionThe reliabilities of instances projected via a seriesof independent modules are different from eachother.
Thus, we propose an assessment strategyfor each projected instance.
To evaluate the reli-ability of a projected instance in L2, we use theconfidence score of monolingual relation detec-tion for the original counterpart instance in L1.The acceptance of a projected instance is deter-mined by whether the score of the instance islarger than a given threshold value ?.
Only ac-cepted instances are considered as the results ofannotation projection and applied to solve the re-lation detection task in target language L2.4 Experimental SetupTo demonstrate the effectiveness of our cross-lingual annotation projection approach for rela-tion detection, we performed an experiment onrelation detection in Korean text with propagatedannotations from English resources.4.1 AnnotationThe first step to evaluate our method was annotat-ing the English sentences in a given parallel cor-pus.
We use an English-Korean parallel corpuscrawled from an English-Korean dictionary on theweb.
The parallel corpus consists of 454,315 bi-sentence pairs in English and Korean 2.
The En-glish sentences in the parallel corpus were prepro-2The parallel corpus collected and other resources are allavailable in our websitehttp://isoft.postech.ac.kr/?megaup/research/resources/567cessed by the Stanford Parser 3 (Klein and Man-ning, 2003) which provides a set of analyzed re-sults including part-of-speech tag sequences, a de-pendency tree, and a constituent parse tree for asentence.The annotation for English sentences is di-vided into two subtasks: entity mention recogni-tion and relation detection.
We utilized an off-the-shelf system, Stanford Named Entity Recog-nizer 4 (Finkel et al, 2005) for detecting entitymentions on the English sentences.
The totalnumber of English entities detected was 285,566.Each pair of recognized entities within a sentencewas considered as an instance for relation detec-tion.A classification model learned with the train-ing set of the ACE 2003 corpus which con-sists of 674 documents and 9,683 relation in-stances was built for relation detection in English.In our implementation, we built a tree kernel-based SVM model using SVM-Light 5 (Joachims,1998) and Tree Kernel Tools 6 (Moschitti, 2006).The subtree kernel method (Moschitti, 2006) forshortest path enclosed subtrees (Zhang et al,2006) was adopted in our model.
Our rela-tion detection model achieved 81.2/69.8/75.1 inPrecision/Recall/F-measure on the test set of theACE 2003 corpus, which consists of 97 docu-ments and 1,386 relation instances.The annotation of relations was performed bydetermining the existence of semantic relationsfor all 115,452 instances with the trained modelfor relation detection.
The annotation detected22,162 instances as positive which have semanticrelations.4.2 ProjectionThe labels about entities and relations in the En-glish sentences of the parallel corpora were propa-gated into the corresponding sentences in Korean.The Korean sentences were preprocessed by ourpart-of-speech tagger 7 (Lee et al, 2002) and a de-pendency parser implemented by MSTParser with3http://nlp.stanford.edu/software/lex-parser.shtml4http://nlp.stanford.edu/software/CRF-NER.shtml5http://svmlight.joachims.org/6http://disi.unitn.it/?moschitt/Tree-Kernel.htm7http://isoft.postech.ac.kr/?megaup/research/postag/Filter Without assessing With assessingnone 97,239 39,203+ heuristics 31,652 12,775+ dictionary 39,891 17,381Table 1: Numbers of projected instancesa model trained on the Sejong corpus (Kim, 2006).The annotation projections were performed onthe bi-sentences of the parallel corpus followedby descriptions mentioned in Section 2.2.
Thebi-sentences were processed by the GIZA++ soft-ware (Och and Ney, 2003) in the standard con-figuration in both English-Korean and Korean-English directions.
The bi-direcional alignmentswere joined by the grow-diag-final algorithm,which is widely used in bilingual phrase extrac-tion (Koehn et al, 2003) for statistical machinetranslation.
This system achieved 65.1/41.6/50.8in Precision/Recall/F-measure in our evaluationof 201 randomly sampled English-Korean bi-sentences with manually annotated alignments.The number of projected instances varied withthe applied strategies for reducing noise as shownin Table 1.
Many projected instances were fil-tered out by heuristics, and only 32.6% of the in-stances were left.
However, several instances wererescued by dictionary-based alignment correctionand the number of projected instances increasedfrom 31,652 to 39,891.
For all cases of noise re-duction strategies, we performed the assessment-based instance selection with a threshold value ?of 0.7, which was determined empirically throughthe grid search method.
About 40% of the pro-jected instances were accepted by instance selec-tion.4.3 EvaluationIn order to evaluate our proposed method, we pre-pared a dataset for the Korean RDC task.
Thedataset was built by annotating the informationabout entities and relations in 100 news docu-ments in Korean.
The annotations were performedby two annotators following the guidelines for theACE corpus processed by LDC.
Our Korean RDCcorpus consists of 835 sentences, 3,331 entitymentions, and 8,354 relation instances.
The sen-568Model w/o assessing with assessingP R F P R FBaseline 60.5 20.4 30.5 - - -Non-filtered 22.5 6.5 10.0 29.1 13.2 18.2Heuristic 51.4 15.5 23.8 56.1 22.9 32.5Heuristic + Dictionary 55.3 19.4 28.7 59.8 26.7 36.9Table 2: Experimental Resultstences of the corpus were preprocessed by equiva-lent systems used for analyzing Korean sentencesfor projection.
We randomly divided the datasetinto two subsets with the same number of in-stances for use as a training set to build the base-line system and for evaluation.For evaluating our approach, training instancesets to learn models were prepared for relationdetection in Korean.
The instances of the train-ing set (half of the manually built Korean RDCcorpufs) were used to train the baseline model.All other sets of instances include these baselineinstances and additional instances propagated bythe annotation projection approach.
The train-ing sets with projected instances are categorizedinto three groups by the level of applied strategiesfor noise reduction.
While the first set includedall projections without any noise reduction strate-gies, the second included only the instances ac-cepted by the heuristics.
The last set consisted ofthe results of a series of heuristic-based filteringand dictionary-based correction.
For each trainingset with projected instances, an additional set wasderived by performing assessment-based instanceselection.We built the relation detection models for allseven training sets (a baseline set, three pro-jected sets without assessing, and three pro-jected sets with assessing).
Our implementationsare based on the SVM-Light and Tree KernelTools described in the former subsection.
Theshortest path dependency kernel (Bunescu andMooney, 2005) implemented by the subtree kernelmethod (Moschitti, 2006) was adopted to learn allmodels.The performance for each model was evaluatedwith the predictions of the model on the test set,which was the other half of Korean RDC corpus.We measured the performances of the models ontrue entity mentions with true chaining of coref-erence.
Precision, Recall and F-measure wereadopted for our evaluation.5 Experimental ResultsTable 2 compares the performances of the differ-ent models which are distinguished by the appliedstrategies for noise reduction.
It shows that:?
The model with non-filtered projectionsachieves extremely poor performance due toa large number of erroneous instances.
Thisindicates that the efforts for reducing noiseare urgently needed.?
The heuristic-based alignment filtering helpsto improve the performance.
However, it ismuch worse than the baseline performancebecause of a falling-off in recall.?
The dictionary-based correction to our pro-jections increased both precision and recallcompared with the former models with pro-jected instances.
Nevertheless, it still fails toachieve performance improvement over thebaseline model.?
For all models with projection, theassessment-based instance selection booststhe performances significantly.
This meansthat this selection strategy is crucial inimproving the performance of the modelsby excluding unreliable instances with lowconfidence.?
The model with heuristics and assessmentsfinally achieves better performance than thebaseline model.
This suggests that the pro-jected instances have a beneficial influence569on the relation detection task when at leastthese two strategies are adopted for reducingnoises.?
The final model incorporating all proposednoise reduction strategies outperforms thebaseline model by 6 in F-measure.
This isdue to largely increased recall by absorbingmore useful features from the well-refinedset of projected instances.The experimental results show that our pro-posed techniques effectively improve the perfor-mance of relation detection in the resource-poorKorean language with a set of annotations pro-jected from the resource-rich English language.6 ConclusionThis paper presented a novel cross-lingual annota-tion projection method for relation extraction in aresource-poor language.
We proposed methods ofpropagating annotations from a resource-rich lan-guage to a target language via parallel corpora.
Inorder to relieve the bad influence of noisy projec-tions, we focused on the strategies for reducing thenoise generated during the projection.
We appliedour methods to the relation detection task in Ko-rean.
Experimental results show that the projectedinstances from an English-Korean parallel corpushelp to improve the performance of the task whenour noise reduction strategies are adopted.We would like to introduce our method to theother subtask of relation extraction, which is re-lation categorization.
While relation detection isa binary classification problem, relation catego-rization can be solved by a classifier for multi-ple classes.
Since the fundamental approachesof the two tasks are similar, we expect that ourprojection-based relation detection methods canbe easily adapted to the relation categorizationtask.For this further work, we are concerned aboutthe problem of low performance for Korean,which was below 40 for relation detection.
The re-lation categorization performance is mostly lowerthan detection because of the larger number ofclasses to be classified, so the performance ofprojection-based approaches has to be improvedin order to apply them.
An experimental resultof this work shows that the most important factorin improving the performance is how to select thereliable instances from a large number of projec-tions.
We plan to develop more elaborate strate-gies for instance selection to improve the projec-tion performance for relation extraction.AcknowledgementThis research was supported by the MKE (TheMinistry of Knowledge Economy), Korea, un-der the ITRC (Information Technology ResearchCenter) support program supervised by the NIPA(National IT Industry Promotion Agency) (NIPA-2010-C1090-1031-0009).ReferencesBunescu, Razvan C. and Raymond J. Mooney.
2005.A shortest path dependency kernel for relation ex-traction.
In Proceedings of the conference on Hu-man Language Technology and Empirical Methodsin Natural Language Processing, page 724731.Chen, Jinxiu, Donghong Ji, Chew Lim Tan, andZhengyu Niu.
2006.
Relation extraction using la-bel propagation based semi-supervised learning.
InProceedings of the 21st International Conferenceon Computational Linguistics and the 44th annualmeeting of the Association for Computational Lin-guistics, pages 129?136, Sydney, Australia.
Associ-ation for Computational Linguistics.Culotta, Aron and Jaffrey Sorensen.
2004.
Depen-dency tree kernels for relation extraction.
In Pro-ceedings of ACL, volume 4.Doddington, George, Alexis Mitchell, Mark Przy-bocki, Lance Ramshaw, Stephanie Strassel, andRalph Weischedel.
2004.
The automatic contentextraction (ACE) programtasks, data, and evalua-tion.
In Proceedings of LREC, volume 4, page837840.Finkel, Jenny R., Trond Grenager, and ChristopherManning.
2005.
Incorporating non-local informa-tion into information extraction systems by gibbssampling.
In Proceedings of the 43rd Annual Meet-ing on Association for Computational Linguistics,volume 43, page 363.Hwa, Rebecca, Philip Resnik, Amy Weinberg, ClaraCabezas, and Okan Kolak.
2005.
Bootstrappingparsers via syntactic projection across parallel texts.Natural Language Engineering, 11(03):311?325.570Joachims, Thorsten.
1998.
Text categorization withsupport vector machines: Learning with many rele-vant features.
In Proceedings of the European Con-ference on Machine Learning, pages 137?142.Kambhatla, Nanda.
2004.
Combining lexical, syntac-tic, and semantic features with maximum entropymodels for extracting relations.
In Proceedings ofthe ACL 2004 on Interactive poster and demonstra-tion sessions, page 22, Barcelona, Spain.
Associa-tion for Computational Linguistics.Kim, Hansaem.
2006.
Korean national corpus in the21st century sejong project.
In Proceedings of the13th NIJL International Symposium, page 4954.Klein, Dan and Christopher D. Manning.
2003.
Ac-curate unlexicalized parsing.
In Proceedings of the41st Annual Meeting on Association for Computa-tional Linguistics - Volume 1, pages 423?430, Sap-poro, Japan.
Association for Computational Lin-guistics.Koehn, Philipp, Franz Josef Och, and Daniel Marcu.2003.
Statistical phrase-based translation.
In Pro-ceedings of the 2003 Conference of the North Amer-ican Chapter of the Association for ComputationalLinguistics on Human Language Technology, vol-ume 1, pages 48?54.Lee, Gary Geunbae, Jeongwon Cha, and Jong-HyeokLee.
2002.
Syllable pattern-based unknown mor-pheme segmentation and estimation for hybrid part-of-speech tagging of korean.
Computational Lin-guistics, 28(1):53?70.Merlo, Paola, Suzanne Stevenson, Vivian Tsang, andGianluca Allaria.
2002.
A multilingual paradigmfor automatic verb classification.
In Proceedings ofthe 40th Annual Meeting on Association for Compu-tational Linguistics, pages 207?214, Philadelphia,Pennsylvania.
Association for Computational Lin-guistics.Moschitti, Alessandro.
2006.
Making tree kernelspractical for natural language learning.
In Proceed-ings of EACL06.Och, Franz Josef and Hermann Ney.
2003.
A sys-tematic comparison of various statistical alignmentmodels.
Computational Linguistics, 29(1):19?51,March.Pado, Sebastian and Mirella Lapata.
2009.Cross-lingual annotation projection of semanticroles.
Journal of Artificial Intelligence Research,36(1):307340.Yarowsky, David and Grace Ngai.
2001.
Inducingmultilingual POS taggers and NP bracketers via ro-bust projection across aligned corpora.
In Secondmeeting of the North American Chapter of the Asso-ciation for Computational Linguistics on Languagetechnologies 2001, pages 1?8, Pittsburgh, Pennsyl-vania.
Association for Computational Linguistics.Yarowsky, David, Grace Ngai, and Richard Wicen-towski.
2001.
Inducing multilingual text analysistools via robust projection across aligned corpora.In Proceedings of the first international conferenceon Human language technology research, pages 1?8, San Diego.
Association for Computational Lin-guistics.Zelenko, Dmitry, Chinatsu Aone, and AnthonyRichardella.
2003.
Kernel methods for relation ex-traction.
J. Mach.
Learn.
Res., 3:1083?1106.Zhang, Min, Jie Zhang, Jian Su, and Guodong Zhou.2006.
A composite kernel to extract relations be-tween entities with both flat and structured features.In Proceedings of the 21st International Conferenceon Computational Linguistics and the 44th annualmeeting of the Association for Computational Lin-guistics, pages 825?832, Sydney, Australia.
Associ-ation for Computational Linguistics.Zhang, Zhu.
2004.
Weakly-supervised relation clas-sification for information extraction.
In Proceed-ings of the thirteenth ACM international conferenceon Information and knowledge management, pages581?588, Washington, D.C., USA.
ACM.Zhou, Guodong, Jian Su, Jie Zhang, and Min Zhang.2005.
Exploring various knowledge in relation ex-traction.
In Proceedings of the 43rd Annual Meetingon Association for Computational Linguistics, page434.Zitouni, Imed and Radu Florian.
2008.
Mention detec-tion crossing the language barrier.
In Proceedingsof the Conference on Empirical Methods in NaturalLanguage Processing, pages 600?609, Honolulu,Hawaii.
Association for Computational Linguistics.571
