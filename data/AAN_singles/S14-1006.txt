Proceedings of the Third Joint Conference on Lexical and Computational Semantics (*SEM 2014), pages 51?56,Dublin, Ireland, August 23-24 2014.Exploring ESA to Improve Word RelatednessNitish Aggarwal Kartik Asooja Paul BuitelaarInsight Centre for Data AnalyticsNational University of IrelandGalway, Irelandfirstname.lastname@deri.orgAbstractExplicit Semantic Analysis (ESA) is an ap-proach to calculate the semantic relatednessbetween two words or natural language textswith the help of concepts grounded in humancognition.
ESA usage has received much at-tention in the field of natural language pro-cessing, information retrieval and text analy-sis, however, performance of the approach de-pends on several parameters that are includedin the model, and also on the text data typeused for evaluation.
In this paper, we investi-gate the behavior of using different number ofWikipedia articles in building ESA model, forcalculating the semantic relatedness for differ-ent types of text pairs: word-word, phrase-phrase and document-document.
With ourfindings, we further propose an approach toimprove the ESA semantic relatedness scoresfor words by enriching the words with theirexplicit context such as synonyms, glosses andWikipedia definitions.1 IntroductionExplicit Semantic Analysis (ESA) is a distributionalsemantic model (Harris, 1954) that computes therelatedness scores between natural language textsby using high dimensional vectors.
ESA buildsthe high dimensional vectors by using the explicitconcepts defined in human cognition.
Gabrilovichand Markovitch (2007) introduced the ESA modelin which Wikipedia and Open Directory Project1was used to obtain the explicit concepts.
ESA con-siders every Wikipedia article as a unique explicit1http://www.dmoz.orgtopic.
It also assumes that the articles are topicallyorthogonal.
However, recent work (Gottron etal., 2011) has shown that by using the documentsfrom Reuters corpus instead of Wikipedia articlescan also achieve comparable results.
ESA modelincludes various parameters (Sorg and Cimiano,2010) that play important roles on its performance.Therefore, the model requires further investigationin order to better tune the parameters.ESA model has been adapted very quickly indifferent fields related to text analysis, due to thesimplicity of its implementation and the availabilityof Wikipedia corpus.
Gabrilovich and Markovitch(2007) evaluated the ESA against word relatednessdataset WN353 (Finkelstein et al., 2001) and doc-ument relatedness dataset Lee50 (Lee et al., 2005)by using all the articles from Wikipedia snapshot of11 Nov, 2005.
However, the results reported usingdifferent implementations (Polajnar et al., 2013)(Hassan and Mihalcea, 2011) of ESA on samedatasets (WN353 and Lee50) vary a lot, due thespecificity of ESA implementation.
For instance,Hassan and Mihalcea (2011) found a significantdifference between the scores obtained from theirown implementation and the scores reported in theoriginal article (Gabrilovich and Markovitch, 2007).In this paper, first, we investigate the behaviorof ESA model in calculating the semantic related-ness for different types of text pairs: word-word,phrase-phrase and document-document by usingdifferent number of Wikipedia articles for buildingthe model.
Second, we propose an approach51for context enrichment of words to improve theperformance of ESA on word relatedness task.2 BackgroundThe ESA model can be described as a method ofobtaining the relatedness score between two texts byquantifying the distance between two high dimen-sional vectors.
Every explicit concept represents adimension of the ESA vector, and the associativityweight of a given word with the explicit conceptcan be taken as magnitude of the correspondingdimension.
For instance, there is a word t, ESAbuilds a vector v, where v =?Ni=0ai?
ciand ciisithconcept from the explicit concept space, and aiis the associativity weight of word t with the conceptci.
Here, N represents the total number of concepts.In our implementation, we build ESA model byusing Wikipedia articles as explicit concepts, andtake the TFIDF weights as associativity strength.Similarly, ESA builds the vector for natural lan-guage text by considering it as a bag of words.
LetT = {t1, t2, t3...tn}, where T is a natural languagetext that has n words.
ESA generates the vectorV, where V =?tkTvkand v =?Ni=0ai?
ci.
vkrepresents the ESA vector of a individual words asexplained above.
The relatedness score between twonatural language texts is calculated by computingcosine product of their corresponding ESA vectors.In recent years, some extensions (Polajnar etal., 2013) (Hassan and Mihalcea, 2011) (Scholl etal., 2010) have been proposed to improve the ESAperformance, however, they have not discussed theconsistency in the performance of ESA.
Polajnaret al.
(2013) used only 10,000 Wikipedia articlesas the concept space, and got significantly differentresults on the previously evaluated datasets.
Hassanand Mihalcea (2011) have not discussed the ESAimplementation in detail but obtained significantlydifferent scores.
Although, these proposed exten-sions got different baseline ESA scores but theyimprove the relatedness scores with their additions.Polajnar et al.
(2013) used the concept-conceptcorrelation to improve the ESA model.
Hassan andMihalcea (2011) proposed a model similar to ESA,which builds the high dimensional vector of salientconcepts rather than explicit concepts.
Gortton etal.
(2011) investigated the ESA performance fordocument relatedness and showed that ESA scoresare not tightly dependent on the explicit conceptspaces.Minimum unique Total number ofwords (K) articles (N)100 438379300 110900500 46035700 23608900 137181100 83221300 52411500 33291700 21261900 1368Table 1: The total number of retrieved articles for differ-ent values of K3 Investigation of ESA modelAlthough Gortton et al.
(2011) has shown that ESAperformance on document pairs does not get af-fected by using different number of Wikipedia ar-ticles, we further examine it for word-word andphrase-phrase pairs.
We use three different datasetsWN353, SemEvalOnWN (Agirre et al., 2012) andLee50.
WN353 contains 353 word pairs, SemEval-OnWN consists of 750 short phrase/sentence pairs,and Lee50 is a collection of 50 document pairs.All these datasets contain relatedness scores givenby human annotators.
We evaluate ESA modelon these three datasets against different number ofWikipedia articles.
In order to select different num-ber of Wikipedia articles, we sort them according tothe total number of unique words appearing in eacharticle.
We select N articles, where N is total num-ber of articles which have at least K unique words.Table 1 shows the total number of retrieved articlesfor different values of K. We build 20 different ESAmodels with the different values of N retrieved byvarying K from 100 to 2000 with an interval of 100.Figure 1 illustrates Spearman?s rank correlation ofall the three types of text pairs on Y-axis while X-axis shows the different values of N which are takento build the model.
It shows that ESA model gener-ates very consistent results for phrase pairs similarto the one reported in (Aggarwal et al., 2012), how-52Figure 1: ESA performance on different types of textpairs by varying the total number of articlesever, the correlation scores decreases monotonouslyin the case of word pairs as the number of articlesgoes down.
In the case of document pairs, ESA pro-duces similar results until the value of N is chosenaccording to K = 1000, but after that, it decreasesquickly because the number of articles becomes toolow for making a good enough ESA model.
All thisindicates that word-word relatedness scores have astrong impact of changing the N in comparison ofdocument-document or phrase-phrase text pairs.
Anexplanation to this is that the size of the ESA vec-tor for a word solely depends upon the popularityof the given word, however, in the case of text, thevector size depends on the popularity summation ofall the words appearing in the given text.
It suggeststhat the word relatedness problem can be reduced toshort text relatedness by adding some related con-text with the given word.
Therefore, to improvethe ESA performance for word relatedness, we pro-pose an approach for context enrichment of words.We perform context enrichment by concatenating re-lated context with the given word and use this con-text to build the ESA vector, which transforms theword relatedness problem to phrase relatedness.4 Context EnrichmentContext enrichment is performed by concatenatingthe context defining text to the given word beforebuilding the ESA vector.
Therefore, instead of build-ing the ESA vector of a word, the vector is built forthe short text that is obtained after concatenating therelated context.
This is similar to classical query ex-pansion task (Aggarwal and Buitelaar, 2012; Pan-tel and Fuxman, 2011), where related concepts areconcatenated with a query to improve the informa-tion retrieval performance.
We propose three differ-ent methods to obtain related context: 1) WordNet-based Context Enrichment 2) Wikipedia-based Con-text Enrichment, and 3) WikiDefinition-based Con-text Enrichment.4.1 WordNet-based Context EnrichmentWordNet-based context enrichment uses the Word-Net synonyms to obtain the context, and concate-nates them into the given word to build the ESA vec-tor.
However, WordNet may contain more than onesynset for a word, where each synset represents adifferent semantic sense.
Therefore, we obtain morethan one contexts for a given word, by concatenat-ing the different synsets.
Further, we calculate ESAscore of every context of a given word against all thecontexts of the other word which is being compared,and consider the highest score as the final related-ness score.
For instance, there is a given word pair?train and car?, car has 8 different synsets that build8 different contexts, and train has 6 different synsetsthat build 6 different contexts.
We calculate the ESAscore of these 8 contexts of car to the 6 contexts oftrain, and finally select the highest obtained scorefrom all of the 24 calculated scores.4.2 Wikipedia-based Context EnrichmentIn this method, the context is defined by the wordusage in Wikipedia articles.
We retrieve top 5Wikipedia articles by querying the articles?
content,and concatenate the short abstracts of the retrievedarticles to the given word to build the ESA vector.Short abstract is the first two sentences of Wikipediaarticle and has a maximum limit of 500 characters.In order to retrieve the top 5 articles from Wikipediafor a given word, we build an index of all Wikipediaarticles and use TF-IDF scores.
We further explain53our implementation in Section 5.1.4.3 WikiDefinition-based Context EnrichmentThis method uses the definition of a given word fromWikipedia.
To obtain a definition from Wikipedia,we first try to find a Wikipedia article on the givenword by matching the Wikipedia title.
As definition,we take the short abstract of the Wikipedia article.For instance, for a given word ?train?, we take theWikipedia article with the title ?Train?2.
If there isno such Wikipedia article, then we use the previousmethod ?Wikipedia-based Context Enrichment?
toget the context defining text for the given word.
Incontrary to the previous method for defining context,here we first try to get a more precise context as itcomes from the Wikipedia article on that word only.After obtaining the definition, we concatenate it tothe given word to build the ESA vector.
At the timeof experimentation, we were able to find 339 wordsappearing as Wikipedia articles out of 437 uniquewords in the WN353 dataset.Figure 2: Effect of different types of context enrichmentson WN353 gold standard2http://en.wikipedia.org/wiki/Train5 Experiment5.1 ESA implementationIn this section, we describe the implementation ofESA and the parameters used to build the model.We build an index over all Wikipedia articles fromthe pre-processed Wikipedia dump from November11, 2005 (Gabrilovich, 2006).
We use Lucene3tobuild the index and retrieve the articles using TF-IDF scores.
As described in section 3, we build 20different indices with different values of total num-ber of articles (N).5.2 Results and DiscussionTo evaluate the effect of the aforementionedapproaches for context enrichment, we comparethe results obtained by them against the resultsgenerated by ESA model as a baseline.
We cal-culated the scores on WN353 word pairs datasetby using ESA, WordNet-based Context Enrich-ment (ESA CEWN), Wikipedia-based ContextEnrichment (ESA CEWiki) and WikiDefition-basedContext Enrichment (ESA CEWikiDef).
Further,we examine the performance of context enrichmentapproaches by reducing the total number of articlestaken to build the model.
Figure 2 shows that theproposed methods of context enrichment signifi-cantly improve over the ESA scores for differentvalues of N.Table 2 reports the results obtained by usingdifferent context enrichments and ESA model.It shows Spearman?s rank correlation on fourdifferent values of N. All the proposed con-text enrichment methods improve over the ESAbaseline scores.
Context enrichments based onWikipedia outperforms the other methods, andESA CEWikiDef significantly improves over theESA baseline.
Moreover, given a very less numberof Wikipedia articles used for building the model,ESA CEWikiDef obtains a correlation score whichis considerably higher than the one obtained byESA baseline.
ESA CEWN and ESA CEWiki caninclude some unrelated context as they do not careabout the semantic sense of the given word, forinstance, for a given word ?car?, ESA CEWiki3https://lucene.apache.org/54K Total articles (N) ESA ESA CEWN ESA CEWiki ESA CEWikiDef100 438,379 0.711 0.692 0.724 0.741200 221,572 0.721 0.707 0.726 0.743500 46,035 0.673 0.670 0.679 0.6981000 10,647 0.563 0.593 0.598 0.614Table 2: Spearman rank correlation scores on WN353 gold standardincludes the context about the word ?car?
at surfacelevel rather than at the semantic level.
However,ESA CEWikiDef only includes the definition if itdoes not refer to more than one semantic sense,therefore, ESA CEWikiDef outperforms all othertypes of context enrichment.We achieved best results in all the cases by tak-ing all the articles which has a minimum of 200unique words (K=200).
This indicates that furtherincreasing the value of K considerably decreasesthe value of N, consequently, it harms the overalldistributional knowledge of the language, which isthe core of ESA model.
However, decreasing thevalue of K introduces very small Wikipedia articlesor stubs, which do not provide enough content on asubject.6 ConclusionIn this paper, we investigated the ESA performancefor three different types of text pairs: word-word,phrase-phrase and document-document.
We showedthat ESA scores varies significantly for word re-latedness measure with the change in the number(N) and length (?K which is the number of uniquewords) of the Wikipedia articles used for buildingthe model.
Further, we proposed context enrichmentapproaches for improving word relatedness compu-tation by ESA.
To this end, we presented three dif-ferent approaches: 1) WordNet-based, 2) Wikipedia-based, and 3) WikiDefinition-based, and we real-ized that concatenating the context defining text im-proves the ESA performance for word relatednesstask.AcknowledgmentsThis work has been funded in part by a researchgrant from Science Foundation Ireland (SFI) underGrant Number SFI/12/RC/2289 (INSIGHT) and bythe EU FP7 program in the context of the projectLIDER (610782).ReferencesNitish Aggarwal and Paul Buitelaar.
2012.
Query expan-sion using wikipedia and dbpedia.
In CLEF.Nitish Aggarwal, Kartik Asooja, and Paul Buitelaar.2012.
DERI&UPM: Pushing corpus based relatednessto similarity: Shared task system description.
In Pro-ceedings of the First Joint Conference on Lexical andComputational Semantics - Volume 1: Proceedings ofthe Main Conference and the Shared Task, and Volume2: Proceedings of the Sixth International Workshop onSemantic Evaluation, SemEval ?12, pages 643?647,Stroudsburg, PA, USA.
Association for ComputationalLinguistics.Eneko Agirre, Mona Diab, Daniel Cer, and AitorGonzalez-Agirre.
2012.
Semeval-2012 task 6: A piloton semantic textual similarity.
In Proceedings of theFirst Joint Conference on Lexical and ComputationalSemantics-Volume 1: Proceedings of the main confer-ence and the shared task, and Volume 2: Proceedingsof the Sixth International Workshop on Semantic Eval-uation, pages 385?393.
Association for ComputationalLinguistics.Lev Finkelstein, Evgeniy Gabrilovich, Yossi Matias,Ehud Rivlin, Zach Solan, Gadi Wolfman, and EytanRuppin.
2001.
Placing search in context: The con-cept revisited.
In Proceedings of the 10th internationalconference on World Wide Web, pages 406?414.
ACM.Evgeniy Gabrilovich and Shaul Markovitch.
2007.
Com-puting semantic relatedness using wikipedia-basedexplicit semantic analysis.
In Proceedings of the20th international joint conference on Artifical intel-ligence, IJCAI?07, pages 1606?1611, San Francisco,CA, USA.
Morgan Kaufmann Publishers Inc.Evgeniy Gabrilovich.
2006.
Feature generation fortextual information retrieval using world knowledge.Ph.D.
thesis, Technion - Israel Institute of Technology,Haifa, Israel, December.Thomas Gottron, Maik Anderka, and Benno Stein.
2011.Insights into explicit semantic analysis.
In Proceed-ings of the 20th ACM international conference on In-formation and knowledge management, pages 1961?1964.
ACM.Zellig Harris.
1954.
Distributional structure.
In Word 10(23), pages 146?162.55Samer Hassan and Rada Mihalcea.
2011.
Semantic re-latedness using salient semantic analysis.
In AAAI.Michael David Lee, BM Pincombe, and Matthew BrianWelsh.
2005.
An empirical evaluation of models oftext document similarity.
Cognitive Science.Patrick Pantel and Ariel Fuxman.
2011.
Jigs and lures:Associating web queries with structured entities.
InACL, pages 83?92.Tamara Polajnar, Nitish Aggarwal, Kartik Asooja, andPaul Buitelaar.
2013.
Improving esa with docu-ment similarity.
In Advances in Information Retrieval,pages 582?593.
Springer.Philipp Scholl, Doreen B?ohnstedt, Renato Dom??nguezGarc?
?a, Christoph Rensing, and Ralf Steinmetz.
2010.Extended explicit semantic analysis for calculatingsemantic relatedness of web resources.
In Sustain-ing TEL: From Innovation to Learning and Practice,pages 324?339.
Springer.Philipp Sorg and Philipp Cimiano.
2010.
An experi-mental comparison of explicit semantic analysis im-plementations for cross-language retrieval.
In NaturalLanguage Processing and Information Systems, pages36?48.
Springer.56
