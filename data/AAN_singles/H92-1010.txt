Spoken Language Processing in the Framework of Human-Mach ineCommunicat ion  at LIMSIJ.
MarianiL IMSI -CNRS,  BP  13391403 Orsuy cedex, FRANCEmar ian i@fr t im51.b i tnet  or mar ian iQ l ims i .
f rABSTRACTThe paper provides an overview of the research conducted atLIMSI in the field of speech processing, but also in the related ar-eas of Human-Machine Communication, i cluding Natural Lan-guage Processing, Non Verbal and Multimodal Communication.Also presented are the commercial pplications ofsome of the re-search projects.
When applicable, the discussion is placed in theframework of international collaborations.INTRODUCTIONThe initial work on Text-to-Speech synthesis and Word-Based recognition resulted in the development of softwareand hardware (including an Asic) systems which have sincebeen marketed, and used in different applications uch ascockpit design.
Some of the problems encountered in theirpractical use are discussed.
The development of a speakerverification system presently under test field trials is alsopresented.Our speech research program is now oriented along twomain axes: Voice Dictation and Spoken Dialog.
The suc-cessive steps of the voice dictation project are presented,and the difficulties pecific to the French language in thistask are highlighted.
For the dialog project, the integra-tion of linguistic and pragmatic information with continuousspeech recognition in the context of air controller training isdescribed.While this paper focuses on our speech processingprojects, other efforts in related areas, such as characterrecognition and computer vision with algorithms derivedfrom those developed for speech processing are mentioned.Speech processing is placed in the general framework ofHuman-Machine Communication.
This is reflected in thestructure of the laboratory, by the relationship of the SpeechCommunication group with the two other components ofthe Human-Machine Communication department: he Lan-guage ~ Cognition and Non- Verbal Communication groups.When applicable, the projects of the laboratory are situatedin the general context of European/international coopera-tive actions.
Perspectives on the directions of research aregiven.L IMS I  & CNRSThe LIMSI laboratory is a "full" CNRS (French NationalResearch Agency) laboratory.
The acronym stands for "Lab-oratoire d'Informatique pour la M6canique t les Sciencesde t'Ing6nieur" (Laboratory of Informatics for Mechanical,Chemical and Electrical Engineering).CNRS is the French National Research Agency.
It wascreated in 1939.
With 12,000 permanent researchers and15,000 permanent technical and administrative staff, it isprobably the largest research institution in Europe.
It has375 full laboratories, and 1000 academic "associated" labo-ratories.
The 1991 budget of CNRS was 2,000 M$ (74% forsalaries).
CNRS has a general director, and is divided into6 different scientific departments, each having a scientificdirector.
LIMSI is attached to the "Engineering Sciences"department, with a secondary attachment to the "Social andHuman Sciences" Department.There are also 40 advisory committees, forming the "Na-tional Committee for Scientific Research", and correspond-ing to general research areas.
Those committees are respon-sible for evaluating the quality of each laboratory and ofeach researcher.
LIMSI is principally attached to the com-mittee 7 (Information Sciences and Technologies: ComputerScience, Control and Signal Processing), but has secondaryattachments o sections 10 (Chemical and Mechanical Engi-neering), 34 (Language Sciences), and may in the near futurebe attached to section 29 (Cognition and Psychology).For 1991, the laboratory staff comprised approximately180 members, with a total budget of 6 MS (60% for salaries).With J. Mariani as director, the laboratory is structured inDepartments, Groups and Research Topics, each with itsown manager.
It has two departments: Human-MachineCommunication, headed by J. Mariani and Mechanical andChemical Engineering, headed by P. Le Qu6r6, which willnot be presented here.THE HUMAN-MACHINE COMMUNICAT IONDEPARTMENTThe Human-Machine Communication department has atotal of about 100 persons (38 permanent researchers (CNRSand University, including 30 PhDs), 3 technical and adminis-trative staff, 38 PhD students and 36 postdoctoral, contrac-tual, associate and visiting researchers, or Master Thesis stu-dents).
There are 3 research groups: the Speech Communi-cation group, headed by F. N6el, the Language ?J Cognitiongroup, headed by G. Sabah, and the Non-Verbal Commu-55nication group, headed by D. Teil.
The groups are dividedin research topics, each being headed by a researcher.
Thisstructure is flexible, and researchers may participate in dif-ferent, research topics (see Appendix).The activities in Speech Communication i  the laboratorywere initiated in 1968 by Dr J.S.
Li~nard.
The group itselfwas created in 1981.
The Natural Language Processinggroupwas created in 1985, when a group headed by Dr G. Sabahat University Paris VI joined a group already situated atUniversity Paris XI, the location of LIMSI.
The Non-verbalCommunication group was created in Fall 1989, by mergingteams in the laboratory already working on 3D modeling,Computer Vision and Robotics.The Human-Machine Communication Department con-ducts research in closely related areas: Speech, Language,Vision and other means of communication between humansand machines.
These areas use common methodologies and,having them studied in the same laboratory, allows for an in-depth study of the different communication modes, which,we believe, is mandatory for the development of multimodalcommunication systems.
The research activities are multi-disciplinary, and deal with Computer Science, Linguistics,Cognitive Psychology and Neuro-Sciences, and have boththeoretical and applied aspects.The communication process is studied as a triplet Percep-tion - Production - Cognition: Perception by the machineof speech (that could be enlarged to any sound), of vision(with reading as a subpart), of touch or gesture; Productionof speech or text, image synthesis (that could be enlarged toSolid Modeling); And all the cognitive aspects related to di-alogue, reasoning, knowledge representation a d integrationof different communicatitm odes.
We try as much as possi-ble to :link the studies of production and perception (i.e.
theemission and reception of information), as it can be observedin speech recognition and synthesis, text analysis and gener-ation, scene analysis and image synthesis, movement sensingand effort feedback.The relationship between Language and Image processingis becoming more and more important, with the concept of"Intelligent Images", where the different parts of the imageare in agreement with their mutual constraints, and withthe constraints of the real physical world (Newton Law ofgravity, phenomena which occurs in an explosion ...).
Thoseimages need advanced Human-Machine Communication, asthe task is complex with commands like "Put the ball onthe table and make it bounce back".This opens the perspective of a true multimodal commu-nication system, including oral, written, visual and gestualcommunication, with the typical problems of multireferenceprocessing (like a voice message accompanied by a gesture).It can even be thought hat processing multiple communi-cation modes simultaneously is mandatory for each of themodes, as it is a necessity for knowledge acquisition in train-ing within self-organizing approaches.We find common methodologies in the different domains:signal processing techniques, tatistical or structural coding,Vector or Matrix Quantization i  Speech and Vision.
Pat-tern recognition techniques such as Hidden Markov Models,Markov Random Fields, Multi Layer Perceptrons, Boltz-mann Machines are used in speech, language and vision.Morphological, Lexical, Grammatical, Syntactic, Semanticor Pragmatic analysis are applicable to written and spokenlanguage, with specifics for speaking or writing.Finally, these domains also have the commonality of re-quiring a study of Human Factors (Ergonomics) for designof acceptable systems.THE SPEECH COMMUNICATION GROUPThe Speech Communication group produced very early aText-to-Speech stand-alone synthesis system in French (Ico-phone).
The Icophone V system was marketed in 1975 (andappeared in Electronics, June 1975) by the TITN company,and a single unit of this one cubic meter TTS system wassold (to the Iranian Minister of Education...) at that time.The TTS system used a battery of 44 analog oscillators toproduce diphone-based synthesis (using 427 diphones).
In1980, it was replaced by a single board digital version, Icolog,which is marketed by the Vecsys company.
The grapheme-to-phoneme conversion algorithm uses about 1,000 rules.
Ithas to take into account he difficult problem of liaisons be-tween words in French.Another early application was formant synthesis with afirst synthesizer designed in 1975 (Icophone VI).
A paral-lel formant synthesizer based on segmental rules is now be-ing developed in the framework of the CEC/Esprit Poly-glot project, and should be adapted for 7 different languageswithin the consortium.Together with the Text-to-Speech effort, research was con-ducted on segmentation f continuous speech into phonemesand speech recognition.
An analog speech segmentator, us-ing a 32 analog filters bank was presented in 1974 (J.S.
Li~-nard et al, 1974).
The speech recognition work addressedboth analytical phoneme recognition, in the design of a"Speech Understanding System" comparable to those de-veloped in the ARPA-SUR project (J. Mariani et al, 1978),and word-based recognition.The first approach was also aimed at designing a"phoneme vocoder', with a 50 b/s rate.
The experimentsconducted in this project showed that a phoneme recogni-tion rate of at least 85%, with no major recognition errors(like vowel/consonant substitutions), was necessary in orderto transmit a message that can be understood by the humanlistener (J.S.
Li~nard et al, 1977).The word-based approach took advantage of the idea thatthe stationary parts of the signal convey less, and morevariable information than transition parts (3.L.
Gauvain, J.Mariani, J.S.
Li~nard, 1983).
This led us to non-linear fixed-length compression for isolated word recognition (Morse sys-tem in 1980), and non-linear variable-length compression forconnected word recognition (Mozart system in 1982) (J.L.Gauvain, 3.
Mariani, 1982).
Both systems used templatematching via dynamic programming.
Both systems resultedin single-board products which were marketed by the Vecsyscompany.56Theses systems were the first IWR and CWR systemsmade in France and have been used in several applications,like Voice-activated telephone dialing (Jeumont-Sehneider,1985), or packet sorting (NMPP, 1983).
Most of these ap-plications provided the opportunity for experimenting withvoice input as a new communication means, and the marketstayed limited to a few units.
The application where mostefforts have been devoted was pilot-plane dialog.
In col-laboration with the Crouzet company, a program was con-ducted for the "Research and Technology Agency" (Dret)of the French DoD.
A flight with an IWR voice commandsystem with actual commands to the plane was made inJuly 1982, and was reported as the first voice-controlledflight.
The conclusions of the flight trials specified the needof continuous peech recognition, the necessity of a stablelevel of performances, whoever the pilot, and that voice in-put was especially interesting in critical conditions (high Gs,stress), which unfortunately correspond to adverse nviron-ments which tend to lower the recognition rates.The computing power needed for the Dynamic Program-ming algorithm led us to develop an Asic chip.
The MuPCD(Microprocessor for Dynamic Programming) was developedat Limsi, together with the Bull company on a contract ofthe Ministry of Telecommunications.
It was available in 1989(G. Qudnot et al, 1989).
It has 120,000 transistors in Cmos2 micron technology, and a power of 70 MOPS.
It allows forthe recognition of up to 5,000 isolated words, or 300 con-nected words.
This chip is used in the last generation ofVecsys Datavox recognition systems.The work on Language modeling was also an early projectat LIMSI.
It started with a set of experiments on the problemof phoneme-to-grapheme conversion in French.
A casual 9phoneme string can generate more than 32,000 possible com-binations of segmentation i to words, and spelfing of thosewords.
In many cases, the absence of pronunciation of themark of the plural (-s at the end of the nouns, -nt at the endof verbs), generates many of those homophones.
First, asimple heuristic was tried with a 20,000 word lexicon whichsegmented the phoneme string into the smallest number ofwords.
It gave good results for the segmentation task, butalso demonstrated the necessity of using a language model toimprove the quality.
This resulted in a collaboration with re-searchers using stochastic language modeling based on gram-matical categories for document retrieval, and results werereported in 1979 on phoneme-to-grapheme conversion with a270,000 word full-form lexicon (A. Andreewski et al, 1979).This approach was also applied to stenotype-to-graphemecouversion.Another area of research is speaker verification (J. Marianiet al, 1983).
The algorithm used for word-based recognitionwas adapted to speaker verification, with dynamic adapta-tion of the reference templates of the speaker to their dailyvariations.
The Sesame system was tested "live" at the Ma-chines Parlantes exhibition in 1985, and had an impostoracceptance of 4 per 1000 obtained with informal test condi-tions.
The system is currently in use in everyday operationalconditions as the entry system at LIMSI by about 100 userssince 1987.PRESENT PROJECTSIn the Speech Communication group, work is now con-ducted around two main projects: the Dictation project,and the Dialog project.In the dictation project, several steps have been taken inthe design of a Voice-Activated typewriter (VAT) in Frenchsince the beginning of the project 10 years ago.
Continuingthe study on phoneme-to-grapheme conversion, for contin-uous, error-free phonemic strings, using a large vocabularyand a natural anguage syntax, LIMSI participated in theESPRIT project 860 "Linguistic Analysis of the EuropeanLanguages".
In this framework, the approach for languagemodeling developed at LIMSI has been extended to 7 Eu-ropean languages.
The link between the language modeland the acoustic recognition was made, and resulted in acomplete system (Hamlet), for a limited vocabulary (2,000words), pronounced in isolation, and then to a 5,000 wordVAT system taking advantage of the existence of the spe-cialized MuPCD DTW chip.
The complete system wasdemonstrated in Spring 1988.
Now, work is being conductedwithin the ESPRIT Polyglot project, with the goal of de-signing speech-to-text and text-to-speech systems for the 7languages.
In this framework, the methods first developed atOlivetti for dictation in isolated mode is adapted to French,and other methods are being developed, based on discrete& tied-mixture HMMs, and TDNNs & TDNNs-HMMs com-binations, for continuous peech recognition.
Comparativetests are being conducted on part of the DARPA ResourceManagement Database.We have recorded BREF, a large read-speech corpus forFrench, containing over 36 GBytes of speech data from 120speakers.
The text materials were selected verbatim fromthe French newspaper Le Monde, so as to provide a largevocabulary (over 20,000 words) and a wide range of phoneticenvironments.
Separate text materials, with similar distri-butional properties, were selected for training, developmenttest and evaluation purposes.
A series of experiments for vo-cabulary independent phone recognition has been recentlycarried out using this corpus.
A baseline phone accuracyof 60% was obtained with context-independent phone mod-els, and no phone grammar, and a phone accuracy of 68.6%with context dependent phone models and a bigram phonelanguage model (J.L.
Gauvain, L. Lamel, this conference).The dialog project has been explored within the frame-work of the application of air-controller t aining.
Currently,the training sessions are limited by the availability of thehuman instructor who plays the role of a pilot.
Our goalis to replace him by a spoken dialog system.
This allowsfor more availability of the system, and also to have severalvoices corresponding todifferent pilots in the synthesis mod-ule.
In this project, speech understanding uses speech recog-nition in conjunction with a representation f the semanticand pragmatic knowledge related to the task.
While thelanguage is supposed to follow a pre-defined "phraseology",it is not the case most of the time.
The language modelis a bigram model based on grammatical categories.
The57probabilities for word successions are changed epending onthe previous step in the dialog (prediction), and correctionsof the recognized sentence can be made, using redundancywithin the sentence, and a word confusion matrix.
An evalu-ation test involving 6 speakers, and 5 scripts of an average of20 sentences each, prediction improved the results by 10%,and correction added an extra 18.5% (the sentence under-standing rate improved from 68% to 96.5%) (A. Matrouf etal., 1991).
Prior to this work, large "Wizard of Oz" experi-ments were conducted (D. Luzzati, 1984), and the linguisticanalysis of the resulting corpus in a train timetable nquirysystem simulation was realized (D. Luzzati, 1987).
In gen-eral, all the implementations u ed linguistic analysis of realcorpora in order to meet the user's needs.
The recording ofa spontaneous speech database (Spot) has also been started.Other research topics concern speech signal processing,with both basic research on wavelet analysis, and develop-ment oil a real time PC-Based speech analysis tools (theUnice package which is marketed by Vecsys).
The studyof phonological variations has been pursued on a text ("LaBise et le Soleil") pronounced by several speakers, and willcontinue with the analysis of BREF.
Another area of in-terest is the use of symbolic coding for improving cochlearimplants.
Also, apart from the classical Multilayer percep-tron or TDNN approaches, an original "Guided Propaga-tion" connectionist model is experimented.
In the hardwaredomain, the use of several MuPCD Asic chips in parallelis now being implemented, and the design of a new chip,taking advantage of improved technology is envisioned.APPL ICAT ION OF THE ALGORITHMSDEVELOPED FOR SPEECH TO OTHERAREASThe algorithms developed for speech recognition havebeen appfied in other areas.
The DP matching process de-veloped for connected word recognition, with the MuPCDAsic, has been adapted to the problem of optical characterrecognition.
Instead of considering the recognition of indi-vidual characters after segmentation (including eventuallysegmentation errors), the complete line of characters i con-sidered, and segmentation is included in the recognition pro-cess (M. Khemakhem, 1987).
The algorithm has also beenextended successfully in 2 dimensions in Computer Visionfor matching similar images, with application to stereovi-sion, and to movement analysis (G. Qu~not, 1992).
Prelim-inary studies for gesture recognition (throwing away, tak-ing, hoMing tight...) using a Data GloveTM have also beenconducted.
It is expected that the increase of quality ob-tained by stochastic modeling instead of template matchingin speech recognition can also be obtained in the fields ofcharacter ecognition and computer vision, and we are nowconsidering applying these techniques.THE LANGUAGE & COGNIT IONGROUPThe activities of the Language ~ Cognition group haveof course many interactions with the Speech Communica-tion group.
Several common research projects have been, orare being, conducted, such as the use of Conceptual Graphsto represent semantic information in a speech understand-ing system, or stochastic modeling of semantic informa-tion.
Also, the grapheme-to-phoneme conversion softwarehas been used to correct errors.
There are also many in-teractions between the Connectionist Systems and the Con-nectionist Models research topics in the two groups.
The"Time 8z Space representation" topic has also close rela-tionship with the Non-verbal Communication group.A new activity is now starting in the field of cognitivepsychology.
A group is being created, integrating the for-mer Center for Cognitive Psychology (Cepco), a universityParis XI laboratory within Limsi.
It includes researchersin the field of the psychology of reading and text compre-hension, visuo-spatial mental representation and cognitiveergonomics.SPEECH IN THE FRAMEWORK OFMULTIMODAL COMMUNICAT IONSpeech can be used with other communication modes inorder to obtain the more versatile and reliable means forhuman-machine communication.
A study on automatedtelematic (voice ?
text) switchboard has been conductedby both the Speech Communication and the Language 8JCognition groups.
Speech recognition together with gesture(touch screen) showed that using both together allows forbetter efficiency and better comfort (D. Teil et al, 1991),with gestual communication being preferable anytime thereis a need to give a low level analogous information.
Timingand co-reference are the difficult problems to solve with theintegrated system.PERSPECT IVES FOR FUTURERESEARCHA more ambitious project is now starting, including com-puter vision and 3D modeling, natural anguage and knowl-edge representation, and speech and gestual communication.This project aims at examining the theoretical problems ofmodel training in the framework of multimodal information,how non-verbal (visual, gestual) information can be used inbuilding a language model, and how linguistic informationcan help in order to build models of objects.REFERENCES"French Ready terminal that speaks English", Electron-ics, June 26, 1975.A.
Andreewski, J.P. Binquet, F. Debili, C. Fluhr, Y. Hlal,B.
Pouderoux, J.S.
Li~nard, J. Mariani, "Les dictionnalresen forme complete et leur utilisation dans la transforma-tion lexicale et syntaxique de cha\[nes phon6tiques correctes',10~mes JEP du GALF, Grenoble, Mai-Juin 1979J.L.
Gauvaln, J. Mariani, "A method for connected wordrecognition and word spotting on a microprocessor.
", Proc.IEEE ICASSP 82.
Paris, 3-5 mal 1982.J.L.
Gauvaln, J. Mariani, J.S.
Li~nard, "On the use oftime compression for word-based recognition.
", ICASSP 83.Boston, April 14-16, 1983.583.L.
Gauvain, L.F. Lamel, "Speaker-Independent PhoneRecognition using BREF", DARPA Speech and LanguageWorkshop, Arden House, February 1992M.
Khemakhem, J.L.
Gauvain, J. Rivaillier, "Reconnais-sance de caract~res imprim6s par comparaison dynamique.
",6~me Congr~s AFCET-INRIA "Reconnaissance d s Formeset Intelligence Artificielle".
Antibes, 16-20 novembre 1987.J.S.
Li6nard, M. Mlouka, J. Mariani, J. Sapaly, "Timesegmentation of speech", Speech Communication Seminar,Stockholm, Aofit 1974J.S.
Li6nard, J. Mariani, G. Renard, "Intelligibilit6 dephrases ynth6tiques altdr6es : application ~t la transmissionphon6tique de la parole", ICA, Madrid, Juillet 1977D.
Luzzati, "ORSO.
Projet pour la constitution etl'6tude de dialogues homme-machine.
", LIMSI internal re-port, Septembre 1984.D.
Luzzati, "ALORS : a skimming parser for spontaneousspeech processing.
", Computer Speech and Language, Vol.2,1987J.
Mariani, J.S.
Li6nard, "ESOPE 0 : un pro-gramme de compr6hension de la parole continue procddantpar pr6diction-vdrification aux niveaux phondtique, lexi-cal et syntaxique", ler Congr~s AFCET "Reconnaissancedes formes et Intelligence Artificielle, Chatenay-Malabry,F6vrier 1978J.
Mariani, J.L.
Gauvain, J.L.
Soury, "Un syst~me de v6ri-fication du locuteur", 13~mes JEP du GALF, 28-30 Mai 1984K.
Matrouf, F. N6el, "Use of Upper Level Knowledgeto Improve Human-Machine Interaction", Venaco Work-shop & ETRW on "The structure of MultimodaJ Dialogue",Maratea, September 1991G.
Qu6not, J.L.
Gauvain, J.J. Gangolf, J.J. Mariani, "ADynamic Programming Processor for Speech Recognition",IEEE Journal of Solid-State Circuits, Vol.
24, N. 2, Avril1989G.
Qu6not, "The "Orthogonal Algorithm" for optical flowdetection using Dynamic Programming", IEEE ICASSP'92,San Francisco, March 1992D.
Teil, Y. Bellik, "Multimodal Dialogue interface on aworkstation", Venaco Workshop & ETRW on "The struc-ture of Multimodal Dialogue", Maratea, September 1991APPENDIXSpeech Communicat ion  Group (Head:  F. N6el)17 permanent researchers, 17 Phd thesis students6 Research topics:Speech Analysis and Synthesis: This topic includes Shortterm analysis, Wavelets, Instantaneous frequency analysis,Speech signal editor (Unice product marketed by Vecsys)and coding (SNCF contract), Recognition in noisy envi-ronments (Dret (MoD) contract), Text-to-speech synthesis,High-quality synthesis, Multivoice and multidialect synthe-sis (cooperation with Montreal University (MoFA), CEC-Esprit Polyglot project), Models in Prosodies and diagnostic(paralinguistic) aspects.Assessment and Variability: In this topic, Recording oflarge vocabulary recognition evaluation data base (Gdr-Prc CHM "Bref" project) and spontaneous speech database(Spot), Standardization of speech recognition systems as-sessment (contribution to Afnor), Use of phonotactic on-straints, Grapheme-to-phoneme conversion with phonolog-ical variations, Regrouping of wavelets, improvement ofcochlear implants.Recognition: Word-based recognition (hardware andsoftware) (Vecsys Datavox product, Sextant-Dret con-tract), Syllable-based recognition, Diphone-based recogni-tion, Large vocabulary recognition (10,000 words), Contin-uous and discrete HMMs, Custom Dynamic ProgrammingVLSI (DGT-DGA/ Bull (VTI) contract), Application toprinted character ecognition, Speaker-independent recog-nition, Vocabulary-independent recognition, Discriminantrecognition, Speaker adaptation, Recognition in adverse n-vironments (DRET/Sextant contract), Speaker verification(MRT contract with Fichet-Bauche and Vecsys), Evaluationof speech recognition systems (participation i CEC/Esprit-SAM project).Dialog Structures: Models for dialogue structures(Gdr/PRC CHM programme), Speaker models, Task-oriented oral dialogue system for air controller training (Ste-tin/Sextant Avionique/Vecsys contract for C6NA), Linguis-tic study of man-machine dialogues, Selective syntax parser,Multimodal dialogue (Pilot's assistant application (Dret /Sextant) and Simulation of a telephone operator.Spoken language modeling: Linguistic Models (EspritPolyglot project), Phoneme-to-grapheme conversion (Esprit291/860 project), Stenotype-to-grapheme conversion (Ccett-Systex project), Continuous peech automatic phonetic la-belling and recognition through learning (Inserm collabora-tion), Morphosyntactic analysis, Automatic syntactic lassi-fication, Use of linguistic models for handwritten characterrecognition.Connectionist systems: Guided Propagation Models(CEC-Stimulation Brain programme, Dret (MoD) contract),Application to noisy speech analysis (cocktail party ef-fect), to continuous speech recognition (contract with FrenchPhilips Research Labs (LEP)) and to the modeling ofreading activity, Back Propagation Models, Application tocharacter recognition and grapheme-to-phoneme conversion,Feature Maps, Parallel architectures, Integration of the con-nectionist approach and of the symbolic approach (AI) intothe same formalism, Perception-to-Action modeling (Dretcontract).Langage & Cogn i t ion  Group (Head:  G. Sabah)14 Permanent Researchers, 13 PhD Thesis students8 Research topics:Automatic analysis of sentences and texts: Study and im-plementation of a general architecture for automatic lan-guage processing (Distributed AI: communicating multi-expert system structure); Application to the automatic on-59struction of internal representations, Trope and anaphoraprocessing, Semantic flexibility and context influence, Prag-matics (CEC/Esprit PLUS project).Written Dialog: Implementing a real dialogue in question-answer processes, Speaker modeling, Direct and indirectspeech act processing, Adapting an answer to the speaker,Application to computer-aided education (chess playing),and to documentation database query (MRT contract withthe Resoudre company).Flexibility: Elaborated lexical search, Justification or op-position to presupposed concepts (question-answer systems),Interpretation of unforeseen events (orthographic, syntacticerrors... (Mannesman-Tally prize)).Generation: Development of a Computer-Aided languagetraining system (SWIM (See What.
I Mean)), Developmentof a multilingual sentence generator: Arabic-French-Russian(Collaboration between France and Bulgaria), Developmentof a text generator which produces cene descriptions ac-cording to psycholinguistic principles.Learning: Automatic parsing rules creation from exam-ples, Syntactic and semantic aspects, Automatic pragmaticknowledge learning from texts using frames, Fine grain par-allel architecture (connection machine) for knowledge repre-sentation.Connectionist Models: Neural networks for Natural Lan-guage Processing, Disambiguation and syntactic structure,Relationship with symbolic approaches, Epistemology ofconnectionism.Semantic representations: Study of the most adequatelexical representations for automatic processing, Relation-ship between semantic and connectionist networks, Text se-mantics.Time and space representation: Modeling time and spacein text analysis, Temporal Logic, Use of generalized inter-vals, Parallel complexity of temporal constraint networks.Non-Verba l  Communicat ion  Group  (Head:  D.Tell)7 Permanent Researchers, 8 PhD Thesis students6 Research Topics:Tri-dimensional Modeling: 3D Modeling software "Sculp-tor", Steady and animated image synthesis.
Multiparamet-ric varieties, Application to acquisition and modeling for lifeand earth sciences and for cartoons; Human Factor study ofinteractivity in graphic interfaces.Computer Vision: Stereo Vision, Neural and Symboliclearning in computer vision, Application of Genetic Algo-rithms to image analysis, Scene analysis (contours and tex-ture).
Use of a parallel architecture (Transputers).
Appli-cation to the analysis of road traffic (Inrets contract).Real 'Time Architecture: Medium and fine grain parallelarchitecture.
Use of Object Oriented Languages, Hardwarespecialised for image synthesis.
Representation of multi-modal knowledge, learning, decision making.
Use of AI tech-niques; link with mobile robots, and Computer IntegratedManufacturing, Real Time modeling and formulation.Character recognition and coding: Graphic encoding ofcharacters (Eco system, Anvar licence), Printed characterrecognition by training and template matching (using theMuPCD VLSI chip).Gestual and m.ulti-modal Communication: Use of tactilescreens, touch analysis, mouvement analysis and synthesis,Effort feedback (3D mouse, Data GIoVeTM).
Integration ofdifferent communication means, perceptive sensor fusion.Human Factors: Human Factors for system design, Studyof the vocal interface for dialog and voice-activated dicta-tion.
Study of multimodal communication.
Application toAir Traffic Control, to the Pilot's Associate, to an automatedtelecommunication switchboard.Industrial  Cooperation: Amd, Bull, Cap-Gemini,Ccett, Cral, Cselt, Daimler-Benz, Erli, Fichet-Bauche,Hewlett-Packard, Jutland Telephone, Logica, Olivetti-Syntax, Philips, Resoudre, Sextant Avionique, Siemens, Ste-ria, Systex, Vecsys.International Cooperation: Universities of Aalborg,Amsterdam, Athens, Bochum, Cambridge, Copenhagen,Delft, Dublin, Edinburgh, Hamburg, Madrid, McGill, Ni-jmegen, Patras, Pisa, Rabat, Roskilde, Saarlandes, Sheffield,Stuttgart, Tilburg, UCL London, Umist, Inesc, IUT Luxem-bourg, IPO-Eindhoven, DRA (RSRE), TNO.LIMSI is a Managing node in the "Speech and Language"Esprit Basic Research Network of Excellence.
This networkhas the goal to promote the integration of Speech and Nat-ural Language.
It has now about 40 nodes around Europe.LIMSI is also a node in the French Coordinated ResearchProject (Prc/Gdr) on "Human-Machine Communication.
"The Prc has 4 poles on Speech Communication, NaturalLanguage Processing, Vision and Multimodal Communica-tion.60
