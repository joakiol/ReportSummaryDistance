Natural Language GenerationJourneys to Interactive 3D Worlds*Invited Talk Extended AbstractJames C. Lester and Wi l l iam H. BaresChar les B, Cal laway and Stuart  G. Towns?
Multimedia LaboratoryDepartment of Computer ScienceNorth Carolina State UniversityRaleigh, NC 27695{lester, whbsres, cbcallaw , sgtowns}~os.ncsu.eduhttp://multimedia.ncsu.edu/imedia/Abst rac tInteractive 3D worlds offer an intriguing testbed forthe  natural anguage generation community.
To com-plement interactive 3D worlds' rich visualizations, they~equire significant linguistic flexibility and communica-tive ?power.
We explore the major functionalities and~rchitectural implications of natural anguage genera-tion for three key classes of interactive 3D worlds: self-.
."
explaining 3D environments, habitable 3D learning en-vironments, and interactive 3D narrative worlds.
Theseare illustrated with .empirical investigations underwayin our laboratory with severalsuch systems.?
?
?
.
.?
Introduct ionNatural anguage generation (NLG) has witnessed greatstrides over the past decade.
Our theoretical Underpin-nings are firming up, our systems building activitiesare proceeding quickly, and we are beginning to seesignificant empirical results.
As a result of this mat-uration, the field is now well positioned to attack the?
"challenges pose'd by a new family of computing envi-?
ronments: interactive 3D worlds, which continuously?
?render the activities playing out in rich 3D scenes inrealtime.
Because of these worlds' compelling visualproperties and their promise of a high degree of mul-timodal interactivity, they will soon form the basis forapplications ranging from learning environments for ed,ucation and training to interactive fiction systems for?entertainment.Interactive 3D worlds offer an intriguing testbed forthe NLG ?community for several reasons.
They mayportray scenes with complicated spatial relationships," * Support for this work was provided by the follow-lag ?organizations: the National Science Foundation undergrants CDA-9720395 (Learning and Intelligent Systems Ini-tiative) and IRI-9701503 (CAREER Award Program); theNorth Carolina State University Intelli/Cledia Initiative; theWilliam S: Kenan Institute for Engineering, Technology andScience; and a Corporate gift from Novell, Inc.?
such as  those found in the domain of electricity andmagnetism in physics.
They may include multiple dy-namic objects tracing out complex motion paths, suchas water particles traveling through xylem tissue in Vir-tual plants.
They might be inhabited by user-directedavatars that manipulate objects in the world and lifelikeagents that will need to coordinate speech, gesture, andlocomotion as they explain and demonstrate complexphenomena.
In 3D interactive fiction systems, user-directed avatars and lifelike autonomous agents maynavigate through complex cityscapes and interact withusers and with one another to create new forms of the-ater.As the visual complexities of interactive 3D worldsgrow, they will place increasingly heavy demands onthe visual channel.
To complement their rich visualiza-tions, interactive 3D worlds will require the linguisticflexibility and ?communicative power that only NLG canprovide.
In interactive learning environments, the spa-tial complexities and dynamic phenomena that charac-terize physical devices must be clearly explained.
NLGdelivered with speech synthesis will need to be care-fully coordinated with 3D graphics generation to createinteractive presentations that are both coherent and in-teresting.
In a similar fashion, lifelike agents roaming ?around the same 3D worlds through which users guidetheir avatars will require sophisticated NLG capabili-ties, and 3D interacti.ve fiction systems will-benefit con-siderably from virtual narrators that are articulate andcan generate interesting commentary in realtime.In this talk, we will ?explore the major issues, func-tionalities, and architectural implications of ?naturallanguage generation for interactive 3D worlds.
Our dis-cussion will examine NLG issues for three interestingclasses of interactive 3D worlds:?
Self-Explaining 3D Environments:  In responseto  users' questions, Self-explaining environments dy-namically generate spoken natural anguage and 3Danimated visualizations and produce vivid explana-.
?
?
:Figure 1: The PHYSVIZ Self-Explaining 3D Environmenttions of complex phenomena.?
Hab i tab le  3D Learning Environments:  In hab-itable learning environments, lifelike pedagogicalagents generate advice combining speech and gestureas users solve problems by guiding avatars through3D worlds and manipulating devices housed in theworlds.?
Interact ive 3D Narrat ive Worlds: Virtual narra-tors generate fluid descriptions of lifelike characters'interaction with one another in response to incremen-tal specifications produced by narrative planners andinteractively-issued user directives.To begin mapping out the very large and complexspace of NLG phenomena in 3D interactive worlds,it is informative to examine the issues empirically.These issues are being studied in the context of severalprojects currently under development in our laboratory.First, self-explaining 3D environments must coordinateNLG with 3D graphics generation.
These require-ments will be discussed with regard to the PHYSVIZ(Towns, Callaway, & Lester 1998) and the PLANT-WORLD (Bares & Lester 1997) self-explaining 3D en-vironments for the domains of physics and plant phys-iology, respectively.
Second, in habitable 3D learningenvironments, lifelike agents must be able to gener-ate clear language that is carefully coordinated withagents' gestures and movements as they interact withusers in problem-solving episodes.
We examine theseissues in the VIRTUAL COMPUTER (Bares el al.
1998;Bares, Zettlemoyer, & Lester 1998), a habitable 3Dlearning environment for the domain of introductorycomputer architecture.
Third, virtual narrators for3D interactive fiction should be able to generate com-pelling realtime descriptions of multiple characters' be-haviors.
These issues are illustrated with examples fromthe COPS~ROBBERS world (Bares, Gr~goire, & Lester1998), a 3D interactive fiction testbed.In the talk, we discuss current efforts to introduceNLG capabilities into these worlds at several levels.This includes (1) discourse planning, as provided by theKNIGHT explanation planner (Lester & Porter 1997),(2) sentence construction, as provided by the the FAREsentence planner (Callaway & Lester 1995) and the RE-v isor  clause aggregator (Callaway & Lester 1997), and(3) surface generation, as provided by FUF (Elhadad1991).
Below we briefly summarize the requirementsand issues of NLG for self-explaining 3D environments,habitable 3D learning environments, and interactive 3Dnarrative worlds.
These will be discussed in some detailin the talk.Generat ion  in Se l f -Exp la in ing3D Env i ronmentsAs graphics technologies reach ever higher levels ofsophistication, knowledge-based learning environmentsand intelligent raining systems can create increasinglyFigure 2: The PLANTWORLD Self-Explaining 3D Environmenteffective ducational experiences.
A critical functional-ity required in many such systems is the ability to un-ambiguously communicate spatial knowledge.
Learningenvironments for the basic sciences frequently focus onphysical structures and the fundamental forces that acton them in the world, and training systems for tech-nical domains often revolve around the structure andfunction of complex devices.
Explanations of electro-magnetism, for example, must effectively communicatethe complex spatiM relationships governing the direc-tions and magnitudes of multiple vectors representingcurrents and electromagnetic fields, many of which areorthogonal to one another.Because text-only explanations are inadequate for ex-pressing complex spatial relationships and describingdynamic phenomena, realtime xplanation generationcombining natural language and 3D graphics could con-tribute significantly to a broad range of learning envi-ronments and training systems.
This calls for a com-putational model of 3D multimodal explanation gen-eration for complex spatial and dynamic phenomena.Unfortunately, planning the integrated creation of 3Danimation and spatial/behavior l nguistic utterances inrealtime requires coordinating the visual presentationof 3D objects and generating appropriate referring ex-pressions that accurately reflect the relative position,orientation, direction, and motion paths of the objectspresented with respect o the virtual camera's view ofthe scene.To address this problem, we are developing the visuo-linguistic ezplanation planning framework for gener-ating multimodal spatial and behavioral explanationscombining 3D animation and speech that complementone another.
Because 3D animation planners requirespatial knowledge in a geometric form and natural an-guage generators equire spatial knowledge in a linguis-tic form, a realtime multimodal planner interposed be-tween the visual and linguistic components serves asa mediator.
This framework has been implementedin CINESP~.AK, a multimodal generator consisting ofa media-independent explanation planner, a visuo-linguistic mediator, a 3D animation planner, and a real-time natural anguage generator with a speech synthe-sizer.
Experimentation with CINESPEAK is underwayin conjunction with self-explaining environments hatare being designed to produce language of spatial anddynamic phenomena:?
Complex spatial explanations: PHYSVIZ (Towns,Callaway, & Lester 1998) is a self-explaining 3D en-vironment in the domain of physics that generatesmultimodal explanations of three dimensional elec-tromagnetic fields, force, and electric urrents in re-altime (Figure I).?
Complex dynamic behavior explanations: PLANT-WORbD (Bares & Lester 1997) is a self-explaining3D environment in the domain of plant anatomy and4!
!i|!.--Figure 3: The VIRTUAL COMPUTER Habitable 3D Learning Environmentphysiology that generates multimodal explanations ofdynamic three dimensional physiological phenomenasuch as nutrient ransport (Figure 2).Generat ion  in Hab i tab le3D Learn ing  Env i ronmentsEngaging 3D learning environments in which usersguide avatars through virtual worlds hold great promisefor learner-centered ucation.
By enabling users toparticipate in immersive xperiences, 3D learning en-vironments could help them come to develop accuratemental models of highly complex biological, electronic,or mechanical systems.
In particular, 3D learning envi-ronments could permit learners to actively participatein the very systems about which they are learning andinteract with lifelike agents that could effectively com-municate the knowledge relevant o the user's task.
Forexample, users could study computer architecture in avirtual computer where they might be advised by a life-like agent about how to help a CPU carry data fromRAM to the hard disk, or they could study the humanimmune system by helping a T-cell traverse a virtuallymph system.
Properly designed, 3D learning environ-ments that blur the distinction between education andentertainment could produce ngrossing learning expe-riences that are intrinsically motivating and are solidlygrounded in problem solving.Lifelike agents that are to interact with users inhabitable 3D learning environments should be able togenerate language that enables them to provide clearproblem-solving advice.
Rather than operating in iso-lation, generation decisions must be carefully coordi-nated with decisions about gesture, locomotion, andeventually prosody.
In collaboration with the STEVEvirtual environments utor project at USC/ISI (Rickel&: Johnson 1998), we have begun to design NLG tech-niques for embodied explanation generation in which theavatar/agent generates coordinated utterances (deliv-ered with a speech synthesizer) and gestural and lo-comotive behaviors as it manipulates various devices inthe world.
Embodied explanation generation poses par-ticularly interesting challenges in the following areas:?
Deictic believability: Lifelike agents must be able toemploy referring expressions and gestures that to-gether are both unambiguous and natural (Lester etal.
1998).?
Socially motivated generation: Lifelike agents mustnot only express concepts clearly but also create ut-terances that are properly situated in the currentsocio-linguistic context.?
Embodied iscourse planning: Media allocation issuesmust be considered in adjudicating between express-ing advice verbally or through agents' demonstrativeactions.Over the past two years, we have constructed a habit-able learning environment for the domain of computerFigure 4: The COPSe:ROBBERS Interactive 3D Narrative Worldarchitecture.
The VIRTUAL COMPUTER (Bares et al1998; Bares, Zettlemoyer, & Lester 1998) (Figure 3) is ahabitable 3D learning environment that teaches novicesthe fundamentals of computer architecture and systemalgorithms, e.g., the fetch-execute cycle.
To learn thebasics of computation, users direct an avatar in the formof a friendly robot courier as they execute instructionsand transport data packets to appropriate locations ina 3D "town" whose buildings represent theCPU, RAM,and hard disk.
We are beginning to investigate deicticbelievability, socially motivated generation, and embod-ied discourse planning in an lifelike agent hat providesadvice in the VIRTUAL COMPUTER.In teract ive  3D Nar ra t ive  Wor ldsWhile story generation has been an NLG goal that datesback more than.
a quarter century and text-based inter-active fiction systems have b en the subject of increas-ing attention, it is the prospect of coupling sophisti-cated NLG with 3D believable characters that offersthe potential of achieving interactive fiction generationin a visually compelling environment.
One can imag-ine different genres of 3D interactive fiction, many ofwhich will involve a virtual narrator who comments onthe events unfolding in the world.
In much the samemanner that sports announcers come in two varieties,play-by-play and color commentary, virtual narratorscan provide both a descriptive account of the world'sactivities as well as a running analysis on their signifi-cance.
To stress test NLG, we adopt three constraintson generation for 3D narrative worlds: 1?
Realtime: World events play out in realtime and canbe modified by users.
Consequently, the relevance ofutterances i time-bound; generators must constructtheir utterances in realtime and cannot know in ad-vance how the actions in the world will play out.?
Non-interference: Generators cannot hemselves en-act modifications on objects or characters in theworld.
As a result, they must cope with what heyare dealt by world simulators and users' actions.
* Multiple, simultaneous events: Multiple activities oc-cur in the world at the same time.
Consequently,generators must make time-bounded moment-by-moment content determination decisions that neces-sarily omit mention of many actions.We have recently begun to study these issues inCOPS&ROBBERs (Bares, Gr~goire, & Lester 1998), a3D interactive fiction testbed with multiple charactersinteracting with each other in an intricate cityscape.
InCOPS&ROBBERS (Figure 4), three autonomous charac-ters, a policeman and two robbers, attempt o capturea lost money bag dropped by a careless bank teller.
I fl Efisabeth Andrfi and colleagues at DFKI are addressingsimilar issues in their realtime generator for the ROBOCUPcompetition.!iiIII!
!the policeman finds the money bag first, he dutifullyreturns it to the bank, but if either of the two miscre-ants find the unclaimed money, they will scurry off toJoe's Bar to spend their new found loot.
If the copcatches either robber carrying the money, he will im-mobilize him and return the money bag to the bank.When the narrative begins, the three characters mean-der randomly through the town searching for the lostmoney bag.
A t  any time, users may affect he narrativeby modifying characters' physical abilities uch as theirspeed or eyesight.Despite the relative simplicity of the testbed, it posessignificant NLG challenges.
Of particular interest areproblems in the virtual narrator's expressing time se-quence relations, concisely describing locations whereparticular events are occurring, and linking characters'actions to their intentions.
Because events occur si-multaneously, tense issues are problematic in accuratelydescribing the temporal relations between events in se-quential utterances.
Especially difficult are generatingprecise disambiguating locative descriptions involvingrelative locations, direction of movement, and proxim-ity of characters and structures in the world.
Becauseit is often important o identify where a specific ac-tion has occurred, generators must be able to formu-late locatives that are precise.
Frequently, they mustalso be concise, because utterances?
that are too verbosewill require xcessive speaking times, causing tile narra-tion to miss other important events.
Finally, generatorsmust be able to communicate about, characters' goals,actions, and the relation between the two.
For exam-ple, if the cop is scurrying toward one of the robbers,rather than merely reporting the action, the generatorshould sometimes comment on the causal ink betweenthe cop's desire to obtain the money bag and and hisaccosting the targeted robber.A New Era  for  NLGAs a result of both technological nd societal develop-ments, the advent of a new era for NLG is upon us.On the technology front, high-end 3Dgraphics, as wellas the 3D interactive worlds they will spawn, will makesignificant demands on NLG systems.
On the societalfront, we're beginning to see the rapid convergence ofthe software, telecommunications, andeven the enter-tainment industries.
This will undoubtedly provide sig-nificant impetus for integrating NLG into applicationsthat could not have even been imagined at the incep-tion of the field.
With continued progress in theory,systems building, and empirical studies, we will be wellpositioned to meet he upcoming challenges.AcknowledgementsMany people have contributed to the projects discussedin the talk.
The authors would like to thank:?
thetechnical members of the the IntelliMedia Initiative's3D team including Jo~l Gr~goire, Ben Lee, Dennis Ro-driguez, and Luke Zettlemoyer; the IntelliMedia ni-mation and modeling team, led by Patrick FitzGerald,including Tim Buie, Mike Cuales, Rob Gray, and AlexLevy; Bruce Porter for his collaboration on the KNIGHTexplanation system; Jeff Rickel for his collaboration onthe pedagogical gents dialogue work; and especiallyMichael Elhadad for creating and generously assistingus with FUF for the past five years.Re ferencesBares, W. H., and Lester, J. C. 1997.
Realti'me generationof customized 3D animated explanations for knowledge-based learning environments.
In AAAI-97: Proceedings ofthe Fourteenth National Conference on Artificial Intelli-gence, 347-354.Bares, W.; Zettlemoyer, L.; Rodriguez, D.; and Lester,J.
1998.
Task-sensitive cinematography interfaces for in-teractive 3D learning environments.
In Proceedings of theFourth International Conference on Intelligent User Inter-faces, 81-88.Bares, W.; Gr6goire, J.; and Lester, J.
1998.
Realtimeconstraint-based cinematography for complex interactive3D worlds.
In Proceedings of the Tenth National':Confer-ence on Innovative Applications of Artificial Intelligence.Bares, W.; Zettlemoyer, L.; and Lester, J.
1998.
Habitable3D learning environments forsituated learning.
In Proceed-ings of the Fourth International Conference on IntelligentTutoring Systems.
Forthcoming.Callaway, C., and Lester, J.
1995.
Robust natural languagegeneration from large-scale knowledge bases.
Ill Proceed-ings of the Fourth Bar-Ban Symposium on the Foundationso f  Artificial Intelligence, 96-105.Callaway, C. B., and Lester, J. C. 1997.
Dynamically im-proving explanations: A revision-based approach to expla-nation generation.
In Proceedings of the Fifteenth Interna-tional Joint Conference on Artificial Intelligence, 952-58.Elhadad, M. 1991.
FUF: The universal unifier user manualversion 5.0.
Technical Report CUCS-038-91, Departmentof Computer Science, Columbia University.Lester, J. C., and Porter, B.W.
1997.
~)evelopingand empirically evaluating robust explanation generators:The KNIGHT experiments~ Computational Linguistics23(1):65-101.Lester, J.; Voerman, J.; Towns, S.; and Callaway, C. 1998.Deicfic believability: Coordinating esture, locomotion,and speech in lifelike pedagogical agents.
Applied ArtificialIntelligence.
Forthcoming.Rickel, J., and Johnson, W. L. 1998.
Animated agentsfor procedural training in virtual reality: I Percepti6n, cog-nition, and motor control.
Applied Artificial Intelligence.Forthcoming.Towns, S. G.; Callaway, C. B.; and Lester, J. C. 1998.
Gen-erating coordinated natural language and 3D animationsfor complex spatial explanations.
In Proceedings of the Fif-teenth National Conference on Artificial Intelligence.7
