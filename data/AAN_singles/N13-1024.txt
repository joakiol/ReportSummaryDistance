Proceedings of NAACL-HLT 2013, pages 239?247,Atlanta, Georgia, 9?14 June 2013. c?2013 Association for Computational LinguisticsEnforcing Subcategorization Constraints in a Parser Using Sub-parsesRecombiningSeyed Abolghasem Mirroshandel?,?
Alexis Nasr?
Beno?
?t Sagot?Laboratoire d?Informatique Fondamentale de Marseille- CNRS - UMR 7279Universite?
Aix-Marseille, Marseille, FranceAlpage, INRIA & Universite?
Paris-Diderot, Paris, France?Computer Engineering Department, Faculty of Engineering,University of Guilan, Rasht, Iran(ghasem.mirroshandel@lif.univ-mrs.fr, alexis.nasr@lif.univ-mrs.fr,benoit.sagot@inria.fr)AbstractTreebanks are not large enough to adequatelymodel subcategorization frames of predica-tive lexemes, which is an important source oflexico-syntactic constraints for parsing.
Asa consequence, parsers trained on such tree-banks usually make mistakes when selectingthe arguments of predicative lexemes.
In thispaper, we propose an original way to correctsubcategorization errors by combining sub-parses of a sentence S that appear in the listof the n-best parses of S. The subcatego-rization information comes from three differ-ent resources, the first one is extracted froma treebank, the second one is computed on alarge corpora and the third one is an existingsyntactic lexicon.
Experiments on the FrenchTreebank showed a 15.24% reduction of er-roneous subcategorization frames (SF) selec-tions for verbs as well as a relative decrease ofthe error rate of 4% Labeled Accuracy Scoreon the state of the art parser on this treebank.1 IntroductionAutomatic syntactic parsing of natural languageshas witnessed many important changes in the lastfifteen years.
Among these changes, two have mod-ified the nature of the task itself.
The first one isthe availability of treebanks such as the Penn Tree-bank (Marcus et al 1993) or the French Treebank(Abeille?
et al 2003), which have been used in theparsing community to train stochastic parsers, suchas (Collins, 1997; Petrov and Klein, 2008).
Suchwork remained rooted in the classical language the-oretic tradition of parsing, generally based on vari-ants of generative context free grammars.
The sec-ond change occurred with the use of discriminativemachine learning techniques, first to rerank the out-put of a stochastic parser (Collins, 2000; Charniakand Johnson, 2005) and then in the parser itself (Rat-naparkhi, 1999; Nivre et al 2007; McDonald et al2005a).
Such parsers clearly depart from classicalparsers in the sense that they do not rely anymore ona generative grammar: given a sentence S, all pos-sible parses for S1 are considered as possible parsesof S. A parse tree is seen as a set of lexico-syntacticfeatures which are associated to weights.
The scoreof a parse is computed as the sum of the weights ofits features.This new generation of parsers allows to reachhigh accuracy but possess their own limitations.
Wewill focus in this paper on one kind of weaknessof such parser which is their inability to properlytake into account subcategorization frames (SF) ofpredicative lexemes2, an important source of lexico-syntactic constraints.
The proper treatment of SF isactually confronted to two kinds of problems: (1)the acquisition of correct SF for verbs and (2) theintegration of such constraints in the parser.The first problem is a consequence of the use oftreebanks for training parsers.
Such treebanks arecomposed of a few thousands sentences and only asmall subpart of acceptable SF for a verb actually1Another important aspect of the new parsing paradigm isthe use of dependency trees as a means to represent syntacticstructure.
In dependency syntax, the number of possible syn-tactic trees associated to a sentence is bounded, and only de-pends on the length of the sentence, which is not the case withsyntagmatic derivation trees.2We will concentrate in this paper on verbal SF.239occur in the treebank.The second problem is a consequence of the pars-ing models.
For algorithmic complexity as well asdata sparseness reasons, the parser only considerslexico-syntactic configurations of limited domain oflocality (in the parser used in the current work, thisdomain of locality is limited to configurations madeof one or two dependencies).
As described in moredetails in section 2, SF often exceed in scope suchdomains of locality and are therefore not easy to in-tegrate in the parser.
A popular method for intro-ducing higher order constraints in a parser consist inreranking the n best output of a parser as in (Collins,2000; Charniak and Johnson, 2005).
The rerankersearch space is restricted by the output of the parserand high order features can be used.
One draw-back of the reranking approach is that correct SF forthe predicates of a sentence can actually appear indifferent parse trees.
Selecting complete trees cantherefore lead to sub-optimal solutions.
The methodproposed in this paper merges parts of different treesthat appear in an n best list in order to build a newparse.Taking into account SF in a parser has been a ma-jor issue in the design of syntactic formalisms in theeighties and nineties.
Unification grammars, suchas Lexical Functional Grammars (Bresnan, 1982),Generalized Phrase Structure Grammars (Gazdar etal., 1985) and Head-driven Phrase Structure Gram-mars (Pollard and Sag, 1994), made SF part of thegrammar.
Tree Adjoining Grammars (Joshi et al1975) proposed to extend the domain of locality ofContext Free Grammars partly in order to be ableto represent SF in a generative grammar.
Morerecently, (Collins, 1997) proposed a way to intro-duce SF in a probabilistic context free grammar and(Arun and Keller, 2005) used the same techniquefor French.
(Carroll et al 1998), used subcate-gorization probabilities for ranking trees generatedby unification-based phrasal grammar and (Zeman,2002) showed that using frame frequency in a de-pendency parser can lead to a significant improve-ment of the performance of the parser.The main novelties of the work presented here is(1) the way a new parse is built by combining sub-parses that appear in the n best parse list and (2)the use of three very different resources that list thepossible SF for verbs.The organization of the paper is the following: insection 2, we will briefly describe the parsing modelthat we will be using for this work and give accuracyresults on a French corpus.
Section 3 will describethree different resources that we have been using tocorrect SF errors made by the parser and give cov-erage results for these resources on a developmentcorpus.
Section 4 will propose three different waysto take into account, in the parser, the resources de-scribed in section 3 and give accuracy results.
Sec-tion 5 concludes the paper.2 The ParserThe parser used in this work is the second ordergraph based parser (McDonald et al 2005b) imple-mentation of (Bohnet, 2010).
The parser was trainedon the French Treebank (Abeille?
et al 2003) whichwas transformed into dependency trees by (Canditoet al 2009).
The size of the treebank and its de-composition into train, development and test sets arerepresented in table 1.nb of sentences nb of tokensTRAIN 9 881 278 083DEV 1 239 36 508TEST 1 235 36 340Table 1: Size and decomposition of the French TreebankThe parser gave state of the art results for parsingof French, reported in table 2.
Table 2 reports thestandard Labeled Accuracy Score (LAS) and Unla-beled Accuracy Score (UAS) which is the ratio ofcorrect labeled (for LAS) or unlabeled (for UAS) de-pendencies in a sentence.
We also defined a morespecific measure: the SF Accuracy Score (SAS)which is the ratio of verb occurrences that have beenpaired with the correct SF by the parser.
We haveintroduced this quantity in order to measure moreaccurately the impact of the methods described inthis paper on the selection of a SF for the verbs of asentence.TEST DEVSAS 80.84 79.88LAS 88.88 88.53UAS 90.71 90.37Table 2: Subcategorization Frame Accuracy, Labeled andUnlabeled Accuracy Score on TEST and DEV.240We have chosen a second order graph parser inthis work for two reasons.
The first is that it is theparsing model that obtained the best results on theFrench Treebank.
The second is that it allows usto impose structural constraints in the solution ofthe parser, as described in (Mirroshandel and Nasr,2011), a feature that will reveal itself precious whenenforcing SF in the parser output.3 The ResourcesThree resources have been used in this work in orderto correct SF errors.
The first one has been extractedfrom a treebank, the second has been extracted froman automatically parsed corpus that is several orderof magnitude bigger than the treebank.
The third onehas been extracted from an existing lexico-syntacticresource.
The three resources are respectively de-scribed in sections 3.2, 3.3 and 3.4.
Before describ-ing the resources, we describe in details, in section3.1 our definition of SF.
In section 3.5, we evalu-ate the coverage of these resources on the DEV cor-pus.
Coverage is an important characteristic of a re-source: in case of an SF error made by the parser, ifthe correct SF that should be associated to a verb, ina sentence, does not appear in the resource, it will beimpossible to correct the error.3.1 Subcat Frames DescriptionIn this work, a SF is defined as a couple (G,L)where G is the part of speech tag of the element thatlicenses the SF.
This part of speech tag can eitherbe a verb in infinitive form (VINF), a past participle(VPP), a finite tense verb (V) or a present participle(VPR).
L is a set of couples (f, c) where f is a syn-tactic function tag chosen among a set F and c isa part of speech tag chosen among the set C. Cou-ple (f, c) indicates that function f can be realized aspart of speech tag c. Sets F and C are respectivelydisplayed in top and bottom tables of figure 1.
Ananchored SF (ASF) is a couple (v, S) where v is averb lemma and S is a SF, as described above.A resource is defined as a collection of ASF(v, S), each associated to a count c, to represent thefact that verb v has been seen with SF S c times.
Inthe case of the resource extracted form an existinglexicon (section 3.4), the notion of count is not ap-plicable and we will consider that it is always equalSUJ subjectOBJ objectA OBJ indirect object introduced by the preposition a`DE OBJ indirect object introduced by the preposition deP OBJ indirect object introduced by another prepositionATS attribute of the subjectATO attribute of the direct objectADJ adjectiveCS subordinating conjunctionN nounV verb finite tenseVINF verb infinitive formVPP verb past participleVPR verb present participleFigure 1: Syntactic functions of the arguments of the SF(top table).
Part of speech tags of the arguments of the SF(bottom table)to one.Below is an example of three ASF for the frenchverb donner (to give).
The first one is a transitive SFwhere both the subject and the object are realized asnouns as in Jean donne un livre (Jean gives a book.
).The second one is ditransitive, it has both a directobject and an indirect one introduced by the prepo-sition a` as in Jean donne un livre a` Marie.
(Jeangives a book to Marie).
The third one correspondsto a passive form as in le livre est donne?
a` Marie parJean (The book is given to Marie by Jean).
(donner,(V,(suj,N),(obj,N)))(donner,(V,(suj,N),(obj,N),(a_obj,N)))(donner,(VPP,(suj,N),(aux_pass,V),(a_obj,N),(p_obj,N)))One can note that when an argument correspondsto an indirect dependent of the verb (introduced ei-ther by a preposition or a subordinating conjunc-tion), we do not represent in the SF, the categoryof the element that introduces the argument, but thecategory of the argument itself, a noun or a verb.Two important choices have to be made whendefining SF.
The first one concerns the dependentsof the predicative element that are in the SF (argu-ment/adjunct distinction) and the second is the levelof abstraction at which SF are defined.In our case, the first choice is constrained by thetreebank annotation guidelines.
The FTB distin-guishes seven syntactic functions which can be con-sidered as arguments of a verb.
They are listed inthe top table of figure 1.
Most of them are straight-241forward and do not deserve an explanation.
Some-thing has to be said though on the syntactic functionP OBJ which is used to model arguments of the verbintroduced by a preposition that is neither a` nor de,such as the agent in passive form, which is intro-duced by the preposition par.We have added in the SF two elements that do notcorrespond to arguments of the verb: the reflexivepronoun, and the passive auxiliary.
The reason foradding these elements to the SF is that their pres-ence influences the presence or absence of some ar-guments of the verb, and therefore the SF.The second important choice that must be madewhen defining SF is the level of abstraction, or, inother words, how much the SF abstracts away fromits realization in the sentence.
In our case, we haveused two ways to abstract away from the surface re-alization of the SF.
The first one is factoring sev-eral part of speech tags.
We have factored pronouns,common nouns and proper nouns into a single cat-egory N. We have not gathered verbs in differentmodes into one category since the mode of the verbinfluences its syntactic behavior and hence its SF.The second means of abstraction we have used isthe absence of linear order between the arguments.Taking into account argument order increases thenumber of SF and, hence, data sparseness, withoutadding much information for selecting the correctSF, this is why we have decided to to ignore it.
Inour second example above, each of the three argu-ments can be realized as one out of eight parts ofspeech that correspond to the part of speech tag Nand the 24 possible orderings are represented as onecanonical ordering.
This SF therefore correspondsto 12 288 possible realizations.3.2 Treebank Extracted Subcat FramesThis resource has been extracted from the TRAINcorpus.
At a first glance, it may seen strange to ex-tract data from the corpus that have been used fortraining our parser.
The reason is that, as seen insection 1, SF are not directly modeled by the parser,which only takes into account subtrees made of, atmost, two dependencies.The extraction procedure of SF from the treebankis straightforward : the tree of every sentence is vis-ited and, for every verb of the sentence, its daughtersare visited, and, depending whether they are consid-ered as arguments of the verb (with respect to theconventions or section 3.1), they are added to the SF.The number of different verbs extracted, as well asthe number of different SF and the average numberof SF per verb are displayed in table 3.
Column T(for Train) is the one that we are interested in here.T L A0 A5 A10nb of verbs 2058 7824 23915 4871 3923nb of diff SF 666 1469 12122 2064 1355avg.
nb of SF 4.83 52.09 14.26 16.16 13.45Table 3: Resources statisticsThe extracted resource can directly be comparedwith the TREELEX resource (Kupsc and Abeille?,2008), which has been extracted from the same tree-bank.
The result that we obtain is different, due tothe fact that (Kupsc and Abeille?, 2008) have a moreabstract definition of SF.
As a consequence, they de-fine a smaller number of SF: 58 instead of 666 inour case.
The smaller number of SF yields a smalleraverage number of SF per verb: 1.72 instead of 4.83in our case.3.3 Automatically computed Subcat FramesThe extraction procedure described above has beenused to extract ASF from an automatically parsedcorpus.
The corpus is actually a collection of threecorpora of slightly different genres.
The first oneis a collection of news reports of the French pressagency Agence France Presse, the second is a col-lection of newspaper articles from a local Frenchnewspaper : l?Est Re?publicain.
The third one isa collection of articles from the French Wikipedia.The size of the different corpora are detailed in ta-ble 4.The corpus was first POS tagged with the MELTtagger (Denis and Sagot, 2010), lemmatized with theMACAON tool suite (Nasr et al 2011) and parsedin order to get the best parse for every sentence.Then the ASF have been extracted.The number of verbs, number of SF and averagenumber of SF per verb are represented in table 3,in column A0 (A stands for Automatic).
As onecan see, the number of verbs and SF are unrealis-tic.
This is due to the fact that the data that we ex-tract SF from is noisy: it consists of automaticallyproduced syntactic trees which contain errors (recall242CORPUS Sent.
nb.
Tokens nb.AFP 2 041 146 59 914 238EST REP 2 998 261 53 913 288WIKI 1 592 035 33 821 460TOTAL 5 198 642 147 648 986Table 4: sizes of the corpora used to collect SFthat the LAS on the DEV corpus is 88, 02%).
Thereare two main sources of errors in the parsed data: thepre-processing chain (tokenization, part of speechtagging and lemmatization) which can consider asa verb a word that is not, and, of course, parsingerrors, which tend to create crazy SF.
In order tofight against noise, we have used a simple thresh-olding: we only collect ASF that occur more than athreshold i.
The result of the thresholding appearsin columns A5 and A10 , where the subscript is thevalue of the threshold.
As expected both the numberof verbs and SF decrease sharply when increasingthe value of the threshold.Extracting SF for verbs from raw data has beenan active direction of research for a long time, dat-ing back at least to the work of (Brent, 1991) and(Manning, 1993).
More recently (Messiant et al2008) proposed such a system for French verbs.
Themethod we use for extracting SF is not novel withrespect to such work.
Our aim was not to devisenew extraction techniques but merely to evaluate theresource produced by such techniques for statisticalparsing.3.4 Using an existing resourceThe third resource that we have used is the Lefff(Lexique des formes fle?chies du franc?ais ?
Lexiconof French inflected form), a large-coverage syntac-tic lexicon for French (Sagot, 2010).
The Lefff wasdeveloped in a semi-automatic way: automatic toolswere used together with manual work.
The latestversion of the Lefff contains 10,618 verbal entriesfor 7,835 distinct verbal lemmas (the Lefff covers allcategories, but only verbal entries are used in thiswork).A sub-categorization frame consists in a list ofsyntactic functions, using an inventory slightly morefine-grained than in the French Treebank, and foreach of them a list of possible realizations (e.g.,noun phrase, infinitive clause, or null-realization ifthe syntactic function is optional).For each verbal lemma, we extracted all sub-categorization frames for each of the four verbalpart-of-speech tags (V, VINF, VPR, VPP), thus cre-ating an inventory of SFs in the same sense and for-mat as described in Section 3.1.
Note that such SFsdo not contain alternatives concerning the way eachsyntactic argument is realized or not: this extractionprocess includes a de-factorization step.
Its output,hereafter L, contains 801,246 distinct (lemma, SF)pairs.3.5 CoverageIn order to be able to correct SF errors, the threeresources described above must possess two impor-tant characteristics: high coverage and high accu-racy.
Coverage measures the presence, in the re-source, of the correct SF of a verb, in a given sen-tence.
Accuracy measures the ability of a resourceto select the correct SF for a verb in a given contextwhen several ones are possible.We will give in this section coverage result, com-puted on the DEV corpus.
Accuracy will be de-scribed and computed in section 4.
The reason whythe two measures are not described together is dueto the fact that coverage can be computed on a ref-erence corpus while accuracy must be computed onthe output of a parser, since it is the parser that willpropose different SF for a verb in a given context.Given a reference corpus C and a resource R,two coverage measures have been computed, lexi-cal coverage, which measures the ratio of verbs of Cthat appear in R and syntactic coverage, which mea-sures the ratio of ASF of C that appear in R. Twovariants of each measures are computed: on typesand on occurrences.
The values of these measurescomputed on the DEV corpus are summarized in ta-ble 5.T L A0 A5 A10Lex.
types 89.56 99.52 99.52 98.56 98.08cov.
occ 96.98 99.85 99.85 99.62 99.50Synt.
types 62.24 78.15 95.78 91.08 88.84cov.
occ 73.54 80.35 97.13 93.96 92.39Table 5: Lexical and syntactic coverage of the three re-sources on DEVThe figures of table 5 show that lexical cover-age of the three resources is quite high, ranging243from 89.56 to 99.52 when computed on types andfrom 96.98 to 99.85 when computed on occurrences.The lowest coverage is obtained by the T resource,which does not come as a surprise since it is com-puted on a rather small number of sentences.
Itis also interesting to note that lexical coverage ofA does not decrease much when augmenting thethreshold, while the size of the resource decreasesdramatically (as shown in table 3).
This validatesthe hypothesis that the resource is very noisy andthat a simple threshold on the occurrences of ASF isa reasonable means to fight against noise.Syntactic coverage is, as expected, lower than lex-ical coverage.
The best results are obtained by A0:95.78 on types and 97.13 on occurrences.
Thresh-olding on the occurrences of anchored SF has a big-ger impact on syntactic coverage than it had on lexi-cal coverage.
A threshold of 10 yields a coverage of88.84 on types and 92.39 on occurrences.4 Integrating Subcat Frames in the ParserAs already mentioned in section 1, SF usually ex-ceed the domain of locality of the structures that aredirectly modeled by the parser.
It is therefore dif-ficult to integrate directly SF in the model of theparser.
In order to circumvent the problem, we havedecided to work on the n-best output of the parser:we consider that a verb v, in a given sentence S,can be associated to any of the SF that v licenses inone of the n-best trees.
The main weakness of thismethod is that an SF error can be corrected only ifthe right SF appears at least in one of the n-best parsetrees.In order to estimate an upper bound of the SASthat such methods can reach (how many SF errorscan actually be corrected), we have computed theoracle SAS on the 100 best trees of the DEV corpusDEV (for how many verbs the correct SF appearsin at least one of the n-best parse trees).
The oraclescore is equal to 95.16, which means that for 95.16%of the verb occurrences of the DEV, the correct SFappears somewhere in the 100-best trees.
95.16 istherefore the best SAS that we can reach.
Recallthat the baseline SAS is equal to 79.88% the roomfor progress is therefore equal to 15.28% absolute.Three experiments are described below.
In thefirst one, section 4.1, a simple technique, called PostProcessing is used.
Section 4.2 describes a secondtechnique, called Double Parsing, which is a is arefinement of Post Processing.
Both sections 4.1and 4.2 are based on single resources.
Section 4.3proposes a simple way to combine the different re-sources.4.1 Post ProcessingThe post processing method (PP) is the simplest onethat we have tested.
It takes as input the differentASF that occur in the n-best output of the parser aswell as a resource R. Given a sentence, let?s noteT1 .
.
.
Tn the trees that appear in the n-best outputof the parser, in decreasing order of their score.
Forevery verb v of the sentence, we note S(v) the setof all the SF associated to v that appear in the treesT1 .
.
.
Tn.Given a verb v and a SF s, we define the followingfunctions:C(v, s) is the number of occurrences of the ASF(v, s) in the trees T1 .
.
.
Tn.F(v) is the SF associated to v in T1CR(v, s) the number of occurrences of the ASF(v, s) in the resource R.We define a selection function as a function thatselects a SF for a given verb in a given sentence.A selection function has to take into account the in-formation given by the resource (whether an SF isacceptable/frequent for a given verb) as well as theinformation given by the parser (whether the parserhas a strong preference to associate a given SF to agiven verb).In our experiments, we have tested two simpleselection functions.
?R which selects the first SFs ?
S(v), such that CR(v, s) > 0 when traversingthe trees T1 .
.
.
Tn in the decreasing order of score(best tree first).The second function, ?R(v) compares the mostfrequent SF for v in the resourceRwith the SF of thefirst parse.
If the ratio of the number of occurrencesin the n-best of the former and the latter is above athreshold ?, the former is selected.
More formally:?R(v) =?????????s?
= argmaxs?S(v) CR(v, s)if C(v,s?
)C(v,F(v)) > ?F(v)otherwise244The coefficient?
has been optimized on DEV cor-pus.
Its value is equal to 2.5 for the Automatic re-source, 2 for the Train resource and 1.5 for the Lefff.The construction of the new solution proceeds asfollows: for every verb v of the sentence, a SF is se-lected with the selection function.
It is important tonote, at this point, that the SF selected for differentverbs of the sentence can pertain to different parsetrees.
The new solution is built based on tree T1.
Forevery verb v, its arguments are potentially modifiedin agreement with the SF selected by the selectionfunction.
There is no guarantee at this point that thesolution is well formed.
We will return to this prob-lem in section 4.2.We have evaluated the PP method with differentselection functions on the TEST corpus.
The resultsof applying function ?R were more successful.
Asa result we just report the results of this function intable 6.
Different levels of thresholding for resourceA gave almost the same results, we therefore usedA10 which is the smallest one.B T L ASAS 80.84 83.11 82.14 82.17LAS 88.88 89.14 89.03 89.03UAS 90.71 90.91 90.81 90.82Table 6: LAS and UAS on TEST using PPThe results of table 6 show two interesting facts.First, the SAS is improved, it jumps from 80.84 to83.11.
PP therefore corrects some SF errors madeby the parser.
It must be noted however that this im-provement is much lower than the oracle score.
Thesecond interesting fact is the very moderate increaseof both LAS and UAS.
This is due to the fact thatthe number of dependencies modified is small withrespect to the total number of dependencies.
Theimpact on LAS and UAS is therefore weak.The best results are obtained with resource T .
Al-though the coverage of T is low, the resource is veryclose to the train data, this fact probably explains thegood results obtained with this resource.It is interesting, at this point, to compare ourmethod with a reranking approach.
In order to do so,we have compared the upper bound of the number ofSF errors that can be corrected when using rerank-ing and our approach.
The results of the comparisoncomputed on a list of 100 best trees is reported intable 7 which shows the ratio of subcat frame errorsthat could be corrected with a reranking approachand the ratio of errors sub-parse recombining couldreach.DEV TESTreranking 53.9% 58.5%sub-parse recombining 75.5% 76%Table 7: Correction rate for subcat frames errors with dif-ferent methodsTable 7 shows that combining sub-parses can, intheory, correct a much larger number of wrong SFassignments than reranking.4.2 Double ParsingThe post processing method shows some improve-ment over the baseline.
But it has an important draw-back: it can create inconsistent parses.
Recall thatthe parser we are using is based on a second ordermodel.
In other words, the score of a dependencydepends on some neighboring dependencies.
Whenbuilding a new solution, the post processing methodmodifies some dependencies independently of theircontext, which may give birth to very unlikely con-figurations.In order to compute a new optimal parse treethat preserves the modified dependencies, we haveused a technique proposed in (Mirroshandel andNasr, 2011) that modifies the scoring function of theparser in such a way that the dependencies that wewant to keep in the parser output get better scoresthan all competing dependencies.
The new solutionis therefore the optimal solution that preserves thedependencies modified by the PP method.The double parsing (DP) method is therefore athree stage method.
First, sentence S is parsed, pro-ducing the n-best parses.
Then, the post processingmethod is used, modifying the first best parse.
Let?snote D the set of dependencies that were changed inthis process.
In the last stage, a new parse is pro-duced, that preserves D.B T L ASAS 80.84 83.11 82.14 82.17LAS 88.88 89.30 89.25 89.31UAS 90.71 91.07 91.05 91.08Table 8: LAS and UAS on TEST using DP245The results of DP on TEST are reported in table8.
SAS did not change with respect to PP, becauseDP keeps the SF selected by PP.
As expected DPdoes increase LAS and UAS.
Recomputing an op-timal solution therefore increases the quality of theparses.
Table 8 also shows that the three resourcesget alst the same LAS and UAS although SAS isbetter for resource T.4.3 Combining ResourcesDue to the different generation techniques of ourthree resources, another direction of research iscombining them.
We did different experiments con-cerning all possible combination of resources: A andL (AL), T and L (TL), T and A (TA), and all tree(TAL) resources.
The results of these combinationsfor PP and DP methods are shown in tables 9 and10, respectively.The resource are combined in a back-off schema:we search for a candidate ASF in a first resource.
Ifit is found, the search stops.
Otherwise, the next re-source(s) are probed.
One question that arises is:which sequence is the optimal one for combiningthe resources.
To answer this question, we did sev-eral experiments on DEV set.
Our experiments haveshown that it is better to search T resource, thenA, and, eventually, L. The results of this combiningmethod, using PP are reported in table 9.
The bestresults are obtained for the TL combination.
TheSAS jumps from 83.11 to 83.76.
As it was the casewith single resources, the LAS and UAS increase ismoderate.B AL TL TA TALSAS 80.84 82.12 83.76 83.50 83.50LAS 88.88 89.03 89.22 89.19 89.19UAS 90.71 90.79 90.98 90.95 90.95Table 9: LAS and UAS on TEST using PP with resourcecombinationWith DP (table 9), the order of resource combina-tion is exactly the same as with PP.
As was the casewith single resources, DP has a positive, but moder-ate, impact on LAS and UAS.The results of tables 9 and 10 do not show con-siderable improvement over single resources.
Thismight be due to the large intersection between ourresources.
In other words, they do not have comple-mentary information, and their combination will notB AL TL TA TALSAS 80.84 82.12 83.76 83.50 83.50LAS 88.88 89.22 89.31 89.34 89.34UAS 90.71 91.02 91.05 91.08 91.09Table 10: LAS and UAS on TEST using DP with resourcecombinationintroduce much information.
Another possible rea-son for this result is the combination technique used.More sophisticated techniques might yield better re-sults.5 ConclusionsSubcategorization frames for verbs constitute a richsource of lexico-syntactic information which is hardto integrate in graph based parsers.
In this paper, wehave used three different resources for subcatego-rization frames.
These resources are from differentorigins with various characteristics.
We have pro-posed two different methods to introduce the usefulinformation from these resources in a second ordermodel parser.
We have conducted different exper-iments on French Treebank that showed a 15.24%reduction of erroneous SF selections for verbs.
Al-though encouraging, there is still plenty of roomfor better results since the oracle score for 100 bestparses is equal to 95.16% SAS and we reached83.76%.
Future work will concentrate on more elab-orate selection functions as well as more sophisti-cated ways to combine the different resources.AcknowledgmentsThis work has been funded by the French AgenceNationale pour la Recherche, through the projectEDYLEX (ANR-08-CORD-009).ReferencesA.
Abeille?, L. Cle?ment, and F. Toussenel.
2003.
Buildinga treebank for french.
In Anne Abeille?, editor, Tree-banks.
Kluwer, Dordrecht.A.
Arun and F. Keller.
2005.
Lexicalization in crosslin-guistic probabilistic parsing: The case of french.
InProceedings of the 43rd Annual Meeting on Associ-ation for Computational Linguistics, pages 306?313.Association for Computational Linguistics.B.
Bohnet.
2010.
Very high accuracy and fast depen-dency parsing is not a contradiction.
In Proceedingsof ACL, pages 89?97.246Michael Brent.
1991.
Automatic acquisition of subcate-gorization frames from untagged text.
In Proceedingsof ACL.Joan Bresnan, editor.
1982.
The Mental Representationof Grammatical Relations.
MIT Press.M.
Candito, B.
Crabbe?, P. Denis, and F. Gue?rin.
2009.Analyse syntaxique du franc?ais : des constituants auxde?pendances.
In Proceedings of Traitement Automa-tique des Langues Naturelles.J.
Carroll, G. Minnen, and T. Briscoe.
1998.
Can sub-categorisation probabilities help a statistical parser?Arxiv preprint cmp-lg/9806013.Eugene Charniak and Mark Johnson.
2005.
Coarse-to-Fine n-Best Parsing and MaxEnt DiscriminativeReranking.
In Proceedings of ACL.Michael Collins.
1997.
Three Generative, LexicalisedModels for Statistical Parsing.
In Proceedings of the35th Annual Meeting of the ACL.Michael Collins.
2000.
Discriminative Reranking forNatural Language Parsing.
In Proceedings of ICML.P.
Denis and B. Sagot.
2010.
Exploitation d?uneressource lexicale pour la construction d?un e?tiqueteurmorphosyntaxique e?tat-de-l?art du franc?ais.
In Pro-ceedings of Traitement Automatique des Langues Na-turelles.Gerald Gazdar, Ewan Klein, Geoffrey K. Pullum, andIvan Sag.
1985.
Generalized Phrase Structure Gram-mar.
Harvard University Press.Aravind Joshi, Leon Levy, and M Takahashi.
1975.
Treeadjunct grammars.
Journal of Computer and SystemSciences, 10:136?163.Anna Kupsc and Anne Abeille?.
2008.
Treelex: A subcat-egorisation lexicon for french verbs.
In Proceedings ofthe First International Conference on Global Interop-erability for Language Resources.Christopher Manning.
1993.
Automatic acquisition ofa large subcategorization dictionary from corpora.
InProceedings of ACL.M.P.
Marcus, M.A.
Marcinkiewicz, and B. Santorini.1993.
Building a large annotated corpus of en-glish: The penn treebank.
Computational linguistics,19(2):313?330.R.
McDonald, K. Crammer, and F. Pereira.
2005a.
On-line large-margin training of dependency parsers.
InProceedings of the 43rd Annual Meeting of the Asso-ciation for Computational Linguistics, pages 91?98.R.
McDonald, F. Pereira, K. Ribarov, and J. Hajic?.
2005b.Non-projective dependency parsing using spanningtree algorithms.
In Proceedings of HLT-EMNLP,pages 523?530.C.
Messiant, A. Korhonen, T. Poibeau, et al2008.Lexschem: A large subcategorization lexicon forfrench verbs.
In Proceedings of the Language Re-sources and Evaluation Conference.S.A.
Mirroshandel and A. Nasr.
2011.
Active learningfor dependency parsing using partially annotated sen-tences.
In Proceedings of International Conference onParsing Technologies.A.
Nasr, F. Be?chet, J-F. Rey, B. Favre, and Le Roux J.2011.
MACAON: An NLP tool suite for processingword lattices.
In Proceedings of ACL.J.
Nivre, J.
Hall, J. Nilsson, A. Chanev, G. Eryigit,S.
Kbler, S. Marinov, and E. Marsi.
2007.
Maltparser:A language-independent system for data-driven de-pendency parsing.
Natural Language Engineering,13(2):95?135.Slav Petrov and Dan Klein.
2008.
Discriminative Log-Linear Grammars with Latent Variables.
In J.C. Platt,D.
Koller, Y.
Singer, and S. Roweis, editors, Advancesin Neural Information Processing Systems 20 (NIPS),pages 1153?1160, Cambridge, MA.
MIT Press.Carl Pollard and Ivan Sag.
1994.
Head-driven PhraseStructure Grammmar.
CSLI Series.
University ofChicago Press.Adwait Ratnaparkhi.
1999.
Learning to parse naturallanguage with maximum entropy models.
Machinelearning, 34(1):151?175.Beno?
?t Sagot.
2010.
The Lefff, a freely available andlarge-coverage morphological and syntactic lexiconfor french.
In Proceedings of the Seventh conferenceon International Language Resources and Evaluation(LREC?10), pages 2744?2751, Valletta, Malta.D.
Zeman.
2002.
Can subcategorization help a statisticaldependency parser?
In Proceedings of the 19th in-ternational conference on Computational linguistics-Volume 1, pages 1?7.
Association for ComputationalLinguistics.247
