A Computational Approach to Deciphering Unknown ScriptsKev in  KnightUSC/Information Sciences Institute4676 Admiralty WayMarina del Rey, CA 90292knight@isi.eduKenji YamadaUSC/Information Sciences Institute4676 Admiralty WayMarina del Rey, CA 90292kyamada@isi.eduAbstractWe propose and evaluate computational techniquesfor deciphering unknown scripts.
We focus on thecase in which an unfamiliar script encodes a knownlanguage.
The decipherment of a brief documentor inscription is driven by data about the spokenlanguage.
We consider which scripts are easy or hardto decipher, how much data is required, and whetherthe techniques are robust against language changeover time.1 IntroductionWith surprising frequency, archaeologists dig updocuments that no modern person can read.Sometimes the written characters are familiar(say, the Phoenician alphabet), but the lan-guage is unknown.
Other times, it is the reverse:the written script is unfamiliar but the languageis known.
Or, both script and language may beunknown.Cryptanalysts also encounter unreadable doc-uments, but they try to read them anyway.With patience, insight, and computer power,they often succeed.
Archaeologists and lin-guists known as epigraphers apply analogoustechniques to ancient documents.
Their deci-pherment work can have many resources as in-put, not all of which will be present in a givencase: (1) monolingual inscriptions, (2) accom-panying pictures or diagrams, (3) bilingual in-scriptions, (4) the historical record, (5) physicalartifacts, (6) bilingual dictionaries, (7) informalgrammars, etc.In this paper, we investigate computationalapproaches to deciphering unknown scripts, andreport experimental results.
We concentrate onthe following case:?
unfamiliar script?
known language?
minimal input (monolingual inscriptionsonly)This situation has arisen in many famouscases of decipherment--for example, in the Lin-ear B documents from Crete (which turnedout to be a "non-Greek" script for writing an-cient Greek) and in the Mayan documents fromMesoamerica.
Both of these cases lay unsolveduntil the latter half of the 20th century (Chad-wick, 1958; Coe, 1993).In computational linguistic terms, this de-cipherment task is not really translation, butrather text-to-speech conversion.
The goal ofthe decipherment is to "make the text speak,"after which it can be interpreted, translated,etc.
Of course, even after an ancient docu-ment is phonetically rendered, it will still con-tain many unknown words and strange con-structions.
Making the text speak is thereforeonly the beginning of the story, but it is a cru-cial step.Unfortunately, current text-to-speech sys-tems cannot be applied directly, becausethey require up front a clearly specifiedsound/writing connection.
For example, a sys-tem designer may create a large pronunciationdictionary (for English or Chinese) or a set ofmanually constructed character-based pronun-ciation rules (for Spanish or Italian).
But indecipherment, this connection is unknown!
It isexactly what we must discover through analysis.There are no rule books, and literate informantsare long-since dead.2 Writing SystemsTo decipher unknown scripts, is useful to under-stand the nature of known scripts, both ancientand modern.
Scholars often classify scripts intothree categories: (1) alphabetic, (2) syllabic,37Figure 1: The Phaistos Disk (c. 1700BC).
Thedisk is six inches wide, double-sided, and is theearliest known document printed with a form ofmovable type.. ~  and (3) log6graphic (Sampson, 1985).Alphabetic systems attempt to repre-sent single sounds with single characters,though no system is "perfect."
For exam-ple, Semitic alphabets have no charactersfor vowel sounds.
And even highly regularwriting systems like Spanish have plenty ofspelling variation, as we shall see later.Syllabic systems have characters for entiresyllables, such as "ba" and "shu."
BothLinear B and Mayan are primarily syllabic,as is Japanese kana.
The Phaistos Diskfrom Crete (see Figure 1) is thought o besyllabic, because of the number of distinctcharacters present.Finally, logographic systems have charac-ters for entire words.
Chinese is often citedas a typical example.Unfortunately, actual scripts do not fallneatly into one category or another (DeFrancis,1989; Sproat, forthcoming).
Written Japanesewill contain syllabic kana, alphabetic roomaji,and logographic kanji characters all in the samedocument.
Chinese characters actually have aphonetic omponent, and words are often com-posed of more than one character.
IrregularEnglish writing is neither purely alphabetic norpurely logographic; it is sometimes called mor-phophonemic.
Ancient writing is also mixed,and archaeologists frequently observe radicalwriting changes in a single language over time.3 Exper imenta l  F rameworkIn this paper, we do not decipher any ancientscripts.
Rather, we develop algorithms and ap-ply them to the "decipherment" of known, mod-ern scripts.
We pretend to be ignorant of theconnection between sound and writing.
Onceour algorithms have come up with a proposedphonetic decipherment of a given document, weroute the sound sequence to a speech synthe-sizer.
If a native speaker can understand thespeech and make sense of it, then we considerthe decipherment a success.
(Note that the na-tive speaker need not even be literate, theoreti-cally).
We experiment with modern writing sys-tems that span the categories described above.We are interested in the following questions:?
Can automatic techniques decipher an un-known script?
If so, how accurately??
What quantity of written text is neededfor successful decipherment?
(this may be?
quite limited by circumstances)?
What knowledge of the spoken language isneeded?
Can it to be extracted automati-cally from available resources?
What quan-tity of resources??
Are some writing systems easier to decipherthan others?
Are there systematic differ-ences among alphabetic, syllabic, and lo-gographic systems??
Are word separators necessary or helpful??
Can automatic techniques be robustagainst language evolution (e.g., modernversus ancient forms of a language)??
Can automatic techniques identify the lan-guage behind a script as a precursor to de-ciphering it?4 A lphabet ic  Wr i t ing  (Span ish)Five hundred years ago, Spaniards invadedMayan lands, burning documents and effec-tively eliminating everyone who could read andwrite.
(Modern Spaniards will be quick to pointout that most of the work along those lines38Sounds:B, D, G, J (ny as in canyon), L (y asin yarn), T (th as in thin), a, b, d, e,f, g, i, k, l, m, n, o, p, r, rr (trilled), s,t, tS (ch as in chin), u, x (h as in hat)Characters:fi, ?, 6, i, o, u, a, b, c, d, e, f, g, h, i, j,k, l, m, n, o, p, q, r, s, t, u, v, w, x, y,ZFigure 2: Inventories of Spanish sounds (withrough English equivalents in parentheses) andcharacters.had already been carried out by the Aztecs).Mayan hieroglyphs remained uninterpreted formany centuries.
We imagine that if the Mayanshave invaded Spain, then 20th century Mayanscholars might be deciphering ancient Spanishdocuments instead.We begin with an analysis of Spanish writing.The task of decipherment will be to re-inventthese rules and apply them to written docu-ments in reverse.
First, is necessary to settleon the basic inventory of sounds and characters.Characters are easy; we simply tabulate the dis-tinct ones observed in text.
For sounds, we needsomething that  will serve as reasonable input toa speech synthesizer.
We use a Spanish-relevantsubset of the International Phonetic Alphabet(IPA), which seeks to capture all sounds in alllanguages.
Actually, we use an ASCII versionof the IPA called SAMPA (Speech AssessmentMethods Phonetic Alphabet), originally devel-oped under ESPRIT  project 1541.
There is alsoa public-domain Castillian speech synthesizer(called Mbrola) for the Spanish SAMPA soundset.
Figure 2 shows the sound and characterinventories.Now to spelling rules.
Spanish writing isclearly not a one-for-one proposition:?
a single sound can produce a single charac-ter (a -+ a)* a sound can produce two characters (tSch)?
two sounds can produce a single character(k s ---+ x)B -+borvD~dG~gJ - -+f iL--+ l lo rya .--~ a or ?b --.~.
b or vd - -~de ---~ e or 6f~fgagi~ ior~l~ lm-+mn- -+no -moor6p - -~pr - - J rt - - r ttS~chu--~ u or fix -+ jnothing --+ hT (followed by a, o, or u) ~ zT (followed by e or i) --+ c or zT (otherwise) ~ ck (followed by e or i) ~ q uk (followed by s) ---+ xk (otherwise) ~ crr (at beginning of word) ~ rrr (otherwise) ---,, rrs (preceded by k) ~ nothings (otherwise) --+ sFigure 3: Spanish sound-to-character spellingrules.
The left-hand side of each rule contains aSpanish sound (and possible conditions), whilether ight-hand side contains zero or more Span-ish characters.?
silence can produce a character (h)Moreover, there are ambiguities.
The sound L(English y-sound) may be written as either ll ory.
The sound i may also produce the charactery, so the pronunciation of y varies according tocontext.
The sound rr (trilled r) is written rr inthe middle of a word and r at the beginning ofa word.Figure 3 shows a sample set of Spanish39spelling rules.
We formalized these rules com-putationally in a finite-state transducer (Pereiraand Riley, 1997).
The transducer is bidirec-tional.
Given a specific sound sequence, wecan extract all possible character sequences, andvice versa.
It turns out that while there aremany ways to write a given Spanish sound se-quence with these rules, it is fairly clear how topronounce a written sequence?In our decipherment experiment, we blithelyignore many of the complications just described,and pretend that  Spanish writing is, in fact, aone-for-one proposition.
That  is, to write downa sound sequence, one replaces each sound witha single character.
We do allow ambiguity, how-ever.
A given sound may produce one charactersometimes, and another character other times.Decipherment is driven by knowledge aboutthe spoken language.
In the case of archeologi-cal decipherment, his knowledge may includevocabulary, grammar,  and meaning.
We usesimpler data.
We collect frequencies of sound-triples in spoken Spanish.
If we know that triple"t 1 k" is less frequent than "a s t," then weshould ult imately prefer a decipherment thatcontains the latter instead of the former, allother things being equal.This leads naturally in to  a statistical ap-proach to decipherment.
Our goal is to settleon a sound-to-character scheme that somehowmaximizes the probability of the observed writ-ten document.
Like many linguistic problems,this one can be formalized in the noisy-channelframework.
Our sound-triple frequencies canbe turned into conditional probabilities uch asP(t  I a s).
We can estimate the probability ofa sound sequence as the product of such localprobabilities.P(sl .
.
.
sn)P(s3 I Sl s2) ?
P(s4 I s2 s3) ?
P(s5 I s3 s4) .
.
.
.A specific sound-to-character scheme can berepresented as a set of conditional probabilitiessuch as P(v I B).
Read this as "the probabilitythat Spanish sound B is written with characterv."
We can estimate the conditional probabil-ity of entire character sequence given an entiresound sequence as a product of such probabili-ties.P(cl .
.
.on \]Sl .
.
.
s , )  ,.~P(cl Is1) ?
P(c2 Is2) ?
P(c3 I $3) " .
.
.Armed with these basic probabilities, we cancompute two things.
First, the total probabil-ity of observing a particular written sequence ofcharacters cl .
.
.
cn:P(Cl ...Cn) =Es,.. .s.
P(sl .
.
.
s , )  ?
P(c 1 .
.
.Cn  I Sl .
.
.Sn)And second, we can compute the most proba-ble phonetic decipherment sl .
.
.
s ,  of a particu-lar written sequence of characters cl .
.
.
c , .
Thiswill be the one that maximizes P(sl .
.
.s~ I cl?
.
.cn), or equivalently, maximizes P(sl .
.
.s~)?
P(cl .
.
.
c ,  I Sl .
.
.sn) .
The trick is that theP(character I sound ) probabilities are unknownto us.
We want to assign values that maximizeP(cl .
.
.
c , ) .
These same values can then beused to decipher.We adapt the EM algorithm (Dempster etal., 1977), for decipherment, starting with auniform probability over P(character \[ sound).That  is, any sound will produce any characterwith probability 0.0333.
The algorithm succes-sively refines these probabilities, guaranteeingto increase P(cl .
.
.
cn) at each iteration.
EM re-quires us to consider an exponential number ofdecipherments at each iteration, but this can bedone efficiently with a dynamic-programmingimplementation (Baum, 1972).
The trainingscheme is illustrated in Figure 4.In our experiment, we use the first page ofthe novel Don Quixote as our "ancient" Span-ish document cl .
.
.cn.
To get phonetic data,we might tape-record modern Spanish speak-ers and transcribe the recorded speech into theIPA alphabet.
Or we might use documentswritten in an alternate, known script, if anyexisted.
In this work, we take a short cutby reverse-engineering a set of medical Spanishdocuments, using the finite-state transducer de-scribed above, to obtain a long phonetic trainingsequence Sl ?
?
?
s,~.At each EM iteration, we extract the mostprobable decipherment and synthesize it intoaudible form.
At iteration 0, with uniformprobabil!ties, the result is pure babble.
Atiteration 1, Spanish speakers report that  "itsounds like someone speaking Spanish, but us-ing words I don't  know."
At iteration 15,the decipherment can be readily understood.
(Recordings can be accessed on the WorldWide Web at ht tp  : llwww, i s i .
edu /natura l -40soundi ~  sequenci~i ............................................................................. iI trained on iobservablespoken data.
L_trained on document written inunknown script (only sound-to-characterparameter values are allowed to changeduring training).charactersequencesFigure 4: Training scheme for decipherment.We first train a phonetic model on phoneticdata.
We then combine the phonetic model witha generic (uniform) spelling model to create aprobabilistic generator of character sequences.Given a particular character sequence ("an-cient document"), the EM algorithm searchesfor adjustments o the spelling model that willincrease the probability of that character se-quence.la.nguago/mt/decipher, tml).If we reverse-engineer Don Quixote, we canobtain a gold standard phonetic decipherment.Our automatic decipherment correctly identifies96% of the sounds.
Incorrect or dropped soundsare due to our naive one-for-one model, and notto weak algorithms or small corpora.
For ex-ample, "de la Mancha" is deciphered as "d e la m a n T i a" even though the characters chreally represent the single sound tS rather thanthe two sounds T i.Figure 5 shows how performance changes ateach EM iteration.
It shows three curves.
Theworst-performing curve reflects the accuracy ofthe most-probable decipherment using the for-mula above, i.e., the one that maximizes P(sl?
..sn) ?
P(cl .
.
.ca \] sl ...sn).
We find thatit is better to ignore the P(Sl ...s,~) factor al-together, because while the learned sound-to-Deciphermentaccuracy(% phonemescorrectlypronounced)100% --90% --80% --70% --60% --50% --<<<<maximizingP(sl...sn) * P(cl...cn I sl...sn) 3~maximiz ing  P(cl .
.
.c .
I sl.
.
.s.)P(sl...S.)
* P(c l .
.
.c .
I s l .
sn)I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I I IEM iterationsFigure 5: Performance of Spanish decipher-ment.
As we increase the number of EM it-erations, we see an improvement in decipher-ment performance (measured in terms of cor-rectly generated phonemes).
The best resultis obtained by weighting the learned spellingmodel more highly than the sound model, i.e.,by choosing a phonetic decoding Sl ...sn forcharacter sequence cl ... c~ that maximizes P(sl.
.
.
s . )
?
P(cl .
.
.
c .
Is1 .
.
.
s .
)character probabilities are fairly good, they arestill somewhat unsure, and this leaves room forthe phonetic model to overrule them incorrectly.However, the P(sl ...sn) model does have use-ful things to contribute.
Our best performance,shown in the highest curve, is obtained byweighing the learned sound-to-character prob-abilities more highly, i.e., by maximizing P(sl?
.
.Sn)"  P (C l  .
.
.
ca  I sl ...sn) 3.We performed some alternate xperiments?Using phoneme pairs instead of triples isworkable--it results in a drop from 96% ac-curacy to 92%.
Our main experiment uses41word separators; removing these degrades per-formance.
For example, it becomes more dif-ficult to tell whether the r character should betrilled or not.
In our experiments with Japaneseand Chinese, described next, we did not useword separators, as these languages are usuallywritten without them.5 Sy l lab ic  wr i t ing  ( Japanese  Kana)The phonology of Japanese adheres trongly toa consonant-vowel-consonant-vow@l structure,which makes it quite amenable to syllabic writ-ing.
Indeed, the Japanese have devised a kanasyllabary consisting of about 80 symbols.
Thereis a symbol for ka, another for ko, etc.
Thus,the writing of a sound like K depends on itsphonetic ontext.
Modern Japanese is not writ-ten in pure kana; it employs a mix of alpha-betic, syllabic, and logographic writing devices.However, we will use pure kana as a stand-infor wide range of syllabic writing systems, asJapanese data is readily available.
We obtainkana text sequences from the Kyoto Treebank,and we obtain sound sequences by using thefinite-state transducer described in (Knight andGraehl, 1998).As with Spanish, we build a spoken languagemodel based on sound-triple frequencies.
Thesound-to-kana model is more complex.
We as-sume that each kana token is produced by asequence of one, two, or three sounds.
Us-ing knowledge of syllabic writing in general--plus an analysis of Japanese sound patterns--we restrict hose sequences to be (1) consonant-vowel, (2) vowel-only, (3) consonant-no-vowel,and (4) consonant-semivowel-vowel.
For ini-tial experiments, we mapped "small kana" ontotheir large versions, even though this leads tosome incorrect learning targets, such as KIYOinstead of KYO.
We implement the sound- andsound-to-kana models in a large finite-state ma-chine and use EM to learn individual weightssuch as P(ka-kana \[ SHY U).
Unlike the Spanishcase, we entertain phonetic hypotheses of vari-ous lengths for any given character sequence.Deciphering 200 sentences of kana text yields99% phoneme accuracy.
We render the soundsimperfectly (yet inexpensively) through ourpublic-domain Spanish synthesizer.
The resultis comprehensible to a Japanese speaker.We also experimented with decipheringsmaller documents.
100 sentences yields 97.5%accuracy; 50 sentences yields 96.2% accuracy;20 sentences yields 82.2% accuracy; five sen-tences yields 48.5% accuracy.
If we were togive the sound sequence model some knowledgeabout words or grammar, the accuracy wouldlikely not fall off as quickly.6 "Logograph ic"  wr i t ing  (Ch inese)As we mentioned in Section 2, Chinese char-.... acters .have internal phonetic omponents, andwritten Chinese does not really have a differ-ent character for every word: so, it is not re-ally logographic.
However, it is representativeof writing systems whose distinct characters aremeasured in the thousands, as opposed to 20-50for alphabets and 40-90 for syllabaries.
Thiscreates everal difficulties for decipherment:?
computational complexity--our decipher-ment algorithm runs in time roughly cubicin the number of known sound triples.?
very rare characters--if we only see a char-acter once, the context may not be richenough for us to guess its sound.?
sparse sound-triple data-- the decipher-ment of a written text is likely to includenovel sound triples.We created spoken language data for Chineseby automatically (if imperfectly) pronouncingChinese text.
We are indebted to RichardSproat for running our documents through thetext-to-speech system at Bell Labs.
We createdsound-pair frequencies over the resulting set of1177 distinct syllables, represented in pinyinformat, suitable for synthesizing speech.
We at-tempted to decipher a written document of 1900phrases and sentences, containing 2113 distinctcharacters and no word separators.Our result was 22% syllable accuracy, after20 EM iterations.
We may compare this to abaseline strategy of guessing the pinyin soundde0 (English "of") for every character, whichyields 3.2% accuracy.
This shows a considerableimprovement, but the speech in not comprehen-sible.
Due to computational limits, we had to(1) eliminate all pinyin pairs that occurred lessthan five times, and (2) prevent our decoderfrom proposing any novel pinyin pairs.
Becauseour our goal-standard decipherment contained42many rare sounds and novel pairs, these com-putational limits severely impaired accuracy.7 D iscuss ionWe have presented and tested a computationalapproach to phonetically deciphering writtenscripts.
We cast decipherment as a specialkind of text-to-speech conversion in which wehave no rules or data that directly connectspeech sounds with written characters.
We setup general finite-state transducers for turningsounds into writing, and use the EM algorithmto estimate their parameters.
The whole pro-cess is driven by knowledge about the spokenlanguage, which may include frequency infor-mation about sounds, sound sequences, words,grammar, meaning, etc.
An interesting resultis that decipherment is possible using limitedknowledge of the spoken language, e.g., sound-triple frequencies.
This is encouraging, becauseit may provide robustness against language vo-lution, a fixture of archaeological deciphering.However, our experiments have been targeteda bit narrowly.
We were able to re-use the Span-ish decoder on Chinese, but it could not workfor Japanese kana.
Even our Japanese decoderwould fail on an alternative syllabic script forJapanese which employed a single symbol forthe sound KAO, instead of separate kana sym-bols for KA and O.
One ambitious line of re-search would be to examine writing systems inan effort to invent a single, generic "mother ofall writing systems," whose specializations in-clude a large fraction of actual ones.
To coverSpanish and Japanese, for example, we could setup a scheme in which each sound produces zeroor more characters, where the sound is poten-tially influenced by the two sounds immediatelypreceding and following it.
This gets tricky: the"mother Of all" has to be general, but it also hasto be narrow enough to support deciphermentthrough automatic training.
(Sproat, forthcom-ing) suggests the class of finite-state transduc-ers as one candidate.
This narrows things downsignificantly from the class of Turing machines,but not far enough for the direct application ofknown training algorithms.In the future, we would like to attack an*cient scripts.
We would start with scripts thathave already been roughly deciphered by ar-chaeologists.
Computer decipherments could bechecked by humans, and published human deci-pherments could be checked by computer.
Wewould subsequently like to attack ancient scriptsthat yet to be deciphered.
High-speed comput-ers are not very intelligent, but they display apatience that exceeds even the most thoroughhuman linguist.It will be important o consider text-layoutquestions when dealing with real scripts.
For ex-ample, Mayan glyphs may run from top to bot-tom, right to left, or they may run differently.Furthermore, ach glyph contain sub-parts rep-resenting up to ten sounds, and these may beorganized in a spiral pattern.Another intriguing possibility is to do lan-guage identification at the same time as deci-pherment.
Such identification would need tobe driven by online sound sets and spoken cor-pora that span a very wide range of languages.Whether a document represents a given lan-guage could then be estimated quantitatively.In case language identification fails, we maybe faced with a completely extinct language.Current computational techniques demonstratethat it is theoretically possible to figure outwhere nouns, verbs, and adjectives from rawtext, but actual translation into English is an-other matter.
Archaeologists have sometimessucceeded in such cases by leveraging bilingualdocuments and loan words from related lan-guages.
Only a truly optimistic cryptanalystwould believe that progress could be made evenwithout these resources; but see (AI-Onaizanand Knight, 1999) for initial results on Arabic-English translation using only monolingual re-sources.Finally, we note that the application ofsource-channel models to the text-to-speechproblem is promising.
This kind of statisticalmodeling is prevalent in speech recognition, butours is one of the few applications in speech syn-thesis.
It may be possible to use uncorrelatedstreams of speech and text data to learn map-pings that go beyond character pronunciation,to pitch, duration, stress, and so on.Re ferencesY.
A1-Onaizan and K. Knight.
1999.
Aciphertext-only approach to translation.
(Inpreparation).43L.
E. Baum.
1972.
An inequality and associatedmaximization technique in statistical estima-tion of probabilistic functions of a Markovprocess.
Inequalities, 3.J.
Chadwick.
1958.
The Decipherment o/Lin-ear B. Cambridge University Press, Cam-bridge.M.
Coe.
1993.
Breaking the Maya Code.Thames and Hudson, New York.J.
DeFrancis.
1989.
Visible Speech: The Di-verse Oneness of Writing Systems.
Univer-sity of Hawaii Press, Honolulu.A.
P. Dempster, N. M. Laird, and D. B. Rubin.1977.
Maximum likelihood from incompletedata via the EM algorithm.
Journal of theRoyal Statistical Society, 39(B):1-38.K.
Knight and J. Graehl.
1998.
Machinetransliteration.
Computational Linguistics,24(4).F.
Pereira and M. Riley.
1997.
Speech recog-nition by composition of weighted finite au-tomata.
In E. Roche and Y. Schabes, editors,Finite-State Language Processing.
MIT Press.J.
Sampson.
1985.
Writing Systems.
Stanford,Stanford.R.
Sproat.
forthcoming.
A Computational The-ory of Writing Systems.44
