Proceedings of the 5th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, pages 50?58,Baltimore, Maryland, USA.
June 27, 2014.c?2014 Association for Computational LinguisticsModelling Sarcasm in Twitter, a Novel ApproachFrancesco Barbieri and Horacio Saggion and Francesco RonzanoPompeu Fabra University, Barcelona, Spain<firstName>.<lastName>@upf.eduAbstractAutomatic detection of figurative languageis a challenging task in computational lin-guistics.
Recognising both literal and fig-urative meaning is not trivial for a ma-chine and in some cases it is hard evenfor humans.
For this reason novel andaccurate systems able to recognise figura-tive languages are necessary.
We presentin this paper a novel computational modelcapable to detect sarcasm in the socialnetwork Twitter (a popular microbloggingservice which allows users to post shortmessages).
Our model is easy to imple-ment and, unlike previous systems, it doesnot include patterns of words as features.Our seven sets of lexical features aim todetect sarcasm by its inner structure (forexample unexpectedness, intensity of theterms or imbalance between registers), ab-stracting from the use of specific terms.1 IntroductionSarcasm is a mode of communication where literaland intended meanings are in opposition.
Sarcasmis often used to express a negative message usingpositive words.
Automatic detection of sarcasm isthen very important in the sentiment analysis field,as a sarcastic phrase that includes positive wordsconveys a negative message and can be easily mis-understood by an automatic system.A number of systems with the objective of de-tecting sarcasm have been designed in the pastyears (Davidov et al., 2010; Gonz?alez-Ib?a?nez etal., 2011; Riloff et al., 2013).
All these computa-tional models have in common the use of frequentand typical sarcastic expressions as features.
Thisis of course a good approach as some words areused sarcastically more often than others.Our research seeks to avoid the use of words asfeatures, for two reasons.
Firstly, we want to re-duce the complexity of the computational model,decreasing drastically the number of features re-quired for classification.
Secondly, typical sarcas-tic expressions are often culturally specific (an ex-pression that is considered sarcastic in British En-glish is not necessary sarcastic in American En-glish and vice-versa).
For these reasons we havedesigned a system that aims to detect sarcasmwithout the use of words and patterns of words.We use simple features such as punctuation (Car-valho et al., 2009) and more sophisticated features,that for example detect imbalance between regis-ters (the use of an ?out of context?
word may sug-gest sarcastic intentions) or the use of very intenseterms.We study sarcasm detection in the micro-blogging platform Twitter1that allows users tosend and read text messages (shorter than 140characters) called tweets, which often do not fol-low the expected rules of the grammar.
The datasetwe adopted contains positive examples tagged assarcastic by the users (using the hashtag #sarcasm)and negative examples (tagged with a differenthashtag).
This methodology has been previouslyused in similar studies (Reyes et al., 2013; Lukinand Walker, 2013; Liebrecht et al., 2013).We presented in Barbieri and Saggion (2014) amodel capable of detecting irony, in this paper weadd important features to this model and evaluatea new corpus to determine if our system is capa-ble of detecting tweets marked as sarcastic (#sar-casm).
The contributions of this paper are the fol-lowing:?
Novel set of features to improve the perfor-mances of our model?
A new set of experiments to test our model?sability to detect sarcasm?
A corpus to study sarcasm in twitter1https://twitter.com/50We will show in the paper that results are posi-tive and the system recognises sarcasm with goodaccuracy in comparison with the state-of-the-art.The rest of the paper is organised as follows: inthe next Section we describe related work.
InSection 3 we describes the corpus and text pro-cessing tools used and in Section 4 we presentour approach to tackle the sarcasm detection prob-lem.
Section 5 describes the experiments whileSection 6 interprets the results.
Finally, we closethe paper in Section 7 with conclusions and futurework.2 Related WorkA standard definition for sarcasm seems not to ex-ist.
Sarcasm is often identified as irony or verbalirony (?).
Irony has been defined in several waysover the years as for example ?saying the oppositeof what you mean?
(Quintilien and Butler, 1953),or by Grice (1975) as a rhetorical figure that vio-lates the maxim of quality: ?Do not say what youbelieve to be false?, or as any form of negationwith no negation markers (Giora, 1995).
Otherdefinitions are the ones of Wilson and Sperber(2002) who states irony is an echoic utterance thatshows a negative aspect of someone?s else opinion,and as form of pretence by Utsumi (2000) and byVeale and Hao (2010a).
Veale states that ?ironicspeakers usually craft their utterances in spite ofwhat has just happened, not because of it.
Thepretence alludes to, or echoes, an expectation thathas been violated?.Irony and sarcasm has been approached ascomputation problem recently by Carvalho et al.
(2009) who created an automatic system for de-tecting irony relying on emoticons and specialpunctuation.
They focused on detection of ironicstyle in newspaper articles.
Veale and Hao (2010b)proposed an algorithm for separating ironic fromnon-ironic similes, detecting common terms usedin this ironic comparison.
Reyes et al.
(2013) andalso Barbieri and Saggion (2014) have recentlyproposed two approaches to detect irony in Twit-ter.
There are also some computational model todetect sarcasm in Twitter.
The systems of Gon-zalez et al.
(2011) and Davidov et al.
(2010) de-tect sarcasm with good accuracy in English tweets(the latter model is also studied in the Amazonreview context).
Lukin and Walker (2013) usedbootstrapping to improve the performance of sar-casm and nastiness classifiers for Online Dialogue,and Liebrecht et al.
(2013) designed a model to de-tect sarcasm in Duch tweets.
Finally Riloff (2013)built a model to detect sarcasm with a bootstrap-ping algorithm that automatically learn lists ofpositive sentiments phrases and negative situationphrases from sarcastic tweet, in order to detect thecharacteristic of sarcasm of being a contrast be-tween positive sentiment and negative situation.One may argue that sarcasm and irony are thesame linguistic phenomena, but in our opinion thelatter is more similar to mocking or making jokes(sometimes about ourselves) in a sharp and non-offensive manner.
On the other hand, sarcasm isa meaner form of irony as it tends to be offensiveand directed towards other people (or products likein Amazon reviews).
Textual examples of sarcasmlack the sharp tone of an aggressive speaker, sofor textual purposes we think irony and sarcasmshould be considered as different phenomena andstudied separately (Reyes et al., 2013).Some datasets exist for the study of sarcasm andirony.
Filatova (2012) designed a corpus genera-tion experiment where regular and sarcastic Ama-zon product reviews were collected.
Also Boscoet.
al (2013) collected and annotate a set of ironicexamples (in Italian) for the study of sentimentanalysis and opinion mining.3 Data and Text ProcessingWe adopted a corpus of 60,000 tweets equallydivided into six different topics: Sarcasm, Edu-cation, Humour, Irony, Politics and Newspaper.The Newspaper set includes 10,000 tweets fromthree popular newspapers (New York Times, TheEconomist and The Guardian).
The rest of thetweets (50,000) were automatically selected bylooking at Twitter hashtags #education, #humour,#irony, #politics and #sarcasm) added by users inorder to link their contribution to a particular sub-ject and community.
These hashtags are removedfrom the tweets for the experiments.
According toReyes et al.
(2013), these hashtags were selectedfor three main reasons: (i) to avoid manual se-lection of tweets, (ii) to allow irony analysis be-yond literary uses, and because (iii) irony hash-tag may ?reflect a tacit belief about what consti-tutes irony?
(and sarcasm in the case of the hash-tag #sarcasm).
Education, Humour and Politicstweets were prepared by Reyes et al.
(2013), we51added Irony, Newspaper and Sarcasm tweets2.
Weobtained these data using the Twitter API.Examples of tweets tagged with #sarcasm are:?
This script is superb, honestly.?
First run in almost two months.
I think I didreally well.?
Jeez I just love when I?m trying to eat lunchand someone?s blowing smoke in my face.Yum.
I love ingesting cigarette smoke.Another corpora is employed in our approach tomeasure the frequency of word usage.
We adoptedthe Second Release of the American National Cor-pus Frequency Data3(Ide and Suderman, 2004),which provides the number of occurrences of aword in the written and spoken ANC.
From nowon, we will mean with ?frequency of a term?
theabsolute frequency the term has in the ANC.Processing microblog text is not easy becausethey are noisy, with little context, and often En-glish grammar rules are violated.
For these rea-sons, in order to process the tweets, we use theGATE Plugin TwitIE (Bontcheva et al., 2013) astokeniser and Part of Speech Tagger.
The POStagger (adapted version of the Stanford tagger(Toutanova et al., 2003)) achieves 90.54% tokenaccuracy, which is a very good results knowingthe difficulty of the task in the microblogging con-text.
This POS tagger is more accurate and reliablethan the method we used in the previous research,where the POS of a term was defined by the mostcommonly used (provided by WordNet).
TwitIEalso includes the best Named Entity Recognitionsfor Twitter (F1=0.8).We adopted also Rita WordNet API (Howe,2009) and Java API for WordNet Searching (Spell,2009) to perform operations on WordNet synsets.4 MethodologyWe approach the detection of sarcasm as a clas-sification problem applying supervised machinelearning methods to the Twitter corpus describedin Section 3.
When choosing the classifiers we hadavoided those requiring features to be independent2To make possible comparisons with our sys-tem we published the IDs of these tweets athttp://sempub.taln.upf.edu/tw/wassa2014/3The American National Corpus (http://www.anc.org/) is,as we read in the web site, a massive electronic collection ofAmerican English words (15 million)(e.g.
Naive Bayes) as some of our features are not.Since we approach the problem as a binary deci-sion we picked a tree-based classifiers: DecisionTree.
We already studied the performance of an-other classifier (Random Forest) but even if Ran-dom Forest performed better in cross validationexperiments, Decision Tree resulted better in crossdomain experiments, suggesting that it would bemore reliable in a real situation (where the nega-tive topics are several).
We use the Decision Treeimplementation of the Weka toolkit (Witten andFrank, 2005).Our model uses seven groups of features to rep-resent each tweet.
Some of them are designedto detect imbalance and unexpectedness, othersto detect common patterns in the structure of thesarcastic tweets (like type of punctuation, length,emoticons), and some others to recognise senti-ments and intensity of the terms used.
Below isan overview of the group of features in our model:?
Frequency (gap between rare and commonwords)?
Written-Spoken (written-spoken style uses)?
Intensity (intensity of adverbs and adjectives)?
Structure (length, punctuation, emoticons)?
Sentiments (gap between positive and nega-tive terms)?
Synonyms (common vs. rare synonyms use)?
Ambiguity (measure of possible ambiguities)To the best of our knowledge Frequency, WrittenSpoken, Intensity and Synonyms groups have notbeen used before in similar studies.
The othergroups have been used already (for example byCarvalho et al.
(2009) or Reyes et al.
(2013)) yetour implementation is different.In the following sections we quickly describe allthe features we used.4.1 FrequencyUnexpectedness can be a signal of verbal irony,Lucariello (1994) claims that irony is strictly con-nected to surprise, showing that unexpectedness isthe feature most related to situational ironies.
Inthis first group of features we try to detect it.
Weexplore the frequency imbalance between words,i.e.
register inconsistencies between terms of the52same tweet.
The idea is that the use of many wordscommonly used in English (i.e.
high frequency inANC) and only a few terms rarely used in English(i.e.
low frequency in ANC) in the same sentencecreates imbalance that may cause unexpectedness,since within a single tweet only one kind of regis-ter is expected.Three features belong to this group: frequencymean, rarest word, frequency gap.
The first oneis the arithmetic average of all the frequencies ofthe words in a tweet, and it is used to detect thefrequency style of a tweet.
The second one, rarestword, is the frequency value of the rarest word,designed to capture the word that may create im-balance.
The assumption is that very rare wordsmay be a sign of irony.
The third one is the abso-lute difference between the first two and it is usedto measure the imbalance between them, and cap-ture a possible intention of surprise.4.2 Written-SpokenTwitter is composed of written text, but an infor-mal spoken English style is often used.
We de-signed this set of features to explore the unexpect-edness created by using spoken style words in amainly written style tweet or vice versa (formalwords usually adopted in written text employed ina spoken style context).
We can analyse this aspectwith ANC written and spoken, as we can see us-ing this corpora whether a word is more often usedin written or spoken English.
There are three fea-tures in this group: written mean, spoken mean,written spoken gap.
The first and second ones arethe means of the frequency values, respectively, inwritten and spoken ANC corpora of all the wordsin the tweet.
The third one, written spoken gap,is the absolute value of the difference between thefirst two, designed to see if ironic writers use bothstyles (creating imbalance) or only one of them.
Alow difference between written and spoken stylesmeans that both styles are used.4.3 StructureWith this group of features we want to study thestructure of the tweet: if it is long or short (length),if it contains long or short words (mean of wordlength), and also what kind of punctuation is used(exclamation marks, emoticons, etc.
).The length feature consists of the number ofcharacters that compose the tweet, n. words isthe number of words, and words length mean isthe mean of the words length.
Moreover, we usethe number of verbs, nouns, adjectives and adverbsas features, naming them n. verbs, n. nouns, n.adjectives and n. adverbs.
With these last fourfeatures we also computed the ratio of each partof speech to the number of words in the tweet; wecalled them verb ratio, noun ratio, adjective ra-tio, and adverb ratio.
All these features have thepurpose of capturing the style of the writer.The punctuation feature is the sum of the num-ber of commas, full stops, ellipsis and exclama-tion that a tweet presents.
We also added a featurecalled laughing which is the sum of all the inter-net laughs, denoted with hahah, lol, rofl, and lmaothat we consider as a new form of punctuation: in-stead of using many exclamation marks internetusers may use the sequence lol (i.e.
laughing outloud) or just type hahaha.Inspired by Davidov et al.
(2010) and Carvalho(2009) we designed features related to punctua-tion.
These features are: number of commas, fullstops, ellipsis, exclamation and quotation marksthat a tweet contain.The emoticon feature is the sum of the emoti-cons :), :D, :( and ;) in a tweet.The new features we included are http that sim-ply says if a tweet includes or not an Internetlink, and the entities features provided by TwitIE(Bontcheva et al., 2013).
These features check if atweet contains the following entities: n. organisa-tion, n. location, n. person, n. first person, n. title,n job title, n. date.
These last seven features werenot available in the previous model, and some ofthem work very well when distinguishing sarcasmfrom newspaper tweets.4.4 IntensityIn order to produce a sarcastic effect some authorsmight use an expression which is antonymic towhat they are trying to describe (saying the op-posite of what they mean (Quintilien and Butler,1953)).
In the case the word being an adjectiveor adverb its intensity (more or less exaggerated)may well play a role in producing the intended ef-fect (Riloff et al., 2013).
We adopted the intensityscores of Potts (2011) who uses naturally occur-ring metadata (star ratings on service and prod-uct reviews) to construct adjectives and adverbsscales.
An example of adjective scale (and relativescores in brackets) could be the following: horri-ble (-1.9)?
bad (-1.1)?
good (0.2)?
nice (0.3)?
great (0.8).53With these scores we evaluate four features foradjective intensity and four for adverb intensity(implemented in the same way): adj (adv) tot,adj (adv) mean, adj (adv) max, and adj (adv)gap.
The sum of the AdjScale scores of all the ad-jectives in the tweet is called adj tot.
adj mean isadj tot divided by the number of adjectives in thetweet.
The maximum AdjScale score within a sin-gle tweet is adj max.
Finally, adj gap is the differ-ence between adj max and adj mean, designed tosee ?how much?
the most intense adjective is outof context.4.5 SynonymsAs previously said, sarcasm convey two messagesto the audience at the same time.
It follows that thechoice of a term (rather than one of its synonyms)is very important in order to send the second, notobvious, message.For each word of a tweet we get its synonymswith WordNet (Miller, 1995), then we calculatetheir ANC frequencies and sort them into a de-creasing ranked list (the actual word is part of thisranking as well).
We use these rankings to definethe four features which belong to this group.
Thefirst one is syno lower which is the number of syn-onyms of the word wiwith frequency lower thanthe frequency of wi.
It is defined as in Equation 1:slwi= |syni,k: f(syni,k) < f(wi)| (1)where syni,kis the synonym of wiwith rank k,and f(x) the ANC frequency of x.
Then we alsodefined syno lower mean as mean of slwi(i.e.
thearithmetic average of slwiover all the words of atweet).We also designed two more features: synolower gap and syno greater gap, but to definethem we need two more parameters.
The first oneis word lowest syno that is the maximum slwiin atweet.
It is formally defined as:wlst= maxwi{|syni,k: f(syni,k) < f(wi)|}(2)The second one is word greatest syno defined as:wgst= maxwi{|syni,k: f(syni,k) > f(wi)|}(3)We are now able to describe syno lower gapwhich detects the imbalance that creates a com-mon synonym in a context of rare synonyms.
It isthe difference between word lowest syno and synolower mean.
Finally, we detect the gap of veryrare synonyms in a context of common ones withsyno greater gap.
It is the difference betweenword greatest syno and syno greater mean, wheresyno greater mean is the following:sgmt=|syni,k: f(syni,k) > f(wi)|n.
words of t(4)The arithmetic averages of syno greater gapand of syno lower gap in the Sarcasm corpus arehigher than in the other topics, suggesting that avery common (or very rare) synonym is often usedout of context i.e.
a very rare synonym when mostof the words are common (have a high rank in ourmodel) and vice versa.4.6 AmbiguityAnother interesting aspect of sarcasm is ambi-guity.
We noticed that sarcastic tweets presentswords with more meanings (more WordNetsynsets).
Our assumption is that if a word hasmany meanings the possibility of ?saying some-thing else?
with this word is higher than in a termthat has only a few meanings, then higher possibil-ity of sending more then one message (literal andintended) at the same time.There are three features that aim to capturethese aspects: synset mean, max synset, andsynset gap.
The first one is the mean of the num-ber of synsets of each word of the tweet, to see ifwords with many meanings are often used in thetweet.
The second one is the greatest number ofsynsets that a single word has; we consider thisword the one with the highest possibility of beingused ironically (as multiple meanings are availableto say different things).
In addition, we calculatesynset gap as the difference between the numberof synsets of this word (max synset) and the av-erage number of synsets (synset mean), assumingthat if this gap is high the author may have usedthat inconsistent word intentionally.4.7 SentimentsWe also evaluate the sentiment of the sarcas-tic tweets.
The SentiWordNet sentiment lexicon(Esuli and Sebastiani, 2006) assigns to each synsetof WordNet sentiment scores of positivity and neg-ativity.
We used these scores to examine what kindof sentiments characterises sarcasm.
We exploreironic sentiments with two different views: thefirst one is the simple analysis of sentiments (to54Figure 1: Information gain of each feature of the model.
Sarcasm is compared to Education, Humor,Irony, Newspaper and Politics.
High values of information gain help to better discriminate sarcasticfrom non-sarcastic tweets.identify the main sentiment of a tweet) and the sec-ond one concerns sentiment imbalances betweenwords.There are six features in the Sentiments group.The first one is named positive sum and it is thesum of all the positive scores in a tweet, the sec-ond one is negative sum, defined as sum of all thenegative scores.
The arithmetic average of the pre-vious ones is another feature, named positive neg-ative mean, designed to reveal the sentiment thatbetter describe the whole tweet.
Moreover, thereis positive-negative gap that is the difference be-tween the first two features, as we wanted also todetect the positive/negative imbalance within thesame tweet.The imbalance may be created using only onesingle very positive (or negative) word in thetweet, and the previous features will not be ableto detect it, thus we needed to add two more.
Forthis purpose the model includes positive singlegap defined as the difference between most posi-tive word and the mean of all the sentiment scoresof all the words of the tweet and negative singlegap defined in the same way, but with the mostnegative one.5 Experiments and ResultsIn order to evaluate our system we use fivedatasets, subsets of the corpus in Section 3: Sar-casm vs Education, Sarcasm vs Humour, Sarcasmvs Irony, Sarcasm vs Newspaper and Sarcasmvs Politics.
Each combination is balanced with10.000 sarcastic and 10.000 of non-sarcastic ex-amples.
We run the following two types of exper-iments:1.
We run in each datasets a 10-fold cross-validation classification experiment.2.
We train the classifier on 75% of positive ex-amples and 75% of negative examples of thesame dataset, then we use as test set the rest25% positive and 25% negative.
We performthis experiment for the five datasets.In Figure 1 and Figure 2 we show the values ofinformation gain of the five combinations of topics(Sarcasm versus each not-sarcastic topic).
Notethat, in the first figure the scale we chose to bet-ter visualise all the features truncates the scoresof the feature http of Education, Newspaper, andPolitics.
These three values are respectively 0.4,0.7 and 0.4.
Table 1 and Table 2 includes Preci-sion, Recall, and F-Measure results of Experiment1 and Experiment 2.6 DiscussionThe best results are obtained when our model hasto distinguish Sarcasm from Newspaper tweets.This was expected as the task was simpler than theothers.
In Newspaper tweets nine out of ten timespresent an internet link, and this aspect can be usedto well distinguish sarcasm as internet links are notused often.
Moreover the Newspaper tweets use aformal language easily distinguishable from sar-casm.
In Newspaper tweets there are more nouns(average ratio of 0.5) than in sarcastic tweets (ratio55Figure 2: Information gain of each feature of the model.
Sarcasm is compared to Education, Humor,Irony, Newspaper and Politics.
High values of information gain help to better discriminate sarcasticfrom non-sarcastic tweets.Prec.
Recall F1Education .87 .90 .88Humour .88 .87 .88Irony .62 .62 .62Newspaper .98 .96 .97Politics .90 .90 .90Table 1: Precision, Recall and F-Measure of eachtopic combination for Experiment 1 (10 cross val-idation).
Sarcasm corpus is compared to Educa-tion, Humour, Irony, Newspaper, and Politics cor-pora.
The classifier used is Decision Tree0.3), and Newspaper uses less punctuation marksthan sarcasm.
Overall Newspaper results are verygood, the F1 is over 0.95.Education and Politics results are very good aswell, F1 of 0.90 and 0.92.
Also in these topics theinternet link is a good feature.
Other powerful fea-tures in these two topics are noun ratio (as News-paper they present more number of nouns than sar-casm), question, rarest val.
(sarcasm includesless frequently used words) and syno lower.Results regarding sarcasm versus Humour arepositive, F-Measure is above 0.87.
The mostmarked differences between Humour and sar-casm are the following.
Humour includes morelinks (http), more question marks are used tomark jokes like: ?Do you know the differencebetween...?
?, ?What is an elephant doing...??
(question), sarcasm includes rarer terms and moreintense adverbs than Humour (rarest val., adv.max).Our model struggles to detect tweets marked assarcastic from the ones marked as ironic.
Evenif not very powerful, relevant features to detectsarcasm against irony are two: use of adverbs(sarcasm uses less but more intense adverbs) andsentiment scores (as expected sarcastic tweets aredenoted by more positive sentiments than irony).Poor results in this topic indicate that irony andsarcasm have similar structures in our model,and that new features are necessary to distinguishthem.Prec.
Recall F1Education .87 .88 .87Humour .87 .86 .86Irony .60 .61 .60Newspaper .95 .96 .95Politics .89 .89 .89Table 2: Precision, Recall and F-Measure of eachtopic combination for Experiment 2 (Test set).Sarcasm corpus is compared to Education, Hu-mour, Irony, Newspaper, and Politics corpora.Theclassifier used is Decision TreeThe comparison with other similar systems isnot easy.
We obtain better results than Reyes etal.
(2013) and than Barbieri and Saggion (2014),but the positive class in their experiments is irony.The system of Davidov et al.
(2010) to detect sar-casm seems to be powerful as well, and their re-sults can compete with ours, but in the mentionedstudy there is no negative topic distinction, the not-sarcastic topic is not a fixed domain (and our con-56trolled experiments results show that depending onthe negative example the task can be more or lessdifficult).7 Conclusion and Future WorkIn this study we evaluate our system to detect sar-casm in the social network Twitter.
We tackle thisproblem as binary classification, where the nega-tive topics are Education, Humour, Irony, News-paper and Politics.
The originality of our systemis avoiding the use of pattern of words as feature todetect sarcasm.
In spite of the good results, thereis much space for improvement.
We can still en-hance our results by including additional featuressuch as language models.
We will also run new ex-periments with different negative topics and differ-ent kind of text, for example on Amazon reviewsas Davidov et al.
(2010).
Finally, a very interestingbut challenging issue will be distinguishing withbetter accuracy sarcasm from irony.AcknowledgmentsWe are grateful to two anonymous reviewers fortheir comments and suggestions that help improveour paper.
The research described in this paper ispartially funded by fellowship RYC-2009-04291from Programa Ram?on y Cajal 2009 and projectnumber TIN2012-38584-C06-03 (SKATER-UPF-TALN) from Ministerio de Econom?
?a y Compet-itividad, Secretar?
?a de Estado de Investigaci?on,Desarrollo e Innovaci?on, Spain.
We also ac-knowledge partial support from the EU projectDr.
Inventor (FP7-ICT-2013.8.1 project number611383).ReferencesFrancesco Barbieri and Horacio Saggion.
2014.
Mod-elling Irony in Twitter.
In Proceedings of the StudentResearch Workshop at the 14th Conference of theEuropean Chapter of the Association for Computa-tional Linguistics, pages 56?64, Gothenburg, Swe-den, April.
Association for Computational Linguis-tics.Kalina Bontcheva, Leon Derczynski, Adam Funk,Mark A. Greenwood, Diana Maynard, and NirajAswani.
2013.
TwitIE: An Open-Source Informa-tion Extraction Pipeline for Microblog Text.
In Pro-ceedings of the International Conference on RecentAdvances in Natural Language Processing.
Associ-ation for Computational Linguistics.Cristina Bosco, Viviana Patti, and Andrea Bolioli.2013.
Developing corpora for sentiment analysisand opinion mining: the case of irony and senti-tut.Intelligent Systems, IEEE.Paula Carvalho, Lu?
?s Sarmento, M?ario J Silva, andEug?enio de Oliveira.
2009.
Clues for detect-ing irony in user-generated contents: oh...!!
it?sso easy;-).
In Proceedings of the 1st internationalCIKM workshop on Topic-sentiment analysis formass opinion, pages 53?56.
ACM.Dmitry Davidov, Oren Tsur, and Ari Rappoport.
2010.Semi-supervised recognition of sarcastic sentencesin twitter and amazon.
In Proceedings of the Four-teenth Conference on Computational Natural Lan-guage Learning, pages 107?116.
Association forComputational Linguistics.Andrea Esuli and Fabrizio Sebastiani.
2006.
Sen-tiwordnet: A publicly available lexical resourcefor opinion mining.
In Proceedings of LanguageResources and Evaluation Conference, volume 6,pages 417?422.Elena Filatova.
2012.
Irony and Sarcasm: CorpusGeneration and Analysis Using Crowdsourcing.
InProceedings of Language Resources and EvaluationConference, pages 392?398.Rachel Giora.
1995.
On irony and negation.
Discourseprocesses, 19(2):239?264.Roberto Gonz?alez-Ib?a?nez, Smaranda Muresan, andNina Wacholder.
2011.
Identifying Sarcasm inTwitter: A Closer Look.
In ACL (Short Papers),pages 581?586.
Citeseer.H Paul Grice.
1975.
Logic and conversation.
1975,pages 41?58.Daniel C Howe.
2009.
Rita wordnet.
Java based APIto access Wordnet.Nancy Ide and Keith Suderman.
2004.
The Ameri-can National Corpus First Release.
In Proceedingsof the Language Resources and Evaluation Confer-ence.Christine Liebrecht, Florian Kunneman, and Antalvan den Bosch.
2013.
The perfect solution fordetecting sarcasm in tweets# not.
WASSA 2013,page 29.Joan Lucariello.
1994.
Situational irony: A concept ofevents gone awry.
Journal of Experimental Psychol-ogy: General, 123(2):129.Stephanie Lukin and Marilyn Walker.
2013.
Really?well.
apparently bootstrapping improves the perfor-mance of sarcasm and nastiness classifiers for onlinedialogue.
NAACL 2013, page 30.George A Miller.
1995.
WordNet: a lexicaldatabase for English.
Communications of the ACM,38(11):39?41.57Christopher Potts.
2011.
Developing adjective scalesfrom user-supplied textual metadata.
NSF Work-shop on Restructuring Adjectives in WordNet.
Ar-lington,VA.Quintilien and Harold Edgeworth Butler.
1953.
TheInstitutio Oratoria of Quintilian.
With an EnglishTranslation by HE Butler.
W. Heinemann.Antonio Reyes, Paolo Rosso, and Tony Veale.
2013.A multidimensional approach for detecting irony inTwitter.
Language Resources and Evaluation, pages1?30.Ellen Riloff, Ashequl Qadir, Prafulla Surve, Lalin-dra De Silva, Nathan Gilbert, and Ruihong Huang.2013.
Sarcasm as contrast between a positive senti-ment and negative situation.Brett Spell.
2009.
Java API for WordNet Searching(JAWS).Kristina Toutanova, Dan Klein, Christopher D Man-ning, and Yoram Singer.
2003.
Feature-rich part-of-speech tagging with a cyclic dependency network.In Proceedings of the 2003 Conference of the NorthAmerican Chapter of the Association for Computa-tional Linguistics on Human Language Technology-Volume 1, pages 173?180.
Association for Compu-tational Linguistics.Akira Utsumi.
2000.
Verbal irony as implicit dis-play of ironic environment: Distinguishing ironicutterances from nonirony.
Journal of Pragmatics,32(12):1777?1806.Tony Veale and Yanfen Hao.
2010a.
An ironic fistin a velvet glove: Creative mis-representation in theconstruction of ironic similes.
Minds and Machines,20(4):635?650.Tony Veale and Yanfen Hao.
2010b.
Detecting IronicIntent in Creative Comparisons.
In ECAI, volume215, pages 765?770.Deirdre Wilson and Dan Sperber.
2002.
Relevancetheory.
Handbook of pragmatics.Ian H Witten and Eibe Frank.
2005.
Data Mining:Practical machine learning tools and techniques.Morgan Kaufmann.58
