Unsupervised Word Sense DisambiguationUsing Bilingual Comparable CorporaHiroyuki Kaji and Yasutsugu MorimotoCentral Research Laboratory, Hitachi, Ltd.1-280 Higashi-Koigakubo, Kokubunji-shi, Tokyo 185-8601, Japan{kaji, y-morimo}@crl.hitachi.co.jpAbstractAn unsupervised method for word sense disam-biguation using a bilingual comparable corpus wasdeveloped.
First, it extracts statistically significantpairs of related words from the corpus of each lan-guage.
Then, aligning pairs of related wordstranslingually, it calculates the correlation betweenthe senses of a first-language polysemous word andthe words related to the polysemous word, whichcan be regarded as clues for determining the mostsuitable sense.
Finally, for each instance of thepolysemous word, it selects the sense that maxi-mizes the score, i.e., the sum of the correlationsbetween each sense and the clues appearing in thecontext of the instance.
To overcome both theproblem of ambiguity in the translingual alignmentof pairs of related words and that of disparity oftopical coverage between corpora of different lan-guages, an algorithm for calculating the correlationbetween senses and clues iteratively was devised.An experiment using Wall Street Journal and Ni-hon Keizai Shimbun corpora showed that the newmethod has promising performance; namely, theapplicability and precision of its sense selection are88.5% and 77.7%, respectively, averaged over 60test polysemous words.1 IntroductionWord sense disambiguation (WSD) is an ?intermedi-ate?
task that is necessary for accomplishing mostnatural language processing tasks, especially machinetranslation and information retrieval.
A variety ofWSD methods have been proposed over the last dec-ade; however, such methods are still immature.
Inresponse to this situation, we have developed an unsu-pervised WSD method using bilingual comparablecorpora.With the growing amount of texts available in elec-tronic form, data-driven or corpus-based WSD hasbecome popular.
The knowledge useful for WSD canbe learned from corpora.
However, supervisedlearning methods suffer from the high cost of manuallytagging the sense onto each instance of a polysemousword in a training corpus.
A number of bootstrappingmethods have been proposed to reduce the sense-tagging cost (Hearst 1991; Basili 1997).
A variety ofunsupervised WSD methods, which use a machine-readable dictionary or thesaurus in addition to a corpus,have also been proposed (Yarowsky 1992; Yarowsky1995; Karov and Edelman 1998).
Bilingual parallelcorpora, in which the senses of words in the text of onelanguage are indicated by their counterparts in the textof another language, have also been used in order toavoid manually sense-tagging training data (Brown, etal.
1991).Unlike the previous methods using bilingual cor-pora, our method does not require parallel corpora.The availability of large parallel corpora is extremelylimited.
In contrast, comparable corpora are availablein many domains.
The comparability required by ourmethod is very weak: any combination of corpora ofdifferent languages in the same domain is acceptable asa comparable corpus.Several types of information are useful for WSD(Ide and Veronis 1998).
Three major types are thegrammatical characteristics of the polysemous word tobe disambiguated, words that are syntactically relatedto the polysemous word, and words that are topicallyrelated to the polysemous word.
Among these types,use of grammatical characteristics, which are language-dependent, is not compatible with the approach usingbilingual corpora.
On the other hand, since a topicalrelation is language-independent, use of topically relat-ed words is most compatible with the approach usingbilingual corpora.
Accordingly, we focused on usingtopically related words as clues for determining themost suitable sense of a polysemous word.2 Approach2.1 FrameworkA comparable corpus consists of a first-language cor-pus and a second-language corpus of the same domain.Unlike a parallel corpus, we cannot align sentences orinstances of words translingually.
Therefore, we ex-tract a collection of statistically significant pairs ofrelated words from each language corpus indepen-dently of the other language, and then align the pairs ofrelated words translingually with the assistance of abilingual dictionary.
The underlying assumption isthat translations of words that are related in one lan-guage are also related in the other language (Rapp1995).Translingual alignment of pairs of related wordsenables us to acquire knowledge useful for WSD (i.e.,sense-clue pair).
For example, the alignment of (tank,gasoline) with (??
?<TANKU>, ???
?<GASORIN>)implies that ?gasoline?
is a clue for selecting the ?con-tainer?
sense of ?tank?, which is translated as ???
?<TANKU>?, and the alignment of (tank, soldier) with (?
?<SENSYA>, ?
?<HEISI>) implies that ?soldier?
is aclue for selecting the ?military vehicle?
sense of ?tank?,which is translated as ??
?<SENSYA>?.Figure 1 shows an overview of our proposedmethod for acquiring knowledge for WSD.
In theframework of translingually aligning pairs of relatedwords, we encounter two major problems: the ambi-guity in alignment, and the disparity of topical cover-age between the corpora of the two languages.
Thefollowing sections discuss how to overcome theseproblems.2.2 Coping with ambiguity in alignmentMatching of pairs of related words via a bilingual dic-tionary often suggests that a pair in one language canbe aligned with two or more pairs in the other language.For example, an English pair (tank, troop) can bealigned with Japanese pairs (?
?<SUISOU>, ?
?<MURE>), (?<SOU>, ?
?<TASUU>), (?
?<SENSYA>,?<GUN>), (?
?<SENSYA>, ?
?<TASUU>), and (?
?<SENSYA>, ?<TAI>).
We resolve this ambiguity on theassumption that correct alignments are accompanied bya lot of common related words that can be aligned witheach other.
In the above example, a lot of wordsrelated to both ?tank?
and ?troop?
can be aligned withwords related to both ???<SENSYA>?
and ??<TAI>?
(see Figure 2(b5)).The plausibility of alignment is evaluated ac-cording to the set of first-language common relatedwords that can be aligned with second-languagecommon related words.
Then, using the plausi-bility of alignment, the correlation between thesenses of a polysemous word and the clues for se-lecting the most suitable sense is calculated.
Toprecisely evaluate the plausibility of alignment, wedefine it as the sum of the correlations between thesense suggested by the alignment and the commonrelated words accompanying the alignment.2.3 Coping with disparity between corporaGiven the disparity of topical coverage between thecorpora of two languages as well as the insufficientcoverage of the bilingual dictionary, the method de-scribed in the preceding section seems too strict.
Asexemplified in Figure 2, even for a correct alignment ofa first-language pair of related words with a second-language pair of related words, only a small part of thefirst-language common related words can be alignedwith second-language common related words.
Toimprove the robustness of the method, instead of theset of first-language common related words that can bealigned with second-language common related words,we use a weighted set consisting of all the first-language common related words, where those alignedwith second-language common related words are givenComparable corpus1st language corpus 2nd language corpusAlign pairs of related words translinguallyExtract co-occurrencedata and calculatemutual informationCalculate correlation betweensenses and clues iterativelyBilingualdictionarySenses definedby sets oftranslationsSense-vs.-clue correlationAlignments of pairs of related words accompaniedby a set of common related wordsCollection of pairsof related wordsCollection of pairsof related wordsExtract co-occurrencedata and calculatemutual informationFig.
1 Overview of the proposed method foracquiring knowledge for WSD(a) Common related words of (tank, troop)Army, Bosnian, Bosnian government, Chechen,Chechnya, Force, Grozny, Israel, Moscow, Mr. Yelt-sin, Mr. Yeltsin's, NATO, Pentagon, Republican,Russia, Russian, Secretary, Serb, U.N., Yeltsin, Yelt-sin's, air, area, army, assault, battle, bomb, carry, ci-vilian, commander, control, defense, fight, fire, force,government, helicopter, military, missile, rebel, sol-dier, weapon(b1) Common related words of (tank, troop) that canbe aligned with common related words of (?
?<SUISOU>, ?
?<MURE>)air, area, fire, government(b2) Common related words of (tank, troop) that canbe aligned with common related words of (?<SOU>, ?
?<TASUU>)area, army, control, force(b3) Common related words of (tank, troop) that canbe aligned with common related words of (?
?<SENSYA>, ?<GUN>)area, army, battle, commander, force, government(b4) Common related words of (tank, troop) that canbe aligned with common related words of (?
?<SENSYA>, ?
?<TASUU>)Serb, area, army, battle, force, government(b5) Common related words of (tank, troop) that canbe aligned with common related words of (?
?<SENSYA>, ?<TAI>)Russia, Serb, air, area, army, battle, commander, de-fense, fight, fire, force, government, helicopter, sol-dierFig.
2 Example of common related wordslarger weights than the others.The disparity of topical coverage between the cor-pora of two languages and the insufficient coverage ofthe bilingual dictionary also cause a lot of pairs of re-lated words not to be aligned with any pair of relatedwords.
To recover the failure in alignment, we intro-duce a ?wild card?
pair, with which every first-language pair of related words is aligned compulsorily.The alignment with the wild-card pair suggests allsenses of the first-language polysemous word, and it isaccompanied by a set consisting of the first-languagecommon related words with the same weight.3 Proposed method3.1 Defining word sensesWe define each sense of a polysemous word x of thefirst language by a synonym set consisting of x itselfand one or more of its translations y1, y2, ... into thesecond language.
The synonym set is similar to thatin WordNet (Miller 1990) except that it is bilingual, notmonolingual.
Examples of some sets are given be-low.
{tank, ??
?<TANKU>, ?
?<SUISOU>, ?<SOU>}{tank, ?
?<SENSYA>}These synonym sets define the ?container?
sense andthe ?military vehicle?
sense of ?tank?
respectively.Translations that preserve the ambiguity are prefer-ably eliminated from the synonym sets defining sensesbecause they are useless for distinguishing the senses.An example is given below.
{title, ??
?<KATAGAKI>, ?
?<SYOUGOU>, ???
?<TAITORU>, ?
?<KEISYOU>}{title, ?
?<DAIMEI>, ?
?<DAIMOKU>, ?
?<HYOUDAI>, ?
?<SYOMEI>, ???
?<TAITORU>}{title, ???
?<TAITORU>, ??
?<SENSYUKEN>}These synonym sets define the ?person?s rank or pro-fession?
sense, the ?name of a book or play?
sense, andthe ?championship?
sense of ?title?.
A Japanese word????
?<TAITORU>?, which represents all these senses,is preferably eliminated from all these synonym sets.3.2 Extraction of pairs of related wordsThe corpus of each language is statistically processedin order to extract a collection of pairs of related wordsin the language (Kaji et al 2000).
First, we extractwords from the corpus and count the occurrence fre-quencies of each word.
We reject words whose fre-quencies are less than a certain threshold.
We alsoextract pairs of words co-occurring in a window andcount the co-occurrence frequency of each pair ofwords.
In the present implementation, the words arerestricted to nouns and unknown words, which areprobably nouns, and the window size is set to 25 wordsexcluding function words.Next, we calculate mutual information MI(x, x?
)between each pair of words x and x?.
MI(x, x?)
is de-fined by the following formula:)'xPr()xPr()'x,xPr(log)'x,x(MI?= ,where Pr(x) is the occurrence probability of x, and Pr(x,x?)
is the co-occurrence probability of x and x?.
Fi-nally, we select pairs of words whose mutual informa-tion value is larger than a certain threshold and at thesame time whose relation is judged to be statisticallysignificant through a log-likelihood ratio test.3.3 Alignment of pairs of related wordsIn this section, RX and RY denote the collections of pairsof related words extracted from the corpora of the firstlanguage and the second language, respectively.
Ddenotes a bilingual dictionary, that is, a collection ofpairs consisting of a first-language word and a second-language word that are translations of each other.Let X(x) be the set of clues for determining the sen-se of a first-language polysemous word x, i.e.,X(x)={x?|(x, x?
)?RX}.Henceforth, the j-th clue for determining the sense of xis denoted as x?
(j).Let Y(x, x?
(j)) be the set of counterparts of a pair offirst-language related words (x, x?
(j)), i.e.,Y(x, x?
(j))={(y, y?)
| (y, y?
)?RY, (x, y)?D, (x?
(j), y?)?D}.
(1) Each pair of first-language related words (x, x?
(j)) isaligned with each counterpart (y, y?)
(?Y(x, x?
(j))),and a weighted set of common related words Z((x,x?
(j)), (y, y? ))
is constructed as follows:Z((x, x?
(j)), (y, y? ))
={x?
/ w(x?)
| (x, x?
)?RX, (x?
(j), x?
)?RX},where w(x?
), which denotes the weight of x?, is setas follows:- w(x?)
= 1+?
?MI(y, y?)
when ?y?
(x?, y?
)?D,(y, y?
)?RY, and (y?, y?
)?RY .- w(x?)
= 1 otherwise.The mutual information of the counterpart, MI(y, y?
),was incorporated into the weight according to the as-sumption that alignments with pairs of strongly relat-ed words are more plausible than those with pairs ofweakly related words.
The coefficient ?
was setto 5 experimentally.
(2) Each pair of first-language related words (x, x?
(j)) isaligned with the wild-card pair (y0, y0?
), and a weight-ed set of common related words Z((x, x?
(j)), (y0, y0?
))is constructed as follows:Z((x, x?
(j)), (y0, y0?))
={x?
/ w(x?)
| (x, x?
)?RX, (x?
(j), x?
)?RX},where w(x?)
= 1 for all x?.3.4?Calculation of correlation between senses andcluesWe define the correlation between the i-th sense S(i)and the j-th clue x?
(j) of a polysemous word x as fol-lows:( ) ( )( )( ),)k(S),'y,y()),j('x,x(Amaxmax)i(S),'y,y()),j('x,x(Amax)j('x,xMI)j('x),i(SC}y{)k(Sy)}'y,y{())j('x,x(Y)'y,y(k}y{)i(Sy)}'y,y{())j('x,x(Y)'y,y(000000???????????=???????
?where A((x, x?
(j)), (y, y), S(i)) denotes the plausibility ofalignment of (x, x?
(j)) with (y, y) suggesting S(i).The first factor in the above formula, i.e., the mutu-al information between the polysemous word and the j-th clue, is the base of the correlation.
The numeratorof the second factor is the maximum plausibility ofalignments that suggest the i-th sense of the polyse-mous word.
The denominator of the second factorhas been introduced to normalize the plausibility.We define the plausibility of alignment suggesting asense as the weighted sum of the correlations betweenthe sense and the common related words, i.e.,( )( )."x),i(SC)"x(w)i(S),'y,y()),j('x,x(A))'y,y()),j('x,x((Z"x??
?=As the definition of the correlation between sensesand clues is recursive, we calculate it iteratively withthe following initial values: C0(S(i), x?
(j))=MI(x, x?
(j)).The number of iteration was set at 6 experimen-tally.Figure 3 shows how the correlation values converge.?Troop?
demonstrates a typical pattern of convergence;namely, while the correlation with the relevant sen-se is kept constant, that with the irrelevant sensedecreases as the iteration proceeds.
?Ozone?
de-monstrates the effect of the wild-card pair.
Notethat the correlation values due to an alignment withthe wild-card pair begin to diverge in the secondcycle of iteration.
The alignment with the wild-card pair, which is shared by all senses, does notproduce any distinction among the senses in thefirst cycle of iteration; the divergence is caused bythe difference in correlation values between thesenses and the common related words.3.5 Selection of the sense of a polysemous wordConsulting sense-vs.-clue correlation data acquired bythe method described in the preceding sections, weselect a sense for each instance of a polysemous word xin a text.
The score of each sense of the polysemousword is defined as the sum of the correlations betweenthe sense and clues appearing in the context, i.e.,( ) ( )?
?=)x(Context)j('x)j('x),i(SC)i(SScore .A window of 51 words (25 words before the polyse-mous word and 25 words after it) is used as the context.Scores of all senses of a polysemous word are calcu-lated, and the sense whose score is largest is selected asthe sense of the instance of the polysemous word.When all scores are zero, no sense can be selected; thecase is called ?inapplicable?.4 Experiment4.1 Experimental methodWe evaluated our method through an experiment usingcorpora of English and Japanese newspaper articles.The first language was English and the second lan-guage was Japanese.
A Wall Street Journal corpus(July, 1994 to Dec., 1995; 189 Mbytes) and a NihonKeizai Shimbun corpus (Dec., 1993 to Nov., 1994; 275Mbytes) were used as the training comparable corpus.EDR (Japan Electronic Dictionary Research Institute)English-to-Japanese and Japanese-to-English diction-aries were merged for the experiment.
The resultingdictionary included 269,000 English nouns and276,000 Japanese nouns.
Pairs of related words wereextracted from the corpus of each language under thefollowing parameter settings:- threshold for occurrence frequencies of words: 10- threshold for mutual information: 0.0These settings were common to the English and Ja-panese corpora.We selected 60 English polysemous nouns as thetest words.
Words whose different senses appear innewspapers were preferred.
The frequencies of thetest words in the training corpus ranged from 39,140(?share?, the third noun in descending order of fre-quency) to 106 (?appreciation?, the 2,914th noun).00.511.522.530 1 2 3 4 5 6 7 8 9 10IterationCorrelationC({tank, ??
?<TANKU>, ?
?<SUISOU>, ?<SOU>}, troop)C({tank, ?
?<SENSYA>}, troop)C({tank, ??
?<TANKU>, ?
?<SUISOU>, ?<SOU>}, ozone)C({tank, ?
?<SENSYA>}, ozone)C({tank, ??
?<TANKU>, ?
?<SUISOU>, ?<SOU>}, safety)C({tank, ?
?<SENSYA>}, safety)Fig.
3 Convergence of correlation betweensenses and cluesWe defined the senses of each test word.
The numberof senses per test word ranged from 2 to 8, and theaverage was 3.4.
For each test word, sense-vs.-cluecorrelation data were acquired by the method describedin Sections 3.2 through 3.4.
175 clues on averagewere acquired for each test word.For evaluation, we selected 100 test passages pertest word from a Wall Street Journal corpus (Jan., 1996to Dec. 1996) whose publishing period was differentfrom that of the training corpus.
The instances of testwords positioned in the center of each test passagewere disambiguated by the method described in Sec-tion 3.5, and the results were compared with the manu-ally selected senses.4.2 Results and evaluationWe used two measurements, applicability and precision(Dagan and Itai 1994), to evaluate the performance ofour method.
The applicability is the proportion ofinstances of the test word(s) that the method coulddisambiguate.
The precision is the proportion of dis-ambiguated instances of the test word(s) that themethod disambiguated correctly.
The applicabilityand precision of the proposed method, averaged overthe 60 test polysemous words, were 88.5% and 77.7%,respectively.The performance of our method on six out of the 60test words is summarized in Table 1.
That is, the in-stances are classified according to the correct sense andthe sense selected by our method.
These results showthat the performance varies according to the test words,that our method is better in the case of frequent senses,but worse in the case of infrequent senses, and that ourmethod can easily distinguish topic-specific senses, butnot generic senses.We consider the reason for the poor performanceconcerning ?measure?
[Table 1(a)] and ?race?
[Table1(c)] as follows.
The second sense of ?measure?,{measure, ?
?
<TAISAKU>, ?
?
<SYUDAN>, ?
?<SYOTI>}, is a very generic sense; therefore effectiveclues for identifying the sense could not be acquired.The first sense of ?race?, {race, ??
?<REESU>, ?
?<KYOUSOU>, ??
<KYOUSOU>, ??
<ARASOI>, ?<SEN>}, is specific to the ?race for the presidency?topic and the second sense of ?race?, {race, ?
?<ZINSYU>, ??
<MINZOKU>, ??
<SYUZOKU>}, isspecific to the ?racial discrimination?
topic; however,both topics are related to ?politics?
and, therefore,many clues were shared by these two senses.Comparison with a baseline method, which selectsthe most frequent sense of each polysemous wordindependently of contexts, was also done.
Since largesense-tagged corpora were not available, we simulatedthe baseline method with a modified version of theproposed method; namely, for each polysemous word,the sense that maximizes the sum of correlations withall clues was selected as the most frequent sense.
Theapplicability of the baseline method is 100%, while thatof the proposed method is less than 100%.
To com-pare with the baseline method, the proposed methodwas substituted with the proposed method + baselinemethod; namely, the baseline method was appliedwhen the proposed method was inapplicable.The average precisions of the baseline method andthe proposed method + baseline method, both of whichattained 100% applicability, were 62.8% and 73.4%respectively.
Figure 4 visualizes the superiority of theproposed method + baseline method; the 60 test poly-semous words are scattered on a plane whose horizon-tal and vertical coordinates represent the precision ofthe baseline method and that of the proposed method +baseline method, respectively.5 DiscussionAlthough it has produced promising results, the devel-oped WSD method has a few problems.
These limi-tations, along with future extensions, are discussedbelow.
(1) Multilingual distinction of sensesThe developed method is based on the premise thatthe senses of a polysemous word in a language arelexicalized differently in another language.
However,the premise is not always true; that is, the ambiguity ofa word may be preserved by its translations.
As de-scribed in Section 3.1, we preferably use translationsthat do not preserve the ambiguity.
However, doingso is useless unless such translations are frequentlyused words.
An essential approach to solving thisproblem is to use two or more second languages (Res-nik and Yarowsky 2000).
(2) Use of syntactic relationsThe developed method extracts clues for WSD ac-cording to co-occurrence in a window.
However, it isobvious that doing this is not suitable for all polyse-mous words.
Syntactic co-occurrence is more usefulfor disambiguating some sorts of polysemous words.It is an important and interesting research issue to ex-tend our method so that it can acquire clues accordingto syntactic co-occurrence.
This extended methoddoes not replace the present method; however, we00.20.40.60.810 0.2 0.4 0.6 0.8 1Baseline methodProposedmethod+baselinemethodFig.
4 Precision of sense selectionshould combine both methods or use the one suitablefor each polysemous word.
It should be noted thatthis extension also enables disambiguation of polyse-mous verbs.The framework of the method is compatible withsyntactic co-occurrence.
Basically, we only have toincorporate a parser into the step of extracting pairs ofrelated words.
A parser of the first language is indis-pensable, but a parser of the second language is not.As for the second language, we can use co-occurrencein a small-sized window instead of syntactic co-occurrence.6 Comparison with other methodsWhile our method aligns pairs of related words that arestatistically extracted, WSD using parallel corporaaligns instances of words (Brown, et al 1991).
Bothalignment techniques are quite different.
Actually,from the technological viewpoint, our method is closeto WSD using a second-language monolingual corpusTable 1 Results of sense selection for six polysemous words(a) Polysemous word ?measure?
(applicability=91.0%; precision=48.4%)ResultsCorrect sense S1 S2 S3 ?
TotalS1={measure, ??
, ???
, ?
, ??
,?
?, ?
?, ?
?, ?
?, ??
}20 0 13 4 37S2={measure, ?
?, ?
?, ??}
4 0 29 5 38S3={measure, ?
?, ?
?, ??}
1 0 24 0 25Total 25 0 66 9 100[Note]S1: a system or instrument for calculatingamount, size, weight, etc.S2: an action taken to gain a certain endS3: a law suggested in Parliament(b) Polysemous word ?promotion?
(applicability=96.0%; precision=89.6%)ResultsCorrect sense S1 S2 S3 ?
TotalS1={promotion, ?
?, ???
?, ???
?, ???????}
71 1 0 1 73S2={promotion, ?
?, ?
?, ?
?, ?
?, ?
?, ??}
6 15 0 3 24S3={promotion, ?
?, ?
?, ?
?, ?
?, ??}
2 1 0 0 3Total 79 17 0 4 100[Note]S1: an activity intended tohelp sell a productS2: advancement in rank orpositionS3: action to help somethingdevelop or succeed(c) Polysemous word ?race?
(applicability=79.0%; precision=57.0%)ResultsCorrect sense S1 S2 S3 ?
TotalS1={race, ??
?, ?
?, ?
?, ?
?, ?}
28 33 0 15 76S2={race, ?
?, ?
?, ??}
1 17 0 6 24S3={race, ?
?, ??}
0 0 0 0 0Total 29 50 0 21 100[Note]S1: any competition, or a contest of speedS2: one of the groups that humans can be divid-ed into according to physical features, his-tory, language, etc.S3: a channel for a current of water(d) Polysemous word ?tank?
(applicability=89.0%; precision=89.9%)ResultsCorrect sense S1 S2 ?
TotalS1={tank, ??
?, ?
?, ?}
57 1 6 64S2={tank, ??}
8 23 5 36Total 65 24 11 100[Note]S1: a large container for storing liquid or gasS2: an enclosed heavily armed, armored vehicle(e) Polysemous word ?title?
(applicability=92.0%; precision=81.5%)ResultsCorrect sense S1 S2 S3 S4 ?
TotalS1={title, ??
?, ?
?, ??}
43 1 0 0 2 46S2={title, ?
?, ?
?, ?
?, ??}
6 26 0 1 5 38S3={title, ?
?, ?
?, ???}
1 1 0 1 1 4S4={title, ???}
3 3 0 6 0 12Total 53 31 0 8 8 100[Note]S1: a word or name given to a person tobe used before his/her name as a signrank, profession, etc.S2: a name given to a book, play, etc.S3: the legal right to own somethingS4: the position of being the winner of ansports competition(f) Polysemous word ?trial?
(applicability=92.0%; precision=92.4%)ResultsCorrect sense S1 S2 S3 S4 S5 ?
TotalS1={trial, ?
?, ?
?, ??}
62 3 0 0 0 5 70S2={trial, ?
?, ?
?, ?
?, ?
?, ??}
4 23 0 0 0 2 29S3={trial, ??}
0 0 0 0 0 1 1S4={trial, ?
?, ???}
0 0 0 0 0 0 0S5={trial, ?
?, ?
?, ??}
0 0 0 0 0 0 0Total 66 26 0 0 0 8 100[Note]S1: a legal process in which a courtexamines a caseS2: a process of testing to determinequality, value, usefulness, etc.S3: a sports competition that tests aplayer?s abilityS4: annoying thing or personS5: difficulties and troubles(Dagan and Itai 1994; Kikui 1998), where instances ofco-occurrence in a first-language text are aligned withco-occurrences statistically extracted from the second-language corpus.
A comparison of our method withWSD using a second-language monolingual corpus isgiven below.First, our method performs alignment during theacquisition phase, and transforms word-word correla-tion data into sense-clue correlation data, which is farmore informative than the original word-word correla-tion data.
In contrast, a method using a second-language monolingual corpus uses original word-wordcorrelation data during the disambiguation phase.This difference results in a difference in the perfor-mance of WSD, particularly in a poor-context situation(e.g., query translation).Second, our method can acquire sense-clue correla-tion even from a pair of related words for which align-ment results in failure [e.g., C({tank, ???<TANKU>,?
?<SUISOU>, ?<SOU>}, ozone) in Figure 3].
Onthe contrary, a conventional WSD method using a sec-ond-language monolingual corpus uses only pairs ofrelated words for which alignment results in success.Thus, our method can elicit more information than theconventional method.Tanaka and Iwasaki (1996) exploited the idea oftranslingually aligning word co-occurrences to extractpairs consisting of a word and its translation form anon-aligned (comparable) corpus.
The essence oftheir method is to obtain a translation matrix thatmaximizes the distance between the co-occurrencematrix of the first language and that of the second lan-guage.
Their method is useful for extracting corpus-dependent translations; however, it does not extractknowledge for WSD, i.e., which co-occurring wordsuggests which sense or translation.7 ConclusionA method for word sense disambiguation using a bilin-gual comparable corpus together with sense definitionsby translations into another language was developed.In this method, knowledge for WSD, i.e., sense-vs.-clue correlation, is acquired in an unsupervised fashionas follows.
First, statistically significant pairs of relat-ed words are extracted from the corpus of each lan-guage.
Then, aligning pairs of related words translin-gually, the correlation between the senses of a polyse-mous word and the clues, i.e., the words related to thepolysemous word, is calculated.
In order to overcomeboth the problem of ambiguity in the translingualalignment of pairs of related words and that of disparityof topical coverage between corpora of different lan-guages, an iterative algorithm for calculating the cor-relation was developed.WSD for each instance of the polysemous word isdone by selecting the sense that maximizes the score,i.e., the sum of the correlations between each sense andthe clues appearing in the context of the instance.
Anexperiment using corpora of English and Japanesenewspaper articles showed that the performance of thenew method is promising: the applicability and preci-sion of sense selection were 88.5% and 77.7%, respec-tively, averaged over 60 test polysemous words.Acknowledgments: This research was sponsored inpart by the Telecommunications Advancement Organi-zation of Japan.ReferencesBasili, Roberto, Michelangelo Della Rocca, and MariaTereza Pazienza.
1997.
Towards a bootstrapping frame-work for corpus semantic tagging.
In Proceedings of theACL-SIGLEX Workshop ?Tagging Text with Lexical Se-mantics: Why, What, and How??
pages 66-73.Brown, Peter F., Stephen A. Della Pietra, Vincent J. DellaPietra, and Robert L. Mercer.
1991.
Word-sense disam-biguation using statistical methods.
In Proceedings of the29th Annual Meeting of the ACL, pages 264-270.Dagan, Ido and Alon Itai.
1994.
Word sense disambiguationusing a second language monolingual corpus.
Computa-tional Linguistics, 20(4): 563-596.Hearst, Marti A.
1991.
Noun homograph disambiguationusing local context in large corpora.
In Proceedings of the7th Annual Conference of the Centre for the New OED andText Research: Using Corpora, pages 1-22.Ide, Nancy and Jean Veronis.
1998.
Introduction to the spe-cial issue on word sense disambiguation: the state of the art.Computational Linguistics, 24(1): 1-40.Kaji, Hiroyuki, Yasutsugu Morimoto, Toshiko Aizono,and Noriyuki Yamasaki.
2000.
Corpus-dependentassociation thesaurus for information retrieval, InProceedings of the 18th International Conference onComputational Linguistics, pages 404-410.Karov, Yael and Shimon Edelman.
1998.
Similarity-basedword sense disambiguation.
Computational Linguistics,24(1): 41-59.Kikui, Genichiro.
1998.
Term-list translation using mono-lingual word co-occurrence vectors.
In Proceedings of the17th International Conference on Computational Linguis-tics, pages 670-674.Miller, George A.
1990.
WordNet: an on-line lexical data-base.
International Journal of Lexicography, 3(4): 235-312.Rapp, Reinhard.
1995.
Identifying word translations in non-parallel texts.
In Proceedings of the 33rd Annual Meetingof the ACL, pages 320-322.Resnik, Philip and David Yarowsky.
2000.
Distinguishingsystems and distinguishing senses: new evaluationmethods for word sense disambiguation.
Natural Lan-guage Engineering, 5(2): 113-133.Tanaka, Kumiko and Hideya Iwasaki.
1996.
Extraction oflexical translations from non-aligned corpora, In Proceed-ings of the 16th International Conference on Computation-al Linguistics, pages 580-585.Yarowsky, David.
1992.
Word sense disambiguation usingstatistical models of Roget's categories trained on large cor-pora.
In Proceedings of the 14th International Conferenceon Computational Linguistics, pages 454-460.Yarowsky, David.
1995.
Unsupervised word sense disam-biguation rivaling supervised methods.
In Proceedings ofthe 33rd Annual Meeting of the ACL, pages 189-196.
