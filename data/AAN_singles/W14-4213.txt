Language Technology for Closely Related Languages and Language Variants (LT4CloseLang), pages 99?108,October 29, 2014, Doha, Qatar.c?2014 Association for Computational LinguisticsHandling OOV Words in Dialectal Arabic to English Machine TranslationMaryam Aminian, Mahmoud Ghoneim, Mona DiabDepartment of Computer ScienceThe George Washington UniversityWashington, DC{aminian,mghoneim,mtdiab}@gwu.eduAbstractDialects and standard forms of a languagetypically share a set of cognates that couldbear the same meaning in both varieties oronly be shared homographs but serve asfaux amis.
Moreover, there are words thatare used exclusively in the dialect or thestandard variety.
Both phenomena, fauxamis and exclusive vocabulary, are consid-ered out of vocabulary (OOV) phenomena.In this paper, we present this problem ofOOV in the context of machine translation.We present a new approach for dialectto English Statistical Machine Translation(SMT) enhancement based on normaliz-ing dialectal language into standard formto provide equivalents to address both as-pects of the OOV problem posited by di-alectal language use.
We specifically fo-cus on Arabic to English SMT.
We usetwo publicly available dialect identifica-tion tools: AIDA and MADAMIRA, toidentify and replace dialectal Arabic OOVwords with their modern standard Arabic(MSA) equivalents.
The results of evalua-tion on two blind test sets show that usingAIDA to identify and replace MSA equiv-alents enhances translation results by 0.4%absolute BLEU (1.6% relative BLEU) andusing MADAMIRA achieves 0.3% ab-solute BLEU (1.2% relative BLEU) en-hancement over the baseline.
We showour replacement scheme reaches a notice-able enhancement in SMT performancefor faux amis words.1 IntroductionIn this day of hyper connectivity, spoken vernacu-lars are ubiquitously ever more present in textualsocial media and informal communication chan-nels.
Written (very close to the spoken) informallanguage as represented by dialect poses a signifi-cant challenge to current natural language process-ing (NLP) technology in general due to the lackof standards for writing in these vernaculars.
Theproblem is exacerbated when the vernacular con-stitutes a dialect of the language that is quite dis-tinct and divergent from a language standard andpeople code switch within utterance between thestandard and the dialect.
This is the case for Ara-bic.
Modern Standard Arabic (MSA), as the nameindicates, is the official standard for the Arabiclanguage usually used in formal settings, while itsvernaculars vary from it significantly forming di-alects known as dialectal Arabic (DA), commonlyused in informal settings such as the web and so-cial media.
Contemporary Arabic is a collection ofthese varieties.
Unlike MSA, DA has no standardorthography (Salloum and Habash, 2013).
Mostof the studies in Arabic NLP have been conductedon MSA.
NLP research on DA, the unstandard-ized spoken variety of Arabic, is still at its in-fancy.
This constitutes a problem for Arabic pro-cessing in general due to the ubiquity of DA usagein written social media.
Moreover, linguistic codeswitching between MSA and DA always happenseither in the course of a single sentence or acrossdifferent sentences.
However this intrasententialcode switching is quite pervasive (Elfardy et al.,2013).
For instance 98.13% of sentences crawledfrom Egyptian DA (EGY) discussion forums forthe COLABA project (Diab et al., 2010) containsintrasentential code switching.MSA has a wealth of NLP tools and resourcescompared to a stark deficiency in such resourcesfor DA.
The mix of MSA and DA in utterancesconstitutes a significant problem of Out of Vocab-ulary (OOV) words in the input to NLP applica-tions.
The OOV problem is two fold: completelyunseen words in training data, and homographOOVs where the word appears in the training databut with a different sense.
Given these issues, DA99NLP and especially DA statistical machine trans-lation (SMT) can be seen as highly challengingtasks and this illustrates the need for conductingmore research on DA.MSA has a wealth of resources such as parallelcorpora and tools like morphological analyzers,disambiguation systems, etc.
On the other hand,DA still lacks such tools and resources.
As an ex-ample, parallel DA to English (EN) corpora arestill very few and there are almost no MSA-DAparallel corpora.
Similar to MSA, DA has theproblem of writing with optional diacritics.
It alsolacks orthographic standards.
Hence, translatingfrom DA to EN is challenging as there are imped-iments posed by the nature of the language cou-pled with the lack of resources and tools to processDA (Salloum and Habash, 2013).MSA and DA are significantly different on all lev-els of linguistic representation: phonologically,morphologically, lexically, syntactically, semanti-cally and pragmatically.
The morphological dif-ferences between MSA and DA are most notice-ably expressed by using some clitics and affixesthat do not exist in MSA.
For instance, the DA(Egyptian and Levantine) future marker clitic H1is expressed as the clitic s in MSA (Salloum andHabash, 2013).
On a lexical level, MSA and DAshare a considerable number of faux amis wherethe lexical tokens are homographs but have dif-ferent meanings.
For instance the word yEny inMSA means ?to mean?, but in DA, it is a prag-matic marker meaning ?to some extent?.
We referto this phenomenon as sense OOV (SOOV).
Thisphenomenon is in addition to the complete OOV(COOV) that exist in DA but don?t exist in MSA.These issues constitute a significant problem forprocessing DA using MSA trained tools.
Thisproblem is very pronounced in machine transla-tion.In this paper, we present a new approach to build aDA-to-EN MT system by normalizing DA wordsinto MSA.
We focus our investigation on theEgyptian variety of DA (EGY).
We leverage MSAresources with robust DA identification tools toimprove SMT performance for DA-to-EN SMT.We focus our efforts on replacing identified DAwords by MSA counterparts.
We investigate thereplacement specifically in the decoding phase ofthe SMT pipeline.
We explore two state of the1We use the Buckwalter Transliteration as representedin www.qamus.com for Romanized Arabic representationthroughout the paper.art DA identification tools for the purposes of ourstudy.
We demonstrate the effects of our replace-ment scheme on each OOV type and show thatnormalizing DA words into their equivalent MSAconsiderably enhances SMT performance in trans-lating SOOVs.The remainder of this paper is organized as fol-lows: Section 2 overviews related work; Section 3details our approach; Section 4 presents the resultsobtained on standard data sets; in Section 5, wediscuss the results and perform error analysis; fi-nally we conclude with some further observationsin Section 6.2 Related WorkLeveraging MSA resources and tools to enrich DAfor NLP purposes has been explored in severalstudies.
Chiang, et.
al.
(2006) exploit the rela-tion between Levantine Arabic (LEV) and MSAto build a syntactic parser on transcribed spokenLEV without using any annotated LEV corpora.Since there are no DA-to-MSA parallel corpora,rule-based methods have been predominantly em-ployed to translate DA-to-MSA.
For instance,Abo Bakr et al.
(2008) introduces a hybrid ap-proach to transfer a sentence from EGY into adiacritized MSA form.
They use a statistical ap-proach for tokenizing and tagging in addition toa rule-based system for constructing diacritizedMSA sentences.
Moreover, Al-Sabbagh and Girju(2010) introduce an approach to build a DA-to-MSA lexicon through mining the web.In the context of DA translation, Sawaf (2010) in-troduced a hybrid MT system that uses statisticaland rule-based approaches for DA-to-EN MT.
Inhis study, DA words are normalized to the equiv-alent MSA using a dialectal morphological ana-lyzer.
This approach achieves 2% absolute BLEUenhancement for Web texts and about 1% absoluteBLEU improvement over the broadcast transmis-sions.
Furthermore, Salloum and Habash (2012)use a DA morphological analyzer (ADAM) and alist of hand-written morphosyntactic transfer rules(from DA to MSA) to improve DA-to-EN MT.This approach improves BLEU score on a blindtest set by 0.56% absolute BLEU (1.5% rela-tive) on the broadcast conversational and broad-cast news data.
Test sets used in their study con-tain a mix of Arabic dialects but Levantine Arabicconstitutes the majority variety.Zbib et al.
(2012) demonstrate an approach to ac-100Figure 1: Block diagram of the proposed system for enhancing DA-to-EN SMT via normalizing DAquire more DA-to-EN data to improve DA SMTperformance by enriching translation models withmore DA data.
They use Amazon MechanicalTurk to create a DA-to-EN parallel corpus.
Thisparallel data is augmented to the available largeMSA-to-EN data and is used to train the SMT sys-tem.
They showed that their trained SMT modelon this DA-to-EN data, can achieve 6.3% and 7%absolute BLEU enhancement over an SMT systemtrained on MSA-to-EN data when translating EGYand LEV test sets respectively.
Habash (2008)demonstrates four techniques for handling OOVwords through modifying phrase tables for MSA.He also introduces a tool which employs thesefour techniques for online handling of OOV inSMT (Habash, 2009).Habash et al.
(2013) introduces MADA-ARZ, anew system for morphological analysis and dis-ambiguation of EGY based on an MSA morpho-logical analyzer MADA (Habash and Rambow,2005).
They evaluate MADA-ARZ extrinsicallyin the context of DA-to-EN MT and show that us-ing MADA-ARZ for tokenization leads to 0.8%absolute BLEU improvement over the baselinewhich is simply tokenized with MADA.
In thispaper, we use MADAMIRA (Pasha et al., 2014),a system for morphological analysis and disam-biguation for both MSA and DA (EGY), to iden-tify DA words and replace MSA equivalents.
Ourapproach achieves 0.6% absolute BLEU improve-ment over the scores reported in (Habash et al.,2013).3 ApproachIn the context of SMT for DA-to-EN, we en-counter a significant OOV rate between test andtraining data since the size of the training data isrelatively small.
On the other hand, we have sig-nificant amounts of MSA-to-EN parallel data toconstruct rich phrase tables.
MSA and DA, thoughdivergent, they share many phenomena that can beleveraged for the purposes of MT.
Hence, if wecombine training data from MSA with that fromDA, and then at the decode time normalize OOVDA words into their equivalent MSA counterpartswe should be able to overcome the resource chal-lenges in the DA-to-EN SMT context, yieldingbetter overall translation performance.
The OOVproblem is two fold: complete OOV (COOV) andsense OOV (SOOV).
The COOV problem is thestandard OOV problem where an OOV in the in-put data is not attested at all in the training data.The SOOV problem is where a word is observedin the training data but with a different usage orsense, different from that of the test data occur-rence.
To our knowledge, our research is the firstto address the SOOV directly in the context ofSMT.
To that end, we employ two DA identifica-tion tools: a morphological tagger, as well as afull-fledged DA identification tool to identify andreplace DA words with their equivalent MSA lem-mas in the test data at decoding time.Accordingly, the ultimate goal of this work is toassess the impact of different DA identificationand replacement schemes on SMT overall perfor-101mance and overall OOV (both types) reduction.
Itis worth noting that we focus our experiments onthe decoding phase of the SMT system.
Figure1shows the block diagram of the proposed system.We exploit the following tools and resources:?
MADAMIRA: A system for morphologi-cal analysis and disambiguation for bothMSA and DA (EGY).
MADAMIRA indi-cates whether a word is EGY or MSA basedon its underlying lexicon which is used togenerate an equivalent EN gloss.
However,for EGY words, MADAMIRA does not gen-erate the equivalent MSA lemma (Pasha etal., 2014);?
AIDA: A full-fledged DA identification toolwhich is able to identify and classify DAwords on the token and sentence levels.AIDA exploits MADAMIRA internally inaddition to more information from context toidentify DA words (Elfardy and Diab, 2013).AIDA provides both the MSA equivalentlemma(s) and corresponding EN gloss(es) forthe identified DA words;?
THARWA: A three-way lexicon betweenEGY, MSA and EN (Diab et al., 2014).To evaluate effectiveness of using each of these re-sources in OOV reduction, we have exploited thefollowing replacement schemes:?
AIDA identifies DA words in the context andreplaces them with the most probable equiv-alent MSA lemma;?
MADAMIRA determines whether a word isDA or not.
If the word is DA, then ENgloss(es) from MADAMIRA are used to findthe most probable equivalent MSA lemma(s)from THARWA.As all of these DA identification resources(MADAMIRA, AIDA and THARWA) returnMSA equivalents in the lemma form, we adopt afactored translation model to introduce the extrainformation in the form of lemma factors.
There-fore, DA replacement affects only the lemma fac-tor in the factored input.
We consider the fol-lowing setups to properly translate replaced MSAlemma to the the corresponding inflected form(lexeme):22We use the term lexeme to indicate an inflected tokenizeduncliticized form of the lemma.
A lemma in principle is alexeme but it is also a citation form in a dictionary.?
Generated lexeme-to-lexeme translation(Glex-to-lex): To derive inflected MSAlexeme from MSA replaced lemma andPOS, we construct a generation table on thefactored data to map lemma and POS factorsinto lexeme.
This table is generated usingMoses toolkit (Koehn et al., 2007) genera-tion scripts and provides a list of generatedlexemes for each lemma-POS pair.
An MSAlexeme language model (LM) is then used todecode the most probable sequence of MSAlexemes given these generated lexemes foreach word in the sentence.?
lemma+POS-to-lexeme translation(lem+POS-to-lex): In this path sourcelemma and POS are translated into theappropriate target lexeme.
We expect thispath provides plausible translations for DAwords that are not observed in the phrasetables.?
lexeme-to-lexeme;lemma+POS-to-lexemetranslation (lex-to-lex;lem+POS-to-lex): Thefirst path translates directly from a sourcelexeme to the target lexeme.
So it providesappropriate lexeme translations for the words(MSA or DA) which have been observedin the trained model.
It is worth notingthat lex-to-lex translation path does notcontain any replacement or normalization.Therefore, it is different from the first path(Glex-to-lex).
The second path is similarto the lem+POS-to-lex path and is used totranslate DA words that do not exist in thetrained model.3.1 Data SetsFor training translation models we use a collec-tion of MSA and EGY texts created from mul-tiple LDC catalogs3comprising multiple genres(newswire, broadcast news, broadcast conversa-tions, newsgroups and weblogs).The train datacontains 29M MSA and 5M DA tokenized words.We use two test sets to evaluate our method onboth highly DA and MSA texts: For DA test data,we selected 1065 sentences from LDC2012E30,which comprises 16177 tokenized words (BOLT-arz-test); For MSA, we use the NIST MTE-val 2009 test set (LDC2010T23), which contains341 LDC catalogs including data prepared for GALE andBOLT projects.
Please contact the authors for more details.1021445 sentences corresponding to 40858 tokenizedwords (MT09-test).
As development set (dev set),we randomly select 1547 sentences from multi-ple LDC catalogs (LDC2012E15, LDC2012E19,LDC2012E55) which comprises 20780 tokens.The following preprocessing steps are performedon the train, test and dev sets: The Arabicside of the parallel data is Alef/Ya normal-ized and tokenized using MADAMIRA v1.
ac-cording to Arabic Treebank (ATB) tokenizationscheme (Maamouri et al., 2004); Tokenization onthe EN side of the parallel data is performed usingTree Tagger (Schmid, 1994).3.2 Language ModelingWe create a 5-gram language model (LM)from three corpora sets: a) The English Giga-word 5 (Graff and Cieri, 2003); b) The En-glish side of the BOLT Phase1 parallel data;and, c) different LDC English corpora col-lected from discussion forums (LDC2012E04,LDC2012E16, LDC2012E21, LDC2012E54).
Weuse SRILM (Stolcke., 2002) to build 5-gram lan-guage models with modified Kneser-Ney smooth-ing.3.3 SMT SystemWe use the open-source Moses toolkit (Koehn etal., 2007) to build a standard phrase-based SMTsystem which extracts up to 8 words phrases in theMoses phrase table.
The parallel corpus is word-aligned using GIZA++ (Och and Ney, 2003).
Fea-ture weights are tuned to maximize BLEU onthe dev set using Minimum Error Rate Training(MERT) (Och, 2003).
To account for the in-stability of MERT, we run the tuning step threetimes per condition with different random seedsand use the optimized weights that give the me-dian score on the development set.
As all ourDA identification resources (MADAMIRA, AIDAand THARWA) are lemma-based, we adopt a fac-tored translation model setup to introduce the ex-tra information in the form of a lemma factor.
Aslemma only is not enough to generate appropriateinflected surface (lexeme) forms, we add a POSfactor with two main translation paths: (i) directtranslation from a source lexeme to the target lex-eme; and (ii) translation from source lemma andPOS to the appropriate target lexeme.
Therefore,the first path should provide plausible translationsfor the words that have been seen before in thephrase tables while we expect that the second pathprovides feasible translations for DA words thatare not seen in the trained model.4 Experimental Results4.1 Baseline ResultsFor each experimental condition mentioned inSection 3, we define a separate baseline with sim-ilar setup.
These baselines use the SMT setup de-scribed in Section 3.3 and are evaluated on the twotest sets mentioned in Section 3.1.
To assess ef-fectiveness of normalizing DA into MSA on theoverall performance of MT system, the dev andtest sets are processed through the similar stepsto generate factored data but without any replace-ment of the DA words with MSA correspondents.We believe this to be a rigorous and high base-line as data contains some morphological informa-tion useful for DA-to-EN translation in the formof lemma and POS factors.
We started with abaseline trained on the 29M words tokenized MSAtraining set and 5M words tokenized DA set sepa-rately.
We created the baseline trained on the 34Mwords MSA+DA train data.
Our objective of split-ting train data based on its dialectal variety is toassess the role of DA words existing in the trainset in the performance of our approach.Table 1 illustrates baseline BLEU scores onBOLT-arz and MT09-test sets with three differ-ent training conditions: MSA+DA, MSA only, andDA only.4.2 Replacement Experimental ResultsWe run the SMT pipeline using the feature weightsthat performed best during the tuning session onour dev set.
Then the SMT pipeline with thesetuned weights is run on two blind test sets.
Toaccount for statistical significance tests we usedbootstrapping methods as detailed in (Zhang andVogel, 2010).
Table 2 shows BLEU scores of dif-ferent DA identification and replacement schemesexploited in different setups on the test sets.As we can see in Table 2, both AIDA andMADAMIRA replacement schemes outperformthe baseline scores using MSA+DA trained mod-els and lem+POS-to-lex;lex-to-lex setup.
AIDAreaches 0.4% absolute BLEU (1.6% relativeBLEU) improvement and MADAMIRA achieves0.3% absolute BLEU (1.2% relative BLEU) en-hancement over the corresponding baselines.
Thisis while the same enhancement in BLEU scorescan not be captured when we exploit the model103Test Set Train Set lex-to-lex lem+POS-to-lex lex-to-lex:lem+POS-to-lexBOLT-arz-testMSA+DA 26.2 25.4 25.5MSA 21.8 21.2 21.8DA 24.3 24.6 24.8MT09-testMSA+DA 48.2 46.9 47.3MSA 44.4 45.4 44.6DA 35.6 36.1 34.2Table 1: Baseline BLUE scores for each setup on two test sets: BOLT-arz-test and MT09-test.
Resultsare reported for each training input language variety separately.Test Set Train Set Glex-to-lex lem+POS-to-lex lex-to-lex:lem+POS-to-lexAIDA MADAMIRA AIDA MADAMIRA AIDA MADAMIRABOLT-arz-testMSA+DA 24.4 25.1 22.6 24.1 25.9 25.8MSA 20.6 21.0 20.1 20.3 21.7 22.0DA 24.3 23.7 21.3 23.1 24.5 24.8MT09-testMSA+DA 45.9 45.8 45.4 44.6 47.1 47.3MSA 42.7 42.4 45.2 43.7 44.5 44.6DA 35.6 34.0 36.1 34.5 34.1 34.3Table 2: BLEU scores of AIDA and MADAMIRA replacement for the different setups onBOLT-arz-test and MT09-test.
Results are reported for each training language variety separately.which is trained on MSA or DA parallel datasolely.
This indicates that normalizing DA intoMSA can reach its best performance only whenwe enrich the training model with DA words atthe same time.
Therefore, we note that acquir-ing more DA data to enrich phrase tables at thetraining phase and normalizing DA at the decod-ing step of SMT system would yield the best DA-to-EN translation accuracy.Regardless of the replacement scheme we use toreduce the OOV rate (AIDA or MADAMIRA),BLEU scores on the MT09 are much higher thanthose on the BOLT-arz because the amount ofMSA words in the training data is much more thanDA words.
Therefore, SMT system encountersless OOVs at the decode time on MSA texts suchas MT09.
Overall we note that adding AIDA orMADAMIRA to the setup at best has no impacton performance on the MT09 data set since it ismostly MSA.
However, we note a small impactfor using the tools in the lex-to-lex:lem+POS-to-lex path in the MSA+DA experimental setting.Comparing results of different setups indi-cates that adding lex-to-lex translation path tothe lem+POS-to-lex increases both AIDA andMADAMIRA performance on two test sets sig-nificantly.
As Table 2 demonstrates adding lex-to-lex path to the lem+POS-to-lex translation us-ing the model trained on MSA+DA data leads to3.3% and 1.7% BLEU improvement using AIDAand MADAMIRA, respectively on the BOLT-arzset.
Similar conditions on the MT09-test givesus 1.7% and 0.7% absolute improvement in theBLEU scores using AIDA and MADAMIRA re-spectively.
This happens because lex-to-lex pathcan provide better translations for the words (MSAor DA) which have been seen in the phrase tablesand having both these paths enables the SMT sys-tem to generate more accurate translations.
Ourleast results are obtained when we use lem+POS-to-lex translation path solely either using AIDA orMADAMIRA which mainly occurs due to someerrors existing in the output of morphological an-alyzer that yields to the erroneous lemma or POS.BOLT-arz MT09Sent.
1065 1445Types 4038 8740Tokens 16177 40858COOV (type) 126 (3%) 169 (2%)COOV (token) 134 (0.82%) 187 (0.45%)Table 3: Number of sentences, types, tokens andCOOV percentages in each test set104Reference not private , i mean like buses and the metro and trains ... etc .Baseline mc mlkyp xASp yEny AqSd zy AlAtwbys w+ Almtrw w+ AlqTAr .
.
.
AlxBaseline translation privately , i mean , i mean , i do not like the bus and metro and train , etc .Replacement mc mlkyp xASp yEny AqSd mvl AlAtwbys w+ Almtrw w+ AlqTAr .
.
.
AlxReplacement translation not a private property , i mean , i mean , like the bus and metro and train , etc .Table 4: Example of translation enhancement by SOOV replacement5 Error AnalysisTo assess the rate of OOV reduction usingdifferent replacement methodologies, we firstidentify OOV words in the test sets.
Then, outof these words, cases that our approach has ledto an improvement in the sentence BLEU scoreover the baseline is reported.
Table 3 showsthe number of sentences, types and tokens foreach test set as well as the corresponding typeand token OOV counts.
As we can see in thistable, 0.82% of tokens in BOLT-arz and 0.45% oftokens in MT09-test sets are OOV.
These coverthe complete OOV cases (COOV).In addition to these cases of COOV that are causedby lack of enough training data coverage, thereare sense OOV (SOOV).
SOOV happens whena particular word appears in both DA and MSAdata but have different senses as faux amis.
Forinstance the Arabic word qlb occurs in both MSAand DA contexts but with a different set of sensesdue to the lack of diacritics.
In the specific MSAcontext it means ?heart?
while in DA it meanseither ?heart?
or ?change?.
Therefore, in additionto the cases that word sense is triggered by DAcontext, other levels of word sense ambiguitysuch as homonymy and polysemy are involved indefining an SOOV word.
Hence, SOOV identifi-cation in the test set needs additional informationsuch as word equivalent EN gloss.We determine SOOV as the words that (i) areobserved as MSA word in the training data andconsidered a DA word in the test set once pro-cessed by AIDA and MADAMIRA; and, (ii) MSAand DA renderings have different non-overlappedequivalent EN glosses as returned by our AIDAand MADAMIRA.
We assume that words withdifferent dialectal usages in the train and testwill have completely different EN equivalents,and thereby will be considered as SOOV.
Oneof the words that this constraint has recognizedas SOOV is the word zy with English equivalent?uniform?
or ?clothing?
in MSA and ?such as?
or?like?
in DA.
Replacement of this SOOV by theMSA equivalent ?mvl?
yields better translation asshown in Table 4.Among all COOV words, our approach only tar-gets COOV which are identified as DA.
Table 5and 6 report the number of COOV words (type andtoken) which have been identified as DA by AIDAor MADAMIRA in BOLT-arz and MT09 test sets,respectively.
Second column in these tables repre-sent number of SOOV (type and token) in each set.Last columns show percentage of sentences whichhave had at least one COOV or SOOV word andour replacement methodology has improved thesentence BLEU score over the baseline for eachsetup, respectively.
Percentages in these columnsdemonstrate the ratio of enhanced sentences to thetotal number of sentences which have been deter-mined to have at least one COOV or SOOV word.These percentages are reported on the MSA+DAdata to train the SMT system condition.While Table 5 and 6 show enhancements throughDA COOV replacements, our manual assessmentfinds that most of these enhancements are actu-ally coming from SOOVs present in the same sen-tences.
For example, when we examined the 21types identified by AIDA as DA COOV in BOLT-arz we found 9 typos, 5 MSAs, one foreign wordand only 6 valid DA types.
Moreover, none of thereplacements over these 6 DA types yield an en-hancement.Although Table 5 shows that MADAMIRAachieves more success enhancing BLEU score ofsentences which contain SOOV words on BOLT-arz test set, results of our investigation show thatAIDA deteriorated performance on SOOV hap-pens due to the noise that its MSA replacementsadd to the non-SOOV proportion of data.
To as-sess this hypothesis we ran the best experimentalsetup (decoding:lex-to-lex:lem+POS-to-lex, train-ing: MSA+DA) on the proportion of sentencesin BOLT-arz which contain at least one SOOV105Replacement SchemeDA COOV SOOV setup Enhanced SentencesDA COOV SOOVAIDA Replacementtype 21 712lex-to-lex 40% 58%lem+POS-to-lex 60% 35%token 26 1481lex-to-lex:lem+POS-to-lex 55% 57%MADAMIRA Replacementtype 9 194lex-to-lex 34% 55%lem+POS-to-lex 34% 47%token 9 281lex-to-lex:lem+POS-to-lex 45% 62%Table 5: Columns from left to right: number of DA COOV, SOOV and percentages of enhancedsentences for BOLT-arz set.Replacement SchemeDA COOV SOOV setup Enhanced SentencesDA COOV SOOVAIDA Replacementtype 6 376lex-to-lex 67% 44%lem+POS-to-lex 84% 35%token 6 499lex-to-lex:lem+POS-to-lex 50% 61%MADAMIRA Replacementtype 7 559lex-to-lex 29% 40%lem+POS-to-lex 27% 34%token 7 852lex-to-lex:lem+POS-to-lex 43% 48%Table 6: Similar to Table 5 for MT09 set.word as processed using AIDA and MADAMIRA(the intersection subset).
It is worth noting thatcompared to the baseline BLEU score of 23.8on this subset, AIDA achieves a BLEU score of24.4 while MADAMIRA only achieves a lowerBLEU score of 24.0.
This implicitly demon-strates that AIDA provides better MSA equiva-lents even for DA words which have MSA homo-graphs with different meanings (faux amis cases).Overall, we note that the same results can be cap-tured from Table 2 that shows AIDA outperform-ing MADAMIRA in identifying and replacing DAwords.6 Conclusion and Future WorkWe presented a new approach to enhance DA-to-EN machine translation by reducing the rateof DA OOV words.
We employed AIDA andMADAMIRA to identify DA words and replacethem with the corresponding MSA equivalent.We showed our replacement scheme reaches anoticeable enhancement in SMT performance forSOOVs.
This can be considered one of the con-tributions of this work which was not addressed inthe previous studies before.
The results of evalua-tion on two blind test sets showed that using AIDAto identify and replace MSA equivalents enhancestranslation results by 0.4% absolute BLEU (1.6%relative BLEU) and using MADAMIRA achieves0.3% absolute BLEU (1.2% relative BLEU) en-hancement over the baseline on two blind test sets.One of the interesting ideas to extend thisproject in the future is to combine AIDA andMADAMIRA top choices in a confusion networkand feeding this confusion network to the SMTsystem.
Acquiring more DA-to-EN parallel datato enrich translation models is another work whichwe intend to pursue later.
Moreover, evaluatingpossible effects of different genres and domainson the framework efficiency provides another pathto extend this work in future.AcknowledgmentsThis work was supported by the Defense Ad-vanced Research Projects Agency (DARPA) Con-tract No.
HR0011-12-C-0014, the BOLT programwith subcontract from Raytheon BBN.
We wouldlike to acknowledge the useful comments by threeanonymous reviewers who helped in making thispublication more concise and better presented.ReferencesAbhaya Agarwal, and Alon Lavie.
2008.
Meteor,m-bleu and m-ter: Evaluation metrics for high-106correlation with human rankings of machine trans-lation output.
In Proceedings of the Third Workshopon Statistical Machine Translation, pp.
115-118,Rania Al-Sabbagh and Roxana Girju.
2010.
Miningthe Web for the Induction of a dialectal Arabic Lexi-con.
In Proceedings of the Language Resources andEvaluation Conference (LREC),David Chiang, Mona Diab, Nizar Habash, Owen Ram-bow, and Safiullah Shareef.
2006.
Parsing ArabicDialects.
In Proceedings of EACL 2006,Mona Diab, Mohamed Al-Badrashiny, MaryamAminian, Mohammed Attia, Pradeep Dasigi, HebaElfardy, Ramy Eskander, Nizar Habash, AbdelatiHawwari and Wael Salloum.
2014.
Tharwa: ALarge Scale Dialectal Arabic - Standard Arabic -English Lexicon.
In Proceedings of LREC 2014,Reykjavik, Iceland.Mona Diab, Nizar Habash, Owen Rambow, MohamedAltantawy and Yassin Benajiba.
2010.
Colaba: Ara-bic dialect annotation and processing.
In Proceed-ings of LREC Workshop on Semitic Language Pro-cessing, pp.
6674.Heba Elfardy and Mona Diab.
2013.
Sentence leveldialect identification in Arabic.
In Proceedings ofACL 2013, Sofia, Bulgaria.Heba Elfardy, Mohamed Al-Badrashiny and MonaDiab.
2013.
Code Switch Point Detection in Ara-bic.
In Natural Language Processing and Informa-tion Systems, Springer Berlin Heidelberg, pp.
412-416.David Graff and Christopher Cieri.
2003.
English Gi-gaword, LDC Catalog No.
: LDC2003T05 Linguis-tic Data Consortium, University of Pennsylvania.Nizar Habash and Owen Rambow.
2005.
Arabic tok-enization, part-of-speech tagging and morphologicaldisambiguation in one fell swoop.
In Proceedings ofACL 2005,Nizar Habash.
2009.
REMOOV: A tool for online han-dling of out-of-vocabulary words in machine transla-tion..
In Proceedings of the 2nd International Con-ference on Arabic Language Resources and Tools(MEDAR), Cairo, Egypt.Nizar Habash.
2008.
Four Techniques for OnlineHandling of Out-of-Vocabulary Words in Arabic-English Statistical Machine Translation.
In Pro-ceedings of ACL 2008: HLT, Short Papers, Colum-bus, Ohio.Nizar Habash, Ryan Roth, Owen Rambow, Ramy Es-kander and Nadi Tomeh.
2013.
Morphological anal-ysis and disambiguation for dialectal Arabic.
InProceedings of NAACL 2013:HLT, pp.
426-432.Philipp Koehn, Hieu Hoang, Alexandra Birch, Christo-pher Callison-Burch, Marcello Federico, NicolaBertoldi, Brooke Cowan, Wade Shen, ChristineMoran, Richard Zens, Christopher Dyer, Ondrej Bo-jar, Alexandra Constantin, and Evan Herbst.
2007.Moses: open source toolkit for statistical machinetranslation.
In Proceedings of ACL 2007, Demo andPoster Sessions.
Prague, Czech Republic.Mohamed Maamouri, Ann Bies, Tim Buckwalter, andWigdan Mekki.
2004.
The Penn Arabic Treebank:Building a Large-Scale Annotated Arabic Corpus.In NEMLAR Conference on Arabic Language Re-sources and Tools, Cairo, Egypt.Franz Josef Och.
2003.
Minimum Error Rate Trainingfor Statistical Machine Translation.
In Proceedingsof ACL 2003, pages 160-167 Sapporo, Japan.Franz Josef Och and Hermann Ney.
2003.
A sys-tematic comparison of various statistical alignmentmodels.
Computational linguistics.
Vol.
29. pp.
19-51.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
BLEU: a Method for AutomaticEvaluation of Machine Translation.
In Proceedingsof ACL 2002, pages 311318, Philadelphia, PA.Arfath Pasha, Mohamed Al-Badrashiny, Mona Diab,Ahmed El Kholy, Ramy Eskander, Nizar Habash,Manoj Pooleery, Owen Rambow and Ryan M. Roth.2014.
MADAMIRA: A Fast, Comprehensive Toolfor Morphological Analysis and Disambiguation ofArabic.
In Proceedings of LREC 2014, Reykjavik,Iceland.Wael Salloum and Nizar Habash.
2013.
DialectalArabic to English Machine Translation: Pivotingthrough Modern Standard Arabic.
In Proceedingsof NAACL 2013:HLT, Atlanta, Georgia.Wael Salloum and Nizar Habash.
2012.
Elissa: A Di-alectal to Standard Arabic Machine Translation Sys-tem.
In Proceedings of COLING 2012, Denver,Colorado.Hassan Sawaf.
2010.
Arabic dialect handling in hybridmachine translation.
In Proceedings of AMTA 2010,Denver, Colorado.Helmut Schmid.
1994.
Probabilistic part-of-speechtagging using decision trees.
In Proceedings of in-ternational conference on new methods in languageprocessing, pp.
44-49.Matthew Snover, Bonnie Dorr, Richard Schwartz, Lin-nea Micciulla, and John Makhoul.
2006.
A study oftranslation edit rate with targeted human annotation.In Proceedings of AMTA 2006, pp.
223-231.Andreas Stolcke.
2002.
SRILM an Extensible Lan-guage Modeling Toolkit.
In Proceedings of the In-ternational Conference on Spoken Language Pro-cessing,Ying Zhang and Stephan Vogel.
2010.
SignificanceTests of Automatic Machine Translation EvaluationMetrics.
In Machine Translation, Vol.
24, Issue 1,pages 51-65.107Rabih Zbib, Erika Malchiodi, Jacob Devlin, DavidStallard, Spyros Matsoukas, Richard Schwartz, JohnMakhoul, Omar F. Zaidan, and Chris Callison-Burch.
2012.
Machine translation of Arabic di-alects.
In Proceedings of NAACL 2012:HLT,108
