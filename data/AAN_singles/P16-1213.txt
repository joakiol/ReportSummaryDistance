Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 2255?2264,Berlin, Germany, August 7-12, 2016.c?2016 Association for Computational LinguisticsOne for All: Towards Language Independent Named Entity LinkingAvirup Sil and Radu FlorianIBM T. J. Watson Research Center1101 Kitchawan RoadYorktown Heights, NY 10598avi@us.ibm.com, raduf@us.ibm.comAbstractEntity linking (EL) is the task of dis-ambiguating mentions in text by associ-ating them with entries in a predefineddatabase of mentions (persons, organiza-tions, etc).
Most previous EL research hasfocused mainly on one language, English,with less attention being paid to other lan-guages, such as Spanish or Chinese.
Inthis paper, we introduce LIEL, a Lan-guage Independent Entity Linking system,which provides an EL framework which,once trained on one language, works re-markably well on a number of differentlanguages without change.
LIEL makesa joint global prediction over the entiredocument, employing a discriminative re-ranking framework with many domainand language-independent feature func-tions.
Experiments on numerous bench-mark datasets, show that the proposed sys-tem, once trained on one language, En-glish, outperforms several state-of-the-artsystems in English (by 4 points) and thetrained model also works very well onSpanish (14 points better than a competi-tor system), demonstrating the viability ofthe approach.1 IntroductionWe live in a golden age of information, wherewe have access to vast amount of data in variousforms: text, video and audio.
Being able to ana-lyze this data automatically, usually involves fill-ing a relational database, which, in turn, requiresthe processing system to be able to identify actorsacross documents by assigning unique identifiersto them.
Entity Linking (EL) is the task of map-ping specific textual mentions of entities in a textdocument to an entry in a large catalog of entities,often called a knowledge base or KB, and is oneof the major tasks in the Knowledge-Base Popula-tion track at the Text Analysis Conference (TAC)(Ji et al, 2014).
The task also involves groupingtogether (clustering) NIL entities which do nothave any target referents in the KB.Previous work, pioneered by (Bunescu andPasca, 2006; Cucerzan, 2007; Sil et al, 2012;Ratinov et al, 2011; Guo et al, 2013), have usedWikipedia as this target catalog of entities be-cause of its wide coverage and its frequent updatesmade by the community.
As with many NLP ap-proaches, most of the previous EL research havefocused on English, mainly because it has manyNLP resources available, it is the most prevalentlanguage on the web, and the fact that the EnglishWikipedia is the largest among all the Wikipediadatasets.
However, there are plenty of web docu-ments in other languages, such as Spanish (Fahrniet al, 2013; Ji et al, 2014), and Chinese (Caoet al, 2014; Shi et al, 2014), with a large num-ber of speakers, and there is a need to be able todevelop EL systems for these languages (and oth-ers!)
quickly and inexpensively.In this paper, we investigate the hypothesis thatwe can train an EL model that is entirely un-lexicalized, by only allowing features that com-pute similarity between the text in the input docu-ment and the text/information in the KB.
For thispurpose, we propose a novel approach to entitylinking, which we call Language Independent En-tity Linking (henceforth LIEL).
We test this hy-pothesis by applying the English-trained systemon Spanish and Chinese datasets, with great suc-cess.This paper has three novel contributions: 1) ex-tending a powerful inference algorithm for globalentity linking, built using similarity measures, cor-pus statistics, along with knowledge base statis-2255tics, 2) integrates many language-agnostic anddomain independent features in an exponentialframework, and 3) provide empirical evidence ona large variety of popular benchmark datasets thatthe resulting model outperforms or matches thebest published results, and, most importantly, thetrained model transfers well across languages, out-performing the state-of-the-art (SOTA) in Spanishand matching it in Chinese.We organize the paper as follows: the nextsection motivates the problem and discusses thelanguage-independent model along with the fea-tures.
Section 3 describes our experiments andcomparison with the state-of-the-art.
Section 4 il-lustrates the related previous work and Section 5concludes.2 Problem Formulation2.1 Motivation for Language IndependenceOur strategy builds an un-lexicalized EL systemby training it on labeled data, which consists ofpairs of mentions in text and entries in a databaseextracted from a Wikipedia collection in English.Unlike traditional EL, however, the purpose hereis to be able to perform entity linking with respectto any Wikipedia collection.
Thus the strategymust take care to build a model that can transferits learned model to a new Wikipedia collection,without change.At a first glance, the problem seemsvery challenging - learning how to dis-criminate Lincoln, Nebraska andAbraham Lincoln1, the former US Pres-ident, seemingly bears little resemblance todisambiguating between different Spanish personentities named ?Ali Quimico?.
The crux of theproblem lies in the fact that Wikipedia-driven fea-tures are language-specific: for instance, countinghow many times the category 2010 Deathsappears in the context of an entity is highly usefulin the English EL task, but not directly useful forSpanish EL.
Also, learning vocabulary-specificinformation like the list of ?deaths?, ?presidents?,etc.
is very useful for disambiguating personentities like ?Lincoln?
in English, but the samemodel, most likely, will not work for mentionslike ????
in a Chinese document which mighteither refer to the famous athlete ??
(?????)
or the singer??
(??
).1Teletype font denotes Wikipedia titles and categories.Practically we assume the existence of a knowl-edge base that defines the space of entities we wantto disambiguate against, where each entry containsa document with the entity; Wikipedia is a stan-dard example for this2.
If there are other proper-ties associated with the entries, such as categories,in-links, out-links, redirects, etc., the system canmake use of them, but they are theoretically notrequired.
The task is defined as: given a mentionm in a document d, find the entry e in the knowl-edge base that m maps to.We expand on the architecture described in (Siland Yates, 2013) (henceforth NEREL), becauseof the flexibility provided by the feature-basedexponential framework which results in an En-glish SOTA EL system.
However, we design allour features in such a way that they measure thesimilarity between the context where the mentionm appears in d and the entries in the knowledgebase.
For example, instead of counting howoften the category 2010 Deaths3appearsin the context around an entity mention, wecreate a feature function such as CATEGORYFREQUENCY(m, e), which counts how oftenany category of entity referent e appears inthe context of mention m. For entities likeLincoln, Nebraska in the English EL,CATEGORY FREQUENCY will add togethercounts for appearances of categories like Citiesin Lancaster County, Nebraska andLincoln metropolitan area, amongother categories.
At the same time, in the SpanishEL domain, CATEGORY FREQUENCY will addtogether counts for Pol?
?ticos de Irakand Militares de Irak for the KB idcorresponding to ?Ali Quimico?.
This feature iswell-defined in both domains, and larger valuesof the feature indicate a better match between mand e. As mentioned earlier, it is our hypothesis,that the parameters trained for such featureson one language (English, in our case) can besuccessfully used, without retraining, on otherlanguages, namely Spanish and Chinese.While training, the system will take as input aknowledge base in source language S, KBS(ex-tracted from Wikipedia) and a set of training ex-amples (mi, ei, gi), where instances miare men-tions in a document of language S, eiare en-tity links, ei?
KBS, and giare Boolean val-2We will assume, without loss of generality, that theknowledge base is derived from Wikipedia.3Or a specific Freebase type.2256ues indicating the gold-standard match / mismatchbetween miand ei.
During decoding, givenlanguage T4, the system must classify examples(mj, ej) drawn from a target language T andknowledge-base KBT.2.2 LIEL: Training and InferenceOur language-independent system consists of twocomponents: 1. extracting mentions of named-entities from documents and 2. linking the de-tected mentions to a knowledge base, which in ourcase is Wikipedia (focus of this paper).
We runthe IBM Statistical Information and Relation Ex-traction (SIRE)5system which is a toolkit thatperforms mention detection, relation extraction,coreference resolution, etc.
We use the system toextract mentions and perform coreference resolu-tion: in particular, we use the CRF model of IBMSIRE for mention detection and a maximum en-tropy clustering algorithm for coreference reso-lution.
The system identifies a set of 53 entitytypes.
To improve the mention detection and res-olution, case restoration is performed on the in-put data.
Case restoration is helpful to improvethe mention detection system?s performance, es-pecially for discussion forum data.
Obviously, thisprocessing step is language-dependent, as the in-formation extraction system is - but we want toemphasize that the entity linking system is lan-guage independent.In the EL step, we perform a full documententity disambiguation inference, described as fol-lows.
Given a document d, and a selected mentionm ?
d, our goal is to identify its label e?
that max-imizese?
= P (e|m, d) (1)= argmaxe:m?k,m?mk1,ek1P(mk1|m, d)P(ek1|mk1, d)where mk1are mentions found in document d, andek1are some label assignment.
In effect, we arelooking for the best mention labeling of the en-tire document mk1(that contains m) and a labelto these mentions that would maximize the infor-mation extracted from the entire document.
Sincedirect inference on Equation 1 is hard, if not in-tractable, we are going to select the most likely4Language prediction can be done relatively accurately,given a document; however, in this paper, we focus on theEL task, so we assume we know the identity of the targetlanguage T .5The IBM SIRE system can be currently accessed at :http://www.ibm.com/smarterplanet/us/en/ibmwatson/developercloud/relationship-extraction.htmlmention assignment instead (as found by an in-formation extraction system): we will only con-sider the detected mentions (m1, .
.
.
,mk), andother optional information that can be extractedfrom the document, such as links l, categories r,etc.
The goal becomes identifying the set of labels(e1, .
.
.
, ek) that maximizeP(ek1|mk1, d)(2)Since searching over all possible sets of (mention,entity)-pairs for a document is still intractable forreasonable large values of k, typical approachesto EL make simplifying assumption on how tocompute the probability in Equation 2.
Sev-eral full-document EL approaches have investi-gated generating up to N global tuples of en-tity ids (e1, .
.
.
, ek), and then build a model torank these tuples of entity ids (Bunescu and Pasca,2006; Cucerzan, 2007).
However, Ratinov etal.
(Ratinov et al, 2011) argue that this typeof global model provides a relatively small im-provement over the purely-local approach (whereP(ek1|mk1, d)=?iP (ei|mi, d)).
In this paper,we follow an approach which combines both ofthese strategies.Following the recent success of (Sil and Yates,2013), we partition the full set of extractedmentions, (mi)i=?1,nof the input document d intosmaller subsets of mentions which appear nearone another: we consider two mentions that arecloser then 4 words to be in the same connectedcomponent, then we take the transitive closureof this relation to partition the mention set.
Werefer to these sets as the connected componentsof d, or CC(d).
We perform classificationover the set of entity-mention tuples T (C) ={(ei1, .
.
.
, einC|mi1, .
.
.
,minC)|eij?
KB,?j}6that are formed using candidate entities withinthe same connected component C ?
CC(d).Consider this small snippet of text:?.
.
.
Home Depot CEO Nardelli quits .
.
.
?In this example text, the phrase ?Home DepotCEO Nardelli?
would constitute a connectedcomponent.
Two of the entity-mention tu-ples for this connected component wouldbe: (Home Depot, Robert Nardelli|?Home Depot?, ?Nardelli?)
and (Home Depot,Steve Nardelli | ?Home Depot?,?Nardelli?
).6For simplicity, we denote by (e|m) the tuple (e,m),written like that to capture the fact that m is fixed, while eis predicted.22572.2.1 Collective Classification ModelTo estimate P (t|d,C), the probability of an entity-mention tuple t for a given connected compo-nent C ?
CC(d), LIEL uses a maximum-entropymodel:P (t|d,C) =exp (w ?
f(t, d, C))?t?
?T (C)exp (w ?
f(t?, d, C))(3)where f(t, d, C) is a feature vector associated witht, d, and C, and w is a weight vector.
For training,we use L2-regularized conditional log likelihood(CLL) as the objectiveCLL(G,w) =?
(t,d,C)?GlogP (t|d,C,w)??
?w?22(4)where G is the gold-standard training data, con-sisting of pairs (t, d, C), where t is the correct tu-ple of entities and mentions for connected compo-nent C in document d, and ?
is a regularizationparameter.
Given that the function 4 is convex, weuse LBFGS (Liu and Nocedal, 1989) to find theglobally optimal parameter settings over the train-ing data.2.3 Extracting potential target entitiesFrom the dump of our Wikipedia data, we extractall the mentions that can refer to Wikipedia titles,and construct a set of disambiguation candidatesfor each mention (which are basically the hyper-links in Wikipedia).
This is, hence, an anchor-titleindex that maps each distinct hyperlink anchor-text to its corresponding Wikipedia titles and alsostores their relative popularity score.
For example,the anchor text (or mention) ?Titanic?
is used inWikipedia to refer both to the ship or to the movie.To retrieve the disambiguation candidates eifor agiven mention mi, we query the anchor-title in-dex that we constructed and use lexical sub-wordmatching.
eiis taken to be the set of titles (or en-tities, in the case of EL) most frequently linked towith anchor text miin Wikipedia.
We use onlythe top 40 most frequent Wikipedia candidates forthe anchor text for computational efficiency pur-poses for most of our experiments.
We call thisstep ?Fast Search?
since it produces a bunch ofcandidate links by just looking up an index.2.3.1 DecodingAt decoding time, given a document d, we iden-tify its connected components CC (d) and run in-ference on each component C containing the de-sired input mention m. To further reduce the runtime, for each mention mj?
C, we obtain theset of potential labels ejusing the algorithm de-scribed in Section 2.3, and then exhaustively findthe pair that maximizes equation 3.
For each can-didate link, we also add a NIL candidate to fastmatch to let the system link mentions to ids not ina KB.2.4 Language-Independent FeatureFunctionsLIEL makes use of new as well as well-establishedfeatures in the EL literature.
However, we makesure to use only non-lexical features.
The localand global feature functions computed from thisextracted information are described below.Generically, we have two types of basic fea-tures: one that takes as input a KB entry e, themention m and its document and a second typethat scores two KB entries, e1and e2.
When com-puting the probability in Equation 3, where weconsider a set of KB entries t7, we either sum orapply a boolean AND operator (in case of booleanfeatures) among all entities e ?
t, while the entity-entity functions are summed/and?ed for consecu-tive entities in t. We describe the features in theseterms, for simplicity.2.4.1 Mention-Entity Pair FeaturesText-based Features: We assume the existenceof a document with most entries in the KB, andthe system uses similarity between the inputdocument and these KB documents.
The basicintuition behind these features, inspired by Rati-nov et al(2011), is that a mention m ?
d is morelikely to refer to entity e if its KB page, W (e), hashigh textual similarity to input document d. LetText (W (e)) be the vector space model associ-ated with W (e), Top (W (e)) be the vector of thetop most frequently occurring words (excludingstop-words) from W (e), and Context(W (e)) bethe vector space of the 100 word window aroundthe first occurrence of m in W (e).
Similarly,we create vector space models Text(m) andContext(m).
We then use cosine similarity overthese vector space models as features:i. cosine(Text (W (e)) , T ext (m)),ii.
cosine(Text (W (e)) , Context (m)),iii.
cosine(Context (W (e)) , T ext (m)),iv.
cosine(Context (W (e)) , Context (m)),v. cosine(Top (W (e)) , T ext (m)),7Recall that the probability is computed for all the entityassignments for mentions in a clique.2258vi.
cosine (Top (W (e)) , Context (m)).KB Link Properties: LIEL can make use of ex-isting relations in the KB, such as inlinks, outlinks,redirects, and categories.
Practically, for each suchrelation l, a KB entry e has an associated set ofstrings I(l, e)8; given a mention-side set M (ei-ther Text(m) or Context(m)), LIEL computesFREQUENCY feature functions for the names ofthe Categories, Inlinks, Outlinks and Redirects,we computef(e,m, d) = |I(l, e) ?M |Title Features: LIEL also contains a number offeatures that make use of the Wikipedia title of theentity links in t (remember t = entity mention tu-ples and not a Wikipedia title) :?
NIL FREQUENCY: Computes the frequencyof entities that link to NIL?
EXACT MATCH FREQUENCY: returns 1 ifthe surface form of m is a redirect for e;?
MATCH ALL: returns true if m matches ex-actly the title of e;?
MATCH ACRONYM: returns true if m is anacronym for a redirect of e;?
LINK PRIOR: the prior link probabilityP (e|m), computed from anchor-title pairs inKB (described in Section 2.3).2.4.2 Entity-Entity Pair FeaturesCoherence Features: To better model consecu-tive entity assignments, LIEL computes a coher-ence feature function called OUTLINK OVER-LAP.
For every consecutive pair of entities (e1, e2)that belongs to mentions in t, the feature com-putes Jaccard(Out(e1), Out(e2)), where Out(e)denotes the Outlinks of e. Similarly, we also com-pute INLINK OVERLAP.LIEL also uses categories in Wikipedia whichexist in all languages.
The first feature EN-TITY CATEGORY PMI, inspired by Sil and Yates(2013), make use of Wikipedia?s category infor-mation system to find patterns of entities that com-monly appear next to one another.
Let C(e) bethe set of Wikipedia categories for entity e. Wemanually inspect and remove a handful of com-mon Wikipedia categories based on threshold fre-quency on our training data, which are associ-ated with almost every entity in text, like Living8For instance, redirect strings for ?Obama?
are ?BarackObama?, ?Barack Obama Jr.?
and ?Barack Hussein Obama?.People etc., since they have lower discriminat-ing power.
These are analogous to all WP lan-guages.
From the training data, the system firstcomputes point-wise mutual information (PMI)(Turney, 2002) scores for the Wikipedia categoriesof pairs of entities, (e1, e2):PMI(C(e1), C(e2)) =ntC?1?j=11[C(e1) = C(eij) ?
C(e2) = C(eij+1)]?j1[C(e1) = C(eij)]?
?j1[C(e2) = C(eij)]?
ENTITY CATEGORY PMI adds these PMIscores up for every consecutive (e1, e2) pairin t.?
CATEGORICAL RELATION FREQUENCYWe would like to boost consecutive entity as-signments that have been seen in the trainingdata.
For instance, for the text ?England cap-tain Broad fined for..?, we wish to encouragethe tuple that links ?England?
to the entityid of the team name England cricketteam, and ?Broad?
to the entity id of theperson Stuart Broad.
Wikipedia con-tains a relation displayed by the categorycalled English cricketers that indi-cates that Stuart Broad is a team mem-ber of England cricket team, andcounts the number of such relations betweenevery consecutive pair of entities in (e, e?)
?t.?
TITLE CO-OCCURRENCE FREQUENCYfeature computes for every pair of consecu-tive entities (e, e?)
?
t, the number of timesthat e?appears as a link in the Wikipedia pagefor e, and vice versa (similar to (Cucerzan,2007).
It adds these counts up to get a singlenumber for t.3 ExperimentsWe evaluate LIEL?s capability by testing againstseveral state-of-the-art EL systems on English,then apply the English-trained system to Spanishand Chinese EL tasks to test its language tran-scendability.3.1 DatasetsEnglish: The 3 benchmark datasets for the En-glish EL task are: i) ACE (Ratinov et al, 2011), ii)MSNBC (Cucerzan, 2007) and iii) TAC 2014 (Ji et2259Name |M | In KB Not in KBACE 257 100% 0MSNBC 747 90% 10%TAC En14 5234 54% 46%TAC Es13 2117 62% 38%TAC Es14 2057 72% 28%TAC Zh13 2155 57% 43%WikiTrain 158715 100% 0%Table 1: Data statistics: number of mentionqueries, % of mention queries that have theirreferents present in the Wikipedia/KB, and %of mention queries that have no referents inWikipedia/KB as per our datasets.
En=English,Es=Spanish and Zh=Chinese for the evaluationdata for TAC for the years 2013 and 2014.al., 2014)9, which contain data from diverse genrelike discussion forum, blogs and news.
Table 1provides key statistics on these datasets.
In theTAC10evaluation setting, EL systems are given asinput a document and a query mention with its off-sets in the input document.
As the output, systemsneed to predict the KB id of the input query men-tion if it exists in the KB or NIL if it does not.Further, they need to cluster the mentions whichcontain the same NIL ids across queries.The training dataset, WikiTrain, consists of10,000 random Wikipedia pages, where all ofthe phrases that link to other Wikipedia articlesare treated as mentions, and the target Wikipediapage is the label.
The dataset was made avail-able by Ratinov et al and (Sil and Yates, 2013),added Freebase to Wikipedia mappings resultingin 158,715 labeled mentions with an average of12.62 candidates per mention.
The total numberof unique mentions in the data set is 77,230 witha total of 974,381 candidate entities and 643,810unique candidate entities.
The Wikipedia dumpthat we used as our knowledge-base for English,Spanish and Chinese is the April 2014 dump.
TheTAC dataset involves the TAC KB which is a dumpof May 2008 of English Wikipedia.
LIEL linksentities to the Wikipedia 2014 dump and uses theredirect information to link back to the TAC KB.Spanish: We evaluate LIEL on both the 20139This is the traditional Entity Linking (EL) task and notEntity Discovery and Linking (EDL), since we are comparingthe linking capability in this paper.10For more details on TAC seehttp://nlp.cs.rpi.edu/kbp/2014/index.htmland 2014 benchmark datasets of the TAC Spanishevaluation.Chinese: We test LIEL on the TAC 2013 Chi-nese dataset.3.2 Evaluation MetricWe follow standard measures used in the litera-ture for the entity linking task.
To evaluate ELaccuracy on ACE and MSNBC, we report on aBag-of-Titles (BOT) F1 evaluation as introducedby (Milne and Witten, 2008; Ratinov et al, 2011).In BOT-F1, we compare the set of Wikipedia ti-tles output for a document with the gold set of ti-tles for that document (ignoring duplicates), andcompute standard precision, recall, and F1 mea-sures.
On the TAC dataset, we use standard met-rics B3+ variant of precision, recall and F1.
Onthese datasets, the B3+ F1 metric includes theclustering score for the NIL entities, and hencesystems that only perform binary NIL predictionwould be heavily penalized11.3.3 Comparison with the State-of-the-artTo follow the guidelines for the TAC NIST evalu-ation, we anonymize participant system names asSystem 1 through 9.
Interested readers may lookat their system description and scores in (Ji et al,2014; Fahrni et al, 2013; Miao et al, 2013; May-field, 2013; Merhav et al, 2013).
Out of thesesystems, System 1 and System 7 obtained the topscore in Spanish and Chinese EL evaluation atTAC 2013 and hence can be treated as the currentstate-of-the-art for the respective EL tasks.
Wealso compare LIEL with some traditional ?wiki-fiers?
like MW08 (Milne and Witten, 2008) andUIUC (Cheng and Roth, 2013) and also NEREL(Sil and Yates, 2013) which is the system whichLIEL resembles the most.3.4 Parameter SettingsLIEL has two tuning parameters: ?, the regular-ization weight; and the number of candidate linksper mention we select from the Wikipedia dump.We set the value of ?
by trying five possible valuesin the range [0.1, 10] on held-out data (the TAC2009 data).
We found ?
= 0.5 to work best forour experiments.
We chose to select a maximumof 40 candidate entities from Wikipedia for eachcandidate mention (or fewer if the dump had fewerthan 40 links with nonzero probability).11For more details on the scoring metric used for TAC ELsee: http://nlp.cs.rpi.edu/kbp/2014/scoring.html22600.7280.853 0.859 0.8620.6850.812 0.846 0.8500.5000.5500.6000.6500.7000.7500.8000.8500.900MW08 UIUC NEREL LIELBOT-F1BOT-F1:	LIEL	vs.
The	State-of-the-artACE MSNBCFigure 1: LIEL outperforms all its competitors onboth ACE and MSNBC.3.5 ResultsEnglish: Figure 1 compares LIEL with previouslyreported results by MW08, UIUC and NEREL onthe ACE and MSNBC datasets in (Cheng andRoth, 2013; Sil and Yates, 2013).
LIEL achievesan F1 score of 86.2 on ACE and 85.0 on MSNBC,clearly outperforming the others e.g.
3.8% abso-lute value higher than UIUC on MSNBC.
We be-lieve that LIEL?s strong model comprising rela-tional information (coherence features from largecorpus statistics), textual and title lets it outper-form UIUC and MW08 where the former uses re-lational information and the latter a naive versionof LIEL?s coherence features.
Comparison withNEREL is slightly unfair (though we outperformthem marginally) since they use both Freebase andWikipedia as their KB whereas we are comparingwith systems which only use Wikipedia as theirKB.To test the robustness of LIEL on a diversegenre of data, we also compare it with some of theother state-of-the-art systems on the latest bench-mark TAC 2014 dataset.
Figure 2 shows our re-sults when compared with the top systems in theevaluation.
Encouragingly, LIEL?s performance istied with the top performer, System 6, and out-performs all the other top participants from thischallenging annual evaluation.
Note that LIEL ob-tains 0.13 points more than System 1, the onlyother multi-lingual EL system and, in that sense,LIEL?s major competitor.
Several other factors areevident from the results: System 1 and 2 are sta-tistically tied and so are System 3, 4 and 5.
Wealso show the bootstrapped percentile confidenceintervals (Singh and Xie, 2008) for LIEL whichare [0.813, 0.841]: (we do not have access to theother competing systems).0.69 0.700.76 0.76 0.770.82 0.820.50.550.60.650.70.750.80.85Axis	TitleEnglish EL	Test:	LIEL	vs.	other	TAC	EL	systemsFigure 2: Comparison of several state-of-the-artEnglish EL systems along with LIEL on the latestTAC 2014 dataset and LIEL obtains the best score.
* indicates systems that perform multilingual EL.0.550.650.71 0.740.660.800.500.550.600.650.700.750.800.85System9 System7 System1 LIELasdasdaSpanish	EL	Test:	LIEL	vs.	other	TAC	EL	Systems2013 2014Figure 3: System performance on the TAC 2013and 2014 Spanish datasets are shown.
LIEL out-performs all the systems in terms of overall F1score.3.5.1 Foreign Language ExperimentsNote that LIEL was trained only on the EnglishWikitrain dataset (Section 3.1), and then applied,unchanged, to all the evaluation datasets acrosslanguages and domains described in Section 3.1.Hence, it is the same instance of the model forall languages.
As we will observe, this one sys-tem consistently outperforms the state of the art,even though it is using exactly the same trainedmodel across the datasets.
We consider this to bethe take-away message of this paper.Spanish: LIEL obtains a B3+ F1 score of0.736 on the TAC 2013 dataset and clearly outper-forms the SOTA, System 1, which obtains 0.709as shown in Figure 3 and considerably higher thanthe other participating systems.
We could only ob-tain the results for Systems 9 and 7 on 2013.
Onthe 2014 evaluation dataset, LIEL obtains a highergain of 0.136 points (precision of 0.814 and re-call of 0.787) over its major competitor System1, showing the power of its language-independentmodel.22610.60 0.600.63 0.630.50.520.540.560.580.60.620.64System	1 LIEL System	8 System	7Axis	TitleChinese	EL	Test:	LIEL	vs.	other	TAC	EL	SystemsFigure 4: LIEL achieves competitive performancein Chinese EL further proving its robustness tomultilingual data.Chinese: Figure 4 shows the results of LIEL?sperformance on the Chinese benchmark datasetcompared to the state-of-the-art.
Systems 7 and8 obtains almost similar scores.
We observe thatLIEL is tied with System 1 and achieves com-petitive performance compared to Systems 7 and8 (note that LIEL has a confidence interval of[0.597, 0.632]) which requires labeled ChineseTAC data to be trained on and the same model doesnot work for other languages.
Emphasizing again:LIEL is trained only once, on English, and testedon Chinese unchanged.3.5.2 Error AnalysisWhile we see LIEL?s strong multi-lingual empiri-cal results, it is important to note some of the areaswhich confuses the system.
Firstly, a major sourceof error which affects LIEL?s performance is dueto coreference resolution e.g.
from the text ?Bel-tran Leyva, also known as ?The Bearded One,?is ...?, TAC?s mention query asks the systems toprovide the disambiguation for The Bearded One.LIEL predicts that the The Bearded One refersto the entity Richard Branson, which is themost common entity in Wikipedia that refers tothat nickname (based on our dump), while, clearly,the correct entity should have been Beltran Levya.We believe that this type of an error can be han-dled by performing joint EL and coreference res-olution, which is a promising future research areafor LIEL.Contextual information can also hurt systemperformance e.g.
from the text, ?..
dijo AlexS?anchez , analista..?, LIEL predicts the Wikipediatitle Alex S?anchez (outfielder) for themention Alex S?anchez since the document talksabout sports and player names.
The query men-tion was actually referring to a journalist, not inthe KB, and hence a NIL.
Handling sparse en-tities, similar to this, are also an important futuredirection.4 Related WorkEntity linking has been introduced and activelydeveloped under the NIST-organized Text Analy-sis Conference, specifically the Knowledge BasePopulation track.
The top performing EnglishEL system in the TAC evaluation has been theMS MLI system (Cucerzan and Sil, 2013), whichhas obtained the top score in TAC evaluation in thepast 4 years (2011 through 2014): the system linksall mentions in a document simultaneously, withthe constraint that their resolved links should beglobally consistent on the category level as muchas possible.
Since global disambiguation can beexpensive, (Milne and Witten, 2008) uses the setof unambiguous mentions in the text surroundinga mention to define the mention?s context, anduses the Normalized Google Distance (Cilibrasiand Vitanyi, 2007) to compute the similarity be-tween this context and the candidate Wikipedia en-try.
The UIUC system, (Cheng and Roth, 2013),another state-of-the-art EL system, which is an ex-tension of (Ratinov et al, 2011), adds relationalinference for wikification.
NEREL (Sil and Yates,2013) is a powerful joint entity extraction and link-ing system.
However, by construction their modelis not language-independent due to the heavy re-liance on type systems of structured knowledge-bases like Freebase.
It also makes use of lexicalfeatures from Wikipedia as their model performsjoint entity extraction and disambiguation.
Someof the other systems which use a graph based algo-rithm such as partitioning are LCC, NYU (Ji et al,2014) and HITS (Fahrni et al, 2013) which ob-tained competitive score in the TAC evaluations.Among all these systems, only the HITS systemhas ventured beyond English and has obtained thetop score in Spanish EL evaluation at TAC 2013.It is the only multilingual EL system in the lit-erature which performs reliably well across a se-ries of languages and benchmark datasets.
Re-cently, (Wang et al, 2015) show a new domain andlanguage-independent EL system but they makeuse of translation tables for non-English (Chi-nese) EL; thereby not making the system entirelylanguage-independent.
Empirically their perfor-mance comes close to System 1 which LIEL out-performs.
The BASIS system (Merhav et al,22622013), is the state-of-the-art for Chinese EL asit obtained the top score in TAC 2013.
The FU-JITSU system (Miao et al, 2013) obtained similarscores.
It is worth noting that these systems, unlikeLIEL, are heavily language dependent, e.g.
per-forming lexicon specific information extraction,using inter-language links to map between the lan-guages or training using labeled Chinese data.In more specialized domains, Dai et al (2011)employed a Markov logic network for buildingan EL system with good results in a bio-medicaldomain; it would be interesting to find out howtheir techniques might extended to other lan-guages/corpora.
Phan et al (2008) utilize topicmodels derived from Wikipedia to help classifyshort text segment, while Guo et al (2013) investi-gate methods for disambiguating entities in tweets.Neither of these methods do show how to transferthe EL system developed for short texts to differ-ent languages, if at all.The large majority of entity linking researchoutside of TAC involves a closely related task -wikification (Bunescu and Pasca, 2006; Cucerzan,2007; Ratinov et al, 2011; Guo et al, 2013), andhas been mainly performed on English datasets,for obvious reasons (data, tools availability).These systems usually achieve high accuracy onthe language they are trained on.
Multilingualstudies, e.g.
(McNamee et al, 2011), use a largenumber of pipelines and complex statistical ma-chine translation tools to first translate the originaldocument contexts into English equivalents andtransform the cross-lingual EL task into a mono-lingual EL one.
The performance of the entitylinking system is highly dependent on the exis-tence and potential of the statistical machine trans-lation system in the given pair of languages.5 ConclusionIn this paper we discussed a new strategy formultilingual entity linking that, once trained onone language source with accompanying knowl-edge base, performs without adaptation in multi-ple target languages.
Our proposed system, LIELis trained on the English Wikipedia corpus, af-ter building its own knowledge-base by exploit-ing the rich information present in Wikipedia.
Oneof the main characteristics of the system is that itmakes effective use of features that are built ex-clusively around computing similarity between thetext/context of the mention and the document textof the candidate entity, allowing it to transcendlanguage and perform inference on a completelynew language or domain, without change or adap-tation.The system displays a robust and strong empir-ical evidence by not only outperforming all state-of-the-art English EL systems, but also achievingvery good performance on multiple Spanish andChinese entity linking benchmark datasets, and itdoes so without the need to switch, retrain, or eventranslate, a major differentiating factor from theexisting multi-lingual EL systems out there.AcknowledgmentsWe would like to thank the anonymous review-ers for their suggestions.
We also thank SalimRoukos, Georgiana Dinu and Vittorio Castelli fortheir helpful comments.
This work was fundedunder DARPA HR0011-12-C-0015 (BOLT).
Theviews and findings in this paper are those of theauthors and are not endorsed by DARPA.ReferencesR.
Bunescu and M. Pasca.
2006.
Using encyclope-dic knowledge for named entity disambiguation.
InEACL.Ziqiang Cao, Sujian Li, and Heng Ji.
2014.
Jointlearning of chinese words, terms and keywords.
InEMNLP.X.
Cheng and D. Roth.
2013.
Relational inferencefor wikification.
In Proc.
of the Conference onEmpirical Methods in Natural Language Processing(EMNLP).R.L.
Cilibrasi and P.M.B.
Vitanyi.
2007.
The googlesimilarity distance.
IEEE Transactions on Knowl-edge and Data Engineering, 19(3):370?383.Silviu Cucerzan and Avirup Sil.
2013.
The MSR Sys-tems for Entity Linking and Temporal Slot Filling atTAC 2013.
In Text Analysis Conference.Silviu Cucerzan.
2007.
Large-scale named entity dis-ambiguation based on wikipedia data.
In EMNLP-CoNLL, pages 708?716.Hong-Jie Dai, Richard Tzong-Han Tsai, Wen-LianHsu, et al 2011.
Entity disambiguation using amarkov-logic network.
In IJCNLP.Angela Fahrni, Benjamin Heinzerling, Thierry G?ockel,and Michael Strube.
2013.
Hits monolingual andcross-lingual entity linking system at TAC 2013.
InText Analysis Conference.2263Stephen Guo, Ming-Wei Chang, and Emre K?c?man.2013.
To link or not to link?
a study on end-to-endtweet entity linking.
In NAACL.Heng Ji, HT Dang, J Nothman, and B Hachey.
2014.Overview of tac-kbp2014 entity discovery and link-ing tasks.
In Proc.
Text Analysis Conference(TAC2014).D.C.
Liu and J. Nocedal.
1989.
On the limited memorymethod for large scale optimization.
MathematicalProgramming B, 45(3):503?528.James Mayfield.
2013.
Overview of the kbp 2013 en-tity linking track.Paul McNamee, James Mayfield, Douglas W Oard,Tan Xu, Ke Wu, Veselin Stoyanov, and David Do-ermann.
2011.
Cross-language entity linking inmaryland during a hurricane.
In Text Analysis Con-ference.Yuval Merhav, Joel Barry, James Clarke, David Mur-gatroyd, and One Alewife Center.
2013.
Basis tech-nology at tac 2013 entity linking.Qingliang Miao, Ruiyu Fang, Yao Meng, and ShuZhang.
2013.
Frdc?s cross-lingual entity linkingsystem at tac 2013.David Milne and Ian H. Witten.
2008.
Learning to linkwith wikipedia.
In CIKM.Xuan-Hieu Phan, Le-Minh Nguyen, and SusumuHoriguchi.
2008.
Learning to classify short andsparse text & web with hidden topics from large-scale data collections.
In Proceedings of the 17thinternational conference on World Wide Web.L.
Ratinov, D. Roth, D. Downey, and M. Anderson.2011.
Local and global algorithms for disambigua-tion to wikipedia.
In Proc.
of the Annual Meeting ofthe Association of Computational Linguistics (ACL).Xing Shi, Kevin Knight, and Heng Ji.
2014.
How tospeak a language without knowing it.
In ACL.Avirup Sil and Alexander Yates.
2013.
Re-rankingfor Joint Named-Entity Recognition and Linking.
InCIKM.Avirup Sil, Ernest Cronin, Penghai Nie, Yinfei Yang,Ana-Maria Popescu, and Alexander Yates.
2012.Linking Named Entities to Any Database.
InEMNLP-CoNLL.Kesar Singh and Minge Xie.
2008.
Bootstrap: a statis-tical method.P.
D. Turney.
2002.
Thumbs up or thumbs down?
se-mantic orientation applied to unsupervised classifi-cation of reviews.
In Procs.
of ACL, pages 417?424.Han Wang, Jin Guang Zheng, Xiaogang Ma, Peter Fox,and Heng Ji.
2015.
Language and domain indepen-dent entity linking with quantified collective valida-tion.
In Proc.
Conference on Empirical Methods inNatural Language Processing (EMNLP2015).2264
