First Joint Conference on Lexical and Computational Semantics (*SEM), pages 151?160,Montre?al, Canada, June 7-8, 2012. c?2012 Association for Computational LinguisticsRegular polysemy: A distributional modelGemma BoledaDept.
of LinguisticsUniversity of Texas at Austingemma.boleda@upf.eduSebastian Pado?ICLUniversity of Heidelbergpado@cl.uni-heidelberg.deJason UttIMSUniversity of Stuttgartuttjn@ims.uni-stuttgart.deAbstractMany types of polysemy are not word specific,but are instances of general sense alternationssuch as ANIMAL-FOOD.
Despite their perva-siveness, regular alternations have been mostlyignored in empirical computational semantics.This paper presents (a) a general frameworkwhich grounds sense alternations in corpusdata, generalizes them above individual words,and allows the prediction of alternations fornew words; and (b) a concrete unsupervisedimplementation of the framework, the Cen-troid Attribute Model.
We evaluate this modelagainst a set of 2,400 ambiguous words anddemonstrate that it outperforms two baselines.1 IntroductionOne of the biggest challenges in computational se-mantics is the fact that many words are polysemous.For instance, lamb can refer to an animal (as in Thelamb squeezed through the gap) or to a food item (asin Sue had lamb for lunch).
Polysemy is pervasivein human language and is a problem in almost allapplications of NLP, ranging from Machine Trans-lation (as word senses can translate differently) toTextual Entailment (as most lexical entailments aresense-specific).The field has thus devoted a large amount of effortto the representation and modeling of word senses.The arguably most prominent effort is Word SenseDisambiguation, WSD (Navigli, 2009), an in-vitrotask whose goal is to identify which, of a set of pre-defined senses, is the one used in a given context.In work on WSD and other tasks related to pol-ysemy, such as word sense induction, sense alter-nations are treated as word-specific.
As a result, amodel for the meaning of lamb that accounts for therelation between the animal and food senses cannotpredict that the same relation holds between instancesof chicken or salmon in the same type of contexts.A large number of studies in linguistics and cog-nitive science show evidence that there are regulari-ties in the way words vary in their meaning (Apres-jan, 1974; Lakoff and Johnson, 1980; Copestakeand Briscoe, 1995; Pustejovsky, 1995; Gentner etal., 2001; Murphy, 2002), due to general analogicalprocesses such as regular polysemy, metonymy andmetaphor.
Most work in theoretical linguistics hasfocused on regular, systematic, or logical polysemy,which accounts for alternations like ANIMAL-FOOD.Sense alternations also arise from metaphorical useof words, as dark in dark glass-dark mood, and alsofrom metonymy when, for instance, using the nameof a place for a representative (as in Germany signedthe treatise).
Disregarding this evidence is empiri-cally inadequate and leads to the well-known lexicalbottleneck of current word sense models, which haveserious problems in achieving high coverage (Navigli,2009).We believe that empirical computational semanticscould profit from a model of polysemy1 which (a) isapplicable across individual words, and thus capableof capturing general patterns and generalizing to new1Our work is mostly inspired in research on regular polysemy.However, given the fuzzy nature of ?regularity?
in meaningvariation, we extend the focus of our attention to include othertypes of analogical sense construction processes.151words, and (b) is induced in an unsupervised fashionfrom corpus data.
This is a long-term goal with manyunsolved subproblems.The current paper presents two contributions to-wards this goal.
First, since we are working on arelatively unexplored area, we introduce a formalframework that can encompass different approaches(Section 2).
Second, we implement a concrete instan-tiation of this framework, the unsupervised CentroidAttribute Model (Section 3), and evaluate it on a newtask, namely, to detect which of a set of words in-stantiate a given type of polysemy (Sections 4 and 5).We finish with some conclusions and future work(Section 7).2 Formal frameworkIn addition to introducing formal definitions for termscommonly found in the literature, our framework pro-vides novel terminology to deal with regular poly-semy in a general fashion (cf.
Table 1; capital lettersdesignate sets and small letters elements of sets).2For a lemma l like lamb, we want to knowhow well a meta alternation (such as ANIMAL-FOOD) explains a pair of its senses (such as theanimal and food senses of lamb).3 This is for-malized through the function score, which mapsa meta alternation and two senses onto a score.As an example, let lambanm denote the ANIMALsense of lamb, lambfod the FOOD sense, andlambhum the PERSON sense.
Then, an appropri-ate model of meta alternations should predict thatscore(animal,food, lambanm, lambfod) is greaterthan score(animal,food, lambanm, lambhum).Meta alternations are defined as unordered pairsof meta senses, or cross-word senses like ANIMAL.The meta sensesM can be defined a priori or inducedfrom data.
They are equivalence classes of senses towhich they are linked through the function meta.
Asense s instantiates a meta sense m iff meta(s) =m.
Functions inst and sns allow us to define metasenses and lemma-specific senses in terms of actualinstances, or occurrences of words in context.2We re-use inst as a function that returns the set of instancesfor a sense: SL ?
?
(IL) and assume that senses partitionlemmas?
instances: ?l : inst(l) =?s?sns(l) inst(s).3Consistent with the theoretical literature, this paper focuseson two-way polysemy.
See Section 7 for further discussion.L set of lemmasIL set of (lemma-wise) instancesSL set of (lemma-wise) sensesinst : L?
?
(IL) mapping lemma?
instancessns : L?
?
(SL) mapping lemma?
sensesM set of meta sensesmeta: SL ?M mapping senses?meta sensesA ?M ?M set of meta alternations (MAs)A set of MA representationsscore : A?
S2L ?
R scoring function for MAsrepA : A?
A MA representation functioncomp: A?S2L ?
R compatibility functionTable 1: Notation and signatures for our framework.We decompose the score function into two parts:a representation function repA that maps a meta al-ternation into some suitable representation for metaalternations, A, and a compatibility function compthat compares the relation between the senses of aword to the meta alternation?s representation.
Thus,comp ?
repA = score.3 The Centroid Attribute ModelThe Centroid Attribute Model (CAM) is a simpleinstantiation of the framework defined in Section 2,designed with two primary goals in mind.
First, it isa data-driven model.
Second, it does not require anymanual sense disambiguation, a notorious bottleneck.To achieve the first goal, CAM uses a distribu-tional approach.
It represents the relevant entities asco-occurrence vectors that can be acquired from alarge corpus (Turney and Pantel, 2010).
To achievethe second goal, CAM represents meta senses usingmonosemous words only, that is, words whose sensesall correspond to one meta sense.
4 Examples arecattle and robin for the meta sense ANIMAL.
Wedefine the vector for a meta sense as the centroid (av-erage vector) of the monosemous words instantiatingit.
In turn, meta alternations are represented by thecentroids of their meta senses?
vectors.This strategy is not applicable to test lemmas,which instantiate some meta alternation and are bydefinition ambiguous.
To deal with these without410.8% of noun types in the corpus we use are monosemousand 2.3% are disemous, while, on a token level, 23.3% aremonosemous and 20.2% disemous.152vecI : IL ?
Rk instance vector computationC : Rk?m ?
Rk centroid computationvecL : L?
Rk lemma (type) vector computationrepM : M ?
Rk meta sense representationTable 3: Additional notation and signatures for CAMexplicit sense disambiguation, CAM represents lem-mas by their type vectors, i.e., the centroid of theirinstances, and compares their vectors (attributes) tothose of the meta alternation ?
hence the name.CoreLex: A Semantic Inventory.
CAM usesCoreLex (Buitelaar, 1998) as its meta sense inven-tory.
CoreLex is a lexical resource that was designedspecifically for the study of polysemy.
It builds onWordNet (Fellbaum, 1998), whose sense distinctionsare too fine-grained to describe general sense al-ternations.
CoreLex defines a layer of abstractionabove WordNet consisting of 39 basic types, coarse-grained ontological classes (Table 2).
These classesare linked to one or more Wordnet anchor nodes,which define a mapping from WordNet synsets ontobasic types: A synset s maps onto a basic type b if bhas an anchor node that dominates s and there is noother anchor node on the path from b and s.5We adopt the WordNet synsets as S, the set ofsenses, and the CoreLex basic types as our set ofmeta senses M .
The meta function (mapping wordsenses onto meta senses) is given directly by the an-chor mapping defined in the previous paragraph.
Thismeans that the set of meta alternations is given by theset of pairs of basic types.
Although basic types donot perfectly model meta senses, they constitute anapproximation that allows us to model many promi-nent alternations such as ANIMAL-FOOD.Vectors for Meta Senses and Alternations.
Allrepresentations used by CAM are co-occurrence vec-tors in Rk (i.e., A := Rk).
Table 3 lists new conceptsthat CAM introduces to manipulate vector represen-tations.
vecI returns a vector for a lemma instance,vecL a (type) vector for a lemma, and C the centroidof a set of vectors.We leave vecI and C unspecified: we will experi-ment with these functions in Section 4.
CAM does fix5This is necessary because some classes have non-disjointanchor nodes: e.g., ANIMALs are a subset of LIVING BEINGs.the definitions for vecL and repA.
First, vecL definesa lemma?s vector as the centroid of its instances:vecL(l) = C{vecI(i) | i ?
inst(l)} (1)Before defining repA, we specify a function repMthat computes vector representations for meta sensesm.
In CAM, this vector is defined as the centroidof the vectors for all monosemous lemmas whoseWordNet sense maps onto m:repM(m) = C{vecL(l) | meta(sns(l)) = {m}} (2)Now, repA can be defined simply as the centroid ofthe meta senses instantiating a:repA(m1,m2) = C{repM(m1), repM(m2)} (3)Predicting Meta Alternations.
The final compo-nent of CAM is an instantiation of comp (cf.
Table 1),i.e., the degree to which a sense pair (s1, s2) matchesa meta alternation a.
Since CAM does not representthese senses separately, we define comp ascomp(a, s1, s2) = sim(a, vecL(l))so that {s1, s2} = sns(l)(4)The complete model, score, can now be stated as:score(m,m?, s, s?)
= sim(repA(m,m?
), vecL(l))so that {s, s?}
= sns(l) (5)CAM thus assesses how well a meta alternationa = (m,m?)
explains a lemma l by comparing thecentroid of the meta senses m,m?
to l?s centroid.Discussion.
The central feature of CAM is thatit avoids word sense disambiguation, although itstill relies on a predefined sense inventory (Word-Net, through CoreLex).
Our use of monosemouswords to represent meta senses and meta alternationsgoes beyond previous work which uses monosemouswords to disambiguate polysemous words in context(Izquierdo et al, 2009; Navigli and Velardi, 2005).Because of its focus on avoiding disambiguation,CAM simplifies the representation of meta alterna-tions and polysemous words to single centroid vec-tors.
In the future, we plan to induce word senses(Schu?tze, 1998; Pantel and Lin, 2002; Reisinger andMooney, 2010), which will allow for more flexibleand realistic models.153abs ABSTRACTION ent ENTITY loc LOCATION prt PARTact ACT evt EVENT log GEO.
LOCATION psy PSYCHOL.
FEATUREagt AGENT fod FOOD mea MEASURE qud DEFINITE QUANTITYanm ANIMAL frm FORM mic MICROORGANISM qui INDEFINITE QUANTITYart ARTIFACT grb BIOLOG.
GROUP nat NATURAL BODY rel RELATIONatr ATTRIBUTE grp GROUPING phm PHENOMENON spc SPACEcel CELL grs SOCIAL GROUP pho PHYSICAL OBJECT sta STATEchm CHEMICAL hum HUMAN plt PLANT sub SUBSTANCEcom COMMUNICATION lfr LIVING BEING pos POSSESSION tme TIMEcon CONSEQUENCE lme LINEAR MEASURE pro PROCESS pro PROCESSTable 2: CoreLex?s basic types with their corresponding WordNet anchors.
CAM adopts these as meta senses.4 EvaluationWe test CAM on the task of identifying which lem-mas of a given set instantiate a specific meta alterna-tion.
We let the model rank the lemmas through thescore function (cf.
Table (1) and Eq.
(5)) and evaluatethe ranked list using Average Precision.
While analternative would be to rank meta alternations for agiven polysemous lemma, the method chosen herehas the benefit of providing data on the performanceof individual meta senses and meta alternations.4.1 DataAll modeling and data extraction was carried out onthe written part of the British National Corpus (BNC;Burnage and Dunlop (1992)) parsed with the C&Ctools (Clark and Curran, 2007).
6For the evaluation, we focus on disemous words,words which instantiate exactly two meta sensesaccording to WordNet.
For each meta alternation(m,m?
), we evaluate CAM on a set of disemous tar-gets (lemmas that instantiate (m,m?))
and disemousdistractors (lemmas that do not).
We define threetypes of distractors: (1) distractors sharing m withthe targets (but not m?
), (2) distractors sharing m?with the targets (but not m), and (3) distractors shar-ing neither.
In this way, we ensure that CAM cannotobtain good results by merely modeling the similarityof targets to either m or m?, which would rather be acoarse-grained word sense modeling task.To ensure that we have enough data, we evaluateCAM on all meta alternations with at least ten targetsthat occur at least 50 times in the corpus, discardingnouns that have fewer than 3 characters or containnon-alphabetical characters.
The distractors are cho-6The C&C tools were able to reliably parse about 40M words.sen so that they match targets in frequency.
Thisleaves us with 60 meta alternations, shown in Ta-ble 5.
For each meta alternation, we randomly select40 lemmas as experimental items (10 targets and 10distractors of each type) so that a total of 2,400 lem-mas is used in the evaluation.7 Table 4 shows fourtargets and their distractors for the meta alternationANIMAL-FOOD.84.2 Evaluation Measure and BaselinesTo measure success on this task, we use AveragePrecision (AP), an evaluation measure from IR thatreaches its maximum value of 1 when all correctitems are ranked at the top (Manning et al, 2008).It interpolates the precision values of the top-n pre-diction lists for all positions n in the list that con-tain a target.
Let T = ?q1, .
.
.
, qm?
be the list oftargets, and let P = ?p1, .
.
.
, pn?
be the list of pre-dictions as ranked by the model.
Let I(xi) = 1 ifpi ?
T , and zero otherwise.
Then AP (P, T ) =1m?mi=1 I(xi)?ij=1 I(xi)i .
AP measures the qualityof the ranked list for a single meta alternation.
Theoverall quality of a model is given by Mean AveragePrecision (MAP), the mean of the AP values for allmeta alternations.We consider two baselines: (1) A random baselinethat ranks all lemmas in random order.
This baselineis the same for all meta alternations, since the distri-bution is identical.
We estimate it by sampling.
(2)A meta alternation-specific frequency baseline whichorders the lemmas by their corpus frequencies.
This7Dataset available at http://www.nlpado.de/?sebastian/data.shtml.8Note that this experimental design avoids any overlap be-tween the words used to construct sense vectors (one meta sense)and the words used in the evaluation (two meta senses).154Targets Distractors with meta sense anm Distractors with meta sense fod Random distractorscarp amphibian (anm-art) mousse (art-fod) appropriation (act-mea)duckling ape (anm-hum) parsley (fod-plt) scissors (act-art)eel leopard (anm-sub) pickle (fod-sta) showman (agt-hum)hare lizard (anm-hum) pork (fod-mea) upholstery (act-art)Table 4: Sample of experimental items for the meta alternation anm-fod.
(Abbreviations are listed in Table 2.
)baseline uses the intuition that frequent words willtend to exhibit more typical alternations.4.3 Model ParametersThere are four more parameters to set.Definition of vector space.
We instantiate the vecIfunction in three ways.
All three are based ondependency-parsed spaces, following our intuitionthat topical similarity as provided by window-basedspaces is insufficient for this task.
The functions dif-fer in the definition of the space?s dimensions, incor-porating different assumptions about distributionaldifferences among meta alternations.The first option, gram, uses grammatical pathsof lengths 1 to 3 as dimensions and thus character-izes lemmas and meta senses in terms of their gram-matical context (Schulte im Walde, 2006), with atotal of 2,528 paths.
The second option, lex, useswords as dimensions, treating the dependency parseas a co-occurrence filter (Pado?
and Lapata, 2007),and captures topical distinctions.
The third option,gramlex, uses lexicalized dependency paths likeobj?see to mirror more fine-grained semantic proper-ties (Grefenstette, 1994).
Both lex and gramlexuse the 10,000 most frequent items in the corpus.Vector elements.
We use ?raw?
corpus co-occurrence frequencies as well as log-likelihood-transformed counts (Lowe, 2001) as elements of theco-occurrence vectors.Definition of centroid computation.
There arethree centroid computations in CAM: to combineinstances into lemma (type) vectors (function vecLin Eq.
(1)); to combine lemma vectors into metasense vectors (function repM in Eq.
(2)); and to com-bine meta sense vectors into meta alternation vectors(function repA in Eq.
(3)).For vecL, the obvious definition of the centroidfunction is as a micro-average, that is, a simple av-erage over all instances.
For repM and repA, thereis a design choice: The centroid can be computedby micro-averaging as well, which assigns a largerweight to more frequent lemmas (repM) or metasenses (repA).
Alternatively, it can be computedby macro-averaging, that is, by normalizing the in-dividual vectors before averaging.
This gives equalweight to the each lemma or meta sense, respectively.Macro-averaging in repA thus assumes that sensesare equally distributed, which is an oversimplifica-tion, as word senses are known to present skeweddistributions (McCarthy et al, 2004) and vectors forwords with a predominant sense will be similar to thedominant meta sense vector.
Micro-averaging par-tially models sense skewedness under the assumptionthat word frequency correlates with sense frequency.Similarity measure.
As the vector similarity mea-sure in Eq.
(5), we use the standard cosine similar-ity (Lee, 1999).
It ranges between ?1 and 1, with 1denoting maximum similarity.
In the current modelwhere the vectors do not contain negative counts, therange is [0; 1].5 ResultsEffect of Parameters The four parameters of Sec-tion 4.3 (three space types, macro-/micro-averagingfor repM and repA, and log-likelihood transforma-tion) correspond to 24 instantiations of CAM.Figure 1 shows the influence of the four parame-ters.
The only significant difference is tied to the useof lexicalized vector spaces (gramlex / lex arebetter than gram).
The statistical significance of thisdifference was verified by a t-test (p < 0.01).
Thisindicates that meta alternations can be characterizedbetter through fine-grained semantic distinctions thanby syntactic ones.The choice of micro- vs. macro-average does nothave a clear effect, and the large variation observedin Figure 1 suggests that the best setup is dependenton the specific meta sense or meta alternation being155MACRO MICRO0.350.370.39repMMACRO MICRO0.350.370.39repAgram gramlex lex0.350.370.39space type?False True0.350.370.39LL transformationFigure 1: Effect of model parameters on performance.
Adata point is the mean AP (MAP) across all meta alterna-tions for a specific setting.modeled.
Focusing on meta alternations, whether thetwo intervening meta senses should be balanced ornot can be expected to depend on the frequencies ofthe concepts denoted by each meta sense, which varyfor each case.
Indeed, for AGENT-HUMAN, the alter-nation which most benefits from the micro-averagingsetting, the targets are much more similar to the HU-MAN meta sense (which is approximately 8 times asfrequent as AGENT) than to the AGENT meta sense.The latter contains anything that can have an effect onsomething, e.g.
emulsifier, force, valium.
The targetsfor AGENT-HUMAN, in contrast, contain words suchas engineer, manipulator, operative, which alternatebetween an agentive role played by a person and theperson herself.While lacking in clear improvement, log-likelihood transformation tends to reduce variance,consistent with the effect previously found in selec-tional preference modeling (Erk et al, 2010).Overall Performance Although the performanceof the CAM models is still far from perfect, all 24models obtain MAP scores of 0.35 or above, whilethe random baseline is at 0.313, and the overall fre-quency baseline at 0.291.
Thus, all models con-sistently outperform both baselines.
A bootstrapresampling test (Efron and Tibshirani, 1994) con-firmed that the difference to the frequency baselineis significant at p < 0.01 for all 24 models.
Thedifference to the random baseline is significant atp < 0.01 for 23 models and at p < 0.05 for theremaining model.
This shows that the models cap-ture the meta alternations to some extent.
The bestmodel uses macro-averaging for repM and repA ina log-likelihood transformed gramlex space andachieves a MAP of 0.399.Table 5 breaks down the performance of the bestCAM model by meta alternation.
It shows an en-couraging picture: CAM outperforms the frequencybaseline for 49 of the 60 meta alternations and bothbaselines for 44 (73.3%) of all alternations.
The per-formance shows a high degree of variance, however,ranging from 0.22 to 0.71.Analysis by Meta Alternation Coherence Metaalternations vary greatly in their difficulty.
SinceCAM is an attribute similarity-based approach, weexpect it to perform better on the alternations whosemeta senses are ontologically more similar.
We nexttest this hypothesis.Let Dmi = {dij} be the set of distractors forthe targets T = {tj} that share the meta sense mi,and DR = {d3j} the set of random distractors.
Wedefine the coherence ?
of an alternation a of metasenses m1,m2 as the mean (?)
difference betweenthe similarity of each target vector to a and the simi-larity of the corresponding distractors to a, or for-mally ?
(a) = ?
sim(repA(m1,m2), vecL(tj)) ?sim(repA(m1,m2), vecL(dij)), for 1 ?
i ?
3 and1 ?
j ?
10.
That is, ?
measures how much moresimilar, on average, the meta alternation vector is tothe target vectors than to the distractor vectors.
For ameta alternation with a higher ?, the targets shouldbe easier to distinguish from the distractors.Figure 2 plots AP by ?
for all meta alternations.As we expect from the definition of ?, AP is stronglycorrelated with ?.
However, there is a marked Yshape, i.e., a divergence in behavior between high-?
and mid-AP alternations (upper right corner) andmid-?
and high-AP alternations (upper left corner).In the first case, meta alternations perform worsethan expected, and we find that this typically pointsto missing senses, that is, problems in the underlyinglexical resource (WordNet, via CoreLex).
For in-stance, the FOOD-PLANT distractor almond is given156grs-psy 0.709 com-evt 0.501 art-com 0.400 atr-com 0.361 art-frm 0.286pro-sta 0.678 art-grs 0.498 act-pos 0.396 atr-sta 0.361 act-hum 0.281fod-plt 0.645 hum-psy 0.486 phm-sta 0.388 act-phm 0.339 art-fod 0.280psy-sta 0.630 hum-nat 0.456 atr-psy 0.384 anm-art 0.335 grs-hum 0.272hum-prt 0.602 anm-hum 0.448 fod-hum 0.383 art-atr 0.333 act-art 0.267grp-psy 0.574 com-psy 0.443 plt-sub 0.383 act-psy 0.333 art-grp 0.258grs-log 0.573 act-grs 0.441 act-com 0.382 agt-hum 0.319 art-nat 0.248act-evt 0.539 atr-rel 0.440 grp-grs 0.379 art-evt 0.314 act-atr 0.246evt-psy 0.526 art-qui 0.433 art-psy 0.373 atr-evt 0.312 art-hum 0.240act-tme 0.523 act-sta 0.413 art-prt 0.364 art-sta 0.302 art-loc 0.238art-pho 0.520 art-sub 0.412 evt-sta 0.364 act-grp 0.296 art-pos 0.228act-pro 0.513 art-log 0.407 anm-fod 0.361 com-hum 0.292 com-sta 0.219Table 5: Meta alternations and their average precision values for the task.
The random baseline performs at 0.313 whilethe frequency baseline ranges from 0.255 to 0.369 with a mean of 0.291.
Alternations for which the model outperformsthe frequency baseline are in boldface (mean AP: 0.399, standard deviation: 0.119).grs-psy democracy, faculty, humanism, regime,pro-sta bondage, dehydration, erosion,urbanizationpsy-sta anaemia,delight, pathology, sensibilityhum-prt bum, contractor, peter, subordinategrp-psy category, collectivism, socialism, underworldTable 6: Sample targets for meta alternations with highAP and mid-coherence values.a PLANT sense by WordNet, but no FOOD sense.
Inthe case of SOCIAL GROUP-GEOGRAPHICAL LOCA-TION, distractors laboratory and province are miss-ing SOCIAL GROUP senses, which they clearly pos-sess (cf.
The whole laboratory celebrated Christmas).This suggests that our approach can help in WordSense Induction and thesaurus construction.In the second case, meta alternations perform bet-ter than expected: They have a low ?, but a highAP.
These include grs-psy, pro-sta, psy-sta,hum-prt and grp-psy.
These meta alternationsinvolve fairly abstract meta senses such as PSYCHO-LOGICAL FEATURE and STATE.9 Table 6 lists asample of targets for the five meta alternations in-volved.
The targets are clearly similar to each otheron the level of their meta senses.
However, they canoccur in very different semantic contexts.
Thus, hereit is the underlying model (the gramlex space) thatcan explain the lower than average coherence.
It isstriking that CAM can account for abstract words andmeta alternations between these, given that it usesfirst-order co-occurrence information only.9An exception is hum-prt.
It has a low coherence becausemany WordNet lemmas with a PART sense are body parts.0.00 0.05 0.10 0.15 0.20 0.250.20.30.40.50.60.7coherenceAPact?artact?atract?comact?evtact?grpact?grsact?humact?phmact?posact?prosyact?staact?tmeagt?humanm?artanm?fodanm?humart?atart?comart?evtart?fodart?frmart?grpart?grsart?humart?locart?logr natart?phoart?posart?prtart?psyart?quir staart?subatr?comatr?evta r?psyatr?relstacom?evtcom?humcom psycom?staevt?psyev ?stafod humfod?pltgrp?grsgrp?psygrs?humgrs?loggrs?psyhum?nathum?prthum?psyphm?staplt?subpro?stapsy?staFigure 2: Average Precision and Coherence (?)
for eachmeta alternation.
Correlation: r = 0.743 (p < 0.001)6 Related workAs noted in Section 1, there is little work in empiri-cal computational semantics on explicitly modelingsense alternations, although the notions that we haveformalized here affect several tasks across NLP sub-fields.Most work on regular sense alternations has fo-cused on regular polysemy.
A pioneering study isBuitelaar (1998), who accounts for regular polysemythrough the CoreLex resource (cf.
Section 3).
Asimilar effort is carried out by Tomuro (2001), buthe represents regular polysemy at the level of senses.Recently, Utt and Pado?
(2011) explore the differencesbetween between idiosyncratic and regular polysemypatterns building on CoreLex.
Lapata (2000) focuses157on the default meaning arising from word combina-tions, as opposed to the polysemy of single words asin this study.Meta alternations other than regular polysemy,such as metonymy, play a crucial role in Informa-tion Extraction.
For instance, the meta alternationSOCIAL GROUP-GEOGRAPHICAL LOCATION cor-responds to an ambiguity between the LOCATION-ORGANIZATION Named Entity classes which isknown to be a hard problem in Named Entity Recog-nition and Classification (Markert and Nissim, 2009).Metaphorical meta alternations have also receivedattention recently (Turney et al, 2011)On a structural level, the prediction of meta al-ternations shows a clear correspondence to analogyprediction as approached in Turney (2006) (carpen-ter:wood is analogous to mason:stone, but not tophotograph:camera).
The framework defined in Sec-tion 2 conceptualizes our task in a way parallel to thatof analogical reasoning, modeling not ?first-order?semantic similarity, but ?second-order?
semantic re-lations.
However, the two tasks cannot be approachedwith the same methods, as Turney?s model relies oncontexts linking two nouns in corpus sentences (whatdoes A do to B?).
In contrast, we are interested inrelations within words, namely between word senses.We cannot expect two different senses of the samenoun to co-occur in the same sentence, as this is dis-couraged for pragmatic reasons (Gale et al, 1992).A concept analogous to our notion of meta sense(i.e., senses beyond single words) has been used inprevious work on class-based WSD (Yarowsky, 1992;Curran, 2005; Izquierdo et al, 2009), and indeed,the CAM might be used for class-based WSD aswell.
However, our emphasis lies rather on modelingpolysemy across words (meta alternations), some-thing that is absent in WSD, class-based or not.
Theonly exception, to our knowledge, is Ando (2006),who pools the labeled examples for all words from adataset for learning, implicitly exploiting regularitiesin sense alternations.Meta senses also bear a close resemblance to thenotion of semantic class as used in lexical acqui-sition (Hindle, 1990; Merlo and Stevenson, 2001;Schulte im Walde, 2006; Joanis et al, 2008).
How-ever, in most of this research polysemy is ignored.A few exceptions use soft clustering for multiple as-signment of verbs to semantic classes (Pereira et al,1993; Rooth et al, 1999; Korhonen et al, 2003),and Boleda et al (to appear) explicitly model regularpolysemy for adjectives.7 Conclusions and Future WorkWe have argued that modeling regular polysemy andother analogical processes will help improve currentmodels of word meaning in empirical computationalsemantics.
We have presented a formal frameworkto represent and operate with regular sense alterna-tions, as well as a first simple instantiation of theframework.
We have conducted an evaluation of dif-ferent implementations of this model in the new taskof determining whether words match a given sensealternation.
All models significantly outperform thebaselines when considered as a whole, and the bestimplementation outperforms the baselines for 73.3%of the tested alternations.We have two next steps in mind.
The first is tobecome independent of WordNet by unsupervisedinduction of (meta) senses and alternations from thedata.
This will allow for models that, unlike CAM,can go beyond ?disemous?
words.
Other improve-ments on the model and evaluation will be to developmore informed baselines that capture semantic shifts,as well as to test alternate weighting schemes for theco-occurrence vectors (e.g.
PMI) and to use largercorpora than the BNC.The second step is to go beyond the limited in-vitroevaluation we have presented here by integrating al-ternation prediction into larger NLP tasks.
Knowl-edge about alternations can play an important role incounteracting sparseness in many tasks that involvesemantic compatibility, e.g., testing the applicabilityof lexical inference rules (Szpektor et al, 2008).AcknowledgementsThis research is partially funded by the Spanish Min-istry of Science and Innovation (FFI2010-15006,TIN2009-14715-C04-04), the AGAUR (2010 BP-A00070), the German Research Foundation (SFB732), and the EU (PASCAL2; FP7-ICT-216886).
Itis largely inspired on a course by Ann Copestake atU.
Pompeu Fabra (2008).
We thank Marco Baroni,Katrin Erk, and the reviewers of this and four otherconferences for valuable feedback.158ReferencesRie Kubota Ando.
2006.
Applying alternating structureoptimization to word sense disambiguation.
In Proceed-ings of the 10th Conference on Computational NaturalLanguage Learning, pages 77?84, New York City, NY.Iurii Derenikovich Apresjan.
1974.
Regular polysemy.Linguistics, 142:5?32.Gemma Boleda, Sabine Schulte im Walde, and Toni Badia.to appear.
Modeling regular polysemy: A study of thesemantic classification of Catalan adjectives.
Computa-tional Linguistics.Paul Buitelaar.
1998.
CoreLex: An ontology of sys-tematic polysemous classes.
In Proceedings of For-mal Ontologies in Information Systems, pages 221?235,Amsterdam, The Netherlands.Gavin Burnage and Dominic Dunlop.
1992.
Encodingthe British National Corpus.
In Jan Aarts, Pieter deHaan, and Nelleke Oostdijk, editors, English LanguageCorpora: Design, Analysis and Exploitation, Papersfrom the Thirteenth International Conference on En-glish Language Research on Computerized Corpora.Rodopi, Amsterdam.Stephen Clark and James R. Curran.
2007.
Wide-coverage efficient statistical parsing with ccg and log-linear models.
Computational Linguistics, 33(4).Ann Copestake and Ted Briscoe.
1995.
Semi-productivePolysemy and Sense Extension.
Journal of Semantics,12(1):15?67.James Curran.
2005.
Supersense tagging of unknownnouns using semantic similarity.
In Proceedings of the43rd Annual Meeting of the Association for Computa-tional Linguistics (ACL?05), pages 26?33, Ann Arbor,Michigan.Bradley Efron and Robert Tibshirani.
1994.
An Introduc-tion to the Bootstrap.
Monographs on Statistics andApplied Probability 57.
Chapman & Hall.Katrin Erk, Sebastian Pado?, and Ulrike Pado?.
2010.
Aflexible, corpus-driven model of regular and inverseselectional preferences.
Computational Linguistics,36(4):723?763.Christiane Fellbaum, editor.
1998.
WordNet: an elec-tronic lexical database.
MIT, London.William A. Gale, Kenneth W. Church, and DavidYarowsky.
1992.
One sense per discourse.
In Proceed-ings of the 1992 ARPA Human Language TechnologiesWorkshop, pages 233?237, Harriman, NY.Dedre Gentner, Brian F. Bowdle, Phillip Wolff, and Con-suelo Boronat.
2001.
Metaphor is like analogy.
InD.
Gentner, K. J. Holyoak, and B. N. Kokinov, edi-tors, The analogical mind: Perspectives from CognitiveScience, pages 199?253.
MIT Press, Cambridge, MA.Gregory Grefenstette.
1994.
Explorations in AutomaticThesaurus Discovery.
Kluwer Academic Publishers.Donald Hindle.
1990.
Noun classification from predicate-argument structures.
In Proceedings of the 28th Meet-ing of the Association for Computational Linguistics,pages 268?275.Rube?n Izquierdo, Armando Sua?rez, and German Rigau.2009.
An empirical study on class-based word sensedisambiguation.
In Proceedings of the 12th Conferenceof the European Chapter of the ACL (EACL 2009),pages 389?397, Athens, Greece.Eric Joanis, Suzanne Stevenson, and David James.
2008.A general feature space for automatic verb classifica-tion.
Natural Language Engineering, 14(03):337?367.Anna Korhonen, Yuval Krymolowski, and Zvika Marx.2003.
Clustering polysemic subcategorization framedistributions semantically.
In Proceedings of the 41stAnnual Meeting of the Association for ComputationalLinguistics, pages 64?71.George Lakoff and Mark Johnson.
1980.
Metaphors WeLive By.
University of Chicago Press.Mirella Lapata.
2000.
The Acquisition and Modelingof Lexical Knowledge: A Corpus-based Investigationof Systematic Polysemy.
Ph.D. thesis, University ofEdinburgh.Lillian Lee.
1999.
Measures of distributional similarity.In Proceedings of the 37th Annual Meeting on Asso-ciation for Computational Linguistics, pages 25?32,College Park, MA.Will Lowe.
2001.
Towards a theory of semantic space.
InProceedings of the 23rd Annual Meeting of the Cogni-tive Science Society, pages 576?581, Edinburgh, UK.Christopher D. Manning, Prabhakar Raghavan, and Hin-rich Schu?tze.
2008.
Introduction to Information Re-trieval.
Cambridge University Press, Cambridge, UK,1st edition.Katja Markert and Malvina Nissim.
2009.
Data andmodels for metonymy resolution.
Language Resourcesand Evaluation, 43(2):123?138.Diana McCarthy, Rob Koeling, Julie Weeds, and John Car-roll.
2004.
Using automatically acquired predominantsenses for word sense disambiguation.
In Proceedingsof the ACL SENSEVAL-3 workshop, pages 151?154.Paola Merlo and Suzanne Stevenson.
2001.
Automaticverb classification based on statistical distributionsof argument structure.
Computational Linguistics,27(3):373?408.Gregory L. Murphy.
2002.
The Big Book of Concepts.MIT Press, Cambridge, MA.Roberto Navigli and Paola Velardi.
2005.
Structural se-mantic interconnections: a knowledge-based approachto word sense disambiguation.
IEEE Transactions onPattern Analysis and Machine Intelligence, 27(7):1075?1086, July.159Roberto Navigli.
2009.
Word sense disambiguation:A survey.
ACM Computing Surveys, 41:10:1?10:69,February.Sebastian Pado?
and Mirella Lapata.
2007.
Dependency-based construction of semantic space models.
Compu-tational Linguistics, 33(2):161?199.Patrick Pantel and Dekang Lin.
2002.
Discovering wordsenses from text.
In Proceedings of ACM SIGKDDConference on Knowledge Discovery and Data Mining2002, pages 613?619, Edmonton.Fernando C. N. Pereira, Naftali Tishby, and Lillian Lee.1993.
Distributional clustering of English words.
InProceedings of the 31st Meeting of the Association forComputational Linguistics, pages 183?190, Columbus,OH.James Pustejovsky.
1995.
The Generative Lexicon.
MITPress, Cambridge, MA.Joseph Reisinger and Raymond J. Mooney.
2010.
Multi-prototype vector-space models of word meaning.
InProceedings of the 11th Annual Conference of the NorthAmerican Chapter of the Association for ComputationalLinguistics (NAACL-2010), pages 109?117.Mats Rooth, Stefan Riezler, Detlef Prescher, Glenn Car-roll, and Franz Beil.
1999.
Inducing a semanticallyannotated lexicon via EM-based clustering.
In Proceed-ings of the 37th Annual Meeting of the Association forComputational Linguistics, College Park, MD.Sabine Schulte im Walde.
2006.
Experiments on theautomatic induction of German semantic verb classes.Computational Linguistics, 32(2):159?194.Hinrich Schu?tze.
1998.
Automatic word sense discrimi-nation.
Computational Linguistics, 24(1):97?123.Idan Szpektor, Ido Dagan, Roy Bar-Haim, and Jacob Gold-berger.
2008.
Contextual preferences.
In Proceed-ings of the 46th Annual Meeting of the Association forComputational Linguistics, pages 683?691, Columbus,Ohio.Noriko Tomuro.
2001.
Tree-cut and a lexicon based onsystematic polysemy.
In Proceedings of the secondmeeting of the North American Chapter of the Asso-ciation for Computational Linguistics on Languagetechnologies, NAACL ?01, pages 1?8, Stroudsburg, PA,USA.
Association for Computational Linguistics.Peter D. Turney and Patrick Pantel.
2010.
From frequencyto meaning: Vector space models of semantics.
Journalof Artificial Intelligence Research, 37:141?188.Peter Turney, Yair Neuman, Dan Assaf, and Yohai Cohen.2011.
Literal and metaphorical sense identificationthrough concrete and abstract context.
In Proceedingsof the Conference on Empirical Methods in NaturalLanguage Processing, pages 680?690, Edinburgh, Scot-land, UK.Peter D. Turney.
2006.
Similarity of semantic relations.Computational Linguistics, 32:379?416.Jason Utt and Sebastian Pado?.
2011.
Ontology-baseddistinction between polysemy and homonymy.
In Pro-ceedings of the 9th International Conference on Com-putational Semantics, Oxford, UK.David Yarowsky.
1992.
Word-sense disambiguation usingstatistical models of Roget?s categories trained on largecorpora.
In Proceedings of the 14th conference onComputational linguistics - Volume 2, COLING ?92,pages 454?460, Stroudsburg, PA, USA.
Association forComputational Linguistics.160
