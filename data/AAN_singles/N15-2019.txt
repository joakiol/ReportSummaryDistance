Proceedings of NAACL-HLT 2015 Student Research Workshop (SRW), pages 140?146,Denver, Colorado, June 1, 2015.c?2015 Association for Computational LinguisticsSemantics-based Graph Approach to Complex Question-AnsweringTomasz JurczykMathematics and Computer ScienceEmory UniversityAtlanta, GA 30322, USAtomasz.jurczyk@emory.eduJinho D. ChoiMathematics and Computer ScienceEmory UniversityAtlanta, GA 30322, USAjinho.choi@emory.eduAbstractThis paper suggests an architectural approachof representing knowledge graph for complexquestion-answering.
There are four kinds ofentity relations added to our knowledge graph:syntactic dependencies, semantic role labels,named entities, and coreference links, whichcan be effectively applied to answer complexquestions.
As a proof of concept, we demon-strate how our knowledge graph can be usedto solve complex questions such as arithmetics.Our experiment shows a promising result onsolving arithmetic questions, achieving the 3-folds cross-validation score of 71.75%.1 IntroductionQuestion-answering has lately gained lots of interestfrom both academic and industrial research.
Servicessuch as Yahoo!
Answers1or Quora2provide plat-forms for their users to ask questions to one another;however, answer accuracy or response rate of theseservices strongly depends on the users?
willingnessof sharing their knowledge, which is not always con-sistent.
This kind of inconsistency has led many re-searchers to focus on developing question-answeringsystems that retrieve, analyze, and answer questionswithout much human engagement.Although the task of question-answering has beenbeen well-explored, several challenges still remain.One of such challenges concerns about architecturalaspects of meaning representation.
Thanks to yearsof research on statistical parsing, several tools are1https://answers.yahoo.com2https://www.quora.comalready available that provide rich syntactic and se-mantic structures from texts.
Output of these tools,however, often needs to be post-processed into morecomplicated structures, such as graphs of knowledge,in order to retrieve answers for complex questions.These graphs consist of relations between entitiesfound not only within a sentence, but also acrosssentences.
Vertices and edges in these graphs repre-sent linguistic units (e.g., words, phrases) and theirsyntactic or semantic relations, respectively.Robustness of handling several types of questionsis one of the key aspects about a question-answeringsystem; yet most of previous work had focused onanswering simple factoid questions (Yao et al, 2013;Yih et al, 2013).
Recently, researchers started fo-cusing on solving complex questions involving arith-metics or biological processes (Hosseini et al, 2014;Berant et al, 2014).
A complex question can be de-scribed as a question requiring the collection and syn-thesis of information from multiple sentences (Chaliand Joty, 2008).
The more complex the questionsbecome, the harder it is to build a structural modelthat is general enough to capture information for alldifferent types of questions.This paper suggests an architectural approach ofrepresenting entity relations as well as its applicationto complex question-answering.
First, we presenta systematic way of building a graph by mergingfour kinds of information: syntactic dependencies,semantic role labels, named entities, and coreferencelinks, generated by existing tools (Section 3).
Wethen demonstrate, how our graph can be coupled withstatistical learning to solve complex questions such asarithmetic, which requires understanding of the entire140context (Section 4).
Our experiments show that it ispossible to retrieve document-level entity relationsthrough our graph, providing enough information tohandle such complex questions (Section 5).2 Related WorkPunyakanok et al (2004) presented a system usingedit distance between question and potential answerpairs, measured by the number of required trans-formations of their dependency trees.
Heilman andSmith (2010) presented a more sophisticated systemfinding the most efficient tree transformation using agreedy search.
Cui et al (2005) proposed a systemutilizing fuzzy relation matching guided by statisti-cal models.
Yao et al (2013) described an approachtaking both an edit distance and sequence tagging forselecting finer-grained answers within answer candi-dates.
All the work above leverages dependency treematching similar to ours; however, our approach per-forms matching through semantic relations as wellas coreference links, and also is designed for han-dling complex questions whereas the others mainlyfocused on factoid questions.Kushman et al (2014) described an approach forpredicting sentence-to-equation alignments for solv-ing arithmetic questions.
Hosseini et al (2014) pre-sented a system predicting verb categories, and con-structing equations from the context using these cat-egories.
Berant et al (2014) proposed an approachthat extracted structures from biological processes,and mapped each question to a query form.
Ourwork is related to the first two work; however, it isdistinguished in a way that our constructed graph isnot designed to handle just arithmetic questions, butcomplex questions in general.Our work is also related to research of aligning textinto a set of entities and instances describing statesof the world.
Snyder and Barzilay (2007) presentedan approach for solving text-to-database alignmentas a structured multi-label classification.
Vogel andJurafsky (2010) presented a learning system that fol-lowed navigational paths based on natural languageby utilizing apprenticeship from directions on themap paired with human language.
Chambers and Ju-rafsky (2009) presented an unsupervised learning sys-tem for narrative schemas based on coreferent argu-ments in chains of verbs.
Pourdamghani et al (2014)and Pan et al (2015) presented Abstract MeaningRepresentation (AMR) consisting of multi-layeredrelations for English sentences.
Our semantics-basedgraph shares a similar idea with AMR; however, ourgraph is constructed from existing structures such asdependency trees and semantic roles, whereas AMRrequires its won annotation, which could be manualintensive work for building statical parsing models.3 Semantics-based Knowledge Approach3.1 MotivationOur motivation arises from both the complexity andthe variety of questions and their relevant contexts.The complexity concerns with exploiting syntacticdependencies, semantic role labels, named entities,and coreference links all together for finding the bestanswers.
For arithmetic questions, such complex-ity comes from the flow of entity relations acrosssentences and semantic polarities of verb predicates,which are required to transform the contexts in natu-ral language into mathematical equations.The variety concerns with robustly handling var-ious types of questions.
It is relatively easier to de-velop an architecture designated to handle just onetype of questions (e.g., a system to extract answersfor factoid questions) than many different types ofquestions (e.g., opinions, recommendations, com-mentaries).
In this section, we present a semantic-based knowledge approach (constructed graph) thatnot only conveys relations from different layers orlinguistic theories, but also is effective for findinganswers for various types of questions.3.2 ComponentsGiven a document, our system first parses each sen-tences into a dependency tree, then finds predicate-argument structures on top of the dependency tree.Once sentences are parsed, coreference links arefound for nodes across all trees.
Finally, each depen-dency node gets turned into an instance, which can belinked to other related instances.
Multiple instancescan be grouped together as an entity if they are coref-erent.
Our graph is semantically driven because se-mantic predicate-argument relations take precedenceover syntactic dependencies when both exist.141HeblackSUVcarThe carcarDocumentarg:A0newbought attr:qualityattr:quantityattr:temporalEntity 1arg:A1attr:qualityarg:A0arg:A1attr:identitysold oldyesterdayEntity 2aattr:qualityJohn hisattr:possessiveFigure 1: Example of our semantic-based graph given three sentences:John bough a new car, The car was black SUV, and He sold his old car yesterday.DocumentA document contains a graph consisting of a set of en-tities, instances, and relations between the instances(Figure 1).
A document can be small as a microblogor big as the entire Wikipedia articles.EntityAn entity can be described as a set of instances refer-ring to the same object mostly found through corefer-ence resolution.
In Figure 1, although John, He, andhis are recognized as individual instances, they aregrouped into one entity because they all refer to John.Maintaining these relations is crucial for answeringcomplex questions.InstanceAn instance is the atomic-level object in our graphthat usually represents a word-token, but can alsorepresent compound words (e.g., New York), multi-word expressions, etc.
The instance is linked to otherinstances as a predicate, an argument, or an attribute.Predicate & ArgumentAn instance is a predicate of another instance if itforms any argument structure (Palmer et al, 2005).Currently, our graph takes non-auxiliary verbs anda few eventive nouns as predicates provided by asemantic role labeler.
An instance is an argumentof another if it is required to complete the meaningof the other instance.
In Figure 1, John and car arearguments of bought because they are necessary togive an understanding of bought.
We plan to improvethese relations through semantic parsing in the future.The predicate and argument relations representboth semantic and syntactic relations between in-stances in the document.
Semantic role labels in(Palmer et al, 2005) and dependency labels in (Choiand Palmer, 2012) are used to represent semantic andsyntactic relations in our graph.
Our experimentsshow that these relations play a crucial role in an-swering arithmetic questions (Section 5).AttributeAn instance is an attribute of another if it is not anargument but gives extra information about the otherinstance.
While an argument completes the meaningof its predicate, an attribute augments the meaningwith specific information.
In Figure 1, new is notan argument but an attribute of car because this in-formation is not required for understanding car, butprovides finer-grained information about the car.Attributes can be shared among instances withinthe same entity.
In Figure 1, the attributes new andblack are shared between instances car and the car.This is particularly useful for questions requiring in-formation scattered across sentences.
Table 1 showsthe types of attributes that we have specified so far.142This list will be continuously updated as we add morequestion types to our system.Type DescriptionLocative Geographical or relative location in-formation (e.g., New York, near myhouse).Temporal Absolute or relative temporal in-formation (e.g., tomorrow noon, 2years ago).Possessive Possessor of this instance (e.g., his,of Mary).Quantity Absolute or relative quantity infor-mation (e.g., two books, few books).Quality Every other kind of attributes.Table 1: List of attributes used in our graph.3.3 Graph constructionAlgorithm 1 shows a pseudo-code for constructingour graph given a dependency tree, consisting of syn-tactic and semantic relations, and coreference links.Input: D: a dependency tree,C: a set of coreference links.Output: G: Graph.foreach node N in D doif N .skip() thencontinue;else if N .isArgument() thenP ?
N .getPredicate();L?
N .getArgumentLabel();G.addArgument(P , N , L);else if N .isAttribute() thenA?
N .getAttributeHead();L?
N .getAttributeType();G.addAttribute(A, N , L);elseH ?
N .getSyntacticHead();L?
N .getSyntacticLabel();G.addArgument(H , N , L);endif C.hasEntityFor(N ) thenE ?
C.getEntityFor(N )G.addToEntity(E, N );endAlgorithm 1: Graph constructing algorithm.Every node in the dependency tree has exactly onesyntactic head and can be a semantic argument ofzero to many predicates.
For each node, it first checksif this node should be added to the graph (i.g., aux-iliary verbs are not added).
If it should, it checksit is a semantic argument of some predicate.
If not,it checks if it is an attribute of some instance.
Bydefault, it becomes an argument of its syntactic head.Finally, it gets added to an entity if it is coreferentto some other instance.
Moreover, our graph is alsodesigned to support weights of vertices and edges.Now, we assign a value of 1 as a weight for everyelement, but we plan to extend our work by determin-ing the importance of different weights for specificsemantic relations.
We believe that an intelligentweighting system will improve the overall accuracyof the system by enhancing the matching process.4 Case Study4.1 Arithmetic questionsThis section demonstrates our approach to the appli-cation of complex question-answering, targeted onarithmetic questions.
The purpose of this section isto show a proof of concept that our graph can beeffectively applied to answer such questions.
Forour experiments, we take a set of arithmetic ques-tions used for elementary and middle school students.These questions consist of simple arithmetic opera-tions such as addition and subtraction.
Table 2 showsa sample of these questions.The main challenge of this task is mostly relatedto the contiguous representation of state changes.The question at the end concerns about either thestart state, the transitions, or the end state of a spe-cific theme (e.g., pizza, kitten).
Therefore, simplis-tic string matching approaches, which would haveworked well on factoid questions, would not performwell on this type of questions.
Another challengeis found by coreference mentions in these questions.Arithmetic questions generally consist of multiplesentences such that coreference resolution plays acrucial role for getting high accuracy.
These issuesare further discussed in Section 5.4.4.2 Verb polarity sequence classificationWe turn the task of arithmetic question-answeringinto a sequence classification of verb polarities.
We143Knowledge GraphVerb filteringP1 P2 P4v2v1x = P1*I1 + P2*I2 + ?
+ Pn*Invn?f0 fm?
f0 fm?
f0 fm??
(a) Flow of execution in our system for solving arithmeticquestions.
First, the verb filtering process is applied toselect verbs in all sentences (Vi), which share the samesemantic argument with the question.
Given the selectedverbs, their features (fi) are extracted and the polarities (Pi)are predicted by a statistical model.
Finally, the equation Xis formed, where polarities are multiplied by the quantitiesof the arguments.31 24+ x=Sara has 31 red and 15 green balloons.Sandy has 24 red balloons.How many red balloons do they havein total?+ has31 redballons0 has15 greenballons+ has24 redballons?
hasredballons(b) Flow of execution for the example document.
First,verbs are filtered and selected for the polarity selection.Next, all necessary information (numericals, themes etc.)
iscollected and organized into states.
Finally, based on theverbs polarity, equation is being formed.Figure 2: Flow of execution in general (a) and for an example document (b).believe the verbs need to be classified in sequencebecause the same verb can convey different polaritiesin different contexts.
Three types of verb polaritiesare used: +, -, and 0.
Given the list of sentencesin each question and the equation associated withit (Table 2), we map each verb with its polarity bycomparing their quantities.
?+?
and ?-?
are assignedto verbs whose arguments show a plus sign or a minussign in the equation, respectively.
?0?
is assigned toverbs whose arguments do not appear in the equation.This information is used to build a statistical model,which is used for decoding.Arithmetic questions often contain verbs whosearguments are not relevant to the final question.
Forinstance, in ?Jason has 43 blue and 16 red marbles.Tom has 24 blue marbles.
How many blue marblesdo they have in all?
?, ?16 red marbles?
is more like anoise to answer this question.
Our approach classifiessuch verbs as 0 so that they do not participate intothe final equation.
Once the equation is form, it istrivial to solve the problem using simple algebra.Our approach is distinguished from some of theprevious work where each verb is categorized intomultiple classes (Hosseini et al, 2014) in a sense thatour verb classes are automatically derived from theequations (no extra annotation is needed).
Further-more, our approach can be extended to more compli-cated operations such as multiplication and divisionas long as the correct equations are provided.
Thedataset used in Kushman et al (2014) contains thistype of questions and we plan to apply our approachon this dataset as the future work.Question EquationA restaurant served 9 pizzas x = 9 + 6during lunch and 6 during dinnertoday.
How many pizzas wereserved today?Tim?s cat had kittens.
He gave 3 x = 3 + 6 + 9to Jessica and 6 to Sara.
He nowhas 9 kittens.
How many kittensdid he have to start with?Table 2: Sample of arithmetic questions.5 Experiments5.1 DataFor our experiments, we use the arithmetic datasetprovided by the Allen Institute.3The dataset con-sists of 395 arithmetic questions together with their3allenai.org/content/data/arithmeticquestions.pdf144equations and answers.
We parsed all data usingthe dependency parser, the semantic role labeler, thenamed entity tagger, and the coreference resolution inClearNLP (Choi and McCallum, 2013; Choi, 2012).4We then split the dataset into 3-folds for cross valida-tion in a way that the polarity distributions are similaracross different sets (Table 3).5.2 FeaturesThe following features are used for our experiments:?
Semantic role labels; especially numbered argu-ments as in PropBank (Palmer et al, 2005).?
Sequence of verbs and arguments whose seman-tic roles are recognized as ?themes?.?
Frequency of verbs and theme arguments in thecurrent context.?
Similarity between verbs and theme argumentsacross sentences.?
Distance of the verb to the final question.Given our graph, it was trivial to extract all features.5.3 Machine learningTo build statistical models, we use a stochastic adap-tive subgradient algorithm called ADAGRAD thatuses per-coordinate learning rates to exploit rarelyseen features while remaining scalable (Duchi et al,2011).
This is suitable for NLP tasks where rarelyseen features often play an important role and train-ing data consists of a large number of instances withhigh dimensional features.
We use the implementa-tion of ADAGRAD in ClearNLP using the hinge-loss,and take their default hyper-parameters (learning rate:a = 0.01, termination criterion: r = 0.1).5.4 EvaluationTable 3 shows the distributions of each fold and theaccuracy of our system in answering arithmetic ques-tions.
Our cross-validation score is 71.75%, whichis promising given how complex these questions are.Hosseini et al (2014) were able to achieve 77.7% ac-curacy on the same dataset, which is higher than ourresult.
However, our main goal for these experimentsremains as to prove that our graph can be utilized toanswer complex questions.4http://www.clearnlp.comWe also analyzed errors found in our experiment.
Themajority of errors were caused by errors from depen-dency parsing, semantic role labeling, or coreferenceresolution.
For instance, verbs are not recognizedcorrectly in some dependency trees, which becomesa major factor of decreasing accuracy.
Also, seman-tic role labels sometimes were incorrectly assigned,which extremely influenced the accuracy of our sys-tem.
As mentioned earlier, coreference resolutionremains as one of the main challenges in handlingcomplex questions.
We will explore ways of im-proving these NLP tools, hoping to achieve higheraccuracy for answering complex questions.1st fold 2nd fold 3rd fold# of questions 118 118 118# of verbs 418 423 420# of + verbs 326 330 328# of - verbs 51 51 51# of 0 verbs 41 42 41Accuracy 67.80 76.27 71.19Table 3: Distributions and accuracies of all folds.6 Conclusion and future workThis paper presents semantics-based knowledge ap-proach for answering different types of complexquestions.
As a proof of concept, we demonstratethe application of our graph for arithmetic question-answering.
By using the grounded knowledge in ourgraph, our system was able to extract appropriatefeatures and build a statistical model for recogniz-ing verb polarities that effectively solved arithmeticquestions.
Our system shows a promising result foranswering arithmetic questions.
Although we viewthe problem of solving arithmetic questions as a sig-nificant step towards complex question-answering,numerous challenges still remain, not only in thesub-domain of arithmetic questions, but also in othertypes of complex questions.In the future, we plan to extend our work by explor-ing new features for the statistical model.
Also, weplan to make improvement in dependency parsing,semantic role labeling, and coreference resolutionthrough error analysis of our question-answering sys-tem.
Finally, we will try to apply our knowledgeapproach to other types of complex questions.145ReferencesJonathan Berant, Vivek Srikumar, Pei-Chun Chen, AbbyVander Linden, Brittany Harding, Brad Huang, PeterClark, and Christopher D. Manning.
2014.
Model-ing Biological Processes for Reading Comprehension.In Proceedings of the 2014 Conference on EmpiricalMethods in Natural Language Processing, EMNLP?14,pages 1499?1510, Doha, Qatar, October.
Associationfor Computational Linguistics.Yllias Chali and Shafiq Joty.
2008.
Selecting Sentencesfor Answering Complex Questions.
In Proceedings ofthe 2008 Conference on Empirical Methods in Natu-ral Language Processing, EMNLP?08, pages 304?313,Honolulu, Hawaii, October.Nathanael Chambers and Dan Jurafsky.
2009.
Unsuper-vised Learning of Narrative Schemas and their Partic-ipants.
In Proceedings of the Joint Conference of the47th Annual Meeting of the ACL and the 4th Interna-tional Joint Conference on Natural Language Process-ing of the AFNLP, ACL?09, pages 602?610, Suntec,Singapore, August.Jinho D. Choi and Andrew McCallum.
2013.
Transition-based Dependency Parsing with Selectional Branching.In Proceedings of the 51st Annual Meeting of the Asso-ciation for Computational Linguistics (Volume 1: LongPapers), ACL?13, pages 1052?1062, Sofia, Bulgaria,August.Jinho D. Choi and Martha Palmer.
2012.
Guidelines forthe Clear Style Constituent to Dependency Conversion.Technical report, Technical Report 01-12, University ofColorado at Boulder.Jinho D. Choi.
2012.
Optimization of Natural LanguageProcessing Components for Robustness and Scalability.Ph.D.
thesis, University of Colorado Boulder.Hang Cui, Renxu Sun, Keya Li, Min-Yen Kan, and Tat-Seng Chua.
2005.
Question Answering Passage Re-trieval Using Dependency Relations.
In Proceedings ofthe 28th annual international ACM SIGIR conferenceon Research and development in information retrieval,pages 400?407.
ACM.John Duchi, Elad Hazan, and Yoram Singer.
2011.
Adap-tive Subgradient Methods for Online Learning andStochastic Optimization.
The Journal of MachineLearning Research, 12(39):2121?2159.Michael Heilman and Noah A Smith.
2010.
Tree EditModels for Recognizing Textual Entailments, Para-phrases, and Answers to Questions.
In Human Lan-guage Technologies: The 2010 Annual Conference ofthe North American Chapter of the Association forComputational Linguistics, NAACL?10, pages 1011?1019.Mohammad Javad Hosseini, Hannaneh Hajishirzi, OrenEtzioni, and Nate Kushman.
2014.
Learning to SolveArithmetic Word Problems with Verb Categorization.In Proceedings of the 2014 Conference on EmpiricalMethods in Natural Language Processing, EMNLP?14,pages 523?533, Doha, Qatar, October.Nate Kushman, Yoav Artzi, Luke Zettlemoyer, and ReginaBarzilay.
2014.
Learning to Automatically Solve Alge-bra Word Problems.
In Proceedings of the 52nd AnnualMeeting of the Association for Computational Linguis-tics, ACL?14, pages 271?281, Baltimore, Maryland,June.Martha Palmer, Daniel Gildea, and Paul Kingsbury.
2005.The Proposition Bank: An Annotated Corpus of Seman-tic Roles.
Computational linguistics, 31(1):71?106.Xiaoman Pan, Taylor Cassidy, Ulf Hermjakob, Heng Ji,and Kevin Knight.
2015.
Unsupervised Entity Linkingwith Abstract Meaning Representation.
In Proceedingsof the 2015 Conference of the North American Chap-ter of the Association for Computational Linguistics -Human Language Technologies, NAACL?15.Nima Pourdamghani, Yang Gao, Ulf Hermjakob, andKevin Knight.
2014.
Aligning English Strings with Ab-stract Meaning Representation Graphs.
In Proceedingsof the 2014 Conference on Empirical Methods in Natu-ral Language Processing, EMNLP?14, pages 425?429,Doha, Qatar, October.Vasin Punyakanok, Dan Roth, and Wen-tau Yih.
2004.Mapping Dependencies Trees: An Application to Ques-tion Answering.
In Proceedings of AI&Math, pages1?10.Benjamin Snyder and Regina Barzilay.
2007.
Database-Text Alignment via Structured Multilabel Classification.In IJCAI, pages 1713?1718.Adam Vogel and Daniel Jurafsky.
2010.
Learning toFollow Navigational Directions.
In Proceedings of the48th Annual Meeting of the Association for Computa-tional Linguistics, ACL?10, pages 806?814, Uppsala,Sweden, July.Xuchen Yao, Benjamin Van Durme, Chris Callison-Burch,and Peter Clark.
2013.
Answer Extraction as SequenceTagging with Tree Edit Distance.
In Proceedings ofthe 2013 Conference of the North American Chapter ofthe Association for Computational Linguistics: HumanLanguage Technologies, NAACL?13, pages 858?867,Atlanta, Georgia, June.Wen-tau Yih, Ming-Wei Chang, Christopher Meek, andAndrzej Pastusiak.
2013.
Question Answering Us-ing Enhanced Lexical Semantic Models.
In Proceed-ings of the 51st Annual Meeting of the Association forComputational Linguistics (Volume 1: Long Papers),EMNLP?13, pages 1744?1753, Sofia, Bulgaria, Au-gust.146
