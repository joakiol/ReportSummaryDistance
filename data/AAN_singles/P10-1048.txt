Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 465?474,Uppsala, Sweden, 11-16 July 2010. c?2010 Association for Computational LinguisticsHindi-to-Urdu Machine Translation Through TransliterationNadir Durrani Hassan Sajjad Alexander Fraser Helmut SchmidInstitute for Natural Language ProcessingUniversity of Stuttgart{durrani,sajjad,fraser,schmid}@ims.uni-stuttgart.deAbstractWe present a novel approach to integratetransliteration into Hindi-to-Urdu statisti-cal machine translation.
We propose twoprobabilistic models, based on conditionaland joint probability formulations, that arenovel solutions to the problem.
Our mod-els consider both transliteration and trans-lation when translating a particular Hindiword given the context whereas in pre-vious work transliteration is only usedfor translating OOV (out-of-vocabulary)words.
We use transliteration as a toolfor disambiguation of Hindi homonymswhich can be both translated or translit-erated or transliterated differently basedon different contexts.
We obtain finalBLEU scores of 19.35 (conditional prob-ability model) and 19.00 (joint probabilitymodel) as compared to 14.30 for a base-line phrase-based system and 16.25 for asystem which transliterates OOV words inthe baseline system.
This indicates thattransliteration is useful for more than onlytranslating OOV words for language pairslike Hindi-Urdu.1 IntroductionHindi is an official language of India and is writ-ten in Devanagari script.
Urdu is the national lan-guage of Pakistan, and also one of the state lan-guages in India, and is written in Perso-Arabicscript.
Hindi inherits its vocabulary from Sanskritwhile Urdu descends from several languages in-cluding Arabic, Farsi (Persian), Turkish and San-skrit.
Hindi and Urdu share grammatical structureand a large proportion of vocabulary that they bothinherited from Sanskrit.
Most of the verbs andclosed-class words (pronouns, auxiliaries, case-markers, etc) are the same.
Because both lan-guages have lived together for centuries, someUrdu words which originally came from Arabicand Farsi have also mixed into Hindi and are nowpart of the Hindi vocabulary.
The spoken form ofthe two languages is very similar.The extent of overlap between Hindi and Urduvocabulary depends upon the domain of the text.Text coming from the literary domain like novelsor history tend to have more Sanskrit (for Hindi)and Persian/Arabic (for Urdu) vocabulary.
How-ever, news wire that contains text related to me-dia, sports and politics, etc., is more likely to havecommon vocabulary.In an initial study on a small news corpus of5000 words, randomly selected from BBC1 News,we found that approximately 62% of the Hinditypes are also part of Urdu vocabulary and thuscan be transliterated while only 38% have to betranslated.
This provides a strong motivation toimplement an end-to-end translation system whichstrongly relies on high quality transliteration fromHindi to Urdu.Hindi and Urdu have similar sound systems buttransliteration from Hindi to Urdu is still very hardbecause some phonemes in Hindi have several or-thographic equivalents in Urdu.
For example the?z?
sound2 can only be written as whenever itoccurs in a Hindi word but can be written as ,, and in an Urdu word.
Transliterationbecomes non-trivial in cases where the multipleorthographic equivalents for a Hindi word are allvalid Urdu words.
Context is required to resolveambiguity in such cases.
Our transliterator (de-scribed in sections 3.1.2 and 4.1.3) gives an accu-racy of 81.6% and a 25-best accuracy of 92.3%.Transliteration has been previously used only asa back-off measure to translate NEs (Name Enti-ties) and OOV words in a pre- or post-processingstep.
The problem we are solving is more difficultthan techniques aimed at handling OOV words,1http://www.bbc.co.uk/hindi/index.shtml2All sounds are represented using SAMPA notation.465Hindi Urdu SAMPA Gloss/ Am Mango/Ordinary/ d ZAli Fake/Net/ Ser Lion/VerseTable 1: Hindi Words That Can Be TransliteratedDifferently in Different ContextsHindi Urdu SAMPA Gloss/ simA Border/Seema/ Amb@r Sky/Ambar/ vId Ze Victory/VijayTable 2: Hindi Words That Can Be Translated orTransliterated in Different Contextswhich focus primarily on name transliteration, be-cause we need different transliterations in differ-ent contexts; in their case context is irrelevant.
Forexample: consider the problem of transliteratingthe English word ?read?
to a phoneme represen-tation in the context ?I will read?
versus the con-text ?I have read?.
An example of this for Hindito Urdu transliteration: the two Urdu words(face/condition) and (chapter of the Koran)are both written as (sur@t d) in Hindi.
Thetwo are pronounced identically in Urdu but writ-ten differently.
In such cases we hope to choosethe correct transliteration by using context.
Someother examples are shown in Table 1.Sometimes there is also an ambiguity ofwhether to translate or transliterate a particularword.
The Hindi word , for example, willbe translated to (peace, s@kun) when it is acommon noun but transliterated to (Shanti,SAnt di) when it is a proper name.
We try tomodel whether to translate or transliterate in agiven situation.
Some other examples are shownin Table 2.The remainder of this paper is organized as fol-lows.
Section 2 provides a review of previouswork.
Section 3 introduces two probabilistic mod-els for integrating translations and transliterationsinto a translation model which are based on condi-tional and joint probability distributions.
Section 4discusses the training data, parameter optimizationand the initial set of experiments that compare ourtwo models with a baseline Hindi-Urdu phrase-based system and with two transliteration-aidedphrase-based systems in terms of BLEU scores(Papineni et al, 2001).
Section 5 performs an er-ror analysis showing interesting weaknesses in theinitial formulations.
We remedy the problems byadding some heuristics and modifications to ourmodels which show improvements in the results asdiscussed in section 6.
Section 7 gives two exam-ples illustrating how our model decides whetherto translate or transliterate and how it is able tochoose among different valid transliterations giventhe context.
Section 8 concludes the paper.2 Previous WorkThere has been a significant amount of work ontransliteration.
We can break down previous workinto three groups.
The first group is generictransliteration work, which is evaluated outside ofthe context of translation.
This work uses eithergrapheme or phoneme based models to translit-erate words lists (Knight and Graehl, 1998; Liet al, 2004; Ekbal et al, 2006; Malik et al,2008).
The work by Malik et al addresses Hindi toUrdu transliteration using hand-crafted rules anda phonemic representation; it ignores translationcontext.A second group deals with out-of-vocabularywords for SMT systems built on large parallel cor-pora, and therefore focuses on name translitera-tion, which is largely independent of context.
Al-Onaizan and Knight (2002) transliterate ArabicNEs into English and score them against their re-spective translations using a modified IBM Model1.
The options are further re-ranked based on dif-ferent measures such as web counts and using co-reference to resolve ambiguity.
These re-rankingmethodologies can not be performed in SMT atthe decoding time.
An efficient way to computeand re-rank the transliterations of NEs and inte-grate them on the fly might be possible.
However,this is not practical in our case as our model con-siders transliterations of all input words and notjust NEs.
A log-linear block transliteration modelis applied to OOV NEs in Arabic to English SMTby Zhao et al (2007).
This work is also translit-erating only NEs and not doing any disambigua-tion.
The best method proposed by Kashani etal.
(2007) integrates translations provided by ex-ternal sources such as transliteration or rule-basetranslation of numbers and dates, for an arbitrarynumber of entries within the input text.
Our workis different from Kashani et al (2007) in that ourmodel compares transliterations with translations466on the fly whereas transliterations in Kashani et aldo not compete with internal phrase tables.
Theyonly compete amongst themselves during a sec-ond pass of decoding.
Hermjakob et al (2008) usea tagger to identify good candidates for translit-eration (which are mostly NEs) in input text andadd transliterations to the SMT phrase table dy-namically such that they can directly compete withtranslations during decoding.
This is closer toour approach except that we use transliteration asan alternative to translation for all Hindi words.Our focus is disambiguation of Hindi homonymswhereas they are concentrating only on translit-erating NE?s.
Moreover, they are working witha large bitext so they can rely on their transla-tion model and only need to transliterate NEs andOOVs.
Our translation model is based on datawhich is both sparse and noisy.
Therefore we pittransliterations against translations for every inputword.
Sinha (2009) presents a rule-based MT sys-tem that uses Hindi as a pivot to translate from En-glish to Urdu.
This work also uses transliterationonly for the translation of unknown words.
Theirwork can not be used for direct translation fromHindi to Urdu (independently of English) ?due tovarious ambiguous mappings that have to be re-solved?.The third group uses transliteration models in-side of a cross-lingual IR system (AbdulJaleel andLarkey, 2003; Virga and Khudanpur, 2003; Pirkolaet al, 2003).
Picking a single best transliterationor translation in context is not important in an IRsystem.
Instead, all the options are used by giv-ing them weights and context is typically not takeninto account.3 Our ApproachBoth of our models combine a character-basedtransliteration model with a word-based transla-tion model.
Our models look for the most probableUrdu token sequence un1 for a given Hindi tokensequence hn1 .
We assume that each Hindi token ismapped to exactly one Urdu token and that there isno reordering.
The assumption of no reordering isreasonable given the fact that Hindi and Urdu haveidentical grammar structure and the same word or-der.
An Urdu token might consist of more than oneUrdu word3.
The following sections give a math-3This occurs frequently in case markers with nouns,derivational affixes and compounds etc.
These are writtenas single words in Hindi as opposed to Urdu where they areematical formulation of our two models, Model-1and Model-2.3.1 Model-1 : Conditional Probability ModelApplying a noisy channel model to compute themost probable translation u?n1 , we get:argmaxun1p(un1 |hn1 ) = argmaxun1p(un1 )p(hn1 |un1 )(1)3.1.1 Language ModelThe language model (LM) p(un1 ) is implementedas an n-gram model using the SRILM-Toolkit(Stolcke, 2002) with Kneser-Ney smoothing.
Theparameters of the language model are learned froma monolingual Urdu corpus.
The language modelis defined as:p(un1 ) =n?i=1pLM (ui|ui?1i?k) (2)where k is a parameter indicating the amount ofcontext used (e.g., k = 4 means 5-gram model).ui can be a single or a multi-word token.
Amulti-word token consists of two or more Urduwords.
For a multi-word ui we do multiple lan-guage model look-ups, one for each uix in ui =ui1 , .
.
.
, uim and take their product to obtain thevalue pLM (ui|ui?1i?k).Language Model for Unknown Words: Ourmodel generates transliterations that can be knownor unknown to the language model and the trans-lation model.
We refer to the words known tothe language model and to the translation modelas LM-known and TM-known words respectivelyand to words that are unknown as LM-unknownand TM-unknown respectively.We assign a special value ?
to the LM-unknownwords.
If one or more uix in a multi-word ui areLM-unknown we assign a language model scorepLM (ui|ui?1i?k) = ?
for the entire ui, meaningthat we consider partially known transliterationsto be as bad as fully unknown transliterations.
Theparameter ?
controls the trade-off between LM-known and LM-unknown transliterations.
It doesnot influence translation options because they arealways LM-known in our case.
This is because ourmonolingual corpus also contains the Urdu part oftranslation corpus.
The optimization of ?
is de-scribed in section 4.2.1.written as two words.
For example (beautiful ; xub-sur@t d) and (your?s ; ApkA) are written asand respectively in Urdu.4673.1.2 Translation ModelThe translation model (TM) p(hn1 |un1 ) is approx-imated with a context-independent model:p(hn1 |un1 ) =n?i=1p(hi|ui) (3)where hi and ui are Hindi and Urdu tokens re-spectively.
Our model estimates the conditionalprobability p(hi|ui) by interpolating a word-based model and a character-based (translitera-tion) model.p(hi|ui) = ?pw(hi|ui) + (1?
?
)pc(hi|ui) (4)The parameters of the word-based translationmodel pw(h|u) are estimated from the word align-ments of a small parallel corpus.
We only retain1-1/1-N (1 Hindi word, 1 or more Urdu words)alignments and throw away N-1 and M-N align-ments for our models.
This is further discussed insection 4.1.1.The character-based transliteration modelpc(h|u) is computed in terms of pc(h, u), a jointcharacter model, which is also used for Chinese-English back-transliteration (Li et al, 2004) andBengali-English name transliteration (Ekbal et al,2006).
The character-based transliteration proba-bility is defined as follows:pc(h, u) =?an1?align(h,u)p(an1 )=?an1?align(h,u)n?i=1p(ai|ai?1i?k) (5)where ai is a pair consisting of the i-th Hindi char-acter hi and the sequence of 0 or more Urdu char-acters that it is aligned with.
A sample alignmentis shown in Table 3(b) in section 4.1.3.
Our bestresults are obtained with a 5-gram model.
Theparameters p(ai|ai?1i?k) are estimated from a smalltransliteration corpus which we automatically ex-tracted from the translation corpus.
The extrac-tion details are also discussed in section 4.1.3.
Be-cause our overall model is a conditional probabil-ity model, joint-probabilities are marginalized us-ing character-based prior probabilities:pc(h|u) =pc(h, u)pc(u)(6)The prior probability pc(u) of the character se-quence u = cm1 is defined with a character-basedlanguage model:pc(u) =m?i=1p(ci|ci?1i?k) (7)The parameters p(ci|ci?1i?k) are estimated fromthe Urdu part of the character-aligned translitera-tion corpus.
Replacing (6) in (4) we get:p(hi|ui) = ?pw(hi|ui) + (1?
?
)pc(hi, ui)pc(ui)(8)Having all the components of our model definedwe insert (8) and (2) in (1) to obtain the final equa-tion:u?n1 = argmaxun1n?i=1pLM (ui|ui?1i?k)[?pw(hi|ui)+ (1?
?
)pc(hi, ui)pc(ui)] (9)The optimization of the interpolating factor ?
isdiscussed in section 4.2.1.3.2 Model-2 : Joint Probability ModelThis section briefly defines a variant of our modelwhere we interpolate joint probabilities instead ofconditional probabilities.
Again, the translationmodel p(hn1 |un1 ) is approximated with a context-independent model:p(hn1 |un1 ) =n?i=1p(hi|ui) =n?i=1p(hi, ui)p(ui)(10)The joint probability p(hi, ui) of a Hindi and anUrdu word is estimated by interpolating a word-based model and a character-based model.p(hi, ui) = ?pw(hi, ui)+(1??
)pc(hi, ui) (11)and the prior probability p(ui) is estimated as:p(ui) = ?pw(ui) + (1?
?
)pc(ui) (12)The parameters of the translation model pw(hi, ui)and the word-based prior probabilities pw(ui) areestimated from the 1-1/1-N word-aligned corpus(the one that we also used to estimate translationprobabilities pw(hi|ui) previously).The character-based transliteration probabilitypc(hi, ui) and the character-based prior probabil-ity pc(ui) are defined by (5) and (7) respectively in468the previous section.
Putting (11) and (12) in (10)we getp(hn1 |un1 ) =n?i=1?pw(hi, ui) + (1?
?
)pc(hi, ui)?pw(ui) + (1?
?
)pc(ui)(13)The idea is to interpolate joint probabilities and di-vide them by the interpolated marginals.
The finalequation for Model-2 is given as:u?n1 = argmaxun1n?i=1pLM (ui|ui?1i?k)?
?pw(hi, ui) + (1?
?
)pc(hi, ui)?pw(ui) + (1?
?
)pc(ui)(14)3.3 SearchThe decoder performs a stack-based search usinga beam-search algorithm similar to the one usedin Pharoah (Koehn, 2004a).
It searches for anUrdu string that maximizes the product of trans-lation probability and the language model proba-bility (equation 1) by translating one Hindi wordat a time.
It is implemented as a two-level pro-cess.
At the lower level, it computes n-besttransliterations for each Hindi word hi accord-ing to pc(h, u).
The joint probabilities given bypc(h, u) are marginalized for each Urdu transliter-ation to give pc(h|u).
At the higher level, translit-eration probabilities are interpolated with pw(h|u)and then multiplied with language model probabil-ities to give the probability of a hypothesis.
We use20-best translations and 25-best transliterations forpw(h|u) and pc(h|u) respectively and a 5-gramlanguage model.To keep the search space manageable and timecomplexity polynomial we apply pruning and re-combination.
Since our model uses monotonic de-coding we only need to recombine hypotheses thathave the same context (last n-1 words).
Next wedo histogram-based pruning, maintaining the 100-best hypotheses for each stack.4 Evaluation4.1 TrainingThis section discusses the training of the differentmodel components.4.1.1 Translation CorpusWe used the freely available EMILLE Corpusas our bilingual resource which contains roughly13,000 Urdu and 12,300 Hindi sentences.
Fromthese we were able to sentence-align 7000 sen-tence pairs using the sentence alignment algorithmgiven by Moore (2002).The word alignments for this task were ex-tracted by using GIZA++ (Och and Ney, 2003) inboth directions.
We extracted a total of 107323alignment pairs (5743 N-1 alignments, 8404 M-N alignments and 93176 1-1/1-N alignments).
Ofthese alignments M-N and N-1 alignment pairswere ignored.
We manually inspected a sample of1000 instances of M-N/N-1 alignments and foundthat more than 70% of these were (totally or par-tially) wrong.
Of the 30% correct alignments,roughly one-third constitute N-1 alignments.
Mostof these are cases where the Urdu part of the align-ment actually consists of two (or three) wordsbut was written without space because of lack ofstandard writing convention in Urdu.
For exam-ple (can go ; d ZA s@kt de) is alterna-tively written as (can go ; d ZAs@kt de)i.e.
without space.
We learned that these N-1translations could be safely dropped because wecan generate a separate Urdu word for each Hindiword.
For valid M-N alignments we observed thatthese could be broken into 1-1/1-N alignments inmost of the cases.
We also observed that we usu-ally have coverage of the resulting 1-1 and 1-Nalignments in our translation corpus.
Looking atthe noise in the incorrect alignments we decidedto drop N-1 and M-N cases.
We do not modeldeletions and insertions so we ignored null align-ments.
Also 1-N alignments with gaps were ig-nored.
Only the alignments with contiguous wordswere kept.4.1.2 Monolingual CorpusOur monolingual Urdu corpus consists of roughly114K sentences.
This comprises 108K sentencesfrom the data made available by the University ofLeipzig4 + 5600 sentences from the training dataof each fold during cross validation.4.1.3 Transliteration CorpusThe training corpus for transliteration is extractedfrom the 1-1/1-N word-alignments of the EMILLEcorpus discussed in section 4.1.1.
We use an editdistance algorithm to align this training corpus atthe character level and we eliminate translationpairs with high edit distance which are unlikely tobe transliterations.4http://corpora.informatik.uni-leipzig.de/469We used our knowledge of the Hindi and Urduscripts to define the initial character mapping.
Themapping was further extended by looking intoavailable Hindi-Urdu transliteration systems[5,6]and other resources (Gupta, 2004; Malik et al,2008; Jawaid and Ahmed, 2009).
Each pair in thecharacter map is assigned a cost.
A Hindi charac-ter that always map to only one Urdu character isassigned a cost of 0 whereas the Hindi charactersthat map to different Urdu characters are assigneda cost of 0.2.
The edit distance metric allowsinsert, delete and replace operations.
The hand-crafted pairs define the cost of replace operations.We set a cost of 0.6 for deletions and insertions.These costs were optimized on held out data.
Thedetails of optimization are not mentioned due tolimited space.
Using this metric we filter out theword pairs with high edit-distance to extract ourtransliteration corpus.
We were able to extractroughly 2100 unique pairs along with their align-ments.
The resulting alignments are modified bymerging unaligned ?
?
1 (no character on sourceside, 1 character on target side) or ?
?
N align-ments with the preceding alignment pair.
If thereis no preceding alignment pair then it is mergedwith the following pair.
Table 3 gives an exampleshowing initial alignment (a) and the final align-ment (b) after applying the merge operation.
Ourmodel retains 1 ?
?
and N ?
?
alignments asdeletion operations.a) Hindi ?
b c ?
e fUrdu A XY C D ?
Fb) Hindi b c e fUrdu AXY CD ?
FTable 3: Alignment (a) Before (b) After MergeThe parameters pc(h, u) and pc(u) are trainedon the aligned corpus using the SRILM toolkit.We use Add-1 smoothing for unigrams andKneser-Ney smoothing for higher n-grams.4.1.4 Diacritic Removal and NormalizationIn Urdu, short vowels are represented with diacrit-ics but these are rarely written in practice.
In or-der to keep the data consistent, all diacritics areremoved.
This loss of information is not harm-ful when transliterating/translating from Hindi toUrdu because undiacritized text is equally read-5CRULP: http://www.crulp.org/software/langproc.htm6Malerkotla.org: http://translate.malerkotla.co.inable to native speakers as its diacritized counterpart.
However leaving occasional diacritics in thecorpus can worsen the problem of data sparsity bycreating spurious ambiguity7.There are a few Urdu characters that have mul-tiple equivalent Unicodes.
All such forms are nor-malized to have only one representation8.4.2 Experimental SetupWe perform a 5-fold cross validation taking 4/5 ofthe data as training and 1/5 as test data.
Each foldcomprises roughly 1400 test sentences and 5600training sentences.4.2.1 Parameter OptimizationOur model contains two parameters ?
(the inter-polating factor between translation and transliter-ation modules) and ?
(the factor that controls thetrade-off between LM-known and LM-unknowntransliterations).
The interpolating factor ?
is ini-tialized, inspired by Written-Bell smoothing, witha value of NN+B9.
We chose a very low value1e?40 for the factor ?
initially, favoring LM-known transliterations very strongly.
Both of theseparameters are optimized as described below.Because our training data is very sparse we donot use held-out data for parameter optimization.Instead we optimize these parameters by perform-ing a 2-fold optimization for each of the 5 folds.Each fold is divided into two halves.
The param-eters ?
and ?
are optimized on the first half andthe other half is used for testing, then optimiza-tion is done on the second half and the first half isused for testing.
The optimal value for parameter?
occurs between 0.7-0.84 and for the parameter?
between 1e?5 and 1e?10.4.2.2 ResultsBaseline Pb0: We ran Moses (Koehn et al, 2007)using Koehn?s training scripts10, doing a 5-foldcross validation with no reordering11.
For theother parameters we use the default values i.e.5-gram language model and maximum phrase-length= 6.
Again, the language model is imple-7It should be noted though that diacritics play a very im-portant role when transliterating in the reverse direction be-cause these are virtually always written in Hindi as dependentvowels.8www.crulp.org/software/langproc/urdunormalization.htm9N is the number of aligned word pairs (tokens) and B isthe number of different aligned word pairs (types).10http://statmt.org/wmt08/baseline.html11Results are worse with reordering enabled.470M Pb0 Pb1 Pb2 M1 M2BLEU 14.3 16.25 16.13 18.6 17.05Table 4: Comparing Model-1 and Model-2 withPhrase-based Systemsmented as an n-gram model using the SRILM-Toolkit with Kneser-Ney smoothing.
Each foldcomprises roughly 1400 test sentences, 5000 intraining and 600 in dev12.
We also used two meth-ods to incorporate transliterations in the phrase-based system:Post-process Pb1: All the OOV words in thephrase-based output are replaced with their top-candidate transliteration as given by our translit-eration system.Pre-process Pb2: Instead of adding translit-erations as a post process we do a second passby adding the unknown words with their top-candidate transliteration to the training corpus andrerun Koehn?s training script with the new trainingcorpus.
Table 4 shows results (taking arithmeticaverage over 5 folds) from Model-1 and Model-2 in comparison with three baselines discussedabove.Both our systems (Model-1 and Model-2) beatthe baseline phrase-based system with a BLEUpoint difference of 4.30 and 2.75 respectively.
Thetransliteration aided phrase-based systems Pb1and Pb2 are closer to our Model-2 results but areway below Model-1 results.
The difference of2.35 BLEU points between M1 and Pb1 indicatesthat transliteration is useful for more than onlytranslating OOV words for language pairs likeHindi-Urdu.
Our models choose between trans-lations and transliterations based on context un-like the phrase-based systems Pb1 and Pb2 whichuse transliteration only as a tool to translate OOVwords.5 Error AnalysisBased on preliminary experiments we found threemajor flaws in our initial formulations.
This sec-tion discusses each one of them and provides someheuristics and modifications that we employ to tryto correct deficiencies we found in the two modelsdescribed in section 3.1 and 3.2.12After having the MERT parameters, we add the 600 devsentences back into the training corpus, retrain GIZA, andthen estimate a new phrase table on all 5600 sentences.
Wethen use the MERT parameters obtained before together withthe newer (larger) phrase-table set.5.1 Heuristic-1A lot of errors occur because our translation modelis built on very sparse and noisy data.
The moti-vation for this heuristic is to counter wrong align-ments at least in the case of verbs and functionalwords (which are often transliterations).
Thisheuristic favors translations that also appear in then-best transliteration list over only-translation andonly-transliteration options.
We modify the trans-lation model for both the conditional and the jointmodel by adding another factor which stronglyweighs translation+transliteration options by tak-ing the square-root of the product of the translationand transliteration probabilities.
Thus modifyingequations (8) and (11) in Model-1 and Model-2we obtain equations (15) and (16) respectively:p(hi|ui) = ?1pw(hi|ui) + ?2pc(hi, ui)pc(ui)+ ?3?pw(hi|ui)pc(hi, ui)pc(ui)(15)p(hi, ui) = ?1pw(hi, ui) + ?2pc(hi, ui)+ ?3?pw(hi, ui)pc(hi, ui) (16)For the optimization of lambda parameters wehold the value of the translation coefficient ?113and the transliteration coefficient ?2 constant (us-ing the optimized values as discussed in section4.2.1) and optimize ?3 again using 2-fold opti-mization on all the folds as described above14.5.2 Heuristic-2When an unknown Hindi word occurs for whichall transliteration options are LM-unknown thenthe best transliteration should be selected.
Theproblem in our original models is that a fixed LMprobability ?
is used for LM-unknown transliter-ations.
Hence our model selects the translitera-tion that has the best pc(hi,ui)pc(ui) score i.e.
we max-imize pc(hi|ui) instead of pc(ui|hi) (or equiva-lently pc(hi, ui)).
The reason is an inconsistencyin our models.
The language model probabil-ity of unknown words is uniform (and equal to?)
whereas the translation model uses the non-uniform prior probability pc(ui) for these words.There is another reason why we can not use the13The translation coefficient ?1 is same as ?
used in previ-ous models and the transliteration coefficient ?2 = 1?
?14After optimization we normalize the lambdas to maketheir sum equal to 1.471value ?
in this case.
Our transliterator model alsoproduces space inserted words.
The value of ?
isvery small because of which transliterations thatare actually LM-unknown, but are mistakenly bro-ken into constituents that are LM-known, will al-ways be preferred over their counter parts.
An ex-ample of this is (America) for which twopossible transliterations as given by our model are(AmerIkA, without space) and (AmerIkA, with space).
The latter version is LM-knownas its constituents are LM-known.
Our models al-ways favor the latter version.
Space insertion is animportant feature of our transliteration model.
Wewant our transliterator to tackle compound words,derivational affixes, case-markers with nouns thatare written as one word in Hindi but as two or morewords in Urdu.
Examples were already shown insection 3?s footnote.We eliminate the inconsistency by using pc(ui)as the 0-gram back-off probability distribution inthe language model.
For an LM-unknown translit-erations we now get in Model-1:p(ui|ui?1i?k)[?pw(hi|ui) + (1?
?
)pc(hi, ui)pc(ui)]= p(ui|ui?1i?k)[(1?
?
)pc(hi, ui)pc(ui)]=k?j=0?
(ui?1i?j )pc(ui)[(1?
?
)pc(hi, ui)pc(ui)]=k?j=0?
(ui?1i?j )[(1?
?
)pc(hi, ui)]where?kj=0 ?
(ui?1i?j ) is just the constant thatSRILM returns for unknown words.
The lastline of the calculation shows that we simply droppc(ui) if ui is LM-unknown and use the constant?kj=0 ?
(ui?1i?j ) instead of ?.
A similar calculationfor Model-2 gives?kj=0 ?
(ui?1i?j )pc(hi, ui).5.3 Heuristic-3This heuristic discusses a flaw in Model-2.
Fortransliteration options that are TM-unknown, thepw(h, u) and pw(u) factors becomes zero and thetranslation model probability as given by equation(13) becomes:(1?
?
)pc(hi, ui)(1?
?
)pc(ui)=pc(hi, ui)pc(ui)In such cases the ?
factor cancels out and noweighting of word translation vs. transliterationH1 H2 H12M1 18.86 18.97 19.35M2 17.56 17.85 18.34Table 5: Applying Heuristics 1 and 2 and theirCombinations to Model-1 and Model-2H3 H13 H23 H123M2 18.52 18.93 18.55 19.00Table 6: Applying Heuristic 3 and its Combina-tions with other Heuristics to Model-2occurs anymore.
As a result of this, translitera-tions are sometimes incorrectly favored over theirtranslation alternatives.In order to remedy this problem we assign aminimal probability ?
to the word-based priorpw(ui) in case of TM-unknown transliterations,which prevents it from ever being zero.
Becauseof this addition the translation model probabilityfor LM-unknown words becomes:(1?
?
)pc(hi, ui)??
+ (1?
?
)pc(ui)where ?
=1Urdu Types in TM6 Final ResultsThis section shows the improvement in BLEUscore by applying heuristics and combinations ofheuristics in both the models.
Tables 5 and 6 showthe improvements achieved by using the differ-ent heuristics and modifications discussed in sec-tion 5.
We refer to the results as MxHy where xdenotes the model number, 1 for the conditionalprobability model and 2 for the joint probabilitymodel and y denotes a heuristic or a combinationof heuristics applied to that model15.Both heuristics (H1 and H2) show improve-ments over their base models M1 and M2.Heuristic-1 shows notable improvement for bothmodels in parts of test data which has high num-ber of common vocabulary words.
Using heuris-tic 2 we were able to properly score LM-unknowntransliterations against each other.
Using theseheuristics together we obtain a gain of 0.75 overM-1 and a gain of 1.29 over M-2.Heuristic-3 remedies the flaw in M2 by assign-ing a special value to the word-based prior pw(ui)for TM-unknown words which prevents the can-celation of interpolating parameter ?.
M2 com-bined with heuristic 3 (M2H3) results in a 1.4715For example M1H1 refers to the results when heuristic-1 is applied to model-1 whereas M2H12 refers to the resultswhen heuristics 1 and 2 are together applied to model 2.472BLEU point improvement and combined with allthe heuristics (M2H123) gives an overall gain of1.95 BLEU points and is close to our best results(M1H12).
We also performed significance testby concatenating all the fold results.
Both our bestsystems M1H12 and M2H123 are statistically sig-nificant (p < 0.05)16 over all the baselines dis-cussed in section 4.2.2.One important issue that has not been investi-gated yet is that BLEU has not yet been shownto have good performance in morphologically richtarget languages like Urdu, but there is no metricknown to work better.
We observed that some-times on data where the translators preferred totranslate rather than doing transliteration our sys-tem is penalized by BLEU even though our out-put string is a valid translation.
For other parts ofthe data where the translators have heavily usedtransliteration, the system may receive a higherBLEU score.
We feel that this is an interestingarea of research for automatic metric developers,and that a large scale task of translation to Urduwhich would involve a human evaluation cam-paign would be very interesting.7 Sample OutputThis section gives two examples showing how ourmodel (M1H2) performs disambiguation.
Givenbelow are some test sentences that have Hindihomonyms (underlined in the examples) alongwith Urdu output given by our system.
In the firstexample (given in Figure 1) Hindi word can betransliterated to ( Lion) or (Verse) depend-ing upon the context.
Our model correctly identi-fies which transliteration to choose given the con-text.In the second example (shown in Figure 2)Hindi word can be translated to (peace,s@kun) when it is a common noun but transliter-ated to (Shanti, SAnt di) when it is a propername.
Our model successfully decides whether totranslate or transliterate given the context.8 ConclusionWe have presented a novel way to integratetransliterations into machine translation.
Inclosely related language pairs such as Hindi-Urduwith a significant amount of vocabulary overlap,16We used Kevin Gimpel?s tester(http://www.ark.cs.cmu.edu/MT/) which uses bootstrapresampling (Koehn, 2004b), with 1000 samples.Ser d Z@ngl kA rAd ZA he?Lion is the king of jungle?AIqbAl kA Aek xub sur@t d Ser he?There is a beautiful verse from Iqbal?Figure 1: Different Transliterations in DifferentContextsp hIr b hi vh s@kun se n@her?h s@kt dA?Even then he can?t live peacefully?Aom SAnt di Aom frhA xAn ki d dusri fIl@m he?Om Shanti Om is Farah Khan?s second film?Figure 2: Translation or Transliterationtransliteration can be very effective in machinetranslation for more than just translating OOVwords.
We have addressed two problems.
First,transliteration helps overcome the problem of datasparsity and noisy alignments.
We are able to gen-erate word translations that are unseen in the trans-lation corpus but known to the language model.Additionally, we can generate novel translitera-tions (that are LM-Unknown).
Second, generat-ing multiple transliterations for homograph Hindiwords and using language model context helps ussolve the problem of disambiguation.
We foundthat the joint probability model performs almost aswell as the conditional probability model but thatit was more complex to make it work well.AcknowledgmentsThe first two authors were funded by the HigherEducation Commission (HEC) of Pakistan.
Thethird author was funded by Deutsche Forschungs-gemeinschaft grants SFB 732 and MorphoSynt.The fourth author was funded by DeutscheForschungsgemeinschaft grant SFB 732.473ReferencesNasreen AbdulJaleel and Leah S. Larkey.
2003.
Sta-tistical transliteration for English-Arabic cross lan-guage information retrieval.
In CIKM 03: Proceed-ings of the twelfth international conference on In-formation and knowledge management, pages 139?146.Yaser Al-Onaizan and Kevin Knight.
2002.
Translat-ing named entities using monolingual and bilingualresources.
In Proceedings of the 40th Annual Meet-ing of the Association for Computational Linguis-tics, pages 400?408.Asif Ekbal, Sudip Kumar Naskar, and Sivaji Bandy-opadhyay.
2006.
A modified joint source-channelmodel for transliteration.
In Proceedings of theCOLING/ACL poster sessions, pages 191?198, Syd-ney, Australia.
Association for Computational Lin-guistics.Swati Gupta.
2004.
Aligning Hindi and Urdu bilin-gual corpora for robust projection.
Masters projectdissertation, Department of Computer Science, Uni-versity of Sheffield.Ulf Hermjakob, Kevin Knight, and Hal Daume?
III.2008.
Name translation in statistical machine trans-lation - learning when to transliterate.
In Proceed-ings of ACL-08: HLT, pages 389?397, Columbus,Ohio.
Association for Computational Linguistics.Bushra Jawaid and Tafseer Ahmed.
2009.
Hindi toUrdu conversion: beyond simple transliteration.
InConference on Language and Technology 2009, La-hore, Pakistan.Mehdi M. Kashani, Eric Joanis, Roland Kuhn, GeorgeFoster, and Fred Popowich.
2007.
Integration of anArabic transliteration module into a statistical ma-chine translation system.
In Proceedings of the Sec-ond Workshop on Statistical Machine Translation,pages 17?24, Prague, Czech Republic.
Associationfor Computational Linguistics.Kevin Knight and Jonathan Graehl.
1998.
Ma-chine transliteration.
Computational Linguistics,24(4):599?612.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran,Richard Zens, Chris Dyer, Ondrej Bojar, AlexandraConstantin, and Evan Herbst.
2007.
Moses: Opensource toolkit for statistical machine translation.
InProceedings of the 45th Annual Meeting of the Asso-ciation for Computational Linguistics, Demonstra-tion Program, Prague, Czech Republic.Philipp Koehn.
2004a.
Pharaoh: A beam search de-coder for phrase-based statistical machine transla-tion models.
In AMTA, pages 115?124.Philipp Koehn.
2004b.
Statistical significance tests formachine translation evaluation.
In Dekang Lin andDekai Wu, editors, Proceedings of EMNLP 2004,pages 388?395, Barcelona, Spain, July.
Associationfor Computational Linguistics.Haizhou Li, Zhang Min, and Su Jian.
2004.
A jointsource-channel model for machine transliteration.In ACL ?04: Proceedings of the 42nd Annual Meet-ing on Association for Computational Linguistics,pages 159?166, Barcelona, Spain.
Association forComputational Linguistics.M G Abbas Malik, Christian Boitet, and Pushpak Bhat-tacharyya.
2008.
Hindi Urdu machine translitera-tion using finite-state transducers.
In Proceedingsof the 22nd International Conference on Computa-tional Linguistics, Manchester, UK.Robert C. Moore.
2002.
Fast and accurate sentencealignment of bilingual corpora.
In Conference of theAssociation for Machine Translation in the Ameri-cas (AMTA).Franz J. Och and Hermann Ney.
2003.
A systematiccomparison of various statistical alignment models.Computational Linguistics, 29(1):19?51.Kishore A. Papineni, Salim Roukos, Todd Ward, andWei-Jing Zhu.
2001.
BLEU: a method for auto-matic evaluation of machine translation.
TechnicalReport RC22176 (W0109-022), IBM Research Di-vision, Thomas J. Watson Research Center, York-town Heights, NY.Ari Pirkola, Jarmo Toivonen, Heikki Keskustalo, KariVisala, and Kalervo Ja?rvelin.
2003.
Fuzzy trans-lation of cross-lingual spelling variants.
In SIGIR?03: Proceedings of the 26th annual internationalACM SIGIR conference on Research and develop-ment in informaion retrieval, pages 345?352, NewYork, NY, USA.
ACM.R.
Mahesh K. Sinha.
2009.
Developing English-Urdumachine translation via Hindi.
In Third Workshopon Computational Approaches to Arabic Script-based Languages (CAASL3), MT Summit XII, Ot-tawa, Canada.Andreas Stolcke.
2002.
SRILM - an extensible lan-guage modeling toolkit.
In Intl.
Conf.
Spoken Lan-guage Processing, Denver, Colorado.Paola Virga and Sanjeev Khudanpur.
2003.
Translit-eration of proper names in cross-lingual informationretrieval.
In Proceedings of the ACL 2003 workshopon Multilingual and mixed-language named entityrecognition, pages 57?64, Morristown, NJ, USA.Association for Computational Linguistics.Bing Zhao, Nguyen Bach, Ian Lane, and Stephan Vo-gel.
2007.
A log-linear block transliteration modelbased on bi-stream HMMs.
In Human LanguageTechnologies 2007: The Conference of the NorthAmerican Chapter of the Association for Computa-tional Linguistics; Proceedings of the Main Confer-ence, pages 364?371, Rochester, New York.
Associ-ation for Computational Linguistics.474
