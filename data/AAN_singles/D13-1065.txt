Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 693?703,Seattle, Washington, USA, 18-21 October 2013. c?2013 Association for Computational LinguisticsTwo-stage Method for Large-scale Acquisition ofContradiction Pattern Pairs using EntailmentJulien Kloetzer?
Stijn De Saeger?
Kentaro Torisawa?
Chikara Hashimoto?Jong-Hoon Oh?
Motoki Sano?
Kiyonori Ohtake?
?Information Analysis Laboratory,National Institute of Information and Communications Technology (NICT), Kyoto, Japan{?julien, ?
stijn, ?
torisawa, ?
ch, ?rovellia, ?msano, ?
?kiyonori.ohtake}@nict.go.jpAbstractIn this paper we propose a two-stage methodto acquire contradiction relations betweentyped lexico-syntactic patterns such as Xdrugprevents Ydisease and Ydisease caused byXdrug .
In the first stage, we train an SVMclassifier to detect contradiction pattern pairsin a large web archive by exploiting the exci-tation polarity (Hashimoto et al 2012) of thepatterns.
In the second stage, we enlarge thefirst stage classifier?s training data with newcontradiction pairs obtained by combining theoutput of the first stage?s classifier and that ofan entailment classifier.
We acquired this way750,000 typed Japanese contradiction patternpairs with an estimated precision of 80%.
Weplan to release this resource to the NLP com-munity.1 IntroductionThe ability to detect contradictory information intext has many practical applications.
Among those,Murakami et al(2009) pointed out that a contra-diction recognition system can detect conflicts andanomalies in large bodies of texts and flag them tohelp users identify unreliable information.
For ex-ample, many Japanese web pages claim that agari-cus prevents cancer, where agaricus is a species ofmushroom found in a variety of commercial prod-ucts.
Although this has been accepted by manyJapanese people, by Googling keywords ?agaricus?,?promotes?
and ?cancer?, we can find pages claim-ing that ?agaricus promotes cancer?, some of whichpoint to a study authorized by the Japanese Min-istry of Health, Labour and Welfare1 reporting that1 http://www.mhlw.go.jp/topics/bukyoku/iyaku/syoku-anzen/qa/060213-1.htmla commercial product containing agaricus promotedcancer.
Obviously, the existence of these pages castsserious doubt on the ability of agaricus to preventcancer and encourages readers to dig more about thissubject.The above example suggests that recognizingcontradictory information can guide users to a truefact.
Likewise, we believe that contradiction recog-nition is also useful when dealing with non-factualinformation that occupy most of our daily lives.
Forinstance, there is a big controversy recently whetherJapan should join an economic partnership agree-ment called the Trans Pacific Partnership (TPP), andquite serious but contradictory claims are plentiful inthe mass media and on the web, e.g., TPP will wipeout Japan?s agricultural businesses and TPP willstrengthen Japan?s agricultural businesses.
Neitherof these are facts; they are predictions that can onlybe realized or disputed after the underlying decision-making is done: joining or refusing the TPP.Furthermore, after reading documents includingcontradictory predictions, one should notice thateach of them is supported by a convincing the-ory that has no obvious defect, e.g., ?Exports ofJapan?s agricultural products will increase thanks tothe TPP?
or ?A large amount of low-price agricul-tural products will be imported to Japan due to theTPP?.
Even if one of these predictions may just hap-pen to be true because of unexpected reasons such asminor fluctuations in the Japanese yen, we must sur-vey such theories that support contradictory predic-tions, conduct balanced decision-making, and pre-pare counter measures for the expected problems af-ter examining multiple viewpoints.
Contradictionrecognition should be useful to select documents tobe surveyed.693Figure 1: Method workflowWe have developed a method for recog-nizing pairs of contradictory binary patternssuch as ?
?X promotes Y?, ?X prevents Y??
and?
?X will wipe out Y?, ?X will strengthen Y??.
Tosolve the problem described above, we can easilydevelop a system that can find contradictory textfragments from the web like ?agaricus promotescancer?
and ?agaricus prevents cancer?
from thediscovered contradictory pattern pairs.Our method is a two-stage procedure with threesupervised classifiers (Fig.
1).
In the first stage,we build a classifier BASE to recognize contradic-tions between binary patterns, and a classifier ENTto recognize entailment.
In the second stage, wecombine the contradiction pairs recognized by BASEand the entailment pairs recognized by ENT to ex-pand BASE?s training data and train a new contra-diction classifier, EXP.
This expansion using en-tailment is one key idea of this work: we acquired750,000 contradiction pairs with 80% precision us-ing the expanded training data, more than doublingthe 285,000 pairs acquired at the same precisionlevel without expansion.
We also demonstrate thatthis result is not trivial by showing that our methodoutperforms an alternative one based on Integer Lin-ear Programming inspired by the successful entail-ment recognition method of Berant et al(2011).As another technical contribution of this work, weexploit the recently proposed semantic polarity ofexcitation (Hashimoto et al 2012) to recognize con-tradictions between binary patterns.
Hashimoto etal.
(2012) previously showed that excitation polari-ties are useful to recognize contradictions betweenphrases that consist of a noun and a predicate, suchas ?promote cancer?
and ?prevent cancer?.
Whileit is trivial to extend this framework to contradic-tions between unary patterns such as ?promote X?and ?prevent X?
by replacing the common nounsin each pair with a variable, the information rep-resented in unary patterns is often vague, and it isunlikely that a contradiction between unary patternsdirectly leads to the discovery of unreliable infor-mation to be flagged or to a meaningful survey ofcomplex problems.
As exemplified by the agaricusand TPP examples, contradictions between binarypatterns that include two variables such as ?X pro-motes Y?
or ?X will wipe out Y?
are more usefulthan those between unary patterns.
We also showthat it is not trivial to recognize contradictions be-tween binary patterns using contradictions betweenunary patterns.Most works dealing with contradiction recogni-tion up till now (Harabagiu et al 2006; Bobrowet al 2007; Kawahara et al 2008; Kawahara etal., 2010; Ohki et al 2011) focus on recognizingcontradictions between full sentences or documents,not text fragments that match our relatively shortpatterns (survey in Section 5).
We expect that thecontradictory pattern pairs we acquired can be usedas building blocks in such full-fledged contradictionrecognition for full sentences or documents, simi-larly to antonym pairs in Harabagiu et al(2006).Also, we should emphasize that our methodfocuses on the most challenging part of contra-diction recognition according to the classificationof De Marneffe et al(2008).
Since we discardpatterns with negations, an evident source of contra-dictions like ?
?X causes Y?, ?X does not cause Y?
?,most of our output are non-trivial contradic-tions related to high-level semantic phenomena,e.g., contradiction pairs related to antonymslike ??X?
Y????
?, ?X?
Y??????(?
?X increases Y?, ?X decreases Y??
), lexical contra-dictions like ??X?
Y???
?, ?Y?
X?????(?
?X wins against Y?, ?Y wins against X??
), orcontradictions due to common-sense knowledgelike ??X?
Y??????
?, ?X?
Y??????(?
?X reassures Y?, ?X betrays Y??).
We believeacquiring such contradictions in a large scale is avaluable contribution.The following is the outline of this paper.
Sec-tion 2 details our target and our proposed method.Evaluation results are discussed in Section 3.
Sec-694Figure 2: Detailed data flowtion 4 details our features set, and Section 5 relatedwork.
Section 6 provides a conclusion.2 Proposed methodAs showed in Figure 1, our method consists ofthree supervised classifiers.
Classifiers BASE andEXP recognize contradiction relations between bi-nary patterns, and ENT recognizes entailment rela-tions between binary patterns.
The contradictionpairs recognized by BASE and the entailment pairsrecognized by ENT are combined to generate newcontradiction pairs, part of which are then added toBASE training data to train the EXP classifier.
Ourfinal output is the set of all binary pattern pairs re-garded as contradictions by EXP.
Since the depen-dencies between these three classifiers, their distinctsets of training data, and the two data sets to be clas-sified (we describe those in the two sections below)is a bit complex, we show a complete description ofthe whole process in Figure 2.The key idea is in the scheme that expands thetraining data.
Logically speaking, patterns p and rare contradictory if there exists a pattern q such thatp entails q and q contradicts r. For example, since?X causes Y?
entails ?X promotes Y?
and ?X pro-motes Y?
contradicts ?X prevents Y?, then ?X causesY?
contradicts ?X prevents Y?.
Hence, by combin-ing entailment and contradiction pairs, we can ob-tain more contradiction pairs.Following this property of contradiction relations,we collect a set of pattern pairs {?p, r?}
for whichthere exists a pattern q such that ENT recognizes thatp entails q and BASE recognizes that q contradicts r.Then we rank these pairs based on a novel scoringfunction called Contradiction Derivation Precision(CDP) and expand BASE training data by adding toit the top-ranked pairs according to CDP in order totrain EXP.
This ranking scheme selects highly accu-rate contradiction pairs and prevents errors causedby BASE and ENT from being propagated to EXP.In the following, after defining the patterns forwhich we acquire contradiction relations, we de-scribe BASE, EXP, ENT, and our expansion scheme.2.1 PatternsIn this work, a binary pattern is a word sequenceon the path of dependency relations connecting twonouns in a syntactic dependency tree, like ?X causesY?, and we say a noun pair co-occurs with a patternif the two nouns are connected by this pattern in thedependency tree of a sentence in the corpus.We focus on typed binary patterns, which placesemantic class restrictions on the noun pairs theyco-occur with, e.g., ?Yorganization is in Xlocation?.Subscripts organization and location indicate the se-mantic classes of the X and Y slots.
Since typedpatterns can distinguish between multiple sensesof ambiguous patterns, they greatly reduce errorsdue to pattern ambiguity (De Saeger et al 2009;Schoenmackers et al 2010; Berant et al 2011).We automatically induced semantic classes from ourcorpus using the EM-based noun clustering algo-695rithm presented in Kazama and Torisawa (2008),and clustered one million nouns into 500 rela-tively clean semantic classes, including for exampleclasses of diseases and of chemical substances.The binary patterns and their co-occurring nounpairs were extracted from our corpus of 600 mil-lion Japanese web pages dependency parsed withKNP (Kurohashi and Nagao, 1994).
We restrictedour patterns to the most frequent 3.9 million pat-terns of the form ?X-[case particle] Y-[case parti-cle] predicate?
such as ?X-ga Y-ni aru?
(?X is in Y?
)which do not contain any negation, number, symbolor punctuation character.
Based on our observationthat patterns in meaningful contradiction and entail-ment pairs tend to share many co-occurring nounpairs, we used as input to our classifiers the set Pallof 792 million pattern pairs for which both patternsshare three co-occurring noun pairs.2.2 BASE: First stage Classifier forContradictionBelow, we detail BASE: its training data and inputdata to be classified, and some experimental results.Our first stage classifier for contradictions, BASE,is an SVM that uses commonsensical surface andlexical resources based features, such as n-grams ex-tracted from patterns, which will be detailed in Sec-tion 4.
An important point to be stressed here isthat we restricted the pattern pairs to be classifiedby BASE by exploiting their excitation polarity, asemantic orientation proposed by Hashimoto et al(2012).
Excitation characterizes unary patterns asexcitatory, inhibitory, or neutral.
Excitatory unarypatterns, such as ?cause X?
or ?increase X?, entailthat the function, effect, purpose, or role of their ar-gument?s referent is activated or enhanced, and in-hibitory unary patterns, such as ?prevent X?
or ?Xdisappears?, entail that the function, effect, purpose,or role of their argument?s referent is deactivated orsuppressed.
Neutral unary patterns like ?close to X?are neither excitatory nor inhibitory.We exploited excitation to restrict the input ofBASE.
Based on the result of Hashimoto et al(2012) showing that two unary patterns with op-posite polarity have a higher chance to be a con-tradiction, we extracted from set Pall the set Poppof binary pattern pairs that contain unary patternswith opposite excitation polarities as sub-patterns.?
?Y cause X?, ?Y prevent X??
is an example of sucha pair since the unary sub-patterns ?cause X?
and?prevent X?
are respectively excitatory and in-hibitory.
We used here 6,470 excitation unary pat-terns hand-labeled as either excitatory (4,882 pat-terns) or inhibitory (1,588 patterns).
Set Popp con-tains 8 million pattern pairs with roughly 38% truecontradiction pairs, and is the input to BASE.
Wewill show in experiments at the end of this sectionthat this restriction is necessary to obtain good per-formance for BASE.
We also tried to add the excita-tion polarities in BASE?s feature set and classify Pall,but the performance was worse.Training Data Another key feature of BASE isthat it is distantly supervised.
We did not usetraining samples that are directly manually anno-tated.
Instead we automatically generated trainingdata from a smaller set of (non-)contradiction unarypattern pairs.
We first prepared a set of roughly800 unary pattern pairs hand-labeled by three humanannotators as contradictions (238 pairs) and non-contradictions (558 pairs) using majority vote.
Theinter-annotator agreement was 0.78 (Fleiss?kappa).Inspired by Hashimoto et al(2012), we selectedthese unary pattern pairs among pairs with high dis-tributional similarity, with and without restrictingthem to having opposite excitation polarity, such asto get a fair distribution of contradictions and non-contradictions.We then extracted from set Pall all 256,000 pat-tern pairs containing a contradictory unary patternpair, and all 5.2 million pattern pairs containing anon-contradictory unary pattern pair, which we re-spectively used as positive and negative training data(estimated 79% and 73% accuracy from 200 hand-labeled samples).
Table 1 shows some examples.The optimal composition of training data forBASE was determined according to preliminary ex-periments using our development set (1,000 manu-ally labelled samples.
See Section 3.1).
We trained20 different classifiers using from 6,250 to 50,000positive samples (4 sets) and from 12,500 to 200,000negative samples (5 sets), doubling the amounts ineach step, for a total of 20 configurations.
We couldnot try a larger training data due to long training timebut we do not expect it to be a problem because theworst performance was observed with large train-696Table 1: Examples of training samples for BASE obtained from unary pattern pairsBinary pattern pair (the unary pattern pair that extracted it is underlined) Unary pattern pair labelY ?
X ???
(X is bad in Y too) - Y ??
X ???
(X is good even in Y) contradictionY ?
X ????
(Y too heads toward X) - Y ?
X ???
(Y too comes out of X) contradictionX ?Y ?
???
(add Y to X) - X ?Y ?
???
(insert X into Y) non-contradictionY ?
X ???
(Y too comes to X) - Y ??
X ???
(go to X with Y) non-contradictionFigure 3: Effect of the restriction using excitationing data (25,000 positives and 200,000 negatives;the difference from the optimal setting was 2.3% inaverage precision).
The optimal training data set,Trainbase, consists of 12,500 positives and 100,000negatives samples as described above and is the onewe use in our experiments below and in Section 3.Since BASE input for classification data is Poppwe also tried sampling Trainbase from Popp.
Weobtained 56.27% average precision for our classi-fier BASE, and 52.99% when restricting the sourceof training data to pairs in Popp.
We believe that thedifference lies in the size of the sets from which wesampled our training data: while there are 5.46 mil-lion binary pattern pairs in Pall with a hand-labeledunary pattern pair in Pall, there are only 237,000pairs in Popp.
We believe this much smaller sam-ple source lead to a lower performance because itincluded much less variations of the patterns.To train BASE and other classifiers mentioned inthis paper, we used the SVM tool TinySVM2 witha polynomial kernel of degree 2, the setting whichshowed the best performance during our preliminaryexperiments.Effect of Excitation Polarities We also empiri-cally examined the effect of the restriction on thepatterns using excitation polarities.
We used our testset (2,000 manually annotated samples described in2 http://chasen.org/?taku/software/TinySVM/Section 3.1) and 250 manually annotated samples(majority vote from 3 annotators) from top rankedpairs of Pall to draw precision curves for BASE overthe top 2 million binary pairs from both Popp andPall.
In each case we assumed that pairs were dis-tributed uniformly (i.e., with a constant interval) inthe ranked list of pairs of Popp and Pall, and com-puted precision accordingly.
Since the pairs setsare reasonably large and were sampled randomly wethought this was a reasonable hypothesis.
The pre-cision over Popp is higher than that over Pall witha large margin, suggesting that the restriction usingexcitation polarities is beneficial.2.3 ENT: First stage Classifier for EntailmentENT is an SVM classifier for entailment trained us-ing 27,500 hand-annotated binary pattern pairs (setTrainent, 45% of positive entailment pairs) createdfor some previous work (Kloetzer et al 2013).
It es-sentially uses the same feature set as that for BASEwith the addition of several distributional similar-ity measures (see Section 4 below for more details).This classifier is given all pairs of Pall as input andscores each of them.
For this study, we consideredthe 44.5 million pattern pairs with a positive SVMscore as entailment pairs.
Manual annotation of 200random samples revealed that the precision of thesepairs was 63% and that the top 7.1 million pairs had80% precision (result interpolated from the top 16%of the annotated samples).2.4 Second stage: Training Data Expansionand Classifier EXPBelow, we show how we combine BASE?s top output(hereafter C) and ENT?s top output (hereafter E) inthe second stage of our method to expand Trainbaseand train a new classifier, EXP.The training data expansion process is based onthe following logical constraint: if a pattern p entailsa pattern q and pattern q contradicts a third pattern r,then p must contradict r. For example, because ?X697Table 2: Examples of triplets ?p, q,r?
where p entails q, q contradicts r, and hence p contradicts rPattern p Pattern q Pattern r X/Y examples SV M Score(p, r) CDP (p, r)Y ??
X ????
Y ??
X ?????
Y ?
X ????
??/?
0.3 0.98X disappears from Y X vanishes from Y Y is full of X anger/eyeY ?
X ?????
Y ?
X ????
Y ??
X ????
??/??
-0.3 0.61stop X in Y finish X in Y start X in Y April/activityX ?
Y ???
X ?
Y ???
X ?
Y ???
???/??
0.07 0.45X shows Y X have Y X loses Y team/confidenceAlgorithm 1 Training data expansion: C is the top 5%output of BASE, E is the top output of ENT (score > 0)1: procedure EXPAND(C, E)2: Compute the set of expanded pairs C?
= {?p, r?
|?q : ?p, q??
E,?q, r??
C}.3: Rank the pairs in C?
using CDP.4: Add the N top-ranked pairs in C?
\ C as new positivesamples to Trainbase.5: Remove incoherent negative training samples usingnegative cleaning.6: end procedurecauses Y?
(pattern p) entails ?X promotes Y?
(patternq) and the latter contradicts ?X prevents Y?
(patternr), we conclude that ?X causes Y?
(p) contradicts?X prevents Y?
(r).
We call the former contradic-tion ?q, r?
a source contradiction pair, and the laterpair ?p, r?
an expanded contradiction pair.
Based onthis idea, we combine C and E to aggressively ex-pand Trainbase.
This process is described in Al-gorithm 1, and Table 2 shows examples of triples?p, q,r?
obtained in our experiments.Expanding pairs fromC andE compounds the er-rors made by BASE and ENT, hence it is crucial toselect a highly precise subset of the expanded pairs.Taking the top pairs according to their SVM scorewould achieve this, but since BASE already handlescorrectly such pairs, they should not help much asnew training data.
We therefore propose a new scor-ing function for selecting highly precise expandedpairs: Contradiction Derivation Precision (CDP ).CDP was designed according to the followingassumption: a source contradiction pair that derivescorrect expanded pairs with a high precision shouldbe reliable.
Probably, all the expanded pairs derivedfrom such a reliable source pair will be correct andshould be included in the new training data .In our formulation of CDP , correctness of an ex-panded pair is judged according to the pair?s SVMscore using BASE.
In other words, we regard anexpanded pair that has an SVM score above somethreshold ?
as a true contradiction.
A source contra-diction pair that derives true contradiction pairs witha high precision is regarded as a reliable source con-tradiction pair.
CDP , which is defined over a ex-panded pairs, is the maximum precision among thatof the source contradiction pairs that derive a givenexpanded pair.We first define CDPsub(q, r) over a source con-tradiction pair ?q, r?
as the ratio of expanded pairsobtained from ?q, r?
whose SVM score is abovethreshold ?.
This ratio corresponds to the precisionof the expanded pairs derived from the source con-tradiction pair ?q, r?.CDPsub(q, r) = |{?p, r?
?
Ex(q, r) | Sc(p, r) > ?
}||Ex(q, r)|HereEx(q, r) is the set of expanded pairs derivedfrom a source pair ?q, r?, and Sc is the SVM scoregiven by BASE.
In our experiments, we set ?
= 0.46such that pattern pairs for which BASE gives a scoreover ?
corresponds to the top 5% of BASE?s output.CDP (p, r) over an expanded pair is defined as fol-lows, where Source(p, r) is the set of source con-tradiction pairs that were derived into the expandedpair ?p, r?.CDP (p, r) = max?q,r?
?Source(p,r)CDPsub(q, r)We then expand the top 5% contradictions ofBASE?s output (set C) and pattern pairs scored pos-itively by ENT (set E), rank all expanded pairs notalready in C according to CDP, and add the top Npairs with the highest CDP values as positives toTrainbase to train EXP.
The value of N shall bedetermined empirically in later experiments usinga development set.
Note that, since CDP (p, r) isindependent of ?p, r?
?s SVM score, even pairs thatwere assigned a negative score by BASE can becomehighly ranked by CDP (second triplet in Table 2)698and be added to train EXP, hence we expect EXP tolearn something new from these pairs.Finally, after the addition of expanded pairs, weremove incoherent training samples.
We propose toremove from the negative training samples of EXPany pattern pair that may conflict with the newlyadded positives; we call this step negative cleaning.Intuitively, since the content word pairs in a patternpair should present some of the strongest evidencefor determining the patterns (non-)contradiction sta-tus, we remove any negative sample that shares acontent word pair with one of the added expandedpairs.
The final training data for EXP, set Trainexp,consists of the following: (1) positive samples fromTrainbase, (2) (positive) expanded pairs, and (3)negative training samples from Trainbase, cleanedusing negative cleaning.
We confirmed in our exper-iments that negative cleaning was necessary to traina strong EXP classifier (details omitted for reason ofspace).After training EXP with Trainexp, we classifyPopp with EXP to produce the final output of thewhole method.
Note that while this expansion pro-cess can be re-iterated with EXP?s output, our exper-iments failed to show any improvement with subse-quent iterations.3 EvaluationThis section presents our experimental results.
Wedescribe first how we constructed test and develop-ment data, and then report comparison results be-tween our method and others including BASE and anInteger Linear Programming-based (ILP) method.3.1 Development and Test DataWe asked three human annotators to label 3,000 bi-nary pattern pairs randomly sampled from Popp ascontradiction or non-contradiction to be used as de-velopment (1,000 pairs) and test (2,000 pairs) sets.We considered a pattern pair as a true contradic-tion relation if at least two out of the three annota-tors marked it as positive.
The inter-rater agreementscore (Fleiss Kappa) was 0.523, indicating moderateagreement (Landis and Koch, 1977).
As a definitionof contradiction, we used the notion of incompati-bility (i.e., two statements are extremely unlikely tobe simultaneously true) proposed by De Marneffe etFigure 4: Precision of all the compared methodsal.
(2008).
We then say binary patterns such as ?Xcauses Y?
and ?X prevents Y?
are contradictory ifthe above definition holds for any noun pair that caninstantiate the patterns?
variables in the provided se-mantic class pair.Because our semantic classes are obtained by au-tomatic clustering and have no meaningful labels,we followed Szpektor et al(2007) and provided theannotators with three random noun pairs that co-occur with the patterns as a proxy for the class pair.The annotators marked a given pattern pair as posi-tive if the contradiction relation between the patternsheld for all three noun pairs presented.3.2 Experimental ResultsHere we show how our proposed method outper-forms baseline methods.
We compare the followingfour methods:?
PROPOSED: our proposed method.
N , thenumber of newly added positive training sam-ples during the training data expansion pro-cess, was set to 6,000 according to preliminaryexperiments using the development set.
Wetried 50 different values of N from 1,000 up to50,000, adding 1,000 each time, and chose theN value giving the highest average precisionagainst our development set (1,000 samples).?
BASE: our first stage classifier.?
PROP-SCORE: same as PROPOSED except forthe use of BASE?s SVM score instead of CDP .N was set to 30,000 in the same way we set Nfor PROPOSED.?
HAS: an adaptation of the contradiction ex-traction method presented in Hashimoto et al699(2012).
For a binary pattern pair we firstextracted its unary pattern pair with oppositepolarity (or one at random in case there aretwo) and scored it based on our implementa-tion of Hashimoto et al(2012); the score isbased on the distributional similarity betweenunary patterns and an excitation score obtainedusing a minimally supervised method based onthe spin model.
We then scored the binary pat-tern pair by the score of this unary pattern pair.We ranked the pattern pairs of our test set (2,000random pairs from set Popp) based on the score pro-duced by each method.
For each tested method weassumed that pairs in the test set were distributeduniformly like explained in Section 2.2.
The pre-cision curves we obtained are shown in Figure 4.PROPOSED clearly outperformed BASE and ac-quired around 750,000 contradiction pattern pairswith an estimated precision of 80%, out of whichsome examples are shown in Table 3.
These pairscover 26,941 content word pairs and reduce to272,164 untyped pairs, showing that PROPOSEDdoes not just acquire a handful of contradictions inmany different class pairs.
Also, when matchingthese pairs against an antonyms database (extractedfrom the dictionary of the morphical analyzer JU-MAN) we found that only 100,886 of these patternpairs contain an antonym pair, which means thatmost of the extracted pairs?
contradictions are dueto more complex phenomena than simple antonymy.With the same precision, BASE and PROP-SCOREacquired only 285,000 pairs (covering 11,794 con-tent word pairs) and 636,000 pairs respectively.
Thisimplies that our two-stage method can more thandouble the number of highly precise contradictionpairs we acquire as well as increasing their vari-ety, and that ranking expanded pairs using our scor-ing function CDP is better than with SVM score,though even PROP-SCORE performs better thanBASE in our setting.
Finally, the poor performanceof HAS suggests that extending the Hashimoto etal.
?s framework to recognition of binary patterns isnot a trivial task.As to why adding only 6,000 top pairs rankedby CDP performs better than adding 30,000 pairsranked by SVM score, the pattern pairs added inPROP-SCORE had high SVM scores given by BASEand as such are already handled nicely by BASE.Table 3: Examples of pairs acquired by PROPOSED: con-tradiction (label +) and non-contradiction (label -)Lab.
Pattern pairs (with rank) X/Y exampleY ?
X ????
- Y ??
X ?????
??/?
?+ X finished Y - X started from Y sale/yesterdayRank 228,039X ?
Y ???
- Y ?
X ???
??/???
?+ X wins against Y - Y wins against X Japan/VietnamRank: 258,068X ?
Y ???
- X ??
Y ???
?/?
?- X lose Y - Have Y in X people/interestRank 474,143Y ?
X ????
- Y ??
X ???
??/?
?+ Lose X in Y - Have X in Y too confidence/Rank 522,534 oneselfY ?
X ?????
- X ?
Y ????
9 ?/?
?- Y falls down to X - raise Y to X 9th/rankingRank 538,901X ?
Y ?????
- X ??
Y ???
?/???
?+ Y exists in X - Keep Y out X inside/virusRank 620,430X ??
Y ???
- X ?
Y ????
?/?- Remove Y off X - X answer with Y I (or me)/eyesRank 652,530Y ?
X ??????
- X ?
Y ???
?/?
?+ Kick out Y from X - Y remains in X body/fatigueRank 697,177Y ?
X ??????
- Y ?
X ?????
?/?
?+ X reassures Y - X betrays Y I/herRank: 749,916Hence, we think the effect of adding a new sam-ple from PROP-SCORE is smaller than that in PRO-POSED, because in PROPOSED we add to the train-ing data pattern pairs with both high and low (possi-bly negative) SVM scores.Finally, while the quality of the entailment pairsplays a very important role in the assumption thatwas the base of CDP , these results show that evena simple rule such as ?Use entailment pairs withSVM score over 0 to expand contradictions beforeranking them with CDP ?
is sufficient to make themethod work.
Though it may be possible to designa more complex CDP formula which takes entail-ment score into account, we did not explore this di-rection in this work.Comparison with an ILP-based method Finally,we would like to compare our method with an ILP-based method.
The interaction between contradic-tion and entailment that forms the basis for our ex-pansion method has a natural interpretation as an op-timization problem.
We thus compared our methodto the following ILP formulation of this interactioninspired by Berant et al(2011), using our test set:700Figure 5: Comparison between PROPOSED, BASE andBASE+ILP on a restricted test set (1,306 samples)(1) G = argmax?p6=q(e(p, q)??
)?Epq +(c(p, q)??
)?Cpq(2) s.t.
?p,q,r Epq + Cqr ?
Cpr ?
1(3) ?p,q Epq + Cpq ?
1(4) ?p,q Epq ?
{0, 1} (5) ?p,q Cpq ?
{0, 1}The objective in Equation (1) is a sum over theweights of every pair of patterns ?p, q?, where Epqindicates whether a pair ?p, q?
is an entailment pair(Equation (4)), andCpq indicates whether it is a con-tradiction pair (Equation (5)).
e(p, q) and c(p, q) arethe score given respectively by ENT and BASE, and?
is a prior defining the weight of a pair as neitherentailment nor contradiction that shall be set beforeany experimentation.
Equation (2) states the tran-sitivity relation which is the basis of our expansionmethod.
Finally, Equation (3) states that a given pat-tern pair cannot be a contradiction pair and an entail-ment pair at the same time.
Since our patterns areclass-dependent, we solved separate ILP instancesfor each semantic class pair.We drew a precision curve for each of BASE,PROPOSED and BASE+ILP.
To draw the curve forBASE+ILP, we incrementally raised the sample?snon-contradiction non-entailment prior ?
(more de-tails in Berant et al(2011)).
Because of the com-putational difficulty of ILP (NP-complete) and thesize of our data, the computation for the ILP-basedmethod ran out of memory on a 72GB machine for116 class pairs out of the 1,031 that our test set cov-ers.
For this reason, we only used the 1,306 samplesof the test set covered by the remaining 915 classpairs.
We also measured the performance of BASEand PROPOSED on the same restricted test set.Figure 5 shows that under these conditions theILP-based method performance resembles BASEand is worse than PROPOSED on all data points.PROPOSED performs slightly worse in this settingcompared to when classifying the whole of Popp,but this only means that its performance is good forthe 116 class pairs we ignored in this experiment.While this comparison is only made in a restrictedsetting, our expansion method still outperforms ILPand is clearly more scalable.
The ILP results couldbe improved by adding more constraints (contradic-tion is symmetric, entailment is transitive), but thiswould also make the problem even more intractablein terms of computational costs.4 FeaturesIn this section we present the features used in ourclassifiers, which are mainly categorized into three:surface features (i.e., those reflecting the patterns?content itself), features based on external lexical re-sources, and distributional similarity based features;all features are listed in Table 4.
ENT uses all thefeatures while BASE and EXP use all except for thedistributional similarity based ones.
The optimalityof the feature sets was confirmed through ablationtests using the development set (results omitted forthe sake of space).Since patterns with a contradiction or entailmentrelation are often superficially similar, for instance,in case structure or inflection, we use a number ofsurface features based on string similarity measures,extending the feature sets used by Malakasiotis andAndroutsopoulos (2007) for entailment recognition.They include bag-of-words features such as n-gramsand similarity scores concerning the bag-of-wordssuch as their Euclidian distance.To complement the surface features with knowl-edge about the content words, we used lexi-cal databases including such as antonymy, syn-onymy, entailment, or allography.
The presenceof such word pairs is usually a good indicator of(non-)contradiction or (non-)entailment at the pat-tern level.
More specifically, for any word pair?wp,wq?
taken from a pattern pair ?p, q?
we markthe presence of ?wp,wq?
in each of the lexical re-sources as a binary feature.
We used the Japaneselexical resources distributed by the ALAGIN Fo-rum3: the verb entailment database (117,000 verb3 http://www.alagin.jp/701Table 4: Features summary, computed over a pair of patterns ?p, q?surface Similarity measures: common elements ratios, Dice coefficient, Jaccard and discounted Jaccard scores, Cosine, Euclidian, Manhattan, Levenshteinand Jaro distances; computed over: the patterns?
1-, 2- and 3-grams sets of: characters, morphemes, their stems & POS; content words and stemsbinary feature for each of the patterns?
subtrees, 1- and 2-grams ; patterns?
lengths and length ratioslex.r.
entries in databases of verb entailments and non-entailments, synonyms, antonyms, allographs ; checked over: pairs of content words,pairs of content word stems, same for the reverse pattern pair ?q, p?dis.s.
Distributional similarity measures: Common elements ratios, Jaccard and discounted Jaccard scores, sets and sets intersection cardinality,DIRT (Lin and Pantel, 2001), Weeds (Weeds and Weir, 2003) and Hashimoto (Hashimoto et al 2009) scores; computed over: patterns?co-occurring noun pairs, POS tags of those, nouns co-occurring in each variable slot, nouns co-occurring with each unary sub-patternsother binary feature for each semantic class pair and individual semantic classespatterns frequency rank in the given semantic class pairpairs; Alagin ID A-2), the databases of synonyms,antonyms and meronyms (respectively 111,000,5000 and 2500 pairs; Alagin ID A-9), and the al-lographic word database (2.7 million pairs; AlaginID A-7).
We also used the information concerningallographic words in the dictionary of the morpho-logical analyzer JUMAN4.Distributional similarity values between patternsare based on the idea that patterns that appear insimilar contexts tend to have similar meanings andas such are useful to recognize entailment (Lin andPantel, 2001).
We computed as features several dis-tributional similarity measures on the sets of eachpattern?s co-occurring noun pairs and their POStags, of nouns co-occurring in each variable slot, andwith each of the pattern?s unary sub-patterns.We also added a few more uncategorizable fea-tures.
See Table 4 for more details.5 Related WorkA number of previous work dealt with the recogni-tion of contradictions between sentences.
Harabagiuet al(2006) proposed a contradiction detectionmethod that focuses on negation, antonymy andsome discourse information.
Kawahara et al(2010)also used negations and antonyms to extract con-trastive/contradictory statements from the web topresent users with a bird ?s-eye view of statementsabout a given topic.
Bobrow et al(2007) showeda method using logical forms with relatively preciseresults.
Ohki et al(2011) proposed a method to rec-ognize confinment, a novel semantic relation relatedto both entailment and contradiction.
While we donot deal ourselves directly with sentences, we expectthat the binary pattern pairs we acquire can play arole similar to that of basic linguistic resources such4 http://nlp.ist.i.kyoto-u.ac.jp/EN/index.php?JUMANas antonyms and negations in these works.
Closerto our work, Ritter et al(2008) presented a methodfor detecting contradictions between functional re-lations like ?X was born in Y?, but these constituteonly a part of the semantic relations expressed by thebinary patterns we deal with in this paper.Other works analyzed contradictions from lin-guistic/semantic viewpoints.
Voorhees (2008) ana-lyzed the contradiction recognition-task of the RTE3contest.
Magnini and Cabrio (2010) examined rela-tions between contradictions and textual entailmentsamples.
De Marneffe et al(2008) presented atypology of contradictions, and showed that con-tradictions can arise from a multitude of phenom-ena.
They showed contradictions based on lexical orworld knowledge are challenging and require a high-level understanding of language and/or the world.As stated in the introduction, these are the types ofcontradictions our method focuses on.6 ConclusionThis paper showed how to acquire a large number ofcontradiction pairs between lexico-syntactic binarypatterns by exploiting (1) the interaction betweencontradiction and entailment, and (2) excitation po-larities.
In the end, we could acquire 750,000 typedcontradiction pattern pairs with an estimated 80%precision.
The resulting contradiction pairs cov-ered ones deeply related to world knowledge suchas the pair ?
?X reassures Y?, ?X betrays Y??.
We ex-pect our work to lead to a high level analysis oftextual information, such as flagging unreliable in-formation or identifying important documents to besurveyed for understanding complex social prob-lems.
We plan to release the data we acquired tothe NLP community through the ALAGIN Forum5.5 http://www.alagin.jp/702ReferencesJ.
Berant, I. Dagan, and J. Goldberger.
2011.
Globallearning of typed entailment rules.
In Proceedings ofACL 2011, pages 610?619.D.
G. Bobrow, C. Condoravdi, R. Crouch, V. De Paiva,L.
Karttunen, T. H. King, R. Nairn, L. Price, andA.
Zaenen.
2007.
Precision-focused textual inference.In Proceedings of the ACL-PASCAL Workshop on Tex-tual Entailment and Paraphrasing, page 16?21.M.-C. De Marneffe, A. N. Rafferty, and C. D. Manning.2008.
Finding contradictions in text.
Proceedings ofACL 2008, page 1039?1047.S.
De Saeger, K. Torisawa, J. Kazama, K. Kuroda, andM.
Murata.
2009.
Large scale relation acquisition us-ing class dependent patterns.
In Proceedings of ICDM2009, page 764?769.S.M.
Harabagiu, A. Hickl, and V.F.
Lacatusu.
2006.Negation, contrast and contradiction in text process-ing.
In Proceedings of AAAI 2006, pages 755?762.C.
Hashimoto, K. Torisawa, K. Kuroda, S. De Saeger,M.
Murata, and J. Kazama.
2009.
Large-scale verbentailment acquisition from the web.
In Proceedingsof EMNLP 2009, volume 3, page 1172?1181.C.
Hashimoto, K. Torisawa, S. De Saeger, J.-H. Oh, andJ.
Kazama.
2012.
Excitatory or inhibitory: A new se-mantic orientation extracts contradiction and causalityfrom the web.
In Proceedings of EMNLP 2012.D.
Kawahara, S. Kurohashi, and K. Inui.
2008.
Grasp-ing major statements and their contradictions towardinformation credibility analysis of web contents.
InProceedings of WI-IAT 2008, volume 1, page 393?397.D.
Kawahara, K. Inui, and S. Kurohashi.
2010.
Iden-tifying contradictory and contrastive relations betweenstatements to outline web information on a given topic.In Proceedings of COLING 2010, page 534?542.J.
Kazama and K. Torisawa.
2008.
Inducing gazetteersfor named entity recognition by large-scale clusteringof dependency relations.
Proceedings of ACL 2008,page 407?415.J.
Kloetzer, S. De Saeger, K. Torisawa, M. Sano,C.
Hashimoto, and J. Gotoh.
2013.
Large-scale acqui-sition of entailment pattern pairs.
In Information Pro-cessing Society of Japan (IPSJ) Kansai-Branch Con-vention.S.
Kurohashi and M. Nagao.
1994.
KN parser: Japanesedependency/case structure analyzer.
In Proceedingsof the Workshop on Sharable Natural Language Re-sources, page 48?55.J.
R. Landis and G. G. Koch.
1977.
The measurement ofobserver agreement for categorical data.
Biometrics,page 159?174.D.
Lin and P. Pantel.
2001.
Dirt - discovery of inferencerules from text.
In Proceedings of the ACM SIGKDDConference on Knowledge Discovery and Data Min-ing, pages 323?328.B.
Magnini and E. Cabrio.
2010.
Contradiction-focusedqualitative evaluation of textual entailment.
In Pro-ceedings of the Workshop on Negation and Speculationin Natural Language Processing, page 86?94.P.
Malakasiotis and I. Androutsopoulos.
2007.
Learningtextual entailment using SVMs and string similaritymeasures.
In Proceedings of the ACL- PASCAL Work-shop on Textual Entailment and Paraphrasing, page 42?47.K.
Murakami, E. Nichols, S. Matsuyoshi, A. Sumida,S.
Masuda, K. Inui, and Y. Matumoto.
2009.
State-ment map: assisting information crediblity analysisby visualizing arguments.
In Proceedings of the 3rdworkshop on Information credibility on the web, page43?50.
ACM.M.
Ohki, S. Matsuyoshi, J. Mizuno, K. Inui, E. Nichols,K.
Murakami, S. Masuda, and Y. Matsumoto.
2011.Recognizing confinement in web texts.
In the Pro-ceedings of the Ninth International Conference onComputational Semantics, page 215?224.A.
Ritter, D. Downey, S. Soderland, and O. Etzioni.2008.
It?s a contradiction?no, it?s not: a case studyusing functional relations.
In Proceedings of EMNLP2008, pages 11?20.S.
Schoenmackers, O. Etzioni, D. S Weld, and J. Davis.2010.
Learning first-order horn clauses from web text.In Proceedings of EMNLP 2010, page 1088?1098.I.
Szpektor, E. Shnarch, and I. Dagan.
2007.
Instance-based evaluation of entailment rule acquisition.
InProceedings of ACL 2007, volume 45, page 456?463.E.
M. Voorhees.
2008.
Contradictions and justifications:Extensions to the textual entailment task.
In Proceed-ings of ACL 2008, page 63?71.J.
Weeds and D. Weir.
2003.
A general framework fordistributional similarity.
In Proceedings of EMNLP2003, page 81?88.
Association for ComputationalLinguistics.703
