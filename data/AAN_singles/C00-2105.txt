Robust  German Noun Chunk ingWi th  a Probab i l i s t i c  Context -F ree  GrammarHelmut  Schmid  and Sab ine  Schu l te  im Walde*Institut fiir Maschinelle SprachverarbeitungUnivers i tS t  S tut tgar tAzenbergst ra f ie  12, 70174 Stut tgar t ,  Germany{schmid, s chulte}@ims, uni-stuttgart, deAbst rac tWe present a noun chunker for German which isbased on a head-lexicalised probabilistic context-fl'ee grammar.
A manually developed grammarwas semi-automatically extended with robustnessrules in order to allow parsing of unrestricted text.Tile model parmncters were learned from unlabellcdtraining data by a probabilistic ontext-fl'ee parser.For extracting noun chunks, the parser generatesall possible noun chunk analyses, scores them witha novel algorithm which maximizes tile best chunksequence criterion, and chooscs the most probablechunk sequence.
An evaluation of the chunker on2,140 hand-annotated noun chunks yielded 92% re-call and 93% precision.1 In t roduct ionA fro'lilt oh'unicef i narks  the noun chunks in a sen-tence as in the tbllowing example:(Wirtschaftsbosse) mit (zweitblhaftem Ruf)economy (:hef~ with doubtable reputationsind an (der in (Engt)Sssen) mlgewandten Fiihrung)are in the in bottlenecks apl)lied guidance(des Landes) beteiligt.of the country involved.
'Leading economists with doubtable reI)u-tations are involved in guiding the countryin times of bottlenecks.
'A tool which identifies noun chunks is useflfl forterm extraction (most technical terms are nouns orcomI)lex noun groups), for lexicograt)hic lmrposes(see (\]~panainen a d JSrvinen, 1.998) on syntacti-cally organised concordancing), and as index termsfor information retrieval.
Chunkers may also markother types of chunks like verb groups, adverbialt)hrases or adjectival I)hrases.Several methods have been develoI)ed tbr nounchunking.
Church's noun phrase tagger (Church,1988), one of the first; noun ehunkers, was based on aHidden Markov Model (HMM) similar to those used* Thanks  to Mats  Rooth  and  Uli I Ieid for many helpfl f l  com-ir lonts.for part-of-speech tagging.
Another HMM-bascd ap-proach has been developed by Mats Rooth (Rooth,1992).
It integrates two HMMs; one of them mod-els noun chunks internally, the other models thecontext of noun chunks.
Abney's cascaded finite-state parser (Almey, 1996) also contains a process-ing step which recognises noun chunks and othertypes of chunks.
Ramshaw and Marcus (Ramshawand Marcus, 1995) successflflly applied Eric Brill'stransformation-based l arning method to the chunk-ing problem.
Voutilainen's NPtool (Voutilainen,1993) is based on his constraint-grammar system.Finally, Brants (Brmlts, 1999) described a Ger-man clumker which was implemented with cascadedMarkov Models.In this 1)aper, a prol)abilistic ontext-free parseris aI)I)lied to the noui, chunking task.
Tile Ger-man grammar used in the experiments was semi-autolnati(:ally extended with robustness rules in o fder to be able to process arbitrary int)ut.
The gram-mar parameters were trained on unlabelled ata.
Anovel algorithm is used for noun chunk extraction.It maximises the t)robability of the chunk set.The tbllowing section introduces the grammarfi'alnework, followed by a description of the chunk-ing algorithm in section 3, and the experiments andtheir evaluation in section 4.2 The  GrammarThe German grammar is a head-lexicalised I)roba-bilistic context-free grainmar.
Section 2.1 definesprobabilistic ontext-ti'ee grammars and their head-lexicalised refinement.
Section 2.2 introduces ourgrmnmar architecture, focusing on noun chunks.The robustness rules for the ehunker a.re describedin section 2.3.2.1 (Head-Lexiealised) Probab i l i s t ieContext-Free GrammarsA probabilistic context-free g~tmmar (PCFG) is acontext-free grmnmar which assigns a probability Pto each context-fl'ee grammar ule in the rule setR.
The probability of a parse tree T is definedas \[I,.eRP(,.
)'"l, whore I"1 is the number of timesrule r was applied to build T. The parmneters of726PCFGs ca:: be learned f'rom unparsed corpora us-ing the Inside-Outside algorithm (Lari and Young,1990).Hcad-lcxicaliscd probabilistic contczt-frcc .qra?lt-mar;s (It-L PCFG) (Carroll and Rooth, 1998) ex-tend the PCFG al)proach by incorl)orating informa-tion about the lcxi('al head of constituents into thet)robal)ilistic model.
: Each node in a parse of a H-L PCFG is labelled with a ca.tegory and the lexi-cal head of the category.
A H-L PCFG rule lookslike a PCFG rule in which one of the daughtershas been marked as the head.
The rule i)robabili-ties l~.uze(C --+ alC) m'e replaced by lexicalised ruleprobabilities l~,~t~(C -~ o~\]C, h) where h is the lex-ical head of the lnother constituent C. The prob-ability of a rule therefore depends not only on thecategory of the mother node, but also on its lexi-cal head.
Assume that the grmnmar has two rulesVP -+ V NP and VP ---> V. Then the transitive verbbuy should have a higher probability for the for-mer rule whereas the latter rule shouhl be morelikely for intrm:sitive verbs like sh'.cp.
II-L PCFGsincorporate another type of parameters called lexi-cal choice probabilities.
The lexical choice probabil-ity l~hoi,,~ (hd\]C,z, G,~, h,,,, ) rel)reseitt,s the prolml)ilitythat a node of category Cd with a mother node ofcategory C,~ and lexical head h,,,, bears the texicalhead h,d.
The probability of a parse tree is obtainedby multiplying lexicalised rule protml)ilities and lex~ical choice ln'obal)ilities for all nodes.
Since it ispossible to transform H-L PCFGs into PCFGs, thePCFG algorithms are ai)l)licable to I\]:-L PCF(4s.2.2 Noun Chunks  in the German GrammarCurrently, the German grammar contains d,619 rulesand covers 92% of our 15 million words of verbfinal and relative clauses ~.
Tl:e structmal :lOtlnchunk concel)t in tim grammar is defined accord-ing to Almey's chunk style (Abney, 1991) who de-scribes chunks as syntactic units which correspondin some way to prosodic 1)atterns, containing a con-tent word surrounded t)y some function word(s): allwords from the beginning of the noun 1)hrase to thehead noun are included.
:~ The difl'erent kinds of nounchunks covered by our grmnmar are listed below andillustrated with exmnples:.. a combination of a non-obligatory deternfiner,optional adjectives or cardinals and the noun1Other types of lexicalised PCFGs have been (h!scrib('.d in(Charniak, 1997), (Collins, 1997), (G'oodman, 1997), (Chcll)aand .lelinek, 1998) mid (Eisner and Sat:a, 1999).2'l'he restricted (:orl)ora were exl;ra(:ted mltomatically fromthe llugc German Corpus (I1GC), a collection of Germannewsl)al)ers as well as sl)ecialiscd magazines ibr industry, law,computer science.3As you will sc'e below, there is one exception, noun chunksrefinc.d by a proper nanm, which end with the.
name insteadof the head noun.itself:(1) cine gutc Meca good idea(2) viclcn Menschcnfor many 1)eot)le(3) dercn kiinstliche Stimmewhose m'tificial voice(4) elf Ladungeneleven cargos(5) Wasscrwaterand prepositional phrases where the definite m'-ticle of the embedded noun chunk is morpholog-ically combined with a 1)rel)osition, so the purenoun chunk could not be set)arated:(6) zum Schlussat the end?
personal pronouns: ich (I), mir (me)?
reflexive pronouns: reich (myself), sich (him-self/herself/itself)?
possessive pronou: l s :(7) Mcins ist sauber.Mine is clean.?
demonstrative t ) ronouns :(8) Jcncr ffi.hrt viel sclmeller.That one goes much faster.?
indefinite 1)ronom~s:(9) Einige sind durchgefifllen.Some failed.?
relative 1)ronouns:(10) Ich mag Menschen, die ehrlich sind.I like peol)le who are honest.?
nonfinalised adjectives: Wichtigcm (importantthings)?
l)roper nmnes: Christoph, Kolumbus?
a noun chunk refined by a prol)er name:(1.1.)
der Erobere.r Christoph Kolumbusthe conquerer Christoph Cohlmbus?
cardinals indicating a ycm':(1.2) Ich begann 1996.I started 1996.The chunks may be recursive in case they appear asc, omplement of an adjectival phrase, as in (dcr (iraRc.qc, 0 wartendc 5'oh, n) (the son who was waiting inthe rain).Noun chunks have features for case, without fi:r-ther agreement features for nouns and verbs.
Thecase is constrained by the time:ion of the nounchunk, as verbal or adjectival co:nplement with nom-inative, accusative, dative or genitive case, as mod-ifier with genit ive case, or as part of a prel:ositional727phrase (also in the special case representing a prepo-sitional phrase itself) with accusative or dative case.Both structure mid case of noun phrases may beambiguous and have to be disambiguated:?
ambiguity concenfing structure:diesen (this) is disregarding the context ademonstrative pronoun mnbiguous between rep-resenting a standalone noun chunk (cf.
example(8)) or a determiner within a noun chunk (cf.example (2))?
mnbiguity concerning case:die Beitriige (the contributions) is disregardingtile context ambiguous between onfinative midaccusative caseThe disambiguation is learned during grammartraining, since the lexicalised rule probabilities aswell as the lexical choice probabilities tend to enforcethe correct structure and case information.
Con-sidering the above examples, the trained grmnmarshould be able to parse diesen I(rie9 (this war) asone noun chunk instead of two (with diesen repre-senting a standalone noun clmnk) because of (i) thepreferred use of denlonstrative pronouns as deter-miners (+ lexicalised rule probabilities), and (ii) thelexical coherence between the two words (~ lexicalchoice probabilities); in a sentence like er zahlte dieBeitr@e (lie paid the contributions) the accusativecase of the latter noun chunk should be identifiedbecause of the lexical coherence between the verbzaMen (pay) and the lexical head of the subcate-gorised noun phrase Beitrag (contribution) as re-lated direct object head (+ lexical choice probat)il-ides).2.3 Robustness RulesTile Gernlan grammar covers over 90% of tile clausesof our verb final and relative clause corpora.
Thisis sufiqcient for the extraction of lexical infornlation,e.g.
the subcategorisation f verbs (see (Beil et al,1999)).
For chunking, however, it is usually neces-sary to analyse all sentences.
Therefore, the gram-mar was augmented with a set of robustness rules.Three types of robustness rules have been consid-ered, namely unigram rules, bigram rules aud tri-gram rules.Unigram rules are rules of the form X -+ YP X,where YP is a grammatical category and X is a newcategory.
If such a rule is added for each grammarcategory 4, the coverage is 100% because the gram-mar is then able to generate any sequence of categorylabels, hi practice, some of the rules can be omittedwhile still retaining full coverage: e.g.
the rule X -+4Also needed are two rules which start and terminate the"X chain".
We used the rules T0P --+ START X and X --+ END.START and END expand to SGML tags which mark the begin-ning and the end of a sentence, respectively.ADV X is not necessary if the grmnmar already con-tains tile rules ADVP --+ ADV and X --+ ADVP X. Uni-gram rules are insensitive to their context so that allpermutations of the categories which are generatedby the X chain have the stone probability.The second type of robustness rules, called trigramrules (Carroll and Rooth, 1998) is more context sen-sitive.
Trigram rules have the form X:Y -+ Y Y:Zwhere X, Y, Z are categories and X:Y and Y:Z arenew categories.
\]Mgram rules choose the next cat-egory on the basis of the two preceding categories.Therefore the number of rules grows as the numberof categories raises to the third power.
For exam-ple, 125,000 trigrmn rules are needed to generate 50different categories in arbitrary order.Since unigram rules are context insensitive andtrigram rules are too numerous, a tlfird type of ro-bustness rules, called bi9ram rules, was developed.A bigram rule actually consists of two rules, a ruleof the form :Y --+ Y Y: which generates the COl>stituent Y deternlinistically, and a rule Y: -~ :Zwhich selects the next constituent Z based on thecurrent one.
Given n categories, we obtain n rulesof the first form and n 2 rules of the second fornl.Even when categories which directly project o someother category were oufitted in the generation of thebigram rules for our Germm~ grmnmar, the num-ber of rules was still fairly large.
Hence we gener-alised some of the grammatical categories by addingadditional chain rules.
For example, the preposi-tional phrase categories PP.
Akk : an, PP.
Akk : auf,PP.Akk:gegen etc.
were generalised to PPX byadding the rules PPX --~ PP.Akk:an et(:.
Instead ofn + 1 t)igram rules for each of tlm 23 prepositionalcategories, we now obtained only n + 2 rules withthe new category PPX.
Altogedmr, 3,332 robustnessrules were added.3 Chunk ingA head-lexicalised probabilistic ontext-fl'ee parser,called LoPar (Schnfid, 1999), was used for pa.rs-ing.
The f'unctionality of LoPar encompasses lmrelysynlbolic parsing as well as Vitcrbi parsing, inside-outside computation, POS tagging, chunking andtraining with PCFGs as well as H-L PCFGs.
Be-cause of the large number of parameters in l)al'tic-ular of H-L PCFGs, the parser smoothes the prob-ability distributions in order to re,old zero proba-bilities.
The absolute discounting method (Ney etal., 1994) was adapted to fractional counts for thispurpose.
LoPar also supports lemmatisation of thelexical heads of a H-L PCFG.
Tile input to theparser consists of ambiguously tagged words.
Thetags are provided by a German morphological mlal-yser (Schiller and St6ckert, 1995).The best chunk set of a sentence is defined as tileset of chunks (with category, start mid end position)728for which the stun of the prolmbilities of all parseswhich c, ontain exactly that chunk set is maximal.The chunk set of the most likely parse (i.e.
Viterbiparse) is not necessarily the best chunk set accordingto this definition, as the folh)wing PCFG shows.S -~A 0.6 B -+x 1.0S -~ B 0.4 C - -+x  1.0A -~C 0.5 l ) -+x  1.0A -+ D 0.5This grmmnar generates the three parse trees (S(A (C x ) ) ) ,  (S (A (D x ) ) ) ,and  (S (B x)) .
Theparse tree probal)ilities are 0.3, 0.3 and 0.4, respec-tively.
The last parse is therefore the Viterbi parse ofx.
Now assume that {A,B} is the set; of chunk cate-gories.
The most likely chunk set is then { (A, 0 ,1)}because the sum of the l/robal/ilities of all parseswhich contain h is 0.6, whereas the sum over tit(;l/robal/ilities of all 1)arses containing B is only 0.4.computeChunks i a slightly simlllified l)seudo-code version of the actual chunking algorithm:computeChunks(G, Prul,:)hfitialize float array p\[Gv\]Initialize chunk set array.ch.
'unks\[Gv\]for each vertex v ill GV in bottom-up order doif v is an or-node thenInitialize float array prob\[ch:unk.
@l(v)\]\] to 0fin" each daughter 'u C d(v) do-,-p\[',,,\]<- v,.ol,\[dp\[,,,\] +-elsev\[q <- II,<,,(,,t 2,\[,*\]<-if v is labelled with a chunk category (7 thench/,,,,a:.~\[v\] +- ~-l,,,,,,~a:.~\[,,\] U {(C, .,'t,,'t(,,), c,,.d(v))}return ch,'.,Tzks\[,'oot(G)\]computeChunks takes two arguments.
The first, ar-gument is a parse fore.st G which is represented as anand-or-graph.
Gv is the set of vertices.
The secondargument is the rule probability vector, d is a flmc-tion which returns the daughters of a vertex.
The al-gorithm comtmtes the best elmnk set; ch,,,m, ks\[v\] andthe corresponding I)robability ply\] for all vertices vin bottom-up order, chunks\[d(v)\] returns the set ofchunk sets of the daughter nodes of vertex v. r'ule(v)reSurns tile rule which created v and is only definedtbr and-nodes, start(v) and end(v) return the startaml end position of the constituent represented byV.The chunking algorithm was extmrimentally eoltl-pared with chunk extraction fl'om Viterbi parses.
In35 out of 41 ewfluation rims with different parame-ter settings '~, the f-score of tile chunking algorithmS'Fhe runs differed wrt.
training strategy and number ofiterations.
See section 4 for details.was better than that of the Viterbi algorithm.
Theaverage f-score of the chunking algorithm was 84.7 %compared to 84.0 % for the Viterbi algorithm.4 ExperimentsWe performed two main chunking experiments, hfi-tially, the parser trained the chunk grammar basedon the restricted grmnmar described in section 2 ac-cording to tbur different training strategies.
A pre-ferred training strategy was then applied to inves-tigate the potential of grammar efim;ment and ex-tended training data.4.1 Tra in ingIll the frst  exlmriment, the chunker version of thegrmmnar was trained oil a corpus comprising a 1million word subcortms of relative clauses, a 1 mil-lion word subeorpus of verb final clauses and 2 mil-lion words of consecutive text.
All data had beenextracted from the Huge German Corpus.
The testdata used for the later evahmtion was not includedin the training corpus.For training strategy 1, the elmnker gralnmar wasfirst; trained on the whole cortms in mflexiealisedmode, i.e.
like a PCFG.
The tmrmneters were rees-timated once in the middle and once at the end ofthe eorlms.
In the next stel) , the grammar was lexi-calised, i.e.
the parser computed |;tie parse probabil-ities with the unlexicalised model, lint extracted De-quencies for the lexicalised model.
These fl'equencieswere summed over the.
whole eorl)us.
Three moreiterations on the whole corpus tbllowed in whichthe parmneters of the lexicalised model were rees-timate(t.The parameters of the unlexicalised chunker gram-mar were initialised in the following way: a fl'e-queney of 7500 was assigned to all original granunarrules and 0 to the majority of robustness rules.
Theparmneters were then estimated on the basis of theseDequencies.
Because of the smoothing, the t)roba-bilities of the robustness rules were small lint notzero.For training strategy 2, the chunker rules wereinitialised with frequencies fl'om a grammar withoutrobustness rule extensions, which had been trainedmflexiealised on a 4 million subeortms of verb finalclauses and a 4 million word subcorpus of relativec lauses .Training strategy 3 again set the fi'equency of theoriginal rules to 7500 and of tile robustness rules to0.
The parser trained with three unlexicalised iter-ations over the whole training corpus, reestimatingthe parameters only at the end of the corpus, ill o fder to find out; whether the lexicalised probabilisticparser had been better than tile fully trained mflexi-calised parser on the task of chunk parsing.
Trainingstrategy 4 repeated this procedure, but with initial-729ising the chunker frequencies on basis of a trainedgramnlar.For each training strategy, further iterations wereadded until the precision and recall values ceased toimprove.For the second part of the experiments, the basegrammar was extended with a few simple verb-firstand verb-second clause rules.
Strategy 4 was appliedfor training the ehunker(A) on the same training corpus as betbre, i.e.
2million words of relative and verb final clauses,and 2 million words of unrestricted corpus datafrom the HGC,(B) on a training corpus consisting of 10 millionwords of unrestricted corpus data from theHGC.4.2 Eva luat ionThe evaluation of tile ctmnker was carried outon noun chunks from 378 unrestricted sentencesfrom the German newspaper Frankfu~'ter Allgcmci~cZeitun9 (FAZ).
Two persons independently anno-tated all noun chunks in the corpus -a  total of 2,140noun chunks-, according to the noun chunk deft-nition in section 2.2, without considering rammarcoverage, i.e.
noun chunks not actually covered bythe grammar (e.g.
noun chunk ellipsis such as dieklcinc~ \[ \]N) were annotated as such.
As labels, weused the identifier NC plus case information: NC.
Nom,IqC.
Ace, NC.
Dat, NC.Gen.
In addition, we includedidentifiers for prepositional phrases where the prepo-sition is nlorphologically merged with the definitearticle, (el.
example (6)), also including case infor-mation: PNC.Acc, PNC.Dat.For each training strategy described in section 4.1we evaluated the chunker before the training processand after each training iteration: the model in itscurrent training state parsed the test sentences andextracted the most probable clnmk sequence as de-fined in section 3.
We then compared the extractednoun elmnks with tile haud-ammtated data, accord-ing to* the range of the chunks, i.e.
(lid the chunkerfind a chunk at all?.
the range and the identifier of the chunks, i.e.did the ehunker find a chunk and identify thecorrect syntactic ategory and case?Figures 1 and 2 display the results of the eval-uation in tile first experiment, ?
according to nounchunk range only and according to noun chunkrange, syntactic category and case, respectively.Bold font highlights the best versions.Training strategy 2 with two iterations of lexi-calised training produced tile best f-scores tbr noun6The lexieatised ehunker versions obtained by strategy 2were also utilised for parsing the test sentences unlexiealised.chunk boundary recognition if unlexicalised parsingwas done.
The respective precision and recall val-ues were 93.06% and 92.19%.
For recognising nounchunks with range, category and case, the best; chun-ker version was created by training strategy 4, afterfive iterations of unlexicalised training; precision andrecall values were 79.28% and 76.75%, respectively.From the experimental results, we can concludethat:1. initialisation of the chunker grammar frequen-cies on the basis of a trained grammar improvesthe untrained version of the elumker, but thedifference vanishes in the training process2.
unlexicalised parsing is sufficient for noun chunkextraction; for extraction of chunks with caseilfformation, unlexicalised training turned outto be even more successflfl than a combinationwith lexicalised trainingFigures 3 and 4 display the results of the evalu-ation concerning the second experilnent, comparedto the initial w, lues from the first experiinent.Extending the base grammar and the training cor-pus slightly increased precision and recall values forrecognising noun chunks according to range only.The main inlprovement was ill noun chunk recogni-tion according to range, category and case: precisionand recall values increased to 83.88% and 83.21%,respectively.4.3 Fai lure Ana lys i sA comparison of the parsed noun chunks with themmotated ata showed that failure in detecting anoun chunk was mainly caused by proper names,for exalnple Neta~j(E~,~t, abbreviations like OSZE, orcomposita like So~tth Ch, ina Mor,ti,tg Post.
The di-versity of proper names makes it difficult for tilechunker to learn them properly.
On the one hand,the lexieal infornl~tion for proper names is unreliablebecause Inany proper na lnes  were not  reeognised assuch.
On the other hand, most prot)er names aretoo rare to learn reliable statistics tbr them.Minor mistakes were cruised by (a) articles whichare morphologically identical to noun chunks con-sisting of a pronoun, for example den Rc,t,t~,e,'~ (tiLepensionersd(,t,) was analysed as two noun clumks, dcTt(demonstrative pronoun) and Rent~t,e~'7t, (b) capitalletter eonfnsion: since Gerinan nouns typically startwith capital etters, sentence beginnings are wronglyinterpreted as nouns, for example Wiirden as theconditional of the auxiliary wcrdc~ (to become) isinterpreted as the dative case of Wib'dc (dignity), (e)noun chunk internal umctuation as in seine ' Pa~'t-,tcr' ' (his ' partners ').Failure in assigning the correct; syntactic cate-gory and case to a noun chunk was mainly causedby (a) assigning accusative case instead of nomina-tive case, and (b) assigning dative case or nomina-730la':~inedI(;xllex2I(;x3lex4lex5lexOlexl.lo, x2lc, x3Strategy 1 Str~ttegy 2 -l)~trsed unlex Str~tegy 3 Strategy 41)roe I'e{'.83.63%91.88%89.13%88.37%88.25%88.17%83.63%89.62%89.71%89.52%89.57%89.62%prec r(~c90.22% 99.18%92.84% 91.58%90.12% 90.41%88.97% 89.76%89.79% 90.46%89.d2% 90.13%\])I'(!C 1"(~(~90.22% 00.18%92.84% 9J .58%93.01% 91.49%93.02% 91.67%93.06% 92.19%.93.05% 92.05%prec leC83.
(13% 83.63%:H .aa% 8:).62%:)2.55% 90.04%92.78% 90.22%l) r('.c l'eC90.22% 90.18%92.84% 91.58%:)3.01% 9\] .49%92.95% 91.25%93.
(19% 90.79%93 .29% 9(I.32%Figure 1: Comt)aring training strategies: noun chunk (',valuation according t;o range onlySt;l'~tl;(;gy 1 Strategy 2 parsed lmlex Stl';tl;(.~gy 23 Strategy 4l)re(: re(:untraille(1unlexlunlex2unlex:~unlex4ulllox5lex0lexllex2lex363.52%74.50%7:{.68%72.02%72.76%711.97%63.52%78.11%73.15%72.97%73.85%73.15%\])re(" I'(\]C72.02% 71.98%75.87% 74.84%75.10% 75.35%74.69% 75.35%75.2(i% 75.82%75.03% 75.63%\] )F(!C r(~C72.02% 71.98%75.87% 74.84%78.27% 76.99%77.27% 7(1.15%77.48% 76.75%77.45% 7(i.61%l)l'(!
(; 1"(IC63.52% 63.52%74.50% 73.t 1%76.88% 74.79%77.97% 75.82%pl'OC F(~C72.02% 71.98%75.87% 74.84%78.27% 76.99%78.70% 77.27%78.80% 76.85%79.28% 76.75%Figure 2: Comi)aring training strategies: noun chun\]{ evahtal;ion according l;o range and labeltive case instead of a(:cusal;ive (:an(;.
2}he confl,sionbetween l~ominal;ive an(t accusative case is due (;()1;he facl; that both cases at(', (~xI)rc'ss(.
'(t t)y i(lenl;icalm()ri)tlology in l;he f(;minine and neul;ra\] genders inG(n'man.
The morl)hologi(" similarity l)ei:ween a(:-(:u,;ative and (lative is less substantial, but esl)eciallyprol)er names and bar(; nouns are sl;ill sul)jecl; 1;o (:(m-fllsion.
As |;lie evaluation resull;s show, the (lisLinc-tion between 1;he cases could be learned in general,bul; morl)hological similaril;y and in addil;ion l;he rel-atively Dee word order in German impose high de-mure(Is on the n(;(:essary i)rot)a|)ilil;y model.5 SummaryWe t)resenl;ed a German noun ('hunker for unre-stricted text.
The chunker in based on a head-lexicalised probabilistic context-free grammar and|;r~,ined on unlal)elled data.
~\]'he base grammar wassemi-automatically augmenl;ed with robust, heSS rulesin order to cover unrestricted input.
An algorit;hmfor chunk exl, ract, ion was develoi)ed which maximisesthe probabilil;y of l;he chunk set;s rather than theprobability of single t)arses like l;he Vil;erl)i algo-rithm.German noun chunks were del;ected wil;h 93% 1)re-cision and 92(~) re(:all.
Asking the clmnker to addi-tionally identil~y the syntactic ategory and l;he caseof the chunks resulted in recall of 83% and precisionof 84~).
A COml)arison of different training strate-gies showed that unlexicalised parsing inforlnationxv~s sufIi('ienl; for noun chunk extra(:l;ion wil;h andwil;ho111; (:~s('.
informal;ion.
The base gralltllt~r playedan iml)orl;ant role in the chunker dev(dot)ment: (i)building the (:hunker on |,11(; basis of an ~dreadytrain(~(t gr~mmmr iml)rov(~d the chtmker rules, and(ii) relining l;he base grammar wil;h even simple verb-tirs\[; and verl)-se(:ond rules improved accuracy, so itshould \])e worthwhile to flirt;her extend lhe grammarrules.
Increasing l;he ~mlounl; of training (tal;a alsoimproved noun ('hunk r(;cognition, especially casedisaml)iguat;ion.
I~(;IA:er heuristi(:s for guessing theI)arts-of-st)eech of unknown words should flu'ther im-prove l;he noun chunk recognition, since lnalk~, errorswere ('ause(1 l)y llnk\]~own words.ReferencesSteven Abney.
1991.
Parsing by Chunks.
In RobertBerwick, Steven Almey, and Carol Tenny, editors,Pri'~tciplc-Bascd ParsiTt.q.
Kluwer Academic Pul)-lishers.St;even Almey.
1996.
Partial Parsing via Finite-St;ate Cascades.
In ProcccdiTt.qs of the \]~;SSLLI '96Rob't, st Pa,;s'i~zq Wo,'t~shop.Franz 13eil, Glenn Carroll, Det, lef Prescher, StefimRiezler, and Mal;s ll,ooth.
1999.
Inside-OutsideEstimation of a Lexi('alize(t PCFG for German.In ProceediT~,.qs of th, e 37th Annual Mceti,z!l of theACL, pages 269-276.731untrainedunlexlreflex2unlex3reflex4unlex5unlex6unlex7Strategy 4Initial A Bpree rec prec t}rec rec90.22% 90.18%92.84% 91.58%93.01% 91.49%92.95% 91.25%93.09% 90.7{}%93.29% 90.32%90.43%91.65%92.45%92.64%93.11%93.20%90.60%91.35%91.58%91.21%91.07%91.02%90.43%91.52%91.89%92.21%92.73%92.73%92.91%92.83%Figure 3: Granunar and training data extensions: noun chunk evaluationrec90.60%9\].35%91.67%91..86%91..86%91.86%91.96%92.10%according to range onlyuntrainedunlexlunlex2unlcx3unlcx4unlex5unlex6unlex7Strategy 4Initial A Bprec rec prec rec 1)roe ree72.02% 71.98%75.87% 74.84%78.27% 76.99%78.70% 77".27%78.80% 76.85%79.28% 76.75%74.42%78.51%80.74%81.24%81.83%81.85%74.56%78.25%79.98%79.98%80.03%79.93%74.42%77.60%79.89%81.17%82.44%82.53%82.94%88.88%74.56%77.46%79.70%80.87%81.67%81.76%82.09%83.21%Figure 4: Grammar and trailfing data extensions: noun chunk evaluation according to range mid labelThorsten Brants.
1999.
Cascaded inarkov models.Ill Proceedings of EA CL '99.Glenn Carroll and Mats Rooth.
1998.
Valence In-duction with a Head-Lexicalized PCFG.
In Pro-ccedings of Third Conference on Empirical Meth-ods in Natural Language Processing.Eugene Charniak.
1997.
Statistical Parsing with aContext-Free Granunar and Word Statistics.
InProceedings of the l~th National Confcrence onArtificial Intelligence.Ciprian Chelba and Frederick Jelinek.
1998.
Ex-ploiting Syntactic Structure for Language Mod-eling, hi Proceedings of the 35th Annual Meetingof the A CL.Kenneth W. Church.
1988.
A Stochastic Parts Pro-granl and Noun Phrase Pm'ser for unrestrictedText.
In Proceedings of the Second Conference onApplied Natural Language Processing, pages 136-143.Michael Collins.
1997.
Three Generative, Lexi-calised Models for Statistical Parsing.
In Proceed-ings of the 35th Annual Meeting of the A CL.Jason Eisner and Giorgio Satta.
1999.
EfficientParsing for Bilexical Context-Free Grmmnars andHead Automaton Grammars.
In Procecdings ofthe 37th Annual Meeting of the ACL, pages 457-464.Joshua Goodman.
1996.
Parsing Algorithms andMetrics.
In Proceedings of the 34th Annual Meet-ing of the ACL, pages 177-183.Joshna Goodman.
1997.
Probabilistic FeatureGrammars.
In Procecdings of the 5th Interna-tional Workshop on Parsing Technologies, pages89-100.K.
Lari and S. Young.
1990.
The Estimationof Stochastic Context-Free Grmmnars using theInside-Outside Algorithm.
Computation Specchand Language Proccssing, 4:35-56.Herlnann Ney, U. Essen, and R. Kneser.
1994.On Structuring Probabilistic Dependencies inStochastic Language Modelling.
Computer Speechand Language, 8:1 38.L.
Ramshaw and M. Marcus.
1995.
Text Chunkingusing Transtbrlnation-Based Learning.
Ill Pro-ccedings of thc Third Workshop on Vcry LaTyeCorpora, pages 82-94.Mats Rooth.
1992.
Statistical NP Tagging.
Unpub-lished manuscript.Anne Schiller and Chris StSckert, 1995.
DMOR.Institut fiir Maschinelle Spraehverarbeitung, Uni-versit~t Stuttgart.Hehnut Schmid.
1999.
Lopar: Design and hn-plementation.
Technical report, Institut fiirMaschinelle Sprachverarbeitung, Universit'gtStuttgArt.Pasi Tapanainen and Time JSrvinen.
1998.
De-pendeney Concordances.
International Journal ofLexicography, 11(3):187-203.Atro Voutilainen.
1993.
NPtool, a Detector of En-glish Noun Phrases.
In Proceedings of the Work-shop on Vcry Large Corpora, pages 48-57.732
