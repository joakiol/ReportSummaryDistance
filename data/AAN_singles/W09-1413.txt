Proceedings of the Workshop on BioNLP: Shared Task, pages 99?102,Boulder, Colorado, June 2009. c?2009 Association for Computational LinguisticsBioEve: Bio-Molecular Event Extraction from Text Using SemanticClassification and Dependency ParsingSyed Toufeeq Ahmed, Radhika Nair, Chintan Patel and Hasan DavulcuSchool of Computing and InformaticsArizona State UniversityTempe, Arizona{toufeeq, ranair1, chpatel, hdavulcu}@asu.eduAbstractIn this paper, we present BioEve a fully auto-mated event extraction system for bio-medicaltext.
It first semantically classifies each sen-tence to the class type of the event mentionedin the sentence, and then using high coveragehand-crafted rules, it extracts the participantsof that event.
We participated in Task 1 ofBioNLP 2009 Shared task, and the final eval-uation results are described here.
Our exper-imentation with different approaches to clas-sify a sentence to bio-interaction classes arealso shared.1 IntroductionHuman genome sequencing marked beginning of theera of large-scale genomics and proteomics, whichin turn led to large amount of information.
Lotsof that exists (or generated) as unstructured text ofpublished literature.
The first step towards extract-ing event information, in biomedical domain, is torecognize the names of proteins (Fukuda et al,1998; Blaschke et al, 1999), genes, drugs and othermolecules.
The next step is to recognize relation-ship between such entities (Blaschke and Valen-cia, 2002; Ono et al, 2001; Fundel et al, 2007)and then to recognize the bio-molecular interactionevents with these entities as participants (Yakushijiet al, 2001; Tateisi et al, 2004).
The BIONLP?09shared task involved recognition of bio-molecularevents, which appear in the GENIA corpus.
Wemainly focused on task 1, which was detection ofan event and its participants.Figure 1: BioEve System ArchitectureThe rest of the paper is organized as follows.
InSection 2 we describe BioEve system, sentence levelclassification and event extraction using dependencyparse tree of the sentence.
Sections 3 describes ex-periments with classification approaches and evalu-ation results for shared task 1.
Section 4 concludesthe paper.2 BioEve: Bio-Molecular Event ExtractorBioEve architecture is shown in Figure 1.
Firstthe biomedical abstracts are split into sentences,before being sent to sentence level classifier.
Weused Na?ive Bayes Classifier to classify sentencesinto different event class types.
Classification atsentence level is a difficult task, as sentences havelesser information as compared to the whole doc-ument.
To help event extraction module, each ofthese sentences are then semantically labeled withadditional keywords.
We created a dictionary-based99labeler, which included trigger words from train-ing data, along with the corresponding event type.These labeled sentences are parsed using a depen-dency parser to identify argument-predicateroles.
For each event class type, we hand craftedhigh coverage extraction rules, similar to Fundel etal.
(2007), to identity all event participants.
ForBioNLP shared task, the event-participant outputwas formatted to GENIA format.2.1 Sentence Level Classification and SemanticLabelingWe used Na?ive Bayes Classifier from Weka 1 libraryto classify sentences into different event class types.Classification at sentence level is a difficult task, assentences have lesser information as compared to thewhole document.
We tried different approaches forclassification : 1) Na?ive Bayes Classifier using bag-of-words, 2) Na?ive Bayes Classifier using bag-of-words and parts-of-speech tags and 3) SVM Classi-fier for Weka library.BioEve event extraction module depends on classlabels for extraction.
To help with this task, weneeded to improve sentence labeling with correctclass type information.
For this, we employed dic-tionary based semantic class labeling by identifyingtrigger (or interaction) words, which clearly indicatepresence of a particular event.
We used ABNER 2gene name recognizer to enrich the sentences withgene mentions.There have been cases in the training data wherethe same trigger word is associated with more thanone event type.
To resolve such cases, the triggerwords were mapped to the most likely event typebased on their occurrence count in the training data.We labeled trigger words in each sentence with theirmost likely event type.
These tagged words servedas a starting point for the extraction of event par-ticipants.
This was done to speed-up the extractionprocess, as event extraction module now only needsto focus on the parts of the sentences related to thesetagged trigger words.1http://www.cs.waikato.ac.nz/ml/weka/2http://pages.cs.wisc.edu/ bsettles/abner/2.2 Event Extraction Using DependencyParsingThe sentences, after being class labeled and tagged,are parsed using a dependency parser (Stanfordparser3) to identify argument-predicateroles.
Words in the sentence and the relationshipsbetween these words form the dependency parsetree of the sentence.
For our system, we usedtyped-dependency representation output formatfrom Stanford parser which is a simple tuple,reln(gov, dep), where reln is the depen-dency relation, gov is the governor word and depis the dependent word.
Consider the followingexample sentence:We investigated whether PU.1 bindsand activates the M-CSF receptorpromoter.After this sentence is class labeled and tagged:We investigated whetherT7 binds/BINDING andactivates/POSITIVE REGULATION theT8 promoter.The tagged sentence is parsed to obtain dependencyrelations as shown below:nsubj(investigated-2, We-1)complm(binds-5, whether-3)nsubj(binds-5, T7-4)ccomp(investigated-2, binds-5)conj and(binds-5, activates-7)det(promoter-10, the-8)nn(promoter-10, T8-9)dobj(binds-5, promoter-10)This sentence mentions two separate events, bind-ing and positive regulation.
Let?s consider the ex-tracting the event binding and its participants.
Fig-ure 2 shows the parse tree representation and the partof the tree that needs to be identified for extractingevent binding.For each event class type, we carefully handcrafted rules, keeping theme of the event, numberof participants, and their interactions into consider-ation.
Table 1 lists these extraction rules.
In an ex-traction rule, T represents the occurrence of proteinin sentence.
If multiple proteins are involved, thensubscripts, Tn, are used to represent this.
The rule3http://nlp.stanford.edu/software/lex-parser.shtml100Figure 2: Dependency Parse tree, and event ?binding?and its participants are shown.is triggered when it matches I (for an interactionword, or trigger word ) in the sentence.
Some de-pendency relations and rule predicates are explainedbelow:?
obj(verb/I, T) :- The matching protein is a di-rect object of the interaction word?
prep(I, T) :- The matching protein is con-nected to its interaction word by a preposition?
T1 (I) T2 : ?
The interaction word occurs inbetween the two matching interacting proteins?
conj(T1, T2 ) The two matching proteins are beconnected to each other using conjugates suchas ?and??
ConnectedRule :- The interaction word and thematching protein should be directly connectedwith a single edge ( dependency relation)?
NearestRule :- The interaction word and thematching protein should be connected to eachother, directly or indirectly within 5 edge hops,in either directionAlgorithm 1 shows the steps to extract event par-ticipants using the rules given in Table 1.3 Experiments and EvaluationsBioEve shared task evaluation results for Task 1 areshown in Table 2.
Event extraction for classes gene-expression, protein-catabolism and phosphoryla-tion performed better comparatively, where as, forInput: Abstract tagged with interaction wordsand class labelsOutput: Bio Events with interaction words andthe participantsforeach abstract do Iterate over each abstractforeach sentence in current abstract doretrieve all the interaction words incurrent sentence;sort them according to precedence of theevent class type;foreach interaction word in the sentencedoextract the participants by matchingthe corresponding event?s rule to thesentence?s dependency parse;endendendAlgorithm 1: BioEve Event Extraction algorithmclasses transcription, regulation, positive-regulationand negative-regulation, it was below par.
The rea-son noticed (in training examples) was that, mostof the true example sentences of positive-regulationor negative-regulation class type were mis-classifiedas either phosphorylation or gene-expression.
Thiscalls for further improvement of sentence classifieraccuracy.
Experiments with different approachesfor sentence level classification are shown in Ta-ble 3.
Classifiers were trained on training data andtested on development data.
Interestingly, simpleNa?ive Bayes Classifier (NBC) (using just bag-of-words (BOW)) showed better results (up to 10% bet-ter) compared to other approaches, even SVM clas-sifier.4 ConclusionsIn this paper, BioEve?s Task 1 evaluation resultswere described, with additional results from differ-ent approaches experimented to semantically clas-sify a sentence to the event type.
Event ex-traction performed better for some categories, butclearly needs re-compiling extraction rules for some.Where as classification results showed simple Na?iveBayes Classifier performing better than other ap-proaches.101Event Class Extraction Rules Event Class Extraction RulesPositive Regulationa) obj(verb/I , T )Negative Regulationa) obj(verb/I , T )b) prep(I , T ) b) prep(I , T )c) ConnectedRule c) ConnectedRuled) NearestRule d) NearestRuleRegulationa) prep(I , T )Bindinga) T1 (I) T2b) ConnectedRule b) prep(I , T1); prep(T1, T2)c) NearestRule c) prep(I , T1); conj(T1, T2)Phosphorylationa) prep(I , T ) d) obj(verb/I , T )b) T (connecting-word) I e) prep(I , T )c) ConnectedRule f) ConnectedRuled) NearestRule g) NearestRuleGene Expression a) ConnectedRule Protein Catabolisma) prep(I , T )b) NearestRule b) ConnectedRuleTranscriptiona) prep(I , T ) c) NearestRuleb) T (connecting-word) ILocalizationa) prep(I , T )c) ConnectedRule b) ConnectedRuled) NearestRule c) NearestRuleTable 1: Extraction rules for each class type.
Rules are fired in the order they are listed for each class.Approach recall precision f-scoreLocalization 27.59 33.57 30.28Binding 16.71 30.53 21.60Gene-expression 44.04 39.55 41.68Transcription 10.95 11.28 11.11Prot-catabolism 57.14 27.59 37.21Phosphorylation 50.37 63.55 56.20Regulation 9.28 5.18 6.65Pos-regulation 10.48 7.34 8.63Neg-regulation 12.93 10.19 11.40All Total 21.81 18.21 19.85Table 2: BioNLP Shared Task Evaluation: Task 1 Resultsusing approximate span matching.Sentence Classifier Correct IncorrectNBC(BOW) 60.45% 39.54%NBC(BOW+POS) 43.12% 56.87%SVM 50.14% 49.85%Table 3: Sentence Classifier results for different ap-proaches: 1) Na?ive Bayes Classifier (NBC) (using bag-of-words (BOW)), 2) Na?ive Bayes Classifier(using BOW+ Parts-of-speech(POS) tags) and 3) SVM Classifier.
To-tal number of instances =708.ReferencesChristian Blaschke and Alfonso Valencia.
2002.
Theframe-based module of the suiseki information extrac-tion system.
IEEE Intelligent Systems, 17(2):14?20.C.
Blaschke, MA.
Andrade, C. Ouzounis, and A. Valen-cia.
1999.
Automatic extraction of biological infor-mation from scientific text: protein-protein interaction.In Proceedings of the AAAI conference on IntelligentSystems in Molecular Biology, pages 60?7.
AAAI.K.
Fukuda, A. Tamura, T. Tsunoda, and T. Takagi.
1998.Toward information extraction: identifying proteinnames from biological papers.
In Pac Symp Biocom-put, volume 707, page 18.Katrin Fundel, Robert Ku?ffner, and Ralf Zimmer.
2007.Relex?relation extraction using dependency parsetrees.
Bioinformatics, 23(3):365?371.Toshihide Ono, Haretsugu Hishigaki, Akira Tanigami,and Toshihisa Takagi.
2001.
Automated extractionof information on protein-protein interactions from thebiological literature.
Bioinformatics, 17(2):155?161.Y.
Tateisi, T. Ohta, and J. Tsujii.
2004.
Annotationof predicate-argument structure of molecular biologytext.
In JCNLP-04 workshop on Beyond Shallow Anal-yses.Akane Yakushiji, Yuka Tateisi, Yusuke Miyao, and Junichi Tsujii.
2001.
Event extraction from biomedicalpapers using a full parser.
In Pac.
Symp.
Biocomput,pages 408?419.102
