Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 527?531,Dublin, Ireland, August 23-24, 2014.SeemGo: Conditional Random Fields Labeling and Maximum EntropyClassification for Aspect Based Sentiment AnalysisPengfei Liu and Helen MengHuman-Computer Communications LaboratoryDepartment of Systems Engineering and Engineering ManagementThe Chinese University of Hong Kong, Hong Kong SAR, China{pfliu,hmmeng}@se.cuhk.edu.hkAbstractThis paper describes our SeemGo sys-tem for the task of Aspect Based Sen-timent Analysis in SemEval-2014.
Thesubtask of aspect term extraction is castas a sequence labeling problem modeledwith Conditional Random Fields that ob-tains the F-score of 0.683 for Laptops and0.791 for Restaurants by exploiting bothword-based features and context features.The other three subtasks are solved by theMaximum Entropy model, with the occur-rence counts of unigram and bigram wordsof each sentence as features.
The sub-task of aspect category detection obtainsthe best result when applying the Boostingmethod on the Maximum Entropy model,with the precision of 0.869 for Restau-rants.
The Maximum Entropy model alsoshows good performance in the subtasksof both aspect term and aspect categorypolarity classification.1 IntroductionIn this paper, we present the SeemGo system de-veloped for the task of Aspect Based SentimentAnalysis in SemEval-2014.
The task consists offour subtasks: (1) aspect term extraction (iden-tify particular aspects of a given entity, e.g., lap-top, restaurant, etc.
); (2) aspect category detection(detect the category of a given sentence, e.g., food,service for a restaurant, etc.
), (3) aspect term po-larity, and (4) aspect category polarity.
The po-larity of each aspect term or aspect category in-cludes positive, negative, neutral or conflict (i.e.,both positive and negative).This work is licenced under a Creative Commons Attribu-tion 4.0 International License.
Page numbers and proceed-ings footer are added by the organizers.
License details:http://creativecommons.org/licenses/by/4.0/In the SeemGo system, the subtask of aspectterm extraction is implemented with the CRFmodel that shows good performance by integrat-ing both word-based features and context features.The other subtasks of aspect category detection,aspect term/category polarity classification are alldeveloped with the MaxEnt model with the occur-rence counts of unigram and bigram words of eachsentence as features.
Experimental results showthat MaxEnt obtains good performance in all thethree subtasks.
For the subtask of aspect cate-gory detection, MaxEnt obtains even better perfor-mance when combined with the Boosting method.The rest of this paper is organized as fol-lows: Section 2 discusses related work; Section 3presents the architecture and the underlying mod-els of the SeemGo system as well as the experi-mental results.
We summarize the paper and pro-pose future work in Section 4.2 Related WorkThe subtask of aspect term extraction is quitesimilar with Noun Phrase Chunking (NPC) (Shaand Pereira, 2003) and Named Entity Recognition(NER) (Finkel et al., 2005).
NPC recognizes nounphrases from sentences, while NER extracts a setof entities such as Person, Place, and Organiza-tion.
Both NPC and NER are sequential learn-ing problems and they are typically modelled bysequence models such as Hidden Markov Model(HMM) and CRF (Finkel et al., 2005).For the task of aspect term extraction, some re-lated papers also model it with sequence models.Jin et al.
(2009) proposed an HMM-based frame-work to extract product entities and associatedopinion orientations by integrating linguistic fea-tures such as part-of-speech tag, lexical patternsand surrounding words/phrases.
Choi et al.
(2005)proposed a hybrid approach using both CRF andextraction patterns to identify sources of opinionsin text.
Jakob and Gurevych (2010) described a527CRF-based approach for the opinion target extrac-tion problem in both single- and cross-domain set-tings.
Shariaty and Moghaddam (2011) used CRFfor the task of identifying aspects, aspect usagesand opinions in review sentences by making useof labeled dataset on aspects, opinions as well asbackground words in the sentences.The task of aspect category detection is essen-tially a text classification problem, for which manytechniques exist.
Joachims (1998) explored theuse of Support Vector Machines (SVM) for textcategorization and obtained good performancedue to their ability to generalize well in high-dimensional feature spaces.
Nigam et al.
(1999)proposed the MaxEnt model for document clas-sification by estimating the conditional distribu-tion of the class variable give the document, andshowed that MaxEnt is significantly better thatNaive Bayes on some datasets.For polarity classification, Pang et al.
(2002)conducted experiments on movie reviews andshowed that standard machine learning techniques(e.g., Naive Bayes, SVM and MaxEnt) outperformhuman-produced baselines.3 The SeemGo SystemWe use the CRF model (Lafferty et al., 2001) forthe subtask of aspect term extraction, and adoptthe MaxEnt model for the other three subtaskswith the vectors of word count as features.
Eachentry in the vector represents the occurrence countof each unigram or bigram words in the sentence.Figure 1 shows the architecture and the MaxEntand CRF models of the SeemGo system.
The la-bel is denoted in lowercase (e.g.
y for sentiment),while word count, label sequence and word se-quence are vectors, denoted in bold lowercase (e.g.y for label sequence).
We developed the SeemGosystem in Java based on the MALLET Toolkit(McCallum, 2002) for MaxEnt and the StanfordCRFClassifier(Finkel et al., 2005) for CRF.3.1 Background3.1.1 Maximum Entropy ClassifierThe MaxEnt model defines the conditional distri-bution of the class (y) given an observation vectorx as the exponential form in Formula 1:P(y|x) =1Z(x)exp(K?k=1?kfk(x, y))(1)??
?1 word count?1 label MaxEnt P(?|?)
?
labelx word countTrain Predict ??
word count??
labelTransform(a) MaxEnt model for label classificationI?ve been to several places for Dim Sum and this has got to be the WORST.Test sentence:Training Set??
?1 word sequence?1 label sequence CRF P(?|x) ?
label sequence?
word sequenceTrain Predict ??
word sequence??
label sequenceTransform(b) CRF model for sequence labelingI?ve been to several places for Dim Sum and this has got to be the WORST.Test sentence:Training SetFigure 1: The Architecture, the MaxEnt and CRFModels of the SeemGo System.where ?kis a weight parameter to be estimated forthe corresponding feature function fk(x, y), andZ(x) is a normalizing factor over all classes to en-sure a proper probability.
K is the total number offeature functions.3.1.2 Conditional Random FieldsCRF is an extension to the MaxEnt model for han-dling sequence data.
The linear-chain CRF is aspecial case of CRF that obeys the Markov prop-erty between its neighbouring labels.
FollowingMcCallum and Li (2003), Formula 2 defines thelinear-chain CRF: y = {yt}Tt=1, x = {xt}Tt=1arelabel sequence and observation sequence respec-tively, and there are K arbitrary feature functions{fk}1?k?Kand the corresponding weight param-eters {?k}1?k?K.
Z(x) is a normalizing factorover all label sequences.P (y|x) =1Z(x)exp(T?t=1K?k=1?kfk(yt, yt?1,x, t))(2)In the labeling phase, the Viterbi decoding algo-rithm is applied to find the best label sequence y?for the observation sequence x.3.2 Subtask 1: Aspect Term ExtractionThe datasets (Laptops and Restaurants) are pro-vided in XML format, with each sentence and itsannotations consisting of a training instance.
Foreach instance, SeemGo first transform the sen-tence into a word sequence x, and converts the cor-responding annotations into the label sequence y.SeemGo then learns a CRF model P (y|x) basedon the N the training instances {(xn,yn)}Nn=1.5283.2.1 IOB LabelingSince an aspect term can contain multiple words(e.g., hard disk), we define the label B-TERMfor the beginning of an aspect term, the label I-TERM for the subsequent inside words or endword of an aspect term and the label O for all otherwords.
This definition follows the Inside, Out-side, Beginning (IOB) labeling scheme (Ramshawand Marcus, 1999).
The subtask 1 can be viewedas a sequence labeling problem by labeling eachword either as B-TERM, I-TERM or O. Figure2 shows two example sentences labeled with theIOB2 scheme1.The hard disk is very noisy.O B-TERM I-TERM O O OI liked the service and  the staff.O O O B-TERM O O B-TERMFigure 2: Example Sentences with IOB2 Labels.3.2.2 Features for the CRF ModelIn CRF, features typically refer to feature func-tions {fk}, which can be arbitrary functions.
Intext applications, CRF features are typically bi-nary (Sutton and McCallum, 2012).
As an exam-ple for ?virus protection?, a binary feature func-tion may have value 1 if and only if the label for?virus?
is B-TERM and the current word ?protec-tion?
has the suffix of ?tion?, and otherwise 0.Similar to the features used in Finkel et al.
(2005)for the NER task, Table 1 summarizes the featuresfor the aspect term extraction task.
We call the fea-tures derived from the current word word-basedfeatures such as wid, wcharacter, and the featuresfrom the surrounding words and the previous labelthe contex features (context).We consider the sentence ?I?ve been to severalplaces for Dim Sum and this has got to be theWORST.?
as an example to explain why we choosethese features: (a) word-based features: the word?Sum?
is located in the middle of the sentence,with the first character capitalized.
(b) context fea-tures: the previous word ?Dim?
is also capitalizedin the first character and the label of ?Dim?
is as-sumed to be ?B-TERM?.
By combining the word-based features and the context features, the Viterbidecoding algorithm will then label ?Sum?
as ?I-TERM?
with high degree of confidence, which is1With IOB2, every aspect term begins with the B label.a part of the multi-word term ?Dim Sum?, insteadof a mathematical function in some other context.Table 1: Features for the CRF Model.Feature Descriptionwidword identitywcharacterwhether the word characters are capital-ized, hyphenated, numeric, e.g., built-incamera, BIOS, Dim Sum, Windows 7wlocationword index in the word sequence xwngramn-gram character sequences of eachword with maximum length of 6, includ-ing prefixes and suffixes, e.g., ?tion?
inspecification, navigationcontextcurrent wordwt, its neighbouring words(wt?2,...,wt+2) and previous label yt?1wpospart-of-speech tag of each word3.2.3 Experimental ResultsWe trained the CRF model with different fea-ture set on the training set provided by the Se-mEval2014 organizers, and reported the experi-mental results on the testing set by the evaluationtool eval.jar.
The detailed experimental results arelisted in Table 2.
The basic feature set consists ofwid,wcharacterandwlocation.
The results from oneof the best systems on each dataset are also listed,marked with the star (*).Table 2: Experimental Results on Different Fea-ture Set for Aspect Term Extraction.Feature Set Precision Recall F-scoreLapbasic0.780(263/337)0.402(263/654)0.531basic+ wngram0.781(375/480)0.573(375/654)0.661(+0.13)basic+ wcontext0.827(296/358)0.453(296/654)0.585(+0.054)basic+wngram+context0.830(380/458)0.581(380/654)0.683(+0.152)basic+wngram+context+ wpos0.837(365/436)0.558(365/654)0.670(-0.013)IHS RD Belarus* 0.848 0.665 0.746Resbasic0.862(692/803)0.610(692/1134)0.715basic+ wngram0.838(804/959)0.709(804/1134)0.768(+0.053)basic+ wcontext0.856(704/822)0.621(704/1134)0.720(+0.05)basic+wngram+context0.865(827/956)0.729(827/1134)0.791(+0.076)basic+wngram+context+ wpos0.870(806/926)0.711(806/1134)0.783(-0.08)XRCE* 0.909 0.818 0.840We have the following observations:(1) Compared with using only the basic features,adding the feature of wn?gramcontributes the529greatest performance improvement, with theabsolute increase of F-score by 13% for Lap-tops and 5.3% for Restaurants; while addingthe wcontextfeature improves the F-score byaround 5% for both datasets.
(2) Combining the word-based features (basicand wngram) and the context-based features(wcontext) lead to the best performance forboth datasets in terms of recall and F-score.
(3) The POS tags lead to a decrease in both re-call and F-score, with the absolute decreaseof F-score by 1.3% for Laptops and 8% forRestaurants.
The same observation is also re-ported by Tkachenko and Simanovsky (2012)for NER.3.3 Subtask 3: Aspect Category DetectionWe encode each sentence as a feature vector xwith each entry representing occurrence count ofeach unigram word and bigram words (i.e., wordcount).
All words are lowercased, while keepingthe stopwords as most sentences in the datasets areshort.
Using the provided training set, We traineda MaxEnt classifier (ME) P (y|x) with a Gaussianprior variance of 20 to prevent overfitting.We also tried the Bagging (Breiman, 1996) onMaxEnt (BaggingME) and the Boosting (Freundand Schapire, 1996) on MaxEnt (BoostME).
Table3 shows the experimental results on the providedtesting set.
It shows that the Boosting method onMaxEnt improves both precision and recall as wellas the F-score by 1.1%.
The best evaluation resultis by the NRC-Canada team.Table 3: Performance of Different Classifiers forAspect Category Detection.Classifier Precision Recall F-scoreME0.858(686/800)0.669(686/1025)0.752BagME0.843(674/800)0.658(674/1025)0.739BoostME0.869(695/800)0.678(695/1025)0.762Best* 0.910 0.862 0.8863.4 Subtask 2 & 4: Aspect Term & CategoryPolarity ClassificationSimilar to subtask-3, we also used MaxEnt for thesubtasks of 2 and 4, with word count as features.For category polarity classification, we count thewords from both the sentence and the categoryname.
For example, we count the sentence ?TheDim Sum is delicious.?
and its category ?Food?as features.
This improves performance comparedwith counting the sentence only.Table 4 shows the accuracy of each classifier forthe subtasks of 2 and 4 on Laptops and Restau-rants, including the best results from NRC-Canada(a) and DCU (b).
In both datasets, the distributionsof aspect term/category polarities are very imbal-anced with very few sentences on conflict but withmost sentences on positive or negative.
This leadsto very low classification performance for the con-flict class, with the F-score less than 0.2.
In thiscase, the Boosting method does not necessarilyimprove the performance.Table 4: Accuracy of Different Classifiers for As-pect Term & Category Polarity Classification.ClassifierTermCategoryLaptops Restaurants (Restaurants)ME0.648(424/654)0.729(827/1134)0.752(771/1025)BagME0.635(415/654)0.732(830/1134)0.752(771/1025)BoostME0.642(420/654)0.730(828/1134)0.747(766/1025)Best*0.705 (a,b)(461/654)0.810 (b)(918/1134)0.829 (a)(850/1025)3.5 Evaluation RanksTable 5 shows the official ranks (and the new ranksin braces of the revised version after evaluation) ofthe SeemGo system on the two datasets.
The eval-uation metrics are Precision, Recall and F-scorefor the subtasks of 1 and 3, and Accuracy (Acc)for the subtasks of 2 and 4.Table 5: Ranks of SeemGo on the ConstrainedRun (Using only the Provided Datasets).Subtask Precision Recall F-score AccLap1 4 12 (8) 8 (4) -2 - - - 12 (6)Res1 3 11 (7) 5 -2 - - - 8 (6)3 3 (2) 12 8 (7) -4 - - - 44 ConclusionsThis paper presents the architecture, the CRFand MaxEnt models of our SeemGo system forthe task of Aspect Based Sentiment Analysis in530SemEval-2014.
For the subtask of aspect term ex-traction, CRF is trained with both the word-basedfeatures and the context features.
For the otherthree subtasks, MaxEnt is trained with the fea-tures of the occurrence counts of unigram and bi-gram words in the sentence.
The subtask of aspectcategory detection obtains the best performancewhen applying the Boosting method on MaxEnt.MaxEnt also shows good average accuracy for po-larity classification, but obtains low performancefor the conflict class due to very few training sen-tences.This leaves us the future work to improveclassification performance for imbalanced datasets(He and Garcia, 2009).AcknowledgementsWe thank the organizers for their hard work in or-ganizing this evaluation, and the two anonymousreviewers for their helpful comments.ReferencesLeo Breiman.
1996.
Bagging predictors.
Machinelearning, 24(2):123?140.Yejin Choi, Claire Cardie, Ellen Riloff, and SiddharthPatwardhan.
2005.
Identifying sources of opin-ions with conditional random fields and extractionpatterns.
In Proceedings of the Conference on Hu-man Language Technology and Empirical Methodsin Natural Language Processing, pages 355?362.Jenny Rose Finkel, Trond Grenager, and ChristopherManning.
2005.
Incorporating non-local informa-tion into information extraction systems by gibbssampling.
In Proceedings of the 43rd Annual Meet-ing on Association for Computational Linguistics,pages 363?370.Yoav Freund and Robert E Schapire.
1996.
Experi-ments with a new boosting algorithm.
In Interna-tional Conference on Machine Learning, volume 96,pages 148?156.Haibo He and Edwardo A Garcia.
2009.
Learningfrom imbalanced data.
Knowledge and Data Engi-neering, IEEE Transactions on, 21(9):1263?1284.Niklas Jakob and Iryna Gurevych.
2010.
Extractingopinion targets in a single-and cross-domain settingwith conditional random fields.
In Proceedings ofthe Conference on Empirical Methods in NaturalLanguage Processing, pages 1035?1045.Wei Jin, Hung Hay Ho, and Rohini K Srihari.
2009.
Anovel lexicalized HMM-based learning frameworkfor web opinion mining.
In Proceedings of the In-ternational Conference on Machine Learning, pages465?472.
Citeseer.Thorsten Joachims.
1998.
Text categorization withsupport vector machines: Learning with many rel-evant features.
Springer.John Lafferty, Andrew McCallum, and Fernando CNPereira.
2001.
Conditional random fields: Prob-abilistic models for segmenting and labeling se-quence data.Andrew McCallum and Wei Li.
2003.
Early results fornamed entity recognition with conditional randomfields, feature induction and web-enhanced lexicons.In Proceedings of the seventh conference on Naturallanguage learning at HLT-NAACL 2003-Volume 4,pages 188?191.Andrew Kachites McCallum.
2002.
MALLET: A Ma-chine Learning for Language Toolkit.Kamal Nigam, John Lafferty, and Andrew McCallum.1999.
Using maximum entropy for text classifica-tion.
In IJCAI-99 workshop on machine learningfor information filtering, volume 1, pages 61?67.Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.2002.
Thumbs up?
: sentiment classification usingmachine learning techniques.
In Proceedings of theConference on Empirical Methods in Natural Lan-guage Processing, pages 79?86.Lance A Ramshaw and Mitchell P Marcus.
1999.
Textchunking using transformation-based learning.
InNatural language processing using very large cor-pora, pages 157?176.
Springer.Fei Sha and Fernando Pereira.
2003.
Shallow pars-ing with conditional random fields.
In Proceedingsof the Conference of the North American Chapterof the Association for Computational Linguistics onHuman Language Technology, pages 134?141.Shabnam Shariaty and Samaneh Moghaddam.
2011.Fine-grained opinion mining using conditional ran-dom fields.
In Data Mining Workshops (ICDMW),2011 IEEE 11th International Conference on, pages109?114.
IEEE.Charles Sutton and Andrew McCallum.
2012.
An in-troduction to conditional random fields.
Founda-tions and Trends in Machine Learning, 4(4):267?373.Maksim Tkachenko and Andrey Simanovsky.
2012.Named entity recognition: Exploring features.
InProceedings of KONVENS, volume 2012, pages118?127.531
