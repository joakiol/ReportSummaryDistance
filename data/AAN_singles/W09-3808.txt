Proceedings of the 11th International Conference on Parsing Technologies (IWPT), pages 61?64,Paris, October 2009. c?2009 Association for Computational LinguisticsAn Incremental Earley Parser for Simple Range Concatenation GrammarLaura Kallmeyer and Wolfgang MaierCollaborative Research Center 833University of Tu?bingenTu?bingen, Germany{lk,wmaier}@sfs.uni-tuebingen.deAbstractWe present an Earley-style parser forsimple range concatenation grammar, aformalism strongly equivalent to linearcontext-free rewriting systems.
Further-more, we present different filters whichreduce the number of items in the pars-ing chart.
An implementation shows thatparses can be obtained in a reasonabletime.1 IntroductionLinear context-free rewriting systems (LCFRS)(Vijay-Shanker et al, 1987), the equivalent mul-tiple context-free grammars (MCFG) (Seki et al,1991) and simple range concatenation grammars(sRCG) (Boullier, 1998) have recently attractedan increasing interest in the context of natu-ral language processing.
For example, Maierand S?gaard (2008) propose to extract simpleRCGs from constituency treebanks with crossingbranches while Kuhlmann and Satta (2009) pro-pose to extract LCFRS from non-projective depen-dency treebanks.
Another application area of thisclass of formalisms is biological computing (Katoet al, 2006).This paper addresses the symbolic parsing ofsRCG/LCFRS.
Starting from the parsing algo-rithms presented in Burden and Ljunglo?f (2005)and Villemonte de la Clergerie (2002), we pro-pose an incremental Earley algorithm for simpleRCG.
The strategy is roughly like the one pur-sued in Villemonte de la Clergerie (2002).
How-ever, instead of the automaton-based formalizationin Villemonte de la Clergerie?s work, we give ageneral formulation of an incremental Earley al-gorithm, using the framework of parsing as de-duction.
In order to reduce the search space, weintroduce different types of filters on our items.We have implemented this algorithm and tested iton simple RCGs extracted from the German tree-banks Negra and Tiger.In the following section, we introduce simpleRCG and in section 3, we present an algorithm forsymbolic parsing of simple RCG.
Section 4 thenpresents different filtering techniques to reduce thenumber of items.
We close discussing future work.2 Grammar FormalismA range concatenation grammar (RCG) is a 5-tupleG = (N,T, V, P, S).
N is a finite set of non-terminals (predicate names) with an arity functiondim: N ?
N+, T and V are disjoint finite sets ofterminals and variables.
P is a finite set of clausesof the form ?0 ?
?1 .
.
.
?m, where m ?
0 andeach of the ?i, 0 ?
i ?
m, is a predicate of theform Ai(?i1, .
.
.
, ?idim(A)).
Each ?ij ?
(T ?
V )?,1 ?
j ?
dim(A) and 0 ?
i ?
k, is an argument.As a shorthand notation for Ai(?1, .
.
.
, ?dim(A)),we use Ai(~?).
S ?
N is the start predicate namewith dim(S) = 1.Note that the order of right-hand side (RHS)predicates in a clause is of no importance.
Sub-classes of RCGs are introduced for further ref-erence: An RCG G = (N,T, V, P, S) is sim-ple if for all c ?
P , it holds that every variableX occurring in c occurs exactly once in the left-hand side (LHS) and exactly once in the RHS, andeach argument in the RHS of c contains exactlyone variable.
A simple RCG is ordered if for all?0 ?
?1 ?
?
?
?m ?
P , it holds that if a variable X1precedes a variable X2 in a ?i, 1 ?
i ?
m, thenX1 also precedes X2 in ?0.
The ordering require-ment does not change the expressive power, i.e.,ordered simple RCG is equivalent to simple RCG(Villemonte de la Clergerie, 2002).
An RCG is?-free if it either contains no ?-rules or there is ex-actly one rule S(?)
?
?
and S does not appear inany of the righthand sides of the rules in the gram-mar.
A rule is an ?-rule if one of the arguments61of the lefthand side is the empty string ?.
(Boul-lier, 1998) shows that for every simple RCG, onecan construct an equivalent ?-free simple RCG.
AnRCG G = (N,T, V, P, S) is a k-RCG if for allA ?
N, dim(A) ?
k.The language of RCGs is based on the notionof range.
For a string w1 ?
?
?wn a range is a pairof indices ?i, j?
with 0 ?
i ?
j ?
n, i.e., astring span, which denotes a substring wi+1 ?
?
?wjin the source string or a substring vi+1 ?
?
?
vj inthe target string.
Only consecutive ranges can beconcatenated into new ranges.
Terminals, vari-ables and arguments in a clause are bound toranges by a substitution mechanism.
An instan-tiated clause is a clause in which variables and ar-guments are consistently replaced by ranges; itscomponents are instantiated predicates.
For ex-ample A(?g ?
?
?h?)
?
B(?g + 1 ?
?
?
h?)
is an in-stantiation of the clause A(aX1) ?
B(X1) ifthe target string is such that wg+1 = a.
A de-rive relation ?
is defined on strings of instanti-ated predicates.
If an instantiated predicate is theLHS of some instantiated clause, it can be replacedby the RHS of that instantiated clause.
The lan-guage of an RCG G = (N,T, V, P, S) is the setL(G) = {w1 ?
?
?wn | S(?0, n?)
??
?
}, i.e., an in-put string w1 ?
?
?wn is recognized if and only if theempty string can be derived from S(?0, n?).
In thispaper, we are dealing only with ordered simpleRCGs.
The ordering requirement does not changethe expressive power (Villemonte de la Clergerie,2002).
Furthermore, without loss of generality, weassume that for every clause, there is a k ?
0 suchthat the variables occurring in the clause are ex-actly X1, .
.
.
,Xk.We define derivation trees for simple RCGs asunordered trees whose internal nodes are labelledwith predicate names and whose leaves are la-belled with ranges such that all internal nodesare licensed by RCG clause instantiations: givena simple RCG G and a string w, a tree D =?V,E, r?
is a derivation tree of w = a1 .
.
.
aniff 1. there are exactly n leaves in D labelled?0, 1?, .
.
.
, ?n ?
1, n?
and 2. for all v0 ?
V withv1, .
.
.
, vn ?
V , n ?
1 being all vertices with?v0, vi?
?
E (1 ?
i ?
n) such that the leftmostrange dominated by vi precedes the leftmost rangedominated by vi+1 (1 ?
i < n): there is a clauseinstantiation A0(~?0) ?
A1(~?1) .
.
.
An( ~?n) suchthat a) l(vi) = Ai for 0 ?
i ?
n and b) the yieldof the leaves dominates by vi is ~?i.3 ParsingOur parsing algorithm is a modification of the?incremental algorithm?
of Burden and Ljunglo?f(2005) with a strategy very similar to the strategyadopted by Thread Automata (Villemonte de laClergerie, 2002).
It assumes the grammar to beordered and ?-free.
We refrain from supportingnon-?-free grammars since the treebank grammarsused with our implementation are all ?-free.
How-ever, note that only minor modifications would benecessary in order to support non-?-free grammars(see below).We process the arguments of LHS of clauses in-crementally, starting from an S-clause.
Wheneverwe reach a variable, we move into the clause ofthe corresponding RHS predicate (predict or re-sume).
Whenever we reach the end of an argu-ment, we suspend this clause and move into theparent clause that has called the current one.
Inaddition, we treat the case where we reach the endof the last argument and move into the parent as aspecial case.
Here, we first convert the item intoa passive one and then complete the parent itemwith this passive item.
This allows for some addi-tional factorization.The item form for passive items is [A, ~?]
whereA a predicate of some arity k, ~?
is a range vector ofarity k. The item form for active items: [A(~?)
?A1( ~?1) .
.
.
Am( ~?m), pos, ?i, j?, ~?]
where A(~?)
?A1( ~?1) .
.
.
Am( ~?m) ?
P ; pos ?
{0, .
.
.
, n} is theposition up to which we have processed the input;?i, j?
?
N2 marks the position of our dot in thearguments of the predicate A: ?i, j?
indicates thatwe have processed the arguments up to the jth ele-ment of the ith argument; ~?
is an range vector con-taining the bindings of the variables and terminalsoccurring in the lefthand side of the clause (~?
(i)is the range the ith element is bound to).
Whenfirst predicting a clause, it is initialized with a vec-tor containing only symbols ???
for ?unknown?.We call such a vector (of appropriate arity) ~?init.We introduce an additional piece of notation.
Wewrite ~?
(X) for the range bound to the variable Xin ~?.
Furthermore, we write ~?
(?i, j?)
for the rangebound to the jth element in the ith argument of theclause lefthand side.Applying a range vector ~?
containing variablebindings for a given clause c to the argument vec-tor of the lefthand side of c means mapping the ithelement in the arguments to ~?
(i) and concatenat-ing adjacent ranges.
The result is defined iff every62argument is thereby mapped to a range.We start by predicting the S-predicate:[S(~?)
?
~?, 0, ?1, 0?, ~?init] S(~?)
?
~?
?
PScan: Whenever the next symbol after the dotis the next terminal in the input, we can scan it:[A(~?)
?
~?, pos, ?i, j?, ~?][A(~?)
?
~?, pos+ 1, ?i, j + 1?, ~??]~?
(i, j+1) = wpos+1where ~??
is ~?
updated with ~?
(i, j + 1) =?pos, pos+ 1?.In order to support ?-free grammars, one wouldneed to store the pair of indices a ?
is mapped toin the range vector, along with the mappings ofterminals and variables.
The indices could be ob-tained through a Scan-?
operation, parallel to theScan operation.Predict: Whenever our dot is left of a variablethat is the first argument of some RHS predicateB, we predict new B-clauses:[A(~?)
?
.
.
.
B(X, .
.
. )
.
.
.
, pos, ?i, j?, ~?A][B(~?)
?
~?, pos, ?1, 0?, ~?init]with the side condition ~?
(i, j + 1) = X,B(~?)
?~?
?
P .Suspend: Whenever we arrive at the end of anargument that is not the last argument, we suspendthe processing of this clause and we go back to theitem that was used to predict it.[B(~?)
?
~?, pos?, ?i, j?, ~?B ],[A(~?)
?
.
.
.
B(~?)
.
.
.
, pos, ?k, l?, ~?A][A(~?)
?
.
.
.
B(~?)
.
.
.
, pos?, ?k, l + 1?, ~?
]where the dot in the antecedent A-item precedesthe variable ~?
(i), |~?
(i)| = j (the ith argument haslength j and has therefore been completely pro-cessed), |~?| < i (the ith argument is not the lastargument of B), ~?B(~?
(i)) = ?pos, pos??
and forall 1 ?
m < i: ~?B(~?
(m)) = ~?A(~?(m)).
~?
is ~?Aupdated with ~?A(~?
(i)) = ?pos, pos?
?.Convert: Whenever we arrive at the end of thelast argument, we convert the item into a passiveone:[B(~?)
?
~?, pos, ?i, j?, ~?B ][B, ?]|~?
(i)| = j, |~?| = i,~?B(~?)
= ?Complete: Whenever we have a passive B itemwe can use it to move the dot over the variable ofthe last argument of B in a parent A-clause thatwas used to predict it.
[B, ~?B], [A(~?)
?
.
.
.
B(~?)
.
.
.
, pos, ?k, l?, ~?A][A(~?)
?
.
.
.
B(~?)
.
.
.
, pos?, ?k, l + 1?, ~?
]where the dot in the antecedent A-item precedesthe variable ~?
(|~?B |), the last range in ~?B is?pos, pos?
?, and for all 1 ?
m < |~?B |: ~?B(m) =~?A(~?(m)).
~?
is ~?A updated with ~?A(~?
(|~?B |)) =?pos, pos?
?.Resume: Whenever we are left of a variablethat is not the first argument of one of the RHSpredicates, we resume the clause of the RHS pred-icate.[A(~?)
?
.
.
.
B(~?)
.
.
.
, pos, ?i, j?, ~?A],[B(~?)
?
~?, pos?, ?k ?
1, l?, ~?B][B(~?)
?
~?, pos, ?k, 0?, ~?B]where ~?
(i)(j + 1) = ~?
(k), k > 1 (the next el-ement is a variable that is the kth element in ~?,i.e., the kth argument of B), |~?
(k ?
1)| = l, and~?A(~?
(m)) = ~?B(~?
)(m) for all 1 ?
m ?
k ?
1.The goal item has the form [S, ?0, n?
].Note that, in contrast to a purely bottom-upCYK algorithm, the Earley algorithm presentedhere is prefix valid, provided that the grammardoes not contain useless symbols.4 FiltersDuring parsing, various optimizations known from(P)CFG parsing can be applied.
More concretely,because of the particular form of our simpleRCGs, we can use several filters to reject itemsvery early that cannot lead to a valid parse tree fora given input w = w1 .
.
.
wn.Since our grammars are ?-free, we know thateach variable or occurrence of a terminal in theclause must cover at least one terminal in the in-put.
Furthermore, since separations between ar-guments are generated only in cases where be-tween two terminals belonging to the yield of anon-terminal, there is at least one other terminalsthat is not part of the yield, we know that betweendifferent arguments of a predicate, there must be atleast one terminal in the input.
Consequently, weobtain as a filtering condition on the validity of anactive item that the length of the remaining inputmust be greater or equal to the number of variablesand terminal occurrences plus the number of argu-ment separations to the right of the dot in the left-hand side of the clause.
More formally, an activeitem [A(~?)
?
A1( ~?1) .
.
.
Am( ~?m), pos, ?i, j?, ~?
]satisfies the length filter iff(n?
pos)?
(|~?
(i)| ?
j) + ?dim(A)k=i+1 |~?
(k)| + (dim(A) ?
i)The length filter is applied to results of predict,resume, suspend and complete.A second filter, first proposed in Klein andManning (2003), checks for the presence of re-quired preterminals.
In our case, we assume the63preterminals to be treated as terminals, so this fil-ter amounts to checking for the presence of allterminals in the predicted part of a clause (thepart to the right of the dot) in the remaining in-put.
Furthermore, we check that the terminalsappear in the predicted order and that the dis-tance between two of them is at least the num-ber of variables/terminals and argument separa-tions in between.
In other words, an active item[A(~?)
?
A1( ~?1) .
.
.
Am( ~?m), pos, ?i, j?, ~?]
satis-fies the terminal filter iff we can find an injec-tive mapping fT : Term = {?k, l?
| ~?
(k)(l) ?
Tand either k > i or (k = i and l > j)} ?
{pos+ 1, .
.
.
, n} such that1.
wfT (?k,l?)
= ~?
(k)(l) for all ?k, l?
?
Term;2. for all ?k1, l1?, ?k2, l2?
?
Term with k1 = k2and l1 < l2: fT (?k2, l2?)
?
fT (?k1, l1?)
+(l2 ?
l1);3. for all ?k1, l1?, ?k2, l2?
?
Term with k1 <k2: fT (?k2, l2?)
?
fT (?k1, l1?)
+ (|~?
(k1)| ?l1) + ?k2?1k=k1+1|~?
(k)| + l2 + (k2 ?
k1).Checking this filter amounts to a linear traversalof the part of the lefthand side of the clause thatis to the right of the dot.
We start with index i =pos + 1, for every variable or gap we incrementi by 1.
For every terminal a, we search the nexta in the input, starting at position i.
If it occursat position j, then we set i = j and continue ourtraversal of the remaining parts of the lefthand sideof the clause.The preterminal filter is applied to results of thepredict and resume operations.We have implemented the incremental Earleyparser with the filtering conditions on items.
Inorder to test it, we have extracted simple RCGsfrom the first 1000 sentences of Negra and Tiger(with removed punctuation) using the algorithmdescribed in Maier and S?gaard (2008) and parsedthe sentences 1001-1100 with it.
The grammarscontained 2474 clauses (Negra) and 2554 clauses(Tiger).
The following table contains the to-tal number of sentences for different length andresp.
the number of sentences for which a parsewas found, along with the average parsing timesof those that had a parse:Negra Tigerparse/tot av.
t. parse/tot av.
t.|w| ?
20 73/84 0.40 sec.
50/79 0.3220 ?|w| ?
35 14/16 2.14 sec.
10/19 2.165 Conclusion and Future WorkWe have presented an Earley-style algorithm forsimple range concatenation grammar, formulatedas deduction system.
Furthermore, we have pre-sented a set of filters on the chart reducing thenumber of items.
An implementation and a testwith grammars extracted from treebanks showedthat reasonable parsing times can be achieved.We are currently working on a probabilistick-best extension of our parser which resumescomparable work for PCFG (Huang and Chiang,2005).
Unfortunately, experiments with the Ear-ley algorithm have shown that with grammars of areasonable size for data-driven parsing (> 15, 000clauses), an exhaustive parsing is no longer ef-ficient, due to the highly ambiguous grammars.Algorithms using only passive items seem morepromising in this context since they facilitate theapplication of A?
parsing techniques.ReferencesPierre Boullier.
1998.
Proposal for a natural lan-guage processing syntactic backbone.
Rapport deRecherche RR-3342, INRIA.Ha?kan Burden and Peter Ljunglo?f.
2005.
Parsing lin-ear context-free rewriting systems.
In Proceedingsof IWPT 2005.Liang Huang and David Chiang.
2005.
Better k-bestparsing.
In Proceedings of IWPT 2005.Yuki Kato, Hiroyuki Seki, and Tadao Kasami.
2006.Stochastic multiple context-free grammar for RNApseudoknot modeling.
In Proceedings of TAG+8.Dan Klein and Christopher D. Manning.
2003.
A*Parsing: Fast Exact Viterbi Parse Selection.
In Pro-ceedings of HLT-NAACL.Marco Kuhlmann and Giorgio Satta.
2009.
Treebankgrammar techniques for non-projective dependencyparsing.
In Proceedings of EACL.Wolfgang Maier and Anders S?gaard.
2008.
Tree-banks and mild context-sensitivity.
In Proceedingsof Formal Grammar 2008.Hiroyuki Seki, Takahashi Matsumura, Mamoru Fujii,and Tadao Kasami.
1991.
On multiple context-freegrammars.
Theoretical Computer Science.K.
Vijay-Shanker, David Weir, and Aravind Joshi.1987.
Characterising structural descriptions used byvarious formalisms.
In Proceedings of ACL.Eric Villemonte de la Clergerie.
2002.
Parsing mildlycontext-sensitive languages with thread automata.In Proceedings of COLING.64
