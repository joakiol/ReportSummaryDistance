Proceedings of NAACL-HLT 2013, pages 550?555,Atlanta, Georgia, 9?14 June 2013. c?2013 Association for Computational LinguisticsUsing Derivation Trees for Informative Treebank Inter-AnnotatorAgreement EvaluationSeth Kulick and Ann Bies and Justin Mottand Mohamed MaamouriLinguistic Data ConsortiumUniversity of Pennsylvania{skulick,bies,jmott,maamouri}@ldc.upenn.eduBeatrice Santorini andAnthony KrochDepartment of LinguisticsUniversity of Pennsylvania{beatrice,kroch}@ling.upenn.eduAbstractThis paper discusses the extension of a sys-tem developed for automatic discovery of tree-bank annotation inconsistencies over an entirecorpus to the particular case of evaluation ofinter-annotator agreement.
This system makesfor a more informative IAA evaluation thanother systems because it pinpoints the incon-sistencies and groups them by their structuraltypes.
We evaluate the system on two corpora- (1) a corpus of English web text, and (2) acorpus of Modern British English.1 IntroductionThis paper discusses the extension of a system de-veloped for automatic discovery of treebank annota-tion inconsistencies over an entire corpus to the par-ticular case of evaluation of inter-annotator agree-ment (IAA).
In IAA, two or more annotators anno-tate the same sentences, and a comparison identi-fies areas in which the annotators might need moretraining, or the annotation guidelines some refine-ment.
Unlike other IAA evaluation systems, thissystem application results in a precise pinpointing ofinconsistencies and the grouping of inconsistenciesby their structural types, making for a more infor-mative IAA evaluation.Treebank annotation, consisting of syntacticstructure with words as the terminals, is by its na-ture more complex and therefore more prone to errorthan many other annotation tasks.
However, high an-notation consistency is crucial to providing reliabletraining and testing data for parsers and linguisticresearch.
Error detection is therefore an importantarea of research, and the importance of work such asDickinson and Meurers (2003) is that errors and an-notation inconsistencies might be automatically dis-covered, and once discovered, be targeted for subse-quent quality control.A recent approach to this problem (Kulick et al2011; Kulick et al 2012) (which we will call theKBM system) improves upon Dickinson and Meur-ers (2003) by decomposing the full syntactic treeinto smaller units, using ideas from Tree AdjoiningGrammar (TAG) (Joshi and Schabes, 1997).
This al-lows the comparison to be based on small syntacticunits instead of string n-grams, improving the detec-tion of inconsistent annotation.The KBM system, like that of Dickinson andMeurers (2003) before it, is based on the notion ofcomparing identical strings.
In the general case, thisis a problematic assumption, since annotation in-consistencies are missed because of superficial worddifferences between strings which one would wantto compare.1 However, this limitation is not presentfor IAA evaluation, since the strings to compare are,by definition, identical.2 The same is also true ofparser evaluation, since the parser output and thegold standard are based on the same sentences.We therefore take the logical step of applying theKBM system developed for automatic discovery ofannotation inconsistency to the special case of IAA.31Boyd et al(2007) and other current work tackles this prob-lem.
However, that is not the focus of this paper.2Aside from possible tokenization differences by annotators.3In this paper, we do not yet apply the system to parser eval-uation, although it is conceptually the same problem as IAAevaluation.
We wanted to first refine the system using annota-tor input for the IAA application before applying it to parser550(1) a. NP-SBJNPNPThe wordNPrenaissanceNP-LRB- NPRinascimentoPPin NPItalian-RRB-b.
NP-SBJThe word renaissance PRN-LRB- FRAGNPRinascimentoPPin NPItalian-RRB-Figure 1: Two example trees showing a difference in IAATo our knowledge, this work is the first to utilizesuch a general system for this special case.The advantages of the KBM system play outsomewhat differently in the context of IAA evalu-ation than in the more general case.
In this con-text, the comparison of word sequences based onsyntactic units allows for a precise pinpointing ofdifferences.
The system also retains the ability togroup inconsistencies together by their structuraltype, which we have found to be useful for the moregeneral case.
Together, these two properties makefor a useful and informative system for IAA evalua-tion.In Section 2 we describe the basic working of oursystem.
In Section 3 we discuss in more detail theadvantages of this approach.
In Section 4 we evalu-ate the system on two treebanks, a corpus of Englishweb text and a corpus of Modern British English.Section 5 discusses future work.2 System OverviewThe basic idea of the KBM system is to detect wordsequences that are annotated in inconsistent ways byevaluation.wordNPThe RinascimentoNP -RRB--LRB-renaissanceNPrenaissanceNPb1The -RRB--LRB- RinascimentoFRAGword PRNa1a2a3a4a5a8b2b3 b5b4 b8inPPa6 ItalianNP a7inPP b6 ItalianNPb7NPAAA A A AAAMM MM MA(2) a.b.Figure 2: E-trees and derivation trees corresponding to(1ab)comparing local syntactic units.
Following Dickin-son and Meurers (2003), we refer to sequences ex-amined for inconsistent annotation as nuclei.
Thesentence excerpts (1ab) in Figure 1, from the testcorpora used in this work, illustrate an inconsistencyin the annotation of corresponding strings.
We fo-cus here on the difference in the annotation of thenucleus The word renaissance, which in (1a) is an-notated as an appositive structure, while in (1b) it isflat.Following the TAG approach, KBM decomposesthe full phrase structure into smaller chunks calledelementary trees (henceforth, e-trees).
The relation-ship of the e-trees underlying a full phrase struc-ture to each other is recorded in a derivation tree,in which each node is an e-tree, related to its par-ent node by a composition operation, as shown in(2ab).4KBM uses two composition operations, each withleft and right variants, shown in Figure 3: (1) ad-4The decomposition is based on head-finding heuristics,with the result here that word is the head of (1a), while renais-sance is the head of (1b), as reflected in their respective deriva-tion trees (2a) and (2b).
We omit the POS tags in (1ab) and(2ab) to avoid clutter.551wo ro wo wo rodNPTheRinaschNmswot wo-BLhebN1hBFeRinaschNmsro t ro-BLheRinaschNmswot wodNPThebN1hBFeRinaschNmsrotroworo ro wo woFigure 3: Composition operations (left and right)junction, which attaches one tree to a target node inanother tree by creating a copy of the target node,and (2) sister adjunction, which attaches one tree asa sister to a target node in another tree.
Each arc inFigure 2 is labeled by an ?M?
for adjunction and ?A?for sister-adjunction.
5The system uses the tree decomposition and re-sulting derivation tree for the comparison of differ-ent instances of the same nucleus.
The full deriva-tion tree for a sentence is not used, but rather onlythat slice of it having e-trees with words that are inthe nucleus being examined, which we call a deriva-tion tree fragment.
That is, for a given nucleus witha set of instances, we compare the derivation frag-ments for each instance.For example, for the nucleus The word renais-sance, the derivation tree fragment for the instancein (1a) consists of the e-trees a1, a2, a3 (and theirarcs) in (2a), and likewise the derivation tree fromthe instance in (1b) consists of the e-trees b1, b2, b3in (2b).
These derivation fragments have a differ-ent structure, and so the two instances of The wordrenaissance are recognized as inconsistent.Two important aspects of the overall system re-quire mention here: (1) Nuclei are identified by us-ing sequences that occur as a constituent anywhere5KBM is based on a variant of Spinal TAG (Shen et al2008), and uses sister adjunction without substitution.
Spaceprohibits full discussion, but multiple adjunction to a singlenode (e.g., a4, a6, a8 to a5 in (2a)) does not create multiplelevels of recursion, while a special specification handles the ex-tra NP recursion for the apposition with a2, a3, and a5.
Forreasons of space, we also leave aside a precise comparison toTree Insertion Grammar (Chiang, 2003) and Spinal TAG (Shenet al 2008).in the corpus, even if other instances of the samesequence are not constituents.
Both instances ofThe word renaissance are compared, because thesequence occurs at least once as a constituent.
(2)We partition each comparison of the instances of anucleus by the lowest nonterminal in the derivationtree fragment that covers the sequence.
The two in-stances of The word renaissance are compared be-cause the lowest nonterminal is an NP in both in-stances.3 Advantages of this approachAs Kulick et al(2012) stressed, using derivationtree fragments allows the comparison to abstractaway from interference by irrelevant modifiers, anissue with Dickinson and Meurers (2003).
However,in the context of IAA, this advantage of KBM playsout in a different way, in that it allows for a pre-cise pinpointing of the inconsistencies.
For IAA,the concern is not whether an inconsistent annota-tion will be reported, since at some level higher inthe tree every difference will be found, even if thecontext is the entire tree.
KBM, however, will findthe inconsistencies in a more informative way, forexample reporting just The word renaissance, notsome larger unit.
Likewise, it reports Rinascimentoin Italian as an inconsistently annotated sequence.6A critical desirable property of KBM that carriesover from the more general case is that it allows fordifferent nuclei to be grouped together in the sys-tem?s output if they have the same annotation in-consistency type.
As in Kulick et al(2011), eachnucleus found to be inconsistent is categorized byan inconsistency type, which is simply the collec-tion of different derivation tree fragments used forthe comparison of its instances, including POS tagsbut not the words.
For example, the inconsistencytype of the nucleus The word renaissance in (1ab) isthe pair of derivation tree fragments (a1,a2,a3) and(b1,b2,b3) from (2ab), with the POS tags.
This nu-6Note however that it does not report -LRB- Rinascimentoin Italian -RRB- which is also a constituent, and so might beexpected to be compared.
The lowest nonterminal above thissubstring in the two derivation trees in Figure 2 is the NP in a5and the FRAG in b5, thus exempting them from comparison.
Itis exactly this sort of case that motivated the ?external check?discussed in Kulick et al(2012), which we have not yet imple-mented for IAA.552Inconsistency type # Found # AccurateFunction tags only 53 53POS tags only 18 13Structural 129 122Table 1: Inconsistency types found for system evaluationcleus is then reported together with other nuclei thatuse the same derivation fragments.
In this case, ittherefore also reports the nucleus The term renais-sance, which appears elsewhere in the corpus withthe two annotations from the different annotators asin (3):(3) a. NPNPThe termNPrenaissanceb.
NPThe term renaissanceKBM reports The word renaissance and The termrenaissance together because they are inconsistentlyannotated in exactly the same way, in spite of the dif-ference in words.
This grouping together of incon-sistencies based on structural characteristics of theinconsistency is critically important for understand-ing the nature of the annotation inconsistencies.It is the combination of these two characteristics -(1) pinpointing of errors and (2) grouping by struc-ture - that makes the system so useful for IAA.
Thisis an improvement over alternatives such as usingevalb (Sekine and Collins, 2008) for IAA.
No othersystem to our knowledge groups inconsistencies bystructural type, as KBM does.
The use of the deriva-tion tree fragments greatly lessens the multiple re-porting of a single annotation difference, which isa difficulty for using evalb (Manning and Schuetze,1999, p. 436) or Dickinson and Meurers (2003).4 Evaluation4.1 English web textWe applied our approach to pre-release subset of(Bies et al 2012), dually annotated and used forannotator training, from which the examples in Sec-tions 2 and 3 are taken.
It is a small section of thecorpus, with 4,270 words dually annotated.For this work, we also took the further step ofcharacterizing the inconsistency types themselves,allowing for an even higher-level view of the incon-sistencies found.
In addition to grouping togetherdifferent strings as having the same inconsistent an-notation, the types can also be grouped together forcomparison at a higher level.
For this IAA sample,we separated the inconsistency types into the threegroups in Table 1, with the derivation tree fragmentsdiffering (1) only on function tags, (2) only on POStags7, and (3) on structural differences.
We man-ually examined each inconsistency group to deter-mine if it was an actual inconsistency found, or aspurious false positive.
As shown in Table 1, the pre-cision of the reported inconsistencies is very high.It is in fact even higher than it appears, becausethe seven (out of 129) instances incorrectly listedas structural problems were actually either POS orfunction tag inconsistencies, that were discoveredby the system only by a difference in the derivationtree fragment, and so were categorized as structuralproblems instead of POS or function tag inconsis-tencies.
8Because of the small size of the corpus, thereare relatively few nuclei grouped into inconsistencytypes.
The 129 structural inconsistency types in-clude 130 nuclei, with the only inconsistency typewith more than one nucleus being the type with Theword renaissance and The term renaissance, as dis-cussed above.
There is more grouping together inthe ?POS tags only?
case (37 nuclei included inthe 18 inconsistency types), and the ?function tagsonly?
case (56 nuclei included in the 53 inconsis-tency types).4.2 Modern British English corpusWe also applied our approach to a supplemental sec-tion (Kroch and Santorini, in preparation) to a cor-pus of modern British English (Kroch et al 2010),part of a series of corpora used for research into lan-guage change.
The annotation style is similar to thatof the Penn Treebank, although with some differ-ences.
In this case, because neither the function tagsnor part-of-speech tags were part of the IAA work,7As mentioned in footnote 4, although POS tags were leftout of Figure 2 for readability, they are included in the actual e-trees.
This allows POS differences in a similar syntactic contextto be naturally captured within the overall KBM framework.8A small percentage of inconsistencies are the result of lin-guistic ambiguities and not an error by one of the annotators.553we do not separate out the inconsistency types, asdone in Section 4.1.The supplement section consisted of 82,701words dually annotated.
The larger size, as com-pared with the corpus in Section 4.1, results in somedifferences in the system output.
Because of thelarger size, there are more substantial cases of dif-ferent nuclei grouped together as the same inconsis-tency type than in Section 4.1.
The first inconsis-tency type (sorted by number of nuclei) has 88 nu-clei, and the second has 37 nuclei.
In total, there are1,532 inconsistency types found, consisting of 2,194nuclei in total.
We manually examined the first 20inconsistency types (sorted by number of nuclei),consisting in total of 375 nuclei.
All were found tobe true instances of inconsistent annotation.
(4) a. NPthe ADJPonly truethingb.
NPthe only true thing(5) a. NPtheir ADJPonly actualargumentb.
NPtheir only actual argumentThe trees in (4) and (5) show two of the 88 nu-clei grouped into the first inconsistency type.
Aswith The word renaissance and The term renais-sance in the English web corpus, nuclei with similar(although not identical) words are often grouped intothe same inconsistency type.
To repeat the point,this is not because of any search for similarity ofthe words in the nuclei.
It arises from the fact thatthe nuclei are annotated inconstantly in the sameway.
Of course not all nuclei in an inconsistencytype have the same words.
Nuclei found in this in-consistency type include only true and only actualas shown above, and also nuclei such as new En-glish, greatest possible, thin square, only necessary.Taken together, they clearly indicate an issue withthe annotation of multi-word adjective phrases.99Note that the inconsistencies discussed throughout this pa-per are not taken from the the published corpora.
These resultsare only from internal annotator training files.5 Future workThere are several ways in which we plan to improvethe current approach.
As mentioned above, there isa certain class of inconsistencies which KBM willnot pinpoint precisely, which requires adopting the?external check?
from Kulick et al(2012).
The ab-straction on inconsistency types described in Sec-tion 4 can also be taken further.
For example, onemight want to examine in particular inconsistencytypes that arise from PP attachment or that have todo with the PRN function tag.One main area for future work is the applicationof this work to parser evaluation as well as IAA.
Forthis area, there is some connection to the work ofGoldberg and Elhadad (2010) and Dickinson (2010),which are both concerned with examining depen-dency structures of more than one edge.
The con-nection is that those works are focused on depen-dency representations, and ithe KBM system doesphrase structure analysis using a TAG-like deriva-tion tree, which strongly resembles a dependencytree (Rambow and Joshi, 1997).
There is much inthis area of common concern that is worth examin-ing further.AcknowledgmentsThis material is based upon work supported bythe Defense Advanced Research Projects Agency(DARPA) under Contract No.
HR0011-11-C-0145.The content does not necessarily reflect the positionor the policy of the Government, and no official en-dorsement should be inferred.
This applies to thefirst four authors.
The first, fifth, and sixth authorswere supported in part by National Science Foun-dation Grant # BCS-114749.
We would also liketo thank Colin Warner, Aravind Joshi, Mitch Mar-cus, and the computational linguistics group at theUniversity of Pennsylvania for helpful conversationsand feedback.554ReferencesAnn Bies, Justin Mott, Colin Warner, and Seth Kulick.2012.
English Web Treebank.
LDC2012T13.
Lin-guistic Data Consortium.Adriane Boyd, Markus Dickinson, and Detmar Meurers.2007.
Increasing the recall of corpus annotation er-ror detection.
In Proceedings of the Sixth Workshopon Treebanks and Linguistic Theories (TLT 2007),Bergen, Norway.David Chiang.
2003.
Statistical parsing with an auto-matically extracted Tree Adjoining Grammar.
In DataOriented Parsing.
CSLI.Markus Dickinson and Detmar Meurers.
2003.
Detect-ing inconsistencies in treebanks.
In Proceedings of theSecond Workshop on Treebanks and Linguistic The-ories (TLT 2003), Sweden.
Treebanks and LinguisticTheories.Markus Dickinson.
2010.
Detecting errors inautomatically-parsed dependency relations.
In Pro-ceedings of the 48th Annual Meeting of the Associ-ation for Computational Linguistics, pages 729?738,Uppsala, Sweden, July.
Association for ComputationalLinguistics.Yoav Goldberg and Michael Elhadad.
2010.
Inspectingthe structural biases of dependency parsing algorithms.In Proceedings of the Fourteenth Conference on Com-putational Natural Language Learning, pages 234?242, Uppsala, Sweden, July.
Association for Compu-tational Linguistics.A.K.
Joshi and Y. Schabes.
1997.
Tree-adjoining gram-mars.
In G. Rozenberg and A. Salomaa, editors,Handbook of Formal Languages, Volume 3: BeyondWords, pages 69?124.
Springer, New York.Anthony Kroch and Beatrice Santorini.
in preparation.Supplement to the Penn Parsed Corpus of ModernBritish English.Anthony Kroch, Beatrice Santorini, and Ariel Dier-tani.
2010.
Penn Parsed Corpus of Mod-ern British English.
http://www.ling.upenn.edu/hist-corpora/PPCMBE-RELEASE-1/index.html.Seth Kulick, Ann Bies, and Justin Mott.
2011.
Usingderivation trees for treebank error detection.
In Pro-ceedings of the 49th Annual Meeting of the Associa-tion for Computational Linguistics: Human LanguageTechnologies, pages 693?698, Portland, Oregon, USA,June.
Association for Computational Linguistics.Seth Kulick, Ann Bies, and Justin Mott.
2012.
Furtherdevelopments in treebank error detection using deriva-tion trees.
In LREC 2012: 8th International Confer-ence on Language Resources and Evaluation, Istanbul.Christopher Manning and Hinrich Schuetze.
1999.Foundations of Statistical Natural Language Process-ing.
MIT Press.Owen Rambow and Aravind Joshi.
1997.
A formallook at dependency grammars and phrase-structuregrammars, with special consideration of word-orderphenomena.
In L. Wanner, editor, Recent Trendsin Meaning-Text Theory, pages 167?190.
John Ben-jamins, Amsterdam and Philadelphia.Satoshi Sekine and Michael Collins.
2008.
Evalb.http://nlp.cs.nyu.edu/evalb/.Libin Shen, Lucas Champollion, and Aravind Joshi.2008.
LTAG-spinal and the Treebank: A new re-source for incremental, dependency and semantic pars-ing.
Language Resources and Evaluation, 42(1):1?19.555
