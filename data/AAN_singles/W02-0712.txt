Automatic Interpretation System IntegratingFree-style Sentence Translation and Parallel Text Based TranslationTakahiro Ikeda Shinichi Ando Kenji Satoh Akitoshi Okumura Takao WatanabeMultimedia Res.
Labs.
NEC Labs.4-1-1 Miyazaki, Miyamae-ku, Kawasaki, Kanagawa 216t-ikeda@di.jp.nec.com, s-ando@cw.jp.nec.com, k-satoh@da.jp.nec.com,a-okumura@bx.jp.nec.com, t-watanabe@ay.jp.nec.comAbstractThis paper proposes an automatic in-terpretation system that integrates free-style sentence translation and parallel textbased translation.
Free-style sentencetranslation accepts natural language sen-tences and translates them by machinetranslation.
Parallel text based translationprovides a proper translation for a sen-tence in the parallel text by referring to acorresponding translation of the sentenceand supplements free-style sentence trans-lation.
We developed a prototype of an au-tomatic interpretation system for Japaneseoverseas travelers with parallel text basedtranslation using 9206 parallel bilingualsentences prepared in task-oriented man-ner.
Evaluation results show that the par-allel text based translation covers 72% oftypical utterances for overseas travel andthe user can easily find an appropriate sen-tence from a natural utterance for 64% oftypical traveler?s tasks.
This indicates thatthe user can benefit from reliable transla-tion based on parallel text for fundamentalutterances necessary for overseas travel.1 IntroductionA speech-to-speech translation system must inte-grate at least three components ?
speech recogni-tion, machine translation, and speech synthesis.
Inpractice, each component does not always outputthe correct result for various inputs, and an errorin one component often leads to an incorrect resultbeing produced by the total system even for a lim-ited domain.
Clearly, we need ways to complementspeech-to-speech translation systems that cannot re-liably produce a correct result.Although some robust methods that make the er-roneous results of other components acceptable havebeen proposed (Yumi et al, 1997; Furuse et al,1998), there is no guarantee that the final outputfrom a system will be appropriate even with thesemethods.
To deal with this problem, we have taken amore practical approach to developing an automaticinterpretation system where the user can obtain acorrect result instead of having to apply additionaloperations and judgment.In actual use of a speech-to-speech translationsystem, an error in the speech-recognition or speech-synthesis components is not a large problem if thesystem has a screen that displays each result.
Theuser of the system can correct errors in the recogni-tion result on the screen, and can communicate byshowing the other person the translated sentence onthe screen.On the other hand, an error in the machine-translation component is critical because a user whois not familiar with the target language is unlikelyto notice the error in some cases.
When a nonsensi-cal sentence is generated by machine translation, theuser may realize that the listener does not understandthe translated sentence.
However, when a plausiblesentence that means something different from the in-tended meaning is generated by the machine trans-lation, the user may incorrectly assume that the ut-terance was properly communicated.
Consequently,the user can seldom be sure that the listener cor-rectly understood the intended meaning when usinga speech-to-speech translation system.
A conversa-Association for Computational Linguistics.Algorithms and Systems, Philadelphia, July 2002, pp.
85-92.Proceedings of the Workshop on Speech-to-Speech Translation:tion could continue for some time before it becameapparent that the two sides misunderstood what theother was saying.Moreover, if the user realizes that there is an er-ror in the machine translation, correcting it will bedifficult.
Without knowing the source of the error,the user cannot modify the input to obtain a correctresult.These error problems severely limit the usabilityof speech-to-speech translation.In this paper, we propose an automatic interpreta-tion system that integrates free-style sentence trans-lation and parallel text based translation.
In this sys-tem, free-style sentence translation accepts naturallanguage sentences and translates them by machinetranslation without guaranteeing the quality of thetranslation.
On the other hand, parallel text basedtranslation uses parallel bilingual sentences regis-tered in the system and translates a registered sen-tence by referring to the corresponding translation.Although this translation process limits the input toregistered sentences, it is a robust means of han-dling input with recognition errors and consistentlyprovides a correct translation.
We integrated thesetwo types of translation to realize a robust transla-tion system where the two types of translation com-pensate for the shortcomings of each other.For appropriate integration of free-style sentencetranslation and parallel text based translation, wehad to consider three main points.1.
User interface: how best to present the twofunctions to the user?2.
Content of registered sentences: How many ut-terances should be covered by registered sen-tences?3.
Retrieval system: What methods of searchingamong the registered sentences should be pro-vided to the user?In this paper, we discuss these three points withrespect to a translation system for Japanese travelersin the overseas travel domain.
We construct a modelof the integration of free-style sentence translationand parallel text based translation in Section 2.
Wedescribe a prototype system based on the model inSection 3 and evaluate it in Section 4.
Related workon translation systems utilizing parallel text are dis-cussed in Section 5, and we conclude in Section 6.2 The Integration Model2.1 User InterfaceAlthough parallel text based translation provides acorrect result, the registered parallel bilingual sen-tences cannot cover all possible utterances by theuser in the target domain.
Free-style sentence trans-lation, on the contrary, accepts free-style input sen-tences but provides no guarantee as to the quality ofresults.For many routine situations, users will clearlybenefit from using parallel text based translation.In such cases, the system will probably include asentence that totally or partially fits what they wantto say.
To ensure high translation reliability, usersshould use free-style sentence translation only forutterances not covered by the registered sentences.However, users usually will not know what sen-tences are registered in the system and will have tosearch for an appropriate sentence before they canuse parallel text based translation.
In some cases, theuser will be forced to use free-style sentence trans-lation if unable to find an appropriate sentence.A seamless user interface that allows the user toeasily switch between free-style sentence transla-tion and parallel text based translation is thereforeneeded in a system integrating these two forms oftranslation.
Two conditions in particular had to bemet to make the system easy to use.1.
The user should be able to use an input sen-tence seamlessly as both a source sentence forfree-style sentence translation and a key sen-tence for registered sentence retrieval.2.
The user should be able to use each sentence in-cluded in the results of the registered sentenceretrieval and the input sentence as a sourcesentence for translation.
(The former wouldbe used for parallel text based translation, andthe latter would be used for free-style sentencetranslation.
)2.2 Content of Registered SentencesRegistered sentences must cover the utterances nec-essary for accomplishing typical tasks in the targetdomain to provide correct translation for minimalcommunication.
In a translation system for overseastravelers, some typical tasks are changing money,checking in at a hotel, and ordering at a restaurant.We adopted a three-tier model that consists ofscenes, tasks, and subtasks to prepare a sufficient setTable 1: Examples of scenes, tasks, subtasks, and templates of sentencesScene Task Subtask Template of sentenceHotel Check-in Checking in I?d like to check in, please.Hotel Check-in Requesting a type of room I?d like a room with the ocean view.Restaurant Order Requesting cooking time for your steak Medium, please.Restaurant Order Asking what they recommend What do you recommend for appetizers?of necessary sentences to be registered in the sys-tem.
A scene comprised a place or situation thatcorresponds to where a traveler is likely to be (e.g., ahotel) and a problem that could arise.
We made a listof typical travelers?
tasks that would be necessary invarious travel scenes, divided each task into smallerprimitive tasks (subtasks), and assigned a sentencetemplate to each subtask based on the model.In general, more than one round of conversationis necessary to accomplish each task.
We assumedthat a task would consist of smaller subtasks, eachof which would correspond to one round of conver-sation that consisted simply of an utterance from atraveler to a respondent and a response from the re-spondent to the traveler.
For example, the task ofchecking in to a hotel consists of subtasks such asgiving your name, confirming your departure date,and so on.
Each subtask should be the smallest unitof a task because users cannot use a registered sen-tence effectively if it includes more than what theywant to say.In this way, only one sentence template is neededfor each subtask with regard to an utterance from atraveler to a respondent.
For example, we can assigna sentence template of ?I?d like to have ....?
to thesubtask of ordering a dish in a restaurant.
We canprovide a sufficient number of sentences by enablingthe user to fill in the part denoted as ?...?
(referred toas a slot) with words applicable to the situation.Table 1 shows examples of scenes, tasks, sub-tasks, and sentence templates.
An underlined partrepresents a slot.
We define a list of words individu-ally for each slot.For each task, both the utterances from a travelerto a respondent and the responses from a respon-dent to a traveler are significant.
Responses shouldalso be supported by parallel text based translation toensure reliable communication.
However, inputtingthe response and retrieving a registered sentence thatmatches it will be difficult and time consuming forthe respondent who is unlikely to be familiar withthe translation system.We use a system that presents a menu of responsesfor the respondent to choose from.
The system keepstypical responses in parallel bilingual form for eachregistered sentence that the traveler can use and dis-plays these as candidate responses when the traveleruses the sentence.
The system then shows the trav-eler the translation of the response selected by therespondent.This approach enables travelers to obtain a reli-able response and also enables respondents to easilyselect an appropriate response.2.3 Retrieval SystemThe retrieval system to search for a registered sen-tence that we use is based on a combination of threeconditions ?
the natural language sentence, scene,and action.Registered sentence retrieval based on a naturallanguage sentence is essential for seamless integra-tion of free-style sentence translation and paralleltext based translation.
We used a simple keyword-based retrieval system for registered sentence re-trieval.
This system extracts keywords from an in-putted natural language sentence, searches for sen-tences including the keywords, and presents the re-sults ranked mainly by the number of keywords in-cluded in each sentence.The system retrieves all sentences including morethan one keyword to reduce the chance of an appro-priate sentence not being retrieved.
We overcamethe increased retrieval noise in the result by applyingan additional retrieval system to search for registeredsentences in terms of the scene and action.Each registered sentence to be retrieved for trans-lation corresponds to a set of a scene, a task, anda subtask as described in the previous section.
Ascene represents a place or a situation where the userwishes to accomplish the task and the subtask.
Atask and a subtask represent a user?s actions.
Thismeans that the user?s utterance is related to the user?sintention regarding where (scene) the user wants todo something (action).We use the additional retrieval system in situa-tions where the user has to search for sentences from										Figure 1: The configuration of our prototype systemthe points of view of scene and action.1) Search by sceneThe number of scenes where travelers are likely tohave a conversation is limited and can be systemat-ically classified regarding places such as an airport,a hotel, or a restaurant.We provide a directory-type search system thatcan be used to search for sentences by scene.
Webuilt up the travel-scene directory tree and assignedsentences to the leaf nodes of the tree.
When theuser selects a scene in the tree, sentences belongingto that scene are presented to the user.
The selectedscene does not change until the user selects anotherscene in this search system since the user generallywill not move to a different scene while talking.2) Search by actionSince it is difficult to represent actions with key-words and a traveler?s range of probable actionsin overseas travel is limited, we also provided adirectory-type search system to search for sentencesby action.
We constructed a directory tree of traveleractions, and the user can obtain the sentences usedfor an action by selecting the action from the tree.By inputting a natural language sentence and se-lecting a scene and an action, the user can obtainsentences that include the keywords extracted fromthe input sentence and that match the selected sceneand action.
When the user selects a different sceneor action, the system again searches through the reg-istered sentences using the new condition regardingthe scene or action along with the original conditionthat was not changed.
This enables the user to dy-namically adjust the search conditions.Table 2: Top layer nodes of the scene directoryScenesUsing Interpretation MachineBasic ExpressionsOn the airplaneAirportHotelRestaurantShoppingTransportationRent a car / DrivingSightseeing / EntertainmentTelephone / Mail / BankProperty loss / Incident / AccidentSickness / InjuryTable 3: Action directoryActionsMaking a requestAsking for permissionAsking a questionComplainingExplainingGreeting3 Prototype SystemWe have integrated free-style sentence translation(Watanabe et al, 2000) and parallel text based trans-lation based on the model described in the previoussection and built a new prototype system.
Here, wedescribe the system configuration, the contents ofthe registered sentences in the system, and the sceneand action directories.
We also explain how the useroperates the system interface.3.1 System ConfigurationThe prototype system consists of six components?
speech recognition, machine translation, regis-tered sentence retrieval, parallel text based transla-tion, registered sentence database, speech synthesis(Figure 1).
We have utilized the speech recognition,machine translation, and speech synthesis describedin (Watanabe et al, 2000).
The registered sentenceretrieval component searches the registered sentencedatabase using the system input.
The parallel textbased translation component produces a translationof the registered sentence selected by the user fromthe search results provided by the registered sen-tence retrieval component.
The system input canbe used as the machine-translation target and as asearch key for registered sentence retrieval accord-ing to the user?s instruction.Figure 2: A sentence inputted to the automatic inter-pretation systemFigure 3: The result of registered sentence retrievalfor the sentence in Figure 23.2 Registered SentencesWe first listed a traveler?s typical tasks in elevenscenes where travelers often have to speak to peopleand then made a list of typical subtasks by analyzingthe process necessary to accomplish each task.
Next,we composed a sentence template for each subtaskand a list of typical words that could be inserted intoeach slot of the templates.
We have composed 2590templates, which can be used to generate 7410 sen-tences with the slot word-lists, and have installedthese in the system.We have also composed 1185 templates, whichcan be used to generate 1796 sentences throughslot word expansion, as response candidates for therespondent.
Sharing a set of response candidatesamong several sentences for the traveler decreasesthe total number of response templates needed.
Aset of response candidates is linked to every sentencefor the traveler to which the respondent can respond.Figure 4: English translation of the first registeredsentence in Figure 3Figure 5: English translation of the input sentence inFigure 23.3 Scene and Action DirectoriesFor each of the eleven scenes, we listed the relevanttasks in a two-layered tree with 70 leaf nodes to cre-ate a scene directory.
Table 2 shows the top layernodes of the scene directory.We used only the six actions listed in Table 3 forthe action directory and constructed a one-layeredtree since it is difficult for the user to select the actionif actions are classified in detail.3.4 User InterfaceFigure 2 shows the display screen of the prototypesystem.
In this example, the user inputs the Japanesesentence ?Kono hoteru kara ku?ko?
ni iku basu wa ari-masuka.
(Is there a bus going to the airport fromthis hotel?)?
by speaking.
The result of the speechrecognition is displayed in the input window at thecenter of the screen.When the user clicks the ?kensaku jikko?
(search)?button in the screen, the system searches amongFigure 6: The result of registered sentence retrievalfor the sentence ?Kozeni o irete kudasai.
(I?d likesome small change.
)?Figure 7: The screened result for the scene ?Denwa?
Yu?bin ?
Ginko?
(Telephone / Mail / Bank)?the registered sentences using the input sentence asa key and displays the search result under the in-put window (Figure 3).
The sky-blue color of thebackground in the window indicates the sentence se-lected as the target for translation.
The user can se-lect another sentence including the input sentence byclicking it.When the user clicks the ?honyaku (translate)?button after selecting the first registered sentencein Figure 3, the system retrieves an English trans-lation of the sentence registered with the Japanesesentence, displays it (Figure 4), and reads it throughthe speech synthesis.If the user cannot find an appropriate sentencein the search results, the user can resort to free-style sentence translation.
When the user clicks the?honyaku (translate)?
button after selecting the in-put sentence, the system translates it into Englishthrough the machine translation, displays it (FigureFigure 8: English translation of the registered sen-tence ?Kore wa chu?mon to chigaimasu.
(This is notwhat I ordered.
)?Figure 9: Japanese translation of the first responsein Figure 85), and reads it through the speech synthesis.In this way, the user can use free-style sentencetranslation and parallel text based translation seam-lessly for the same input sentence.Next, we explain how a user can narrow down thesearch result by using the directory.Figure 6 shows the system display when the userinputs the Japanese sentence ?Kozeni o irete kuda-sai.
(I?d like some small change.)?
by speaking andsearches for a matching registered sentence.
Thesearch result is displayed in the lower central win-dow.
In this case, no appropriate sentence appearsamong the higher ranking sentences.In Figure 6, the scene directory is displayed in theleft part of the window.
When the user selects thescene ?Denwa ?
Yu?bin ?
Ginko?
(Telephone / Mail/ Bank)?, the search result is narrowed down to thesentences associated with the scene in ?Telephone/ Mail / Bank?
(Figure 7).
The registered sentence?Kozeni o mazete itadakemasuka.
(I?d like somesmall change.)?
is then displayed at the second ofthe results, and the user can use this sentence fortranslation.The user can similarly narrow down the resultwith the action directory.
If necessary, the user canalso use a combination of the scene and the actiondirectories.We next explain how a respondent can respond byselecting from among the response candidates regis-tered in the system.Figure 8 shows the screen of the system when theuser selects the registered Japanese sentence ?Korewa chu?mon to chigaimasu.
(This is not what I or-dered.)?
and translates it.
The English translation isdisplayed in the upper central window of the screen,and the response candidates are listed in the lowercentral window.When the respondent selects the first responsefrom these and clicks the ?Trans?
button, the systemdisplays Japanese translation of the response (Figure9) and reads it through the speech synthesis.In this way, the respondent can easily respond tothe traveler by selecting a response from among theprovided candidates when the traveler uses a regis-tered sentence.
The traveler can thus fully under-stand the response.4 EvaluationIn this section, we evaluate the prototype systemwith respect to the extent that typical traveler utter-ances are covered by the registered sentences andwhether the user can easily find a registered sentencethat matches a natural utterance.4.1 Coverage provided by the RegisteredSentencesThe system can provide correct translation if the in-put sentence can be matched to a registered sen-tence; otherwise, it can only provide a translationthrough machine translation whose quality is uncer-tain.
To determine the proportion of commonly usedsentences for which the system would provide a cor-rect translation, we evaluated the coverage providedby the registered sentences for sentences randomlyextracted from travel conversation corpora.Table 4 displays the evaluation results.
In the ta-ble, ?closed set?
denotes the result for sentences ex-tracted from the corpora we referred to when devel-oping the registered sentences and ?open set?
de-Table 4: Coverage provided by the registered sen-tences for travel conversation corporaTotal CoveredClosed set 358 260 (72.6%)Open set 308 163 (52.9%)Table 5: The number of the subtask for which properregistered sentence retrievedTotal Subtask Sentence Retrieved116 74 (63.8%)notes the result for sentences extracted from corporanot referred to when developing the registered sen-tences.
The registered sentences covered 72.6% ofthe sentences in the closed set and 52.9% of the sen-tences in the open set.The coverage of almost 73% for the closed setsuggests that roughly 27% of the sentences in thecorpora are not used for typical travel conversation.If the open set includes an equal proportion of atyp-ical sentences, the registered sentences cover about72% of the typical sentences used for travel in theopen set.We therefore believe that our prototype systemcan provide reliable translation for a minimum setof utterances necessary for overseas travel.4.2 Basic Performance of the RegisteredSentence RetrievalSince registered sentences are retrieved mainly byusing sentences inputted with natural language, apoorly performing retrieval system may prevent theuser finding an appropriate sentence that is regis-tered in the system.
To determine whether the sys-tem can reliably retrieve an appropriate sentencefrom the utterance the user first thinks of, we ran-domly picked 116 subtasks for which registered sen-tences had been developed, had experimental sub-jects compose a natural sentence that could be usedto accomplish each subtask, and evaluated whetherthe retrieval result when using a composed sentenceas a key included the registered sentence.Table 5 shows the evaluation results.
The usercould find a registered sentence corresponding to thenatural utterance with our retrieval system for 63.8%of the traveler?s subtasks when a sentence for thesubtask was registered in the system.Although this retrieval system performance is notsufficient when we take into consideration the de-creased performance caused by recognition errorsin the input sentence, we expect to improve the re-trieval performance by adding expressions synony-mous with those in each sentence template to the in-dex used for registered sentence retrieval.5 Related WorkExample-based machine translation has been pro-posed as a method for translating with parallel bilin-gual sentences (Nagao, 1984; Shirai et al, 1997; Fu-ruse et al, 1994).
An example-based machine trans-lation system retrieves example sentences similar tothe input sentence, and translates by appropriatelyassembling and adapting the retrieved sentence tothe input.On the other hand, the parallel text based transla-tion that we apply uses a translation that correspondsto each sentence as it is.
Our system thus enablesrobust overall translation by allowing users to selectthe most appropriate sentence for the situation.The technique of translation memory allows usersto apply parallel bilingual sentences and widely usedin commercial systems (Falcone, 2000).
Previoustranslation results are stored and reused to providesimilar translations for new input.
This techniqueis mainly used for document translation to improvethe efficiency of translation and to ensure the consis-tency in translation results.On the other hand, the parallel text based transla-tion that is used in our system was designed to al-low seamless cooperation with real-time speech-to-speech translation.
Also, it is equipped in advancewith sentences specially composed for any likelyconversation.6 ConclusionWe have developed an automatic interpretation sys-tem by integrating free-style sentence translationand parallel text based translation.
The system pro-vides a predefined always-correct translation whenthe user can use a registered sentence.
Users caneasily switch between the two forms of translation ifnecessary.Our prototype of the automatic interpretation sys-tem for Japanese overseas travelers includes 9206task-oriented parallel bilingual sentences for trav-elers.
The composed sentences cover 72% of thesentences typically used during overseas travel.
Thesystem also provides predefined response candidatesthat a respondent can use when answering the trav-eler.Registered sentences are searched for in responseto natural language sentences input by the user.
Theuser can narrow down the search results by specify-ing a scene and an action.
We found that users couldfind a registered sentence that corresponded to a nat-ural utterance for 64% of traveler?s subtasks if a sen-tence for the subtask was registered in the system.Our next step is to improve the performance ofthe registered sentence retrieval.
We plan to add ex-pressions synonymous with those in each sentencetemplate to the index used for registered sentenceretrieval.
We also plan to restrict the search space byestimating the scene from the dialogue context.ReferencesSuzanne Falcone.
2000.
More translation memory tools(not many more, but good ones).
Translation Journal,4(2).Osamu Furuse, Eiichiro Sumita, and Hitoshi Iida.
1994.Transfer-driven machine translation utilizing empricalknowledge.
Transactions of IPSJ, 35(3):414?425.
inJapanese.Osamu Furuse, Setsuo Yamada, and Kazuhide Ya-mamoto.
1998.
Splitting long or ill-formed input forrobust spoken-language translation.
In Proceedings ofCOLING-ACL?98, pages 421?427.Makoto Nagao.
1984.
A framework of a mechanicaltranslation between japanese and english by analogyprinciple.
In Alick Elithorn and Ranan Banerji, ed-itors, Artificial and Human Intelligence, pages 173?180.
North-Holland.Satoshi Shirai, Francis Bond, and Yamato Takahashi.1997.
A hybrid rule and example based method formachine translation.
In Proceedings of NLPRS-97,pages 49?54.Takao Watanabe, Akitoshi Okumura, Shinsuke Sakai,Kiyoshi Yamabana, Shinichi Doi, and Ken Hanazawa.2000.
An automatic interpretation system for travelconversation.
In Proceedings of ICSLP 2000.Wakita Yumi, Kawai Jun, and Iida Hitoshi.
1997.
Cor-rect parts extraction from speech recognition resultsusing semantic distance calculation, and its applicationto speech translation.
In Proceedings of ACL/EACL-97Workshop on Spoken Language Translation, pages 24?31.
