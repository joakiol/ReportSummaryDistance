Proceedings of SIGDIAL 2009: the 10th Annual Meeting of the Special Interest Group in Discourse and Dialogue, pages 178?187,Queen Mary University of London, September 2009. c?2009 Association for Computational LinguisticsDiscourse Structure and Performance Analysis:Beyond the CorrelationMihai RotaruTextkernel B.V.Amsterdam, The Netherlandsmich.rotaru@gmail.comDiane J. LitmanUniversity of PittsburghPittsburgh, USAlitman@cs.pitt.eduAbstractThis paper is part of our broader investi-gation into the utility of discourse struc-ture for performance analysis.
In our pre-vious work, we showed that several in-teraction parameters that use discoursestructure predict our performance metric.Here, we take a step forward and showthat these correlations are not only a sur-face relationship.
We show that redesign-ing the system in light of an interpreta-tion of a correlation has a positive impact.1 IntroductionThe success of a spoken dialogue system (SDS)depends on a large number of factors and thestrategies employed to address them.
Some ofthese factors are intuitive.
For example, problemswith automated speech recognition can derail adialogue from the normal course: e.g.
non-understandings, misunderstandings, end-pointing, etc.
(e.g.
(Bohus, 2007; Raux and Es-kenazi, 2008)).
The strategies used to handle oravoid these situations are also important and re-searchers have experimented with many suchstrategies as there is no clear winner in all con-texts (e.g.
(Bohus, 2007; Singh et al, 2002)).However, other factors can only be inferredthrough empirical analyses.A principled approach to identifying importantfactors and strategies to handle them comes fromperformance analysis.
This approach was pio-neered by the PARADISE framework (Walker etal., 2000).
In PARADISE, the SDS behavior isquantified in the form of interaction parameters:e.g.
speech recognition performance, number ofturns, number of help requests, etc.
(M?ller,2005).These parameters are then used in a multi-variate linear regression to predict a SDS per-formance metric (e.g.
task completion, user satis-faction: (Singh et al, 2002)).
Finally, SDS redes-ign efforts are informed by the parameters thatmake it in the regression model.Conceptually, this equates to investigating twoproperties of interaction parameters: predictive-ness and informativeness1.
Predictiveness looksat the connection between the parameter and sys-tem performance via predictive models (e.g.
mul-tivariate linear regression in PARADISE).
Oncethe predictiveness is established, it is importantto look at the parameter informativeness.
Infor-mally, informativeness looks at how much theparameter can help us improve the system.
Wealready know that the parameter is predictive ofperformance.
But this does not tell us if there is acausal link between the two.
In fact, the maindrive is not to prove a causal link but to showthat the interaction parameter will inform a modi-fication of the system and that this modificationwill improve the system.This paper is part of our broader investigationinto the utility of discourse structure for per-formance analysis.
Although each dialogue hasan inherent structure called the discourse struc-ture (Grosz and Sidner, 1986), this informationhas received little attention in performanceanalysis settings.
In our previous work (Rotaruand Litman, 2006), we established the predic-tiveness of several interaction parameters derivedfrom discourse structure.
Here we take a stepfurther and demonstrate the informativeness ofthese parameters.We show that one of the predictive discoursestructure-based parameters (PopUp-Incorrect)informs a promising modification of our system.1 Although this terminology is not yet established in theSDS community, the investigations behind these propertiesare a common practice in the field.178We implement this modification and we compareit with the original version of the system througha user study.
Our analyses indicate that the modi-fication leads to objective improvements for oursystem (e.g.
performance improvements for cer-tain users but not at the population level andfewer system turns).2 BackgroundITSPOKE (Intelligent Tutoring Spoken Dia-logue System) (Litman et al, 2006) is a speech-enabled version of the text-based Why2-Atlasconceptual physics tutoring system (VanLehn etal., 2007).
The interaction between ITSPOKEand users is mediated through a graphical webinterface supplemented with a headphone-microphone unit.
ITSPOKE first analyzes a usertyped essay response to a physics problem formistakes and omissions.
Then it engages in aspoken dialogue to remediate the identified prob-lems.
Finally, users revise their essay andITSPOKE either does another round of tutor-ing/essay revision if needed or moves on to thenext problem.While for most information access SDS per-formance is measured using task completion oruser satisfaction, for the tutoring SDS the pri-mary performance metric is learning.
To measurelearning, users take a knowledge test before andafter interacting with ITSPOKE.
The NormalizedLearning Gain (NLG) is defined as (posttest-pretest)/(1-pretest) and measures the percentageimprovement relative to the perfect improve-ment: an NLG of 0.0 means no improvementwhile an NLG of 1.0 means maximum improve-ment.2.1 Discourse structureWe use the Grosz & Sidner theory of discourse(Grosz and Sidner, 1986).
According to this the-ory, dialogue utterances naturally aggregate intodiscourse segments, with each segment having anassociated purpose or intention.
These segmentsare hierarchically organized forming the dis-course structure hierarchy.
This hierarchical as-pect of dialogue has inspired several generic dia-logue management frameworks (e.g.
RavenClaw(Bohus, 2007)).
We briefly describe our auto-matic annotation of this hierarchy and its usethrough discourse transitions.
A sample exampleis shown in Appendix 1.
For more details see(Rotaru and Litman, 2006).Since dialogues with ITSPOKE follow a ?tu-tor question - user answer - tutor response?
for-mat, which is hand-authored beforehand in a hi-erarchical structure, we can easily approximatethe discourse structure hierarchy.
After the essayanalysis, ITSPOKE selects a group of questionswhich are asked one by one.
These questionsform the top-level discourse segment (e.g.
DS1in Appendix 1).
For incorrect answers to morecomplex questions (e.g.
applying physics laws),ITSPOKE will engage in a remediation subdia-logue that attempts to remediate the student?slack of knowledge or skills.
These subdialoguesform the embedded discourse segments (e.g.
DS2in Appendix 2).We define six discourse transitions in the dis-course structure hierarchy and use them to labeleach system turn.
A NewTopLevel label is usedfor the first question after an essay submission.
Ifthe previous question is at the same level withthe current question we label the current questionas Advance.
The first question in a remediationsubdialogue is labeled as Push.
After a remedia-tion subdialogue is completed, ITSPOKE willpop up and a heuristic determines whether to askagain the question that triggered the remediationdialogue.
Reasking is labeled as a PopUp, whilemoving on to the next question is labeled asPopUpAdv.
Rejections due to speech problems ortimeouts are labeled as SameGoal.Our transitions partially encode the hierarchi-cal information of discourse structure: they cap-ture the position of each system turn in this hier-archy relative to the previous system turn.2.2 Discourse structure-based interactionparametersTo derive interaction parameters, we look attransition?phenomena and transition?transitionbigrams.
The first type of bigrams is motivatedby our intuition that dialogue phenomena relatedto performance are not uniformly important buthave more weight depending on their position inthe dialogue.
For example, it is more importantfor users to be correct at specific places in thedialogue rather than overall in the dialogue.
Weuse two phenomena related to performance in oursystem/domain: user correctness (e.g.
correct,incorrect) and user certainty (e.g.
uncertain, neu-tral, etc.).
For example, a PopUp-Incorrect eventoccurs whenever users are incorrect after beingreasked the question that initially triggered theremediation dialogue.
The second type of bi-grams is motivated by our intuition that ?good?and ?bad?
dialogues have different discoursestructures.
To compare two dialogues in terms of179the discourse structure we look at consecutivetransitions: e.g.
Push-Push.For each bigram we compute 3 interaction pa-rameters: a total (e.g.
the number of PopUp-Incorrect events), a percentage (e.g.
the numberof PopUp-Incorrect relative to the number ofturns) and a relative percentage (e.g.
the percent-age of times a PopUp is followed by an incorrectanswer).3 PredictivenessIn (Rotaru and Litman, 2006), we demonstratethe predictiveness of several discourse structure-based parameters.
Here we summarize the resultsfor parameters derived from the PopUp?Correctand PopUp?Incorrect bigrams (Table 1).
Thesebigrams caught our attention as their predictive-ness has intuitive interpretations and generalizesto other corpora.
Predictiveness was measured bylooking at correlations (i.e.
univariate linear re-gression) between our interaction parameters andlearning2.
We used a corpus of 95 dialogues from20 users (2334 user turns).
For brevity, we reportin Table 1 only the bigram, the best Pearson?sCorrelation Coefficient (R) associated with pa-rameters derived from that bigram and the statis-tical significance of this coefficient (p).R pPopUp-Correct 0.45 0.05PopUp-Incorrect -0.46 0.05BigramTable 1.
Several discourse structure-based parameterssignificantly correlated with learning(for complete results see (Rotaru and Litman, 2006))The two bigrams shed light into user?s learn-ing patterns.
In both cases, the student has justfinished a remediation subdialogue and the sys-tem is popping up by reasking the original ques-tion again (a PopUp transition).
We find that cor-rect answers after a PopUp are positively corre-lated with learning.
In contrast, incorrect answersafter a PopUp are negatively correlated withlearning.
We hypothesize that these correlationsindicate whether the user took advantage of theadditional learning opportunities offered by theremediation subdialogue.
By answering correctlythe original system question (PopUp?Correct),the user demonstrates that he/she has absorbedthe information from the remediation dialogue.This bigram is an indication of a successfullearning event.
In contrast, answering the origi-2 As it is commonly done in the tutoring research (e.g.
(Lit-man et al, 2006)), we use partial Pearson?s correlationsbetween our parameters and the posttest score that accountfor the pretest score.nal system question incorrectly (PopUp?Incorrect) is an indication of a missed learningopportunity; the more such events happen theless the user learns.In  (Rotaru and Litman, 2006) we also demon-strate that discourse structure is an importantsource for producing predictive parameters.
In-deed, we found that simple correctness parame-ters (e.g.
number of incorrect answers) are sur-prisingly not predictive in our domain.
In con-trast, parameters that look at correctness at spe-cific places in the discourse structure hierarchyare predictive (e.g.
PopUp?Incorrect).4 InformativenessWe investigate the informativeness of thePopUp?Incorrect bigram as in (Rotaru, 2008) wealso show that its predictiveness generalizes totwo other corpora.
We need 3 things for this: aninterpretation of the predictiveness (i.e.
an inter-pretation of the correlation), a new system strat-egy derived from this interpretation and a valida-tion of the strategy.As mentioned in Section 3, our interpretationof the correlation between PopUp?Incorrectevents and learning is that these events signalfailed learning opportunities.
The remediationsubdialogue is the failed learning opportunity:the system had a chance to correct user?s lack ofknowledge and failed to achieve that.
The moresuch events we see, the lesser the system per-formance.How can we change the system in light of thisinterpretation?
We propose to give additionalexplanations after a PopUp?Incorrect event asthe new strategy.
To arrive at this strategy, wehypothesized why the failed opportunity has oc-curred.
The simplest answer is that the user hasfailed to absorb the information from the reme-diation dialogue.
It is possible that the user didnot understand the remediation dialogue and/orfailed to make the connection between the reme-diation dialogue and the original question.
Thecurrent ITSPOKE strategy after a PopUp?Incorrect is to give away the correct answer andmove on.
The negative correlations indicate thatthis strategy is not working.
Thus, maybe itwould be better if the system will engage in addi-tional explanations to correct the user.
If we canmake the user understand, then we transform thefailed learning opportunity into a successfullearning opportunity.
This will be equivalent to aPopUp?Correct event which we have seen ispositively correlated with learning (Section 3).180While other interpretation and hypothesesmight also be true, our results (Section 5) showthat the new strategy is successful.
This validatesthe interpretation, the strategy and consequentlythe informativeness of the parameter.4.1 ModificationTo modify the system, we had to implement thenew PopUp?Incorrect strategy: provide addi-tional explanations rather than simply givingaway the correct answer and moving on.
But howto deliver the additional explanations?
One wayis to engage in an additional subdialogue.
How-ever, this was complicated by the fact that we didnot know exactly what information to conveyand/or what questions to ask.
It was crucial thatthe information and/or the questions were on tar-get due to the extra burden of the new subdia-logue.Instead, we opted for a different implementa-tion of the strategy: interrupt the conversation atPopUp?Incorrect events and offer the additionalexplanations in form of a webpage that the userwill read (recall that ITSPOKE uses in addition agraphical web interface ?
Section 2).
Each poten-tial PopUp?Incorrect event had an associatedwebpage that is displayed whenever the eventoccurs.
Because the information was presentedvisually, users can choose which part to read,which meant that we did not have to be on targetwith our explanations.
To return to the spokendialogue, users pressed a button when done read-ing the webpage.All webpages included several pieces of in-formation we judged to be helpful.
We includedthe tutor question, the correct answer and a textsummary of the instruction so far and of theremediation subdialogue.
We also presented agraphical representation of the discourse struc-ture, called the Navigation Map.
Our previouswork (Rotaru and Litman, 2007) shows that usersprefer this feature over not having it on manysubjective dimensions related to understanding.Additional information not discussed by the sys-tem was also included if applicable: intuitionsand examples from real life, the purpose of thequestion with respect to the current problem andprevious problems and/or possible pitfalls.
SeeAppendix 2 for a sample webpage.The information we included in the PopUp?Incorrect webpages has a ?reflective?
nature.
Forexample, we summarize and discuss the relevantinstruction.
We also comment on the connectionbetween the current problem and previous prob-lems.
The value of ?reflective?
information hasbeen established previously e.g.
(Katz et al,2003).All webpages and their content were createdby one of the authors.
All potential places forPopUp?Incorrect events (i.e.
system questions)were identified and a webpage was authored foreach question.
There were 24 such places out ofa total of 96 questions the system may ask duringthe dialogue.5 ResultsThere are several ways to demonstrate the suc-cess of the new strategy.
First, we can investigateif the correlation between PopUp?Incorrect andlearning is broken by the new strategy.
Our re-sults (5.2) show that this is true.
Second, we canshow that the new system outperforms the oldsystem.
However, this might not be the best wayas the new PopUp?Incorrect strategy directlyaffects only people with PopUp?Incorrect events.In addition, its effect might depend on how manytimes it was activated.
Indeed, we find no sig-nificant effect of the new strategy in terms ofperformance at the population level.
However,we find that the new strategy does produce a per-formance improvement for users that ?needed?
itthe most: users with more PopUp?Incorrectevents (5.3).We begin by describing the user study andthen we proceed with our quantitative evalua-tions.5.1 User studyTo test the effect of the new PopUp?Incorrectstrategy, we designed and performed a between-subjects study with 2 conditions.
In the controlcondition (R) we used the regular version ofITSPOKE with the old PopUp?Incorrect strategy(i.e.
give the current answer and move on).
In theexperimental condition (PI), we had the regularversion of ITSPOKE with the new PopUp?Incorrect strategy (i.e.
give additional informa-tion).The resulting corpus has 22 R users and 25 PIusers and it is balanced for gender.
There are 235dialogues and 3909 user turns.
The experimenttook 2?
hours per user on average.5.2 Breaking the correlationThe predictiveness of the PopUp?Incorrect bi-gram (i.e.
its negative correlation with learning)means that PopUp?Incorrect events signal lowerperformance.
One way to validate the effective-181ness of the new PopUp?Incorrect strategy is toshow that it breaks down this correlation.
Inother words, PopUp?Incorrect events no longersignal lower performance.
Simple correlationdoes not guarantee that this is true because corre-lation does not necessarily imply causality.In our experiment, this translates to showingthat that PopUp?Incorrect bigram parameters arestill correlated with learning for R students butthe correlations are weaker for PI students.Table 2 shows these correlations.
As in Table 1,we show only the bigrams for brevity.R p R pPopUp-Correct 0.60 0.01 0.18 0.40PopUp-Incorrect -0.65 0.01 -0.18 0.40BigramR  users PI usersTable 2.
Correlation with learning in each conditionWe find that the connection between user be-havior after a PopUp transition and learning con-tinues to be strong for R users.
PopUp?Incorrectevents continue to signal lower performance (i.e.a strong significant negative correlation of-0.65).
PopUp?Correct events signal increasedperformance (i.e.
a strong significant positivecorrelation of +0.60).
The fact that these correla-tions generalize across experiments/corpora fur-ther strengthens the predictiveness of thePopUp?Incorrect parameters.PopUp-Incorrect (rel %)NLG0% 20% 40% 60% 80%0.00.10.20.30.40.50.60.70.80.9PIRFigure 1.
Correlations between a PopUp-Incorrectparameter and NLGIn contrast, for PI users these correlations aremuch weaker with non-significant correlationcoefficients of -0.18 and 0.18 respectively.
Inother words the new PopUp?Incorrect strategybreaks down the observed correlation: PopUp?Incorrect events are no longer a good indicator oflower performance.It is interesting to visualize these correlationsgraphically.
Figure 1 shows a scatter plot of thePopUp?Incorrect relative percentage parameterand NLG for each PI and R user.
The regressionlines for the correlation between PopUp?Incorrect and NLG for PI and R are shown.
Thegraph shows that users with less PopUp?Incorrect events (e.g.
less than 30% relative) tendto have a higher NLG (0.5 or higher) regardlessof the condition.
However, for users with morePopUp?Incorrect events, the behavior dependson the condition: R users (crosses) tend to havelower NLG (0.5 or lower) while PI users (cir-cles) tend to cover the whole NLG spectrum (0.2to 0.73).
Our next analysis will provide objectivesupport for this observation.5.3 Performance improvementsThe simplest way to investigate the effect of thenew PopUp?Incorrect strategy is to compare thetwo systems in terms of performance (i.e.
learn-ing).
Table 3 shows in the second column thelearning (NLG) in each condition.
We find thatthe new strategy provides a small 0.02 perform-ance improvement (0.48 vs. 0.46), but this effectis far from being significant.
A one-wayANOVA test finds no significant effect of thecondition on the NLG (F(1,45)=0.12, p<0.73).All Low HighPI 0.48 (0.19) 0.49 (0.21) 0.48 (0.17)R 0.46 (0.19) 0.56 (0.13) 0.30 (0.18)PI SplitTable 3.
System performance (NLG) in each condi-tion(averages and standard deviation in parentheses)There are several factors that contribute to thislack of significance.
First, the new PopUp?Incorrect strategy is only activated by users thathave PopUp?Incorrect events.
Including userswithout such events in our comparison couldweaken the effect of the new strategy.
Second,the impact of the new strategy might depend onhow many times it was activated.
This relatesback to our hypothesis that that a PopUp?Incorrect is an instance of a failed learning op-portunity.
If this is true and our new PopUp?Incorrect strategy is effective, then we should seea stronger impact on PI users with a highernumber of PopUp?Incorrect events comparedwith the similar R users.To test if the impact of the strategy depends onhow many times it was engaged, we split usersbased on their PopUp?Incorrect (PISplit) behav-ior into two subsets: Low and High.
We used the182mean split based on the PopUp?Incorrect relativepercentage parameter (see the X axis in Figure1): users with a parameter value less than 30% gointo the Low subset (15 PI and 14 R users) whilethe rest go into the High subset (10 PI and 8 Rusers).Results are shown in the third and the fourthcolumns in Table 3.
To test the significance ofthe effect, we run a two-way factorial ANOVAwith NLG as the dependent variable and two fac-tors: PISplit (Low vs. High) and Condition (PIvs.
R).
We find a significant effect of the combi-nation PISplit ?
Condition (F(1,43)=5.13,p<0.03).
This effect and the results of the post-hoc tests are visualized in Figure 2.
We find thatPI users have a similar NLG regardless of theirPopUp?Incorrect behavior while for R, High PI-Split users learn less than Low PISplit users.Posthoc tests indicate that High PISplit R userslearn significantly less than Low PISplit R users(p<0.01) and both categories of PI users(p<0.05).
In other words, there is an inherent andsignificant performance gap between R users inthe two subsets.
The effect of the new PopUp?Incorrect strategy is to bridge this gap and bringHigh PISplit users to the performance level ofthe Low PISplit users.
This confirms that the newPopUp?Incorrect strategy is effective where it ismost needed (i.e.
High PISplit users).pi rcondition0.10.20.30.40.50.60.7NLGLHFigure 2.
PISplit ?
Condition effect on NLG(bars represent 95% confidence intervals)It is interesting to note that Low PISplit R us-ers learn better than both categories of PI usersalthough the differences are not significant.
Wehypothesize this happens because not all learningissues are signaled by PopUp?Incorrect events: auser might still have low learning even if he/shedoes not exhibit any PopUp?Incorrect events.Indeed, there are two PI users with a singlePopUp?Incorrect event but with very low learn-ing (NLG of 0.00 and 0.14 respectively).
It isvery likely that other things went wrong for theseusers rather than the activation of the newPopUp?Incorrect strategy (e.g.
they might haveother misconceptions that are not addressed bythe remediation subdialogues).
In fact, removingthese two users results in identical NLG averagesfor the two low PISplit subsets.5.4 Dialogue durationWe also wanted to know if the new PopUp?Incorrect strategy has an effect on measures ofdialogue duration.
The strategy delivers addi-tional explanations which can result in an in-crease in the time users spend with the system(due to reading of the new instruction).
Also,when designing tutoring systems researchersstrive for learning efficiency: deliver increasedlearning as fast as possible.Total time(min)No.
of sys.turnsPI 44.2 (6.2) 86.4 (6.8)R 45.5 (5.7) 90.9 (9.3)Table 4.
Dialogue duration metrics(averages and standard deviation in parentheses)We look at two shallow dialogue metrics: dia-logue time and number of turns.
Table 4 showsthat, in fact, the dialogue duration is shorter forPI users on both metrics.
A one way ANOVAfinds a non-significant effect on dialogue time(F(1,45)=0.57, p<0.45) but a trend effect fornumber of system turns (F(1,45)=3.72, p<0.06).We hypothesize that 2 factors are at play here.First, the additional information activated by thenew PopUp?Incorrect strategy might have apositive effect on users?
correctness for futuresystem questions especially on questions thatdiscuss similar topics.
As a result, the system hasto correct the user less and, consequently, finishfaster.
Second, the average total time PI usersspend reading the additional information is verysmall (about 2 minutes) compared to the averagedialogue time.6 Related workDesigning robust, efficient and usable spokendialogue systems (SDS) is a complex processthat is still not well understood by the SDS re-search community (M?ller and Ward, 2008).Typically, a number of evaluation/performance183metrics are used to compare multiple (versionsof) SDS.
But what do these metrics and the re-sulting comparisons tell us about designing SDS?There are several approaches to answering thisquestion, each requiring a different level of su-pervision.One approach that requires little human super-vision is to use reinforcement learning.
In thisapproach, the dialogue is modeled as a (partiallyobservable) Markov Decision Process (Levin etal., 2000; Young et al, 2007).
A reward is givenat the end of the dialogue (i.e.
the evaluationmetric) and the reinforcement learning processpropagates back the reward to learn what the beststrategy to employ at each step is.
Other semi-automatic approaches include machine learningand decision theoretic approaches (Levin andPieraccini, 2006; Paek and Horvitz, 2004).
How-ever, these semi-automatic approaches are feasi-ble only in small and limited domains thoughrecent work has shown how more complex do-mains can be modeled (Young et al, 2007).An approach that works on more complexdomains but requires more human effort isthrough performance analysis: finding and tack-ling factors that affect the performance (e.g.PARADISE (Walker et al, 2000)).
Central tothis approach is the quality of the interaction pa-rameters in terms of predicting the performancemetric (predictiveness) and informing usefulmodifications of the system (informativeness).An extensive set of parameters can be found in(M?ller, 2005).Our use of discourse structure for performanceanalysis extends over previous work in two im-portant aspects.
First, we exploit in more detailthe hierarchical information in the discoursestructure through the domain-independent con-cept of discourse structure transitions.
Most pre-vious work does not use this information (e.g.
(M?ller, 2005)) or, if used, it is flattened (Walkeret al, 2001).
Also, to our knowledge, previouswork has not employed parameters similar to ourtransition?phenomena (transition?correctness inthis paper) and transition?transition bigram pa-rameters.
In addition, several of these parametersare predictive (Rotaru and Litman, 2006).Second, in our work we also look at the in-formativeness while most of the previous workstops at the predictiveness step.
A notable excep-tion is the work by (Litman and Pan, 2002).
Thefactor they look at is user?s having multiplespeech recognition problems in the dialogue.This factor is well known in the SDS field and ithas been shown to be predictive of system per-formance by previous work (e.g.
(Walker et al,2000)).
To test the informativeness of this factor,Litman and Pan propose a modification of thesystem in which the initiative and confirmationstrategies are changed to more conservative set-tings whenever the event is detected.
Their re-sults show that the modified version leads to im-provements in terms of system performance (taskcompletion).
We extend over their work by look-ing at a factor (PopUp?Incorrect) that was notknown to be predictive of performance before-hand.
We discover this factor through our em-pirical analyses of existing dialogues and weshow that by addressing it (the new PopUp?Incorrect strategy) we also obtain performanceimprovements (at least for certain users).
In addi-tion, we are looking at a performance metric forwhich significant improvements are harder toobtain with small system changes (e.g.
(Graesseret al, 2003)).7 ConclusionsIn this paper we finalize our investigation intothe utility of discourse structure for SDS per-formance analysis (at least for our system).
Weuse the discourse structure transition informationin combination with other dialogue phenomenato derive a number of interaction parameters (i.e.transition?phenomena and transition?transition).Our previous work (Rotaru and Litman, 2006)has shown that these parameters are predictive ofsystem performance.
Here we take a step furtherand show that one of these parameters (thePopUp?Incorrect bigram) is also informative.From the interpretation of its predictiveness, weinform a promising modification of our system:offer additional explanations after PopUp?Incorrect events.
We implement this modifica-tion and we compare it with the original systemthrough a user study.
We find that the modifica-tion breaks down the negative correlation be-tween PopUp?Incorrect and system performance.In addition, users that need the modification themost (i.e.
users with more PopUp?Incorrectevents) show significant improvement in per-formance in the modified system over corre-sponding users in the original system.
However,this improvement is not strong enough to gener-ate significant differences at the population level.Even though the additional explanations add ex-tra time to the dialogue, overall we actually see asmall reduction in dialogue duration.Our work has two main contributions.
First,we demonstrate the utility of discourse structure184for performance analysis.
In fact, our other work(Rotaru and Litman, 2007) shows that discoursestructure is also useful for other SDS tasks.
Sec-ond, to our knowledge, we are the first to show acomplete application of the performance analysismethodology.
We discover a new set of predic-tive interaction parameters in our system and weshow how our system can be improved in light ofthese findings.
Consequently, we validate per-formance analysis as an iterative, ?debugging?approach to dialogue design.
By analyzing cor-pora collected with an initial version of the sys-tem, we can identify semi-automatically prob-lems in the dialogue design.
These problems in-form a new version of the system which will betested for performance improvements.
In termsof design methodology for tutoring SDS, our re-sults suggest the following design principle: ?donot give up but try other approaches?.
In ourcase, we do not give up after a PopUp-Incorrectbut give additional explanations.In the future, we would like to extend ourwork to other systems and domains.
This shouldbe relatively straightforward as the main ingredi-ents, the discourse transitions, are domain inde-pendent.AcknowledgmentsThis work is supported by the NSF grants0328431 and 0428472.
We would like to thankthe ITSPOKE group.ReferencesD.
Bohus.
2007.
Error Awareness and Recovery inConversational Spoken Language Interfaces.
Ph.D.Dissertation, Carnegie Mellon University, Schoolof Computer ScienceA.
Graesser, K. Moreno, J. Marineau, A. Adcock, A.Olney and N. Person.
2003.
AutoTutor improvesdeep learning of computer literacy: Is it the dialogor the talking head?
In Proc.
of Artificial Intelli-gence in Education (AIED).B.
Grosz and C. L. Sidner.
1986.
Attentions, inten-tions and the structure of discourse.
ComputationalLinguistics, 12(3).S.
Katz, D. Allbritton and J. Connelly.
2003.
GoingBeyond the Problem Given: How Human TutorsUse Post-Solution Discussions to Support Transfer.International Journal of Artificial Intelligence inEducation (IJAIED), 13.E.
Levin and R. Pieraccini.
2006.
Value-based opti-mal decision for dialogue systems.
In Proc.
ofIEEE/ACL Workshop on Spoken Language Tech-nology (SLT).E.
Levin, R. Pieraccini and W. Eckert.
2000.
A Sto-chastic Model of Human Machine Interaction forLearning Dialog Strategies.
IEEE Transactions onSpeech and Audio Processing, 8:1.D.
Litman and S. Pan.
2002.
Designing and Evaluat-ing an Adaptive Spoken Dialogue System.
UserModeling and User-Adapted Interaction, 12(2/3).D.
Litman, C. Rose, K. Forbes-Riley, K. VanLehn, D.Bhembe and S. Silliman.
2006.
Spoken VersusTyped Human and Computer Dialogue Tutoring.International Journal of Artificial Intelligence inEducation, 16.S.
M?ller.
2005.
Parameters for Quantifying the In-teraction with Spoken Dialogue Telephone Services.In Proc.
of SIGDial.S.
M?ller and N. Ward.
2008.
A Framework forModel-based Evaluation of Spoken Dialog Systems.In Proc.
of Workshop on Discourse and Dialogue(SIGDial).T.
Paek and E. Horvitz.
2004.
Optimizing AutomatedCall Routing by Integrating Spoken Dialog Modelswith Queuing Models.
In Proc.
of HLT-NAACL.A.
Raux and M. Eskenazi.
2008.
Optimizing End-pointing Thresholds using Dialogue Features in aSpoken Dialogue System.
In Proc.
of 9th SIGdialWorkshop on Discourse and Dialogue.M.
Rotaru.
2008.
Applications of Discourse Structurefor Spoken Dialogue Systems.
Ph.D. Dissertation,University of Pittsburgh, Department of ComputerScienceM.
Rotaru and D. Litman.
2006.
Exploiting DiscourseStructure for Spoken Dialogue Performance Analy-sis.
In Proc.
of EMNLP.M.
Rotaru and D. Litman.
2007.
The Utility of aGraphical Representation of Discourse Structurein Spoken Dialogue Systems.
In Proc.
of ACL.S.
Singh, D. Litman, M. Kearns and M. Walker.
2002.Optimizing Dialogue Management with Rein-forcement Learning: Experiments with the NJFunSystem.
Journal of Artificial Intelligence Research,(16).K.
VanLehn, A. C. Graesser, G. T. Jackson, P. Jordan,A.
Olney and C. P. Rose.
2007.
When are tutorialdialogues more effective than reading?
CognitiveScience, 31(1).M.
Walker, D. Litman, C. Kamm and A. Abella.
2000.Towards Developing General Models of Usabilitywith PARADISE.
Natural Language Engineering.M.
Walker, R. Passonneau and J. Boland.
2001.Quantitative and Qualitative Evaluation of DarpaCommunicator Spoken Dialogue Systems.
In Proc.of ACL.S.
Young, J. Schatzmann, K. Weilhammer and H. Ye.2007.
The Hidden Information State Approach toDialog Management.
In Proc.
of ICASSP.185DS 1TUTOR1: Consider Newton's laws applied to twoobjects that move together.
What threequantities does Newton's Second Lawdescribe the relationship between?Student answer1: correct (e.g.
force, mass, accel.
)TUTOR2: If two bodies are connected so that they movetogether and you know the acceleration of thefirst body, what is the acceleration of thesecond body?Student answer2: incorrect (e.g.
zero)TUTOR5: If a force acts on one body suchthat it moves, what happens to the secondbody?Student answer5: incorrect but rejected (e.g.
stays)TUTOR6: Could you please repeat that?
?DS 2TUTOR3: If the two bodies always movetogether and one body speeds up,what happens to the other?Student answer3: incorrect (e.g.
lags behind)TUTOR4: The second body will speed up too.
Ifthe first body accelerates at aparticular rate, will the second bodyaccelerate at an equal or differentrate?Student answer4: correct (e.g.
equal)ESSAY SUBMISSION & ANALYSISAppendix 1.
Automatic annotation of discourse structure hierarchy and of discourse structure transitionsDiscourse structure hierarchy annotation: DS1 is the top level discourse segment.
Its purpose isto correct misconceptions in user?s essay and/or to elicit more complete explanations for theessay.
DS2 is an embedded discourse segment which corresponds to the remediation subdia-logue for question Tutor2.Discourse structure transition annotation: Each transition labels the system turn at the tip of thearrow (e.g.
Tutor2 is labeled with Advance).
Please note that Tutor2 will not be labeled withPopUp because, in such cases, an extra system turn will be created between Tutor4 and Tutor5with the same content as Tutor2.
This extra turn also includes variations of ?Ok, back to theoriginal question?
to mark the discourse segment boundary transition.186Appendix 2.
Sample additional instructions webpageProblem discussed by ITSPOKE: Suppose a man is running in a straight line at constant speed.He throws a pumpkin straight up.
Where will it land?
Explain.Location in the dialogue: For this problem, ITSPOKE discusses what happens during threetime frames: before pumpkin toss, during pumpkin toss and after pumpkin toss.
ITSPOKE iscurrently discussing the forces and the net force on the pumpkin during the toss.187
