Last WordsAncient Symbols, Computational Linguistics,and the Reviewing Practices of the GeneralScience JournalsRichard Sproat?Center for Spoken LanguageUnderstanding1.
IntroductionFew archaeological finds are as evocative as artifacts inscribed with symbols.
Wheneveran archaeologist finds a potsherd or a seal impression that seems to have symbolsscratched or impressed on the surface, it is natural to want to ?read?
the symbols.
Andif the symbols come from an undeciphered or previously unknown symbol system itis common to ask what language the symbols supposedly represent and whether thesystem can be deciphered.Of course the first question that really should be asked is whether the symbols arein fact writing.
A writing system, as linguists usually define it, is a symbol system thatis used to represent language.
Familiar examples are alphabets such as the Latin, Greek,Cyrillic, or Hangul alphabets, alphasyllabaries such as Devanagari or Tamil, syllabariessuch as Cherokee or Kana, and morphosyllabic systems like Chinese characters.
Butsymbol systems that do not encode language abound: European heraldry, mathematicalnotation, labanotation (used to represent dance), and Boy Scout merit badges are allexamples of symbol systems that represent things, but do not function as part of asystem that represents language.Whether an unknown system is writing or not is a difficult question to answer.It can only be answered definitively in the affirmative if one can develop a verifiabledecipherment into some language or languages.
Statistical techniques have been used indecipherment for years, but these have always been used under the assumption that thesystem one is dealing with is writing, and the techniques are used to uncover patterns orregularities that might aid in the decipherment.
Patterns of symbol distribution mightsuggest that a symbol system is not linguistic: For example, odd repetition patternsmight make it seem that a symbol system is unlikely to be writing.
But until recentlynobody had argued that statistical techniques could be used to determine that a systemis linguistic.1It was therefore quite a surprise when, in April 2009, there appeared in Sciencea short article by Rajesh Rao of the University of Washington and colleagues at tworesearch institutes in India that purported to provide such a measure (Rao et al 2009a).Rao et al?s claim, which we will describe in more detail in the next section, was that?
Center for Spoken Language Understanding, Oregon Health & Science University, 20000 NW Walker Rd,Beaverton, OR, 97006, USA.
E-mail: rws@xoba.com.1 People have used the existence of quasi-Zipfian distributions in symbol systems to argue for their statusas writing; such claims figure in the work of Rao and colleagues.
But because it has been long known thatZipfian distributions hold of many things besides language, such arguments are easy to dismiss.?
2010 Association for Computational LinguisticsComputational Linguistics Volume 36, Number 3one could use conditional entropy as evidence that the famous symbol system of the thirdmillenium BCE Indus Valley civilization was most probably writing, and not some otherkind of system.That the Indus symbols were writing is hardly a novel claim.
Indeed, ever since thefirst seal impression was found at Harappa (1872?1873 CE), it has been the standardassumption that the symbols were part of a writing system and that the Indus Valleycivilization was literate.
Over the years there have been literally hundreds of claimsof decipherment, the most well-known of these being the work of Asko Parpola andcolleagues over the last four decades (Parpola 1994).
Parpola, who argues that the IndusValley people spoke an early form of Dravidian, has produced interpretations of a smallset of symbols, but nothing that can be characterized as a decipherment.The first serious arguments against the idea that the Indus symbols were part ofa writing system were presented in work that Steve Farmer, Michael Witzel, and Ipublished in Farmer, Sproat, and Witzel (2004), which reviews extensive support for thatview from archaeological evidence and comparisons with other ancient symbol systems.Although our arguments were certainly not universally acknowledged?least of allamong people who had spent most of their careers trying to decipher the symbols?they have been accepted by many archaeologists and linguists, and established a viablealternative view to the traditional view of these symbols.
It was against this backdropthat the Rao et al (2009a) paper appeared.Taken at face value, Rao et al?s (2009a) paper would appear to have reestablishedthe traditional view of the Indus symbols as the correct one, and indeed that is how thepaper was received by many who read it.
A number of articles appeared in the popularscience press, with Wired declaring ?Artificial Intelligence Cracks Ancient Mystery?
(Keim 2009).
The Indian press had a field day; they had studiously ignored the evidencereported in our paper, presumably because it led to the unpalatable conclusion thatIndia?s earliest civilization was illiterate.
But Rao et al?s paper, which appeared todemonstrate the opposite, was widely reported.The work has also apparently attracted attention beyond the popular science pressand those with some sort of axe to grind on the Indus Valley issue, for in March 2010there appeared in the Proceedings of the Royal Society, Series A, a paper that used similartechniques to Rao et al?s (2009a) in order to argue that ancient Pictish symbols, whichare found inscribed on about 300 standing stones in Scotland, are in fact a previously un-recognized ancient writing system (Lee, Jonathan, and Ziman 2010).
A trend, it seems,has been established: We now have a set of statistical techniques that can distinguishamong ancient symbol systems and tell you which ones were writing and which oneswere not.The only problem is that these techniques are in fact useless for this purpose, andfor reasons that are rather trivial and easy to demonstrate.
The remainder of this articlewill be devoted to two points.
First, in Section 2, I review the techniques from the Raoet al (2009a) and Lee, Jonathan, and Ziman (2010) papers, and show why they don?twork.
The demonstration will seem rather obvious to any reader of this journal.
Andthis in turn brings us to the second point: How is it that papers that are so trivially anddemonstrably wrong get published in journals such as Science or the Proceedings of theRoyal Society?
Both papers relate to statistical language modeling, which is surely oneof the core techniques in computational linguistics, yet (apparently) no computationallinguists were asked to review these papers.
Would a paper that made some blatantlywrong claim about genetics be published in such venues?
What does this say about ourfield and its standing in the world?
And what can we do about that?
Those questionsare the topic of Section 3.586Sproat Ancient Symbols and Computational Linguistics2.
The FallaciesRao et al?s (2009a) paper is a typical short paper in Science consisting of a page of textand figures, and a link to a longer description that details the techniques and data.The main paper?which is presumably all that most people would read?contains aconvincing-looking plot, their Figure 1A, here reproduced as Figure 1.
The plot purportsto show that bigram conditional entropy , defined asH(Y|X) = ?
?x?X ,y?Yp(x, y)logp(y|x) (1)can distinguish between non-linguistic symbol systems and linguistic symbol systems,and that the Indus Valley symbols behave like linguistic symbol systems.The plot looks very convincing indeed, but what does it mean?Several aspects of the plot require explanation.
First the horizontal axis, labeledas ?number of tokens,?
represents the bigram conditional entropy of subsets of eachcorpus starting with the subset consisting of the 20 most common symbols, the 40most common symbols, the 60 most common symbols, and so forth.
What we see foreach corpus is that the conditional entropy grows over these successive subsets until itapproaches the conditional entropy of the corpus as a whole.Second, the corpora represent small samples of various languages including En-glish (sampled both as words and letters), Sumerian (cuneiform symbols), Old Tamil(largely consonant?vowel combinations in the Tamil alphasyllabary), the Indus Valleycorpus due to Mahadevan (1977), and two types of non-linguistic systems (though seesubsequent discussion).
The sample sizes are small because the Indus corpus againstwhich all other symbol systems are compared is very small.
The average length of anIndus ?inscription?
(in Mahadevan?s corpus) is only about 4.5 symbols; the total size ofFigure 1Conditional entropies for a variety of linguistic scripts and other symbol systems.
From:Rao, Rajesh, Nisha Yadav, Mayank Vahia, Hrishikesh Joglekar, R. Adhikari, and IravathamMahadevan.
2009.
Entropic evidence for linguistic structure in the Indus script.
Science,324(5931):1165.
Figure 1A, page 1165.
Reprinted with permission from AAAS.
Poor qualityof the figure is due to poor quality in the original.587Computational Linguistics Volume 36, Number 3the Mahadevan corpus is 7,000 tokens (and about 400 types).
Though Rao et al (2009a)make a point of stressing that they use sophisticated smoothing techniques (a modifiedversion of Kneser-Ney), one must remember that with such small data sets, smoothingcan only do so much for you.Third, the curves labeled as ?Type 1?
and ?Type 2?
non-linguistic systems areexplained as follows:Two major types of nonlinguistic systems are those that do not exhibit much sequentialstructure (?Type 1?
systems) and those that follow rigid sequential order (?Type 2?systems).
For example, the sequential order of signs in Vinc?a inscriptions appears tohave been unimportant.
On the other hand, the sequences of deity signs in Near Easterninscriptions found on boundary stones (kudurrus) typically follow a rigid order that isthought to reflect the hierarchical ordering of the deities.
(Rao et al 2009a, page 1165)On the face of it, it is not too surprising, given these descriptions, that the Type 1 systemshows rapid growth in the conditional entropy, whereas Type 2 stays close to zero.
Theproblem is that there is little evidence that either of these types accurately characterizedany ancient symbol system.
So for example, the Vinc?a symbols of Old Europe werecertainly not random in their distribution according to the most authoritative source onthe topic (Winn 1981).2 Indeed, Gimbutas (1989) and Haarmann (1996) even proposedthat they represented a pre-Sumerian European script; although that is highly unlikely,it is also unlikely they would have proposed the idea in the first place if the distributionof symbols seemed random.
Similarly, it is apparently not the case that the deity symbolsin kudurrus were arranged in a rigid order (see subsequent discussion): Clearly it is notonly computational linguists who should be bothered by the claims of this paper.
In fact,as one learns only if one reads the supplementary material for the paper, the data forType 1 and Type 2 were artificially generated from a rigid model (Type 2) and a randomand equiprobable model (Type 1).Various on-line discussions, starting with Farmer, Sproat, and Witzel (2009), crit-icized Rao et al (2009a) for their use of artificial data.3 So, in subsequent discussion,including a recently published paper (Rao 2010) that largely rehashes the issues ofboth the Science paper and another paper in PNAS (Rao et al 2009b),4 Rao backs offfrom these claims and talks about the Type 1 and Type 2 curves as the limits of thedistribution.
The take-home message appears to be that in principle symbol systemscould vary as widely as being completely rigid or completely random and equiprobable.It is therefore surprising, the story goes, that the Indus symbols seem to fall right inthat narrow band that includes unequivocal writing systems.
The problem with thisargument is that it is highly unlikely that there were ever any functional symbol sys-tems that had either of these properties, and one can argue this point on basic infor-mation theoretic grounds.
A symbol system that was completely rigid?had an entropyof 0?would convey no information whatsoever.
If whenever symbol x occurred, sym-2 Rao et al (2009a) mis-cite Winn to claim that the Vinc?a sequences were random.3 We also summarized our criticisms of the paper in a letter to the editor of Science.
This was rejected forpublication with the note ?we receive many more letters than we can accommodate.?
This seemed anodd excuse given that the letter would presumably be published online rather than in print?so spacewould not be an issue, and the letter pertained directly to flows in a paper published in the magazine,which one would think would be of importance.4 Rao et al (2009b) has one advantage over Rao et al (2009a) in that they actually do show something: Theyuse Markov models to show that there is structure, which they term ?rich syntactic structure,?
in theIndus texts.
That there is structure?the system is not random?has of course been known for decades;see Farmer, Sproat, and Witzel (2004) for discussion of this point.
And given the average length of theIndus texts of around 4.5 glyphs, one wonders just how ?rich?
the syntax could have been.588Sproat Ancient Symbols and Computational Linguisticsbol y always followed, there would be little point in having more than just symbol x,except perhaps for decorative purposes.
Even in language one finds pockets of suchpredictability: The word sequence Monty Python?s Flying will hardly ever be followedby anything other than Circus.
For a whole system to be so rigid would be unexpected.The other extreme?random and equiprobable?seems equally unlikely in general, ifonly because symbols represent things, and the things they represent typically do notoccur with equal probability.
So although Rao is technically correct that his Types 1 and 2do represent the logical extremes of the distribution, it is not likely that any meaningfulsymbol systems were ever created that had either of these properties.In particular it is important to remember that random is not the same thing as randomand equiprobable: at least some of the discussion of Rao et al?s (2009a) paper (and the Lee,Jonathan, and Ziman [2010] paper we examine subsequently) seems to depend uponthe confusion of these two quite distinct notions.
If one allows that symbols have aquasi-Zipfian distribution?something that is surely true of linguistic symbol systems,but of many other things too?then one finds curves that look very similar to whatRao et al find for their ?linguistic?
systems in their Science paper.
Thus, as I arguedin a contribution to Liberman (2009), one can ?get a very good fit to [Rao et al?s]results for the Indus corpus with a model that has 400 elements with a perfect Zipfdistribution, with ?
= 1.5, and conditional independence for the bigrams.?
Similarly inmy invited talk at EMNLP?09 (Sproat 2009), I showed that one could replicate theirresults with an artificially generated corpus that only matched the unigram frequenciesfrom the Mahadevan corpus and again had conditional independence for the bigrams.It is not hard to understand why the plot for a randomly generated corpus with aroughly Zipfian distribution should ?look like?
language using Rao et al?s methods.There are no constraints on what symbols can follow others, so for the n most frequentsymbols there is a large amount of uncertainty.
But as one?s sample grows to the 2n mostfrequent, the 3n most frequent, and so forth, the gain in uncertainty decreases simplybecause the next n symbols have a smaller overall probability and thus their incrementalcontribution to the uncertainty is smaller.
Furthermore at no point will the entropy bemaximal: because the distribution of symbols is not equiprobable.In subsequent discussions Rao?for example, Rao (2010)?has defended his posi-tion by arguing that conditional entropy and other such measures are not intended to bedefinitive, but merely suggestive and, when combined with other evidence that pointsin the same direction, supportive of the conclusion that the Indus system is writing:Simply put, it is an issue of weight of evidence.
The problem is that for that argument towork there must at least be some weight: If conditional entropy measures of a particularform correlate more with language than they do with non-linguistic systems, if evenweakly, then that might count as evidence for the conclusion.
In other words, onewants a measure that can tell one, with better than chance accuracy, that the systemin question is (or is not) linguistic.
But this has not been demonstrated: Nobody hasdone the legwork of putting together the needed corpora of ancient linguistic and non-linguistic symbol systems, and demonstrated that one can in fact use such measures todo a better than chance job of classifying systems.
The simple experiments involvingrandomly generated texts discussed earlier do not leave one with much optimism thatthis will be the case.
But one has to admit that it is an open question.
But it is the questionthat has to be asked, and the fact that none of the reviewers of the Science article thoughtto ask it speaks to the reviewing practices of that journal, at least as it relates to our field.We turn now to Pictish symbols.
The Picts were an Iron Age people (or possiblyseveral peoples) of Scotland who, among other things, left a few hundred standingstones inscribed with symbols, with ?texts?
ranging from one to a few symbols in589Computational Linguistics Volume 36, Number 3length.
Lee, Jonathan, and Ziman?s (2010) paper attempts to use measures derivedfrom entropy to ascertain whether these symbols are part of a linguistic writing system.Similarly to Rao et al?s (2009a) work, they compare the symbols to a variety of knownwriting systems, as well as symbol systems like Morse code, and European heraldry, andrandomly generated texts?by which, again, is meant random and equiprobable.
As theirtitle ?Pictish symbols revealed as a written language through application of Shannonentropy?
suggests, they are much bolder than Rao et al (2009a) in what they think theyhave demonstrated.As with Rao et al?s (2009a) paper, there are a number of things in Lee, Jonathan, andZiman (2010) that should bother people other than computational linguists: They char-acterize Egyptian hieroglyphs as a ?syllabic?
writing system (it was a consonantal andthus essentially a segmental writing system); they linearize their corpus of Europeanheraldry by reading bottom to top, which follows no conventions that I am aware of;and they refer credulously to the supposed ?script?
examples from Chinese Neolithicpottery, which few Sinologists take seriously.
But again, we focus here on the issues thatrelate to computational linguistics.Lee, Jonathan, and Ziman?s (2010) techniques are substantially more complicatedthan Rao et al?s (2009a), and we do not have space to describe them fully here.
Onereason for the complication is that they recognize the problem imposed by the verysmall sample sizes of the corpora (a few hundred symbols in the case of Pictish), andseek a method that is robust to such small sizes.
They develop two measures, Ur andand Cr, defined as follows.
First, Ur is defined asUr =F2log2(Nd/Nu)(2)where F2 is the bigram entropy, Nd is the number of bigram types, and Nu is the numberof unigram types.5 Cr is defined asCr =NdNu+ aSdTd(3)where Nd and Nu are as before, a is a constant (for which, in their experiments, theyderive a value of 7, using cross-validation), Sd is the number of bigrams that occur once,and Td is the total number of bigram tokens; this latter measure will be familiar asn1N ,the Good-Turing estimate of the probability mass for unseen events.
To illustrate thecomponents of Cr, Lee, Jonathan, and Ziman show a plot (their Figure 5.5), reproducedhere as Figure 2.
According to their description this shows[a p]lot of Sd/Td (degree of di-gram repetition) versus Nd/Nu (degree of di-gram lexiconcompleteness).
.
.
.
Dashes, sematograms?heraldry; filled diamonds, letters?prose,poetry and inscriptions; grey filled triangles, syllables?prose, poetry, inscriptions;open squares, words?genealogical lists; crosses, code characters; open diamonds,letters?genealogical lists; filled squares, words?prose, poetry and inscriptions.
(Lee,Jonathan, and Ziman 2010, page 8)Note that the non-linguistic system of heraldry (given their assumptions of how to?read?
heraldic ?texts?)
seems to have a much lower number of singleton bigrams thanwould be expected given the corpus size, clearly separating it from linguistic systems.5 Unfortunately, a complication in Lee, Jonathan, and Ziman?s (2010) paper is that their formulation ofbigram entropy in their Equation (2.2) is apparently wrong.590Sproat Ancient Symbols and Computational LinguisticsFigure 2Reproduction of Figure 5.5, page 8, from Lee, Rob, Philip Jonathan, and Pauline Ziman.
?Pictishsymbols revealed as a written language through application of Shannon entropy.?
Proceedings ofthe Royal Society A: Mathematical, Physical & Engineering Sciences, pages 1?16, 31 March 2010.
Usedwith permission of the Royal Society.
See text for explanation.Lee, Jonathan, and Ziman (2010) use Cr and Ur to train a decision tree to classifysymbol systems.
If Cr ?
4.89, the system is linguistic.
Subsequent refinements use val-ues of Ur to classify the system as segmental (Ur < 1.09), syllabic (Ur < 1.37), or elselogographic.All very impressive looking, but does it really work?
In order to put the Lee,Jonathan, and Ziman (2010) theory to a serious test, I looked to another symbol system,namely, Mesopotamian deity symbols from kudurrus (boundary stones) catalogued inSeidl (1989).
A small corpus was developed from the stones for which the depictionsin Seidl?s book were clear enough to read.
The corpus contains only 545 tokens, with59 types (the full set of types described by Seidl comprises 66).
The Mesopotamian deitysymbols are pictographic, a property shared with many scripts, including Egyptianand Luwian hieroglyphs and Mayan glyphs; and there are other script-like properties,including the fact that the symbols are often arranged linearly (Figure 3), and somesymbols are ?ligatured?
together.
Yet we know that these symbols were not part of awriting system.Unfortunately the corpus is far too small for a meaningful comparison with theresults of Rao et al (2009a), though one point is clear from even a cursory examinationFigure 3The linearly arranged symbols of the major deities of As?s?urnas.irpal II.
From http://upload.wikimedia.org/wikipedia/commons/8/87/Ashurnasirpal II stela british museam.jpg,released under the GNU Free Documentation License, Version 1.2.591Computational Linguistics Volume 36, Number 3of the texts: Rao et al?s claim that kudurru texts are rigidly ordered is clearly false(which we also showed in Farmer, Sproat, and Witzel [2004]); if nothing else, somesymbols repeat within the same text, with different symbols following each repetition.Turning now to Lee, Jonathan, and Ziman?s (2010) method, I computed Cr and Ur forthe kudurrus, yielding values of Cr = 8.0 and Ur = 1.55.
For the Pictish symbols, Lee,Jonathan, and Ziman computed values for Cr and Ur under various assumptions ofwhat the symbol type set was, with the largest values being Cr = 6.16 and Ur = 1.45.The values for the kudurru texts are different than what they calculate for the Pictishstones, but crucially they are different in the direction that, given their decision tree,suggests that kudurrus are writing.
In particular, Cr ?
4.89 and Ur ?
1.37, yieldingclassification of the system as a logographic writing system.
It is worth noting also thatthe values for Nd/Nu and Sd/Td are 5.58 and 0.35, respectively, which puts them firmlyin the ?linguistic?
range, as shown by the superimposed point in Figure 2.More embarrassingly, a set of 75 ?texts?
consisting of ?symbols?
derived by succes-sive tosses of seven six-sided dice, as suggested by Liberman (2010), with individualtext lengths ranging between 3 and 14, with a total of 638 ?symbols,?
is revealed bythe application of Shannon entropy to be a syllabic writing system.
For this systemCr = 12.64 and Ur = 1.18.Lee, Jonathan, and Ziman?s method thus fails a crucial test: It misclassifies aswriting systems whose true classification?as a non-linguistic system, as a randomlygenerated and meaningless sequence?is known.
Again, the reasons for this failureseem clear enough.
First, the tiny sample sizes of many of the texts they use make itunlikely that one can derive reliable statistics in the first place.
And second, even if weallow that Lee, Jonathan, and Ziman?s measures reveal something about the structuresof the systems they are examining, the source of the structure could in principle bemany things.
Perhaps it would have been too much to expect that a reviewer wouldhave known about the Mesopotamian deity symbols and suggested that Lee, Jonathan,and Ziman should check those with their methods.
But it would have been reasonableto expect that someone should have asked them whether they can detect a truly randombut non-equiprobable system.In summary, what neither the Rao et al work on the Indus symbols, nor the Lee,Jonathan, and Ziman work on Pictish symbols have shown is that one can distinguishstructure that derives from linguistic constraints from structure that derives from someother kind of constraints.
Furthermore, they fail for rather trivial reasons?reasons thatshould have been caught if competent reviewers had been assigned to these papers.I must stress that I do not wish to argue that it is impossible that one could come upwith a sound statistical argument to show that a particular symbol system is not linguis-tic.
If one took a large sample of known linguistic and non-linguistic symbol systems,and showed that a particular set of measures could reliably distinguish between themwith very high accuracy, then such measures could presumably be applied in the case ofunknown systems such as the Indus or Pictish systems.
Then, and only then would onehave a clear and unequivocal demonstration of anything.
But it is patently clear that thepapers we have critiqued here do not even come close to this.3.
What Can We Do about This?The situation described in this article surely presents a problem for the field of computa-tional linguistics.
Although entropy and related concepts clearly predate computationallinguistics, they are central to statistical language processing and are used widely inthe field.
Such measures certainly can tell us some things about a corpus of symbols,592Sproat Ancient Symbols and Computational Linguisticsbut there is no evidence that they can tell us what Rao et al (2009a) or Lee, Jonathan,and Ziman (2010) think they can tell us.
Yet, with the publication of these papers, andtheir promotion by the all-too-eager popular science press, non-specialists might easilybelieve that ?artificial intelligence?
methods can provide crucial evidence for a symbolsystem?s status as writing.
One can only expect that more such papers will appear.Such work represents a misuse of the methods of the field of computational lin-guistics, so in principle it should be of interest to practitioners in that field to try todo something about this.
At the very least, it would be useful if one could convincegeneral ?peer?
reviewed publications such as Science or the Proceedings of the RoyalSociety to include qualified computational linguists among the peer reviewers of anysuch publications in the future.
This was essentially Pereira?s plea (Pereira 2009).
Sucha situation would hardly be tolerated in other fields, yet in publications like Science itseems to be common when it comes to issues having to do with language.Part of the problem may be that computational linguistics has relatively low visi-bility.
It is not clear that the editors of publications like Science even know that there arepeople who spend their lives doing statistical and computational analyses of text; or, ifthey do, that computational linguists have knowledge that is relevant to judging paperslike the ones under discussion here.
The time is ripe for changing that.
As the resultsof computational linguistic research, in the form of things like machine translation orautomatic speech recognition systems, become more widely known and used, compu-tational linguists have an opportunity to educate the wider community?and we shouldtake every opportunity to do so.
For example the fact that n-gram language models areused with a high degree of success in speech recognition systems depends upon the factthat such language models are typically built from data consisting of millions or evenbillions of tokens.
Such points need to be stressed more fully in dealings with the pressor the science magazines, so that people do not get the impression that one can derivereliable results by such techniques from corpora consisting of only a few hundred or fewthousand symbols.
Despite a famous XKCD cartoon6 that characterizes computationallinguistics as a field that is ?so ill-defined?
that people can ?subscribe to any of dozensof contradictory models and still be taken seriously,?
there are core methods that arebacked up by solid empirical data.
Yet, as with any science, there are good ways andbad ways to apply such methods.Ultimately we may be fighting a losing battle.
It is more exciting to learn thata statistical method can tell you that such-and-such an ancient symbol system waswriting, than to learn that in fact the proposed methods do not work.
But at least onehas a duty to try to set the record straight.AcknowledgmentsI thank Steve Farmer, Brian Roark, RobertDale, and a reviewer for ComputationalLinguistics for useful comments on earlierversions of this article.ReferencesFarmer, Steve, Richard Sproat, and MichaelWitzel.
2004.
The collapse of theIndus-script thesis: The myth of a literateHarappan civilization.
Electronic Journal ofVedic Studies, 11(2):19?57.Farmer, Steve, Richard Sproat, and MichaelWitzel.
2009.
A refutation of the claimedrefutation of the nonlinguistic natureof Indus symbols: Invented data setsin the statistical paper of Rao et al(Science, 2009).
www.safarmer.com/Refutation3.pdf.Gimbutas, M. 1989.
The Language of theGoddess: Unearthing the Hidden Symbols of6 http://xkcd.com/114/.593Computational Linguistics Volume 36, Number 3Western Civilization.
Thames and Hudson,London.Haarmann, Harald.
1996.
Early Civilizationand Literacy in Europe: An Inquiry intoCultural Continuity in the Ancient World.Mouton de Gruyter, Berlin.Keim, Brandon.
2009.
Artificial intelligencecracks 4,000-year-old mystery.
Wired,23 April.
www.wired.com/wiredscience/2009/04/indusscript/Lee, Rob, Philip Jonathan, and PaulineZiman.
2010.
Pictish symbols revealed as awritten language through application ofShannon entropy.
Proceedings of the RoyalSociety A: Mathematical, Physical &Engineering Sciences, pages 1?16,31 March 2010.Liberman, Mark.
2009.
Conditional entropyand the Indus script.
Language Log,26 April.
http://languagelog.ldc.upenn.edu/nll/?p=1374.Liberman, Mark.
2010.
Pictish writing?Language Log, 2 April.
http://languagelog.ldc.upenn.edu/nll/?p=2227.Mahadevan, Iravatham.
1977.
The IndusScript: Texts, Concordance and Tables.Archaeological Survey of India, Calcuttaand Delhi.Parpola, Asko.
1994.
Deciphering the IndusScript.
Cambridge University Press,New York.Pereira, Fernando.
2009.
Falling for themagic formula, April 26. http://earningmyturns.blogspot.com/2009/04/falling-for-magic-formula.html.Rao, Rajesh.
2010.
Probabilistic analysis of anancient undeciphered script.
Computer,April:76?80.Rao, Rajesh, Nisha Yadav, Mayank Vahia,Hrishikesh Joglekar, R. Adhikari, andIravatham Mahadevan.
2009a.
EntropicEvidence for Linguistic Structure in theIndus Script.
Science, 324(5931):1165.Rao, Rajesh, Nisha Yadav, Mayank Vahia,Hrishikesh Joglekar, R. Adhikari, andIravatham Mahadevan.
2009b.
A Markovmodel of the Indus script.
Proceedingsof the National Academy of Sciences,106(33):13685?13690.Seidl, Ursula.
1989.
Die babylonischenKudurru-Reliefs.
Symbole mesopotamischerGottheiten.
Universita?tsverlag Freiburg,Freiburg.Sproat, Richard.
2009.
Symbols, meaningand statistics.
Invited talk at EMNLP,Singapore.
http://www.fask.uni-mainz.de/lk/videoarchive/videos/2009-08-06-emnlp-2009-richard-sproat.html.Winn, Shan M. M. 1981.
Pre-writing inSoutheastern Europe: The Sign System of theVinc?a Culture, ca.
4000 B.C.
WesternPublishers, Calgary.594
