Proceedings of the 2nd Workshop on EVENTS: Definition, Detection, Coreference, and Representation, pages 12?20,Baltimore, Maryland, USA, June 22-27, 2014.c?2014 Association for Computational LinguisticsChallenges of Adding Causation to Richer Event DescriptionsRei Ikuta*, William F. Styler IV+, Mariah Hamang*, Tim O?Gorman*, and Martha Palmer*Department of Linguistics, University of Colorado at Boulder*{rei.ikuta, mariah.hamang, ogormant, martha.palmer}@colorado.edu,+will@savethevowels.orgAbstractThe goal of this study is to create guide-lines for annotating cause-effect relationsas part of the Richer Event Descriptionschema.
We present the challenges facedusing the definition of causation in termsof counterfactual dependence and proposenew guidelines for cause-effect annotationusing an alternative definition which treatscausation as an intrinsic relation betweenevents.
To support the use of such an in-trinsic definition, we examine the theoret-ical problems that the counterfactual def-inition faces, show how the intrinsic defi-nition solves those problems, and explainhow the intrinsic definition adheres to psy-chological reality, at least for our annota-tion purposes, better than the counterfac-tual definition.
We then evaluate the newguidelines by presenting results obtainedfrom pilot annotations of ten documents,showing that an inter-annotator agreement(F1-score) of 0.5753 was achieved.
Theresults provide a benchmark for futurestudies concerning cause-effect annotationin the RED schema.1 Introduction: The RED schema andcause-effect relationRicher Event Description (Styler et al., 2014a)is an annotation schema which is developed ?asa synthesis of the THYME-TimeML guidelines1,the Stanford Event coreference guidelines andthe Carnegie Mellon University Event coreferenceguidelines.?
In other words, it combines Corefer-ence (Pradhan et al., 2007; Lee et al.
, 2012) andTHYME Temporal Relations annotation (Styler1The THYME annotation schema also includes corefer-ence annotation.et al.
(2014b)) to provide a thorough representa-tion of entities (including events) and their rela-tions, including temporal relations.
An overviewof the annotation process, which shows how coref-erence and temporal annotations are combined, isdescribed in the following section.The RED schema therefore attempts to anno-tate cause-effect relations, which are annotated inneither Coreference nor THYME (Styler et al.,2014b).
There is a synergy between annotatingboth causal and temporal relations, since causesnecessarily precede their effects.Other characteristics of the cause-effect annota-tion in RED are that it allows annotators to makeinferences without relying on explicit connectivesor verbs of causation, that it is not domain specific,and that it allows the relation to cross one (but notmore than one) sentence boundary.1.1 The annotation processThe process of RED annotation is divided intotwo passes: the first in which entities (includingevents) are annotated, and the second in which re-lations between those entities are annotated.In the first pass, annotators identify three typesof entities: events (an occurence with a definitivetemporal duration), temporal expressions such asAugust 2013, and other entities that have an ex-istence as opposed to an occurrence (e.g., propernouns, objects, and pronouns).
Specific propertiesof each event are also annotated in this pass (e.g.,its relation to the document creation time, whetherit is an actual event or a hypothetical event, etc.
).After the annotations in the first pass have beenadjudicated, annotators mark temporal, cause-effect, and coreference relations between the en-tities identified in the first pass.
Temporal rela-tions (e.g., before, overlaps, contains) are anno-tated between two events or between an event anda TIMEX3, cause-effect relations are annotatedbetween two events, and coreference relations are12annotated between two entities (e.g., PresidentJohn F. Kennedy ... he) or two events (an earth-quake ... the quake).
Coreference relations includepart-whole and set-member relations, as well asidentical relations in which two entities share a ref-erent.As a result of combining Coreference andTHYME, different coreference and temporal rela-tions between an event pair can be covered by asingle relation in RED.
For example, a part-wholerelation between events annotated in Coreference(e.g., an incision and a surgury) is a subset of tem-poral ?contains?
relation in RED.Therefore, the goal of RED is to combine Coref-erence and THYME annotation, while findingoverlaps between the two and also introducingcause-effect annotation to achieve a richer repre-sentation of entities, events, and their relations.1.2 Overview of the following sectionsIn the following sections, we present the chal-lenges faced during our first pilot annotation andwhy we decided to change the definition of causa-tion, from a counterfactual one to an intrinsic one.To support the use of the intrinsic definition, weexamine the theoretical problems that the coun-terfactual definition faces, show how the intrinsicdefinition solves those problems, and explain howthe intrinsic definition adheres to psychological re-ality, at least for our annotation purposes, betterthan the counterfactual definition.
We then pro-pose new guidelines based on the intrinsic defini-tion and evaluate them by presenting results ob-tained from our second pilot annotations of tendocuments, showing that an inter-annotator agree-ment (F1-score) of 0.5753 was achieved.2 Challenges of cause-effect annotationusing the counterfactual definitionThe pilot annotations were done by three annota-tors who are native speakers of English and areexperienced in linguistic annotation, on Englishproxy reports (i.e., approximations of intelligenceagency reports) written by Garland, et al.
(2013).Our original guidelines were based on the coun-terfactual definition of causation, as defined be-low.
Early on in the annotation process, the cause-effect annotation was halted and removed fromthe RED schema because there were a number ofcases in which events matched our guidelines forthe cause-effect relation but did not match our in-tuitions about the relation.2.1 Counterfactual definition of causationIn the original guidelines for cause-effect rela-tions, we defined causation as follows:?
?X caused Y?
means if X had not occurred,Y would not have occurred.This definition of causation in terms of counterfac-tual dependence (as philosophers call it) has beenthe most popular definition of causation in the fieldof philosophy for the past forty years since DavidLewis?s possible world model (Lewis, 1973) andremain influential in contemporary studies suchas the structural model (Pearl, 2000; Halpern andPearl, 2005).Using this definition, one annotator marked twocausal relations between the two event pairs in thefollowing sentence2:(1) PYONGYANG INSISTS IT WILLALLOW FULL IAEA INSPEC-TIONS ONLY WHEN A SIGNIFI-CANT PORTION OF THE PROJECTAS DEFINED IN THE 1994 ACCORDIS COMPLETED.Annotations:ALLOW causes INSPECTIONSDEFINED causes PROJECTThese annotations are done perfectly in line withthe guidelines3, since there would be no inspec-tions if there were no allowing, and there wouldbe no projects if there were no defining (of theproject).
Furthermore, one could argue that the1994 accord causes Pyongyang to insist, since ifthere had been no such accord, Pyongyang wouldnot have been able to insist anything pertaining toit, although the annotators did refrain from creat-ing such a causal annotation.However, the relation between these event pairsdoes not match our intuition about what causationis.
For example, the allowing should be consid-ered as a precondition for the inspections, and not2Another annotator who annotated the same text did notmark any causal relations in this sentence.3The annotation guidelines allow future events to be incausal relations, although the counterfactual definition onlydeals with past events, and for quoted speech, narrators areassumed to be reliable.
Thus, future events can participate ina causal relation if the narrator is certain about the relation.If the relation is presented to be likely or hypothetical insteadof being actual, annotators can mark such modalities also.13the cause.
Furthermore, the guideline creates toomany event pairs that are potentially in a cause-effect relation (such as the accord and the insist-ing), contributing to confusion among annotators.A similar issue can be seen in the following sen-tence, in which the internet should be consideredas a possible precondition of funding, and not thecause:(2) THE WORKSHOP WILL STUDYTHE USE OF THE INTERNET TOPROMOTE TERRORISM AND THEINTERNET?S ROLE IN FACILITAT-ING MONEY TRANSACTIONS ANDFUNDING TERRORIST GROUPS.Annotation:INTERNET?S causes FUNDINGTherefore, we concluded that the counterfactualdefinition of causation is not optimal for our anno-tation guidelines, and that we need an alternativedefinition of causation which does not rely on an-notators to consider a possible world in which thecause does not occur.Such an alternative definition, which we call theintrinsic definition, has been argued for by Men-zies (1996; 1999; 2014).
Such a definition treatscausation as an intrinsic relation between events,meaning that it is ?a local relation depending onthe intrinsic properties of the events and what goeson between them, and nothing else?
(Menzies,2014).Drawing on Menzies idea, we propose the fol-lowing definition of causation which is being usedin our new guidelines for cause-effect annotation:?
?X caused Y?
means Y was inevitable givenX.With this definition, annotators would not have toconsider any possible worlds in which an event didnot occur in order to annotate cause-effect rela-tions, and only have to focus on whether Y nec-essarily follows X, according to the context andtheir encyclopedic knowledge of the world.In order to support our use of such a definition,we also present the challenges that the counterfac-tual definition faces in terms of theory and psycho-logical reality in the following sections, and showhow the intrinsic definition solves those problems.3 Theoretical challenge of thecounterfactual definitionThe two situations below illustrate theoreticalchallenges which are faced by the counterfactualdefinition but not by the intrinsic definition.3.1 Multiple causes?
There are three events (1, 2 and 3), and threeindividuals (A, B, and C).
Events 1 and 2occur at the same time, and event 3 followsevents 1 and 2.?
In event 1, A shoots C in the head.?
In event 2, B shoots C in the heart.?
In event 3, C dies.?
Then, an autopsy reveals that each of theshots C received (one in the head, shot by A,and the other in the heart, shot by B) was suf-ficient by itself to kill C.In the above situation (a modified version of theexample in Lagnado et al.
(2013)), the counter-factual definition would falsely predict that bothevents 1 and 2 are not the causes of event 3, sinceeven if event 1 did not occur, event 3 would haveoccurred because of event 2, and if event 2 didnot occur, event 3 would have occurred becauseof event 1.Acknowledging this problem, Halpern andPearl (2005) retain the counterfactual notion andextend their causal model by stating that counter-factual dependence should be evaluated relative tocertain contingencies.
According to this defini-tion, the counterfactual dependence of event 1 toevent 3 should be evaluated relative to a contin-gency in which event 2 does not occur.
The ob-vious problem that this extended model faces isthe difficulty of finding a principled way to de-cide which contingencies are allowed.
AlthoughHalpern and Pearl (2005) do offer a complex setof conditions that are aimed at capturing the in-tuition that one should only invoke contingen-cies ?that do not interfere with active causal pro-cesses,?
the question of which contingencies areallowed is non-trivial and is the subject of ongo-ing debate (Halpern and Hitchcock, 2010; Hiddle-ston, 2005; Hopkins and Pearl, 2003; Lagnado etal., 2013).This situation, however, is easily handled by theintrinsic definition, since event 3 (the death of C) is14inevitable given event 1 (A shooting C in the head)regardless of other events, and event 3 is inevitablegiven event 2 (B shooting C in the heart) regard-less of other events, according to what we knowabout the results of the autopsy.
Thus the intrinsicdefinition correctly predicts that both events 1 and2 are equally the causes of event 3.3.2 Oxygen, lightning, and wildfire?
There are three events (1, 2 and 3).
Event 1is a state encompassing events 2 and 3, andevent 3 follows event 2.?
In event 1, oxygen exists.?
In event 2, a lightning strikes a tree in a forest.?
In event 3, a wildfire starts in the forest.In this situation described by Halpern and Hitch-cock (2013), event 1 (the existence of oxygen)would be predicted as being one of the causes ofevent 3 (wildfire), since if oxygen did not exist, awildfire would not start.
However, they argue thathuman intuition would treat only event 2, and notevent 1, as a cause of event 3.To counter this problem, Halpern and Hitchcock(2013) again extend the counterfactual model,stating that potential causes are graded accordingto the normality of their witnesses (a witness isa world in which a potential cause is the actualcause of an outcome).
In this extended model, theworld in which oxygen exists is more normal thanthe world in which lightning strikes a particulartree.
Therefore, the lightning, being less normal,?receives a higher causal grading.?
In their causalmodel, a static ranking of the witnesses are givenbefore the processing (i.e., causal inference) starts,and thus it is possible to compute which witnessreceives a higher causal grading.Unlike the extended counterfactual definition,the intrinsic definition does not assume a givenranking of the world, and thus it is especially use-ful when applied to annotation tasks.
For exam-ple, annotators would identify a causal relation be-tween the oxygenation and the wildfire in the fol-lowing sentence:(3) The oxygenation of the atmosphereaccompanied by a lightning strike trig-gered the first wildfire in Earth?s history.But not in the following:(4) The first wildfire in Earth?s historywas caused by a lightning strike in theProterozoic, an era noted for the evolu-tion of multicellular organisms, glacia-tions, and the oxygenation of the atmo-sphere.Even though the two events (oxygenation andwildfire) described in the above sentences refer tothe same events in the world, the annotators canchoose whether to note a causal link between themdepending on the inevitability implied by the text.In sentence (2), it is suggested that the wildfire wasinevitable given the oxygenation and the strike,thus both of the events would be annotated as thecause, while sentence (3) does not imply such acausal relation.
This would effectively let the an-notators avoid marking cause-effect relations be-tween births and deaths in texts such as obituariesand medical reports.
Such varying interpretationsof texts are not possible with the original counter-factual definition, or with Halpern and Hitchcocksextended counterfactual model (2013) which as-sumes a given ranking of witnesses which is avail-able to the writer but not to the annotator.4 Challenge of the counterfactualdefinition in terms of psychologicalrealityIn addition to the theoretical problem that thecounterfactual definition faces, experiments doneby White (2006) have shown that counterfactualdependence is not used as preferred evidence formaking causal inference when subjects are pas-sively (i.e., without the ability to intervene) ex-posed to a scenario in which there are a numberof events affecting one another.In one of the experiments, subjects are pre-sented with scenarios concerning two game re-serves, in each of which live five species, who mayor may not prey on each other.
For each reserve,there are five statements corresponding to five con-secutive seasons, and each statement describeswhether the population of each of the species haschanged in that season.
Based on the statements,the subjects must decide whether a change in thepopulation of one species causes changes in thatof the others.
The subjects are instructed that ifthe population of X changed and that of Y did notin a given season, they are supposed to concludethat X does not prey on Y, because if it did, thepopulations of both X and Y would have changed.15In other words, the subjects are explicitly told torely on counterfactual dependence as evidence formaking causal inference.
The five statements pro-vided enough counterfactually dependent relationsfor the subjects to reach one correct answer.However, the results of the experiment showthat only 5 out of 36 subjects made correct judg-ments on the predator-prey (cause-effect) relationsin both reserves, and the success rates were be-low optimum and not far above chance.
Instead,the answers by the subjects showed that they weremore likely to rely on the temporal order of eventsas the evidence for the causal relations (i.e., ?thepopulation of X changed in season 1 and that ofY changed in season 2, thus X must be the preda-tor of Y?
), although they were instructed to rely oncounterfactual dependence within the same seasoninstead.White (2006) carried out three additional ex-periments, one in which he changed the order ofthe seasons, another in which subjects were toldthat the seasons were in random order and that thetemporal order is irrelevant to the answer, and thelast in which the scenario was changed to a situa-tion where the levels of five chemicals in a bloodstream affect each other.
The subjects?
answersexhibited more reliance on counterfactual depen-dence in the experiment where they were told thattemporal order is irrelevant, but the other experi-ments showed similar results with the first experi-ment.Thus, White (2006) concludes that there is apreference for basing causal inference on domain-specific causal knowledge (i.e., ?the populationchange in season 1 must be causally related tothe change in season 2, according to what weknow about ecosystems?)
over counterfactual de-pendence, when such knowledge is available foruse and when subjects are passively exposed4to acomplex scenario in which there are a number ofevents affecting one another.These results support our motivation to avoidusing the counterfactual definition, since annota-tors are passively exposed to text without the abil-ity to intervene, texts to be annotated are complexsystems in which a number of events may or maynot affect each other, and it is usually the case4It has been claimed that subjects perform better in mak-ing causal inferences on complex structures when they areactively exposed to (i.e., have the ability to intervene with)the structures (Lagnado and Sloman, 2004; Sloman andLagnado, 2005; Steyvers et al., 2003).that domain-specific causal knowledge is avail-able.
The use of an intrinsic definition for cause-effect annotation, on the other hand, is in line withthe results of these experiments, since annotatorswould not have to consider any possible worldswhere some event does not occur, and only have tofocus on whether Y necessarily follows X, accord-ing to the context and their encyclopedic knowl-edge of the world.5 The new guidelinesGiven the challenges faced by the counterfactualdefinition and the advantages of the intrinsic defi-nition presented above, we developed new guide-lines for cause-effect annotation which instruct an-notators as follows:?
In our schema, we annotate ?X CAUSESY?
if, according to the writer, the particularEVENT Y was inevitable given the particu-lar EVENT X.We then utilized the counterfactual definition asthe definition of precondition relations as follows:?
We annotate ?X PRECONDITIONS Y?
if,according to the writer, had the particu-lar EVENT X not happened, the particularEVENT Y would not have happened.The reason we kept the counterfactual definitionin our guidelines as a definition of a preconditionrelation is that the relation defined by counterfac-tual dependence still gives us information aboutthe temporal relation between events; if we knowthat Y would not have happened if X had not hap-pened, we also know that X started before Y.6 The second pilot annotationUsing the new guidelines, ten proxy reports wereeach annotated by two annotators.
One of themwas among the two annotators who participated inour first pilot annotation, and the other, who is alsoa native speaker of English experienced in linguis-tic annotation, was trained using the old guidelinesbut only started annotating in the RED schemaafter the cause-effect annotation was halted, andthus had not actually annotated cause-effect rela-tions until the second pilot.
The following sectionspresent the inter-annotator agreement of cause andprecondition annotations done in the ten reportsand the analysis of specific examples where theannotators disagreed.166.1 Inter-annotator agreementThis section presents the inter-annotator agree-ment (IAA) obtained from the second pilot annota-tion, and analyzes the annotations to examine thesources of disagreement between the annotators.Perhaps the most important thing to note beforediscussing the specific numbers and examples isthat this pilot annotation did not include the ad-judication stage between the first pass where en-tities including events and temporal expressionsare identified, and the second pass where the rela-tions between those entities are marked (see Sec-tion 1.1 for the specifics of the annotation pro-cess).
Therefore, many of the disagreements inthe causation and precondition annotations involvedisagreements in the first pass.A total of 114 relations (50 causation and 64precondition relations) were created by the two an-notators.
Among them, 24 exhibited perfect matchbetween the annotators, while 18 exhibited par-tial match (meaning that they agreed on whetherthe relation was causation/precondition, but dis-agreed on other aspects of the relation, such asthe modality and temporal relation5) .
Among the114 relations, 72 relations showed disagreements,but 69 of them involved disagreements in the firstpass.
Upon analysis, we judged 41 of those 69disagreements as being avoidable by introducingthe adjudication stage between the two passes, and28 as having the potential of surviving adjudica-tion, meaning that even if the adjudication wereproperly done, the same parts of the text may stillcause similar disagreements.
Only 3 among the 72disagreements occurred purely in the second pass,meaning that the annotators completely agreed onwhat the entities involved in the 3 relations shouldbe, but disagreed on the relation.Thus, the results give us four types of IAA(best-case, realistic, worst-case, and extra-strict),shown in Table 1 as F1-scores.The best-case IAA assumes that all disagree-ments involving disagreements in the first pass5As well as marking the modality (whether the relation isstated as being actual, likely or hypothetical) and the temporalrelation (whether the cause ends before the effect starts orcause overlaps with the effect), annotators have a choice ofmarking a relation as ?difficult?
when they are not sure oftheir annotation.
This difficulty marking was not consideredwhen judging whether the two annotators agreed completelyor not.
In other words, even if one annotator marked a relationas difficult and the other did not, the annotation would beconsidered as showing complete agreement as long as otherproperties of the annotation matched.F1-scoreBest-case 0.9333Realistic 0.5753Worst-case 0.3684Extra-strict 0.2105Table 1: Inter-annotator agreement for the secondpilot annotationwill not show up as issues in the second pass, andonly takes into account the 3 disagreements thatoccurred purely in the second pass.The realistic IAA takes into account the 28 dis-agreements involving disagreements in the firstpass that have the potential of surviving adjudica-tion.The worst-case IAA assumes that all disagree-ments in the first pass survive adjudication.Finally, the extra-strict IAA allows relations tobe judged as agreeing only when the two anno-tations completely match, including the modalityand the temporal relations marked together withcausation/precondition.6.2 Evaluation of the inter-annotatoragreementThis section compares the IAA presented abovewith results shown in a previous study by Styleret al.
(2014b) which deals with temporal relationannotations in the clinical domain.
In their study,Styler et al (2014b) reported results from annota-tions done on a subset of the THYME colon cancercorpus, which includes clinical notes and pathol-ogy reports for 35 patients diagnosed with coloncancer for a total of 107 documents.
Two grad-uate or undergraduate students in the Departmentof Linguistics at the University of Colorado anno-tated each text.
For the annotation guidelines, theyused the THYME-TimeML guidelines which arealso used within the RED guidelines for temporalrelation annotation.
Unlike the annotations in thiscurrent study, the temporal relation annotations onthe THYME corpus were done after the identifica-tion of events and temporal expressions were ad-judicated (the THYME-TimeML schema does notidentify entities that are not events or temporal ex-pressions).
Therefore, the IAA they presented (Ta-ble 2) are not affected by the disagreements at thelevel of event identification.The figure for ?participants only?
shows theIAA concerning cases in which the annotators17F1-scoreParticipants only 0.5012Participants and relation 0.4506?Contains?
relaion 0.5630Table 2: Inter-annotator agreement presented inStyler et al.
(2014b)agreed that there is some sort of a temporal re-lation between the two participants, but did notnecessarily agree on which temporal relation (be-fore, overlap, contains, etc.)
holds between them.The figure for ?participants and relation?
showsthe agreement on both the participants and the typeof the temporal relation.
The third figure is theIAA for the temporal relation ?contains,?
whichexhibited the highest IAA among all the temporalrelations.These figures are significantly higher than theresults reported for the 2012 i2b2 challenge (Sunet al., 2013), in which the F1-score for ?partici-pants only?
IAA was 0.39.The realistic IAA of 0.5753 obtained in this cur-rent study is not far-off from the figures by Styleret al.
(2014b), which shows that causation and pre-condition annotations using the new guidelines areindeed feasible.6.3 Examples of disagreementsBelow, we present examples of different typesof disagreements observed in the annotations.The annotations are represented in the form of?EVENT relation-relation EVENT.?
The first halfof the relation indicates the temporal relation an-notated between the events, and the latter halfshows whether there was a causation or a precon-dition relation between the events.
For example,?P before-cause Q?
indicates that event P hap-pened before and caused event Q.6.3.1 Disagreement in the 1st pass: avoidableby adjudication(5) A BUDGET WAS ALLO-CATED FOR THE BARRIER TOBE EQUIPPED WITH ELECTRONICDETENTION EQUIPMENT.Annotations by annotators X and Y:X: ALLOCATED before-preconditionsEQUIPPEDY: BUDGET before-preconditionsEQUIPPEDIn (5), annotator X marked allocated as an eventwhile not marking budget as an event, and Y an-notated budget as an event and did not mark allo-cated as an event.
If the adjudication was correctlydone, only marking allocated as an event and notbudget, it is likely that Y would have annotated thesame way as X.6.3.2 Disagreement in the 1st pass: notavoidable by adjudication(6) CRITICS STATE THAT WITH AC-CESS TO PLUTONIUM AVAILABLEFROM ROGUE STATES TERROR-ISTS COULD CONSULT THE DE-TAILED DOCUMENTS AND BUILDAN ATOMIC BOMB.Y: CONSULT before-preconditionsBUILDX: No relations identifiedIn (6), the annotators did disagree on whetherthe two events consult and build happen after oroverlap with the document creation time (Doc-Time).
X annotated those two events as overlap-ping the DocTime, while Y annotated them as af-ter the DocTime.
The annotators agreed that thosetwo events were hypothetical events.
Althoughsuch a disagreement about the temporal propertyof the events may have caused the disagreementsabout whether there should be a precondition rela-tion, it is likely that X would have missed what Yhad found even if there had been adjudication.6.3.3 Disagreements in the 2nd pass(7) THE SMH AND JENNINGS WERETHEN SUED OVER 3 ARTICLESPUBLISHED IN THE LEAD-UP TOTHE 000000 OLYMPICS.X: No relations identifiedY: PUBLISHED before-preconditionsSUED(8) HEAD OF A TAJIK GOVERN-MENT AGENCY THAT FIGHTSDRUG TRAFFICKING AVAZ YUL-DACHEV STATED THAT HEROINUSERS ARE ILL AND NEEDTREATMENT.X: ILL overlap-cause NEEDY: No relations identified18(7) and (8) above show cases in which one an-notator missed the relation that the other annotatoridentified, even though both annotators completelyagreed on the property of the entities involved inthe relation.7 ConclusionIn this paper, we have presented the challengesthat the counterfactual definition of causationfaces in terms of its application to annotationguidelines, theory, and psychological reality.
Wehave shown that the intrinsic definition better suitsour purpose of annotation, and proposed newguidelines for annotating cause-effect relations us-ing such a definition.
The new guidelines wereevaluated using results obtained from a pilot an-notation of ten documents.
An inter-annotatoragreement (F1-score) of 0.5753 was obtained.
Weare currently in the process of training four addi-tional annotators with the new guidelines, and fu-ture studies concerning cause-effect annotation inthe RED schema can assess their performances byusing results presented in this paper as a bench-mark.AcknowledgmentsThe project described was supported by DARPAFA-8750-13-2-0045, subaward 560215 (via LDC)DEFT: Deep Exploration and Filtering of Text andNIH: 1 R01 LM010090-01A1, THYME (via Har-vard).
The content is solely the responsibility ofthe authors and does not necessarily represent theofficial views of DARPA or NIH.ReferencesGarland, J., Fore, D., Strassel, S., and Grimes, S.2013.
DEFT Phase 1 Narrative Text Source DataR1 LDC2013E19.
Web download file.
Philadelphia:Linguistic Data ConsortiumHalpern, J. Y., and Hitchcock, C. 2010.
Actual cau-sation and the art of modeling.
In R. Dechter, H.Geffner,and J. Y. Halpern, eds., Heuristics, proba-bility and causality: A Tribute to Judea Pearl.
(pp.383?406).
London: College Publications.Halpern, J. Y., and Hitchcock, C. 2013.
Compact Rep-resentations of Extended Causal Models.
CognitiveScience, 37:986?1010.Halpern, J. Y., and Pearl, J.
2005.
Causes and explana-tions: A structural-model approach.
Part I: Causes.The British Journal for the Philosophy of Science,56(4):843?887.Hiddleston, E. 2005.
A causal theory of counterfactu-als.
Nous, 39(4):632?657.Hopkins, M., and Pearl, J.
2003.
Clarifying the usageof structural models for commonsense causal rea-soning.
In P. Doherty, J. McCarthy, M.
Williams,eds., Proceedings of the AAAI Spring Symposium onLogical Formalization of Commonsense Rea-soning.(pp.
83?89).
Menlo Park, CA: AAAI Press.Knobe, J., and Fraser, B.
2008.
Causal judgment andmoral judgment: Two experiments.
In W. Sinnott-Armstrong, eds., Moral psychology, Volume 2: Thecognitive science of morality.
(pp.
441?447).
Cam-bridge, MA: MIT Press.Lagnado, D. A., Gerstenburg, T., and Zultan, R. 2013.Causal Responsibility and Counterfactuals.
Cogni-tive Science 37:1036?1073.Lagnado, D. A., and Sloman, S. 2004.
The advan-tage of timely intervention.
Journal of Experimen-tal Psychology: Learning, Memory and Cognition,30:856?876.Lee, H., Recasens, M., Chang, A., Surdeanu, M., andJurafsky, D. 2012.
Joint entity and event corefer-ence resolution across documents.
In Proceedingsof the Conference on Empirical Methods in Natu-ral Language Processing and Computational Natu-ral Language Learning (EMNLP-CoNLL), Jeju Is-land, 489-500.Lewis, D. 1973.
Causation.
The Journal of Philoso-phy, 70(17):556?567.Menzies, P. 1996.
Probabilistic Causation and the Pre-emption Problem.
Mind, 105:85?117.Menzies, P. 1999.
Intrinsic versus Extrinsic Concep-tions of Causation.
In H. Sankey, ed., Causation andLaws of Nature, Kluwer Academic Publishers, pp.313?29.Menzies, P. 2014.
Counterfactual Theories of Causa-tion.
In E. N. Zalta, ed., The Stanford Encyclopediaof Philosophy.
Retrieved from http://plato.stanford.edu/archives/spr2014/entries/causation-counterfactual/Pearl, J.
2000.
Causality.
Cambridge: CambridgeUniversity Press.Pradhan, S. Ramshaw, L., Weischedel, R., MacBride,J., and Micciulla, L. 2007.
UnrestrictedCoreference: Indentifying Entities and Events inOntoNotes.
In Proceedings of the IEEE Interna-tional Conference on Semantic Computing (ICSC),September 17-19.Sloman, S., and Lagnado, D. A.
2005.
Do we ?do?
?Cognitive Science, 29:5?39.Steyvers, M., Tenenbaum, J. T., Wagenmakers, E. J.,and Blum, B.
2003.
Inferring causal networks fromobservations and interventions.
em Cognitive Sci-ence, 27:453?489.19Styler, W., Crooks, K., O?Gorman, T., and Hamang,M.
2014a.
Richer Event Description (RED) Anno-tation Guidelines.
Unpublished manuscript, Univer-sity of Colorado at Boulder.Styler, W. F., Bethard, S., Finan, S., Palmer, M., Pra-dhan, S., de Groen, P. C., Erickson, B., Miller,T., Lin, C., Savova, G., and Pustejovsky., J.2014b.
Temporal Annotation in the Clinical Do-main, Transactions of the Association of Compu-tational Linguistics, 2:143?154.White, P. A.
2006.
How well is causal structure in-ferred from cooccurrence information?
EuropeanJournal of Cognitive Psychology, 18 (3):454?480.20
