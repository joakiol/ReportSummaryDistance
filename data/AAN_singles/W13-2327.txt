Proceedings of the 7th Linguistic Annotation Workshop & Interoperability with Discourse, pages 223?227,Sofia, Bulgaria, August 8-9, 2013. c?2013 Association for Computational LinguisticsEnunciative and modal variations in newswire texts in French: Fromguideline to automatic annotationMarine DamianiMoDyCo, UMR 7114, Universit?
ParisOuestmarinedamiani@gmail.comDelphine BattistelliSTIH, EA 4509, Universit?
Paris Sorbonnedelphine.battistelli@paris-sorbonne.frAbstractIn this paper we present the development of acorpus of French newswire texts annotatedwith enunciative and modal commitment in-formation.
The annotation scheme we proposeis based on the detection of predicative cues -referring to an enunciative and/or modal varia-tion - and their scope at a sentence level.
Wedescribe how we have improved our annota-tion guideline by using the evaluation (interms of precision, recall and F-Measure) of afirst round of annotation produced by two ex-pert annotators and by our automatic annota-tion system.1 IntroductionThis paper concerns the design of a referencecorpus that can be used to evaluate an automaticannotation system of enunciative and modalcommitment in newswire texts in French.
Thiscomplex linguistic phenomenon refers to the factthat a situation can be presented as certain, oronly possible/probable, by an enunciator who canbe the author of the text but who can also be an-other enunciator (explicitly named or not) fromwhom the author reports some content that he hasheard, read, imagined, etc.
Different kinds of lin-guistic cues are involved.
In addition to the needto identify and semantically classify these cues,one has to deal with the question of their scope.This question is even more complex as manycues can be present together in a sentence, thuscomplexifying the interpretation of the interac-tion of different scopes (see Example 1.).1.
M. Arabi a exprim?cue1 [le souhaitcue2 [d?aider laSyrie ?
surmonter cette phase]scope2]scope1] // [Mr.Arabi expressedcue1 [a desirecue2 [to help Syriaovercome this phase.
]scope2]scope1Another major difficulty concerns the factthat evidential and modal characteristics are verysimilar (see for example a noun like desire).
Ourwork addresses the question of annotating thesecues and their semantic scope.
Unlike most otherapproaches, we have chosen not to treat thesetwo kinds of characteristics separately, sinceboth are implicated in what is called enunciativecommitment.
We will focus here on our practicefor the development of a reference corpus.After a brief presentation of the theoreticalbackground (section 2), we describe which kindsof linguistic cues are considered and what kindof semantic scopes are then encountered (section3).
Our annotation procedure aims to delimit tex-tual segments that are semantically impacted bythe presence of enunciative and modal cues.
Inthis light, we will focus only on what we willdescribe below as predicative cues.
Then we willexplain how we have improved our annotationguideline by using the evaluation of a first roundof annotation produced for the same task by twoexpert annotators and by our automatic annota-tion system (section 4).2 The phenomenon of enunciative andmodal commitmentIn the field of linguistics, the notion of modalitycan be considered from an enunciative perspec-tive (see Bally, 1932 Benveniste, 1966; Culioli,1973).
From this perspective, which is the onewe adopt here, the construction of an utterance(or a text) has to take into account certain lan-guage operations such as predication or opera-tions of commitment, the expression of whichleaves a certain number of surface linguistictraces (or cues).
The enunciator?s degree ofcommitment to a predicative content is markedin the utterance by different kinds of linguistictraces.
In other words, it can be said that in dis-course the enunciator expresses different degreesof commitment to the truth of the propositionalcontent.Very close to this issue is thus the long tradi-tion of tracking veridicality in discourse.
Wheth-er ?
in the most recent work - under the term of?factuality degrees of events?
(Sauri andPustejovsky, 2012), ?event veridicality?
(DeMarneffe et al 2012), ?detection of uncertainty?
(CoNLL-2010 Shared Task) or ?attributions?
and223?private states?
(Wilson and Wiebe, 2005), thisnotion refers to the relationship between lan-guage and reader commitment.
In our approach,we do not attempt to access the notion of veridi-cality directly but rather via the organization ofthe text into different textual segments that havedifferent enunciative and modal validation con-texts.
However, the cues we have to take intoaccount to achieve this goal are mostly the sameas in veridicality studies (modal verbs, reportedspeech verbs, verb of propositional attitude,hedging adverbs, and so on).
Moreover, beyondtraditional lexical cues, we also include in ourwork other cues such as morphological inflection(e.g.
inflection of the French conditional tense),syntactic constructions such as subordinateclauses of condition or prepositional construc-tions (e.g.
according to X, at first sight?).
Fur-thermore, we have to take into account the factthat a lot of cues are embedded (as seen in Ex-ample 1 with express and a desire).
If we want tointerpret the enunciative and modal context ofthe textual segment to help Syria overcome thisphase, we have to consider the fact that it is em-bedded in the segment a desire to help Syriaovercome this phase.
From this point of view ourwork is related to Kilicoglu (2012) who studied?embedding predications?.
Thus, we do not onlyconsider the type of cues we find in text but alsothe way they interact.
This methodology alsoenables us to consider cues that play a role at adiscursive level.
This question of discursivemarkers is discussed in (Charolles et al 2005).Although modality markers in French - intheir close relationship with the markers of evi-dentiality - have been systematically described(see for example Gosselin, 2010; Le Querler,2004) there is still no reference corpus proposingthe annotation of enunciative and modal charac-teristics as a discursive delimitation task and thisis the goal we seek to achieve.
This problem ofidentifying modal cues related to a scope wasinitially researched in biomedical texts (Vinczeet al 2008).
This applicative task made it possi-ble to renew the linguistic approach to modalityby adopting a more concrete approach, focusingfirst on the variety of cues that can be identifiedin a text.
This perspective also enables the issueof the influence of textual genre on modalitymarkers to be addressed.In the next section, we present the way wepropose to annotate this enunciative and modalcommitment variation in text in terms of cuesand scopes.3 Annotating enunciative and modalcommitment in term of cues and scopeOur annotation goal is to define in which enunci-ative and modal context a propositional contentoccurs.
Observation of the cues in our corpusshowed that there are two kinds of cues: predica-tive cues that lead to the opening of a new textualsegment (this kind of cue has the syntactic prop-erty of governing another textual segment, e.g.cue1 in Example 2.)
and what we called modifiercues (mainly adverbs and some adjectives, e.g.cue2 in Example 2.).
The identification of pre-dicative cues (and their scope) leads to split thetext into different textual segments and then theidentification of modifier cues influence the vali-dation context of the textual segment previouslyidentified.2.
Paul veutcue1 s?rementcue2 que [Mary vienne.
]scope // Paul certainlycue1 wantscue2 [Mary tocome] scope.The annotation task we present here consistsin annotating these predicative cues (that lead tomodify the level of enunciative and/or modalcommitment of a textual segment) and theirscope.
The scope of a predicative cue corre-sponds to the textual segment impacted by thevariation in the level of enunciative and/or modalcommitment.
Table 1 presents the four classes ofpredicative cues that we consider and for each ofthem gives some examples of the syntactic com-ponents that can be under the scope of the cue.Cues  ScopeVerbs  Direct and/or indirect objectReporting verb,modal verbsPaul prometcue qu?
[il viendra]scope /Paul promisescue that [he willcome]scopePaul veutcue[venir]scope / Paulwantscue [to come]scopeNouns Noun complements, relativeclausePredicativenounsC'est son souhaitcue [d'?tre impli-qu?
]scope / It is his wishcue [to beinvolved]scopeMorphological  All the verb complementsFuture, condi-tionalJohn viendracue [plus tard]scope /John willcue [come later]scopeSyntactic Main clauseSubordinateclauses of condi-tionPrepositionalconstruction[Mary refuse de donner son appro-bation]scope ?
moins que Paul ac-ceptecue / [Mary refuses to give herapproval]scope unless Paul ac-ceptscueD?apres Paulcue, [Mary va venir]scope / According to Paulcue, [Maryis coming]scopeTable 1: Cues and associated scopes224As can be seen, depending on the type of pre-dicative cue, the syntactic dependents we consid-er in the scope vary.
This description of what weconsider as a predicative cue and how to delimitthe corresponding scope is reported in the firstversion of an annotation guideline.
In order torefine our descriptions and measure their rele-vance on the corpus, the following section pre-sents the inter-annotator agreement between twoexpert annotators and the first results of the au-tomatic system for the same annotation task.
Thisevaluation process should lead to the productionof a more precise guideline that can reveal finediscursive shades and also stimulate reflection onhow best to deal with syntactic and semantic in-formation in the automatic annotation system.4 Annotation and evaluation processOur final goal is to develop an automatic annota-tion system that produces the annotation ofenunciative and modal cues and their scope innewswire texts.
In this light, we have to build aguideline of our annotation aim and a referencecorpus that can be used to evaluate the system.Figure 1.Workflow of guideline improvementFigure 1 illustrates the steps in the workflowapplied to improve our annotation guideline.
Forthis purpose, two annotators (henceforth A1 andA2), both of them experts in linguistics, workedtogether to build a guideline and then the refer-ence corpus1.
First of all, the two annotators de-fined the annotation goals together (see step 1 inFigure 1).
Then they annotated separately a cor-pus of 20 newswire texts (see step 2a in Figure3).
This corpus contains 256 predicative cues andtheir associated scopes (see Table 2).# Sent Total Verbs Nouns Morpho Syntactic199 256 210 4 11 31Table 2: Corpus statistics1Our annotation process is based on Morante andDaelemans (2012).This manual annotation task was carried outusing the Glozz Annotation Tool (Widl?cher andMathet, 2012) that relies on the URS (Unit-Relation-Schema) meta model and produces anxml output.
The model permits to annotate textu-al units that can be embedded or not (in our casethe predicative cues and their scope) and rela-tions (for us, the opening relation links the pre-dicative cue to its scope).After this first annotation round, inter-annotator agreement was calculated (see table 3).The results show that the agreement between thetwo annotators is high for the cues but not verygood for the scopes.
By comparing the two setsof annotations in detail, we observed in our cor-pus that some textual segments can be either in-cluded or excluded from the scope depending onthe annotator?s interpretation.
Example (3) showsthe scope annotation proposed by annotator A1.As we can see, the textual segment qui a d?but?lundi is included in the scope by this annotatorbut it is excluded in the annotation proposed byA2.
In this particular case, we consider that bothinterpretations are acceptable since we cannotsay for sure if this segment is presented from theviewpoint of the journalist or from the viewpointof the source un de ses avocats.
The same phe-nomenon is often observed with temporal adver-bials that cannot be interpreted unambiguously asbeing a part of the scope or not.
In these twokinds of cases the annotator needs to use the con-text and his linguistic background to decide.
Thisraises the issue - already mentioned in Farkas etal.
(2010) ?
as to whether it is advisable to set astrict boundary for the scope.We propose to address this issue by evaluat-ing the scope annotation both strictly and moreflexibly.
In the flexible interpretation we distin-guish the segments that are detected with an ex-act match boundary from those that are detectedwith different boundaries but that are still correctin the interpretation (as in example 3).3.
[Le proc?s devant un tribunal militaire d'unblogueur ?gyptien arr?t?
pour avoir critiqu?
l'ar-m?e, qui a d?but?
lundi, a ?t?
ajourn?
?
di-manche]scope, a indiqu?cue mardi un de ses avocats.// [The trial before a military court of an Egyptianblogger arrested for criticizing the army, whichbegan on Monday, has been postponed to Sun-day]scope, saidcue one of his lawyers on Tuesday.To measure the distinction of using strict orflexible boundaries for scope, we propose to dis-tinguish the scope evaluation (for strict scopeboundaries) from the weighted scope evaluation(for flexible boundaries).225Flexible boundaries are calculated with a 0.5 fac-tor as follows:????????
?????????
???
?
0.5	 ?
?????????????
??????
???
?
0.5	 ?
??????
SB (strict boundaries): the number of enti-ties with a strict scope boundary?
FB (flexible boundaries): the number ofentities with a flexible scope boundary?
Ref: the number of reference entities (i.e.ideally identified)?
Rel: the number of relevant entities (i.e.correctly identified)The distinction between the evaluation ofscope and weighted scope revealed that in a sig-nificant number of cases (in this experimentationabout 10 %) the two annotators disagreed in theirannotation but that both interpretations were cor-rect.
This observation helped us to rethink ourannotation goals and based on the result of inter-annotator agreement, the two annotators pro-duced a common adjudicated version of theirannotation2 (step 4 in Figure 1).
This new anno-tated version is the result of a reflection on thetwo annotators?
disagreements and considers thecontext to delimit scope boundaries.Adjudicated /System precision recall F1Cues 0.85 0.86 0.86Scopes 0.79 0.72 0.76Weighted Scopes 0.84 0.77 0.80SB FB Rel Ref185 22 256 234Table 3: IAA: the annotations of annotator A1 areevaluated against the annotations of annotator A2Adjudicated /System precision recall F1Cues 0.83 0.85 0.84Scopes 0.52 0.59 0.55Weighted Scopes 0.67 0.76 0.71SB FB Rel Ref59 33 100 113Table 4: System evaluation: annotations from the sys-tem are evaluated against the adjudicated versionIn a second step, we evaluated the first anno-tation version of our automatic system (step 2b inFigure 1) on a subset of the corpus against theannotation of the adjudicated version (see table4).
The subset corpus contains 100 cues and theirassociated scopes.
Our automatic annotation sys-tem is based on the analysis dependency syntac-tic parser combined with scope detection rules(see Battistelli and Damiani, 2013).
The results2This adjudicated version is available for consultation:http://vmoaxc.1fichier.com/predicative_cue_scope.zipof this evaluation show that the detection of cuesis good, as with the manual annotation, while thescope detection is not as good.
This can be ex-plained partly by the fact that the syntactic parseranalysis produces some analysis errors (taggingor parsing errors, wrong syntactic attachmentespecially with coordinating conjunctions).Moreover, this evaluation shows that with anautomatic system, distinguishing strict and flexi-ble boundaries can highlight the results in anoth-er way.
Indeed, if we look at the scope evalua-tion, the F-measure is not really satisfactory.
Ifwe take into account only this measure, it couldbe concluded that our system is not efficient.However, with the measure of weighted scopewe see that while in many cases the scope did notmatch exactly with the reference corpus, it wasnot wrong either.
This phenomenon of scopeboundaries that are not easily decidable repre-sents 10% of disagreement in the IAA (ie 22 cas-es) and 30% in the system evaluation (ie 33 cas-es), and has to be taken into account to improvethe guideline and the annotation system.
Thisfirst annotation experiment on a small corpushelped us to define new annotation goals thatmust be integrated both in the new version of theguideline (step 6 in Figure 1) and in the automat-ic annotation system.5 ConclusionIn this paper, we have focused on a methodologyto produce a reference corpus proposing the an-notation of enunciative and modal commitmentinformation as a discursive delimitation task.
Theannotation scheme we propose is based on thedetection of predicative cues and their scopes.The results of the evaluation presented here showthat the most challenging task is not to find thepredicative cues but to delimit their scopes andbeyond this delimitation question to define howto assess whether a scope is correct or not.
Nextstep of our work is to launch a larger annotationcampaign involving more human annotators anda bigger corpus.
In this second step, our modelwill integrate modifier cues such as hedging ad-verbs that modify the semantic value of the tex-tual segments that have been first delimited andintroduce discursive cues that can impact morethan a single sentence At last, in order to makeour work available for the community our guide-line and reference corpus will soon be availableon Chronolines project website3.3http://www.chronolines.fr/226ReferencesBally, C. 1932.
Linguistique g?n?rale et Linguistiquefran?aise.
Paris : Leroux, 2?d.
(1944), Berne.Battistelli, D. and Damiani, M. 2013.
Analyzing mod-al and enunciative discursive heterogeneity: how tocombine semantic resources and a syntactic parseranalysis.
In IWCS 2013 Workshop: WAMM,Potsdam.Benveniste, E. 1966.
Probl?mes de linguistique g?n?-rale, 1, Paris : Gallimard.Charolles, M., Le Draoulec, A., P?ry-Woodley, M. P.and Sarda, L. 2005.
Temporal and spatial dimen-sions of discourse organisation.
Journal of FrenchLanguage Studies, 15(2), 115.Culioli, A.
1973.
Sur quelques contradictions en lin-guistique.
Communications, 20(1), 83-91.De Marneffe, M. C., Manning, C. D. and Potts, C.2012.
Did it happen?
The pragmatic complexity ofveridicality assessment.
Computational Linguistics38(2):301-333.Farkas R., Vincze V., M?ra G, Csirik J. and SzarvasG.
2010.
The CoNLL 2010 Shared Task: Learningto Detect Hedges and their Scope in Natural Lan-guage Text.
In Proceedings of the 2010 Conferenceon Computational Natural Language Learning.Kilocoglu, H.H.
2012.
Embedding predications.
PhDDissertation, Concordia University, Montreal.Morante, R. and Daelemans, W. 2012.
ConanDoyle-neg: Annotation of negation in Conan Doyle sto-ries.
In Proceedings of the Eighth InternationalConference on Language Resources and Evaluation(LREC).Sauri, R. and Pustejovsky, J.
2012.
Are You Sure ThatThis Happened?
Assessing the Factuality Degreeof Events in Text.
Computational Linguistics,38(2):261-299.Widl?cher A. and Mathet Y.
2012.
The Glozz Plat-form: A Corpus Annotation and Mining Tool.
InProceedings of the 2012 ACM symposium onDocument engineering, 171-180.Wilson, T. and Wiebe, J.
2005.
Annotating Attribu-tions and Private States.
In ACL 2005 Workshop:Frontiers in Corpus Annotation II: Pie in the Sky,53-60.227
