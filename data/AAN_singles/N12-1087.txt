2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 688?698,Montre?al, Canada, June 3-8, 2012. c?2012 Association for Computational LinguisticsUnified Expectation MaximizationRajhans SamdaniUniversity of Illinoisrsamdan2@illinois.eduMing-Wei ChangMicrosoft Researchminchang@microsoft.comDan RothUniversity of Illinoisdanr@illinois.eduAbstractWe present a general framework containing agraded spectrum of Expectation Maximization(EM) algorithms called Unified ExpectationMaximization (UEM.)
UEM is parameterizedby a single parameter and covers existing al-gorithms like standard EM and hard EM, con-strained versions of EM such as Constraint-Driven Learning (Chang et al, 2007) and Pos-terior Regularization (Ganchev et al, 2010),along with a range of new EM algorithms.For the constrained inference step in UEM wepresent an efficient dual projected gradient as-cent algorithm which generalizes several dualdecomposition and Lagrange relaxation algo-rithms popularized recently in the NLP litera-ture (Ganchev et al, 2008; Koo et al, 2010;Rush and Collins, 2011).
UEM is as efficientand easy to implement as standard EM.
Fur-thermore, experiments on POS tagging, infor-mation extraction, and word-alignment showthat often the best performing algorithm in theUEM family is a new algorithm that wasn?tavailable earlier, exhibiting the benefits of theUEM framework.1 IntroductionExpectation Maximization (EM) (Dempster et al,1977) is inarguably the most widely used algo-rithm for unsupervised and semi-supervised learn-ing.
Many successful applications of unsupervisedand semi-supervised learning in NLP use EM in-cluding text classification (McCallum et al, 1998;Nigam et al, 2000), machine translation (Brown etal., 1993), and parsing (Klein and Manning, 2004).Recently, EM algorithms which incorporate con-straints on structured output spaces have been pro-posed (Chang et al, 2007; Ganchev et al, 2010).Several variations of EM (e.g.
hard EM) exist inthe literature and choosing a suitable variation is of-ten very task-specific.
Some works have shown thatfor certain tasks, hard EM is more suitable than reg-ular EM (Spitkovsky et al, 2010).
The same issuecontinues in the presence of constraints where Poste-rior Regularization (PR) (Ganchev et al, 2010) cor-responds to EM while Constraint-Driven Learning(CoDL)1 (Chang et al, 2007) corresponds to hardEM.
The problem of choosing between EM and hardEM (or between PR and CoDL) remains elusive,along with the possibility of simple and better alter-natives, to practitioners.
Unfortunately, little studyhas been done to understand the relationships be-tween these variations in the NLP community.In this paper, we approach various EM-basedtechniques from a novel perspective.
We believe that?EM or Hard-EM??
and ?PR or CoDL??
are not theright questions to ask.
Instead, we present a unifiedframework for EM, Unified EM (UEM), that coversmany EM variations including the constrained casesalong with a continuum of new ones.
UEM allows usto compare and investigate the properties of EM in asystematic way and helps find better alternatives.The contributions of this paper are as follows:1.
We propose a general framework called Uni-fied Expectation Maximization (UEM) thatpresents a continuous spectrum of EM algo-rithms parameterized by a simple temperature-like tuning parameter.
The framework coversboth constrained and unconstrained EM algo-rithms.
UEM thus connects EM, hard EM, PR,and CoDL so that the relation between differ-ent algorithms can be better understood.
It alsoenables us to find new EM algorithms.2.
To solve UEM (with constraints), we propose1To be more precise, (Chang et al, 2007) mentioned usinghard constraints as well as soft constraints in EM.
In this paper,we refer to CoDL only as the EM framework with hard con-straints.688a dual projected subgradient ascent algorithmthat generalizes several dual decompositionand Lagrange relaxation algorithms (Bertsekas,1999) introduced recently in NLP (Ganchev etal., 2008; Rush and Collins, 2011).3.
We provide a way to implement a family ofEM algorithms and choose the appropriate one,given the data and problem setting, rather thana single EM variation.
We conduct experi-ments on unsupervised POS tagging, unsuper-vised word-alignment, and semi-supervised in-formation extraction and show that choosingthe right UEM variation outperforms existingEM algorithms by a significant margin.2 PreliminariesLet x denote an input or observed features and h bea discrete output variable to be predicted from a fi-nite set of possible outputs H(x).
Let P?
(x,h) bea probability distribution over (x,h) parameterizedby ?.
Let P?
(h|x) refer to the conditional probabil-ity of h given x.
For instance, in part-of-speech tag-ging, x is a sentence, h the corresponding POS tags,and ?
could be an HMM model; in word-alignment,x can be an English-French sentence pair, h theword alignment between the sentences, and ?
theprobabilistic alignment model.
Let ?
(h = h?)
bethe Kronecker-Delta distribution centered at h?, i.e.,it puts a probability of 1 at h?
and 0 elsewhere.In the rest of this section, we review EM andconstraints-based learning with EM.2.1 EM AlgorithmTo obtain the parameter ?
in an unsupervised way,one maximizes log-likelihood of the observed data:L(?)
= logP?
(x) = log?h?H(x)P?
(x,h) .
(1)EM (Dempster et al, 1977) is the most commontechnique for learning ?, which maximizes a tightlower bound onL(?).
While there are a few differentstyles of expressing EM, following the style of (Nealand Hinton, 1998), we defineF (?, q) = L(?
)?KL(q, P?
(h|x)), (2)where q is a posterior distribution over H(x) andKL(p1, p2) is the KL divergence between two dis-tributions p1 and p2.
Given this formulation, EM canbe shown to maximize F via block coordinate ascentalternating over q (E-step) and ?
(M-step) (Neal andHinton, 1998).
In particular, the E-step for EM canbe written asq = arg minq?
?QKL(q?, P?
(h|x)) , (3)where Q is the space of all distributions.
While EMproduces a distribution in the E-step, hard EM isthought of as producing a single output given byh?
= arg maxh?H(x)P?
(h|x) .
(4)However, one can also think of hard EM as pro-ducing a distribution given by q = ?
(h = h?).
Inthis paper, we pursue this distributional view of bothEM and hard EM and show its benefits.EM for Discriminative Models EM-like algo-rithms can also be used in discriminative set-tings (Bellare et al, 2009; Ganchev et al, 2010)specifically for semi-supervised learning (SSL.
)Given some labeled and unlabeled data, such algo-rithms maximize a modified F (?, q) function:F (?, q) = Lc(?)?
c1??
?2 ?
c2KL(q, P?
(h|x)) , (5)where, q, as before, is a probability distribution overH(x), Lc(?)
is the conditional log-likelihood of thelabels given the features for the labeled data, and c1and c2 are constants specified by the user; the KLdivergence is measured only over the unlabeled data.The EM algorithm in this case has the same E-stepas unsupervised EM, but the M-step is different.
TheM-step is similar to supervised learning as it finds ?by maximizing a regularized conditional likelihoodof the data w.r.t.
the labels ?
true labels are used forlabeled data and ?soft?
pseudo labels based on q areused for unlabeled data.2.2 Constraints in EMIt has become a common practice in the NLP com-munity to use constraints on output variables toguide inference.
Few of many examples includetype constraints between relations and entities (Rothand Yih, 2004), sentential and modifier constraintsduring sentence compression (Clarke and Lapata,2006), and agreement constraints between word-alignment directions (Ganchev et al, 2008) or var-ious parsing models (Koo et al, 2010).
In the con-689text of EM, constraints can be imposed on the pos-terior probabilities, q, to guide the learning proce-dure (Chang et al, 2007; Ganchev et al, 2010).In this paper, we focus on linear constraints overh (potentially non-linear over x.)
This is a very gen-eral formulation as it is known that all Boolean con-straints can be transformed into sets of linear con-straints over binary variables (Roth and Yih, 2007).Assume that we have m linear constraints on out-puts where the kth constraint can be written asukTh ?
bk .Defining a matrix U as UT =[u1T .
.
.
umT]and a vector b as bT = [b1, .
.
.
, bm], we write downthe set of all feasible2 structures as{h | h ?
H(x),Uh ?
b} .Constraint-Driven Learning (CoDL) (Chang etal., 2007) augments the E-step of hard EM (4) byimposing these constraints on the outputs.Constraints on structures can be relaxed to expec-tation constraints by requiring the distribution q tosatisfy them only in expectation.
Define expecta-tion w.r.t.
a distribution q over H(x) as Eq[Uh] =?h?H(x) q(h)Uh.
In the expectation constraintssetting, q is required to satisfy:Eq[Uh] ?
b .The space of distributions Q can be modified as:Q = {q | q(h) ?
0, Eq[Uh] ?
b,?h?H(x)q(h) = 1}.Augmenting these constraints into the E-step ofEM (3), gives the Posterior Regularization (PR)framework (Ganchev et al, 2010).
In this paper, weadopt the expectation constraint setting.
Later, weshow that UEM naturally includes and generalizesboth PR and CoDL.3 Unified Expectation MaximizationWe now present the Unified Expectation Maximiza-tion (UEM) framework which captures a continuumof (constrained and unconstrained) EM algorithms2Note that this set is a finite set of discrete variables not tobe confused with a polytope.
Polytopes are also specified as{z|Az ?
d} but are over real variables whereas h is discrete.Algorithm 1 The UEM algorithm for both the genera-tive (G) and discriminative (D) cases.Initialize ?0for t = 0, .
.
.
, T doUEM E-step:qt+1 ?
arg minq?QKL(q, P?t(h|x); ?
)UEM M-step:G: ?t+1 = arg max?
Eqt+1 [logP?
(x,h)]D: ?t+1 = arg max?
Eqt+1 [logP?(h|x)]?
c1??
?2end forincluding EM and hard EM by modulating the en-tropy of the posterior.
A key observation underlyingthe development of UEM is that hard EM (or CoDL)finds a distribution with zero entropy while EM (orPR) finds a distribution with the same entropy as P?
(or close to it).
Specifically, we modify the objectiveof the E-step of EM (3) asq = arg minq?
?QKL(q?, P?
(h|x); ?)
, (6)where KL(q, p; ?)
is a modified KL divergence:KL(q, p; ?)
=?h?H(x)?q(h) log q(h)?q(h) log p(h).
(7)In other words, UEM projects P?
(h|x) on thespace of feasible distributions Q w.r.t.
a metric3KL(?, ?
; ?)
to obtain the posterior q.
By simply vary-ing ?, UEM changes the metric of projection and ob-tains different variations of EM including EM (PR,in the presence of constraints) and hard EM (CoDL.
)The M-step for UEM is exactly the same as EM (ordiscriminative EM.
)The UEM Algorithm: Alg.
1 shows the UEM al-gorithm for both the generative (G) and the discrimi-native (D) case.
We refer to the UEM algorithm withparameter ?
as UEM?
.3.1 Relationship between UEM and Other EMAlgorithmsThe relation between unconstrained versions of EMhas been mentioned before (Ueda and Nakano,1998; Smith and Eisner, 2004).
We show that therelationship takes novel aspects in the presence ofconstraints.
In order to better understand differentUEM variations, we write the UEM E-step (6) ex-plicitly as an optimization problem:3The term ?metric?
is used very loosely.
KL(?, ?
; ?)
doesnot satisfy the mathematical properties of a metric.690Framework ?
= ??
?
= 0 ?
?
(0, 1) ?
= 1 ?
=??
1Constrained Hard EM Hard EM (NEW) UEM?
Standard EM DeterministicAnnealing EMUnconstrained CoDL (Chang etal., 2007)(NEW) EMwith Lin.
Prog.
(NEW) constrainedUEM?PR (Ganchev et al,2010)Table 1: Summary of different UEM algorithms.
The entries marked with ?(NEW)?
have not been proposed before.Eq.
(8) is the objective function for all the EM frameworks listed in this table.
Note that, in the absence of constraints,?
?
(?
?, 0] corresponds to hard EM (Sec.
3.1.1.)
Please see Sec.
3.1 for a detailed explanation.minq?h?H(x)?q(h) log q(h)?
q(h) logP?(h|x)(8)s.t.
Eq[Uh] ?
b,q(h) ?
0,?h ?
H(x),?h?H(x) q(h) = 1 .We discuss below, both the constrained and theunconstrained cases.
Tab.
1 summarizes differentEM algorithms in the UEM family.3.1.1 UEM Without ConstraintsThe E-step in this case, computes a q obeyingonly the simplex constraints:?h?H(x) q(h) = 1.For ?
= 1, UEM minimizes KL(q, P?
(h|x); 1)which is the same as minimizing KL(q, P?
(h|x))as in the standard EM (3).
For ?
= 0, UEMis solving arg minq?Q?h?H(x)?q(h) logP?
(h|x)which is a linear programming (LP) problem.
Due tothe unimodularity of the simplex constraints (Schri-jver, 1986), this LP outputs an integral q =?
(h = arg maxh?H(x) P?
(h|x))which is the sameas hard EM (4).
It has already been noted in the liter-ature (Kearns et al, 1997; Smith and Eisner, 2004;Hofmann, 2001) that this formulation (correspond-ing to our ?
= 0) is the same as hard EM.
In fact,for ?
?
0, UEM stays the same as hard EM be-cause of negative penalty on the entropy.
The range?
?
(0, 1) has not been discussed in the literature,to the best of our knowledge.
In Sec.
5, we showthe impact of using UEM?for ?
?
{0, 1}.
Lastly,the range of ?
from?
to 1 has been used in deter-ministic annealing for EM (Rose, 1998; Ueda andNakano, 1998; Hofmann, 2001).
However, the focusof deterministic annealing is solely to solve the stan-dard EM while avoiding local maxima problems.3.1.2 UEM With ConstraintsUEM and Posterior Regularization (?
= 1) For?
= 1, UEM solves arg minq?QKL (q, P?
(h|x))which is the same as Posterior Regulariza-tion (Ganchev et al, 2010).UEM and CoDL (?
= ??)
When ?
?
?
?then due to an infinite penalty on the entropy of theposterior, the entropy must become zero.
Thus, nowthe E-step, as expressed by Eq.
(8), can be written asq = ?
(h = h?)
where h?
is obtained asarg maxh?H(x)logP?
(h|x) (9)s.t.
Uh ?
b ,which is the same as CoDL.
This combinatorialmaximization can be solved using the Viterbi algo-rithm in some cases or, in general, using Integer Lin-ear Programming (ILP.
)3.2 UEM with ?
?
[0, 1]Tab.
1 lists different EM variations and their associ-ated values ?.
This paper focuses on values of ?
be-tween 0 and 1 for the following reasons.
First, the E-step (8) is non-convex for ?
< 0 and hence compu-tationally expensive; e.g., hard EM (i.e.
?
= ??
)requires ILP inference.
For ?
?
0, (8) is a convexoptimization problem which can be solved exactlyand efficiently.
Second, for ?
= 0, the E-step solvesmaxq?h?H(x) q(h) logP?
(h|x) (10)s.t.
Eq[Uh] ?
b,q(h) ?
0, ?h ?
H(x),?h?H(x) q(h) = 1 ,which is an LP-relaxation of hard EM (Eq.
(4)and (9)).
LP relaxations often provide a decentproxy to ILP (Roth and Yih, 2004; Martins et al,2009).
Third, ?
?
[0, 1] covers standard EM/PR.3.2.1 Discussion: Role of ?The modified KL divergence can be related tostandard KL divergence as KL(q, P?
(h|x); ?)
=691KL(q, P?
(y|x)) + (1?
?
)H(q) ?
UEM (6) mini-mizes the former during the E-step, while StandardEM (3) minimizes the latter.
The additional term(1 ?
?
)H(q) is essentially an entropic prior on theposterior distribution q which can be used to regu-larize the entropy as desired.For ?
< 1, the regularization term penalizes theentropy of the posterior thus reducing the probabilitymass on the tail of the distribution.
This is signifi-cant, for instance, in unsupervised structured predic-tion where the tail can carry a substantial amount ofprobability mass as the output space is massive.
Thisnotion aligns with the observation of (Spitkovskyet al, 2010) who criticize EM for frittering awaytoo much probability mass on unimportant outputswhile showing that hard EM does much better inPCFG parsing.
In particular, they empirically showthat when initialized with a ?good?
set of parame-ters obtained by supervised learning, EM drifts away(thus losing accuracy) much farther than hard-EM.4 Solving Constrained E-step withLagrangian DualIn this section, we discuss how to solve the E-step (8) for UEM.
It is a non-convex problem for?
< 0; however, for ?
= ??
(CoDL) one can useILP solvers.
We focus here on solving the E-step for?
?
0 for which it is a convex optimization problem,and use a Lagrange relaxation algorithm (Bertsekas,1999).
Our contributions are two fold:?
We describe an algorithm for UEM with con-straints that is as easy to implement as PR orCoDL.
Existing code for constrained EM (PRor CoDL) can be easily extended to run UEM.?
We solve the E-step (8) using a Lagrangiandual-based algorithm which performs projectedsubgradient-ascent on dual variables.
Our al-gorithm covers Lagrange relaxation and dualdecomposition techniques (Bertsekas, 1999)which were recently popularized in NLP (Rushand Collins, 2011; Rush et al, 2010; Koo et al,2010).
Not only do we extend the algorithmicframework to a continuum of algorithms, wealso allow, unlike the aforementioned works,general inequality constraints over the outputvariables.
Furthermore, we establish new andinteresting connections between existing con-strained inference techniques.4.1 Projected Subgradient Ascent withLagrangian DualWe provide below a high-level view of our algo-rithm, omitting the technical derivations due to lackof space.
To solve the E-step (8), we introduce dualvariables ?
?
one for each expectation constraint inQ.
The subgradient O?
of the dual of Eq.
(8) w.r.t.?
is given byO?
?
Eq[Uh]?
b .
(11)For ?
> 0, the primal variable q can be written interms of ?
asq(h) ?
P?t(h|x)1?
e??TUh?
.
(12)For ?
= 0, the q above is not well defined and sowe take the limit ?
?
0 in (12) and since lp normapproaches the max-norm as p?
?, this yieldsq(h) = ?
(h = arg maxh??H(x)P?(h?|x)e??TUh?).
(13)We combine both the ideas by setting q(h) =G(h, P?t(?|x), ?TU, ?)
whereG(h, P,v, ?)
=??????
?P (h)1?
e?
vh??h?
P (h?)1?
e?
vh???
> 0 ,?
(h= argmaxh?
?H(x)P (h?)e?vh?)
?
= 0 .(14)Alg.
2 shows the overall optimization scheme.The dual variables for inequality constraints are re-stricted to be positive and hence after a gradient up-date, negative dual variables are projected to 0.Note that for ?
= 0, our algorithm is a Lagrangerelaxation algorithm for approximately solving theE-step for CoDL (which uses exact arg max infer-ence).
Lagrange relaxation has been recently shownto provide exact and optimal results in a large num-ber of cases (Rush and Collins, 2011).
This showsthat our range of algorithms is very broad ?
it in-cludes PR and a good approximation to CoDL.Overall, the required optimization (8) can besolved efficiently if the expected value computationin the dual gradient (Eq.
(11)) w.r.t.
the posterior qin the primal (Eq (14)) can be performed efficiently.In cases where we can enumerate the possible out-puts h efficiently, e.g.
multi-class classification, we692Algorithm 2 Solving E-step of UEM?
for ?
?
0.1: Initialize and normalize q; initialize ?
= 0.2: for t = 0, .
.
.
, R or until convergence do3: ??
max (?+ ?t (Eq[Uh]?
b) , 0)4: q(h) = G(h, P?t(?|x), ?TU, ?
)5: end forcan compute the posterior probability q explicitlyusing the dual variables.
In cases where the out-put space is structured and exponential in size, e.g.word alignment, we can optimize (8) efficiently ifthe constraints and the model P?
(h|x) decomposein the same way.
To elucidate, we give a more con-crete example in the next section.4.2 Projected Subgradient based DualDecomposition AlgorithmSolving the inference (8) using Lagrangian dual canoften help us decompose the problem into compo-nents and handle complex constraints in the dualspace as we show in this section.
Suppose ourtask is to predict two output variables h1 and h2coupled via linear constraints.
Specifically, theyobey Ueh1 = Ueh2 (agreement constraints) andUih1 ?
Uih2 (inequality constraints)4 for givenmatrices Ue and Ui.
Let their respective probabilis-tic models be P 1?1 and P2?2 .
The E-step (8) can bewritten asarg minq1,q2A(q1, q2; ?)
(15)s.t.
Eq1 [Ueh1] = Eq2 [Ueh2]Eq1 [Uih1] ?
Eq2 [Uih2] ,where A(q1, q2; ?)
= KL(q1(h1), P 1?1(h1|x); ?)
+KL(q2(h2), P 2?2(h2|x); ?
).The application of Alg.
2 results in a dual decom-position scheme which is described in Alg.
3.Note that in the absence of inequality constraintsand for ?
= 0, our algorithm reduces to a simplerdual decomposition algorithm with agreement con-straints described in (Rush et al, 2010; Koo et al,2010).
For ?
= 1 with agreement constraints, ouralgorithm specializes to an earlier proposed tech-nique by (Ganchev et al, 2008).
Thus our algo-rithm puts these dual decomposition techniques with4The analysis remains the same for a more general formu-lation with a constant offset vector on the R.H.S.
and differentmatrices for h1 and h2.Algorithm 3 Projected Subgradient-based LagrangeRelaxation Algorithm that optimizes Eq.
(15)1: Input: Two distributions P 1?1 and P2?2 .2: Output: Output distributions q1 and q2 in (15)3: Define ?T =[?eT ?iT]and UT =[UeT UiT]4: ??
05: for t = 0, .
.
.
, R or until convergence do6: q1(h1)?
G(h1, P 1?1(?|x), ?TU, ?
)7: q2(h2)?
G(h2, P 2?2(?|x),?
?TU, ?
)8: ?e ?
?e + ?t(?Eq1 [Ueh1] + Eq2 [Ueh2])9: ?i ?
?i + ?t(?Eq1 [Uih1] + Eq2 [Uih2])10: ?i ?
max(?i, 0) {Projection step}11: end for12: return (q1, q2)agreement constraints on the same spectrum.
More-over, dual-decomposition is just a special case ofLagrangian dual-based techniques.
Hence Alg.
2is more broadly applicable (see Sec.
5).
Lines 6-9show that the required computation is decomposedover each sub-component.Thus if computing the posterior and expected val-ues of linear functions over each subcomponent iseasy, then the algorithm works efficiently.
Con-sider the case when constraints decompose linearlyover h and each component is modeled as an HMMwith ?S as the initial state distribution, ?E as em-mision probabilities, and ?T as transition probabil-ities.
An instance of this is word alignment overlanguage pair (S, T ) modeled using an HMM aug-mented with agreement constraints which constrainalignment probabilities in one direction (P?1 : fromS to T ) to agree with the alignment probabilities inthe other direction (P?2 : from T to S.) The agree-ment constraints are linear over the alignments, h.Now, the HMM probability is given byP?
(h|x) = ?S(h0)?i ?E(xi|hi)?T (hi+1|hi)where vi denotes the ith component of a vector v.For ?
> 0, the resulting q (14) can be expressedusing a vector ?
=+/-?TU (see lines 6-7) asq(h) ?
(?S(h0)?i?E(xi|hi)?T (hi+1|hi)) 1?e?i ?ihi???i?S(h0)1?
(?E(xi|hi)e?ihi) 1?
?T (hi+1|hi)1?
.The dual variables-based term can be folded intothe emission probabilities, ?E .
Now, the resulting qcan be expressed as an HMM by raising ?S , ?E , and693?T to the power 1/?
and normalizing.
For ?
= 0, qcan be computed as the most probable output.
Therequired computations in lines 6-9 can be performedusing the forward-backward algorithm or the Viterbialgorithm.
Note that we can efficiently compute ev-ery step because the linear constraints decomposenicely along the probability model.5 ExperimentsOur experiments are designed to explore tuning ?in the UEM framework as a way to obtain gainsover EM and hard EM in the constrained and uncon-strained cases.
We conduct experiments on POS-tagging, word-alignment, and information extrac-tion; we inject constraints in the latter two.
In all thecases we use our unified inference step to implementgeneral UEM and the special cases of existing EMalgorithms.
Since both of our constrained problemsinvolve large scale constrained inference during theE-step, we use UEM0 (with a Lagrange relaxationbased E-step) as a proxy for ILP-based CoDL .As we vary ?
over [0, 1], we circumvent much ofthe debate over EM vs hard EM (Spitkovsky et al,2010) by exploring the space of EM algorithms in a?continuous?
way.
Furthermore, we also study therelation between quality of model initialization andthe value of ?
in the case of POS tagging.
This isinspired by a general ?research wisdom?
that hardEM is a better choice than EM with a good initial-ization point whereas the opposite is true with an?uninformed?
initialization.Unsupervised POS Tagging We conduct exper-iments on unsupervised POS learning experimentwith the tagging dictionary assumption.
We use astandard subset of Penn Treebank containing 24,115tokens (Ravi and Knight, 2009) with the tagging dic-tionary derived from the entire Penn Treebank.
Werun UEM with a first order (bigram) HMM model5.We consider initialization points of varying qualityand observe the performance for ?
?
[0, 1].Different initialization points are constructed asfollows.
The ?posterior uniform?
initialization iscreated by spreading the probability uniformly overall possible tags for each token.
Our EM model on5(Ravi and Knight, 2009) showed that a first order HMMmodel performs much better than a second order HMM modelon unsupervised POS tagging-0.15-0.1-0.05 0 0.05 1.00.90.80.70.60.50.40.30.20.10.0Relative performance to EM (Gamma=1)Gammauniform posteriorinitializer5 labeled examples initializer10 labeled examples initializer20 labeled examples initializer40 labeled examples initializer80 labeled examples initializerFigure 1: POS Experiments showing the relation betweeninitial model parameters and ?.
We report the relative per-formance compared to EM (see Eq.
(16)).
The posterioruniform initialization does not use any labeled examples.As the no.
of labeled examples used to create the initialHMM model increases, the quality of the initial modelimproves.
The results show that the value of the best ?
issensitive to the initialization point and EM (?
= 1) andhard EM (?
= 0) are often not the best choice.this dataset obtains 84.9% accuracy on all tokensand 72.3% accuracy on ambiguous tokens, whichis competitive with results reported in (Ravi andKnight, 2009).
To construct better initializationpoints, we train a supervised HMM tagger on hold-out labeled data.
The quality of the initializationpoints is varied by varying the size of the labeleddata over {5, 10, 20, 40, 80}.
Those initializationpoints are then fed into different UEM algorithms.Results For a particular ?, we report the perfor-mance of UEM?
w.r.t.
EM (?
= 1.0) as given byrel(?)
=Acc(UEM?
)?Acc(UEM?=1.0)Acc(UEM?=1.0)(16)where Acc represents the accuracy as evaluated onthe ambiguous words of the given data.
Note thatrel(?)
?
0, implies performance better or worsethan EM.
The results are summarized in Figure 1.Note that when we use the ?posterior uniform?initialization, EM wins by a significant margin.
Sur-prisingly, with the initialization point constructedwith merely 5 or 10 examples, EM is not the bestalgorithm anymore.
The best result for most cases isobtained at ?
somewhere between 0 (hard EM) and 1(EM).
Furthermore, the results not only indicate thata measure of ?hardness?
of EM i.e.
the best value694of ?, is closely related to the quality of the ini-tialization point but also elicit a more fine-grainedrelationship between initialization and UEM.This experiment agrees with (Merialdo, 1994),which shows that EM performs poorly in the semi-supervised setting.
In (Spitkovsky et al, 2010), theauthors show that hard EM (Viterbi EM) works bet-ter than standard EM.
We extend these results byshowing that this issue can be overcome with theUEM framework by picking appropriate ?
based onthe amount of available labeled data.Semi-Supervised Entity-Relation ExtractionWe conduct semi-supervised learning (SSL) ex-periments on entity and relation type predictionassuming that we are given mention boundaries.We borrow the data and the setting from (Roth andYih, 2004).
The dataset has 1437 sentences; fourentity types: PER, ORG, LOC, OTHERS and;five relation types LIVE IN, KILL, ORG BASED IN,WORKS FOR, LOCATED IN.
We consider relationsbetween all within-sentence pairs of entities.
Weadd a relation type NONE indicating no relationexists between a given pair of entities.We train two log linear models for entity type andrelation type prediction, respectively via discrimina-tive UEM.
We work in a discriminative setting inorder to use several informative features which weborrow from (Roth and Small, 2009).
Using thesefeatures, we obtain 56% average F1 for relations and88% average F1 for entities in a fully supervised set-ting with an 80-20 split which is competitive withthe reported results on this data (Roth and Yih, 2004;Roth and Small, 2009).
For our SSL experiments,we use 20% of data for testing, a small amount, ?%,as labeled training data (we vary ?
), and the remain-ing as unlabeled training data.
We initialize with aclassifier trained on the given labeled data.We use the following constraints on the posterior.1) Type constraints: For two entities e1 and e2, therelation type ?
(e1, e2) between them dictates a par-ticular entity type (or in general, a set of entity types)for both e1 and e2.
These type constraints can beexpressed as simple logical rules which can be con-verted into linear constraints.
E.g.
if the pair (e1, e2)has relation type LOCATED IN then e2 must have en-tity type LOC.
This yields a logical rule which isconverted into a linear constraint as0.3?0.32?0.34?0.36?0.38?0.4?0.42?0.44?0.46?0.48?5?
10?
20?Avg.?F1?for?rela?ons?%?of?labeled?data?Sup.?Bas.?
PR?CoDL?
UEM?Figure 2: Average F1 for relation prediction for varyingsizes of labeled data comparing the supervised baseline,PR, CoDL, and UEM.
UEM is statistically significantlybetter than supervised baseline and PR in all the cases.(?
(e1, e2) == LOCATED IN) ?
(e2 == LOC)?
q (LOCATED IN; e1, e2) ?
q (LOC; e2) .Refer to (Roth and Yih, 2004) for more statistics onthis data and a list of all the type constraints used.2) Expected count constraints: Since most entitypairs are not covered by the given relation types, thepresence of a large number of NONE relations canoverwhelm SSL.
To guide learning in the right direc-tion, we use corpus-wide expected count constraintsfor each non-NONE relation type.
These constraintsare very similar to the label regularization techniquementioned in (Mann and McCallum, 2010).
Let Drbe the set of entity pairs as candidate relations in theentire corpus.
For each non-NONE relation type ?,we impose the constraintsL?
??(e1,e2)?Drq(?
; e1, e2) ?
U?
,where L?
and U?
are lower and upper bound on theexpected number of ?
relations in the entire corpus.Assuming that the labeled and the unlabeled data aredrawn from the same distribution, we obtain thesebounds using the fractional counts of ?
over the la-beled data and then perturbing it by +/- 20%.Results We use Alg.
2 for solving the constrainedE-step.
We report results averaged over 10 randomsplits of the data and measure statistical significanceusing paired t-test with p = 0.05.
The results forrelation prediction are shown in Fig.
2.
For eachtrial, we split the labeled data into half to tune thevalue of ?.
For ?
= 5%, 10%, and 20%, the average695value of gamma is 0.52, 0.6, and 0.57, respectively;the median values are 0.5, 0.6, and 0.5, respectively.For relation extraction, UEM is always statisticallysignificantly better than the baseline and PR.
Thedifference between UEM and CoDL is small whichis not very surprising because hard EM approacheslike CoDL are known to work very well for discrim-inative SSL.
We omit the graph for entity predic-tion because EM-based approaches do not outper-form the supervised baseline there.
However, no-tably, for entities, for ?
= 10%, UEM outperformsCoDL and PR and for 20%, the supervised baselineoutperforms PR statistically significantly.Word Alignment Statistical word alignment is awell known structured output application of unsu-pervised learning and is a key step towards ma-chine translation from a source language S to a tar-get language T .
We experiment with two language-pairs: English-French and English-Spanish.
Weuse Hansards corpus for French-English trans-lation (Och and Ney, 2000) and Europarl cor-pus (Koehn, 2002) for Spanish-English translationwith EPPS (Lambert et al, 2005) annotation.We use an HMM-based model for word-alignment (Vogel et al, 1996) and add agreementconstraints (Liang et al, 2008; Ganchev et al, 2008)to constrain alignment probabilities in one direction(P?1 : from S to T ) to agree with the alignment prob-abilities in the other direction (P?2 : from T to S.)We use a small development set of size 50 to tunethe model.
Note that the amount of labeled data weuse is much smaller than the supervised approachesreported in (Taskar et al, 2005; Moore et al, 2006)and unsupervised approaches mentioned in (Liang etal., 2008; Ganchev et al, 2008) and hence our resultsare not directly comparable.
For the E-step, we useAlg.
3 with R=5 and pick ?
from {0.0, 0.1, .
.
.
, 1.0},tuning it over the development set.During testing, instead of running HMM mod-els for each direction separately, we obtain posteriorprobabilities by performing agreement constraints-based inference as in Alg.
3.
This results in aposterior probability distribution over all possiblealignments.
To obtain final alignments, follow-ing (Ganchev et al, 2008) we use minimum Bayesrisk decoding: we align all word pairs with poste-rior marginal alignment probability above a certainSize EM PR CoDL UEM EM PR CoDL UEMEn-Fr Fr-En10k 23.54 10.63 14.76 9.10 19.63 10.71 14.68 9.2150k 18.02 8.30 10.08 7.34 16.17 8.40 10.09 7.40100k 16.31 8.16 9.17 7.05 15.03 8.09 8.93 6.87En-Es Es-En10k 33.92 22.24 28.19 20.80 31.94 22.00 28.13 20.8350k 25.31 19.84 22.99 18.93 24.46 20.08 23.01 18.95100k 24.48 19.49 21.62 18.75 23.78 19.70 21.60 18.64Table 2: AER (Alignment Error Rate) comparisonsfor French-English (above) and Spanish-English (below)alignment for various data sizes.
For French-English set-ting, tuned ?
for all data-sizes is either 0.5 or 0.6.
ForSpanish-English, tuned ?
for all data-sizes is 0.7.threshold, tuned over the development set.Results We compare UEM with EM, PR, andCoDL on the basis of Alignment Error Rate (AER)for different sizes of unlabeled data (See Tab.
2.
)See (Och and Ney, 2003) for the definition of AER.UEM consistently outperforms EM, PR, and CoDLwith a wide margin.6 ConclusionWe proposed a continuum of EM algorithmsparameterized by a single parameter.
Our frame-work naturally incorporates constraints on outputvariables and generalizes existing constrained andunconstrained EM algorithms like standard andhard EM, PR, and CoDL.
We provided an efficientLagrange relaxation algorithm for inference withconstraints in the E-step and empirically showedhow important it is to choose the right EM version.Our technique is amenable to be combined withmany existing variations of EM (Berg-Kirkpatricket al, 2010).
We leave this as future work.Acknowledgments: We thank Joa?o Grac?a for provid-ing the code and data for alignment with agreement.
Thisresearch is sponsored by the Army Research Laboratory(ARL) under agreement W911NF-09-2-0053, DefenseAdvanced Research Projects Agency (DARPA) MachineReading Program under Air Force Research Laboratory(AFRL) prime contract no.
FA8750-09-C-018, and anONR Award on Guiding Learning and Decision Makingin the Presence of Multiple Forms of Information.
Anyopinions, findings, conclusions or recommendations arethose of the authors and do not necessarily reflect theviews of the funding agencies.696ReferencesK.
Bellare, G. Druck, and A. McCallum.
2009.
Alter-nating projections for learning with expectation con-straints.
In UAI.T.
Berg-Kirkpatrick, A.
Bouchard-Co?te?, J. DeNero, andD.
Klein.
2010.
Painless unsupervised learning withfeatures.
In ACL, HLT ?10.D.
P. Bertsekas.
1999.
Nonlinear Programming.
AthenaScientific, 2nd edition.P.
Brown, S. D. Pietra, V. D. Pietra, and R. Mercer.
1993.The mathematics of statistical machine translation: pa-rameter estimation.
Computational Linguistics.M.
Chang, L. Ratinov, and D. Roth.
2007.
Guiding semi-supervision with constraint-driven learning.
In ACL.J.
Clarke and M. Lapata.
2006.
Constraint-basedsentence compression: An integer programming ap-proach.
In ACL.A.
P. Dempster, N. M. Laird, and D. B. Rubin.
1977.Maximum likelihood from incomplete data via the EMalgorithm.
Journal of the Royal Statistical Society.K.
Ganchev, J. Graca, and B. Taskar.
2008.
Better align-ments = better translations.
In ACL.K.
Ganchev, J. Grac?a, J. Gillenwater, and B. Taskar.2010.
Posterior regularization for structured latentvariable models.
Journal of Machine Learning Re-search.T.
Hofmann.
2001.
Unsupervised learning by probabilis-tic latent semantic analysis.
MlJ.M.
Kearns, Y. Mansour, and A. Y. Ng.
1997.
Aninformation-theoretic analysis of hard and soft assign-ment methods for clustering.
In ICML.D.
Klein and C. D. Manning.
2004.
Corpus-based induc-tion of syntactic structure: models of dependency andconstituency.
In ACL.P.
Koehn.
2002.
Europarl: A multilingual corpus forevaluation of machine translation.T.
Koo, A. M. Rush, M. Collins, T. Jaakkola, and D. Son-tag.
2010.
Dual decomposition for parsing with non-projective head automata.
In EMNLP.P.
Lambert, A.
De Gispert, R. Banchs, and J. Marino.2005.
Guidelines for word alignment evaluation andmanual alignment.
Language Resources and Evalua-tion.P.
Liang, D. Klein, and M. I. Jordan.
2008.
Agreement-based learning.
In NIPS.G.
S. Mann and A. McCallum.
2010.
Generalizedexpectation criteria for semi-supervised learning withweakly labeled data.
JMLR, 11.A.
Martins, N. A. Smith, and E. Xing.
2009.
Conciseinteger linear programming formulations for depen-dency parsing.
In ACL.A.
K. McCallum, R. Rosenfeld, T. M. Mitchell, and A. Y.Ng.
1998.
Improving text classification by shrinkagein a hierarchy of classes.
In ICML.B.
Merialdo.
1994.
Tagging text with a probabilisticmodel.
Computational Linguistics.R.
C. Moore, W. Yih, and A.
Bode.
2006.
Improveddiscriminative bilingual word alignment.
In ACL.R.
M. Neal and G. E. Hinton.
1998.
A new view ofthe EM algorithm that justifies incremental, sparse andother variants.
In M. I. Jordan, editor, Learning inGraphical Models.K.
Nigam, A. K. Mccallum, S. Thrun, and T. Mitchell.2000.
Text classification from labeled and unlabeleddocuments using EM.
Machine Learning.F.
J. Och and H. Ney.
2000.
Improved statistical align-ment models.
In ACL.F.
J. Och and H. Ney.
2003.
A systematic comparison ofvarious statistical alignment models.
CL, 29.S.
Ravi and K. Knight.
2009.
Minimized models forunsupervised part-of-speech tagging.
ACL, 1(August).K.
Rose.
1998.
Deterministic annealing for clustering,compression, classification, regression, and related op-timization problems.
In IEEE, pages 2210?2239.D.
Roth and K. Small.
2009.
Interactive feature spaceconstruction using semantic information.
In Proc.of the Annual Conference on Computational NaturalLanguage Learning (CoNLL).D.
Roth and W. Yih.
2004.
A linear programming formu-lation for global inference in natural language tasks.
InH.
T. Ng and E. Riloff, editors, CoNLL.D.
Roth and W. Yih.
2007.
Global inference for entityand relation identification via a linear programmingformulation.
In L. Getoor and B. Taskar, editors, In-troduction to Statistical Relational Learning.A.
M. Rush and M. Collins.
2011.
Exact decoding ofsyntactic translation models through lagrangian relax-ation.
In ACL.A.
M. Rush, D. Sontag, M. Collins, and T. Jaakkola.2010.
On dual decomposition and linear program-ming relaxations for natural language processing.
InEMNLP.A.
Schrijver.
1986.
Theory of linear and integer pro-gramming.
John Wiley & Sons, Inc.N.
A. Smith and J. Eisner.
2004.
Annealing techniquesfor unsupervised statistical language learning.
In ACL.V.
I. Spitkovsky, H. Alshawi, D. Jurafsky, and C. D. Man-ning.
2010.
Viterbi training improves unsuperviseddependency parsing.
In CoNLL.B.
Taskar, S. Lacoste-Julien, and D. Klein.
2005.
A dis-criminative matching approach to word alignment.
InHLT-EMNLP.N.
Ueda and R. Nakano.
1998.
Deterministic annealingem algorithm.
Neural Network.697S.
Vogel, H. Ney, and C. Tillmann.
1996.
Hmm-basedword alignment in statistical translation.
In COLING.698
