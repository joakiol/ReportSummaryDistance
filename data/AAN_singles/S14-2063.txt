Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 370?374,Dublin, Ireland, August 23-24, 2014.JU_CSE: A Conditional Random Field (CRF) Based Approach toAspect Based Sentiment AnalysisBraja Gopal Patra, Soumik Mandal, Dipankar Das and Sivaji BandyopadhyayDepartment of Computer Science & Engineering,Jadavpur University, Kolkata, Indiabrajagopal.cse@gmail.com, mandal.soumik@gmail.com,dipankar.dipnil2005@gmail.com, sivaji_cse_ju@yahoo.comAbstractThe fast upswing of online reviews and theirsentiments on the Web became very usefulinformation to the people.
Thus, the opin-ion/sentiment mining has been adopted as asubject of increasingly research interest inthe recent years.
Being a participant in theShared Task Challenge, we have developed aConditional Random Field based system toaccomplish the Aspect Based SentimentAnalysis task.
The aspect term in a sentenceis defined as the target entity.
The presentsystem identifies aspect term, aspect catego-ries and their sentiments from the Laptopand Restaurants review datasets provided bythe organizers.1 IntroductionIn recent times, the research activities in theareas of Opinion Mining/Sentiment Analysis innatural language texts and other media are gain-ing ground under the umbrella of subjectivityanalysis and affect computing1.
The reason maybe the huge amount of available text data in So-cial Web in the forms of news, reviews, blogs,chat and twitter etc.
Majority of research effortsare being carried out for the identification of pos-itive or negative polarity from the textual con-tents like sentence, paragraph, or text span re-gardless of the entities (e.g., laptops, restaurants)and their aspects (e.g., battery, screen; food, ser-vice).This work is licensed under a Creative Commons At-tribution 4.0 International Licence.
Page numbers and pro-ceedings footer are added by the organisers.
Licence details:http://creativecommons.org/licenses/by/4.0/1http://www.saaip.org/Aspect is a multinomial distribution overwords that represent a more specific topic in re-views (Jo and Oh, 2011).
For example, in case ofLaptop reviews, ?touchpad?
is considered anaspect.
Similarly, given a predefined entity, anaspect term describes a specific aspect of thatentity (e.g., for the entity ?restaurant?, ?wine?can be an aspect term).
Aspect term can be ap-peared as a single word (e.g., ?menu?)
or multi-ple words (?side dish?
).It is observed that for a particular entity, oneor more number of aspect terms can be groupedinto a single category (e.g., aspect terms?drinks?, ?main course?
belongs to the same cat-egory, ?food?
).The main goal of the Aspect Based SentimentAnalysis (ABSA) (Pontiki et al., 2014) task is toidentify the aspect terms and their categoriesfrom the given target entities as well as to identi-fy the sentiments expressed towards each of theaspect terms.
The datasets provided by theshared task organizers consist of customer re-views with human-annotations.We have participated in all of the four tasks.
Acombination of Conditional Random Field (CRF)based machine learning algorithm and rule basedtechniques has been adopted for identifying theaspect term, aspect category and their senti-ments.
We have used several features like Part ofSpeech (POS), Stanford dependency relations2,WordNet information, and sentiment lexicon(SentiWordNet3) to accomplish these tasks.The rest of the paper is organized in the fol-lowing manner.
Section 2 provides the details ofprevious works.
Section 3 provides an elabora-tive description of the data used in the task.
Fea-tures used in these experiments are described inSection 4.
The detailed setup of experimentationand analysis of the results are described in Sec-2 http://nlp.stanford.edu/software/lex-parser.shtml3 http://sentiwordnet.isti.cnr.it/370tion 5.
Finally, conclusions and future directionsare presented.2 Related WorkIt has been observed that most of the previousworks on aspect detection were based on infor-mation extraction, to find the most frequent nounphrases (Hu and Liu, 2004).
This approach isgenerally useful in finding aspects which arestrongly associated with a single noun.
But, oneprincipal disadvantage of this approach is that itcannot detect the aspect terms which are of lowfrequency and noun phrases (e.g., differentnames of dishes like Biryani, Dosa and Uttapametc.
for the aspect category, ?food?).
The pro-posed work of such problem involves semantichierarchy, rule-based or combination of both(Popescu and Etzioni 2005).
More recent ap-proaches of aspect detection are based on topicmodelling, that use Latent Dirichlet Allocation(LDA) (Brody and Elhadad, 2010).
But, thestandard Latent Dirichlet Allocation (LDA) isnot exactly suitable for the task of aspect detec-tion due to their inherent nature of capturingglobal topics in the data, rather than finding localaspects related to the predefined entity.
This ap-proach was further modified in Sentence-LDA(SLDA) and Aspect and Sentiment UnificationModel (ASUM) (Jo and Oh, 2011).
Similarly, theidentification of focussed text spans for opiniontopics and targets were identified in (Das andBandyopadhyay, 2010).Snyder and Barzilay (2007) addressed theproblem of identifying categories for multiplerelated aspect terms appeared in the text.
Forinstance, in a restaurant review, such categoriesmay include food, ambience and service etc.
Inour task, we call them as aspect or review cate-gories.
The authors implemented the Good Griefdecoding algorithm on a corpus collected on res-taurant review4, which outperforms over the fa-mous PRank algorithm (Crammer and Singer,2001).Ganu et al., (2009) have classified the restau-rant reviews collected from City search NewYork5 into six categories namely Food, Service,Price, Ambience, Anecdotes, and Miscellaneous.Sentiment associated with each category has alsobeen identified and both the experiments werecarried out using Support Vector Machine classi-fiers.
Finally, they implemented the regressionbased model containing MATLAB regression4 http://people.csail.mit.edu/bsnyder/naacl07/5 http://www.citysearch.com/guide/newyork-ny-metrofunction (mvregress) to give rating (1 to 5) toeach review.To determine the sentiment or polarity of theaspect term and aspect category, we need a priorsentiment annotated lexicon.
Several works havebeen conducted on building emotional corpora indifferent English languages such as SentiWord-Net (Baccianella et al., 2010), WordNet Affect(Strapparava and Valitutti, 2004) (Patra et al.,2013) etc.
Among all these publicly availablesentiment lexicons, SentiWordNet is one of thewell-known and widely used ones (number ofcitations is higher than other resources6) that hasbeen utilized in several applications such as sen-timent analysis, opinion mining and emotionanalysis.Several works have been performed on the au-tomated opinion detection or polarity identifica-tion from reviews (Yu and Hatzivassiloglou,2003; Hu and Liu, 2004).
Yu and Hatzivass-iloglou (2003) has focused on characterizingopinions and facts in a generic manner, withoutexamining who the opinion holder is or what theopinion is about.
Then, they have identified thepolarity or sentiment of the fact using NaiveBayes classifier.
Hu and Liu, (2004) has summa-rized the customer review and then identified thesentiment of that review.
They have achievedpromising accuracy in case of identifying polari-ty of the reviews.3 DataThe sentences collected from the customer re-views of Restaurants and Laptops are used inthese tasks.
The training data of Restaurant re-views contains 3041 English sentences annotatedwith aspect terms and aspect categories alongwith their polarity.
The training data of Laptopreviews contains 3045 sentences annotated withaspect terms along with their polarity.
The testdata contains 800 sentences from each of the re-view sets.An example extracted from the corpus is asfollows:But the staff was so horrible to us.Here, "staff" is the aspect term and its polarityis "negative".
The aspect category is "service"and polarity of the aspect category is also "nega-tive".6 http://citeseerx.ist.psu.edu/index3714 Feature AnalysisIn general, the feature selection always playsan important role in any machine learningframework and depends upon the data set usedfor the experiments.
Based on a preliminary in-vestigation of the dataset, we have identifiedsome of the following features.
Different combi-nations of the features have also been used to getthe best results from the classification task.Parts-of-Speech (POS): the aspect terms arebasically represented by the noun phrases.
On theother hand, the POS tag plays an important rolein aspect term identification (Hu and Liu, 2004;Brody and Elhadad, 2010).
Thus, we have usedthe Stanford CoreNLP7 tool to parse each of thereview sentences to find out the part-of-speechtag of each word and included them as a featurein all of our experiments.POS Frequency: We have observed that theaspect terms surrounded by a noun or adjectiveare also denoted as aspect terms.
Therefore, wehave utilized this information in our system.
Forexample, in the phrase ?external_JJ mouse_NN?.Here the word ?mouse?
is an object and aspectterm.
The word ?external?
is also tagged as as-pect term.Before be verb: We have observed that thenouns occur before the ?be?
verbs denote theaspect terms in most of the cases.
e.g.
?The harddisk is noisy?.
Here ?hark disk?
is an aspect termand is followed by the ?be?
verb "is".Inanimate words: In case of the Restaurantand Laptop reviews, we observed that many ofthe inanimate nouns occur as aspect terms.
Wehave used the hyponym tree of RiTa.WordNet8 toidentify the inanimate words.
For example, in thefollowing sentence, the words food, kitchen andmenu are inanimate nouns occurred as aspectterms.
?The food is uniformly exceptional, with avery capable kitchen which will proudly whip upwhatever you feel like eating, whether it's on themenu or not.
?Dependency Relation for finding Object: Wehave identified the object based dependency rela-tions from parsed sentences, as we have observedthat the words occupied in such relations are rep-resented as aspect terms in many cases.
?dobj?,?obj?
and ?xobj?
are considered as the probablecandidate relations for identifying the aspect7http://nlp.stanford.edu/software/corenlp.shtml8www.rednoise.org/rita/reference/RiWordNet.htmlterms.
Here, the Stanford Parser9 has been usedto get the dependency relations.Ontology Information (Liu, 2012): We havecounted the aspect terms in the training data.
Theaspect terms occurred more than five times in thecorpus are considered during our experiments.
Atfirst, we have tested this ontology information onthe development set and observed that the aspectterms with frequency five or more also give bet-ter results in the test set.Sentiment Words: We have used the senti-ment words as a feature for the sentiment identi-fication tasks (Liu, 2012; Brody and Elhadad,2010).
Words are identified as positive, negativeor neutral using SentiWordNet10.WordNet Information: The RiTa.WordNetpackage has been used to extract different prop-erties of the words.For aspect category identification, we havematched the hypernym tree of each word withthe four categories (service, price, food, and am-bience).
If the hypernym tree does not containany of such words, we check the next level hy-pernym tree of the words derived from hypernymof previous word.
We have checked up to thesecond degree hypernym tree.
We also searchedhypernym tree of the synset of each word.Number of Sentence: It has been found thatmany reviews contain more than one sentence.Therefore, we have included the number of sen-tence as a feature based on the output of StanfordParser.
We have split the output of StanfordParser by the mark, ?
(S?.In case of our experiments, the stop words areexcluded.
Total of 329 stop words was preparedmanually.5 Experimentation and Result AnalysisWe have used the CRF++ 0.58 11 , an opensource tool for implementing the machine learn-ing framework for our experiments.
CRF is wellknown for sequence labeling tasks (Lafferty etal., 2001).
Similarly, in the present task, the as-pect terms use the context information and arerepresented in sequences.
Many of the aspectterms are multiword expressions such as ?harddisk?.
We have created different templates fordifferent subtasks to capture all the relations be-tween different sequence related features.9http://nlp.stanford.edu/software/lex-parser.shtml10http://sentiwordnet.isti.cnr.it/11http://crfpp.googlecode.com/svn/trunk/doc/index.htm372a.
Classification of Aspect TermFeatures used in case of identifying aspectterms are POS, POS Frequency, Before be verb,Inanimate word, objects of the sentence, ontolo-gy information.
We have used several rules toidentify these features.
Then, we have used theCRF++ to identify the aspect terms.
Some postprocessing techniques are also used in order toget better accuracy.
The present system identifiesonly single word aspect terms.
But it is found inthe training data that many aspect terms consistof multiple words.
Therefore, if there is a stopword in between two system identified aspectwords, the stop word is also considered as a partof the aspect term.
We have joined the aspectwords along with the stop words to form a singlebut multiword aspect terms.Precisions, Recalls and F-scores are recordedfor our system in Table 1.
The maximum F-scores achieved in the aspect term identificationtask for Laptop and Restaurant are 0.7455012and 0.84012544, respectively.
Our system per-forms better on Restaurant reviews than Laptopreviews.Laptop RestaurantPrecision 0.4938838 0.6481481Recall 0.7442396 0.8184855F-score 0.59375 0.72342515Table 1: JU_CSE system result for aspectterm identification.b.
Classification of Aspect CategoryFeatures used in this experiment are POS, De-pendency relations for object and a few semanticrelations of WordNet.
In this subtask, we havealso used aspect term knowledge as a feature.We identified the POS of the words using Stan-ford CoreNLP tool and used the words which arenot listed in our stop-word list.
The objects areidentified from the dependency relations.
Thehpernym trees of these words are searched up tosecond degree to find four aspect categories(service, price, food, and ambience).
If we don?tfind these four categories in the hypernym tree,we increase the frequency of anecdotes/ miscel-laneous category.
Frequency counts of thesematched words are listed as a feature.
The accu-racy of the system for aspect categories in theRestaurant reviews are shown in Table 2.Maximum F-score achieved in this aspect cat-egory identification is 0.8857715.
The mainproblem faced in this task was to assign the an-ecdotes/ miscellaneous category to the respectivereviews.
There are many cases in which the an-ecdotes/miscellaneous categories occurred withother categories.
In these cases, our system failsto identify the anecdotes/miscellaneous category.RestaurantPrecision Recall F-score0.7307317 0.68029064 0.7046096Table 2: JU_CSE system result for aspectcategory identification.We have also observed that every review hasat least one category.
If any word of the reviewdoes not belong to any of the four categories, weassign these reviews with anecdotes/ miscellane-ous category at the time of post processing.c.
Classification of Sentiment of Aspectterm and categoryFeatures used in these experiments are POS,Positive, Negative and Neutral words and num-ber of sentences.
Some reviews with multiplesentences contain different sentiments associatedwith different aspect terms.
This observation alsoleads to conflict sentiment.
Therefore, we havealso included the aspect term and aspect catego-ry information during sentiment identification.The accuracy of the system is given in the Table3.Accuracy?AspectTermSentimentAspectCategorySentimentLaptop 0.5321101 NaNRestaurant 0.65547705 0.6409756Table 3: JU_CSE system result for aspectterm and category sentiment identification.Our system performs moderate in case of sen-timent identification.
Mainly, the system wasbiased towards the positive tags.
It is found thatthe number of positive tags in the training datawas more as compared to others.
We have ob-served that a conflict tag occurs when an aspectterm was present as both positive and negative.As the present system identifies the sentimentbased on word level only, it was unable to detectthe conflict tags.
The feature, number of sentenc-es fails to identify the conflict tags.
Therefore,we need to find more suitable features for oursystem to improve the accuracy.3736 ConclusionIn this paper, we have presented a CRF basedsystem for identifying the aspect terms, aspectcategories and their sentiments.
We believe thatthis problem will become increasingly importantfor common people.
This task will not only beuseful to common shoppers, but also crucial toproduct manufacturers and restaurateurs.Overall accuracies of our system were moder-ate.
In future, we will include more suitable fea-tures to improve accuracy of our system.
We alsointend to explore different machine learning al-gorithms for these tasks in future.ReferenceBenjamin Snyder and Regina Barzilay.
2007.
Multi-ple Aspect Ranking Using the Good Grief Algo-rithm.
In Proceedings of the Human LanguageTechnologies: The Annual Conference of the NorthAmerican Chapter of the Association for Computa-tional Linguistics (NAACL-HLT 2007), pp.
300-307.Bing Liu.
2012.
Sentiment Analysis and OpinionMining.
Synthesis Lectures on Human LanguageTechnologies 5, no.
1 (2012): 1-167.Braja G. Patra, Hiroya Takamura, Dipankar Das,Manabu Okumura, and Sivaji Bandyopadhyay.2013.
Construction of Emotional Lexicon UsingPotts Model.
In Proceedings of the 6th Internation-al Joint Conference on Natural Language Pro-cessing (IJCNLP-2013), Nagoya, Japan, pp.
674?679.Carlo Strapparava, and Alessandro Valitutti.
2004.WordNet Affect: an Affective Extension of Word-Net.
In LREC, vol.
4, pp.
1083-1086.Dipankar Das and Sivaji Bandyopadhyay.
2010.
Ex-tracting emotion topics from blog sentences: use ofvoting from multi-engine supervised classifiers.
InProceedings of the 2nd international workshop onSearch and mining user-generated contents, pp.119-126.Ganu Gayatree, Noemie Elhadad, and Amelie Marian.2009.
Beyond the stars: Improving rating predic-tions using review text content.
In Proceedings ofthe 12th International Workshop on the Web andDatabases, Providence, Rhode Island.Hong Yu and Vasileios Hatzivassiloglou.
2003.
To-wards answering opinion questions: Separatingfacts from opinions and identifying the polarity ofopinion sentences.
In Proceedings of the Confer-ence on Empirical Methods in Natural LanguageProcessing (EMNLP-2013), pp.
129-136.Koby Crammer and Yoram Singer.
2001.
Prankingwith ranking.
In NIPS, vol.
14, pp.
641-647.John Lafferty, Andrew McCallum, Fernando C.N.Pereira.
2001.
Conditional Random Fields: Proba-bilistic Models for Segmenting and Labeling Se-quence Data.
In Proceedings of the 18th Interna-tional Conference on Machine Learning (ICML2001), pp.
282-289.Minqing Hu and Bing Liu.
2004.
Mining and summa-rizing customer reviews.
In Proceedings of the 10thACM SIGKDD International Conference onKnowledge Discovery and Data Mining, pp.
168-177.Ana-Maria Popescu and Oren Etzioni.
2005.
Extract-ing product features and opinions from reviews.
Inproceedings of the Human Language TechnologyConference: Conference on Empirical Methods inNatural Language Processing (HLT-EMNLP).Morristown, NJ, USA, pp.
339?346.Samaneh Moghaddam and Martin Ester.
2010.
Opin-ion digger: an unsupervised opinion miner fromunstructured product reviews.
In Proceedings of the19th ACM international conference on Informationand knowledge management, pp.
1825-1828.Samuel Brody and Noemie Elhadad.
2010.
An unsu-pervised aspect-sentiment model for online re-views.
In Proceedings of the Human LanguageTechnologies: The 2010 Annual Conference of theNorth American Chapter of the Association forComputational Linguistics (HLT-NAACL).Soo-Min Kim and Eduard Hovy.
2006.
Extractingopinions, opinion holders, and topics expressed inonline news media text.
In Proceedings of theWorkshop on Sentiment and Subjectivity in Text,pp.
1-8.Stefano Baccianella, Andrea Esuli, and Fabrizio Se-bastiani.
2010.
SentiWordNet 3.0: An EnhancedLexical Resource for Sentiment Analysis andOpinion Mining.
In LREC, vol.
10, pp.
2200-2204.Yohan Jo and Alice H. Oh.
2011.
Aspect and senti-ment unification model for online review analysis.In Proceedings of the fourth ACM internationalconference on Web search and data mining.Zhongwu Zhai, Bing Liu, Hua Xu, and Peifa Jia.2011.
Clustering product features for opinion min-ing.
In Proceedings of the fourth ACM internation-al conference on Web search and data mining, pp.347-354.Maria Pontiki, Dimitrios Galanis, John Pavlopoulos,Haris Papageorgiou, Ion Androutsopoulos, andSuresh Manandhar.
2014.
SemEval-2014 Task 4:Aspect Based Sentiment Analysis.
In Proceedingsof the 8th International Workshop on SemanticEvaluation (SemEval 2014), Dublin, Ireland.374
