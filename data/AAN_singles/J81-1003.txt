Operating Statistics forThe Transformational Question Answering SystemFred  J .
DamerauMathemat ica l  Sc iences  Depar tmentIBM Thomas  J. Watson  Research  CenterPost  Of f i ce  Box ,218York town He ights ,  New York  10598This paper presents a statistical summary of the use of the Transformational QuestionAnswering (TQA) system by the City of White Plains Planning Department during the year1978.
A complete record of the 788 questions submitted to the system that year isincluded, as are separate listings of some of the problem inputs.
Tables summarizing theperformance of the system are also included and discussed.
In general, performance of thesystem was sufficiently good that we believe that the approach being followed is a viableone, and are continuing to develop and extend the system.IntroductionNatural language question answering systems havebeen the subject of much research over approximately20 years.
In only very few cases have such systemsbeen exposed to real users trying to solve real prob-lems, another example perhaps being Krause (1979).In an attempt o see if a useful natural anguage querysystem could be built for an application which existedindependently of the research program, an approachwas made to the Planning Department of the City ofWhite Plains asking them to take part in such an expe-riment.
Their incentive was the free use of an interac-tive query facility which would allow them to exploretheir data base more freely than the batch computerfacility run by the city could do.
The remainder of thepaper describes the user environment, describes theoperation of the TQA system, and discusses the oper-ating results in the first year of operation, 1978.The User EnvironmentWhen the experiment was first being discussed, thePlanning Department had five professionals plus theservices of a consultant more or less constantly availa-ble.
The main files used for planning were the parcelfile and the geobase file, which had been converted tomachine readable form under a grant from the Depart-ment of Housing and Urban Development.
Depart-ment members were very familiar with these files, inmany instances knowing the correspondence betweencodes in the file and their English equivalents.The parcel file contained a record for each parcelof land in the city, approximately 10,000 of them,which had a taxable existence.
Each record containedthe account number, the block, the owner, the address,land use information, number of dwelling units, area,taxes, and the like.
The geobase file contained a re-cord for each city block, telling what census tract itwas in, what traffic zone, what neighborhood associa-tion, etc.
Selected summaries of these files had beenprepared by the City's computing center, and the filesthemselves had been printed in a couple of large vol-umes.
Ad hoe queries required special programs to bewritten by the computing center, with sufficient delaythat this was seldom done.
Thus, we were told thatduring the 1974 gasoline shortage, the parcel file wassearched by hand on the land use code field to findthe locations of all the gas stations so that police couldbe routed there to direct traffic.
Other uses of thefiles are apparent from inspection of the questionsasked of the system, a sample of which are given inFigure 1.Although the terminal was located in an open areaavailable to all members of the department, it turnedout that most of the questions were asked by one ofthe department members, who had been designated asour liaison.
The reason for this was never clear, butmay have simply been normal reluctance to experimentwith radically new technology on the part of the oldermembers of the department.
Other personnel didsometimes use the system, but under his sign-on code,Copyright 1981 by the Association for Computational Linguistics.
Permission to copy without fee all or part of this material is grantedprovided that the copies are not made for direct commercial dvantage and the Journal reference and this copyright notice are included onthe first page.
To copy otherwise, or to republish, requires afee and/or specific permission.0362-613X/81/010030-13501.0030 American Journal of Computational Linguistics, Volume 7, Number 1, January-March 1981Fred J. Damerau Operating Statistics for the Transformational Question Answering SystemWhere are the parcels with a LUC of  641 ?What single fami ly houses in Fisher H i l l  haveexemptions greater than $0 ?How many two fami ly houses are there in theOak Ridge Residents Assn.
?Who owns the parcels in subplanning area 7.60 ?Where are the churches on North Street ?What parcels on Stevens St. have a LUC of 116 ?What parcel in ward 1 does c i ty  own ?Pr int  the parcel area of the LUC'S 300 - 399 !What is the assessment of the parcels in theBat t le  H i l l  Assn.
having more than 3 dwell ing units ?Where is Mar t in ' s  parcel ?Where are the apartment dwell ings which have more than 50units which are more than 6 stor ies  high on Lake St. ?Where is the Calvary Bapt ist  Church parcels ?Where is parcel 50550006401 ?What propert ies does Longo own ?Where are the apartment bui ldings having lessthan 8401 sq f t  ground f loor  area ?Figure 1.
Example inputs to TQA.so that the actual user for any question cannot bedetermined from the log in most cases.
During thecourse of the experiment, a new planning director wasappointed, who changed the mission of the departmentsomewhat.
The result was that members of the plan-ning department did fewer of the conventional plan-ning activities than formerly, with results that are ap-parent in the statistics that follow.The TQA SystemThe TQA system, originally named REQUEST,  hasbeen under development for some time at the IBMThomas J. Watson Research Center.
An experimentalapplication using business statistics had been quitesatisfying.
For the White Plains application, majoradditions were made to the lexicon, new grammar ulesextending coverage were written, a new component forinterfacing the grammar and a data base was devel-oped, and an interface was built to an existing database management system, the RSS.
The system wasinstalled in White Plains late in 1977 for final debug-ging, and turned over to the planners at the beginningof 1978.
It was disconnected at the end of 1979 part-ly for legal reasons and partly because we felt littlenew could be learned by leaving it there.A generalized flow diagram of the TQA system isgiven in Figure 2, and an example of processing inFigures 3a-g.
The structures printed in Figure 3a area bracketed terminal string representation of structureswhich are stored and manipulated as trees by the proc-essing programs.
The trees, together with their associ-ated complex features, for the example are shown inFigures 3b-g.
These structures are the outputs at simi-I nputlIIPreprocessor( < .
.
.
.
.
.
.
.
.
.
Lexiconl\[ L i s t  of  lex ica l  treesi.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.ITransformational parserl < .
.
.
.
Str ing transformations.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.lI L i s t  of  treesl.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.IContext free parserl < .
.
.
.
.
.
Context f ree phrase.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
s t ructure  ruleslr L i s t  of  surface treesi.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.ITransformational parserl < .
.
.
.
Inverse transformational.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
grammarJJ Underlying s t ructure(s )l. .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.ITransformational parserl < .
.
.
.
Data base spec i f i c. .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
t ransformational  rulesII Query s t ructure(s )I. .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.ISemantic interpreter J  < .
.
.
.
.
Semantic rules.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
< - - Ii lI Logical form(s)l l. .
.
.
.
.
.
.
.
.
.
IIEvaluator l  < .
.
.
.
.
.
.
.
.
.
.
.
Data baseIiAnswerFigure 2.
Flow diagram of TQA.larly named points of the flow diagram in Figure 2.Input from an IBM 3275 display station is fed tothe preprocessor, which segments the input characterstring into words and performs lexical lookup.
Theprocess of lookup is complicated somewhat by a provi-sion for synonym and phrase replacement.
Words like"car" and "automobi le" are changed to auto , andstrings like "gas station" are frozen into single lexicalunits.
The output from the lexical lookup is a list oftrees, each tree containing part-of-speech information,syntactic features and semantic features, as required.A description of the lexical component, now obsoleteAmerican Journal of Computational Linguistics, Volume 7, Number  1, January-March 1981 31Fred J. Damerau Operating Statistics for the Transformational Question Answering SystemTYPE NEXT QUESTION.Where are the gas stations in traf f ic  zone 579 ?STRING TRANSFORMATIONS:((AT ((WH SOME) (PLACE X11))) BE THE((GAS_STATION =$17) X4) IN (TRAFFIC_ZONE 579) ?
)SURFACE STRUCTURES:I.
((AT ((WH SOME) (PLACE X\]I))) BE (THE(((GAS_STATION =$17) X4) (IN (TRAFFIC_ZONE 5792.
((AT ((WH SOME) (PLACE X11))) BE (THE((GAS STATION =$17) X4)) (IN (TRAFFIC_ZONE 579UNDERLY I NG STRUCTURES :I.
(BD LOCATED (THE (((GAS STATION =$17) X4)(* BD LOCATED X4 (TRAFFIC ZONE 579) BD *)))((WH SOME) (PLACE X11)) BD)QUERY STRUCTURES:1.
(BD ADDRESS ((WH SOME) (THING Xll))(THE (((GAS STATION 553) X4)(* BD TRAFFIC ZONE 579 X4 BD *))) BD)LOGICAL FORM:(setx 'Xll'(foratleast @I 'X63(setx 'X4'(and(testfct '@579'('TRAFZ X4 '@1976)'= )(testfct '0553'('LUC X4 '@1976)' : ) ) )' ( testfct X11'('ADDRESS X63 '@1976)' : ) ) )ANSWER:ADDRESS19762 06300 02000 122 S LEXINGTON AV2 06600 00100 101W POST RD2 05500 09300 102 W POST RD2 07100 03300 109 W POST RD2 07100 02900 115 W POST RD))??
)Figure 3a.
Short trace of example question showing major interme-diate structures.in its detail but still valid in main outline, is given inRobinson (1973).
Without going into great detail, onecan see in Figure 3b that "gas station" and "trafficzone" have been made into single units.
The node=$17 in the entry for gas station is a macro standingfor a bundle of semantic features.
Many of the fea-ture names should be obvious, but, e.g., PL stands for"place", PAG for parcel aggregate, i.e., an aggregateof separate parcels, and CINS for "cardinal insertion',i.e., can be followed by a cardinal number.
( (where( ((RP ((+ WH) (+ LOC)))((NOM)((NOUN ((+ REL) (- HU) (+ PL)))((INDEX ((- CONST)))( (xo) ) )  ) ) ) ) )(are( ((BAUX ((- PAST) (- SG)))( (BE) ) )  ) )(the(((gET) ( (THE) ) ) ) )(gas_station(((NOM)((NOUN ((- HU) (- SG) (+ PL) (+ SV)))((v)((v) ((GAS STATION)))((=S17)))((INDEX ((- CONST)))) ) ) ) )(in(((PREP) ( ( IN) ) ) ) )( traf f ic  zone(((NOM)((NOUN ((- HU) (+ SG) (+ PL) (+ PAG) (+ GEO)))((V ((+ OGEN) (+ POBJ)))((TRAFFIC ZONE)) )((INDEX ((- CONST) (+ CINS)))) ) ) ) )(579( ((VADJ ((+ ADJ) (+ CARD) (+ D3)))( (579) ) )  ) )(?
( ((PUNCT ((+ QUES)))((?)))
) ) )Figure 3b.
List of lexical trees.The list of lexical trees is input to a set of stringtransformations, described in Plath (1974).
Thesetransformations operate on adjacent lexical items todeal with patterns of classifiers, ordinal numbers,stranded prepositions, and the like.
The effect of thisphase is to reduce the number of surface parses andthe amount of work done in the transformational cy-cle.
Referring to Figure 3c, note that "579" has beenincorporated with "traffic zone" under a single node,PR OPNOM.The resulting list of trees is input to a context freeparser, which produces a set of surface trees.
In theexample, two surface trees are produced, shown inFigures 3d and 3e.
The trees differ in the point ofattachment of the phrase "in traffic zone 579".
Instructure 1, it is attached to the NP "the gas station",and in structure 2 it is directly under the S node.The recognizer attempts to find an underlyingstructure for each surface tree (Plath 1973, 1976).Typically, only one of a set of surface trees will resultin an underlying structure.
In the example, the struc-32 American Journal of Computational Linguistics, Volume 7, Number 1, January-March 1981Fred J. Damerau Operating Statistics for the Transformational Question Answering System((AT ((WH SOME) (PLACE XII)))  BE THE((GAS_STATION :$17) X4) IN (TRAFFIC ZONE 579) ?
)((ST)((PP)((NSPREP) ((AT)))((NP)((NOM)((V ((+ ADJ) (+ QUANT)))((WH))((SOME)))((NOM)((NOUN ((+ SG) (- HU) (+ PL)))((V) ((PLACE)))((INDEX ((- CONST)))( (X l l ) ) )  ) ) ) ) )((BAUX ((- PAST) (- SG)))((BE)))((DET) ((THE)))((NOM)((NOUN ((- HU) (- SG) (+ PL) (+ SV)))((v)((V) ((GAS STATION)))((=$17)))((INDEX ((- CONST)))( (X4)) )  ) )((NSPREP) ((IN)))((PROPNOM)((NOUN ((- HU) (+ SG) (+ PL) (+ PAG) (+ GEO)))((V ((+ OGEN) (+ POBJ)))((TRAFFIC ZONE)) )((INDEX ((+ CONST)))((VADJ ((+ ADJ) (+ CARD) (+ D3)))((579)))  ) ) )((PUNCT ((+ QUES)))( (? )
) )  )Figure 3c.
List of trees after  str ing t ransformat ions .ture in which the prepositional phrase was attached to"gas station" survives.
The underlying structures aresimilar to those proposed under the variant of trans-formational grammar called generative semantics.
Thisis not the place to defend that particular theory or itsuse on the TQA system; suffice it to say that a consid-erable body of grammatical work on English has beendone in a style compatible with this theory.
To simpli-fy, every S in the underlying structure has a predicateand some number of noun phrase a\[guments.
Thenoun phrases may dominate imbedded S's.
In theexample, the top level predicate is LOCATED witharguments of "gas station" and "some place".
TheNP for "gas station" dominates an S which also has amain predicate of LOCATED and arguments of "X4",i.e., the same index as that for "gas station", and"traffic zone 579", i.e., the gas station located in traf-fic zone 579.
Notice that the parser has supplied bothI .
(CAT ((WH SOME) (PLACE Xl I ) ) )  BE (THE(((GAS_STATION =$17) X4) (IN (TRAFFIC_ZONE 579)))) ?
)(($1)((PP)((NSPREP) ((AT)))((NP)((NOM)(iV ((+ ADJ) (+ QUANT)))((WH))((SOME )((NOM)((NOUN (+ SG) (- HU) (+ PL)))((V) (PLACE)))((INDEX ((- CONST)))( (X l i ) ) )  ) ) ) ) )((BAUX ((- PAST) (- SG)))((BE)))((NP)((DETX)((DET) ((THE))))((NOMX)((NOMZ)((NOM)((NOUN ((- HU) (- SG) (+ PL) (+ SV)))((v)((V) ((GAS_STATION)))((=$17)))((INDEX ((- CONST)))((x4))) ) )((Z1)((PP3X)((PP)((NSPREP) ((IN)))((RPX)((NP)((PROPNOM)((NOUN ((- HU) (+ SG) (+ PL)(+ PAG) (+ GEO)))((V ((+ OGEN) (+ POBJ)))((TRAFFIC ZONE)) )((INDEX ((+ CONST)))((VADJ ((+ ADd) (+ CARD) (+ D3)))( (579) ) )  ) ) ) ) ) ) ) ) ) ) )((PUNCT ((+ QUES)))( ( ? )
) )  )Figure 3d.
Surface st ructure  tree 1.instances of " located".
A fuller explanation is givenin Plath (1973, 1976).The data base has no predicate, i.e., column head-ing, named "located".
Even if it did, the two LO-CATEDs in the underlying structures are different,one for address and one for traffic zone.
The underly-ing structure is designed to reflect the linguistic struc-ture of the query, but, as in this case, that structureAmerican Journal of Computational Linguistics, Volume 7, Number 1, January-March 1981 33Fred J. Damerau Operating Statistics for the Transformational Question Answering System2.
((AT ((WH SOME) (PLACE X11))) BE (THE((GAS STATION =$17) X4)) (IN (TRAFFIC ZONE 579)) ?
)(($1)((PP)((NSPREP) ((AT)))((NP)((NOM)((V ((+ ADJ) (+ QUANT)))((WH))((SOME)))((NOM)((NOUN ((+ SG) (- HU) (+ PL)))((V) ((PLACE)))((INDEX ((- CONST)))( (x11) ) )  ) ) ) ) )((BAUX ((- PAST) (- SG)))((BE)))((NP)((DETX)((DET) ((THE))))((NOMX)((NOM)((NOUN ((- HU) (- SG) (+ PL) (+ SV)))((v)((V) ((GAS_STATION)))((=S17)))((INDEX ((- CONST)))((X4)))  ) ) ) )((PP4X)((PP)((NSPREP) ((IN)))((RPX)((NP)((PROPNOM)((NOUN ((- HU) (+ SG) (+ PL) (+ PAG) (+ GEO)))((V ((+ OGEN) (+ POBJ)))((TRAFFIC_ZONE)))((INDEX ((+ CONST)))((VADJ ((+ ADJ) (+ CARD) (+ D3)))( (579)))  ) ) ) ) ) ) )((S2PCX)((PUNCT ((+ QUES)))( ( ? )
) )  ) )Figure 3e.
Surface structure tree 2.may not match a particular data base organization.There are many approaches one could take to makethis match.
We have chosen to implement he match-ing function as a separate transformational componentin the grammar (Damerau 1977).
The underlyingstructure itself is therefore input to the transforma-tional recognizer, using a (small) set of grammar ulestailored to a specific data base and produces a querystructure.
Query structures are similar to underlyingstructures in form, but reflect the particular meaningI .
(BD LOCATED (THE (((GAS_STATION :S17) X4)(* BD LOCATED X4 (TRAFFIC ZONE 579) BD *)))((WH SOME) (PLACE X11)) BD)(($I ((- PAST) (+ WH) (+ QUES) (+ TOP)))((BD))((V ((+ ADJ) (+ EN) (+ LOC) (+ TEMP)(+ PSUBJ) (+ POBJ)))((LOCATED)))((NP)((DET) ((THE)))((NOM)((NOM)((NOUN ((- HU) (- SG) (+ PL) (+ SV)))((v)((V) ((GAS STATION)))( ( :$17)) )((INDEX ((- CONST)))((X4)))  ) )((Si)((BD))((V ((+ ADd) (+'EN) (+ LOC) (+ TEMP)(+ PSUBJ) (+ POBJ)))((LOCATED)))((NP)((NOM)((NOUN ((- HU) (- SG) (+ PL) (+ SV)))((INDEX ((- CONST)))( (X4)) )  ) ) )((NP ((+ IN) (+ LOC)))((NOM)((NOUN ((- HU) (+ SG) (+ PL)(+ PAG) (+ GEO)))((V ((+ OGEN) (+ POBJ)))((TRAFFIC ZONE)) )((INDEX ((+ CONST)))(iV ((+ ADJ) (+ CARD) (+ D3)))( (579)))  ) ) ) )BD)) ) ) )( NP ((+ AT) (+ LOC)))((NOM)((V ((+ ADJ) (+ QUANT)))((WH))((SOME)))((NOM)((NOUN ((+ SG) (- HU) (+ PL)))((V) ((PLACE)))((INDEX ((- CONST)))( (X l l ) ) )  ) ) ) )( (BD)))Figure 3f.
Underlying structure.constraints resulting from the format and content of agiven data base.
In Figure 3g, one can see that thefirst instance of LOCATED has been changed to the34 American Journal of Computational Linguistics, Volume 7, Number 1, January-March 1981Fred J. Damerau Operating Statistics for the Transformational Question Answering System1.
(BD ADDRESS ((WH SOME) (THING Xl l ) )(THE (((GAS STATION 553) X4)(* BD TRAFFIC ZONE 579 X4 BD *))) BD)(($I ((- PAST) (+ WH) (+ QUES) (+ TOP)))((BD))((V ((+ ADJ) (+ EN) (+ LOC) (+ TEMP)(+ PSUBJ) (+ POBJ)))((ADDRESS)))((NP ((+ AT) (+ LOC)))((NOM)((V ((+ ADJ) (+ QUANT)))((WH))((SOME)))((NOM)((NOUN ((+ SG) (- HU) (+ PL)))((V) ((THING)))((INDEX ((- CONST)))((Xll))) ) ) ) )((NP)((DET) ((THE)))((NOM)((NOM)((NOUN ((- HU) (- SG) (+ PL) (+ SV)))(V)((V) ((GAS_STATION)))((LUC) ((553))))(INDEX ((- CONST)))( (X4)))  ) )((s1((BD))((V ((+ ADJ) (+ EN) (+ LOC) (+ TEMP)(+ PSUBJ) (+ POBJ)))((TRAFFIC ZONE)) )((NP ((+ IN) (+ LOC)))((NOM)((NOUN ((- HU) (+ SG) (+ PL)(+ PAG) (+ GEO)))((INDEX ((+ CONST)))((V ((+ ADJ) (+ CARD) (+ D3)))((579)))  ) ) ) )((NP)((NOM)((NOUN ((- HU) (- SG) (+ PL) (+ SV)))((INDEX ((- CONST)))( (x4) ) )  ) ) )((BD))) ) )((BD)))Figure 3g.
Query structure.predicate ADDRESS and the second instance to thepredicate TRAFFIC ZONE.The query structure tree is processed by a Knuth-style semantic interpreter (Petrick 1977), producing alogical form.
A logical form can best be thought of, inour context, as a retrieval expression which is to beevaluated, producing an answer to the English inputquery.
Referring to Figure 3a, the logical form can beread as:Find the set of thiags X l l  such that for atleast l of the things X63 in the set of thingsX4 where the traffic zone of X4 is 579 andthe LUC (land use code) is 0553, (viz., theset of account numbers having both theseproperties), the address of X63 is X11.The process of answer extraction from the database is accomplished by a combination of LISP andPL / !
programs (Damerau 1978), and an experimentalrelational data base management system called Rela-tional Storage System (RSS) (Astrahan, et al, 1976).The RSS provides the capability to generate a database of n-ary relations, with indexes on any field ofthe relation, and low-level access commands likeOPEN, NEXT, CLOSE, with appropriate parameters,to retrieve information from such a data base.
Thisparticular data base had just one relation of 40 col-umns.
The LISP programs examine the logical form toestablish relationships between variables and to gener-ate requests to the data base component to find itemswith specified properties.
In the example, one retriev-al request would find the qualifying account numbers,i.e., the X4s, and a second request would find theaddresses of those account numbers.Notice that the logical form simply specifies a setof addresses as the answer.
This is clearly unsatisfac-tory, and the data base interface program supplies theaccount number for each address as part of the an-swer.
The long numbers in the answer are the parcelidentifiers, (ward-block-lot) referred to above as ac-count numbers and sometimes called lot numbers.All the processing modules are under the control ofa driver module which maintains communication withthe user, calls the processors in the correct sequence,and tests for errors.Usage Stat is t icsThe statistics presented below are not based on aconstant system.
When a problem was discovered inthe course of operation, an attempt was usually madeto change the system so as to make the problem queryrun successfully.
This was not always possible, but agreat many changes were incorporated into the systemduring the course of the year.
An attempt o compen-sate in part for the effect of this situation on the sta-tistics was made by rerunning all the sentences whichfailed during the year with the system in use in May,1979.
The results of this run are incorporated into theappendices.
An additional source of contaminationresulted when a user needed an answer to a questionand none of his attempts was successful.
He mightthen telephone one of the system developers and askAmerican Journal of Computational Linguistics, Volume 7, Number 1, January-March 1981 35Fred J. Damerau Operating Statistics for the Transformational Question Answering SystemTable I.
Number of events.JAN FEB MAR APR MAY dUN JUL AUG SEP OCT NOV DEC TOTALQUERIES 45 161 180 52 45 114 87 31 32 20 13 8 788COMPLETED 18 92 127 44 28 66 68 22 17 17 9 5 513LOOKUP FAILURES 3 19 17 5 10 19 31 8 I 2 3 I 119PARSING FAILURES 14 26 38 4 4 29 11 7 11 0 3 0 147NOTHING IN DATA BASE 12 8 12 3 1 2 13 5 I I 3 0 61ABORTED 3 9 14 2 5 9 4 2 I 2 1 I 53USER COMMENTS 9 10 16 7 3 10 21 11 3 1 4 1 96USER MESSAGES 0 3 0 0 0 3 4 I 0 0 0 0 11OPERATOR MESSAGES 14 6 10 2 2 0 2 3 2 0 4 0 45PROGRAM ERRORS I 12 9 1 6 5 0 0 1 1 0 3 39USER CANCELLED I 5 I 1 2 5 4 0 2 0 0 0 21LEXICAL CHOICE 6 32 11 4 10 31 6 3 1 11 3 I 119Table II.
Percentage of events to number of queries.JAN FEB MAR APR MAY dUN JUL AUG SEP OCT NOV DEC TOTALCOMPLETED 40.0 57.1 70.6 84.6 62.2 57.9 78.2 71.0 53.1 85.0 69.2 62.5 65.1LOOKUP FAILURES 6.7 11.8 9.4 9.6 22.2 16.7 35.6 25.8 3.1 10.0 23.1 12.5 15.1PARSING FAILURES 31.1 16.1 21.1 7.7 8.9 25.4 12.6 22.6 34.4 0.0 23.1 0.0 18.7NOTHING IN DATA BASE 26.7 5.0 6.7 5.8 2.2 1.8 14.9 16.1 3.1 5.0 23.1 0.0 7.7ABORTED 6.7 5.6 7.8 3.8 11.1 7.9 4.6 6.5 3.1 10.0 7.7 12.5 6.7USER COMMENTS 20.0 6.2 8.9 13.5 6.7 8.8 24.1 35.5 9.4 5.0 30.8 12.5 12.2USER MESSAGES 0.0 1.9 0.0 0.0 0.0 2.6 4.6 3.2 0.0 0.0 0.0 0.0 1.4OPERATOR MESSAGES 31.1 3.7 5.6 3.8 4.4 0.0 2.3 9.7 6.3 0.0 30.8 0.0 5.7PROGRAM ERRORS 2.2 7.5 5.0 1.9 13.3 4.4 0.0 0.0 3.1 5.0 0.0 37.5 4.9USER CANCELLED 2.2 3.1 0.6 1.9 4.4 4.4 4.6 0.0 6.3 0.0 0.0 0.0 2.7LEXICAL CHOICE 13.3 19.9 6.1 7.7 22.2 27.2 6.9 9.7 3.1 55.0 23.1 12.5 15.1for a suggestion.
If that suggestion worked, this wouldinflate the percentage of success omewhat.The TQA system incorporates two logging facili-ties.
One of them is a verbatim record of all outputthat appeared on the user terminal.
The other is amuch more comprehensive trace of the system flowwhile it processed each question.
The primary use ofthe second trace was to allow us to isolate the natureof the problems which arose with a view to correction.This file, however, contains much interesting detailabout the amount of computer time, (as opposed toelapsed time), used in each processing step, the num-ber of intermediate structures created, indications asto exactly which step caused a failure, and the like.Unfortunately,  the second file was not originallymeant to be amenable to machine processing, and itsformat was changed a few times during the course ofthe year.
In addit ion, when the computing systemfailed, this second file was sometimes lost, althoughthe basic log file seldom was.
As a result, the statis-tics in the tables may be in error by a percentage pointor two.
In any case, the error is not sufficiently largeto affect any of the major conclusions, which are qual-itative at best.Table I lists the raw numbers, by month and to-taled for the year, for a number of the events whichoccur in system operation.
Percentages for each eventrelative to the number of queries are given in Table II.QUERIES refers to user inputs terminated by aquestion mark or exclamation point.
COMPLETED isthe number of queries which resulted in access to thedata base and a resulting response to the user.LOOKUP FA ILURES is the number of times the usertyped a word which was not in the lexicon and wasnot capitalized.
Such words were displayed back, withthe option of changing the word entered or entering anentire new question.
PARSING FA ILURE means thatthe system did not reach the point of producing aquery structure.
NOTHING IN DATA BASE meansthat a logical form was generated and a query issuedto System/R,  but nothing satisfied the query.
Thiscould happen for a variety of reasons, including anerroneous parse, a wrong logical form, a mistake in theprogram which generated the search request, or a realcase of missing data.
Detai led analysis of each casewould be required to be sure what proport ion fell intoeach category.The other categories are more or less self-explanatory.
ABORTED is an indication that query36 American Journal of Computational Linguistics, Volume 7, Number 1, January-March 1981Fred J. Damerau Operating Statistics for the Transformational Question Answering Systemprocessing did not reach a normal termination, usuallybecause of a machine failure, i.e., hardware or systemsoftware, but sometimes because of a problem in theTQA code.
The USER COMMENTS line comes froma feature we had included in the system in an attemptto collect on-going user reaction to system behavior.At the end of each question, before producing themessage "TYPE NEXT QUESTION" ,  we displayed arequest for comment on the preceding question.
Itturned out that users found this something of a nui-sance, since mostly they were satisfied with the an-swer, so we made an early change to the terminal readprogram such that a reply to the prompting messagefor comments which ended in "?"
would be treated asa null comment and another question, in effect makingthe comment optional.
Student users took the promptsomewhat more seriously than the regular employeesand made more comments.
The two MESSAGE cate-gories refer, to a system facility enabling a user to sendmessages to the TQA operator and the reverse.
Onecan see that it is usually used by the TQA operator asa somewhat more convenient means than the tele-phone for advising a user about the nature of a prob-lem or for warning that the system was to be stopped,and the like.
PROGRAM ERROR is an error in theTQA program which was detected and caused a queryto abort but left the system able to accept anotherinput.
There is also a facility, tabulated under USERCANCELLED,  allowing a user to cancel a query atany time by pressing a special key on the terminalkeyboard.
This is used when the user realizes he madea mistake or when processing seems to be going on toolong.
The category LEX ICAL  CHOICE indicateshow often the system asked the user to clarify themeaning of a word.
For example, "area" can be"parcel area" or "floor area" and if the system cannotdisambiguate by the context, the user is shown the twochoices and asked to "Type A or B".
The most fre-quent ambiguities have to do with duplication ofnames for streets, neighborhoods and schools.As can be seen in line 1 of Table I, there was adrastic fall-off in usage in the latter part of the year.This has two primary causes.
In the first place, theplanning office was being rebuilt during the period andthe work space was often disrupted.
The major cause,as mentioned above, was a re-orientation of the plan-ning department activities by a newly appointed irec-tor.
The department members now spend the majorpart of their time on administrative activities; planningactivities, like land analyses and drafting of new zon-ing districts, are now carried out by off-premises con-sultants who do not have ready access to the terminal.From the latter part of 1978 through 1979, the systemwas used only intermittently by the planners, whooccasionally needed some of the basic land recorddata, and by others, like the fire department,  whowanted to have a list of tall buildings.There is an obvious rise in USER COMMENTS,LOOKUP FAILURES,  and PARSING FA ILURESduring June, July, and August.
During this period, theplanning department had a number of student internswho were using the system, sometimes in a play mode.It is easy to understand that new users exploring thesystem would have more than an ordinary number ofparsing failures.
The increase in lookup failures is alittle more puzzling, although part of the increase hasthe same cause, i.e., some of the questions were out-side the domain, and consequently the words usedwere not in the lexicon.The large percentage for the NOTHING IN DATABASE category in January comes in large part fromtwo queries which had four underlying structures, allof which resulted in the answer "NOTHING IN THEDATA BASE."
This was caused by a problem in thegrammar which has since been corrected.
Some of theother instances of this message during the year result-ed from an inadvertently, and unfortunately, successfulexample of subtle user training or conditioning.
Wediscovered that users tended to respond to the systemby echoing, sometimes exact ly  and sometimes, onlypartially, what the system had printed to them, nomatter if their initial phrasing had been accepted ornot.
Some input word sequences are treated as phras-es by the strategy of scanning an input query against aphrase lexicon first before looking in the regular lexi-con.
An entry like "gas station" came out of thephrase lookup represented as "GASSTAT ION"  forpurposes of lexical lookup.
The users would some-times input that, or some variant like "Gas Station",which would be taken as a proper name.
The resultwould then be interpreted as a query having to do withan owner named "Gas Station".
We now echo whatthe user has typed, or some variant which will be ac-ceptable if typed.
Most of the instances of the catego-ry NOTHING IN DATA BASE really are the responseto a request for information which is not in the database.
Many of these are requests for informationabout people who are not owners of property, orabout addresses which are not legitimate.Apart from the drastic fall in usage at the end ofthe year discussed above, there appears not to be anytrend in any of the other measures of system opera-tion.
The sequence of peaks and valleys may be char-acteristic of systems like this, or may simply resultfrom insufficient ime for the system to settle down.Operating CharacteristicsCumulative statistics for the system operating char-acteristics are found in Tables II I  and IV and Figures4 through 8 for each system component.
The histo-grams have a Poisson-like shape, with a single peakAmerican Journal of Computational Linguistics, Volume 7, Number 1, January-March 1981 37Fred J. Damerau Operating Statistics for the Transformational Question Answering SystemTable III.
Query / log ica l  fo rm t ime - No.
of  s t ructures .1 2 3 4 5 >TOTAL YEARQUERY STRUCTURE TIME (SEC) 497 53 22 16 3LOGICAL FORM TIME (SEC) 536 24 4 2 12NO.
OF SURFACE STRUCTURES 470 146 38 9 3NO.
OF UNDERLYING STRUCTURES 581 7 0 2 0NO.
OF QUERY STRUCTURES 581 7 0 2 0NO.
OF LOGICAL FORMS 571 5 0 2 0NO.
OF ANSWERS 513 0 0 0 0Table IV.
Query / log ica l  fo rm t ime - No.
of  s t ructures  by  month .1 2 3 4 5>MAYQUERY STRUCTURE TIME (SEC) 26 3 7 0 0LOGICAL FORM TIME (SEC) 29 5 2 0 0NO.
OF SURFACE STRUCTURES 6 26 5 3 0NO.
OF UNDERLYING STRUCTURES 36 0 0 0 0NO.
OF QUERY STRUCTURES 36 0 0 0 0NO.
OF LOGICAL FORMS 36 0 0 0 0NO.
OF ANSWERS 28 0 0 0 0JUNEQUERY STRUCTURE TIME (SEC) 35 18 10 7 2LOGICAL FORM TIME (SEC) 64 4 2 2 0NO.
OF SURFACE STRUCTURES 34 31 21 3 0NO.
OF UNDERLYING STRUCTURES 72 0 0 0 0NO.
OF QUERY STRUCTURES 72 0 0 0 0NO.
OF LOGICAL FORMS 72 0 0 0 0NO.
OF ANSWERS 66 0 0 0 0JULYQUERY STRUCTURE TIME (SEC) 58 10 I I 0LOGICAL FORM TIME (SEC) 69 O 0 0 0NO.
OF SURFACE STRUCTURES 62 12 1 0 0NO.
OF UNDERLYING STRUCTURES 70 0 0 0 0NO.
OF QUERY STRUCTURES 70 0 0 0 0NO.
OF LOGICAL FORMS 69 0 0 0 0NO.
OF ANSWERS 68 0 0 0 0QUERIES2001501001501XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXlXXXXXXXXXXXXXXXXXX XXXXX XXX X51 101 151 201 251 301>MINUTESFigure 4.
E lapsed  t ime - Tota l .QUERIES2501IIxIXand a long tail.
(The apparent spike at the right-handend of the "Number of lines in answer" is not real;that point is really "answers of 50 lines or more".The right-most point of all the histograms hould beread in a similar way, i.e., as including the total of allvalues in the remainder of the tail.
)Tables III and IV contain two kinds of information.The first two lines under "Total Year" in Table II I  andunder each month in Table IV show the number ofqueries whose machine processing time required thenumber of seconds shown by the column head.
Thus,in Table III, 4 queries took 3 seconds of processingtime to generate a logical form.
A table form wasused for this information because a histogram for"time to produce a query structure" and "time toproduce a logical form" would have been simply aspike.
The other lines in the tables are counts, so that,IX501XIX XIX X XIXXXX XXX XIXXXX XXXXXXXXXXXXXXXXXXXXXXXX X X XX XX X XX.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.51 101 151 201 251 301 351 401 451 501Figure 5.
Number  of  l ines in answer  - Tota l .again in Table III, 7 queries had 2 underlying struc-tures.From the first two lines of Table III, it can be seenthat neither the query structure nor the logical formaccount for very much of the processing time, mostly38 American Journal of Computational Linguistics, Volume 7, Number 1, January-March 1981Fred J. Damerau Operating Statistics for the Transformational Question Answering SystemQUERIES2001X150 XXXXX100 XXXXXXXXXXXXXXXXXXX501XXXXXXI XXXXXXXI XXXXXXXI XXXXXXXXXXIXXXXXXXXXXXXXXXXXX XXX XXXXX.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.51 101 151 201 251 301>SECONDSQUERIESI4001IIIXIX3501XIXIX50IXIxIXXIXXXXIXXXXXXXXXXXXX x x x x xxxx x. .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.51 101 151 201 251 301>SECONDSFigure 8.
Answer processing - Total.Figure 6.
Generation of surface structures - Total.QUERIESI1501100xxxxxxxxxxxxxxxxxxxxxx501 xxxxxI xxxxxxxI xxxxxxx xxIXXXXXXXXXXXIXXXXXXXXXXXXXXXXX XXXXX XXXXXX xx x. .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.51 lOl 151 201 251 301 351 4Ol 451 501>SECONDSFigure 7.
Transformational p rsing - Total.less than 1 second, and Figure 8 shows that answerprocessing, i.e., data base lookup and printing, is alsonot a major time user.
From Figures 6 and 7 it can beseen that surface structure parsing, which includes thetime for string transformations, and transformationalprocessing both typically consume around 4 seconds.Therefore, total machine time for a typical query isaround 10 seconds, although extreme cases can takemuch longer.From Figure 4, it can be seen that elapsed time fora query is around 3 minutes, although there is again along tail.
Elapsed time depends primarily on machineload and user behavior at the terminal.
The computeron which the system operated was an IBM 370/168with an attached processor, 8 megabytes of memoryand extensive peripheral storage, operating under theVM/370 time-sharing system.
During business hours,there were usually in excess of 200 users logged on tothe system, so any one user received only a smallshare of the resources.
Besides queuing for the CPUand memory, this system developed queues on an IBM3850 Mass Storage System, on which the TQA database was stored.
With all delays accounted for, itcould easily take several minutes of elapsed time toaccumulate 10 or 15 seconds of CPU time.User-caused elays tend to occur when a reply isneeded to correct a lookup failure or to resolve anambiguity, and when the answer to a query requiresmore than one screen for display.
In the latter case,the display has a built in delay of up to one minute, orcan be held indefinitely by depressing a key.
The holdfeature is often used for the long displays, because theuser is writing down information from the display.American Journal of Computational Linguistics, Volume 7, Number 1, January-March 1981 39Fred J. Damerau Operating Statistics for the Transformational Question Answering SystemThe user is, of course, not concerned with his owndelays, but only with the system delay.
In order tokeep him informed of progress through the query, andgive him assurance that the computer is still operating,a CPU time clock is displayed in the lower right cornerof the screen, along with an indication of the process-ing phase being carried out at that time.
In general,these users did not become concerned with responsetime, possibly because they had no experience withother interactive computer systems.
However, if thesystem was slow, a user might well choose to look up asingle piece of information in the printed listing of thedata base rather than ask through the computer sys-tem.Figure 5 shows that most queries have a one lineanswer, but that the tail is very long.
General lyspeaking, users were interested in totals or averages ofdata fields like "dwelling units" or "parcel area" foraggregates of parcels specified by land use, neighbor-hood, census tract, and the like, often in combination.Questions of this kind are not readily answered fromthe printed copies of the parcel file, and specific pat-terns do not occur often enough to make it worthwhileto ask for a batch program to be written by the Citycomputer staff.The yearly summary statistics discussed above con-ceal the considerable variation which can be encoun-tered over shorter time periods.
Table IV shows themonthly statistics, corresponding to Table III for May,June and the more typical July.
The percentage ofqueries with more than one surface structure is clearlyvery high in May and June.
This results in longeraverage times for query structure processing and logi-cal form processing, as seen also in Table IV.
Theeffect is even more obvious in the histograms for sur-face structure processing, Figures 9-11, and underlyingstructure processing, Figures 12-14.
Inspection of thelogs for May and June shows that most of this effectresults from only a few questions, e.g., "What is thearea of the x family houses in the y zone?
", repeatedfor a number of combinations of x and y.
It happensthat one of the planners was checking figures to beincluded in a table in a large report during this period.Sequences of questions like this are, of course, of littlehelp in system development,  but do serve to buildconfidence in the utility of the system.QUERIES15I0XXXXXXXXXXXXXXX XXXX XXXX X XXXXXXX XXXX X X X XX.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.51 101 151 201 251 301>SECONDSFigure 9.
Generat ion of surface structures - May.QUERIESI0XXX XXXXX XXXXXX X XXXXXXX X XXXXXXX XX X XXXXXXXXXXX XXX XXXXXXXXXXXXX XXX X XXXXXXXXXXXXXXXXXXX XXX XXX.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.51 101 151 201 251 301>SECONDSThe Input QueriesFigure 1 given earlier shows a small selection of thequeries put to the system during 1978, to give thereader an idea of the kinds of questions asked by theusers.
Additionally, there are four lengthy appendiceswhich appear only in the microfiche supplement to thisissue of the Journal.
Appendix A presents the entireset of queries submitted to the system during 1978,(but note the caveat at the beginning regarding possi-Figure 10.
Generat ion of surface structures - June.ble missing data because of lost 10gs).
Sentences pre-ceded by a C in Appendix A were completed success-fully, but one must remember that "NOTHING INTHE DATA BASE" was counted as a successful an-swer by the data reduction program even though theremay have been some earlier problem in the query.Appendix B is a list of sentences which did not parse40 Amer ican  Journa l  of Computational Linguistics, Vo lume 7, Number  1, January -March  1981Fred J. Damerau Operat ing Stat ist ics  for the Transformat iona l  Quest ion Answer ing  SystemQUERIESIIiI301I X151 XI XI XI XI XX101 XXXI XXXXI XXXXI XXXXI XXXX5l XXXXXI XXXXXXI XXXXXXXI XXXXXXXXI XXXXXXXXX X. .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.51 101 151 201 251 301>SECONDSFigure 11.
Generation of surface structures - July.X201 XQUERIES25XXXX X/X X X X X XX XX XXX X X XX XX.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.51 101 151 201 251 301 351 401 451 501>SECONDSQUERIES15XXX X101 X XI X XI XX X XI XXX X XI XXX X X51 XXX X XI XXX X X XI XXX XX XX X XI XXXXXXXXXX X X XX XJXXXXXXXXXXXX XXXX X X XXXXXX XX X. .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.51 101 151 201 251 301 351 401 451 501>SECONDSFigure 13.
Transformational parsing - June.QUERIES201IiII151 XI XXI XXI XXXI XXX101 XXXI XXX XI XXXXXI XXXXXI XXXXX51 XXXXXI XXXXX XI XXXXX XI XXXXXXXXXX XI XXXXXXXXXXXX X. .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.51 101 151 201 251 301 351 401 451 501>SECONDSFigure 12.
Transformational parsing - May.
Figure 14.
Transformational parsing - July.Amer ican Journal  of Computat iona l  Linguist ics,  Vo lume 7, Number  1, January-March 1981 41Fred J. Damerau Operating Statistics for the Transformational Question Answering Systemat their first submission, and Appendix C is a listwhich failed for some reason other than parsing attheir first submission.
Appendix D is a list of sen-tences for which the answer was "NOTHING IN THEDATA BASE."
In most cases where this answer wasnot correct, the problem was in dealing with searcheson persons' names.
The treatment used presently isstill not completely satisfactory, but has been im-proved since the initial version.
Names in the database occur in a great variety of patterns, more than wefelt worth devising procedures to handle.
In the threelatter appendices, those sentences which are satisfacto-rily answered by the system of May 14, 1979 are pre-ceded by an X.
(Any necessary spelling corrections orambiguity resolution were supplied.)
A little over 60percent of the failing sentences are processed correctlyby this version.
As can be seen, many of the remain-ing queries are so flawed that no system should beexpected to answer them.The set of successful queries is not really indicativeof the full coverage of the system.
There are a num-ber of permissible constructions which the plannerssimply never used, so the subset is somewhat richerthan shown.
On the other hand there are large num-bers of constructions involving personal pronouns,three-argument comparatives, quantification with"each", etc., which the planners knew the system didnot handle, and which they consequently did not use.ConclusionsThe motivation for publishing this paper with itslong appendices was to make it possible for a reader tocome to some conclusion of his own regarding theutility of the TQA system or something like it in a realenvironment.
For reasons mentioned above, none ofus thinks this experiment provides a definitive test forour system or even that very strong claims about per-cent of success can be made.
For such purposes, acontrolled experiment using a fixed system is clearlynecessary, and we hope to make such a test in the nearfuture.
However, those of us working on the projectare encouraged by the results summarized here, andeven more by our conversations with the users of thesystem, who have been very positive.
Within the limi-tations established by the subset of English that thesystem can recognize, it appears that non-data proc-essing professionals can extract useful informationfrom their files with almost no training.
A number ofthe gaps in our system can certainly be plugged if wecan find the resources to work on them.Our next step will be to make the TQA system afront end to an existing formal query language system,probably SQL-based System R, developed at the IBMSan Jose Research Laboratory, a version of which hasbeen announced as an IBM Program Product for useunder the DOS/VS operating system.
Such a step willpermit us to devote all of our resources to the prob-lems of language and knowledge representation, in-stead of spending part of that effort on data manage-ment.
Beyond that, we will consider seriously thequestion of moving to different environments, both tonew situations in the city planning domain and to com-pletely different domains, without having to rewrite allor even a major portion of our base system.AcknowledgementsBesides Petrick, Plath and the author, the TQAproject currently includes Mark Pivovonsky, who hasdone the systems programming for the project.
Sincethis document summarizes one year's activity, it neces-sarily reflects the content of many discussions withthese individuals, and some of their opinions and in-sights on the nature of these problems are incorporat-ed herein.
The wrong ones naturally are mine.ReferencesAstrahan, M.M.
; Blasgen, M.W.
; Chamberlin, D.D.
; Eswaran, K.P.
;Gray, J.N.
; Griffiths, P.P.
; King, W.F.
; Lorie, R.A.; McJones,J.
; Mehl, J.W.
; Putzolu, G.R.
; Traiger, I.L.
; Wade, B.W.
; Wat-son, V. (1976).
System R: Relational Approach to DatabaseManagement.
ACM Transactions on Database Systems, 1 (21),pp.
97-137.Damerau, Fred J.
(1977).
Advantages of a TransformationalGrammar for Question Answering.
Proceedings of the FifthInternational Joint Conference on Artificial Intelligence, vol 1, p.192.Damerau, Fred J.
(1978).
The Derivation of Answers from LogicalForms in a Question Answering System.
American Journal ofComputational Linguistics, Microfiche 75, pp.
3-42.Krause, Juergen.
(1979).
Results of a User Study with the 'UserSpecialty Languages' System and Consequences for the Archi-tecture of Natural Language Interfaces.
Technical Report79.04.003, IBM Heidelberg Scientific Center, May 1979.Petrick, Stanley R. (1977).
Semantic Interpretation i the RequestSystem.
In Computational and Mathematical Linguistics, Pro-ceedings of the International Conference on Computational Linguis-tics, Pisa, pp.
585-610.Plath, Warren J.
(1973).
Transformational Grammar and Transfor-mational Parsing in the REQUEST System.
IBM ResearchReport RC 4396, Thomas J. Watson Research Center, YorktownHeights, N.Y.Plath, Warren J.
(1974).
String Transformations in the REQUESTSystem.
American Journal of Computational Linguistics, Micro-fiche 8.Plath, Warren J.
(1976).
REQUEST: A Natural LanguageQuestion-Answering System.
IBM Journal of  Research andDevelopment, 20:4, (July 1976), pp.
326-335.Robinson, Jane J.
(1973).
An Inverse Transformational Lexicon.In Natural Language Processing, Randall Rustin, ed., Algorithm-ics Press, Inc., New York, pp.
43-60.Fred J. Damerau is a Research Staf f  Member at theIBM Thomas J. Watson Research Center in YorktownHeights, New York.
He received the Ph.D. degree inlinguistics from Yale University in 1966.42 American Journal of Computational Linguistics, Volume 7, Number 1, January-March 1981
