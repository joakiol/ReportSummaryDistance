Proceedings of the NAACL HLT 2010: Tutorial Abstracts, pages 15?18,Los Angeles, California, June 2010. c?2010 Association for Computational LinguisticsDistributional Semantic ModelsStefan Evert, University of Osnabr?ck1.
DESCRIPTIONDistributional semantic models (DSM) -- also known as "word space" or "distributionalsimilarity" models -- are based on the assumption that the meaning of a word can (atleast to a certain extent) be inferred from its usage, i.e.
its distribution in text.
Therefore,these models dynamically build semantic representations -- in the form of high-dimensional vector spaces -- through a statistical analysis of the contexts in whichwords occur.
DSMs are a promising technique for solving the lexical acquisitionbottleneck by unsupervised learning, and their distributed representation provides acognitively plausible, robust and flexible architecture for the organisation and processingof semantic information.Since the seminal papers of Landauer & Dumais (1997) and Sch?tze (1998), DSMshave been an active area of research in computational linguistics.
Amongst many othertasks, they have been applied to solving the TOEFL synonym test (Landauer & Dumais1997, Rapp 2004), automatic thesaurus construction (Lin 1998), identification oftranslation equivalents (Rapp 1999), word sense induction and discrimination (Sch?tze1998), POS induction (Sch?tze 1995), identification of analogical relations (Turney2006), PP attachment disambiguation (Pantel & Lin 2000), semantic classification(Versley 2008), as well as the prediction of fMRI (Mitchell et al 2008) and EEG (Murphyet al 2009) data.
Recent years have seen renewed and rapidly growing interest indistributional approaches, as shown by the series of workshops on DSM held at Context2007 [1], ESSLLI 2008 [2], EACL 2009 [3], CogSci 2009 [4], NAACL-HLT 2010 [5], ACL2010 [6] and ESSLLI 2010 [7].The proposed tutorial aims to- introduce the most common DSM architectures and their parameters, as well asprototypical applications;- equip participants with the mathematical techniques needed for the implementation ofDSMs, in particular those of matrix algebra;- illustrate visualisation techniques and mathematical arguments that help inunderstanding the high-dimensional DSM vector spaces and making sense of keyoperations such as SVD dimensionality reduction; and- provide an overview of current research on DSMs, available software, evaluation tasksand future trends.The tutorial is targeted both at participants who are new to the field and need acomprehensive overview of DSM techniques and applications, and at experiencedscientists who want to get up to speed on current directions in DSM research.15An implementation of all methods presented in the tutorial will be provided assupplementary material, using the open-source statistical programming language R [8].This implementation, which is based on the code and data sets available at [9], isintended as a "toy laboratory" for participants, but can also form a sound basis forpractical applications and further DSM research.2.
TUTORIAL OUTLINE1) Introduction- motivation and brief history of distributional semantics- common DSM architectures- prototypical applications- concrete examples used in the tutorial2) Taxonomy of DSM parameters including- size and type of context window- feature scaling (tf.idf, statistical association measures, ...)- normalisation and standardisation of rows and/or columns- distance/similarity measures: Euclidean, Minkowski p-norms, cosine, entropy-based, ...- dimensionality reduction: feature selection, SVD, random indexing (RI)3) Elements of matrix algebra for DSM- basic matrix and vector operations- norms and distances, angles, orthogonality- projection and dimensionality reduction4) Making sense of DSMs: mathematical analysis and visualisation techniques- nearest neighbours and clustering- semantic maps: PCA, MDS, SOM- visualisation of high-dimensional spaces- supervised classification based on DSM vectors- understanding dimensionality reduction with SVD and RI- term-term vs. term-context matrix, connection to first-order association- SVD as a latent class model5) Current research topics and future directions- overview of current research on DSMs- evaluation tasks and data sets- available "off-the-shelf" DSM software- limitations and key problems of DSMs- trends for future workEach of the five parts will be compressed into a slot of roughly 30 minutes, leaving a 30-minute coffee break.
In order to cover the large amount of material in a relatively short16time, the discussion of mathematical and implementational aspects will aim primarily atan intuitive understanding of key issues and skip technical details.
Full descriptions areprovided as part of the handouts and supplementary material, esp.
the thoroughlycommented R implementation.3.
INSTRUCTORStefan EvertJuniorprofessor of Computational LinguisticsUniversity of Osnabr?ck, GermanyStefan Evert has studied mathematics, physics and English linguistics, and holds a PhDdegree in computational linguistics.
His research interests include the statisticalanalysis of corpus frequency data (significance tests in corpus linguistics, statisticalassociation measures, Zipf's law and word frequency distributions), quantitativeapproaches to lexical semantics (collocations, multiword expressions and DSM), as wellas processing large text corpora (IMS Open Corpus Workbench, data model and querylanguage of the Nite XML Toolkit, tools for the Web as corpus).
Stefan Evert haspublished extensively on collocations and association measures, has co-organisedseveral workshops on multiword expressions as well as the ESSLLI 2008 workshop ondistributional lexical semantics, and has co-taught an advanced course on DSM atESSLLI 2009 with Alessandro Lenci, as well as a course on Computational LexicalSemantics with Gemma Boleda.
The main focus of his current research is onunderstanding and improving DSMs for applications in natural language processing andlexical semantics.URLS[1] http://clic.cimec.unitn.it/marco/beyond_words/[2] http://wordspace.collocations.de/doku.php/esslli:start[3] http://art.uniroma2.it/gems/[4] http://www.let.rug.nl/disco2009/[5] http://sites.google.com/site/compneurowsnaacl10/[6] http://art.uniroma2.it/gems010/[7] http://clic.cimec.unitn.it/roberto/ESSLLI10-dsm-workshop/[8] http://www.R-project.org/[9] http://wordspace.collocations.de/doku.php/course:scheduleREFERENCESLandauer, Thomas K. and Dumais, Susan T. (1997).
A solution to Plato's problem: Thelatent semantic analysis theory of acquisition, induction and representation ofknowledge.
Psychological Review, 104(2), 211-240.17Lin, Dekang (1998).
Automatic retrieval and clustering of similar words.
In Proceedingsof the 17th International Conference on Computational Linguistics (COLING-ACL 1998),pages 768-774, Montreal, Canada.Mitchell, Tom M.; Shinkareva, Svetlana V.; Carlson, Andrew; Chang, Kai-Min; Malave,Vicente L.; Mason, Robert A.; Just, Marcel Adam (2008).
Predicting human brain activityassociated with the meanings of nouns.
Science, 320, 1191-1195.Murphy, Brian; Baroni, Marco; Poesio, Massimo (2009).
EEG responds to conceptualstimuli and corpus semantics.
In Proceedings of the 2009 Conference on EmpiricalMethods in Natural Language Processing, pages 619-627, Singapore.Pantel, Patrick; Lin, Dekang (2000).
An unsupervised approach to prepositional phraseattachment using contextually similar words.
In Proceedings of the 38th Annual Meetingof the Association for Computational Linguistics, Hongkong, China.Rapp, Reinhard (1999).
Automatic identification of word translations from unrelatedEnglish and German corpora.
In Proceedings of the 37th Annual Meeting of theAssociation for Computational Linguistics, Maryland.Rapp, Reinhard (2004).
A freely available automatically generated thesaurus of relatedwords.
In Proceedings of the 4th International Conference on Language Resources andEvaluation (LREC 2004), pages 395-398.Sch?tze, Hinrich (1995).
Distributional part-of-speech tagging.
In Proceedings of the 7thConference of the European Chapter of the Association for Computational Linguistics(EACL 1995), pages 141-148.Sch?tze, Hinrich (1998).
Automatic word sense discrimination.
ComputationalLinguistics, 24(1), 97-123.Turney, Peter D. (2006).
Similarity of semantic relations.
Computational Linguistics, 32(3), 379-416.Versley, Yannick (2008).
Decorrelation and shallow semantic patterns for distributionalclustering of nouns and verbs.
In Proceedings of the ESSLLI Workshop on DistributionalLexical Semantics, pages 55-62, Hamburg, Germany.18
