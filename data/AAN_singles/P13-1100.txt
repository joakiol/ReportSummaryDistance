Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 1014?1022,Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational LinguisticsSummarization Through Submodularity and DispersionAnirban DasguptaYahoo!
LabsSunnyvale, CA 95054anirban@yahoo-inc.comRavi KumarGoogleMountain View, CA 94043tintin@google.comSujith RaviGoogleMountain View, CA 94043sravi@gooogle.comAbstractWe propose a new optimization frame-work for summarization by generalizingthe submodular framework of (Lin andBilmes, 2011).
In our framework the sum-marization desideratum is expressed as asum of a submodular function and a non-submodular function, which we call dis-persion; the latter uses inter-sentence dis-similarities in different ways in order toensure non-redundancy of the summary.We consider three natural dispersion func-tions and show that a greedy algorithmcan obtain an approximately optimal sum-mary in all three cases.
We conduct ex-periments on two corpora?DUC 2004and user comments on news articles?andshow that the performance of our algo-rithm outperforms those that rely only onsubmodularity.1 IntroductionSummarization is a classic text processing prob-lem.
Broadly speaking, given one or more doc-uments, the goal is to obtain a concise pieceof text that contains the most salient points inthe given document(s).
Thanks to the om-nipresent information overload facing all of us,the importance of summarization is gaining; semi-automatically summarized content is increasinglybecoming user-facing: many newspapers equipeditors with automated tools to aid them in choos-ing a subset of user comments to show.
Summa-rization has been studied for the past in varioussettings?a large single document, multiple docu-ments on the same topic, and user-generated con-tent.Each domain throws up its own set of idiosyn-crasies and challenges for the summarization task.On one hand, in the multi-document case (say, dif-ferent news reports on the same event), the text isoften very long and detailed.
The precision/recallrequirements are higher in this domain and a se-mantic representation of the text might be neededto avoid redundancy.
On the other hand, in thecase of user-generated content (say, comments ona news article), even though the text is short, oneis faced with a different set of problems: volume(popular articles generate more than 10,000 com-ments), noise (most comments are vacuous, lin-guistically deficient, and tangential to the article),and redundancy (similar views are expressed bymultiple commenters).
In both cases, there is adelicate balance between choosing the salient, rel-evant, popular, and diverse points (e.g., sentences)versus minimizing syntactic and semantic redun-dancy.While there have been many approaches to au-tomatic summarization (see Section 2), our workis directly inspired by the recent elegant frame-work of (Lin and Bilmes, 2011).
They employedthe powerful theory of submodular functions forsummarization: submodularity embodies the ?di-minishing returns?
property and hence is a naturalvocabulary to express the summarization desider-ata.
In this framework, each of the constraints (rel-evance, redundancy, etc.)
is captured as a submod-ular function and the objective is to maximize theirsum.
A simple greedy algorithm is guaranteed toproduce an approximately optimal summary.
Theyused this framework to obtain the best results onthe DUC 2004 corpus.Even though the submodularity framework isquite general, it has limitations in its expressiv-ity.
In particular, it cannot capture redundancyconstraints that depend on pairwise dissimilaritiesbetween sentences.
For example, a natural con-straint on the summary is that the sum or the mini-mum of pairwise dissimilarities between sentenceschosen in the summary should be maximized; this,unfortunately, is not a submodular function.
Wecall functions that depend on inter-sentence pair-1014wise dissimilarities in the summary as dispersionfunctions.
Our focus in this work is on signif-icantly furthering the submodularity-based sum-marization framework to incorporate such disper-sion functions.We propose a very general graph-based sum-marization framework that combines a submod-ular function with a non-submodular dispersionfunction.
We consider three natural dispersionfunctions on the sentences in a summary: sumof all-pair sentence dissimilarities, the weight ofthe minimum spanning tree on the sentences, andthe minimum of all-pair sentence dissimilarities.These three functions represent three differentways of using the sentence dissimilarities.
Wethen show that a greedy algorithm can obtain ap-proximately optimal summary in each of the threecases; the proof exploits some nice combinatorialproperties satisfied by the three dispersion func-tions.
We then conduct experiments on two cor-pora: the DUC 2004 corpus and a corpus of usercomments on news articles.
On DUC 2004, weobtain performance that matches (Lin and Bilmes,2011), without any serious parameter tuning; notethat their framework does not have the dispersionfunction.
On the comment corpus, we outperformtheir method, demonstrating that value of disper-sion functions.
As part of our methodology, wealso use a new structured representation for sum-maries.2 Related WorkAutomatic summarization is a well-studied prob-lem in the literature.
Several methods have beenproposed for single- and multi-document summa-rization (Carbonell and Goldstein, 1998; Con-roy and O?Leary, 2001; Takamura and Okumura,2009; Shen and Li, 2010).Related concepts have also been used in severalother scenarios such as query-focused summariza-tion in information retrieval (Daume?
and Marcu,2006), microblog summarization (Sharifi et al,2010), event summarization (Filatova, 2004), andothers (Riedhammer et al, 2010; Qazvinian et al,2010; Yatani et al, 2011).Graph-based methods have been used for sum-marization (Ganesan et al, 2010), but in a dif-ferent context?using paths in graphs to producevery short abstractive summaries.
For a detailedsurvey on existing automatic summarization tech-niques and other related topics, see (Kim et al,2011; Nenkova and McKeown, 2012).3 FrameworkIn this section we present the summarizationframework.
We start by describing a generic ob-jective function that can be widely applied to sev-eral summarization scenarios.
This objective func-tion is the sum of a monotone submodular cov-erage function and a non-submodular dispersionfunction.
We then describe a simple greedy algo-rithm for optimizing this objective function withprovable approximation guarantees for three natu-ral dispersion functions.3.1 PreliminariesLet C be a collection of texts.
Depending on thesummarization application, C can refer to the setof documents (e.g., newswire) related to a partic-ular topic as in standard summarization; in otherscenarios (e.g., user-generated content), it is a col-lection of comments associated with a news articleor a blog post, etc.
For each document c ?
C,let S(c) denote the set of sentences in c. LetU = ?c?CS(c) be the universe of all sentences;without loss of generality, we assume each sen-tence is unique to a document.
For a sentenceu ?
U , let C(u) be the document correspondingto u.Each u ?
U is associated with a weight w(u),which might indicate, for instance, how similar uis to the main article (and/or the query, in query-dependent settings).
Each pair u, v ?
U is as-sociated with a similarity s(u, v) ?
[0, 1].
Thissimilarity can then be used to define an inter-sentence distance d(?, ?)
as follows: let d?
(u, v) =1 ?
s(u, v) and define d(u, v) to be the shortestpath distance from u to v in the graph where theweight of each edge (u, v) is d?
(u, v).
Note thatd(?, ?)
is a metric unlike d?
(?, ?
), which may not bea metric.
(In addition to being intuitive, d(?, ?)
be-ing a metric helps us obtain guarantees on the al-gorithm?s output.)
For a set S, and a point u 6?
S,define d(u, S) = minv?S d(u, v).Let k > 0 be fixed.
A summary of U is a subsetS ?
U, |S| = k. Our aim is to find a summary thatmaximizesf(S) = g(S) + ?h(S), (1)where g(S) is the coverage function that is non-negative, monotone, and submodular1, h(S) is a1A function f : U ?
< is submodular if for every1015dispersion function, and ?
?
0 is a parameter thatcan be used to scale the range of h(?)
to be com-parable to that of g(?
).For two sets S and T , let P be the set of un-ordered pairs {u, v} where u ?
S and v ?
T .
Ourfocus is on the following dispersion functions: thesum measure hs(S, T ) = ?
{u,v}?P d(u, v), thespanning tree measure ht(S, T ) given by the costof the minimum spanning tree of the set S?T , andthe min measure hm(S, T ) = min{u,v}?P d(u, v).Note that these functions span from consider-ing the entire set of distances in S to consider-ing only the minimum distance in S; also it iseasy to construct examples to show that none ofthese functions is submodular.
Define h?
(u, S) =h?
({u}, S) and h?
(S) = h?
(S, S).Let O be the optimal solution of the functionf .
A summary S?
is a ?-approximation if f(S?)
?
?f(O).3.2 AlgorithmMaximizing (1) is NP-hard even if ?
= 0 or ifg(?)
= 0 (Chandra and Halldo?rsson, 2001).
Forthe special case ?
= 0, since g(?)
is submodular,a classical greedy algorithm obtains a (1 ?
1/e)-approximation (Nemhauser et al, 1978).
But if?
> 0, since the dispersion function h(?)
is notsubmodular, the combined objective f(?)
is notsubmodular as well.
Despite this, we show thata simple greedy algorithm achieves a provable ap-proximation factor for (1).
This is possible due tosome nice structural properties of the dispersionfunctions we consider.Algorithm 2 Greedy algorithm, parametrized bythe dispersion function h; here, U, k, g, ?
are fixed.S0 ?
?
; i?
0for i = 0, .
.
.
, k ?
1 dov ?
argmaxu?U\Si g(Si+u)+?h(Si+u)Si+1 ?
Si ?
{v}end for3.3 AnalysisIn this section we obtain a provable approximationfor the greedy algorithm.
First, we show that agreedy choice is well-behaved with respect to thedispersion function h?(?
).Lemma 1.
Let O be any set with |O| = k. If S issuch that |S| = ` < k, then(i)?u?O\S hs(u, S) ?
|O \ S| `hs(O)k(k?1) ;A,B ?
U , we have f(A)+f(B) ?
f(A?B)+f(A?B).
(ii)?u?O\S d(u, S) ?
12ht(O)?
ht(S); and(iii) there exists u ?
O \ S such that hm(u, S) ?hm(O)/2.Proof.
The proof for (i) follows directly fromLemma 1 in (Borodin et al, 2012).To prove (ii) let T be the tree obtained by addingall points of O \S directly to their respective clos-est points on the minimum spanning tree of S. Tis a spanning tree, and hence a Steiner tree, for thepoints in set S ?
O.
Hence, cost(T ) = ht(S) +?u?O\S d(u, S).
Let smt(S) denote the cost ofa minimum Steiner tree of S. Thus, cost(T ) ?smt(O ?
S).
Since a Steiner tree of O ?
S is alsoa Steiner tree of O, smt(O ?
S) ?
smt(O).
Sincethis is a metric space, smt(O) ?
12ht(O) (see, forexample, (Cieslik, 2001)).
Thus,ht(S) +?u?O\Sd(u, S) ?
12ht(O)?
?u?O\Sd(u, S) ?
12ht(O)?
ht(S).To prove (iii), let O = {u1, .
.
.
, uk}.
By def-inition, for every i 6= j, d(ui, uj) ?
hm(O).Consider the (open) ball Bi of radius hm(O)/2around each element ui.
By construction for eachi, Bi ?
O = {ui} and for each pair i 6= j,Bi ?Bj = ?.
Since |S| < k, and there are k ballsBi, there exists k?` ballsBi such that S?Bi = ?,proving (iii).We next show that the tree created by the greedyalgorithm for h = ht is not far from the optimum.Lemma 2.
Let u1, .
.
.
, uk be a sequence of pointsand let Si = {uj , j ?
i}.
Then, ht(Sk) ?1/log k?2?j?k d(uj , Sj?1).Proof.
The proof follows by noting that we get aspanning tree by connecting each ui to its closestpoint in Si?1.
The cost of this spanning tree is?2?j?k d(uj , Sj?1) and this tree is also the re-sult of the greedy algorithm run in an online fash-ion on the input sequence {u1, .
.
.
, uk}.
Using theresult of (Imase and Waxman, 1991), the compet-itive ratio of this algorithm is log k, and hence theproof.We now state and prove the main result aboutthe quality of approximation of the greedy algo-rithm.1016Theorem 3.
For k > 1, there is a polynomial-timealgorithm that obtains a ?-approximation to f(S),where ?
= 1/2 for h = hs, ?
= 1/4 for h = hm,and ?
= 1/3 log k for h = ht.Proof.
For hs and ht, we run Algorithm 1 usinga new dispersion function h?, which is a slightlymodified version of h. In particular, for h = hs,we use h?
(S) = 2hs(S).
For h = ht, weabuse notation and define h?
to be a function overan ordered set S = {u1, .
.
.
, uk} as follows:h?
(S) =?j?|S| d(uj , Sj?1), where Sj?1 ={u1, .
.
.
, uj?1}.
Let f ?
(S) = g(S) + ?h?
(S).Consider the ith iteration of the algorithm.
Bythe submodularity of g(?
),?u?O\Sig(Si ?
{u})?
g(Si) (2)?
g(O ?
Si)?
g(Si) ?
g(O)?
g(Sk),where we use monotonicity of g(?)
to infer g(O ?Si) ?
g(O) and g(Si) ?
g(Sk).For h = hs, the proof follows by Lemma 1(i)and by Theorem 1 in (Borodin et al, 2012).For ht, using the above argument of submodu-larity and monotonicity of g, and the result fromLemma 1(ii), we have?u?O\Sig(Si ?
u)?
g(Si) + ?d(u, Si)?
g(O)?
g(Si) + ?(ht(O)/2?
ht(Si))?
(g(O) + ?ht(O)/2)?
(g(Si) + ?ht(Si))?
f(O)/2?
(g(Si) + ?ht(Si)).Also, ht(Si) ?
2 smt(Si) since this is a met-ric space.
Using the monotonicity of the Steinertree cost, smt(Si) ?
smt(Sk) ?
ht(Sk).
Hence,ht(Si) ?
2ht(Sk).
Thus,?u?O\Sig(Si ?
u)?
g(Si) + ?d(u, Si)?
f(O)/2?
(g(Si) + ?ht(Si))?
f(O)/2?
(g(Sk) + 2?ht(Sk))?
f(O)/2?
2f(Sk).
(3)By the greedy choice of ui+1,f ?
(Si ?
ui+1)?
f ?
(Si)= g(Si ?
ui+1)?
g(Si) + ?d(ui+1, Si)?
(f(O)/2?
2f(Sk))/|O \ Si|?
1k (f(O)/2?
2f(Sk)).Summing over all i ?
[1, k ?
1],f ?
(Sk) ?
(k?1)/k(f(O)/2?
2f(Sk)).
(4)Using Lemma 2 we obtainf(Sk) = g(Sk) + ?ht(Sk) ?f ?
(Sk)log k?
1?1/klog k (f(O)/2?
2f(Sk)).By simplifying, we obtain f(Sk) ?
f(O)/3 log k.Finally for hm, we run Algorithm 1 twice: oncewith g as given and h ?
0, and the secondtime with g ?
0 and h ?
hm.
Let Sg andSh be the solutions in the two cases.
Let Ogand Oh be the corresponding optimal solutions.By the submodularity and monotonicity of g(?
),g(Sg) ?
(1 ?
1/e)g(Og) ?
g(Og)/2.
Similarly,using Lemma 1(iii), hm(Sh) ?
hm(Oh)/2 sincein any iteration i < k we can choose an ele-ment ui+1 such that hm(ui+1, Si) ?
hm(Oh)/2.Let S = argmaxX?
{Sg ,Sh} f(X).
Using an av-eraging argument, since g and hm are both non-negative,f(X) ?
(f(Sg)+f(Sh))/2 ?
(g(Og)+?hm(Oh))/4.Since by definition g(Og) ?
g(O) and hm(Oh) ?hm(O), we have a 1/4-approximation.3.4 A universal constant-factorapproximationUsing the above algorithm that we used for hm,it is possible to give a universal algorithm thatgives a constant-factor approximation to each ofthe above objectives.
By running the Algorithm 1once for g ?
0 and next for h ?
0 and takingthe best of the two solutions, we can argue that theresulting set gives a constant factor approximationto f .
We do not use this algorithm in our exper-iments, as it is oblivious of the actual dispersionfunctions used.4 Using the FrameworkNext, we describe how the framework describedin Section 3 can be applied to our tasks of interest,i.e., summarizing documents or user-generatedcontent (in our case, comments).
First, we repre-sent the elements of interest (i.e., sentences withincomments) in a structured manner by using depen-dency trees.
We then use this representation to1017generate a graph and instantiate our summariza-tion objective function with specific componentsthat capture the desiderata of a given summariza-tion task.4.1 Structured representation for sentencesIn order to instantiate the summarization graph(nodes and edges), we first need to model eachsentence (in multi-document summarization) orcomment (i.e., set of sentences) as nodes in thegraph.
Sentences have been typically modeledusing standard ngrams (unigrams or bigrams) inprevious summarization work.
Instead, we modelsentences using a structured representation, i.e., itssyntax structure using dependency parse trees.
Wefirst use a dependency parser (de Marneffe et al,2006) to parse each sentence and extract the setof dependency relations associated with the sen-tence.
For example, the sentence ?I adore tennis?is represented by the dependency relations (nsubj:adore, I) and (dobj: adore, tennis).Each sentence represents a single node u inthe graph (unless otherwise specified) and is com-prised of a set of dependency relations (or ngrams)present in the sentence.
Furthermore, the edgeweights s(u, v) represent pairwise similarity be-tween sentences or comments (e.g., similarity be-tween views expressed in different comments).The edge weights are then used to define theinter-sentence distance metric d(u, v) for the dif-ferent dispersion functions.
We identify simi-lar views/opinions by computing semantic simi-larity rather than using standard similarity mea-sures (such as cosine similarity based on ex-act lexical matches between different nodes inthe graph).
For each pair of nodes (u, v) inthe graph, we compute the semantic similarityscore (using WordNet) between every pair ofdependency relation (rel: a, b) in u and v as:s(u, v) =?reli?u,relj?vreli=reljWN(ai, aj)?WN(bi, bj),where rel is a relation type (e.g., nsubj) and a, bare the two arguments present in the dependencyrelation (b does not exist for some relations).WN(wi, wj) is defined as the WordNet similar-ity score between words wi and wj .2 The edgeweights are then normalized across all edges in the2There exists various semantic relatedness measuresbased on WordNet (Patwardhan and Pedersen, 2006).
In ourexperiments, for WN we pick one that is based on the pathlength between the two words in the WordNet graph.graph.This allows us to perform approximate match-ing of syntactic treelets obtained from the depen-dency parses using semantic (WordNet) similar-ity.
For example, the sentences ?I adore tennis?and ?Everyone likes tennis?
convey the same viewand should be assigned a higher similarity scoreas opposed to ?I hate tennis?.
Using the syntac-tic structure along with semantic similarity helpsus identify useful (valid) nuggets of informationwithin comments (or documents), avoid redun-dancies, and identify similar views in a semanticspace.4.2 Components of the coverage functionOur coverage function is a linear combination ofthe following.
(i) Popularity.
One of the requirements for a goodsummary (especially, for user-generated content)is that it should include (or rather not miss) thepopular views or opinions expressed by severalusers across multiple documents or comments.
Wemodel this property in our objective function asfollows.For each node u, we define w(u) as the num-ber of documents |Curel ?
C| from the collectionsuch that at least one of the dependency relationsrel ?
u appeared in a sentence within some doc-ument c ?
Curel .
The popularity scores are thennormalized across all nodes in the graph.
We thenadd this component to our objective function asw(S) =?u?S w(u).
(ii) Cluster contribution.
This term captures thefact that we do not intend to include multiple sen-tences from the same comment (or document).Define B to be the clustering induced by the sen-tence to comment relation, i.e., two sentences inthe same comment belong to the same cluster.
Thecorresponding contribution to the objective func-tion is ?B?B |S ?B|1/2.
(iii) Content contribution.
This term promotes thediversification of content.
We look at the graph ofsentences where the weight of each edge is s(u, v).This graph is then partitioned based on a localrandom walk based method to give us clustersD = {D1, .
.
.
, Dn}.
The corresponding contribu-tion to the objective function is?D?D |S?D|1/2.
(iv) Cover contribution.
We also measure thecover of the set S as follows: for each elements in U first define cover of an element u by aset S?
as cov(u, S?)
= ?v?S?
s(u, v).
Then, the1018cover value of the set S is defined as cov(S) =?u?S min(cov(u, S), 0.25cov(u, U)).3Thus, the final coverage function is: g(S) =w(S) + ?
?B?B |S ?
B|1/2 + ?
?D?D |S ?D|1/2 + ?cov(S), where ?, ?, ?
are non-negativeconstants.
By using the monotone submodularityof each of the component functions, and the factthat addition preserves submodularity, the follow-ing is immediate.Fact 4. g(S) is a monotone, non-negative, sub-modular function.We then apply Algorithm 1 to optimize (1).5 Experiments5.1 DataMulti-document summarization.
We use theDUC 2004 corpus4 that comprises 50 clusters (i.e.,50 different summarization tasks) with 10 docu-ments per cluster on average.
Each document con-tains multiple sentences and the goal is to producea summary of all the documents for a given cluster.Comments summarization.
We extracted a setof news articles and corresponding user commentsfrom Yahoo!
News website.
Our corpus contains aset of 34 articles and each article is associated withanywhere from 100?500 comments.
Each com-ment contains more than three sentences and 36words per sentence on average.5.2 EvaluationFor each summarization task, we compare thesystem output (i.e., summaries automatically pro-duced by the algorithm) against the human-generated summaries and evaluate the perfor-mance in terms of ROUGE score (Lin, 2004), astandard recall-based evaluation measure used insummarization.
A system that produces higherROUGE scores generates better quality summaryand vice versa.We use the following evaluation settings in ourexperiments for each summarization task:(1) For multi-document summarization, wecompute the ROUGE-15 scores that was the mainevaluation criterion for DUC 2004 evaluations.3The choice of the value 0.25 in the cover component isinspired by the observations made by (Lin and Bilmes, 2011)for the ?
value used in their cover function.4http://duc.nist.gov/duc2004/tasks.html5ROUGE v1.5.5 with options: -a -c 95 -b 665 -m -n 4 -w1.2(2) For comment summarization, the collectionof user comments associated with a given arti-cle is typically much larger.
Additionally, indi-vidual comments are noisy, wordy, diverse, andinformally written.
Hence for this task, we usea slightly different evaluation criterion that is in-spired from the DUC 2005-2007 summarizationevaluation tasks.We represent the content within each commentc (i.e., all sentences S(c) comprising the com-ment) as a single node in the graph.
We then runour summarization algorithm on the instantiatedgraph to produce a summary for each news article.In addition, each news article and correspondingset of comments were presented to three humanannotators.
They were asked to select a subset ofcomments (at most 20 comments) that best rep-resented a summary capturing the most popularas well as diverse set of views and opinions ex-pressed by different users that are relevant to thegiven news article.
We then compare the auto-matically generated comment summaries againstthe human-generated summaries and compute theROUGE-1 and ROUGE-2 scores.6This summarization task is particularly hard foreven human annotators since user-generated com-ments are typically noisy and there are severalhundreds of comments per article.
Similar to ex-isting work in the literature (Sekine and Nobata,2003), we computed inter-annotator agreement forthe humans by comparing their summaries againsteach other on a small held-out set of articles.
Theaverage ROUGE-1 F-scores observed for humanswas much higher (59.7) than that of automatic sys-tems measured against the human-generated sum-maries (our best system achieved a score of 28.9ROUGE-1 on the same dataset).
This shows thateven though this is a new type of summariza-tion task, humans tend to generate more consistentsummaries and hence their annotations are reliablefor evaluation purposes as in multi-document sum-marization.5.3 ResultsMulti-document summarization.
(1) Table 1compares the performance of our system withthe previous best reported system that partici-pated in the DUC 2004 competition.
We also in-clude for comparison another baseline?a version6ROUGE v1.5.5 with options: -a -n 2 -x -m -2 4 -u -c 95-r 1000 -f A -p 0.5 -t 0 -d -l 1501019of our system that approximates the submodularobjective function proposed by (Lin and Bilmes,2011).7 As shown in the results, our best system8which uses the hs dispersion function achieves abetter ROUGE-1 F-score than all other systems.
(2) We observe that the hm and ht dispersion func-tions produce slightly lower scores than hs, whichmay be a characteristic of this particular summa-rization task.
We believe that the empirical resultsachieved by different dispersion functions dependon the nature of the summarization tasks and thereare task settings under which hm or ht performbetter than hs.
For example, we show later how us-ing the ht dispersion function yields the best per-formance on the comments summarization task.Regardless, the theoretical guarantees presented inthis paper cover all these cases.
(3) We also analyze the contributions of individ-ual components of the new objective function to-wards summarization performance by selectivelysetting certain parameters to 0.
Table 2 illustratesthese results.
We clearly see that each component(popularity, cluster contribution, dispersion) indi-vidually yields a reasonable summarization per-formance but the best result is achieved by thecombined system (row 5 in the table).
We alsocontrast the performance of the full system withand without the dispersion component (row 4 ver-sus row 5).
The results show that optimizing fordispersion yields an improvement in summariza-tion performance.
(4) To understand the effect of utilizing syntacticstructure and semantic similarity for constructingthe summarization graph, we ran the experimentsusing just the unigrams and bigrams; we obtaineda ROUGE-1 F-score of 37.1.
Thus, modelingthe syntactic structure (using relations extracted7Note that Lin & Bilmes (2011) report a slightly higherROUGE-1 score (F-score 38.90) on DUC 2004.
This is be-cause their system was tuned for the particular summarizationtask using the DUC 2003 corpus.
On the other hand, evenwithout any parameter tuning our method yields good perfor-mance, as evidenced by results on the two different summa-rization tasks.
However, since individual components withinour objective function are parametrized it is easy to tune themfor a specific task or genre.8For the full system, we weight certain parameters per-taining to cluster contributions and dispersion higher (?
=?
= ?
= 5) compared to the rest of the objective function(?
= 1).
Lin & Bilmes (2011) also observed a similar find-ing (albeit via parameter tuning) where weighting the clustercontribution component higher yielded better performance.If the maximum number of sentences/comments chosen werek, we brought both hs and ht to the same approximate scaleas hm by dividing hs by k(k ?
1)/2 and ht by k ?
1.from dependency parse tree) along with comput-ing similarity in semantic spaces (using WordNet)clearly produces an improvement in the summa-rization quality (+1.4 improvement in ROUGE-1F-score).
However, while the structured represen-tation is beneficial, we observed that dispersion(and other individual components) contribute sim-ilar performance gains even when using ngramsalone.
So the improvements obtained from thestructured representation and dispersion are com-plementary.System ROUGE-1 FBest system in DUC 2004 37.9(Lin and Bilmes, 2011), no tuning 37.47Our algorithm with h = hm 37.5h = hs 38.5h = ht 36.8Table 1: Performance on DUC 2004.Comments summarization.
(1) Table 3 com-pares the performance of our system against abaseline system that is constructed by pickingcomments in order of decreasing length, i.e., wefirst pick the longest comment (comprising themost number of characters), then the next longestcomment and so on, to create an ordered set ofcomments.
The intuition behind this baseline isthat longer comments contain more content andpossibly cover more topics than short ones.From the table, we observe that the new sys-tem (using either dispersion function) outperformsthe baseline by a huge margin (+44% relativeimprovement in ROUGE-1 and much bigger im-provements in ROUGE-2 scores).
One reason be-hind the lower ROUGE-2 scores for the baselinemight be that while long comments provide morecontent (in terms of size), they also add noise andirrelevant information to the generated summaries.Our system models sentences using the syntacticstructure and semantics and jointly optimizes formultiple summarization criteria (including disper-sion) which helps weed out the noise and identifyrelevant, useful information within the commentsthereby producing better quality summaries.
The95% confidence interval scores for the best systemon this task is [36.5?46.9].
(2) Unlike the multi-document summarization,here we observe that the ht dispersion functionyields the best empirical performance for thistask.
This observation supports our claim that thechoice of the specific dispersion function depends1020Objective function components ROUGE-1 F?
= ?
= ?
= ?
= 0 35.7w(S) = ?
= ?
= ?
= 0 35.1h = hs, w(S) = ?
= ?
= ?
= 0 37.1?
= 0 37.4w(S), ?, ?, ?, ?
> 0 38.5Table 2: Performance with different parameters(DUC).on the summarization task and that the dispersionfunctions proposed in this paper have a wider va-riety of use cases.
(3) Results showing contributions from individualcomponents of the new summarization objectivefunction are listed in Table 4.
We observe a sim-ilar pattern as with multi-document summariza-tion.
The full system using all components out-perform all other parameter settings, achieving thebest ROUGE-1 and ROUGE-2 scores.
The tablealso shows that incorporating dispersion into theobjective function yields an improvement in sum-marization quality (row 4 versus row 5).System ROUGE-1 ROUGE-2Baseline (decreasing length) 28.9 2.9Our algorithm with h = hm 39.2 13.2h = hs 40.9 15.0h = ht 41.6 16.2Table 3: Performance on comments summariza-tion.Objective function ROUGE-1 ROUGE-2components?
= ?
= ?
= ?
= 0 36.1 9.4w(S) = ?
= ?
= ?
= 0 32.1 4.9h = ht, w(S) = ?
= ?
= ?
= 0 37.8 11.2?
= 0 38.0 11.6w(S), ?, ?, ?, ?
> 0 41.6 16.2Table 4: Performance with different parameters(comments).6 ConclusionsWe introduced a new general-purpose graph-basedsummarization framework that combines a sub-modular coverage function with a non-submodulardispersion function.
We presented three naturaldispersion functions that represent three differentways of ensuring non-redundancy (using sentencedissimilarities) for summarization and proved thata simple greedy algorithm can obtain an approxi-mately optimal summary in all these cases.
Exper-iments on two different summarization tasks showthat our algorithm outperforms algorithms thatrely only on submodularity.
Finally, we demon-strated that using a structured representation tomodel sentences in the graph improves summa-rization quality.For future work, it would be interesting to in-vestigate other related developments in this areaand perhaps combine them with our approach tosee if further improvements are possible.
Firstly,it would interesting to see if dispersion offers sim-ilar improvements over a tuned version of the sub-modular framework of Lin and Bilmes (2011).
In avery recent work, Lin and Bilmes (2012) demon-strate a further improvement in performance fordocument summarization by using mixtures ofsubmodular shells.
This is an interesting exten-sion of their previous submodular framework andwhile the new formulation permits more complexfunctions, the resulting function is still submodu-lar and hence can be combined with the dispersionmeasures proposed in this paper.
A different bodyof work uses determinantal point processes (DPP)to model subset selection problems and adapt itfor document summarization (Kulesza and Taskar,2011).
Note that DPPs use similarity kernels forperforming inference whereas our measures arecombinatorial and not kernel-representable.
Whileapproximation guarantees for DPPs are open, itwould be interesting to investigate the empiri-cal gains by combining DPPs with dispersion-likefunctions.AcknowledgmentsWe thank the anonymous reviewers for their manyuseful comments.ReferencesAllan Borodin, Hyun Chul Lee, and Yuli Ye.
2012.Max-sum diversification, monotone submodularfunctions and dynamic updates.
In Proc.
PODS,pages 155?166.Jaime Carbonell and Jade Goldstein.
1998.
The use ofMMR, diversity-based reranking for reordering doc-uments and producing summaries.
In Proc.
SIGIR,pages 335?336.Barun Chandra and Magnu?s Halldo?rsson.
2001.
Facil-ity dispersion and remote subgraphs.
J. Algorithms,38(2):438?465.Dietmar Cieslik.
2001.
The Steiner Ratio.
Springer.1021John M. Conroy and Dianne P. O?Leary.
2001.
Textsummarization via hidden Markov models.
In Proc.SIGIR, pages 406?407.Hal Daume?, III and Daniel Marcu.
2006.
Bayesianquery-focused summarization.
In Proc.
COL-ING/ACL, pages 305?312.Marie-Catherine de Marneffe, Bill Maccartney, andChristopher D. Manning.
2006.
Generating typeddependency parses from phrase structure parses.
InProc.
LREC, pages 449?454.Elena Filatova.
2004.
Event-based extractive summa-rization.
In Proc.
ACL Workshop on Summarization,pages 104?111.Kavita Ganesan, ChengXiang Zhai, and Jiawei Han.2010.
Opinosis: A graph based approach to abstrac-tive summarization of highly redundant opinions.
InProc.
COLING.Makoto Imase and Bernard M. Waxman.
1991.
Dy-namic Steiner tree problem.
SIAM J. Discrete Math-ematics, 4(3):369?384.Hyun Duk Kim, Kavita Ganesan, Parikshit Sondhi, andChengXiang Zhai.
2011.
Comprehensive review ofopinion summarization.
Technical report, Univer-sity of Illinois at Urbana-Champaign.Alex Kulesza and Ben Taskar.
2011.
Learning deter-minantal point processes.
In Proc.
UAI, pages 419?427.Hui Lin and Jeff Bilmes.
2011.
A class of submodu-lar functions for document summarization.
In Proc.ACL, pages 510?520.Hui Lin and Jeff Bilmes.
2012.
Learning mixturesof submodular shells with application to documentsummarization.
In Proc.
UAI, pages 479?490.Chin-Yew Lin.
2004.
ROUGE: A package for auto-matic evaluation of summaries.
In Workshop on TextSummarization Branches Out: Proc.
ACL Work-shop, pages 74?81.G.
L. Nemhauser, L. A. Wolsey, and M. L. Fisher.1978.
An analysis of approximations for maximiz-ing submodular set functions I.
Mathematical Pro-gramming, 14(1):265?294.Ani Nenkova and Kathleen McKeown.
2012.
A surveyof text summarization techniques.
In Charu C. Ag-garwal and ChengXiang Zhai, editors, Mining TextData, pages 43?76.
Springer.Siddharth Patwardhan and Ted Pedersen.
2006.
Us-ing WordNet-based context vectors to estimate thesemantic relatedness of concepts.
In Proc.
EACLWorkshop on Making Sense of Sense: BringingComputational Linguistics and PsycholinguisticsTogether, pages 1?8.Vahed Qazvinian, Dragomir R. Radev, and ArzucanO?zgu?r.
2010.
Citation summarization throughkeyphrase extraction.
In Proc.
COLING, pages 895?903.Korbinian Riedhammer, Benoit Favre, and DilekHakkani-Tu?r.
2010.
Long story short?Globalunsupervised models for keyphrase based meetingsummarization.
Speech Commun., 52(10):801?815.Satoshi Sekine and Chikashi Nobata.
2003.
A surveyfor multi-document summarization.
In Proc.
HLT-NAACL Workshop on Text Summarization, pages65?72.Beaux Sharifi, Mark-Anthony Hutton, and Jugal Kalita.2010.
Summarizing microblogs automatically.
InProc.
HLT/NAACL, pages 685?688.Chao Shen and Tao Li.
2010.
Multi-document summa-rization via the minimum dominating set.
In Proc.COLING, pages 984?992.Hiroya Takamura and Manabu Okumura.
2009.
Textsummarization model based on maximum coverageproblem and its variant.
In Proc.
EACL, pages 781?789.Koji Yatani, Michael Novati, Andrew Trusty, andKhai N. Truong.
2011. Review spotlight: A user in-terface for summarizing user-generated reviews us-ing adjective-noun word pairs.
In Proc.
CHI, pages1541?1550.1022
