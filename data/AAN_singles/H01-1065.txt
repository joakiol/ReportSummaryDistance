Sentence Ordering in Multidocument SummarizationRegina BarzilayComputer ScienceDepartment1214 Amsterdam AveNew York, 10027, NY, USAregina@cs.columbia.eduNoemie ElhadadComputer ScienceDepartment1214 Amsterdam AveNew York, 10027, NY, USAnoemie@cs.columbia.eduKathleen R. McKeownComputer ScienceDepartment1214 Amsterdam AveNew York, 10027, NY, USAkathy@cs.columbia.eduABSTRACTThe problem of organizing information for multidocumentsummarization so that the generated summary is coherenthas received relatively little attention.
In this paper, wedescribe two naive ordering techniques and show that theydo not perform well.
We present an integrated strategy forordering information, combining constraints from chronolog-ical order of events and cohesion.
This strategy was derivedfrom empirical observations based on experiments asking hu-mans to order information.
Evaluation of our augmentedalgorithm shows a signicant improvement of the orderingover the two naive techniques we used as baseline.1.
INTRODUCTIONMultidocument summarization poses a number of newchallenges over single document summarization.
Researchershave already investigated issues such as identifying repeti-tions or contradictions across input documents and deter-mining which information is salient enough to include in thesummary [1, 3, 6, 11, 15, 19].
One issue that has receivedlittle attention is how to organize the selected informationso that the output summary is coherent.
Once all the rel-evant pieces of information have been selected across theinput documents, the summarizer has to decide in whichorder to present them so that the whole text makes sense.In single document summarization, one possible ordering ofthe extracted information is provided by the input docu-ment itself.
However, [10] observed that, in single documentsummaries written by professional summarizers, extractedsentences do not retain their precedence orders in the sum-mary.
Moreover, in the case of multiple input documents,this does not provide a useful solution: information maybe drawn from dierent documents and therefore, no onedocument can provide an ordering.
Furthermore, the orderbetween two pieces of information can change signicantlyfrom one document to another.We investigate constraints on ordering in the context ofmultidocument summarization.
We rst describe two naiveordering algorithms, used in several systems and show thatthey do not yield satisfactory results.
The rst, MajorityOrdering, is critically linked to the level of similarity of theinformation ordering across the input texts.
But many timesinput texts have dierent structure, and therefore, this al-gorithm is not acceptable.
The second, Chronological Or-dering, can produce good results when the information isevent-based and can, therefore, be ordered based on tempo-ral occurence.
However, texts do not always refer to events.We have conducted experiments to identify additional con-straints using a manually built collection of multiple order-ings of texts.
These experiments show that cohesion as animportant constraint.
While it is recognized in the gener-ation community that cohesion is a necessary feature for agenerated text, we provide an operational way to automati-cally ensure cohesion when ordering sentences in an outputsummary.
We augment the Chronological Ordering algo-rithm with a cohesion constraint, and compare it to thenaive algorithms.Our framework is the MultiGen system [15], a domain in-dependent multidocument summarizer which has been trainedand tested on news articles.
In the following sections, werst give an overview of MultiGen.
We then describe thetwo naive ordering algorithms and evaluate them.
We followthis with a study of multiple orderings produced by humans.This allows us to determine how to improve the Chronologi-cal Ordering algorithm using cohesion as an additional con-straint.
The last section describes the augmented algorithmalong with its evaluation.2.
MULTIGEN OVERVIEWMultiGen operates on a set of news articles describingthe same event.
It creates a summary which synthesizescommon information across documents.
In the case of mul-tidocument summarization of articles about the same event,source articles can contain both repetitions and contradic-tions.
Extracting all the similar sentences would produce averbose and repetitive summary, while extracting only someof the similar sentences would produce a summary biasedtowards some sources.
MultiGen uses a comparison of ex-tracted similar sentences to select the appropriate phrasesto include in the summary and reformulates them as a newtext.MultiGen consists of an analysis and a generation compo-nent.
The analysis component [7] identies units of textwhich convey similar information across the input docu-ments using statistical techniques and shallow text analy-sis.
Once similar text units are identied, we cluster theminto themes.
Themes are sets of sentences from dierentdocuments that contain repeated information and do notnecessarily contain sentences from all the documents.
Foreach theme, the generation component [1] identies phraseswhich are in the intersection of the theme sentences, andselects them as part of the summary.
The intersection sen-tences are then ordered to produce a coherent text.3.
NAIVE ORDERING ALGORITHMS ARENOT SUFFICIENTWhen producing a summary, any multidocument summa-rization system has to choose in which order to present theoutput sentences.
In this section, we describe two algorithmsfor ordering sentences suitable for domain independent mul-tidocument summarization.
The rst algorithm, MajorityOrdering (MO), relies only on the original orders of sen-tences in the input documents.
It is the rst solution one canthink of when addressing the ordering problem.
The secondone, Chronological Ordering (CO) uses time related featuresto order sentences.
We analyze this strategy because it wasoriginally implemented in MultiGen and followed by othersummarization systems [18].
In the MultiGen framework,ordering sentences is equivalent to ordering themes and wedescribe the algorithms in terms of themes, but the con-cepts can be adapted to other summarization systems suchas [3].
Our evaluation shows that these methods alone donot provide an adequate strategy for ordering.3.1 Majority Ordering3.1.1 The AlgorithmTypically, in single document summarization, the orderof sentences in the output summary is determined by theirorder in the input text.
This strategy can be adapted tomultidocument summarization.
Consider two themes, Th1and Th2; if sentences from Th1preceed sentences from Th2in all input texts, then presenting Th1before Th2is an ac-ceptable order.
But, when the order between sentences fromTh1and Th2varies from one text to another, this strategyis not valid anymore.
One way to dene the order betweenTh1and Th2is to adopt the order occuring in the majorityof the texts where Th1and Th2occur.
This strategy denesa pairwise order between themes.
However, this pairwise re-lation is not transitive; for example, given the themes Th1and Th2occuring in a text, Th2and Th3occuring in anothertext, and Th3and Th1occuring in a third text, there is aconict between the orders (Th1; Th2; Th3) and (Th3; Th1).Since transitivity is a necessary condition for a relation to becalled an order, this relation does not form a global order.We, therefore, have to expand this pairwise relation toa global order.
In other words, we have to nd a linearorder between themes which maximizes the agreement be-tween the orderings imposed by the input texts.
For eachpair of themes, Thiand Thj, we keep two counts, Ci;jandCj;i| Ci;jis the number of input texts in which sentencesfrom Thioccur before sentences from Thjand Cj;iis thesame for the opposite order.
The weight of a linear order(Thi1; : : : ; Thik) is dened as the sum of the counts for everypair Cil;im, such that il imand l; m 2 f1 : : : kg.
Statingthis problem in terms of a directed graph where nodes arethemes, and a vertex from Thito Thjhas for weight Ci;j,we are looking for a path with maximal weight which tra-verses each node exactly once.
Unfortunately this problemis NP-complete; this can be shown by reducing the travel-ing salesman problem to this problem.
Despite this fact, westill can apply this ordering, because typically the length ofthe output summary is limited to a small number of sen-tences.
For longer summaries, the approximation algorithmdescribed in [4] can be applied.
Figures 1 and 2 show ex-amples of produced summaries.The main problem with this strategy is that it can pro-duce several orderings with the same weight.
This happenswhen there is a tie between two opposite orderings.
In thissituation, this strategy does not provide enough constraintsto determine one optimal ordering; one order is chosen ran-domly among the orders with maximal weight.The man accused of rebombing two Manhattan subwaysin 1994 was convicted Thursday after the jury rejected thenotion that the drug Prozac led him to commit the crimes.He was found guilty of two counts of attempted murder,14 counts of rst-degree assault and two counts of criminalpossession of a weapon.In December 1994, Leary ignited rebombs on two Manhat-tan subway trains.
The second blast injured 50 people { 16seriously, including Leary.Leary wanted to extort money from the Transit Authority.The defense argued that Leary was not responsible for hisactions because of "toxic psychosis" caused by the Prozac.Figure 1: A summary produced using the Majority Or-dering algorithm, graded as Good.A man armed with a handgun has surrendered to Spanishauthorities, peacefully ending a hijacking of a Moroccan jet.O?cials in Spain say a person commandeered the plane.After the plane was directed to Spain, the hijacker said hewanted to be taken to Germany.After several hours of negotiations, authorities convincedthe person to surrender early today.Police said the man had a pistol, but a Moroccan securitysource in Rabat said the gun was likely a \toy".There were no reported injuries.O?cials in Spain say the Boeing 737 left Casablanca, Mo-rocco, Wednesday night with 83 passengers and a nine- per-son crew headed for Tunis, Tunisia.Spanish authorities directed the plane to an isolated sectionof El Prat Airport and o?cials began negotiations.Figure 2: A summary produced using the Majority Or-dering algorithm, graded as Poor.3.1.2 EvaluationWe asked three human judges to evaluate the order ofinformation in 20 summaries produced using the MO algo-rithm into three categories| Poor, Fair and Good.
We de-ne a Poor summary, in an operational way, as a text whosereadability would be signicantly improved by reordering itssentences.
A Fair summary is a text which makes sense butreordering of some sentences can yield a better readability.Finally, a summary which cannot be further improved byany sentence reordering is considered a Good summary.The judges were asked to grade the summaries taking onlyinto account the order in which the information is presented.To help them focus on this aspect of the texts, we resolveddangling references beforehand.
Figure 8 shows the gradesassigned to the summaries using majority to combine thejudges grades.
In our experiments, judges had strong agree-ment; they never gave three dierent grades to a summary.TheMO algorithm produces a small number of Good sum-maries, but most of the summaries were graded as Fair.
Forinstance, the summary graded Good shown in Figure 1 or-ders the information in a natural way; the text starts witha sentence summary of the event, then the outcome of thetrial is given, a reminder of the facts that caused the trialand a possible explanation of the facts.
Looking at the Goodsummaries produced by MO, we found that it performs wellwhen the input articles follow the same order when present-ing the information.
In other words, the algorithm producesa good ordering if the input articles orderings have highagreement.On the other hand, when analyzing Poor summaries, as inFigure 2, we observe that the input texts have very dierentorderings.
By trying to maximize the agreement of the inputtexts orderings, MO produces a new ordering that doesn'toccur in any input text.
The ordering is, therefore, not guar-anteed anymore to be acceptable.
An example of a new pro-duced ordering is given in Figure 2.
The summary would bemore readable if several sentences were moved around (thelast sentence would be better placed before the fourth sen-tence because they both talk about the Spanish authoritieshandling the hijacking).This algorithm can be used to order sentences accuratelyif we are certain that the input texts follow similar orga-nizations.
This assumption may hold in limited domains.However, in our case, the input texts we are processing donot have such regularities.
MO's performance critically de-pends on the quality of the input texts, therefore, we shoulddesign an ordering strategy which better ts our input data.From here on, we will focus only on the Chronological Or-dering algorithm and ways to improve it.3.2 Chronological Ordering3.2.1 The AlgorithmMultidocument summarization of news typically deals witharticles published on dierent dates, and articles themselvescover events occurring over a wide range in time.
Usingchronological order in the summary to describe the mainevents helps the user understand what has happened.
Itseems like a natural and appropriate strategy.
As mentionedearlier, in our framework, we are ordering themes; in thisstrategy, we therefore need to assign a date to themes.
Toidentify the date an event occured requires a detailed in-terpretation of temporal references in articles.
While therehave been recent developments in disambiguating temporalexpressions and event ordering [12], correlating events withthe date on which they occurred is a hard task.
In our case,we approximate the theme time by its rst publication date;that is, the rst time the theme has been reported in ourset of input articles.
It is an acceptable approximation fornews events; the rst publication date of an event usuallycorresponds to its occurrence in real life.
For instance, in aterrorist attack story, the theme conveying the attack itselfwill have a date previous to the date of the theme describinga trial following the attack.Articles released by news agencies are marked with a pub-lication date, consisting of a date and a time with three elds(hour, minutes and seconds).
Articles from the same newsagency are, then, guaranteed to have dierent publicationdates.
This also holds for articles coming from dierentnews agencies.
We never encountered two articles with thesame publication date during the development of MultiGen.Thus, the publication date serves as a unique identier overarticles.
As a result, when two themes have the same pub-lication date, it means that they both are reported for therst time in the same article.Our Chronological Ordering (CO) algorithm takes as in-put a set of themes and orders them chronologically when-ever possible.
Each theme is assigned a date correspondingto its rst publication.
This establishes a partial order overthe themes.
When two themes have the same date (that is,they are reported for the rst time in the same article) wesort them according to their order of presentation in this ar-ticle.
We have now a complete order over the input themes.To implement this algorithm in MultiGen, we select foreach theme the sentence that has the earliest publicationdate.
We call it the time stamp sentence and assign itspublication date as the time stamp of the theme.
Figures 3and 4 show examples of produced summaries using CO.One of four people accused along with former PakistaniPrime Minister Nawaz Sharif has agreed to testify againsthim in a case involving possible hijacking and kidnappingcharges, a prosecutor said Wednesday.Raja Quereshi, the attorney general, said that the formerCivil Aviation Authority chairman has already given a state-ment to police.Sharif's lawyer dismissed the news when speaking to re-porters after Sharif made an appearance before a judicialmagistrate to hear witnesses give statements against him.Sharif has said he is innocent.The allegations stem from an alleged attempt to diverta plane bringing army chief General Pervez Musharraf toKarachi from Sri Lanka on October 12.Figure 3: A summary produced using the ChronologicalOrdering algorithm graded as Good.Thousands of people have attended a ceremony in Nairobicommemorating the rst anniversary of the deadly bombingsattacks against U.S. Embassies in Kenya and Tanzania.Saudi dissidentOsama bin Laden, accused of mastermindingthe attacks, and nine others are still at large.President Clinton said, "The intended victims of this viciouscrime stood for everything that is right about our countryand the world".U.S.
federal prosecutors have charged 17 people in thebombings.Albright said that the mourning continues.Kenyans are observing a national day of mourning in honorof the 215 people who died there.Figure 4: A summary produced using the ChronologicalOrdering algorithm graded as Poor.3.2.2 EvaluationFollowing the same methodology we used for the MO al-gorithm evaluation, we asked three human judges to grade20 summaries generated by the system using the CO algo-rithm applied to the same collection of input texts.
Theresults are shown in Figure 8.Our rst suspicion was that our approximation deviatestoo much from the real chronological order of events, and,therefore, lowers the quality of sentence ordering.
To ver-ify this hypothesis, we identied sentences that broke theoriginal chronological order and restored the ordering man-ually.
Interestingly, the displaced sentences were mainlybackground information.
The evaluation of the modiedsummaries shows a slight but not visible improvement.When comparing Good (Figure 3) and Poor (Figure 4)summaries, we notice two phenomena: rst, many of thebadly placed sentences cannot be ordered based on theirtemporal occurence.
For instance, in Figure 4, the sentencequoting Clinton is not one event in the sequence of eventsbeing described, but rather a reaction to the main events.This is also true for the sentence reporting Albright's reac-tion.
Assigning a date to a reaction, or more generally toany sentence conveying background information, and plac-ing it into the chronological stream of the main events doesnot produce a logical ordering.
The ordering of these themesis therefore not covered by the CO algorithm.The second phenomenon we observed is that Poor sum-maries typically contain abrupt switches of topics and gen-eral incoherences.
For instance, in Figure 4, quotes from USo?cials (third and fth sentences) are split and sentencesabout the mourning (rst and sixth sentences) appear toofar apart in the summary.
Grouping them together wouldincrease the readability of the summary.
At this point, weneed to nd additional constraints to improve the ordering.4.
IMPROVING THE ORDERING:EXPERIMENTS AND ANALYSISIn the previous section, we showed that using naive or-dering algorithms does not produce satisfactory orderings.In this section, we investigate through experiments with hu-mans, how to identify patterns of orderings that can improvethe algorithm.Sentences in a text can be ordered in a number of ways,and the text as a whole will still convey the same meaning.But undoubtedly, some orders are denitely unacceptablebecause they break conventions of information presentation.One way to identify these conventions is to nd common-alities between dierent acceptable orderings of the sameinformation.
Extracting regularities in several acceptableorderings can help us specify the main ordering constraintsfor a given input type.
Since a collection of multiple sum-maries over the same set of articles doesn't exist, we createdour own collection of multiple orderings produced by dif-ferent humans.
Using this collection, we studied commonbehaviors and mapped them to strategies for ordering.Our collection of multiple orderings is available athttp://www.cs.columbia.edu/~noemie/ordering/.
It wasbuilt in the following way.
We collected ten sets of articles.Each set consisted of two to three news articles reporting thesame event.
For each set, we manually selected the inter-section sentences, simulating MultiGen1.
On average, eachset contained 8.8 intersection sentences.
The sentences werecleaned of explicit references (for instance, occurrences of\the President" were resolved to \President Clinton") andconnectives, so that participants wouldn't use them as cluesfor ordering.
Ten subjects participated in the experimentand they each built one ordering per set of intersection sen-tences.
Each subject was asked to order the intersection1We performed a manual simulation to ensure that idealdata was provided to the subjects of the experimentssentences of a set so that they form a readable text.
Over-all, we obtained 100 orderings, ten alternative orderings perset.
Figure 5 shows the ten alternative orderings collectedfor one set.We rst observe that a surprising majority of orderingsare dierent.
Out of the ten sets, only two sets had someidentical orderings (in one set, one pair of orderings wereidentical while in the other set, two pairs of orderings wereidentical).
In other words, there are many acceptable order-ings given one set of sentences.
This conrms the intuitionthat we do not need to look for a single ideal global orderingbut rather construct an acceptable one.We also notice that, within the multiple orderings of aset, some sentences always appear together.
They do notappear in the same order from one ordering to another, butthey share an adjacency relation.
From now on, we refer tothem as blocks.
For each set, we identify blocks by cluster-ing sentences.
We use as a distance metric between two sen-tences the average number of sentences that separate themover all orderings.
In Figure 5, for instance, the distancebetween the sentences D and G is 2.
The blocks identiedby clustering are: sentences B, D, G and I; sentences A andJ; sentences C and F; and sentences E and H.Participant 1 D B G I H F C J A EParticipant 2 D G B I C F A J E HParticipant 3 D B I G F J A E H CParticipant 4 D C F G I B J A H EParticipant 5 D G B I H F J A C EParticipant 6 D G I B F C E H J AParticipant 7 D B G I F C H E J AParticipant 8 D B C F G I E H A JParticipant 9 D G I B E H F A J CParticipant 10 D B G I C F A J E HFigure 5: Multiple orderings for one set in our collec-tion.We observed that all the blocks in the experiment cor-respond to clusters of topically related sentences.
Theseblocks form units of text dealing with the same subject, andexhibit cohesive properties.
For ordering, we can use this toopportunistically group sentences together that all refer tothe same topic.Collecting a set of multiple orderings is an expensive task;it is di?cult and time consuming for a human to order sen-tences from scratch.
Furthermore, to discover signicantcommonalities across orderings, many multiple orderings ofthe same set are necessary.
We plan to extend our collectionand we are condent that it will provide more insights onordering.
Still, the existing collection enables us to identifycohesion as an important factor for ordering.
We describenext how we integrate the cohesion constraint in the COalgorithm.5.
THE AUGMENTED ALGORITHMIn the output of the CO algorithm, disuencies arise whentopics are distributed over the whole text, violating cohesionproperties [13].
A typical scenario is illustrated in Figure 6.The inputs are texts T1, T2, T3(in order of publication).A1, A2and A3belong to the same theme whose intersectionsentence is A and similarly for B and C. The themes A andB are topically related, but C is not related.
Summary S1,based only on chronological clues, contains two topical shifts;from A to C and back from C to B.
A better summary wouldbe S2which keeps A and B together.AA C AB1 2 33C1...B22AC3 BC......T T T S1 2 3 1ACBS 2Figure 6: Input texts T1T2T3are summarized by theChronological Ordering (S1) or by the Augmented algo-rithm (S2).5.1 The AlgorithmOur goal is to remove disuencies from the summary bygrouping together topically related themes.
This can beachieved by integrating cohesion as an additional constraintto the CO algorithm.
The main technical di?culty in in-corporating cohesion in our ordering algorithm is to iden-tify and to group topically related themes across multipledocuments.
In other words, given two themes, we need todetermine if they belong to the same cohesion block.
For asingle document, segmentation [8] could be used to identifyblocks, but we cannot use such a technique to identify co-hesion between sentences across multiple documents.
Themain reason is that segmentation algorithms exploit the lin-ear structure of an input text; in our case, we want to grouptogether sentences belonging to dierent texts.Our solution consists of the following steps.
In a prepro-cessing stage, we segment each input text, so that given twosentences within the same text, we can determine if theyare topically related.
Assume the themes A and B, whereA contains sentences (A1: : :An), and B contains sentences(B1: : :Bm).
Recall that a theme is a set of sentences con-veying similar information drawn from dierent input texts.We denote #AB to be the number of pairs of sentences(Ai;Bj) which appear in the same text, and #AB+to bethe number of sentence pairs which appear in the same textand are in the same segment.In a rst stage, for each pair of themes A and B, we com-pute the ratio #AB+=#AB to measure the relatedness oftwo themes.
This measure takes into account both positiveand negative evidence.
If most of the sentences in A andB that appear together in the same texts are also in thesame segments, it means that A and B are highly topicallyrelated.
In this case, the ratio is close to 1.
On the otherhand, if among the texts containing sentences from A andB, only a few pairs are in the same segments, then A and Bare not topically related.
Accordingly the ratio is close to 0.A and B are considered related if this ratio is higher thana predetermined threshold.
In our experiments, we set it to0.6.This strategy denes pairwise relations between themes.A transitive closure of this relation builds groups of relatedthemes and as a result ensures that themes that do not ap-pear together in any article but are both related to a thirdtheme will still be linked.
This creates an even higher degreeof relatedness among themes.
Because we use a thresholdto establish pairwise relations, the transitive closure doesnot produce elongated chains that could link together unre-lated themes.
We are now able to identify topically relatedthemes.
At the end of the rst stage, they are grouped intoblocks.In a second stage, we assign a time stamp to each block ofrelated themes, as the earliest time stamp of the themes itcontains.
We adapt the CO algorithm described in 3.2.1 towork at the level of the blocks.
The blocks and the themescorrespond to, respectively, themes and sentences in the COalgorithm.
By analogy, we can easily show that the adaptedalgorithm produces a complete order of the blocks.
Thisyields a macro-ordering of the summary.
We still need toorder the themes inside each block.In the last stage of the augmented algorithm, for eachblock, we order the themes it contains by applying the COalgorithm to them.
Figure 7 shows an example of a summaryproduced by the augmented algorithm.This algorithm ensures that cohesively related themes willnot be spread over the text, and decreases the number ofabrupt switches of topics.
Figure 7 shows how the Aug-mented algorithm improves the sentence order comparedwith the order in the summary produced by the CO al-gorithm in Figure 4; sentences quoting US o?cials are nowgrouped together and so are descriptions of the mourning.Thousands of people have attended a ceremony in Nairobicommemorating the rst anniversary of the deadly bomb-ings attacks against U.S. Embassies in Kenya and Tanzania.Kenyans are observing a national day of mourning in honorof the 215 people who died there.Saudi dissidentOsama bin Laden, accused of mastermindingthe attacks, and nine others are still at large.
U.S. federalprosecutors have charged 17 people in the bombings.President Clinton said, "The intended victims of this viciouscrime stood for everything that is right about our countryand the world".
Albright said that the mourning continues.Figure 7: A Summary produced using the Aug-mented algorithm.
Related sentences are groupedinto paragraphs.5.2 EvaluationFollowing the same methodology used to evaluate the MOand the CO algorithms, we asked the judges to grade 20summaries produced by the Augmented algorithm.
Resultsare shown in Figure 8.The manual eort needed to compare and judge systemoutput is extensive; consider that each human judge had toread three summaries for each input set as well as skim theinput texts to verify that no misleading order was introducedin the summaries.
Consequently, the evaluation that weperformed to date is limited.
Still, this evaluation shows asignicant improvement in the quality of the orderings fromthe CO algorithm to the augmented algorithm.
To assess thesignicance of the improvement, we used the Fisher exacttest, conating Poor and Fair summaries into one category.This test is adapted to our case because of the reduced sizeof our test set.
We obtained a p value of 0.014 [20].6.
RELATED WORKFinding an acceptable ordering has not been studied be-fore in summarization.
In single document summarization,Poor Fair GoodMajority Ordering 2 12 6Chronological Ordering 7 7 6Augmented Ordering 2 7 11Figure 8: Evaluation of the the Majority Ordering, theChronological Ordering and the Augmented Ordering.summary sentences are typically arranged in the same orderthat they were found in the full document (although [10]reports that human summarizers do sometimes change theoriginal order).
In multidocument summarization, the sum-mary consists of fragments of text or sentences that wereselected from dierent texts.
Thus, there is no completeordering of summary sentences that can be found in theoriginal documents.The ordering task has been extensively investigated in thegeneration community [14, 17, 9, 2, 16].
One approach istop-down, using schemas [14] or plans [5] to determine theorganizational structure of the text.
This appproach postu-lates a rhetorical structure which can be used to select in-formation from an underlying knowledge base.
Because thedomain is limited, an encoding can be developed of the kindsof propositional content that match rhetorical elements ofthe schema or plan, thereby allowing content to be selectedand ordered.
Rhetorical Structure Theory (RST) allows formoreexibility in ordering content.
The relations occur be-tween pairs of propositions.
Constraints based on intention(e.g., [17]), plan-like conventions [9], or stylistic constraints[2] are used as preconditions on the plan operators contain-ing RST relations to determine when a relation is used andhow it is ordered with respect to other relations.MultiGen generates summaries of news on any topic.
Inan unconstrained domain like this, it would be impossibleto enumerate the semantics for all possible types of sen-tences which could match the elements of a schema, a planor rhetorical relations.
Furthermore, it would be di?cult tospecify a generic rhetorical plan for a summary of news.
In-stead, content determination in MultiGen is opportunistic,depending on the kinds of similarities that happen to existbetween a set of news documents.
Similarly, we describehere an ordering scheme that is opportunistic and bottom-up, depending on the coherence and temporal connectionsthat happen to exist between selected text.
Our approachis similar to the use of basic blocks [16] where a bottom-uptechnique is used to group together stretches of text in along, generated document by nding propositions that arerelated by a common focus.
Since this approach was devel-oped for a generation system, it nds related propositions bycomparisons of proposition arguments at the semantic level.In our case, we are dealing with a surface representation, sowe nd alternative methods for grouping text fragments.7.
CONCLUSION AND FUTURE WORKIn this paper we investigated information ordering con-straints in multidocument summarization.
We analyzed twonaive ordering algorithms, the Majority Ordering (MO) andthe Chronological Ordering (CO).
We show that the MO al-gorithm performs well only when all input texts follow sim-ilar presentation of the information.
The CO algorithm canprovide an acceptable solution for many cases, but is notsu?cient when summaries contain information that is notevent based.
We report on the experiments we conductedto identify other constraints contributing to ordering.
Weshow that cohesion is an important factor, and describe anoperational way to incorporate it in the CO algorithm.
Thisresults in a denite improvement of the overall quality of au-tomatically generated summaries.In future work, we rst plan to extend our collection ofmultiple orderings, so that we can extract more regulari-ties and understand better how human order information toproduce a readable anduent text.
Even though we didnot encounter any misleading inferences introduced by re-ordering MultiGen output, we plan to do an extended studyof the side eects caused by reorderings.
We also plan toinvestigate whether the MO algorithm can be improved byapplying it on cohesive blocks of themes, rather than themes.8.
ACKNOWLEDGMENTThis work was partially supported by DARPA grant N66001-00-1-8919, a Louis Morin scholarship and a Viros scholar-ship.
We thank Eli Barzilay for providing help with theexperiments interface, Michael Elhadad for the useful dis-cussions and comments, and all the voluntary participantsin the experiments.9.
REFERENCES[1] R. Barzilay, K. McKeown, and M. Elhadad.Information fusion in the context of multi-documentsummarization.
In Proc.
of the 37th Annual Meetingof the Assoc.
of Computational Linguistics, 1999.
[2] N. Bouayad-Agha, R. Power, and D. Scott.
Can textstructure be incompatible with rhetorical structure?In Proceedings of the First International Conferenceon Natural Language Generation (INLG'2000),Mitzpe Ramon, Israel, 2000.
[3] J. Carbonell and J. Goldstein.
The use of mmr,diversity-based reranking for reordering documentsand producing summaries.
In Proceedings of the 21stAnnual International ACM SIGIR Conference onResearch and Development in Information Retrieval,1998.
[4] T. Cormen, C. Leiserson, and R. Rivest.
Introductionto Algorithms.
The MIT Press, 1990.
[5] R. Dale.
Generating Referring Expressions:Constructing Descriptions in a Domain of Objects andProcesses.
MIT Press, Cambridge, MA, 1992.
[6] N. Elhadad and K. McKeown.
Generating patientspecic summaries of medical articles.
Submitted,2001.
[7] V. Hatzivassiloglou, J. Klavans, and E. Eskin.Detecting text similarity over short passages:Exploring linguistic feature combinations via machinelearning.
In Proceedings of the Joint SIGDATConference on Empirical Methods in NaturalLanguage Processing and Very Large Corpora, 1999.
[8] M. Hearst.
Multi-paragraph segmentation ofexpository text.
In Proceedings of the 32th AnnualMeeting of the Association for ComputationalLinguistics, 1994.
[9] E. Hovy.
Automated discourse generation usingdiscourse structure relations.
Articial Intelligence, 63,1993.
Special Issue on NLP.
[10] H. Jing.
Summary generation through intelligentcutting and pasting of the input document.
Technicalreport, Columbia University, 1998.
[11] I. Mani and E. Bloedorn.
Multi-documentsummarization by graph search and matching.
InProceedings of the Fifteenth National Conference onArticial Intelligence, 1997.
[12] I. Mani and G. Wilson.
Robust temporal processing ofnews.
In Proceedings of the 38th Annual Meeting ofthe Association for Computational Linguistics, 2000.
[13] K. McCoy and J. Cheng.
Focus of attention:Constraining what can be said next.
In C. Paris,W.
Swartout, and W. Mann, editors, NaturalLanguage Generation in Articial Intelligence andComputational Linguistics.
Kluwer AcademicPublishers, 1991.
[14] K. McKeown.
Text Generation: Using DiscourseStrategies and Focus Constraints to Generate NaturalLanguage Text.
Cambridge University Press, England,1985.
[15] K. McKeown, J. Klavans, V. Hatzivassiloglou,R.
Barzilay, and E. Eskin.
Towards multidocumentsummarization by reformulatin: Progress andprospects.
In Proceedings of the Seventeenth NationalConference on Articial Intelligence, 1999.
[16] D. Mooney, S. Carberry, and K. McCoy.
Thegeneration of high-level structure for extendedexplanations.
In Proceedings of the InternationalConference on Computational Linguistics(COLING{90), pages 276{281, Helsinki, 1990.
[17] J. Moore and C. Paris.
Planning text for advisorydialogues: Capturing intentional and rhetoricalinformation.
Journal of Computational Linguistics,19(4), 1993.
[18] D. Radev, H. Jing, and M. Budzikowska.Centroid-based summarization of multiple documents:sentence extraction, utility-based evaluation, and userstudies.
In Proceedings of the ANLP/NAACL 2000Workshop on Automatic Summarization, 2000.
[19] D. Radev and K. McKeown.
Generating naturallanguage summaries from multiple on-line sources.Computational Linguistics, 24(3):469{500, September1998.
[20] S. Siegal and N. J. Castellan.
Non-Parametricstatistics for the behavioural sciences.
McGraw Hill,1988.
