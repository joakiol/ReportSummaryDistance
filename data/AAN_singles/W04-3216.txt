A Phrase-Based HMM Approach to Document/Abstract AlignmentHal Daume?
III and Daniel MarcuInformation Sciences InstituteUniversity of Southern California4676 Admiralty Way, Suite 1001Marina del Rey, CA 90292{hdaume,marcu}@isi.eduAbstractWe describe a model for creating word-to-word andphrase-to-phrase alignments between documentsand their human written abstracts.
Such alignmentsare critical for the development of statistical sum-marization systems that can be trained on large cor-pora of document/abstract pairs.
Our model, whichis based on a novel Phrase-Based HMM, outper-forms both the Cut & Paste alignment model (Jing,2002) and models developed in the context of ma-chine translation (Brown et al, 1993).1 IntroductionThere are a wealth of document/abstract pairs thatstatistical summarization systems could leverage tolearn how to create novel abstracts.
Detailed stud-ies of such pairs (Jing, 2002) show that human ab-stractors perform a range of very sophisticated op-erations when summarizing texts, which include re-ordering, fusion, and paraphrasing.
Unfortunately,existing document/abstract alignment models arenot powerful enough to capture these operations.To get around directly tackling this problem, re-searchers in text summarization have employed oneof several techniques.Some researchers (Banko et al, 2000) have de-veloped simple statistical models for aligning doc-uments and headlines.
These models, which imple-ment IBM Model 1 (Brown et al, 1993), treat docu-ments and headlines as simple bags of words andlearn probabilistic word-based mappings betweenthe words in the documents and the words in theheadlines.
As our results show, these models aretoo weak for capturing the operations that are em-ployed by humans in summarizing texts beyond theheadline level.Other researchers have developed models thatmake unreasonable assumptions about the data,which lead to the utilization of a very small per-cent of available data.
For instance, the docu-ment and sentence compression models of Daume?III, Knight, and Marcu (Knight and Marcu, 2002;Daume?
III and Marcu, 2002a) assume that sen-tences/documents can be summarized only throughdeletion of contiguous text segments.
Knight andMarcu found that from a corpus of 39, 060 abstractsentences, only 1067 sentence extracts existed: a re-call of only 2.7%.An alternate techinque employed in a large vari-ety of systems is to treat the summarization prob-lem as a sentence extraction problem.
Such sys-tems can be trained either on human constructed ex-tracts or extracts generated automatically from doc-ument/abstract pairs (see (Marcu, 1999; Jing andMcKeown, 1999) for two such approaches).None of these techniques is adequate.
Even for arelatively simple sentence from an abstract, we cansee that none of the assumptions listed above holds.In Figure 1, we observe several phenomena:?
Alignments can occur at the granularity ofwords and at the granularity of phrases.?
The ordering of phrases in an abstract can bedifferent from the ordering in the document.?
Some abstract words do not have direct cor-respondents in the document, and some doc-ument words are never used.It is thus desirable to be able to automaticallyconstruct alignments between documents and theirabstracts, so that the correspondences between thepairs are obvious.
One might be initially temptedto use readily-available machine translation systemslike GIZA++ (Och and Ney, 2003) to perform suchConnecting Point has become the single largest Mac retailer after tripling it ?s Macintosh sales since January 1989 .Connecting Point Systems tripled it ?s sales of Apple Macintosh systems since last January .
It is now the single largest seller of Macintosh .Figure 1: Example abstract/text alignment.alignments.
However, as we will show, the align-ments produced by such a system are inadequate forthis task.The solution that we propose to this problem isan alignment model based on a novel mathematicalstructure we call the Phrase-Based HMM.2 Designing a ModelAs observed in Figure 1, our model needs to be ableto account for phrase-to-phrase alignments.
It alsoneeds to be able to align abstract phrases with arbi-trary parts of the document, and not require a mono-tonic, left-to-right alignment.12.1 The Generative StoryThe model we propose calculates the probability ofan alignment/abstract pair in a generative fashion,generating the summary S = ?s1 .
.
.
sm?
from thedocument D = ?d1 .
.
.
dn?.In a document/abstract corpus that we havealigned by hand (see Section 3), we have observedthat 16% of abstract words are left unaligned.
Ourmodel assumes that these ?null-generated?
wordsand phrases are produced by a unique documentword ?, called the ?null word.?
The parame-ters of our model are stored in two tables: arewrite/paraphrase table and a jump table.
Therewrite table stores probabilities of producing sum-mary words/phrases from document words/phrasesand from the null word (namely, probabilities of theform rewrite(s?
d?
)and rewrite (s?
?
)); the jump ta-ble stores the probabilities of moving within a doc-ument from one position to another, and from andto ?.The generation of a summary from a document isassumed to proceed as follows:1In the remainder of the paper, we will use the words ?sum-mary?
and ?abstract?
interchangeably.
This is because we wishto use the letter s to refer to summaries.
We could use the lettera as an abbreviation for ?abstract?
; however, in the definitionof the Phrase-Based HMM, we reuse common notation whichascribes a different interpretation to a.1.
Choose a starting index i and jump to po-sition di in the document with probabilityjump (i).
(If the first summary phrase is null-generated, jump to the null-word with proba-bility jump (?).)2.
Choose a document phrase of length k ?
0 anda summary phrase of length l ?
1.
Generatesummary words sl1 from document words di+kiwith probability rewrite(sl1 di+ki).23.
Choose a new document index i?
andjump to position di?
with probabilityjump (i?
?
(i + k)) (or, if the new documentposition is the empty state, then jump (?)).4.
Choose k?
and l?
as in step 2, and gener-ate the summary words s1+l+l?1+l from thedocument words di?+k?i?
with probabilityrewrite(s1+l+l?1+l di?+k?i?).5.
Repeat from step 3 until the entire summaryhas been generated.6.
Jump to position dn+1 in the document withprobability jump (n + 1 ?
(i?
+ k?
)).Note that such a formulation allows the samedocument word/phrase to generate many summarywords: unlike machine translation, where such be-havior is typically avoided, in summarization, weobserve that such phenomena do occur.
However,if one were to build a decoder based on this model,one would need to account for this issue to avoiddegenerate summaries from being produced.The formal mathematical model behind the align-ments is as follows: An alignment ?
defines botha segmentation of the summary S and a mappingfrom the segments of S to the segments of the doc-ument D. We write si to refer to the ith segment ofS, and M to refer to the total number of segments2We write xba for the subsequence ?xa .
.
.
xb?.in S. We write d?
(i) to refer to the words in thedocument which correspond to segment si.
Then,the probability of a summary/alignment pair given adocument (Pr (S,?
D)), becomes:M+1?i=1(jump (?
(i) ?
(i ?
1)) rewrite (si d?
(i)))Here, we implicitly define sm+1 to be the end-of-document token ???
and d?
(m+1) to generate thiswith probability 1.
We also define the initial posi-tion in the document, ?
(0) to be 0, and assume auniform prior on segmentations.2.2 The Mathematical ModelHaving decided to use this model, we must nowfind a way to efficiently train it.
The model is verymuch like a Hidden Markov Model in which thesummary is the observed sequence.
However, us-ing a standard HMM would not allow us to accountfor phrases in the summary.
We therefore extenda standard HMM to allow multiple observations tobe emitted on one transition.
We call this model aPhrase-Based HMM (PBHMM).For this model, we have developed equiva-lents of the forward and backward algorithms,Viterbi search and forward-backward parameter re-estimation.
Our notation is shown in Table 1.Here, S is the state space, and the observation se-quences come from the alphabet K .
pij is the prob-ability of beginning in state j.
The transition prob-ability ai,j is the probability of transitioning fromstate i to state j. bi,j,k?
is the probability of emitting(the non-empty) observation sequence k?
while tran-sitioning from state i to state j.
Finally, xt denotesthe state after emitting t symbols.The full derivation of the model is too lengthy toinclude; the interested reader is directed to (Daume?III and Marcu, 2002b) for the derivations and proofsof the formulae.
To assist the reader in understand-ing the mathematics, we follow the same notation as(Manning and Schutze, 2000).
The formulae for thecalculations are summarized in Table 2.2.2.1 Forward algorithmThe forward algorithm calculates the probability ofan observation sequence.
We define ?j(t) as theprobability of being in state j after emitting the firstt ?
1 symbols (in whatever grouping we want).2.2.2 Backward algorithmJust as we can compute the probability of an obser-vation sequence by moving forward, so can we cal-culate it by going backward.
We define ?i(t) as theprobability of emitting the sequence oTt given thatwe are starting out in state i.2.2.3 Best pathWe define a path as a sequence P = ?p1 .
.
.
pL?
suchthat pi is a tuple ?t, x?
where t corresponds to thelast of the (possibly multiple) observations made,and x refers to the state we were coming from whenwe output this observation (phrase).
Thus, we wantto find:argmaxPPr(P oT1 , ?
)= argmaxPPr(P, oT1 ?
)To do this, as in a traditional HMM, we estimatethe ?
table.
When we calculate ?j(t), we essentiallyneed to choose an appropriate i and t?, which westore in another table, so we can calculate the actualpath at the end.2.2.4 Parameter re-estimationWe want to find the model ?
which best explainsobservations.
There is no known analytic solutionfor standard HMMs, so we are fairly safe in assum-ing that we will not find an analytic solution for thismore complex problem.
Thus, we also revert to aniterative hill-climbing solution analogous to Baum-Welch re-estimation (i.e., the Forward Backward al-gorithm).
The equations for the re-estimated valuesa?
and b?
are shown in Table 2.2.2.5 Dirichlet PriorsUsing simple maximum likelihood estimation is in-adequate for this model: the maximum likelihoodsolution is simply to make phrases as long as pos-sible; unfortunately, doing so will first cut down onthe number of probabilities that need to be multi-plied and second make nearly all observed summaryphrase/document phrase alignments unique, thus re-sulting in rewrite probabilities of 1 after normaliza-tion.
In order to account for this, instead of findingthe maximum likelihood solution, we instead seekthe maximum a posteriori solution.The distributions we deal with in HMMs, and,in particular, PBHMMs, are all multinomial.
TheDirichlet distribution is in the conjugate family tothe multinomial distribution3 .
This makes Dirich-let priors very appealing to work with, so long as3This effectively means that the product of a Dirichlet andmultinomial yields a multinomial.S set of statesK output alphabet?
= {pij : j ?
S} initial state probabilitiesA = {ai,j : i, j ?
S} transition probabilitiesB = {bi,j,k?
: i, j ?
S, k?
?
K+} emission probabilitiesTable 1: Notation used for the PBHMM?j(t) = Pr(ot?11 , xt?1 = j ?)=t?1?t?=0?i?S(?i(t?
+ 1) ?
ai,j ?
bi,j,ott?+1)?i(t) = Pr(oTt ?, xt?1 = i)=T?t?=t?j?S(ai,j ?
bi,j,ot?t ?
?j(t?
+ 1))?j(t) = maxl,pl?11Pr(pl?11 , ot?11 , pl.t = t ?
1, pl.x = j ?
)= ?i(t?)ai,jbi,j,ot?1t?
?i,j(t?, t) = E[# of transitions i ; j emitting ott?]=?i(t?)ai,jbi,j,ott?
?j(t + 1)Pr(oT1 ?
)a?i,j =E [# of transitions i ; j]E [# of transitions i ;?]
=?Tt?=1?Tt=t?
?i,j(t?, t)?Tt?=1?Tt=t??j?
?S ?i,j?
(t?, t)b?i,j,k?
=E[# of transitions i ; j with k?
observed]E [# of transitions i ; j] =?T+1?|k?|t=1 ?
(k?, ot+|k?|?1t )?i,j(t, t + |k?| ?
1)?Tt?=1?Tt=t?
?i,j(t?, t)Table 2: Summary of equations for a PBHMMwe can adequately express our prior beliefs in theirform.
(See (Gauvain and Lee, 1994) for the appli-cation to standard HMMs.
)Applying a Dirichlet prior effectively allows us toadd ?fake counts?
during parameter re-estimation,according to the prior.
The prior we choose has aform such that fake counts are added as follows:word-to-word rewrites get an additional count of 2;identity rewrites get an additional count of 4; stem-identity rewrites get an additional count of 3.2.3 Constructing the PBHMMGiven our generative story, we construct a PBHMMto calculate these probabilities efficiently.
Thestructure of the PBHMM for a given document isconceptually simple.
We provide values for each ofthe following: the set of possible states S; the out-put alphabet K; the initial state probabilities ?
; thetransition probabilities A; and the emission proba-bilities B.2.3.1 State SpaceThe state set is large, but structured.
There is aunique initial state p, a unique final state q, and astate for each possible document phrase.
That is, forall 1 ?
i ?
i?
?
n, there is a state that correspondsto the document phrase beginning at position i andending at position i?, di?i , which we will refer to asri,i?
.
There is also a null state for each document po-sition r   ,i, so that when jumping out of a null state,we can remember what our previous position in thedocument was.
Thus, S = {p, q} ?
{ri,i?
: 1 ?
i ?i?
?
n} ?
{r   ,i : 1 ?
i ?
n}.
Figure 2 shows theschematic drawing of the PBHMM constructed forthe document ?a b?.
K , the output alphabet, con-sists of each word found in S, plus the token ?.2.3.2 Initial State ProbabilitiesFor initial state probabilities: since p is our initialstate, we say that pip = 1 and that pir = 0 for allr 6= p.2.3.3 Transition ProbabilitiesThe transition probabilities A are governed by thejump table.
Each possible jump type and it?s as-sociated probability is shown in Table 3.
By thesecalculations, regardless of document phrase lengths,transitioning forward between two consecutive seg-ments will result in jump (1).
When transitioningjump(2)jump(1)jump(1)jump(0)jump(2)jump(1)jump(2)jump(0)jump(1)baabbqpjump(1)jump(   )aFigure 2: Schematic drawing of the PBHMM (with some transition probabilities) for the document ?a b?source target probabilityp ri,i?
jump (i)ri,i?
rj,j?
jump (j ?
i?)ri,j?
q jump (m + 1 ?
i?
)p r   ,i jump (?)
jump (i)r   ,i rj,j?
jump (j ?
i)r   ,i r   ,j jump (?)
jump (j ?
i)r   ,i q jump (m + 1 ?
i)ri,i?
r   ,j jump (?)
jump (j ?
i?
)Table 3: Jump probability decompositionfrom p to ri,i?
, the value ap,ri,i?
= jump (i).
Thus,if we begin at the first word in the document, weincur a transition probability of jump (1).
There areno transitions into p.2.3.4 Rewrite ProbabilitiesJust as the transition probabilities are governed bythe jump table, the emission probabilities B aregoverned by the rewrite table.
In general, we writebx,y,k?
to mean the probability of generating k?
whiletransitioning from state x to state y.
However, inour case we do not need the x parameter, so wewill refer to these as bj,k?, the probability of generat-ing k?
when jumping into state j.
When j = ri,i?
,this is rewrite(k?
di?i).
When j = r   ,i, this isrewrite(k?
?).
Finally, any state transitioning intoq generates the phrase ???
with probability 1 andany other phrase with probability 0.Consider again the document ?a b?
(the PBHMMfor which is shown in Figure 2) in the case whenthe corresponding summary is ?c d?.
Suppose thecorrect alignment is that ?c d?
is aligned to ?a?
and?b?
is left unaligned.
Then, the path taken throughthe PBHMM is p ?
a ?
q.
During the transi-tion p ?
a, ?c d?
is emitted.
During the transitiona ?
q, ?
is emitted.
Thus, the probability for thealignment is: jump (1) rewrite (?cd?
?a?)
jump (2).The rewrite probabilities themselves are gov-erned by a mixture model with unknown mixing pa-rameters.
There are three mixture component, eachof which is represented by a multinomial.
The firstis the standard word-for-word and phrase-for-phrasetable seen commonly in machine translation, whererewrite(s?
d?
)is simply a normalized count of howmany times we have seen s?
aligned to d?.
The sec-ond is a stem-based table, in which suffixes (usingPorter?s stemmer) of the words in s?
and d?
are thrownout before a comparison is made.
The third is asimple identity function, which has a constant zerovalue when s?
and d?
are different (up to stem) anda constant non-zero value when they have the samestem.
The mixing parameters are estimated simul-taneously during EM.2.3.5 Parameter InitializationInstead of initializing the jump and rewrite tablesrandomly or uniformly, as it typically done withHMMs, we initialize the tables according to the dis-tribution specified by the prior.
This is not atypi-cal practice in problems in which a MAP solution issought.3 Evaluation and ResultsIn this section, we describe an intrinsic evaluation ofthe PBHMM document/abstract alignment model.All experiments in this paper are done on the Ziff-Davis corpus (statistics are in Table 4).
In orderto judge the quality of the alignments produced bya system, we first need to create a set of ?goldstandard?
alignments.
Two human annotators man-ually constructed such alignments between docu-ments and their abstracts.
Software for assisting thisprocess was developed and is made freely available.An annotation guide, which explains in detail thedocument/abstract alignment process was also pre-pared and is freely available.44Both the software and documentation are available on thefirst author?s web page.
The alignments are also available; con-tact the authors for a copy.Abstracts ExtractsDocuments 2033Sentences 13k 41kWords 261k 1mTypes 14k 26k29kSentences/Doc 6.28 21.51Words/Doc 128.52 510.99Words/Sent 20.47 23.77Table 4: Ziff-Davis extract corpus statistics3.1 Human AnnotationFrom the Ziff-Davis corpus, we randomly selected45 document/abstract pairs and had both annotatorsalign them.
The first five were annotated separatelyand then discussed; the last 40 were done indepen-dently.Annotators were asked to perform phrase-to-phrase alignments between abstracts and documentsand to classify each alignment as either possible Por sure S, where P ?
S. In order to calculatescores for phrase alignments, we convert all phrasealignments to word alignments.
That is, if we havean alignment between phrases A and B, then thisinduces word alignments between a and b for allwords a ?
A and b ?
B.
Given an alignment A,we could calculate precision and recall as (see (Ochand Ney, 2003)):Precision = |A?P ||A| Recall =|A?S||S|One problem with these definitions is that phrase-based models are fond of making phrases.
That is,when given an abstract containing ?the man?
and adocument also containing ?the man,?
a human mayprefer to align ?the?
to ?the?
and ?man?
to ?man.
?However, a phrase-based model will almost alwaysprefer to align the entire phrase ?the man?
to ?theman.?
This is because it results in fewer probabili-ties being multiplied together.To compensate for this, we define soft precision(SoftP in the tables) by counting alignments where?a b?
is aligned to ?a b?
the same as ones in which?a?
is aligned to ?a?
and ?b?
is aligned to ?b.?
Note,however, that this is not the same as ?a?
aligned to?a b?
and ?b?
aligned to ?b?.
This latter alignmentwill, of course, incur a precision error.
The soft pre-cision metric induces a new, soft F-Score, labeledSoftF.Often, even humans find it difficult to align func-tion words and punctuation.
A list of 58 functionwords and punctuation marks which appeared in thecorpus (henceforth called the ignore-list) was as-sembled.
Agreement and precision/recall have beencalculated both on all words and on all words thatdo not appear in the ignore-list.Annotator agreement was strong for Sure align-ments and fairly weak for Possible alignments (con-sidering only the 40 independently annotated pairs).When considering only Sure alignments, the kappastatistic (over 7.2 million items, 2 annotators and 2categories) for agreement was 0.63.
When wordsfrom the ignore-list were thrown out, this rose to0.68.
Carletta (1995) suggests that kappa valuesover 0.80 reflect very strong agreement and thatkappa values between 0.60 and 0.80 reflect goodagreement.3.2 Machine Translation ExperimentsIn order to establish a baseline alignment model,we used the IBM Model 4 (Brown et al, 1993)and the HMM model (Stephan Vogel and Tillmann,1996) as implemented in the GIZA++ package (Ochand Ney, 2003).
We modified this slightly to allowlonger inputs and higher fertilities.Such translation models require that input be insentence-aligned form.
In the summarization task,however, one abstract sentence often correspondsto multiple document sentences.
In order to over-come this problem, each sentence in an abstract waspaired with three sentences from the correspondingdocument, selected using the techniques describedby Marcu (1999).
In an informal evaluation, 20 suchpairs were randomly extracted and evaluated by ahuman.
Each pair was ranked as 0 (document sen-tences contain little-to-none of the information inthe abstract sentence), 1 (document sentences con-tain some of the information in the abstract sen-tence) or 2 (document sentences contain all of theinformation).
Of the twenty random examples, nonewere labeled as 0; five were labeled as 1; and 15were labeled as 2, giving a mean rating of 1.75.We ran experiments using the document sen-tences as both the source and the target languagein GIZA++.
When document sentences were usedas the target language, each abstract word neededto produce many document words, leading to veryhigh fertilities.
However, since each target word isgenerated independently, this led to very flat rewritetables and, hence, to poor results.
Performance in-creased dramatically by using the document as thesource language and the abstract as the target lan-guage.In all MT cases, the corpus was appended withone-word sentence pairs for each word where thatword is translated as itself.
In the two basic mod-els, HMM and Model 4, the abstract sentence is thesource language and the document sentences are thetarget language.
To alleviate the fertility problem,we also ran experiments with the translation goingin the opposite direction.
These are called HMM-flipped and Model 4-flipped, respectively.
Thesetend to out-perform the original translation direc-tion.
In all of these setups, 5 iterations of Model1 were run, followed by 5 iterations of the HMMmodel.
In the Model 4 cases, 5 iterations of Model4 were run, following the HMM.3.3 Cut and Paste ExperimentsWe also tested alignments using the Cut andPaste summary decomposition method (Jing, 2002),based on a non-trainable HMM.
Briefly, the Cut andPaste HMM searches for long contiguous blocks ofwords in the document and abstract that are iden-tical (up to stem).
The longest such sequences arealigned.
By fixing a length cutoff of n and ignoringsequences of length less than n, one can arbitrarilyincrease the precision of this method.
We found thatn = 2 yields the best balance between precision andrecall (and the highest F-measure).
The results ofthese experiments are shown under the header ?Cut& Paste.?
It clearly outperforms all of the MT-basedmodels.3.4 PBHMM ExperimentsWhile the PBHMM is based on a dynamic program-ming algorithm, the effective search space in thismodel is enormous, even for moderately sized doc-ument/abstract pairs.
We selected the 2000 shortestdocument/abstract pairs from the Ziff-Davis corpusfor training; however, only 12 of the hand-annotateddocuments were included in this set, so we addition-ally added the other 33 hand-annotate documents tothis set, yielding 2033 document/abstract pairs.
Wethen performed sentence extraction on this corpusexactly as in the MT case, using the technique of(Marcu, 1999).
The relevant data for this corpus isin Table 4.
We also restrict the state-space with abeam, sized at 50% of the unrestricted state-space.The PBHMM system was then trained on this ab-stract/extract corpus.
The precision/recall resultsare shown in Table 5.
Under the methodology forcombining the two human annotations by taking theunion, either of the human scores would achieve aSystem SoftP Recall SoftFHuman1 0.727 0.746 0.736Human2 0.680 0.695 0.687HMM 0.120 0.260 0.164Model 4 0.117 0.260 0.161HMM-flipped 0.295 0.250 0.271Model 4-flipped 0.280 0.247 0.262Cut & Paste 0.349 0.379 0.363PBHMM 0.456 0.686 0.548PBHMM O 0.523 0.686 0.594Table 5: Results on the Ziff-Davis corpusprecision and recall of 1.0.
To give a sense of howwell humans actually perform on this task (in addi-tion to the kappa scores reported earlier), we com-pare each human against the other.One common precision mistake made by thePBHMM system is to accidentally align words onthe summary side to words on the document side,when the summary word should be null-aligned.The PBHMMO system is an oracle system in whichsystem-produced alignments are removed for sum-mary words that should be null-aligned (accordingto the hand-annotated data).
Doing this results in arather significant gain in SoftP score.As we can see from Table 5, none of the ma-chine translation models is well suited to this task,achieving, at best, an F-score of 0.298.
The Cut &Paste method performs significantly better, which isto be expected, since it is designed specifically forsummarization.
As one would expect, this methodachieves higher precision than recall, though not byvery much.
Our method significantly outperformsboth the IBM models and the Cut & Paste method,achieving a precision of 0.456 and a recall nearing0.7, yielding an overall F-score of 0.548.4 Conclusions and Future WorkDespite the success of our model, it?s performancestill falls short of human performance (we achievean F-score of 0.548 while humans achieve 0.736).Moreover, this number for human performance isa lower-bound, since it is calculated with only onereference, rather than two.We have begun to perform a rigorous error anal-ysis of the model to attempt to identify its deficien-cies: currently, these appear to primarily be due tothe model having a zeal for aligning identical words.This happens for one of two reasons: either a sum-mary word should be null-aligned (but it is not),or a summary word should be aligned to a differ-ent, non-identical document word.
We can see thePBHMMO model as giving us an upper bound onperformance if we were to fix this first problem.
Thesecond problem has to do either with synonyms thatdo not appear frequently enough for the system tolearn reliable rewrite probabilities, or with corefer-ence issues, in which the system chooses to align,for instance, ?Microsoft?
to ?Microsoft,?
rather than?Microsoft?
to ?the company,?
as might be correctin context.
Clearly more work needs to be doneto fix these problems; we are investigating solvingthe first problem by automatically building a list ofsynonyms from larger corpora and using this in themixture model, and the second problem by inves-tigating the possibility of including some (perhapsweak) coreference knowledge into the model.Finally, we are looking to incorporate the resultsof this model into a real system.
This can be done ei-ther by using the word-for-word alignments to auto-matically build sentence-to-sentence alignments fortraining a sentence extraction system (in which casethe precision/recall numbers over full sentences arelikely to be much higher), or by building a systemthat exploits the word-for-word alignments explic-itly.5 AcknowledgmentsThis work was partially supported by DARPA-ITOgrant N66001-00-1-9814, NSF grant IIS-0097846,and a USC Dean Fellowship to Hal Daume?
III.Thanks to Franz Josef Och and Dave Blei for dis-cussions related to the project.ReferencesMichele Banko, Vibhu Mittal, and Michael Wit-brock.
2000.
Headline generation based on sta-tistical translation.
In Proceedings of the 38thAnnual Meeting of the Association for Compu-tational Linguistics (ACL?2000), pages 318?325,Hong Kong, October 1?8.Peter F. Brown, Stephen A. Della Pietra, VincentJ.
Della Pietra, and Robert L. Mercer.
1993.The mathematics of statistical machine transla-tion: Parameter estimation.
Computational Lin-guistics, 19(2):263?311.Jean Carletta.
1995.
Assessing agreement on clas-sification tasks: the kappa statistic.
Computa-tional Linguistics, 22(2):249?254.Hal Daume?
III and Daniel Marcu.
2002a.
A noisy-channel model for document compression.
InProceedings of the Conference of the Associationof Computational Linguistics (ACL 2002).Hal Daume?
III and Daniel Marcu.
2002b.A phrase-based HMM.
Unpublished; avail-able at http://www.isi.edu/?hdaume/docs/daume02pbhmm.ps, December.J.
Gauvain and C. Lee.
1994.
Maximum a-posteriori estimation for multivariate gaussianmixture observations of markov chains.
IEEETransactions SAP, 2:291?298.Hongyan Jing and Kathleen R. McKeown.
1999.The decomposition of human-written summarysentences.
In Proceedings of the 22nd Confer-ence on Research and Development in Informa-tion Retrieval (SIGIR?99), Berkeley, CA, August15?19.Hongyan Jing.
2002.
Using hidden markov mod-eling to decompose human-written summaries.Computational Linguistics, 28(4):527 ?
544, De-cember.Kevin Knight and Daniel Marcu.
2002.
Summa-rization beyond sentence extraction: A proba-bilistic approach to sentence compression.
Arti-ficial Intelligence, 139(1).Christopher Manning and Hinrich Schutze.
2000.Foundations of Statistical Natural Language Pro-cessing.
The MIT Press.Daniel Marcu.
1999.
The automatic construction oflarge-scale corpora for summarization research.In Proceedings of the 22nd Conference on Re-search and Development in Information Retrieval(SIGIR?99), pages 137?144, Berkeley, CA, Au-gust 15?19.Franz Josef Och and Hermann Ney.
2003.
Asystematic comparison of various statisticalalignment models.
Computational Linguistics,29(1):19?51.Hermann Ney Stephan Vogel and Christoph Till-mann.
1996.
HMM-based word alignment in sta-tistical translation.
In COLING ?96: The 16th Int.Conf.
on Computational Linguistics, pages 836?841.
