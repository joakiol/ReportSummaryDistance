Reversibility in a Constraint and Type based Logic Grammar:Application to Secondary PredicationPalmira MarrafaFLL - Universidade de Lisboa / ILTECAva Engo Arantes e Oliveira, 40 (Lte 41), 8 E.P- 1900 LISBOAPortugalPatrick Saint-DizierIRIT Universit6 Paul Sabatier118, route de NarbonneF-31062TOULOUSE cedex Francee-mail: stdizier@irit.irit.frAbstractIn this document, we present a formalism fornatural language processing which associates typeconstruction principles to constraint logicprogramming.
We show that it provides moreuniform, expressive and efficient tools for parsingand generating language.
Next, we present twoabstract machines which enable us to design, in asymmetric way, a parser and a generator f om thatformalism.
This abstract machinery is thenexemplified by a detailed study of secondarypredication within the framework of a principled-based description of language: Government andBinding theory.IntroductionLexical as well as grammatical and discursiveknowledge required to understand or to producenatural language utterances i usually a descriptionwhich is independent of the sentence production orcomprehension 'algorithms'.
It comes naturally intomind to have a common, shared knowledge base ofwhat language is, independently of its potential uses.Besides well-known advantages of uniformity andtransparency, this point of view is very convenientfor the computer scientist who does not have tointegrate into his parsers or generators theunavoidable updafings required by grammardevelopment.
The linguistic knowledge is thusspecified in a declarative way in different modules(lexical, grammatical, discursive .
.
.
.  )
and differentstrategies are applied which refer to these data(directly for interpreters or via the production of acompiled code for compilers).
This approach canhowever be realiTed more or less easily depending onthe formalisms used to describe languagephenomena.In this document we introduce new advancedtools of the Logic Programming framework andshow that they contribute to meeting therequirements imposed by the manipulation and thecontrol of large amounts of data required by both theparsing and the generation procedure.
We firstconsider logical types which are a declarative andeasy-to-use tool and formalism which permit agrammar writer to encode knowledge in a veryflexible and principled-based way.In addition to types, we introduce new activeconstraints of the Constraint Logic Programming(CLP) framework which allow us to treat and tocheck for consistency of constraints throughout thewhole generation procedure and not to only evaluatethem when they are given in the programme orgrammar.
These active constraints are fullydeclarative and can be used by any type ofparsing/generation process.CLP introduces a greater expressive powertogether with a higher efficiency since the resolutionof constraints is postponed till they can be properlyevaluated and since constraints have to be alwaystrue and consistent with each other.
Finally, a featureof active constraints is that they are usuallyindependent of the way they are processed, they arethus strategy independent and can equivalently beused for parsing and for generation.To make reversibility concrete in our system,we develop in this document two different abstractmachines based on type construction and constraintsatisfaction which give the foundations of a parserand a generator using the same source of declarativelinguistic knowledge.
The differences between thesemachines exemplifies the 'technical' differences onemay have between parsing and generation processes.i1.
A type based description languageThree major types of operations are at the basisof the typed-based language we have designed forlanguage processing, namely:- the expression of type construction togeneratephrase structures,- the expression of dependencies (either local orlong-distance) between types,- the expression of well-formedness constraintson types.Types here refers to the usual data structures incomputer science.
We now informally present hesyntax of our type-based language.
It is directlyderived from the syntax of Login (Ait-Ka~i and Nasr86).
The syntactic representation f a structured termis called a V-term.
It consists of:(1) a root symbol, which is a type constructorand denotes a class of  entities,(2) attribute ~labels, which are record fieldsymbols.
Each attribute denotes a function inextenso, from the root to the attribute value.
Theattribute value can itself be a reference to a type.
(3) coreference constraints among paths oflabels, which indicate that the correspondingattributes denote the same function.
They areindicated by variabies.
Here is an example:person( id => name(first => string,last => X: string),born => date(day => integer,month => monthname,year => integer),father => person( id =>name(last => X ))).The root symbol is person; id, born andfather are three Sub-V-terms which have eitherconstants or type s as values.
X indicates acoreference.
All different ype structures are taggedby different symbols.
Notice also that in the latterfield only relevant information about person ismentioned.
Infinite structures can also be specifiedby coreference links.
Variables are in capital etters,constants in small letters.2.
Dealing with constraintsWe have extended the type descriptionframework with active constraints and have giventhem a Constraint Logic Programming (Colmeraner90, Jaffar and Lassez 87) interpretation, permittingus to have a more principled-based description oflanguage.
The general form of a type is :Type :- Constraints.We view constraints as part of the type:(Type :- Constraints)is itself a type, subsumed by Type.The simplest constraint is the precedenceconstraint:preeede(X,Y),where X and Y are of type string.
Thisconstraint imposes that the string X precedes of thestring Y.
When processing a sentence, precedenceconstraints on constituents are stated in the grammarrules and possibly at the lexical level.
At each stagei of the processing, there is a partial order Pl(i) onthe words and structures already processed.
At the endof the process, precedence constraints give all thepossible word orderings which meet the constraintsof the grammar.
In the case of parsing, constraintsimposed by the order of words in the input stringmust be coherent with the precedence r sults of theparse.The next constraaint imposes the presence of anattribute in a type:has(Attribute, Type)where Attribute is either an attribute label or afull pair attribute-value and Type is a reference to agiven type.
This constraint imposes that at somestage there is an attribute in Type which issubsumed by or equal to Attribute.
Informally, (1)when incoherence with Attribute is detected or (2)when Type is fully constructed, the non-satisfactionof has(Attribute,Type) will provoquebacktracking.
This constraint permits us to encodethematic role assignment and focus management, andalso to encode the inclusion of a set of values intoanother.The last class of constraint is mainly related tothe expression of long-distance relations betweensentence constituents.
Within the framework oftypes, the notion of long-distance is somewhatobsolete since there is no ordering relation onsubtypes in a type (attributes may be written in anyorder).
Thus, the notion of long-distance dependencywill be here formulated as a sub-type co-occurenceconstraint.
This constraint emerged from Dislog(Saint-Dizier 87, 89).
Very briefly, the co-occurenceof two or more subtypes in a larger type is expressedby the constraint: ponding(A,B) where A is atype specification and B is a list of typespecifications.
Informally, this constraint means thatA originates the pending of the sub-types in B, inother terms that A can be used if, somewhere else inthe main type (corresponding for example to a fullsentence), all the sub-types in B are used withidentical substitutions applied to identical variables.3.
P rocess ing  Language with typesand const ra in tsWe will mainly present here simple,motivational examples.
A more abstract syntacticdescription will be given in section 6 which willmore fully motivate our approach.
The examplesgiven in this text show that our description languagecan accomodate principled-based escriptions oflanguage like Government and Binding theory aswell as lexicaUy and head driven descriptions like inthe HPSG framework.In the following simple examples, we onlyhave two main type constructors:- x0 corresponding tolexical entries,- xp corresponding to phrase structures.Here is the description of the lexical entrycorresponding to the verb to give:xO( cat => v, string => \[give\] ) :-pending(xO(cat => v),\[xp( cat => n, string => $1, role => patient ),xp( cat => p, string => $2,role => recipient) \] ),precede(\[give\],S1), precede(S1, $2).This entry says that give is a verb whichsubcategorizes for an np with role patient and a ppwith role recipient; np and pp are left pending.
Thestring S 1 generated from the np has to precede thestring $2 generated from the pp.
These constraintswill be treated at the level of the type describing thestructure of a vp.
The whole description xOconstruction and related constraints i  the type ofthe verb to give, Let us now consider theconstruction of a vp with an np and a ppcomplements.
To the construction of a vp typecorresponds the generation of a (set of) string(s)corresponding to a via, this is stored in S. We thenhave the following construction:xp( cat => v, string => S,constl  => xO(cat => v ),const2 => X : xp(cat => n),const3 => Y : xp( cat => p) ) :-has(role, X), has(case, X),has(role, Y), has(case, Y).The constraints has(role,X) and has(role,Y)impose that the constituents const2 and const3 havea role assigned at some level of the type constructionprocess.
The same situation holds for case.
This is asimple expression, for example, of the case filter inGB theory.
Notice that most pending situations aresatisfied locally, which limits complexity.4.
An abstract machine for typeconstruction in a parsing processParsing a sentence is constructing a well-formedtype describing the sentence structure.
We present inthis section an abstract machine which describes howtypes are constructed.
This machine is based on theprocedural semantics of Prolog but it resembles apush-down tree automaton whose stack is updatedeach dine a subtype is modified.There are two kinds of type constructors: thosecorresponding tonon-terminal structures ( uch as xpand x 1 in our examples) and those corresponding toterminal structures (e.g.
x0).
We now present a stepin the construction of a type.
It can be decomposedinto 3 levels:(1) current state o i :cO( a 1 => t 1, a 2 => t 2 .
.
.
.
.
a n => tn),(2) selection in the current programme P of atype construction specification:c l (b  1 => t' 1 .
.
.
.
.
b m =>t'  m)such that t 1 subsumes it or unifies with itmodulo the mgn 0 i.
(3) New state ?
i+l  : tl is replaced by :el(  b 1 => t' 1 .
.
.
.
.
b m => t' m ),with, as a result, the following type:co(a 1 => c l (b  1 => t' 1 .
.
.
.
.
b m => t' m ) ,a 2 => t 2 .
.
.
.
.
a n => t n) 0 iThe process goes on and processes t'1" The typeconstruction strategy is here similar to Prolog'sstrategy and computation rule : depth-first and fromleft to right.
The main difference at this level withSLD-resolution is that only types corresponding tonon-terminal structures are expanded.
Informally,when a type tj corresponds toa terminal structure, anattempt is made to find a terminal type descriptiont'j in the programme which is subsumed by orunifies with t.j and, if so, a replacement, occurs, t'j issaid to be in a final state.
If t j does not exist,backtracking occurs.
The next type descriptionimmediately to the right of t'j is then treated in thesame manner.
The type construction processsuccessfully ends when all subtypes corresponding toterminal symbols are in a final state and it fails ff aterminal type description tp cannot reach a finalstate.
The initial state: is :xp( cat => sentence istring => \[ string,to,parse\] ).4.2.
Extens ion  o f  the abst ractmachine to constra intsThe above abstract machine can be extended inasimple way to deal with constraints.
Constraintresolution mechanisms are similar to usualconstraint logic programming systems like PrologIH.
The three above le~,els become:(1) current state ?i  represented bythe couple:< c0(a l=>t  1, a 2=>t  2 .
.
.
.
.
a n=>tn) ,S  >where S is the set of current constraints,(2) selection in the current programme P of atype construction specification:c l (b  1 => t' l ,  ...; b m => t' m ) :- R.where R is the set of constraints associated tocl, and t 1 subsumes Or unifies with t' 1 modulo themgu 0 i.
(3) New state o i+ 1 characterized by thefollowing couple:< c0(a 1 =>c l (b  1=> t' 1 .
.
.
.
.
b m => t' m) ,a 2 => t 2, .... a n => t n) 0 i ,S u R u subsume(tl,Cl( b 1 => t' 1 .
.
.
.
.bm =>i t'm ) ) >with the condition that the new set ofconstraints must be satisfiable with respect o theconstraint resolution axioms defined for each type ofconstraint and, if not,:a backtracking occurs.
At thislevel constraints simplifications may also occur.The output of the parsing process may besimply a syntactic tree, but it may also be a logicalformula, similar to the one used and presented insection 5.
We however think that both processes,parsing and generating, need not necessarilyrespectively produce and start from the same abstractinternal representation.5.
An Abst:ract Mach ine  forLanguage Generat ionFrom the above declarative descriptions oflanguage construction, an abstract machine forlanguage generation can also be defined.
At the levelof type construction, generation proceeds bymonotone increasing restrictions: a phrase structurezis described by a type constructor linking a set ofsubtypes.
This operation introduces a restriction onthe possible left and right contexts that each of thesubtypes could potentially have if they wereindependent from each other.
The degree of generalityof the selected type constructor linking thosesubtypes can be subject o various interpretations.Finally, generation is guided by the semanticrepresentation from which a sentence is uttered.
Asshall be seen, the semantic representation willdetermine the computation rule and the subgoalselection procedure.
It is thus much moredeterministic than its parsing process counterpart.Let us now briefly consider the abstract machinefor language generation.
The general technique, thatwe have already exemplified in (Saint-Dizier 89),consists in:- (1) writing a formal grammar of the semanticrepresentation from which the generation processstarts,- (2) identifying the phrasal units and the lexicalunits (and intermediate units if necessary) which canbe associated to the symbols of that formalgrammar,- (3) associating eneration points to thesesymbols (terminal and non-terminal) which willgenerate natural language ffi-agrnents based on aconsultation of the grammatical and the lexicaisystem (these generation points could be addedautomatically).For example, if the formal grammar of thesemantic representation f quantified noun phrasesis:Quant_np--> det(\[Quant, Var\], Np,Rest of sentence).Np --> and( Noun, Modifiers ).We then have, for example, and informally, thefollowing generation points, where the callp(formula, string, corresponding syntactic ategory)is used to process the semantic representation:p(det(\[Quant,Var\],Np,Rest of sent),Type ) :-p(Quant, Type1), p(Np, Type2),generation_point(Type1, Type2, Type3),p(Rest_of_sentence, Type4),generation_point(Type3, Type4, Type).p(and(Np, Mod),Type) :-p(Np, Type1), p(Mod,Type2),generation_point(Type1, Type2, Type).The relation between a predicate (or anargument) and a word is established by a call to alexical entry as follows:p(Predieate, Type) :-Type, has(Type,sem_rept => Predicate ).Informally, Typel and Type2 are constructedfrom the treatment of the quantifier and the nounphrase, they are then combined, in the first ruleabove, by means of the first call togeneration_point, resulting in Type3.
Thisgeneration point includes the treament of the stringof words being generated (including the precedenceconstraints on the words generated from lexicalinsertion) and the treatment of more abstract featuressuch as category, inflection or semanticcharacteristics.
Finally, the second call togeneration_point i tegrates Type3 with Type4, thelatter being the type associated to the remainder ofthe sentence.
The result is Type.Generation points support by themselves thegeneration strategy.
A model of these generationpoints is given below by means of an abstractmachine.
As can be noticed, calls to generationpoints occur after the parse of the correspondingsemantic structure.
This means that calls togeneration points will be stacked (by Prolog) andwill be then unstacked in the reverse order they havebeen stacked: the strategy is then bottom-up.Generation points determine, by means of a callto the grammatical system, the resulting syntacticcategory and the way the partial strings of words illType1, Type2 and Type4 are assembled.
The waytypes are constructed by generation points ismodelled by the following abstract machine.
At thislevel, we generalize the generation points to takeinto account any number of subtypes, and not onlytwo as shown in the examples.We claim that thismethod is general and can be used from most currentsemantic representations (such as, for example, DRTor Conceptual Graphs).The abstract machine for language generationcan be described by its initial state and a step in theconstruction procedure.
It has the general form of afinite state tree automaton.
The initial state is o 0, itis the empty type.
Let us now consider a step a i .1.
Two cases arise: it is either(a) a set of subtypes from which a moregeneral type can be constructed:o i = (a) (C 1, C 2 .
.
.
.
.
C n) is an unorderedsequence of subtypes ; or(b) it is a single type : o i = D12.
Type constructor selection:(a) let DC be such that: DC has exactly kattributes constj,  k <_ n,and DC is of the form:DC := xp( .... const I => C' 1 .
.
.
.
.
const k => C' k )and:for all j E \[ l,k\], subsume(C'i, Ci )(notice that the Cj are not n~cess~rily the jtnelement of the list given in 1 above, notice also thatthe type constructor DC contains the subtypesconstq together with other information like categoryand morphology.
)or (b) D' (single type)3. o i+ l  = (a ) (DC,Ck+ 1 .
.
.
.
.
C n)for all i, j E \[1,k\]or (b) (D1, D').The type constructor DC contains the subtypesconstq together with other information like categoryand rhorphology.
It should be noticed that theconstructor DC is selected according to asubsumption criterion, which is more general andpowerful than standard unification.
It bettercorresponds tothe process of incremental generationof phrases.
The process ends when a type withcategory sentence is reached.
This is a terminal statein the automaton, more precisely it is the root of thetree automaton, since our generation system proceedsin a bottom-up fashion.Let us now consider the step 2 above devoted tothe selection of a type constructor.
This selection ismainly guided by the generation points given in theformal grammar of the semantic representation.
Theyindeed select between cases (a) or (b) and in case (a)they directly characterize which of the C i will beincluded in the type construction atthe current stage.Finally, since active constraints associated to typedescriptions can be executed at any time, theconstraint resolution mechanisms which maintainconstraint coherence are independent of thegeneration strategy.
In other terms, thesemechanisms are independent of the way and the orderconstraints are added to the set of active constraints.IThe abstract machine which handles types andconstraints i the following.
It is represented by atuple: <type, set of active constraints>.We then have:1. a i=(a) < (C 1, C 2 .
.
.
.
.
Cn), S > sequence ofsubtypes Ci and of active constraaints S(b) < D1, S >L2.
Type constructor selection:(a) <DC,  R> where R is the set ofconstraints associated toDC and such that:i) same restrictions as above on DC andii) R is consistent with S(b) < D' , R > (single type)with R consistent with S.3.
ff i+l =(a )<(DC,Ck+ 1 .
.
.
.
.
Cn), (S uRu(subsume(C'j => Cj ))!for all j E \[l,k\] ) >(b) < (DI, D'), S u R >At the end of the generation process, the set ofpossible admissible surface sentences can be directlyderived from the preddence constraints which maynot be a total order (some words may have differentpositions).6.
An  App l i ca t ion  to SecondaryP red icat ionWe now present a more elaborate andcomprehensive example which will further motivateour approach.
Secondary predication is described atboth lexical and syntac'fic levels, the intertwining ofseveral constraints makes it simpler to describe in afully declarative way.
The description is thusindependent of its use~ parsing or generation.
Thisgives a good application example of the specificationand use of our formalism and system for a realphenomenon of mueh importance to naturallanguage system designers.6.1 A l inguist ic  approachSecondary Predication is a term used in theliterature to denote a very productive structuralrelationship in many languages: the relationshipbetween a subject and a predicate, the subject beingassigned a thematic role by that predicate and by anobligatory thematic roie assigner in the sentence,namely the verb.
For instance, in (1)(1) Mary drinks the water coldthe water, the direct object of drinks, is assigned athematic role by this verb and another one by theadjective cold.
Then, water is, at the same time, anobject for drinks and a subject for cold.
In otherterms, water integrates - as an object - a primarypredication which corresponds tothe whole sentence,and - as a subject - a secondary predication whichcorresponds tothe sequence the water cold.6.1.1 Ob ject -or iented  Pred icatesSecondary predication is not an uniform or anhomogeneous phenomenon, either from the pointof view of a specific language, nor from acrosslinguistic one.
We will describe here some ofthe most relevant structural properties and lexicalconstraints of this type of construction i  French.Let us begin by considering the French sentencecorresponding to (1):(2) Marie bolt l'eau froide.
(2) is an ambiguous sentence as can beillustrated by the paraphrases below (the Englishtranslations of the examples are, all of them, literaltranslations):(2) (a)( Marie boit l'eau qui est froide("Mary drinks the water which is cold")(b) Quand Marie boit l'eau, l'eau est froide.
("When Mary drinks the water, the water is cold")Considering the interpretation i  (2)(a), theadjective is part of the direct object of the verb,which is not the case for the interpretation in (2)(b).Then, l'eaufroide can have the structure(3)(a) \[NP\[NP reau\] lAP froide\]\]or the structure:(3)(b) \[NP i reau\]\[AP i froide\].In (3)(a)froide is a modifier of eau, while in(3)(b) it behaves as a predicate, assigning asecondary thematic roleto the NP.
The predicationrelationship sexpressed by coindexation.Let us now consider the sentence (4):(4) Marie boit i'eau mindrale("Mary drinks the water mineral'9In spite of its superficial structural resemblancewith the example above, (4) is not ambiguous, theinterpretation corresponding to the paraphrase (b)being not available:(4)(a) Marie boit l'eau qui est min~rale("Mary drinks the water that is mineral")but :(4)(b) *Quand Marie boit l'eau, l'eau estmin~rale("When Mary drinks the water, the water ismineral")This means that the possibility of having or nothaving an object-oriented secondary predicationdepends on the semantic nature of the adjective.Moreover, there also exist semantic co-occurrencereslrictions between the adjectival predicate and theverb:(5) *Marie boit l'eau congel~e("Mary drinks the water frozen'9(5) is excluded because something frozen cannotbe drunk.
Notice that the presence of an adjective insentences like (2) is optional, in opposition to whathappens in sentences like (6) (for the sameinterpretation of the verb):(6) Marie considdre l'eau froide("Mary considers the water cold")(6)(a) *Marie considdre l'eau"Mary considers the water")What we can infer from the fact that (6)(a) isruled out is that: (i) conside'rer (to consider) does notsubcategorize for an NP, then fro/de can not be amodifier of l'eau; (ii) if fro/de is not a modifier ofl'eau it must be a predicate, but, in this case, wedont have the structure presented in (3)(b).
In fact,l}au froide behaves like a clausal phrase.
It can evenbe replaced by a completive sentence (the semanticinterpretation remaining the same) as exemplified in(6)(b):(6)(b) Marie considdre que l'eau est froide("Mary considers that the water is cold")We have then empirical evidence to analysel'eaufroide in (6) as a clause, a "small clause" usingan usual label in the literature (since the categorialstatus of the small clause is irrelevant for ourpurposes, we will only use the symbol "SC" to referto this constituent, assuming the small clausesanalysis proposed by Stowell (1981) and Stowell(1983)).
As a consequence, l'eau froide is apredication having the structure in (7):(7) \[SC\[NP i l'eau\] \[AP i froide\]\]In this case it is the whole predication, and not onlyits subject, which is theta-marked by the verb.Stricto sensus, we have not a secondary predication,nevertheless, the conlrastive analysis remainsimportant since the two kinds of structures aresuperficially very similar.As largely assumed in the GB framework(Chomsky (1981) and (1986)), predication isconfigurationnaly constrained: subject and predicatemust be reciprocally m-commanded, that is, allmaximal projections (phrase levels) dominating oneof them must dominate the other one.
Given thiscondition and the facts we have examined, (8) and(9) are appropriate r presentations (we use here X-barnotation only when relevan0, respectively, for (2)and (6):(8) \[S \[NP Marie\] IV" \[V'\[V boit\] \[NP i l'eau\] \]\[AP i froide\]\]\](9) \[S \[NP Marie\] \[V"\[V'\[V consid&e\] [SC \[NP il'eau\] \[AP i froide\]\]\]\]\]Although attached to different nodes inside V"(while in (8) the subject of the secondarypredication occupies the direct object position andits predicate is in a weak adjunction position (in thesense of Demonte (1988)), in (9) subject andpredicate are together in direct object position), thepredications we have considered so far involve onlyadjacent elements.
Let us now examine sentence(10):(10) La lessive rend le linge blanc(The washing makes the clothes white")Similary to what happens in (6), the sentence isruled out if the adjecfif is not present:(lO)(a) *La lessive rend le linge("The washing makes the linge")With respect to these facts it seems to benatural that sentence (10) is structurally identical to(9).
Nevertheless, (10)(b), which is equivalent o(10), does not support his hypothesis:(lO)(b) La lessive blanchit le linge("The washing whitens the clothes")As we can observe, blanchit, a verbal predicate,can replace the verb - rend - and the adjectivalpredicate blanc (for the same semanticinterpretation).
Then, rend blanc behaves like asingle predicate.
At the same time, blanc is asecondary predicate for linge.
Following a proposalby Marrafa (1983) and (1985) for similar cases inPortuguese, we consider rend blanc as adiscontinuous complex predicate and we express therelationship between the two elements thatconstitue it by co-superscription.
Therefore, (10) hasthe structure (10)(c),where k indicates thediscontinuity in the predicate rend-blanc :(10)(c) \[S\[NP La lessive\] \[V"\[V'\[V k rend\] \[NP ile linge\] \[Apki blanc\]\]\]\]6.1.2 Subject-oriented predicatesDiscontinuity can also be an obligatoryproperty of a certain kind of secondary predication,namely in the case of subject-oriented predicates.
(11) is an example:(11) Jean dansait riste8("John dansed sad")Since Jean is a proper noun, it can not bemodified.
Then triste is necessarily a predicate forJohn.
Although the subject of triste is the mainsubject and not an NP in object position as in theabove sentences, there are semantic o-occurrenceconstraints between the verb and the adjectivalpredicate, as illustrated below:(11)(a) *Jean dansait repenti("John dansed repented")Taking into account hese constraints and notviolating the m-command condition refered to above,we represent the adjectival predicate as an strongadjunction (again in die terms of Demonte (1988)) toV", the syntactic representation f (11) being, then,(11) (b):(11)@) \[S\[NP i Jean\] IV" IV" IV' IV dansait\]\]\]\[AP i triste\]\]\]Notice that continuous and discontinuoussecondary predication s can co-occurre in the samesentence:(12)Jean i boit l'eauj froidej triste i("John drinks the 'water cold sad")It is also interesting to point out that, in certaincases, sentences are iambiguous with respect tocontinuous and discontinuous secondary predication:(13)Jean i laisse son amiej triste i j("John left his girlfriend sad")To summarize, secondary predication can beassociated to different ypes of structure and tocontinuous or discontinuous elements.
Moreover,there are numerous and different semantic co-occurrence restrictions ~ of different ypes affectingthe lexical items invoNed.6.2 An Implementation in terms oftypes and constraintsWe now show how the above examples areexpressed both at syntactic and lexical levels.
Thefull syntactic structures are given under (8), (9),(10c) and (1 lb).
The structure in (8) says that the APis a sister of the V' (noted in the grammar as V withbar level 1) and that the AP is co-indexed with theobject NP, the co-indeXation relation is left pendingsince it is preceded by the V' description.
We havethe following construction:xp( cat => v, string => SV,const l  => x l (  cat => v, string => $3) ,bconst2 => xp( cat: => a, string => $4,index => I ) :-pending(xp(cat  => v) , \ [x l (  cat => v,string => T, const l  => xO( cat => v,string => $1),  const2 => xp( cat => n,string => $2,  index => I ) ) \] ),precede(S1 ,$2) ,  p recede(S3 ,S4) .Since the AP is not obligatory (it is a weakadjunct), there is nothing said about it in thelexicon.Construction (9) introduces a small clause(noted here as sc).
Since it is not necessarilycontiguous to the V', but only dominated by the V',we need a pending constraint.
The type constructionis the following:x l (  cat => v, string => SV,constl  => xO( cat => v, string => $1 ),const2 => xp( cat => sc, string => $2 ) ) :-pending(x1 (cat => v) , \ [x l (  cat => sc,string => SV, constl => xp( cat => n,index => I, string => $3), const2 =>xp( cat => a, string => S4,index => I ) ) \] ),precede(S1,S2), precede(S3,S4).The lexical entry of the verb (here considerer)has a pending constraint for the small clause: theverb subcategorizes fora small clause.Construction (10c) introduces a doubleindexation but no long-distance dependency for thecompound predicate 'rend-blanc'.
We represent i asfollows:x l (  cat => v, string => SV,constl => xO( cat => v,compound_..pred => K,string => $1),const2 => xp( cat => n, index => I,string => $2 ),const3 => xp( cat => a, index => I,string => $3, compound pred => K ) ) :-precede(S1 ,$2), precede(S2,S3).Finally, the construction given in (l lb)introduces a long-distance r lation between an NP insubject position and an AP which is in objectposition.
To handle this phenomenon, we have to goup to the sentence l vel, that we will represent herefor simplicity as s (instead of, for example, COMP).The type construction is the following:xp( cat => s, string => SV,constl  => xp( cat => n, string => $1,index => I ),const2 => xp(cat=>v,  string => $2 ) )  :-pending(xp(cat => s),\[xp( cat => v,string => T,constl  => xp( eat => v,string => S3),const2 => xp( cat => a,string => $4, index => I ) ) \] ),precede(S1 ,$2), precede(S3,S4).At the lexical level, the adjoined AP is notmentioned, since it is not syntactically necessary(but it might be necessary from a semantic point ofview, as also for case (8) above).7.
Specific features of our approachOur approach can be contrasted mainly with theusual systems based on unification grammar (UG)formalisms (Shieber, 86), (Emele and Zajac 90).
Thefirst major difference is that the unification andrewriting mechanisms usually associated with UGare replaced by a more constraining operation, typeconstruction, which always proceeds by sucessiverestrictions (or monotone increasing specialisation)each time a type is further expanded.
From that pointof view, our approach also substantially differs from(Ait Ka~i and Nasr, 86) who propose apowerful andsemantically clear mechanism for typed unificationassociated totype inheritance.Next, we have a single operation: typeconstruction; we do not have on the one handgrammar rules and on the other hand, associated toeach rule, a set of equations to deal with featurevalues and constraints.
The constraints we haveassociated with our types are not of the same natureand cannot be compared to the equations of UGs.They are moreover a part of the type.Constraints added to types are interpreted withinthe CLP framework, this permits us to have a moreexpressive and powerful constraint system, which isalso more efficient and simpler to write.
Constraintsatisfaction is not indeed guaranteed atthe level theyare given, but throughout the whole typeconstruction process.Our approach is compatible with the currentprincipled-based approaches to describing languages.This is exemplified in section 4 by the constraintson role and case assignments.
In a more general way,the description language we have presented here isparticularly appropriate for highly abstractdescriptions of language, which corresponds toseveral current rends in computational linguistics.Our description language is, in the same time, well-adapted to deal with lexical-based approaches tolanguage processing (those approaches like lexicongrammars where the lexicon plays a central role) andto describe representations developed within lexicalsemantics.Finally, a constraint like pending generalisesthe notion of long-distance dependency to severalother kinds of dependencies.
This generalization is inparticular a consequence of the fact that typestructures do not have any ordering on subtypes andthey cannot, thus, directly express the differencebetween remote and close constituents.Besides these general properties, our approachhas several interesting properties which are morespecific to reversibility.
First, the common datashared by the two processes i all the linguistic datawhich is specified in a declarative way: lexical andgrammatical.
The semantic omposition rules are thesame.
In the case of generation, they are translatedinto a parser of the formal grammar of this semanticrepresentation.
It should be pointed out that theparser given in section 5 can be generatedautomatically.Both processes also have a lot of elements incommon at the procedural level: the typeconstruction mechanisms are identical, the majordifference at this level being the selection rule,which is, in the ease of generation, guided by thesemantic form from which the process starts.
Theother difference is that parsing proceeds a priori top-down in the case we have exemplified (it could alsoproceed bottom-up).
Generation proceeds bottom-up,for reasons explained in section 5.
From thisdifference it results that the starting type in the caseof parsing is a general type corresponding tosentence whereas there are no starting type in thecase of generation, the starting points being thetypes corresponding to the predicates appearing inthe logical formula, which are deduced from anoperation close to lexical insertion.
If the parsingprocess were bottom-up, then the starting typeswould be the same and the subsumpfion operationwould also be used instead of the standardunification.Finally, and most importantly, the constraintsystem that we have presented is fully independent ofthe strategies used and of the direction of the process:generation of parsing.
This is a consequence of thefact that constraints are evaluted only when there is10\[sufficient available information to evaluate them andalso that their coherence with the other constraints ichecked throughout he whole proof constructionprocedure.
The variables which are used by activeconstraints are thus global variables.ConclusionIn this document, we have first defined aformalism based on t~jpes and active constraints ofthe Logic Programming framework and have shownthat it is well-appropriate to describe languageconstructions.
We have in particular illustrated it byfocussing on secondary predication, an importantphenomenon i  langt~age processing.
Finally, wehave shown that our formalism is particularlyappropriate to be used by a parser and by a generator,in a symmetric way, and we have defined for thatprupose two abstract machines.
This work is nowfully implemented in Sicstus Prolog (which allowsthe writing of constraint resolution mechanism) on aSun workstation.
Since constraints are so far meta-interpreted, we cannot make real comparisons withexisting NLP systems.
A significant result ishowever the much smaller number of backtrakingoperations that we havelobserved.AcknowledgementsWe thank N. Hathout for his insightfulcomments on this work, which was supported by thePRC Communication ' Homme-Machine and theFrench ministry of rese~trch.ReferencesAit-Ka~i, H., Nasr, R., LOGIN: A LogicProgramming Language with Built-in Inheritance,journal of Logic Programming, vol.
3, pp 185-215,1986.Chomsky, N., Lectures on Government andBinding, Foris, 1981.Chomsky, N., Barriers, Linguistic Inquirymonograph no 13, MIT Press, 1986.Colmerauer, A., An Introduction to Prolog III,CACM 33-7, 1990.Demonte, V., Remarks on Secondary Predicates:C-Command, Extraction and Reanalysis, TheLinguistic Review 6, pp 1-39, 1988.Emele, M., Zajac, R., Typed UnificationGrammars, in proc.
COLING'90, Heisinki, 1990.Jaffar, J., Lassez, J.L., Constraint LogicProgramming, Proc.
14th ACM Symposium onPrinciples of Programming Languages, 1987.Marrafa, P., Teoria das Pequenas Ora~oes vsTeofia da Predicafao: Controlo, Cfittfio Tematico ePrincipio de Projec~ao, ms, FLL-University ofLisbon, 1983.Marrafa, P., A Constru~ao Transitiva-Predicafiva em Portuguts, FLL-University ofLisbon, 1985.Saint-Dizier, P., Contextual DiscontinuousGrammars, 2nd NLULP, Vancouver 1987 and in:Natural Language Understanding and LogicProgramming II, V. Dahl and P. Salnt-Dizier Edts,North Holland, 1988.Saint-Dizier, P., A generation Strategy based onGB Principles, proc.
2nd European workshop onlanguage generation, Edinburgh, 1989.Saint-Dizier, P., Constrained LogicProgramming for Natural Language Processing,proc.
ACL-89, Manchester, 1989.Sheiber, S., An Introduction to Unification-Based Approaches to Grammar, CSLI lecture notesno 4, Chicago University Press, 1986.Stowell, T., Origins of Phrase Structure, PhD.dissertation, MIT, 1981.Stowell, T., Subject across Categories, TheLinguistic Review 2, pp 285-312, 1983.13.
