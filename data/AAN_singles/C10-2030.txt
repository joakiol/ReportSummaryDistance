Coling 2010: Poster Volume, pages 259?266,Beijing, August 2010AbstractDue to the lack of annotated data sets,there are few studies on machine learningbased approaches to extract named enti-ties (NEs) in clinical text.
The 2009 i2b2NLP challenge is a task to extract sixtypes of medication related NEs, includ-ing medication names, dosage, mode,frequency, duration, and reason fromhospital discharge summaries.
Severalmachine learning based systems havebeen developed and showed good per-formance in the challenge.
Those systemsoften involve two steps: 1) recognition ofmedication related entities; and 2) deter-mination of the relation between a medi-cation name and its modifiers (e.g., do-sage).
A few machine learning algo-rithms including Conditional RandomField (CRF) and Maximum Entropy havebeen applied to the Named Entity Recog-nition (NER) task at the first step.
In thisstudy, we developed a Support VectorMachine (SVM) based method to recog-nize medication related entities.
In addi-tion, we systematically investigated vari-ous types of features for NER in clinicaltext.
Evaluation on 268 manually anno-tated discharge summaries from i2b2challenge showed that the SVM-basedNER system achieved the best F-score of90.05% (93.20% Precision, 87.12% Re-call), when semantic features generatedfrom a rule-based system were included.1 IntroductionNamed Entity Recognition (NER) is an impor-tant step in natural language processing (NLP).
Ithas many applications in general language do-main such as identifying person names, locations,and organizations.
NER is crucial for biomedicalliterature mining as well (Hirschman, Morgan, &Yeh, 2002; Krauthammer & Nenadic, 2004) andmany studies have focused on biomedical entities,such as gene/protein names.
There are mainlytwo types of approaches to identify biomedicalentities: rule-based and machine learning basedapproaches.
While rule-based approaches useexisting biomedical knowledge/resources, ma-chine learning (ML) based approaches rely muchon annotated training data.
The advantage ofrule-based approaches is that they usually canachieve stable performance across different datasets due to the verified resources, while machinelearning approaches often report better resultswhen the training data are good enough.
In orderto harness the advantages of both approaches, thecombination of them, called the hybrid approach,has often been used as well.
CRF and SVM aretwo common machine learning algorithms thathave been widely used in biomedical NER(Takeuchi & Collier, 2003; Kazama, Makino,Ohta, & Tsujii, 2002; Yamamoto, Kudo,Konagaya, & Matsumoto, 2003; Torii, Hu, Wu,& Liu, 2009; Li, Savova, & Kipper-Schuler,2008).
Some studies reported better results usingCRF (Li, Savova, & Kipper-Schuler, 2008),while others showed that the SVM was better(Tsochantaridis, Joachims, & Hofmann, 2005) inNER.
Keerthi & Sundararajan (Keerthi & Sunda-rarajan, 2007) conducted some experiments anddemonstrated that CRF and SVM were quiteclose in performance, when identical featurefunctions were used.2 BackgroundThere has been large ongoing effort onprocessing clinical text in Electronic MedicalRecords (EMRs).
Many clinical NLP systemsRecognizing Medication related Entities in Hospital DischargeSummaries using Support Vector MachineSon Doan and Hua XuDepartment of Biomedical InformaticsSchool of Medicine, Vanderbilt UniversitySon.Doan@Vanderbilt.edu, Hua.Xu@Vanderbilt.edu259have been developed, including MedLEE(Friedman, Alderson, Austin, Cimino, & John-son, 1994), SymTex (Haug et al, 1997), Meta-Map (Aronson, 2001).
Most of those systemsrecognize clinical named entities such as diseas-es, medications, and labs, using rule-based me-thods such as lexicon lookup, mainly because oftwo reasons: 1) there are very rich knowledgebases and vocabularies of clinical entities, suchas the Unified Medical Language System(UMLS) (Lindberg, Humphreys, & McCray,1993), which includes over 100 controlled bio-medical vocabularies, such as RxNorm,SNOMED,  and ICD-9-CM; 2) very few anno-tated data sets of clinical text are available formachine learning based approaches.Medication is one of the most important typesof information in clinical text.
Several studieshave worked on extracting drug names from clin-ical notes.
Evans et al (Evans, Brownlow, Hersh,& Campbell, 1996) showed that drug and dosagephrases in discharge summaries could be identi-fied by the CLARIT system with an accuracy of80%.
Chhieng et al (Chhieng, Day, Gordon, &Hicks, 2007) reported a precision of 83% whenusing a string matching method to identify drugnames in clinical records.
Levin et al (Levin,Krol, Doshi, & Reich, 2007) developed an effec-tive rule-based system to extract drug namesfrom anesthesia records and map to RxNormconcepts with 92.2% sensitivity and 95.7% spe-cificity.
Sirohi and Peissig (Sirohi & Peissig,2005) studied the effect of lexicon sources ondrug extraction.
Recently, Xu et al (Xu et al,2010) developed a rule-based system for medica-tion information extraction, called MedEx, andreported F-scores over 90% on extracting drugnames, dose, route, and frequency from dis-charge summaries.Starting 2007, Informatics for Integrating Bi-ology and the Bedside (i2b2), an NIH-fundedNational Center for Biomedical Computing(NCBC) based at Partners Healthcare System inBoston, organized a series of shared tasks ofNLP in clinical text.
The 2009 i2b2 NLP chal-lenge was to extract medication names, as well astheir corresponding signature information includ-ing dosage, mode, frequency, duration, and rea-son from de-identified hospital discharge sum-maries (Uz?ner, Solti, & Cadag, 2009).
At thebeginning of the challenge, a training set of 696notes were provided by the organizers.
Amongthem, 17 notes were annotated by the i2b2 orga-nizers, based on an annotation guideline (see Ta-ble 1 for examples of medication information inthe guideline), and the rest were un-annotatednotes.
Participating teams would develop theirsystems based on the training set, and they wereClass # Example DescriptionMedication 12773 ?Lasix?, ?Caltrate plus D?, ?fluoci-nonide 0.5% cream?, ?TYLENOL( ACETAMINOPHEN )?Prescription substances, biologicalsubstances, over-the-counter drugs,excluding diet, allergy, lab/test, alco-hol.Dosage 4791 ?1 TAB?, ?One tablet?, ?0.4 mg?
?0.5 m.g.
?, ?100 MG?, ?100 mg x 2tablets?The amount of a single medicationused in each administration.Mode 3552 ?Orally?, ?Intravenous?, ?Topical?,?Sublingual?Describes the method for administer-ing the medication.Frequency 4342 ?Prn?, ?As needed?, ?Three times aday as needed?, ?As needed threetimes a day?, ?x3 before meal?, ?x3a day after meal as needed?Terms, phrases, or abbreviations thatdescribe how often each dose of themedication should be taken.Duration 597 ?x10 days?, ?10-day course?, ?Forten days?, ?For a month?, ?Duringspring break?, ?Until the symptomdisappears?, ?As long as needed?Expressions that indicate for howlong the medication is to be adminis-tered.Reason 1534 ?Dizziness?, ?Dizzy?, ?Fever?, ?Di-abetes?, ?frequent PVCs?, ?rare an-gina?The medical reason for which themedication is stated to be given.Table 1.Number of classes and descriptions with examples in i2b2 2009 dataset.260allowed to annotate additional notes in the train-ing set.
The test data set included 547clinicalnotes, from which 251 notes were randomlypicked by the organizers.
Those 251 notes werethen annotated by participating teams, as well asthe organizers, and they served as the gold stan-dard for evaluating the performance of systemssubmitted by participating teams.
An example oforiginal text and annotated text were shown inFigure 1.The results of systems submitted by the partic-ipating teams were presented at the i2b2 work-shop and short papers describing each systemwere available at i2b2 web site with protectedpasswords.
Among top 10 systems whichachieved the best performance, there were 6 rule-based, 2 machine learning based, and 2 hybridsystems.
The best system, which used a machinelearning based approach, reached the highest F-score of 85.7% (Patrick & Li, 2009).
The secondbest system, which was a rule-based system us-ing the existing MedEx tool, reported an F-scoreof 82.1% (Doan, Bastarache L., Klimkowski S.,Denny J.C., & Xu, 2009).
The difference be-tween those two systems was statistically signifi-cant.
However, this finding was not very surpris-ing, as the machine learning based system uti-lized additional 147 annotated notes by the par-ticipating team, while the rule-based systemmainly used 17 annotated training data to cus-tomize the system.Interestingly, two machine learning systems inthe top ten systems achieved very different per-formance, one (Patrick et al, 2009) achieved anF-score of 85.7%, ranked the first; while another(Li et al, 2009) achieved an F-score of 76.4%,ranked the 10th on the final evaluation.
Both sys-tems used CRF for NER, on the equivalent num-ber of training data (145 and 147 notes respec-tively).
The large difference in F-score of thosetwo systems could be due to: the quality of train-ing set, and feature sets using for classification.More recently, i2b2 organizers also reported aMaximum Entropy (ME) based approach for the2009 challenge (Halgrim, Xia, Solti, Cadag, &Uzuner, 2010).
Using the same annotated data setas in (Patrick et al, 2009), they reported an F-score of 84.1%, when combined features such asunigram, word bigrams/trigrams, and label ofprevious words were used.
These results indi-cated the importance of feature sets used in ma-chine learning algorithms in this task.For supervised machine learning based sys-tems in the i2b2 challenge, the task was usuallydivided into two steps: 1) NER of six medicationrelated findings; and 2) determination of the rela-tion between detected medication names andother entities.
It is obvious that NER is the firstcrucial step and it affects the performance of thewhole system.
However, short papers presentedat the i2b2 workshop did not show much detailedevaluation on NER components in machinelearning based systems.
The variation in perfor-mance of different machine learning based sys-tems also motivated us to further investigate theeffect of different types of features on recogniz-Figure.
1.
An example of the i2b2 data, ?m?
is for MED NAME, ?do?
is for DOSE, ?mo?
is forMODE, ?f?
is for FREQ, ?du?
is for DURATION, ?r?
is for REASON, ?ln?
is for ?list/narrative.
?# Line Original text70..7475DISCHARGE MEDICATION:?Additionally, Percocet 1-2 tablets p.o.
q 4 prn, Colace 100 mgp.o.b.i.d.
, insulin NPH 10 units subcu b.i.d.
, sliding scale insulin?Annotated text:m="colace" 74:10 74:10||do="100 mg" 74:11 74:12||mo="p.o."
74:13 74:13||f="b.i.d."
75:075:0||du="nm" ||r="nm"||ln="list"m="percocet" 74:2 74:2||do="1-2 tablets" 74:3 74:4||mo="p.o."
74:5 74:5||f="q 4 prn" 74:674:8||du="nm"||r="nm"||ln="list"261ing medication related entities.In this study, we developed an SVM-basedNER system for recognizing medication relatedentities, which is a sub-task of the i2b2 chal-lenge.
We systematically investigated the effectsof typical local contextual features that have beenreported in many biomedical NER studies.
Ourstudies provided some valuable insights to NERtasks of medical entities in clinical text.3 MethodsA total of 268 annotated discharge summaries(17 from training set and 251 from test set) fromi2b2 challenge were used in this study.
This an-notated corpus contains 9,689 sentences, 326,474words, and 27,589 entities.
Annotated notes wereconverted into a BIO format and different typesof feature sets were used in an SVM classifier forNER.
Performance of the NER system was eva-luated using precision, recall, and F-score, basedon 10-fold cross validation.3.1 PreprocessingThe annotated corpus was converted into a BIOformat (see an example in Figure 2).
Specifically,it assigned each word into a class as follows: Bmeans beginning of an entity, I means inside anentity, and O means outside of an entity.
As wehave six types of entities, we have six different Bclasses and six different I classes.
For example,for medication names, we define the B class as?B-m?, and the I class as ?I-m?.
Therefore, wehad total 13 possible classes to each word(including O class).DISCHARGE MEDICATION:O OAdditionally, Percocet 1-2 TabletsO B-m B-do I-dop.o.
Q 4 prn,B-mo B-f I-f I-fFigure 2.
An example of the BIO representationof annotated clinical text (Where m as medica-tion, do as dose, mo as mode, and f as frequency).After preprocessing, the NER problem nowcan be considered as a classification problem,which is to assigns one of the 13 class labels toeach word.3.2 SVMSupport Vector Machine (SVM) is a machinelearning method that is widely used in manyNLP tasks such as chunking, POS, and NER.Essentially, it constructs a binary classifier usinglabeled training samples.
Given a set of trainingsamples, the SVM training phrase tries to findthe optimal hyperplane, which maximizes thedistance of training sample nearest to it (calledsupport vectors).
SVM takes an input as a vectorand maps it into a feature space using a kernelfunction.In this paper we used TinySVM1 along withYamcha23.3 Features setsdeveloped at NAIST (Kudo & Matsu-moto, 2000; Kudo & Matsumoto, 2001).
Weused a polynomial kernel function with the de-gree of kernel as 2, context window as +/-2, andthe strategy for multiple classification as pair-wise (one-against-one).
Pairwise strategy meansit will build K(K-1)/2 binary classifiers in whichK is the number of classes (in this case K=13).Each binary classifier will determine whether thesample should be classified as one of the twoclasses.
Each binary classifier has one vote andthe final output is the class with the maximumvotes.
These parameters were used in many bio-medical NER tasks such as (Takeuchi & Collier,2003; Kazama et al, 2002; Yamamoto et al,2003).In this study, we investigated different types offeatures for the SVM-based NER system for me-dication related entities, including 1) words; 2)Part-of-Speech (POS) tags; 3) morphologicalclues; 4) orthographies of words; 5)  previoushistory features; 6) semantic tags determined byMedEx, a rule based medication extraction sys-tem.
Details of those features are described be-low:x Words features: Words only.
We referred itas a baseline method in this study.x POS features: Part-of-Speech tags of words.To obtain POS information, we used a POStagger in the NLTK package31 Available athttp://chasen.org/~taku/software/TinySVM/.2 Available athttp://chasen.org/~taku/software/YamCha/3 www.nltk.org262x Morphologic features: suffix/prefix of up to3 characters within a word.x Orthographic features: information about if aword contains capital letters, digits, specialcharacters etc.
We used orthographic featuresdescribed in (Collier, Nobata, & Tsujii,2000) and modified some as for medicationinformation such as ?digit and percent?.
Wehad totally 21 labels for orthographic fea-tures.x Previous history features: Class assignmentsof preceding words, by the NER system it-self.x Semantic tag features: semantic categories ofwords.
Typical NER systems use dictionarylookup methods to determine semantic cate-gories of a word (e.g., gene names in a dic-tionary).
In this study, we used MedEx, thebest rule-based medication extraction systemin the i2b2 challenge, to assign medicationspecific categories into words.MedEx was originally developed at VanderbiltUniversity, for extracting medication informationfrom clinical text (Xu et al, 2010).
MedEx labelsmedication related entities with a pre-definedsemantic categories, which has overlap with thesix entities defined in the i2b2 challenge, but notexactly same.
For example, MedEx breaks thephrase ?fluocinonide 0.5% cream?
into drugname: ?fluocinonide?, strength: ?0.5%?, andform: ?cream?
; while i2b2 labels the wholephrase as a medication name.
There are a total of11 pre-defined semantic categories which arelisted in (Xu et al, 2010c).
When the Vanderbiltteam applied MedEx to the i2b2 challenge, theycustomized and extended MedEx to label medi-cation related entities as required by i2b2.
Thosecustomizations included:- Customized Rules to combine entities recog-nized by MedEx into i2b2 entities, such ascombine drug name: ?fluocinonide?,strength: ?0.5%?, and form: ?cream?
intoone medication name ?fluocinonide 0.5%cream?.- A new Section Tagger to filter some drugnames in sections such as ?allergy?
and?labs?.- A new Spell Checker to check whether aword can be a misspelled drug names.In a summary, the MedEx system will producetwo sets of semantic tags: 1) initial tags that areidentified by the original MedEx system; 2) finaltags that are identified by the customized MedExsystem for the i2b2 challenge.
The initial taggerwill be equivalent to some simple dictionary lookup methods used in many NER systems.
The fi-nal tagger is a more advanced method that inte-grates other level of information such as sectionsand spellings.
The outputs of initial tag include11 pre-defined semantic tags in MedEx, and out-puts of final tags consist of 6 types of NEs as inthe i2b2 requirements.
Therefore, it is interestingto us to study effects of both types of tags fromMedEx in this study.
These semantic tags werealso converted into the BIO format when theywere used as features.4 Results and DiscussionsIn this study, we measured Precision, Recall, andFeatures Pre Rec F-scoreWords (Baseline) 87.09 77.05 81.76Words + History 90.34 78.17 83.81Words + History + Morphology 91.72 81.08 86.06Words + History + Morphology + POS 91.81 81.06 86.10Words + History + Morphology + POS + Orthographies 91.78 81.29 86.22Words + Semantic Tags (Original MedEx) 90.15 83.17 86.51Words + Semantic Tags (Customized MedEx) 92.38 86.73 89.47Words + History + Morphology + POS + Orthographies + Semantic Tags(Original MedEx) 91.43 84.2 87.66Words + History + Morphology + POS + Orthographies + Semantic Tags(Customized MedEx) 93.2 87.12 90.05Table 2.
Performance of the SVM-based NER system for different feature combinations.263F-score using the CoNLL evaluation script4Table 2 shows the precision, recall, and F-score of the SVM-based NER system for all sixtypes of entities, when different combinations offeature sets were used.
Among them, the best F-score of 90.05% was achieved, when all featuresets were used.
A number of interesting findingscan be concluded from those results.
First, thecontribution of different types of features to thesystem?s performance varies.
For example, the?previous history feature?
and the ?morphologyfeature?
improved the performance substantially(F-score from 81.76% to 83.83%, and from83.81% to 86.06% respectively).
These findingswere consistent with previous reported results onprotein/gene NER (Kazama et al, 2002; Takeu-chi and Collier, 2003; Yamamoto et al, 2003).However, ?POS?
and ?orthographic?
featurescontributed very little, not as much as in pro-tein/gene names recognition tasks.
This could berelated to the differences between gene/proteinphrases and medication phrases ?
more ortho-graphic clues are observed in gene/proteinnames.
Second, the ?semantic tags?
featuresalone, even just using the original tagger in Me-dEx, improved the performance dramatically(from 81.76% to 86.51% or 89.47%).
This indi-.
Pre-cision is the ratio between the number of correct-ly identified NE chunks by the system and thetotal number of NE chunks found by the system;Recall is the ratio between the number of correct-ly identified NE chunks by the system and thetotal number of NE chunks in the gold standard.Experiments were run in a Linux machine with16GB RAM and 8 cores of Intel Xeon 2.0GHzprocessor.
The performance of different types offeature sets was evaluated using 10-fold cross-validation.4 Available athttp://www.cnts.ua.ac.be/conll2002/ner/bin/conlleval.txtcates that the knowledge bases in the biomedicaldomain are crucial to biomedical NER.
Third, thecustomized final semantic tagger in MedEx hadmuch better performance than the original tagger,which indicated that advanced semantic taggingmethods that integrate other levels of linguisticinformation (e.g., sections) were more usefulthan simple dictionary lookup methods.Table 3 shows the precision, recall, and F-score for each type of entity, from the MedExalone, and the baseline and the best runs of theSVM-based NER system.
As we can see, the bestSVM-based NER system that combines all typesof features (including inputs from MedEx) wasmuch better than the MedEx system alone(90.05% vs. 85.86%).
This suggested that thecombination of rule-based systems with machinelearning approaches could yield the most opti-mized performance in biomedical NER tasks.Among six types of medication entities, wenoticed that four types of entities (medicationnames, dosage, mode, and frequency) got veryhigh F-scores (over 92%); while two others (du-ration and reason) had low F-scores (up to 50%).This finding was consistent with results fromi2b2 challenge.
Duration and reason are moredifficult to identify because they do not havewell-formed patterns and few knowledge basesexist for duration and reasons.This study only focused on the first step of thei2b2 medication extraction challenge ?
NER.
Ournext plan is to work on the second step of deter-mining relations between medication names andother entities, thus allowing us to compare ourresults with those reported in the i2b2 challenge.In addition, we will also evaluate and comparethe performance of other ML algorithms such asCRF and ME on the same NER task.Entity MedEx only SVM (Baseline) SVM (Best)Pre Rec F-score Pre Rec F-score Pre Rec F-scoreALL 87.85 83.97 85.86 87.09 77.05 81.76 93.2 87.12 90.05Medication 87.25 90.21 88.71 88.38 75.03 81.16 93.3 91.35 92.31Dosage 92.79 83.94 88.14 89.43 83.65 86.41 94.38 90.99 92.65Mode 95.86 90.06 92.87 96.18 93.30 94.70 97.12 93.8 95.41Frequency 92.67 89.00 90.80 90.33 87.60 88.94 95.88 93.04 94.43Duration 42.65 40.15 41.36 24.16 19.62 21.45 65.18 40.16 49.57Reason 54.23 36.72 43.79 48.40 25.51 33.30 69.21 37.39 48.4Table 3.
Comparison between a rule based system and the SVM based system.2645 ConclusionsIn this study, we developed an SVM-based NERsystem for medication related entities.
We sys-tematically investigated different types of fea-tures and our results showed that by combiningsemantic features from a rule-based system, theML-based NER system could achieve the best F-score of 90.05% in recognizing medication re-lated entities, using the i2b2 annotated data set.The experiments also showed that optimizedusage of external knowledge bases were crucialto high performance ML based NER systems formedical entities such as drug names.AcknowledgementsAuthors would like to thank i2b2 organizers fororganizing the 2009 i2b2 challenge and provid-ing dataset for research studies.
This study was inpart supported by NCI grant R01CA141307-01.References:Aronson, A. R. (2001).
Effective mapping of biomed-ical text to the UMLS Metathesaurus: the MetaMapprogram.
Proc AMIA Symp., 17-21.Chhieng, D., Day, T., Gordon, G., & Hicks, J.
(2007).Use of natural language programming to extractmedication from unstructured electronic medicalrecords.
AMIA.Annu.Symp.Proc., 908.Collier, N., Nobata, C., & Tsujii, J.
(2000).
Extractingthe names of genes and gene products with a hiddenMarkov model.
Proc.of the 18th Conf.on Computa-tional linguistics., 1, 201-207.Doan, S., Bastarache L., Klimkowski S., Denny J.C.,& Xu, H. (2009).
Vanderbilt's System for Medica-tion Extraction.
Proc of 2009 i2b2 workshop..Evans, D. A., Brownlow, N. D., Hersh, W. R., &Campbell, E. M. (1996).
Automating concept iden-tification in the electronic medical record: an expe-riment in extracting dosage information.Proc.AMIA.Annu.Fall.Symp., 388-392.Friedman, C., Alderson, P. O., Austin, J. H., Cimino,J.
J., & Johnson, S. B.
(1994).
A general natural-language text processor for clinical radiology.J.Am.Med.Inform.Assoc., 1, 161-174.Halgrim, S., Xia, F., Solti, I., Cadag, E., & Uzuner, O.(2010).
Statistical Extraction of Medication Infor-mation from Clinical Records.
AMIA Summit onTranslational Bioinformatics, 10-12.Haug, P. J., Christensen, L., Gundersen, M., Clemons,B., Koehler, S., & Bauer, K. (1997).
A natural lan-guage parsing system for encoding admitting diag-noses.
Proc AMIA Annu.Fall.Symp., 814-818.Hirschman, L., Morgan, A.
A., & Yeh, A. S. (2002).Rutabaga by any other name: extracting biologicalnames.
J.Biomed.Inform., 35, 247-259.Kazama, J., Makino, T., Ohta, Y., & Tsujii, T. (2002).Tuning Support Vector Machines for BiomedicalNamed Entity Recognition.
Proceedings of theACL-02 Workshop on Natural LanguageProcessing in the Biomedical Domain, 1-8.Keerthi, S. & Sundararajan, S. (2007).
CRF versusSVM-struct for sequence labeling.
Yahoo ResearchTechnical Report.Krauthammer, M. & Nenadic, G. (2004).
Term identi-fication in the biomedical literature.J.Biomed.Inform., 37, 512-526.Kudo, T. & Matsumoto, Y.
(2000).
Use of SupportVector Learning for Chunk Identification.
Proc.ofCoNLL-2000.Kudo, T. & Matsumoto, Y.
(2001).
Chunking withSupport Vector Machines.
Proc.of NAACL 2001.Levin, M. A., Krol, M., Doshi, A. M., & Reich, D. L.(2007).
Extraction and mapping of drug names fromfree text to a standardized nomenclature.AMIA.Annu.Symp.Proc., 438-442.Li, D., Savova, G., & Kipper-Schuler, K. (2008).Conditional random fields and support vector ma-chines for disorder named entity recognition in clin-ical texts.
Proceedings of the workshop on currenttrends in biomedical natural language processing(BioNLP'08), 94-95.Li, Z., Cao, Y., Antieau, L., Agarwal, S., Zhang, Z., &Yu, H. (2009).
A Hybrid Approach to ExtractingMedication Information from Medical DischargeSummaries.
Proc of 2009 i2b2 workshop..Lindberg, D. A., Humphreys, B. L., & McCray, A. T.(1993).
The Unified Medical Language System.Methods Inf.Med., 32, 281-291.265Patrick, J.
& Li, M. (2009).
A Cascade Approach toExtract Medication Event (i2b2 challenge 2009).Proc of 2009 i2b2 workshop..Sirohi, E. & Peissig, P. (2005).
Study of effect of druglexicons on medication extraction from electronicmedical records.
Pac.Symp.Biocomput., 308-318.Takeuchi, K. & Collier, N. (2003).
Bio-medical entityextraction using Support Vector Machines.
Pro-ceedings of the ACL 2003 workshop on Naturallanguage processing in biomedicine, 57-64.Torii, M., Hu, Z., Wu, C. H., & Liu, H. (2009).
Bio-Tagger-GM: a gene/protein name recognition sys-tem.
J.Am.Med.Inform.Assoc., 16, 247-255.Tsochantaridis, I., Joachims, T., & Hofmann, T.(2005).
Large margin methods for structured and in-terdependent output variables.
Journal of MachineLearning Research, 6, 1453-1484.Uz?ner, O., Solti, I., & Cadag, E. (2009).
The third2009 i2b2 challenge.In https://www.i2b2.org/NLP/Medication/.Xu, H., Stenner, S. P., Doan, S., Johnson, K. B.,Waitman, L. R., & Denny, J. C. (2010).
MedEx: amedication information extraction system for clini-cal narratives.
J.Am.Med.Inform.Assoc., 17, 19-24.Yamamoto, K., Kudo, T., Konagaya, A., & Matsumo-to, Y.
(2003).
Protein name tagging for biomedicalannotation in text.
Proceedings of ACL 2003 Work-shop on Natural Language Processing inBiomedi-cine,2003, 13, 65-72.266
