Proceedings of the Second ACL Workshop on Effective Tools and Methodologies for Teaching NLP and CL, pages 62?68,Ann Arbor, June 2005. c?2005 Association for Computational LinguisticsHands-On NLP for an Interdisciplinary AudienceElizabeth D. Liddy and Nancy J. McCrackenCenter for Natural Language ProcessingSchool of Information StudiesSyracuse Universityliddy@syr.edu, njm@ecs.syr.eduAbstractThe need for a single NLP offering for adiverse mix of graduate students (includingcomputer scientists, information scientists,and linguists) has motivated us to develop acourse that provides students with a breadthof understanding of the scope of real worldapplications, as well as depth of knowledgeof the computational techniques on whichto build in later experiences.
We describethe three hands-on tasks for the course thathave proven successful, namely: 1) in-classgroup simulations of computational proc-esses;  2) team posters and public presenta-tions on state-of-the-art commercial NLPapplications, and; 3) team projects imple-menting various levels of human languageprocessing using open-source software onlarge textual collections.
Methods ofevaluation and indicators of success arealso described.1 IntroductionThis paper presents both an overview and some ofthe details regarding audience, assignments, tech-nology, and projects in an interdisciplinary courseon Natural Language Processing that has evolvedover time and been successful along multiple di-mensions ?
both from the students?
and the fac-ulty?s perspective in terms of accomplishments andenjoyment.
This success has required us to meetthe challenges of enabling students from a range ofdisciplines and diverse experience to each gain areal understanding of what is entailed in NaturalLanguage Processing.2 A Course Within Multiple CurriculaThe course is entitled Natural Language Processingand is taught at the 600 graduate course level in aSchool of Information Studies in a mid to large-size private university.
While NLP is not core toany of the three graduate degree programs in theInformation School, it is considered an importantarea within the Information School for both profes-sional careers and advanced research, as well as inthe Computer Science and Linguistic Programs oncampus.
The course has been taught every 1?
to 2years for the last 18 years.
While some aspects ofthe course have changed dramatically, particularlyin regards to the nature of the student team pro-jects, the basic structure ?
the six levels of lan-guage processing ?
has remained essentially thesame, with updates to topics within these levelsreflecting recent research findings and new appli-cations.3 AudienceAt the moment, this is the only course offering onNLP within the university, but a second-level,seminar course, entitled Content Analysis ResearchUsing Natural Language Processing, geared to-wards PhD students doing social science researchon large textual data sets, will be offered for thefirst time in Fall 2005.
Given that the current NLPcourse is the only one taught, it cannot, by neces-sity, have the depth that could be achieved in cur-ricula where there are multiple courses.
In a moreextensive curriculum, courses provide a greaterdepth than is possible in our single course.
Ourgoal is to provide students with a solid, broad basison which to build in later experiences, and to en-62able real understanding of a complex topic forwhich students realize there is a much greaterdepth of understanding that could be reached.The disciplinary mix of students in the course isusually an even mix of information science andcomputer science students, with slightly fewer lin-guistics majors.
Recently the Linguistics Depart-ment has established a concentration inInformation Representation and Retrieval, forwhich the NLP course is a required course.
Also,the course is cross-listed as an elective for com-puter science graduate students.
All of the abovefacts contribute to the widely diverse mix of stu-dents in the NLP course, and has required us todevelop a curriculum that enables all students to besuccessful in achieving solid competency in NLP.4 Topics CoveredThe topics in the course include typical ones cov-ered in most NLP courses and are organizedaround the levels of language processing and thespecific computational techniques within each ofthese.
Discussions of more general theoretic no-tions such as statistical vs. symbolic NLP, repre-sentation theories, and language modeling areinterspersed.
A single example of topics that aretaught within the levels of language processinginclude:Morphology - Finite state automataLexicology - Part-of-speech taggingSyntax - Parsing with context free grammarsSemantics - Word sense disambiguationDiscourse - Sublanguage analysisPragmatics - Gricean MaximsEach of the topics has assigned readings, from thecourse?s textbook, Speech and Language Process-ing: An Introduction to Natural Language Process-ing, Computational Linguistics, and SpeechRecognition by Daniel Jurafsky & James H. Mar-tin, as well as from recent and seminal papers.5 MethodsWhat really enables the students to fully grasp thecontent of the course are the three important hands-on features of the course, namely:1.
Small, in-class group simulations of compu-tational processes.2.
Team posters and public presentations re-porting on the state-of-the-art in commer-cial NLP applications such assummarization, text mining, machinetranslation, question answering, speechrecognition, and natural language genera-tion.3.
Team projects implementing various levelsof human language processing using open-source software on large collections.Each of these features of the course is described insome detail in the following sections.The course is designed around group projects,while the membership of the teams changes foreach assignment.
This is key to enabling a diversegroup to learn to work with students from differentdisciplines and to value divergent experience.
Ithas also proven extremely successful in forming aclass that thinks of itself as a community and inencouraging sharing of best practices so that eve-ryone advances their learning significantly furtherthan if working alone or with the same teamthroughout the course.
The way that teams areformed for the three types of projects varies, andwill be described in each of the following threesections.Furthermore, constant, frequent presentations tothe class of the group work, no matter how brief,enable students to own their newly-gained under-standings.
In fact, this course no longer requiresany written papers, but instead focuses on applica-tion of what is learned, first at the specific level oflanguage processing, then to new data for newpurposes, and then, to understanding real-worldNLP systems performing various applications ?with the group constantly reporting their findingsback to the class.5.1 In-class Group Simulations of Computa-tional ProcessesDuring the first third of the course, lectures oneach level of language processing are followed bya 30 to 45 minute exercise that enables the studentswho work in small groups to simulate the processthey have just learned about, i.e.
morphologicalanalysis, part-of-speech tagging, or parsing somesample sentences with a small grammar.
Thesegroups are formed by the professor in an ad hocmanner by counting off by 4 in a different patterneach week to ensure that students work with stu-63dents on the other side of the room, given thatfriends or students from the same school tend to sittogether.
After the exercise, each group has 5 min-utes to report back to the class on how they ap-proached the task, with visuals.We?ve found that the formation of these smallgroups is pedagogically sound and enables learningin three ways.
First, the groups break down socialbarriers and as the course advances the studentsfind it much easier to work together and are morecomfortable in sharing their work.
Secondly, thestudents begin to understand and value what thestudents from different disciplines bring to bear onNLP problems.
That is, the computer scientistsrecognize the value of the deeper understanding oflanguage of the linguistic students, and the linguis-tic students learn how the computer science stu-dents approach the task computationally.
Thirdly,while there were concerns on our part that thesesimulations might be too easy, the students haveaffirmed in mid-term course evaluations (which arenot required, but do provide invaluable insight intoa class?s engagement with and assimilation of thematerial) that these simulations really help them tounderstand conceptually what the task is and howit might be accomplished before they have toautomate the processes.5.2 Real World Applications of NLPThis year, two semester-long team projects wereassigned ?
the usual team-based computer imple-mentation of NLP for a particular computationaltask ?
and an investigation into how NLP is util-ized in various state-of-the-art commercial NLPapplications.
The motivation for adding this secondsemester-long team project was that a number ofthe students in the course, particularly the mastersstudents in Information Management, are mostlikely to encounter NLP in their work world whenthey need to advise on particular language-basedapplications.
It has become clear, however, that asa result of this assignment, all of the students arequite pleased with their own improved ability tounderstand what a language-based technology isactually doing.
Even if a student is more research-focused, they are intrigued by what might be doneto improve or add to a particular technology.Students are given two weeks to familiarizethemselves outside of class with the suggested ap-plications sufficiently to select a topic of real inter-est to them.
This year?s choices included SpellCorrection, Machine Translation, Search Engines,Text Mining, Summarization, Question Answer-ing, Speech Recognition, Cross-Language Infor-mation Retrieval, Natural Language Generation,and Dialogue Agents.Students then sign up, on a first-come basis, fortheir preferred application.
The teams are keptsmall (up to four) to ensure that each student con-tributes.
At times a single student is sufficientlyinterested in a topic that a team of one is formed.Students arrange their own division of labor.
Thereare three 10 to 20 minute report-backs by eachteam over the course of the semester, the first twoto the class and the final one during an open invita-tion, school-wide Poster & Reception event.
Thereare guidelines for each of the three presentations,as well as a stated expectation that the teams ac-tively critique and comment on the presentations,both in terms of the information presented as wellas presentational factors.
Five minutes are allowedfor class comments and students are graded on howactively they participate and provide feedback.The 1st presentation is a non-technical overviewof what the particular NLP application does andincludes examples of publicly available systems /products the class might know.
The 2nd presenta-tion covers technical details of the application,concentrating on the computational linguistic as-pects, particularly how such an application typi-cally works, and the levels of NL processing thatare involved (e.g., lexical, syntactic, etc).
The 3rdpresentation involves a poster which incorporatesthe best of their first two presentations and sugges-tions from the class, plus a laptop demo if possible.As stated above, the 3rd presentation is done inan open school-wide Poster and Reception eventwhich is attended by faculty and students, mainlyPhD students.
The Poster Receptions have provenvery successful along multiple dimensions ?
first,the students take great pride in the work they arepresenting;  second, posters are better than one-time, in-class presentations as the multiple oppor-tunities to explain their work and get feedback im-prove the students?
ability to create the bestpresentation of their work; third, the wider expo-sure of the field and its applications builds an audi-ence for future semesters and instills in the studentbody a sense of the reach and importance of NLP.5.3 Hands-On NL Processing of Text64The second of the semester-long team projects isthe computer implementation of NLP.
The goal ofthe project is for students to gain hands-on experi-ence in utilizing NLP software in the context ofaccomplishing analysis of a large, real-world dataset.
The project comprises two tasks, each of whichis reported back to the class by each team.
Thesepresentations were not initially in the syllabus, butinterestingly, the students requested that each teampresent after each task so that they could all learnfrom the experiences of the other teams.The corpus chosen was the publicly availableEnron email data set, which consists of about250,000 unique emails from 150 people.
With du-plication, the data has approximately 500,000 filesand takes up 2.75 gigabytes.
The data set was pre-pared for public release by William Cohen at CMUand, available at http://www-2.cs.cmu.edu/~enron/.This data set is useful not only as real text of theemail genre, but it can be easily divided intosmaller subsets suitable for student projects.
(And,of course, there is also the human interest factor inthat the data set is available due to its use in theEnron court proceedings!
)The goal of the project is to use increasing lev-els of NLP to characterize a selected subset of En-ron email texts.
The project is designed to becarried out in two parts, involving two assignedlevels of NLP.
The first level, part-of-speech tag-ging, is accomplished as Task 1 and the second,phrase-bracketing or chunk-parsing, is assigned asTask 2.
However, the overall characterization ofthe text is left open-ended, and the student teamschose various dimensions for their analyses.
Pro-jects included analyzing the topics of the emails ofdifferent people, social network analyses based onpeople and topics mentioned in the email text, andanalyses based on author and recipient header in-formation about each email.Teams are established for these projects by theprofessor based on the capabilities and interests ofthe individual students as reported in short self-surveys.
This resulted in teams on which there is amix of computer science, linguistics and informa-tion science expertise.
The teams accomplished thetasks of choosing a data analysis method, process-ing data subsets, designing NL processing to ac-complish the analysis, programming the NLprocessing, conducting the data analysis, and pre-paring the in-class reports.5.3.1 Tools Used in the ProjectFor preliminary processing of the Enron emailfiles, programs and data made available by Profes-sor Andr?s Corrada-Emmanuel at the University ofMassachusetts at Amherst, and available athttp://ciir.cs.umass.edu/~corrada/ were used.
Theemails were assigned MD5-digest numbers in or-der to identify them uniquely, and the data con-sisted of mappings from the digest numbers tofiles, as well as to authors and recipients of theemail.
The programs contained filters that could beused to remove extraneous text such as headers andforwarded text.
The teams adapted parts of theseprograms to convert the email files to files withtext suitable for NL processing.For the NL processing, the Natural LanguageToolkit (NL Toolkit or NLTK), developed at theUniversity of Pennsylvania by Loper and Bird(2002), and available for download from Source-Forge at http://nltk.sourceforge.net/ was used.
TheNL Toolkit is a set of libraries written in the Py-thon programming language that provides coredata types for processing natural language text,support for statistical processing, and a number ofstandard processing algorithms used in NLP, in-cluding tokenization, part of speech (POS) tagging,chunk parsing, and syntactic parsing.
The toolkitprovides demonstration packages, tutorials, exam-ple corpora and documentation to support its use ineducational classes.
Experience using the Toolkitshows that in order to use the NL Toolkit, onemember of each team should have at least someprogramming background in order to write Pythonprograms that use the NL Toolkit libraries.
Theuse of Python as the programming language wassuccessful in that the level needed to use the NLToolkit was manageable by the students with onlya little programming background and in that thecomputer science students were able to adapt to thePython programming style and could easily utilizethe classes and libraries.At the beginning of the term project, the stu-dents were offered a lab session and lab materialsto get them started.
Since no one knew the Pythonprogramming language at the outset, there was aninitial learning curve for the Python language aswell as for the NL Toolkit.
The lab materials pro-vided to the students consisted of installation in-structions for Python and NL Toolkit and a numberof example programs that combined programming65snippets from the NL Toolkit tutorials to processtext through the NLP phases of tokenization, POStagging and the construction of frequency distribu-tions over the POS tagged text.
During the lab ses-sion, some of the example programs were workedthrough as a group with the goal of enabling thestudents to become competent in Python and tointroduce them to the NL Toolkit tutorials that hadadditional materials.
The NL Toolkit tutorials areextensive on the lower levels of NL processing(e.g.
lexical and syntactic) and students with someprogramming background were able to utilizethem.As part of their first task, the student teams wereasked to select a subset of the Enron emails towork with.
The entire Enron email directories wereplaced on a server for the teams to look at in mak-ing their selections.
The teams also used informa-tion about the Enron employees as described in apaper by Corrada-Emmanuel (2005).
Some studentteams elected to work with different email topicfolders for one person, while others chose a fewemail folders each from a small number of people(2-5).
Their selected emails first needed to beprocessed to text using programs adapted fromCorrada-Emmanuel.
For the most part, the sub-corpora choices of the student teams worked outwell in terms of size and content.
Several hundredemails turned out to be a good size, providingenough data to experience the challenges of longprocessing times and to appreciate why NLP isuseful in processing large amounts of data, withoutbeing unduly overwhelmed.
Initially, one teamchose all the emails from several people.
Thenumber of email files involved was several thou-sand and it took several hours to unzip those direc-tories, let alne process them, and theysubsequently reduced the number of files for theiranalysis.The first task was to analyze the chosen emailsbased solely on lexical level information, namelywords with POS tags.
NL Toolkit provides librar-ies for tokenization where the user can define thetokens through regular expressions, and the stu-dents used these to tailor the tokenization of theiremails.
The Toolkit also provides a regular expres-sion POS tagger as well as n-gram taggers, and thestudents used these in combination for their POStagging.
Students experimented with the Browncorpus and a part of the Penn Treebank corpus,provided by NL Toolkit to train the POS taggers,and compared the results.Building on the first task, the second task ex-tended the analysis of the chosen emails to phrasesfrom the text.
Again, NL Toolkit provides a libraryfor chunk parsing where regular expressions can beused to specify patterns of words with POS tagseither to be included or excluded from phrases.Since chunk parsing depends on POS tagging,there was a need for a larger training corpus.
Aresearch center within the Information School hasa license for Penn Treebank, and  provided addi-tional Penn Treebank files for the class to use forthat purpose.
Most teams used regular expressionsto bracket proper names, minimal noun phrases,and verb phrases.
One team used these to groupmaximal noun phrases, and another team usedregular expressions to find patterns of communica-tion verbs for use in social network analysis.In retrospect, it was found that the chunk pars-ing did not take the teams far enough in NLPanalysis of text.
Experience in teaching using theNL Toolkit suggests that use of the syntactic pars-ing libraries to find more complex structures in thetext would have provided more depth of analysis.Students also suggested that they would have likedto incorporate semantic level capabilities, such asthe use of WordNet to find conceptual groupingsvia synonym recognition.
The next offering of thecourse will include these improvements.Using the NL Toolkit for NL processing workedout well overall and enabled the students to ob-serve and appreciate details of the processing stepswithout having to write a program for every algo-rithm themselves.
The tutorials are good, both atexplaining concepts and providing programmingexamples.
There were a few places where somedata structure details did not seem to be suffi-ciently documented, either in the tutorials or in theAPI.
This was true for  the recently added BrillPOS tagger, and is likely due to its recency of ad-dition to the toolkit.
However for the most part,the coverage of the documentation is impressive.6 EvaluationMultiple types of evaluation are associated withthe course.
First, the typical evaluation of the stu-dents by the professor (here, 2 professors) wasdone on multiple dimensions that contributed pro-portionately to the student?s final grade as follows:66?
In-Class group exercises 20%?
NLToolkit Team Assignments 35%?
NLP Application Team Poster &Presentations35%?
Contributions to class discussion(both quality and quantity)10%Additionally, each team member evaluated each oftheir fellow team members as well as themselves.This was done for both of the teams in which astudent participated.
For each team member, thequestions covered:  the role or tasks of the studenton the project; an overall performance rating from1 for POOR to 4 for EXCELLENT; the rationalefor this score, and finally; what the student couldhave done to improve their contribution.
Knowl-edge of this end-of-semester team self-evaluationtended to ensure that students were active teamcontributors.The professor was also evaluated by the stu-dents.
And while there are quantitative scores thatare used by the university for comparison acrossfaculty and to track individual faculty improve-ments over time, the most useful feature of the stu-dent evaluations is the set of open-ended questionsconcerning what worked well in the course, whatdidn?t work well, and what could be done to im-prove the course.
Over the years of teaching thiscourse, these comments (plus the mid-term evalua-tions) have been most instructive in efforts to findways to improve the course.
Frequently the sugges-tions are very practical and easy to implement,such as showing a chart with the distribution ofgrades on each assignment when they are returnedso that the students know where they stand relativeto the class as grading is on a scale of 1 to 10.7.
Indicators of SuccessFinally, how is the success of this course measuredin the longer term?
For this, success is measuredby:  whether students elect to do continued work inNLP, either in the context of further courses inwhich NLP is utilized, such as Information Re-trieval or Text Mining;  whether the masters (andundergraduate) students decide to pursue an ad-vanced degree based on the excitement engenderedand knowledge gained from the NLP course; orwhether PhD students elect to do continued re-search either in the school?s Center for NaturalLanguage Processing or as part of their disserta-tion.
For students in a terminal degree program,success is reflected by their seeking and obtainingjobs that utilize the NLP they have learned in thecourse and that has provided them with a solid,broad basis on which to build.
For several of theundergraduate computer science students in thecourse, their NLP experience has given them anadded dimension of specialization and competitiveadvantage in a tight hiring market.An additional measure of success was the re-quest by the doctoral students in the home schoolfor a PhD level seminar course to build on the NLPcourse.
This course is entitled Content AnalysisResearch Using Natural Language Processing andwill enable PhD students doing social science re-search on large textual data sets to explore and ap-ply the NLP tools that are developed within theschool, as well as to understand how these NLPtools can be successfully interleaved with commer-cial content analysis tools to support rich explora-tion of their data.
As is the current course, thisseminar will be open to PhD students from allschools across campus and already has enrolleesfrom public policy, communications, and man-agement, as well as information science.8.
SummaryWhile it might appear that a disproportionateamount of thought and attention is given to themore human and social aspects of designing andconducting this course, experience shows that suchattention is the key to the success of this diversebody of students in learning and understanding thecontent of the course.
Furthermore, given the greatdiversity in class-level and disciplinary back-ground of students, this attention to structuring thecourse has paid off in the multiple ways exempli-fied above.
While it is obvious that a course forcomputer-science majors alone would be designedquite differently, it would not provide the enrichedunderstanding of the field of NLP and its applica-tion value that is possible with the contributions bythe variety of disciplines brought together in thiscourse.Acknowledgements67We would like to acknowledge the contributions ofthe students in all the classes over the years whoseefforts and suggestions have continually improvedthe course.
We would to especially acknowledgethis year?s class, who were especially contributoryof ideas for improving and building on a currentlysuccessful course, namely Agnieszka Kwiat-kowska, Anatoliy Gruzd, Carol Schwartz, Cun-Fang Cheng, Freddie Wade, Joshua Legler, Kei-suke Inoue, Matthew Wolf, Michael Fudge, MichelTinuiri, Olga Azarova, Rebecca Gilbert, ShuyuanHo, Tuncer Can, Xiaozhony Liu, and Xue Xiao.ReferencesLoper, E. & Bird, S., 2002.
NLTK, the NaturalLanguage Toolkit.
In Proceedings of the ACLWorkshop on Effective Tools and Methodolo-gies for Teaching Natural Language Processingand Computational Linguistics.
Philadelphia:Association for Computational Linguistics.Corrada-Emmanuel, A. McCallum, A., Smyth, P.,Steyvers, M. & Chemudugunta, C., 2005.
SocialNetwork Analysis and Topic Discovery for theEnron Email Dataset.
In Proceedings of theWorkshop on Link Analysis, Counterterrorismand Security at 2005 SIAM International Con-ference in Data Mining.68
