Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 525?530,Berlin, Germany, August 7-12, 2016.c?2016 Association for Computational LinguisticsClaim Synthesis via Predicate RecyclingYonatan BiluIBM Haifa Research LabMount Carmel, Haifa, 31905Israelyonatanb@il.ibm.comNoam SlonimIBM Haifa Research LabMount Carmel, Haifa, 31905Israelnoams@il.ibm.comAbstractComputational Argumentation has twomain goals - the detection and analysis ofarguments on the one hand, and the syn-thesis of arguments on the other.
Much at-tention has been given to the former, butconsiderably less to the latter.A key component in synthesizing argu-ments is the synthesis of claims.
One wayto do so is by employing argumentationmining to detect claims within an appro-priate corpus.
In general, this appears tobe a hard problem.
Thus, it is interesting toexplore if - for the sake of synthesis - theremay be other ways to generate claims.Here we explore such a method: we ex-tract the predicate of simple, manually-detected, claims, and attempt to generatenovel claims from them.
Surprisingly, thissimple method yields fairly good results.1 IntroductionWhen people argue, how do they come up with thearguments they present, and can a machine emu-late this?
The motivation for this work comes fromthis second question, for which the relevant field ofstudy is Computational Argumentation, an emerg-ing field with roots in Computer Science, Mathe-matics, Philosophy and Rhetorics.
However, whilemuch attention is given in the field to the modelingand analysis of arguments, automatic synthesis ofarguments receives considerably less.So, how do people come up with arguments?One way is to read-up on the topic and presentthe arguments you find in the literature.
Another- if the topic at hand is within your field of ex-pertise - is to communicate your opinion.
Yet athird way is to ?recycle?
arguments you are famil-iar with and apply them to new domains.
For ex-ample, someone who?s concerned about the freespeech might use an argument like ?it?s a viola-tion of free speech?
when discussing any one ofthese topics: whether violent video games shouldbe banned, whether some Internet content shouldbe censored, or whether certain types of advertise-ment should be restricted.Argumentation Mining (Mochales Palau andMoens, 2011) is analogous to the first option:Given a corpus, it aims to detect arguments therein(and the relations among them).
Thus, it can beused to suggest claims when a relevant corpus isavailable.
The second option is analogous to Natu-ral Language Generation (NLG; (Reiter and Dale,2000)), where applications such as recommendersystems synthesize arguments to explain their rec-ommendations, as done for example in (Careniniand Moore, 2006) .These approaches yield good results when ap-plied to specific domains.
In an NLG applica-tion, there is commonly a specific knowledge basewhich the system communicates.
The form andcontent of arguments are derived and determinedby it and are thus limited to the knowledge therein.Similarly, argument mining works well when anargument-rich and topic-related corpus is available- e.g.
(Wyner et al, 2010) - but in general seemsto be hard (Levy et al, 2014).
Thus, it is interest-ing and challenging to synthesize arguments in anopen domain.
To the best of our knowledge, this isthe first work that directly attempts to address thistask.Modeling of arguments goes back to the an-cient Greeks and Aristotle, and more modern workstarting perhaps most famously with the Toulminargument model (Toulmin, 1958).
A common el-ement in all such models is the claim (or conclu-sion) being forwarded by the argument.
Thus, anatural first step in synthesizing arguments in ageneral setting is being able to synthesize claimsin such a setting.We suggest here a simple way for doing so,525based on the aforementioned notion of argument?recycling?.
Specifically, that the predicate of aclaim - what it says on the topic at hand - maybe applicable to other topics as well.
For exam-ple, if we are familiar with the claim ?banning vi-olent video games is a violation of free speech?in the context of the topic ?banning violent videogames?, we could synthesize the claim ?Internetcensorship is a violation of free speech?
when pre-sented with the topic ?Internet Censorship?.
Thechallenge is then to determine whether the synthe-sized claim is actually coherent and relevant to thenew topic, which we do using statistical MachineLearning techniques, as described in Section 2.1.This two-stages framework - generating textand then selecting whether or not it is appropriate -is reminiscent of Statistical NLG (SNLG; (Langk-lide and Knight, 1998)).
In an SNLG system, af-ter the macro-planning and micro-planning stages(see (Reiter and Dale, 2000)) are executed, and themessage to be communicated is determined, mul-tiple candidate realizations are produced, and thenstatistical methods are used to determine which ofthese realizations is the best (based on a referencecorpus).Our work differs from SNLG in that there are nopre-determined messages.
The generation stageproduces candidate content.
Each candidate claimis a different message, and the selection stage at-tempts to identify those which are coherent andrelevant, rather than best realized.
In other words,while the classical NLG paradigm is to first se-lect the content and then realize it in a natural lan-guage, here our building blocks from the onset arenatural language elements, and statistical methodsare used to determine which content selections -implied by combining them - are valid.Finally, the notion that predicates of claims re-garding one topic may be applicable to anotheris reminiscent of the motivation for the work of(Card et al, 2015), who observe that there arecommonalities (so called ?framing dimensions?
)among the way different topics are framed in newsarticles.2 AlgorithmThe claim synthesis algorithm is composed ofthree components.
The first is a pre-processingcomponent, in which the Predicate Lexicon is con-structed.
The second is the Generation Compo-nent - the input to this component is a topic (andthe Predicate Lexicon), and the output is a list ofcandidate claims.
The final component is the Se-lection Component, in which a classifier is used todetermine which (if any) of the candidate claimsare coherent and relevant for the topic.
In whatfollows we describe these three steps in greater de-tail.The Predicate Lexicon (PL) was constructed byparsing manually-detected claims (Aharoni et al,2014) using the Watson ESG parser (McCord etal., 2012), and considering those which have ex-actly one verb.
Then the verb and a concatena-tion of its right-modifiers, termed here the pred-icate, were extracted from each claim and addedto the PL if they contained at least one sentimentword from the sentiment lexicon of (Hu and Liu,2004).
The sentiment criterion was added to se-lect for predicates which have a clear stance withrespect to the topic.
All in all, there are 1203 en-tries in the PL used here.1A key feature in filtering and selecting can-didate claims is text similarity.
The similaritybetween text segments was defined based onthe constituent words?
word2vec embedding(Mikolov et al, 2013): Consider two list of words,l = w1, .
.
.
, wnand l?= w?1, .
.
.
, w?n?.
Denoteby w2v(w,w?)
the word2vec similarity betweenw and w?- the cosine of the angle between theembeddings of w and w?.
Then the similar-ity between l and l?is defined : sim(l, l?)
=1n?i=1,...,nmaxj=1,...,n?w2v(wi, w?j) +1n?
?j=1,...,n?maxi=1,...,nw2v(w?j, wi) (wordswithout embeddings are ignored).
Addition-ally, if S is a set of text segments, define:sim(l, S) = maxl?
?Ssim(l, l?
).Given a new topic t, the Generation Compo-nent sorts the predicates p in the PL according tosim(t, p), and takes the top k. It then constructsk claim candidate sentences by setting the subjectof the sentence to be the topic t, and the predicateto be one of these k. This may require some ma-nipulation, as the plurality of the topic determinesthe appropriate surface realization of the predicateverb.
We determine the topic?s plurality using theWatson parser (McCord et al, 2012), and do thesurface realization with SimpleNLG (Gatt and Re-iter, 2009) and the NIH lexicon2.1data is avaiable at https://www.research.ibm.com/haifa/dept/vst/mlta_data.shtml.2UMLS Reference Manual [Internet].
Bethesda (MD):National Library of Medicine (US); 2009 Sep-.
6, SPE-CIALIST Lexicon and Lexical Tools.
Available from:526The Selection Component uses a logistic regres-sion classifier to first predict which of the candi-date claims generated by the Generation Compo-nent are valid, and then to rank the valid candi-dates according to the classifier?s score.
It receivestwo parameters, ?
and ?
.
If the fraction of validcandidates (according to the classifier) is less than?
, then it selects none of them.
This is designedto allow the algorithm not to synthesize claims fortopics where the PL does not seem to yield a sub-stantial number of valid claims.
If the number ofvalid candidates is at least ?
, the top ?
valid candi-dates are returned (or all of them, if there are lessthan ?
).2.1 Classification FeaturesTo describe the classification features used, weneed to define - given a topic - the topic?s n-gramLexicon (n-TL).
This is a list of n-grams whichare presumably related to the topic.
Specifically,given an n-gram, we assume its appearance inWikipedia articles follows a hyper-geometric dis-tribution, and estimate the distribution?s parame-ters by counting the n-gram?s appearance in a largeset of Wikipedia articles.
With these parameters,the p-value for its appearances in topic-related ar-ticles is calculated.
The n-TL is the list of n-gramswith Bonferroni-corrected p-value at most 0.05.The topic-related articles were identified manually(see (Aharoni et al, 2014)).For a candidate claim c, denote its words byw1, .
.
.
, wm.
Recall that c is composed of thegiven topic, t, and a predicate p ?
PL.
Recallalso that pwas extracted from a manually-detectedclaim cp.
Denote by tpthe topic for which cpwasdetected, and by spthe subject of the claim sen-tence cp.
Denote by mtthe number of words int.For example, consider the second candidateclaim in Table 1, c = Truth and reconciliationcommissions are a source of conflict.
There t =truth and reconciliation commissions and p = area source of conflict.
pwas extracted from the claimcp= religion is a source of conflict in the labeleddata, which is associated with the topic atheism(and the debatabase motion atheism is the onlyway).
Hence, tp= atheism and sp= religion.The classification features we used are of threetypes: One aims to identify predicates which areinherently amenable to generation of claims, thathttp://www.ncbi.nlm.nih.gov/books/NBK9680/is, which state something fairly general about theirsubject, and which are not very specific to thetopic in which the predicate was originally found(e.g., low sim(p, tp)).
The second aims to findpredicates which are relevant for the new topic forwhich claims are synthesized (e.g., high sim(p,n-TL)).
Finally, we?d like the claim to be a valid andplausible sentence, and so look for the frequencyof its words, and sub-phrases of it, in Wikipedia.All in all 15 features were defined: m, thenumber of words in c; Number of Lucene hitsfor w1, .
.
.
, wm(as a bag of words); Number ofWikipedia sentences containing all w1, .
.
.
, wm;Largest k, such that the k-gram w1.
.
.
wkap-pears in Wikipedia; Number of times the 3-gramwmtwmt+1wmt+2appears in Wikipedia; Numberof times p appears in a claim candidate labeledpositive, and the number of times in one labelednegative (claim candidates generated for t are ex-cluded, see Section 3 for labeling details); Inclu-sion of p?s verb in a manually-crafted list of ?cau-sation verbs?
; sim(p,n-TL) , for n = 1, 2, 3;sim(p, t); sim(p, tp); sim(sp, tp); sim(sp, t).3 Experimental SetupWe generated claims for 67 topics, extracted fromdebatabase motions (http://idebate.org)for which we have previously annotated relevantWikipedia articles (for the benefit of the n-TLsconstruction; see Section 2.1).
Importantly, whengenerating candidate claims for a topic, predicateswhich originated from this topic were not used.For each topic 28 candidate claims were gener-ated, and in addition one manually-detected claim(as per (Aharoni et al, 2014)) and one mock claimwere included for control.
The mock claim wasconstructed by setting the topic as the subject ofa sentence, and selecting a mock predicate at ran-dom from a hand-crafted list.These 67?
30 candidate claims were annotatedusing Amazon?s Mechanical Turk (AMT).
In eachHIT (Human Intelligence Task) we presented theannotators with a debatabase motion and 10 can-didate claims, and asked which of the claims is ap-propriate for the motion (10 annotators per HIT).After filtering out the less reliable annotatorsbased on mutual agreement and control questions,a reasonable agreement was apparent (average?
= 0.73).
After this filtering 45 of the ini-tial 82 annotators remained, as well as 955 of theinitial 2010 annotated candidate claims (discard-527Claim OriginalSubjectLabelDemocratization con-tributes to stability.Nuclearweapons1Truth and reconciliationcommissions are a sourceof conflict.Religion 1Graduated response lacksmoral legitimacy.The State 1Nuclear weapons causelung cancer.Smoking 0A global language leadsto great exhaustion.Great anar-chy0Table 1: Examples of candidate claims (top-ics in italics, predicates in bold), the subjectof the claim sentence which originated theirpredicate, and their label.ing claims with less than 5 valid annotators, thosewithout a clear majority decision, as well as thecontrol claims).
See Table 1 for some examples.We note that annotation tasks like this are in-herently subjective ((Aharoni et al, 2014) report?
= 0.4), so discarding candidates without aclear majority decision can be seen as discardingthose for which the true label is not well defined.Nonetheless, the reason for discarding most of thecandidate claims was annotator?s (lack of) reliabil-ity, not ambiguity of the true label.4 Experimental ResultsInitially we thought to label a candidate claim aseither positive or negative examples, based on themajority vote of the annotators.
This lead to aseemingly 52% of the candidates being ?good?.However, anecdotal examination of this majoritylabeling suggested that the many annotators werebiased toward answering ?good?
- even on some ofthe control questions which contained nonsensicalsentences.
This, along side relatively low meanagreement, raised the need for filtering mentionedabove.
After filtering, 40% of the candidate claimswere taken to be positive examples.
The accuracyof the Selection Component was assessed using aleave-one-out methodology, leaving out one topicat each iteration.
The overall accuracy achieved bythe classifier was 0.75 (Table 2 depicts the confu-sion matrix).We also examined the trade-off between thenumber of selected candidate claims and the frac-tion of them which are valid.
Figure 1 depicts thePredict /Label Pos NegPos 288 (30%) 145 (15%)Neg 96 (10%) 426 (45%)Table 2: Confusion Matrix: Number ofclaim candidates according to AMT annota-tion (x-axis) and predicted label (y-axis).average precision when varying the two SelectionComponent parameters, ?
and ?
.
For example,at the most conservative setting, where the com-ponent outputs at most one claim per topic, andonly for a topic for which at least half the candi-date claims were predicted to be valid (31 of the67 topics), the precision is 0.94.
Recall that in theentire dataset, 40% of the examples are positive.Figure 1: Mean Precision (micro average):Colors indicate different values of ?
.
Inparenthesis is the number of topics for whichclaims were selected.We note that this precision is significantlyhigher than reported for claim detection (Levy etal., 2014), where, for example, mean precision at5 is 0.28 (in our case it is 0.7 ?
0.8).
One shouldnote, however, that this is not a fair comparison.First, we permit the algorithm to discard some top-ics.
Second, here the definition of a valid claim isless strict than in (Levy et al, 2014).Examining the impact of individual features, wefirst looked which of them, on their own, are mostcorrelated with the labels.
These turned out to bethe number of times p appears in a claim candi-date labeled positive and negative (Pearson?s cor-relation 0.33 and -0.34 resp.).
We then examinedwhich features received the most weight in the lo-gistic regression classifier (trained over all data;features were scaled to a [0, 1]).
The top featurewas the number of sentences in which all words528appear, and following it were the aforementionedappearance counts in negative and positive exam-ples.5 Discussion and Work in ProgressThe Generation Component can be thought ofas constructing sentences by using pre-definedtemplates, of the form ?<topic-slot> <extractedpredicate>?.
These ?generation templates?
arecreated by ?mining?
a corpus of manually-detected claims and extracting the predicate fromthem.
They are then filled in during run-time, byinserting a new topic in that slot.
There are sev-eral ways which we have started exploring to ex-tend this paradigm - automatically identifying thegrammatical position of a?topic slot?
in a corpusclaim rather than assuming it is the subject; usingunsupervised methods for mining the predicatesdirectly from Wikipedia; and generating candidateclaims by using several variants for the subject andobject, rather than just the topic and the PL entry.Initial results are promising, but more work is re-quired to achieve reasonable accuracy.Another interesting alternative is to constructthe PL manually, rather than automatically.
Thiscan be seen as analogous to ArgumentationSchemes (Walton et.
al, 2008).
ArgumentationSchemes can be thought of as templates for model-ing arguments - defining a slot for a premise or two(which may be implicit), a slot for a conclusion orclaim, and some fixed connecting text.
While Ar-gumentation Schemes are used for detecting (Wal-ton, 2012) and analyzing argumentative structures,in principle they can also be used to synthesizethem.
In this sense, our work here can be seenas applying the same concept at finer granularity -at the claim level instead of the argument.While at the onset we presented claim synthe-sis as an alternative to argumentation mining forthe purpose of generating arguments, it is interest-ing how the two augment each other.
Specifically,we have started looking at whether claim synthe-sis can generate claims which do not appear in ourcorpus (Aharoni et al, 2014), and whether match-ing Evidence to claims (Rinott et.
al, 2015) canimprove claim synthesis.
Regarding the noveltyof synthesized claims, we looked at 18 synthesizedclaims, labeled as valid for 3 topics - criminaliza-tion of blasphemy, building high-rise for housingand making physical education compulsory - andcompared them to the 94 manually detected claimsfor these topics (each topic separately).
Of the 18claims, 5 appear to be novel.A more circumvent method to assess novelty isas follows - for each candidate claim we lookedfor the most similar claim (for the same topic) inour annotated data.
We then computed Pearson?scorrelation between these similarity scores and thelabels of the candidate claim, getting a coefficientof 0.29 (p-value=10?27).
This is similar to thecorrelation between for the strongest classificationfeatures, suggesting again that many of the gener-ated claims are not novel, yet similarity to anno-tated claims on its own is not enough to determinea candidate-claim?s validity.Similarly, we examined whether having amatching evidence in the annotated corpus(matches were determined using the algorithm of(Rinott et.
al, 2015)), is indicative of a candidate-claim?s validity.
Computing correlation (over the51 topic for which annotated evidence was avail-able) gave a Pearson?s coefficient of 0.23.
Thissuggests that matching Evidence can be a power-ful feature in improving our current classificationmodel.6 AcknowledgementsWe thank Liat Ein-Dor for her contibution to thiswork, and especially for the development of theTopic Lexicons.
We thank Uri Zakai, Ran Levyand Daniel Hershcovich for insightful discussions.ReferencesEhud Aharoni, Anatoly Polnarov, Tamar Lavee, DanielHershcovich, Ran Levy, Ruty Rinott, Dan Gutfre-und, Noam Slonim.
A Benchmark Dataset for Auto-matic Detection of Claims and Evidence in the Con-text of Controversial Topics 2014.
Workshop onArgumentation Mining, ACLNgo Xuan Bach, Nguyen Le Minh, Tran Thi Oanh, andAkira Shimazu.
A Two-Phase Framework for Learn-ing Logical Structures of Paragraphs in Legal Arti-cles.
2013.
In ACM Transactions on Asian Lan-guage Information Processing (TALIP).
12(1):3Dallas Card, Amber E. Boydstun, Justin H. Gross,Philip Resnik and Noah A. Smith.
The MediaFrames Corpus: Annotations of Frames Across Is-sues.
2015.
Association for Computational Linguis-tics Conference (ACL).Carenini, Giuseppe, and Johanna D. Moore.
Generat-ing and evaluating evaluative arguments.
ArtificialIntelligence 170, no.
11: 925-952.529A Gatt and E Reiter (2009).
SimpleNLG: A realisationengine for practical applications.
2009.
Proceed-ings of ENLG-2009.Minqing Hu and Bing Liu.
2004.
Mining and summa-rizing customer reviews.
2004.
In Knowledge Dis-covery and Data Mining: 168-177.J.R.
Landis and G.G.
Kock.
The measurement of ob-server agreement for categorical data?.
1977.
Bio-metrics 33 (1): 159174.Irene Langkilde and Kevin Knight.
Generation that ex-ploits corpus-based statistical knowledge.
1998.
InProceedings of the 36th Annual Meeting of the Asso-ciation for Computational Linguistics and 17th In-ternational Conference on Computational Linguis-tics - Volume 1 (ACL ?98), Vol.
1.
Association forComputational Linguistics, Stroudsburg, PA, USA704-710.Ran Levy, Yonatan Bilu, Daniel Hershcovich, EhudAharoni and Noam Slonim.
Context DependentClaim Detection 2014.
In The 25th InternationalConference on Computational LinguisticsMcCord, Michael C., J. William Murdock, and Bran-imir K. Boguraev.
Deep parsing in Watson.
2012IBM Journal of Research and Development 56, no.3.4: 3-1.Mikolov, Tomas, Ilya Sutskever, Kai Chen, Greg S.Corrado, and Jeff Dean.
Distributed representationsof words and phrases and their compositionality.2013 In Advances in neural information processingsystems, pp.
3111-3119.Mochales Palau, Raquel and Moens, Marie-Francine.Argumentation mining.
2011.
In Artificial Intelli-gence and Law, 19(1): 1-22.Ehud Reiter and Robert Dale.
Building Natural Lan-guage Generation Systems.
2000.
Cambridge Uni-versity Press, New York, NY, USA.Rinott, Ruty, Lena Dankin, Carlos Alzate, Mitesh M.Khapra, Ehud Aharoni, and Noam Slonim.
ShowMe Your Evidencean Automatic Method for ContextDependent Evidence Detection.
2015 In Proceed-ings of the 2015 Conference on Empirical Methodsin NLP (EMNLP), Lisbon, Portugal, pp.
17-21.Stephen Toulmin.
The Uses of Argument.
1958.
Cam-bridge University Press, Cambridge.Douglas Walton, Argument Mining by Applying Ar-gumentation Schemes 2012.
In Studies in Logic4(1):38-64Walton, Douglas, Christopher Reed, and FabrizioMacagno.
Argumentation schemes.
2008.
Cam-bridge University Press.Adam Wyner, Raquel Mochales-Palau, Marie-FrancineMoens, and David Milward.
Approaches to text min-ing arguments from legal cases.
2010.
In Semanticprocessing of legal texts 60-79.530
