Context  Ana lys i s  Sys tem for  Japanese  TextH i tosh i  I sahara  and  Shun I sh izak iE lec t ro techn ica l  Laboratory1-1-4,  Umezono,  Sakura -mura ,  N i ihar i -gun ,Ibarak i ,  Japan  305ABSTRACTA natural language understanding system isdescr ibed which extracts contextual informationfrom Japanese texts.
It integrates syntactic,semantic and contextual processing serially.
Thesyntactic analyzer obtains rough syntacticstructures from the text.
The semantic analyzertreats modify ing relations inside noun phrasesand case relat ions among verbs and noun phrases.Then, the contextual analyzer obtains contextualinformation from the semantic structure extractedby the semantic analyzer.
Our system understandsthe context using preceded contextual knowledgeon terrorism and plugs the event information ininput sentences into the contextual structure.i: IntroductionDespite the advanced state of syntacticanalysis research for natural language processingand the many useful results it has produced,there have been few studies involving contextualinformation, and many problems remain unsolved.The natural language understanding systemdescribed here employs a syntactic analyzer, asemantic analyzer treating modifying relationsinside noun phrases and the relations among verbsand phrases, that is, word-level semantics, and acontextual analyzer (Fig.
i).
These analyzersoperate in a serial ly integrated fashion.
Thoughhumans seem to understand natural language textsusing these three analyzers simultaneously, wehave made their methodology essential ly differentfrom their human counterparts for more eff icientcomputing.
Our system uses a context-freegrammar parser named Extended-Lingol as asyntact ic analyzer to analyze the Japanesesentences and produce parsing trees.
From ananalysis of these, in turn, it obtains word-levelsemantic structures expressed in frame-l ikerepresentations.
Finally, it extracts contextualinformation, using our representation from thesemantic structures.
We remain far from certainat this stage whether this system represents thebest real izat ion of an engineering-based naturallanguage understanding system.
Future plansinclude combining these three processes into oneprocess and br inging the system closer to thehuman process.Because our system uses bottom-up analysisf irst ( including syntactic analysis andword- level  semantic analysis), it can obtain notonly the outl ine of the input sentences but alsotheir details, as necessary.
This method is thebest one in situations where the detai ledinformation of texts are quite important, such asMachine-Translat ion systems and precisequest ion-answering systems.
Of course, in thisway, we must bui ld up a sizable dict ionary ofprecise word definitions.In our system, predict ive-style processing isnot used in syntactic analysis and word-levelsemantic analysis.
But, in the contextualanalysis part, predict ions from the treestructure of the contextual information are usedfor instantiat ion of the contextual structure.We are now developing a system which canunderstand newspaper articles through contextualstructure (see Fig.
2a).
After applying theprocedures out l ined above, the system obtainsI Input sost0nces \](Nouspa2er art ~cles|in Japanese)anal s sL .
.
~ r a t ~  JM.._ s~te,, JFig.l System flow chart of this paper and its applications.
: i~ ~:  ~ 11::: 69 .
::k: -~  "U (,~, 9~, I~1 ~'~ :b:~ -'5"= ~:~11 '.
L ,  "7 .
'a"  4 tc  ?
.
~ ~Lv~-~ ~- " .
,~  " ~ .
~a: Original input (Morning edition of theAsahi Shimbun-- July 30, 1983).THE BOMB KILLS FOUR PEOPLE INCLUDING A JUDGE.\[Rome 29th = correspondent Hirano\]In the morning of the 29th, at Palermo,Sici ly in Italy, a parked car exploded, whichki l led 4 people including a judge who haddirected an investigation into Mafia crimes,and injured about i0 people seriously orslightly.
This is the fourth murder ease onjudges at Palermo and is of the largestscale.Judge Rocco Chinnici, 58, the director ofthe Palermo prel iminary court, policebodyguards and others were murdered.
At themoment when the judge left home, the bombexploded which had been set in the car ofFiatt parked near there.
The explosioninvolved the residents, windows of theapartment and about I0 cars near there.b: The translat ion of the example article (a)from Japanese into English.Fig.
2.
An example of newspaper articles244contextua l  representat ions  expressed  as shown inFig.
3.
Some deta i l s  of the input  text  areabbrev ia ted  in the f igure.2: Syntact i c  and semant ic  analys is \ [2\]Let  us proceed to an exp lanat ion  of themethodo log ies  adopted by our system, us ing thenewspaper  ar t ic le  in Fig.
2a as an example.First, the sys tem ana lyzed  each sentencesyntact ica l ly ,  obta in ing  pars ing  trees.
Next,the sys tem const ructs  a semant ic  s t ruc ture  foreach phrase.
Word meanings  in our wordd ic t ionary  ate descr ibed  in SRL (Semant icRepresentat ion  Language) wh ich  uses f rame- l i keexpress ion  as shown in Fig.
4.
Each word mean ingshares a su i tab le  pos i t ion  in the h ie rarchy  ofconcepts .
SRL enab les  deep semant ic  ana lys is  ina f lex ib le  way.
The formal de f in i t ion  of itssyntax and semant ics  is not  s tated here.
In oursystem, a word  mean ing  wr i t ten  in the lex ica lentry us ing  SRL p lays  an important  role insemant ic  analysis .
The in teract ion  between theword  mean ings  is the central  i ssue of thesemant ic  analys is .
The mod i fy ing  re la t ionsins ide noun phrases  and the case re lat ions  amongverbs and noun phrases  are determined in theword- leve l  semant ic  st ructure.
In Fig.
4, threescenes (explosion, death  and injury) are obta inedby ana lyz in  9 the f i rst  sentence of the ar t ic le  inFig.
2a.
"Human"  is a dummy node that meanshuman beings.
Here, the people  who died inc ludea judge and some pol icemen.There  are severa l  types of ambigu i ty  in inputtext.
In sNntact i c  analysis,  ambigu i ty  means  theex is tanoe  of severa l  pars ing  trees.
Word- leve lsemant ics  o f ten  spec i fy  wh ich  shou ld  be selected.Here, we shou ld  use a k ind  of  predict ion.
Forexample, peop le  who are in author i ty  cou ld  be a?
target of te r ror i sm (See Fig.
2a).
Theseconst ra in ts  are very  he lpfu l  in e l im inat ingambiguity ,  as wel l  as sur face  syntact icin format ion.
Some of this p rocess ing  is done inan in teract ive  way in our  system.
Our sys temasks the user  how to spec i fy  the re la t ionsbetween events  in some dec is ion  points.
Evenafter  the e l iminat ion  of ambigu i ty  by the wordsemantics,  there may be unso lved  ambigui t ies .These wi l l  he e l iminated  by contextua l  ana lys isw i th  the contextua l  structure.3:  Features  of contextua l  representat ionOur contextua l  s t ruc ture  f i ts  into a trees t ructure  w i th  one root node and a number  of leafnodes.
Re la t ions  between events  in a s tory  arede f ined  in the s t ructure  as "scenes", and there la t ions  among our  s t ructure  are def ined by atree structure.
Our  s t ructure  can share sceneswi th  others.Leaf nodes  w i th  a shared root  node have e i theran "and" or  an "or" re la t ionsh ip  w i th  each other.The h ie rarchy  shown in Fig.
5 is an example.
Thenode " ter ror ism invo lv ing  bomb" has, as inFig.
5, three leaf  nodes  (scenes) - "explos ion,""damage" and "rescue".
S ince those seem to occurser ia l ly ,  the re la t ionsh ip  among them is an "and"re la t ionsh ip .
On the 'other hand, the root  node" ter ror is t  act ion" in Fig.
5 has several  leafnodes - " te r ror i sm invo lv ing  bomb", "shoot ing"and so on.
As on ly  one of these usua l lycor responds  to the main  topic  in newspaperstor ies,  they  share an "or" re la t ionsh ip  wi theach other.Input  events  are matched not  on ly  d i rec t lyw i th  scenes  in the structure,  but also w i thh igher  concepts  in accordance  wi th  a predef inedt ree s t ruc ture  of  a concept  h ie rarchy  l lke thatin Fig.
6.
In o ther  words, the sys tem has aconcept  thesaurus.
So, match ing  between thescene of  the s t ruc ture  and the input  eventsbecomes  f lex ib le.
(terrorism involvingF ig .
3.
An example of the contextua l  s t ruc ture ,STALE g :~|Up (varked)LOCATION )~ \[J)P-~ (Palermo)IDCATION "M'M I\] -- (Slclty)LOCATION 49  UY(Italy)TIM~ 29\[\]~J(on the ~orning of the 2Oth)SCA\[?
2~ ~ ~ (large)hCTOl{ JkJll\] (humall)NUNJEII 4INCLUS\]ON !l~.lJ ) ~ (judge)JOB ~ffJJlt:\]-~ (di rccOOBJI~'I' t~!L~'~.
( flu;pecl, lo n )OlilM:;'r ,~\[~l!
(or,h~OhCi?1~ -V74 7 (l~a\[ia)) l~ I tb  (J,Ljurcd ,';erlously or sHght;ly)AC'\[OI{ ),Jill (huJmn)NUff~,R{ ~?,JtO2k(about 10)lug.
4.
\]'ho ~ord-level semantic structure extractedfrom the f i rst  sentence ill Fig.
2a.~(A~ori~t aeries ) C clo.~m o~ cri,.~,.
'::....o.r ,..'.
'.-: .
.
.
.
.
.
.
.
.
.
.
.
.~rrori~m in~olvlng ~~ism iovolving bo--a~ < claim of_ crime --)Fig.
5 The contextual  s t ruc ture  (upper diagram)and its reorganization (lower dlagram).2454: Contextua l  s t ruc ture  se lect ion  processNow we have imp lemented  two se lect ion  methodsfor the se lec t ion  of the contextual  structure,  a" two-event  method" and a " t i t le -based method".First, we wi l l  exp la in  the "two-event  method".In the " two-event  method",  t i t les  are notp rocessed  by the sys tem for select ion.
Insentence process ing,  after  two events  areobtained,  the system begins  a search for as t ructure  invo lv ing  these two events  as the i rscenes.
The use of two events helps decrease  thenumber  of poss ib le  s t ructures  dur ing the search.As ment ioned  prev ious ly ,  se lect ion  of su i tab les t ructures  and scenes can be accompl i shedf lex ib ly  w i th  the concept  thesaurus.A f te r  deve lop ing  the "two-event  method",  webegan to implement  the " t i t le -based method".
Inthe case of newspaper  art ic les,  t i t les  haveimpor tant  in fo rmat ion  for the se lec t ion  ofsu i tab le  contextua l  structures.
If there is aspec ia l  word  (noun or verb) in the tit le,contextua l  representat ion  ind icated by that  wordis se lected.
In th is  way, the system can almosta lways se lect  su i tab le  structures.
Newspapert i t les  shou ld  be wr i t ten  so that readers  can getenough in fo rmat ion  fo r  the se lec t ion  of the topicf rom its t i t le  only.
The correct  se lec t ion  rateof our  " t i t le -based method" is shown in Table I.Der ivat ives  po int  to thei r  or ig ina l  words, and,th rough them, der ivat ives  can se lectsu i tab le  structure.Wi th in  our  exper ience,  there are nod i f fe rences  in the correct  se lect ion  ratesbetween these two methods.
In our system, atpresent,  we use the " t i t le -based method" becauseof its s imi la r i ty  to human behaviour.5: Contextua l  ana lys isOnce a promis ing  s t ructure  is d iscovered,scenes cor respond ing  to the input events  arese lected  in the fo l lowing manner: if an event  inthe input  sentence matches  one of the scenesa l ready act ivated  in the system, it ident i f iesthe event  w i th  that  scene.For  example,  f rom the art ic le  shown in fig.
2aour sys tem ext racts  three events  - "explosion","murder (death)" and "injury".
The contextua ls t ruc ture  of " ter ror i sm invo lv ing bomb" is thense lected  us ing  its tit le, and the contextua lana lys is  begins.
In the contextual  analysis,f irst, "explos ion" matches  d i rect ly  the f i rstscene (scenel) in the structure,  "explosion",  andthis event  is p lugged into scenel.
Next,"murder" is checked compar ing  wi th  each scene.Here, there is no scene which  d i rec t ly  matches"murder" but one of the h igher  concept  of"murder" is "damage".
So the system ident i f ies"murder" w i th  scene2, "damage" and p lugs thatevent  into scene2.
In these cases there  are noevents  a l ready  p lugged into the se lected  scene,so the sys tem can eas i ly  p lug the events  into thescenes.
When process ing  the th i rd  event," injury", it is qu i te  important  to determinewhether  -this event  is the same or d i f fe rent  front"murder".
(Here, " injury" also has the h igherconcept,  "damage".
)The determinat ion  whether  th is  part  of theinput  sentence is g iv ing abso lu te ly  newin format ion  about a new event  now be ingin t roduced or  more prec ise  in fo rmat ion  about theevent a l ready  descr ibed  is accompl i shed  in thefo l lowing manner.
When the input event  isident i f ied  w i th  one scene in the contextua lstructure,  the contextua l  ana lyzer  beg ins  tosearch  for an event  a l ready p lugged into these lected  scene that has the same concept  (or ah igher  concept)  as the input event.
If there isno conf l i c t  between the va lues of the at t r ibutes(for example, ACTOR, OBJECT, TIME) in the inputevent  and the event  found by the search, the246Fig.
6.
Concept thesaurus.Table 1.
Topic se lec t ion  by the " t i t le -based  method".SuccessesTopic \] By title \ [By  subtitle Failures,,,to.~.io,L__.
!
7 6 1 = ~ _ _Shooting 2 2 i 0- - illighjack~ 1 6 G 0 i_ Total J 1 5 0 2 1 _ 5 ~_~i n fo rmat ion  obta ined  by the input  event  ist reated  as a deta i l  of a p redescr ibed  event.
Ifth is  is not  the case, the input  event  is t reatedas a para l le l  event  of the events  in that  scene.6: Conc lus ionIn the above sect ions we have proposed  asys tem for ext rac t ing  contextua l  in fo rmat ion  fromnatura l  language texts  us ing  a contextua lrepresentat ion  s t ructure  as a knowledgestructure.
Our  s t ructure  has proven  i tse l fusefu l  for  express ing  contents  of Japanesenewspaper  art ic les.
Though we propounded themethod used in our  system to unders tand  natura llanguage texts  in every field, some of itsspec i f i ca t ions  such as the t reatment  of t i t lesare o r iented  toward  special\[ features  of newspaperart ic les.At  present,  the app l i ca t ions  of this systemare res t r i c ted  to s tor ies  deal ing wi th  terror ism.For these  l imits  to be extended, the number  ofthe contextua l  s t ruc tures  must  be increased  andthe concept  thesaurus  scale enlarged.
We be l ieve-that the natura l  language unders tand ing  systemdescr ibed  in th is  paper  is f lex ib le  enough toa l low for such extension.
Computer  fac i l i t iesmust, of course, a lso be taken into account.As our  sys tem is st i l l  in the deve lopmentstage, some parts  are not yet complete.
Ourd ic t ionary  is st i l l  ra ther  small.
For thesereasons,  "the scope of th is  paper  has been l imi tedto process ing  ab i l i ty  for a res t r i c ted  categoryof newspaper  art ic les.Re ferencei: Schank, R. C., "Dynamic Memory",  Cambr idgeUniv.
Press (1983)2: Tanaka, H., "A Semant ic  P rocess ing  System forNatura l  Language Understand ing" ,  (in Japanese)Researches  of the Electro-technical Laboratory ,NOo797 (1979)3: Lyt inen,  S. L. and Schank, R. C.,"Representat ion  and Trans lat ion" ,  Text  2:1/3Ya le  Research  Report  (1982)4: Ishizaki ,  S., Isahara, H. and K. Hands,"Natura l  Language Process ing  System wi thDeduct ive  Learn ing  Mechanism",  In ternat iona lSympos ium on Language and Ar t i f i c ia lInte l l igence,  March  16-21, 1986, Kyoto
