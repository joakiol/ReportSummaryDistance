Evaluation of Annotation Schemes for Japanese DiscourseJapanese Discourse Tagging Working GroupIchikawa, A.
(Chiba U.
), Araki, M. (KIT), Horiuchi, Y.
(Chiba V.),Ishizaki, M. (JAIST), Itabashi, S. (Wsukuba U.
), Itoh, W. (Shizuoka U.
),Kashioka, H. (ATR-ITL), Kato, K. (Wsukuba V.), Kikuchi, H. (Waseda U.
),Koiso, H. (NLRI), Kurnagai, W. (NLRI), Kurematsu, A.
(UEC),Maekawa, K. (NLRI), Nakazato, S. (Meio U.
), Wamoto, M. (NTT BRL),Tutiya,S.
(Chiba U.
), Yamashita,Y.
(Ritsumeikan V.) and Yoshimura,W.
(ETL)AbstractThis paper describes standardizing discourseannotation schemes for Japanese and eval-uates the reliability of these schemes.
Wepropose three schemes, that is, utteranceunit, discourse segment and discourse mark-ers.
These schemes have shown to be in-crementally improved based on the experi-mental results, and the reliability of theseschemes are estimated as "good" range.1 IntroductionLinguistic corpora are now indispensableof speech and language research communi-ties.
They are used not only for examin-ing their characteristics, but also for (semi-)automatically learning rules for speechrecognition, parsing and anaphora resolu-tion, and evaluating the performance ofspeech and natural anguage processing sys-tems.Linguistic orpora can be used as they are,however, they are usually annotated with in-formation such as part of speech and syn-tactic structures.
Currently there are manylarge linguistic annotated corpora world-wide, but the types of annotation informa-tion are limited to morphological nd syntac-- tic information.
While there are some cor-pora annotated with discourse informationlike speech act types and discourse struc-tures, they are much smaller than that ofthe corpora, with morphological and syn-tactic information.
One of the major rea-sons for this difference in the size is dueto the lack of computer tools such as mor-phological analyzers and syntactic parsersto semi-automatically annotate information.Of course we will be able to develop suchtools for discourse information, but beforethat, we must create a base corpora by set-ting standards 1 for resource sharing, whichcan contribute to creating large resources fordiscourse.To this end, the Discourse Research Ini-tiative (DRI) was set up in March of 1996byUS, European, and Japanese researchersto develop standard discourse annotationschemes (Walker et al, 1996).
In line withthe effort of this initiative, a discourse tag-ging working group has started in Japan inMay 1996, with the support of the JapaneseSociety of Artificial Intelligence.
The work-ing group consists of representatives fromeight universities and four research institutesin Japan.
In the first year, (1) we collectedand analyzed existing annotation schemesfor Japanese discourse from the viewpointsof annotation units and information types,(2) developed new annotation schemes andexperimentally annotated actual data, and(3) analyzed the experimental results to ira-1 The efforts have been called 'standardization',but we must admit this naming is misleading atleast.
In typical standardizing efforts, as donein audio-visual nd telecommunication technologies,companies try to expand the market for their prod-ucts by making their products or interfaces stan-dards, and this profit directedness leaves room fornegotiation.
Even if the negotiation fails, they canappeal their products or interfaces for the marketto judge.
The objective of standardizing efforts indiscourse is to promote interactions among differentdiscourse researcher groups and thereby provide asolid foundation for corpus-based discourse r search,which makes the researchers dispense with duplicateresource making efforts and increases the resourcesto be shared.26prove the coding schemes.
In the secondyear, based on the examination results ob-tained in the first year's experiments, wehave revised new annotation schemes andconducted the second round of coding ex-periments to verify them.This paper describes our project of stan-dardizing annotation schemes for Japanesediscourse.
In the following, annotationschemes for utterance units, discourse struc-ture, and discourse markers are discussedbased on our coding experiments.2 Utterance Unit2.1 First annotat ion schemeBased on the survey of existing annota-tion schemes uch as the schemes of sev-eral research groups in Japan (Kyoto Univ.,Tsukuba Univ., Waseda Univ., ATR (Na-gata, 1992)) and DRI (Allen and Core, 1996;Carletta et al, 1997a) for utterances (wecall this utterance unit tags), we createdthe first annotation manual for illocutionaryforce type, mood information and exchangestructures.
Illocutionary force types comefrom speech act theory (Searle, 1969), andare one of the most popular set of describ-ing communicative aspects of utterances.Mood information corresponds to the mean-ing of auxiliary verbs in Japanese, which hasbeen hinted that there might be close rela-tions with illocutionary act types?
Exchangestructures define minimal interactional unitsconsisting of initiative, response and follow-up (Coulthhard, 1992; Stenstrom, 1994).We carried out a first annotation exper-iments using the above three manuals, andobtained the following lessons for improvingthe schemes.?
The frequencies of the classifications:There exist exceedingly high and lowfrequency classifications in the illocu-tionary force types and mood informa-tion.
The most frequent classification isinform in the illocutionary force types(54.9 %).?
The disagreement among coders:The disagreement among coders oc-curred due to three factors.
The firstis consistent decision errors caused bydifferent interpretations of the categorynames (some coders classify utterancesbased on their interpretations of the cat-egory names, not on the functional defi-nitions of the categories).
The secondis by the ambiguity of certain wordsand/or expressions.
The last involvesincomplete utterances like omission ofthe end part of utterances observed inJapanese spontaneous speech.The correlation between the informa-tion types:Most of the classifications for illocu-tionary force types and mood informa-tion show high correlation.
This holdsfor exchange structure and speech act /?
mood except for inform category in theillocutionary force types.2.2 Second annotat ion  schemeBased on the analysis of the experimental re-sults, we revised the first annotation schemeby (1) unifying mood information into illo-cutionary force types, and (2) re-classifyingsome categories, i.e., further classifying highfi-equency categories by other informationtype and collapsing low frequency categories.The resultant scheme is composed of the il-locutionary force types and the role of theutterances in the interaction unit.To improve the disagreement amongcoders, we impose the constraint on the pat-terns of exchange structure (Figure 1).In this new scheme, the tags (Figure 2)need to be an element of exchange structureexcept for those of dialogue management.As in (Carletta et al, 1997a; Carletta etal., 1997b), we also created a decision tree toimprove the coding reliability of this scheme.This decision tree consists of a set of ques-tions concerning the functional character oftarget utterances.2.3 Analysis of annotat ion  resultsIn order to examine the reliability of thisnew scheme, we have carried out another27Basic pattern(exchange structure) ---*(initiate) (response) ((follow up/) ((followup))Embedded pattern(exchange structure / ---+(initiate) (embedded structure)* (response)(( follow up)) (( follow up))(embedded structure) ---,(response/i'nitiate) ((response))Figure 1: Patterns of exchange structureDialogue managementOpen, Close?
InitiateRequest, Suggest, Persuade, Pro-pose, Confirm, Yes-No question,Wh-question, Promise, Demand, In-form, Other assert, Other initiate.ResponsePositive, Negative,Other esponse.Answer, Hold,Follow upUnderstandResponse with InitiateThe element of this category is rep-resented as Response Type / InitiateType.Figure 2: Tag set of the second annotationschemetagging experiment for comparing the relia-bility of the first and the second scheme.
Weused five different ypes of task-oriented dia-logues (Japanese Map Task, group schedul-ing, route direction, telephone shopping andappointment scheduling).
An annotationunit is pre-defined based on (Meteer andTaylor, 1995), which roughly corresponds toone verb and related case phrases.The experimental results show major im-provements on the frequency of the cate-gories (by avoiding the categories of high andlow frequencies), and the reliability of thescheme.?
Frequency:The average quantity of information(entropy) are 1.65 in the first scheme,and 3.50 in the new scheme.
The mostfrequent category in the new scheme isUnderstand (15.5 %), and other ca.te-gories are evenly distributed.?
Reliability:The agreement among the coders isquantitatively evaluated with reliabil-ity in terms of the kappa coefficient K(Siegel and Castellan, 1988; Carletta et- al., 1997b).
In raw data, we cannot ob-serve improvement, however, we foundout a number of disagreements causedby consistent mistakes about the word"hai", which can be interpreted as ei-ther a positive response or a follow-up.Some coders neglected the constraintson follow-up introduced by the newmanuM: the constraint says that follow-ups must come only after response classutterances.
This mistake can be alle-viated by making a computer taggingtool display a warning message to thecoders if they do not observe the con-straint.
To correctly evaluate the relia-bility of the schemes, the above simpleproblem should be discounted.
Table 1shows the agreement rate after substi-tuting the mistaken follow-ups with theresponses, in which we can clearly ob-serve improvement on the reliability ofthe new scheme over the that of the first.The reliability score of the new scheme isK = 0.64.
This score is in "good" range ac-cording to (Siegel and Castellan, 1988), butdoes not seem to be the best.
One reason forthis is that our experiments were done withuntrained subjects, which means that therecan be more room for improvements on thereliability.2(3mmm\[\]mm\[\]mmmmmm\[\]mmmmmmhDataMap taskgroup schedulingroute directiontelephone shoppingappointment schedulingTotal II\[ l umber of utterance IIP 'A)P(E)Table 1: Evaluation of utterance unit taggingschemefirst version second versionagree 3 agree 2 disagree agree 360 51 1 4138 8 03 3586 24 126 28 630318729245 119 \[ i i 218375agree 2 disagree54 1812 46 920 421 11i13 463770.76 0.680.44 0.120.57 0.643 D iscourse  S t ruc ture3.1 First annotat ion schemeGrosz and Sidner proposed a model of dis-course structure, in which discourse struc-ture is composed of the linguistic structure,the intentional structure, and the attentionalstate (Grosz and Sidner, 1986).
We built thefirst annotation scheme of discourse struc-ture in dialogue based on this model.
Thewritten instruction of the scheme describesas follows.?
Utterances both at the start and the endof segments are marked.?
Discourse segments may be nested.That is, a discourse segment can con-tain some smaller segments.?
Coders are allowed to decide the size ofdiscourse segments.In the first coding experiments, disagree-ments among the coders are incurred bythree types of difficulties in segmenting di-alogue.?
Identification of the end of discoursesegments:This case often occurs due to the ut-terances which can be interpreted asresponding to the preceding utterancewhile can be interpreted as initiating a"new (but often related) topic, and theutterances followed by long series of re-sponses, which are difficult to judge tobe as initiating or responding.?
Disagreements of the nesting level ofdiscourse segments:There are cases where coders can judgethe relationship between adjacent dis-course segments differently such as co-ordination and subordination.
This re-sults in different discourse structures,although the coders identically recog-nized the start and the end of the seg-ment at the top level.?
Annotation units:Coders are allowed to change annota-tion units if necessary.
Hence, for exam-ple, if some coder combine utterances inthe given transcription, she ,night deleteboundaries for segmenting discourse.3.2 Second annotat ion  schemeWe renewed the annotation scheme based onthe analysis of disagreements in the first cod-ing experiments.In the second annotation scheme, thecoders identify topic breaks between ut-terances based on the exchange structure,2932 A: 'Chikatetsu wa doko made norebaiidesu ka?'
\[I\](What station should I take thesubway to?
)33 B: 'Hommachi eki kara Chuou ekimade nori masu.'
\[R\](From Hommachi station to Chuoustation.
)34 A: 'Hai.'
IF\](Yes.
)35 B: 'Ikura kakari masu ka?'
\[I\](How much does it cost?
)36 A: 'Kuukou kara desu ka?'
\[R&I\](From the airport?
)37 B: 'Chikatetsu no hou dake wa.
~\[aaI\](How much only concerning thesubway?
)38 A: 'Hommachi eki kava Chuou ekimade 210 en desu.'
\[R\](210 yen from Hommachi station toChuou station.
)38 B: 'Hai.'
\[F\](Yes.
)Figure 3: Exchanges in a Japanese dialogue.which is explained in section 2.
The topicbreak always starts a discourse segment.This modification can avoid the problem ofidentifying the segment ends.
This schemeuses an exchange as a building block ofdiscourse segments.
Topic boundaries aremarked before the Initiate and the Response-with-Initiate utterances, which start a newdiscourse segment.
The Response andFollow-up utterances do not start a dis-course segment.
Figure 3 shows exchangestructures with the utterance unit tags ina Japanese dialogue.
In this Figure, \[I\],\[R\], \[l~I\], IF l denotes Initiate, Response,Response-with-Initiate, ndFollow-up utter-ance, respectively.
The topic boundaries areinserted before the utterances 32, 35, 36, and37, in this example.The second scheme is not concerned withthe nesting structure of the discourse seg-ments.
This identification of topic breaksresults in a flat structure of the discoursesegments.
Instead, each topic break is an-notated in terms of two level topic-break-index(TBI), which indicates dissimilarity ofthe topics.
The boundaries of the discoursesegment with TBI=I and =2 indicate aweakand a strong break of topic, respectively.The tagging procedure of the secondscheme is1.
recognizing exchange structures,2.
making tags immediately before all ini-tiating utterances, and3.
assigning the strength of topic break forthe tags.3.3 Analysis of annotation resultsWe carried out tagging experiments for dia-logues of two tasks, scheduling and route di-rection, based on two versions of annotationschemes.
The agreement of tags between thecoders is quantitatively evaluated with K.Table 2 summarizes the average scores ofreliability for paired comparisons among allcoders.
The number of coders is 4 and 5 forthe route direction and the scheduling of thefirst experiments, respectively, and 10 for thesecond experiments.
Table 2(a) shows re-liability of existence of boundaries betweenall discourse segments ignoring the nestingstructure and the strength of topic break.Table 2(b) shows reliability of structure ofthe discourse structure.
The latter compar-ison considers the nesting level for the firstannotation scheme and the TBI for the sec-ond annotation scheme.
The second anno-tation scheme are confirmed to improve thereliability, especially for the segment struc-ture.
It successfully restricts the coder tomark start of the discourse segments usingan exchange as a building block of the dis-course segments.
In the first experiment, re-liability of segment structure was incurred bythe difference of nesting structure the depthof which the coder determine& Replacing30mmmmmmmmmmmmmmm\[\]m\[\]Table 2: Reliability of Annotation of Dis-course Structure(a) for existence of boundariesannotation schemetask 1st I 2ndroute direction 0.508 0.732scheduling 0.756 0.570~average 0.632 0.653(b) for segment structuretask ~ e m ei .
.
.
.route direction 0.412 0.600scheduling 0.478 0.529average 0.445 0.564the nesting by the TBI's for describing struc-ture of the segments also improved codingreliability.4 Discourse  MarkersIn English, some discourse markers haveshown to be a cue to predict he boundary ofdiscourse segments.
In Japanese, discoursemarkers are expressed with the same vo-cabulary with aiduti (acknowledgment) andfillers.Unlike English discourse markers,Japanese discourse markers are not lexi-cal.
Japanese words as "etto', "ano" and"ja" have no meaning themselves.
How-ever, there are abundant in Japanese dis-course.
Kawamori compared English dis-couse markders with Japanese.
In Japanesecoupus, half of the turns are started withthese words, while English corpus shows thatabout 25 % of the turns start with corre-sponding expression(Kawamori et al, 1998).The correlation between Japanese dis-course markers and the boundary of dis-course segments has not shown, which canbe used to improve the identification of thediscourse boundaries.
In this section, the ex-pressions which can be used for discoursemarkers, aiduti and fillers are enumeratedbased on the data survey, and the correlationTable 3: Aiduti expressions selected by theco ders4 coders  3 coders  2 coders  1 coderha l  16 26 38 49soudesuka  0 0 2 0asoudesuka  0 0 2 0e 0 1 1 0na i  0 1 0 0ha  1 0 1 0Tota l  17 30 56 73Table 4: Discourse marker expressions se-lected by the coders4 coders 3 coders10 262 91 01 10 190 190 60 10 114 872 coders176527931060eanodedewaactojaajaiyaTotal1 coder44721510000108between discourse markers and the discourseboundaries in Japanese is shown.4.1 Surface expressions of discoursemarkersDiscourse markers and speech related phe-nomena re defined as utterances that func-tion as a lubricant rather than contributingto achieving some task-related goals in con-versations.
In the first coding experiments,coders are instructed to annotate 'aiduti'(acknowledgments) and discourse markersbased on their functional descriptions.
Herefiller was tentatively included in discoursemarkers.Table 3 and Table 4 show words whichwere selected by 4 coders and their agree-ments of the selection.The results how that surface forms can beUsed to distinguish between discourse mark-ers and aiduti (and fillers), and the varietyof the forms is rather limited.
Based on the31analysis of the results, we defined the func-tions and surface forms of aiduti, discoursemarkers and fillers as follows.4.1.1 Aidut i?
Definition:Items which signify hearing of theother's peaking or prompting the nextutterance (their function is not a defi-nite answer ather a lubricant for con-versations).?
Surface forms:"hai (yes, yeah, right)", "eto (well, aah,urn)", "e (mnun, yeah)"English corresponding expressions areshown in bracket for reference.The above three expressions covered mostof the cases for aiduti n the test-tagging ex-periment (for example, "hai" covered 81%of all aiduti expressions), although we foundout that there are a few expression differentfrom the above.
Candidate words sometimeshave other functions than aiduti.If "hai" functions as a definite answer,coders are instructed not to annotate it asaiduti.4.1.2 Discourse markers?
Definition:Items which mainly contribute to clar-ifying discourse structure but not toproblem solving?
Surface forms:"ja (ok)", "dewa (then, ok)", "sore-dewa (then, ok)", "soushitara (then, inthat case)", "deshitara (then, in thatcase)", "souieba (I've just remembered,aah", "de (you see, so)", "sorede (andso)", "sousuruto (and so, in that case)","soushimasuto (so you mean, in thatcase)", "tsumari (I mean, that meansthat)", "yousuruni (so you mean,)","mazu (first, firstly)", "saishoni (first,firstly)", "kondo (then, next)", "tsugini(then, next)", "saigoni (last, lastly)","ma~ (well)"The phrases uch as "hanashi wa kawari-masuga (by the way)" and "tsugi ni ikimasuTable 5: Correlation betweenmarkers and discourse boundariesdiscourseBefore After Else TotalNo Segment, 5(} 121 633 804(36 %) (88 ~) (73 %) (70 ~)Segment level 1 56 7 140 203(41%) (5 %) (16 %) (18 %)Segment level 2 32 10 94 136(23 %} (7 %) (11%) (12 %)(go ahead)" are also included in discoursemarkers, which are not identified by surfaceforms, but by their functions.4.1.3 Fi l ler?
Definition:Items that fill up the gap between ut-terances and indicate the speaker's state"like under consideration, hesitation andcontinuation.?
Candidate words:"eto (well, aah, urn)", "e (nnnm,yeah)", "ano (well, aa.h, urn)", % (oh)","n (mmm)", "to (well)"To limit candidate words, we suppose dif-ferences between corders decrease.
We canannotate these words almost automatically.4.2 Corre lat ion between discoursemarkers  and discourseboundar iesWe examined the correlation between thediscourse markers and the discourse bound-ary defined in section 3.
In this experi-ment, 5 subjects were instructed to annotatethe discourse boundaries, and 46 discoursemarkers were automatically selected by theirsurface forms in 5 dialogue data.Table 5 shows that 64 % (41% for segmentlevel 1 and 23 % for segment level 2) of dis-course markers are located directly after thediscourse boundaries.
The chance level is 30%, and therefore, surface forms of discoursemarkers were found to be effective cue forrecognizing discourse boundaries.325 ~ Conc lus ionThis paper summarized our efforts on stan-dardizing discourse annotation schemes forJapanese and evaluated the reliability of theschemes.
To improve the base reliability ofthe schemes, (1) interactional units are use-ful for constraining tag candidates and link-ing the utterance to the discourse structurelevel, and (2) discourse markers identified bytheir surface form can be used as a cue forindicating discourse boundaries.The reliability issues involve various fac-tors.
For example, in the projects whichattain high agreement rate of tagging suchas the MapTask and Switchboard, they usedsyntactic ues in the coding manuals.
Thisapparently contribute to the high agreementrate of tagging, although there leave somepossibilities for confusing syntactic informa-tion with the meaning of the tags.
In addi-tion, in the MapTask, they include domainspecific knowledge in the tags.
The Switch-board project took the approach that thecoders are allowed to tag utterances freelyand then create the abstract classificationrelating to DAMSL coding schemes basedon the first tagging experiment.
Interest-ingly, the coders in the above two projectsare all students, not researchers as in DRIand our project.
The student coders arewell-trained, while researchers of DRI andour project sometime have some biases tothe coding schemes and often take little timefor tagging experiments.
The MapTask usedthe decision tree approach and was success-ful for attaining the high agreement rate.Since then, the decision tree approach hasbeen believed to be a key to the high agree-ment rate.
DRI and our project also adoptedthis approach, but the resultant agreementrate is not so high, comparing to the Map-Task project.
Considering various factoringinvolving the reliability, we should realise thedecision tree approach cannot be a only keyto the successful coding schemes.
In this re-spect, our experiments are interesting.
Thatis, we showed there is some room for improv-ing coding schemes by introducing differentdimensions to the original coding schemes.This kind of continuous efforts to improvingcoding schemes hould not be looked over.The computer tagging tools are necessaryat least for creating consistent underlyingrepresentation f the tagging results.
More-over, for multi-level tagging, as in MATEand our project, the tools should provideeasy access to different level.
In both re-spects, the MATE tagging tool currentlydeveloped will be a very valuable resourcefor discourse (tagging) research community.However, if we want to create a large dis-cursive annotated corpora, we must considerto build semi-automatically tagging toolsused in morphological nd syntactic tagging,which should include some kind of machinelearning techniques.ReferencesJ.
Allen and M. Core.
1996.
Draft of damsl:Dialog act markup in several layers.(ftp://ftp.cs.rochester.edu/pub/packages/dialog-annotation/manual.ps.gz).J.
Carletta, N. Dahlback, N. Reithinger,and M. A. Walker.
1997a.
Standardsfor dialogue coding in natural languageprocessing.
Dagstuhl-Seminar-Report: 167( ftp://ftp.cs.uni-sb.de/pub / dagst uhl/ re-porte/97/9706.ps.gz).J.
Carletta, A. Isard, S. Isard, J.C. Kowkto,G.
Doherty-Sneddon, and A.H. Anderson.1997b.
The reliability of a dialogue struc-ture coding scheme.
Computational Lin-guistics, 23:13-31.M.
Coulthhard, editor.
1992.
Advances inSpoken Discourse Analysis.
Routledge.B.
J. Grosz and C. L. Sidner.
1986.Attention, intention and the structureof discourse.
Computational Linguistics,12:175-204.M.
Kawamori, T. Kawabata, and A. Shi-mazu.
1998.
Discourse markers in spon-taneous dialogue: A corpus based studyof japanese and english.
In Proc.
ofA CL98 Workshop on Discourse Relationsand Discourse Markers, pages 93-99.M.
Meteer and A. Taylor.
1995.
Dysfluencyannotation stylebook for the switchboardcorpus.
Linguistic Data Consortium33(ftp://ftp.cis.upenn.edu/pub/treebank/swbd/doc/DFL-book.ps.gz).M.
Nagata.
1992.
Using pragmatics to ruleout recognition errors in cooperative task-oriented ialogues.
In Proc.
of ICSLP.J.
R. Searle.
1969.
Speech Acts.
CambridgeUniversity Press.S.
Siegel and Jr. Castellan, N. J.
1988.
Non-parametric Statistics for the BehavioralSciences.
McGraw-Hill, second edition.A.
B. Stenstrom.
1994.
An Introduction toSpoken Interaction.
Addison-Wesley.M.
Walker, L. Hirshman, J. Moore, andA.
Joshi.
1996.
IRCS workshops on dis-course tagging.http://www.georgetown.edu/luperfoy/Discouse-Treebank/dri-kickoff.html.34
