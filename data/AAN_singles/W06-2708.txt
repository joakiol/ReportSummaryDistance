Tools for hierarchical annotation of typed dialogueMyroslava O. Dzikovska, Charles Callaway, Elaine FarrowHuman Communication Research Centre, University of Edinburgh2 Buccleuch Place, Edinburgh, EH8 9LW, United Kingdom,{mdzikovs,ccallawa,efarrow}@inf.ed.ac.uk1 IntroductionWe discuss a set of tools for annotating a complexhierarchical and linguistic structure of tutorial di-alogue based on the NITE XML Toolkit (NXT)(Carletta et al, 2003).
The NXT API supportsmulti-layered stand-off data annotation and syn-chronisation with timed and speech data.
UsingNXT, we built a set of extensible tools for de-tailed structure annotation of typed tutorial dia-logue, collected from a tutor and student typingvia a chat interface.
There are several corpora oftutoring done with such chat-style communicationtechniques (Shah et al, 2002; Jordan and Siler,2002), however, our annotation presents a specialproblem because of its detailed hierarchical struc-ture.
We applied our annotation methodology toannotating corpora in two different tutoring do-mains: basic electricity and electronics, and sym-bolic differentiation.2 Data StructuresOur corpus has two sources of overlapping anno-tations: the turn structure of the corpus and situ-ational factors annotation.
The data are naturallysplit into turns whenever a participant presses their?submit?
button.
Timing information is associatedwith individual turns, representing the time whenthe entire message was sent to the other partici-pant, rather than with individual words and soundsas it would be in spoken corpora.However, turns are too large to be used as unitsin the annotation for dialogue phenomena.
Forexample, the single turn ?Well done.
Let?s try aharder one.?
consists of two utterances makingdifferent dialogue contributions: positive tutorialfeedback for the previous student utterance and astatement of a new tutorial goal.
Thus, turns mustbe segmented into smaller units which can serveas a basis for dialogue annotation.
We call theseutterances by analogy with spoken language, be-cause they are often fragments such as ?well done?rather than complete sentences.Thus, the corpus has two inherently overlap-ping layers: the turn segmentation layer, groupingutterances into turns, and the dialogue structurelayer built up over individual utterances.
The NXTtoolkit supports such overlapping annotations, andwe built two individual tools to support corpus an-notation: an utterance segmentation tool and a tu-torial annotation tool.Additionally, the corpus contains annotationdone by the tutor herself at collection time whichwe call ?situational factors?.
The tutors wereasked to submit a set of these factors after eachturn describing the progress and state of the stu-dent, such as answer correctness, confidence andengagement.
The factors were submitted sepa-rately from dialogue contributions and provide an-other layer of dialogue annotation which has tobe coordinated with other annotations.
The fac-tors are typically related to the preceding student?sutterance, but the link is implicit in the submis-sion time.1 Currently we include the factors in thetool?s transcript display based on the submissiontime, so they are displayed after the appropriateturn in the transcript allowing the annotators to vi-sually synchronise them with the dialogue.
Wealso provide an option to annotators for makingthem visible or not.
In the future we plan to makefactors a separate layer of the annotation linked bypointers with the preceding student and tutor turns.1The factor interface was designed to be quick to use andminimally impact the dialogue flow, so the submission tim-ings are generally reliable.573 Utterance SegmentationWe process the raw data with an automatic seg-menter/tokenizer which subdivides turns into indi-vidual utterances, and utterances into tokens, pro-viding an initial segmentation for the annotation.However, perfect automatic segmentation is notpossible, because punctuation is often either in-consistent or missing in typed dialogue and thistask therefore requires human judgement.
Theoutput of our automatic segmentation algorithmwas verified and corrected by a human annotator.A screen-shot of the interface we developed forsegmentation verification is displayed in Figure 1.With the aid of this tool, it took 6 person-hoursto check and correct the automatically segmentedutterances for the 18 dialogues in our corpus.4 Tutorial AnnotationTo provide a detailed analysis of tutorial dialogueand remediation strategies, we employ a hierarchi-cal annotation scheme which encodes the recur-sive dialogue structure.
Each tutorial session con-sists of a sequence of tasks, which may be eitherteaching specific domain concepts or doing indi-vidual exercises.
Each task?s structure includesone or more of the following: giving definitions,formulating a question, obtaining the student an-swer and remediation by the tutor.Generally speaking, the structure of tutorial di-alogue is governed by the task structure just as intask-oriented dialogue (Grosz and Sidner, 1986).However, the specific annotation structure differsdepending on the tutoring method.
In our basicelectricity and electronics domain, a tutorial ses-sion consists of a set of ?teach?
segments, andwithin each segment a number of ?task?
segments.Task segments usually contain exercises in whichthe student is asked a question requiring a simple(one- or two-line) answer, which may be followedby a long remediation segment to address the con-ceptual problems revealed by the answer.In contrast, in our calculus domain the studentshave to do multi-step procedures to differentiatecomplex math expressions, but most of the reme-diations are very short, fixing the immediate prob-lem and letting the student continue on with theprocedure.
Thus even though the dialogue is hier-archically structured in both cases, the annotationschemes differ depending on the domain.
We de-veloped a generic tool for annotating hierarchicaldialogue structure which can be configured withthe specific annotation scheme.The tool interface (Figure 2) consists of a tran-script of a session and a linked tree representation.Individual utterances displayed in the transcriptare leaves of the tree.
It is not possible to displaythem as tree leaves directly as would be done insyntactic trees, because they are too large to fit ingraphical tree display.
Instead, a segment is high-lighted in a transcript whenever it is selected in thetutorial structure, and a hotkey is provided to ex-pand the tree to see all annotations of a particularutterance in the transcript.The hierarchical tree structure is supported by aschema which describes the annotations possibleon each hierarchical tree level.
Since the multi-layered annotation scheme is quite complex, thetool uses the annotation schema to limit the num-ber of codes presented to the annotator to be onlythose consistent with the tree level.
For exam-ple, in our basic electricity domain annotation de-scribed above, there are about 20 codes at differentlevel, but an annotator will only have ?teach?
as anoption for assigning a code to a top tree level, andonly ?task?
and ?test?
(with appropriate subtypes)for assigning codes immediately below the teachlevel, based on the schema defined for the domain.5 Transcript SegmentationWe had to conduct several simpler data analy-ses where the utterances in the transcript are seg-mented according to their purpose.
For exam-ple, in tutorial differentiation the dialogue con-centrates on 4 main purposes: general discussion,introducing problems, performing differentiationproper, or doing algebraic transformations to sim-plify the resulting expressions.
In another analysiswe needed to mark the segments where the studentwas making errors and the nature of those errors.We developed a generic annotation tool to sup-port such segmentation annotation over the utter-ance layer.
The tool is configured with the nameof the segment tag and colours indicating differentsegment types.
The annotator can enter a segmenttype, and use a freetext field for other information.A screenshot of the annotation tool with utterancepurposes marked is given in Figure 3.6 Data AnalysisThe NITE query language (NQL) enables us to ac-cess the data as a directed acyclic graph to cor-relate simple annotations, such as finding out the58Figure 1: Utterance Segmentation Tool.Figure 2: Tutorial Strategy Annotation Tool.59Figure 3: Segmentation tool.
The segment labels are shown on the left.number of turns which contain only mathematicalexpressions but no words.
We use the NITE queryinterface for simpler analysis tasks such as findingall instances of specific tags and tag combinations.However, we found the query language less use-ful for coordinating the situational factors anno-tated by tutors with other annotation.
Each set offactors submitted is normally associated with thefirst student turn which precedes it, but the factorswere not linked to student utterances explicitly.NQL does not have a ?direct precedence?
opera-tor.2 Thus it is easier derive this information usingthe JAVA API.
To make the data analysis simpler,we are planning to add a pointer layer, generatedautomatically based on timing information, whichwill use explicit pointers between the factor sub-missions and preceding tutor and student turns.7 ConclusionsWe presented a set of tools for hierarchically an-notating dialogue structure, suitable for annotatingtyped dialogue.
The turns in these dialogues arecomplex and overlap with dialogue structure, andour toolset supports segmenting turns into smaller2It?s possible to express the query in NQL us-ing its precedence operator ?
?
as ?
($f factor)($u utterance) (forall $u1 utterance) :(($f  $u) && ($f  u1)) ?
(u  u1)?.However, this is very inefficient since it must check allutterance pairs in the corpus to determine direct precedence,especially if it needs to be included as part of a bigger query.utterance units and annotating hierarchical dia-logue structure over the utterances, as well as pro-viding simpler segmentation annotation.AcknowledgementsThis material is based upon work supported by agrant from The Office of Naval Research num-ber N000149910165 and European Union 6thframework programme grant EC-FP6-2002-IST-1-507826 (LeActiveMath).ReferencesJean Carletta, J. Kilgour, T. O?Donnell, S. Evert, andH.
Voormann.
2003.
The NITE object model li-brary for handling structured linguistic annotationon multimodal data sets.
In Proceedings of theEACL Workshop on Language Technology and theSemantic Web.Barbara J. Grosz and Candace L. Sidner.
1986.
Atten-tion, intentions, and the structure of discourse.
Com-put.
Linguist., 12(3):175?204.Pamela Jordan and Stephanie Siler.
2002.
Studentinitiative and questioning strategies in computer-mediated human tutoring dialogues.
In Proceedingsof ITS 2002 Workshop on Empirical Methods for Tu-torial Dialogue Systems.Farhana Shah, Martha W. Evens, Joel Michael, andAllen Rovick.
2002.
Classifying student initiativesand tutor responses in human keyboard-to-keyboardtutoring sessions.
Discourse Processes, 33(1).60
