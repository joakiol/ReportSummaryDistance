Proceedings of the TextGraphs-8 Workshop, pages 61?69,Seattle, Washington, USA, 18 October 2013. c?2013 Association for Computational LinguisticsAutomatic Extraction of Reasoning Chains from Textual ReportsGleb Sizov and Pinar O?ztu?rkDepartment of Computer ScienceNorwegian University of Science and TechnologyTrondheim, Norway{sizov, pinar}@idi.ntnu.noAbstractMany organizations possess large collectionsof textual reports that document how a prob-lem is solved or analysed, e.g.
medical pa-tient records, industrial accident reports, law-suit records and investigation reports.
Ef-fective use of expert knowledge contained inthese reports may greatly increase productiv-ity of the organization.
In this article, we pro-pose a method for automatic extraction of rea-soning chains that contain information usedby the author of a report to analyse the prob-lem at hand.
For this purpose, we devel-oped a graph-based text representation thatmakes the relations between textual units ex-plicit.
This representation is acquired auto-matically from a report using natural languageprocessing tools including syntactic and dis-course parsers.
When applied to aviation in-vestigation reports, our method generates rea-soning chains that reveal the connection be-tween initial information about the aircraft in-cident and its causes.1 IntroductionSuccess of an organization is highly depend on itsknowledge which is generated and accumulated byits employees over years.
However, unless madeexplicit and shareable, organizations have the riskof losing this knowledge because employees maychange jobs at any time, or retire.
It is common todocument such experience, also for evidence pur-pose in case of legal problems and governmentalregulations.
Consequently, many companies and in-stitutions have large collections of textual reportsdocumenting their organizational experience on aparticular task, a client or a problem.
Industrial in-cident reports, law suit reports, electronic patientrecords and investigation reports are the most intu-itive examples.
The effective use of the knowledgecontained in these reports can save substantial timeand resources.
For example, incident reports can beused to identify possible risks and prevent future in-cidents, law suit reports constitute precedences forfuture cases, and patient records might help to diag-nose and find an appropriate treatment for a patientwith similar symptoms.Existing search engines are effective at findingrelevant documents.
However, after retrieval, inter-pretation and reasoning with knowledge containedin these documents is still done manually with nocomputer assistance other than basic keyword-basedsearch.
In our research, we are aiming to developmethods that will assist users in interpretation andreasoning with knowledge contained in textual re-ports.
The rationale behind our approach is that ex-perts?
line of reasoning for understanding and solv-ing a problem can be reused for the analysis of a sim-ilar problem.
Reasoning knowledge can be extractedfrom a report by analysing its syntactic and rhetor-ical structure.
When extracted and represented in acomputer-friendly way, this knowledge can be usedfor automatic and computer-assisted reasoning.In this article, we propose a method for auto-matic extraction of reasoning chains from textual re-ports.
A reasoning chain is defined as a sequenceof transitions from one piece of information to an-other starting from the problem description and lead-ing to its solution.
Our model is based on a novel61graph-based text representation, called Text Reason-ing Network (TRN), which decomposes a documentinto text units, discovers the connections betweenthese text units and makes them explicit.
TRN isacquired automatically from text using natural lan-guage processing tools including a syntactic parser,a discourse parser and a semantic similarity mea-sure.We tested our method on aviation investigation re-ports from Transportation Board of Canada.
Thesereports are produced as a result of investigation ofaircraft incidents where experts are assigned the taskof analysing an incident and writing down their un-derstanding of what and why it happened.
Reason-ing chains extracted from the investigation reportsreveal the connection between initial informationabout the incident and its causes.
When visualized,this connection can be interpreted and analysed.The rest of the paper is organized as follows.
Sec-tion 2 provides an overview of the related research.In section 3, TRN representation is described.
Gen-eration of reasoning chains from aviation investiga-tion reports is explained in section 4.
Interesting ex-amples of reasoning chains generated by our systemare demonstrated and analysed in section 5.
In sec-tion 6, we discuss the results and elaborate on futurework.2 Related WorkTo our knowledge, automatic extraction of reason-ing chains from text has not been attempted before.However, we were able to find several papers deal-ing with text processing tasks relevant to our goalthat make use of graph-based representations.The work done by Pechsiri and Piriyakul (2010)is focused on extraction of causal relations from textand construction of an explanation graph.
The rela-tions are extracted between clauses based on minedcause-effect verb pairs, e.g.
?If the [aphids in-fest rice pants], [the leaves will become yellow].
?with cause verb ?infest?
and effect verb ?become?.The explanation graph is constructed directly fromthe extracted relations, which is different from ourapproach where reasoning chains are extracted aspaths from the graph-based representation of a re-port.
There is only one example of the explanationgraph presented in the paper.
This graph is gener-ated from plant disease technical papers capturingpart of the domain knowledge.
Manual inspectionof the graph revealed few mistakes.An interesting research was conducted by Be-rant (2012) for his PhD thesis.
Unlike Pechsiri andPiriyakul (2010), his approach relies on textual en-tailment instead of causal relations.
Entailment re-lations are obtained between propositional patterns,e.g.
(Xsubj???
desireobj???
Y,Xsubj???
wantobj??
?Y ), using a classifier trained on distributional simi-larity features.
The focus of their work is to exploittransitive nature of entailment relations in learningof entailment graphs.
As an application, the au-thors developed a novel text exploration tool, wherea user can drill down/up from one statement to an-other through the entailment graph.
Entailment re-lations alone, i.e.
textentails?????
hypothesis, are notsufficient for extraction of reasoning chains becausethe hypothesis often contains the information whichis already present in the text, making it impossibleto create a path from the problem description to thesolution.
However, when combined with other typesof relations they might be useful for out task.In the paper by Jin and Srihari (2007), authorsgenerate and evaluate evidence trails between con-cepts across documents.
An evidence trail is apath connecting two concepts in a graph wherenodes are concepts that correspond to named enti-ties and noun phrases participating in subject-verb-object constructs.
Three variations of the represen-tation are tested, each with edges capturing differ-ent types of information.
In the first one, edgescapture word order in text.
The second one cap-tures co-occurrence of concepts.
The third varia-tion contains edges with weights corresponding tothe similarity between contexts of the concepts.
Vec-tor space model is used to represent and measure thesimilarity between the contexts.
The concept-basedrepresentation is substantially different from TRNbut the idea of finding a shortest path between nodesand use it as the evidence is similar.
There is oneexample of the evidence trail shown in the paper:?bush - afghanistan - qaeda - bin ladin?, which re-veals the connection between topics rather than con-crete pieces of information.A graph-based representation similar to (Jin andSrihari, 2007) have been applied for Textual Case-62The aircraft stalled at a higher-than-normal airspeed due to accumulated ice on critical surfaces.aircraft stalled at a higher-than-normal airspeedaccumulated ice on critical surfaces ice accumulation on critical surfacesIce accumulation on critical surfaces was possible.ice accumulation critical surfacesSimilaraccumulated iceCausestalled at a higher-than-normal airspeedaircrafthigher-than-normal airspeedContains Contains ContainsContains Contains Contains ContainsContainsContainsContainsSimilarAnalysisContains ContainsFactual InformationFigure 1: Two sentences represented as Text Reasoning Network.Based Reasoning (TCBR) (Lenz and Burkhard,1996; Cunningham et al 2004), a task of automat-ically solving a new problem given a collection ofreports describing previous problems with solutions.The dataset we use in our research can be considereda TCBR dataset, since each report contains a prob-lem description and a solution part.
Problem-solvingbased on knowledge represented in textual form isa tough task and in practice TCBR approaches ei-ther do classification of a problem into predefinedclasses or retrieve a report that describes a problemsimilar to a query problem.
In the later case, in-formation retrieval methods are utilized, includinggraph-based representations for computing similar-ity between documents as it is done by Cunning-ham et al(2004).
Their representation, inspired bySchenker et al(2003), contains terms as nodes andedges connecting the adjacent terms in text.
Nodesand edges are labelled with the frequency of theirappearance and with the section where they appear,i.e.
title or text.
Infrequent terms are removed.
Inaddition, domain knowledge is introduced as a listof important domain terms that are preserved even iftheir frequency is low.
The similarity used is basedon maximum common sub-graph.
When tested onsummary documents from a law firm handling in-surance cases, the results show improvement overvector space model representations.3 Text Reasoning NetworkIn our approach, a reasoning chain is extracted as apath from the graph-based text representation.
Anappropriate representation is crucial because chainsextracted from it are only as good as the represen-tation itself.
In this section we introduce a novelgraph-based text representation, called Text Reason-ing Network (TRN), which is a graph with two typesof nodes: text nodes and section nodes; and threetypes of edges: structural, similarity and causal.
Fig-ure 1 shows two sentences from a report representedas TRN with section nodes on the top and all the textnodes below them.
The representation is acquiredautomatically from text by the following procedure:(1) syntax trees obtained from a syntactic parser areadded to the graph, (2) section nodes are attached tosentence nodes, (3) similarity edges are added be-tween similar text nodes, (4) cause relations identi-fied by a discourse parser are added.
The rest of thissection provides details on the structure of TRN andmethods used to generate it from text.3.1 Nodes and Structural RelationsWe are aiming to extract chains that capture the in-formation used by the author of a report to reasonabout the problem at hand.
Graph-based text rep-resentations described in section 2 use individualterms or short phrases as nodes.
Small text unitssuch as these are unable to capture sufficient infor-mation for our purpose.
Another popular choicefor a node in a textual graph is a sentence, whichcaptures a more or less complete piece of informa-tion and is easy to interpret.
However, a complexsentence may contain several pieces of informationwhere only one is used in a reasoning chain.A syntax tree provides a natural decomposition of63a sentence into its constituents.
Since it is hard todetermine beforehand the size of constituents thatwould be useful in a reasoning chain, we decided toincorporate all the S (sentence, clause), NP (nounphrase) and VP (verb phrase) nodes from syntaxtrees produced by Stanford Parser (Klein and Man-ning, 2003).
These nodes are referred to as textnodes.
In addition to text nodes, the structure of asyntax tree is also retained by adding structural re-lations Contains and PartOf to TRN that correspondto relations between parent and children text unitsin the syntax tree.
Figure 1 shows text nodes ex-tracted from two sentences along with Contains re-lations between them.
PartOf edges are not shownto avoid the clutter.Graphs extracted from different sentences in adocument are combined into one.
Each node hasa unique identity that is composed of a sequence ofstemmed words with stopwords removed.
The ma-jor implication of this is that if two sentences over-lap, they will share one or several nodes, e.g.
node?critical surfaces?
in figure 1.In addition to text nodes, there are also sectionnodes corresponding to parts of a document, e.g.
?Factual Information?
and ?Analysis?
nodes in fig-ure 1.
These nodes capture the structure of a doc-ument.
Text nodes containing a complete sentence,also referred to as sentence nodes, are attached tosection nodes by structural relations.3.2 Similarity RelationsIn addition to structural relations, text nodes are con-nected through similarity relations.
To obtain theserelations, a similarity value is computed for eachpair of text nodes of the same category (S, VP, NP)that are not in the same sentence.
Similar edges areadded to the graph for node pairs with the similarityvalue above a predefined threshold, e.g.
nodes ?iceaccumulation?
and ?accumulated ice?
in figure 1.Our similarity measure finds one-to-one align-ment of words from two text units to maximize thetotal similarity between them.
For words we com-pute LCH (Leacock et al 1998) similarity, based ona shortest path between the corresponding senses inWordNet.
A complete bipartite graph is constructedand the maximum weighted bipartite matching iscomputed using the Hungarian Algorithm (Kuhn,1955).
Nodes in this bipartite graph represent wordsfrom the text units while edges have weights thatcorrespond to similarities between words.
Maxi-mum weighted bipartite matching finds a one-to-onealignment that maximizes the sum of similarities be-tween aligned words.
This sum is normalized to liebetween 0 and 1 and is used as the final value for thesimilarity between text units.
If the value is higheror equal 0.6 a Similar edge is added between the cor-responding nodes.3.3 Causal RelationsCausal relations are essential for analysis and deci-sion making allowing inference about past and fu-ture events (Garcia-Retamero et al 2007).
As seenin (Pechsiri and Piriyakul, 2010) causal graphs ex-tracted from domain-specific documents provide apowerful representation of expert knowledge.State-of-the-art techniques for extraction ofcausal relations from text use automatic classi-fiers trained on lexical features to recognize rela-tions between subject and object in a clause or be-tween verbs of different clauses (Chang and Choi,2005; Bethard and Martin, 2008).
Causal relationsare among discourse relations defined by Rhetori-cal Structure Theory (Mann and Thompson, 1988).Therefore, a discourse parser can be used to obtainthem from text.
The advantage of this approach isthat a discourse parser recognizes relations betweenlarger text units.
Few discourse parsers are avail-able that can parse an entire document.
For our workwe used PDTB-Styled End-to-End Discourse Parserby Lin et al(2010), which makes use of machinelearning techniques trained on Penn Discourse Tree-bank (PDTB) (Prasad et al 2008).
Cause relationsidentified by the parser are added to TRN graph bymapping arguments of the relations to text nodes andthen adding Cause edges between them.4 Generation of Reasoning Chains fromAviation Accident ReportsGeneration of a reasoning chain from a report is athree-stage process: (1) a report is converted fromtext to a TRN graph, (2) given a start and an endnode, several paths are extracted from the graph, (3)paths are combined, post-processed and visualized.644.1 DatasetIn our work we use aviation investigation reportsfrom Transportation Safety Board of Canada1.
Eachreport in this collection documents an aircraft inci-dent and contains the following sections: (1) ?Sum-mary?
is a brief description of the incident, (2) ?Fac-tual Information?
(further referred to as ?Factual?
)contains details about the aircraft, pilot, weatherconditions, terrain and communication with con-trollers (3) ?Analysis?
is a discussion of the incidentwith the purpose to explain it based on the informa-tion presented in the previous section, (4) ?Findingsas to Causes and Contributing Factor?
(further re-ferred to as ?Causes?)
is a brief enumeration of find-ings that most likely caused the incident.The reports were downloaded from Transporta-tion Board of Canada website as html documents.Text and structure were extracted from html usinga custom Java component developed based on man-ual analysis of the html source.
Preprocessing stepsincluding tokenization, sentence splitting and part-of-speech tagging were accomplished using ANNIEcomponents in GATE NLP platform (Cunninghamet al 2002).4.2 Extraction of Reasoning ChainsWe define a reasoning chain as the shortest paththrough a TRN representation of a report startingfrom a sentence in ?Summary?
and ending at oneof the sentences in ?Causes?
section.
The rationalebehind this decision is to reveal the author?s reason-ing line starting from the initial information aboutthe incident contained in ?Summary?
and leading toincident causes in ?Causes?
section.
Hence, the pathfinding process is constrained to follow the directionfrom ?Summary?
to ?Causes?
through ?Factual?
and?Analysis?
sections.
The reasoning chain path withconstraints is defined by the following context-freegrammar in Backus-Naur Form (optional items in[...]):?path?
::= ?summary-path?
[?edge?
?factual-path?][?edge?
?analysis-path?]
?edge?
?causes-path??summary-path?
::= ?summary-node?| ?summary-node?
?contains-edge?
?summary-path?1Aviation Investigation Reports are available at http://goo.gl/k9mMV?factual-path?
::= ?factual-node?| ?factual-node?
?edge?
?factual-path??analysis-path?
::= ?analysis-node?| ?analysis-node?
?edge?
?analysis-path??causes-path?
::= ?causes-node?| ?causes-node?
?partof-edge?
?causes-path??edge?
::= ?partof-edge?| ?contains-edge?| ?similar-edge?| ?cause-edge?Several paths are obtained for each ?Summary?sentence, each of which starting at one of the textnodes contained in the sentence.
These paths arethen combined into a reasoning graph.
Before visu-alization, a post-processing algorithm is applied tomake the reasoning graph more compact.
The al-gorithm collapses a sequence of structural edges ofthe same type into a single edge, e.g.
Acontains??????Bcontains??????
C is converted into Acontains??????
C ifthere is no other edge attached to B.
The com-pressed graph (shown in figures 2, 3 and 4) is visual-ized using JGraphX library with hierarchical layoutfor automatic positioning of nodes.5 Examples and AnalysisIn this section we analyse three reasoning graphsgenerated by our system.
These graphs were se-lected mainly because of their compact size and easeof interpretation even for someone who is not an avi-ation expert.
Every chain starts with a sentence from?Summary?
on the top of the figure and ends withone or several sentences in ?Causes?
on the bottom.For each node a contained text unit is displayed, fol-lowed by one or several letters in parenthesis indicat-ing which section of the report this text node is ob-served in: S - ?Summary?, F - ?Factual?, A - ?Anal-ysis?, C - ?Causes?.Figure 2 shows the reasoning graph with onebranch expressing that the captain?s focus on ?set-ting climb power?
and the ?landing gear?
preventedhim from paying attention to the ?aircraft altitude?so the ?sink rate was undetected and aircraft struckthe ground?.
The start and the end sentences are notsimilar and it is the sentence from the ?Analysis?section that connects these two.65Figure 2: A reasoning graph from report A05O0225(available at goo.gl/SZpTS)The graph in figure 3 has two branches.
The leftbranch directly points to a sentence with ?the aux-iliary fuel pump?
but it does not explain ?a poorelectrical connection?.
The right branch, however, islonger and goes from ?switched fuel tank?
to ?fuelflow?
and then to ?fuel pressure?, which is part ofa sentence in the ?Cause?
section that includes thistext segment: ?reduction of fuel pressure, preventingnormal engine operation?.The graph in figure 4 contains two branchesas well.
The left branch picks up the locationof the flight ?Deer Lake?
which relates to ?icingconditions?
although the text node suggesting ?alower altitude was requested to remain clear of ic-ing conditions?
makes this branch incoherent.
Theright branch provides a connection between ?Provin-cial Airlines Limited?
and ?no requirement?
intheir ?standard operating procedures?
for a ?methodfor ensuring the correct selection of AFCS climbmodes?.
The chain goes through ?an inappropriateAFCS mode?
providing a good idea of the incidentcause.Reasoning chains extracted by the system providea brief overview of the authors?
reasoning line show-ing how a basic information about the incident isconnected to its causes.
However, some chains areless informative than others (left branch in figure 3)or incoherent (left branch of 4).
In the former casethe chain could be made more informative if the sys-tem will be queried to find evidence for ?poor elec-trical connection?
in addition to ?the auxiliary fuelpump?.
In the latter case, the chain becomes inco-herent because ?icing conditions?
is used in differ-ent contexts where the first sentence states the lackof ?icing conditions?
and the second the presence of?icing conditions?.
It is possible to account for thisinconsistency by introducing a preference for largertext units capturing more context or by recognizingnegations/absence.6 Conclusion and Future WorkThis paper presents a method for extraction of rea-soning chains from textual reports.
The method isbased on a graph-based text representation that cap-tures both the structure and the content of the re-port.
Extracted reasoning chains provide a conve-nient way to visualize information used by a domainexpert to reason about causes of an aircraft incident.It may help in analysis of future incidents and opensthe possibility for automatic or computer-assistedanalysis.
The methods can be adapted to other do-mains and applications by defining appropriate startnodes, end nodes and constraints like it is done insection 4.2.Extraction of reasoning chains is a new task andthere are yet no evaluation measures available.
Oneof the primary goals for our future work is to de-velop a formal evaluation procedure for this task.An intrinsic evaluation will require manually con-structed reasoning chains as the gold standard tocompare the automatically extracted ones with.
Forthe extrinsic evaluation, reasoning chains can beused in TCBR task for solution retrieval and eval-uated with TCBR evaluation measures (Raghunan-dan et al 2008; Adeyanju et al 2010).
We alsoplan to continue our work on the representation byadding new types of relations to TRN and on the rea-soning chain extraction algorithm by adapting flownetworks instead of shortest path for extraction ofreasoning chains.66Figure 3: A reasoning graph from report A05O0146 (available at goo.gl/MPMIq)67Figure 4: A reasoning graph from report A05A0059 (available at goo.gl/u1CXI)68ReferencesIbrahim Adeyanju, Nirmalie Wiratunga, Robert Lothian,and Susan Craw.
2010.
Applying machine translationevaluation techniques to textual cbr.
In Case-BasedReasoning.
Research and Development, pages 21?35.Springer.Jonathan Berant.
2012.
Global Learning of Textual En-tailment Graphs.
Ph.D. thesis, Tel Aviv University.Steven Bethard and James H Martin.
2008.
Learningsemantic links from a corpus of parallel temporal andcausal relations.
In Proceedings of the 46th AnnualMeeting of the Association for Computational Linguis-tics on Human Language Technologies: Short Papers,pages 177?180.
Association for Computational Lin-guistics.Du-Seong Chang and Key-Sun Choi.
2005.
Causal rela-tion extraction using cue phrase and lexical pair prob-abilities.
In Natural Language Processing?IJCNLP2004, pages 61?70.
Springer.Hamish Cunningham, Diana Maynard, KalinaBontcheva, and Valentin Tablan.
2002.
Gate:an architecture for development of robust hlt appli-cations.
In Proceedings of 40th Annual Meeting ofthe Association for Computational Linguistics, pages168?175, Philadelphia, Pennsylvania, USA, July.Association for Computational Linguistics.Colleen Cunningham, Rosina Weber, Jason M Proctor,Caleb Fowler, and Michael Murphy.
2004.
Inves-tigating graphs in textual case-based reasoning.
InAdvances in Case-Based Reasoning, pages 573?586.Springer.Rocio Garcia-Retamero, Annika Wallin, and Anja Dieck-mann.
2007.
Does causal knowledge help us be fasterand more frugal in our decisions?
Memory & cogni-tion, 35(6):1399?1409.Wei Jin and Rohini K. Srihari.
2007.
Graph-based textrepresentation and knowledge discovery.
Proceedingsof the 2007 ACM symposium on Applied computing -SAC ?07, page 807.Dan Klein and Christopher D Manning.
2003.
Ac-curate unlexicalized parsing.
In Proceedings of the41st Annual Meeting on Association for Computa-tional Linguistics-Volume 1, pages 423?430.
Associ-ation for Computational Linguistics.Harold W Kuhn.
1955.
The hungarian method for the as-signment problem.
Naval research logistics quarterly,2(1-2):83?97.Claudia Leacock, George A Miller, and MartinChodorow.
1998.
Using corpus statistics and word-net relations for sense identification.
ComputationalLinguistics, 24(1):147?165.Mario Lenz and Hans-Dieter Burkhard.
1996.
Case re-trieval nets: Basic ideas and extensions.
In KI-96:Advances in Artificial Intelligence, pages 227?239.Springer.Ziheng Lin, Hwee Tou Ng, and Min-Yen Kan. 2010.
Apdtb-styled end-to-end discourse parser.
Technical re-port, Cambridge Univ Press.William C Mann and Sandra A Thompson.
1988.Rhetorical structure theory: Toward a functional the-ory of text organization.
Text, 8(3):243?281.Chaveevan Pechsiri and Rapepun Piriyakul.
2010.Explanation knowledge graph construction throughcausality extraction from texts.
Journal of ComputerScience and Technology, 25(5):1055?1070.Rashmi Prasad, Nikhil Dinesh, Alan Lee, Eleni Milt-sakaki, Livio Robaldo, Aravind K Joshi, and Bonnie LWebber.
2008.
The penn discourse treebank 2.0.
InLREC.
Citeseer.M.
A. Raghunandan, Nirmalie Wiratunga, SutanuChakraborti, Stewart Massie, and Deepak Khemani.2008.
Evaluation measures for tcbr systems.
InAdvances in Case-Based Reasoning, pages 444?458.Springer.A.
Schenker, M. Last, H. Bunke, and A. Kandel.
2003.Clustering of web documents using a graph model.Web Document Analysis: Challenges and Opportuni-ties, pages 1?16.69
