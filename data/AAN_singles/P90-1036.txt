AN EFF IC IENT PARSING ALGORITHM FOR TREE ADJOIN INGGRAMMARSKar in  HarbuschDFKI - Deutsches  Forschungszent rum fiir K f inst l i che Inte l l igenzS tuh lsatzenhausweg 3, D-6600 Saarbr i i cken 11, F .R .G .harbusch~dfk i .un i - sb .deABSTRACTIn the literature, Tree Adjoining Grammars(TAGs) are propagated to be adequate for nat-ural language description - -  analysis as well asgeneration.
In this paper we concentrate on thedirection of analysis.
Especially important for animplementation f that task is how efficiently thiscan be done, i.e., how readily the word problemcan be solved for TAGs.
Up to now, a parser withO(n 6) steps in the worst case was known where nis the length of the input string.
In this paper, theresult is improved to O(n 4 log n) as a new lowestupper bound.
The paper demonstrates how localinterpretion of TAG trees allows this reduction.1 INTRODUCTIONCompared with the formalism of context-freegrammars (CFC, s), the rules of Tree AdjoiningGrammars (TAGs) can be imagined intuitivelyas parts of context-free derivation trees.
Withoutpaying attention to the fact that there are somemore restrictions for these rules, the recursion op-eration (adjoining) is represented as replacing anode in a TAG rule by another TAG rule so thatlarger derivation trees are built.This close relation between CFGs and TAGscan imply that they are equivalent.
But TAGsare more powerful than context-free grammars.This additional power - -  characterized as mildlycontext-sensitive - -  leads to the question ofwhether there are efficient algorithms to solve theword problem for TAGs.Up to now, the algorithm of Vijay-Shanker andJoshi with a time complexity of O(n 6) for theworst case was known, in addition to several un-successful attempts to improve this result.
Thispaper's main emphasis is on the improvement ofthis result.
An efficient parser for Tree AdjoiningGrammars with a worst case time complexity ofO(n 4 log n) is discussed.All known parsing algorithms for TAGs usethe close structural similarity between TAGs andCFGs, which can be expressed by writing all innernodes and all their sons in a TAG as the rule setof a context-free grammar (the context-free ker-nelof a TAG).
Additionally, the constraint has tobe tested that all further context-free rules corre-sponding to the same TAG tree must appear inthe derivation tree, iff one rule of that TAG treeis in use.
Therefore, it is clear that a context-freeparser can be the basis for extensions representingthe test of the additional constraint.On the basis of the two fundamental context-free analysers, the different approaches for TAGs284can be divided into two classes.
One class extendsan Earley parser and the second class extends aCocke-Kasami- Younger (CKY) parser for CFGs.Here, we focus on the approaches with a CKYbasis, because the relation between the resultingtriangle matrix and the encoded derivation treesis closer than for the item lists of an Earley parser.In particular, the paper is divided into the fol-lowing sections.
First, a short overview of theTAG formalism is given in order to have a com-mon terminological basis with the reader.In the second section, the approach of Vijay-Shanker and Joshi is presented as the natural wayof extending the CKY algorithm for context-freegrammars to TAGs.
As a precondition for thatanalysis, it has to be proven that each TAG canbe transformed into two form, a normal form re-stricting the outdegree of a node to be less three.In section 4, the main section of this paper,a normal-form is defined as a precondition for anew and more efficient parsing algorithm.
Thisform is more restricted than the two form, and isclosely related to the Chomsky normal form forCFGs.
The main emphasis lies on the descriptionof the new parsing approach.
The general idea isto separate the context-free parsing and the addi-tional testing so that the test can run locally.
Onthe triangle matrix which is the result of the CKYanalysis with the context-free kernel, all completeTAG trees encoded in the triangle matrix arecomputed recursively.
It is intuitively motivatedthat this approach needs fewer steps than thestrategy of Vijay-Shanker and Joshi, which storesall intermediate states of TAG derivations, be-cause the locally represented elementary trees canbe interpreted as TAG derivations where equalparts are computed exactly once instead of indi-vidual representations in each derivation.In the summary, our experience with an imple-mentation in CommonLISP on a Hewlett Packardmachine is mentioned to illustrate the responsetime in an average case.
Finally, different ap-proaches for TAG parsing are characterized andcompared with the approaches presented here.2 TAGS BRIEFLY  REVIS ITEDFirst of all, the basic definitions for TAGs are re-visited in order to have a common terminologywith the reader (even though not defined explic-itly here, CFGs are used as described, e.g., in\[Hopcroft, Ullman 79\]).In 1975, the formalism of Tree Adjoining Gram-mars (TAGs) was introduced by Aravind K.Joshi, Leon S. Levy and Masako Takahashi (\[Joshiet al 75\]).
Since then, a wide variety of prop-erties - -  formal properties as well as linguisti-cally relevant ones - -  have been studied (see, e.g.,\[Joshi 85\] for a good overview).The following example describing the crosseddependencies in Dutch should illustrate the for-malism (see Figure 1, where the node numberswritten in slanted font should be ignored here;they make sense in combination with the descrip-tion of the new algorithm, especially step (tag2)).A TAG is a tree generation system.
It consists,in addition to the set of nonterminals N, the setof terminals T and the start symbol S, an extraor-dinary symbol in N, of two different sets of trees,which specify the rules of a TAG.
Intuitively, theset I of initial trees can be seen as context-freederivation trees.
This means the start symbolis the root node, all inner nodes are nontermi-nals and all leaves are terminals (e.g., in Figure1 tree a).
The second set A, the auxiliary trees,which can replace a node in an initial tree (whichis possibly modified by further adjoinings) dur-ing the recursion process, must have a form, sothat again a derivation tree results.
The trees/31and /32 demonstrate that restriction.
A specialleaf (the foot node) must exist, labelled with thesame nonterminal s the root node.
Further, it isobligatory that an auxiliary tree derives at leastone terminal.
The union of the initial and theauxiliary trees, so to speak the rule set of a TAG,is called the set of elementary trees.Tree 7 in Figure 1 shows a TAG derivationtree, which means an initial tree with an arbi-trary number of adjoinings (here /3x is adjoinedat the node S* in a and/32 at the node S* in theadjoined tree /31).
During the recursion process(adjoining), a node X in an initial tree a, whichcan be modified by further adjoinings, is replacedby an auxiliary tree /3 with the same nontermi-nal label at root and foot node, that X is labelledwith.
The incoming edge in X (if it exists; this istrue if X is not the root node of a) now ends inthe root node of/3, and all outgoing edges of X ina now start at the foot node of/3.The set of all initial trees modified by an arbi-trary number of adjoinings (at least zero) is calledT(G), the tree set of a TAG G. The elements inthis set can also be specified by building a seriesof triples (ai,/3i, Xi) (0 < i < n) - -  the deriva.tion - -  where s0 E I, al (1 < i < n) is the resultof the adjoining of/31-x in node ~:i-x in ai-x,/3i(0 < i < n-l) is the auxiliary tree, which is ad-joined in node Xl in tree ai and Xi (0 < i < n-l)is a unique node number in ai.
This descriptionhas the advantage that structurally equal trees inT(G) which result from different adjoinings canbe uniquely represented.L(G), the language of a TAG, is defined as theset containing all leaf strings of trees in T(G),respectively all trees which can be constructec\[by adjoining as described in the correspondingderivation.
Here, a leaf string means all labels ofleaves in a tree are concatenated in order fromleft to right.
In the tree 3' in Figure 1 'Jan PierMarie e e zag laten zwemmen' is in L(G).The relation between TAGs and CFGs can becharacterized by defining the context.free kernel285a: AS??
/3F ~S I0  /32: /~Marie e Plet e7: s~l'2 men"N~P2' ~atenJan N.P 111 V~ zagMarie cFigure l: A small sample TAG demonstrating theprocess of ADJOININGK of a TAG G. K is a CFG and consists of thesame sets N, T and S of G, but P(K) is the setof all inner nodes of all elementary trees in Ginterpreted as the lefthand side of a rule, whereall sons in their order from left to right build therighthand side of that rule.
E.g., in Figure 1 /32has the corresponding context-free rules: (S, NPVP), (NP, N), (N, Jan), (VP, S V1), (V1, zag).It is clear that having a context-free derivationtree (on the basis of the context-free kernel K ofa TAG G) is a necessary, but not sufficient prop-erty for an input string, which is tested to be anelement in L(G).
In the following, this propertymotivates the extension of context-free parsing al-gorithms to accept TAGs as well.The following parsing algorithms are able to ac-cept some extensions of the pure TAG definitionwithout changing the upper time bound.
Here,only TAGs with Constraints are mentioned (formore information about other extensions, e.g.,TAGs with Links, with Unification or Multi Com-ponent TAGs - -  some extending the generativecapacity - -  see, e.g., \[Joshi 85\]).The motivation for TAGs with ConstraintsTAGCs) is to restrict the recursion operation ofGs.
Each node X in an elementary tree la-belled with a nonterminal has an associated con-straint set C, which has one 0fthe following forms:?
NA stands for null adjoining and means thatat node X no adjoining can take place,?
SA(B) stands for selective adjoining andmeans that at X the adjoining of an auxil-iary tree (6 B).
can take place (where eachtree in B has  the same root and foot nodelabel as X) or?
OA(B) stands for obligalory adjoining andmeans that at X the adjoining of an auxiliarytree (E B) must take place (where each treein B has the same root and foot node labelas X).When TAGs are mentioned in the following, thesame result can be shown for TAGs with Con-straints, which it is not explicitly outlined.
Onlythe property of generative power is illustrated, tomake clear that finding a parsing algorithm is nota trivial task.
For more information about the lin-guistic relevance of TAGs, the reader is referred,e.g., to \[Kroch, Joshi 85\].A first impression comparing the generativepower of TAGs and CFGs can be that they areequivalent, but TAGs are more powerful, e.g., thefamous language an b" e c" can be produced bya TAG with Constraints (the main idea in con-structing this grammar is to represent the produc-tion of an a, a b and a c in one auxiliary tree).Thinking of the application domain of naturallanguage processing, the discussion in the linguis-tic community becomes relevant as to how pow-erful a linguistic formalism should be (see, e.g.,\[Pullum 84\] or \[Shieber 85\]).
TAGs are mildlyconlezt-sensitive, which means that they can de-scribe some context-sensitive languages, but notall (e.g., www with w 6 {a,b)*, but ww is accept-able for a TAG).
One thesis holds that naturallanguage can be described very well by a mildlycontext-sensitive formalism.
But this can only beempirically confirmed by describing difficult lin-guistic phenomena (here, the example in Figure1 can only give an idea of the appropriateness ofTAGs for natural anguage description).This property leads to the question of whetherthe word problem is solvable and if so, how ef-ficiently.
In the following section, two differ-ent polynomial approaches are presented in de-tail.
The property of efficiency becomes impor-tant when a TAG should be used in the applica-tion domain mentioned above, e.g., one can thinkof a syntax description encoded in TAG ruleswhich is part of a natural anguage dialogue sys-tem.
The execution time is responsible for theacceptance of the whole system.
Later on, ourexperience with the response time of an imple-mentation of the new algorithm is described.3 THE V I JAY -SHANKER ANDJOSHI  APPROACHFirst, the approach of Vijay-Shanker and Joshi(see \[Vijay-Shanker, Joshi 85\])is discussed as thenatural way of extending the context-free CKYalgorithm (see, e.g., \[Hopcroft, Ullman 79\]) to an-alyze TAGs as well.
As for the context-free anal-ysis with CKY, the grammar is required in nor-mal form as a precondition for the TAG parser.Therefore, first the two form is defined and theidea of the constructive proof for transforming aTAG into two form is given.
The TAG parser isthen presented in more detail.2863.1 TWO FORM TRANSFOR-MAT IONThe parsing algorithm of Vijay.Shanker and Joshiuses a special CKY algorithm for CFGs whichrequires fewer restrictive constraints than theChomsky normal form for the ordinary CKY al-gorithm does.
Here, the righthand side of all rulesof the grammar should have at most two elements.This definition has to he adapted for TAG rulesto extend this CKY parser to analyze TAGs aswell.A TAG G is in two form, iff each node in eachelementary tree has at most two sons.
It can beproven that each TAG G can be transformed intoa TAG G' in two form with L(G) - L(G').The proof of that theorem uses the same tech-niques as in the context-free case which allow thereduction of the number of elements on the right-hand side to build the Chomsky normal form.
Ifthere are more than two sons, the second and alladditional sons are replaced by a new nontermi-hal which becomes the lefthand side of a new rulewith all replaced symbols on the righthand side(for more details see \[Vijay-Shanker, Joshi 85\]).We always refer to a TAG in two form, even whenit is not explicitly confirmed.3.2 THE STEPS OF THE ALGO-R ITHMNow the idea of extending each context-free anal-ysis step by additional tests to ensure that wholeTAG trees are in use (sufficient property) is moti-vated.
This approach was proposed to be naturalbecause it tries to build TAG derivation trees atonce.
In contrast, a two level approach is pre-sented which constructs all context-free deriva-tion trees before the TAG derivations are com-puted in a second step.In the CKY analysis used here, a cell \[row/,column j\] in the triangle matrix (1 < i, j _<n, the length of the input string w --- tl ...t,,where without loss of generality n >__ 1, becausethe test for e, the empty string, E L(G) sim-ply consists of searching for initial trees with allleaves labelled with e) contains an element X (6N) iff there are rules to produce the derivation forti+l.. .t j_l .
This invariant is extended to repre-sent a TAG derivation for t i+l.
.
.t j_ l  iff X 6 \[i,j\].Therefore additional information of each nonter-minal in a cell has to be stored as to which el-ementary trees are under completion and whatsubtrees have been analyzed up to now.
Impor-tant to note is that the list of trees which areunder completion, can be longer than one.
E.g.,think of adjoinings which have taken place in ad-joined trees as described in Figure 1.For realization of that information, a slack canbe imagined.
Here, the different stack elementsare stored separately to use intermediate statesin common.
A stack element contains the infor-mation of exactly one auxiliary tree which is un-der construction, and a pointer to the next stackelement.
This pointer is realized by two addi-tional positions for each cell in the triangle matrix(\[i,j,k,l\]), where k and I in the third and fourthposition characterize the fact that from tk+l tot1_1 no information about the structure of theTAG derivation is known in this element and hasto be reconstructed by examination of all cells\[k,l,v,w\] (k <_ v < w < 1).
The stack cells whichthe elements point at must also be recursively in-terpreted until the whole subtree is examined (leftand right stack pointer are equal).
It is clear thatin interpreting these chains of pointers the stackat each node X in the triangle matrix representsall intermediate states of TAG derivations with Xas root node in an individual cell of the trianglematrix.The algorithm starts initializing cells for all ter-minal leaves (X E \[i-l,i,i,i\] for ti with father X,1 < i < n) and all foot nodes which can be seenas nonterminal leaves (X E \[i, j, i, j\] where X is afoot node in an auxiliary tree, 0 < i < j < n-l).Just as the CKY algorithm tests all combina-tions of neighboring strings, here new elements ofcells are computed together with the context-freeinvariant computation, e.g., iff (Z,X Y) is a rulein the context-free kernel of the input TAG andX E \[i, j, k, I\], Y E \[j - 1, m, p, p\] and X and Y areroot nodes of neighboring parts in the same ele-mentary tree, then Z is added to \[i, m, k, l\]).
Withthe additional test to determine whether the rule(in the example (Z,X Y)) is in the same TAG treeas the two sons (X and Y) and whether the sameholds for the subtrees below X and Y, it is clearthat a whole TAG tree can be detected.
If thisis the case, i.e., that two neighboring stack ele-ments should be combined, all elements of cells\[k, l, m, p\] are added to \[i, j, m, p\] iff X E\[ i ,  j, k,/\]is the root of an identified auxiliary tree.The time complexity becomes obvious whenthe range of the loops for all four dimensionsof the array is described explicitly (see \[Vijay-Shanker, Joshi 85\]).
From a more abstract pointof view, the main difference between the CKYanalysis for a CFG and a TAG is that, the sub-trees below the foot nodes are stored.
This factextends the input of length n to n 2 to describe thetwo additional dimensions.
On the basis of thatinput, the ordinary CKY analysis can be done,and so the expected time complexity is O((n2) 3)= O(nS).
With the explicitly defined ranges ofthe four dimensions for the positions in the array,it is clear that the worst case and the best casefor this algorithm are equal.4 A NEW AND MORE EFF I -C IENT APPROACHA time bound of O(n e) in the best and worstcase must be seen as a more theoretical result, be-cause an implementation f the algorithm showsthat the execution time is unacceptable.
In orderto use the formalism for any application domain,this result should be improved.
In this section, aTAG parser with an upper bound of O(n 4 log n)in the worst case is presented.
The best case isO(n3), because a CKY analysis has to at least bedone.2874 .1  NORMAL FORM TRANS-FORMATIONAs precondition of the new parsing algorithm, theTAG has to be transformed into a normal formwhich contains only trees with nodes and theirsons, following the Chomsky normal form defini-tion.
This means that the following three condi-tions hold for a TAG G:1. e E L(G) iff a tree with root node S (NA),the start symbol, which allows no further ad-joinings (null adjoining), and a single termi-nal son e is element in the set of initial treesI (this tree is called the e tree),2. except he e tree, no leaf in another elemen-tary tree is labelled with e, and3.
for each node in each elementary tree, thecondition holds that either the node has twosons both labelled with a nonterminal or thatthe node has one son labelled with a termi-nM.In a first step, each TAG is transformed in twoform so that condition 3 can be satisfied easier.This transformation is accomplished by the con-structive proof for the theorem that for each TAG(or TAG with Constraints for which the definitionholds as well) there exists an equivalent TAG withConstraints in normal.Important o note is that the idea of the trans-formation into Chomsky normal form for CFGscannot be adopted further on because this con-struction allows the erasure of nonterminal sym-bols if their derived structure is added to thegrammar.
In TAGs, a nonterminal not only rep-resents the derivation of its subtree in an elemen-tary tree, but can be replaced by an adjoining.Therefore, the general idea of the proof is to eraseparts of elementary trees which are not in normalform, and represent those parts as new auxiliarytrees.
After this step, the original grammar is innormal form and therefore the encoded auxiliarytrees can be used for explicit adjoinings, alwaysproducing structures in normal form.
Expiiciladjoinings mean adjoinings in the new auxiliarytrees which were built out of the erased parts ofthe original grammar.
These adjoinings replacethe nodes which are not in normal form.
Sincethe details of the different steps are of no furtherinterest here, the reader is referred to \[Harbusch89\] for the complete proof.4 .2  THE STEPS OF  THE NEWPARSING ALGORITHMThe input of the new parser consists of a TAG Gin normal form, and a string w = tl ...t,.
Withcondition one in the normal form definition, thetest for e E L(G) is trivial again.
From now onthis case is ignored, i.e., n > 1.The algorithm is divided into two steps.
Firsta CKY analysis is done with the context-free ker-nel K of the input TAG G. Here, the standardCKY algorithm as described in \[Hopcroft, Uliman79\] is taken, which requires a CFG in Chomskynormal form.
K satisfies the requirement thatthe TAG G is in normal form.
One can thinkthat it would be sufficient o simply transform thecontext-free kernel into Chomsky normal form in-stead of transforming the input TAG.
But withthis strategy one would loose the one-to-one map-ping of context-free rules in the CFK and father-son-relations in a TAG rule which becomes impor-tant for finding complete TAG rules in the secondstep of the new parser.Here the invariant of the CKY analysis is XE \[i, j\] iff there are rules to produce a derivationfor ti ... t j+i-1.
This information is slightly ex-tended to recognize complete subtrees of elemen-tary trees in the triangle matrix.
In the terminol-ogy of Vijay-Shanker and Joshi, a stack element isconstructed.
But it's important o note that thepointers are not interpreted, so that here local in-formation is computed relative to an elementarytree.Actually, the correspondence b tween an ele-ment in the triangle matrix and a TAG tree isrepresented as a pointer from the node in a tri-angle cell to a node in an elementary tree as de-scribed in Figure 2 (ignore the dotted lines at themoment).
An equivalent description is presentedin Figure 3 by storing the unique node number atwhich the pointer ends in the elementary tree andadditionally a flag indicating whether the TAGtree is initial (I) or auxiliary (A) and whether thenode is root node (T) of the tree or not (L).
E.g.,in Figure 2 the NP-son of the root node S in treeT carries the flag TA.In this terminology, the special case that thesubtree contains the foot node has to be repre-sented explicitly, because the foot node is a leafin the sense of elementary trees, but not in thesense of a derivation tree.
To know where thisleaf is positioned in the triangle matrix, a footnode pointer (FP) is defined from the root of thesubtree to the foot node if one exists in that tree(in Figure 2 the dashed arc).initial tree ~ auxiliary tree,B: 3' where,6' is adjoined in o~:N~'~I/ VP'~I DETH"~II/I ~ NP ~,~, .~ rVP.
, ,  J I?ET--Figure 2: Example illustrating the inductive basisof the new invariantSo, the invariant in the first step of the newparsing algorithm is computed uring the CKYanalysis - -  in our second terminology - -  by re-cursively defining extended node numbers ( ENNs)by triples (NN,TK,FP) as follows:In i t ia l i zat ionEach element X in level 1 (father of a terminalt) is initialized with an ENN, where NN is thenode number of X in a father-son-relation in anelementary tree a ( x ---* t), the tree kind TK :=LU (U=I,A) iff a E U and NN doesn't .end withzero (X is not the root of a) else TK := TU, andthe foot node pointer FP := nil, because the fa-288ther of a terminal is never a foot node in the sameauxiliary tree.For each node X in level 1 the ENN := iNN=nodenumber of a foot node in an auxiliary tree, LA,pointer to that ENN) is added iff X is the labelof the foot node with node number NN - -  to de-scribe foot node leaves.Recurs ion  a long the  CKY  analys isFor each new context-free element Z (Z ; X Y),the following tests are done in addition:If X has an ENN (NNi,TK1,FPi)  and Y hasan ENN (NNz,TK2,FP2) and NNI-(1 in the lastpositition) = NN2-(2 in the last position) andTKi = TK2 and at least FPi  or FP2 = nil then forZ an ENN (NNI- I ,TK,FP) is added where TK =TK1 if Z is not the root node of the whole tree (inthis case TK = TK I - (L+T in the first position));FP = FPi (i=1,2), which is not equal nil, else itis nil.If an auxiliary tree with Z the label of thefoot node exists, the ENN (NN=node number ofthe foot node in that tree, LA, pointer to thatelement) is added to Z in the currently manipu-lated triangle cell - -  to represent the possibilityof an adjoining in that node.It is obvious that this invariant consisting ofthe nonterminal in a cell of the triangle matrix torepresent the context-free invariant, the pointersto elementary trees, and the foot node pointersto represent which part of an elementary tree isanalyzed computes less information than an arraycell in the approach of Vijay-Shanker and Joshidoes, where whole subtrees of the derivation treeare stored not stopping at a foot node as we do.Also, it is clear that this invariant can be com-puted recursively during the ordinary CKY stepswithin the upper time bound of O(n3).
The num-ber of pointers to elementary trees at each nodecan be restricted by the number ofoccurences of anonterminal s the left-hand side symbol of a rulein the context-free kernel (which is a constant).The number of foot node pointers is restricted bythe outdegree of each cell in the triangle matrixb<e n), because only for such an edge can an FPrecursively defined.In the second step, whole TAG derivations arecomputed by combining the subtrees of elemen-tary trees (represented by the invariant after step1), according to the adjoining definition inter-preted inversely.
Inversely means that the equiva-lence in the adjoining definition is not interpretedin the direction that a node is replaced by a tree,but in the opposite direction, where trees have tobe detected and are eliminated.Since all TAG derivation trees of a string wand a TAG G are encoded in the triangle matrixbnecessary condition w E CFK(G)) and have toe found in the triangle matrix, the derivationdefinition has to be modified as well to supportthe 'inverse' adjoining definition.
It means thata string w E L(G) iff there exists a tree, whererecursively all complete auxiliary trees can be de-tected and replaced bythe  label of the root nodeof the auxiliary tree until this process terminatesin an initial tree.The second step formulates the algorithm forexactly this definition.
An auxiliary tree in thederivation tree which contains no further adjoin-ings is called an innermost ree.
As long as thetermination condition isn't satisfied, at least oneinnermost tree must exist in the derivation tree.Returning to the invariant in the first step, in-nermost rees are characterized as a pointers tothe root node of an auxiliary tree or in the rep-resentation of ENNs as the node number of theroot node (in our numbering algorithm visible bythe end number zero) and the tree kind flag TA(total auxiliary).These trees are eliminated by identifying theroot and the foot nodes of innermost trees, so tospeak, as interpretation of the foot node point-ers as e edges.
This can be represented sim-ply as propagation of the pointers from the footnode to the root node.
This information is suffi-cient because the strategy of the algorithm checkswhether an incoming edge in a node and the in-formation of an outgoing edge (without loss ofgenerality represented at the start node of theedge) belong to the same elementary tree.
Notethat this bottom-up interpretation of the deriva-tion trees (propagation) realizes that the findingof larger subtrees is computed only once (thefather-son relation is only interpreted in the up-ward direction).
In Figure 2 the dotted line fromthe NP node in 7 describes the elimination of/3by propagation of the information from the footnode to the root node.Since it doesn't matter in the algorithm whathistory an information in a node has (especiallyhow much and exactly what trees are eliminated)all possibilities of producing new extended nodenumbers - -  representing the new invariant - -  aresimply called elimination.
The information in anode represents what further parts of the sameelementary tree are expected to be found in thetriangle matrix above that node.
A subclassifica-tion differentiates what kinds of incoming edgesshould be compared to find these parts.
One classdescribes whether such a further piece is detected- -  by interpreting incoming and outgoing edgesof the same node (simple elimination).
E.g., thisis the case in the inductive basis of the invariantdefinition.
The second class realizes the elimina-tion of a detected innermost ree, where its footnode pointer ends in that node.
Then the neigh-borhood of the incoming edges in the root node ofthe innermost tree and the outgoing edges in thefoot node (the currently examined node where theinvariant contains the information of the outgoingedges from this node) has to be tested (complexelimination).
By this classification, each neigh-borhood - -  the explicitly represented ones in thetriangle matrix as well as the neighborhoods viae respectively foot node pointer edges - -  is exam-ined exactly once during the algonthm.The fact that a derivation tree again resultsafter an elimination, which is encoded in the tri-angle matrix as well, becomes clear by lookingat the invariant after an elimination.
In the firststep the invariant describes complete subtrees ofelementary trees.
If a complete innermost tree iseliminated by propagating the complete subtreesof elementary trees derived by the foot node tothe root node, this represents the fact that the289root node can derive both trees, but the subtreesbelow the foot node have to be completed.
Thiscan be done again by elimination (in Figure 2 thedotted line from node S represents the computa-tion of a TAG tree after an elimination).Since this is not the place to present he algo-rithm in detail, it is described in informal terms:(tagl) Treatment of the  Empty  StringACCEPT : -  false;i fw  = e then  if e tree 6 Ithen  ACCEPT := true; fi;goto (tagT); fi;From now on, G is interpreted without the etree.
(tag2) Def in i t ion  of  Un ique  Node NumbersV nodes X in ~ 6 (I t9 A) a unique nodenumber NN is defined recursively as follows:?
a has a unique number k all over thegrammar (starting with zero),?
if X is root node NN := k0, for X theleft or only son of the root NN := kl, forX the right son of the root (if existing)NN := k2, and?
for the left or only son of a node withnode number kx (x 6 {1,2} +) NN :=kxl, for the right son of kx NN := kx2.
(tag3) Computat ion of  the Context -F reeKerne l  for  The  TAG (CFK)Each inner node of an elementary tree in Gand its sons are interpreted as a context-freerule where the node number and the con-straints are represented as well.
(tag4) Cocke- Kasami -Younger -  Analys isw i th  CFK  and  wThe slightly extended CKY algorithm is ap-plied to w and CFK.
The result is a trianglematrix if the following holds:i f  w ~L(CFK) then  goto  (tagT)else goto (tagS); fi;(tagS) Computat ion of  the Initial StateAll possible xtended node numbers are com-puted, which means that all auxiliary trees,or respectively all subtrees of elementarytrees, are computed on the triangle matrixand gathered in SAT, the set of  act ivetrees.
(tag6) Iteration on the Elimination and theInitial StateNEWSAT1 and NEWSAT2 are empty setsand COUNT : -  1.
(it0) if an extended node number with treekind TK -- TI 6 \[1,n\] then  ACCEPT:= true and COUNT := n; fi;( it1) i f  COUNT - n then  goto  (tagT); fi;(it2) ?
nodes k with extended node num-ber ENN 6 SAT and tree kind of ENN= TA : propagate the extended nodenumber of the node which the foot nodepointer points at to the root node andadd this information to NEWSAT1;(it3) V nodes k E NEWSAT1 : do all sim-ple and complez eliminations and addthe new extended node numbers toNEWSAT2;(it4) SAT := NEWSAT2; NEWSAT1 andNEWSAT2 := ~, COUNT :=COUNT+I  and goto  (it0).
(tagT) Output  of  the  Resu l tI f  ACCEPT = true then  w E L(G)else w ~ L(G); ft.Figure 3 illustrates the recursion step (tag6) fora single, but arbitrary innermost ree represent-ing an auxiliary tree with the root node numbernuml.for all auxiliary trees in SAT: all extended node numbers (it2).
(nurn l ,~A,F /~r )  in the node FP1 points at:(nurn~,l.A~FP2) (num2,LA or TI or LI,nil)and .
~  or Apropagate these exlanded node numbers to the mot node:New exlended node numbers and all trees with tree kind LA at the root areadded to NEWSATI.case a) a s/n'p/e elirru'nation (it3) for case b) a coml~x elimlnation for(num2,LA.F P2) is de~rbed: (num2,LA,FP2) is deeo'bed:(num4'LA'~FP2) '~  n ~3,LA,nlI)here exists a context-free rule here exists an eliminated tree(nurn,p nurn 2 num3) and below nurn 2 with a foot node pointerthe subtree is cornpiste?
analyzed, (dashed line) to the Iooal rootthis means nurn 4. nurn 2.
I -  nurn3-2 node (num2,LA,FP2)(in this case nurn 4 not equal root).
(it4): Results are added to SAT, all other sels are redefined wlthe.START " End of recurrJon (It0) M1er at most n-1 interations (Itl).Figure 3: Illustration of the step of recursionHere, the question of correctness is not dis-cussed in more detail (see \[Harbusch 89\]).
Itshould be intuitively clear with the correspon-dence between the derivation definition and it'sinterpretation i the recursion step.Actually, the main emphasis lies on the ex-planation of the time complexity (for the formalproof see \[Harbusch 89\]).
A good intuition canbe won by concentrating for a first glance on asingle, but arbitrary TAG derivation tree 6 for w= tz...tn in the triangle matrix after step one.
Itis clear that (i contains at most n-1 adjoinings,because ach TAG tree must produce at least oneterminal.
Therefore the recursion, which finds in-dependent (unnested) adjoinings imultaneously(after elimination of nested adjoinings identifiedin the last recursion step), terminates definitivelyafter n-1 loops.At the beginning, at most O(n 2) innermosttrees can exist in the triangle matrix.
Each ter-290minal can be a leaf in a constant number of ele-mentary trees and with an indegree of O(n-1) inrow 1 of the triangle matrix, the number of oc-curences of elementary trees containing the inputsymbol tl (1 .< i < n) encoded in the invariantafter step one is restricted.Since an elimination is defined along the pathbetween root and foot node of an auxiliary tree,which has at least length 1 (i.e., root and footnode are father and son), the foot node informa-tion is always propagated to a higher row in thetriangle matrix.
The triangle matrix has depthn so that the information of a node in ~f - -  ourexplicitly chosen derivation tree - -  can only bepassed to O(n-1) nodes because each node hasindegree 1 in a derivation tree.
The passing ofinformation (propagation) stands for the elimi-nation of O(n-1) innermost rees along the pathto the root node.
So, the invariant of that node(a constant number of ENNs) can be propagatedto O(n) nodes.
As a result, the number of in-variants at a node increases to O(n).
This mustbe done for all nodes (O(n2)) so that the overallnumber of steps to find a special, but arbitraryTAG derivation tree is O(n3).These suggestions can be used as a basis forfinding all derivation trees in parallel instead of asingle, but arbitrary one, because all intermedi-ate states in the triangle matrix are shared.
Theonly difference is that the indegree of a node can-not be restricted to 1, but to O(n) so that theexponent 3 increases to 4.
The extension "log n"results from storing the foot node pointers, whereaddresses have to be represented instead of num-bers of other cells as in the Vijay-Shanker-Joshiapproach.In other words, an intuition for an upper timebound of the algorithm is that the recursion stepcan be seen as a CKY analysis, because particu-larly neighboring subtrees are combined to builda larger structure, where the constant number ofnonterminals in a cell has to be replaced by O(n)candidates (O(n 3) x n).Another intuition gives a comparison with theVijay.Shanker and Joshi approach.
It is obviousthat our new approach as a different ime boundfor the best and the worst case, because all possi-bilities violating the necessary condition to have acontext-free derivation are filtered out before steptwo is started.
In the Vijay-Shanker and Joshi ap-proach for all context-free subtrees of the trianglematrix, the invariant is computed.
But this factdoesn't modify the upper time bound.
The maindifference lies in the execution time for the twodifferent invariants.
In the Vijay-Shanker.Joshiapproach, all different TAG derivations for a sub-tree are gathered in the stack of a node in a cell.For all these possibilities, the building process oflarger structures is done separately, although thedifferences in the derivation tree doesn't concernthe auxiliary tree actually mentioned.
Our localinvariant always handles an auxiliary tree with nofurther information about the derivation.
There-fore each elimination of an auxiliary tree is doneonce only for all derivation trees.
From this pointof view, the different exponent results from theexistence of O(n 2) stack pointers at each node inthe triangle matrix.For both approaches, the integration of TAGswith Constraints is mentioned in common.
Forthe new approach, this extension is obligatory be-cause the normal form transformation producesa TAGC.
Anyway, this additional computationdoesn't change the upper time bound, becauseconstraints are local and their satisfaction hasonly to be tested iff an innermost ree shouldbe eliminated ( i.e., a stack pointer has to beextended).
In this case it had to be checkedwhether all obligatory constraints in the elimi-nated tree are satisfied and whether the adjoiningwas allowed (by analyzing to which tree the ruleof the incoming edge in the root node belongs andwhat constraint he end point of that edge has).5 SUMMARYIn the application domain of natural languageprocessing, the execution time in an average caseis of great interest as well.
For the new parsingalgorithm, a result is not yet known, but in basicconsiderations the main idea is to take the depthof analyzed parts of derivation trees as a constantterm to come up with a result of O(n3).Actually, an implementation of the presentedformalism exists written in Common LISP ona Hewlett Packard machine of the 9000 series(for more details about the implementation see\[Buschauer t al.
89\]).
To give an idea of the re-sponse time, the analysis of a sentence of about 10to 15 words and a grammar of about 20 to 30 ele-mentary trees takes at most 6 milliseconds.
Cur-rently, this implementation is extended to builda workbench supporting a linguist in writing andtesting large TAG grammars (respectively TAGswith Unification).Finally, other approaches for TAG parsingshould be mentioned and compared with the pre-sented result.
In the literature, the two Ear-leybased approaches of Schabes and Joshi (see\[Schabes, Joshi 89\]) and of Lang (\[Lang 86\]) areproposed.
The lowest upper time bound for theSchabes.Joshi approach is O(n 9) and for the ap-proach of Lang O(n6).
But both algorithms comeup with better results in the best and in the av-erage case.
In the framework of parallel parsing,results for TAGs are also proposed.
In \[Palis etal.
87\] a linear time approach on O(n 5) proces-sors and in \[Palis, Shende 88\] a sublinear (O(log 2n)) algorithm is described.One future perspective is to parallelize thenew approach by the same method so that theexpected result should be a linear time boundon O(n 2) processors.
More concretely, an op-timal layout for two processors is looked for,where independent subtrees have to be specified(candidates are not always total innermost trees,e.g., if only one TAG derivation exists where allinnermost trees are nested).Further on, we concentrate on appropriate x-tensions of the TAG formalism for analysis as wellas generation of natural anguage with the ambi-tious aim to verify that TAGs (in some extension)are appropriate for a bidirectional and integrateddescription of syntax, semantics and pragmatics.291ACKNOWLED GEMENTSThis paper is based on thesis work done undersupervision of Wolfgang Wahlster and GffntherHotz.
I would like to gratefully acknowledge HansArz, Bela Buschauer, G*inther Hotz, Paul Moli-tor, Peter Poller, Anne Schauder and WolfgangWahlster for their valuable interactions.I would like to thank Aravind Joshi for his helpfulcomments in earlier discussions and especially onthis paper.REFERENCESB.
Buschauer, P. Poller, A. Schauder, K. Har-busch.
1989.
Parsing yon TAGs mit Unifikation.Saarbriicken, F.R.G.
: "AI-Laboratory" Memo,Dept.
of Computer Science, Univ.
of Saarland.K.
Harbusch.
1989.
Eziente Strukturanalysenat~irlicher Sprache mit Tree Adjoining Gram.mars.
PhD Thesis, Saarbriicken, F.R.G.
: Dept.of Computer Science, Univ.
of Saarland.J.
E. Hopcroft, J. D. Ullman.
1979.
In.troduction to Automata Theory, Languages, andComputation.
Addison-Wesley, Reading, Mas-sachusetts.A.
K. Joshi.
1985.
An Introduction to Tree Ad-joining Grammars.
Philadelphia, Pennsylvania:Technical Report MS-CIS-86-64, Dept.
of Com-puter and Information Science, Moore School,Univ.
of Pennsylvania.A.
K. Joshi, L. S. Levy, M. Takahashi.
1975.Tree Adjoining Grammars.
Journal of Computerand Systems Science 10:1, Seite 136-163.T.
Kroch, A. K. Joshi.
1985 Linguistic Rel-evance of Tree Adjoining Grammars.
Philadel-phia, Pennsylvania: Technical Report MS-CIS-85-16, Dept.
of Computer and Information Sci-ence, Moore School, Univ.
of Pennsylvania.B.
Lang.
1989 forthcoming.
A Uniform Frame-work for Parsing, Proceedings of the Interna-tional Workshop on Parsing Technologies in Pitts-burgh, 28~h-31 rd of August.G.
Pullum.
1984.
On Two Recent Attempts toShow That English ls Not a CFL.
ComputationalLinguistics 10(4): 182-186.M.
A. Pallis, S. Shende, D. S. L. Wet.
1987.An Optimal Linear-Time Parallel Parser for TreeAdjoining Languages.
Philadelphia, Pennsyl-vania: Technical Report MS-CIS-87-36, Dept.of Computer and Information Science, MooreSchool, Univ.
of Pennsylvania.Y.
Schabes, A. Joshi.
1988.
An Earley-TypeParsing Algorithm for Tree Adjoining Grammars.Philadelphia, Pennsylvania: Technical Rep.MS-CIS-88-36, Dept.
of Computer and InformationScience, Moore School, Univ.
of Pennsylvania.S.
M. Shieber.
1985.
Evidence against theContext.Freeness of Natural Language.
Linguis-tics and Philosophy 8: 333-343.K.
Vijay-Shanker.
1987.
A Study of Tree Ad-joining Grammars.
Philadelphia, Pennsylvania:PhD Thesis, Dept.
of Computer and InformationScience, Moore School, Univ.
of Pennsylvania.K.
Vijay-Shanker, A. K. Joshi.
1985.Some Computational Properties o/ Tree Adjoin-ing Grammars.
Chicago, Illinois: Proceedings ofthe 23 "d Annual Meeting of the Association forComputational Linguistics: 82-93.
