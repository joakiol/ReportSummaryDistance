Towards Interactive Text UnderstandingMarc Dymetman* Aur?lien Max*+ Kenji Yamada*(*) Xerox Research Centre Europe, Grenoble(+) CLIPS-GETA, Universit?
Joseph Fourier, Grenoble{marc.dymetman,aurelien.max,kenji.yamada@xrce.xerox.com}AbstractThis position paper argues for an interactiveapproach to text understanding.
The proposedmodel extends an existing semantics-basedtext authoring system by using the input textas a source of information to assist the user inre-authoring its content.
The approach per-mits a reliable deep semantic analysis bycombining automatic information extractionwith a minimal amount of human interven-tion.1 IntroductionAnswering emails sent to a company by its cus-tomers ?
to take just one example among manysimilar text-processing tasks ?
requires a reli-able understanding of the content of incomingmessages.
This understanding can currently onlybe done by humans, and represents the main bot-tleneck to a complete automation of the process-ing chain: other aspects could be delegated tosuch procedures as database requests and textgeneration.
Current technology in natural lan-guage understanding or in information extractionis not at a stage where the understanding task canbe accomplished reliably without human inter-vention.In this paper, which aims at proposing a freshoutlook on the problem of text understandingrather than at describing a completed implemen-tation, we advocate an interactive approachwhere:1.
The building of the semantic representationis under the control of a human author;2.
In order to build the semantic representa-tion, the author interacts with an intuitive textualinterface to that representation (obtained from itthrough an NLG process), where some ?active?regions of the text are associated with menus thatdisplay a number of semantic choices for incre-menting the representation;3.
The raw input text to be analyzed serves asa source of information to the authoring systemand permits to associate likelihood levels withthe various authoring choices; in each menu thechoices are then ranked according to their likeli-hood, allowing a speedier selection by the au-thor; when the likelihood of a choice exceeds acertain threshold, this choice is performed auto-matically by the system (but in a way that re-mains revisable by the author).4.
The system acts as a flexible understandingaid to the human operator: by tuning the thresh-old at a low level, it can be used as a purelyautomatic, but somewhat unreliable, informationextraction or understanding system; by tuning thethreshold higher, it can be used as a powerfulinteractive guide to building a semantic interpre-tation, with the advantage of a plain textual inter-face to that representation that is easilyaccessible to general users.The paper is organized as follows.
In section2, we present a document authoring system,MDA,  where the author constructs an internalsemantic representation, but interacts with a tex-tual realization of that representation.
In section3, we explain how such a system may be ex-tended into an Interactive Text Understanding(ITU) aid.
A raw input document acts as an in-formation source that serves to rank the choicesproposed to the author according to their likeli-hood of ?accounting?
for information present inthe input document.
In section 4, we present cur-rent work on using MDA for legacy-documentnormalization and show that this work can pro-vide a first approach to an ITU implementation.In section 5, we indicate some links betweenthese ideas and current work on interactive statis-tical MT (TransType), showing directions to-wards more efficient implementations of ITU.2 MDA: A semantics-based document au-thoring systemThe MDA (Multilingual Document Authoring)system [Brun et al2000] is an instance (de-scended from Ranta?s Grammatical Framework[Ranta 2002]) of a text-mediated interactivenatural language generation system, a notion in-troduced by [Power and Scott 1998] under thename of WYSIWYM.
In such systems, an authorgradually constructs a semantic representation,but rather than accessing the evolving representa-tion directly, she actually interacts with a naturallanguage text generated from the representation;some regions of the text are active, and corre-spond to still unspecified parts of the representa-tion; they are associated with menus presentingcollections of choices for extending the semanticrepresentation; the choices are semantically ex-plicit and the resulting representation contains noambiguities.
The author thus has the feeling ofonly interacting with text, while in fact she isbuilding a formal semantic object.
One applica-tion of this approach is in multilingual authoring:the author interacts with a text in her own lan-guage, but the internal representation can be usedto generate reliable translations in other lan-guages.
Fig.
1 gives an overview of the MDAarchitecture and Fig.
2 is a screenshot of theMDA interface.Fig.
1: Authoring in MDA.
A ?semantic grammar?
definesan enumerable collection of well-formed partial semanticstructures, from which an output text containing active re-gions is generated, with which the author interacts.Fig.
2: Snapshot of the MDA system applied to the author-ing of drug leaflets.3 Interactive Text UnderstandingIn the current MDA system, menu choices areordered statically once and for all in the semanticgrammar1.
However, consider the situation of anauthor producing a certain text while using someinput document as an informal reference source.It would be quite natural to assume that the au-thoring system could use this document as asource of information in order to prime some ofthe menu choices.Thus, when authoring the description of a phar-maceutical drug, the presence in the input docu-ment of the words tablet and solution could serveto highlight corresponding choices in the menucorresponding to the pharmaceutical form of thedrug.
This would be relatively simple to do, butone could go further: rank menu choices and as-sign them confidence weights according to tex-tual and contextual hints found in the inputdocument.
When the confidence is sufficientlyhigh, the choice could then be performed auto-matically by the authoring system, which wouldproduce a new portion of the output text, with theauthor retaining the ability of accepting or reject-ing the system?s suggestion.
In case the confi-dence is not high enough, the author?s choicewould still be sped up through displaying themost likely choices on top of the menu list.Fig.
3: Interactive Text Understanding.This kind of functionality is what we call a text-mediated interactive text understanding system,or for short, an ITU system (see Fig.
3).21While the order between choices listed in a menu does notvary, certain choices may be filtered out depending on thecurrent authoring context; this mechanism relies on unifica-tion constraints in the semantic grammar.2Note that we do not demand that the semantic representa-tion built with an ITU system be a complete representationof the input document, rather it can be a structured descrip-tion of some thematic aspects of that document.
Similarly, itis OK for the input document not to contain enough infor-mation permitting the system or even the author to ?answer?certain menus: then some active regions of the output textremain unspecified.We will now consider some directions to im-plement an ITU system.4 From document normalization to ITUA first route towards achieving an ITU system isthrough an extension of ongoing work on docu-ment normalization [Max and Dymetman 2002,Max 2003].
The departure point is the following.Assume an MDA system is available for author-ing a certain type of documents (for instance acertain class of drug leaflets), and suppose one ispresented a ?legacy?
document of the same type,that is, a document containing the same type ofinformation, but produced independently of theMDA system; using the system, a human couldattempt to ?re-author?
the content of the inputlegacy document, thus obtaining a normalizedversion of it, as well as an associated semanticrepresentation.An attempt to automate the re-authoring proc-ess works as follows.
Consider the virtual spaceof semantic representations enumerated by theMDA grammar.
For each such representation,produce, through the standard MDA realizationprocess3 a certain more or less rough ?descriptor?of what the input text should contain if its con-tent should correspond to that semantic represen-tation; then define a similarity measure betweenthis descriptor and the input text; finally performan admissible  heuristic search [Nilsson 1998] ofthe virtual space to find the semantics whose de-scriptor has the best similarity with the input text.This architecture can accomodate more or lesssophisticated descriptors: from bags of content-words to be intersected with the input text, up topredicted ?top-down?
predicate-argument tuplesto be matched with ?bottom-up?
tuples extractedfrom the input text through a rough information-extraction process.Up to now the emphasis of this work has beenmore on automatic reconstruction of a legacydocument than on interaction, but we have re-cently started to think about adapting the ap-proach to ITU.
The heuristic search that wementioned above associates with a menu choicean estimate of the best similarity score that couldbe obtained by some complete semantic structureextending that choice.
It is then possible to rankchoices according to that heuristic estimate (orsome refinement of it obtained by deepening the3Which was initially designed to produce parallel texts inseveral languages, but can be easily adapted to the produc-tion of non-textual ?renderings?
of the semantic representa-tions.search a few steps down the line), and then topropose to the author a re-ranked menu.While we are currently pursuing this promis-ing line of research because of its conceptual andalgorithmic simplicity, it has some weaknesses.It relies on similarity scores between an inputtext and a descriptor that are defined in a some-what ad hoc manner, it depends on parametersthat are fixed a priori rather than by training, andit is difficult to associate with confidence levelshaving a clear interpretation.A way of solving these problems is to movetowards a more probabilistic approach that com-bines advantages of being built on accepted prin-ciples and of having a well-developed learningtheory.
We finally turn our attention to existingwork in this area that holds promise for improv-ing ITU.5 Towards statistical ITURecent research on the interactive statistical ma-chine translation system TransType [Foster et al1997; Foster et al 2002] holds special interest inrelation to ITU.
This system, outlined in Fig.
4,aims at helping a translator type her (uncon-strained) translation of a source text by predict-ing sequences of characters that are likely tofollow already typed characters in the target text;this prediction is done on the basis of informa-tion present in the source text.
The approach issimilar to standard statistical MT4, but instead ofproducing one single best translation, the systemranks several completion proposals according toa probabilistic confidence measure and uses thismeasure to optimize the length of completionsproposed to the translator for validation.
Evalua-tions of the first version of TransType have al-ready shown significant gains in terms of thenumber of keystrokes needed for producing atranslation, and work is continuing for makingthe approach effective in real translation envi-ronments.If we now compare Fig.
3 and Fig.
4, we seestrong parallels between TransType and ITU:language model enumerating word sequences vs4Initially statistical MT used a noisy-channel approach[Brown et al 1993]; but recently [Och and Ney 2002] haveintroduced a more general framework based on the maxi-mum-entropy principle, which shows nice prospects interms of flexibility and learnability.
An interesting researchthread is to use more linguistic structure in a statisticaltranslation model [Yamada and Knight 2001], which hassome relevance to ITU since we need to handle structuredsemantic data.grammar enumerating semantic structures,source text vs input text as information sources,match between source text and target text vsmatch between input text and semantic structure.In TransType the interaction is directly with thetarget text, while in ITU the interaction with thesemantic structure is mediated through an outputtext realization of that structure.
We can thushope to bring some of the techniques developedfor TransType to ITU, but let us note that someof the challenges are different: for instance train-ing the semantic grammars in ITU cannot bedone on a directly observable corpus of texts.5Fig.
4: TransType.6 ConclusionWe have introduced an interactive approach totext understanding, based on an extension to theMDA document authoring system.
ITU at thispoint is more a research program than a com-pleted realization.
However we think it repre-sents an exciting direction towards permitting areliable deep semantic analysis of input docu-ments by complementing automatic information5Let us briefly mention that we are not the first to note for-mal connections between natural language understandingand statistical MT.
Thus, [Epstein 1996], working in a non-interactive framework, draws the following parallel betweenthe two tasks: while in MT, the aim is to produce a targettext from a source text, in NLU, the aim is to produce asemantic representation from an input text.
He then goes onto adapt the conventional noisy channel MT model of[Brown et al1993] to NLU, where extracting a semanticrepresentation from an input text corresponds to finding:argmax(Sem) {p(Input|Sem) p(Sem)}, where p(Sem) is amodel for generating semantic representations, andp(Input|Sem) is a model for the relation between semanticrepresentations and corresponding texts.
See also [Bergerand Lafferty 1999] and [Knight and Marcu 2002] for paral-lels between statistical MT and Information Retrieval andSummarization respectively.
On a different plane, in thecontext of interactive NLG, [Nickerson 2003] has recentlyproposed to rank semantic choices according to probabilitiesestimated from a corpus; but here the purpose is not textunderstanding, but improving the speed of authoring a newdocument from scratch.extraction with a minimal amount of human in-tervention for those aspects of understanding thatpresently resist automation.AcknowledgementsThanks for discussions and advice to C. Boitet,C.
Brun, E. Fanchon, E. Gaussier, P. Isabelle, G.Lapalme, V. Lux and S. Pogodalla.References[Berger and Lafferty 1999] Information Retrieval asStatistical Translation, SIGIR-99[Brown, Della Pietra, Della Pietra and Mercer 1993]The Mathematics of Statistical Machine Transla-tion: Parameter Estimation.
Computational Linguis-tics 19(2), 1993[Brun, Dymetman and Lux 2000].
Document Struc-ture and Multilingual Text Authoring, INLG-2000[Epstein 1996] Statistical Source Channel Models forNatural Language Understanding, PhD Thesis, NewYork University, 1996.
[Foster, Isabelle and Plamondon, 1997] Target-TextMediated Interactive Machine Translation, MachineTranslation, 12:1-2, 175-194, Dordrecht, Kluwer,1997.
[Foster, Langlais and Lapalme, 2002] User-FriendlyText Prediction for Translators, EMNLP-02[Knight and Marcu 2002] Summarization beyondsentence extraction: A Probabilistic Approach toSentence Compression, Artificial Intelligence,139(1), 2002.
[Max and Dymetman 2002] Document ContentAnalysis through Fuzzy Inverted Generation, inAAAI 2002 Spring Symposium on Using (and Ac-quiring) Linguistic (and World) Knowledge for In-formation Access, 2002[Max 2003].
Reversing Controlled Document Author-ing to Normalize Documents.
In the proceedings ofthe EACL-03 Student Research Workshop, 2003[Nickerson 2003].
Statistical Models for OrganizingSemantic Options in Knowledge Editing Interfaces.In AAAI Spring Symposium workshop on naturallanguage generation in spoken and written dialogue,2003.
[Nilsson 1998] Artificial Intelligence: a New Synthe-sis.
Morgan Kaufmann, 1998.
[Och and Ney 2002] Discriminative Training andMaximum Entropy Models for Statistical MachineTranslation, ACL02[Power and Scott 1998] Multilingual Authoring usingFeedback Texts.
COLING/ACL-98.
[Ranta 2002] Grammatical Framework: A Type-Theoretical Grammar Formalism, Journal of Func-tional Programming, September 2002.
[Yamada and Knight 2001] A Syntax-based Transla-tion Model, ACL-01.
