Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing (EMNLP 2006), pages 449?456,Sydney, July 2006. c?2006 Association for Computational LinguisticsRelevance Feedback Models for RecommendationMasao UtiyamaNational Institute of Information and Communications Technology3-5 Hikari-dai, Soraku-gun, Kyoto 619-0289 Japanmutiyama@nict.go.jpMikio YamamotoUniversity of Tsukuba, 1-1-1 Tennodai, Tsukuba, 305-8573 Japanmyama@cs.tsukuba.ac.jpAbstractWe extended language modeling ap-proaches in information retrieval (IR) tocombine collaborative filtering (CF) andcontent-based filtering (CBF).
Our ap-proach is based on the analogy betweenIR and CF, especially between CF and rel-evance feedback (RF).
Both CF and RFexploit users?
preference/relevance judg-ments to recommend items.
We first in-troduce a multinomial model that com-bines CF and CBF in a language modelingframework.
We then generalize the modelto another multinomial model that approx-imates the Polya distribution.
This gener-alized model outperforms the multinomialmodel by 3.4% for CBF and 17.4% forCF in recommending English Wikipediaarticles.
The performance of the gener-alized model for three different datasetswas comparable to that of a state-of-the-art item-based CF method.1 IntroductionRecommender systems (Resnick and Varian,1997) help users select particular items (e.g,movies, books, music, and TV programs) thatmatch their taste from a large number of choicesby providing recommendations.
The systems ei-ther recommend a set of N items that will be ofinterest to users (top-N recommendation problem)or predict the degree of users?
preference for items(prediction problem).For those systems to work, they first have toaggregate users?
evaluations of items explicitly orimplicitly.
Users may explicitly evaluate certainmovies as rating five stars to express their prefer-ence.
These evaluations are used by the systemsas explicit ratings (votes) of items or the systemsinfer the evaluations of items from the behavior ofusers and use these inferred evaluations as implicitratings.
For example, systems can infer that usersmay like certain items if the systems learn whichbooks they buy, which articles they read, or whichTV programs they watch.Collaborative filtering (CF) (Resnick et al,1994; Breese et al, 1998) and content-based (oradaptive) filtering (CBF) (Allan, 1996; Schapireet al, 1998) are two of the most popular typesof algorithms used in recommender systems.
ACF system makes recommendations to current(active) users by exploiting their ratings in thedatabase.
User-based CF (Resnick et al, 1994;Herlocker et al, 1999) and item-based CF (Sarwaret al, 2001; Karypis, 2001), among other CF algo-rithms, have been studied extensively.
User-basedCF first identifies a set of users (neighbors) thatare similar to the active user in terms of their rat-ing patterns in the database.
It then uses the neigh-bors?
rating patterns to produce recommendationsfor the active user.
On the other hand, item-basedCF calculates the similarity between items before-hand and then recommends items that are similarto those preferred by the active user.
The perfor-mance of item-based CF has been shown to becomparable to or better than that of user-based CF(Sarwar et al, 2001; Karypis, 2001).
In contrastto CF, CBF uses the contents (e.g., texts, genres,authors, images, and audio) of items to make rec-ommendations for the active user.
Because CFand CBF are complementary, much work has beendone to combine them (Basu et al, 1998; Yu etal., 2003; Si and Jin, 2004; Basilico and Hofmann,2004).The approach we took in this study is designedto solve top-N recommendation problems with im-449plicit ratings by using an item-based combinationof CF and CBF.
The methods described in thispaper will be applied to recommending EnglishWikipedia1 articles based on those articles editedby active users.
(This is discussed in Section 3.
)We use their editing histories and the contents oftheir articles to make top-N recommendations.
Weregard users?
editing histories as implicit ratings.That is, if users have edited articles, we considerthat they have positive attitudes toward the arti-cles.
Those implicit ratings are regarded as pos-itive examples.
We do not have negative examplesfor learning their negative attitudes toward arti-cles.
Consequently, handling our application withstandard machine learning algorithms that requireboth positive and negative examples for classifica-tion (e.g., support vector machines) is awkward.Our approach is based on the advancement inlanguage modeling approaches to information re-trieval (IR) (Croft and Lafferty, 2003) and extendsthese to incorporate CF.
The motivation behind ourapproach is the analogy between CF and IR, espe-cially between CF and relevance feedback (RF).Both CF and RF recommend items based on userpreference/relevance judgments.
Indeed, RF tech-niques have been applied to CBF, or adaptive fil-tering, successfully (Allan, 1996; Schapire et al,1998).
Thus, it is likely that RF can also be appliedto CF.To apply RF, we first extend the representationof items to combine CF and CBF under the modelsdeveloped in Section 2.
In Section 3, we reportour experiments with the models.
Future work andconclusion are in Sections 4 and 5.2 Relevance feedback modelsThe analogy between IR and CF that will be ex-ploited in this paper is as follows.2 First, a docu-ment in IR corresponds to an item in CF.
Both arerepresented as vectors.
A document is representedas a vector of words (bag-of-words) and an itemis represented as a vector of user ratings (bag-of-user ratings).
In RF, a user specifies documentsthat are relevant to his information need.
Thesedocuments are used by the system to retrieve new1http://en.wikipedia.org/wiki/Main Page2The analogy between IR and CF has been recognized.For example, Breese et al (1998) used the vector spacemodel to measure the similarity between users in a user-basedCF framework.
Wang et al (2005) used a language modelingapproach different from ours.
These works, however, treatedonly CF.
In contrast with these, our model extends languagemodeling approaches to incorporate both CF and CBF.relevant documents.
In CF, an active user (implic-itly) specifies items that he likes.
These items areused to search new items that will be preferred bythe active user.We use relevance models (Lavrenko and Croft,2001; Lavrenko, 2004) as the basic frameworkof our relevance feedback models because (1)they perform relevance feedback well (Lavrenko,2004) and (2) they can simultaneously handle dif-ferent kinds of features (e.g., different languagetexts (Lavrenko et al, 2002), such as texts and im-ages (Leon et al, 2003).
These two points are es-sential in our application.We first introduce a multinomial model follow-ing the work of Lavrenko (2004).
This model isa novel one that extends relevance feedback ap-proaches to incorporate CF.
It is like a combina-tion of relevance feedback (Lavrenko, 2004) andcross-language information retrieval (Lavrenko etal., 2002).
We then generalize that model to an ap-proximated Polya distribution model that is bettersuited to CF and CBF.
This generalized model isthe main technical contribution of this work.2.1 PreparationLavrenko (2004) adopts the method of kernels toestimate probabilities: Let d be an item in thedatabase or training data, the probability of item xis estimated as p(x) = 1M?d p(x|?d), where Mis the number of items in the training data, ?d is theparameter vector estimated from d, and p(x|?d) isthe conditional probability of x given ?d.3 Thismeans that once we have defined a probability dis-tribution p(x|?)
and the method of estimating ?dfrom d, then we can assign probability p(x) to xand apply language modeling approaches to CFand CBF.To begin with, we define the representationof item x as the concatenation of two vectors{wx,ux}, where wx = wx1wx2 .
.
.
is the se-quence of words (contents) contained in x andux = ux1ux2 .
.
.
is the sequence of users whohave rated x implicitly.
We use Vw and Vu to de-note the set of words and users in the database.The parameter vector ?
is also the concatenationof two vectors {?, ?
}, where ?
and ?
are the pa-rameter vectors for Vw and Vu, respectively.
Theprobability of x given ?
is defined as p(x|?)
=p?(wx|?)p?(ux|?
).3Item d in summation ?d and word w in?w and?wgo over every distinct item d and word w in the training data,unless otherwise stated.4502.2 Multinomial modelOur first model regards that both p?
and p?
followmultinomial distributions.
In this case, ?
(w) and?
(u) are the probabilities of word w and user u.Then, p?(wx|?)
is defined asp?(wx|?)
=|wx|?i=1?
(wxi) =?w?Vw?
(w)n(w,wx)(1)where n(w,wx) is the number of occurrences of win wx.
In this model, we use a linear interpolationmethod to estimate probability ?d(w).
?d(w) = ?
?Pl(w|wd) + (1?
??
)Pg(w) (2)where Pl(w|wd) = n(w,wd)?w?
n(w?,wd), Pg(w) =?d n(w,wd)?d?w?
n(w?,wd)and ??
(0 ?
??
?
1) isa smoothing parameter.
The estimation of userprobabilities goes similarly: Let n(u,ux) be thenumber of times user u implicitly rated item x,we define or estimate p?, ??
and ?d in the sameway.
In summary, we have defined a probabilitydistribution p(x|?)
and the method of estimating?d = {?d, ?d} from d.To recommend top-N items, we have to rankitems in the database in response to the implicitratings of active users.
We call those implicit rat-ings query q.
It is a set of items and is representedas q = {q1 .
.
.qk}, where qi is an item implic-itly rated by an active user and k is the size of q.We next estimate ?q = {?q, ?q}.
Then, we com-pare ?q and ?d to rank items by using Kullback-Leibler divergence D(?q||?d) (Lafferty and Zhai,2001; Lavrenko, 2004).
?q(w) can be approximated as?q(w) = 1kk?i=1?qi(w) (3)where ?qi(w) is obtained by Eq.
2 (Lavrenko,2004).
However, we found in preliminary experi-ments that smoothing query probabilities hurt per-formance in our application.
Thus, we use?qi(w) = Pl(w|wqi) =n(w,wqi)?w?
n(w?,wqi)(4)instead of Eq.
2 when qi is in a query.Because KL-divergence is a distance measure,we use a score function derived from ?D(?q||?d)to rank items.
We use Sq(d) to denote the scoreof d given q. Sq(d) is derived as follows.
(Weignore terms that are irrelevant to ranking items.
)?D(?q||?d) = ?D(?q||?d)?D(?q||?d)?D(?q||?d) rank= 1kk?i=1S(?qi ||?d) (5)whereS(?qi ||?d) =?wPl(w|wqi)?log(??Pl(w|wd)(1?
??
)Pg(w) + 1).
(6)The summation goes over every word w thatis shared by both wqi and wd.
We defineS(?qi ||?d) similarly.4 Then, the score of d givenqi, Sqi(d) is defined asSqi(d) = ?sS(?qi ||?d) + (1?
?s)S(?qi ||?d)(7)where ?s (0 ?
?s ?
1) is a free parameter.
Fi-nally, the score of d given q isSq(d) = 1kk?i=1Sqi(d).
(8)The calculation of Sq(d) can be very efficientbecause once we cache Sqi(d) for each item pairof qi and d in the database, we can reuse it to cal-culate Sq(d) for any query q.
We further optimizethe calculation of top-N recommendations by stor-ing only the top 100 items (neighbors) in decreas-ing order of Sqi(?)
for each item qi and settingthe scores of lower ranked items as 0.
(Note thatSqi(d) >= 0 holds.)
Consequently, we only haveto search small part of the search space withoutaffecting the performance very much.
These twotypes of optimization are common in item-basedCF (Sarwar et al, 2001; Karypis, 2001).2.3 Polya modelOur second model is based on the Polya distribu-tion.
We first introduce (hyper) parameter ?
={?
?, ??}
and denote the probability of x given?
as p(x|?)
= p?(wx|??)p?(ux|??).
??
and??
are the parameter vectors for words and users.p?(wx|??)
is defined as follows.p?(wx|??)
= ?
(?w ??w)?
(?w nxw + ??w)?w?
(nxw + ??w)?(?
?w)(9)4S(?qi ||?d) =?u Pl(u|uqi) ?log(??Pl(u|ud)(1???
)Pg(u) + 1), where Pl(u|uqi) =n(u,?qi )?u?
n(u?,?qi ), Pl(u|ud) = n(u,ud)?u?
n(u?,ud), andPg(u) =?d n(u,ud)?d?u?
n(u?,ud).4510123456789100 2 4 6 8 10012345678910nu(n,alpha)nalpha=1e+5alpha=38.8alpha=16.4alpha=9.0alpha=5.4alpha=3.3alpha=2.0alpha=1.1alpha=0.4alpha=1e-5Figure 1: Relationship between original count nand dumped count ?
(n, ?
)where ?
is known as the gamma function, ?
?w is aparameter for word w and nxw = n(w,wx).
Thiscan be approximated as follows (Minka, 2003).p?(wx|??)
??w?(w)n?
(w,wx) (10)wheren?
(w,wx) = ??w(?
(nxw + ??w)??(??w))?
?
(nxw, ?
?w) (11)?
is known as the digamma function and is sim-ilar to the natural logarithm.
We call Eq.
10 theapproximated Polya model or simply the Polyamodel in this paper.Eq.
10 indicates that the Polya distributioncan be interpreted as a multinomial distributionover a modified set of counts n?(?)
(Minka, 2003).These modified counts are dumped as shown inFig.
1.
When ?
?w ?
?, ?
(nxw, ?
?w) approachesnxw.
When ?
?w ?
0, ?
(nxw, ?
?w) = 0 if nxw = 0otherwise it is 1.
For intermediate values of ?
?w,the mapping ?
dumps the original counts.Under the approximation of Eq.
10, the es-timation of parameters can be understood as themaximum-likelihood estimate of a multinomialdistribution from dumped counts n?(?)
(Minka,2003).
Indeed, all we have to do to estimate theparameters for ranking items is replace Pl and Pgfrom Section 2.2 with Pl(w|wd) = n?(w,wd)?w?
n?
(w?,wd),Pg(w) =?d n?(w,wd)?d?w?
n?
(w?,wd), and Pl(w|wqi) =n?
(w,wqi )?w?
n?
(w?,wqi ).
Then, as in the multinomial model,we can define S(?qi ||?d) with these probabilities.This argument also applies to S(?qi ||?d).The approximated Polya model is a generaliza-tion of the multinomial model described in Sec-tion 2.2.
If we set ?
?w and ?
?u very large then thePolya model is identical to the multinomial model.By comparing Eqs.
1 and 10, we can see why thePolya model is superior to the multinomial modelfor modeling the occurrences of words (and users).In the multinomial model, if a word with probabil-ity p occurs twice, its probability becomes p2.
Inthe Polya model, the word?s probability becomesp1.5, for example, if we set ?
?w = 1.
Clearly,p2 < p1.5; therefore, the Polya model assignshigher probability.
In this example, the Polyamodel assigns probability p to the first occurrenceand p0.5(> p) to the second.
Since words that oc-cur once are likely to occur again (Church, 2000),the Polya model is better suited to model the oc-currences of words and users.
See Yamamoto andSadamitsu (2005) for further discussion on apply-ing the Polya distribution to text modeling.Zaragoza et al(2003) applied the Polya distri-bution to ad hoc IR.
They introduced the exactPolya distribution (see Eq.
9) as an extensionto the Dirichlet prior method (Zhai and Lafferty,2001).
However, we have introduced a multino-mial approximation of the Polya distribution.
Thisapproximation allows us to use the linear interpo-lation method to mix the approximated Polya dis-tributions.
Thus, our model is similar to two-stagelanguage models (Zhai and Lafferty, 2002) thatcombine the Dirichlet prior method and the lin-ear interpolation method.
In contrast to our model,Zaragoza et al(2003) had difficulty in mixing thePolya distributions and did not treat that in theirpaper.3 ExperimentsWe first examined the behavior of the Polya modelby varying the parameters.
We tied ?
?w for everyw and ?
?u for every u; for any w and u, ?
?w = ?
?and ?
?u = ??.
We then compared the Polya modelto an item-based CF method.3.1 Behavior of Polya model3.1.1 DatasetWe made a dataset of articles from EnglishWikipedia5 to evaluate the Polya model.
EnglishWikipedia is an online encyclopedia that anyone5We downloaded 20050713 pages full.xml.gzand 20050713 pages current.xml.gz fromhttp://download.wikimedia.org/wikipedia/en/.452can edit, and it has many registered users.
Ouraim is to recommend a set of articles to each userthat is likely to be of interest to that user.
If wecan successfully recommend interesting articles,this could be very useful to a wide audience be-cause Wikipedia is very popular.
In addition, be-cause wikis are popular media for sharing knowl-edge, developing effective recommender systemsfor wikis is important.In our Wikipedia dataset, each item (article) xconsisted of wx and ux.
ux was the sequence ofusers who had edited x.
If users had edited x mul-tiple times, then those users occurred in ux multi-ple times.
wx was the sequence of words that weretypical in x.
To make wx, we removed stop wordsand stemmed the remaining words with a Porterstemmer.
Next, we identified 100 typical wordsin each article and extracted only those words(|wx| ?
100 because some of them occurredmultiple times).
Typicality was measured usingthe log-likelihood ratio test (Dunning, 1993).
Weneeded to reduce the number of words to speed upour recommender system.To make our dataset, we first extracted 302,606articles, which had more than 100 tokens after thestop words were removed.
We then selected typi-cal words in each article.
The implicit rating datawere obtained from the histories of users editingthese articles.
Each rating consisted of {user, ar-ticle, number of edits}.
The size of this originalrating data was 3,325,746.
From this data, we ex-tracted a dense subset that consisted of users andarticles included in at least 25 units of the originaldata.
We discarded the users who had edited morethan 999 articles because they were often softwarerobots or system operators, not casual users.
Theresulting 430,096 ratings consisted of 4,193 usersand 9,726 articles.
Each user rated (edited) 103articles on average (the median was 57).
The av-erage number of ratings per item was 44 and themedian was 36.3.1.2 Evaluation of Polya modelWe conducted a four-fold cross validation ofthis rating dataset to evaluate the Polya model.
Weused three-fourth of the dataset to train the modeland one-fourth to test it.6 All users who existed in6We needed to estimate probabilities of users and words.We used only training data to estimate the probabilities ofusers.
However, we used all 9,726 articles to estimate theprobabilities of words because the articles are usually avail-able even when editing histories of users are not.both training and test data were used for evalua-tion.
For each user, we regarded the articles in thetraining data that had been edited by the user as aquery and ranked articles in response to it.
Theseranked top-N articles were then compared to thearticles in the test data that were edited by thesame user to measure the precisions for the user.We used P@N (precision at rank N = the ratio ofthe articles edited by the user in the top-N articles),S@N (success at rank N = 1 if some top-N articleswere edited by the user, else 0), and R-precision (=P@N, where N is the number of articles edited bythe user in the test data).
These measures for eachuser were averaged over all users to get the meanprecision of each measure.
Then, these mean pre-cisions were averaged over the cross validation re-peats.Here, we report the averaged mean pre-cisions with standard deviations.
We firstreport how R-precision varied depend-ing on ?
(??
or ??).
?
was varied over10?5, 0.4, 1.1, 2, 3.3, 5.4, 9, 16.4, 38.8, and 105.The values of ?
(10, ?)
were approximately 1, 2,3, 4, 5, 6, 7, 8, 9, and 10, respectively, as shownin Fig.
1.
When ?
= 105, the Polya modelrepresents the multinomial model as discussed inSection 2.3.
For each value of ?, we varied ?
(?
?or ??)
over 0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6,0.7, 0.8, 0.9, 0.95, and 0.99 to obtain the optimumR-precision.
These optimum R-precisions areshown in Fig.
2.
In this figure, CBF and CFrepresent the R-precisions for the content-basedand collaborative filtering part of the Polya model.The values of CBF and CF were obtained bysetting ?s = 0 and ?s = 1 in Eq.
7 (whichis applied to the Polya model instead of themultinomial model), respectively.
The error barsrepresent standard deviations.At once, we noticed that CBF outperformedCF.
This is reasonable because the contents ofWikipedia articles should strongly reflect the users(authors) interest.
In addition, each article hadabout 100 typical words, and this was richer thanthe average number of users per article (44).
Thisobservation contrasts with other work where CBFperformed poorly compared with CF, e.g., (Ali andvan Stam, 2004).Another important observation is that bothcurves in Fig.
2 are concave.
The best R-precisions were obtained at intermediate values of?
for both CF and CBF as shown in Table 1.4530.0650.070.0750.080.0850.090.0951 2 3 4 5 6 7 8 9 10R-precisionnu(10,alpha)CBFCFFigure 2: R-precision for Polya modelTable 1: Improvement in R-precision (RP)best RP (?(?)/?)
RP (?(?)/?)
%changeCBF 0.091 (7/9.0) 0.088 (10/105) +3.4%CF 0.081 (2/0.4) 0.069 (10/105) +17.4%When ?
= 105 or ?
(10, ?)
?
10, the Polyamodel represents the multinomial model as dis-cussed in Section 2.3.
Thus, Fig.
2 and Table 1show that the best R-precisions achieved by thePolya model were better than those obtained bythe multinomial model.
The improvement was3.4% for CBF and 17.4% for CF as shown in Ta-ble 1.
The improvement of CF was larger thanthat of CBF.
This implies that the occurrences ofusers are more clustered than those of words.
Inother words, the degree of repetition in the editinghistories of users is greater than that in word se-quences.
A user who edits an article are likely toedit the article again.From Fig.
2 and Table 1, we concluded that thegeneralization of a multinomial model achieved bythe Polya model is effective in improving recom-mendation performance.3.1.3 Combination of CBF and CFNext, we show how the combination of CBFand CF improves recommendation performance.We set ?
(??
and ??)
to the optimum values inTable 1 and varied ?
(?s, ??
and ??)
to obtain theR-precisions for CBF+CF, CBF and CF in Fig.
3.The values of CBF were obtained as follows.
Wefirst set ?s = 0 in Eq.
7 to use only CBF scoresand then varied ?
?, which is the smoothing pa-rameter for word probabilities, in Eq.
2.
To getthe values of CF, we set ?s = 1 in Eq.
7 and thenvaried ?
?, which is the smoothing parameter foruser probabilities.
The values of CBF+CF wereobtained by varying ?s in Eq.
7 while setting ?
?and ??
to the optimum values obtained from CBF0.0550.060.0650.070.0750.080.0850.090.0950.10 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1R-precisionlambdaCBF+CFCBFCFFigure 3: Combination of CBF and CF.Table 2: Precision and Success at top-NCBF+CF CBF CFN P@N S@N P@N S@N P@N S@N5 0.166 0.470 0.149 0.444 0.137 0.40810 0.135 0.585 0.123 0.562 0.112 0.51615 0.117 0.650 0.107 0.628 0.098 0.58220 0.105 0.694 0.096 0.671 0.089 0.627R-precision 0.099 0.091 0.081optimum ?
?s = 0.2 ??
= 0.01 ??
= 0.2and CF (see Table 2).
These parameters (?s, ?
?and ??)
were defined in the context of the multi-nomial model in Section 2.2 and used similarly inthe Polya model in this experiment.We can see that the combination was quite ef-fective as CBF+CF outperformed both CBF andCF.
Table 2 shows R-precision, P@N and S@Nfor N = 5, 10, 15, 20.
These values were obtainedby using the optimum values of ?
in Fig.
3.Table 2 shows the same tendency as Fig.
3.
Forall values of N , CBF+CF outperformed both CBFand CF.
We attribute this effectiveness of the com-bination to the feature independence of CBF andCF.
CBF used words as features and CF used userratings as features.
They are very different kindsof features and thus can provide complementaryinformation.
Consequently, CBF+CF can exploitthe benefits of both methods.
We need to do fur-ther work to confirm this conjecture.3.2 Comparison with a baseline methodWe compared the Polya model to an implementa-tion of a state-of-the-art item-based CF method,CProb (Karypis, 2001).
CProb has been testedwith various datasets and found to be effective intop-N recommendation problems.
CProb has alsobeen used in recent work as a baseline method(Ziegler et al, 2005; Wang et al, 2005).In addition to the Wikipedia dataset, we usedtwo other datasets for comparison.
The first was454R-precision P@10WP ML BX WP ML BXPolya-CF 0.081 0.272 0.066 0.112 0.384 0.054CProb 0.082 0.258 0.071 0.113 0.373 0.057%change -1.2% +5.4% -7.0% -0.9% +2.9% -5.3%Table 3: Comparison of Polya-CF and CProbthe 1 million MovieLens dataset.7 This data con-sists of 1,000,209 ratings of 3,706 movies by 6,040users.
Each user rated an average of 166 movies(the median was 96).
The average number of rat-ings per movie was 270 and the median was 124.The second was the BookCrossing dataset (Ziegleret al, 2005).
This data consists of 1,149,780 rat-ings of 340,532 books by 105,283 users.
Fromthis data, we removed books rated by less than 20users.
We also removed users who rated less than5 books.
The resulting 296,471 ratings consistedof 10,345 users and 5,943 books.
Each user rated29 books on average (the median was 10).
The av-erage number of ratings per book was 50 and themedian was 33.
Note that in our experiments, weregarded the ratings of these two datasets as im-plicit ratings.
We regarded the number of occur-rence of each rating as one.We conducted a four-fold cross validation foreach dataset to compare CProb and Polya-CF,which is the collaborative filtering part of thePolya model as described in the previous section.For each cross validation repeat, we tuned the pa-rameters of CProb and Polya-CF on the test data toget the optimum R-precisions, in order to comparebest results for these models.8 P@N and S@Nwere calculated with the same parameters.
Thesemeasures were averaged as described above.
R-precision and P@10 are in Table 3.
The max-imum standard deviation of these measures was0.001.
We omitted reporting other measures be-cause they had similar tendencies.
In Table 3, WP,ML and BX represent the Wikipedia, MovieLens,and BookCrossing datasets.In Table 3, we can see that the variation of per-formance among datasets was greater than that be-tween Polya-CF and CProb.
Both methods per-7http://www.grouplens.org/8CProb has two free parameters.
Polya-CF also has twofree parameters (??
and ??).
However, for MovieLens andBookCrossing datasets, Polya-CF has only one free parame-ter ?
?, because we regarded the number of occurrence of eachrating as one, which means ?
(1, ??)
= 1 for all ??
> 0 (SeeFig.
1).
Consequently, we don?t have to tune ??.
Since thenumber of free parameters is small, the comparison of perfor-mance shown in Table 3 is likely to be reproduced when wetune the parameters on separate development data instead oftest data.formed best against ML.
We think that this is be-cause ML had the densest ratings.
The averagenumber of ratings per item was 270 for ML whilethat for WP was 44 and that for BX was 50.Table 3 also shows that Polya-CF outperformedCProb when the dataset was ML and CProb wasbetter than Polya-CF in the other cases.
However,the differences in precision were small.
Overall,we can say that the performance of Polya-CF iscomparable to that of CProb.An important advantage of the Polya modelover CProb is that the Polya model can unify CBFand CF in a single language modeling frameworkwhile CProb handles only CF.
Another advantageof the Polya model is that we can expect to im-prove its performance by incorporating techniquesdeveloped in IR because the Polya model is basedon language modeling approaches in IR.4 Future workWe want to investigate two areas in our futurework.
One is the parameter estimation and theother is the refinement of the query model.We tuned the parameters of the Polya model byexhaustively searching the parameter space guidedby R-precision.
We actually tried to learn ?
?and ??
from the training data by using an EMmethod (Minka, 2003; Yamamoto and Sadamitsu,2005).
However, the estimated parameters wereabout 0.05, too small for better recommendations.We need further study to understand the relationbetween the probabilistic quality (perplexity) ofthe Polya model and its recommendation quality.We approximate the query model as Eq.
3.
Thisallows us to optimize score calculation consider-ably.
However, this does not consider the interac-tion among items, which may deteriorate the qual-ity of probability estimation.
We want to inves-tigate more efficient query models in our futurework.5 ConclusionRecommender systems help users select particularitems from a large number of choices by provid-ing recommendations.
Much work has been doneto combine content-based filtering (CBF) and col-laborative filtering (CF) to provide better recom-mendations.
The contributions reported in this pa-per are twofold: (1) we extended relevance feed-back approaches to incorporate CF and (2) we in-troduced the approximated Polya model as a gen-455eralization of the multinomial model and showedthat it is better suited to CF and CBF.
The perfor-mance of the Polya model is comparable to that ofa state-of-the-art item-based CF method.Our work shows that language modeling ap-proaches in information retrieval can be extendedto CF.
This implies that a large amount of workin the field of IR could be imported into CF.
Thiswould be interesting to investigate in future work.ReferencesKamal Ali and Wijnand van Stam.
2004.
TiVo: Mak-ing show recommendations using a distributed col-laborative filtering architecture.
In KDD?04.James Allan.
1996.
Incremental relevance feedbackfor information filtering.
In SIGIR?96.Justin Basilico and Thomas Hofmann.
2004.
Uni-fying collaborative and content-based filtering.
InICML?04.Chumki Basu, Haym Hirsh, and William Cohen.
1998.Recommendation as classification: Using social andcontent-based information in recommendation.
InAAAI-98.John S. Breese, David Heckerman, and Carl Kadie.1998.
Empirical analysis of predictive algorithmsfor collaborative filtering.
Technical report, MSR-TR-98-12.Kenneth W. Church.
2000.
Empirical estimates ofadaptation: The chance of two Noriegas is closer top/2 than p2.
In COLING-2000, pages 180?186.W.
Bruce Croft and John Lafferty, editors.
2003.
Lan-guage Modeling for Information Retrieval.
KluwerAcademic Publishers.Ted Dunning.
1993.
Accurate methods for the statis-tics of surprise and coincidence.
ComputationalLinguistics, 19(1):61?74.Jonathan L. Herlocker, Joseph A. Konstan,Al Borchers, and John Riedl.
1999.
An algo-rithmic framework for performing collaborativefiltering.
In SIGIR?99, pages 230?237.George Karypis.
2001.
Evaluation of item-based top-N recommendation algorithms.
In CIKM?01.John Lafferty and ChengXiang Zhai.
2001.
Documentlanguage models, query models and risk minimiza-tion for information retrieval.
In SIGIR?01.Victor Lavrenko and W. Bruce Croft.
2001.Relevance-based language models.
In SIGIR?01.Victor Lavrenko, Martin Choquette, and W. BruceCroft.
2002.
Cross-lingual relevance models.
InSIGIR?02, pages 175?182.Victor Lavrenko.
2004.
A Generative Theory of Rele-vance.
Ph.D. thesis, University of Massachusetts.J.
Leon, V. Lavrenko, and R. Manmatha.
2003.
Au-tomatic image annotation and retrieval using cross-media relevance models.
In SIGIR?03.Thomas P. Minka.
2003.
Es-timating a Dirichlet distribution.http://research.microsoft.com/?minka/papers/dirichlet/.Paul Resnick and Hal R. Varian.
1997.
Recommendersystems.
Communications of the ACM, 40(3):56?58.Paul Resnick, Neophytos Iacovou, Mitesh Suchak, Pe-ter Bergstrom, and John Riedl.
1994.
GroupLens:An open architecture for collaborative filtering ofnetnews.
In CSCW?94, pages 175?186.Badrul Sarwar, George Karypis, Joseph Konstan, andJohn Riedl.
2001.
Item-based collaborative filteringrecommendation algorithms.
In WWW10.Robert E. Schapire, Yoram Singer, and Amit Singhal.1998.
Boosting and Rocchio applied to text filtering.In SIGIR?98, pages 215?223.Luo Si and Rong Jin.
2004.
Unified filtering by com-bining collaborative filtering and content-based fil-tering via mixture model and exponential model.
InCIKM-04, pages 156?157.Jun Wang, Marcel J.T.
Reinders, Reginald L. La-gendijk, and Johan Pouwelse.
2005.
Self-organizing distributed collaborative filtering.
In SI-GIR?05, pages 659?660.Mikio Yamamoto and Kugatsu Sadamitsu.
2005.Dirichlet mixtures in text modeling.
Technical re-port, University of Tsukuba, CS-TR-05-1.Kai Yu, Anton Schwaighofer, Volker Tresp, Wei-YingMa, and HongJiang Zhang.
2003.
Collaborativeensemble learning: Combining collaborative andcontent-based information filtering via hierarchicalBayes.
In UAI-2003.Hugo Zaragoza, Djoerd Hiemstra, and Michael Tip-ping.
2003.
Bayesian extension to the languagemodel for ad hoc information retrieval.
In SIGIR?03.ChengXiang Zhai and John Lafferty.
2001.
A study ofsmoothing methods for language models applied toad hoc information retrieval.
In SIGIR?01.ChengXiang Zhai and John Lafferty.
2002.
Two-stagelanguage models for information retrieval.
In SI-GIR?02, pages 49?56.Cai-Nicolas Ziegler, Sean M. McNee, Joseph A. Kon-stan, and Georg Lausen.
2005.
Improving rec-ommendation lists through topic diversification.
InWWW?05, pages 22?32.456
