Context Sensing using Speech and Common SenseNathan Eagle20 Ames St., Cambridge, MA 02139nathan@media.mit.eduPush Singh20 Ames St., Cambridge, MA 02139push@media.mit.eduAbstractWe present a method of inferring aspects of aperson?s context by capturing conversationtopics and using prior knowledge of humanbehavior.
This paper claims that topic-spottingperformance can be improved by using a largedatabase of common sense knowledge.
Wedescribe two systems we built to infer contextfrom noisy transcriptions of spoken conversa-tions using common sense, and detail somepreliminary results.
The GISTER system usesOMCSNet, a commonsense semantic net-work, to infer the most likely topics under dis-cussion in a conversation stream.
TheOVERHEAR system is built on top ofGISTER, and distinguishes between aspectsof the conversation that refer to past, present,and future events by using LifeNet, a prob-abilistic graphical model of human behavior,to help infer the events that occurred in eachof those three time periods.
We conclude bydiscussing some of the future directions wemay take this work.122.1IntroductionCan we build computers that infer a speaker's context bysummarizing the conversation's gist?
Once computersare able to capture the gist of a conversation, an enor-mous number of potential applications become possible.However, current topic-spotting methods have met withlittle success in characterizing spontaneous conversa-tions involving hundreds of potential topics (Jebara etal., 2000).
This paper claims that performance can begreatly improved by making use of not only the text of aspeech transcription, but also perceptual and common-sensical information from the dialogue.We have enabled a suite of wearable computers withthe ability to provide the perceptual information neces-sary for a human to infer a conversation's gist and pre-dict subsequent events.
To take the human fully out ofthe loop we have infused the system with two common-sense knowledge bases that enable the computer tomake educated inferences about the user's context.ImplementationOur system incorporated a Zaurus Linux handheld com-puter, with an 802.11b CF card and a wireless Bluetoothheadset microphone.
Applications were written to en-able the Zaurus to stream high quality audio (22 kHz,16-bit) to an available 802.11b network, or to store theaudio locally when no network is detected.
Besidesstreaming audio, packets in this wireless network couldbe ?sniffed?
by the PDAs interested in determining whoelse is in the local proximity.
Information regardingaccess point signal strength information was correlatedwith location using a static table look-up procedure.
Thesystem is typically kept in a participant's pocket, or forthose with Bluetooth headsets, stored in a briefcase,purse, or backpack.Audio Processing and TranscriptionViaVoice, a commercial speech recognition engine, isused to transcribe the audio streams, however typicallyword recognition rates fall below 35% for spontaneousspeech recognition (Eagle & Pentland, 2002).
This inac-curacy poses a serious problem for determining the gistof an interaction.
However, a human can read through anoisy transcript and with adequate perceptual cues, stillhave an impression of the underlying conversationtopic.Speaker 1: you do as good each key in and tellon that this this printers?
rarely broken key fixedon and off-fixes and the new nine-month Londondeal on and then now take paper out and keeplooking cartridges and then see if we confinesomething of saw someone to fix it but see Sad-dam out of the system think even do about it hadtools on is there a persona for the minister whatwill come paper response to use the paper is notreally going to stay in the printer for very muchlonger high is Chinese college and shreddedwhere inks that inks is really know where thesounds like a Swiss have to have played by earthanSpeaker 2: a can what can do that now I thinkthis this seems to work on which side is workingare inSpeaker 1: an hour riderless I E fix the currenttrend the Stratton practice page of the test cas-ings to of printed nicely I think jacking years agothat is paid toes like a printed NeisseAdditional context, such as information that the con-versation is occurring in an office, or more precisely, bya printer, may help many people understand that theconversation is about fixing a printer jam.
Prior knowl-edge about the conversation participants and the time ofday may also significantly augment a person?s ability toinfer the gist of the interaction, for example, one of thespeakers could be a printer repairman.
Our work sug-gests that the additional contextual and commonsensicalinformation a human can employ for inference on thetranscript above is equally helpful to a probabilisticmodel.As will be shown, this additional contextual andcommonsense information can be used to form prob-abilistic models relating observed keywords to conver-sation topic.
Thus by combining audio and informationfrom a mobile device with a commonsense knowledgenetwork, we can determine the gist of noisy, face-to-face conversations.
In the above example, for instance,our system correctly labeled the conversation as ?print-ing on printer?.33.1GISTERGISTER is a system that infers the most likely topicsunder discussion in a conversation stream by using acommonsense semantic network called OMCSNet.More details about the GISTER system are available in(Eagle et al, 2003) but we summarize its operation inthis section.OMCSNetWe built the OMCSNet commonsense semantic net-work (Liu & Singh, 2004) by aggregating and normaliz-ing the contributions from nearly 14,000 people fromacross the web (Singh et al, 2002).
Its semantic net-work structure resembles that of WordNet (Fellbaum,1998) but its content is motivated by the range ofknowledge in commonsense knowledge bases such asCyc (Lenat, 1995).
As in WordNet, the nodes ofOMCSNet are natural language terms and the links aredrawn from a fixed ontology of semantic relationships.But as in Cyc, the nodes include not just single words,but also compound expressions such as ?at the zoo?, ?eata sandwich?
or ?fix a printer?, and the links are drawnfrom a broader range of semantic relationships than areavailable in WordNet; OMCSNet goes beyond simple?is-a?
and ?part-of?
relations to include spatial, temporal,causal, affect, and other types of relations.
At presentOMCSNet employs the 20 binary semantic relationsshown below in Table 1.Relation Type Semantic RelationThings KindOf, HasProperty, PartOf,MadeOfEvents SubEventOf, FirstSubeventOf,LastSubeventOf, HappensAfterActions Requires, HasEffect, ResultsIn-Want, HasAbilitySpatial OftenNear, LocationOfGoals DoesWant, DoesNotWant,MotivatedByFunctions UsedInLocation, HasFunctionGeneric ConceptuallyRelatedToTable 1.
Semantic relations currently in OMCSNetPrior research in text summarization has recognized theneed for general world knowledge?in SUMMARIST(1997), Hovy & Lin describe how the words ?gun?,?mask?, ?money?, ?caught?, and ?stole?
together wouldindicate the topic of ?robbery?, but they note that thatWordNet and other dictionary-like resources did notcontain enough such knowledge.
However, OMCSNetcontains precisely this type of knowledge.
It contains awide variety of knowledge about many aspects of eve-ryday life: typical objects and their properties, the ef-fects of ordinary actions, the kinds of things people likeand dislike, the structure of typical activities and events,and many other things.
A small excerpt of OMCSNet isshow in Figure 1 below.HAS USEprinterprint on printerload inpaperprinter will jamHAS LOCATIONHAS MOTIVATION HAS REQUIREMENTHAS CONSEQUENCEhard copy ofdocumentconfigure printerHAS FIRST STEPputting ink on paperHAS EFFECTtype ofcomputerhardwareIS ApaperHAS WANTofficeFigure 1.
A selection of OMCSNet?s 250,000 relationsOMCSNet has been used in a variety of applications todate (Lieberman et al, 2004).3.2 GISTER infers fine-grained topicsThe purpose of the GISTER system is to infer the ?finegrained topic?, or gist, of a conversation.
A gist is theclass of event that most accurately summarizes the cur-rent subject of the conversation.
For example:?
Buying a ticket to a baseball game?
Looking for a restaurant?
Scheduling a meeting?
Canceling a meetingThese gists are represented within OMCSNet as thenodes of the semantic network containing simple verbphrases.
For our set of target gists, we use the 700 mostrichly defined verb phrase nodes within OMCSNet(those for which at least 10 facts are asserted.
)GISTER infers gists using a two step process.
First,the transcriptions are preprocessed to reduce the noiseof the speech recognition engine.
To do this the tran-scriptions are lemmatized and filtered for stop words(such as ?like?, ?the?, ?a?, etc.
), and a filtering process isperformed using a clustering metric to reduce the num-ber of weakly connected words.
These outliers, wordswith very sparse links to the rest of the transcription, areremoved from the data set.Second, the OMCSNet network is flattened into abipartite network that incorporates all ties from words inthe OMCSNet lexicon to gists.
The probability of a spe-cific gist can be modeled as proportional to the gist?slinks to the selected words:1( )ii GiiikP g kkGistScore k===?where  is the number of links between a gist, ik ig , andthe observed transcript, and G is the number of potentialgists (approximately 700).
This simple method is oftencapable of identifying a small group of potential gists,frequently with one dominating the others.Once the probable topics of conversation have beenidentified and ranked, contextual information about theconversation is incorporated into the model.
In manyinstances, information such as location or participantidentity can identify the gist from the small subsectionof topics.
In our initial tests we incremented a gist?sscore for each of its links to a keyword related to thegiven context.3.3 ExperimentsWe ran a series of experiments on a testing set of 20speech segments ranging from 50 to 150 words andtaken from a single individual on a wide range of topics.No prior knowledge about the participant was assumed,but the 802.11b networks were used to give generallocations such as office and cafeteria when appropriate.In one test we captured conversations from the studentcenter cafeteria ?
streaming data to an access pointmapped as ?restaurant?.
Using this contextual informa-tion to condition the model, our results significantlyimproved:Transcription:Store going to stop and listen to type of its cellu-lar and fries he backed a bill in the one everyoneget a guess but that some of the past like a saladbar and some offense militias cambers the sitefast food them and the styrofoam large chickennuggets son is a pretty pleased even guess I aslong as can?t you don?t have to wait too long itscomplicity sunrise against NAFTA pact if forlunchSelected Keywords:wait type store stop salad past lunch long longlisten large fry food fast chicken cellular bill bigbar backTop Ten Scores:Without Location Context With Location Context5 talk with someonefar away27 eat in fast food res-taurant5 buy beer 21 eat in restaurant5 Eat in restaurant 18 wait on table5 eat in fast foodrestaurant16 you would go torestaurant becauseyou5 buy hamburger 16 wait table4 go to hairdresser 16 go to restaurant4 wait in line15 know how much youowe restaurant4 howl with laughter 12 store food for peopleto purchase4 eat healthily11 sitting down whileplace order at bar4 play harp 11 cook foodTable 2.
Results of using Context for Gist Differentia-tionActual Situation:Deciding what to get for lunch while standing inline at the cafeteria.4 OVERHEARThe OVERHEAR system is a newer system, built ontop of GISTER, and distinguishes between aspects ofthe conversation that refer to past, present, and futureevents.
The system relies on LifeNet, a probabilisticgraphical model of human behavior, to infer the eventsoccurring in each of those three time periods.We have two reasons for trying to distinguish be-tween past, present, and future events.
First, using addi-tional sensory context (such as addition informationabout the speakers?
location) to bias the results of gistsensing only works when the conversation is referring tothe present context.
Often, people?s conversations re-ferred to things that happened in the past, or things theywere planning to do in the future, and in those casessensory context only hurt GISTER?s performance.However, one could imagine making use of recorded,time-stamped sensory data to bias the gisting of conver-sations that were talking about events that happenedearlier.The structure of LifeNet is represented by a Markovnetwork whose structure resembles a Dynamic BayesianNetwork (DBN).
Although lacking the 'explaining away'power of true Bayesian inference, the model is not con-strained to directed acyclic graphs.
LifeNet is designedto support the same kinds of temporal inferences as aDBN, including predicting future states and guessingprior states from the current state.LifeNet was built as a probabilistic graphical modelbecause stochastic methods can be more tolerant thantraditional logical reasoning methods to the uncertaintyin our knowledge of the situation, as well as to the un-certainty in the reliability of the rules themselves.
Addi-tionally these methods have efficient and well-knowninference procedures for generating approximate solu-tions.Second, our long term goal is to use context sensingfrom speech to build new types of context-aware appli-cations for wearable computers and other mobile de-vices.
An application that knew that the speaker wasreferring to past events could perform tasks like retrievedocuments and e-mails that referred to those pastevents.
However, if the speaker was referring to thecurrent situation, the application could know to makeuse of sensory information to improve its understandingof the current context.
And if the speaker was referringto potential future events, like ?going to a movie thisweekend?, the application could assist the user by mak-ing plans to help make those events happen (or not hap-pen, as the case may be), for instance by offering topurchase movie tickets on-line.Our early experiments reasoning with LifeNet treatit as Markov network, an undirected graphical modelwhere the nodes represent random variables and theedges joint probability constraints relating those vari-ables.
We convert LifeNet into a series of joint prob-abilities (the details of this process are described laterthis paper), and we reason with the resulting networkusing local belief updating techniques.
We engage in?loopy?
belief propagation as described by Pearl (Pearl,1988).
Belief propagation in a Markov network isstraightforward.
We use the following belief updatingrules, as described in (Yedidia et al, 2000):( )\( ) ( , ) ( ) ( )ij i ij i j i i ki ix k N iim x x x x m x?
?
???
?
?j(1) 4.1 LifeNetLifeNet is a probabilistic graphical model that capturesa first-person model of human experience.
It relates80,000 ?egocentric?
propositions with 415,000 temporaland atemporal links between these propositions, asshown in Figure 2.
More details about how the LifeNetmodel is generated are given in (Singh & Williams,2003).
(2)( )( ) ( ) ( )i i i i ki ik N ib x x m x????
?In these rules ix represents the random variable atnode i .
The current belief in node i is denoted by ib , thelocal evidence for node i by i?
and the joint probabilityof a pair of linked nodes andi j by ij?
.
The messagesent from node i to j is denoted by m .
ij ( )N i  is the setof all neighbors of node , and i ( ) \N i j represents theset of all neighbors of node i except for node j .
is anormalization constant.
?I switch TV onI watch televisionI watch evening newsI put child to bedI turn out the lightAn armchair is hereA television is hereI flip a switchA television stand is hereBefore AfterThese simple updating rules run fairly quickly evenon a knowledge base as large as LifeNet.
In our opti-mized Common Lisp implementation, on a 1.8 GHzPentium 4 with 512 MB ram, a single iteration of beliefupdating runs in 15 seconds.
Inference is further sped upby restricting the belief updating to run only on nodeswithin a fixed distance from the evidence nodes.
Givena single evidence node and using only those nodeswithin a depth of three edges away, a single iteration ofbelief updating runs in as little as 0.5 seconds for somenodes; on average it takes about 3 seconds.4.2 Model Integration and ImplementationFigure 2.
A sample of LifeNet GISTER leverages the commonsense facts withinOMCSNet to generate discrete conceptual topics from agiven transcript segmented into twenty-word-longobservations, with each twenty-word observationindependent from the others.
We extended GISTER toinfer the average tense of the text within the observationby detecting verb tenses, auxiliary verbs like did andwill, and also specific temporal expressions likeyesterday and tomorrow.
LifeNet then allows us tocalculate the transition probabilites to a given specificpropositional representation based on previous states.By using the independent output of GISTER as inputinto LifeNet, we are able to improve the inferences of auser's context which subsequently can be used totraining data for improved models of human behavior.As shown in Figure 3, by using the output of GISTERfor inference in LifeNet, additional insight can begained about the user's situation.
If the output fromGISTER is 'eating sushi' and was assigned a past tense,while 'going to the doctor' was assigned a future tense,LifeNet can make educated inferences about whathappened to the user.
This inference can be fed backinto the lower level of the model by weighting wordslike 'sick, full, tired', and rerunning the semanticfiltering technique.
By incorporating this feedback intothe system, the filtering technique would be much lesslikely to exclude words related to being sick despitethem being initally filtered from the transcript.
If thegister's output changes, the process continues until thetwo systems converge on a solution.We propose a variation to the Markov networkimplementation of LifeNet described in section 4.1.Noisy transcript and signal data is still used as initialinput into the system; GISTER then processes this data,semantically filters the speech, and calculates the likelysubjects of conversation and their tenses.
Highly rankedoutput from GISTER is then used as temporalobservations for inference on the LifeNet model, asshown in Figure 3.
These observations are linked tospecific nodes within LifeNet that correspond to thegiven tense (past, present, future).
We used multipleroot nodes with weights proportional to the rankgenerated from the gister.
This belief weighting systemaccounts for the uncertainty of the gister's output whilestarting with multiple roots enables much richerinference.4.3 Preliminary ResultsThe system was initially tested on an office worker'sconversation regarding how she had eaten too much theday before and that she will have to go to the doctor'soffice during the next day.
The following transcriptswere input into GISTER:PAST: had sushi for lunch could then havethought so he and then so yesterday's the sushi Iits while I was at the Senate Committee lunch ittasted good sign yet was expenses over a cost me$7 to buy six roles and they lead to much of its inthe rules were not a very good and I ate toomany roles half so after words about six hourslater I wasn't feeling very well of this so moreMatsushita I never bought some sugar beforeusually advised chicken sandwich usual andnormal food there I thought that this issue wouldbe a good deal I also bought some seltzer waterwas so worked well and silenceOMCSNetPast Present FutureGisterLifeNetuggg.. ate a ton of sushi last night...think i'm going to have to see a doctor tomorrow...I eat sushi.I go to the doctor's office.I feel sick.IFUTURE: of debt reduction appointment tomor-row they can see mental tomorrow to clock willmeet Dr. Smith and he's going to put my stomachbecause of what I a yesterday bomb I'm hopingthat when I'll feel better so looking forward togoingIn this experience an overall tense was assigned to eachpassage.
GISTER correctly inferred that the firstpassage referred to past events and the second to futureevents, and output potential topics of the conversationfor each of those time periods:Figure 3.
The OVERHEAR SystemPast Present Futureeat luncheathave lunchget in shapeget jobget fiteat breakfastcook dinnertaste somethingsweetlose weightfallhave examinationeat cookiego for runhave physical exameat lunchgo on vacationgive assistancetake walkwalkTable 3.
Potential Topics Separated by TenseThe topics generated by GISTER in Table 3 weresubsquently used as observational inputs to the nextsection of the model.
These topics were mapped to thepast and future nodes within LifeNet, marked as 'true',and then we ran the loopy belief propogation algorithmdescribed earlier.
The solution converged on nodesrepresenting the present state, in-between the first tier(past) and the third tier (future).
The nodes deemed mostlikely by the system are listed in Table 4 below.Inferences on Present Situation0.999 I stop being hungry0.999 I warm feeling0.982 I satisfy hunger0.964 I make appointment0.962 I have energy0.957 I schedule appointment with doctor0.956 I feel worryTable 4.
Inferences about Present Situation given Pastand Future4.45Training Future Models of Human BehaviorWhen this system is deployed on many users over anextended period of time, information about people'sbehavior can begin to influence the initial priors fromLifeNet.
Although it has not been determined how addi-tional links could be made, this represents an alternativemethod for increasing the common sense knowledgestored within LifeNet.
Additionally, extensive observa-tions on the same people could augment the originalcommonsense model by better reflecting an individual?sbehavior.ConclusionsCombining common sense with speech and other typesof sensory context presents abundant opportunitieswithin a wide range of fields, from artificial intelligenceand ubiquitous computing to traditional social science.By integrating two common sense knowledge bases, wehave developed a method for inferring human behaviorfrom noisy transcripts and sensor data.
As mobilephones and PDAs become ever more embedded in soci-ety, the additional contextual information they providewill become invaluable for a variety of applications.This paper has shown the potential for these devices toleverage this additional information to begin under-standing informal face-to-face conversations and infer-ring a user's context.AcknowledgementsThe authors would like to thank to Hugo Liu for hiswork developing OMCSNet and Sandy Pentland.ReferencesNathan Eagle and Alex Pentland.
2002.
InformationExplication from Computer-Transcribed Conversa-tions.
MIT Media Lab Vision and Modeling Techni-cal Report.Nathan Eagle, Push Singh, and Alex Pentland.
2003.Common sense conversations: understanding casualconversation using a common sense database.
Pro-ceedings of the Artificial Intelligence, InformationAccess, and Mobile Computing Workshop (IJCAI2003).
Acapulco, Mexico.Christiane Fellbaum (Ed.)
1998.
WordNet: An elec-tronic lexical database.
MIT Press.Eduard Hovy and Chin-Yew Lin.
1997.
Automated textsummarization in SUMMARIST.
In ACL/EACL-97Workshop on Intelligent Scalable Text Summariza-tion.
Madrid, Spain.Douglas Lenat.
1995.
CYC: A large-scale investment inknowledge infrastructure.
Communications of theACM, 38(11).Henry Lieberman, Hugo Liu, Push Singh, and BarbaraBarry.
2004.
Beating Some Common Sense into In-teractive Applications.
In submission.
Draft availableathttp://web.media.mit.edu/~lieber/Publications/Beating-Common-Sense.pdf.Hugo Liu and Push Singh (2004).
OMCSNet: A com-monsense inference toolkit.
MIT Media Lab Techni-cal Report SOM03-01.
Available at: http://web.media.mit.edu/~push/OMCSNet.pdfTony Jebara, Yuri Ivanov, Ali Rahimi, and Alex Pent-land.
2000.
Tracking Conversational Context for Ma-chine Mediation of Human Discourse.
Proceedingsof AAAI Fall Symposium on Socially IntelligentAgents.
North Falmouth, MA.Judea Pearl.
1988.
Probabilistic reasoning in intelligentsystems: networks of plausible inference.
San Mateo,CA: Morgan Kaufman.Push Singh, Thomas Lin,  Erik T. Mueller, GraceLim, Travell Perkins and Wan Li Zhu.
2002.
OpenMind Common Sense: Knowledge acquisition fromthe general public.
Proceedings of ODBASE?02.
Ir-vine, CA.Push Singh and William Williams.
2003.
LifeNet: apropositional model of ordinary human activity.
Pro-ceedings of the Workshop on Distributed and Col-laborative Knowledge Capture (DC-KCAP) at K-CAP 2003.
Sanibel Island, Florida.Jonathan Yedidia, William Freeman, and Yair Weiss.2000.
Generalized belief propagation.
Advances inNeural Information Processing Systems (NIPS), 13,689-695.
