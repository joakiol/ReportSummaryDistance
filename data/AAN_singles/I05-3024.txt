Data-driven Language Independent Word Segmentation UsingCharacter-Level InformationDong-Hee Lim, Seung-Shik KangSchool of Computer Science, Kookmin Univerity861-1 Chongnung-dong, Songbuk-gu, Seoul 136-702, Korea{nlp, HTUsskang}@cs.kookmin.ac.krUTHAbstractThis paper presents a data-driven languageindependent word segmentation system thathas been trained for Chinese corpus at thesecond Chinese word segmentation bakeoff.The system consists of a base segmentationalgorithm and the refining procedures forthe undecided character sequences.
It doesnot use any lexicon and the basesegmentation is simply done by characterbigram and HMM-model is applied for theremaining character sequences.
As a finalstep, high-frequency character trigrammodifies the error-prone parts of the text.T1T1 IntroductionWe participated in the closed track of the secondChinese word segmentation bakeoff for thetraining corpus of HK (City University of HongKong, PK (Beijing University), and MS(Microsoft Research).
Our system is independentof the corpus or the language that we alsoregistered for AS (Academia Sinica) track, butfailed to generate a result because of the code setproblem.
AS uses two-byte space charactersinstead of a blank(0x20), and more 0x0A is usedin AS that is regarded as EOF in Windowsenvironment.The result of our system is not a top-levelsystem when compared to other systems.However, our approach is quite acceptablebecause the data-driven methods can contributeto improving the accuracy of other wordsegmentation systems because we did notperformed a tuning the system to fix thefrequently repeating error patterns.This work was supported by the Korea Science andEngineering Foundation(KOSEF) through AdvanedInformation Technology Research Center(AITrc).2 Bigram and trigram dataWe extracted a character bigram data from thetraining corpus.
In the previous studies,Shim(1996) and Kang(2001) constructed spacegeneration probability for each adjacent twocharacters XY.
They are inside probability?X_Y?, left-side probability ?_XY?, andright-side probability ?XY_?.T 2 T That is, theyignored ?space information?.
In our bigram data,inside and outside space information is extractedfrom the training corpus, together with thecharacter pairs.
We call it ?extended bigram data?and it has eight types of frequency data.
Forexample, XY consists of the frequencies of?0X0Y0?, ?0X0Y1?, ?0X1Y0?, ?0X1Y1?,?1X0Y0?, ?1X0Y1?, ?1X1Y0?, and ?1X1Y1?.T3TFrom the frequencies of the extended bigram data,we compute the space generation probability ofPt=000(CiCi+1) and left/right/inside probabilitiesare also computed from the extended bigramdata.Pt=000(CiCi+1) = Ft=000(CiCi+1) / ?1110001)Ft(CiCittExtended bigram data is more sophisticated thanthe basic bigram data that the accuracy is betterthan that of the basic bigram data.3 Segmentation algorithm3.1 Base AlgorithmThe base segmentation algorithm is a HMMmodel together with the space-insertionprobability.
HMM model chooses theT2T Lee(2002) used bigram and trigram data for HMMmodel which requires a more memory space.T3T ?0?
is a non-space tag and ?1?
is a space tag.158segmentation with the higheset probability.Given a sentence of n characters, S = c1c2...cn, hasa segmentation of m words, then segmentationprobability is estimated as P(T,S) = P(t1,n, c1,n)??
nii iiiii ttcctp0 121 ),|( .
Our starting pointof the word segmentation was the high precisionratio for the Korean language.
We first tried tosimply applying the extended bigram data withan appropriate threshold.
However, it is supposedthat there is a limitation of this approach becauseof the low recall ratio.
It caused an adoption ofHMM model together with the extended bigramdata.
Table 1 shows the results of HMM withextended bigram data.Table 1.
Results of HMM with extended bigramTestingdata Recall Precision F-measureHK 0.924 0.921 0.923PK 0.902 0.919 0.910MS 0.942 0.939 0.9403.2 Postprocessing by trigram dataExtended bigram data in Section 2 consists of 2adjacent characters and 3 space information(2C3S).
In contrast, we may extract trigram datathat is constructed by 3 characters and 2 spaceinformation(3C2S).
This 3C2S trigram data has aform of ?X0Y0Z?, ?X0Y1Z?, ?X1Y0Z?, and?X1Y1Z?.
That is 3 character sequence XYZ has4 frequency data.
We supposed that ?there arefrequent 3-character sequences that are biased toone of the spacing pattern?.We verified this supposition by improving theaccuracy of the word segmentation result.
Table2 shows the final result of the postprocessing.Postprocessing by trigram data got an increase ofboth recall and precision.
When compared to thebase segmentation results of Table 1, F-measuresare increased by 0.3%, 0.4%, and 0.8%,respectively.As an improvement of the system performance,character trigram data has been extracted fromthe training corpus.Table 2.
Final segmentation resultsT4TTestingdata Recall Precision F-measureHK 0.926 0.925 0.926PK 0.904 0.925 0.914MS 0.947 0.949 0.9484 Pure data-driven method withoutusing HMMOnly after submitting the results for bakeoff 2005,we noticed that the accuracy of HMM model islow.
It is not clear what the problem is and thereis a possibility of the implementation error.
So,we looked for a pure data-driven method withoutusing HMM model.
The first step in the basesegmentation is to apply extended bigram withno space information.
In this step, only the spaceswith high confidence are fixed and others aremarked as ?undecided?.T 5 T  In the second step,extended bigram with space information isapplied.
Two more postprocessing modules areadded for refinements.
One of them is to adoptthe word-length feature by using the fact thataverage length of Chinese word is 1.6 characters.The other is to construct ?error dictionary?
for thetraining data.
Error dictionary is constructed byrunning training data and comparing thedifferences.
The context information of errordictionary is four characters (left two and righttwo characters).
The new approach got a betterresult than that of the final result of bakeoff 2005as shown in Table 3.Table 3.
Pure data-driven method without HMMTestngdata Recall Precision F-measureHK 0.933 0.921 0.927PK 0.912 0.929 0.920MS 0.952 0.953 0.952T4T The final results in Table 2 are a bit higher than thebakeoff 2005 results.
F-measures of bakeoff 2005results are 0.921, 0.912, and 0.947, respectively.
Thereason was not identified.
Table 1 and Table 2 arecomputed by the evaluation program ?score.txt?
in thewebsite of SIGHAN bakeoff 2005.T5T If space generation probability is higher than 0.7,space is inserted.
With less than 0.3, space is notinserted, and ?undecided?
mark for the range0.3~0.7,1595 ConclusionWe presented our word segmentation method forthe closed track of bakeoff 2005.
Our approach isdata-driven and language independent.
That is,our method is purely statistical method that nolanguage dependent features are applied fortuning or improving the accuracy.
Wordsegmentation system for bakeoff 2005 appliedHMM model together with extended bigram andtrigram data.
The results show that wordsegmentation problem can be solved with nolexicons or language-dependent resources.One of the good point of our approach is thatdata-driven language independent approach isquite acceptable for the word segmentationproblem.
We also expect that our data-drivenmethod would be a good solution for theenhancement of word segmentation systems as apostprocessing module.ReferencesChen, A., Chinese Word Segmentation UsingMinimal Linguistic Knowledge, SIGHAN2003, pp.148-151, 2003.Gao, J., M. Li, and C.N.
Huang, ImprovedSource-Channel Models for Chinese WordSegmentation, ACL 2003.Kang, S. S. and C. W. Woo, AutomaticSegmentation of Words using Syllable BigramStatistics, Proceedings of NLPRS'2001,pp.729-732, 2001.Lee D. G, S. Z. Lee, ???GH.
C. Rim, H. S. Lim,Automatic Word Spacing Using HiddenMarkov Model for Refining Korean TextCorpora, Proc.
of the 3rd Workshop on AsianLanguage Resources and InternationalStandardization, pp.51-57, 2002.Maosong, S., S. Dayang, and B. K. Tsou,Chinese Word Segmentation without UsingLexicon and Hand-crafted Training Data,Proceedings of the 17PthP InternationalConference on Computational Linguistics(Coling?98), pp.1265-1271, 1998.Asahara, M., C. L. Go, X. Wang, and Y.Matsumoto, Combining Segmenter andChunker for Chinese Word Segmentation,Proceedings of the 2PndP SIGHAN Workshop onChinese Language Processing, pp144-147,2003.Nakagawa, T., Chinese and Japanese WordSegmentation Using Word-Level andCharacter-Level Information, COLING?04.,pp.466-472, 2004.Ng, H.T.
and J.K. Low, Chinese Part-of-SpeechTagging: One-at-a-Time or All-at-Once?Word-Based or Character-Based, EMNLP?04.Shim, K. S., Automated Word-Segmentation forKorean using Mutual Information of Syllables,Journal of KISS: Software and Applications,pp.991-1000, 1996.Sproat, R. and T. Emerson, The FirstInternational Chinese Word SegmentationBakeoff, SIGHAN 2003.160
