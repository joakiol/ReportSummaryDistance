Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 291?301,Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational LinguisticsTransfer Learning for Constituency-Based GrammarsYuan Zhang, Regina BarzilayMassachusetts Institute of Technology{yuanzh, regina}@csail.mit.eduAmir GlobersonThe Hebrew Universitygamir@cs.huji.ac.ilAbstractIn this paper, we consider the problemof cross-formalism transfer in parsing.We are interested in parsing constituency-based grammars such as HPSG and CCGusing a small amount of data specific forthe target formalism, and a large quan-tity of coarse CFG annotations from thePenn Treebank.
While all of the targetformalisms share a similar basic syntacticstructure with Penn Treebank CFG, theyalso encode additional constraints and se-mantic features.
To handle this appar-ent discrepancy, we design a probabilisticmodel that jointly generates CFG and tar-get formalism parses.
The model includesfeatures of both parses, allowing trans-fer between the formalisms, while pre-serving parsing efficiency.
We evaluateour approach on three constituency-basedgrammars ?
CCG, HPSG, and LFG, aug-mented with the Penn Treebank-1.
Our ex-periments show that across all three for-malisms, the target parsers significantlybenefit from the coarse annotations.11 IntroductionOver the last several decades, linguists have in-troduced many different grammars for describingthe syntax of natural languages.
Moreover, theongoing process of developing new formalisms isintrinsic to linguistic research.
However, beforethese grammars can be used for statistical pars-ing, they require annotated sentences for training.The difficulty of obtaining such annotations is akey limiting factor that inhibits the effective use ofthese grammars.1The source code for the work is available athttp://groups.csail.mit.edu/rbg/code/grammar/acl2013.The standard solution to this bottleneck has re-lied on manually crafted transformation rules thatmap readily available syntactic annotations (e.g,the Penn Treebank) to the desired formalism.
De-signing these transformation rules is a major un-dertaking which requires multiple correction cy-cles and a deep understanding of the underlyinggrammar formalisms.
In addition, designing theserules frequently requires external resources suchas Wordnet, and even involves correction of theexisting treebank.
This effort has to be repeatedfor each new grammar formalism, each new anno-tation scheme and each new language.In this paper, we propose an alternative ap-proach for parsing constituency-based grammars.Instead of using manually-crafted transformationrules, this approach relies on a small amount ofannotations in the target formalism.
Frequently,such annotations are available in linguistic textsthat introduce the formalism.
For instance, atextbook on HPSG (Pollard and Sag, 1994) il-lustrates grammatical constructions using about600 examples.
While these examples are infor-mative, they are not sufficient for training.
Tocompensate for the annotation sparsity, our ap-proach utilizes coarsely annotated data readilyavailable in large quantities.
A natural candidatefor such coarse annotations is context-free gram-mar (CFG) from the Penn Treebank, while thetarget formalism can be any constituency-basedgrammars, such as Combinatory Categorial Gram-mar (CCG) (Steedman, 2001), Lexical FunctionalGrammar (LFG) (Bresnan, 1982) or Head-DrivenPhrase Structure Grammar (HPSG) (Pollard andSag, 1994).
All of these formalisms share a sim-ilar basic syntactic structure with Penn TreebankCFG.
However, the target formalisms also encodeadditional constraints and semantic features.
Forinstance, Penn Treebank annotations do not makean explicit distinction between complement andadjunct, while all the above grammars mark these291roles explicitly.
Moreover, even the identical syn-tactic information is encoded differently in theseformalisms.
An example of this phenomenon isthe marking of subject.
In LFG, this informa-tion is captured in the mapping equation, namely?
SBJ =?, while Penn Treebank represents it asa functional tag, such as NP-SBJ.
Figure 1 showsderivations in the three target formalisms we con-sider, as well as a CFG derivation.
We can see thatthe derivations of these formalisms share the samebasic structure, while the formalism-specific infor-mation is mainly encoded in the lexical entries andnode labels.To enable effective transfer the model has toidentify shared structural components betweenthe formalisms despite the apparent differences.Moreover, we do not assume parallel annotations.To this end, our model jointly parses the two cor-pora according to the corresponding annotations,enabling transfer via parameter sharing.
In partic-ular, we augment each target tree node with hiddenvariables that capture the connection to the coarseannotations.
Specifically, each node in the targettree has two labels: an entry which is specific tothe target formalism, and a latent label containinga value from the Penn Treebank tagset, such as NP(see Figure 2).
This design enables us to repre-sent three types of features: the target formalism-specific features, the coarse formalism features,and features that connect the two.
This model-ing approach makes it possible to perform transferto a range of target formalisms, without manuallydrafting formalism-specific rules.We evaluate our approach on threeconstituency-based grammars ?
CCG, HPSG,and LFG.
As a source of coarse annotations,we use the Penn Treebank.2 Our results clearlydemonstrate that for all three formalisms, pars-ing accuracy can be improved by training withadditional coarse annotations.
For instance, themodel trained on 500 HPSG sentences achieveslabeled dependency F-score of 72.3%.
Adding15,000 Penn Treebank sentences during trainingleads to 78.5% labeled dependency F-score, anabsolute improvement of 6.2%.
To achieve similarperformance in the absence of coarse annotations,the parser has to be trained on about 1,500sentences, namely three times what is neededwhen using coarse annotations.
Similar results are2While the Penn Treebank-2 contains richer annotations,we decided to use the Penn Treebank-1 to demonstrate thefeasibility of transfer from coarse annotations.CFG CCGLFGI                eat               apples NP                VB                   NPVPSI                eat                apples NP        (S[dcl]\NP)/NP         NPS[dcl]\NPS[dcl]I               eat                 apples [Pron.I]     [   SBJ,   OBJ]       [N.3pl]ROOT ?=??
?=?SBJ!?
=?OBJ!??=?
HPSG   I              eat                 apples [N.no3sg]   [N<V.bse>N]        [N.3pl] head_comp subj_headFigure 1: Derivation trees for CFG as well asCCG, HPSG and LFG formalisms.also observed on CCG and LFG formalisms.2 Related WorkOur work belongs to a broader class of researchon transfer learning in parsing.
This area has gar-nered significant attention due to the expense asso-ciated with obtaining syntactic annotations.
Trans-fer learning in parsing has been applied in differ-ent contexts, such as multilingual learning (Sny-der et al, 2009; Hwa et al, 2005; McDonald etal., 2006; McDonald et al, 2011; Jiang and Liu,2009), domain adaptation (McClosky et al, 2010;Dredze et al, 2007; Blitzer et al, 2006), and cross-formalism transfer (Hockenmaier and Steedman,2002; Miyao et al, 2005; Cahill et al, 2002; Rie-zler et al, 2002; Chen and Shanker, 2005; Canditoet al, 2010).There have been several attempts to map anno-tations in coarse grammars like CFG to annota-tions in richer grammar, like HPSG, LFG, or CCG.Traditional approaches in this area typically relyon manually specified rules that encode the rela-tion between the two formalisms.
For instance,mappings may specify how to convert traces andfunctional tags in Penn Treebank to the f-structurein LFG (Cahill, 2004).
These conversion rulesare typically utilized in two ways: (1) to create anew treebank which is consequently used to train aparser for the target formalism (Hockenmaier andSteedman, 2002; Clark and Curran, 2003; Miyaoet al, 2005; Miyao and Tsujii, 2008), (2) to trans-late the output of a CFG parser into the target for-malism (Cahill et al, 2002).The design of these rules is a major linguis-tic and computational undertaking, which requiresmultiple iterations over the data to increase cov-erage (Miyao et al, 2005; Oepen et al, 2004).By nature, the mapping rules are formalism spe-292cific and therefore not transferable.
Moreover, fre-quently designing such mappings involves modifi-cation to the original annotations.
For instance,Hockenmaier and Steedman (2002) made thou-sands of POS and constituent modifications to thePenn Treebank to facilitate transfer to CCG.
Moreimportantly, in some transfer scenarios, determin-istic rules are not sufficient, due to the high am-biguity inherent in the mapping.
Therefore, ourwork considers an alternative set-up for cross-formalism transfer where a small amount of an-notations in the target formalism is used as an al-ternative to using deterministic rules.The limitation of deterministic transfer ruleshas been recognized in prior work (Riezler et al,2002).
Their method uses a hand-crafted LFGparser to create a set of multiple parsing candi-dates for a given sentence.
Using the partial map-ping from CFG to LFG as the guidance, the re-sulting trees are ranked based on their consistencywith the labeled LFG bracketing imported fromCFG.
In contrast to this method, we neither requirea parser for the target formalism, nor manual rulesfor partial mapping.
Consequently, our methodcan be applied to many different target grammarformalisms without significant engineering effortfor each one.
The utility of coarse-grained tree-banks is determined by the degree of structuraloverlap with the target formalism.3 The Learning ProblemRecall that our goal is to learn how to parse the tar-get formalisms while using two annotated sources:a small set of sentences annotated in the target for-malism (e.g., CCG), and a large set of sentenceswith coarse annotations.
For the latter, we use theCFG parses from the Penn Treebank.
For sim-plicity we focus on the CCG formalism in whatfollows.
We also generalize our model to otherformalisms, as explained in Section 5.4.Our notations are as follows: an input sentenceis denoted by S. A CFG parse is denoted by yCFGand a CCG parse is denoted by yCCG.
Clearly theset of possible values for yCFG and yCCG is deter-mined by S and the grammar.
The training set is aset of N sentences S1, .
.
.
, SN with CFG parsesy1CFG, .
.
.
, yNCFG, and M sentences S?1, .
.
.
, S?Mwith CCG parses y1CCG, .
.
.
, yMCCG.
It is impor-tant to note that we do not assume we have paralleldata for CCG and CFG.Our goal is to use such a corpus for learningeat applescoarse feature on yCFG VP VP,NPVP    (S[dcl]\NP)/NPVP    S[dcl]\NPNP    NPformalism feature on yCCG S[dcl]\NP (S[dcl]\NP)/NP,NPjoint feature on yCFG, yCCG VP, S[dcl]\NP (VP, (S[dcl]\NP)/NP), (NP, NP)Figure 2: Illustration of the joint CCG-CFG representa-tion.
The shadowed labels correspond to the CFG deriva-tion yCFG, whereas the other labels correspond to the CCGderivation yCCG.
Note that the two derivations share thesame (binarized) tree structure.
Also shown are features thatare turned on for this joint derivation (see Section 6).how to generate CCG parses to unseen sentences.4 A Joint Model for Two FormalismsThe key idea behind our work is to learn a jointdistribution over CCG and CFG parses.
Such adistribution can be marginalized to obtain a distri-bution over CCG or CFG and is thus appropriatewhen the training data is not parallel, as it is in oursetting.It is not immediately clear how to jointly modelthe CCG and CFG parses, which are structurallyquite different.
Furthermore, a joint distributionover these will become difficult to handle com-putationally if not constructed carefully.
To ad-dress this difficulty, we make several simplifyingassumptions.
First, we assume that both parses aregiven in normal form, i.e., they correspond to bi-nary derivation trees.
CCG parses are already pro-vided in this form in CCGBank.
CFG parses in thePenn Treebank are not binary, and we therefore bi-narize them, as explained in Section 5.3.Second, we assume that any yCFG and yCCGjointly generated must share the same derivationtree structure.
This makes sense.
Since both for-malisms are constituency-based, their trees are ex-pected to describe the same constituents.
We de-note the set of valid CFG and CCG joint parses forsentence S by Y(S).The above two simplifying assumptions makeit easy to define joint features on the two parses,as explained in Section 6.
The representation andfeatures are illustrated in Figure 2.We shall work within the discriminative frame-work, where given a sentence we model a dis-tribution over parses.
As is standard in suchsettings, the distribution will be log-linear in aset of features of these parses.
Denoting y =(yCFG, yCCG), we seek to model the distribution293p(y|S) corresponding to the probability of gen-erating a pair of parses (CFG and CCG) given asentence.
The distribution thus has the followingform:pjoint(y|S; ?)
=1Z(S; ?)ef(y,S)??
.
(1)where ?
is a vector of parameters to be learnedfrom data, and f(y, S) is a feature vector.
Z(S; ?
)is a normalization (partition) function normalizedover y ?
Y(S) the set of valid joint parses.The feature vector contains three types of fea-tures: CFG specific, CCG specific and joint CFG-CCG.
We denote these by fCFG, fCCG, fjoint.These depend on yCCG, yCFG and y respectively.Accordingly, the parameter vector ?
is a concate-nation of ?CCG, ?CFG and ?joint.As mentioned above, we can use Equation 1to obtain distributions over yCCG and yCFG viamarginalization.
For the distribution over yCCGwe do precisely this, namely use:pCCG(yCCG|S; ?)
=?yCFGpjoint(y|S; ?)
(2)For the distribution over yCFG we could havemarginalized pjoint over yCCG.
However, thiscomputation is costly for each sentence, and hasto be repeated for all the sentences.
Instead, weassume that the distribution over yCFG is a log-linear model with parameters ?CFG (i.e., a sub-vector of ?)
, namely:pCFG(yCFG|S; ?CFG) =efCFG(yCFG,S)?
?CFGZ(S; ?CFG).
(3)Thus, we assume that both pjoint and pCFG havethe same dependence on the fCFG features.The Likelihood Objective: Given the modelsabove, it is natural to use maximum likelihood tofind the optimal parameters.
To do this, we definethe following regularized likelihood function:L(?)
=N?i=1log(pCFG(yiCFG|Si, ?CFG))+M?i=1log(pCCG(yiCCG|S?i, ?))?
?2 ??
?22where pCCG and pCFG are defined in Equations2 and 3 respectively.
The last term is the l2-normregularization.
Our goal is then to find a ?
thatmaximizes L(?
).Training Algorithm: For maximizing L(?)w.r.t.
?
we use the limited-memory BFGS algo-rithm (Nocedal and Wright, 1999).
Calculatingthe gradient of L(?)
requires evaluating the ex-pected values of f(y, S) and fCFG under the dis-tributions pjoint and pCFG respectively.
This canbe done via the inside-outside algorithm.3Parsing Using the Model: To parse a sentenceS, we calculate the maximum probability assign-ment for pjoint(y|S; ?
).4 The result is both a CFGand a CCG parse.
Here we will mostly be inter-ested in the CCG parse.
The joint parse with max-imum probability is found using a standard CYKchart parsing algorithm.
The chart constructionwill be explained in Section 5.5 ImplementationThis section introduces important implementa-tion details, including supertagging, feature for-est pruning and binarization methods.
Finally,we explain how to generalize our model to otherconstituency-based formalisms.5.1 SupertaggingWhen parsing a target formalism tree, one needsto associate each word with a lexical entry.
How-ever, since the number of candidates is typicallymore than one thousand, the size of the chart ex-plodes.
One effective way of reducing the numberof candidates is via supertagging (Clark and Cur-ran, 2007).
A supertagger is used for selecting asmall set of lexical entry candidates for each wordin the sentence.
We use the tagger in (Clark andCurran, 2007) as a general suppertagger for all thegrammars considered.
The only difference is thatwe use different lexical entries in different gram-mars.5.2 Feature Forest PruningIn the BFGS algorithm (see Section 4), feature ex-pectation is computed using the inside-outside al-gorithm.
To perform this dynamic programmingefficiently, we first need to build the packed chart,namely the feature forest (Miyao, 2006) to rep-resent the exponential number of all possible tree3To speed up the implementation, gradient computationis parallelized, using the Message Passing Interface pack-age (Gropp et al, 1999).4An alternative approach would be to marginalize overyCFG and maximize over yCCG.
However, this is a hardercomputational problem.294structures.
However, a common problem for lex-icalized grammars is that the forest size is toolarge.
In CFG, the forest is pruned according tothe inside probability of a simple generative PCFGmodel and a prior (Collins, 2003).
The basic ideais to prune the trees with lower probability.
For thetarget formalism, a common practice is to prunethe forest using the supertagger (Clark and Cur-ran, 2007; Miyao, 2006).
In our implementation,we applied all pruning techniques, because the for-est is a combination of CFG and target grammarformalisms (e.g., CCG or HPSG).5.3 BinarizationWe assume that the derivation tree in the target for-malism is in a normal form, which is indeed thecase for the treebanks we consider.
As mentionedin Section 4, we would also like to work with bi-narized CFG derivations, such that all trees are innormal form and it is easy to construct featuresthat link the two (see Section 6).Since Penn Treebank trees are not binarized, weconstruct a simple procedure for binarizing them.The procedure is based on the available target for-malism parses in the training corpus, which are bi-narized.
We illustrate it with an example.
In whatfollows, we describe derivations using the POS ofthe head words of the corresponding node in thetree.
This makes it possible to transfer binariza-tion rules between formalisms.Suppose we want to learn the binarization ruleof the following derivation in CFG:NN?
(DT JJ NN) (4)We now look for binary derivations with thesePOS in the target formalism corpus, and take themost common binarization form.
For example, wemay find that the most common binarization to bi-narize the CFG derivation in Equation 4 is:NN?
(DT (JJ NN))If no (DT JJ NN) structure is observed in theCCG corpus, we first apply the binary branchingon the children to the left of the head, and then onthe children to the right of the head.We also experiment with using fixed binariza-tion rules such as left/right branching, instead oflearning them.
This results in a drop on the depen-dency F-score by about 5%.5.4 Implementation in Other FormalismsWe introduce our model in the context of CCG,but the model can easily be generalized to otherconstituency-based grammars, such as HPSG andLFG.
In a derivation tree, the formalism-specificinformation is mainly encoded in the lexical en-tries and the applied grammar rules, rather than thetree structures.
Therefore we only need to changethe node labels and lexical entries to the language-specific ones, while the framework of the modelremains the same.6 FeaturesFeature functions in log-linear models are de-signed to capture the characteristics of eachderivation in the tree.
In our model, as mentionedin Section 1, the features are also defined to en-able information transfer between coarse and richformalisms.
In this section, we first introduce howdifferent types of feature templates are designed,and then show an example of how the features helptransfer the syntactic structure information.
Notethat the same feature templates are used for all thetarget grammar formalisms.Recall that our y contains both the CFG andCCG parses, and that these use the same derivationtree structure.
Each feature will consider either theCFG derivation, the CCG derivation or these twoderivations jointly.The feature construction is similar to construc-tions used in previous work (Miyao, 2006).
Thefeatures are based on the atomic features listed inTable 1.
These will be used to construct f(y, S) asexplained next.hl lexical entries/CCG categories of the head wordr grammar rules, i.e.
HPSG schema, resulting CCGcategories, LFG mapping equationssy CFG syntactic label of the node (e.g.
NP, VP)d distance between the head words of the childrenc whether a comma exists between the head wordsof the childrensp the span of the subtree rooted at the nodehw surface form of the head word of the nodehp part-of-speech of the head wordpi part-of-speech of the i-th word in the sentenceTable 1: Templates of atomic features.We define the following feature templates:fbinary for binary derivations, funary for unaryderivations, and froot for the root nodes.
Theseuse the atomic features in Table 1, resulting in the295following templates:fbinary =?
r, syp, d, csyl, spl, hwl, hpl, hll,syr, spr, hwr, hpr, hlr,pst?1, pst?2, pen+1, pen+2?funary = ?r, syp, hw, hp, hl?froot = ?sy, hw, hp, hl?In the above we used the following notation: p, l, rdenote the parent node and left/right child node,and st, en denote the starting and ending index ofthe constituent.We also consider templates with subsets of theabove features.
The final list of binary feature tem-plates is shown in Table 2.
It can be seen that somefeatures depend only on the CFG derivations (i.e.,those without r,hl), and are thus in fCFG(y, S).Others depend only on CCG derivations (i.e.,those without sy), and are in fCCG(y, S).
Therest depend on both CCG and CFG and are thusin fjoint(y, S).Note that after binarization, grandparent andsibling information becomes very important in en-coding the structure.
However, we limit the fea-tures to be designed locally in a derivation in orderto run inside-outside efficiently.
Therefore we usethe preceding and succeeding POS tag informationto approximate the grandparent and sibling infor-mation.
Empirically, these features yield a signifi-cant improvement on the constituent accuracy.fCFG?d,wl,r, hpl,r, syp,l,r?, ?d,wl,r, syp,l,r?,?c, wl,r, hpl,r, syp,l,r?, ?c, wl,r, syp,l,r?,?d, c, hpl,r, syp,l,r?, ?d, c, syp,l,r?,?c, spl,r, hpl,r, syp,l,r?, ?c, spl,r, syp,l,r?,?pst?1, syp,l,r?, ?pen+1, syp,l,r?,?pst?1, pen+1, syp,l,r?,?pst?1, pst?2, syp,l,r?, ?pen+1, pen+2, syp,l,r?,?pst?1, pst?2, pen+1, pen+2, syp,l,r?,fCCG?r, d, c, hwl,r, hpl,r, hll,r?, ?r, d, c, hwl,r, hpl,r?
?r, d, c, hwl,r, hll,r?,?r, c, spl,r, hwl,r, hpl,r, hll,r?
?r, c, spl,r, hwl,r, hpl,r, ?, ?r, c, spl,r, hwl,r, hll,r?
?r, d, c, hpl,r, hll,r?, ?r, d, c, hpl,r?, ?r, d, c, hll,r?
?r, c, hpl,r, hll,r?, ?r, c, hpl,r?, ?r, c, hll,r?fjoint ?r, d, c, syl,r, hll,r?, ?r, d, c, syl,r?
?r, c, spl,r, syl,r, hll,r?, ?r, c, spl,r, syl,r?Table 2: Binary feature templates used in f(y, S).Unary and root features follow a similar pattern.In order to apply the same feature templates toother target formalisms, we only need to assignthe atomic features r and hl with the formalism-specific values.
We do not need extra engineeringwork on redesigning the feature templates.eat apples VP    (S[dcl]\NP)/NPVP    S[dcl]\NPNP    NPVP VP,NPS[dcl]\NP (S[dcl]\NP)/NP,NPVP, S[dcl]\NP (VP, (S[dcl]\NP)/NP), (NP, NP)CCGbankVPPenn TreebankVP NP write lettersVP VP,NP fCFG (y,S) : fCFG (y,S) :fCCG (y,S) :f joint (y, S) :Figure 3: Example of transfer between CFG andCCG formalisms.Figure 3 gives an example in CCG of howfeatures help transfer the syntactic informationfrom Penn Treebank and learn the correspondenceto the formalism-specific information.
From thePenn Treebank CFG annotations, we can learnthat the derivation VP?
(VP, NP) is common, asshown on the left of Figure 3.
In a CCG tree, thistendency will encourage the yCFG (latent) vari-ables to take this CFG parse.
Then weights on thefjoint features will be learned to model the con-nection between the CFG and CCG labels.
More-over, the formalism-specific features fCCG canalso encode the formalism-specific syntactic andsemantic information.
These three types of fea-tures work together to generate a tree skeleton andfill in the CFG and CCG labels.7 Evaluation SetupGrammar Train Dev.
TestCCGSec.
02-21Sec.
00 Sec.
23HPSGLFG 140 sents.
in 560 sents.
inPARC700 PARC700Table 3: Training/Dev./Test split on WSJ sectionsand PARC700 for different grammar formalisms.Datasets: As a source of coarse annotations, weuse the Penn Treebank-1 (Marcus et al, 1993).
Inaddition, for CCG, HPSG and LFG, we rely onformalism-specific corpora developed in prior re-search (Hockenmaier and Steedman, 2002; Miyaoet al, 2005; Cahill et al, 2002; King et al, 2003).All of these corpora were derived via conversionof Penn Treebank to the target formalisms.
In par-ticular, our CCG and HPSG datasets were con-verted from the Penn Treebank based on hand-2960 1000 3000 7000 11000 150007476788082848688Labeled DepUnlabeled DepUnlabeled Parseval(a) CCG0 1000 3000 7000 11000 150007274767880828486Labeled DepUnlabeled DepUnlabeled Parseval(b) HPSG0 1000 3000 7000 11000 1500065707580Labeled DepUnlabeled DepUnlabeled Parseval(c) LFGFigure 4: Model performance with 500 target formalism trees and different numbers of CFG trees,evaluated using labeled/unlabeled dependency F-score and unlabeled PARSEVAL.crafted rules (Hockenmaier and Steedman, 2002;Miyao et al, 2005).
Table 3 shows which sec-tions of the treebanks were used in training, test-ing and development for both formalisms.
OurLFG training dataset was constructed in a sim-ilar fashion (Cahill et al, 2002).
However, wechoose to use PARC700 as our LFG tesing and de-velopment datasets, following the previous workby (Kaplan et al, 2004).
It contains 700 man-ually annotated sentences that are randomly se-lected from Penn Treebank Section 23.
The splitof PARC700 follows the setting in (Kaplan et al,2004).
Since our model does not assume paralleldata, we use distinct sentences in the source andtarget treebanks.
Following previous work (Hock-enmaier, 2003; Miyao and Tsujii, 2008), we onlyconsider sentences not exceeding 40 words, excepton PARC700 where all sentences are used.Evaluation Metrics: We use two evaluationmetrics.
First, following previous work, we eval-uate our method using the labeled and unlabeledpredicate-argument dependency F-score.
Thismetric is commonly used to measure parsing qual-ity for the formalisms considered in this paper.The detailed definition of this measure as appliedfor each formalism is provided in (Clark and Cur-ran, 2003; Miyao and Tsujii, 2008; Cahill et al,2004).
For CCG, we use the evaluation scriptfrom the C&C tools.5 For HPSG, we evaluateall types of dependencies, including punctuations.For LFG, we consider the preds-only dependen-cies, which are the dependencies between pairsof words.
Secondly, we also evaluate using unla-beled PARSEVAL, a standard measure for PCFGparsing (Petrov and Klein, 2007; Charniak andJohnson, 2005; Charniak, 2000; Collins, 1997).The dependency F-score captures both the target-5Available at http://svn.ask.it.usyd.edu.au/trac/candc/wikigrammar labels and tree-structural relations.
Theunlabeled PARSEVAL is used as an auxiliary mea-sure that enables us to separate these two aspectsby focusing on the structural relations exclusively.Training without CFG Data: To assess theimpact of coarse data in the experiments be-low, we also consider the model trained only onformalism-specific annotations.
When no CFGsentences are available, we assign all the CFG la-bels to a special value shared by all the nodes.
Inthis set-up, the model reduces to a normal log-linear model for the target formalism.Parameter Settings: During training, all thefeature parameters ?
are initialized to zero.
Thehyperparameters used in the model are tuned onthe development sets.
We noticed, however, thatthe resulting values are consistent across differ-ent formalisms.
In particular, we set the l2-normweight to ?
= 1.0, the supertagger threshold to?
= 0.01, and the PCFG pruning threshold to?
= 0.002.8 Experiment and AnalysisImpact of Coarse Annotations on Target For-malism: To analyze the effectiveness of annota-tion transfer, we fix the number of annotated treesin the target formalism and vary the amount ofcoarse annotations available to the algorithm dur-ing training.
In particular, we use 500 sentenceswith formalism-specific annotations, and vary thenumber of CFG trees from zero to 15,000.As Figure 4 shows, CFG data boosts parsing ac-curacy for all the target formalisms.
For instance,there is a gain of 6.2% in labeled dependencyF-score for HPSG formalism when 15,000 CFGtrees are used.
Moreover, increasing the numberof coarse annotations used in training leads to fur-ther improvement on different evaluation metrics.2970 1000 2000 3000 4000 5000 60007475767778798081828384w/o CFG15000 CFG(a) CCG0 1000 2000 3000 4000 5000 600072747678808284w/o CFG15000 CFG(b) HPSG0 1000 2000 3000 4000 5000 600066687072747678w/o CFG15000 CFG(c) LFG0 1000 2000 3000 4000 5000 6000777879808182838485868788w/o CFG15000 CFG(d) CCG0 1000 2000 3000 4000 5000 6000707274767880828486w/o CFG15000 CFG(e) HPSG0 1000 2000 3000 4000 5000 6000687072747678808284w/o CFG15000 CFG(f) LFGFigure 5: Model performance with different target formalism trees and zero or 15,000 CFG trees.
Thefirst row shows the results of labeled dependency F-score and the second row shows the results of unla-beled PARSEVAL.Tradeoff between Target and Coarse Annota-tions: We also assess the relative contributionof coarse annotations when the size of annotatedtraining corpus in the target formalism varies.
Inthis set of experiments, we fix the number of CFGtrees to 15,000 and vary the number of target an-notations from 500 to 4,000.
Figure 5 showsthe relative contribution of formalism-specific an-notations compared to that of the coarse annota-tions.
For instance, Figure 5a shows that the pars-ing performance achieved using 2,000 CCG sen-tences can be achieved using approximately 500CCG sentences when coarse annotations are avail-able for training.
More generally, the result con-vincingly demonstrates that coarse annotations arehelpful for all the sizes of formalism-specific train-ing data.
As expected, the improvement margindecreases when more formalism-specific data isused.Figure 5 also illustrates a slightly different char-acteristics of transfer performance between twoevaluation metrics.
Across all three grammars,we can observe that adding CFG data has amore pronounced effect on the PARSEVAL mea-sure than the dependency F-score.
This phe-nomenon can be explained as follows.
The un-labeled PARSEVAL score (Figure 5d-f) mainly re-lies on the coarse structural information.
Onthe other hand, predicate-argument dependency F-score (Figure 5a-c) also relies on the target gram-mar information.
Because that our model onlytransfers structural information from the sourcetreebank, the gains of PARSEVAL are expected tobe larger than that of dependency F-score.Grammar Parser # Grammar trees1,000 15,000CCG C&C 74.1 / 83.4 82.6 / 90.1Model 76.8 / 85.5 84.7 / 90.9HPSG Enju 75.8 / 80.6 84.2 / 87.3Model 76.9 / 82.0 84.9 / 88.3LFGPipelineAnnotator 68.5 / 74.0 82.6 / 85.9Model 69.8 / 76.6 81.1 / 84.7Table 4: The labeled/unlabeled dependency F-score comparisons between our model and state-of-the-art parsers.Comparison to State-of-the-art Parsers: Wewould also like to demonstrate that the abovegains of our transfer model are achieved usingan adequate formalism-specific parser.
Since ourmodel can be trained exclusively on formalism-specific data, we can compare it to state-of-the-art formalism-specific parsers.
For this experi-ment, we choose the C&C parser (Clark and Cur-ran, 2003) for CCG, Enju parser (Miyao and Tsu-jii, 2008) for HPSG and pipeline automatic an-notator (Cahill et al, 2004) with Charniak parserfor LFG.
For all three parsers, we use the imple-mentation provided by the authors with the defaultparameter values.
All the models are trained oneither 1,000 or 15,000 sentences annotated withformalism-specific trees, thus evaluating their per-formances on small scale or large scale of data.As Table 4 shows, our model is competitive with298all the baselines described above.
It?s not sur-prising that Cahill?s model outperforms our log-linear model because it relies heavily on hand-crafted rules optimized for the dataset.Correspondence between CFG and Target For-malisms: Finally, we analyze highly weightedfeatures.
Table 5 shows such features for HPSG;similar patterns are also found for the othergrammar formalisms.
The first two features areformalism-specific ones, the first for HPSG andthe second for CFG.
They show that we correctlylearn a frequent derivation in the target formalismand CFG.
The third one shows an example of aconnection between CFG and the target formal-ism.
Our model correctly learns that a syntacticderivation with children VP and NP is very likelyto be mapped to the derivation (head comp)?
([N?V?N],[N.3sg]) in HPSG.Feature type Features with high weightTargetformalismTemplate(r) ?
(hll, hpl)(hlr, pr)Examples(head comp)?
([N?V?N],VB)([N.3sg],NN)CoarseformalismTemplate(syp) ?
(syl, hpl)(syr, hpr)Examples(VP)?
(VP,VB)(NP,NN)JointfeaturesTemplate(r) ?
(hll, syl)(ler, syr)Examples(head comp)?
([N?V?N],VP)([N.3sg],NP)Table 5: Example features with high weight.9 ConclusionsWe present a method for cross-formalism trans-fer in parsing.
Our model utilizes coarse syn-tactic annotations to supplement a small num-ber of formalism-specific trees for training onconstituency-based grammars.
Our experimen-tal results show that across a range of such for-malisms, the model significantly benefits from thecoarse annotations.AcknowledgmentsThe authors acknowledge the support of the ArmyResearch Office (grant 1130128-258552).
Wethank Yusuke Miyao, Ozlem Cetinoglu, StephenClark, Michael Auli and Yue Zhang for answeringquestions and sharing the codes of their work.
Wealso thank the members of the MIT NLP groupand the ACL reviewers for their suggestions andcomments.
Any opinions, findings, conclusions,or recommendations expressed in this paper arethose of the authors, and do not necessarily reflectthe views of the funding organizations.ReferencesJohn Blitzer, Ryan McDonald, and Fernando Pereira.2006.
Domain adaptation with structural correspon-dence learning.
In Proceedings of the 2006 Con-ference on Empirical Methods in Natural LanguageProcessing, pages 120?128.
Association for Com-putational Linguistics.Joan Bresnan.
1982.
The mental representation ofgrammatical relations, volume 1.
The MIT Press.Aoife Cahill, Mairad McCarthy, Josef van Genabith,and Andy Way.
2002.
Parsing with pcfgs and au-tomatic f-structure annotation.
In Proceedings ofthe Seventh International Conference on LFG, pages76?95.
CSLI Publications.Aoife Cahill, Michael Burke, Ruth O?Donovan, JosefVan Genabith, and Andy Way.
2004.
Long-distancedependency resolution in automatically acquiredwide-coverage pcfg-based lfg approximations.
InProceedings of the 42nd Annual Meeting on Associ-ation for Computational Linguistics, page 319.
As-sociation for Computational Linguistics.Aoife Cahill.
2004.
Parsing with Automatically Ac-quired, Wide-Coverage, Robust, Probabilistic LFGApproximation.
Ph.D. thesis.Marie Candito, Beno?
?t Crabbe?, Pascal Denis, et al2010.
Statistical french dependency parsing: tree-bank conversion and first results.
In Proceed-ings of the Seventh International Conference onLanguage Resources and Evaluation (LREC 2010),pages 1840?1847.Eugene Charniak and Mark Johnson.
2005.
Coarse-to-fine n-best parsing and maxent discriminativereranking.
In Proceedings of the 43rd Annual Meet-ing on Association for Computational Linguistics,pages 173?180.
Association for Computational Lin-guistics.Eugene Charniak.
2000.
A maximum-entropy-inspired parser.
In Proceedings of the 1st NorthAmerican chapter of the Association for Computa-tional Linguistics conference, pages 132?139.John Chen and Vijay K Shanker.
2005.
Automatedextraction of tags from the penn treebank.
New de-velopments in parsing technology, pages 73?89.Stephen Clark and James R Curran.
2003.
Log-linearmodels for wide-coverage ccg parsing.
In Proceed-ings of the 2003 conference on Empirical methodsin natural language processing, pages 97?104.
As-sociation for Computational Linguistics.299Stephen Clark and James R Curran.
2007.
Wide-coverage efficient statistical parsing with ccg andlog-linear models.
Computational Linguistics,33(4):493?552.Michael Collins.
1997.
Three generative, lexicalisedmodels for statistical pprsing.
In Proceedings of theeighth conference on European chapter of the Asso-ciation for Computational Linguistics, pages 16?23.Association for Computational Linguistics.Michael Collins.
2003.
Head-driven statistical mod-els for natural language parsing.
Computational lin-guistics, 29(4):589?637.Mark Dredze, John Blitzer, Partha Pratim Talukdar,Kuzman Ganchev, Joao V Grac?a, and FernandoPereira.
2007.
Frustratingly hard domain adap-tation for dependency parsing.
In Proceedings ofthe CoNLL Shared Task Session of EMNLP-CoNLL,volume 2007.William Gropp, Ewing Lusk, and Anthony Skjellum.1999.
Using MPI: portable parallel programmingwith the message passing interface, volume 1.
MITpress.Julia Hockenmaier and Mark Steedman.
2002.Acquiring compact lexicalized grammars from acleaner treebank.
In Proceedings of the Third LRECConference, pages 1974?1981.Julia Hockenmaier.
2003.
Data and models for statis-tical parsing with combinatory categorial grammar.Rebecca Hwa, Philip Resnik, and Amy Weinberg.2005.
Breaking the resource bottleneck for multi-lingual parsing.
Technical report, DTIC Document.Wenbin Jiang and Qun Liu.
2009.
Automatic adap-tation of annotation standards for dependency pars-ing: using projected treebank as source corpus.
InProceedings of the 11th International Conference onParsing Technologies, pages 25?28.
Association forComputational Linguistics.Ronald M. Kaplan, Stefan Riezler, Tracy H. King, JohnT.
Maxwell III, Alexander Vasserman, and RichardCrouch.
2004.
Speed and accuracy in shallow anddeep stochastic parsing.
In Proceedings of NAACL.Tracy Holloway King, Richard Crouch, Stefan Riezler,Mary Dalrymple, and Ronald M Kaplan.
2003.
Theparc 700 dependency bank.
In Proceedings of theEACL03: 4th International Workshop on Linguisti-cally Interpreted Corpora (LINC-03), pages 1?8.Mitchell P Marcus, Mary Ann Marcinkiewicz, andBeatrice Santorini.
1993.
Building a large anno-tated corpus of english: The penn treebank.
Compu-tational linguistics, 19(2):313?330.David McClosky, Eugene Charniak, and Mark John-son.
2010.
Automatic domain adaptation for pars-ing.
In Human Language Technologies: The 2010Annual Conference of the North American Chap-ter of the Association for Computational Linguistics,pages 28?36.
Association for Computational Lin-guistics.Ryan McDonald, Kevin Lerman, and Fernando Pereira.2006.
Multilingual dependency analysis with a two-stage discriminative parser.
In Proceedings of theTenth Conference on Computational Natural Lan-guage Learning, pages 216?220.
Association forComputational Linguistics.Ryan McDonald, Slav Petrov, and Keith Hall.
2011.Multi-source transfer of delexicalized dependencyparsers.
In Proceedings of the Conference on Em-pirical Methods in Natural Language Processing,pages 62?72.
Association for Computational Lin-guistics.Yusuke Miyao and Jun?ichi Tsujii.
2008.
Feature for-est models for probabilistic hpsg parsing.
Computa-tional Linguistics, 34(1):35?80.Yusuke Miyao, Takashi Ninomiya, and Junichi Tsu-jii.
2005.
Corpus-oriented grammar developmentfor acquiring a head-driven phrase structure gram-mar from the penn treebank.
Natural LanguageProcessing?IJCNLP 2004, pages 684?693.Yusuke Miyao.
2006.
From Linguistic Theory to Syn-tactic Analysis: Corpus-Oriented Grammar Devel-opment and Feature Forest Model.
Ph.D. thesis.Jorge Nocedal and Stephen J Wright.
1999.
Numericaloptimization.
Springer verlag.Stephan Oepen, Dan Flickinger, and Francis Bond.2004.
Towards holistic grammar engineeringand testing?grafting treebank maintenance into thegrammar revision cycle.
In Proceedings of the IJC-NLP workshop beyond shallow analysis.
Citeseer.Slav Petrov and Dan Klein.
2007.
Improved infer-ence for unlexicalized parsing.
In Human LanguageTechnologies 2007: The Conference of the NorthAmerican Chapter of the Association for Computa-tional Linguistics, pages 404?411.Carl Pollard and Ivan A Sag.
1994.
Head-drivenphrase structure grammar.
University of ChicagoPress.Stefan Riezler, Tracy H King, Ronald M Kaplan,Richard Crouch, John T Maxwell III, and MarkJohnson.
2002.
Parsing the wall street journal us-ing a lexical-functional grammar and discriminativeestimation techniques.
In Proceedings of the 40thAnnual Meeting on Association for ComputationalLinguistics, pages 271?278.
Association for Com-putational Linguistics.Benjamin Snyder, Tahira Naseem, and Regina Barzi-lay.
2009.
Unsupervised multilingual grammar in-duction.
In Proceedings of the Joint Conferenceof the 47th Annual Meeting of the ACL and the3004th International Joint Conference on Natural Lan-guage Processing of the AFNLP: Volume 1-Volume1, pages 73?81.
Association for Computational Lin-guistics.Mark Steedman.
2001.
The syntactic process.
MITpress.Yue Zhang, Stephen Clark, et al 2011.
Shift-reduceccg parsing.
In Proceedings of the 49th Meetingof the Association for Computational Linguistics,pages 683?692.301
