Normalization and Paraphrasing Using Symbolic MethodsCaroline BrunXerox Research Centre Europe6, chemin de Maupertuis38240 Meylan FranceCaroline.Brun@xrce.xerox.comCaroline Hage`geXerox Research Centre Europe6, chemin de Maupertuis38240 Meylan FranceCaroline.Hagege@xrce.xerox.comAbstractWe describe an ongoing work in informa-tion extraction which is seen as a text nor-malization task.
The normalized represen-tation can be used to detect paraphrasesin texts.
Normalization and paraphrasedetection tasks are built on top of a ro-bust analyzer for English and are exclu-sively achieved using symbolic methods.Both grammar development rules and in-formation extraction rules are expressedwithin the same formalism and are devel-oped in an integrated way.
The experimentwe describe in the paper is evaluated andpresents encouraging results.1 IntroductionWork on paraphrase can be seen in two main per-spectives: From the analysis point of view, i.e.
howto recognize expressions found in texts that conveysimilar information (we call it normalization), andfrom the generation point of view, i.e.
how to pro-duce a natural language output semantically equiva-lent to the original phrase.In this paper, we address the analysis point ofview in an experiment we made in the processing ofa corpus consisting of a collection of texts from theAgency for Toxic Substances and Disease Registry(ATSDR) describing different toxic products1.
Inthese texts, multiple ways of describing toxic prod-ucts are present (see 2.1 below), which makes this1see http://www.atsdr.cdc.gov.text collection particularly interesting for the taskof paraphrase detection.
We build a system weredocuments are processed and give as output a nor-malized representation of some selected knowledge.The analysis phase can thus be seen as a paraphrasedetection phase, as it unifies in a same representa-tion different ways of expressing similar informationabout toxic products.We will first describe the corpus on which wework and then the semantic focus of our paraphrasesystem.
The following section is dedicated to theinformation extraction task which is seen as a para-phrase detection task in the continuity of the task ofparsing.
Finally we describe the evaluation of theInformation Extraction task performed by our sys-tem.
Future work and improvements are finally dis-cussed.2 Corpus Analysis and Expected Output2.1 Corpus studyThe corpus on which we work consists of a collec-tion of texts presenting toxic products from ATSDRthat are meant to be read by general public.
We haveconcentrated on the first paragraphs containing inaverage between 6-7 sentences and consisting in thegeneral presentation of a toxic product.
They giveinformation about the name, the appearance (colour,smell), some physical properties and possible syn-onyms of a toxic product.
They also explain wherethe product comes from and for what purposes it isused.
Because of the uniformity of the informationconveyed in these different texts, the corpus is richin paraphrases.For instance, in the text concerning acetone weread:It evaporates easily, is flammable, and dissolves inwater.And in the text concerning acrolein we can read:It dissolves in water very easily and quickly, changesto a vapor when heated.
It also burns easily.Even in the same text, they are some redundanciesand a similar idea can be expressed more than oncein different ways.
For instance, in the text describing2-Butanone we can read:it is also present in the environment from naturalsources.And later:2-Butanone occurs as a natural productThese few examples illustrates that the kind oftexts we work with deal with a restricted semanticdomain and contain a large number of reformula-tions.2.2 Semantic focus of our paraphrase systemOur goal is to detect and represent some selected in-formation in the corpus presented above.
To achievethis, we want to associate a uniform representationwith the different wordings of the same informationthat appears in the texts.
We focus on the differentways of expressing the information relative to theappearance, physical properties, synonyms, use andorigin of toxic products.
Our representation consistsof a list of predicates which are detailed below.?
PHYS FORM/2.
This predicate is the resultof the normalization of strings expressing thephysical form of the toxic product.
For in-stance PHYS FORM(ammonia,gas) expresses thatthe product ammonia is a gas.?
DESCRIPTION COLOUR/2.
This predicate is theresult of the normalization of strings describ-ing the colour of the toxic product.
For in-stance DESCRIPTION COLOUR(antimony,silvery-white) expresses that antimony is a silvery-whiteproduct.?
DESCRIPTION SMELL/2.
This predicate is theresult of the normalization of strings describ-ing the smell of toxic product.
For instanceDESCRIPTION SMELL(1.3-butadiene,gasoline-like)expresses that the product 1.3-butadiene has agasoline-like odor.?
SYNONYM/2.
This predicate expresses that thesecond argument is a synonym of the first,which is the name of the toxic product.
Forinstance SYNONYM(acetone,dimethyl ketone) ex-presses that dimethyl ketone is another name foracetone.?
PROPERTY/5.
The PROPERTY predicateis the result of the normalization of stringsexpressing physical or chemical propertiesof the toxic product.
For instance, PROP-ERTY(acrolein,dissolve,water,in,NONE) expressesthat the product acrolein is soluble in water(instantiation of the four first arguments ofthe predicate), and that we do have precisionsabout the way this dissolution occurs (lastargument NONE is not instantiated by avalue).
For the same product we have PROP-ERTY(acrolein,burn,NONE,NONE,easily) whichexpresses that the product is flammable andthat the localization of the flammability isunspecified.?
ORIGIN/4 contains the normalized informa-tion whether the product is natural or notand where it can be found.
For instance,ORIGIN(ammonia,manufactured,NONE,NONE) ex-presses that the product ammonia is man-made, and ORIGIN(amonnia,natural,soil,in) ex-pressed that the same product can also be foundnaturally in soil.?
USE/6 is the result of the normalization ofthe uses of the described product.
In thisfirst stage we only concentrate in uses wherethe product is used alone2.
For instanceUSE(benzidine,NONE,NONE,produce,dye,past)expresses that in the past (last argumentis past) the product benzidine was used toproduce dyes (4th and 5th arguments) whileUSE(ammonia,smelling salts,in,NONE,NONE,present)expresses that ammonia is now (last argumentis present) used in smelling salts (the purposeof the use is not specified here).2In the texts, uses of a product when it is mixed with anothercan also be described but we decided to ignore this information.To each of the above-mentioned predicates a suf-fix NEG can be added if there is a negation.3 Paraphrase detectionParaphrasing means to be able, from some input textthat convey a certain meaning, to express the samemeaning in a different way.
This subject has recentlybeen receiving an increasing interest.
For instance,Takahashi et.
al.
(Takahashi et al, 2000) developeda lexico-structural paraphrasing system.
Kaji et aldeveloped a system which is able to produce verbalparaphrase using dictionary definitions (Kaji et al,2000) and Barzilay and McKeown showed how, us-ing parallel corpora of English literary translations,they extract paraphrases (Barzilay and McKeown,2001).
Paraphrase detection is a useful step in manyNLP applications.
For instance, in multi-documentsummarization, paraphrase detection helps to iden-tify similar text segments in order that the summarybecome more concise (McKeown et al, 1999).
Para-phrase detection can also be used to augment recallin different IE systems.In our experiment, paraphrase detection is astep in normalization, as we want to instantiate thesame way the predicates presented above when theinformative content is similar.
For instance, we wantto obtain the same normalized predicate for the twoutterances ProductX is a colorless, nonflammableliquid and ProductX is a liquid that has no colourand that does not burn easily namely:DESCRIPTION COLOUR(ProductX,colorless)PHYS FORM(ProductX,liquid)PROPERTY NEG(ProductX,burn,NONE,NONE,NONE).The input to our paraphrase detection system is thewhole paragraph that describes the toxic product.The analysis of the paragraph produces as output theset of normalized predicates.
This output can be pro-duced either in simple text format or in an XML for-mat that can feed directly some database.The paraphrase detection system is based on threedifferent modules that are described in the follow-ing subsections.
As claimed in (Takahashi et al,2000) and for the purpose of re-usability, we dis-tinguish what is of general linguistic interest in theparaphrasing task from what is clearly domain de-pendent, so these three modules are:?
A general English dependency parser;?
A general morpho-syntactic normalizer;?
A specific- and application-oriented normal-izer.3.1 General English dependency parserThis component is a robust parser for English (XIP)(A?
?t-Mokhtar et al, 2002) that extract syntacticfunctionally labeled dependencies between lexicalnodes in the text.Parsing includes tokenization, morpho-syntacticanalysis, tagging which is performed via a combina-tion of hand-written rules and HMM, chunking andfinally, extraction of dependencies between lexicalnodes.Dependencies are binary relations linking twolexical nodes of a sentence.
They are establishedthrough what we call deduction rules.Deduction rulesDeduction rules apply on a chunk tree and consistin three parts:?
Context?
Condition?
ExtractionContext is a regular expression on chunk treenodes that has to be matched with the rule to apply.Condition is a boolean condition on dependen-cies, on linear order between nodes of the chunktree, or on a comparison of features associated withnodes.Extraction corresponds to a list of dependenciesif the contextual description and the conditions areverified.For instance, the following rule establishes aSUBJ dependency between the head of a nominalchunk and a finite verb:| SN{?*,#1[last:+]},?*[verb:?],SV{?
*, #2[last:+]}|if (?SUBJ(#2,#1))SUBJ(#2,#1).The first three lines of the rule corresponds to con-text and describe a nominal chunk in which the lastelement is marked with the variable #1, followed byanything but a verb, followed by a verbal chunk inwhich the last element is marked with the variable#2.
The fourth line (negative condition: ?)
veri-fies if a SUBJ dependency exists between the lexicalnodes corresponding to the variable #2 (the verb)and #1 (the head of the nominal chunk).
The testis true if the SUBJ dependency does not exist.
Ifboth context and condition are verified, then a de-pendency SUBJ is created between the verb and thenoun (last line).An important feature is that our parser always pro-vides a unique analysis (determinism), this analysisbeing potentially underspecified.3.2 General morpho-syntactic normalizationThe morpho-syntactic normalizer is a general mod-ule that is neither corpus- nor application-dedicated.It consists of hand-made rules that apply to the syn-tactic representation produced by our parser.
It useswell known syntactic equivalences such as passive-active transformation and verb alternations proposedin Levin.
It also exploits the classification given bythe COMLEX lexicon (Grishman et al, 1994) in or-der to calculate the deep-subject of infinitive verbs.For instance the utterance Antimony ores aremixed with other metals is finally represented with aset of normalized syntactic relations expressing thatthe normalized subject (SUBJ-N) of the verb mixis unknown, and that mix has two second actants(OBJ-N) ore and metal :SUBJ-N(mix,SOMEONE)OBJ-N(mix,ore)OBJ-N(mix,metal)For this example, both passive transformation andreciprocal alternation transformation have been ap-plied on the set of dependencies produced by thegeneral parser.Deep syntactic rules are expressed using the sameformalism than general syntactic rules presented inthe previous section.
For instance the followingrule construct an OBJ-N (Normalized object) depen-dency between the surface syntactic subject and averb in a passive form3.if ( SUBJ(#1,#2)& VDOMAIN[passive](#1,#3))OBJ-N(#3,#2)Unlike Rose?
?s approach (Rose?, 2000) which alsodeveloped a deep syntactic analyzer, this is done ex-clusively by hand-made rules based on the previouscalculated dependencies on the one hand and syn-tactic and morphological properties of the nodes in-volved in the dependencies on the other hand.Together with the exploration of syntactic prop-erties, we also take advantage of morphologicalproperties in order enrich our deep syntactic anal-ysis.
This is done using the CELEX database (CelexDatabase, 2000) by pairing nouns and verbs that be-long to the same morphological family, which al-lows us to obtain for the expression John?s creationof the painting, the same deep syntactic representa-tion as for John creates the painting.As a result of the second stage, we obtain newdeep syntactic relations, together with the superficialsyntactic relations calculated by the general parser:?
SUBJ-N (Normalized subject) that links thefirst actant of a verb (finite or non-finite) or ofa predicative noun to this verb or noun.?
OBJ-N (Normalized object) that links the sec-ond actant of a verb (finite or non-finite) or of apredicative noun to this verb or noun.?
ATTRIB (General attribute) that links twonodes when the second one denotes a propertyof the first one.?
PURPOSE that links a verb to its actant ex-pressing the purpose of the action.It is important to note that predicative nouns arerepresented by their underlying verbs.
e.g.
Theinvention of the process is represented by OBJ-N(invent,process).3VDOMAIN links the first element of a verbal chain to thelast element of a verbal chain and passive is a feature that isadded to this relation.3.3 Application and corpus specificnormalizationApplication and corpus specific normalization is afollow-up of the previous module.
But while generalnormalization is purely based on syntactic transfor-mations and some derivational morphology proper-ties, synonymy relations and all further possibilitiesof morphological derivations are not exploited.
Thisextension uses the results obtained at the previousanalysis level.The application- and corpus-oriented analysis isorganized in two axes that are detailed below.?
corpus oriented linguistic processing;?
corpus oriented paraphrasing rules.3.3.1 Corpus oriented linguistic processingWe exploit the corpus specific properties at dif-ferent stages of the processing chain in order to im-prove the results of the general syntactic analysis.Below are the additions we made:?
Specific tokenization rules.Since toxic products can have names like 2,3-Benzofuran, which the general tokenizer does notconsider as one unique token, we add a local gram-mar layer dedicated to the detection of these kinds ofnames.
In other words, this layer composes togethertokens that have been separated by the general tok-enizer.?
Specific disambiguation rules valid for thiskind of corpus but not necessarily valid for allkinds of texts.For instance, the word sharp has a priori two possi-ble part-of-speech analyzes, noun and adjective, andwe want to keep these two analyzes for the generalparser.
But, since the noun sharp belongs to a cer-tain domain (music) that has no intersection with thedomain handled by the corpus, we add specific dis-ambiguation rules to remove the noun analysis forthis word.?
Improved treatment of coordination for thiskind of text.The corpus contains long chains of coordinated ele-ments and especially coordination in which the lastcoordinated element is preceded by both a commaand the coordinator.
Since some elements have beentyped semantically, we can be more precise in thecoordination treatment exploiting this semantic in-formation.?
Adding some lexical semantics informationFor the purpose of the application, we have semanti-cally typed some lexical entries that are useful forparaphrase detection.
For instance, colour nameshave the features colour : + added.?
Automatic contextual typingSome of the manually semantic typing (previouspoint) allows us to indirectly type new lexical units.For instance, as formulations like synonyms, call,name, designate are marked as possible synonymyintroducers, we are able to infer that complementsof these lexical units are synonyms.
In a similarway, syntactic modifiers of lexical units that havebeen marked in the application lexicon like smelland odor are odor descriptions.
In these cases, di-rect typing cannot be achieved.
For example, thehuge number of potential smellings (almond-like,unpleasant, etc.)
cannot be code by hand.
How-ever, the inference mechanism enable us to extractthe required information.?
Ad-hoc anaphora resolution.In our corpus, the pronoun it and the possessive itsalways refer to the toxic product that is described inthe text.
As we do not have any anaphora resolutiondevice integrated to our parser, we take advantage ofthis specificity to resolve anaphora for it and its.3.3.2 Corpus oriented paraphrasesParaphrases are detected by hand-made rules us-ing lexical and structural information.Lexical relations for paraphrasingAs mentioned before, in our general normalizersome nouns and verbs belonging to the same mor-phological family are related.
We extend these re-lations to other classes of words that appear in thecorpus.
For instance, we want to link the adjec-tive flammable and the verb burn, and we want thesame kind of relation between the adjectives soluble,volatile, mixable and the verbs dissolve, evaporateand mix respectively.
We declaratively create a re-lation (ISAJ relation) between these pairs of words,and this relation can then be handled by our parserexactly like a dependency relation which has beenpreviously calculated.
Other lexical relations be-tween synonyms (e.g.
call and name) or non-relatedmorphological nouns and verbs (as for instance thenoun flammability and burn) are created.The lexical relations we created are the following?
ISAJ links an adjective and a verb when the verbcan be paraphrased by BE+adjective?
TURNTO links a noun and a verb when the verbcan be paraphrased by TURN TO+noun?
HASN links a noun and a verb when the verbcan be paraphrased by HAVE+noun?
SYNO links two words belonging to the samemorpho-syntactic class when the first is a syn-onym of the second4.Normalization rulesOnce these relations are created, we can then ex-ploit them in rules.For instance, the following rule5 (see below) al-lows for the creation of the predicatePROPERTY(aniline,dissolve,NONE,NONE,NONE)for the utterance aniline is soluble.if (SUBSTANCE(#1) &ATTRIB(#1,#8[adj_property]) &ISAJ(#9,#10) &#8[lemme]:#9[lemme])PROPERTY(#1,#10,##Pron[lemme=NONE],##Pron[lemme=NONE],##Pron[lemme=NONE])The rule formalism is the one used for the generalsyntactic grammar and the deep syntax grammar.
Inthis case, we only have two parts in the rule (Condi-tion and Extraction, Context being omitted).
In the4Since we work in a very specific domain, we have no prob-lem of word-sense ambiguity here.5Variables in a rule are represented by #n.present example, since we have detected that anilineis the described toxic product (SUBSTANCE(aniline)),since an ISAJ relation exists between soluble anddissolve (ISAJ(soluble,dissolve)) and finally since thedeep syntactic analysis of the sentence has given tous the dependency ATTRIB(aniline,soluble), the finalpredicate is created.3.4 Example of outputWhen applied on an input text describing a toxicsubstance, such as the following one :Acetone is a manufactured chemical that is alsofound naturally in the environment.
It is a colorlessliquid with a distinct smell and taste.
It evaporateseasily, is flammable, and dissolves in water.
Itis also called dimethyl ketone, 2-propanone, andbeta-ketopropane.
Acetone is used to make plastic,fibers, drugs, and other chemicals.
It is also usedto dissolve other substances.
It occurs naturally inplants, trees, volcanic gases, forest fires, and as aproduct of the breakdown of body fat.
It is presentin vehicle exhaust, tobacco smoke, and landfill sites.Industrial processes contribute more acetone to theenvironment than natural processes.the system is able to extract the following listof predicates:SUBSTANCE(acetone)PHYS_FORM(acetone,chemical)PHYS_FORM(acetone,liquid)DESCRIPTION_COLOUR(acetone,colorless)DESCRIPTION_SMELL(acetone,distinct)PROPERTY(acetone,burn,NONE,NONE,easily)PROPERTY(acetone,evaporate,NONE,NONE,easily)PROPERTY(acetone,dissolve,water,in,NONE)ORIGIN(acetone,natural,vehicle exhaust,in)ORIGIN(acetone,natural,tobacco smoke,in)ORIGIN(acetone,natural,landfill site,in)ORIGIN(acetone,natural,plant,in)ORIGIN(acetone,natural,the environment,in)ORIGIN(acetone,man-made,NONE,NONE)ORIGIN(acetone,natural,tree,in)ORIGIN(acetone,natural,volcanic gas,in)ORIGIN(acetone,natural,forest fire,in)ORIGIN(acetone,natural,a product,in)SYNONYM(acetone,dimethyl ketone)SYNONYM(acetone,beta-ketopropane)SYNONYM(acetone,2-propanone)USE(acetone,NONE,NONE,make,plastic,present)USE(acetone,NONE,NONE,make,fiber,present)USE(acetone,NONE,NONE,make,drug,present)USE(acetone,NONE,NONE,make,other chemical,present)USE(acetone,NONE,NONE,dissolve,other substance,present)Most of the information present in the orig-inal text has been extracted and normalized:for example, flammable is normalized as PROP-ERTY(acetone,burn,NONE,NONE,easily).
However,form the input ... as a product of the breakdownof body fat, the system extract the partial analysisORIGIN(acetone,natural,a product,in).
Such cases arediscussed in section 4.In this section, we have shown how, extending ageneral parser with limited information (morpholog-ical and transformational) and adding specific do-main knowledge for the corpora we consider, wewere able to obtain a normalization of some knowl-edge enclosed in the texts.
The next section is ded-icated to the evaluation of the performances of thissystem.4 EvaluationWe decided to perform two kinds of evaluation?
First, we wanted to check if our system per-forms correctly the extraction of the selectedinformation.?
Second, we wanted to verify the impact ofthe normalization and the corpus oriented para-phrase modules in the obtained results.4.1 Performance of the whole system forinformation extractionIn order to evaluate the results of the informationextraction system, we apply the full chain of infor-mation extraction on an unseen collection of 30 textsdescribing toxic substances.
Then we associate theoutput predicates to the corresponding texts and askeach of the five evaluators to compare six pairs oftexts/predicates.
We ask them to read carefully thetexts and to fill a table which covers the differenttypes of information in scope, i.e substance, physi-cal form, colour, odor, synonyms, physical proper-ties, and use.
For each topic, they have to expresswhat is missing, superfluous or wrong in the list ofpredicates, compared to the original texts.
We con-sider one missing answer for each missing informa-tion detected by the evaluators.
And we consideran incorrect response for each information that hadbeen extracted by the system and that did not corre-spond to any realization in text.
We then computeprecision and recall, obtaining the following results:Precision Recall F-score.96 .65 .77We obtain a high precision result which could beexpected considering our IE methodology.
In mostof the cases, when the information has been ex-tracted, it is correct.
However, most of the prob-lems are a consequence of insufficient coverage ofboth the extraction grammar (problems with struc-tural ambiguity) and domain-knowledge.
The mainsources of errors which have been identified duringthe evaluation comes from :?
Coordination detection problems.
For exam-ple, from the sentence Hexachlorobutadieneis also used as a solvent, and to make lu-bricants, in gyroscopes, as a heat transferliquid, and as an hydraulic fluid.
the sys-tem detects only one ?use?
of the element:USE(Hexachlorobutadiene,solvent,as,NONE,NONE),because the complex coordination has not beensolved.?
Scope of the extraction: from the sen-tence Nitrobenzene is used in the man-ufacture of dyes, the system extractsUSE(Nitrobenzene,manufacture,in,NONE,NONE),because the PP of dyes was not expected in thestructure of the USE predicate.?
Domain-knowledge coverage: form the sen-tence Acetone completely miscible in water andsoluble in organics., the system extract PROP-ERTY(Acetone,dissolve,in,organic,NONE), becausesoluble is encoded as a property equivalent todissolve in the lexical relations for paraphras-ing.
However, it should also extract PROP-ERTY(Acetone,mix,in,water,NONE), but misciblewas not coded as a possible chemical propertyadjective.From the evaluation results, it appears that furtherdevelopments need to focus on recall improvement.This could be achieved by:?
extending our paraphrase detection module:Some equivalences have not been yet consid-ered.
For instance, take fire which did not ap-pear in the working corpus, appeared in the testcorpus.
This expression had not been codedas a possible equivalent of burn, therefore ex-pected information about the physical propertyof burning for a given element is missing whenthis property is expressed in the text by takefire;?
enriching the ontological knowledge of the do-main;?
Improving structural ambiguity resolution:Coordination and PP attachment resolutioncould be improved by the development ofmore fine-grained semantic and ontological re-sources.4.2 Impact of the normalization and corpusoriented paraphrase modulesThis second experiment was intended to verify inwhat extent the normalization and paraphrase detec-tion module affect the results obtained in the previ-ous evaluation.
This test was performed taking awayfrom the complete processing chain, the modules de-scribed in sections 3.2 and 3.3.2.
The results showthat we only obtained about 60% of the predicatesfound in the first version.
In other words, withoutthese processing steps, recall decreases in a dramaticway.
All predicates found in this second experimentwere also found in the first.
Missing predicates inthe second experiment were the most complex to ex-tract (i.e.
USE, PROPERTY, ORIGIN), since theyintensively involve reformulations and lexical equi-valences.5 ConclusionIn this paper, we have presented a methodology forextracting information using symbolic methods.
In-formation extraction consists here in normalizationof syntactic processing using both deep syntacticand morphological information as well as corpusspecific knowledge.
As the kind of corpus underconsideration is very rich in reformulations, we wereable to verify that our system could be used to de-tect paraphrases in the domain of the corpus.
In fact,paraphrase detection can be seen as a side effect ofnormalization, as utterances conveying similar infor-mation are represented the same way.
This is an on-going work but the first results we obtained for infor-mation extraction are really encouraging, althoughmany improvements seem to be necessary.
We fore-see to continue our experiment applying our systemon a different collection of texts from the same do-main.
We also plan to improve the current coverageof our system having in mind the results of the firstevaluation.AcknowledgmentsWe would like to thank our colleagues Jean-PierreChanod, Marc Dymetman, Aaron Kaplan and ?AgnesSa?ndor for their careful reading and helpful com-ments on this paper.ReferencesSalah A?
?t-Mokhtar, Jean-Pierre Chanod and ClaudeRoux.
2002.
Robustness beyond shallowness: incre-mental dependency parsing.
Special issue of the NLEJournal.Regina Barzilay and Kathleen R. McKeown.
2001.
Ex-tracting Paraphrases from a Parallel Corpus Proceed-ings of the ACL 2001 Toulouse, France.Ralf Grishman, Catherine Macleod, and Adam Meyers.1994 COMLEX: building a computational lexicon InProceedings of the 15th International Conference onComputational Linguistics (COLING 1994), Comlex.Nobuhiro Kaji, Daisuke Kawahara, Sadao Kurohashi,and Satoshi Sato.
2001.
Verb Paraphrase based onCase Frame Alignment Proceedings of the Workshopon Automatic Paraphrasing.
NLPRS 2001, Tokyo,Japan.Beth Levin.
1993.
English Verb Classes and Alterna-tions - A Preliminary Investigation.
The University ofChicago Press.Kathleen R. McKeown, Judith L. Klavans, VasileiosHatzivassiloglou, Regina Barzilay, and Eleazar Eskin.1999.
Towards Multidocument Summarization by Re-formulation: Progress and Prospects.
AAAI/IAAA.Carolyn P. Rose?.
2000.
A syntactic framework for Se-mantic Interpretation.
Proceedings of the 1st meetingof the North American Chapter of the Association forComputational Linguistics.
Seattle, Washington.Celex 2000. http://www.kun.nl/celex/index.html.Tetsuro Takahashi, Tomoyam Iwakura, Ryu Iida, AtsushiFujita and Kentaro Inui.
2001.
KURA: A Transfer-Based Lexico-Structural Paraphrasing Engine.
Pro-ceedings of the Workshop on Automatic Paraphrasing.NLPRS 2001, Tokyo, Japan.
