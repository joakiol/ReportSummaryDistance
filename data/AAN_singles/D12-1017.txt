Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational NaturalLanguage Learning, pages 183?193, Jeju Island, Korea, 12?14 July 2012. c?2012 Association for Computational LinguisticsLocal and Global Contextfor Supervised and Unsupervised Metonymy ResolutionVivi NastaseHITS gGmbHHeidelberg, Germanyvivi.nastase@h-its.orgAlex JudeaUniversity of StuttgartStuttgart, Germanyalexander.judea@ims.uni-stuttgart.deKatja MarkertUniversity of LeedsLeeds, UKK.Markert@leeds.ac.ukMichael StrubeHITS gGmbHHeidelberg, Germanymichael.strube@h-its.orgAbstractComputational approaches to metonymy res-olution have focused almost exclusively onthe local context, especially the constraintsplaced on a potentially metonymic word byits grammatical collocates.
We expand suchapproaches by taking into account the largercontext.
Our algorithm is tested on the datafrom the metonymy resolution task (Task 8) atSemEval 2007.
The results show that incorpo-ration of the global context can improve overthe use of the local context alone, dependingon the types of metonymies addressed.
As asecond contribution, we move towards unsu-pervised resolution of metonymies, made fea-sible by considering ontological relations aspossible readings.
We show that such an unsu-pervised approach delivers promising results:it beats the supervised most frequent sensebaseline and performs close to a supervisedapproach using only standard lexico-syntacticfeatures.1 IntroductionWith the exception of explicit tasks in metonymyand metaphor analysis, computational treatment oflanguage relies on the assumption that the texts to beprocessed have a literal interpretation.
This contrastswith the fact that figurative expressions are com-mon in language, as exemplified by the metonymyin the excerpt from a Wikipedia article in Exam-ple 1 and another in Example 2 from the SemEval2007 metonymy resolution task (Markert and Nis-sim, 2009).
(1) In the gold medal game, Canada defeated theAmerican team 2-0 to win their third consecu-tive gold.
(2) This keyword is only required when your rela-tional database is Oracle.The defeating in Example 1 will not be doneby the country as such, but by a team represent-ing the country in a sporting event.
Hence, in ametonymy a potentially metonymic expression orword (here Canada) stands for a conceptually re-lated entity (here, people of Canada).
In the sec-ond Example, a company name (Oracle) stands fora product (database) developed by the company.Metonymy resolution can be important for avariety of tasks.
Textual entailment may needmetonymy resolution (Bentivogli et al2007): forexample, we would like to be able to induce fromExample 1 the hypothesisThe Canadian team won .
.
.
.Leveling and Hartrumpf (2008) show thatmetonymy recognition on location proper nameshelps geographical information retrieval by ex-cluding metonymically used place names fromconsideration (such as Example 1 or the use ofVietnam for the Vietnam war).
Metonymies also fre-quently interact with anaphora resolution (Nunberg,1995; Markert and Hahn, 2002), as in Example 1where the metonymic use of Canada is referred toby a plural pronoun afterward (their).Metonymies can be quite regular: companynames can be used for their management or theirproducts, country names can be used for associatedsports teams.
Following from this, the currently183prevalent set-up for metonymy resolution ?
as inthe SemEval 2007 task ?
provides a manually com-piled list of frequent readings or metonymic patternssuch as organization-for-product for pre-specified semantic classes (such as organizations) aswell as annotated examples for these patterns so thatsystems can then treat metonymy resolution as a (su-pervised) word sense disambiguation task.
How-ever, this approach needs novel, manual provisionof readings as well as annotated examples for eachnew semantic class.In contrast, we will see readings as relations be-tween the potentially metonymic word (PMW) andother concepts in a large concept network, a prioriallowing all possible relations as readings.
We basethis approach on the observation that metonymicwords stand in for concepts that they are relatedwith ?
e.g.
the part for the whole, the companyfor the product.
These readings are obtained onthe fly and are therefore independent of manuallyprovided, preclassified interpretations or semanticclasses, leading eventually to the possibility of un-supervised metonymy resolution.
We achieve thisby first linking a PMW to an article in Wikipedia.Then we extract from a large concept network de-rived from Wikipedia the relations surrounding thePMW.As there will be (many) more than one such rela-tion, these need to be ranked or scored.
We achievethis in a probabilistic framework where we condi-tion the probability of a relation on the context ofthe PMW.
This ranking showcases our second majorinnovation in that the flexibility of our framework al-lows us to incorporate a wider context than in mostprior approaches.
Let us consider the indications formetonymic readings and its interpretation in Exam-ple 1, on the one hand, and Example 2, on the otherhand.
In Example 1, the grammatical relation to theverb defeat and the verb?s selectional preferences in-dicate the metonymy.
We will call all such grammat-ically related words and the grammatical relationsthe local context of the PMW.
Such types of localcontext have been used by most prior approaches(Pustejovsky, 1991; Hobbs et al1993; Fass, 1991;Nastase and Strube, 2009, among others).
However,Example 2 shows that the local context can be am-biguous or often weak, such as the verb to be.
Inthese examples, the wider context (database, key-word) is a better indication for a metonymy but hasnot been satisfactorily integrated in prior approaches(see Section 2).
We here call all words surround-ing the PMW but not grammatically related to it theglobal context.In our approach we integrate both the local andthe global context in our probabilistic framework.For the local context, we compute the selectionalpreferences for the words related to the PMW from acorpus of English Wikipedia articles and generalizethem in the Wikipedia concept network, thus (auto-matically) providing a set of abstractions ?
generalconcepts in the network that capture the semanticclasses required by the local context.
In the nextstep we compute probabilities of the global con-text surrounding the PMWs under each (locally re-quired) abstraction, and combine this with the se-lectional preferences of the grammatically relatedwords.
That we can integrate local and global con-text in one probabilistic but also knowledge-basedframework is possible because we combine two de-scriptions of meaning ?
ontological and distribu-tional ?
by exploiting different sources of informa-tion in Wikipedia (category-article hierarchy and ar-ticle texts).We compute the probabilities of the relations (=readings) between the concept corresponding to thePMW and its directly related concepts.
These canbe used either (i) as additional features in a super-vised approach or (ii) directly for unsupervised res-olution.
We do both in this paper and show that (i)the supervised approach using both local and globalcontext can outperform one using just local con-text, dependent on the semantic class studied and(ii) that an unsupervised approach ?
although lowerthan the supervised one ?
outperforms the super-vised most frequent reading baseline and performsclose to a standard supervised model with the basicset of lexico-syntactic features (Nissim and Markert,2005).2 Related WorkThe word sense disambiguation setting formetonymy resolution as developed by Nissimand Markert (2005) and used for the SemEval 2007task (Markert and Nissim, 2009) uses a small, pre-specified number of frequently occurring readings.184The approaches building on this work (Farkas etal., 2007; Nicolae et al2007, among others) aresupervised, mostly using shallow surface featuresas well as grammatical relations.1 Most effectivein the SemEval task as summarized in Markertand Nissim (2009) has been the local, grammaticalcontext, with the two systems relying on the globalcontext or the local/global context in a BOW model(Leveling, 2007; Poibeau, 2007) not outperformingthe most frequent reading baseline.
We believethat might be due to the lack of a link between thelocal and global context in these approaches ?
inour work, we condition the global context on theabstractions and selectional preferences yielded bythe local context and achieve better results.Lapata (2003), Shutova (2009) as well as Robertsand Harabagiu (2011) deal with the issue of logicalmetonymy, where the participant stands in for thefull event: e.g.
Mary enjoyed the book., where bookstands in for reading the book, and this missing event(reading) can be inferred from a corpus.
Utiyamaet al2000), Lapata (2003) propose a probabilis-tic model for finding the correct interpretation ofsuch metonymies in an unsupervised manner.
How-ever, these event type metonymies differ from theproblem dealt with in our paper and the SemEval2007 task in that their recognition (i.e.
their distinc-tion from literal occurrences) is achieved simply bygrammatical patterns (a noun instead of a gerund orto-infinitive following the verb) and the problem islimited to interpretation.Our view of relations in a concept network beingthe interpretations of metonymies is strongly remi-niscent of older work in metonymy resolution suchas Hobbs et al1993), Fass (1991), Markert andHahn (2002) or the use of a generative lexicon andits relations in Pustejovsky (1991), which also areunsupervised.
However, these approaches lackedscalability due to the use of small hand-modeledknowledge bases which our use of a very largeWikipedia-derived ontology overcomes.
In addition,most of these approaches (Fass, 1991; Hobbs et al1993; Pustejovsky, 1991; Harabagiu, 1998) rely onthe view that metonymies violate selectional restric-tions in their immediate, local context, usually those1Brun et al2007) is semi-supervised but again relies on thelocal grammatical context.imposed by the verbs on their arguments.
As canbe seen in the Example 2, this misses metonymieswhich do not violate selectional restrictions.
Nas-tase and Strube (2009) use more flexible proba-bilistic selectional preferences instead of strict con-straint violations as well as WordNet as a larger tax-onomy but are also restricted to the local context.Markert and Hahn (2002) do propose a treatment ofmetonymies that takes into account the larger dis-course in the form of anaphoric relations betweena metonymy and the prior context.
However, theyconstrain discourse integration to potential PMWsthat are definite NPs and the context to few previousnoun phrases.
In addition, their framework uses astrict rule-based ranking of competing readings thatcannot be easily extended.The work presented here also relies on a con-cept network, built automatically from Wikipedia.This resource provides us with links between enti-ties in the text, and also a variety of ontological re-lations for the PMW, that will allow us to identify awide variety of metonymic interpretations.
Our ap-proach combines information from the concept net-work with automatically acquired selectional prefer-ences as well as a possibility to combine in a prob-abilistic framework the influence of the local andglobal context on the interpretation of a potentiallymetonymic word.3 The ApproachThe approach we present takes into account boththe local, grammatical, context and the larger textualcontext of a potentially metonymic word.
Figure 1presents a graphical representation of our approach.On the one hand, the word/term to be interpreted(the potentially metonymic word/term ?
PMW) ismapped onto a concept in the concept network (Sec-tion 3.3), which gives us access to the conceptualrelations (Ri) between the PMW and other concepts(cx ?
CRi).
On the other hand, any word w gram-matically related to the PMW via a grammatical re-lation r provides us with semantic restrictions on theinterpretation of the PMW, namely preferred seman-tic classes Aj (we call them abstractions) and a se-lectional preference score.2 These are automatically2We restrict the grammatical context that provides selec-tional preferences to verbs or adjectives grammatically related185A 1 A 21R kRA n12c14c11c13c 1n?1c1nck1c k2ck4ck3ckmckm?1c w1w2w3wlwr......PMWp(Ri|Aj) p(Aj|Cont,w,r)Global context...... .........
...Figure 1: Metonymy resolution using selectional preferencesAj derived from local contextw and r, semantic relationsRi to the PMW from a concept network, and the global context surrounding a term to be interpretedacquired by using a corpus of Wikipedia articles anda repository of encyclopedic knowledge (presentedin Section 3.1), as described in detail in 3.2.
Becausethe abstractions Aj and the PMW?s related concepts(cx) come from the same structured resource, wecan compute the probabilities for each Ri given thegrammatically related word w and the grammaticalrelation r. The global context can also easily beadded to the computation, as the probability of eachword in the context relative to an abstraction Aj canbe computed through the resource?s is a hierarchyand its link to Wikipedia articles.
This is detailed inSection 3.4.3.1 A concept network obtained fromWikipediaWe use a Wikipedia article dump (January 2011)which provided over 3.5 million English articles,interconnected through a hierarchy of categoriesand hyperlinks.
This partly structured repositoryis transformed into a large-scale multilingual con-cept network, whose nodes are concepts correspond-ing to articles or categories in Wikipedia (Nastaseet al2010).
Concepts in this network are con-nected through a variety of semantic relations (e.g.is a, member of, nationality) derived from categorynames and infoboxes.
The version of WikiNet usedto the PMW.had 3,707,718 nodes and 49,931,266 relation in-stances of 494 types, and is freely available3.WikiNet is used here as a concept inventory,and its links and structure to generalize more spe-cific concepts identified in texts to general concepts.The fact that nodes in WikiNet correspond to arti-cles/categories in Wikipedia is used to link articletexts in Wikipedia to general concepts, for the pur-pose of computing various probability scores (de-tailed in Section 3.4).3.2 Selectional preferences and abstractionsTo compute selectional preferences we use the set ofEnglish Wikipedia articles, which describe specificconcepts.
Wikipedia contributors are encouraged toinsert hyperlinks, which link important terms in anarticle to the corresponding articles.
A hyperlinkconsists of two parts, the actual link (i.e.
a URL)and a phrase to appear in the text.
Hyperlinks thenconstitute a bridge from the textual level to the con-ceptual level without the need for word sense dis-ambiguation.
We exploit these links to gather con-cept arguments for verbs and adjectives, and gen-eralize these using the concept network built fromWikipedia.The corpus of Wikipedia articles was first en-riched with hyperlinks, making the ?one sense per3http://www.h-its.org/english/research/nlp/download/wikinet.php186Algorithm 1 computeSelPrefs(G,WkN)Input: G ?
grammatical relation triplesWkN ?
WikiNetM ?
maximum number of generalization stepsOutput: ??
= {}for all (w, r) such that (c, r, w) ?
G doS = {(c, f)|f is the frequency of (c, r, w) in G}?w,r = Smdl = MDL(?w,r,S)for all i = 1,M do??
= abstract(S,WkN)mdl??
= MDL(?
?,S)if mdl??
< mdl then?w,r = ???
= {?w,r} ?
?return ?Algorithm 2 MDL(?,S)Input: ?
= {(c, f)} ?
a scored list of conceptsS ?
the set of observations (concept collocates)Output: MDL(?,S)??
=< f1, ..., fn >; (ci, fi) ?
?remove {(c, f) ?
?|f = 1} // parameter descriptionlength :L(??|?)
= |?|?12 ?
log(|S|) // data description length :for all (c, f) ?
?
doL(S|?, ??)
= L(S|?, ??)
+ f ?
log( fhyponyms(c)?|?| )return L(??|?)?
L(S|?, ??
)Algorithm 3 abstract(S,WkN)Input: S = {(c, f)|(w,R, c) ?
G}WkN ?
WikiNetOutput: S ?S ?
= {}for c|(c, ) ?
S dowhile c has only one is a link doc = c?, (c, is a, c?)
?WkNC = {(c?, c)|(c, is a, c?)
?WkN}for (c?, c) ?
C doif (c?, f ?)
?
S ?
thenreplace (c?, f ?)
with (c?, f ?
+ f|C| ), (c, f) ?
Sin S ?elseS ??
= {(c?, f)}, (c, f) ?
S// Remove hyponyms.for all {(c, c?)
?
S ?|(c?, is a, c) ?WkN} do// update frequency f of cfc = fc + fc?
, f ?
Sdelete c?return S ?discourse?
assumption ?
a phrase that appears as-sociated with a hyperlink once in the article bodywill be associated with the same hyperlink through-out the article (this applies to the article title as well,which is not hyperlinked in the article itself).
Thisnew version of the corpus was then split into sen-tences, and those without hyperlinks were removed.The remaining 18 million sentences were parsedwith a parallelized version of Ensemble4 (Surdeanuand Manning, 2010), and we extracted G, the set ofall grammatical relations of the type (verb, depen-dency, hyperlink) and (adjective, dependency, hy-perlink), with the hyperlinks resolved to their cor-responding node (concept) in the network ( |G| =1,578,413 triples).
For each verb and adjective in theextracted collocations, and for each of their depen-dency relations, their collocates were generalized inthe network defined by the hypernym/hyponym re-lations in WikiNet following a method similar to theMinimum Description Length principle (Li and Abe,1998).Essentially, we aimed to determine a small set of(more general) concepts that describe the set of col-locates for a word w and grammatical relation r.Starting from the concept collocates gathered, wego upwards following WikiNet?s is a links, and foreach node found that covers at least N concept col-locates (N is a parameter, N=2 in the experimentspresented here), the MDL score of the node is com-puted (Algorithm 2).
We place a limit M on thenumber of upward steps in the hierarchy (M=3 inour experiments).
The disjoint set of nodes that hasthe lowest overall MDL score is chosen (?
), and foreach node in this cut (which we call abstraction),we compute the selectional preference score, basedon the number of concepts it dominates.As an example, for the verb defeat, the corpusleads to collocations such as5:defeatnsubjEarle Page (10357) ?
8, Manuela Maleeva(1092361) ?
7, New York Yankees(10128601) ?
5, Tommy Haas (1118005)?
5, .
.
.obj4http://www.surdeanu.name/mihai/ensemble/5The format is:Article name (Article Id) ?
frequency.187New York Yankees (10128601) ?
9, Oak-land Athletics (11641124) ?
6, PhoenixSuns (11309373) ?
4, Jason Suttie(10080653) ?
3, Ravana (100234) ?
3, .
.
.Determining abstractions and selectional prefer-ences leads to the following information6:defeatnsubjMartial artists (118977183) ?
0.5, Person(219599) ?
0.3518, Interest (146738) ?0.037, .
.
.objVideo games (9570081) ?
0.25, Britishgames (24489088) ?
0.25, Person (219599)?
0.1445, Interest (146738) ?
0.1341, .
.
.3.3 Linking the PMW to the concept networkIn our environment, linking the PMW to the con-cept network is equivalent to finding its correspond-ing concept in our ontology, WikiNet.
We see thiscorresponding concept as the literal reading of thePMW.
Doing so is a non-trivial task (see the Cross-Lingual Link Discovery task at NTCIR-9 (Tang etal., 2011) and the Cross-Lingual Entity Linking task?
part of the Knowledge Base Population track ?
atTAC 20117).
In our particular setting, where we usethe metonymy data from SemEval 2007, the domainof the PMW is well defined: locations and compa-nies, respectively.
Using these constraints, findingthe corresponding Wikipedia articles is much sim-plified, by using the category hierarchy and con-straining the concepts to fall under the Geographyand Companies categories respectively.
When mul-tiple options are present, we find instead a matchingdisambiguation page.
In this case we pick the articlethat is listed first on this disambiguation page.
Ona manually checked random sample, the accuracy ofthe approach was 100% (on a sample of 100 PMWs).3.4 Scoring conceptual relations with local andglobal contextWe work under the assumption that the concept cor-responding to the PMW is related to the possible in-terpretations through a semantic relation, in particu-lar one that is captured in the concept network.
After6The format is:Concept name (Concept Id) ?
selectional preference score.7http://nlp.cs.qc.cuny.edu/kbp/2011/countries : Administrator of, Architect of,Based in, Built in, Continent, ...companies : Association, Brand, Company, Dis-tributed by, Executive of, ...Table 1: Example conceptual relationsestablishing the connection to the resource by link-ing the PMW to the concept cPMW corresponding toits literal interpretation (see Section 3.3), we extractthe relations in which it is involved (Ri, i = 1, k),and the concepts it is connected to through these re-lations (CRi = {cx|(cPMWRicx)}).
Table 1 showsexamples of conceptual relations extracted for com-panies and countries.We are interested in computing the likelihood ofa conceptual relation being the correct interpreta-tion of a PMW, given its local and global contextp(Ri|Cont, w, r).3.4.1 The local contextThe local context considered in this work are allgrammatically related verbs and adjectives w andtheir associated grammatical relation r. The gram-matical analysis (see Section 3.2) provides the set ofabstractions corresponding to the grammatically re-lated word w and grammatical relation r: Aj , j =1, n. Remember that these are local context con-straints on the interpretation of the PMW.Through the knowledge resource used we can es-tablish and quantify connections between each cxand Aj , and thus between eachRi and Aj :p(Ri|Aj) =?x?CRip(cx|Aj)(3)where p(cx|Aj) is the probability of concept cx un-der abstraction Aj , which is computed based on thesemantic relations in WikiNet:p(cx|Aj) =?H?hi?Hp(hi|hi+1)whereH is in turn each path from cx toAj followingis a links in WikiNet, starting with cx (i.e.
h0 = cx)and ending in Aj .
p(hi|hi+1) is the probability ofthe child node hi given its ancestor hi+1.
Within thiswork we assume a uniform probability distributionin each node:188p(hi|hi+1) =1|descendants(hi+1)|Through this, it is straightforward that?cx p(cx|Aj) = 1 when cx ranges over allconcepts subsumed by Aj , and is thus a validprobability distribution.3.4.2 The global contextThe abstractions obtained before are concepts.We extract all nodes in the network subsumedby these concepts, and their corresponding articlesin Wikipedia (if they have one).
This produces?abstraction-specific?
article sets, based on whichwe compute the probability of the global context ofa PMW for each abstraction.
We are interested inthe probability of an abstraction, given the contextand the word w and grammatical relation r, whichwe compute as:p(Aj |Cont, w, r) =p(Cont|Aj , w, r) ?
p(Aj , w, r)p(Cont, w, r)which, considering that p(Cont, w, r) is the samefor a given context, we approximate asp(Aj |Cont) ?
p(Cont|Aj) ?
p(Aj , w, r)p(Aj , w, r) = p(Aj |w, r)?p(w, r), and we approxi-mate it through the computed selectional preferencep(Aj |w, r), since p(w, r) is constant for a given ex-ample to analyze.p(Cont|Aj , w, r) =n?j=1p(Cont|Aj)p(Aj |w, r)=n?j=1(m?l=1p(wl|Aj))p(Aj |w, r)where Cont is the global context consisting of mwords wl, l = 1,m.88The global context therefore could be all words in a textor all words in a sentence or any other token-based definitionin our framework.
As the SemEval 2007 data gives metonymicexamples in a three-sentence context we use all the words in the3 sentences as our global context.p(wl|Aj) =count(wl,Aj)|Aj |where Aj is the set of articles subsumed by abstrac-tion Aj , and count(wl,Aj) is the number of timesword wl appears in the article collection Aj .3.4.3 Putting it all togetherThis enables us now to compute p(Ri|Cont, w, r)based on the formulas 3, 4:p(Ri|Cont, w, r) =n?j=1(p(Ri|Aj)?p(Aj |Cont, w, r))4 ExperimentsThe computed probabilities for each conceptual re-lation (= potential readings) of the PMW in the con-cept network can be used as features in a supervisedframework or directly as an unsupervised prediction,returning the most likely conceptual relation giventhe context as the required reading.Although the latter is our ultimate goal, to allowcomparison with related work from the metonymyresolution task (Task 8) at SemEval 2007, we firstinvestigate the supervised set-up.
We then simulatethe unsupervised setting in Section 4.3.4.1 DataWe use the data from the metonymy resolution task(Task 8) at SemEval 2007.
It consists of training andtest data for country and company names which arepotentially metonymic.
Table 2 shows the statisticsof the data, and the possible interpretations for thePMWs.
The training-test division was achieved ran-domly so that the test data can have metonymic read-ings for which no training data exists, showing againthe limitations of a supervised approach of prespec-ified readings.Grammatical features The features used by Nis-sim and Markert (2005), and commonly used forthe supervised classification of metonymy readings(Markert and Nissim, 2009):?
grammatical role of PMW (subj, obj, ...);?
lemmatized head/modifier of PMW (announce,say, ...);189reading train testlocations 925 908literal 737 721mixed 15 20othermet 9 11obj-for-name 0 4obj-for-representation 0 0place-for-people 161 141place-for-event 3 10place-for-product 0 1organizations 1090 842literal 690 520mixed 59 60othermet 14 8obj-for-name 8 6obj-for-representation 1 0org-for-members 220 161org-for-event 2 1org-for-product 74 67org-for-facility 15 16org-for-index 7 3Table 2: Statistics for the Task 8 data?
determiner of PMW (def, indef, bare, demonst,other, ...);?
grammatical number of PMW (sg, pl);?
number of grammatical roles in which thePMW appears in its current context;?
number of words in PMW.All these features can be extracted from the gram-matically annotated and POS tagged data providedby the organizers.The annotations provided are dependency rela-tions, many of which contain a preposition as an ar-gument (e.g.
(to, pp, UK) from the example ... thevisit to the UK of ...).
Such relations are not infor-mative, but together with the head that dominates theprepositional complement (e.g.
visit to) they may be.Because of this, we process the provided annotationsand add wherever possible to the simple prepositionsthe head of their subsuming constituent.
This wouldchange the above mentioned dependency to (visit,prep-to, UK).Semantic relations as features To evaluate theproposed approach we use the PMW?s conceptualrelations as features.
The feature values are thep(Ri|Cont, w, r) scores.For the ?countries?
portion of the data this adds109 semantic relation features, and for companies29 features.
Table 1 showed examples of these newfeatures.4.2 Supervised learningWe use the SMO classifier in the WEKA machinelearning toolkit (Witten and Frank, 2000) with itsstandard settings, training on the SemEval 2007(Task 8) training set.Table 3 shows the results of various configura-tions on the test data, in comparison with a mostfrequent reading baseline (assigning literal to allPMWs) as well as a system M&N that shows the re-sults computed using only the features proposed byNissim and Markert (2005).
In addition, we com-pare to the best results9 at SemEval 2007 (SEmax)and Nastase and Strube (2009) (N09).
Nastase andStrube (2009) added WordNet supersenses as fea-tures, and their values are selectional preferencescomputed with reference to WordNet.
These aresimilar to our abstractions, which in our approachserve to link the local and the global context to theontological relations, but do not appear as features.Our system SP shows the results obtained us-ing the M&N features plus the conceptual relationfeatures conditioned on both local and global con-text whereas SPlocal and SPglobal use conceptualrelations conditioned on local (p(Aj |Cont, w, r) ?p(Aj |w, r)) or global context (p(Aj |Cont, w, r) ?p(Aj |Cont) =?nj=1(?ml=1 p(wl|Aj))) only.While the differences in overall accuracies aresmall, there are significant differences in classifyingindividual classes, as shown in Tables 4 ?
510, wherethe distrib.
column shows the class distribution inthe test data.
It is interesting to note that, in our set-ting, the global context is more useful than the local9We show the best result for each category, not necessarilyfrom the overall best performing system.
This holds for Tables4 and 5 as well.10The detailed results for previous approaches are reproducedfrom (Nastase and Strube, 2009).
We include only the classesthat have a non-zero F-score for at least one of the presentedapproaches.190task ?
method?
baseline SEmax N09 M&N SP SPlocal SPglobal SPunsupLOCATION-COARSE 79.4 85.2 86.1 83.4 85.8 83.0 85.0 81.6LOCATION-MEDIUM 79.4 84.8 85.9 82.3 85.7 82.7 84.6 81.5LOCATION-FINE 79.4 84.4 85.0 81.3 84.7 82.1 83.8 81.0ORGANIZATION-COARSE 61.8 76.7 74.9 74.0 77.0 76.4 76.8 67.8ORGANIZATION-MEDIUM 61.8 73.3 72.4 69.4 74.6 74.0 74.4 66.3ORGANIZATION-FINE 61.8 72.8 71.0 68.5 72.8 71.9 72.7 65.3Table 3: Accuracy scorestask ?
method?
distrib.
SEmax N09 SPLOCATION-COARSEliteral 79.4 91.2 91.6 91.4non-literal 20.6 57.6 59.1 58.5LOCATION-MEDIUMliteral 79.4 91.2 91.6 91.4metonymic 18.4 58.0 61.5 61.6mixed 2.2 8.3 16 9.1LOCATION-FINEliteral 79.4 91.2 91.6 91.4place-for-people 15.5 58.9 61.7 61.1place-for-event 1.1 16.7 0 0obj-for-name 0.4 66.7 0 0mixed 2.2 8.3 16 9.1Table 4: Fine-grained results for each classification taskfor countries (F-scores)one for resolving metonymies.
Combining local andglobal evidence improves over both, indicating thatthe information they provide is not redundant.For companies the difference is small in terms ofaccuracy, but in classification of individual classesthe difference in performance is higher, but becauseof the small data size not statistically significant.Countries in WikiNet have a high number of sur-rounding relations, because they are used as cat-egorization criteria for professionals, for example,which generates fine-grained relations such as Ad-ministrator of, Ambassador of, Chemist of .... Sucha fine grained distinction between different profes-sions for people in a country is not necessary, or in-deed, desirable, for the metonymy resolution task.The results show that despite this shortcoming, theresults are on par with the state-of-the-art, but in fu-ture work we plan to explore the task of relation gen-eralization and its impact on the current task.task ?
method?
distrib.
SEmax N09 SPORGANIZATION-COARSEliteral 61.8 82.5 81.4 82.7non-literal 38.2 65.2 61.6 65.5ORGANIZATION-MEDIUMliteral 61.8 82.5 81.4 82.7metonymic 31.0 60.4 58.7 63.1mixed 7.2 30.8 26.8 27.4ORGANIZATION-FINEliteral 61.8 82.6 81.4 82.7org-for-members 19.1 63.0 59.7 66.5org-for-product 8.0 50.0 44.4 35.0org-for-facility 2.0 22.2 36.3 45.5org-for-name 0.7 80.0 58.8 44.4mixed 7.2 34.3 27.1 27.4Table 5: Fine-grained results for each classification taskfor companies (F-scores)4.3 Simulating unsupervised metonymyresolutionIn an unsupervised metonymy resolution approach,we would assign as interpretation the conceptual re-lation whose probability given the PMW, global andlocal contexts is highest.
To simulate then the un-supervised metonymy resolution task, we make therelation features (used in the supervised approach)binary, where for each instance the relation that hashighest probability has the value 1, the others 0.Using only the relation features simulates an un-supervised approach ?
this set-up learns a map-ping between the relations used as features andthe metonymy classes in the data used.
ColumnSPUnsup in Table 3 shows the results obtained inthis configuration.
As expected the results are lower,but still close to the supervised method when usingonly grammatical features (M&N) for the location191setting.
The results also significantly beat the base-line (apart from the Location-Fine setting).
One fea-ture that contributes greatly to the results, especiallyfor the company semantic class, is the grammaticalrole of the PMW, but we could not incorporate thisin the unsupervised setting.The results in the simulated unsupervised set-ting indicate that relations are a viable substitutefor manually provided classes in an unsupervisedframework, while leaving space for improvement.5 ConclusionWe have explored the usage of local and global con-text for the task of metonymy resolution in a prob-abilistic framework.
The global context has beenrarely used for the task of determining the intendedreading of a potentially metonymic word (PMW)in context.
We rely on automatically computed se-lectional preferences, extracted from a corpus ofWikipedia articles, and generalized based on a con-cept network also extracted from Wikipedia.
De-spite relying on automatically derived resources, thepresented approach produces results on-a-par withcurrent state-of-the-art systems.
The method de-scribed here is also a step towards the unsupervisedresolution of metonymic words in context, by tak-ing into account knowledge about the concept cor-responding to the literal interpretation of the PMW,and its relations to other concepts.
This frame-work would also allow for exploring the metonymyresolution phenomena in various languages (sinceWikipedia and WikiNet are multilingual), and inves-tigate whether the same relations apply or differentlanguages have different metonymic patterns.AcknowledgmentsKatja Markert is the recipient of an Alexander-von-Humboldt Fellowship for Experienced Researchers.This work was financially supported by the EC-funded project CoSyne (FP7-ICT-4-24853) and theKlaus Tschirra Foundation.
We thank the review-ers for the helpful comments, and Helga Kra?mer-Houska for additional support for conference partic-ipation.ReferencesLuisa Bentivogli, Elena Cabrio, Ido Dagan, Danilo Gi-ampiccolo, Medea Lo Leggio, and Bernardo Magnini.2007.
Building textual entailment specialized datasets: A methodology for isolating linguistic phenom-ena relevant to inference.
In Proceedings of the 7thInternational Conference on Language Resources andEvaluation, La Valetta, Malta, 17?23 May 2010.Caroline Brun, Maud Ehrmann, and Guillaume Jacquet.2007.
XRCE-M: A hybrid system for named en-tity metonymy resolution.
In Proceedings of the4th International Workshop on Semantic Evaluations(SemEval-1), Prague, Czech Republic, 23?24 June2007, pages 488?491.Richa?rd Farkas, Eszter Simon, Gyo?rgy Szarvas, andDa?niel Varga.
2007.
GYDER: Maxent metonymy res-olution.
In Proceedings of the 4th International Work-shop on Semantic Evaluations (SemEval-1), Prague,Czech Republic, 23?24 June 2007, pages 161?164.Dan C. Fass.
1991.
met?
: A method for discriminatingmetonomy and metaphor by computer.
ComputationalLinguistics, 17(1):49?90.Sanda M. Harabagiu.
1998.
Deriving metonymic co-ercions from WordNet.
In Proceedings of the Work-shop on the Usage of WordNet in Natural LanguageSystems, Montral, Quebec, Canada, 16 August, 1998,pages 142?148.Jerry Hobbs, Mark Stickel, Douglas Appelt, and PaulMartin.
1993.
Interpretation as abduction.
ArtificialIntelligence, 63(1-2):69?142.Maria Lapata.
2003.
Probabilistic text structuring: Ex-periments with sentence ordering.
In Proceedings ofthe 41st Annual Meeting of the Association for Compu-tational Linguistics, Sapporo, Japan, 7?12 July 2003,pages 545?552.Johannes Leveling and Sven Hartrumpf.
2008.
Onmetonymy recognition for geographic information re-trieval.
International Journal of Geographical Infor-mation Science, 22(3):289?299.Johannes Leveling.
2007.
FUH (FernUniversita?t in Ha-gen): Metonymy recognition using different kinds ofcontext for a memory-based learner.
In Proceedingsof the 4th International Workshop on Semantic Eval-uations (SemEval-1), Prague, Czech Republic, 23?24June 2007, pages 153?156.Hang Li and Naoki Abe.
1998.
Generalizing case framesusing a thesaurus and the MDL principle.
Computa-tional Linguistics, 24(2):217?244.Katja Markert and Udo Hahn.
2002.
Metonymies in dis-course.
Artificial Intelligence, 135(1/2):145?198.Katja Markert and Malvina Nissim.
2009.
Data andmodels for metonymy resolution.
Language Re-sources and Evaluation, 43(2):123?138.192Vivi Nastase and Michael Strube.
2009.
Combiningcollocations, lexical and encyclopedic knowledge formetonymy resolution.
In Proceedings of the 2009Conference on Empirical Methods in Natural Lan-guage Processing, Singapore, 6-7 August 2009, pages910?918.Vivi Nastase, Michael Strube, Benjamin Bo?rschinger,Ca?cilia Zirn, and Anas Elghafari.
2010.
WikiNet:A very large scale multi-lingual concept network.In Proceedings of the 7th International Conferenceon Language Resources and Evaluation, La Valetta,Malta, 17?23 May 2010.Cristina Nicolae, Gabriel Nicolae, and Sanda Harabagiu.2007.
UTD-HLT-CG: Semantic architecture formetonymy resolution and classification of nominal re-lations.
In Proceedings of the 4th International Work-shop on Semantic Evaluations (SemEval-1), Prague,Czech Republic, 23?24 June 2007, pages 454?459.Malvina Nissim and Katja Markert.
2005.
Learning tobuy a Renault and talk to BMW: A supervised ap-proach to conventional metonymy.
In Proceedings ofthe 6th International Workshop on Computational Se-mantics, Tilburg, Netherlands, January 12-14, 2005.Geoffrey Nunberg.
1995.
Transfers of meaning.
Journalof Semantics, 12(1):109?132.Thierry Poibeau.
2007.
Up13: Knowledge-poor meth-ods (sometimes) perform poorly.
In Proceedings ofthe 4th International Workshop on Semantic Evalu-ations (SemEval-1), Prague, Czech Republic, 23?24June 2007, pages 418?421.James Pustejovsky.
1991.
The generative lexicon.
Com-putational Linguistics, 17(4):209?241.Kirk Roberts and Sanda M. Harabagiu.
2011.
Unsuper-vised learning of selectional restrictions and detectionof argument coercions.
In Proceedings of the 2011Conference on Empirical Methods in Natural Lan-guage Processing, Edinburgh, UK, 27-29 July 2011,pages 980?990.Ekaterina Shutova.
2009.
Sense-based interpretation oflogical metonymy using a statistical method.
In Pro-ceedings of the Joint Conference of the 47th AnnualMeeting of the Association for Computational Lin-guistics and the 4th International Joint Conference onNatural Language Processing, Singapore, 2?7 August2009, pages 1?9.Mihai Surdeanu and Christopher D. Manning.
2010.
En-semble Models for Dependency Parsing: Cheap andGood?
In Proceedings of Human Language Tech-nologies 2010: The Conference of the North AmericanChapter of the Association for Computational Linguis-tics, Los Angeles, Cal., 2?4 June 2010, pages 649?652.Ling-Xiang Tang, Shlomo Geva, Andrew Trotman, YueXu, and Kelly Y. Itakura.
2011.
Overview of theNTCIR-9 crosslink task: Cross-lingual link discovery.In Proceedings of the 9th NII Test Collection for IRSystems Workshop meeting ?
NTCIR-9 Tokyo, Japan,6?9 December 2011.Masao Utiyama, Masaki Murata, and Hitoshi Isahara.2000.
A statistical approach to the processingof metonymy.
In Proceedings of the 18th Inter-national Conference on Computational Linguistics,Saarbru?cken, Germany, 31 July ?
4 August 2000,pages 885?891.Ian H. Witten and Eibe Frank.
2000.
Data Mining:Practical Machine Learning Tools and Techniqueswith Java Implementations.
Morgan Kaufmann, SanDiego, CA.193
