Human Language Technologies: The 2015 Annual Conference of the North American Chapter of the ACL, pages 1042?1048,Denver, Colorado, May 31 ?
June 5, 2015.c?2015 Association for Computational LinguisticsMatching Citation Text and Cited Spans in Biomedical Literature:a Search-Oriented ApproachArman Cohan, Luca Soldaini, Nazli GoharianGeorgetown University, Information Retrieval Lab, Computer Science Department{arman, luca, nazli}@ir.cs.georgetown.eduAbstractCitation sentences (citances) to a reference ar-ticle have been extensively studied for sum-marization tasks.
However, citances might notaccurately represent the content of the citedarticle, as they often fail to capture the con-text of the reported findings and can be af-fected by epistemic value drift.
Followingthe intuition behind the TAC (Text AnalysisConference) 2014 Biomedical Summarizationtrack, we propose a system that identifies textspans in the reference article that are relatedto a given citance.
We refer to this problemas citance-reference spans matching.
We ap-proach the problem as a retrieval task; in thispaper, we detail a comparison of different ci-tance reformulation methods and their combi-nations.
While our results show improvementover the baseline (up to 25.9%), their absolutemagnitude implies that there is ample room forfuture improvement.1 IntroductionThe size of scientific literature has increased dra-matically during recent decades.
In biomedical do-main for example, PubMed ?
the largest repositoryof biomedical literature ?
contains more than 24 mil-lion articles.
Thus, there is a need for concise pre-sentation of important findings in the scientific arti-cles being published.
Text summarization of scien-tific articles is a method for such presentation.
Oneobvious form of scientific summaries, is the abstractof the articles.
Another type of scientific summariesrelates to citance-based summaries which are sum-maries created using the set of citations to a refer-ence article.
This kind of summary covers someaspects of the reference article which might not bepresent in its abstract (Elkiss et al, 2008).Citances often cover important and novel insightsabout findings or aspects of a paper that othersReference Article(Voorhoeve et al, 2006): ?These miRNAs neutralize p53-mediatedCDK inhibition, possibly through direct inhibition of the expressionof the tumor suppressor LATS2.
?Citing Article(Okada et al, 2011): ?Two oncogenic miRNAs, miR-372 and miR-373, directly inhibit the expression of Lats2, thereby allowing tu-morigenic growth in the presence of p53 (Voorhoeve et al, 2006).
?Figure 1: Example of epistemic value drift from(De Waard and Maat, 2012).
The claim in (Voorhoeveet al, 2006) becomes fact in (Okada et al, 2011).have found interesting; thus, they capture contribu-tions that had an impact on the research community(Elkiss et al, 2008; Qazvinian and Radev, 2008).In the past, many have focused on citance extrac-tion and citance-based summarization.
Example ofcitance extraction include (Siddharthan and Teufel,2007), who used a machine learning approach withlinguistic, lexical, statistical and positional features,and (Kaplan et al, 2009), who studied a coreferenceresolution based approach.
Citance extraction hasbeen also studied in the context of automatic sum-marization.
For example, (Qazvinian and Radev,2010) proposed a framework based on probabilis-tic inference to identify citances, while (Abu-Jbaraand Radev, 2011) approached the problem as a clas-sification task.
In the biomedical domain, the use ofcitances was first studied by (Nakov et al, 2004).While useful, citances by themselves lack the ap-propriate evidence to capture the exact content ofthe original paper, such as circumstances, data andassumptions under which certain findings were ob-tained.
Citance-based summaries might also modifythe epistemic value of a claim presented in the citedwork (De Waard and Maat, 2012); that is, they mightreport a preliminary result or a claim as a definitefact (example in figure 1).Recently, a new track at TAC has been introducedto explore ways to generate better citance-based1042summaries1.
One way to achieve this, is to link ci-tances to text spans in the reference article to ob-tain a more informative collection of sentences rep-resenting the reference article (figure 2).
A frame-work designed to solve such problem requires twocomponents: (i) a method to identify the most rel-evant spans of text in the reference text and (ii) asystem to automatically generate a summary given aset of citances and reference spans.In this paper, we propose an information retrievalapproach designed to address the first task.
We ex-plore the impact of several query reformulation tech-niques ?
some domain independent, others tailoredto biomedical literature ?
on the performance of thesystem.
Furthermore, we apply combined refor-mulations, which yields an additional improvementover any single method (25% over the baseline).As a related area, passage retrieval in biomedicalarticles has been studied in the context of the ge-nomics track (Hersh et al, 2006; Hersh et al, 2007)and in following efforts (Urbain et al, 2008; Urbainet al, 2009; Chen et al, 2011).
In these works, thegoal is to find passages that relate to a given termor keyword (e.g.
GeneRIF).
In contrast, our systemconsiders citances as queries, which are substan-tially longer than keyword-based queries and havea syntactical structure.In summary, our contributions are: (i) Asearch-based, unsupervised (thus easily scalable toother domains) approach to citance-reference spansmatching and (ii) adaptation of various query refor-mulation techniques for the citatnce-refrence spanmatching.2 MethodologyThe goal of the proposed system is to retrieve textspans from the reference paper that match the find-ing(s) each citance is referring to.
We approach thisproblem as a search task.
That is we consider the ci-tance as a query and the reference text spans as doc-uments.
Then, using a retrieval model along withquery reformulation, we find the most relevant textspans to a given citance.
Our methodology consistof the following steps:1.
Create sentence level index from the referencearticle.1http://www.nist.gov/tac/2014/BiomedSumm/Citing Article Reference Article...Indeed, shRNA knockdown of Myc in iKrasPDAC cells significantly downregulated theexpression of metabolism genes in the glycolysis,HBP, and nonoxidative PPP pathways (FiguresS7E and S7F).
Another possible candidatemediator of Kras-induced transcriptional changesof metabolism genes was HIF1?.
Although therewas some enrichment of HIF1?
promoterelements in the Kras transcriptional changes,knockdown of HIF1?
had only minimal impacton metabolic enzyme expression (data notshown).
Together, our data indicates that theMAPK pathway and Myc-directed transcriptionalcontrol play key roles for KrasG12D-mediatedmetabolic reprogramming in PDAC?
?There has been much interest recently in therevival of the suggestion that altered metabolismcan contribute to, as well as respond to,oncogenic transformation.
Several elegant studieshave illustrated the importance of metabolictransformation in cancer development (Freed-Pastor et al, 2012; Locasale et al, 2011; Schaferet al, 2009; Ying et al, 2012), although there islimited information about how these metabolicchanges may impact on tumorigenicity in vivo.The regulation of glucose metabolism by TIGARmay have several important consequences; whilethe contribution of TIGAR to antioxidant activityhas been shown in several cell systems (Bensaadet al, 2006; Li and Jogl, 2009; Wanka et al,2012)?Citance Article Reference Article(Cheung et al, 2013) (Ying et al, 2012)Figure 2: Example of a citance/reference article pair fromthe TAC training set1.
The text in the red box on the left isreferred to as the citance text, while the text in the greenboxes on the right is referred to as the reference text.2.
Apply query reformulation to the given citanceand retrieve the most relevant spans.3.
Rerank and merge the retrieved spans that cor-rectly describe the citance.We will describe each step in the following sections.2.1 Creating the indexTo create an index of spans, each reference arti-cle is tokenized at a sentence level using the Punkttokenize (Kiss and Strunk, 2006).
Because eachrelevant reference span in the reference text can beformed by several consecutive sentences (accordingto the annotation guidelines, each span can consistof one up to five consecutive sentences), we indextext spans comprised of one up to five sentences.2.2 Retrieval modelWe evaluated the performance of several retrievalmodels during experimentation, i.e.
vector spacemodel (Salton et al, 1975), probabilistic BM25(Robertson and Zaragoza, 2009), divergence fromrandomness (DFR) (Amati and Van Rijsbergen,2002), and language models (Ponte and Croft, 1998)with Dirichlet priors.
All models showed very sim-ilar performances (with only DFR constantly under-performing all other models) and we did not observeany statistically significant differences between eachset of runs.
Therefore, we opted for the vector spacemodel as our retrieval model.2.3 Query reformulationWe apply several query reformulation techniquesto the citance to better retrieve the related textspans.
We leverage both general and domain specificquery reformulations for this purpose.
Specifically,1043we use biomedical concepts, ontology information,keyphrases and the syntactic structure of the citance.2.3.1.
Unmodified query (baseline): The citanceafter removing stop words, numeric values and cita-tion markers (i.e.
the actual indicator of the citation)serves as our baseline.2.3.2.
Biomedical concepts (UMLS-reduce): Weremove from the query those terms that do not mapto any medical concept in the UMLS1metathesaurus.We use MetaMap (Aronson, 2001) to map biomed-ical expressions in the citances to UMLS concepts.More specifically, our heuristic greedily matches thelongest expressions in the citance to concepts inthe UMLS metathesaurus; such strategy was deemedthe most appropriate after experimenting with var-ious matching approaches.
We limited the scopeof UMLS-reduce to SNOMED Clinical Terms (Boset al, 2006) collection of UMLS and the ?preferredconcepts?
(i.e., concepts that are determined by theNational Library of Medicine to provide the bestrepresentation for a concept); terms that are notmapped to any UMLS concept were removed.2.3.3.
Noun phrases (NP): Citances include manyimportant biological concepts, often appearing asnoun phrases.
For this reason, we reformulate ci-tance by only keeping noun phrases and filtering outother parts of speech.
We retain noun phrases thatconsist of up to 3 terms, as longer phrases were em-pirically determined to be too specific.
Stopwordsare removed from noun phrases.2.3.4.
Keyword based (KW): We consider a statis-tical measure for identifying key terms in the ci-tance.
Specifically, we computed the idf2of theterms in the citance in a domain-specific corpus toevaluate their importance.
Given the domain of ourdataset, we used the Open Access Subset of PubMedCentral3.
We filter out the terms whose idf value isless than a fixed threshold (after empirical evalua-tion, this threshold was set to 2.5).2.3.5.
Biomedical expansion (UMLS-expand): Theterminology used by the citing author and the refer-enced author is not necessarily identical.
Multiple1http://www.nlm.nih.gov/research/umls/2Inverted Document Frequency3http://www.ncbi.nlm.nih.gov/pmc/terms or multi-word expressions can be mapped tothe same concepts and each author might use theirown choice of terms for describing a concept.
In thisapproach, we add related terminology to the impor-tant concepts in the citance to solve this issue.
Sinceour dataset consists of articles from biomedical lit-erature, we took advantage of the UMLS metathe-saurus to expand terms or multi-word expressionswith their synonyms.
We did not enforce any thresh-old for the number of terms added by UMLS-expand.However, in order to prevent query drift, we ex-panded citances using only UMLS?s ?preferred con-cepts?
and concepts from the ?SNOMED ClinicalTerms?
(SNOMED CT) terminology.2.3.6.
Combined reformulation: Due to the nar-rative structure of citances and their relative longlength, using all citance terms for expansion is likelyto cause query drift.
Therefore, we first reduce thecitance using one of previously described reductionapproaches and then apply query expansion.
In de-tail, we evaluated the combination of noun phrasesand UMLS expansion, as well as UMLS reduction andexpansion.2.4 Combining retrieved spansDue to our indexing strategy described in sec-tion 2.1, some text spans retrieved by the searchengine could overlap with each other.
Intuitively,if a span containing multiple contiguous sentences{s1, .
.
.
, sl} is retrieved alongside any of its con-stituent sentences si, its relevance score should beincreased to account for the relevance of si.We exploited such intuition by adding the scoreof each span with the score of any of the constituentsentences or sub-spans retrieved alongside it.
Af-ter the score is updated, the constituent sentences orsub-spans are removed from the list of retrieved re-sults.
Finally, because the number of reference spansindicated by the annotators in our data set is at mostthree, the system returns the top three results.It is worth mentioning that we also looked atsome other query reformulation approaches such aspseudo relevance feedback (Buckley et al, 1995)and Wikipedia based biomedical term filtering (Co-han et al, 2014); however, our experimentationsshould that these methods performed substantiallyworse than the baseline, consequently, we do not re-port those results nor their relevant discussions.1044Type of agreement Count Average overlapFull agreement 2 100%Partial agreement betweenall annotators 66 21.7?
15.4%Partial agreement betweena majority of annotators 121 19.2?
11.4%Partial agreement betweena minority of annotators 113 27.0?
15.9%No agreement at all 11 0%Table 1: Levels of agreement between annotators.
The4 annotators fully agree on just 2 of the 313 annotations.In most cases, a majority (3 annotators) or a minority (2annotators) agrees on a portion of reference spans, indi-cating that the task is not trivial even for domain experts.3 Evaluation and DatasetThe system was evaluated on TAC 2014 Biomedi-cal Summarization track training dataset.
It consistsof 20 topics, each of which contains between 10 to20 citing articles and 1 reference article.
For eachtopic, four domain experts were asked to identifythe appropriate reference spans for each citance inthe reference text.
To better understand the dataset,we analyzed the agreement between annotators (ta-ble 1).
This table shows that the overall agreementis relatively low.We used two sets of metrics for evaluation of thetask.
The first one is based on the weighted overlapsbetween the retrieved spans and the correct spansdesignated by annotators and is meant to rewardspans overlapping with the ground truth.
Weightedrecall and precision for a system returning span Swith respect to a set of M annotators, consisting ofgold spans G1, ..., GMare defined as follows:Recalldef=?Mi=1|S ?Gi|?Mi=1|Gi|Precdef=?Mi=1|S ?Gi|M ?
|S|(1)The overall score of the system is the mean F-1(harmonic mean of the weighted precision and re-call) over all the topics.Based on the weighted F-1 score, a method couldbe penalized for retrieving any spans that are notindicated as gold spans by the annotators.
Evenif those spans are semantically similar to the goldspans, they will not receive any score.
This is notideal because, as the high disagreement shown intable 1 implies, gold spans by offset locations arehighly controversial.
For this reason, we also con-sidered ROUGE-L (Lin, 2004) as another evalua-tion metric, as it rewards a method for retrievingspans that are similar to the gold spans.
Specifically,ROUGE-L, takes into account the sentence similar-ity by considering the longest in sequence n-gramsbetween the retrieved spans and gold spans.4 Results and discussionThe problem of matching citations with cited spansin scientific articles is a new task and to the bestof our knowledge, there is no prior work on thistask.
Thus to evaluate the effectiveness of our differ-ent methods, we compared the performance of ourproposed approaches against the unmodified querybaseline.
The results are shown in Table 2.Interestingly, we observe that UMLS-reduce per-forms worse than the baseline in terms of F-1.
Thiscan be attributed to the fact that multiple expressionsin the biomedical literature can be used to refer tothe same concept.
Such diversity is not captured byUMLS-reduce, as it only performs query reduction.Moreover, a citance often contains expressions that,while not mapping to any biomedical concepts, pro-vide useful context and therefore are fundamental inconveying the meaning of the citance (we will re-fer to such expressions as supporting expressions inthe reminder of the paper).
These supporting expres-sions are not captured by UMLS-reduce.NP outperforms the baseline (+18.8% F-1).
Thisoutcome is expected, as most important biomedicalconcepts in the citance are noun phrases.
Moreover,supporting expressions are also captured, as most ofthem are noun phrases.KW also shows promising results (+11.5% F-1and +15.2% ROUGE-L F-1 improvement), provingthat the idf of the terms in citance over a largebiomedical corpus is a valid measure of their infor-mativeness for this task.When comparing KW and NP, we notice that theformer obtains higher precision values than the lat-ter; this outcome is reversed with respect to recall(i.e., NP?s recall is higher than KW?s).
Such behav-ior can be motivated by the fact that NP, as it ex-tracts noun phrases that are likely to appear in thegold reference span, has a higher chance of retriev-ing relevant sections of the reference text.
However,NP is more likely to retrieve non-relevant spans, asthe extracted noun phrases, which are often describ-ing the main findings of the cited paper, are preva-1045Recall Precision F-1 ROUGE-L Recall ROUGE-L Prec ROUGE-L F-1baseline 0.169 0.152 0.156 0.496 0.200 0.280UMLS-reduce 0.132 (-22.0%) 0.146 (-4.08%) 0.136 (-12.5%) 0.496 (0.0%) 0.224* (12.0%) 0.293 (4.8%)KW 0.173* (3.0%) 0.193** (27.6%) 0.174** (11.5%) 0.491 (-0.1%) 0.273** (36.3%) 0.323** (15.2%)NP 0.199** (18.3%) 0.178** (17.6%) 0.185** (18.8%) 0.550** (11.1 %) 0.211* (5.5 %) 0.280 (0.0%)UMLS-expand 0.182** (8.1%) 0.148 (-2.1%) 0.160* (3.2 %) 0.498 (0.5%) 0.245** (22.2%) 0.315** (12.3%)UMLS-reduce +UMLS-expand 0.201** (19.6%) 0.179** (18.0%) 0.187** (20.0%) 0.558** (12.6 %) 0.209** (4.4 %) 0.293* (4.4%)NP +UMLS-expand 0.180* (7.1%) 0.224** (47.8%) 0.196** (25.9%) 0.501 (1.13%) 0.280** (39.9%) 0.333** (18.8%)Table 2: Results for reference span matching; KW: reduction using KeyWords; NP: reduction using Noun Phrases;UMLS-expand: expansion using UMLS; UMLS-reduce: reduction using UMLS; * (**) indicates statistical significanceat p < 0.05 (p < 0.01) using student?s t-test over the baseline.lent throughout the reference article.
On the otherhand, KW selects highly discriminative terms whichare highly effective in retrieving some relevant ref-erence spans, but might not appear in others.We observe that UMLS-expand, by adding relatedconcepts to the query, achieves significant improve-ment over the baseline in terms of recall (+8.1%).Such improvement is expected, as UMLS-expandaugments the citance with all possible formulationsof the detected biomedical concepts.
However, itsprecision is only comparable with the baseline, as itdoes not remove any noisy terms from the citance.Interestingly, we notice that its ROUGE-L precisiongreatly outperforms the baseline (+22.2%).
This be-havior is motivated by the fact that UMLS-expand,even when not retrieving all the correct referencespans, extracts certain parts of the reference articlesthat share many biomedical concepts with the goldspans, thus achieving high structural similarity.The two combined methods (NP + UMLS-expandand UMLS-reduce + UMLS-expand) obtain the bestoverall performance compared to the baseline.UMLS-reduce + UMLS-expand obtains the highestrecall among all methods.
This outcome directlydepends on the fact that all the synonyms of a cer-tain biomedical concept are captured using UMLS-expand.
However, unlike UMLS-expand, this com-bined method also achieves statistically significantimprovement in terms of precision, as UMLS-reduceremoves terms that can cause query drift.NP + UMLS-expand has the highest overall per-formance, achieving a 25.9% increase over the base-line in terms of F-1, and an 18.8% increase in termsof ROUGE-L F-1.
As previously mentioned, nounphrases are highly effective in identifying relevantbiomedical concepts, as well as supporting expres-sions.
Given the addition of UMLS-expand, syn-onyms of the extracted noun phrases are also con-sidered, further increasing the chance of retrievingrelevant reference spans.The limited performance of all methods in termsof the overall weighted F-1 and ROUGE-L scores isexpected due to the difficulty of the task, as furthercorroborated by the low agreement between annota-tors.
As previously stated, this makes the task partic-ularly challenging for any system, as identifying themost appropriate reference spans is highly nontriv-ial even for domain experts.
Nevertheless, while fullagreement between domain experts is not present,as it is shown in table 1, more than 60% of the time,annotators agree ?
at least partially ?
on the positionof the reference spans.
This makes the task worthexploring.5 ConclusionIn this paper, we propose an information retrievalapproach for the problem of matching reference textspans with citances.
Our approach takes advan-tage of several general and domain specific queryreformulation techniques.
Our best performingmethod obtains a significant increase over the base-line (25.9% F-1).
However, as the absolute perfor-mance of the system indicates, the task of identify-ing matching reference spans to a given citance ishighly non trivial.
This fact is also reflected by thehigh disagreement between domain experts annota-tions and suggests that further exploration of the taskis needed.AcknowledgmentsThis work was partially supported by NSF (grantCNS-1204347).1046ReferencesAbu-Jbara, A. and Radev, D. (2011).
Coherent citation-based summarization of scientific papers.
In Pro-ceedings of the 49th Annual Meeting of the Associa-tion for Computational Linguistics: Human LanguageTechnologies-Volume 1, pages 500?509.
Associationfor Computational Linguistics.Amati, G. and Van Rijsbergen, C. J.
(2002).
Probabilis-tic models of information retrieval based on measuringthe divergence from randomness.
ACM Transactionson Information Systems (TOIS), 20(4):357?389.Aronson, A. R. (2001).
Effective mapping of biomedicaltext to the umls metathesaurus: the metamap program.In Proceedings of the AMIA Symposium, page 17.American Medical Informatics Association.Bos, L. et al (2006).
Snomed-ct: The advanced termi-nology and coding system for ehealth.
Stud HealthTechnol Inform, 121:279?290.Buckley, C., Singhal, A., Mitra, M., and Salton, G.(1995).
New retrieval approaches using smart: Trec4.
In Proceedings of the Fourth Text REtrieval Confer-ence (TREC-4), pages 25?48.Chen, R., Lin, H., and Yang, Z.
(2011).
Passage retrievalbased hidden knowledge discovery from biomedi-cal literature.
Expert Systems with Applications,38(8):9958?9964.Cheung, E. C., Athineos, D., Lee, P., Ridgway, R. A.,Lambie, W., Nixon, C., Strathdee, D., Blyth, K., San-som, O. J., and Vousden, K. H. (2013).
Tigar is re-quired for efficient intestinal regeneration and tumori-genesis.
Developmental cell, 25(5):463?477.Cohan, A., Soldaini, L., and Goharian, N. (2014).
To-wards citation-based summarization of biomedical lit-erature.
Proceedings of the Text Analysis Conference(TAC ?14).De Waard, A. and Maat, H. P. (2012).
Epistemic modal-ity and knowledge attribution in scientific discourse:A taxonomy of types and overview of features.
InProceedings of the Workshop on Detecting Structurein Scholarly Discourse, pages 47?55.
Association forComputational Linguistics.Elkiss, A., Shen, S., Fader, A., Erkan, G., States, D., andRadev, D. (2008).
Blind men and elephants: Whatdo citation summaries tell us about a research article?Journal of the American Society for Information Sci-ence and Technology, 59(1):51?62.Hersh, W. R., Cohen, A. M., Roberts, P. M., and Reka-palli, H. K. (2006).
Text retrieval conference 2006 ge-nomics track overview.
In TREC.Hersh, W. R., Cohen, A. M., Ruslen, L., and Roberts,P.
M. (2007).
Text retrieval conference 2007 genomicstrack overview.
In TREC.Kaplan, D., Iida, R., and Tokunaga, T. (2009).
Auto-matic extraction of citation contexts for research papersummarization: A coreference-chain based approach.In Proceedings of the 2009 Workshop on Text and Ci-tation Analysis for Scholarly Digital Libraries, pages88?95.
Association for Computational Linguistics.Kiss, T. and Strunk, J.
(2006).
Unsupervised multilingualsentence boundary detection.
Computational Linguis-tics, 32(4):485?525.Lin, C.-Y.
(2004).
Rouge: A package for automatic eval-uation of summaries.
In Text Summarization BranchesOut: Proceedings of the ACL-04 Workshop, pages 74?81.Nakov, P. I., Schwartz, A. S., and Hearst, M. (2004).Citances: Citation sentences for semantic analysisof bioscience text.
In Proceedings of the SIGIR?04workshop on Search and Discovery in Bioinformatics,pages 81?88.Okada, N., Yabuta, N., Suzuki, H., Aylon, Y., Oren,M., and Nojima, H. (2011).
A novel chk1/2?lats2?14-3-3 signaling pathway regulates p-body formationin response to uv damage.
Journal of cell science,124(1):57?67.Ponte, J. M. and Croft, W. B.
(1998).
A language model-ing approach to information retrieval.
In Proceedingsof the 21st annual international ACM SIGIR confer-ence on Research and development in information re-trieval, pages 275?281.
ACM.Qazvinian, V. and Radev, D. R. (2008).
Scientific papersummarization using citation summary networks.
InProceedings of the 22Nd International Conference onComputational Linguistics - Volume 1, COLING ?08,pages 689?696, Stroudsburg, PA, USA.
Associationfor Computational Linguistics.Qazvinian, V. and Radev, D. R. (2010).
Identifying non-explicit citing sentences for citation-based summariza-tion.
In Proceedings of the 48th annual meeting of theassociation for computational linguistics, pages 555?564.
Association for Computational Linguistics.Robertson, S. and Zaragoza, H. (2009).
The probabilisticrelevance framework: BM25 and beyond.
Now Pub-lishers Inc.Salton, G., Wong, A., and Yang, C.-S. (1975).
A vectorspace model for automatic indexing.
Communicationsof the ACM, 18(11):613?620.Siddharthan, A. and Teufel, S. (2007).
Whose idea wasthis, and why does it matter?
attributing scientificwork to citations.
In HLT-NAACL, pages 316?323.Citeseer.Urbain, J., Frieder, O., and Goharian, N. (2009).
Passagerelevance models for genomics search.
BMC bioinfor-matics, 10(Suppl 3):S3.1047Urbain, J., Goharian, N., and Frieder, O.
(2008).
Prob-abilistic passage models for semantic search of ge-nomics literature.
Journal of the American Society forInformation Science and Technology, 59(12).Voorhoeve, P. M., Le Sage, C., Schrier, M., Gillis, A. J.,Stoop, H., Nagel, R., Liu, Y.-P., Van Duijse, J., Drost,J., Griekspoor, A., et al (2006).
A genetic screen im-plicates mirna-372 and mirna-373 as oncogenes in tes-ticular germ cell tumors.
Cell, 124(6):1169?1181.Ying, H., Kimmelman, A. C., Lyssiotis, C. A., Hua,S., Chu, G. C., Fletcher-Sananikone, E., Locasale,J.
W., Son, J., Zhang, H., Coloff, J. L., et al (2012).Oncogenic kras maintains pancreatic tumors throughregulation of anabolic glucose metabolism.
Cell,149(3):656?670.1048
