Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 211?219,Gothenburg, Sweden, April 26-30 2014.c?2014 Association for Computational LinguisticsFrame Semantic Tree Kernels for Social Network Extraction from TextApoorv AgarwalDept.
of Computer ScienceColumbia UniversityNew York, NY, USASriramkumar BalasubramanianDept.
of Computer ScienceColumbia UniversityNew York, NY, USAAnup KotalwarMicrosoft, Inc.Redmonad, WA, USAJiehan ZhengThe Peddie SchoolHightstown, NJ, USAOwen RambowCCLSColumbia UniversityNew York, NY, USAapoorv@cs.columbia.eduAbstractIn this paper, we present work on ex-tracting social networks from unstructuredtext.
We introduce novel features de-rived from semantic annotations based onFrameNet.
We also introduce novel se-mantic tree kernels that help us improvethe performance of the best reported sys-tem on social event detection and classi-fication by a statistically significant mar-gin.
We show results for combining themodels for the two aforementioned sub-tasks into the overall task of social net-work extraction.
We show that a combina-tion of features from all three levels of ab-stractions (lexical, syntactic and semantic)are required to achieve the best performingsystem.1 IntroductionSocial network extraction from text has recentlybeen gaining a considerable amount of attention(Agarwal and Rambow, 2010; Elson et al., 2010;Agarwal et al., 2013a; Agarwal et al., 2013b; Heet al., 2013).
One of the reason for this attention,we believe, is that being able to extract social net-works from unstructured text may provide a pow-erful new tool for historians, political scientists,scholars of literature, and journalists to analyzelarge collections of texts around entities and theirinteractions.
The tool would allow researchers toquickly extract networks and assess their size, na-ture, and cohesiveness, a task that would otherwisebe impossible with corpora numbering millions ofdocuments.
It would also make it possible to makefalsifiable claims about these networks, bringingthe experimental method to disciplines like his-tory, where it is still relatively rare.In our previous work (Agarwal et al., 2010),we proposed a definition of a network based oninteractions: nodes are entities and links are so-cial events.
We defined two broad types of links:one-directional links (one person thinking aboutor talking about another person) and bi-directionallinks (two people having a conversation, a meet-ing, etc.).
For example, in the following sen-tence, we would add two links to the network: aone-directional link between Toujan Faisal andthe committee, triggered by the word said (be-cause Toujan is talking about the committee) anda bi-directional link between the same entities trig-gered by the word informed (a mutual interaction).
(1) [Toujan Faisal], 54, said [she] was informedof the refusal by an [Interior Ministry com-mittee] overseeing election preparations.In this paper, we extract networks using theaforementioned definition of social networks.
Weintroduce and add tree kernel representations andfeatures derived from frame-semantic parses toour previously proposed system.
Our results showthat hand-crafted frame semantic features, whichare linguistically motivated, add less value tothe overall performance in comparison with theframe-semantic tree kernels.
We believe this is dueto the fact that hand-crafted features require frameparses to be highly accurate and complete.
In con-trast, tree kernels are able to find and leverage lessstrict patterns without requiring the semantic parseto be entirely accurate or complete.Apart from introducing semantic features andtree structures, we evaluate on the task of socialnetwork extraction, which is a combination of twosub-tasks: social event detection and social eventclassification.
In our previous work (Agarwal andRambow, 2010), we presented results for the two211sub-tasks, but no evaluation was presented for thetask of social network extraction.
We experimentwith two different designs of combining modelsfor the two sub-tasks: 1) One-versus-All and 2)Hierarchical.
We find that the hierarchical de-sign outperforms the more commonly used One-versus-All by a statistically significant margin.Following are the contributions of this paper:1.
We design and propose novel frame semanticfeatures and tree-based representations andshow that tree kernels are well suited to workwith noisy semantic parses.2.
We show that in order to achieve the bestperforming system, we need to include fea-tures and tree structures from all levels ofabstractions, lexical, syntactic, and semantic,and that the convolution kernel framework iswell-suited for creating such a combination.3.
We combine the previously proposed sub-tasks (social event detection and classifica-tion) into a single task, social network ex-traction, and show that combining the mod-els using a hierarchical design is significantlybetter than the one-versus-all design.The rest of the paper is structured as follows:In Section 2, we give a precise definition of thetask and describe the data.
In Section 3, we givea brief overview of frame semantics and motivatethe need to use frame semantics for the tasks ad-dressed in this paper.
In Section 4, we presentsemantic features and tree kernel representationsdesigned for the tasks.
In Section 5, we brieflyreview tree kernels and support vector machines(SVM).
In Section 6 we present experiments anddiscuss the results.
In Section 7 we discuss relatedwork.
We conclude and give future directions ofwork in Section 8.2 Data and Task DefinitionIn Agarwal et al.
(2010), we presented the annota-tion details of social events on a well-known cor-pus ?
Automated Content Extraction1(ACE2005).We defined a social event to be a happening be-tween two entities (of type person) E1 and E2(E1 6= E2), in which at least one entity is cog-nitively aware of the other and of the happen-ing taking place.
We defined two broad cate-1Version: 6.0, Catalog number: LDC2005E18No-Event INR OBS# of Examples 1,609 199 199Table 1: Data distribution; INR are interaction so-cial events.
OBS are observation social events.gories of social events: Interaction (INR) and Ob-servation (OBS).
In a social event of type INR,the two participating entities are mutually awareof each other, i.e., INR is a bi-directional socialevent.
For example, meetings and dinners are so-cial events of type interaction.
In a social event oftype OBS, only one of the two participating enti-ties is aware of the other and therefore, OBS is aone-directional social event, directed from the en-tity that is aware of the other to the other entity.For example, thinking about someone, or missingsomeone are social events of type OBS.
Table 1shows the distribution of the data.
There are 199INR type of social events, 199 OBS events, and1,609 pairs of entity mentions have no event be-tween them.Task definition : The task is, given a pair of en-tity mentions in a sentence, to predict if the en-tities are participating in a social event or not(social event detection, SED), and if they are, tofurther predict the type of social event (INR orOBS, social event classification, SEC).
In this pa-per, we evaluate our system on the above tasks aswell as a combined task: social network extraction(SNE): given a sentence and a pair of entity men-tions, predict the class of the example from one ofthe following three categories: {No-Event, INR,OBS}.For the purposes of this paper, we use goldnamed entity mentions to avoid errors caused dueto named entity recognition systems.
This is acommon practice used in the literature for re-porting relation extraction systems (Zelenko etal., 2003; Kambhatla, 2004; Zhao and Grishman,2005; GuoDong et al., 2005; Harabagiu et al.,2005; Nguyen et al., 2009).
We use standard ter-minology from the literature to refer to the pair ofentities mentions as target entities T1and T2.3 Frame Semantics and FrameNetFrameNet (Baker et al., 1998) is a resource whichassociates words of English with their meaning.Word meanings are based on the notion of ?se-mantic frame?.
A frame is a conceptual descrip-tion of a type of event, relation, or entity, and it212includes a list of possible participants in terms ofthe roles they play; these participants are called?frame elements?.
Through the following exam-ple, we present the terminology and acronyms thatwill be used throughout the paper.Example (2) shows the frame annotations forthe sentence Toujan Faisal said she was informedof the refusal by an Interior Ministry committee.One of the semantic frames in the sentence isStatement.
The frame evoking element (FEE) forthis frame is said.
It has two frame elements (FE):one of type Speaker (Toujan Faisal) and the otherof type Message (she was informed ... by an Inte-rior Ministry committee).
(2) [FE?SpeakerToujan Faisal] [FEE?Statementsaid] [FE?Messageshe was informed of therefusal by an Interior Ministry committee]In example (2), the speaker of the message (ToujanFaisal) is mentioning another group of people (theInterior Ministry committee) in her message.
Bydefinition, this is a social event of type OBS.
Ingeneral, there is an OBS social event between anySpeaker and any person mentioned in the frameelement Message of the frame Statement.
Thisclose relation between frames and social events isthe reason for our investigation and use of framesemantics for the tasks addressed in this paper.4 Feature space and data representationWe convert examples2into two kinds of structuredrepresentations: feature vectors and tree struc-tures.
Each of these structural representations maybroadly be categorized into one or more of the fol-lowing levels of abstraction: {Lexical, Syntactic,Semantic}.
Table 2 presents this distribution.
Ourfinal results show that all of our top performingmodels use a data representation that is a combi-nation of features and structures from all levels ofabstraction.
We review previously proposed fea-tures and tree structures in subsections 4.1, 4.2,and 4.3.
To the best of our knowledge, the re-maining features and structures presented in thissection are novel.4.1 Bag of words (BOW)We create a vocabulary from our training databy using the Stanford tokenizer (Klein and Man-ning, 2003) followed by removal of stop words2An input example is a sentence with a pair of entity men-tions between whom we predict and classify social events.and Porter Stemming.
We convert each example(~x) to a set of three boolean vectors: {~b1,~b2,~b3}.~b1is the occurrence of words before the first tar-get,~b2between the two targets and~b3after the sec-ond target.
Here the first target and second targetare defined in terms of the surface order of words.Though these features have been previously pro-posed for relation extraction on ACE (GuoDonget al., 2005), they have not been utilized for thetask we address in this paper.4.2 Syntactic structures (AR2010)In Agarwal and Rambow (2010), we exploreda wide range of syntactic structures for the twotasks of social event detection (SED) and classi-fication (SEC).
All our previous structures werederived from a variation of two underlying treestructures: phrase structure trees and depen-dency trees.
The best structure we proposed wasPET_GR_SqGRW, which was a linear combina-tion of two tree kernels and one word kernel: 1)a structure derived from a phrase structure tree(PET); 2) a grammatical role tree (GR), which isa dependency tree in which words are replacedwith their grammatical roles; and 3) a path fromone entity to the other in a dependency tree, inwhich grammatical roles of words are inserted asadditional nodes between the dependent and par-ent (SqGRW).
We refer the reader to Agarwaland Rambow (2010) for details of these structures.For the rest of the paper, we refer to this struc-ture, PET_GR_SqGRW, as ?AR2010?.
We useAR2010 as one of our baselines.4.3 Bag of frames (BOF)We use Semafor (Chen et al., 2010) for obtainingthe semantic parse of a sentence.
Semafor foundinstances of 1,174 different FrameNet frames inour corpus.
Each example (~x) is converted to avector of dimension 1,174, in which xi(the ithcomponent of vector ~x) is 1 if the frame numberi appears in the example, and 0 otherwise.4.4 Hand-crafted semantic features (RULES)We use the manual of the FrameNet resource tohand-craft 199 rules that are intended to detect thepresence and determine the type of social eventsbetween two entities mentioned in a sentence.
Anexample of one such rule is given in section 3,which we reformulate here.
We also present an-other example:213Feature Vectors Tree StructuresBOW BOF RULES AR2010 FrameForest FrameTree FrameTreePropLexical !
!
!Syntactic !
!Semantic (novel) !
!
!
!
!Table 2: Features and tree structures and the level of abstraction they fall into.
(3) If the frame is Statement, and the first tar-get entity mention is contained in the FESpeaker, and the second is contained in theFE Message, then there is an OBS socialevent from the first entity to the second.
(4) If the frame is Commerce_buy, and one tar-get entity mention is contained in the FEBuyer, and the other is contained in the FESeller, then there is an INR social event be-tween the two entities.Each rule corresponds to a binary feature: ittakes a value 1 if the rule fires for an input ex-ample, and 0 otherwise.
Consider the followingsentence:(5) [Coleman]T1?Ind{claimed}[he]T1?
?Ind{bought} drugs from the[defendants]T2?Grp.In this sentence, there are two social events:1) an OBS event triggered by the word claimedbetween Coleman and defendants and 2) an INRevent triggered by the word bought between he(co-referential with Coleman) and the defendants.Semafor correctly detects two frames in thissentence: 1) the frame Statement, with Colemanas Speaker, and he bought ... defendants as Mes-sage, and 2) the frame Commerce_buy, with he asthe Buyer, drugs as the Goods and the defendantsas the Seller.
Both hand-crafted rules (3 and 4)fire and the corresponding feature values for theserules is set to 1.
Firing of these rules (and thusthe effectiveness these features) is of course highlydependent on the fact that Semafor provides an ac-curate frame parse for the sentence.4.5 Semantic trees (FrameForest,FrameTree, FrameTreeProp)Semafor labels text spans in sentences as frameevoking elements (FEE) or frame elements (FE).A sentence usually has multiple frames and theframe annotations may overlap.
There may be twoways in which spans overlap (Figure 1): (a) oneFigure 1: Two overlapping scenarios for frame an-notations of a sentence, where F1, F2 are frames.frame annotation is completely embedded in theother frame annotation and (b) some of the frameelements overlap (in terms of text spans).
We nowpresent the three frame semantic tree kernel rep-resentations that handle these overlapping issues,along with providing a meaningful semantic ker-nel representation for the tasks addressed in thispaper.For each of the following representations,we assume that for each sentence s, we havethe set of semantic frames, Fs= {F =?FEE, [FE1, FE2, .
.
.
, FEn]?}
with each frameF having an FEE and a list of FEs.
.
We illustratethe structures using sentence (5).4.5.1 FrameForest Tree RepresentationWe first create a tree for each frame annota-tion F in the sentence.
Consider a frame,F = ?FEE, [FE1, FE2, .
.
.
, FEn]?.
For thepurposes of tree construction, we treat FEE asanother FE (call it FE0) of type Target.
Foreach FEi, we choose the subtree from the de-pendency parse tree that is the smallest subtreecontaining all words annotated as FEiby Se-mafor.
Call this subtree extracted from the de-pendency parse DepTree_FEi.
We then cre-ate a larger tree by adding DepTree_FEiasa child of a new node labeled with frame el-ement FEi: (FEiDepTree_FEi).
Call thisresulting tree SubTree_FEi.
We then connectall the SubTree_FEi(i ?
{0, 1, 2, .
.
.
, n}) toa new root node labeled with the frame F :(F SubTree_FE0.
.
.
SubTree_FEn).
Thisis the tree for a frame F .
Since the sentencecould have multiple frames, we connect the for-est of frame trees to a new node called ROOT .214ROOTCommerce_buyTarget4BuyerT1-IndSellerfromT2-GrpStatementTargetclaimed4SpeakerT1?-IndMessage4StatementSpeakerT1-IndColemanMessageCommerce_buyBuyerT1?-IndheSellerT2-GrpdefendantsFigure 2: Semantic trees for the sentence ?Coleman claimed [he]T1?Indbought drugs from the[defendants]T2?Grp.?.
The tree on the left is FrameForest and the tree on the right is FrameTree.
4in FrameForest refers to the subtree (bought (T1-Ind) (from T2-Grp)).
Ind refers to individual and Grprefers to group.We prune away all subtrees that do not containthe target entities.
We refer to the resulting treeas FrameForest.For example, in Figure 2, the left tree is theFrameForest tree for sentence (5).
There are twoframes in this sentence that appear in the final treebecause both these frames contain the target enti-ties and thus are not pruned away.
The two framesare Commerce_buy and Statement.
We first cre-ate trees for each of the frames.
For the Com-merce_buy frame, there are three frame elements:Target (the frame evoking element), Buyer andSeller.
For each frame element, we get the sub-tree from the dependency tree that contains all thewords belonging to that frame element.
The sub-tree for FEE Target is (bought T1-Ind (from T2-Grp)).
The subtree for FE Buyer is (T1-Ind) andthe subtree for FE Seller is (from T2-Grp).
Weconnect these subtrees to their respective frame el-ements and connect the resulting subtrees to theframe (Commerce_buy).
Similarly, we create atree for the frame Statement.
Finally, we connectall frame trees to the ROOT .In this representation, we have avoided theframe overlapping issues by repeating the com-mon subtrees: the subtree (bought T1-Ind (fromT2-Grp)) is repeated under the FEE Target of theStatement frame as well as under the FE Messageof the Statement frame.4.5.2 FrameTree Tree RepresentationFor the design of this tree, we deal with the twooverlapping conditions shown in Figure 1 differ-ently.
If one frame is fully embedded in anotherframe, we add the former as a child of the latterframe.
In Figure 2, the frame Commerce_buy isfully embedded in the frame element Message ofthe frame Statement.
Therefore, the frame sub-tree for Commerce_buy appears as a subtree ofMessage.If the frames overlap partially, we copy over theoverlapping portions of the structures to each ofthe frame sub-trees.For the design of this representation, we removeall lexical nodes (struck out nodes in Figure 2) andtrees that do not span any of the target entities (notshown in the figure).
As a result, this structureis the smallest semantic structure that contains thetwo target entities.
The right tree in Figure 2 is theFrameTree tree for sentence (5).4.5.3 FrameTreeProp Tree RepresentationWe are using a partial tree kernel (PTK) for calcu-lating the similarity of two trees (as detailed in sec-tion 5).
The PTK does not skip over nodes of thetree that lie on the same path.
For establishing anOBS social event between Coleman and the defen-dants, all the structure needs to encode is the factthat one target appears as a Speaker and the otherappears in the Message (of the speaker).
In Frame-Tree, this information is encoded but in an unclearmanner ?
there are two nodes (Commerce_buyand Seller) that come in between the node Mes-sage and T2-Grp.For this reason, we copy the nodes labeled withthe target annotations (T1?
?, T2??)
to all nodes(that are frame elements of a frame) on the pathfrom them to the root in FrameTree.
We call this215variation of FrameTree, in which we propagateT1 ?
?, T2 ?
?
nodes to the root, FrameTreeP-rop.
For the running example, FrameTreePropwill be: (Statement (Speaker T1-Ind) (Message(Commerce_buy ...) (T2-Grp))).
Using this treerepresentation, one of the sub-trees in the implicitfeature space will be (Statement (Speaker T1-Ind)(Message (T2-Grp)), which encodes the relationbetween the two targets in a more direct manneras compared to FrameTree.5 Machine LearningWe represent our data in form of feature vectorsand tree structures.
We use convolution kernels(Haussler, 1999) that make use of the dual formof Support Vector Machines (SVMs).
In the dualform, the optimization problem that SVM solvesis the following (Burges, 1998):max ?i?i?
?i,j?i?jyiyjK(xi, xj)s.t.
?i?iyi= 0?i?
0 ?i = 1, 2, .
.
.
, lHere, xiis the input example, yiis the class ofthe example xi, ?iis the Lagrange multiplier as-sociated with example xi, l is the number of train-ing examples, and K is the kernel function thatreturns a similarity between two examples.
Moreformally, K is the function, K : X ?
X ?
R,that maps a pair of objects belonging to the set Xto a real number.
For example, if we represent ourinput examples as feature vectors, the setX wouldbe the set of feature vectors.
For feature vectors,we use a linear kernel, i.e.
K(xi, xj) = xi?
xj(dot product of the two vectors).
For our tree rep-resentations, we use a Partial Tree Kernel (PTK),first proposed by Moschitti (2006).
PTK is a re-laxed version of the Subset Tree (SST) kernel pro-posed by Collins and Duffy (2002).
A subsettree kernel measures the similarity between twotrees by counting all subtrees common to the twotrees.
However, there is one constraint: all daugh-ter nodes of a parent node must be included (inthe sub-trees).
In PTK, this constraint is removed.Therefore, in contrast to SST, PT kernels comparemany more substructures.
For a combination offeature vectors and tree representations, we sim-ply use the linear combination of their respectivekernels.6 Experiments and ResultsWe present 5-fold cross-validation results on theACE2005 corpus annotated for social events.Since the number of types of features and struc-tures is not large (Table 2), we run an exhaustiveset of 27?
1 = 127 experiments for each of threetasks: Social Event Detection (SED), Social EventClassification (SEC) and Social Network Extrac-tion (SNE).
To avoid over-fitting to a particularpartition into folds, we run each 5-fold experi-ment 50 times, for 50 randomly generated parti-tions.
The results reported in the following tablesare all averaged over these 50 partitions.
The ab-solute standard deviation on an average is less than0.004.
This means that the performance of ourmodels across 50 random folds does not fluctuateand hence the system is robust.
We use McNe-mar?s significance test and refer to statistical sig-nificance as p < 0.05.6.1 Social event detection (SED) andclassification (SEC)We report precision (P), recall (R) and F1 measurefor the detection task, and % accuracy for the clas-sification task.
For both these tasks, our previousbest performing system was PET_GR_SqGRW(which we refer to as AR2010).
We use this asa baseline, and introduce two new baselines: thebag-of-words (BOW) baseline and a linear com-bination of BOW and AR2010, referred to asBOW_AR2010.Table 3 presents the results for these two tasksfor various features and structures.
The resultsshow that our purely semantic models (RULES,BOF, FrameTree, FrameTreeProp) do not performwell alone.
FrameForest, which encodes somelexical and syntactic level features (but is primar-ily semantic), also performs worse than the base-lines when used alone.
However, a combinationof lexical, syntactic and semantic structures im-proves the performance by an absolute of 1.1% inF1-measure for SED (from 0.574 to 0.585).
Thisgain is statistically significant.
For SEC, the abso-lute gain from our best baseline (BOW_AR2010)is 0.8% in F1-measure (from 82.3 to 83.1), whichis not statistically significant.
However, the gainof 2% from our previously proposed best system(AR2010) is statistically significant.216SED SEC SNE HierarchicalModel P R F1 %Acc P R F1BOW 0.343 0.391 0.365 70.9 0.247 0.277 0.261AR2010 0.464 0.751 0.574 81.1 0.375 0.611 0.465BOW_AR2010 0.488 0.645 0.555 82.3 0.399 0.532 0.456RULES 0.508 0.097 0.164 60.2 0.301 0.059 0.099BOF 0.296 0.416 0.346 64.4 0.183 0.266 0.217FrameForest 0.331 0.594 0.425 74.5 0.247 0.442 0.317FrameTree 0.295 0.594 0.395 68.3 0.206 0.405 0.273FrameTreeProp 0.308 0.554 0.396 70.7 0.217 0.390 0.279All 0.494 0.641 0.558 82.5 0.405 0.531 0.460BOW_AR2010_FrameForest_FrameTreeProp 0.490 0.633 0.552 83.1 0.405 0.528 0.459AR2010_FrameTreeProp 0.484 0.740 0.585 82.0 0.397 0.608 0.480Table 3: Results for three tasks: ?SED?
is Social Event Detection, ?SEC?
is Social Event Classification,?SNE?
is Social Network Extraction.
The first three models are the baseline models.
The next fivemodels are the novel semantic features and structures we propose in this paper.
?All?
refers to themodel that uses all the listed structures together.
?BOW_AR2010_FrameForest_FrameTreeProp?
refersto the model that uses a linear combination of mentioned structures.
AR2010_FrameTreeProp is a linearcombination of AR2010 and FrameTreeProp.6.2 Social network extraction (SNE)Social network extraction is a multi-way classifi-cation task, in which, given an example, we clas-sify it into one of three categories: {No-Event,INR, OBS}.
A popular technique of performingmulti-way classification using a binary classifierlike SVM, is one-versus-all (OVA).
We try thisalong with a less commonly used technique, inwhich we stack two binary classifiers in a hier-archy.
For the hierarchical design, we train twomodels: (1) the SED model ({INR + OBS} ver-sus No-Event) and (2) the SEC model (INR versusOBS).
Given a test example, it is first classified us-ing the SED model.
If the prediction is less thanzero, we label it as No-Event.
Otherwise, the testexample is passed onto SEC and finally classifiedinto either INR or OBS.We see that none of the semantic features andstructures alone outperform the baseline.
How-ever, a combination of structures from differentlevels of abstraction achieve the best performance:an absolute gain of 1.5% in F1 (statistically sig-nificant) when we use a hierarchical design (from0.465 to 0.480).Comparing hierarchical verus OVA approaches,we observe that the hierarchical approachoutperforms the OVA approach for all ourmodels by a statistically significant margin.The performance for our best reported model(AR2010_FrameTreeProp) for OVA in termsprecision, recall, and F1-measure is 0.375, 0.592,0.459 respectively.
This is statistically signifi-cantly worse than hierarchical approach (0.397,0.608, 0.480).6.3 Discussion of resultsPerforming well on SED is more important thanSEC, because if a social event is not detected inthe first place, the goodness of the SEC model isirrelevant.
Therefore, the best feature and struc-ture combination we report in this paper is a com-bination of AR2010 and FrameTreeProp.To gain insight into the how each type of se-mantic feature and structure contribute to ourpreviously proposed lexical and syntactic model(AR2010), we perform experiments in which weadd one semantic feature/structure at a time toAR2010.
Table 4 presents the results for thisstudy.
We see that the hand-crafted RULES donot help in the overall task.
We investigated thereason for RULES not being as helpful as we hadexpected.
We found that when there is no socialevent, the rules fire in 7% of the cases.
Whenthere is a social event, they fire in 17% of cases.So while they fire more often when there is a so-cial event, the percentage of cases in which theyfire is small.
We hypothesize that this is due thedependence of RULES on the correctness of se-217mantic parses.
For example, Rule (4) correctlydetects the social event in sentence (5), since Se-mafor correctly parses the input.
In contrast, Se-mafor does not correctly parse the input sentence(1): it correctly identifies the Statement frame andits Message frame element, but it fails to find theSpeaker.
As a result, Rule (3) does not fire, eventhough the semantic structure is partially identi-fied.
This, we believe, highlights the main strengthof tree kernels ?
they are able to learn seman-tic patterns, without requiring correctness or com-pleteness of the semantic parse.Out of the semantic structures we propose,FrameTreeProp adds the most value to the base-line system as compared to other semantic featuresand structures.
This supports our intuition that weneed to reduce unbounded semantic dependenciesbetween the target entities by propagating the tar-get entity tags to the top of the semantic tree.Model SED(F1)SEC(%A)SNE Hier.
(F1)AR2010 0.574 81.1 0.465+ RULES 0.576 80.8 0.465+ BOF 0.569 80.7 0.459+ FrameForest 0.571 82.6 0.472+ FrameTree 0.579 81.5 0.473+ FrameTreeProp 0.585 82.0 0.480Table 4: A study to show which semantic featuresand structures add the most value to the baseline.The top row gives the performance of the base-line.
Each consecutive row shows the result ofthe baseline plus the feature/structure mentionedin that row.7 Related WorkThere have been recent efforts to extract net-works from text (Elson et al., 2010; He et al.,2013).
However, these efforts extract a differenttype of network: a network of only bi-directionallinks, where the links are triggered by quotationmarks.
For example, Elson et al.
(2010) and Heet al.
(2013) will extract an interaction link be-tween Emma and Harriet in the following sen-tence.
However, their system will not detect anyinteraction links in the other examples mentionedin this paper.
(6) ?Take it,?
said Emma, smiling, and pushingthe paper towards Harriet ?it is for you.
Takeyour own.
?Our approach to extract and classify socialevents builds on our previous work (Agarwal andRambow, 2010), which in turn builds on workfrom the relation extraction community (Nguyenet al., 2009).
Therefore, the task of relation extrac-tion is most closely related to the tasks addressedin this paper.
Researchers have used other notionsof semantics in the literature such as latent se-mantic analysis (Plank and Moschitti, 2013) andrelation-specific semantics (Zelenko et al., 2003;Culotta and Sorensen, 2004).
To the best of ourknowledge, there is only one work that uses framesemantics for relation extraction (Harabagiu et al.,2005).
Harabagiu et al.
(2005) propose a novel se-mantic kernel that incorporates frame parse infor-mation in the kernel computation that calculatessimilarity between two dependency trees.
They,however, do not propose data representations thatare based on frame parses and the resulting ar-borescent structures, instead adding features tosyntactic trees.
We believe the implicit featurespace of kernels based on our data representationencode a richer and larger feature space than theone proposed by Harabagiu et al.
(2005).8 Conclusion and Future WorkThis work has only scratched the surface of possi-bilities for using frame semantic features and treestructures for the task of social event extraction.We have shown that tree kernels are well suited towork with possibly inaccurate semantic parses incontrast to hand-crafted features that require thesemantic parses to be completely accurate.
Wehave also extended our previous work by design-ing and evaluating a full system for social networkextraction.A more natural data representation for seman-tic parses is a graph structure.
We are activelyexploring the design of semantic graph structuresthat may be brought to bear with the use of graphkernels (Vishwanathan et al., 2010).AcknowledgmentsWe would like to thank CCLS?s IT heads, HatimDiab and Manoj Pooleery, for providing the infras-tructure support.
This paper is based upon worksupported in part by the DARPA DEFT Program.The views expressed are those of the authors anddo not reflect the official policy or position of theDepartment of Defense or the U.S. Government.218ReferencesApoorv Agarwal and Owen Rambow.
2010.
Auto-matic detection and classification of social events.In Proceedings of the 2010 Conference on Empiri-cal Methods in Natural Language Processing, pages1024?1034, Cambridge, MA, October.
Associationfor Computational Linguistics.Apoorv Agarwal, Owen C. Rambow, and Rebecca J.Passonneau.
2010.
Annotation scheme for socialnetwork extraction from text.
In Proceedings of theFourth Linguistic Annotation Workshop.Apoorv Agarwal, Anup Kotalwar, and Owen Ram-bow.
2013a.
Automatic extraction of social net-works from literary text: A case study on alice inwonderland.
In the Proceedings of the 6th Interna-tional Joint Conference on Natural Language Pro-cessing (IJCNLP 2013).Apoorv Agarwal, Anup Kotalwar, Jiehan Zheng, andOwen Rambow.
2013b.
Sinnet: Social interactionnetwork extractor from text.
In Sixth InternationalJoint Conference on Natural Language Processing,page 33.Collin F. Baker, J. Fillmore, and John B. Lowe.
1998.The Berkeley FrameNet project.
In 36th Meet-ing of the Association for Computational Linguis-tics and 17th International Conference on Computa-tional Linguistics (COLING-ACL?98), pages 86?90,Montr?al.Chris Burges.
1998.
A tutorial on support vector ma-chines for pattern recognition.
Data mining andknowledge discovery.Desai Chen, Nathan Schneider, Dipanjan Das, andNoah A. Smith.
2010.
Semafor: Frame argumentresolution with log-linear models.
In Proceedings ofthe 5th International Workshop on Semantic Evalu-ation, pages 264?267, Uppsala, Sweden, July.
Asso-ciation for Computational Linguistics.Michael Collins and Nigel Duffy.
2002.
New rank-ing algorithms for parsing and tagging: Kernels overdiscrete structures, and the voted perceptron.
In Pro-ceedings of the 40th annual meeting on associationfor computational linguistics, pages 263?270.
Asso-ciation for Computational Linguistics.Aron Culotta and Jeffrey Sorensen.
2004.
Dependencytree kernels for relation extraction.
In Proceedingsof the 42nd Meeting of the Association for Compu-tational Linguistics (ACL?04), Main Volume, pages423?429, Barcelona, Spain, July.David K. Elson, Nicholas Dames, and Kathleen R.McKeown.
2010.
Extracting social networks fromliterary fiction.
Proceedings of the 48th AnnualMeeting of the Association for Computational Lin-guistics, pages 138?147.Zhou GuoDong, Su Jian, Zhang Jie, and Zhang Min.2005.
Exploring various knowledge in relation ex-traction.
In Proceedings of 43th Annual Meeting ofthe Association for Computational Linguistics.Sanda Harabagiu, Cosmin Adrian Bejan, and PaulMorarescu.
2005.
Shallow semantics for relationextraction.
In International Joint Conference On Ar-tificial Intelligence.David Haussler.
1999.
Convolution kernels on discretestructures.
Technical report, University of Califor-nia at Santa Cruz.Hua He, Denilson Barbosa, and Grzegorz Kondrak.2013.
Identification of speakers in novels.
The51st Annual Meeting of the Association for Compu-tational Linguistics (ACL 2013).Nanda Kambhatla.
2004.
Combining lexical, syntac-tic, and semantic features with maximum entropymodels for extracting relations.
In Proceedings ofthe ACL 2004 on Interactive poster and demonstra-tion sessions, page 22.
Association for Computa-tional Linguistics.Dan Klein and Christopher D. Manning.
2003.
Accu-rate unlexicalized parsing.
Proceedings of the 41stMeeting of the Association for Computational Lin-guistics, pages 423?430.Alessandro Moschitti.
2006.
Efficient convolution ker-nels for dependency and constituent syntactic trees.In Proceedings of the 17th European Conference onMachine Learning.Truc-Vien T. Nguyen, Alessandro Moschitti, andGiuseppe Riccardi.
2009.
Convolution kernels onconstituent, dependency and sequential structuresfor relation extraction.
Conference on EmpiricalMethods in Natural Language Processing.Barbara Plank and Alessandro Moschitti.
2013.
Em-bedding semantic similarity in tree kernels for do-main adaptation of relation extraction.
In Proceed-ings of the 51st Annual Meeting of the Associationfor Computational Linguistics (Volume 1: Long Pa-pers), pages 1498?1507, Sofia, Bulgaria, August.Association for Computational Linguistics.SVN Vishwanathan, Nicol N Schraudolph, Risi Kon-dor, and Karsten M Borgwardt.
2010.
Graph ker-nels.
The Journal of Machine Learning Research,11:1201?1242.Dmitry Zelenko, Chinatsu Aone, and AnthonyRichardella.
2003.
Kernel methods for relationextraction.
The Journal of Machine Learning Re-search, 3:1083?1106.Shubin Zhao and Ralph Grishman.
2005.
Extract-ing relations with integrated information using ker-nel methods.
In Proceedings of the 43rd Meeting ofthe ACL.219
