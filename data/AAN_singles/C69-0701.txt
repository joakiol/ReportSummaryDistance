Prepr int  No.
7 Classification: IR 4.1Automatic error-correction in natural languagesbyA.J.
SzanserComputer Science Division,National Physical I~boratory, Teddington, England.AbstractAutomatic error-correction in natural language processing isbased on the principle of 'elastic matching'.
Text words are segmen-ted into 'lines' with letters arranged according to a pre-determinedsequence, and then matched line-by-line, shifts being applied if thenumbers of lines are unequal.In order to resolve the possible multiple choices produced, themethod may be supplemented by another one, based on the observedrepetition of words in natural texts, and also by syntactic analysis.This paper describes the above methods and gives an account ofan experiment now in progress at the National Physical Laboratory.I.
Elastic matchin~~ith increased application of computers in the processing ofnatural languages comes the need for correcting errors introduced byhuman operators at the input stage.A statistic investigation \[1\] revealed that roughly 80 per centof all misspelled words contain only one error, belonging to one ofthe following cases: a letter missing, an extra letter, a wrongletter and finally two adjacent letters interchanged.
As such anerror can occur in any position, a check by trying all possiblealternatives in turn is clearly impracticable.A method which can obtain the same result but in a less tediousand time-constming way has been worked out and experimented upon atthe National Physical Laboratory, Teddington, England.
This method,named'elastic matching' was first proposed at the 1968 I.F.I.P.Congress in Edinburgh, Scotland \[2\].The elastic matching of words consists basically of coding allthe characters (letters) as bits in a computer word, allotting to eachletter a specific position.
The whole English alphabet will there-fore be represented by a sequence of 26 bits, although their order,as will be shown below, may, and indeed should, differ from theusual order of letters in the alphabet.-2 -All words belonging to a complete set, which may be a list ofwords or a whole dictionary, are 'linearized', that is converted intosegments, called 'lines', in which the letters are arranged in theagreed order?
if the current letter has a position prior to the laststored, a new line must be started.
Thus, if the sequence in questionwere the alphabet itself, the word 'interest' (for example) would belinearized as follows: 'int-er-est'.
The actual sequence, by theway, has to be chosen in such a way that it would produce the longestpossible lines or, in other words, the minimum number of lines fora given sample of text.The matching is carried out not between words but between lines.~ll errors will then stand out immediately as one or more disagree-ing bits ~.
In the case of two bits a simple check will reveal whetherthis is the result of an accepted type of error (one wrong letter, ortwo adjacent letters interchanged), or the result of two separateerrors, and therefore to be rejected under the limit accepted (oneerror per word).In the examples shown below the alphabet has been assumed to bethe linearizing sequence; this is done for the sake of better clarityonly.M 0 RST I f I R T Y !Mo I i D I Ydisagreeing bit .~ ..............
...~!
(a) ~Extra letter (b) Letter missin~B H N TB E N T JJJB N ST IB E N T iI(c) Wrong letter (d) Two errors(unacceptable)tThe result (d) is unacceptable because the two disagreeing bitsFor example by using the logical 'NOT-EQUIVALENT' operation.-3 -are formed as a result of two errors (extra S and missing E).
Inthe computer check this is shown by the two outstanding bits (letters)being separated by another bit (letter).If the numbers of lines in the two versions (misspelled andcorrect) are unequal, the procedure is as follows.
The next line ofthe longer version is shifted back and matched against the result(that is, the disagreeing bits) of the previous match.
Thus, forexample,I M 0 UM 0 STI o ST(an extra letter)In the case of two disagreeing bits some simple checks haveagain to be made to eliminate the two-error cases, and also to pre-vent spurious matches resulting from the self-cancellation of charac-ters between the two successive lines of the same version.More particulars of the operation of this method can be found ina special paper \[5\].2.
The dictionary organizationThe elastic matching, as was mentioned above, is applicableagainst any set of (correct) words, which may be, for example, a listof proper names, or any other words, even of artificial (e.g.programming) languages.It is, however, the application to natural languages, in particu-lar English, which is the subject of this paper.
There are two prob-lems which have to be overcome or, at least, reduced to manageable pro-portions before this method can be applied using a complete Englishdictionary.The first problem is access to the dictionary which may containtens or even hundreds of thousands of entries.
This number, however,includes all grammatical forms of English words (fortunately, they arenot so numerous as in highly inflected languages such as Russian).The dictionary look-up takes different forms depending on the-4 -way in which the dictionary is organized.
The latter could haveeither a tree-like structure (preferably built of 'lines') which islikely to be quicker in operation, or a list structure, in which wordsmay be grouped by their line numbers, then by numbers of letters andfinally, if the lists are still too long, by part-alphabetization(according to the accepted sequence).
This structure is easier toprepare.The words to be checked against the dictionary of the liststructure will be linearized, and during this process the numbers oftheir lines and letters will be determined.
The sections of thedictionary to be used in the matching process will be those withequal numbers of lines (and letters) and those ir~,ediately below andabove these numbers (depending on the error threshold accepted).The other problem is connected with the number of multiplematches likely to occur, especially for short words.Two ways of alleviating this problem are described in the nextsection.3- The supplementary procedures3.1 The ~eneral-content checkOne possibility of choosing between the multiple equivalentsproduced by dictionary look-up is to select those which are repeatedthroughout the article or speech in question.
For this purpose aprocedure called 'general-content check' has been devised.
~s thetext is processed, each different word satisfying certain conditionsis stored.
Then all multiple results from dictionary look-up arecompared with the contents of this store (which may also be organizedinto sections) and words found there are given preference to others.The idea behind this is, of course, that words tend to be repeated byone writer or speaker.The size of the sample processed for the general-content checkmust not be too small or too large.
The optimum size should bedetermined experimentally, but one may risk the guess that perhaps1-2 thousand (current) test words are a practical amount.Further, there is no need to store al l  the different words.Ideally, these should be the so-called'content' words, such as nouns,verbs, adjectives and adverbs, whereas the remaining, 'function' words(prepositions, conjunctions, etc.)
should be left aside, as not beingcontent-typical.
The selection can easily be done in the storingprocess if dictionary entries are suitably marked.Also, if one grammatical form of a word is stored, there is no-5 -need for storing others, so that the general-content vocabulary mayassume the character of a stem-word list.
This again, can convenien-tly be arranged both in storing and in matching.3.2 S~xntactic analysis2mother possibility of making a choice between multiple equiva-i\[ents is syntactic ~alysis.
This is especially promising, because ifone consider~ a typical lexical set of common words, one must noticethat long words (which give, as a rule, better results in elasticmatching) usually belong to Icontent' words, whereas the 'function'words, which are specially amenable to syntactic analysis are normallyshort and, therefore, would either produce more multiple choices er~if of less than four letters, would escape the elastic matching~together*.
In this way the two methods are largely complementary.More of syntactic analysis in error-correction will be said below.Neither of the two supplementary methods mentioned above isapplicable where elastic matching is used for non-textual material(list of names, etc.).4.
c~experiment in automatic error-correctionAn experiment has been carried out at the NPL on the lines des-cribed above.First of all, an optimum linearizing sequence had to be estab-lished for English texts.
Several methods were used for this purpose,both statistical and purely linguistic, and the results were sub-mitted to computer tests.
Sequences bringing lower yield had beengradually eliminated and changes were made in those remaining, inorder to determine the optimum sequence by the well-known lhill-climbing' technique.
This investigation has been fully describedelsewhere \[3\] and it has produced the following sequence:F J V W M B P H I O Q U E A R L N X G S C K T D Y ZNext, through lack of a proper dictionary, the general-contentcheck procedure was used to compile lists of words occurring inselected stretches of English (parts of three articles on physics,linguistics and secio-politics, containing about 3,000 text words in~l).This limit has been accepted.-6 -Several hundred distorted words (based on words in the s~nearticles) were matched against these vocabularies.
After all the cor-rections and adjustments, the need for which naturally occurred duringthe tests, have been made, the final results can be summarized asfollows:(i) The retrievals were both exact and complete, in the sensethat no misspelled words (within the proper error limit) were leftunretrieved and no wrong retrievals were produced;(ii) The number of multiple equivalents increased rapidly asthe lower limit of the number of letters (four) in a word wasapproached (in some cases up to five equivalents);(iii) The number of multiple equivalents was generally insigni-ficant for 'content' words (in most cases only one word was retrieved),whereas 'function' words often produced many equivalents, e.g.WTH~'--,THEY, OTHER, THEN, T}~M, TImElY, TI~IRAll these observations confirmed the results anticipated inprevious sections.The latest stage of the experiment is being carried out at thetime of writing this paper (May, 1969).
The author is now able touse the English side of the Palantype - '_iuglish dictionary ~ of about80,000 entries.
For the sake of economy in programming and machinetime, only one section of the dictionary, namely the entries startingwith letter S (about I~% of the whole dictionary) is being used.The linearization and organization of this section is now in progress.This will enable the author to test a more complete dictionary look-up than before, together with general-content check and later withsyntactic analysis as well.5.
Other applications5.1 Apart from the general use for natural English texts, anapplication of the elastic m!~tching technique has been proposed in theautomatic tra!
!scription of machine-shorthand of the Palantype system.This system uses a special machine with a keyboard enabling thesimultaneous striking of several keys, each 'stroke' corresponding toa phonetically-based group of consonants and vowels, roughly equivalentto a syllable.
In normal operation all the characters of each strokeare printed together on a continuous paper band, shifting after eachThis will be explained below, Section 5--7 -stroke.
The recording is later read and transcribed by a human opera-tor.
Since the latter part of the operation is naturally much slower(about four times that of the recording), a project, now in progressat the NPL, aims at securing automatic transcription, in which thecharacter levers, in addition to the ordinary printing action, activateelectric contacts.
These create impulses, which are fed into acomputer and result, after a series of operations, in printing out atext as new to ordinary English, as possible.
One of the problemsencountered in this process is caused by the flexibility of therecording conve~tion, enabling the human operator to record phoneticcombinations in more than one way.
Generally, this is provided forby inserting in the automatic Palantype-~haglish dictionary all ver-sions of each word that can be reasonably foreseen.
In practice theUnforeseen sometimes happens and the word is output untranslated (but'transliterated' phonetically), which is at the best annoying, butmay even be unreadable.
An analysis has shown that most of thedeviations from standard versions stored in the dictionary are causedby a few convention rtules, such as e.g.
'vowel elision': any unaccen-ted vowel in a word can be omitted.
Now, if the matching is done noton palantype strokes but on their linearized versions, the elasticmatching rules can easily be adjusted to include the versions produced.Incidentally, the Palantype sequence is ~Iready partlylinearized, and reads:SCPTH + M~LYOEAUI  .
NLCF~RPT + SH(the "+" and "."
signs have special phonetic functions).
For thelinearization purposes all that is needed is to exclude the repeatedconsonants (from second "N" to the end); the number of lines willtherefore exceed the number of 'strokes'.The relevant procedures have been fully tested on sample lists ofstandard and non-standard versions (containing up to 300 words) andwere found satisfactory.
The implementation, however, for use withthe full dictionary remains to be done.
It is still not clearwhether it would repay to linearize and store in this form the com-plete dictionary of eighty odd thousand entries; or whether itwould be more practical to linearize while checking, stroke by stroke,which would be, of course, a much slower procedure.
At the presenttime it does not look likely that either solution would lead tostandardization being possible in 'real-time', but there remains thepossibility of an 'errata' sheet being produced almost immediatelyafter the normal output.
More particulars about this applicationcan be found in the paper \[4\].5.2 Another application, now under consideration, is theretrieval of misspelled proper names from lists used in a fact-retrieval project, which is also in progress at the NPL.-8 -6.
Further plansOnce the work on the English dictionary section is completed itis hoped that the results will be extended to the full dictionary, andgive the correct idea of the size of the problem and the times invol-ved in the operation of the system.
Also the question of the mostreasonable dictionary organisation will find an answer.Independently of the above, the application of syntactic analysisfor the resolution of ambiguities (multiple equivalents) will bestudied.
A very limited syntactic check has already been theoreticallyworked out and proposed for the resolution of ambiguities in theautomatic transcription of machine-shorthand.
This is limited to theinspection of only the adjacent words; since, however, in thePalantype system speed is all important, the limitations brought bythis condition may still be worth incorporating in the system.The work described above has been carried out at the NationalPhysical Laboratory, Teddington, England.References\[I\]\[2\]\[3\]\[4\]\[5\]F.J. Damerau, "Technique for computer detection and correctionof spelling errors", Comm.
A.C.M.
~, (3), 1964.A.J.
Szanser, "Error-correcting methods in natural languageprocessing", IFIP Congress 68, Edinburgh,,Lugust, 1968(Booklet H, pp 15-19).
"Error-correcting methods in natural language processing - I.Optimum letter sequence for longest strings in English",COM.SCI.
T.M.
12~ National PhysiealLaboratory, Teddington,England, May 1968.
"Error-correcting methods in natural language processing - II.Standardization of variants in the Palantype automatic transcrip-tion", CO~LZ~CI.
T.M.
16, April 1969.
"Error-correcting methods in natural language processing - III.
'm~lastic matching' technique in the processing of F~uglish",COM.SCI.
T.M.
21, April 1969 .
