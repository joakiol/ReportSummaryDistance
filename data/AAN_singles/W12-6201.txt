Proceedings of the 10th International Workshop on Finite State Methods and Natural Language Processing, pages 1?9,Donostia?San Sebastia?n, July 23?25, 2012. c?2012 Association for Computational LinguisticsEffect of Language and Error Models on Efficiency of Finite-StateSpell-Checking and CorrectionTommi A PirinenUniversity of HelsinkiDepartment of Modern LanguagesFI-00014 Univ.
of Helsinki, PO box 24tommi.pirinen@helsinki.fiSam HardwickUniversity of HelsinkiDepartment of Modern LanguagesFI-00014 Univ.
of Helsinki, PO box 24sam.hardwick@helsinki.fiAbstractWe inspect the viability of finite-state spell-checking and contextless correction of non-word errors in three languages with a large de-gree of morphological variety.
Overviewingprevious work, we conduct large-scale testsinvolving three languages ?
English, Finnishand Greenlandic ?
and a variety of error mod-els and algorithms, including proposed im-provements of our own.
Special referenceis made to on-line three-way composition ofthe input, the error model and the languagemodel.
Tests are run on real-world text ac-quired from freely available sources.
We showthat the finite-state approaches discussed aresufficiently fast for high-quality correction,even for Greenlandic which, due to its mor-phological complexity, is a difficult task fornon-finite-state approaches.1 IntroductionIn most implementations of spell-checking, effi-ciency is a limiting factor for selecting or discard-ing spell-checking solutions.
In the case of finite-state spell-checking it is known that finite-state lan-guage models can efficiently encode dictionaries ofnatural languages (Beesley and Karttunen, 2003),even for polysynthetic languages.
Most contem-porary spell-checking and correction systems arestill based on programmatic solutions (e.g.
hun-spell1, and its *spell relatives), or at most specialisedalgorithms for implementing error-tolerant traver-sal of the finite-state dictionaries (Oflazer, 1996;Hulde?n, 2009a).
There have also been few fully1http://hunspell.sf.netfinite-state implementations that both detect and cor-rect errors (Schulz and Mihov, 2002; Pirinen andLinde?n, 2010).
In this paper we further evaluate theuse of finite-state dictionaries with two-tape finite-state automatons as a mechanism for correcting mis-spellings, and optimisations to the finite-state errormodels, intending to demonstrate that purely finite-state algorithms can be made sufficiently efficient.To evaluate the general usability and efficiencyof finite-state spell-checking we test a number ofpossible implementations of such a system withthree languages of typologically different morpho-logical features2 and reference implementations forcontemporary spell-checking applications: Englishas a morphologically more isolating language withessentially a word-list approach to spell-checking;Finnish, whose computational complexity has beenjust beyond the edge of being too hard to implementnicely in eg.
hunspell (Pitka?nen, 2006); and Green-landic, a polysynthetic language which is imple-mented as a finite-state system using Xerox?s orig-inal finite-state morphology formalism (Beesley andKarttunen, 2003).
As a general purpose finite-statelibrary we use HFST3, which also contains our spell-2We will not go into details regarding the morphological fea-tures of these languages.
We thank the anonymous reviewer forguiding us to make a rough comparison using a piece of trans-lated text.
We observe from the translations of the UniversalDeclaration of Human Rights (with pre-amble included) as fol-lows: the number of word-like tokens for English is 1,746, forFinnish 1,275 and for Greenlandic 1,063.
The count of the 15most frequent tokens are for English 120?28, for Finnish 85?10 and for Greenlandic 38?7.The average word length is 5.0 characters for English, 7.8for Finnish and 14.9 for Greenlandic.
For the complexity ofcomputational models refer to Table 2 in this article.3http://hfst.sf.net1checking code.As neither Finnish nor Greenlandic have beensuccessfully implemented in the hunspell formal-ism, we mainly use them to evaluate how the com-plexity of a language model affects the efficiency offinite-state spell-checking.
For a full-scale survey onthe state-of-the-art non-finite-state spell-checking,refer to Mitton (2009).The efficiency results are contrasted with the ex-isting research on finite-state spell-checking in Has-san et al (2008) and the theoretical results on finite-state error-models in Mitankin (2005).
Our contri-bution primarily comprises the addition of morpho-logically complex languages with actual cyclic dic-tionary automata (i.e.
infinite dictionaries formedby compounding and recurring derivation) and morecomplex structure in general, compared to those ofEnglish and Arabic.
Our goal is to demonstrate thatfinite-state spelling is tractable for these complexlanguages, to document their implications for per-formance and to present an algorithm for the task.We also point out that previous approaches have ne-glected to simultaneously constrain the error modeland the dictionary with each other in on-line com-position, which affords a significant speed benefitcompared to generating the two component compo-sitions.The rest of the paper is organised as follows.
InSection 2 we discuss the spell-checking task, currentnon-finite-state spell-checkers and previously usedfinite-state methods for spell-checking and correc-tion and propose some possible speed optimisationsfor the error models.
We also investigate algorith-mic limitations of finite-state approaches and waysto remedy them.
In Section 3 we present the lan-guage models, error models and the testing corpora.In Section 4 we present the comparisons of speedand quality with combinations of different languageand error models and corpora for spell-checking.
InSection 5 we summarise our findings and results,and outline future goals.2 MethodsA finite-state spell-checker is typically (Pirinen andLinde?n, 2010) composed of at least two finite-stateautomata; one for the dictionary of the language, orthe language model, which contains valid strings ofthe language, and one automaton to map misspeltwords into correct strings, or the error model.
Boththe language model and the error model are usu-ally (Pirinen and Linde?n, 2010) weighted finite-stateautomata, where the weights represent the prob-abilities are of a word being correctly spelled inthe language model and of specific misspellings,respectively.
We evaluate here the effect of boththe language and error model automatons?
structureand complexity on the efficiency of the finite-statespelling task.42.1 Language ModelsThe most basic language model for a spell-checkingdictionary is a list of correctly spelled word forms.One of the easiest ways of creating such a spell-checker is to collect the word forms from a reason-ably large corpus of (mostly) correctly spelt texts.Additionally we can count the frequency of wordsand use that as the likelihood, P (w) = c(w)?w?D c(w)where c(w) is the count of the word w and D is theset of corpus word forms.
For morphologically moreisolating languages such as English, this is often asufficient approach (Norvig, 2010), and we use it tocreate a dictionary for our English spell-checker aswell.
As a non-finite-state reference point we usehunspell.For agglutinative languages like Finnish, forwhich the word-list approach is likely to miss amuch greater number of words, one of the mostcommon approaches is to use right-linear gram-mars, possibly combined with finite-state rule lan-guages to implement morphophonological alter-ations (Koskenniemi, 1983).
This approach also ap-plies to the newest available free / open source andfull-fledged finite-state Finnish morphological dic-tionary we found (Pirinen, 2011).
This languagemodel features productive derivations, compound-ing and rudimentary probabilistic models.
We take,as a reference non-finite state language model forFinnish, Voikko?s implementation in Malaga, whichis currently used as a spell-checking componentin open source software.
It is implemented in a4The methods introduced in this research as well as all ma-terials are free/libre open source.
Please see our svn repos-itory https://hfst.svn.sf.net/svnroot/trunk/fsmnlp-2012-spellers/ for detailed implementationand scripts to reproduce all the results.2left-associative grammar formalism, which is a po-tentially less efficient system with more expressivepower.
It?s similar to finite-state formulations interms of linguistic coverage.For polysynthetic languages it will be obviousthat the coverage of any word-list-based approachwill be even lower.
Furthermore, most simple ex-tensions to it such as affix stripping (as in hun-spell) are not adequate for describing word forms.To our knowledge, the only approaches that havebeen widely used for spell-checking and morpho-logical analysis of Greenlandic have been basedon traditional finite-state solutions, such as the Xe-rox formalisms.
In our case we have obtaineda freely available finite-state morphology imple-mentation from the Internet5.
For further de-tails we refer to the authors?
website http://oqaaserpassualeriffik.org/.2.2 Error ModelsThe ubiquitous formula for modeling typing er-rors since computer-assisted spelling correction be-gan has been the edit distance metric sometimesattributed to Levenshtein (1966) and/or Damerau(1964).
It maps four typical slips of the fingers ona keyboard to events in the fuzzy matching of mis-spelt word forms to correct ones, that is, the deletionof a character (i.e.
failing to press a key), additionof a character (i.e.
hitting an extra key accidentally),changing a character (i.e.
hitting the wrong key) andtransposing adjacent characters (i.e.
hitting two keysin the wrong order).When modeling edit distance as a finite-state au-tomaton, a relatively simple two-tape automaton issufficient to implement the algorithm (Hassan et al,2008).
The automaton will consist of one arc foreach type of error, and additionally one state foreach transposition pair.
This means that the trivialnondetermistic finite-state automaton implementingthe algorithm is of space complexity S(V,E,?)
=O(|?|2|V | + |?|2|E|), where ?
is the alphabet oflanguage, V is the set vertices in automaton and E isthe set of edges in automaton.
This edit distance for-mulation is roughly feature equivalent to hunspell?sTRY mechanism.5https://victorio.uit.no/langtech/trunk/st/kalTo further fine-tune this finite-state formulationof the edit distance algorithm, it is possible to at-tach a probability to each of the error events as aweight in a weighted finite-state automaton, corre-sponding to the likelihood of an error, or a con-fusion factor.
This can be used to implement fea-tures like keyboard adjacency or an OCR confusionfactor to the error correction model.
This will notmodify the structure of the finite-state error mod-els or the search space?which is why we did nottest their effects in this article?, but introduction ofnon-homogenous weights to the resulting finite-statenetwork may have an effect on search time.
This ad-dition is equivalent to hunspell?s KEY mechanism.For English language spelling correction thereis also an additional type of error model to dealwith competence-related misspellings?as opposedto models that mainly deal with mistypings?implemented in the form of phonemic folding andunfolding.
This type of error is very specific to cer-tain types of English text and is not in the scope ofthis experiment.
This is the PHON part of the hun-spell?s correction mechanism.After fine-tuning the error models to reimplementhunspell?s feature set, we propose variations of thisedit distance scheme to optimise the speed of er-ror correction with little or no negative effect to thequality of the correction suggestions.
The time re-quirement of the algorithm is determined by the sizeof the search space, i.e.
the complexity of the result-ing network when the error model is applied to themisspelt string and intersected with the dictionary6.To optimise the application of edit distance bylimiting the search space, many traditional spellcheckers will not attempt to correct the very first let-ter of the word form.
We investigated whether thisdecision is a particularly effective way to limit thesearch space, but it does not appear to significantlydiffer from restricting edits at any other position inthe input.Dividing the states of a dictionary automaton into6For non-finite-state solutions, the search space is simplythe number of possible strings given the error corrections madein the algorithm.
For finite-state systems the amount of gener-ated strings with cyclic language and error models is infinite, socomplexity calculation are theoretically slightly more complex,however for basic edit distance implementations used in this ar-ticle the search space complexities are always the same and theamount of suggestions generated finite3classes corresponding to the minimum number ofinput symbols consumed by that state, we foundthat the average ambiguity in a particular class issomewhat higher for the first input symbols, butthen stabilises quickly at a lower level.
This wasaccomplished by performing the following state-categorisation procedure:1.
The start state is assigned to class 0, and allother states are assigned to a candidate pool.2.
All states to which there is an (input) epsilontransition from the start state are assigned toclass 0 and removed from the candidate pool.3.
This is repeated for each state in class 0 untilno more states are added to class 0.
This com-pletes class 0 as the set of states in which theautomaton can be before consuming any input.4.
For each state in class 0, states in the candidatepool to which there is a non-epsilon transitionare assigned to class 1 and removed from thecandidate pool.5.
Class 1 is epsilon-completed as in (2-3).6.
After the completion of class n, class n + 1is constructed.
This continues until the candi-date pool is empty, which will happen as longas there are no unreachable states.With this categorisation, we tallied the total num-ber of arcs from states in each class and divided thetotal by the number of states in the class.
This isintended as an approximate measure of the ambigu-ity present at a particular point in the input.
Someresults are summarized in Table 1.Class Transitions States Average0 156 3 521 1,015 109 9.32 6,439 1,029 6.33 22,436 5,780 3.94 38,899 12,785 3.05 44,973 15,481 2.96 47,808 17,014 2.87 47,495 18,866 2.58 39,835 17,000 2.39 36,786 14,304 2.610 45,092 14,633 3.111 66,598 22,007 3.012 86,206 30,017 2.9Table 1: State classification by minimum input consumedfor the Finnish dictionaryFurther, the size of a dictionary automaton that isrestricted to have a particular symbol in a particularposition does not apparently depend on the choiceof position.
This result was acquired by intersectingeg.
the automaton e.+ with the dictionary to restrictthe first position to have the symbol e, the automa-ton .e.+ to restrict the second position, and so on.The transducers acquired by this intersection vary insize of the language, number of states and number oftransitions, but without any trend depending on theposition of the restriction.
This is in line with therather obvious finding that the size of the restricteddictionary in terms of number of strings is similarilyposition-agnostic.Presumably, the rationale is a belief that errorspredominately occur at other positions in the input.As far as we know, the complete justification for thisbelief remains to be made with a high-quality, hand-checked error corpus.On the error model side this optimisation has beenjustified by findings where between 1.5 % and 15 %of spelling errors happen in the first character of theword, depending on the text type (Bhagat, 2007); the1.5 % from a small corpus of academic texts (Yan-nakoudakis and Fawthrop, 1983) and 15 % from dic-tated corpora (Kukich, 1992).
We also performed arudimentary classification of the errors in the smallerror corpus of 333 entries from Pirinen et al (2012),and found errors at the first position in 1.2 % of theentries.
Furthermore, we noticed that when evenlysplitting the word forms in three parts, 15 % of theerrors are in the first third of the word form, whilesecond has 47 % and third 38 %, which would be infavor of discarding initial errors7.A second form of optimisation that is used bymany traditional spell-checking systems is to applya lower order edit distance separately before tryinghigher order ones.
This is based on the assumptionthat the vast majority of spelling errors will be oflower order.
In the original account of edit distancefor spell-checking, 80 % of the spelling errors werefound to be correctable with distance 1 (Pollock andZamora, 1984).The third form of optimisation that we test isomitting redundant corrections in error models ofhigher order than one.
Without such an optimisa-7By crude classification we mean that all errors were forcedto one of the three classes at weight of one, e.g.
a series ofthree consecutive instances of the same letters was counted asdeletion at the first position.4tion, higher order error models will permit addingand deleting the same character in succession at anyposition, which is obviously futile work for errorcorrection.
Performing the optimisation makes theerror model larger but reduces the search space, anddoes not affect the quality of results.2.3 AlgorithmsThe obvious baseline algorithm for the task of find-ing which strings can be altered by the error modelin such a way that the alteration is present in the lan-guage model is generating all the possible alterationsand checking which ones are present in the languagemodel.
This was done in Hassan et al (2008) by firstcalculating the composition of the input string withthe error model and then composing the result withthe language model.If we simplify the error model to one in whichonly substitutions occur, it can already be seen thatthis method is quite sensitive to input length and al-phabet size.
The composition explores each combi-nation of edit sites in the input string.
If any numberof edits up to d can be made at positions in an inputstring of length n, there ared?i=1(ni)ways to choose the edit site, and each site is subjectto a choice of |?|?1 edits (the entire alphabet exceptfor the actual input).
This expression has no closedform, but as d grows to n, the number of choiceshas the form 2n, so the altogether complexity is ex-ponential in input length and linear in alphabet size(quadratic if transpositions are considered).In practice (when d is small relative to n) it is use-ful to observe that an increase of 1 in distance resultsin an additional term to the aforementioned sum, theratio of which to the previously greatest term isn!/(d!
?
(n?
d!))n!/((d?
1)!
?
(n?
d + 1)!)
=n?
d + 1dindicating that when d is small, increases in it pro-duce an exponential increase in complexity.
Foran English 26-letter lowercase alphabet, edit dis-tance 2 and the 8-letter word ?spelling?, 700 stringsare stored in a transducer.
With transpositions,deletions, insertions and edit weights this grows to100, 215 different outputs.
We have implementedthis algorithm for our results by generating theedited strings by lookup, and performing anotherlookup with the language model on these strings.Plainly, it would be desirable to improve on this.The intuition behind our improvement is that whenediting an input string, say ?spellling?, it is a wastedeffort to explore the remainder after generating aprefix that is not present in the lexicon.
For example,after changing the first character to ?z?
and not edit-ing the second characted, we have the prefix ?zp-?,which does not occur in our English lexicon.
So theremaining possibilities - performing any edits on theremaining 7-character word - can be ignored.This is accomplished with a three-way composi-tion in which the input, the error model and the lan-guage model simultaneously constrain each other toproduce the legal correction set.
This algorithm ispresented in some detail in Linde?n et al (2012).
Amore advanced and general algorithm is due to Al-lauzen and Mohri (2009).3 MaterialFor language models we have acquired suitable free-to-use dictionaries, readily obtainable on the Inter-net.We made our own implementations of the al-gorithms to create and modify finite-state errormodels.
Our source repository contains a Pythonscript for generating error models and an extensiveMakefile for exercising it in various permuta-tions.To test the effect of correctness of the sourcetext to the speed of the spell-checker we have re-trieved one of largest freely available open sourcetext materials from the Internet, i.e.
Wikipedia.
TheWikipedia text is an appropriate real-world materialas it is a large body of text authored by many individ-uals, and may be expected to contain a wide varietyof spelling errors.
For material with more errors, wehave used a simple script to introduce (further, ar-bitrary) errors at a uniform probability of 1/33 percharacter; using this method we can also obtain acorpus of errors with correct corrections along them.Finally we have used a text corpus from a languagedifferent than the one being spelled to ensure that themajority of words are not in the vocabulary and (al-5most always) not correctable by standard error mod-els.The Wikipedia corpora were sourced fromwikimedia.org.
For exact references, see ourpreviously mentioned repository.
From the dumpswe extracted the contents of the articles and pickedthe first 100,000 word tokens for evaluation.In Table 2 we summarize the sizes of automata interms of structural elements.
On the first row, wegive the size of the alphabet needed to represent theentire dictionary.
Next we give the sizes of automataas nodes and arcs of the finite-state automaton en-coding the dictionary.
Finally we give the size of theautomaton as serialised on the hard disk.
While thisis not the same amount of memory as its loaded datastructures, it gives some indication of memory usageof the program while running the automaton in ques-tion.
As can be clearly seen from the table, the mor-phologically less isolating languages do fairly con-sistently have larger automata in every sense.Automaton En Fi Kl?
set size 43 117 133Dictionary FSM nodes 49,778 286,719 628,177Dictionary FSM arcs 86,523 783,461 11,596,911Dictionary FSM on disk 2.3 MiB 43 MiB 290 MiBTable 2: The sizes of dictionaries as automataIn Table 3 we give the same figures for the sizes oferror models we?ve generated.
The ?
size row hereshows the number of symbols left when we have re-moved the symbols that are usually not consideredto be a part of a spell-checking mechanism, such asall punctuation that does not occur word-internallyand white-space characters8.
Note that sizes of errormodels can be directly computed from their parame-ters; i.e., the distance, the ?
set size and the optimi-sation, so this table is provided for reference only.4 EvaluationWe ran various combinations of language and errormodels on the corpora described in section 3.
Wegive tabular results of the speed of the system andthe effect of the error model on recall.
The latter8The method described here does not handle run-on wordsor extraneous spaces, as they introduce lot of programmaticcomplexity which we believe is irrelevant to the results of thisexperiment.Automaton En Fi Kl?
set size 28 60 64Edit distance 1 nodes 652 3,308 3,784Edit distance 1 arcs 2,081 10,209 11,657Edit distance 2 nodes 1,303 6,615 7,567Edit distance 2 arcs 4136 20,360 23,252No firsts ed 1 nodes 652 3,308 3,784No firsts ed 1 arcs 2,107 10,267 11,719No firsts ed 2 nodes 1,303 6,615 7,567No firsts ed 2 arcs 4,162 20,418 23,314No redundancy and 1st ed 2 nodes 1,303 6,615 7,567No redundancy and 1st ed 2 arcs 4,162 20,418 23,314Lower order first ed 1 to 2 arcs 6,217 30,569 34,909Lower order first ed 1 to 2 nodes 1,955 9,923 11,351Table 3: The sizes of error models as automatais to establish that simpler error models lead to de-graded recall?and not to more generally evaluatethe present system as a spell-checker.The evaluations in this section are performed onquad-core Intel Xeon E5450 running at 3 GHz with64 GiB of RAM memory.
The times are averagedover five test runs of 10,000 words in a stable serverenvironment with no server processes or runninggraphical interfaces or other uses.
The test resultsare measured using the getrusage C function ona system that supports the maximum resident stacksize ru maxrss and user time ru utime fields.The times are also verified with the GNU timecommand.
The results for hunspell, Voikkospelland foma processes are only measured with timeand top.
The respective versions of the soft-ware are Voikkospell 3.3, hunspell 1.2.14, and Foma0.9.16alpha.
The reference systems are tested withdefault settings, meaning that they will only givesome fixed number of suggestions whereas our sys-tem will calculate all strings within the given errormodel.As a reference implementation for English we usehunspell?s en-US dictionary9 and for a finite-stateimplementation we use a weighted word-list fromNorvig (2010).
As a Finnish reference implementa-tion we use Voikko10, with a LAG-based dictionaryusing Malaga11.
The reference correction task forGreenlandic is done with foma?s (Hulde?n, 2009b)9http://wiki.services.openoffice.org/wiki/Dictionaries10http://voikko.sf.net11http://home.arcor.de/bjoern-beutel/malaga/6apply med function with default settings12.The baseline feature set and the efficiency ofspell-checking we are targeting is defined by the cur-rently de facto standard spelling suite in open sourcesystems, hunspell.In Table 4 we measure the speed of the spell-checking process on native language Wikipediatext with real-world spelling errors and unknownstrings.
The error model rows are defined as fol-lows: on the Reference impl.
row, we test the spell-checking speed of the hunspell tool for English, andVoikkospell tool for Finnish.
On the edit distance 2row we use the basic traditional edit distance 2 with-out any modifications.
On the No first edits row weuse the error model that does not modify the firstcharacter of the word.
On the No redundancy rowwe use the edit distance 2 error model with the re-dundant edit combinations removed.
On the No re-dundancy and firsts rows we use the combined er-ror model of No first edits and No redundancy func-tionalities.
On the row Lower order first we apply alower order edit distance model first, then if no re-sults are found, a higher order model is used.
In thetables and formulae we routinely use the languagecodes to denote the languages: en for English, fi forFinnish and kl for Greenlandic (Kalaallisut).Error model En Fi KlReference impl.
9.93 7.96 11.42Generate all edits 2 3818.20 118775.60 36432.80Edit distance 1 0.26 6.78 4.79Edit distance 2 7.55 220.42 568.36No first edits 1 0.44 3.19 3.52No firsts ed 2 1.38 61.88 386.06No redundancy ed 2 7.52 4230.94 6420.66No redundancy and firsts ed 2 1.51 62.05 386.63Lower order first ed 1 to 2 4.31 157.07 545.91Table 4: Effect of language and error models to speed(time in seconds per 10,000 word forms)The results show that not editing the first posi-tion does indeed give significant boost to the speed,regardless of language model, which is of coursecaused by the significant reduction in search space.However, the redundancy avoidance does not seemto make a significant difference.
This is most likelybecause the amount of duplicate paths in the searchspace is not so proportionally large and their traver-sal will be relatively fast.
The separate application12http://code.google.com/p/Foma/of error models gives the expected timing result be-tween its relevant primary and secondary error mod-els.
It should be noteworthy that, when thinking ofreal world applications, the speed of the most of themodels described here is greater than 1 word per sec-ond (i.e.
10,000 seconds per 10,000 words).We measured memory consumption when per-forming the same tests.
Varying the error model hadlittle to no effect.
Memory consumption was almostentirely determined by the language model, givingconsumptions of 13-7 MiB for English, 0.2 GiB forFinnish and 1.6 GiB for Greenlandic.To measure the degradation of quality when us-ing different error models we count the proportionof suggestion sets that contain the correct correctionamong the corrected strings.
The suggestion sets arethe entire (unrestricted by number) results of correc-tion, with no attempt to evaluate precision13.
Forthis test we use automatically generated corpus ofspelling errors to get the large-scale results.Error model En Fi KlEdit distance 1 0.89 0.83 0.81Edit distance 2 0.99 0.95 0.92Edit distance 3 1.00 0.96 ?No firsts ed 1 0.74 0.73 0.60No firsts ed 2 0.81 0.82 0.69No firsts ed 3 0.82 ?
?Table 5: Effect of language and error models to quality(recall, proportion of suggestion sets containing a cor-rectly suggested word)This test with automatically introduced errorsshows us that with uniformly distributed errors thepenalty of using an error model that ignores word-initial corrections could be significant.
This con-trasts to our findings with real world errors, that thedistribution of errors tends towards the end of theword, described in 2.2 and (Bhagat, 2007), but itshould be noted that degradation can be as bad asgiven here.Finally we measure how the text type usedwill affect the speed of spell-checking.
As thebest-case scenario we use the unmodified texts ofWikipedia, which contain probably the most real-istic native-language-speaker-like typing error dis-13Which, in the absence of suitable error corpora and a morefull-fledged language model taking context into account, wouldbe irrelevant for the goal at hand.7tribution available.
For text with more errors,where the majority of errors should be recoverable,we introduce automatically generated errors in theWikipedia texts.
Finally to see the performance inthe worst case scenario where most of the wordshave unrecoverable spelling errors we use textsfrom other languages, in this case English texts forFinnish and Greenlandic spell-checking and Finnishtexts for English spell-checking, which should bringus close to the lower bounds on performance.
Theeffects of text type (i.e.
frequency of non-words) onspeed of spell-checking is given in Table 6.
All ofthe tests in this category were performed with er-ror models under the avoid redundancy and firstsed 2 row in previous tables, which gave us the bestspeed/quality ratio.Error model En Fi KlNative Lang.
Corpus 1.38 61.88 386.06Added automatic errors 6.91 95.01 551.81Text in another language 22.40 148.86 783.64Table 6: Effect of text type on error models to speed (inseconds per 10,000 word-forms)Here we chiefly note that the amount of non-words in text directly reflects the speed of spell-checking.
This shows that the dominating factor ofthe speed of spell-checking is indeed in the correct-ing of misspelled words.5 Conclusions and Future WorkIn this article, we built a full-fledged finite-statespell-checking system from existing finite-state lan-guage models and generated error models.
Thiswork uses the system initially described in Pirinenand Linde?n (2010) and an algorithm described inLinde?n et al (2012), providing an extensive quan-titative evaluation of various combinations of con-stituents for such a system, and applying it to themost challenging linguistic environments availablefor testing.
We showed that using on-line composi-tion of the word form, error model and dictionary isusable for morphologically complex languages.
Fur-thermore we showed that the error models can be au-tomatically optimised in several ways to gain somespeed at cost of recall.We showed that the memory consumption of thespell-checking process is mainly unaffected by theselection of error model, apart from the need to storea greater set of suggestions for models that generatemore suggestions.
The error models may thereforebe quite freely changed in real world applications asneeded.We verified that correcting only the first input let-ter affords a significant speed improvement, but thatthis improvement is not greatly dependent on the po-sition of such a restriction.
This practice is some-what supported by our tentative finding that it maycause the least drop in practical recall figures, atleast in Finnish.
It is promising especially in con-junction with a fallback model that does correct thefirst letter.We described a way to avoid having a finite-stateerror model perform redundant work, such as delet-ing and inserting the same letter in succession.
Thepractical improvement from doing this is extremelymodest, and it increases the size of the error model.In this research we focused on differences in au-tomatically generated error models and their optimi-sations in the case of morphologically complex lan-guages.
For future research we intend to study morerealistic error models induced from actual error cor-pora (e.g.
Brill and Moore (2000)).
Research intodifferent ways to induce weights into the languagemodels, as well as further use of context in finite-state spell-checking (as in Pirinen et al (2012)), iswarranted.AcknowledgementsWe thank the anonymous reviewers for their com-ments and the HFST research team for fruity discus-sions on the article?s topics.
The first author thanksthe people of Oqaaserpassualeriffik for introducingthe problems and possibilities of finite-state appli-cations to the morphologically complex language ofGreenlandic.ReferencesCyril Allauzen and Mehryar Mohri.
2009.
N-way com-position of weighted finite-state transducers.
Interna-tional Journal of Foundations of Computer Science,20:613?627.Kenneth R Beesley and Lauri Karttunen.
2003.
FiniteState Morphology.
CSLI publications.8Meenu Bhagat.
2007.
Spelling error pattern analysis ofpunjabi typed text.
Master?s thesis, Thapar University.Eric Brill and Robert C. Moore.
2000.
An improvederror model for noisy channel spelling correction.
InACL ?00: Proceedings of the 38th Annual Meetingon Association for Computational Linguistics, pages286?293, Morristown, NJ, USA.
Association for Com-putational Linguistics.Fred J Damerau.
1964.
A technique for computer detec-tion and correction of spelling errors.
Commun.
ACM,(7).Ahmed Hassan, Sara Noeman, and Hany Hassan.
2008.Language independent text correction using finite stateautomata.
In Proceedings of the Third InternationalJoint Conference on Natural Language Processing,volume 2, pages 913?918.Ma?ns Hulde?n.
2009a.
Fast approximate string match-ing with finite automata.
Procesamiento del LenguajeNatural, 43:57?64.Ma?ns Hulde?n.
2009b.
Foma: a finite-state compilerand library.
In Proceedings of the 12th Conference ofthe European Chapter of the Association for Compu-tational Linguistics: Demonstrations Session, EACL?09, pages 29?32, Stroudsburg, PA, USA.
Associationfor Computational Linguistics.Kimmo Koskenniemi.
1983.
Two-level Morphology: AGeneral Computational Model for Word-Form Recog-nition and Production.
Ph.D. thesis, University ofHelsinki.Karen Kukich.
1992.
Techniques for automatically cor-recting words in text.
ACM Comput.
Surv., 24(4):377?439.Vladimir I. Levenshtein.
1966.
Binary codes capable ofcorrecting deletions, insertions, and reversals.
SovietPhysics?Doklady 10, 707710.
Translated from Dok-lady Akademii Nauk SSSR, pages 845?848.Krister Linde?n, Erik Axelson, Senka Drobac, Sam Hard-wick, Miikka Silfverberg, and Tommi A Pirinen.2012.
Using hfst for creating computational linguisticapplications.
In Proceedings of Computational Lin-guistics - Applications, 2012, page to appear.Petar Nikolaev Mitankin.
2005.
Universal levenshteinautomata.
building and properties.
Master?s thesis,University of Sofia.Roger Mitton.
2009.
Ordering the suggestions of aspellchecker without using context*.
Nat.
Lang.
Eng.,15(2):173?192.Peter Norvig.
2010.
How to write a spelling corrector.referred 2011-01-11, available http://norvig.com/spell-correct.html.Kemal Oflazer.
1996.
Error-tolerant finite-state recog-nition with applications to morphological analysis andspelling correction.
Comput.
Linguist., 22(1):73?89.Tommi A Pirinen and Krister Linde?n.
2010.
Finite-statespell-checking with weighted language and error mod-els.
In Proceedings of the Seventh SaLTMiL workshopon creation and use of basic lexical resources for less-resourced languagages, pages 13?18, Valletta, Malta.Tommi Pirinen, Miikka Silfverberg, and Krister Linden.2012.
Improving finite-state spell-checker suggestionswith part of speech n-grams.
In Internatational Jour-nal of Computational Linguistics and Applications IJ-CLA (to appear).Tommi A Pirinen.
2011.
Modularisation of finnishfinite-state language descriptiontowards wide collab-oration in open source development of morphologicalanalyser.
In Proceedings of Nodalida, volume 18 ofNEALT proceedings.Harri Pitka?nen.
2006.
Hunspell-in kesa?koodi 2006: Fi-nal report.
Technical report.Joseph J. Pollock and Antonio Zamora.
1984.
Auto-matic spelling correction in scientific and scholarlytext.
Commun.
ACM, 27(4):358?368, April.Klaus Schulz and Stoyan Mihov.
2002.
Fast string cor-rection with levenshtein-automata.
International Jour-nal of Document Analysis and Recognition, 5:67?85.Emmanuel J Yannakoudakis and D Fawthrop.
1983.
Anintelligent spelling error corrector.
Information Pro-cessing and Management, 19(2):101?108.9
