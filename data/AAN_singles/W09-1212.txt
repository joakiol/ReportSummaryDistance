Proceedings of the Thirteenth Conference on Computational Natural Language Learning (CoNLL): Shared Task, pages 79?84,Boulder, Colorado, June 2009. c?2009 Association for Computational LinguisticsA Second-Order Joint Eisner Model for Syntactic and Semantic DependencyParsingXavier Llu?
?s Stefan Bott Llu?
?s Ma`rquezTALP Research Center ?
Software Department (LSI)Technical University of Catalonia (UPC){xlluis,sbott,lluism}@lsi.upc.eduAbstractWe present a system developed for theCoNLL-2009 Shared Task (Hajic?
et al, 2009).We extend the Carreras (2007) parser tojointly annotate syntactic and semantic depen-dencies.
This state-of-the-art parser factor-izes the built tree in second-order factors.
Weinclude semantic dependencies in the factorsand extend their score function to combinesyntactic and semantic scores.
The parser iscoupled with an on-line averaged perceptron(Collins, 2002) as the learning method.
Ouraveraged results for all seven languages are71.49 macro F1, 79.11 LAS and 63.06 seman-tic F1.1 IntroductionSystems that jointly annotate syntactic and semanticdependencies were introduced in the past CoNLL-2008 Shared Task (Surdeanu et al, 2008).
Thesesystems showed promising results and proved thefeasibility of a joint syntactic and semantic pars-ing (Henderson et al, 2008; Llu?
?s and Ma`rquez,2008).The Eisner (1996) algorithm and its variants arecommonly used in data-driven dependency pars-ing.
Improvements of this algorithm presentedby McDonald et al (2006) and Carreras (2007)achieved state-of-the-art performance for English inthe CoNLL-2007 Shared Task (Nivre et al, 2007).Johansson and Nugues (2008) presented a sys-tem based on the Carreras?
extension of the Eis-ner algorithm that ranked first in the past CoNLL-2008 Shared Task.
We decided to extend the Car-reras (2007) parser to jointly annotate syntactic andsemantic dependencies.The present year Shared Task has the incentiveof being multilingual with each language presentingtheir own particularities.
An interesting particularityis the direct correspondence between syntactic andsemantic dependencies provided in Catalan, Spanishand Chinese.
We believe that these correspondencescan be captured by a joint system.
We specially lookat the syntactic-semantic alignment of the Catalanand Spanish datasets.Our system is an extension of the Llu?
?s andMa`rquez (2008) CoNLL-2008 Shared Task system.We introduce these two following novelties:?
An extension of the second-order Car-reras (2007) algorithm to annotate semanticdependencies.?
A combined syntactic-semantic scoring forCatalan and Spanish to exploit the syntactic-semantic mappings.The following section outlines the system archi-tecture.
The next sections present in more detail thesystem novelties.2 ArchitectureThe architecture consists on four main components:1) Preprocessing and feature extraction.
2) Syntacticpreparsing.
3) Joint syntactic-semantic parsing.
4)Predicate classification.The preprocessing and feature extraction is in-tended to ease and improve the performance ofthe parser precomputing a binary representation of79each sentence features.
These features are borrowedfrom existing and widely-known systems (Xue andPalmer, 2004; McDonald et al, 2005; Carreras et al,2006; Surdeanu et al, 2007).The following step is a syntactic pre-parse.
Itis only required to pre-compute additional features(e.g., syntactic path, syntactic frame) from the syn-tax.
These new features will be used for the semanticrole component of the following joint parser.The joint parser is the core of the system.
Thissingle algorithm computes the complete parse thatoptimizes a score according to a function that de-pends on both syntax and semantics.
Some of therequired features that could be unavailable or expen-sive to compute at that time are provided by the pre-vious syntactic pre-parse.The predicate sense classification is performed asthe last step.
Therefore no features representing thepredicate sense are employed during the training.The predicates are labeled with the most frequentsense extracted from the training corpus.No further postprocessing is applied.3 Second-order Eisner modelThe Carreras?
extension of the Eisner inference al-gorithm is an expensive O(n4) parser.
The numberof assignable labels for each dependency is a hiddenmultiplying constant in this asymptotic cost.We begin describing a first-order dependencyparser.
It receives a sentence x and outputs a de-pendency tree y.
A dependency, or first-order factor,is defined as f1 = ?h,m, l?.
Where h is the headtoken, m the modifier and l the syntactic label.
Thescore for this factor f1 is computed as:score1(f1, x,w) = ?
(h,m, x) ?w(l)Where w(l) is the weight vector for the syntactic la-bel l and ?
a feature extraction function.The parser outputs the best tree y?
from the setT (x) of all projective dependency trees.y?
(x) = argmaxy?T (x)?f1?yscore(f1, x,w)The second-order extension decomposes the de-pendency tree in factors that include some childrenof the head and modifier.
A second-order factor is:f2 = ?h,m, l, ch, cmo, cmi?where ch is the daughter of h closest to m withinthe tokens [h, .
.
.
,m]; cmo is the outermost daugh-ter of m outside [h, .
.
.
,m]; and cmi is the furthestdaughter of m inside [h, .
.
.
,m].The score for these new factors is computed byscore2(f2, x,w) = ?
(h,m, x) ?w(l) +?
(h,m, ch, x) ?w(l)ch +?
(h,m, cmi, x) ?w(l)cmi +?
(h,m, cmo, x) ?w(l)cmoThe parser builds the best-scoring projective treefactorized in second-order factors.
The score of thetree is also defined as the sum of the score of itsfactors.3.1 Joint second-order modelWe proceeded in an analogous way in which theLlu?
?s and Ma`rquez (2008) extended the first-orderparser.
That previous work extended a first-ordermodel by including semantic labels in first-order de-pendencies.Now we define a second-order joint factor as:f2syn-sem =?h,m, l, ch, cmo, cmi, lsemp1 , .
.
.
, lsempq?Note that we only added a set of semantic labelslsemp1 , .
.
.
, lsempq to the second-order factor.
Eachone of these semantic labels represent, if any, onesemantic relation between the argument m and thepredicate pi.
There are q predicates in the sentence,labeled p1, .
.
.
, pq.The corresponding joint score to a given joint fac-tor is computed by adding a semantic score to thepreviously defined score2 second-order score func-tion:score2syn-sem(f2syn-sem, x,w) =score2(f2, x,w) +?piscoresem(h,m, pi, lsempi , x,w)qwhere,scoresem(h,m, pi, lsem, x,w) =?sem(h,m, pi, x) ?w(lsem)80We normalize the semantic score by the numberof predicates q.
The semantic score is computed as ascore betweenm and each sentence predicate pi.
Nosecond-order relations are considered in these scorefunctions.
The search of the best ch, cmo and cmi isindependent of the semantic components of the fac-tor.
The computational cost of the algorithm is in-creased by one semantic score function call for everym, h, and pi combination.
The asymptotic cost ofthis operation is O(q ?
n2) and it is sequentially per-formed among other O(n2) operations in the mainloop of the algorithm.Algorithm 1 Extension of the Carreras (2007) algo-rithmC[s][t][d][m]?
0, ?s, t, d,mO[s][t][d][l]?
0,?s, t, d, lfor k = 1, .
.
.
, n dofor s = 0, .
.
.
, n?
k dot?
s+ k?l O[s][t][?
][l] = maxr,cmi,chC[s][r][?
][cmi] + C[r + 1][t][?
][ch]+score(t, s, l)+scorecmi(t, s, cmi, l)+scorech(t, s, l, ch)+?pi maxlsemscoresem(t, s, pi, lsem)/q?l O[s][t][?
][l] = maxr,cmi,chC[s][r][?
][ch] + C[r + 1][t][?
][cmi]+score(s, t, l)+scorecmi(s, t, cmi, l)+scorech(s, t, l, ch)+?pi maxlsemscoresem(t, s, pi, lsem)/q?m C[s][t][?
][m] = maxl,cmoC[s][m][?
][cmo] +O[m][t][?
][l]+scorecmo(s,m, l, cmo)?m C[s][t][?
][m] = maxl,cmoO[s][m][?
][l] + C[m][t][?
][cmo]+scorecmo(m, t, l, cmo)end forend forOur implementation slightly differs from the orig-inal Carreras algorithm description.
The main dif-ference is that no specific features are extracted forthe second-order factors.
This allows us to reuse thefeature extraction mechanism of a first-order parser.Algorithm 1 shows the Carreras?
extension of theEisner algorithm including our proposed joint se-mantic scoring.The tokens s and t represent the start and endtokens of the current substring, also called span.The direction d ?
{?,?}
defines whether t ors is the head of the last dependency built insidethe span.
The score functions scorech,scorecmi andscorecmo are the linear functions that build up thepreviously defined second-order global score, e.g.,scorech= ?
(h,m, ch, x)?w(l)ch .
The two tablesC andO maintain the dynamic programming structures.Note that the first steps of the inner loop are ap-plied for all l, the syntactic label, but the semanticscore function does not depend on l. Therefore thebest semantic label can be chosen independently.For simplicity, we omitted the weight vectors re-quired in each score function and the backpointerstables to save the local decisions.
We also omit-ted the definition of the domain of some variables.Moreover, the filter of the set of assignable labelsis not shown.
A basic filter regards the POS of thehead and modifier to filter out the set of possible ar-guments for each predicate.
Another filter extractthe set of allowed arguments for each predicate fromthe frames files.
These last filters were applied to theEnglish, German and Chinese.3.2 Catalan and Spanish joint modelThe Catalan and Spanish datasets (Taule?
et al, 2008)present two interesting properties.
The first prop-erty, as previously said, is a direct correspondencebetween syntactic and semantic labels.
The secondinteresting property is that all semantic dependen-cies exactly overlap with the syntactic tree.
Thusthe semantic dependency between a predicate andan argument always has a matching syntactic depen-dency between a head and a modifier.
The Chinesedata also contains direct syntactic-semantic map-pings.
But due to the Shared Task time constraintswe did not implemented a specific parsing methodfor this language.The complete overlap between syntax and seman-tics can simplify the definition of a second-orderjoint factor.
In this case, a second-order factor willonly have, if any, one semantic dependency.
We onlyallow at most one semantic relation lsem betweenthe head token h and the modifier m. Note that hmust be a sentence predicate and m its argument if81lsem is not null.
We extend the second-order fac-tors with a single and possibly null semantic label,i.e., f2syn-sem = ?h,m, l, ch, cmo, cmi, lsem?.
Thisslightly simplifies the scoring function:score2syn-sem(f2syn-sem, x,w) =score2(f2, x,w) +?
?
scoresem(h,m, x,w)where ?
is an adjustable parameter of the model and,scoresem(h,m, x,w) = ?sem(h,m, x) ?w(lsem)The next property that we are intended to exploitis the syntactic-semantic mappings.
These map-pings define the allowed combinations of syntacticand semantic labels.
The label combinations canonly be exploited when there is semantic depen-dency between the head h and the modifier m of afactor.
An argument identification classifier deter-mines the presence of a semantic relation, given his a predicate.
In these cases we only generate fac-tors that are compliant with the mappings.
If a syn-tactic label has many corresponding semantic labelswe will score all of them and select the combinationwith the highest score.The computational cost is not significantly in-creased as there is a bounded number of syntacticand semantic combinations to score.
In addition, theonly one-argument-per-factor constraint reduces thecomplexity of the algorithm with respect to the pre-vious joint extension.We found some inconsistencies in the frames filesprovided by the organizers containing the correspon-dences between syntax and semantics.
For this rea-son we extracted them directly from the corpus.
Theextracted mappings discard the 7.9% of the cor-rect combinations in the Catalan development cor-pus that represent a 1.7% of its correct syntactic de-pendencies.
The discarded semantic labels are the5.14% for Spanish representing the 1.3% of the syn-tactic dependencies.4 Results and discussionTable 1 shows the official results for all seven lan-guages, including out-of-domain data labeled asood.
The high computational cost of the second-order models prevented us from carefully tuning thesystem parameters.
After the shared task evaluationdeadline, some bug were corrected, improving thesystem performance.
The last results are shown inparenthesis.The combined filters for Catalan and Spanish hurtthe parsing due to the discarded correct labels butwe believe that this effect is compensated by an im-proved precision in the cases where the correct la-bels are not discarded.
For example, in Spanishthese filters improved the syntactic LAS from 85.34to 86.77 on the development corpus using the goldsyntactic tree as the pre-parse tree.Figure 1 shows the learning curve for the Englishand Czech language.
The results are computed inthe development corpus.
The semantic score is com-puted using gold syntax and gold predicate senseclassification.
We restricted the learning curve tothe first epoch.
Although the this first epoch is veryclose to the best score, some languages showed im-provements until the fourth epoch.
In the figure wecan see better syntactic results for the joint systemwith respect to the syntactic-only parser.
We shouldnot consider this improvement completely realisticas the semantic component of the joint system usesgold features (i.e., a gold pre-parse).
Nonetheless,it points that a highly accurate semantic componentcould improve the syntax.Table 2 shows the training time for a second-ordersyntactic and joint configurations of the parser.
Notethat the time per instance is an average and somesentences could require a significantly higher time.Recall that our parser is O(n4) dependant on thesentence length.
We discarded large sentences dur-ing training for efficiency reasons.
We discardedsentences with more than 70 words for all languagesexcept for Catalan and Spanish where the thresh-old was set to 100 words in the syntactic parser.This larger number of sentences is aimed to im-prove the syntactic performance of these languages.The shorter sentences used in the joint parsing andthe pruning of the previously described filters re-duced the training time for Catalan and Spanish.
Theamount of main memory consumed by the system is0.5?1GB.
The machine used to perform the compu-tations is an AMD64 Athlon 5000+.82avg cat chi cze eng ger jap spamacro F1 71.49 (74.90) 56.64 (73.21) 66.18 (70.91) 75.95 81.69 72.31 81.76 65.91 (68.46)syn LAS 79.11 (82.22) 64.21(84.20) 70.53 (70.90) 75.00 87.48 81.94 91.55 83.09 (84.48)semantic F1 63.06 (67.41) 46.79 (61.68) 59.72 (70.88) 76.90 75.86 62.66 71.60 47.88 (52.30)ood macro F1 71.92 - - 74.56 73.91 67.30 - -ood syn LAS 75.09 - - 72.11 80.92 72.25 - -ood sem F1 68.74 - - 77.01 66.88 62.34 - -Table 1: Overall results.
In parenthesis post-evaluation results.cat chi cze eng ger jap spasyntax only (s/sentence) 18.39 8.07 3.18 2.56 1.30 1.07 15.31joint system (s/sentence) 10.91 9.49 3.99 3.13 2.36 1.25 12.29Table 2: Parsing time per sentence.707274767880828486889092  102030405060708090100semanic f1, LAS% of corpussyn czsyn czjointsemcz joint syn engsyn eng jointsemeng jointFigure 1: Learning curves for the syntactic-only and jointparsers in Czech and English.5 ConclusionWe have shown that a joint syntactic-semanticparsing can be based on the state-of-the-art Car-reras (2007) parser at an expense of a reasonablecost.
Our second-order parser still does not repro-duce the state-of-the art results presented by similarsystems (Nivre et al, 2007).
Although we achievedmild results we believe that a competitive systembased in our model can be built.
Further tuning isrequired and a complete set of new second-order fea-tures should be implemented to improve our parser.The multilingual condition of the task allows us toevaluate our approach in seven different languages.A detailed language-dependent evaluation can giveus some insights about the strengths and weaknessesof our approach across different languages.
Unfor-tunately we believe that this objective was possiblynot accomplished due to the time constraints.The Catalan and Spanish datasets presented in-teresting properties that could be exploited.
Themapping between syntax and semantics should bespecially useful for a joint system.
In additionthe semantic dependencies for these languages arealigned with the projective syntactic dependencies,i.e., the predicate-argument pairs exactly match syn-tactic dependencies.
This is a useful property to si-multaneously build joint dependencies.6 Future and ongoing workOur syntactic and semantic parsers, as many others,is not exempt of bugs.
Furthermore, very few tuningand experimentation was done during the develop-ment of our parser due to the Shared Task time con-straints.
We believe that we still did not have enoughdata to fully evaluate our approach.
Further exper-imentation is required to asses the improvement ofa joint architecture vs. a pipeline architecture.
Alsoa careful analysis of the system across the differentlanguages is to be performed.AcknowledgmentsWe thank the corpus providers (Taule?
et al, 2008;Palmer and Xue, 2009; Hajic?
et al, 2006; Surdeanuet al, 2008; Burchardt et al, 2006; Kawahara et al,2002) for their effort in the annotation and conver-sion of the seven languages datasets.83ReferencesAljoscha Burchardt, Katrin Erk, Anette Frank, AndreaKowalski, Sebastian Pado?, and Manfred Pinkal.
2006.The SALSA corpus: a German corpus resource forlexical semantics.
In Proceedings of the 5th Interna-tional Conference on Language Resources and Evalu-ation (LREC-2006), Genoa, Italy.Xavier Carreras, Mihai Surdeanu, and Llu?
?s Ma`rquez.2006.
Projective dependency parsing with perceptron.In Proceedings of the 10th Conference on Computa-tional Natural Language Learning (CoNLL-2006).Xavier Carreras.
2007.
Experiments with a higher-orderprojective dependency parser.
In Proceedings of the11th Conference on Computational Natural LanguageLearning (CoNLL-2007).Michael Collins.
2002.
Discriminative training meth-ods for hidden markov models: Theory and experi-ments with perceptron algorithms.
In Proceedings ofthe ACL-02 conference on Empirical methods in natu-ral language processing.Jason M. Eisner.
1996.
Three new probabilistic modelsfor dependency parsing: An exploration.
In Proceed-ings of the 16th International Conference on Compu-tational Linguistics (COLING-96).Jan Hajic?, Jarmila Panevova?, Eva Hajic?ova?, PetrSgall, Petr Pajas, Jan S?te?pa?nek, Jir???
Havelka, MarieMikulova?, and Zdene?k Z?abokrtsky?.
2006.
Prague De-pendency Treebank 2.0.Jan Hajic?, Massimiliano Ciaramita, Richard Johans-son, Daisuke Kawahara, Maria Anto`nia Mart?
?, Llu?
?sMa`rquez, Adam Meyers, Joakim Nivre, SebastianPado?, Jan S?te?pa?nek, Pavel Stran?a?k, Mihai Surdeanu,Nianwen Xue, and Yi Zhang.
2009.
The CoNLL-2009 shared task: Syntactic and semantic depen-dencies in multiple languages.
In Proceedings ofthe 13th Conference on Computational Natural Lan-guage Learning (CoNLL-2009), June 4-5, Boulder,Colorado, USA.James Henderson, Paola Merlo, Gabriele Musillo, andIvan Titov.
2008.
A latent variable model of syn-chronous parsing for syntactic and semantic depen-dencies.
In Proceedings of the 12th Conference onComputational Natural Language Learning (CoNLL-2008), Manchester, UK.Richard Johansson and Pierre Nugues.
2008.Dependency-based syntactic?semantic analysiswith propbank and nombank.
In Proceedings of the12th Conference on Computational Natural LanguageLearning (CoNLL-2008), Manchester, UK.Daisuke Kawahara, Sadao Kurohashi, and Ko?iti Hasida.2002.
Construction of a Japanese relevance-taggedcorpus.
In Proceedings of the 3rd InternationalConference on Language Resources and Evaluation(LREC-2002), pages 2008?2013, Las Palmas, CanaryIslands.Xavier Llu?
?s and Llu?
?s Ma`rquez.
2008.
A joint modelfor parsing syntactic and semantic dependencies.
InProceedings of the 12th Conference on ComputationalNatural Language Learning (CoNLL-2008), Manch-ester, UK.Ryan McDonald and Fernando Pereira.
2006.
On-line learning of approximate dependency parsing algo-rithms.
In 11th Conference of the European Chapter ofthe Association for Computational Linguistics (EACL-2006).Ryan McDonald, Koby Crammer, and Fernando Pereira.2005.
Online large-margin training of dependencyparsers.
In Proceedings of the 43rd Annual Meeting ofthe Association for Computational Linguistics (ACL-2005).J.
Nivre, J.
Hall, S. Ku?bler, R. McDonald, J. Nilsson,S.
Riedel, and D. Yuret.
2007.
The CoNLL 2007shared task on dependency parsing.Martha Palmer and Nianwen Xue.
2009.
Adding seman-tic roles to the Chinese Treebank.
Natural LanguageEngineering, 15(1):143?172.Mihai Surdeanu, Llu?
?s Ma`rquez, Xavier Carreras, andPere R. Comas.
2007.
Combination strategies for se-mantic role labeling.
Journal of Artificial IntelligenceResearch.Mihai Surdeanu, Richard Johansson, Adam Meyers,Llu?
?s Ma`rquez, and Joakim Nivre.
2008.
The CoNLL-2008 shared task on joint parsing of syntactic and se-mantic dependencies.
In Proceedings of the 12th Con-ference on Computational Natural Language Learning(CoNLL-2008).Mariona Taule?, Maria Anto`nia Mart?
?, and Marta Re-casens.
2008.
AnCora: Multilevel Annotated Corporafor Catalan and Spanish.
In Proceedings of the 6thInternational Conference on Language Resources andEvaluation (LREC-2008), Marrakesh, Morroco.Nianwen Xue and Martha Palmer.
2004.
Calibrating fea-tures for semantic role labeling.
In Proceedings of theEmpirical Methods in Natural Language Processing(EMNLP-2004).84
