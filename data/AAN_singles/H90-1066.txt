Recognition of Noisy Speech:Using Minimum-Mean Log-Spectral Distance EstimationA.
Ere11 and M. WeintraubSRI International333 Ravenswood Ave.Menlo Park, CA 94025AbstractA model-based spectral estimation algorithm is derivedthat improves the robustness of speech recognitionsystems to additive noise.
The algorithm is tailored forfilter-bank-based systems, where the estimation shouldseek to minimize the distortion as measured by therecognizer's distance metric.
This estimation criterion isapproximated by minimizing the Euclidean distancebetween spectral log-energy vectors, which is equivalentto minimizing the nonweighted, nontruncated cepstraldistance.
Correlations between frequency channels areincorporated in the estimation by modeling the spectraldistribution of speech as a mixture of components, eachrepresenting a different speech class, and assuming thatspectral energies at different frequency channels areuncorrelated within each class.
The algorithm was testedwith SRI's continuous-speech, speaker-independent,hidden Markov model recognition system using the large-vocabulary NIST "Resource Management Task."
Whentrained on a clean-speech database and tested withadditive white Gaussian noise, the new algorithm has anerror rate half of that with MMSE estimation of logspectral energies at individual frequency channels, and itachieves a level similar to that with the ideal condition oftraining and testing at constant SNR.
The algorithm isalso very efficient with additive environmental noise,recorded with a desktop microphone.I.
IntroductionSpeech-recognition systems are very sensitive todifferences between the testing and training conditions.In particular, systems that are trained on high-qualityspeech degrade drastically in noisy environments.Several methods for handling this problem are incommon use, among them supplementing the acousticfront end of the recognizer with a statistical estimator.This paper introduces a novel estimation algorithm for afilter-bank-based front end and describes recognitionexperiments with noisy speech.The problem of designing a statistical estimator forspeech recognition is that of defining an optimalitycriterion that will match the recognizer, and deriving analgorithm to compute the estimator based on thiscriterion.
Defining the optimal criterion is easier forspeech recognition than it is for speech enhancement forhuman listeners, since the signal processing is known inthe former, but not in the latter.
For a recognition systemthat is based on a distance metric, whether for templatematching or vector quantization, a reasonable criterionwould be to minimize the average distortion as measuredby the distance metric.
In practice, achieving thiscriterion may turn out not to be feasible, and the questionis then to what extent the computationally feasiblemethods approximate the desired optirnality criterion.A basic difference between the cepstral distancecriterion and the MMSE of single frequency channels(whether DFT coefficients or filter energies) is that theformer implies a joint estimate of a feature vector,whereas the latter implies an independent estimation ofscalar variables.
Because the speech spectral energies atdifferent frequencies are correlated, an independentestimate of individual channels results in a suboptimalestimation.
To incorporate part of the correlations in theestimator, we modified our single-channel MMSE to beconditioned on the total energy in addition to the filterenergy.
This modification indeed improved performancesignificantly.We here derive a more rigorous method ofapproximating the cepstral distance criterion.
Theoptimality criterion is the minimization of the distortionas measured by the Euclidean distance between vectors offilter log energies.
We name the algorithm minimum-mean-log-spectral-distance (MMLSD).
The MMLSD isequivalent to minimizing the nonweighted, nontruncatedcepstral distance rather than the weighted, truncated oneused by the recognizer.
The necessity for thiscompromise arises from the difficulty in modeling thestatistics of additive noise in the transform domain,whereas a model can be constructed in the spectraldomain [for details see Eq.
(2): the approximation therewill not work for the transformed vector].The MMLSD estimator is first computed using astationary model for the speech spectral probabilitydistribution (PD).
The PD of the filter log-energy vectorsis assumed to comprise a mixture of classes, within whichdifferent filter energies are statistically independent.Several implementations of this model are considered,including vector quanfizafion and a maximum-likelihodfit to a mixture of Gaussian distributions.II.
Minimum-mean log-spectral distanceestimationThe MMSE on the vector S of K filter log-energiesyields the following vector estimatorS =)  P (S I S') dS , (1)where ~' is the observed noisy vector, P(S~)is~he cleanspeech log-spectral vector PD, and P(S'I S) is theconditional probability of the noisy log-spectral vectorgiven the clean.
This estimator is considerably morecomplex than the independent MMSE of single channelsbecause it requires an integration of K-dimensionalprobability distributions.
However, its computation canproceed using the following models for P (S'I S) andP(S).The conditioned probability P (S' I S) can be modeledsimply as the product of the marginal probabilities,~ KP (S' I  S )= I I  P (S 'k lSk)k=l(2)where P(S'klSk) is given in \[1\].
This factonzation is areasonable approximation because the noise i suncorrelated in the frequency domain and because, foradditive noise, the value of a given noisy filter energy,S'k, depends only on the clean energy Sk and on the noiselevel in that frequency.
This model is obviously only anapproximation for overlapping filters.A similar factorization of P(S) would lead to MMSE ofindividual frequency channels.
However, such afactodzafion would be very inaccurate because the speechsignal is highly correlated in the frequency domain.
Amore accurate model that partly incorporates thecorrelations between frequency channels is the followingmixture model:N --, ~ KP (S)= ~ CnPn(S) Pn(S)=I'I Pn(SK) (3)n=l ' k=lthe idea being that the acoustic space can be divided intoclasses within which the correlation between differentfrequency channels is significantly smaller than in thespace as a whole.
An easily implementedparameterization would be to model the probabilitiesPn(Sk) as Gaussian with means ktnk and standarddeviations (Yak.
The classes can represent either mutuallyexclusive or overlapping regions of the acoustic space.The estimator isnow given bySk = ~ Sk I n ?
P(nl S --r)n=l(4)where the first term is the n th class-conditioned MMSEestimator, computed similarly to Eq.
(2) with P(Sk)replaced by Pn(Sk):/"k'n- !
)P (Sk I n)P (Sk I n)tSk P (Sk I Sk) Pn (Sk) dSk(5a)P (S k I Sk) Pn (Sk) dSk (5b)and the second term is the a posteriori probability thatthe clean speech vector belonged to the n th class, givenbyP(n IS') = C n P(S' In) NZ - "  C n P(S' In)n=l(6a)wh~eKP(S-71n) =H P ( S 'k I n)k=l(6b)Thus the estimator is a weighted sum of class-conditioned MMSE estimators.HI.
Speech-recognition experimentsWe evaluated the above algorithms with SRI'sDECIPHER continuous-speech, speaker-independent,I-IMM recognition system \[2\].
The recognition task wasthe 1,000-word vocabulary of the DARPA-NIST"Resource management task" using a word-pair grammarwith of perplexity 60 \[3\].
The training was based on3,990 sentences ofhigh-quality speech, recorded at TexasInstruments in a sound-attenuated room with a close-talking microphone (designated by NIST as the February1989 large training set).The testing material was from the DARPA-NIST"Resource Management Task" February 1989 test set \[3\]and consisted of 30 sentences from each of 10 talkers notin the training set, with two types of additive noise.
Thefirst is a computer-generated white Gaussian oise, addedto the waveform at a global SNR of 10 dB.
The SNR inindividual frequency channels, averaged over all channels342and speakers, was 9 dB.
The second is environmentalnoise recorded at SRI's speech laboratory with a desktopmicrophone.
The environmental noise was quasistationary, predominantly generated by air conditioning,and had most of its energy concentrated in the lowfrequencies.
The noise was sampled and added igitallyto the speech waveforms with global SNR of 0 dB; theSNR in individual frequency channels, averaged over allchannels and speakers, was 12 dB.The experiments in the environmental noise have beenconducted both with and without uning of the estimationalgorithms to this particular noise.
The tuning consistedof adjusting the degrees-of-freedom parameter in the chi-squared model, for the noise-filter energy, wide-bandenergy and total energy.
Without uning, the parametervalues were those determined for white noise.
Asignificant difference between the degrees of freedom forwhite noise and for environmental noise was found for thetotal-energy model: Because most of the environmentalnoise energy concentrated in the low frequencies, thenumber of degrees of freedom was very small comparedto that with white noise.
Only minor differences werefound for the wide-band energies, and even smallerdifferences for the filter log energies.Table 1 lists for reference the error rates with andwithout additive white Gaussian oise at 10-dB SNR,without any processing and with MMSE estimation.Table 2 lists error rates with white Gaussian noise,comparing the single-frame MMLSD algorithm with fourmixture models, as a function of the number of classes N.With N=I, all the mixture models are identical to theMMSE estimator whose performance is given in Table 1.MMLSD-VQ and GM achieve the lowest error ates, withan insignificant edge to MMLSD-GM.
The performanceof both algorithms improves lowly but significantlywhen the number of classes N increases from 4 to 128.MMLSD-TE achieves error rates comparable toMMLSD-WB, and both algorithms reach a plateau intheir performance l vel with N=4.
MMLSD-TEP, withthe total energy computed on the preemphasizedwaveform, does not perform as well as MMLSD-TE.Summarizing the results, when training on clean speechand testing with white noise, the best MMLSD algorithmachieves the same error rate as training and testing innoise.
In comparison, the error rate with MMSE is twiceas high.
Replacing the static mixture model by a dynamicMarkov one makes no significant improvement.
Theerror rates with environmental noise for the variousalgorithms are very similar to those with white noise,indicating that the algorithms are effective to a similardegree with the two types of noise.IV.
DiscussionA.
Validity of the mixture modelThe MMLSD estimator computed using the mixturemodel is much superior to the single-channel MMSE,indicating that the mixture model is successful inincorporating correlations between different frequencychannels into the estimation.
An interesting question,however, is to what extent he underlying assumption ofthe mixture model is correct: that is, is the statisticaldependence b tween different frequency channels indeedsmall within a single mixture component.
Measunngcorrelations between frequency channels with overlappingfilters, we found that this assumption is incorrect.
Forexample, with the vector quantization method (MMLSD-VQ) and a code book of size 32, the correlation betweenany pair of adjacent channels is of the order of 0.8,dropping to 0.4 for channels that are 3 filters apart and to0.1 for channels that are 8 filters apart.
The Gaussianmixtures model (MMLSD-GM) did not reduce thecorrelations: the maximum likelihood search convergedon parameters that were very similar to the initialconditions derived from the vector quantization.
Therecognition accuracy obtained with MMLSD-GM isindeed identical to MMLSD-VQ.Examining the MMLSD estimator in Eq.
(4), we findthat it is the a posteriori class probability that iserroneously estimated because of the invalid channel-independence asumption, Eq.
(6b).
The error inestimating this probability is magnified by the highnumber of channels: Small errors accumulate in theproduct Eq.
(6b) of the assumedly independent marginalprobabilities.
In contrast to Eq.
(6b), the output PD forthe nonoverlapping wide bands is more accurate.
With3 bands and 32 classes the correlation between energies ofdifferent bands is approximately 0.15.
Thus, although theoverall MMLSD-WB estimator isnot more accurate thanMMLSD-VQ, the a posteriori class probability is moreaccurately estimated in MMLSD-WB than in MMLSD-VQ.B.
Total energyThe classification according to total energy, computedwithout preemphasis (MMLSD-TE), achieved excellentresults with white noise but did not do as well as the otheralgorithms with the environmental noise.
This result canbe explained by the different SNRs in the two cases:whereas the total energy was 10 dB with the SNR whitenoise, it was 0 dB with the environmental noise.
Becausethe degree to which the a posteriori class probability P(n IE') peaks around the true class depends on the SNR in thetotal energy, it not surprising that MMLSD-TE wasefficient for white but not for environmental noise.A similar argument explains the advantage ofMMLSD-TEP (where the total energy is defined on the343preemphasized waveform) over MMLSD-TE for theenvironmental noise, and the reverse for white noise: Theaverage SNR on the preemphasized waveforms was12 dB for the environmental noise and 3 dB for whitenoise.
However, it seems that in no case is MMLSD-TEPas efficient as MMLSD-TE is with white noise.C.
Relation to adaptive prototypesIf one augments he MMLSD estimator with a detailedword-, or phoneme-based, continuous-density HMM, thatmodel itself can be used for the speech recognition task.Instead of preprocessing the speech, optimal recognitionwould be achieved by simply replacing the clean speechoutput PDs by the PDs of the noisy speech, Eq.
(6b).Another, computationally easier alternative is to adaptonly the acoustic labeling in a semicontinuous HMM.Nadas et al \[4\] used such an approach: their HMM wasdefined with semicontinuous output PDs, modeled in thespectral domain by fled mixtures of diagonal covarianceGaussians.
The acoustic labeling was performed bychoosing the most probable prototype given the signal.The same procedure was used in noise, modifying theoutput PDs to account for the noise.
A similar procedurecan be used with the model presented here: all that isrequired for aco~tic labeling in noise is choosing n thatmaximizes P(n IS'), where the latter is given by Eq.
(6).The difference between our model and that of Nadas et alwill then be only that hey use the approximate MIXMAXmodel for P(S'k I n), whereas we will use the moreaccurate model in Eq.
(5b).The above approach would have an advantage overpreprocessing by estimation if the HMM can indeed bedesigned with output PDs in the spectral domain and withdiagonal covariance matrices.
Unfortunately, it iscurrently believed that for speech recognition defining thePDs in the spectral domain is much inferior to thetransform domain.
It is for HMMs in the transformdomain that he MMLSD preprocessing should be used.V.
ConclusionsWe presented an estimation algorithm for noise robustspeech recognition, MMLSD.
The estimation is matchedto the recognizer by seeking to minimize the averagedistortion as measured by a Euclidean distance betweenfilter-bank log-energy vectors, approximating theweighted-cepstral distance used by the recognizer.
Theestimation is computed using a clean speech spectralprobability distribution, estimated from a database, and astationary, ARMA model for the noise.The MMLSD is computed by modeling the speech-spectrum PD as a mixture of classes, within whichdifferent frequency channels are statistically independent.Although the model is only partially successful indescribing speech data, the MMLSD algorithm proves tobe much superior to the MMSE estimation of individualchannels, even with a small number of classes.
A highlyefficient implementation f the mixture model is torepresent the speech spectrum by a small number ofenergies in wide frequency bands (three in ourimplementation), quantizing this space of wide-bandspectrum and identifying classes with code words.
Thismethod achieves performance that is almost comparableto that of a Gaussian-mixture model, at a much smallercomputational load.When trained on clean speech and tested with additivewhite noise at 10-dB SNR, the recognition acuracy withthe MMLSD algorithm is comparable to that achievedwith training the recognizer at the same constant 10-dBSNR.
Since training and testing in constant SNR is anideal situation, unlikely ever to be realized, this is aremarkable r sult.
The algorithm is also highly efficientwith a quasi-stationary environmntal noise, recorded witha desktop microphone, and requires almost no tuning todifferences between this noise and the computer-generated white noise.AcknowledgmentsThis work was supported in part by National ScienceFoundation Grant IRI-8720403, and in part by SRIinternal research and development funding.References1.
A. Erell and M. Weintraub, "Spectral estimation fornoise robust speech recognition," DARPA Speech andNatural Language Workshop, October 1989.2.
M. Cohen, H. Murveit, P. Price, and M. Weintraub,"The DECIPHER speech recognition system," Proc.ICASSP,,1 (1990), $2.10.3.
P. Price, W. Fisher, J. Bernstein, and D. Pallett, "TheDARPA 1000-word resource management database forcontinuous speech recognition," Proc.
ICASSP 1,651-654, 1988.4.
A. Nadas, D. Nahamoo, and M.A.
Picheny, "Speechrecognition using noise-adaptive prototypes," IEEETrans.
on ASSP 37, No.
10 (October 1989).344PercentAlgorithm and Noise Conditions ErrorTrain clean, test cleanTrain clean, test in noise:No processing 92MMSE 38Train and test in noise r no processing 21Table 1.
Word error rate with and without MMSEestimation, for several noise conditions.ModelMMLSD-VQMMLSD-GMMMLSD-WB (3 bands)MMLSD-TEMMLSD-TEP425.024.726.325.1Number of Classes1225.334.33222.721.925.212821.0Table 2.
Word error rote with digital white noise at 10 dB SNR using asingle-frame MMLSD estimation, as a function of the number of classes(mixture components) for the different mixture models.AlgodthmNo processingMMSEMMLSD-VQ (N=32)MMLSD-WB (N=32)MMLSD-TE (N=12)Error RateUntuned84.632.218.520.432.4Tuned32.218.519.727.5Table 3.
Word error rate with added noise recorded by a desktopmicrophone at 0 dB SNR; tuning refers to adjusting thenoise-model parameters (number of degrees of freedom) fromtheir values in white noise to their best values in theenvironmental noise.345
