Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on SemanticEvaluation (SemEval 2013), pages 207?211, Atlanta, Georgia, June 14-15, 2013. c?2013 Association for Computational LinguisticsSATTY : Word Sense Induction Application in Web Search Clustering?Satyabrata BeheraIIT BombayMumbai, Indiasatty@cse.iitb.ac.inRamakrishna BairiIIT BombayMumbai, Indiabairi@cse.iitb.ac.inUpasana GaikwadIIT BombayMumbai, Indiaupasana@cse.iitb.ac.inGanesh RamakrishnanIIT BombayMumbai, Indiaganesh@cse.iitb.ac.inAbstractThe aim of this paper is to perform WordSense induction (WSI); which clusters websearch results and produces a diversified list ofsearch results.
It describes the WSI system de-veloped for Task 11 of SemEval - 2013.
Thispaper implements the idea of monotone sub-modular function optimization using greedyalgorithm.1 IntroductionTwo different types of systems were submitted un-der Task 11 of SemEval - 2013 (Roberto Navigli andDaniele Vannella, 2013).
The two system types areWSI (Word Sense Induction) and WSD (Word SenseDisambiguation).
WSD is the task of automaticallyassociating meaning with words.
In WSD the pos-sible meanings for a given word are drawn from anexisting sense inventory.
In contrast, WSI aims atautomatically identifying the meanings of a givenword from raw text.
A WSI system will be asked toidentify the meaning of the input query and clusterthe search results into semantically-related groupsaccording to their meanings.
Instead, a WSD sys-tem will be requested to sense-tag the above searchresults with the appropriate senses of the input queryand this, again, will implicitly determine a clusteringof snippets (i.e., one cluster per sense).
?This system was designed and submitted in the com-petition SemEval-2013 under task 11 : Evaluating WordSense Induction & Disambiguation within An End-UserApplication (Roberto Navigli and Daniele Vannella2013).http://www.cs.york.ac.uk/semeval-2013/.Our system implements the idea given in (Jin-grui He and Hanghang Tong and Qiaozhu Mei andBoleslaw Szymanski, 2012).
This developed sys-tem uses the concept of submodularity.
The taskis treated as a submodular function maximizationwhich has its benefits.
On the one hand, there existsa simple greedy algorithm for monotone submod-ular function maximization where the solution ob-tained is guaranteed to be almost as good as the bestpossible solution according to an objective.
Moreprecisely, the greedy algorithm is a constant factorapproximation to the cardinality constrained versionof the problem, so that the approximate soultion isin the bound of (1 ?
1/e) of optimal solution.
It isalso important to note that this is a worst case bound,and in most cases the quality of the solution ob-tained will be much better than this bound suggests.In our system, monotone submodular objective of(Jingrui He and Hanghang Tong and Qiaozhu Meiand Boleslaw Szymanski, 2012) was implementedto find the top k simultaneously relevant and diver-sified list of search results.
Once these top k resultsare obtained, they are used as centroids to form clus-ters by classifying each of remaining search resultsto one of the centroid with maximum similarity, pro-ducing k clusters.
Those results which are not simi-lar to any of the centroids are either put in a differentcluster or are assigned to cluster with highest simi-larity.2 Background on SubmodularityOur system uses the concept of submodularity.Given a set of objects V = v1, ..., vn and a functionF : 2V ?
R that returns a real value for any subset207S ?
V .
The function F is said to be submodular ifit satisfies the property of diminishing returns, i.e.,A ?
B ?
V \ v, a submodular function F must sat-isfy F (A + v) ?
F (A) ?
F (B + v) ?
F (B).
Aset function F is monotone nondecreasing if ?A ?B,F (A) ?
F (B).
A monotone nondecreasing sub-modular function is referred to as monotone sub-modular.We need to find the subset of bounded size|S| ?
k that maximizes the function F , e.g.argmaxS?V F (S).
In general, this operation is in-tractable.
As shown in (G.L.
Nemhauser and L.A.Wolsey, 1978), if function F is monotone submod-ular, then a simple greedy algorithm finds an ap-proximate solution which is guaranteed to be within(1?
1/e) ?
0.63 of optimal solution.
Many proper-ties of submodular functions are common with con-vex and concave functions (L. Lova?sz, 1983).
Oneof those is that they are closed under a number ofcommon combination operations such as summa-tion, certain compositions, restrictions etc.Previous work on submodularity is in (Hui Linand Jeff Bilmes, 2011) where a monotone submodu-lar objective is maximized using a greedy algorithmfor document summarization.
The objective func-tion is:F (S) = L(S) + ?R(S)where L(S) measures the coverage of summaryset S to the document V and R(S) measures di-versity in S, which are properties of a good sum-mary.
?
?
0 is trade-off coefficient.
V representsall the sentences (or other linguistic units) in a docu-ment (or document collection).
AlsoL(S) andR(S)are monotone submodular functions.
This work wasagain extended in (Hui Lin and Jeff A. Bilmes, 2012)where the submodular objective is itself a weightedcombination of several submodular functions, wherethe weights are learnt in a max-margin setting.
Thiswork also demonstrates the use of this idea for doc-ument summarization.3 System DescriptionThe system works in 2 stages:1.
The first stage produces top k diversified andrelevant set of search results.2.
The second stage forms k clusters of search re-sults treating top k results as centroids.The problem of finding top k diversified and rele-vant search results is posed as an optimization prob-lem.
This optimization function has the propertyof diminishing returns and monotonicity, which isa monotone submodular function.
This enablesto design a scalable, greedy algorithm to find the(1 ?
1/e) near-optimal solution.
The optimizationfunction is taken from (Jingrui He and HanghangTong and Qiaozhu Mei and Boleslaw Szymanski,2012) and presented below.Objective Function : The aim is to find a subsetT of k search results which optimizes the objectivefunction.argmax|T |=k w?i?Tqiri ?
?i,j?TriSijrjwhere, T is the subset of search results.
q = S.r isa nx1 vector.
Intuitively, its ith element qi measuresthe importance of ith search result.
To be specific,if xi is similar to many search results that are highlyrelevant to the query, it is more important than thesearch results whose neighbours are less relevant.
Sis a nxn similarity matrix between search results.
ris a nx1 relevance vector of search results to query.w is a regularization parameter which defines trade-off between two terms.The first term of the objective function measuresthe total weighted relevance of T with respect toquery.
It favours relevant search results from bigclusters.
In other words, if two search results areequally relevant to the query, one from a big clusterand the other isolated, by using weighted relevance,it prefers the former.The second term measures the similarity amongthe search results within T such that it penalizes theselection of multiple relevant search results that arevery similar to each other.
By including this term inthe objective function, we try to find a set of searchresults which are highly relevant to the query andalso dissimilar to each other.As the objective function is monotone submodu-lar, the greedy algorithm finds the top k search re-208sults (i.e.
near optimal solution) with approximationguarantee of (1?
1/e).The second stage performs clustering using re-sults of previous stage.
The top k search results out-put by the previous stage are treated as centroids andthe remaining search results are assigned to the cen-troid with the maximum similarity.4 Experimental ResultsThe implemented system was tested on data givenby SemEval - 20131(Roberto Navigli and DanieleVannella, 2013).
Data contains 100 queries, eachwith 64 search results.
Each search result containstitle, url and snippet.Only title and snippet information was used.
Therelevance between query and a search result is cal-culated using weighted Jaccard.
Cosine similarity isused to calculate the similarity between search re-sults using only title and snippet.
It was just bag ofwords (i.e.
unigram) approach and no other prepro-cessing of data was done.
In the first stage, systemproduces top 10 diversified search results which arethen used as centroids to form 10 clusters.
Thoseresults which are not similar to any of the centroidsare put in a different cluster, sometimes resulting in11 clusters.The evaluation method required : (i) to rank thesearch results within each cluster according to theconfidence with which they belong to that cluster,(ii) to rank the clusters according to their diversity.The cluster ranking is kept same as the rank oftheir centroids in top 10 results returned in first stageof the system.Also search results within each cluster are thenranked by their average similarity to rest of thesearch results in the same cluster, in descending or-der with respect to the ranking score.
The rankingscore of search result xi in cluster C is calculated asbelow, which is used in our system :score(xi) =1|C| ?
1?j:j?C,i6=jSij1http://www.cs.york.ac.uk/semeval-2013/task11/index.php?id=dataThe other way of ranking search results within acluster can be ranking by their relevance to thequery.
In that case, it depends on how good therelevance scores are.
This ranking affects the abil-ity of the system to diversify search results, i.e.,Subtopic Recall@K and Subtopic Precision@r mea-sures.
The clustering quality is measured by mea-sures of Rand Index (RI), Adjusted Rand Index(ARI), F1-measure (F1) and Jaccard Index (JI).
Allthese evaluation metrics used are described in (An-tonio Di Marco and Roberto Navigli, 2013).
Allthe given evaluation metric values are obtained forthe described data using the java evaluator providedby SemEval - 2013 (Roberto Navigli and DanieleVannella, 2013).
Our system?s evaluation measuresalong with other systems, submitted in SemEval -2013 are shown in tables 1, 2 and 3.
Our system?sname is task11-satty-approach1.The clustering quality was found to be good asindicated by F1 and RI while scoring low for ARI,JI.
In terms of diversification of search results, it didnot perform that well indicating that either rankingof search results within each cluster or cluster rank-ing or both were not that good.5 ConclusionIn this paper Word Sense Induction was imple-mented on web search clustering.
The developedsystem evaluated with respect to different evaluationmetrics.
The system?s clustering quality was foundto be good while its ability to diversify search re-sults was not that good.
Better ranking of clusters aswell as ranking of search results within each clustercan improve the system?s ability to diversify searchresults.The similarity score between search results werecalculated using only title and snippet, but it can alsobe evaluated by fetching whole document.
Since therelevance score of each search result to the querywas not available, it was calculated by consideringoccurrence frequency of query words in search re-sults (i.e.
title and snippet).
If a better relevancescore were available by the search engine, the sys-tem might have performed better.
These two aspectscan be tested in further work.209System Type F1 ARI RI JaccardAvg.
No.ofClustersAvg.ClusterSizehdp-clusters-lemma WSI 0.683 0.2131 0.6522 0.3302 6.63 11.0756hdp-clusters-nolemma WSI 0.6803 0.2149 0.6486 0.3375 6.54 11.6803task11-satty-approach1 WSI 0.6709 0.0719 0.5955 0.1505 9.9 6.4631task11-ukp-wsi-wp-pmi WSI 0.6048 0.0364 0.505 0.2932 5.86 30.3098task11.duluth.sys7.pk2 WSI 0.5878 0.0678 0.5204 0.3103 3.01 25.1596task11-ukp-wsi-wp-llr2 WSI 0.5864 0.0377 0.5109 0.3177 4.17 21.8702task11-ukp-wsi-wacky-llrWSI 0.5826 0.0253 0.5002 0.3394 3.64 32.3434task11.duluth.sys9.pk2 WSI 0.5702 0.0259 0.5463 0.2224 3.32 19.84task11.duluth.sys1.pk2 WSI 0.5683 0.0574 0.5218 0.3179 2.53 26.4533rakesh WSD 0.3949 0.0811 0.5876 0.3052 9.07 2.9441singleton 1.0000 0.0000 0.6009 0.0000 64.0000 1.0000allinone 0.5442 0.0000 0.3990 0.3990 1.0000 64.0000gold 1.0000 0.9900 1.0000 1.0000 7.6900 11.5630Table 1: The best result for each column is presented in boldface.
singleton and allinone are baseline systems andgold is the theoretical upper-bound for the task.
WSI : Word Sense Induction, WSD : Word Sense DisambiguationSystem Type K=5 K=10 K=20 K=40 K=60hdp-clusters-nolemma WSI 0.508 0.6321 0.7926 0.9248 0.9821hdp-clusters-lemma WSI 0.4813 0.6551 0.7886 0.9168 0.9856task11-ukp-wsi-wacky-llrWSI 0.4119 0.5541 0.6861 0.839 0.9691task11-ukp-wsi-wp-llr2 WSI 0.4107 0.5376 0.6887 0.8587 0.983task11-ukp-wsi-wp-pmi WSI 0.4045 0.5625 0.687 0.8492 0.978task11-satty-approach1 WSI 0.3897 0.489 0.6272 0.8214 0.9745task11.duluth.sys7.pk2 WSI 0.3888 0.5379 0.7038 0.8623 0.9844task11.duluth.sys9.pk2 WSI 0.3715 0.499 0.6891 0.8365 0.9734task11.duluth.sys1.pk2 WSI 0.3711 0.5329 0.7124 0.8848 0.9849rakesh WSD 0.4648 0.6236 0.7866 0.9072 0.9903Table 2: S-recall@K for different values of K averaged over 100 queries.210System Type r=0.5 r=0.6 r=0.7 r=0.8 r=0.9hdp-clusters-lemma WSI 0.4885 0.4293 0.3519 0.2762 0.2376hdp-clusters-nolemma WSI 0.4818 0.4388 0.3485 0.293 0.2485task11-ukp-wsi-wp-pmi WSI 0.4283 0.334 0.2663 0.2292 0.2039task11-ukp-wsi-wacky-llrWSI 0.4247 0.3173 0.2539 0.2271 0.1849task11-ukp-wsi-wp-llr2 WSI 0.4206 0.3204 0.2657 0.2241 0.1858task11.duluth.sys1.pk2 WSI 0.4008 0.3131 0.2673 0.2451 0.2177task11.duluth.sys7.pk2 WSI 0.3911 0.3042 0.2654 0.2343 0.1995task11.duluth.sys9.pk2 WSI 0.359 0.2972 0.2526 0.2126 0.1951task11-satty-approach1 WSI 0.3494 0.2688 0.2355 0.204 0.1736rakesh WSD 0.48 0.3904 0.3272 0.2792 0.2394Table 3: S-precision@r for different values of r averaged over 100 queries.ReferencesHui Lin and Jeff Bilmes.
2011.
A class of submodu-lar functions for document summarization.
The 49thAnnual Meeting of the Association for ComputationalLinguistics: Human Language Technologies (ACL-HLT), Portland, OR, June.Hui Lin and Jeff A Bilmes.
2012.
Learning mixtures ofsubmodular shells with application to document sum-marization.
arXiv preprint arXiv:1210.4871.Jingrui He and Hanghang Tong and Qiaozhu Mei andBoleslaw Szymanski.
2012.
GenDeR: A Generic Di-versified Ranking Algorithm.
Advances in Neural In-formation Processing Systems 25.Antonio Di Marco and Roberto Navigli.
2013.
Cluster-ing and Diversifying Web Search Results with Graph-Based Word Sense Induction.
Computational Linguis-tics, 39(4), MIT Press.Roberto Navigli and Daniele Vannella.
2013.
SemEval-2013 Task 11: Evaluating Word Sense Induction Dis-ambiguation within An End-User Application.
Pro-ceedings of the 7th International Workshop on Seman-tic Evaluation (SemEval 2013), in conjunction withthe Second Joint Conference on Lexical and Compu-tational Semantcis (*SEM 2013), Atlanta, USA, 2013.L.
Lova?sz.
1983.
Submodular functions and convexity.Mathematical programming-The state of the art,(eds.A.
Bachem, M. Grotschel and B. Korte) Springer,pages 235257.G.L.
Nemhauser and L.A. Wolsey.
1978 An analysis ofapproximations for maximizing submodular set func-tions I.
Mathematical Programming, 14(1):265294.211
