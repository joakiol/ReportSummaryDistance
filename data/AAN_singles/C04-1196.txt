Understanding Students?
Explanations in Geometry TutoringOctav Popescu, Vincent Aleven, and Kenneth KoedingerHuman-Computer Interaction InstituteCarnegie Mellon University5000 Forbes AvenuePittsburgh, PA 15213 USAoctav@cmu.edu, aleven@cs.cmu.edu, koedinger@cmu.eduAbstractPrecise Natural Language Understanding isneeded in Geometry Tutoring to accuratelydetermine the semantic content of students?explanations.
The paper presents an NLUsystem developed in the context of theGeometry Explanation Tutor.
The systemcombines unification-based syntacticprocessing with description logics basedsemantics to achieve the necessary accuracylevel.
Solutions to specific semantic problemsdealing with equivalence of semanticrepresentations are described.
Experimentalresults on classification accuracy are alsopresented.1 IntroductionThe Geometry Cognitive Tutor is designed tohelp high school and middle school studentslearn geometry.
As a kind of Cognitive Tutor(Anderson et al 1995), the system is based on anunderlying cognitive model, implemented as anACT-R production system (Anderson andLebiere 1998), of both novice and ideal studentknowledge.
This model is used to monitorstudent performance and to provide assistancejust when students need it and in a context thatdemands it.
Currently the Geometry CognitiveTutor is in regular use (two days per week) inabout 350 schools around the US.The tutor proposes problems to students andchecks their solutions step by step.
It can alsoprovide context-sensitive hints at each step insolving the problem, as needed.
The students areasked to compute various elements of theproblem (mostly angle measures) by applying thetheorems and definitions they have learned.
Incase the results are correct, the students are alsoasked to provide a justification for their results.In the version of the tutor that is currently in usein schools, the justification consists in choosingthe right theorem or definition out of a menu.The choice is accepted or rejected by the tutor,accordingly.The use of this tutor in combination withclassroom instruction has been shown to lead toimprovements in students?
test scores overtraditional classroom instruction alone(Koedinger et al 1997).
Experiments have alsoshown that the use of menu-based justificationshelp students learn with greater understandingover a tutor that does not ask for justifications(Aleven and Koedinger 2002).However there is room for improvement.Classroom observation shows that some studentstry to game the system by choosing each item inthe menu in turn, until one is accepted.
Evenwhen this is not the case, it is possible thatsimply recognizing the name of the correcttheorem or definition out of a menu does notimply that the student is fully knowledgeableabout the actual content of the theorem involved.Thus it is plausible that asking the students toexpress the content of these theorems anddefinitions in their own words as a form of self-explanation could lead to a deeper level of theirunderstanding.To verify this hypothesis we are currentlydeveloping the Geometry Explanation Tutor.This version is based on the Geometry CognitiveTutor, with the modification that the justificationconsists of a natural language sentence thatexpresses the content of the theorem or definitionused to derive the result, in free form.
The tutorchecks the semantic content of the explanationand provides feedback on its correctness andcompleteness.
In case the explanation quality isdeemed not good enough, the student is allowedto refine it, until it becomes acceptable.Thus, one of the main problems that theGeometry Explanation Tutor faces is todetermine with accuracy the semantic content ofstudents?
utterances.
There are many differentways to express the same semantic content,which have to be recognized as being equivalent.The determination of equivalence relations has towork reliably over variation of syntacticstructure, variation of content words, or acombination of both.
For example, the sentencesbelow all express the same geometry theorem,about the measures of angles formed by otherangles.An angle formed by adjacent angles is equal to thesum of these angles.The measure of an angle formed by other angles isequal to the sum of the measures of those adjacentangles.An angle's measure is equal to the sum of the twoadjacent angles that form it.The sum of the measures of two adjacent angles isequal to the measure of the angle formed by the twoangles.The measure of an angle formed by two adjacentangles is equal to the sum of the measures of the twoangles.If adjacent angles form an angle, its measure is theirsum.When an angle is formed by adjacent angles, itsmeasure is equal to the sum of those angles.The process has also to be consistent, so nounwarranted conclusions are derived from thetext, and robust, in an environment of impreciseor ungrammatical language, as uttered more oftenthan not by high school students.
Many times thiscontent equivalence relies on inferences specificto the domain of discourse.
Our hypothesis is thatsuch a high-precision recognition process needsto be based on contextual information about thedomain of discourse modeled in a logic system.2 The System?s ArchitectureThe system?s overall architecture is presented inFigure 1 below.
The interface module takes theinput sentence from the tutor, word by word, inreal time, and after some preprocessing andspelling checking, it passes it to the chart parser.It also passes the results back to the tutor.
Thechart parser is the main engine of the system.
Ituses linguistic knowledge about the target naturallanguage from the unification grammar and thelexicon.
The parser used currently is LCFlex, aleft-corner active-chart parser developed at theUniversity of Pittsburgh (Ros?
and Lavie 1999).The parser calls the feature structure unifier inorder to process restrictions attached to grammarrules and build feature structures for each phrasesuccessfully recognized.
These feature structuresstore lexical, syntactic, and semantic propertiesof corresponding words and phrases.
The parseruses an active chart that serves as a storage areafor all valid phrases that could be built from theword sequence it received up to each point in theprocess.Figure 1.
System ArchitectureSome of the restrictions in the grammar aredirectives to the description logic system,currently Loom (MacGregor 1991).
The logicssystem relies on a model of the domain ofdiscourse, encoded as concepts, relations, andproduction rules, in the two knowledge bases.Concepts and relations stand for predicates in theunderlying logic.
Production rules performadditional inferences that are harder to encodeinto concepts and/or relations.The linguistic inference module mediates theinteraction between the feature structure unifierand the description logics system.
This module isresponsible for performing semantic processingthat is specific to natural language understanding,like compositional semantics, resolvingmetonymies and references, and performingsemantic repairs.Based on this knowledge base, the logicsystem builds compositionally a model-theoreticsemantic representation for the sentence, as a setof instances of various concepts connectedthrough various relations.
An instancecorresponds to a discourse referent in thesentence.
The logic system performs forward-chaining classification of resulting instances, andalso ensures semantic coherence of the semanticrepresentation.The logic system then uses a classifier toevaluate the semantic representation against aclassification hierarchy of valid representationsTUTOR SYNTACTIC PROCESSINGSEMANTIC PROCESSINGUPPER MODELKNOWLEDGEBASESTUDENTMODELCHARTPARSER(LCFLEX)UNIFICATIONGRAMMARLEXICONFEATURESTRUCTUREUNIFIERFEATURESTRUCTURESACTIVECHARTINTERFACEMODULEPRODUCTIONENGINECLASSIFICATIONHIERARCHYSEMANTICREPRESENTATIONCOGNITIVEMODELLINGUISTICINFERENCEDESCRIPTIONLOGIC (LOOM)GEOMETRYKNOWLEDGEBASEfor geometry theorems.
The results of theclassification are passed back to the tutor.1.1 Example of Compositional Build ofthe Semantic RepresentationTo see how the compositional building ofsemantic representations works, let?s consider thelast step in parsing the sentence:The measure of a right angle is 90 degrees.A set of simplified knowledge base definitionsnecessary for building its representation, inLoom?s definitional language, is:(defconcept Configuration:is-primitive (:and Thing (:all participant Thing)))(defconcept Being&Having:is-primitive (:and Configuration(:at-most 2 participant)))(defconcept Ascription:is (:and Being&Having (:exactly 1 attribuend)(:exactly 1 attribute))(defproduction ascription-production:when (:detects (Ascription x)):do ((combine-instances (x attribute)(x attribuend))))(defconcept Geometry-Unit:is (:and Unit (:one-of ?degree ?radian ?meter ?foot)))(defconcept Angle-Unit:is (:and Geometry-Unit (:one-of ?degree ?radian)))(defconcept Geometry-Measure:is (:and Measure (:the unit Geometry-Unit)))(defconcept Angle-Measure:is (:and Geometry-Measure (:the unit Angle-Unit)))(defconcept Geometry-Object:is-primitive (:and Spatial(:all measure Geometry-Measure)))(defproperty Right :domain Geometry-Object)(defconcept Angle:is-primitive (:and Geometry-Object(:the measure Angle-Measure)))(defconcept Right-Angle :is (:and Right Angle))Figure 2.
Example of Semantic RepresentationBased on these definitions and the rules of thegrammar, the system builds the representationbelow for the subject of the example above,expressed in Loom?s assertional language:(tell (:about measure-1 (:create Angle-Measure)))(tell (:about angle-1 (:create Right-Angle)(measure measure-1)))The system also builds this structure for the verbphrase:(tell (:about measure-2 (:create Angle-Measure)(unit ?degree) (value 90)))(tell (:about being&having-1 (:create Being&Having)(attribute measure-2)))The two structures are illustrated in Figure 2.Then the parser applies the grammar rule forclauses, given below in simplified form.
Connect-s eman t i c s  will assert an attribuend relationbetween instances being&having-1 and measure-1,relation specified in the lexicon as the semanticrole of the verb?s subject.
(<Cl> ==> (<NP> <VP>)((x0 = x2)((x0 subject) = x1)((x0 semantics) <=(connect-semantics (x2 semantics)(x2 subject sem-role) (x1 semantics)))))Loom then classifies being&having-1 as aninstance of the more specific concept Ascription,and this classification triggers productionascription-production.
The production will combinethe two measure instances, measure-1 andmeasure-2, into a single instance, resulting in thestructure below:(tell (:about measure-1 (:create Angle-Measure)(unit ?degree) (value 90)))(tell (:about angle-1 (:create Right-Angle)(measure measure-1)))(tell (:about being&having-1 (:create Ascription)(attribute measure-1) (attribuend measure-1)))The structure is shown in Figure 3.Figure 3.
Resulting Semantic RepresentationThis structure is then classified against ahierarchy of concept definitions representingclasses of possible explanations.
A few of themare shown in Figure 4.WS-8VALUEUNITMEASUREATTRIBUEND ATTRIBUTERIGHT-ANGLEASCRIPTIONANGLE-MEASURENUMBERANGLE-UNITANGLE-1 MEASURE-1 DEGREE90BEING&HAVING-1WS-7UNITATTRIBUTEVALUEBEING&HAVING-1WS-4MEASURE-1ANGLE-1MEASURERIGHT-ANGLEANGLE-MEASUREBEING&HAVINGANGLE-MEASUREANGLE-UNITNUMBERMEASURE-2 DEGREE90Figure 4.
Partial Classification Hierarchy3  Specific Problems in Students?ExplanationsThe basic approach we take to the contentequivalence problem is to provide the rightinference rules to make the logic system derivethe same semantic representation for allsentences that are semantically equivalent.
Belowwe present how this is done in some specificcases.1.2 Variation of Syntactic StructureEven when the choice of content words is thesame, the same meaning can be conveyedthrough a variety of syntactic structures.
Somecases, like that of passive versus activeconstructs, can be taken care of in the grammar.Other cases require specific knowledge about thedomain of discourse.
One such situation is that ofprepositional phrases attached in different placesin the sentence, without changing the meaning,like in these examples:In a triangle angles opposite to congruent sides arecongruent.Angles opposite to congruent sides in a triangle arecongruent.Angles in a triangle opposite to congruent sides arecongruent.Angles opposite to congruent sides are congruent ina triangle.The solution in our system comes as a conceptdefinition that identifies the container relation atthe assertion level, and percolates it down toinvolved objects.
(defconcept Ascription-Location:is (:and Ascription (:at-least 1 belongs-to)):implies(:and (:relates belongs-to attribuend belongs-to)(:relates belongs-to attribute belongs-to))))A similar case is that of using constructs specificto the domain of discourse.The measures of these two angles are equal.These two angles are equal in measure.Knowledge about the semantics of ?equal?
and?measure?
is involved in determining that ?equalin measure?
means the same thing as ?measures ?are equal?.
We can model this knowledge bydefining a rule that will identify cases of ?equal insome measurable quantity?
and will generate astructure with the meaning of ?equal quantity?.
(defconcept Equal-in:is (:and Equal (:some belongs-to Measure)))(defproduction equal-in-production:when (:detects (Equal-in ?object)):do (combine-semantics ?object(?object belongs-to)))The use of relative and subordinate clauses canalso lead to a large variety of syntactic structureswithout a significant change in meaning:The sum of the measures of complementary anglesis 90 degrees.If angles are complementary, then the sum of theirmeasures is 90 degrees.The measures of the angles sum to 90 degrees,because they are complementary angles.Complementary angles are angles whose measuressum to 90 degrees.These sentences all express the same theoremabout complementary angles using respectively asingle clause sentence, a conditional clause, asubordinate clause, or a relative clause.
Becausethe semantic representation we build does notkeep any trace of the original syntactic structure,such variations are automatically ignored.
Forexample, the structure built for the first sentenceis:(tell (:about measure-1 (:create Geometry-Measure)))(tell (:about angle-1 (:create Angle)Complementary (measure measure-1))(tell (:about sum-1 (:create Sum)(value 90) (unit 'degree) (term measure-1))(tell (:about being&having-1 (:create Ascription)(attribute sum-1) (attribuend sum-1))Ignoring the conditionality, the structures for thetwo clauses in the second sentence are:(tell (:about angle-1 (:create Angle) Complementary))(tell (:about being&having-1 (:create Ascription)(attribute angle-1) (attribuend angle-1))(tell (:about thing-1 (:create Thing)(measure measure-1)))(tell (:about measure-1 (:create Geometry-Measure)))(tell (:about sum-1 (:create Sum)(value 90) (unit 'degree) (term measure-1))COMPLEMENTARY-ANGLES?The angles arecomplementary.
?ANGLES-90?The measure of thisangle is 90 degrees.
?UNKNOWNANGLE-SUM-90?These angles addup to 90.?RIGHT-ANGLES-90?The measure of a rightangle is 90 degrees.
?COMPLEMENTARY-ANGLES-SUM-90?Complementary anglessum to 90.?RIGHT-ANGLES?This is a right angle.?
(tell (:about being&having-2 (:create Ascription)(attribute sum-1) (attribuend sum-1))All that is needed to achieve semanticequivalence is a reference resolution mechanismthat identifies referents at the semantic level withtheir antecedents.
In the example above thesystem would solve thing-1  to angle-1.1.3 Variation of Content WordsMany times differences in the content wordsused in the sentence do not make any differenceat the meaning level.
An obvious case is that ofsynonyms.
However there are cases whendifferent words are used as synonyms only incertain contexts.
For instance:Angles ABC and BAC are equal.Angles ABC and BAC are congruent.Versus:The measures of angles ABC and BAC are equal.
*The measures of angles ABC and BAC arecongruent.Here the synonymy holds only when the objectsinvolved in the relation are geometry objects, andit is not allowed when they are measures.
We canmake this distinction by defining ?congruent?
as aspecialized case of ?equal?
:(defrelation equal-to:is-primitive (:and relation (:domain Thing)(:range Thing)):characteristics :symmetric)(defrelation congruent-to:is (:and equal-to (:domain Geometry-Object)(:range Geometry-Object)))Moreover, we can add a production rule that willperform the inference that if the measures ofsome objects are equal, then the objectsthemselves are congruent.
This rule will makethe third sentence above be recognized asequivalent to the first two sentences.
(defconcept Equal-Measure:is (:and Measure (:at-least 1 equal-to)))(defproduction equal-measure-production:when (:detects (Equal-Measure ?measure)):do (connect-semantics(?measure measure-of) congruent-to(?measure equal-to measure-of)))A related phenomenon is that of using verygeneric functional words in usual language todenote specific relations among the concepts ofthe domain.The angles of a linear pair sum to 180.The angles that form a linear pair sum to 180.The angles that are elements of a linear pair sum to180.In these examples the angles are actually theelements of the linear pair.
However in the firsttwo sentences the relation is expressed eitherthrough a preposition, or through a generic verblike ?form?.
Recovering the explicit relation andthus being able to determine that the threeexamples above are semantically equivalentrequires once again a model of the domain ofdiscourse.
We can model this first by definingthe element-of relation as a more specific versionof the generic relation belongs-to expressed by?of?.
This definition will make the system buildthe same representation for the first sentence asfor the third one.
(defconcept Set :is-primitive Thing)(defrelation element-of:is (:and belongs-to (:domain Thing) (:range Set)))Second, we can define a production rule thatrecognizes a ?form?
configuration and asserts a?belongs-to?
relation between the arguments, thusgenerating for the second sentence the samerepresentation as for the first one:(defconcept Form-Configuration:is (:and Generalized-Possession(:the part Thing)(:the whole Thing)))(defproduction form-configuration-production:when (:detects(Form-Configuration ?configuration)):do (connect-instances (?configuration part)belongs-to(?configuration whole)))Another similar situation is that when studentsuse the definition of a concept expressed in termsof more generic concepts, instead of its name.Adjacent angles on a line sum to 180 degrees.Linear angles sum to 180 degrees.The ability to recognize such examples as beingsemantically equivalent, with the right degree ofgenerality, is conditioned by the possibility tomodel the definitions of those specific conceptswithin the framework of the system.
This casecan be dealt with by defining ?
linear angles?
as?adjacent angles on a line?
:(defrelation adjacent-to:is-primitive (:and relation(:domain Geometry-Object)(:range Geometry-Object)))(defconcept Adjacent-Angle:is (:and Angle (:at-least 1 adjacent-to)))(defconcept Angle-on-Line:is (:and Angle (:some location Line)))(defconcept Linear-Angle:is (:and Adjacent-Angle Angle-on-Line))1.4 Syntactic AmbiguitySyntactic ambiguity in many cases does notreflect semantic ambiguity.
One such possibilityis prepositional phrase attachment.
That is,following only the grammar rules, many times aprepositional phrase could be an adjunct/argument of several preceding components.
Adeeper look at those alternative attachmentsreveals that most of them can be discardedbecause they do not result in a meaningfulsentence.
However, in absence of detailedknowledge about the meaning of the words in thesentence and their possible interactions, an NLUapproach would not be able to disambiguateamong them.The sum of the measures of the three interior anglesin a triangle is equal to 180 degrees.The subject in this example contains threeprepositional phrases: ?of the measures?, ?of thethree interior angles?, and ?in a triangle?.
While thefirst one can only be attached to one place: thenoun ?sum?, the second one already can beattached to two places: ?sum?
or ?measures?, andthe third one can be attached to three places:?sum?, ?measures?, or ?angles?, resulting in atotal of 6 different valid parses.
By addingappropriate restrictions to the definitions of theconcepts involved, our approach can make someof these combinations invalid during the parsingprocess.
In our example we can restrict sums toonly apply to elements that are measures, andthus eliminate the attachment of prepositionalphrase ?of the three interior angles?
to ?the sum?.And then we can restrict the containment relationto have geometry objects on both sides, and thuseliminate the attachment of ?
in a triangle?
to either?the sum?
or ?the measures?.
(defconcept Sum:is-primitive (:and Measure (:all term Measure)))(defconcept Object-in-Location:is (:and Object (:some location Geometry-Object)):implies Geometry-Object)1.5 Reference ResolutionDisambiguationThe presence of anaphora in students?explanations results in cases where sentenceswith different sets of words are semanticallyequivalent.
Recognizing the semanticequivalence of such cases leads to the necessityto have an accurate reference resolutionmechanism, which allows us to build the rightsemantic representation for the sentence.The resolution of referents to antecedents isdone in our system at the semantic level.
That iswe simply try to merge the semanticrepresentation of the referent with that of theantecedent.
This mechanism has the advantagethat the logic system will make sure that allsemantic constraints associated with the twodiscourse referents are enforced, so that elementsthat are incompatible will fail the merge.
Thistakes care both of the number restrictions, as wellas all other semantic features, like taxonomiccompatibility between the concepts involved.Finding the right referent for an anaphor is notalways easy.
Syntactic criteria can help withdisambiguation among candidates, but there arecases where they cannot lead to a uniqueantecedent.
Adding semantic constraints to thesolution can increase the accuracy considerably.If the lengths of two sides of triangles are equal, thenthe measures of the angles opposite them will alsobe equal.In this example there are five possible candidatesas antecedent for the pronoun ?them?
: ?thelengths?, ?two sides?, ?a triangle?, ?the measures?,and ?
the angles?.
Constraints of the BindingTheory implemented in our system eliminate ?theangles?, since ?them?
is a personal pronoun thathas to be free within its local domain.
Constraintson number eliminate ?a triangle?, as beingsingular, while ?them?
is plural.
Then semanticconstraints attached to the definition of relation?opposite?
can eliminate both ?the lengths?
and?the measures?, by asking that geometry objectscan oppose only other geometry objects:(defconcept Object-opposite:is (:and Geometry-Object(:some opposite-to Thing)):implies (:all opposite-to Geometry-Object))4 Performance EvaluationAs a measure of the system?s ability tounderstand students?
explanations we evaluatedthe accuracy of the classification of thesesentences with respect to the hierarchy ofexplanation classes.
The evaluation used a set of700 sentences representing actual explanationsprovided by high school students during anexperimental study in 2003.
The classificationtask consists in associating each sentence withone or more of 200 fine-grained categories, adifficult task even for humans.
We used thekappa statistic (Cohen 1960) to measure theinter-rater reliability between the system and twohuman raters.
We used three different measures.First, a ?set equality?
measure, where two sets ofclasses match only if they are identical.
Second,an ?overlap?
measure, where two sets areconsidered to partially match if they share somesubset.
And third, a ?weighted overlap?, whichtakes into account the relative semantic distancebetween different classes in assessing the matchbetween two sets of categories.
The results inTable 1 show the system to work reasonablywell, although not at human level.
?ActualAgreementChanceAgreement s?Set equalityHuman-Human0.84 0.84 0.034 0.014System-Human0.65 0.66 0.025 0.018OverlapHuman-Human0.87 0.88 0.040 0.012System-Human0.73 0.74 0.033 0.016WeightedoverlapHuman-Human0.92 0.94 0.30 0.0087System-Human0.81 0.87 0.30 0.012Table 1.
Agreement between the system andhuman raters.Regarding the hypothesis question of whetherreplacing menu-based justifications with naturallanguage justifications helps students have abetter understanding of geometry, we do not havea definitive answer yet.
Some experimentalresults based on the same study seem to show(Aleven et al 2004) that while students?
abilityto express their knowledge was improvedconsiderably, students?
performance on actualproblem solving was not affected significantly.There are a number of possible causes for that, sofurther studies are needed.5 ConclusionsWe present a natural language understandingsystem that combines unification-based syntacticprocessing with logic-based semantics.
Thesystem is used in conjunction with a GeometryCognitive Tutor to help students betterunderstand geometry.
The approach we takeallows for an elegant solution to the problem ofdetermining equivalence between various waysto express the same meaning.
Study results showthat the system works reasonably well onclassifying students?
explanations on a grid ofabout 200 fine-grained categories, although thereis space for further improvement.
One particularproblem is robustness in the face ofungrammaticality.
Also the question of whethernatural language explanations improve students?understanding of geometry still waits for adefinitive answer.AcknowledgementsThis work was supported by NSF ITR/IPE, NSFgrant No.
EIA-0113864, ?Tutoring explanationand discovery learning: Achieving deepunderstanding through tutorial dialog.
?ReferencesVincent Aleven and Kenneth R. Koedinger 2002.
AnEffective Meta-cognitive Strategy: Learning byDoing and Explaining with a Computer-BasedCognitive Tutor.
Cognitive Science, 26(2), 147-179.Vincent Aleven, Amy Ogan, Octav Popescu, CristenTorrey, Kenneth R. Koedinger 2004.
Evaluatingthe Effectiveness of a Tutorial Dialogue System forSelf-Explanation.
In Proceedings of the 7thInternational Conference on Intelligent TutoringSystems, Macelo, Brasil.John R. Anderson, Albert T. Corbett, Kenneth R.Koedinger, and Ray Pelletier 1995.
Cognitivetutors: Lessons learned.
In The Journal of theLearning Sciences, 4:167-207.John R. Anderson and Christian Lebiere 1998.
TheAtomic Components of Thought.
Hillsdale, NJ:Erlbaum.Jacob Cohen 1960.
A coefficient of agreement fornominal scales.
Educational and PsychologicalMeasurement, 20, 37-46.Kenneth R. Koedinger, John J. Anderson, William H.Hadley and Mary A.
Mark 1997.
Intelligenttutoring goes to school in the big city.
InInternational Journal of Artificial Intelligence inEducation, 8:30-43.Robert MacGregor 1991.
Using a descriptionclassifier to enhance deductive inference.
InProceedings of the Seventh IEEE Conference on AIApplications, 141-147, Miami, FL.Carolyn Penstein Ros?
and Alon Lavie 1999.
LCFlex:An efficient robust left-corner parser, User?smanual, University of Pittsburgh.
