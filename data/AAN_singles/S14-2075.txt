Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 433?436,Dublin, Ireland, August 23-24, 2014.NILC USP: Aspect Extraction using Semantic LabelsPedro P. Balage Filho and Thiago A. S. PardoInterinstitutional Center for Computational Linguistics (NILC)Institute of Mathematical and Computer Sciences, University of S?ao PauloS?ao Carlos - SP, Brazil{balage, taspardo}@icmc.usp.brAbstractThis paper details the system NILC USPthat participated in the Semeval 2014: As-pect Based Sentiment Analysis task.
Thissystem uses a Conditional Random Field(CRF) algorithm for extracting the aspectsmentioned in the text.
Our work added se-mantic labels into a basic feature set formeasuring the efficiency of those for as-pect extraction.
We used the semanticroles and the highest verb frame as fea-tures for the machine learning.
Overall,our results demonstrated that the systemcould not improve with the use of this se-mantic information, but its precision wasincreased.1 IntroductionSentiment analysis, or opinion mining, has gainedlots of attention lately.
The importance of thisfield of study is linked with the grown of informa-tion in the internet and the commercial attention itbrought.According to Liu et al.
(2010), there are twokinds of information available in the internet: factsand opinions.
Facts are objective statements aboutentities and events in the world.
Opinions are sub-jective statements that reflect people?s sentimentsor perceptions about the entities and events.
Ac-cording to Liu, by that time, there was a lot of at-tention on the processing of facts but little workhad been done on the processing of opinions.This work is licensed under a Creative Commons At-tribution 4.0 International Licence.
Page numbers and pro-ceedings footer are added by the organisers.
Licence details:http://creativecommons.org/licenses/by/4.0/Three levels of analysis for sentiment analysisare known (Liu, 2012): document level, sentencelevel and aspect level.
The aspect-based sentimentanalysis is the name of the research topic that aimsto extract the sentiments about the aspects presentin the text.This work presents a system evaluated in theSemEval Task4: Aspect Based Sentiment Analy-sis shared task (Pontiki et al., 2014).
Our systemparticipated only in subtask 1: Aspect Term Ex-traction.
In this subtask, given a text, the systemshould extract all aspects that are present.
Therewere two different domains for this task: restau-rants and laptops.The goal of our system was to verify how se-mantic labels used in machine learning classifica-tion would improve the aspect extraction task.
Forthis goal, we used two kinds of semantic labels:the semantic roles (Palmer et al., 2010) and the se-mantic frames (Baker et al., 1998).Liu et al.
(2012) categorizes the works for as-pect extraction in four types, regarding the ap-proach they follow, using: frequent terms, infre-quent terms, machine learning, and topic model-ing.
This work uses a machine learning approachthat consists in training a sequential labeling algo-rithm for aspect detection and extraction.In what follows, we present some related workin Section 2.
Section 3 and 4 introduce our systemand report the achieved results.
Some conclusionsare presented in Section 5.2 Related workJin and Hovy (2009) reported one the first worksusing sequential labeling for aspect extraction.
Inthis work, the authors used a Lexicalized HiddenMarkov Model to learn patterns to extract aspectsand opinions.
Jakob and Gurevych (2010) trained433a Conditional Random Field for aspect extraction.In this work, the authors report the results for a sin-gle domain and a cross domain experiment.
Theyshow that even in other domains the method couldbe good.Kim and Hovy (2006) explored the semanticstructure of a sentence, anchored to an opinionbearing verb or adjective.
Their method uses se-mantic role labeling as an intermediate step to la-bel an opinion holder and topic using data fromFrameNet.Houen (2011) presented a system for opinionmining with semantic analysis.
The author ex-plores the use of the semantic frame-based ana-lyzer FrameNet (Baker et al., 1998) for modelingfeatures in a machine learning approach.
The au-thor found that the FrameNet information was nothelpful in this classifier.3 System DescriptionOur system uses a sequential labeling algorithm.In our work, we use the Conditional Random Field(Lafferty et al., 2001) algorithm provided by theCRF++ tool1.For training the sequential labeling algorithm,we give as input features for each word in the cor-pus.
The algorithm will then learn how to classifythose words.
In our approach, the possible classesare: True, representing an aspect word; and False,representing the remaining words.The goal of our system was to evaluate the per-formance of the semantic labels for the task.
Inorder to model our system, we built a feature setconsisting of 6 features.1.
the word2.
the part-of-speech3.
the chunk4.
the named-entity category5.
the semantic role label (SRL)6. the most generic frame in FrameNetThe use of the first four features is consistentwith the best approaches in aspect-based senti-ment analysis.
The last two features are the oneswe are testing in our work.In order to extract the features, we used two im-portant tools: the Senna (Collobert et al., 2011), a1Available at http://crfpp.googlecode.com/semantic role labeling system, and the ARK SE-MAFOR, a Semantic Analyzer of Frame Repre-sentations (Das et al., 2010).The Senna system uses a deep learning neuralnetwork (Collobert, 2011) to provide several pre-dictions for natural language processing.
The sys-tem output is represented in the CONLL format,the same used in CRF++.Our first 5 features were directly provided bythe Senna output.
In these features, we decided tokeep the IOBE information since the initial exper-iments showed the results were better with it thanwithout.Our fifth feature, the semantic role label, wasretrieved from Senna as well.
In the correspondingpaper, they reported Senna could achieve a F1 of75% for the SRL task.The example below shows how the featureswere represented.
In this example, we are onlyshowing four features: the word, the part-of-speech, the chunk and the SRL.
The classes arein the last column.WORD POS CHUNK SRL IS_ASPECT?Great JJ B-NP B-A0 Falselaptop NN E-NP E-A0 Falsethat WDT S-NP S-R-A0 Falseoffers VBZ S-VP S-V Falsemany JJ B-NP B-A1 Falsegreat JJ I-NP I-A1 Falsefeatures NNS E-NP E-A1 True!
.
O - FalseThe last feature was retrieved by ARK SE-MAFOR tool.
ARK SEMAFOR uses a probabilis-tic frame-semantic parsing using the FrameNet re-source.
The ARK SEMAFOR output is the anal-ysis of the frames present in the text for a givenverb.
As our feature set has only word related fea-tures, we decided to use the most upper level struc-ture in the frame.
In case of multiple verbs in thesentence, we used the structure for the verb that isclosest to the word of interest.The following example shows how the frameswere added into the training model.
We limit toshow only the word, frame and the class.
For train-ing, we used the full training set with the six fea-tures plus the class.WORD FRAME IS_ASPECT?I Shopping Falseshopped Shopping Falsearound Relational_quantity Falsebefore Relational_quantity False434buying Relational_quantity False.
O FalseThe organization from SemEval-2014 Task 4:Aspect Based Sentiment Analysis provided twodomains for evaluation: restaurants and laptops.For each domain, the organization provided threedatasets: a trainset, a devset and a testset.We executed our algorithm with C pa-rameter equal to 4.0.
The experimentcode is fully available at the weblinkhttps://github.com/pedrobalage/4 ResultsTables 1 and 2 show our system results for therestaurants and laptops domains respectively.
Inthese tables, the results are discriminated by thefeature sets that were used.
The reader may seethat a ?+ Frame?
system, for example, stands forall the features discriminated above (Word, POS,Chunk, NR, SRL) plus the Frame feature.
The lastline shows the results scored by our system in theSemEval shared task with all the features.
We alsoshow the results for the baseline system providedby the shared task (Pontiki et al., 2014).Table 1: Results for restaurants domainSystem Precision Recall F1-mesaureBaseline 52.54 42.76 47.15Word + POS 83.76 68.69 75.48+ Chunk 83.38 68.16 75.01+ NE 83.45 68.07 74.98+ SRL 82.79 67.46 74.34+ Frame 87.72 34.03 49.04Table 2: Results for laptops domainSystem Precision Recall F1-mesaureBaseline 44.31 29.81 35.64Word + POS 80.87 39.44 53.03+ Chunk 78.83 39.29 52.44+ NE 79.93 39.60 52.96+ SRL 78.22 38.99 52.04+ Frame 83.62 14.83 25.19Comparing with the baseline, we may noticedthat our submitted system (+Frame) outperformedthe baseline for the restaurants domain but it didnot outperformed the baseline for the laptops do-main (considering F1 mesaure).When we look in detail for the inclusion of fea-tures in our feature set, we may notice that, at ev-ery new feature, the precision goes up, but the re-call goes down.
We believe this is due to the be-haviour of the conditional random field algorithmfor compensating for a sparser feature set.In general, the semantic labels (SRL and Frame)could not improve the results.
However, if weare interested only on precision, these features arehelpful.
This may be the case in scenarios where alot of information is available, as in the web, andwe want to be sure about the retrieved informa-tion.
Certainly, there is a conflict between preci-sion and computational complexity, since the se-mantic features are more expensive to be achieved(in relation to the usual simpler features that maybe used).Despite of that, we judge to be necessary to con-duct more experiments in order to better evaluatethe impact of semantic labels in the aspect extrac-tion task.5 ConclusionWe presented an aspect extraction system built ona conditional random field algorithm.
We useda rich feature set with the semantic roles andthe FrameNet upper frames for each word.
Wehave showed that the semantic labels may help toachieve a more precise classifier, but it did not helpto improve the overall F-measure of the system.Regarding the shared task, our system achievedthe second best precision value among the com-peting systems, but the lowest recall value.
Futurework should investigate ways of also improvingrecall without penalty for the achieved precision.AcknowledgmentsWe would like to thank the organizers for theirwork constructing the dataset and overseeing thetask.
We also would like to thank FAPESP for thefinancial support.ReferencesCollin F Baker, Charles J Fillmore, and John B Lowe.1998.
The berkeley framenet project.
In Proceed-ings of the 36th Annual Meeting of the Associa-tion for Computational Linguistics and 17th Inter-national Conference on Computational Linguistics-Volume 1, pages 86?90.
Association for Computa-tional Linguistics.Ronan Collobert, Jason Weston, L?eon Bottou, MichaelKarlen, Koray Kavukcuoglu, and Pavel Kuksa.2011.
Natural language processing (almost) from435scratch.
The Journal of Machine Learning Re-search, 12:2493?2537.Ronan Collobert.
2011.
Deep learning for efficientdiscriminative parsing.
In Geoffrey J. Gordon andDavid B. Dunson, editors, Proceedings of the Four-teenth International Conference on Artificial Intel-ligence and Statistics (AISTATS-11), volume 15,pages 224?232.
Journal of Machine Learning Re-search - Workshop and Conference Proceedings.Dipanjan Das, Nathan Schneider, Desai Chen, andNoah A Smith.
2010.
Semafor 1.0: A probabilisticframe-semantic parser.
Technical report, LanguageTechnologies Institute, School of Computer Science,Carnegie Mellon University.S?ren Houen.
2011.
Opinion Mining with Seman-tic Analysis.
Ph.D. thesis, Department of ComputerScience, University of Copenhagen.Niklas Jakob and Iryna Gurevych.
2010.
Extractingopinion targets in a single-and cross-domain settingwith conditional random fields.
In Proceedings ofthe 2010 Conference on Empirical Methods in Nat-ural Language Processing, pages 1035?1045.Wei Jin and Hung Hay Ho.
2009.
A Novel LexicalizedHMM-based Learning Framework for Web OpinionMining.
In L?eon Bottou and Michael Littman, ed-itors, Proceedings of International Conference onMachine Learning (ICML-2009), ICML ?09, pages1?8.
ACM, ACM Press.Soo-Min Kim and Eduard Hovy.
2006.
Extractingopinions, opinion holders, and topics expressed inonline news media text.
In Proceedings of the Work-shop on Sentiment and Subjectivity in Text, SST ?06,pages 1?8, Stroudsburg, PA, USA.
Association forComputational Linguistics.John D. Lafferty, Andrew McCallum, and FernandoC.
N. Pereira.
2001.
Conditional random fields:Probabilistic models for segmenting and labeling se-quence data.
In Proceedings of the Eighteenth Inter-national Conference on Machine Learning, ICML?01, pages 282?289, San Francisco, CA, USA.
Mor-gan Kaufmann Publishers Inc.Bing Liu.
2010.
Sentiment Analysis and Subjectivity.In N Indurkhya and F J Damerau, editors, Handbookof Natural Language Processing, number 1, chap-ter 28, pages 627?666.
CRC Press, Taylor and Fran-cis Group, Boca Raton.Bing Liu.
2012.
Sentiment Analysis and Opinion Min-ing.
Synthesis Lectures on Human Language Tech-nologies, 5(1):1?167.Martha Palmer, Daniel Gildea, and Nianwen Xue.2010.
Semantic role labeling.
Synthesis Lectureson Human Language Technologies, 3(1):1?103.Maria Pontiki, Dimitrios Galanis, John Pavlopou-los, Haris Papageorgiou, Ion Androutsopoulos, andSuresh Manandhar.
2014.
SemEval-2014 Task 4:Aspect Based Sentiment Analysis.
In Proceedingsof the 8th International Workshop on Semantic Eval-uation, SemEval 2014, Dublin, Ireland.436
