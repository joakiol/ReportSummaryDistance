Workshop on Computationally Hard Problemsand Joint Inference in Speech and Language Processing, pages 41?48,New York City, New York, June 2006. c?2006 Association for Computational LinguisticsPractical Markov Logic Containing First-Order Quantifierswith Application to Identity UncertaintyAron Culotta and Andrew McCallumDepartment of Computer ScienceUniversity of MassachusettsAmherst, MA 01003{culotta, mccallum}@cs.umass.eduAbstractMarkov logic is a highly expressive languagerecently introduced to specify the connec-tivity of a Markov network using first-orderlogic.
While Markov logic is capable ofconstructing arbitrary first-order formulaeover the data, the complexity of these for-mulae is often limited in practice becauseof the size and connectivity of the result-ing network.
In this paper, we present ap-proximate inference and estimation meth-ods that incrementally instantiate portionsof the network as needed to enable first-order existential and universal quantifiersin Markov logic networks.
When appliedto the problem of identity uncertainty, thisapproach results in a conditional probabilis-tic model that can reason about objects,combining the expressivity of recently in-troduced BLOG models with the predic-tive power of conditional training.
We vali-date our algorithms on the tasks of citationmatching and author disambiguation.1 IntroductionMarkov logic networks (MLNs) combine the proba-bilistic semantics of graphical models with the ex-pressivity of first-order logic to model relational de-pendencies (Richardson and Domingos, 2004).
Theyprovide a method to instantiate Markov networksfrom a set of constants and first-order formulae.While MLNs have the power to specify Markovnetworks with complex, finely-tuned dependencies,the difficulty of instantiating these networks growswith the complexity of the formulae.
In particular,expressions with first-order quantifiers can lead tonetworks that are large and densely connected, mak-ing exact probabilistic inference intractable.
Becauseof this, existing applications of MLNs have not ex-ploited the full richness of expressions available infirst-order logic.For example, consider the database of researchersdescribed in Richardson and Domingos (2004),where predicates include Professor(person),Student(person), AdvisedBy(person, per-son), and Published(author, paper).
First-order formulae include statements such as ?studentsare not professors?
and ?each student has at mostone advisor.?
Consider instead statements such as?all the students of an advisor publish papers withsimilar words in the title?
or ?this subset of stu-dents belong to the same lab.?
To instantiate anMLN with such predicates requires existential anduniversal quantifiers, resulting in either a denselyconnected network, or a network with prohibitivelymany nodes.
(In the latter example, it may be nec-essary to ground the predicate for each element ofthe power set of students.
)However, as discussed in Section 2, there maybe cases where these aggregate predicates increasepredictive power.
For example, in predictingthe value of HaveSameAdvisor(ai .
.
.
ai+k),it may be useful to know the valuesof aggregate evidence predicates such asCoauthoredAtLeastTwoPapers(ai .
.
.
ai+k),which indicates whether there are at least two papersthat some combination of authors from ai .
.
.
ai+khave co-authored.
Additionally, we can constructpredicates such as NumberOfStudents(ai) tomodel the number of students a researcher is likelyto advise simultaneously.These aggregate predicates are examples of uni-versal and existentially quantified predicates over ob-served and unobserved values.
To enable these sorts41of predicates while limiting the complexity of theground Markov network, we present an algorithmthat incrementally expands the set of aggregate pred-icates during the inference procedure.
In this paper,we describe a general algorithm for incremental ex-pansion of predicates in MLNs, then present an im-plementation of the algorithm applied to the problemof identity uncertainty.2 Related WorkMLNs were designed to subsume various previouslyproposed statistical relational models.
Probabilisticrelational models (Friedman et al, 1999) combinedescriptive logic with directed graphical models, butare restricted to acyclic graphs.
Relational Markovnetworks (Taskar et al, 2002) use SQL queries tospecify the structure of undirected graphical mod-els.
Since first-order logic subsumes SQL, MLNscan be viewed as more expressive than relationalMarkov networks, although existing applications ofMLNs have not fully utilized this increased expres-sivity.
Other approaches combining logic program-ming and log-linear models include stochastic logicprograms (Cussens, 2003) and MACCENT(Dehaspe,1997), although MLNs can be shown to representboth of these.Viewed as a method to avoid grounding an in-tractable number of predicates, this paper has similarmotivations to recent work in lifted inference (Poole,2003; de Salvo Braz et al, 2005), which performsinference directly at the first-order level to avoid in-stantiating all predicates.
Although our model is notan instance of lifted inference, it does attempt to re-duce the number of predicates by instantiating themincrementally.Identity uncertainty (also known as record linkage,deduplication, object identification, and co-referenceresolution) is the problem of determining whether aset of constants (mentions) refer to the same object(entity).
Successful identity resolution enables vi-sion systems to track objects, database systems todeduplicate redundant records, and text processingsystems to resolve disparate mentions of people, or-ganizations, and locations.Many probabilistic models of object identificationhave been proposed in the past 40 years in databases(Fellegi and Sunter, 1969; Winkler, 1993) and nat-ural language processing (McCarthy and Lehnert,1995; Soon et al, 2001).
With the introductionof statistical relational learning, more sophisticatedmodels of identity uncertainty have been developedthat consider the dependencies between related con-solidation decisions.Most relevant to this work are the recent relationalmodels of identity uncertainty (Milch et al, 2005;McCallum and Wellner, 2003; Parag and Domingos,2004).
McCallum and Wellner (2003) present exper-iments using a conditional random field that factor-izes into a product of pairwise decisions about men-tion pairs (Model 3).
These pairwise decisions aremade collectively using relational inference; however,as pointed out in Milch et al (2004), there are short-comings to this model that stem from the fact that itdoes not capture features of objects, only of mentionpairs.
For example, aggregate features such as ?a re-searcher is unlikely to publish in more than 2 differ-ent fields?
or ?a person is unlikely to be referred to bythree different names?
cannot be captured by solelyexamining pairs of mentions.
Additionally, decom-posing an object into a set of mention pairs resultsin ?double-counting?
of attributes, which can skewreasoning about a single object (Milch et al, 2004).Similar problems apply to the model in Parag andDomingos (2004).Milch et al (2005) address these issues by con-structing a generative probabilistic model over pos-sible worlds called BLOG, where realizations of ob-jects are typically sampled from a generative process.While BLOG model provides attractive semantics forreasoning about unknown objects, the transition togeneratively trained models sacrifices some of the at-tractive properties of the discriminative model in Mc-Callum and Wellner (2003) and Parag and Domin-gos (2004), such as the ability to easily incorporatemany overlapping features of the observed mentions.In contrast, generative models are constrained eitherto assume the independence of these features or toexplicitly model their interactions.Object identification can also be seen as an in-stance of supervised clustering.
Daume?
III andMarcu (2004) and Carbonetto et al (2005) presentsimilar Bayesian supervised clustering algorithmsthat use a Dirichlet process to model the numberof clusters.
As a generative model, it has similar ad-vantages and disadvantages as Milch et al (2005),with the added capability of integrating out the un-certainty in the true number of objects.In this paper, we present of identity uncertaintythat incorporates the attractive properties of Mc-Callum and Wellner (2003) and Milch et al (2005),resulting in a discriminative model to reason aboutobjects.3 Markov logic networksLet F = {Fi} be a set of first order formulae withcorresponding real-valued weights w = {wi}.
Givena set of constants C = {ci}, define ni(x) to be thenumber of true groundings of Fi realized in a setting42of the world given by atomic formulae x.
A Markovlogic network (MLN) (Richardson and Domingos,2004) defines a joint probability distribution overpossible worlds x.
In this paper, we will work withdiscriminative MLNs (Singla and Domingos, 2005),which define the conditional distribution over a setof query atoms y given a set of evidence atoms x.Using the normalizing constant Zx, the conditionaldistribution is given byP (Y = y|X = x) =1Zxexp?
?|Fy|?i=1wini(x, y)??
(1)where Fy ?
F is the set of clauses for which at leastone grounding contains a query atom, and ni(x, y)is the number of true groundings of the ith clausecontaining evidence atom x and query atom y.3.1 Inference Complexity in GroundMarkov NetworksThe set of predicates and constants in Markov logicdefine the structure of a Markov network, called aground Markov network.
In discriminative Markovlogic networks, this resulting network is a conditionalMarkov network (also known as a conditional ran-dom field (Lafferty et al, 2001)).From Equation 1, the formulae Fy specify thestructure of the corresponding Markov network asfollows: Each grounding of a predicate specified inFy has a corresponding node in the Markov network;and an edge connects two nodes in the network if andonly if their corresponding predicates co-occur in agrounding of a formula Fy.
Thus, the complexityof the formulae in Fy will determine the complexityof the resulting Markov network, and therefore thecomplexity of inference.
When Fy contains complexfirst-order quantifiers, the resulting Markov networkmay contain a prohibitively large number of nodes.For example, let the set of constants C be the set ofauthors {ai}, papers {pi}, and conferences {ci} froma research publication database.
Predicates may in-clude AuthorOf(ai, pj), AdvisorOf(ai, aj), andProgramCommittee(ai, cj).
Each grounding of apredicate corresponds to a random variable in thecorresponding Markov network.It is important to notice how query predicates andevidence predicates differ in their impact on inferencecomplexity.
Grounded evidence predicates result inobserved random variables that can be highly con-nected without resulting in an increase in inferencecomplexity.
For example, consider the binary evi-dence predicate HaveSameLastName(ai .
.
.
ai+k).This aggregate predicate reflects informa-tion about a subset of (k ?
i + 1) constants.The value of this predicate is dependent onthe values of HaveSameLastName(ai, ai+1),HaveSameLastName(ai, ai+2), etc.
However,since all of the corresponding variables are observed,inference does not need to ensure their consistencyor model their interaction.In contrast, complex query predicates can makeinference more difficult.
Consider the querypredicate HaveSameAdvisor(ai .
.
.
ai+k).
Here,the related predicatesHaveSameAdvisor(ai, ai+1),HaveSameAdvisor(ai, ai+2), etc., all correspondto unobserved binary random variables that themodel must predict.
To ensure their consistency,the resulting Markov network must contain depen-dency edges between each of these variables, result-ing in a densely connected network.
Since inferencein general in Markov networks scales exponentiallywith the size of the largest clique, inference in thegrounded network quickly becomes intractable.One solution is to limit the expressivity of thepredicates.
In the previous example, we can decom-pose the predicate HaveSameAdvisor(ai .
.
.
ai+k)into its (k ?
i + 1)2 corresponding pairwise pred-icates, such as HaveSameAdvisor(ai, ai+1).
An-swering an aggregate query about the advisors of agroup of students can be handled by a conjunctionof these pairwise predicates.However, as discussed in Sections 1 and 2, wewould like to reason about objects, not just pairsof mentions, because this enables richer evidencepredicates.
For example, the evidence predicatesAtLeastTwoCoauthoredPapers(ai .
.
.
ai+k)and NumberOfStudents(ai) can behighly predictive of the query predicateHaveSameAdvisor(ai .
.
.
ai+k).Below, we describe a discriminative MLN for iden-tity uncertainty that is able to reason at the objectlevel.3.2 Identity uncertaintyTypically, MLNs make a unique names assumption,requiring that different constants refer to distinct ob-jects.
In the publications database example, eachauthor constant ai is a string representation of oneauthor mention found in the text of a citation.
Theunique names assumption assumes that each ai refersto a distinct author in the real-world.
This simplifiesthe network structure at the risk of weak or fallaciouspredictions (e.g., AdvisorOf(ai, aj) is erroneous ifai and aj actually refer to the same author).
Theidentity uncertainty problem is the task of removingthe unique names assumption by determining which43constants refer to the same real-world objects.Richardson and Domingos (2004) address this con-cern by creating the predicate Equals(ci, cj) be-tween each pair of constants.
While this retains thecoherence of the model, the restriction to pairwisepredicates can be a drawback if there exist informa-tive features over sets of constants.
In particular,by only capturing features of pairs of constants, thissolution cannot model the compatibility of object at-tributes, only of constant attributes (Section 2).Instead, we desire a conditional model that allowspredicates to be defined over a set of constants.One approach is to introduce constants that repre-sent objects, and connect them to their mentions bypredicates such as IsMentionOf(ci, cj).
In additionto computational issues, this approach also some-what problematically requires choosing the numberof objects.
(See Richardson and Domingos (2004) fora brief discussion.
)Instead, we propose instantiating aggregate pred-icates over sets of constants, such that a setting ofthese predicates implicitly determines the number ofobjects.
This approach allows us to model attributesover entire objects, rather than only pairs of con-stants.
In the following sections, we describe aggre-gate predicates in more detail, as well as the approx-imations necessary to implement them efficiently.3.3 Aggregate predicatesAggregate predicates are predicates that take as ar-guments an arbitrary number of constants.
For ex-ample, the HaveSameAdvisor(ai .
.
.
ai+k) predi-cate in the previous section is an example of an ag-gregate predicate over k ?
i + 1 constants.Let IC = {1 .
.
.
N} be the set of indices into the setof constants C, with power set P(IC).
For any subsetd ?
P(IC), an aggregate predicate A(d) defines aproperty over the subset of constants d.Note that aggregate predicates can be trans-lated into first-order formulae.
For example,HaveSameAdvisor(ai .
.
.
ai+k) can be re-writtenas ?
(ax, ay) ?
{ai .
.
.
ai+k} SameAdvisor(ax, ay).By using aggregate predicates we make explicit thefact that we are modeling the attributes at the objectlevel.We distinguish between aggregate query predi-cates, which represent unobserved aggregate vari-ables, and aggregate evidence predicates, which rep-resent observed aggregate variables.
Note that usingaggregate query predicates can complicate inference,since they represent a collection of fully connectedhidden variables.
The main point of this paper isthat although these aggregate query predicates arespecifiable in MLNs, they have not been utilized be-cause of the resulting inference complexity.
We showthat the gains made possible by these predicates of-ten outweigh the approximations required for infer-ence.As discussed in Section 3.1, for each aggregatequery predicates A(d), it is critical that the modelpredict consistent values for every related subset of d.Enforcing this consistency requires introducing de-pendency edges between aggregate query predicatesthat share arguments.
In general, this can be a diffi-cult problem.
Here, we focus on the special case foridentity uncertainty where the main query predicateunder consideration is AreEqual(d).The aggregate query predicate AreEqual(d) istrue if and only if all constants di ?
d refer to thesame object.
Since each subset of constants corre-sponds to a candidate object, a (consistent) settingof all the AreEqual predicates results in a solutionto the object identification problem.
The numberof objects is chosen based on the optimal groundingof each of these aggregate predicates, and thereforedoes not require a prior over the number of objects.That is, once all the AreEqual predicates are set,they determine a clustering with a fixed number ofobjects.
The number of objects is not modeled or setdirectly, but is implied by the result of MAP infer-ence.
(However, a posterior over the number of ob-jects could be modeled discriminatively in an MLN(Richardson and Domingos, 2004).
)This formulation also allows us to compute aggre-gate evidence predicates over objects to help predictthe values of each AreEqual predicate.
For exam-ple, NumberFirstNames(d) returns the number ofdifferent first names used to refer to the object ref-erenced by constants d. In this way, we can modelaggregate features of an object, capturing the com-patibility among its attributes.For a given C, there are |P(IC)| possible ground-ings of the AreEqual query predicates.
Naively im-plemented, such an approach would require enumer-ating all subsets of constants, ultimately resulting inan unwieldy network.An equivalent way to state the problem is thatusing N -ary predicates results in a Markov networkwith one node for each grounding of the predicate.Since in the general case there is one groundingfor each subset of C, the size of the correspondingMarkov network will be exponential in |C|.
See Fig-ure 1 for an example instantiation of an MLN withthree constants (a, b, c) and one AreEqual predi-cate.In this paper, we provide algorithms to per-form approximate inference and parameter estima-tion by incrementally instantiating these predicates44AreEqual(a,b) AreEqual(a,c) AreEqual(b,c)AreEqual(a,b,c)Figure 1: An example of the network instantiatedby an MLN with three constants and the aggregatepredicate AreEqual, instantiated for all possiblesubsets with size ?
2.as needed.3.4 MAP InferenceMaximum a posteriori (MAP) inference seeks the so-lution toy?
= argmaxyP (Y = y|X = x)where y?
is the setting of all the query predicatesFy (e.g.
AreEqual) with the maximal conditionaldensity.In large, densely connected Markov networks, acommon approximate inference technique is loopybelief propagation (i.e.
the max-product algorithmapplied to a cyclic graph).
However, the use of ag-gregate predicates makes it intractable even to in-stantiate the entire network, making max-productan inappropriate solution.Instead, we employ an incremental inference tech-nique that grounds aggregate query predicates inan agglomerative fashion based on the model?s cur-rent MAP estimates.
This algorithm can be viewedas a greedy agglomerative search for a local opti-mum of P (Y |X), and has connections to recent workon correlational clustering (Bansal et al, 2004) andgraph partitioning for MAP estimation (Boykov etal., 2001).First, note that finding the MAP estimate does notrequire computing Zx, since we are only interested inthe relative values of each configuration, and Zx isfixed for a given x.
Thus, at iteration t, we computean unnormalized score for yt (the current setting ofthe query predicates) given the evidence predicatesx as follows:S(yt, x) = exp?
?|F t|?i=0wini(x, yt)?
?where F t ?
Fy is the set of aggregate predicatesrepresenting a partial solution to the object identifi-cation task for constants C, specified by yt.Algorithm 1 Approximate MAP Inference Algo-rithm1: Given initial predicates F 02: while ScoreIsIncreased do3: F ?i ?
FindMostLikelyPredicate(Ft)4: F ?i ?
true5: F t ?
ExpandPredicates(F ?i , Ft)6: end whileAlgorithm 1 outlines a high-level description of theapproximate MAP inference algorithm.
The algo-rithm first initializes the set of query predicated F 0such that all AreEqual predicates are restrictedto pairs of constants, i.e.
AreEqual(ci, cj) ?
(i, j).This is equivalent to a Markov network containingone unobserved random variable for each pair of con-stants, where each variable indicates whether a pairof constants refer to the same object.Initially, each AreEqual predicate is assumedfalse.
In line 3, the procedure FindMostLike-lyPredicate iterates through each query predicatein F t, setting each to true in turn and calculating itsimpact on the scoring function.
The procedure re-turns the predicate F ?i such that setting F?i to Trueresults in the greatest increase in the scoring functionS(yt, x).Let (c?i .
.
.
c?j ) be the set of constants ?merged?by setting their AreEqual predicate to true.
TheExpandPredicates procedure creates new predi-cates AreEqual(c?i .
.
.
c?j , ck .
.
.
cl) corresponding toall the potential predicates created by merging theconstants c?i .
.
.
c?j with any of the other previouslymerged constants.
For example, after the first it-eration, a pair of constants (c?i , c?j ) are merged.The set of predicates are expanded to includeAreEqual(c?i , c?j , ck) ?ck, reflecting all possible ad-ditional references to the proposed object referencedby c?i , c?j .This algorithm continues until there is no predi-cate that can be set to true that increases the scorefunction.In this way, the final setting of Fy is a local max-imum of the score function.
As in other searchalgorithms, we can employ look-ahead to reducethe greediness of the search (i.e., consider multiplemerges simultaneously), although we do not includelook-ahead in experiments reported here.It is important to note that each expansion of theaggregate query predicates Fy has a correspondingset of aggregate evidence predicates.
These evidencepredicates characterize the compatibility of the at-tributes of each hypothesized object.453.4.1 PruningThe space required for the above algorithm scales?
(|C|2), since in the initialization step we mustground a predicate for each pair of constants.
We usethe canopy method of McCallum et al (2000), whichthresholds a ?cheap?
similarity metric to prune un-necessary comparisons.
This pruning can be doneat subsequent stages of inference to restrict whichpredicates variables will be introduced.Additionally, we must ensure that predicate set-tings at time t do not contradict settings at t ?
1(e.g.
if F t(a, b, c) = 1, then F t+1(a, b) = 1).
Bygreedily setting unobserved nodes to their MAP es-timates, the inference algorithm ignores inconsistentsettings and removes them from the search space.3.5 Parameter estimationGiven a fully labeled training set D of constants an-notated with their referent objects, we would like toestimate the value of w that maximizes the likelihoodof D. That is, w?
= argmaxw Pw(y|x).When the data are few, we can explicitly instan-tiate all AreEqual(d) predicates, setting their cor-responding nodes to the values implied by D. Thelikelihood is given by Equation 1, where the normal-izer is Zx =?y?
exp(?|F ?y|i=1 wini(x, y?
)).Although this sum over y?
to calculate Zx is ex-ponential in |y|, many inconsistent settings can bepruned as discussed in Section 3.4.1.In general, however, instantiating the entire setof predicates denoted by y and calculating Zx isintractable.
Existing methods for MLN parame-ter estimation include pseudo-likelihood and votedperceptron (Richardson and Domingos, 2004; Singlaand Domingos, 2005).
We instead follow the recentsuccess in piecewise training for complex undirectedgraphical models (Sutton and McCallum, 2005) bymaking the following two approximations.
First, weavoid calculating the global normalizer Zx by calcu-lating local normalizers, which sum only over the twovalues for each aggregate query predicate groundedin the training data.
We therefore maximize the sumof local probabilities for each query predicate giventhe evidence predicates.This approximation can be viewed as constructinga log-linear binary classifier to predict whether anisolated set of constants refer to the same object.Input features include arbitrary first-order featuresover the input constants, and the output is a binaryvariable.
The parameters of this classifier correspondto the w weights in the MLN.
This simplificationresults in a convex optimization problem, which wesolve using gradient descent with L-BFGS, a second-order optimization method (Liu and Nocedal, 1989).The second approximation addresses the fact thatall query predicates from the training set cannot beinstantiated.
We instead sample a subset FS ?
Fyand maximize the likelihood of this subset.
The sam-pling is not strictly uniform, but is instead obtainedby collecting the predicates created while perform-ing object identification using a weak method (e.g.string comparisons).
More explicitly, predicates aresampled from the training data by performing greedyagglomerative clustering on the training mentions,using a scoring function that computes the similar-ity between two nodes by string edit distance.
Thegoal of this clustering is not to exactly reproduce thetraining clusters, but to generate correct and incor-rect clusters that have similar characteristics (size,homogeneity) to what will be present in the testingdata.4 ExperimentsWe perform experiments on two object identificationtasks: citation matching and author disambiguation.Citation matching is the task of determining whethertwo research paper citation strings refer to the samepaper.
We use the Citeseer corpus (Lawrence et al,1999), containing approximately 1500 citations, 900of which are unique.
The citations are manually la-beled with cluster identifiers, and the strings are seg-mented into fields such as author, title, etc.
The cita-tion data is split into four disjoint categories by topic,and the results presented are obtained by training onthree categories and testing on the fourth.Using first-order logic, we create a number of ag-gregate predicates such as AllTitlesMatch, Al-lAuthorsMatch, AllJournalsMatch, etc., aswell as their existential counterparts, ThereExist-sTitleMatch, etc.
We also include count predi-cates, which indicate the number of these matches ina set of constants.Additionally, we add edit distance predicates,which calculate approximate matches1 between titlefields, etc., for each pair of citations in a set of cita-tions.
Aggregate features are used for these, such as?there exists a pair of citations in this cluster whichhave titles that are less than 30% similar?
and ?theminimum edit distance between titles in a cluster isgreater than 50%.
?We evaluate using pairwise precision, recall, andF1, which measure the system?s ability to predictwhether each pair of constants refer to the same ob-ject or not.
Table 1 shows the advantage of our1We use the Secondstring package, found athttp://secondstring.sourceforge.net46Table 1: Precision, recall, and F1 performance forcitation matching task, where Objects is an MLNusing aggregate predicates, and Pairs is an MLN us-ing only pairwise predicates.
Objects outperformsPairs on three of the four testing sets.Objects Pairspr re f1 pr re f1constraint 85.8 79.1 82.3 63.0 98.0 76.7reinforce 97.0 90.0 93.4 65.6 98.2 78.7face 93.4 84.8 88.9 74.2 94.7 83.2reason 97.4 69.3 81.0 76.4 95.5 84.9Table 2: Performance on the author disambiguationtask.
Objects outperforms Pairs on two of thethree testing sets.Objects Pairspr re f1 pr re f1miller d 73.9 29.3 41.9 44.6 1.0 61.7li w 39.4 47.9 43.2 22.1 1.0 36.2smith b 61.2 70.1 65.4 14.5 1.0 25.4proposed model (Objects) over a model that onlyconsiders pairwise predicates of the same features(Pairs).
Note that Pairs is a strong baseline thatperforms collective inference of citation matching de-cisions, but is restricted to use only IsEqual(ci, cj)predicates over pairs of citations.
Thus, the perfor-mance difference is due to the ability to model first-order features of the data.Author disambiguation is the task of decidingwhether two strings refer to the same author.
To in-crease the task complexity, we collect citations fromthe Web containing different authors with matchinglast names and first initials.
Thus, simply performinga string match on the author?s name would be insuffi-cient in many cases.
We searched for three commonlast name / first initial combinations (Miller, D;Li, W; Smith, B).
From this set, we collected 400citations referring to 56 unique authors.
For theseexperiments, we train on two subsets and test on thethird.We generate aggregate predicates similar to thoseused for citation matching.
Additionally, we in-clude features indicating the overlap of tokens fromthe titles and indicating whether there exists a pairof authors in this cluster that have different mid-dle names.
This last feature exemplifies the sort ofreasoning enabled by aggregate predicates: For ex-ample, consider a pairwise predicate that indicateswhether two authors have the same middle name.Very often, middle name information is unavailable,so the name ?Miller, A.?
may have high similarity toboth ?Miller, A.
B.?
and ?Miller, A. C.?.
However,it is unlikely that the same person has two differentmiddle names, and our model learns a weight for thisfeature.
Table 2 demonstrates the advantage of thismethod.Overall, Objects achieves F1 scores superior toPairs on 5 of the 7 datasets.
These results indicatethe potential advantages of using complex first-orderquantifiers in MLNs.
The cases in which Pairs out-performs Objects are likely due to the fact that theapproximate inference used in Objects is greedy.Increasing the robustness of inference is a topic offuture research.5 Conclusions and Future WorkWe have presented an algorithm that enables practi-cal inference in MLNs containing first-order existen-tial and universal quantifiers, and have demonstratedthe advantages of this approach on two real-worlddatasets.
Future work will investigate efficient waysto improve the approximations made during infer-ence, for example by reducing its greediness by revis-ing the MAP estimates made at previous iterations.Although the optimal number of objects is cho-sen implicitly by the inference algorithm, there maybe reasons to explicitly model this number.
For ex-ample, if there exist global features of the data thatsuggest there are many objects, then the inference al-gorithm should be less inclined to merge constants.Additionally, the data may exhibit ?preferential at-tachment?
such that the probability of a constantbeing added to an existing object is proportional tothe number of constants that refer to that object.Future work will examine the feasibility of addingaggregate query predicates to represent these values.More subtly, one may also want to directly modelthe size of the object population.
For example, givena database of authors, we may want to estimate notonly how many distinct authors exist in the database,but also how many distinct authors exist outside ofthe database, as discussed in Milch et al (2005).Discriminatively-trained models cannot easily reasonabout objects for which they have no observations;so a generative/discriminative hybrid model may berequired to properly estimate this value.Finally, while the inference algorithm we describeis evaluated only on the object uncertainty task, wewould like to extend it to perform inference over ar-bitrary query predicates.476 AcknowledgmentsWe would like to thank the reviewers, and Pallika Kananifor helpful discussions.
This work was supported inpart by the Center for Intelligent Information Retrieval,in part by U.S. Government contract #NBCH040171through a subcontract with BBNT Solutions LLC, inpart by The Central Intelligence Agency, the NationalSecurity Agency and National Science Foundation un-der NSF grant #IIS-0326249, and in part by the DefenseAdvanced Research Projects Agency (DARPA), throughthe Department of the Interior, NBC, Acquisition Ser-vices Division, under contract number NBCHD030010.Any opinions, findings and conclusions or recommenda-tions expressed in this material are the author(s)?
and donot necessarily reflect those of the sponsor.ReferencesNikhil Bansal, Avrim Blum, and Shuchi Chawla.
2004.Correlation clustering.
Machine Learining, 56:89?113.Yuri Boykov, Olga Veksler, and Ramin Zabih.
2001.
Fastapproximate energy minimization via graph cuts.
InIEEE transactions on Pattern Analysis and MachineIntelligence (PAMI), 23(11):1222?1239.Peter Carbonetto, Jacek Kisynski, Nando de Freitas, andDavid Poole.
2005.
Nonparametric bayesian logic.
InUAI.J.
Cussens.
2003.
Individuals, relations and structuresin probabilistic models.
In Proceedings of the FifteenthConference on Uncertainty in Artificial Intelligence,pages 126?133, Acapulco, Mexico.Hal Daume?
III and Daniel Marcu.
2004.
Supervised clus-tering with the dirichlet process.
In NIPS?04 Learn-ing With Structured Outputs Workshop, Whistler,Canada.Rodrigo de Salvo Braz, Eyal Amir, and Dan Roth.
2005.Lifted first-order probabilistic inference.
In IJCAI,pages 1319?1325.L.
Dehaspe.
1997.
Maximum entropy modeling withclausal constraints.
In Proceedings of the SeventhInternational Workshop on Inductive Logic Program-ming, pages 109?125, Prague, Czech Republic.I.
P. Fellegi and A.
B. Sunter.
1969.
A theory for recordlinkage.
Journal of the American Statistical Associa-tion, 64:1183?1210.Nir Friedman, Lise Getoor, Daphne Koller, and Avi Pf-effer.
1999.
Learning probabilistic relational models.In IJCAI, pages 1300?1309.John Lafferty, Andrew McCallum, and Fernando Pereira.2001.
Conditional random fields: Probabilistic modelsfor segmenting and labeling sequence data.
In Proc.18th International Conf.
on Machine Learning, pages282?289.
Morgan Kaufmann, San Francisco, CA.S.
Lawrence, C. L. Giles, and K. Bollaker.
1999.
Digi-tal libraries and autonomous citation indexing.
IEEEComputer, 32:67?71.D.
C. Liu and J. Nocedal.
1989.
On the limited mem-ory BFGS method for large scale optimization.
Math.Programming, 45(3, (Ser.
B)):503?528.A.
McCallum and B. Wellner.
2003.
Toward condi-tional models of identity uncertainty with applicationto proper noun coreference.
In IJCAI Workshop onInformation Integration on the Web.Andrew K. McCallum, Kamal Nigam, and Lyle Ungar.2000.
Efficient clustering of high-dimensional data setswith application to reference matching.
In Proceed-ings of the Sixth International Conference On Knowl-edge Discovery and Data Mining (KDD-2000), Boston,MA.Joseph F. McCarthy and Wendy G. Lehnert.
1995.
Us-ing decision trees for coreference resolution.
In IJCAI,pages 1050?1055.Brian Milch, Bhaskara Marthi, and Stuart Russell.
2004.Blog: Relational modeling with unknown objects.
InICML 2004 Workshop on Statistical Relational Learn-ing and Its Connections to Other Fields.Brian Milch, Bhaskara Marthi, and Stuart Russell.
2005.BLOG: Probabilistic models with unknown objects.
InIJCAI.Parag and Pedro Domingos.
2004.
Multi-relationalrecord linkage.
In Proceedings of the KDD-2004 Work-shop on Multi-Relational Data Mining, pages 31?48,August.D.
Poole.
2003.
First-order probabilistic inference.
InProceedings of the Eighteenth International Joint Con-ference on Artificial Intelligence, pages 985?991, Aca-pulco, Mexico.
Morgan Kaufman.M.
Richardson and P. Domingos.
2004.
Markov logicnetworks.
Technical report, University of Washington,Seattle, WA.Parag Singla and Pedro Domingos.
2005.
Discriminativetraining of markov logic networks.
In Proceedings ofthe Twentieth National Conference of Artificial Intel-ligence, Pittsburgh, PA.Wee Meng Soon, Hwee Tou Ng, and Daniel Chung YongLim.
2001.
A machine learning approach to corefer-ence resolution of noun phrases.
Comput.
Linguist.,27(4):521?544.Charles Sutton and Andrew McCallum.
2005.
Piecewisetraining of undirected models.
In Submitted to 21stConference on Uncertainty in Artificial Intelligence.Ben Taskar, Abbeel Pieter, and Daphne Koller.
2002.Discriminative probabilistic models for relational data.In Uncertainty in Artificial Intelligence: Proceedings ofthe Eighteenth Conference (UAI-2002), pages 485?492,San Francisco, CA.
Morgan Kaufmann Publishers.William E. Winkler.
1993.
Improved decision rules inthe fellegi-sunter model of record linkage.
Technicalreport, Statistical Research Division, U.S. Census Bu-reau, Washington, DC.48
