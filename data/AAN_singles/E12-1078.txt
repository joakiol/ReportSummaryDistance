Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 767?776,Avignon, France, April 23 - 27 2012. c?2012 Association for Computational LinguisticsTo what extent does sentence-internal realisation reflect discoursecontext?
A study on word orderSina Zarrie?
Jonas KuhnInstitut fu?r maschinelle SprachverarbeitungUniversity of Stuttgart, Germanyzarriesa,jonas@ims.uni-stuttgart.deAoife CahillEducational Testing ServicePrinceton, NJ 08541, USAacahill@ets.orgAbstractWe compare the impact of sentence-internal vs. sentence-external features onword order prediction in two generationsettings: starting out from a discrimina-tive surface realisation ranking model foran LFG grammar of German, we enrichthe feature set with lexical chain featuresfrom the discourse context which can berobustly detected and reflect rough gram-matical correlates of notions from theoreti-cal approaches to discourse coherence.
In amore controlled setting, we develop a con-stituent ordering classifier that is trainedon a German treebank with gold corefer-ence annotation.
Surprisingly, in both set-tings, the sentence-external features per-form poorly compared to the sentence-internal ones, and do not improve overa baseline model capturing the syntacticfunctions of the constituents.1 IntroductionThe task of surface realization, especially in a rel-atively free word order language like German, isonly partially determined by hard syntactic con-straints.
The space of alternative realizations thatare strictly speaking grammatical is typically con-siderable.
Nevertheless, for any given choice oflexical items and prior discourse context, only afew realizations will come across as natural andwill contribute to a coherent text.
Hence, any NLPapplication involving a non-trivial generation stepis confronted with the issue of soft constraints ongrammatical alternatives in one way or another.There are countless approaches to modellingthese soft constraints, taking into account theirinteraction with various aspects of the discoursecontext (givenness or salience of particular refer-ents, prior mentioning of particular concepts).Since so many factors are involved and there isfurther interaction with subtle semantic and prag-matic differentiations, lexical choice, stylisticsand presumably processing factors, theoretical ac-counts making reliable predictions for real cor-pus examples have for a long time proven elusive.As for German, only quite recently, a number ofcorpus-based studies (Filippova and Strube, 2007;Speyer, 2005; Dipper and Zinsmeister, 2009) havemade some good progress towards a coherence-oriented account of at least the left edge of theGerman clause structure, the Vorfeld constituent.What makes the technological application oftheoretical insights even harder is that for mostrelevant factors, automatic recognition cannot beperformed with high accuracy (e.g., a coreferenceaccuracy in the 70?s means there is a good dealof noise) and for the higher-level notions suchas the information-structural focus, interannotatoragreement on real corpus data tends to be muchlower than for core-grammatical notions (Poesioand Artstein, 2005; Ritz et al 2008).On the other hand, many of the relevant dis-course factors are reflected indirectly in proper-ties of the sentence-internal material.
Most no-tably, knowing the shape of referring expressionsnarrows down many aspects of givenness andsalience of its referent; pronominal realizationsindicate givenness, and in German there are eventwo variants of the personal pronoun (er and der)for distinguishing salience.
So, if the genera-tion task is set in such a way that the actual lex-ical choice, including functional categories suchas determiners, is fully fixed (which is of coursenot always the case), one can take advantage of767these reflexes.
This explains in part the fairly highbaseline performance of n-gram language mod-els in the surface realization task.
And the effectcan indeed be taken much further: the discrimi-native training experiments of Cahill and Riester(2009) show how effective it is to systematicallytake advantage of asymmetry patterns in the mor-phosyntactic reflexes of the discourse notion ofinformation status (i.e., using a feature set withwell-chosen purely sentence-bound features).These observations give rise to the question: inthe light of the difficulty in obtaining reliable dis-course information on the one hand and the effec-tiveness of exploiting the reflexes of discourse inthe sentence-internal material on the other ?
canwe nevertheless expect to gain something fromadding sentence-external feature information?We propose two scenarios for adressing thisquestion: first, we choose an approximative ac-cess to context information and relations betweendiscourse referents ?
lexical reiteration of headwords, combined with information about theirgrammatical relation and topological positioningin prior sentences.
We apply these features in arich sentence-internal surface realisation rankingmodel for German.
Secondly, we choose a morecontrolled scenario: we train a constituent order-ing classifier based on a feature model that cap-tures properties of discourse referents in terms ofmanually annotated coreference relations.
As weget the same effect in both setups ?
the sentence-external features do not improve over a baselinethat captures basic morphosyntactic properties ofthe constituents ?
we conclude that sentence-internal realisation is actually a relatively accuratepredictor of discourse context, even more accuratethan information that can be obtained from coref-erence and lexical chain relations.2 Related WorkIn the generation literature, most works on ex-ploiting sentence-external discourse informationare set in a summarisation or content orderingframework.
Barzilay and Lee (2004) propose anaccount for constraints on topic selection based onprobabilistic content models.
Barzilay and Lapata(2008) propose an entity grid model which repre-sents the distribution of referents in a discoursefor sentence ordering.
Karamanis et al(2009)use Centering-based metrics to assess coherencein an information ordering system.
Clarke and La-pata (2010) have improved a sentence compres-sion system by capturing prominence of phrasesor referents in terms of lexical chain informationinspired by Morris and Hirst (1991) and Center-ing (Grosz et al 1995).
In their system, discoursecontext is represented in terms of hard constraintsmodelling whether a certain constituent can bedeleted or not.In the linearisation or surface realisation do-main, there is a considerable body of work ap-proximating information structure in terms ofsentence-internal realisation (Ringger et al 2004;Filippova and Strube, 2009; Velldal and Oepen,2005; Cahill et al 2007).
Cahill and Riester(2009) improve realisation ranking for German ?which mainly deals with word order variation ?
byrepresenting precedence patterns of constituentsin terms of asymmetries in their morphosyntac-tic properties.
As a simple example, a pattern ex-ploited by Cahill and Riester (2009) is the ten-dency of definite elements tend to precede indef-inites, which, on a discourse level, reflects thatgiven entities in a sentence tend to precede newentities.Other work on German surface realisation hashighlighted the role of the initial position in theGerman sentence, the so-called Vorfeld (or ?pre-field?).
Filippova and Strube (2007) show thatonce the Vorfeld (i.e.
the constituent that precedesthe finite verb) is correctly determined, the pre-diction of the order in the Mittelfeld (i.e.
the con-stituents that follow the finite verb) is very easy.Cheung and Penn (2010) extend the approachof Filippova and Strube (2007) and augment asentence-internal constituent ordering model withsentence-external features inspired from the en-tity grid model proposed by Barzilay and Lapata(2008).3 MotivationWhile there would be many ways to construeor represent discourse context (e.g.
in terms ofthe global discourse or information structure), weconcentrate on capturing local coherence throughthe distribution of discourse referents in a text.These discourse referents basically correspond tothe constituents that our surface realisation modelhas to put in the right order.
As the order of refer-ents or constituents is arguably influenced by theinformation structure of a sentence given the pre-vious text, our main assumption was that infor-768(1) a. Kurze Zeit spa?ter erkla?rte ein Anrufer bei Nachrichtenagenturen in Pakistan , die Gruppe Gamaa bekenne sich.Shortly after, a caller declared at the news agencies in Pakistan, that the group Gamaa avowes itself.b.
Diese Gruppe wird fu?r einen Gro?teil der Gewalttaten verantwortlich gemacht , die seit dreieinhalb Jahren inA?gypten veru?bt worden sind .This group is made responsible for most of the violent acts that have been committed in Egypt in the last three anda half years.
(2) a. Belgien wu?nscht, dass sich WEU und NATO daru?ber einigen.Belgium wants that WEU and NATO agree on that.b.
Belgien sieht in der NATO die beste milita?rische Struktur in Europa .Belgium sees the best military structure of Europe in the NATO.
(3) a. Frauen vom Land ka?mpften aktiv darum , ein Staudammprojekt zu verhindern.Women from the countryside fighted actively to block the dam project.b.
Auch in den Sta?dten fa?nden sich immer mehr Frauen in Selbsthilfeorganisationen zusammen.Also in the cities, more and more women team up in self-help organisations.mation about the prior mentioning of a referentwould be helpful for predicting the position of thisreferent in a sentence.The idea that the occurence of discourse refer-ents in a text is a central aspect of discourse struc-ture has been systematically pursued by CenteringTheory (Grosz et al 1995).
Its most importantnotions are related to the realisation of discoursereferents (i.e.
described as ?centers?)
and the waythe centers are arranged in a sequence of utter-ances to make this sequence a coherent discourse.Another important concept is the ?ranking?
of dis-course referents which basically determines theprominence of a referent in a certain sentence andis driven by several factors (e.g.
their grammati-cal function).
For free word order languages likeGerman, word order has been proposed as one ofthe factors that account for the ranking (Poesio etal., 2004).
In a similar spirit, Morris and Hirst(1991) have proposed that chains of (related) lex-ical items in a text are an important indicator oftext structure.Our main hypothesis was that it is possible toexploit these intuitions from Centering Theoryand the idea of lexical chains for word order pre-diction.
Thus, we expected that it would be easierto predict the position of a referent in a sentenceif we have not only given its realisation in the cur-rent utterance but also its prominence in the previ-ous discourse.
Especially, we expected this intu-ition to hold for cases where the morpho-syntacticrealisation of a constituent does not provide manyclues.
This is illustrated in Examples (1) and (2)which both exemplify the reiteration of a lexicalitem in two subsequent sentences, (reiteration isone type of lexical chain discussed in Morris andHirst (1991)).
In Example (1), the second instanceof the noun ?group?
is modified by a demonstra-tive pronoun such that its ?known?
and prominentdiscourse status is overt in the morpho-syntacticrealisation.
In Example (2), both instances of?Belgium?
are realised as bare proper nouns with-out an overt morphosyntactic clue indicating theirdiscourse status.Beyond the simple presence of reitered items insequences of sentences, we expected that it wouldbe useful to look at the position and syntacticfunction of the previous mentions of a discoursereferent.
In Example (1), the reiterated item is firstintroduced in an embedded sentence and realisedin the Vorfeld in the second utterance.
In termsof centering, this transition would correspond toa topic shift.
In Example (2), both instances arerealised in the Vorfeld, such that the topic of thefirst sentence is carried over to the next.In Example (3), we illustrate a further type oflexical reiteration.
In this case, two identical headnouns are realised in subsequent sentences, eventhough they refer to two different discourse refer-ents.
While this type of lexical chain is describedas ?reiteration without identity of referents?
byMorris and Hirst (1991), it would not be capturedin Centering since this is not a case of strict coref-erence.
On the other hand, lexical chains do notcapture types of reiterated discourse referents thathave distinct morpho-syntactic realisations, e.g.nouns and pronouns.Originally, we had the hypothesis that strictcorefence information is more useful and accuratefor word order prediction than rather loose lexi-cal chains which conflate several types of referen-tial and lexical relations.
However, the advantageof chains, especially chains of reiteration, is thatthey can be easily detected in any corpus text and769that they might capture ?topics?
of sentences be-yond the identity of referents.
Thus, we startedout from the idea of lexical chains and added cor-responding features in a statistical ranking modelfor surface realisation of German (Section 4).
Asthis strategy did not work out, we wanted to assesswhether an ideal coreference annotation would behelpful at all for predicting word order.
In a sec-ond experiment, we use a corpus which is manu-ally annotated for coreference (Section 5).4 Experiment 1: Realisation Rankingwith Lexical ChainsIn this Section, we present an experiment that in-vestigates sentence-external context in a surfacerealisation task.
The sentence-external context isrepresented in terms of lexical chain features andcompared to sentence-internal models which arebased on morphosyntactic features.
The experi-ment thus targets a generation scenario where nocoreference information is available and aims atassessing whether relatively naive context infor-mation is also useful.4.1 System DescriptionWe carry out our first experiment in a regener-ation set-up with two components: a) a large-scale hand-crafted Lexical Functional Grammar(LFG) for German (Rohrer and Forst, 2006), usedto parse and regenerate a corpus sentence, b)a stochastic ranker that selects the most appro-priate regenerated sentence in context accordingto an underlying, linguistically motivated featuremodel.
In contrast to fully statistical linearisationmethods, our system first generates the full setof sentences that correspond to the grammaticallywell-formed realisations of the intermediate syn-tactic representation.1 This representation is anf-structure, which underspecifies the order of con-stituents and, to some extent, their morphologicalrealisation, such that the output sentences containall possible combinations of word order permu-tations and morphological variants.
Dependingon the length and structure of the original corpussentence, the set of regenerated sentences can behuge (see Cahill et al(2007) for details on regen-erating the German treebank TIGER).1There are occasional mistakes in the grammar whichsometimes lead to ungrammatical strings being generated,but this is rare.The realisation ranking component is an SVMranking model implemented with SVMrank,a Support Vector Machine-based learning tool(Joachims, 2006).
During training, each sentenceis annotated with a rank and a set of features ex-tracted from the F-structure, its surface string andexternal resources (e.g.
a language model).
Ifthe sentence matches the original corpus string,its rank will be highest, the assumption being thatthe original sentence corresponds to the optimalrealisation in context.
The output of generation,the top-ranked sentence, is evaluated against theoriginal corpus sentence.4.2 The Feature ModelsAs the aim of this experiment is to better un-derstand the nature of sentence-internal featuresreflecting discourse context and compare themto sentence-external ones, we build several fea-ture models which capture different aspects of theconstituents in a given sentence.
The sentence-internal features describe the morphosyntacic re-alisation of constituents, for instance their func-tion (?subject?, ?object?
), and can be straightfor-wardly extracted from the f-structure.
These fea-tures are then combined into discriminative prece-dence features, for instance ?subject-precedes-object?.
We implement the following types ofmorphosyntactic features:?
syntactic function (arguments and adjuncts)?
modification (e.g.
nouns modified by relativeclauses, genitive etc.)?
syntactic category (e.g.
adverbs, propernouns, phrasal arguments)?
definiteness for nouns?
number and person for nominal elements?
types of pronouns (e.g.
demonstrative, re-flexive)?
constituent span and number of embeddednodes in the treeIn addition, we also include language modelscores in our ranking model.
In Section 4.4,we report on results for several subsets of thesefeatures where ?BaseSyn?
refers to a model thatonly includes the syntactic function features and?FullMorphSyn?
includes all features mentionedabove.For extracting the lexical chains, we check forany overlapping nouns in the n sentences previ-ous to the current one being generated.
We check770Rank Sentence and Features% Diese Gruppe wird fu?r einen Gro?teil der Gewalttaten verantwortlich gemacht.% This group is for a major part of the violent acts responsible made.1 subject-<-pp-object, demonstrative-<-indefinite, overlap-<-no-overlap, overlap-in-vorfeld, lm:-7.89% Fu?r einen Gro?teil der Gewalttaten wird diese Gruppe verantwortlich gemacht.% For a major part of the violent acts is this group responsible made.3 pp-object-<-subject, indefinite-<-demonstrative, no-overlap-<-overlap, no-overlap-in-vorfeld, lm:-10.33% Verantwortlich gemacht wird diese Gruppe fu?r einen Gro?teil der Gewalttaten.% Responsible made is this group for a major part of the violent acts.3 subject-<-pp-object, demonstrative-<-indefinite, overlap-<-no-overlap, lm:-9.41Figure 1: Made-up training example for realisation ranking with precedence featuresproper and common nouns, considering full andpartial overlaps as shown in Examples (1) and(2), where the (a) example is the previous sen-tence in the corpus.
For each overlap, we recordthe following properties: (i) function in the previ-ous sentence, (ii) position in the previous sentence(e.g.
Vorfeld), (iii) distance between sentences,(iv) total number of overlaps.These overlap features are then alsocombined in terms of precedence, e.g.
?has subject overlap:3-precedes-no overlap?,meaning that in the current sentence a nounthat was previously mentioned in a subject 3sentences ago precedes a noun that was notmentioned before.In Figure 1, we give an example of a set of gen-eration alternatives and their (partial) feature rep-resentation for the sentence (1-b).
Precedence isindicated by ?<?.Basically, our sentence-external feature modelis built on the intuition that lexical chains or over-laps approximate discourse status in a way whichis similar to sentence-internal morphosyntacticproperties.
Thus, we would expect that overlapsindicate givenness, salience or prominence andthat asymmetries between overlapping and non-overlapping entities are helpful in the ranking.4.3 DataAll our models are trained on 7,039 sentences(subdivided into 1259 texts) from the TIGERTreebank of German newspaper text (Brants et al2002).
We tune the parameters of our SVM modelon a development set of 55 sentences and reportthe final results for our unseen test set of 240 sen-tences.
Table 1 shows how many sentences in ourtraining, development and test sets have at leastone textually overlapping phrase in the previous1?10 sentences.We choose the TIGER treebank, which has no# Sentences % Sentences with overlapin context Training Dev Test1 20.96 23.64 20.422 35.42 40.74 35.003 45.58 50.00 53.334 52.66 53.70 58.755 57.45 58.18 64.586 61.42 57.41 68.757 64.58 61.11 70.838 67.05 62.96 72.089 69.20 64.81 74.1710 71.16 70.37 75.83Table 1: The percentage of sentences that have at leastone overlapping entity in the previous n sentencescoreference annotation, since we already have anumber of resources available to match the syn-tactic analyses produced by our grammar againstthe analyses in the treebank.
Thus, in our regen-eration system, we parse the sentences with thegrammar, and choose the parsed f-structures thatare compatible with the manual annotation in theTIGER treebank as is done in Cahill et al(2007).This compatibility check eliminates noise whichwould be introduced by generating from incorrectparses (e.g.
incorrect PP-attachments typically re-sult in unnatural and non-equivalent surface reali-sations).For comparing the string chosen by the mod-els against the original corpus sentence, we useBLEU, NIST and exact match.
Exact match isa strict measure that only credits the system if itchooses the exact same string as the original cor-pus string.
BLEU and NIST are more relaxedmeasures that compare the strings on the n-gramlevel.
Finally, we report accuracy scores for theVorfeld position (VF) corresponding to the per-centage of sentences generated with a correct Vor-feld.771Sc BLEU NIST Exact VF0 0.766 11.885 50.19 64.01 0.765 11.756 49.78 64.02 0.765 11.886 50.01 64.13 0.765 11.885 50.08 63.84 0.761 11.723 49.43 63.25 0.765 11.884 49.71 64.26 0.768 11.892 50.42 64.67 0.765 11.885 50.01 64.58 0.764 11.884 49.78 64.39 0.765 11.888 49.82 63.610 0.764 11.889 49.7 63.5Table 2: Tenfold-crossvalidation for feature modelFullMorphSyn and different context windows (Sc)Model BLEU VFLanguage Model 0.702 51.2Language Model + Context Sc = 5 0.715 54.3BaseSyn 0.757 62.0BaseSyn + Context Sc = 5 0.760 63.0FullMorphSyn 0.766 64.0FullMorphSyn + Context Sc = 5 0.763 64.2Table 3: Evaluation for different feature models; ?Lan-guage Model?
: ranking based on language modelscores, ?BaseSyn?
: precedence between constituentfunctions, ?FullMorphSyn?
: entire set of sentence-internal features.4.4 ResultsIn Table 2, we report the performance of the fullsentence-internal feature model combined withcontext windows from zero to ten.
The scoreshave been obtained from tenfold-crossvalidation.For none of the context windows, the model out-performs the baseline with a zero context whichhas no sentence-external features.
In Table 3,we compare the performance of several featuremodels corresponding to subsets of the featuresused so far which are combined with sentence-external features respectively.
We note that thefunction precedence features (i.e.
the ?BaseSyn?model) are very powerful, leading to a major im-provement compared to a language model.
Thesentence-external features lead to an improvementwhen combined with the language-model basedranking.
However, this improvement is leveledout in the BaseSyn model.On the one hand, the fact that the lexical chainfeatures improve a language-model based rankingsuggests these features are, to some extent, pre-dictive for certain patterns of German word order.On the other hand, the fact that they don?t improveover an informed sentence-internal baseline sug-gests that these patterns are equally well capturedby morphosyntactic features.
However, we cannotexclude the possibility that the chain features aretoo noisy as they conflate several types of lexicaland coreferential relations.
This will be adressedin the following experiment.5 Experiment 2: Constituent Orderingwith Centering-inspired FeaturesWe now look at a simpler generation setup wherewe concentrate on the ordering of constituents inthe German Vorfeld and Mittelfeld.
This strat-egy has also been adopted in previous investiga-tions of German word order: Filippova and Strube(2007) show that once the German Vorfeld is cor-rectly chosen, the prediction accuracy for the Mit-telfeld (the constituents following the finite verb)is in the 90s.In order to eliminate noise introduced from po-tentially heterogeneous chain features, we look atcoreference features and, again, compare them tosentence-internal morphosyntactic features.
Wetarget a generation scenario where coreference in-formation is available.
The aim is to establish anupper bound concerning the quality improvementfor word order prediction by recurring to manualcorefence annotation.5.1 Data and SetupWe carry out the constituent ordering experimenton the Tu?ba-D/Z treebank (v5) of German news-paper articles (Telljohann et al 2006).
It com-prises about 800k tokens in 45k sentences.
Wechoose this corpus because it is not only annotatedwith syntactic analyses but also with coreferencerelations (Naumann, 2006).
The syntactic annota-tion format differs from the TIGER treebank usedin the previous experiment, for instance, it ex-plicitely represents the Vorfeld and Mittelfeld asphrasal nodes in the tree.
This format is very con-venient for the extraction of constituents in the re-spective positions.The Tu?ba-D/Z coreference annotation distin-guishes several relations between discourse ref-erents, most importantly ?coreferential relation?and ?anaphoric relation?
where the first denotesa relation between noun phrases that refer to thesame entity, and the latter refers to a link betweena pronoun and a contextual antecedent, see Nau-mann (2006) for further detail.
We expected thecoreferential relation to be particularly useful, as772it cannot always be read off the morphosyntac-tic realisation of a noun phrase, whereas pronounsare almost always used in an anaphoric relation.The constituent ordering model is implementedas a classifier that is given a set of constituentsand predicts the constituent that is most likely tobe realised in the Vorfeld.The set of candidate constituents is determinedfrom the tree of the original corpus sentence.
Wewill assume that all constituents under a Vorfeldand Mittelfeld node can be freely reordered.
Thus,we do not check whether the word order variantswe look at are actually grammatical assuming thatmost of them are.
In this sense, this experimentis close to fully statistical generation approaches.As a further simplification, we do not look at mor-phological generation variants of the constituentsor their head verb.The classifier is implemented with SVMrankagain.
In contrast to the previous experimentwhere we learned to rank sentences, the classi-fier now learns to rank constituents.
The con-stituents have been extracted using the tool de-scribed in Bouma (2010).
The final data set com-prises 48.513 candidate sets of freely orderableconstituents.5.2 Centering-inspired Feature ModelTo compare the discourse context model against asentence-based model, we implemented a numberof sentence-internal features that are very similarto the features used in the previous experiment.Since we extract them from the syntactic annota-tion instead of f-structures, some labels and fea-ture names will be different, however, the designof the sentence-internal model is identical to theprevious one in Section 4.The sentence-external features differ in someaspects from Section 4, since we extract coref-erence relations of several types (see (Naumann,2006) for the anaphoric relations annotated in theTueba-D/Z).
For each type of coreference link,we extract the following properties: (i) functionof the antecedent, (ii) position of the antecedent,(iii) distance between sentences, (iv) type of rela-tion.
We also distinguish coreference links anno-tated for the whole phrase (?head link?)
and linksthat are annotated for an element embedded by theconstituent (?contained link?).
The two types areillustrated in Examples (4) and (5).
Note that bothcases would not have been captured in the lexical# VF # MFBackward Center 3.5% 5.1%Forward Center 6.8% 6.8%Coref Link 30.5% 23.4%Table 4: Backward and forward centers and their posi-tionschain model since there is no lexical overlap be-tween the realisations of the discourse referents.These types of coreference features implicitlycarry the information that would also be consid-ered in a Centering formalisation of discoursecontext.
In addition to these, we designed featuresthat explicitly describe centers as these mighthave a higher weight.
In line with Clarke andLapata (2010), we compute backward (CB) andforward centers (CF ) in the following way:1.
Extract all entities from the current sentenceand the previous sentence.2.
Rank the entities of the previous sentence ac-cording to their function (subject < directobject < indirect object ...).3.
Find the highest ranked entity in the previoussentence that has a link to an entity in thecurrent sentence, this entity is the CB of thesentence.In the same way, we mark entities as forwardcenters that are ranked highest in the current sen-tence and have a link to an entity in the followingsentence.2 In Table 4, we report the percentage ofsentences that have backward and forward centersin the Vorfeld or Mittelfeld.
While the percentageof sentences that realise a backward center is quitelow, the overall proportion of sentences contain-ing some type of coreference link is in a dimen-sion such that the learner could definitely pick upsome predictive patterns.
Going by the relativefrequencies, coreferential constituents have a biastowards appearing in the Vorfeld rather than in theMittelfeld.5.3 ResultsFirst, we build three coreference-based con-stituent classifiers on their entire training set andcompare them to their sentence-internal baseline.The most simple baseline records the category of2In Centering, all entities in a given utterance can be seenas forward centers, however we thought that this implemen-tation would be more useful.773(4) a.
Die Rechnung geht an die AWO.The bill goes to the AWO.b.
[Hintergrund der gegenseitigen Vorwu?rfe in der Arbeiterwohlfahrt] sind offenbar scharfe Konkurrenzen zwischenBremern und Bremerhavenern.Apparently, [the background of the mutual accusations at the labour welfare] are rivalries between people fromBremen and Bremerhaven.
(5) a.
Dies ist die Behauptung, mit der Bremens Ha?fensenator die Skeptiker davon u?berzeugt hat, [...].This is the claim, which Bremen?s harbour senator used to convince doubters, [...].b.
Fu?r diese Behauptung hat Beckmeyer bisher keinen Nachweis geliefert.
So far, Beckmeyer has not given a prove ofthis claim.Model VFConstituentLength + HeadPos 47.48%ConstituentLength + HeadPos + Coref 51.30%BaseSyn 54.82%BaseSyn + Coref 56.21%FullMorphSyn 57.24%FullMorphSyn + Coref 57.40%Table 5: Results from Vorfeld classification, trainingand evaluation on entire treebankthe constituent head and the number of words thatthe constituent spans.
Additionally, in parallel tothe experiment in Section 4, we build a ?BaseSyn?model which has the syntactic function features,and a ?FullMorphSyn?
model which comprisesthe entire set of sentence-internal features.
Toeach of these baseline, we add the coreferencefeatures.
The results are reported in Table 5.In this experiment, we find an effect ofthe sentence-external features over the simplesentence-internal baselines.
However, in the fullyspelled-out, sentence-internal model, the effectis, again, minimal.
Moreover, for each base-line, we obtain higher improvements by addingfurther sentence-internal features than by addingsentence-external ones the accuracy of the sim-ple baseline (47.48%) improves by 7.34 pointsthrough adding function features (the accuracyof BaseSyn is 54.82%) and by only 3.48 pointsthrough adding coreference features.We run a second experiment in order to so seewhether the better performance of the sentence-internal features is related to their coverage.
Webuild and evaluate the same set of classifiers onthe subset of sentences that contain at least onecoreference link for one of its constituents (seeTable 4 for the distribution of coreference linksin our data).
The results are given in Table 6.
Inthis experiment, the coreference features improveover all sentence-internal baselines including the?FullMorphSyn?
model.Model VFConstituentLength + HeadPos 46.61%ConstituentLength + HeadPos + Coref 52.23%BaseSyn 54.63%BaseSyn + Coref 56.67%FullMorphSyn 55.36%FullMorphSyn + Coref 57.93%Table 6: Results from Vorfeld classification, trainingand evaluation on sentences that contain a coreferencelink5.4 DiscussionThe results presented in this Section consis-tently complete the picture that emerged fromthe experiments in Section 4.
Even if we havehigh quality information about discourse con-text in terms of relations between referents, anon-trivial sentence-internal model for word or-der prediction can be hardly improved.
Thissuggests that sentence-internal approximations ofdiscourse context provide a fairly good way ofdealing with local coherence in a linearisationtask.
It is also interesting that the sentence-external features improve over simple baselines,but get leveled out in rich sentence-internal fea-ture models.
From this, we conclude that thesentence-external features we implemented are tosome extent predictive for word order, but thatthey can be covered by sentence-internal featuresas well.Our second evaluation concentrating on thesentences that have coreference informationshows that the better performance of the sentence-internal features is also related to their cover-age.
These results confirm our initial intuitionthat coreference information can add to the pre-dictive power of the morpho-syntactic features incertain contexts.
This positive effect disappearswhen sentences with and without coreferentialconstituents are taken together.
For future work,it would be promising to investigate whether the774positive impact of coreference features can bestrengthened if the coreference annotation schemeis more exhaustive, including, e.g., bridging andevent anaphora.6 ConclusionWe have carried out a number of experiments thatshow that sentence-internal models for word orderare hardly improved by features which explicitelyrepresent the preceding context of a sentence interms of lexical and referential relations betweendiscourse entities.
This suggests that sentence-internal realisation implicitly carries a lot of im-formation about discourse context.
On average,the morphosyntactic properties of constituents ina text are better approximates of their discoursestatus than actual coreference relations.This result feeds into a number of researchquestions concerning the representation of dis-course and its application in generation systems.Although we should certainly not expect a com-putational model to achieve a perfect accuracy inthe constituent ordering task ?
even humans onlyagree to a certain extent in rating word order vari-ants (Belz and Reiter, 2006; Cahill, 2009) ?
theaverage accuracy in the 60?s for prediction of Vor-feld occupance is still moderate.
An obvious di-rection would be to further investigate more com-plex representations of discourse that take into ac-count the relations between utterances, such astopic shifts.
Moreover, it is not clear whether theeffects we find for linearisation in this paper carryover to other levels of generation such as tacti-cal generation where syntactic functions are notfully specified.
In a broader perspective, our re-sults underline the need for better formalisationsof discourse that can be translated into features forlarge-scale applications such as generation.AcknowledgmentsThis work was funded by the Collaborative Re-search Centre (SFB 732) at the University ofStuttgart.ReferencesRegina Barzilay and Mirella Lapata.
2008.
Modelinglocal coherence: An entity-based approach.
Com-putational Linguistics, 34:1?34.Regina Barzilay and Lillian Lee.
2004.
Catching thedrift: Probabilistic content models with applicationsto generation and summarization.
In Proceedings ofHLT-NAACL 2004, Boston,MA.Anja Belz and Ehud Reiter.
2006.
Comparing auto-matic and human evaluation of NLG systems.
InProceedings of EACL 2006, pages 313?320, Trento,Italy.Gerlof Bouma.
2010.
Syntactic tree queries in prolog.In Proceedings of the Fourth Linguistic AnnotationWorkshop, ACL 2010.Sabine Brants, Stefanie Dipper, Silvia Hansen, Wolf-gang Lezius, and George Smith.
2002.
The TIGERTreebank.
In Proceedings of the Workshop on Tree-banks and Linguistic Theories.Aoife Cahill and Arndt Riester.
2009.
Incorporat-ing information status into generation ranking.
InProceedings of the Joint Conference of the 47th An-nual Meeting of the ACL and the 4th InternationalJoint Conference on Natural Language Processingof the AFNLP, pages 817?825, Suntec, Singapore,August.
Association for Computational Linguistics.Aoife Cahill, Martin Forst, and Christian Rohrer.2007.
Stochastic Realisation Ranking for a FreeWord Order Language.
In Proceedings of theEleventh European Workshop on Natural LanguageGeneration, pages 17?24, Saarbru?cken, Germany.DFKI GmbH.Aoife Cahill.
2009.
Correlating human and automaticevaluation of a german surface realiser.
In Proceed-ings of the ACL-IJCNLP 2009 Conference Short Pa-pers, pages 97?100, Suntec, Singapore, August.
As-sociation for Computational Linguistics.Jackie C.K.
Cheung and Gerald Penn.
2010.
Entity-based local coherence modelling using topologicalfields.
In Proceedings of the 48th Annual Meetingof the Association for Computational Linguistics(ACL 2010).
Association for Computational Lin-guistics.James Clarke and Mirella Lapata.
2010.
Discourseconstraints for document compression.
Computa-tional Linguistics, 36(3):411?441.Stefanie Dipper and Heike Zinsmeister.
2009.
Therole of the German Vorfeld for local coherence.
InChristian Chiarcos, Richard Eckart de Castilho, andManfred Stede, editors, Von der Form zur Bedeu-tung: Texte automatisch verarbeiten/From Form toMeaning: Processing Texts Automatically, pages69?79.
Narr, Tu?bingen.Katja Filippova and Michael Strube.
2007.
The ger-man vorfeld and local coherence.
Journal of Logic,Language and Information, 16:465?485.Katja Filippova and Michael Strube.
2009.
Tree Lin-earization in English: Improving Language ModelBased Approaches.
In Proceedings of Human Lan-guage Technologies: The 2009 Annual Conferenceof the North American Chapter of the Associationfor Computational Linguistics, Companion Volume:Short Papers, pages 225?228, Boulder, Colorado,June.
Association for Computational Linguistics.775Barbara J. Grosz, Aravind Joshi, and Scott Weinstein.1995.
Centering: A framework for modeling thelocal coherence of discourse.
Computational Lin-guistics, 21(2):203?225.Thorsten Joachims.
2006.
Training linear SVMs inlinear time.
In Proceedings of the ACM Conferenceon Knowledge Discovery and Data Mining (KDD),pages 217?226.Nikiforos Karamanis, Massimo Poesioand Chris Mel-lish, and Jon Oberlander.
2009.
Evaluating center-ing for information ordering using corpora.
Com-putational Linguistics, 35(1).Jane Morris and Graeme Hirst.
1991.
Lexical cohe-sion, the thesaurus, and the structure of text.
Com-putational Linguistics, 17(1):21?225.Karin Naumann.
2006.
Manual for the annotation ofin-document referential relations.
Technical report,Seminar fu?r Sprachwissenschaft, Abt.
Computerlin-guistik, Universita?t Tu?bingen.Massimo Poesio and Ron Artstein.
2005.
The relia-bility of anaphoric annotation, reconsidered: Takingambiguity into account.
In Proc.
of ACL Workshopon Frontiers in Corpus Annotation.Massimo Poesio, Rosemary Stevenson, Barbara di Eu-genio, and Janet Hitzeman.
2004.
Centering: Aparametric theory and its instantiations.
Computa-tional Linguistics, 30(3):309?363.Eric K. Ringger, Michael Gamon, Robert C. Moore,David Rojas, Martine Smets, and Simon Corston-Oliver.
2004.
Linguistically Informed Statisti-cal Models of Constituent Structure for Orderingin Sentence Realization.
In Proceedings of the2004 International Conference on ComputationalLinguistics, Geneva, Switzerland.Julia Ritz, Stefanie Dipper, and Michael Go?tze.
2008.Annotation of information structure: An evaluationacross different types of texts.
In Proceedings of thethe 6th LREC conference.Christian Rohrer and Martin Forst.
2006.
Improv-ing Coverage and Parsing Quality of a Large-ScaleLFG for German.
In Proceedings of the Fifth In-ternational Conference on Language Resources andEvaluation (LREC), Genoa, Italy.Augustin Speyer.
2005.
Competing constraints onvorfeldbesetzung in german.
In Proceedings of theConstraints in Discourse Workshop, pages 79?87.Heike Telljohann, Erhard Hinrichs, Sandra Ku?bler,and Heike Zinsmeister.
2006.
Stylebook for thetu?bingen treebank of written german (tu?ba-d/z).revised version.
Technical report, Seminar fu?rSprachwissenschaft, Universita?t Tu?bingen.Erik Velldal and Stephan Oepen.
2005.
Maximumentropy models for realization ranking.
In Proceed-ings of the 10th Machine Translation Summit, pages109?116, Thailand.776
