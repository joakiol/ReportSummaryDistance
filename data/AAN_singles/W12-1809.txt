NAACL-HLT 2012 Workshop on Future directions and needs in the Spoken Dialog Community: Tools and Data, pages 17?18,Montre?al, Canada, June 7, 2012. c?2012 Association for Computational LinguisticsAfter Dialog Went Pervasive: Separating Dialog Behavior Modeling andTask ModelingAmanda J. StentAT&T Labs - ResearchFlorham Park, NJ 07932, USAstent@research.att.comDialog Goes Pervasive Until recently, many dialogsystems were information retrieval systems.
For ex-ample, using a telephone-based interactive responsesystem a US-based user can find flights from United(1-800-UNITED-1), get movie schedules (1-800-777-FILM), or get bus information (Black et al,2011).
These systems save companies money andhelp users access information 24/7.
However, theinteraction between user and system is tightly con-strained.
For the most part, each system only dealswith one domain, so the task models are typicallyflat slot-filling models (Allen et al, 2001b).
Also,the dialogs are very structured, with system initia-tive and short user responses, giving limited scopeto study important phenomena such as coreference.Smart phones and other mobile devices makepossible pervasive human-computer spoken dialog.For example, the Vlingo system lets users do websearches (information retrieval), but also connectscalls, opens other apps, and permits voice dictationof emails or social media updates1.
Siri can also helpusers make reservations and schedule meetings2.These new dialog systems are different from tra-ditional ones in several ways; they are multi-task,asynchronous, can involve rich context modeling,and have side effects in the ?real world?
:Multi-task ?
The system interacts with the user toaccomplish a series of (possibly related) tasks.
Forexample, a user might use the system to order a bookand then say schedule it for book club - a differenttask (e.g.
requiring different backend DB lookups)but related to the previous one by the book informa-1www.vlingo.com2http://www.apple.com/iphone/features/siri.htmltion.
Multi-task interaction increases the difficultyof interpretation and task inference, and so requiresnew kinds of dialog model (e.g.
(Lison, 2011)).Asynchronous ?
the user may give the system a com-mand (e.g.
Add Hunger Games with Mary for 3 pm),and the system may follow up on that command anhour later, after considerable intervening dialog (e.g.Mary texted you about the Hunger Games).
Becausethe dialog is multi-task, it is more free-flowing, withless clear start and end points but more opportunitiesfor adaptation and personalization.Rich context modeling ?
Mobile devices comewith numerous sensors useful for collecting non-linguistic context (e.g.
GPS, camera, web browseractions), while the semi-continuous nature of the in-teraction permits collection of rich linguistic con-text.
So far, dialog systems have used this contextonly in limited ways (e.g.
speech recognizer per-sonalization).
However, the opportunities for mod-eling human interaction behavior, including multi-modal interaction, are tremendous.Side effects ?in the real world?
?
the system (withinput from the user) can cause changes in the stateof the world (e.g.
emails get sent, hotel rooms getbooked).
This increases the importance of ground-ing and agreement in the interaction.
But it en-ables new kinds of evaluation, for example based onthe number of successfully completed subtasks overtime, or on comparing the efficacy of alternative sys-tem behaviors with the same user.Dialog Challenges and Task Challenges The im-plications for research on dialog systems are clear.It is unsustainable to reimplement dialog behaviorsfor each new task, or limit the use of context to the17most basic semantic representations.
As the fieldmoves forward, dialog behavior modeling will beincreasingly separated from task modeling (Allenet al, 2001a; Allen et al, 2001b).
Research ondialog modeling will focus on dialog layers, task-independent dialog behaviors such as (incremental)turn-taking, grounding, and coreference that involveboth participants.
Research on task modeling can fo-cus on the design of task models that are agnostic tothe types or forms of interaction that will use them,on general models for interactive problem-solving(Blaylock and Allen, 2005), and on rapid acquisitionand adaptation of task models (Jung et al, 2009).Within this space, there can be two types of (col-laborative or competitive) ?dialog challenge?
:Dialog layer-focused ?
Participants focus on modelsfor a particular dialog behavior, such as turn-taking,grounding, alignment, or coreference.
Implementa-tions cover both the interpretation and the generationaspects of the behavior.
Evaluation may be basedon a comparison of the implemented behaviors tohuman language behaviors (e.g.
for turn-taking,inter-turn silence, turn-final and turn-initial prosodiccues), and/or on user error rates and satisfactionscores.
An initial dialog layer-focused challengecould be on turn-taking (Baumann and Schlangen,2011; Selfridge and Heeman, 2010).Task modeling focused ?
This type of challenge willmove from modeling individual tasks, to automaticacquisition and use of task models for interactivetasks in dialog systems.
Future challenges of thistype would build on this by incorporating (in order):(a) tasks other than information retrieval (e.g.
surveytasks (Stent et al, 2008)); (b) task completion (taskswith subtasks that have side effects, e.g.
purchas-ing a ticket after looking up a route); (c) task adap-tation (during development, participants work withone task, and during evaluation, participants workwith a different but related task); and (d) multi-taskmodeling.
Participating systems could learn by do-ing (Jung et al, 2009), via user simulation (Rieserand Lemon, 2011), from corpora (Bangalore andStent, 2009), or from scripts or other abstract taskrepresentations (Barbosa et al, 2011).Tools for the Community It has never been eas-ier (with a little Web programming) to rapidlyprototype dialog systems as mobile apps, or touse them to collect data.
To enable researchersto focus on dialog- and task-modeling ratherthan component development, AT&T is happyto offer its AT&T WATSONSM speech recog-nizer and Natural VoicesTM text-to-speech syn-thesis engine in the cloud, through its SpeechMashup platform (Di Fabbrizio et al, 2009), toparticipants in dialog challenges.
The SpeechMashup supports rich logging of both linguisticand non-linguistic context, and is freely available athttp://service.research.att.com/smm.ReferencesJ.
F. Allen, G. Ferguson, and A. Stent.
2001a.
An archi-tecture for more realistic conversational systems.
InProceedings of IUI.J.
F. Allen et al 2001b.
Towards conversational human-computer interaction.
AI Magazine, 22(4):27?37.S.
Bangalore and A. Stent.
2009.
Incremental parsingmodels for dialog task structure.
In Proceedings ofEACL.L.
Barbosa et al 2011.
SpeechForms - from web tospeech and back.
In Proceedings of Interspeech.T.
Baumann and D. Schlangen.
2011.
Predicting themicro-timing of user input for an incremental spokendialogue system that completes a user?s ongoing turn.In Proceedings of SIGDIAL.A.
W. Black et al 2011.
Spoken dialog challenge 2010:comparison of live and control test results.
In Proceed-ings of SIGDIAL.N.
Blaylock and J. F. Allen.
2005.
A collaborativeproblem-solving model of dialogue.
In Proceedingsof SIGDIAL.G.
Di Fabbrizio, T. Okken, and J. Wilpon.
2009.
Aspeech mashup framework for multimodal mobile ser-vices.
In Proceedings of ICMI-MLMI.H.
Jung et al 2009.
Going beyond PBD: A play-by-playand mixed-initiative approach.
In Proceedings of theCHIWorkshop on End User Programming for the Web.P.
Lison.
2011.
Multi-policy dialogue management.
InProceedings of SIGDIAL.V.
Rieser and O.
Lemon.
2011.
Learning and evaluationof dialogue strategies for new applications: Empiricalmethods for optimization from small data sets.
Com-putational Linguistics, 37(1):153?196.E.
Selfridge and P. Heeman.
2010.
Importance-driventurn-bidding for spoken dialogue systems.
In Proceed-ings of ACL.A.
Stent, S. Stenchikova, and M. Marge.
2006.
Dialogsystems for surveys: The Rate-A-Course system.
InProceedings of SLT.18
