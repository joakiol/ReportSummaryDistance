Creating Multilingual Translation Lexicons with Regional VariationsUsing Web CorporaPu-Jen Cheng*, Yi-Cheng Pan*, Wen-Hsiang Lu+, and Lee-Feng Chien*?
* Institute of Information Science, Academia Sinica, Taiwan+ Dept.
of Computer Science and Information Engineering, National Cheng Kung Univ., Taiwan?
Dept.
of Information Management, National Taiwan University, Taiwan{pjcheng, thomas02, whlu, lfchien}@iis.sinica.edu.twAbstractThe purpose of this paper is to automaticallycreate multilingual translation lexicons withregional variations.
We propose a transitivetranslation approach to determine translationvariations across languages that have insuffi-cient corpora for translation via the miningof bilingual search-result pages and clues ofgeographic information obtained from Websearch engines.
The experimental resultshave shown the feasibility of the proposedapproach in efficiently generating translationequivalents of various terms not covered bygeneral translation dictionaries.
It also re-vealed that the created translation lexiconscan reflect different cultural aspects acrossregions such as Taiwan, Hong Kong andmainland China.1 IntroductionCompilation of translation lexicons is a crucial proc-ess for machine translation (MT) (Brown et al, 1990)and cross-language information retrieval (CLIR)systems (Nie et al, 1999).
A lot of effort has beenspent on constructing translation lexicons from do-main-specific corpora in an automatic way(Melamed, 2000; Smadja et al, 1996; Kupiec, 1993).However, such methods encounter two fundamentalproblems: translation of regional variations and thelack of up-to-date and high-lexical-coverage corpussource, which are worthy of further investigation.The first problem is resulted from the fact thatthe translations of a term may have variations in dif-ferent dialectal regions.
Translation lexicons con-structed with conventional methods may not adapt toregional usages.
For example, a Chinese-Englishlexicon constructed using a Hong Kong corpus can-not be directly adapted to the use in mainland Chinaand Taiwan.
An obvious example is that the word?taxi?
is normally translated into ????
(Chinesetransliteration of taxi) in Hong Kong, which is com-pletely different from the translated Chinese wordsof ?????
(rental cars) in mainland China and ?????
(cars with meters) in Taiwan.
Besides, trans-literations of a term are often pronounced differentlyacross regions.
For example, the company name?Sony?
is transliterated into ????
(xinli) in Tai-wan and ????
(suoni) in mainland China.
Suchterms, in today?s increasingly internationalizedworld, are appearing more and more often.
It is be-lieved that their translations should reflect the cul-tural aspects across different dialectal regions.Translations without consideration of the regionalusages will lead to many serious misunderstandings,especially if the context to the original terms is notavailable.Halpern (2000) discussed the importance oftranslating simplified and traditional Chinese lex-emes that are semantically, not orthographically,equivalent in various regions.
However, previouswork on constructing translation lexicons for use indifferent regions was limited.
That might be resultedfrom the other problem that most of the conventionalapproaches are based heavily on domain-specificcorpora.
Such corpora may be insufficient, or un-available, for certain domains.The Web is becoming the largest data repositoryin the world.
A number of studies have been re-ported on experiments in the use of the Web to com-plement insufficient corpora.
Most of them(Kilgarriff et al, 2003) tried to automatically collectparallel texts of different language versions (e.g.
Eng-lish and Chinese), instead of different regional ver-sions (e.g.
Chinese in Hong Kong and Taiwan), fromthe Web.
These methods are feasible but only certainpairs of languages and subject domains can extractsufficient parallel texts as corpora.
Different from theprevious work, Lu et al (2002) utilized Web anchortexts as a comparable bilingual corpus source to ex-tract translations for out-of-vocabulary terms (OOV),the terms not covered by general translation diction-aries.
This approach is applicable to the compilationof translation lexicons in diverse domains but requirespowerful crawlers and high network bandwidth togather Web data.It is fortunate that the Web contains rich pages ina mixture of two or more languages for some lan-guage pairs such as Asian languages and English.Many of them contain bilingual translations of terms,including OOV terms, e.g.
companies?, personal andtechnical names.
In addition, geographic informationabout Web pages also provides useful clues to theregions where translations appear.
We are, therefore,interested in realizing whether these nice character-istics make it possible to automatically constructmultilingual translation lexicons with regional varia-tions.
Real search engines, such as Google(http://www.google.com) and AltaVista (http://www.altavista.com), allow us to search English terms onlyfor pages in a certain language, e.g.
Chinese orJapanese.
This motivates us to investigate how toconstruct translation lexicons from bilingual search-result pages (as the corpus), which are normally re-turned in a long ordered list of snippets of summaries(including titles and page descriptions) to help userslocate interesting pages.The purpose of this paper is trying to propose asystematic approach to create multilingual transla-tion lexicons with regional variations through min-ing of bilingual search-result pages.
The bilingualpages retrieved by a term in one language areadopted as the corpus for extracting its translationsin another language.
Three major problems arefound and have to be dealt with, including: (1) ex-tracting translations for unknown terms ?
how toextract translations with correct lexical boundariesfrom noisy bilingual search-result pages, and how toestimate term similarity for determining correcttranslations from the extracted candidates; (2) find-ing translations with regional variations ?
how tofind regional translation variations that seldom co-occur in the same Web pages, and how to identifythe corresponding languages of the retrieved search-result pages once if the location clues (e.g.
URLs) inthem might not imply the language they are writtenin; and (3) translation with limited corpora  ?
howto translate terms with insufficient search-resultpages for particular pairs of languages such as Chi-nese and Japanese, and simplified Chinese and tradi-tional Chinese.The goal of this paper is to deal with the threeproblems.
Given a term in one language, all possibletranslations will be extracted from the obtained bi-lingual search-result pages based on their similarity tothe term.
For those language pairs with unavailablecorpora, a transitive translation model is proposed,by which the source term is translated into the targetlanguage through an intermediate language.
Thetransitive translation model is further enhanced by acompetitive linking algorithm.
The algorithm caneffectively alleviate the problem of error propagationin the process of translation, where translation errorsmay occur due to incorrect identification of the am-biguous terms in the intermediate language.
In addi-tion, because the search-result pages might containsnippets that do not be really written in the target lan-guage, a filtering process is further performed toeliminate the translation variations not of interest.Several experiments have been conducted to ex-amine the performance of the proposed approach.The experimental results have shown that the ap-proach can generate effective translation equivalentsof various terms ?
especially for OOV terms such asproper nouns and technical names, which can beused to enrich general translation dictionaries.
Theresults also revealed that the created translation lexi-cons can reflect different cultural aspects across re-gions such as Taiwan, Hong Kong and mainlandChina.In the rest of this paper, we review related work intranslation extraction in Section 2.
We present thetransitive model and describe the direct translationprocess in Sections 3 and 4, respectively.
The con-ducted experiments and their results are described inSection 5.
Finally, in Section 6, some concluding re-marks are given.2 Related WorkIn this section, we review some research in generat-ing translation equivalents for automatic construc-tion of translational lexicons.Transitive translation: Several transitive transla-tion techniques have been developed to deal with theunreliable direct translation problem.
Borin (2000)used various sources to improve the alignment ofword translation and proposed the pivot alignment,which combined direct translation and indirect trans-lation via a third language.
Gollins et al (2001) pro-posed a feasible method that translated terms inparallel across multiple intermediate languages toeliminate errors.
In addition, Simard (2000) ex-ploited the transitive properties of translations toimprove the quality of multilingual text alignment.Corpus-based translation: To automatically con-struct translation lexicons, conventional research inMT has generally used statistical techniques to ex-tract translations from domain-specific sentence-aligned parallel bilingual corpora.
Kupiec (1993)attempted to find noun phrase correspondences inparallel corpora using part-of-speech tagging andnoun phrase recognition methods.
Smadja et al(1996) proposed a statistical association measure ofthe Dice coefficient to deal with the problem of col-location translation.
Melamed (2000) proposed sta-tistical translation models to improve the techniquesof word alignment by taking advantage of pre-existing knowledge, which was more effective thana knowledge-free model.
Although high accuracy oftranslation extraction can be easily achieved by thesetechniques, sufficiently large parallel corpora for(a) Taiwan (Traditional Chinese)   (b)  Mainland China (Simplified Chinese) (c)  Hong Kong (Traditional Chinese)Figure 1: Examples of the search-result pages in different Chinese regions that were obtained via the Englishquery term ?George Bush?
from Google.various subject domains and language pairs are notalways available.Some attention has been devoted to automatic ex-traction of term translations from comparable oreven unrelated texts.
Such methods encounter moredifficulties due to the lack of parallel correlationsaligned between documents or sentence pairs.
Rapp(1999) utilized non-parallel corpora based on theassumption that the contexts of a term should besimilar to the contexts of its translation in any lan-guage pairs.
Fung et al (1998) also proposed a simi-lar approach that used a vector-space model andtook a bilingual lexicon (called seed words) as a fea-ture set to estimate the similarity between a wordand its translation candidates.Web-based translation: Collecting parallel texts ofdifferent language versions from the Web has re-cently received much attention (Kilgarriff et al,2003).
Nie et al (1999) tried to automatically dis-cover parallel Web documents.
They assumed a Webpage?s parents might contain the links to differentversions of it and Web pages with the same contentmight have similar structures and lengths.
Resnik(1999) addressed the issue of language identificationfor finding Web pages in the languages of interest.Yang et al (2003) presented an alignment method toidentify one-to-one Chinese and English title pairsbased on dynamic programming.
These methods of-ten require powerful crawlers to gather sufficientWeb data, as well as more network bandwidth andstorage.
On the other hand, Cao et al (2002) usedthe Web to examine if the arbitrary combination oftranslations of a noun phrase was statistically impor-tant.3 Construction of Translation LexiconsTo construct translation lexicons with regional varia-tions, we propose a transitive translation modelStrans(s,t) to estimate the degree of possibility of thetranslation of a term s in one (source) language lsinto a term t in another (target) language lt. Giventhe term s in ls, we first extract a set of terms C={tj},where tj in lt acts as a translation candidate of s, froma corpus.
In this case, the corpus consists of a set ofsearch-result pages retrieved from search enginesusing term s as a query.
Based on our previous work(Cheng et al, 2004), we can efficiently extract termtj by calculating the association measurement ofevery character or word n-gram in the corpus andapplying the local maxima algorithm.
The associa-tion measurement is determined by the degree ofcohesion holding the words together within a word n-gram, and enhanced by examining if a word n-gramhas complete lexical boundaries.
Next, we rank theextracted candidates C as a list T in a decreasing or-der by the model Strans(s,t) as the result.3.1 Bilingual Search-Result PagesThe Web contains rich texts in a mixture of multiplelanguages and in different regions.
For example,Chinese pages on the Web may be written in tradi-tional or simplified Chinese as a principle languageand in English as an auxiliary language.
Accordingto our observations, translated terms frequently oc-cur together with a term in mixed-language texts.For example, Figure 1 illustrates the search-resultpages of the English term ?George Bush,?
whichwas submitted to Google for searching Chinesepages in different regions.
In Figure 1 (a) it containsthe translations ??????
(George Bush) and ????
(Bush) obtained from the pages in Taiwan.
InFigures 1 (b) and (c) the term ?George Bush?
istranslated into ????
(busir) or ????
(buson) inmainland China and ????
(busu) in Hong Kong.This characteristic of bilingual search-result pages isalso useful for other language pairs such as otherAsian languages mixed with English.For each term to be translated in one (source)language, we first submit it to a search engine forlocating the bilingual Web documents containing theterm and written in another (target) language from aspecified region.
The returned search-result pagescontaining snippets (illustrated in Figure 1), insteadof the documents themselves, are collected as a cor-pus from which translation candidates are extractedand correct translations are then selected.Compared with parallel corpora and anchor texts,bilingual search-result pages are easier to collect andcan promptly reflect the dynamic content of the Web.In addition, geographic information about Webpages such as URLs also provides useful clues to theregions where translations appear.3.2 The Transitive Translation ModelTransitive translation is particularly necessary forthe translation of terms with regional variations be-cause the variations seldom co-occur in the samebilingual pages.
To estimate the possibility of beingthe translation t ?T of term s, the transitive transla-tion model first performs so-called direct translation,which attempts to learn translational equivalents di-rectly from the corpus.
The direct translation methodis simple, but strongly affected by the quality of theadopted corpus.
(Detailed description of the directtranslation method will be given in Section 4.
)If the term s and its translation t appear infre-quently, the statistical information obtained from thecorpus might not be reliable.
For example, a term insimplified Chinese, e.g.
???
(Internet) does notusually co-occur together with its variation in tradi-tional Chinese, e.g.
????
(Internet).
To dealwith this problem, our idea is that the term s can befirst translated into an intermediate translation m,which might co-occur with s, via a third (or interme-diate) language lm.
The correct translation t can thenbe extracted if it can be found as a translation of m.The transitive translation model, therefore, combinesthe processes of both direct translation and indirecttranslation, and is defined as:???????=>=?
"otherwise ),(),(),(),(),( if                                                ),,(),(mtmSmsStsStsStsStsSdirectdirectindirectdirectdirectmtransvqwhere m is one of the top k most probable interme-diate translations of s in language lm, and v is theconfidence value of m?s accuracy, which can be es-timated based on m?s probability of occurring in thecorpus, and q is a predefined threshold value.3.3 The Competitive Linking AlgorithmOne major challenge of the transitive translationmodel is the propagation of translation errors.
Thatis, incorrect m will significantly reduce the accuracyof the translation of s into t. A typical case is theindirect association problem (Melamed, 2000), asshown in Figure 2 in which we want to translate theterm s1 (s=s1).
Assume that t1 is s1?s correspondingtranslation, but appears infrequently with s1.
An in-direct association error might arise when t2, thetranslation of s1?s highly relevant term s2, co-occursoften with s1.
This problem is very important for thesituation in which translation is a many-to-manymapping.
To reduce such errors and enhance thereliability of the estimation, a competitive linkingalgorithm, which is extended from Melamed?s work(Melamed, 2000), is developed to determine themost probable translations.Figure 2: An illustration of a bipartite graph.The idea of the algorithm is described below.
Foreach translated term tj?T in lt, we translate it backinto original language ls and then model the transla-tion mappings as a bipartite graph, as shown in Fig-ure 2, where the vertices on one side correspond tothe terms {si} or {tj} in one language.
An edge eijindicates the corresponding two terms si and tj mightbe the translations of each other, and is weighted bythe sum of Sdirect(si,tj) and Sdirect(tj,si,).
Based on theweighted values, we can examine if each translatedterm tj?T in lt can be correctly translated into theoriginal term s1.
If term tj has any translations betterthan term s1 in ls, term tj might be a so-called indirectassociation error and should be eliminated from T. Inthe above example, if the weight of e22 is larger thanthat of e12, the term ?Technology?
will be not con-sidered as the translation of ??????
(Internet).Finally, for all translated terms {tj} ?
T that are noteliminated, we re-rank them by the weights of theedges {eij} and the top k ones are then taken as thetranslations.
More detailed description of the algo-rithm could be referred to Lu et al (2004).4 Direct TranslationIn this section, we will describe the details of the di-rect translation process, i.e.
the way to compute Sdi-rect(s,t).
Three methods will be presented to estimatethe similarity between a source term and each of itstranslation candidates.
Moreover, because the search-result pages of the term might contain snippets that donot actually be written in the target language, we willintroduce a filtering method to eliminate the transla-tion variations not of interest.4.1 Translation ExtractionThe Chi-square Method: A number of statisticalmeasures have been proposed for estimating termassociation based on co-occurrence analysis, includ-ing mutual information, DICE coefficient, chi-squaretest, and log-likelihood ratio (Rapp, 1999).
Chi-square test (?2) is adopted in our study because therequired parameters for it can be obtained by submit-InternetTechnology????
(Internet)??
(Technology)???
(Browser)??
(Computer)??
(Information)t1t2s2eijs3s4s5s1ting Boolean queries to search engines and utilizingthe returned page counts (number of pages).
Given aterm s and a translation candidate t, suppose the totalnumber of Web pages is N; the number of pages con-taining both s and t, n(s,t), is a; the number of pagescontaining s but not t, n(s,?t), is b; the number ofpages containing t but not s, n(?s,t), is c; and thenumber of pages containing neither s nor t, n(?s, ?t),is d. (Although d is not provided by search engines, itcan be computed by d=N-a-b-c.) Assume s and t areindependent.
Then, the expected frequency of (s,t),E(s,t), is (a+c)(a+b)/N; the expected frequency of(s,?t), E(s,?t), is (b+d)(a+b)/N; the expected fre-quency of (?s,t), E(?s,t), is (a+c)(c+d)/N; and the ex-pected frequency of (?s,?t), E(?s,?t), is (b+d)(c+d)/N.Hence, the conventional chi-square test can be com-puted as:.
)()()()()(),()],(),([) ,(2},{},,{22dcdbcabacbdaNYXEYXEYXntsSttYssXdirect+?+?+?+?-?
?=-= ???"??
"cAlthough the chi-square method is simple to com-pute, it is more applicable to high-frequency termsthan low-frequency terms since the former are morelikely to appear with their candidates.
Moreover, cer-tain candidates that frequently co-occur with term smay not imply that they are appropriate translations.Thus, another method is presented.The Context-Vector Method: The basic idea of thismethod is that the term s?s translation equivalentsmay share common contextual terms with s in thesearch-result pages, similar to Rapp (1999).
For boths and its candidates C, we take their contextual termsconstituting the search-result pages as their features.The similarity between s and each candidate in C willbe computed based on their feature vectors in the vec-tor-space model.Herein, we adopt the conventional tf-idf weightingscheme to estimate the significance of features anddefine it as:)log(),(max),( nNptfptfwjjiti ?= ,where f(ti,p) is the frequency of term ti in search-resultpage p, N is the total number of Web pages, and n isthe number of the pages containing ti.
Finally, thesimilarity between term s and its translation candidatet can be estimated with the cosine measure, i.e.CVdirectS (s,t)=cos(cvs, cvt), where cvs and cvt are the con-text vectors of s and t, respectively.In the context-vector method, a low-frequencyterm still has a chance of extracting correct transla-tions, if it shares common contexts with its transla-tions in the search-result pages.
Although the methodprovides an effective way to overcome the chi-squaremethod?s problem, its performance depends heavilyon the quality of the retrieved search-result pages,such as the sizes and amounts of snippets.
Also, fea-ture selection needs to be carefully handled in somecases.The Combined Method: The context-vector and chi-square methods are basically complementary.
Intui-tively, a more complete solution is to integrate thetwo methods.
Considering the various ranges of simi-larity values between the two methods, we computethe similarity between term s and its translation can-didate t by the weighted sum of 1/R?2(s,t) and1/RCV(s,t).
R?2(s,t) (or RCV(s,t)) represents the similar-ity ranking of each translation candidate t with respectto s and is assigned to be from 1 to k (number of out-put) in decreasing order of similarity measureSX2direct(s,t) (or SCVdirect(s,t)).
That is, if the similarityrankings of t are high in both of the context-vectorand chi-square methods, it will be also ranked high inthe combined method.4.2 Translation FilteringThe direct translation process assumes that the re-trieved search-result pages of a term exactly containsnippets from a certain region (e.g.
Hong Kong) andwritten in the target language (e.g.
traditional Chi-nese).
However, the assumption might not be reliablebecause the location (e.g.
URL) of a Web page maynot imply that it is written by the principle languageused in that region.
Also, we cannot identify the lan-guage of a snippet simply using its character encodingscheme, because different regions may use the samecharacter encoding schemes (e.g.
Taiwan and HongKong mainly use the same traditional Chinese encod-ing scheme).From previous work (Tsou et al, 2004) we knowthat word entropies significantly reflect languagedifferences in Hong Kong, Taiwan and China.Herein, we propose another method for dealing withthe above problem.
Since our goal is trying to elimi-nate the translation candidates {tj} that are not fromthe snippets in language lt, for each candidate tj wemerge all of the snippets that contain tj into a docu-ment and then identify the corresponding language oftj based on the document.
We train a uni-gram lan-guage model for each language of concern and per-form language identification based on adiscrimination function, which locates maximumcharacter or word entropy and is defined as:?????
?= ???
)|(ln)|(maxarg)()(lwplwptlangtjNwLlj ,where N(tj) is the collection of the snippets containingtj and L is a set of languages to be identified.
The can-didate tj will be eliminated if ?
)( jtlang lt.To examine the feasibility of the proposedmethod in identifying Chinese in Taiwan, mainlandChina and Hong Kong, we conducted a preliminaryexperiment.
To avoid the data sparseness of using atri-gram language model, we simply use the aboveunigram model to perform language identification.Even so, the experimental result has shown that veryhigh identification accuracy can be achieved.
SomeWeb portals contain different versions for specificregions such as Yahoo!
Taiwan (http://tw.yahoo.com) and Yahoo!
Hong Kong (http://hk.yahoo.com).This allows us to collect regional training data forconstructing language models.
In the task of translat-ing English terms into traditional Chinese in Taiwan,the extracted candidates for ?laser?
contained ????
(translation of laser mainly used in Taiwan) and????
(translation of laser mainly used in mainlandChina).
Based on the merged snippets, we found that????
had higher entropy value for the languagemodel of mainland China while ????
had higherentropy value for the language models of Taiwanand Hong Kong.5 Performance EvaluationWe conducted extensive experiments to examine theperformance of the proposed approach.
We obtainedthe search-result pages of a term by submitting it tothe real-world search engines, including Google andOpenfind (http://www.openfind.com.tw).
Only thefirst 100 snippets received were used as the corpus.Performance Metric: The average top-n inclusionrate was adopted as a metric on the extraction oftranslation equivalents.
For a set of terms to be trans-lated, its top-n inclusion rate was defined as the per-centage of the terms whose translations could befound in the first n extracted translations.
The ex-periments were categorized into direct translation andtransitive translation.5.1 Direct TranslationData set: We collected English terms from two real-world Chinese search engine logs in Taiwan, i.e.Dreamer (http://www.dreamer.com.tw) and GAIS(http://gais.cs.ccu.edu.tw).
These English terms werepotential ones in the Chinese logs that needed correcttranslations.
The Dreamer log contained 228,566unique query terms from a period of over 3 months in1998, while the GAIS log contained 114,182 uniquequery terms from a period of two weeks in 1999.
Thecollection contained a set of 430 frequent Englishterms, which were obtained from the 1,230 Englishterms out of the most popular 9,709 ones (with fre-quencies above 10 in both logs).
About 36% (156/430)of the collection could be found in the LDC (Linguis-tic Data Consortium, http://www.ldc.upenn.edu/Projects/Chinese) English-to-Chinese lexiconwith 120K entries, while about 64% (274/430) werenot covered by the lexicon.English-to-Chinese Translation: In this experiment,we tried to directly translate the collected 430 Englishterms into traditional Chinese.
Table 1 shows the re-sults in terms of the top 1-5 inclusion rates for thetranslation of the collected English terms.
?
?2?, ?CV?,and ??2+CV?
represent the methods based on the chi-square, context-vector, and chi-square plus context-vector methods, respectively.
Although either thechi-square or context-vector method was effective,the method based on both of them (?2+CV) achievedthe best performance in maximizing the inclusionrates in every case because they looked complemen-tary.
The proposed approach was found to be effec-tive in finding translations of proper names, e.g.personal names ?Jordan?
(??
, ??
), ?KeanuReeves?
(???
?, ????
), companies?
names?TOYOTA?
(??
), ?EPSON?
(???
), and tech-nical terms  ?EDI?
(??????
), ?Ethernet?
(????
), etc.English-to-Chinese Translation for MainlandChina, Taiwan and Hong Kong: Chinese can beclassified into simplified Chinese (SC) and tradi-tional Chinese (TC) based on its writing form orcharacter encoding scheme.
SC is mainly used inmainland China while TC is mainly used in Taiwanand Hong Kong (HK).
In this experiment, we furtherinvestigated the effectiveness of the proposed ap-proach in English-to-Chinese translation for thethree different regions.
The collected 430 Englishterms were classified into five types: people, organi-zation, place, computer and network, and others.Tables 2 and 3 show the statistical results andsome examples, respectively.
In Table 3, the numberstands for a translated term?s ranking.
The under-lined terms were correct translations and the otherswere relevant translations.
These translations mightbenefit the CLIR tasks, whose performance could bereferred to our earlier work which emphasized ontranslating unknown queries (Cheng et al, 2004).
Theresults in Table 2 show that the translations formainland China and HK were not reliable enough inthe top-1, compared with the translations for Taiwan.One possible reason was that the test terms werecollected from Taiwan?s search engine logs.
Most ofthem were popular in Taiwan but not in the others.Only 100 snippets retrieved might not balance or besufficient for translation extraction.
However, theinclusion rates for the three regions were close in thetop-5.
Observing the five types, we could find thattype place containing the names of well-knowncountries and cities achieved the best performance inmaximizing the inclusion rates in every case and al-most had no regional variations (9%, 1/11) exceptTable 4: Inclusion rates of transitive translations of proper names and technical termsType Source LanguageTargetLanguageIntermediateLanguage Top-1 Top-3 Top5Chinese English None 70.0% 84.0% 86.0%English Japanese None 32.0% 56.0% 64.0%English Korean None 34.0% 58.0% 68.0%Chinese Japanese English 26.0% 40.0% 48.0%Scientist NameChinese Korean English 30.0% 42.0% 50.0%Chinese English None 50.0% 74.0% 74.0%English Japanese None 38.0% 48.0% 62.0%English Korean None 30.0% 50.0% 58.0%Chinese Japanese English 32.0% 44.0% 50.0%Disease NameChinese Korean English 24.0% 38.0% 44.0%that the city ?Sydney?
was translated into ??
(Syd-ney) in SC for mainland China and HK and ??
(Sydney) in TC for Taiwan.
Type computer andnetwork containing technical terms had the mostregional variations (41%, 47/115) and type peoplehad 36% (5/14).
In general, the translations in the twotypes were adapted to the use in different regions.
Onthe other hand, 10% (15/147) and 8% (12/143) of thetranslations in types organization and others, respec-tively, had  regional variations, because most of theterms in type others were general terms such as?bank?
and ?movies?
and in type organization manylocal companies in Taiwan had no translation varia-tions in mainland China and HK.Moreover, many translations in the types of peo-ple, organization, and computer and network werequite different in Taiwan and mainland China suchas the personal name ?Bred Pitt?
was translated into?????
in SC and ???????
in TC, the com-pany name ?Ericsson?
into ?????
in SC and ?????
in  TC, and the computer-related term ?EDI?into ????????
in SC and ????????
inTC.
In general, the translations in HK had a higherchance to cover both of the translations in mainlandChina and Taiwan.5.2 Multilingual & Transitive TranslationTable 1: Inclusion rates for Web query terms using various similarity measurementsDic OOV All Method Top-1 Top-3 Top-5 Top-1 Top-3 Top-5 Top-1 Top-3 Top-5?2 42.1% 57.9% 62.1% 40.2% 53.8% 56.2% 41.4% 56.3% 59.8%CV 51.7% 59.8% 62.5% 45.0% 55.6% 57.4% 49.1% 58.1% 60.5%?2+ CV 52.5% 60.4% 63.1% 46.1% 56.2% 58.0% 50.7% 58.8% 61.4%Table 2: Inclusion rates for different types of Web query termsExtracted TranslationsTaiwan (Big5) Mainland China (GB) Hong Kong (Big5) TypeTop-1 Top-3 Top-5 Top-1 Top-3 Top-5 Top-1 Top-3 Top-5People (14) 57.1% 64.3% 64.3% 35.7% 57.1% 64.3% 21.4% 57.1% 57.1%Organization (147) 44.9% 55.1% 56.5% 47.6% 58.5% 62.6% 37.4% 46.3% 53.1%Place (11) 90.9% 90.9% 90.9% 63.6% 100.0% 100.0% 81.8%   81.8% 81.8%Computer & Network (115) 55.8% 59.3% 63.7% 32.7% 59.3% 64.6% 42.5% 65.5% 68.1%Others (143) 49.0%  58.7% 62.2% 30.8% 49.7% 58.7% 28.7% 50.3% 60.8%Total (430) 50.7% 58.8% 61.4% 38.1% 56.7% 62.8% 36.5% 54.0% 60.5%Table 3: Examples of extracted correct/relevant translations of English terms in three Chinese regionsExtracted Correct or Relevant Target Translations English TermsTaiwan (Traditional Chinese) Mainland China (Simplified Chinese) Hong Kong (Traditional Chinese)Police ??
(1) ???
(2) ???
(4) ??
(1) ??
(2) ??
(4) ???
(1) ??
(3) ??
(5)Taxi ???
(1) ??
(3) ???
(1) ??
(4) ??
(1) ????
(2) ???
(15)Laser ??
(1) ????
(3) ???
(4) ??
(1) ??
(2) ???
(3) ??
(4) ??
(1) ??
(2) ???
(3) ??
(4)Hacker ??
(1) ??
(2) ??
(7) ??
(1)  ????
(5) ???
(6) ??
(1) ??
(2) ???
(9)Database ???
(1) ?????
(3)  ???
(1) ?????
(9) ???
(1) ???
(3) ??
(5)Information ??
(1) ??
(3) ???
(4) ??
(1) ???
(3) ??
(7) ??
(1) ??
(6)Internet caf?
????
(3) ??
(4) ??
(5) ????
(1) ?????
(2) ??
(6) ??
(1) ??
(3) ??
(4)Search Engine ???
(2) ????
(5) ??????
(1) ????
(3) ???
(1)  ???
(8)Digital Camera ??
(1) ????
(2) ????
(1) ????
(6) ??
(1) ????
(2) ??
(3)Data set: Since technical terms had the most regionvariations among the five types as mentioned in theprevious subsection, we collected two other data setsfor examining the performance of the proposed ap-proach in multilingual and transitive translation.
Thedata sets contained 50 scientists?
names and 50 dis-ease names in English, which were randomly se-lected from 256 scientists (Science/People) and 664diseases (Health/Diseases) in the Yahoo!
Directory(http://www.yahoo.com), respectively.English-to-Japanese/Korean Translation: In thisexperiment, the collected scientists?
and diseasenames in English were translated into Japanese andKorean to examine if the proposed approach couldbe applicable to other Asian languages.
As the resultin Table 4 shows, for the English-to-Japanese trans-lation, the top-1, top-3, and top-5 inclusion rateswere 35%, 52%, and 63%, respectively; for the Eng-lish-to-Korean translation, the top-1, top-3, and top-5 inclusion rates were 32%, 54%, and 63%, respec-tively, on average.Chinese-to-Japanese/Korean Translation viaEnglish: To further investigate if the proposed tran-sitive approach can be applicable to other languagepairs that are not frequently mixed in documentssuch as Chinese and Japanese (or Korean), we didtransitive translation via English.
In this experiment,we first manually translated the collected data sets inEnglish into traditional Chinese and then did theChinese-to-Japanese/Korean translation via the thirdlanguage English.The results in Table 4 show that the propagationof translation errors reduced the translation accuracy.For example, the inclusion rates of the Chinese-to-Japanese translation were lower than those of theEnglish-to-Japanese translation since only 70%-86%inclusion rates were reached in the Chinese-to-English translation in the top 1-5.
Although transi-tive translation might produce more noisy transla-tions, it still produced acceptable translationcandidates for human verification.
In Table 4, 45%-50% of the extracted top 5 Japanese or Korean termsmight have correct translations.6 ConclusionIt is important that the translation of a term can beautomatically adapted to its usage in different dialec-tal regions.
We have proposed a Web-based transla-tion approach that takes into account limitedbilingual search-result pages from real search en-gines as comparable corpora.
The experimental re-sults have shown the feasibility of the automaticapproach in generation of effective translationequivalents of various terms and construction ofmultilingual translation lexicons that reflect regionaltranslation variations.ReferencesL.
Borin.
2000.
You?ll take the high road and I?ll take thelow road: using a third language to improve bilingualword alignment.
In Proc.
of COLING-2000, pp.
97-103.P.
F. Brown, J. Cocke, S. A. D. Pietra, V. J. D. Pietra, F.Jelinek, J. D. Lafferty, R. L. Mercer, and P. S. Roossin.1990.
A statistical approach to machine translation.Computational Linguistics, 16(2):79-85.Y.-B.
Cao and H. Li.
2002.
Base noun phrase translationusing Web data the EM algorithm.
In Proc.
ofCOLING-2002, pp.
127-133.P.-J.
Cheng, J.-W. Teng, R.-C. Chen, J.-H. Wang, W.-H.Lu, and L.-F. Chien.
2004.
Translating unknown que-ries with Web corpora for cross-language informationretrieval.
In Proc.
of ACM SIGIR-2004.P.
Fung and L. Y. Yee.
1998.
An IR approach for translat-ing new words from nonparallel, comparable texts.
InProc.
of ACL-98, pp.
414-420.T.
Gollins and M. Sanderson.
2001.
Improving cross lan-guage information with triangulated translation.
InProc.
of ACM SIGIR-2001, pp.
90-95.J.
Halpern.
2000.
Lexicon-based orthographic disam-biguation in CJK intelligent information retrieval.
InProc.
of Workshop on Asian Language Resources andInternational Standardization.A.
Kilgarriff and G. Grefenstette.
2003.
Introduction tothe special issue on the web as corpus.
ComputationalLinguistics 29(3): 333-348.J.
M. Kupiec.
1993.
An algorithm for finding noun phrasecorrespondences in bilingual corpora.
In Proc.
of ACL-93, pp.
17-22.W.-H. Lu, L.-F. Chien, and H.-J.
Lee.
2004.
Anchor textmining for translation of web queries: a transitive trans-lation Approach.
ACM TOIS 22(2): 242-269.W.-H. Lu, L.-F. Chien, and H.-J.
Lee.
2002.
Translationof Web queries using anchor text mining.
ACM TALIP:159-172.I.
D. Melamed.
2000.
Models of translational equivalenceamong words.
Computational Linguistics, 26(2): 221-249.J.-Y.
Nie, P. Isabelle, M. Simard, and R. Durand.
1999.Cross-language information retrieval based on paralleltexts and automatic mining of parallel texts from theWeb.
In Proc.
of ACM SIGIR-99, pp.
74-81.R.
Rapp.
1999.
Automatic identification of word transla-tions from unrelated English and German corpora, InProc.
of ACL-99, pp.
519-526.P.
Resnik.
1999.
Mining the Web for bilingual text.
InProc.
of ACL-99, pp.
527-534.M.
Simard.
2000.
Multilingual Text Alignment.
In ?Paral-lel Text Processing?, J. Veronis, ed., pages 49-67,Kluwer Academic Publishers, Netherlands.F.
Smadja, K. McKeown, and V. Hatzivassiloglou.
1996.Translating collocations for bilingual lexicons: a statis-tical approach.
Computational Linguistics, 22(1): 1-38.B.
K. Tsou, T. B. Y. Lai, and K. Chow.
2004.
Comparingentropies within the Chinese language.
In Proc.
ofIJCNLP-2004.C.
C. Yang and K.-W. Li.
2003.
Automatic constructionof English/Chinese parallel corpora.
JASIST 54(8):730-742.
