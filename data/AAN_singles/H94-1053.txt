STATISTICAL LANGUAGE PROCESSING USINGHIDDEN UNDERSTANDING MODELSScott MillerCollege o f  Computer ScienceNortheastern UniversityBoston, MA 02115Richard SchwartzBBN Systems and Technologies70 Fawcett St.,Cambridge, MA 02138Robert BobrowBBN Systems and Technologies70 Fawcett St.,Cambridge, MA 02138Robert IngriaBBN Systems and Technologies70 Fawcett St.,Cambridge, MA 02138ABSTRACTThis paper introduces a class of statistical mechanisms, calledhidden understanding models, for natural anguage processing.Much of the framework for hidden understanding models derivesfrom statistical models used in speech recognition, especially theuse of hidden Markov models.
These techniques are applied tothe central problem of determining meaning directly from asequence of spoken or written words.
We present an overalldescription of the hidden understanding methodology, anddiscuss some of the critical implementation issues.
Finally, wereport on experimental results, including results of theDecember 1993 AR.PA evaluation.1 INTRODUCTIONHidden understanding models are an innovative application ofstatistical mechanisms that, given a string of words, determinesthe most likely meaning for the string.
The overall approachrepresents a substantial departure from traditional approaches byreplacing hand-crafted grammars and rules with statisticalmodels that are automatically learned from examples.Advantages of tiffs approach include potential improvements inboth robustness and portability of natural language systems.Hidden understanding models were motivated by techniques thathave been extremely successful in speech recognition, especiallyhidden Markov Models \[Baum, 72\].
Related techniques havepreviously been applied to the problem of segmenting a sentenceinto a sequence of concept relations \[Pieraccini et aL, 91\].However, because of differences between languageunderstanding and speech recognition, significant changes arerequired in the speech recognition methodology.
Unlike speech,where each phoneme results in a local sequence of spectra, therelation between the meaning of a sentence and the sequence ofwords is not a simple linear sequential model.
Language isinherently nested, with subgroups of concepts within otherconcepts.A statistical system for understanding language must take thisand other differences into account in its overall design.
Inprinciple, we have the following requirements for a hiddenunderstanding system:A notational system for expressing meanings.A statistical model that is capable of representing meaningsand the association between meanings and words.An automatic training program which, given pairs ofmeanings and word sequences, can estimate the parametersof a statistical model.An understanding program that can search the statisticalmodel to fred the most likely meaning given a wordsequence."
J  training \ [ /  m eanin$ sentences 1"- program ~ expressions4,I "  program I I "  expressmnsJFigure 1: The main components ofa hidden understandingsystem.Below, we describe solutions for each of these requirements, andreport on initial experiments with hidden understanding models.-2 EXPRESSING MEANINGSOne of the key requirements for a hidden understanding modelis that the meaning representation must be both expressive andappropriate for automatic learning techniques.
Logicalnotations, such as the predicate calculus, are generallyconsidered to possess sufficient expressive power.
Thedifficulty lies in finding a meaning representation that can be278readily aligned to the words of a sentence, and for which there isa tractable probability model for meanings.
To satisfy theserequirements, we have developed a family of representationswhich we call tree structured meaning representations.2.1 TREE STRUCTURED MEANINGREPRESENTAT IONSThe central characteristic of a tree structured representation isthat individual concepts appear as nodes in a tree, withcomponent concepts appearing as nodes attached irectly belowthem.
For example, the concept of aflight in the ATIS domainhas component concepts including airline,flight number, origin,and destination.
These could then form part of therepresentation for the phrase: United flight 203 from Dallas toAtlanta.
We require that the order of the component conceptsmust match the order of the words they correspond to.
Thus, therepresentation f the phrase flight 203 to Atlanta from Dallas onUnited includes the same nodes as the earlier example, but in adifferent order.
For both examples, the interpretation isidentical.
More formally, the meaning of a tree structuredrepresentation is invariant with respect o the left-to-fight orderof the component concept nodes.At the leaves of a meaning tree are the words of the sentence.We distinguish between odes that appear above other nodes,and those that appear directly above the words.
These will bereferred to as nonterminal nodes and terminal nodesrespectively, forming two disjoint sets.
No node has both wordsand other nodes appearing directly below it.
In the currentexample, aflight node represents he abstract concept of a flight,which is a structured entity that may contain an origin, adestination, and other component concepts.
Appearing directlyabove the word "flight" is a terminal node, which we call afight indicator.
This name is chosen to distinguish it from theflight node, and also because the word "flight," in some sense,indicates the presence of a flight concept.
Similarly, there areairline indicators, origin indicators, and destination i dicators?These nodes can be thought of as elements in a specializedsublanguage for expressing meaning in the ATIS domain.3 THE STAT IST ICAL  MODELOne central characteristic of hidden understanding models isthat they are generative.
From this viewpoint, language isproduced by a two component statistical process.
The firstcomponent chooses the meaning to be expressed, effectivelydeciding "what to say".
The second component selects wordsequences to express that meaning, effectively deciding "how tosay it".
The first phase is referred to as the semantic languagemodel, and can be thought of as a stochastic process thatproduces meaning expressions elected from a universe ofmeanings.
The second phase is referred to as the lexicalrealization model, and can be thought of as a stochastic processthat generates words once a meaning is given.abstracts~'ucau'cs sequencesFigure 3: Language as a generative process.By analogy with hidden Markov models, we refer to thecombination of these two models as a hidden understandingmodel.
The word hidden refers to the fact that only words canbe observed.
The internal states of each of the two models areunseen and must be inferred from the words.
The problem oflanguage understanding, then, is to recover the most likelymeaning structure given a sequence of words.
More formally,understanding a word sequence W is accomplished by searchingamong all possible meanings for some meaning M such thatP(MIW) is maximized.
By Bayes Rule, P(MIW) can berewritten as:) nonterminal nodesFigure 2: An example of a tree structure meaining representation.279P( MIW) = P(WIM)P( M)P(W)Now, since P(W) does not depend on M, maximizing P(MIW)is equivalent to maximizing the product P(W1M) P( M).However, P(W1M) is simply our !exical realization model, andP(M) is simply our semantic language model.
Thus, bysearching a combination of these models it is possible to fred themost likely meaning M given word sequence W.3.1 Semantic Language ModelFor tree structured meaning representations, individualnontenninal nodes determine particular abstract semanticconcepts.
In the semantic language model, each abstract conceptcorresponds toa probabilistic state transition etwork.
All suchnetworks are then combined into a single probabilistic recursivetransition etwork, forming the entire semantic language model.The network corresponding to a particular abstract conceptconsists of states for each of its component concepts, togetherwith two extra states that define the entry and exit points.
Everycomponent concept is fully connected to every other componentconcept, with additional paths leading from the entry state toeach component concept, and from each component concept othe exit state.
Figure 4 shows a sample network correspondingto the flight concept.
Of course, there are many more flightcomponent concepts in the ATIS domain than actually appear inthis example.Associated with each arc is a probability value, in a similarfashion to the TINA system \[Seneff, 92\].
These probabilitieshave the form P(State,,IStaten_l,Context), which is theprobability of taking a transition from one state to another withina particular context.
Thus, the arc from origin to dest hasprobability P(dest Iorigin,flight), meaning the probability ofentering dest from origin within the context of the flightnetwork.
Presumably, this probability is relatively high, sincepeople usually mention the destination of a flight directly aftermentioning its origin.
Conversely, P(origin I dest,flight) isprobably low because people don't usually express concepts inthat order.
Thus, while all paths through the state space arepossible, some have much higher probabilities than others.Within a concept network, component concept states exist forboth nonterminal concepts, such as origin, as well as terminalconcepts, such as flight indicator.
Arrows pointing intononterminal states indicate entries into other networks, whilearrows pointing away indicate exits out of those networks.Terminal states correspond to networks as well, although theseare determined by the lexical realization model and have adifferent internal structure.
Thus, every meaning tree directlycorresponds directly to some particular path through the statespace.
Figure 5 shows a meaning tree and its correspondingpath through the state space.3.2 Lexical Realization ModelJust as nonterminal tree nodes correspond to networks in thesemantic language model, terminal nodes correspond tonetworks in the lexical realization model.
The difference is thatsemantic language networks specify transition probabilitiesbetween states, while lexical realization networks specifytransition probabilities between words.
Lexical realizationenterFigure 4: A partial network corresponding totheflight concept.280probabilities have the form P( word n l wordn_ l ,context ) , whichis the probability of taking a transition from one word to anothergiven a particular context.
Thus,P(showlplease, show-indicator ) is the probability that theword show follows the word please within the context of a showindicator phrase.
In addition, there are two pseudo-words,*begin* and *end*, which indicate the beginning and ending ofphrases.
Thus, we have probabilities such asP(please\[*begin*,show-indicator ), which is the probabilitythat please is the first word of a show indicator phrase, andP(*end*lme, show-indicator ), which is the probability ofexiting a show indicator phrase given that the previous wordwas me.4 THE UNDERSTANDING COMPONENTAs we have seen, understanding a word string W requiresfinding a meaning M such that the probability P(W\]M) P (M)  ismaximized.
Since, the semantic language model and the lexicalrealization model are both probabilistic networks,P(WJM) P(M)  is the probability of a particular path throughthe combined network.
Thus, the problem of understanding is tofred the highest probability path among all possible paths, wherethe probability of a path is the product of all the transitionprobabilities along that path.r r  \[ P (  state.lstaten_ l,context) if  t in Semantic Language Model\]P(rat~)=,l~hLP(word, lword,_t,context) .
.
.
.
if t in Lexieal Realization ModelJ /Thus far, we have discussed the need to search among allmeanings for one with a maximal probability.
In fact, if it werenecessary to search every path through the combined networkindividually, the algorithm would require exponential time withrespect o sentence length.
Fortunately, this can be drasticallyreduced by combining the probability computation of commonsubpaths through dynamic programming.
In particular, becauseour meaning representation aligns to the words, the search canbe efficiently performed using the well-known Viterbi \[Viterbi,67\] algorithm.Since our underlying model is a recursive transition etwork, thestates for the Viterbi search must be allocated ynamically as thesearch proceeds.
In addition, it is necessary to prune very lowprobability paths in order to keep the computation tractable.
Wehave developed an elegant algorithm that integrates stateallocation, Viterbi search, and pruning all within a singletraversal of a tree-like data structure.5 THE TRAINING COMPONENTIn order to train the statistical model, we must estimatetransition probabilities for the semantic language model andlexical realization model.
In the ease of fully specified meaningtrees, each meaning tree can be straightforwardly converted intoa path through state space.
Then, by counting occurrence andtransition frequencies along those paths, it is possible to fonnsimple estimates of the transition probabilities.
LetC(statem,contexts) denote the number of times state m hasoccurred in contexts, and let C(statenlstatem,contexts)denotethe number of times that this condition has led to a transition tostate state n. Similarly, define counts C(wordm,contextt) andC(wordnlwordm,contextt).
Then, a direct estimate of theprobabilities i given by:andJb (state n lstate re,context) C( statenlstatem ,c?ntext ) ,C ( state m ,context )A C(word word context)P(wordnlwordm,context) = n m' .C( word m , context )show flight " ~ .Show flights to AtlantaFigure 5: A meaning tree and its corresponding path through state space.281In order to obtain robust estimates, these simple estimates aresmoothed with backed-off estimates \[Good, 53\], usingtechniques similar to those used in speech recognition \[Katz, 87;Placeway et al, 93\] .
Thus, P(statenlstatem,context ) issmoothed with 1~( statenJ,context ), and P( wordnJ word re,context )is smoothed with 15(wordnlcontext).
Robustness is furtherincreased through word classes.
For example, Boston and SanFrancisco are both members of the class of cities.6 EXPERIMENTAL  RESULTSWe haw: implemented a hidden understanding system andperformed a variety of experiments.
In addition, we participatedin the 1993 ARPA ATIS NL evaluation.One experiment involved a 1000 sentence ATIS corpus,annotated according to a simple specialized sublanguage model.To annotate the training data, we used a bootstrapping process inwhich only the first 100 sentences were annotated strictly byhand.
Thereafter, we worked in cycles of:1.
Running the training program using all available annotateddata.2.
Running the understanding component to annotate newsentences.3.
Hand correcting the new annotations.Annotating in this way, we found that a single annotator couldproduce 200 sentences per day.
We then extracted the first 100sentences as a test set, and trained the system on the remaining900 sentences.
The results were as follows:?
61% matched exactly.?
21% had correct meanings, but did not match exactly.?
28% had the wrong meaning.Another experiment involved a 6000 sentence ATIS corpus,annotated according to a more sophisticated meaning model.
Inthis experiment, the Delphi system automatically produced theannotation by printing out its own internal representation foreach sentence, converted into a more readable form.
We thenremoved 300 sentences as a test set, and trained the system onthe remaining 5700.
The results were as follows:?
85% matched exactly.?
8% had correct meanings, but did not match exactly.?
7% had the wrong meaning.For the ARPA evaluation, we coupled our hidden understandingsystem to the discourse and backend components of the Delphisystem.
Using the entire 6000 sentence corpus described aboveas training data, the system produced a score of 23% simpleerror on the ATIS NL evaluation.
By examining the errors, wehave reached the conclusion that nearly half are due to simpleprogramming issues, especially in the interface between Delphiand the hidden understanding system.
In fact, the interface wasstill incomplete at the time of the evaluation.ACKNOWLEDGEMENTSThe work reported here was supported in part by the DefenseAdvanced Research Projects Agency under ARPA Contract No.N00014-92-C-0035.
The views and conclusions contained inthis document are those of the authors and should not beinterpreted as necessarily representing the official policies,either expressed or implied, of the Defense Advanced ResearChProjects Agency or the United States Government.2.REFERENCESL.
E. Baum, "An Inequality and AssociatedMaximization Technique in Statistical Estimation ofProbabilistic Functions of Markov Processes,"Inequalities 3:1-8, 1972I.J.
Good, "The Population Frequencies of Species andthe Estimation of Population Parameters," Biometrika40, pp.237-264, 19533.
S.M.
Katz, "Estimation of Probabilities from SparseData for the Language Model Component of a SpeechRecognizer," IEEE Transactions on Acoustics, Speech,and Signal Processing, Vol.
ASSP-35, pp.
400..401, 19874.
S. Seneff, "TINA, A Natural Language System forSpoken Language Applications," ComputationalLinguistics, Vol.
18, Number 1, pp.
61-86, March 19925.
R. Pieraccini, E. Levin, C.H.
Lee, "StochasticRepresentation of Conceptual Structure in the ATISTask," Proceedings of the Speech and Natural LanguageWorkshop, pp.
121-124, Morgan Kaufmann Publishers,Feb.
19916.7.P.
Placeway, R. Schwartz, P. Fung, L. Nguyen, "TheEstimation of Powerful Language Models from Smalland Large Corpora," IEEE ICASSP, 1I:33-36A.
J. Viterbi, "Error Bounds for Convolutional Codesand an Asympotically Optimum Decoding Algorithm,"IEEE Transactions on Information Theory IT-13(2):260-269, April 1967282
