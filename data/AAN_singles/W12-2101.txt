Proceedings of the 2012 Workshop on Language in Social Media (LSM 2012), pages 1?8,Montre?al, Canada, June 7, 2012. c?2012 Association for Computational LinguisticsAnalyzing Urdu Social Media for Sentiments using Transfer Learningwith Controlled TranslationsAuthor 2Smruthi Mukund Rohini K SrihariCEDAR, Davis Hall, Suite 113 CEDAR, Davis Hall, Suite 113University at Buffalo, SUNY, Buffalo, NY University at Buffalo, SUNY, Buffalo, NYsmukund@buffalo.edu rohini@cedar.buffalo.eduAbstractThe main aim of this work is to perform sen-timent analysis on Urdu blog data.
We use themethod of structural correspondence learning(SCL) to transfer sentiment analysis learningfrom Urdu newswire data to Urdu blog data.The pivots needed to transfer learning fromnewswire domain to blog domain is not trivialas Urdu blog data, unlike newswire data iswritten in Latin script and exhibits code-mixing and code-switching behavior.
We con-sider two oracles to generate the pivots.
1.Transliteration oracle, to accommodate scriptvariation and spelling variation and 2.
Trans-lation oracle, to accommodate code-switchingand code-mixing behavior.
In order to identi-fy strong candidates for translation, we pro-pose a novel part-of-speech tagging methodthat helps select words based on POS catego-ries that strongly reflect code-mixing behav-ior.
We validate our approach against asupervised learning method and show that theperformance of our proposed approach iscomparable.1 IntroductionThe ability to break language barriers and under-stand people's feelings and emotions towards soci-etal issues can assist in bridging the gulf that existstoday.
Often emotions are captured in blogs or dis-cussion forums where writers are common peopleempathizing with the situations they describe.
Asan example, the incident where a cricket team vis-iting Pakistan was attacked caused widespread an-guish among the youth in that country who thoughtthat they will no longer be able to host internation-al tournaments.
The angry emotion was towardsthe failure of the government to provide adequateprotection for citizens and visitors.
Discussion fo-rums and blogs on cricket, mainly written by Paki-stani cricket fans, around the time, verbalized thisemotion.
Clearly analyzing blog data helps to esti-mate emotion responses to domestic situations thatare common to many societies.Traditional approaches to sentiment analysis re-quire access to annotated data.
But facilitating suchdata is laborious, time consuming and most im-portantly fail to scale to new domains and capturepeculiarities that blog data exhibits; 1. spelling var-iations and 2. code mixing and code switching.
3.script difference (Nastaliq vs Latin script).
In thiswork, we present a new approach to polarity classi-fication of code-mixed data that builds on a theorycalled structural correspondence learning (SCL)for domain adaptation.
This approach uses labeledpolarity data from the base language (in this case,Urdu newswire data - source) along with two sim-ple oracles that provide one-one mapping betweenthe source and the target data set (Urdu blog data).Subsequent sections are organized as follows.Section 2 describes the issues seen in Urdu blogdata followed by section 3 that explains the con-cept of structural correspondence learning.
Section4 details the code mixing and code switching be-havior seen in blog data.
Section 5 describes thestatistical part of speech (POS) tagger developedfor blog data required to identify mixing patternsfollowed by the sentiment analysis model in sec-tion 6.
We conclude with section 7 and briefly out-line analysis and future work in section 8.12 Urdu Blog DataThough non-topical text analysis like emotion de-tection and sentiment analysis, have been exploredmostly in the English language, they have alsogained some exposure in non-English languageslike Urdu (Mukund and Srihari, 2010), Arabic(Mageed et al, 2011) and Hindi (Joshi andBhattacharya, 2012).
Urdu newswire data is writ-ten using Nastaliq script and follows a relativelystrict grammatical guideline.
Many of the tech-niques proposed either depend heavily on NLPfeatures or annotated data.
But, data in blogs anddiscussion forums especially written in a languagelike Urdu cannot be analyzed by using modulesdeveloped for Nastaliq script for the following rea-sons; (1) the tone of the text in blogs and discus-sion forums is informal and hence differs in thegrammatical structure (2) the text is written usingLatin script (3) the text exhibits code mixing andcode switching behavior (with English) (4) thereexists spelling errors which occur mostly due to thelack of predefined standards to represent Urdu datain Latin script.Urdish (Urdu blog data) is the term used forUrdu, which is (1) written either in Nastaliq or Lat-in script, and (2) contains several Englishwords/phrases/sentences.
In other words, Urdish isa name given to a language that has Urdu as thebase language and English as the seasoning lan-guage.
With the wide spread use of English key-boards these days, using Latin script to encodeUrdu is very common.
Data in Urdish is never inpure Urdu.
English words and phrases are com-monly used in the flow integrating tightly with thebase language.
Table 1 shows examples of differ-ent flavors in which Urdu appears in the internet.Differ-entFormsof DataMain Issues Example Sentence1.
Urduwrittenin Nasta-liq1.
Lack of tools forbasic operations suchas segmentation anddiacritic restoration2.
Lack of sufficientannotated data forPOS and NE tagging3.
Lack of annotateddata for more ad-vanced NLP???
??????
??
?????????
??
???
????
[ The soldiers wereangry with a lot ofpeople]2.
Urduwrittenin ASCII1.
Several variationsin spellings that needto be normalizedWo Mulk Jisko Humnay 1000000 logoonsey zayada Loogoon(Eng-lish)2.
No normalizationstandards3.
Preprocessingmodules needed iftools for Urdu inNastaliq are to beused4.
Developing acompletely new NLPframework needsannotated dataki Qurbanian dey kerhasil kia usi mulkmain yai kaisa waqt agay hai ?
[Look at what kind oftime the land that had1000000?s of peoplesacrifice their lives isexperiencing now]3.
Urd-ish writ-ten inNastaliq1.
No combinedparser that deals withEnglish and Urdusimultaneously2.
English is writtenin Urdu but withmissing diacritics??
???
???
?????
??
?????
???
???
[the phones rang oneafter the other in theTV station]4.
Urd-ish writ-ten inASCII(English)1.
No combinedparser that dealswith English andUrdu simultaneous-ly2.
Issue of spellingvariations that needto be normalizedAfsoos key baat hai .kal tak jo batainNon Muslim bhikartay hoay dartaythay abhi this manhas brought it out inthe open.
[It is sad to see thatthose words that evena non muslim wouldfear to utter till yes-terday, this man hadbrought it out in theopen]Table 1: Different forms of using Urdu lan-guage on the internetBlog data follows the order shown in example4 of table 1.
Such a code-switching phenomenon isvery common in multilingual societies that havesignificant exposure to English.
Other languagesexhibiting similar behaviors are Hinglish (Hindiand English), Arabic with English and Spanglish(Spanish with English).3   Structural Correspondence LearningFor a problem where domain and data changesrequires new training and learning, resorting toclassical approaches that need annotated data be-comes expensive.
The need for domain adaptationarises in many NLP tasks ?
part of speech tagging,semantic role labeling, dependency parsing, andsentiment analysis and has gained high visibility inthe recent years (Daume III and Marcu, 2006;Daume III et al, 2007; Blitzer et al, 2006, Pret-tenhofer and Stein et al, 2010).
There exists twomain approaches; supervised and semi-supervised.2In the supervised domain adaptation approachalong with labeled source data, there is also accessto a small amount of labeled target data.
Tech-niques proposed by Gildea (2001), Roark and Bac-chiani (2003), Daume III (2007) are based on thesupervised approach.
Studies have shown thatbaseline approaches (based on source only, targetonly or union of data) for supervised domain adap-tion work reasonably well and beating this is sur-prisingly difficult (Daume III, 2007).In contract, the semi supervised domain adapta-tion approach has access to labeled data only in thesource domain (Blitzer et al, 2006; Dredze et al,2007; Prettenhofer and Stein et al, 2010).
Sincethere is no access to labeled target data, achievingbaseline performance exhibited in the supervisedapproach requires innovative thinking.The method of structural correspondence learn-ing (SCL) is related to the structural learning para-digm introduced by Ando and Zhang (2005).
Thebasic idea of structural learning is to constrain thehypothesis space of a learning task by consideringmultiple different but related tasks on the sameinput space.
SCL was first proposed by Blitzer etal., (2006) for the semi supervised domain adapta-tion problem and works as follows (Shimizu andNakagawa, 2007).1.
A set of pivot features are defined on unla-beled data from both the source domain andthe target domain2.
These pivot features are used to learn a map-ping from the original feature spaces of bothdomains to a shared, low-dimensional real?valued feature space.
A high inner product inthis new space indicates a high degree of cor-respondence along that feature dimension3.
Both the transformed and the original featuresin the source domain are used to train a learn-ing model4.
The effectiveness of the classifier in the sourcedomain transfers to the target domain based onthe mapping learntThis approach of SCL was applied in the field ofcross language sentiment classification scenario byPrettenhofer and Stein (2010) where English wasused as the source language and German, Frenchand Japanese as target languages.
Their approachinduces correspondence among the words fromboth languages by means of a small number ofpivot pairs that are words that process similar se-mantics in both the source and the target lan-guages.
The correlation between the pivots is mod-eled by a linear classifier and used as a languageindependent predictor for the two equivalent clas-ses.
This approach solves the classification prob-lem directly, instead of resorting to a more generaland potentially much harder problem such as ma-chine translation.The problem of sentiment classification in blogdata can be considered as falling in the realm ofdomain adaptation.
In this work, we approach thisproblem using SCL tailored to accommodate thechallenges that code-mixed data exhibits.
Similarto the work done by Prettenhofer and Stein (2010),we look at generating pivot pairs that capture code-mixing and code-switching behavior and languagechange.4 Code Switching and Code MixingCode switching refers to the switch that exists fromone language to another and typically involves theuse of longer phrases or clauses of another lan-guage while conversing in a totally different baselanguage.
Code mixing, on the other hand, is aphenomenon of mixing words and other smallerunits of one language into the structure of anotherlanguage.
This is mostly inter-sentential.In a society that is bilingual such as that in Pa-kistan and India, the use of English in the nativelanguage suggests power, social prestige and thestatus.
The younger crowd that is technologicallywell equipped tends to use the switching phenom-enon in their language, be it spoken or written.Several blogs, discussion forums, chat rooms etc.hold information that is expressed is intensely codemixed.
Urdu blog data exhibits mix of Urdu lan-guage with English.There are several challenges associated withdeveloping NLP systems for code-switched lan-guages.
Work done by Kumar (1986) and Sinha &Thakur, (2005) address issues and challenges asso-ciated with Hinglish (Hindi ?
English) data.Dussias (2003) and Celia (1997) give an overviewof the behavior of code switching occurring inSpanish - Spanglish.
This phenomenon can be seenin other languages like Kannada and English,German and English.
Rasul (2006) analyzes thelinguistic patterns occurring in Urdish (Urdu andEnglish) language.
He tries to quantize the extentto which code-mixing occurs in media data, in par-ticular television.
Most of his rules are based on3what is proposed by Kachru (1978) for Hinglishand has a pure linguistic approach with manualintervention for both qualitative and quantitativeanalysis.Several automated techniques proposed forHinglish and Spanglish are in the context of ma-chine translation and may not be relevant for a tasklike information retrieval since converting the datato one standardized form is not required.
A morerecent work was by Goyal et al, (2003) where theydeveloped a bilingual parser for Hindi and Englishby treating the code mixed language as a complete-ly different variety.
However, the credibility of thesystem depends on the availability of WordNet1.4.1 Understanding Mixing PatternsPerforming analysis on data that exhibit code-switching has been attempted by many across vari-ous languages.
Since the Urdu language is verysimilar to Hindi, in this section we discuss thecode-mixing behavior based on a whole battery ofwork done by researchers in the Hindi language.Researchers have studied the behavior of themixed patterns and generated rules and constraintson code-mixing.
The study of code mixing withHindi as the base language is attempted by Sinhaand Thakur (2005) in the context of machine trans-lation.
They categorize the phenomenon into twotypes based on the extent to which mixing happensin text in the context of the main verb.
Linguistssuch as Kachru (1996) and Poplack (1980) havetried to formalize the terminologies used in thiskind of behavior.
Kumar (1986) says that the moti-vation for assuming that the switching occursbased on certain set of rules and constraints arebased on the fact that users who use this can effec-tively communicate with each other despite themixed language.
In his paper he proposes a set ofrules and constraints for Hindi-English codeswitching.
However, these rules and constraintshave been countered by examples proposed in theliterature (Agnihotri, 1998).
This does not meanthat researchers earlier had not considered all thepossibilities.
It only means that like any other lan-guage, the language of code-mixing is evolvingover time but at a very fast pace.One way to address this problem of code-mixingand code switching for our task of sentiment analy-1 http://www.cfilt.iitb.ac.in/wordnet/webhwn/sis in blog data is rely on predefined rules to identi-fy mixed words.
But this can get laborious and therules may be insufficient to capture the latest be-havior.
Our approach is to use a statistical POSmodel to determine part of speech categories ofwords that typically undergo such switches.5 Statistical Part of Speech TaggerExample 5.1 showcases a typical sentence seen inblog data.
Example 5.2 shows the issue withspelling variations sometimes that occur in thesame sentenceExample 5.1: Otherwise humara bhi wohi haal hoga jois time Palestine, Iraq, Afghanistan wagera ka hai ~Otherwise our state will also be like what is in Pales-tine, Iraq, Afghanistan etc.
are experiencing at this timeExample 5.2: Shariyat ke aitebaar se bhi ghaur kia jaeytu aap ko ilm ho jaega key joh haraam khata hai uskadil kis tarhan ka hota hey ~ If you look at it from moralspoint of you too you will understand the heart of peoplewho cheatA statistical POS tagger for blog data has to takeinto consideration spelling variations, mixing pat-terns and script change.
The goal here is not togenerate a perfect POS tagger for blog data(though the idea explained here can be extendedfor further improvisation) but to be able to identifyPOS categories that are candidates for switch andmix.
The basic idea of our approach is as follows1.
Train Latin script POS tagger (LS tagger) onpure Urdu Latin script data (Example 2 in table1 ?
using Urdu POS tag set, Muaz et al, 2009)2.
Train English POS tagger on English data(based on English tag sets, Santorini, 1990)3.
Apply LS tagger and English tagger on Urdishdata and note the confidence measures of theapplied tags on each word4.
Use confidence measures, LS tags, phonemecodes (to accommodate spelling variations) asfeatures to train a new learning model on Urd-ish data5.
Those words that get tagged with the Englishtagset are potential place holders for mixingpatternsWord Act Eng LSUrduUrdCMEngCMand CC CC NN 0.29 0.99most RB RB VM 0.16 0.83im-portantJJ JJ VAUX 0.08 0.97thing NN NN CC 0.06 0.914Zardari NNP NNP NN 0.69 0.18ko PSP NNP PSP 0.99 0.28shoot VB NNP JJ 0.54 0.29ker NN NNP NN 0.73 0.29dena VM NNP VM 0.83 0.29chahiya VAUX NNP VAUX 0.98 0.21.
SYM .
SYM 0.99 0.99Table 2.
POS tagger with confidence measuresThe training data needed to develop LS tagger forUrdu is obtained from Hindi.
IIIT POS annotatedcorpus for Hindi contains data in the SSF format(Shakti Standard Format) (Bharati, 2006).
Thisformat tries to capture the pronunciation infor-mation by assigning unique English characters toHindi characters.
Since this data is already in Latinscript with each character capturing a unique pro-nunciation, changing this data to a form that repli-cates chat data using heuristic rules is trivial.However, this data is highly sanskritized and henceneed to be changed by replacing Sanskrit wordswith equivalent Urdu words.
This replacement isdone by using online English to Urdu dictionaries(www.urduword.com and www.hamariweb.com).We have succeeded in replacing 20,000 pure San-skrit words to Urdu by performing a manuallookup.
The advantage with this method is that1.
The whole process of setting up annotationguidelines and standards is eliminated.2.
The replacement of pure Hindi words with Ur-du words in most cases is one-one and the POSassignment is retained without disturbing theentire structure of the sentence.Our training data now consists of Urdu words writ-ten in Latin script.
We also generate phonemes foreach word by running the phonetic model.
A POSmodel is trained using CRF (Lafferty, 2001) learn-ing method with current word, previous word andthe phonemes as features.
This model called theLatin Script (LS) POS model has an F-score of83%.English POS tagger is the Stanford tagger thathas a tagging accuracy of about 98.7%2 .5.1 ApproachUrdish blog data consists of Urdu code-mixed withEnglish.
Running simple Latin script based UrduPOS tagger results in 81.2% accuracy when POStags on the entire corpus is considered and 52.3%2 http://nlp.stanford.edu/software/tagger.shtmlaccuracy on only the English words.
Running Eng-lish tagger on the entire corpus improves the POStagging accuracy of English words to 79.2% accu-racy.
However, the tagging accuracy on the entirecorpus reduces considerably ?
55.4%.
This indi-cates that identifying the language of the wordswill definitely improve tagging.Identifying the language of the words can bedone simply by a lexicon lookup.
Since Englishwords are easily accessible and more enriched,English Wordnet3 makes a good source to performthis lookup.
Running Latin script POS tagger andEnglish tagger on the language specific words re-sulted in 79.82% accuracy for the entire corpus and59.2% accuracy for English words.
Clearly there isno significant gain in the performance.
This is onaccount of English equivalent Urdu representationof words (e.g.
key ~ their, more ~ peacock, bat ~speak).Since identifying the language explicitly yieldsless benefit, we showcase a new approach that isbased on the confidence measures of the taggers.We first run the English POS tagger on the entirecorpus.
This tagger is trained using a CRF model.Scores that indicate the confidence with which thistagger has applied tags to each word in the corpusis also estimated (table 2).
Next, the Latin scripttagger is applied on the entire corpus and the con-fidence scores for the selected tags are estimated.So, for each word, there exist two tags, one fromthe English tagger and the other from the Latinscript Urdish tagger along with their confidencescores.
This becomes our training corpus.The CRF learning model trained on the abovecorpus using features shown in table 3 generates across validation accuracy is 90.34%.
The accuracyon the test set is 88.2%, clearly indicating the ad-vantages of the statistical approach.Features used to train Urdish POS taggerUrdish wordPOS tag generated by LS taggerPOS tag generated by English taggerConfidence measure by LS taggerConfidence measure by English taggerDouble metaphone valuePrevious and next tags for English and UrduPrevious and next wordsConfidence prioritiesTable 3.
Features used to train the final POS taggerfor Urdish data3 http://wordnet.princeton.edu/5Table 4 illustrates the POS categories used as po-tential pattern switching place holdersPOS Category Examplenoun within a nounphraseuski life par itna control acha nahihai ~ its not good to control his lifethis muchInterjection  Comon Reema yaar!
~ Hey ManReema!lol!
~ lolAdjective Yeh story bahut hi scary or ugly tha~ This story was really scary anduglyAdverb Babra Shareef ki koi bhi film lagtihai, hum definitely dekhtai ~ I woulddefinitely watch any movie of BabraShareefGerund (tagged as averb by EnglishPOS tagger)Yaha shooting mana hai ~ shootingis prohibited hereVerb Iss movie main I dozed ~ I sleptthrough the movieVerb Afridi..
Cool off!Table 4.
POS categories that exhibit pattern switch6 Sentiment Polarity DetectionThe main goal of this work is to perform sentimentanalysis in Urdu blog data.
However, this task isnot trivial owing to all the peculiarities that blogdata exhibits.
The work done on Urdu sentimentanalysis (Mukund and Srihari, 2010) provided an-notated data for sentiments in newswire domain.
.Newspaper data make a good corpus to analyzedifferent kinds of emotions and emotional traits ofthe people.
They reflect the collective sentimentsand emotions of the people and in turn the societyto which they cater.
When specific frames are con-sidered (such as semantic verb frames) in the con-text of the triggering entities ?
opinion holders(entities who express these emotions) and opiniontargets (entities towards whom the emotion is di-rected) - performing sentiment analysis becomesmore meaningful and newspapers make an excel-lent source to analyze such phenomena (Mukund etal., 2011).
We use SCL to transfer sentiment anal-ysis learning from this newswire data to blog data.Inspired by the work done by (Prettenhofer andStein, 2010), we rely on oracles to generate pivotpairs.
A pivot pair {wS, wT} where wS ?
9S (thesource language ?
Urdu newswire data) and wT ?VT (the target language ?
Urdish data) should satis-fy two conditions 1. high support and 2. high con-fidence, making sure that the pairs are predictive ofthe task.Prettenhofer and Stein (2010) used a simpletranslation oracle in their experiments.
Howeverthere exist several challenges with Urdish data thatinhibits the use of a simple translation oracle.1.
Script difference in the source and targetlanguages.
Source corpus (Urdu) is writtenin Nastaleeq and the target corpus (Urdish)is written in ASCII2.
Spelling variations in roman Urdu3.
Frequent use of English words to expressstrong emotionsWe use two oracles to generate pivot pairs.The first oracle accommodates the issue withspelling variations.
Each Urdu word is converted toroman Urdu using IPA (1999) guidelines.
Usingthe double metaphone algorithm4 phoneme codefor the Urdu word is determined.
This is also ap-plied to Urdish data at the target end.
Words thathave the same metaphone code across the sourceand target languages are considered pivot pairs.The second oracle is a simple translation oraclebetween Urdu and English.
Our first experiment(experiment 1) is using words that belong to theadjective part of speech category as candidates forpivots.
We augment this set to include words thatbelong to other POS categories shown in table 4that exhibit pattern mixing (experiment 2).6.1 ImplementationThe feature used to train the learning algorithm islimited to unigrams.
For linear classification, weuse libSVM (Chang and Lin, 2011).
The computa-tional bottleneck of this method is in the SVD de-composition of the dense parameter matrix W. Weset the negative values of W to zero to get a sparserepresentation of the matrix.
For SVD computationthe Lanczos algorithm provided by SVDLIBC5 isemployed.
Each feature matrix used in libSVM isscaled between -1 and 1 and the final matrix forSVD is standardized to zero mean and unit vari-ance estimated on DS U Du (source subset and tar-get subset).6.2 ResultsThe domain of the source data set is limited tocricket and movies in order to ensure domain over-4 http://en.wikipedia.org/wiki/Double_Metaphone5 http://tedlab.mit.edu/~dr/SVDLIBC6lap between newswire data that we have and blogdata.
In order to benchmark the proposed tech-nique, our baseline technique is based on the con-ventional method of supervised learning approachon annotated data.
Urdish data set used for polarityclassification contains 705 sentences written inASCII format (example 6.1).
This corpus is manu-ally annotated by one annotator (purely based onintuition and does not follow any predefined anno-tation guidelines) to get 440 negative sentencesand 265 positive sentences.
The annotated corpusis purely used for testing and in this work consid-ered as unlabeled data.
A suitable linear kernelbased support vector machine is modeled on theannotated data and a five-fold cross validation onthis set gives an F-Measure of 64.3%.Example 6.1:General zia-ul-haq ke zamane mai qabayli elaqe Russiake khilaf jang ka merkaz thea aur general PervezMusharraf ke zamane mai ye qabayli elaqe Pakistan kekhilaf jang ka markaz ban gye .
~ negativeOur first experiment is based on using the se-cond oracle for translations on only adjectives(most obvious choice for emotion words).
We use438 pivot pairs.
The average F-measure for theperformance is at 55.78% which is still much be-low the baseline performance of 64.3% if we hadaccess to annotated data.
However, the resultsshow the ability of this method.Our second experiment expands the power ofthe second oracle to provide translations to otherPOS categories that exhibit pattern switching.
Thisincreased the number of pivot pairs to 640.
In-crease in pivots improved the precision.
Also wesee significant improvement in the recall.
The new-ly added pivots brought more sentences under theradar of the transfer model.
The average F-Measure increased to 59.71%.The approach can be further enhanced by im-proving the oracle used to select pivot features.One way is add more pivot pairs based on the cor-relation in the topic space across language domains(future work).7 ConclusionIn this work we show a way to perform sentimentanalysis in blog data by using the method of struc-tural correspondence learning.
This method ac-commodates the various issues with blog data suchas spelling variations, script difference, patternswitching.Table 5.
SCL based polarity classification for Urdish dataWe rely on two oracles, one that takes care ofspelling variations and the other that providestranslations.
The words that are selected to betranslated by the second oracle are carefully cho-sen based on POS categories that exhibit emotionsand pattern switching.
We show that the perfor-mance of this approach is comparable to what isachieved by training a supervised learning model.In order to identify the POS categories that exhibitpattern switching, we developed a statistical POStagger for Urdish blog data using a method thatdoes not require annotated data in the target lan-guage.
Through these two modules (sentimentanalysis and POS tagger for Urdish data) we suc-cessfully show that the efforts in performing non-topical analysis in Urdu newswire data can easilybe extended to work on Urdish data.8 Future workAnalyzing the test data set for missing and falsepositives, here are some of the examples of wherethe model did not workExample 7.1: ?tring tring tring tring..
Phone to bar barbajta hai.
Annoying.?
~ tring tring tring tring tring..the phone rings repeatedly.
Annoying.Example 7.2: ?bookon ko padna tho ab na mumkin hai.Yaha thak mere friends mujhe blindee pukarthey hai?
~cannot read books any more.
Infact, my friends call meblindee.Example 7.3: ?Ek Tamana Hai Ke Faqt Mujh PeMehrban Raho, Tum Kise Or Ko Dekho To Bura LagtaHai?
~ I have this one wish that destiny be kind to meIf you see someone else I feel badOur method fails to tag sentences like in example7.1 where English verbs are used by themselves.Our POS tagger fails to capture such stand-alonePrecision (P %) Recall (R %) F-Measure (F %)Phonemes (Roman Urdu)37.97 58.82 46.15Metaphones based synonym mapping (adjectives)50.9 51 50.8956.6 56.4 55.6258.9 60.64 59.75Precision (P %) Recall (R %) F-Measure (F %)Metaphones based synonym mapping (adjectives + otherPOS categories)54.2 64.3 58.8258.4 60.85 59.659.4 62.12 60.737verbs as verbs but tags them as nouns.
Hence,GRHVQ?W RFFXU LQ WKH SLYRW VHWOur second issue is with Morpho syntacticswitching, a behavior seen in example 7.2.Nadhkarni (1975) and Pandaripande (1983) haveshown that when two or more languages come intocontact, there is mutual feature transfer from onelanguage to another.
The languages influence eachother considerably and constraints associated withfree morphemes fail in most cases.
The directionand frequency of influence depends on the socialstatus associated with the languages used in mix-ing.
The language that has a high social statustends to use the morphemes of the lower language.Example 7.4: Bookon ?
in books, Fileon ?
in files,Companiyaa ?
many companiesClearly we can see that English words due to theirfrequent contact with Urdu grammatical systemtend to adopt the morphology associated with thebase language and used mostly as native Urduwords.
These are some issues, if addressed, willdefinitely improve the performance of the senti-ment analysis model in Urdish data.ReferencesAbdul-Mageed, M., Diab, M., and Korayem, M. 2011.
Sub-jectivity and Sentiment Analysis of Modern Standard Ara-bic.
In proceedings of the 49th Meeting of ACL.
Portland,Oregon, USA, June 19-24Agnihotri, Rama Kant.
1998.
Social Psychological Perspec-tives on Second Language Learning.
Sage Publications,New DelhiBharati, Askhar, Rajeev Sangal and Dipti M Sharma.
2005.Shakti Analyser: SSF RepresentationBlitzer, John, Ryan McDonald, and Fernando Pereira.
2006.Domain adaptation with structural correspondence learning.In proceedings of the 2006 Conference on EMNLP, pp.120?128, Sydney, AustraliaChang, Chih-Chung, Chih-Jen Lin.
2011.
LIBSVM: a libraryfor support vector machines.
In the ACM Transactions onIntelligent Systems and Technology, Vol 2, no 27, pp 1-27Dredze, Mark., Blitzer, John., Talukdar,  Partha Pratim.,Ganchev, Kuzman., Graca, Joao., Pereira, Fernando.
2007.Frustratingly Hard Domain Adaptation for Parsing.
SharedTask  of CoNLL.Dussias, P. E. 2003.
Spanish-English code-mixing at the auxil-iary phrase: Evidence from eye-movements.
Revista Inter-nacional de Ling?
?stica Iberoamerican.
Vol  2, pp.
7-34Gildea, Daniel and Jurafsky, Dan.
2002.
Automatic Labelingof Semantic Roles, Computational Linguistics, 28(3):245?288Goyal, P, Manav R. Mital, A. Mukerjee, Achla M. Raina, D.Sharma, P. Shukla, and K Vikram.
2003.
Saarthaka - A Bi-lingual Parser for Hindi, English and code-switching struc-tures.
In proceedings of the 11th Conference of the ECALHal Daume III and Daniel Marcu.
2006.
Domain adaptationIRU VWDWLVWLFDO FODVVL?HUV Journal of Artificial IntelligenceResearch, Vol 26, pp.
101?126Hal Daume III.
2007.
Frustratingly easy domain adaptation.
Inproceedings of the 45th Meeting of ACL, pp.
256?263International Phonetic Association (IPA).
1999.
Handbook ofthe International Phonetic Association: A guide to the use ofthe International Phonetic Alphabet.
Cambridge: Cam-bridge University Press.
ISBN 0-521-65236-7 (hb); ISBN0-521-63751-1Joshi, Adithya and Bhattacharyya, Pushpak.
2012.
Cost andBenefit of Using WordNet Senses for Sentiment Analysis.LREC, Istanbul, TurkeyKachru, Braj.
1978.
Conjunct verbs; verbs or verb phrases?.In proceedings of the XIIth International Congress of Lin-guistics.
pp.
366-70Lafferty, John, Andrew McCallum, Pereira.
F. 2001.
Condi-tional random fields: Probabilistic models for segmentingand labeling sequence data.
In proceedings of the 18th In-ternational Conference on Machine Learning, MorganKaufmann, San Francisco, CA .
pp.
282?289Muaz, Ahmed, Aasim Ali, and Sarmad Hussain.
2009.
Analy-sis and Development of Urdu POS Tagged Corpus.
In pro-ceedings of the 7th Workshop on ACL-IJCNLP, Suntec,Singapore, pp.
24?31, 6-7 August.Mukund, Smruthi, Rohini K. Srihari.
2010.
A Vector SpaceModel for Subjectivity Classification in Urdu aided by Co-Training, In proceedings of the 23rd COLING, Beijing,ChinaMukund, Smruthi, Debanjan Ghosh, Rohini K. Srihari, 2011.Using Sequence Kernels to Identify Opinion Entities in Ur-du.
In Proceedings of CONLLNadkarni, Mangesh.
1975.
Bilingualism and Syntactic Changein Konkani Language, vol.
51, pp.
672 C 683.Pandaripande, R. 1981.
Syntax and Semantics of the PassiveConstruction in selected South Asian Languages.
PhD disser-tation.
University of Illinois, IllinoisPrettenhofer, Peter and Benno Stein.
2010.
Cross-LingualAdaptation Using Structural Correspondence Learning.
Inproceedings of ACLRasul, Sarwat.
2006.
Language Hybridization and Code Mix-ing in Pakistani Talk Shows.
Bahaudin Zakriya UniversityJournal 2nd Issue.
pp.
29-41Roark, Brian and Michiel Bacchiani.
2003.
Supervised andunsupervised PCFG adaptation to novel domains.In Proceedings of the 2003 Conference of NAACL, HLT -Volume 1 (NAACL '03)Rie-K. Ando and Tong Zhang.
2005.
A framework for learningpredictive structures from multiple tasks and unlabeled data.In Jornal of Machine Learning.
Res., Vol 6, pp.
1817?1853Santorini, Beatrice.
1990.
Part-of-speech tagging guidelinesfor the Penn Treebank Project.
University of Pennsylvania,3rd Revision, 2nd Printing.Shimizu, Nobuyuki and Nakagawa, Hiroshi.
2007.
StructuralCorrespondence Learning for Dependency Parsing.
In pro-ceedings of CoNLL Shared Task Session of EMNLP-CoNLL.Sinha, R.M.K.
and Anil Thakur.
2005.
Machine Translation ofBi-lingual Hindi-English (Hinglish) Text.
10th MachineTranslation summit (MT Summit X)Zentella, Ana Celia.
1997.
A bilingual manual on how to raiseSpanish Children.8
