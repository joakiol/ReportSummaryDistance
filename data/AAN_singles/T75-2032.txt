REPRESENTATION OF KNOWLEDGE:NON-LINGUISTIC FORMSDO WE NEED IMAGES AND ANALOGUES?Zenon W. PylyshynDepartment of PsychologyUniversity of Western OntarioLondon, CanadaI.
OLD HOMONCULI NEVER DIEIt is no accident that inside mostpsychological theories of representation wecan, if we look closely enough, discern asmall person with his eyes on a screen andhis hands on the controls.
The metaphor isso seductive that almost all theories ofperception succumb to it (as Kaufman, 1974has noted in his recent review of theoriesin perception).
True, we try to deliver thehomonculus a better and more stable picturethan falls on the eye of the larger personhe is controll ing -- in fact we usually goto the trouble of presenting him with athree-dimensional model (often holographic),hoping to lighten his load, but the littleman seems so friendly and familiar that wecan't imagine how we could do without him.The dilemma this places us in goes backseveral millenia.
It runs something likethis.
We need to have some internalrepresentation of the world in order tothink about it (indeed, in order toapprehend it at all).
But if this internalrepresentation is too similar to the worlditself it cannot help us to apprehend itsince it merely moves the same probleminside.
On the other hand if it is toodissimilar then how can it represent theworld at all?
Epistemologists have squirmedunder the horns of this dilemma trying byvarious means to make the problem disappear.Psychologists on the other hand have by andlarge dismissed the problem as old-fashioned(which it is) and have proceeded to berigorous in their experimental analysis ofthe "functional role of images", Whereimages are not merely "pictures" but areartfully becoming much more fleeting andsketchy.
Sometimes they are referred to asperceptual schemas, sometimes as "theactivation of perceptual processes", andmore recently as a~alo~ues.
The little manfor his part has been put in a black boxwhere he continues to live under such guisesas "the visual system" or as something whichresponds to the analogues by moving limbs oruttering sentences as required.
Thisaccount is admittedly unfair to the manyinvestigators who understand the basicproblem quite well and are struggling todevelop representation systems adequate tothe task.
But I believe that the caricatureadequately characterizes the vast majorityof psychological approaches to thephenomenon of so-called "non-verbalrepresentation".I will confine my written remarks to asmall subset of questions bearing on thisdilemma.
I would be glad to providereprints of my other relevant papers onrequest.
Primarily what I will try to do is160to point out that many of the ways ofcasting the problem of "alternative forms ofrepresentation,, are misguided and that byblurring certain distinctions andemphasizing others we may be burying thesignificant problems in a mire of catchwords(e.g., procedural embedding, analogical,holistic and even propositional -- which Inow regret using because of the sententialconnotations which, despite all my efforts,it continues to have).II.
THE FUNCTION OF REPRESENTING:"RESEMBLING" OR "DESCRIBING"?Let us look at the representationdilemma again.
It asked (in part) how anentity could represent some object if it wastoo dissimilar from that object.
But this,like a great many other questions of thissort, already presupposes something crucial.We normally only speak about two thingsbeing similar if they are to be examined inthe same way -- in particular if they areboth to be viewed.
Since we don't want tostart off with this as the assumption (wemight then ask "who does the viewinginside?")
we should drop the idea that therepresentation literally rese~ the thingit represents (see Goodman, 1968, for moreon this point).
Well then can therepresentation be any arbitrary symbol?Clearly it cannot in general be anunstructured atomic symbol since then therewould be no way to show that the thingrepresented had a structure -- i.e., hadsubparts, relations and attributes.
So whatconstraints are there on the structure ofthe representation?
Here the going getstougher.
One is tempted to give therecursive reply that it must havesubstructures, relations, properties, etc.which represent the substructures, relationsand properties of the object(s) beingrepresented.
But here we have to be carefulfor two reasons.
One reason is that if therepresentation maps all the structures, etc.of the object we will have an isomorphismwhich has all the disadvantages of thepicture-in-the-head alternative.
Therepresentation must not only be highlypartial but it must be partial in theappropriate way (see below).
The otherreason is that it is meaningless to speak of~he structure of the representation.Structure is relative to the processes whichconstruct and use the representation.
It isthese processes which define the semanticsof the representation: we may speak of thestructure of a representation relative to aSemantic Interpretation Function (SIF).Thus the two distinct strings of symbols"not (P and q)" and "not-p or not-q" areidentical structures from the point of viewof a theorem prover and the distinct strings,w +, and "(LEFT-OF STAR PLUS)" may beidentical structures from the point of viewof some other SIF.
Neglect of the SIFrepresents one of the most ubiquitoussources of confusion in discussions aboutrepresentation.
It leads some people, forexample, to assert that non-llngulsticrepresentations "preserve the structure ofthat which they represent".
They do so ofcourse only to the extent that the "sameIIIIIIIIIIIIIIIIIIIstructure" is extracted bysome appropr iateSIF.
In that sense the sentence "the bookis on the table" can be said to preservepart of the structure of a scene containinga book on a table.
To be sure the latterhas a lot more structure as well but so doesthe sentence (it has order, length, color,etc.).
It is up to the SIF to pick outthose aspects which are signifying fromthose that are not and to process the str ing(in the appropr iate contexts) as it wouldthe scene.
Without knowing what the SIF didwe could not speak of structural similarity.I don't mean to imply by this example thatsentences provide an adequate representat ionof scenes (they don't for other reasons) butonly that the di f ferences are more subtlethan captured in the simple claim that thescene  and the sentence have dif ferentstructures.
At this level all we can say isthat they don't "resemble" one another.One can of course remove much of thearbitrar iness in the above character izat ionof the structure of representatons byrequir ing that the SIF be perceptual innature -- i.e., by assuming that the SIF hasmuch in common with visual perception.There is a good deal of psychologicalevidence suggesting that imaging andperceiving are similar in many ways.Although this seems like a reasonableproposal it creates many problems and mustbe approached with care.
It is tempting to"explain" aspects of cognit ion (e.g.,Moyer's (1973) account of magnftudejudgments from memory) by pointing out thatthey are "like" their perceptualcounterparts in respect to such measures asreaction time.
But since we have no idea ofhow the latter is accompl ished this is acase of "obscurum per obscurus".Furthermore to note that some cognit iveoperations bear a (not yet well understood)relation to perception is in no senseevidence that these cognit ive operatonsinvolve pictorial  or analogical or any otherentit ies which resemble objects in theenvironment.
Presumably perception involvesthe construct ion and processing of internalrepresentatons Just as does imaging so somerelations between the two should not be toosurprising.
Furthermore there are somemajor di f ferences as well.
These  arerelated to the fact that objects in theenvironment have a stable existence so theycan be re-examined and to the fact thattransformations of internal objects (such asthose studied by Shepard) depend on theperson's tacit knowledge concerningpermissible transformations.
The way inwhich this knowledge must be brought tobear -- and not intr insic propert ies of therepresentat ion (i.e., not the r igidity ofpatterns being mental ly rotated) are whatmust account for experimental  results onmental t ransformat ions (we shall return tothis point in section III).But perhaps the main argument againstthe view that the SIF isperceptual -- assuming that we can specifywhat we mean by perceptual  in other thanhand-waving terms -- is that it implies thatthe representat ion to which it is appl ied issomething capable of being perceived.Unfortunately no matter how hard we try tomake it sound like we are avoiding pictures(or worse, objects) in the head there is nocoherent intermediate ground: if the SIF hasperceptual pr imit ives (e.g., operations suchas those studied in vision for featuredetection, etc.)
it must be applied tosomething which, however fleeting, sketchy,vague, dynamic, etc.
is still pictorial  orisomorphic in a sense which is incompatiblewith the facts of human memory andcognition.
I want to make it clear that Idon't object to the rei f icat ion of picturesor some such analogues on ontologicalgrounds, but simply on the grounds that suchobjects as a class have the wrongproperties.
Our representat ions of thevisual world are not like any (degraded,topological ly  transformed, filtered, etc.
)project ion of proximal stimulation: they areconstructed from aspects of the world whichwe not ic~ (and such aspects can be global,abstract and highly cognit ive -- i.e.,knowledge-dr iven and assimi lated intoavai lable conceptual  categories) and theyrepresent equivalence-c lasses of stimuliwhich are physical ly very different fromeach other and from any conceivablepicture- l ike entity.
For example I mightnotice shapes (or at least a class ofshapes) but not colors, objects but notlocations, and non-sensory relat ions such ascausality, potential  actions, intensions,etc.
Such representatons, derived fromvisual perception, cannot be sharplydist inguished from knowledge derived byother means; that is why I prefer to referto them as "structured descriptions".
Thevocabulary of such descr ipt ions and theaccessib i l i ty  relat ions may be quitedifferent from that of l inearly orderedutterances.
Such "visual images" are insome ways more like models than logicalstatements insofar as they may not containquanti f iers (at least the currentcomputat ional  models of imagery donot -- e.g., Baylor 1972, Moran 1973).Images in such an approach are datastructures in which objects are indiv iduated(i.e., there is no node for "seven blocks"),contain many "default" attr ibutes andtypical ly use spatial  relat ions as accesspaths.
Yet in my view it is moreappropr iate to refer to them as descr ipt ionsthan images because the term is lessmis leading since they consist of conceptualstructures very much like those constructedwhen the input is l inguist ic -- exceptperhaps using a modal i ty-specl f lc  vocabularyof symbols.
One cannot of course rule outthe possibi l i ty that there are cognit ive lyfunctional aspects of percepts which cannotbe captured in such a discrete symbolsystem, but I have yet to hear a persuasiveargument for that case.
Furthermore, I haveargued elsewhere (Pylyshyn, 1973) that thereare many conceptual  traps await ing those whotalk in terms of stor ing and using images.III.
ANALOGICAL AGAINThe most common proposal for analternat ive form of representat ion forperceptual ly  derived knowledge is that it isanalogica l .
This term has become the new161buzzword in cognit ive psyoh61ogy and is usedas a synonym for anythlng from "warm andcuddly" through "holistic", "continuous" , orsimply "anything which is notlanguage-l ike".
Few psychologists havetried to be very specif ic in character iz ingthe meaning of this term.
When people havetried to be expl ic it  (as, for example,Sloman 1971; Block and Fodor 1973; Lewis1971, Goodman 1968) they have found it to bea very diff icult concept to character ize andhave had to d ist inguish several di f ferentsenses in which the term is used.
I hatediscussed some of these elsewhere (Pylyshyn,in press) so I will not repeat myself  here.I want merely to add to what I have wr i t tensome discussion of why people may be temptedto reach  for analogues to account forcertain psychological  evidence, and tosuggest why such entit ies whatever they maybe, fall short of serving the functionexpected of them.As a psychologist  one of the mainobject ions that I have to the whole notionof analogue representat ion is that it seemsto me to be a convenient way of hiding alarge part of the problem we are trying toexplain -- i.e., how people represent andreason about objects and actions.
You mayrecall  being at least mildly surprised thatthere is such a thing as a "frame problem"in reasoning about actions (McCarthy andHayes, 1969; Simon, 1972).
The reason ~hatit never occurred to many of us that therewas a problem is that when we interact withthe environment (as opposed to th inkingabout it) the laws of physics take care ofall the relevant interact ions amongevents -- we don't have to worry aboutover looking what wil l  happen to evrythingelse in the world when we carry out someaction on a part of it.
Such relations aregiven to us free by the environment.
In thecase of reasoning, however, the relat ionsare not free.
We must in some wayexpl ic i t ly  build in the knowledge regardingwhat effects do and don't fol low from anyaction.
Now it seems to me that the notionof an analogue representat ion is in part anattempt to get this information for freeagain.
Thus the claim that data on thet ime-course of mental  rotat ion (c.f., Cooperand Shepard, 1973) argues that the processis analogue (since, as the proponentsinnocent ly  ask "how can you rotate a datastructure through its intermediateposit ions?")
.
This carr ies the impl icat ionthat once we start a rotation the mediumwil l  take care of mainta in ing the r ig idityof the total pattern and carry along all theparts for us -- just as the laws of physicstake care of this for us in the realenvironment.
But, as in the frame problem,we are over looking the fact that the person(or the robot) must know what wil l  and wil lnot happen to the bottom part when the toppart starts to rotate.
In a descr ipt ivestructure this is precisely what makes"mental rotat ion" appear awkward andcomputat ional ly  unduly costly.
But this isunavoidable unless we have an analogicalmodel l ing medium which intr ins ica l ly  fol lowsthe laws of physics.
Unless we are wi l l ingto ascr ibe such laws to brain t issue (which,by the way, is what Gestalt psychologists162attempted to do) we are stuck with locat ingit in what I have called the SIF (which doesnot, incidental ly,  preclude it from being adistr ibuted computat ion attached to the datastructure itself).
If we admit this,however, there appears l ittle reason to callthe result ing representat ional  systemanalogical  (though Shepard's use of the termis, by his own admission, broad enough tocover this case).Another example where analogues areinvoked in a s imi lar role is for therepresentat ion of magnitudes.
When we"mental ly compare" two objects -- say a dogand a horse -- to judge which is larger, theanswer seems immediate and intu i t ive lyappears to depend on a comparison of twoimages or some sort of "analogues".
Now wehave some idea of what sort of operat ion isinvolved when two physical  objects arecompared by placing them side-by-side.Again the laws of physics and optics assureus that, as in the frame problem, the rightthings wil l  happen (e.g., the object sizeswil l  remain fixed as they are moved, thesmal ler object wil l  part ia l ly  occlude thelarger, etc.).
But in the mental  compar isoncase we somehow feel that the analogues wil l"do the right thing" because  of intr ins icpropert ies of the analogue medium, just asin the mental  rotat ion example we feel thatanalogues wil l  intr ins ica l ly  maintain theirform in a rigid manner during rotation.
Inthe mental  compar ison case the assumption isthat if the process is analogue, the SIFdoes not need to "know" the rules oft ransformat ion nor does it need to "know"about order re lat ions -- e.g., that suchrelat ions are asymmetr ic  andtransi t ive -- since it has merely to "readoff" the answer from the analogue.
Therepresentat ion again seems to have theanswer "written on its sleeve".
Thus byat t r ibut ing such propert ies to the intr ins icnature of the representat ion we beg the veryquest ion of how magnitudes are encoded andcompared.The phenomenon of at t r ibut ing to theintr ins ic  nature of a representat ion some ofthe crucial  aspects that need to be takeninto account (because these are sointu i t ive ly  obvious to the theorist) is notconfined to analogical  representat ions.Woods (1975) has recent ly  shown that wefrequent ly commit the same oversight in thecase of semantic networks.
This is why itis important to attempt to s imulate as igni f icant port ion of cognit ion by machine(although even here the existence of suchbui lt - in funct ions as an ar i thmet icprocessor may create the i l lus ion that weget magnitudes for free -- i.e., we need notmodel them in detail).In conclus ion let me reiterate that Idon't c laim to have made an argument againstanalogical  modes of representat ion -- andsti l l  less that I am sat isf ied that semanticnetworks, procedures, etc.
are adequate tohandle all forms of knowledge.
I havesimply tried to argue that many of thereasons people have for Jumping on the"non- l inguist lc"  (whatever that may be)bandwagon are insuff ic ient.
Furthermore weIIIIIIIIIiIIIIiiiiIare so far from understanding the semanticsof discrete data structures (as Woods hascogently argued) that any mass movement toabandon them (or even augment them withsomething radically different) is at thevery least premature.REFERENCESBaylor, G.W., A treatise on the mind's eye:An empirical investigation of visualmental imagery.
(Doctoral dissertation,Carnegie-Mellon University) Ann Arbor,Mich.
: University Microfilms 1972.
No.72-13, 699.Block, N.J., & Foder, J.A., Cognitivism andthe  analog/digital distinction, Mimeo,MIT, 1973.Cooper, L.A., & Shepard, R.N., Chronometricstudies of the rotation of mental images.In W.G.
Chase (Ed.
), Visua~ infor~atiQnprocessing.
New York: Academic Press,1973.Kaufman, L., Sight and Mind, New York:Oxford University Press, 1974.Lewis, D., Analog and digital.
Nous, 1971,321-327.McCarthy, J.
& Hayes, P., Somephilosophical problems from thestandpoint of artificial intelligence.In B. Meltzer & D. Michie (Eds.
)Machine Inte&llgence ~, Edinburgh:University of Edinburgh Press, 1969.Moran, T., The symbolic imagery hypothesis:a production system model.
UnpublishedPh.D.
dissertation, Carnegie-MellonUniversity, 1973.Moyer, R.S., Comparing objects in memory:evidence suggesting an internalpsychophysics.
P~r~eptionPs?chophysics, 1973, 13, 180-184.Pylyshyn, Z.W., What the mind's eye tellsthe mind's brain: a critique of mentalimagery.
Psychological Bulletin, 1973,13, 1-24.Pylyshyn, Z.W., The symbolic nature ofmental representaions.
In S. Kaneff andJ.E.
O'Callaghan (Eds.)
Obieetives aqdMethodologies in Artificial Iqte&ligen9e.New York: Academic Press (in press).Simon, H.A., On reasoning about actions.
InH.A.
Simon and L. Siklossy (Eds.
)ReDresentation ~d meaning.
EnglewoodCliffs, NJ: Prentice-Hall, 1972.Woods, W., What's in a link: foundations forsemantic networks.
In D. Bobrow and A.Collins (Eds.
), ReDresentatio~ aq~~ndrstanding: studies in cogpi~ivescience, New York: Academic Press, 1975.163
