Unsupervised Feature Selection for Relation ExtractionJinxiu Chen1 Donghong Ji1 Chew Lim Tan2 Zhengyu Niu11Institute for Infocomm Research 2Department of Computer Science21 Heng Mui Keng Terrace National University of Singapore119613 Singapore 117543 Singapore{jinxiu,dhji,zniu}@i2r.a-star.edu.sg tancl@comp.nus.edu.sgAbstractThis paper presents an unsupervised re-lation extraction algorithm, which in-duces relations between entity pairs bygrouping them into a ?natural?
num-ber of clusters based on the similarityof their contexts.
Stability-based crite-rion is used to automatically estimatethe number of clusters.
For removingnoisy feature words in clustering proce-dure, feature selection is conducted byoptimizing a trace based criterion sub-ject to some constraint in an unsuper-vised manner.
After relation clusteringprocedure, we employ a discriminativecategory matching (DCM) to find typi-cal and discriminative words to repre-sent different relations.
Experimentalresults show the effectiveness of our al-gorithm.1 IntroductionRelation extraction is the task of finding rela-tionships between two entities from text contents.There has been considerable work on supervisedlearning of relation patterns, using corpora whichhave been annotated to indicate the information tobe extracted (e.g.
(Califf and Mooney, 1999; Ze-lenko et al, 2002)).
A range of extraction mod-els have been used, including both symbolic rulesand statistical rules such as HMMs or Kernels.These methods have been particularly success-ful in some specific domains.
However, manu-ally tagging of large amounts of training data isvery time-consuming; furthermore, it is difficultfor one extraction system to be ported across dif-ferent domains.Due to the limitation of supervised methods,some weakly supervised (or semi-supervised) ap-proaches have been suggested (Brin, 1998; Eu-gene and Luis, 2000; Sudo et al, 2003).
Onecommon characteristic of these algorithms is thatthey need to pre-define some initial seeds for anyparticular relation, then bootstrap from the seedsto acquire the relation.
However, it is not easyto select representative seeds for obtaining goodresults.Hasegawa, et al put forward an unsuper-vised approach for relation extraction from largetext corpora (Hasegawa et al, 2004).
First, theyadopted a hierarchical clustering method to clus-ter the contexts of entity pairs.
Second, after con-text clustering, they selected the most frequentwords in the contexts to represent the relationthat holds between the entities.
However, the ap-proach exists its limitation.
Firstly, the similar-ity threshold for the clusters, like the appropriatenumber of clusters, is somewhat difficult to pre-defined.
Secondly, the representative words se-lected by frequency tends to obscure the clusters.For solving the above problems, we present anovel unsupervised method based on model or-der selection and discriminative label identifica-tion.
For achieving model order identification,stability-based criterion is used to automaticallyestimate the number of clusters.
For removingnoisy feature words in clustering procedure, fea-ture selection is conducted by optimizing a tracebased criterion subject to some constraint in an262unsupervised manner.
Furthermore, after relationclustering, we employ a discriminative categorymatching (DCM) to find typical and discrimina-tive words to represent different relations types.2 Proposed MethodFeature selection for relation extraction is the taskof finding important contextual words which willhelp to discriminate relation types.
Unlike su-pervised learning, where class labels can guidefeature search, in unsupervised learning, it is ex-pected to define a criterion to assess the impor-tance of the feature subsets.
Due to the interplaybetween feature selection and clustering solution,we should define an objective function to evaluateboth feature subset and model order.In this paper, the model selection capability isachieved by resampling based stability analysis,which has been successfully applied to several un-supervised learning problems (e.g.
(Levine andDomany, 2001), (Lange et al, 2002), (Roth andLange et al, 2003), (Niu et al, 2004)).
We extendthe cluster validation strategy further to addressboth feature selection and model order identifica-tion.Table 1 presents our model selection algorithm.The objective function MFk,k is relevant withboth feature subset and model order.
Clusteringsolution that is stable against resampling will giverise to a local optimum of MFk,k, which indicatesboth important feature subset and the true clusternumber.2.1 Entropy-based Feature RankingLet P = {p1, p2, ...pN} be a set of local contextvectors of co-occurrences of entity pair E1 andE2.
Here, the context includes the words occur-ring between, before and after the entity pair.
LetW = {w1, w2, ..., wM} represent all the wordsoccurred in P .
To select a subset of importantfeatures from W , words are first ranked accord-ing to their importance on clustering.
The im-portance can be assessed by the entropy criterion.Entropy-based feature ranking is based on the as-sumption that a feature is irrelevant if the presenceof it obscures the separability of data set(Dash etal., 2000).We assume pn, 1 ?
n ?
N , lies in featurespace W , and the dimension of feature space isTable 1: Model Selection Algorithm for Relation Extrac-tionInput: Corpus D tagged with Entities(E1, E2);Output: Feature subset and Model Order (number ofrelation types);1.
Collect the contexts of all entity pairs in the documentcorpus D, namely P ;2.
Rank features using entropy-based method describedin section 2.1;3.
Set the range (Kl,Kh) for the possible number ofrelation clusters;4.
Set estimated model order k = Kl;5.
Conduct feature selection using the algorithm pre-sented in section 2.2;6.
Record F?k,k and the score of the merit of both ofthem, namely MF,k;7.
If k < Kh, k = k + 1, go to step 5; otherwise, go toStep 7;8.
Select k and feature subset F?k which maximizes thescore of the merit MF,k;M .
Then the similarity between i-th data pointpi and j-th data point pj is given by the equa-tion: Si,j = exp(??
?
Di,j), where Di,j is theEuclidean distance between pi and pj , and ?
is apositive constant, its value is ?
ln 0.5D , where D isthe average distance among the data points.
Thenthe entropy of data set P with N data points isdefined as:E = ?N?i=1N?j=1(Si,j logSi,j + (1?
Si,j) log(1?
Si,j))(1)For ranking of features, the importance of eachword I(wk) is defined as entropy of the data af-ter discarding feature wk.
It is calculated in thisway: remove each word in turn from the featurespace and calculate E of the data in the new fea-ture space using the Equation 1.
Based on theobservation that a feature is the least important ifthe removal of it results in minimum E, we canobtain the rankings of the features.2.2 Feature Subset Selection and ModelOrder IdentificationIn this paper, for each specified cluster number,firstly we perform K-means clustering analysis oneach feature subset and adopts a scattering cri-terion ?Invariant Criterion?
to select an optimalfeature subset F from the feature subset space.Here, trace(P?1W PB) is used to compare the clus-ter quality for different feature subsets 1, which1trace(P?1W PB) is trace of a matrix which is the sumof its diagonal elements.
PW is the within-cluster scatter263Table 2: Unsupervised Algorithm for Evaluation of Fea-ture Subset and Model OrderFunction: criterion(F, k, P, q)Input: feature subset F , cluster number k, entity pairsset P , and sampling frequency q;Output: the score of the merit of F and k;1.
With the cluster number k as input, perform k-meansclustering analysis on pairs set PF ;2.
Construct connectivity matrix CF,k based on aboveclustering solution on full pairs set PF ;3.
Use a random predictor ?k to assign uniformly drawnlabels to each entity pair in PF ;4.
Construct connectivity matrix CF,?k based on aboveclustering solution on full pairs set PF ;5.
Construct q sub sets of the full pairs set, by randomlyselecting ?N of the N original pairs, 0 ?
?
?
1;6.
For each sub set, perform the clustering analysis inStep 2, 3, 4, and result C?F,k, C?F,?k ;7.
Compute MF,k to evaluate the merit of k using Equa-tion 3;8.
Return MF,k;measures the ratio of between-cluster to within-cluster scatter.
The higher the trace(P?1W PB), thehigher the cluster quality.To improve searching efficiency, features arefirst ranked according to their importance.
As-sume Wr = {f1, ..., fM} is the sorted feature list.The task of searching can be seen in the featuresubset space: {(f1, ..., fk),1 ?
k ?
M}.Then the selected feature subset F is eval-uated with the cluster number using the ob-jective function, which can be formulated as:F?k = argmaxF?Wr{criterion(F, k)}, subjectto coverage(P, F ) ?
?
2.
Here, F?k is the opti-mal feature subset, F and k are the feature subsetand the value of cluster number under evaluation,and the criterion is set up based on resampling-based stability, as Table 2 shows.Let P?
be a subset sampled from full entitypairs set P with size ?|P | (?
set as 0.9 in thispaper.
), C(C?)
be |P | ?
|P |(|P?| ?
|P?|) con-nectivity matrix based on the clustering results onP (P?).
Each entry cij(c?ij) of C(C?)
is calculatedin the following: if the entity pair pi ?
P (P?
),pj ?
P (P?)
belong to the same cluster, thencij(c?ij) equals 1, else 0.
Then the stability is de-matrix as: PW =?cj=1?Xi?
?j (Xi ?
mj)(Xj ?
mj)tand PB is the between-cluster scatter matrix as: PB =?cj=1(mj ?m)(mj ?m)t, where m is the total mean vec-tor and mj is the mean vector for jth cluster and (Xj?mj)tis the matrix transpose of the column vector (Xj ?mj).2let coverage(P, F ) be the coverage rate of the featureset F with respect to P .
In practice, we set ?
= 0.9.fined in Equation 2:M(C?, C) =?i,j 1{C?i,j = Ci,j = 1, pi ?
P?, pj ?
P?
}?i,j 1{Ci,j = 1, pi ?
P?, pj ?
P?
}(2)Intuitively, M(C?, C) denotes the consistencybetween the clustering results on C?
and C. Theassumption is that if the cluster number k is actu-ally the ?natural?
number of relation types, thenclustering results on subsets P?
generated bysampling should be similar to the clustering re-sult on full entity pair set P .
Obviously, the abovefunction satisfies 0 ?
M ?
1.It is noticed that M(C?, C) tends to decreasewhen increasing the value of k. Therefore foravoiding the bias that small value of k is to beselected as cluster number, we use the clustervalidity of a random predictor ?k to normalizeM(C?, C).
The random predictor ?k achievedthe stability value by assigning uniformly drawnlabels to objects, that is, splitting the data into kclusters randomly.
Furthermore, for each k, wetried q times.
So, in the step 7 of the algorithmof Table 2, the objective function M(C?F,k, CF,k)can be normalized as equations 3:MnormF,k = 1qq?i=1M(C?iF,k, CF,k)?1qq?i=1M(C?iF,?k , CF,?k )(3)Normalizing M(C?, C) by the stability of therandom predictor can yield values independent ofk.After the number of optimal clusters and thefeature subset has been chosen, we adopted theK-means algorithm for the clustering phase.
Theoutput of context clustering is a set of contextclusters, each of them is supposed to denote onerelation type.2.3 Discriminative Feature identificationFor labelling each relation type, we use DCM(discriminative category matching) scheme toidentify discriminative label, which is also usedin document classification (Gabriel et al, 2002)and weights the importance of a feature based ontheir distribution.
In this scheme, a feature is notimportant if the feature appears in many clustersand is evenly distributed in these clusters, other-wise it will be assigned higher importance.To weight a feature fi within a category, wetake into account the following information:264Table 3: Three domains of entity pairs: frequency distribution for different relation typesPER-ORG # of pairs:786 ORG-GPE # of pairs:262 ORG-ORG # of pairs:580Relation types Percentage Relation types Percentage Relation types PercentageManagement 36.39% Based-In 46.56% Member 27.76%General-staff 29.90% Located 35.11% Subsidiary 19.83%Member 19.34% Member 11.07% Part-Of 18.79%Owner 4.45% Affiliate-Partner 3.44% Affiliate-Partner 17.93%Located 3.28% Part-Of 2.29% Owner 8.79%Client 1.91% Owner 1.53% Client 2.59%Other 1.91% Management 2.59%Affiliate-Partner 1.53% Other 1.21%Founder 0.76% Other 0.52%?
The relative importance of fi within a cluster is de-fined as: WCi,k = log2(pfi,k+1)log2(Nk+1) , where pfi,k is thenumber of those entity pairs which contain feature fiin cluster k. Nk is the total number of term pairs incluster k.?
The relative importance of fi across clusters is givenby: CCi = log N?maxk?Ci{WCi,k}?Nk=1 WCi,k?
1logN , where Ciis the set of clusters which contain feature fi.
N is thetotal number of clusters.Here, WCi,k and CCi are designed to captureboth local information within a cluster and globalinformation about the feature distribution acrossclusters respectively.
Combining both WCi,k andCCi we define the weight Wi,k of fi in cluster kas: Wi,k = WC2i,k?CC2i?WC2i,k+CC2i?
?2, 0 ?
Wi,k ?
1.3 Experiments and Results3.1 DataWe constructed three subsets for domains PER-ORG, ORG-GPE and ORG-ORG respectivelyfrom ACE corpus3 The details of these subsetsare given in Table 3, which are broken down bydifferent relation types.
To verify our proposedmethod, we only extracted those pairs of entitymentions which have been tagged relation types.And the relation type tags were used as groundtruth classes to evaluate.3.2 Evaluation method for clustering resultSince there was no relation type tags for eachcluster in our clustering results, we adopted apermutation procedure to assign different rela-tion type tags to only min(|EC|,|TC|) clusters,where |EC| is the estimated number of clusters,and |TC| is the number of ground truth classes3http://www.ldc.upenn.edu/Projects/ACE/(relation types).
This procedure aims to find anone-to-one mapping function ?
from the TC toEC.
To perform the mapping, we construct acontingency table T , where each entry ti,j givesthe number of the instances that belong to boththe i-th cluster and j-th ground truth class.
Thenthe mapping procedure can be formulated as:??
=argmax?
?|TC|j=1 t?
(j),j , where ?
(j) is the indexof the estimated cluster associated with the j-thclass.Given the result of one-to-one mapping, wecan define the evaluation measure as follows:Accuracy(P ) =?j t??
(j),j?i,j ti,j.
Intuitively, it reflectsthe accuracy of the clustering result.3.3 Evaluation method for relation labellingFor evaluation of the relation labeling, we needto explore the relatedness between the identifiedlabels and the pre-defined relation names.
To dothis, we use one information-content based mea-sure (Lin, 1997), which is provided in Wordnet-Similarity package (Pedersen et al, 2004) to eval-uate the similarity between two concepts in Word-net.
Intuitively, the relatedness between two con-cepts in Wordnet is captured by the informationcontent of their lowest common subsumer (lcs)and the information content of the two conceptsthemselves , which can be formalized as follows:Relatednesslin(c1, c2) = 2?IC(lcs(c1,c2))IC(c1)+IC(c2) .
Thismeasure depends upon the corpus to estimate in-formation content.
We carried out the experi-ments using the British National Corpus (BNC)as the source of information content.3.4 Experiments and ResultsFor comparison of the effect of the outer andwithin contexts of entity pairs, we used five dif-265Table 4: Automatically determined the number of relation types using different feature ranking methods.Domain ContextWindowSize# of realrelationtypesModel Or-der Base-lineModelOrder with?2ModelOrder withFreqModel Or-der withEntropyPER-ORG 0-5-0 9 7 7 7 72-5-2 9 8 6 7 80-10-0 9 8 6 8 82-10-2 9 6 7 6 85-10-5 9 5 5 6 7ORG-GPE 0-5-0 6 3 3 3 42-5-2 6 2 3 4 40-10-0 6 6 4 5 62-10-2 6 4 3 4 55-10-5 6 2 3 3 3ORG-ORG 0-5-0 9 7 7 7 72-5-2 9 7 5 6 70-10-0 9 9 8 9 92-10-2 9 6 6 6 75-10-5 9 8 5 7 9ferent settings of context window size (WINpre-WINmid-WINpost) for each domain.Table 4 shows the results of model order iden-tification without feature selection (Baseline) andwith feature selection based on different featureranking criterion( ?2 , Frequency and Entropy).The results show that the model order identifica-tion algorithm with feature selection based on en-tropy achieve best results: estimate cluster num-bers which are very close to the true values.
In ad-dition, we can find that with the context setting, 0-10-0, the estimated number of the clusters is equalor close to the ground truth value.
It demonstratesthat the intervening words less than 10 are appro-priate features to reflect the structure behind thecontexts, while the intervening words less than 5are not enough to infer the structure.
For the con-textual words beyond (before or after) the enti-ties, they tend to be noisy features for the relationestimation, as can be seen that the performancedeteriorates when taking them into consideration,especially for the case without feature selection.Table 5 gives a comparison of the aver-age accuracy over five different context win-dow size settings for different clustering settings.For each domain, we conducted five cluster-ing procedures: Hasegawa?s method, RLBaseline,RLFS?2 , RLFSFreq and RLFSEntropy.
ForHasegawa?s method (Hasegawa et al, 2004), weset the cluster number to be identical with thenumber of ground truth classes.
For RLBaseline,we use the estimated cluster number to clus-ter contexts without feature selection.
ForRLFS?2 ,RLFSFreq and RLFSEntropy, we usethe selected feature subset and the estimated clus-ter number to cluster the contexts, where the fea-ture subset comes from ?2, frequency and entropycriterion respectively.
Comparing the average ac-curacy of these clustering methods, we can findthat the performance of feature selection methodsis better than or comparable with the baseline sys-tem without feature selection.
Furthermore, it isnoted that RLFSEntropy achieves the highest av-erage accuracy in three domains, which indicatesthat entropy based feature pre-ranking providesuseful heuristic information for the selection ofimportant feature subset.Table 6 gives the automatically estimated labelsfor relation types for the domain PER-ORG.
Weselect two features as labels of each relation typeaccording to their DCM scores and calculate theaverage (and maximum) relatedness between ourselected labels (E) and the predefined labels (H).Following the same strategy, we also extracted re-lation labels (T) from the ground truth classes andprovided the relatedness between T and H. Fromthe column of relatedness (E-H), we can see that itis not easy to find the hand-tagged relation labelsexactly, furthermore, the identified labels from theground-truth classes are either not always compa-rable to the pre-defined labels in most cases (T-H).
The reason may be that the pre-defined rela-tion names tend to be some abstract labels overthe features, e.g., ?management?
vs. ?president?,266Table 5: Performance of the clustering algorithms over three domains: the average accuracy over 5 different context windowsize.Domain Hasegawa?smethodRLBaseline RLFS?2 RLFSFreq RLFSEntropyPER-ORG 32.4% 34.3% 33.9% 36.6% 41.3%ORG-GPE 43.7% 47.4% 47.1% 48.4% 50.6%ORG-ORG 26.5% 36.2% 36.0% 38.7% 42.4%Table 6: Relation Labelling using DCM strategy for the domain PER-ORG.
Here, (T) denotes the identified relation labelsfrom ground truth classes.
(E) is the identified relation labels from our estimated clusters.
?Ave (T-H)?
denotes the averagerelatedness between (T) and (H).
?Max (T-H)?
denotes the maximum relatedness between (T) and (H).Hand-tagged La-bel (H)Identified Label(T)Identified Label(E)Ave(T-H)Max(T-H)Ave(E-H)Max(E-H)Ave(E-T)Max(E-T)management head,president president,control 0.3703 0.4515 0.3148 0.3406 0.7443 1.0000general-staff work,fire work,charge 0.6254 0.7823 0.6411 0.7823 0.6900 1.0000member join,communist become,join 0.394 0.4519 0.1681 0.3360 0.3366 1.0000owner bond,bought belong,house 0.1351 0.2702 0.0804 0.1608 0.2489 0.4978located appear,include lobby,appear 0.0000 0.0000 0.1606 0.3213 0.2500 1.0000client hire,reader bought,consult 0.4378 0.8755 0.0000 0.0000 0.1417 0.5666affiliate-partner affiliate,associate assist,affiliate 0.9118 1.0000 0.5000 1.0000 0.5000 1.0000founder form,found invest,set 0.1516 0.3048 0.3437 0.6875 0.4376 0.6932?head?
or ?control?
; ?member?
vs.
?join?, ?be-come?, etc., while the abstract words and the fea-tures are located far away in Wordnet.
Table 6also lists the relatedness between (E) and (T).
Wecan see that the labels are comparable by theirmaximum relatedness(E-T).4 Conclusion and Future workIn this paper, we presented an unsupervised ap-proach for relation extraction from corpus.
Theadvantages of the proposed approach includesthat it doesn?t need any manual labelling of the re-lation instances, it can identify an important fea-ture subset and the number of the context clustersautomatically, and it can avoid extracting thosecommon words as characterization of relations.ReferencesMary Elaine Califf and Raymond J.Mooney.
1999.
Rela-tional Learning of Pattern-Match Rules for InformationExtraction, AAAI99.Sergey Brin.
1998.
Extracting patterns and relations fromworld wide web.
In Proc.
of WebDB?98.
pages 172-183.Kiyoshi Sudo, Satoshi Sekine and Ralph Grishman.
2003.An Improved Extraction Pattern Representation Modelfor Automatic IE Pattern Acquisition.
Proceedings of ACL2003; Sapporo, Japan.Eugene Agichtein and Luis Gravano.
2000.
Snowball: Ex-tracting Relations from large Plain-Text Collections, InProc.
of the 5th ACM International Conference on Digi-tal Libraries (ACMDL?00).Takaaki Hasegawa, Satoshi Sekine and Ralph Grishman.2004.
Discovering Relations among Named Entities fromLarge Corpora, ACL2004.
Barcelona, Spain.Dmitry Zelenko, Chinatsu Aone and Anthony Richardella.2002.
Kernel Methods for Relation Extraction,EMNLP2002.
Philadelphia.Lange,T., Braun,M.,Roth, V., and Buhmann,J.M.. 2002.Stability-Based Model Selection, Advances in Neural In-formation Processing Systems 15.Levine,E.
and Domany,E.. 2001.
Resampling Methodfor Unsupervised Estimation of Cluster Calidity, NeuralComputation, Vol.13, 2573-2593.Zhengyu Niu, Donghong Ji and Chew Lim Tan.
2004.
Doc-ument Clustering Based on Cluster Validation, CIKM?04.November 8-13, 2004, Washington, DC, USA.Volker Roth and Tilman Lange.
2003.
Feature Selection inClustering Problems, NIPS2003 workshop.Manoranjan Dash and Huan Liu.
2000.
Feature Selectionfor Clustering, Proceedings of Pacific-Asia Conferenceon Knowledge Discovery and Data Mining.Gabriel Pui Cheong Fung, Jeffrey Xu Yu and HongjunLu.
2002.
Discriminative Category Matching: Effi-cient Text Classification for Huge Document Collections,ICDM2002.
December 09-12, 2002, Japan.D.Lin.
1997.
Using syntactic dependency as a local contextto resolve word sense ambiguity.
In Proceedings of the35th Annual Meeting of ACL,.
Madrid, July 1997.Ted Pedersen, Siddharth Patwardhan and Jason Michelizzi.2004.
WordNet::Similarity-Measuring the Relatedness ofConcepts, AAAI2004.267
