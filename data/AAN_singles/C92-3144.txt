THE FIRST BUC REPORTJe f f  Go ldbergTheoret i ca l  L ingu is t i cs  P rogram,  Budapest  Un ivers i ty  (ELTE)Lhsz l6  K ~.1 ra~i.nResearch  Institute for Linguistics, BudapestTheoret i ca l  L ingu is t i cs  P rogram,  Budapest  Un ivers i ty  (ELTE)Depar tment  of Computat iona l  L ingu is t i cs ,  Un ivers i ty  of Amsterdam1.
I n t roduct ionThe Budapest  Un i f i cat ion  Grammar  (BUG)system described in this paper is a system for gener-ating natural anguage parsers from feature-structurebased grammatical descriptions (graamnars).
In thecurrent version, source grammars are limited to thecontext-free phrase structure grammar format.
BuGcompiles ource grmnmars into automata, which itcan then use for parsing input strings.BUG was developed at the ftesearch Institutefor Linguistics (Budapest) and at the TheoreticalLinguistics Program, Budapest University (ELTE)with the support of OTKA (National Funds forResearch) of the Hungarian Academy of Sciences.
Itwas written in C and is portable across Unix*, DOSand VMS.BUG differs from other unification-basedgrammar-writ ing tools in two major respects aswell as in a number of minor ways.
One majordifference is that nu(~ uses feature  geometr ies .The feature geometry is a (recursive) definitionof well-formed feature structures, which must bespecified in the source grammar.
The other majordifference is that BUG uses a built-in performancerestriction, called tile s t r ing  complet ion  l imit(SCL).
Using the string completion limit, we canlimit the generative power of a context-free grammarto regular languages.
The paper focuses on these twoinnovations as well as a third feature of huG, whichis the separation of the structural description(SD, conditions of application) from the structuralchange (SC, effect of application) in source rules.
* Unix is a trademark of AT&T.2.
Feature Geometr ies2.1.
What  Are  Feature  Geometr ies?Tile term feature  geometry  is taken from gen-erative phonology, where it was introduced byClements (1985).
A feature geometry determineswhat feature structures are allowed by specifyingwhat (complex or atomic) values each path in afeature structure can have.
In this way, a fea-ture geometry expresses certain kinds of featureco -occur rence  res t r i c t ions  (FCRs, Gazdar etal., 1985), namely, those FCRs that are local inthe sense that they can be formulated in terms ofpath continuation restrictions.
For example, we canincorporate the FCIt\[TENSE ~- PAST\] z:~ \[FINITE\]in a geometry by making TENSE a sub-feature of onlyFINITE (and PAST a possible value of TENSE).
On theotlmr hand, we cannot encode a global FCR like\[SUBJ DEF : +\] -:~ \[INDIR_OBJ NUMBER : PLURAL\].Also, we cannot encode a global FCR such as\[TENSE = PAST\] ~ \[AGREEMENT\]unless we make TENSE a sub-feature of AGREEMENTalone.
This is important because allowing arbitraryor global constraints on wen-fornmd feature struc-tures leads to undecidable systems if coupled withstructure sharing (Blackburn and Spaan, 1991).Our feature geometries, just like the ones used illphonology, specify whether or not the continuationsof a given path are pairwise incmnpatible.
Forexample, the attributes FINITE and NON-FINITE canbe made incompatible continuations of the attributeVERB_FORM.
As a result, in any actual featurestructure at most one edge can lead from a node thata path ending in VERB_FORM leads to.
What  thismechanism allows us to express are also local FCRs,e.g.~~(\[VERB..FORM FINITE\] A \[VERB-FORM NON-FINITE\])in this case.ACRES DE COLING-92, NANTES, 23-28 AO~' 1992 9 4 5 PaGe.
OF COLING-92, NANTES, AUG. 23-28, 19922.2 .
How Are  Feature  Geometr iesUsed?The main advantage of using feature geometriesis that it makes the unification operation andthe unifiabi\[ity test more efficient.
Traditionalunification only fails if atomic values clash, whereasgeometry-based unification will fail if incompatiblecontinuations of a path are to be unified.
As amatter of course, this means that an extra check isperformed each time new continuations are createdduring unification, lfowever, if the feature geometryis reasonably structured (i.e., not flat), then the costof this extra checking is significantly less than thegain from early unification failure.
In the typicalcase, the growth of the comparative advantage ofearly unification failurc over traditional unification(i.e., the proportion of all possibilities of failure tothe number of leaves) should grow faster than itscomparative disadvantage, i.e., the number of checks.If feature geometries are used as intended, thenthe major distinctions between linguistic objectsare made by attributes closer to the root of afeature structure, and minor features are in deeplysubordinate positions.
For example, the informationthat something is a verb will be superordinate o theinformation that it has a second person form.
As aconsequence, the most frequent reason for the failureof unification (which is a conflict between major classfeatures) will be detected earliest.
Typically, theopposite is true in traditional unification, i.e., onlyconflicts between terminal nodes of feature structuresare detected.
In such systems, major category clashesare found early enough only if the feature structuresare very fiat, which is undesirable for other reasons.Moreover, the use of feature geometries assiststhe grammar-writer to develop her/his grammar intwo ways.
First, requiring the grammar-writer tospecify a feature geometry and write rules accordinglyforces her/him to take the semantics of features andfeature structures more seriously than is typicallythe case.
Second, since feature geometries define theset of possible feature structures, they also determinewhich paths can share values.
The checking ofstructure sharing is not necessary during run-timeunification, because it can be succeaqfufiy dealt withat compile-time, thus providing additional errorchecking on the grammar.
These two by-productsof using feature geometries should lead to bettergrammar-writing.3.
The  St r ing  Complet ion  L imi t3.1.
What  I s  the  SCL?The str ing complet ion  l imit,  which is a smallinteger parameter of BUG's compiler, expresses aperformance limitation that BUG incorporates intothe automaton it produces.
Imposing constraints onthe complexity of derivation trees has a long traditionin linguistics.
Most proposals of this sort, such asYngve's (1961), which lirrfits the depth of possiblederivation trees, or limitations on the direction oftheir branching (e.g., Yngve, 1960) are either tooweak or too strong on their own.
However, there is asuggestion that we find broad enough in its coverage,and yet conceptually simple.
This is Kornai's (1984)hypothesis, in terms of which any string that canhe the beginning of a grammatical string can becompleted with k or less terminal symbols, wherek (i.e., the SCL) is a small integer.
For example,consider:(1) This is1 the2 dog3 that4 chaseds thes eat7 thatsate9 theto rat l l  that l2 stolel3 thel4 eheesel5thaq6In this string, each portion up to a numberedposition can be completed with at most one word,as the following table illustrates (position numbersare on the left, completions in the middle, and theminimum completion length K on the right):(1') 1,5,9, 13: .
.
.
John.
K= 12, 6, 10, 14: .
.
.
cheese.
K = 13, 7, 11, 15: .
.
.
.
K = 04, 8, 12, 16: .
.
.
st inks.
K = 1On the other hand, the following string, although itsportions up to each number are grammatical, will beexcluded if the SOL is smaller than 5:(2) The 1 cheese2 thats the4 rats that6 the7 eatsthats thoo  dogtt ehasedl~ ateis stolet4The corresponding table is:(2 t) 1: .
.
cheese st inks.2: .
.
ro~s.3: .
.
rots stinks.4: .
.
rat ate rots.5: .
.
ate rots.6: .
.
st inks ate rots.7: .
.
.
cat chased ate st inks.8: .
.
.
chased ate st inks.9: .
.
.
st inks ate stole rots.10: .
.
.
dog chased ate stole stinks.11: .
.
.
chased ale stole st inks.12: .
.
.
ate stole st inks.13: .
.
.
stole stinks.14: .
.
.
st inks.
(This seems to show that the SCL in termsmust be 3 or 4.
)K---2K=IK=2K---3K=2K=3K=4K=3K=4K---5K~4K=3K=2K=Iof wordsACRES DE COLING-92, NANTES, 23-28 AOt\]T 1992 9 4 6 PROC.
OF COL1NG-92, NANTEs, AUG. 23-28, 1992As (2) shows, the SCL imposes a limit on thedepth of center-embedding; but, as can be seenfrom (1), it does not constrain the depth of fight-branching structures.
Left branching, however, islimited, though the effect of this limitation is lesspronounced than in the case of center-embedding.The example with the highest K that we could findin English can be accommodated if k is 3:(3) Aflerl as verya(3') 1: .
.
.
walkiug~ sleep!
K : 22: .
.
.
walk, sleep!
K = "23: .
.
.
long walk, sleep!
K : 3Although the current implementation of BUGuses the context-free source grammar format, inwhich so-called cross-serial dependencies cannot beexpressed, it s worth noting that the SCL also putsan upper bound on tile length of these:(4) John, t Even Carlos3 and4 Peters marriedrespectivelys Sally, T Paul, s Susan9 andlalnez.
(4') 1: .
.
.
sleeps.
K = 12,3: .
.
.
and Peter sleep.
K =34: ._ Peter sleep.
K = 25: .. sleep.
K : 16: .. Sally, Paul, Susan and Iaez.
K = 57: .. Paul, Susan and lnez.
K = 48: .. Susan and lnez.
K = 39: .. and Inez.
K = 210: .. lncz.
K = 1The SCL has two additional consequences (andmaybe more).
First, it excludes certain lexicalcategories, uch as modifiers of adjective modifiers(if k < 4).
If, say, shlumma were a word of thatcategory, then we would need at least 4 words tocomplete After a shlumma.. .
(cf.
(3) above).
Second,all upper limit is placed on the uumber of obligatorydaughters of non-terminal nodes.3 ,2 .
How I s  the  SCL  Used?The way in which we can produce the biggest regularsubset of a context-free language that respects theSCL can be sketched as follows.
First we producean RTN (recursive transition network) equivalent tothe source grammar, call it A.
(An RTN is like afinite-state automaton, but its input symbols maybe RTNs or terminal symbols.)
Then we assign aminimum completion length (K in the tables above)to each node (accepting states will bare K = 0).
If Bis an RTN accepted by the transition from state stto state s2 in A, then we try to replace the transitionwith B itself, so that initial state of B becomes tand its accepting states become s~.
(This can bedone with standard techniques.)
Since the K-valueof s2 may be bigger than 0, assigning K values tosome states of B may be impossible (if those valueswould exceed k).
We leave out those states (andwhatever additional states and transitions depend onthem).In those cases when the above procedure wouldnot terminate (i.e., when s2 is an accepting statein A and B is the same RTN as some other RTNC the acceptance of which takes the machine tos~, we eliminate the transition corresponding to  B,and collapse sl with the initial state of C (with thestandard technique).
So the procedure will terminatein all cases.
In the current implementation, we usethe actual finite-state network so produced, but (asour reviewer notes) we could as well use the RTNdirectly, and compute whether the SCL is respectedas we go.
We have not made experiments withthis latter solution, so we cannot compare it withour current solution in terms of space and timerequirements.4.
SD Versus  SCOne of tile most important aznong BUG's featuresis the separation of s t ructura l  descr ipt ions  froms t ructura l  changes  in source rules.
Although theunificationalists have been asserting that this old-fashioned istinction should be abandoned (arguingthat pieces of information coming from differentsources have the same status), many voices havebeen raised to show that the origins of a piece ofinformation may matter (see Zaenen and Karttunen,1984; Pullum and Zwicky, 1986; Ingria.
1990).The structural description in a BUG rule specifiesthe conditions under which the rule cml be appliedin the parsing process.
That is, when parsing, itrefers to the right-hand side of the rewrite rule only,and it is never used to update any feature structure.The structural change, on the other hand, describeswbat action to take when the structural descriptionis satisfied, i.e., how to build a new feature structure(when parsing, this corresponds to the left-handside of tile context-free rule).
Tbus, structuraldescriptions are used to check unifiability, whereasthe application of structural changes actually buildsstructure.In usual unification-based grammars, the con-ditions of applying a rule are satisfied if someunification succeeds.
In BUG, what determineswhether a rule should apply is unifiability.
Unifiabil-ity differs from unification in a crucial respect,which is illustrated by the following example:A: \[1B: \[NUMBER = SINGULAR\]C: \[NUMBER = PLURAL\]A is unifiable with B and A is unifiable with C,even though B is not unifiable with C. Therefore,if a structural description requires unifiability of AAcrEs DE COLING-92, NANTES.
23-28 AOOT 1992 9 4 7 PROC.
OF COLlNG-92, NAMES.
AUQ.
23-28, 1992with both B and C, it will be satisfied.
IIowever,if we were to formulate tiffs requirement in terms ofunification, as is currently done in unification-basedgrammars, then A, B and C will not satisfy thisrequirement.
A similar example from 'real life' isthe requirement that the auxiliary verb should agreewith each subject of a co-ordination:(5) *Is/*Are Jean leaving and the others arrzving?In this example, SUMNER of is is not unifiable withthat of lhe ethers, and NUMBER of arc is not unifiablewith that of Jean, so traditional unification-basedgrammars and BUG would yield the same (correct)result.
Now, consider:(6) Will Jean leave and the others arrive?This sentence is in because will's NUMBER is unifiablewith both that of Jean and that of the others,although the unification of all three NUMBEII.
valuesstill leads to failure.
So sou  will behave correctly inthis case.5 ,  Generat ive  Capac i tySomewhat misleadingly, we have avoided so far mak-hag a distinction between the context-free grammarformat and context-free grammars.
In actual fact,it is well-known that a unification-based grammarin the context-free format is not context-free unlessthe number of possible feature structures arising inall its possible derivations is finite.
By the sametoken, the automata compiled by BU~ would notrecognize a regular language if we did not constrainthe possible feature structures that they give riseto.
The separation of SDs from SCS allows ~IUGto avoid this problem.
Since SDs are only used inunifiability tests and are never modified at run-time,they can be constrained in such a way that theyyield a finite set of equivalence classes of featurestructures.
Moreover, carrying out SCs only affectsthe structures being built and cannot interfere withthe trajectory through the automaton.
Incidentally,this means that unification (but not unifiabilitytests!)
may never fail.
For that purpose, we use anassociative, idempotent and commutative version of'default unification' (see Bouma, 1990), which weare not going into here.
The automaton producedby BU~ is, thus, actually finite-state.
We considerthis an extremely important benefit, if not the mostimportant one, of separating SDs from SCs in agrammar-writ ing system.ReferencesBlackburn, Patrick and Edith Spaan.
1991.
'Somecomplexity results for Attribute Value Struc-tures'. '
ib appear in: Proceedings of the EightbAmsterdam Colloquium.Bouma, Gosse.
1990.
'Defaults in unification gram-mar', In: Proceedings of the 28th Annum Meet-ing of the ACL, ACL, Pittsburgh.Clements, George N. 1985.
'The geometry of phono-logical features'.
Phonology Yearbook 2, 223-250.Gazdar, Gerald, Ewan Klein, Geoffrey Pullum andIvan Sag.
1985.
Generalized Phrase StructureGrammar.
Harvard University Press, CambridgeMA.Ingria, Robert J.P. 1999.
'The limits of unification'.In: 28th Annum Meeting of ACL: Proceedings ofthe Conference.
ACL, Morristown, NJ.
Pp.
194-204.Kornai, Andre .
1984.
'Natural Languages and theChomsky Hierarchy'.
In: Proceedings of theACL Second European Chapter Conference.ACL, Geneva.
Pp.
1-7.Pullum, Geoffrey K., mad Arnold M. Zwicky.
1986.
'Phonological resolution of syntactic featureconflict'.
Language 62, 751-773.Zaenen, Annie and Lauri Karttunen.
1984.
'Morpho-logical non-distinctness and co-ordination'.
In:ESCOL 84, pp.
309-320.Yngve, Victor II.
1961.
'The depth hypothesis'.Language 61, 283-305.Yngve, Victor It.
1960.
'A model and an hypothesisfor language structure'.
Proceedings of theAmerican PhilosophicM Society 104, 444 466.ACTES DE COLING-92, NANTES.
23-28 AOt3"r 1992 9 4 8 PROC.
OF COLING-92.
NANTES.
AUG. 23-28, 1992Append ix :  Example  BUG source filesand run;c,eometry for simple categorial grammar; Major features: category and semantics,?
both of them may be present?
at the same time< > = {cat sem}; Category is simple or complex; (but not both):<cat> = \[simple complex\]; Simple category is np, s or n:<cat  simple> = Lap s n\]; A complex category consists of an input,?
a result, and a slash:<cat complex> = {inp res slash); The input must be a simple category here:<cat complex inp> = <sat simple>; The result may be any category:<cat complex res> = <cat>; The slash is either forward or backward:<cat complex slash> = \[forw back\]; SemaJ1tics is analogous to category:<sem> = \[sim cam\]; (no constraint on simple values)<sere cam> = {fun arg)<sem cam fu~> = <sem><sem cam art> = <sem>;End of geometry; .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
;Start category:; Name of start category:Sentence; SD:; it has to be o5 category s:<Sentence cat simple s>; SC:; only the semantics is kept:<sem> = <Sentence sem>;End o5 start category; .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
;Rules:; The name o5 forward application rule:"Forward application"; Production schema:RES -~> FUN ARC,; SD:; FUN must be a complex category; with forward slash:<FUN cat complex slash forw>; ARC, must have a simple category:<ARG cat simple>; FUN's input must be ARG's category:<FUN cat complex inp> == <ARG cat simple>; SC:; RES's category  is FUM's result:<cat> = <FUN cat  complex res>; RES's semantics is as expected:<sam cola fun> = <FUN sam><sam cam arg>= <ARC, sam>; .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
; Backward application is very similar:"Backward application"RES --> ARC, FUN<FUN cat complex slash back><ARC, cat simple><FUN cat complex inp> == <ARC, cat simple><cat> = <FUN cat complex ~es><sem cam fun> = <FUN sem><sem cam arg>= <ARG sem>;End of rules................................;Sample lexical items:?
'-' indicates the beginning of a lexicon:"Joe" ; np 'JOE'<cat simple up><sere sire JOE>"hit" ; (s\np)/np 'HIT'; Note how parentheses can be used?
for abbreviation:<cat complex> (<inp np><res complex><lap up><res simple s><slash back>)<slash ~oru>)<sere sire HIT>"the" ; np/n 'THE'<cat complex> (<inp n><res simple up><slash foru>)<sere sire THE>"ball" ; n 'BALL'<cat simple n><sere sim BALL>;End of lexical items#Example run:Y, bug -i cat cat(Re-)compiling cat.gs --> cat .go .
(Re- )compi l ing  lex icon  cat .
l s  - ->  cat .
lo .Joeh i ttheba l lLoading lexicon cat.lo.==> Joe hit the ball.sem cam art sim JDEfun cam fun sire HITart cam fun sire THEar t  sire BALLAc ixs  DE CO\[ , ING-92,  NANJES, 23-28 Aour  1992 9 4 9 I'ROC.
OF COL1NG-92,  NANTES, AUG. 23-28.
1992
