Idiomatic object usage and support verbsPasi Tapanainen, Jussi Pi itulainen and Timo J~irvinen*Research Unit for Multilingual Language TechnologyP.O.
Box 4, FIN-00014 University of Helsinki, Finlandhttp ://www.
ling.
helsinki, fi/1 In t roduct ionEvery language contains complex expressionsthat are language-specific.
The general prob-lem when trying to build automated translationsystems or human-readable dictionaries i  to de-tect expressions that can be used idiomaticallyand then whether the expressions can be usedidiomatically in a particular text, or whethera literal translation would be preferred.
It fol-lows from the definition of idiomatic expressionthat when a complex expression is used idiomat-ically, it contains at least one element which issemantically "out of context".
In this paper,we discuss a method that finds idiomatic col-locations in a text corpus.
The method etectssemantic asymmetry by taking advantage ofdif-ferences in syntactic distributions.We demonstrate the method using a spe-cific linguistic phenomenon, verb-object collo-cations.
The asymmetry between a verb and itsobject is the focus in our work, and it makes theapproach different from the methods that usee.g.
mutual information, which is a symmetricmeasure.Our novel approach differs from mutual infor-mation and the so-called t-value measures thathave been widely used for similar tasks, e.g.,Church et al (1994) and Breidt (1993) for Ger-man.
The tasks where mutual information canbe applied are very different in nature as wesee in the short comparison at the end of thispaper.
The work reported in Grefenstette andTeufel (1995) for finding empty support verbsused in nominallsations is also related to thepresent work.
* Emai l :  Pasi.Tapanainen@ling.helsinki.fi, Jussi.Piitu-lainen~ling.helsinki.fi and Timo.Jarvinen@ling.helsin-ki.\]i, Parsers  & demos:  http://www.conezor.~2 Semantic asymmetryThe linguistic hypothesis that syntactic rela-tions, such as subject-verb and object-verb re-lations, are semantically asymmetric in a sys-tematic way (Keenan, 1979) is well-known.
Mc-Glashan (1993, p. 213) discusses Keenan's prin-ciples concerning directionality ofagreement re-lations and concludes that semantic interpreta-tion of functor categories varies with argumentcategories, but not vice versa.
He cites Keenanwho argues that the meaning of a transitive verbdepends on the object, for example the mean-ing of the verb cut seems to vary with the directobject:?
in cut finger "to make an incision on thesurface of",?
in cut cake "to divide into portions",?
in cut lawn "to trim" and?
in cut heroin "diminish the potency".This phenomenon is also called semantic tailor-ing (Allerton, 1982, p. 27).There are two different ypes of asymmetricexpressions even if they probably form a con-tinuum: those in which the sense of the functoris modified or selected by a dependent elementand those in which the functor is semanticallyempty.
The former type is represented by theverb cut above: a distinct sense is selected ac-cording to the (type of) object.
The latter typecontains an object hat forms a fixed collocationwith a semantically empty verb.
These pairingsare usually language-specific and semanticallyunpredictable.Obviously, the amount of tailoring varies con-siderably.
At one end of the continuum is id-iomatic usage.
It is conceivable that even ahighly idiomatic expression like taking toll can1289be used non-idiomatically.
There may be textswhere the word toll is used non-idiomatically, asit also may occur from time to time in any textas, for instance, in The Times corpus: The IRAcould be profiting by charging a toll for cross-border smuggling.
But when it appears in asentence like Barcelona's fierce summer is tak-ing its toll, it is clearly a part of an idiomaticexpression.3 D is t r ibuted  f requency  o f  an  ob jec tAs the discussion in the preceding chaptershows, we assume that when there is a verb-object collocation that can be used idiomati-cally, it is the object that is the more interestingelement.
The objects in idiomatic usages tendto have a distinctive distribution.
If an objectappears only with one verb (or few verbs) in alarge corpus we expect that it has an idiomaticnature.
The previous example of take toll is il-lustrative: if the word toll appears only with theverb take but nothing else is done with tolls, wemay then assume that it is not the toll in theliterary sense that the text is about.The task is thus to collect verb-object colloca-tions where the object appears in a corpus withfew verbs; then study the collocations that aretopmost in the decreasing order of frequency.The restriction that the object is always at-tached to the same verb is too strict.
Whenwe applied it to ten million words of newspapertext, we found out that even the most frequentof such expressions, make amends and takeprecedence, appeared less than twenty times,and the expressions have temerity, go berserkand go ex-dividend were even less frequent.
Itwas hard to obtain more collocations becausetheir frequency went very low.
Then expres-sions like have appendix were equivalently ex-posed with expressions like run errand.Therefore, instead of taking the objects thatoccur with only one verb, we take all objects anddistribute them over their verbs.
This meansthat we are concerned with all occurrences of anobject as a block, and give the block the scorethat is the frequency of the object divided bythe number of different verbs that appear withthe object.The formula is now as follows.
Let o be anobject and let(F~, V~, o), .
.
.
, (Fn, Vn, o)be triples where Fj > 0 is the frequency or therelative frequency of the collocation of o as anobject of the verb ~ in a corpus.
Then the scorefor the object o is the sum ~- -1  F~/n.The frequency of a given object is divided bythe number of different verbs taking this givenobject.
If the number of occurrences of a givenobject grows, the score increases.
If the objectappears with many different verbs, the score de-creases.
Thus the formula favours common ob-jects that are used in a specific sense in a givencorpus.This scheme still needs some parameters.First, the distribution of the verbs is not takeninto account.
The score is the same in thecase where an object occurs with three differentverbs with the frequencies, say, 100, 100, and100, and in the case where the frequencies ofthe three heads are 280, 10 and 10.
In this case,we want to favour the latter object, becausethe verb-object relation seems to be more stablewith a small number of exceptions.
One way todo this is to sum up the squares of the frequen-cies instead of the frequencies themselves.Second, it is not clear what the optimalpenalty is for multiple verbs with a given ob-ject.
This may be parametrised by scaling thedenominator of the formula.
Third, we intro-duce a threshold frequency for collocations othat only the collocations that occur frequentlyenough are used in the calculations.
This lastmodification is crucial when an automatic pars-ing system is applied because it eliminates in-frequent parsing errors.The final formula for the distributed fre-quency DF(o)  of the object o in a corpus ofn triples (Fj, Vj, o) with Fj > C is the sum4=1 nbwhere a, b and C are constants that may dependon the corpus and the parser.4 The  corpora  and  pars ing4.1 The  syntact i c  parserWe used the Conexor Functional Depen-dency Grammar (FDG) by Tapanainen andJ~rvinen (1997) for finding the syntactic rela-tions.
The new version of the syntactic parsercan be tested at h t tp : / /www,  conexor .
f i .12904.2 Processing the corporaWe analysed the corpora with the syntacticparser and collected the verb-object collocationsfrom the output.
The verb may be in the infini-tive, participle or finite form.
A noun phrase inthe object function is represented by its head.For instance, the sentence I saw a big black catgenerates the pair (see, cat I.
A verb may alsohave an infinitive clause as its object.
In such acase, the object is represented by the infinitive,with the infinitive marker if present.
Naturally,transitive nonfinite verbs can have objects oftheir own.
Therefore, for instance, the sentenceI want to visit Paris generates two verb-objectspairs: (want, to visit) and (visit, Paris).
Theparser ecognises also clauses, e.g.
that-clauses,as objects.We collect the verbs and head words of nom-inal objects from the parser's output.
Othersyntactic arguments are ignored.
The outputis normalised to the baseforms o that, for in-stance, the clause He made only three real mis-takes produces the normalised pair: (make,mistake).
The tokenisation i the lexical anal-ysis produces some "compound nouns" likevice?president, which are glued together.
Weregard these compounds as single tokens.The intricate borderline between an object,object adverbial and mere adverbial nominal isof little importance here, because the latter tendto be idiomatic anyway.
More importantly, dueto the use of a syntactic parser, the presence ofother arguments, e.g.
subject, predicative com-plement or indirect object, do not affect he re-sult.5 Exper imentsIn our experiment, we used some ten mil-lion words from a The Times newspaper cor-pus, taken from the Bank of English corpora(J~irvinen, 1994).
The overall quality of the re-sult collocations i good.
The verb-object collo-cations with highest distributed object frequen-cies seem to be very idiomatic (Table 1).The collocations seem to have different statusin different corpora.
Some collocations appearin every corpus in a relatively high position.
Forexample, collocations like take toll, give birthand make mistake are common English expres-sions.Some other collocations are corpus spe-DF(o) F(vo)37.50 7328.00 2825.00 2524.83 6022.00 2221.00 2121.00 2121.00 2120.40 9319.50 2819.25 12818.00 1818.00 1817.50 7617.50 6117.25 6217.04 81717.00 1717.00 1716.29 15216.17 31916.00 1616.00 1615.69 24815.57 8415.00 1514.57 19014.50 2714.50 1614.47 16514.14 11014.12 32914.00 13314.00 1414.00 1414.00 1414.00 1413.90 22613.63 13113.50 25verb + objecttake tollgo bustmake plainmark anniversaryfinish seventhmake inroaddo homeworkhave hesitationgive birthhave a=gomake mistakego so=far=astake precautionlook as=thoughcommit suicidepay tributetake placemake mockerymake headwaytake wicketcost ?have qualmmake pilgrimagetake advantagemake debuthave second=thoughtdo jobfinish sixthsuffer heartattackdecide whetherhave impacthave chancegive warnhave sexual=intercoursetake plungehave misfortunethank goodnesshave nothingmake moneystrike chordTable 1: Verb-object collocations from TheTimescific.
An experiment with the Wall StreetJournal corpus contains collocations like namevice-/-precident and file lawsuit that are rare inthe British corpora.
These expressions could becategorised ascultural or area specific.
They are1291F MI t-value Verb + object(scaled) (scaled)1512111412132112181013121117131112119.47 3.878.62 3.468.48 3.328.42 3.748.30 3.468.21 3.60wreak havocarmour carriergrasp nettlefirm lpbury Edmundweather storm8.18 4.588.17 3.468.10 4.248.10 3.168.05 3.608.03 3.467.92 3.317.91 4.127.91 3.607.80 3.317.72 3.467.72 3.31bid farewellstrut stuffbreathe sighsuck toeincur wrathinvade Kuwaitprotest innocencehole puttpoke funtighten beltstem tideheal woundTable 2: Collocations according to mutual in-formation filtered with t-value of 3frequency verb329 have302274256247229226210203186164155142139138135132123122119+ objectchancehave ithave timehave effecthave righthave problemhave nothinghave littlehave ideahave powerhave whathave muchhave childhave experiencehave somehave reasonhave onehave advantagehave intentionhave planTable 4: What do we have?
- Top-20position verb + object124157478770862100910331225124419422155finish seventhmark anniversarygo bustdo homeworkgive birthmake inroadtake tollmake mistakemake plainhave hesitationhave a--goTable 3: The order of top collocations accordingto mutual informationlikely to appear again in other issues of WSJ  orin other American newspapers.6 Mutua l  in fo rmat ionMutual information between a verb and its ob-ject was also computed for comparison with ourmethod.
The collocations from The Times withthe highest mutual information and high t-valueare listed in Table 2.
See Church et al (1994)for further information.
We selected the t-valueso that it does not filter out the collocations ofTable 1.
Mutual information is computed froma list of verb-object collocations.The first impression~ when comparing Ta-bles 1 and 2, is that the collocations in the latterare somewhat more marginal though clearly se-mantically motivated.
The second observationis that the top collocations contain mostly rarewords and parsing errors made by the underly-ing syntactic parser; three out of the top fivepairs are parsing errors.We tested how the top ten pairs of Table 1 arerated by mutual information.
The result is inTable 3 where the position denotes the positionwhen sorted according to mutual informationand filtered by the t-value.
The t-value is se-lected so that it does not filter out the top pairsin Table 1.
Without filtering, the positions arein range between 32 640 and 158091.
The re-sult shows clearly how different the nature ofmutual information is.
Here it seems to favourpairs that we would like to rule out and viceversa.1292frequency verb + object21281615110329141422613511727441282561817101010have hesitationhave a--gohave qualmhave second=thoughthave impacthave chancehave sexual=intercoursehave misfortunehave nothinghave reasonhave choicehave timehave regardhave no=doubthave effecthave bedroomhave regrethave penchanthave pedigreehave cloutTable 5: The collocations of the verb havesorted according to the DF function7 F requencyIn a related piece of work, Hindle (1994) used aparser to study what can be done with a givennoun or what kind of objects a given verb mayget.
If we collect the most frequent objects forthe verb have, we are answering the question:"What do we usually have?"
(see Table 4).
Thedistributed frequency of the object gives a dif-ferent flavour to the task: if we collect the collo-cations in the order of the distributed frequencyof the object, we are answering the question:"What do we only have?"
(see Table 5).8 Conc lus ionThis paper was concerned with the semanticasymmetry which appears as syntactic asym-metry in the output of a syntactic parser.
Thisasymmetry is quantified by the presented is-tributed frequency function.
The function canbe used to collect and sort the collocations othat the (verb-object) collocations where theasymmetry between the elements i  the largestcome first.
Because the semantic asymmetry isrelated to the idiomaticity of the expressions,we have obtained a fully automated method tofind idiomatic expressions from large corpora.ReferencesD.
J. Allerton.
1982.
Valency and the Engli.shVerb.
London: Academic Press.Elisabeth Breidt.
1993.
Extraction of V-N-collocations from text corpora: A feasibilitystudy for German.
Proceedings of the Work-shop on Very Large Corpora: Academic andIndustrial Perspectives, pages 74-83, June.Kenneth Ward Church, William Gale, PatrickHanks, Donald Hindle, and Rosamund Moon.1994.
Lexical substitutability.
In B.T.S.Atkins and A Zampolli, editors, Computa-tional Approaches to the Lexicon, pages 153-177.
Oxford: Clarendon Press.Gregory Grefenstette and Simone Teufel.
1995.Corpus-based method for automatic identifi-cation of support verbs for nominalizations.Proceedings of the 7th Conference of the Eu-ropean Chapter of the A CL, March 27-31.Donald Hindle.
1994.
A parser for text corpora.In B.T.S.
Atkins and A Zampolli, editors,Computational Approaches to the Lexicon,pages 103-151.
Oxford: Clarendon Press.J~irvinen, Timo.
1994.
Annotating 200 Mil-lion Words: The Bank of English Project.COLING 94.
The 15th International Confer-ence on Computational Linguistics Proceed-ings.
pages 565-568.
Kyoto: Coling94 Orga-nizing Committee.Edward L. Keenan.
1979.
On surface form andlogical form.
Studies in the Linguistic Sci-ences, (8):163-203.
Reprinted in Edward L.Keenan (1987).
Universal Grammar: fifteenessays.
London: Croom Helm.
375-428.Scott McGlashan.
1993.
Heads and lexical se-mantics.
In Greville G. Corbett, Norman M.Fraser, and Scott McGlashan, editors, Headsin Grammatical Theory, pages 204-230.
Cam-bridge: CUP.Pasi Tapanainen and Timo J~irvinen.
1997.
Anon-projective dependency parser.
In Pro-ceedings of the 5th Conference on AppliedNatural Language Processing, pages 64-71,Washington, D.C.: ACL.1293
