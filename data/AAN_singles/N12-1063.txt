2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 548?552,Montre?al, Canada, June 3-8, 2012. c?2012 Association for Computational LinguisticsRanking-based readability assessment for early primary children?s literatureYi Ma, Eric Fosler-LussierDept.
of Computer Science & EngineeringThe Ohio State UniversityColumbus, OH 43210, USAmay,fosler@cse.ohio-state.eduRobert LofthusXerox CorporationRochester, NY 14604, USARobert.Lofthus@xerox.comAbstractDetermining the reading level of children?s lit-erature is an important task for providing edu-cators and parents with an appropriate readingtrajectory through a curriculum.
Automatingthis process has been a challenge addressedbefore in the computational linguistics litera-ture, with most studies attempting to predictthe particular grade level of a text.
However,guided reading levels developed by educatorsoperate at a more fine-grained level, with mul-tiple levels corresponding to each grade.
Wefind that ranking performs much better thanclassification at the fine-grained leveling task,and that features derived from the visual lay-out of a book are just as predictive as standardtext features of level; including both sets offeatures, we find that we can predict the read-ing level up to 83% of the time on a small cor-pus of children?s books.1 IntroductionDetermining the reading level of a text has receivedsignificant attention in the literature, dating back tosimple arithmetic metrics to assess the reading levelbased on syllable counts (Flesch, 1948).
In the com-putational linguistics community, several projectshave attempted to determine the grade level of a text(2nd/3rd/4th/etc).
However, the education commu-nity typically makes finer distinctions in reading lev-els, with each grade being covered by multiple lev-els.
Moreover, there are multiple scales within theeducational community; for example 1st grade is ap-proximately covered by levels 3?14 on the ReadingRecovery scale,1 or levels C to H in the Fountas andPinnell leveling system.2For grade-level assessment, classification andregression approaches have been very promising.However, it is not clear that an increased number ofclasses will allow classification techniques to suc-ceed with a more fine-grained leveling system.
Sim-ilarly, regression techniques may have problems ifthe reading levels are not linearly distributed.
In thiswork, we investigate a ranking approach to book lev-eling, and apply this to a fine-grained leveling prob-lem for Kindergarten through 2nd grade books.
Theranking approach also allows us to be more agnosticto the particular leveling system: for the vast ma-jority of pairs of books, different systems will rankthe levels of the books the same way, even if theexact differences in levels are not the same.
Sincemost previous work uses classification techniques,we compare against an SVM multi-class classifieras well as an SVM regression approach.What has not received much attention in recentresearch is the visual layout of the page.
Yet, if onewalks into a bookstore and rummages through thechildren?s section, it is very easy to tell the readinglevel of a book just by thumbing through the pages.Visual clues such as the number of text lines perpage, or the area of text boxes relative to the illustra-tions, or the font size, give instant information to thereader about the reading level of the book.
What isnot clear is if this information is sensitive enough todeliver a fine-grained assessment of the book.
While1http://www.readingrecovery.org2http://www.fountasandpinnellleveledbooks.com548publishers may have standard guidelines for contentproviders on visual layout, these guidelines likelydiffer from publisher to publisher and are not avail-able for the general public.
Moreover, in the digi-tal age teachers are also content providers who donot have access to these guidelines, so our proposedranking system would be very helpful as they cre-ate reading materials such as worksheets, web pages,etc.2 Related WorkDue to the limitations of traditional approaches,more advanced methods which use statistical lan-guage processing techniques have been introducedby recent work in this area (Collins-Thompson andCallan, 2004; Schwarm and Ostendorf, 2005; Fenget al, 2010).
Collins-Thompson and Callan (2004)used a smoothed unigram language model to pre-dict the grade reading levels of web page documentsand short passages.
Heilman et al (2007) com-bined a language modeling approach with grammar-based features to improve readability assessment forfirst and second language texts.
Schwarm/Petersenand Ostendorf (2005; 2009) used a support vectormachine to combine surface features with languagemodels and parsed features.
The datasets used inthese previous related works mostly consist of webpage documents and short passages, or articles fromeducational newspapers.
Since the datasets used aretext-intensive, many efforts have been made to in-vestigate text properties at a higher linguistic level,such as discourse analysis, language modeling, part-of-speech and parsed-based features.
However, tothe best of our knowledge, no prior work attempts torank scanned children?s books (in fine-grained read-ing levels) directly by analyzing the visual layout ofthe page.3 Ranking Book Leveling AlgorithmOur proposed method can be regarded as a modi-fied version of a standard ranking algorithm, wherewe develop a leveling classification by first rank-ing books, and then assigning the level based onthe ranking output.
Given a set of leveled books,the process to generate a prediction for a new targetbook involves the following two steps.In the first step, we extract features from eachbook, and train an off-the-shelf ranking model tominimize the pairwise error of books.
During thetest phase (second step), we rank all of the leveledtraining books as well as the new target (test) bookusing the trained ranking model.
The predicted read-ing level of the target book then can be inferred fromthe reading levels of neighboring leveled books inthe rank-ordered list of books (in our experiment, wetake into account a window of three books above andbelow the target book with reading levels weightedby distance).
Intuitively, we can imagine a book-shelf in which books are sorted by their reading lev-els.
The ranker?s prediction of the reading level of atarget book corresponds to inserting the target bookinto the sorted bookshelf.4 Data Preparation4.1 Book Selection, Scanning and MarkupWe have processed 36 children?s books which rangefrom reading level A to L (3 books each level).
Thegolden standard key reading levels of those booksare obtained from Fountas and Pinnell leveled booklist (Fountas and Pinnell, 1996) in which letter A in-dicates the easiest books to read and letter L iden-tifies more challenging books; this range coversroughly Kindergarten through Second Grade.
Theset of children?s books covers a large variety of gen-res, series and publishers.After seeking permission from the publishers,3all of the books are scanned and OCRed (OpticalCharacter Recognized) to create PDF versions ofthe book.
In order to facilitate the feature extrac-tion process, we manually annotate each book usingAdobe Acrobat markup drawing tools before con-verting them into corresponding XML files.
Theannotation process consists of two straightforwardsteps: first, draw surrounding rectangles around thelocation of text content; second, find where the pri-mary illustration images are and mark them usingrectangle markups.
Then the corresponding XMLcan be generated directly from Adobe Acrobat withone click on a customized menu item, which is im-plemented by using Adobe Acrobat JavaScript API.3This is perhaps the most time-consuming part of the pro-cess.549# of partitions 1 2 3 4?1 Accuracy %SVM Ranker 72.2 69.4 80.6 83.3SVM Classifier 47.2 61.1 55.6 63.9SVM Regression 72.2 61.1 58.3 58.3Flesch-Kincaid 30.6 30.6 30.6 19.4Spache 27.8 13.9 13.9 11.1Average leveling error ?
standard deviationSVM Ranker 1.00 ?
0.99 1.03 ?
0.91 0.94 ?
0.83 0.92 ?
0.73SVM Classifier 2.00 ?
1.60 1.86 ?
1.69 1.78 ?
1.57 1.44 ?
1.23SVM Regression 1.14 ?
1.13 1.25 ?
1.11 1.33 ?
1.22 1.36 ?
1.22Flesch-Kincaid 3.03 ?
2.21 3.03 ?
2.29 3.08 ?
2.31 3.31 ?
2.28Spache 4.06 ?
3.33 4.72 ?
3.27 4.83 ?
3.34 5.19 ?
3.21Table 1: Per-book (averaged) results for ranking versus classification, reporting accuracy within one level and averageerror for different numbers of partitions4.2 Feature Design4.2.1 Surface-level FeaturesWe extract a number of purely text-based featuresthat have typically been used in the education litera-ture (e.g., (Flesch, 1948)), including:1.
Number of words; 2.
Number of letters perword; 3.
Number of sentences; 4.
Average sentencelength; 5.
Type-token ratio of the text content.4.2.2 Visually-oriented FeaturesIn this feature set, we include a number of featuresthat would not be available without looking at thephysical layout of the page; with the annotated PDFversions of the book we are able to extract:1.
Page count; 2.
Number of words per page; 3.Number of sentences per page; 4.
Number of textlines per page; 5.
Number of words per text line;6.
Number of words per annotated text rectangle;7.
Number of text lines per annotated text rectan-gle; 8.
Average ratio of annotated text rectangle areato page area; 9.
Average ratio of annotated imagerectangle area to page area; 10.
Average ratio of an-notated text rectangle area to annotated image rect-angle area; 11.
Average font size.The OCR process provides some of this informa-tion automatically; while we have manually anno-tated rectangles for this study one could theoreti-cally use the OCR information and vision process-ing techniques to extract rectangles automatically.5 Experiments5.1 Ranking vs. Classification/RegressionIn this experiment, we look at whether treating bookleveling as a ranking problem is promising com-pared to using classification/regression techniques.Besides taking a whole book as input, we also exper-iment with partitioning each book uniformly into 2,3, or 4 parts, treating each sub-book as an indepen-dent entity.
We use a leave-n-out paradigm ?
dur-ing each iteration of the training (iterated through allbooks), the system leaves out all n partitions corre-sponding to one book and then tests on all partitionscorresponding to the held-out book.
By averagingthe results for the partitions of the held-out book, wecan obtain its predicted reading level.For ranking, we use the SVMrank ranker(Joachims, 2006), which learns a (sparse) weightvector that minimizes the number of swapped pairsin the training set.
The test book is inserted into theordering of the training books by the ranking algo-rithm, and the level is assigned by averaging the lev-els of the books above and below the order.
To com-pare the performance of our method with classifiers,we use both SVMmulticlass classifier (Tsochantaridiset al, 2004) and SVMlight (with regression learningoption) (Joachims, 1999) to determine the level ofthe book directly.
All systems are given the sameset of surface text-based and visual-based features(Sections 4.2.1 and 4.2.2) as input.550# of partitions 1 2 3 4?1 Accuracy %All Features 72.2 69.4 80.6 83.3Surface Features 61.1 63.9 58.3 61.1Visual Features 72.2 72.2 72.2 83.3Average leveling error ?
standard deviationAll Features 1.00 ?
0.99 1.03 ?
0.91 0.94 ?
0.83 0.92 ?
0.73Surface Features 1.42 ?
1.18 1.28 ?
1.00 1.44 ?
0.91 1.28 ?
1.11Visual Features 1.03 ?
0.88 0.94 ?
0.86 1.03 ?
0.81 0.89 ?
0.82Table 2: Per-book (averaged) results for all, surface-only, and visual-only features, reporting accuracy within one leveland average error for different numbers of partitionsWe score the systems in two ways: first, we com-pute the accuracy of the system by claiming it is cor-rect if the book level is within ?1 of the true level.4The second scoring method is the absolute error ofnumber of levels away from the true value, averagedover all of the books.As we can observe from Table 1, our rankingsystem constantly beats the other two approaches(the ranker is statistically significantly better thanthe classifier at p < 0.05 level ?
figures in bold).One bit of interesting discovery is that SVM regres-sion needs more data in order to have reliable results,as the performance is downgraded when the numberof partitions goes up; the ranking approach benefitsfrom averaging the increasing number of partitions.5All three methods have the same style of learner(support vector learning), which suggests that theperformance gain is due to using a ranking crite-rion in our method.
Therefore we believe rankingis likely a more effective and accurate method thanclassification for this task.One might also wonder how a traditional measureof reading level (in this case, the Flesch-Kincaid(Flesch, 1948) and Spache (Spache, 1953) GradeLevel) would hold up for this data.
Flesch-Kincaidand Spache predictions are linearly converted fromcalculated grade levels to Fountas-Pinnell levels; allof the systems utilizing our full feature set outper-form these two baselines by a significant amount onboth ?1 accuracy and average leveling error.4Note that this is still rather fine-grained as there are multi-ple book levels per grade level.5We only partition the books up to 4 sub-books because theshortest book we have only contains 4 PDF pages (8 ?book?pages) and further partitioning the book will lead to sparse data.5.2 Visual vs.
Surface FeaturesIn order to evaluate the benefits of using visual cuesto assess reading levels, we repeat the experimentsusing SVMrank based on our proposed ranking bookleveling algorithm with only the visual features oronly surface features.Table 2 shows that the visual features surprisinglyoutperform the surface features (statistically signif-icant at p < 0.05 level ?
figures in bold) and onsome partition levels, visual cues even beat the com-bination of all features.
We note, however, that forearly children?s books, pictures and textual layoutdominate the book content over text.
Visual featurescan be as useful as traditional surface text-based fea-tures, but as one moves out of primary literature, wesuspect text features will likely be more effective forleveling as content becomes more complex.6 ConclusionsIn this paper, we proposed a ranking-based book lev-eling algorithm to assess reading level for children?sliterature.
Our experimental results showed that theranking-based approach performs significantly bet-ter than classification approaches as used in currentliterature.
The increased number of classes deterio-rates the performance of classifiers in a fine-grainedleveling system.
We also introduced visual featuresinto readability assessment and have seen consider-able benefits of using visual cues.
Since our targetdata are children?s books that contain many illustra-tions and pictures, it is quite reasonable to utilize vi-sual content to help predict a more accurate readinglevel.
Future studies in early childhood readabilityneed to take visual content into account.551ReferencesK.
Collins-Thompson and J. Callan.
2004.
A languagemodeling approach to predicting reading difficulty.
InProceedings of HLT / NAACL 2004, volume 4, pages193?200, Boston, USA.L.
Feng, M. Jansche, M. Huenerfauth, and N. Elhadad.2010.
A comparison of features for automatic read-ability assessment.
In Proceedings of the 23rd In-ternational Conference on Computational Linguistics(COLING 2010), pages 276?284, Beijing, China.
As-sociation for Computational Linguistics.R.
Flesch.
1948.
A new readability yardstick.
Journal ofapplied psychology, 32(3):221?233.I.
Fountas and G. Pinnell.
1996.
Guided Reading:Good First Teaching for All Children.
Heinemann,Portsmouth, NH.M.
Heilman, K. Collins-Thompson, J. Callan, and M. Es-kenazi.
2007.
Combining lexical and grammaticalfeatures to improve readability measures for first andsecond language texts.
In Proceedings of NAACLHLT, pages 460?467.T.
Joachims.
1999.
Making large-scale SVM learningpractical.
In B. Scho?lkopf, C. Burges, and A. Smola,editors, Advances in Kernel Methods - Support Vec-tor Learning, chapter 11, pages 169?184.
MIT Press,Cambridge, MA.T.
Joachims.
2006.
Training linear SVMs in linear time.In Proceedings of the 12th ACM SIGKDD interna-tional conference on Knowledge discovery and datamining, pages 217?226.
ACM.S.
Petersen and M. Ostendorf.
2009.
A machine learn-ing approach to reading level assessment.
ComputerSpeech & Language, 23(1):89?106.S.
Schwarm and M. Ostendorf.
2005.
Reading level as-sessment using support vector machines and statisticallanguage models.
In Proceedings of the 43rd AnnualMeeting on Association for Computational Linguis-tics, pages 523?530.
Association for ComputationalLinguistics.G.
Spache.
1953.
A new readability formula for primary-grade reading materials.
The Elementary School Jour-nal, 53(7):410?413.I.
Tsochantaridis, T. Hofmann, T. Joachims, and Y. Altun.2004.
Support vector machine learning for interdepen-dent and structured output spaces.
In Proceedings ofthe twenty-first international conference on Machinelearning, page 104.
ACM.552
