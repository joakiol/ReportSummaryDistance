Sense Tagging:Semantic Tagging with a LexiconYorick Wilks and Mark StevensonDepartment ofComputer Science,University of Sheffield,Regent Court, 211 Portobello Street,Sheffield S1 4DP, UK{yorick, marks}@dcs, shef.
ac.ukAbstractSense tagging, the automatic assignment ofthe appropriate s nse from some lexicon toeach of the words in a text, is a specialisedinstance of the general problem of seman-tic tagging by category or type.
We discusswhich recent word sense disambignation al-gorithms are appropriate for sense tagging.It is our belief that sense tagging can becarried out effectively by combining severalsimple, independent, methods and we in-clude the design of such a tagger.
A proto-type of this system has been implemented,correctly tagging 86% of polysemous wordtokens in a small test set, providing evi-dence that our hypothesis correct.1 Sense taggingThis workshop is about semantic tagging: markingeach word token 1in a text with some marker identi-fying its semantic category, similar to the way a part-of-speech tagger assigns a grammatical category toeach token in a text.
Our recent work has been con-cerued with sense tagging, a particular instance ofthis problem.
Sense tagging is the process of assign-ing, to each content word in a text, its particularsense from some lexicon.
This differs from the moregeneral case of semantic tagging, where the tags foreach word (type) are not be specific to that type anddo not correspond to word senses in a lexicon.
Forexample the tags may be broad semantic ategoriessuch as HUMAN or ANI14ATE or WordNet synsets.Another, broader, class of algorithms are wordsense disambiguation (WSD) algorithms.
By WSDalgorithm we mean any procedure which carries outsemantic disambignation words, these may notnecessarily be tagging algorithms, in that they doIOften loosened to each content word in a text.47not attempt to mark every token in a text but maybe restricted to disambiguating small sets of wordtypes.Sense tagging is a difficult problem: each word(type) has its own set of tags which may be quitelarge.
This rules out approaches which rely on a dis-criminator being created for each semantic tag whichis then applied to text, although this is a valuabletechnique when there are a small number of tagswhich are broad semantic categories.However, sense tagging is an extremely useful pro-cedure to carry out since the tags which are associ-ated during sense tagging are rich in knowledge andtherefore likely to be extremely useful for furtherprocessing.
Indeed, the lack of reliable, large-scale,sense taggers has often been blamed for the failureof machine translation for the last 30 years.In this paper we shall discuss some recent ap-proaches to the WSD problem and examine theirusefulness for the more specialised task of sense tag-ging.
We then propose an approach which makesuse of several different types of information and re-port a partial implementation f this system whichproduces very encouraging results.2 Recent Word SenseDisambiguation algorithmsRecent word sense disambignation (WSD) algo-rithms can be categorised into two broad types:1.
WSD using information i  an explicit lexicon.This is usually a Machine Readable Dictio-nary (MRD) such as the Longman Dictionaryo\] Contemporary English (LDOCE) (Procter,1978), WordNet (Miller (Ed.
), 1990) or hand-crafted.
Recent examples of this work include(Bruce and Guthrie, 1992), (Bruce and Wiebe,1994), (McRoy, 1992).2.
WSD using information gained from training onsome corpus.
This approach can be further sub-mmclassified:(a) Supervised training, where information isgathered from corpora which have alreadybeen semantically disambiguated.
As suchcorpora are hard to obtain, usually re-quiring expensive hand-tagging, research inthis area has concentrated on other formsof lexical ambiguities, eg.
(Gale, Church,and Yarowsky, 1992).
(b) Unsupervised training, where informationis gathered from raw corpora which hasnot been semantically disambiguated.
Thebest examples of this approach has beenthe resent work of Yarowsky - (Yarowsky,1992), (Yarowsky, 1993), (Yarowsky, 1995).These approaches are not mutually exclusive andthere are, of course, some hybrid cases, for exampleLuk (Luk, 1995) uses information in MRD defini-tions (approach 1) and statistical information fromuntagged corpora (approach 2b).3 Comparing Different ApproachesApproach 2a is the least promising since text taggedwith word senses is practically non-existent and isboth time consuming and difficnlt o produce manu-ally.
Much of the research in this area has been com-promised by the fact that researchers have focussedon lexical ambiguities that are not true word sensedistinctions, such as words translated ifferentlyacross two languages (Gale, Church, and Yarowsky,1992) or homophones ~ (Yarowsky, 1993).Even in the cases where data with the appropriatesense distinctions i available, the text is unliicely tobe from the desired domain: a word sense discrim-inator trained on company news text will be muchless effective on text about electronics products.
Adiscriminator t ained on many types of text so as tobe generic will not be particularly successful in anyspecific domain.Approach 2b has received much attention recently.Its disadvantage is that sense disambiguation is notcarried out relative to any well defined set of senses,but rather an ad hoc set.
Although this researchhas been the most successful of all approa~es, it isdifficult to see what use could be made of the wordsense distinctions produced.Using approach 1 with hand crafted lexicons hasthe disadvantage of being expensive to create: in-deed Small and Rieger (Small and Rieger, 1982)attempted WSD using "word experts", which were2Words pronounced identically but spelled di~erently.48essentially hand crafted disambiguators.
They re-ported that the word expert for "throw" is "cur-rently six pages long, but should be ten times thatsize", making this approach impractical for any sys-tem aiming for broad coverage.4 Proposed ApproachWord senses are not absolute or Platonic but definedby a given lexicon, as has been known for many yearsfrom early work on WSD, even though the contraryseems widely believed: ".. it is very difficult o assignword occurrences tosense classes in any manner thatis both general and determinate.
In the sentences "Ihave a stake in this country."
and "My stake in thelast race was a pound" is "stake" being used in thesame sense or not?
If "stake" can be interpretedto mean something as vague as 'Stake as any kindof investment in any enterprise' then the answer isyes.
So, if a semantic dictionary contained only twosenses for "stake": that vague sense together with'Stake as a post', then one would expect o assign thevague sense for both the sentences above.
But if, onthe other hand, the dictionary distinguished 'Stakeas an investment' and 'Stake as an initial payment ina game or race' then the answer would be expectedto be different.
So, then, word sense disambiguationis relative to the dictionary of sense choices availableand can have no absolute quality about it."
(Wilks,1972)There is no general agreement over the number ofsenses appropriate for lexical entries: at one end ofthe spectrum Wierzbicka (Wierzbicka, 1989) claimswords have essentially one sense while Pustejovskybelieves that "... words can assume a potentiallyini~nite number of senses in context.
"(Pustejovsky,1995) How, then, are we to get an initial lexicon ofword senses?
We believe the best resource is stilla Machine Readable Dictionary: they have a rela-tively well-defined set of sense tags for each wordand lexical coverage is high.MRDs are, of course, normally generic, and muchpractical WSD work is for sub-domains.
We are ad-hering to the view that it is better to start with sucha generic lexicon and adapt it automatically withspecialist words and senses.
The work described hereis part of ECRAN (Wilks, 1995), a European LREproject on tuning lexicons to domains, with a gen-eral sense tagging module used as a first stage.5 Knowledge SourcesAn interesting fact about recent word sense disam-biguation algorithms is that they have made use ofdifferent, orthogonal, sources of information: the in-mmmmm\[\]mmmmmmmmmmmmmmmmmmmmformation provided by each source seems indepen-dent of and has no bearing on any of the others.
Wepropose a tagger that makes use of several types ofinformation (dictionary definitions, parts-of-speech,domain codes, selectional preferences and collocates)in the tradition of McRoy (McRoy, 1992) although,the information sources we use are orthogonal, un-like the sources he used, making it easier to evaluatethe performance of the various modules.5.1 Part-of-speechIt has already been shown that part-of-speech tagsare a useful discriminator for semantic disambigua-tion (Wilks and Stevenson, 1996), although they arenot, normally, enough to fully disambiguate a text.For example knowing "bank" in "My bank is on thecorner."
is being used as a noun will tell us that theword is not being used in the 'plane turning cor-ner' sense but not whether it is being used in the'financial institution' or 'edge of river' senses.
Part-of-speech tags can provide a valuable step towardsthe solution to sense tagging: fully disambiguatingabout 87% of ambiguous word tokens and reducingthe ambiguity for some of the rest.5.2 Domain codes (Thesaural categories)Pragmatic domain codes can be used to disam-biguate (usually nominal) senses, as was shown by(Bruce and Guthrie, 1992) and (Yarowsky, 1992).Our intuition here is that disambiguation evidencecan be gained by choosing senses which are closest ina thesanral hierarchy.
Closeness in such a hierarchycan be effectively expressed as the number of nodesbetween concepts.
We are implementing a simplealgorithm which prefers close senses in our domainhierarchy which was derived from LDOCE (Bruceand Guthrie, 1992).5.3 CollocatesRecent work has been done using collocations assemantic disambiguators, (Yarowsky, 1993), (Dorr,1996), particularly for verbs.
We are attempting toderive disambiguation information by examining theprepositions a  given in the subcategorization framesof verbs, and in the example sentences in LDOCE.5.4 Selectionai PreferencesThere has been a long tradition in NLP of using se-lectional preferences for WSD (Wilks, 1972).
Thisapproach as been recently used by (McRoy, 1992)and (Mahesh and Beale, 1996).
At its best it disam-biguates both verbs, adjectives and the nouns theymodify at the same time, but we shall use this in-formation late in the disambiguation process when49we hope to be reasonably confident of the senses ofnouns in the text from processes such as 5.2 and 5.5.5.5 Dictionary definitionsLesk (Lesk, 1986) proposed a method for seman-tic disambiguation using the dictionary definitionsof words as a measure of their semantic losenessand proposed the disambiguation f sentences bycomputing the overlap of definitions for a sentence.Simmulated annealing, a numerical optimisation al-gorithm, was used to make this process practical(Cowie, Guthrie, and Guthri~, 1992), choosing anassignment ofsenses from as many as 10 l?
choices.The optimisation is carried out by minimising anevaluation function, computed from the overlap ofa given configuration of senses.
The overlap is thetotal number of times each word appears more thanonce in the dictionary definitions of all the sensesin the configuration.
So that if the word "bank"appeared three times in a given configuration wewould add two to the overlap total.
This functionhas the disadvantage that longer definitions are pref-ered over short ones, since these simply have morewords which can contribute to the overlap.
Thusshort definitions or definitions by synonym are pe-nalised.We attempted to solve this problem by makinga slight change to the method for calculating theoverlap.
Instead of each word contributing one wenormalise it's contribution by the number of wordsin the definition it came from, so if a word came froma definition with three words it would add one thirdto the overlap total.
In this way long definitions haveto have many words contributing to the total to beinfluential and short definitions are not penalised.We found that this new function lead to a smallimprovement in the results of the disambiguation,however we do not believe this to be statisticallysignificant.6 A Basic TaggerWe have recently implemented a basic version ofthis tagger, initially incorporating only the part-of-speech (5.1) and dictionary definition (5.5) stages inthe process, with further stages to be added later.Our tagger currently consists of three modules:?
Dictionary look-up module?
Part-of-speech filter?
Simulated annealing1.
We have chosen to use the machine readableversion of LDOCE as our lexicon.
This has beenused extensively in NLP research and providesa broad set of senses for sense tagging.The text is initially stemmed, leaving only mor-phological roots, and split into sentences.
Thenwords belonging to a list of stop words (prepo-sitions, pronouns etc.)
are removed.
For eachof the remaining words, e~ of its senses areextracted from LDOCE and stored with thatword.
The textual definitions in each sense isprocessed to remove stop words and stem re-maining words.2.
The text is tagged using the Brill tagger (Brill,1992) and a translation is carried out using amanually defined mapping from the syntactictags assigned by Briil (Penn Tree Bank tags(Marcus, Santorini, and Marcinkiewicz, 1993))onto the simpler part-of-speech ategories asso-ciated with LDOCE senses.
We then removeall senses whose part-of-speech is not consistentwith the one assigned by the tagger, if none ofthe senses are consistent with the part-of-speechwe assume the tagger has made an error and donot remove any senses.3.
The final stage is to use the simulated anneal-ing algorithm to optimise the dictionary deft-nition overlap for the remaining senses.
Thisalgorithm assigns a single sense to each tokenwhich is the tag assodated with that token.7 Example OutputBelow is an example of the senses assigned by thesystem for the sentence "A rapid rise in prices sooneventuated unemployment."
We show the homo-graph and sense numbers from LDOCE with thestemmed content words from the dictionary defini-tions which are used to calculate the overlap follow-ing the dash.?
rapid homograph 1 sense 2 - done short time?
r i se  homograph 2 sense 1 - act grow greaterpowerful?
soon homograph 0 sense 1 - long short time?
pr ices homograph 1 sense 1 - amount moneywhich thing be offer sell buy?
unemployment homograph 0 sense 1 - conditionlack jobThe senses have additional information associatedwhich we do not show here: domain codes, part of50speech and grammatical information as well as se-mantic information.The senses for a word in LDOCE are groupedinto homographs, ets of senses realeated by mean-ing.
For example, one of the homographs of "bank"means roughly 'things piled up', the different sensesdistinguishing exactly what is piled up.8 ResultsWe have conducted some preliminary testing ofthis approach: our tests were run on 10 hand-disambiguated sentences from the Wall Street Jour-nal amounting to a 209 word corpus.
We foundthat of, the word tokens which had more than 1homograph, 86% were assigned the correct homo.graph and 57% of tokens were assigned the cor-rect sense using our simple tagger.
These figuresshould be compared to 72% correct homograph as-signment and 47% correct sense assignment usingsimulated annealing alone on the same test set (see(Cowie, Guthrie, and Guthrie, 1992)).
It should henoted that the granularity of sense distinctions atthe LDOCE homograph level (eg.
"bank" as 'edgeof river' or 'financial institution') is the same as thedistinctions made by current small-scale WSD algo-ritbm~ (eg.
(Gale, Church, and Yarowsky, 1992),(Yarowsky, 1993), (Schfitze, 1992)) and our systemis a true tagging algorithm, operating on free text.Our evaluation is unsatisfactory due to the smalltest set, but does demonstrate that the use of inde-pendent knowledge sources leads to an improvementin the quality of disambignation.
We fully expectour results to improve with the addition of further,independent, modules.9 ConclusionIn this paper we have argued that semantic taggingcan be carried out only relative to the senses in somelexicon and that a machine readable dictionary pro-vides an appropriate set of senses.We reported a simple semantic tagger whichachieves 86% correct disambignation using two inde-pendent sources of information: part-of-speech tagsand dictionary definition overlap.
A proposal to ex-tend this tagger is developed, based on other, mutu-ally independent, sources of lexical information.AcknowledgementsThis research was supported by the European UnionLanguage Engineering project ECRAN, numberLE2110.
We are grateful to Jim Cowie at CRL forproviding the simulated annealing code and to KevinHumphries and Hamish Cnnningham ofthe SheffieldINLP group for advice with the implementation fthe tagger.ReferencesBrill, E. 1992.
A simple rule-based pad-of-speechtagger.
In Proceeding of the Third Conferenceon Applied Natural Language Processing, Trento,Italy.Bruce, R. and L. Guthrie.
1992.
Genus dis-ambiguation: A study in weighted preference.In Proceesings of COLING-9~, pages 1187-1191,Nantes, France.Bruce, R. and J. Wiebe.
1994.
Word-sense disam-biguation using decomposable models.
In Proceed-ings of the 3~nd Annual Meeting of the Associ-ation for Computational Linguistics, pages 139-145, Los Cruces, New Mexico.Cowie, J., L. Guthrie, and J. Guthrie.
1992.
Lex-ical disambiguation using simulated annealing.In Proceedings of COLING-9,~, pages 359-365,Nantes, France.Dorr, B.
1996.
Role of word sense disambiguation inlexical aquisition: Predicting semantics from syn-tactic cues.
In Proceedings ol COLING-96, pages322-327, Copenhagen, Denmark.Gale, W., K. Church, and D. Yarowsky.
1992.
Onesense per discourse.
In Proceedings of the DARPASpeech and Natural Language Workshop, pages233-237, Harriman, New York, February.Lesk, M. I986.
Automatic sense disambiguation us-ing machine readable dictionaries: how to tell apine cone from an ice cream cone.
In Proceed-ings ol ACM SIGDOC Conference, pages 24-26,Toronto, Ontario.Luk, A.
1995.
Statstical sense disambiguation withrelatively small corpora using dictionary defini-tions.
In Proceedings of ACL 95, pages 181-188.Mahesh, K. and S. Beale.
1996.
Evaluation of theMikrokosmos system as of 1996.
Technical ReportMCCS-96-300, Computing Research Laboratory.Marcus, M., R. Santorini, and M. A. Marcinkiewicz.1993.
Building a large annotated corpus of En-glish: The Penn Tree Bank.
Computational Lin-guistics, 19(2):313-330.McRoy, S. 1992.
Using multiple knowledge sourcesfor word sense disambiguation.
ComputationalLinguistics, 18(1).Miller (Ed.
), G. A.
1990.
WordNet: An on-linelexical database.
International Journal of Lexi-cography.51Procter, P. 1978.
Longman Dictionary of Contem-porary English.
Longman Group, Essex, England.Pustejovsky, J.
1995.
The Generative Lexicon.
MITPress, Cambridge, MA.Schiitze, H. 1992.
Dimensions of meaning.
In Pro-ceedings of Supercomputing 'g2.Small, S. and C. Rieger.
1982.
Parsing and com-prehending with word experts (a theory and itsrealisation).
In W. Lehnert and M. Ringle, edi-tors, Strategies for Natural Language Processing.Lawrence Erlbaum Associates, Hillsdale, NJ.Wierzbicka, A.
1989.
Semantics, Culture and Cog-nition.
Oxford University Press, Oxford.Wilks, Y.
1972.
Grammar, Meaning and the Ma-chine Analysis of Language.
Rontledge, London.Wilks, Y.
1995.
ECRAN: Extraction of Content:Research at Near-market.
EU funded LRE Re-search Proposal.Wilks, Y. and M. Stevenson.
1996.
The grammarof sense: Is word-sense tagging much more thanpart-of-speech tagging?
Technical Report CS-96-05, University of Sheffield.Yarowsky, D. 1992.
Word-sense disambiguation us-hag statistical models of Roget's categories trainedon large corpora.
In COLING-92.Yarowsky, D. 1993.
One sense per collocation.
InProceedings ARPA Human Language TechnologyWorkshop, pages 266--271.Yarowsky, D. 1995.
Unsupervised word-sense dis-ambiguation rivaling supervised methods.
In Pro-ceedings of ACL95, pages 189-196.
