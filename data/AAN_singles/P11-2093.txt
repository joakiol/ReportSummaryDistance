Pointwise Prediction for Robust, AdaptableJapanese Morphological AnalysisGraham Neubig, Yosuke Nakata, Shinsuke MoriGraduate School of Informatics, Kyoto UniversityYoshida Honmachi, Sakyo-ku, Kyoto, JapanAbstractWe present a pointwise approach to Japanesemorphological analysis (MA) that ignoresstructure information during learning and tag-ging.
Despite the lack of structure, it is able tooutperform the current state-of-the-art struc-tured approach for Japanese MA, and achievesaccuracy similar to that of structured predic-tors using the same feature set.
We alsofind that the method is both robust to out-of-domain data, and can be easily adaptedthrough the use of a combination of partial an-notation and active learning.1 IntroductionJapanese morphological analysis (MA) takes an un-segmented string of Japanese text as input, and out-puts a string of morphemes annotated with parts ofspeech (POSs).
As MA is the first step in JapaneseNLP, its accuracy directly affects the accuracy ofNLP systems as a whole.
In addition, with the prolif-eration of text in various domains, there is increasingneed for methods that are both robust and adaptableto out-of-domain data (Escudero et al, 2000).Previous approaches have used structured predic-tors such as hidden Markov models (HMMs) or con-ditional random fields (CRFs), which consider theinteractions between neighboring words and partsof speech (Nagata, 1994; Asahara and Matsumoto,2000; Kudo et al, 2004).
However, while struc-ture does provide valuable information, Liang et al(2008) have shown that gains provided by struc-tured prediction can be largely recovered by using aricher feature set.
This approach has also been called?pointwise?
prediction, as it makes a single indepen-dent decision at each point (Neubig andMori, 2010).While Liang et al (2008) focus on the speed ben-efits of pointwise prediction, we demonstrate that italso allows for more robust and adaptable MA.
Wefind experimental evidence that pointwise MA canexceed the accuracy of a state-of-the-art structuredapproach (Kudo et al, 2004) on in-domain data, andis significantly more robust to out-of-domain data.We also show that pointwise MA can be adaptedto new domains with minimal effort through thecombination of active learning and partial annota-tion (Tsuboi et al, 2008), where only informativeparts of a particular sentence are annotated.
In arealistic domain adaptation scenario, we find that acombination of pointwise prediction, partial annota-tion, and active learning allows for easy adaptation.2 Japanese Morphological AnalysisJapanese MA takes an unsegmented string of char-acters xI1 as input, segments it into morphemes wJ1 ,and annotates each morpheme with a part of speechtJ1 .
This can be formulated as a two-step process offirst segmenting words, then estimating POSs (Ngand Low, 2004), or as a single joint process of find-ing a morpheme/POS string from unsegmented text(Kudo et al, 2004; Nakagawa, 2004; Kruengkrai etal., 2009).
In this section we describe an existingjoint sequence-based method for Japanese MA, aswell as our proposed two-step pointwise method.2.1 Joint Sequence-Based MAJapanese MA has traditionally used sequence basedmodels, finding a maximal POS sequence for en-Figure 1: Joint MA (a) performs maximization over theentire sequence, while two-step MA (b) maximizes the 4boundary and 4 POS tags independently.Type Feature StringsUnigram tj , tjwj , c(wj), tjc(wj)Bigram tj?1tj , tj?1tjwj?1,tj?1tjwj , tj?1tjwj?1wjTable 1: Features for the joint model using tags t andwords w.
c(?)
is a mapping function onto character types(kanji, katakana, etc.
).tire sentences as in Figure 1 (a).
The CRF-basedmethod presented by Kudo et al (2004) is gener-ally accepted as the state-of-the-art in this paradigm.CRFs are trained over segmentation lattices, whichallows for the handling of variable length sequencesthat occur due to multiple segmentations.
The modelis able to take into account arbitrary features, as wellas the context between neighboring tags.We follow Kudo et al (2004) in defining our fea-ture set, as summarized in Table 11.
Lexical featureswere trained for the top 5000 most frequent words inthe corpus.
It should be noted that these are word-based features, and information about transitions be-tween POS tags is included.
When creating trainingdata, the use of word-based features indicates thatword boundaries must be annotated, while the useof POS transition information further indicates thatall of these words must be annotated with POSs.1More fine-grained POS tags have provided small boosts inaccuracy in previous research (Kudo et al, 2004), but these in-crease the annotation burden, which is contrary to our goal.Type Feature StringsCharacter xl, xr, xl?1xl, xlxr,n-gram xrxr+1, xl?1xlxr, xlxrxr+1Char.
Type c(xl), c(xr)n-gram c(xl?1xl), c(xlxr), c(xrxr+1)c(xl?2xl?1xl), c(xl?1xlxr)c(xlxrxr+1), c(xrxr+1xr+2)WS Only ls, rs, isPOS Only wj , c(wj), djkTable 2: Features for the two-step model.
xl and xr indi-cate the characters to the left and right of the word bound-ary or word wj in question.
ls, rs, and is represent theleft, right, and inside dictionary features, while djk indi-cates that tag k exists in the dictionary for word j.2.2 2-Step Pointwise MAIn our research, we take a two-step approach, firstsegmenting character sequence xI1 into the word se-quencewJ1 with the highest probability, then taggingeach word with parts of speech tJ1 .
This approach isshown in Figure 1 (b).We follow Sassano (2002) in formulating wordsegmentation as a binary classification problem, es-timating boundary tags bI?11 .
Tag bi = 1 indi-cates that a word boundary exists between charac-ters xi and xi+1, while bi = 0 indicates that a wordboundary does not exist.
POS estimation can alsobe formulated as a multi-class classification prob-lem, where we choose one tag tj for each word wj .These two classification problems can be solved bytools in the standard machine learning toolbox suchas logistic regression (LR), support vector machines(SVMs), or conditional random fields (CRFs).We use information about the surrounding charac-ters (character and character-type n-grams), as wellas the presence or absence of words in the dictio-nary as features (Table 2).
Specifically dictionaryfeatures for word segmentation ls and rs are activeif a string of length s included in the dictionary ispresent directly to the left or right of the presentword boundary, and is is active if the present wordboundary is included in a dictionary word of lengths.
Dictionary feature djk for POS estimation indi-cates whether the current word wj occurs as a dic-tionary entry with tag tk.Previous work using this two-stage approach hasused sequence-based prediction methods, such asmaximum entropy Markov models (MEMMs) orCRFs (Ng and Low, 2004; Peng et al, 2004).
How-ever, as Liang et al (2008) note, and we confirm,sequence-based predictors are often not necessarywhen an appropriately rich feature set is used.
Oneimportant difference between our formulation andthat of Liang et al (2008) and all other previousmethods is that we rely only on features that are di-rectly calculable from the surface string, without us-ing estimated information such as word boundariesor neighboring POS tags2.
This allows for trainingfrom sentences that are partially annotated as de-scribed in the following section.3 Domain Adaptation for MorphologicalAnalysisNLP is now being used in domains such as medi-cal text and legal documents, and it is necessary thatMA be easily adaptable to these areas.
In a domainadaptation situation, we have at our disposal bothannotated general domain data, and unannotated tar-get domain data.
We would like to annotate thetarget domain data efficiently to achieve a maximalgain in accuracy for a minimal amount of work.Active learning has been used as a way to pickdata that is useful to annotate in this scenario forseveral applications (Chan and Ng, 2007; Rai etal., 2010) so we adopt an active-learning-based ap-proach here.
When adapting sequence-based predic-tion methods, most active learning approaches havefocused on picking full sentences that are valuable toannotate (Ringger et al, 2007; Settles and Craven,2008).
However, even within sentences, there aregenerally a few points of interest surrounded bylarge segments that are well covered by already an-notated data.Partial annotation provides a solution to this prob-lem (Tsuboi et al, 2008; Sassano and Kurohashi,2010).
In partial annotation, data that will not con-tribute to the improvement of the classifier is leftuntagged.
For example, if there is a single difficultword in a long sentence, only the word boundariesand POS of the difficult word will be tagged.
?Dif-2Dictionary features are active if the string exists, regardlessof whether it is treated as a single word in wJ1 , and thus can becalculated without the word segmentation result.Type Train TestGeneral 782k 87.5kTarget 153k 17.3kTable 3: General and target domain corpus sizes in words.ficult?
words can be selected using active learningapproaches, choosing words with the lowest classi-fier accuracy to annotate.
In addition, corpora thatare tagged with word boundaries but not POS tagsare often available; this is another type of partial an-notation.When using sequence-based prediction, learningon partially annotated data is not straightforward,as the data that must be used to train context-basedtransition probabilities may be left unannotated.
Incontrast, in the pointwise prediction framework,training using this data is both simple and efficient;unannotated points are simply ignored.
A methodfor learning CRFs from partially annotated data hasbeen presented by Tsuboi et al (2008).
However,when using partial annotation, CRFs?
already slowtraining time becomes slower still, as they must betrained over every sequence that has at least one an-notated point.
Training time is important in an activelearning situation, as an annotator must wait whilethe model is being re-trained.4 ExperimentsIn order to test the effectiveness of pointwise MA,we did an experiment measuring accuracy both onin-domain data, and in a domain-adaptation situa-tion.
We used the Balanced Corpus of Contempo-rary Written Japanese (BCCWJ) (Maekawa, 2008),specifying the whitepaper, news, and books sectionsas our general domain corpus, and the web text sec-tion as our target domain corpus (Table 3).As a representative of joint sequence-based MAdescribed in 2.1, we used MeCab (Kudo, 2006), anopen source implementation of Kudo et al (2004)?sCRF-based method (we will call this JOINT).
For thepointwise two-step method, we trained logistic re-gression models with the LIBLINEAR toolkit (Fanet al, 2008) using the features described in Section2.2 (2-LR).
In addition, we trained a CRF-basedmodel with the CRFSuite toolkit (Okazaki, 2007)using the same features and set-up (for both wordTrain Test JOINT 2-CRF 2-LRGEN GEN 97.31% 98.08% 98.03%GEN TAR 94.57% 95.39% 95.13%GEN+TAR TAR 96.45% 96.91% 96.82%Table 4: Word/POS F-measure for each method whentrained and tested on general (GEN) or target (TAR) do-main corpora.segmentation and POS tagging) to examine the con-tribution of context information (2-CRF).To create the dictionary, we added all of the wordsin the corpus, but left out a small portion of single-tons to prevent overfitting on the training data3.
Asan evaluation measure, we follow Nagata (1994) andKudo et al (2004) and use Word/POS tag pair F-measure, so that both word boundaries and POS tagsmust be correct for a word to be considered correct.4.1 Analysis ResultsIn our first experiment we compared the accuracy ofthe three methods on both the in-domain and out-of-domain test sets (Table 4).
It can be seen that2-LR outperforms JOINT, and achieves similar butslightly inferior results to 2-CRF.
The reason foraccuracy gains over JOINT lies largely in the factthat while JOINT is more reliant on the dictionary,and thus tends to mis-segment unknown words, thetwo-step methods are significantly more robust.
Thesmall difference between 2-LR and 2-CRF indicatesthat given a significantly rich feature set, context-based features provide little advantage, although theadvantage is larger on out-of-domain data.
In addi-tion, training of 2-LR is significantly faster than 2-CRF.
2-LR took 16m44s to train, while 2-CRF took51m19s to train on a 3.33GHz Intel Xeon CPU.4.2 Domain AdaptationOur second experiment focused on the domainadaptability of each method.
Using the target do-main training corpus as a pool of unannotated data,we performed active learning-based domain adapta-tion using two techniques.?
Sentence-based annotation (SENT), where sen-tences with the lowest total POS and word3For JOINT we removed singletons randomly until coveragewas 99.99%, and for 2-LR and 2-CRF coverage was set to 99%,which gave the best results on held-out data.Figure 2: Domain adaptation results for three approachesand two annotation methods.boundary probabilities were annotated first.?
Word-based partial annotation (PART), wherethe word or word boundary with the smallestprobability margin between the first and secondcandidates was chosen.
This can only be usedwith the pointwise 2-LR approach4 .For both methods, 100 words (or for SENT untilthe end of the sentence in which the 100th wordis reached) are annotated, then the classifier is re-trained and new probability scores are generated.Each set of 100 words is a single iteration, and 100iterations were performed for each method.From the results in Figure 2, it can be seen thatthe combination of PART and 2-LR allows for sig-nificantly faster adaptation than other approaches,achieving accuracy gains in 15 iterations that areachieved in 100 iterations with SENT, and surpassing2-CRF after 15 iterations.
Finally, it can be seen thatJOINT improves at a pace similar to PART, likely dueto the fact that its pre-adaptation accuracy is lowerthan the other methods.
It can be seen from Table 4that even after adaptation with the full corpus, it willstill lag behind the two-step methods.5 ConclusionThis paper proposed a pointwise approach toJapanese morphological analysis.
It showed that de-spite the lack of structure, it was able to achieve re-4In order to prevent wasteful annotation, each unique wordwas only annotated once per iteration.sults that meet or exceed structured prediction meth-ods.
We also demonstrated that it is both robust andadaptable to out-of-domain text through the use ofpartial annotation and active learning.
Future workin this area will include examination of performanceon other tasks and languages.ReferencesMasayuki Asahara and Yuji Matsumoto.
2000.
Extendedmodels and tools for high-performance part-of-speechtagger.
In Proceedings of the 18th International Con-ference on Computational Linguistics, pages 21?27.Yee Seng Chan and Hwee Tou Ng.
2007.
Domain adap-tation with active learning for word sense disambigua-tion.
In Proceedings of the 45th Annual Meeting of theAssociation for Computational Linguistics.Gerard Escudero, Llu?
?s Ma`rquez, and German Rigau.2000.
An empirical study of the domain dependenceof supervised word sense disambiguation systems.
InProceedings of the 2000 Joint SIGDAT Conference onEmpirical Methods in Natural Language Processingand Very Large Corpora.Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, Xiang-RuiWang, and Chih-Jen Lin.
2008.
LIBLINEAR: A li-brary for large linear classification.
Journal of Ma-chine Learning Research, 9:1871?1874.Canasai Kruengkrai, Kiyotaka Uchimoto, Jun?ichiKazama, Yiou Wang, Kentaro Torisawa, and HitoshiIsahara.
2009.
An error-driven word-character hybridmodel for joint Chinese word segmentation and POStagging.
In Proceedings of the 47th Annual Meeting ofthe Association for Computational Linguistics.Taku Kudo, Kaoru Yamamoto, and Yuji Matsumoto.2004.
Applying conditional random fields to Japanesemorphological analysis.
In Proceedings of the Confer-ence on Empirical Methods in Natural Language Pro-cessing, pages 230?237.Taku Kudo.
2006.
MeCab: yet anotherpart-of-speech and morphological analyzer.http://mecab.sourceforge.net.Percy Liang, Hal Daume?
III, and Dan Klein.
2008.Structure compilation: trading structure for features.In Proceedings of the 25th International Conferenceon Machine Learning, pages 592?599.Kikuo Maekawa.
2008.
Balanced corpus of contempo-rary written Japanese.
In Proceedings of the 6th Work-shop on Asian Language Resources, pages 101?102.Masaaki Nagata.
1994.
A stochastic Japanese morpho-logical analyzer using a forward-DP backward-A?
N-best search algorithm.
In Proceedings of the 15th In-ternational Conference on Computational Linguistics,pages 201?207.Tetsuji Nakagawa.
2004.
Chinese and Japanese wordsegmentation using word-level and character-level in-formation.
In Proceedings of the 20th InternationalConference on Computational Linguistics.Graham Neubig and Shinsuke Mori.
2010.
Word-basedpartial annotation for efficient corpus construction.
InProceedings of the 7th International Conference onLanguage Resources and Evaluation.Hwee Tou Ng and Jin Kiat Low.
2004.
Chinese part-of-speech tagging: one-at-a-time or all-at-once?
word-based or character-based.
In Proceedings of the Con-ference on Empirical Methods in Natural LanguageProcessing.Naoaki Okazaki.
2007.
CRFsuite: a fast im-plementation of conditional random fields (CRFs).http://www.chokkan.org/software/crfsuite/.Fuchun Peng, Fangfang Feng, and Andrew McCallum.2004.
Chinese segmentation and new word detectionusing conditional random fields.
In Proceedings of the20th International Conference on Computational Lin-guistics.Piyush Rai, Avishek Saha, Hal Daume?
III, and SureshVenkatasubramanian.
2010.
Domain Adaptationmeets Active Learning.
In Workshop on Active Learn-ing for Natural Language Processing (ALNLP-10).Eric Ringger, Peter McClanahan, Robbie Haertel, GeorgeBusby, Marc Carmen, James Carroll, Kevin Seppi, andDeryle Lonsdale.
2007.
Active learning for part-of-speech tagging: Accelerating corpus annotation.
InProceedings of the Linguistic Annotation Workshop,pages 101?108.Manabu.
Sassano and Sadao Kurohashi.
2010.
Us-ing smaller constituents rather than sentences in ac-tive learning for Japanese dependency parsing.
In Pro-ceedings of the 48th Annual Meeting of the Associationfor Computational Linguistics, pages 356?365.Manabu Sassano.
2002.
An empirical study of activelearning with support vector machines for Japaneseword segmentation.
In Proceedings of the 40th AnnualMeeting of the Association for Computational Linguis-tics, pages 505?512.Burr Settles and Mark Craven.
2008.
An analysis ofactive learning strategies for sequence labeling tasks.In Conference on Empirical Methods in Natural Lan-guage Processing, pages 1070?1079.Yuta Tsuboi, Hisashi Kashima, Hiroki Oda, ShinsukeMori, and Yuji Matsumoto.
2008.
Training condi-tional random fields using incomplete annotations.
InProceedings of the 22th International Conference onComputational Linguistics, pages 897?904.
