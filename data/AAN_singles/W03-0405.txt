Unsupervised Personal Name DisambiguationGideon S. Mann and David YarowskyDepartment of Computer ScienceJohns Hopkins UniversityBaltimore, MD 21218 USA{gsm,yarowsky}@cs.jhu.eduAbstractThis paper presents a set of algorithms fordistinguishing personal names with mul-tiple real referents in text, based on littleor no supervision.
The approach utilizesan unsupervised clustering technique overa rich feature space of biographic facts,which are automatically extracted via alanguage-independent bootstrapping pro-cess.
The induced clustering of namedentities are then partitioned and linked totheir real referents via the automaticallyextracted biographic data.
Performance isevaluated based on both a test set of hand-labeled multi-referent personal names andvia automatically generated pseudonames.1 IntroductionOne open problem in natural language ambiguityresolution is the task of proper noun disambigua-tion1.
While word senses and translation ambigu-ities may typically have 2-20 alternative meaningsthat must be resolved through context, a personalname such as ?Jim Clark?
may potentially refer tohundreds or thousands of distinct individuals.
Eachdifferent referent typically has some distinct contex-tual characteristics.
These characteristics can helpdistinguish, resolve and trace the referents when thesurface names appear in online documents.A search of Google shows 76,000 web pagesmentioning Jim Clark, of which the first 10 uniquereferents are:1This has been recognized even by the popular press.Reuters (March 13, 2003) observed the problem of name am-biguity to be a major stumbling block in personal name websearches.1.
Jim Clark - Race car driver from Scotland2.
Jim Clark - Clockmaker from Colorado3.
Jim Clark - Film Editor4.
Jim Clark - Netscape Founder5.
Jim Clark - Disaster Survivor6.
Jim Clark - Car Salesman in Kansas7.
Jim Clark - Fishing Instructor in Canada8.
Jim Clark - Computer Science student in Hong Kong9.
Jim Clark - Professor at McGill10.
Jim Clark - Gun Dealer in LouisianaIn this paper, we present a method for dis-tinguishing the real world referent of a givenname in context.
Approaches to this probleminclude Wacholder et al (1997), focusing on thevariation of surface name for a given referent,and Smith and Crane (2002), resolving geographicname ambiguity.
We present preliminary evaluationon pseudonames: conflations of multiple personalnames, constructed in the same way pseudowordsare used for word sense disambiguation (Gale et al,1992).
We then present corroborating evidence fromreal personal name polysemy to show that this tech-nique works in practice.Miles Davisbirth day May 26(5), May 25(5)birth year 1926(82), 1967(18), 1969(9)...occupation trumpeter(38), artist(10), player(5)...birth place Alton(7), Illinois(6)Joerg Haiderbirth year 1950(6)occupation leader(198) politician(93) chairman(6)...birth place Austria(1)Table 1: Extracted Biographical Information from1000 Web PagesAnother topic of recent interest is in producingbiographical summaries from corpora (Schiffman etal., 2001).
Along with disambiguation, our systemsimultaneously collects biographic information (Ta-ble 1).
The relevant biographical attributes are de-picted along with a clustering which shows the dis-tinct referents (Section 4.1).2 Robust Extraction of CategoricalBiographic DataPast work on this task (e.g.
Bagga and Baldwin,1998) has primarily approached personal name dis-ambiguation using document context profiles or vec-tors, which recognize and distinguish identical nameinstances based on partially indicative words in con-text such as computer or car in the Clark case.
How-ever, in the specialized case of personal names, thereis more precise information available.In particular, information extraction techniquescan add high precision, categorical information suchas approximate age/date-of-birth, nationality andoccupation.
This categorical data can support orexclude a candidate name?referent matches withhigher confidence and greater pinpoint accuracythan via simple context vector-style features alone.Another major source of disambiguation infor-mation for proper nouns is the space of associatednames.
While these names could be used in a undif-ferentiated vector-based bag-of-words model, fur-ther accuracy can be gained by extracting specifictypes of association, such as familial relationships(e.g.
son, wife), employment relationships (e.g.manager of), and nationality as distinct from sim-ple term co-occurrence in a window.
The Jim Clarkmarried to ?Vickie Parker-Clark?
is likely not thesame Jim Clark married to ?Patty Clark?.
Addi-tionally, information about one?s associates can helppredict information about the person in question.Someone who frequently associates with Egyptiansis likely to be Egyptian, or at the very least, has aclose connection to Egypt.2.1 Generating Extraction PatternsOne standard method for generating extraction pat-terns is simply to write them by hand.
In this paper,we have experimented with generating patterns au-tomatically from data.
This has the advantage of be-ing more flexible, portable and scalable, and poten-tially having higher precision and recall.
It also hasthe advantage of being applicable to new languagesfor which no developer with sufficient knowledge ofthe language is available.String Patterns with <person> and <birth year>Extractions where <birth year> is a yearExtraction graded by #correct extractions/#total extractions<person> ( <birth year> ?
\d\d\d\d)<person> <birthyear>?\d\d\d\d<person> was born in <birth year><person> ( b.<birth year>Extractions of <person> with potential <birth years>Web Pages w/<person> and <birth year>Sentences with <person> and <birth year>Substrings with <person> and <birth year>Web Pages with <person>Sentences with <person>16421685186917701899Ludwig van BeethovenHumphrey BogartMohandas GandhiJohn Sebastian BachIsaac Newton<person>                       <birth year>Figure 1: Learning Extraction Patterns from FilledTemplates and Web PagesIn the late 90s, there was a substantial body ofresearch on learning information extraction patternsfrom templates (Huffman, 1995; Brin, 1998; Califfand Mooney, 1998; Freitag and McCallum, 1999;Yangarber et al, 2000; Ravichandran and Hovy,2002).
These techniques provide a way to bootstrapinformation extraction patterns from a set of exam-ple extractions or seed facts, where a tuple with thefilled roles for the desired pattern are given.
Forthe task of extracting biographical information, eachexample would include the personal name and thebiographic feature.
For example, training data forthe pattern born in might be (?Wolfgang AmadeusMozart?,1756).
Given this set of examples, eachmethod generates patterns differently.In this paper, we employ and extend the methoddescribed by Ravichandran and Hovy (2002) shownin Figure 1.
For each seed fact pair for a given tem-plate (such as (Mozart,1756)), a web query is madewhich in turn leads to sentences in which the rolesare observed in nearby association (e.g.
?Mozartwas born in 1756?).
All substrings from these sen-tences are then extracted.
The substrings are thensubject to simple generalization, to produce can-didate patterns: Mozart is replaced by <name>,1756 is replaced by <birth year>, and all digitsare replaced by #.
These substring templates canEnglish SpanishPurely Syntactic PatternsPattern Template Precision Count<name> ( <birth year> - #### ) 1 31<name> ( <birth year> - #### 1 31- <name> ( <birth year>-#### ) 1 30- <name> ( <birth year>-#### 1 30<name> <birth year>-#### 1 27<name> ( <birth year>-#### ) - 1 26<name> <name> ( <birth year> 1 18Syntactic & LexicalPattern Template Precision Count<name> was born in <birth year> 1 19<name> was born in <birth year> in 1 12by <name> ( <birth year>-#### ) 1 10by <name> ( <birth year>-#### 1 10of <name> ( <birth year>-#### ) 0.933 15of <name> ( <birth year>-#### 0.933 15<name> ( <birth year>-#### ) was 0.833 12Purely Syntactic PatternsPattern Template Precision Count.
<name> ( <birth year>- 1 62.
<name> ( <birth year>-## 1 58.
<name> ( <birth year>-#### 1 55.
<name> ( <birth year>-#### ) 1 54<name> ( <birth year>-#### ) : 1 38<name> <birth year>-#### , 1 26<name> , <birth year>-#### 1 25Syntactic & LexicalPattern Template Precision Counta <name> ( <birth year>-#### 1 30a <name> ( <birth year>-#### ) 1 29<birth year> .
- Nace <name> 1 21<birth year> .
- Nace <name> , 1 17<name> ( <birth year>-#### ) , con 1 15<name> ( <birth year>-#### ) se 1 12, de <name> ( <birth year>-#### ) 1 12Table 2: Highest Precision Patterns Extracted for English and Spanish using Suffix Tree Methodologythen serve as extraction patterns for previously un-known fact pairs, and their precision in fact extrac-tion can be calculated with respect to a set of cur-rently known facts.We examined a subset of the available and desir-able extracted information.
We learned patterns forbirth year and occupation, and hand-coded patternsfor birth location, spouse, birthday, familial relation-ships, collegiate affiliations and nationality.
Otherpotential patterns currently under investigation in-clude employer/employee and place of residence.2.2 Multilingual Information ExtractionWe adapted the information extraction pattern gen-eration techniques described above to multiple lan-guages.
In particular, the methodology proposed byRavichandran and Hovy (2002) requires no parsingor other language specific resources, so is an idealcandidate for multilingual use.
In this paper, weconducted an initial test test of the viability of in-ducing these information extraction patterns acrosslanguages.
To test, we constructed a initial databaseof 5 people and their birthdays, and used this to in-duce the English patterns.
We then increased thedatabase to 50 people and birthdays and induced pat-terns for Spanish, presenting the results above.
Fig-ure 2 shows the top precision patterns extracted forEnglish and for Spanish.It can be seen that the Spanish patterns are ofthe same length, with similar estimated precision, aswell as similar word and punctuation distribution asthe English ones.
In fact, the purely syntactic pat-terns look identical.
The only difference being thatto generate equivalent Spanish data, a database oftraining examples an order of magnitude larger wasrequired.
This may be because for each database en-try more pages were available on English websitesthan on Spanish websites.3 Using Unsupervised Clustering toIdentify the Referents of Personal NamesThis section examines clustering of web pageswhich containing an ambiguous personal name(with multiple real referents).
The cluster methodwe employed is bottom-up centroid agglomerativeclustering.
In this method, each document is as-signed a vector of automatically extracted features.At each stage of the clustering, the two most similarvectors are merged, to produce a new cluster, witha vector equal to the centroid of the vectors in thecluster.
This step is repeated until all documents areclustered.To generate the vectors for each document, we ex-plored a variety of methods:1.
Baseline : All words (plain) or only ProperNouns (nnp)2.
Most Relevant words (mi and tf-idf)3.
Basic biographical features (feat)4.
Extended biographical Features (extfeat)word weight(mi) weight(extfeat)adderley 5.30 0snipes 5.16 0coltrane 5.06 0montreux 5.01 0bitches 4.99 0danson 4.97 0hemp 4.97 0mullally 4.95 0porgy 4.94 0remastered 4.92 0actor 3.50 2.401926 0 2.20trumpeter 0 2.20midland 0 1.39Table 3: The 10 words with highest mutual infor-mation with the document collection and all of ex-tended feature words for DAVIS/HARRELSON pseudon-ame3.1 Baseline ModelsIn our baseline models, we used term vectors com-posed either of all words (minus a set of closed class?stop?
words) or of only proper nouns.
To assesssimilarity between vectors we utilized standard co-sine similarity (cos(a, b) = a?b||a||?||b||).We experimentally determined that the use ofproper nouns alone led to more pure clustering.
Asa result, for the remainder of the experiments, weused only proper nouns in the vectors, except forthose common words introduced by the various fea-ture sets.3.2 Relevant Words (mi and tf-idf)Selective term weighting has been shown to behighly effective for information retrieval.
For thisstudy, we investigated both the use of standard TF-IDF weighting and weighting based on the mutualinformation, where given a document collection c,for each word w, we calculate I(w; c) = p(w|c)p(w) .From these, we select words which appear morethan ?1 = 20 times in the collection, and have aI(w; c) greater than ?2 = 10.
These words are tothe document?s feature vector with a weight equal tolog(I(w; c)).3.3 Extracted Biographical Features (feat)The next set of models use the features extractedusing the methodology described in Section 2.
Bi-ographical information such as birth year, and oc-cupation, when found, is quite useful in connectingdocuments.
If a document connects a name with abirth year, and another document connects the samename with the same birth year, typically, those twodocuments refer to the same person.Type Extracted Featurebirth place Midland(4), Texas (3), Alton(1),Illinois(1)birth year 1926 (9), 1967(3), 1973(2),1947(1), 1958(1), 1969(1)occupation actor (11), trumpeter(9),heavyweight(2) ...spouse Demi Moore(1)Table 4: feat: Features Extracted forDAVIS/HARRELSON pseudonameThese extracted features were used to categori-cally cluster documents in which they appeared.
Be-cause of their high degree of precision and speci-ficity, documents which contained similar extractedfeatures are virtually guaranteed to have the samereferent.
By clustering these documents first, largehigh quality clusters formed, which then then pro-vided an anchor for the remaining pages.
By ex-amining the dendrogram in Figure 3, it is clear thatthe clusters start with documents with matching fea-tures, and then the other documents cluster aroundthis core.In addition to improving disambiguation perfor-mance, these extracted features help distinguish thedifferent clusters, and provide information about thedifferent people.3.4 Extended Biographical Features (extfeat)Another method for using these extracted features isto give higher weight to words which have ever beenseen as filling a pattern.
For example, if 1756 is ex-tracted as a birth year from a syntactic-based patternfor the polysemous name, then whenever 1756 isobserved anywhere in context (outside an extractionpattern), it is given a higher weighting and added tothe document vector as a potential biographic fea-ture.
In our experiments, we did this only for wordswhich appeared as values for a feature more than athreshold of 4 times.
Then, whenever the word wasseen in a document, it was given a weight equal tothe log of the number of times the word was seen asan extracted feature.actor comedy  |     spouse:Demi Moore  |       Woody Harrelson|                        |       Woody Harrelson|                        |       Woody Harrelsoncomedy starring  |                        |       Woody Harrelsonmovie  |                        |       Woody Harrelsonactor movie  |                        |       Woody Harrelson|             occ:actor  |       Woody Harrelson|             occ:actor  |       Woody Harrelson|             occ:actor  |       Woody Harrelsonmovie  |             occ:actor  |       Woody Harrelsonactor sleeve  |             occ:actor  |       Woody Harrelsonactor  |             occ:actor  |       Woody Harrelson|                        |       Woody Harrelson|          occ:resident  |       Woody Harrelsonmovie  |                        |       Woody Harrelson|                        |       Woody Harrelson|                        |       Woody Harrelson|                        |       Woody Harrelson|                        |       Woody Harrelson|                        |       Woody Harrelsonactor star  |                        |       Woody Harrelsonactor star  |                        |       Woody HarrelsonSeed1formats  |                        |       Woody Harrelsonformats  |                        |           Miles Davis|            byear:1926  |           Miles Davisquintet  |            byear:1926  |           Miles Davisformats  |                        |           Miles Davis|                        |           Miles Davis|                        |           Miles Davis|                        |           Miles Davis|                        |           Miles Davis|            byear:1973  |           Miles Davis|            byear:1973  |           Miles Davisclick title  |                        |           Miles Davisclick title  |                        |           Miles Davis|         occ:trumpeter  |           Miles Davis|         occ:trumpeter  |           Miles Davisinterviews...  |         occ:trumpeter  |           Miles Davisbiography...  |  byear:1967,occ:trumpeter  |           Miles Davis|         occ:trumpeter  |           Miles Davis|            byear:1967  |           Miles Davisrecordings  |            byear:1967  |           Miles Davisrecordings  |                        |           Miles Davisquintet trumpet  |      brthloc:Alton,IL  |           Miles Davis|                        |           Miles Davistrumpet  |                        |           Miles Davis|                        |           Miles Davis|                        |           Miles Davisartist  |                        |           Miles Davis|                        |           Miles Davisalbum jazz  |                        |           Miles Davisalbum  |                        |           Miles Davisalbum music  |                        |           Miles Davis|                        |           Miles Davis|                        |           Miles Davisde  |                        |           Miles Davisquintet trumpet  |                        |           Miles Davismusic nbsp  |          occ:musician  |           Miles Davisalbum  |          occ:musician  |           Miles Davis|                        |           Miles Davis|            byear:1969  |           Miles Davis|                        |           Miles Davisartist  |                        |           Miles Davis|                        |           Miles DavisSeed20.0 0.05 0.1 0.15 0.2keywords features referentInduced Seed 1Induced Seed 2Figure 2: nnp+feat+extfeat+mi Clustering Visual-ization for DAVIS/HARRELSON pseudoname3.5 Cluster RefactoringIdeally, the raw unsupervised clustering would yielda top level distinction between the different refer-ents.
However, this is rarely the case.
With thistype of agglomerative clustering, the most similarpages are clustered first, and outliers are assignedas stragglers at the top levels of the cluster tree.This typically leads to a full clustering where thetop-level clusters are significantly less discrimina-tive than those at the roots.
In order to compensatefor this effect, we performed a type of tree refac-toring, which attempted to pick out and utilize seedclusters from within the entire clustering.In the refactoring, the clustering is stopped be-fore it runs to completion, based on the percentageof documents clustered and the relative size of theclusters achieved.
At this intermediate stage, rel-atively large and high-precision clusters are found(e.g.
Figure 2).
These automatically-induced clus-ters are then used as seeds for the next stage, wherethe unclustered documents are assigned to the seedwith the closest distance measure (Figure 3).An alternative to this form of cluster refactoringwould be to initially cluster only pages with ex-tracted features.
This would yield a set of clusterseeds, divided by features, which could then be usedfor further clustering.
However, this method relieson having a number of pages with extracted featuresthat overlap from each referent.
This can only beactor comedy  |     spouse:Demi Moore  |       Woody Harrelson|                        |       Woody Harrelson|                        |       Woody Harrelsoncomedy starring  |                        |       Woody Harrelsonmovie  |                        |       Woody Harrelsonactor movie  |                        |       Woody Harrelson|             occ:actor  |       Woody Harrelson|             occ:actor  |       Woody Harrelson|             occ:actor  |       Woody Harrelsonmovie  |             occ:actor  |       Woody Harrelsonactor sleeve  |             occ:actor  |       Woody Harrelsonactor  |             occ:actor  |       Woody Harrelson|                        |       Woody Harrelson|          occ:resident  |       Woody Harrelsonmovie  |                        |       Woody Harrelson|                        |       Woody Harrelson|                        |       Woody Harrelson|                        |       Woody Harrelson|                        |       Woody Harrelson|                        |       Woody Harrelsonactor star  |                        |       Woody Harrelsonactor star  |                        |       Woody HarrelsonSeed1hemp  |  brthloc:Midland,Texas  |       Woody Harrelsonhemp  |  brthloc:Midland,Texas  |       Woody Harrelson|         brthloc:Texas  |       Woody Harrelson|                        |       Woody Harrelsonfilm movie  |                        |       Woody Harrelsonsolo  |                        |           Miles Davis|                        |       Woody Harrelson|                        |       Woody Harrelsonformats killers  |             occ:lover  |       Woody Harrelson|                        |       Woody Harrelsoncomedy reviews  |                        |       Woody Harrelsoncom  |                        |       Woody Harrelson|                        |           Miles Davis|                        |           Miles Davisactor  |                        |       Woody Harrelson|                        |       Woody Harrelson|                        |       Woody Harrelson|                        |       Woody Harrelsonencoding  |                        |       Woody Harrelson|                        |       Woody Harrelsonmarijuana  |                        |       Woody Harrelsonmovie  |                        |       Woody Harrelsonfilm marijuana  |                        |       Woody Harrelsonmarijuana  |                        |       Woody Harrelson|                        |       Woody Harrelsonactor marijuana  |                        |       Woody Harrelsonupcoming  |                        |       Woody Harrelsonstarring  |                        |       Woody Harrelson|                        |       Woody Harrelsonfilm movie  |       occ:heavyweight  |       Woody Harrelsonupcoming  |                        |       Woody Harrelson|                        |       Woody Harrelsonbiography  |                        |       Woody Harrelsonbiography  |                        |       Woody Harrelson|                        |           Miles Davismovie  |                        |       Woody Harrelson|                        |       Woody Harrelson|                        |       Woody Harrelson|                        |       Woody Harrelsonbowling  |                        |       Woody Harrelsonbowling soundtrack...  |                        |       Woody Harrelson|                        |       Woody Harrelson|                        |       Woody Harrelsonmusic  |                        |           Miles Davisactor album  |                        |       Woody Harrelson|                        |       Woody Harrelson|                        |           Miles Davis|                        |       Woody Harrelsoncom musician reviews  |                        |           Miles Davis|                        |       Woody Harrelson|                        |       Woody Harrelsonmarijuana  |            occ:farmer  |       Woody Harrelsonhemp  |                        |       Woody Harrelsonhemp tune  |                        |       Woody Harrelsonhemp  |          occ:activist  |       Woody Harrelsontitle ~  |                        |       Woody Harrelsontitle ~  |                        |       Woody Harrelsontitle ~  |                        |       Woody Harrelsontitle  |                        |           Miles Davis|                        |       Woody Harrelsoncom  |                        |       Woody Harrelsoncom reviews  |                        |       Woody Harrelsonblues  |                        |           Miles Davis|                        |       Woody Harrelson|                        |       Woody Harrelson|                        |       Woody Harrelson|                        |       Woody Harrelsonactors  |                        |       Woody Harrelsonreview  |                        |       Woody Harrelsonclick  |                        |       Woody Harrelson|                        |           Miles Davis|                        |       Woody Harrelson|                        |       Woody Harrelson|                        |       Woody Harrelsoncomedy guest  |                        |       Woody Harrelsonamp  |                        |       Woody Harrelsonw/  |                        |       Woody Harrelsonnbsp w/  |                        |       Woody Harrelson|                        |           Miles Davisnbsp  |                        |           Miles Davis|                        |           Miles Davis|                        |       Woody Harrelsonarrange celebrity...  |                        |       Woody Harrelson|                        |           Miles Davis|                        |           Miles Davisevil smile smiles  |                        |           Miles Davis|                        |           Miles Davis|                        |           Miles Davis|                        |           Miles Davisde  |                        |       Woody Harrelson|                        |           Miles Davis|                        |           Miles Davisformats  |                        |       Woody Harrelsonformats  |                        |           Miles Davis|            byear:1926  |           Miles Davisquintet  |            byear:1926  |           Miles Davisformats  |                        |           Miles Davis|                        |           Miles Davis|                        |           Miles Davis|                        |           Miles Davis|                        |           Miles Davis|            byear:1973  |           Miles Davis|            byear:1973  |           Miles Davisclick title  |                        |           Miles Davisclick title  |                        |           Miles Davis|         occ:trumpeter  |           Miles Davis|         occ:trumpeter  |           Miles Davisinterviews...  |         occ:trumpeter  |           Miles Davisbiography...  |  byear:1967,occ:trumpeter  |           Miles Davis|         occ:trumpeter  |           Miles Davis|            byear:1967  |           Miles Davisrecordings  |            byear:1967  |           Miles Davisrecordings  |                        |           Miles Davisquintet trumpet  |      brthloc:Alton,IL  |           Miles Davis|                        |           Miles Davistrumpet  |                        |           Miles Davis|                        |           Miles Davis|                        |           Miles Davisartist  |                        |           Miles Davis|                        |           Miles Davisalbum jazz  |                        |           Miles Davisalbum  |                        |           Miles Davisalbum music  |                        |           Miles Davis|                        |           Miles Davis|                        |           Miles Davisde  |                        |           Miles Davisquintet trumpet  |                        |           Miles Davismusic nbsp  |          occ:musician  |           Miles Davisalbum  |          occ:musician  |           Miles Davis|                        |           Miles Davis|            byear:1969  |           Miles Davis|                        |           Miles Davisartist  |                        |           Miles Davis|                        |           Miles DavisSeed2tracks  |            byear:1958  |           Miles Davis|                        |       Woody Harrelsonformats rehkram  |                        |           Miles Davis|                        |       Woody Harrelsonfusion music...  |                        |           Miles Davis|                        |           Miles Davisidem  |                        |           Miles Davisbiography videos  |                        |       Woody Harrelsonnbsp  |                        |           Miles Davis|                        |       Woody Harrelsondiscography  |                        |           Miles Davissolos  |                        |           Miles Davis|                        |           Miles Davis|                        |           Miles Davisdisc  |                        |           Miles Davis|                        |           Miles Davis|                        |           Miles Davis|                        |           Miles Davismusic  |                        |           Miles Davis|                        |           Miles Davis|                        |           Miles Davismusic  |                        |           Miles Daviscom poster  |                        |           Miles Davisposter  |                        |           Miles Davisposter  |                        |           Miles Davis|                        |           Miles Davissoundtrack  |                        |           Miles Davis|                        |           Miles Davisdiscography  |            byear:1947  |           Miles Davis|                        |           Miles Davis|            occ:artist  |           Miles Davis|                        |           Miles Davis|                        |           Miles Davis|                        |           Miles Davisbowling  |                        |       Woody Harrelsonmusicians recordings...  |            occ:player  |           Miles Davismusic trumpet  |                        |           Miles Davisdiscography trumpet  |                        |           Miles Davisflute saxophone...  |                        |           Miles Davismusicians  |                        |           Miles Davisstudio  |                        |           Miles Davis|                        |       Woody Harrelson|                        |           Miles Davis|                        |           Miles Davis0.0 0.2 0.4 0.6 0.8keywords referentfeaturesInducedCluster 1InducedCluster2Figure 3: nnp+feat+extfeat+mi Clustering Visual-ization for DAVIS/HARRELSON pseudonameassured when the feature set is rich, or a large docu-ment space is assumed.4 ExperimentsTo test these clustering methods, we collected webpages by making requests to the Google website fora set of target personal names (up to a maximumof 1000 pages per name).
There was no require-ment that the web page be focused on that name, norwas there a minimum number of name occurrences.As a result, some pages clustered only mentionedthe name in passing, or in a specialized, commercialcontext (e.g.
Amazon sales product).The pseudonames were created as follows.
Theretrieval results from two different randomly-selected people were taken, and all references toeither name (in full or part) replaced by a unique,shared pseudoname.
The resulting collection thenconsisted of documents which were ambiguous asto whom they talked about.
The aim of the clus-tering was then to distinguish this artificially con-flated pseudoname.
In addition, a test set of fournaturally occurring polysemous names (such as JimClark), containing an average of 60 instances each,was manually annotated with distinguishing nameIDnumbers and used for a parallel evaluation.The experiments consist of two parts.
The firstoutput is the clustering visualizations whose utilitycan be judged by inspection.
The second is a quanti-tative analysis of the different methodologies.
Bothare conducted over test sets of pseudonames and nat-urally occurring ambiguities.4.1 Clustering VisualizationsFigures 2/3 and 4 each have two subfigures.
Theleft/top figure shows the extracted seed sets.
Theright/bottom figure shows the final clustering of theentire document collection.
In each figure, thereare three columns of information before the dendro-gram.
The first column contains high weighted doc-ument content words.
The second column containsthe extracted features from the document.
The thirdcolumn indicates the real referent.
This is either thereal name of the conflated pseudoname (e.g.
WoodyHarrelson or Miles Davis), or a number indicatingthe referent (e.g.
1 - 20 in the case of Jim Clark).This presentation allows a quick scan of the cluster-ing to reveal correlations.In general, the visualizations are informative.
Oc-casionally, the extractions err.
One time when thepatterns themselves cannot be syntactically faultedcomes in the case where Woody Harrelson?s wifeis extracted as Demi Moore.
The information wasextracted from the sentence: ?Architect Woody Har-relson and his wife realtor Demi Moore ...?
whichappears as a plot description for the movie ?Inde-driver racing  |            occ:driver  |      1racing  |           brthyr:1968  |      1racing  |                        |      1championship  |                        |      1championship  |                        |      1|                        |      1racing  |                        |      1racing  |                        |      1road  |                        |      1statistics  |                        |      1|                        |      1championship driver  |                        |      1championship rally  |                        |      1|                        |      1link  |                        |      1|                        |      1rally  |                        |      1|                        |      1|                        |      1|                        |      1rally  |                        |      1promoter rally  |                        |      1|                        |      1championship  |                        |      1Seed1|                        |      4|                        |      4|                        |      4|                        |      4founder  |                        |      4software  |                        |      4|                        |    All|                        |      4|           occ:founder  |      4|           occ:founder  |      4|           occ:founder  |      4|                        |      4software  |                        |      4|       occ:billionaire  |      4graphics  |                        |      4|                        |      4|                        |      4|                        |      4|                        |      4|      occ:entrepreneur  |      4|                        |      4|                        |      4browser graphics  |                        |      4software  |                        |      4|                        |      9|                        |     11|                        |     11|                        |     11prevention  |                        |     19|                        |     17|                        |     17Seed20.0 0.1 0.2 0.3 0.4 0.5Induced Seed 1 (1 = Racing Jim Clark)Induced Seed 2 (4 = Netscape Jim Clark)keywords features referentdriver racing  |            occ:driver  |      1racing  |           brthyr:1968  |      1racing  |                        |      1championship  |                        |      1championship  |                        |      1|                        |      1racing  |                        |      1racing  |                        |      1road  |                        |      1statistics  |                        |      1|                        |      1championship driver  |                        |      1championship rally  |                        |      1|                        |      1link  |                        |      1|                        |      1rally  |                        |      1|                        |      1|                        |      1|                        |      1rally  |                        |      1promoter rally  |                        |      1|                        |      1championship  |                        |      1Seed1|                        |      4|                        |      4|                        |      4|                        |      4founder  |                        |      4software  |                        |      4|                        |    All|                        |      4|           occ:founder  |      4|           occ:founder  |      4|           occ:founder  |      4|                        |      4software  |                        |      4|       occ:billionaire  |      4graphics  |                        |      4|                        |      4|                        |      4|                        |      4|                        |      4|      occ:entrepreneur  |      4|                        |      4|                        |      4browser graphics  |                        |      4software  |                        |      4|                        |      9|                        |     11|                        |     11|                        |     11prevention  |                        |     19|                        |     17|                        |     17Seed2|                        |     15|                        |     18|                        |     20|                        |     10|                        |      3|                        |      3links  |                        |     14|                        |     14|                        |      2|                        |      5|                        |      5|                        |     13|                        |      1software  |                        |      9|                        |      6|                        |     12|                        |      7|                        |     16|                        |      80.0 0.2 0.4 0.6 0.8Induced Cluster 1(1 = Racing Jim Clark)Induced Cluster 2keywords features referent(4 = Netscape Jim Clark)Figure 4: nnp+feat+extfeat+mi Clustering Visual-ization of Jim Clark Pages: ?1?=Race Car Driver,?4?=Netscape Founder, ?A?=multiple referentscent Proposal?.
Here, untangling of synecdoche isneeded.
For Miles Davis, the incorrectly extractedbirth years refer to record release dates, which takethe same surface form as birth years in some genres.Figure 4 shows a clustering for a naturally occur-ing name ambiguity, in particular that of web pageswhich refer to ?Jim Clark?.
The set was constructedby retrieving 100 web pages, and then labeling thepages with respect to their referent.
As can be seen,the clusterings are highly coherent.
All of the rele-vant pages are included in the seed set, and few in-appropriate pages are added.
This type of clusteringwould be useful to someone searching for a specificindividual named Jim Clark.
Once the clustering hadbeen performed, a user could scan the output, andidentity the ?Jim Clark?
of interest, based both onextracted features and key words.4.2 Evaluation on PseudonamesFor automated pseudoname evaluation purposes, weselected a set of 8 different people for confla-tion, who we presumed had one vastly predominantsense.
We selected these people giving room for his-torical figures, figures from pop culture and mod-ern media culture, as well as ?ordinary?
people.
Weadded people with similar backgrounds (born closeto each other, or having the same profession).
Thefull list was composed of these 8 individuals:Haifa Al-Faisal, William Blake, TomCruise, Woody Harrelson, HermannHesse, Wolfgang Amadeus Mozart, AnnaShusterman, Bryon TosoffFor each, we submitted Google queries, and re-trieved up to 1000 pages each.
We then took thesehit returns, and subsampled to a maximum of 100pages per person.
The person with the smallest rep-resentation was Anna Shusterman with 26 pages.We subsampled by taking the first 100 as orderedlexically.
This may have biased the results some-what towards unreliable web pages, since pages withnumeric addresses tend to be newer and more tran-sient.We evaluated two guanularities of feature extrac-tion.
The small feature set uses high precisionrules to extract occupation (occ), birthday (brthyr),spouse, birth location (brthloc), and school.
Thelarge feature set adds higher recall (and thereforenoisier) patterns for the previous relationships andas well as parent/child relationships.As can be seen from the table, the highest per-forming system combines proper nouns, relevantwords, and the high precision extracted features(nnp+feat+mi and nnp+feat+tfidf).
The extendedfeatures (nnp+feat+extfeat+mi) do not give addi-tional benefit to this combination.
As can be seenfrom the table, the large feature set yields betteroverall performance than the smaller feature set.Clustering Method Disambiguation Accuracyno extracted featuresmajority sense 62.5plain 74.5tfidf 76.7nnp 79.7nnp+tfidf 79.7nnp+mi 82.9w/ extracted features feature set sizesmall largennp+feat 82.5 85.1nnp+feat+extfeat 82.0 84.6nnp+feat+mi 85.6 85.2nnp+feat+tfidf 82.9 86.4Table 5: Disambiguation Accuracy of differentClustering Methods over 28 pseudonamesThis suggests that the increased coverage outweighsthe introduced noise.For the feat+tfidf system, accuracy at the two-class disambiguation was above 80% for 25 out ofthe 28 pairs.
Without these pairs, the average two-class disambiguation performance over the remain-ing pairs is 90%.
In two of the problematic cases, thecontexts of the names are easily confusable, as theindividuals share the same profession and many ofthe same keywords.
More complete biographic pro-files and different clustering biases would be helpfulin fully partitioning these cases.
However, in prac-tice these pseudoname pair situations may be moredifficult than expected for naturally occurring namepairs.
In many occupations that are typically news-worthy (such as actors, authors, musicians, politi-cians, etc.
), there may be a tendency for individu-als to avoid using identical names (or entering thefield entirely) to minimize confusion.
When peoplewith identical names do indeed share the same fieldone would expect a greater effort to providing dis-ambiguating contextual features to distinguish them.We have made some preliminary investigationsinto selecting pages according to the number ofmentions, as opposed to by random.
The resultshave not been conclusive, and continuing work is in-vestigating the cause.4.3 Evaluation on Naturally Ambiguous NamesThe above results have utilized pseudoname test setswhere high accuracy ground truth is automaticallyavailable in large quantities [O(1000) examples pername] to better distinguish model performance.
Ta-ble 6 shows the performance on the four O(60) ex-ample hand-labeled test sets for naturally occurringpolysemous person names.
Given that this is ann-ary classification task, for consistency with theabove experiments the data were assigned to oneof 3 clusters, corresponding to the 2 automaticallyderived first-pass majority seed sets and the resid-ual ?other-use?
classification, but evaluated strictlyon performance for the two major senses.
Whileadditional analyses could be accomplished on theresidual sets, this is difficult given their small size(remaining personal exemplars were mostly single-tons) and lack of evidence on many single-mentionweb pages.
Thus the task of accurately partitioningthe two most common uses and clustering the resid-ual examples for visual exploration may be a naturaland practical use for these classification and visual-ization technologies.Weighting Method Precision RecallTF-IDF .81 .70Mutual Information .88 .73Table 6: Classification performance for naturallyoccurring name ambiguities on 3-way classificationtask (Majority-Use, Secondary-Use, Other-Use).5 ConclusionIn this paper we have presented a set of algorithmsfor finding the real referents for ambiguous per-sonal names in text using unsupervised clusteringand feature extraction methods.
In particular, wehave shown how to learn and use automatically ex-tracted biographic information to improve clusteringresults, and have demonstrated this improvement byevaluating on pseudonames.
We have presented ini-tial results on learning these patterns to extract bio-graphic information for multiple languages, and in-tend to use these techniques for large-scale multilin-gual polysemous name clustering.The results presented here support the automaticclustering of polysemous personal name referentsand visualization of these induced clusters and theirmotivating features.
These distinct referents canbe verified by inspection both of extracted featuresand of the high weighted terms for each document.These clusterings may be useful in two ways.
Firstas a useful visualization tool themselves, and secondas seeds for disambiguating further entities.ReferencesA.
Bagga and B. Baldwin.
1998.
Entity-based cross-documentcoreferencing using the vector space model.
In Chris-tian Boitet and Pete Whitelock, editors, Proceedings of theThirty-Sixth Annual Meeting of the Association for Compu-tational Linguistics and Seventeenth International Confer-ence on Computational Linguistics, pages 79?85, San Fran-cisco, California.
Morgan Kaufmann Publishers.S.
Brin.
1998.
Extracting patterns and relations from the worldwide web.
In WebDB Workshop at 6th International Confer-ence on Extending Database Technology, EDBT?98.M.
E. Califf and R. J. Mooney.
1998.
Relational learningof pattern-match rules for information extraction.
In Work-ing Notes of AAAI Spring Symposium on Applying MachineLearning to Discourse Processing, pages 6?11, Menlo Park,CA.
AAAI Press.D.
Freitag and A. McCallum.
1999.
Information extractionwith hmms and shrinkage.
In Proceedings of the AAAI-99Workshop on Machine Learning for Information Extraction.B.
Gale, K. Church, and D. Yarowsky.
1992.
Work on statisti-cal methods for word sense disambiguation.
In AAAI FallSymposium on Probabilistic Approaches to Natural Lan-guage Processing, pages 54?60, Cambridge, MA.S.
B. Huffman.
1995.
Learning information extraction patternsfrom examples.
In Learning for Natural Language Process-ing, pages 246?260.D.
Ravichandran and E. Hovy.
2002.
Learning surface text pat-terns for a question answering system.
In Proceedings of the40th Annual Meeting of the Association for ComputationalLinguistics.B.
Schiffman, I. Mani, and K. J. Concepcion.
2001.
Producingbiographical summaries: Combining linguistic knowledgewith corpus statistics.
In Proceedings of the 39th AnnualMeeting of the Association for Computational Linguistics.D.
A. Smith and G. Crane.
2002.
Disambiguating geographicnames in a historic digital library.
In Proceedings of ECDL,pages 127?136.N.
Wacholder, Y. Ravin, and M. Choi.
1997.
Disambiguationof proper names in text.
In Proceedings of Fifth Conferenceon Applied Natural Language Processing, pages 202?208.R.
Yangarber, R. Grishman, P. Tapanainen, and S. Huttunen.2000.
Unsupervised discovery of scenario-level patterns forinformation extraction.
In Proceedings of the Sixth Con-ference on Applied Natural Language Processing, (ANLP-NAACL 2000), pages 282?289.
