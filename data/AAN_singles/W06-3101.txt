Proceedings of the Workshop on Statistical Machine Translation, pages 1?6,New York City, June 2006. c?2006 Association for Computational LinguisticsMorpho-syntactic Information for Automatic Error Analysis of StatisticalMachine Translation OutputMaja Popovic?
?Hermann Ney?Adria` de Gispert?Jose?
B. Marin?o?Deepa Gupta?Marcello Federico?Patrik Lambert?Rafael Banchs??
Lehrstuhl fu?r Informatik VI - Computer Science Department, RWTH Aachen University, Aachen, Germany?
TALP Research Center, Universitat Polite`cnica de Catalunya (UPC), Barcelona, Spain?
ITC-irst, Centro per la Ricerca Scientifica e Tecnologica, Trento, Italy{popovic,ney}@informatik.rwth-aachen.de {agispert,canton}@gps.tsc.upc.es{gupta,federico}@itc.it {lambert,banchs}@gps.tsc.upc.esAbstractEvaluation of machine translation outputis an important but difficult task.
Over thelast years, a variety of automatic evalua-tion measures have been studied, some ofthem like Word Error Rate (WER), Posi-tion Independent Word Error Rate (PER)and BLEU and NIST scores have becomewidely used tools for comparing differentsystems as well as for evaluating improve-ments within one system.
However, thesemeasures do not give any details aboutthe nature of translation errors.
Thereforesome analysis of the generated output isneeded in order to identify the main prob-lems and to focus the research efforts.
Onthe other hand, human evaluation is a timeconsuming and expensive task.
In thispaper, we investigate methods for usingof morpho-syntactic information for auto-matic evaluation: standard error measuresWER and PER are calculated on distinctword classes and forms in order to get abetter idea about the nature of translationerrors and possibilities for improvements.1 IntroductionThe evaluation of the generated output is an impor-tant issue for all natural language processing (NLP)tasks, especially for machine translation (MT).
Au-tomatic evaluation is preferred because human eval-uation is a time consuming and expensive task.A variety of automatic evaluation measures havebeen proposed and studied over the last years, someof them are shown to be a very useful tool for com-paring different systems as well as for evaluatingimprovements within one system.
The most widelyused are Word Error Rate (WER), Position Indepen-dent Word Error Rate (PER), the BLEU score (Pap-ineni et al, 2002) and the NIST score (Doddington,2002).
However, none of these measures give anydetails about the nature of translation errors.
A rela-tionship between these error measures and the actualerrors in the translation outputs is not easy to find.Therefore some analysis of the translation errors isnecessary in order to define the main problems andto focus the research efforts.
A framework for hu-man error analysis and error classification has beenproposed in (Vilar et al, 2006), but like human eval-uation, this is also a time consuming task.The goal of this work is to present a frameworkfor automatic error analysis of machine translationoutput based on morpho-syntactic information.2 Related WorkThere is a number of publications dealing withvarious automatic evaluation measures for machinetranslation output, some of them proposing newmeasures, some proposing improvements and exten-sions of the existing ones (Doddington, 2002; Pap-ineni et al, 2002; Babych and Hartley, 2004; Ma-tusov et al, 2005).
Semi-automatic evaluation mea-sures have been also investigated, for example in(Nie?en et al, 2000).
An automatic metric whichuses base forms and synonyms of the words in or-der to correlate better to human judgements has been1proposed in (Banerjee and Lavie, 2005).
However,error analysis is still a rather unexplored area.
Aframework for human error analysis and error clas-sification has been proposed in (Vilar et al, 2006)and a detailed analysis of the obtained results hasbeen carried out.
Automatic methods for error anal-ysis to our knowledge have not been studied yet.Many publications propose the use of morpho-syntactic information for improving the perfor-mance of a statistical machine translation system.Various methods for treating morphological andsyntactical differences between German and Englishare investigated in (Nie?en and Ney, 2000; Nie?enand Ney, 2001a; Nie?en and Ney, 2001b).
Mor-phological analysis has been used for improvingArabic-English translation (Lee, 2004), for Serbian-English translation (Popovic?
et al, 2005) as well asfor Czech-English translation (Goldwater and Mc-Closky, 2005).
Inflectional morphology of Spanishverbs is dealt with in (Popovic?
and Ney, 2004; deGispert et al, 2005).
To the best of our knowledge,the use of morpho-syntactic information for erroranalysis of translation output has not been investi-gated so far.3 Morpho-syntactic Information andAutomatic EvaluationWe propose the use of morpho-syntactic informa-tion in combination with the automatic evaluationmeasures WER and PER in order to get more detailsabout the translation errors.We investigate two types of potential problems forthe translation with the Spanish-English languagepair:?
syntactic differences between the two lan-guages considering nouns and adjectives?
inflections in the Spanish language consideringmainly verbs, adjectives and nounsAs any other automatic evaluation measures,these novel measures will be far from perfect.
Pos-sible POS-tagging errors may introduce additionalnoise.
However, we expect this noise to be suffi-ciently small and the new measures to be able to givesufficiently clear ideas about particular errors.3.1 Syntactic differencesAdjectives in the Spanish language are usuallyplaced after the corresponding noun, whereas in En-glish is the other way round.
Although in most casesthe phrase based translation system is able to han-dle these local permutations correctly, some errorsare still present, especially for unseen or rarely seennoun-adjective groups.
In order to investigate thistype of errors, we extract the nouns and adjectivesfrom both the reference translations and the sys-tem output and then calculate WER and PER.
If thedifference between the obtained WER and PER islarge, this indicates reordering errors: a number ofnouns and adjectives is translated correctly but in thewrong order.3.2 Spanish inflectionsSpanish has a rich inflectional morphology, espe-cially for verbs.
Person and tense are expressedby the suffix so that many different full forms ofone verb exist.
Spanish adjectives, in contrast toEnglish, have four possible inflectional forms de-pending on gender and number.
Therefore the er-ror rates for those word classes are expected to behigher for Spanish than for English.
Also, the er-ror rates for the Spanish base forms are expected tobe lower than for the full forms.
In order to investi-gate potential inflection errors, we compare the PERfor verbs, adjectives and nouns for both languages.For the Spanish language, we also investigate differ-ences between full form PER and base form PER:the larger these differences, more inflection errorsare present.4 Experimental Settings4.1 Task and CorpusThe corpus analysed in this work is built in theframework of the TC-Star project.
It contains morethan one million sentences and about 35 million run-ning words of the Spanish and English EuropeanParliament Plenary Sessions (EPPS).
A descriptionof the EPPS data can be found in (Vilar et al, 2005).In order to analyse effects of data sparseness, wehave randomly extracted a small subset referred toas 13k containing about thirteen thousand sentencesand 370k running words (about 1% of the original2Training corpus: Spanish Englishfull Sentences 1281427Running Words 36578514 34918192Vocabulary 153124 106496Singletons [%] 35.2 36.213k Sentences 13360Running Words 385198 366055Vocabulary 22425 16326Singletons [%] 47.6 43.7Dev: Sentences 1008Running Words 25778 26070Distinct Words 3895 3173OOVs (full) [%] 0.15 0.09OOVs (13k) [%] 2.7 1.7Test: Sentences 840 1094Running Words 22774 26917Distinct Words 4081 3958OOVs (full) [%] 0.14 0.25OOVs (13k) [%] 2.8 2.6Table 1: Corpus statistics for the Spanish-EnglishEPPS task (running words include punctuationmarks)corpus).
The statistics of the corpora can be seen inTable 1.4.2 Translation SystemThe statistical machine translation system used inthis work is based on a log-linear combination ofseven different models.
The most important ones arephrase based models in both directions, additionallyIBM1 models at the phrase level in both directionsas well as phrase and length penalty are used.
Amore detailed description of the system can be foundin (Vilar et al, 2005; Zens et al, 2005).4.3 ExperimentsThe translation experiments have been done in bothtranslation directions on both sizes of the corpus.
Inorder to examine improvements of the baseline sys-tem, a new system with POS-based word reorderingsof nouns and adjectives as proposed in (Popovic?
andNey, 2006) is also analysed.
Adjectives in the Span-ish language are usually placed after the correspond-ing noun, whereas for English it is the other wayround.
Therefore, local reorderings of nouns and ad-Spanish?English WER PER BLEUfull baseline 34.5 25.5 54.7reorder 33.5 25.2 56.413k baseline 41.8 30.7 43.2reorder 38.9 29.5 48.5English?Spanish WER PER BLEUfull baseline 39.7 30.6 47.8reorder 39.6 30.5 48.313k baseline 49.6 37.4 36.2reorder 48.1 36.5 37.7Table 2: Translation Results [%]jective groups in the source language have been ap-plied.
If the source language is Spanish, each noun ismoved behind the corresponding adjective group.
Ifthe source language is English, each adjective groupis moved behind the corresponding noun.
An adverbfollowed by an adjective (e.g.
?more important?)
ortwo adjectives with a coordinate conjunction in be-tween (e.g.
?economic and political?)
are treated asan adjective group.
Standard translation results arepresented in Table 2.5 Error Analysis5.1 Syntactic errorsAs explained in Section 3.1, reordering errors dueto syntactic differences between two languages havebeen measured by the relative difference betweenWER and PER calculated on nouns and adjectives.Corresponding relative differences are calculatedalso for verbs as well as adjectives and nouns sep-arately.Table 3 presents the relative differences for theEnglish and Spanish output.
It can be seen thatthe PER/WER difference for nouns and adjectivesis relatively high for both language pairs (more than20%), and for the English output is higher than forthe Spanish one.
This corresponds to the fact thatthe Spanish language has a rather free word order:although the adjective usually is placed behind thenoun, this is not always the case.
On the other hand,adjectives in English are always placed before thecorresponding noun.
It can also be seen that thedifference is higher for the reduced corpus for bothoutputs indicating that the local reordering problem3English output 1?
PERWERfull nouns+adjectives 24.7+reordering 20.8verbs 4.1adjectives 10.2nouns 20.113k nouns+adjectives 25.7+reordering 20.1verbs 4.6adjectives 8.4nouns 19.1Spanish output 1?
PERWERfull nouns+adjectives 21.5+reordering 20.3verbs 3.3adjectives 5.6nouns 16.913k nouns+adjectives 22.9+reordering 19.8verbs 3.9adjectives 5.4nouns 19.3Table 3: Relative difference between PER andWER [%] for different word classesis more important when only small amount of train-ing data is available.
As mentioned in Section 3.1,the phrase based translation system is able to gen-erate frequent noun-adjective groups in the correctword order, but unseen or rarely seen groups intro-duce difficulties.Furthermore, the results show that the POS-basedreordering of adjectives and nouns leads to a de-crease of the PER/WER difference for both out-puts and for both corpora.
Relative decrease of thePER/WER difference is larger for the small corpusthan for the full corpus.
It can also be noted that therelative decrease for both corpora is larger for theEnglish output than for the Spanish one due to freeword order - since the Spanish adjective group is notalways placed behind the noun, some reorderings inEnglish are not really needed.For the verbs, PER/WER difference is less than5% for both outputs and both training corpora, in-dicating that the word order of verbs is not an im-English output PERfull verbs 44.8adjectives 27.3nouns 23.013k verbs 56.1adjectives 38.1nouns 31.7Spanish output PERfull verbs 61.4adjectives 41.8nouns 28.513k verbs 73.0adjectives 50.9nouns 37.0Table 4: PER [%] for different word classesportant issue for the Spanish-English language pair.PER/WER difference for adjectives and nouns ishigher than for verbs, for the nouns being signifi-cantly higher than for adjectives.
The reason for thisis probably the fact that word order differences in-volving only the nouns are also present, for example?export control = control de exportacio?n?.5.2 Inflectional errorsTable 4 presents the PER for different word classesfor the English and Spanish output respectively.
Itcan be seen that all PERs are higher for the Spanishoutput than for the English one due to the rich in-flectional morphology of the Spanish language.
Itcan be also seen that the Spanish verbs are espe-cially problematic (as stated in (Vilar et al, 2006))reaching 60% of PER for the full corpus and morethan 70% for the reduced corpus.
Spanish adjectivesalso have a significantly higher PER than the Englishones, whereas for the nouns this difference is not sohigh.Results of the further analysis of inflectional er-rors are presented in Table 5.
Relative differencebetween full form PER and base form PER is sig-nificantly lower for adjectives and nouns than forverbs, thus showing that the verb inflections are themain source of translation errors into the Spanishlanguage.Furthermore, it can be seen that for the small cor-4Spanish output 1?
PERbPERffull verbs 26.9adjectives 9.3nouns 8.413k verbs 23.7adjectives 15.1nouns 6.5Table 5: Relative difference between PER of baseforms and PER of full forms [%] for the Spanishoutputpus base/full PER difference for verbs and nouns isbasically the same as for the full corpus.
Since nounsin Spanish only have singular and plural form as inEnglish, the number of unseen forms is not partic-ularly enlarged by the reduction of the training cor-pus.
On the other hand, base/full PER difference ofadjectives is significantly higher for the small corpusdue to an increased number of unseen adjective fullforms.As for verbs, intuitively it might be expected thatthe number of inflectional errors for this word classalso increases by reducing the training corpus, evenmore than for adjectives.
However, the base/fullPER difference is not larger for the small corpus,but even smaller.
This is indicating that the problemof choosing the right inflection of a Spanish verb ap-parently is not related to the number of unseen fullforms since the number of inflectional errors is veryhigh even when the translation system is trained ona very large corpus.6 ConclusionIn this work, we presented a framework for auto-matic analysis of translation errors based on the useof morpho-syntactic information.
We carried out adetailed analysis which has shown that the resultsobtained by our method correspond to those ob-tained by human error analysis in (Vilar et al, 2006).Additionally, it has been shown that the improve-ments of the baseline system can be adequately mea-sured as well.This work is just a first step towards the devel-opment of linguistically-informed evaluation mea-sures which provide partial and more specific infor-mation of certain translation problems.
Such mea-sures are very important to understand what are theweaknesses of a statistical machine translation sys-tem, and what are the best ways and methods forimprovements.For our future work, we plan to extend the pro-posed measures in order to carry out a more de-tailed error analysis, for example examinating dif-ferent types of inflection errors for Spanish verbs.We also plan to investigate other types of translationerrors and other language pairs.AcknowledgementsThis work was partly supported by the TC-STARproject by the European Community (FP6-506738)and partly by the Generalitat de Catalunya and theEuropean Social Fund.ReferencesBogdan Babych and Anthony Hartley.
2004.
Extendingbleu mt evaluation method with frequency weighting.In Proc.
of the 42nd Annual Meeting of the Associa-tion for Computational Linguistics (ACL), Barcelona,Spain, July.Satanjeev Banerjee and Alon Lavie.
2005.
Meteor:An automatic metric for mt evaluation with improvedcorrelation with human judgements.
In 43rd AnnualMeeting of the Assoc.
for Computational Linguistics:Proc.
Workshop on Intrinsic and Extrinsic EvaluationMeasures for MT and/or Summarization, pages 65?72,Ann Arbor, MI, June.Adria` de Gispert, Jose?
B. Marin?o, and Josep M. Crego.2005.
Improving statistical machine translation byclassifying and generalizing inflected verb forms.
InProc.
of the 9th European Conf.
on Speech Commu-nication and Technology (Interspeech), pages 3185?3188, Lisbon, Portugal, September.George Doddington.
2002.
Automatic evaluation of ma-chine translation quality using n-gram co-occurrencestatistics.
In Proc.
ARPA Workshop on Human Lan-guage Technology, pages 128?132, San Diego.Sharon Goldwater and David McClosky.
2005.
Improv-ing stastistical machine translation through morpho-logical analysis.
In Proc.
of the Conf.
on EmpiricalMethods for Natural Language Processing (EMNLP),Vancouver, Canada, October.Young-suk Lee.
2004.
Morphological analysis for statis-tical machine translation.
In Proc.
2004 Meeting of theNorth American chapter of the Association for Compu-tational Linguistics (HLT-NAACL), Boston, MA, May.5Evgeny Matusov, Gregor Leusch, Oliver Bender, andHermann Ney.
2005.
Evaluating machine transla-tion output with automatic sentence segmentation.
InProceedings of the International Workshop on SpokenLanguage Translation (IWSLT), pages 148?154, Pitts-burgh, PA, October.Sonja Nie?en and Hermann Ney.
2000.
Improving SMTquality with morpho-syntactic analysis.
In COLING?00: The 18th Int.
Conf.
on Computational Linguistics,pages 1081?1085, Saarbru?cken, Germany, July.Sonja Nie?en and Hermann Ney.
2001a.
Morpho-syntactic analysis for reordering in statistical machinetranslation.
In Proc.
MT Summit VIII, pages 247?252,Santiago de Compostela, Galicia, Spain, September.Sonja Nie?en and Hermann Ney.
2001b.
Toward hier-archical models for statistical machine translation ofinflected languages.
In Data-Driven Machine Trans-lation Workshop, pages 47?54, Toulouse, France, July.Sonja Nie?en, Franz J. Och, Gregor Leusch, and Her-mann Ney.
2000.
An evaluation tool for ma-chine translation: Fast evaluation for mt research.
InProc.
Second Int.
Conf.
on Language Resources andEvaluation (LREC), pages 39?45, Athens, Greece,May.Kishore Papineni, Salim Roukos, Todd Ward, and Wie-Jing Zhu.
2002.
BLEU: a method for automatic eval-uation of machine translation.
In Proc.
of the 40thAnnual Meeting of the Association for ComputationalLinguistics (ACL), pages 311?318, Philadelphia, PA,July.Maja Popovic?
and Hermann Ney.
2004.
Towards the useof word stems & suffixes for statistical machine trans-lation.
In Proc.
4th Int.
Conf.
on Language Resourcesand Evaluation (LREC), pages 1585?1588, Lissabon,Portugal, May.Maja Popovic?
and Hermann Ney.
2006.
POS-basedword reorderings for statistical machine translation.
InProc.
of the Fifth Int.
Conf.
on Language Resourcesand Evaluation (LREC), Genova, Italy, May.Maja Popovic?, David Vilar, Hermann Ney, SlobodanJovic?ic?, and Zoran ?Saric?.
2005.
Augmenting a smallparallel text with morpho-syntactic language resourcesfor Serbian?English statistical machine translation.
In43rd Annual Meeting of the Assoc.
for ComputationalLinguistics: Proc.
Workshop on Building and UsingParallel Texts: Data-Driven Machine Translation andBeyond, pages 41?48, Ann Arbor, MI, June.David Vilar, Evgeny Matusov, Sas?a Hasan, Richard Zens,and Hermann Ney.
2005.
Statistical machine transla-tion of european parliamentary speeches.
In Proc.
MTSummit X, pages 259?266, Phuket, Thailand, Septem-ber.David Vilar, Jia Xu, Luis Fernando D?Haro, and Her-mann Ney.
2006.
Error analysis of statistical machinetranslation output.
In Proc.
of the Fifth Int.
Conf.
onLanguage Resources and Evaluation (LREC), page toappear, Genova, Italy, May.Richard Zens, Oliver Bender, Sas?a Hasan, ShahramKhadivi, Evgeny Matusov, Jia Xu, Yuqi Zhang, andHermann Ney.
2005.
The RWTH phrase-based statis-tical machine translation system.
In Proceedings of theInternational Workshop on Spoken Language Transla-tion (IWSLT), pages 155?162, Pittsburgh, PA, October.6
