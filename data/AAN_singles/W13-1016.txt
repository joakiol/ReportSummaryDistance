Proceedings of the 9th Workshop on Multiword Expressions (MWE 2013), pages 106?115,Atlanta, Georgia, 13-14 June 2013. c?2013 Association for Computational LinguisticsSyntactic Identification of Occurrences of Multiword Expressions in Textusing a Lexicon with Dependency StructuresEduard Bejc?ek, Pavel Stran?a?k, Pavel PecinaCharles University in Prague, Faculty of Mathematics and Physics,Institute of Formal and Applied LinguisticsMalostranske?
na?me?st??
25, 118 00 Praha 1, Czechia{bejcek,stranak,pecina}@ufal.mff.cuni.czAbstractWe deal with syntactic identification of oc-currences of multiword expression (MWE)from an existing dictionary in a text corpus.The MWEs we identify can be of arbitrarylength and can be interrupted in the surfacesentence.
We analyse and compare three ap-proaches based on linguistic analysis at a vary-ing level, ranging from surface word order todeep syntax.
The evaluation is conducted us-ing two corpora: the Prague Dependency Tree-bank and Czech National Corpus.
We use thedictionary of multiword expressions SemLex,that was compiled by annotating the PragueDependency Treebank and includes deep syn-tactic dependency trees of all MWEs.1 IntroductionMultiword expressions (MWEs) exist on the inter-face of syntax, semantics, and lexicon, yet they arealmost completely absent from major syntactic the-ories and semantic formalisms.
They also have inter-esting morphological properties and for all these rea-sons, they are important, but challenging for NaturalLanguage Processing (NLP).
Recent advances showthat taking MWEs into account can improve NLPtasks such as dependency parsing (Nivre and Nils-son, 2004; Eryig?it et al 2011), constituency parsing(Arun and Keller, 2005), text generation (Hogan etal., 2007), or machine translation (Carpuat and Diab,2010).The Prague Dependency Treebank (PDT) ofCzech and the associated lexicon of MWEs Sem-Lex1 offer a unique opportunity for experimentation1http://ufal.mff.cuni.cz/lexemann/mwe/semlex.zipwith MWEs.
In this paper, we focus on identifica-tion of their syntactic structures in the treebank us-ing various levels of linguistic analysis and match-ing algorithms.2 We compare approaches operatingon manually and automatically annotated data withvarious depth of annotation from two sources: thePrague Dependency Treebank and Czech NationalCorpus (CNC).The remainder of the paper is organised as fol-lows.
Section 2 describes the state of the art of inacquisition and identification of MWEs.
Section 3explains what we consider a MWE.
In Section 4we describe the data used for our experiments.
Sec-tion 5 gives the details of our experiments, and inSection 6 we analyse and discuss the results.
Con-clusions from the analysis are drawn in Section 7.2 Processing of Multiword Expressionsand Related WorkAutomatic processing of multiword expressions in-cludes two distinct (but interlinked) tasks.
Most ofthe effort has been put into acquisition of MWEsappearing in a particular text corpus into a lexi-con of MWEs (types) not necessarily linked withtheir occurrences (instances) in the text.
The best-performing methods are usually based on lexical as-sociation measures that exploit statistical evidenceof word occurrences and co-occurrences acquiredfrom a corpus to determine degree of lexical asso-ciation between words (Pecina, 2005).
Expressionsthat consist of words with high association are then2We do not aim at disambiguating the occurrences as figura-tive or literal.
We have not observed enough literal uses to sub-stantiate working on this step.
There are bigger improvementsto be gained from better identification of syntactic occurrences.106denoted as MWEs.
Most of the current approachesare limited to bigrams despite the fact that higher-order MWEs are quite common.The task of identification of MWE occurrencesexpects a list of MWEs as the input and identifiestheir occurrences (instances) in a corpus.
This mayseem to be a trivial problem.
However, the complexnature of this phenomenon gives rise to problems onall linguistic levels of analysis: morphology, syntax,and semantics.In morphologically complex languages, a singleMWE can appear in a number of morphologicalvariants, which differ in forms of their individualcomponents; and at the same time, a sequence ofwords whose base forms match with base formsof components of a given MWE do not neces-sarily represent an instance of this MWE (Praco-val dnem i noc??
/ He?s been working day and nightvs.
Ti dva byli jako den a noc / Those two were asday and night).MWEs differ in the level of syntactic fixedness.On the one hand, certain MWEs can be modifiedby inserting words in between their componentsor by changing word order.
Such expressions canonly be identified by matching their syntactic struc-tures, but only if a reliable syntactic information isavailable in both the lexion and text (Po pr?evratupadaly hlavy / After the coup, heads were rollingvs.
Hlavy zkorumpovany?ch na?me?stku?
budou padatjedna za druhou / One head of a corrupt deputywill be rolling after the other).
On the other hand,some MWEs can appear only as fixed expressionswith no modifications allowed.
In that case, the syn-tactic matching approach can miss-indicate their in-stances because of an inserted word or altered wordorder (Vys?s???
spolec?nost / High society vs.
*Vys?s???
bo-hats???
spolec?nost / High rich society).From the semantic point of view, MWEs are of-ten characterized by more or less non-compositional(figurative) meaning.
Their components, however,can also occur with the same syntax but composi-tional (literal) semantics, and therefore not actingas MWEs (Jedinou branku dal az?
v posledn??
minute?za?pasu / He scored his only goal in the last minute ofthe match.
vs.
Rozhodc???
dal branku zpe?t na sve?
m?
?sto/ The referee put a goal back to its place).Automatic discrimination between figurative andliteral meaning is a challenging task similar toword sense disambiguation which has been stud-ied extensively: Katz and Giesbrecht (2006), Cooket al(2007), Hashimoto and Kawahara (2008), Liand Sporleder (2009), and Fothergill and Baldwin(2011).
Seretan (2010) includes MWE identification(based on a lexicon) in a syntactic parser and reportsan improvement of parsing quality.
As a by-product,the parser identified occurrences of MWEs from alexicon.
Similarly, Green et al(2013) embed identi-fication of some MWEs in a Tree Substitution Gram-mar and achieve improvement both in parsing qual-ity and MWE identification effectiveness.
None ofthese works, however, attempt to identify all MWEs,regardless their length or complexity, which is themain goal of this paper.3 Definition of Multiword ExpressionsWe can use the rough definition of MWEs put for-ward by Sag et al(2002): ?idiosyncratic interpreta-tions that cross word boundaries (or spaces)?.
Wecan also start from their ?
or Bauer?s (1983) ?
ba-sic classification of MWEs as lexicalised or insti-tutionalised phrases, where lexicalised phrases in-clude some syntactic, semantic or lexical (i.e.
wordform) element, that is idiosyncratic.
Institutionalisedphrases are syntactically and semantically compo-sitional, but still require a particular lexical choice,e.g.
disallowing synonyms (mobile phone, but not*movable phone).We need to make just one small adjustment to theabove: ?phrase?
above must be understood as a sub-tree, i.e.
it can have holes in the surface sentence, butnot in terms of a dependency tree.In reality there is no clear boundary, in particu-lar between the institutional phrases and other collo-cations.
Like many other traditional linguistic cate-gories, cf.
Manning (2003), this phenomenon seemsto be more continuous than categorial.For the purpose of this paper, however, it is notimportant at all.
We simply try to find all instancesof the expressions (subtrees) from a lexicon in a text,whatever form the expression may take in a sen-tence.4 DataIn this work we use two datasets: Czech NationalCorpus (CNC), version SYN2006-PUB, and the107Prague Dependency Treebank (PDT), version 2.5.We run and compare results of our experiments onboth manual annotation of PDT, and automatic anal-ysis of both PDT and CNC (see Section 5.3).
Wealso make use of SemLex, a lexicon of MWEs inthe PDT featuring their dependency structures thatis described in Section 4.3.4.1 Corpora ?
Czech National Corpus andPrague Dependency TreebankCNC is a large3 corpus of Czech.
Its released ver-sions are automatically segmented and they containautomatic morphological tagging (Hajic?, 2004).PDT (Bejc?ek et al 2011) is a smaller news-domain corpus based on a subset of the news sectionof CNC.
It contains approx.
0.8 million words thathave three layers of annotation: morphological, ana-lytical (surface syntax), and tectogrammatical (deepsyntax).Annotation of a sentence on the morphologicallayer consists of attaching morphological lemmaand tag to the tokens.
A sentence at the analyticallayer is represented as a rooted ordered tree with la-belled nodes.
The dependency relation between twonodes is captured by an edge with a functional label.On the tectogrammatical layer only content wordsform nodes in a tree (t-nodes).4 Auxiliary words arerepresented by various attributes of t-nodes, as theydo not have their own lexical meaning, but rathermodify the meaning of the content words.
Each t-node has a t-lemma: an attribute whose value is thenode?s basic lexical form, and a dependency func-tion that relates it to its parent.
Figure 1 shows therelations between the neighbouring layers of PDT.4.2 MWE in Prague Dependency Treebank 2.5In the Functional Generative Description (Sgall etal., 1986, FGD)5 the tectogrammatical layer is con-strued as a layer of the linguistic meaning of text.This meaning is composed by means of ?deep?
(tecto-grammatical) syntax from single-meaning-carrying units: monosemic lexemes.3It contains 200 mil.
words in SYN2000, 600 mil.
inSYN2006-PUB; http://www.korpus.cz.4with a few exceptions (personal pronouns or coord.
heads)5FGD is a framework for systematic description of a lan-guage, that the PDT project is based upon.Byl         by        ?el       do     lesa       .Byl          by                   do                 lesa?elAuxV          AuxV                     AuxPb?t             b?t            j?t            do        les             .
VpYS---XR-AA---      Vc-------------       VpYS---XR-AA---    RR?2----------    NNIS2-----A----        Z:-------------AdvPredAuxSj?tPRED#PersPronACT  lesDIR3atree.rfa/aux.rfa/aux.rfa/lex.rfa/aux.rfa/lex.rft - layera - laye rm - layer.AuxKFigure 1: A visualisation of the annotation schema ofPDT.
Lit.
: ?
[He] would have gone into forest.
?In order to better facilitate this concept of t-layer,all multiword expressions in the release of PDT 2.5(Bejc?ek et al 2011) have been annotated and theyare by default displayed as single units, althoughtheir inner structure is still retained.A lexicon of the MWEs has been compiled.
Asimple view of the result of this annotation is givenin the Figure 2.
A detailed description can be foundin Bejc?ek and Stran?a?k (2010), and Stran?a?k (2010).The MWEs in PDT 2.5 include both multiword lex-emes (phrasemes, idioms) and named entities (NEs).In the present work we ignore the named entities,concentrating on the lexemes.
Some NEs (names ofpersons, geographical entities) share characteristicsof multiword lexemes, other NEs do not (addresses,bibliographic information).We build on the PDT 2.5 data and MWE lexiconSemLex (Section 4.3) to evaluate the approach withvarious automatic methods for detection of MWEs.4.3 Lexicon of MWEs ?
SemLexSemLex is the lexicon of all the MWEs annotatorsidentified during the preparation of PDT 2.5 t-layer.In the PDT 2.5 these instances of MWEs can then bedisplayed as single nodes and all the MWEs them-selves are compiled in the SemLex lexicon.
The lex-icon itself is freely available.
See http://ufal.mff.cuni.cz/lexemann/mwe/.
Length (size)108Can word sense disambiguation help statistical machine translation?helpdisambiguationsensewordtranslationmachinestatistical#roothelpWSD MT#rootstatisticalWord sense disambiguationMachine translation ?BASIC_FORM: Word sense disambiguationTREE_STRUCT: disambiguation?sense?wordLEMMATIZED: ?
?SemLexFigure 2: An illustration of changes in t-trees in PDT 2.5;every MWE forms a single node and has its lexicon entrydistribution of MWEs in PDT 2.5 is given in Table 1.There are three attributes of SemLex entries cru-cial for our task:BASIC FORM ?
The basic form of a MWE.
Inmany languages including Czech it often containsword forms in other than the basic form for the givenword on its own.
E.g.
?vysoke?
uc?en???
contains aneuter suffix of the adjective ?vysoky??
(high) be-cause of the required agreement in gender with thenoun, whereas the traditional lemma of adjectives inCzech is in the masculine form.LEMMATIZED ?
?Lemmatised BASIC FORM?,i.e.
take the basic form of an entry and substituteeach form with its morphological lemma.
This at-tribute is used for the identification of MWEs on themorphological layer.
For more details see Section 5.TREE STRUCT (TS) ?
A simplified tectogram-matical dependency tree structure of an entry.
Eachnode in this tree structure has only two attributes: itstectogrammatical lemma, and a reference to its ef-fective parent.4.4 Enhancing SemLex for the ExperimentsSemLex contains all the information we use for theidentification of MWEs on t-layer.6 It also containsbasic information we use for MWE identification onm-layer: the basic form and the lemmatized form ofeach entry.
For the experiments with MWE iden-tification on analytical (surface syntactic) layer we6Automatic identification of MWES was, after all, one ofthe reasons for its construction.a) len types instances2 7063 189143 1260 24494 305 4485 100 1416 42 427 16 158 4 59 4 311 1 012 2 2b) len types instances18 148 5342 7444 194903 843 14074 162 2445 34 326 13 87 3 18 4 19 1 110 0 0Table 1: Distribution of MWE length in terms of words (a)and t-nodes (b) in SemLex (types) and PDT (instances).need to add some information about the surface syn-tactic structures of MWEs.
Given the annotated oc-currences of MWEs in the t-layer and links fromt-layer to a-layer, the extraction is straightforward.Since one tectogrammatical TS can correspond toseveral analytical TSs that contain auxiliaries anduse morphological lemmas, we add a list of a-layerTSs with their frequency in data to each SemLex en-try (MWE).
In reality the difference between t-layerand a-layer is unfortunately not as big as one couldexpect.
Lemmas of t-nodes still often include evenminute morphological variants, which goes againstthe vision of tectogrammatics, as described in Sgallet al(1986).7 Our methods would benefit from moreunified t-lemmas, see also Section 6.2.5 Methodology of ExperimentsSemLex ?
with its almost 8,000 types of MWEs andtheir 22,000 instances identified in PDT ?
allows usto measure accuracy of MWE identification on vari-ous layers, since it is linked with the different layersof PDT 2.5.
In this section, we present the methodfor identification of MWEs on t-layer in compari-son with identification on a-layer and m-layer.
The7These variants are unified in FGD theory, but time consum-ing to annotate in practice.
Therefore, this aspect was left outfrom the current version of PDT.8Indeed, there are expressions that are multiword, but?single-node?.
E.g.
: the preposition in bez va?ha?n??
(without hes-itation) does not have its own node on t-layer; the phrase naspra?vnou m?
?ru (lit.
: into correct scale) is already annotated asone phrasal node in PDT with the lemma ?na spra?vnou m??ru?
;the verbal expression ume?t si pr?edstavit (can imagine) has againonly one node for reflexive verb ?pr?edstavit si?
plus an attributefor the ability (representing ?ume?t?
as explained in Section 4.1).109idea of using tectogrammatical TS for identificationis that with a proper tectogrammatical layer (as itis proposed in FGD, i.e.
with correct lemmatisation,added nodes in place of ellipses, etc.
), this approachshould have the highest Precision.Our approach to identification of MWEs in thiswork is purely syntactic.
We simply try to findMWEs from a lexicon in any form they may take(including partial ellipses in coordination, etc.).
Wedo not try to exploit semantics, instead we want toput a solid baseline for future work which may doso, as mentioned in Section 2.5.1 MWE Identification on t-layerWe assume that each occurrence of a given MWEhas the same t-lemmas and the same t-layer struc-ture anywhere in the text.
During the manual con-struction of SemLex, these tectogrammatical ?treestructures?
(TSs) were extracted from PDT 2.5 andinserted into the lexicon.
In general this approachworks fine and for majority of MWEs only one TSwas obtained.
For the MWEs with more than one TSin data we used the most frequent one.
These casesare due to some problems of t-layer, not deficienciesof the theoretical approach.
See section 6.2 for thediscussion of the problems.These TSs are taken one by one and we try to findthem in the tectogrammatical structures of the inputsentences.
Input files are processed in parallel.
Thecriteria for matching are so far only t-lemmas andtopology of the subtree.9 Comparison of tree struc-tures is done from the deepest node and we consideronly perfect matches of structure and t-lemmata.5.2 MWE Identification on a-layer and m-layerWe use identification of MWE occurrences on a-layer and m-layer mainly for comparison with ourapproach based on the t-layer.9It is not sufficient, though.
Auxiliary words that are ig-nored on t-layer are occasionally necessary for distinguishingMWE from similar group of nodes.
(E.g.
?v tomto sme?ru?
(?inthis regard?)
is an MWE whereas ?o tomto sme?ru?
(?aboutthis direction?)
is not.)
There are also attributes in t-layer thatare?although rarely?important for distinguishing the mean-ing.
(E.g.
words typeset in bold in ?Leonardo dal svy?m go?lemsigna?l.?
(?Leonardo signalled by his goal.?)
compose exactlythe same structure as in ?Leonardo dal go?l.?
(?Leonardo scoreda goal.?).
I.e., the dependency relation is ?dal governs go?l?
inboth cases.
The difference is in the dependency function of go?l:it is either MEANS or DIRECT OBJECT (CPHR).
)We enhance SemLex with a-tree structures as ex-plained in Section 4.4, and then a-layer is processedin the same manner as t-layer: analytical TS is takenfrom the SemLex and the algorithm tries to match itto all a-trees.
Again, if more than one TS is offeredin lexicon, only the most frequent one is used forsearching.MWE identification on the m-layer is based onmatching lemmas (which is the only morphologicalinformation we use).
The process is parametrisedby a width of a window which restricts the maxi-mum distance (in a sentence) of MWE componentsto span (irrespective of their order) measured in thesurface word order.
However, in the setting whichdoes not miss any MWE in a sentence (100% Re-call), this parameter is set to the whole sentence andthe maximum distance is not restricted at all.The algorithm processes each sentence at a time,and tries to find all lemmas the MWE consists of,running in a cycle over all MWEs in SemLex.
Thismethod naturally over-generates ?
it correctly findsall MWEs that have all their words present in the sur-face sentence with correct lemmatisation (high Re-call), but it also marks words as parts of some MWEeven if they appear at the opposite ends of the sen-tence by complete coincidence (false positives, lowPrecision).In other experiments, the window width variesfrom two to ten and MWE is searched for within alimited context.5.3 Automatic Analysis of Data SetsThe three MWE identification methods are appliedon three corpora:?
manually annotated PDT: This is the samedata, from which the lexicon was created.
Resultsevaluated on the same data can be seen only as num-bers representing the maximum that can be obtained.?
automatically annotated PDT: These are thesame texts (PDT), but their analysis (morphological,analytical as well as tectogrammatical) started fromscratch.
Results can be still biased ?
first, there areno new lexemes that did not appear during annota-tion (that is as if we had a complete lexicon); second,it should be evaluated only on eval part of the data ?see discussion in Section 6.1.?
automatically annotated CNC: Automaticanalysis from scratch on different sentences.
The110layer/span PDT/man PDT/auto CNC/autotecto 61.99 / 95.95 / 75.32 63.40 / 86.32 / 73.11 44.44 / 58.00 / 50.33analytical 66.11 / 88.67 / 75.75 66.09 / 81.96 / 73.18 45.22 / 60.00 / 51.58morpho / 2 67.76 / 79.96 / 73.36 67.77 / 79.26 / 73.07 51.85 / 56.00 / 53.853 62.65 / 90.50 / 74.05 62.73 / 89.80 / 73.86 46.99 / 60.00 / 52.704 58.84 / 92.03 / 71.78 58.97 / 91.29 / 71.65 42.83 / 61.33 / 50.485 56.46 / 92.94 / 70.25 56.59 / 92.16 / 70.12 40.09 / 61.33 / 48.496 54.40 / 93.29 / 68.81 54.64 / 92.51 / 68.70 38.27 / 61.33 / 47.137 52.85 / 93.42 / 67.51 53.01 / 92.64 / 67.43 36.99 / 61.33 / 46.158 51.39 / 93.46 / 66.32 51.57 / 92.68 / 66.27 35.59 / 61.33 / 45.049 50.00 / 93.46 / 65.15 50.18 / 92.68 / 65.11 34.67 / 61.33 / 44.3010 48.57 / 93.46 / 63.92 48.71 / 92.68 / 63.86 33.84 / 61.33 / 43.64?
35.12 / 93.51 / 51.06 35.16 / 92.72 / 50.99 22.70 / 62.00 / 33.24P / R / F P / R / F P / R / FTable 2: Evaluation of all our experiments in terms of Precision (P), Recall (R) and F1 score (F) in percent.
Experimentson the m-layer are shown for different widths of window (see Section 5.2).disadvantage here is the absence of gold data.
Man-ual evaluation of results has to be accomplished.For the automatic analysis we use the modularNLP workflow system Treex (Popel and Z?abokrtsky?,2010).
Both datasets were analysed by the standardTreex scenario ?Analysis of Czech?
that includes thefollowing major blocks:1) standard rule-based Treex segmentation and to-kenisation2) morphology (Hajic?, 2004) and Featurama tag-ger (Spousta, 2011) trained on the train part ofthe PDT3) MST Parser with an improved set of features byNova?k and Z?abokrtsky?
(2007)4) and t-trees structure provided by standard rule-based Treex block.6 ResultsEffectiveness of our methods of identification ofMWE occurrences is presented in Table 2.
Numbersare given as percentages of Precision and Recall Thefirst two columns show the results of the evaluationagainst gold data in PDT 2.5, the third column re-flects the manual evaluation on 546 sentences.
Theresults obtained for PDT (the first two columns) arealso visualised in Figure 3.The important issue to be decided when evaluat-ing MWE identification is whether partial match be-tween automatic identification and gold data MWEis to be counted.
Because of cases containing el-lipses (see Section 6.2), it can happen that longerMWE is used for annotation of its subset in text.10We do not want to penalise automatic identification(either performing this behaviour or confronted withit in the gold data), so we treated subset as a match.Another decision is that although the MWEs can-not be nested in gold data, we accept it for automaticidentification.
Since one word can belong to severalMWEs, the Recall rises, while Precision declines.116.1 Discussion of ResultsThe automatically parsed part of the CNC consistsof 546 sentences.
Thus the third column in Table 2represents evaluation on a much smaller data set.During manual annotation of this data carried outby one annotator (different from those who anno-tated PDT data, but using the same methodology anda tool), 163 occurences of MWEs were found.
Out10Let us say, only elliptic term Ministry of Industry is seenin the data (instead of the full name Ministry of Industry andTrade) annotated by the full-term lexicon entry.
Whenever Min-istry of Industry and Trade is spotted in the test data, its firstpart is identified.
Should that be qualified as a mistake whenconfronted with the gold annotation of the whole term?
The as-signed lexicon entry is the same ?
only the extent is different.11For example, annotator had to choose only one MWE to an-notate in vla?dn??
na?vrh za?kona o dani z pr??
?jmu (lit.
: governmentproposal of the Law on Income Tax), while it is allowed to auto-matically identify vla?dn??
na?vrh za?kona, za?kon o dani and dan?
zpr??
?jmu together with the whole phrase.
Recall for this exampleis 1, whereas Precision is 0.25.111Str?nka 178 80 82 84 86 88 90 92 94 96 98303540455055606570m-layer a-layer t-layerRecallPrecisionStr?nka 178 80 82 84 86 88 90 92 94 96 98303540455055606570m-layer a-layer t-layerRecallPrecisionFigure 3: Precision?Recall scores of identification of MWE structures on manually/automatically annotated PDT.of them, 46 MWEs were out-of-vocabulary expres-sions: they could not be found by automatic prece-dure using the original SemLex lexicon.Note that results obtained using automaticallyparsed PDT are very close to those for manual dataon all layers (see Table 2).
The reasons need to beanalysed in more detail.
Our hypotheses are:?
M-layer identification reaches the same resultson both data.
It is caused by the fact that the ac-curacy of morphological tagging is comparable tomanual morphological annotation: 95.68% (Spous-tova?, 2008).?
Both a- and t-parsers have problems mostly incomplex constructions such as coordinations, thatvery rarely appear inside MWEs.There are generally two issues that hurt our accu-racy and that we want to improve to get better re-sults.
First, better data can help.
Second, the methodcan always be improved.
In our case, all data areannotated?we do nothing on plain text?and it canbe expected that with a better parser, but also possi-bly a better manual annotation we can do better, too.The room for improvement is bigger as we go deeperinto the syntax: data are not perfect on the a-layer(both automatically parsed and gold data) and onthe significantly more complex t-layer it gets evenworse.
By contrast, the complexity of methods andtherefore possible improvements go in the oppositedirection.
The complexity of tectogrammatic anno-tation results in a tree with rich, complex attributesof t-nodes, but simple topology and generalised lem-mas.
Since we only use tree topology and lemmas,the t-layer method can be really simple.
It is slightlymore complex on the a-layer (with auxiliary nodes,for example); and finally on the m-layer there is vir-tually unlimited space for experiments and a lot ofliterature on that problem.
As we can see, these twoissues (improving data and improving the method)complement each other with changing ratio on indi-vidual layers.It is not quite clear from Table 2 that MWE iden-tification should be done on the t-layer, because it iscurrently far from our ideal.
It is also not clear that itshould be done on the m-layer, because it seems thatthe syntax is necessary for this task.6.2 Error Analysis and Possible ImprovementsThere are several reasons, why the t-layer results arenot clearly better:1. our representation of tree structures proved abit too simple,2.
there are some deficiencies in the current t-layer parser, and3.
t-layer in PDT has some limitations relative tothe ideal tectogrammatical layer.Ad 1.
We thought the current SemLex implemen-tation of simple tree structures would be sufficientfor our purpose, but it is clear now that it is toosimple and results in ambiguities.
At least auxiliarywords and some further syntactico-semantic infor-mation (such as tectogrammatical functions) shouldbe added to all nodes in these TSs.Ad 2.
Current tectogrammatical parser does notdo several things we would like to use.
E.g.
it cannot112properly generate t-nodes for elided parts of coordi-nated MWEs that we need in order to have the sameTS of all MWE occurrences (see below).Ad 3.
The total of 771 out of 8,816 SemLex en-tries, i.e.
8.75%, have been used with more than onetectogrammatical tree structure in the PDT 2.5.
Thatargues against our hypothesis (stated in Section 5.1)and cause false negatives in the output, since we cur-rently search for only one TS.
In this part we analyzetwo of the most important sources of these inconsis-tent t-trees and possible improvements:?
Gender opposites, diminutives and lemma vari-ations.
These are currently represented by variationsof t-lemma.
We believe that they should rather berepresented by attributes of t-nodes that could beroughly equivalent to some of the lexical functionsin the Meaning-text theory (see Mel?c?uk (1996)).This should be tackled in some future version ofPDT.
Once resolved it would allow us to identifyfollowing (and many similar) cases automatically.?
obchodn??
r?editel vs.
obchodn??
r?editelka(lit.
: managing director-man vs. managingdirector-woman)?
rodinny?
du?m vs. rodinny?
domek(lit.
: family house vs. family little-house; butthe diminutive domek does not indicate that thehouse is small)?
obc?ansky?
za?kon vs. obc?ansky?
za?kon??k(lit.
: citizen law vs. citizen law-codex, meaningthe same thing in modern Czech)These cases were annotated as instances of the sameMWE, with a vision of future t-lemmas disregard-ing this variation.
Until that happens, however, wecannot identify the MWEs with these variations au-tomatically using the most frequent TS only.?
Elided parts of MWEs in coordinations.
Al-though t-layer contains many newly established t-nodes in place of elided words, not all t-nodesneeded for easy MWE annotation were there.
Thisdecision resulted in the situation, when some MWEsin coordinations cannot be correctly annotated, esp.in case of coordination of several multiword lexemeslike inz?eny?rska?, monta?z?n??
a stavebn??
spolec?nost (en-gineering, assembling and building company), thereis only one t-node for company.
Thus the MWEinz?eny?rska?
spolec?nost / engineering company is notin PDT 2.5 data and cannot be found by the t-layeridentification method.
It can, however, be found bythe m-layer surface method, provided the window islarge enough and MWEs can overlap.7 ConclusionsIdentification of occurrences of multiword expres-sions in text has not been extensively studied yetalthough it is very important for a lot of NLP ap-plications.
Our lexicon SemLex is a unique resourcewith almost 9 thousand MWEs, each of them witha tree-structure extracted from data.
We use this re-source to evaluate methods for automatic identifica-tion of MWE occurrences in text based on matchingsyntactic tree structures (tectogrammatical ?
deep-syntactic, and analytical ?
surface-syntactic trees)and sequences of lemmas in the surface sentence.The theoretically ideal approach based on tec-togrammatical layer turned out not to perform bet-ter, mainly due to the imperfectness of the t-layerimplemented in PDT and also due to the low ac-curacy of automatic tectogrammatical parser.
It stillshows very high Recall, as expected ?
due to sim-ple topology of the trees ?
however Precision is notideal.
Morphology-based MWE identification guar-antees high Recall (especially when no limits are puton the MWE component distance) but Precision ofthis approach is rather low.
On the other hand, if themaximum distance is set to 4?5 words we get a veryinteresting trade-off between Precision and Recall.Using analytical layer (and thus introducing surfacesyntax to the solution) might be a good approach formany applications, too.
It provides high Precision aswell as reasonable Recall.AcknowledgementsThis research was supported by the Czech Sci-ence Foundation (grant n. P103/12/G084 andP406/2010/0875).
This work has been using lan-guage resources developed and/or stored and/or dis-tributed by the LINDAT-Clarin project of the Min-istry of Education of the Czech Republic (projectLM2010013).
We want to thank to our colleaguesMichal Nova?k, Martin Popel and Ondr?ej Dus?ek forproviding the automatic annotation of the PDT andCNC data.113ReferencesAbhishek Arun and Frank Keller.
2005.
Lexicaliza-tion in crosslinguistic probabilistic parsing: The caseof French.
In Proceedings of the 43rd Annual Meet-ing of the Association for Computational Linguistics(ACL?05), pages 306?313, Ann Arbor, Michigan.Laurie Bauer.
1983.
English Word-formation.
Cam-bridge Textbooks in Linguistics.
Cambridge Univer-sity Press.Eduard Bejc?ek and Pavel Stran?a?k.
2010.
Annotation ofmultiword expressions in the Prague dependency tree-bank.
Language Resources and Evaluation, (44):7?21.Eduard Bejc?ek, Jarmila Panevova?, Jan Popelka, LenkaSmejkalova?, Pavel Stran?a?k, Magda S?evc??
?kova?, JanS?te?pa?nek, Josef Toman, Zdene?k Z?abokrtsky?, andJan Hajic?.
2011.
Prague dependency tree-bank 2.5. http://hdl.handle.net/11858/00-097C-0000-0006-DB11-8.
Data.Marine Carpuat and Mona Diab.
2010.
Task-based eval-uation of multiword expressions: a pilot study in statis-tical machine translation.
In Human Language Tech-nologies: The 2010 Annual Conference of the NorthAmerican Chapter of the Association for Computa-tional Linguistics, HLT ?10, pages 242?245, Strouds-burg, PA, USA.Paul Cook, Afsaneh Fazly, and Suzanne Stevenson.2007.
Pulling their weight: exploiting syntactic formsfor the automatic identification of idiomatic expres-sions in context.
In Proceedings of the Workshop on aBroader Perspective on Multiword Expressions, MWE?07, pages 41?48.Gu?ls?en Eryig?it, Tugay I?lbay, and Ozan Arkan Can.
2011.Multiword expressions in statistical dependency pars-ing.
In Proceedings of the Second Workshop on Sta-tistical Parsing of Morphologically Rich Languages,SPMRL ?11, pages 45?55, Stroudsburg, PA, USA.
As-sociation for Computational Linguistics.Richard Fothergill and Timothy Baldwin.
2011.
Flesh-ing it out: A supervised approach to MWE-token andMWE-type classification.
In Proceedings of 5th Inter-national Joint Conference on Natural Language Pro-cessing, pages 911?919, Chiang Mai, Thailand.Spence Green, Marie-Catherine de Marneffe, andChristopher D. Manning.
2013.
Parsing models foridentifying multiword expressions.
ComputationalLinguistics, 39(1):195?227.Jan Hajic?.
2004.
Disambiguation of Rich Inflection(Computational Morphology of Czech).
Nakladatel-stv??
Karolinum.Chikara Hashimoto and Daisuke Kawahara.
2008.
Con-struction of an idiom corpus and its application to id-iom identification based on WSD incorporating idiom-specific features.
In Proceedings of the Conference onEmpirical Methods in Natural Language Processing,EMNLP ?08, pages 992?1001.Deirdre Hogan, Conor Cafferkey, Aoife Cahill, and Josefvan Genabith.
2007.
Exploiting multi-word units inhistory-based probabilistic generation.
In EMNLP-CoNLL, pages 267?276.
ACL.Graham Katz and Eugenie Giesbrecht.
2006.
Automaticidentification of non-compositional multi-word ex-pressions using latent semantic analysis.
In Proceed-ings of the Workshop on Multiword Expressions: Iden-tifying and Exploiting Underlying Properties, MWE?06, pages 12?19.Linlin Li and Caroline Sporleder.
2009.
Classifier com-bination for contextual idiom detection without la-belled data.
In Proceedings of the 2009 Conference onEmpirical Methods in Natural Language Processing:Volume 1 - Volume 1, EMNLP ?09, pages 315?323.Christopher D. Manning, 2003.
Probabilistic Linguistics,chapter Probabilistic Syntax, pages 289?341.
MITPress, Cambridge, MA.Igor Mel?c?uk.
1996.
Lexical functions: A tool for thedescription of lexical relations in a lexicon.
In LeoWanner, editor, Lexical Functions in Lexicography andNatural Language Processing, volume 31 of Studiesin Language Companion Series, pages 37?102.
JohnBenjamins.Joachim Nivre and Jens Nilsson.
2004.
Multiword unitsin syntactic parsing.
In Dias, G., Lopes, J. G. P. andVintar, S.
(eds.)
MEMURA 2004 - Methodologies andEvaluation of Multiword Units in Real-World Applica-tions, Workshop at LREC 2004, pages 39?46, Lisbon,Portugal.Va?clav Nova?k and Zdene?k Z?abokrtsky?.
2007.
Fea-ture engineering in maximum spanning tree depen-dency parser.
In Va?clav Matous?ek and Pavel Mautner,editors, Lecture Notes in Artificial Intelligence, Pro-ceedings of the 10th International Conference on Text,Speech and Dialogue, volume 4629 of Lecture Notesin Computer Science, pages 92?98, Berlin / Heidel-berg.
Springer.Pavel Pecina.
2005.
An extensive empirical study ofcollocation extraction methods.
In Proceedings of theACL Student Research Workshop, pages 13?18, AnnArbor, Michigan.Martin Popel and Zdene?k Z?abokrtsky?.
2010.
TectoMT:Modular NLP framework.
In Hrafn Loftsson, EirikurRo?gnvaldsson, and Sigrun Helgadottir, editors, Lec-ture Notes in Artificial Intelligence, Proceedings of the7th International Conference on Advances in NaturalLanguage Processing (IceTAL 2010), volume 6233 ofLNCS, pages 293?304, Berlin / Heidelberg.
IcelandCentre for Language Technology (ICLT), Springer.Ivan A.
Sag, Timothy Baldwin, Francis Bond, AnnCopestake, and Dan Flickinger.
2002.
Multiword114expressions: A pain in the neck for NLP.
In Com-putational Linguistics and Intelligent Text Process-ing: Third International Conference, CICLing, vol-ume 2276/2002 of Lecture Notes in Computer Science.Springer Berlin / Heidelberg.Violeta Seretan.
2010.
Syntax-Based Collocation Ex-traction, volume 44 of Text, Speech and LanguageTechnology.
Springer.Petr Sgall, Eva Hajic?ova?, and Jarmila Panevova?.
1986.The Meaning of the Sentence in Its Semantic andPragmatic Aspects.
Academia/Reidel Publ.
Comp.,Praha/Dordrecht.Miroslav Spousta.
2011.
Featurama.
http://sourceforge.net/projects/featurama/.Software.Drahom?
?ra ?johanka?
Spoustova?.
2008.
Combining sta-tistical and rule-based approaches to morphologicaltagging of Czech texts.
The Prague Bulletin of Math-ematical Linguistics, 89:23?40.Pavel Stran?a?k.
2010.
Annotation of Multiword Expres-sions in The Prague Dependency Treebank.
Ph.D. the-sis, Charles University in Prague.115
