Logical Structure andL iv ia  Po lany iFX Palo Alto Laboratory3400 Hillview Ave Bldg 4Palo Alto CA 94304po lany i@pal ,  xerox ,  comDiscourse Anaphora  Resolution*Martin van den BergFX Palo Alto Laboratory3400 Hillview Ave Bldg 4Palo Alto CA 94304vdberg@pal, xerox, comAbstractWorking within the Dynamic "Quantifier Logic(DQL) framework (van den Berg 1992, 1996a,b), weclaim in this paper that in every language the trans-lation into a logical language will be such that thepreference ordering of possible discourse r ferents foran anaphor in a sentence can be explained interms ofthe scopal order of the exp _re~Lslons in the antecedentthat introduce the discourse referents.
Since thescope of terms is derived from arguments indepen-dent of any discourse theory, our account explal~discour~ anaphora resolution in terms of generalprinciples of utterance semantics, from whichthepredictions of centering theory follow.
When com-b'med with the powerful discourse structural frame-work of the Linguistic Discourse Model (Polanyi(1985, 1986, 1988, 1996) Potanyi and Scha (1984),Scha and Polanyi (1988), Prfist, H., tL Scha andM.
tLvan den Berg, 1994; Po~u~, L. and M. H.van den Berg 1996; van den Berg, M. H. 1996b),we provide a uni6ed account of di~ourse anaphoraresolution.1 In t roduct ionIn thl.
paper, we use a semantic theory based on Dy-namic Quantifier Logic (van den Berg 1992,1998a,b)to present an approach to discom~ anaphora resolu-tion under the Linguistic DL~ourse Model (Polanyi(1985, 1986, 1988, 1996) Pohmyi and Scha (1984),Scha and Pclawfi (1988), Prfmt, H., I t  Scha andM.
H. van den Berg, 1994; Po~q~ L. and M. ILvan den Berg 1996; van den Berg, M. H. 1996b).Our treatment integrates the imights of the Center-~g framework (Jmbi audK,,h- 1979, 1981; Groszet~l.
1983, 1986, 1995; Gundel 1998; Walker et.al.1998b) into a -n~Sed theory of discourse l vel struc-tufa/and semantic relations.
In our account, dis-course level aaaphora resolution effects fall out ofa general theory of discourse quantification.
Scopeorderinge in the logical representation f  theantecedent utterance result in d|fferences in" The authors dedkate this paper to the memory of MegumiKameyama (1953-1999), a dedicated researcher and a verydear friend.accessibility for potential referents in a targetutterance.
No additional c~ntering mechanisms arerequired, the centering predictions follow from thistheory.Our treatment is universal: explanations of rela-tive coherence do not depend on conventions thatmight differ in different languages.
Furthermore,we provide a treatment for the resolution of mul-tiple anaphors, resulting from a range of possi-ble antecedents including plurals and multiple an-tecedents.The approach to discourse anaph?ra resolution wetake in this paper integrates a rigorous formal se-mantic machinery within a theory Of discourse strtlc-ture.
Before giving a detailed account of our treat-meat of di~murse r ference r solution, we would llketo address explicitly some of the positions towardsrdereace resolution and discour~ ~mcture whichinform our work.1.1 Theoretical and MethodologicalConsiderationsTo begin with, we should state explicitly that our en-terprise is a semantic one~ we are interested indevet-oping and implemen "ring a formalization capable of._,~'amln~ a con-ect interpretation to each utterancein a discourse.
In this, we are fully committed to theDynamic Semantics enterprise (Kamp 1981, H~m1982, Groenendijk and Stokhof, 1990, 1991, Cider-~i .
1992, van den Berg 1991, Kamp and Reyle 1993,Asher 1993, van den Berg 1998).
Except in so far asit is provably necessary, we are not concerned withpsychological L~sues of how human language userspro~ discourse nor with what human beings in-tend when they use language to commuIlicate withone another.Our aim is to build machinery applicable to allgenres and all modes of comm~nLication.
Thus wecan not assume that a discourse is n ec~x l ly  uco.hereat" and that our goal is to provide an accountof why that is so, nor can we assume that all dis-course iswritten or spoken or.occurs in a task con-text where the demands or reasonable expectationsof a~ external activity are available to guide parsingand interpretation.11000O0@0@00000@000@@O0O0000000OO0OOOOOOOOOOOOOO@OO?OOOOOOOOO@OOOOOOOOOur theory is a formal one, therefore we can relyon well-known, rule-driven, parsing methods devel-oped for sentences which allows us ~parse discourseincrementally as it unfolds.
In order to do so, ourframework formalizes the relationship among con-stituent units in the discourse by specifying how anttecedent units provide context for the interpretationof later units.
In all cases, our method involvescomputing the resulting meaning of the combina-tion of the meanings of the combined units, ratherthan identifying appropriate labels under which tocharacterize the relationship obtaining between theunits.
Our units of analysis are welldefined seman-tic units.
These units are usually encoded as singlesimple sentences or clauses but may also be realizedby words, phrases or gestures which communicateexactly one elementary predication.In our view, a formal theory of discourse structureshould give well defined structures on which infer-encing operates and on which world know, ledge ap-plies.
We strive to limit the role of world knowledgein so far as possible to a specific moment in d~;ourseprocessing--namely at the precise moment when achoice must be made about how a newly incomingunit must be integrated into the unfolding discourse.Just as in sentence grammar where world knowledgeis used to decide between syntacticaUy equivalent al-ternatives in the case of pp attachment, for example,in discourse grammar the relationshilm between ele-ments are purely grammatical, and world knowledgeis only used to decide between syntactically equallyreasonable alternatives.Similarly, in calculating the structure of discourse,we do not rely on the use of cue words suchas so,angtway or thcfefor~ because these terms are neverobligatory.
The relationsl~p of one unit to anotheris always calculated on the relationshlp between themeanings of the constituent utterances which maythen be ~in?orced by the presence of terms whichspecify the nature of the intended relationship.In the framework developed below, thea-e isa dose relationship I~en discourse rderentsand discourse structure.
We deal both withhow anaphors are resolved to partienb, r an-tecedents using the structure of  the discourse,and how an  antecedent gives me,,nlng toan anaphor.
The problem of identifying the an-tecedent to which an anaphor efe~ is dealt within Centering Theory, discussed in Section 2 below.After reviewing Centering, we will discuss DynamicQuantifier Logic (Section 3) and then show how theinsights of Centering can be integrated into a ben-era\] theory of discourse syntactic and semantic struc-ture (Section 5.1), We shall point out how our ap-proach accounts for multiple anaphors to differentantecedents a well as ac~tmting for anaphoric ref-erence to multiple antecedents, a problem which re-main unsolved within that framework (5.2).2 Center ing  TheoryCenteringTheory first described in detail in Gro~z,Joshi and Weinstein (1983, 1986 \[1995\]) is designedto provide an assignment of a preference orderamong discourse ntities in a sentence for the pur-pose of anaphora resolution.
Centering Theory,which built upon earlier work by Joshi and Kuhn(1979) and Joshi and Weinstein (1981, 1998), pro-posed that (1) is perceived to be more coherent than(2) because in (1)(I) (a) JeH helped Dick wash the mr. (b) He.washed the windows as Dick washed the car(c) Heb soaped a pane..He~ and h~ are both co-referential with .leO', whilein .(2).
(2) (a) Je~ ha~ed Dick wasA the car.
(b) //e.washed the windows as Dick wazed the car(c) Heb b..~ed the hood.
=.the referent fo r / /~ in  (c) is D/ck while he, in (b)refers to Je~.We quote here from the concise description of Cen-tering given in (Walker et.al., 1998b):The centering model is very simple.
Dis-courses consist of constituent segments andeach segment is represented as part of a dis-course model.
Centers are semantic entiUes ?that ~re part of the discourse model for eachutterance in a discourse segment.
The set ofvO~wxao-LOOKma ?~r~,  Cj(vi~v) repre-seats discourse ntities evoked by an utter-ance Ui in a discourse segment D (Webber1978; Prince 1981).
The \[unique\] BACKWARD-WOKmO c~-rza, C,(Ui.D) is a sp~l  mem-ber of the C:, which represents the discourseentity that the utt~ance U most omtrallyconcermL ...
The Ct entity links the currentutterance to the previous discour~ ...(ornot more thaa one) ...
The set of I~01~WARD-woxmo cm~m~.s, C:, is ranked according todiscom~ s~enm.
This ranki~ is a part~order.
The hi~es~ ranking member of the setof forward-looking centers.., represents a pre-diction about he CGd the following utlterance.W~ker, Joshi, Prince (1998b) in Walker, Jochi," Prince 1998a henceforth WJP) p. 3.From a linguistic perspective (cL papers and ref-erences in Walker, Joshi and Prince 1998; Strube1998), Centering theor/sts have explained the choiceof C6 in a sentence in terms of a'large .number ofpotential factors.
In particular: the grammatical hi-erarchy with subjects ranking higher than objects(Grosz, Joshi, Weinstein 1983), topic or empathymarking (Kameyama 198,5), surface order position111(Rainbow, 1993) or grammatical function (Brennan,Friedman and Pollard 1987) of the encoding of dis-course entities in the immediately preceding seg-ment.Roberts (1998) argues that C0 is an unordered set-of backward-looking centers in terms of classical Dis-course Representation Theory notions of familiarity,compatibility and logical accessibility (Kamp 1981,Helm 1982, Kamp and Reyle 1993, Asher 1993),with an additional constraint that the set of dis-course referents are attentionally accessible, a notiontaken from Grosz and Sidner (1986).
Under Roberts'treatment, he set of preferred centers, takes theplace of the original C6.
Walker (1998) also replacesa unique Ct with a set of possible backward look-ing centers computed from a set of possible forwardlooking centers using agreement features, selectionconstraints of the verb and contra-indexing condi-tions.The choice of segment also remains contestedground in Centering, with mint linguists choosingfor the sentence or clause while Walker (1998), ar-gues for integrating Centering with a more globalmodel of discourse focus.
Within computationallinguistics, several Centering Algorithms have beenproposed, most notably by Brennan, S, M. ~ied-man and C. Pollard (1987), Walker, Iida and Cote(1990, 1994) and, more recently, by Strube and Hahn(1996), Strube (1998), and Walker (1998) which re-flect these various perspectives.Although the several variants of Centering can beargued to be better suited to one or another taskor to account for phenomena in one or another lan-guage, they all fail to account for the interpretationof common examples SUch as (3) s.(3) (a) Joan s went to ~ork at e~hZ.
(b) B//g ar-t/veal at n/he.
(c) Th~+a met in the ?on/erencerOOl~In (3), no entity in a single target clause or sentenceresolves the plural pronoun in (3c).
Thqa+a refersto a complex semantic entity created by combiningentities in (3a) and (3b).In the reformulation f Centering in terms of Dy-namic Quantifier Logic presented in Section 3, be-low, we show how multiple anaphoric elements canbe handled and each assigned its preferred resolu-.tion.
DQL allows us to calculate a preference order-ing on the discourse referents that can be  used toaccount for multiple anaphors refering to differentantecedents.
When paired withthe LDM, we alsoprovide a means for one anaphor to refer back tomultiple antecedents.s Notational Convention: Introduced Indices are written assupe~pts; indices that are old (refer back) amwritten assubscript&?
3 - Dynamic  Quant i f ie r  Logic.DQL combines Generalized ~uantifier Theory(GQT) (Barwise and Cooper 1991) and PluralQuantifier Logic (Scha 1981; van der Does 1992)with Dynamic Semantics.
DQL was designed to han-dle phenomena such as plurals and complex relationsbetween discourse r ferents often left unaddressed byother formal semantic frameworks ( ee van de Berg1992,1996a,b).Dynamic Quantifier Logic is based on the observa-tion that NPs are generally anaphoric, quantif l -cationa\] and can be the antecedent of furtheranaphora, as illustrated by (4):(4) (a) The children I arrived at the natural historymuseum early in the morning.
(b) Threes boys 2disappeared in the girl shop.
(c) The~ had agreat time touching almost evert~ing.In (4b), thr~ boys is anaphoric: its domain ofquantification is given by The chi/dre~ ,Within thisdomain, it is quantificatiunal:, there are exactly threeboys that disappeared in the gi~ shop.
Finally, it isan antecedent: i  introduces a referent picked up byTheyl in (4c) to refer back to the three/w~.DQL, designed to explaia examples like (4), wasd~ned to preserve as far as possible the prediction ofits precursors while inheriting most of the/r results.Under DQL well known, solid results and establishedprocedures remain tmehanL, ed.
As.
an illustration ofa DQL representation of a sentence, take the simpli-fied representation f (5b) below(5) (a) Some childrerf were playing in the back-yar~ (b) Every= g/rP ~ wear/ng a hat,.
(c) ~ had put ~ on belore ~ le# thehouse..(5'b) Vg C z (girl(y), ~ C_ ?
(hat(z), wear(y, z)))Formula (50o) states that/or ever g eat/ry that is ag/d, taken from the doma/n Siren by the d/scoursengereat z', it is the case that there is a hat suchtha~ she wmws iL This expremion is vew similar toclamcal umslatious into logic of Co).
The only dif-fe~mco in the form of the expression is the explicitmention d the context set that sets the domain of.
qumstiflcation.
These context sets are given by dis-Course referents.
The universal quantification Eve~girl takes its range from the discourse referent =, andintroduces a subset y, the indefinite a ha?
takes itsdomain from an as yet unspecified domain (-).3.1 Quantification and ReferenceResolutionIn DQL, all d i~ourse anaphoric effects takeplace through discourse referents functioningas context sets to quantifiers.
Variables that112OO0000O0@0O000@00@@@00@@O0O0O@@000000@00OOOOOOOOOOO@OOOOOOOO0@OOOO@are quantified over 2 are introduced as dis-course referents to function as :context setsin subsequent sentences.Although (Sb) introduces both referents y for thegirls and z for the hats, the referents do not haveequivalent status.
This is caused by the quantifica-tionaI structure.
The set of girls is given as a simplesubset of the set of children, and as such is readilyavailable.
The set of hats, on the other hand, is onlyintroduced relative to the set of girls.
The hats a renot introduced independently, but rather are intro-duced indirectly as belonging to the girls.
Referringback to the set of hats is much more computation-ally expensive than referring back to the set of girls;to refer to the hats we must implicitly refer to thegirls relative to which the set of hats is defined.A consequence of the fact that the hats are intro-duced relative to the g/r/s, is that there is an impliedordering of the discourse referents that we use in re-letting back to these sets.
The discourse referentcorresponding to the ~ is much easier to pick upfrom the conti~ than the discourse referent refer-ring back to the hats .
Everything else being equal,the discourse referent referring to 'the g/r/a will bepreferred over the discourse referent referring to thehats because accessing it requires less computation.?
This preference order corresponds closely to theforward-lcoking centers C1.
However, there is noth-ing in the construction of the preference orderingbased on complexity of retrieval sketched above thatwould lead us to believe that there is at most onebackward-looking center.
In fact, our treatmentgives the same predictions as Centering for the firstpronoun resolved, but results in different predictionsfor embedded auaphors.
The foliowing diagram rep-resenting the scopes of (b) and (c) illustrates th!~:==~vts/mts ol y \[ (6) ~ .
~, = y ("t,'~") \]I I w II3.2 Anaphera Resolution Preference OrderIt follows from the argument we have laid out above,?
that the referent I/in (e), is preferred for anapherieHowever, once the girk are available as a set:in(c) via u, the hats are ako available, via discoursereferent z, to ser~ as an antecedent.
The set ofgirls, being already available no longer adds to thecomputational burden of calculating the set of hats.Within the scope of they, the referent z is much moreaccessible than outside that scope.We can push this line of reasoning further.
Con-sider example (Ta).
In this example, the subject,2Like y and z in (5'b).SThk is related to the discussion in Jmhi and Weinstein1998, whi?.h motivates Centering from the perspective ofcom-plexity of inference in discourse.Every amman, has scope over the object, a car.
As(7-8) shows, the preferred center of the C!
corre-sponding to this is the set of women because thecars are introduced as a function of the women.
Torefer correctly to the set of cars, we must also referindirectly to the set of women since we are interestedin retrieving only the cars owned by the women, notcars owned by men.
On the other hand, to refer tothe women, we need no information about heir cars.This does not mean that we cannot refer to the carain a subsequent sentence, as (gb) shows .
.
.
(7) (a) Every waman in this town has a car.
(b) They park them in their garages.Where the set of women is referred to with Theg,the cars can be.referred to directly.
There is then nolonger a hidden cost of retrieving the set of womenin addition to the cars, since cars are already givenin the sentence.But now consider (8) and (9):(8) (a) Every  woman in this town has a car..(b) They use it to drive to work.
(9) (a) Every t~oman in this town has a car.~o) They are l~u'ked in their garages.Note that (7-9) are decreasin" g in acceptability.
(8) is more problematic than (7), because in (7) onlythe set of cars need be retaieved, while in (8) also theactual dependence of the carsonthe women that ownthem is invoked by the use of the singular ~.
(9) ismuch less acceptable than either (7) or (8), becausein (9) They refers to the cars without he help of anexplicitly given set of women.The fact that once we have used a discourse ref-erent, we can use other discourse referents that de-pend on it has important consequences a soon aswe consider anaphora more complex than pronouns.Consider exmnple (I0)..(10) (a) Seventeen people 1 in our lab have their owncmnputer~.
(b) Three o~f themt are silly andthem~ oD ~ n~Lh (10a), a discourse referent d~ to aset of seven-teen people is introduced, and as well as a discoursereferent d~ to a the set of computers they own, whichdepends on ds.
In (10b), Three o!
them quantifiesover the domain given by all, and states that withindh there are exactly three people who switch their4For some people (8) is totally impmsible, becamm theydemand a plural here as in (7), seemingly preferring semanticnumber agreement over syntactic number agreement.
How-ever, syntactic agreement does occur, as the following exampleillustrates:~ sotd/er/, neqmu/bte lot ~ own gun.
He haJ to deanit and will be reln' imandd i\] anll dirt is found on it.113:!?
"own computers off every night.
If the discourse refer-ent introduced by their own computers would sim-ply refer to the set of computers owned by peoplein the company, and not be dependent on the peo-ple, them2 would refer to this set, rather than onlyto the set of computers owned by the three people.The meaning of (10b) would then be that these threepeople switch off all computers in the company, notjust their own.
This, of course, in not the correctreading.4 Quant i f ie r  Scope  and  AnaphoraR~-so lut ionUnder our analysis, the preferred antecedent for apronoun is based on computational complexity aris-ing from universal facts of scope ordering in the log-ical representation f the antecedent u terance.
Dif-ferent approaches tocentering will be better or worseat predicting ordering relations depending on thematch between the ordering scheme decided uponand the underlying scopal ordering.We argue as follows.If the discourse referent A is introduced by a termthat has scope over a term introducing discourserefe~.nt B, and discourse zefe~ent B is introducedby a term that has scope over discourse referent C,A will be preferred over B and B will be preferred.over C. Since this explanation is not dependent onconventions that might be different in different lan-guages our treatment is universal.
This is not thecase for explanations based on linear ordexing of syn-tactic onstituents orarguments based on gemnmat-ical function, for example.
Because in .Engli~ thesubject has scope over the objects, and the objectshave scope over more deeply embedded terms, theordering of discourse rderents familiar to us fromthe literature will result in the well known C!
pre-dictions.Rejecting a preferred ordering for a less preferredordering is a computationally complex operation.First the preferred order is computed, then this anal-is rejected ---perha~ on pragmatic grounds.The calculations must then be re-done and the re-sulting less preferred ordering checked to see if it fits?
the pragmatic facts of the situation described in thetarget utterance.
Differences ha computational com-plexity arising from rejecting more prderred inter-pretations for less preferred thus result in the judg-ments of relative coherence which have been notedin the literature.
Our account hns explains howCentering effects originate and why some anaphoricchoices may involve more attention to the referentretrieval process than others s.SThe DQL formalism has been explicitly designed to lookas similar as peasible to weIl-lmown, standard logiel.
"1"o argueabout issum of acceesibility ofthe referents, a logical systemthat is le88 natural, but externalizes the dependencies between4.1 Acceptabil ity PredictionsTo return then to examples (1) and (2), reproducedhere as (11) and (12)(11) (a) Jeff helped Dick wash the car.
(b) Heawashed the windows as Dick washed the car(c) He6 soaped a pane.
(12) (a) 3e~ helped Dick wash the car.
(b) Heewashed the windows as Dick waxed the car(c) Heb bused the hoodSince the d iscom-se referent Jell is introduced bY aterm that has scope over a term introducing dis-course referent D/ck, Je~ will be preferred overD/ok The difference inperceived coherence between(1/11) and (2/12) falls out of the more general factthat wide scope quantifiers are preferred over narrowscope quaatifiers.We will now turn to discussing how discoursestructure and Anaphora Resolution interact o pro-duce different acceptability predictions for differentstructures of discourse.5 D iscourse  S t ructure  and  AnaphoraReso lu t ionAlthough Centering Theory is associated with theDiscourse Structurm Theory of Gr~z and Sidner(1986) which considers speaker intention and hearerattention as the critical dimensions to be modeled indiscourse understanding, there are alternative mod-els for understanding the relations among utterancesin a discourse which are based on other principles.
Inparticular, Dynamic Quantifier Logic, the anaphoraresolution mechanism based on quantifier scope weare working with here, has been designed to providethe semantic machinery for the Linguistic DiscourseModel (LDM).
The LDM provides an account fordiscourse interpretation i  terms of structural andsemantic relations among the linguistic onstituentsmaking up a discourse e.5.1 The Linguistic Discourse ModelThe LDM is designed as a discourse ~ designedto construct a meaning representation f the in-put discourse icrementally.
The LDM treats a dis-course as a sequence of basic discourse units (evue)ranges of values for ~ might be more suitable, such asliar to DO~ we thank eae mmaymous revumer mr pomungout the work of Ranta (1991), who's use of Marthz-16Ps typetheory, m~ atso be suttsble ts a~ anal3~t8 toolela Prfmt, Scha and van den Berg 1991, ?
resolution mech-anJmn for unification based iscourse grammar for verb phraseanaphom is defined, in terms of the Linguistic DiscourseModel (LDM; PolanyJ and Scha 1984;.
Polanyi 1987, i988.1996), which takes semantic representations as input.
Thistreatment was later extended to a unification based iscoursegrammar actinf~ on dynamic quantifier logic in Polanyi 1996,van den Berg and Polanyl 1996.
The current paper extendsthat work.,qp114000000$000000000000000000000000000OOOOOOOOOOOOOOOOO@OO@OOOOOO@OOOOOOOOOOOeach of which encodes formal semantic, syntacticand phonological properties of either an elementarypredication or a discourse function.
Using rules ofdiscourse wellformedness whiCh specify how to com-pute the relationship between a BDO and the pre-vious discourse, the LDM constructs a parse treeby successively attaching the SVUs to a node at thefight of edge of the emerging tree.
The nodes of thetree are called Discourse Constituent Umts (VCUS) 7.DCUs encode formal semantic, syntactic and phono-logical properties that are calculated by followingconstruction rules corresponding to the relationshipcomputed as a result of the attachment process.The discourse parse tree represents he structuralrelations obtaining ~Lmong the DCUs.
There are threebasic types of relations among DCUs: Coordination,Subordination and Binary Re!A_tion.
Correspondingto these relations, a DCU can be attached at a nodeon the right edge of a tree in one of three waysS:1.
The input DCU will be Coordinated with a nodepresent on the fight-edge of the tree if it contin-?
ues a discourse activity (such as topic Chainingor narrating) underway at that node.2.
The input DCU win be Subordl,a~ted to a nodeon the right-edge of the tree if it elaborates onmaterial expressed at that node or if it inter-rupts the flow of the discourse completely.3.
The input DCU will be Binary-attached to anode if it is related to that node in a logical,rhetorical or interactional pattern specified ex-plicitly by the grammar.The LDM is a compesitional framework.
Simnltane-oas with the incremental construction of the strucotural representation fthe discourse by attaching in-coming DCUS, a semantic representation f the mean-ink of the discourse is constructed by incorporatingthe interpretation fan incomi-~ ~ in the ~man-tie representation the discourse.The LDM a~m~ts for both structural and se-mantic aspects of discounse parsing using logical andstructural notions analogous to units and p ~constituting lower levels of the linguistic hierarchy.It is an ideal framework for tmdenmmding the re-latioas between sentential syntax and semantics, onthe one hand, and on the other hand, the texts and~teractious that are constructed using sentential lin-guistic structures.
?BDU8 once attached to the tree are DCU8.-8Baside8 these three basic composition relations betweenncus, a complex ncu can also he constructed by an operatorhaving a ncu as an argdment and within mmtences, a ncu canoccur embedded in another DcU.
These two cases wiU not bed~umed here.5.2 Reference Resolution in the LinguisticDiscourse ModelLet us now look at several short example of the inter-action of anaphora resolution with discourse struc-ture using the Dynamic Quantifier Logic frameworkabove.
(13) (a) Susan came home late yesterday.
(b) Dorishod held her up at work.
(c) She needed helpwith the copier.In (13) the relationship between vco (13a) andDco (13b) is a Subordination relation because (13b)supplies more detailed information about why Susancame home late.
As is shown in (13a), the S node in-herits all information about he dominating VCO.
Inthis case (a).
A representation f Susan is thereforeavailable at this constructed node.
(13e) gives moreexplanation about what went on when Doris heldSusan up at work and is therefore Subordinated to(b).
Susan and Doris available for reference at thatnode.
In (14) the situation is different.
(14) (a) Susan came home late yesterda3l.
(b) Dorishad held her up at worl~ (e) She didn't ~oenhave time \]or dinner.
(13') ~-~ (14')~.~.,Although the relationship between DCU (14a) andDCU (14b) is a Subordination relation, as shown in(14a), as the di~ourse continues with (14c), thestate of the discourse POPS from the embedded ex-planation to continue describing the state of affairsof Sasan's evening.
(14c) is therefor~ in a Coordi-nation relation with (14a) as shown.
Only Susan isnow available as a potential referent in the currentcontext.In fact, the antecedent of an anaphora need notbe one specific earlier utterance, but may be a con-structed higher node in the parse tree as in (15):(15) (a) J~m went to um'k at dght  (b) ,8///art/reda?
n/,w~ (e) They met in the ~/e,m~eroom.Qt+I(ARRIVE(AT-TIME)) and Theys+=(meet-in-C)Qs+=(ARRIVE(AT-~~~heyx  (meet-in-CiJoanX(got-to-w~rk(at eight)) Bmt  (arr ive(at  eight))In this case, the antecedent of (15c) is not (15a)or (15b), but the discourse node that constitutes115the list (15a+b).
In this higher node, there is aconstructed schematicrepresentation of what (lSa)and (15b) share, and They is resolved to this.
Veryschematically, it amounts to resolving the anaphorX to the outer quantifier of its antecedent, Ql+2.6 Conc lus ions?
Within our unified framework we are able to providea detailed account of how anaphora resolution worksacross tretches of discourse, Because the LDM re-quires specific calculation of the information avail-able at intermediary nodes.
Computationally, dur-ing parsing, a rich data structure is created rep-resenting the meaning of the discourse.
This, wewould argue, is a distinct advantage of DynamicSemantic approaches such as the LDM/DQL sys-tem over current computational lternatives suchas Discourse Structures Theory (Gro.~ and Sidner1989) and Rhetorical Structure Theory (Mann andThompson 1987) which rely upon inferring the at-- tentional and intentional states of language users,in one case, and on labe!ing the coherence r lationsamong clauses, in the other.
Looking towards formaldiscourse syst~m-__q, we believe that while it would bepossible to integrate the insights of DQL into a DRTapproach such as that t~ by Asher (1993), the ap-p r .~  taken here is computationally more tractablethan more standard implementation of DRT for dis-course parsing.
The increased tractability resultsfrom the separation ofdiscourse syntax and seman-tics which our approach imposes, taken togetherwith the restriction of appeals to inference and worldknowledge to specific moments in interpretation.
Ithe case of the LDM, appeals to external knowledgeare made only at the moment of DCU attachment.to the parse.tree.?
Re ferencesNicholas Asher.
1993.
Refe~eace to Abstract Ob-jects in Discourse.
Dordrecht, Kluwer.John Barwise, and P~ Cooper.
1981.
GeneralizedQuantifiers and Natural Language Linguisticsand PhiloaophTI 4:159-219.Susan E. Brennan, Madlyn E. F1iedman sad Carl J.Pollard.
1987.
A Centering Approach to Pro-nouns.
In: ~ s  o~f the 25st Annual Meetingo!
the Auoda~ /or Oomm,t~io,~ l in~is~,Stanford CA 155-62.Gennar0 C\]fierrh~.
1992.
Anaphora nd DynamicBincHng.
Ling~dstics and Philosophy 15:111-183.Jeroen Groenendijk, Theo M. V. Januen and Mar-tin Stokhof (ed)1981.
Formal Methods in theStudy of Language_ Amsterdam, MathematicalCentrum.Barbara Grosz, Aravind Joshi and Scott Weinstein.1983.
Providing a Unified Account of DefiniteNoun Phrases in Discourse.
Proceedings of the21st Annual Meeting of the Association for Com-putational Linguistics, Cambridge, MA 44-50.Barbara Grosz, Aravind Joshi and Scott Weinstein.1995.
Towards a Computational Theory of Dis-course Interpretation.
Computational Linguistics,21/2:203-25.Barbara Grosz and Candace Sidner.
1986.
Atten-tion, intention, and the Structure of Discourse.Computational Linguistics, 12/3:175-204.Jeanette K. Gundel.
1998.
Centering Theory andthe Giverness Hierarchy.
In (Walker et.aL, 1998a)183-198.
"Irene He|re.
1982~ The Semantics of Definite andIndefinite Noun Phrases.
Ph.d. Thesis.
Universityof Massachusetts at Amherst.Aravind Joshi and Steve Kuhn.
1979.
CenteredLogic: The Role of Entity Centered Sentence Rep-resentations in Natural Language Inferencing.
InProceedin#$ of the 6th International Joint Confer-ence on Artificial Intelligence.
Tokyo, 435-9.Aravind Joshi and Scott Weinstein.
1981.
Controlo f  Inference: Role of Some Aspects of DiscourseStructure--Centering.
In Proc-__~_ings o\] the 7thInternational Joint Conlerence on Artificial Intel.iigence.
Vancouver 385-7.Aravind Jcehi and Scott Weinstein.
1998.
Complex-ity and Control of Inference.
In (Walker et.al.,1998a), 31-9.Meg~,mi Kameymna.
1985.
Zero Anaphora: TheCase of Japanese.
Ph.D. Thesis.
Stanford Univer-sity.Hans Kamp.
1981.
A Theory of'llmth and SemanticRepresentation.
I  (Groenendijk et.al., 1981)William C. Mann and Sandra A. Thompson.
1987.Rhetorical Structure Theory.
In G. Kempen (ed.
)Natural Language Generation.
The Hague, Mou-ton.Per Martin-L6?
1984.
Intuitionistic type TheoryBibliopolis, Naples.Livia Polanyi and Martin H. van den Berg.
1996.Discourse Structure and Discourse Interpretation.In Prvce~__~_ings o~the Tenth Amsterdam (70110-qu/=nL ILLC, Amsterdam.Livia Polanyi and Remlm SchL 1984.
A SyntacticApproach to Discourse Semantics.
In P_roce_~____ingso!
t~z ~tb lntmmCionat Cony~we on Comz~t,.a-t/ona/?ing~/st/~.
Stanford CA.Livia Polanyi.
1987.
Keeping it all Straight: Inter-preting Narrative Time in Real Discourse.
WC-CTL 6: 229-245.Livia Polanyi.
1988.
A Formal Model of DiscourseStructure.
In Journal o/Pragmm~cs 12.~01-638.Livia Polanyi.
1996.
The.
Linguistic Structure ofDiscourse.
Stanford CA: CSLI Technical Report.Hub Prfist, Remko Scha and Martin H. van' denBerg.
1994.
Discourse Grammar and Verb Phrase1160O00000OO00@@@00O000O@000OOO@00@000OOO@O0OOOO0OOOOO@OOOOO@@OAnaphora.
Linguistics and Philosophy, 17;261-327.Owen Rainbow.
1993.
Pragmatic Aspects of Scram-bling and Topicalization i  German.
Paper pre-sented at the Workshop in Centering Theory, Isti-tute for Research in Cognitive Science, Universityof Pennsylvania, Philadelphia.
PA.Aarne Ranta.
1991.
Intuitionistic categorial Gram-.
mar.
Linguistics and Philosophy, 14:203-239.Craige Roberts.
1998.
The Place of Centering ina General Theory of Anaph0ra Resolution.
In(Walker et.al., 1998a), 359-400.Remko Scha.
1981.
Distributive, Collective and Cu-mulative Quantification.
In (Groenendijk et.al.,1981).Michael Strube.
1998.
Never Look Back: An Al-ternative to Centering.
In: Collng-ACL '98: Pro-ceedings of the 17th International Conference onComputational Linguistics and the 36th, AnnualMeeting of the Assodstion for ComputationalLinguistics.
Montreal, Quebec, Canada, Aug 10-14, pp.1251-1257.Mi'chael Strube and Udo Hahn.
1996).
FunctionalCentering.
Proceedings ofthe 34th Annual Meet-ing of the Association for Computational Linguis-tics, Santa ~uz, CA 270-7.Martin H. van den Berg.
1992.
Dynamic General-ized Quantifiers.
In Does J. M. v. d. and Eijck J.v.
:  quantifiers, logic and Language.
CSLI LectureNotes 54, Stanford CA.Martin H. van den Berg.
l~J6a.
The Internal Struc-ture of Discourse- Ph.D. Dissertation.
ILLC, Uni-versity Of ~,m.~.rdam.Martin H. van den Berg.
1996b.
Discourse Gram-m~ and Dynamic Logic.
Proceedings ofthe TenthAmsterdam Colloquium, ILLC, Amsterdam.Jaap van der Does.
1991.
Applied Quantifier Log-ics collectives and Naked Infinitives.
Ph.D. thes/s.University of ~ .Jaap vSa der Do~ 1993.
Formalizing E-typeAnaphor& Proceedings ofthe NinthColloquium, ILLC, Amsterdam.Msrilyn Walker, Amvind Joshi and Ellen Prince(ed).
199Sa.
~ Theory in Viscour~ Ox-ford.
Clarendon Press.Marilyn Walker, Amvind Joshi and Ellen Prince.1998b.
Centeri~ in Naturally Occurring Dis-course: An Overview.
In (Walker et.al., 199Sa)1-29.Marilyn Walker.
1998.
Centering, Anaphora Reso-lution, and Discourse Structure.
In (Walker et.al.,l~Sa), ~9-400.117118000000000000000000000000000000?000
