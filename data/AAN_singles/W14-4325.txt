Proceedings of the SIGDIAL 2014 Conference, pages 186?193,Philadelphia, U.S.A., 18-20 June 2014.c?2014 Association for Computational LinguisticsInitiative Taking in NegotiationElnaz NouriUniversity of Southern CaliforniaLos Angeles, CA, USAnouri@ict.usc.eduDavid TraumUSC Institute for Creative Technologies12015 Waterfront DrPlaya Vista, CA 90094, USAtraum@ict.usc.eduAbstractWe examine the relationship between ini-tiative behavior in negotiation dialoguesand the goals and outcomes of the ne-gotiation.
We propose a novel annota-tion scheme for dialogue initiative, includ-ing four labels for initiative and responsebehavior in a dialogue turn.
We anno-tate an existing human-human negotiationdataset, and use initiative-based featuresto try to predict both negotiation goal andoutcome, comparing our results to priorwork using other (non-initiative) featuressets.
Results show that combining initia-tive features with other features leads toimprovements over either set and a major-ity class baseline.1 IntroductionNegotiation is a complex interaction in which twoor more parties confer with one another to arriveat the settlement of some matter, for example re-solving a conflict or to share common resources.The parties involved in the negotiation often havenon-identical preferences and goals that they try toreach.
Sometimes the parties simply try to changea situation to their favor by haggling over price.
Inother cases, there can be a more complex trade-offbetween issues.
Investigating these rich and com-plex interactions in a scientific manner has beenimportant to researchers in different fields due tothe significant implications and potential applica-tions for business and profit making.
Being a goodnegotiator is not a skill that all humans naturallyhave; therefore, this line of research can poten-tially be used to help humans become better ne-gotiators.
Computer agents will also benefit fromthe ability to understand human negotiators.
Therehas been a fair amount of previous work in un-derstanding negotiation dialogs, e.g., (Walton andMcKersie, 1991; Baker, 1994); as well as agentswho can engage in negotiation, e.g.
(Jameson etal., 1994; Sidner, 1994; Kraus et al., 2008; Traumet al., 2008).
In this paper we investigate the rolethat dialogue initiative plays in negotiation.Negotiations can be characterized by both thegoals that each negotiator is trying to achieve, aswell as the outcomes.
Even for negotiations thatattempt to partition a set of goods, the participantsmay have differences in their valuation of items,and the negotiations can be very different if peo-ple are trying to maximize the total gain or theirindividual gain, or gain a competitive advantageover the other.Negotiations between two people are usuallymixed-initiative (Walker and Whittaker, 1990),with control of conversation being transferredfrom one person to another.
To our knowledge,no previous studies have investigated the relation-ship between verbal initiative taking patterns andthe goal or the outcome of the negotiation.
Wesuspected that both of the mentioned characteris-tics of the negotiation (goal and outcome) might becorrelated with different initiative-taking patterns.We used an existing negotiation dataset in orderto study the mixed initiative patterns between thetwo parties in the negotiation.
We describe thisdata set in Section 2, as well as previous work thatattempted to predict outcome and goal, using otherfeatures (Nouri et al., 2013).This paper makes the following contributions:a new annotation scheme for dialogue initiative isintroduced in Section 3 and used to annotate thenegotiation dataset.
We then study the relation-ship between initiative taking patterns and the goaland outcome of the negotiation for the participants(Section 4).2 DataWe make use of a previously collected and ana-lyzed dataset in order to examine the relative con-186tribution of initiative to problems of goal and out-come detection.
We briefly describe the datasetand relevant prior work on this dataset.The Farmers Market dataset (Carnevale, 2013)contains audio, video and transcription of 41dyadic negotiation sessions.
Participants were un-dergraduate students majoring in business.
Eachparticipant only took part in one negotiation ses-sion.Before each negotiation session, the experi-menter told participants that they were randomlyassigned to represent one of two restaurants in thetask.
The owners of the two restaurants had askedthe participants to go to the market and get someapples, bananas, lemons, peppers and strawber-ries.
The payoff matrix for each restaurant andtype of item is shown in Table 1.
There were mul-tiple items of each type available.
Each participantwas only given the pay-off matrix of his assignedrestaurant and the total score of the negotiation foreach participant was calculated by adding up thepoints for each item they received in the negotia-tion.
The participants were told that they had 10minutes to negotiate how to distribute the items onthe table and reach an agreement.
As an incentive,each participant could receive up to 50 dollars de-pending on the final points earned by each partici-pant for his/her restaurant.R1 R2Apples 1 3Bananas 3 3Lemons 0 0Peppers 3 1Strawberries 1 1Table 1: The Payoff Matrix for each Restaurant2.1 GoalsThe study was originally designed to investigatenegotiators?
behavior when they have differentgoals in the negotiation.
There were three typesof instructions given to the participants.
All thedetails were the same except for their goal in thenegotiation.?
In ?individualistic?
instructions participantswere told that their goal was to get at as manypoints as they could for themselves.
An ex-cerpt from an individualistic negotiation isshown in Table 13 in the Appendix.?
in ?cooperative?
instructions they were toldthat they should try to maximize the joint gainwith the other side of the negotiation.
An ex-cerpt from a cooperative negotiation is shownin Table 11 in the Appendix.?
in ?competitive?
instructions they were toldto try to get more points than the other party.An excerpt from a competitive negotiation isshown in Table 12 in the Appendix.Out of the 41 interactions in the dataset 15 werecompetitive, 13 were individualistic and 13 werecooperative sessions.2.2 OutcomesThe outcome of the negotiation in this case is mea-sured based on the calculation of the scores corre-sponding to the items that each negotiator has re-ceived by the end of the negotiation.
In order tomake the prediction of outcome possible based onour small dataset, we labeled the calculated scorefor each participant with one of the three labels:H,E or L, showing whether the participant had re-ceived more, equal or fewer points than the otherperson.The goal of the ?competitive?
instructions wasto get a higher score.
For cooperative negotiations,the relative score did not matter.
For the individu-alistic goal, higher score is somewhat correlatedwith the goal, but not absolutely (what mattersis only an individual high score, not the relationto the other partner).
17 negotiations resulted inequal final scores for the two parties and 24 withone side scoring more than the other side.
Ta-ble 2 shows the average scores for each restaurant,across the three types of goals.
The scores are onaverage higher in the cooperative negotiations thanin the other two conditions.Average score R1 R2 JointGainCooperative 24.9 25.1 50Competitive 23.7 23.6 47.3Individualistic 25.5 22.5 48Table 2: Average Score by Restaurant and GoalThe average score for individuals who scorehigher (labeled as H) than the other side of the ne-gotiation was 26.46 whereas the average score fortheir counterparts (labeled as L) was 21.65.
The187average score for individuals who ended up in atie (labeled as E) was 24.16.2.3 Previous Work and Baseline SystemThis data set was previously used for various pur-poses but (Nouri et al., 2013) was most similarto our current work in that it also tried to pre-dict the goal and outcome in the negotiation, us-ing a different set of features, and a slightly dif-ferent formulation of the problem.
(Nouri et al.,2013) used multimodal features (such as acousticfeatures and sentiments of the turns) for this pur-pose.
We use initiative-features to build our pre-diction models.
In order to make a baseline classi-fier, we used the following automatically derivablefeatures from (Nouri et al., 2013):?
The mean and standard deviation of acousticfeatures automatically extracted;?
The amount of silence and speaking time foreach speaker;?
Sentiment (positive, negative) and subjectiv-ity scores calculated for words and turns?
number of words, turns, words per turn andwords related to the negotiation objectsWe used only features that were easily and au-tomatically derivable, excluding features from(Nouri et al., 2013) such as the number of offersand the number of rejections or acceptances.3 Initiative LabelingA common way of structuring dialogue is withInitiative-Response pairs, or IR units (Dahlb?ackand J?onsson, 1998), which are also similar to adja-cency pairs (Levinson, 1983), or simple exchangeunits (Sinclair and Coulthard, 1975).
Several re-searchers have also proposed multiple levels ofinitiative.
For example, (Whittaker and Stenton,1988) had levels based on the type of utterance(commands, questions, assertions, and prompts).
(Chu-Carroll and Brown, 1997) posit two levelsof initiative: discourse initiative, attained by pro-viding reasons for responses, and critiques of pro-posed plans, and task initiative, obtained by sug-gesting new tasks or plans.
Linell et al.
exam-ine several factors, such as initiative vs response,strength of initiative, adequacy of response, scopeand focality of response (Linell et al., 1988).
Theyend up with an ordered set of six possible strengthsof initiative.
Each of these schemes is somewhatcomplicated by the fact that turns can consist ofmultiple basic elements.Analyzing previous work, we can see that initia-tive breaks down into two distinct concepts.
Firstthere is providing unsolicited, or optional, or ex-tra material, that is not a required response to aprevious initiative.
Second, there is the sense ofputting a new discourse obligation (Traum andAllen, 1994) on a dialogue partner to respond.These two concepts often come together, such asfor new questions or proposals that require somesort of response: they are both unsolicited and im-pose an obligation, which is why (Whittaker andStenton, 1988) indicate that control should belongto the speaker of these utterances.
However, it isalso possible to have each one without the other.Statements can include new unsolicited material,without imposing an obligation to respond (otherthan the weak obligation to ground understand-ing of any contribution).
Likewise, clarificationquestions impose new obligations on the other, butoften do not contribute new material or are notoptional, in that the responder can not reply ap-propriately without the clarification.
For (Whit-taker and Stenton, 1988), the issue of whethera question or assertion was a ?response?
woulddetermine whether control went to the speakeror remained with a previous speaker.
On theother hand, (Narayanan et al., 2000) call a re-sponse that includes unsolicited material ?mixed-initiative?
rather than ?system initiative?
for userresponses that contain only prompted material.Likewise, response can also be broken downinto two related concepts.
One concerns fulfillingobligations imposed by prior initiatives.
To not doso could be considered rude and a violation of con-versational norms in some cases.
This is only rel-evant, if there is an existing initiative-related obli-gation as part of the conversational state.
Anotherconcept generalizes the notion of response to any-thing that contributes to the same topic and makesan effort to relate to prior utterances by the otherparty, whether or not it fulfills an obligation orwhether there even is a pending obligation.
Thisis like relevance in the sense of Sperber and Wil-son (Sperber and Wilson, 1986) and Lascaridesand Asher (Asher and Lascarides, 2003).Our annotation scheme thus includes four la-bels, as indicated in Table 4.
Each of the labelscan either be present or absent from a dialogue188Time/Speaker Example Utterance Labels(R,F,I,N)[1 : 58] Person 1: Do you want to do just like one grab at a time?Or do you know how you want to divvy it up?
(-,-,I,N)[2 : 13] Person 2: Um, I?m just thinking.
(R,F,-,-)[3 : 38] Person 1: Do you want it?
I?ll take it.
Um, do you want to do any trading?
(R,-,I,-)[4 : 15] Person 2: Um, how much is a banana for you?
(-,-,I,N)[4 : 15] Person 1: For me?
A point, or two points.
How much is the pepper worth?
(R,F,I,N)Table 3: Sample Annotated UtterancesLabel DescriptionR directly relates to prior utteranceF fulfills a pending discourse obligationI imposes a discourse obligationN provides new material that is optionaland not just fulfilling an obligation.Table 4: Initiative Labelssegment.
The annotation is done on each turn onthe conversation.
In general, a turn can consist ofalmost any combination of these four initiative la-bels (I,R,F,N).
We thus treat each of these as anindependent binary dimension, and code each turnas to which set of these labels it contains.
Table 3shows an example from the corpus with initiativeannotations.
More examples can be found in theAppendix, Tables 11, 12, and 13.3.1 Inter Annotator ReliabilityTo assess the reliability of our annotations, ap-proximately 10% of the dialogs (4 dialogs) wereannotated by two annotators.
The level of theagreement was then assessed using the Kappastatistic (Carletta, 1996; Siegel and Castellan,1988).
Table 5 shows the result of the assessmentof the reliability of the annotations for the four an-notation labels.1Based on this metric our resultsindicate that the annotators have reasonable levelof agreement in labeling utterances with the I, F,N labels, though there is less reliability for the?related?
label.
Further work is needed to clar-ify the degree of relation that should count andalso whether relation refers just to the immediatelyprior turn or something further back.
The remain-der of the dialogues were annotated by one anno-tator.1Chance agreement is the probability of agreement usingthe frequencies of each label, but applied randomly.R F I Nkappa 0.36 0.64 0.66 0.73actual agreement 0.76 0.83 0.83 0.86chance agreement 0.62 0.52 0.49 0.50Table 5: Inter-Annotator Reliability Assessment3.2 Initiative Taking PatternsTable 6 shows the average frequency of each ini-tiative label for each negotiation goal.
We can seethat competitive dialogues have more turns thatimpose and fulfill obligations than the other con-ditions, while individualistic dialogues include ahigher percentage of turns introducing new mate-rial.Label R F I NCooperative 0.79 0.35 0.40 0.33Competitive 0.82 0.38 0.47 0.34Individualistic 0.82 0.34 0.39 0.40Table 6: Comparison of the Relative Frequency ofthe Initiative Labels for Each GoalTable 7 shows the relative frequency of initia-tive labels for the different outcome conditions.The higher scoring participants had a higher fre-quency of initiative-related turns (labels I and N),while their lower scoring partners had a higher fre-quency of responsive turns (R,F).
Equal scoringparticipants tended to pattern closer to higher scor-ing participants, concerning responses, but closerto lower scoring participants, considering initia-tive.3.3 Initiative FeaturesAfter the Initiative annotation was done, the fol-lowing features were automatically extracted:?
the count of each label (I,F,R,N) per negotia-tion and per person189Label R F I NH 0.80 0.35 0.47 0.38E 0.81 0.35 0.40 0.34L 0.84 0.38 0.43 0.36Table 7: Comparison of the Relative Frequency ofthe Initiative Labels for Each Score Label?
the ratio, difference and absolute differenceof the number of labels for each personagainst the number of labels for their nego-tiation counterpart?
the above measures normalized by the num-ber of turns in dialog?
Within-turn patterns the number of all pos-sible combinations of labels for each utter-ance.
There are 16 possible combinations forthe 4 types of labels that can be shown as tu-ples (R,F,I,N).
Refer to Table 5 for examples.?
Across-turn Patterns the number of all pos-sible sequences of labels across two adjacentturns.
There are also 16 possible combina-tions capturing how often each label is fol-lowed by labels.
For example, the feature(I,F) applies to all two-turn sequences wherethe first turn contains label I and the secondcontains label F, such as in the last two linesof Figure 3.
We count the these features forthe dialogue and for each speaker.All of the above features were automatically ex-tracted from the annotated dialogues.
We exam-ined four different spans of the dialogues, to inves-tigate whether the most salient initiative informa-tion comes early in the dialogue or requires the fulldialogue.
We calculated features for the first quar-ter (q1), first half (q2), first three quarters (q3), andthe whole negotiation (q4).4 Prediction ModelsWe conducted experiments to recognize negotia-tion goal and score for each of the 82 negotia-tors.
We made prediction models for recognizingthe goal and outcome for each individual.For theprediction models, we compared the result of sup-port vector machine (SVM- with the polynomialkernel function) classifier, Naive Bayes and De-cision Tree.
None of the classifiers outperformedthe others on all cases, we are reporting the resultof SVM classifier here.
Considering the size ofour dataset which consists of 82 samples (41 pairsof individuals) and the distribution of the samplesin different classes, we decided to use the 10-foldcross validation paradigm for our prediction tasks.In splitting the dataset into the folds we controlledso that the participants from the same negotiationwere not split across training and test sets.
Wetrained and tested at the end of the each quarterof the negotiation.We used three sets of features to make three pre-diction models for each task:1.
Non-initiative features from (Nouri et al.,2013), described in section 2.3.
We refer tothese non-initiative features as IS2013?
fromthis point on.2.
Initiative features3.
All features combined.We compare the performance of these models withtwo baseline prediction models: one that choosesone of the outcomes at random, and one that pre-dicts the majority class for all instances.
In theupcoming sections, we use q1, q2, q3 and q4 torefer to the ends of the first, second, third and theforth quarters of the negotiation (e.g.
q3 includesall data from the first three quarters, but not thelast).4.1 Automatic Prediction of GoalThis task predicts whether the negotiators are fol-lowing the cooperative, competitive or individual-istic instructions.
It is important to note that noneof the features used require understanding of thecontent or a semantic analysis of the conversation.However, using these basic features it?s possibleto make the classification into the mentioned threeclasses with accuracy that is significantly higherthan chance.
The average accuracy of predictionat the four different points in the negotiation areshown in Table 8.q1 q2 q3 q4Random 0.33 0.33 0.33?
0.33?Majority 0.37 0.37 0.37?
0.37IS2013 0.41 0.34 0.40?
0.48 ?
?Initiative 0.29?
0.52 ???
0.48 ??
0.29?Combined 0.41 0.40 0.57 ??
0.44 ?Table 8: Accuracy of the Prediction of Goal190We use the two-sided binomial test to measurethe significance of the differences of the predictionmodels?
performances.
Table 8 and the upcomingTables 9 and 10 use symbols to indicate the resultsof these significance tests.
Symbols (?),(?)
and(?)
show which models?
performances are signif-icantly different from the random baseline, major-ity baseline or the ?Combined?
classifier respec-tively (p < 0.05).The combined classifier is always better thanboth baselines, as well as the lower of classi-fiers for the IS2013 and Initiative features.
Inq3, where the two are close in performance, thecombined classifier significantly outperforms bothbaselines and the IS2013 model.
Note that ex-cept for q3, these numbers are lower than thosereported by (Nouri et al., 2013).
However the priorwork did not ensure that both individuals in a ne-gotiation were in the same training/test partition,and some features are the same for both partici-pants.
That work also made use of higher-levelfeatures, such as the offers, and final distributionsof items.4.2 Automatic Prediction of OutcomeIn this task the goal is to predict how a partic-ipant in the negotiation is going to do in termsof the scores at the end of the negotiation.
Themodel predicts whether the negotiator would scorehigher, lower or equal to the other player at the endof the different quarters of the negotiation.
Resultsare shown in Table 9.q1 q2 q3 q4Random 0.33 0.33 0.33 0.33?Majority 0.41 0.41 0.41 0.41IS2013 0.43 ?
0.34 0.23 ???
0.39Initiative 0.37 0.35 0.32 0.39Combined 0.38 0.40 0.41 0.4 6?Table 9: Accuracy of the Prediction of OutcomeExcept for the combined model in q4, thesemodels are not able to significantly outperform thebaseline of selecting the random class (with equallikelihood).
Results were also presented for out-come in (Nouri et al., 2013), however only the fi-nal quarter results are comparable, since that paperpredicted interim quarter-end results rather than fi-nal results.
Also, that work did not make sure thatboth participants in a negotiation were in the sametraining-test partitions, and used features related tothe final deal, that are directly related to outcome.Because the relative score was not important forcooperative negotiations, where both sides are justtrying to maximize their combined points, we nextexamined outcome for the 28 pairs in individualis-tic and competitive conditions.
Results are shownin table 10.
The combined classifier outperformsall the other classifiers, starting from quarter 2.
Atthe end of the negotiation(q4) the performance ofthis classifier is significantly better than all othermodels.q1 q2 q3 q4Random 0.33 0.33?
0.33?
0.33?Majority 0.38 0.38 0.38 0.38?IS2013 0.39 0.36?
0.36?
0.34?Initiative 0.27 0.41 0.36?
0.38?Combined 0.35 0.50 ?
0.50 ?
0.55 ?
?Table 10: Accuracy of the Prediction of Outcomefor Negotiations that are not Cooperative5 ConclusionWe demonstrated how discourse initiatives in ne-gotiation dialog can be used for automaticallymaking predictions about other aspects of the ne-gotiation such as the goals of the negotiators.
Pre-vious work has mostly focused on using non-verbal cues for accomplishing similar tasks butthey have not used discourse features like initia-tives.
We also show that initiative features cangive clues about the final outcome for the negotia-tors.
Making such predictions are generally chal-lenging tasks even for humans and require under-standing of the content of the negotiations.
From adialog system?s perspective our results show howmore information can be derived about the usersintentions and performance by analyzing their dis-course behavior.6 Future WorkThe annotations of the initiative taking patternsare done manually at this point.
Automatic label-ing of the utterances with the initiative tags is ournext step.
We will use the labels in our datasetfor learning how to automatically label new nego-tiation datasets.
We think that HMM and HCRFmethods due to their ability to capture the sequen-tial and temporal aspect of the negotiation mightbe better methods for building the prediction mod-191els.
We are interested in further analysis of the re-lationship between initiatives and other aspects ofnegotiation such as intentions and the use of lan-guage.
We also want to measure the suitability ofour annotation scheme for initiatives for other di-alogue genres.AcknowledgmentsWe like to thank Kristina Striegnitz, ChristopherWienberg, Angela Nazarian and David DeVaultfor their help with this work.
The effort describedhere has been sponsored by the US Army.
Anyopinions, content or information presented doesnot necessarily reflect the position or the policyof the United States Government, and no officialendorsement should be inferred.ReferencesNicholas Asher and Alex Lascarides.
2003.
Logics ofConversation.
Cambridge University Press.Michael Baker.
1994.
A model for negotiation inteaching-learning dialogues.
Journal of artificial in-telligence in education.Jean Carletta.
1996.
Assessing agreement on classi-fication tasks: the kappa statistic.
Computationallinguistics, 22(2):249?254.Peter J Carnevale.
2013.
Audio/video recordings of bi-lateral negotiations over synthetic objects on a tablethat vary in monetary value.
Unpublished raw data.Jennifer Chu-Carroll and Michael K. Brown.
1997.Tracking initiative in collaborative dialogue inter-actions.
In Proceedings of the Thirty-Fifth Meet-ing of the Association for Computational Linguis-tics, pages 262?270.
Association for ComputationalLinguistics.Nils Dahlb?ack and Arne J?onsson.
1998.
A codingmanual for the link?oping dialogue model.
unpub-lished manuscript.Anthony Jameson, Bernhard Kipper, Alassane Ndi-aye, Ralph Sch?afer, Joep Simons, Thomas Weis, andDetlev Zimmermann.
1994.
Cooperating to be non-cooperative: The dialog system PRACMA.
Springer.Sarit Kraus, Penina Hoz-Weiss, Jonathan Wilkenfeld,David R Andersen, and Amy Pate.
2008.
Resolv-ing crises through automated bilateral negotiations.Artificial Intelligence, 172(1):1?18.Stephen C. Levinson.
1983.
Pragmatics.
CambridgeUniversity Press.Per Linell, Lennart Gustavsson, and P?aivi Juvonen.1988.
Interactional dominance in dyadic communi-cation: a presentation of initiative-response analysis.Linguistics, 26(3):415?442.Shrikanth Narayanan, Giuseppe Di Fabbrizio, Can-dace A. Kamm, James Hubbell, Bruce Buntschuh,P.
Ruscitti, and Jerry H. Wright.
2000.
Effects ofdialog initiative and multi-modal presentation strate-gies on large directory information access.
In IN-TERSPEECH, pages 636?639.
ISCA.Elnaz Nouri, Sunghyun Park, Stefan Scherer, JonathanGratch, Peter Carnevale, Louie Philippe Morency,and David Traum.
2013.
Prediction of strategy andoutcome as negotiation unfolds by using basic ver-bal and behavioral features.
In proceedings of theInterspeech conference.Candace L. Sidner.
1994.
An artificial discourse lan-guage for collaborative negotiation.
In Proceedingsof the Fourteenth National Conference of the Amer-ican Association for Artificial Intelligence (AAAI-94), pages 814?819.S.
Siegel and N. J. Castellan.
1988.
Nonparamet-ric statistics for the Behavioral Sciences.
McGraw-Hill, 2nd edition.J.
M. Sinclair and R. M. Coulthard.
1975.
Towards ananalysis of Discourse: The English used by teachersand pupils.
Oxford University Press.Dan Sperber and Deirdre Wilson.
1986.
Relevence:Communication and Cognition.
Harvard UniversityPress.David R. Traum and James F. Allen.
1994.
Discourseobligations in dialogue processing.
In Proceedingsof the 32ndAnnual Meeting of the Association forComputational Linguistics, pages 1?8.David Traum, Stacy C Marsella, Jonathan Gratch, JinaLee, and Arno Hartholt.
2008.
Multi-party, multi-issue, multi-strategy negotiation for multi-modalvirtual agents.
In Intelligent Virtual Agents, pages117?130.
Springer.Marilyn Walker and Steve Whittaker.
1990.
Mixed ini-tiative in dialogue: An investigation into discoursesegmentation.
In Proceedings of the 28th annualmeeting on Association for Computational Linguis-tics, pages 70?78.
Association for ComputationalLinguistics.Richard E Walton and Robert B McKersie.
1991.
Abehavioral theory of labor negotiations: An analysisof a social interaction system.
Cornell UniversityPress.Steve Whittaker and Phil Stenton.
1988.
Cues andcontrol in expert-client dialogues.
In ProceedingsACL-88, pages 123?130.Appendix: Sample Annotated NegotiationsThe following tables show examples of each of thegoal conditions with initiative labeling, using thescheme in Table 4.192Time Speaker: Utterance Labels(R,F,I,N)[2 : 18] 2: So what?s, so what?s everything worth to you?
(-,-,I,N)[2 : 20] 1: Um, so apples are three, bananas are three, strawberries are one, pep-pers are one, and lemons are nothing.
(R,F,-,-)[2 : 33] 2: Okay so for me peppers are three, bananas are three, and apples andstrawberries are one.
(R,-,-,-)[2 : 39] 1: Lemons are zero.
(R,-,-,-)[2 : 40] 2: Yeah.
(R,-,-,)Table 11: Sample Annotated Cooperative NegotiationTime Speaker: Utterance Labels[1 : 40] 2: So, I think I need peppers and bananas for my restaurant.
(-,-,-,N)[1 : 46] 1: Okay.
Um, well I really need.
I want five apples and um, five bananas.Five apples and five bananas.
(R,-,I,N)[2 : 05] 2: Um, how about this: You take five apples, and I take five peppers andwe can share the bananas.
(R,F,I,N)[2 : 13] 1: Okay.
If I give you, if I give you five or if I give you, if we were toshare the bananas, if I take three bananas, I?ll give you three lemons.
(R,F,I,N)[2 : 23] 2: But we don?t need lemons in our restaurant.
We only use lemons forour store.
(R,F,-,N)[2 : 27] 1: Okay.
So, um, I need bananas, like that?s gonna be my top.
(R,-,-,N)Table 12: Sample Annotated Competitive NegotiationTime Speaker: Utterance Labels[3 : 22] 2: How about we do this.
You take two of these, I take one, and since wehave five here, I take three, you take two.
(-,F,I,N)[3 : 37] 1: I?m not interested in lemons at all.
But I can give you... (R,F,-,N)[3 : 52] 2: At my restaurant, one of our dessert dishes is with strawberries, sostrawberries are very important to me.
(-,-,-,N)[4 : 00] 1: Okay.
I?m willing to give you all the strawberries if you give me abanana and two apples.
I?m also willing to give you these two.
(R,-,-,N)[4 : 23] 2: So you?re going to give me those two?
(R,-,I,-)[4 : 24] 1: You can have everything on this side, I just want two apples and abanana.
(R,F,-,-)[4 : 30] 2: Two apples and a banana?
Yeah, let?s go.
(R,-,-,-)[4 : 39] 1: We have a deal.
(R,F,-,N)Table 13: Sample Annotated Individualistic Negotiation193
