Proceedings of the First Celtic Language Technology Workshop, pages 76?80,Dublin, Ireland, August 23 2014.Subsegmental language detection in Celtic language textAkshay MinochaIIIT HyderabadHyderabad (India)akshay.minocha@students.iiit.ac.inFrancis M. TyersGiellateknoUiT Norgga ?arktala?s universitehta9017 Romsa (Norway)francis.tyers@uit.noAbstractThis paper describes an experiment to perform language identification on a sub-sentence basis.The typical case of language identification is to detect the language of documents or sentences.However, it may be the case that a single sentence or segment contains more than one language.This is especially the case in texts where code switching occurs.1 IntroductionDetermining the language of a piece of text is one of the first steps that must be taken before proceedingwith further computational processing.
This task has received a substantial amount of attention in recentyears (Cavnar and Trenkle, 1994; Lui and Baldwin, 2012).
However, previous research has on the wholeassumed that a given text will be in a single language.
When dealing with text from formal domains, thismay be the case ?
although there are exceptions ?
such as quotations embedded in the text in anotherlanguage.
But when dealing with informal text, particularly in languages where the speech communityis predominantly bi- or multi-lingual, this assumption may not hold.The work presented in this paper was motivated by the problems in normalising non-standard inputfor the Celtic languages as a precursor to machine translation.
When applying a normalisation strategyto a piece of text, it is necessary to first know the language of the piece of text you are applying it to.The remainder of the paper is laid out as follows.
In Section 3 we describe the problem in more detailand look at relevant prior work before proposing a novel method of sub-sentential language detection.Section 4 describes the evaluation methodology.
Then in Section 5 we present the results of our methodand compare it against several other possible methods.
Finally, Section 6 presents future work andconclusions.2 Related WorkCode-switching and segment detection problems have been the subject of previous research.
A gooddeal of work has been done on detecting code-switched segments in speech data (Chan et al., 2004; Lyuet al., 2006).
It is seen that language modelling techniques have shown promise earlier, such as in Yu etal.
(2013), the experiment on Mandarin-Taiwanese sentences show a high accuracy in terms of detectingcode-switched sentences.In Chan et al.
(2004) the authors have made use of the bi-phone probabilities and calculated them tomeasure a confidence metric, to (Lyu et al., 2006) which has made use of named syllable-based durationclassification, which uses the tonal syllable properties along with the speech signals to help predict thecode switch points.
In Yeong and Tan (2010) the authors use syllable structure information to identifywords in code-switched text in Malay-English, however they did not recognise segments in running text,only identifying individual words.This work is licensed under a Creative Commons Attribution 4.0 International Licence.
Page numbers and proceedings footer areadded by the organisers.
Licence details: http://creativecommons.org/licenses/by/4.0/76Pair LanguageStatistics (%)Tokens SegmentsIrish?EnglishIrish 332 40English 379 42Welsh?EnglishWelsh 419 64English 378 66Breton?FrenchBreton 388 54French 379 53Table 1: Document statistics of the annotated data used.
[en You?re a] [ga Meirice?anach, c?en f?ath] [en are you] [ga foghlaim Gaeilge?!
]@afaltomkins [cy gorfod cael bach o tan] [en though init][en omg] [cy mar cwn bach yn] [en black and tan] [cy a popeth,] [en even cuter!!
]Figure 1: Example of text from a microblogging site chunked manually.3 MethodologyAs the number of possible languages for each segment is in theory the set of all the world?s writtenlanguages, we take a decision to simplify the task by only looking at texts in the Celtic language andthe corresponding majority language spoken where the Celtic language is spoken.
That is, we looked atdetecting between Irish and English, Welsh and English and Breton and French.3.1 CorpusWe hand-annotated a small evaluation set from a selection of posts to a popular microblogging site.1The tweets (microblog posts) were filtered into three sets which had been identified as Irish, Welsh andBreton using the langid tool (Lui and Baldwin, 2012).
From these, we manually selected between 40and 50 tweets for each language pair.
Statistics on the number of segments and tokens is presentedin Table 1.
Certain tokens were escaped from the data, such as the ?mentioned?
character (@ symbol),subject tags ?hashtags?
which are preceded by a # symbol, hyperlinks and the sequence rt which standsfor ?re-tweet?.
An example of the content of our corpus after hand annotation is given in Figure 1.
All ofthe tweets had at least one instance of code-switching.3.2 Alphabet n-gram approachWe use the character n-gram approach along with some heuristics which are relevant to our problemdomain of identifying segments for subsequent processing.
We would like to both predict the codeswitched points but looking at the surrounding structure also decide the inclusion of them into the currentor the next segment.We first built character language models using IRSTLM (Federico et al., 2008) for the five languagesin question.
For English and French a model was trained using the EuroParl corpus (Koehn, 2005).
ForBreton, Welsh and Irish we used corpora of text crawled from the web.
To ensure no bias and also sinceour dataset for Breton was around 1.5 million, we sampled the same size of data for all the five languages.In order to build a character language model we replaced spaces with the underscore symbol ?
?, and thenplaced a space character between each character.
Punctuation and non-letter characters are also part ofthis language model.
For example, the word ?sl?ainte!?
would be broken down into a sequence of {?
s?,?s l?, ?l ?a?, ?
?a i?, ?i n?, ?n t?, ?t e?, ?e !
?, ?!
?
}.3.3 Sequence chunkingThis section describes the way we apply heuristics to segment and label the input text.
In Figure 2,?chunks?
represent the list of evaluated tuples of segments and their labelled language, ?buffer?
is theexpanding segment.
LANGPREDICT corresponds to any function which is used to determine the language1http://indigenoustweets.blogspot.in/2013/12/mapping-celtic-twittersphere.html77of the token.
The flag variable helps in implementing the heuristic of minimum segment size whilelabelling chunks.Require: s : sentence to chunk1: buffer = [ ] /*Undecided expanding window of chunk*/2: chunks = [ ] /*Decided labelled segment*/3: buffer language?
LANGPREDICT(s[0]) /* Language of first word */4: flag?
05: for all w ?
s do6: if LANGPREDICT(w)=buffer language then7: if flag = 1 then8: buffer?
buffer + [word buffer,w]9: flag?
010: else11: buffer?
buffer + [ w]12: if LANGPREDICT(w) ?
=buffer language then13: if flag= 0 then14: flag?
115: word buffer?
w16: continue17: else18: chunks?
chunks + [(buffer,buffer language)]19: buffer?
[word buffer,w]20: buffer language?
LANGPREDICT(w) /* Language of new expanding chunk */21: flag?
022: if length(buffer) ?
=0 then23: chunks?
chunks + [(buffer,buffer language)]Figure 2: Chunking Algorithm3.4 Word-based predictionDesigned keeping in mind importance of the most common words, this procedure included checkingeach word against both of the word lists in question,2it is associated to one language or another.
Incase of a conflict, for example, when the word exists in both wordlists, or in the case that it is unknownto both, the option of continuing with the previous span was taken and the previous selected tag waslabelled, thus increasing the chunk.3.5 Word-based prediction with character backoffIn case of the word being present in only one of the two monolingual word lists the classification issimple, but in case of a conflict, a character bigram backoff was introduced to help us disambiguate thelanguage label.4 EvaluationFor the Evaluation procedure, we follow the footsteps of the CoNLL-2000 shared task on language-independent named entity recognition: dividing text into syntactically related non-overlapping groups ofwords.
This chunking mechanism (Tjong Kim Sang and De Meulder, 2003) is very similar to ours, interms of words which only belong to one category (here, language), and also evaluation based on thesegment structure present in the data.
The chunks here are such that they belong to only one language.The evaluation statistics shown in Tables 2 and 3 mention two values for each of the experimentconducted on the three bilingual language datasets.
The first, is the percentage of correctly detectedphrases, which is the overall precision and the second is the number of phrases in the data that werefound by the chunker, which is the overall recall.Apart from the techniques discussed in Section 3, some baselines are also used to give a comparativeview of how well all the mechanisms perform.4.1 BaselineWe used the language identification tool langid.py (Lui and Baldwin, 2012) on the whole dataset andlabelled all the individual lines according to this majority classification.
As no chunking is performed we2For the wordlists we used the aspell wordlists widely available on Unix systems.78SystemIrish?English Welsh?English Breton?FrenchIrish English Welsh English Breton Frenchbaselinep 2.50 0.0 0.0 0.0 0.0 0.0r 2.56 0.0 0.0 0.0 0.0 0.0langid-3characterp 5.00 14.29 0.0 21.21 1.85 20.75r 5.41 8.45 0.0 14.58 1.92 12.36wordlistp 32.50 28.57 26.69 40.91 57.41 33.96r 23.64 26.09 26.03 33.75 47.69 33.33character bigramp 32.50 35.71 23.44 19.70 57.41 52.83r 22.41 26.79 15.31 16.67 41.33 37.84wordlist+character bigramp 52.50 50.00 32.81 31.82 70.37 67.92r 38.18 43.75 24.14 25.61 57.58 57.14Table 2: Precision, p and recall, r for the systems by language.SystemAccuracy (%)Irish?English Welsh?English Breton?Frenchbaseline 42.76 42.16 44.07langid-3character 57.24 45.92 43.16wordlist 79.75 74.28 83.96character bigram 81.29 65.62 76.79wordlist+character bigram 85.79 72.40 88.79Table 3: Accuracy of the systems over the three language pairs.
The accuracy measures how often a token was assigned to theright language, independent of span.can expect that the precision and recall will be very low.
However it does provide a reasonable baselinefor the per-word accuracy.4.2 langid character trigram predictionFor this system we used the character trigram probabilities to predict the detected language for eachtoken.
Trigrams were chosen after experimenting with 1?5 grams.
The heuristics in Section 3 werefollowed for the text processing and chunking part of the method.5 ResultsAs described in Section 3 the data collected from Twitter for the three language pairs, was processedusing the techniques mentioned.
The statistics of the same are given in Table 1.While the precision and recall are low for the remaining models, we see that we are able to improveThe performance by combining the wordlist based model with a character bigram model.
And what ismore, we are able to begin to not only identify particular words in a language, but also segments.6 ConclusionsThis paper has presented a very preliminary investigation into subsegment language identification inCeltic language texts.
We have proposed a model that chunks input text into segments and performslanguage identification on these segments at the same time.
Precision and recall are low, leaving a lot ofroom for further work.
Although King and Abney (2013) label on a per word level, yet we would liketo include supervised methods and features talked about in this research to improve our efficiency whiledealing with segments.
We would also like to attempt our method using higher order character n-grammodels for backoff, and n-gram word language models for detection and on more annotated data.AcknowledgementsWe thank Kevin Scannell for help with providing data from Twitter and for useful comments and sug-gestions.
This work was undertaken as part of the Apertium project in the 2014 Google Summer ofCode.79ReferencesWilliam B Cavnar and John M Trenkle.
1994.
N-gram-based text categorization.
Ann Arbor MI, 48113(2):161?175.Joyce YC Chan, PC Ching, Tan Lee, and Helen M Meng.
2004.
Detection of language boundary in code-switchingutterances by bi-phone probabilities.
In Chinese Spoken Language Processing, 2004 International Symposiumon, pages 293?296.
IEEE.Marcello Federico, Nicola Bertoldi, and Mauro Cettolo.
2008.
Irstlm: an open source toolkit for handling largescale language models.
In Interspeech, pages 1618?1621.Ben King and Steven P Abney.
2013.
Labeling the languages of words in mixed-language documents usingweakly supervised methods.
In HLT-NAACL, pages 1110?1119.Philipp Koehn.
2005.
Europarl: A parallel corpus for statistical machine translation.
In MT summit, volume 5,pages 79?86.Marco Lui and Timothy Baldwin.
2012. langid.
py: An off-the-shelf language identification tool.Dau-cheng Lyu, Ren-yuan Lyu, Yuang-chin Chiang, and Chun-nan Hsu.
2006.
Language identification by us-ing syllable-based duration classification on code-switching speech.
In Chinese Spoken Language Processing,pages 475?484.
Springer.Erik F Tjong Kim Sang and Fien De Meulder.
2003.
Introduction to the CoNLL-2003 shared task: Language-independent named entity recognition.
In Proceedings of the seventh conference on Natural language learningat HLT-NAACL 2003-Volume 4, pages 142?147.
Association for Computational Linguistics.Yin-Lai Yeong and Tien-Ping Tan.
2010.
Language identification of code switching malay-english words usingsyllable structure information.
Spoken Languages Technologies for Under-Resourced Languages (SLTU?10),pages 142?145.Liang-Chih Yu, Wei-Cheng He, Wei-Nan Chien, and Yuen-Hsien Tseng.
2013.
Identification of code-switchedsentences and words using language modeling approaches.
Mathematical Problems in Engineering, 2013.80
