Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 257?265,Uppsala, Sweden, 11-16 July 2010. c?2010 Association for Computational LinguisticsRecommendation in Internet Forums and BlogsJia WangSouthwestern Univ.of Finance &Economics Chinawj96@sina.cnQing LiSouthwestern Univ.of Finance &Economics Chinaliq t@swufe.edu.cnYuanzhu Peter ChenMemorial Univ.
ofNewfoundlandCanadayzchen@mun.caZhangxi LinTexas Tech Univ.USAzhangxi.lin@ttu.eduAbstractThe variety of engaging interactionsamong users in social medial distinguishesit from traditional Web media.
Such a fea-ture should be utilized while attempting toprovide intelligent services to social me-dia participants.
In this article, we presenta framework to recommend relevant infor-mation in Internet forums and blogs usinguser comments, one of the most represen-tative of user behaviors in online discus-sion.
When incorporating user comments,we consider structural, semantic, and au-thority information carried by them.
Oneof the most important observation fromthis work is that semantic contents of usercomments can play a fairly different rolein a different form of social media.
Whendesigning a recommendation system forthis purpose, such a difference must beconsidered with caution.1 IntroductionIn the past twenty years, the Web has evolvedfrom a framework of information dissemination toa social interaction facilitator for its users.
Fromthe initial dominance of static pages or sites, withaddition of dynamic content generation and pro-vision of client-side computation and event han-dling, Web applications have become a preva-lent framework for distributed GUI applications.Such technological advancement has fertilized vi-brant creation, sharing, and collaboration amongthe users (Ahn et al, 2007).
As a result, the roleof Computer Science is not as much of designingor implementing certain data communication tech-niques, but more of enabling a variety of creativeuses of the Web.In a more general context, Web is one of themost important carriers for ?social media?, e.g.
In-ternet forums, blogs, wikis, podcasts, instant mes-saging, and social networking.
Various engaginginteractions among users in social media differ-entiate it from traditional Web sites.
Such char-acteristics should be utilized in attempt to pro-vide intelligent services to social media users.One form of such interactions of particular inter-est here is user comments.
In self-publication, orcustomer-generated media, a user can publish anarticle or post news to share with others.
Otherusers can read and comment on the posting andthese comments can, in turn, be read and com-mented on.
Digg (www.digg.com), Yahoo!Buzz(buzz.yahoo.com) and various kinds of blogs arecommercial examples of self-publication.
There-fore, reader responses to earlier discussion providea valuable source of information for effective rec-ommendation.Currently, self-publishing media are becomingincreasingly popular.
For instance, at this point ofwriting, Technorati is indexing over 133 millionblogs, and about 900,000 new blogs are createdworldwide daily1.
With such a large scale, infor-mation in the blogosphere follows a Long Tail Dis-tribution (Agarwal et al, 2010).
That is, in aggre-gate, the not-so-well-known blogs can have morevaluable information than the popular ones.
Thisgives us an incentive to develop a recommenderto provide a set of relevant articles, which are ex-pected to be of interest to the current reader.
Theuser experience with the system can be immenselyenhanced with the recommended articles.
In thiswork, we focus on recommendation in Internet fo-rums and blogs with discussion threads.Here, a fundamental challenge is to account fortopic divergence, i.e.
the change of gist duringthe process of discussion.
In a discussion thread,the original posting is typically followed by otherreaders?
opinions, in the form of comments.
Inten-1http://technorati.com/257tion and concerns of active users may change asthe discussion goes on.
Therefore, recommenda-tion, if it were only based on the original posting,can not benefit the potentially evolving interests ofthe users.
Apparently, there is a need to considertopic evolution in adaptive content-based recom-mendation and this requires novel techniques inorder to capture topic evolution precisely and toprevent drastic topic shifting which returns com-pletely irrelevant articles to users.In this work, we present a framework to recom-mend relevant information in Internet forums andblogs using user comments, one of the most rep-resentative recordings of user behaviors in theseforms of social media.It has the following contributions.?
The relevant information is recommendedbased on a balanced perspective of both theauthors and readers.?
We model the relationship among commentsand that relative to the original posting us-ing graphs in order to evaluate their combinedimpact.
In addition, the weight of a commentis further enhanced with its content and withthe authority of its poster.2 Related WorkIn a broader context, a related problem is content-based information recommendation (or filtering).Most information recommender systems select ar-ticles based on the contents of the original post-ings.
For instance, Chiang and Chen (Chiang andChen, 2004) study a few classifiers for agent-basednews recommendations.
The relevant news selec-tions of these work are determined by the textualsimilarity between the recommended news and theoriginal news posting.
A number of later proposalsincorporate additional metadata, such as user be-haviors and timestamps.
For example, Claypool etal.
(Claypool et al, 1999) combine the news con-tent with numerical user ratings.
Del Corso, Gull?
?,and Romani (Del Corso et al, 2005) use times-tamps to favor more recent news.
Cantador, Bel-login, and Castells (Cantador et al, 2008) utilizedomain ontology.
Lee and Park (Lee and Park,2007) consider matching between news article at-tributes and user preferences.
Anh et al (Ahnet al, 2007) and Lai, Liang, and Ku (Lai et al,2003) construct explicit user profiles, respectively.Lavrenko et al (Lavrenko et al, 2000) proposethe e-Analyst system which combines news storieswith trends in financial time series.
Some go evenfurther by ignoring the news contents and only us-ing browsing behaviors of the readers with similarinterests (Das et al, 2007).Another related problem is topic detection andtracking (TDT), i.e.
automated categorization ofnews stories by their themes.
TDT consistsof breaking the stream of news into individualnews stories, monitoring the stories for eventsthat have not been seen before, and categorizingthem (Lavrenko and Croft, 2001).
A topic is mod-eled with a language profile deduced by the news.Most existing TDT schemes calculate the similar-ity between a piece of news and a topic profile todetermine its topic relevance (Lavrenko and Croft,2001) (Yang et al, 1999).
Qiu (Qiu et al, 2009)apply TDT techniques to group news for collabo-rative news recommendation.
Some work on TDTtakes one step further in that they update the topicprofiles as part of the learning process during itsoperation (Allan et al, 2002) (Leek et al, 2002).Most recent researches on information recom-mendation in social media focus on the blogo-sphere.
Various types of user interactions in theblogosphere have been observed.
A prominentfeature of the blogosphere is the collective wis-dom (Agarwal et al, 2010).
That is, the knowledgein the blogosphere is enriched by such engaginginteractions among bloggers and readers as post-ing, commenting and tagging.
Prior to this work,the linking structure and user tagging mechanismsin the blogosphere are the most widely adoptedones to model such collective wisdom.
For ex-ample, Esmaili et al (Esmaili et al, 2006) fo-cus on the linking structure among blogs.
Hayes,Avesani, and Bojars (Hayes et al, 2007) exploremeasures based on blog authorship and reader tag-ging to improve recommendation.
Li and Chenfurther integrate trust, social relation and semanticanalysis (Li and Chen, 2009).
These approachesattempt to capture accurate similarities betweenpostings without using reader comments.
Dueto the interactions between bloggers and readers,blog recommendation should not limit its input toonly blog postings themselves but also incorporatefeedbacks from the readers.The rest of this article is organized as follows.We first describe the design of our recommenda-tion framework in Section 3.
We then evaluatethe performance of such a recommender using two258     fffiflffi   ! "fi#$$"fi# $"fi#%&Figure 1: Design schemedifferent social media corpora (Section 4).
Thispaper is concluded with speculation on how thecurrent prototype can be further improved in Sec-tion 5.3 System DesignIn this section, we present a mechanism for rec-ommendation in Internet forums and blogs.
Theframework is sketched in Figure 1.
Essentially,it builds a topic profile for each original postingalong with the comments from readers, and usesthis profile to retrieve relevant articles.
In par-ticular, we first extract structural, semantic, andauthority information carried by the comments.Then, with such collective wisdom, we use a graphto model the relationship among comments andthat relative to the original posting in order to eval-uate the impact of each comment.
The graph isweighted with postings?
contents and the authors?authority.
This information along with the originalposting and its comments are fed into a synthe-sizer.
The synthesizer balances views from bothauthors and readers to construct a topic profile toretrieve relevant articles.3.1 Incorporating CommentsIn a discussion thread, comments made at differ-ent levels reflect the variation of focus of read-ers.
Therefore, recommended articles should re-flect their concerns to complement the author?sopinion.
The degree of contribution from eachcomment, however, is different.
In the extremecase, some of them are even advertisements whichare completely irrelevant to the discussion topics.In this work, we use a graph model to differenti-ate the importance of each comment.
That is, wemodel the authority, semantic, structural relationsof comments to determine their combined impact.3.1.1 Authority Scoring CommentsIntuitively, each comment may have a different de-gree of authority determined by the status of itsauthor (Hu et al, 2007).
Assume we have n usersin a forum, denoted by U = {u1, u2, .
.
.
, un}.We calculate the authority ai for user ui.
To dothat, we employ a variant of the PageRank algo-rithm (Brin and Page, 1998).
We consider thecases that a user replies to a previous posting andthat a user quotes a previous posting separately.For user uj , we use lr(i, j) to denote the numberof times that uj has replied to user ui.
Similarly,we use lq(i, j) to denote the number of times thatuj has quoted user ui.
We combine them linearly:l?
(i, j) = ?1lr(i, j) + ?2lq(i, j).Further, we normalize the above quantity to recordhow frequently a user refers to another:l(i, j) = l?
(i, j)?nk=1 l?
(i, k) + ?.Inline with the PageRank algorithm, we definethe authority of user ui asai = ?n + (1?
?
)?n?k=1(l(k, i)?
ak) .3.1.2 Differentiating comments withSemantic and Structural relationsNext, we construct a similar model in terms of thecomments themselves.
In this model, we treat theoriginal posting and the comments each as a textnode.
This model considers both the content simi-larity between text nodes and the logic relationshipamong them.On the one hand, the semantic similarity be-tween two nodes can be measured with any com-monly adopted metric, such as cosine similarityand Jaccard coefficient (Baeza-Yates and Ribeiro-Neto, 1999).
On the other hand, the structural re-lation between a pair of nodes takes two formsas we have discussed earlier.
First, a commentcan be made in response to the original postingor at most one earlier comment.
In graph theo-retic terms, the hierarchy can be represented as atree GT = (V,ET ), where V is the set of all textnodes and ET is the edge set.
In particular, theoriginal posting is the root and all the commentsare ordinary nodes.
There is an arc (directed edge)eT ?
ET from node v to node u, denoted (v, u), ifthe corresponding comment u is made in responseto comment (or original posting) v. Second, acomment can quote from one or more earlier com-ments.
From this perspective, the hierarchy canbe modeled using a directed acyclic graph (DAG),259M0.8 0.50.8 0 0000.500 00 0000010 00 100 000.50 100.8CMTMD213213Semantic RelationQuotation RelationReply RelationM00 01.50.8Figure 2: Multi-relation graph of comments basedon the structural and semantic informationdenoted GD = (V,ED).
There is an arc eD ?
EDfrom node v to node u, denoted (v, u), if the corre-sponding comment u quotes comment (or originalposting) v. As shown in Figure 2, for either graphGT or GD, we can use a ?V ?
?
?V ?
adjacency ma-trix, denoted MT and MD, respectively, to recordthem.
Similarly, we can also use a ?V ?
?
?V ?
ma-trix defined on [0, 1] to record the content similar-ity between nodes and denote it by MC .
Thus, wecombine these three aspects linearly:M = ?1 ?MC + ?2 ?MT + ?3 ?MD.The importance of a text node can be quantizedby the times it has been referred to.
Consideringthe semantic similarity between nodes, we use an-other variant of the PageRank algorithm to calcu-late the weight of comment j:s?j =?
?V ?
+ (1?
?)?
?V ?
?k=1rk,j ?
s?k,where ?
is a damping factor, and rk,j is the nor-malized weight of comment k referring to j de-fined asr(k, j) = Mk,j?jMk,j + ?
,where Mk,j is an entry in the graph adjacency ma-trix M and ?
is a constant to avoid division by zero.In some social networking media, a user mayhave a subset of other users as ?friends?.
This canbe captured by a ?U ??
?U ?
matrix of {0, 1}, whoseentries are denoted by fi,j .
Thus, with this infor-mation and assuming poster i has made a commentk for user j?s posting, the final weight of this com-ment is defined assk = s?k ?
(ai + fi,j2).3.2 Topic Profile ConstructionOnce the weight of comments on one posting isquantified by our models, this information alongwith the entire discussion thread is fed into a syn-thesizer to construct a topic profile.
As such, theperspectives of both authors and readers are bal-anced for recommendation.The profile is a weight vector of terms to modelthe language used in the discussion thread.
Con-sider a posting d0 and its comment sequence{d1, d2, ?
?
?
, dm}.
For each term t, a compoundweight W (t) = (1?
?)
?
W1(t) + ?
?
W2(t)is calculated.
It is a linear combination of thecontribution by the posting itself, W1(t), and thatby the comments, W2(t).
We assume that eachterm is associated with an ?inverted document fre-quency?, denoted by I(t) = log Nn(t) , where N isthe corpus size and n(t) is the number of docu-ments in corpus containing term t. We use a func-tion f(t, d) to denote the number of occurrences ofterm t in document d, i.e.
?term frequency?.
Thus,when the original posting and comments are eachconsidered as a document, this term frequency canbe calculated for any term in any document.
Wethus define the weight of term t in document d, bethe posting itself or a comment, using the standardTF/IDF definition (Baeza-Yates and Ribeiro-Neto,1999):w(t, d) =(0.5 + 0.5?
f(t, d)maxt?
f(t?, d))?
I(t).The weight contributed by the posting itself, d0,is thus:W1(t) = w(t, d0)maxt?
w(t?, d0).The weight contribution from the comments{d1, d2, ?
?
?
, dm} incorporates not only the lan-guage features of these documents but also theirimportance in the discussion thread.
That is, thecontribution of comment score is incorporated intoweight calculation of the words in a comment.W2(t) =m?i=1( w(t, di)maxt?
w(t?, di))?
( s(i)maxi?
s(i?
)).Such a treatment of compounded weight W (t)is essentially to recognize that readers?
impact onselecting relevant articles and the difference oftheir influence.
For each profile, we select the top-n highest weighted words to represent the topic.260With the topic profile thus constructed, the re-triever returns an ordered list of articles with de-creasing relevance to the topic.
Note that ourapproach to differentiate the importance of eachcomment can be easily incorporated into anygeneric retrieval model.
In this work, our retrieveris adopted from (Lavrenko et al, 2000).3.3 Interpretation of RecommendationSince interpreting recommended items enhancesusers?
trusting beliefs (Wang and Benbasat, 2007),we design a creative approach to generate hintsto indicate the relationship (generalization, spe-cialization and duplication) between the recom-mended articles and the original posting based onour previous work (Candan et al, 2009).Article A being more general than B can be in-terpreted as A being less constrained than B bythe keywords they contain.
Let us consider two ar-ticles, A and B, where A contains keywords, k1and k2, and B only contains k1.?
If A is said to be more general than B, thenthe additional keyword, k2, of article A mustrender A less constrained than B. Therefore,the content of A can be interpreted as k1?k2.?
If, on the other hand, A is said to be morespecific than B, then the additional keyword,k2, must render A more constrained than B.Therefore, the content of A can be interpretedas k1 ?
k2.Note that, in the two-keyword space ?k1, k2?, Acan be denoted by a vector ?aA, bA?
and B can bedenoted by ?aB, 0?.
The origin O = ?0, 0?
cor-responds to the case where an article does containneither k1 nor k2.
That is, O corresponds to anarticle which can be interpreted as ?k1 ?
?k2 ??
(k1 ?
k2).
Therefore, if A is said to be moregeneral than B, ?A = d(A,O) should be greaterthan ?B = d(B,O).
This allows us to measurethe degrees of generalization and specialization oftwo articles.
Given two articles, A and B, of thesame topic, they will have a common keywordbase, while both articles will also have their owncontent, different from their common base.
Letus denote the common part of A by Ac and com-mon part of B by Bc.
Note that ?AC and ?BCare usually unequal because the same words in thecommon part have different term weights in articleA and B respectively.
Given these and the gener-alization concept introduced above for two similararticles A and B, we can define the degree of gen-eralization (GAB) and specialization (SAB) of Bwith respect to A asGAB = ?A/?Bc, SAB = ?B/?Ac.To alleviate the effect of document length, werevise the definition asGAB = ?A/ log(?A)?Bc/ log(?A+?B) ,SAB = ?B/ log(?B)?Ac/ log(?A+?B) .The relative specialization and generalizationvalues can be used to reveal the relationships be-tween recommended articles and the original post-ing.
Given original posting A and recommendedarticle B, if GAB > ?g, for a given generalizationthreshold ?g, then B is marked as a generalization.When this is not the case, if SAB > ?s, for a givenspecialization threshold, ?s, then B is marked asa specialization.
If neither of these cases is true,then B is duplicate of A.Such an interpretation provides a control on de-livering recommended articles.
In particular, wecan filter the duplicate articles to avoid recom-mending the same information.4 Experimental EvaluationTo evaluate the effectiveness of our proposed rec-ommendation mechanism, we carry out a series ofexperiments on two synthetic data sets, collectedfrom Internet forums and blogs, respectively.
Thefirst data set is called Forum.
This data set isconstructed by randomly selecting 20 news arti-cles with corresponding reader comments from theDigg Web site and 16,718 news articles from theReuters news Web site.
This simulates the sce-nario of recommending relevant news from tradi-tional media to social media users for their furtherreading.
The second one is the Blog data set con-taining 15 blog articles with user comments and15,110 articles obtained from the Myhome Website 2.
Details of these two data sets are shown inTable 1.
For evaluation purposes, we adopt the tra-ditional pooling strategy (Zobel, 1998) and applyto the TREC data set to mark the relevant articlesfor each topic.2http://blogs.myhome.ie261Table 1: Evaluation data setSynthetic Data Set Forum BlogTopicsNo.
of postings 20 15Ave.
length of postings 676 236No.
of comments per posting 81.4 46Ave.
length of comments 45 150Target No.
of articles 16718 15110Ave.
length of articles 583 317The recommendation engine may return a set ofessentially the same articles re-posted at differentsites.
Therefore, we introduce a metric of noveltyto measure the topic diversity of returned sugges-tions.
In our experiments, we define precision andnovelty metrics asP@N = ?C ?R??R?
and D@N =?E ?R??R?
,where R is the subset of the top-n articles returnedby the recommender, C is the set of manuallytagged relevant articles, and E is the set of man-ually tagged relevant articles excluding duplicateones to the original posting.
We select the top 10articles for evaluation assuming most readers onlybrowse up to 10 recommended articles (Karypis,2001).
Meanwhile, we also utilize mean aver-age precision (MAP) and mean average novelty(MAN) to evaluate the entire set of returned ar-ticle.We test our proposal in four aspects.
First, wecompare our work to two baseline works.
We thenpresent results for some preliminary tests to findout the optimal values for two critical parameters.Next, we study the effect of user authority andits integration to comment weighting.
Fourth, weevaluate the performance gain obtained from inter-preting recommendation.
In addition, we providea significance test to show that the observed differ-ences in effectiveness for different approaches arenot incidental.
In particular, we use the t-test here,which is commonly used for significance tests ininformation retrieval experiments (Hull, 1993).4.1 Overall PerformanceAs baseline proposals, we also implement twowell-known content-based recommendation meth-ods (Bogers and Bosch, 2007).
The first method,Okapi, is commonly applied as a representa-tive of the classic probabilistic model for rele-vant information retrieval (Robertson and Walker,1994).
The second one, LM, is based on statisti-cal language models for relevant information re-trieval (Ponte and Croft, 1998).
It builds a proba-Table 2: Overall performancePrecision NoveltyData Method P@10 MAP D@10 MANForumOkapi 0.827 0.833 0.807 0.751LM 0.804 0.833 0.807 0.731Our 0.967 0.967 0.9 0.85BlogOkapi 0.733 0.651 0.667 0.466LM 0.767 0.718 0.70 0.524Our 0.933 0.894 0.867 0.756bilistic language model for each article, and ranksthem on query likelihood, i.e.
the probability of themodel generating the query.
Following the strat-egy of Bogers and Bosch, relevant articles are se-lected based on the title and the first 10 sentencesof the original postings.
This is because articlesare organized in the so-called inverted pyramidstyle, meaning that the most important informa-tion is usually placed at the beginning.
Trimmingthe rest of an article would usually remove rela-tively less crucial information, which speeds upthe recommendation process.A paired t-test shows that using P@10 andD@10 as performance measures, our approachperforms significantly better than the baselinemethods for both Forum and Blog data sets asshown in Table 2.
In addition, we conduct t-testsusing MAP and MAN as performance measures,respectively, and the p-values of these tests are allless than 0.05, meaning that the results of experi-ments are statistically significant.
We believe thatsuch gains are introduced by the additional infor-mation from the collective wisdom, i.e.
user au-thority and comments.
Note that the retrieval pre-cision for Blog of two baseline methods is not asgood as that for Forum.
Our explanation is thatblog articles may not be organized in the invertedpyramid style as strictly as news forum articles.4.2 Parameters of Topic ProfileThere are two important parameters to be consid-ered to construct topic profiles for recommenda-tion.
1) the number of the most weighted wordsto represent the topic, and 2) combination coeffi-cient ?
to determine the contribution of originalposting and comments in selecting relevant arti-cles.We conduct a series of experiments and findout that the optimal performance is obtained whenthe number of words is between 50 and 70, and?
is between 0.65 and 0.75.
When ?
is set to 0,the recommended articles only reflect the author?sopinion.
When ?
= 1, the suggested articles rep-resent the concerns of readers exclusively.
In the262Table 3: Performance of four runsPrecision NoveltyMethod P@10 MAP D@10 MANForumRUN1 0.88 0.869 0.853 0.794RUN2 0.933 0.911 0.9 0.814RUN3 0.94 0.932 0.9 0.848RUN4 0.967 0.967 0.9 0.85BlogRUN1 0.767 0.758 0.7 0.574RUN2 0.867 0.828 0.833 0.739RUN3 0.9 0.858 0.833 0.728RUN4 0.933 0.894 0.867 0.756following experiments, we set topic word numberto 60 and combination coefficient ?
to 0.7.4.3 Effect of Authority and CommentsIn this part, we explore the contribution of userauthority and comments in social media recom-mender.
In particular, we study the following sce-narios with increasing system capabilities.
Notethat, lacking friend information (Section 3.1.2) inthe Forum data set, fi,j is set to zero.?
RUN 1 (Posting): the topic profile is con-structed only based on the original postingitself.
This is analogous to traditional rec-ommenders which only consider the focus ofauthors for suggesting further readings.?
RUN 2 (Posting+Authority): the topic profileis constructed based on the original postingand participant authority.?
RUN 3 (Posting+Comment): the topic profileis constructed based on the original postingand its comments.?
RUN 4 (All): the topic profile is constructedbased on the original posting, user authority,and its comments.Here, we set ?1 = ?2 = ?3 = 1.
Our t-testshows that using P@10 and D@10 as performancemeasures, RUN4 performs best in both Forum andBlog data sets as shown in Table 3.
There is a step-wise performance improvement while integratinguser authority, comments and both.
With the as-sistance of user authority and comments, the rec-ommendation precision is improved up to 9.8%and 21.6% for Forum and Blog, respectively.
Theopinion of readers is an effective complementarityto the authors?
view in suggesting relevant infor-mation for further reading.Moreover, we investigate the effect of the se-mantic and structural relations among comments,i.e.
semantic similarity, reply, and quotation.
Forthis purpose, we carry out a series of experimentsbased on different combinations of these relations.CR RR QR CQR CRR QRR AllMAP0.60.70.80.91.0 Forum Data SetBlog Data SetFigure 3: Effect of content, quotation and replyrelation?
Content Relation (CR): only the content rela-tion matrix is used in scoring the comments.?
Quotation Relation (QR): only the quotationrelation matrix is used in scoring the com-ments.?
Reply Relation (RR): only the reply relationmatrix is used in scoring the comments.?
Content+Quotation Relation (CQR): both thecontent and quotation relation matrices isused in scoring the comments.?
Content+Reply Relation(CRR): both the con-tent and reply relation matrices are used inscoring the comments.?
Quotation+Reply Relation (QRR): both thequotation and reply relation matrices are usedin scoring the comments.?
All: all three matrices are used.The MAP yielded by these combinations forboth data sets is plotted in Figure 3.
For the case ofForum, we observe that incorporating content in-formation adversely affects recommendation pre-cision.
This concurs with what we saw in our pre-vious work (Wang et al, 2010).
On the other hand,when we test the Blog data set, the trend is the op-posite, i.e.
content similarity does contribute to re-trieval performance positively.
This is attributedby the text characteristics of these two forms ofsocial media.
Specifically, comments in news fo-rums usually carry much richer structural informa-tion than blogs where comments are usually ?flat?among themselves.4.4 Recommendation InterpretationTo evaluate the precision of interpreting the re-lationship between recommended articles and the263original posting, the evaluation metric of successrate S is defined asS =m?i=1(1?
ei)/m,where m is the number of recommended articles,ei is the error weight of recommended article i.Here, the error weight is set to one if the resultinterpretation is mis-labelled.From our studies, we observe that the successrate at top-10 is around 89.3% and 87.5% for theForum and Blog data sets, respectively.
Note thatthese rates include the errors introduced by the ir-relevant articles returned by the retrieval module.To estimate optimal thresholds of generalizationand specialization, we calculate the success rate atdifferent threshold values and find that neither toosmall nor too large a value is appropriate for inter-pretation.
In our experiments, we set generaliza-tion threshold ?g to 3.2 and specialization thresh-old ?s to 1.8 for the Forum data set, and ?g to 3.5and ?s to 2.0 for Blog.
Ideally, threshold valueswould need to be set through a machine learningprocess, which identifies proper values based on agiven training sample.5 Conclusion and Future WorkThe Web has become a platform for social net-working, in addition to information disseminationat its earlier stage.
Many of its applications arealso being extended in this fashion.
Traditionalrecommendation is essentially a push service toprovide information according to the profile of in-dividual or groups of users.
Its niche at the Web2.0 era lies in its ability to enable online discus-sion by serving up relevant references to the par-ticipants.
In this work, we present a framework forinformation recommendation in such social mediaas Internet forums and blogs.
This model incor-porates information of user status and commentsemantics and structures within the entire discus-sion thread.
This framework models the logic con-nections among readers and the innovativeness ofcomments.
By combining such information withtraditional statistical language models, it is capa-ble of suggesting relevant articles that meet the dy-namic nature of a discussion in social media.
Oneimportant discovery from this work is that, whenintegrating comment contents, the structural infor-mation among comments, and reader relationship,it is crucial to distinguish the characteristics of var-ious forms of social media.
The reason is that therole that the semantic content of a comment playscan differ from one form to another.This study can be extended in a few interest-ing ways.
For example, we can also evaluate itseffectiveness and costs during the operation of adiscussion forum, where the discussion thread iscontinually updated by new comments and votes.Indeed, its power is yet to be further improved andinvestigated.AcknowledgmentsLi?s research is supported by National Natural Sci-ence Foundation of China (Grant No.60803106),the Scientific Research Foundation for the Re-turned Overseas Chinese Scholars, State Educa-tion Ministry, and the Fok Ying-Tong EducationFoundation for Young Teachers in the Higher Ed-ucation Institutions of China.
Research of Chenis supported by Natural Science and EngineeringCouncil (NSERC) of Canada.ReferencesNitin Agarwal, Magdiel Galan, Huan Liu, and ShankarSubramanya.
2010.
Wiscoll: Collective wis-dom based blog clustering.
Information Sciences,180(1):39?61.Jae-wook Ahn, Peter Brusilovsky, Jonathan Grady,Daqing He, and Sue Yeon Syn.
2007.
Open userprofiles for adaptive news systems: help or harm?In Proceedings of the 16th International Conferenceon World Wide Web (WWW), pages 11?20.James Allan, Victor Lavrenko, and Russell Swan.2002.
Explorations within topic tracking and detec-tion.
Topic detection and tracking: event-based in-formation organization Kluwer Academic Publish-ers, pages 197?224.Ricardo Baeza-Yates and Berthier Ribeiro-Neto.
1999.Modern information retrieval.
Addison WesleyLongman Publisher.Toine Bogers and Antal Bosch.
2007.
Comparing andevaluating information retrieval algorithms for newsrecommendation.
In Proceedings of 2007 ACM con-ference on Recommender Systems, pages 141?144.Sergey Brin and Lawrence Page.
1998.
Theanatomy of a large-scale hypertextual web searchengine.
Computer networks and ISDN systems,30(1-7):107?117.K.
Selc?uk Candan, Mehmet E. Do?nderler, Terri Hedg-peth, Jong Wook Kim, Qing Li, and Maria LuisaSapino.
2009.
SEA: Segment-enrich-annotateparadigm for adapting dialog-based content for im-proved accessibility.
ACM Transactions on Informa-tion Systems (TOIS), 27(3):1?45.264Ivan Cantador, Alejandro Bellogin, and Pablo Castells.2008.
Ontology-based personalized and context-aware recommendations of news items.
In Pro-ceedings of IEEE/WIC/ACM international Confer-ence on Web Intelligence and Intelligent Agent Tech-nology (WI), pages 562?565.Jung-Hsien Chiang and Yan-Cheng Chen.
2004.
Anintelligent news recommender agent for filtering andcategorizing large volumes of text corpus.
Inter-national Journal of Intelligent Systems, 19(3):201?216.Mark Claypool, Anuja Gokhale, Tim Miranda, PavelMurnikov, Dmitry Netes, and Matthew Sartin.
1999.Combining content-based and collaborative filters inan online newspaper.
In Proceedings of the ACMSIGIR Workshop on Recommender Systems.Abhinandan S. Das, Mayur Datar, Ashutosh Garg, andShyam Rajaram.
2007.
Google news personaliza-tion: scalable online collaborative filtering.
In Pro-ceedings of the 16th International Conference onWorld Wide Web (WWW), pages 271?280.Gianna M. Del Corso, Antonio Gull?
?, and FrancescoRomani.
2005.
Ranking a stream of news.
InProceedings of the 14th International Conference onWorld Wide Web(WWW), pages 97?106.Kyumars Sheykh Esmaili, Mahmood Neshati, MohsenJamali, Hassan Abolhassani, and Jafar Habibi.2006.
Comparing performance of recommendationtechniques in the blogsphere.
In ECAI 2006 Work-shop on Recommender Systems.Conor Hayes, Paolo Avesani, and Uldis Bojars.
2007.An analysis of bloggers, topics and tags for a blogrecommender system.
In Workshop on Web Mining(WebMine), pages 1?20.Meishan Hu, Aixin Sun, and Ee-Peng Lim.
2007.Comments-oriented blog summarization by sen-tence extraction.
In Proceedings of the sixteenthACM Conference on Conference on Information andKnowledge Management(CIKM), pages 901?904.David Hull.
1993.
Using statistical testing in the eval-uation of retrieval experiments.
In Proceedings ofthe 16th Annual International ACM SIGIR Confer-ence on Research and Development in InformationRetrieval, pages 329?338.George Karypis.
2001.
Evaluation of item-based Top-N recommendation algorithms.
In Proceedings ofthe 10th International Conference on Informationand Knowledge Management (CIKM), pages 247?254.Hung-Jen Lai, Ting-Peng Liang, and Yi Cheng Ku.2003.
Customized internet news services based oncustomer profiles.
In Proceedings of the 5th Interna-tional Conference on Electronic commerce (ICEC),pages 225?229.Victor Lavrenko and W. Bruce Croft.
2001.
Rele-vance based language models.
In Proceedings ofthe 24th Annual International ACM SIGIR Confer-ence on Research and Development in InformationRetrieval, pages 120?127.Victor Lavrenko, Matt Schmill, Dawn Lawrie, PaulOgilvie, David Jensen, and James Allan.
2000.Language models for financial news recommenda-tion.
In Proceedings of the 9th International Confer-ence on Information and Knowledge Management(CIKM), pages 389?396.Hong Joo Lee and Sung Joo Park.
2007.
MONERS:A news recommender for the mobile web.
ExpertSystems with Applications, 32(1):143?150.Tim Leek, Richard Schwartz, and Srinivasa Sista.2002.
Probabilistic approaches to topic detectionand tracking.
Topic detection and tracking: event-based information organization, pages 67?83.Yung-Ming Li and Ching-Wen Chen.
2009.
A synthet-ical approach for blog recommendation: Combiningtrust, social relation, and semantic analysis.
ExpertSystems with Applications, 36(3):6536 ?
6547.Jay Michael Ponte and William Bruce Croft.
1998.A language modeling approach to information re-trieval.
In Proceedings of the 21st Annual Interna-tional ACM SIGIR Conference on Research and De-velopment in Information Retrieval, pages 275?281.Jing Qiu, Lejian Liao, and Peng Li.
2009.
Newsrecommender system based on topic detection andtracking.
In Proceedings of the 4th Rough Sets andKnowledge Technology.Stephen E. Robertson and Stephen G Walker.
1994.Some simple effective approximations to the 2-poisson model for probabilistic weighted retrieval.In Proceedings of the 17th ACM SIGIR conferenceon Research and Development in Information Re-trieval, pages 232?241.Weiquan Wang and Izak Benbasat.
2007.
Recommen-dation agents for electronic commerce: Effects ofexplanation facilities on trusting beliefs.
Journal ofManagement Information Systems, 23(4):217?246.Jia Wang, Qing Li, and Yuanzhu Peter Chen.
2010.User comments for news recommendation in socialmedia.
In Proceedings of the 33rd ACM SIGIR Con-ference on Research and Development in Informa-tion Retrieval, pages 295?296.Yiming Yang, Jaime Guillermo Carbonell, Ralf D.Brown, Thomas Pierce, Brian T. Archibald, and XinLiu.
1999.
Learning approaches for detecting andtracking news events.
IEEE Intelligent Systems,14(4):32?43.Justin Zobel.
1998.
How reliable are the results oflarge-scale information retrieval experiments?
InProceedings of the 21st International ACM SIGIRConference on Research and Development in Infor-mation Retrieval, pages 307?314.265
