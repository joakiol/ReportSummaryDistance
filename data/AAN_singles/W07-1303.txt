Proceedings of Ninth Meeting of the ACL Special Interest Group in Computational Morphology and Phonology, pages 15?22,Prague, June 2007. c?2007 Association for Computational LinguisticsBayesian Identiation of Cognates and CorrespondenesT.
Mark EllisonLinguistis, University of Western Australia,and Analith Ltdmarkmarkellison.netAbstratThis paper presents a Bayesian approahtoomparing languages: identifyingog-nates and the regularorrespondenesthatompose them.
A simple model oflanguage is extended to inlude these no-tions in an aount of parent languages.An expression is developed for the pos-terior probability ofhild language formsgiven a parent language.
Bayes' Theo-rem oers a shema for evaluatinghoiesofognates andorrespondenes to ex-plain semantially mathed data.
An im-plementation optimising this value withgradient desent is shown to distinguishognates from non-ognates in data fromPolish and Russian.Modern historial linguistis addresses ques-tions like the following.
How did languageoriginate?
What were historially-reorded lan-guages like?
How related are languages?
Whatwere the anestors of modern languages like?Reently,omputation has beome a key tool inaddressing suh questions.Kirby (2002) gives an overview ofurrentur-rent work on how language evolved, muh of itbased onomputational models and simulations.Ellison (1992) presents a linguistially motivatedmethod forlassifyingonsonants asonsonantsor vowels.
An unexpeted result for the deadlanguage Gothiprovides added weight to oneof twoompeting phonologial interpretations ofthe orthography of this dead language.Other reent work has appliedomputationalmethods for phylogenetis to measuring linguis-tidistanes, and/oronstruting taxonomitrees from distanes between languages and di-alets (Dyen et al, 1992; Ringe et al, 2002; Grayand Atkinson, 2003; MMahon and MMahon,2003; Nakleh et al, 2005; Ellison and Kirby,2006).Aentral fous of historial linguistis is thereonstrution of parent languages from the ev-idene of their desendents.
In historial lin-guistis proper, this is done by theompara-tive method (Jeers and Lehiste, 1989; Hok,1991) in whih shared arbitrary struture is as-sumed to reetommon origin.
At the phono-logial level, reonstrution identiesognatesandorrespondenes, and thenonstruts soundhanges whih explain them.This paper presents a Bayesian approah toassessingognates andorrespondenes.
Bestsets ofognates andorrespondenesan thenbe identied by gradient asent on this evalua-tion measure.
While the work is motivated bythe eventual goal of oering software solutionsto historial linguistis, it also hopes to showthat Bayes' theorem applied to an expliit, sim-ple model of languagean lead to a prinipledand tratable method for identifyingognates.The struture of the paper is as follows.
Thenext setion details the notions of historial lin-guistis needed for this paper.
Setion 2 for-mally denes a model of language and parentlanguage.
The subsequent setion situates thework amongst similar work in the literature,15making use ofonepts desribed in the earliersetions.
Setion 4 desribes thealulation ofthe probability of wordlist data given a hypoth-esised parent language.
This isombined withBayes' theorem and gradient searh in an algo-rithm to nd the best parent language for thedata.
Setion 5 desribes the results of apply-ing an implementation of the algorithm to datafrom Polish and Russian.
The nal setion sum-marises the paper and suggests further work.1 Cognates, Correspondenes andReonstrutionIn the neo-Grammarian model of languagehange, a population speaking a uniform lan-guage divides, and then the two populations un-dergo separate languagehanges.Word forms withontinuous histories in re-spetive daughter languages desending whihfrom aommon word-form anestor arealledognate, no matter what has happened to theirsemantis.
Cognate word forms may have un-dergone deformations to make them less simi-lar to eah other, these deformations resultingfrom regular, phonologialhanges.
Note thatin the elds of applied linguistis, seond lan-guage aquisition, and mahine translation, thetermognate is used to mean any words that arephonologially similar to eah other.
This is notthe sense meant here.Phonologialhange produes modiationsto the segmental inventory, replaing one seg-ment by another in all or only someontexts.This sometimes has the eet ofollapsing seg-ment types together.
Otherhanges may di-vide one segment type into two, depending onaontextualondition.
The relation of parent-language segments to daughter-language seg-ments is, usually, a many-to-many relation.Parent-hild segmental relations are reetedin theorrespondenes between segment in-ventories in the daughter languages.
Cor-respondenes are pairings of segments fromdaughter languages whih have derived fromaommon parent segment.
For example, pin Latin frequentlyorresponds to f in En-glish, as in words like pater and father.
Bothsegments have developed from a (postulated)Proto-IndoEuropean *p. Beauseorrespon-denes only our betweenognates, identify-ing the two is often a bootstrap proess:or-ralingognates helps nd moreorrespondenes,and forms sharing a numberorrespondenes areprobablyognate.2 Formal StruturesThe method presented in this paper is based ona formal model of language.
This is desribed insetion 2.1.
The subsequent setion extends themodel to dene a parent language, whose seg-mental inventory isorrespondenes and whoselexion isognates linking two desendent lan-guages.2.1 Language modelThe language model is based on three assump-tions.Assumption 1 There is a universal, disreteset M of meanings.Assumption 2 A language L has its own set ofsegments ?
(L).Assumption 3 The lexion ?
of a language L isa partial map of meanings to strings of segments?
: M ?
?
(L)?.On the basis of these assumptions, wean de-ne a language L to be a triple (M,?
(L), ?
(L))of meanings, segments and mappings from mean-ings onto strings of segments.For example,onsider written Polish.
Theset of meaningsontainsonepts as to take-perfet-innitive, tree-nominative-singular,and so on.
The segmental inventoryontainsthe 32 segments a a bd e e f g h i j k ll m n n o o p r s s t u w y zz z, ignoringapitalisation.
The lexion mathes meanings tostrings of segments, to take-perfet-innitiveto wzia, tree-nominative-singular to drzewo.2.2 Parent language modelDenition 1 A degree-(u, v)orrespondenebetween L1 and L2 is a pair of strings (s, t) ??
(L1) ?
?
(L2) over the segments of L1 and L216respetively, with lengths at least u and no morethan v.As an example of aorrespondene,onsiderthe pair of small strings from Polish and Russian,(,??).
This is a degree-(1, 2)orrespondenebeause its members have lengths as low as oneand as high as two.
It is also a degree-(u, v)orrespondene for any u ?
1 and v ?
2.Anyorrespondenean be mapped onto itsomponents by projetion funtions.Denition 2 The projetions pi1 and pi2 mapaorrespondene (s, t) onto its rst pi1(s, t) = sor seond pi2(s, t) = tomponent string respe-tively.The rst projetion funtion will map (,??
)onto , while the seond maps (,??)
onto ?
?.Correspondenesan be formed into strings.These strings also have projetions.Denition 3 The projetions pi1 and pi2 mapa string oforrespondenes c1..ck onto theon-atenation of the projetions of eahorrespon-dene.pi1(c1..ck) = pi1(c1)pi1(c2)..pi1(ck),pi2(c1..ck) = pi2(c1)pi2(c2)..pi2(ck)Suppose we sequene fourorrespondenesinto the string (w,?)(z,?
)(ia,?)(,??).
Thisstring has rst and seond projetions, wziaand ????
?, formed byonatenating the respe-tive projetions of eahorrespondene.Wean now dene a parent language.Denition 4 A degree-(u, v) parent L0 of twolanguages L1, L2 is a triple (M,?
(L0), ?
(L0))where ?
(L0) is a set of degree-(u, v)orrespon-denes between L1 and L2, exluding the pair ofnull strings, and ?
(L0) is a partial mapping fromM onto ?
(L0) whih obeyspi1 ?
?
(L0) ?
?
(L1), pi2 ?
?
(L0) ?
?
(L2)Theirle stands for funtionomposition.Continuing our past example, we will fouson the two meanings to take-perfet-innitiveand tree-nominative-singular.
The segment in-ventory for the parent languageontains degree-(0, 2)orrespondenes: (,?
), (,??
), (d,?),(e,?
), (ia,?
), (o,?
), (rz,?
), (w,?
), (z,?).
Thelexial funtion maps to take-perfet-innitiveonto the string oforrespondenes (w,?)
(z,?
)(ia,?)
(,??)
while tree-nominative-singularmaps to (d,?)
(,?)
(rz,?)
(e,?)
(w,?)
(o,?
).The parent languageondition is veried byheking the projetions of the twoorrespon-dene strings.
The rst string has proje-tions wziaand ????
?, whih are forms forthe meaning to take-perfet-innitive in Pol-ish and Russian respetively.
The seond stringhas projetions drzewo and ?????
?, whih areforms for the meaning tree-nominative-singularin Polish and Russian respetively.
So the pro-jetionondition is satised.
If the lexial fun-tion is only dened on these two meanings, thenthis is a valid parent language.It is worth emphasising that the projetionondition for qualifying as a parent language ap-plies only for those meanings for whih the par-ent lexial mapping is dened.
Theorrespond-ing forms in thehild languages are said to beognate in this model.
Where no parent formis reonstruted, the forms are notognate, andare to be aounted for in some way other thanthe parent language.3 Related WorkTheurrent work is, ofourse, far from the rstto seek to identifyognates and/ororrespon-denes.
Here is an abbreviated overview of pre-vious work in the eld1.
More detailed surveysan be found inhapter 3 of Kondrak's (2002)PhD thesis or Lowe's online survey2of prior artin this eld.In perhaps the rstomputational work onhistorial linguistis, Kay (1964) desribed an al-gorithm for determiningorrespondenes givena list ofognate pairs aross two daughter lan-guages.
His method seeks to nd the smallest set1An anonymous reviewer suggests that theurrentwork shares features with that of Kessler (2001).
I havebeen unable to aess this book in time to inlude dis-ussion of it in this paper.2linguistis.berkeley.edu/?
jblowe/REWWW/PriorArt.html17oforrespondenes whih allows a degree-(1,?
)alignment for eahognate pair.
Unfortunately,theomplexity of the problem has preluded itsappliation to signiant daa sets.Frantz (1970) developed a PL/1 programmingwhih returned numerial evaluations oforre-spondenes andognay, given a list of possi-bleognate word-pairs.
Eah word pair must besupplied as a degree-(0, 1) reonstrution, thatis, aligning single segments with eah other orwith gaps.Guy (1984; 1994) presented a programalledCOGNATE whih nds regularorrespondenesand identiesognates using statistial teh-niques.For his Master's, Broza (1998) developedMDL-based softwarealledandid whih identi-esorrespondenes fromognates and expressesthese asontextual phonologial transformationrules.Kondrak's (2002) dotoral dissertationom-bines phonologial and semantisimilarity meth-ods withorrespondane-learning.
The algo-rithms for learningorrespondenes are takenfrom Melamed's (2000) probabilistimethodsfor identifying word-word translation equiva-lene.
These methods, like theurrent work,are Bayesian.
Beause Melamed's problem seekspartial rather thanomplete explanation of theinputs in terms oforrespondenes, the math-ing problem is somewhat more diult theoret-ially.
As a result, he does not arrive at the de-omposition of the sum of the probability of twoinputs given the set of possibleorrespondenes,approximating this with a high probability align-ment.4 Conditional Probability of theDataTheore of any Bayesian model is theondi-tional probability of the data given the hypoth-esis.
This setion details how probabilities as-signed to data, and the assumptions on whihthis assignment is based.The data is the mapping of meanings ontoforms in two daughter languages.
If those twolanguages are L1 and L2, we want to determineP (?
(L1), ?(L2)|h).
The nature of h will be dis-ussed in setion 4.6.For brevity, we will write ?i for ?
(Li).4.1 Meaning independeneThe rst step in dening theonditional prob-ability of the data is to deompose it intomeaning-by-meaning probabilities.
Thisan beahieved by adopting the following two assump-tions.Assumption 4 In a given language, the formsfor dierent meanings are seleted indepen-dently.This assumption states that within a singlelanguagehoosing, for example, a form wziafor meaning to take-perfet-innitive is no helpin prediting the form whih expresses tree-nominative-singular.Assumption 5 Aross dierent languages, theformsorresponding to dierent meanings areindependent.Aording to this assumption, the Polish wordwziaand the Russian word ????
?an bestruturally dependent beause they express thesame meaning.
Inontrast, wean only ex-pet ahane relationship between the Rus-sian word ?????
meaning to take-perfet-innitive, and the Polish word drzewo express-ing tree-nominative-singular.Together, these two assumptions imply thatthe only dependenies possible between any fourforms expressing the two meanings m1 and m2 intwo languages L1 and L2 are between ?
(m1) and?
(m1) on the one hand and ?
(m2) and ?
(m2) onthe other.Consequently the probability of generating theword forms in two languagesan be deomposedinto the produt of generating the two language-partiular forms for eah meaning.P (?1, ?2|h) =?m?MP (?1(m), ?2(m)|h)184.2 Cognay and independeneThe next assumption holds that struturalor-relation betweenorresponding forms should beexplained as resulting fromognay.Assumption 6 Aross dierent languages,formsorresponding to the same meaning aredependent only if the forms areognate.If the words for a partiular meaning do notderive from aommon anestral form, then theyare unorrelated.
To return to our Polish andRussian examples, wean expet dependeniesin struture between theognate words drzewoand ??????.
But we should expet no suhor-relation in the non-ognate pair pomaranzaand ????????
meaning orange-nominative-singular.Let us write Mi for the domain of the lexialfuntion in language Li.
This is the set of mean-ings for whih this language has dened a wordform.
The set ofognates is the domain of thelexial funtion of the parent language, M0.
Wean deompose the evidential words into threesets: M0 ofognates, M1 \M0 of meanings onlyexpressed in language L1, and M2 \M0 of mean-ings only expressed in language L2.
Words in theseond and thirdategories are non-ognate, andso probabilistially independent of eah other.Theonditional probability of the dataanthus be expressed as follows.P (?1, ?2|h) =?m?M0P (?1(m), ?2(m)|h)?m?M1\M0P (?1(m)|h)?m?M2\M0P (?2(m)|h)4.3 Probability of a wordWe now turn to the probability of generating astring in a language.
The rst assumption de-nes the distribution over word-length.Assumption 7 The probability of a word hav-ing a partiular length is negative exponential inthat length.The seond assumption allows segment prob-ability to depend only on the segment identity,and not on its neighbourhood.Assumption 8 Segmenthoie isontext-independent.These two assumptions together imply thatthe probability of strings is determined by a xeddistribution over ?
(Li) ?
{#}, where # is anend-of-word marker.
For the desendent lan-guages, this distributionan be taken as the rela-tive frequenies of the segments and end-of-wordmarker.
Denote this distribution for language Liby fi.The probability of generating a word in a lan-guage, given relative frequenies fi, is the prod-ut of the relative frequenies for eah lettern inthe word, multiplied by the relative frequeny ofthe end-of-word marker.P (?i(m)|h) = fi(#)?a?
?i(m)fi(a)Note that this expression only holds for wordsthat are independent of all others, suh asom-ponents of non-ognate pairs.4.4 Probability of generating aognatepairThe probability of generating aognate pair ofwords is similar to the above, beause desen-dent forms are deterministially derivable fromthe parent forms.
If (?1(m), ?2(m)) are a pair ofognates derived from an anestral form ?0(m),then there is unit probability that the desen-dent forms are what they are given the parent:P (?1(m), ?2(m)|?0(m)) = 1.Sine aognate pair is derivable from a par-ent form, the probability of aognate pair isthe sum of the probabilities of all parent formswhih will generate the two desendents.
WriteW (m) = W (?1(m), ?2(m)) for the set of pos-sibleorrespondene strings in the parent whihprojet onto wordforms ?1(m) and ?2(m).
Thenthe probability of the word pair is given by:P (?1(m), ?2(m)|h) =?s?W (m)P (?0(m) = s|h)The summation poses a slight problem, however.How do we sum over all possible strings withgiven projetions?
Fortunately, wean deom-pose the summation.
Start by reognising that19the parent language is also a language, and sothe probability of forms in the language is de-termined by a distribution over segments  inthisaseorrespondenes  and the end-of-wordmarker.
Foronsisteny, weall this distributionf0.The only parent form whih projets onto twoempty strings is the empty string,onsistingonly of the end-of-word marker.
For brevity,we will drop the lambdas, writing P (x, y|h) forP (?1(m) = x, ?2(m) = y|h)P (0, 0|h) = f0(#)We assume, without loss of generality, thatthe segmental inventory of the parent languageonsists of all degree-(u, v)orrespondenes be-tween L1 and L2.
Parent segments whih arenever usedan be exluded by giving them zerorelative frequeny in f0.The funtion Pre(s;u, v) returns the set of bi-nary divisions (a, b) of the string s, suh that thelength of the rst part a is at least u and at mostv.Pre(s;u, v) = {(a, b)|ab = s,m ?
|a| ?
n}With this funtion, wean reursively dene afuntion W (s, t;u, v) on pairs of strings (s, t)whih returns the set of all degree-(u, v) parentlanguage strings whih projet onto s and t. Forbrevity, we will treat all u, v arguments as im-pliit.W (0, 0) = {0}By denition, the only parent language stringwhihan map onto the empty string in bothdesendents is the empty string.The reursive step breaks the strings s andt into all possible prexes a and c respetively.Theorrespondene (a, c) is then preposed on allstrings returned by W when it is applied to theremainders of s and t.W (s, t) =?(a,b)?Pre(s)?
(c,d)?Pre(t)(a, c)W (b, d)Note that this is the set W (m) we dened earlier.W (m) = W (?1(m), ?2(m);u, v)The reursive denition of W in terms of dis-joint unions andonatenationan be trans-formed into a reursive denition for the proba-bility P0(s, t|h) ofonstruting a member of theset.
Disjoint union is replaed by summation,onatenation by produt.
The probability ofan individualorrespondene (a, c) is its (un-known) relative frequeny f0(a, c) in the parentlanguage.
One again, we hide the impliit u, vparameters.P0(0, 0|h) = f0(#)P0(s, t|h) =?(a,b)?Pre(s)?
(c,d)?Pre(t)f0(a, c)P (b, d|h)4.5 Probability of a form-pairWe now have the piees to speify the probabil-ity of nding any partiular form as the form-pair for the desendent languages.
The prob-ability of the pair in thease ofognay isP0(?1(m), ?2(m)|h).
If the pair are notognate,then they are independent, and their probabil-ity is P1(?1(m))P2(?2(m)|h).
If we write c(m|h)for the likelihood that the pair isognate, weanombine these two values to given a totalprobability of the two forms.P0(?1(m), ?2(m)|h)c(m|h)+P1(?1(m))P2(?2(m)|h)(1.0 ?
c(m|h))Beause the word-pairs are independent (as-sumption 4), the produt of the above probabil-ity for eah meaning m gives the probability ofthe data given the hypothesis.4.6 HypothesisOne burning question remains, however.
Whatis the hypothesis?
The simple answer is that itis exatly those free variables in the speiationof the probability of the dataThere were two groups of unknowns in theprobability of the data.
The rst is the rela-tive frequeny f0 assigned toorrespondenes inparent-language forms.
The seond is the like-lihood ofognay c, a vetor of values betweenzero and one indexed by meanings.A hypothesis is therefore any setting of valuesfor the pair of vetors (f, c).20Note that while the degree variables u, v werenot xed in the above derivation, they will beheldonstant for any partiular searh, and thusdo not dene a dimension in the hypothesisspae.4.7 SearhIn this setion, we have derived P (D|h), the like-lihood of our data given a hypothesis.For simpliity, wehoose a at prior over hy-potheses, rendering the MAP Bayesian approahan instane of maximum likelihood determina-tion.
The value for the likelihood is dierentiablein eah of the parameters.
Consequently, gradi-ent desentan be used to nd the hypothesiswhih maximises the probability of the data.5 ResultsInonstruting the method, we made a numberof assumptions about independene of forms.
Itis sensible that for testing, the method is appliedto data thatonforms reasonably well to theseassumptions.
The alternative is to apply it todata whihontradits its fundamental assump-tions,onsequently hampering its eetiveness.5.1 The dataPolish and Russian werehosen to provide thedata beause they approximately obey assump-tion 6: words have dependent strutures if andonly if they areognate.
For our two lan-guages, this means that borrowings fromom-mon soures are unommon (numbering 45 inour data set), at least inomparison with thenumber ofognates (numbering 156).The data was harvested from two onlineditionaries (Wordgumbo, 2007a; Wordgumbo,2007b), one English-Polish, the other English-Russian.
Multiple translations were simplied,with the shortest translation retained.
The En-glish glosses were used as the meanings for thewords.
Where the glossontained aapital let-ter, indiating a proper noun, this was elimi-nated from the data.The data should alsoonform to assumption4, that words for dierent meanings with a lan-guage are independent.
So where two meaningsin the data sets were realised with the same form,these meanings were deemed to be struturallydependent, and so only the rst was retained inthe wordlist.The remaining dataontains 407 alignedPolish-Russian word pairs.Polish and Russian both use a great deal ofderivational and inetional morphology.
Thesimple language model used here does not takethis into aount, so this will be a disturbinginuene on the results.5.2 EvaluationThe aligned wordlists were hand-tagged asog-nate,ommon borrowing or non-ognate.
A per-missive rule ofognay was used: if the rootsof words in the two languages wereognate,they wereognate, even if represented with non-ognate derivational and/or inetional mor-phology.Figure 1 shows the evaluation of the program'sperformane on the data.Borrowings as:ognates non-ognatesFound f 162 119Missed m 41 37Errant e 6 49Auray f/(f + e) 96% 71%Reall f/(f + m) 81% 76%Figure 1: Evaluation of program performaneon 407 meaning-mathed pairs of Polish-Russianwords.
Common borrowings are sored asog-nates in the rstolumn, non-ognates in theseond.The sores show that the method works wellin identifyingognates, partiularly ifommonborrowings are aepted asognates, or exludedmanually.
Ifommon borrowings are sored asnon-ognates, then the auray falls.Of theorrespondenes found between Polishand Russian, 67 have a phonologial basis.
Theremaining 27 result from mismath morphologyinognates or dierenes inommon borrowings.6 ConlusionThis paper has presented a model of languagewhih allows thealulation of the posteriorprobability of forms arising in theases where21they areognate, and where they are not.
Bayes'theorem relates these probabilities to the poste-rior likelihood of partiularorrespondenes andognay relationships.
Gradient desentan beused to searh this spae for the best distributionoverorrespondenes, and bestognay evalua-tions for meaning-paired words.
The appliationto data from Polish and Russian shows remark-able suess identifying bothognates and non-ognates.Future work will proeed by relaxingon-straints on the parent language.
The parent in-ventory will be widened to inlude multisegmentorrespondenes.
Multiple parent languages willbe permitted, to the end of separating borrow-ings fromognates.
Finally, riher models oflanguage, inorporating syllable struture, willallow more information to identifyognates.ReferenesGil Broza.
1998.
Inter-language regularity: thetransformation learning problem.
Master's thesis,Institute of Computer Siene, Hebrew Universityof Jerusalem, Otober.Isidore Dyen, Joseph B. Kruskal, and Paul Blak.1992.
An Indo-Europeanlassiation: a lexio-statistial experiment.
Transations of the Amer-ian Philosophial Soiety, 82(5).T.
Mark Ellison and Simon Kirby.
2006.
Measuringlanguage divergene by intra-lexialomparison.In ACL, pages 273280, Sydney.T.
Mark Ellison.
1992.
The Mahine Learning ofPhonologial Struture.
Ph.D. thesis, Universityof Western Australia.Donald G. Frantz.
1970.
A PL/1 program to assisttheomparative linguist.
Communiations of theACM, 13(6):353356.Russell D. Gray and Quentin D. Atkinson.
2003.Language-tree divergene times support the ana-tolian theory of indo-european origin.
Nature,426:435439.Jaques B. M. Guy.
1984.
An algorithm for identi-fyingognates between related languages.
In 10thInternational Conferene on Computational Lin-guistis and 22nd Annual Meeting of the Asso-iation for Computational Linguistis.
Availableonline as http://al.ld.upenn.edu/P/P84/P84-1091.pdf.Jaques B. M. Guy.
1994.
An algorithm for identi-fyingognates in bilingual wordlists and its appli-ability to mahine translation.
Journal of Quan-titative Linguistis, 1(1):3542.Hans Heinrih Hok.
1991.
Priniples of HistorialLinguistis.
Mouton de Gruyter, Berlin.Robert J. Jeers and Ilse Lehiste.
1989.
Prini-ples and Methods for Historial Linguistis.
MITPress, Cambridge, MA.Martin Kay.
1964.
The logiofognate reognitionin historial linguistis.
Tehnial Report RM-4224-PR, The RAND Corporation, Santa Monia,CA, September.Brett Kessler.
2001.
The Signiane of Word Lists.CSLI Publiations, Stanford, CA.Simon Kirby.
2002.
Natural language from artiiallife.
Artiial Life, 8(2):185215.Grzegorz Kondrak.
2002.
Algorithms for Lan-guage Reonstrution.
Ph.D. thesis, University ofToronto.April MMahon and Robert MMahon.
2003.
Find-ing families: quantitative methods in languagelassiation.
Transations of the Philologial So-iety, 101:755.I.
Dan Melamed.
2000.
Models of translationalequivalene among words.
Computational Lin-guistis, 26(2):221249.Luay Nakleh, Tandy Warnow, Don Ringe, andSteven N. Evans.
2005.
Aomparison ofphylogenetireonstrution methods on an iedataset.
Transations of the Philologial Soiety,103(2):171192.D.
Ringe, Tandy Warnow, and A. Taylor.2002.
Indo-European andomputationalladis-tis.
Transations of the Philologial Soiety,100(1):59129.Wordgumbo.
2007a.
/ie/sla/pol/erengpol.htm.Website http://www.wordgumbo.om/.Wordgumbo.
2007b.
/ie/sla/rus/erengrus.htm.Website http://www.wordgumbo.om/.22
