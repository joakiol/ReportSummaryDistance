Weight Estimation for N-Best Rescoring*Ashvin Kannant, Mari Ostendorj\]', J. Robin Rohlicekl:t Boston University44 Cummington St.Boston, MA 02215:~ BBN Inc.10 Moulton St.Cambridge, MA 02138ABSTRACTThis paper describes recent improvements in the weight esti-mation technique for sentence hypothesis rescoring using theN-Best formalism.
Mismatches between training and testdata are also explored.1.
INTRODUCTIONThe N-Best rescoring paradigm involves the generationof a list of the N best sentence hypotheses by a recog-nition system and the subsequent rescoring of these hy-potheses by other knowledge sources.
The sentence hy-potheses are then reranked according to a weighted linearcombination of the different scores.
This paradigm hasthe potential of achieving better performance than thatof any individual knowledge source, if these scores arecombined in an "optimal" manner.
This paper discussesthe key issues related to estimation of robust weights fora linear combination of scores.2.
WEIGHT EST IMAT IONIn the initial work \[1\], the weights used in the linearscore combination were chosen to minimize the general-ized mean of the rank of the correct hypothesis using aniterative search algorithm based on Powell's method \[2\].Further experience using this technique suggested thatthe result was very sensitive to the large number of localminima in the optimization criterion.Several steps have been taken to address this issue.
Theoptimization criterion now minimizes the average worderror in the top ranking hypothesis.
The use of this cri-terion results in a "smoother" weight space, i.e., havingfewer local minima.
Also addressing the problem of lo-cal minima, we examine a large number of points in theweight space on a lattice spanning the range of proba-ble weights.
Powell's method may be used with pointson  the grid as the initial estimate of weights to find thebest performance, or the points on a fine grid may beevaluated irectly.The error function is piece-wise constant over the weight*This research was jointly funded by NSF and DARPA underNSF grant number IRI-8902124.space.
A particular anking of the hypotheses corre-sponds to a region (cell) defined by a set of inequalitiesthat describe a polytope.
In the hope of obtaining amore robust estimate, we measure the amount of slackfor the different coefficients along the coordinate axessuch that the weight remains within the cell as well asdetermine the "center" of the cell.
The product of theslacks in the different coordinate directions at the "cen-ter" is an approximate indicator of the "volume" of thecell.
If more than one cell gives the same performance,we choose the one with the largest "volume".
Weightswhich correspond to the "center" of this cell are used forcombining scores in the test set.3.
EXPERIMENTSExperiments were conducted to gain a better under-standing of the weight space.
In our implementationof the N-Best rescoring paradigm \[1\], the N-Best list(N = 20) is generated by the BBN BYBLOS system\[3\].
This list is rescored by the BU system, which isbased on the stochastic segment model (SSM) \[4, 5\], astatistical model for the sequence of observations thatcomprise a phoneme segment.
The SSM models arebased on independent-frame assumptions, are gender-dependent and are context-dependent wi h context yingbased on automatic lustering.
Results are reported onthe speaker-independent Resource Management corpususing the Word-Pair grammar.
The weights were trainedon the Feb 89 test set and then used to combine scoresfor the Oct 89 test set.
The training of weights may beeither gender-dependent or gender-independent.Figure 1 and Figure 2 show contour plots for the worderror distribution as a function of normalized HMM andSSM scores on the two test sets, keeping the phonemeand word insertion penalties fixed at typical values.
Thecontours have been drawn for the ten lowest word errors,with intensity being inversely proportional to error.
TheHMM and SSM scores were normalized by the average ofthe respective scores for the correct sentences to betterillustrate their relative weight in the combined score.Figure 1 represents the case for gender-dependent op-455Feb890Ct890,U2.0.0.5 i 1.5 2 2.5 3SSM weigh?Feb89Oct891.50.5I.0.0 0.5 1 1.5 2SSM weight0 0 .s  1 1 .s  2 2 .s  3Figure 1: Error function for optimization over malespeakers.
Range: 2.9-3.6% (Feb89), 2.8-3.3% (Oct89).0 0.5 1 1.5 2Figure 2: Error function for gender-independent op i-mization.
Range: 2.8-3.2% (Feb89), 3.2-3.6% (Oct89).tirnization over male speakers.
The weight space forthe two test sets appears vastly different.
The effectsof gender-independent optimization is shown in Figure2.
Though the Oct 89 figure has fewer local optima,it must be noted that the best region for one test setstill does not match that of the other.
Normalizing theacoustic scores shows that the HMM is weighted higherthan the SSM, but the weights are of the same order ofmagnitude.
The word vs. phoneme count contours (notshown) suggest that typical values of the word penaltyare about 3-5 times that of the phoneme penalty.Our current word recognition results on the Feb 89 testset are 4.2% for SSM and 2.8% for the combined system(HMM-SSM) using weights estimated on this test set.Using the same weights and testing on the Oct 89 testset, the results are 4.8% for the SSM and 3.3% for thecombined system.
Combining the SSM with the BBNHMM yields a 13% reduction in error rate over the HMMperformance alone which was 3.8%.4.
DISCUSSIONIn summary, we have described techniques that alleviatethe problem of sensitivity to local optima in weight esti-mation for N-Best rescoring.
However we find that therestill exists a significant problem of mismatch betweentraining and test sets.
By comparing the contour plotswe see that gender-independent optimization seems to beless sensitive to mismatch.
This leads us to believe thatwe must estimate weights over a larger set of speakers.ReferencesI.
Ostendorf, M., Kannan, A., Austin, S., Kimball, O,Schwartz, R., Rohlicek, J. R., "Integration of DiverseRecognition Methodologies Through Reevaluation ofN-Best Sentence Hypotheses," Proceedings of the DARPAWorkshop on Speech and Natural Language, pp.
83-87,February 1991.2.
Press, W. H., Flannery, B. P,, Teukolsky, S. A., andVetterling, W. T., Numerical Recipes, Cambridge Uni-versity Press, Cambridge 1986.3.
Schwartz, R., and Austin, S., "Efficient, High Perfor-mance Algorithms for N-Best Search", Proceedings off theThird DARPA Workshop on Speech and Natural Lan-guage, pp.
6-11, June 1990.4.
Ostendorf, M., and Roukos, S., "A Stochastic SegmentModel for Phoneme-Based Continuous Speech Recogni-tion," 1EEE Trans.
on Acoust., Speech and Signal Pro-cessing, pp.
1857-1869, December 1989.5.
Roukos, S., Ostendorf, M., Gish, H., and Derr, A.,"Stochastic Segment Modeling Using the Estimate-Maximize Algorithm," Proceedings 1EEE lnt.
Conf.Acoust., Speech, Signal Processing, pp.
127-130, NewYork, New York, April 1988.456
