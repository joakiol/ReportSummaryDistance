Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 671?679,Beijing, August 2010Learning the Scope of Negation via Shallow Semantic ParsingJunhui Li  Guodong Zhou?
Hongling Wang  Qiaoming ZhuSchool of Computer Science and TechnologySoochow University at Suzhou{lijunhui, gdzhou, redleaf, qmzhu}@suda.edu.cn?
Corresponding authorAbstractIn this paper we present a simplified shallowsemantic parsing approach to learning thescope of negation (SoN).
This is done byformulating it as a shallow semantic parsingproblem with the negation signal as thepredicate and the negation scope as its ar-guments.
Our parsing approach to SoNlearning differs from the state-of-the-artchunking ones in two aspects.
First, we ex-tend SoN learning from the chunking levelto the parse tree level, where structured syn-tactic information is available.
Second, wefocus on determining whether a constituent,rather than a word, is negated or not, via asimplified shallow semantic parsing frame-work.
Evaluation on the BioScope corpusshows that structured syntactic informationis effective in capturing the domination rela-tionship between a negation signal and itsdominated arguments.
It also shows that ourparsing approach much outperforms thestate-of-the-art chunking ones.1 IntroductionWhereas negation in predicate logic iswell-defined and syntactically simple, negationin natural language is much complex.
Gener-ally, learning the scope of negation involvestwo subtasks: negation signal finding and nega-tion scope finding.
The former decides whetherthe words in a sentence are negation signals(i.e., words indicating negation, e.g., no, not,fail, rather than), where the semantic informa-tion of the words, rather than the syntactic in-formation, plays a critical role.
The latter de-termines the sequences of words in the sen-tence which are negated by the given negationsignal.
Compared with negation scope finding,negation signal finding is much simpler and hasbeen well resolved in the literature, e.g.
withthe accuracy of 95.8%-98.7% on the threesubcorpora of the Bioscope corpus (Moranteand Daelemans, 2009).
In this paper, we focuson negation scope finding instead.
That is, weassume golden negation signal finding.Finding negative assertions is essential ininformation extraction (IE), where in general,the aim is to derive factual knowledge fromfree text.
For example, Vincze et al (2008)pointed out that the extracted informationwithin the scopes of negation signals shouldeither be discarded or presented separatelyfrom factual information.
This is especiallyimportant in the biomedical domain, wherevarious linguistic forms are used extensively toexpress impressions, hypothesized explanationsof experimental results or negative findings.Szarvas et al (2008) reported that 13.45% ofthe sentences in the abstracts subcorpus of theBioScope corpus and 12.70% of the sentencesin the full papers subcorpus of the Bioscopecorpus contain negative assertions.
In additionto the IE tasks in the biomedical domain, SoNlearning has attracted more and more attentionin some natural language processing (NLP)tasks, such as sentiment classification (Turney,2002).
For example, in the sentence ?The chairis not comfortable but cheap?, although boththe polarities of the words ?comfortable?
and?cheap?
are positive, the polarity of ?the chair?regarding the attribute ?cheap?
keeps positivewhile the polarity of ?the chair?
regarding theattribute ?comfortable?
is reversed due to thenegation signal ?not?.Most of the initial research on SoN learningfocused on negated terms finding, using eithersome heuristic rules (e.g., regular expression),or machine learning methods (Chapman et al,2001; Huang and Lowe, 2007; Goldin andChapman, 2003).
Negation scope finding hasbeen largely ignored until the recent release of671the BioScope corpus (Szarvas et al, 2008;Vincze et al, 2008).
Morante et al (2008) andMorante and Daelemans (2009) pioneered theresearch on negation scope finding by formu-lating it as a chunking problem, which classi-fies the words of a sentence as being inside oroutside the scope of a negation signal.
How-ever, this chunking approach suffers from lowperformance, in particular on long sentences,due to ignoring structured syntactic information.For example, given golden negation signals onthe Bioscope corpus, Morante and Daelemans(2009) only got the performance of 50.26% inPCS (percentage of correct scope) measure onthe full papers subcorpus (22.8 words per sen-tence on average), compared to 87.27% in PCSmeasure on the clinical reports subcorpus (6.6words per sentence on average).This paper explores negation scope findingfrom a parse tree perspective and formulates itas a shallow semantic parsing problem, whichhas been extensively studied in the past fewyears (Carreras and M?rquez, 2005).
In par-ticular, the negation signal is recast as the pre-dicate and the negation scope is recast as itsarguments.
The motivation behind is thatstructured syntactic information plays a criticalrole in negation scope finding and should bepaid much more attention, as indicated by pre-vious studies in shallow semantic parsing(Gildea and Palmer, 2002; Punyakanok et al,2005).
Our parsing approach to negation scopefinding differs from the state-of-the-art chunk-ing ones in two aspects.
First, we extend nega-tion scope finding from the chunking level intothe parse tree level, where structured syntacticinformation is available.
Second, we focus ondetermining whether a constituent, rather than aword, is negated or not.
Evaluation on theBioScope corpus shows that our parsing ap-proach much outperforms the state-of-the-artchunking ones.The rest of this paper is organized as follows.Section 2 reviews related work.
Section 3 in-troduces the Bioscope corpus on which ourapproach is evaluated.
Section 4 describes ourparsing approach by formulating negationscope finding as a simplified shallow semanticparsing problem.
Section 5 presents the ex-perimental results.
Finally, Section 6 concludesthe work.2 Related WorkWhile there is a certain amount of literaturewithin the NLP community on negated termsfinding (Chapman et al, 2001; Huang andLowe, 2007; Goldin and Chapman, 2003),there are only a few studies on negation scopefinding (Morante et al, 2008; Morante andDaelemans, 2009).Negated terms findingRule-based methods dominated the initial re-search on negated terms finding.
As a repre-sentative, Chapman et al (2001) developed asimple regular expression-based algorithm todetect negation signals and identify medicalterms which fall within the negation scope.They found that their simple regular expres-sion-based algorithm can effectively identify alarge portion of the pertinent negative state-ments from discharge summaries on determin-ing whether a finding or disease is absent.
Be-sides, Huang and Lowe (2007) first proposedsome heuristic rules from a parse tree perspec-tive to identify negation signals, taking advan-tage of syntactic parsing, and then located ne-gated terms in the parse tree using a corre-sponding negation grammar.As an alternative to the rule-based methods,various machine learning methods have beenproposed for finding negated terms.
As a rep-resentative, Goldin and Chapman (2003) a-dopted both Na?ve Bayes and decision trees todistinguish whether an observation is negatedby the negation signal ?not?
in hospital reports.Negation scope findingMorante et al (2008) pioneered the research onnegation scope finding, largely due to theavailability of a large-scale annotated corpus,the Bioscope corpus.
They approached the ne-gation scope finding task as a chunking prob-lem which predicts whether a word in the sen-tence is inside or outside of the negation scope,with proper post-processing to ensure consecu-tiveness of the negation scope.
Morante andDaelemans (2009) further improved the per-formance by combing several classifiers.Similar to SoN learning, there are some ef-forts in the NLP community on learning thescope of speculation.
As a representative,?zg?r and Radev (2009) divided speculation672learning into two subtasks: speculation signalfinding and speculation scope finding.
In par-ticular, they formulated speculation signalfinding as a classification problem while em-ploying some heuristic rules from the parse treeperspective on speculation scope finding.3 Negation in the BioScope CorpusThis paper employs the BioScope corpus(Szarvas et al, 2008; Vincze et al, 2008)1, afreely downloadable negation resource fromthe biomedical domain, as the benchmark cor-pus.
In this corpus, every sentence is annotatedwith negation signals and speculation signals(if it has), as well as their linguistic scopes.Figure 1 shows a self-explainable example.
Inthis paper, we only consider negation signals,rather than speculation ones.
Our statisticsshows that 96.57%, 3.23% and 0.20% of nega-tion signals are represented by one word, twowords and three or more words, respectively.Additional, adverbs (e.g., not, never) and de-terminers (e.g., no, neither) occupy 45.66% and30.99% of negation signals, respectively.The Bioscope corpus consists of three sub-corpora: the full papers and the abstracts fromthe GENIA corpus (Collier et al, 1999), andclinical (radiology) reports.
Among them, thefull papers subcorpus and the abstracts subcor-pus come from the same genre, and thus sharesome common characteristics in statistics, suchas the number of words in the negation scope tothe right (or left) of the negation signal and theaverage scope length.
In comparison, the clini-cal reports subcorpus consists of clinical radi-ology reports with short sentences.
For detailedstatistics about the three subcorpora, please seeMorante and Daelemans (2009).1 http://www.inf.u-szeged.hu/rgai/bioscopeFor preprocessing, all the sentences in theBioscope corpus are tokenized and then parsedusing the Berkeley parser2 (Petrov and Klein,2007) trained on the GENIA TreeBank (GTB)1.0 (Tateisi et al, 2005)3, which is a bracketedcorpus in (almost) PTB style.
10-foldcross-validation on GTB1.0 shows that theparser achieves the performance of 86.57 inF1-measure.
It is worth noting that the GTB1.0corpus includes all the sentences in the ab-stracts subcorpus of the Bioscope corpus.4 Negation Scope Finding via ShallowSemantic ParsingIn this section, we first formulate the negationscope finding task as a shallow semantic pars-ing problem.
Then, we deal with it using a sim-plified shallow semantic parsing framework.4.1 Formulating Negation Scope Findingas a Shallow Semantic Parsing Prob-lemGiven a parse tree and a predicate in it, shallowsemantic parsing recognizes and maps all theconstituents in the sentence into their corre-sponding semantic arguments (roles) of thepredicate.
As far as negation scope findingconsidered, the negation signal can be regardedas the predicate4, while the scope of the nega-tion signal can be mapped into several con-stituents which are negated and thus can beregarded as the arguments of the negation sig-nal.
In particular, given a negation signal andits negation scope which covers wordm, ?,wordn, we adopt the following two heuristicrules to map the negation scope of the negationsignal into several constituents which can bedeemed as its arguments in the given parse tree.<sentence id="S26.8">These findings <xcopeid="X26.8.2"><cue type="speculation"ref="X26.8.2">indicate that</cue> <xcopeid="X26.8.1">corticosteroid resistance in bron-chial asthma <cue type="negation"ref="X26.8.1">can not</cue> be explained byabnormalities in corticosteroid receptor charac-teristics</xcope></xcope>.</sentence>Figure 1: An annotated sentence in the BioScopecorpus.1) The negation signal itself and all of its an-cestral constituents are non-arguments.2) If constituent X is an argument of the givennegation signal, then X should be the high-est constituent dominated by the scope ofwordm, ?, wordn.
That is to say, X?s parentconstituent must cross-bracket or includethe scope of wordm, ?, wordn.2 http://code.google.com/p/berkeleyparser/3 http://www-tsujii.is.s.u-tokyo.ac.jp/GENIA4 If a negation signal consists of multiply words(e.g., rather than), the last word (e.g., than) is cho-sen to represent the negation signal.673Figure 2: An illustration of a negation signal and its arguments in a parse tree.These findingsindicatesthatcorticosteroid resistanceNP0,1VBP2,2 SBAR3,11can notIN3,3beexplained by abnormalitiesNP4,5MD6,6 RB7,7VB8,8 VP9,11VP8,11VP6,11S4,11VP2,11S0,11predicateargumentsThe first rule ensures that no argument cov-ers the negation signal while the second ruleensures no overlap between any two arguments.For example, in the sentence ?These findingsindicate that corticosteroid resistance can notbe explained by abnormalities?, the negationsignal ?can not?
has the negation scope ?corti-costeroid resistance can not be explained byabnormalities?.
As shown in Figure 2, the node?RB7,7?
(i.e., not) represents the negation signal?can not?
while its arguments include threeconstituents {NP4,5, MD6,6, and VP8,11}.
It isworth noting that according to the above rules,negation scope finding via shallow semanticparsing, i.e.
determining the arguments of agiven negation signal, is robust to some varia-tions in parse trees.
This is also empiricallyjustified by our later experiments.
For example,if the VP6,11 in Figure 2 is incorrectly expandedby the rule VP6,11?MD6,6+RB7,7+VB8,8+VP9,11,the negation scope of the negation signal ?cannot?
can still be correctly detected as long as{NP4,5, MD6,6, VB8,8, and VP9,11} are predictedas the arguments of the negation signal ?cannot?.Compared with common shallow semanticparsing which needs to assign an argumentwith a semantic label, negation scope findingdoes not involve semantic label classificationand thus could be divided into three consequentphases: argument pruning, argument identifica-tion and post-processing.4.2 Argument PruningSimilar to the predicate-argument structures incommon shallow semantic parsing, the nega-tion signal-scope structures in negation scopefinding can be also classified into several cer-tain types and argument pruning can be doneby employing several heuristic rules to filterout constituents, which are most likelynon-arguments of a negation signal.
Similar tothe heuristic algorithm as proposed in Xue andPalmer (2004) for argument pruning in com-mon shallow semantic parsing, the argumentpruning algorithm adopted here starts fromdesignating the negation signal as the currentnode and collects its siblings.
It then iterativelymoves one level up to the parent of the currentnode and collects its siblings.
The algorithmends when it reaches the root of the parse tree.To sum up, except the negation signal and itsancestral constituents, any constituent in theparse tree whose parent covers the given nega-tion signal will be collected as argument can-didates.
Taking the negation signal node?RB7,7?
in Figure 2 as an example, constituents{MD6,6, VP8,11, NP4,5, IN3,3, VBP2,2, and NP0,1}are collected as its argument candidates conse-quently.4.3 Argument IdentificationHere, a binary classifier is applied to determinethe argument candidates as either valid argu-ments or non-arguments.
Similar to argument674identification in common shallow semanticparsing, the structured syntactic informationplays a critical role in negation scope finding.Basic FeaturesTable 1 lists the basic features for argumentidentification.
These features are also widelyused in common shallow semantic parsing forboth verbal and nominal predicates (Xue, 2008;Li et al, 2009).Feature Remarksb1 Negation: the stem of the negation signal,e.g., not, rather_than.
(can_not)b2 Phrase Type: the syntactic category of theargument candidate.
(NP)b3 Path: the syntactic path from the argumentcandidate to the negation signal.
(NP<S>VP>RB)b4 Position: the positional relationship of theargument candidate with the negation sig-nal.
?left?
or ?right?.
(left)Table 1: Basic features and their instantiations forargument identification in negation scope finding,with NP4,5 as the focus constituent (i.e., the argu-ment candidate) and ?can not?
as the given negationsignal, regarding Figure 2.Additional FeaturesTo capture more useful information in the ne-gation signal-scope structures, we also explorevarious kinds of additional features.
Table 2shows the features in better capturing the de-tails regarding the argument candidate and thenegation signal.
In particular, we categorize theadditional features into three groups accordingto their relationship with the argument candi-date (AC, in short) and the given negation sig-nal (NS, in short).Some features proposed above may not beeffective in argument identification.
Therefore,we adopt the greedy feature selection algorithmas described in Jiang and Ng (2006) to pick uppositive features incrementally according totheir contributions on the development data.The algorithm repeatedly selects one featureeach time which contributes most, and stopswhen adding any of the remaining features failsto improve the performance.
As far as the ne-gation scope finding task concerned, the wholefeature selection process could be done by firstrunning the selection algorithm with the basicfeatures (b1-b4) and then incrementally pickingup effective features from (ac1-ac6, AC1-AC2,ns1-ns4, NS1-NS2, nsac1-nsac2, and NSAC1-NSAC7).Feature Remarksargument candidate (AC) relatedac1 the headword (ac1H) and its POS (ac1P).
(resistance, NN)ac2 the left word (ac2W) and its POS (ac2P).
(that, IN)ac3 the right word (ac3W) and its POS (ac3P).
(can, MD)ac4 the phrase type of its left sibling (ac4L)and its right sibling (ac4R).
(NULL, VP)ac5 the phrase type of its parent node.
(S)ac6 the subcategory.
(S:NP+VP)combined features (AC1-AC2)b2&fc1H, b2&fc1Pnegation signal (NS) relatedns1 its POS.
(RB)ns2 its left word (ns2L) and right word (ns2R).
(can, be)ns3 the subcategory.
(VP:MD+RB+VP)ns4 the phrase type of its parent node.
(VP)combined features (NS1-NS2)b1&ns2L, b1&ns2RNS-AC-relatednsac1 the compressed path of b3: compressingsequences of identical labels into one.
(NP<S>VP>RB)nsac2 whether AC and NS are adjacent in posi-tion.
?yes?
or ?no?.
(no)combined features (NSAC1-NSAC7)b1&b2, b1&b3, b1&nsac1, b3&NS1, b3&NS2,b4&NS1, b4&NS2Table 2: Additional features and their instantiationsfor argument identification in negation scope find-ing, with NP4,5 as the focus constituent (i.e., theargument candidate) and ?can not?
as the givennegation signal, regarding Figure 2.4.4 Post-ProcessingAlthough a negation signal in the BioScopecorpus always has only one continuous blockas its negation scope (including the negationsignal itself), the negation scope finder mayresult in discontinuous negation scope due toindependent prediction in the argument identi-fication phase.
Given the golden negation sig-nals, we observed that 6.2% of the negationscopes predicted by our negation scope finderare discontinuous.Figure 3 demonstrates the projection of allthe argument candidates into the word level.According to our argument pruning algorithmin Section 4.2, except the words presented by675the negation signal, the projection covers thewhole sentence and each constituent (LACi orRACj in Figure 3) receives a probability distri-bution of being an argument of the given nega-tion signal in the argument identification phase.Since a negation signal is deemed inside of itsnegation scope in the BioScope corpus, ourpost-processing algorithm first includes thenegation signal in its scope and then starts toidentify the left and the right scope boundaries,respectively.As shown in Figure 3, the left boundary hasm+1 possibilities, namely the negation signalitself, the leftmost word of constituent LACi(1<=i<=m).
Supposing LACi receives prob-ability of Pi being an argument, we use the fol-lowing formula to determine LACk* whoseleftmost word represents the boundary of theleft scope.
If k*=0, then the negation signalitself represents its left boundary.
( )*1 1arg max 1k mi ik i i kk P= = += ??
?
P?Similarly, the right boundary of the givennegation signal can be decided.5 ExperimentationWe have evaluated our shallow semantic pars-ing approach to negation scope finding on theBioScope corpus.5.1 Experimental SettingsFollowing the experimental setting in Moranteand Daelemans (2009), the abstracts subcorpusis randomly divided into 10 folds so as to per-form 10-fold cross validation, while the per-formance on both the papers and clinical re-ports subcorpora is evaluated using the systemtrained on the whole abstracts subcorpus.
Inaddition, SVMLight5 is selected as our classi-fier.
In particular, we adopt the linear kerneland the training parameter C is fine-tuned to0.2.15 http://svmlight.joachims.org/The evaluation is made using the accuracy.We report the accuracy using three measures:PCLB and PCRB, which indicate the percent-ages of correct left boundary and right bound-ary respectively, PCS, which indicates the per-centage of correct scope as a whole.LACm   ?.
LAC1 RAC1   ?.
RACnm nFigure 3: Projecting the left and the right argumentcandidates into the word level.5.2 Experimental Results on Golden ParseTreesIn order to select beneficial features from theadditional features proposed in Section 4.3, werandomly split the abstracts subcorpus intotraining and development datasets with propor-tion of 4:1.
After performing the greedy featureselection algorithm on the development data,features {NSAC5, ns2R, NS1, ac1P, ns3,NSAC7, ac4R} are selected consecutively forargument identification.
Table 3 presents theeffect of selected features in an incrementalway on the development data.
It shows that theadditional features significantly improve theperformance by 11.66% in PCS measure from74.93% to 86.59% ( ).
2; 0.0p?
<Feature PCLB PCRB PCSBaseline 84.26 88.92 74.93+NSAC5 90.96 88.92 81.34+ns2R 91.55 88.92 81.92+NS1 92.42 89.50 83.09+ac1P 93.59 89.50 84.26+ns3 93.88 90.09 84.84+NSAC7 94.75 89.80 85.42+ac4R 95.04 90.67 86.59Table 3: Performance improvement (%) of includ-ing the additional features in an incremental way onthe development data (of the abstracts subcorpus).However, Table 3 shows that the additionalfeatures behave quite differently in terms ofPCLB and PCRB measures.
For example,PCLB measure benefits more from featuresNSAC5, ns2R, NS1, ac1P, and NSAC7 whilePCRB measure benefits more from featuresNS1 and ac4R.
It also shows that the features(e.g., NSAC5, ns2R, NS1, NSAC7) related toneighboring words of the negation signal play acritical role in recognizing both left and rightboundaries.
This may be due to the fact thatneighboring words usually imply sententialinformation.
For example, ?can not be?
indi-cates a passive clause while ?did not?
indicatesan active clause.
Table 3 also shows that therecognition of left boundaries is much easierthan that of right boundaries.
This may be due676to the fact that 83.6% of negation signals havethemselves as the left boundaries in the ab-stracts subcorpus.gument candidate is outside or cross-bracketswith the golden negation scope, then it is anon-argument.
The oracle performance is pre-sented in the rows of oracle in Table 5 and Ta-ble 6.Table 4 presents the performance on the ab-stracts subcorpus by performing 10-foldcross-validation.
It shows that the additionalfeatures significantly improve the performanceover the three measures ( ).
2; 0.0p?
<Table 5 and Table 6 show that:1) Automatic syntactic parsing lowers the per-formance of negation scope finding on theabstracts subcorpus in all three measures (e.g.from 83.10 to 81.84 in PCS).
As expected,the parser trained on the whole GTB1.0corpus works better than that trained on6,691 sentences (e.g.
64.02 Vs. 62.70, and89.79 Vs. 85.21 in PCS measure on the fullpapers and the clinical reports subcorpora,respectively).
However, the performance de-crease shows that negation scope finding isnot as sensitive to automatic syntactic pars-ing as common shallow semantic parsing,whose performance might decrease by about~10 in F1-measure (Toutanova et al, 2005).This indicates that negation scope findingvia shallow semantic parsing is robust tosome variations in the parse trees.1Feature PCLB PCRB PCSBaseline 84.29 87.82 74.05+selected features 93.06 88.96 83.10Table 4: Performance (%) of negation scope findingon the abstracts subcorpus using 10-foldcross-validation.5.3 Experimental Results on AutomaticParse TreesThe GTB1.0 corpus contains 18,541 sentencesin which 11,850 of them (63.91%) overlap withthe sentences in the abstracts subcorpus6.
Inorder to get automatic parse trees for the sen-tences in the abstracts subcorpus, we train theBerkeley parser with the remaining 6,691 sen-tences in GTB1.0.
The Berkeley parser trainedon 6,691 sentences achieves the performance of85.22 in F1-measure on the other sentences inGTB1.0.
For both the full papers and clinicalreports subcorpora, we get their automaticparse trees by using two Berkeley parsers: onetrained on 6,691 sentences in GBT1.0, and theother trained on all the sentences in GTB1.0.2) autoparse(test) consistently outperformsautoparse(t&t) on both the abstracts and thefull papers subcorpora.
However, it is sur-prising to find that autoparse(t&t) achievesbetter performance on the clinical reportssubcorpus than autoparse(test).
This may bedue to the special characteristics of theclinical reports subcorpus, which mainlyconsists of much shorter sentences with 6.6words per sentence on average, and betteradaptation of the argument identificationclassifier to the variations in the automaticparse trees.To test the performance on automatic parsetrees, we employ two different configurations.First, we train the argument identification clas-sifier on the abstracts subcorpus using auto-matic parse trees produced by Berkeley parsertrained on 6,691 sentences.
The experimentalresults are presented in the rows of auto-parse(t&t) in Table 5 and Table 6.
Then, wetrain the argument identification classifier onthe abstracts subcorpus using golden parsetrees.
The experimental results are presented inthe rows of autoparse(test) in Table 5 and Ta-ble 6.3) The performance on all three subcorporaindicates that the recognition of rightboundary is much harder than that of leftboundary.
This may be due to the longerright boundary on an average.
Our statisticsshows that the average left/right boundariesare 1.1/6.9, 0.1/3.7, and 1.2/6.5 words on theabstracts, the full papers and the clinical re-ports subcorpora, respectively.We also report an oracle performance to ex-plore the best possible performance of our sys-tem by assuming that our negation scope findercan always correctly determine whether a can-didate is an argument or not.
That is, if an ar-4) The oracle performance is less sensitive toautomatic syntactic parsing.
In addition,given the performance gap between the per-formance of our negation scope finder andthe oracle performance, there is still muchroom for further performance improvement.6 There are a few cases where two sentences in theabstracts subcorpus map into one sentence in GTB.677Abstracts Papers ClinicalPCLB PCRB PCS PCLB PCRB PCS PCLB PCRB PCSautoparse(t&t) 91.97 87.82 80.88 85.45 67.20 59.26 97.48 88.30 85.89autoparse(test) 92.71 88.33 81.84 87.57 68.78 62.70 97.48 87.73 85.21oracle 99.72 94.59 94.37 98.94 84.13 83.33 99.89 98.39 98.39Table 5: Performance (%) of negation scope finding on the three subcorpora by using automatic parser trainedwith 6,691 sentences in GTB1.0.Papers ClinicalPCLB PCRB PCS PCLB PCRB PCSautoparse(t&t) 85.98 67.99 60.32 97.48 92.66 90.48autoparse(test) 87.83 70.11 64.02 97.36 92.20 89.79oracle 98.94 83.86 83.07 99.77 97.94 97.82Table 6: Performance (%) of negation scope finding on the two subcorpora by using automatic parser trainedwith all the sentences in GTB1.0.Method Abstracts Papers ClinicalM et al (2008) 57.33 n/a n/aM & D (2009) 73.36 50.26 87.27Our baseline 73.42 53.70 88.42Our final system 81.84 64.02 89.79Table 7: Performance comparison over the PCSmeasure (%) of our system with otherstate-of-the-art ones.Table 7 compares our performance in PCSmeasure with related work.
It shows that evenour baseline system with four basic features aspresented in Table 1 performs better thanMorante et al (2008) and Morante and Daele-mans(2009).
This indicates the appropriatenessof our simplified shallow semantic parsing ap-proach and the effectiveness of structured syn-tactic information on negation scope finding.
Italso shows that our final system significantlyoutperforms the state-of-the-art ones using achunking approach, especially on the abstractsand full papers subcorpora.
However, the im-provement on the clinical reports subcorpus isless apparent, partly due to the fact that thesentences in this subcorpus are much simpler(with average length of 6.6 words per sentence)and thus a chunking approach can achieve highperformance.
Following are two typical sen-tences from the clinical reports subcorpus,where the negation scope covers the whole sen-tence (except the period punctuation).
Suchsentences account for 57% of negation sen-tences in the clinical reports subcorpus.6 ConclusionIn this paper we have presented a simplifiedshallow semantic parsing approach to negationscope finding by formulating it as a shallowsemantic parsing problem, which has been ex-tensively studied in the past few years.
In par-ticular, we regard the negation signal as thepredicate while mapping the negation scopeinto several constituents which are deemed asarguments of the negation signal.
Evaluation onthe Bioscope corpus shows the appropriatenessof our shallow semantic parsing approach andthat structured syntactic information plays acritical role in capturing the domination rela-tionship between a negation signal and its ne-gation scope.
It also shows that our parsingapproach much outperforms the state-of-the-artchunking ones.
To our best knowledge, this isthe first research on exploring negation scopefinding via shallow semantic parsing.Future research will focus on joint learningof negation signal and its negation scope find-ings.
Although Morante and Daelemans (2009)reported the performance of 95.8%-98.7% onnegation signal finding, it lowers the perform-ance of negation scope finding by about7.29%-16.52% in PCS measure.AcknowledgmentsThis research was supported by Projects60683150, 60970056, and 90920004 under theNational Natural Science Foundation of China,Project 20093201110006 under the SpecializedResearch Fund for the Doctoral Program ofHigher Education of China.
(1) No evidence of focal pneumonia .
(2) No findings to account for symptoms .678ReferencesXavier Carreras and Llu?s M?rquez.
2005.
Introduc-tion to the CoNLL-2005 Shared Task: SemanticRole Labeling.
In Proceedings of CoNLL 2005.Wendy W. Chapman, Will Bridewell, Paul Hanbury,Gregory F. Cooper, and Bruce G. Buchanan.2001.
A Simple Algorithm for Identifying Ne-gated Findings and Diseases in Discharge Sum-maries.
Journal of Biomedical Informatics, 34:301-310.Nigel Collier, Hyun Seok Park, Norihiro Ogata, etal.
1999.
The GENIA project: corpus-basedknowledge acquisition and information extrac-tion from genome research papers.
In Proceed-ings of EACL 1999.Daniel Gildea and Martha Palmer.
2002.
The Ne-cessity of Parsing for Predicate Argument Rec-ognition.
In Proceedings of ACL 2002.Ilya M. Goldin and Wendy W. Chapman.
2003.Learning to Detect Negation with ?Not?
in Medi-cal Texts.
In Proceedings of SIGIR 2003.Yang Huang and Henry Lowe.
2007.
A Novel Hy-brid Approach to Automated Negation Detectionin Clinical Radiology Reports.
Journal of theAmerican Medical Informatics Association, 14(3):304-311.Zheng Ping Jiang and Hwee Tou Ng.
2006.
Seman-tic Role Labeling of NomBank: A Maximum En-tropy Approach.
In Proceedings of EMNLP2006.Junhui Li, Guodong Zhou, Hai Zhao, Qiaoming Zhu,and Peide Qian.
Improving Nominal SRL inChinese Language with Verbal SRL Informationand Automatic Predicate Recognition.
In Pro-ceedings of EMNLP 2009.Roser Morante, Anthony Liekens, and WalterDaelemans.
2008.
Learning the Scope of Nega-tion in Biomedical Texts.
In Proceedings ofEMNLP 2008.Roser Morante and Walter Daelemans.
2009.
AMetalearning Approach to Processing the Scopeof Negation.
In Proceedings of CoNLL 2009.Arzucan ?zg?r; Dragomir R. Radev.
2009.
Detect-ing Speculations and their Scopes in ScientificText.
In Proceedings of EMNLP 2009.Slav Petrov and Dan Klein.
2007.
Improved Infer-ence for Unlexicalized Parsing.
In Proceedings ofNAACL 2007.Vasin Punyakanok, Dan Roth, and Wen-tau Yih.2005.
The Necessity of Syntactic Parsing forSemantic Role Labeling.
In Proceedings of IJCAI2005.Gy?rgy Szarvas, Veronika Vincze, Rich?rd Farkas,and J?nos Csirik.
2008.
The BioScope corpus:annotation for negation, uncertainty and theirscope in biomedical texts.
In Proceedings ofBioNLP 2008.Yuka Tateisi, Akane Yakushiji, Tomoko Ohta, andJun?ichi Tsujii.
2005.
Syntax Annotation for theGENIA Corpus.
In Proceedings of IJCNLP 2005,Companion volume.Kristina Toutanova, Aria Haghighi, and ChristopherD.
Manning.
2005.
Joint Learning Improves Se-mantic Role Labeling.
In Proceedings of ACL2005.Peter D. Turney.
2002.
Thumbs Up or ThumbsDown?
Semantic Orientation Applied to Unsu-pervised Classification of Reviews.
In Proceed-ings of ACL 2002.Veronika Vincze, Gy?rgy Szarvas, Rich?rd Farkas,Gy?rgy M?ra, and J?nos Csirik.
2008.
The Bio-Scope corpus: biomedical texts annotated foruncertainty, negation and their scopes.
BMCBioinformatics, 9(Suppl 11):S9.Nianwen Xue and Martha Palmer.
2004.
CalibratingFeatures for Semantic Role Labeling.
In Pro-ceedings of EMNLP 2004.Nianwen Xue.
2008.
Labeling Chinese Predicateswith Semantic Roles.
Computational Linguistics,34(2):225-255.679
