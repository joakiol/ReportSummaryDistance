Proceedings of the Sixth Workshop on Innovative Use of NLP for Building Educational Applications, pages 96?104,Portland, Oregon, 24 June 2011. c?2011 Association for Computational LinguisticsGRASP: Grammar- and Syntax-based Pattern-Finder in CALLChung-Chi Huang*  Mei-Hua Chen* Shih-Ting Huang+  Hsien-Chin Liou**  Jason S. Chang+* Institute of Information Systems and Applications, NTHU, HsinChu, Taiwan, R.O.C.
300+ Department of Computer Science, NTHU, HsinChu, Taiwan, R.O.C.
300**  Department of Foreign Languages and Literature, NTHU, HsinChu, Taiwan, R.O.C.
300{u901571,chen.meihua,koromiko1104,hsienchin,jason.jschang}gmail.comAbstractWe introduce a method for learning todescribe the attendant contexts of a givenquery for language learning.
In ourapproach, we display phraseologicalinformation in the form of a summary ofgeneral patterns as well as lexical bundlesanchored at the query.
The methodinvolves syntactical analyses and invertedfile construction.
At run-time, grammaticalconstructions and their lexicalinstantiations characterizing the usage ofthe given query are generated anddisplayed, aimed at improving learners?deep vocabulary knowledge.
We present aprototype system, GRASP, that applies theproposed method for enhanced collocationlearning.
Preliminary experiments showthat language learners benefit more fromGRASP than conventional dictionarylookup.
In addition, the informationproduced by GRASP is potentially usefulinformation for automatic or manualediting process.1 IntroductionMany learners submit word or phrase queries (e.g.,?role?)
to language learning sites on the Web toget usage information every day, and an increasingnumber of services on the Web specifically targetsuch queries.
Language learning tools such asconcordancers typically accept single-word queriesand respond with example sentences containing thewords.
There are also collocation reference toolssuch as Sketch Engine and TANGO that provideco-occurring words for the query word.
Anothercollocation tool, JustTheWord further organizesand displays collocation clusters.Learners may want to submit phrase queries(fixed or rigid collocaions) to learn further how touse the phrase in context, or in other words, toacquire the knowledge on the attendantphraseology of the query.
These queries could beanswered more appropriately if the tool acceptedlong queries and returned a concise summary oftheir surrounding contexts.Consider the query ?play role?.
The bestresponses for this query are probably not justexample sentences, but rather the phraseologicaltendencies described grammatically or lexically.
Agood response of such a summary might containpatterns such as ?play Det Adj role?
(as in ?play animportant role?)
and ?play ~ role in V-ing?
(as in?play ~ role in shaping ??).
Intuitively, byexploiting simple part-of-speech analysis, we canderive such patterns, inspired by the grammaticaltheory of Pattern Grammar 1  in order to providemore information on demand beyond what is givenin a grammar book.We present a system, GRASP, that provide ausage summary of the contexts of the query in theform of patterns and frequent lexical bundles.
Suchrich information is expected to help learners andlexicographers grasp the essence of word usages.An example GRASP response for the query ?play1Please refer to (Hunston and Francis, 2000).96role?
is shown in Figure 1.
GRASP has retrievedthe sentences containing the query in a referencecorpus.
GRASP constructs these query-to-sentenceindex in the preparation stage (Section 3).Figure 1.
An example GRASP search for ?play role?.At run-time, GRASP starts with a search query(e.g., ?play role?)
submitted by the user.
GRASPthen retrieves example sentences and generates asummary of representative contexts, using patterns(e.g., ?play ~ role in V-ing?)
and lexical bundles(e.g., ?play ~ role in shaping.
In ourimplementation, GRASP also returns thetranslations and the example sentences of thelexical instances, so the learner can use theirknowledge of native language to enhance thelearning process.2 Related WorkComputer-assisted language learning (CALL) hasbeen an area of active research.
Recently, more andmore research based on natural languageprocessing techniques has been done to helplanguage learners.
In our work, we introduce alanguage learning environment, where summarizedusage information are provided, including howfunction words and verb forms are used incombination with the query.
These usage notesoften help contrast the common sources of error inlearners?
writing (Nicholls, 1999).
In our pilotteaching experiment, we found learners haveproblems using articles and prepositions correctlyin sentence composition (as high as 80% of thearticles and 60% of the prepositions were usedincorrectly), and GRASP is exactly aimed athelping ESL or EFL learners in that area.Until recently, collocations and usageinformation are compiled mostly manually(Benson et al, 1986).
With the accessibility tolarge-scale corpora and powerful computers, it hasbecome common place to compile a list ofcollocations automatically (Smadja, 1993).
Inaddition, there are many collocation checkersdeveloped to help non-native language learners(Chang et al, 2008), or learners of English foracademic purposes (Durrant, 2009).Recently, automatic generation of collocationsfor computational lexicography and onlinelanguage learning has drawn much attention.Sketch Engine (Kilgarriff et al, 2004) summarizesa word?s grammatical and collocation behavior,while JustTheWord clusters the co-occurringwords of single-word queries and TANGO (Jian etal., 2004) accommodates cross-lingual collocationsearches.
Moreover, Cheng et al (2006) describehow to retrieve mutually expected words usingconcgrams.
In contrast, GRASP, going one stepfurther, automatically computes and displays theinformation that reveals the regularities of thecontexts of user queries in terms of grammarpatterns.Recent work has been done on incorporatingword class information into the analyses ofphraseological tendencies.
Stubbs (2004)introduces phrase-frames, which are based onlexical ngrams with variable slots, while Wible etal.
(2010) describe a database called StringNet,with lexico-syntactic patterns.
Their methods ofusing word class information are similar in spirit toour work.
The main differences are that ourpatterns is anchored with query words directly andgeneralizes query?s contexts via parts-of-speech,and that we present the query?s usage summary inSearch query:Mapping query words to (position, sentence) pairs:?play?
occurs in (10,77), (4,90), (6,102), ?, and so on.?role?
occurs in (7,90), (12,122), (6,167), ?, and so on.A.
In-between pattern grammar:Distance 3 (1624):play DT JJ role (1364):e.g., ?play an important role?
(259), ?play a major role?
(168), ?play DT VBG role (123):e.g., ?play a leading role?
(75), ?play a supporting role?
(5), ?play DT JJR role (40):e.g., ?play a greater role?
(17), ?play a larger role?
(8), ?Distance 2 (480):play DT role (63):e.g., ?play a role?
(197), ?play the role?
(123), ?play JJ role (63):e.g., ?play important role?
(15), ?play different role?
(6), ?Distance 1 (6):play role (6)B.
Subsequent pattern grammar:play ~ role IN(in) DT (707):e.g., ?play ~ role in the?
(520), ?play ~ role in this?
(24), ?play ~ role IN(in) VBG (407):e.g., ?play ~ role in shaping?
(22), ?play ~ role IN(in) NN (166):e.g., ?play ~ role in society?
(7), ?play ~ role in relation?
(5), ?C.
Precedent pattern grammar:NN MD play ~ role (83):e.g., ?communication will play ~ role ?
(2), ?JJ NNS play ~ role (69):e.g., ?voluntary groups play ~ role?
(2), ?Type your search query, and push GRASP!97terms of function words as well as content wordform (e.g., ?play ~ role in V-ing?
), as well aselastic lexical bundles (e.g., ?play ~ role inshaping?).
Additionally, we also use semanticcodes (e.g., PERSON) to provide more informationin a way similar what is provided in learnerdictionaries.3 The GRASP System3.1 Problem StatementWe focus on constructing a usage summary likelyto explain the contexts of a given linguistic search.The usage summary, consisting of the query?spredominant attendant phraseology ranging frompattern grammar to lexical phrases, is then returnedas the output of the system.
The returned summary,or a set of patterns pivoted with both content andfunction words, can be used for learners?
benefitsdirectly, or passed on to an error detection andcorrection system (e.g., (Tsao and Wible, 2009)and some modules in (Gamon et al, 2009) as rules.Therefore, our goal is to return a reasonable-sizedset of lexical and grammatical patternscharacterizing the contexts of the query.
We nowformally state the problem that we are addressing.Problem Statement: We are given a referencecorpus C from a wide range of sources and alearner search query Q.
Our goal is to construct asummary of word usages based on C that is likelyto represent the lexical or grammatical preferenceson Q?s contexts.
For this, we transform the wordsin Q into sets of (word position, sentence record)pairs such that the context information, whetherlexically- or grammatical-oriented, of the queryingwords is likely to be acquired efficiently.In the rest of this section, we describe oursolution to this problem.
First, we define a strategyfor preprocessing our reference corpus (Section3.2).
Then, we show how GRASP generatescontextual patterns, comprising the usage summary,at run-time (Section 3.3).3.2 Corpus PreprocessingWe attempt to find the word-to-sentence mappingsand the syntactic counterparts of the L1 sentencesexpected to speed up run-time pattern generation.Our preprocessing procedure has two stages.Lemmatizing and PoS Tagging.
In the first stage,we lemmatize each sentence in the referencecorpus C and generate its most probable POS tagsequence.
The goal of lemmatization is to reducethe impact of morphology on statistical analyseswhile that of POS tagging is to provide a way togrammatically describe and generalize thecontexts/usages of a linguistic query.
Actually,using POS tags is quite natural: they are often usedfor general description in grammar books, such asone?s (i.e., possessive pronoun) in the phrase?make up one?s mind?, oneself (i.e., reflexivepronoun) in ?enjoy oneself very much?,superlative_adjective in ?the mostsuperlative_adjective?, NN (i.e., noun) and VB (i.e.,base form of a verb) in ?insist/suggest/demand thatNN VB?
and so on.Constructing Inverted Files.
In the second stage,we build up inverted files of the lemmas in C forquick run-time search.
For each lemma, we recordthe sentences and positions in which it occurs.Additionally, its corresponding surface word andPOS tag are kept for run-time pattern grammargeneration.Figure 2.
Generating pattern grammar and usagesummary at run-time.procedure GRASPusageSummaryBuilding(query,proximity,N,C)(1)  queries=queryReformulation(query)(2)  GRASPresponses= ?for each query in queries(3)    interInvList=findInvertedFile(w1 in query)for each lemma wi in query except for w1(4)      InvList=findInvertedFile(wi)//AND operation on interInvList and InvList(5a)    newInterInvList= ?
; i=1; j=1(5b)    while i<=length(interInvList) and j<=lengh(InvList)(5c)       if interInvList[i].SentNo==InvList[j].SentNo(5d)         if withinProximity(interInvList[i].wordPosi,InvList[j].wordPosi,proximity)(5e)   Insert(newInterInvList, interInvList[i],InvList[j])else if interInvList[i].wordPosi<InvList[j].wordPosi(5f)   i++else //interInvList[i].wordPosi>InvList[j].wordPosi(5g)   j++else if interInvList[i].SentNo<InvList[j].SentNo(5h)          i++else //interInvList[i].SentNo>InvList[j].SentNo(5i)           j++(5j)     interInvList=newInterInvList//construction of GRASP usage summary for this query(6)    Usage= ?for each element in interInvList(7)       Usage+={PatternGrammarGeneration(query,element,C)}(8a)  Sort patterns and their instances in Usage in descending orderof frequency(8b)  GRASPresponse=the N patterns and instances in Usage withhighest frequency(9)    append GRASPresponse to GRASPresponses(10) return GRASPresponses983.3 Run-Time Usage Summary ConstructionOnce the word-to-sentence mappings and syntacticanalyses are obtained, GRASP generates the usagesummary of a query using the procedure in Figure2.In Step (1) we reformulate the user query intonew ones, queries, if necessary.
The first type ofquery reformulation concerns the language used inquery.
If it is not in the same language as C, wetranslate query and append the translations toqueries as if they were submitted by the user.
Thesecond concerns the length of the query.
Sincesingle words may be ambiguous in senses andcontexts or grammar patterns are closely associatedwith words?
meanings (Hunston and Francis, 2000),we transform single-word queries into theircollocations, particularly focusing on one wordsense (Yarowsky, 1995), as stepping stones toGRASP patterns.
Notice that, in implementation,users may be allowed to choose their owninterested translation or collocation of the queryfor usage learning.
The prototypes for first-language (i.e., Chinese) queries and Englishqueries of any length are at A2 and B3 respectively.The goal of cross-lingual GRASP is to assist EFLusers even when they do not know the words oftheir searches and to avoid incorrect querieslargely because of miscollocation, misapplication,and misgeneralization.Afterwards, we initialize GRASPresponses tocollect usage summaries for queries (Step (2)) andleverage inverted files to extract and generate eachquery?s syntax-based contexts.
In Step (3) we prepinterInvList for the intersected inverted files of thelemmas in query.
For each lemma wi within, wefirst obtain its inverted file, InvList (Step (4)) andperform an AND operation on interInvList(intersected results from previous iteration) andInvList (Step (5a) to (5j)4), defined as follows.First, we enumerate the inverted lists (Step (5b))after the initialization of their indices i and j andtemporary resulting intersection newInterInvList(Step (5a)).
Second, we incorporate a new instanceof (position, sentence), based on interInvList[i] andInvList[j], into newInterInvList (Step (5e)) if thesentence records of the indexed list elements arethe same (Step (5c)) and the distance between their2http://140.114.214.80/theSite/bGRASP_v552/3http://140.114.214.80/theSite/GRASP_v552/4These steps only hold for sorted inverted files.words are within proximity (Step (5d)).
Otherwise,i and j are moved accordingly.
To accommodatethe contexts of queries?
positional variants (e.g.,?role to play?
and ?role ~ play by?
for the query?play role?
), Step (5d) considers the absolutedistance.
Finally, interInvList is set for the nextAND iteration (Step (5j)).Once we obtain the sentences containing query,we construct its context summary as below.
Foreach element, taking the form ([wordPosi(w1), ?,wordPosi(wn)], sentence record) denoting thepositions of query?s lemmas in the sentence, wegenerate pattern grammar involving replacingwords in the sentence with POS tags and words inwordPosi(wi) with lemmas, and extracting fixed-window 5  segments surrounding query from thetransformed sentence.
The result is a set ofgrammatical patterns with counts.
Their lexicalrealizations also retrieved and displayed.The procedure finally generates top Npredominant syntactic patterns and their N mostfrequent lexical phrases as output (Step (8)).
Theusage summaries GRASP returns are aimed toaccelerate EFL learners?
language understandingand learning and lexicographers?
word usagenavigation.
To acquire more semantic-orientedpatterns, we further exploit WordNet and majorityvoting to categorize words, deriving the patternslike ?provide PERSON with.
?4 Experimental ResultsGRASP was designed to generate usagesummarization of a query for language learning.As such, GRASP will be evaluated over CALL.
Inthis section, we first present the setting of GRASP(Section 4.1) and report the results of differentconsulting systems on language learning in Section4.2.4.1 Experimental SettingWe used British National Corpus (BNC) as ourunderlying reference corpus C. It is a BritishEnglish text collection.
We exploited GENIAtagger to obtain the lemmas and POS tags of C?ssentences.
After lemmatizing and syntacticanalyses, all sentences in BNC were used to buildup inverted files and used as examples forgrammar pattern extraction.5Inspired by (Gamon and Leacock, 2010).99English (E) sentence with corresponding Chinese (C) translation answer to 1st blank  answer to 2nd blankC: ????????????
?E: Environmental protection has ___ impact ___.a profound on the EarthC: ????????????
?E: The real estate agent ___ record profit ___.made a on house sellingC: ?????????????
?E: They plan to release their new album in ___ futurethe near noneC: ???????????
?E: He waited for her for a long time in ___ attempt ___ again.an to see her4.2 Results of Constrained ExperimentsIn our experiments, we showed GRASP6  to twoclasses of Chinese EFL (first-year) college students.32 and 86 students participated, and were trainedto use GRASP and instructed to perform a sentencetranslation/composition task, made up of pretestand posttest.
In (30-minute) pretest, participantswere to complete 15 English sentences withChinese translations as hints, while, in (20-minute)posttest, after spending 20 minutes familiarizingword usages of the test candidates from us byconsulting traditional tools or GRASP, participantswere also asked to complete the same Englishsentences.
We refer to the experiments asconstrained ones since the test items in pre- andpost-test are the same except for their order.
Amore sophisticated testing environment, however,are to be designed.Each test item contains one to two blanks asshown in the above table.
In the table, the first itemis supposed to test learners?
knowledge on theadjective and prepositional collocate of ?haveimpact?
while the second test the verb collocatemake, subsequent preposition on, and precedingarticle a of ?record profit?.
On the other hand, thethird tests the ability to produce the adjectiveenrichment of ?in future?, and the fourth the in-between article a or possessive his and thefollowing infinitive of ?in attempt?.
Note that asexisting collocation reference tools retrieve anddisplay collocates, they typically ignore functionwords like articles and determiners, which happento be closely related to frequent errors made by thelearners (Nicholls, 1999), and fail to provide anoverall picture of word usages.
In contrast, GRASPattempts to show the overall picture withappropriate function words and word forms.We selected 20 collocations and phrases 7manually from 100 most frequent collocations in6http://koromiko.cs.nthu.edu.tw/grasp/7Include the 15 test items.BNC whose MI values exceed 2.2 and used themas the target for learning between the pretest andposttest.
To evaluate GRASP, half of theparticipants were instructed to use GRASP forlearning and the other half used traditional toolssuch as online dictionaries or machine translationsystems (i.e., Google Translate and Yahoo!
BabelFish).
We summarize the performance of ourparticipants on pre- and post-test in Table 1 whereGRASP denotes the experimental group and TRADthe control group.class 1 class 2 combinedpretest posttest  pretest  posttest  pretest posttestGRASP 26.4 41.9 43.6 58.4 38.9 53.9TRAD 27.1 32.7 43.8 53.4 39.9 48.6Table 1.
The performance (%) on pre- and post-test.We observe in Table 1 that (1) the partition ofthe classes was quite random (the differencebetween GRASP and TRAD was insignificantunder pretest); (2) GRASP summaries of words?contexts were more helpful in language learning(across class 1, class 2 and combined).
Specifically,under the column of the 1st class, GRASP helped toboost students?
achievements by 15.5%, almosttripled (15.5 vs. 5.6) compared to the gain usingTRAD; (3) the effectiveness of GRASP in languagelearning do not confine to students at a certainlevel.
Encouragingly, both high- and low-achieving students benefited from GRASP if wethink of students in class 2 and those in class 1 asthe high and the low respectively (due to theperformance difference on pretests).We have analyzed some participants?
answersand found that GRASP helped to reduce learners?article and preposition errors by 28% and 8%,comparing to much smaller error reduction rate 7%and 2% observed in TRAD group.
Additionally, anexperiment where Chinese EFL students wereasked to perform the same task but using GRASPas well as GRASP with translation information88http://koromiko.cs.nthu.edu.tw/grasp/ch100was conducted.
We observed that with Chinesetranslation there was an additional 5% increase instudents?
test performance.
This suggests to someextent learners still depend on their first languagesin learning and first-language information mayserve as another quick navigation index even whenEnglish GRASP is presented.Overall, we are modest to say that (in theconstrained experiments) GRASP summarizedgeneral-to-specific usages, contexts, or phrase-ologies of words are quite effective in assistinglearners in collocation and phrase learning.5 Applying GRASP to Error CorrectionTo demonstrate the viability of GRASP-retrievedlexicalized grammar patterns (e.g., ?play ~ role InV-ING?
and ?look forward to V-ING?)
in errordetection and correction, we incorporate them intoan extended Levenshtein algorithm (1966) toprovide broad-coverage sentence-level grammat-ical edits (involving substitution, deletion, andinsertion) to inappropriate word usages in learnertext.Previously, a number of interesting rule-basederror detection/correction systems have beenproposed for some specific error types such asarticle and preposition error (e.g., (Uria et al,2009), (Lee et al, 2009), and some modules in(Gamon et al, 2009)).
Statistical approaches,supervised or unsupervised, to grammar checkinghave become the recent trend.
For example,unsupervised systems of (Chodorow and Leacock,2000) and (Tsao and Wible, 2009) leverage worddistributions in general and/or word-specificcorpus for detecting erroneous usages while(Hermet et al, 2008) and (Gamon and Leacock,2010) use Web as a corpus.
On the other hand,supervised models, typically treating errordetection/correction as a classification problem,utilize the training of well-formed texts ((De Feliceand Pulman, 2008) and (Tetreault et al, 2010)),learner texts, or both pairwisely (Brockett et al,2006).
Moreover, (Sun et al, 2007) describes away to construct a supervised error detectionsystem trained on well-formed and learner textsneither pairwise nor error tagged.In contrast to the previous work in grammarchecking, our pattern grammar rules areautomatically inferred from a general corpus (asdescribed in Section 3) and helpful for correctingerrors resulting from the others (e.g., ?to close?
in?play ~ role to close?
), our pattern grammarlexicalizes on both content and function words andlexical items within may be contiguous (e.g., ?lookforward to V-ING PRP?)
or non-contiguous (e.g.,?play ~ role In V-ING?
), and, with word class(POS) information, error correction or grammaticalsuggestion is provided at sentence level.5.1 Error Correcting ProcessFigure 3 shows how we check grammaticality andprovide suggestions for a given text with accuratespelling.Figure 3.
Procedure of grammar suggestion/correction.In Step (1), we initiate a set Suggestions tocollect grammar suggestions to the user text Taccording to a bank of patternsPatternGrammarBank, i.e., a collection ofsummaries of grammatical usages (e.g., ?play ~role In V-ING?)
of queries (e.g., ?play role?
)submitted to GRASP.
Since we focus on grammarchecking at sentence level, T is heuristically split(Step (2)).For each sentence, we extract user-proposedword usages (Step (3)), that is, the usergrammatical contexts of ngram and collocationsequences.
Take for example the (ungrammatical)sentences and their corresponding POS sequences?he/PRP play/VBP an/DT important/JJ roles/NNSto/TO close/VB this/DT deals/NNS?
and ?he/PRPlooks/VBZ forward/RB to/TO hear/VB you/PRP?.Ngram contexts include ?he VBP DT?, ?play an JJNNS?, ?this NNS?
for the first sentence and ?lookforward to VB PRP?
and ?look forward to hearPRP?
for the second.
And collocation contexts forprocedure GrammarChecking(T,PatternGrammarBank)(1) Suggestions=?
?//candidate suggestions(2) sentences=sentenceSplitting(T)for each sentence in sentences(3)   userProposedUsages=extractUsage(sentence)for each userUsage in userProposedUsages(4)     patGram=findPatternGrammar(userUsage.lexemes,PatternGrammarBank)(5)     minEditedCost=SystemMax; minEditedSug=?
?for each pattern in patGram(6)        cost=extendedLevenshtein(userUsage,pattern)if cost<minEditedCost(7)            minEditedCost=cost; minEditedSug=patternif minEditedCost>0(8)       append (userUsage,minEditedSug) to Suggestions(9) Return Suggestions101the first sentence are ?play ~ role to VERB?
and?close ~ deal .
?For each userUsage in the sentence (e.g., ?play~ role TO VB?
and ?look forward to hear PRP?
),we first acquire the pattern grammar of its lexemes(e.g., ?play role?
and ?look forward to hear?)
suchas ?play ~ role in V-ing?
and ?look forward tohear from?
in Step (4), and we compare the user-proposed usage against the correspondingpredominant, most likely more proper, ones (fromStep (5) to (7)).
We leverage an extendedLevenshtein?s algorithm in Figure 4 for usagecomparison, i.e.
error detection and correction,after setting up minEditedCost and minEditedSugfor the minimum-cost edit from alleged error usageinto appropriate one (Step (5)).Figure 4.
Extended Levenshtein algorithm for correction.In Step (1) of the algorithm in Figure 4 weallocate and initialize costArray to gather thedynamic programming based cost to transformuserUsage into a specific pattern.
Afterwards, thealgorithm defines the cost of performingsubstitution (Step (2)), deletion (Step (3)) andinsertion (Step (4)) at i-indexed userUsage and j-indexed pattern.
If the entries userUsage[i] andpattern[j] are equal literally (e.g., ?VB?
and ?VB?
)or grammatically (e.g., ?DT?
and ?PRP$?9), no edit9ONE?S denotes possessives.is needed, hence, no cost (Step (2a)).
On the otherhand, since learners tend to select wrong wordform and preposition, we make less the cost of thesubstitution of the same word group, say from?VERB?
to ?V-ing?, ?TO?
to ?In?
and ?In?
to?IN(on)?
(Step (2b)) compared to a total edit (Step(2c)).
In addition to the conventional deletion andinsertion (Step (3b) and (4b) respectively), we lookahead to the elements userUsage[i+1] andpattern[j+1] considering the fact that ?with orwithout preposition?
and ?transitive or intransitiveverb?
often puzzles EFL learners (Step (3a) and(4a)).
Only a small edit cost is applied if the nextelements in userUsage and Pattern are ?equal?.
InStep (6) the extended Levenshtein?s algorithmreturns the minimum cost to edit userUsage basedon pattern.Once we obtain the costs to transform theuserUsage into its related frequent patterns, wepropose the minimum-cost one as its grammaticalsuggestion (Step (8) in Figure 3), if its minimumedit cost is greater than zero.
Otherwise, the usageis considered valid.
At last, the gatheredsuggestions Suggestions to T are returned to users(Step (9)).
Example edits to the user text ?he playan important roles to close this deals.
he looksforward to hear you.?
from our working prototype,EdIt10, is shown in Figure 5.
Note that we exploitcontext checking of collocations to cover longerspan than ngrams?, and longer ngrams likefourgrams and fivegrams to (more or less) helpsemantic checking (or word sense disambiguation).For example, ?hear?
may be transitive orintransitive, but, in the context of ?look forwardto?, there is strong tendency it is used intransitivelyand follows by ?from?, as EdIt would suggest (seeFigure 5).There are two issues worth mentioning on thedevelopment of EdIt.
First, grammar checkerstypically have different modules examiningdifferent types of errors with different priority.
Inour unified framework, we set the priority ofchecking collocations?
usages higher than that ofngrams?, set the priority of checking longerngrams?
usages higher than that of shorter, and wedo not double check.
Alternatively, one may firstcheck usages of all sorts and employ majorityvoting to determine the grammaticality of asentence.
Second, we further incorporate10http://140.114.214.80/theSite/EdIt_demo2/procedure extendedLevenshtein(userUsage,pattern)(1) allocate and initialize costArrayfor i in range(len(userUsage))for j in range(len(pattern))//substitutionif equal(userUsage[i],pattern[j])(2a)       substiCost=costArray[i-1,j-1]+0elseif sameWordGroup(userUsage[i],pattern[j])(2b)       substiCost=costArray[i-1,j-1]+0.5else(2c)       substiCost=costArray[i-1,j-1]+1//deletionif equal(userUsage[i+1],pattern[j+1])(3a)       delCost=costArray[i-1,j]+smallCostelse(3b)       delCost=costArray[i-1,j]+1//insertionif equal(userUsage[i+1],pattern[j+1])(4a)        insCost=costArray[i,j-1]+smallCostelse(4b)       insCost=costArray[i,j-1]+1(5)       costArray[i,j]=min(substiCost,delCost,insCost)(6) Return costArray[len(userUsage),len(pattern)]102Erroneous sentence EdIt suggestion ESL Assistant suggestionWrong word form?
a sunny days ?
a sunny NN a sunny dayevery days, I ?
every NN every dayI would said to ?
would VB would sayhe play a ?
he VBD none?
should have tell the truth should have VBN should have to tell?
look forward to see you look forward to VBG none?
in an attempt to seeing you an attempt to VB none?
be able to solved this problem able to VB noneWrong prepositionhe plays an important role to close ?
play ~ role IN(in) nonehe has a vital effect at her.
have ~ effect IN(on) effect on herit has an effect on reducing ?
have ~ effect IN(of) VBG none?
depend of the scholarship depend IN(on) depend onConfusion between intransitive and transitive verbhe listens the music.
missing ?to?
after ?listens?
missing ?to?
after ?listens?it affects to his decision.
unnecessary ?to?
unnecessary ?to?I understand about the situation.
unnecessary ?about?
unnecessary ?about?we would like to discuss about this matter.
unnecessary ?about?
unnecessary ?about?Mixtureshe play an important roles to close this deals.
she VBD; an JJ NN;play ~ role IN(in) VBG; this NNplay an important role;close this dealI look forward to hear you.
look forward to VBG;missing ?from?
after ?hear?noneTable 2.
Three common score-related error types and their examples with suggestions from EdIt and ESL Assistant.Figure 5.
Example EdIt responses to the ungrammatical.probabilities conditioned on word positions toweigh edit costs.
For example, the conditionalprobability of ?VERB?
being the immediatefollower of ?look forward to?
is virtually zero, butthe probability of ?V-ing?
is around 0.3.5.2 Preliminary Results in Error CorrectionWe examined three common error types in learnertext that are highly correlated with essay scores(Leacock and Chodorow, 2003; Burstein et al,2004), to evaluate EdIt, (see Table 2).
In Table 2,the results of a state-of-the-art checker, ESLAssistant (www.eslassistant.com/), are shown forcomparison, and information produced by bothsystems are underscored.
As indicated, GRASPretrieves patterns which are potential useful ifincorporated into an extension of Levenshtein?salgorithm to correct substitution, deletion, andinsertion errors in learner.6 SummaryWe have introduced a new method for producing ageneral-to-specific usage summary of the contextsof a linguistic search query aimed at acceleratinglearners?
grasp on word usages.
We haveimplemented and evaluated the method as appliedto collocation and phrase learning and grammarchecking.
In the preliminary evaluations we showthat GRASP is more helpful than traditionallanguage learning tools, and that the patterns andlexical bundles provided are promising in detectingand correcting common types of errors in learnerwriting.ReferencesMorton Benson, Evellyn Benson, and Robert Ilson.1986.
The BBI Combinatory Dictionary of English: AArticle:Related pattern grammar(a) of collocation sequences includes ?play ~ roleIN(in) NN?, ?play ~ role IN(in) DT?, ?play ~ roleIN(in) VBG?
and so on.
(b) of ngram sequences includes ?he VBD DT?, ?playan JJ NN?, ?this NN?, ?look forward to VBG PRP?and ?look forward to hear IN(from) PRP?
and so on.Grammatical/Usage suggestion:For sentence 1:(a) use the VBD of ?play?, (b) use the NN of ?roles?,(c) use the preposition ?in?
and VBG of ?close?,instead of ?to close?.
(d) use the NN of ?deals?For sentence 2:(a) insert the preposition ?from?
after ?hear?, (b) usethe ?VBG?
of ?hear?he play an important roles to close this deals.he looks forward to hear you.Type your article and push the buttom ?EdIt?
!103guide to word combinations.
Philadelphia: JohnBenjamins.Chris Brockett, William B. Dolan, and Michael Gamon.2006.
Correcting ESL errors using phrasal SMTtechniques.
In Proceedings of the ACL, pages 249-256.Jill Burstein, Martin Chodorow, and Claudia Leacock.2004.
Automated essay evaluation: the criteriononline writing service.
AI Magazine, 25(3): 27-36.Yu-Chia Chang, Jason S. Chang, Hao-Jan Chen, andHsien-Chin Liou.
2008.
An automatic collocationwriting assistant for Taiwanese EFL learners: a caseof corpus-based NLP technology.
CALL, 21(3): 283-299.Winnie Cheng, Chris Greaves, and Martin Warren.
2006.From n-gram to skipgram to concgram.
CorpusLinguistics, 11(4): 411-433.Martin Chodorow and Claudia Leacock.
2000.
Anunsupervised method for detecting grammaticalerrors.
In Proceedings of the NAACL, pages 140-147.Rachele De Felice and Stephen G. Pulman.
2008.
Aclassifer-based approach to preposition anddeterminer error correction in L2 English.
InProceedings of the COLING, pages 169-176.Philip Durrant.
2009.
Investigating the viability of acollocation list for students of English for academicpurposes.
ESP, 28(3): 157-169.John R. Firth.
1957.
Modes of meaning.
In Papers inLinguistics.
London: Oxford University Press, pages190-215.Michael Gamon, Claudia Leacock, Chris Brockett,William B.
Dolan., Jianfeng Gao, Dmitriy Belenko,and Alexandre Klementiev.
2009.
Using statisticaltechniques and web search to correct ESL errors.CALICO, 26(3): 491-511.Michael Gamon and Claudia Leacock.
2010.
Searchright and thou shalt find ?
using web queries forlearner error detection.
In Proceedings of the NAACL.Matthieu Hermet, Alain Desilets, and Stan Szpakowicz.2008.
Using the web as a linguistic resource toautomatically correct lexico-syntatic errors.
InProceedings of the LREC, pages 874-878.Susan Hunston and Gill Francis.
2000.
PatternGrammar: A Corpus-Driven Approach to the LexicalGrammar of English.
Amsterdam: John Benjamins.Jia-Yan Jian, Yu-Chia Chang, and Jason S. Chang.
2004.TANGO: Bilingual collocational concordancer.
InACL Poster.Adam Kilgarriff, Pavel Rychly, Pavel Smrz, and DavidTugwell.
2004.
The sketch engine.
In Proceedings ofthe EURALEX, pages 105-116.Chong Min Lee, Soojeong Eom, and Markus Dickinson.2009.
Toward analyzing Korean learner particles.
InCALICO Workshop.Claudia Leacock and Martin Chodorow.
2003.Automated grammatical error detection.
In M.D.Shermis and J.C. Burstein, editors, Automated EssayScoring: A Cross-Disciplinary Perspective, pages195-207.Vladimir I. Levenshtein.
1966.
Binary codes capable ofcorrecting deletions, insertions and reversals.
SovietPhysics Doklady, 10, page 707.Diane Nicholls.
1999.
The Cambridge Learner Corpus ?error coding and analysis for writing dictionaries andother books for English Learners.John M. Sinclair.
1987.
The nature of the evidence.
In J.Sinclair (ed.)
Looking Up.
Collins: 150-159.Frank Smadja.
1993.
Retrieving collocations from text:Xtract.
Computational Linguistics, 19(1): 143-177.Michael Stubbs.
2004.
Athttp://web.archive.org/web/20070828004603/http://www.uni-trier.de/uni/fb2/anglistik/Projekte/stubbs/icame-2004.htm.Guihua Sun, Xiaohua Liu, Gao Cong, Ming Zhou,Zhongyang Xiong, John Lee, and Chin-Yew Lin.2007.
Detecting erroneous sentences usingautomatically mined sequential patterns.
InProceedings of the ACL, pages 81-88.Joel Tetreault, Jennifer Foster, and Martin Chodorow.2010.
Using parse features for prepositions selectionand error detection.
In Proceedings of the ACL, pages353-358.Nai-Lung Tsao and David Wible.
2009.
A method forunsupervised broad-coverage lexical error detectionand correction.
In NAACL Workshop, pages 51-54.Larraitz Uria, Bertol Arrieta, Arantza D. De Ilarraza,Montse Maritxalar, and Maite Oronoz.
2009.Determiner errors in Basque: analysis and automaticdetection.
Procesamiento del Lenguaje Natural,pages 41-48.David Wible and Nai-Lung Tsao.
2010.
StringNet as acomputational resource for discovering andinvestigating linguistic constructions.
In NAACLWorkshop, pages 25-31.David Yarowsky.
1995.
Unsupervised word sensedisambiguation rivaling supervised methods.
InProceedings of the ACL, pages 189-196.104
