Generation of Referring Expression Using Prefix Tree StructureSibabrata Paladhi                                   Sivaji BandyopadhyayDepartment of Computer Sc.
& Engg.
Department of Computer Sc.
& Engg.Jadavpur University, India                              Jadavpur University, Indiasibabrata_paladhi@yahoo.com                        sivaji_cse_ju@yahoo.comAbstractThis paper presents a Prefix Tree (Trie)based model for Generation of ReferringExpression (GRE).
The existing algorithmsin GRE lie in two extremities.
Incrementalalgorithm is simple and speedy but less ex-pressive in nature whereas others are com-plex and exhaustive but more expressive innature.
Our prefix tree based model notonly incorporates all relevant features ofGRE (like describing set, generating Boo-lean and context sensitive description etc.
)but also try to attain simplicity and speedproperties of Incremental algorithm.
Thusthis model provides a simple and linguisti-cally rich approach to GRE.1 IntroductionGeneration of referring expression (GRE) is animportant task in the field of Natural LanguageGeneration (NLG) systems (Reiter and Dale,1995).
The task of any GRE algorithm is to find acombination of properties that allow the audienceto identify an object (target object) from a set ofobjects (domain or environment).
The propertiesshould satisfy the target object and dissatisfy allother objects in the domain.
We sometimes call itdistinguishing description because it helps us todistinguish the target from potential distractors,called contrast set.
When we generate any naturallanguage text in a particular domain, it has beenobserved that the text is centered on certain objectsfor that domain.
When we give introductory de-scription of any object, we generally give fulllength description (e.g.
?The large black hairydog?).
But the later references to that object tend tobe shorter and only support referential communica-tion goal of distinguishing the target from otherobjects.
For example the expression ?The blackdog?
suffices if the other dogs in the environmentare all non black.
Grice, an eminent philosopher oflanguage, has stressed on brevity of referentialcommunication to avoid conversational implica-ture.
Dale (1992) developed Full Brevity algorithmbased on this observation.
It always generatesshortest possible referring description to identifyan object.
But Reiter and Dale (1995) later provedthat Full Brevity requirement is an NP-Hard task,thus computationally intractable and offered analternative polynomial time Incremental Algo-rithm.
This algorithm adds properties in a prede-termined order, based on the observation that hu-man speakers and audiences prefer certain kinds ofproperties when describing an object in a domain(Krahmer et al 2003).
The Incremental Algorithmis accepted as state of the art algorithm in NLGdomain.
Later many refinements (like Boolean de-scription and set representation (Deemter 2002),context sensitivity (Krahmer et al2002) etc) havebeen incorporated into this algorithm.
Several ap-proaches have also been made to propose an alter-native algorithmic framework to this problem likegraph-based (Krahmer et al 2003), conceptualgraph based (Croitoru and Deemter 2007) etc thatalso handle the above refinements.
In this paper wepropose a new Prefix Tree (Trie) based frameworkfor modeling GRE problems.
Trie is an orderedtree data structure which allows the organization ofprefixes in such a way that the branching at eachlevel is guided by the parts of prefixes.
There areseveral advantages of this approach: 1) Trie datastructure has already been extensively used inmany domains where search is the key operation.2) The structure is scalable and various optimizedalgorithms are there for time, space optimizations.In this paper it is shown how scenes can berepresented using a Trie (section 2) and how de-scription generation can be formalized as a searchproblem (section 3).
In section 4 the algorithm isexplained using an example scene.
In section 5, thebasic algorithm is extended to take care of differentscenarios.
The algorithm is analyzed for time com-697plexity in section 6 and conclusion is drawn in sec-tion 7.2 Modeling GRE Using Trie StructureIn this section, it is shown how a scene can be rep-resented using a trie data structure.
The scheme isbased on Incremental algorithm (Reiter and Dale1995) and incorporates the attractive properties(e.g.
speed, simplicity etc) of that algorithm.
Laterit is extended to take care of different refinements(like relational, boolean description etc) that couldnot be handled by Incremental algorithm.
Reiterand Dale (1995) pointed out the notion of?PreferredAttributes?
(e.g.
Type, Size, Color etc)which is a sequence of attributes of an object thathuman speakers generally use to identify that ob-ject from the contrast set.
We assume that the ini-tial description of an entity is following this se-quence (e.g.
?The large black dog?)
then the laterreferences will be some subset of initial description(like ?The dog?
or ?The large dog?)
which is de-fined as the prefix of the initial description.
So, wehave to search for a prefix of the initial full lengthdescription so that it is adequate to distinguish thetarget object.
Following the Incremental versionwe will add properties one by one from the?PreferredAttributes?
list.
In our model, the rootconsists of all entities in the domain and has emptydescription.
Then at each level, branching is madebased on different values of corresponding pre-ferred attribute.
The outgoing edge is labeled withthat value.
For example, at the first level, branch-ing is made based on different values of ?Type?attribute like ?Dog?, ?Cat?, ?Poodle?
etc.
A node inTrie will contain only those objects which have theproperty(s) expressed by the edges, constituting thepath from root to that node.
After construction ofthe Trie structure for a given domain in this way,referring expression generation problem for an ob-ject r is reduced to search the tree for a node whichconsists of r and no other object.
Description for rcan be found from the search path itself as we havesaid earlier.
Now we will introduce some notationsthat we will use to describe the actual algorithm.Let D be the Domain, r be the target object and Pbe the ?PreferredAttributes?
List.
 Ni   = {d |d?D and d is stored at node Ni} where Ni is an i-thlevel node.
Obviously  No   = D since No is rootnode.
E(Ni, Nki+1) is an edge between parent nodeNi and Nki+1, k-th child of that node (considering anenumeration among children nodes).
Since everyedges in Trie are labeled, thus {E} ?
{N} x L x{N}, where {E} and {N} are set of all edges andnodes respectively in the tree and L is the set ofattribute values.
Let Val(E(Ni, Nki+1)) denotes thelabel or value of the edge and  Val(E(Ni, Nki+1)) = {d | d?D and d is satisfied by the edge value}i.e.
the set contains those objects who have thisproperty.
We define  Nki+1  =  Ni ?
 Val(E(Ni, Nki+1)) where Ni and Nki+1 are par-ent and child node respectively.
Similarly  Nki   = Ni-1   ?
  Val(E(Ni-1, Nki))  .
Ultimately, wecan say that ?
i  Ni   =  No ?
 Val(E(No,N1)) ?
??
?
 Val(E(Ni-1,Ni))  .
Since our con-struction is basically a tree, each node is reachablefrom root and there exists a unique path from rootto that node.
So, for each node in the tree we willget some description.
We will formulate referringexpression construction as search in the con-structed tree for the node min(k){Nk} such that  Nk = {r}.
If Nk is leaf node then description of r willbe same with the full description but if it is an in-termediate node then description is some properprefix of initial description.
But the point is that, inboth cases the later reference is prefix of initial one(as both ?ab?
and ?abc?
are prefixes of ?abc?
).3 Basic AlgorithmBased on above discussions, algorithms are devel-oped for construction of Trie from the domain andgeneration of reference description for any objectin that domain.
The Trie construction algorithmConstructTrie(D,P,T) is shown in figure 1, Refer-ring expression generation algorithm MakeRe-fExpr(r,p,T,L) is shown in figure 2, where T is anode pointer and p is pointer to parent of that node.Our algorithm MakeRefExpr returns set of attrib-ute-values L to identify r in the domain.
As dis-cussed earlier, it is basically a node searching algo-rithm.
In course of searching, if it is found that anintermediate node N doesn?t have r i.e.
r?
 N then our search will not move forward through thesubtree rooted at N. Our search will proceedthrough next level iff r?
 N  .
For a node Nk, ifwe get  Nk   = {r} then we have succeeded andour algorithm will return L, set of descriptions forthat node.
If there is no distinguishing descriptionexists for r, then ?
(null) will be returned.
We698would like to point out that our algorithm will findout only one description that exists at the minimumlevel of the tree.
Moreover, a description is addedto L only if it is distinguishing i.e.
the connectingedge must remove some contrasting object(s).Thus, the child node should contain less number ofobjects than that of parent node.
In this case, cardi-nality of parent Ni (Card(Ni)) will be greater thanthat of child (Card(Ni+1)).
This condition is in-cluded in our algorithm and if (Card (P?N)) >Card (T?N) holds then only the value is addedP->N and T->N respectively represents parent andchild node.
After finding a distinguishing descrip-tion for r, search will neither move further downthe tree nor explore the remaining branches of thecurrent node.
Search will explore the next branchonly if the search in current branch returned NULLdescription i.e.
when L?
= ?
in the algorithm.
Ifwe reach a leaf node and that contains r along withother objects then it is not possible to distinguishr?.
In that case, the algorithm returns NULL indi-cating that no description exists at all.
It has beenlater shown that some distinguishing descriptionmay still exist and the algorithm will be modifiedto find that.
It should be mentioned that once theprefix tree is constructed offline, it can be usedrepetitively to find description for any object in thedomain throughout the text generation phase.
OurMakeRefExpr() algorithm is very simple and itdoesn?t employ any set theoretic operation, whichis a non trivial task, to find current contrast set atevery steps of algorithm.
In existing algorithms,computing referential description for every objectrequire computing similar things (like finding cur-rent contrast set, ruled out objects) again and again.And it has to be repeated every time the object isreferred.
It is not possible to generate descriptiononce, store it and use it later because of the factthat domain may also change in course of time(Krahmer, 2002).
That?s why every time we wantto refer to ?r?, such rigorous set operations need tobe computed.
But in our prefix tree structure, oncethe tree is constructed, it is very easy to find de-scription for that object using simple tree searchfunction.
It is also very easy to add/delete objectsto/from domain.
We have to follow just the initialproperties of that object to find the proper branch-ing at each level, followed by addition /deletion ofthat object to /from relevant nodes, which is essen-tially a search operation.
The disadvantage of ouralgorithm is that space complexity is high but itcan be tackled using bit Vector representation ofindividual nodes of the prefix tree.
Besides, severalmethods are there for compressing Trie structure.But these optimization techniques are beyond thescope of our current discussion.4 Formalizing A Scene using Prefix TreeConsider an example scene in figure 3, from[Krahmer 2002].
In this scene, there is a finite do-main of entities D. Let D = {d1, d2, d3, d4}, P ={Type, Size, Color} and values are Type = {dog,cat}; Size = {small, large}; Color = {black, white}.A scene is usually represented as a database (orConstructTrie(D, P, T) {If (D = ?
?
P = ?
)Then StopElseCreate a node N at TSet  N   = DExtract front attribute Ai from list PP?
=   P ?
{ Ai }For each value Vj  of  attribute  Ai  doCreate Edge Ej with label Vj as T?NextjDj?
= D ?
 Val(Ej) ConstructTrie(Dj?
, P?, T?Nextj)End ForEnd If}Figure 2.
Expression Generation AlgorithmFigure 1.
Prefix Tree Generation AlgorithmMakeRefExpr(r, P, T, L) {If ( r ?
 T?N  )Then  L ?
?Return LElse If ({r} =  T?N  )L = L ?
Val(P?Ej )Return LElse If (isLeaf (T) ?
{r} ?
 N  )Then L ?
?Return LElse {If (Card(P?N) > Card (T?N))Then L = L ?
Val(P?Ej )P = TFor each outgoing edge T?
Nextj (Ej)  doL?
= MakeRefExpr(r, P,T?
Childj, L)If (L?
??
)Then Return L?}
}699knowledge base) listing the properties of each ele-ment in D. Thus:d1 : ?
Type : dog ?
, ?
Size : small ?
, ?
Color: white ?d2 : ?
Type : dog ?
, ?
Size : large ?
, ?
Color: white ?d3 : ?
Type : dog ?
, ?
Size : large ?
, ?
Color: black ?d4:  ?
Type : cat ?
,  ?
Size: small ?
,  ?
Color: white ?Now it will be shown how our MakeRefExpr()algorithm will find a description for a target objectr.
Let r = {d1}.
In the first phase, starting fromroot, edge labeled D is traversed.
Since d1 exists inthe node and D discards some objects (d4), D isdistinguishing description and it is added to L. Inthe next phase the node connected by the edge la-beled L does not contain d1 so search will not pro-ceed further.
Rather the node connected by theedge labeled S contains d1.
Since, d1 is the onlyobject, then we are done and the referring expres-sion is ?The small dog?.
But for d2, we have tosearch upto the leaf node which generates the de-scription ?The large white dog?.Figure 3.
Scene Representation5 Extension of Basic Algorithm5.1 Specifying Overlapping ValuesDeemter (2002) has shown incompleteness of In-cremental algorithm in case of overlapping values.Due to vagueness of properties, sometimes it ishard to classify an object in a particular class.
Con-sider the example scene D = {a,b,c,d} Color:{Red(a,b); Orange(a,c,d)} Size: {Large(a,b);Small(c,d)}.
In this case a can not be properly clas-sified by Color type.
Incremental algorithm alwaysselect Red(a,b) at first phase, since it rules outmaximum distractors and returns failure because itcan?t distinguish a from b at second phase.
Deem-ter(2002) suggested inclusion of all overlappingvalues that are true of target while also removingsome distractors.
So, referring expression for a is?The red orange desk?.
But it fails to obey Griceanmaxims of conversational implicature.
We con-sider the failure as ?Early Decision?
problem anddefer the decision making in our model.
We keepin our mind the fact that human beings seldom takeinstantaneous decision.
Rather they consider allopportunities in parallel and take decision in thefavor of the best one at later point of time.
Since,our algorithm searches in parallel through allpromising branches until some description isfound; it mimics the capabilities of human mind toconsider in parallel.
Our algorithm will generate?The large orange desk?
which will help audiencesto better identify the desk.
The execution sequenceis shown in figure 4.Figure 4.
Dealing with overlapping values5.2 Describing Set of ObjectsGeneration of referring description for a set of ob-jects is very important in NLG.
Deemter?s (2002)suggestion can be easily incorporated into ourframework.
We will represent target r as set of ob-jects.
Now our algorithm will try to find a node inthe tree which only consists of all objects in the setr.
In this way, we can find a distinguishing de-scription for any set, for which description exists.In figure 3, the description for the set {d2,d3} is?The large dogs?.
Thus, our basic algorithm is ableto describe set of objects.
In case of set like {d2, d3,d4} where there is no separate node consisting allthe object, we need to partition the set and finddescription for individual set.
In our case the pos-sible partitions are {d2, d3} and {d4} for whichseparate nodes exist.7005.3 Boolean DescriptionsDeemter (2002) shown that Incremental algorithmis only intersectively complete.
But he argues thatother Boolean combination of properties can beused to generate description for an object.
Considerthe example from (Deemter, 2002).
Let D = {a, b,c, d, e} Type: {Dog(a,b,c,d,e); Poodle(a,b)} Color:{Black(a,b,c); White(d,e)} and r = {c}.
In this sce-nario Incremental algorithm is not able to indi-viduate any of the animals.
However a descriptionfor c exists, ?The black dog that is not a poodle?.Since {c} = [[Black]] ?
[[ ?
Poodle]].
Deemter(2002) has modified the Incremental algorithm byadding negative values for each attribute.
Now wewill show that our basic algorithm can be modifiedto take care of this situation.
In our basic algorithmConstructTrie(), we add branches at each level fornegative values also.
In this case our simple rou-tine MakeRefExpr() is able to find boolean de-scription while remaining as close as to Incre-mental algorithm.
In figure 5, we show part of thetrie structure, which is generated for the abovescene.
The dashed arrows show the alternativesearch paths for node containing {c}.Figure 5.
Trie structure (Partial) incorporatingnegation of  propertiesFor referring objects using disjunction of proper-ties we have do same thing as negations.
We haveto extend our prefix tree structure by adding extraedges at different levels for making implicit infor-mation explicit as described in [Krahmer 2002].5.4 Incorporating Context SensitivityKrahmer and Theune [2002] have added the notionof context sensitivity into GRE.
Earlier algorithmsassumed that all objects in environment are equallysalient.
Krahmer and Theune refined the idea byassigning some degree of salience to each object.They proposed that during referring any object, theobject needs to be distinguished only from thoseobjects which are more salient (having higher sali-ence weight).
An object that has been mentionedrecently, is linguistically more salient than otherobjects and can be described using fewer proper-ties (?The dog?
instead of ?The large black hairydog?).
They introduced the concept of centeringtheory, hierarchical focus constraints in the field ofNLG and devised a constant function mapping sw:D ??
, where sw is salience weight function, D isdomain and ?
is set of natural numbers.
We canincorporate this idea into our model easily.
In eachnode of the prefix tree we keep a field ?salienceweight?
(sw) for each of the object stored in thatnode in the form (di, swi).
During describing anobject if we find a node that is containing r whereit is the most salient then we need not traversehigher depth of the tree.
So, we have to modifyMakeRefExpr() algorithm by adding more condi-tions.
If the current node is N and both 1) r?
 N and 2) ?
d?
 N   (d ?
r ?
sw(d) < sw(r)) holdthen r is the most salient and the edges constitutingthe path from root to N represents distinguishingdescription for r. In figure 6, a is most salient dogand referred to as ?The dog?
whereas b is referredto as ?The small dog?.Figure 6:  Trie structure (Partial) representing Con-text Sensitivity5.5 Relational DescriptionsRelational descriptions are used to single out anobject with reference to other one.
For example?The cup on the table?
is used to distinguish a cupfrom other cups which are not on the table.
Daleand Haddock (1991) first offer the idea of rela-701tional description and extend Full Brevity algo-rithm to incorporate this idea.
Later Krahmer et al(2003) Graph based framework for generating rela-tional description.
We follow Krahmer (2002) anddenote relations as Spatial: {In(a,b); Left_of(c,d)}etc.
Then we treat ?Spatial?
as another attribute andconsider ?In?, ?Left_of?
as different values for thatattribute.
In this way, our basic algorithm itself iscapable of handling relational descriptions.
Theonly modification that we add that when a relationR is included, the MakeRefExpr() should becalled again for the relatum.
Thus, if Val(E(Ni,Nki+1)) expresses a relation of r with r?
then wehave to call MakeRefExpr (r?,p,T,L) again to finddescription for  r?.5.6 Modeling Full BrevityIn this section, we will show that our prefix treestructure can be so modified that it can generateshortest possible description which is requirementof Full Brevity (Dale, 1992).
Consider a scenewhere a domain is identified by set of n attributes{A1, A2?An}.
We can generate n!
number of dif-ferent permutations of Ai?s ?
i?
[1,n].
We con-sider each permutation as different PreferredAt-tributes list Pk and generate all possible prefixtrees Tk for each Pk ?
k?
[1,n!]
for same domainD.
Now, we connect roots of all trees with a com-mon dummy root node with edges having emptydescription (?).
Now, if we search the branches ofnew combined tree in parallel, it?s obvious that wecan always find the target node at lowest possiblelevel.
Thus we can generate shortest length de-scription using our algorithm.6 Complexity of The AlgorithmLet the domain entities are identified by a numberof attributes and each attribute has on the averagek number of different values.
So, our Con-structTrie() algorithm takes ?
(ka) time.
Now wewill consider different cases for analyzing the timecomplexity of our MakeRefExpr() algorithm.1) In case of non overlapping properties, oursearch tree will be pruned at each level by a factorof k. Thus the time complexity will be ?
(logk(ka))= ?
(a) which is linear.2) In case of overlapping properties, we have tosearch whole tree in worst case (although in aver-age cases also there will be large pruning, as foundfrom test cases) which will take ?
(ka) time.3) In case of achieving full brevity requirement,both time and space complexity will be exponen-tial as in the original algorithm by Dale (1992).7 ConclusionsIn this paper, we present a new Prefix tree (Trie)based approach for modeling GRE problems.
Weconstruct the trie in such a way that a node at a par-ticular level consists of only those objects whichare satisfied by values of the edges, constitutingthe path from root to that node.
We formulate de-scription generation as a search problem.
So, whenwe reach the target node, the attribute values corre-sponding to the edges in the path automaticallyform the distinguishing description.
Different sce-narios of GRE problems like representation of set,boolean descriptions etc.
is taken care of in thispaper.
We have shown that in simple non overlap-ping scenarios, our algorithm will find distinguish-ing description in linear time.8 ReferencesE.
Krahmer and M. Theune.
2002.
Efficient ContextSensitive Generation of Referring Expressions.
CSLIPubl, Stanford : 223 ?
264E.
Krahmer, S. van Erk and A. Verlag.
2003.
Graphbased Generation of Referring Expressions Computa-tional Linguistics, 29(1): 53-72H.
Horacek.
2004.
On Referring to Set of Objects Natu-rally.
Proceedings of Third INLG, Brokenhurst, U.K:70-79M.
Croitoru  and van Deemter.
2007.
A conceptualGraph Approach to the Generation of Referring Ex-pressions.
Proceedings of IJCAI 2007 : 2456-2461R.
Dale and N. Haddock.
1991.
Generating ReferringExpressions containing Relations.
Proceedings ofFifth ACL- EACL conference, 161-166R.
Dale.
1992.
Generating Referring Expressions:Building Descriptions in a Domain of Objects andProcesses.
MIT PressR.
Dale  and E. Reiter.
1995.
Computational Interpreta-tions of the Gricean Maxims in the generation of Re-ferring Expressions.
Cognitive Science (18): 233 ?263van Deemter.
2002.
Generating Referring Expressions:Boolean Extensions of Incremental Algorithm.
Com-putational Linguistics 28(1): 37-52702
