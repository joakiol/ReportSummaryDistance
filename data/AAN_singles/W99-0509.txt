An Overt Semantics with a Machine-guided Approach for RobustLKBsEve lyne  V iegasNew Mexico  S ta te  Umvers l tyComput ing  Research  LaboratoryLas Cruces,  NM 88003USAwegas@crl nmsu eduAbst rac tIn this paper, we report on our experience in build-mg computational semantic lexicons for use in NLPapplications In a machine-graded approach, thecomputer educes part of the semantic knowledgeto be acquired by an acqulrer An overt semanticscan help predict the syntactic behavior of words Byovert semantics we mean applying the hnkmg or lexl-cal rules at the semantic level and not on lexlcal baseforms More specffically~ we address the differentstrategies of acqms~tlon arguing for an application-driven, training-intensive effort We also report onhow to develop lexicons using off the shelf resources,and address multlhngual issues We will try to pro-vide an assessment of the difficulties we encounteredand some directions to bypass them1 In t roduct ionOur experience in building computational semanticlexlcons which are used by Natural Language Pro-cessmg (NLP) systems comes from Mlkrokosmos,a knowledge-based machine translation system, 1where texts from Spanish and Chinese are translatedinto Enghsh Mlkr0k~n~os adopts an xnterhngua-based approach (Nlrenfurg et al 1992) and all lexi-cons can be used for multdmgual nalysis and gener-atmn each word is mapped to an mterhngua struc-ture The lexicons built for Mlkrokosmos are multi-purpose mul t lhngua l  to support translation ormultflmgual generatmn tasks, reusable,  that is, ap-phcable to several NLP tasks~ (e g, generation, anal-ysis, information extraction), and mainta inable ,that Is, supporting semi-automatic a quisition andrestructuring of the lexiconsThe content of the Lexlcal Knowledge Base (LKB)~s essentially the same ~rrespective of a particularapplication The types of information important foranalysis and generation might differ, as suggested byDale and Melhsh (1998) For instance, recording allthe senses of a lexeme is more important for analy-sis than generation, conversely, knowing styhstlc m-formation on words such as hzghfalutm or formal m1For a descnptmn of Mlkrokosmos, seeh t tp / / c r l  nmsu edu/Research/Pro jects /nukro/mdex htmlimportant for generation (Hovy, 1988) The contentof a multl-purpose LKB is apphcatlon Independent(modulo its indexing m analysis the LKB Is Indexedon lexemes whereas for generation the LKB is in-dexed on concepts) We argue, m section 2 that theacquisition process ~s apphcatmn-dependent Mole-over we argue that defining the meamng of a wordfor NLP systems requires a training-intensive effoltIn other words, the fact that we, as humans, under-stand texts does not entail that we can determinethe "computational" meaning of a word Chomsklant rees  a re  l ingu is ts '  const ruc ts ,  not  Innate  s t ruc turesA hngmst must be trained to be able to build syn-tactic patterns (e g,  trees) In computational se-mantics, the same rule applies one must be trainedto build the corresponding semantics (e g frames,predicates, ) for a word In order to approachthe "computational" meaning of a word, training Isthe most important means we have to date to en-sure consistency among acquuers Other means areto adopt an overt semantics with a machine-guidedapproach which directs as much as possible the ac-qulrer (Section 3) This machine guided approachcould also act behind the ' back" of an acquner "cor-recting ~' some mc0nslstencms m lexmal descnptlonsbetween acqmrers, as will be shown m Sectmn 6In Section 4, we &scuss our use of off the shelf le-sources, such as WordNet (Miller, 1990), to accel-erate the machine-graded acqmsltlon of the Enghshlexicon by taking advantage of the existing databaseof synsets 2 whmh provide synonym lists for a lexemeWe also show how a semantic-based approach, canhelp predict the syntactic behavior of words Notethat the reverse (predicting semantms from syntax)is not true, as some experiments on Levm's work(1993) have shown (Sectmn 4) In Sectmn 5, we ad-dress mulUlmgual issues in lexicon development2 App l i ca t ion -dr iven  Acqu is i t ionThe semantics of an entry is an underspecffied TextMeaning Representation (TMR) fragment (e g,  De-2Synsets represent WordNet's building blocks whmh arewords, synonyms or Rear-synonyms, that can be used to referto a given concept (Miller, 1990)62\[\]fnse and Nlrenburg, 1991) Th,s TMR fragment canbe a concept from the ontology or some lnterhnguastructures such as att,tudes, modahtms, aspects, setsand TMR relatmns (addltion, enumeratlon, com-pamson) Concepts and lnterhngua structures canappear together or independently The ontology,to which lexemes are mapped, conmsts of concepts(named sets of property-value pairs) organized hl-erarchmally along subsumptlon hnks, w~th an aver-age of 14 relational hnks (such as ISA, SUBCLASS,AGENT, THEME-OF, HEADED-BY, HAS-MEMBER)per concept (Mahesh, 1996) In a multflmgual enw-ronment, the main practical advantage of connect-mg the lexlcon to an ontology is cost-effect,veness,as only the "language-dependent" propertms have tObe acquired when adding new natural affh~iages tothe systemThe mapping between a word and the ontologyis the most difficult task of lexicon acquisition, andrequires to develop the most cost-effective approachin terms of trmmng and strategms2 1 Impor tance  of Tra in ingThe expemment reported below shows that trainingis essential to determine the "computational" mean-mg of a word A native spea\]~er of Spanish, who hadnot taken part m the lexacon traanmg process, wasasked to add some senses to entries m the Spanishlexicon Thls was mainly done for testing the ana-lyzer, as there were only 23 out of 167 words whichwere ambiguous m one text we were analyzing Butwe also d~scovered thls was a very useful exercise fortesting the quahty of a semantic lexiconThe list of added senses was reviewed by two com-putational hngmsts, one in charge of supervising thetraining and the other with proficiency m our frame-work who had seen entries as they were used by theanalyzer but had not taken part to the training pro-cess either The untrained acqmrer, hereafter UN-ACQ, added a total of 111 to 55 open class wordsor so Among these 55 words where ambiguity hadbeen added, 33 were already ambiguous in the Span-zsh lexiconAfter a closer look at the Spanish lexicon, and atthe senses retrieved by the semantic analyzer, andafter doing an on-hne corpora search, the compu-tational hngulsts accepted less than 20 new sensesamong the 111 suggested This "overge,aeratlor~" ofsenses by UNACQ had different origins 1) the ana-lyzer did not present all the senses from the Span-lsh lexicon to UNACQ, it only presented the onesthat were accepted after syntactic binding, u) thesenses added by UNACQ were "equivalent" to thesenses already in the Spanish lexicon, but not rec-ogmzed by UNACQ, as they were acquired as "un-specffied" in the Spanish lexicon, m) UNACQ hard-coded non-hteral meanings of the words, iv) the ad-dition of senses was MRD-dnven UNACQ acquiredthe list of meanings provzded by the Spanlsh-EnghshLarousse and Colhns, adopt,ng an enumeration ap-proach Such a task Is not superficial, it ensures thatthe quahty of the core lexicon ,s good enough so thatit can serve as a basis for lexicon expansion tech-tuques, some of which we develop below (see Vmgas(1999) for the choices an acqu,rer faces when work-mg out the semantic mapping Of a word)2.2 S t ra tegmsThere are mainly two approaches to word sense as-signment corpus-dr,yen and mental-driven Theformer is better adapted to braiding lexicons usedm analysis, whereas the latter better suits lexiconsto be used in generation We refer to Kllganff (1997)for the corpus-driven approach, and discuss m thispaper the mental-driven.approach A mental-drivenor thesaurus-drlven approach consists m groupingtogether lexemes which share the same meaning Inorder to ensure consistency among acqulrers' map-pings we have divided the process of acqu,rmg a coin-putatlonal semantic lexicon into two phases pre-acquisition and acquisition There is still time torevise a pre-acqulred mapping at acquis,tlon time, ifneeded2.3 The  Pre -Acqu is i tmn PhaseFor a generatmn lexicon, the method of preparingthe pre-acqulsltlon files can be as follows 1) extractall concepts from the ontology, n) lexlcahze them us-mg on-hne thesauri, dlctlonanes and native speak-ers' lntultmns, m) order pre-acqulsltion files accord-mg to the semantic Mapping-Tag (see below)A pre-acqmmtion record includes 7 fields Seman-tics, Mapping-Tag, Lexeme, POS, Translations, Fie-quency_, and Polysemy-CountThe Semantics field includes only the ontologicalhead concept, in which the word sense should beanchored (no selectlonal restrictions or other ptop-ertms are specified at this stage) The Mapping-Tagfield (see below) describes the type of connectloabetween the word sense and its conceptual mean-mg some word senses are directly mapped ("dim"map) to a single concept in the ontology, wheleasthe meaning of some other word senses is descllbedthrough the combination of concepts hnked vm prop-ertles (relations or attributes) We defined seventags which flag the entry for a specific task For m-stance, "devb" (deverbal) is used primarily for nounsand adjectives when their meaning is a compositionof a filler and an event (e g bombing, readable),"asp" (aspecttral) is used for true aspectuals (e gbegin) and also with actions expressing aspectual-lty (e g stare, duration prolonged) The Transla-tmns field includes an English translation (for lan-guages other than English) Frequency, POS andpolysemy count are extracted automatically, usingon-hne large corpora for frequency, and WordNet for?
.
i nmm63the part of speech and the polysemy count Bihn-gum dictionaries, filtered by a native speaker of theforeign language, are used for the translations intoEnglish (for the acquisition of languages other thanEnglish)In order to increase speed at acqulsitmn time, eachacqmrer works on one type of Mapping-Tag at atime For instance, some acqmrers work on typeOBJECT Type OBJECT call only be lexlcahzed intonouns, e g DEVICE -+ devzce instrument tool apph-ance Others work on the type EVENT ~VENTScan be lexlcahzed into nouns, e g EXPLODE --~bombzn9, bombardment, or into verbs bomb, bombard,drop_bombs_on, throw_bombs_at In order to increaseconsistency, acquIrers go through specially designedtrammg sessions3 Over t  Semant ics  to  P red ic tSyntax :  A Mach ine-gu idedApproachMappings between semantic roles and syntacUc om-plements axe defined via a mapping (a rule) Thesemappings can be defined for large sub-classes of lex-ical entries For example, the rule Atl;-Pred-Adjcreates an entry which accepts in the semantic fea-ture a concept from the subtree of ATTRIBUTE oran ATTITUDE and accepts attributive (e g safecar) and predlcat,ve uses (e g the car zs sa\]e) Inthe case of an adjecUve mapped to a RELATION(e g MENTAL-OBJECT-RELATION) the preferredrule would be Att-Adj generating an attributivereading (e g ,  dental practzce), and not (~the prac-tice ~s dental)By selecting the appropriate mapping for classesof entries, it is possible to hide the mapping fromthe acqulrer since these mappings are defined in alexlcal class, not m an instance As defined by anacqulrer, an entry looks as follows\[key "safe",syn Att-Pred-Adj,sem \[name Safety-Attrlbute,range Safe\]\],During compilation of the dictionary, theAtt-Pred-Ad 3 label is replaced with its definitionand makes explicit the co-reference between the sub-categorization and the semanticsSo far we have developed for the English lexiconabout twenty syntactic patterns whmh apply to alarge number of semantic frames In the case of ad-jectives, we have 3 rules, one for attributive adjec-tives, another one for predicative adjectives, and athird one for attributive adjective used predicativelyIn the case of nouns, we have developed four pat-terns as Illustrated belowSubcat pattern Example.................................................weaponNObllOpt father  (o f  two)NObll-0bl20pt bomblng of Iraq (by the US)NObllOpt-Obl2Opt computatlon (of the bank reserve)(by its clerks)We presented above the labels of subcategorlza-tion patterns as they appear at acqms~tlon time Atprocessing time, there is no difference between Oblland Ob12, which are both of type Oblique Ourmachine-graded approach elps the acqmrer to se-lect a rule as it only presents the relevant ones fora specffic semantic type For instance, in the caseof a lexeme mapped to an OBJECT no rules havingobliques will be presented to the acqmrer as de-scribed belowexample semantzcs subeat lexlcal class..................................................weapon 0hi N 0binfather .
Prop NObll0pt PropN0bjEvent0bllOptbomblng Event N0110b120pt EventN0b\]0bll0b\]computatlon N0bllOp~0bl20pt -Event0bl20pt..................................................The table above should be read as follows the firstcolumn provides type examples for nouns, the sec-ond column (semantics) provides the list of semantlctypes that a noun can be, Obj (Object), Prop (Prop-erty) and Event, the third column (subcategonza-tion) presents all subcategorizations a noun can sub-categorize for, the fourth column (lexlcal class) con-catenates the semantics and the subcategorizationFor instance EventNObjObllObjEventOb12Opt' isthe lexmal, class of nouns.which are of.type 'Event'and therefore subcategorlze for two obhques (Obl)- the former must be Obj whereas the latter canbe either Obj or Event These Obl can be optional(Opt)Acqmrers may specify the preposition (head of theoblique or preposlUonal phrase) For Instance, in thecase of lather, once an acqulrer has mapped the wordto the concept ' Father" which is a Prop (Property)the acquisition tool presents the subcategorizatmnNObl lOpt  This allows the acquirer to select wluchprepositlon(s) can go with the range of Father (inthis case "of" will be selected) This Information isimportant in generation For generation, one mustspecify, at acquisition tlme, whether or not one cansay the bombing o/Iraq , the bombing of Iraq by theUS ~ the bombing by the US It also helps in wordsense dxsamblguationIn the case of verbs, one can also define lexico-syntactic lasses for different semantic lasses Forinstance, in the case of ASSERTIVEACT the lexemesmapped to it will accept a comp clause (e g heA64sazd (that,) he would come) One class of aspec-tuals subcategonzes for nps (e g I started a newbook), xcomps (e g I started reading/Tinting a newbook), and accepts the intransitive alternation whenthe grammatical object is of type Event (e g thesurgery started very late) 34 Propagation of LexiconsIn this section, we briefly discuss how to extend alexmon using denvatlonal morphology, and off theshelf resources uch as WordNet (Miller, 1990) topropagate the English lexicon with synonyms, andLevm's database of subcategonzatlons and alterna-tions for Enghsh verbs (Levm, 1993) to encode syn-tactic information m the verb entries 44.1 Morpho-semant ics  for Der lvat lona lMorpho logyWe refer the reader to Vmgas et al(1996) for thedetails on this type of acquisition and theoreticalbackground of Lexlcal Rules (LRs) To sketch thisoperation briefly, applying morpho semantic LRsto the entry for the Spanish verb comprar (buy),our acquisition system produced automatically 26new entries (comprador-N1 (buyer), comprable-Ad\](buyable), etc) This includes creating new syntax,semantics and syntax-semantm mappings with cor-rect subcategomzations a d also the right semanticsFor instance, the lexmal entry for comprable will havethe subcategonzatlon f r predicative and attributiveadjectives and the semantics adds the attribute FEA-SIBIL ITYATTRIBUTE to the basic meaning BuY ofcomprar (Vmgas et al 1996) describes about 100morpho-semantlc LRs, which were applied to 1056verb citation forms with 1,263 senses among themThe rules helped acquire an average of 26 candidatenew ~ntrms per verb sense This produced a totalof 31,680 candidate ntries, with an average of over90% and 85% correctness in the assignment ofsyntaxand semantics respectively LRs constitute a power-ful tool to extend a core lexicon from a monohngualviewpoint We present other ways of extending lex-icons, from monohngual (next paragraph) and mul-tlhngual (Section 5) perspectives4 2 Us ing WordNetWordNet has been used as follows We extractedthe synsets assooated with a lexeme using fuzzystring matches between, on the one hand, the valueof the ontological concept (e g,  DESIRE), its defim-tlon (e g ,  for DESIRE "to want something") andthe concept and definition of ~ts corresponding ISAconcept (e g ,  INTEND) and, on the other hand, thedirect hypernyms and hyponyms for the lexeme m3See Vmgas et al(1999) for the details on the web rater-faces used for the acqulsltmn4See Vlegas et al(1998) for more detailsWordNet synsets For instance, for the English verbexpect, mapped to the ontological concept DESIREour algorithm only kept one synset hope, expect,trust, deswe for expect and the following synsets forIts hypernyms wzsh, des:re, wantThe output of our automatlc procedure and man-ual filtering Is illustrated below for the ontologicalconcept DESIRE, along with the synonyms fromWordNet belonging to the same ontological classDESIREwantexpecttrustwishAll these lexemes will be mapped to the conceptDESIRE and minimally accept he same subcatego-mzatlons (e g np-v-np-xcomp as in I want you to/eel comfortable)We should mention that this step also Involvedsome manual filtering by acqulrers We used amachine-guided mode to help the acqulrer in thistask This type of filtering was done very quickly,mainly due to the fact that WordNet is orgamzedon a semantic basis4.3 Using Levin's DBOne of the major problems m using Levm's databasewas filtering out homonyms, as classes in Levm'sdatabase are defined on the basis of the same subcat-egonzatlon pattern (as seen in alternations) and noton a semantic basis, as shown by many researchers sThe advantage of our approach is that ~t issemantic-based, this allows us to organize verbs intotrue (frame-based) semantic lasses, with their asso-ciated sets of subcategonzatlons Therefore, we canpledlct that all velbs belonging to a particular se-mantra class Will have the Same syntactic behaviorFor instance, if one considers the serhantm class ofaspectual verbs which selects a theme of type Event,e g begin, continue, finzsh, then one can minimallyassociate to any verb belonging to this semantic lassthe following subcategonzatlons (a) NP-V-NP mJohn began h:s homework, (b) NP-V-XCOMP Johnbegan to work//workzng Note that the reverse is notnecessarily true verbs which accept (a) and (b) arenot necessarily aspectuals, e g forget in I forgot thekey or I forgot to brzng the key5 App l i cab i l i ty  to  Other  LanguagesIn thls sectlon,-we briefly address what can be gen-erahzed to multiple languages The methodologmsdescribed here are part of what is needed to build5Many experiments have resulted m a sumlar finding, asdescribed In (Dorr et al 1997), (Dang et al 1997) Samt-D~z~er (1996) also showed that these classes do not apply eas-fly to French65a multi-purpose LKB while keeping the costs of ac-qmsltmn as low as possible5.1 Semant ic  Mul t i l lnguahtyBy mapping lexemes to concepts, it is possible tocreate lexicons for dufferent languages, at a mml-mum cost, once a core lexicon has been acquiredTh~s task can be further accelerated if one has ac-cess to blhngual d~ctmnames to semi-automate hetranslatmn task Finally, if one has access to a rlchstructured ontology (as is the case in Mlkrokosmos)then dynamic procedures (e g,  generalization, spe-ciahzatmn) can help the acqulrer in "filling" the gapm the case of lexlco-semantm mismatches (eg, cook,bake ~ cuwe)5.2 More  Re la ted  Languag eMult f l inguahty:  Morpho:semant icsAll the LRs (e g,  LR2agent-o\]) developed for Span-lsh can be used to extend other languages, even un-related ones, in other words, these rules are lan-guage mdependent The morpho-semant,c aspectof the LRs is, however, specific to particular lan-guages But, in order to benefit from the work doneon morpho-semantlc LRs, we separated the assign-meat of affixes from the assignment ofLRs In otherwords, if m Spanish LR~agent-of mass~ghed to saythe suffix -dot, by translating suffixes between lan-guages, (-dot -+ -cur in French), the French lexl-con can be extended m the same way (comprador--+ acheteur) Again, this work will necesmtate somemanual checking, because of some overgeneration,which cannot be accepted for generation But over-all, one can use the same methodology, the same LRsand engine to produce new entries5.3 Even More Re lated LanguageMul t ihnguahtYThe subcategonzatlons attached to a lexeme have aneven more idiosyncratic behavmr than lexlcal LRsBut here agam, the rules we developed can be ap-plied at least to family-related languages, and thenfiltered out by a human For mstance, the Spanishword comer has the pattern np-v-np associated to it(e g Juan come una pera), so this same pattern willbe attached to the translatmn of comer (eat) as m(Juan eats a pear) However, gomg from Spanish toEnglish, one misses all the alternatmns (Lewn, 1993)not common in Spanish such as John gave Mary abook6 SummaryThe MIkrokosmos lexicon acqulmtlon group has ac-quired the following data - Spanish lexicon 7,000word sense entrms (35,000 word sense entries afterapplying the morpho-semantm lexlcal rules), Chi-nese lexicon about 3,000 word sense entries, and En-ghsh, about 15,000 word sense entrms so far Forinstance, the acquisition of 15,000 word sense en-tries took one year and involved 50% of the timeof a computational hngmst (to develop the method-ology, train the acqulrers and design the GUIs), 50acqmrer hours per week, 10 hours per week of a pro-grammer to tmplement the GUIs, mamtam the toolsand test the entriesOur approach to the development of lex, cons dif-fers from others m that our rules apply directly tosemantlc frames and not to the basic forms of verbsOur methodology allows us to alleviate the burdenof manual checking by applying linking rules directlyon the semantics of the lexemes Some rules adddiscourse related features, such as focus m some al-ternations, eg,  they zmproved the s~tuatwn --+ thes~tuatzon zmprovedWhat is Important to evaluate is how much do wegam by using rules and other resources Today, ~t ~sstill d~fficult o say exactly how muchAdequately predicting the subcategonzatlons fora semantic lass depends on its gram size the finer-grained, the better the pred2ctwn wall be However,m NLP apphcatlons, where one Is constramed bytlme, only the semantics necessary for a particularapplication is acquired, which means that m manycases the semantms i  left at a coarser grain s~zethan the one required to predict he subcategomza-tlons In practice, we overgenerate some subcatego-rtzatlons and need therefore to have them checkedby humans This ~s why we have concentrated ona small set of rules Results on that trade-off issuehave been reported in Vmgas et al(1998)Our experience in large-scale acqulsltmn of lexi-cons shows that Idiosyncrasies overrule many of ourgeneral rules This is mainly due to the fact thatwe need a more fine-gramed semantms than the onewhich is available now This ,s not just a criti-cism of our framework, ,t is a genelal fact that weall encounter when mvestlgatmg lexlcal semanticsThis might be due to the fact that we work m asynchronic perspective (a highly recommended ap-proachl), whereas language volves constantly, thuscreatmg "artificial" ldmsyncrasms In any case onecannot avold them when butldmg a computatmnalsemantic lexiconWe have also learnt dunng the acquisition of theMtkrokosmos lexmons that different acqulrers, whohave been through the same Intensive tralmng, willarrive at the same numbel of meanings for a word,in more than 90% of the cases The meaning ofa word might differ, for different rained acqulrers,along ISA links Corpora also Influence the decisionof the acqmrers, and here too we have seen some hu-man "mconsltencms" which we thmk could be "cor-rected" automatically, as discussed in the followmgsection667 Perspect ivesWe are investigating the msue of taking into accountmconmstent lex~cal descnptmns between the lexiconacqmrers by taking advantage of the semantm tarot-matron encoded in the ontologyIf we look at the following data and their subcat-egonzatlons(1) I fixed the meal - \[NP1, NP2\](2) I fixed a sandwlch for you - \[NP1, NP2, PP1\](3) I fixed you a sandwich - \[NP1, NP3, NP2\]where fix means  PREPAREFOOD, then one mustsubcategonzatmns m between square brackets areassocmted to the lexmal ~tems mapped to A, B andCA-  CREATEINGEST\[NP1, NP2, PP1, PP2, \]allow the analysm and generation of any of sentences(1), (2) and (3), whether there is a mapping of fix s - CREATEINGESTBENEF C - CREATEINGESTTHEMEonto the concepts A or B or C 6 \[NPI, NP3, NP2\] \[NPI, NP2\]\[NPI, NP2, PPI\]A-  CREATE INGEST\[ARGI, ARO2, ARQ3, ARC4, \]B - CREATEINGESTBENEF C-  CREATEINGESTTHEME\[ARGI, ARG2, ARG3\] \[ARGI, haG2\]Looking at example (1), and m absence of exam-ples (2) and (3) in the corpus, fix could easily bemapped into A or C, whereas with examples (2) and(3), and m absence of example (1) m the corpus,~t could be easily mapped into A or B by the ac-qmrers We clmm that thin is of no importance asfar as there are mechamsms to go from one to theother This requires to have access to semantic refor-mation The dmgram above is a computational hn-gumt construct and has no "reality" per se B andC are constructs which provide for every semanticclass the different semantic patterns that a particu-lar semantic lass accepts, such as the pattern CRE-ATEINGESTBENEF requires 3 semantm arguments(AGENT, BENEFICIARY and THEME), whereas CRE-ATEINGESTTHEME only reqmres 2 semantic argu-ments In this case, thin means that the BENEFI-CIARY IS optional, a fact the acqmrer "failed" torecogmzeThis diagram can be further specified for a partic-ular natural anguage, where the required argumentsare mapped to syntactic arguments and where lex-lcal rules for a particular language provide the linkbetween the different semantic patterns for a seman-tic class The dmgram below is for English where6We g*ve the general diagram for CREATEINGEST events, asPREPAREFOOD is a subtype and will inherit all the propertiesof the semantic lass CREATEINGESTThe corpus can indeed Influence the way a lexi-con acqmrer will do the mapping So if a lexiconacqmrer creates an unspecffied entry (mapping fixon (A), as opposed to (B) or (C)), dynamic mecha-msms such as speclahzatlon r generahzatmn wouldenable the system to get to (B) and (C) from (A)and vice versa (to (A) from (B) or (C)) Moreover,ff a lexicon acqmrer decides to map to (B) instead of(C) or vine versa, then a lexmal rule (LR) between(B) and (C) will enable the system to go from (B)to (C) and wce versaIn other words, although there are three poten-trolly different ways of writing the lexlcon entry forfix for example sentences (1), (2) and (3), these dif-ferent ways of encoding fix should remain a virtualdifference at processing t~me the system must en-code mechanisms and rules to "interpret" and recon-cile the different points of wew of different acqmrelsThis enables the system to process entences (1), (2)and (3) from any of the three p0tentml lexicon en-triesWe beheve that an unportant msue m compu-tational semantics m to study how lexicon entriescould be dynamically changed to fit different hngms-tic contexts and different acqmrers' analysis of thedata This is what we plan to investigate m ourfuture researchAcknowledgments .This work has been supported m part by DoD un-der contract number MDA-904-92-C-5189 We aregrateful to the Mikrokosmos team, and m partmu-lar Stephen Be'ale, Kavl Mahesh, Sergel Nlrenburg,Boyan Onyshkevych and Victor Raskm Withouttheir input and the many d~scusmons with themit would not have been posmble for the author todevelop the methodologms described here and su-pervise the acqmmtlon of the Mlkrokosmos lexi-cons However, the opinions expressed m th~s at-67hcle are those of the author and do not necessar-tly reflect their opmmns We would also hke tothank the anonymous rewewers for their useful com-ments Last but not least, we would hke to thankall the acqmrers who developed the lexicons over theyears Oscar Cossm, Ron Dolan, Margarita Gon-zales, Wanymg Jm, Juhe Lonergan, Jeff Longwell,Maya, Jawer Ochoa, Armm RuelasLarge-scale Semantic LKB to Su~t an IntelligentPlanner In Proc of the 7th ENLG ToulouseReferencesDale, R & C Melhsh (1998) Towards Evaluation mNatural Language Generahon In Proc of LRE,Granada, SpareDang, H, Rosenzwelg, J & M Palmer (1997) As-sociating Semantic Components with IntersechveLevm Classes In MCCS-97-314, CRL, NMSUDorr, B , Olsen, M & D Clark (1997) Using Word-Net to Point Hmrarchlcal Structure m Levm's VerbClasses In MCCS-97-314, CRL, NMSUHovy, E (1988) Generating Natural Language UnderPragmatzc Constraznts L Erlbaum, Hlllsdale, NJKllgarrtff, A (1997) Sample the Lezzcon TechmcalReport, ITRI-97-01Levm, B (1993) Enghsh Verb Classes and Alterna-hons A Prehmmary Investigation Chmago Um-verslty of Chicago PressMahesh, K (1996) Ontology Development Ideologyand Methodology MCCS-96-292, CRL, NMSUMiller, G A (1990) Nouns m WordNet A LexlcalInheritance System In Internatzonal Journal o/Lexicography 34Nlrenburg, S, J Carbonell, M Tomlta & K Good-man (1992) Machine Translatzon A Knowledge-Based Approach Morgan KaufmannNlrenburg, S & C Defnse (1991) Practmal Compu-tat!onal Llngulstlcs In Johnson & Rosner (eds)Computatzonal Lmguzstzcs and Formal SemanticsCUPSamt-Dlzmr, P (1996) Verb semantm classes basedon 'alternatmns' and on WordNet-hke seman-tic criteria A Powerful Convergence In Procof Predzcatwe Forms m Lezzcal Semantzcs andLKBs, ToulouseVmgas, E, Onyshkevych, B Raskm, V & S Nlren-burg (1996) From Submzt o Submztted via Sub-mzsswn on Lexlcal Rules m Large-scale LexiconAcqmmtmn In Proc of the 34th ACL, UCSC, CAVmgas, E (1999) The Manifesto f Large-scale Se-mantra Lexicon Acqulsltmn In R Zajac (ed)TALN- Le Multdmguzsme, Vol 40-1Vmgas, E, Ruelas, A, Beale, S & S Nlrenburg(1998) Extending a Core Lexicon Using On-hneLanguage Resources with Savolr-Fmre In Procof the lrst LRE, Granada, SpareVmgas, E, Ruelas, A, Lonergan, J ,  Longwell, J ,Beale, S and S Nlrenburg (1999) Developing a68
