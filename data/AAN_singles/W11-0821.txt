Proceedings of the Workshop on Multiword Expressions: from Parsing and Generation to the Real World (MWE 2011), pages 131?133,Portland, Oregon, USA, 23 June 2011. c?2011 Association for Computational LinguisticsThe Ngram Statistics Package (Text::NSP) - A Flexible Tool for IdentifyingNgrams, Collocations, and Word AssociationsTed Pedersen?Department of Computer ScienceUniversity of MinnesotaDuluth, MN 55812Satanjeev BanerjeeTwitter, Inc.795 Folsom StreetSan Francisco, CA 94107Bridget T. McInnesCollege of PharmacyUniversity of MinnesotaMinneapolis, MN 55455Saiyam KohliSDL Language Weaver, Inc.6060 Center Drive, Suite 150Los Angeles, CA 90045Mahesh JoshiLanguage Technologies InstituteCarnegie Mellon UniversityPittsburgh, PA 15213Ying LiuCollege of PharmacyUniversity of MinnesotaMinneapolis, MN 55455AbstractThe Ngram Statistics Package (Text::NSP)is freely available open-source software thatidentifies ngrams, collocations and word as-sociations in text.
It is implemented in Perland takes advantage of regular expressions toprovide very flexible tokenization and to allowfor the identification of non-adjacent ngrams.It includes a wide range of measures of associ-ation that can be used to identify collocations.1 IntroductionThe identification of multiword expressions is a keyproblem in Natural Language Processing.
Despiteyears of research, there is still no single best wayto proceed.
As such, the availability of flexible andeasy to use toolkits remains important.
Text::NSPis one such package, and includes programs forcounting ngrams (count.pl, huge-count.pl), measur-ing the association between the words that make upan ngram (statistic.pl), and for measuring correlationbetween the rankings of ngrams created by differ-ent measures (rank.pl).
It is also able to identify n-th order co-occurrences (kocos.pl) and pre?specifiedcompound words in text (find-compounds.pl).This paper briefly describes each component ofNSP.
Additional details can be found in (Banerjeeand Pedersen, 2003) or in the software itself, whichis freely available from CPAN 1 or Sourceforge 2.?Contact author : tpederse@d.umn.edu.
Note that authorsBanerjee, McInnes, Kohli and Joshi contributed to Text::NSPwhile they were at the University of Minnesota, Duluth.1http://search.cpan.org/dist/Text-NSP/2http://sourceforge.net/projects/ngram/2 count.plThe program count.pl takes any number of plaintext files or directories of such files and counts thetotal number of ngrams as well their marginal to-tals.
It provides the ability to define what a tokenmay be using regular expressions (via the --tokenoption).
An ngram is an ordered sequence of n to-kens, and under this scheme tokens may be almostanything, including space separated strings, charac-ters, etc.
Also, ngrams may be made up of nonadja-cent tokens due to the --window option that allowsusers to specify the number of tokens within whichan ngram must occur.Counting is done using hashes in Perl which arememory intensive.
As a result, NSP also providesthe huge-count.pl program and various other huge-*.pl utilities that carry out count.pl functionality us-ing hard drive space rather than memory.
This canscale to much larger amounts of text, although usu-ally taking more time in the process.By default count.pl treats ngrams as ordered se-quences of tokens; dog house is distinct from housedog.
However, it may be that order does not alwaysmatter, and a user may simply want to know if twowords co-occur.
In this case the combig.pl programadjusts counts from count.pl to reflect an unorderedcount, where dog house and house dog are consid-ered the same.
Finally, find-compounds.pl allows auser to specify a file of already known multiword ex-pressions (like place names, idioms, etc.)
and thenidentify all occurrences of those in a corpus beforerunning count.pl1313 statistic.plThe core of NSP is a wide range of measures ofassociation that can be used to identify interest-ing ngrams, particularly bigrams and trigrams.
Themeasures are organized into families that share com-mon characteristics (which are described in detail inthe source code documentation).
This allows for anobject oriented implementation that promotes inher-itance of common functionality among these mea-sures.
Note that all of the Mutual Information mea-sures are supported for trigrams, and that the Log-likelihood ratio is supported for 4-grams.
The mea-sures in the package are shown grouped by familyin Table 1, where the name by which the measure isknown in NSP is in parentheses.Table 1: Measures of Association in NSPMutual Information (MI)(ll) Log-likelihood Ratio (Dunning, 1993)(tmi) true MI (Church and Hanks, 1990)(pmi) Pointwise MI (Church and Hanks, 1990)(ps) Poisson-Stirling (Church, 2000)Fisher?s Exact Test (Pedersen et al, 1996)(leftFisher) left tailed(rightFisher) right tailed(twotailed) two tailedChi-squared(phi) Phi Coefficient (Church, 1991)(tscore) T-score (Church et al, 1991)(x2) Pearson?s Chi-Squared (Dunning, 1993)Dice(dice) Dice Coefficient (Smadja, 1993)(jaccard) Jaccard Measure(odds) Odds Ratio (Blaheta and Johnson, 2001)3.1 rank.plOne natural experiment is to compare the output ofstatistic.pl for the same input using different mea-sures of association.
rank.pl takes as input the out-put from statistic.pl for two different measures, andcomputes Spearman?s Rank Correlation Coefficientbetween them.
In general, measures within the samefamily correlate more closely with each other thanwith measures from a different family.
As an ex-ample tmi and ll as well as dice and jaccard differby only constant terms and therefore produce identi-cal rankings.
It is often worthwhile to conduct ex-ploratory studies with multiple measures, and therank correlation can help recognize when two mea-sures are very similar or different.4 kocos.plIn effect kocos.pl builds a word network by findingall the n-th order co-occurrences for a given literalor regular expression.
This can be viewed somewhatrecursively, where the 3-rd order co-occurrences ofa given target word are all the tokens that occur withthe 2-nd order co-occurrences, which are all the to-kens that occur with the 1-st order (immediate) co-occurrences of the target.
kocos.pl outputs chains ofthe form king -> george -> washington,where washington is a second order co-occurrence(of king) since both king and washington are firstorder co-occurrences of george.
kocos.pl takes asinput the output from count.pl, combig.pl, or statis-tic.pl.5 APIIn addition to command line support, Test::NSP of-fers an extensive API for Perl programmers.
All ofthe measures described in Table 1 can be includedin Perl programs as object?oriented method calls(Kohli, 2006), and it is also easy to add new mea-sures or modify existing measures within a program.6 Development History of Text::NSPThe Ngram Statistics Package was originally imple-mented by Satanjeev Banerjee in 2000-2002 (Baner-jee and Pedersen, 2003).
Amruta Purandare in-corporated NSP into SenseClusters (Purandare andPedersen, 2004) and added huge-count.pl, com-big.pl and kocos.pl in 2002-2004.
Bridget McInnesadded the log-likelihood ratio for longer ngramsin 2003-2004 (McInnes, 2004).
Saiyam Kohlirewrote the measures of association to use object-oriented methods in 2004-2006, and also addednumerous new measures for bigrams and trigams(Kohli, 2006).
Mahesh Joshi improved cross plat-form support and created an NSP wrapper for Gatein 2005-2006.
Ying Liu wrote find-compounds.pland rewrote huge-count.pl in 2010-2011.132ReferencesS.
Banerjee and T. Pedersen.
2003.
The design, imple-mentation, and use of the Ngram Statistics Package.In Proceedings of the Fourth International Conferenceon Intelligent Text Processing and Computational Lin-guistics, pages 370?381, Mexico City, February.D.
Blaheta and M. Johnson.
2001.
Unsupervised learn-ing of multi-word verbs.
In ACL/EACL Workshop onCollocations, pages 54?60, Toulouse, France.K.
Church and P. Hanks.
1990.
Word association norms,mutual information and lexicography.
ComputationalLinguistics, pages 22?29.K.
Church, W. Gale, P. Hanks, and D. Hindle.
1991.
Us-ing statistics in lexical analysis.
In U. Zernik, editor,Lexical Acquisition: Exploiting On-Line Resources toBuild a Lexicon.
Lawrence Erlbaum Associates, Hills-dale, NJ.K.
Church.
1991.
Concordances for parallel text.
InSeventh Annual Conference of the UW Centre for NewOED and Text Research, Oxford, England.K.
Church.
2000.
Empirical estimates of adaptation:The chance of two noriegas is closer to p/2 than p2.In Proceedings of the 18th International Conferenceon Computational Linguistics (COLING-2000), pages180?186, Saarbru?cken, Germany.T.
Dunning.
1993.
Accurate methods for the statistics ofsurprise and coincidence.
Computational Linguistics,19(1):61?74.S.
Kohli.
2006.
Introducing an object oriented design tothe ngram statistics package.
Master?s thesis, Univer-sity of Minnesota, Duluth, July.B.
McInnes.
2004.
Extending the log-likelihood ratioto improve collocation identification.
Master?s thesis,University of Minnesota, Duluth, December.T.
Pedersen, M. Kayaalp, and R. Bruce.
1996.
Signifi-cant lexical relationships.
In Proceedings of the Thir-teenth National Conference on Artificial Intelligence,pages 455?460, Portland, OR, August.A.
Purandare and T. Pedersen.
2004.
Word sensediscrimination by clustering contexts in vector andsimilarity spaces.
In Proceedings of the Conferenceon Computational Natural Language Learning, pages41?48, Boston, MA.F.
Smadja.
1993.
Retrieving collocations from text:Xtract.
Computational Linguistics, 19(1):143?177.133
