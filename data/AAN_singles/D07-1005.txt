Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and ComputationalNatural Language Learning, pp.
42?50, Prague, June 2007. c?2007 Association for Computational LinguisticsImproving Word Alignment with Bridge LanguagesShankar Kumar and Franz Och and Wolfgang MachereyGoogle Inc.1600 Amphitheatre ParkwayMountain View, CA 94043, U.S.A.{shankarkumar,och,wmach}@google.comAbstractWe describe an approach to improveStatistical Machine Translation (SMT)performance using multi-lingual, parallel,sentence-aligned corpora in several bridgelanguages.
Our approach consists of a sim-ple method for utilizing a bridge language tocreate a word alignment system and a proce-dure for combining word alignment systemsfrom multiple bridge languages.
The finaltranslation is obtained by consensus de-coding that combines hypotheses obtainedusing all bridge language word alignments.We present experiments showing that mul-tilingual, parallel text in Spanish, French,Russian, and Chinese can be utilized inthis framework to improve translationperformance on an Arabic-to-English task.1 IntroductionWord Alignment of parallel texts forms a cru-cial component of phrase-based statistical machinetranslation systems.
High quality word alignmentscan yield more accurate phrase-pairs which improvequality of a phrase-based SMT system (Och andNey, 2003; Fraser and Marcu, 2006b).Much of the recent work in word alignment hasfocussed on improving the word alignment qualitythrough better modeling (Och and Ney, 2003; Dengand Byrne, 2005; Martin et al, 2005) or alternativeapproaches to training (Fraser and Marcu, 2006b;Moore, 2005; Ittycheriah and Roukos, 2005).
Inthis paper we explore a complementary approach toimprove word alignments using multi-lingual, par-allel (or multi-parallel) corpora.
Two works in theliterature are very relevant to our approach.
Borin(2000) describes a non-statistical approach where apivot alignment is used to combine direct translationand indirect translation via a third language.
Filaliand Bilmes (2005) present a multi-lingual extensionto the IBM/HMMmodels.
Our current approach dif-fers from this latter work in that we propose a sim-ple framework to combine word alignments fromany underlying statistical alignment model withoutthe need for changing the structure of the model.While both of the above papers focus on improv-ing word alignment quality, we demonstrate thatour approach can yield improvements in transla-tion performance.
In particular, we aim to improvean Arabic-to-English (Ar-En) system using multi-parallel data from Spanish (Es), French (Fr), Rus-sian (Ru) and Chinese (Zh).
The parallel data inthese languages X ?
{Es, Fr,Ru, Zh} is used togenerate word alignments between Arabic-X andX-English.
These alignments are then combined toobtain multiple word alignments for Arabic-Englishand the final translation systems.The motivation for this approach is two-fold.First, we believe that parallel corpora availablein several languages provide a better training ma-terial for SMT systems relative to bilingual cor-pora.
Such multi-lingual parallel corpora are be-coming widely available; examples include proceed-ings of the United Nations in six languages (UN,2006), European Parliament (EU, 2005; Koehn,2003), JRC Acquis corpus (EU, 2007) and religioustexts (Resnik et al, 1997).
Word alignment systems42trained on different language-pairs (e.g.
French-English versus Russian-English) make errors whichare somewhat orthogonal.
In such cases, incorrectalignment links between a sentence-pair can be cor-rected when a translation in a third language is avail-able.
Thus it can help resolve errors in word align-ment.
We combine word alignments using severalbridge languages with the aim of correcting someof the alignment errors.
The second advantage ofthis approach is that the word alignment from eachbridge language can be utilized to build a phrase-based SMT system.
This provides a diverse collec-tion of translation hypotheses for MT system com-bination (Bangalore et al, 2002; Sim et al, 2007;Matusov et al, 2006; Macherey and Och, 2007).
Fi-nally, a side benefit of this paper is that it provides astudy that compares alignment qualities and BLEUscores for models in different languages trained onparallel text which is held identical across all lan-guages.We show that parallel corpora in multiple lan-guages can be exploited to improve the translationperformance of a phrase-based translation system.This paper gives specific recipes for using a bridgelanguage to construct a word alignment and for com-bining word alignments produced by multiple statis-tical alignment models.The rest of this paper is organized as follows: Sec-tion 2 gives an overview of our framework for gen-erating word alignments in a single language-pair.In Section 3, we describe how a bridge languagemay be used for producing word alignments.
In Sec-tion 4, we describe a scheme to combine word align-ments from several bridge languages.
Section 5 de-scribes our experimental setup and reports the align-ment and translation performance.
A final discus-sion is presented in Section 6.2 Word Alignment FrameworkA statistical translation model (Brown et al, 1993;Och and Ney, 2003) describes the relationship be-tween a pair of sentences in the source and targetlanguages (f = fJ1 , e = eI1) using a translationprobability P (f |e).
Alignment models introduce ahidden alignment variable a = aJ1 to specify a map-ping between source and target words; aj = i in-dicates that the jth source word is linked to the ithtarget word.
Alignment models assign a probabil-ity P (f ,a|e) to the source sentence and alignmentconditioned on the target sentence.
The transla-tion probability is related to the alignment model as:P (f |e) =?a P?
(f ,a|e), where ?
is a set of param-eters.Given a sentence-pair (f , e), the most likely(Viterbi) word alignment is found as (Brown et al,1993): a?
= argmaxa P (f ,a|e).
An alternate cri-terion is the Maximum A-Posteriori (MAP) frame-work (Ge, 2004; Matusov et al, 2004).
We use arefinement of this technique.Given any word alignment model, posterior prob-abilities can be computed as (Brown et al, 1993)P (aj = i|e, f) =?aP (a|f , e)?
(i, aj), (1)where i ?
{0, 1, ..., I}.
The assignment aj = 0corresponds to the NULL (empty) alignment.
Theseposterior probabilities form a matrix of size (I+1)?J , where entries along each column sum to one.The MAP alignment for each source position j ?
{1, 2, ..., J} is then computed asaMAP (j) = argmaxiP (aj = i|e, f).
(2)We note that these posterior probabilities can becomputed efficiently for some alignment modelssuch as the HMM (Vogel et al, 1996; Och and Ney,2003), Models 1 and 2 (Brown et al, 1993).In the next two sections, we describe how poste-rior probabilities can be used to a) construct align-ment systems from a bridge language, and b) mergeseveral alignment systems.3 Constructing Word Alignment Using aBridge LanguageWe assume here that we have triples of sentencesthat are translations of each other in languages F, E,and the bridge language G: f = fJ1 , e = eI1,g =gK1 .
Our goal is to obtain posterior probability es-timates for the sentence-pair in FE: (f , e) using theposterior probability estimates for the sentence pairsin FG: (f ,g) and GE: (g, e).
The word alignmentsbetween the above sentence-pairs are referred to asaFE , aFG, and aGE respectively; the notation aFEindicates that the alignment maps a position in F toa position in E.43We first express the posterior probability as a sumover all possible translations g in G and hiddenalignments aFG.P (aFEj = i|e, f)=?gP (aFEj = i,g|e, f)=?g,kP (aFEj = i,g, aFGj = k|e, f)=?g,k{P (g|e, f)P (aFGj = k|g, e, f)?P (aFEj = i|aFGj = k,g, e, f)}(3)We now make some assumptions to simplify theabove expression.
First, there is exactly one trans-lation g in bridge language G corresponding to thesentence-pair f , e. Since aGEaFGj= i = aFEj , we canexpressP (aFEj = i|aFGj = k,g, f , e) = P (aGEk = i|g, e).Finally, alignments in FG do not depend on E.Under these assumptions, we arrive at the final ex-pression for the posterior probability FE in terms ofposterior probabilities for GF and EGP (aFEj = i|e, f) = (4)K?k=0P (aFGj = k|g, f)P (aGEk = i|g, e)The above expression states that the posterior prob-ability matrix for FE can be obtained using a simplematrix multiplication of posterior probability ma-trices for GE and FG.
In this multiplication, weprepend a column to the GE matrix correspondingto k = 0.
This probability P (aGEk = i) when k = 0is not assigned by the alignment model; we set it asfollowsP (aGEk = i|k = 0) ={ i = 01?I i ?
{1, 2, ..., I}The parameter  controls the number of empty align-ments; a higher value favors more empty alignmentsand vice versa.
In our experiments, we set  = 0.5.4 Word Alignment Combination UsingPosterior ProbabilitiesWe next show how Word Alignment Posterior Prob-abilities can be used for combining multiple wordalignment systems.
In our context, we use this pro-cedure to combine word alignments produced usingmultiple bridge languages.Suppose we have translations in bridge languagesG1, G2, ..., GN , we can generate a posterior prob-ability matrix for FE using each of the bridge lan-guages.
In addition, we can always generate a poste-rior probability matrix for FE with the FE alignmentmodel directly without using any bridge language.These N + 1 posterior matrices can be combined asfollows.
Here, the variable B indicates the bridgelanguage.
B ?
{G0, G1, ..., GN}; G0 indicates thecase when no bridge language is used.P (aFEj = i|e, f) (5)=N?l=0P (B = Gl, aFEj = i|e, f)=N?l=0P (B = Gl)P (aFEj = i|Gl, e, f),where P (aFEj = i|Gl, j, e, f) is the posterior proba-bility when bridge language B = Gl.
The probabili-ties P (B = Gl) sum to one over l ?
{0, 1, 2, ..., N}and represent the prior probability of bridge lan-guage l. In our experiments, we use a uniform priorP (B = Gl) = 1N+1 .
Equation 5 provides us a wayto combine word alignment posterior probabilitesfrom multiple bridge languages.
In our alignmentframework (Section 2), we first interpolate the pos-terior probability matrices (Equation 5) and then ex-tract the MAP word alignment (Equation 2) from theresulting matrix.5 ExperimentsWe now present experiments to demonstrate the ad-vantages of using bridge languages.
Our experi-ments are performed in the open data track of theNIST Arabic-to-English (A-E) machine translationtask 1.5.1 Training and Test DataOur approach to word alignment (Section 3) requiresaligned sentences in multiple languages.
For train-ing alignment models, we use the ODS United Na-1http://www.nist.gov/speech/tests/mt/44Set # of Ar words (K) # of sentencesdev1 48.6 2007dev2 11.4 498test 37.8 1610blind 36.5 1797Table 1: Statistics for the test data.tions parallel data (UN, 2006) which contains par-liamentary documents from 1993 onwards in all sixofficial languages of the UN: Arabic (Ar), Chinese(Zh), English (En), French (Fr), Russian (Ru), andSpanish (Es).We merge the NIST 2001-2005 Arabic-Englishevaluation sets into a pool and randomly sam-ple this collection to create two development sets(dev1,dev2) and a test set (test) with 2007, 498, and1610 sentences respectively.
Our blind test (blind)set is the NIST part of the NIST 06 evaluation setconsisting of 1797 sentences.
The GALE portion ofthe 06 evaluation set is not used in this paper.
We re-port results on the test and blind sets.
Some statisticscomputed on the test data are shown in Table 1.5.2 Alignment Model TrainingFor training Arabic-English alignment models, weuse Chinese, French, Russian and Spanish as bridgelanguages.
We train a model for Ar-En and 4 mod-els each for Ar-X and X-En, where X is the bridgelanguage.
To obtain aligned sentences in these lan-guage pairs, we train 9 sentence aligners.
We thentrain alignment models for all 9 language-pairs us-ing a recipe consisting of 6 Model-1 iterations and6 HMM iterations.
Finally, Word Alignment Poste-rior Probabilities are generated over the bitext.
InTable 2, we report the perplexities of the alignmentmodels for the translation directions where eitherArabic or English is predicted.
There are 55M Ara-bic tokens and 58M English tokens.
We observethat the alignment model using Spanish achieves thelowest perplexity; this value is even lower than theperplexity of the direct Arabic-English model.
Per-plexity is related to the hardness of the word align-ment; the results suggest that bridge languages suchas Spanish make alignment task easier while othersdo not.
We stress that perplexity is not related to thealignment or the translation performance.Bridge PerplexityLang ?
Ar ?EnNone 113.8 26.1Es 99.0 22.9Fr 138.6 30.2Ru 128.3 27.5Zh 126.1 34.6Table 2: Perplexities of the alignment models.5.3 Bridge Language Word AlignmentsEach of the 4 bridge languages is utilized for con-structing a word alignment for Arabic-English.
Us-ing each bridge language X, we obtain Arabic-English word alignments in both translation direc-tions (AE and EA).
The posterior matrix for AE isobtained using AX and XE matrices while the EAmatrix is obtained from EX and XA matrices (Equa-tion 4).
The AE (EA) matrices from the bridgelanguages are then interpolated with the AE (EA)matrix obtained from the alignment model traineddirectly on Arabic-English (Section 4).
The MAPword alignment for AE (EA) direction is computedfrom the AE (EA) matrix.
We next outline how theseword alignments are utilized in building a phrase-based SMT system.5.4 Phrase-based SMT systemOur phrase-based SMT system is similar to thealignment template system described in Och andNey (2004).
We first extract an inventory of phrase-pairs up to length 7 from the union of AE and EAword alignments.
Various feature functions (Ochand Ney, 2004) are then computed over the entriesin the phrase table.
5-gram word language modelsin English are trained on a variety of monolingualcorpora (Brants et al, 2007).
Minimum Error RateTraining (MERT) (Och, 2003) under BLEU crite-rion is used to estimate 20 feature function weightsover the larger development set (dev1).Translation is performed using a standard dy-namic programming beam-search decoder (Och andNey, 2004).
Decoding is done in two passes.
An ini-tial list of 1000-best hypotheses is generated by thedecoder.
This list is then rescored using MinimumBayes-Risk (MBR) decoding (Kumar and Byrne,2004).
The MBR scaling parameter is tuned on thesmaller development set (dev2).45Bridge Metrics(%)Language AE EAPrec Rec AER Prec Rec AERNone 74.1 73.9 26.0 67.3 57.7 37.9Es 61.7 56.3 41.1 50.0 40.2 55.4Fr 52.9 48.0 49.7 42.3 33.6 62.5Ru 57.4 50.8 46.1 40.2 31.6 64.6Zh 44.3 39.3 58.3 39.7 29.9 65.9AC1 70.0 65.0 32.6 56.8 46.4 48.9Table 3: Alignment Performance with Bridge Lan-guages5.5 Alignment ResultsWe first report alignment performance (Table 3) ofthe alignment models obtained using the bridge lan-guages.
Alignment results are reported in termsof Precision (Prec), Recall (Rec) and AlignmentError Rate (AER).
We report these numbers ona 94-sentence test set with translations in all sixlanguages and human word alignments in Arabic-English.
Our human word alignments do not dis-tinguish between Sure and Probable links (Och andNey, 2003).In these experiments, we first identify the com-mon subset of sentences which have translations inall six languages.
Each of the 9 alignment modelsis then trained on this subset.
We report Alignmentperformance in both translation directions: Arabic-to-English (AE) and English-to-Arabic (EA).
Thefirst row (None) gives the results when no bridgelanguage is used.Among the bridge languages, Spanish gives thebest alignment for Arabic-English while Chinese re-sults in the worst.
This might be related to how dif-ferent the bridge language is relative to either En-glish or Arabic.
The last row (AC1) shows the per-formance of the alignment obtained by combiningNone/Es/Fr/Ru/Zh alignments.
This alignment out-performs all bridge alignments but is weaker thanthe alignment without any bridge language.
Ourhypothesis is that a good choice of interpolationweights (Equation 5) would reduce AER of the AC1combination.
However, we did not investigate thesechoices in this paper.
We report alignment error rateshere to give the readers an idea of the vastly differ-ent alignment performance using each of the bridgelanguages.5.6 Translation ResultsWe now report translation performance of our tech-niques.
We measure performance using the NISTimplementation of case sensitive BLEU-4 on true-cased translations.
We observed in experimentsnot reported here that results are almost identicalwith/without Minimum Error Rate Training ; wetherefore report the results without the training.
Wenote that the blind set is the NIST subset of the 2006NIST evaluation set.
The systems reported here arefor the Unlimited Data Track in Arabic-to-Englishand obtain competitive performance relative to theresults reported on the NIST official results page 2We present three sets of experiments.
In Table 4,we describe the first set where all 9 alignment mod-els are trained on nearly the same set of sentences(1.9M sentences, 57.5M words in English).
Thismakes the alignment models in all bridge languagescomparable.
In the first rowmarked None, we do notuse a bridge language.
Instead, an Ar-En alignmentmodel is trained directly on the set of sentence pairs.The next four rows give the performance of align-ment models trained using the bridge languages Es,Fr, Ru and Zh respectively.
For each language, weuse the procedure (Section 3) to obtain the posteriorprobability matrix for Arabic-English from Arabic-X and X-English matrices.
The row AC1 refers toalignment combination using interpolation of poste-rior probabilities described in Section 4.
We com-bine posterior probability matrices from the systemsin the first four rows: None, Es, Ru and Zh.
Weexclude the Zh system from the AC1 combinationbecause it is found to degrade the translation perfor-mance by 0.2 points on the test set.In the final six rows of Table 4, we show the per-formance of a consensus decoding technique thatproduces a single output hypothesis by combin-ing translation hypotheses from multiple systems;this is an MBR-like candidate selection procedurebased on BLEU correlation matrices and is de-scribed in Macherey and Och (2007).
We first reportperformance of the consensus output by combiningNone systems with/without MERT.
Each of the fol-lowing rows provides the results from consensus de-coding for adding an extra system both with/withoutMERT.
Thus, the final row (TC1) combines transla-2http://www.nist.gov/speech/tests/mt/mt06eval official results.html46tions from 12 systems: None, Es, Fr, Ru, Zh, AC1with/without MERT.
All entries marked with an as-terisk are better than the None baseline with 95%statistical significance computed using paired boot-strap resampling (Koehn, 2004).35 40 45 50 55 60 65 703737.53838.53939.54040.5NoneEsFrRuZhAC1100?AER(%)BLEU(%)Figure 1: 100-AER (%) vs. BLEU(%) on the blindset for 6 systems from Table 3.Figure 1 shows the plot between 100-AER% (av-erage of EA/AE directions) and BLEU for the sixsystems in Table 3.
We observe that AER is looselycorrelated to BLEU (?
= 0.81) though the re-lation is weak, as observed earlier by Fraser andMarcu (2006a).
Among the bridge languages, Span-ish gives the lowest AER/highest BLEU while Chi-nese results in highest AER/lowest BLEU.
We canconclude that Spanish is closest to Arabic/Englishwhile Chinese is the farthest.
All the bridge lan-guages yield lower BLEU/higher AER relative to theNo-Bridge baseline.
Therefore, our estimate of theposterior probability (Equation 4) is always worsethan the posterior probability obtained using a di-rect model.
The alignment combination (AC1) be-haves differently from other bridge systems in that itgives a higher AER and a higher BLEU relative toNone baseline.
We hypothesize that AC1 is differ-ent from the bridge language systems since it arisesfrom a different process: interpolation with the di-rect model (None).Both system combination techniques give im-provements relative to None baseline: alignmentcombination AC1 gives a small gain (0.2 points)while the consensus translation TC1 results in alarger improvement (0.8 points).
The last 4 rowsof the table show that the performance of the hy-pothesis consensus steadily increases as systems getadded to the None baseline.
This shows that whilebridge language systems are weaker than the di-rect model, they can provide complementary sourcesof evidence.
To further validate this hypothesis,we compute inter-system BLEU scores betweenNone/es and all the systems in Table 5.
We observethat the baseline (None) is very dissimilar from therest of the systems.
We hypothesize that the baselinesystem has an alignment derived from a real align-ment model while the rest of the bridge systems arederived using matrix multiplication.
The low inter-system BLEU scores show that the bridge systemsprovide diverse hypotheses relative to the baselineand therefore contribute to gains in consensus de-coding.Bridge Lang # Msents BLEU (%)test blindNone 1.9 52.1 40.1Es 1.9 51.7 39.8Fr 1.9 51.2 39.5Ru 1.9 50.4 38.7Zh 1.9 48.4 37.1AC1 1.9 52.1 40.3Hypothesis ConsensusNone 1.9 51.9 39.8+Es 1.9 52.2 40.0+Fr 1.9 52.4?
40.5?+Ru 1.9 52.8?
40.7?+Zh 1.9 52.6?
40.6?+AC1 = TC1 1.9 53.0?
40.9?Table 4: Translation Experiments for Set 1; Resultsare reported on the test and blind set: (NIST portionof 2006 NIST eval set).Ref None es fr ru zh AC1None 100.0 60.0 59.8 59.7 59.5 58.7es 59.6 100.0 79.9 69.3 67.4 70.5Table 5: Inter-system BLEU scores (%) betweenNone/es and all systems in Table 3.To gain some insight about how the bridge sys-tems help in Table 4, we present an example in Ta-ble 6.
The example shows the consensus Transla-tions and the 12 input translations for the consensusdecoding.
The example suggests that the inputs tothe consensus decoding exhibit diversity.Table 7 reports the second and third sets of ex-periments.
For both sets, we first train each bridgelanguage system X using all aligned sentences avail-47System MERT HypothesisNone N The President of the National Conference Visit Iraqi Kurdistan IraqiNone Y President of the Iraqi National Conference of Iraqi Kurdistan VisitEs N President of the Iraqi National Congress to Visit Iraqi KurdistanEs Y President of the Iraqi National Congress to Visit Iraqi KurdistanFr N President of the Iraqi National Conference Visits Iraqi KurdistanFr Y Chairman of the Iraqi National Conference Visits Iraqi KurdistanRu N The Chairman of the Iraqi National Conference Visits Iraqi KurdistanRu Y Chairman of the Iraqi National Conference Visit the Iraqi KurdistanZh N The Chairman of the Iraqi National Conference Visits Iraqi KurdistanZh Y The Chairman of the Iraqi National Conference Visit Iraqi KurdistanAC1 N President of the Iraqi National Congress to Visit Iraqi KurdistanAC1 Y Chairman of the Iraqi National Congress to Visit Iraqi KurdistanTC1 - The Chairman of the Iraqi National Conference Visits Iraqi KurdistanRef - Head of Iraqi National Congress Visits Iraqi KurdistanTable 6: An example showing the Consensus Translation (TC1) and the 12 inputs for consensus decoding.The final row shows the reference translation.able in Ar, En and X.
In Set 2, the first row (Union)is an alignment model trained on all sentence-pairsin Ar-En which are available in at least one bridgelanguage X. AC2 refers to alignment combinationusing bridge languages Es/Fr/Ru and Union.
TC2refers to the translation combination from 12 sys-tems: Es/Fr/Ru/Zh/Union/AC2 with/without Mini-mum Error Rate training.
Finally, the goal in Set 3(last 3 rows) is to improve the best Arabic-Englishsystem that can be built using all available sen-tence pairs from the UN corpus.
The first row(Direct) gives the performance of this Ar-En sys-tem; AC3 refers to alignment combination usingEs/Fr/Ru and Direct.
TC3 merges translations fromEs/Fr/Ru/Zh/Direct/AC3.
All entries marked withan asterisk (plus) are better than the Union (Direct)baseline with 95% statistical significance computedusing paired bootstrap resampling (Koehn, 2004).The motivation behind Sets 2 and 3 is to train allbridge language systems on as much bitext as possi-ble.
As a consequence, these systems give better re-sults than the corresponding systems in Table 4.
TheUnion system outperforms None by 1.7/1.4 BLEUpoints and provides a better baseline.
We show un-der this scenario that system combination techniquesAC2 and TC2 can still give smaller improvements(0.3/0.5 and 1.0/0.7 points) relative to this baseline.As mentioned earlier, our approach requiressentence-aligned corpora.
In our experiments, weuse a single sentence aligner for each language pair(total of 9 aligners).
Since these aligners make inde-pendent decisions on sentence boundaries, we endup with a smaller pool of sentences (1.9M) that iscommon across all language pairs.
In contrast, asentence aligner that makes simultaneous decisionsin multiple languages would result in a larger set ofcommon sentence pairs (close to 7M sentence pairs).Simard (1999) describes a sentence aligner of thistype that improves alignment on a trilingual paral-lel text.
Since we do not currently have access tosuch an aligner, we simulate that situation with Sets2 and 3: AC2/AC3 do not insist that a sentence-pairbe present in all input word alignments.
We note thatSet 2 is a data scenario that falls between Sets 1 and3.Set 3 provides the best baseline for Arabic-English based on the UN data by training onall parallel sentence-pairs.
In this situation, sys-tem combination with bridge languages (AC3/TC3)gives reasonable improvements in BLEU on the testset (0.4/1.0 points) but only modest improvements(0.1/0.4 points) on the blind set.
However, this doesshow that the bridge systems continue to provide or-thogonal evidence at different operating points.6 DiscussionWe have described a simple approach to improveword alignments using bridge languages.
This in-cludes two components: a matrix multiplication toassemble a posterior probability matrix for the de-sired language-pair FE using a pair of posteriorprobability matrices FG and GE relative to a bridgelanguage G. The second component is a recipe forcombining word alignment systems by linearly in-48Bridge Lang # Msents BLEU (%)test blindEs 4.7 53.7 40.9Fr 4.7 53.2 40.7Ru 4.5 52.4 39.9Zh 3.4 49.7 37.9Set 2Union 7.2 53.8 41.5AC2 7.2 54.1 42.0?TC2 - 54.8?
42.2?Set 3Direct 7.0 53.9 42.2AC3 9.0 54.3+ 42.3TC3 - 54.9+ 42.6+Table 7: Translation performance for Sets 2 and 3 ontest and blind:NIST portion of 2006 NIST eval set.terpolating posterior probability matrices from dif-ferent sources.
In our case, these sources are multi-ple bridge languages.
However, this method is moregenerally applicable for combining posterior matri-ces from different alignment models such as HMMand Model-4.
Such an approach contrasts with thelog-linear HMM/Model-4 combination proposed byOch and Ney (2003).There has been recent work by Ayan and Dorr(2006) on combining word alignments from differ-ent alignment systems; this paper describes a maxi-mum entropy framework for this combination.
Theirapproach operates at the level of the alignment linksand uses maximum entropy to decide whether ornot to include an alignment link in the final out-put.
In contrast, we use posterior probabilities as theinterface between different alignment models.
An-other difference is that this maxent framework re-quires human word aligned data for training featureweights.
We do not require any human word aligneddata to train our combiner.Another advantage of our approach is that it isbased on word alignment posterior probability ma-trices that can be generated by any underlying align-ment model.
Therefore, this method can be used tocombine word alignments generated by fairly dis-similar word alignment systems as long as the sys-tems can produce posterior probabilities.Bridge languages have been used by NLP re-searchers as a means to induce translation lexiconsbetween distant languages without the need for par-allel corpora (Schafer and Yarowsky, 2002; Mannand Yarowsky, 2001).
Our current approach differsfrom these efforts in that we use bridge languages toimprove word alignment quality between sentencepairs.
Furthermore, we do not use linguistic insightto identify bridge languages.
In our framework, agood bridge language is one that provides the besttranslation performance using the posterior matrixmultiplication.
Our experiments show that Spanishis a better bridge language relative to Chinese forArabic-to-English translation.
We speculate that ifour approach was carried out on a data set with hun-dreds of languages, we might be able to automati-cally identify language families.A downside of our approach is the requirementfor exact sentence-aligned parallel data.
Except fora few corpora such as UN, European Parliament etc,such a resource is hard to find.
One solution is to cre-ate such parallel data by automatic translation andthen retaining reliable translations by using confi-dence metrics (Ueffing and Ney, 2005).Our approach to using bridge languages is ex-tremely simple.
Despite its simplicity, the systemcombination gives improvements in alignment andtranslation performance.
In future work, we willconsider several extensions to this framework thatlead to more powerful system combination strategiesusing multiple bridge languages.
We recall that thepresent approach trains bridge systems (e.g.
Arabic-to-French, French-to-English) until the alignmentstage and then uses these for constructing Arabic-to-English word alignment.
An alternate scenariowould be to build phrase-based SMT systems forArabic-to-Spanish and Spanish-to-English, and thenobtain Arabic-to-English translation by first trans-lating from Arabic into Spanish and then Spanishinto English.
Such end-to-end bridge systems maylead to an even more diverse pool of hypotheses thatcould further improve system combination.ReferencesN.
Ayan and B. Dorr.
2006.
A maximum entropyapproach to combining word alignments.
In HLT-NAACL, New York, New York.S.
Bangalore, V. Murdock, and G. Riccardi.
2002.
Boot-strapping bilingual data using consensus translationfor a multilingual instant messaging system.
In COL-ING, Taipei, Taiwan.L.
Borin.
2000.
You?ll take the high road and I?ll take the49low road: Using a third language to improve bilingualword alignment.
In COLING, pages 97?103, Saar-brucken, Germany.T.
Brants, A. Popat, P. Xu, F. Och, and J.
Dean.
2007.Large language models in machine translation.
InEMNLP, Prague, Czech Republic.P.
F. Brown, S. A. Della Pietra, V. J. Della Pietra, andR.
L. Mercer.
1993.
The mathematics of statisticalmachine translation: Parameter estimation.
Computa-tional Linguistics, 19(2):263?311.Y.
Deng and W. Byrne.
2005.
HMM word andphrase alignment for statistical machine translation.
InEMNLP, Vancouver, Canada.EU, 2005.
European Parliament Proceedings.http://www.europarl.europa.eu.EU, 2007.
JRC Acquis Corpus.
http://langtech.jrc.it/JRC-Acquis.html.K.
Filali and J. Bilmes.
2005.
Leveraging multiple lan-guages to improve statistical mt word alignments.
InIEEE Workshop on Automatic Speech Recognition andUnderstanding, San Juan, Puerto Rico.A.
Fraser and D. Marcu.
2006a.
Measuring word align-ment quality for statistical machine translation.
Tech-nical Report ISI-TR-616, ISI/University of SouthernCalifornia.A.
Fraser and D. Marcu.
2006b.
Semi-supervised train-ing for statistical word alignment.
In ACL, pages 769?776, Sydney, Australia.N.
Ge.
2004.
Improvements in word alignments.
InPresentation given at DARPA/TIDES workshop.A.
Ittycheriah and S. Roukos.
2005.
A maximum en-tropy word aligner for arabic-english machine transla-tion.
In EMNLP, Vancouver, Canada.P.
Koehn, 2003.
European Parlia-ment Proceedings, Sentence Aligned.http://people.csail.mit.edu/koehn/publications/europarl/.P.
Koehn.
2004.
Statistical significance tests for machinetranslation evaluation.
In EMNLP, Barcelona, Spain.S.
Kumar and W. Byrne.
2004.
Minimum Bayes-riskdecoding for statistical machine translation.
In HLT-NAACL, pages 169?176, Boston, MA, USA.W.
Macherey and F. Och.
2007.
An empirical study oncomputing consensus translations from multiple ma-chine translation systems.
In EMNLP, Prague, CzechRepublic.G.
Mann and D. Yarowsky.
2001.
Multipath translationlexicon induction via bridge languages.
In NAACL,Pittsburgh, PA, USA.J.
Martin, R. Mihalcea, and T. Pedersen.
2005.
Wordalignment for languages with scarce resources.
In ACLWorkshop on Building and Using Parallel Texts, pages65?74, Ann Arbor, MI, USA.E.
Matusov, R. Zens, and H. Ney.
2004.
Symmetric wordalignments for statistical machine translation.
InCOL-ING, Geneva, Switzerland.E.
Matusov, N. Ueffing, and H. Ney.
2006.
Computingconsensus translation from multiple machine transla-tion systems using enhanced hypotheses alignment.
InEACL, Trento, Italy.R.
C. Moore.
2005.
A discriminative framework forbilingual word alignment.
In EMNLP, Vancouver,Canada.F.
Och and H. Ney.
2003.
A systematic comparison ofvarious statistical alignment models.
ComputationalLinguistics, 29(1):19 ?
51.F.
Och and H. Ney.
2004.
The alignment template ap-proach to statistical machine translation.
Computa-tional Linguistics, 30(4):417 ?
449.F.
Och.
2003.
Minimum error rate training in statisticalmachine translation.
In ACL, Sapporo, Japan.P.
Resnik, M. Olsen, and M. Diab.
1997.
Creating aparallel corpus from the book of 2000 tongues.
InText Encoding Initiative 10th Anniversary User Con-ference, Providence, RI, USA.C.
Schafer and D. Yarowsky.
2002.
Inducing translationlexicons via diverse similarity measures and bridgelanguages.
In CoNLL, Taipei, Taiwan.K.
C. Sim, W. J. Byrne, M. J. F. Gales, H. Sahbi, and P. C.Woodland.
2007.
Consensus network decoding forstatistical machine translation system combination.
InIEEE International Conference on Acoustics, Speech,and Signal Processing, Honolulu, HI, USA.M.
Simard.
1999.
Text translation alignment: Three lan-guages are better than two.
In EMNLP-VLC, CollegePark, MD, USA.N.
Ueffing and H. Ney.
2005.
Word-level confidenceestimation for machine translation using phrase-basedtranslation models.
In EMNLP, pages 763 ?
770, Van-couver, Canada.UN, 2006.
ODS UN Parallel Corpus.
http://ods.un.org/.S.
Vogel, H. Ney, and C. Tillmann.
1996.
HMM basedword alignment in statistical translation.
In COLING,pages 836?841, Copenhagen, Denmark.50
