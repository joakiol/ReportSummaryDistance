Robust  Pars ing Based on Discourse Information:Complet ing  par t ia l  parses  o f  i l l - fo rmed sentenceson  the  bas is  o f  d i scourse  in fo rmat ionTetsuya  NasukawaIBM Research ,  Tokyo  Research  Laboratory1623-14, Sh imotsurmna,  Yamato-sh i ,  Kanagawa-ken  242, JapannasukawaOtr l ,  vnet.
ibm.
comAbst rac tIn a consistent text, many words andphrases are repeatedly used in more thanone sentence.
When an identical phrase(a set of consecutive words) is repeated indifferent sentences, the constituent wordsof those sentences tend to be associated inidentical modification patterns with identi-cal parts of speech and identical modifiee-modifier relationships.
Thus, when asyntactic parser cannot parse a sentenceas a unified structure, parts of speechand modifiee-modifier relationships amongmorphologically identical words in com-plete parses of other sentences within thesame text provide useful information forobtaining partial parses of the sentence.In this paper, we describe a method forcompleting partial parses by maintainingconsistency among morphologically identi-cal words within the same text as regardstheir part of speech and their modifiee-modifier relationship.
The experimentalresults obtained by using this method withtechnical documents offer good prospectsfor improving the accuracy of sentenceanalysis in a broad-coverage natural lan-guage processing system such as a machinetranslation system.1 In t roduct ionIn order to develop a practical natural anguage pro-cessing (NLP) system, it is essential to deal withill-formed sentences that cannot be parsed correctlyaccording to the grammar ules in the system.
Inthis paper, an "ill-formed sentence" means one thatcannot be parsed as a unified structure.
A syntac-tic parser with general grammar ules is often un-able to analyze not only sentences with grammati-cal errors and ellipses, but also long sentences, ow-ing to their complexity.
Thus, ill-formed sentencesinclude not only ungrammatical sentences, but alsosome grammatical sentences that cannot be parsedas unified structures owing to the presence of un-known words or to a lack of completeness in thesyntactic parser.
In texts from a restricted omain,such as computer manuals, most sentences are gram-matically correct.
However, even a well-establishedsyntactic parser usually fails to generate a unifiedparsed structure for about 10 to 20 percent of all thesentences in such texts, and the failure to generatea unified parsed structure in syntactic analysis leadsto a failure in the output of a NLP system.
Thus,it is indispensable to establish a correct analysis forsuch a sentence.To handle such sentences, most previous ap-proaches apply various heuristic rules (Jensen etal., 1992; Douglas and Dale, 1992; Richardson andBraden-Harder, 1988), including?
Relaxing constraints in the condition part of agrammatical rule, such as number and genderconstraints?
Joining partial parses by using meta rules.Either way, the output reflects the general plausibil-ity of an analysis that can be obtained from infor-mation in the sentence; however, the interpretationof a sentence depends on its discourse, and incon-sistency with recovered parses that contain differentanalyses of the same phrase in other sentences in thediscourse often results in odd outputs of the naturallanguage processing system.Starting from the viewpoint hat an interpretationof a sentence must be consistent in its discourse, weworked on completing incomplete parses by usinginformation extracted from complete parses in thediscourse.
The results were encouraging.
Since mostwords in a sentence are repeatedly used in other sen-tences in the discourse, the complete parses of well-formed sentences usually provided some useful infor-mation for completing incomplete parses in the samediscourse.
Thus, rather than trying to enhance asyntactic parser's grammar ules in order to supportill-formed sentences, which seems to be an endlesstask after the parser has obtained enough coverageto parse general grammatical sentences, we treat the39syntactic parser as a black box and complete incom-plete parses, in the form of partially parsed chunksthat a bottom-up arser outputs for ill-formed sen-tences, by using information extracted from the dis-course.In the next section, the effectiveness of using in-formation extracted from the discourse to completesyntactic analysis of ill-formed sentences.
After that,we propose an algorithm for completing incompleteparses by using discourse information, and give theresults of an experiment on completing incompleteparses in technical documents.2 D iscourse  in fo rmat ion  fo rcomplet ing  incomplete  parsesIn this section, we use the word "discourse" todenote a set of sentences that forms a text con-cerning related topics.
Gale (Gale et al, 1992) andNasukawa (Nasukawa, 1993) reported that polyse-mous words within the same discourse have the sameword sense with a high probability (98% accord-ing to (Gale et al, 1992),) and the results of ouranalysis indicate that most content words are fre-quently repeated in the discourse, as is shown inTable 1; moreover, collocation (modifier-modifiee r -lationship) patterns are also repeated frequently inthe same discourse, as is shown in Figure 1.
Thisfigure reflects the analysis of structurally ambiguousphrases in a computer manual consisting of 791 con-secutive sentences for discourse sizes ranging from10 to 791 sentences.
For each structurally ambigu-ous phrase, more than one candidate collocation pat-tern was formed by associating the structurally am-biguous phrase with its candidate modifiees 1 and acollocation pattern identical with or similar to eachof these candidate collocation patterns was searchedfor in the discourse.
An identical collocation patternis one in which both modifiee and modifier sides con-sist of words that are morphologically identical withthose in the sentence being analyzed, and that standin an identical relationship.
A similar collocationpattern is one in which either the modifiee or modi-tier side has a word that is morphologically identicalwith the corresponding word in the sentence beinganalyzed, while the other has a synonym.
Again,the relationship of the two sides is identical withthat in the sentence being analyzed.
Except in thecase where all 791 sentences were referred to as adiscourse, the results indicate the averages obtainedby referring to each of several sample areas as a dis-course.
For example, to obtain data for the case inwhich the size of a discourse was 20 sentences, weexamined 32 areas each consisting of 20 sentences,1 For example, in the sentenceYou can use the folder on the desktop,the ambiguous phrase, on the desktop, forms two candi-date collocation patterns:"use -(on)- desktop" and '%lder -(on)- desktop.
"such as the 1st sentence to the 20th, the 51st to the70th, and the 701st to the 720th.
Thus, Figure 1indicates that a collocation pattern either identicalwith or similar to at least one of the candidate collo-cation patterns of a structurally ambiguous phrasewas found within the discourse in more than 70% ofcases, provided the discourse contained more than300 consecutive sentences.On the assumption that this feature of words in adiscourse provides a clue to improving the accuracyof sentence analysis, we conducted an experimenton sentences for which a syntactic parser generatedmore than one parse tree, owing to the presence ofwords that can be assigned to more than one partof speech, or to the presence of complicated coor-dinate structures, or for various other reasons.
Ifthe constituent words tend to be associated in iden-tical modification patterns with an identical partof speech and identical modifiee-modifier relation-ship when an identical phrase (a set of consecutivewords) is repeated in different sentences within thediscourse, the candidate parse that shares the mostcollocation patterns with other sentences in the dis-course should be selected as the correct analysis.Out of 736 consecutive sentences in a computer man-ual, the ESG parser (McCord, 1991) generated mul-tiple parses for 150 sentences.
In this experiment, wedivided the original 736 sentences into two texts, onea discourse of 400 sentences and the other a discourseof 336 sentences.
Of the 150 sentences with multipleparses, 24 were incorrectly analyzed in all candidateparses or had identical candidate parses; we there-fore focused on the other 126 sentences.
In eachcandidate parse of these sentences, we assigned ascore for each collocation that was repeated in othersentences in the discourse (in the form of either anidentical collocation or a similar collocation), andadded up the collocation scores to assign a prefer-ence value to the candidate parse.
Out of the 126sentences, different preference values were assignedto candidate parses in 54 sentences, and the highestvalue was assigned to a correct parse in 48 (88.9%)of the 54 sentences.
Thus, there is a strong tendencyfor identical collocations to be actually repeated inthe discourse, and when an identical phrase (a setof consecutive words) is repeated in different sen-tences, their constituent words tend to be associatedin identical modification patterns.Figure 2 shows the output of the PEG parser(Jensen, 1992) for the following sentence:(2.1) As you can see, you can choose from manytopics to find out what information is availableabout the AS /400  system.This is the 53rd sentence in Chapter 6 of a computermanual (IBM, 1992), mid every word of it is repeat-edly used in other sentences in the same chapter, asshown in Table 2.
For example, the 39th sentencein the same chapter contains "As you can see," as40Table 1: Frequency of morphologically identical words in computer manuaJsPart Freq.
of morph, identical words Proportion of all content wordsof Two or more Five or more Total number of Proportionspeech times (%) times (%) appearances (words) (%)Noun 90.7 76.2 99047 59.8Verb 94.9 83.6 35622 21.5Adjective 88.9 71.0 16941 10.2Adverb 68.8 4993 3.0Pronoun85.998.0 94.8 8911 5.4Total \[ 91.6 78.0 165514 I - -Rate of repetition (%)100.00  - -80 .00  - -60 .00-40 .00  -20.00-0 .00-J0 200 400 600Size of discourse800 (Number of sentences)Figure 1: Rate of finding identical or similar collocation patterns in relation to the size of the discourseshown in Figure 3.
The sentences that contain somewords in common with sentence (2.1) provide infor-mation that is very useful for deriving a correct parseof the sentence.
Table 2 also shows that the partsof speech (POS) for most words in sentence (2.1)can be derived from words repeated in other sen-tences in the same chapter.
In this table, the up-percase letters below the top sentence indicate theparts of speech that can be assigned to the wordsabove.
Underneath the candidate part of speech, re-peated phases in other sentences are presented alongwith the part of speech of each word in those sen-tences; thus, the first word of sentence (2.1), "As,"can be a conjunction, an adverb, or a preposition,but complete parses of the 39th and 175th sentencesindicate that in this discourse the word is used as aconjunction when it is used in the phrase "As youca~ see.
"Furthermore, information on the dependenciesamong most words in sentence (2.1) can be extractedfrom phrases repeated in other sentences in the samechapter, as shown in Figure 4.
~2Thick arrows indicate dependencies xtracted fl'omthe discourse information.3 Imp lementat ion3.1 A lgor i thmAs we showed in the previous section, informationthat is very useful for obtaining correct parses of ill-formed sentences i provided by complete parses ofother sentences in the same discourse in cases wherea parser cannot construct a parse tree by using itsgrammar ules.
In this section, we describe an al-gorithm for completing incomplete parses by usingthis information.The first step of the procedure is to extract fi'oman input text discourse information that the systemcan refer to in the next step in order to complete in-complete parses.
The procedure for extracting dis-course information is as follows:1.
Each sentence in the whole text given as a dis-course is processed by a syntactic parser.
Then,except for sentences with incomplete parses andmultiple parses, the results of each parse arestored as discourse information.
To be pre-cise, the position and the part of speech ofeach instance of every lemma are stored alongwith the lemma's modifiee-modifier relation-ships with other content words extracted from41((XXXX (COMMENT(CONJ(NP(AUXP(VERB*(PUNC ",")(VP (NP(AUXP(VERB*(PP(VP* (INFCL(NP(VERB*(AJP?
(PUNC ". ")
)"as")(PRON* "you" ("you" (SG PL))))(VERB* "can" ("can" PS)))"see" ("see" PS)))(PRON* "you" ("you" (SG PL))))(VERB* "can" ("can" PS)))"choose" ("choose" PS))(PP (PREP* "from"))(QUANP (ADJ* "many" ("many" BS)))(NOUN* "topics" ("topic" PL))))(INFT0 (PREP* "to") )(VERB* "find" ("find" PS))(COMPCL (COMPL "")(VERB* "out" ("out" PS))(NP (PRON* "vhat" ("what" (SG PL))))))(NOUN* "information" ("information" SG)))"is" ("be" PS))(ADJ* "available" ("available" BS))(PP (PP (PREP* "about") )(DETP (ADJ* "the" ("the" BS)))(NP (NOUN* "AS/400" ("AS/400" (SG PL))))(NOUN* "system" ("system" SG)))))0)Figure 2: Example of an incomplete parse obtained by the PEG parserAs you can see, the help display provides additional information about the menu optionsava/lable, as well as a list of related topics.
((DECL (SUBCL(NP(VERB*(CONJ "as")(NP (PRON* "you" ("you" (SG PL))))(AUXP (VERB* "can" ("can" PS)))(VERB* "see" ("see" PS))(PUNC ,,,,,))(DETP (ADJ* "the" ("the" BS)))(NP (NOUN* "help" ("help" SG)))(NOUN* "display" ("display" SG)))"provides" ("provide" PS))Figure 3: Thirty-ninth sentence of Chapter 6 and a part of its parsethe parse data.
Table 3 shows an example ofsuch information.
In this table, CFRAMEuuuuuuindicates an instance of cursor in the discourse;information on the position and on the wholesentence can be extracted from each occurrenceof CFRAME.
In accumulating discourse informa-tion, a score of 1.0 is awarded for each definitemodifiee-modifier relationship.
A lower score,0.1, is awarded for each ambiguous modifiee-modifier relationship, since such relationshipsare less reliable.2.
When all the sentences have been parsed, thediscourse information is used to select the mostpreferable candidate for sentences with multi-ple possible parses, and the data of the selectedparse are added to the discourse information.After all the sentences except the ill-formed sen-tences that caused incomplete parses have provideddata for use as discourse information, the parse com-pletion procedure begins.The initial data used in the completion procedureare a set of partial parses generated by a bottom-upparser as an incomplete parse tree.
For example, thePEG parser generated three partial parses for sen-tence (2.1), consisting of "As you can see," "you canchoose from many topics," and "to find out whatinformation is available about the AS/400 system,"as shown in Figure 2.
Since partial parses are gen-erated by means of grammar ules in a parser, wedecided to restructure ach partial parse and unifythem according to the discourse information, ratherthan construct he whole parse tree from discourseinformation.The completion procedure consists of two steps:S tep  1: Inspect ing  each  par t ia l  parse  andres t ructur ing  it on the  basis  o f  the  d iscoursein fo rmat ionFor each word in a partial parse, the part of speechand the rood,flee-modifier relationships with otherwords are inspected.
If they are different from those42Table 2: Selecting POS candidates on the basis of discourse informationAs you can see, you can choose from many topics to find outCandidates CJ PN N N PN N V PP AJ N PP N PPfor the POS AV V V V N V Nof each word PP PN AV PPVAs you can see, appears in sentences 39, 175.Phrasesrepeatedwithin thediscourseCJ PN V V you can choose appears in sentences 179.PN V V many appears in sentences 49.AJ I topics find out whatappears in sentences 39, 140 , 145 , 160, 161 167 169... N to find \[appears in sentences 236.
PP V 1appears in sentences 32.
V PP (PN)POS CJ PN V V PN V V PP AJ N PP V PPwhat information is available about the AS/400 system.Candidates AJ N V AJ AJ DET N Nfor the POS AV AVof each word PN PPPhrases what information is available about the appears in sentences 49.repeated AJ N V AJ PP DETwithin the the AS/400 system.discourse appears in sentences 6, 109, 115.
DET N NPOS PN N V AJ PP DET N NAJN=noun PN= ~ronoun V=verb A J----adjective AV=adverb CJ=conjunction PP=preposition DET=determiner".
?,Figure 4: Construct ing a dependency structure bycombining dependencies xisting within phrases thatoccur in other sentences of the same chapterin the discourse information, the partial parse is re-structured according to the discourse information.For example,  Figure 5 shows an incomplete parseof the following sentence, which is the 43rd sentencein a technical text that consists of 175 sentences.
3(3.1) Fig.
3 is an isometr ic v iew of  the magazinetaken from the operator's side with one car-tridge shown in an unprocessed position andtwo cartridges shown in a processed position.In the second partial parse, the word "side" is an-alyzed as a verb.
The same word appears fifteentimes in the discourse information extracted fromwell-formed sentences, and is analyzed as a noun ev-ery t ime it appears in complete parses; furthermore,there are no data on the noun "operator" modify-ing the verb "take" through the preposition "from,"while there is information on the noun "operator's"modifying the noun "side," as in sentence (3.2), andon the noun "side" modifying the verb "take," as insentence (3.3).
(3.2) In the operation of  the invention, an oper-ator loads cartridges into the magazine from3This structure resulting from an incomplete parsedoes not indicate that the grammar of the parser lacks arule for handling a possessive case indicated by an apos-trophe and an s. When the parser fails to generate aunified parse, it outputs partial parses in such a mannerthat fewer partial parses cover every word in the inputsentence.43Table 3: Discourse information on modifiees and modifiers of a noun "cursor"ModifiersPOS Relation Word (CFRAMEs preference value)Noun of display (CFRAME106873 0.1)in protected area (CFRAME106872 1)to left (CFRAME106407 0.1) right(CFRAME106338 0.1)DIRECT position (CFRAME106405 1)Adjective up line (CFRAME106295 0.1)DIRECT your (CFRAMEI06690 CFRAMEI06550 2)POS RelationVerb withupSUBJOBJRECIPIENTModifieesWord (CFRAMEs preference value)play (CFRAME106928 0.1) be (CFRAMEI06927 0.1)move (CFRAME106688 1)stop (CFRAME106572 1) reach (CFRAME106346 1) move (CFRAME106248 1)move (CFRAME106402 CFKAME106335 CFRAME106292 3) confuse (CFRAME106548 1)move (CFRAME106304 1)isometric view (n) I~"~f.
':~,~ magazine (n) ltaken Ivll~:: ~o.
:~o':q operator (n) \].
......... and (conj) \]q one cartridge (n) J~\[" shown (v) l~':!n'~q unprocessed position (n) \]two cartridges (n) IJ shown (v) l~,':!ni-- \[ processed position (n) \]Figure 5: Example of an incomplete parse by theESG parserthe operator's ide as seen in Figs.
3 and 12.
(151st sentence)(3.3) Fig.
4 is an isometric view of the magazinetaken from the machine side with one cartridgeshown in the unprocessed position and two car-tridges shown in the processed position.
(44thsentence)Therefore, these two partial parses are restructuredby changing the part of speech of the word "side"to noun, and the modifiee of the noun "operator" tootric view (n)J~.~ :~'f.
':~.~ magazine (n)li from !"
~  operator (n)\].
.
!
.
.
.
.
.
.
with\[ and (conj) \]I one cartridge (n)\]  ho.n,v,J  -4:.u -Z-oce,sed, pos,,onCn)\] two cartridges (n) J #~,~ shown (v)J~:!n:}--\[ processed position (n) \]Figure 6: Example of a completed parsethe noun "side," while at the same time changingthe modifiee of the noun "side" to the verb "take.
"As a result, a unifed parse is obtained, as shown inFigure 6.S tep  2: J o in ing  par t ia l  parses  on  the  basis  ofthe  d i scourse  in fo rmat ionIf the partial parses are not unified into a singlestructure in the previous step, they are joined to-gether on the basis of the discourse information untila unified parse is obtained.44Partial parses are joined as follows:First, the possibility of joining the first two partiMparses is examined, then, either the unification ofthe first two parses or the second parse is examinedto determine whether it can be joined to the thirdparse, then the examination moves to the next parse,and so on.Two partial parses are joined if the root (headnode) of either parse tree can modify a node inthe other parse without crossing the modification ofother nodes.To examine the possibility of modification, dis-course information is applied at three different lev-els.
First, for a candidate modifier and modifiee,an identical pattern containing the modifier wordand the modifiee word in the same part of speechand in the same relationship is searched for in thediscourse information.
Next, if there is no identi-cal pattern, a modification pattern with a synonym(Collins, 1984) of the node on one side is searchedfor in the discourse information.
Then, if this alsofails, a modification pattern containing a word thathas the same part of speech as the word on one sideof the node is searched for.Since the discourse information consists of mod-ification patterns extracted from complete parses,it reflects the grammar ules of the parser, and amatching pattern with a part of speech rather thanan actual word on one side can be regarded as arelaxation rule, in the sense that syntactic and se-mantic constraints are less restrictive than the cor-responding rammar ule in the parser.These matching conditions at different levels areapplied in such a manner that partial parses arejoined through the most preferable nodes.3.2 Resu l tsWe have implemented this method on an English-to-Japanese machine translation system called Shalt2(Takeda et al, 1992), and conducted experimentsto evaluate the effectiveness of this method.
Ta-ble 4 gives the result of our experiments on twotechnical documents of different kinds, one a patentdocument (text 1), and the other a computer man-ual (text 2).
Since text 1 contained longer andmore complex sentences thml text 2, our ESG parserfailed to generate unified parses more often in text1; on the other hand, the frequency of morpholog-ically identical words and collocation patterns washigher in text 1, and our method was more effec-tive in text 1.
In both texts, the discourse infor-mation provided enough information to unify par-tial parses of an incomplete parse in more than halfof the cases.
However, the resulting unified parseswere not always correct.
Since sentences with in-complete parses are usually quite long and containcomplicated structures, it is hard to obtain a per-fect analysis for those sentences.
Thus, in order toevaluate the improvement in the output translationrather than the improvement in the rate of successin syntactic analysis, in which only perfect analy-ses are counted, we compared output translationsgenerated with and without the application of ourmethod.
When our method was not applied, partialparses of an incomplete parse were joined by meansof some heuristic rules such as the one that joins apartial parse with "NP" ill its root node to a partialparse with "VP" in its root node, and the root nodeof the second partial parse was joined to the lastnode of the first partial parse by default.
When thediscourse information did not provide enough infor-mation to unify partial parses with the applicationof our method, the heuristic rules were applied.
Insuch cases the default rule of joining the root node ofthe second partial parse to the last node of the firstpartial parse was mostly applied, since the least re-strictive matching patterns in our method were sim-ilar to the heuristic rules.
Thus, the system gen-erated a unified parse for each sentence regardlessof the discourse information, and we compared theoutput translations generated with and without theapplication of our method.
The results are shown inTable 4.
The translations were compared by check-ing how well the output Japanese sentence conveyedthe meaning of the input English sentence.
Sincemost unified parses contained various errors, such asincorrect modification patterns and incorrect partsof speech assigned to some words, fewer errors gen-erally resulted in better translations, but incorrectparts of speech resulted in worse translations.4 Conc lus ionWe have proposed a method for completing partialparses of ill-formed sentences on the basis of informa-tion extracted from complete parses of well-formedsentences in the discourse.
Our approach to han-dling ill-formed sentences i fundamentally differentfrom previous ones in that it reanalyzes the part ofspeech and modifiee-modifier relationships of eachword in an ill-formed sentence by using informationextracted from analyses of other sentences in thesame text, thus, attempting to generate the analy-sis most appropriate to the discourse.
The resultsof our experiments how the effectiveness of thismethod; moreover, implementation of this methodon a machine translation system improved the accu-racy of its translation.
Since this method has a sim-ple framework that does not require any extra knowl-edge resources or inference mechanisms, it is robustand suitable for a practical natural language pro-cessing system.
Furthermore, in terms of the turn-around time (TAT) of the whole translation pro-cedure, the improvement in the parses achieved byusing this method along with other disambiguationmethods involving discourse information, as shownin another paper (Nasukawa, 1995), shortened theTAT in the late stages of the translation procedure,45Table 4: Results of completing incomplete parses on the basis of discourse informationText i Text 2Number of sentences in discourse 175 354Incomplete parses 32 31Unified into a single parse 18 (56.3%) 17 (54.8%)ImprovementintranslationBetterEven 10 7Worse 1 3Partially joined or restructured'" Improvement Betterin Eventranslation Worse12 (37.5%) 8 (25.8%)4 27 31 3Not changed 2 (6.3%) 6 (19.4%)and compensated for the extra TAT required as aresult of using the discourse information, providedthe size of the discourse was kept to between 100and 300 sentences.In this paper, the term "discourse" is used as aset of words in a text together with the usage ofeach of those words in that text - namely, a partof speech and modifiee-modifier relationships withother words.
The basic idea of our method is to im-prove the accuracy of sentence analysis simply bymaintaining consistency in the usage of morphologi-cally identical words within the same text.
Thus, theeffectiveness of this method is highly dependent onthe source text, since it presupposes that morpholog-ically identical words are likely to be repeated in thesame text.
However, the results have been encourag-ing at least with technical documents uch as com-puter manuals, where words with the same lemmaare frequently repeated in a small area of text.
More-over, our method improves the translation accuracy,especially for frequently repeated phrases, which areusually considered to be important, and leads to animprovement in the overall accuracy of the naturallanguage processing system.AcknowledgementsI would like to thank Michael McDonald for in-valuable help in proofreading this paper.
I wouldalso like to thank Taijiro Tsutsumi, Masayuki Mo-rohashi, Koichi Takeda, Hiroshi Maruyama, HiroshiNomiyama, Hideo Watanabe, Shiho Ogino, and theanonymous reviewers for their comments and sug-gestions.Gale, W.A., Church, K.W., and Yarowsky, D. 1992.One Sense per Discourse.
In Proceedings o/the 4thDARPA Speech and Natural Language Workshop.Jensen, K., Heidorn, G.E., Miller, L.A. and Ravin,Y.
1983.
Parse Fitting and Prose Fixing: Gettinga Hold on Ill-Formedness.
Computational Linguis-tics, Vol.
9, Nos.
3-4.Jensen, K. 1992.
PEG: The PLNLP English Gram-mar.
Natural Language Processing: The PLNLPApproach, K. Jensen, G. Heidorn, and S. Richard-son, eds., Boston, Mass.
: Kluwer Academic Pub-lishers.McCord, M. 1991.
The Slot Grammar System.
IBMResearch Report, RC17313.Nasukawa, T. 1993.
Discourse Constraint in Com-puter Manuals.
In Proceedings of TMI-93.Nasukawa, T. 1995.
Shallow and Robust ContextProcessing for a Practical MT System.
To appearin Proceedings of IJCAI-95 Workshop on "Contextin Natural Language Processing.
"Richardson, S.D.
and Braden-Harder, L.C.
1988.The Experience of Developing a Large-Scale Nat-ural Language Text Processing System: CRI-T IQUE.
In Proceedings o/ ANLP-88.Takeda, K., Uramoto, N., Nasukawa, T., and Tsut-sumi, T. 1992.
Shalt2 - A Symmetric MachineTranslation System with Conceptual Transfer.
InProceedings of COLING-92.IBM 1992.
IBM Application System/400 NewUser's Guide Version 2.
IBM Corp.COLLINS 1984.
The New Collins Thesaurus.Collins Publishers, Glasgow.ReferencesDouglas, S. and Dale, R. 1992.
Towards RobustPATR.
In Proceedings of COLING-92.46
