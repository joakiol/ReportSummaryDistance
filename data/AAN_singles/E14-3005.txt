Proceedings of the Student Research Workshop at the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 38?44,Gothenburg, Sweden, April 26-30 2014. c?2014 Association for Computational LinguisticsExpanding the Range of Automatic Emotion Detection inMicroblogging TextJasy Liew Suet YanSchool of Information StudiesSyracuse UniversitySyracuse, New York, USAjliewsue@syr.eduAbstractDetecting emotions on microblogging sites such asTwitter is a subject of interest among researchers inbehavioral studies investigating how people react todifferent events, topics, etc., as well as among usershoping to forge stronger and more meaningfulconnections with their audience through social media.However, existing automatic emotion detectors arelimited to recognize only the basic emotions.
I arguethat the range of emotions that can be detected inmicroblogging text is richer than the basic emotions,and restricting automatic emotion detectors to identifyonly a small set of emotions limits their practicality inreal world applications.
Many complex emotions areignored by current automatic emotion detectorsbecause they are not programmed to seek out these?undefined?
emotions.
The first part of myinvestigation focuses on discovering the range ofemotions people express on Twitter using manualcontent analysis, and the emotional cues associatedwith each emotion.
I will then use the gold standarddata developed from the first part of my investigationto inform the features to be extracted from text formachine learning, and identify the emotions thatmachine learning models are able to reliably detectfrom the range of emotions which humans canreliably detect in microblogging text.1 IntroductionThe popularity of microblogging sites such asTwitter provide us with a new source of data tostudy how people interact and communicate withtheir social networks or the public.
Emotion is asubject of interest among researchers inbehavioral studies investigating how people reactto different events, topics, etc., as well as amongusers hoping to forge stronger and moremeaningful connections with their audiencethrough social media.
There is growing interestamong researchers to study how emotions onsocial media affect stock market trends (Bollen,Mao, & Zeng, 2011), relate to fluctuations insocial and economic indicators (Bollen, Pepe, &Mao, 2011), serve as a measure for thepopulation?s level of happiness (Dodds &Danforth, 2010), and provide situationalawareness for both the authorities and the publicin the event of disasters (Vo & Collier, 2013).In order to perform large-scale analysis ofemotion phenomena and social behaviors onsocial media, there is a need to first identify theemotions that are expressed in text as theinteractions on these platforms are dominantlytext-based.
With the surging amount ofemotional content on social media platforms, it isan impossible task to detect the emotions that areexpressed in each message using manual effort.Automatic emotion detectors have beendeveloped to deal with this challenge.
However,existing applications still rely on simple keywordspotting or lexicon-based methods due to theabsence of sufficiently large emotion corpora fortraining and testing machine learning models38(Bollen, Pepe, et al., 2011; Dodds & Danforth,2010).Research in using machine learningtechniques to process emotion-laden text isgaining traction among sentiment analysisresearchers, but existing automatic emotiondetectors are restricted to identify only a smallset of emotions, thus limiting their practicalityfor capturing the richer range of emotionsexpressed on social media platforms.
The currentstate-of-the-art of simply adopting the basicemotions described in the psychology literatureas emotion categories in text, as favored by amajority of scholars, is too limiting.
Ekman?s sixbasic emotions (happiness, sadness, fear, anger,disgust, and surprise) (Ekman, 1971) arecommon emotion categories imposed on bothhumans and computers tasked to detect emotionsin text (Alm, Roth, & Sproat, 2005; Aman &Szpakowicz, 2007; Liu, Lieberman, & Selker,2003).
It is important to note that most basicemotions such as the six from Ekman are derivedfrom facial expressions that can be universallyrecognized by humans.
Verbal expressions ofemotion are different from non-verbalexpressions of emotion.
Emotions expressed intext are richer than the categories suggested bythe basic emotions.
Also, people from differentcultures use various cues to express a myriad ofemotions in text.By using a restricted set of emotioncategories, many emotions not included as partof the basic set are ignored or worse still, force-fitted into one of the available emotioncategories.
This introduces a greater level offuzziness in the text examples associated witheach emotion.Example [1]: ?My prayers go to family of Amb.Stevens & others affected by this tragedy.
Wemust not allow the enemy to take another.http://t.co/X8xTzeE4?Example [1] is an obvious case of ?sympathy?as the writer is expressing his or her condolencesto people affected by a tragedy.
If ?sympathy?
isnot in the pre-defined list of emotion categoriesthat humans can choose from, human annotatorsmay label this instance as ?sadness?, which is notentirely accurate.
These inaccuracies will then bepropagated into the automatic emotion detector.While the basic emotions have beenestablished as universal emotions (Ekman,1999), their usefulness in emotion detection intext is still unclear.
How useful are the six basicemotions in detecting consumers?
emotionalreactions towards a product or service frommicroblogs?
What if a company wishes to detectdisappointment?
The focus on only the basicemotions has resulted in a dearth of effort tobuild emotion detectors that are able to recognizea wider range of emotions, especially thecomplex ones.
Complex emotions are not merelycombinations of the basic ones.
For example,none of the combinations of Ekman?s six basicemotions seem to represent ?regret?
or?empathy?.
Without human-annotated examplesof complex emotions, automatic emotiondetectors remain ignorant of these emotionssimply because they are not programmed to seekout these ?undefined?
emotions.There is a need to create automatic emotiondetectors that can detect a richer range ofemotions apart from the six basic emotionsproposed by Ekman to deal with emotionalcontent from social media platforms.
A broaderrange of emotions will enable automatic emotiondetectors to capture more fine-grained emotionsthat truly reflect actual human emotionalexperience.
Limited research has been done sofar to determine the full range of emotions whichhumans can reliably detect in text, as well assalient cues that can be used to identify distinctemotions in text.
A crucial step to address thisgap is to develop a gold standard corpusannotated with a richer set of emotions formachine learning models to learn from.My research goal is to first discover the rangeof emotions humans can reliably detect inmicroblogging text, and investigate specific cueshumans rely on to detect each emotion.
Is there auniversal set of cues humans rely on to detect aparticular emotion or do these cues differ across39individuals?
Using grounded theory, the first partof my investigation focuses on discovering therange of emotions from tweets collected from apopular microblogging site, Twitter, and theemotional cues associated with each emotion.Twitter offers a wealth of publicly availableemotional content generated by a variety of userson numerous topics.
The inherently social natureof interactions on Twitter also allows me toinvestigate social emotions apart from personalemotions.
In the second part of my investigation,human annotations from the first part of myinvestigation will serve as gold standard data formachine learning experiments used to determinethe emotions that automatic methods can reliablydetect from the range of emotions that humanscan reliably identify.2 BackgroundEarly research on automatic emotion detection intext is linked to subjectivity analysis (Wiebe,Wilson, Bruce, Bell, & Martin, 2004; Wiebe,Wilson, & Cardie, 2005).
Emotion detection intext is essentially a form of sentimentclassification task based on finer-grainedemotion categories.
Automatic emotion detectionhas been applied in the domain of emails (Liu etal., 2003), customer reviews (Rubin, Stanton, &Liddy, 2004), children?s stories (Alm et al.,2005), blog posts (Aman & Szpakowicz, 2007),newspaper headlines (Strapparava & Mihalcea,2008), suicide notes (Pestian et al., 2012), andchat logs (Brooks et al., 2013).
Earlydevelopment of automatic emotion detectorsfocused only on the detection of Ekman?s sixbasic emotions: happiness, surprise, sadness, fear,disgust, and anger (Alm et al., 2005; Aman &Szpakowicz, 2007; Liu et al., 2003; Strapparava& Mihalcea, 2008).
Plutchik?s model is anexpansion of Ekman?s basic emotions throughthe addition of trust and anticipation in his eightbasic emotions (Plutchik, 1962), while Izard?sten basic emotions also include guilt and shame(Izard, 1971).Scholars have only recently started to expandthe categories for automatic emotionclassification as noted in the 14 emotions that arepertinent in the domain of suicide notes (Pestianet al., 2012), and 13 top categories that are usedfor emotion classification out of 40 emotions thatemerged from the scientific collaboration chatlogs (Brooks et al., 2013; Scott et al., 2012).However, existing gold standard corpora arelimited by the emotion categories that are mostoften specific to a particular domain.Furthermore, it is difficult to pinpoint the exactwords, symbols or phrases serving as salientemotion indicators because existing goldstandard data are manually annotated at thesentence or message level.Using Twitter, scholars have exploreddifferent strategies to automatically harness largevolumes of data automatically for emotionclassification.
Pak & Paroubek (2010) applied amethod similar to Read (2005) to extract tweetscontaining happy emoticons to represent positivesentiment, and sad emoticons to representnegative sentiment.
First, this limits the emotionclassifier to detect only happiness and sadness.Second, the lack of clear distinctions between theconcepts of sentiment and emotion isproblematic because tweeters may express anegative emotion towards an entity which theyhold a positive sentiment on, and vice versa.
Forexample, a tweeter expressing sympathy toanother person who has experienced anunfortunate event is expressing a negativeemotion but the tweet contains an overallpositive sentiment.
Third, such a data collectionmethod assumes that the emotion expressed inthe text is the same as the emotion the emoticonrepresents, and does not take into account ofcases where the emotion expressed in the textmay not be in-sync with the emotion representedby the emoticon (e.g., sarcastic remarks).Mohammad (2012) and Wang, Chen,Thirunarayan, & Sheth (2012) applied a slightlyimproved method to create a large corpus ofreadily-annotated tweets for emotionclassification.
Twitter allows the use of hashtags(words that begin with the # sign) as topicindicators.
These scholars experimented withextracting tweets that contain a predefined list of40emotion words appearing in the form of hashtags.Mohammad (2012) only extracted tweets withemotion hashtags corresponding to Ekman?s sixbasic emotions (#anger, #disgust, #fear, #joy,#sadness, and #surprise) while Wang et al.
(2012)expanded the predefined hashtag list to includeemotion words associated with an emotioncategory, as well as the lexical variants of theseemotion words.
Although this method allowsresearchers to take advantage of the huge amountof data available on Twitter to train machinelearning models, little is known about thespecific emotional cues that are associated withthese emotion categories.
Also, this datacollection method is biased towards tweeterswho choose to express their emotions explicitlyin tweets.Kim, Bak, & Oh (2012) proposed a semi-supervised method using unannotated data foremotion classification.
They first applied LatentDirichlet Allocation (LDA) to discover topicsfrom tweets, and then determined emotions fromthe discovered topics by calculating thepointwise mutual information (PMI) score foreach emotion from a list of eight emotions givena topic.
The evaluation of this method using acorpus of manually annotated tweets revealedthat this automatic emotion detector onlymanaged to correctly classify 30% of tweetsfrom the test dataset.
The gold standard corpusused for evaluation was developed throughmanual annotations using Amazon MechanicalTurk (AMT).
Only 3% of the tweets received fullagreement among five annotators.3 Defining Emotions In TextIn everyday language, people refer to emotion asprototypes of common emotions such ashappiness, sadness, and anger (Fehr & Russell,1984).
In the scientific realm, emotion isgenerally defined as ?ongoing states of mind thatare marked by mental, bodily or behavioralsymptoms?
(Parrott, 2001).
Specifically, eachemotion category (e.g., happiness, sadness, anger,etc.)
is distinguishable by a set of mental, bodilyor behavioral symptoms.
When a personexpresses emotion in text, these symptoms areencoded in written language (words, phrases andsentences).Emotion in text is conceptualized as emotionexpressed by the writer of the text.
Emotionexpression consists of ?signs that people give invarious emotional states?, usually with theintention to be potentially perceived orunderstood by the others (Cowie, 2009).
Peopleexpress their emotional states through differentnon-verbal (e.g., facial expression, vocalintonation, and gestures) and verbal (e.g., text,spoken words) manifestations.
Emotionexpression in text is a writer?s descriptions of hisor her emotional experiences or feelings.
It isimportant to note that emotion expression onlyprovides a window into a person?s emotionalstate depending on what he or she chooses toreveal to the others.
It may not be depictions of aperson?s actual emotional state, which is alimitation to the study of emotion in text (Calvo& D?Mello, 2010).4 Research QuestionsDetecting emotions in microblog posts posesnew challenges to existing automatic emotiondetectors due to reasons described below:?
Unlike traditional texts, tweets consist ofshort texts expressed within the limit of140 characters, thus the language used toexpress emotions differs from longertexts (e.g., blogs, news, and fairy tales).?
The language tweeters use is typicallyinformal.
Automatic emotion detectorsmust be able to deal with the presence ofabbreviations, acronyms, orthographicelements, and misspellings.?
Emotional cues are not limited to onlyemotion words.
Twitter features such as#hashtags (topics), @username, retweets,and other user profile metadata mayserve as emotional cues.Using data from Twitter, a popularmicroblogging platform, I will develop an initialframework to study the richness of emotions41expressed for personal, as well as for socialpurposes.
My research investigation is guided bythe research questions listed below:?
What emotions can humans reliablydetect in microblogging text??
What salient cues are associated witheach emotion??
How can good features for machinelearning be identified from the salientcues humans associate with each emotion??
What emotions in microblogging text canbe reliably detected using currentmachine learning techniques?5 Proposed MethodologyMy research design consists of three phases: 1)small-scale inductive content analysis for codebook development, 2) large-scale deductivecontent analysis for gold standard datadevelopment, and 3) the design of machinelearning experiments for automatic emotiondetection in text.5.1 Data CollectionWhen sampling for tweets from Twitter, I willutilize three sampling strategies to ensure thevariability of emotions being studied.
First, I willcollect a random sample of publicly-availabletweets.
This sampling strategy aims to create asample that is representative of the population onTwitter but may not produce a collection oftweets with sufficient emotional content.
Thesecond sampling strategy is based on topics orevents.
To ensure that tweets are relevant to thisinvestigation, tweets will be sampled based onhashtags of events likely to evoke text withemotional content.
Topics will include politics,sports, products/services, festive celebrations,and disasters.The third sampling strategy is based on users.This sampling strategy allows me to explore therange of emotions expressed by differentindividuals based on different stimuli, and notbiased towards any specific events.
To make themanual annotation feasible, I plan to first identifythe usernames of 1) active tweeters with a largenumber of followers (e.g., tweets frompoliticians) to ensure sufficient data for analysis,and 2) random tweeters to represent ?average?users of Twitter.
I acknowledge that thissampling strategy may be limited to only certaingroups of people, and may not be representativeof all Twitter users but it offers a good start toexploring the range of emotions being expressedin individual streams of tweets.5.2 Phase 1To develop a coding scheme for emotionannotation, I will first randomly sample 1,000tweets each from the random, topic-based, anduser-based datasets for open coding.
I will workwith a small group of coders to identify theemotion categories from a subset of the 1,000tweets.
Coders will be given instructions toassign each tweet with only one emotion label(i.e., the best emotion tag to describe the overallemotion expressed by the writer in a tweet),highlight the specific cues associated with theemotion, as well as identify the valence andintensity of the emotion expressed in the tweet.To verify the grouping of the emotion tags,coders will be asked to perform a card sortingexercise to group emotion tags that aresemantically similar in the same group.
Based onthe discovered emotion categories, nuancedcolorations within each category may be detectedfrom the valence and intensity codes.Coders will incrementally annotate moretweets (300 tweets per round) until a point ofsaturation is reached, where new emotioncategories stop emerging from data.
I willcontinuously meet with the coders to discussdisagreements until the expected inter-annotatoragreement threshold for the final set of emotioncategories is achieved.5.3 Phase 2Using the coding scheme developed from Phase1, I will obtain a larger set of manual annotationsusing Amazon Mechanical Turk (AMT).
AMTallows me to collect manual annotations of42emotions on a large-scale, thus enabling me toinvestigate if there are any differences as to whata larger crowd of people identify as emotion cuesin tweets.
Each tweet will be annotated by atleast three coders.
To ensure the quality of themanual annotations collected from AMT,workers on AMT will have to undergo a shorttraining module explaining the coding scheme,and will have to pass a verification test beforebeing presented with the actual tweets to beannotated.
Inter-annotator agreement will becalculated, and the emotion categories thathumans can reliably detect in text will beidentified.5.4 Phase 3Detecting a single emotion label for each tweetcan be defined as a multi-class classificationproblem.
The corpus from Phase 2 will be usedas training data, and the corpus from Phase 1 willbe used as testing data for the machine learningmodel.
An analysis of the emotional cues fromPhase 1 and Phase 2 datasets is conducted toidentify salient features to be used for machinelearning.
Support vector machines (SVM) havebeen shown to perform well in this problemspace (Alm et al., 2005; Aman & Szpakowicz,2007; Brooks et al., 2013; Cherry, Mohammad,& de Bruijn, 2012) so I will run experimentsusing SVM, and compare the performance of themodel against a baseline using simple lexicalfeatures (i.e., n-grams).6 Research ContributionsAnalyzing the emotional contents in tweetscan expand the theoretical understanding of therange of emotions humans express on socialmedia platforms like Twitter.
From a naturallanguage processing standpoint, it is also crucialfor the community to gain clearer insights on thecues associated with each fine-grained emotion.On top of that, findings from the machinelearning experiments will inform the communityas to whether training the machine learningmodels based on data collected using usernames,instead of topic hashtags will reduce noise in thedata, and improve the performance of automaticemotion detection in microblogging texts.The expected contributions of this researchinvestigation are three-fold: 1) the constructionof an emotion taxonomy and detailed annotationscheme that could provide a useful starting pointfor future research, 2) the creation of machinelearning models that can detect a wider range ofemotions in text in order to enable researchers totap into this wealth of information provided byTwitter to study a greater multitude of behavioraland social phenomenon, and 3) findings on therange of emotions people express on Twitter canpotentially help inform the design of socialnetwork platforms to be more emotion sensitive.ReferencesAlm, C. O., Roth, D., & Sproat, R. (2005).
Emotionsfrom text: Machine learning for text-basedemotion prediction.
In Proceedings of theConference on Human Language Technologyand Empirical Methods in Natural LanguageProcessing (pp.
579?586).
Stroudsburg, PA,USA.Aman, S., & Szpakowicz, S. (2007).
Identifyingexpressions of emotion in text.
In Text,Speech and Dialogue (pp.
196?205).Bollen, J., Mao, H., & Zeng, X.
(2011).
Twitter moodpredicts the stock market.
Journal ofComputational Science, 2(1), 1?8.Bollen, J., Pepe, A., & Mao, H. (2011).
Modelingpublic mood and emotion: Twitter sentimentand socio-economic phenomena.
InProceedings of the Fifth International AAAIConference on Weblogs and Social Media(pp.
450?453).Brooks, M., Kuksenok, K., Torkildson, M. K., Perry,D., Robinson, J. J., Scott, T. J., ?
Aragon,C.
R. (2013).
Statistical affect detection incollaborative chat.
Presented at theConference on Computer SupportedCooperative Work and Social Computing,San Antonio, TX.Calvo, R. A., & D?Mello, S. (2010).
Affect detection:An interdisciplinary review of models,methods, and their applications.
IEEETransactions on Affective Computing, 1(1),18?37.Cherry, C., Mohammad, S. M., & de Bruijn, B.(2012).
Binary classifiers and latent sequence43models for emotion detection in suicidenotes.
Biomedical Informatics Insights, 5,147?154.Cowie, R. (2009).
Perceiving emotion: Towards arealistic understanding of the task.Philosophical Transactions of the RoyalSociety of London B: Biological Sciences,364(1535), 3515?3525.Dodds, P. S., & Danforth, C. M. (2010).
Measuringthe happiness of large-scale writtenexpression: Songs, blogs, and Presidents.Journal of Happiness Studies, 11(4), 441?456.Ekman, P. (1971).
Universals and cultural differencesin facial expressions of emotion.
NebraskaSymposium on Motivation, 19, 207?283.Ekman, P. (1999).
Basic emotions.
In Handbook ofCognition and Emotion (pp.
45?60).
JohnWiley & Sons, Ltd.Fehr, B., & Russell, J.
A.
(1984).
Concept of emotionviewed from a prototype perspective.Journal of Experimental Psychology:General, 113(3), 464?486.Izard, C. E. (1971).
The face of emotion (Vol.
xii).East Norwalk,  CT,  US: Appleton-Century-Crofts.Kim, S., Bak, J., & Oh, A. H. (2012).
Do you feelwhat I feel?
Social aspects of emotions inTwitter conversations.
In International AAAIConference on Weblogs and Social Media(ICWSM).Liu, H., Lieberman, H., & Selker, T. (2003).
A modelof textual affect sensing using real-worldknowledge.
In Proceedings of the 8thInternational Conference on Intelligent UserInterfaces (pp.
125?132).Mohammad, S. M. (2012).
#Emotional tweets.
InProceedings of the First Joint Conference onLexical and Computational Semantics.Montreal, QC.Pak, A., & Paroubek, P. (2010).
Twitter as a corpusfor sentiment analysis and opinion mining.
InSeventh International Conference onLanguage Resources and Evaluation(LREC).Parrott, W. G. (2001).
Emotions in social psychology:Essential readings (Vol.
xiv).
New York,NY,  US: Psychology Press.Pestian, J. P., Matykiewicz, P., Linn-Gust, M., South,B., Uzuner, O., Wiebe, J., ?
Brew, C.(2012).
Sentiment analysis of suicide notes:A shared task.
Biomedical InformaticsInsights, 5(Suppl.
1), 3?16.Plutchik, R. (1962).
The Emotions: Facts, theories,and a new model.
New York: RandomHouse.Read, J.
(2005).
Using emoticons to reducedependency in machine learning techniquesfor sentiment classification.
In Proceedingsof the ACL Student Research Workshop (pp.43?48).
Stroudsburg, PA, USA.Rubin, V. L., Stanton, J. M., & Liddy, E. D. (2004).Discerning emotions in texts.
In The AAAISymposium on Exploring Attitude and Affectin Text (AAAI-EAAT).Scott, T. J., Kuksenok, K., Perry, D., Brooks, M.,Anicello, O., & Aragon, C. (2012).
Adaptinggrounded theory to construct a taxonomy ofaffect in collaborative online chat.
InProceedings of the 30th ACM InternationalConference on Design of Communication(pp.
197?204).
New York, USA.Strapparava, C., & Mihalcea, R. (2008).
Learning toidentify emotions in text.
In Proceedings ofthe 2008 ACM Symposium on AppliedComputing (pp.
1556?1560).
New York,USA.Vo, B.-K. H., & Collier, N. (2013).
Twitter emotionanalysis in earthquake situations.International Journal of ComputationalLinguistics and Applications, 4(1), 159?173.Wang, W., Chen, L., Thirunarayan, K., & Sheth, A. P.(2012).
Harnessing Twitter ?big data?
forautomatic emotion identification.
In 2012International Conference on Privacy,Security, Risk and Trust (PASSAT), and 2012International Conference on SocialComputing (SocialCom) (pp.
587?592).Wiebe, J. M., Wilson, T., Bruce, R., Bell, M., &Martin, M. (2004).
Learning subjectivelanguage.
Computational Linguistics, 30(3),277?308.Wiebe, J. M., Wilson, T., & Cardie, C. (2005).Annotating expressions of opinions andemotions in language.
Language Resourcesand Evaluation, 39(2-3), 165?210.44
