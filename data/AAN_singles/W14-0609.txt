Proceedings of the 8th Workshop on Language Technology for Cultural Heritage, Social Sciences, and Humanities (LaTeCH) @ EACL 2014, pages 62?70,Gothenburg, Sweden, April 26 2014.c?2014 Association for Computational LinguisticsMining the Twentieth Century?s History from the Time Magazine CorpusMike KestemontUniversity of AntwerpPrinsstraat 13, D.188B-2000, AntwerpBelgiummike.kestemont@uantwerpen.beFolgert KarsdorpMeertens InstitutePostbus 942641090 GG AmsterdamThe NetherlandsFolgert.Karsdorp@meertens.knaw.nlMarten D?uringUniversity of North-Carolina551 Hamilton HallCB 3195, Chapel HillNorth Carolina 27599United Statesmarten@live.unc.eduAbstractIn this paper we report on an explorativestudy of the history of the twentieth cen-tury from a lexical point of view.
Asdata, we use a diachronic collection of270,000+ English-language articles har-vested from the electronic archive of thewell-known Time Magazine (1923?2006).We attempt to automatically identify sig-nificant shifts in the vocabulary used inthis corpus using efficient, yet unsuper-vised computational methods, such as Par-simonious Language Models.
We offer aqualitative interpretation of the outcomeof our experiments in the light of momen-tous events in the twentieth century, suchas the Second World War or the rise ofthe Internet.
This paper follows up on arecent string of frequentist approaches tostudying cultural history (?Culturomics?
),in which the evolution of human culture isstudied from a quantitative perspective, onthe basis of lexical statistics extracted fromlarge, textual data sets.1 Introduction: CulturomicsAlthough traditionally, the Humanities have beenmore strongly associated with qualitative ratherthan quantitative methodologies, it is hard to missthat ?hipster?
terms like ?Computational Analy-sis?, ?Big Data?
and ?Digitisation?, are currentlytrending in Humanities scholarship.
In the interna-tional initiative of Digital Humanities, researchersfrom various disciplines are increasingly explor-ing novel, computational means to interact withtheir object of research.
Often, this is done in col-laboration with researchers from ComputationalLinguistics, who seem to have adopted quantita-tive approaches relatively sooner than other Hu-manities disciplines.
The subfield of Digital His-tory (Zaagsma, 2013), in which the present paperis to be situated, is but one of the multiple Human-ities disciplines in which rapid progress is beingmade as to the application of computational meth-ods.
Although the vibrant domain of Digital His-tory cannot be exhaustively surveyed here due tospace limits, it is nevertheless interesting to referto a recent string of frequentist lexical approachesto the study of human history, and the evolution ofhuman culture in particular: ?Culturomics?.This line of computational, typically data-intensive research seeks to study various aspects ofhuman history, by researching the ways in which(predominantly cultural) phenomena are reflectedin, for instance, word frequency statistics extractedfrom large textual data sets.
The field has been ini-tiated in a lively, yet controversial publication byMichel et al.
(2011), which ?
while it has inviteda lot of attention in popular media ?
has not goneuncriticized in the international community of Hu-manities.1In this paper, the authors show how anumber of major historical events show interest-ing correlations with word counts in a vast corpusof n-grams extracted from the Google Books, al-legedly containing 4% percent of all books everprinted.In recent years, the term ?Culturomics?
seemsto have become an umbrella term for studies en-gaging, often at an increasing level of complex-ity, with the seminal, publicly available GoogleBooks NGram Corpus (Juola, 2013; Twenge et al.,2012; Acerbi et al., 2013b).
Other studies, likethe inspiring contribution by Leetaru (2011) haveindependently explored other data sets for simi-lar purposes, such as the retroactive prediction ofthe Arab Spring Revolution using news data.
In1Consult, for instance, the critical report by A. Graftonon the occasion of a presentation by Michel and LiebermanAiden at one of the annual meetings of the American His-torical Association (https://www.historians.org/publications-and-directories/perspectives-on-history/march-2011/loneliness-and-freedom).62the present paper, we seek to join this recent lineof Culturomics research: we will discuss a seriesof quantitative explorations of the Time MagazineCorpus (1923?2006), a balanced textual data setcovering a good deal of the twentieth (and earlytwenty-first) century.The structure of the paper is as follows: in thefollowing section 2, we will discuss the data setused.
In section 3, we will introduce some ofthe fundamental assumptions underlying the Cul-turomics approach for Big Data, and report onan experiment that replicates an earlier sentiment-related analysis of the Google Books Corpus(Acerbi et al., 2013b) using our Time data.
Subse-quently, we will apply a Parsimonious LanguageModel to our data (section 4) and assess from aqualitative perspective how and whether this tech-nique can be used to extract the characteristic vo-cabulary from specific time periods.
To conclude,we will use these Parsimonious Language Mod-els in a variability-based neighbor clustering (sec-tion 5), in an explorative attempt to computation-ally identify major turning points in the twentiethcentury?s history.2 Data: Time Magazine CorpusFor the present research, we have used a collectionof electronic articles harvested from the archive ofthe well-known weekly publication Time Maga-zine.
The magazine?s online archive is protectedby international copyright law and it can only beconsulted via a paying subscription.2Therefore,the corpus cannot be freely redistributed in anyformat.
To construct the corpus, we have usedmetadata provided by corpus linguist Mark Davieswho has published a searchable interface to theTime Corpus (Davies, 2013).
For the presentpaper, we were only dependent on the uniqueidentification number and publication year whichDavies provides for each article.
Users who are in-terested in downloading (a portion of) the corpuswhich we used, can use this metadata to replicateour findings.We have used the Stanford CoreNLP Suite toannotate this collection (with its default settingsfor the English language).3We have tokenizedand lemmatized the corpus with this tool suite.Additionally, we have applied part-of-speech tag-2http://content.time.com/time/archive.3http://nlp.stanford.edu/software/corenlp.shtmlPeriod # Documents # Word forms # Unique forms1920s 24,332 11,155,681 158,4431930s 32,788 20,622,526 222,7771940s 41,832 22,547,958 234,9181950s 42,249 25,638,032 251,6581960s 35,440 27,355,389 258,2761970s 27,804 25,449,488 218,3221980s 25,651 24,185,889 208,6781990s 23,300 20,637,179 204,3932000s 17,299 14,151,399 176,515Overall 270,695 191,743,541 867,399Table 1: General word frequency statistics on thereconstructed version of the Time Corpus (1923-2006).ging (Toutanova et al., 2003) and named entityrecognition (Finkel et al., 2005).
In the end, ourreconstructed version of the Time Corpus in to-tal amounted to 270,695 individual articles.
Inits entirety, the corpus counted 191,743,541 dis-tinct word forms (including punctuation marks),867,399 forms of which proved unique in theirlowercased format.
Some general statistics aboutour reconstructed version of the Time Corpus aregiven in Table 1.
In addition to the cumulativeword count statistics about the corpus, we haveincluded the frequency information per decade(1920s, 1930s, etc.
), as this periodisation willprove important for the experiments described insection 4.In its entirety, the corpus covers the periodMarch 1923 throughout December 2006.
It onlyincludes articles from the so-called ?U.S.
edition?of Time (i.e., it does not contain articles whichonly featured in the e.g.
European edition of theMagazine).
Because of Time?s remarkably contin-uous publication history, as well as the consider-able attention the magazine traditionally pays tointernational affairs and politics, the Time Cor-pus can be expected to offer an interesting, al-beit exclusively American perspective on the re-cent world history.
As far as we know, the cor-pus has only been used so far in corpus linguisticpublications and we do not know of any advancedstudies in the field of cultural history that makeextensive use of the corpus.3 Assumption: Lexical frequencyPrevious contributions to the field of Culturomicsall have in common that they attempt to establish acorrelation between word frequency statistics andcultural phenomena.
While this is rarely explicitlyvoiced, the broader assumption underlying thesestudies is that frequency statistics extracted from63the texts produced by a society at specific mo-ment in history, will necessarily reflect that soci-ety?s cultural specific (e.g.
cultural) concerns atthat time.
As such, it can for instance be expectedthat the frequency of conflict-related terminologywill tend to be more elevated in texts produced bya society at war than one at peace.
(Needless tosay, this need not imply that a society e.g.
sup-ports that war, since the same conflict-related ter-minology will be frequent in texts that oppose aparticular conflict.)
Obviously, the resulting as-sumption is that the study of developments in thevocabulary of a large body of texts should enablethe study of the evolution of the broader histori-cal concerns that exist(ed) in the culture in whichthese texts were produced.Frequency has been considered a key measurein recent studies into cultural influence (Skienaand Ward, 2013).
The more frequent a wordin a corpus, the more weighty the cultural con-cerns which that word might be related to.
Anaive illustration of this frequency effect can begleaned from Figure 1.
In the subplots of the fig-ure, we have plotted the absolute frequency withwhich the last names of U.S. presidents have beenyearly mentioned throughout the Time Corpus (intheir lowercased form, and only when tagged asa named entity).
The horizontal axis representstime, with grey zones indicating start and enddates of the administration periods.
The absolutefrequencies have been normalised in each year, bytaking their ratio over the frequency of the defi-nite article the.
Before plotting, these relative fre-quencies have been mean-normalised.
(Readersare kindly requested to zoom in on the digital PDFto view more detail for all figures.)
Although thisis by no means a life-changing observation, eachpresidential reign is indeed clearly characterisedby a significant boost in the frequency of the cor-responding president?s last name.
Nevertheless,the graph also displays some notable deficiencies,such the confusion of father and son Bush, or theincrease in frequency right before an administra-tion period, which seems related to the presidentialelection campaigns.Importantly, it has been stressed that reliablefrequency information can only be extracted fromlarge enough corpora, in order to escape the biascaused by limiting oneself to e.g.
too restricted anumber of topics or text varieties.
This has causedstudies to stress the importance of so-called ?BigFigure 1: Diachronic visualisation of mean-normalised frequencies-of-mention of the lastnames of U.S. presidents in the Time corpus, to-gether with their administration periods.CoolidgeHooverRooseveltTrumanEisenhowerKennedyJohnsonNixonFordCarterReaganBushClinton1920 1930 1940 1950 1960 1970 1980 1990 2000 2010BushData?
when it comes to Culturomics, reviving theold adagium from the field of Machine Learning?There?s no data like more data?, attributed to Mer-cer.
In terms of data size, it is therefore an impor-tant question whether the Time Corpus is a reli-able enough resource for practicing Culturomics.While the Time Corpus (just under 200 million to-kens) is not a small data set, it is of course ordersof magnitude smaller than the Google Books cor-pus with its intimidating 361 billion words.
Assuch, the Time Corpus might hardly qualify as?Big Data?
in the eyes of many contemporary datascientists.
One distinct advantage which the TimeCorpus might offer to counter-balance the disad-vantage of its limited size, is the high quality, bothof the actual text, as well as the metadata (OCR-errors are for instance extremely rare).In order to assess whether a smaller, yet higher-quality corpus like the Time Corpus might yieldvalid results when it comes to Culturomics wehave attempted to replicate an interesting experi-ment reported by Acerbi et al.
(2013b) in the con-text of a paper on the expression of emotions intwentieth century books.
For their research, theyused the publicly available Google Books unigramcorpus.
In our Figure 2 we have reproduced their?Figure 1: Historical periods of positive and neg-ative moods?.
For this analysis, they used the so-called LIWC-procedure: a methodology which at-tempts to measure the presence of particular emo-tions in texts by calculating the relative occur-rences of a set of key words (Tausczik and Pen-64nebaker, 2010).4In the authors?
own words, thegraph ?shows that moods tracked broad histori-cal trends, including a ?sad?
peak correspondingto Second World War, and two ?happy?
peaks, onein the 1920?s and the other in the 1960?s.
?We have exactly re-engineered their methodol-ogy and applied it to the Time Corpus.
The resultof this entirely parallel LIWC-analysis (Tausczikand Pennebaker, 2010) of the Time Corpus is visu-alized in Figure 3.
While our data of course onlystarts in 1923 instead of 1900 (cf.
grey area), itis clear that our experiment has produced a sur-prisingly similar curve, especially when it comesto the ?sad?
and ?happy?
periods in the 1940s and1960s respectively.
These pronounced similaritiesare especially remarkable because, to our knowl-edge, the Time Corpus is not only much smallerbut also completely unrelated to the Google Bookscorpus.
This experiment thus serves to emphasisethe remarkable stability of certain cultural trendsas reflected across various text types and unrelatedtext corpora.5Moreover, these results suggest thatthe Time Corpus, in spite of limited size, mightstill yield interesting and valid results in the con-text of Culturomics research.4 Parsimonious Language ModelsAs discussed above, Michel et al.
(2011) haveproposed a methodology in their seminal paper,whereby, broadly speaking, they try to establisha correlation between historical events and wordcounts in corpora.
They show, for instance, thatthe term ?Great War?
is only frequent in their datauntil the 1940s: at that point the more distinc-tive terms ?World War I?
and ?World War II?
sud-denly become more frequent.
One interesting is-sue here is that this methodology is characterisedby a modest form a ?cherry picking?
: with thisway of working, a researcher will only try outword frequency plots of which (s)he expects be-forehand that they will display interesting trends.Inevitably, this fairly supervised approach mightlower one?s chance to discover new phenomena,and thus reduces the chance for scientific serendip-ity to occur.
An equally interesting, yet much less4We would like to thank Ben Verhoeven for sharinghis LIWC-implementation.
The methodology adopted byAcerbi et al.
(2013b) has been detailed in the follow-ing blog post: http://acerbialberto.wordpress.com/tag/emotion/.5Acerbi et al.
(2013a) have studied the robustness of theirown experiments recently, using different metrics.Figure 2: Figure reproduced from Acerbi etal.
(2013b): ?Figure 1: Historical periods of posi-tive and negative moods?.
Also see Figure 3.supervised approach might therefore be to auto-matically identify which terms are characteristicfor a given time span in a corpus.In this respect, it is interesting to refer to Par-simonious Language Models (PLMs), a fairly re-cent addition to the field of Information Retrieval(Hiemstra et al., 2004).
PLMs can be used to cre-ate a probabilistic model of a text collection, de-scribing the relevance of words in individual docu-ments in contrast to all other texts in the collection.From the point of view of indexing in InformationRetrieval, the question which a PLM in reality triesto answer is: ?Suppose that in the future, a userwill be looking for this document, which searchterms is (s)he most likely to use??
As such, PLMsoffers a powerful alternative to the established TF-IDF metric, in that they are also able to estimatewhich words are most characteristic of a givendocument.
While PLMs are completely unsuper-vised (i.e.
no manual annotation of documents isneeded), they do require setting the ?
parameterbeforehand.
The ?
parameter will of course havea major influence on the final results, since it willcontrol the rate at which the language of each doc-ument will grow different from that of all otherdocuments, during the subsequent updates of themodel.
(For the mathematical details on ?, con-sult Hiemstra et al.
(2004).)
Thus, PLMs can beexpected to single out more characteristic vocab-65Figure 3: LIWC-analysis carried on the Time Cor-pus (cf.
Figure 2), attempting to replicate thetrends found by Acerbi et al.
(2013b).
Plottedis the absolute difference between the z-scoresfor the LIWC-categories ?Positive emotions?
and?Negative emotions?.
The same smoother (?Fried-man?s supersmoother?)
has been applied (R CoreTeam, 2013).llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll1900 1920 1940 1960 1980 20000.0020.0040.0060.0080.010YearJoy?Sadness(z?scores)ulary than simpler frequentist approaches and, in-terestingly, they are more lightweight to run thane.g.
temporal topic models.In a series of explorative experiments, we haveapplied PLMs to the Time Corpus.
In particu-lar, we have build PLMs for this data, by com-bining individual articles into much larger docu-ments: both for each year in the data, as well as all?decades?
(e.g.
1930 = 1930?1939) we have con-structed such large, multi-article documents.
Forboth document types (years and decades), we havesubsequently generated PLMs.
In Figure 4 to Fig-ure 12 we have plotted the results for the PLMsbased on the decade documents (for ?
= 0.1).In the left subpanel, we show the 25 words (tech-nically, the lowercased lemma?s) which the PLMestimated to be most discriminative for a givendecade.
In the right subpanel, we have plotted theevolution of the relevance scores for each of these25 words in the year-based PLM (the grey zone in-dicates the decade).
Higher scores indicate a morepronounced relevance for a given decade.
For thesake of interpretation, we have restricted our anal-ysis to words which were tagged as nouns (?NN?Figure 4: PLM for the 1920s.manplaynewspapernamesonbillgentlemanmotorletterdaughtertariffp.railroadladyfootinterestspeechstatementgovernorpersonshipconditionhonorautomobilea.Highest PML scores (1920s)1920 1930 1940 1950 1960 1970 1980 1990 2000 2010Figure 5: PLM for the 1930s.weekp.centfortnighta.picturepresidentsongovernorcinemanameauthoremployefriendautomobileno.goldrailroadm.bankdaughternewshawkedwifedepressionHighest PML scores (1930s)1920 1930 1940 1950 1960 1970 1980 1990 2000 2010& ?NNS?
).It is not immediately clear how the output ofthese PLMs can be evaluated using quantitativemeans.
A concise qualitative discussion seemsmost appropriate to assess the results.
For thisreason, we have combined individual articles intolarger decade documents in these experiments,since this offers a very intuitive manner of ar-ranging the available sources from a historical,interpretative point of view.
Often, when peo-ple address the periodisation of the twentieth cen-tury they will use decades, where terms like e.g.
?the seventies?
or ?the twenties?
refer to a fairlywell-delineated concept in people?s minds, associ-ated with a particular set of political events, peo-ple and cultural phenomena, etc.
By stickingto this decade-based periodisation, we can verifyfairly easily to what extent the top 25 yielded bythe PLM corresponds to commonplace historical66Figure 6: PLM for the 1940s.warweekmanplanedayairshipsoldierradiojapproductionbattleenemyadmirallaborfrontofficerbomberbombmiletonjobtanktroopsplantHighest PML scores (1940s)1920 1930 1940 1950 1960 1970 1980 1990 2000 2010Figure 7: PLM for the 1950s.manweektimedaytvstoryproductionpicturehandrecordboyredworldarmyendpartyft.committeewifeppmileshowgirlfarmtroubleHighest PML scores (1950s)1920 1930 1940 1950 1960 1970 1980 1990 2000 2010Figure 8: PLM for the 1960s.manp.m.studentnationschoolcitychurchnegrostateartcenturyspaceworldgirluniversitytodayareacollegejetlifemoonfactft.marketrightsHighest PML scores (1960s)1920 1930 1940 1950 1960 1970 1980 1990 2000 2010Figure 9: PLM for the 1970s.%priceoilcountryproblemnationinflationgovernmentenergystateblackofficialareacourtratewomanexampletaxpolicyincreaseleaderaidecitypeoplegroupHighest PML scores (1970s)1920 1930 1940 1950 1960 1970 1980 1990 2000 2010Figure 10: PLM for the 1980s.%officialcountrygovernmentcomputerleadermissilepolicyfirmpeoplebudgetcompanyrateprogramweaponarmdeficitsystemdrugforceproblemhostagegrouptelevisionaideHighest PML scores (1980s)1920 1930 1940 1950 1960 1970 1980 1990 2000 2010Figure 11: PLM for the 1990s.peoplechildnokidfamilymoviedrugwomancomputerparentissuetvwayfilmdirectorlotshowguydecademediathinggroupphonenetworksexHighest PML scores (1990s)1920 1930 1940 1950 1960 1970 1980 1990 2000 201067Figure 12: PLM for the 2000s.kidpeoplecompanyparentlotmoviedrugguythingfamilycellphonesiteinternetrisktechnologyattackstudyofficialintelligencewaysourcewebsiteterrorismgroupHighest PML scores (2000s)1920 1930 1940 1950 1960 1970 1980 1990 2000 2010stereotypes about the decades in the twentieth cen-tury.Let us start by inspecting the top 25 for the1940s, a decade in which the Second War II natu-rally played a major role.
Already at first glance,it is clear that the top 25 is dominated by war-related terminology (war, soldier, enemy, .
.
.
).
In-terestingly, the list also contains words referringto WWII, but not from the politically correct jar-gon which we would nowadays use to address theissue (e.g.
jap).
Remarkable is the pronouncedposition of aviary vocabulary (bomber, air, plane,.
.
.
), which is perhaps less surprising if we con-sider the fact that WWI was one of the first inter-national conflicts in which aircrafts played a majormilitary role.Interestingly, the 1920s are hardly characterisedby an equally focused set of relevant words.
Al-though mobility does seem to play an importantrole (cf.
the recently invented automobile, butalso ship and railroad), a number of less mean-ingful abbreviations (such as p. for ?page?)
popup that seem connected to superficial changes inTime?s editorial policies, rather than cultural de-velopments.
(Future analyses might want to re-move such words manually.)
On the other hand,the use of the terms lady and honour might berooted in a cultural climate that is different fromours (?lady?
seems the equivalent of woman to-day).
A number of parallel observations can bemade for the 1930s, although here, the high rank-ing word depression is of course striking (cf.
theeconomic crisis of 1929).
Fascinatingly, a varietyof denominations for (popular) media play a ma-jor role throughout the decade PLMs.
Note, thatwhile the 1920s?
top 25 mentioned the radio as theprimary communication medium, the popular cin-ema and (moving?)
picture show up in the 1930s.Interestingly, the popular media of tv and recordmake their appearance in the 1950s.
(In the 1980sand 1990s top 25, television moreover continuesto show up.
)The PLM also seems to offer an excellent cul-tural characterisation of the 1960s and the associ-ated baby boom, with an emphasis on the contro-versies of the time, debate involving human rights(rights, negro, nation), and in particular educa-tional (college, university, school).
The use of?educational?
words might well be related to thesocial unrest, much of which took place in andaround universities.
Does the striking presence ofthe word ?today?
in the list reveal an elevated hic etnunc mentality in the contemporary States?
Amer-ica?s well-documented interest in space travelingat the time is also appropriately reflected (space,moon).
Perhaps unexpectedly, this seemingly op-timistic ?Zeitgeist?
is more strongly associated inthe Time Corpus with the sixties, than with theseventies: in the flower-power era, Time displays aremarkable focus on political and especially eco-nomic issues.
Rather, the oil crisis seems to domi-nate Time?s lexis in the seventies.In the 1990s and 2000s, we can observe a fo-cus on what one might unrespectfully call ?first-world problems?, involving for instance family re-lations (family, kid, parent, child, etc.).
Apartfrom the fact that Time?s vocabulary seems to growmore colloquial in general in this period (at leastin our eyes, e.g.
guy, lot, thing), a number ofcontroversial taboo subjects seem to have becomediscussable: sex, drug.
?Terrorism?
and ?intelli-gence?
seem to have become major concerns inpost-09/11 America, and perhaps the presence ofthe word ?attack?
and ?technology?
might be (par-tially) interpreted in the same light.
Again, wesee how vocabulary related to media absolutelydominates the final rankings in the corpus: Hol-lywood seems to have enjoyed an increasing pop-ularity (film, director, movie, .
.
. )
but it is in-formation technology that seems to have had thebiggest cultural impact: mobile communicationdevices (phone, cell) and Internet-related termi-nology (network, computer, internet, .
.
. )
seem tohave caused a major turning point in Time?s lexis.66Due to lack of space, we only report results for ?
= 0.1applied to nouns, but highly similar results could be obtained685 Twentieth Century Turning Points?An interesting technique in this respect is a clus-tering method called VNC or ?Variability-BasedNeighbor Clustering?
(Gries and Hilpert, 2008).The technique has been introduced in the field ofhistorical linguistics as an aid in the automatedidentification of temporal stages in diachronicdata.
The method will apply a fairly straightfor-ward clustering algorithm to a data set (with e.g.Ward linkage applied to a Cosine distance matrix)but, importantly, it will add the connectivity con-straint that (clusters of) data points can only mergewith each other at the next level in a dendrogram,if they are immediately adjacent.
That is to saythat e.g.
in a series of yearly observations 1943would be allowed to merge with 1942 and 1944,but not with 1928 (even if 1943 would be muchmore similar to 1928 than to 1943).
We have ap-plied VNC (with Ward linkage applied to a plainCosine distance table) to a series of vectors whichfor each year in our data (1923-2006) containedthe PML scores of 5,000 words deemed most rel-evant for that year by the model.The dendrogram resulting from the VNC pro-cedure is visualised in Figure 13.
The early his-tory of Time Magazine (1923-1927) does not re-ally seem to fit in with the rest and takes up a fairlydeviant position.
However, the most attention-grabbing feature of this tree structure is the majordivide which the dendrogram suggests (cf.
red vs.green-blue cluster) between the years before andafter 1945, the end of the Second World War.
An-other significant rupture seem to be present beforeand after 1996: the discussion leaves us to won-der whether this turning point might related to therecent introduction of new communication tech-nologies, in particular the rise of the Internet.Historically speaking, these turning points donot come as a surprise.
There is, for instance,widespread acceptance among historians WWIIhas indeed been the single most influential eventin the twentieth century.
What does surprise, how-ever, is the relative easy with which a completelyunsupervised procedure has managed to suggestusing other part-of-speech categories and settings for ?.
Aninteresting effect was associated with ?fiddling the knob?
ofthis last parameter: for lower values (0.01, 0.001 etc.
), themodel would come up with perhaps increasingly characteris-tic, but also increasingly obscure and much less frequent vo-cabulary.
For the fourties, for instance, instead of returningthe word ?bomber?
the analysis would return the exact nameof a particular bomber type which was used at the time.
Thisparameter setting deserves further exploration.Figure 13: Dendrogram resulting from apply-ing Variability-Based Neighbor Analysis to vec-tors which contain for each year the 5,000 wordsdeemed most relevant by the PML.1923 1924 1925 1926 1927 1928 1929 1930 1931 1932 1933 1934 1935 1936 1937 1938 1939 1940 1941 1942 1943 1944 1945 1946 1947 1948 1949 1950 1951 1952 1953 1954 1955 1956 1957 1958 1959 1960 1961 1962 1963 1964 1965 1966 1967 1968 1969 1970 1971 1972 1973 1974 1975 1976 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 20060.0000.0050.0100.0150.020Variability-Based Neighbor Clustering Dendrogram(5000 highest PML scores per year)this identification.
Arguably, this is where weleave the realm of the obvious when it comes tothe computational study of cultural history.
Theidentification of major events and turning points inhuman history is normally a task which requires agood deal of formal education and some advancedreasoning skills.
Here, we might be nearing amodest form of Artificial Intelligence when we ap-ply computational methods to achieve a fairly sim-ilar goal.
Hopefully, these analyses, as well as theones reported above, illustrate the huge potentialof computational methods in the study of culturalhistory, even if only as a discovery tool.6 Conclusion and criticismIn this paper we have discussed a series of analy-ses that claim to mine a data-driven cultural char-acterization of the ?Zeitgeist?
of some of the mainperiods in the twentieth century.
Nevertheless, wemust remain vigilant not to overstate the achieve-ment of these techniques: it remains to be deter-mined to which extent can we truly call these ap-plications Digital History and whether these anal-yses have taught us anything which we did notknow before.
Because the twentieth century isso well known to most of us, the evidence oftentends to be self-referential and self-explanatory,and merely confirms that which we already knewintuitively.
Like with most distant reading ap-proaches, the results urge us to go back to the orig-inal material for the close reading of individualsources in their historical context, in order to ver-69ify the macro-hypotheses that might be suggestedat a higher level.
Therefore, the proposed methodmight in fact be more suitable for the study of timeperiods and corpora of which we know less.Nevertheless, our methodology seems promis-ing for future applications in Digital History: ourna?
?ve periodisation in decades, for instance, mightbe hugely fine-tuned by processing the results ofa VNC-dendrogram.
Breaking up history intomeaningful units is a much more complex, and of-ten controversial matter (e.g.
?When does moder-nity start??).
In this light, it would be helpful tohave at our disposal unbiased, computational toolsthat might help us to identify cultural ruptures oreven turning points in history.
Our results reportedin the final section do show that this applicationyields interesting results, and again, the methodseems promising for the analysis of lesser knowncorpora.AcknowledgmentsThe authors would like to thank the anonymous re-viewers and Kalliopi Zervanou for their valuablefeedback on earlier drafts of this paper, as well asWalter Daelemans and Antal van den Bosch forthe inspiring discussions on the topic.
For thisstudy, Mike Kestemont was funded as a postdoc-toral research fellow for the Research Foundationof Flanders (FWO).
Folgert Karsdorp was sup-ported as a Ph.D. candidate by the ComputationalHumanities Programme of the Royal NetherlandsAcademy of Arts and Sciences, as part of theTunes & Tales project.ReferencesAlberto Acerbi, Vasileios Lampos, and Alexander R.Bentley.
2013a.
Robustness of emotion extractionfrom 20th century English books.
In BigData ?13.IEEE, IEEE.Alberto Acerbi, Vasileios Lampos, Philip Garnett, andAlexander R. Bentley.
2013b.
The Expressionof Emotions in 20th Century Books.
PLoS ONE,8(3):e59030.Mark Davies.
2013.
TIME Magazine Corpus: 100million words, 1920s-2000s.Jenny Rose Finkel, Trond Grenager, and ChristopherManning.
2005.
Incorporating Non-local Informa-tion into Information Extraction Systems by GibbsSampling.
In Proceedings of the 43rd Annual Meet-ing on Association for Computational Linguistics,ACL ?05, pages 363?370, Stroudsburg, PA, USA.Association for Computational Linguistics.Stefan Th.
Gries and Martin Hilpert.
2008.
The iden-tification of stages in diachronic data: variability-based neighbour clustering.
Corpora, 3(1):59?81.Djoerd Hiemstra, Stephen E. Robertson, and HugoZaragoza.
2004.
Parsimonious language models forinformation retrieval.
In Mark Sanderson, KalervoJrvelin, James Allan, and Peter Bruza, editors, SI-GIR, pages 178?185.
ACM.Patrick Juola.
2013.
Using the Google N-Gram corpusto measure cultural complexity.
Literary and Lin-guistic Computing, 28(4):668?675.Kalev H. Leetaru.
2011.
Culturomics 2.0: Forecastinglarge-scale human behavior using global news mediatone in time and space.
First Monday, 16(9).Jean-Baptiste Michel, Yuan Kui Shen, Aviva PresserAiden, Adrian Veres, Matthew K. Gray, TheGoogle Books Team, Joseph P. Pickett, DaleHoiberg, Dan Clancy, Peter Norvig, Jon Orwant,Steven Pinker, Martin A. Nowak, and Erez Lieber-man Aiden.
2011.
Quantitative Analysis of Cul-ture Using Millions of Digitized Books.
Science,331(6014):176?182.R Core Team, 2013.
R: A Language and Environmentfor Statistical Computing.
R Foundation for Statis-tical Computing, Vienna, Austria.Steve Skiena and Charles Ward.
2013. Who Belongsin Bonnie?s Textbook?
Cambridge University Press.Yla R. Tausczik and James W. Pennebaker.
2010.
ThePsychological Meaning of Words: LIWC and Com-puterized Text Analysis Methods.
Journal of Lan-guage and Social Psychology, 29(1):24?54.Kristina Toutanova, Dan Klein, Christopher Manning,and Yoram Singer.
2003.
Feature-rich Part-of-speech Tagging with a Cyclic Dependency Network.In Proceedings of the 2003 Conference of the NorthAmerican Chapter of the Association for Computa-tional Linguistics on Human Language Technology- Volume 1, NAACL ?03, pages 173?180, Strouds-burg, PA, USA.
Association for Computational Lin-guistics.Jean M. Twenge, Keith W. Campbell, and BrittanyGentile.
2012.
Increases in Individualistic Wordsand Phrases in American Books, 19602008.
PLoSONE, 7(7):e40181.Gerben Zaagsma.
2013.
On Digital History.
BMGN ?Low Countries Historical Review, 128(4):3?29.70
