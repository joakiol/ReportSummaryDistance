Proceedings of the ACL-08: HLT Demo Session (Companion Volume), pages 28?31,Columbus, June 2008. c?2008 Association for Computational LinguisticsModelTalker Voice Recorder ?
An Interface System for Recording aCorpus of Speech for SynthesisDebra Yarrington, John Gray,Chris PenningtonH.
Timothy Bunnell, Allegra Cornaglia,Jason Lilley, Kyoko Nagao,James Polikoff,AgoraNet, Inc.
Speech Research LaboratoryNewark, DE  19711 A.I.
DuPont Hospital for ChildrenUSA Wilmington, DE  19803, USA{yarringt, gray, penningt}@agora-net.com{bunnell, cornagli, lilley,nagao, polikoff}@asel.udel.eduAbstractWe will demonstrate the ModelTalker VoiceRecorder (MT Voice Recorder) ?
an interfacesystem that lets individuals record and bank aspeech database for the creation of a syntheticvoice.
The system guides users through an au-tomatic calibration process that sets pitch,amplitude, and silence.
The system thenprompts users with both visual (text-based)and auditory prompts.
Each recording isscreened for pitch, amplitude and pronuncia-tion and users are given immediate feedbackon the acceptability of each recording.
Userscan then rerecord an unacceptable utterance.Recordings are automatically labeled andsaved and a speech database is created fromthese recordings.
The system?s intention is tomake the process of recording a corpus of ut-terances relatively easy for those inexpe-rienced in linguistic analysis.
Ultimately, therecorded corpus and the resulting speech da-tabase is used for concatenative syntheticspeech, thus allowing individuals at home orin clinics to create a synthetic voice in theirown voice.
The interface may prove usefulfor other purposes as well.
The system facili-tates the recording and labeling of large cor-pora of speech, making it useful for speechand linguistic research, and it provides imme-diate feedback on pronunciation, thus makingit useful as a clinical learning tool.1 Demonstration1.1 MT Voice Recorder BackgroundWhile most of us are familiar with the highly intel-ligible but somewhat robotic sound of syntheticspeech, for the approximately 2 million people inthe United States with a limited ability to commu-nicate vocally (Matas et al, 1985), these syntheticvoices are inadequate.
The restricted number ofavailable voices lack the personalization they de-sire.
While intelligibility is a priority for these in-dividuals, almost equally important is thenaturalness and individuality one associates withone?s own voice.
Individuals with difficulty speak-ing can be any age, gender, and from any part ofthe country, with regional dialects and idiosyncrat-ic variations.
Each individual deserves to speakwith a voice that is not only intelligible, but uni-quely his or her own.
For those with degenerativediseases such as Amyotrophic Lateral Sclerosis(ALS), knowing they will be losing the voice thathas become intricately associated with their identi-ty is not only traumatic to the individual but tofamily and friends as well.A form of synthesis that incorporates the quali-ties of individual voices is concatenative synthesis.In this type of synthesis, units of recorded speechare appended.
By using recorded speech, many ofthe voice qualities of the person recording thespeech remain in the resulting synthetic voice.
Dif-ferent synthesis systems append different sized28segments of speech.
Appending larger the units ofspeech results in smoother, more natural soundingsynthesis, but requires many hours of recording,often by a trained professional.
The recordingprocess is usually supervised, and the recordingsare often hand-polished.
Because appending small-er units requires less recording on the part of thespeaker, this is the approach the ModelTalker Syn-thesizer has taken.
However using smaller unitsmay result in noticeable auditory glitches at conca-tenative junctures that are a result of variations (inpitch, amplitude, pronunciation, etc.)
between thespeech units being appended.
Thus the speech rec-orded must be more uniform in pitch and ampli-tude.
In addition, the units cannot bemispronounced because each unit is crucial to theresulting synthetic speech.
In a smaller databasethere may not be a second example of a specificphoneme sequence.MT Voice Recorder expects that the individualsrecording will be untrained and unsupervised, andmay lack strength and endurance because of thepresence of a degenerative disease.
Thus the sys-tem is user-friendly enough for untrained, unsu-pervised individuals to record a corpus of speech.The system provides the user with feedback on thequality of each utterance they record in terms ofpronunciation accuracy, relative uniformity ofpitch, and relative uniformity of amplitude.
Confe-rence attendees will be able to experience this in-terface system and test all its different features.1.2 Feature DemonstrationAt the conference, attendees will be able to try outthe different features of ModelTalker Voice Re-corder.
These features include automatic micro-phone calibration, pitch, amplitude, andpronunciation detection and feedback, and auto-matic phoneme labeling of speech recordings.1.2.1 Microphone calibrationOne important new feature of the MT Voice Re-corder is the automatic microphone calibrationprocedure.
In InvTool, a predecessor software ofMT Voice Recorder, users had to set the micro-phone?s amplitude.
The system now calibrates thesignal to noise ratio automatically through a step-by-step process (see Figure 1, below).Using the automatic calibration procedure, theoptimal signal to noise ratio is set for the recordingsession.
These measurements are retained for fu-ture recording sessions in cases in which an indi-29vidual is unable to record the entire corpus in onesitting.Once the user has completed the automatic cali-bration procedure, he will be able to start recordinga corpus of speech.
The interface has been de-signed with the assumption that individuals will berecording without supervision.
Thus the interfaceincorporates a number of feedback mechanisms toaid individuals in making a high quality corpus forsynthesis (see Figure 2, below).1.2.2 Recording UtterancesThe corpus was carefully chosen so that all fre-quently used phoneme combinations are includedat least once.
Thus it is critical that users pro-nounce prompted sentences in the manner in whichthe system expects.
Alterations in pronunciation assmall as saying /i/ versus /?/ for ?the,?
for example,can negatively affect the resulting synthetic voice.To reduce the incidence of alternate pronunciation,the user is prompted with both a text and an audito-ry version of the utterance.1.2.3 Recording FeedbackOnce an utterance has been recorded, the user rece-ives feedback on the overall quality of the utter-ance.
Specifically, the user receives feedback onthe pitch, the overall amplitude, and the pronuncia-tion of the recording.Pitch: The user receives feedback on whetherthe utterance?s average pitch is within range of theuser?s base pitch determined during the calibrationprocess.
Collecting all recordings within a relative-ly small pitch range minimizes concatenation costsduring the synthesis process.
MT Voice Recorderdetermines the average pitch of each utterance andgives the user feedback on whether the pitch iswithin an acceptable range.
This feedback mechan-ism also helps to eliminate cases in which the sys-tem is unable to accurately track the pitch of anutterance.
In these cases, the utterance will bemarked unacceptable and the user should rerecord,hopefully yielding an utterance with more accuratepitch tracking.Figure 2: MT Voice Recorder User Interface30Amplitude: The user is also given feedback onthe overall amplitude of an utterance.
If the ampli-tude is either too low or too high, the user mustrerecord the utterance.Pronunciation: Each recorded utterance is eva-luated for pronunciation.
Each utterance within thecorpus is associated with a string of phonemesrepresenting its transcription.
When an utterance isrecorded, the phoneme string associated with theutterance is force-aligned with the recordedspeech.
If the alignment does not fall within anacceptable range, the user is given feedback thatthe recording?s pronunciation may not be accepta-ble and the user is given the option of rerecordingthe utterance.1.2.4 Automatic Phoneme LabelingDuring the process of pronunciation evaluation, anassociated phoneme transcription is aligned withthe utterance.
This alignment is retained so thateach utterance is automatically labeled.
Once theentire corpus has been recorded, alignments areautomatically refined based on specific individualvoice characteristics.1.2.5 Other FeaturesThe MT Voice Recorder also allows users to addutterances of their choice to the corpus of speechfor the synthetic voice.
These utterances are thosethe user wants to be synthesized clearly and willautomatically be included in their entirety in thespeech database.
These utterances are also auto-matically labeled before being stored.In addition, for those with more speech and lin-guistic experience, the system has a number ofother features that can be explored.
For example,the MT Voice Recorder also allows one to changesettings so that the phoneme string, peak ampli-tude, RMS range, average F0, F0 range, and pro-nunciation score can be viewed.
Users may use thisinformation to more precisely adjust their utter-ances.1.3 Synthetic Voice DemonstrationThose attending the demonstration will also beable to listen to a sampling of synthetic voicescreated using the ModelTalker system.
While oneof the synthetic voices was created by a profes-sional speaker and manually polished, all othervoices were created by untrained individuals, mostof whom have ALS, in an untrained setting, withthe recordings having no manual polishing.2 Other ApplicationsAlthough the MTVR was designed specifically torecord speech for the creation of a database thatwill be used in speech synthesis, it can also be usedas a digital audio recording tool for speech re-search.
For example, the MT Voice Recorder of-fers useful features for language documentation.An immediate warning about a poor quality re-cording will alert a researcher to rerecord the utter-ance.
MT Voice Recorder employs file formatsthat are recommended for digital language docu-mentation (e.g., XML, WAV, and TXT) (Bird &Simons, 2003).
The recorded files are automatical-ly stored with broad phonetic labels.
The automaticsaving function will reduce the time of recordingsand the potential risk for miscataloging the files.Currently, the automatic phonetic labeling featureis only available for English, but it could be appli-cable to different languages in the future.For more information about the ModelTalkerSystem and to experience an interactive demo aswell as listen to sample synthetic voices,visit http://www.modeltalker.com.AcknowledgmentsThis work was supported by STTR grantsR41/R42-DC006193 from NIH/NIDCD and fromNemours Biomedical Research.
We are especiallyindebted to the many people with ALS, the AACspecialists in clinics, and other interested individu-als who have invested a great deal of time and ef-fort into this project and have provided valuablefeedback.ReferencesBird, S. and Simons, G.F. (2003).
Seven dimensions ofportability for language documentation and descrip-tion.
Language, 79(3): 557-582.Matas, J., Mathy-Laikko, P., Beaukelman, D. and Le-gresley.
K. (1985).
Identifying the nonspeakingpopulation: a demographic study, Augmentative &Alternative Communication, 1: 17-31.31
