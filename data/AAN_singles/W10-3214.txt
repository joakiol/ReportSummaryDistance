Proceedings of the 8th Workshop on Asian Language Resources, pages 103?110,Beijing, China, 21-22 August 2010. c?2010 Asian Federation for Natural Language ProcessingBuilding NLP resources for Dzongkha:A Tagset and A Tagged CorpusChungku Chungku, Jurmey RabgayResearch DivisionDepartment of Information Technology& Telecom{chungku,jrabgay}@dit.gov.btGertrud Faa?Institute f?r MaschinelleSprachverarbeitung(NLP processing),University of Stuttgartfaasz@ims.uni-stuttgart.deAbstractThis paper describes the application ofprobabilistic  part  of  speech taggers  tothe  Dzongkha  language.
A  tag  setcontaining 66 tags is designed, which isbased  on  the  Penn  Treebank1.
Atraining  corpus  of  40,247  tokens  isutilized  to  train  the  model.
Using  thelexicon  extracted  from  the  trainingcorpus and lexicon from the availableword  list,  we  used  two  statisticaltaggers  for  comparison  reasons.
Thebest  result  achieved  was  93.1%accuracy in  a  10-fold cross  validationon the training set.
The winning taggerwas  thereafter  applied  to annotate  a570,247 token corpus.1 IntroductionDzongkha is  the national  language of Bhutan.Bhutan  has  only  begun  recently  applyingNatural Language Processing (henceforth NLP)methodologies  and  tools.
However,  Dzongkhacomputing is currently progressing rapidly.Part of speech (henceforth POS) tagging meansannotating each word with their respective POSlabel  according  to  its  definition  and  context.Such annotation generates a description of thetext  on  a  meta-level,  i.e.
a  representation  oflinguistic units on the basis of their properties.This POS-level provides significant informationusable by further linguistic research, may it beof  the  morphological,  syntactic  or  semantic1 [http://www.cis.upenn.edu/~treebank/]kind.
Producing such enriched data is proven tobe  useful  especially  when  designing  NLPrepresentations  of  higher  levels  ofrepresentation, e.g.
syntactic parses.Our project  is  designed to annotate Dzongkhacyclopedia  text  with  parts  of  speech  using  aprobabilistic  tagger.
This  means  that  a  set  oftags is to be developed and applied manually toparts  of  these  texts  creating  training  data.Probabilistic  taggers  can  then  be  applied  toannotate other texts with their  parts  of speechautomatically.
In this paper, we make use of twosuch taggers and report on their results.At present,  our POS tagged data is already inuse  in  projects  concerning  Dzongkha  Text  toSpeech (TTS) processing, further tests on wordsegmentation  (see  current  state  below)  and  incorpus-linguistic  research.
Future  work  entailsits utilization for higher-level NLP tasks such asparsing,  building parallel  corpora,  research onsemantics, machine translation, and many more.Sections  2  and  3  of  this  paper  describe  theDzongkha  script  and  the  challenges  inDzongkha,  section  4  presents  our  resources,tagset and corpus.
Section 5 describes taggingand  validation  processes  and  reports  on  theirresults.
Section 6 concludes and discusses futurework.2  The Dzongkha LanguageDzongkha  is  recognized  as  the  national  andofficial language of Bhutan.
It is categorized asa  Sino-Tibetan  Language  and  said  to  havederived  from  the  classical  Tibetan  or  choka:Dzongkha  consonants,  vowels,  phonemes,phonetics and writing system are all identical.103From a linguistic perspective, Dzongkha scriptis syllabic, a syllable can contain one characteror as many as six characters.
A syllable markerknown  as  ?tsheg?,  which  is  simply  asuperscripted  dot,  separates  the  syllables  of  aword.
Linguistic  words  may  contain  one  ormore  syllables  and  are  also  separated  by  thesame  symbol,  ?tsheg?,  thus  the  language  islacking word boundaries.Sentences  of  Dzongkha  contain  one  or  morephrases which themselves contain one or morewords.
A character  known as  ?shed?
marks  asentence border, it looks like a vertical pipe.Phonetic information is available, too: In mostsentences, a pause of silence is taken after eachphrase while speaking the Dzongkha language.The written form of Dzongkha represents thispause with a space after each phrase in the casethat it occurs not at the end of the sentence.
TheDzongkha  writing  system  leads  to  a  seriousproblem: the detection of word borders, becauseonly  phrases  are  separated  by  a  space.
POStagging  usually  requires  a  one-token-per  lineformat,  which is produced by a process calledword  segmentation.
The  tagger  then  adds  thePOS category to each token.The  training  data  of  (40247  tokens)  wassegmented manually to achieve higher accuracyof word boundary and also due to lack of wordsegmentation  during  that  time.
After  aDzongkha  word  segmentation2 tool  wasdeveloped,  the  remaining  text  was  segmentedwith  this  tool,  which  works  basically  with  alexicon and the longest string matching method.3 Challenges  and  suggestions  fortagging Dzongkha texts3.1 Words unknown to the language modelA  statistical  tagger  learns  from  POS  dis-tributions in manually tagged data while beingtrained  and,  when  being  applied  to  unknowntext,  ?guesses?
the  POS  of  each  word.
TheTreeTagger (Schmid, 1994) additionally makesuse  of  a  lexicon  externally  provided  whenproducing its  language model  (the  ?parameterfile?).
We had opted for using the TreeTagger2This tool was developed at NETEC(National Electronicsand Computer Technology Center), Thailand.and  hence  we  have  listed  about  28,300Dzongkha  words  with  their  POS in  a  lexiconselected from the 570,247 token corpus to  betagged.
We fed these data to  the tagger duringits  training phase.
Note,  however,  that  such alexicon  may  never  be  complete,  as  there  aremorphologically  productive  processes  creatingnew forms (these belong to POS classes that areoften named ?open?).
Such forms may be takeninto  account  when  developing  a  tagset,however, in this work, we opted for postponingthe issue until a morphological analyser can bedeveloped.3.2  Ambiguous function wordsA  number  of  Dzongkha  function  words  areambiguous; for each occurrence of such a word,the  tagger  has  to  decide  on  the  basis  of  theword?s contexts, which of the possible tags is tobe assigned.
Here, the tagset itself comes intoview:  whenever  it  is  planned  to  utilizeprobabilistic POS taggers, the tagset should bedesigned  on  the  basis  of  the  words?distributions,  otherwise  the  potential  accuracyof the taggers may never be achieved.In Dzongkha it is mainly the function words thatare ambiguous in terms of their POS.
A typicalexample  is  ??
?/le/(from)  belonging  to  thecategory  PP  (post  position)  and  ??
?/le/(so)which is of the category CC (conjunction).3.3 Fused formsSome morpho-phonemic processes in Dzongkhalead to the fusing of words, presenting anotherchallenge for tagging.
Such words3 are not veryfrequent,  thus  proposing  a  challenge  tostatistical  taggers.
The  word ???????
?/gelpoi/(king[+genitive]),  for  example,  is  fused  from  thephrase  ????????
?/gelpo  gi/  (king  is);  anotherexample is the fused form ?????
?/sen/ ([to] kill),made from ???????????
?/se wa cin/ (if [to] kill).When a tagset does not cater for fused forms ofwords,  one  could  split  these  forms  whiletokenizing  adding  an  intermediate  level  ofrepresentation  between  original  text  level  and3 In our training set, there were 1.73% of all wordsdetected as fused forms.104the  POS  level:  a  level  of  text  material  to  beutilized for tagging or other further processing,as  e.g.
done  by  (Taljard  et  al.,  2008)  for  theBantu Language Northern Sotho.
However, theforms  could not easily be split, as the resultingfirst  parts  of the words would not contain theseparator  ?tsheg?.
Splitting  the  word ???????
?/gelpoi/  (king[+genitive]),  for  example,  wouldresult  in  ????
?/gelpo/(king)  and ??
?/yi/[+genitive].The language model  does  not  cater  for  wordsending in  characters  other than "tsheg" (wordborder) or being directly followed by "shed" (aword like ????
?/gelpo/(king) may only appear ifpreceding a sentence border).
Tagging accuracyfor such theoretical forms are not expected to beacceptable.
Fusing  processes  are  productive,therefore,  further  research  in  the  frame  of  aproject  developing  a  Dzongkha  tokenizer  isdeemed necessary.We examined all fused words contained in ourtextual data to find an workable solution at thecurrent  stage  of  the  project.
As  long  as  theproblem  of  tokenizing  automatically  is  notsolved, we opted for keeping the fused forms asthey  are.
To  enhance  our  tagger  results,   wesuggest to add  a number of tags to our tagsetthat consist of the two POS tags involved.
???????
?/gelpoi/  (king[+genitive]),  for  example,  istagged as ?NN+CG?
and   ?????
?/sen/ ([to] kill)as  ?VB+SC?.
The  ?+?
indicates  combinedindividual tags.
All known forms are added to anew version of the lexicon.
Note, however, thatall tagging results reported upon in this paper,are still based on the tag set described below.4  Resources used4.1  TagsetDuring  the  first  phase  of  PAN  Localizationproject,  the  first  Dzongkha  POS  tagset4 wascreated.
It  consisted  of  47  tags,  its  design  isbased on the Penn Guidelines5 and its categoriesof  POS  correspond  to  the  respective  EnglishPenn categories.
PAN generally makes  use of4 The original Dzongkha tag set is described athttp://www.panl10n.net5 The Penn Guidelines can be downloaded from:http://www.cis.upenn.edu/~treebank/the Penn Treebank tags as a basis for tagging.Examining  the  similar  features  exhibited  byboth  the  languages  (Dzongkha  and  English),tags  that  were  applicable  to  Dzongkha  weretaken directly from the Penn Treebank.
In caseswhere these languages showed dissimilarities intheir  nature,  new  tags  for  Dzongkha  wereassigned  (based  e.g.
on  the  work  on  Urdu ofSajjad and Schmid,  2009).
As an example  forsuch dissimilarity,  Dzongkha postpositions arementioned here, cf.
(1); the respective tag (PP)only exist for Dzongkha whereas in English thewhole set  of  ad position tags (preposition andpostpositions) exist.
(1)   ??????
??????????????
?j'ili shing-gi w?lu -d?Cat tree[posp] under[PP] be''A cat is under the tree''Whenever  a  tagset  designed  on  theoreticalimplications is applied to text, it will be foundin the course of creating the training data thatnot  all  morpho-syntactic  phenomena  of  thelanguage  had been considered.
This  happenedfor Dzongkha, too: words appeared in the textsthat didn't fit in any of the pre-defined classes.Dzongkha uses honorific forms:  ?????
?/nam za/(cloths)  is  the  honorific  form  of  the  noun  ????
?/gola/(cloths),  ????
?/sung/(tell)  the  honorificform of the verb ???/lab/(tell).
We opted to markthem  by  adding  the  tag  NNH  (honorificcommon  noun)  and  VBH  (honorific  verb)  toenable future research on this specific usage ofDzongkha  language.
A  number  of  tags  wereadded to the set, of which we describe four inmore detail: two of the additional tags are sub-classes  of  verbs:  VBH (honorific  verb  form),and VBN which describes past participle forms,like,  e.g.
???
?/jun/(created),  the  past  particleform of ??
?/jung/(create).Concerning case,  we  added two subclasses  ofcase: CDt and CA.
These differentiate betweendative  (CDt)  and  ablative  (CA):  The  CDt(Dative  case)  labels  e.g.??????
?/doen  le/(for  it)and  ?????
?/doen lu/(for  this).
The Ablative  case105(CA)  is  used  when  the  argument  of  thepreposition describes a source.
For example, inthe phrase   ????????????
?/shing le kang thri/(fromwood chair),  ??
?/le/from/   will  be labeled CAsince  the  chair  described  is  made  from  (thesource)  wood  (Muaz,  et  al.
2009).
The  tagsetutilized in our experiment consists of a total of66 parts of speech as shown in Appendix (A).4.2 Collecting a Corpus and generating atraining data setThe Corpus collection process.
The process ofcollecting  a  corpus  should  be  based  on  itspurpose.
As  our  goal  was  the  design  aDzongkha text corpus as balanced as possible interms of its linguistic diversity, the text data wasgathered from different sources like newspaperarticles,  samples  from  traditional  books,  anddictionaries,  some  text  was  added  manually(poetry and songs).
The text selection was alsoprocessed with a view on the widest range ofgenres possible: texts from social science, artsand culture, and texts describing world affairs,travel adventure, fiction and history books wereadded as our goal is to make it representative ofevery  linguistic  phenomena  of  language(Sarkar, et al 2007).
The corpus is however notbalanced  for  a  lack  of  available  electronicresources of informative text (so far only 14%belong  to  this  category).
Future  work  willtherefore  entail  collecting  more  data  fromrespective websites and newspapers.The  entire  corpus  contains  570,247  tokens;  itmade from the domains described in table (1).Domain Share % Text type1) World Affairs 12% Informative2) Social Science 2% Informative3) Arts 9% Descriptive4) Literature 72% Expository5) Adventure 1% Narrative6) Culture 2% Narrative7) History 2% DescriptiveTable (1): Textual domains containedin the corpusThe Training data setCleaning  of  texts.
Raw text  is  usually  to  bemodified before it can be offered to a tagger.
Itis  to  be  cleaned  manually,  e.g.
by  removingextra  blank  spaces,  inserting  missing  blanks,correcting spelling mistakes,  and by removingduplicate  occurrences  of  sequences.
Secondly,the  process  of  tokenization  (?WordSegmentation?)
is to be applied.Design and generation of training data.
Thetraining data set was produced in several steps:Firstly,  20,000  tokens  were  manually  labeledwith  their  respective  parts  of  speech (for  acomparison of tagging techniques, cf.
Hasan etal.,   2007).
Thereafter,  the  problems  that  hadoccurred  during  the  manual  process  weresummarized and the tagset revised as describedin  section  4.1.
Thereafter,  we  added  another20,247 tokens.
The final training data set henceconsists  of  40,247  tokens  (2,742  sentences,36,362 words, 3,265 punctuation, 650 numbers).4.3 Tagging  technique:  TreeTagger  andTnTTreeTagger  (Schmid,  1994): TreeTagger(Schmid, 1994) is a probabilistic part of speechtagger operating on the basis of decision trees.Helmut Schmid developed it in the frame of the?TC?6 project at the Institute for ComputationalLinguistics  at  the  University  of  Stuttgart,Germany.The software consists of two modulesa)  train-tree-tagger:  utilized  to  generate  aparameter  file  from  a  lexicon  and  a  hand-tagged corpus.b) tree-tagger: makes use of the parameter filegenerated with a); annotates text (which is tobe  tokenized  first)  with  part-of-speechautomatically.a) Generating a language model: TrainingWhen generating a language model stored in aso-called  ?parameter  file?,  three  files  arerequired: a lexicon describing tokens and theirrespective tags, a list of open tags, and training6 The tagger is freely available at http://www.ims.uni-stuttgart.de/projekte/corplex/TreeTagger/DecisionTreeTagger.html106data.
The ?train-tree-tagger?
module generatesa binary parameter file.The lexicon is a file that contains tokens (wordforms and punctuation),  in the format  of oneper  line.
The  TreeTagger  was  developed  forlanguages with inflection, i.e.
languages whereone  word  may  occur  in  a  number  ofallomorphs.
To ease the task of tagging suchlanguages, the tool can operate on the level ofa base form, the ?lemma?
which may be addedto every word form.
In the case of Dzongkha,lemmatization  has  not  been  developed  yet,therefore, we either make use of the word formitself, or a hyphen in the case that no lemma isavailable.
As  table  (2)  demonstrates,  thelexicon  contains  the  word  forms  in  the  firstcolumn, the second column contains the POSand  the  third  a  hyphen.
In  the  case  ofambiguous  entries,  one  line  may  contain  asequence of tag-?lemma?
pairs that follow theword  form  of  the  first  column.
The  lexiconmay not contain any spaces; all columns mustbe  separated  by  exactly  one  tab(ulator).Because the lexicon is only made use of duringthe  training  phase  of  the  tagger,  any  updatemust result in reproducing the parameter file.Word Pos tag lemma Pos tag lemma??
NN ??????
NN ?????????
NNP --???
PP ???
CC ??
?Table (2) Example entries of the lexiconOpen class  tags:  a  file  containing  the  list  ofopen class tags, i.e.
the productive classes (oneentry per line), cf.
Appendix A.
In the upcomingversion of the tagset, tags of the following fusedforms  will  be  added,  like,  e.g.
NN+CG(combination of all  forms nouns with genitivecase  CG),  VB+CG (combination  of  all  formsverb  with  genitive  case  CG),  JJ+CG(combination  of  all  forms  of  adjective  withgenitive case CG), RB+CG (combination of alladverb with genitive case CG), and same withthe  combination  of  Subordinate  conjunctionNN+SC, VB+SC, JJ+SC, RB+SC, just to namea few.Tagged  training  data: a  file  that  containstagged training data.
The data must be stored inone-token-per-line format.
This means that eachline contains one token and its  respective tag,these  are  separated  by one tabulator.
The fileshould be cleaned from empty lines, no meta-information,  like,  e.g.
SGML  markup  isallowed.b) TaggingTwo files serve as input: the binary parameterfile and a text file that is to be tagged.Parameter file: the file that was generated bystep a) above.Text  file:  a  file  that  is  to  be  tagged;  it  ismandatory that the data in this file appears in aone-token-per line format.TnT  (Brants,  2000):The  Trigram?s?n?Tags(TnT) tagger was developed by Thorsten Brants(Brants, 2000).
It  is language independent andhas  been  used  widely  for  a  number  oflanguages, often yielding an accuracy of +96%without utilizing an external lexicon or an openword  class  file.
TnT  is  based  on  Markovmodels, and takes not only distributional data oftokens,  but  also  the  final  sequences  ofcharacters  of  a  token  into  account  whenguessing the POS of a word.
It can use the sameformat  for  training  data  as  the  TreeTagger,therefore,  in order to use TnT for comparisonreasons, no additional preparations for taggingDzongkha are necessary.5 Validation and Results5.1 k-fold  cross  validation  andbootstrappingWhen applying a tagset to training data for thefirst time, it is advisable to progress in steps andto  validate  each  step  separately:  One  beginswith  annotating  a  rather  small  portion  of  textthat  is  then  divided  into  k  number  of  slices.Slices k-1 are then utilized to create a parameterfile, the slice k is stripped of its annotations andannotated  by  the  tagger  using  that  parameterfile.
The  same  procedure  is  followed  for  allother  slices  (?k-fold  cross  validation?
).107Afterwards, a comparison between the originaltags with the tags assigned by the tagger willthen help to judge upon a number of issues, like,e.g.,  whether  the  size  of  the  training  data  issufficient  (quantitative review).
Examining themost frequent (typical) assignment errors of thetagger will also support the enhancement of thetagset:  if  e.g.
the  distribution of  two differenttags  is  more  or  less  identical,  a  probabilistictagger  will  not  succeed  in  making  the  rightchoices, here, one is to consider if using one tagwould be acceptable from a linguistic point ofview (qualitative review).The  knowledge  gained  here  usually  leads  toupdates in the tagset and/or to the necessity toadd  more  amounts  of  texts  containingconstellations  that  were  found  as  beingproblematic  for  probabilistic  tagging  for  theyoccur too rarely in the texts.
After such updatesare done on the existing training texts and tagsetrespectively,  the  k-fold  validation  may  berepeated and reviewed again.Updating  training  data  and  tagset  will  berepeated until the tagging results are satisfying(such  a  progressing  method  is  usually  called?bootstrap-ping?
).5.2 TreeTagger resultsThe work on automatic part of speech taggingfor Dzongkha began with the manual annotationof  20,000  tokens.
Because  a  non-linguisticperson  performed  the  process  manually,  thelanguage coordinator did thorough correction.The 20,000 token training set, made use of 43different  single  tags  (of  47  provided  by  thetagset).
The token-tag combinations from therewere  combined  with  an  external  lexiconproduced  from  a  dictionary;  the  resultinglexicon file thus contained all types.The  10-fold  cross  validation  resulted  in  anaccuracy of  around 78%.
Result  introspectionlead to the knowledge that more data had to beadded and that fused words will have to receiveseparate  tags.
It  also  showed  that  manualtokenization  is  an  error-prone  procedure,  as  asignificant  number  of  word  and  sentenceborders had to be corrected in the data.After updating tagset and training data, another20,247 tokens were added to the training set andthe lexicon was updated accordingly, except forthe fused forms, where a final solution on howto  tag  them is  not  found yet.
The  tagset  wasextended to 66 tags (cf.
Appendix A).
With afull  knowledge  of  the  possible  tag-tokencombinations,  the  Tree-Tagger  achieved  amedian accuracy of 93.1%.5.3 TnT  results  and  comparison  withthe TreeTaggerUsing the 40,247 tokens text segment, a 10-foldcross  validation  was  also  performed  with  theTnT  tagger.
It  achieves  a  91.5  %  medianaccuracy when the tagset containing 47 tags isapplied.
Results for each slice and mean/mediancan  be  found in  table  (3)  of  both  taggers  forcomparison reasons.
TnT reports on the numberof unknown tokens detected in each slice;  themean of 16.49 % (median 14.18%) of unknowntokens offers an explanation why TnT does notperform as good as the TreeTagger which wassupplied with a complete lexicon thus not beingfaced with unknown tokens at all.Tagger:Tree-Taggeraccuracy %TNTaccuracy %slice 1 92.13 92.33slice 2 84.61 89.73slice 3 89.08 89.88slice 4 90.17 90.43slice 5 92.95 91.01slice 6 93.32 91.35slice 7 94.24 91.69slice 8 93.32 92.03slice 9 95.21 92.55slice 10 94.56 92.60Mean 91.96 91.36Median 93.14 91.20Table (3) 10-fold cross validation results forTreeTagger and TnTA qualitative review of the results showed thatusually it  is  the tag CC that  is  confused withothers (NN, DT, NN, DT, PRL, etc.)
by TnT,while  the  TreeTagger  is  rather  confusing  NN(with VB, NNP, PRL, CC).However,  a  more  thorough  qualitativeexamination of these results is still to be doneand may lead to further updates on the tagset.1086 Discussion,  Conclusions  and  FutureworkThis  paper  describes  the  building  of  NLPresources for the national language of Bhutan,namely Dzongkha.
We have designed and builtan electronic corpus containing 570,247 tokensbelonging to different text types and domains.Automated  word  segmentation  with  a  highprecision/recall  still  remains  a  challenge.
Wehave  begun  to  examine  statistical  methods  tofind solutions for this and we plan to report onour progress in the near future.We have developed a first version of a tag seton the basis of the Penn Tree tagset for English(cf.
section 4.1)  A training data set  of  40,247tokens  has  been  tagged  manually  andthoroughly checked.
Lastly, we have tagged thecorpus  with  the  TreeTagger  (Schmid,  1994)using a full form lexicon achieving 93.1% and,for  comparison  reasons,  with  TnT  (Brants,2000), without a lexicon, achieving 91.5 %.We  have  used  the  present  output  in  theconstruction  of  an  advance   Dzongkha  TTS(text  to speech) using an HMM-based methodwhich  is  developed  by  the  Bhutan  team  incollaboration  with  HLT  team  at  NECTEC,Thailand7Loads  of  work  still  remains,  we  are  still  toexamine  the  tagger  results  from  a  qualitativeaspect  in  order  to  answer  inter  Alia  thefollowing  questions:  Are  there  any  furtherupdates  on  the  tag  set  necessary,  what  is  thebest  way to process fused forms.
Quantitativeaspects might also still play a role:  It still mightbe  necessary  to  add  further  training  datacontaining  part  of  speech  constellations  thatrarely  occur,  so  tagger  results  for  those  willenhance.We also  plan to increase our corpus collectionfrom  various  ranges of  domains.
At  presentthere are more media, e.g.
newspapers availablein  the  world  wide  web,  we  will  be  able  tocollect such texts easily.
In Bhutan, there is  anongoing  project  on  OCR  (optical  characterrecognition) of  Dzongkha  under  the  PANproject (www.PANL10n.net).
Given the successof this project, we will be able to scan text fromtextbooks.7 http://www.nectec.or.th/en/AcknowledgmentsThis research work carried out as part of PANLocalization  Project  (www.PAN10n.net)  withthe  aid  of  grant  from  the  InternationalDevelopment Research Center (IDRC), Ottawa,Canada,  administered  through  the  Center  ofResearch  in  Urdu  language  Processing(CRULP), National University of Computer andEmerging  Sciences  (NUCES),  Pakistan.
Theresearch team would also like to thank PD Dr.Helmut Schmid and Prof. Dr. Heid, Insitut f?rMaschinelle  Sprachverarbeitung  (NLPinstitute),  Universit?t  Stuttgart,  Germany  fortheir  valuable  support  and  contributions  thatmade this research successful.ReferencesBrants, Thorsten.
2000.
TnT - as statistical part-of-speech tagger.
In Proceedings of the Sixth AppliedNatural Language Processing Conference(ANLP-2000), Seattle, WA, USA, pages 224 ?
231.Hasan, Fahim Muhammad, Naushad UzZaman, andMumit Khan.
2007.
Comparison of different POSTagging Techniques (N-Gram, HMM andBrill?s tagger) for Bangla.
PAN LocalizationWorking Papers, 2004-2007, pages 31-37.Hassan, Sajjad and Helmut Schmid .
2009.
TaggingUrdu Text with Parts of Speech: A TaggerComparison, Proceedings of the 12th Conference ofthe European Chapter of the Association forComputational Linguistics (EACL) .
Athens, Greece,2009.Muaz, Ahmed,  Aasim Ali,  and Sarmad Hussain.2009.
Analysis and Development of Urdu POSTagged Corpus.
Association for ComputationalLinguistics.
Morristown, NJ, USA.Retrieved  December 1, 2009, fromhttp://  www.lancs.ac.ukSchmid, Helmut.
1994.
Probabilistic Part-of-SpeechTagging Using Decision Trees.
In Proceedings ofthe International Conference on New Methods inLanguage Processing.
Manchester, UK, pages 44 ?49.Sarkar, Asif Iqbal, Dewan Shahriar Hossain Paveland Mumit Khan.
2007.
Automatic Bangla CorpusCreation.
BRAC University, Dhaka, Bangladesh.109PAN Localization Working Papers, 2004-2007.pages 22-26.Taljard Elsab?, Faa?
Gertrud, Heid Ulrich, and DaanJ.
Prinsloo.
2000.
On the development of a tagset forNorthern Sotho with special reference tostandardization.
Literator 29(1), April 2008 (specialedition on Human Language Technologies), SouthAfrica, pages 111 ?
137APPENDIX AThe Dzongkha Tagsetas used for the validation testsType SubClass LabelOpen classes:Noun Common Noun NNHonorific form NNHParticular/Person NNPQuantifier NNQPlural NNSVerb Aspirational VBAsHonorific VBHAgentive VBAtNon-Agentive VBNaAuxiliary VBAUXImperative VBIModal VBMDPast participle VBNVerb VBAdjective Characteristic JJCtPeriodic JJPComparative JJRSuperlative JJSAdjective JJAdverb Behavioral RBBComparative RBRSuperlative RBSAdverb RBInterjection UHClosed classes:Marker Affirmative AMInterrogative IrMTense TMCase marker Ablative Case CADative Case CDtGenitive Case CGType SubClass LabelVocative Case CVPronouns Locative PRLDifferential PRDPersonal PRPReflexive PRRFConjunction Coordinate CCSubordinate SCNumber Cardinal Number CDOrdinal Number ODNominal Number NDAd position Post position PPDeterminer Definite DTPossessive DT$Indefinite DTINegator NEGPunctuation PUNCombinedtags:Noun+Genitive case(CG)Common+CG NNCGParticular+CG NNPCGQuantifier+CG NNQCGPlural+CG NNSCGAdjective+CG Adjective+CG JJCGCharacteristic +CG JJCtCGPeriodic+CG JJPCGVerb+CG Honorific+CG VBHCGAgentive+CG VBAtCGVerb+CG VBCGModal+CG VBMDCGDefiniteDeterminer+CGDeterminer+CG DTCGLocativePronoun +CGLocative+CG PRLCGNegator+CG Negator+CG NEGCGNoun+SubordinateConjunction(SC)Common Noun+SCNNSCVerb+SC Verb+SC VBSCAgentive+SC VBAtSCModal verb+SC VBMDCAffirmative+SCAffirmative +SC AMSCNegator+SC Negator+SC NEGSC110
