Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 665?672,Sydney, July 2006. c?2006 Association for Computational LinguisticsAn Unsupervised Morpheme-Based HMM for HebrewMorphological DisambiguationMeni AdlerDepartment of Computer ScienceBen Gurion University of the Negev84105 Beer Sheva, Israeladlerm@cs.bgu.ac.ilMichael ElhadadDepartment of Computer ScienceBen Gurion University of the Negev84105 Beer Sheva, Israelelhadad@cs.bgu.ac.ilAbstractMorphological disambiguation is the pro-cess of assigning one set of morphologi-cal features to each individual word in atext.
When the word is ambiguous (thereare several possible analyses for the word),a disambiguation procedure based on theword context must be applied.
This paperdeals with morphological disambiguationof the Hebrew language, which combinesmorphemes into a word in both agglutina-tive and fusional ways.
We present an un-supervised stochastic model ?
the only re-source we use is a morphological analyzer ?which deals with the data sparseness prob-lem caused by the affixational morphologyof the Hebrew language.We present a text encoding method forlanguages with affixational morphology inwhich the knowledge of word formationrules (which are quite restricted in He-brew) helps in the disambiguation.
Weadapt HMM algorithms for learning andsearching this text representation, in sucha way that segmentation and tagging canbe learned in parallel in one step.
Resultson a large scale evaluation indicate thatthis learning improves disambiguation forcomplex tag sets.
Our method is applicableto other languages with affix morphology.1 IntroductionMorphological disambiguation is the process of as-signing one set of morphological features to eachindividual word in a text, according to the wordcontext.In this work, we investigate morphological dis-ambiguation in Modern Hebrew.
We explore unsu-pervised learning method, which is more challeng-ing than the supervised case.
The main motivationfor this approach is that despite the development?This work is supported by the Lynn and WilliamFrankel Center for Computer Sciences, and by theKnowledge Center for Hebrew Processing, Israel Sci-ence Ministry.of annotated corpora in Hebrew1, there is still notenough data available for supervised training.
Theother reason, is that unsupervised methods canhandle the dynamic nature of Modern Hebrew, asit evolves over time.In the case of English, because morphology issimpler, morphological disambiguation is generallycovered under the task of part-of-speech tagging.The main morphological variations are embeddedin the tag name (for example, Ns and Np fornoun singular or plural).
The tagging accuracyof supervised stochastic taggers is around 96%-97% (Manning and Schutze, 1999, 10.6.1).
Meri-aldo (1994) reports an accuracy of 86.6% for an un-supervised word-based HMM, trained on a corpusof 42,186 sentences (about 1M words), over a tagset of 159 different tags.
Elworthy (1994), in con-trast, reports an accuracy of 75.49%, 80.87% and79.12% for unsupervised word-based HMM trainedon parts of the LOB corpora, with a tagset of134 tags.
With good initial conditions, such asgood approximation of the tag distribution for eachword, Elworthy reports an improvement to 94.6%,92.27% and 94.51% on the same data sets.
Meri-aldo, on the other hand, reports an improvementto 92.6% and 94.4% for the case where 100 and2000 sentences of the training corpus are manuallytagged.Modern Hebrew is characterized by rich mor-phology, with a high level of ambiguity.
On aver-age, in our corpus, the number of possible analysesper word reached 2.4 (in contrast to 1.4 for En-glish).
In Hebrew, several morphemes combine intoa single word in both agglutinative and fusionalways.
This results in a potentially high number oftags for each word.In contrast to English tag sets whose sizes rangefrom 48 to 195, the number of tags for Hebrew,based on all combinations of the morphologicalattributes (part-of-speech, gender, number, per-son, tense, status, and the affixes?
properties2),1The Knowledge Center for Hebrew processing isdeveloping such corpora: http://mila.cs.technion.ac.il/2The list of morphological attributes is described in(Yona and Wintner, 2005).
An in-depth discussion ofthe Hebrew word form is provided in (Allon, 1995, pp.665can grow theoretically to about 300,000 tags.
Inpractice, we found only 1,934 tags in a corpus ofnews stories we gathered, which contains about 6Mwords.The large size of such a tag set (about 10 timeslarger than the most comprehensive English tagset) is problematic in term of data sparseness.Each morphological combination appears rarely,and more samples are required in order to learnthe probabilistic model.In this paper, we hypothesize that the large setof morphological features of Hebrew words, shouldbe modeled by a compact morpheme model, basedon the segmented words (into prefix, baseform, andsuffix).
Our main result is that best performanceis obtained when learning segmentation and mor-pheme tagging in one step, which is made possibleby an appropriate text representation.2 Hebrew and Arabic Tagging -Previous WorkSeveral works have dealt with Hebrew tagging inthe past decade.
In Hebrew, morphological anal-ysis requires complex processing according to therules of Hebrew word formation.
The task of amorphological analyzer is to produce all possibleanalyses for a given word.
Recent analyzers pro-vide good performance and documentation of thisprocess (Yona and Wintner, 2005; Segal, 2000).Morphological analyzers rely on a dictionary, andtheir performance is, therefore, impacted by the oc-currence of unknown words.
The task of a morpho-logical disambiguation system is to pick the mostlikely analysis produced by an analyzer in the con-text of a full sentence.Levinger et al (1995) developed a context-freemethod in order to acquire the morpho-lexicalprobabilities, from an untagged corpus.
Theirmethod handles the data sparseness problem byusing a set of similar words for each word, builtaccording to a set of rules.
The rules produce vari-ations of the morphological properties of the wordanalyses.
Their tests indicate an accuracy of about88% for context-free analysis selection based on theapproximated analysis distribution.
In tests we re-produced on a larger data set (30K tagged words),the accuracy is only 78.2%.
In order to improvethe results, the authors recommend merging theirmethod together with other morphological disam-biguation methods ?
which is the approach we pur-sue in this work.Levinger?s morphological disambiguation sys-tem (Levinger, 1992) combines the above approx-imated probabilities with an expert system, basedon a manual set of 16 syntactic constraints .
Inthe first phase, the expert system is applied, dis-24?86).ambiguating 35% of the ambiguous words with anaccuracy of 99.6%.
In order to increase the applica-bility of the disambiguation, approximated proba-bilities are used for words that were not disam-biguated in the first stage.
Finally, the expert sys-tem is used again over the new probabilities thatwere set in the previous stage.
Levinger reportsan accuracy of about 94% for disambiguation of85% of the words in the text (overall 80% disam-biguation).
The system was also applied to pruneout the least likely analyses in a corpus but with-out, necessarily, selecting a single analysis for eachword.
For this task, an accuracy of 94% was re-ported while reducing 92% of the ambiguous anal-yses.Carmel and Maarek (1999) use the fact thaton average 45% of the Hebrew words are unam-biguous, to rank analyses, based on the numberof disambiguated occurrences in the text, normal-ized by the total number of occurrences for eachword.
Their application ?
indexing for an informa-tion retrieval system ?
does not require all of themorphological attributes but only the lemma andthe PoS of each word.
As a result, for this case,75% of the words remain with one analysis with95% accuracy, 20% with two analyses and 5% withthree analyses.Segal (2000) built a transformation-based tag-ger in the spirit of Brill (1995).
In the first phase,the analyses of each word are ranked according tothe frequencies of the possible lemmas and tags ina training corpus of about 5,000 words.
Selectionof the highest ranked analysis for each word givesan accuracy of 83% of the test text ?
which con-sists of about 1,000 words.
In the second stage,a transformation learning algorithm is applied (incontrast to Brill, the observed transformations arenot applied, but used for re-estimation of the wordcouples probabilities).
After this stage, the accu-racy is about 93%.
The last stage uses a bottom-up parser over a hand-crafted grammar with 150rules, in order to select the analysis which causesthe parsing to be more accurate.
Segal reports anaccuracy of 95%.
Testing his system over a largertest corpus, gives poorer results: Lembersky (2001)reports an accuracy of about 85%.Bar-Haim et al (2005) developed a word seg-menter and PoS tagger for Hebrew.
In their archi-tecture, words are first segmented into morphemes,and then, as a second stage, these morphemes aretagged with PoS.
The method proceeds in twosequential steps: segmentation into morphemes,then tagging over morphemes.
The segmentationis based on an HMM and trained over a set of 30Kannotated words.
The segmentation step reachesan accuracy of 96.74%.
PoS tagging, based on un-supervised estimation which combines a small an-notated corpus with an untagged corpus of 340K666Word Segmentation Tag Translationbclm bclm PNN name of a human rights association (Betselem)bclm bclm VB while taking a picturebclm bcl-m cons-NNM-suf their onionbclm b-cl-m P1-NNM-suf under their shadowbclm b-clm P1-NNM in a photographerbclm b-clm P1-cons-NNM in a photographerbclm b-clm P1-h-NNM in the photographerhn?im h-n?im P1-VBR that are movinghn?im hn?im P1-h-JJM the lovelyhn?im hn?im VBP made pleasantTable 1: Possible analyses for the words bclm hn?imwords by using smoothing technique, gives an ac-curacy of 90.51%.As noted earlier, there is as yet no large scaleHebrew annotated corpus.
We are in the processof developing such a corpus, and we have devel-oped tagging guidelines (Elhadad et al, 2005) todefine a comprehensive tag set, and assist humantaggers achieve high agreement.
The results dis-cussed above should be taken as rough approxima-tions of the real performance of the systems, untilthey can be re-evaluated on such a large scale cor-pus with a standard tag set.Arabic is a language with morphology quite sim-ilar to Hebrew.
Theoretically, there might be330,000 possible morphological tags, but in prac-tice, Habash and Rambow (2005) extracted 2,200different tags from their corpus, with an averagenumber of 2 possible tags per word.
As reportedby Habash and Rambow, the first work on Arabictagging which used a corpus for training and eval-uation was the work of Diab et al (2004).
Habashand Rambow were the first to use a morphologicalanalyzer as part of their tagger.
They developed asupervised morphological disambiguator, based ontraining corpora of two sets of 120K words, whichcombines several classifiers of individual morpho-logical features.
The accuracy of their analyzeris 94.8% ?
96.2% (depending on the test corpus).An unsupervised HMM model for dialectal Ara-bic (which is harder to be tagged than writtenArabic), with accurracy of 69.83%, was presentedby Duh and Kirchhoff (2005).
Their supervisedmodel, trained on a manually annotated corpus,reached an accuracy of 92.53%.Arabic morphology seems to be similar to He-brew morphology, in term of complexity and datasparseness, but comparison of the performancesof the baseline tagger used by Habash and Ram-bow ?
which selects the most frequent tag for agiven word in the training corpus ?
for Hebrew andArabic, shows some intriguing differences: 92.53%for Arabic and 71.85% for Hebrew.
Furthermore,as mentioned above, even the use of a sophisti-cated context-free tagger, based on (Levinger etal., 1995), gives low accuracy of 78.2%.
This mightimply that, despite the similarities, morphologicaldisambiguation in Hebrew might be harder than inArabic.
It could also mean that the tag set usedfor the Arabic corpora has not been adapted to thespecific nature of Arabic morphology (a commentalso made in (Habash and Rambow, 2005)).We propose an unsupervised morpheme-basedHMM to address the data sparseness problem.
Incontrast to Bar-Haim et al, our model combinessegmentation and morphological disambiguation,in parallel.
The only resource we use in this work isa morphological analyzer.
The analyzer itself canbe generated from a word list and a morphologi-cal generation module, such as the HSpell wordlist(Har?el and Kenigsberg, 2004).3 Morpheme-Based Model forHebrew3.1 Morpheme-Based HMMThe lexical items of word-based models are thewords of the language.
The implication of thisdecision is that both lexical and syntagmatic re-lations of the model, are based on a word-orientedtagset.
With such a tagset, it must be possible totag any word of the language with at least one tag.Let us consider, for instance, the Hebrew phrasebclm hn?im3, which contains two words.
The wordbclm has several possible morpheme segmentationsand analyses4 as described in Table 1.
In word-based HMM, we consider such a phrase to be gen-erated by a Markov process, based on the word-oriented tagset of N = 1934 tags/states and aboutM = 175K word types.
Line W of Table 2 de-scribes the size of a first-order word-based HMM,built over our corpus.
In this model, we found 834entries for the ?
vector (which models the distri-bution of tags in first position in sentences) out ofpossibly N = 1934, about 250K entries for the Amatrix (which models the transition probabilitiesfrom tag to tag) out of possibly N 2 ?
3.7M , andabout 300K entries for the B matrix (which models3Transcription according to Ornan (2002).4The tagset we use for the annotation follows theguidelines we have developed (Elhadad et al, 2005).667States PI A A2 B B2W 1934 834 250K 7M 300K 5MM 202 145 20K 700K 130K 1.7MTable 2: Model Sizesthe emission probabilities from tag to word) out ofpossibly M ?N ?
350M .
For the case of a second-order HMM, the size of the A2 matrix (which mod-els the transition probabilities from two tags to thethird one), grows to about 7M entries, where thesize of the B2 matrix (which models the emissionprobabilities from two tags to a word) is about 5M.Despite the sparseness of these matrices, the num-ber of their entries is still high, since we model thewhole set of features of the complex word forms.Let us assume, that the right segmentation forthe sentence is provided to us ?
for example: bclm hn?im ?
as is the case for English text.
Insuch a way, the observation is composed of mor-phemes, generated by a Markov process, basedon a morpheme-based tagset.
The size of such atagset for Hebrew is about 200, where the size ofthe ?,A,B,A2 and B2 matrices is reduced to 145,16K, 140K, 700K, and 1.7M correspondingly, asdescribed in line M of Table 2 ?
a reduction of90% when compared with the size of a word-basedmodel.The problem in this approach, is that ?someone?along the way, agglutinates the morphemes of eachword leaving the observed morphemes uncertain.For example, the word bclm can be segmented infour different ways in Table 1, as indicated by theplacement of the ?-?
in the Segmentation column,while the word hn?im can be segmented in two dif-ferent ways.
In the next section, we adapt the pa-rameter estimation and the searching algorithmsfor such uncertain output observation.3.2 Learning and Searching Algorithmsfor Uncertain Output ObservationIn contrast to standard HMM, the output observa-tions of the above morpheme-based HMM are am-biguous.
We adapted Baum-Welch (Baum, 1972)and Viterbi (Manning and Schutze, 1999, 9.3.2) al-gorithms for such uncertain observation.
We firstformalize the output representation and then de-scribe the algorithms.Output Representation The learning andsearching algorithms of HMM are based on theoutput sequence of the underlying Markov pro-cess.
For the case of a morpheme-based model,the output sequence is uncertain ?
we don?t see theemitted morphemes but the words they form.
If,for instance, the Markov process emitted the mor-phemes b clm h n?im, we would see two words (bclmhn?im) instead.
In order to handle the output am-biguity, we use static knowledge of how morphemesare combined into a word, such as the four knowncombinations of the word bclm, the two possiblecombinations of the word hn?im, and their possi-ble tags within the original words.
Based on thisinformation, we encode the sentence into a struc-ture that represents all the possible ?readings?
ofthe sentence, according to the possible morphemecombinations of the words, and their possible tags.The representation consists of a set of vectors,each vector containing the possible morphemes andtheir tags for each specific ?time?
(sequential posi-tion within the morpheme expansion of the wordsof the sentence).
A morpheme is represented bya tuple (symbol, state, prev, next), where symboldenotes a morpheme, state is one possible tag forthis morpheme, prev and next are sets of indexes,denoting the indexes of the morphemes (of the pre-vious and the next vectors) that precede and followthe current morpheme in the overall lattice, repre-senting the sentence.
Fig.
2 describes the repre-sentation of the sentence bclm hn?im.
An emissionis denoted in this figure by its symbol, its stateindex, directed edges from its previous emissions,and directed edges to its next emissions.In order to meet the condition of Baum-Eagoninequality (Baum, 1972) that the polynomialP (O|?)
?
which represents the probability of anobserved sequence O given a model ?
?
be homo-geneous, we must add a sequence of special EOS(end of sentence) symbols at the end of each pathup to the last vector, so that all the paths reachthe same length.The above text representation can be used tomodel multi-word expressions (MWEs).
Considerthe Hebrew sentence: hw?
?wrk dyn gdwl, which canbe interpreted as composed of 3 units (he lawyergreat / he is a great lawyer) or as 4 units (he editslaw big / he is editing an important legal deci-sion).
In order to select the correct interpretation,we must determine whether ?wrk dyn is an MWE.This is another case of uncertain output observa-tion, which can be represented by our text encod-ing, as done in Fig.
1.?wrk dyn 6 gdwl 19 EOS 17 EOS 17dyn 6 gdwl 19?wrk 18hw?
20Figure 1: The sentence hw?
?wrk dyn gdwlThis representation seems to be expensive interm of the number of emissions per sentence.However, we observe in our data that most of thewords have only one or two possible segmentations,and most of the segmentations consist of at mostone affix.
In practice, we found the average numberof emissions per sentence in our corpus (where eachsymbol is counted as the number of its predecessoremissions) to be 455, where the average numberof words per sentence is about 18.
That is, the668cost of operating over an ambiguous sentence rep-resentation increases the size of the sentence (from18 to 455), but on the other hand, it reduces theprobabilistic model by a factor of 10 (as discussedabove).Morphological disambiguation over such a se-quence of vectors of uncertain morphemes is similarto words extraction in automatic speech recogni-tion (ASR)(Jurafsky and Martin, 2000, chp.
5,7).The states of the ASR model are phones, whereeach observation is a vector of spectral features.Given a sequence of observations for a sentence,the encoding ?
based on the lattice formed by thephones distribution of the observations, and thelanguage model ?
searches for the set of words,made of phones, which maximizes the acoustic like-lihood and the language model probabilities.
In asimilar manner, the supervised training of a speechrecognizer combines a training corpus of speechwave files, together with word-transcription, andlanguage model probabilities, in order to learn thephones model.There are two main differences between the typi-cal ASR model and ours: (1) an ASR decoder dealswith one aspect - segmentation of the observationsinto a set of words, where this segmentation canbe modeled at several levels: subphones, phonesand words.
These levels can be trained individ-ually (such as training a language model from awritten corpus, and training the phones model foreach word type, given transcripted wave file), andthen combined together (in a hierarchical model).Morphological disambiguation over uncertain mor-phemes, on the other hand, deals with both mor-pheme segmentation and the tagging of each mor-pheme with its morphological features.
Model-ing morpheme segmentation, within a given word,without its morphology features would be insuf-ficient.
(2) The supervised resources of ASR arenot available for morphological disambiguation: wedon?t have a model of morphological features se-quences (equivalent to the language model of ASR)nor a tagged corpus (equivalent to the transcriptedwave files of ASR).These two differences require a design whichcombines the two dimensions of the problem, in or-der to support unsupervised learning (and search-ing) of morpheme sequences and their morpholog-ical features, simultaneously.Parameter Estimation We present a variationof the Baum-Welch algorithm (Baum, 1972) whichoperates over the lattice representation we have de-fined above.
The algorithm starts with a proba-bilistic model ?
(which can be chosen randomlyor obtained from good initial conditions), and ateach iteration, a new model ??
is derived in order tobetter explain the given output observations.
For agiven sentence, we define T as the number of wordsin the sentence, and T?
as the number of vectors ofthe output representation O = {ot}, 1 ?
t ?
T?
,where each item in the output is denoted by olt =(sym, state, prev, next), 1 ?
t ?
T?
, 1 ?
l ?
|ot|.We define ?
(t, l) as the probability to reach olt attime t, and ?
(t, l) as the probability to end the se-quence from olt.
Fig.
3 describes the expectationand the maximization steps of the learning algo-rithm for a first-order HMM.
The algorithm worksin O(T? )
time complexity, where T?
is the total num-ber of symbols in the output sequence encoding,where each symbol is counted as the size of its prevset.Searching for best state sequence Thesearching algorithm gets an observation sequenceO and a probabilistic model ?, and looks for thebest state sequence that generates the observation.We define ?
(t, l) as the probability of the best statesequence that leads to emission olt, and ?
(t, l) asthe index of the emission at time t?1 that precedesolt in the best state sequence that leads to it.
Fig.
4describes the adaptation of the Viterbi (Manningand Schutze, 1999, 9.3.2) algorithm to our text rep-resentation for first-order HMM, which works inO(T? )
time.4 Experimental ResultsWe ran a series of experiments on a Hebrew corpusto compare various approaches to the full morpho-logical disambiguation and PoS tagging tasks.
Thetraining corpus is obtained from various newspa-per sources and is characterized by the followingstatistics: 6M word occurrences, 178,580 distinctwords, 64,541 distinct lemmas.
Overall, the ambi-guity level is 2.4 (average number of analyses perword).We tested the results on a test corpus, manuallyannotated by 2 taggers according to the guidelineswe published and checked for agreement.
The testcorpus contains about 30K words.
We comparedtwo unsupervised models over this data set: Wordmodel [W], and Morpheme model [M].
We alsotested two different sets of initial conditions.
Uni-form distribution [Uniform]: For each word, eachanalysis provided by the analyzer is estimated withan equal likelihood.
Context Free approximation[CF]: We applied the CF algorithm of Levinger etal.
(1995) to estimate the likelihood of each analy-sis.Table 3 reports the results of full morphologi-cal disambiguation.
For each morpheme and wordmodels, three types of models were tested: [1]First-order HMM, [2-] Partial second-order HMM -only state transitions were modeled (excluding B2matrix), [2] Second-order HMM (including the B2matrix).Analysis If we consider the tagger which selectsthe most probable morphological analysis for each669clm 7m 3n?im 16clm 10cl 9hn?im 14hn?im 15h 2n?im 16h 2EOS 17clm 8hn?im 11hn?im 12m 4hn?im 14hn?im 15h 2hn?im 11hn?im 12EOS 17hn?im 14hn?im 15hn?im 11hn?im 12EOS 17n?im 16EOS 17bcl 6b 1bclm 5b 0Figure 2: Representation of the sentence bclm hn?imExpectation?
(1, l) = piol1.statebol1.state,ol1.sym (1)?
(t, l) = bolt.state,olt.sym?l??olt.prev?(t?
1, l?)aol?t?1.state,olt.state?(T?
, l) = 1 (2)?
(t, l) =?l??olt.nextaolt.state,ol?t+1.statebol?t+1.state,ol?t+1.sym?
(t+ 1, l?
)Maximization?i =?l:ol1.state=i ?
(1, l)?
(1, l)?l ?
(1, l)?
(1, l)(3)a?i,j =?T?t=2?l:olt.state=j?l??olt.prev:ol?t?1.state=i?(t?
1, l?)ai,jbj,olt.sym?
(t, l)?T?
?1t=1?l:olt.state=i ?
(t, l)?
(t, l)(4)b?i,k =?T?t=1?l:olt.sym=k,olt.state=i ?
(t, l)?
(t, l)?T?t=1?l:olt.state=i ?
(t, l)?
(t, l)(5)Figure 3: The learning algorithm for first-order modelInitialization?
(1, l) = piol1.statebol1.state,ol1.sym (6)Induction?
(t, l) = maxl??olt.prev?(t?
1, l?
)aol?t?1.state,olt.statebolt.state,olt.sym (7)?
(t, l) = argmaxl??olt.prev?(t?
1, l?
)aol?t?1.state,olt.statebolt.state,olt.sym (8)Termination and path readoutX?T?
= argmax1?l?|T?
| ?(T?
, l) (9)X?t = ?
(t+ 1, X?t+1)P (X?)
= max1?l?|OT?
|?(T?
, l) (10)Figure 4: The searching algorithm for first-order model670Order Uniform CFW 1 82.01 84.08W 2- 80.44 85.75W 2 79.88 85.78M 1 81.08 84.54M 2- 81.53 88.5M 2 83.39 85.83Table 3: Morphological Disambiguationword in the text, according to Levinger et al (1995)approximations, with accuracy of 78.2%, as thebaseline tagger, four steps of error reduction canbe identified.
(1) Contextual information: Thesimplest first-order word-based HMM with uniforminitial conditions, achieves error reduction of 17.5%(78.2 ?
82.01).
(2) Initial conditions: Error reduc-tions in the range: 11.5% ?
37.8% (82.01 ?
84.08for word model 1, and 81.53 ?
88.5 for morhpememodel 2-) were achieved by initializing the variousmodels with context-free approximations.
Whilethis observation confirms Elworthy (1994), the im-pact of error reduction is much less than reportedthere for English - about 70% (79 ?
94).
The keydifference (beside the unclear characteristic of El-worthy initial condition - since he made use of anannotated corpus) is the much higher quality of theuniform distribution for Hebrew.
(3) Model order:The partial second-order HMM [2-] produced thebest results for both word (85.75%) and morpheme(88.5%) models over the initial condition.
The fullsecond-order HMM [2] didn?t upgrade the accu-racy of the partial second-order, but achieved thebest results for the uniform distribution morphememodel.
This is because the context-free approxima-tion does not take into account the tag of the previ-ous word, which is part of model 2.
We believe thatinitializing the morpheme model over a small set ofannotated corpus will set much stronger initial con-dition for this model.
(4) Model type: The mainresult of this paper is the error reduction of themorpheme model with respect to the word model:about 19.3% (85.75 ?
88.5).In addition, we apply the above models for thesimpler task of segmentation and PoS tagging, asreported in Table 4.
The task requires picking thecorrect morphemes of each word with their correctPoS (excluding all other morphological features).The best result for this task is obtained with themorpheme model 2: 92.32%.
For this simpler task,the improvement brought by the morpheme modelover the word model is less significant, but stillconsists of a 5% error reduction.Unknown words account for a significantchunk of the errors.
Table 5 shows the distributionof errors contributed by unknown words (wordsthat cannot be analyzed by the morphological an-alyzer).
7.5% of the words in the test corpus areunknown: 4% are not recognized at all by the mor-phological analyzer (marked as [None] in the ta-Order Uniform CFW 1 91.07 91.47W 2- 90.45 91.93W 2 90.21 91.84M 1 89.23 91.42M 2- 89.77 91.76M 2 91.42 92.32Table 4: Segmentation and PoS Taggingble), and for 3.5%, the set of analyses proposed bythe analyzer does not contain the correct analy-sis [Missing].
We extended the lexicon to includemissing and none lexemes of the closed sets.
Inaddition, we modified the analyzer to extract allpossible segmentations of unknown words, with allthe possible tags for the segmented affixes, wherethe remaining unknown baseforms are tagged asUK.
The model was trained over this set.
In thenext phase, the corpus was automatically tagged,according to the trained model, in order to form atag distribution for each unknown word, accordingto its context and its form.
Finally, the tag foreach unknown word were selected according to itstag distribution.
This strategy accounts for abouthalf of the 7.5% unknown words.None Missing %Proper name 26 36 62Closed Set 8 5.6 13.6Other 16.5 5.4 21.9Junk 2.5 0 2.553 47 100Table 5: Unknown Word DistributionTable 6 shows the confusion matrix for knownwords (5% and up).
The key confusions can be at-tributed to linguistic properties of Modern Hebrew:most Hebrew proper names are also nouns (andthey are not marked by capitalization) ?
which ex-plains the PN/N confusion.
The verb/noun andverb/adjective confusions are explained by the na-ture of the participle form in Hebrew (beinoni) ?participles behave syntactically almost in an iden-tical manner as nouns.Correct Error %proper name noun 17.9noun verb 15.3noun proper name 6.6verb noun 6.3adjective noun 5.4adjective verb 5.0Table 6: Confusion Matrix for Known Words5 Conclusions and Future WorkIn this work, we have introduced a new text encod-ing method that captures rules of word formationin a language with affixational morphology such asHebrew.
This text encoding method allows us to671learn in parallel segmentation and tagging rules inan unsupervised manner, despite the high ambigu-ity level of the morphological data (average num-ber of 2.4 analyses per word).
Reported results ona large scale corpus (6M words) with fully unsu-pervised learning are 92.32% for PoS tagging and88.5% for full morphological disambiguation.In this work, we used the backoff smoothingmethod, suggested by Thede and Harper (1999),with an extension of additive smoothing (Chen,1996, 2.2.1) for the lexical probabilities (B and B2matrices).
To complete this study, we are currentlyinvestigating several smoothing techniques (Chen,1996), in order to check whether the morphememodel is critical for the data sparseness problem,or whether it can be handled with smoothing overa word model.We are currently investigating two major meth-ods to improve our results: first, we have startedgathering a larger corpus of manually tagged textand plan to perform semi-supervised learning ona corpus of 100K manually tagged words.
Second,we plan to improve the unknown word model, suchas integrating it with named entity recognition sys-tem (Ben-Mordechai, 2005).ReferencesEmmanuel Allon.
1995.
Unvocalized Hebrew Writ-ing.
Ben Gurion University Press.
(in Hebrew).Roy Bar-Haim, Khalil Sima?an, and Yoad Winter.2005.
Choosing an optimal architecture for seg-mentation and pos-tagging of modern Hebrew.In Proceedings of ACL-05 Workshop on Compu-tational Approaches to Semitic Languages.Leonard E. Baum.
1972.
An inequality and asso-ciated maximization technique in statistical es-timation for probabilistic functions of a Markovprocess.
Inequalities, 3:1?8.Na?ama Ben-Mordechai.
2005.
Named entitiesrecognition in Hebrew.
Master?s thesis, Ben Gu-rion University of the Negev, Beer Sheva, Israel.
(in Hebrew).Eric Brill.
1995.
Transformation-based error-driven learning and natural languge processing:A case study in part-of-speech tagging.
Compu-tational Linguistics, 21:543?565.David Carmel and Yoelle S. Maarek.
1999.
Mor-phological disambiguation for Hebrew searchsystems.
In Proceeding of NGITS-99.Stanley F. Chen.
1996.
Building ProbabilisticModels for Natural Language.
Ph.D. thesis, Har-vard University, Cambridge, MA.Mona Diab, Kadri Hacioglu, and Daniel Jurafsky.2004.
Automatic tagging of Arabic text: Fromraw text to base phrase chunks.
In Proceedingof HLT-NAACL-04.Kevin Duh and Katrin Kirchhoff.
2005.
Pos tag-ging of dialectal Arabic: A minimally supervisedapproach.
In Proceedings of ACL-05 Workshopon Computational Approaches to Semitic Lan-guages.Michael Elhadad, Yael Netzer, David Gabay, andMeni Adler.
2005.
Hebrew morphological tag-ging guidelines.
Technical report, Ben GurionUniversity, Dept.
of Computer Science.David Elworthy.
1994.
Does Baum-Welch re-estimation help taggers?
In Proceeding ofANLP-94.Nizar Habash and Owen Rambow.
2005.
Arabictokenization, part-of-speech tagging and mor-phological disambiguation in one fell swoop.
InProceeding of ACL-05.Nadav Har?el and Dan Kenigsberg.
2004.
HSpell- the free Hebrew spell checker and morphologi-cal analyzer.
Israeli Seminar on ComputationalLinguistics, December 2004.Daniel Jurafsky and James H. Martin.
2000.Speech and language processing.
Prentice-Hall.Gennady Lembersky.
2001.
Named entities recog-nition; compounds: approaches and recognitionsmethods.
Master?s thesis, Ben Gurion Univer-sity of the Negev, Beer Sheva, Israel.
(in He-brew).Moshe Levinger, Uzi Ornan, and Alon Itai.
1995.Learning morpholexical probabilities from anuntagged corpus with an application to Hebrew.Computational Linguistics, 21:383?404.Moshe Levinger.
1992.
Morhphological disam-biguation in hebrew.
Master?s thesis, Technion,Haifa, Israel.
(in Hebrew).Christopher D. Manning and Hinrich Schutze.1999.
Foundation of Statistical Language Pro-cessing.
MIT Press.Bernard Merialdo.
1994.
Tagging English textwith probabilistic model.
Computatinal Linguis-tics, 20:155?171.Uzi Ornan.
2002.
Hebrew in latin script.Le?s?one?nu, LXIV:137?151.
(in Hebrew).Erel Segal.
2000.
Hebrew morphological ana-lyzer for Hebrew undotted texts.
Master?s the-sis, Technion, Haifa, Israel.
(in Hebrew).Scott M. Thede and Mary P. Harper.
1999.
Asecond-order hidden Markov model for part-of-speech tagging.
In Proceeding of ACL-99.Shlomo Yona and Shuly Wintner.
2005.
A finite-state morphological grammar of Hebrew.
InProceedings of ACL-05 Workshop on Computa-tional Approaches to Semitic Languages.672
