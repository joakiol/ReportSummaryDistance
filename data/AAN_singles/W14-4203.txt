Language Technology for Closely Related Languages and Language Variants (LT4CloseLang), pages 13?24,October 29, 2014, Doha, Qatar.c?2014 Association for Computational LinguisticsCross-lingual Dependency Parsing of Related Languages with RichMorphosyntactic Tagsets?Zeljko Agi?c J?org Tiedemann Kaja Dobrovoljczagic@uni-potsdam.de jorg.tiedemann@lingfil.uu.se kaja.dobrovoljc@trojina.siSimon Krek Danijela Merkler Sara Mo?zesimon.krek@ijs.si dmerkler@ffzg.hr s.moze@wlv.ac.ukAbstractThis paper addresses cross-lingual depen-dency parsing using rich morphosyntac-tic tagsets.
In our case study, we experi-ment with three related Slavic languages:Croatian, Serbian and Slovene.
Four dif-ferent dependency treebanks are used formonolingual parsing, direct cross-lingualparsing, and a recently introduced cross-lingual parsing approach that utilizes sta-tistical machine translation and annota-tion projection.
We argue for the benefitsof using rich morphosyntactic tagsets incross-lingual parsing and empirically sup-port the claim by showing large improve-ments over an impoverished common fea-ture representation in form of a reducedpart-of-speech tagset.
In the process, weimprove over the previous state-of-the-artscores in dependency parsing for all threelanguages.1 IntroductionA large majority of human languages are under-resourced in terms of text corpora and tools avail-able for applications in natural language process-ing (NLP).
According to recent surveys (Bender,2011; Uszkoreit and Rehm, 2012; Bender, 2013),this is especially apparent with syntactically anno-tated corpora, i.e., treebanks ?
both dependency-based ones and others.
In this paper, we fo-cus on dependency parsing (K?ubler et al., 2009),but the claims should hold in general.
The lackof dependency treebanks is due to the fact thatthey are expensive and time-consuming to con-struct (Abeill?e, 2003).
Since dependency parsingof under-resourced languages nonetheless drawssubstantial interest in the NLP research commu-nity, over time, we have seen a number of researchefforts directed towards their processing despitethe absence of training data for supervised learn-ing of parsing models.
We give a brief overview ofthe major research directions in the following sub-section.
Here, we focus on supervised learning ofdependency parsers, as the performance of unsu-pervised approaches still falls far behind the stateof the art in supervised parser induction.1.1 Related WorkThere are two basic strategies for data-driven pars-ing of languages with no dependency treebanks:annotation projection and model transfer.
Bothfall into the general category of cross-lingual de-pendency parsing as they attempt to utilize ex-isting dependency treebanks or parsers from aresource-rich language (source) for parsing theunder-resourced (target) language.Annotation projection: In this approach, de-pendency trees are projected from a source lan-guage to a target language using word alignmentsin parallel corpora.
It is based on a presumptionthat source-target parallel corpora are more read-ily available than dependency treebanks.
The ap-proach comes in two varieties.
In the first one, par-allel corpora are exploited by applying the avail-able state-of-the-art parsers on the source sideand subsequent projection to the target side us-ing word alignments and heuristics for resolvingpossible link ambiguities (Yarowsky et al., 2001;Hwa et al., 2005).
Since dependency parsers typ-ically make heavy use of various morphologicaland other features, the apparent benefit of this ap-proach is the possibility of straightforward pro-jection of these features, resulting in a feature-rich representation for the target language.
On thedownside, the annotation projection noise adds upto dependency parsing noise and errors in wordalignment, influencing the quality of the resultingtarget language parser.The other variety is rare, since it relies on paral-lel corpora in which the source side is a depen-13dency treebank, i.e., it is already manually an-notated for syntactic dependencies (Agi?c et al.,2012).
This removes the automatic parsing noise,while the issues with word alignment and annota-tion heuristics still remain.Model transfer: In its simplest form, transfer-ring a model amounts to training a source lan-guage parser and running it directly on the targetlanguage.
It is usually coupled with delexicaliza-tion, i.e., removing all lexical features from thesource treebank for training the parser (Zeman andResnik, 2008; McDonald et al., 2013).
This in turnrelies on the same underlying feature model, typi-cally drawing from a shared part-of-speech (POS)representation such as the Universal POS Tagset ofPetrov et al.
(2012).
Negative effects of using suchan impoverished shared representation are typi-cally addressed by adapting the model to better fitthe target language.
This includes selecting sourcelanguage data points appropriate for the target lan-guage (S?gaard, 2011; T?ackstr?om et al., 2013),transferring from multiple sources (McDonald etal., 2011) and using cross-lingual word clusters(T?ackstr?om et al., 2012).
These approaches needno projection and enable the usage of source-sidegold standard annotations, but they all rely ona shared feature representation across languages,which can be seen as a strong bottleneck.
Also,while most of the earlier research made use ofheterogenous treebanks and thus yielded linguisti-cally implausible observations, research stemmingfrom an uniform dependency scheme across lan-guages (De Marneffe and Manning, 2008; Mc-Donald et al., 2013) made it possible to performmore consistent experiments and to assess the ac-curacy of dependency labels.Other approaches: More recently, Durrett etal.
(2012) suggested a hybrid approach that in-volves bilingual lexica in cross-lingual phrase-based parsing.
In their approach, a source-sidetreebank is adapted to a target language by ?trans-lating?
the source words to target words througha bilingual lexicon.
This approach is advancedby Tiedemann et al.
(2014), who utilize full-scale statistical machine translation (SMT) sys-tems for generating synthetic target language tree-banks.
This approach relates to annotation pro-jection, while bypassing the issue of dependencyparsing noise as gold standard annotations are pro-jected.
The SMT noise is in turn mitigated bybetter word alignment quality for synthetic data.The influence of various projection algorithms inthis approach is further investigated by Tiedemann(2014).
This line of cross-lingual parsing researchsubstantially improves over previous work.1.2 Paper OverviewAll lines of previous cross-lingual parsing researchleft the topics of related languages and shared richfeature representations largely unaddressed, withthe exception of Zeman and Resnik (2008), whodeal with phrase-based parsing test-cased on Dan-ish and Swedish treebanks, utilizing a mappingover relatively small POS tagsets.In our contribution, the goal is to observe theproperties of cross-lingual parsing in an envi-ronment of relatively free-word-order languages,which are related and characterized by rich mor-phology and very large morphosyntactic tagsets.We experiment with four different small- andmedium-size dependency treebanks of Croatianand Slovene, and cross-lingually parse into Croa-tian, Serbian and Slovene.
Along with monolin-gual and direct transfer parsing, we make use ofthe SMT framework of Tiedemann et al.
(2014).We are motivated by:?
observing the performance of various ap-proaches to cross-lingual dependency parsingfor closely related languages, including the veryrecent treebank translation approach by Tiede-mann et al.
(2014);?
doing so by using rich morphosyntactic tagsets,in contrast to virtually all other recent cross-lingual dependency parsing experiments, whichmainly utilize the Universal POS tagset ofPetrov et al.
(2012);?
reliably testing for labeled parsing accuracy inan environment with heterogenous dependencyannotation schemes; and?
improving the state of the art for Croatian,Slovene and Serbian dependency parsing acrossthese heterogenous schemes.In Section 2, we describe the language resourcesused: treebanks, tagsets and test sets.
Section 3describes the experimental setup, which includesa description of parsing, machine translation andannotation projection.
In Section 4, we discuss theresults of the experiments, and we conclude thediscussion by sketching the possible directions forfuture research in Section 5.14Figure 1: Histogram of edge distances in the tree-banks.
Edge distance is measured in tokens be-tween heads and dependents.
Distance of 1 de-notes adjacent tokens.Figure 2: Histogram of average tree depths.2 ResourcesWe make use of the publicly available language re-sources for Croatian, Serbian and Slovene.
Theseinclude dependency treebanks, test sets annotatedfor morphology and dependency syntax, and amorphosyntactic feature representation drawingfrom the Multext East project (Erjavec, 2012).A detailed assessment of the current state of de-velopment for morphosyntactic and syntactic pro-cessing of these languages is given by Agi?c et al.
(2013) and Uszkoreit and Rehm (2012).
Here, weprovide only a short description.2.1 TreebanksWe use two Croatian and two Slovene dependencytreebanks.1One for each language is based on thePrague Dependency Treebank (PDT) (B?ohmov?aet al., 2003) annotation scheme, while the othertwo introduced novel and more simplified syntac-tic tagsets.
All four treebanks use adaptations of1No treebanks of Serbian were publicly available at thetime of conducting this experiment.Feature hr PDT hr SET sl PDT sl SSJSentences 4,626 8,655 1,534 11,217Tokens 117,369 192,924 28,750 232,241Types 25,038 37,749 7,128 48,234Parts of speech 13 13 12 13MSDs 821 685 725 1,142Syntactic tags 26 15 26 10Table 1: Basic treebank statistics.the Multext East version 4 tagset (Erjavec, 2012)for the underlying morphological annotation layer,which we shortly describe further down.
Basicstatistics for the treebanks are given in Table 1.hr PDT: This treebank is natively referred toas the Croatian Dependency Treebank (HOBS)(Tadi?c, 2007; Berovi?c et al., 2012).
Its most recentinstance, HOBS 2.0 (Agi?c et al., 2014) slightly de-parts from the PDT scheme.
Thus, in this exper-iment, we use the older version, HOBS 1.0, andhenceforth refer to it as hr PDT for consistency andmore clear reference to its annotation.2hr SET: The SETIMES.HR dependency treebankof Croatian has a 15-tag scheme.
It is targetedtowards high parsing accuracy, while maintaininga clear distinction between all basic grammaticalcategories of Croatian.
Its publicly available 1.0release consists of approximately 2,500 sentences(Agi?c and Merkler, 2013), while release 2.0 hasjust under 4,000 sentences (Agi?c and Ljube?si?c,2014) of newspaper text.
Here, we use an evennewer, recently developed version with more than8,500 sentences from multiple domains.3sl PDT: The PDT-based Slovene DependencyTreebank (D?zeroski et al., 2006) is built on top ofa rather small portion of Orwell?s novel 1984 fromthe Multext East project (Erjavec, 2012).
Even ifthe project was discontinued, it is still heavily usedas part of the venerable CoNLL 2006 and 2007shared task datasets (Buchholz and Marsi, 2006;Nivre et al., 2007).4sl SSJ: The Slovene take on simplifying syntac-tic annotations resulted in the 10-tag strong JOSCorpus of Slovene (Erjavec et al., 2010).
Similarto hr SET, this new annotation scheme is loosely2HOBS is available through META-SHARE (Tadi?c andV?aradi, 2012).3http://nlp.ffzg.hr/resources/corpora/setimes-hr/4http://nl.ijs.si/sdt/15PDT-based, but considerably reduced to facilitatemanual annotation.
The initial 100,000 token cor-pus has recently doubled in size, as described byDobrovoljc et al.
(2012).
We use the latter versionin our experiment.5The statistics in Table 1 show a variety of tree-bank sizes and annotations.
Figure 1 illustrates thestructural complexity of the treebanks by provid-ing a histogram of egdes by token distance.
Whileadjacent edges expectedly dominate the distribu-tions, it is interesting to see that almost 30% ofall edges in sl SSJ attach to root, resulting in aneasily parsable flattened tree structure.
Knowingthat relations denoting attributes account for morethan one third of all non-root dependents in the re-mainder, one can expect dependency parsing per-formance comparable to CoNLL-style chunking(Tjong Kim Sang and Buchholz, 2000).
This isfurther supported by the distributions of sentencesin the four treebanks by average tree depth in Fig-ure 2.
We can see that virtually all sl SSJ trees haveaverage depths of 1 to 3, while the other treebanksexhibit the more common structural properties ofdependency trees.In these terms of complexity, the Croatian tree-banks are richer than their Slovene counterparts.In sl SSJ, attributes and edges to root account formore than 60% of all dependencies.
Even in theother three treebanks, 20-30% of the edges are la-beled as attributes, while the rest is spread moreevenly between the basic syntactic categories suchas predicates, subject and objects.
More detailedand more linguistically motivated comparisons ofthe three annotation guidelines fall outside thescope of our paper.
Instead, we refer to the pre-viously noted publications on the respective tree-banks, and to (Agi?c and Merkler, 2013; Agi?c etal., 2013) for comparisons between PDT and SETin parsing Croatian and Serbian.2.2 Morphosyntactic TagsetAll four treebanks were manually created: theyare sentence- and token-split, lemmatized, mor-phosyntactically tagged and syntactically anno-tated.
In morphosyntactic annotation, they allmake use of the Multext East version 4 (MTE4) guidelines (Erjavec, 2012).6MTE 4 is a po-sitional tagset in which morphosyntactic descrip-tors of word forms are captured by a morphosyn-5http://eng.slovenscina.eu/tehnologije/ucni-korpus6http://nl.ijs.si/ME/V4/tactic tag (MSD) created by merging atomic at-tributes in the predefined positions.
This is illus-trated in Table 2 through an example verb tag.
Thefirst character of the tag denotes the part of speech(POS), while each of the following characters en-codes a specific attribute in a specific position.Both the positions and the attributes are language-dependent in MTE 4, but the attributes are stilllargely shared between these three languages dueto their relatedness.The Slovene treebanks closely adhere to thespecification, while each of the Croatian treebanksimplements slight adaptations of the tagset to-wards Croatian specifics.
In hr PDT, the adaptationis governed by and documented in the CroatianMorphological Lexicon (Tadi?c and Fulgosi, 2003),and the modifications in hr SET were targeted tomore closely match the ones for Slovene.72.3 Test SetsRecent research by McDonald et al.
(2013) hasuncovered the downsides of experimenting withparsing using heterogenous dependency annota-tions, while at the same time providing possi-bly the first reliable results in cross-lingual pars-ing.
They did so by creating the uniformly anno-tated Universal Dependency Treebanks collectionbased on Stanford Typed Dependencies (De Marn-effe and Manning, 2008), which in turn also en-abled measuring both labeled (LAS) and unla-beled (UAS) parsing accuracy.Having four treebanks with three different an-notation schemes, we seek to enable reliable ex-perimentation through our test sets.
Along withCroatian and Slovene, which are represented in thetraining sets, we introduce Serbian as a target-onlylanguage in the test data.
Following the CoNLLshared tasks setup (Buchholz and Marsi, 2006;Nivre et al., 2007), our test sets have 200 sentences(approx.
5,000 tokens) per language, split 50:50between newswire and Wikipedia text.
Each testset is manually annotated for morphosyntax, fol-lowing the MTE 4 guidelines for the respectivelanguages, and checked by native speakers for va-lidity.
On top of that, all test sets are annotatedwith all three dependency schemes: PDT, SET andSSJ.
This enables observing LAS in a heteroge-nous experimental environment, as we test eachmonolingual and cross-lingual parser on an anno-7http://nlp.ffzg.hr/data/tagging/msd-hr.html16Language MSD tag Attribute-value pairshr Vmn Category = Verb, Type = main, Vform = infinitivesl Vmen Category = Verb, Type = main, Aspect = perfective, VForm = infinitivesr Vmn----an-n---e Category = Verb, Type = main, VForm = infinitive, Voice = active,Negative = no, Clitic = no, Aspect = perfectiveTable 2: Illustration of the Multext East version 4 tagset for Croatian, Serbian and Slovene.
The attributesare language-dependent, as well as their positions in the tag, which are also dependent on the part ofspeech, denoted by position zero in the tag.tation layer matching its training set.
In contrast,the MTE 4 tagsets are not adjusted, i.e., each testset only has a single language-specific MTE 4 an-notation.
We rely on their underlying similaritiesin feature representations to suffice for improvedcross-lingual parsing performance.3 Experiment SetupThis section describes the experiment settings.
Welist the general workflow of the experiment andthen provide the details on the parser setup andthe more advanced approaches used for target lan-guage adaptation of the models.3.1 WorkflowThe experiment consists of three work packages:(1) monolingual parsing, (2) direct cross-lingualparsing, and (3) cross-lingual parsing using syn-thetic training data from SMT.
In the first one, wetrain dependency parsers on the four treebanks andtest them on the corresponding languages, thusassessing the monolingual parsing performance.The second stage observes the effects of directlyapplying the parsers from the first stage across thelanguages.
Finaly, in the third work package, weuse four different approaches to automatic transla-tion to create synthetic training data.
We translatethe Croatian treebanks to Slovene and vice versa,project the annotations using two different projec-tion algorithms, and train and apply the adaptedparsers across the languages.
The details are in-cluded in the two following subsections.Two general remarks apply to our experiment.First, we perform cross-lingual parsing, and notcross-annotation-scheme parsing.
Thus, we do notcompare the dependency parsing scores betweenthe annotation schemes, but rather just betweenthe in-scheme parsers.
Second, we use Serbian asa test-set-only language.
As there are no treebanksof Serbian, we cannot use it as a source language,and we leave SMT and annotation projection intoSerbian for future work.3.2 Dependency ParsingIn all experiments, we use the graph-based de-pendency parser by Bohnet (2010) with defaultsettings.
We base our parser choice on its state-of-the-art performance across various morpholog-ically rich languages in the SPMLR 2013 sharedtask (Seddah et al., 2013).
While newer contribu-tions targeted at joint morphological and syntacticanalysis (Bohnet and Kuhn, 2012; Bohnet et al.,2013) report slightly higher scores, we chose theformer one for speed and robustness, and becausewe use gold standard POS/MSD annotations.
Thechoice of gold standard preprocessing is motivatedby previous research in parsing Croatian and Ser-bian (Agi?c et al., 2013), and by insight of Sed-dah et al.
(2013), who report a predictable lineardecrease in accuracy for automatic preprocessing.This decrease amounts to approximately 3 pointsLAS for Croatian and Serbian across various testcases in (Agi?c et al., 2013).We observe effects of (de)lexicalization and ofusing full MSD tagset as opposed to only POS tagsin all experiments.
Namely, in all work packages,we compare parsers trained with {lexicalized,delexicalized} ?
{MSD, POS} features.
In lexi-calized parsers, we use word forms and features,while we exclude lemmas from all experiments ?both previous research using MSTParser (McDon-ald et al., 2005) and our own test runs show nouse for lemmas as features in dependency parsing.Delexicalized parsers are stripped of all lexicalfeatures, i.e., word forms are omitted from trainingand testing data.
Full MSD parsers use both thePOS information and the sub-POS features in theform of atomic attribute-value pairs, while POS-only parsers are stripped of the MSD features ?they use just the POS information.
The delexi-calized POS scenario is thus very similar to the17direct transfer by McDonald et al.
(2013), sinceMTE 4 POS is virtually identical to Universal POS(Petrov et al., 2012).83.3 Treebank Translation and AnnotationProjectionFor machine translation, we closely adhere to thesetup implemented by Tiedemann et al.
(2014) intheir treebank translation experiments.
Namely,our translations are based on automatic wordalignment and subsequent extraction of translationequivalents as common in phrase-based SMT.
Weperform word alignment by using GIZA++ (Ochand Ney, 2003), while utilizing IBM model 4 forcreating the Viterbi word alignments for parallelcorpora.
For the extraction of translation tables,we use the de facto standard SMT toolbox Moses(Koehn et al., 2007) with default settings.
Phrase-based SMT models are tuned using minimum er-ror rate training (Och, 2003).
Our monolinguallanguage modeling using KenLM tools9(Heafield,2011) produces standard 5-gram language mod-els using modified Kneser-Ney smoothing withoutpruning.For building the translation models, we usethe OpenSubtitles parallel resources from OPUS10(Tiedemann, 2009) for the Croatian-Slovene pair.Even if we expect this to be a rather noisy paral-lel resource, we justify the choice by (1) the factthat no other parallel corpora11of Croatian andSlovene exist, other than Orwell?s 1984 from theMultext East project, which is too small for SMTtraining and falls into a very narrow domain, and(2) evidence from (Tiedemann et al., 2014) that theSMT-supported cross-lingual parsing approach isvery robust to translation noise.For translating Croatian treebanks into Sloveneand vice versa, we implement and test four dif-ferent methods of translation.
They are coupledwith approaches to annotation projection from thesource side gold dependency trees to the targettranslations via the word alignment informationavailable from SMT.8A mapping from Slovene MTE 4 to UniversalPOS is available at https://code.google.com/p/universal-pos-tags/ as an example.9https://kheafield.com/code/kenlm/10http://opus.lingfil.uu.se/11We note the Croatian-Slovene parallel corpus project de-scribed by Po?zgaj Had?zi and Tadi?c (2000), but it appears thatthe project was not completed and the corpus itself is not pub-licly available.LOOKUP: The first approach to translation inour experiment is the dictionary lookup approach.We simply select the most reliable translations ofsingle words in the source language into the tar-get language by looking up the phrase translationtables extracted from the parallel corpus.
This isvery similar to what Agi?c et al.
(2012) did for theCroatian-Slovene pair.
However, their approachinvolved both translating and testing on the samesmall corpus (Orwell?s novel), while here we ex-tract the translations from full-blown SMT phrasetables on a much larger scale.
The trees projec-tion from source to target is trivial since the num-ber and the ordering of words between them doesnot change.
Thus, the dependencies are simplycopied.CHAR: By this acronym, we refer to an ap-proach known as character-based statistical ma-chine translation.
It is shown to perform verywell for closely related languages (Vilar et al.,2007; Tiedemann, 2012; Tiedemann and Nakov,2013).
The motivation for character-level transla-tion is the ability of such models to better gener-alize the mapping between similar languages es-pecially in cases of rich productive morphologyand limited amounts of training data.
With this,character-level models largely reduce the num-ber of out-of-vocabulary words.
In a nutshell,our character-based model performs word-to-wordtranslation using character-level modeling.
Simi-lar to LOOKUP, this is also a word-to-word trans-lation model, which also requires no adaptation ofthe source dependency trees ?
they are once againsimply copied to target sentences.WORD: Our third take on SMT is slightly moreelaborate but still restricts the translation modelto one-to-one word mappings.
In particular, weextract all single word translation pairs from thephrase tables and apply the standard beam-searchdecoder implemented in Moses to translate theoriginal treebanks to all target languages.
Thus,we allow word reordering and use a languagemodel while still keeping the projection of anno-tated data as simple as possible.
The languagemodel may influence not only the word order butalso the lexical choice as we now allow multipletranslation options in our phrase table.
Also notethat this approach may introduce additional non-projectivity in the projected trees.
This systemis the overall top-performer in (Tiedemann et al.,18NcfsnVmip3sVmnAfpmpaNcmpaVladaplaniraotvoritiinformativneuredeVladanac?rtujeodprtjeinformacijskepisarneNcfsnVmip3sVmnAfpmpaNcmpaSbPredAtvAtrObjSbPredAtvAtrObjNcfsnVmip3sVmnAfpmpaNcmpaVladaplaniraotvoritiinformativneuredeVladanac?rtujeodprtjepisarneinformativneNcfsnVmip3sVmnAfpmpaNcmpaSbPredAtvAtrObjSbPredAtvAtrObjNcfsnVmip3sVmnAfpmpaNcmpaVladaplaniraotvoritiinformativneuredeVladanac?rtuje,daboodprlaDUMMYinformacijskepisarneNcfsnVmip3s--dummydummydummyVmnAfpmpaNcmpaSbPredPredAtvObjSbPredAtvdummydummydummyObjAtrFigure 3: An illustration of the projections.
Left side = CHAR, middle = WORD, right side = PHRASE.
Asillustrated, WORD might introduce reorderings, while PHRASE can enter dummy nodes and edges to thedependency trees.
The sentence: The government plans to open information offices.
See (Tiedemann etal., 2014; Tiedemann, 2014) for detailed insight into projection algorithms.2014), where reordering played an important rolein adapting the models to the target languages.
Wetest whether it holds for related languages as well.PHRASE: This model implements translationbased on the entire phrase table using the standardapproach to phrase-based SMT.
We basically runthe Moses decoder with default settings and theparameters and models trained on our parallel cor-pus.
Here, we can have many-to-many word align-ments, which require a more elaborate approach tothe projection of the source side dependency an-notatio s. It is important for the annotation trans-fer to keep track of the alignment between phrasesand words of the input and output sentences.
TheMoses decoder provides both, phrase seg enta-tion and word alignment.
We use the annotationprojection algorithm of Hwa et al.
(2005).
Asillustrated in Figure 3, it resolves many-to-manyalignments by introducing dummy nodes to thedependency trees.
We use the implementation byTiedemann (2014), which addresses certain issueswith algorithm choices for ambiguous alignmentswhich were left unaccounted for in the originalwork.
Since this paper does not focus on the intri-cacies of annotation projection, but rather on ap-plying it in an environment of related languagesand rich MSD tagsets, we refer the reader to re-lated work regarding the details.We translate from Croatian to Slovene and viceversa using four different treebanks and thesefour different methods of translation and annota-tion projection.
As we stated in the experimentoverview, for each of these, we also experimentwith (de)lexicalization and MSD vs. POS, and wetest on all three languages.
The three experimentalbatches ?
monolingual, direct and SMT-supportedtransfer ?
produce a large number of observations,all of which we assess in the following section.4 Results and DiscussionWe split our discussion of the parsing results intothe following three subsections.
We first observethe performance of monolingual parsers.
Sec-ondly, we measure the quality of these when ap-plied directly on the other two languages.
Finally,we look into the accuracy of parsers trained onSMT-generated artificial treebank data when ap-plied across the test languages.4.1 Monolingual ParsingAccuracies of parsers trained and applied on train-ing and testing data belonging to the same lan-guage ?
i.e., our monolingual parsers ?
are pro-vided in the g ayed out sections of Table 3.Parsing Croatian using hr PDT yields a highscore of 69.45 LAS, better than the former stateof the art on this test set (Agi?c et al., 2013) simplydue to applying a newer generation parser.
Thisscore is provided by a lexicalized model with thefull MSD feature set.
Replacing MSD with POS ordelexicalizing this model results in a 3-point dropin LAS, while applying both replacements sub-stantially decreases the score ?
by more than 11points LAS.
We observe virtually the same patternfor the other Croatian treebank, hr SET, where thislatter drop is even more significant, at 14 points.Incidentally, 76.36 points LAS is also the newstate of the art for hr SET parsing, owing to therecent enlargement of the treebank.The Slovene parsers exhibit effectively the samebehavior as the Croatian ones.
The lexicalizedMSD models of sl PDT and sl SSJ both record newstate-of-the-art scores, although the latter one on adifferent test set than in previous research (Dobro-voljc et al., 2012).
At over 92 points LAS, sl SSJ19lexicalized delexicalizedhr sl sr hr sl srMSD POS MSD POS MSD POS MSD POS MSD POS MSD POShr PDT 69.45 66.95 60.09 50.19 69.42 66.96 66.03 57.79 57.98 42.66 66.79 57.41SET 76.36 73.02 68.65 59.52 76.08 73.37 72.52 62.31 68.16 55.17 72.71 62.04sl PDT 51.19 47.99 76.46 73.33 52.46 49.64 49.58 42.59 71.96 62.99 50.41 44.11SSJ 78.50 74.18 92.38 88.93 78.94 75.96 75.23 66.23 87.19 77.92 75.25 67.47Table 3: Monolingual and direct cross-lingual parsing accuracy, expressed by the labeled accuracy metric(LAS).
Scores are split for lexicalized and delexicalized, full MSD and POS only parsers.
Monolingualscores are in grey.
Row indices represent source languages and treebanks.expectedly shows to be the easiest to parse, mostlikely due to the relatively flat tree structure and itssmall label set.We note the following general pattern of fea-ture importance.
Dropping MSD features seemsto carry the most weight in all models, followedby lexicalization.
Dropping MSD is compensatedin part by lexical features paired with POS, whiledropping both MSD and word forms severely de-grades all models.
At this point, it is very impor-tant to note that at 60-70 points LAS, these de-creased scores closely resemble those of McDon-ald et al.
(2013) for the six languages in the Uni-versal Treebanks.
This observation is taken furtherin the next subsection.4.2 Direct Cross-lingual ParsingThe models used for monolingual parsing are heredirectly applied on all languages but the treebanksource language, thus constituting a direct cross-lingual parsing scenario.
Its scores are also givenin Table 3, but now in the non-grey parts.Croatian models are applied to Slovene and Ser-bian test sets.
For hr PDT, the highest score is60.09 LAS on Slovene and 69.42 LAS on Serbian,the latter noted as the state of the art for SerbianPDT parsing.
Comparing the cross-lingual score tomonolingual Slovene, the difference is substantialas expected and comparable to the drops observedby McDonald et al.
(2013) in their experiments.Our ranking of feature significance established inthe monolingual experiments holds here as well,or rather, the absolute differences are even morepronounced.
Most notably, the difference betweenthe lexicalized MSD model and the delexicalizedPOS model is 17 points LAS in favor of the for-mer one on Slovene.
hr SET appears to be moreresilient to delexicalization and tagset reductionwhen applied on Slovene and Serbian, most likelydue to the treebank?s size, well-balanced depen-dency label set and closer conformance with theofficial MTE 4 guidelines.
That said, the featurepatterns still hold.
Also, 76.08 LAS for Serbian isthe new state of the art for SET parsing.Slovene PDT is an outlier due to its small size,as its training set is just over 1,500 sentences.
Still,the scores maintain the level of those in relatedresearch, and the feature rankings hold.
Perfor-mance of parsing Croatian and Serbian using slSSJ is high, arguably up to the level of usabilityin down-stream applications.
These are the firstrecorded scores in parsing the two languages us-ing SSJ, and they reach above 78 points LAS forboth.
Even if the scores are not comparable acrossthe annotation schemes due to their differences, itstill holds that the SSJ scores are the highest ab-solute parsing scores recorded in the experiment.This might hold significance in applications thatrequire robust parsing for shallow syntax.Generally, the best transfer scores are quitehigh in comparison with those on Universal Tree-banks (McDonald et al., 2013; Tiedemann et al.,2014).
This is surely due to the relatedness ofthe three languages.
However, even for these ar-guably closely related languages, the performanceof delexicalized models that rely only on POS fea-tures ?
averaging at around 55 points LAS ?
is vir-tually identical to that on more distant languagestest-cased in related work.
We see this as a verystrong indicator of fundamental limitations of us-ing linguistically impoverished shared feature rep-resentations in cross-lingual parsing.4.3 Cross-lingual Parsing with TreebankTranslationFinally, we discuss what happens to parsing per-formance when we replace direct cross-lingual ap-plication of parsers with training models on trans-lated treebanks.
We take a treebank, Croatian orSlovene, and translate it into the other language.20Target Approach PDT SET SSJhr monolingual 69.45 76.36 ?direct 51.19 ?
78.50translated 67.55 ?
74.68 ?
79.51 ?sl monolingual 76.46 ?
92.38direct 60.09 68.65 ?translated 72.35 ?
70.52 ?
88.71 ?sr monolingual ?
?
?direct 69.42 76.08 78.94translated 68.11 ?
74.31 ?
79.81 ?
?Legend: ?
CHAR ?
LOOKUP ?
PHRASE ?
WORDTable 4: Parsing score (LAS) summary for the top-performing systems with respect to language andapproach to parser induction.
All models are MSD+ lexicalized.We then train a parser on the translation and ap-ply it on all three target test sets.
We do this for allthe treebanks, and in all variations regarding trans-lation and projection methods, morphological fea-tures and lexicalization.All scores for this evaluation stage are given inTable 5 for completeness.
The table contains 192different LAS scores, possibly constituting a te-dious read.
Thus, in Table 4 we provide a sum-mary of information on the top-performing parsersfrom all three experimental stages, which includestreebank translation.We can see that the best models based ontranslating the treebanks predominantly stem fromword-to-word SMT, i.e., from WORD transla-tion models that basically enrich the lexical fea-ture space and perform word reordering, enablingstraightforward copying of syntactic structuresfrom translation sources to translation targets.
Fol-lowing them are the CHAR and LOOKUP models,expectedly leaving ?
although not too far behind?
PHRASE behind given the similarities of the lan-guage pair.
Since Croatian and Slovene are relatedlanguages, the differences between the models arenot as substantial as in (Tiedemann et al., 2014),but WORD models still turn out to be the most ro-bust ones, even if word reordering might not be sofrequent in this language pair as in the data from(McDonald et al., 2013).
Further, when compar-ing the best SMT-supported models to monolin-gual parsers, we see that the models with trans-lation come really close to monolingual perfor-mance.
In comparison with direct transfer, modelstrained on translated treebanks manage to outper-form them in most cases, especially for the moredistant language pairs.
For example, the sl ?
hrSSJ WORD model is 1 point LAS better on Croat-ian than the directly applied Slovene model, andthe same holds for testing on Serbian with thesame dataset.
On the other side, directly appliedmodels from Croatian SET outperform the trans-lated ones for Serbian.
For PDT, the translatedmodels are substantially better between Croatianand Slovene since sl PDT is an outlier in termsof size and dataset selection, while direct trans-fer from Croatian seems to work better for Serbianthan the translated models.Reflecting on the summary in Table 4 moregenerally, by and large, we see high parsing ac-curacies.
Averages across the formalisms reachwell beyond 70 points LAS.
We attribute this tothe relatedness of the languages selected for thiscase study, as well as to the quality of the un-derlying language resources.
From another view-point, the table clearly shows the prominence oflexical and especially rich morphosyntactic tagsetfeatures throughout the experiment.
Across ourmonolingual, direct and SMT-supported parsingexperiments, these features are represented in thebest systems, and dropping them incurs significantdecreases in accuracy.5 Conclusions and Future WorkIn this contribution, we addressed the topic ofcross-lingual dependency parsing, i.e., applyingdependency parsers from typically resource-richsource languages to under-resourced target lan-guages.
We used three Slavic languages ?
Croat-ian, Slovene and Serbian ?
as a test case for relatedlanguages in different stages of language resourcedevelopment.
As these are relatively free-word-order languages with rich morphology, we wereable to test the cross-lingual parsers for perfor-mance when using training features drawing fromlarge morphosyntactic tagsets ?
typically consist-ing of over 1,000 different tags ?
in contrast toimpoverished common part-of-speech representa-tions.
We tested monolingual parsing, direct cross-lingual parsing and a very recent promising ap-proach with artificial creation of training data viamachine translation.
In the experiments, we ob-served state-of-the-art results in dependency pars-ing for all three languages.
We strongly arguedand supported the case for using common rich rep-resentations of morphology in dependency parsing21lexicalized delexicalizedhr sl sr hr sl srMSD POS MSD POS MSD POS MSD POS MSD POS MSD POSCHAR hr ?
sl PDT 66.92 60.25 61.49 55.57 67.83 62.04 66.56 57.63 58.34 43.04 66.89 57.65SET 73.65 64.64 70.52 66.11 72.95 64.44 72.98 62.98 69.03 54.81 72.74 62.73sl ?
hr PDT 51.96 48.14 72.35 63.71 53.11 49.47 49.58 42.59 71.96 62.99 50.41 44.11SSJ 78.69 75.45 88.21 78.88 79.25 77.09 75.23 66.23 87.19 77.92 75.25 67.47LOOKUP hr ?
sl PDT 67.55 59.96 60.81 56.54 67.78 61.41 66.56 57.63 58.34 43.04 66.89 57.65SET 73.58 64.98 69.93 68.09 73.70 64.25 72.52 62.72 68.47 55.27 72.71 62.73sl ?
hr PDT 51.74 49.15 72.02 63.08 53.49 51.33 49.58 42.59 71.96 62.99 50.41 44.11SSJ 79.25 77.06 88.10 78.53 79.81 77.23 75.23 66.23 87.19 77.92 75.25 67.47WORD hr ?
sl PDT 67.33 59.24 61.80 57.14 68.11 61.13 65.84 57.12 58.17 42.99 67.12 57.70SET 73.26 65.87 69.98 68.98 73.63 65.85 72.71 62.29 68.50 55.06 73.14 62.40sl ?
hr PDT 51.67 49.58 71.47 63.51 54.62 51.82 50.25 43.17 71.27 62.79 50.79 44.07SSJ 79.51 76.89 88.71 79.69 79.81 78.03 75.95 67.19 86.92 77.28 75.89 68.18PHRASE hr ?
sl PDT 67.28 58.90 60.53 56.79 67.92 61.36 65.77 55.06 58.18 45.41 66.16 55.79SET 74.68 65.29 69.42 68.55 74.31 65.17 73.36 60.77 68.16 58.42 72.15 61.55sl ?
hr PDT 49.92 46.82 68.18 58.18 52.15 49.42 47.73 41.08 68.51 55.29 48.93 42.59SSJ 79.29 78.09 88.24 78.75 79.32 78.85 75.33 68.10 86.59 75.66 75.91 68.67Table 5: Parsing scores (LAS) for cross-lingual parsers trained on translated treebanks.
Scores aresplit for lexicalized and delexicalized, full MSD and POS only parsers, and with respect to the trans-lation/projection approaches.
Row indices represent source languages and treebanks, and indicate thedirection of applying SMT (e.g., hr ?
sl denotes a Croatian treebank translated to Slovene).for morphologically rich languages.
Through ourmultilayered test set annotation, we also facilitateda reliable cross-lingual evaluation in a heteroge-nous testing environment.
We list our most impor-tant observations:?
Even for closely related languages, using onlythe basic POS features ?
which are virtuallyidentical to the widely-used Universal POS ofPetrov et al.
(2012) ?
substantially decreasesparsing accuracy up to the level comparable withresults of McDonald et al.
(2013) across the Uni-versal Treebanks language groups.?
Adding MSD features heavily influences all thescores in a positive way.
This has obvious im-plications for improving over McDonald et al.
(2013) on the Universal Treebanks dataset.?
Other than that, we show that it is possibleto cross-lingually parse Croatian, Serbian andSlovene using all three syntactic annotationschemes, and with high accuracy.
A treebank forSerbian does not exist, but we accurately parseSerbian by using PDT, SET and SSJ-style annota-tions.
We parse Croatian using SSJ (transferredfrom Slovene) and Slovene using SSJ (trans-ferred from Croatian).
This clearly indicates thepossibilities of uniform downstream pipeliningfor any of the schemes.?
We show clear benefits of using the SMT ap-proach for transferring SSJ parsers to Croatianand SET parsers to Slovene.
We observe thesebenefits regardless of the low-quality, out-of-domain SMT training data (OpenSubs).Given the current interest for cross-lingual depen-dency parsing in the natural language processingcommunity, we will seek to further test our obser-vations on shared morphological features by us-ing other pairs of languages of varying relatedness,drawing from datasets such as Google UniversalTreebanks (McDonald et al., 2013) or HamleDT(Zeman et al., 2012; Rosa et al., 2014).
The goalof cross-lingual processing in general is to enableimproved general access to under-resourced lan-guages.
With this in mind, seeing how we intro-duced a test case of Serbian as a language cur-rently without a treebank, we hope to explore otheroptions for performing cross-lingual experimentson actual under-resourced languages, rather thanin an exclusive group of resource-rich placehold-ers, possibly by means of down-stream evaluation.Acknowledgments The second author was sup-ported by the Swedish Research Council (Veten-skapsr?adet), project 2012-916.
The fifth author isfunded by the EU FP7 STREP project XLike.22ReferencesAnne Abeill?e.
2003.
Treebanks: Building and UsingParsed Corpora.
Springer.
?Zeljko Agi?c and Nikola Ljube?si?c.
2014.
The SE-Times.HR Linguistically Annotated Corpus of Croa-tian.
In Proc.
LREC, pages 1724?1727.
?Zeljko Agi?c and Danijela Merkler.
2013.
ThreeSyntactic Formalisms for Data-Driven DependencyParsing of Croatian.
LNCS, 8082:560?567.
?Zeljko Agi?c, Danijela Merkler, and Da?sa Berovi?c.2012.
Slovene-Croatian Treebank Transfer UsingBilingual Lexicon Improves Croatian DependencyParsing.
In Proc.
IS-LTC, pages 5?9.
?Zeljko Agi?c, Danijela Merkler, and Da?sa Berovi?c.2013.
Parsing Croatian and Serbian by Using Croat-ian Dependency Treebanks.
In Proc.
SPMRL, pages22?33.
?Zeljko Agi?c, Da?sa Berovi?c, Danijela Merkler, andMarko Tadi?c.
2014.
Croatian Dependency Tree-bank 2.0: New Annotation Guidelines for ImprovedParsing.
In Proc.
LREC, pages 2313?2319.Emily Bender.
2011.
On achieving and evaluatinglanguage-independence in nlp.
Linguistic Issues inLanguage Technology, 6(3):1?26.Emily Bender.
2013.
Linguistic Fundamentals forNatural Language Processing: 100 Essentials fromMorphology and Syntax.
Morgan & Claypool Pub-lishers.Da?sa Berovi?c,?Zeljko Agi?c, and Marko Tadi?c.
2012.Croatian Dependency Treebank: Recent Develop-ment and Initial Experiments.
In Proc.
LREC, pages1902?1906.Alena B?ohmov?a, Jan Haji?c, Eva Haji?cov?a, and BarboraHladk?a.
2003.
The Prague Dependency Treebank.In Treebanks, pages 103?127.Bernd Bohnet and Jonas Kuhn.
2012.
The Best ofBoth Worlds ?
A Graph-based Completion Modelfor Transition-based Parsers.
In Proc.
EACL, pages77?87.Bernd Bohnet, Joakim Nivre, Igor Boguslavsky,Rich?ard Farkas, Filip Ginter, and Jan Hajic.
2013.Joint Morphological and Syntactic Analysis forRichly Inflected Languages.
TACL, 1:415?428.Bernd Bohnet.
2010.
Top Accuracy and Fast Depen-dency Parsing is not a Contradiction.
In Proc.
COL-ING, pages 89?97.Sabine Buchholz and Erwin Marsi.
2006.
CoNLL-XShared Task on Multilingual Dependency Parsing.In Proc.
CoNLL, pages 149?164.Marie-Catherine De Marneffe and Christopher D Man-ning.
2008.
The Stanford Typed Dependencies Rep-resentation.
In Proc.
COLING, pages 1?8.Kaja Dobrovoljc, Simon Krek, and Jan Rupnik.
2012.Skladenjski raz?clenjevalnik za sloven?s?cino.
In Proc.IS-LTC, pages 42?47.Greg Durrett, Adam Pauls, and Dan Klein.
2012.
Syn-tactic Transfer Using a Bilingual Lexicon.
In Proc.EMNLP-CoNLL, pages 1?11.Sa?so D?zeroski, Toma?z Erjavec, Nina Ledinek, Petr Pa-jas, Zdenek?Zabokrtsky, and Andreja?Zele.
2006.Towards a Slovene Dependency Treebank.
In Proc.LREC, pages 1388?1391.Toma?z Erjavec, Darja Fi?ser, Simon Krek, and NinaLedinek.
2010.
The JOS Linguistically Tagged Cor-pus of Slovene.
In Proc.
LREC, pages 1806?1809.Toma?z Erjavec.
2012.
MULTEXT-East: Morphosyn-tactic Resources for Central and Eastern EuropeanLanguages.
Language Resources and Evaluation,46(1):131?142.Kenneth Heafield.
2011.
KenLM: Faster and SmallerLanguage Model Queries.
In Proc.
WSMT, pages187?197.Rebecca Hwa, Philip Resnik, Amy Weinberg, ClaraCabezas, and Okan Kolak.
2005.
Bootstrap-ping Parsers via Syntactic Projection across ParallelTexts.
Natural Language Engineering, 11(3):311?325.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran,Richard Zens, et al.
2007.
Moses: Open SourceToolkit for Statistical Machine Translation.
In Proc.ACL, pages 177?180.Sandra K?ubler, Ryan McDonald, and Joakim Nivre.2009.
Dependency Parsing.
Morgan & ClaypoolPublishers.Ryan McDonald, Fernando Pereira, Kiril Ribarov, andJan Haji?c.
2005.
Non-projective Dependency Pars-ing Using Spanning Tree Algorithms.
In Proc.
HLT-EMNLP, pages 523?530.Ryan McDonald, Slav Petrov, and Keith Hall.
2011.Multi-Source Transfer of Delexicalized DependencyParsers.
In Proc.
EMNLP, pages 62?72.Ryan McDonald, Joakim Nivre, Yvonne Quirmbach-Brundage, Yoav Goldberg, Dipanjan Das, Kuz-man Ganchev, Keith Hall, Slav Petrov, HaoZhang, Oscar T?ackstr?om, Claudia Bedini, N?uriaBertomeu Castell?o, and Jungmee Lee.
2013.Universal Dependency Annotation for MultilingualParsing.
In Proc.
ACL, pages 92?97.Joakim Nivre, Johan Hall, Sandra K?ubler, Ryan Mc-Donald, Jens Nilsson, Sebastian Riedel, and DenizYuret.
2007.
The CoNLL 2007 Shared Task on De-pendency Parsing.
In Proc.
CoNLL, pages 915?932.23Franz Josef Och and Hermann Ney.
2003.
A System-atic Comparison of Various Statistical AlignmentModels.
Computational Linguistics, 29(1):19?51.Franz Josef Och.
2003.
Minimum Error Rate Trainingin Statistical Machine Translation.
In Proc.
ACL,pages 160?167.Slav Petrov, Dipanjan Das, and Ryan McDonald.
2012.A Universal Part-of-Speech Tagset.
In Proc.
LREC,pages 2089?2096.Vesna Po?zgaj Had?zi and Marko Tadi?c.
2000.
Croatian-Slovene Parallel Corpus.
In Proc.
IS-LTC.Rudolf Rosa, Jan Ma?sek, David Mare?cek, MartinPopel, Daniel Zeman, and Zden?ek?Zabokrtsk?y.2014.
HamleDT 2.0: Thirty Dependency TreebanksStanfordized.
In Proc.
LREC, pages 2334?2341.Djam?e Seddah, Reut Tsarfaty, Sandra K?ubler, MarieCandito, Jinho D. Choi, Rich?ard Farkas, Jen-nifer Foster, Iakes Goenaga, Koldo Gojenola Gal-letebeitia, Yoav Goldberg, Spence Green, NizarHabash, Marco Kuhlmann, Wolfgang Maier, JoakimNivre, Adam Przepi?orkowski, Ryan Roth, WolfgangSeeker, Yannick Versley, Veronika Vincze, MarcinWoli?nski, Alina Wr?oblewska, and Eric Villemontede la Clergerie.
2013.
Overview of the SPMRL2013 Shared Task: Cross-framework Evaluation ofParsing Morphologically Rich Languages.
In Proc.SPMRL, pages 146?182.Anders S?gaard.
2011.
Data Point Selection for Cross-language Adaptation of Dependency Parsers.
InProc.
ACL, pages 682?686.Oscar T?ackstr?om, Ryan McDonald, and Jakob Uszko-reit.
2012.
Cross-lingual Word Clusters for DirectTransfer of Linguistic Structure.
In Proc.
NAACL,pages 477?487.Oscar T?ackstr?om, Ryan McDonald, and Joakim Nivre.2013.
Target Language Adaptation of Discrimina-tive Transfer Parsers.
In Proc.
NAACL, pages 1061?1071.Marko Tadi?c and Sanja Fulgosi.
2003.
Building theCroatian Morphological Lexicon.
In Proc.
BSNLP,pages 41?46.Marko Tadi?c and Tam?as V?aradi.
2012.
Central andSouth-East European Resources in META-SHARE.Proc.
COLING, pages 431?438.Marko Tadi?c.
2007.
Building the Croatian Depen-dency Treebank: The Initial Stages.
Suvremenalingvistika, 63:85?92.J?org Tiedemann and Preslav Nakov.
2013.
Analyzingthe Use of Character-Level Translation with Sparseand Noisy Datasets.
In Proc.
RANLP, pages 676?684.J?org Tiedemann,?Zeljko Agi?c, and Joakim Nivre.
2014.Treebank Translation for Cross-Lingual Parser In-duction.
In Proc.
CoNLL, pages 130?140.J?org Tiedemann.
2009.
News from OPUS: A Collec-tion of Multilingual Parallel Corpora with Tools andInterfaces.
In Proc.
RANLP, volume 5, pages 237?248.J?org Tiedemann.
2012.
Character-Based Pivot Trans-lations for Under-Resourced Languages and Do-mains.
In Proc.
EACL, pages 141?151.J?org Tiedemann.
2014.
Rediscovering AnnotationProjection for Cross-Lingual Parser Induction.
InProc.
COLING.Erik F Tjong Kim Sang and Sabine Buchholz.
2000.Introduction to the CoNLL-2000 Shared Task:Chunking.
In Proc.
CoNLL, pages 127?132.Hans Uszkoreit and Georg Rehm.
2012.
LanguageWhite Paper Series.
Springer.David Vilar, Jan-Thorsten Peter, and Hermann Ney.2007.
Can We Translate Letters?
In Proc.
WMT,pages 33?39.David Yarowsky, Grace Ngai, and Richard Wicen-towski.
2001.
Inducing Multilingual Text Analy-sis Tools via Robust Projection Across Aligned Cor-pora.
In Proc.
HLT, pages 1?8.Daniel Zeman and Philip Resnik.
2008.
Cross-Language Parser Adaptation between Related Lan-guages.
In Proc.
IJCNLP, pages 35?42.Daniel Zeman, David Marecek, Martin Popel,Loganathan Ramasamy, Jan Step?anek, ZdenekZabokrtsk`y, and Jan Hajic.
2012.
HamleDT: ToParse or Not to Parse?
In Proc.
LREC, pages 2735?2741.24
