A Comparative Study of Language Models forBook and Author RecognitionO?zlem Uzuner and Boris KatzMIT,Computer Science and Artificial Intelligence Laboratory,Cambridge, MA 02139{ozlem, boris}@csail.mit.eduAbstract.
Linguistic information can help improve evaluation of simi-larity between documents; however, the kind of linguistic information tobe used depends on the task.
In this paper, we show that distributionsof syntactic structures capture the way works are written and accuratelyidentify individual books more than 76% of the time.
In comparison,baseline features, e.g., tfidf-weighted keywords, function words, etc., givean accuracy of at most 66%.
However, testing the same features on au-thorship attribution shows that distributions of syntactic structures areless successful than function words on this task; syntactic structures varyeven among the works of the same author whereas features such as func-tion words are distributed more similarly among the works of an authorand can more effectively capture authorship.1 IntroductionExpression is an abstract concept that we define as ?the way people conveyparticular content?.
Copyrights protect an author?s expression of content wherecontent refers to the information contained in a work and expression refers tothe linguistic choices of authors in presenting this content.
Therefore, capturingexpression is important for copyright infringement detection.In this paper, we evaluate syntactic elements of expression in two contexts:book recognition for copyright infringement detection and authorship attribu-tion.
Our first goal is to enable identification of individual books from theirexpression of content, even when they share content, and even when they arewritten by the same person.
For this purpose, we use a corpus that includestranslations of the same original work into English by different people.
For thepurposes of this study, we refer to the translations as books and an original workitself as a title.Given the syntactic elements of expression, our second goal is to test them onauthorship attribution, where the objective is to identify all works by a particu-lar author.
Our syntactic elements of expression capture differences in the waypeople express content and could be useful for authorship attribution.
However,the experiments we present here indicate that syntactic elements of expressionare more successful at identifying expression in individual books while functionwords are more successful at identifying authors.R.
Dale et al (Eds.
): IJCNLP 2005, LNAI 3651, pp.
969?980, 2005.c?
Springer-Verlag Berlin Heidelberg 2005970 O?.
Uzuner and B. Katz2 Related WorkIn text classification literature, similarity of works has been evaluated, for ex-ample, in terms of genre, e.g., novels vs. poems, in terms of the style of au-thors, e.g., Austen?s novels vs. Kipling?s novels, and in terms of topic, e.g., sto-ries about earthquakes vs. stories about volcanoes.
In this paper, we compareseveral different language models in two different classification tasks: book recog-nition based on similarity of expression, and authorship attribution.
Authorshipattribution has been studied in the literature; however, evaluation of similar-ity of expression, e.g., Verne?s 20000 Leagues vs. Flaubert?s Madame Bovary,is a novel task that we endeavor to address as a first step towards copyrightinfringement detection.We define expression as ?the linguistic choices of authors in presenting con-tent?
: content of works and the linguistic choices made while presenting it to-gether constitute expression.
Therefore, capturing expression requires measuringsimilarity of works in terms of both of these components.To classify documents based on their content, most approaches focus on key-words.
Keywords contain information regarding the ideas and facts presentedin documents and, despite being ambiguous in many contexts, have been heav-ily exploited to represent content.
In addition to keywords, subject?verb andverb?object relationships [12], noun phrases [12,13], synonym sets of words fromWordNet [12], semantic classes of verbs [12] from Levin?s studies [21], and propernouns have all been used to capture content.Linguistic choices of authors have been studied in stylometry for authorshipattribution.
Brinegar [7], Glover [9] and Mendenhall [22], among others, useddistribution of word lengths to identify authors, e.g., Glover and Hirst studieddistributions of two- and three-letter words [9].
Thisted et al [33] and Holmes [14]studied the idea of richness of vocabulary and the rate at which new words areintroduced to the text.
Many others experimented with distributions of sentencelengths [9,18,24,30,31,32,38,40], sequences of letters [17,20], and syntactic classes(part of speech) of words [9,20,19].Mosteller and Wallace [25] studied the distributions of function words toidentify the authors of 12 unattributed Federalist papers.
Using a subset of thefunction words from Mosteller and Wallace?s work, Peng [26] showed that verbs(used as function words, e.g., be, been, was, had) are important for differentiatingbetween authors.
Koppel et al [19] studied the ?stability?
of function words andshowed that the features that are most useful for capturing the style of authorsare ?unstable?, i.e., they can be replaced without changing the meaning of thetext.
Koppel et al?s measure of stability identified function words, tensed verbs,and some part-of-speech tag trigrams as unstable.Syntactically more-informed studies of the writings of authors came fromdiMarco and Wilkinson [39] who treated style as a means for achieving par-ticular communicative goals and used parsed text to study the syntactic ele-ments associated with each goal, e.g., clarity vs. obscurity.
Adapting elementsfrom Halliday and Hasan [10,11], diMarco et al studied the use of cohesive el-ements of text, e.g., anaphora and ellipsis, and disconnective elements of text,A Comparative Study of Language Models for Book and Author Recognition 971e.g., parenthetical constructions, as well as the patterns in the use of relativeclauses, noun embeddings, and hypotaxis (marked by subordinating conjunc-tions) when authors write with different communicative goals.Expression is related to both content and style.
However, it is important todifferentiate expression from style.
Style refers to the linguistic elements that,independently of content, persist over the works of an author and has been widelystudied in authorship attribution.
Expression involves the linguistic elementsthat relate to how an author phrases particular content and can be used toidentify potential copyright infringement.3 Syntactic Elements of ExpressionWe hypothesize that, given particular content, authors choose from a set ofsemantically equivalent syntactic constructs to create their own expression ofit.
As a result, different authors may choose to express the same content indifferent ways.
In this paper, we capture the differences in expression of authorsby studying [34,35,36]:?
sentence-initial and -final phrase structures that capture the shift in focusand emphasis of a sentence due to reordered material,?
semantic classes and argument structures of verbs such as those used inSTART for question answering [16] and those presented by Levin [21],?
syntactic classes of embedding verbs, i.e., verbs that take clausal arguments,such as those studied by Alexander and Kunz [1] and those used in STARTfor parsing and generation [15], and?
linguistic complexity of sentences, measured both in terms of depths ofphrases and in terms of depths of clauses, examples of which are shownin Table 1.Table 1.
Sample sentences broken down into their clauses and the depth of the top-level subject (the number on the left) and predicate (the number on the right)Sentence Depth ofClauses[I]a [would not think that [this]b [was possible]b]a 0, 2[I]a [have found [it]b [difficult to say that [I]c [like it]c]b] a.
2, 2[That [she]b [would give such a violent reaction]b]a [was unexpected]a.
1, 1[For [her]b [to see this note]b]a [is impossible]a.
1, 1[Wearing the blue shirt]a [was a good idea]a.
1, 1[It]a [is not known whether [he]b [actually libelled the queen]b]a.
0, 2[He]a [was shown that [the plan]b [was impractical]b ]a.
0, 2[They]a [believed [him]b [to be their only hope]b]a.
0, 2[I]a [suggest [he]b [go alone]b]a.
0, 2[I]a [waited for [John]b [to come]b]a.
0, 2972 O?.
Uzuner and B. KatzWe extracted all of these features from part-of-speech tagged text [5] andstudied their distributions in different works.
We also studied their correlationswith each other, e.g., semantic verb classes and the syntactic structure of thealternation [21] in which they occur.
The details of the relevant computationsare discussed by Uzuner [34].3.1 ValidationWe validated the syntactic elements of expression using the chi-square (and/orlikelihood ratio) test of independence.
More specifically, for each of sentence-initial and -final phrase structures, and semantic and syntactic verb classes, wetested the null hypothesis that these features are used similarly by all authorsand that the differences observed in different books are due to chance.
We per-formed chi-square tests in three different settings: on different translations ofthe same title (similar content but different expression), on different books bydifferent authors (different content and different expression), and on disjoint setsof chapters from the same book (similar content and similar expression).For almost all of the identified features, we were able to reject the null hy-pothesis when comparing books that contain different expression, indicating thatregardless of content, these features can capture expression.
For all of the fea-tures, we were unable to reject the null hypothesis when we compared chaptersfrom the same book, indicating a certain consistency in the distributions of thesefeatures throughout a work.4 EvaluationWe used the syntactic elements of expression, i.e., sentence-initial and sentence-final phrase structures, semantic and syntactic classes of verbs, and measures oflinguistic complexity [34,35,36], for book recognition and for authorship attribu-tion.4.1 Baseline FeaturesTo evaluate the syntactic elements of expression, we compared the performanceof these features to baseline features that capture content and baseline featuresthat capture the way works are written.
Our baseline features that capture con-tent included tfidf-weighted keywords [27,28] excluding proper nouns, becausefor copyright infringement purposes, proper nouns can easily be changed withoutchanging the content or expression of the documents and a classifier based onproper nouns would fail to recognize otherwise identical works.
Baseline featuresthat focus on the way people write included function words [25,26], distributionsof word lengths [22,40], distributions of sentence lengths [14], and a basic setof linguistic features, extracted from tokenized, part-of-speech tagged, and/orsyntactically parsed text.
This basic set of linguistic features included the num-ber of words and the number of sentences in the document; type?token ratio;A Comparative Study of Language Models for Book and Author Recognition 973average and standard deviation of the lengths of words (in characters) and ofthe lengths of sentences (in words) in the document; frequencies of declarativesentences, interrogatives, imperatives, and fragmental sentences; frequencies ofactive voice sentences, be-passives, and get-passives; frequencies of ?s-genitives,of-genitives, and of phrases that lack genitives; frequency of overt negations; andfrequency of uncertainty markers [9,34].4.2 Classification ExperimentsWe compared the syntactic elements of expression with the baseline featuresin two separate experiments: recognizing books even when some of them arederived from the same title (different translations) and recognizing authors.
Forthese experiments, we split books into chapters, created balanced sets of relevantclasses, and used boosted [29] decision trees [41] to classify chapters into booksand authors.
We tuned parameters on the training set: we determined that theperformance of classifiers stabilized at around 200 rounds of boosting and weeliminated from each feature set the features with zero information gain [8,37].Recognizing Books: Copyrights protect original expression of content for alimited time period.
After the copyright period of a work, its derivatives bydifferent people are eligible for their own copyright and need to be recognizedfrom their unique expression of content.
Our experiment on book recognitionfocused on and addressed this scenario.Data: For this experiment, we used a corpus that included 49 books derived from45 titles ; for 3 of the titles, the corpus included multiple books (3 books for thetitle Madame Bovary, 2 books for 20000 Leagues, and 2 books for The KreutzerSonata).
The remaining titles included works from J. Austen, F. Dostoyevski,C.
Dickens, A. Doyle, G. Eliot, G. Flaubert, T. Hardy, I. Turgenev, V. Hugo,W.
Irving, J. London, W. M. Thackeray, L. Tolstoy, M. Twain, and J. Verne.We obtained 40?50 chapters from each book (including each of the books thatare derived from the same title), and used 60% of the chapters from each bookfor training and the remaining 40% for testing.Results: The results of this evaluation showed that the syntactic elements ofexpression accurately recognized books 76% of the time; they recognized eachof the paraphrased books 89% of the time (see right column in Table 2).
Ineither case, the syntactic elements of expression significantly outperformed allindividual baseline features (see Table 2).The syntactic elements of expression contain no semantic information; theyrecognize books from the way they are written.
The fact that these featurescan differentiate between translations of the same title implies that translatorsadd their own expression to works, even when their books are derived fromthe same title, and that the expressive elements chosen by each translator helpdifferentiate between books derived from the same title.Despite recognizing books more accurately than each of the individual base-line features, syntactic elements of expression on their own are less effective974 O?.
Uzuner and B. KatzTable 2.
Classification results on the test set for recognizing books from their expres-sion of content even when some books contain similar contentFeature Set Accuracy on complete Accuracy oncorpus paraphrases onlySyntactic elements of expression 76% 89%Tfidf-weighted keywords 66% 88%Function words 61% 81%Baseline linguistic 42% 53%Dist.
of word length 29% 72%Dist.
of sentence length 13% 14%than the combined baseline features in recognizing books; the combined baselinefeatures give an accuracy of 88% on recognizing books (compare this to 76%accuracy by the syntactic elements of expression alone).
But the performance ofthe combined baseline features is further improved by the addition of syntacticelements of expression (see Table 3).
This improvement is statistically significantat ?
= 0.05.Table 3.
Classification results of combined feature sets on the test set for book recog-nition even when some books contain similar contentFeature Set Accuracy on complete Accuracy oncorpus paraphrases onlyAll baseline features +syntactic elements of expression 92% 98%All baseline features 88% 97%Ranking the combined features based on information gain for recognizingbooksshows that the syntactic elements of expression indeed play a significant role in rec-ognizing books accurately; of the top tenmost useful features identifiedby informa-tion gain, seven are syntactic elements of expression (see rows in italics in Table 4).In the absence of syntactic elements of expression, the top ten most usefulfeatures identified by information gain from the complete set of baseline featuresreveal that the keywords ?captain?
and ?sister?
are identified as highly discrim-inative features.
Similarly, the function words ?she?, ?her?, and ??ll?
are highlydiscriminative (see Table 5).
Part of the predictive power of these features is dueto the distinct contents of most of the books in this corpus; we expect that asthe corpus grows, these words will lose predictive power.Recognizing Authors: In Section 2, we described the difference between styleand expression.
These concepts, though different, both relate to the way peoplewrite.
Then, an interesting question to answer is: Can the same set of featureshelp recognize both books (from their unique expression) and authors (from theirunique style)?A Comparative Study of Language Models for Book and Author Recognition 975Table 4.
Top ten features identified by information gain for recognizing books evenwhen some books share content.
Features which are syntactic elements of expressionare in italics; baseline features are in roman.FeaturesStd.
dev.
of the depths of the top-level left branches (measured in phrase depth)Std.
dev.
of the depths of the top-level right branches (measured in phrase depth)Std.
dev.
of the depths of the deepest prepositional phrases of sentences(measured in phrase depth)% of words that are one character longAverage word length% of sentences that contain unembedded verbs% of sentences that contain an unembedded verb with noun phrase object (0-V-NP)Frequency of the word ?the?
(normalized by chapter length)Avg.
depth of the subordinating clauses at the beginning of sentences(measured in phrase depth)% of sentences that contain equal numbers of clauses in left and right branchType-token ratioTable 5.
Top ten baseline features identified by information gain that recognize bookseven when some books share contentFeatures% words that are one character longAverage word lengthFrequency of the word ?the?
(normalized by chapter length)Type-token ratioFrequency of the word ?captain?
(tfidf-weighted)Probability of NegationsFrequency of the word ?sister?
(tfidf-weighted)Frequency of the word ?she?
(normalized by chapter length)Frequency of the word ?her?
(normalized by chapter length)Frequency of the word ??ll?
(normalized by chapter length)Data: In order to answer this question, we experimented with a corpus of booksthat were written by native speakers of English.
This corpus included works fromeight authors: three titles by W. Irving, four titles by G. Eliot, five titles by J.Austen, six titles by each of C. Dickens and T. Hardy, eight titles by M. Twain,and nine titles by each of J. London and W. M. Thackeray.Results: To evaluate the different sets of features on recognizing authors fromtheir style, we trained models on a subset of the titles by each of these authorsand tested on a different subset of titles by the same authors.
We repeated thisexperiment five times so that several different sets of titles were trained and testedon.
At each iteration, we used 150 chapters from each of the authors for trainingand 40 chapters from each of the authors for testing.976 O?.
Uzuner and B. KatzTable 6.
Results for authorship attribution.
Classifier is trained on 150 chapters fromeach author and tested on 40 chapters from each author.
The chapters in the trainingand test sets come from different titles.Feature Set AccuracyAccuracyAccuracyAccuracyAccuracyRun 1 Run 2 Run 3 Run 4 Run 5Function words 86% 89% 87% 90% 81%Syntactic elements of expression 64% 63% 64% 55% 62%Distribution of word length 33% 37% 44% 53% 35%Baseline linguistic 39% 39% 41% 48% 28%Distribution of sentence length 33% 41% 31% 41% 25%Table 7.
Average classification results on authorship attributionFeature Set Avg.
AccuracyFunction words 87%Syntactic elements of expression 62%Distribution of word length 40%Baseline linguistic 39%Distribution of sentence length 34%The results in Table 7 show that function words capture the style of authorsbetter than any of the other features; syntactic elements of expression are not aseffective as function words in capturing the style of authors.
This finding is consis-tent with our intuition: we selected the syntactic elements of expression for theirability to differentiate between individual works, even when some titles are writtenby the same author and even when some books were derived from the same title.Recognizing the style of an author requires focus on the elements that are similar inthe works written by the same author, instead of focus on elements that differenti-ate these works.
However, the syntactic elements of expression are not completelydevoid of any style information: they recognize authors accurately 62%of the time.In comparison, the function words recognize authors accurately 87% of the time.Top ten most predictive function words identified by information gain for author-ship attribution are: the, not, of, she, very, be, her, ?s, and, and it.Combining the baseline features together does not improve the performance offunction words on authorship attribution: function words give an accuracy of 87%by themselves whereas the combined baseline features give an accuracy of 86%.1Adding the syntactic elements of expression to the combination of baseline featureshurts performance (see Table 8).We believe that the size of the corpus is an important factor in this conclu-sion.
More specifically, we expect that as more authors are added to the corpus,the contribution of syntactic elements of expression to authorship attribution willincrease.
To test this hypothesis, we repeated our experiments with up to thir-teen authors.
We observed that the syntactic elements of expression improved the1 This difference is not statistically significant.A Comparative Study of Language Models for Book and Author Recognition 977Table8.Average classification results of combined feature sets on authorship attributionFeature Set Average Accuracy for 8 AuthorsAll baseline features +syntactic elements of expression 81%All baseline features 86%Function words 87%Syntactic elementsof expression 62%Table 9.
Average classification results of combined feature sets on authorship attribu-tion.
For these experiments, the original corpus was supplemented with works from W.Ainsworth, L. M. Alcott, T. Arthur, M. Braddon, and H. James.Feature Set Average Accuracy for 8-13 Authors8 9 10 11 12 13All baseline features +syntactic elements of expression 81% 88% 88.4% 87.6% 88% 88%All baseline features 86% 86% 87.8% 86.6% 86% 86.8%Function words 87% 86.4% 85.4% 85.2% 84.8% 82.6%Syntactic elementsof expression 62% 65.6% 68.2% 67.4% 66% 64.4%performance of the baseline features: as we added more authors to the corpus, theperformance of function words degraded, the performance of syntactic elements ofexpression improved, and the performance of the combined feature set remainedfairly consistent at around 88% (see Table 9).4.3 ConclusionIn this paper, we compared several different language models on two classifica-tion tasks: book recognition and authorship attribution.
In particular, we evalu-ated syntactic elements of expression consisting of sentence-initial and -final phrasestructures, semantic and syntactic categories of verbs, and linguistic complexitymeasures, on recognizing books (even when they are derived from the same title)and on recognizing authors.
Through experiments on a corpus of novels, we haveshown that syntactic elements of expression outperform all individual baseline fea-tures in recognizing books and when combined with the baseline features, they im-prove recognition of books.In our authorship attribution experiments, we have shown that the syntacticelements of expression are not as useful as function words in recognizing the style978 O?.
Uzuner and B. Katzof authors.
This finding highlights the need for a task-dependent approach to en-gineering feature sets for text classification.
In our experiments, feature sets thathave been engineered for studying expression and the language models based onthese feature sets outperform all others in identifying expression.
Similarly, featuresets that have been engineered for studying style and the language models basedon these feature sets outperform syntactic elements of expression in authorshipattribution.References1.
D. Alexander and W. J. Kunz.
SomeClasses of Verbs inEnglish.
Linguistics ResearchProject.
Indiana University, 1964.2.
J. C. Baker.
A Test of Authorship Based on the Rate at which New Words Enter anAuthor?s Text.
Journal of the Association for Literary and Linguistic Computing,3(1), 36?39, 1988.3.
D. Biber.
A Typology of English Texts.
Language, 27, 3?43, 1989.4.
D. Biber, S. Conrad, and R. Reppen.
Corpus Linguistics: Investigating LanguageStructure and Use.
Cambridge University Press, 1998.5.
E. Brill.
A Simple Rule-Based Part of Speech Tagger.
Proceedings of the 3rd Con-ference on Applied Natural Language Processing, 1992.6.
M. Diab, J. Schuster, and P. Bock.
A Preliminary Statistical Investigation into theImpact of an N-GramAnalysisApproach based onWordSyntacticCategories towardText Author Classification.
In Proceedings of Sixth International Conference onArtificial Intelligence Applications, 1998.7.
C. S. Brinegar.
Mark Twain and the QuintusCurtius Snodgrass Letters: A StatisticalTest of Authorship.
Journal of the American Statistical Association, 58, 85?96, 1963.8.
G. Forman.
An Extensive Empirical Study of Feature Selection Metrics for TextClassification.
Journal of Machine Learning Research, 3, 1289?1305, 2003.9.
A. Glover and G. Hirst.
Detecting stylistic inconsistencies in collaborative writing.
InSharples, Mike and van derGeest, Thea (eds.
), The new writing environment: Writersat work in a world of technology.
London: Springer-Verlag, 1996.10.
M. Halliday and R. Hasan.
Cohesion in English.
London: Longman, 1976.11.
M. Halliday.
An introduction to functional grammar.
London; Baltimore, Md., USA: Edward Arnold, 1985.12.
V. Hatzivassiloglou, J. Klavans, and E. Eskin.
Detecting Similarity by ApplyingLearning over Indicators.
37th Annual Meeting of the ACL, 1999.13.
V. Hatzivassiloglou, J. Klavans, M. Holcombe, R. Barzilay, M.Y.
Kan, andK.R.
McKeown.
SimFinder: A Flexible Clustering Tool for Summarization.NAACL?01 Automatic Summarization Workshop, 2001.14.
D. I. Holmes.
Authorship Attribution.
Computers and the Humanities, 28, 87?106.Kluwer Academic Publishers, Netherlands, 1994.15.
B. Katz.
Using English for Indexing and Retrieving.
Artificial Intelligence at MIT:Expanding Frontiers.
P. H. Winston and S. A. Shellard, eds.
MIT Press.
Cambridge,MA., 1990.16.
B. Katz andB.
Levin.
ExploitingLexical Regularities in Designing Natural LanguageSystems.
In Proceedings of the 12th International Conference on Computational Lin-guistics, COLING ?88, 1988.17.
D. Khmelev and F. Tweedie.
Using Markov Chains for Identification of Writers.Literary and Linguistic Computing, 16(4), 299?307, 2001.A Comparative Study of Language Models for Book and Author Recognition 97918.
G. Kjetsaa.
The Authorship of the Quiet Don.
ISBN 0391029487. International Spe-cialized Book Service Inc., 1984.19.
M. Koppel, N. Akiva, and I. Dagan.
A Corpus-Independent Feature Set for Style-Based Text Categorization.
Proceedings of IJCAI?03 Workshop on ComputationalApproaches to Style Analysis and Synthesis, 2003.20.
O. V. Kukushkina, A.
A. Polikarpov, and D. V. Khemelev.
Using Literal and Gram-matical Statistics for Authorship Attribution.
Published in Problemy Peredachi In-formatsii,37(2), April-June 2000, 96?108.
Translated in ?Problems of InformationTransmission?, 172?184.21.
B. Levin.
English Verb Classes and Alternations.
A Preliminary Investigation.
ISBN0-226-47533-6.
University of Chicago Press.
Chicago, 1993.22.
T. C. Mendenhall.
Characteristic Curves of Composition.
Science, 11, 237?249,1887.23.
G. A. Miller, E. B. Newman, and E. A.
Friedman.
: Length-Frequency Statistics forWritten English.
Information and Control,1(4), 370?389, 1958.24.
A. Q. Morton.
The Authorship of Greek Prose.
Journal of the Royal StatisticalSociety (A), 128, 169?233, 1965.25.
F. Mosteller and D. L. Wallace.
Inference in an authorship Problem.
Journal of theAmerican Statistical Association, 58(302), 275?309, 1963.26.
R. D. Peng and H. Hengartner.
Quantitative Analysis of Literary Styles.
The Amer-ican Statistician, 56(3), 175?185, 2002.27.
G. Salton and C. Buckley.
Term-weighting approaches in automatic text retrieval.Information Processing and Management, 24(5), 513?523, 1998.28.
G. Salton, A. Wong, and C. S. Yang.
A vector space model for automatic indexing.Communications of the ACM, 18(11), 613?620, 1975.29.
R. E. Schapire.
The Boosting Approach to Machine Learning.
In MSRI Workshopon Nonlinear Estimation and Classification, 2002.30.
H. S. Sichel.
On a Distribution Representing Sentence-Length in Written Prose.Journal of the Royal Statistical Society (A), 137, 25?34, 1974.31.
M. W. A. Smith.
Recent Experience and New Developments of Methods for theDetermination of Authorship.
Association for Literary and Linguistic ComputingBulletin, 11, 73?82, 1983.32.
D. R. Tallentire.
An Appraisal of Methods and Models in Computational Stylistics,with Particular Reference to Author Attribution.
PhD Thesis.
University of Cam-bridge, 1972.33.
R. Thisted and B. Efron.
Did Shakespeare Write a Newly-discovered Poem?Biometrika, 74, 445?455, 1987.34.
O?.
Uzuner.
Identifying Expression Fingerprints using Linguistic Information.
Ph.D.Dissertation.
Massachusetts Institute of Technology, 2005.35.
O?.
Uzuner and B. Katz.
Capturing Expression Using Linguistic Information.
InProceedings of the 20th National Conference on Artificial Intelligence (AAAI-05),2005.36.
O?.
Uzuner, B. Katz and Thade Nahnsen.
Using Syntactic Information to IdentifyPlagiarism.
In Proceedings of the Association for Computational Linguistics Work-shop on Educational Applications (ACL 2005), 2005.37.
Y. Yang and J. O. Pedersen.
A Comparative Study on Feature Selection in Text Cat-egorization.
In Proceedings of ICML-97, 14th International Conference on MachineLearning.
412?420, 1997.980 O?.
Uzuner and B. Katz38.
G. U. Yule.
On Sentence-Length as a Statistical Characteristic of Style in Prose,with Application to Two Cases of Disputed Authorship.
Biometrika, 30, 363?390,1938.39.
J. Wilkinson and C. diMarco.
Automated Multi-purpose Text Processing.
In Pro-ceedings of IEEE Fifth Annual Dual-Use Technologies and Applications Conference,1995.40.
C. B. Williams.
Mendenhall?s Studies of Word-Length Distribution in the Works ofShakespeare and Bacon.
Biometrika, 62(1), 207?212, 1975.41.
I. H. Witten and E. Frank.
Data Mining: Practical machine Learning Tools withJava Implementations.
Morgan Kaufmann, San Francisco, 2000.
