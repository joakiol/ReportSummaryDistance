Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1613?1624,Seattle, Washington, USA, 18-21 October 2013. c?2013 Association for Computational LinguisticsA Study on Bootstrapping Bilingual Vector Spaces from Non-Parallel Data(and Nothing Else)Ivan Vulic?
and Marie-Francine MoensDepartment of Computer ScienceKU LeuvenCelestijnenlaan 200ALeuven, Belgium{ivan.vulic,marie-francine.moens}@cs.kuleuven.beAbstractWe present a new language pair agnostic ap-proach to inducing bilingual vector spacesfrom non-parallel data without any other re-source in a bootstrapping fashion.
The pa-per systematically introduces and describes allkey elements of the bootstrapping procedure:(1) starting point or seed lexicon, (2) the confi-dence estimation and selection of new dimen-sions of the space, and (3) convergence.
Wetest the quality of the induced bilingual vec-tor spaces, and analyze the influence of thedifferent components of the bootstrapping ap-proach in the task of bilingual lexicon extrac-tion (BLE) for two language pairs.
Results re-veal that, contrary to conclusions from priorwork, the seeding of the bootstrapping pro-cess has a heavy impact on the quality of thelearned lexicons.
We also show that our ap-proach outperforms the best performing fullycorpus-based BLE methods on these test sets.1 IntroductionBilingual lexicons serve as an indispensable sourceof knowledge for various cross-lingual tasks suchas cross-lingual information retrieval (Lavrenko etal., 2002; Levow et al 2005) or statistical machinetranslation (Och and Ney, 2003).
Additionally, theyare a crucial component in cross-lingual knowledgetransfer, where the knowledge about utterances inone language may be transferred to another.
Theutility of the transfer or annotation projection bymeans of bilingual lexicons has already been provenin various tasks such as semantic role labeling (Pado?and Lapata, 2009; van der Plas et al 2011), parsing(Zhao et al 2009; Durrett et al 2012; Ta?ckstro?m etal., 2013b), POS tagging (Yarowsky and Ngai, 2001;Das and Petrov, 2011; Ta?ckstro?m et al 2013a), etc.Techniques for automatic bilingual lexicon ex-traction (BLE) from parallel corpora on the basisof word alignment models are well established (Ochand Ney, 2003).
However, due to a relative scarce-ness of parallel data for many language pairs anddomains, alternative approaches that rely on compa-rable corpora have also gained much interest (e.g.,Fung and Yee (1998); Rapp (1999)).The models that rely on non-parallel data typ-ically represent each word by a high-dimensionalvector in a feature vector space, where the dimen-sions of the vector are its context features.
The con-text features are typically words co-occurring withthe word in a predefined context.1 The similar-ity of two words, wS1 given in the source languageLS with vocabulary V S and wT2 in the target lan-guage LT with vocabulary V T is then computed assim(wS1 , wT2 ) = SF (cv(wS1 ), cv(wT2 )).
cv(wS1 ) =[scS1 (c1), .
.
.
, scS1 (cN )] is a context vector for wS1with N context features ck, where scS1 (ck) denotesthe score for wS1 associated with context feature ck(similar for wT2 ).
SF is a similarity function (e.g.,cosine, the Kullback-Leibler divergence, the Jaccardindex) operating on the context vectors (Lee, 1999).When operating with 2 languages, the context fea-tures cannot be compared directly.
Therefore, inorder to compare the feature vectors cv(wS1 ) andcv(wT2 ), the context features need to span a shared1The context may be a document, a paragraph, a window ofpredefined size around each occurrence of wSi in CS , etc.
Foran overview, see, e.g., (Tamura et al 2012).1613bilingual vector space.
The standard way of build-ing a bilingual vector space is to use bilingual lex-icon entries (Rapp, 1999; Fung and Cheung, 2004;Gaussier et al 2004) as dimensions of the space.However, there seems to be an apparent flaw inlogic, since the methods assume that there existreadily available bilingual lexicons that are thenused to induce bilingual lexicons!
Therefore, the fo-cus of the researchers has turned to designing BLEmethods that do not rely on any external translationresources such as machine-readable bilingual lex-icons and parallel corpora (Haghighi et al 2008;Vulic?
et al 2011).In order to circumvent this issue, one line of re-cent work aims to bootstrap high-quality bilingualvector spaces from a small initial seed lexicon.
Theseed lexicon is constructed by harvesting identicalor similarly spelled words across languages (Koehnand Knight, 2002; Peirsman and Pado?, 2010), and itspans the initial bilingual vector space.
The space isthen gradually enriched with new dimensions/axesduring the bootstrapping procedure.
The bootstrap-ping process has already proven its validity in induc-ing bilingual lexicons for closely similar languagessuch as Spanish-Portuguese or Croatian-Slovene(Fis?er and Ljubes?ic?, 2011), but it still lacks furthergeneralization to more distant language pairs.The main goal of this paper is to shed new lighton the bootstrapping approaches to bilingual lexiconextraction, and to construct a language pair agnos-tic bootstrapping method that is able to build high-quality bilingual vector spaces that consequentlylead to high-quality bilingual lexicons for more dis-tant language pairs where orthographic similarity isnot sufficient to seed bilingual vector spaces.
Weaim to answer the following key questions:?
How to seed bilingual vector spaces besides us-ing only orthographically similar words??
Is it better to seed bilingual spaces with trans-lation pairs/dimensions that are frequent in thecorpus, and does the frequency matter at all?Does the size of the initial seed lexicon matter??
How to enrich bilingual vector spaces with onlyhighly reliable dimensions in order to preventsemantic drift?With respect to these questions, the main contribu-tions of this article are:?
We present a complete overview of the frame-work of bootstrapping bilingual vector spacesfrom non-parallel data without any additionalresources.
We dissect the bootstrapping pro-cess and describe all its key components.?
We introduce a new way of seeding the boot-strapping procedure that does not rely on anyorthographic clues and that yields bilingualvector spaces of higher quality.
We analyze theimpact of different seed lexicons on the qualityof induced bilingual vector spaces.?
We show that in the setting without any ex-ternal translation resources, our bootstrappingapproach yields lexicons that outperform thebest performing corpus-based BLE methods onstandard test datasets for 2 language pairs.2 Boostrapping Bilingual Vector Spaces: AGeneral OverviewThis section presents the complete bootstrappingprocedure that starts with an initial seed lexiconwhich spans the initial bilingual vector space, whileas the output in each iteration of the procedure it pro-duces an updated bilingual vector space that can beused to extract a bilingual lexicon.2.1 General FrameworkWe assume that we are solely in possession of a(non-parallel) bilingual corpus C that is composedof a sub-corpus CS given in the source language LS ,and a sub-corpus CT in the target language LT .
Allword types that occur in CS constitute a set V S .
Allword types in CT constitute a set V T .
The goal is tobuild a bilingual vector space using only corpus C.Assumption 1.
Dimensions of the bilingual vectorspace are one-to-one word translation pairs.
For in-stance, dimensions of a Spanish-English space arepairs like (perro, dog), (ciencia, science), etc.
Theone-to-one constraint (Melamed, 2000), althoughnot valid in general, simplifies the construction ofthe bootstrapping procedure.
Z denotes the set oftranslation pairs that are the dimensions of the space.Computing cross-lingual word similarity in abilingual vector space.
Now, assume that our bilin-gual vector space consists of N one-to-one wordtranslation pairs ck = (cSk , cTk ), k = 1, .
.
.
, N .
Foreach word wSi ?
V S , we compute the similarity of1614that word with each word wTj ?
V T by computingthe similarity between their context vectors cv(wSi )and cv(wTj ), which are actually their representationsin the N -dimensional bilingual vector space.The cross-lingual similarity is computed follow-ing the standard procedure (Gaussier et al 2004):(1) For each source word wSi ?
V S , build its N -dimensional context vector cv(wSi ) that consists ofassociation scores scSk (cSk ), that is, we compute thestrength of association with the ?source?
part of eachdimension ck that constitutes the N -dimensionalbilingual space.
The association is dependent on theco-occurrence of wSi and cSk in a predefined context.Various functions such as the log-likelihood ratio(LLR) (Rapp, 1999; Ismail and Manandhar, 2010),TF-IDF (Fung and Yee, 1998), or pointwise mu-tual information (PMI) (Bullinaria and Levy, 2007;Shezaf and Rappoport, 2010) are typically used asweighting functions to quantify the strength of theassociation.
(2) Repeat step (1) for each target word wTj ?
V Tand build context vectors cv(wTj ) that consist ofscores scTk (cTk ).
(3) Since cSk and cTk address the same dimensionck in the bilingual vector space for each k =1, .
.
.
, N , we are able to compute the similarity be-tween cv(wSi ) and cv(wTj ) using any similarity mea-sure such as the Jaccard index, the Kullback-Leibleror the Jensen-Shannon divergence, the cosine mea-sure, or others (Lee, 1999; Cha, 2007).The similarity score for two words wSi and wTjis sim(wSi , wTj ).
For each source word wSi , we canbuild a ranked listRL(wSi ) that consists of all wordswTj ?
V T ranked according to their respective sim-ilarity scores sim(wSi , wTj ).
In the similar fashion,we can build a ranked list RL(wTj ), for each targetword wTj .
We call the top scoring target word wTjfor some source word wSi its translation candidate,and write TC(wSi ) = wTj .
Additionally, we labelthe ranked list RL(wSi ) that is pruned at position Mas RLM (wSi ).Bootstrapping.
The key idea of the bootstrappingapproach relies on an insight that highly reliabletranslation pairs (wS1 , wT2 ) that are encountered us-ing the N -dimensional bilingual vector space mightbe added as new dimensions of the space.
By addingthese new dimensions, it might be possible to extractmore highly reliable translation pairs that were pre-viously not used as dimensions of the space, and theiterative procedure repeats until no new dimensionsare found.
The induced bilingual vector space maythen be observed as a bilingual lexicon per se, but itmay also be used to find translation equivalents forother words which are not used to span the space.Algorithm 1: Bootstrapping a bilingual vector spaceInput : Bilingual corpus C = CS ?
CTInitialize: (1) Obtain a one-to-one seed lexicon.
Theentries from the lexicon are initial dimensions of thespace: Z0; (2) s = 0;Bootstrap:repeat1: For each wSi ?
VS : compute RL(wSi ) using Zs ;2: For each wTj ?
VT : compute RL(wTj ) using Zs ;3: For each wSi ?
VS and wTj ?
VT : score eachtranslation pair (wSi , TC(wSi )) and (TC(wTj ), wTj )and add them to a pool of candidate dimensions ;4: Choose the best candidates from the pool and addthem as new dimensions: Zs+1 ?
Zs ?
{best} ;5: Resolve collisions in Zs+1;6: s?
s + 1 ;until no new dimensions are found (convergence) ;Output: One-to-one translation pairs?
Dimensions of abilingual vector space ZfinalThe overview of the procedure as given by alg.
1reveals these crucial points in the procedure: (Q1)how to provide initial dimensions of the space?
(theinitialization step), (Q2) how to score each trans-lation pair, estimate their confidence, and how tochoose the best candidates from the pool of candi-dates?
(steps 3 and 4), and (Q3) how to resolvepotential collisions that violate the one-to-one con-straint?
(step 5).
We will discuss (Q1) and (Q2) inmore detail later, while we resolve (Q3) following asimple heuristic as follows:Assumption 2.
In case of collision, dimen-sions/pairs that are found at later stages of the boot-strapping process overwrite previous dimensions.The intuition here is that we expect for the quality ofthe space to increase at each stage of the bootstrap-ping process, and newer translation pairs should bemore confident than the older ones.
For instance, if 2out of N dimensions of a Spanish-English bilingualspace are pairs (piedra,wall) and (tapia,stone), butthen if during the bootstrapping process we extract anew candidate pair (piedra,stone), we will delete theformer two dimensions and add the latter.16152.2 Initializing Bilingual Vector SpacesSeeding or initializing a bootstrapping procedure isoften a critical step regardless of the actual task(McIntosh and Curran, 2009; Kozareva and Hovy,2010), and it decides whether the complete processwill end as a success or a failure.
However, Peirsmanand Pado?
(2011) argue that the initialization step isnot crucial when dealing with bootstrapping bilin-gual vector spaces.
Here, we present two differentstrategies of initializing the bilingual vector space.Identical words and cognates.
Previous work re-lies exclusively on identical and similarly spelledwords to build the initial set of dimensions Z0(Koehn and Knight, 2002; Peirsman and Pado?, 2010;Fis?er and Ljubes?ic?, 2011).
This strategy yieldspromising results for closely similar language pairs,but is of limited use for other language pairs.High-frequency seeds.
Another problem with us-ing only identical words and cognates as seeds lies inthe fact that many of them might be infrequent in thecorpus, and as a consequence the expressiveness of abilingual vector space might be limited.
On the otherhand, high-frequency words offer a lot of evidencein the corpus that could be exploited in the boot-strapping approach.
In order to induce initial trans-lation pairs, we rely on the framework of multilin-gual probabilistic topic modeling (MuPTM) (Boyd-Graber and Blei, 2009; De Smet and Moens, 2009;Mimno et al 2009; Zhang et al 2010), that doesnot require a bilingual lexicon, it operates with non-parallel data, and is able to produce highly confidenttranslation pairs for high-frequency words (Mimnoet al 2009; Vulic?
and Moens, 2013).2 Therefore,we can construct the initial seed lexicon as follows:(1) Train a multilingual topic model on the corpus.
(2) Obtain one-to-one translation pairs using any ofthe MuPTM-based models of cross-lingual similar-ity, e.g., (Vulic?
et al 2011; Vulic?
and Moens, 2013).
(3) Retain only symmetric translation pairs.
Thisstep ensures that only highly confident pairs are usedas seed translation pairs.
(4) Rank translation pairs according to their fre-quency in the corpus and use a subset of the most2One can also use other models that are similar to MuPTMsuch as (Haghighi et al 2008; Daume?
III and Jagarlamudi,2011) to produce the initial seed lexicon, but that analysis isbeyond the scope of this work.frequent symmetric pairs as seeds.2.3 Estimating Confidence of New DimensionsAnother crucial step in the bootstrapping proce-dure is the estimation of confidence in a translationpair/candidate dimension.
Errors in the early stagesof the procedure may negatively affect the learningprocess and even cause semantic drift (Riloff andShepherd, 1999; McIntosh and Curran, 2009).
Wetherefore impose the constraint which requires trans-lation pairs to be symmetric in order to qualify as po-tential new dimensions of the space.
In other words,given the current set of dimensions Zs, a transla-tion pair (wSi , wTj ) has a possibility to be chosen asa new dimension from the pool of candidate dimen-sions if and only if it holds: TC(wSi ) = wTj andTC(wTj ) = wSi .
This symmetry constraint shouldensure a relative reliability of translation pairs.In each iteration of the bootstrapping process, wemay add all symmetric pairs from the pool of candi-dates as new dimensions, or we could impose addi-tional selection criteria that quantify the degree ofconfidence in translation pairs.
We are then ableto rank the symmetric candidate translation pairs inthe pool of candidates according to their confidencescores (step 3 of alg.
1), and choose only the bestB candidates from the pool in each iteration (step 4)as done in (Thelen and Riloff, 2002; McIntosh andCurran, 2009; Huang and Riloff, 2012).
By pickingonly a subset of the B most confident candidates ineach iteration, we hope to further prevent a possibil-ity of semantic drift, i.e., ?poisoning?
the bootstrap-ping process that might happen if we include incor-rect translation pairs as dimensions of the space.In this paper, we investigate 3 different confidenceestimation functions:3(1) Absolute similarity score.
Confidence of atranslation pair CF (wSi , TC(wSi )) is simply the ab-solute similarity value sim(wSi , TC(wSi ))(2) M-Best confidence function.
It contrasts thescore of the translation candidate with the averagescore over the first M most similar words in theranked list.
The larger the difference, the more con-fidence we have in the translation candidate.
Givena word wSi ?
V S and a ranked list RLM (wSi ), the3A symmetrized version of the confidence functions is com-puted as the geometric mean of source-to-target and target-to-source confidence scores.1616average score of the best M words is computed as:simM (wSi ) =1M?wTj ?RLM (wSi )sim(wSi , wTj )The final confidence score is then:CF (wSi , TC(wSi )) = sim(wSi , TC(wSi ))?
simM (wSi )(3) Entropy-based confidence function.
We adaptthe well-known entropy-based confidence (Smithand Eisner, 2007; Tu and Honavar, 2012) to this par-ticular task.
First, we need to define a distribution:p(wTj |wSi ) =esim(wSi ,wTj )?wTl ?VT esim(wSi ,wTl )The confidence function is then minus the entropyof the probability distribution p:CF (wSi , TC(wSi )) =?wTl ?V Tp(wTl |wSi ) log p(wTl |wSi )3 Experimental SetupData collections.
We investigate our bootstrappingapproach on the BLE task for 2 language pairs:Spanish-English (ES-EN) and Italian-English (IT-EN), and work with the following corpora previ-ously used by Vulic?
and Moens (2013): (i) a col-lection of 13, 696 Spanish-English Wikipedia arti-cle pairs (Wiki-ES-EN), (ii) 18, 898 Italian-EnglishWikipedia article pairs (Wiki-IT-EN).4Following (Koehn and Knight, 2002; Haghighi etal., 2008; Prochasson and Fung, 2011; Vulic?
andMoens, 2013), we use TreeTagger (Schmid, 1994)for POS-tagging and lemmatization of the corpora,and then retain only nouns that occur at least 5 timesin the corpus.
We record the lemmatized form whenavailable, and the original form otherwise.
Our fi-nal vocabularies consist of 9, 439 Spanish nouns and4Vulic?
and Moens (2013) also worked with Dutch-English(NL-EN), but we have decided to leave out the results obtainedfor that language pair due to space constraints, high similaritybetween the two languages, and the fact that the results obtainedfor that language pair are qualitatively similar to the results wereport for ES-EN and IT-EN.
Hence including the results forNL-EN would not contribute to the paper with any new impor-tant insight and conclusion.12, 945 nouns for ES-EN, and 7, 160 Italian nounsand 9, 116 English nouns for IT-EN.Ground truth.
The goal of the BLE task is to ex-tract a bilingual lexicon of one-to-one translations.In order to test the quality of bilingual vector spacesinduced by our bootstrapping approach, we evaluateit on standard 1000 ground truth one-to-one trans-lation pairs built for the Wiki-ES-EN and Wiki-IT-EN datasets (Vulic?
and Moens, 2013).
Note thatwe do not explicitly test the bilingual vector spaceas a bilingual lexicon, but rather its ability to findsemantically similar words and translations also forwords that are not used as dimensions of the space(see sect.
2.1).Evaluation metrics.
We measure the performanceon the BLE task using a standard Top M accuracy(AccM ) metric.
It denotes the number of sourcewords wSi from ground truth translation pairs whoselist RLM (wSi ) contains the correct translation ac-cording to our ground truth over the total numberof ground truth translation pairs (=1000) (Gaussieret al 2004; Tamura et al 2012).5 Additionally,we report the mean reciprocal rank (MRR) scores(Voorhees, 1999) for some experimental runs.Multilingual topic model.
We utilize a straightfor-ward multilingual extension of the standard Blei etal.
?s LDA model (Blei et al 2003) called bilingualLDA (Mimno et al 2009; Ni et al 2009; De Smetand Moens, 2009).
BiLDA training follows the pro-cedure from (Vulic?
and Moens, 2013), that is, thetraining method is Gibbs sampling with the numberof topics set to K = 2000.
Hyperparameters of themodel are set to standard values (Steyvers and Grif-fiths, 2007): ?
= 50/K and ?
= 0.01.Building initial seed lexicons.
To produce the listsof one-to-one translation pairs that are used as seedsfor the bootstrapping approach (see sect.
2.2), weexperiment with the TopicBC and the ResponseBCmethods from (Vulic?
and Moens, 2013), which arethe MuPTM-based models of cross-lingual seman-tic similarity that obtain the best results in the BLEtask on these datasets.
In short, the TopicBC methodcomputes the similarity of two words according tothe similarity of their conditional topic distributions(Griffiths et al 2007; Vulic?
et al 2011) using5We can build a one-to-one bilingual lexicon by harvestingone-to-one translation pairs (wSi , TC(wSi )), and the quality ofthat lexicon is best reflected in the Acc1 score.1617the Bhattacharyya coefficient (BC) (Kazama et al2010) as the similarity function.
ResponseBC is asecond-order similarity method.
It first computesinitial similarity scores between all words cross-lingually and monolingually using the cross-lingualtopical space and, in the second step, it computes thesimilarity between 2 words as the similarity betweentheir word vectors that now contain the initial word-to-word similarity scores with all source and targetwords.
The similarity function is again BC.We use these models of similarity as a black boxto acquire seeds for the bootstrapping approach, butwe encourage the interested reader to find more de-tails about the methods in the relevant literature.These two models also serve as our baseline models,and our goal is to test whether we are able to obtainbilingual lexicons of higher quality using bootstrap-ping that starts from the output of these models.Weighting and similarity functions.
We haveexperimented with different families of weighting(e.g., PMI, LLR, TF-IDF, chi-square) and similar-ity functions (e.g., cosine, Dice, Kullback-Leibler,Jensen-Shannon) (Lee, 1999; Turney and Pantel,2010).
In this paper, we present results obtainedby positive pointwise mutual information (PPMI)(Niwa and Nitta, 1994) as a weighting function,which is a standard choice in vector space seman-tics (Turney and Pantel, 2010), and (combined withcosine) yields the best results over a group of seman-tic tasks according to (Bullinaria and Levy, 2007).We use a smoothed version of PPMI as presentedin (Pantel and Lin, 2002; Turney and Pantel, 2010).Again, based on the results reported in the relevantliterature (Bullinaria and Levy, 2007; Laroche andLanglais, 2010; Turney and Pantel, 2010), we optfor the cosine similarity as a standard choice for SF .We have also experimented with different windowsizes ranging from 3 to 15 in both directions aroundthe pivot word, but we have not detected any majorqualitative difference in the results and their inter-pretation.
Therefore, all results reported in the paperare obtained by setting the window size to 6.4 Results and Discussion4.1 Are Seeds Important?In recent work, Peirsman and Pado?
(2010; 2011)report that ?the size and quality of the (seed) lex-icon are not of primary importance given that thebootstrapping procedure effectively helped filter outincorrect translation pairs and added more newlyidentified mutual nearest neighbors.?
According totheir findings, (1) noisy translation pairs are cor-rected in later stages of the bootstrapping process,since the quality of bilingual vector spaces gradu-ally increases, (2) the size of the seed lexicon doesnot matter since the bootstrapping approach is ableto learn translation pairs that were previously notpresent in the seed lexicon.
Additionally, they do notprovide any insight whether the frequency of seedsin the corpus influences the quality of induced bilin-gual vector spaces.
In this paper, we question theseclaims with a series of BLE experiments.All experiments conducted in this section do notrely on any extra confidence estimation except forthe symmetry constraint, that is, in each step we en-rich the bilingual vector space with all new symmet-ric translation pairs (see alg.
1 and sect.
2.3).Exp.
I: Same size, different seedings?
The goalof this experiment is to test whether the quality ofseeds plays an important role in the bootstrappingapproach.
We experiment with 3 different seed lex-icons: (1) Following (Peirsman and Pado?, 2010;Fis?er and Ljubes?ic?, 2011), we harvest identicallyspelled words across 2 languages and treat themas one-to-one translations.
This procedure resultsin 459 seed translation pairs for ES-EN, and 431pairs for IT-EN (SEED-ID), (2) We obtain symmet-ric translation pairs using the TopicBC method (seesect.
3) and use 459 pairs that have the highest fre-quency in the Wiki-ES-EN corpus as seeds for ES-EN (similarly 431 pairs for IT-EN) (SEED-TB), (3)As in (2), but we now use the ResponseBC method toacquire seeds (SEED-RB).
The frequency of a one-to-one translation pair is simply computed as the ge-ometric mean of the frequencies of words that con-stitute the translation pair.Fig.
1(a) and 1(b) display the progress of the samebootstrapping procedure using the 3 different seedlexicons.
We derive several interesting conclusions:(i) Regardless of the actual choice of the seedingmethod, the bootstrapping process proves its valid-ity and utility since we observe that the quality ofinduced bilingual vector spaces increases over timefor all 3 seeding methods.
The bootstrapping proce-dure converges quickly.
The increase is especially16180.20.40.60.8Acc M0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15IterationAcc1 (SEED-ID)Acc1 (SEED-TB)Acc1 (SEED-RB)Acc10 (SEED-ID)Acc10 (SEED-TB)Acc10 (SEED-RB)(a) Spanish to English0.20.40.60.8Acc M0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15IterationAcc1 (SEED-ID)Acc1 (SEED-TB)Acc1 (SEED-RB)Acc10 (SEED-ID)Acc10 (SEED-TB)Acc10 (SEED-RB)(b) Italian to English5007501000125015001750Numberofdimensions0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15IterationSEED-ID (ES-EN)SEED-TB (ES-EN)SEED-RB (ES-EN)SEED-ID (IT-EN)SEED-TB (IT-EN)SEED-RB (IT-EN)(c) # Dimensions over iterationsFigure 1: Results with 3 different seeding methods as starting points of the bootstrapping process: (i) identical wordsonly (SEED-ID), (ii) the TopicBC method (SEED-TB), (iii) the ResponseBC method (SEED-RB).
(a)AccM scores forES-EN; (b) AccM scores for IT-EN; (c) the number of dimensions in the space with the 3 different seeding methodsin each iteration for ES-EN and IT-EN.
The bootstrapping procedure typically converges after a few iterations.00.20.40.60.81AccM0 1 2 3 4 5 6 7 8 9 10IterationAcc1 (HF-SEED)Acc1 (MF-SEED)Acc1 (LF-SEED)Acc10 (HF-SEED)Acc10 (MF-SEED)Acc10 (LF-SEED)(a) Spanish to English00.20.40.60.81AccM0 1 2 3 4 5 6 7 8 9 10IterationAcc1 (HF-SEED)Acc1 (MF-SEED)Acc1 (LF-SEED)Acc10 (HF-SEED)Acc10 (MF-SEED)Acc10 (LF-SEED)(b) Italian to EnglishFigure 2: Results on the BLE task with SEED-RB when using seed translation pairs of different frequency: (i) high-frequency (HF-SEED), (ii) medium-frequency (MF-SEED), (iii) low-frequency (LF-SEED).prominent in the first few iterations, when the ap-proach learns more new dimensions (see fig.
1(c)).
(ii) The seeding method is important.
A bootstrap-ping approach that starts with a better seed lexiconis able to extract bilingual lexicons of higher qualityas reflected in Acc1 scores.
Although the bootstrap-ping approach seems more beneficial when dealingwith noisier seed lexicons (226% increase in termsof Acc1 for ES-EN and 177% increase for IT-ENwhen starting with SEED-ID, compared to 35% in-crease for ES-EN, and 15% for IT-EN with SEED-RB), when starting from a noisy seed lexicon suchas SEED-ID the method is unable to reach the samelevel of performance.
Starting with SEED-ID, theapproach is able to recover noisy dimensions froman initial bilingual vector space, but it is still unableto match the results that are obtained when startingfrom a better initial space (e.g., SEED-RB).
(iii) SEED-RB produces slightly better results thanSEED-TB (e.g., the final Acc1 of 0.649 for SEED-RB compared to 0.626 for SEED-TB for IT-EN, and0.572 compared to 0.553 for ES-EN).
This finding isin line with the results reported in (Vulic?
and Moens,2013) where ResponseBC proved to be a more ro-bust and a more effective method when applied tothe BLE task directly.
In all further experiments weuse ResponseBC to acquire seed pairs, i.e., the seed-ing method is SEED-RB.Exp.
II: Does the frequency of seeds matter?
Inthe next experiment, we test whether the frequencyof seeds in the corpus plays an important role inthe bootstrapping process.
The intuition is that byusing highly frequent and highly confident transla-tion pairs the bootstrapping method has more reli-able clues that help extract new dimensions in sub-sequent iterations.
On the other hand, low-frequency1619pairs (although potentially correct one-to-one trans-lations) do not occur in the corpus and in the con-texts of other words frequently enough, and aretherefore not sufficient to extract reliable new di-mensions of the space.To test the hypothesis, we again obtain all sym-metric translation pairs using ResponseBC and thensort them in descending order based on their fre-quency in the corpus.
In total, we retrieve a sortedlist of 2031 symmetric translation pairs for ES-EN,and 1689 pairs for IT-EN.
Following that, we splitthe list in 3 parts of equal size: (i) the top third com-prises translation pairs with the highest frequency inthe corpus (HF-SEED), (ii) the middle third com-prises pairs of ?medium?
frequency (MF-SEED),(iii) the bottom third are low-frequency pairs (LF-SEED).
We then use these 3 different seed lexiconsof equal size to seed the bootstrapping approach.Fig.
2(a) and 2(b) show the progress of the boot-strapping process using these 3 seed lexicons.
Weagain observe several interesting phenomena:(i) High-frequency seed translation pairs are betterseeds, and that finding is in line with our hypothesis.Although the bootstrapping approach again displaysa positive trend regardless of the actual choice ofseeds (we observe an increase even when using LF-SEED), high-frequency seeds lead to better overallresults in the BLE task.
Besides its high presence incontexts of other words, another advantage of high-frequency seed pairs is the fact that an initial sim-ilarity method will typically acquire more reliabletranslation candidates for such words (Pekar et al2006).
For instance, 89.5% of ES-EN pairs in HF-SEED are correct one-to-one translations, comparedto 65.1% in MF-SEED, and 44.3% in LF-SEED.
(ii) The difference in results between HF-SEED andMF-SEED is more visible in Acc1 scores.
Althoughboth seed lexicons for all test words provide rankedlists which contain words that exhibit some semanticrelation to the given word, the reliability and the fre-quency of translation pairs are especially importantfor detecting the relation of cross-lingual word syn-onymy, that is, the translational equivalence that isexploited in building one-to-one bilingual lexicons.Exp.
III: Does size matter?
The following exper-iment investigates whether bilingual vector spacesmay be effectively bootstrapped from small high-quality seed lexicons, and if larger seed lexiconsnecessarily lead to bilingual vector spaces of higherquality as reflected in BLE results.
We again retrievea sorted list of symmetric translation pairs as in Exp.II.
Following that, we build seed lexicons of vari-ous sizes by retaining only the first N pairs fromthe list, where we vary N from 200 to 1400 in stepsof 200.
We also use the entire sorted list as a seedlexicon (All), and compare the results on the BLEtask with the results obtained by applying the Re-sponseBC and TopicBC methods directly (Vulic?
andMoens, 2013).
The results are summarized in tables1 and 2.
We observe the following:(i) If we provide a seed lexicon with sufficient en-tries, the bootstrapping procedure provides compa-rable results regardless of the seed lexicon size, al-though results tend to be higher for larger seed lex-icons (e.g., compare results when starting with 600and 1200 lexicon entries).
When starting with thesize of 600, the bootstrapping approach is able tofind dimensions that were already in the seed lexi-con of size 1200.
The consequence is that, althoughbootstrapping with a smaller seed lexicon displays aslower start (see the difference in results at iteration0), the performances level after convergence.
(ii) Regardless of the seed lexicon size, the boot-strapping approach is valuable.
It consistently im-proves the quality of the induced bilingual vectorspace, and consequently, the quality of bilingual lex-icons extracted using that vector space.
The positiveimpact is more prominent for smaller seed lexicons,i.e., we observe an increase of 78% for ES-EN whenstarting with only 200 seed pairs, compared to anincrease of 15% when starting with 800 seed pairs,and 10% when starting with 1400 seed pairs.
(iii) The bootstrapping approach outperforms Re-sponseBC and TopicBC in terms of Acc1 and MRRscores for both language pairs when the seed lexi-con provides a sufficient number of entries.
How-ever, in terms of Acc10, TopicBC and ResponseBCstill exhibit comparable (for IT-EN) or even better(ES-EN) results.
Both TopicBC and ResponseBCare MuPTM-based methods that, due to MuPTMproperties, model the similarity of two words at thelevel of documents as contexts, while the bootstrap-ping approach is a window-based approach that nar-rows down the context to a local neighborhood of aword.
The MuPTM-based models are better suitedto detect a general topical similarity of words, and1620Iteration: 0 2 5 10Seed lexicon Acc1 MRR Acc10 Acc1 MRR Acc10 Acc1 MRR Acc10 Acc1 MRR Acc10200(?1617) 0.274 0.352 0.525 0.446 0.534 0.713 0.481 0.569 0.753 0.488 0.576 0.752400(?1563) 0.416 0.499 0.663 0.518 0.602 0.774 0.542 0.620 0.787 0.545 0.625 0.788600(?1554) 0.459 0.539 0.707 0.550 0.630 0.787 0.573 0.650 0.803 0.578 0.654 0.802800(?1582) 0.494 0.572 0.728 0.548 0.631 0.799 0.563 0.644 0.802 0.567 0.646 0.8061000(?1636) 0.516 0.591 0.744 0.563 0.644 0.805 0.578 0.656 0.813 0.581 0.658 0.8171200(?1740) 0.536 0.613 0.764 0.586 0.661 0.804 0.588 0.664 0.812 0.591 0.667 0.8141400(?1888) 0.536 0.620 0.776 0.583 0.659 0.808 0.589 0.666 0.815 0.588 0.666 0.818All-2031(?2437) 0.543 0.625 0.785 0.589 0.667 0.813 0.597 0.675 0.818 0.599 0.677 0.820TopicBC 0.433 0.576 0.843 ?
?
?
?
?
?
?
?
?ResponseBC 0.517 0.635 0.891 ?
?
?
?
?
?
?
?
?Table 1: ES-EN: Results with different sizes of the seed lexicon.
The number in the parentheses denotes the numberof dimensions in the bilingual space after the bootstrapping procedure converges.
The seeding method is SEED-RB.Iteration: 0 2 5 10Seed lexicon Acc1 MRR Acc10 Acc1 MRR Acc10 Acc1 MRR Acc10 Acc1 MRR Acc10200(?1255) 0.394 0.469 0.703 0.515 0.595 0.757 0.548 0.621 0.782 0.555 0.628 0.787400(?1265) 0.546 0.618 0.757 0.623 0.690 0.831 0.639 0.704 0.840 0.644 0.709 0.844600(?1309) 0.585 0.657 0.798 0.653 0.718 0.856 0.664 0.726 0.859 0.672 0.734 0.862800(?1365) 0.602 0.672 0.813 0.657 0.723 0.857 0.663 0.726 0.865 0.665 0.730 0.8671000(?1416) 0.616 0.688 0.828 0.629 0.706 0.853 0.636 0.709 0.857 0.642 0.714 0.8611200(?1581) 0.628 0.700 0.840 0.655 0.724 0.869 0.664 0.733 0.877 0.668 0.736 0.8831400(?1749) 0.626 0.701 0.851 0.654 0.727 0.867 0.656 0.728 0.867 0.661 0.733 0.874All-1689(?2008) 0.616 0.695 0.850 0.643 0.716 0.860 0.653 0.724 0.862 0.654 0.726 0.866TopicBC 0.578 0.667 0.834 ?
?
?
?
?
?
?
?
?ResponseBC 0.622 0.729 0.882 ?
?
?
?
?
?
?
?
?Table 2: IT-EN: Results with different sizes of the seed lexicon.
The number in the parentheses denotes the number ofdimensions in the bilingual space after the bootstrapping procedure converges.
The seeding method is SEED-RB.are therefore not always able to push the real cross-lingual synonyms higher in the ranked list of seman-tically similar words, while the window-based boot-strapping approach is better tailored to model therelation of cross-lingual synonymy, i.e., to extractone-to-one translation pairs (as reflected in Acc1scores).
A similar conclusion for monolingual set-tings is drawn by Baroni and Lenci (2010).
(iv) Since our bootstrapping approach utilizes Re-sponseBC or TopicBC as a preprocessing step, it isobvious that the approach leads to an increased com-plexity.
On top of the initial complexity of Respon-seBC and TopicBC, the bootstrapping method re-quires |V S ||V T | comparisons at each iteration, butgiven the fact that each wSi ?
V S may be processedindependently of any other wSj ?
V S in each itera-tion, the bootstrapping method is trivially paralleliz-able.
That makes the method computationally fea-sible even for vocabularies larger than the ones re-ported in the paper.4.2 Is Confidence Estimation Important?According to the results from tables 1 and 2, re-gardless of the seed lexicon size, the bootstrappingapproach does not suffer from semantic drift, i.e.,if we seed the process with high-quality symmetrictranslation pairs, it is able to recover more pairs andadd them as new dimensions of the bilingual vectorspace.
However, we also study the influence of ap-plying different confidence estimation functions ontop of the symmetry constraint (see sect 2.3), but wedo not observe any improvement in the BLE results,regardless of the actual choice of a confidence esti-mation function.
The only observed phenomenon,as illustrated by fig.
3, is the slower convergencerate when setting the parameter B to lower values.The symmetry constraint alone seems to be sufficientto prevent semantic drift, but it might also be a toostrong and a too conservative assumption, since onlya small portion of all possible translation pairs isused to span the bilingual vector space (for instance,16210.40.450.50.550.6Acc 10 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15IterationB = 30B = 50B = 100B = 150B = 200B = AllFigure 3: The effect of learning rate B on bootstrapping.Language pair: ES-EN, seed lexicon: SEED-RB with600 pairs, confidence function: symmetrized M-Best.when starting with 600 entries for ES-EN, the finalbilingual vector space consists of only 1554 pairs,while the total number of ES nouns is 9439).
Oneline of future work will address the construction ofbootstrapping algorithms that also enable the usageof highly reliable asymmetric pairs as dimensions,and the confidence estimation functions might havea more important role in that setting.5 ConclusionWe have presented a new bootstrapping approach toinducing bilingual vector spaces from non-paralleldata, and have shown the utility of the induced spacein the BLE task.
The approach is fully corpus-basedand, unlike previous work, it does not rely on theavailability of machine-readable translation dictio-naries or predefined concept categories.
We havesystematically described, analyzed and evaluated allkey components of the bootstrapping approach.
Re-sults reveal that, contrary to conclusions from priorwork, the initialization of the bilingual vector spaceis especially important.
We have presented a novelapproach to initializing the bootstrapping procedure,and have shown that better results in the BLE taskare obtained by starting from seed lexicons that com-prise highly reliable high-frequent translation pairs.The bootstrapping framework presented in the pa-per is completely language pair independent, whichmakes it effectively applicable to any language pair.In future work, we will investigate other modelsof similarity besides TopicBC and ResponseBC (e.g,the method from (Haghighi et al 2008)) that couldbe used as preliminary models for constructing aninitial bilingual vector space.
Furthermore, we planto study other confidence functions and explore ifasymmetric translation candidates could also con-tribute to the bootstrapping method.
Finally, we alsoplan to test the robustness of our fully corpus-basedbootstrapping approach by porting it to more lan-guage pairs.AcknowledgmentsWe would like to thank the anonymous reviewers fortheir useful suggestions.
This research has been car-ried out in the framework of the TermWise Knowl-edge Platform (IOF-KP/09/001) funded by the In-dustrial Research Fund, KU Leuven, Belgium.ReferencesMarco Baroni and Alessandro Lenci.
2010.
Distribu-tional memory: A general framework for corpus-basedsemantics.
Computational Linguistics, 36(4):673?721.David M. Blei, Andrew Y. Ng, and Michael I. Jordan.2003.
Latent Dirichlet Allocation.
Journal of Ma-chine Learning Research, 3:993?1022.Jordan Boyd-Graber and David M. Blei.
2009.
Multilin-gual topic models for unaligned text.
In Proceedingsof UAI, pages 75?82.John A. Bullinaria and Joseph P. Levy.
2007.
Extract-ing semantic representations from word co-occurrencestatistics: A computational study.
Behavior ResearchMethods, 39(3):510?526.Sung-Hyuk Cha.
2007.
Comprehensive survey ondistance/similarity measures between probability den-sity functions.
International Journal of MathematicalModels and Methods in Applied Sciences, 1(4):300?307.Dipanjan Das and Slav Petrov.
2011.
Unsupervised part-of-speech tagging with bilingual graph-based projec-tions.
In Proceedings of ACL-HLT, pages 600?609.Hal Daume?
III and Jagadeesh Jagarlamudi.
2011.
Do-main adaptation for machine translation by mining un-seen words.
In Proceedings of ACL-HLT, pages 407?412.Wim De Smet and Marie-Francine Moens.
2009.
Cross-language linking of news stories on the Web using in-terlingual topic modeling.
In Proceedings of the CIKM2009 Workshop on Social Web Search and Mining,pages 57?64.Greg Durrett, Adam Pauls, and Dan Klein.
2012.
Syntac-tic transfer using a bilingual lexicon.
In Proceedingsof EMNLP-CoNLL, pages 1?11.1622Darja Fis?er and Nikola Ljubes?ic?.
2011.
Bilingual lexiconextraction from comparable corpora for closely relatedlanguages.
In Proceedings of RANLP, pages 125?131.Pascale Fung and Percy Cheung.
2004.
Mining very-non-parallel corpora: Parallel sentence and lexicon ex-traction via bootstrapping and EM.
In Proceedings ofEMNLP, pages 57?63.Pascale Fung and Lo Yuen Yee.
1998.
An IR approachfor translating new words from nonparallel, compara-ble texts.
In Proceedings of COLING, pages 414?420.E?ric Gaussier, Jean-Michel Renders, Irina Matveeva,Cyril Goutte, and Herve?
De?jean.
2004.
A geometricview on bilingual lexicon extraction from comparablecorpora.
In Proceedings of ACL, pages 526?533.Thomas L. Griffiths, Mark Steyvers, and Joshua B.Tenenbaum.
2007.
Topics in semantic representation.Psychological Review, 114(2):211?244.Aria Haghighi, Percy Liang, Taylor Berg-Kirkpatrick,and Dan Klein.
2008.
Learning bilingual lexiconsfrom monolingual corpora.
In Proceedings of ACL,pages 771?779.Ruihong Huang and Ellen Riloff.
2012.
Bootstrappedtraining of event extraction classifiers.
In Proceedingsof EACL, pages 286?295.Azniah Ismail and Suresh Manandhar.
2010.
Bilin-gual lexicon extraction from comparable corpora usingin-domain terms.
In Proceedings of COLING, pages481?489.Jun?ichi Kazama, Stijn De Saeger, Kow Kuroda, MasakiMurata, and Kentaro Torisawa.
2010.
A Bayesianmethod for robust estimation of distributional similar-ities.
In Proceedings of ACL, pages 247?256.Philipp Koehn and Kevin Knight.
2002.
Learning atranslation lexicon from monolingual corpora.
In Pro-ceedings of the ACL Workshop on Unsupervised Lexi-cal Acquisition, pages 9?16.Zornitsa Kozareva and Eduard H. Hovy.
2010.
Not allseeds are equal: Measuring the quality of text min-ing seeds.
In Proceedings of NAACL-HLT, pages 618?626.Audrey Laroche and Philippe Langlais.
2010.
Revisitingcontext-based projection methods for term-translationspotting in comparable corpora.
In Proceedings ofCOLING, pages 617?625.Victor Lavrenko, Martin Choquette, and W. Bruce Croft.2002.
Cross-lingual relevance models.
In Proceedingsof SIGIR, pages 175?182.Lillian Lee.
1999.
Measures of distributional similarity.In Proceedings of ACL, pages 25?32.Gina-Anne Levow, Douglas W. Oard, and Philip Resnik.2005.
Dictionary-based techniques for cross-languageinformation retrieval.
Information Processing andManagement, 41(3):523?547.Tara McIntosh and James R. Curran.
2009.
Reducing se-mantic drift with bagging and distributional similarity.In Proceedings of ACL, pages 396?404.I.
Dan Melamed.
2000.
Models of translational equiv-alence among words.
Computational Linguistics,26(2):221?249.David Mimno, Hanna M. Wallach, Jason Naradowsky,David A. Smith, and Andrew McCallum.
2009.Polylingual topic models.
In Proceedings of EMNLP,pages 880?889.Xiaochuan Ni, Jian-Tao Sun, Jian Hu, and Zheng Chen.2009.
Mining multilingual topics from Wikipedia.
InProceedings of WWW, pages 1155?1156.Yoshiki Niwa and Yoshihiko Nitta.
1994.
Co-occurrencevectors from corpora vs. distance vectors from dictio-naries.
In Proceedings of COLING, pages 304?309.Franz Josef Och and Hermann Ney.
2003.
A system-atic comparison of various statistical alignment mod-els.
Computational Linguistics, 29(1):19?51.Sebastian Pado?
and Mirella Lapata.
2009.
Cross-lingualannotation projection for semantic roles.
Journal ofArtificial Intelligence Research, 36:307?340.Patrick Pantel and Dekang Lin.
2002.
Discovering wordsenses from text.
In Proceedings of KDD, pages 613?619.Yves Peirsman and Sebastian Pado?.
2010.
Cross-lingual induction of selectional preferences with bilin-gual vector spaces.
In Proceedings of NAACL-HLT,pages 921?929.Yves Peirsman and Sebastian Pado?.
2011.
Semantic re-lations in bilingual lexicons.
ACM Transactions onSpeech and Language Processing, 8(2):article 3.Viktor Pekar, Ruslan Mitkov, Dimitar Blagoev, and An-drea Mulloni.
2006.
Finding translations for low-frequency words in comparable corpora.
MachineTranslation, 20(4):247?266.Emmanuel Prochasson and Pascale Fung.
2011.
Rareword translation extraction from aligned comparabledocuments.
In Proceedings of ACL, pages 1327?1335.Reinhard Rapp.
1999.
Automatic identification of wordtranslations from unrelated English and German cor-pora.
In Proceedings of ACL, pages 519?526.Ellen Riloff and Jessica Shepherd.
1999.
A corpus-basedbootstrapping algorithm for semi-automated semanticlexicon construction.
Natural Language Engineering,5(2):147?156.Helmut Schmid.
1994.
Probabilistic part-of-speech tag-ging using decision trees.
In International Conferenceon New Methods in Language Processing.Daphna Shezaf and Ari Rappoport.
2010.
Bilingual lex-icon generation using non-aligned signatures.
In Pro-ceedings of ACL, pages 98?107.1623David A. Smith and Jason Eisner.
2007.
Bootstrappingfeature-rich dependency parsers with entropic priors.In Proceedings of EMNLP-CoNLL, pages 667?677.Mark Steyvers and Tom Griffiths.
2007.
Probabilistictopic models.
Handbook of Latent Semantic Analysis,427(7):424?440.Oscar Ta?ckstro?m, Dipanjan Das, Slav Petrov, Ryan Mc-Donald, and Joakim Nivre.
2013a.
Token and typeconstraints for cross-lingual part-of-speech tagging.Transactions of ACL, 1:1?12.Oscar Ta?ckstro?m, Ryan McDonald, and Joakim Nivre.2013b.
Target language adaptation of discrimina-tive transfer parsers.
In Proceedings of NAACL-HLT,pages 1061?1071.Akihiro Tamura, Taro Watanabe, and Eiichiro Sumita.2012.
Bilingual lexicon extraction from comparablecorpora using label propagation.
In Proceedings ofEMNLP-CoNLL, pages 24?36.Michael Thelen and Ellen Riloff.
2002.
A bootstrap-ping method for learning semantic lexicons using ex-traction pattern contexts.
In Proceedings of EMNLP,pages 214?221.Kewei Tu and Vasant Honavar.
2012.
Unambiguity reg-ularization for unsupervised learning of probabilisticgrammars.
In Proceedings of EMNLP-CoNLL, pages1324?1334.Peter D. Turney and Patrick Pantel.
2010.
From fre-quency to meaning: vector space models of semantics.Journal of Artifical Intelligence Research, 37(1):141?188.Lonneke van der Plas, Paola Merlo, and James Hender-son.
2011.
Scaling up automatic cross-lingual seman-tic role annotation.
In Proceedings of ACL-HLT, pages299?304.Ellen M. Voorhees.
1999.
The TREC-8 question answer-ing track report.
In Proceedings of TREC, pages 77?82.Ivan Vulic?
and Marie-Francine Moens.
2013.
Cross-lingual semantic similarity of words as the similarityof their semantic word responses.
In Proceedings ofNAACL-HLT, pages 106?116.Ivan Vulic?, Wim De Smet, and Marie-Francine Moens.2011.
Identifying word translations from comparablecorpora using latent topic models.
In Proceedings ofACL-HLT, pages 479?484.David Yarowsky and Grace Ngai.
2001.
Inducing mul-tilingual POS taggers and NP bracketers via robustprojection across aligned corpora.
In Proceedings ofNAACL, pages 200?207.Duo Zhang, Qiaozhu Mei, and ChengXiang Zhai.
2010.Cross-lingual latent topic extraction.
In Proceedingsof ACL, pages 1128?1137.Hai Zhao, Yan Song, Chunyu Kit, and Guodong Zhou.2009.
Cross language dependency parsing using abilingual lexicon.
In Proceedings of ACL, pages 55?63.1624
