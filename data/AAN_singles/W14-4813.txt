Proceedings of the 4th International Workshop on Computational Terminology, pages 104?113,Dublin, Ireland, August 23 2014.Identifying Portuguese Multiword Expressions using DifferentClassification Algorithms - A Comparative AnalysisAlexsandro FonsecaUniversity of Quebec inMontreal201 President Kennedy,Montreal, QC, Canadaaffonseca@gmail.comFatiha SadatUniversity of Quebec inMontreal201 President Kennedy,Montreal, QC, Canadasadat.fatiha@uqam.caAlexandre Blondin Mass?University of Quebec inChicoutimi555, boul.
de l'Univ.Chicoutimi, QC, G7H 2B1alexandre.blondin.masse@gmail.comAbstractThis paper presents a comparative analysis based on different classification algorithms and tools for theidentification of Portuguese multiword expressions.
Our focus is on two-word expressions formed bynouns, adjectives and verbs.
The candidates are selected on the basis of the frequency of the bigrams;then on the basis of the grammatical class of each bigram?s constituent words.
This analysis comparesthe performance of three different multi-layer perceptron training functions in the task of extractingdifferent patterns of multiword expressions, using and comparing nine different classificationalgorithms, including decision trees, multilayer perceptron and SVM.
Moreover, this analysis comparestwo different tools, Text-NSP and Termostat for the identification of multiword expressions usingdifferent association measures.1 IntroductionThe exact definition of a multiword expression (MWE) is a challenging task and it varies from authorto author.
For example, Moon (1998) says: ??
there is no unified phenomenon to describe but rather acomplex of features that interact in various, often untidy, ways and represent a broad continuumbetween non-compositional (or idiomatic) and compositional groups of words.?
Moreover, thisphenomenon receives different names in the literature (Proost, 2005): phraseological units, fixedexpressions, word combinations, phrasemes, etc.In this study, we consider MWE in a similar way Mel'?uk (1998) defines a phraseme: a phrasewhich is not free, i.e.
the expression?s signifier and/or signified are not unrestrictedly and regularlyconstructed.A phrase P is unrestrictedly constructed when the rules applied to construct P are not mandatory.For example, instead of the phrase: ?doing a research?
it is possible to say ?performing a research?,?executing a research?
i.e., this expression is not fixed.
However, in a sign like ?No smoking?, it is notcommon to see variants like ?Smoking prohibited?
or ?Do not smoke?, although those aregrammatically correct variants which express the same meaning.
Then, ?No smoking?
is a phraseme(MWE), because it is not unrestrictedly constructed.A phrase P is regularly constructed when the words forming it are combined following the generalrules of the grammar and its sense can be derived exclusively from the sense of its constituent words.The phrase: ?he died yesterday?, is regularly constructed because it follows the rules of the grammarand its sense follows from the sense the words forming it.
However, the expression ?kicked thebucket?
is not regularly constructed, in relation to its meaning (the combination of words follows therules of the grammar), because its sense, ?died?, cannot be derived from the sense of its constituent______________This work is licensed under a Creative Commons Attribution 4.0 International License.
Page numbers and proceedings footerare added by the organizers.
License details: http://creativecommons.org/licenses/by/4.0/104words.
On the other hand, the expression ?passing by?
is not regularly constructed because it does notfollow the general rules of the grammar.According to Mel?
?uk (1998), it is possible to divide the phrasemes (MWEs) in two groups:pragmatemes and semantic phrasemes.
As pragmatemes, we can have:- Expressions in which both the signified and the signifier are not unrestrictedly constructed(although they are regularly constructed), e.g.
?all you can eat?, or- Expressions in which only the signified is not unrestrictedly constructed.
For example, in alibrary it is possible to have signs like ?Please be quiet?, ?No talking please?, etc.
In this case,the signifier (the form, the words forming the expression) is more or less free; however, thesense is always the same.In semantic phrasemes, the signified is free (it is constructed unrestrictedly; however, it is notconstructed regularly) and the signifier is not free.
We can have three types of semantic phrasemes:- Idioms: the sense of the expression goes beyond the sense of its constituent words, and doesnot include their senses.
Examples: ?of course?, ?
(to) pull (someone?s) leg?, ?
(to) spill thebeans?
;- Collocations: the sense of the expression includes the sense of one of its constituent words, say,w1.
The other word is freely chosen and w1 is chosen contingent to it.
Collocations can be(Manning and Sch?tze, 1999): light verbs constructions (e.g.
make a call, take a decision), verbparticle constructions (e.g.
to switch on, to pass by), proper names (e.g.
San Francisco, BillGates) and terminological expressions, i.e., multiword terms (e.g.
gross domestic product, lightyear).- Quasi-phrasemes or quasi-idioms: the signified of the expression contains the signified of itsconstituent words; however, it also contains a signified that goes beyond the signified of theisolated words (e.g.
(to) start a family, bed and breakfast).For a more complete explanation about pragmatemes and semantic phrasemes, refer to (Mel?
?uk,1998) or to (Morgan, 1978).
For a more detailed linguistic description on the properties of MWEs, see(Baldwin and Kim, 2010).In this paper, we assume as MWE any kind of phraseme.
However, we are interested in the studyof Portuguese two-word expressions formed mostly by nouns, adjectives and verbs.
For this reason,since most of pragmatemes and idioms are formed by more than two words, basically our focus is onquasi-phrasemes and collocations (mostly light verbs constructions, proper names and multiwordterms (MWT)).The literature on MWE extraction describes different methods for the identification or extraction ofMWEs.
Many of them rely on association measures, such as Dice?s coefficient (Smadja, 1996) ormutual information (Church and Hanks, 1990).
A complete explanation on the use of this associationmeasures on the task of extraction MWEs from text can be found in (Manning and Sch?tze, 1999).The main idea behind such measures is that the higher the association among the words that appeartogether in a text, the higher the probability that they constitute a single semantic unit.There are other methods, which use linguistic information or hybrid approaches that combinestatistical measures with the linguistic information, such as the grammatical class of each word, thesense of the expression or the syntactic regularities.
Yet others are based on classification algorithms,popular in machine learning systems.In this study we performed two types of comparison.
In the first one, we compared the performanceof nine different classification algorithms in the task of identifying MWEs.
In the second, wecompared two different tools, Text-NSP and Termostat, using different association measures, in thetask of extracting MWEs from text.
Although our focus is in general MWE, the current study couldalso be applied to corpus in a specific area for the extraction of multiword terms (MWT).2 Related WorkBaptista (1994) presents a linguistic study about the nominal expressions formed by more than twowords in Portuguese.
From a set of 10,000 expressions, he created a typology of nominal MWEs.
Hefound that 70% of the nominal MWEs follow only five different patterns (A = adjective, N = noun, V= verb and P = preposition): A-N, N-A, N-P-N, N-N and V-N.
He analyses the syntactic proprieties ofeach of these groups, focusing his attention on the patterns N-A and N-P-N, which he considers less105rigid and more difficult to treat automatically.
Finally, he integrates the MWEs?
morphologicalinformation to an electronic dictionary.Antunes and Mendes (2013) propose the creation of a MWE typology that includes its semantic,syntactic and pragmatic properties, aiming the annotation of a MWE lexicon using this typologyinformation.
They divide the MWEs in three groups, from a semantic standpoint: expressions withcompositional meaning, e.g.
?banana bread?, expression with partial idiomatic meaning, e.g.
?vontadede ferro?
(iron will) and expressions with total idiomatical meaning (or with no compositionality), e.g.
?spill the beans?.
Within each of these three groups, the expressions are subdivided according to theirgrammatical categories and lexical and syntactical fixedness.After a survey and a comparison on different association measures, algorithms and tools used onthe identification of MWEs, Portela (2011) presents a study on the identification of Portuguese MWEsfollowing two patterns, N-A and N-P-N, using different association measures.
After the extraction ofcandidates, syntactic criteria are applied to them, to verify their fixedness and determine if a candidateis a MWE.
Examples of syntactic criteria applied to bigrams following the pattern N-A and N-P-N:- Loss of adjective?s predicative characteristic: when the adjective comes after the noun and itcan be paraphrased by a copulative verb (e.g.
verb ?to be?)
+ the same adjective, keeping thesame sense, the adjective has a predicative function.
For example, in the expression: ?homemcansado?
(tired man, lit.
man tired), it is possible to substitute ?cansado?
for ?que estavacansado?
(that was tired), and the adjective?s predicative characteristic is maintained.However, in the expression ?sorriso amarelo?
(false, not natural smile, lit.
smile yellow), if wesubstitute the expression for ?sorriso que ?
amarelo?, (smile that is yellow), the predicativecharacteristic is not maintained, because the original sense is lost.
This loss of predicativecharacteristic shows that the expression is fixed, and it is evidence that the expression is aMWE.- Insertion of elements in the expression (N-P-N): consider the expression ?livro de bolso?
(pocket book, lit.
book of pocket).
It is not possible to freely insert a modifier, for example?
*livro do Paulo de bolso?
(lit.
book of Paulo of Pocket).
In this example, the modifier can beinserted only at the end of the expression: ?livro de bolso do Paulo?.
This kind of fixedness isevidence that the expression is a MWE.3 MethodologyWe restricted the present study on the extraction of two-word MWEs.
For their data, for example, Piaoet al.
(2003) found that 81.88% of the recognized MWEs were bigrams.The current study uses CETENFolha (Corpus de Extractos de Textos Electr?nicos/NILC Folha deS?o Paulo) as a Brazilian Portuguese corpus, available on the Linguateca Portuguesa website, which ispart of a project on the automatic processing of the Portuguese language (Kinoshita et al., 2006).CETENFolha is composed by excerpts from the Brazilian newspaper "Folha de S?o Paulo", andcontains over 24 million words.
At the current stage, we use a small fraction of the corpus, comprising3,409 excerpts of text (about 250,000 words).
Each excerpt corresponds to individual news coveringdifferent areas.
The number 3,409 represents 1% of the number of excerpts composing the corpus.We performed different types of evaluation.
First, we generated a reference file containing the mostfrequent MWEs in the corpus and we compared nine different classification algorithms against thisreference in the task of identifying Portuguese MWEs.
Second, we tested a multilayer perceptronusing three different training functions in the task of classifying MWEs in different patterns.
We alsoextracted automatically the 2,000 most frequent bigrams from the entire corpus and we identified, byhand, which ones are MWEs, and we classified them in patterns.
Finally, we used two different toolsfor the identification of MWEs: Text-NSP (Banerjee and Pedersen, 2003) and Termostat (Drouin,2003).
For these tools, we are interested in two types of evaluation.
In the first evaluation, we used ourreference list to automatically compare the best candidates obtained by each tool against this reference.In the second evaluation, we manually counted the number of MWEs, among a list of the 500-bestcandidates ranked by one of the association measures, log-likelihood, and we calculated the precisionfor each tool.1063.1 Reference File CreationBefore the indexation, some pre-processing methods on the corpus were performed, such aslemmatization and elimination of stop words (articles, prepositions, conjunctions).
In this study, weare mostly interested in analyzing MWEs formed by nouns, adjectives and verbs.
And since those stopwords are very common in Portuguese, their elimination reduces considerably the number of MWEcandidates that would not be relevant to this study.
In this case, some common Portuguese MWEs arenot considered, especially the ones following the pattern noun-preposition-noun, e.g.
?teia de aranha?
(cobweb), or the pattern preposition-noun, e.g.
?
?s vezes?
(sometimes).We obtained 49,589 bigrams and we established a frequency of 3 as a threshold.
We selected 1,170bigrams that appeared more than 3 times in our corpus?
excerpts as our MWE candidates, and by handwe recognized 447 of them as Portuguese MWEs, and we considered those 447 MWEs as ourreference file.It is important to note that our reference file does not contain all the two-word MWEs in the corpus?excerpt, since we generated more than 49,000 bigrams, and we could not evaluate all of them by hand.Furthermore, the corpus is formed by newspaper texts, treating different subjects, thus it is moredifficult to create a closed set of all possible two-word MWEs.
Therefore, our evaluation in the presentstudy is based on a comparison of how many of the most frequent two-word MWEs in our corpus areranked as n-best candidates by some of the association measures implemented by each tool.3.2 Comparison of Different Classification AlgorithmsFirst, we computed the frequency of each of those 1,170 bigrams and the frequency of its constituentwords.
Then, we classified by hand each of the words according to their grammatical class: 1 fornouns, 2 for adjectives, 3 for verbs, 4 for other classes (adverbs, pronouns and numbers) and 5 forproper names.
We decided not to use a POS-tagger to guarantee the correct grammatical classassignment to each word.
This gave us 25 patterns of bigrams: N-N (noun-noun), N-A (noun-adjective), N-V (noun-verb), V-N, PN-PN (proper name-proper name), etc.Second, we created a matrix of 1,170 lines and five columns.
For each line, the first columnrepresents the frequency of a bigram in the excerpt of text, the second column represents the frequencyof the first bigram?s word, the third column represents the frequency of the second bigram?s word, thefourth column represents the grammatical class of the first bigram?s word and the fifth columnrepresents the grammatical class of the second bigram?s word.
This matrix was used to evaluate theprecision and recall of nine different classification algorithms: decision tree, random forest, ada boost(using decision stamp as classifier), bagging (using fast decision tree learner as classifier), KNN (Knearest neighbors), SVM, multilayer perceptron, na?ve Bayesian net and Bayesian net.3.3 Bigrams Pattern ClassificationWe chose one of the algorithms with the best performance (multi-layer perceptron) and we evaluatedit using three different training functions, Bayesian regulation back propagation (br), Levenberg-Marquardt (lm) and scaled conjugate gradient (scg), and we compared their performance in theclassification of different patterns of bigrams as MWE.
The data used for the classification isformatted in the same way as in the Subsection 3.2.
However, for this comparison, we used only thepatterns that gave 10 or more samples of MWE, for example, the patterns: N-A, N-N and N-PN.3.4 The Text-NSP ToolText-NSP is a tool used in the task of MWE extraction from texts (Banerjee and Pedersen, 2003).
Inorder to use Text-NSP tool, we do not provide a file containing the POS patterns of the bigrams thatwe would like to extract as MWE candidates.
Therefore, before applying this tool, the only pre-processing task we performed with the source corpus, was removing the XML tags they contained.The next step was to define a stop words list file, since we were interested in finding MWEs followingthe bigram?s patterns formed only by nouns, adjectives, verbs and others classes (adverbs, pronounsand numbers), e.g.
N-N, N-A, N-V, O-N.We ran the program using the ?count.pl?
script, giving the stop words file and the corpus files asparameters, and 2 as n-gram value, which refers to our aim to generate only bigrams.107The output file is a list of all bigrams in the corpus, and each line contains a bigram, the frequencyof the bigram, and the frequency of each of the two words forming the bigram.Using the output file and the ?statistics.pl?
script, we generated the candidates?
files ranked by fourdifferent association measures: Dice's coefficient (dice), log-likelihood (ll), pointwise mutualinformation (pmi) and Student's t-test (t).
Then we transformed each of the candidate files to the XMLformat used by MWEtoolkit (Ramisch, 2012) and used MWEtoolkit?s scripts to create files with the n-best candidates (n = 50, 100, 500, 1000 and 3000) and compare each candidate file against thereference file.3.5 The Termostat ToolTermostat (Drouin, 2003) is a tool developed for an automatic extraction of terms.
It can be currentlyused with five different languages: English, French, Italian, Portuguese and Spanish.
It generatesstatistics for simple and complex expressions.
Since in this study we are interested in MWE, weextracted only the complex expressions.As for Text-NSP, Termostat requires the elimination of the XML tags the corpus contained; whichwas the only pre-processing step of the corpus.After the analysis of the corpus, the system generated the lists of expressions ranked by fourassociation measures: log-likelihood (ll), chi-squared (?2), log-odds ratio (lor) and the ?sp?cificit?
?measure (Lafon, 1980) (sp).Then we proceeded as for Text-NSP: we created files with the n-best candidates, ranked by the fourassociation measures and compared each candidate file against the reference file.3.6 Comparison between the 500-best Candidates of each ToolUsing the association measure that is implemented by both tools, the log-likelihood, we analyzed the500-best candidates ranked by this association measure using each tool.
We selected by hand theMWEs among those candidates and we calculated the precision of each tool, for the n-best firstcandidates (n = 50, 100, 150?500).4 Evaluations4.1 Comparison of Different Classification AlgorithmsFirst, we had to proceed to an indirect estimative of the recall.
We found 49,589 bigrams in theselected excerpts of texts, and the manual evaluation of each one, in order to decide which one is aMWE, would take too much time.
So, we estimated the amount of MWEs for the total 49,589 bigramsas in (Piao et al., 2003).
Using 100 excerpts of text we generated all the bigrams, with all frequencies.We obtained 1,715 bigrams.Then, we found by hand 136 MWEs, which tells us that about 7.93% of the bigrams are MWEs.Considering that the corpus is homogeneous, we can extrapolate and say that about 7.93% of the49,589 bigrams in our total excerpts are MWEs, which gives 3,932 MWEs.
Since we found 447MWEs after applying the filter of frequency (> 3), our base recall is 11.37% (447/3,932).
We used thisbase recall as a multiplying factor for the recall given by each classification algorithm.We used our generated data to test nine different classification algorithms: decision tree, randomforest, ada boost, bagging, KNN (K nearest neighbors), SVM, multilayer perceptron, na?ve Bayesiannet and Bayesian net.
The main parameters used with each algorithm are listed below.Decision tree: C4.5 algorithm (Quinlan, 1993) with confidence factor = 0.25.Random Forest (Breiman, 2001): number of trees = 10; max depth = 0; seed = 1.Ada Boost (Freund and Schapire, 1996): classifier = decision stamp; weight threshold = 100;iterations = 10; seed = 1.Bagging (Breiman, 1996): classifier = fast decision tree learner (min.
number = 2; min.
variance =0.001; number of folds = 3; seed = 1; max.
depth = -1); bag size percent = 100; seed = 1; number ofexecution slots = 1; iterations = 10.KNN (Aha and Kibler, 1991): K = 3; window size = 0; search algorithm = linear NN search(distance function = Euclidian distance).SVM (Chang and Lin, 2001): cache size = 40; cost = 1; degree = 3; eps = 0.001; loss = 0.1; kerneltype = radial basis function; nu = 0.5; seed = 1.108Multilayer perceptron: learning rate = 0.3; momentum = 0.2; training time = 500; validationthreshold = 500; seed = 0;Bayesian net: search algorithm = k2 (Cooper and Herskovits, 1992); estimator = simple estimator(alpha = 0.5).The results are summarized in Table 1, where Recall-1 is the recall given by each algorithm basedon the 447 MWEs found among the MWE candidates and Recall-2 is Recall-1 multiplied by 0.1137(base recall, as previously calculated), which gives an estimative of the recall for the entire corpus.As we see in Table 1, the values of precision are very similar for all the algorithms, varyingbetween 0.830 (random forest) and 0.857 (bagging), with the exception of SVM, which gave aprecision of 0.738.
The recall-1values were between 0.831 and 0.857 (0.655 for SVM) and the recall-2between 9.4% and 9.7% (7.4% for SVM).We observe that we obtained good precision and weak recall.
This is due, as observed by Piao et al.
(2003), to the fact that the extraction of the MWE candidates is based only on the frequency of thebigrams, and only after the extraction of these candidates we applied the linguistic information(classification in grammatical classes).However, we must consider that, although we extracted only about 11% of the MWEs, these 11%are the most frequent and they represent about 46% of all the MWEs in the corpus, if we sum up thefrequency of each MWE.
Together, the 447 MWEs found appear 4,824 times in our corpus?
excerpt,while the remaining 3,485 (from a predicted 3,932 MWEs in the corpus?
excerpt) appear 5,576 times.In absolute terms we have: 4,824 / (4,824+5,576) = 0.46.Algorithm TP Rate FP Rate Precision Recall Recall-2Decision tree 0.853 0.158 0.854 0.853 0.097Random forest 0.831 0.194 0.830 0.831 0.094Ada boost 0.837 0.196 0.836 0.837 0.095Bagging 0.857 0.163 0.857 0.857 0.097KNN ?
k = 3 0.846 0.171 0.846 0.846 0.096SVM 0.655 0.553 0.738 0.655 0.074M.
perceptron 0.852 0.174 0.851 0.852 0.097Na?ve B. net 0.836 0.170 0.839 0.836 0.095Bayesian net 0.842 0.170 0.843 0.842 0.096Base recall 0.1137Table 1: True-positive rate, false-positive rate, precision and recall for nine classification algorithms.4.2 Bigrams Patterns ClassificationWe obtained eight patterns that together represent 59% of the candidate bigrams (689/1,170) and 94%of the MWEs that appear three or more times in the corpus (420/447).
The rest of the bigrams?patterns (41%) rarely formed MWE (only 6% of the total MWEs).
Table 2 shows the results.
?N?stands for ?Noun?, ?A?
for adjective, ?O?
for other classes (adverbs, pronouns and numbers) and ?PN?for ?proper names?.Analyzing the table, we had best results with the patterns N-A (e.g.
?comiss?o t?cnica?, ?bancocentral?, ?imposto ?nico?)
and PN-PN (?Fidel Castro?, ?Jos?
Sarney?, ?Max Mosley?).
The functionlm gave the best value for the F1 measure (0.912) for the pattern N-A, and the function scg gave thebest value for the pattern PN-PN (0.931).In general, we had the weakest results with the patterns O-N, e.g.
?terceiro mundo?, (third world)and A-PN, e.g.
?Nova York?, ?Santa Catarina?.
Using the training functions ?lm?
and ?scg?, none ofthe 10 MWEs belonging to the pattern O-O, e.g.
?at?
agora?
(until now), ?al?m disso?
(moreover, lit.beyond this) was recognized, and none of the 46 MWEs belonging to the pattern O-N was recognized,when using the training function ?scg?.The last line of each table presents the total values for the eight patterns, for the three learningfunctions.
We had the best precision and recall using the ?lm?
function.109br   lm   scgPattern Bigrams MWE Prec.
Rec.
F1 Prec.
Rec.
F1 Prec.
Rec.
F1N-A 229 193 0.867 0.912 0.889 0.845 0.990 0.912 0.850 0.969 0.906O-N 164 46 0.378 0.304 0.337 0.647 0.239 0.349 0.720 0.000 0.000PN-PN 117 101 0.862 0.931 0.895 0.863 1.000 0.927 0.871 1.000 0.931A-N 53 21 0.813 0.619 0.703 0.810 0.810 0.810 0.630 0.810 0.708O-O 46 10 0.357 0.500 0.417 0.000 0.000 0.000 0.783 0.000 0.000N-PN 34 16 0.438 0.438 0.438 0.688 0.688 0.688 0.222 0.125 0.160N-N 31 20 0.647 0.550 0.595 0.696 0.800 0.744 0.692 0.900 0.783A-PN 15 13 0.750 0.231 0.353 0.500 0.154 0.235 0.667 0.154 0.250All Pat.
689 420 0.776 0.769 0.773 0.819 0.831 0.825 0.815 0.779 0.797Table 2: Multi-layer perceptron precision, recall and F-measure in the classification of the mostcommon bigram?s patterns using different training functions: Bayesian regulation back-propagation(br), Levenberg-Marquardt (lm) and scaled conjugate gradient (scg).Using Text-NSP tool, we extracted from the entire corpus all the bigrams (including the onesformed by stop words) and we analyzed by hand the 2,000 most frequent bigrams.
We found 165 two-word MWEs formed by nouns, adjectives, verbs and other classes (adverbs, pronouns and numerals)and we classified them according to their pattern.
Table 3 shows the number of MWEs and their totalfrequency in the corpus, classified by patterns.
The words belonging to the classes of adverb, pronounand numeral were classified as ?O?
(other classes).The much smaller proportion of bigrams recognized as MWEs (165/2000) in comparison to theprevious analysis (447/1,170) is explained by the fact that in the previous analysis we had eliminatedthe stop words before generating the bigrams, and now all the bigrams were generated.
This createdmany bigrams composed by prepositions or conjunctions that do not form MWE, for example: ?deum?, ?de uma?, ?de S?o?, ?que os?, ?diz que?, ?do que?, ?em que?.We note that the five most common patterns are the same as found before, in the small excerpt oftext, with the pattern N-A giving the greatest number of expressions, e.g.
?ano passado?
(last year, lit.year last), ?Banco Central?
(Central Bank, lit.
bank central), ?norte americano?
(north American),?sele?
?o brasileira?
(Brazilian team, lit.
selection Brazilian), ?equipe econ?mica?
(economic team, lit.team economic).
In terms of frequency, the MWEs following the pattern N-A represent about 38% ofthe most frequent two-word MWEs found in the corpus.It is important to observe that, although we are not differentiating Brazilian and Portuguese MWEsin this study, the recognized MWEs follow the Brazilian orthography (e.g.
?equipe econ?mica?
vs?equipa econ?mica?, ?sele?
?o brasileira?
vs ?selec?
?o brasileira?
), since we used a BrazilianPortuguese corpus.Pattern MWE  FrequencyN-A 58          101,442O-N 27            29,697PN-PN 24            39,270O-O 23            13,923A-N 13            51,460N-N 12            21,559A-O 2              1,975A-PN 2              2,115V-N 2              2,263N-PN 1              2,589N-V 1              1,423Total 165          267,716Table 3: Frequency of the most common MWEs patterns extracted from the entire corpus1104.3 Text-NSPBefore applying this tool, the only pre-processing performed in the corpus was to remove the XMLtags.
The next step was to define a stop words list file like in Subsections 4.1 and 4.2.We ran the program using the script ?count.pl?, giving as parameter the stop word file and thecorpus file, and 2 as n-gram value, meaning that we wanted to generate only bigrams.The exit file is a list of all bigrams in the corpus?
excerpt, and each line contains a bigram, thefrequency of the bigram, and the frequency of each of the two words forming the bigram.Using the output file and the script ?statistics.pl?
we generated the candidates?
files ranked by thefour association measures listed in Subsection 3.4.
Then we transformed each of the candidates?
filesto the XML format used by the MWEtoolkit and we used the MWEtoolkit?s scripts to create files withthe n-best candidates and to evaluate each of the files against our reference file.
Table 4a shows theresults of this evaluation.The results show that for values of n = 50, 100 and 500 we had the best results using the log-likelihood measure and for n = 1000 and 3000, Student?s t-test gave the best results.Table 4b shows the precision, recall and F-measure that we obtained using the log-likelihoodmeasure.
We had very good values of precision using the Text-NSP using this measure.
For example,from the 50 best ranked candidates by this measure, 31 were MWEs present in our reference list.4.4 TermostatTermostat generated n-grams following eleven POS patterns, all of them are nominal ones: N-N, N-A,N-P-N, N-N-N, N-P-N-A, N-N-N-N, N-V-N, N-N-N-N-N, N-A-A, N-N-A and N-A-N.
In total, 4,284n-grams were generated, and we selected only the bigrams (N-N and N-A), which gave 3,458 bigrams(81% of all n-grams).
The last five patterns listed above produced less than ten candidates each oneand the patterns N-P-N-A, N-N-N-N produced less than 30 candidates each one.Those 3,458 candidates were ranked according to the four association measures listed in Subsection3.5.
Then we compared the n-best candidates against our reference file.
The results are in Table 5a.Table 5b shows the precision, recall and F-measure that we obtained using the log-likelihood measure.Looking at Table 5a, we notice that we had best performance with ?2 for the 50 and 100 bestcandidates and for the 500, 1000 and 3000 best candidates we had better results using the ll measure.Comparing with Text-NSP, Termostat had best performance for the first 50 and 100 candidates.However, Text-NSP outperformed for n = 500, 1000 and 3000, when using the ll measure andStudent?s t-test.dice ll pmi t  ll TP Prec.
Recall F150 7 31 0 23  50 31 0.62 0.07 0.12100 7 64 0 39  100 64 0.64 0.14 0.23500 8 241 1 180  500 241 0.48 0.54 0.511000 11 314 4 331  1000 314 0.31 0.70 0.433000 69 375 11 392  3000 375 0.13 0.84 0.22(a)                                               (b)Table 4: Text-NSP: Number of MWEs among the first n-best candidates, ranked by four associationmeasures (a) and precision, recall and F-measure for the log-likelihood measure (b).
?2 ll lor sp  ll TP Prec.
Recall F150 42 38 32 38  50 38 0.76 0.09 0.15100 72 68 66 68  100 68 0.68 0.15 0.25500 153 162 117 159  500 162 0.32 0.36 0.341000 181 197 127 192  1000 197 0.20 0.44 0.273000 198 211 143 208  3000 211 0.07 0.47 0.12(a)       (b)Table 5: Termostat: Number of MWEs among the first n-best candidates, ranked by fourassociation measures (a) and precision, recall and F-measure for the log-likelihood measure (b).1114.5 Comparing the 500-best candidates of each toolWe analyzed by hand the 500-best candidates obtained using Text-NSP and Termostat, ranked by thelog-likelihood association measure, to decide which ones are MWEs.
Table 6 shows the precisiongiven by each tool, for the first n candidates, n = 50, 100, 150?500.With Termostat, we had the best precision for all values of n candidates, going from 86% for thefirst 50 candidates to 82% for the first 500 candidates.
Using Text-NSP, the precision starts with 82%for the first best 50 candidates and decreases to 72% for the first 500-best candidates.As in the tests performed in Subsection 4.2, the most common patterns of MWE found by bothtools were noun-adjective, e.g.
?Congresso Nacional?, ?emenda constitucional?, ?deputado federal?and proper name-proper name, e.g.
?Fernando Collor?, ?Get?lio Vargas?, ?Itamar Franco?.n first cand.
Text-NSP Termostat50 0.82 0.86100 0.82 0.85150 0.83 0.86200 0.79 0.84250 0.76 0.84300 0.75 0.84350 0.74 0.83400 0.74 0.82450 0.73 0.81500 0.72 0.82Table 6: Text-NSP and Termostat precision for the first n best candidates, using log likelihoodassociation measure.5 Conclusions and Future WorkIn this paper, we presented a comparative study on different classification algorithms and tools for theidentification of Portuguese multiword expressions, using information about the frequency, thegrammatical classes of the words and bigrams and different association measures.In what concerns the classification algorithms, bagging, decision trees and multi-layer perceptronhad a slightly better precision.
Using multi-layer perceptron with three different training functions, weidentified the part-of-speech patterns that are best classified as two-word MWEs.
Using the functionLevenberg-Marquardt we had better results in classifying the pattern noun-adjective (the mostcommon in our corpus) and we were more successful in classifying MWEs following the pattern?proper name-proper name?
using the function scaled conjugate gradient.With the objective of making an estimative on the part-of-speech patterns followed by the mostfrequent two-word MWEs in the corpus, we applied Text-NSP to the extraction of the 2,000 mostfrequent bigrams and we identified and classified the MWEs, according to their part-of-speechpatterns.
As a result, we found that the patterns ?noun-adjective?
and ?proper name-proper name?
arethe most common two-word MWE patterns in the corpus.
We also found that verbs do not form agreat variety of two-word MWE in Portuguese.The comparison between tools for the automatic identification of MWEs showed that Termostathad better precision than Text-NSP when applied to a small number of candidates (50 and 100).
Whenthe number of candidates increases, Text-NSP had better precision using log-likelihood measure andStudent?s t-test association measures.As future work, we intend to apply the same tools, especially Termostat, to a specific domaincorpus, in order to compare their performance in the identification of Portuguese multiword terms, notlimiting the study to bigrams, but also analyzing n-grams in general.ReferencesAha, D. and Kibler, D. (1991).
Instance-based learning algorithms.
In: Machine Learning.
6:37-66.112Antunes, S. and Mendes, A.
(2013).
MWE in Portuguese - Proposal for a Typology for Annotation in RunningText.
Proceedings of the 9th Workshop on Multiword Expressions (MWE 2013), pp.
87?92, Atlanta, Georgia.Baldwin, T. and Kim, S. N. (2010).
Multiword expressions.
Nitin Indurkhya and Fred J. Damerau (eds.
), In:Handbook of Natural Language Processing, Second Ed.
Chapman & Hall/CRC, London, UK., pp.
267-292.Banerjee, S and Pedersen, T. (2003).
The Design, Implementation, and Use of the Ngram Statistic Package.
In:Proceedings of Fourth International Conference on Intelligent Text Processing and ComputationalLinguistics, pp.
370-381, Mexico City.
http://search.cpan.org/~tpederse/Text-NSP/Baptista, J.
(1994).
Estabelecimento e Formaliza?
?o de Classes de Nomes Compostos.
Master Thesis.
Faculdadede Letras, Universidade de Lisboa, 145 pp.Breiman, L. (2001).
Random Forests.
In: Machine Learning.
45(1):5-32.Breiman , L. (1996).
Bagging predictors.
In: Machine Learning.
24(2):123-140.Chang, Chih-Chung and Lin, Chih-Jen (2001).
LIBSVM - A Library for Support Vector Machines.http://www.csie.ntu.edu.tw/~cjlin/libsvm/.Church, K. W. and Hanks, P (1990).
Word Association Norms, Mutual Information and Lexicography.
In:Computational Linguistics, 16(1):22?29.Cooper, G.  and Herskovits, E. (1992).
A Bayesian Method for the Induction of Probabilistic Networks fromData.
In: Machine Learning.
9(4):309-347.Drouin, P. (2003).
Term Extraction Using Non-technical Corpora as a Point of Leverage, In: Terminology, 9(1):99-117.
-  http://termostat.ling.umontreal.ca/Freund, Y. and Schapire, R. E (1996).
Experiments with a new boosting algorithm.
In: Thirteenth InternationalConference on Machine Learning, San Francisco, pp.
148-156.Kinoshita, J., Nascimento Salvador, L.D., Dantas de Menezes, C., E. (2006).
CoGrOO: a Brazilian-PortugueseGrammar Checker based on the CETENFOLHA Corpus.
In: Proceedings of Fifth International Conferenceon Language Resources and Evaluation, pp.
2190-2193.Lafon, P. (1980).
Sur la Variabilit?
de la Fr?quence des Formes dans un Corpus.
In: MOTS, no 1, pp.
128-165.Manning, C. D. and Sch?tze, H. (1999).
Foundations of Statistical Natural Language Processing.
Cambridge,MA: The MIT Press, 1999, 680 pp.Mel'?uk, I.
(1998).
Collocations and Lexical Functions.
In: A.P.
Cowie (ed.
), Phraseology.
Theory, Analysis, andApplications, 1998, Oxford: Clarendon Press, pp.
23-53.Moon, R. E. (1998).
Fixed Expressions and Idioms in English: A Corpus Based Approach.
Oxford: ClarendonPress, 356 pp.Morgan, J. L. (1978).
Two Types of Convention in Indirect Speech acts.
In: P. Cole (ed.
), Syntax and Semantics,v.9.
Pragmatics (New York etc.
: Academic Press), pp.
261-80.Piao, S., Rayson, P., Archer, D., Wilson, A., and McEnery, T.  (2003).
Extracting Multiword Expressions with aSemantic Tagger.
In: Workshop on Multiword Expressions: Analysis, Acquisition and Treatment, at ACL2003, 41st Annual Meeting of the Association for Computational Linguistics, pp.
49-56, Sapporo, Japan.Portela, R. J. R. (2011).
Identifica?
?o Autom?tica de Nomes Compostos.
Instituto Superior T?cnico,Universidade T?cnica de Lisboa.
Master Thesis.
November 2011, Lisbon, Portugal, 104 pp.Proost, K. (2007).
Conceptual Structure in Lexical Items: The Lexicalisation of Communication Concepts inEnglish, German and Dutch.
John Benjamins Pub.
Co, 304 pp.Quinlan, J. R. (1993).
C4.5: Programs for Machine Learning.
Morgan Kaufmann Publishers, 303 pp.Ramisch, C. (2012).
A Generic and Open Framework for MWE Treatment ?
From Acquisition to Applications -Ph.D. Thesis, Universidade Federal do Rio Grande do Sul - UFRGS, Brazil, 248 pp.http://mwetoolkit.sourceforge.net/PHITE.php?sitesig=MWESmadja, F. A.
(1996).
Translating Collocations for Bilingual Lexicons: A Statistical Approach.
Association forComputational Linguistics, 22 (1):1-38.113
