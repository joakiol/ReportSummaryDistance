Proceedings of HLT/EMNLP 2005 Demonstration Abstracts, pages 26?27,Vancouver, October 2005.Japanese Speech Understanding Using Grammar SpecializationManny Rayner, Nikos Chatzichrisafis, Pierrette BouillonUniversity of Geneva, TIM/ISSCO40 bvd du Pont-d?Arve, CH-1211 Geneva 4, Switzerlandmrayner@riacs.edu{Pierrette.Bouillon,Nikolaos.Chatzichrisafis}@issco.unige.chYukie Nakao, Hitoshi Isahara, Kyoko KanzakiNational Institute of Information and Communications Technology3-5 Hikaridai, Seika-cho, Soraku-gun, Kyoto, Japan 619-0289yukie-n@khn.nict.go.jp, {isahara,kanzaki}@nict.go.jpBeth Ann HockeyUCSC/NASA Ames Research CenterMoffet Field, CA 94035bahockey@riacs.eduMarianne Santaholma, Marianne StarlanderUniversity of Geneva, TIM/ISSCO40 bvd du Pont-d?ArveCH-1211 Geneva 4, SwitzerlandMarianne.Santaholma@eti.unige.chMarianne.Starlander@eti.unige.chThe most common speech understanding archi-tecture for spoken dialogue systems is a combinationof speech recognition based on a class N-gram lan-guage model, and robust parsing.
For many typesof applications, however, grammar-based recogni-tion can offer concrete advantages.
Training agood class N-gram language model requires sub-stantial quantities of corpus data, which is gen-erally not available at the start of a new project.Head-to-head comparisons of class N-gram/robustand grammar-based systems also suggest that userswho are familiar with system coverage get better re-sults from grammar-based architectures (Knight etal., 2001).
As a consequence, deployed spoken dia-logue systems for real-world applications frequentlyuse grammar-based methods.
This is particularlythe case for speech translation systems.
Althoughleading research systems like Verbmobil and NE-SPOLE!
(Wahlster, 2000; Lavie et al, 2001) usu-ally employ complex architectures combining sta-tistical and rule-based methods, successful practicalexamples like Phraselator and S-MINDS (Phrasela-tor, 2005; Sehda, 2005) are typically phrasal trans-lators with grammar-based recognizers.Voice recognition platforms like the NuanceToolkit provide CFG-based languages for writinggrammar-based language models (GLMs), but it ischallenging to develop and maintain grammars con-sisting of large sets of ad hoc phrase-structure rules.For this reason, there has been considerable inter-est in developing systems that permit language mod-els be specified in higher-level formalisms, normallysome kind of unification grammar (UG), and thencompile these grammars down to the low-level plat-form formalisms.
A prominent early example of thisapproach is the Gemini system (Moore, 1998).Gemini raises the level of abstraction signifi-cantly, but still assumes that the grammars will bedomain-dependent.
In the Open Source REGULUSproject (Regulus, 2005; Rayner et al, 2003), wehave taken a further step in the direction of increasedabstraction, and derive all recognizers from a sin-gle linguistically motivated UG.
This derivation pro-cedure starts with a large, application-independentUG for a language.
An application-specific UG isthen derived using an Explanation Based Learning(EBL) specialization technique.
This corpus-basedspecialization process is parameterized by the train-ing corpus and operationality criteria.
The trainingcorpus, which can be relatively small, consists of ex-amples of utterances that should be recognized bythe target application.
The sentences of the corpusare parsed using the general grammar, then thoseparses are partitioned into phrases based on the op-erationality criteria.
Each phrase defined by theoperationality criteria is flattened, producing rulesof a phrasal grammar for the application domain.This application-specific UG is then compiled into26a CFG, formatted to be compatible with the Nuancerecognition platform.
The CFG is compiled into theruntime recognizer using Nuance tools.Previously, the REGULUS grammar specializationprogramme has only been implemented for English.In this demo, we will show how we can apply thesame methodology to Japanese.
Japanese is struc-turally a very different language from English, so itis by no means obvious that methods which workfor English will be applicable in this new context:in fact, they appear to work very well.
We willdemo the grammars and resulting recognizers in thecontext of Japanese ?
English and Japanese ?French versions of the Open Source MedSLT medi-cal speech translation system (Bouillon et al, 2005;MedSLT, 2005).The generic problem to be solved when buildingany sort of recognition grammar is that syntax aloneis insufficiently constraining; many of the real con-straints in a given domain and use situation tend tobe semantic and pragmatic in nature.
The challengeis thus to include enough non-syntactic constraintsin the grammar to create a language model that cansupport reliable domain-specific speech recognition:we sketch our solution for Japanese.The basic structure of our current generalJapanese grammar is as follows.
There are four maingroups of rules, covering NP, PP, VP and CLAUSEstructure respectively.
The NP and PP rules each as-sign a sortal type to the head constituent, based onthe domain-specific sortal constraints defined in thelexicon.
VP rules define the complement structureof each syntactic class of verb, again making use ofthe sortal features.
There are also rules that allowa VP to combine with optional adjuncts, and ruleswhich allow null constituents, in particular null sub-jects and objects.
Finally, clause-level rules form aclause out of a VP, an optional subject and optionaladjuncts.
The sortal features constrain the subjectand the complements combining with a verb, but thelack of constraints on null constituents and optionaladjuncts still means that the grammar is very loose.The grammar specialization mechanism flattens thegrammar into a set of much simpler structures, elim-inating the VP level and only permitting specific pat-terns of null constituents and adjuncts licenced bythe training corpus.We will demo several different versions of theJapanese-input medical speech translation system,differing with respect to the target language andthe recognition architecture used.
In particular, wewill show a) that versions based on the specializedJapanese grammar offer fast and accurate recogni-tion on utterances within the intended coverage ofthe system (Word Error Rate around 5%, speed un-der 0.1?RT), b) that versions based on the originalgeneral Japanese grammar are much less accurateand more than an order of magnitude slower.ReferencesP.
Bouillon, M. Rayner, N. Chatzichrisafis, B.A.
Hockey,M.
Santaholma, M. Starlander, Y. Nakao, K. Kanzaki,and H. Isahara.
2005.
A generic multi-lingual opensource platform for limited-domain medical speechtranslation.
In In Proceedings of the 10th Conferenceof the European Association for Machine Translation(EAMT), Budapest, Hungary.S.
Knight, G. Gorrell, M. Rayner, D. Milward, R. Koel-ing, and I. Lewin.
2001.
Comparing grammar-basedand robust approaches to speech understanding: a casestudy.
In Proceedings of Eurospeech 2001, pages1779?1782, Aalborg, Denmark.A.
Lavie, C. Langley, A. Waibel, F. Pianesi, G. Lazzari,P.
Coletti, L. Taddei, and F. Balducci.
2001.
Ar-chitecture and design considerations in NESPOLE!
:a speech translation system for e-commerce applica-tions.
In Proceedings of HLT: Human Language Tech-nology Conference, San Diego, California.MedSLT, 2005. http://sourceforge.net/projects/medslt/.As of 9 June 2005.R.
Moore.
1998.
Using natural language knowledgesources in speech recognition.
In Proceedings of theNATO Advanced Studies Institute.Phraselator, 2005. http://www.phraselator.com/.
As of 9June 2005.M.
Rayner, B.A.
Hockey, and J. Dowding.
2003.
Anopen source environment for compiling typed unifica-tion grammars into speech recognisers.
In Proceed-ings of the 10th EACL (demo track), Budapest, Hun-gary.Regulus, 2005. http://sourceforge.net/projects/regulus/.As of 9 June 2005.Sehda, 2005. http://www.sehda.com/.
As of 9 June 2005.W.
Wahlster, editor.
2000.
Verbmobil: Foundations ofSpeech-to-Speech Translation.
Springer.27
