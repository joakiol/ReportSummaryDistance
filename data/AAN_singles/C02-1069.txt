Effective Structural Inference for Large XML DocumentsJason Sankey Raymond K. WongSchool of Computer Science & EngineeringUniversity of New South WalesSydney 2052, AustraliaAbstractThis paper investigates methods to automaticallyinfer structural information from large XML doc-uments.
Using XML as a reference format, we ap-proach the schema generation problem by applica-tion of inductive inference theory.
In doing so, we re-view and extend results relating to the search spacesof grammatical inferences for large data set.
Weevaluate the result of an inference process using theconcept of Minimum Message Length.
Comprehen-sive experimentation reveals our new hybrid methodto be the most effective for large documents.
Finallytractability issues, including scalability analysis, arediscussed.1 IntroductionGiven the recent emergence of XML, there are manyproblems that must be solved to facilitate its mosteffective use.
Amongst the most important of theseinvolves addressing the differences between the new,loosely formatted data and traditional, structureddata.
Clearly, the ability to infer the structure ofXML documents would be a very powerful tool forbridging the gap.
Given such a method of infer-ence, XML information may be handled in more ef-fective ways without loosing the advantage of flex-ibility.
There are still many possible approachesto the problem, and correspondingly many suitableoutcomes.
For this reason it is best to firstly de-rive a suitable measure for the quality of an inferredDTD.
As will be seen in section 3.1, determining therelative utility of content models is a task in itself.This paper extends the hybrid method from our pre-vious work (Sankey & Wong 2001) to automaticallyinfer structural information from large XML docu-ments.
Comprehensive experimentation reveals theproposed method to be the most effective for largedocuments.The paper is presented in the following fashion.Section 2 provides details of previous work in thisand related fields.
Section 3 provides an overviewof our solution method, followed by details of theinference algorithms in section 4.
Section 5 includescomprehensive testing for large models and section6 discusses the tractability considerations, followedby conclusions in section 7.2 Previous WorkThe inference of structure in XML information is arelatively new area of research.
However, there areseveral closely related topics that have been studiedfor a longer period.
Many of these topics fall intothe general field of Inductive Inference, more specif-ically the sub-field of Grammatical Inference.
Thissub-field is concerned with the theory and methodsfor learning grammars from example data.
For fur-ther details concerning the field of Grammatical In-ference the reader is referred to the surveys of Pitt(Pitt 1989) and Sakakibara (Sakakibara 1997).
Inaddition, there has also been prior research into au-tomatic recognition of document structure.
Earlierattempts by (Chen 1991), (Fankhauser & Yu 1994)and (Shafer 1995) in similar problem spaces all usesolutions based on heuristic methods.
In each case,the generalisation step involves searching for sim-ilar patterns in the data and combining the cor-responding structural information.
Although thesetechniques may work well in some cases, their ap-plicability is restricted by a lack of generality.
Theapproaches of (Ahonen 1996) and (Young-Lai 1996)are more powerful in concept.
In both of theseworks, methods derived from theoretical grammat-ical inference are applied to the problem of infer-ring DTD content models.
The first known appli-cation of such theory to this problem, in (Ahonen1996), makes use of a characterising method to infera subset of the regular language class.
The alterna-tive solution in (Young-Lai 1996) makes use of anadapted stochastic method.
In both cases, the re-sults are post-processed to produce more desirablecontent models.
Unfortunately, neither paper inves-tigates or compares other methods.
It is partly forthis reason that these methods have been includedin this study for comparisons.
The more recent pa-per of Garofalakis et al(Garofalakis et al 2000)is very similar to this work in terms of motivationand the application of information theory.
However,their inference algorithms are based upon direct gen-eralisation and factoring of regular expressions, withinformation theoretic principles used to choose a fi-nal result from a pool of candidates.
In contrast,we propose a hybrid method which employs variousprinciples throughout the inference process, with theaim of producing a more general method.3 Overview of SolutionThe major grammatical inference methods fall intoa few general categories.
One of these categories in-cludes a family of algorithms known as state mergingmethods.
A state merging method typically beginsby constructing what is known as a Prefix TreeAutomaton (PTA) from the positive examples ofthe language to be inferred.
If we let the set of pos-itive examples be R+, then the prefix tree for R+(PTA(R+)) may be constructed as follows.
We be-gin with an automaton that simply accepts the firststring in R+.
Then we iterate over the rest of thestrings in R+ and for each one follow transitionsin the automaton for as many symbols as possible.When a symbol is found that does not match a validtransition, the PTA is augmented with a new pathto accept the rest of the string.
In particular, aProbabilistic Finite State Automaton (PFSA)is merely an automaton with probabilities associatedwith each transition and final state.
This is impor-tant both for some of the inference methods and forevaluating the quality of solutions.3.1 Evaluating a SolutionTo measure the quality of the inferred DTD, we usethe concept of Minimum Message Length (MML)(Georgeff & Wallace 1984).
In particular, we adaptthe formula developed for PFSA (Raman 1997) asbelow:MML(A) =N?j=1{log2(tj ?
1)!
(mj ?
1)!
?mji=1(nij ?
1)!
}+M(log2 V + 1) + M ?
log2 N?
log2(N ?
1)!where:?
N is the number of states in the PFSA?
V is the cardinality of the alphabet plus one?
tj is the number of times the jth state is visited?
mj is the number of arcs from the jth state (plusone for final states)?
m?j is the number of arcs from the jth state (nochange for final states)?
nij is the frequency of the ith arc from the jth state?
M is the sum of all mj values and?
M ?
is the sum of all m?j values3.2 ImplementationOne of the goals of this work was to both pro-duce new inference methods and make comprehen-sive comparisons with existing techniques.
This en-tailed a significant amount of implementation thatconsists of several modules to perform stages of theinference process.
The most important stage in-volves PTA generalisation using the inference meth-ods.
These methods fall into two broad categories,which are labelled generalisation and optimisationin the implementation.
The first of these consists ofthe Merge methods with its pseudo-code shown inalgorithm 1.Algorithm 1 GeneralisePTAInput: A PTA A to be generalised, a merge crite-rion criterionOutput: The generalised form of AMethod:1. repeat2.
for all pairs (s1, s2) of states in A do3.
if criterion(s1, s2) then4.
A.merge(s1, s2)5. criterion.forcedMerges(A)6. if criterion.determinise() then7.
determinise(A)8. end if9.
end if10.
end for11.
until no more merges are possible12.
if not criterion.determinise() then13.
determinise(A)14. end if15.
return AHere the merge criterion determines the actual be-haviour of the inference procedure.
For each methodbelonging to the merge family, a merge criterionclass is derived from a base interface.
The mergecriterion is allowed to make forced merges after aninitial merge is decided (see line 5), which may benecessary to fit the semantics of a method, or may bemore efficient.
Also, merge criteria may decide if thePFSA is determinised after every merge (lines 6?8)or only at the end of the inference process (lines 12?14).
Determinisation itself is performed by mergingof states, as opposed to the traditional algorithms.The alternative inference methods all apply optimi-sation techniques to try and minimise the MML ofthe PTA.
These algorithms vary significantly in im-plementation, ruling out the possibility of buildingthem around the same core algorithm.4 Inference Algorithms4.1 Reference MethodsSeveral previously applied methods were imple-mented to evaluate their relative performance.
Twosuch algorithms are those applied by Ahonen in(Ahonen 1996), the first known paper to addressDTD generation using tradition grammatical infer-ence methods.
These methods are theoretically ap-pealing, as they guarantee to infer languages fallingwithin certain language classes.
These classes aretermed k-contextual and (k, h)-contextual, so namedas they assume the structure to be inferred to havelimited context.
It is not clear whether this assump-tion is valid in practice, however.
Another methodapplied to DTD generation ((Young-Lai 1996)), isderived from more recent work in grammatical in-ference.
The base algorithm is known as Alergia,introduced in (Carrasco & Oncina 1994b).
The cri-terion for state equivalence in Alergia is based uponobserved frequencies of transitions and finalities of apair of states.
As with the methods of Ahonen, Aler-gia has strong theoretical appeal.
Again, though, weare interested in practical performance.
Further tothe methods described above, we devised two ba-sic optimisation strategies against which to bench-mark the results of our main algorithm.
The firstof these, termed the Greedy method, is a straight-forward steepest-descent algorithm which employsincremental MML calculation to optimise a PTA.Along with this a weighted stochastic hill-climbingmethod was implemented, which also used incremen-tal MML calculation.
These two methods illustratethe need for more sophisticated optimisation algo-rithms.4.2 The sk-strings MethodThe sk-strings method actually consists of a familyof algorithms, described in (Raman & Patrick 1997)and in more detail in (Raman 1997), of which fivewere implemented.
The basis of these algorithms isan extension upon the k-tails heuristic of Biermannand Feldman (Biermann & Feldman 1972), whichin turn is a relaxed variant of the Nerode equiva-lence relation.
Under the Nerode relation, a pairof states are equivalent if they are indistinguishablein the strings that may be accepted following them.The k-tails criterion relaxes this to only consideringthese strings (tails) up to a given length (k.) Thesk-strings method is extended using stochastic au-tomata, and considers only the top s percent of themost probable k-strings.
The k-strings differ fromk-tails in that they are not required to end at a fi-nal state, unless they have length less than k. Theprobability of a k-string is calculated by taking theproduct of the probabilities of the transitions exer-cised by that k-string.4.3 Ant Colony OptimisationThe Ant Colony Optimisation (ACO) meta-heuristicis a relatively new optimisation technique.
First de-scribed in (Dorigo et al 1991), the method uses apositive feedback technique for searching in a simi-lar manner to actual ants.
In biological experimentsit was revealed that insect ants cooperated in find-ing shortest paths by leaving pheromone trails asthey walked.
An ant traveling back and forth alonga short path increases the pheromone level on thatpath more rapidly than an ant using a longer path,thus influencing more ants to take the shorter route.The effect is then self-reinforcing until eventually allants will choose the shorter path.
ACO algorithmsmimic this technique using artificial ants to searchout good solutions to optimisation problems.The ACO heuristic operates over several iterationsto allow the positive feedback of the pheromones totake effect.
In each iteration, the artificial ants nav-igate the search space using only a simple heuris-tic, but as they move they leave pheromones on thetrail they follow.
In some variants, including the oneused in this work, the pheromone placement is de-layed until the end of an iteration, when all ants havecompleted a full walk.
At this point the amount ofpheromone assigned to each ant is weighted with re-spect to the quality of the solution it found.
Thusmoves involved in higher quality solutions are morelikely to be chosen by ants in future iterations.
Al-though ants acting by themselves are only capable offinding relatively poor solutions, working in cooper-ation they may approach higher quality ones.
Aftera certain number of iterations without improvementto the best solution found the algorithm terminates.4.4 The Proposed Hybrid MethodThe sk-ANT Heuristic: The motivation for thisnew heuristic was to create a method that would besuccessful for a variety of input data sizes by com-bining the best features of both the sk-strings andACO techniques.
One consideration was to first runthe sk-strings algorithms, and then use the resultsto seed the ACO optimisation.
However, this ap-proach suffers from several problems.
Firstly, it isnot practical to attempt all possible combinationsof both algorithms.
Thus we would be required tochoose a limited number of models resulting fromthe sk-strings technique to seed the second stage ofthe process.
The simplest way to achieve this wouldbe to choose the best models, up to a reasonablenumber.
These models will not necessarily lead tothe best results, though, as they may have alreadybeen over-generalised.
More importantly, by lettingthe sk-strings methods run to completion we wouldlose many of the advantageous aspects of the ACOmethod.
Most notably, its willingness to explore agreater breadth of the search space would be missed.The new method thus incorporates both the sk-strings and ACO heuristics at each step of the infer-ence process.
It is most easily described as a mod-ified version of the ACO technique with the antsguided by an sk-strings criterion.
The guiding ismade progressively weaker as the model becomessmaller, to allow the advantages of the ACO methodfor smaller models to take effect.
The key of this newmethod is a new algorithm for the ant move selec-tion as shown in algorithm 2.
In particular in line 4,a merge must pass the sk-strings criterion to be con-sidered.
The outer while loop on line 2 and if state-ment on line 11 combine to progressively weaken thesk-strings criterion when it has become too strict.Eventually the criterion will be weak enough to letall merges pass, and the algorithm will behave iden-tically to the original version.Algorithm 2 sk-antMoveSelectorInput: A set of all state pairs merges, an antheuristic heuristic, an ant weighting functionweighting, a pheromone table pheremones andan sk-strings criterion skCriterion.Output: A state pair representing the chosenmerge.Method:1. choices?
[ ]2. while choices.size() = 0 do3.
for merge in merges do4.
if skCriterion(merge) then5.
h?
heuristic(merge)6. p?
pheremones[merge]7. value?
weighting(h, p)8. choices.add((value, merge))9. end if10.
end for11.
if choices.size() = 0 then12.
skCriterion.weaken()13. end if14.
end while15.
return stochasticChoice(choices)5 Experimental ResultsTo fulfill our goal of comprehensive testing, we ap-plied three sets of tests.
The first two of these usedgenerated data, which allowed systematic experi-mentation on widely varied input.
The other testset consisted of a few models chosen from real data,to illustrate the nature of the models inferred by thesk-ANT method.
In each test the algorithms wererun with a range of input parameters, and the resultsfrom each run combined.0 20 40 60 80 100ACOAlergiaGreedyk-conk-h-consk-ANTsk-ALLsk-ANDsk-LAXsk-ORsk-STRICTsk-XENStochasticAlgorithmFrequency from 100 TrialsBest AverageBest OverallFigure 1: Success rates for large models5.1 Inference of Large ModelsThe larger data set alo consisted of 100 samplefiles generated from random PFSA.
In this case thePFSA had a maximum of 20 states with an alpha-bet cardinality of 8.
For each of these a total of 25strings were generated giving an average PTA sizeof 143.38 states.
On average the inferred modelswere larger than for the small data set, though theyranged from an average of 1.23 to 142.74 states fordiffering algorithms.Figure 1 shows the success rates of each algorithmin inferring models with the lowest MML values.
Foreach algorithm, two results have been shown.
Thefirst is the frequency of inferring the best model over-all, by choosing the best of the algorithm?s attempts.The second is the frequency of obtaining the bestaverage performance, derived by averaging all of thealgorithm?s attempts before ranking.
The best over-all performance is most important, whilst the bestaverage indicates stability across different input pa-rameters.
In particular, sk-ALL denotes the imple-mentation of sk-strings with five variants from itsfamily (refer to (Raman 1997) for details of differentvariants).
The results show the poor performanceof both the Stochastic and ACO methods, and theclear dominance of the sk-ANT heuristic.
The poorperformance of the ACO and Stochastic methods islikely due to the large search space.
The heuris-tic guidance used in the sk-ANT method clearlyovercomes this difficulty, producing the best results.Other poor algorithms are desirable due to their sim-plicity and efficiency, but are lacking in quality ofsolutions found.The deviations from the best model were calcu-lated for each algorithm, as presented in table 1.The numbers were derived from the difference be-tween the MML values of the best model inferredby a given algorithm as compared with the bestmodel overall.
The hybrid sk-ANT technique againAlgorithm Average WorstDeviation (%) Deviation (%)ACO 31.57 154.87Alergia 32.44 86.58Greedy 173.46 574.48k-contextual 30.39 84.15(k, h)-contextual 21.57 58.57sk-ANT 2.81 28.52sk-ALL 3.15 20.51Stochastic 36.40 159.11Table 1: Deviation from the best model inferred(large data set)proved to be the best in terms of average devia-tion at 2.81%.
Thus the newer method is preferableif only one choice is allowed.
On the other hand,the sk-ALL heuristic was better in terms of worst-case performance, though the deviation is still ratherhigh.
Again, some applications may need to employa combination of difference methods to achieve bet-ter worst-case results.The experiments have revealed many interestingpoints.
Firstly, the k-contextual, (k, h)-contextualand Alergia methods previously applied to this prob-lem have been shown to perform poorly.
Althoughthe papers describing their use extend the algo-rithms and employ refining operations, it appearsthat other methods are a more appropriate startingpoint.
We have also seen that the simple Greedy andStochastic methods cannot match the performanceof more complicated techniques.
This highlights thedifficulties inherent in the search space of grammat-ical inference.
The sk-strings method developed in(Raman 1997) has proven to be much more effective,provided combined results from all of the heuristicsare used.
A major contribution to its success may liein its use of statistical data in the inference process.The ACO algorithm?s failure on large testing dataled to a new method which we have named sk-ANT.This new hybrid algorithm proved to be the mosteffective by a considerable margin, and is thus thealgorithm of choice.
Where worst case guaranteesare required, we recommend using combined resultsof both the sk-ANT and sk-ALL methods.5.2 Real Data Set: Webster?s p ElementThe real data set we used was an extract of the dig-ital form of the 1913 Webster Unabridged Dictio-nary.
The dictionary format is almost compatiblewith SGML, and after some preprocessing we wereable to extract the structural information in XMLformat.
Only a small subset of the entire dictionarywas used, due to its overwhelming size.
We selectedthe paragraph element ?p?, which is used to group to-gether the information pertaining to each dictionaryword, for the experiment.
This particular elementwas chosen as it exhibits a rather complex and vari-able structure.
This is in contrast to the structure1718i (1)1 (96)cd (1)i (4)7sd (1)8wf (1)def (14) pos (1)14def (1)i (5)9 (2)u (2)def (9)u (8)grk (40)4 (1)i (78)5cd (1)13i (1)16cd (1)11 i (1)15def (8)sd (8)2def (2)pos (83)i (1)def (65)grk (8)sd (8)i (39)12plw (4)6i (2)0 (3)point26 (1)col (2)hw (86)sn (7)blockquote (2)3i (2)10 (1)i (2)grk (4) u (1)col (1)Figure 2: Best model for the ?p?
elementof the other models chosen from real data sets, withthe intent being to stretch the capabilities of the sk-ANT method.The inferred model is shown in figure 2.
Observethe dominant path through states 0, 2, 9, 4 and 1.
Itis most important that this path is preserved, withthe rest of the structure accounting for exceptionsand noise in the data.
Such irregularity is a fact oflife when dealing with semi-structured data such asXML.6 Tractability ConsiderationsThe goals of grammatical inference such as the struc-tural inference presented in this paper require notonly that our methods be effective, but also thatthey are useful in practice.
For this reason, we inves-tigate the complexity of our new algorithm of choice,namely sk-ANT.
Coverage of the tractability of theother algorithms may be found in the original papersin which they are presented ((Ahonen 1996), (Car-rasco & Oncina 1994b) and (Raman 1997).)
In ourtesting, we found that the sk-ANT method was themost expensive in terms of running time.
This didnot provide an obstacle for the experimental data,but may become important when working with verylarge PTA (several thousand states) or under tighttime constraints.
Fortunately, in practice, a modelfor typical large XML documents would be normallyfewer than one hundred states.By analysing the sk-ANT algorithm, we foundthat the most important factor is the number ofmerges considered at each iteration of the inferenceprocess.
At every step, each one of the possible statepairings is considered for merging.
At a stage when0204060801001201400 20 40 60 80 100 120 140 160CPUtime(secs)PTA sizesk-ANTcubicFigure 3: Empirical measure of sk-ANT complexitythe PFSA being inferred has r states, there are (r2)such merges.
This may be expanded to give:r(r ?
1)2merges considered.
As the algorithm proceeds fromthe full number of states, say n, until there is justone state, the total number of merges considered is:2?r=nr(r ?
1)2These merges are considered by all ants, introducingan extra constant factor.
This factor does not influ-ence the asymptotic complexity, however, which isclearly O(n3).
Although not unmanageable, thereare applications for which this complexity may betoo great.6.1 Measured ScalabilityTo complement the theoretical analysis, we also per-formed a simple empirical test to measure the per-formance of the algorithm in practice.
The test wasperformed on PTA with sizes ranging from 10 to 150states, with several of each size.
Keeping in line withthe experimental results shown earlier, we used thesame range of parameters and averaged the resultsfor each PTA size.Figure 3 shows a graph of the obtained timing val-ues.
The points give the actual values for each PTAsize, with a bezier approximation shown using a solidline.
For comparison, we have also included a cubicfunction, shown with the dotted line.
Clearly theanalytical result corresponds well to the empiricalmeasurement, with the cubic function proving to bea reasonable approximation of the points.
Note thatthe individual CPU times shown are not of partic-ular interest, as the primary goal of the implemen-tation was not efficiency.
Profiling has shown thatthere is scope for improvement, though of course theasymptotic growth will remain the dominant factor.6.2 DiscussionThe analytical and empirical analysis of the sk-ANTalgorithm have both shown it to have asymptoticcomplexity of O(n3).
In practice, this is quite ac-ceptable for a wide range of applications.
Where itis not acceptable, there are several alternatives.
Asimple one would be to employ one of the more ef-ficient algorithms until the PFSA inferred reaches asmall enough size to seed the sk-ANT method.
Amore complicated method may use a modified sk-ANT heuristic that employs approximations, andperhaps limits the size of the neighbourhood exam-ined by each individual ant.
Such a method may beable to reduce the complexity to O(n2), though ithas not been thoroughly investigated.
Cases wherelarge amounts of data are involved can often be bro-ken down into several sub-problems to make themmanageable.
For instance, in a database where doc-uments are drawn from many sources, it may be ap-propriate to treat each data source separately.
In-deed, this is a requirement for many applications.In other cases, it is feasible to take a sample of thedata to use for inference, as the sk-ANT algorithmhas been shown to perform well on sparse examples.7 ConclusionWe have addressed the problem of structural infer-ence for large XML documents.
In doing so we beganby motivating the research and reviewing the litera-ture.
The use of Minimum Message Length as a mea-sure for the quality of inferred content models hasbeen introduced, adapted from work in related fields.This measure has proven to be an appropriate anda vast improvement over previous subjective tech-niques.
We have also presented the first wide spreadcomparison of different grammatical inference tech-niques.
This involved the implementation of the ex-isting Alergia, k-contextual, (k, h)-contextual andsk-strings methods, as well as the creation of newalgorithms.
The new methods include the Greedystrategy, the ACO meta-heuristic, Stochastic HillClimbing and our proposed, hybrid sk-ANT heuris-tic.
Comprehensive experimental data revealed thatour proposed method was the most effective andmost stable of the methods, followed by the sk-strings heuristic.
From this work we may concludethat the problem of structural inference is both im-portant and tractable.
For current applications werecommend use of the sk-ANT technique.
The useof MML as a quality measure is also recommended,due to its generality and objectivity.ReferencesH Ahonen.
Generating Grammars for Structured Docu-ments Using Grammatical Inference Methods.
ReportA-1996-4, Department of Computer Science, Univer-sity of Finland, 1996.A W Biermann and J A Feldman.
On the synthesis offinite-state machines from samples of their behaviour.IEEE Transactions on Computers, 21:591?597, 1972.R C Carrasco and J Oncina (editors).
Grammatical In-ference and Applications.
Proceedings of the SecondInternational Colloquium on Grammatical Inference(ICGI-94), Lecture Notes in Artificial Intelligence 862,Springer-Verlag 1994.R C Carrasco and J Oncina.
Learning Stochastic Regu-lar Grammars by Means of a State Merging Method.In R C Carrasco and J Oncina (editors) (Carrasco &Oncina 1994a).J Chen.
Grammar Generation and Query Processing forText Databases.
Research proposal, University of Wa-terloo, January 1991.M Dorigo, V Maniezzo and A Coloni.
Positive Feedbackas a Search Strategy.
Technical Report 91?016, Di-partmento di Elettronica, Politecnico di Milano, Italy,1991.P Fankhauser and Y Xu.
Markitup!
An Incremental Ap-proach to Document Structure Recognition.
ElectronicPublishing - Origination, Dissemination and Design,6(4):447?456, 1994.M Garofalakis, A Gionis, R Rastogi, S Seshadri and KShim.
XTRACT: A System for Extracting DocumentType Descriptors from XML Documents.
In Proceed-ings of SIGMOD 2000, pages 165?176, Dallas, TX,2000.M P Georgeff and C S Wallace.
A General Selection Cri-terion for Inductive Inference.
In T O?Shea (editor),ECAI-84: Advances in Artificial Intelligence, pages473?481.
Dordretch: Elsevier, 1984.L Pitt.
Inductive Inference, DFA?s and ComputationalComplexity.
In J Siekmann (editor), Proceedings ofthe International Workshop AII ?89, Lecture Notesin Artificial Intelligence 397, pages 18?44, Springer-Verlag 1989.A V Raman and J D Patrick.
The sk-strings methodfor inferring PFSA.
In Proceedings of the 14th Inter-national Conference on Machine Learning, ICML?97,1997.A V Raman.
An Information Theoretic Approach to Lan-guage Relatedness.
PhD Thesis, Massey University,1997.Y Sakakibara.
Recent Advances in Grammatical In-ference.
Theoretical Computer Science Volume 185,Number 1, October 1997.J Sankey and R K Wong.
Structural Inference forSemistructured Data.
In Proceedings of the ACM In-ternational Conference on Information and KnowledgeManagement, CIKM?01, 2001.K Shafer.
Creating DTDs via the GB-engine and Fred.Available at http://www.oclc.org/fred/, 1995.M D Young-Lai.
Application of a Stochastic Grammati-cal Inference Method to Text Structure.
Master?s the-sis, Computer Science Department, University of Wa-terloo, 1996.
