Proceedings of the NAACL HLT 2010 Fifth Workshop on Innovative Use of NLP for Building Educational Applications, pages 57?65,Los Angeles, California, June 2010. c?2010 Association for Computational LinguisticsGenerating Quantifiers and Negation to Explain Homework TestingJason Perry and Chung-chieh ShanRutgers UniversityDepartment of Computer ScienceAbstractWe describe Prograder, a software package forautomatic checking of requirements for pro-gramming homework assignments.
Prograderlets instructors specify requirements in naturallanguage as well as explains grading results tostudents in natural language.
It does so usinga grammar that generates as well as parses totranslate between a small fragment of Englishand a first-order logical specification languagethat can be executed directly in Python.
Thisexecution embodies multiple semantics?bothto check the requirement and to search for ev-idence that proves or disproves the require-ment.
Such a checker needs to interpret andgenerate sentences containing quantifiers andnegation.
To handle quantifier and negationscope, we systematically simulate continua-tion grammars using record structures in theGrammatical Framework.1 IntroductionThe typical programming assignment in a computer-science course comes with not only a problem de-scription but also correctness and stylistic require-ments such as(1) Every source file compiles and has comments,and a text file mentions every source file andevery header file.Although the requirements do not usually specifyexactly how the students?
work will be judged, theymake it much easier to grade and respond to the sub-mitted work.
Many requirements can be checkedautomatically by computer, and often they are?perhaps even right after each student uploads theirwork so that the student can revise their work usingthe immediate feedback.This common workflow is wanting in two aspects.First, the requirements are both specified to the stu-dents in English and coded into a testing harness bythe course staff.
Keeping the two versions is a hasslethat involves much boilerplate text as well as boil-erplate code.
Second, students rightfully demandcomprehensible explanations when their work is re-jected by the requirement tester.
It is tricky to codeup a tester that produces error messages neither tooterse nor too verbose, when one student might forgetto comment just one file and another might not knowthe lexical syntax of comments at all.A natural approach to improve this workflow,then, is to specify the requirements in a formal lan-guage and to implement an interpreter for the lan-guage that produces explanations.
Because manyinstructors, like students, are averse to learning newlanguages, we pursue the use of a controlled subsetof English as that formal language.
In short, we aimto produce a programming-assignment tester thatallows instructors to specify requirements for pro-gramming assignments in natural language, checksthose requirements automatically by executing com-mands on the submitted assignment files, and gen-erates for the student a natural-language explanationof the results.
For example, in an introductory pro-gramming class, a professor may write the specifi-cation sentence (1).
The system would then gradeall students?
programming assignments according tothese criteria, and return individualized explanations57to students like(2) Credit was lost because bar.c did not compileand no text file mentioned the files foo.h andbaz.h.As this example illustrates, the tester needs to in-terpret and generate sentences with quantifiers andnegation.
Although the interpretation of quantifiersand negation is a traditional research area in com-putational linguistics (VanLehn, 1978; Hobbs andShieber, 1987; Moran, 1988), their generation ismuch less studied (Gailly, 1988).
Even if our systemwere to compose explanations entirely from the in-put specification sentences and their negation, it can-not negate a specification sentence merely by addingor removing verbal auxiliaries: the negation of ?asource file defines main()?
is not ?a source file doesnot define main()?.1.1 ContributionsWe have built Prograder, a rudimentary program-ming-assignment tester that correctly interprets andgenerates a small fragment of English that includesquantifiers and negation.
This paper describes thearchitecture of Prograder.
Our implementation usesa declarative grammar that simultaneously supportsinterpretation and generation by relating Englishphrase structure to type-logical semantics.
This pa-per details the new techniques we use in this gram-mar to represent quantifier scope and De Morgan du-ality in a tractable way.Prograder also lets us investigate how to make acomputer program explain its own execution.
Theconcerns for a tester that must justify its output tostudents are not merely grammatical, but involve thesemantics and pragmatics of summarization and jus-tification.
For example, when is it semantically cor-rect to combine entities within an NP, as in ?foo.hand baz.h?
above?
When is an explanation prag-matically enough for a student who has a right toknow why she lost credit on a programming assign-ment?
Which pieces of evidence must be stated andwhich are better left out?
We plan to study thesequestions within type-logical semantics as well.1.2 Organization of This PaperIn Section 1, we have introduced the problem andoutlined the contributions of the research carried outin building Prograder.
In Section 2, we give a high-level overview of the architecture of the system, in-cluding the representation of natural-language syn-tax and type-logical semantics, as well as the proce-dure of operation.
Section 3 describes Prograder?schecking procedure and how it generates explana-tions in tandem with the checking.
In Section 4,we begin to describe the details of the grammati-cal framework that allows us to handle bidirectionaltranslation between English and the logical form.Continuing in Section 5, we discuss the handlingof negation and quantifier scoping by means of arecord-based implementation of continuation gram-mars.
Section 6 reviews the architecture of the sys-tem with additional implementation details, and Sec-tion 7 concludes with future work.2 System OverviewWe explain the architecture of our Prograder sys-tem using a simplified example.
Suppose that theinstructor specifies the requirement that(3) Every source file compiles.Prograder begins by parsing this sentence into an ab-stract syntax tree:(4) ApplySEverySourceFile CompilesInterpreting this tree compositionally gives themeaning of the sentence:(5) everysourcefile(lambda x:compiles(x))On one hand, this expression is a formula in pred-icate logic.
In general, each requirement specifi-cation is a sentence, whose truth value is deter-mined by checking a single student?s programmingassignment.
We use the types of Montague gram-mar (1974), which are the base type of entities e, thebase type of propositions t, and function types no-tated by !.
Our logical language is defined by adomain-specific vocabulary of typed predicates andentities (Hudak, 1996).
Naturally, the files submit-ted by the student are entities.58For example, the unary predicates compiles andhascomments have the type e !
t, and the bi-nary predicate mentions has the type e!
e!
t.These predicates in our vocabulary represent vari-ous properties of submitted files that instructors maywant to check.
Logical connectives are also partof the vocabulary; for instance, and and or havethe type t !
t !
t, not_b has the type t !
t, andeverysourcefile has the type (e!
t)!
t. There-fore, the expression (5) has the type t, as do the ex-pressions(6) compiles("foo.c")(7) and(compiles("foo.c"),hascomments("bar.c"))On the other hand, the expressions (5?7) are exe-cutable Python code.
Prograder includes a libraryof Python functions such as everysourcefile,which iterates over the source files submitted, andcompiles, which invokes gcc.
As each student sub-mits their homework, we evaluate the expression (5)to check the requirement (3).
We use Python?s ownlambda abstraction and first-class functions to ex-press quantified statements.
For example, evaluating(5) invokes gcc on each source file submitted.Evaluation not only computes a Boolean value butalso yields a tree of evidence statements to justifythe result.
At the root of the tree is either the re-quirement (5) or its negation:(8) asourcefile(lambda x:not_b(compiles(x)))Each node?s children are the premises that togetherjustify the conclusion at that node.
For example, ifevery source file submitted by the student compilessuccessfully except one, then (8) would be justifiedby a sole child:(9) not_b(compiles("bar.c"))Prograder then parses each evidence statement intoabstract syntax:(10) ApplySASourceFile Not_VPCompilesApplySbar.c Not_VPCompilesFrom these trees, Prograder finally renders each ev-idence statement as an English clause:(11) A source file does not compile because bar.cdoes not compile.To summarize, Prograder?s steps of operation areas follows:1.
Parse the natural-language requirement state-ment into a phrase-structure syntax tree.2.
Produce a logical semantic representation fromthe syntax tree.3.
Execute the semantic representation to checkthe requirement and produce a semantic repre-sentation of each evidence statement.4.
Parse the evidence statements into phrase-structure syntax trees.5.
Produce natural-language explanation from thesyntax trees.From end to end, these steps operate on just threelevels of representation: the abstract syntax trees in(4) and (10) can be spelled out either in natural lan-guage (English) as in (3) and (11) or in predicatelogic (Python) as in (5?9).
Thus, Prograder inter-prets natural-language requirements and generatesnatural-language explanations using the same exe-cutable semantic representations.
In fact, it uses thesame grammar, as described in Section 4.3 Gathering Evidence while Testing TruthAs sketched above, evaluating a proposition gives aBoolean result along with a tree of evidence propo-sitions that justify that result.
That is, we representthe type t in Python as an ordered pair, not just aBoolean value.
This is straightforward for primitivefirst-order predicates.
For example, the compilesfunction, when invoked with the argument "foo.c",tries to compile foo.c, then either returns Truealong with a trivial evidence tree containing just theproposition compiles("foo.c"), or returns Falsealong with a trivial evidence tree containing justthe proposition not_b(compiles("foo.c")).
Inshort, we hold whether a file compiles to be self-evident.59The picture is more complex for logical connec-tives, especially higher-order functions such as thequantifier everysourcefile.
Ideally, the falsityof (3) should be justified by an explanation like(12) Not every source file compiles because foo.cand bar.c do not compile.Also, the explanation should be generated by com-posing the implementations of everysourcefileand of compiles, so that new quantifiers (?mostsource files?)
and predicates (?has comments?)
canbe added as separate modules.
For example, evaluat-ing the proposition not_b(compiles("foo.c"))first evaluates compiles("foo.c") then negatesthe Boolean while keeping the evidence the same.Prograder currently justifies quantified proposi-tions in the following compositional way.
Whenthe higher-order function everysourcefile is in-voked with the predicate argument p, it invokes pon each source file submitted and collects the result-ing Boolean-evidence pairs.
If any of the Booleanresults is False, then the overall Boolean result isof course also False.
This result is justified by anevidence tree whose root proposition is(13) not_b(everysourcefile(p))and whose subtrees are the evidence trees for all theFalse results.
(After all, the primary mode of ex-planation required in grading a programming assign-ment is to say why credit has been subtracted.)
Pro-grader then produces the serviceable explanation(14) Not every source file compiles because foo.cdoes not compile and bar.c does not compile.
(We are working on simplifying this explanationto (12).)
This process generalizes immediately topropositions with multiple quantifiers, such as(15) Every text file mentions a source file.everytextfile(lambda x:asourcefile(lambda y:mentions(y)(x)))For example, Prograder might explain that(16) Not every text file mentions a source file be-cause README mentions no source file.In sum, Prograder generates explanations in thesame process?the same sequence of function callsand returns?as it computes Boolean values.
In thisway, the checking process gains an additional inter-pretation as a process of gathering evidence for theexplanation.
The explanation itself is a tree structurecorresponding to the pattern of function calls in thecomputation; in fact, it is a proof tree for the require-ments specification statement (or its negation).
Onceall the evidence has been gathered, a textual versionof the explanation can be generated by traversing thetree and concatenating evidence statements, possi-bly using summarization techniques to make the ex-planation more concise.We have so far glossed over how English sen-tences, especially those with quantification andnegation such as (14) and (16), are parsed into andgenerated from logical representations.
The rest ofthis paper describes our principled approach to thisproblem, based on a consistent mapping betweensyntactic categories and semantic types.4 Using the Grammatical FrameworkWe relate natural language (English) to logical se-mantics (Python) using the Grammatical Framework(GF) of Ranta (2004).
GF is a mature system that al-lows linguists and logicians to define grammars forboth natural and formal languages using a Haskell-like syntax.
Once defined, the grammars can be usedfor parsing as well as generation (linearization) withno further programming.In GF, grammars are specified in two parts: an ab-stract grammar and a concrete grammar.
An abstractgrammar specifies the set of well-formed abstractsyntax trees, whereas a concrete grammar specifieshow to spell out abstract syntax as strings.
For exam-ple, an abstract grammar can admit the abstract syn-tax tree in (4) by specifying that EverySourceFileis an NP, Compiles is a VP, and ApplyS combinesan NP and a VP into an S:fun EverySourceFile: NP;fun Compiles: VP;fun ApplyS: NP -> VP -> S;A concrete grammar for English can then specifythat the linearization of EverySourceFile is a sin-gular (Sg) string,lin EverySourceFile = {s = "every source file"; n = Sg };the linearization of Compiles is a pair of strings,60lin Compiles = {s = { Sg => "compiles";Pl => "compile" } };and the linearization of ApplyS is a function thatcombines these two linearizations into the string (3).lin ApplyS NP VP = {s = NP.s ++ (VP.s !
NP.n) };Here ++ denotes string concatenation and !
denotestable lookup.Multiple concrete grammars can share the sameabstract grammar in GF, as in synchronous gram-mars (Aho and Ullman, 1969) and abstract catego-rial grammars (de Groote, 2002).
This sharing ismeant to enable multilingual applications, in whichthe same meaning representation defined by a sin-gle abstract grammar can be rendered into variousnatural languages by different concrete grammars.This separation into abstract and concrete gram-mars lets us use one concrete grammar to model En-glish and another to model the Python syntax of Pro-grader?s logical forms.
For example, the lineariza-tion of Compiles into Python is simply compiles,which can be combined with "foo.c" by the lin-earization of ApplyS to form compiles("foo.c").The system can thus parse a natural-language spec-ification into an abstract syntax tree using the firstconcrete grammar, then produce the correspondingsemantic representation using the second concretegrammar.
Since each concrete grammar can be usedfor both parsing and generation, the system can alsobe run in the other direction, to parse the semanticrepresentations of an explanation, then generate thatexplanation in natural language.Since the linearization compiles("foo.c") inPython is virtually isomorphic to its abstract syn-tax tree, one may wonder why we bother with thesecond concrete grammar at all.
Why not just ex-press the type-theoretical semantic structure in theabstract syntax and relate it to English in a sin-gle concrete grammar?
The answer is that usingtwo concrete grammars lets us represent quantifiermeanings and scope preferences.
Without the dis-tinction between abstract syntax and logical seman-tics, we would have to specify how to linearizeeverysourcefile and asourcefile so that thePython in (15) linearizes to the English.
Moreover,Prograder should disprefer the inverse-scope reading(17) asourcefile(lambda y:everytextfile(lambda x:mentions(y)(x)))for the same English sentence.
We do not see a wayto achieve these goals given GF?s limited support forhigher-order abstract syntax.
Instead, we keep ourgrammars first-order and let our abstract grammarexpress only the surface structure of English, wherequantifiers stay ?in situ?
just like proper names.Below we describe how even a first-order concretegrammar for semantic representations can representquantifier meanings and scope preferences.5 Quantifier Scope, Negation andContinuation GrammarsQuantifier scoping has long been a key source ofdifficulty in mapping natural language sentences tological forms.
Scope ambiguities arise even in rela-tively simple sentences such as (15), which any in-structor might be expected to generate in specifyingprogramming assignment requirements.
The scopeof negation is also problematic.
An algorithm forgenerating all possible quantifier scopings was de-tailed by Hobbs and Shieber (1987).
However, weneed a solution that prefers one highly likely defaultscoping, that supports both interpretation and gener-ation, and that is integrated with the type structureof our semantic representation.Compositional semantics based on continuations(Barker, 2002) can represent preferred scoping ofquantifiers and negation without the semantic type-shifting or syntactic underspecification (Hendriks,1993; Steedman, 1996; Bos, 1995; Koller et al,2003) that typically complicates interpreting andgenerating quantification.
The rough idea is to gen-eralize Montague?s PTQ (1974), so that every con-stituent?s semantic type has the form (   !
t)!
t:not only does every NP denote the type (e!
t)!
tinstead of e, but every VP also denotes the type((e!
t)!
t)!
t instead of e!
t. For example(as in PTQ),(18) ?foo.c?
denotes lambda c: c("foo.c")(19) ?every text file?
denoteslambda c:everytextfile(lambda x: c(x))61Analogously (but unlike in PTQ),(20) ?compiles?
denotes lambda c: c(compiles)(21) ?mentions a source file?
denoteslambda c:asourcefile(lambda x:c(mentions(x)))Recall from Section 4 that we model denotations asthe linearizations of abstract syntax trees.
Therefore,in GF, we want to specify linearizations likelin EverySourceFile =lambda c:everysourcefile(lambda x: c(x));lin Compiles = lambda c: c(compiles);to be combined by the linearization of ApplySlin ApplyS NP VP =NP(lambda n: VP(lambda v: v(n)));into the expression (5).In this last linearization, the innermost applicationv(n) means to apply the VP?s predicate meaningto the subject NP?s entity meaning.
The surround-ing NP(lambda n: VP(lambda v: ...)) lets aquantificational subject take wide scope over the VP.This general composition rule thus yields surfacescope to the exclusion of inverse scope.
In particu-lar, it equally well combines the denotations in (19)and (21) into the expression (15), rather than (17).In the present implementation of Prograder, the rulesall encode surface scope for the quantifiers.
A simi-lar linearization forms the VP denotation in (21) bycomposing a transitive verb and its object NP:lin ApplyVP VT NP =lambda c: NP(lambda n: c(VT(n)))The same machinery generalizes to handle posses-sives, ditransitive verbs, relative clauses, and so on.5.1 Simulating higher-order functionsAs shown above, denotations using continuationsare higher-order functions.
However, linearizationin GF does not allow higher-order functions?infact, the only ?functions?
allowed in GF are recordor table structures indexed by a finite set of parame-ters.
To keep parsing tractable, GF only lets stringsbe concatenated, not beta-reduced as lambda-terms;the one extension that GF makes to the context-freemodel is allowing argument suppression and repeti-tion.
In other words, GF cannot equate logical formsby beta-equivalence.
Therefore, we cannot just feedthe pseudocode above into GF to generate explana-tions.
This is an instance of the problem of logical-form equivalence (Shieber, 1993).Fortunately, because denotations using continua-tions are always of a certain form (Danvy and Filin-ski, 1992), we can simulate these higher-order func-tions using first-order records.
Specifically, we sim-ulate a higher-order function of the form(22) lambda c: sl c(sm) srby the triple of strings(23) { s_l = sl; s_m = sm; s_r = sr }in GF.
The middle string sm corresponds to the?core?
of the phrase, and the left and right stringssl;sr are those parts which may take scope over otherphrases.
For example, following the pseudocodeabove, we writelin EverySourceFile = {s_l = "everysourcefile ( lambda x :";s_m = "x";s_r = ")" };lin Compiles = {s_l = "";s_m = "compiles";s_r = "" };in our GF concrete grammar.
Continuing to followthe pseudocode above, we can also implement thelinearizations of ApplyS and ApplyVP to operate ontriples rather than the functions they simulate:lin ApplyS NP VP = {s = NP.s_l ++ VP.s_l ++VP.s_m ++ "(" ++ NP.s_m ++ ")" ++VP.s_r ++ NP.s_r };lin ApplyVP VT NP = {s_l = NP.s_l;s_m = VT.s ++ NP.s_m;s_r = NP.s_r };Here the linearization of the transitive verb VT con-sists of a single string s.This simulation is reminiscent of Barker andShan?s ?tower notation?
(2008).
In general, wecan simulate a n-level semantic tower by a tuple of622n  1 strings.
Overall, this simulation makes ushopeful that linearization in GF can be extended to abroad, useful class of higher-order expressions whilekeeping parsing tractable.5.2 Maintaining De Morgan dualsBoth to interpret requirements and to generate ex-planations, our system needs to deal with negationcorrectly.
Whether in the form of a negative quanti-fier such as ?no source file?
or a VP modifier such as?don?t?, negation takes scope.
(In the case of the de-terminer ?no?, the scope of negation is linked to thecontaining NP.)
We use continuations to account forthe scope of negation, as for all scope-taking.When scope ambiguities arise, negation exhibitsthe same preference for surface scope as other quan-tifiers.
For example, all of the sentences below pre-fer the reading where the subject takes wide scope.
(24) A source file doesn?t compile.
(25) A text file mentions no source file.
(26) No text file mentions a source file.The linearization of ApplyS shown above alreadycaptures this preference; we just need to specify newlinearizations with not_b in them.
The pseudocodelin NoSourceFile =lambda c:not_b(asourcefile(lambda x: c(x)));lin Not_VP VP =lambda c:not_b(VP(lambda v: c(v)));captures the fact that the negation of ?A source filecompiles?
is not (24) but ?No source file compiles?.To generate natural-sounding negations of sen-tences containing quantification, some simple logi-cal equivalences are necessary.
To take an extremeexample, suppose that Prograder needs to negate therequirement specification(27) Every text file mentions no source file.Strictly speaking, it would be correct to generate(28) Not every text file mentions no source file.However, it would be much more comprehensiblefor Prograder to report instead(29) A text file mentions a source file.One heuristic for preferring (29) over (28) is to useas few negations as possible.
But to apply thisheuristic, Prograder must first realize that (29) is acorrect negation of (27).
In general, our concretegrammar ought to equate formulas that are equiv-alent by De Morgan?s laws.
Unfortunately, GF canno more equate formulas by De Morgan equivalencethan by beta-equivalence.In lieu of equating formulas, we normalize them:we use De Morgan?s laws to move negations log-ically as far ?inside?
as possible.
In other words,we impose an invariant on our semantic represen-tation, that not_b applies only to atomic formulas(as in (8?9)).
This invariant is easy to enforce inour Python code for gathering evidence, because wecan rewrite each evidence statement after generatingit.
It is trickier to enforce the invariant in our GFconcrete grammar for semantic representations, be-cause (to keep parsing tractable) linearizations canonly be concatenated, never inspected and rewritten.Therefore, our linearizations must maintain formu-las alongside their De Morgan duals.Specifically, we revise the simulation described inthe previous section as follows.
The record(30) { spl = s+l ; spm = s+m; spr = s+r ;snl = s l ; snm = s m; snr = s r ;switched = False }represents a higher-order function of the form(31) lambda c: s+l c(s+m) s+rassuming that it is equivalent to(32) lambda c: not_b(s l not_b(c(s m)) s r )Dually, the record(33) { spl = s+l ; spm = s+m; spr = s+r ;snl = s l ; snm = s m; snr = s r ;switched = True }represents a higher-order function of the form(34) lambda c: s+l not_b(c(s+m)) s+rassuming that it is equivalent to(35) lambda c: not_b(s l c(s m) s r )For example, given the linearizations63lin NoSourceFile = {spl = "everysourcefile ( lambda x :";spm = "x"; spr = ")";snl = "asourcefile ( lambda x :";snm = "x"; snr = ")";switched = True };lin EverySourceFile = {spl = "everysourcefile ( lambda y :";spm = "y"; spr = ")";snl = "asourcefile ( lambda y :";snm = "y"; snr = ")";switched = False };lin ASourceFile = {spl = "asourcefile ( lambda x :";spm = "x"; spr = ")";snl = "everysourcefile ( lambda x :";snm = "x"; snr = ")";switched = False };(and an alphabetic variant of ASourcefile), Pro-grader uses the switched flags to deduce that oneway to negate ?Every source file mentions no sourcefile?
is ?A source file mentions a source file?.Our solution demonstrates that an existing gram-matical software package can express continuationgrammars.
While the record-based implementationis somewhat unwieldy when encoded in the gram-mar by hand, restricting ourselves to GF?s context-free rewrite grammars also ensures efficient parsing.6 Putting It All TogetherCurrently, our English grammar supports declarativesentences with a small vocabulary of transitive andintransitive verbs (?exists?, ?compiles?, ?has com-ments?, ?mentions?
), proper noun phrases referringto specific source files, noun phrases representingquantified nouns, and negations.Given that the grammars correctly specify logi-cal scoping and natural language syntax for parsingand generation, the Python code that implements re-quirement checking and evidence gathering is rela-tively straightforward.
As described above, the log-ical form of the requirements specification is exe-cutable Python, and their execution emits an evi-dence statement in the same logical language foreach check performed, in a tree structure.
Thusthe execution of the checking code is an evidence-gathering or proof-search process.
The evidencestatements are then translated to natural language bymeans of the two GF grammars.A Python ?glue script?
ties the Python and GFcomponents together and manages the dataflow ofthe end-to-end system.
This script provides a simplescanner and symbol table to replace file names withstandardized placeholders from the grammar.
Thevariables used in lambda expressions also need to berenamed in order to prevent conflicts.Here is a sample output of the system as it cur-rently runs:./runPrograder.py 'every source filecompiles and every source file hascomments'******************************RESULT: False, because:some source files don't compile andsome source files don't havecomments:"nowork2.c" doesn't compile"nowork.c" doesn't compile"nowork2.c" doesn't have comments"nowork.c" doesn't have comments7 Conclusions and Future WorkTo our knowledge, Prograder incorporates the firstimplementation of continuation-based semanticswithin a grammatical framework that supports ef-ficient parsing and generation.
Consequently, ourdeclarative grammar uniformly expresses quantifiermeanings and scope preferences.We want to see how far we can stretch a record-based grammar system such as GF to handle quan-tifiers and negation using continuations.
In the end,the boilerplate ingredients of our solution ought tobe automated, so as to combine the expressivity ofcontinuation-based semantics with the usability andefficiency of GF.
This will also make it easier to ex-pand the range of natural-language constructs thatthe system handles.
Of course, this developmentshould be driven by feedback from actual instructorsusing the system, which we also intend to obtain.Our second area of future work is the summa-rization of explanations.
We plan to use Prograderto investigate the semantics and pragmatics of sum-marization, and to search for underlying principlesbased on proofs and types.64ReferencesAlfred V. Aho and Jeffrey D. Ullman.
1969.
Syn-tax directed translations and the pushdown assembler.Journal of Computer and System Sciences, 3(1):37?56, February.Chris Barker and Chung-chieh Shan.
2008.
Donkeyanaphora is in-scope binding.
Semantics and Prag-matics, 1(1):1?46.Chris Barker.
2002.
Continuations and the na-ture of quantification.
Natural Language Semantics,10(3):211?242.Johan Bos.
1995.
Predicate logic unplugged.
In PaulDekker and Martin Stokhof, editors, Proceedings ofthe 10th Amsterdam Colloquium, pages 133?142.
In-stitute for Logic, Language and Computation, Univer-siteit van Amsterdam.Olivier Danvy and Andrzej Filinski.
1992.
Representingcontrol: A study of the CPS transformation.
Math-ematical Structures in Computer Science, 2(4):361?391, December.Philippe de Groote.
2002.
Towards abstract catego-rial grammars.
In Proceedings of the 40th AnnualMeeting of the Association for Computational Linguis-tics, pages 148?155, San Francisco, CA, July.
MorganKaufmann.Pierre-Joseph Gailly.
1988.
Expressing quantifier scopein French generation.
In COLING ?88: Proceedings ofthe 12th International Conference on ComputationalLinguistics, volume 1, pages 182?184.Herman Hendriks.
1993.
Studied Flexibility: Categoriesand Types in Syntax and Semantics.
Ph.D. thesis, In-stitute for Logic, Language and Computation, Univer-siteit van Amsterdam.Jerry R. Hobbs and Stuart M. Shieber.
1987.
An al-gorithm for generating quantifier scopings.
Compu-tational Linguistics, 13(1?2):47?63.Paul Hudak.
1996.
Building domain-specific embeddedlanguages.
ACM Computing Surveys, 28.Alexander Koller, Joachim Niehren, and Stefan Thater.2003.
Bridging the gap between underspecificationformalisms: Hole semantics as dominance constraints.In Proceedings of the 10th Conference of the EuropeanChapter of the Association for Computational Linguis-tics, pages 195?202, Somerset, NJ.
Association forComputational Linguistics.Richard Montague.
1974.
The proper treatment ofquantification in ordinary English.
In Richmond H.Thomason, editor, Formal Philosophy: Selected Pa-pers of Richard Montague, pages 247?270.
Yale Uni-versity Press, New Haven.Douglas B. Moran.
1988.
Quantifier scoping in theSRI core language engine.
In Proceedings of the 26thAnnual Meeting of the Association for ComputationalLinguistics, pages 33?40, Somerset, NJ.
Associationfor Computational Linguistics.Aarne Ranta.
2004.
Grammatical Framework: A type-theoretical grammar formalism.
Journal of FunctionalProgramming, 14(2):145?189.Stuart M. Shieber.
1993.
The problem of logical-formequivalence.
Computational Linguistics, 19(1):179?190.Mark J. Steedman.
1996.
Surface Structure and Inter-pretation.
MIT Press, Cambridge.Kurt A. VanLehn.
1978.
Determining the scope ofEnglish quantifiers.
Master?s thesis, Department ofElectrical Engineering and Computer Science, Mas-sachusetts Institute of Technology.65
