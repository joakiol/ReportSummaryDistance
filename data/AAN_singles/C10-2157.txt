Coling 2010: Poster Volume, pages 1373?1381,Beijing, August 2010Syntax-Driven Machine Translation as a Model of ESLRevisionHuichao Xue and Rebecca HwaDepartment of Computer ScienceUniversity of Pittsburgh{hux10,hwa}@cs.pitt.eduAbstractIn this work, we model the writing re-vision process of English as a SecondLanguage (ESL) students with syntax-driven machine translation methods.We compare two approaches: tree-to-string transformations (Yamada andKnight, 2001) and tree-to-tree trans-formations (Smith and Eisner, 2006).Results suggest that while the tree-to-tree model provides a greater cover-age, the tree-to-string approach offersa more plausible model of ESL learn-ers?
revision writing process.1 IntroductionWhen learning a second language, studentsmake mistakes along the way.
While somemistakes are idiosyncratic and individual,many are systematic and common to peoplewho share the same primary language.
Therehas been extensive research on grammar errordetection.
Most previous efforts focus on iden-tifying specific types of problems commonlyencountered by English as a Second Language(ESL) learners.
Some examples include theproper usage of determiners (Yi et al, 2008;Gamon et al, 2008), prepositions (Chodorowet al, 2007; Gamon et al, 2008; Hermet et al,2008), and mass versus count nouns (Nagataet al, 2006).
However, previous work suggeststhat grammar error correction is considerablymore challenging than detection (Han et al,2010).
Furthermore, an ESL learner?s writingmay contain multiple interacting errors thatare difficult to detect and correct in isolation.A promising research direction is to tackleautomatic grammar error correction as a ma-chine translation (MT) problem.
The dis-fluent sentences produced by an ESL learnercan be seen as the input source language,and the corrected revision is the result of thetranslation.
Brockett et al (2006) showedthat phrase-based statistical MT can help tocorrect mistakes made on mass nouns.
Toour knowledge, phrase-based MT techniqueshave not been applied for rewriting entire sen-tences.
One major challenge is the lack of ap-propriate training data such as a sizable par-allel corpus.
Another concern is that phrase-based MT may not be similar enough to theproblem of correcting ESL learner mistakes.While MT rewrites an entire source sentenceinto the target language, not every word writ-ten by an ESL learner needs to be modified.Another alternative that may afford a moregeneral model of ESL error corrections is toconsider syntax-driven MT approaches.
Weargue that syntax-based approaches can over-come the expected challenges in applying MTto this domain.
First, it can be less data-intensive because the mapping is formed at astructural level rather than the surface wordlevel.
While it does require a robust parser,a syntax-driven MT model may not need totrain on a very large parallel corpus.
Second,syntactic transformations provide an intuitivedescription of how second language learnersrevise their writings: they are transformingstructures in their primary language to thosein the new language.In this paper, we conduct a first inquiry intothe applicability of syntax-driven MT meth-ods to automatic grammar error correction.In particular, we investigate whether a syntax-driven model can capture ESL students?
pro-cess of writing revisions.
We compare two ap-proaches: a tree-to-string mapping proposedby Yamada & Knight (2001) and a tree-to-tree mapping using the Quasi-Synchronous1373Grammar (QG) formalism (Smith and Eisner,2006).
We train both models on a parallel cor-pus consisting of multiple drafts of essays byESL students.
The approaches are evaluatedon how well they model the revision pairs in anunseen test corpus.
Experimental results sug-gest that 1) the QG model has more flexibilityand is able to describe more types of transfor-mations; but 2) the YK model is better at cap-turing the incremental improvements in theESL learners?
revision writing process.2 Problem DescriptionThis paper explores the research question: canESL learners?
process of revising their writ-ings be described by a computational model?A successful model of the revision process hasseveral potential applications.
In addition toautomatic grammar error detection and cor-rection, it may also be useful as an auto-matic metric in an intelligent tutoring systemto evaluate how well the students are learningto make their own revisions.Revising an ESL student?s writing bearssome resemblance to translating.
The stu-dent?s first draft is likely to contain disfluentexpressions that arose from translation diver-gences between English and the student?s pri-mary language.
In the revised draft, the diver-gences should be resolved so that the text be-comes fluent English.
We investigate to whatextent are formalisms used for machine trans-lation applicable to model writing revision.We hypothesize that ESL students typicallymodify sentences to make them sound morefluent rather than to drastically change themeanings of what they are trying to convey.Thus, our work focuses on syntax-driven MTmodels.One challenge of applying MT methods tomodel grammar error correction is the lack ofappropriate training data.
The equivalenceto the bilingual parallel corpus used for de-veloping MT systems would be a corpus inwhich each student sentence is paired with afluent version re-written by an instructor.
Un-like bilingual text, however, there is not muchdata of this type in practice because thereare typically too many students for the teach-ers to provide detailed manual inspection andcorrection at a large scale.
More commonly,students are asked to revise their previouslywritten essays as they learn more about theEnglish language.
Here is an example of astudent sentence from a first-draft essay:The problem here is that they cometo the US like illegal.In a later draft, it has been revised into:The problem here is that they cometo the US illegally.Although the students are not able to cre-ate ?gold standard revisions?
due to their stillimperfect understanding of English, a corpusthat pairs the students?
earlier and later draftsstill offers us an opportunity to model howESL speakers make mistakes.More formally, the corpus C consists of aset of sentence pairs (O,R), where O repre-sents the student?s original draft and R rep-resents the revised draft.
Note that while Ris assumed to be an improvement upon O,its quality may fall short of the gold stan-dard revision, G. To train the syntax-drivenMT models, we optimize the joint probabil-ity of observing the sentence pair, Pr(O,R),through some form of mapping between theirparse trees, ?O and ?R.An added wrinkle to our problem is that itmight not always be possible to assign a sen-sible syntactic structure to an ungrammati-cal sentence.
It is well-known that an Englishparser trained on the Penn Treebank is badat handling disfluent sentences (Charniak etal., 2003; Foster et al, 2008).
In our domain,since O (and perhaps also R) might be disflu-ent, an important question that a translationmodel must address is: how should the map-ping between the trees ?O and ?R be handled?3 Syntax-Driven Models for EssayRevisionsThere is extensive literature on syntax-drivenapproaches to MT (cf.
a recent survey by1374Lopez (2008)); we focus on two particular for-malisms that reflects different perspectives onthe role of syntax.
Our goal is to assess whichformalism is a better fit with the domain ofessay revision modeling, in which the datalargely consist of imperfect sentences that maynot support a plausible syntactic interpreta-tion.3.1 Tree-to-String ModelThe Yamada & Knight (henceforth, YK) tree-to-string model is an instance of noisy channeltranslation systems, which assumes that theobserved source sentence is the result of trans-formation performed on the parse tree of theintended target sentence due to a noisy com-munication channel.
Given a parallel corpus,and a parser for the the target side, the pa-rameters of this model can be estimated usingEM(Expectation Maximization).
The trainedmodel?s job is to recover the target sentence(and tree) through decoding.While the noisy channel generation storymay sound somewhat counter-intuitive fortranslation, it gives a plausible account of ESLlearner?s writing process.
The student reallywants to convey a fluent English sentence witha well-formed structure, but due to an im-perfect understanding of the language, writesdown an ungrammatical sentence, O, as a firstdraft.
The student serves as the noisy channel.The YK model describes this as a stochasticprocess that performs three operations on ?G,the parse of the intended sentence, G:1.
Each node in ?G may have its childrenreordered with some probability.2.
Each node in ?G may have a child nodeinserted to its left or right with someprobability.3.
Each leaf node (i.e., surface word) in ?Gis replaced by some (possibly empty)string according to its lexical translationdistribution.The resulting sentence, O, is the concatena-tion of the leaf nodes of the transformed ?G.Common mistakes made by ESL learners,such as misuses of determiners and preposi-tions, word choice errors, and incorrect con-stituency orderings, can be modeled by a com-bination of the insert, replace, and reorderoperators.
The YK model allows us to per-form transformations on a higher syntacticlevel.
Another potential benefit is that themodel does not attempt to assign syntacticinterpretations over the source sentences (i.e.,the less fluent original draft).3.2 Tree-to-Tree ModelThe Quasi-Synchronous Grammar formalism(Smith and Eisner, 2006) is a generative modelthat aims to produce the most likely targettree for a given source tree.
It differs from themore strict synchronous grammar formalisms(Wu, 1995; Melamed et al, 2004) because itdoes not try to perform simultaneous pars-ing on parallel grammars; instead, the modellearns an augmented target-language gram-mar whose rules make ?soft alignments?
witha given source tree.QG has been applied to some NLP tasksother than MT, including answer selection forquestion-answering (Wang et al, 2007), para-phrase identification (Das and Smith, 2009),and parser adaptation and projection (Smithand Eisner, 2009).
In this work we usean instantiation of QG that largely followsthe model described by Smith and Eisner(2006).
The model is trained on a parallelcorpus in which both the first-draft and re-vised sentences have been parsed.
Using EMto estimate its parameters, it learns an aug-mented target PCFG grammar1 whose pro-duction rules form associations with the givensource trees.Consider the scenario in Figure 1.
Given asource tree ?O, the trained model generates atarget tree by expanding the production rulesin the augmented target PCFG.
To apply a1For expository purposes, we illustrate the modelusing a PCFG production rule.
In the experiment, astatistical English dependency parser (Klein and Man-ning, 2004) was used.1375Figure 1: An example of QG?s soft alignmentsbetween a given source tree and a possible tar-get rule expansion.target-side production rule such asA?
BC,the model considers which source tree nodesmight be associated with each target-side non-terminals:(?,A)?
(?,B)(?,C)where ?, ?, ?
are nodes in ?O.
Thus, as-suming that the target symbol A has alreadybeen aligned to source node ?
from an ear-lier derivation step, the likelihood of expand-ing (?,A) with the above production rule de-pends on three factors:1. the likelihood of the monolingual tar-get rule, Pr(A?
BC)2. the likelihood of alignments between Band ?
as well as C and ?.3.
the likelihood that the source nodes formsome expected configuration (i.e., be-tween ?
and ?
as well as between ?
and?).
In this work, we distinguish betweentwo configuration types: parent-child andother.
This restriction doesn?t reduce theexplanatory power of the resulting QGmodel, though it may not be as fine-tunedas some models in (Smith and Eisner,2006).Under QG, the ESL students?
first draftsare seen as text in a different language thathas its own syntactic constructions.
QG ex-plains the grammar rules that govern the re-vised text in terms of how different compo-nents map to structures in the original draft.It makes explicit the representation of diver-gences between the students?
original mentalmodel and the expected structure.3.3 Method of Model ComparisonCross entropy can be used as a metric thatmeasures the distance between the learnedprobabilistic model and the real data.
It canbe interpreted as measuring the amount of in-formation that is needed in addition to themodel to accurately recover the observed data.In language modeling, cross entropy is widelyused in showing a given model?s predictionpower.To determine how well the two syntax-driven MT models capture the ESL studentrevision generation process, we measure thecross entropy of each trained model on an un-seen test corpus.
This quantity measures howsurprised a model is about relating an initialsentence, O, to its corresponding revision, R.Specifically, the cross entropy for some modelM on a test corpus C of original and revisedsentence pairs (O,R) is:?
1|C|?
(O,R)?Clog PrM(O,R)Because neither model computes the jointprobability of the sentence pair, we need tomake additional computations so that themodels can be compared directly.The YK model computes the likelihoodof the first-draft sentence O given an as-sumed gold parse ?R of the revised sentence:PrY K(O | ?R).
To determine the joint proba-bility, we would need to compute:PrY K(O,R) =??R?
?RPrY K(O, ?R)=??R?
?RPrY K(O | ?R) Pr(?R)where ?R represents the set of possible parsetrees for sentence R. Practically, perform-ing tree-to-string mapping over the entire setof trees in ?R is computationally intractable.Moreover, the motivation behind the YK1376mean stdevpercentage of O = R 54.11% N/AO?s length 12.95 4.87R?s length 12.74 4.20edit distance 1.88 3.58Table 1: This table summarizes some statis-tics of the dataset.model is to trust the given ?R.
Thus, we madea Viterbi approximation:PrY K(O,R) =??R?
?RPrY K(O | ?R) Pr(?R)?
PrY K(O | ?
?R) Pr(?
?R)where Pr(?
?R) is the probability of the singlebest parse tree according to a standard En-glish parser.Similarly, to compute the joint sentence pairprobability under the QG model would requiresumming over both sets of trees because themodel computes PrQG(?R | ?O).
Here, wemake the Viterbi approximation on both trees.PrQG(O,R) =??R??R??O?
?OPrQG(?O, ?R)=??R??R??O?
?OPrQG(?R | ?O) Pr(?O)?
PrQG(?
?R | ?
?O) Pr(?
?O)where ?
?O and ?
?R are the best parses for sen-tences O and R according to the underlyingEnglish dependency parser, respectively.4 Experiments4.1 DataOur experiments are conducted using a collec-tion of ESL students?
writing samples2.
Theseare short essays of approximately 30 sentenceson topics such as ?a letter to your parents.
?The students are asked to revise their essaysat least once.
From the dataset, we extracted358 article pairs.2The dataset is made available by the PittsburghScience of Learning Center English as a Second Lan-guage Course Committee, supported by NSF AwardSBE-0354420.Typically, the changes between the draftsare incremental.
Approximately half of thesentences are not changed at all.
These sen-tences are considered useful because this phe-nomenon strongly implies that the originalversion is good enough to the best of the au-thor?s knowledge.
In a few rare cases, stu-dents may write an entirely different essay.We applied TF-IDF to automatically align thesentences between essay drafts.
Any sentencepair with a cosine similarity score of less than0.3 is filtered.
This resulted in a parallel cor-pus of 7580 sentence pairs.Because both models are computational in-tensive, we further restricted our experimentsto sentence pairs for which the revised sen-tence has no more than 20 words.
This re-duces our corpus to 4666 sentence pairs.
Somestatistics of the sentence pairs are shown inTable 1.4.2 Experimental SetupWe randomly split the resulting dataset intoa training corpus of 4566 sentence pairs and atest corpus of 100 pairs.The training of both models involve an EMalgorithm.
We initialize the model parameterswith some reasonable values.
Then, in each it-eration of training, the model parameters arere-estimated by collecting the expected countsacross possible alignments between each sen-tence pair in the training corpus.
In out ex-periments, both models had two iterations oftraining.
Below, we highlight our initializa-tion procedure for each model.In the YK model, the initial reorderingprobability distribution is set to prefer nochange 50% of the time.
The remaining prob-ability mass is distributed evenly over all ofthe other permutations.
For the insertionoperation, for each node, the YK model firstchooses whether to insert a new string to itsleft, to its right, or not at all, conditioned onthe node?s label and its parent?s label.
Thesedistributions are initialized uniformly (13).
Ifa new string should be inserted, the modelthen makes that choice with some probability.The insertion probability of each string in the1377dictionary is assigned evenly with 1N , whereN is the number of words in the dictionary.Finally, the replace probability distributionis initialized uniformly with the same value( 1N+1) across all words in the dictionary, in-cluding the empty string.For the QG model, the initial parametersare determined as follows: For the monolin-gual target parsing model parameters,we first parse the target side of the corpus(i.e., the revised sentences) with the Stanfordparser; we then use the maximum likelihoodestimates based on these parse trees to ini-tialize the parameters of the target parser,Dependency Model with Valence (DMV).
Weuniformly initialized the configuration pa-rameters; the parent-child configuration andother configuration each has 0.5 probability.For the alignment parameters, we ran theGIZA++ implementation of the IBM wordalignment model (Och and Ney, 2003) on thesentence pairs, and used the resulting transla-tion table as our initial estimation.
There maybe better initialization setups, but the differ-ence between those setups will become smallafter a few rounds of EM.Once trained, the two models compute thejoint probability of every sentence pair in thetest corpus as described in Section 3.3.4.3 Experiment ITo evaluate how well the models describe theESL revision domain, we want to see whichmodel is less ?surprised?
by the test data.
Weexpected that the better model should be ableto transform more sentence pair in the testcorpus; we also expect that the better modelshould have a lower cross entropy with respectto the test corpus.Applying both YK and QG to the test cor-pus, we find that neither model is able totransform all the test sentence pairs.
Of thetwo, QG had the better coverage; it success-fully modeled 59 pairs out of 100 (we denotethis subset as DQG).
In contrast, YK modeled36 pairs (this subset is denoted as DY K).To determine whether there were somecharacteristics of the data that made onemodel better at performing transformationsfor certain sentence pairs, we compare corpusstatistics for different test subsets.
Based onthe results summarized in Table 2, we make afew observations.First, the sentence pairs that neither modelcould transform seem, as a whole, more diffi-cult.
Their average lengths are longer, and theaverage per word Levenshtein edit distance isbigger.
The differences between Neither andthe other subsets are statistically significantwith 90% confidence.
For the length differ-ence, we applied standard two-sample t-test.For the edit distance difference, we applied hy-pothesis testing with the null-hypothesis that?longer sentence pairs are as likely to be cov-ered by our model as shorter ones.
?Second, both models sometimes have trou-ble with sentence pairs that require no change.This may be due to out-of-vocabulary wordsin the test corpus.
A more aggressive smooth-ing strategy could improve the coverage forboth models.Third, comparing the subset of sentencepairs that only QG could transform (DQG ?DY K) against the subset of sentences thatboth models could transform (DQG ?
DY K),the former has slightly higher average edit dis-tance and length, but the difference is notstatistically significant.
Although QG couldtransform more sentence pairs, the cross en-tropy of DQG ?DY K is higher than QG?s es-timate for the DQG ?DY K subset.
QG?s softalignment property allows it to model morecomplex transformations with greater flexibil-ity.Finally, while the YK model has a more lim-ited coverage, it models those transformationswith a greater certainty.
For the common sub-set of sentence pairs that both models couldtransform, YK has a much lower cross entropythan QG.
Table 3 further breaks down thecommon subset.
It is not surprising that bothmodels have low entropy for identical sentencepairs.
For modeling sentence pairs that con-tain revisions, YK is more efficient than QG.1378Neither DQG ?DY K DQG ?DY K DY K ?DQGnumber of instances 38 33 26 3average edit distance 2.42 1.88 2.08 1% of identical pairs 53% 48% 58% 67%average O length 14.63 12.36 12.58 6.67average R length 13.87 12.06 12.62 6.67QG cross entropy N/A 127.95 138.9 N/AYK cross entropy N/A 78.76 N/A 43.84Table 2: A comparison of the two models based on their coverage of the test corpus.
Somerelevant statistics on the sentence subsets are also summarized in the table.YK QGoverall entropy 78.76 127.95on identical pairs 52.59 85.40on non-identical pairs 103.99 168.00Table 3: A further comparison of the two mod-els on DQG ?DY K , the sentence pairs in thetest corpus that both could transform.4.4 Experiment IIThe results of the previous experiment raisesthe possibility that QG might have a greatercoverage because it is too flexible.
However,an appropriate model should not only assignlarge probability mass to positive examples,but it should also have a low chance of choos-ing negative examples.
In this next experi-ment, we construct a ?negative?
test corpusto see how it affects the models.To construct a negative scenario, we stilluse the same test corpus as before, but we re-verse the sentence pairs.
That is, we use therevised sentences as ?originals?
and the origi-nal sentences as ?revisions.?
We would expecta good model to have a raised cross entropyvalues along with a drop in coverage on thenew dataset because the ?revisions?
should bemore disfluent than the ?original?
sentences.Table 4 summarizes the results.
We ob-serve that the number of instances that canbe transformed has dropped for both models:from 59 to 49 pairs for QG, and from 36 to20 pairs for YK; also, the proportion of iden-tical instances in each set has raised.
Thismeans that both models are more surprisedby the reverse test corpus, suggesting thatboth models have, to some extent, succeededin modeling the ESL revision domain.
How-ever, QG still allows for many more transfor-mations.
Moreover, 16 out of the 49 instancesare non-identical pairs.
In contrast, YK mod-eled only 1 non-identical sentence pair.
Theresults from these two experiments suggestthat YK is more suited for modeling the ESLrevision domain than QG.
One possible expla-nation is that QG allows more flexibility andwould require more training.
Another possi-ble explanation is that because YK assumeswell-formed syntax structure for only the tar-get side, the philosophy behind its design is abetter fit with the ESL revision problem.5 Related WorkThere are many research directions in the fieldof ESL error correction.
A great deal of thework focuses on the lexical or shallow syn-tactic level.
Typically, local features suchas word identity and POS tagging informa-tion are combined to deal with some specifickind of error.
Among them, (Burstein et al,2004) developed a tool called Critique thatdetects collocation errors and word choice er-rors.
Nagata et al (2006) uses a rule-basedapproach in distinguishing mass and countnouns.
Knight and Chander (1994) and Hanet al (2006) both addressed the misuse of ar-ticles.
Chodorow et al (2007), Gamon et al(2008), Hermet et al (2008) proposed severaltechniques in detecting and correcting propo-sition errors.
In detecting errors and givingsuggestions, Liu et al (2000), Gamon et al(2008) and Hermet et al (2008) make use of1379Neither DQG ?DY K DQG ?DY K DY K ?DQGnumber of instances 50 19 30 1average edit distance 2.88 0.05 2.17 1percentage of identical pairs 0.40 0.95 0.5 0average O length 14.18 9.00 12.53 17average R length 14.98 9.05 12.47 16QG cross entropy N/A 81.85 139.36 N/AYK cross entropy N/A 51.2 N/A 103.75Table 4: This table compares the two models on a ?trick?
test corpus in which the earlier andlater drafts are reversed.
If a model is trained to prefer more fluent English sentences are therevision, it should be perplexed on this corpus.information retrieval techniques.
Chodorowet al (2007) instead treat it as a classificationproblem and employed a maximum entropyclassifier.
Similar to our approach, Brockettet al (2006) view error correction as a Ma-chine Translation problem.
But their transla-tion system is built on phrase level, with thepurpose of correcting local errors such as massnoun errors.The problem of error correction at a syn-tactic level is less explored.
Lee and Seneff(2008) examined the task of correcting verbform misuse by applying tree template match-ing rules.
The parse tree transformation rulesare learned from synthesized training data.6 ConclusionThis paper investigates the suitability ofsyntax-driven MT approaches for modelingthe revision writing process of ESL learn-ers.
We have considered both the Yamada &Knight tree-to-string model, which only con-siders syntactic information from the typicallymore fluent revised text, as well as Quasi-Synchronous Grammar, a tree-to-tree modelthat attempts to learn syntactic transforma-tion patterns between the students?
originaland revised texts.
Our results suggests thatwhile QG offers a greater degree of freedom,thus allowing for a better coverage of thetransformations, YK has a lower entropy onthe test corpus.
Moreover, when presentedwith an alternative ?trick?
corpus in which the?revision?
is in fact the earlier draft, YK wasmore perplexed than QG.
These results sug-gest that the YK model may be a promisingapproach for automatic grammar error correc-tion.AcknowledgmentsThis work has been supported by NSF GrantIIS-0745914.
We thank Joel Tetreault and theanonymous reviewers for their helpful com-ments and suggestions.ReferencesBrockett, Chris, William B. Dolan, and MichaelGamon.
2006.
Correcting esl errors usingphrasal smt techniques.
In Proceedings ofCOLING-ACL 2006, Sydney, Australia, July.Burstein, Jill, Martin Chodorow, and Claudia Lea-cock.
2004.
Automated essay evaluation: Thecriterion online writing service.
AI Magazine,25(3).Charniak, Eugene, Kevin Knight, and Kenji Ya-mada.
2003.
Syntax-based language models formachine translation.
In Proc.
MT Summit IX,New Orleans, Louisiana, USA.Chodorow, Martin, Joel Tetreault, and Na-RaeHan.
2007.
Detection of grammatical errorsinvolving prepositions.
In Proceedings of the4th ACL-SIGSEM Workshop on Prepositions,Prague, Czech Republic.Das, Dipanjan and Noah A. Smith.
2009.Paraphrase identification as probabilistic quasi-synchronous recognition.
In Proceedings ofACL-IJCNLP 2009, Suntec, Singapore, August.Foster, Jennifer, Joachim Wagner, and Josef vanGenabith.
2008.
Adapting a WSJ-trained1380parser to grammatically noisy text.
In Proceed-ings of the 46th ACL on Human Language Tech-nologies: Short Papers, Columbus, Ohio.Gamon, Michael, Jianfeng Gao, Chris Brock-ett, Alexandre Klementiev, William B. Dolan,Dmitriy Belenko, and Lucy Vanderwende.
2008.Using contextual speller techniques and lan-guage modeling for ESL error correction.
InProceedings of IJCNLP, Hyderabad, India.Han, Na-Rae, Martin Chodorow, and Claudia Lea-cock.
2006.
Detecting errors in English articleusage by non-native speakers.
Natural LanguageEngineering, 12(02).Han, Na-Rae, Joel Tetreault, Soo-Hwa Lee, andJin-Young Han.
2010.
Using an error-annotatedlearner corpus to develop and ESL/EFL er-ror correction system.
In Proceedings of LREC2010, Valletta, Malta.Hermet, Matthieu, Alain De?silets, and Stan Sz-pakowicz.
2008.
Using the web as a linguis-tic resource to automatically correct Lexico-Syntactic errors.
In Proceedings of the LREC,volume 8.Klein, Dan and Christopher Manning.
2004.Corpus-based induction of syntactic structure:Models of dependency and constituency.
In Pro-ceedings of ACL 2004, Barcelona, Spain.Knight, Kevin and Ishwar Chander.
1994.
Auto-mated postediting of documents.
In Proceedingsof AAAI-94, Seattle, Washington.Lee, John and Stephanie Seneff.
2008.
Correctingmisuse of verb forms.
Proceedings of the 46thACL, Columbus.Liu, Ting, Ming Zhou, Jianfeng Gao, EndongXun, and Changning Huang.
2000.
PENS: amachine-aided english writing system for chi-nese users.
In Proceedings of the 38th ACL,Hong Kong, China.Lopez, Adam.
2008.
Statistical machine transla-tion.
ACM Computing Surveys, 40(3), Septem-ber.Melamed, I. Dan, Giorgio Satta, and Ben Welling-ton.
2004.
Generalized multitext grammars.
InProceedings of the 42nd ACL, Barcelona, Spain.Nagata, Ryo, Atsuo Kawai, Koichiro Morihiro,and Naoki Isu.
2006.
A feedback-augmentedmethod for detecting errors in the writing oflearners of english.
In Proceedings of COLING-ACL 2006, Sydney, Australia, July.Och, Franz Josef and Hermann Ney.
2003.
A sys-tematic comparison of various statistical align-ment models.
Computational Linguistics, 29(1).Smith, David A. and Jason Eisner.
2006.
Quasi-synchronous grammars: Alignment by soft pro-jection of syntactic dependencies.
In Proceed-ings on the Workshop on Statistical MachineTranslation, New York City, June.Smith, David A. and Jason Eisner.
2009.Parser adaptation and projection with quasi-synchronous grammar features.
In Proceedingsof EMNLP 2009, Singapore, August.Wang, Mengqiu, Noah A. Smith, and Teruko Mi-tamura.
2007.
What is the Jeopardy model?a quasi-synchronous grammar for QA.
InProceedings of EMNLP-CoNLL 2007, Prague,Czech Republic, June.Wu, Dekai.
1995.
Stochastic inversion transduc-tion grammars, with application to segmenta-tion, bracketing, and alignment of parallel cor-pora.
In Proc.
of the 14th Intl.
Joint Conf.
onArtificial Intelligence, Montreal, Aug.Yamada, Kenji and Kevin Knight.
2001.
Asyntax-based statistical translation model.
InProceedings of the 39th ACL, Toulouse, France.Yi, Xing, Jianfeng Gao, and William B Dolan.2008.
A web-based english proofing system forenglish as a second language users.
In Proceed-ings of IJCNLP, Hyderabad, India.1381
