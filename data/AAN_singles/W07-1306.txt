Proceedings of Ninth Meeting of the ACL Special Interest Group in Computational Morphology and Phonology, pages 40?47,Prague, June 2007. c?2007 Association for Computational LinguisticsCan Corpus Based Measures be Used for Comparative Study of Languages?Anil Kumar SinghLanguage Tech.
Research CentreInt?l Inst.
of Information Tech.Hyderabad, Indiaanil@research.iiit.netHarshit SuranaLanguage Tech.
Research CentreInt?l Inst.
of Information Tech.Hyderabad, Indiasurana.h@gmail.comAbstractQuantitative measurement of inter-languagedistance is a useful technique for studyingdiachronic and synchronic relations betweenlanguages.
Such measures have been usedsuccessfully for purposes like deriving lan-guage taxonomies and language reconstruc-tion, but they have mostly been applied tohandcrafted word lists.
Can we insteaduse corpus based measures for comparativestudy of languages?
In this paper we try toanswer this question.
We use three corpusbased measures and present the results ob-tained from them and show how these resultsrelate to linguistic and historical knowledge.We argue that the answer is yes and that suchstudies can provide or validate linguistic andcomputational insights.1 IntroductionCrosslingual and multilingual processing is acquir-ing importance in the computational linguisticscommunity.
As a result, semi-automatic crosslin-gual comparison of languages is also becominga fruitful area of study.
Among the fundamen-tal tools for crosslingual comparison are measuresof inter-language distances.
In linguistics, thestudy of inter-language distances, especially for lan-guage classification, has a long history (Swadesh,1952; Ellison and Kirby, 2006).
Basically, thework on this problem has been along linguistic,archaeological and computational streams.
Likein other disciplines, computational methods are in-creasingly being combined with other more conven-tional approaches (Dyen et al, 1992; Nerbonne andHeeringa, 1997; Kondrak, 2002; Ellison and Kirby,2006).
The work being presented in this paper be-longs to the computational stream.Even in the computational stream, most of theprevious work on inter-language distances had astrong linguistic dimension.
For example, mostof the quantitative measures of inter-language dis-tance have been applied on handcrafted wordlists (Swadesh, 1952; Dyen et al, 1992).
However,with increasing use of computational techniques andthe availability of electronic data, a natural ques-tion arises: Can languages be linguistically com-pared based on word lists extracted from corpora.A natural counter-question is whether such compar-ison will be valid from linguistic and psycholinguis-tic points of view.
The aim of this paper is to exam-ine such questions.To calculate inter-language distances on the basisof words in corpora, we propose two corpus baseddistance measures.
They internally use a more lin-guistically grounded distance measure for compar-ing strings.
We also present the results obtained withone purely statistical measure, just to show that evennaive corpus based measures can be useful.
Themain contribution is to show that even noisy corporacan be used for comparative study of languages.
Dif-ferent measures can give different kinds of insights.2 Related WorkTypology or history of languages can be studied us-ing spoken data or text.
There has been work onthe former (Remmel, 1980; Kondrak, 2002), but we40will focus only on text.
An example of a major workon text based similarity is the paper by Kondrak andSherif (Kondrak and Sherif, 2006).
They have evalu-ated various phonetic similarity algorithms for align-ing cognates.
They found that learning based al-gorithms outperform manually constructed schemes,but only when large training data is used.A recent work on applications of such techniquesfor linguistic study is by Heeringa et al (Heeringaet al, 2006).
They performed a study on differ-ent variations of string distance algorithms for di-alectology and concluded that order sensitivity isimportant while scaling with length is not.
It maybe noted that Ellison and Kirby (Ellison and Kirby,2006) have shown that scaling by distance does givesignificantly better results.
Nakleh et al (Naklehet al, 2005) have written about using phyloge-netic techniques in historical linguistics as men-tioned by Nerbonne (Nerbonne, 2005) in the reviewof the book titled ?Language Classification by Num-bers?
by McMahon and McMahon (McMahon andMcMahon, 2005).
All these works are about usingquantitative techniques for language typology andclassification etc.3 Inter-Language ComparisonInter-language comparison is more general thanmeasuring inter-language distance.
In addition tothe overall linguistic distance, the comparison canbe of more specific characteristics like the propor-tion of cognates derived vertically and horizontally.Or it can be of specific phonetic features (Nerbonne,2005; McMahon and McMahon, 2005).
Quantita-tive measures for comparing languages can first beclassified according to the form of data being com-pared, i.e., speech, written text or electronic text.Assuming that the text is in electronic form, the mostcommon measures are based on word lists.
Theselists are usually prepared by linguists and they areoften in some special notation, e.g.
more or less aphonetic transcription.The measures can be based on inter-lingual or onintra-lingual comparison of phonetic forms (Ellisonand Kirby, 2006).
They may or may not use statis-tical techniques like measures of distributional sim-ilarity (cross entropy, KL-divergence, etc.).
Thesecharacteristics of measures may imply some linguis-tic or psycholinguistic assumptions.
One of these isabout a common phonetic space.4 Common Phonetic SpaceLanguage distance can be calculated throughcrosslingual as well as intra-lingual comparison.Many earlier attempts (Nerbonne and Heeringa,1997; Kondrak, 2002) were based on crosslingualcomparison of phonetic forms, but some researchershave argued against the possibility of obtainingmeaningful results from crosslingual comparison ofphonetic forms.
This is related to the idea of acommon phonetic space.
Port and Leary (Port andLeary, 2005) have argued against it.
Ellison andKirby (Ellison and Kirby, 2006) argue that even ifthere is a common space, language specific catego-rization of sound often restructures this space.
Theyconclude that if there is no language-independentcommon phonetic space with an equally commonsimilarity measure, there can be no principled ap-proach to comparing forms in one language withanother.
They suggest that language-internal com-parison of forms is better and psychologically morewell-grounded.This may be true, but should we really abandonthe approach based on crosslingual comparison?
Aseven Ellison and Kirby say, it is possible to arguethat there is a common phonetic space.
After all,the sounds produced by humans are determined byhuman physiology.
The only matter of debate iswhether common phonetic space makes sense fromthe cognitive point of view.
We argue that it does.In psychology, there has been a long debate abouta similar problem which can be stated in terms of acommon chromatic space.
Do humans in differentcultures see the same colors?
There is still no con-clusive answer, but many computational techniqueshave been tried to solve real world problems likeclassifying human faces, seemingly with the implicitassumption that there is a common chromatic space.Such techniques have shown some success (shengChen and kai Liu, 2003).Could it be that we are defining the notion of acommon chromatic (or phonetic) space too strictly?Or that the way we define it is not relevant for com-putational techniques?
In our view the answer isyes.
We will give a simple, not very novel, exam-41ple.
The phoneme t as in the English word battery isnot present in many languages of the world.
Whena Thai speaker can not say battery, with the correctt, he will say battery with t as in the French wordentre.
Such substitution will be very regular.
Thepoint is that even if phonetic space is restructuredfor a particular language, we can still find whichsegments or sections of two differently structuredphonetic spaces are close.
Cyan may span differentranges (on the spectrum) in different cultures, but theranges are likely to be near to one another.
Even ifsome culture has no color which can be called cyan,one or two of the colors that it does have will becloser to cyan than the others.
The same is truefor all the other colors and also for sounds.
If weuse fuzzy similarity measures to take care of suchdifferently structured cognitive spaces, cross-lingualcomparison may still be meaningful for certain pur-poses.
This argument is in defence of cross-lingualcomparison, not against intra-lingual comparison.5 Common Orthographic SpaceWriting systems used by languages differ verywidely.
This can be taken to mean that thereis no common orthographic space for meaning-ful crosslingual comparison of orthographic forms.This may be true in general, but for sets of languagesusing related scripts, we can assume a similar ortho-graphic space.
For example, most of the major SouthAsian languages use scripts derived from Brahmi.The similarity among these scripts is so much thatcrosslingual comparison of text is possible for var-ious purposes such as identifying cognates withoutany phonetic transcription.
This is in spite of the factthat the letter shapes differ so much that they are notmutually identifiable.
Such similarity is relevant forcorpus based measures.6 Corpus Based MeasuresSince we use (non-parallel) corpora of the two lan-guages for finding out the cognates and hence com-paring two languages, the validity of the results de-pends on how representative the corpora are.
How-ever, if they are of enough size, we might still beable to make meaningful, even if limited, compar-ison among languages.
We restrict ourselves toword list based comparison.
In such a case, cor-pus based measures can be effective if the corporacontain a representative portion of the vocabulary,or even of word segments.
The second case (of seg-ments) is relevant for the n-gram measure describedin section-7.This category of measures have to incorporatemore linguistic information if they are to providegood results.
Designing such measures can be achallenging problem as we will be mainly relyingon the corpus for our information.
Knowledge aboutsimilarities and differences of writing systems canplay an important role here.
The two cognate basedmeasures described in sections 9 and 10 are an at-tempt at this.
But first we describe a simple n-grambased measure.7 Symmetric Cross Entropy (SCE)The first measure is purely a letter n-gram basedmeasure similar to the one used by Singh (Singh,2006b) for language and encoding identification.
Tocalculate the distance, we first prepare letter 5-grammodels from the corpora of the languages to be com-pared.
Then we combine n-grams of all orders andrank them according to their probability in descend-ing order.
Only the top N n-grams are retained andthe rest are pruned.
1 Now we have two probabilitydistributions which can be compared by a measureof distributional similarity.
We have used symmetriccross entropy as such a measure:dsce =?gl=gm(p(gl) log q(gm) + q(gm) log p(gl))(1)where p and q are the probability distributions forthe two languages and gl and gm are n-grams in lan-guages l and m, respectively.The disadvantage of this measure is that it doesnot use any linguistic (e.g., phonetic) information,but the advantage is that it can measure the similar-ity of distributions of n-grams.
Such measures haveproved to be very effective in automatically iden-tifying languages of text, with accuracies nearing100% for fairly small amounts of training and testdata (Adams and Resnik, 1997; Singh, 2006b).1This is based on the results obtained by Cavnar (Cavnar andTrenkle, 1994) and our own studies, which show that the top N(300 according to Cavnar) n-grams have a high correlation withthe identity of the language.428 Method for Cognate IdentificationThe other two measures are based on cognates, in-herited as well as borrowed.
Both of them use analgorithm for identification of cognates.
Many suchalgorithms have been proposed.
Estimates of sur-face similarity can be used for finding cognate wordsacross languages for related languages.
By surfacesimilarity we mean the orthographic, phonetic and(possibly) morphological similarity of two words orstrings.
In spite of the name, surface similarity isdeeper than string similarity as calculated by editdistances.
Ribeiro et al (Ribeiro et al, 2001) havesurveyed some of the algorithms for cognate align-ment.
However, since they studied methods basedon parallel text, we cannot use them directly.For identifying cognates, we are using the compu-tational model of scripts or CPMS (Singh, 2006a).This model takes into account the characteristics ofBrahmi origin scripts and calculates surface simi-larity in a fuzzy way.
This is achieved by usinga stepped distance function (SDF) and a dynamicprogramming (DP) algorithm.
We have adapted theCPMS for identifying cognates.Different researchers have argued about the im-portance of order sensitivity and scaling in usingstring comparison algorithms (Heeringa et al, 2006;Ellison and Kirby, 2006).
The CPMS takes bothof these into account, as well as using knowledgeabout the script.
In general, the distance betweentwo strings can be defined as:clm = fp(wl, wm) (2)where fp is the function which calculates surfacesimilarity based cost between the word wl of lan-guage l and the word wm of language m.Those word pairs are identified as cognates whichhave the least cost.9 Cognate Coverage Distance (CCD)The second measure used by us is a corpus basedestimate of the coverage of cognates across two lan-guages.
Cognate coverage is defined as the num-ber of words (out of the vocabularies of the two lan-guages) which are of the same origin.
The decisionabout whether two words are cognates or not is madeon the basis of surface similarity of the two wordsas described in the previous section.
We use (non-parallel) corpora of the two languages for identify-ing the cognates.The normalized distance between two languagesis defined as:t?lm = 1?tlmmax(t) (3)where tlm and tml are the number of cognates foundwhen comparing from language l to m and from lan-guage m to l, respectively.Since the CPMS based measure of surface lexicalsimilarity is asymmetric, we calculate the averagenumber of unidirectional cognates:dccd = t?lm + t?ml2 (4)10 Phonetic Distance of Cognates (PDC)Simply finding the coverage of cognates may in-dicate the distance between two languages, but ameasure based solely on this information does nottake into account the variation between the cognatesthemselves.
To include this variation into the esti-mate of distance, we use another measure based onthe sum of the CPMS based cost of n cognates foundbetween two languages:Cpdclm =n?i = 0clm (5)where n is the minimum of tlm for all the languagepairs compared.The normalized distance can be defined as:C ?lm =Cpdclmmax(Cpdc) (6)A symmetric version of this cost is then calcu-lated:dpdc =C ?lm + C ?ml2 (7)11 Experimental SetupFor synchronic comparison, we selected ten lan-guages for our experiment (table-1), mainly be-cause sufficient corpora were available for these lan-guages.
These languages, though belonging to twodifferent families (Indo-Iranian and Dravidian), have43HIASBNORKNMRMLTETAPAHIASBNORKNMRMLTETAPAHIASBNORKNMRMLTETAPA0.200.520.320.020.070.200.420.610.610.530.620.850.720.160.370.120.050.110.160.170.250.560.810.310.170.45CCDPDCCombinedFigure 1: Graphical view of synchronic comparison among ten major South Asian languages using CCDand PDC measures.
The layout of the graph is modeled on the geographical locations of these languages.The connections among the nodes of the graph are obtained by joining each node to its two closest neighborsin terms of the values obtained by using the two measures.a lot of similarities (Emeneau, 1956).
The cognatewords among them are loanwords as well as inher-ited words.
In fact, the similarity among these lan-guages is due to common origin (intra-family) aswell as contact and borrowing over thousands ofyears (intra- and inter-family).
Moreover, they alsouse scripts derived from the same origin (Brahmi),which allows us to use the CPMS for identifyingcognates.
The corpora used for these ten languagesare all part of the CIIL (Central Institute of IndianLanguages) multilingual corpus.
This corpus is acollection of documents from different domains andis one of best known corpora for Indian languages.Still, the representativeness of this corpus may be amatter of debate as it is not as large and diverse asthe BNC (British National Corpus) corpus for En-glish.For the cognate measures (CCD and PDC), theonly information we are extracting from the cor-pora are the word types and their frequencies.Thus, in a way, we are also working with wordlists, but our word lists are extracted from cor-pora.
Word lists handcrafted by linguists may bevery useful, but they are not always available forall kinds of inter-language or inter-dialectal compar-ison, whereas electronic corpora are more likely tobe available.
Currently we are not doing any prepro-cessing or stemming on the word lists before runningthe cognate extraction algorithm.
For SCE, n-grammodels are being prepared as described in section-7.
For all three measures, we calculate the distancesamong all possible pairs of the languages.For diachronic comparison, we selected modernstandard Hindi, medieval Hindi (actually, Avadhi)and Sanskrit.
The corpus for modern Hindi was thesame as that used for synchronic comparison.
Themedieval Hindi we have experimented with is of twodifferent periods.
These are the varieties used bytwo great poets of that period, namely Jaayasi (1477-1542 A.D.) and Tulsidas (1532-1623 A.D.).
We tooksome of their major works available in electronicform as the corpora.
For Sanskrit, we used the elec-tronic version of Mahabharata (compiled during theperiod 1000 B.C.
to 500 A.D. approximately) as thecorpus.
We calculate the distances among all pos-sible pairs of the four varieties using the three mea-sures.
We also compare the ten modern languageswith Sanskrit using the same Mahabharata corpus.For synchronic comparison, we first extract thelist of word types with frequencies from the corpus.Then we rank them according to frequency.
Top Nof these are retained.
This is done because other-wise a lot of less relevant word types like propernouns get included.
We are interested in compar-ing the core vocabulary of languages.
The assump-tion is that words in the core vocabulary are likelyto be more frequent.
Another reason for restrictingthe experiments to the top N word types is that there44BN HI KN ML MR OR PA TA TEAS 0.02 0.39 0.71 0.86 0.61 0.20 0.61 0.93 0.730.12 0.25 0.39 0.61 0.45 0.11 0.58 0.95 0.460.05 0.30 0.51 0.50 0.43 0.18 0.42 0.70 0.64BN 0.32 0.68 0.86 0.57 0.07 0.56 0.96 0.700.29 0.42 0.64 0.42 0.05 0.56 0.90 0.500.29 0.47 0.45 0.43 0.14 0.42 0.74 0.43HI 0.61 0.81 0.42 0.40 0.20 0.93 0.610.17 0.56 0.16 0.27 0.16 0.87 0.380.43 0.46 0.16 0.33 0.20 0.74 0.34KN 0.77 0.68 0.75 0.73 0.88 0.530.45 0.17 0.31 0.50 0.82 0.250.18 0.38 0.52 0.58 0.42 0.09ML 0.89 0.88 0.88 0.62 0.720.65 0.59 0.77 0.56 0.310.42 0.53 0.55 0.07 0.19MR 0.64 0.52 0.95 0.680.40 0.37 0.94 0.460.34 0.39 0.60 0.30OR 0.63 0.98 0.740.45 0.89 0.440.65 0.83 0.64PA 0.90 0.710.90 0.590.92 0.48TA 0.850.810.39Table 1: Inter-language comparison among ten ma-jor South Asian languages using three corpus basedmeasures.
The values have been normalized andscaled to be somewhat comparable.
Each cell con-tains three values: by CCD, PDC and SCE.are huge differences in sizes of corpora of differentlanguages.
In the next step we identify the cognatesamong these word lists.
No language specific fea-tures or thresholds are used.
Only common thresh-olds are used.
We now branch out to using eitherCCD or PDC.The method used for diachronic comparison issimilar except that N is much smaller because theamount of classical corpus being used (Jaayasi, Tul-sidas) is also much smaller.
Two letter codes areused for ten languages and four varieties2.12 Analysis of ResultsThe results of our experiments are shown tables 1to 3 and figures 1 and 2.
Table-1 shows the dis-tances among pairs of languages using the three2AS: Assamese, BN: Bengali, HI: Hindi, KN: Kannada,ML: Malayalam, MR: Marathi, OR: Oriya, PA: Punjabi,TA: Tamil, TE: Telugu, TL: Avadhi (Tulsidas), JY: Avadhi(Jaayasi), MB: Sanskrit (Mahabharata)measures.
Figure-1 shows a graph showing the dis-tances according to CCD and PDC.
Figure-2 showsthe effect of the size of word lists (N ) on com-parison for three linguistically close language pairs.Table-2 shows the comparison of ten languages withSanskrit.
Table-3 gives the diachronic comparisonamong four historical varieties.12.1 Synchronic ComparisonAs table-1 shows, all three measures give resultswhich correspond well to the linguistic knowledgeabout differences among these languages.
Cognatebased measures give better results, but even the n-gram based measure gives good results.
However,there are some differences among the values ob-tained with different measures.
These differencesare also in accordance with linguistic insights.
Forexample, the distance between Hindi and Teluguwas given as 0.61 by CCD and 0.38 by PDC.
Simi-larly, the distance between Hindi and Kannada wasgiven as 0.61 by CCD and 0.17 by PDC.
These val-ues, in relative terms, indicate that the number ofcognates between these languages is in the mediumrange as compared to other pairs.
But less PDC costshows that top N cognates are very similar.
Thisis because most cognates are tatsam words directlyborrowed from Sanskrit without any change.The results presented in the table have been nor-malized on all language pairs using the maximumand minimum cost.
The results would be differ-ent and more comparable if we normalize over lan-guage families (Indo-Iranian and Dravidian).
Withsuch normalization, Punjabi-Oriya and Marathi-Assamese are identified as the farthest languagepairs with costs of 0.92 and 0.90, respectively.
Thiscorresponds well with the actual geographical andlinguistic distances.While comparing with Sanskrit, it is clear thatdifferent languages have different levels of cognatecoverage.
However, except for Punjabi and Tamil,all languages have very similar PDC cost with theMahabharata corpus.
This again shows that theclosest cognates among these languages are tatsamwords.
These results agree well with linguisticknowledge, even though the Sanskrit corpus (Ma-habharata) is highly biased.Figure-1 makes the results clearer.
It shows thatjust by connecting each node to its nearest two45Distance AS BN HI KN ML MR OR PA TA TECCD 0.71 0.70 0.65 0.78 0.87 0.73 0.71 0.78 0.94 0.77PDC 0.37 0.38 0.40 0.43 0.37 0.41 0.37 0.50 0.63 0.30Table 2: Comparison with Sanskrit (Mahabharata)Figure 2: Effect of the size of word lists on inter-language comparison.TL JY MBHI 0.45 0.54 0.820.45 0.42 0.700.64 0.56 0.49TL 0.01 0.840.02 0.720.16 0.91JY 0.980.950.81Table 3: Diachronic comparison among four histor-ical varieties.neighbors we can get a very good graphical repre-sentation of the differences among languages.
It alsoshows that different measures capture different as-pects.
For example, CCD fails to connect Marathiwith Kannada and Kannada with Malayalam.
Sim-ilarly, PDC fails to connect Bengali with Hindi.We get this missing information by combining thegraphs obtained with the two measures.
More so-phisticated methods for creating such graphs maygive better results.
Note that the Hindi-Telugu andMarathi-Kannada connections are valid as these lan-guage pairs are close, even though they are not ge-netically related.
The results indicate closeness be-tween two languages, but they do not distinguish be-tween inheritance and borrowing.We also experimented with several word list sizes.In figure-2 the CCD values are plotted against wordlist sizes for three close language pairs.
There isvariation for Hindi-Punjabi and Malayalam-Telugu,but not for Assamese-Bengali.
The following obser-vations can be derived from the three lines on theplot.
Malayalam-Telugu share a lot of common corewords but not less common words.
Hindi-Punjabishare a lot of less common words, but core wordsare not exactly similar.
Finally, Assamese-Bengalishare both core as well as less common words.12.2 Diachronic ComparisonTable-4 shows the results.
We can see that Hindi iscloser to Tulsidas than to Jaayasi by the CCD mea-sure.
PDC gives almost similar results for both.
Tul-sidas and Jaayasi are the nearest.
Tulsidas is muchnearer to Mahabharata than Jaayasi, chiefly becauseTulsidas?
language has more Sanskrit origin words.Our results put Tulsidas nearest to Hindi, followedby Jaayasi and then Sanskrit.
This is historically aswell as linguistically correct.13 Conclusions and Further WorkIn this paper we first discussed the possibility andvalidity of using corpus based measures for compar-ative study of languages.
We presented some ar-guments in favor of this possibility.
We then de-scribed three corpus based measures for comparativestudy of languages.
The first measure was symmet-ric cross entropy of letter n-grams.
This measureuses the least amount of linguistic information.
Thesecond and third measures were cognate coveragedistance and phonetic distance of cognates, respec-tively.
These two are more linguistically grounded.Using these measures, we presented a synchroniccomparison of ten major South Asian languages anda diachronic comparison of four historical varieties.The results of our experiments show that even thesesimple measures based on crosslingual comparison46and on the data extracted from not very representa-tive and noisy corpora can be used for obtaining orvalidating useful linguistic insights about languagedivergence, classification etc.These measures can be tried for more languagesto see whether they have any validity for less relatedlanguages than the languages we experimented with.We can also try to design measures and find meth-ods for distinguishing between borrowed and inher-ited words.
Proper combination of synchronic anddiachronic comparison might help us in doing this.Other possible applications could be for language re-construction, classification, dialectology etc.Better versions of the two cognate based measurescan be defined by using the idea of confusion prob-abilities (Ellison and Kirby, 2006) and the idea ofdistributional similarity.
If intra-lingual comparisonis more meaningful than inter-lingual comparison,then these modified versions should be even moreuseful for comparative study of languages.ReferencesGary Adams and Philip Resnik.
1997.
A languageidentification application built on the Java client-serverplatform.
In Jill Burstein and Claudia Leacock, ed-itors, From Research to Commercial Applications:Making NLP Work in Practice, pages 43?47.
Associa-tion for Computational Linguistics.William B. Cavnar and John M. Trenkle.
1994.
N-gram-based text categorization.
In Proceedings of SDAIR-94, 3rd Annual Symposium on Document Analysis andInformation Retrieval, pages 161?175, Las Vegas, US.I.
Dyen, J.B. Kruskal, and P. Black.
1992.
Anindo-european classification: A lexicostatistical exper-iment.
In Transactions of the American PhilosophicalSociety, 82:1-132.T.
Mark Ellison and Simon Kirby.
2006.
Measuring lan-guage divergence by intra-lexical comparison.
In Pro-ceedings of the 21st International Conference on Com-putational Linguistics and 44th Annual Meeting of theAssociation for Computational Linguistics, Sydney,Australia.
Association for Computational Linguistics.M.
B. Emeneau.
1956.
India as a linguistic area.
InLinguistics 32:3-16.W.
Heeringa, P. Kleiweg, C. Gooskens, and J. Nerbonne.2006.
Evaluation of String Distance Algorithms forDialectology.
In Proc.
of ACL Workshop on LinguisticDistances.G.
Kondrak and T. Sherif.
2006.
Evaluation of SeveralPhonetic Similarity Algorithms on the Task of CognateIdentification.
In Proc.
of ACL Workshop on LinguisticDistances.Grzegorz Kondrak.
2002.
Algorithms for language re-construction.
Ph.D. thesis.
Adviser-Graeme Hirst.April McMahon and Robert McMahon.
2005.
Lan-guage Classification by the Numbers.
Oxford Univer-sity Press, Oxford.Luay Nakleh, Don Ringe, and Tandy Warnow.
2005.Perfect phylogentic networks: A new methodology forreconstructing the evolutionary history of natural lan-guages.
pages 81?2:382?420.J.
Nerbonne and W. Heeringa.
1997.
Measuring dialectdistance phonetically.
In Proceedings of SIGPHON-97: 3rd Meeting of the ACL Special Interest Group inComputational Phonology.J.
Nerbonne.
2005. Review of ?language classificationby the numbers?
by april mcmahon and robert mcma-hon.B.
Port and A. Leary.
2005.
Against formal phonology.pages 81(4):927?964.M.
Remmel.
1980.
Computers in the historical phoneticsand phonology of Balto-Finnic languages: problemsand perspectives.
In Communication pre?sente?e au 5thInternational Finno-Ugric Congress, Turku.A.
Ribeiro, G. Dias, G. Lopes, and J. Mexia.
2001.
Cog-nates alignment.
Machine Translation Summit VIII,Machine Translation in The Information Age, pages287?292.Duan sheng Chen and Zheng kai Liu.
2003.
A novelapproach to detect and correct highlighted face re-gion in color image.
In AVSS ?03: Proceedings ofthe IEEE Conference on Advanced Video and SignalBased Surveillance, page 7, Washington, DC, USA.IEEE Computer Society.Anil Kumar Singh.
2006a.
A computational phoneticmodel for indian language scripts.
In Constraints onSpelling Changes: Fifth International Workshop onWriting Systems, Nijmegen, The Netherlands.Anil Kumar Singh.
2006b.
Study of some distance mea-sures for language and encoding identification.
In Pro-ceedings of ACL 2006 Workshop on Linguistic Dis-tance, Sydney, Australia.M.
Swadesh.
1952.
Lexico-dating of prehistoric ethniccontacts.
In Proceedings of the American philosophi-cal society, 96(4).47
