Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 170?179,Singapore, 6-7 August 2009.c?2009 ACL and AFNLPSupervised and Unsupervised Methods in Employing Discourse Relationsfor Improving Opinion Polarity ClassificationSwapna SomasundaranUniv.
of PittsburghPittsburgh, PA 15260swapna@cs.pitt.eduGalileo NamataUniv.
of MarylandCollege Park, MD 20742namatag@cs.umd.eduJanyce WiebeUniv.
of PittsburghPittsburgh, PA 15260wiebe@cs.pitt.eduLise GetoorUniv.
of MarylandCollege Park, MD 20742getoor@cs.umd.eduAbstractThis work investigates design choices inmodeling a discourse scheme for im-proving opinion polarity classification.For this, two diverse global inferenceparadigms are used: a supervised collec-tive classification framework and an un-supervised optimization framework.
Bothapproaches perform substantially betterthan baseline approaches, establishing theefficacy of the methods and the underlyingdiscourse scheme.
We also present quan-titative and qualitative analyses showinghow the improvements are achieved.1 IntroductionThe importance of discourse in opinion analy-sis is being increasingly recognized (Polanyi andZaenen, 2006).
Motivated by the need to en-able discourse-based opinion analysis, previousresearch (Asher et al, 2008; Somasundaran et al,2008) developed discourse schemes and createdmanually annotated corpora.
However, it was notknown whether and how well these linguistic ideasand schemes can be translated into effective com-putational implementations.In this paper, we first investigate ways in whichan opinion discourse scheme can be computation-ally modeled, and then how it can be utilized toimprove polarity classification.
Specifically, thediscourse scheme we use is from Somasundaranet al (2008), which was developed to support aglobal, interdependent polarity interpretation.
Toachieve discourse-based global inference, we ex-plore two different frameworks.
The first is asupervised framework that learns interdependentopinion interpretations from training data.
Thesecond is an unsupervised optimization frame-work which uses constraints to express the ideasof coherent opinion interpretation embodied in thescheme.
For the supervised framework, we use It-erative Collective Classification (ICA), which fa-cilitates machine learning using relational infor-mation.
The unsupervised optimization is imple-mented as an Integer Linear Programming (ILP)problem.
Via our implementations, we aim toempirically test if discourse-based approaches toopinion analysis are useful.Our results show that both of our implemen-tations achieve significantly better accuracies inpolarity classification than classifiers using localinformation alone.
This confirms the hypothesisthat the discourse-based scheme is useful, and alsoshows that both of our design choices are effective.We also find that there is a difference in the wayICA and ILP achieve improvements, and a simplehybrid approach, which incorporates the strengthsof both, is able to achieve significant overall im-provements over both.
Our analyses show thateven when our discourse-based methods bootstrapfrom noisy classifications, they can achieve goodimprovements.The rest of this paper is organized as follows:we discuss related work in Section 2 and thediscourse scheme in Section 3.
We present ourdiscourse-based implementations in Section 4, ex-periments in Section 5, discussions in Section 6and conclusions in Section 7.2 Related WorkPrevious work on polarity disambiguation hasused contextual clues and reversal words (Wil-son et al, 2005; Kennedy and Inkpen, 2006;Kanayama and Nasukawa, 2006; Devitt and Ah-mad, 2007; Sadamitsu et al, 2008).
However,these do not capture discourse-level relations.Researchers, such as (Polanyi and Zaenen,2006), have discussed how the discourse struc-ture can influence opinion interpretation; and pre-vious work, such as (Asher et al, 2008; Soma-sundaran et al, 2008), have developed annota-170tion schemes for interpreting opinions with dis-course relations.
However, they do not empiri-cally demonstrate how automatic methods can usetheir ideas to improve polarity classification.
Inthis work, we demonstrate concrete ways in whicha discourse-based scheme can be modeled usingglobal inference paradigms.Joint models have been previously explored forother NLP problems (Haghighi et al, 2005; Mos-chitti et al, 2006; Moschitti, 2009).
Our global in-ference model focuses on opinion polarity recog-nition task.The biggest difference between this work andprevious work in opinion analysis that use globalinference methods is in the type of linguisticrelations used to achieve the global inference.Some of the work is not related to discourseat all (e.g., lexical similarities (Takamura et al,2007), morphosyntactic similarities (Popescu andEtzioni, 2005) and word-based measures like TF-IDF (Goldberg and Zhu, 2006)).
Others usesentence cohesion (Pang and Lee, 2004), agree-ment/disagreement between speakers (Thomas etal., 2006; Bansal et al, 2008), or structural adja-cency.
In contrast, our work focuses on discourse-based relations for global inference.
Another dif-ference from the above work is that our work isover multi-party conversations.Previous work on emotion and subjectivitydetection in multi-party conversations has ex-plored using prosodic information (Neiberg et al,2006), combining linguistic and acoustic infor-mation (Raaijmakers et al, 2008) and combininglexical and dialog information (Somasundaran etal., 2007).
Our work is focused on harnessingdiscourse-based knowledge and on interdependentinference.There are several collective classificationframeworks, including (Neville and Jensen, 2000;Lu and Getoor, 2003; Taskar et al, 2004; Richard-son and Domingos, 2006; Bilgic et al, 2007).
Inthis paper, we use an approach by (Lu and Getoor,2003) which iteratively predicts class values usinglocal and relational features.
ILP has been usedon other NLP tasks, e.g., (Denis and Baldridge,2007; Choi et al, 2006; Roth and Yih, 2004).
Inthis work, we employ ILP for modeling discourseconstraints for polarity classification.3 Discourse Scheme and DataThe scheme in Somasundaran et al (2008) hasbeen developed and annotated over the AMI meet-ing corpus (Carletta et al, 2005).1This schemeannotates opinions, their polarities (positive, neg-ative, neutral) and their targets (a target is whatthe opinion is about).
The targets of opinions arerelated via two types of relations: the same rela-tion, which relates targets referring to the sameentity or proposition, and the alternative relation,which relates targets referring to mutually exclu-sive options in the context of the discourse.
Ad-ditionally, the scheme relates opinions via twotypes of frame relations: the reinforcing and non-reinforcing relations.
The frame relations repre-sent discourse scenarios: reinforcing relations ex-ist between opinions when they contribute to thesame overall stance, while non-reinforcing rela-tions exist between opinions that show ambiva-lence.The opinion annotations are text-span based,while in this work, we use Dialog Act (DA) basedsegmentation of meetings.2As the DAs are ourunits of classification, we map opinion annotationsto the DA units as follows.
If a DA unit containsan opinion annotation, the label is transferred up-wards to the containing DA.
When a DA containsmultiple opinion annotations, each with a differ-ent polarity, one of them is randomly chosen asthe label for the DA.
The discourse relations exist-ing between opinions are also transferred upwards,between the DAs containing each of these anno-tations.
We recreate an example from Somasun-daran et al (2008) using DA segmentation in Ex-ample 1.
Here, the speaker has a positive opiniontowards the rubbery material for the TV remote.
(1) DA-1: ... this kind of rubbery material,DA-2: it?s a bit more bouncy,DA-3: like you said they get chucked around a lot.DA-4: A bit more durable and that can also be er-gonomic andDA-5: it kind of feels a bit different from all theother remote controls.In the example, the individual opinion expressions(shown in bold) are essentially regarding the samething ?
the rubbery material.
Thus, the explicittargets (shown in italics), it?s, that, and it, and theimplicit target of a bit more durable are all linked1The AMI corpus contains a set of scenario-based meet-ings where participants have to design a new TV remote pro-totype.2DA segmentation is provided with the AMI corpus.171Figure 1: Discourse Relations between DA seg-ments for Example 1.with same target relations.
Also, notice that theopinions reinforce a particular stance, i.e., a pro-rubbery-material stance.
Thus, the scheme linksthe opinions via reinforcing relations.
Figure 1 il-lustrates the corresponding discourse relations be-tween the containing DA units.4 Implementing the Discourse ModelThe hypothesis in using discourse information forpolarity classification is that the global discourseview will improve upon a classification with onlya local view.
Thus, we implement a local clas-sifier to bootstrap the classification process, andthen implement classifiers that use discourse in-formation from the scheme annotations, over it.We explore two approaches for implementing ourdiscourse-based classifier.
The first is ICA, wherediscourse relations and the neighborhood informa-tion brought in by these relations are incorporatedas features into the learner.
The second approachis ILP optimization, which tries to maximize theclass distributions predicted by the local classifier,subject to constraints imposed by discourse rela-tions.
Both classifiers thus accommodate prefer-ences of the local classifier and for coherence withdiscourse neighbors.4.1 Local ClassifierA supervised local classifier, Local, is used to pro-vide the classifications to bootstrap the discourse-based classifiers.3It is important to make Local asreliable as possible; otherwise, the discourse rela-tions will propagate misclassifications.
Thus, webuild Local using a variety of knowledge sourcesthat have been shown to be useful for opinion anal-ysis in previous work.
Specifically, we constructfeatures using polarity lexicons (used by (Wilsonet al, 2005)), DA tags (used by (Somasundaran3Local is supervised, as previous work has shown thatsupervised methods are effective in opinion analysis.
Eventhough this makes the final end-to-end system with the ILPimplementation semi-supervised, note that the discourse-based ILP part is itself unsupervised.et al, 2007)) and unigrams (used by many re-searchers, e.g., (Pang and Lee, 2004)).Note that, as our discourse-based classifiers at-tempt to improve upon the local classifications,Local is also a baseline for our experiments.4.2 Iterative Collective ClassificationWe use a variant of ICA (Lu and Getoor, 2003;Neville and Jensen, 2000), which is a collectiveclassification algorithm shown to perform consis-tently well over a wide variety of relational data.Algorithm 1 ICA Algorithmfor each instance i do {bootstrapping}Compute polarity for i using local attributesend forrepeat {iterative}Generate ordering I over all instancesfor each i in I doCompute polarity for i using local and re-lational attributesend foruntil Stopping criterion is metICA uses two classifiers: a local classifier and arelational classifier.
The local classifier is trainedto predict the DA labels using only the local fea-tures.
We use Local, described in Section 4.1, forthis purpose.
The relational classifier is trained us-ing the local features, and an additional set of fea-tures commonly referred to as relational features.The value of a relational feature, for a given DA,depends on the polarity of the discourse neighborsof that DA.
Thus, the relational features incorpo-rate discourse and neighbor information; that is,they incorporate the information about the frameand target relations in conjunction with the polar-ity of the discourse neighbors.
Intuitively, our mo-tivation for this approach can be explained usingExample 1.
Here, in interpreting the ambiguousopinion a bit different as being positive, we usethe knowledge that it participates in a reinforc-ing discourse, and that all its neighbors (e.g., er-gonomic, durable) are positive opinions regard-ing the same thing.
On the other hand, if it hadbeen a non-reinforcing discourse, then the polar-ity of a bit different, when viewed with respect tothe other opinions, could have been interpreted asnegative.Table 1 lists the relational features we definedfor our experiments where each row represents a172Percent of neighbors with polarity type a related via frame relation f?Percent of neighbors with polarity type a related via target relation t?Percent of neighbors with polarity type a related via frame relation f and target relation tPercent of neighbors with polarity type a and same speaker related via frame relation f?Percent of neighbors with polarity type a and same speaker related via target relation t?Percent of neighbors with polarity type a related via a frame relation or target relationPercent of neighbors with polarity type a related via a reinforcing frame relation or same target relationPercent of neighbors with polarity type a related via a non-reinforcing frame relation or alt target relationMost common polarity type of neighbors related via a same target relationMost common polarity type of neighbors related via a reinforcing frame relation and same target relationTable 1: Relational features: a ?
{non-neutral (i.e., positive or negative), positive, negative}, t ?
{same, alt},f ?
{reinforcing, non-reinforcing}, t??
{same or alt, same, alt}, f??
{reinforcing or non-reinforcing, reinforcing, non-reinforcing}set of features.
Features are generated for all com-binations of a, t, t?, f and f?for each row.
Forexample, one of the features in the first row is Per-cent of neighbors with polarity type positive, thatare related via a reinforcing frame relation.
Thus,each feature for the relational classifier identifiesneighbors for a given instance via a specific rela-tion (f , t, f?or t?, obtained from the scheme an-notations) and factors in their polarity values (a,obtained from the classifier predictions from theprevious round).
This adds a total of 59 relationalfeatures to the already existing local features.ICA has two main phases: the bootstrappingand iterative phases.
In the bootstrapping phase,the polarity of each instance is initialized to themost likely value given only the local classifierand its features.
In the iterative phase, we cre-ate a random ordering of all the instances and,in turn, apply the relational classifier to each in-stance where the relational features, for a giveninstance, are computed using the most recent po-larity assignments of its neighbors.
We repeat thisuntil some stopping criterion is met.
For our ex-periments, we use a fixed number of 30 iterations,which has been found to be sufficient in most datasets for ICA to converge to a solution.The pseudocode for the algorithm is shown inAlgorithm 1.4.3 Integer Linear ProgrammingFirst, we explain the intuition behind viewing dis-course relations as enforcing constraints on polar-ity interpretation.
Then, we explain how the con-straints are encoded in the optimization problem.4.3.1 Discourse Constraints on PolarityThe discourse relations between opinions can pro-vide coherence constraints on the way their polar-ity is interpreted.
Consider a discourse scenarioin which a speaker expresses multiple opinionsregarding the same thing, and is reinforcing hisstance in the process (as in Example 1).
The setof individual polarity assignments that is most co-herent with this global scenario is the one whereall the opinions have the same (equal) polarity.
Onthe other hand, a pair of individual polarity assign-ments most consistent with a discourse scenariowhere a speaker reinforces his stance via opinionstowards alternative options, is one with opinionshaving mutually opposite polarity.
For instance,in the utterance ?Shapes should be curved, noth-ing square-like?, the speaker reinforces his pro-curved stance via his opinions about the alternativeshapes: curved and square-like.
And, we see thatthe first opinion is positive and the second is neg-ative.
Table 2 lists the discourse relations (targetand frame relation combinations) found in the cor-pus, and the likely polarity interpretation for therelated instances.Target relation + Frame relation Polaritysame+reinforcing equal (e)same+non-reinforcing opposite (o)alternative+reinforcing opposite (o)alternative+non-reinforcing equal (e)Table 2: Discourse relations and their polarity con-straints on the related instances.4.3.2 Optimization ProblemFor each DA instance i in a dataset, the localclassifier provides a class distribution [pi, qi, ri],where pi, qiand ricorrespond to the probabilitiesthat i belongs to positive, negative and neutral cat-egories, respectively.
The optimization problem isformulated as an ILP minimization of the objec-tive function in Equation 1.?1?
?i(pixi+qiyi+rizi)+?i,jij+?i,j?ij(1)173where the xi, yiand ziare binary class vari-ables corresponding to positive, negative and neu-tral classes, respectively.
When a class variableis 1, the corresponding class is chosen.
Variablesijand ?ijare binary slack variables that corre-spond to the discourse constraints between twodistinct DA instances i and j.
When a given slackvariable is 1, the corresponding discourse con-straint is violated.
Note that the objective func-tion tries to achieve two goals.
The first part(?ipixi+ qiyi+ rizi) is a maximization that triesto choose a classification for the instances thatmaximizes the probabilities provided by the localclassifier.
The second part (?i,jij+?i,j?ij) is aminimization that tries to minimize the number ofslack variables used, that is, minimize the numberof discourse constraints violated.Constraints in Equations 2 and 3 listed belowimpose binary constraints on the variables.
Theconstraint in Equation 4 ensures that, for each in-stance i, only one class variable is set to 1.xi?
{0, 1}, yi?
{0, 1}, zi?
{0, 1} , ?i (2)ij?
{0, 1}, ?ij?
{0, 1} , ?i 6= j (3)xi+ yi+ zi= 1 , ?i (4)We pair distinct DA instances i and j as ij,and if there exists a discourse relation betweenthem, they can be subject to the corresponding po-larity constraints listed in Table 2.
For this, wedefine two binary discourse-constraint constants:the equal-polarity constant, eijand the opposite-polarity constant, oij.
If a given DA pair ij isrelated by either a same+reinforcing relation oran alternative+non-reinforcing relation (rows 1, 4of Table 2), then eij= 1; otherwise it is zero.Similarly, if it is related by either a same+non-reinforcing relation or an alternative+reinforcingrelation (rows 2, 3 of Table 2), then oij= 1.
Botheijand oijare zero if the instance pair is unrelatedin the discourse.For each DA instance pair ij, equal-polarityconstraints are applied to the polarity variables of i(xi, yi) and j (xj, yj) via the following equations:|xi?
xj| ?
1?
eij+ ij, ?i 6= j (5)|yi?
yj| ?
1?
eij+ ij, ?i 6= j (6)?
(xi+ yi) ?
?li, ?i (7)When eij= 1, the Equation 5 constrains xiandxjto be of the same value (both zero or both one).Similarly, Equation 6 constrains yiand yjto beof the same value.
Via these equations, we ensurethat the instances i and j do not have the oppo-site polarity when eij= 1.
However, notice that,if we use just Equations 5 and 6, the optimizationcan converge to the same, non-polar (neutral) cat-egory.
To guide the convergence to the same polar(positive or negative) category, we use Equation 7.Here li= 1 if the instance i participates in one ormore discourse relations.
When eij= 0, xiand xj(and yiand yj), can take on assignments indepen-dently of one another.
Notice that both constraints5 and 6 are relaxed when ij= 1; thus, xiand xj(or yiand yj) can take on values independently ofone another, even if eij= 1.Next, the opposite-polarity constraints are ap-plied via the following equations:|xi+ xj?
1| ?
1?
oij+ ?ij, ?i 6= j (8)|yi+ yj?
1| ?
1?
oij+ ?ij, ?i 6= j (9)In the above equations, when oij= 1, xiand xj(and yiand yj) take on opposite values; for exam-ple, if xi= 1 then xj= 0 and vice versa.
Whenoij= 0, the variable assignments are independentof one another.
This set of constraints is relaxedwhen ?ij= 1.In general, in our ILP formulation, notice thatif an instance does not have a discourse relation toany other instance in the data, its classification isunaffected by the optimization.
Also, as the un-derlying discourse scheme poses constraints onlyon the interpretation of the polarity of the relatedinstances, discourse constraints are applied only tothe polarity variables x and y, and not to the neu-tral class variable, z.
Finally, even though slackvariables are used, we discourage the ILP systemfrom indiscriminately setting the slack variables to1 by making them a part of the objective functionthat is minimized.5 ExperimentsIn this work, we are particularly interested inimprovements due to discourse-based methods.Thus, we report performance under three con-ditions: over only those instances that are re-lated via discourse relations (Connected), over in-stances not related via discourse relations (Single-tons), and over all instances (All).The annotated data consists of 7 scenario-based,multi-party meetings from the AMI meeting cor-pus.
We filter out very small DAs (DAs with fewerthan 3 tokens, punctuation included).
This gives174us a total of 4606 DA instances, of which 1935(42%) have opinion annotations.
For our exper-iments, the DAs with no opinion annotations aswell as those with neutral opinions are consideredas neutral.
Table 3 shows the class distributions inthe data for the three conditions.Pos Neg Neutral TotalConnected 643 343 81 1067Singleton 553 233 2753 3539All 1196 576 2834 4606Table 3: Class distribution over connected, singleand all instances.5.1 ClassifiersOur first baseline, Base, is a simple distribution-based classifier that classifies the test data basedon the overall distribution of the classes in thetraining data.
However, in Table 3, the class distri-bution is different for the Connected and Single-ton conditions.
We incorporate this in a smarterbaseline, Base-2, which constructs separate dis-tributions for connected instances and singletons.Thus, given a test instance, depending on whetherit is connected, Base-2 uses the corresponding dis-tribution to make its prediction.The third baseline is the supervised classifier,Local, described in Section 4.1.
It is imple-mented using the SVM classifiers from the Wekatoolkit (Witten and Frank, 2002).4Our super-vised discourse-based classifier, ICA from Sec-tion 4.2, also uses a similar SVM implemen-tation for its relational classifier.
We imple-ment our ILP approach from Section 4.3 us-ing the optimization toolbox from Mathworks(http://www.mathworks.com) and GNU LinearProgramming Kit.We observed that the ILP system performs bet-ter than the ICA system on instances that are con-nected, while ICA performs better on singletons.Thus, we also implemented a simple hybrid clas-sifier (HYB), which selects the ICA prediction forclassification of singletons and the ILP predictionfor classification of connected instances.5.2 ResultsWe performed 7-fold cross validation experi-ments, where six meetings are used for training4We use the SMO implementation, which, when usedwith the logistic regression, has an output that can be viewedas a posterior probability distribution.and the seventh is used for testing the supervisedclassifiers (Base, Base-2, Local and ICA).
In thecase of ILP, the optimization is applied to the out-put of Local for each test fold.
Table 4 reports theaccuracies of the classifiers, averaged over 7 folds.First, we observe that Base performs poorlyover connected instances, but performs consider-ably better over singletons.
This is expected as theoverall majority class is neutral and the singletonsare more likely to be neutral.
Base-2, which incor-porates the differentiated distributions, performssubstantially better than Base.
Local achieves anoverall performance improvement over Base andBase-2 by 23 percentage points and 9 percent-age points, respectively.
In general, Local outper-forms Base for all three conditions (p < 0.001),and Base-2 for the Singleton and All conditions(p < 0.001).
This overall improvement in Local?saccuracy corroborates the utility of the lexical, un-igram and DA based features for polarity detectionin this corpus.Turning to the discourse-based classifiers, ICA,ILP and HYB, all of these perform better thanBase and Base-2 for all conditions.
ICA improvesover Local by 9 percentage points for Connected,3 points for Singleton and 4 points for All.
ILP?simprovement over Local for Connected and All iseven more substantial: 28 percentage points and6 points, respectively.
Notice that ILP has thesame performance as Local for Singletons, as thediscourse constraints are not applied over uncon-nected instances.
Finally, HYB significantly out-performs Local under all conditions.
The signif-icance levels of the improvements over Local arehighlighted in Table 4.
These improvements alsosignify that the underlying discourse scheme iseffective, and adaptable to different implementa-tions.Interestingly, ICA and ILP improve over Localin different ways.
While ILP sharply improves theperformance over the connected instances, ICAshows relatively modest improvements over bothconnected and singletons.
ICA?s improvementover singletons is interesting because it indicatesthat, even though the features in Table 1 are fo-cused on discourse relations, ICA utilizes them tolearn the classification of singletons too.Comparing our discourse-based approaches,ILP does significantly better than ICA over con-nected instances (p < 0.001), while ICA doessignificantly better than ILP over singletons (p <175Base Base-2 Local ICA ILP HYBConnected 24.4 47.56 46.66 55.64 75.07 75.07Singleton 51.72 63.23 75.73 78.72 75.73 78.72All 45.34 59.46 68.72 73.31 75.35 77.72Table 4: Accuracies of the classifiers measured over Connected, Singleton and All instances.
Perfor-mance significantly better than Local are indicated in bold for p < 0.001 and underline for p < 0.01.0.01).
However, there is no significant differencebetween ICA and ILP for the All condition.
TheHYB classifier outperforms ILP for the Singletoncondition (p < 0.01) and ICA for the Connectedcondition (p < 0.001).
Interestingly, over all in-stances (the All condition), HYB also performssignificantly better than both ICA (p < 0.001) andILP (p < 0.01).5.3 AnalysisAmongst our two approaches, ILP performs bet-ter, and hence we further analyze its behavior tounderstand how the improvements are achieved.Table 5 reports the performance of ILP and Localfor the precision, recall and f-measure metrics (av-eraged over 7 test folds), measured separately foreach of the opinion categories.
The most promi-nent improvement by ILP is observed for the re-call of the polar categories under the Connectedcondition: 40 percentage points for the positiveclass, and 29 percentage points for the negativeclass.
The gain in recall is not accompanied bya significant loss in precision.
This results in animprovement in f-measure for the polar categories(24 points for positive and 16 points for negative).Also note that, by virtue of the constraint in Equa-tion 7, ILP does not classify any connected in-stance as neutral; thus the precision is NaN, recallis 0 and the f-meaure is NaN.
This is indicated as* in the Table.The improvement of ILP for the All condition,for the polar classes, follows a similar trend for re-call (18 to 21 point improvement) and f-measure(9 to 13 point improvement).
In addition to this,the ILP has an overall improvement in precisionover Local.
This may seem counterintuitive, asin Table 5, ILP?s precision for connected nodes issimilar to, or lower than, that of Local.
This isexplained by the fact that, while going from con-nected to overall conditions, Local?s polar predic-tions increase by threefold (565 to 1482), but itscorrect polar predictions increase by only twofold(430 to 801).
Thus, the ratio of change in the totalGold LocalPos Neg Neut TotalPos 551 113 532 1196Neg 121 250 205 576Neut 312 135 2387 2834Total 984 498 3124 4606Gold ILPPos Neg Neut TotalPos 817 157 222 1196Neg 147 358 71 576Neut 358 147 2329 2834Total 1322 662 2622 4606Table 6: Contingency table over all instances.polar predictions to the correct polar predictions is3 : 2.
On the other hand, while polar predictionsby ILP increase by only twofold (1067 to 1984),its correct polar predictions increase by 1.5 times(804 to 1175).
Here, the ratio of change in the totalpolar predictions to the correct polar predictions is4 : 3, a smaller ratio.The contingency table (Table 6) shows how Lo-cal and ILP compare against the gold standardannotations.
Notice here, that even though ILPmakes more polar guesses as compared to Local, agreater proportion of the ILP guesses are correct.The number of non-diagonal elements are muchsmaller for ILP, resulting in the accuracy improve-ments seen in Table 4.6 Examples and DiscussionThe results in Table 4 show that Local, which pro-vides the classifications for bootstrapping ICA andILP, predicts an incorrect class for more than 50%of the connected instances.
Methods starting withnoisy starting points are in danger of propagatingthe errors and hence worsening the performance.Interestingly, in spite of starting with so many badclassifications, ILP is able to achieve a large per-formance improvement.
We discovered that, givena set of connected instances, even when Local hasonly one correct guess, ILP is able to use this torectify the related instances.
We illustrate this situ-ation in Figure 2, which reproduces the connectedDAs for Example 1.
It shows the classifications176Positive Negative NeutralLocal ILP Local ILP Local ILPConnected-Prec 78.1 78.2 71.9 69.8 12.1Connected-Recall 45.3 86.3 44.1 73.4 62.8 *Connected-F1 56.8 81.5 54.0 70.7 18.5All-Prec 56.2 61.3 52.3 54.6 76.3 88.3All-Recall 46.6 67.7 44.3 62.5 83.9 81.5All-F1 50.4 64.0 46.0 57.1 79.6 84.6Table 5: Precision, Recall, Fmeasure for each Polarity category.
Performance significantly better thanLocal are indicated in bold (p < 0.001), underline (p < 0.01) and italics (p < 0.05).
The * denotes thatILP does not retrieve any connected node as neutral.Figure 2: Discourse Relations and Classificationsfor Example 1.for each DA from the gold standard (G), the Localclassifier (L) and the ILP classifier (ILP).
Observethat Local predicts the correct positive class (+) foronly DA-4 (the DA containing bit more durableand ergonomic).
Notice that these are clear casesof positive evaluation.
It incorrectly predicts thepolarity of DA-2 (containing bit more bouncy)as neutral (*), and DA-5 (containing a bit dif-ferent from all the other remote controls) asnegative (-).
DA-2 and DA-5 exemplify the factthat polarity classification is a complex and diffi-cult problem: being bouncy is a positive evalua-tion in this particular discourse context, and maynot be so elsewhere.
Thus, naturally, lexicons andunigram-based learning would fail to capture thispositive evaluation.
Similarly, ?being different?could be deemed negative in other discourse con-texts.
However, ILP is able to arrive at the correctpredictions for all the instances.
As the DA-4 isconnected to both DA-2 and DA-5 via a discourserelation that enforces an equal-polarity constraint(same+reinforcing relation of row 1, Table 2), bothof the misclassifications are rectified.
Presumably,the incorrect predictions made by Local are lowconfidence estimates, while the predictions of thecorrect cases have high confidence, which makesit possible for ILP to make the corrections.We also observed the propagation of the correctclassification for other types of discourse relations,for more complex types of connectivity, and alsofor conditions where an instance is not directlyconnected to the correctly predicted instance.
Themeeting snippet below (Example 2) and its cor-responding DA relations (Figure 3) illustrate this.This example is a reinforcing discourse where thespeaker is arguing for the number keypad, which isan alternative to the scrolling option.
Thus, he ar-gues against the scrolling, and argues for enteringthe number (which is a capability of the numberkeypad).
(2) D-1: I reckon you?re gonna have to have a num-ber keypad anyway for the amount of channels thesedays,D-2: You wouldn?t want to just have to scrollthrough all the channels to get to the one you wantD-3: You wanna enter just the number of it , if youknow itD-4: I reckon we?re gonna have to have a numberkeypad anywayIn Figure 3, we see that, DA-2 is connected via analternative+reinforcing discourse relation to eachof its neighbors DA-1 and DA-3, which encour-ages the optimization to choose a class for it thatis opposite to DA-1 and DA-3.
Notice also, thateven though Local predicts only DA-4 correctly,this correct classification finally influences the cor-rect choice for all the instances, including the re-motely connected DA-2.7 Conclusions and Future WorkThis work focuses on the first step to ascertainwhether discourse relations are useful for improv-ing opinion polarity classification, whether theycan be modeled and what modeling choices canbe used.
To this end, we explored two distinctparadigms: the supervised ICA and the unsuper-vised ILP.
We showed that both of our approachesare effective in exploiting discourse relations to177Figure 3: Discourse Relations and Classifications for Example 2.significantly improve polarity classification.
Wefound that there is a difference in how ICA andILP achieve improvements, and that combiningthe two in a hybrid approach can lead to furtheroverall improvement.
Quantitatively, we showedthat our approach is able to achieve a large in-crease in recall of the polar categories withoutharming the precision, which results in the perfor-mance improvements.
Qualitatively, we illustratedhow, even if the bootstrapping process is noisy,the optimization and discourse constraints effec-tively rectify the misclassifications.
The improve-ments of our diverse global inference approachesindicate that discourse information can be adaptedin different ways to augment and improve existingopinion analysis techniques.The automation of the discourse-relation recog-nition is the next step in this research.
The be-havior of ICA and ILP can change, depending onthe automation of discourse level recognition.
Theimplementation and comparison of the two meth-ods under full automation is the focus of our futurework.AcknowledgmentsThis research was supported in part by theDepartment of Homeland Security under grantN000140710152 and NSF Grant No.
0746930.We would also like to thank the anonymous re-viewers for their helpful comments.ReferencesN.
Asher, F. Benamara, and Y. Mathieu.
2008.
Dis-tilling opinion in discourse: A preliminary study.COLING-2008.M.
Bansal, C. Cardie, and L. Lee.
2008.
The power ofnegative thinking: Exploiting label disagreement inthe min-cut classification framework.
In COLING-2008.M.
Bilgic, G. M. Namata, and L. Getoor.
2007.
Com-bining collective classification and link prediction.In Workshop on Mining Graphs and Complex Struc-tures at the IEEE International Conference on DataMining.J.
Carletta, S. Ashby, S. Bourban, M. Flynn,M.
Guillemot, T. Hain, J. Kadlec, V. Karaiskos,W.
Kraaij, M. Kronenthal, G. Lathoud, M. Lincoln,A.
Lisowska, I. McCowan, W. Post, D. Reidsma, andP.
Wellner.
2005.
The ami meetings corpus.
In Pro-ceedings of the Measuring Behavior Symposium on?Annotating and measuring Meeting Behavior?.Y.
Choi, E. Breck, and C. Cardie.
2006.
Joint extrac-tion of entities and relations for opinion recognition.In EMNLP 2006.P.
Denis and J. Baldridge.
2007.
Joint determinationof anaphoricity and coreference resolution using in-teger programming.
In HLT-NAACL 2007.A.
Devitt and K. Ahmad.
2007.
Sentiment polarityidentification in financial news: A cohesion-basedapproach.
In ACL 2007.A.
B. Goldberg and X. Zhu.
2006.
Seeing starswhen there aren?t many stars: Graph-based semi-supervised learning for sentiment categorization.
InHLT-NAACL 2006 Workshop on Textgraphs: Graph-based Algorithms for Natural Language Processing.A.
Haghighi, K. Toutanova, and C. Manning.
2005.
Ajoint model for semantic role labeling.
In CoNLL.H.
Kanayama and T. Nasukawa.
2006.
Fully auto-matic lexicon expansion for domain-oriented sen-timent analysis.
In EMNLP-2006, pages 355?363,Sydney, Australia.A.
Kennedy and D. Inkpen.
2006.
Sentiment classi-fication of movie reviews using contextual valenceshifters.
Computational Intelligence, 22(2):110?125.Q.
Lu and L. Getoor.
2003.
Link-based classification.In Proceedings of the International Conference onMachine Learning (ICML).A.
Moschitti, D. Pighin, and R. Basili.
2006.
Seman-tic role labeling via tree kernel joint inference.
InCoNLL.A.
Moschitti.
2009.
Syntactic and semantic kernels forshort text pair categorization.
In EACL.178D.
Neiberg, K. Elenius, and K. Laskowski.
2006.Emotion recognition in spontaneous speech usinggmms.
In INTERSPEECH 2006 ICSLP.J.
Neville and D. Jensen.
2000.
Iterative classifica-tion in relational data.
In In Proc.
AAAI-2000 Work-shop on Learning Statistical Models from RelationalData, pages 13?20.
AAAI Press.B.
Pang and L. Lee.
2004.
A sentimental education:Sentiment analysis using subjectivity summarizationbased on minimum cuts.
In ACl 2004.L.
Polanyi and A. Zaenen, 2006.
Contextual ValenceShifters.
Computing Attitude and Affect in Text:Theory and Applications.A.-M. Popescu and O. Etzioni.
2005.
Extracting prod-uct features and opinions from reviews.
In HLT-EMNLP 2005.S.
Raaijmakers, K. Truong, and T. Wilson.
2008.
Mul-timodal subjectivity analysis of multiparty conversa-tion.
In EMNLP.M.
Richardson and P. Domingos.
2006.
Markov logicnetworks.
Mach.
Learn., 62(1-2):107?136.D.
Roth and W. Yih.
2004.
A linear programmingformulation for global inference in natural languagetasks.
In Proceedings of CoNLL-2004, pages 1?8.Boston, MA, USA.K.
Sadamitsu, S. Sekine, and M. Yamamoto.
2008.Sentiment analysis based on probabilistic models us-ing inter-sentence information.
In LREC?08.S.
Somasundaran, J. Ruppenhofer, and J. Wiebe.
2007.Detecting arguing and sentiment in meetings.
InSIGdial Workshop on Discourse and Dialogue 2007.S.
Somasundaran, J. Wiebe, and J. Ruppenhofer.
2008.Discourse level opinion interpretation.
In Coling2008.H.
Takamura, T. Inui, and M. Okumura.
2007.
Extract-ing semantic orientations of phrases from dictionary.In HLT-NAACL 2007.B.
Taskar, M. Wong, P. Abbeel, and D. Koller.
2004.Link prediction in relational data.
In Neural Infor-mation Processing Systems.M.
Thomas, B. Pang, and L. Lee.
2006.
Get out thevote: Determining support or opposition from con-gressional floor-debate transcripts.
In EMNLP 2006.T.
Wilson, J. Wiebe, and P. Hoffmann.
2005.
Recog-nizing contextual polarity in phrase-level sentimentanalysis.
In HLT-EMNLP 2005.I.
H. Witten and E. Frank.
2002.
Data mining: practi-cal machine learning tools and techniques with javaimplementations.
SIGMOD Rec., 31(1):76?77.179
