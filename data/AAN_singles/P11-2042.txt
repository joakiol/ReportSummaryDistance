Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pages 242?247,Portland, Oregon, June 19-24, 2011. c?2011 Association for Computational LinguisticsData-oriented Monologue-to-Dialogue GenerationPaul PiwekCentre for Research in ComputingThe Open UniversityWalton Hall, Milton Keynes, UKp.piwek@open.ac.ukSvetlana StoyanchevCentre for Research in ComputingThe Open UniversityWalton Hall, Milton Keynes, UKs.stoyanchev@open.ac.ukAbstractThis short paper introduces an implementedand evaluated monolingual Text-to-Text gen-eration system.
The system takes mono-logue and transforms it to two-participant di-alogue.
After briefly motivating the taskof monologue-to-dialogue generation, we de-scribe the system and present an evaluation interms of fluency and accuracy.1 IntroductionSeveral empirical studies show that delivering in-formation in the form of a dialogue, as opposed tomonologue, can be particularly effective for educa-tion (Craig et al, 2000; Lee et al, 1998) and per-suasion (Suzuki and Yamada, 2004).
Information-delivering or expository dialogue was already em-ployed by Plato to communicate his philosophy.
Itis used primarily to convey information and possiblyalso make an argument; this in contrast with dra-matic dialogue which focuses on character develop-ment and narrative.Expository dialogue lends itself well for presenta-tion through computer-animated agents (Prendingerand Ishizuka, 2004).
Most information is howeverlocked up as text in leaflets, books, newspapers,etc.
Automatic generation of dialogue from text inmonologue makes it possible to convert informationinto dialogue as and when needed.This paper describes the first data-orientedmonologue-to-dialogue generation system which re-lies on the automatic mapping of the discourserelations underlying monologue to appropriate se-quences of dialogue acts.
The approach is data-oriented in that the mapping rules have been auto-matically derived from an annotated parallel mono-logue/dialogue corpus, rather than being hand-crafted.The paper proceeds as follows.
Section 2 reviewsexisting approaches to dialogue generation.
Section3 describes the current approach.
We provide anevaluation in Section 4.
Finally, Section 5 describesour conclusions and plans for further research.2 Related WorkFor the past decade, generation of information-delivering dialogues has been approached primarilyas an AI planning task.
Andre?
et al (2000) describea system, based on a centralised dialogue planner,that creates dialogues between a virtual car buyerand seller from a database; this approach has beenextended by van Deemter et al (2008).
Others haveused (semi-) autonomous agents for dialogue gener-ation (Cavazza and Charles, 2005; Mateas and Stern,2005).More recently, first steps have been taken towardstreating dialogue generation as an instance of Text-to-Text generation (Rus et al, 2007).
In particu-lar, the T2D system (Piwek et al, 2007) employsrules that map text annotated with discourse struc-tures, along the lines of Rhetorical Structure Theory(Mann and Thompson, 1988), to specific dialoguesequences.
Common to all the approaches discussedso far has been the manual creation of generationresources, whether it be mappings from knowledgerepresentations or discourse to dialogue structure.242With the creation of the publicly available1 CODAparallel corpus of monologue and dialogue (Stoy-anchev and Piwek, 2010a), it has, however, becomepossible to adopt a data-oriented approach.
This cor-pus consists of approximately 700 turns of dialogue,by acclaimed authors such as Mark Twain, that arealigned with monologue that was written on the ba-sis of the dialogue, with the specific aim to expressthe same information as the dialogue.2 The mono-logue side has been annotated with discourse rela-tions, using an adaptation of the annotation guide-lines of Carlson and Marcu (2001), whereas the di-alogue side has been marked up with dialogue acts,using tags inspired by the schemes of Bunt (2000),Carletta et al (1997) and Core and Allen (1997).As we will describe in the next section, our ap-proach uses the CODA corpus to extract mappingsfrom monologue to dialogue.3 Monologue-to-Dialogue GenerationApproachOur approach is based on five principal steps:I Discourse parsing: analysis of the input mono-logue in terms of the underlying discourse rela-tions.II Relation conversion: mapping of text annotatedwith discourse relations to a sequence of dia-logue acts, with segments of the input text as-signed to corresponding dialogue acts.III Verbalisation: verbal realisation of dialogueacts based on the dialogue act type and text ofthe corresponding monologue segment.IV Combination Putting the verbalised dialoguesacts together to create a complete dialogue, andV Presentation: Rendering of the dialogue (thiscan range for simple textual dialogue scripts tocomputer-animated spoken dialogue).1computing.open.ac.uk/coda/data.html2Consequently, the corpus was not constructed entirely ofpre-existing text; some of the text was authored as part of thecorpus construction.
One could therefore argue, as one of the re-viewers for this paper did, that the approach is not entirely data-driven, if data-driven is interpreted as ?generated from unadul-terated, free text, without any human intervention needed?.For step I we rely on human annotation or existingdiscourse parsers such as DAS (Le and Abeysinghe,2003) and HILDA (duVerle and Prendinger, 2009).For the current study, the final step, V, consists sim-ply of verbatim presentation of the dialogue text.The focus of the current paper is with steps II andIII (with combination, step IV, beyond the scope ofthe current paper).
Step II is data-oriented in thatwe have extracted mappings from discourse relationoccurrences in the corpus to corresponding dialogueact sequences, following the approach described inPiwek and Stoyanchev (2010).
Stoyanchev and Pi-wek (2010b) observed in the CODA corpus a greatvariety of Dialogue Act (DA) sequences that couldbe used in step II, however in the current versionof the system we selected a representative set of themost frequent DA sequences for the five most com-mon discourse relations in the corpus.
Table 1 showsthe mapping from text with a discourse relationsto dialogue act sequences (i indicates implementedmappings).DA sequence A C C E M TRD T R M TYNQ; Expl i i dYNQ; Yes; Expl i i i dExpl; CmplQ; Expl i dComplQ; Expl i/t i/t i i cExpl; YNQ;Yes i dExpl; Contrad.
i dFactQ; FactA; Expl i cExpl; Agr; Expl i dExpl; Fact; Expl t cTable 1: Mappings from discourse relations (A = Attribu-tion, CD = Condition, CT = Contrast, ER = Explanation-Reason, MM = Manner-Means) to dialogue act sequences(explained below) together with the type of verbalisationtransformation TR being d(irect) or c(omplex).For comparison, the table also shows the muchless varied mappings implemented by the T2D sys-tem (indicated with t).
Note that the actual mappingsof the T2D system are directly from discourse rela-tion to dialogue text.
The dialogue acts are not ex-plicitly represented by the system, in contrast withthe current two stage approach which distinguishesbetween relation conversion and verbalisation.243Verbalisation, step III, takes a dialogue act typeand the specification of its semantic content as givenby the input monologue text.
Mapping this to theappropriate dialogue act requires mappings that varyin complexity.For example, Expl(ain) can be generated by sim-ply copying a monologue segment to dialogue utter-ance.
The dialogue acts Yes and Agreement can begenerated using canned text, such as ?That is true?and ?I agree with you?.In contrast, ComplQ (Complex Question), FactQ(Factoid Question), FactA (Factiod Answer) andYNQ (Yes/No Question) all require syntactic ma-nipulation.
To generate YNQ and FactQ, we usethe CMU Question Generation tool (Heilman andSmith, 2010) which is based on a combinationof syntactic transformation rules implemented withtregex (Levy and Andrew, 2006) and statisticalmethods.
To generate the Compl(ex) Q(uestion) inthe ComplQ;Expl Dialogue Act (DA) sequence, weuse a combination of the CMU tool and lexical trans-formation rules.3 The GEN example in Table 2 il-lustrates this: The input monologue has a Manner-Means relations between the nucleus ?In September,Ashland settled the long-simmering dispute?
and thesatellite ?by agreeing to pay Iran 325 million USD?.The satellite is copied without alteration to the Ex-plain dialogue act.
The nucleus is processed by ap-plying the following template-based rule:Decl?
How Yes/No Question(Decl)In words, the input consisting of a declarative sen-tence is mapped to a sequence consisting of the word?How?
followed by a Yes/No-question (in this case?Did Ashland settle the long-simmering dispute inDecember??)
that is obtained with the CMU QG toolfrom the declarative input sentence.
A similar ap-proach is applied for the other relations (Attribution,Condition and Explanation-Reason) that can lead toa ComplQ; Expl dialogue act sequence (see Table 1).Generally, sequences requiring only copying orcanned text are labelled d(irect) in Table 1, whereasthose requiring syntactic transformation are labelledc(omplex).3In contrast, the ComplQ in the DA sequenceExpl;ComplQ;Expl is generated using canned text such as?Why??
or ?Why is that?
?.4 EvaluationWe evaluate the output generated with both complexand direct rules for the relations of Table 1.4.1 Materials, Judges and ProcedureThe input monologues were text excerpts from theWall Street Journal as annotated in the RST Dis-course Treebank4.
They consisted of a single sen-tence with one internal relation, or two sentences(with no internal relations) connected by a singlerelation.
To factor out the quality of the discourseannotations, we used the gold standard annotationsof the Discourse Treebank and checked these forcorrectness, discarding a small number of incorrectannotations.5 We included text fragments with avariety of clause length, ordering of nucleus andsatellite, and syntactic structure of clauses.
Table 2shows examples of monologue/dialogue pairs: onewith a generated dialogue and the other from the cor-pus.Our study involved a panel of four judges, eachfluent speakers of English (three native) and ex-perts in Natural Language Generation.
We collectedjudgements on 53 pairs of monologue and corre-sponding dialogue.
19 pairs were judged by all fourjudges to obtain inter-annotator agreement statistics,the remainder was parcelled out.
38 pairs consistedof WSJ monologue and generated dialogue, hence-forth GEN, and 15 pairs of CODA corpus monologueand human-authored dialogue, henceforth CORPUS(instances of generated and corpus dialogue wererandomly interleaved) ?
see Table 2 for examples.The two standard evaluation measures for lan-guage generation, accuracy and fluency (Mellish andDale, 1998), were used: a) accuracy: whether adialogue (from GEN or CORPUS) preserves the in-formation of the corresponding monologue (judge-ment: ?Yes?
or ?No?)
and b) monologue and dialoguefluency: how well written a piece of monologue ordialogue from GEN or CORPUS is.
Fluency judge-ments were on a scale from 1 ?incomprehensible?
to5 ?Comprehensible, grammatically correct and nat-urally sounding?.4www.isi.edu/?marcu/discourse/Corpora.html5For instance, in our view ?without wondering?
is incorrectlyconnected with the attribution relation to ?whether she is mov-ing as gracefully as the scenery.
?244GEN MonologueIn September, Ashland settled thelong-simmering dispute by agreeing topay Iran 325 million USD.Dialogue (ComplQ; Expl)A: How did Ashland settle thelong-simmering dispute in December?B: By agreeing to pay Iran 325million USD.CORPUS MonologueIf you say ?I believe the world isround?, the ?I?
is the mind.Dialogue (FactQ; FactA)A: If you say ?I believe the world is round?,who is the ?I?
that is speaking?B: The mind.Table 2: Monologue-Dialogue Instances4.2 ResultsAccuracy Three of the four judges marked 90%of monologue-dialogue pairs as presenting the sameinformation (with pairwise ?
of .64, .45 and .31).One judge interpreted the question differently andmarked only 39% of pairs as containing the sameinformation.
We treated this as an outlier, and ex-cluded the accuracy data of this judge.
For the in-stances marked by more than one judge, we took themajority vote.
We found that 12 out of 13 instances(or 92%) of dialogue and monologue pairs from theCORPUS benchmark sample were judged to containthe same information.
For the GEN monologue-dialogue pairs, 28 out of 31 (90%) were judged tocontain the same information.Fluency Although absolute agreement betweenjudges was low,6 pairwise agreement in terms ofSpearman rank correlation (?)
is reasonable (aver-age: .69, best: .91, worst: .56).
For the subset of in-stances with multiple annotations, we used the datafrom the judge with the highest average pair-wiseagreement (?
= .86)The fluency ratings are summarised in Figure 1.Judges ranked both monologues and dialogues for6For the four judges, we had an average pairwise ?
of .34with the maximum and minimum values of .52 and .23, respec-tively.Figure 1: Mean Fluency Rating for Monologues and Dia-logues (for 15 CORPUS and 38 GEN instances) with 95%confidence intervalsthe GEN sample higher than for the CORPUS sam-ple (possibly as a result of slightly greater length ofthe CORPUS fragments and some use of archaic lan-guage).
However, the drop in fluency, see Figure 2,from monologue to dialogue is greater for GEN sam-ple (average: .89 points on the rating scale) than theCORPUS sample (average: .33) (T-test p<.05), sug-gesting that there is scope for improving the genera-tion algorithm.Figure 2: Fluency drop from monologue to correspond-ing dialogue (for 15 CORPUS and 38 GEN instances).
Onthe x-axis the fluency drop is marked, starting from nofluency drop (0) to a fluency drop of 3 (i.e., the dialogueis rated 3 points less than the monologue on the ratingscale).245Direct versus Complex rules We examined thedifference in fluency drop between direct and com-plex rules.
Figure 3 shows that the drop in fluencyfor dialogues generated with complex rules is higherthan for the dialogues generated using direct rules(T-test p<.05).
This suggests that use of direct rulesis more likely to result in high quality dialogue.
Thisis encouraging, given that Stoyanchev and Piwek(2010a) report higher frequencies in professionallyauthored dialogues of dialogue acts (YNQ, Expl) thatcan be dealt with using direct verbalisation (in con-trast with low frequency of, e.g., FactQ).Figure 3: Decrease in Fluency Score from Monologueto Dialogue comparing Direct (24 samples) and Complex(14 samples) dialogue generation rules5 Conclusions and Further WorkWith information presentation in dialogue form be-ing particularly suited for education and persua-sion, the presented system is a step towards mak-ing information from text automatically availableas dialogue.
The system relies on discourse-to-dialogue structure rules that were automatically ex-tracted from a parallel monologue/dialogue corpus.An evaluation against a benchmark sample from thehuman-written corpus shows that both accuracy andfluency of generated dialogues are not worse thanthat of human-written dialogues.
However, drop influency between input monologue and output dia-logue is slightly worse for generated dialogues thanfor the benchmark sample.
We also established a dif-ference in quality of output generated with complexversus direct discourse-to-dialogue rules, which canbe exploited to improve overall output quality.In future research, we aim to evaluate the accu-racy and fluency of longer stretches of generated di-alogue.
Additionally, we are currently carrying outa task-related evaluation of monologue versus dia-logue to determine the utility of each.AcknowledgementsWe would like to thank the three anonymousreviewers for their helpful comments and sug-gestions.
We are also grateful to our col-leagues in the Open University?s Natural Lan-guage Generation group for stimulating discussionsand feedback.
The research reported in this pa-per was carried out as part of the CODA re-search project (http://computing.open.ac.uk/coda/)which was funded by the UK?s Engineering andPhysical Sciences Research Council under GrantEP/G020981/1.ReferencesE.
Andre?, T. Rist, S. van Mulken, M. Klesen, andS.
Baldes.
2000.
The automated design of believabledialogues for animated presentation teams.
In Jus-tine Cassell, Joseph Sullivan, Scott Prevost, and Eliz-abeth Churchill, editors, Embodied ConversationalAgents, pages 220?255.
MIT Press, Cambridge, Mas-sachusetts.H.
Bunt.
2000.
Dialogue pragmatics and context spec-ification.
In H. Bunt and W. Black, editors, Abduc-tion, Belief and Context in Dialogue: Studies in Com-putational Pragmatics, volume 1 of Natural LanguageProcessing, pages 81?150.
John Benjamins.J.
Carletta, A. Isard, S. Isard, J. Kowtko, G. Doherty-Sneddon, and A. Anderson.
1997.
The reliability ofa dialogue structure coding scheme.
ComputationalLinguistics, 23:13?31.L.
Carlson and D. Marcu.
2001.
Discourse taggingreference manual.
Technical Report ISI-TR-545, ISI,September.M.
Cavazza and F. Charles.
2005.
Dialogue Gener-ation in Character-based Interactive Storytelling.
InProceedings of the AAAI First Annual Artificial Intel-ligence and Interactive Digital Entertainment Confer-ence, Marina Del Rey, California, USA.M.
Core and J. Allen.
1997.
Coding Dialogs withthe DAMSL Annotation Scheme.
In Working Notes:AAAI Fall Symposium on Communicative Action inHumans and Machine.246S.
Craig, B. Gholson, M. Ventura, A. Graesser, and theTutoring Research Group.
2000.
Overhearing dia-logues and monologues in virtual tutoring sessions.International Journal of Artificial Intelligence in Ed-ucation, 11:242?253.D.
duVerle and H. Prendinger.
2009.
A novel discourseparser based on support vector machines.
In Proc 47thAnnual Meeting of the Association for ComputationalLinguistics and the 4th Int?l Joint Conf on NaturalLanguage Processing of the Asian Federation of Nat-ural Language Processing (ACL-IJCNLP?09), pages665?673, Singapore, August.M.
Heilman and N. A. Smith.
2010.
Good question!statistical ranking for question generation.
In Proc.
ofNAACL/HLT, Los Angeles.Huong T. Le and Geehta Abeysinghe.
2003.
A study toimprove the efficiency of a discourse parsing system.In Proceedings 4th International Conference on Intel-ligent Text Processing and Computational Linguistics(CICLing-03), Springer LNCS 2588, pages 101?114.J.
Lee, F. Dinneen, and J. McKendree.
1998.
Supportingstudent discussions: it isn?t just talk.
Education andInformation Technologies, 3:217?229.R.
Levy and G. Andrew.
2006.
Tregex and tsurgeon:tools for querying and manipulating tree data struc-tures.
In 5th International Conference on LanguageResources and Evaluation (LREC 2006)., Genoa, Italy.William C. Mann and Sandra A. Thompson.
1988.Rhetorical structure theory: Toward a functional the-ory of text organization.
Text, 8(3):243?281.M.
Mateas and A. Stern.
2005.
Structuring content in thefaade interactive drama architecture.
In Proc.
of Artifi-cial Intelligence and Interactive Digital Entertainment(AIIDE), Marina del Rey, Los Angeles, June.C.
Mellish and R. Dale.
1998.
Evaluation in the contextof natural language generation.
Computer Speech andLanguage, 12:349?373.P.
Piwek and S. Stoyanchev.
2010.
Generating Exposi-tory Dialogue from Monologue: Motivation, Corpusand Preliminary Rules.
In Human Language Tech-nologies: The 2010 Annual Conference of the NorthAmerican Chapter of the Association for Computa-tional Linguistics, pages 333?336, Los Angeles, Cali-fornia, June.P.
Piwek, H. Hernault, H. Prendinger, and M. Ishizuka.2007.
T2D: Generating Dialogues between VirtualAgents Automatically from Text.
In Intelligent Vir-tual Agents: Proceedings of IVA07, LNAI 4722, pages161?174.
Springer Verlag.H.
Prendinger and M. Ishizuka, editors.
2004.
Life-LikeCharacters: Tools, Affective Functions, and Applica-tions.
Cognitive Technologies Series.
Springer, Berlin.V.
Rus, A. Graesser, A. Stent, M. Walker, and M. White.2007.
Text-to-Text Generation.
In R. Dale andM.
White, editors, Shared Tasks and ComparativeEvaluation in Natural Language Generation: Work-shop Report, Arlington, Virginia.S.
Stoyanchev and P. Piwek.
2010a.
Constructing theCODA corpus.
In Procs of LREC 2010, Malta, May.S.
Stoyanchev and P. Piwek.
2010b.
Harvesting re-usablehigh-level rules for expository dialogue generation.
In6th International Natural Language Generation Con-ference (INLG 2010), Dublin, Ireland, 7-8, July.S.
V. Suzuki and S. Yamada.
2004.
Persuasion throughoverheard communication by life-like agents.
In Procsof the 2004 IEEE/WIC/ACM International Conferenceon Intelligent Agent Technology, Beijing, September.K.
van Deemter, B. Krenn, P. Piwek, M. Klesen,M.
Schroeder, and S. Baumann.
2008.
Fully Gen-erated Scripted Dialogue for Embodied Agents.
Arti-ficial Intelligence Journal, 172(10):1219?1244.247
