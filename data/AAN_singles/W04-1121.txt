Aligning Bilingual Corpora Using Sentences Location Information*Li Weigang   Liu Ting   Wang Zhen   Li ShengInformation Retrieval Lab, Computer Science & Technology School,Harbin Institute of Technology 321#Harbin, China, 150001{LEE, tliu, wangzhen, lis}@ir.hit.edu.cnAbstractLarge amounts of bilingual resource on the Internetprovide us with the probability of building a largescale of bilingual corpus.
The irregular characteris-tics of the real texts, especially without the strictlyaligned paragraph boundaries, bring a challenge toalignment technology.
The traditional alignmentmethods have some difficulties in competency fordoing this.
This paper describes a new method foraligning real bilingual texts using sentence pairlocation information.
The model was motivated bythe observation that the location of a sentence pairwith certain length is distributed in the whole textsimilarly.
It uses (1:1) sentence beads instead ofhigh frequency words as the candidate anchors.The method was developed and evaluated throughmany different test data.
The results show that itcan achieve good aligned performance and be ro-bust and language independent.
It can resolve thealignment problem on real bilingual text.1 IntroductionThere have been a number of papers on aligningparallel texts at the sentence level in the last cen-tury, e.g., (Brown et al 1991; Gale and Church,1993; Simard et al 1992; Wu DeKai 1994).
Onclean inputs, such as the Canadian Hansards andthe Hong Kang Hansards, these methods have beenvery successful.
(Church, Kenneth W, 1993; Chen, Stanley, 1993)proposed some methods to resolve the problem innoisy bilingual texts.
Cognate information betweenIndo-European languages pairs are used to align n-oisy texts.
But these methods are limited whenaligning the language pairs which are not in thesame genre or have no cognate information.
(Fung,1994) proposed a new algorithm to resolve thisproblem to some extent.
The algorithm uses fre-quency, position and recency information as fea-tures for pattern matching.
(W. Bin, 2000) adaptedthe similar idea with (Fung, 1994) to align specialdomain bilingual texts.
Their algorithms needsome high frequency word pairs as anchor points.When processing the texts that include less high-frequency words, these methods will performweakly and with less precision because of the scar-city of the data problem.
(Haruno and Yamazaki, 1996) tried to alignshort texts without enough repeated words in struc-turally different languages, such as English andJapanese.
They applied the POS information ofcontent words and an online dictionary to findmatching word pairs.
But this is only suitable forthe short texts.The real text always includes some noisy infor-mation.
It has the following characteristics as fol-lows:1) There are no strict aligned paragraph bounda-ries in real bilingual text;2) Some paragraphs may be merged into a largerparagraph because of the translator?s individualidea;3) There are many complex translation patternsin real text;4)  There exist different styles and themes;5) Different genres have different inherent char-acteristics.The tradition approaches to alignment fall intotwo main classes: lexical and length.
All thesemethods have limitations when facing the real textaccording to the characteristics mentioned above.
* This research was supported by National NaturalScience Foundation (60203020) and Science Founda-tion of Harbin Institute of technology (hit.2002.73).We proposed a new alignment method based onthe sentences location information.
Its basic idea isthat the location of a sentence pair with certainlength is distributed in the whole text similarly.The local and global location information of a sen-tence pair is fully combined together to determinethe probability with which the sentence pair is asentence bead.In the first of the following sections, we describeseveral concepts.
The subsequent section reportsthe mathematical model of our alignment approach.Section 4 presents the process of anchors selectionand algorithm implementation is shown in section5.
The experiment results and discussion are shownin section 6.
In the final section, we conclude witha discussion of future work.2 Several conceptions1) Alignment anchors: (Brown, 1991) firstly in-troduced the concept of alignment anchors whenhe aligned Hansard corpus.
He considered that thewhole texts were divided into some small frag-ments by these alignment anchors.
Anchors aresome aligned sentence pairs.2) Sentence bead:  and at the same time, (Brown,1991) called each aligned sentence pair a sentencebead.
Sentence bead has some different styles,such as (0:1), (1:0), (1:1), (1:2), (1: more), (2:1),(2:2), (2: more), (more: 1), (more: 2), (more: more).3) Sentence pair: Any two sentences in the bilin-gual text can construct a sentence pair.4) Candidate anchors: Candidate anchors arethose that can be possible alignment anchors.
Inthis paper, all (1:1) sentence beads are categorizedas candidate anchors.3 Mathematical Model of AlignmentThe alignment process has two steps: the firststep is to integrate all the origin paragraphs intoone large paragraph.
This can eliminate the prob-lem induced by the vague paragraph boundaries.The second step is the alignment process.
Afteralignment, the bilingual text becomes sequences oftranslated fragments.
The unit of a fragment can beone sentence, two sentences or several sentences.The traditional alignment method can be used withthe fragment with several sentences to improve thealignment granularity.
In this paper the formal de-scription of the alignment task was given by ex-tending the concepts of bipartite graph andmatching in graph theory.3.1 Bipartite graphBipartite graph: Here, we assumed G to be anundirected graph, then it could be defined as G=<V,E>.
The vertex+ set of V has two finite subsets: V1and V2, also V1 ?
V2?V, V1?V2??.
Let E be acollection of pairs, when e?E, then e={vi, vj},where vi?V1,vj?V2.
The triple G was describedas, G=<V1, E, V2>, called bipartite graph.
In a bi-partite graph G, if each vertex of V1 is joined witheach vertex of V2, or vice versa, here an edgerepresents a sentence pair.
The collection E is theset of all the edges.
The triple G=<V1, E, V2> iscalled complete bipartite graph.
We consideredthat: |V1|?m, |V2|?n, where the parameters m andn are respectively the elements numbers of V1 andV2.
The complete bipartite graph was usually ab-breviated as Km, n (as shown in figure 1).3.2 MatchingMatching: Assuming G?<V1, E, V2> was a bi-partite graph.
A matching of G was defined as M, asubset of E with the property that no two edges ofM have a common vertex.3.3 Best Alignment MatchingThe procedure of alignment using sentence loca-tion information can be seen as a special matching.We defined this problem as ?Best AlignmentMatching?
(BAM).BAM: If M=<S, EM, T> is a best alignmentmatching of G=<S, E, T>, then M must meet thefollowing conditions:1) All the vertexes in the complete bipartitegraph are ordered;2) The weight of any edges in EM d(si, tj) has:d(si, tj)< D (where D is alignment threshold); at thesame time, there are no edges {sk, tr} which madek<i and r>j, or k>i and r<j;Figure 1 K3,3 complete bipartite graph3) If we consider: |S|=m and |T|=n, then the edge{sm, tn} belonged to EM;Best alignment matching can be attained bysearching for the smallest weight of edge in collec-tion E, until the weight of every edge d(si, tj) isequal or more than the alignment threshold D.Generally, the alignment threshold D is determinedaccording to experience because different textshave different styles.If each sentence in the text S (or T) corre-sponds with a vertex in V1(or V2), the text S or Tcan be denoted by S(s1, s2, s3,?si, ?sj, ?sm) orT(t1, t2, t3?ti, ?tj, ?tn).
Considering the formmerely, each element in S combined with any ele-ment in T can create a complete bipartite graph.Thus the alignment task can be seen as the processof searching for the BAM in the complete bipartitegraph.
As shown in figure 2, the edge e = {si, tj}belongs to M; this means that the i-th sentence intext S and the j-th sentence in text T can make analignment anchor.
Each edge is corresponding toan alignment value.
In order to ensure the bilingualtexts are divided with the same fragment number,we default that the last sentence in the bilingualtext is aligned.
That is to say, {sm, tn} E?
M wascorrect, if |S|=m and |T|=n in the BAM mathemati-cal model.We stipulated the smaller the alignment value is,the more similar the sentence pair is to a candidateanchor.
The smallest value of the sentence pair isfound from the complete bipartite graph.
Thatmeans the selected sentence pair is the most prob-able aligned (1:1) sentence bead.
Alignment proc-ess is completed until the alignment anchorsbecome saturated under alignment threshold value.Sentence pairs extracted from all sentence pairsare seen as alignment anchors.
These anchors di-vide the whole texts into short aligned fragments.The definition of BAM ensures that the selectedsentence pairs cannot produce cross-alignment er-rors, and some cases of (1: more) or (more: 1)alignment fragments can be attained by the frag-ments pairs between two selected alignment an-chors.4 Anchors Selection during AlignmentAll (1:1) sentence beads are extracted from dif-ferent styles of bilingual texts.
The distributionstates that all of them are similar as presented infigure 3.
The horizontal axis denotes the sentencenumber in Chinese text, and the vertical axis de-notes the sentence number in English text.-20 0 20 40 60 80 100 120 140 160 180-20020406080100120140160180200Sentence Number inEnglish TextSentence Number in Chinese TextBeadsStatistical results show that more than 85% sen-tence beads are (1:1) sentence beads in bilingualtexts and their distributions obey an obvious lawwell.
(DeKai Wu, 1994) offered that (1:1) sentencebeads occupied 89% in English-Chinese as well.
Ifwe select these style sentence beads as candidateanchors, the alignment method will be general onany other language pairs.
The main points of ouralignment method using sentences location infor-mation are: locating by the whole text, collocatingby sentence length and checking by a bilingualdictionary.
Location information of any sentencepair is used fully.
Three lengths are used: are sen-tence length, upper context length above the sen-tence pair and nether context length below thesentence.
All this information is considered to cal-culate the alignment weight of each sentence pair.Finally, the sentence pair with high weight will bechecked by a English-Chinese bilingual dictionary.In order to study the relationship between everysentence pair of {si, tj}, four parameters are defined:Whole text length ratio: P0 = Ls / Lt;Upper context length ratio: Pu[i, j] = Usi / Utj;Nether context length ratio: Pd[i, j] = Dsi / DtjSentence length ratio: Pl[i, j] = Lsi / Ltj;Figure 2 Sketch map of Km, n BAM underalignment threshold Dt1  t2   t3  t4  t5  t6  t7      ti     tj                      tn-2   tn-1  tns1  s2  s3   s4  s5   s6  s7      si   sj                    sm-2  sm-1 sm???????
?Figure 3 Distribution of (1:1) sentence beadsin bilingual textsWheresi    the i-th sentence of S;tj    the j-th sentence of T;Ls  the length of source language text S;Lt   the length of target language text T;Lsi  the length of si;Ltj  the length of tj;Usi  the upper context length above sentence si;Utj  the upper context length above sentence tj;Dsi  the nether context length below sentence si;Dtj  the nether context length below sentence tj;Figure 4 illustrates clearly the relationship of allvariables.If si and tj can construct a (1:1) alignment anchor,P[i, j] must be less than the alignment threshold,where P[i,j] denotes the integrated alignment valuebetween si and tj.
We assume that the weight coef-ficient of Pl[i, j] is 1.
Only considering the form,Pu[i, j] and Pd[i, j] must have the same weight co-efficient.
Here the weight coefficient is set ?.
Weconstructed a formal alignment function on everysentence pair:P[i,j] =?
(Pu[i, j]-P0)?
+ (Pl[i, j] -P0)?
+?
(Pd[i, j] -P0)?Where, the parameter ?
is the weight coefficient,if can adjust the weight of sentence pair length andthe weight of context lengths well.
The longer thetext is, the more insensitive the effect of the con-text-length is.
So ?
?s value should increase in orderto balance the whole proportion.
The short text isvice versa.
In this paper we define:?= (Ls/Lsi + Lt/Ltj)/2According to the definition of BAM, the smallerthe alignment function value of P[i, j] is, the morethe probability of sentence pair {si, tj} being a (1:1)sentence bead is.
In this paper, we adopt a greedyalgorithm to select alignment anchors according toall the alignment function values of P[i, j] whichare less than the alignment threshold.
This proce-dure can be implemented with a time complexityof O(m*n).To obtain further improvement in alignment ac-curacy requires calculation of the similarity of thesentence pairs.
An English-Chinese bilingual dic-tionary is adopted to calculate the semantic simi-larity between the two sentences in a sentence pair.The similarity formula based on a bilingual dic-tionary is followed:Where L| | is the bytes number of all elements,Match (T) is (according to English-Chinese dic-tionary) the English words which have Chinesetranslation in the Chinese sentence, Match (S) isthe matched Chinese fragments.According to the above dictionary check, align-ment precision is improved greatly.
We take a sta-tistic on all the errors and find that most errors arepartial alignment errors.
Partial alignment meansthat the alignment location is correct, but a halfpair of the alignment pairs is not integrated.
It isvery difficult to avoid these errors when only tak-ing into account the sentence location and lengthinformation.
Thus in order to reduce this kind oferror, we check the semantic similarity of the con-text-adjacent sentence pairs also.
Because thesepairs could be other alignment patterns, such as(1:2) or (2:1), the similarity formulas have somedifference from the (1:1) sentence pair formula.Here, a simple judgement is performed.
It isshown as:If?Lsi-1 * P0 > Ltj-1?elseHere, those alignment anchors whose similari-ties exceed the similarity threshold based on thebilingual dictionary will become the final align-ment anchors.
These final anchors divide the wholebilingual texts into aligned fragments.Figure 4 Sketch map of variables relationshipsi tjLsi LtjUsi UtjDsi DtjLs LtChinese Text English Texts1 t1tnsm| ( ) | | ( ) || | | |L Match S L Match TH L S L T+= +adjacentadjacent *)01(|)(||)(|LsPTMatchLSMatchLH ++=adjacentadjacent *)0/11(|)(||)(|LtPTMatchLSMatchLH ++=5 Algorithm ImplementationAccording to the definition of BAM, the first se-lected anchor will divide the whole bilingual textsinto two parts.
We stipulated that the sentences inthe upper part of source text cannot match any sen-tence in the nether part of target text.
As shown inFig 5, after the first alignment anchors were se-lected, the second candidate anchors must be se-lected in the first quadrant or the third quadrantand exclusive from the boundary.
It is obvious thatif the candidate anchors exist in the second quad-rant or fourth quadrant, the cross alignment willhappen.
For example, if the (i, j) is the first se-lected alignment anchor, and the (i-1, j+1) is thesecond selected alignment anchor, the cross align-ment appears.
We can limit the anchors selectionfield to prevent the cross-alignment errors.In addition, in order to resolve the problem thatthe first sentence pair is not a (1:1) sentence bead,we use a virtual sentence length as the originalignment sentence bead when we initialize thealignment process.The implementation of alignment algorithm isdescribed as followed:1) Load the bilingual text and English-Chinesedictionary;2) Identify the English and Chinese sentencesboundaries and number each sentence;3) Default the last sentence pair to be alignedand calculate every sentence pair?s alignment value;4) Search for sentence pair that is correspondingto the smallest alignment function value;5) If the smallest alignment function value isless than the alignment threshold and the go to step6), and if the smallest value is equal to or morethan the threshold, then go to step 7);6) If the similarity of the sentence pair is morethan a certain threshold, the sentence pair will be-come an alignment anchor and divide the bilingualtext into two parts respectively, then limit thesearch field of the next candidate anchors and go tothe step 4)7) Output the aligned texts, and go to the end.6 Results and DiscussionWe use the real bilingual texts of the seven-teenth chapter in the literary masterpiece ?Wuther-ing Heights?
as our test data.
The basicinformation of the data is shown in the table 1.English text size 38.1KChinese text size  25.1KEnglish sentence number 273Chinese sentence number 277Table 1 Basic information of the test dataIn order to verify the validity of our algorithm,we implement the classic length-based sentencealignment method using dynamic programming.The precision is defined:Precision = The correct aligned sentence pairs /All alignment sentence pairs in bilingual textsThe comparison results are presented in table 2.Method Precision (%)Length-basedalignment method  20.3Location-basedalignment method 87.8Table 2 Comparison results between two methodsBecause the origin bilingual texts have no obvi-ous aligned paragraph boundaries, the error exten-sion phenomena happen easily in the length-basedalignment method if the paragraphs are not strictlyaligned correctly.
Its alignment results are soweaker that it cannot be used.
If we omit all of theorigin paragraphs information, we merge all theparagraphs in the bilingual text into one largerparagraph respectively.
The length-based align-ment method rated the precision of 25.4%.
This ismainly because the English and Chinese languagesdon?t belong to the same genre and have large dif-ference between the language pairs.
But ourFigure 5 Anchors selection in Bilingual Textsj+1secondquadrantfirstquadrantthirdquadrantfourthquadrant0 mniji-1method rated 129 (1:1) sentence pairs as alignmentanchors which divide the bilingual text into alignedfragments.
The length-based classic method wasapplied to these aligned fragments and got a highprecision.
Fig 6 shows 129 selected anchors distri-bution which is in the same trend with all the (1:1)sentence beads.
Their only difference is the sparseextent of the aligned pairs.0 50 100 150 200 250 300050100150200250300EnglishSentenceNumberChinese Sentence NumberAFigure 6 Distribution of alignment anchorsIn order to evaluate the adaptability of ourmethod, we select texts with different themes andstyles as the test set.
We merge two news bilingualtexts and two novel texts.
The data information isshow in Table 3.Our method is applied on the fixed data and re-ceives the precision rating of 86.9%.
The resultshows that this alignment method is theme inde-pendent.English text size 63.9KChinese text size  41.5KEnglish sentence number 510Chinese sentence number 526Table 3 Basic information of the fixed test data(Haruno and Yamazaki, 1996) tried to alignshort texts in structurally different languages, suchas English and Japanese.
In this paper the alignedlanguage pairs of English and Chinese belongs tostructurally different languages as well.
Ourmethod gets the highest precision in aligning shorttexts.
A bilingual news text is selected to be testdata.
The result is shown in table 4.
There are twoaligned sentence error pairs which are induced bythe lack the corresponding translation.English text size 5.6KChinese text size  3.4KEnglish sentence number 40Chinese sentence number 38Precision (%) 94.4Table 4 Alignment results of short test dataIt is difficult to attain large test set because do-ing so need more manual work.
We construct thetest set by merging the aligned sentence pairs inthe existing sentence aligned bilingual corpus intotwo files.
Then the two translated files can be astest set.
Here we merge 2000 aligned sentencepairs.
The file information is as follows:English text size 200.3KChinese text size  144.2KEnglish sentence number 2069Chinese sentence number 2033Table 5 Basic information of the large test dataFrom the table 4, it is evident that there aremany different styles of sentence beads.
Themethod is developed on this large test set and getsthe precision of 90.5%.
The reason of the slightprecision increase is that the last test set is rela-tively clean and the sentence length distributionrelatively average.
But overall, our method per-forms very well to align the real bilingual texts.
Itshows the high robustness and is not related to thelanguages, text themes, text length.
This methodcan resolve the alignment problem of the real text.7 ConclusionThis paper proposed a new method for fullyaligning real bilingual texts using sentence locationinformation, described concretely in section 3 and4.
The model was motivated by the observationthat the location of a sentence pair with certainlength is distributed in the whole text similarly.
Ituses the (1:1) sentence beads instead of the highfrequency words as the candidate anchors.
Localand global location characteristics of sentence pairsare involved to determine the probability which thesentence pair is an alignment anchors.Every sentence pair corresponds to an alignmentvalue which is calculated according to the formalalignment function.
Then the process of BAM isperformed to get the alignment anchors.
Thisalignment method can restrain the errors extensioneffectively in comparison to the traditional align-ment method.
Furthermore, it has shown strongrobustness, even if when it meets ill-quality textsthat include incorrect sentences.
To obtain furtherimprovement in alignment accuracy sentence simi-larity based on an English-Chinese dictionary wasperformed.
It need not segment the Chinese sen-tence.
The whole procedure requires little cost toimplement.Additionally, we can adjust the alignment andsimilarity thresholds dynamically to get high preci-sion alignment anchors, for example, applying thefirst test set, even if we get only 105 (1:1) sentencebeads but the precision is 100%.
We found that thismethod can perform the function of paragraphalignment very well and ensure simultaneous thealignment precision.Of these pairs about half of total number of (1:1)sentence beads can be even extracted from the bi-lingual text directly to build a large scale bilingualcorpus if the original bilingual text is abundant.And the rest bilingual text can be used as spareresource.
Now, we have obtained about 500,000English-Chinese aligned sentence pairs with highquality.In the future, we hope to do further alignment onthe basis of current work and extend the method toalign other language pairs.ReferencesWu, DeKai.
1994.
Aligning a parallel English-Chinese corpus statistically with lexical criteria.In Proceedings of the 32nd Annual Conferenceof the Association for Computational Linguistics,80--87, Las Cruces, New MexicoSimard, M., Foster, G., and Isabelle, P. 1992.
Us-ing Cognates to Align Sentences in BilingualCorpora.Fourth International Conference onTheoretical and Methodological Issues in Ma-chine Translation (TMI-92), Montreal, CanadaBrown, P., Lai, J. and Mercer, R. 1991.
AligningSentences in Parallel Corpora.
ACL-91Fung Pascale and Kathleen Mckeown.
1994.
Align-ing noisy parallel corpora across languagegroups: Word pair feature matching by dynamictime warping.
In AMTA-94, Association forMachine Translation in the Americas, 81--88,Columbia, MarylandWang Bin, Liu Qin, Zhang Xiang.
2000.
Auto-matic Chinese-English Paragraph Segmentationand Alignment.
Journal of Software,11(11):1547-1553 (Chinese)Church, Kenneth W. 1993.
Char_align: A Pro-gram for Aligning Parallel Texts at the Charac-ter Level.
Proceedings of ACL-93, ColumbusOHChen, Stanley.
1993.
Aligning Sentences in Bilin-gual Corpora Using Lexical Information.
In Pro-ceedings of the 31st Annual Meeting of theAssociation for Computational Linguistics(ACL-1993)Gale, W.A.
Church, K.W.
1993.
A Program forAligning Sentences in Bilingual Corpora.
Com-putational Linguistics, 19(2): 75-102Haruno, Masahiko & Takefumi Yamazaki (1996),High-performance bilingual text alignment usingstatistical and dictionary information, In Pro-ceedings of ACL '96, Santa Cruz, California,USA, pp.
131-138M.
Kay & M. Roscheisen.
1993.
Text-TranslationAlignment.
Computational Linguistics 19:1
