Using Bidirect ional  Semant ic  Rules for Generat ionJ im Barnet t  and  Inder jeet  Man iM ic roe lec t ron ics  and  Computer  Techno logy  Corporat ion  (MCC)3500 West  Ba lcones  Center  Dr iveAust in ,  Texas  78759U.S .A .Abst rac tThis paper describes the use of a system of semanticrules to generate noun compounds, vague or polyse-mous words, and cases of metonymy.
The rules are bi-directional and are used by the understanding systemto interpret he same constructions.In t roduct ionIn generation systems that are paired with understand-ing systems, bidirectionality is desirable for reasonsthat are both theoretical (a single model of linguis-tic behaviour) and practical (shorter development time,greater consistency, etc.)
1.
Recently, \[Shieber et al 89\]and \[Calder at al.
89\] have presented generation algo-rithms that share both semantics and syntax with theunderstanding system.
This paper presents an exten-sion of these algorithms to deal with phenomena thathave often been lumped together under 'pragmatics',namely noun compounding, metonymy (the use of aword to refer to a related concept), and vague or poly-semous words like "have.
"The difficulty with these constructions i  that theyare productive, and cannot be handled easily by simplylisting meanings in a lexicon.
Taking noun compound-ing as an example, we have "corn oil" and "olive oil"referring to oil made from corn or olives.
We could adda lexical sense for "corn" meaning "made from corn,"but then we face an explosion in the size of the lexi-con, and an inability to understand or generate novelcompounds: if we acquire "safflower" as the name of aplant, we would like the system to be able to handle"safflower oil" immediately, but this won't be possibleif we need a separate lexical sense to handle compound-ing.
The system will be more robust (and the lexiconmore compact) if we can derive the desired sense of"safflower" from the basic noun sense when we need it.We have therefore developed a system of bidirectionalsemantic rules to handle these phenomena t the ap-propriate level of generality.IF or more detailed arguments along these lines, see\[Appelt 87\], \[Shieber 88\], \[Jacobs 88a\].We have implemented these rules in Common Lisp aspart of the KBNL system \[Barnett et M. 90\] at MCC,but nothing depends on the idiosyncracies of our for-malisms or implementation, so the technique is com-patible with a wide variety of theories of the kindsof relations that are likely to occur in these construc-tions, as in, e.g., \[Finin 80\] for noun compounds and\[Nunberg 78\] for oblique reference.The  F rameworkThe algorithms for recognition and generation usean agenda-based blackboard for communication andcontrol \[Cohen et al 89\].
Our syntax componentuses an extension of Categorial Unification Grammar\[Wittenburg 86\] as the phrase-structure component ofan LFG-style functional representation (f-struCture),and the semantic omponent maps from this represen-tation to sets of assertions in the interface language ofthe CYC knowledge base \[Lenat et al 90\].Semantic rules map partial semantic interpretationsonto other partial interpretations.
They consist of aleft-hand side and a right-hand side, each consisting ofone or more templates, plus a mechanism for mappingan instantiation of either set of templates onto an in-stantiation of the other set.
The intuitive semantics ofthese rules is that any interpretation that matches theleft-hand side licenses a second interpretation match-ing the right-hand side.
For example, we can use thename of an author to refer to his works ("I read Shake-speare"), and the corresponding semantic rule statesthat the existence of an NP denoting an artist licencesthe use of the same NP to refer to his works.
The gen-eration system applies the rules in a backward-chainingdirection, while the understanding system runs themforward.
A later section contains a fuller discussion ofthe implementation f the rules, while the next sectionsdiscuss their use at runtime.Generat ionThe generator is divided into strategic and tactical com-ponents.
The former takes a frame as input and cre-ates a description of it based on a set of discriminative47properties which are recorded in the KB and indicatewhich aspects of a frame are likely to be salient.
Ifa comparison class is available, the resulting descrip-tion uniquely identifies the frame with respect o thatclass, otherwise it contains default 'interesting' proper-ties.
Once it has generated this set of assertions, thestrategic omponent calls the tactical component witha goal Semantics : Syntax, where Semantics consists ofthe assertions plus the distinguished variable that theutterance is 'about', and Syntax is an f-structure (whichmay specify no more than the category.
)Given this input, the tactical component uses a vari-ant of the semantic-head driven algorithms describedby \[Calder at al.
89\] and \[Shieber et al 89\] to generatea phrase whose syntax and semantics match the goal.Before examining this algorithm, we note that in cat-egorial grammars, most of the syntactic information iscontained in the lexical definitions of words.
For ex-ample, the lexical entry for a transitive verb like "read"specifies that it takes an object NP to its right and thena subject NP to its left.
Any such constituent that takesat least one argument is called a funclor, while a con-stituent with no arguments i  called atomic.
Functorsand their arguments are combined by a small numberof binary rules, and there is also a set of unary rules,which can change the category of a constituent (formingpassive verbs out of actives, for example.
)Next we define two relationships between con-stituents and goals: first, a constituent matches a goal ifits semantics subsumes the goal's semantics and its syn-tactic category is the same as the goal's, with possibleextra arguments.
Thus the transitive verb "eat", withcategory S\NP/NP ,  is a syntactic match for the goalcategory S because it will he an S once it gets its ar-guments.
Second, a constituent satisfies a goal if it hasidentical semantics and its f-structure is a supergraphof the goal's f-structure.Given this syntactic framework, the algorithm worksby peeling off lexical functors and recursing on their ar-guments until it bottoms out in an atomic constituent.Given a goal, the first step consists of lexical look-upto find an item that matches the goal.
Once this item,called the semantic head, is found, the algorithm pro-ceeds both top-down and bottom up.
If the semantichead is a functor, it proceeds top-down trying to solvethe sub-goal for its argument.
Once this sub-goal issatisfied, the algorithm works bottom-up by applyingunary grammar ules to to the argument constituentalone, or binary rules to combine it with the functor.When a complete constituent is found which satisfiesthe goal, we are done.Extens ion :  Goa l  Rev is ionThe algorithm described above assumes a fixed set ofchoices in the lexicon.
It can generate metonymic ex-pressions and noun compounds, but only at the costof massive lexical ambiguity.
We therefore xtend it byconsidering the possibility of goal revision as an alterna-tive to the lexical ook-up step s. By running a semanticrule backward, we can map the current goal onto oneor more new goals to which the algorithm recursivelyapplies.
Satisfying the new goals will generate an ex-pression with the desired meaning and thus indirectlysatisfy the original goal.Revision using noun compounding rules leads to abinary decomposition of the original goal, as shown inFigure 2, while metonymy rules result in a unary de-composition, as shown in Figure 3.
From this perspec-tive, we note that the lexical look-up of a functor canbe viewed as a kind of guided binary decomposition(Figure 1), splitting the original goal into two sub-goalswith the knowledge that one of them will be satisfiedimmediately.
[ :o.L I (X HRSCOLOR Y) \[ (x Isg BOOK) I (Y EOURLS RED) |(X HRSCRER/OR Z) I(Z EOURLS MRO) \].
t .
I (U HRSCOLOR V)l |(X ISR BOOK) |\[(X HRSCRERTOR Z)\[ l(V E%URLS RED)\]\[(Z EOURLS .BO) IFigure 1: Lexical Lookup as DecompositionOur extension to the algorithms of \[Calder at al.
89\]and \[Shieber et al 89\] thus amounts to the decision toallow top-down decomposition to be guided by rulesas well as lexical items.
As we would expect, this isthe mirror image of the situation during understanding,where semantic rules are used as an extension to thelexicon in the process of merging translations bottom-up.
The extended algorithm is shown in the Appendix.Cont ro l l ing  Ru le  App l i ca t ionThe strategic omponent can control the choice amongalternatives through its specification of the goal's syn-tax.
For example, the strategic omponent can forcethe use of a compound by providing an appropriatelydetailed f-structure (i.e., one that specifies the presenceof a modifier of category N.) If it does so, no matterwhether we are in best-first or all-paths mode, only thecompounding alternative will succeed and satisfy thesyntactic goal.
On the other hand, if the syntactic goalis underspecified, the output (in best-first mode) willaThe notion of goal revision in generation dates back to\[Appelt 83\] where various conditions could lead to replan-ning of the input; for recent work incorporating goal revisionsee \[Vaughan et al 86\].48depend on the tactical component's heuristic ordering.In this case, given the default ordering which preferslexical ook-up to noun compounding to metonymy, thetactical component will use a noun compound whenlexical look-up fails (i.e., there is no corresponding ad-jective or preposition).
Another result of this defaultordering is that metonymy will never fire in the ab-sence of a syntactic specification since there is alwaysanother way (unless the lexicon is incomplete) of say-ing the same thing using words that are in the lexicon.However, the literal alternative is usually more verbosethan the metonymous expression, ,so the strategic om-ponent can force the use of metonymy by specifying alimit on the number of words the tactical componentis allowed to use.
Given a limit of 3 words, descriptivephrases like "a book by Joyce" will fail, and only themetonymous expression "Joyce" will succeed.In best-first mode, substantial improvements in effi-ciency are possible by re-ordering the alternatives basedon the syntactic properties of the goal.
For example, itmakes sense to try metonymy first if the desired lengthis significantly less than the number of assertions in thegoal's semantics, ince each lexical item normally coversonly a few assertions.Generat ing  Noun CompoundsSuppose we have a So f tware -Mach ine  rule, statingthat if "y" denotes any kind of Software and "x" acomputer, "a y x" means a Computer x that CanRun-Language y.
Now consider a goal with semantics (WISA Computer)(Z Equals Lisp)(W CanRunLanguageZ), distinguished variable W, and syntax NP.
There isno lexical item covering all these assertions, or any lex-ical functor covering part of them (i.e., "Lisp" is notin the lexicon as an adjective.)
Thus, even in best-firstmode, we will end up applying the So f tware -Mach inerule to this goal, resulting in the decomposition shownin Figure 2.GOALrtP(Q CRMRUMLPJIGURGE Z)(W ISR COMPUTER)(Z EOURLS LIGP)I(Z EOURLS LISP) I I(W ISR CO.PUIER) Iisfy the other.
Combining the sub-goal solutions yields"Lisp machine" as a solution to the original goal.Multiple compounds are handled by repeated invo-cations of the rules.
Suppose we have a Mechan ism-Ma intenance  rule, stating that if "x" denotes a Ma-chine and "y" denotes any kind of MaintenanceOpera-lion, "x y" denotes a MaintenanceOperation y with yMaintains x.
Given input semantics (Y ISA Repair-Operation)(Y Maintains X)(X ISA Computer)(X Can-RunLanguage Z)(Z Equals Lisp), with distinguished ref-erent Y, the maintenance rule will eventually fire, gen-erating patterns for a head (Y ISA RepairOperation)and a modifier (X ISA Computer)(X CanRunLanguageZ)(Z Equals Lisp).
The head's goal will be satisfied bythe entry for "repair", but processing of the modifierwill invoke the So f tware -Mach ine  rule, just as in theexample above.
The output will be "Lisp machine re-pair", with the left-branching structure \[\[Lisp machine\]repair\].For an example of a right-branching compound, sup-pose we have a P roduct -Manufacturer  rule statingthat if "x" is the name of a Product and "y" is thename of a Company, then "a y x" is a Product x that isManuffacluredBy company .
Given the input (X ISAComputer)(X UanufacturedBy Y)(X CanRunianguageZ)(Y Equals Symbolics)(Z Equals Lisp), the productrule will fire, producing a modifier sub-goal for (YEquals Symbolics) and a head sub-goal for (X ISA Com-puter)(X CanRunLanguage Z)(Z Equals Lisp).
Thistime the So f tware -Mach lne  rule will be invoked onthe head sub-goal, while lexical item "Symbolics" willsatisfy the modifier sub-goal, and the output will be\[Symbolics \[Lisp machine\]\].Generat ing  Metonymic  ReferencesIGORL~ ISR BOOK)(X HRSCRERTO~ ?
)(Y EOURLS JRMESJOYCE)IFigure 3: Decomposition for MetonymyFigure 2: Decomposition for a Noun CompoundRecursing on the sub-goals, the lexical item "Lisp"will satisfy the left sub-goal, and "machine" will sat-Suppose we have an Ar t i s t  rule licensing the use ofan artist's name to refer to his works, and are try-ing to generate an NP with semantics (X ISA Book)(XHasCrealor JamesJoyce).
If we are in all-paths mode,or if the strategic omponent has requested a succinct49rule, we need to compute the inverse of the relation.
4To do this we reverse the order of the statements and re-place each Bind statement (which computes a relationbetween variable bindings) with its inverse.
Here werely on the fact that the CYC KB automatically main-tains inverses for all relations defined in it (for KBswithout this feature, we would have to define inversesfor all relations used in rules).
If CreatorOffis the in-verse of HasGreator, then the inverse of (Bind Z (XCreatorOf)) is simply (Bind X (Z HasCreator)).A few more details are necessary to complete the im-plementation.
First, we define tlie relation Instances,which maps from classes to their elements, as the in-verse of ISA.
Next we define a concatenation operator+ on relations, so that (Z (Instances +ttasGreator)) e-turns all the creators of instances of the class Z.
5 Next,we stipulate that if the variable X is already bound,(Bind X (Z ttasCreator)) acts as a Filter, returning Tiff X is among the values for (Z gasCreator.)
Finally,for reasons of efficiency, we cache separate patterns forbackward and forward application, instead of reversingthe expressions at run time.
The generation and under-standing patterns for the Ar t i s t  rule are given below:Input Pattern (W ISA Z)(new-var HasCreator X)Bind Y (Z Instances 4-HasCreator)F i l te r  (Y ISA Person)OutputPattera (X Equals Y)Input Pattern (X Equals Y)Filter (Y ISA Person)Bind Z (Y CreatorOf + ISA)Output Pattern(W ISA Z)(new-var HasCreator Y)Running the rule backward on (Q ISA Book)(QHasCreator JamesJoyce), initial unification binds Q toW, Z to Book and Y to JamesJoyce.
The Bind ex-pression serves as a filter in this case, checking that Yis in fact the CrealorOfsome instance of Z, the Filterexpression checks that Y is a Person, and the outputis (X Equals JamesJoyce), which will match the lexi-cal semantics for "Joyce" permitting us to use that NPto refer to the book.
Running the rule forward on (XEquals JamesJoyce), Yis bound to JamesJoyce, the Fil-ter expression again checks that Yis a Person, and theBind expression binds Z to all the classes of objects Yisthe CreatorOf(in this case, the class Book).
The outputis an expression denoting any Book which HasCreatorJamesJoyce, thus letting us understand "Joyce" as re-ferring to a Book.The rule format is similar for noun compounds, ex-cept that there are two input patterns (in the forwarddirection) and a single output pattern.
During under-standing, the two patterns are unified with the inter-4Mathematically, a relation is a set of ordered pairs, andits inverse is the set of inverted pairs.
Any relation is there-fore guaranteed to have a unique inverse.5The inverse of (rl + r2) is ((inverse r2) + (inverse rl)).pretations of the head and modifier nouns, the Filtersand Binds work as before, and the output pattern is theinterpretation of the compound.
Backward applicationis as before, except that the output is a pair of instan-tiated patterns which the generation routine then usesas new goals.Re la ted  WorkA variety of systems have used rules of the kindwe are considering, either explicitly or implicitly,for use in understanding compounds, vague expres-sions, and metonymy, for example, \[DaM et at.
87\],\[Hobbs et al 88\], \[Grosz et at.
85\], \[Stallard 87\], butno mention is made of reversing these rules for gen-eration.A number of systems generate compounds, butmost apparently do so using either phrasal lexi-cons (e.g., \[Hovy 88\], \[Jacobs 88b\], \[Wilensky 88\]), ormultiple lexical senses (e.g., \[Pustejovsky et at.
87\],\[Nirenburg et al 88\]), rather than rules of the sort wepropose.
Other generation systems apparently con-struct noun compounds via specialized (uni-directional)strategies pecified in the interface to the tactical com-ponent \[McDonald et at.
88\], or a combination of thesetechniques \[McKeown 82\].
We have been unable to finddiscussions of generation of metonymy, though at leastsome cases of it could obviously be handled via lexicalambiguity.DiscussionThe use of semantic rules seems to us to handle most ofthe technical problems in providing an economical, bi-directional treatment of a variety of non-literal and/orvague constructions.
At the heart of any reversible sys-tem is the notion of being able to run mappings for-wards or backwards, so that, for example, the under-standing and generation lexicons are inverses of eachother.
These rules are a natural extension of this mech-anism to more complex constructions.
Furthermore,these rules can handle a wide variety of phenomena.
Inaddition to the examples discussed above, we have usedsemantic rules for the lexical semantics of vague wordslike "have" and "of", which are like noun compoundingand metonymy in that the only alternative to massivelexical ambiguity is to compute the nature of the rela-tion based on the interpretation of the arguments.
Thisuse of semantic rules for lexical semantics amounts topermitting a lexical item to further decompose its sub-goal, instead of satisfying it immediately in the man-ner of Figure 1.
Finally, these rules do not commit usto any particular analysis of the constructions in ques-tion (except insofar as they assume separate levels ofsyntactic and semantic representation.)
To take nouncompounding as an example, we can implement a widevariety of theories of the kinds of relations compoundsexpress and of the hierarchies among them.51The main open issue is the development of strategiesfor the use of these expressions.
The problem is mostacute in the case of metonymy.
At present, the strate-gic component can force the use of metonymous expres-sions by requiring brevity.
However, use of metonymyis not just a matter of succinctness since it also tendsto indicate informality and familiarity.
In more ex-treme uses, it may have a poetic or humorous force.To use metonymy, compounds, or other vague expres-sions successfully, we need a theory of how they effectthe discourse, as well as a strategic omponent whichis sophisticated enough to exploit the theory.
As a firststep in this direction, we are implementing a discoursemodule which will allow us to address some of theseissues.
For example, metonymous expressions are saferwhen used to refer to classes of objects that have al-ready been described than when used to introduce newones.
If "an Orris fishing rod" has already been men-tioned, then "an Orris" is likely to make sense, even topeople who wouldn't have understood it the first timearound.
However, such individual heuristics will be oflimited usefulness until they are integrated into a com-prehensive model of communication.AcknowledgmentsWe are grateful to Elaine Rich for comments on an ear-lier draft of this paper.Append ix :  Generat ion  A lgor i thmThe psuedocode for the generation algorithm is shownbelow, identifying the point of departure from the\[Calder at al.
89\] algorithm.
The lexical lookup-step ofline 1 is replaced with the more general top-down stepof line la, by calling the new function ge,erafe-tp-dn.The rest of the (pseudo)code r mains unchanged.Here are the language constructs used in the pseu-docode.
We denote local variable assignment as X :=Y, with scope extending to the immediate containingconstruct.
Destructuring by pattern matching is al-lowed, e.g.
< X1 X2 X3 >:= Y simultaneously bindsX1, X2 and X3 to the corresponding components in Y.AND and OR have exactly the behavior of CommonLisp AND and OR.For the sake of conciseness,the function choose is usedas a shorthand for control strategies: in all-paths mode,it finds all solutions; in best-first mode it imposes aheuristic ordering on the choices and finds a single so-lution, finding any subsequent solutions on backtrack-ing.
The function choose-tp-dn-operatio, heuristicallypicks the best operation based on the goal.
The func-tions match and satisfy are as defined earlier.
Thefunctions apply-unavy-bup-rule and apply-bi.avy-bup-rule constitute the rule application interface to gram-mar rules; similarly, the functions apply-uuary-tp-dn-rule and apply-binary-tp-d.-rule constitute the rule ap-plication interface for the semantic rules.FUNCTION generate(Goal);1AND(;;OLD: Subgoal :ffi lex-decomp(Goal);; NEW:la Subgoal := choose(generate-tp-dn(Goal)); ;  AS BEFORE:2 choose(generate-bup(Subgoal, Goal))).FUNCTION generate-tp-dn(Goal);operation :=choose(choose-tp-dn-operation(Goal))CASE operation:lexlex-decomp(Goal):unary-decomp;; e.g.
METONYMY RULES:choose(apply-unary-tp-dn-rule(Goal)):binary-decomp; ;  e.g.
COMPOL~DING/VAGUEWORD ULES:AND(<lef$-subgoal, right-subgoal> :=choose(apply-binary-tp-dn-rule(Goal)),choose(generate(left-subgoal)),choose(generate(right-subgoal)),choose(apply-binary-bup-rule(left-subgoal, right-subgoal))).FUNCTION generate-bup(Subgoal, Goal);OR(satisfies(Subgoal, Goal),AND(Arg :=choose(extract-arg(Subgoal)),Goall :=choose(apply-binary-bup-rule(Subgoal, ARE)),choose(generate(Arg)),choose(generate-bup(Goall, Goal))),AND(Goall :=choose(apply-unary-bup-rule(Subgoal)),choose(generate-bup(Goall, Goal)))).FUNCTION lex-decomp(Goal);AND(Subgoal :=choose(lexical-lookup(Goal)),matches(Subgoal, Goal),Subgoal).References\[Appelt 83\] D. E. Appelt, "Telegram: A Grammar For-malism For Language Planning", Proceedings ofthe ACt, M.I.T., 15-17 June, 1983.\[Appelt 87\] D. E. Appelt, "Bidirectional Grammarsand the Design of Natural Language GenerationSystems", TINLAP-3 Posilion Papers, New Mex-ico State University, 7-9 January, 1987.\[Barnett e al.
90\] J. Barnett, K. Knight, I. Mani, andE.
Rich, "Knowledge and Natural Language Pro-52eessing', to appear in Communications of theACM, August, 1990.\[Calder at al.
89\] J. Calder, M. Reape, and H. Zeevat,"An Algorithm for Generation i Unification Cat-egorial Grammar", Proceedings of the 4th Confer-ence of the European Chapter of the ACL, pp.
233--240, Manchester, 10-12 April, 1989.\[Cohen et al 89\] R. M. Cohen, T. P. McCandless, andE.
Rich, "A Problem Solving Approach to Human-Computer Interface Management", MCC TechReport ACT-HI-g06-89, Fall 1989.\[Dahl et al 87\] D. Dahl, M. Palmer, and R. Passon-neau, "Nominalizations in Pundit", Proceedings ofthe ACL, Stanford, 6-9 July, 1987.\[Finin 80\] T. Finin, "The Semantic Interpretationof Compound Nominals", University of Illinois,Ph.D.
Dissertation, 1980.\[Grosz et al 85\] B. Grosz, D. Appelt, P. Martin, andF.
C. N. Pereira, "Team: An Experiment in theDesign of Transportable Natural-Language Inter-faces", Artificial Intelligence.\[Hobbs et al 88\] J. K. Hobbs, M. Stickel, P. Martin,and D. Edwards, "Interpretation as Abduction",Proceedings of the ACL, Buffalo, 7-10 June, 1988.\[IIovy 88\] E. H. Hovy, "Generating Language with aPhrasal Lexicon", in D. D. McDonald and L.Bole, eds., Natural Language Generation Systems,Springer-Verlag, 1988.\[Jacobs 88a\] P. S. Jacobs, "Achieving Bidirectional-ity", Proceedings of the lth International Confer-ence on Computational Linguistics, Budapest, 22-27 August, 1988, pp.
267-269.\[Jacobs 88b\] P. S. Jacobs, "PHRED: A Generator forNatural Language Interfaces", in D. D. McDonaldand L. Bole, eds., Natural Language GenerationSystems, Springer-Verlag, 1988.\[Lenat et al 90\] D. Lenat and R. Guha, f'BuildingLarge Knowledge Based Systems, Representationsand Inference in the CYC Project", Addison Wes-ley, 1990.\[McDonald et al 88\] D. D. McDonald and M. W.Meteer, "From Water to Wine: Generating Natu-ral Language Text from Today's Application Pro-grams", Second Conference on Applied NaturalLanguage Processing, Austin, 9-12 February, 1988.\[McKeown 82\] K. R. McKeown, "Generating NaturalLanguage Text in Response to Questions AboutDatabase Structure", University of Pennsylvania,Ph.D.
Dissertation, 1982.\[Nirenburg et al 88\] S. Nirenburg, R. MeCardell, E.Nyberg, P. Werner, S. Huffman, E. Kenschaft andI.
Nirenburg, "DIOGENES-88", CMU Tech Re-port CMU-CMT-88-107, June 1988.\[Nunberg 78\] G. Nunberg, "The Pragmatics of Refer-ence", City College of New York, Ph.D. Disserta-tion, 1978.\[Pustejovsky et al 87\] J. Pustejovsky and S. Niren-burg, "Lexical Selection in the Process of Lan-guage Generation", Proceedings of the A CL, Stan-ford, 6-9 July, 1987.\[Shieber 88\] S. M. Shieber, "A Uniform Architecturefor Parsing and Generation", Proceedings of the121h International Conference on ComputationalLinguistics, Budapest, 22-27 August, 1988, pp.614-619.\[Shieber t al.
89\] S. M. Shieber, G. van Noord, R. C.Moore, and F. C. N. Pereira, "A Semantic-fiend-Driven Generation Algorithm for Unification-Based Formalisms", Proceedings of the AGL, Van-couver, 26-29 June, 1989.\[Stallard 87\] D. Stallard, "The Logical Analysis of Lex-teal Ambiguity", Proceedings of the ACL, Stan-ford, 6-9 July, 1987.\[Vaughan et al 86\] M. M. Vaughan and D. D. McDon-ald, "A Model of Revision in Natural LanguageGeneration", Proceedings of the ACL, New York,10-13 June, 1986.\[Wilensky 88\] R. Wilensky, D. N. Chin, M. Luria, J.Martin, J. Mayfield, and D. Wu, "The BerkeleyUNIX Consultant Project", Computational Lin-guistics, Vol.
14, No.
4, December 1988.\[Wittenburg 86\] K. Wittenburg, "A Parser for PortableNL Interfaces Using Graph-Unification-BasedGrammars", Proceedings of AAAI 86, 1986.53
