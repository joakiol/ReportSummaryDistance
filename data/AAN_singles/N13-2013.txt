Proceedings of the NAACL HLT 2013 Student Research Workshop, pages 91?97,Atlanta, Georgia, 13 June 2013. c?2013 Association for Computational LinguisticsUser Goal Change Model for Spoken Dialog State TrackingYi MaDepartment of Computer Science & EngineeringThe Ohio State UniversityColumbus, OH 43210, USAmay@cse.ohio-state.eduAbstractIn this paper, a Maximum Entropy MarkovModel (MEMM) for dialog state trackingis proposed to efficiently handle user goalevolvement in two steps.
The system firstpredicts the occurrence of a user goal changebased on linguistic features and dialog contextfor each dialog turn, and then the proposedmodel could utilize this user goal change in-formation to infer the most probable dialogstate sequence which underlies the evolve-ment of user goal during the dialog.
It isbelieved that with the suggested various do-main independent feature functions, the pro-posed model could better exploit not only theintra-dependencies within long ASR N-bestlists but also the inter-dependencies of the ob-servations across dialog turns, which leads tomore efficient and accurate dialog state infer-ence.1 IntroductionThe ability to converse with humans is usually con-sidered the most important characteristic which de-fines the intelligent nature of a machine.
In recentyears, advanced approaches for handling differentcomponents within a spoken dialogue system havebeen proposed and studied.
Both statistical infer-ence methods for dialog state tracking and machinelearning techniques (such as reinforcement learning)for automatic policy optimization are active domainsof research, which implies that there are still manyopen challenges in this field that are worth being ex-plored.
One of such challenges is how to better ex-ploit the ASR (Automatic Speech Recognition) N-best list when the top ASR hypothesis is incorrect.Furthermore, reasoning over different ASR N-bestlists is also difficult since it is hard to decide whento detect commonality (when user repeats) and whento look for differences (when user changes her or hismind) among multiple ASR N-best lists.
Anotherchallenge is how to handle more complex user ac-tions such as negotiating alternative choices or seek-ing out other potential solutions when interactingwith the system.This proposal presents a probabilistic frameworkfor modeling the evolvement of user goal during thedialog (focusing on the shaded component DialogState Tracking in Figure 1 that shows a typical di-agram for a spoken dialog system), which aims toendow the system with the ability to model naturalnegotiation strategies, in the hope of leading to moreaccurate and efficient dialog state tracking perfor-mance.Figure 1: a typical spoken dialogue system2 Unanswered Challenges for SpokenDialog SystemsDue to the inevitable erroneous hypotheses made bythe speech recognizer as well as the ubiquitous am-biguity existing in the natural language understand-91ing process, it is impossible for a spoken dialog sys-tem to observe the true user goal directly.
Therefore,methods to efficiently infer the true hidden dialogstates from noisy observations over multiple dialogturns become crucial for building a robust spokendialog system.The POMDP (Partially Observable Markov De-cision Process) framework has been proposed tomaintain multiple dialog state hypotheses underuncertainty with automated dialog policy learn-ing (Williams and Young, 2007; Henderson etal., 2008; Thomson and Young, 2010; Young etal., 2010).
Although the original POMDP frame-work suffers difficulties of scaling up the model tohandle real-world domains in practice, it providesa unified statistical framework for existing tech-niques with global optimization.
Partition-based ap-proaches (Gas?ic?
and Young, 2011; Williams, 2010;Young et al 2010) attempt to group user goals intoa number of partitions and won?t split a partition un-less when a distinction is required by observations.Due to this property, partition-based methods couldhave high scalability for more complex practical do-mains.Bayesian network based approximate methodsalso emerged to tackle the complexity of represent-ing and tracking multiple dialog states within proba-bilistic frameworks (Raux and Ma, 2011; Thomsonand Young, 2010).
In previous work, we presenteda new probabilistic model ?
DPOT (Dynamic Prob-abilistic Ontology Trees) ?
to track dialog state in aspoken dialog system (Raux and Ma, 2011).
DPOTcaptures both the user goal and the history of user di-alog acts (user actions) using a unified Bayesian net-work.
Efficient inference (a form of blocked Gibbssampling) is performed to exploit the structure ofthe model.
Evaluation on a corpus of dialogs fromthe CMU Let?s Go system shows that DPOT signif-icantly outperforms a deterministic baseline by ex-ploiting long ASR N-best lists without loss of ac-curacy.
At any point in the dialog, the joint distri-bution over the goal network represents the inferreddialog state about the user goal.1 The goal networkof DPOT does not expand per time slice for eachturn but the evidence accumulates as the dialog pro-1In the Let?s Go bus information system, a user goal is de-composed into three concepts: Bus (the bus number), Orig(the origin stop) and Dest (the destination stop).gresses.
Therefore the model becomes inefficientwhen users change their mind ?
user has to repeatmultiple times in order to possibly trigger a goalchange in the inferred dialog state.Figure 2: Example of user goal change: at the end of thedialog the user would like to explore alternative flights ata different time, but the dialog system did not expect sucha user action, leading to a system failureCurrent approaches often assume that user wouldhave a fixed goal in his or her mind before convers-ing with the system and this single goal remains un-changed throughout the dialog.
However, the keyquestion we would like to raise here is that whetherthe assumption that a user would not change her orhis mind during the dialog is reasonable or not inthe first place.2 Figure 2 shows an example whereuser goal evolves as the dialog moves on.
In this ex-ample, the system did not catch the partial changeof user goal and failed to return alternative answersgiven a new request from the user ?
now the fixedgoal assumption has been challenged.
Moreover,sometimes people do not even have a clear goal intheir minds before they start speaking to the system(e.g., a user might want a flight from Columbus toSan Francisco during the coming weekend, but theexact departure date depends on user?s schedule aswell as the price of the ticket.).
From the exampledialog shown in Figure 2, clearly it can be noticedthat there are some useful hints or linguistic patterns?
such as How about ...?
and ... instead?
?
whichcould be extracted from the user?s spoken language2It is true that for some simple domains such as luggage re-trieval or call routing, users are less likely to change their mind.92as predictors for potential user goal change.
We canthen further use this predicted information (user goalchanged or not) to better infer the true user goal andprevent a system failure or start over.
In fact, it isthis intuition that forms the basis of the proposedmethods.However, existing methods heavily rely on the as-sumption that user won?t change her or his mindthroughout the dialog.
In order to keep the compu-tations tractable in practice, POMDP-based methodsoften assume that user goal does not change duringthe dialog (Young et al 2010).
Moreover, withinthe POMDP framework there is a user action modelwhich would suppress the weights of conflict ob-servations for those slots which have already beenfilled ?
the intuition is that if a value for a certainslot has already been provided or observed, it isless likely that a new value will be provided again(based on the assumption of fixed user goal) and itis more likely to be a speech recognition error in-stead (Williams and Young, 2007).
Furthermore,one of the claimed benefit for existing statistical di-alog state inference methods is the ability to exploitthe information lower down from ASR N-best listsby aggregating weak information across multiple di-alog turns ?
the intuition is that overlapped consis-tent weak evidence is sometimes a useful hint forpredicting the underlying true user goal (as illus-trated in Figure 3) ?
again it implies that the userwould repeatedly refine the same goal until the ma-chine gets it.Figure 3: Given the fact that user action BOSTON hasbeen repeatedly observed as DEPARTURE CITY acrossthe first two turns ?
although not at the top position of theASR N-best list ?
existing statistical dialog state trackingalgorithms would capture this pattern and put a strongbias on BOSTON as the inferred user goal.It is true that putting such a constraint ?
assum-ing a fixed user goal during the dialog ?
simplifiesthe computational complexity, it also sacrifices theflexibility and usability of a spoken dialog system.Although one could think of some hand-crafted andad-hoc rules such as explicit or implicit confirma-tion/disconfirmation to deal with sudden user goalchanges during a dialog, it increases the number ofdialog turns and makes the dialog system less natu-ral and user friendly.3 Spoken Dialog State Tracking withExplicit Model of User Goal Change3.1 BuildByVoice DomainIn fact, there are many situations where frequentuser goal changes would be highly expected (i.e.
theuser might try to negotiate with the system).
Thesedomains might include but not limited to findingnearby restaurants or hotels, searching for moviesto watch, ordering food or online shopping, etc., inwhich users are very likely to explore different alter-natives and their goals would probably change fre-quently as the dialog progresses.Figure 4: An experimental web interface prototype forBuildByVoice ?
a spoken dialog system aimed to assistpotential car buyers to customize a car by voiceConsidering one typical example among those do-mains ?
a spoken interactive system which could al-low a user to configure a new car by speech (a pro-totype web interface of the BuildByVoice system isshown in Figure 43) ?
one could imagine the userwould tend to experiment many possible combina-tions of different configurations for a car.
Indeedthat is the purpose of having such a system so thatusers could preview the resulting effect before a realcar is made.
A BuildByVoice domain may consist of3A baseline BuildByVoice system by using DPOT for dialogstate tracking (without user goal change detection) is under im-plementation.
The baseline system will be deployed to AmazonMechanical Turk for initial data collection.93the following five independent concepts with theirpossible values listed as follows:4Model: Accord Coupe, Accord Sedan,Accord Plug-In, Civic Coupe,Civic Sedan, .
.
.
5Engine: V4, V4 Turbo, V4 Sport, V6, V6Turbo, V6 Sport, .
.
.Exterior Color: Toffee Brown, CoffeeBrown, Candy Brown, Night Blue,Moonlight Blue, Midnight Blue, .
.
.Interior Color: Black Leather, BlackVinyl, Gray Leather, Gray Vinyl,Brown Leather, Brown Vinyl, .
.
.Wheels: 17 inches Steel, 17 inchesAlloy, 18 inches Steel, 18 inchesAlloy, 18 inches Polished Alloy,.
.
.In (Ammicht et al 2007), the semantic represen-tation of a spoken dialog system is augmented witha dynamic parameter that determines the evolutionof a concept-value pair over time, which could beconsidered as early attempts for coping with usergoal changes.
However, the determined dynamicconfidence score is used to make a hard choicefor the candidate semantic values, i.e., determin-ing the birth and death of the observed concept-value pairs.
Thomson and Young (2010) intro-duced a new POMDP-based framework for buildingspoken dialog systems by using Bayesian updatesof dialog state (BUDS).
It accommodates for usergoal changes by using a dynamic Bayesian network,but BUDS is generative rather than a discriminativemodel.
Therefore it lacks the flexibility of incor-porating all kinds of overlapping features ?
one ofthe advantages discriminative models have.
Further-more, BUDS assumes limited changes in the usergoal in order to gain further efficiency.
More re-cently, Gas?ic?
and Young (2011) introduces the ex-plicit representation of complements in partitionswhich enables negotiation-type dialogs when user4More concepts could also be included such as Accessoriesor MPG Level, but only these five concepts are picked fordemonstration purpose.5Here Honda car models are used as an example.goal evolves during the dialog.
However, the explicitrepresentation of complements is used to provide ex-istential and universal quantifiers in the system?s re-sponse.6 Also a special pruning technique is neededin their approach to ensure the number of partitionsdoesn?t grow exponentially.Therefore, new approaches for recognizing theevent of user goal change and utilizing the goalchange information to better infer dialog states havebeen proposed in the following two subsections 3.2and 3.3.3.2 Dialog State Tracking with Detected UserGoal ChangeDialog state tracking is usually considered as thecore component of a spoken dialog system where di-alog manager uses the inferred dialog states to gen-erate system responses (normally through a learnedor hand-crafted policy mapping from dialog states tosystem actions).
A specialized version of MaximumEntropy Markov Model with user goal change vari-able is proposed for dialog state tracking.7 The mostprobable dialog state sequence as well as the mostlikely dialog state value for the latest turn can be in-ferred given the model.
Figure 5 illustrates how theproposed model could infer dialog states of a sin-gle concept Exterior Color for a dialog of four userturns where the user changes her or his mind at thethird dialog turn.8For traditional dialog state tracking methods with-out user goal change model, the system would bequite confused by completely conflicting observeduser actions starting from the third dialog turn.
How-ever, the proposed MEMM with user goal changedetection could notice that the user has alreadychanged her or his mind.
Therefore the proposedmodel would not only trust more on the observeduser actions for the current dialog turn, but also fa-vor those transitions which lead to a different statevalue by increasing corresponding transition proba-bilities.6E.g., ?Charlie Chan is the only Chinese restaurant in thecenter.?
or ?All Chinese restaurants are in the center.
?7Methods for detecting user goal change are described inSection 3.3.8We assume every concept in the domain is mutually inde-pendent with each other and we model the user goal changeseparately for each concept.94Figure 5: MEMM for dialog state tracking with explicit user goal change variable.
A single concept Exterior Colorfrom BuildByVoice domain is tracked by the model.
The shaded nodes are observed user actions and the white nodesare hidden dialog states.
The bold text in the observed nodes indicates the true user actions whereas the bold text inthe hidden states shows the true dialog state sequence (in this case it is also the most probable decoded dialog statepath inferred by the model).A more formal description of the proposedMEMM is given as follows.
The observations ot(shaded nodes) consist of N-best lists of semanticspeech hypotheses (or dialog acts) with confidencescores (scale from 0 to 100) for the current dialogturn hypt and previous turn hypt?1 as well as thebinary goal change variable gct for the current turn?
essentially a context window of speech hypothesesincluding history:ot = {hypt?1, hypt, gct}Typically the semantic speech hypotheses hypt areextracted concept-value pairs out of ASR results byusing a semantic tagger (such as an FST (Finite StateTransducer) parser or a segment-based semi-MarkovCRF semantic labeler (Liu et al 2012)).
The hid-den dialog state qt (white nodes) represents the usergoal for dialog turn t (such as a particular colorMoonlight Blue for Exterior Color at time t).The individual probability of a transition from a stateqt?1 to a state qt producing an observation ot is in aform of the following:P (qt|qt?1, ot) =exp(?nk=1 wkfk(qt?1, qt, ot))Z(ot, qt?1)Given labeled sequences of true dialog states (trueuser goal) for each turn, the corresponding obser-vations and designed feature functions, we want tolearn a set of weights wk to optimize the discrimina-tion among competing state values given the train-ing data.
In other words, the learning procedure in-volves searching in parameter space to maximize thefollowing conditional likelihood:P (Q|O) =N?i=1T?t=1exp(?nk=1 wkfk(qi,t?1, qit, oit))Z(oit, qi,t?1)where N is the number of training dialogs.
MEMMcan be trained with methods from the field of convexoptimization and Viterbi decoding algorithm couldbe applied to MEMMs for inference (McCallum etal., 2000).The proposed feature functions are as follows.The first feature function (1a) implies that if the usergoal is not changed, the system should look for thecommon evidence across dialog turns.f(qt = v, ot) =??
?1 if gct=0 &v?common(hypt?1, hypt)0 otherwise(1a)where common(hypt?1, hypt) will return the over-lapped values from the two N-best lists of dialogacts hypt?1 and hypt.
The second and third featurefunctions ((1b) and (1c)) are basically saying that if auser goal change has been detected, then we shouldexpect a different state value, otherwise we should95remain the same value from previous dialog turn.f(qt?1 = u, qt = v, ot) ={1 if gct=0 & u=v0 otherwise(1b)f(qt?1 = u, qt = v, ot) ={1 if gct=1 & u6=v0 otherwise(1c)The intuition behind the following four feature func-tions (feature function (1d) to (1g)) is that if the userchanges her or his mind then the model should trustmore on the current observed user actions than thosefrom previous turn; but if the user does not changeher or his mind, we could then consider the observa-tions from the past.f(qt = v, ot) ={1 if gct=0 & v?hypt?10 otherwise(1d)f(qt = v, ot) ={1 if gct=1 & v?hypt?10 otherwise(1e)f(qt = v, ot) ={1 if gct=0 & v?hypt0 otherwise (1f)f(qt = v, ot) ={1 if gct=1 & v?hypt0 otherwise (1g)The last two feature functions ((1h) and (1i)) tryto incorporate information from confidence scores?
the higher the confidence score is, the more likelythe hypothesis is to be correct.f(qt = v, ot) =??
?1 if v?hypt &confidencehypt(v)>C0 otherwise(1h)f(qt = v, ot) =??????
?1 if gct=0 &v?hypt?1 &confidencehypt?1(v)>C0 otherwise(1i)where confidencehypt(v) returns the confidencescore for value v in the speech hypotheses N-bestlist hypt and C is an empirical constant thresholdrange between 0 to 100 obtained from the trainingcorpus.3.3 User Goal Change Detection withLinguistic Features and Dialog ContextIn previous subsection 3.2, we assume we alreadyknow whether or not user changes her or his mindat each dialog turn, whereas this subsection we dis-cuss the possible approaches on how to detect a usergoal change.
Detecting user goal changes during adialog could be cast as a binary classification prob-lem where class 0 means no goal change and class 1indicates user changes her or his mind during a dia-log turn.
Candidate machine learning algorithms in-cluding MLP (Multi-layer Perceptron), SVM (Sup-port Vector Machine) or Logistic Regression couldbe applied to this binary classification problem ina supervised manner.
The input features might beextracted from user utterance transcription9 and thecorresponding ASR N-best list for each dialog turn.As mentioned in Section 2, the language patternsfound in the user utterances as presented in the ex-ample dialog (shown in Figure 2) forms the intuitionfor linguistic features to identify user goal change.The dialog context such as last system action couldalso be included as useful hint for predicting a po-tential user goal change ?
user is likely to changeher or his goal if system returns empty results for arequest.
Also other helpful features could includebag of words model, n-grams, prosodic features(e.g., a pitch change or initial pause) and parsed fea-tures (e.g., WH questions).
Baseline system suchas key word spotting based approach (i.e.
look forHow/What about in a sentence) could also be imple-mented for performance comparison.104 ConclusionBy modeling the user goal change in a probabilisticframework, the proposed approach should better ex-ploit the mutual information buried deep in the ASRN-best lists across dialog turns, which leads to morerobust and accurate dialog state estimation.
Withthe ability to predict and handle user goal change,proposed techniques provide a bottom-up solutionfor managing negotiation style dialogs and not onlyshould produce more efficient and natural conver-sations but also open up new possibilities for auto-mated negotiation dialog policy learning.9At test time, this could be approximated by the top hypoth-esis in the ASR N-best list.10A detailed list of proposed features is omitted due to spacelimit.96ReferencesEgbert Ammicht, Eric Fosler-Lussier, and AlexandrosPotamianos.
2007.
Information seeking spoken di-alogue systems?part i: Semantics and pragmatics.Multimedia, IEEE Transactions on, 9(3):532?549.M.
Gas?ic?
and S. Young.
2011.
Effective handlingof dialogue state in the hidden information statepomdp-based dialogue manager.
ACM Transactionson Speech and Language Processing (TSLP), 7(3):4.James Henderson, Oliver Lemon, and Kallirroi Georgila.2008.
Hybrid reinforcement/supervised learning of di-alogue policies from fixed data sets.
ComputationalLinguistics, 34(4):487?511.J.
Liu, S. Cyphers, P. Pasupat, I. McGraw, and J. Glass.2012.
A conversational movie search system based onconditional random fields.
In INTERSPEECH.A.
McCallum, D. Freitag, and F. Pereira.
2000.
Maxi-mum entropy markov models for information extrac-tion and segmentation.
In Proceedings of the Seven-teenth International Conference on Machine Learning,volume 951, pages 591?598.A.
Raux and Y. Ma.
2011.
Efficient probabilistic track-ing of user goal and dialog history for spoken dialogsystems.
In Twelfth Annual Conference of the Interna-tional Speech Communication Association.Blaise Thomson and Steve Young.
2010.
Bayesian up-date of dialogue state: A pomdp framework for spo-ken dialogue systems.
Computer Speech & Language,24(4):562?588.J.D.
Williams and S. Young.
2007.
Partially observablemarkov decision processes for spoken dialog systems.Computer Speech & Language, 21(2):393?422.Jason D Williams.
2010.
Incremental partition recombi-nation for efficient tracking of multiple dialog states.In Acoustics Speech and Signal Processing (ICASSP),2010 IEEE International Conference on, pages 5382?5385.
IEEE.S.
Young, M.
Gas?ic?, S. Keizer, F. Mairesse, J. Schatz-mann, B. Thomson, and K. Yu.
2010.
The hiddeninformation state model: A practical framework forpomdp-based spoken dialogue management.
Com-puter Speech & Language, 24(2):150?174.97
