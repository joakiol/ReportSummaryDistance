Proceedings of the SIGDIAL 2014 Conference, pages 79?83,Philadelphia, U.S.A., 18-20 June 2014.c?2014 Association for Computational LinguisticsAlex: Bootstrapping a Spoken Dialogue System for a New Domain by RealUsers?Ond?rej Du?ek, Ond?rej Pl?tek, Luk??
?ilka, and Filip Jur?c?
?cekCharles University in Prague, Faculty of Mathematics and PhysicsInstitute of Formal and Applied LinguisticsMalostransk?
n?m?est?
25, CZ-11800 Prague, Czech Republic{odusek,oplatek,zilka,jurcicek}@ufal.mff.cuni.czAbstractWhen deploying a spoken dialogue sys-tem in a new domain, one faces a situationwhere little to no data is available to traindomain-specific statistical models.
We de-scribe our experience with bootstrappinga dialogue system for public transit andweather information in real-word deploy-ment under public use.
We proceeded in-crementally, starting from a minimal sys-tem put on a toll-free telephone number tocollect speech data.
We were able to incor-porate statistical modules trained on col-lected data ?
in-domain speech recogni-tion language models and spoken languageunderstanding ?
while simultaneously ex-tending the domain, making use of auto-matically generated semantic annotation.Our approach shows that a successful sys-tem can be built with minimal effort andno in-domain data at hand.1 IntroductionThe Alex Public Transit Information System is anexperimental Czech spoken dialogue system pro-viding information about all kinds of public tran-sit in the Czech Republic, publicly available at atoll-free 800 telephone number.1It was launchedfor public use as soon as a first minimal workingversion was developed, using no in-domain speechdata.
We chose an incremental approach to sys-tem development in order to collect call data anduse them to bootstrap statistical modules.
Nearly?This work was funded by the Ministry of Education,Youth and Sports of the Czech Republic under the grantagreement LK11221 and core research funding, SVV project260 104, and grants GAUK 2058214 and 2076214 of CharlesUniversity in Prague.
It used language resources stored anddistributed by the LINDAT/CLARIN project of the Min-istry of Education, Youth and Sports of the Czech Republic(project LM2010013).1Call 800-899-998 from the Czech Republic.a year after launch, we have collected over 1,300calls from the general public, which enabled usto train and deploy an in-domain language modelfor Automatic Speech Recognition (ASR) and astatistical Spoken Language Understanding (SLU)module.
The domain supported by the system hasextended from transit information in one city to ca.5,000 towns and cities in the whole country, plusweather and time information.
This shows that aeven a very basic system is useful in collecting in-domain data and that the incremental approach isviable.Spoken dialogue systems have been a topic ofresearch for the past several decades, and manyexperimental systems were developed and testedwith users (Walker et al., 2001; Ga?i?c et al., 2013;Janarthanam et al., 2013).
However, few experi-mental systems became available to general publicuse.
Let?s Go (Raux et al., 2005; Raux et al., 2006)is a notable example in the public transportationdomain.
Using interaction with users from thepublic to bootstrap data-driven methods and im-prove the system is also not a common practice.Both Let?s Go and the GOOG-411 business findersystem (Bacchiani et al., 2008) collected speechdata, but applied data-driven methods only to im-prove statistical ASR.
We use the call data for sta-tistical SLU as well and plan to further introducestatistical modules for dialogue management andnatural language generation.Our spoken dialogue system framework isfreely available on GitHub2and designed for easyadaptation to new domains and languages.
An En-glish version of our system is in preparation.We first present the overall structure of the AlexSDS framework and then describe the minimalsystem that has been put to public use, as well asour incremental extensions.
Finally, we providean evaluation of our system based on the recordedcalls.2http://github.com/UFAL-DSG/alex792 Overall Alex SDS System StructureThe basic architecture of Alex is modular and con-sists of the traditional SDS components: automaticspeech recognizer (ASR), spoken language under-standing (SLU), dialogue manager (DM), naturallanguage generator (NLG), and a text-to-speech(TTS) module.We designed the system to allow for easy re-placement of the individual components: There isa defined interface for each of them.
As the in-terfaces are domain-independent, changing the do-main is facilitated as well by this approach.3 Baseline Transit Information SystemWe decided to create a minimal working systemthat would not require any in-domain data andopen it to general public to collect call data as soonas possible.
We believe that this is a viable al-ternative to Wizard-of-Oz experiments (Rieser andLemon, 2008), allowing for incremental develop-ment and producing data that correspond to realusage scenarios (see Section 4).3.1 Baseline Implementation of theComponentsHaving no in-domain data available, we resortedto very basic implementations using hand-writtenrules or external services:?
ASR used a neural network based voice activitydetector trained on small out-of-domain data.Recordings classified as speech were fed to thethe web-based Google ASR service.?
SLU was handcrafted for our domain using sim-ple keyword-spotting rules.?
In DM, the dialogue tracker held only one valueper dialogue slot, and the dialogue policy washandcrafted for the basic tasks in our domain.?
NLG is a simple template-based module.?
We use a web-based Czech TTS service pro-vided to us by SpeechTech.33.2 Baseline DomainAt baseline, our domain only consisted of a verybasic public transport information for the city ofPrague.
Our ontology contained ca.
2,500 publictransit stops.
The system was able to present thenext connection between two stops requested bythe user, repeat the information, or return several3http://www.speechtech.cz/0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 120253035404550Google ASRKaldi ASR Training set portionWorderrorrate(%)Figure 1: ASR word error rate depending on thesize of in-domain language model training dataThe full training set amounts to 9,495 utterances (30,126 to-kens).
The test set contains 1,187 utterances (4,392 tokens).following connections.
Connection search wasbased on Google Directions API.44 Collecting Data and Extending theSystem in Real UsageWe launched our system at a public toll-free 800number and advertised the service at our univer-sity, among friends, and via Facebook.
We alsocooperate with the Czech Blind United associa-tion,5promoting our system among its membersand receiving comments about its use.
We adver-tised our extensions and improvements using thesame channels.We record and collect all calls to the system,including our own testing calls, to obtain trainingdata and build statistical models into our system.4.1 Speech Recognition: Building In-DomainModelsThe Google on-line ASR service, while reach-ing state-of-the-art performance in some tasks(Morbini et al., 2013), showed very high word er-ror rate in our specific domain (see Figure 1).
Wereplaced it with the Kaldi ASR engine (Povey etal., 2011) trained on general-domain Czech acous-tic data (Korvas et al., 2014) with an in-domainclass-based language model built using collectedcall data and lists of all available cities and stops.We describe our modifications to Kaldi for on-line decoding in Pl?tek and Jur?c?
?cek (2014).
Aperformance comparison of Google ASR with4https://developers.google.com/maps/documentation/directions/5http://www.sons.cz800 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1646668707274767880SLU trained on Google ASRSLU trained on Kaldi ASRTraining set portionDialogueactitemsF-measure(%)Figure 2: SLU performance (F-measure on dia-logue act items) depending on training data sizeThe same data sets as in Figure 1 are used, with semanticannotations from handcrafted SLU running on manual tran-scriptions.Kaldi trained on our data is shown in Figure 1.One can see that the in-domain language modelbrings a substantial improvement, even with verysmall data sizes.4.2 Spoken Language UnderstandingTo increase system robustness, we built a statisti-cal SLU based on a set of logistic regression clas-sifiers and word n-gram features (Jur?c?
?cek et al.,2014).
We train it on the output of our handcraftedSLU applied to manual transcriptions.
We chosethis approach over obtaining manual semantic an-notation due to two main reasons:1.
Obtaining semantic annotation for Czech data isrelatively slow and complicated; using crowd-sourcing is not a possibility due to lack ofspeakers of Czech on the platforms.2.
As we intended to gradually extend our domain,semantic annotation changed over time as well.This approach still allows the statistical SLU toimprove on a handcrafted one by compensatingfor errors made by the ASR.
Figure 2 shows thatthe performance of the statistical SLU module in-creases with more training data and with the in-domain ASR models.4.3 Dialogue ManagerWe have replaced the initial simplistic dialoguestate tracker (see Section 3.1) by the probabilis-tic discriminative tracker of ?ilka et al.
(2013),which achieves near state-of-the-art performancewhile remaining completely parameter-free.
Thisproperty allowed us to employ the tracker withoutany training data; our gradual domain extensionsalso required no further adjustments.The dialogue policy is handcrafted, though ittakes advantage of uncertainty estimated by thebelief tracker.
Its main logic is similar to that ofJur?c?
?cek et al.
(2012).
First, it implements a set ofdomain-independent actions, such as:?
dialogue opening, closing, and restart,?
implicit confirmation of changed slots with highprobability of the most probable value,?
explicit confirmation for slots with a lowerprobability of the most probable value,?
a choice among two similarly probable values.Second, domain-specific actions are imple-mented for the domain(s) described in Section 4.4.4.4 Extending the DomainWe have expanded our public transit informationdomain with the following tasks:?
The user may specify departure or arrival timein absolute or relative terms (?in ten minutes?,?tomorrow morning?, ?at 6 pm.
?, ?at 8:35?
etc.).?
The user may request more details about theconnection: number of transfers, journey dura-tion, departure and arrival time.?
The user may travel not only among publictransport stops within one city, but also amongmultiple cities or towns.The expansion to multiple cities has lead to anontology improvement: The system is able to findthe corresponding city in the database based on astop name, and can use a default stop for a givencity.
We initially supported three Czech majorcities covered by the Google Directions service,then extended the coverage to the whole country(ca.
44,000 stops in 5,000 cities and towns) usingCzech national public transport database providedby CHAPS.6We now also include weather information for allCzech cities in the system.
The user may ask forweather at the given time or on the whole day.
Weuse OpenWeatherMap as our data source.7Furthermore, the user may ask about the currenttime at any point in the dialogue.5 System Evaluation from RecordedCallsWe have used the recorded call data for an eval-uation of our system.
Figure 3 presents the num-6http://www.idos.cz7http://openweathermap.org/81Jun '13 Jul Aug Sep Oct Nov Dec Jan '14 Feb Mar Apr May0102030405060708090100110 Total calls (incl.testing)Public user callsABCDE FGHIFigure 3: Number of calls per weekThe dashed line shows all recorded calls, including thosemade by the authors.
The full line shows calls from the publiconly.Spikes: A ?
initial testing, B ?
first advertising, C ?
systempartially offline due to a bug, D ?
testing statistical SLU mod-ule, E ?
larger advertising with Czech Blind United, F ?
test-ing domain enhancements, G ?
no advertising and limitedsystem performance, H ?
deploying Kaldi ASR and nation-wide coverage, I ?
no further advertising.Jun '13 Jul Aug Sep Oct Nov Dec Jan '14 Feb Mar Apr May00.10.20.30.40.50.60.70.80.91% Informed or apologized% Rather positive answerFigure 4: System success rates by monthPercentage of calls where the system provided information(or apology for not having one) and percentage of rather pos-itive responses to the final question, both shown with standarderror bars.ber of calls to our system per week and reflectsthe testing and advertising phases, as well as someof our extensions and improvements described inSection 4.
A steeper usage increase is visible inrecent weeks after the introduction of Kaldi ASRengine and nationwide coverage (see Sections 4.1and 4.4).
The number of calls and unique users(caller phone numbers) grows steadily; so far,more than 300 users from the public have madeover 1,300 calls to the system (cf.
Figure 5 andTable 1 in the appendix).8Figure 4 (and Table 1 in the appendix) give a de-tailed view of the success of our system.
Informa-8We only count calls with at least one valid user utterance,disregarding calls where users hang up immediately.tion is provided in the vast majority of calls.
Uponmanual inspection of call transcripts, we discov-ered that about half of the cases where no infor-mation is provided can be attributed to the systemfailing to react properly; the rest is off-topic callsor users hanging up too early.We have also introduced a ?final question?
asan additional success metric.
After the user saysgood-bye, the system asks them if they receivedthe information they were looking for.
By lookingat the transcriptions of responses to this question,we recognize a majority of them as rather positive(?Yes?, ?Nearly?
etc.
); the proportion of positivereactions seems to remain stable.
However, the fi-nal question is not an accurate measure as mostusers seem to hang up directly after receiving in-formation from the system.6 Conclusions and Further WorkWe use an iterative approach to build a complexdialogue system within the public transit informa-tion domain.
The system is publicly available on atoll-free phone number.
Our extensible dialoguesystem framework as well as the system imple-mentation for our domain can be downloaded fromGitHub under the Apache 2.0 license.We have shown that even very limited work-ing version can be used to collect calls fromthe public, gathering training data for statisticalsystem components.
Our experiments with theKaldi speech recognizer show that already a smallamount of in-domain data for the language modelbrings a substantial improvement.
Generating au-tomatic semantic annotation from recording tran-scripts allows us to maintain a statistical spokenlanguage understanding unit with changing do-main and growing data.The analysis of our call logs shows that our sys-tem is able to provide information in the vast ma-jority of cases.
Success rating provided by theusers themselves is mostly positive, yet the con-clusiveness of this metric is limited as users tendto hang up directly after receiving information.In future, we plan to add an English versionof the system and further expand the domain, al-lowing more specific connection options.
As wegather more training data, we plan to introduce sta-tistical modules into the remaining system compo-nents.82A System Evaluation DataIn the following, we include additional data fromcall logs evaluation presented in Section 5.Jun '13 Jul Aug Sep Oct Nov Dec Jan '14 Feb Mar Apr May0150300450600750900105012001350Total callsUnique callersFigure 5: Cumulative number of calls and uniquecallers from the public by weeksThe growth rates of the number of unique users and the totalnumber of calls both correspond to the testing and advertisingperiods shown in Figure 3.Total calls 1,359Unique users (caller phone numbers) 304System informed (or apologized) 1,124System informed about directions 990System informed about weather 88System informed about current time 41Apologized for not having information 223System asked the final question 229Final question answered by the user 199Rather positive user?s answer 146Rather negative user?s answer 23Table 1: Detailed call statisticsTotal absolute numbers of calls from general public usersover the period of nearly one year are shown.ReferencesM.
Bacchiani, F. Beaufays, J. Schalkwyk, M. Schus-ter, and B. Strope.
2008.
Deploying GOOG-411:early lessons in data, measurement, and testing.
InProceedings of ICASSP, page 5260?5263.
IEEE.M.
Ga?i?c, C. Breslin, M. Henderson, D. Kim,M.
Szummer, B. Thomson, P. Tsiakoulis, andS.
Young.
2013.
On-line policy optimisation ofbayesian spoken dialogue systems via human inter-action.
In Proceedings of ICASSP, page 8367?8371.IEEE.S.
Janarthanam, O.
Lemon, P. Bartie, T. Dalmas,A.
Dickinson, X. Liu, W. Mackaness, and B. Web-ber.
2013.
Evaluating a city exploration dialoguesystem combining question-answering and pedes-trian navigation.
In Proceedings of ACL.F.
Jur?c?
?cek, B. Thomson, and S. Young.
2012.
Rein-forcement learning for parameter estimation in sta-tistical spoken dialogue systems.
Computer Speech& Language, 26(3):168?192.F.
Jur?c?
?cek, O.
Du?ek, and O. Pl?tek.
2014.
A factoreddiscriminative spoken language understanding forspoken dialogue systems.
In Proceedings of TSD.To appear.M.
Korvas, O. Pl?tek, O.
Du?ek, L. ?ilka, and F.
Ju-r?c??cek.
2014.
Free English and Czech telephonespeech corpus shared under the CC-BY-SA 3.0 li-cense.
In Proceedings of LREC, Reykjav?k.F.
Morbini, K. Audhkhasi, K. Sagae, R. Artstein,D.
Can, P. Georgiou, S. Narayanan, A. Leuski, andD.
Traum.
2013.
Which ASR should i choose formy dialogue system?
In Proceedings of SIGDIAL,page 394?403.O.
Pl?tek and F.
Jur?c??cek.
2014.
Free on-line speechrecogniser based on kaldi ASR toolkit producingword posterior lattices.
In Proceedings of SIGDIAL.D.
Povey, A. Ghoshal, G. Boulianne, L. Burget,O.
Glembek, N. Goel, M. Hannemann, P. Motlicek,Y.
Qian, P. Schwarz, et al.
2011.
The Kaldi speechrecognition toolkit.
In Proceedings of ASRU, page1?4, Hawaii.A.
Raux, B. Langner, D. Bohus, Alan W. Black, andM.
Eskenazi.
2005.
Let?s go public!
taking a spo-ken dialog system to the real world.
In Proceedingsof Interspeech.A.
Raux, D. Bohus, B. Langner, Alan W. Black, andM.
Eskenazi.
2006.
Doing research on a deployedspoken dialogue system: one year of Let?s Go!
ex-perience.
In Proceedings of Interspeech.V.
Rieser and O.
Lemon.
2008.
Learning effectivemultimodal dialogue strategies from Wizard-of-Ozdata: Bootstrapping and evaluation.
In Proceedingsof ACL, page 638?646.M.
A. Walker, R. Passonneau, and J. E. Boland.
2001.Quantitative and qualitative evaluation of DARPAcommunicator spoken dialogue systems.
In Pro-ceedings of ACL, page 515?522.L.
?ilka, D. Marek, M. Korvas, and F.
Jur?c??cek.
2013.Comparison of bayesian discriminative and genera-tive models for dialogue state tracking.
In Proceed-ings of SIGDIAL, page 452?456, Metz, France.83
