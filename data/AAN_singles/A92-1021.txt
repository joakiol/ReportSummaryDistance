A Simple Rule-Based Part of Speech TaggerEr ic  Br i l l  *Depar tment  of Computer  Sc ienceUn ivers i ty  of  Pennsy lvan iaPh i lade lph ia ,  Pennsy lvan ia  19104U.S.A.br i l l@unag i .c i s .upenn.eduAbst ractAutomatic part of speech tagging is an areaof natural anguage processing where statisticaltechniques have been more successful than rule-based methods.
In this paper, we present asim-ple rule-based part of speech tagger which au-tomatically acquires its rules and tags with ac-curacy comparable to stochastic taggers.
Therule-based tagger has many advantages overthese taggers, including: a vast reduction instored information required, the perspicuity ofa small set of meaningful rules, ease of findingand implementing improvements o the tagger,and better portability from one tag set, cor-pus genre or language to another.
Perhaps thebiggest contribution of this work is in demon-strating that the stochastic method is not theonly viable method for part of speech tagging.The fact that a simple rule-based tagger thatautomatically learns its rules can perform sowell should offer encouragement for researchersto further explore rule-based tagging, search-ing for a better and more expressive set of ruletemplates and other variations on the simplebut effective theme described below.1 In t roduct ionThere has been a dramatic increase in the application ofprobabilistic models to natural anguage processing overthe last few years.
The appeal of stochastic techniquesover traditional rule-based techniques comes from theease with which the necessary statistics can be automat-ically acquired and the fact that very little handcraftedknowledge need be built into the system.
In contrast,the rules in rule-based systems are usually difficult toconstruct and are typically not very robust.One area in which the statistical approach has doneparticularly well is automatic part of speech tagging, as-signing each word in an input sentence its proper partof speech \[Church 88; Cutting et al 92; DeRose 88;Deroualt and Merialdo 86; Garside et al 87; Jelinek 85;*The author would like to thank Mitch Marcus and RichPito for valuable input.
This work was supported by DARPAand AFOSR jointly under grant No.
AFOSR-90-0066, andby ARO grant No.
DAAL 03-89-C0031 PRI.Kupiec 89; Meteer et al 91\].
Stochastic taggers have ob-tained a high degree of accuracy without performing anysyntactic analysis on the input.
These stochastic part ofspeech taggers make use of a Markov model which cap-tures lexical and contextual information.
The parame-ters of the model can be estimated from tagged (\[Church88; DeRose 88; Deroualt and Merialdo 86; Garside et al87; Meteer et al 91\]) or untagged (\[Cutting et al 92;Jelinek 85; Kupiec 89J) text.
Once the parameters of themodel are estimated, a sentence can then be automat-ically tagged by assigning it the tag sequence which isassigned the highest probability by the model.
Perfor-mance is often enhanced with the aid of various higherlevel pre- and postprocessing procedures or by manuallytuning the model.A number of rule-based taggers have been built \[Kleinand Simmons 63; Green and Rubin 71; Hindle 89\].
\[Kleinand Simmons 63\] and \[Green and Rubin 71\] both haveerror rates substantially higher than state of the artstochastic taggers.
\[Hindle 89\] disambiguates wordswithin a deterministic parser.
We wanted to determinewhether a simple rule-based tagger without any knowl-edge of syntax can perform as well as a stochastic tagger,or if part of speech tagging really is a domain to whichstochastic techniques are better suited.In this paper we describe a rule-based tagger whichperforms as well as taggers based upon probabilisticmodels.
The rule-based tagger overcomes the limitationscommon in rule-based approaches to language process-ing: it is robust, and the rules are automatically ac-quired.
In addition, the tagger has many advantagesover stochastic taggers, including: a vast reduction instored information required, the perspicuity of a smallset of meaningful rules as opposed to the large tablesof statistics needed for stochastic taggers, ease of find-ing and implementing improvements o the tagger, andbetter portability from one tag set or corpus genre toanother.2 The  TaggerThe tagger works by automatically recognizing and rem-edying its weaknesses, thereby incrementally improvingits performance.
The tagger initially tags by assigningeach word its most likely tag, estimated by examining alarge tagged corpus, without regard to context.
In bothsentences below, run  would be tagged as a verb:152The run  lasted thirty minutes.We run  three miles every day.The initial tagger has two procedures built in to im-prove performance; both make use of no contextual in-formation.
One procedure is provided with informationthat words that were not in the training corpus and arecapitalized tend to be proper nouns, and attempts to fixtagging mistakes accordingly.
This information could beacquired automatically (see below), but is prespecifiedin the current implementation.
In addition, there is aprocedure which attempts to tag words not seen in thetraining corpus by assigning such words the tag mostcommon for words ending in the same three letters.
Forexample, blahblahous would be tagged as an adjective,because this is the most common tag for words endingin ous.
This information is derived automatically fromthe training corpus.This very simple algorithm has an error rate of about7.9% when trained on 90% of the tagged Brown Corpus 1\[Francis and Ku~era 82\], and tested on a separate 5% ofthe corpus.
2 Training consists of compiling a list of themost common tag for each word in the training corpus.The tagger then acquires patches to improve its per-formance.
Patch templates are of the form:?
If a word is tagged a and it is in context C, thenchange that tag to b, or?
If a word is tagged a and it has lexical property P,then change that tag to b, or?
If a word is tagged a and a word in region R haslexical property P, then change that tag to b.The initial tagger was trained on 90% of the corpus(the training corpus).
5% was held back to be used forthe patch acquisition procedure (the patch corpus) and5% for testing.
Once the initial tagger is trained, it isused to tag the patch corpus.
A list of tagging errors iscompiled by comparing the output of the tagger to thecorrect tagging of the patch corpus.
This list consistsof triples < tag~, tagb, number >, indicating the numberof times the tagger mistagged a word with taga whenit should have been tagged with tagb in the patch cor-pus.
Next, for each error triple, it is determined whichinstantiation of a template from the prespecified set ofpatch templates results in the greatest error reduction.Currently, the patch templates are:Change tag a to tag b when:3.
One of the two preceding (following) words is taggedZ.4.
One of the three preceding (following) words istagged z.5.
The preceding word is tagged z and the followingword is tagged w.6.
The preceding (following) word is tagged z and theword two before (after) is tagged w.7.
The current word is (is not) capitalized.8.
The previous word is (is not) capitalized.For each error triple < taga,tagb, number > andpatch, we compute the reduction in error which resultsfrom applying the patch to remedy the mistagging of aword as taga when it should have been tagged tagb.
Wethen compute the number of new errors caused by ap-plying the patch; that is, the nmnber of times the patchresults in a word being tagged as tagb when it shouldbe tagged taga.
The net improvement is calculated bysubtracting the latter value from the former.For example, when the initial tagger tags the patchcorpus, it mistags 159 words as verbs when they shouldbe nouns.
If the patch change the lag from verb to nounif one of the two preceding words is lagged as a deter-miner is applied, it corrects 98 of the 159 errors.
How-ever, it results in an additional 18 errors from changingtags which really should have been verb to noun.
Thispatch results in a net decrease of 80 errors on the patchcorpus.The patch which results in the greatest improvementto the patch corpus is added to the list of patches.
Thepatch is then applied in order to improve the tagging ofthe patch corpus, and the patch acquisition procedurecontinues.The first ten patches found by the system are listedbelow 3.
(1) TO iN NEXT-TAG AT(2) VBN VBD PREV-WORD-IS-CAP YES(3) VBD VBN PREV-1-OR-2-OR-3-TAG HVD(4) VB NN PREV-1-OR-2-TAG AT(5) NN VB PREV-TAG TO(6) TO IN NEXT-WORD-IS-CAP YES(7) NN VB PREV-TAG MD(8) PPS PPO NEXT-TAG.
(9) VBN VBD PREV-TAG PPS(10) NP NN CURRENT-WORD-IS-CAP NO1.
The preceding (following) word is tagged z.2.
The word two before (after) is tagged z.1The Brown Corpus contains about 1.1 million words froma variety of genres of written English.
There are 192 tags inthe tag set, 96 of which occur more than one hundred timesin the corpus.2The test set contained text from all genres in the BrownCorpus.The first patch states that if a word is tagged TOand the following word is tagged AT, then switch thetag from TO to IN.
This is because a noun phrase is3AT = article, HVD = had, IN = preposition, MD =modal, NN = sing.
noun, NP = proper noun, PPS = 3rdsing.
nora.
pronoun, PPO = obj.
personal pronoun, TO =infinitive to, VB = verb, VBN = past part.
verb, VBD =past verb.153much more likely to immediately follow a prepositionthan to immediately follow infinitive TO.
The secondpatch states that a tag should be switched from VBNto VBD if the preceding word is capitalized.
This patcharises from two facts: the past verb tag is more likelythan the past participle verb tag after a proper noun,and is also the more likely tag for the second word of thesentence.
4 The third patch states that VBD should bechanged to VBN if any of the preceding three words aretagged HVD.Once the list of patches has been acquired, new textcan be tagged as follows.
First, tag the text using thebasic lexical tagger.
Next, apply each patch in turn tothe corpus to decrease the error rate.
A patch whichchanges the tagging of a word from a to b only appliesif the word has been tagged b somewhere in the trainingcorpus.Note that one need not be too careful when construct-ing the list, of patch templates.
Adding a bad templateto the list will not worsen performance.
If a templateis bad, then no rules which are instantiations of thattemplate will appear in the final list of patches learnedby the tagger.
This makes it easy to experiment withextensions to the tagger.3 Resu l t sThe tagger was tested on 5% of the Brown Corpus in-cluding sections from every genre.
First, the test corpuswas tagged by the simple lexical tagger.
Next, each ofthe patches was in turn applied to the corpus.
Below is agraph showing the improvement in accuracy from apply-ing patches.
It is significant hat with only 7i patches,an error rate of 5.1% was obtained 5.
Of the 71 patches,66 resulted in a reduction in the number of errors in thetest corpus, 3 resulted in no net change, and 2 resultedin a higher number of errors.
Almost all patches whichwere effective on the training corpus were also effectiveon the test corpus.Unfortunately, it is difficult to compare our resultswith other published results.
In \[Meteer et al 91\], anerror rate of 3-4% on one domain, Wall Street Journalarticles and 5.6% on another domain, texts on terrorismin Latin American countries, is quoted.
However, boththe domains and the tag set are different from what weuse.
\[Church 88\] reports an accuracy of "95-99% cor-rect, depending on the definition of correct".
We imple-mented a version of the algorithm described by Church.When trained and tested on the same samples used inour experiment, we found the error rate to be about4.5%.
\[DeRose 88\] quotes a 4% error rate; however, thesample used for testing was part of the training corpus.\[Garside t al.
87\] reports an accuracy of 96-97%.
Theirprobabilistic tagger has been augmented with a hand-crafted procedure to pretag problematic "idioms".
Thisprocedure, which requires that a list of idioms be la-4Both the first word of a sentence and proper nouns arecapitalized.5We ran the experiment three times.
Each time we dividedthe corpus into training, patch and test sets in a different way.All three runs gave an error rate of 5%.Patch Application and Error ReductionI I I0 20 40 60Number of P~chesboriously created by hand, contributes 3% toward theaccuracy of their tagger, according to \[DeRose 88\].
Theidiom list would have to be rewritten if one wished to usethis tagger for a different ag set or a different corpus.It is interesting to note that the information containedin the idiom list can be automatically acquired by therule-based tagger.
For example, their tagger had diffi-culty tagging as old as.
An explicit rule was written topretag as old as with the proper tags.
According to thetagging scheme of the Brown Corpus, the first as shouldbe tagged as a qualifier, and the second as a subordi-nating conjunction.
In the rule-based tagger, the mostcommon tag for as is subordinating conjunction.
So ini-tially, the second as is tagged correctly and the first as istagged incorrectly.
To remedy this, the system acquiresthe patch: i f  the current word is tagged as a subordinat-ing conjunction, and so is the word two positions ahead,then change the tag of the current word to qualifier.
6The rule-based tagger has automatically earned how toproperly tag this "idiom.
"Regardless of the precise rankings of the various tag-gers, we have demonstrated that a simple rule-based tag-ger with very few rules performs on par with stochastictaggers.eThis was one of the 71 patches acquired by the rule-basedtagger.1544 Conc lus ionsWe have presented a simple part of speech tagger whichperforms as well as existing stochastic taggers, but hassignificant advantages over these taggers.The tagger is extremely portable.
Many of the higherlevel procedures used to improve the performance ofstochastic taggers would not readily transfer over to adifferent ag set or genre, and certainly would not trans-fer over to a different language.
Everything except forthe proper noun discovery procedure is automatically ac-quired by the rule-based tagger 7, making it much moreportable than a stochastic tagger.
If the tagger weretrained on a different corpus, a different set of patchessuitable for that corpus would be found automatically.Large tables of statistics are not needed for the rule-based tagger.
In a stochastic tagger, tens of thousandsof lines of statistical information are needed to capturecontextual information.
This information is usually a ta-ble of trigram statistics, indicating for all tags taga, tagband rage the probability that lagc follows taga and tagb.In the rule-based tagger, contextual information is cap-tured in fewer than eighty rules.
This makes for a muchmore perspicuous tagger, aiding in better understandingand simplifying further development of the tagger.
Con-textual information is expressed in a much more compactand understandable form.
As can be seen from compar-ing error rates, this compact representation f contextualinformation isjust as effective as the information hiddenin the large tables of contextual probabilities.Perhaps the biggest contribution of this work is indemonstrating that the stochastic method is not the onlyviable approach for part of speech tagging.
The fact thatthe simple rule-based tagger can perform so well shouldoffer encouragement for researchers to further explorerule-based tagging, searching for a better and more ex-pressive set of patch templates and other variations onthis simple but effective theme.\[Francis and Ku~era 82\] Francis,W.
Nelson and Ku~era, Henry, Frequencyanalysis of English usage.
Lexicon and gram-mar.
Houghton Mifflin, Boston, 1982.\[Garside t al.
87\] Garside, R., Leech, G. & Sampson,G.
The Computational Analysis of English:A Corpus-Based Approach.
Longman: Lon-don, 1987.\[Green and Rubin 71\] Green, B. and Rubin, G. Auto-mated Grammatical Tagging of English.
De-partment of Linguistics, Brown University,1971.\[Hindle 89\] Hindle, D. Acquiring disambiguation rulesfrom text.
Proceedings of the 27th AnnualMeeting of the Association for Computa-tional Linguistics, 1989.\[Jelinek 85\] Jelinek, F. Markov source modeling of textgeneration.
In J. K. Skwirzinski, ed., Im-pact of Processing Techniques on Commu-nication, Dordrecht, 1985.\[Klein and Simmons 63\] Klein, S. and Simmons, R.F.A Computational Approach to GrammaticalCoding of English Words.
JACM 10: 334-47.1963.\[Kupiec 89\] Kupiec, J. Augmenting a hidden Markovmodel for phrase-dependent word tagging.In Proceedings of the DARPA Speech andNatural Language Workshop, Morgan Kauf-mann, 1989.\[Meteer et al 91\] Meteer, M., Schwartz, R., andWeischedel, R. Empirical Studies in Partof Speech Labelling, Proceedings of theDARPA Speech and Natural LanguageWorkshop, Morgan Kaufmann, 1991.Re ferences\[Church 88\]\[Cutting etChurch, K. A Stochastic Parts Program andNoun Phrase Parser for Unrestricted Text.In Proceedings of the Second Conference onApplied Natural Language Processing, ACL,136-143, 1988.al.
92\] Cutting, D., Kupiec, J., Pederson, J.and Sibun, P. A Practical Part-of-SpeechTagger.
In Proceedings of the Third Confer-ence on Applied Natural Language Process-ing, ACL, 1992.\[DeRose 88\] DeRose, S.J.
Grammatical Category Dis-ambiguation by Statistical Optimization.Computational Linguistics 14: 31-39, 1988.\[Deroualt and Merialdo 86\] Deroualt, A. and Merialdo,B.
Natural language modeling for phoneme-to-text ranscription.
IEEE Transactions onPattern Analysis and Machine Intelligence,Vol.
PAMI-8, No.
6, 742-749, 1986.rAnd even this could be learned by the tagger.155
