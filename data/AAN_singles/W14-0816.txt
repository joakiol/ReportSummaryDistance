Proceedings of the 10th Workshop on Multiword Expressions (MWE 2014), pages 94?98,Gothenburg, Sweden, 26-27 April 2014.c?2014 Association for Computational LinguisticsAn Approach to Take Multi-Word ExpressionsClaire Bonial?Meredith Green?
?Jenette Preciado?
?Martha Palmer?
?Department of Linguistics, University of Colorado at Boulder?
?Institute of Cognitive Science, University of Colorado at Boulder{Claire.Bonial,Laura.Green,Jenette.Preciado,Martha.Palmer}@colorado.eduAbstractThis research discusses preliminary efforts toexpand the coverage of the PropBank lexiconto multi-word and idiomatic expressions, suchas take one for the team.
Given overwhelmingnumbers of such expressions, an efficient wayfor increasing coverage is needed.
This re-search discusses an approach to adding multi-word expressions to the PropBank lexicon inan effective yet semantically rich fashion.
Thepilot discussed here uses double annotationof take multi-word expressions, where anno-tations provide information on the best strat-egy for adding the multi-word expression tothe lexicon.
This work represents an impor-tant step for enriching the semantic informa-tion included in the PropBank corpus, whichis a valuable and comprehensive resource forthe field of Natural Language Processing.1 IntroductionThe PropBank (PB) corpus provides informa-tion associating semantic roles with certain syn-tactic structures, thereby contributing valuabletraining data for Natural Language Process-ing (NLP) applications (Palmer et al., 2005).For example, recent research shows that us-ing semantic role information in machine trans-lation systems improves performance (Lo, Be-loucif & Wu, 2013).
Despite these successes,PB could be improved with greater coverageof multi-word expressions (MWEs).
The PBlexicon (http://verbs.colorado.edu/PB/framesets-english) is comprised of senses of verb, noun andadjective relations, with a listing of their seman-tic roles (thus a sense is referred to as a ?roleset?
).Although the lexicon encompasses nearly 12,000rolesets, relatively few of these apply to instancesof MWEs.
PB has previously treated languageas if it were purely compositional, and has there-fore lumped the majority of MWEs in with lexi-cal verb usages.
For example, annotations of thesingle PB sense of take meaning acquire, come tohave, choose, bring with you from somewhere in-clude MWEs such as take measures, take comfortand take advantage, and likely others.
AlthoughPB senses typically, and this sense especially, arequite coarse-grained, valuable semantic informa-tion is lost when these distinct MWEs are lumpedtogether with other lexical senses.The importance of coverage for MWEs isunderscored by their prevalence.
Jackendoff(1997:156) estimates that the number of MWEsin a speaker?s lexicon is approximately equal tothe number of single words, and in WordNet1.7 (Fellbaum, 1998), 41% of the entries wereMWEs (cited in Sag et al., 2002).
Furthermore,Sag (2002) estimates the vocabularies of special-ized domains will continue to contribute moreMWEs than simplex words.
For systems like PBto continue to provide adequate training data forNLP systems, coverage must extend to MWEs.The lack of coverage in this area has alreadybecome problematic for the recently developedAbstract Meaning Representation (AMR) project(Banarescu et al., 2013), which relies upon the PBlexicon, or ?frame files?
as the groundwork for itsannotations.
As AMR and PB have extended intomore informal domains, such as online discussionforums and SMS texts, the gaps in coverage ofMWEs have become more and more problematic.To address this issue, this research discusses a pi-lot approach to increasing the coverage of the PBlexicon to a variety of MWEs involving the verbtake, demonstrating a methodology for efficientlyaugmenting the lexicon with MWEs.2 PB BackgroundPB annotation was developed to provide trainingdata for supervised machine learning classifiers.It provides semantic information, including the94basic ?who is doing what to whom,?
in the form ofpredicate-by-predicate semantic role assignments.The annotation firstly consists of the selection of aroleset, or a coarse-grained sense of the predicate,which includes a listing of the roles, expressedas generic argument numbers, associated withthat sense.
Here, for example, is the roleset forTake.01, mentioned previously:Take.01: acquire, come to have, choose, bringArg0: TakerArg1: Thing takenArg2: Taken-from, source of thing takenArg3: DestinationThese argument numbers, along with a varietyof modifier tags, such as temporal and locative,are assigned to natural language sentences drawnfrom a variety of corpora.
The roleset and examplesentences serve as a guide to annotators on how toassign argument numbers to annotation instances.The goal is to assign these simple, general-purposelabels consistently across the many possible syn-tactic realizations of the same event participant orsemantic role.PB has recently undertaken efforts to expandthe types of predicates that are annotated.
Pre-viously, annotation efforts focused on verbs, butevents generally, and even the same event, can of-ten be expressed with a variety of different parts ofspeech, or with MWEs.
For example,1.
He fears bears.2.
His fear of bears...3.
He is afraid of bears.4.
He has a fear of bears.Thus, it has been necessary to expand PB annota-tions to provide coverage for noun, adjective andcomplex predicates.
While this greatly enrichesthe semantics that PB is able to capture, it has alsoforced the creation of an overwhelming number ofnew rolesets, as generally each new predicate typereceives its own set of rolesets.
To alleviate this,PB has opted to begin unifying frame files througha process of ?aliasing?
(Bonial et al., 2014).
Inthis process, etymologically related concepts arealiased to each other, and aliased rolesets are uni-fied, so that there is a single roleset representing,for example the concept of ?fear,?
and this rolesetis used for all syntactic instantiations of that con-cept.This methodology is suited to complex pred-icates, such as light verb constructions (LVCs),wherein the eventive noun, carrying the bulk of theevent semantics, may have an etymologically re-lated verb that is identical in its participants or se-mantic roles (for a description of LVC annotation,see (Hwang et al., 2010).
Thus, have a fear aboveis aliased to fear, as take a bath would be aliasedto bathe.
In this research, the possibility of ex-tending aliasing to a variety of MWEs is explored,such that take it easy, as in ?I?m just going to takeit easy on Saturday,?
would be aliased to the exist-ing lexical verb roleset for relax.
In many cases,the semantics of MWEs are quite complex, addingshades of meaning that no lexical verb quite cap-tures.
Thus, additional strategies beyond aliasingare developed; each strategy is discussed in thefollowing sections.3 Take PilotFor the purposes of this pilot, the take MWEswere gathered from WordNet?s MWE and phrasalverb entries (Fellbaum, 1998), the Prague Czech-English Dependency Treebank (Haji?c-2012), andAfsaneh Fazly?s dissertation work (Fazly, 2007).Graduate student annotators were trained to useWordNet, Sketch Engine (Kilgarriff et al., 2004)and PB to complete double-blind annotation ofthese MWEs as a candidate for one of the three fol-lowing strategies for increasing roleset coverage:1) Aliasing the MWE to a lexically-similar verbor noun roleset from PB, 2) proposing the creationof groups of expressions for which one or severalrolesets will be created, or 3) simply designatingthe MWE as an idiomatic expression.
First, anno-tators were to try to choose a verb or noun rolesetfrom PB that most closely resembled the syntaxand semantics of the MWE.
Annotators also madecomments as necessary for difficult cases.
Theannotators were considered to have agreed if theproposed lexical verb or noun alias was the same.Strategies (2) and (3) were pursued during adjudi-cation if the annotators were unable to agree uponan appropriate alias.
Each of the possible strate-gies for increasing coverage is discussed in turn inthe following sections.3.1 AliasingAliasing involves proposing an existing rolesetfrom PB as a suitable roleset for future MWE an-notation.
LVCs were the simplest of these to alias95since the eventive or stative noun predicate (e.g.
:take a look) may already have an existing role-set, or there is likely an existing, etymologicallyrelated verb roleset (e.g.
verb roleset Look.01).Some other MWEs were not so straightforward.For instance, take time off does not include an et-ymologically related predicate that would easilyencompass the semantics of the MWE, so the an-notators proposed a roleset that is not as intuitive,but captures the semantics nonetheless: the role-set for the noun vacation.
This frame allows foran Agent to take time off, and importantly, whattime is taken off from: take time off from work,school etc.
Selecting an appropriate alias is theideal strategy for increasing coverage, because itdoes not require the time and effort of manuallycreating a new roleset or rolesets.Both of the instances discussed above are rathersimple cases, where their coverage can be ad-dressed efficiently through aliasing.
However,many MWE instances were considerably moredifficult to assign to an equivalent roleset.
Onesuch example includes take shape, for which theannotators decided that shape was an appropriateroleset.
Yet, shape does not quite cover the uniquesemantics of take shape, which lacks the possibil-ity of an Agent.
In these cases, the MWEs maystill be aliased, but they should also include ansemantic constraint to convey the semantic differ-ence, such as ?-Agent?
Thus, in some cases, thesetypes of semantic constraints were used for aliasesthat were almost adequate, but lacked some shadeof meaning conveyed by the MWE.
In other cases,the semantic difference between an MWE and ex-isting lexical verb or noun roleset was too greatto be captured by the addition of such constraints,thus a new roleset or group of rolesets was createdto address coverage of such MWEs, as describedin the next section.3.2 Groups of Syntactically/Lexically SimilarRolesetsIn cases in which it was not possible to find asingle adequate alias for an MWE, a group ofrolesets representing different senses of the sameMWE was created.
For example, take down canmean to write something down, to defeat some-thing, or to deconstruct something.
Thus, a groupof take down rolesets were added, with each role-set reflecting one of these senses.Similarly, some of the proposed rolesets fortake MWEs were easily subsumed under a morecoarse-grained, new frame in PB.
For instance,take one?s lumps and take it on the chin bothmore or less mean to endure or atone for, so com-bining these in a coarser-grained MWE frame isboth efficient and allows for valuable distinctionsin terms of semantic role labeling.
Namely, theAgent choosing to atone for something, and whatthe entity is atoning for.
However, such situationsin which it?s possible to create new coarse-grainedMWE rolesets seem to be rare.
Some MWEs ini-tially seem similar enough to combine into a sin-gle roleset, but further exploration of usages showsthat they are semantically different.
Take comfortand take heart in both involve improving mood,but take heart in might be more closely-related tohope in meaning, while take comfort in might sim-ply mean to cheer up.3.3 Idiomatic Expression DesignationIn cases in which PB annotation would be very dif-ficult for annotators, due to polysemy or semanticsthat cannot be conveyed by aliasing to an exist-ing roleset, MWEs will be listed for future annota-tion as Idiomatic Expressions (IE), which get spe-cial treatment.
This designation indicates that theMWE is so unique that it would require its ownnew roleset(s) in PB, and even with these role-sets, annotators may still have difficulty determin-ing the appropriate roleset choice or sense of theMWE.
As mentioned previously, creating multi-ple rolesets for each expression is inefficient, es-pecially so if the rolesets manually created will bedifficult to distinguish; thus, currently such casesare simply marked with the generic IE roleset.The MWE take the count is an illustrative exam-ple of this type of case.
Undergraduate and grad-uate annotators trained in linguistics tend to havedifficulty with detailed sports references in anno-tation instances, regardless of how much contextis provided.
This MWE applies to several sportsscenarios: one can take the count in boxing ortake the (full) count in baseball, and some usageswere even found for football, where many speak-ers would use run down the clock.
Annotatorsunfamiliar with the somewhat esoteric meaningsof these phrases would undoubtedly have troubledistinguishing the rolesets and arguments of therolesets, thus take the count in sports contexts (asopposed to the LVC take the count, meaning tocount) will simply be designated IE.96Currently, IE instances are simply set asidefrom the rest of the PB corpus, so as to avoid theseinstances adding noise to the data.
In the future,these IE expressions will need to be treated indi-vidually to determine the best way to capture theirunique semantics.4 Results & ConclusionsOne way of analyzing the validity of this method-ology is to examine the Inter-Annotator Agree-ment (IAA) on the proposed alias.
After thetraining period (in which about 60 MWEs wereinvestigated as a group), annotators worked ondouble-blind annotation of 100 additional MWEs.Of these, 17 were found to be repeats of earlierMWEs.
Of the remaining 83, annotators agreedon the exact alias in 32 cases, giving a rather poor,simple IAA of about 39%.
However, the stan-dards used to calculate IAA were rigid, as onlyinstances in which the annotators aliased the mul-tiword expressions to exactly the same lexical verbor noun roleset were counted as an agreement.Annotators often disagreed on lexical verbs, butstill chose verbs that were extraordinarily similar.Take, for example, the MWE take back.
One an-notator chose to alias this MWE to retract whilethe other annotator chose reclaim.
It is safe to saythat both of these lexical verbs are equally logicalchoices for take back and have similar semanticand syntactic qualities.
In other cases, annotatorshad discovered different senses in their researchof usages, and therefore the aliases reflect differ-ent senses of the MWE.
Instances like these weremarked as disagreements, resulting in a mislead-ingly low IAA.
After discussion of disagreements,IAA for these 83 MWEs rose to 78%, leaving 18MWEs for which the annotators were unable toagree on a strategy.
Annotation proceeded with anadditional 76 MWEs, and for this set annotatorsdisagreed on only 6 MWEs.
This process demon-strates that although annotators may not agree onthe first alias that comes to mind, they tend toagree on similar verbs that can capture the seman-tics of an MWE appropriately.
In a final adjudica-tion pass, adjudicators discussed the cases of dis-agreement with the annotators and made a final de-cision on the strategy to be pursued.In all, 159 unique MWEs were examined indouble-blind annotation.
Of these, 21 were dis-carded either because annotators felt they werenot truly MWEs, and could be treated composi-tionally, or because they were very slight variantsof other MWEs.
The following table shows howmany of the remaining 138 MWEs were agreedupon for aliasing (and how many of these werethought to be LVCs), how many cases led to theaddition of new rolesets, how many will be la-beled IE in future annotation, and how many willremain classed with the existing Take senses (notethat 4 MWEs were classed as having both a poten-tial alias for LVC usages, and requiring rolesetsor another strategy for other usages; for example,take the count discussed above).
Overall, this pilotMWE Example Strategy Counttake tumble Alias-LVC 45take it easy Alias-nonLVC 55take down Roleset(s) Created 20take count IE 4take home Take.XX 18Table 1: MWE cases addressed by each strategy.demonstrated that the approach is promising, con-sidering that it requires only about 20 new rolesetsto be created, as opposed to over 138 (given thatsome MWEs have multiple senses, requiring mul-tiple rolesets).
As annotations move on to addi-tional MWEs involving other verbs, a similar re-duction in the roleset workload will be invaluableto expanding PB.5 Future WorkThe next step in this research is to complete theroleset unification, which allows the aliasing totake effect.
This process is currently underway.Once this is complete, an investigation of takeannotations using the unified rolesets will be un-dertaken, with special focus on whether IAA fortake instances is improved, and whether perfor-mance of automatic Semantic Role Labeling andWord Sense Disambiguation applications trainedon this data is improved.
If results in these areasare promising, this research will shift to analyzingmake, get, and have MWEs with this methodology.AcknowledgmentsWe gratefully acknowledge the support of theNational Science Foundation Grant NSF-IIS-1116782, A Bayesian Approach to Dynamic Lex-ical Resources for Flexible Language Process-ing, and funding under the BOLT and Machine97Reading programs, HR0011-11-C-0145 (BOLT)FA8750-09-C-0179 (M.R.).
Any opinions, find-ings, and conclusions or recommendations ex-pressed in this material are those of the authorsand do not necessarily reflect the views of the Na-tional Science Foundation.ReferencesL.
Banarescu, C. Bonial, S. Cai, M. Georgescu, K.Griffitt, U. Hermjakob, K. Knight, P. Koehn, M.Palmer, and N. Schneider 2013.
Abstract Mean-ing Representation for Sembanking.
Proceedings ofthe Linguistic Annotation Workshop.Claire Bonial, Julia Bonn, Kathryn Conger, Jena D.Hwang and Martha Palmer.
In preparation.
Prop-Bank: Semantics of New Predicate Types.
Pro-ceedings of the Language Resources and EvaluationConference - LREC-2014.
Reykjavik, Iceland.Jan Haji?c, Eva Haji?cov, Jarmila Panevov, Petr Sgall,Silvie Cinkov, Eva Fu?ckov, Marie Mikulov, PetrPajas, Jan Popelka, Ji?r Semeck?y, Jana?Sindlerov,Jan?St?epnek, Josef Toman, Zde?nka Ure?sov, Zden?ek?Zabokrtsk?y.
2012.
Prague Czech-English Depen-dency Treebank 2.0.
Linguistic Data Consortium,Philadelphia.Afsaneh Fazly.
2007.
Automatic Acquisition of LexicalKnowledge about Multiword Predicates.
PhD The-sis, Department of Computer Science, University ofToronto.Christiane Fellbaum (Ed.)
1998.
Wordnet: An Elec-tronic Lexical Database.
MIT press, Cambridge.Jena D. Hwang, Archna Bhatia, Claire Bonial, AousMansouri, Ashwini Vaidya, Nianwen Xue andMartha Palmer.
2010.
PropBank Annotation ofMultilingual Light Verb Constructions Proceedingsof the Linguistic Annotation Workshop held in con-junction with ACL-2010.
Uppsala, Sweden.Adam Kilgarriff, Pavel Rychly, Pavel Smrz, and DavidTugwell.
2004.
The Sketch Engine.
Proceedings ofEURALEX.
Lorient, France.Chi-kiu Lo, Meriem Beloucif, and Dekai Wu.
2013.Improving machine translation into Chinese by tun-ing against Chinese MEANT.
Proceedings of 10thInternational Workshop on Spoken Language Trans-lation (IWSLT 2013).
Heidelberg, Germany.Martha Palmer, Daniel Gildea, and Paul Kingsbury.2005.
The Proposition Bank: An annotated cor-pus of semantic roles.
Computational Linguistics31(1):71?106.Ivan Sag, Timothy Baldwin, Francis Bond, Ann Copes-take and Dan Flickinger.
2002.
Multiword Expres-sions: A Pain in the Neck for NLP.
In Proceedingsof the Third International Conference on IntelligentText processing and Computational Linguistics (CI-CLING 2002) 1?15.
Mexico City, Mexico98
