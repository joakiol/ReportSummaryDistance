Word Boundary Token Model for the SIGHAN Bakeoff 2007Tsai Jia-LinDepartment of Information ManagementTungnan UniversityTaipei 222, Taiwantsaijl@mail.tnu.edu.twAbstractThis paper describes a Chinese word seg-mentation system based on word boundarytoken model and triple template matchingmodel for extracting unknown words; andword support model for resolving segmen-tation ambiguity.1 IntroductionIn the SIGHAN bakeoff 2007, we participated inthe CKIP and the CityU closed tasks.
Our Chineseword segmentation system is based on three mod-els: (a) word boundary token (WBT) model and (b)triple context matching model for unknown wordextraction, and (c) word support model for seg-mentation disambiguation.
Since the word supportmodel and triple context matching model havebeen proposed in our previous work (Tsai, 2005,2006a and 2006b) at the SIGHAN bakeoff 2005(Thomas, 2005) and 2006 (Levow, 2006), the ma-jor descriptions of this paper is on the WBT model.The remainder of this paper is arranged as follows.In Section 2, we present the WBT model for ex-tracting words from each Chinese sentence.
Scoredresults and analyses of our CWS system are pre-sented in Section 3.
Finally, in Section 4, we pre-sent our conclusion and discuss the direction offuture research.2 Word Boundary Token ModelTo develop the WBT model, first, we define wordboundary token.
Second, we give definition andcomputation of the WBT probability and the WBTfrequency for a given corpus.
Finally, algorithm ofour WBT model for word extraction is given.2.1 Types of Word Boundary TokenWe classify WBT into three types: left, right andbi-direction.
The left and right word boundary(WB) tokens are the immediately preceding wordand the following word of a word in a Chinesesentence, respectively.
Suppose W1W2W3 is aChinese sentence comprised of three Chinesewords W1, W2 and W3.
To this case, W1 and W3are the left and the right WB tokens of W2,respectively.
On the other hand, those words thatcan simultaneously be left and right WB tokens ofa word in corpus are defined as bi-direction WBtokens.
Suppose W4W2W1 is a Chinese sentencecomprised of three Chinese words W4, W2 and W1.Following the above cases, W1 can be a bi-direction WB token for W2.
Table 1 is the Top 5left, right and bi-direction WB tokens derived bythe Academia Sinica (AS) corpus (CKIP, 1995 and1996).
From Table 1, the Top 1 left , right and bi-direction WB tokens is ??(of).
?Left      Right Bi-DirectionTop1 ?
(of)      ?
(of) ?
(of)Top2 ?
(is)      ?
(is) ?
(is)Top3 ?
(at)      ?
(already) ?
(at)Top4 ?
(a)      ?
(at) ?
(already)Top5 ?
(has)      ?
(one) ?
(and)Table 1.
Top 5 left, right and bi-direction WB to-kens derived from the AS corpus151Sixth SIGHAN Workshop on Chinese Language Processing2.2 WBT Frequency and WBT ProbabilityWe first give the computation of WBT frequency,then, the computation of WBT probability.
(1) WBT frequency: we use WBT_F(string, WBT,L/R) as the function of WBT frequency, wherestring is a n-char string containing n Chinesecharacters, WBT is a word boundary token, andL/R indicates to compute left or right WBTfrequency.
Now, take WBT_F(???
(we)?,??
(of)?, L) as example.
First, we submit thequery ?????
to system corpus.
Second, setthe number of sentences including this query isthe WBT_F(???
(we)?, ??
(of), L).
(2) WBT Probability: we use WBT_P(string1,string2, WBT, L/R) as the function of WBTprobability, where string1 and string2 are twon-char strings, WBT is a word boundary token,and L/R indicates to compute left or right WBTprobability.
The equations of left and the rightWBT probability are:WBT_P(string1, string2, WBT, L) =WBT_F(string1, WBT, L) /(WBT_F(string1, WBT, L)+WBT_F(string2, WBT, L) )       (1)WBT_P(string1, string2, WBT, R) =WBT_F(string1, WBT, R) /(WBT_F(string1, WBT, R)+WBT_F(string2, WBT, R) )       (2)2.3 Algorithm of WBT ModelWe use WBTM(n, WBT, threshold_p, threshold_f)as the function of the WBT model, where n is thewindow size, threshold_p is the threshold value ofWBT probability and threshold_f is the thresholdvalue of WBT frequency.
The algorithm of ourWBT model applied to extract words from a givenChinese sentence is as follows:Step 1.
INPUT:n, WBT, threshold_p and  threshold_f;Step 2.
IF sentence length is less or equal to nTHEN GOTO Step 4;Step 3.SET loopCount to oneREPEATCOMBINE the characters of sentence betweenloopCountth and (loopCount + n ?
1)th to be astring_aCOMBINE the characters of sentence between(loopCount+1)th and (loopCount + n)th to bea string_bIF WBT_P(string_a, string_b, WBT, L) ?threshold_p ANDWBT_P(string_a, string_b, WBT, R) ?threshold_p ANDWBT_F(string_a, WBT, L) ?
threshold_fANDWBT_F(string_a, WBT, R) ?
threshold_fTHEN SET string_a is as wordENDIFIF WBT_P(string_b, string_a, WBT, L) ?threshold_p ANDWBT_P(string_b, string_a, WBT, R) ?threshold_p ANDWBT_F(string_b, WBT, L) ?
threshold_fANDWBT_F(string_b, WBT, R) ?
threshold_fTHEN SET string_b to a wordENDIFINCREMENT loopCountUNTIL loopCount > sentence length ?
nStep 4.
END.loopCount is 1string_a = ??
; string_b = ?
?WBT_F(string_a, ??
?, L) = 0WBT_F(string_a, ??
?, R) = 7WBT_F(string_b, ??
?, L) = 0WBT_F(string_b, ??
?, R) = 0WBT_P(string_a, string_b, ??
?, L) = 0WBT_P(string_a, string_b, ??
?, R) = 1WBT_P(string_b, string_a, ??
?, L) = 0WBT_P(string_b, string_a, ??
?, R) = 0SET??
to a wordloopCount is 2string_a = ??
; string_b = ?
?WBT_F(string_a, ??
?, L) = 0WBT_F(string_a, ??
?, R) = 0WBT_F(string_b, ??
?, L) = 0WBT_F(string_b, ??
?, R) = 0WBT_P(string_a, string_b, ??
?, L) = 0WBT_P(string_a, string_b, ??
?, R) = 0WBT_P(string_b, string_a, ??
?, L) = 0WBT_P(string_b, string_a, ??
?, R) = 0Table 2.
An example of applying WBTM(2, ??
?, 0.95,1) to extract word ????
from the Chinese sentence?????
?152Sixth SIGHAN Workshop on Chinese Language ProcessingTable 2 is an example of applying  WBTM(2, ??
?,0.95, 1) to extract words from the Chinese sentence??????
by the AS corpus3 EvaluationIn the SIGHAN Bakeoff 2007, there are five train-ing corpus for word segmentation (WS) task: AS(Academia Sinica), CityU (City University ofHong Kong) are traditional Chinese corpus; CTB(University of Colorado, United States), NCC(State Language Commission of P.R.C., Beijing)and SXU (Shanxi University, Taiyuan) are simpli-fied Chinese corpus.
For each corpus, there areclosed and open tasks.
In this Bakeoff, we attendthe AS (Academia Sinica) and CityU (City Univer-sity of Hong Kong) closed WS tasks.
Tables 3 and4 show the details of CKIP and CityU tasks.
FromTable 3, it indicates that the CKIP should be a 10-folds design.
From Table 4, it indicates that theCityU should be a 5-folds design.Training TestingSentence 95,303  10,834Wordlist 48,114  14,662Table 3.
The details of CKIP WS taskTraining TestingSentence 36,227    8,093Wordlist 43,639  23,303Table 4.
The details of CityU WS task3.1 Our CWS SystemThe major steps of our CWS system with wordboundary token model, triple context matchingmodel and word support model are as below:Step 0.
Combine training corpus and testing corpusas system corpus;Step 1.
Generate the BMM segmentation for thegiven Chinese sentence by system dictionary;Step 2.
Use WBT model with system corpus toextract 2-char, 3-char and 4-char words fromthe given Chinese sentence, where WBT is setto ??,?
??,?
??,?
??,?
??,?
threshold_pis set to 0.95 and threshold_f is set to 1;Step 3.
Use TCT (triple context template) matchingmodel to extract 2-char, 3-char and 4-charwords from the segmented Chinese sentenceof Step 1.
The details of TCT matching modelcan be found in (Tsai, 2005);Step 4.
Add the found words of Steps 2 and 3 intosystem dictionary;Step 5.
Generate the BMM segmentation for thegiven Chinese sentence by system dictionary;Step 6.
Use word support model to resolve Over-lap Ambiguity (OA) and Combination Am-biguity (CA) problems for the BMM seg-mentation of Step 5.3.2 Bakeoff Scored ResultsTable 5 is the comparison of scored results be-tween our CWS and the SIGHAN Bakeoff 2007baseline system for the CKIP closed WS task bythe SIGHAN Bakeoff 2007.
Table 6 is the com-parison between our CWS and the SIGHAN Bake-off 2007 baseline system for the CityU closed WStask by the SIGHAN Bakeoff 2007.Baseline Our CWS IncreaseR 0.8978  0.915  0.0172P 0.8232  0.9001  0.0769F 0.8589  0.9075  0.0486Table 5.
The comparison of scored results betweenour CWS system and the SIGHAN Bakeoff 2007baseline system for the CKIP closed WS taskBaseline Our CWS IncreaseR 0.9006  0.9191  0.0185P 0.8225  0.9014  0.0789F 0.8598  0.9102  0.0504Table 6.
The comparison of scored results betweenour CWS system and the SIGHAN Bakeoff 2007baseline system for the CityU closed WS taskFrom Tables 5 and 6, it shows the major im-provement of our CWS for the baseline system ison the precision of word segmentation.
That is tosay, the major target system for improving ourCWS system is the unknown word extraction sys-tem, i.e.
the word boundary model and the triplecontext template matching model.3.3 AnalysisTable 7 is the coverage of 2-char, 3-char, 4-charand great than 4-char error words extracting by ourCWS for the CKIP and the CityU closed WS tasks.153Sixth SIGHAN Workshop on Chinese Language ProcessingCoverage (%)2-char 3-char 4-char > 4-charCKIP  68% 24% 4% 4%CityU  78% 19% 2% 1%Total  75% 21% 3% 1%Table 7.
The coverage of 2-char, 3-char, 4-charand great than 4-char error words extracting by ourCWS for the CKIP and the CityU closed WS tasksFrom Table 7, it shows the major n-char unknownword extraction for improving our CWS system ison 2-char unknown word extraction.
It is becausethat the total coverage of 2-char word errors ex-traction of our CWS system for the CKIP and theCityU WS tasks is 75%.4 ConclusionsIn this paper, we describes a Chinese word seg-mentation system based on word boundary tokenmodel and triple context matching model (Tsai,2005) for extracting unknown words; and wordsupport model (Tsai, 2006a and 2006b) for resolv-ing segmentation ambiguity.
To develop the wordboundary model, we define WBT and classifyWBT into three types of left, right and bi-direction.As per three types of WBT, we define WBT prob-ability and WBT frequency.In the SIGHAN Bakeoff 2007, we take part inthe CKIP and the CityU closed word segmentationtasks.
The scored results show that our CWS canincrease the Bakeoff baseline system with 4.86%and 5.04% F-measures for the CKIP and the CityUword segmentation tasks, respectively.
On theother hand, we show that the major room for im-proving our CWS system is the 2-char unknownword extraction of the word boundary model andtriple context matching model.
The performance ofword support model is great and supports our pre-vious work (Tsai, 2006a and 2006b).We believe one major advantage of the WBTmodel is to use it with web as live corpus to mini-mum the corpus sparseness effect.
Therefore, inthe future, we shall investigate the WBT modelwith the web corpus, such as the searching resultsof GOOGLE and Yahoo!, etc.ReferencesCKIP (Chinese Knowledge Information ProcessingGroup).
1995.
Technical Report no.
95-02, thecontent and illustration of Sinica corpus of Aca-demia Sinica.
Institute of Information Science,Academia Sinica.CKIP (Chinese Knowledge Information ProcessingGroup).
1996.
A study of Chinese Word Bounda-ries and Segmentation Standard for Informationprocessing (in Chinese).
Technical Report, Taiwan,Taipei, Academia Sinica.Levow, Gina-Anne.
2006.
The Third International Chi-nese Language Processing Bakeoff: Word Seg-mentation and Named Entity Recognition, InProceedings of SIGHAN5 the 3rd InternationalChinese Language Processing Bakeoff at Col-ing/ACL 2006, July, Sydney, Australia, 108-117.Thomas, Emerson.
2005.
The Second International Chi-nese Word Segmentation Bakeoff, In Proceed-ings of The 2nd International Chinese WordSegmentation Bakeoff at SIGHAN-4, October,Jeju Island, Korea, 123-133.Tsai, Jia-Lin.
2005.
Report to BMM-based ChineseWord Segmentor with Context-based UnknownWord Identifier for the Second International Chi-nese Word Segmentation Bakeoff, In Proceed-ings of The 2nd International Chinese WordSegmentation Bakeoff at SIGHAN-4, October,Jeju Island, Korea, 142-145.Tsai, Jia-Lin.
2006.
Using Word Support Model to Im-prove Chinese Input System, In Proceedings ofColing/ACL 2006, July, Sydney, Australia, 842-849.Tsai, Jia-Lin.
2006.
BMM-based Chinese Word Seg-mentor with Word Support Model for theSIGHAN Bakeoff 2006, In Proceedings ofSIGHAN5 the 3rd International Chinese Lan-guage Processing Bakeoff at Coling/ACL 2006,July, Sydney, Australia, 130-133.154Sixth SIGHAN Workshop on Chinese Language Processing
