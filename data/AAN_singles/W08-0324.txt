Proceedings of the Third Workshop on Statistical Machine Translation, pages 163?166,Columbus, Ohio, USA, June 2008. c?2008 Association for Computational LinguisticsStatistical Transfer Systems for French?Englishand German?English Machine TranslationGreg Hanneman and Edmund Huber and Abhaya Agarwal and Vamshi Ambatiand Alok Parlikar and Erik Peterson and Alon LavieLanguage Technologies InstituteCarnegie Mellon UniversityPittsburgh, PA 15213 USA{ghannema, ehuber, abhayaa, vamshi, aup, eepeter, alavie}@cs.cmu.eduAbstractWe apply the Stat-XFER statistical transfermachine translation framework to the task oftranslating from French and German into En-glish.
We introduce statistical methods withinour framework that allow for the principledextraction of syntax-based transfer rules fromparallel corpora given word alignments andconstituency parses.
Performance is evaluatedon test sets from the 2007 WMT shared task.1 IntroductionThe Carnegie Mellon University statistical trans-fer (Stat-XFER) framework is a general search-based and syntax-driven framework for develop-ing MT systems under a variety of data condi-tions (Lavie, 2008).
At its core is a transfer en-gine using two language-pair-dependent resources:a grammar of weighted synchronous context-freerules (possibly augmented with unification-style fea-ture constraints), and a probabilistic bilingual lexi-con of syntax-based word- and phrase-level transla-tions.
The Stat-XFER framework has been used todevelop research MT systems for a number of lan-guage pairs, including Chinese?English, Hebrew?English, Urdu?English, and Hindi?English.In this paper, we describe our use of the frame-work to create new French?English and German?English MT systems for the 2008 Workshop on Sta-tistical Machine Translation shared translation task.We first describe the acquisition and processing ofresources for each language pair and the roles ofthose resources within the Stat-XFER system (Sec-tion 2); we then report results on common test sets(Section 3) and share some early analysis and futuredirections (Section 4).2 System DescriptionBuilding a new machine translation system underthe Stat-XFER framework involves constructing abilingual translation lexicon and a transfer gram-mar.
Over the past six months, we have developednew methods for extracting syntax-based translationlexicons and transfer rules fully automatically fromparsed and word-aligned parallel corpora.
Thesenew methods are described in detail by Lavie etal.
(2008).
Below, we detail the statistical meth-ods by which these resources were extracted for ourFrench?English and German?English systems.2.1 LexiconThe bilingual lexicon is automatically extractedfrom automatically parsed and word-aligned paral-lel corpora.
To obtain high-quality statistical wordalignments, we run GIZA++ (Och and Ney, 2003)in both the source-to-target and target-to-source di-rections, then combine the resulting alignments withthe Sym2 symmetric alignment heuristic of Ortiz-Mart?
?nez et al (2005)1.
From this data, we extract alexicon of both word-to-word and syntactic phrase-to-phrase translation equivalents.The word-level correspondences are extracted di-rectly from the word alignments: parts of speech forthese lexical entries are obtained from the preter-1We use Sym2 over more well-known heuristics such as?grow-diag-final?
because Sym2 has been shown to give thebest results for the node-alignment subtask that is part of ourprocessing chain.163ws cs wt ct rparu V appeared V 0.2054paru V seemed V 0.1429paru V found V 0.0893paru V published V 0.0804paru V felt V 0.0714.........paru V already ADV 0.0089paru V appear V 0.0089paru V authoritative ADJ 0.0089Table 1: Part of the lexical entry distribution for theFrench (source) word paru.minal nodes of parse trees of the source and targetsentences.
If parsers are unavailable for either lan-guage, we have also experimented with determin-ing parts of speech with independent taggers suchas TreeTagger (Schmid, 1995).
Alternatively, partsof speech may be projected through the word align-ments from one language to the other if the infor-mation is available on at least one side.
Syntacticphrase-level correspondences are extracted from theparallel data by applying the PFA node alignmentalgorithm described by Lavie et al (2008).
Theyields of the aligned parse tree nodes are extractedas constituent-level translation equivalents.Each entry in the lexicon is assigned a rule score,r, based on its source-side part of speech cs, source-side text ws, target-side part of speech ct, and target-side text wt.
The score is a maximum-likelihood es-timate of the distribution of target-language transla-tion and source- and target-language parts of speech,given the source word or phrase.r = p(wt, ct, cs |ws) (1)?
#(wt, ct, ws, cs)#(ws) + 1(2)We employ add-one smoothing in the denominatorof Equation 2 to counteract overestimation in thecase that #(ws) is small.
Rule scores provide a wayto promote the more likely translation alternativeswhile still retaining a high degree of diversity in thelexicon.
Table 1 shows part of the lexical distribu-tion for the French (source) word paru.The result of the statistical word alignment pro-cess and lexical extraction is a bilingual lexicon con-taining 1,064,755 entries for French?English and1,111,510 entries for German?English.
Sample lex-ical entries are shown in Figure 1.2.2 GrammarTransfer grammars for our earlier statistical transfersystems were manually created by in-house expertsof the languages involved and were therefore small.The Stat-XFER framework has since been extendedwith procedures for automatic grammar acquisitionfrom a parallel corpus, given constituency parses forsource or target data or both.
Our French and Ger-man systems used the context-free grammar rule ex-traction process described by Lavie et al (2008).For French, we used 300,000 parallel sentences fromthe Europarl training data parsed on the English sidewith the Stanford parser (Klein and Manning, 2003)and on the French side with the Xerox XIP parser(A?
?t-Mokhtar et al, 2001).
For German, we used300,000 Europarl sentence pairs parsed with the En-glish and German versions of the Stanford parser2.The set of rules extracted from the parsed corporawas filtered down after scoring to improve systemperformance and run time.
The final French rule setwas comprised of the 1500 most frequently occur-ring rules.
For German, rules that occurred less thantwice were filtered out, leaving a total of 16,469.
Ineach system, rule scores were again calculated byEquation 2, with ws and wt representing the fullright-hand sides of the source and target grammarrules.A secondary version of our French system used aword-level lexicon extracted from the intersection,rather than the symmetricization, of the GIZA++alignments in each direction; we hypothesize thatthis tends to improve precision at the expense of re-call.
The word-level lexicon was supplemented withsyntax-based phrase-level entries obtained from thePFA node alignment algorithm.
The grammarcontained the 700 highest-frequency and the 500highest-scoring rules extracted from the parallelparsed corpus.
This version had a total lexicon sizeof 2,023,531 entries and a total grammar of 1034rules after duplicates were removed.
Figure 2 shows2Due to a combination of time constraints and paucity ofcomputational resources, only a portion of the Europarl parallelcorpus was utilized, and none of the supplementary news com-mentary training data was integrated.164)({VS,248840}V::V |: ["paru"] ?> ["appeared"](*score* 0.205357142857143))(*score* 0.763636363636364){NP,2000012}NP::NP |: ["ein" "Beispiel"] ?> ["an" "example"](Figure 1: Sample lexical entries for French and German.sample grammar rules automatically learned by theprocess described above.2.3 Transfer EngineThe Stat-XFER transfer engine runs in a two-stageprocess, first applying the grammar and lexiconto an input sentence, then running a decoder overthe resulting lattice of scored translation pieces.Scores for each translation piece are based on alog-linear combination of several features: languagemodel probability, rule scores, source-given-targetand target-given-source lexical probabilities, parsefragmentation, and length.
For more details, seeLavie (2008).
The use of a German transfer gram-mar an order of magnitude larger than the corre-sponding French grammar was made possible due toa recent optimization made in the engine.
When en-abled, it constrains the search of translation hypothe-ses to the space of hypotheses whose structure satis-fies the consituent structure of a source-side parse.3 EvaluationWe trained our model parameters on a subset ofthe provided ?dev2006?
development set, optimiz-ing for case-insensitive IBM-style BLEU (Papineniet al, 2002) with several iterations of minimum errorrate training on n-best lists.
In each iteration?s list,we also included the lists from previous iterations inorder to maintain a diversity of hypothesis types andscores.
The provided ?test2007?
and ?nc-test2007?data sets, identical with the test data from the 2007Workshop on Statistical Machine Translation sharedtask, were used as internal development tests.Tables 2, 3, and 4 report scores on these data setsfor our primary French, secondary French, and Ger-man systems.
We report case-insensitive scores forversion 0.6 of METEOR (Lavie and Agarwal, 2007)with all modules enabled, version 1.04 of IBM-styleBLEU (Papineni et al, 2002), and version 5 of TER(Snover et al, 2006).Data Set METEOR BLEU TERdev2006 0.5332 0.2063 64.81test2007 0.5358 0.2078 64.75nc-test2007 0.5369 0.1719 69.83Table 2: Results for the primary French?English systemon provided development and development test sets.Data Set METEOR BLEU TERdev2006 0.5330 0.2086 65.02test2007 0.5386 0.2129 64.29nc-test2007 0.5311 0.1680 70.90Table 3: Results for the secondary French?English sys-tem on provided development and development test sets.4 Analysis and ConclusionsFrom the development test results in Section 3, wenote that the Stat-XFER systems?
performance cur-rently lags behind the state-of-the-art scores on the2007 test data3.
This may be in part due to the lowvolume of training data used for rule learning.
A keyresearch question in our approach is how to distin-guish low-frequency correct and useful transfer rulesfrom ?noisy?
rules that are due to parser errors andincorrect word alignments.
We believe that learningrules from more data will help alleviate this prob-lem by proportionally increasing the counts of goodrules compared to incorrect ones.
We also plan tostudy methods for more effective rule set pruning,regardless of the volume of training data used.The difference in metric scores between in-domain and out-of-domain data is partly due to ef-fects of reference length on the metrics used.
De-tailed output from METEOR and BLEU shows thatthe reference translations for the test2007 set areabout 94% as long as the primary French?English3Top scores on the 2007 test data are approximately 0.60METEOR, 0.33 BLEU, and 57.6 TER.
See Callison-Burch etal.
(2007) for full results.165((*score* 0.866050808314088){PP,1627955}PP:PP [PRE "d?"
"autres" N] ?> [PRE "other" N](X1::Y1)(X4::Y3))({PP,3000085}PP:ADVP ["vor" CARD "Monaten"] ?> [NUM "months" "ago"](*score* 0.9375)(X2::Y1))Figure 2: Sample grammar rules for French and German.Data Set METEOR BLEU TERdev2006 0.4967 0.1794 68.68test2007 0.5052 0.1878 67.94nc-test2007 0.4939 0.1347 74.38Table 4: Results for the German?English system on pro-vided development and development test sets.system?s translations.
On this set, our system hasapproximately balanced precision (0.62) and recall(0.66).
However, the nc-test2007 references are only84% as long as our output, a situation that hurts oursystem?s precision (0.57) but boosts its recall (0.68).METEOR, as a metric that favors recall, shows anegligible increase in score between these two testsets, while BLEU and TER report significant relativedrops of 17.3% and 7.8%.
This behavior appears tobe consistent on the test2007 and nc-test2007 datasets across systems (Callison-Burch et al, 2007).AcknowledgmentsThis research was supported in part by NSF grantsIIS-0121631 (AVENUE) and IIS-0534217 (LE-TRAS), and by the DARPA GALE program.
Wethank the members of the Parsing and Semanticsgroup at Xerox Research Centre Europe for assistingin parsing the French data using their XIP parser.ReferencesSalah A?
?t-Mokhtar, Jean-Pierre Chanod, and ClaudeRoux.
2001.
A multi-input dependency parser.
InProceedings of the Seventh International Workshop onParsing Technologies, Beijing, China, October.Chris Callison-Burch, Cameron Fordyce, Philipp Koehn,Christof Monz, and Josh Schroeder.
2007.
(Meta-)evaluation of machine translation.
In Proceedings ofthe Second Workshop on Statistical Machine Transla-tion, pages 136?158, Prague, Czech Republic, June.Dan Klein and Christopher D. Manning.
2003.
Fast exactinference with a factored model for natural languageparsing.
In Advances in Neural Information Process-ing Systems 15, pages 3?10.
MIT Press, Cambridge,MA.Alon Lavie and Abhaya Agarwal.
2007.
METEOR: Anautomatic metric for MT evaluation with high levels ofcorrelation with human judgments.
In Proceedings ofthe Second Workshop on Statistical Machine Transla-tion, pages 228?231, Prague, Czech Republic, June.Alon Lavie, Alok Parlikar, and Vamshi Ambati.
2008.Syntax-driven learning of sub-sentential translationequivalents and translation rules from parsed paral-lel corpora.
In Proceedings of the Second Work-shop on Syntax and Structure in Statistical Transla-tion, Columbus, OH, June.
To appear.Alon Lavie.
2008.
Stat-XFER: A general search-basedsyntax-driven framework for machine translation.
InComputational Linguistics and Intelligent Text Pro-cessing, Lecture Notes in Computer Science, pages362?375.
Springer.Franz Josef Och and Hermann Ney.
2003.
A system-atic comparison of various statistical alignment mod-els.
Computational Linguistics, 29(1):19?51.Daniel Ortiz-Mart?
?nez, Ismael Garc?
?a-Varea, and Fran-cisco Casacuberta.
2005.
Thot: A toolkit to trainphrase-based models for statistical machine transla-tion.
In Proceedings of the 10th Machine TranslationSummit, pages 141?148, Phuket, Thailand, September.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
BLEU: A method for automatic eva-lution of machine translation.
In Proceedings of the40th Annual Meeting of the Association for Computa-tional Linguistics, pages 311?318, Philadelphia, PA,July.Helmut Schmid.
1995.
Improvements in part-of-speechtagging with an application to German.
In Proceed-ings of the ACL SIGDAT Workshop.Matthew Snover, Bonnie Dorr, Richard Schwartz, LinneaMicciulla, and John Makhoul.
2006.
A study of trans-lation edit rate with targeted human annotation.
InProceedings of the Seventh Conference of the Associ-ation for Machine Translation in the Americas, pages223?231, Cambridge, MA, August.166
