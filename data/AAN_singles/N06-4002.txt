Proceedings of the Human Language Technology Conference of the NAACL, Companion Volume, pages 257?260,New York City, June 2006. c?2006 Association for Computational LinguisticsFrom Pipedreams to Products, and Promise!Janet M. Baker Patri J. PuglieseSaras Institute / Dibner Institute Saras Institute / Dibner InstituteMIT ?
Bldg E56-100 MIT ?
Bldg E56-10038 Memorial Drive 38 Memorial DriveCambridge, MA 02139  USA Cambridge, MA 02139  USAHistSpch@mit.edu HistSpch@mit.eduAbstractThis demonstration  provides a historicalperspective of a number of  research andcommercial systems in Spoken LanguageTechnology over the past 20+ years.
Aseries of chronologically ordered videoclips from many sources will  be  pre-sented to illustrate the many steps and thetremendous progress that has beenachieved over the years.
The clips them-selves are drawn from diverse academicand commercial research labs, productpresentations, and user applications.
Allshow systems being demonstrated  or inactual use.
Over 20 different laboratorysystems, products, and companies are rep-resented in this collection of video mate-rials.
Each of the clips has previouslybeen shown publicly.
The present selec-tion primarily focuses on speech andnatural language systems for speech rec-ognition and synthesis.
Additional contri-butions to this collection are welcome.1.
Project DescriptionPreparations of these materials are being done inconjunction with the History of Speech and Lan-guage Technology Project being conducted bySaras Institute, in affiliation with the Dibner Insti-tute for the History of Science and Technology, atMIT (Cambridge, MA).
The overall mission forthis project is to collect, preserve, and make readilyavailable information about significant researchdiscoveries, technical achievements, and businessdevelopments in speech and language technology.For further information on this project, please go towww.SarasInstitute.org.Work on this project is on-going.
Additionalcontributions of relevant materials are welcome inthe area of Spoken Language Technology, includ-ing speech and natural language systems and ap-plications incorporating speech recognition, speechsynthesis, interactive dialogue, information re-trieval, machine translation, multimodal interfaces,etc.
Please contact us at HistSpch@mit.edu if youhave materials you would like to contribute or withany inquiries, updates, corrections, and sugges-tions.2.
IntroductionThis demonstration is intended to increase aware-ness and understanding of the Spoken LanguageTechnology field, and an appreciation of the evolu-tionary and revolutionary steps which have turnedpipedreams of the past into present products, andfuture promise.
The progression of many stagesfrom research and commercial laboratories intoworking systems are well illustrated by this collec-tion of video clips.
Each video clip (typically 1-5minutes duration) represents technology at the cut-ting edge.
There are 3 categories of video clips:1) Laboratory and Prototype SystemsIn some cases, pioneers and major contributors ofthe field are personally demonstrating their sys-tems.2) Commercial Product DemonstrationsThese run the gamut of televised inter-views/demonstrations (including many live demos)to instructional and commercial videos.257Speak and Spell, model 2(Owned by J. M. Baker)3) User ApplicationsHere users are demonstrating how they use theirsystems on a routine basis in a variety of diverseapplications.3.
HardwareWith the advent of ever more powerful inexpen-sive silicon and the integration of computers withaudio interfaces, the computing platforms onwhich spoken language technology resides haveundergone dramatic changes, progressively reach-ing many more users, ever more conveniently.Over the past 30+ years, we have witnessed thetransition from monolithic room-filling computersto personal, even hand-held devices supportingstate-of-the-art speech technology.
The type andscope of applications have concomitantly multi-plied with the ready access of affordable usefultechnology.
Like other initially expensive central-ized hardware and even biological systems (!
), asthe cost curves come down, evolution progresses,and more processing can be conducted relatively orwholly autonomously, the processing itself can befar more distributed.
So while there continue to beoperations or services (e.g.
call centers) which arestill best done in a centralized fashion, the distribu-tion and proliferation of stand-alone systems (e.g.PCs, and cell phones) become progressively morefeasible and popular.4.
Speech SynthesisThe primary focus of the present set of demonstra-tions is on speech recognition and synthesis.
Start-ing with Homer Dudley's Voder (a manually-controlled speech synthesizer) at the 1939 World'sFair, audio examples of historical speech synthesisapproaches and techniques clearly demonstrateextensive progress (see Resources).
Video clipsillustrate users interacting with different types ofsynthesis systems and applications.Mechanical speaking machines in the 1700'seventually gave way to electrical devices in theearly 1920's, which in turn gave way to computergeneration of speech by the 1960's.
The inventionof the speech spectrogram in the 1940's spurred in-depth speech research, and significantly facilitatedspeech signal and waveform analyses, which blos-somed in the 1960's.Speech generation has taken two basic forms.With analysis-resynthesis the speechwaveform is firstparameterized and thenregenerated or playedback, as in the Voder.With  the advent ofpowerful inexpensivemicroprocessors andDSP chips in the1970's, a multitude  ofdiverse sound-producing consumerproducts hit the market.The popular Speak 'nSpell learning toyintroduced in 1978, was the most notable early en-try.Articulatory synthesis, first demonstrated in1958, models the components and the characteris-tics of the physical production system -  the articu-lators, their movements and their trajectories, aswell as the vocal tract, its resonances, excitations,etc.
A clear understanding of such a system ishighly desirable, and may eventually be achieved.Unfortunately, the underlying complexity of thespeech production system still confounds under-standing and application utility.
Consequently,while studies in articulatory synthesis are still on-going, they were largely superceded by formantsynthesizers.Formant synthesis, also referred to as synthesis-by-rule, characterizes speech in terms of a source-filter model.
In this model, one or more soundsources, representing the vibrating vocal cords andnoise dynamically produced at articulator constric-tions, excite one or more filters, representing thevocal tract and side-tube (e.g.
nasal branch, etc.)resonances.
A catalog of sounds (corresponding to(sub) phones, diphones, or other units) can be con-structed and then reassembled (and smoothed) inaccordance with a dictionary of word or phrasepronunciations.
With careful selection of materials,and the careful tuning and adjustments of parame-ters, synthetic speech can be made to sound verynatural.
Although computationally efficient, auto-matically achieving high quality output is neithereasy nor consistently achievable.Concatenative synthesis refers to the process ofsequentially combining prerecorded exemplars ofspeech or other waveforms to produce the desired258output.
A large database (including many phoneticelements, allophones, words, etc.)
of well-concatenated sound elements can easily producesynthetic speech indistinguishable from naturalspeech.
This process is very memory-intensive, buttypically produces the highest quality speech syn-thesis available.
It is widely deployed in applica-tions requiring natural-sounding speech outputfrom a given voice.Although three major approaches are outlinedhere, a number of hybrid synthesizers, HMM syn-thesizers, and other synthesis methodologies areutilized to address different requirements.5.
Speech RecognitionRadio Rex in his house(Photo by Hy Murveit, Rexowned by Michael Cohen)In the past century, speech recognition has pro-gressed from recognizing small vocabularies totranscribing general purpose dictation in real time,recognizing commands in noisy environments, andreliably extracting words and information fromtelephone conversations and television broadcasts.In 1922, the toy dog "Rex", would spring from hisdoghouse when hewas called by name!Early digit rec-ognizers weredemonstrated in the1950's and 1960's,when the predomi-nant approach was torecognize wholeword templates.
Thisapproach continuedup to the beginningof the 1970's when itstarted beinggradually replacedby Hidden MarkovModel (HMM) sys-tems using stochasticmodels to moreaccurately characterize the naturally highly vari-able speech signal.Spurred on by government funders for "speechunderstanding" in Europe, Japan, and the USA,many university and commercial laboratoriescommenced to advance the technology.
Proceedingfirst through limited vocabulary systems andhighly constrained grammars, systems graduallyexpanded the number of words they could simulta-neously distinguish, despite greater variability inspeakers, languages, and progressively more chal-lenging acoustic/channel and natural language en-vironments.
Starting in the 1970's, hefty special-purpose commercial hardware systems were de-ployed for limited vocabulary industrial applica-tions (e.g.
for hands-free command/control, dataentry, quality control, etc.
), speaker verification,simple telephone data input and query systems, etc.Inexpensive PC sound board enabling discrete rec-ognition started appearing in the market by the late1970's to mid 1980's.In the latter 1980's, vocabulary expanded to sev-eral thousand words, and then in 1990, suddenlyexploded to full general-purpose dictation capabili-ties, though still limited to discrete "one word at atime" input.
Meanwhile in the early 1990's, thefirst speech audio-mining and audio informationretrieval capabilities were successfully proven  towork on prerecorded conversational continuousspeech, on telephone and broadcast data.
Real-timecontinuous speech dictation "software only" prod-ucts became available and sold to millions of cus-tomers by the end of the 1990's.
The availability oflarge corpora of recorded speech and text dramati-cally improved modeling capabilities and systemperformance for both dictation and transcription.Meantime  telephone query systems allowed forusers to engage in dialogue to get stock quotes,weather updates, and even make train and planereservations.
By the year 2000, commercial tele-phone directory assistance systems started appear-ing as well.
Today call centers routinely employspeech technology to elicit and supply customerinformation through interactive spoken dialogue, inlarge part replacing expensive human operators.Though directed dialogues predominate, somemixed initiative dialogues ("How can I help you?
")are becoming available.
Spoken language transla-tion programs, coupling speech recognition to ma-chine translation software, started appearing first inthe laboratory in the late 1990's, and then pro-gressed to the marketplace on PCs and handhelddevices, by about 2000.
Major government-fundedresearch initiatives are presently focusing onspeech-to-speech systems with different languageinputs and outputs.With embedded systems, speech input and out-put are now available on a growing number ofconsumer products including automotive naviga-tion systems, PDAs and toys; hands-free voice-259dialing is shipping on millions of cell phones.
De-spite funding cuts and other setbacks about year2000, the steady stream of ever improving  speechtechnology is gradually becoming an integral partof systems and services, large and small.
The is-sues we face in improving speech technology con-tinue to be very challenging.
The retrospectiveafforded by this demonstration reflects on the greatprogress that we have made!basic principals and history of speech recognition andsynthesis.
From their Home page, click on "Training" toget to the tutorial menu.
http://www.eurovamp.com/IEEE History Center has a website on AutomaticSpeech Synthesis & Recognition which includes inter-views with seminal contributors (under "Archives") tospeech technology an other relevant materials.http://www.ieee.org/organizations/history_center/sloan/ASSR/assr_index.html6.
Resources Saras Institute has a website for the History of Speechand Language Technology with information on histori-cal artifacts, institutions,  major contributors, resources,etc.
http://www.SarasInstitute.orgThe American Association for Artificial Intelligence(AAAI), founded in 1979, includes on their website anvariety of materials on the history of speech technology.The Smithsonian Speech Synthesis History Project(SSSHP) provides a collection of tape recordings, tech-nical records and artifacts of speech synthesis technol-ogy from 1922 to the mid-1980s.http://www.aaai.org/AITopics/html/speech.html#readonJanet M. Baker, "Milestones in Speech Technology ?Past and Future!
", Speech Technology Magazine, Sep-tember/October 2005.  http://www.mindspring.com/~ssshp/ssshp_cd/ss_home.htmThe web site "comp.speech Frequently Asked Ques-tions" provides a myriad of links to sites dealing withthe various aspects of speech technology.Special Workshop in Maui (SWIM): Lectures by Mas-ters in Speech Processing, January 11-14, 2004, in-cluded a series of papers by senior researchers onvarious aspects of the history of speech technology.
A"Program Guide" with summaries of these "Peer Lec-tures" is available at:http://www.speech.cs.cmu.edu/comp.speech/Eurovamp (Voice Adapted Multipurpose Peripherals)maintains a web site which includes tutorials on thehttp://dspincars.sdsu.edu/swim/WorkshopGuide.pdf"The Typewriter one hundred years hence": cartoon from The Illustrated Phonographic World (June, 1984).260
