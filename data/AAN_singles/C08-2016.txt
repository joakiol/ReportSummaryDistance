Coling 2008: Companion volume ?
Posters and Demonstrations, pages 63?66Manchester, August 2008Exact Inference for Multi-label Classification using Sparse GraphicalModelsYusuke Miyao?
Jun?ichi Tsujii???
?Department of Computer Science, University of Tokyo, Japan?School of Computer Science, University of Manchester, UK?National Center for Text Mining, UK{yusuke,tsujii}@is.s.u-tokyo.ac.jpAbstractThis paper describes a parameter estima-tion method for multi-label classificationthat does not rely on approximate infer-ence.
It is known that multi-label clas-sification involving label correlation fea-tures is intractable, because the graphi-cal model for this problem is a completegraph.
Our solution is to exploit the spar-sity of features, and express a model struc-ture for each object by using a sparsegraph.
We can thereby apply the junc-tion tree algorithm, allowing for efficientexact inference on sparse graphs.
Exper-iments on three data sets for text catego-rization demonstrated that our method in-creases the accuracy for text categorizationwith a reasonable cost.1 IntroductionThis paper describes an exact inference methodfor multi-label classification (Schapire and Singer,2000; Ghamrawi and McCallum, 2005), intowhich label correlation features are incorporated.In general, directly solving this problem is compu-tationally intractable, because the graphical modelfor this problem is a complete graph.
Neverthe-less, an important characteristic of this problem,in particular for text categorization, is that only alimited number of features are active; i.e., non-zero, for a given object x.
This sparsity of fea-tures is a desirable characteristic, because we canremove the edges of the graphical model when nocorresponding features are active.
We can there-fore expect that a graphical model for each objectis a sparse graph.
When a graph is sparse, wecan apply the junction tree algorithm (Cowell etc?
2008.
Licensed under the Creative CommonsAttribution-Noncommercial-Share Alike 3.0 Unported li-cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).Some rights reserved.al., 1999), allowing for efficient exact inference onsparse graphs.Our method is evaluated on three data sets fortext categorization; one is from clinical texts, andthe others are from newswire articles.
We ob-serve the trade-off between accuracy and trainingcost, while changing the number of label correla-tion features to be included.2 Multi-label ClassificationGiven a set of labels, L = {l1, .
.
.
, l|L|}, multi-label classification is the task of assigning a sub-set y ?
L to a document x.
In the framework ofstatistical machine learning, this problem can beformulated as a problem of maximizing a scoringfunction ?:y?
= argmaxy?
(x, y) = argmaxy?
(f(x, y)).
(1)As is usually the case in statistical machinelearning, we represent a probabilistic event,?x, y?, with a feature vector, f(x, y) =?f1(x, y), .
.
.
, f|f |(x, y)?.
In text categorization,most effective features represent a frequency of aword w in a document; i.e.,fl,w(x, y) ={cx(w) if l ?
y,0 otherwise,where cx(w) is a frequency of w in x.The most popular method for multi-label classi-fication is to create |L| binary classifiers, each ofwhich determines whether or not to assign a singlelabel (Yang and Pedersen, 1997).
However, sincethe decision for each label is independent of the de-cision for other labels, this method cannot be sen-sitive to label correlations, or the tendency of labelcooccurrences.A recent research effort has been devoted tothe modeling of label correlations.
While a num-ber of approaches have been proposed for deal-ing with label correlations (see Tsoumakas and63Katakis (2007) for the comprehensive survey), theintuitively-appealing method is to incorporate fea-tures on two labels into the model (Ghamrawi andMcCallum, 2005).
The following label correlationfeature indicates a cooccurrence of two labels anda word:fl,l?,w(x, y) ={cx(w) if l, l?
?
y,0 otherwise.3 A Method for Exact InferenceA critical difficulty encountered in the model withlabel correlation features is the computational costfor training and decoding.
When features on everypair of labels are included in the model, its graph-ical model becomes a complete graph, which in-dicates that the exact inference for this model isNP-hard.
However, not all edges are necessaryin actual inference, because of the sparsity of fea-tures.
That is, we can remove edges between l andl?
when no corresponding features are active; i.e.,fl,l?,w(x, y) = 0 for all w. In text categorization,when feature selection is performed, many edgescan be removed because of this characteristic.Therefore, our idea is to enjoy this sparsity offeatures.
We construct a graphical model for eachdocument, and put edges only when one or morefeatures are active on the corresponding label pair.When a graph is sparse, we can apply a methodfor exact inference, such as the junction tree al-gorithm (Cowell et al, 1999).
The junction treealgorithm is a generic algorithm for exact infer-ence on any graphical model, and it allows for ef-ficient inference on sparse graphs.
The methodconverts a graph into a junction tree, which is atree of cliques in the original graph.
When wehave a junction tree for each document, we canefficiently perform belief propagation in order tocompute argmax in Equation (1), or the marginalprobabilities of cliques and labels, necessary forthe parameter estimation of machine learning clas-sifiers, including perceptrons (Collins, 2002), andmaximum entropy models (Berger et al, 1996).The computational complexity of the inference onjunction trees is proportional to the exponential ofthe tree width, which is the maximum number oflabels in a clique, minus one.An essential idea of this method is that a graph-ical model is constructed for each document.
Evenwhen features are defined on all pairs of labels,active features for a specific document are lim-ited.
When combined with feature selection, this# train # test # labels card.cmc2007 978 976 45 1.23reuters10 6,490 2,545 10 1.10reuters90 7,770 3,019 90 1.24Table 1: Statistics of evaluation data sets?
?
ccmc2007 1,000 10 0reuters10 5,000 20 5reuters90 5,000 80 5Table 2: Parameters for evaluation data setsmethod greatly increases the sparsity of the result-ing graphs, which is key to efficiency.A weakness of this method comes from the as-sumption of feature sparseness.
We are forced toapply feature selection, which is considered effec-tive in text categorization, but not necessarily forother tasks.
The design of features is also restrictedin order to ensure the sparsity of features.4 Experiments4.1 Experimental SettingsWe evaluate our method for multi-label classifica-tion using three data sets for text categorization.Table 1 shows the statistics of these data.
In thistable, ?card.?
denotes the average number of la-bels assigned to a document.cmc2007 is a data set used in the Computa-tional Medicine Center (CMC) Challenge 2007(Pestian et al, 2007)1.
This challenge aimed atthe assignment of ICD-9-CM codes, such as coughand pneumonia, to clinical free texts.
It should benoted that this data is controlled, so that both train-ing and test sets include the exact same label com-binations, and the number of combinations is 90.This indicates that this task can be solved as a clas-sification of 90 classes.
However, since this is anunrealistic situation for actual applications, we donot rely on this characteristic in this work.reuters10 and reuters90 are taken fromthe Reuters-21578 collection,2 which is a popu-lar benchmark for text categorization.
This textcollection consists of newswire articles, and eachdocument is assigned topic categories, such asgrain and ship.
We split the data into training andtest sets, according to the so-called ModApte split.1Available at http://www.computationalmedicine.org2Available at http://www.daviddlewis.com/resources/testcollections/reuters21578/64cmc2007BPM ME?
micro-F1 sub.
acc.
micro-F1 sub.
acc.0 82.79 69.88 83.09 69.06100 83.49 70.70 83.68 70.39200 82.95 69.67 83.67 70.18400 83.03 69.98 83.49 70.49800 83.51 71.41 83.58 70.701600 83.10 70.49 83.56 71.003200 80.74 66.70 82.02 69.57reuters10BPM ME?
micro-F1 sub.
acc.
micro-F1 sub.
acc.0 94.23 89.71 93.71 88.76500 94.22 89.98 93.80 89.191000 94.43 90.37 94.07 89.552000 94.46 90.61 94.04 89.944000 94.12 90.26 94.12 89.988000 94.14 90.61 94.50 90.8116000 93.92 90.29 94.30 90.88reuters90BPM ME?
micro-F1 sub.
acc.
micro-F1 sub.
acc.0 84.07 77.91 86.83 79.50500 84.96 78.27 86.89 79.661000 85.38 78.70 86.94 79.992000 85.73 79.79 86.55 79.934000 85.72 79.73 86.54 80.238000 85.90 80.19 86.77 80.3916000 86.17 80.52 ?
?Table 3: Accuracy for cmc2007, reuters10,and reuters90From this data, we create two data sets.
The firstset, reuters10, is a subset of the ModApte split,to which the 10 largest categories are assigned.The other, reuters90, consists of documentsthat are labeled by 90 categories, having at leastone document in each of the training and test sets.In the following experiments, we run two ma-chine learning classifiers: Bayes Point Machines(BPM) (Herbrich et al, 2001), and the maximumentropy model (ME) (Berger et al, 1996).
ForBPM, we run 100 averaged perceptrons (Collins,2002) with 10 iterations for each.
For ME, theorthant-wise quasi-Newton method (Andrew andGao, 2007) is applied, with the hyper parameterfor l1regularization fixed to 1.0.We use word unigram features that represent thefrequency of a particular word in a target docu-ment.
We also use features that indicate the non-existence of a word, which we found effective inpreliminary experiments; feature fl,w?
(x, y) is 1 ifl ?
y and w is not included in the document x.Words are stemmed and number expressions arenormalized to a unique symbol.
Words are notused if they are included in the stopword list (322cmc2007?
max.
width avg.
width time (sec.
)0 0 0.00 90100 2 1.17 132200 3 1.51 145400 3 1.71 165800 4 2.11 2001600 5 2.93 4273200 4 3.99 2280reuters10?
max.
width avg.
width time (sec.
)0 0 0.00 787500 2 1.72 13781000 3 2.00 17522000 4 2.16 25944000 6 2.90 71838000 6 4.22 2155516000 6 5.67 116535reuters90?
max.
width avg.
width time (sec.
)0 0 0.00 26172500 5 1.74 280671000 6 2.24 385102000 6 3.22 424794000 8 3.68 600298000 14 4.56 15326816000 17 6.39 ?Table 4: Tree width and training time forcmc2007, reuters10, and reuters90words), or they occur fewer than a threshold, c, intraining data.
We set c = 5 for reuters10 andreuters90, following previous works (Gham-rawi and McCallum, 2005), while c = 0 forcmc2007, because the data is small.These features are selected according to av-eraged mutual information (information gain),which is the most popular method in previousworks (Yang and Pedersen, 1997; Ghamrawi andMcCallum, 2005).
For each label, features aresorted according to this score, and top-ranked fea-tures are included in the model.
By preliminaryexperiments, we fixed parameters, ?
for word uni-gram features and ?
for non-existence features, foreach data set, as shown in Table 2.The same method is applied to the selection oflabel correlation features.
In the following experi-ments, we observe the accuracy and training timeby changing the threshold parameter ?
for the se-lection of label correlation features.4.2 ResultsTable 33 shows microaveraged F-scores (micro-F1) and subset accuracies (sub.
acc.)
(Ghamrawiand McCallum, 2005) while varying ?, the num-3The experiment with ?
= 16000 for ME was not per-formed due to its cost (estimated time is approx.
two weeks).65ber of label correlation features.
In all data setsand with all classifiers, the accuracy is increasedby incorporating label correlation features.
The re-sults also demonstrate that the accuracy saturates,or even decreases, with large ?.
This indicates thatthe feature selection is necessary not only for ob-taining efficiency, but also for higher accuracy.Table 4 shows tree widths, and the time for thetraining of the ME models.
As shown, the graph-ical model is represented effectively with sparsegraphs, even when the number of label correlationfeatures is increased.
With these results, we canconclude that our method can model label correla-tions with a tractable cost.The accuracy for cmc2007 is significantly bet-ter than the results reported in Patrick et al (2007)(micro-F1=81.1) in a similar setting, in which onlyword unigram features are used.
Our best result isapproaching the results of Crammer et al (2007)(micro-F1=84.6), which exploits various linguisti-cally motivated features.
Numerous results havebeen reported for reuters10, and most of themreport the microaveraged F-score around 91 to 94,while our best result is comparable to the state-of-the-art accuracy.
For reuters90, Ghamrawi andMcCallum (2005) achieved an improvement in themicroaveraged F-score from 86.34 to 87.01, whichis comparable to our result.5 ConclusionThis paper described a method for the exact infer-ence for multi-label classification with label corre-lation features.
Experimental results on text cate-gorization with the CMC challenge data and theReuters-21578 text collection demonstrated thatour method improves the accuracy for text cate-gorization with a tractable cost.
The availabilityof exact inference enables us to apply various ma-chine learning methods not yet investigated in thispaper, including support vector machines.From the perspective of machine learning re-search, feature selection methods should be recon-sidered.
While we used a feature selection methodthat is widely accepted in text categorization re-search, it has no direct connection with machinelearning models.
Since feature selection methodsmotivated by the optimization criteria of machinelearning models have been proposed (Riezler andVasserman, 2004), we expect that the integrationof our proposal with those methods will open up anew framework for multi-label classification.AcknowledgmentsThis work was partially supported by Grant-in-Aidfor Specially Promoted Research (MEXT, Japan)and Grant-in-Aid for Young Scientists (MEXT,Japan).ReferencesAndrew, G. and J. Gao.
2007.
Scalable training ofl1-regularized log-linear models.
In 24th Annual In-ternational Conference on Machine Learning.Berger, A. L., S. A. Della Pietra, and V. J. DellaPietra.
1996.
A maximum entropy approach to natu-ral language processing.
Computational Linguistics,22(1):39?71.Collins, M. 2002.
Discriminative training methodsfor hidden markov models: Theory and experimentswith perceptron algorithms.
In 2002 Conference onEmpirical Methods in Natural Language Processing.Cowell, R. G., A. P. Dawid, S. L. Lauritzen, and D. J.Spiegelhalter.
1999.
Probabilistic Networks and Ex-pert Systems.
Springer-Verlag, New York.Crammer, K., M. Dredze, K. Ganchev, and P. P. Taluk-dar.
2007.
Automatic code assignment to medicaltext.
In BioNLP 2007, pages 129?136.Ghamrawi, N. and A. McCallum.
2005.
Collectivemulti-label classification.
In ACM 14th Conferenceon Information and Knowledge Management.Herbrich, R., T. Graepel, and C. Campbell.
2001.Bayes point machines.
Journal of Machine Learn-ing Research, 1:245?279.Patrick, J., Y. Zhang, and Y. Wang.
2007.
Evaluat-ing feature types for encoding clinical notes.
In 10thConference of the Pacific Association for Computa-tional Linguistics, pages 218?225.Pestian, J. P., C. Brew, P. Matykiewicz, DJ Hovermale,N.
Johnson, K. B. Cohen, and W. Duch.
2007.A shared task involving multi-label classification ofclinical free text.
In BioNLP 2007, pages 97?104.Riezler, S. and A. Vasserman.
2004.
Gradient fea-ture testing and l1regularization for maximum en-tropy parsing.
In 42nd Meeting of the Associationfor Computational Linguistics.Schapire, R. E. and Y.
Singer.
2000.
Boostexter: aboosting-based system for text categorization.
Ma-chine Learning, 39(2/3):135?168.Tsoumakas, G. and I. Katakis.
2007.
Multi-label clas-sification: an overview.
Journal of Data Warehous-ing and Mining, 3(3):1?13.Yang, Y. and J. O. Pedersen.
1997.
A comparativestudy on feature selection in text categorization.
In14th International Conference on Machine Learn-ing, pages 412?420.66
