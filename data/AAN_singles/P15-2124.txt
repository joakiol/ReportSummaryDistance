Proceedings of the 53rd Annual Meeting of the Association for Computational Linguisticsand the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 757?762,Beijing, China, July 26-31, 2015.c?2015 Association for Computational LinguisticsHarnessing Context Incongruity for Sarcasm DetectionAditya Joshi1,2,3Vinita Sharma1Pushpak Bhattacharyya11IIT Bombay, India,2Monash University, Australia3IITB-Monash Research Academy, Indiaaadi.cse@iitb.ac.in, pb@cse.iitb.ac.inAbstractThe relationship between context incon-gruity and sarcasm has been studied in lin-guistics.
We present a computational sys-tem that harnesses context incongruity as abasis for sarcasm detection.
Our statisticalsarcasm classifiers incorporate two kindsof incongruity features: explicit and im-plicit.
We show the benefit of our incon-gruity features for two text forms - tweetsand discussion forum posts.
Our systemalso outperforms two past works (with F-score improvement of 10-20%).
We alsoshow how our features can capture inter-sentential incongruity.1 IntroductionSarcasm is defined as ?a cutting, often ironic re-mark intended to express contempt or ridicule?1.Sarcasm detection is the task of predicting a textas sarcastic or non-sarcastic.
The past work in sar-casm detection involves rule-based and statisticalapproaches using: (a) unigrams and pragmatic fea-tures (such as emoticons, etc.)
(Gonzalez-Ibanezet al., 2011; Carvalho et al., 2009; Barbieri et al.,2014), (b) extraction of common patterns, suchas hashtag-based sentiment (Maynard and Green-wood, 2014; Liebrecht et al., 2013), a positive verbbeing followed by a negative situation (Riloff etal., 2013), or discriminative n-grams (Tsur et al.,2010a; Davidov et al., 2010).Thus, the past work detects sarcasm with spe-cific indicators.
However, we believe that it is timethat sarcasm detection is based on well-studied lin-guistic theories.
In this paper, we use one such lin-guistic theory: context incongruity.
Although thepast work exploits incongruity, it does so piece-meal; we take a more well-rounded view of in-congruity and place it center-stage for our work.1Source: The Free DictionaryThe features of our sarcasm detection system arebased on two kinds of incongruity: ?explicit?
and?implicit?.
The contribution of this paper is:?
We present a sarcasm detection system that isgrounded on a linguistic theory, the theory ofcontext incongruity in our case.
Sarcasm de-tection research can push the frontiers by tak-ing help of well-studied linguistic theories.?
Our sarcasm detection system outperformstwo state-of-art sarcasm detection sys-tems (Riloff et al., 2013; Maynard andGreenwood, 2014).
Our system shows animprovement for short ?tweets?
as well aslong ?discussion forum posts?.?
We introduce inter-sentential incongruity forsarcasm detection, that expands context of adiscussion forum post by including the previ-ous post (also known as the ?elicitor?
post) inthe discussion thread.Rest of the paper is organized as follows.
We firstdiscuss related work in Section 2.
We introducecontext incongruity in Section 3.
Feature designfor explicit incongruity is presented in Section 3.1,and that for implicit incongruity is in Section 3.2.We then describe the architecture of our sarcasmdetection system in Section 4 and our experimen-tal setup in Section 5.
Quantitative evaluation isin Section 6.
Inter-sentential sarcasm detection isin Section 7.
Section 8 presents the error analysis.Section 9 concludes the paper and points to futuredirections.2 Related WorkSarcasm/irony as a linguistic phenomenon hasbeen extensively studied.
According to Wilson(2006), sarcasm arises from situational disparity.The relationship between context incongruity andsarcasm processing (by humans) has been studiedin Ivanko and Pexman (2003).
Several propertiesof sarcasm have also been investigated.
Campbell757and Katz (2012) state that sarcasm occurs alongdifferent dimensions, namely, failed expectation,pragmatic insincerity, negative tension, presenceof a victim and along stylistic components such asemotion words.
Eisterhold et al.
(2006) observethat sarcasm can be identified based on the state-ment preceding and following the sarcastic state-ment.
This is particularly true in cases where theincongruity is not expressed within the sarcastictext itself.Computational detection of sarcasm is a rela-tively recent area of research.
Initial work onsarcasm detection investigates the role of lexi-cal and pragmatic features.
Tepperman et al.
(2006) present sarcasm recognition in speech us-ing prosodic, spectral (average pitch, pitch slope,etc.)
and contextual cues (laughter or responseto questions).
Carvalho et al.
(2009) use sim-ple linguistic features like interjection, changednames, etc.
for irony detection.
Davidov et al.
(2010) train a sarcasm classifier with syntacticand pattern-based features.
Gonzalez-Ibanez et al.
(2011) study the role of unigrams and emoticonsin sarcasm detection.
Liebrecht et al.
(2013) usea dataset of Dutch tweets that contain sarcasm-related hashtags and implement a classifier to pre-dict sarcasm.
A recent work by ?)
takes the outputof sarcasm detection as an input to sentiment clas-sification.
They present a rule-based system thatuses the pattern: if the sentiment of a tokenizedhashtag does not agree with sentiment in rest of thetweet, the tweet is sarcastic, in addition to otherrules.Our approach is architecturally similar to Tsuret al.
(2010b) who use a semi-supervised patternacquisition followed by classification.
Our featureengineering is based on Riloff et al.
(2013) andRamteke et al.
(2013).
Riloff et al.
(2013) statethat sarcasm is a contrast between positive senti-ment word and a negative situation.
They imple-ment a rule-based system that uses phrases of pos-itive verb phrases and negative situations extractedfrom a corpus of sarcastic tweets.
Ramteke et al.
(2013) present a novel approach to detect thwart-ing: the phenomenon where sentiment in majorportions of text is reversed by sentiment in smaller,conclusive portions.3 Context IncongruityIncongruity is defined as ?the state of being notin agreement, as with principles?1.
Context incon-gruity is a necessary condition for sarcasm (Camp-bell and Katz, 2012).
Ivanko and Pexman (2003)state that the sarcasm processing time (time takenby humans to understand sarcasm) depends on thedegree of context incongruity between the state-ment and the context.Deriving from this idea, we consider two casesof incongruity in sarcasm that are analogous to twodegrees of incongruity.
We call them explicit in-congruity and implicit incongruity, where im-plicit incongruity demands a higher processingtime.
It must be noted that our system only han-dles incongruity between the text and commonworld knowledge (i.e., the knowledge that ?beingstranded?
is an undesirable situation, and hence,?Being stranded in traffic is the best way to startmy week?
is a sarcastic statement).
This leaves outan example like ?Wow!
You are so punctual?
whichmay be sarcastic depending on situational context.3.1 Explicit incongruityExplicit incongruity is overtly expressed throughsentiment words of both polarities (as in the caseof ?I love being ignored?
where there is a positiveword ?love?
and a negative word ?ignored?).
Theconverse is not true as in the case of ?The moviestarts slow but the climax is great?.3.2 Implicit IncongruityAn implicit incongruity is covertly expressedthrough phrases of implied sentiment, as op-posed to opposing polar words.
Considerthe example ?I love this paper so much thatI made a doggy bag out of it?.
There is no explicitincongruity here: the only polar word is ?love?.However, the clause ?I made a doggy bag out of it?has an implied sentiment that is incongruous withthe polar word ?love?.3.3 Estimating prevalenceWe conduct a na?
?ve, automatic evaluation on adataset of 18,141 sarcastic tweets.
As a crudeestimate, we consider an explicit incongruity aspresence of positive and negative words.
Around11% sarcastic tweets have at least one explicit in-congruity.
We also manually evaluate 50 sarcas-tic tweets and observe that 10 have explicit incon-gruity, while others have implicit incongruity.4 ArchitectureOur system for sarcasm detection augments thefeature vector of a tweet with features based on the758two types of incongruity.
Specifically, we use fourkinds of features: (a) Lexical, (b) Pragmatic, (c)Implicit congruity, and (d) Explicit incongruityfeatures.
Lexical features are unigrams obtainedusing feature selection techniques such as ?2Testand Categorical Proportional Difference.
Prag-matic features include emoticons, laughter expres-sions, punctuation marks and capital words asgiven by Carvalho et al.
(2009).
In addition tothe two, our system incorporates two kinds of in-congruity features, as discussed next.
The explicitincongruity features are numeric, qualitative fea-tures, while implicit incongruity features are re-lated to implicit phrases.4.1 Feature Design: Explicit IncongruityAn explicit incongruity giving rise to sarcasmbears resemblance to thwarted expectations (an-other commonly known challenge to sentimentanalysis).
Consider this example: ?I love thecolor.
The features are interesting.
But abad battery life ruins it?.
The positive expectationin the first two sentences is thwarted by the lastsentence.
A similar incongruity is observed inthe sarcastic ?My tooth hurts!
Yay!?.
The nega-tive word ?hurts?
is incongruous with the positive?Yay!?.
Hence, our explicit incongruity featuresare a relevant subset of features from a past sys-tem to detect thwarting by Ramteke et al.
(2013).These features are:?
Number of sentiment incongruities: Thenumber of times a positive word is followedby a negative word, and vice versa?
Largest positive/negative subsequence: Thelength of the longest series of contiguous pos-itive/negative words?
Number of positive and negative words?
Lexical Polarity: The polarity based purelyon the basis of lexical features, as determinedby Lingpipe SA system (Alias-i, 2008).
Notethat the ?native polarity?
need not be correct.However, a tweet that is strongly positive onthe surface is more likely to be sarcastic thana tweet that seems to be negative.
This isbecause sarcasm, by definition, tends to becaustic/hurtful.
This also helps against hum-ble bragging.
(as in case of the tweet ?so ihave to be up at 5am to autograph 7,000 picsof myself?
Sounds like just about the worstWednesday morning I could ever imagine?
).4.2 Feature Design: Implicit IncongruityWe use phrases with implicit sentiment as theimplicit incongruity features.
These phrases aresentiment-bearing verb and noun phrases, the lat-ter being situations with implied sentiment (e.g.
?getting late for work?).
For this, we modifythe algorithm given in Riloff et al.
(2013) in twoways: (a) they extract only positive verbs and neg-ative noun situation phrases.
We generalize it toboth polarities, (b) they remove subsumed phrases(i.e.
?being ignored?
subsumes ?being ignored bya friend?)
while we retain both phrases.
The ben-efit of (a) and (b) above was experimentally vali-dated, but is not included in this paper due to lim-ited space.While they use rule-based algorithms that em-ploy these extracted phrases to detect sarcasm, weinclude them as implicit incongruity features, inaddition to other features.
It is possible that the setof extracted situation phrases may contain somephrases without implicit sentiment.
We hope thatthe limited size of the tweet guards against suchfalse positives being too many in number.
We addphrases in the two sets as count-based implicit in-congruity features.5 Experimental SetupWe use three datasets to evaluate our system:1.
Tweet-A (5208 tweets, 4170 sarcastic):We download tweets with hashtags #sar-casm and #sarcastic as sarcastic tweetsand #notsarcasm and #notsarcastic as non-sarcastic, using the Twitter API (https://dev.twitter.com/).
A similar hashtag-based approach to create a sarcasm-annotateddataset was employed in Gonzalez-Ibanez etal.
(2011).
As an additional quality check, arough glance through the tweets is done, andthe ones found to be wrong are removed.
Thehashtags mentioned above are removed fromthe text so that they act as labels but not asfeatures.2.
Tweet-B (2278 tweets, 506 sarcastic): Thisdataset was manually labeled for Riloff et al.(2013).
Some tweets were unavailable, dueto deletion or privacy settings.3.
Discussion-A (1502 discussion forumposts, 752 sarcastic): This dataset is createdfrom the Internet Argument Corpus (Walkeret al., 2012) that contains manual annota-759LexicalUnigrams Unigrams in the training corpusPragmaticCapitalization Numeric feature indicating presence of capital lettersEmoticons & laughter ex-pressionsNumeric feature indicating presence of emoticons and ?lol?sPunctuation marks Numeric feature indicating presence of punctuation marksImplicit IncongruityImplicit SentimentPhrasesBoolean feature indicating phrases extracted from the implicit phraseextraction stepExplicit Incongruity#Explicit incongruity Number of times a word is followed by a word of opposite polarityLargest positive /negativesubsequenceLength of largest series of words with polarity unchanged#Positive words Number of positive words#Negative words Number of negative wordsLexical Polarity Polarity of a tweet based on words presentTable 1: Features of our sarcasm detection systemtions for sarcasm.
We randomly select 752sarcastic and 752 non-sarcastic discussionforum posts.To extract the implicit incongruity features, we runthe iterative algorithm described in Section 4.2,on a dataset of 4000 tweets (50% sarcastic) (alsocreated using hashtag-based supervision).
The al-gorithm results in a total of 79 verb phrases and202 noun phrases.
We train our classifiers for dif-ferent feature combinations, using LibSVM withRBF kernel (Chang and Lin, 2011), and report av-erage 5-fold cross-validation values.Features P R FOriginal Algorithm by Riloff et al.
(2013)Ordered 0.774 0.098 0.173Unordered 0.799 0.337 0.474Our systemLexical (Baseline) 0.820 0.867 0.842Lexical+Implicit 0.822 0.887 0.853Lexical+Explicit 0.807 0.985 0.8871All features 0.814 0.976 0.8876Table 2: Comparative results for Tweet-A usingrule-based algorithm and statistical classifiers us-ing our feature combinations6 EvaluationTable 2 shows the performance of our classifiersin terms of Precision (P), Recall (R) and F-scoreFeatures P R FLexical (Baseline) 0.645 0.508 0.568Lexical+Explicit 0.698 0.391 0.488Lexical+Implicit 0.513 0.762 0.581All features 0.489 0.924 0.640Table 3: Comparative results for Discussion-A us-ing our feature combinations(F), for Tweet-A.
The table first reports valuesfrom a re-implementation of Riloff et al.
(2013)?stwo rule-based algorithms: the ordered versionpredicts a tweet as sarcastic if it has a positiveverb phrase followed by a negative situation/nounphrase, while the unordered does so if the two arepresent in any order.
We see that all statisticalclassifiers surpass the rule-based algorithms.
Thebest F-score obtained is 0.8876 when all four kindsof features are used.
This is an improvement ofabout 5% over the baseline, and 40% over the al-gorithm by Riloff et al.
(2013).
Table 3 showsthat even in the case of the Discussion-A dataset,our features result in an improved performance.The F-score increases from 0.568 to 0.640, an im-provement of about 8% in case of discussion fo-rum posts, when all features are used.To confirm that we indeed do better, we com-pare our system, with their reported values.
Thisis necessary for several reasons.
For example,we reimplement their algorithm but do not have760Approach P R FRiloff et al.
(2013)(best reported)0.62 0.44 0.51Maynard and Green-wood (2014)0.46 0.38 0.41Our system (all fea-tures)0.77 0.51 0.61Table 4: Comparison of our system with two pastworks, for Tweet-Baccess to their exact extracted phrases.
Table 4shows that we achieve a 10% higher F-scorethan the best reported F-score of Riloff et al.(2013).
This value is also 20% higher than ourre-implementation of Maynard and Greenwood(2014) that uses their hashtag retokenizer and rule-based algorithm.7 Incorporating inter-sententialincongruityOur system performs worse for Discussion-Athan Tweet-A/B possibly because of incongruityoutside the text.
Because of the thread struc-ture of discussion forums, sarcasm in a ?targetpost?
can be identified using the post precedingit (called ?elicitor post?
), similar to human con-versation (Eisterhold et al., 2006).
For example,?Wow, you are smart!?
may or may not be sarcas-tic.
If a sarcasm classifier incorporates informa-tion from the elicitor post ?I could not finish my as-signment?, a correct prediction is possible.
Hence,we now explore how our incongruity-based fea-tures can help to capture ?inter-sentential incon-gruity?.
We compute the five explicit incongruityfeatures for a concatenated version of target postand elicitor post (elicitor posts are available forIAC corpus, the source of Discussion-A).
The pre-cision rises to 0.705 but the recall falls to 0.274.
Apossible reason is that only 15% posts have elicitorposts, making the inter-sentential features sparse.That notwithstanding, our observation showsthat using the inter-sentential context is an in-teresting direction for sarcasm detection.8 Error AnalysisSome common errors made by our system are:1.
Subjective polarity: The tweet ?Yay for 3hour Chem labs?
is tagged by the author assarcastic, which may not be common percep-tion.2.
No incongruity within text: As stated inSection 2, our system does not detect sar-casm where incongruity is expressed outsidethe text.
About 10% misclassified examplesthat we analyzed, contained such an incon-gruity.3.
Incongruity due to numbers: Our systemcould not detect incongruity arising due tonumbers as in ?Going in to work for 2 hourswas totally worth the 35 minute drive.?.4.
Dataset granularity: Some discussionforum posts are marked as sarcastic,but contain non-sarcastic portions, lead-ing to irrelevant features.
For example,?How special, now all you have to do is provethat a glob of cells has rights.
I happen tobelieve that a person?s life and the right tolife begins at conception?.5.
Politeness: In some cases, implicit incon-gruity was less evident because of politeness,as in, ?Post all your inside jokes on facebook,I really want to hear about them?.9 Conclusion & Future WorkOur paper uses the linguistic relationship betweencontext incongruity and sarcasm as a basis for sar-casm detection.
Our sarcasm classifier uses fourkinds of features: lexical, pragmatic, explicit in-congruity, and implicit incongruity features.
Weevaluate our system on two text forms: tweets anddiscussion forum posts.
We observe an improve-ment of 40% over a reported rule-based algo-rithm, and 5% over the statistical classifier base-line that uses unigrams, in case of tweets.
The cor-responding improvement in case of discussion fo-rum posts is 8%.
Our system also outperformstwo past works (Riloff et al., 2013; Maynard andGreenwood, 2014) with 10-20% improvement inF-score.
Finally, to improve the performance fordiscussion forum posts, we introduce a novel ap-proach to use elicitor posts for sarcasm detection.We observe an improvement of 21.6% in preci-sion, when our incongruity features are used tocapture inter-sentential incongruity.Our error analysis points to potential futurework such as: (a) role of numbers for sarcasm, and(b) situations with subjective sentiment.
We arecurrently exploring a more robust incorporation ofinter-sentential incongruity for sarcasm detection.761ReferencesAlias-i.
2008.
Lingpipe natural language toolkit.Francesco Barbieri, Horacio Saggion, and FrancescoRonzano.
2014.
Modelling sarcasm in twitter, anovel approach.
ACL 2014, page 50.John D Campbell and Albert N Katz.
2012.
Are therenecessary conditions for inducing a sense of sarcas-tic irony?
Discourse Processes, 49(6):459?480.Paula Carvalho, Lu?
?s Sarmento, M?ario J Silva, andEug?enio de Oliveira.
2009.
Clues for detect-ing irony in user-generated contents: oh...!!
it?sso easy;-).
In Proceedings of the 1st internationalCIKM workshop on Topic-sentiment analysis formass opinion, pages 53?56.
ACM.Chih-Chung Chang and Chih-Jen Lin.
2011.
Lib-svm: a library for support vector machines.
ACMTransactions on Intelligent Systems and Technology(TIST), 2(3):27.Dmitry Davidov, Oren Tsur, and Ari Rappoport.
2010.Semi-supervised recognition of sarcastic sentencesin twitter and amazon.
In Proceedings of the Four-teenth Conference on Computational Natural Lan-guage Learning, pages 107?116.
Association forComputational Linguistics.Jodi Eisterhold, Salvatore Attardo, and Diana Boxer.2006.
Reactions to irony in discourse: Evidence forthe least disruption principle.
Journal of Pragmat-ics, 38(8):1239?1256.Roberto Gonzalez-Ibanez, Smaranda Muresan, andNina Wacholder.
2011.
Identifying sarcasm in twit-ter: a closer look.
In Proceedings of the 49th An-nual Meeting of the Association for ComputationalLinguistics: Human Language Technologies: shortpapers-Volume 2, pages 581?586.
Association forComputational Linguistics.Stacey L Ivanko and Penny M Pexman.
2003.
Contextincongruity and irony processing.
Discourse Pro-cesses, 35(3):241?279.CC Liebrecht, FA Kunneman, and APJ van den Bosch.2013.
The perfect solution for detecting sarcasm intweets# not.Diana Maynard and Mark A Greenwood.
2014.
Whocares about sarcastic tweets?
investigating the im-pact of sarcasm on sentiment analysis.
In Proceed-ings of LREC.Ankit Ramteke, Pushpak Bhattacharyya, Akshat Malu,and J Saketha Nath.
2013.
Detecting turnaroundsin sentiment analysis: Thwarting.
In Proceedings ofACL.Ellen Riloff, Ashequl Qadir, Prafulla Surve, Lalin-dra De Silva, Nathan Gilbert, and Ruihong Huang.2013.
Sarcasm as contrast between a positive senti-ment and negative situation.
In Proceedings of the2013 Conference on Empirical Methods in NaturalLanguage Processing, pages 704?714.
Associationfor Computational Linguistics.Joseph Tepperman, David R Traum, and ShrikanthNarayanan.
2006. yeah right : sarcasm recognitionfor spoken dialogue systems.
In INTERSPEECH.Oren Tsur, Dmitry Davidov, and Ari Rappoport.2010a.
Icwsm-a great catchy name: Semi-supervised recognition of sarcastic sentences in on-line product reviews.
In ICWSM.Oren Tsur, Dmitry Davidov, and Ari Rappoport.2010b.
Icwsm-a great catchy name: Semi-supervised recognition of sarcastic sentences in on-line product reviews.
In ICWSM.Marilyn A Walker, Jean E Fox Tree, Pranav Anand,Rob Abbott, and Joseph King.
2012.
A corpus forresearch on deliberation and debate.
In LREC, pages812?817.Deirdre Wilson.
2006.
The pragmatics of verbal irony:Echo or pretence?
Lingua, 116(10):1722?1743.762
