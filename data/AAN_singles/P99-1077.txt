Cohesion and Collocation:Using Context Vectors in Text SegmentationSte fan  KaufmannCSLI, Stanford UniversityLinguistics Dept.
,  Bldg.
460Stanford, CA 94305-2150, U.S.A.kaufmann@csli, stanford,, eduAbst ractCollocational word similarity is considered a sourceof text cohesion that is hard to measure and quan-tify.
The work presented here explores the use of in-formation from a training corpus in measuring wordsimilarity and evaluates the method in the text seg-mentation task.
An implementation, the VecT i lesystem, produces imilarity curves over texts usingpre-compiled vector representations of the contex-tual behavior of words.
The performance of thissystem is shown to improve over that of the purelystring-based TextTi l ing algorithm (Hearst, 1997).1 BackgroundThe notion of text cohesion rests on the intuitionthat a text is "held together" by a variety of inter-nal forces.
Much of the relevant linguistic literatureis indebted to Halliday and Hasan (1976), where co-hesion is defined as a network of relationships be-tween locations in the text, arising from (i) gram-matical factors (co-reference, use of pro-forms, ellip-sis and sentential connectives), and (ii) lexical fac-tors (reiteration and collocation).
Subsequent workhas further developed this taxonomy (Hoey, 1991)and explored its implications in such are.as as para-graphing (Longacre, 1979; Bond and Hayes, 1984;Stark, 1988), relevance (Sperber and Wilson, 1995)and discourse structure (Grosz and Sidner, 1986).The lexical variety of cohesion is semantically de-fined, invoking a measure of word similarity.
Butthis is hard to measure objectively, especially in thecase of collocational relationships, which hold be-tween words primarily because they "regularly co-occur."
Halliday and Hasan refrained from a deeperanalysis, but hinted at a notion of "degrees of prox-imity in the lexical system, a function of the prob-ability with which one tends to co-occur with an-other."
(p. 290)The VecTile system presented here is designedto utilize precisely this kind of lexical relationship,relying on observations on a large training corpusto derive a measure of similarity between words andtext passages.2 Re la ted  WorkPrevious approaches to calculating cohesion dif-fer in the kind of lexical relationship they quan-tify and in the amount of semantic knowledge theyrely on.
Topic parsing (Hahn, 1990) utilizes bothgrammatical cues and semantic inference based onpre-coded domain-specific knowledge More gen-eral approaches assess word mmllanty based on the-sauri (Morris and Hirst, 1991) or dictionary defini-tions (Kozima, 1994).Methods that solely use observations of pat-terns in vocabulary use include vocabulary manage-ment (Youmans, 1991) and the blocks algorithm im--plemented in the TextTi l ing system (Hearst, 1997).The latter is compared below with the system intro-duced here.A good recent overview of previous approachescan be found in Chapters 4 and 5 of (Reynar, 1998).3 The  Method3.1 Context  VectorsThe VecTile system is based on the WordSpae~model of (Schiitze, 1997; Schfitze, 1998).
The ideais to represent words by encoding the environmentsin which they typically occur in texts.
Such a rep-resentation can be obtained automatically and oftenprovides ufficient information to make deep linguis-tic analysis unnecessary.
This has led to promis-ing results in information retrieval and related ar-eas (Flournoy et al, 1998a; Flournoy et al, 1998b).Given a dictionary W and a relatively small set-C of meaningful "content" words, for each pair inW ?
C, the number of times is recorded that thetwo co-occur within some measure of distance in atraining corpus.
This yields a \[C\]-dimensionalvectorfor each w E W. The direction that the vector has inthe resulting ICI-dimensional space then representsthe collocational behavior of w in the training cor-pus.
In the present implementation, IW\[-- 20,500and ICI = 1000.
For computational efficiency and toavoid the high number of zero values in the resultingmatrix, the matrix is reduced to 100 dimensions us-ing Singular-Value Decomposition (Golub and vanLoan, 1989).5910.980.960.940.921 2 3 9 1D 11 1920 21;0.90. .
.
.
.
.
.
.
.
.
.12 13 14 151B 17 18 4 $ 6 7 82 3Section Breaks>(9Figure 1: Example of a VecT?le similarity plotAs a measure of similarity in collocational behav-ior between two words, the cosine between their vec-tors is computed: Given two n-dimensional vectorsV, W,co8( , 3) = , ,w, (1)3.2 Compar ing  Window Vectors  .In order to represent pieces of text larger than sin-gle words, the vectors of the constituent words areadded up.
This yields new vectors in the same space,which can again be compared against each other andword vectors.
If the word vectors in two adjacentportions of text are added up, then the cosine be-tween the two resulting vectors is a measure of thelexical similarity between the two portions of text.The VecT i le  system uses word vectors based onco-occurrence ounts on a corpus of New York Timesarticles.
Two adjacent windows (200 words each inthis experiment) move over the input text, and atpre-determined intervals (every 10 words), the vec-tors associated with the words in each window areadded up, and the cosine between the resulting win-dow vectors is assigned to the gap between the win-dows in the text.
High values indicate lexical close-ness.
Troughs in the resulting similarity'curve markspots with low cohesion.3.3 Text  Segmentat ionTo evaluate the performance of the system and facil-itate comparison with other approaches, it was usedin text segmentation.
The motivating assumptionbehind this test is that cohesion reinforces the topi-cal unity of subparts of text and lack of it correlateswith their boundaries, hence if a system correctly;predicts egment boundaries, it is indeed measuringcohesion.
For want of a way of observing cohesiondirectly, this indirect relationship is commonly usedfor purposes of evaluation.4 Imp lementat ionThe implementation of the text segmenter resem-bles that of the Texl~Tiling system (Hearst, 1997.
),The words from the input are stemmed and asso-ciated with their context vectors.
The similaritycurve over the text, obtained as described above,is smoothed out by a simple low-pass filter, and lowpoints are assigned epth scores according to the dif-ference between their values and those of the sur-rounding peaks.
The mean and standard deviationof those depth scores are used to calculate a cutoffbelow which a trough is judged to be near a sec-tion break.
The nearest paragraph boundary is thenmarked as a section break in the output.An example of a text similarity curve is given inFigure 1.
Paragraph numbers are inside the plot atthe bottom.
Speaker judgments by five subjects areinserted in five rows in the upper half.592Table 1: Precision and recall on the text segmentation taskTextTiling VecTile \[ SubjectsText # Prec I Rec Free \] aec \] Prec \ ]aec1 60 50 60 50 75 7,72 14 20 100 80 76 763 50 50 50 50 72 734 25 50 10 25 70 755 10 25 40 50 70 74avg 32 40 52 51 73 75The crucial difference between this and theTextT i l ing  system is that the latter builds win-dow vectors solely by counting the occurrences ofstrings in the windows.
Repetition is rewarded bythe present approach, too, as identical 'words con-tribute most to the similarity between the block vec-tors.
However, similarity scores can be high evenin the absence of pure string repetition, as long asthe adjacent windows contain words that co-occurfrequently in the training corpus.
Thus what a di-rect comparison between the systems will show iswhether the addition of collocational informationgleaned from the training corpu s sharpens or bluntsthe judgment.For comparison, the TextT f l ing  algorithm wasimplemented and run with the same window size(200) and gap interval (10).5 Eva luat ion5.1 The  TaskIn a pilot study, five subjects were presented withfive texts from a popular-science magazine, all be-tween 2,000 and 3,400 words, or between 20 and 35paragraphs, in length.
Section headings and anyother clues were removed from the layout.
Para-graph breaks were left in place.
Thus the task wasnot to find paragraph breaks, but breaks betweenmulti-paragraph passages that according to the thesubject's judgment marked topic shifts.
All subjectswere native speakers of English.
11 The instructions read:"You will be given five magazine articles of roughly equallength with section breaks removed.
Please mark the placeswhere the topic seems to change (draw a line between para-graphs).
Read at normal speed, do not take much longer thanyou normally would.
But do feel free to go back and recon-sider your decisions (even change your markings) as you goalong.Also, for each section, suggest a headline of a few words thatcaptures its main content.If you find it hard to decide between two places, mark both,giving preference toone and indicating that the other was aclose rival.
"5.2 Resu l tsTo obtain an "expert opinion" against which tocompare the algorithms, those paragraph bound-aries were marked as "correct" section breaks whichat least three out of the five subjects had marked.
(Three out of seven (Litman and Passonneau, 1995;Hearst, 1997) or 30% (Kozima, 1994) are also some-times deemed sufficient.)
For the two systems as wellas the subjects, precision and recall with respect othe set of "correct" section breaks were calculated.The results are listed in Table 1.The context vectors clearly led to an improvedperformance over the counting of pure string repeti-tions.The simple assignment of section breaks to thenearest paragraph boundary may have led to noisein some cases; moreover, it is not really part ofthe task of measuring cohesion.
Therefore the textswere processed again, this time moving the windowsover whole paragraphs at a time, calculating ap-values at the paragraph gaps.
For each paragraphbreak, the number of subjects who had marked itas a section break was taken as an indicator of the"strength" of the boundary.
There was a significantnegative correlation between the values calculatedby both systems and that measure of strength, withr = -.338(p = .0002) for the VecTi le system andr --- - .220(p = .0172) for Tex?Ti l ing.
In otherwords, deep gaps in the similarity measure are asso-ciated with strong agreement between subjects thatthe spot marks a section boundary.
Although r 2is low both cases, the VecTi le system yields moresignificant results.5.3 Discuss ion and  Fur ther  WorkThe results discussed above need further supportwith a larger subject pool, as the level of agree:ment among the judges was at the low end of whatcan be considered significant.
This is shown bythe Kappa coefficients, measured against he expertopinion and listed in Table 2.
The overall averagewas .594.Despite this caveat, the results clearly show thatadding collocational information from the training?
r593Table 2: Kappa coefficientsSubject#Text# 112\ ]3141511~1 .775 .629 .596 .444 .642 .6172 .723 .649 .491 .753 .557 .6353 .859 .121 .173 .538 .738 .4864 .870 .532 .635 .299 .870 .6415 .833 .500 .625 .423 .500 .576AH texts .814 .491 .508 481 .675 .594corpus improves the prediction of section breaks,hence, under common assumptions, the measure-ment of lexical cohesion.
It is likely that these en-couraging results can be further improved.
Follow-ing are a few suggestions ofways to do so.Some factors work against the context vectormethod.
For instance, the system currently has nomechanism to handle words that it has no contextvectors for.
Often it is precisely the co-occurrenceof uncommon words not in the training corpus (per-sonal names, rare terminology etc.)
that ties texttogether.
Such cases pose no challenge to the string-based system, but the VecTile system cannot utilizethem.
The best solution might be a hybrid systemwith a backup procedure for unknown words.Another point to note is how well the much sim-pler TextTile system compares.
Indeed, a close lookat the figures in Table 1 reveals that the better re-sults of the VecTile system are due in large part toone of the texts, viz.
#2.
Considering the additionaleffort and resources involved in using context vec-tors, the modest boost in performance might oftennot be worth the effort in practice.
This suggeststhat pure string repetition is a particularly strongindicator of similarity, and the vector-based systemmight benefit from a mechanism to give those vec-tors a higher weight than co-occurrences of merelysimilar words.Another potentially important parameter is thenature of the training corpus.
In this case, it con-sisted mainly of news texts, while the texts in theexperiment were scientific expository texts.
A morehomogeneous setting might have further improvedthe results.Finally, the evaluation of results in this task iscomplicated by the fact that "near-hits" (cases inwhich a section break is off by one paragraph) donot have any positive ffect on the score."
This prob-lem has been dealt with in the Topic Detection andTracking (TDT) project by a more flexible score thatbecomes gradually worse as the distance between hy-pothesized and "real" boundaries increases (TDT,1997a; TDT, 1997b).AcknowledgementsThanks to Stanley Peters, Yasuhiro Takayama, Hin-rich Schiitze, David Beaver, Edward Flemming andthree anonymous reviewers for helpful discussionand comments, to Stanley Peters for office spaceand computational infrastructure, and to RaymondFlournoy for assistance with the vector space.Re ferencesS.J.
Bond and J.R. Hayes.
1984.
Cues people useto paragraph text.
Research in the Teaching ofEnglish, 18:147-167.Raymond Flournoy, Ryan Ginstrom, Kenichi Imai,Stefan Kaufmann, Genichiro Kikui, Stanley Pe-ters, Hinrich Schiitze, and Yasuhiro Takayama.1998a.
Personalization a d users' semantic expec-tations.
ACM SIGIR'98 Workshop on Query In-put and User Expectations, Melbourne, Australia.Raymond Flournoy, Hiroshi Masuichi, and Stan~ley Peters.
1998b.
Cross-language information re-trievM: Some methods and tools.
In D. Hiemstra,F.
de Jong, and K. Netter, editors, TWLT 13 Lan-guage Technology in Multimedia Information Re-trieval, pages 79-83.Talmy Givbn, editor.
1979.
Discourse and Syntax.Academic Press.G.
H. Golub and C. F. van Loan.
1989.
Matrix Com-putations.
Johns Hopkins University Press.
.Barbara J. Grosz and Candace L. Sidner.
1986.
At-tention, intentions, and the structure of discourse.Computational Linguistics, 12(3) :175-204.Udo Hahn.
1990.
Topic parsing: Accounting for textmacro structures infull-text analysis.
InformationProcessing and Management, 26:135-170.Michael A.K.
Halliday and Ruqaiya Hasan.
1976.Cohesion in English.
Longman.Marti Hearst.
1997.
TextTiling: Segmenting tex~into multi-paragraph subtopic passages.
Compu-tational Linguistics, 23(1):33-64.Michael Hoey.
1991.
Patterns of Lexis in Text.
Ox-ford University Press.Hideki Kozima.
1994.
Computing Lexical Cohesionas a Tool for Text Analysis.
Ph.D. thesis, Univer-sity of Electro-Communications.Chin-Yew Lin.
1997.
Robust AutomaticTopic Identification.
Ph.D. thesis, Uni~versity of Southern California.
\[Online\]http ://ww.. isi.
edu/~cyl/thesis/thesis, html\[1999, April 24\].Diane J. Litman and Rebecca J. Passonneau.
1995.Combining multiple knowledge sources for dis-course segmentation.
In Proceedings of the 33rdACL, pages 108-115.L.E.
Longacre.
1979.
The paragraph as a grammat-ical unit.
In Givbn (Givbn, 1979), pages 115-134:594Jane Morris and Graeme Hirst.
1991.
Lexical co-hesion computed by thesaural relations as an in-dication of the structure of text.
ComputationalLinguistics, 17(1):21-48.Jeffrey C. Reynar.
1998.
Topic.
Segmenta-tion: Algorithms and Applications.
Ph.D.thesis, University of Pennsylvania.
\[Online\]http ://~ww.
cis.
edu/-j creynar/research, html\[1999, April 24\].K.
Richmond, A. Smith, and E. Amitay.
1997.Detecting subject boundaries within text: Alanguage independent statistical approach.
InProceedings of The Second Conference on Em-pirical Methods in Natural Language.
Processing(EMNLP-2).Hinrich Schiitze.
1997.
Ambiguity Resolution inLanguage Learning.
CSLI.Hinrich Schiitze.
1998.
Automatic word sensediscrimination.
Computational Linguistics,24(1):97-123.Dan Sperber and Deidre Wilson.
1995.
Relevance:Communication and Cognition.
Harvard Univer-sity Press, 2nd edition.Heather Stark.
1988.
What do paragraph markingsdo?
Discourse Processes, 11(3):275-304.1997a.
The TOT Pilot Study Corpus Documenta-tion version 1.3, 10.
Distributed by the LinguisticData Consortium.1997b.
The Topic Detection and Tracking (TDT) Pi-lot Study Evaluation Plan, 10.
Distributed by theLinguistic Data Consortium.Gilbert Youmans.
1991.
A new tool for discourseanalysis: The vocabulary-management profile.Language, 47(4):763-789.595
