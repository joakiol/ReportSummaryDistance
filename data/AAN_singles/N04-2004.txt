A Computational Framework for Non-Lexicalist SemanticsJimmy LinMIT Computer Science and Artificial Intelligence LaboratoryCambridge, MA 02139jimmylin@csail.mit.eduAbstractUnder a lexicalist approach to semantics, a verbcompletely encodes its syntactic and semanticstructures, along with the relevant syntax-to-semantics mapping; polysemy is typically at-tributed to the existence of different lexical en-tries.
A lexicon organized in this fashion con-tains much redundant information and is un-able to capture cross-categorial morphologicalderivations.
The solution is to spread the ?se-mantic load?
of lexical entries to other mor-phemes not typically taken to bear semanticcontent.
This approach follows current trendsin linguistic theory, and more perspicuously ac-counts for alternations in argument structure.I demonstrate how such a framework can becomputationally realized with a feature-based,agenda-driven chart parser for the MinimalistProgram.1 IntroductionThe understanding of natural language text includes notonly analysis of syntactic structure, but also of semanticcontent.
Due to advances in statistical syntactic parsingtechniques (Collins, 1997; Charniak, 2001), attention hasrecently shifted towards the harder question of analyzingthe meaning of natural language sentences.A common lexical semantic representation in the com-putational linguistics literature is a frame-based modelwhere syntactic arguments are associated with various se-mantic roles (essentially frame slots).
Verbs are viewedas simple predicates over their arguments.
This approachhas its roots in Fillmore?s Case Grammar (1968), andserves as the foundation for two current large-scale se-mantic annotation projects: FrameNet (Baker et al, 1998)and PropBank (Kingsbury et al, 2002).Underlying the semantic roles approach is a lexical-ist assumption, that is, each verb?s lexical entry com-pletely encodes (more formally, projects) its syntactic andsemantic structures.
Alternations in argument structureare usually attributed to multiple lexical entries (i.e., verbsenses).
Under the lexicalist approach, the semantics ofthe verb break might look something like this:(1) break(agent, theme)agent: subject theme: objectbreak(agent, theme, instrument)agent: subject theme: objectinstrument: oblique(with)break(theme)theme: subject.
.
.The lexicon explicitly specifies the different subcate-gorization frames of a verb, e.g., the causative frame, thecausative instrumental frame, the inchoative frame, etc.The major drawback of this approach, however, is thetremendous amount of redundancy in the lexicon?forexample, the class of prototypical transitive verbs wherethe agent appears as the subject and the theme as the di-rect object must all duplicate this pattern.The typical solution to the redundancy problem isto group verbs according to their argument realizationpatterns (Levin, 1993), possibly arranged in an inheri-tance hierarchy.
The argument structure and syntax-to-semantics mapping would then only need to be specifiedonce for each verb class.
In addition, lexical rules couldbe formulated to derive certain alternations from more ba-sic forms.Nevertheless, the lexicalist approach does not captureproductive morphological processes that pervade natu-ral language, for example, flat.V ?
flatten.ADJ or ham-mer.N ?
hammer.V; most frameworks for computationalsemantics fail to capture the deeper derivational relation-ship between morphologically-related terms.
For lan-guages with rich derivational morphology, this problemis often critical: the standard architectural view of mor-phological analysis as a preprocessor presents difficultiesin handling semantically meaningful affixes.In this paper, I present a computational implementationof Distributed Morphology (Halle and Marantz, 1993), anon-lexicalist linguistic theory that erases the distinctionbetween syntactic derivation and morphological deriva-tion.
This framework leads to finer-grained semantics ca-pable of better capturing linguistic generalizations.2 Event StructureIt has previously been argued that representations basedon a fixed collection of semantic roles cannot adequatelycapture natural language semantics.
The actual inventoryof semantic roles, along with precise definitions and di-agnostics, remains an unsolved problem; see (Levin andRappaport Hovav, 1996).
Fixed roles are too coarse-grained to account for certain semantic distinctions?theonly recourse, to expand the inventory of roles, comeswith the price of increased complexity, e.g., in the syntax-to-semantics mapping.There is a general consensus among theoretical lin-guists that the proper representation of verbal argumentstructure is event structure?representations grounded ina theory of events that decompose semantic roles interms of primitive predicates representing concepts suchas causality and inchoativity (Dowty, 1979; Jackendoff,1983; Pustejovsky, 1991b; Rappaport Hovav and Levin,1998).
Consider the following example:(2) He sweeps the floor clean.
[ [ DO(he, sweeps(the floor)) ] CAUSE[ BECOME [ clean(the floor) ] ] ]Dowty breaks the event described by (2) into twosubevents, the activity of sweeping the floor and its result,the state of the floor being clean.
A more recent approach,advocated by Rappaport Hovav and Levin (1998), de-scribes a basic set of event templates corresponding toVendler?s event classes (Vendler, 1957):(3) a.
[ x ACT<MANNER> ] (activity)b.
[ x <STATE> ] (state)c. [ BECOME [ x <STATE> ] ] (achievement)d. [ x CAUSE [ BECOME [ x <STATE> ] ] ](accomplishment)e. [ [ x ACT<MANNER> ] CAUSE [ BECOME[ x <STATE> ] ] ] (accomplishment)A process called Template Augmentation allows basicevent templates to be freely ?augmented?
to any otherevent template.
This process, for example, explains theresultative form of surface contact verbs like sweep:(4) a. Phil swept the floor.
[ Phil ACT<SWEEP> floor ]b. Phil swept the floor clean.
[ [ Phil ACT<SWEEP> floor ] CAUSE[ BECOME [ floor <CLEAN> ] ] ]Following this long tradition of research, I propose asyntactically-based event representation specifically de-signed to handle alternations in argument structure.
Fur-thermore, I will show how this theoretical analysis canbe implemented in a feature-driven computational frame-work.
The product is an agenda-driven, chart-basedparser for the Minimalist Program.3 A Decompositional FrameworkA primary advantage of decompositional (non-lexicalist)theories of lexical semantics is the ability to transpar-ently relate morphologically related words?explaining,for example, categorial divergences in terms of differ-ences in event structure.
Consider the adjective flat andthe deadjectival verb flatten:(5) a.
The tire is flat.b.
The tire flattened.Clearly, (5a) is a stative sentence denoting a static situ-ation, while (5b) denotes an inchoative event, i.e., a tran-sition from ?tire is not flat?
to ?tire is flat?.
One mightassign the above two sentence the following logical form:(6) a.
BE(tire, [state flat])b.
ARG?
(tire, e) ?
BECOME(BE([state flat]), e)In Davidsonian terms, dynamic events introduce eventarguments, whereas static situations do not.
In (6b), thesemantic argument that undergoes the change of state(ARG?)
is introduced externally via the event argument.Considering that the only difference between flat.ADJand flatten.V is the suffix -en, it must be the source ofinchoativity and contribute the change of state readingthat distinguishes the verb from the adjective.
Here, wehave evidence that derivational affixes affect the seman-tic representation of lexical items, that is, fragments ofevent structure are directly associated with derivationalmorphemes.
We have the following situation:(7) JflatK = [state flat]Jis flatK = ?xBE(x, [state flat])J-enK = ?s?xARG?
(x, e) ?
BECOME(BE(s), e)Jflat-enK = ?x.ARG?
(x, e)?BECOME(BE([state flat]), e)In this case, the complete event structure of a wordcan be compositionally derived from its component mor-phemes.
This framework, where the ?semantic load?
isspread more evenly throughout the lexicon to lexical cat-egories not typically thought to bear semantic content, isessentially the model advocated by Pustejovsky (1991a),among many others.
Note that such an approach is nolonger lexicalist: each lexical item does not fully encodeits associated syntactic and semantic structures.
Rather,meanings are composed from component morphemes.In addition to -en, other productive derivational suf-fixes in English such as -er, -ize, -ion, just to name afew, can be analyzed in a similar way.
In fact, we mayview morphological rules for composing morphemes intolarger phonological units the same way we view syntac-tic rules for combining constituents into higher-level pro-jections, i.e., why distinguish VP ?
V + NP from V?
Adj + -en?
With this arbitrary distinction erased, weare left with a unified morpho-syntactic framework forintegrating levels of grammar previously thought to beseparate?this is indeed one of the major goals of Dis-tributed Morphology.
This theoretical framework trans-lates into a computational model better suited for analyz-ing the semantics of natural language, particularly thoserich in morphology.A conclusion that follows naturally from this analysisis that fragments of event structure are directly encodedin the syntactic structure.
We could, in fact, further pos-tulate that all event structure is encoded syntactically, i.e.,that lexical semantic representation is isomorphic to syn-tactic structure.
Sometimes, these functional elements areovertly realized, e.g., -en.
Often, however, these func-tional elements responsible for licensing event interpre-tations are not phonologically realized.These observations and this line of reasoning has notescaped the attention of theoretical linguists: Hale andKeyser (1993) propose that argument structure is, in fact,encoded syntactically.
They describe a cascading verbphrase analysis with multiple phonetically empty verbalprojections corresponding to concepts such as inchoativ-ity and agentivity.
This present framework builds on thework of Hale and Keyser, but in addition to advancing amore refined theory of verbal argument structure, I alsodescribe a computational implementation.4 Event TypesAlthough the study of event types can be traced backto Aristotle, it wasn?t until the twentieth century whenphilosophers and linguists developed classifications ofevents that capture logical entailments and the co-occurrence restrictions between verbs and other syntacticelements such as tenses and adverbials.
Vendler?s (1957)four-way classification of events into states, activities, ac-complishments, and achievements serves as a good start-ing point for a computational ontology of event types.Examples of the four event types are given below:(8)States Activitiesknow runbelieve walkAccomplishments Achievementspaint a picture recognizemake a chair findUnder Vendler?s classification, activities and statesboth depict situations that are inherently temporally un-bounded (atelic); states denote static situations, whereasactivities denote on-going dynamic situations.
Accom-plishments and achievements both express a change ofstate, and hence are temporally bounded (telic); achieve-ments are punctual, whereas accomplishments extendover a period of time.
Tenny (1987) observes that ac-complishments differ from achievements only in terms ofevent duration, which is often a question of granularity.From typological studies, it appears that states, changeof states, and activities form the most basic ontology ofevent types.
They correspond to the primitives BE, BE-COME, and DO proposed by a variety of linguists; let usadopt these conceptual primitives as the basic vocabularyof our lexical semantic representation.Following the non-lexicalist tradition, these primitivesare argued to occupy functional projections in the syntac-tic structure, as so-called light verbs.
Here, I adopt themodel proposed by Marantz (1997) and decompose lexi-cal verbs into verbalizing heads and verbal roots.
Verbal-izing heads introduce relevant eventive interpretations inthe syntax, and correspond to (assumed) universal primi-tives of the human cognitive system.
On the other hand,verbal roots represent abstract (categoryless) conceptsand basically correspond to open-class items drawn fromencyclopedic knowledge.
I assume an inventory of threeverbalizing heads, each corresponding to an aforemen-tioned primitive:(9) vDO [+dynamic, ?inchoative] = DOv?
[+dynamic, +inchoative] = BECOMEvBE [?dynamic] = BEThe light verb vDO licenses an atelic non-inchoativeevent, and is compatible with verbal roots expressing ac-tivity.
It projects a functional head, voice (Kratzer, 1994),whose specifier is the external argument.
(10) John ran.voicePDPJohnvoice vDOPvDO?runARGext(John, e) ?
DO([activity run], e)The entire voiceP is further embedded under a tenseprojection (not shown here), and the verbal complex un-dergoes head movement and left adjoins to any overttense markings.
Similarly, the external argument raises to[Spec, TP].
This is in accordance with modern linguistictheory, more specifically, the subject-internal hypothesis.The verbal root can itself idiosyncratically license aDP to give rise to a transitive sentence (subjected, nat-urally, to selectional restrictions).
These constructionscorrespond to what Levin calls ?non-core transitive sen-tences?
(1999):(11) John ran the marathon.voicePDPJohn voice vDOPvDO?Prun DPthe marathonARGext(John, e) ?
DO([activity run(marathon)], e)Similarly, vBE licenses static situations, and is compat-ible with verbal roots expressing state:(12) Mary is tall.vBEPDPMaryvBEis?tallBE(Mary, [state tall])The light verb v?
licenses telic inchoative events (i.e.,change of states), which correspond to the BECOMEprimitive:(13) The window broke:v?PDPwindowv?vBE?breakARG?
(window, e) ?
BECOME(BE([state break]), e)The structure denotes an event where an entity under-goes a change of state to the end state specified by theroot.
v?P can be optionally embedded as the complementof a vDO, accounting for the causative/inchoative alterna-tion.
Cyclic head movement (incorporation) of the verbalroots into the verbalizing heads up to the highest verbalprojection accounts for the surface form of the sentence.
(14) John broke the window.voicePDPJohn voice vDOPvDO v?PDPwindowv?vBE?breakCAUSE(e1, e2) ?
ARGext(John, e1) ?DO([activity undef], e1) ?
ARG?
(window, e2) ?BECOME(BE([state break]), e2)Note that in the causative form, vDO is unmodified bya verbal root?the manner of activity is left unspecified,i.e., ?John did something that caused the window to un-dergo the change of state break.
?Given this framework, deadjectival verbs such as flat-ten can be directly derived in the syntax:(15) The tire flattened.v?PDPtirev?-envBEPvBE?flatARG?
(tire, e) ?
BECOME(BE([state flat]), e)In (Lin, 2004), I present evidence from Mandarin Chi-nese that this analysis is on the right track.
The rest ofthis paper, however, will be concerned with the computa-tional implementation of my theoretical framework.5 Minimalist DerivationsMy theory of verbal argument structure can be imple-mented in a unified morpho-syntactic parsing modelthat interleaves syntactic and semantic parsing.
Thesystem is in the form of an agenda-driven chart-basedparser whose foundation is similar to previous formaliza-tions of Chomsky?s Minimalist Program (Stabler, 1997;Harkema, 2000; Niyogi, 2001).Lexical entries in the system are minimally specified,each consisting of a phonetic form, a list of relevant fea-tures, and semantics in the form of a ?
expression.The basic structure building operation, MERGE, takestwo items and creates a larger item.
In the process,compatible features are canceled and one of the itemsprojects.
Simultaneously, the ?
expression associatedwith the licensor is applied to the ?
expression associatedwith the licensee (in theoretical linguistic terms, Spell-Out).The most basic feature is the =x licensor feature,which cancels out a corresponding x licensee feature andprojects.
A simple example is a determiner selecting anoun to form a determiner phrase (akin to the context freerule DP ?
det noun).
This is shown below (underline in-dicates canceled features, and the node label < indicatesthat the left item projects):(16) <the:::=n d -kshelf:nThe features >x and <x trigger head movement (in-corporation), i.e., the phonetic content of the licensee isaffixed to the left or right of the licensor?s phonetic con-tent, respectively.
These licensor features also cancel cor-responding x licensee features:(17) <book -s:::>n d -kbook:n<de- bone::<n Vbone:nFinally, feature checking is implemented by +x/-x fea-tures.
The +x denotes a need to discharge features, andthe -x denotes a need for features.
A simple example ofthis is the case assignment involved in building a preposi-tional phrase, i.e., prepositions must assign case, and DPsmuch receive case.
(18) <on:::=d:::+k ploc<the:::=n:d ::-kshelf:nNiyogi (2001) has developed an agenda-driven chartparser for the feature-driven formalism described above;please refer to his paper for a description of the parsingalgorithm.
I have adapted it for my needs and developedgrammar fragments that reflect my non-lexicalist seman-tic framework.
As an example, a simplified derivation ofthe sentence ?The tire flattened.?
is shown in Figure 1.The currently implemented system is still at the ?toyparser?
stage.
Although the effectiveness and coverage<//::>s vbe?x.BE(x)/flat/:s[state flat]</flat -en/::::>be =d?x.?y.ARG?
(y, e)?BECOME(x, e)<::>s :::vbeBE([state flat]):s>/the tire/::dtire</flat -en/::::>be ::=d?y.ARG?
(y, e)?BECOME(BE([state tall]), e)<:::>s::::vbe :sARG?
(he, e) ?
BECOME(BE([state tall(3cm)]), e)Figure 1: Simplified derivation for the sentence ?The tireflattened.
?of my parser remains to be seen, similar approaches havebeen successful at capturing complex linguistic phenom-ena.
With a minimal set of features and a small num-ber of lexical entries, Niyogi (2001) has successfullymodeled many of the argument alternations described byLevin (1993) using a Hale and Keyser (1993) style anal-ysis.
I believe that with a suitable lexicon (either handcrafted or automatically induced), my framework can beelaborated into a system whose performance is compara-ble to that of current statistical parsers, but with the addedadvantage of simultaneously providing a richer lexical se-mantic representation of the input sentence than flat pred-icate argument structures based on semantic roles.6 ConclusionA combination of factors in the natural development ofcomputational linguistics as a field has conspired to nar-row the diversity of techniques being explored by re-searchers.
While empirical and quantitative research isthe mark of a mature field, such an approach is not with-out its adverse side-effects.
Both syntactic and semanticparsing technology faces a classic chicken-and-egg prob-lem.
In order for any new framework to become widelyadopted, it must prove to be competitive with state-of-the-art systems in terms of performance.
However, ro-bust parsing cannot be achieved without either labori-ously crafting grammars or a massive dedicated annota-tion effort (and experience has shown the latter methodto be superior).
Therein, however, lies the catch: neithereffort is likely to be undertaken unless a new frameworkproves to be quantitatively superior than previously es-tablished methodologies.
Lacking quantitative measurescurrently, the merits of my proposed framework can onlybe gauged on theoretical grounds and its future potentialto better capture a variety of linguistic phenomena.ReferencesCollin F. Baker, Charles J. Fillmore, and John B. Lowe.1998.
The Berkeley FrameNet project.
In Proceedingsof the 36th Annual Meeting of the Association for Com-putational Linguistics and 17th International Con-ference on Computational Linguistics (COLING/ACL1998).Eugene Charniak.
2001.
Immediate head parsing forlanguage models.
In Proceedings of the 39th AnnualMeeting of the Association for Computational Linguis-tics (ACL-2001).Michael Collins.
1997.
Three generative lexicalizedmodels for statistical parsing.
In Proceedings of the35th Annual Meeting of the Association for Computa-tional Linguistics (ACL-1997).David Dowty.
1979.
Word Meaning and MontagueGrammar.
D. Reidel Publishing Company, Dordrecht,The Netherlands.Charles J. Fillmore.
1968.
The case for case.
In E. Bachand R. Harms, editors, Universals in Linguistic The-ory, pages 1?88.
Holt, Rinehart, and Winston, NewYork.Kenneth Hale and Samuel Jay Keyser.
1993.
On argu-ment structure and the lexical expression of syntacticrelations.
In Kenneth Hale and Samuel Jay Keyser,editors, The View from Building 20: Essays in Linguis-tics in Honor of Sylvain Bromberger.
MIT Press, Cam-bridge, Massachusetts.Morris Halle and Alec Marantz.
1993.
Distributed mor-phology and the pieces of inflection.
In Kenneth Haleand S. Jay Keyser, editors, In The View from Build-ing 20, pages 111?176.
MIT Press, Cambridge, Mas-sachusetts.Henk Harkema.
2000.
A recognizer for minimalistgrammars.
In Proceedings of the Sixth InternationalWorkshop on Parsing Technologies (IWPT 2000).Ray Jackendoff.
1983.
Semantics and Cognition.
MITPress, Cambridge, Massachusetts.Paul Kingsbury, Martha Palmer, and Mitch Marcus.2002.
Adding semantic annotation to the Penn Tree-Bank.
In Proceeding of 2002 Human Language Tech-nology Conference (HLT 2002).Angelika Kratzer.
1994.
The event argument and the se-mantics of voice.
Unpublished manuscript, Universityof Massachusetts, Amherst.Beth Levin and Malka Rappaport Hovav.
1996.
Fromlexical semantics to argument realization.
Unpub-lished manuscript, Northwestern University and BarIlan University.Beth Levin.
1993.
English Verb Classes and Alter-nations: A Preliminary Investigation.
University ofChicago Press, Chicago, Illinois.Beth Levin.
1999.
Objecthood: An event structure per-spective.
In Proceedings of the 35th Annual Meetingof the Chicago Linguistics Society.Jimmy Lin.
2004.
Event Structure and the Encoding ofArguments: The Syntax of the English and MandarinVerb Phrase.
Ph.D. thesis, Department of ElectricalEngineering and Computer Science, Massachusetts In-stitute of Technology.Alec Marantz.
1997.
No escape from syntax: Don?t trymorphological analysis in the privacy of your own lex-icon.
In Proceedings of the 21st Annual Penn Linguis-tics Colloquium.Sourabh Niyogi.
2001.
A minimalist implementationof verb subcategorization.
In Proceedings of the Sev-enth International Workshop on Parsing Technologies(IWPT-2001).James Pustejovsky.
1991a.
The generative lexicon.Computational Linguistics, 17(4):409?441.James Pustejovsky.
1991b.
The syntax of event structure.Cognition, 41:47?81.Malka Rappaport Hovav and Beth Levin.
1998.
Buildingverb meanings.
In Miriam Butt and Wilhelm Geuder,editors, The Projection of Arguments: Lexical andCompositional Factors.
CSLI Publications, Stanford,California.Edward Stabler.
1997.
Derivational minimalism.
InChristian Retore?, editor, Logical Aspects of Computa-tional Linguistics.
Springer.Carol Tenny.
1987.
Grammaticalizing Aspect and Affect-edness.
Ph.D. thesis, Massachusetts Institute of Tech-nology.Zeno Vendler.
1957.
Verbs and times.
PhilosophicalReview, 56:143?160.
