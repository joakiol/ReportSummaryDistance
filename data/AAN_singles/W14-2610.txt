Proceedings of the 5th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, pages 59?65,Baltimore, Maryland, USA.
June 27, 2014.c?2014 Association for Computational LinguisticsEmotive or Non-emotive: That is The QuestionMichal Ptaszynski Fumito MasuiDepartment of Computer Science,Kitami Institute of Technology{ptaszynski,f-masui}@cs.kitami-it.ac.jpRafal Rzepka Kenji ArakiGraduate School of Information Scienceand Technology, Hokkaido University{rzepka,araki}@ist.hokudai.ac.jpAbstractIn this research we focus on discriminat-ing between emotive (emotionally loaded)and non-emotive sentences.
We define theproblem from a linguistic point of view as-suming that emotive sentences stand outboth lexically and grammatically.
Weverify this assumption experimentally bycomparing two sets of such sentences inJapanese.
The comparison is based onwords, longer n-grams as well as more so-phisticated patterns.
In the classificationwe use a novel unsupervised learning algo-rithm based on the idea of language com-binatorics.
The method reached resultscomparable to the state of the art, whilethe fact that it is fully automatic makes itmore efficient and language independent.1 IntroductionRecently the field of sentiment analysis has at-tracted great interest.
It has become popular totry different methods to distinguish between sen-tences loaded with positive and negative senti-ments.
However, a few research focused on a taskmore generic, namely, discriminating whether asentence is even loaded with emotional content ornot.
The difficulty of the task is indicated by threefacts.
Firstly, the task has not been widely un-dertaken.
Secondly, in research which addressesthe challenge, the definition of the task is usuallybased on subjective ad hoc assumptions.
Thirdly,in research which do tackle the problem in a sys-tematic way, the results are usually unsatisfactory,and satisfactory results can be obtained only withlarge workload.We decided to tackle the problem in a standard-ized and systematic way.
We defined emotionallyloaded sentences as those which in linguistics aredescribed as fulfilling the emotive function of lan-guage.
We assumed that there are repetitive pat-terns which appear uniquely in emotive sentences.We performed experiments using a novel unsu-pervised clustering algorithm based on the ideaof language combinatorics.
By using this methodwe were also able to minimize human effort andachieve F-score comparable to the state of the artwith much higher Recall rate.The outline of the paper is as follows.
Wepresent the background for this research in Section2.
Section 3 describes the language combinatoricsapproach which we used to compare emotive andnon-emotive sentences.
In section 4 we describeour dataset and experiment settings.
The results ofthe experiment are presented in Section 5.
Finallythe paper is concluded in Section 6.2 BackgroundThere are different linguistic means used to in-form interlocutors of emotional states in an ev-eryday communication.
The emotive meaning isconveyed verbally and lexically through exclama-tions (Beijer, 2002; Ono, 2002), hypocoristics (en-dearments) (Kamei et al., 1996), vulgarities (Crys-tal, 1989) or, for example in Japanese, throughmimetic expressions (gitaigo) (Baba, 2003).
Thefunction of language realized by such elements oflanguage conveying emotive meaning is called theemotive function of language.
It was first distin-guished by B?uhler (1934-1990) in his Sprachthe-orie as one of three basic functions of language1.B?uhler?s theory was picked up later by Jakobson(1960), who by distinguishing three other func-tions laid the grounds for structural linguistics andcommunication studies.2.1 Previous ResearchDetecting whether sentences are loaded with emo-tional content has been undertaken by a number1The other two being descriptive and impressive.59of researchers, most often as an additional taskin either sentiment analysis (SA) or affect analy-sis (AA).
SA, in great simplification, focuses ondetermining whether a language entity (sentence,document) was written with positive or negativeattitude toward its topic.
AA on the other handfocuses on specifying which exactly emotion type(joy, anger, etc.)
has been conveyed.
The fact,that the task was usually undertaken as a subtask,influences the way it was formulated.
Below wepresent some of the most influential works on thetopic, but formulating it in slightly different terms.Emotional vs.
Neutral: Discriminating whe-ther a sentence is emotional or neutral is to answerthe question of whether it can be interpreted asproduced in an emotional state.
This way the taskwas studied byMinato et al.
(2006), Aman and Sz-pakowicz (2007) or Neviarouskaya et al.
(2011).Subjective vs.
Objective: Discriminating be-tween subjective and objective sentences is tosay whether the speaker presented the sentencecontents from a first-person-centric perspective orfrom no specific perspective.
The research formu-lating the problem this way include e.g, Wiebe etal.
(1999), who classified subjectivity of sentencesusing naive Bayes classifier, or later Wilson andWiebe (2005).
In other research Yu and Hatzi-vassiloglou (2003) used supervised learning to de-tect subjectivity and Hatzivassiloglou and Wiebe(2012) studied the effect of gradable adjectives onsentence subjectivity.Emotive vs. Non-emotive: Saying that a sen-tence is emotive means to specify the linguisticfeatures of language which where used to producea sentence uttered with emphasis.
Research thatformulated and tackled the problem this way wasdone by, e.g., Ptaszynski et al.
(2009).Each of the above nomenclature implies sim-ilar, though slightly different assumptions.
Forexample, a sentence produced without any emo-tive characteristics (non-emotive) could still im-ply emotional state in some situations.
Also Bingand Zhang (2012) notice that ?not all subjectivesentences express opinions and those that do area subgroup of opinionated sentences.?
A compari-son of the scopes and overlaps of different nomen-clature is represented in Figure 1.
In this researchwe formulate the problem similarly to Ptaszynskiet al.
(2009), therefore we used their system tocompare with our method.Figure 1: Comparison of between differentnomenclature used in sentiment analysis research.3 Language CombinatoricsThe idea of language combinatorics (LC) assumesthat patterns with disjoint elements provide bet-ter results than the usual bag-of-words or n-gramapproach (Ptaszynski et al., 2011).
Such patternsare defined as ordered non-repeated combinationsof sentence elements.
They are automatically ex-tracted by generating all ordered combinations ofsentence elements and verifying their occurrenceswithin a corpus.In particular, in every n-element sentence thereis k-number of combination clusters, such as that1 ?
k ?
n, where k represents all k-element com-binations being a subset of n. The number of com-binations generated for one k-element cluster ofcombinations is equal to binomial coefficient, likein eq.
1.
Thus the number of all possible combina-tions generated for all values of k from the rangeof {1, ..., n} is equal to the sum of all combina-tions from all k-element clusters, like in eq.
2.(nk)=n!k!(n?
k)!(1)n?k=1(nk)=n!1!(n?
1)!+n!2!(n?
2)!+ ...
+n!n!(n?
n)!= 2n?
1(2)One problem with combinatorial approach is thephenomenon of exponential and rapid growth offunction values during combinatorial manipula-tions, called combinatorial explosion (Krippen-dorff, 1986).
Since this phenomenon causes longprocessing time, combinatorial approaches havebeen often disregarded.
We assumed however,that it could be dealt with when the algorithmis optimized to the requirements of the task.
Inpreliminary experiments Ptaszynski et al.
(2011)used a generic sentence pattern extraction archi-tecture SPEC to compare the amounts of generatedsophisticated patterns with n-grams, and noticedthat it is not necessary to generate patterns of alllengths, since the most useful ones usually appearin the group of 2 to 5 element patterns.
Follow-ing their experience we limit the pattern length inour research to 6 elements.
All non-subsequent el-60Table 1: Some examples from the dataset representing emotive and non-emotive sentences close incontent, but differing in emotional load expressed in the sentence (Romanized Japanese / Translation).emotive non-emotiveTakasugiru kara ne / ?Cause its just too expensive K?ogaku na tame desu.
/ Due to high cost.Un, umai, kangeki da.
/ Oh, so delicious, I?m impressed.
Kono kar?e wa karai.
/ This curry is hot.Nanto ano hito, kekkon suru rashii yo!
/ Have you heard?
She?s getting married!
Ano hito ga kekkon suru rashii desu.
/ They say she is gatting married.Ch?o ha ga itee / Oh, how my tooth aches!
Ha ga itai / A tooth achesSugoku kirei na umi da naaa / Oh, what a beautiful sea!
Kirei na umi desu / This is a beautiful seaements are also separated with an asterisk (?*?)
tomark disjoint elements.The weight wjof each pattern generated thisway is calculated, according to equation 3, as aratio of all occurrences of a pattern in one corpusOposto the sum of occurrences in two comparedcorporaOpos+Oneg.
The weights are also normal-ized to fit in range from +1 (representing purelyemotive patterns) to -1 (representing purely non-emotive patterns).
The normalization is achievedby subtracting 0.5 from the initial score and mul-tiplying this intermediate product by 2.
The scoreof one sentence is calculated as a sum of weightsof patterns found in the sentence, like in eq.
4.wj=(OposOpos+ Oneg?
0.5)?
2 (3)score =?wj, (1 ?
wj?
?1) (4)The weight can be further modified by either?
awarding length k, or?
awarding length k and occurrence O.The list of generated frequent patterns can also befurther modified.
When two collections of sen-tences of opposite features (such as ?emotive vs.non-emotive?)
are compared, a generated list willcontain patterns appearing uniquely on only oneof the sides (e.g.
uniquely emotive patterns anduniquely non-emotive patterns) or in both (am-biguous patterns).
Therefore the pattern list canbe modified by deleting?
all ambiguous patterns, or?
only ambiguous patterns appearing in the samenumber on both sides (later called ?zero pat-terns?, since their weight is equal 0).Moreover, since a list of patterns will contain boththe sophisticated patterns as well usual n-grams,the experiments were performed separately for allpatterns and n-grams only.
Also, if the initial col-lection was biased toward one of the sides (sen-tences of one kind were longer or more numer-ous), there will be more patterns of a certain sort.To mitigate this bias, instead of applying a rule ofthumb, the threshold was optimized automatically.4 Experiments4.1 Dataset PreparationIn the experiments we used a dataset developed byPtaszynski et al.
(2009) for the needs of evaluatingtheir affect analysis system ML-Ask for Japaneselanguage.
The dataset contains 50 emotive and 41non-emotive sentences.
It was created as follows.Thirty people of different age and social groupsparticipated in an anonymous survey.
Each partic-ipant was to imagine or remember a conversationwith any person they know and write three sen-tences from that conversation: one free, one emo-tive, and one non-emotive.
Additionally, the par-ticipants were asked to make the emotive and non-emotive sentences as close in content as possible,so the only difference was whether a sentence wasloaded with emotion or not.
The participants alsoannotated on their own free utterances whether ornot they were emotive.
Some examples from thedataset are represented in Table 1.In our research the above dataset was furtherpreprocessed to make the sentences separable intoelements.
We did this in three ways to check howthe preprocessing influences the results.
We usedMeCab2, a morphological analyzer for Japaneseto preprocess the sentences from the dataset in thethree following ways:?
Tokenization: All words, punctuation marks,etc.
are separated by spaces.?
Parts of speech (POS): Words are replacedwith their representative parts of speech.?
Tokens with POS: Both words and POS infor-mation is included in one element.The examples of preprocessing are representedin Table 2.
In theory, the more generalized a sen-tence is, the less unique patterns it will produce,but the produced patterns will be more frequent.This can be explained by comparing tokenizedsentence with its POS representation.
For exam-ple, in the sentence from Table 2 we can see thata simple phrase kimochi ii (?feeling good?)
can be2https://code.google.com/p/mecab/61Table 2: Three kinds of preprocessing of a sen-tence in Japanese; N = noun, TOP = topic marker,ADV = adverbial particle, ADJ = adjective, COP= copula, EXCL = exclamation mark.Sentence:Transliteration: Ky?owanantekimochiiihinanda!Glossing: Today TOP what pleasant day COP EXCLTranslation: What a pleasant day it is today!Preprocessing examples1.
Words: Ky?o wa nante kimochi ii hi nanda !2.
POS: N TOP ADV N ADJ N COP EXCL3.Words+POS: Ky?o[N] wa[TOP] nante[ADV]kimochi[N] ii[ADJ] hi[N] nanda[COP] !
[EXCL]represented by a POS pattern N ADJ.
We can eas-ily assume that there will be more N ADJ patternsthan kimochi ii, because many word combinationscan be represented as N ADJ.
Therefore POS pat-terns will come in less variety but with higher oc-currence frequency.
By comparing the result ofclassification using different preprocessing meth-ods we can find out whether it is better to representsentences as more generalized or as more specific.4.2 Experiment SetupThe experiment was performed three times, oncefor each kind of preprocessing.
Each time 10-fold cross validation was performed and the resultswere calculated using Precision (P), Recall (R)and balanced F-score (F) for each threshold.
Weverified which version of the algorithm achievesthe top score within the threshold span.
However,an algorithm could achieve the best score for onecertain threshold, while for others it could performpoorly.
Therefore we also looked at which ver-sion achieves high scores for the longest thresholdspan.
This shows which algorithm is more bal-anced.
Finally, we checked the statistical signifi-cance of the results.
We used paired t-test becausethe classification results could represent only oneof two classes (emotive or non-emotive).
We alsocompared the performance to the state of the art,namely the affect analysis system ML-Ask devel-oped by Ptaszynski et al.
(2009).5 Results and DiscussionThe overall F-score results were generally the bestfor the datasets containing in order: both tokensand POS, tokens only and POS only.
The F-scores for POS-preprocessed sentences revealedthe least constancy.
For many cases n-gramsscored higher than all patterns, but almost none ofTable 3: Best results for each version of themethod compared with the ML-Ask system.ML-AskSPECtokenized POS token-POSn-grams patterns n-grams patterns n-grams patternsPrecision 0.80 0.61 0.6 0.68 0.59 0.65 0.64Recall 0.78 1.00 0.96 0.88 1.00 0.95 0.95F-score 0.79 0.75 0.74 0.77 0.74 0.77 0.76the results reached statistical significance.
The F-score results for the tokenized dataset were alsonot unequivocal.
For higher thresholds patternsscored higher, while for lower thresholds the re-sults were similar.
The scores were rarely sig-nificant, utmost at 5% level (p<0.05), however,in all situations where n-grams visibly scoredhigher, the differences were not statistically sig-nificant.
Finally, for the preprocessing includingboth tokens and POS information, pattern-basedapproach achieved significantly better results (p-value <0.01 or <0.001).
The algorithm reachedits plateau at F-score around 0.73?0.74 for to-kens and POS separately, and 0.75?0.76 for to-kens with POS together.
In the POS dataset theelements were more abstracted, while in token-POS dataset the elements were more specific, pro-ducing a larger number, but less frequent patterns.Lower scores for POS dataset could suggest thatthe algorithm works better with less abstractedpreprocessing.
Examples of F-score comparisonbetween n-grams and patterns for tokenized andtoken-POS datasets are represented in Figures 2and 3, respectively.Results for Precision showed similar tenden-cies.
They were the most ambiguous for POS pre-processing.
For the tokenized dataset, althoughthere always was one or two thresholds for whichn-grams scored higher, scores for patterns weremore balanced, starting with a high score and de-creasing slowly.
As for the token-POS preprocess-ing patterns achieved higher Precision for most ofthe threshold span.
The highest Precision of allwas achieved in this dataset by patterns with P =0.87 for R = 0.50.As for Recall, the scores were consistent forall kinds of preprocessing, with higher scores forpatterns within most of the threshold span andequaling while the threshold decreases.
The high-est scores achieved for each preprocessing for n-grams and patterns are represented in Table 3.The affect analysis system ML-Ask (Ptaszynskiet al., 2009) on the same dataset reached F = 0.79,P = 0.8 and R = 0.78.
The results were generally62comparable, however slightly higher for ML-Askwhen it comes to P and F-score.
R was always bet-ter for the proposed method.
However, ML-Ask isa system requiring handcrafted lexicons, while ourmethod is fully automatic, learning the patternsfrom data, not needing any particular preparations,which makes it more efficient.5.1 Detailed Analysis of Learned PatternsWithin some of the most frequently appearingemotive patterns there were for example: !
(exclamation mark), n*yo, cha (emotive verbmodification), yo (exclamative sentence endingparticle), ga*yo, n*!
or naa (interjection).
Someexamples of sentences containing those patternsare below (patterns underlined).
Interestingly,most elements of those patterns appear in ML-Askhandcrafted databases, which suggests it couldbe possible to improve ML-Ask performance byextracting additional patterns with SPEC.Ex.
1.
Megane, soko ni atta nda yo.
(The glasseswere over there!)Ex.
2.
Uuun, butai ga mienai yo.
(Ohh, I cannotsee the stage!)Ex.
3.
Aaa, onaka ga suita yo.
(Ohh, I?m sohungry)Another advantage of our method is the fact thatit can mark both emotive and non-emotive ele-ments in sentence, while ML-Ask is designed toannotate only emotive elements.
Some examplesof extracted non-emotive patterns were for exam-ple: desu, wa*desu, mashi ta, or te*masu.
All ofthem were patterns described in linguistic litera-ture as typically non-emotive, consisting in copu-las (desu), verb endings (masu, mashi ta).
Somesentence examples with those patterns include:00.10.20.30.40.50.60.70.8-1-0.8-0.6-0.4-0.2 0 0.2 0.4 0.6 0.8 1scorethresholdF-scoreall_patternsngramsFigure 2: F-score comparison between n-gramsand patterns for tokenized detaset (p = 0.0209).Ex.
4.
K?ogaku na tame desu.
(Due to high cost.)Ex.
5.
Kirei na umi desu (This is a beautiful sea)Ex.
6.
Kyo wa yuki ga futte imasu.
(It is snowingtoday.
)6 Conclusions and Future WorkWe presented a method for automatic extractionof patterns from emotive sentences.
We assumedemotive sentences are distinguishable both lex-ically and grammatically and performed experi-ments to verify this assumption.
In the experi-ments we used a set of emotive and non-emotivesentences preprocessed in different ways (tokens,POS, token-POS) The patterns extracted fromsentences were applied to recognize emotionallyloaded sentences.The algorithm reached its plateau for F-scorearound 0.75?0.76 for patterns containing both to-kens and POS information.
Precision for patternswas balanced, while for n-grams, although occa-sionally achieving high scores, it was quickly de-creasing.
Recall scores were almost always betterfor patterns.
The generally lower results for POS-represented sentences suggest that the algorithmworks better with less abstracted elements.The results of the proposed method and the af-fect analysis system ML-Ask were comparable.ML-Ask achieved better Precision, but lower Re-call.
However, our method is more efficient asit does not require handcrafted lexicons.
More-over, automatically extracted patterns overlap withhandcrafted databases of ML-Ask, which suggestsit could be possible to improve ML-Ask perfor-mance with our method.
In the near future we planto perform experiments on larger datasets, also inother languages, such as English or Chinese.00.10.20.30.40.50.60.70.8-1-0.8-0.6-0.4-0.2 0 0.2 0.4 0.6 0.8 1scorethresholdF-scoreall_patternsngramsFigure 3: F-score comparison for n-grams and pat-terns for dataset with tokens and POS (p = 0.001).63ReferencesSaima Aman and Stan Szpakowicz.
2007.
Iden-tifying expressions of emotion in text.
In Pro-ceedings of the 10th International Conferenceon Text, Speech, and Dialogue (TSD-2007),Lecture Notes in Computer Science (LNCS),Springer-Verlag.Junko Baba.
2003.
Pragmatic function of Japanesemimetics in the spoken discourse of varyingemotive intensity levels.
Journal of Pragmatics,Vol.
35, No.
12, pp.
1861-1889, Elsevier.Fabian Beijer.
2002.
The syntax and pragmaticsof exclamations and other expressive/emotionalutterances.
Working Papers in Linguistics 2,The Dept.
of English in Lund.Bing Liu, Lei Zhang.
2012.
A survey of opinionmining and sentiment analysis.
In Mining TextData, pp.
415-463.
Springer.Karl B?uhler.
1990.
Theory of Language.
Represen-tational Function of Language.
John BenjaminsPubl.
(reprint from Karl B?uhler.
Sprachtheorie.Die Darstellungsfunktion der Sprache, Ullstein,Frankfurt a. M., Berlin, Wien, 1934.
)David Crystal.
1989.
The Cambridge Encyclope-dia of Language.
Cambridge University Press.Vasileios Hatzivassiloglou and Janice Wiebe.
Ef-fects of adjective orientation and gradability onsentence subjectivity.
In Proceedings of Inter-national Conference on Computational Linguis-tics (COLING-2000), pp.
299-305, 2000.Roman Jakobson.
1960.
Closing Statement: Lin-guistics and Poetics.
Style in Language, pp.350-377, The MIT Press.Takashi Kamei, Rokuro Kouno and Eiichi Chino(eds.).
1996.
The Sanseido Encyclopedia of Lin-guistics, Vol.
VI, Sanseido.Klaus Krippendorff.
1986.
Combinatorial Explo-sion, In: Web Dictionary of Cybernetics andSystems.
Princia Cybernetica Web.Junko Minato, David B. Bracewell, Fuji Ren andShingo Kuroiwa.
2006.
Statistical Analysis of aJapanese Emotion Corpus for Natural LanguageProcessing.
LNCS 4114, pp.
924-929.Alena Neviarouskaya, Helmut Prendinger andMitsuru Ishizuka.
2011.
Affect analysis model:novel rule-based approach to affect sensingfrom text.
Natural Language Engineering, Vol.17, No.
1 (2011), pp.
95-135.Hajime Ono.
2002.
An emphatic particle DA andexclamatory sentences in Japanese.
Universityof California, Irvine.Christopher Potts and Florian Schwarz.
2008.
Ex-clamatives and heightened emotion: Extractingpragmatic generalizations from large corpora.Ms., UMass Amherst.Michal Ptaszynski, Pawel Dybala, Rafal Rzepkaand Kenji Araki.
2009.
Affecting Corpora: Ex-periments with Automatic Affect AnnotationSystem - A Case Study of the 2channel Forum-, In Proceedings of The Conference of the Pa-cific Association for Computational Linguistics(PACLING-09), pp.
223-228.Michal Ptaszynski, Rafal Rzepka, Kenji Araki andYoshio Momouchi.
2011.
Language combina-torics: A sentence pattern extraction architec-ture based on combinatorial explosion.
Inter-national Journal of Computational Linguistics(IJCL), Vol.
2, Issue 1, pp.
24-36.Kaori Sasai.
2006.
The Structure of ModernJapanese Exclamatory Sentences: On the Struc-ture of the Nanto-Type Sentence.
Studies in theJapanese Language, Vol, 2, No.
1, pp.
16-31.Janyce M. Wiebe, Rebecca F. Bruce and ThomasP.
O?Hara.
1999.
Development and use of agold-standard data set for subjectivity classi-fications.
In Proceedings of the Associationfor Computational Linguistics (ACL-1999), pp.246-253, 1999.Theresa Wilson and Janyce Wiebe.
2005.
Anno-tating Attributions and Private States.
Proceed-ings of the ACL Workshop on Frontiers in Cor-pus Annotation II, pp.
53-60.Hong Yu and Vasileios Hatzivassiloglou.
2003.Towards answering opinion questions: separat-ing facts from opinions and identifying the po-larity of opinion sentences.
In Proceedings ofConference on Empirical Methods in NaturalLanguage Processing (EMNLP-2003), pp.
129-136, 2003.64Appendix: Comparison of experiment results in all experiment settings for all three ways ofdataset preprocessing.00.10.20.30.40.50.60.70.8-1-0.8-0.6-0.4-0.2 0 0.2 0.4 0.6 0.8 1scorethresholdF-scoreall_patternszero_deletedambiguous_deletedlength_awardedlength_awarded_zero_deletedlength_awarded_ambiguous_deletedlength_and_occurrence_awardedngramsngrams_zero_deletedngrams_ambiguous_deletedngrams_length_awardedngrams_length_awarded_zero_deletedngrams_length_awarded_ambiguous_deletedngrams_length_and_occurrence_awarded00.10.20.30.40.50.60.70.80.9-1-0.8-0.6-0.4-0.2 0 0.2 0.4 0.6 0.8 1scorethresholdPrecisionall_patternszero_deletedambiguous_deletedlength_awardedlength_awarded_zero_deletedlength_awarded_ambiguous_deletedlength_and_occurrence_awardedngramsngrams_zero_deletedngrams_ambiguous_deletedngrams_length_awardedngrams_length_awarded_zero_deletedngrams_length_awarded_ambiguous_deletedngrams_length_and_occurrence_awarded00.10.20.30.40.50.60.70.80.91-1-0.8-0.6-0.4-0.2 0 0.2 0.4 0.6 0.8 1scorethresholdRecallall_patternszero_deletedambiguous_deletedlength_awardedlength_awarded_zero_deletedlength_awarded_ambiguous_deletedlength_and_occurrence_awardedngramsngrams_zero_deletedngrams_ambiguous_deletedngrams_length_awardedngrams_length_awarded_zero_deletedngrams_length_awarded_ambiguous_deletedngrams_length_and_occurrence_awarded(a) F-score comparison for tokenizeddataset.
(b) Precision comparison for tok-enized dataset.
(c) Recall comparison for tokenizeddataset.00.10.20.30.40.50.60.70.8-1-0.8-0.6-0.4-0.2 0 0.2 0.4 0.6 0.8 1scorethresholdF-scoreall_patternszero_deletedambiguous_deletedlength_awardedlength_awarded_zero_deletedlength_awarded_ambiguous_deletedlength_and_occurrence_awardedngramsngrams_zero_deletedngrams_ambiguous_deletedngrams_length_awardedngrams_length_awarded_zero_deletedngrams_length_awarded_ambiguous_deletedngrams_length_and_occurrence_awarded00.10.20.30.40.50.60.70.8-1-0.8-0.6-0.4-0.2 0 0.2 0.4 0.6 0.8 1scorethresholdPrecisionall_patternszero_deletedambiguous_deletedlength_awardedlength_awarded_zero_deletedlength_awarded_ambiguous_deletedlength_and_occurrence_awardedngramsngrams_zero_deletedngrams_ambiguous_deletedngrams_length_awardedngrams_length_awarded_zero_deletedngrams_length_awarded_ambiguous_deletedngrams_length_and_occurrence_awarded00.10.20.30.40.50.60.70.80.91-1-0.8-0.6-0.4-0.2 0 0.2 0.4 0.6 0.8 1scorethresholdRecallall_patternszero_deletedambiguous_deletedlength_awardedlength_awarded_zero_deletedlength_awarded_ambiguous_deletedlength_and_occurrence_awardedngramsngrams_zero_deletedngrams_ambiguous_deletedngrams_length_awardedngrams_length_awarded_zero_deletedngrams_length_awarded_ambiguous_deletedngrams_length_and_occurrence_awarded(d) F-score comparison for POS-tagged dataset.
(e) Precision comparison for POS-tagged dataset.
(f) Recall comparison for POS-taggeddataset.00.10.20.30.40.50.60.70.8-1-0.8-0.6-0.4-0.2 0 0.2 0.4 0.6 0.8 1scorethresholdF-scoreall_patternszero_deletedambiguous_deletedlength_awardedlength_awarded_zero_deletedlength_awarded_ambiguous_deletedlength_and_occurrence_awardedngramsngrams_zero_deletedngrams_ambiguous_deletedngrams_length_awardedngrams_length_awarded_zero_deletedngrams_length_awarded_ambiguous_deletedngrams_length_and_occurrence_awarded0.20.30.40.50.60.70.80.9-1-0.8-0.6-0.4-0.2 0 0.2 0.4 0.6 0.8 1scorethresholdPrecisionall_patternszero_deletedambiguous_deletedlength_awardedlength_awarded_zero_deletedlength_awarded_ambiguous_deletedlength_and_occurrence_awardedngramsngrams_zero_deletedngrams_ambiguous_deletedngrams_length_awardedngrams_length_awarded_zero_deletedngrams_length_awarded_ambiguous_deletedngrams_length_and_occurrence_awarded00.10.20.30.40.50.60.70.80.91-1-0.8-0.6-0.4-0.2 0 0.2 0.4 0.6 0.8 1scorethresholdRecallall_patternszero_deletedambiguous_deletedlength_awardedlength_awarded_zero_deletedlength_awarded_ambiguous_deletedlength_and_occurrence_awardedngramsngrams_zero_deletedngrams_ambiguous_deletedngrams_length_awardedngrams_length_awarded_zero_deletedngrams_length_awarded_ambiguous_deletedngrams_length_and_occurrence_awarded(g) F-score comparison for tokenizeddataset with POS tags.
(h) Precision comparison for tok-enized dataset with POS tags.
(i) Recall comparison for tokenizeddataset with POS tags.65
