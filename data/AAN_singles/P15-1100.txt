Proceedings of the 53rd Annual Meeting of the Association for Computational Linguisticsand the 7th International Joint Conference on Natural Language Processing, pages 1035?1044,Beijing, China, July 26-31, 2015.c?2015 Association for Computational LinguisticsSparse, Contextually Informed Models for Irony Detection:Exploiting User Communities, Entities and SentimentByron C. WallaceUniversity of Texas at Austinbyron.wallace@utexas.eduDo Kook Choe and Eugene CharniakBrown University{dc65, ec}@cs.brown.eduAbstractAutomatically detecting verbal irony(roughly, sarcasm) in online content isimportant for many practical applications(e.g., sentiment detection), but it is dif-ficult.
Previous approaches have reliedpredominantly on signal gleaned fromword counts and grammatical cues.
Butsuch approaches fail to exploit the contextin which comments are embedded.
Wethus propose a novel strategy for verbalirony classification that exploits contex-tual features, specifically by combiningnoun phrases and sentiment extractedfrom comments with the forum type(e.g., conservative or liberal) to whichthey were posted.
We show that thisapproach improves verbal irony classifica-tion performance.
Furthermore, becausethis method generates a very large featurespace (and we expect predictive contextualfeatures to be strong but few), we proposea mixed regularization strategy that placesa sparsity-inducing `1penalty on thecontextual feature weights on top of the `2penalty applied to all model coefficients.This increases model sparsity and reducesthe variance of model performance.1 Introduction and MotivationAutomated verbal irony detection is a challengingproblem.1But recognizing when an author has in-tended a statement ironically is practically impor-tant for many text classification tasks (e.g., senti-ment detection).Previous models for irony detection (Tsur etal., 2010; Lukin and Walker, 2013; Riloff et al,1In this paper we will be a bit cavalier in using the terms?verbal irony?
and ?sarcasm?
interchangeably.
We recognizethat the latter is a special type of the former, the definition ofwhich is difficult to pin down precisely.Guys who the fuck cares?!
Leave him alone, there are real problemslike bridge-gate scandal with Chris CristieFigure 1: A reddit comment illustrating contextualizing fea-tures that we propose leveraging to improve classification.Here the highlighted entities (external the comment text it-self) provide contextual signals indicating that the showncomment was intended ironically.
As we shall see, Oba-macare is in general a strong indicator of irony when presentin posts to the conservative subreddit, but less so in posts tothe progressive subreddit.2013) have relied predominantly on features in-trinsic to the texts to be classified.
By contrast,here we propose exploiting contextualizing infor-mation, which is often available for web-basedclassification tasks.
More specifically, we exploitsignal gleaned from the conversational threads towhich comments belong.
Our approach capital-izes on the intuition that members of different usercommunities are likely to be sarcastic about dif-ferent things.
As a proxy for user community,we leverage knowledge of the specific forums towhich comments were posted.
For example, onemay surmise that the statement ?I really am proudof Obama?
is likely to have been intended iron-ically if it was posted to a forum frequented bypolitical conservatives.
But if this same utterancewere posted to a liberal-leaning forum, it is morelikely to have been intended in earnest.
This sortof information is often directly or indirectly avail-able on social media, but previous models have notcapitalized on it.
This is problematic; recent workhas shown that humans require such contextualiz-ing information to infer ironic intent (Wallace et1035al., 2014).As a concrete example, we consider the taskof identifying verbal irony in comments posted toreddit (http://www.reddit.com), a social-news website.
Users post content (e.g., links tonews stories) to reddit, which are then voted on bythe community.
Users may also discuss this con-tent on the website; these are the comments thatwe will work with here.
Reddit comprises manysubreddits, which are user communities centeredaround specific topics of interest.
In this workwe consider comments posted to two pairs of po-larized user communities, or subreddits: (1) pro-gressive and conservative subreddits (comprisingindividuals on the left and right of the US polit-ical spectrum, respectively), and (2) atheism andChristianity subreddits.Our aim is to develop a model that can recog-nize verbal irony in comments posted to such fo-rums, e.g., automatically discern that the user whoposted the comment shown in Figure 1 intendedhis or her comment ironically.
To this end, we pro-pose a strategy that capitalizes on available con-textualizing information, such as interactions be-tween the user community (subreddit) that com-ments were posted to, extracted entities (here weuse noun phrases, or NNPs) and inferred senti-ment.The contributions of this work are summarizedas follows.?
We demonstrate that contextual information,such as inferred user-community (in thiscase, the subreddit) can be crossed with ex-tracted entities and sentiment to improve de-tection of verbal irony.
This improves perfor-mance over baseline models (including thosethat exploit inferred sentiment, but not con-text).?
We introduce a novel composite regular-ization strategy that applies a sparsifying`1penalty to the contextual/sentiment/entityfeature weights in addition to the standardsquared `2penalty to all feature weights.This induces more compact, interpretablemodels that exhibit lower variance.While discerning ironic comments on redditis our immediate task, the proposed approach isgenerally applicable to a wide-range of subjec-tive, web-based text classification tasks.
Indeed,this approach would be useful for any scenario inwhich we expect different groups of individualsproducing content to tend to discuss different en-tities in a way that correlates with the target cate-gorization.
The key is in identifying an availableproxy for user groupings (here we rely on the sub-reddits to which a comment was posted).
Suchinformation is often available (or can be derived)for comments posted to different mediums on theweb: for example on Twitter we know who a userfollows; and on YouTube we know the channels towhich videos belong.2 Exploiting context2.1 Communities and sentimentAs discussed above, a shortcoming with existingmodels for detecting sarcasm/verbal irony on theweb is their failure to capitalize on contextualiz-ing information.
But such information is criticalto discerning irony.
A large body of work on theuse and interpretation of verbal irony supports thissupposition (Grice, 1975; Clark and Gerrig, 1984;Wallace, 2013; Wallace et al, 2014).
Individu-als will be more likely, in general, to use sarcasmwhen discussing specific entities.
Which entitieswill depend in part on the community to whichthe individual belongs.
As a proxy for user com-munity, here we leverage the subreddits to whichcomments were posted.Sentiment may also play an important role.
Ingeneral, verbal irony is almost always used to con-vey negative views via ostensibly positive utter-ances (Sperber and Wilson, 1981).
And recentwork (Riloff et al, 2013) has exploited featuresbased on sentiment to improve irony detection.To summarize: when assuming an ironic voicewe expect that individuals will convey ostensiblypositive sentiment about entities, and that these en-tities will depend on the type of individual in ques-tion.
We propose capitalizing on such informa-tion by introducing features that encode subred-dits, sentiment and noun phrases (NNPs), as wedescribe next.2.2 FeaturesWe leverage the feature sets enumerated in Ta-ble 1.
Subreddits are observed variables.
Nounphrase (NNP) extraction and sentiment inferenceare performed automatically via state of the artNLP tools.
In particular, we use the Stanford Sen-timent Analysis tool (Socher et al, 2013) to infersentiment.
To extract NNPs we use the Stanford1036Feature DescriptionSentiment The inferred sentiment (nega-tive/neutral or positive) for a givencomment.Subreddit the subreddit (e.g., progressive or con-servative; atheism or Christianity) towhich a comment was posted.NNP Noun phrases (e.g., proper nouns) ex-tracted from comment texts.NNP+ Noun phrases extracted from commenttexts and the thread to which they be-long (for example, ?Obamacare?
fromthe title in Figure 1).Table 1: Feature types that we exploit.
We view the (ob-served) subreddit as a proxy for user type.
We combine thiswith sentiment and extracted noun phrases (NNPs) to im-prove classifier performance.Part of Speech tagger (Toutanova et al, 2003).
Wethen introduce ?bag-of-NNP?
features and featuresthat indicate whether the sentiment inferred for agiven sentence was positive or not.Additionally, we introduce ?interaction?
fea-tures that capture combinations of these.
For ex-ample, a feature that indicates whether a givensentence mentions Obamacare (which will be oneof many NNPs automatically extracted) and wasposted in the conservative subreddit.
This is anexample of a two-way interaction.
We also exper-iment with three-way interactions, crossing senti-ment with NNPs and subreddits.
An example is afeature that indicates if a sentence was: inferredto be positive and mentions Obamacare (NNP)and was part of a comment made in the conserva-tive subreddit.
Finally, we experiment with addingNNPs extracted from the comment thread in addi-tion to the comment text.These are rich features that capture signal notdirectly available from the sentences themselves.Features that encode subreddits crossed with ex-tracted NNP?s, in particular, offer a chance to ex-plicitly account for differences in how the ironicdevice is used by individuals in different com-munities.
However, this has the downside of in-troducing a large number of irrelevant terms intothe model: we expect, a priori, that many enti-ties will not correlate with the use of verbal irony.We would therefore expect this strategy to exhibithigh variance in terms of predictive performance,and we later confirm this empirically.
Ideally, amodel would perform feature selection during pa-rameter estimation, thus dropping irrelevant inter-action terms.
We next introduce a composite `1/`2regularization strategy toward this end.3 Enforcing sparsity3.1 PreliminariesIn this work we consider linear models with bi-nary outputs (y ?
{?1,+1}).
We will assumewe have access to a training dataset comprising ninstances, x = {x1, ...,xn} and associated labelsy = {y1, ..., yn}.
We then aim to find a weight-vector w that optimizes the following objective.argminwn?i=1L(sign{w ?
xi}, yi) + ?R(w) (1)Where L is a loss function, R(w) is a regulariza-tion term and ?
is a parameter expressing the rel-ative emphasis placed on achieving minimum em-pirical loss versus producing a simple model (i.e.,a weight vector with small weights).
Typically onesearches for a good ?
using the available train-ing data.
For L, we will use the log-loss in thiswork, though other loss functions may be used inits place.3.2 Sparsity via RegularizationConcerning R, one popular regularization func-tion is the squared `2norm:?jw2j(2)This is the norm used in the standard Support Vec-tor Machine (SVM) formulation, for example, andhas been shown empirically to work well for textclassification (Joachims, 1998).
An alternative isto use the `1norm:?j|wj| (3)Which has the advantage of inducing sparse mod-els: i.e., using the `1norm as a penalty tends todrive feature weights to 0.Returning to the present task of detecting ver-bal irony in comments, it seems reasonable to as-sume that there will be a relatively small set ofentities that correlate with sarcasm.
But becausewe are introducing ?interaction?
features that enu-merate the cross-product of subreddits and entities(and, in some cases, sentiment), we have a largefeature-space.
This space includes features thatcorrespond to NNPs extracted from, and sentimentinferred for, the sentence itself: we will denote theindices for these by I.
Other interaction features1037correspond to entities extracted from the threadsassociated with comments: we denote the corre-sponding set of indices by T .
We expect only afraction of the features comprising both I and Tto have non-zero weights (i.e., to signal ironic in-tent).This scenario is prone to the undesirable prop-erty of high-variance, and hence calls for strongerregularization.
But in general replacing thesquared `2norm with an `1penalty (over allweights) hampers classification performance (in-deed, as we later report, this strategy performsvery poorly here).
Therefore, in our scenario wewould like to place a sparsifying `1regularizerover the contextual (interaction) features whilestill leveraging the squared `2-norm penalty for thestandard bag-of-words (BoW) features.2We thuspropose the following composite penalty:?jw2j+?k?I|wk|+?l?T|wl| (4)The idea is that this will drive many of the weightsassociated with the contextual features to zero,which is desirable in light of the intuition that arelatively small number of entities will likely in-dicate sarcasm.
At the same time, this compositepenalty applies only the squared `2norm to thestandard BoW features, given the comparativelystrong predictive performance realized with thisstrategy.Putting this together, we modify the original ob-jective (Equation 1) as follows:argminwn?i=1L(sign{w ?
xi}, yi)+?0?jw2j+ ?1?k?I|wk|+?2?l?T|wl| (5)Where we have placed separate ?
scalars on the re-spective penalty terms.
Note that this is similar tothe elastic net (Zou and Hastie, 2005) joint regu-larization and variable selection strategy.
The dis-tinction here is that we only apply the `1penaltyto (i.e., perform feature selection for) the subsetof ?interaction?
feature weights, which is in con-trast to the elastic net, which imposes the compos-ite penalty to all feature weights.
One can viewthis as using the regularizer to encourage a spar-sity pattern specific to the task at hand.2Note that we apply both `1and `2penalties to the fea-tures in I and T .3.3 InferenceWe fit this model via Stochastic Gradient Descent(SGD).3During each update, we impose both thesquared `2and `1penalties; the latter is appliedonly to the contextual/interaction features in I andT .
For the `1penalty, we adopt the cumulativetruncated gradient method proposed by Tsuruokaet al (2009).4 Experimental Setup4.1 DatasetsFor our development dataset, we used a subset ofthe reddit irony corpus (Wallace et al, 2014) com-prising annotated comments from the progressiveand conservative subreddits.
We also report re-sults from experiments performed using a sepa-rate, held-out portion of this data, which we didnot use during model refinement.
Furthermore, welater present results on comments from the athe-ism and Christianity subreddits (we did not usethis data during model development, either).The development dataset includes 1,825 anno-tated comments (876 and 949 from the progressiveand conservative subreddits, respectively).
Thesecomprise 5,625 sentences in total, each of whichwas independently labeled by three annotators ashaving been intended ironically or not.
For addi-tional details on the annotation process, see (Wal-lace et al, 2014).
For simplicity, we consider asentence to be ?ironic?
(y = 1) when at least twoof the three annotators designated it as such, and?unironic?
(y = ?1) otherwise.
Using this crite-ria, 286 (5%) of the labeled sentences are labeled?ironic?.The test portion of the political dataset com-prises 996 annotated comments (409 progressiveand 587 conservative comments), totalling 2,884sentences.
Using the same criteria as above ?
atleast 2/3 annotators labeling a given sentence as?ironic?
?
we have 154 ?ironic?
sentences (againabout 5%).The ?religion?
dataset (comments from athe-ism and Christianity) contains 1,682 labeled com-ments comprising 5615 sentences (2,966 and2,649 from the atheism and Christian subreddits,respectively); 313 (?6%) were deemed ?ironic?.3We have implemented this within the sklearn package(Pedregosa et al, 2011).10384.2 Experimental DetailsWe recorded results from 500 independently per-formed experiments on random train (80%)/test(20%) splits of the data.
These splits were per-formed at the comment (rather than sentence)level, so as not to test on sentences belonging tocomments encountered in the training set.
Wemeasured performance, however, at the sentencelevel (often only a single sentence in a given com-ment will have been labeled as ?ironic?
).Our baseline approach is a standard squared-`2regularized log-loss linear model (fit via SGD) thatleverages uni- and bi-grams and features indicat-ing grammatical cues, such as exclamation pointsand emoticons.
We also experiment with a modelthat includes inferred sentiment indicators, but notcontext.
We performed standard English stop-wording, and we used Term Frequency Inverse-Document Frequency (TF-IDF) feature weighting.For the gradient descent procedure, we used a de-caying learning rate (specifically,1t, where t is theupdate count).
We performed a coarse grid searchto find values for ?
that maximize F1 on the train-ing datasets.
We took five full passes over thetraining data before terminating descent.We report paired recalls and precisions, as ob-served on each random train/test split of the data.The former is defined asTPTP+FNand the latterasTPTP+FP, where TP denotes the true positivecount, FN the number of false negatives and FPthe false positive count.
We report these sepa-rately - rather than collapsing into F1 - becauseit is not clear that one would value recall and pre-cision equally for irony detection, and because thisallows us to tease out how the models differ in per-formance.
Notably, for example, sentiment andcontext features both improve recall, but the lat-ter does so without harming precision.5 Results5.1 Results on the Development CorpusFigure 2 and Table 2 summarize the performanceof the different approaches over 500 indepen-dently performed train/test splits of the politicaldevelopment corpus.
For reference, a randomchance strategy (which predicts ?ironic?
with prob-ability equal to the observed prevalence) achievesa median recall of 0.048 and a median precision of0.047.Figure 2 shows histograms of the observed ab-solute differences between the baseline linear clas-Figure 4: Empirical distributions (violin plots) of non-zerofeature counts in the NNP ?
subreddit model (rows 3 and 4in Figure 3) using standard `2-norm (left) and the proposed`1`2-norm (right) regularization approaches on the athe-ism/Christianity data over 500 independent train/test splits.The composite norm achieves much greater sparsity, result-ing in lower variance.
This sparsity also (arguably) providesgreater interpretability; one can inspect contextual featureswith non-zero weights.sifier and the proposed augmentations.
Addingthe proposed features (which capitalize on senti-ment and NNP-mentions on specific subreddits)increases absolute median recall by 3.4 percent-age points (a relative gain of ?12%).
And this isachieved without sacrificing precision (in contrastto exploiting only sentiment).
Furthermore, as wecan see in Figures 2 and 3, the proposed regular-ization strategy shrinks the variance of the classi-fier.
This variance reduction is achieved throughgreater model sparsity, as can be seen in Figure4, which improves interpretability.
We note thatleveraging only an `1regularization penalty (withthe full feature-set) results in very poor perfor-mance (median recall and precision of 0.05 and0.09, respectively).
Similarly, the elastic-net strat-egy (Zou and Hastie, 2005) (in which we do notspecify which features to apply the `1penalty to),here achieves a median recall of 0.11 and a medianprecision of 0.07.5.2 Results on the Held-out (Test) CorpusTable 4 reports results on the held-out political testdataset, achieved after training the models on theentirety of the development corpus.
To accountfor the variance inherent to inference via SGD, weperformed 100 runs of the SGD procedure and re-port median results from these runs.
These resultsmostly agree with those reported for the develop-ment corpus: the proposed strategy improves me-dian recall on the held-out corpus by nearly 4.0percentage points, at a median cost of about 1point in precision.
By contrast, sentiment aloneprovides a 2% absolute improvement in recall at1039mean; median (25th, 75th) mean; median (25th, 75th)baseline (BoW) 0.288; 0.283 (0.231, 0.333) 0.129; 0.124 (0.103, 0.149)?
recall ?
precision(overall) sent.
+0.036; +0.037 (+0.015, +0.063) -0.008; -0.007 (-0.018, +0.003)NNP +0.021; +0.018 (+0.000, +0.036) -0.008; -0.008 (-0.016, -0.001)NNP ?
subreddit +0.013; +0.016 (+0.000, +0.031) -0.002; -0.003 (-0.009, +0.004)NNP ?
subreddit (`1`2) +0.010; +0.000 (+0.000, +0.021) -0.002; -0.002 (-0.007, +0.004)NNP+ ?
sent.
?
subreddit + sent.
+0.036; +0.038 (+0.000, +0.065) -0.000; -0.001 (-0.012, +0.011)NNP+ ?
sent.
?
subreddit + sent.
(`1`2) +0.035; +0.034 (+0.000, +0.062) +0.001; +0.000 (-0.011, +0.011)Table 2: Summary results over 500 random train/test splits of the development dataset.
The top row reports mean and medianbaseline (BoW) recall and precision and lower and upper (25th and 75th) percentiles.
We report pairwise differences w.r.t.
thisbaseline in terms of recall and precision for each strategy.
Exploiting NNP features and subreddits improves recall with littleto not cost in precision.
Capitalizing on sentiment alone improves recall but at a greater cost in precision.
The proposed `1`2regularization strategy achieves comparable performance with fewer features, and shrinks the variance over different train/testsplits (as can bee seen in Figure 2).mean; median (25th, 75th) mean; median (25th, 75th)baseline (BoW) 0.281; 0.268 (0.222, 0.327) 0.189; 0.187 (0.144, 0.230)?
recall ?
precision(overall) sent.
+0.001; +0.000 (-0.011, +0.015) -0.014; -0.012 (-0.023, -0.002)NNP +0.018; +0.018 (+0.000, +0.039) -0.009; -0.010 (-0.021, +0.001)NNP ?
subreddit +0.024; +0.025 (+0.000, +0.046) +0.002; +0.001 (-0.011, +0.013)NNP ?
subreddit (`1`2) +0.013; +0.015 (+0.000, +0.033) +0.002; +0.002 (-0.009, +0.011)NNP+ ?
sent.
?
subreddit + sent.
+0.023; +0.024 (+0.000, +0.046) +0.001; +0.001 (-0.012, +0.013)NNP+ ?
sent.
?
subreddit + sent.
(`1`2) +0.014; +0.015 (+0.000, +0.036) -0.008; -0.008 (-0.021, +0.004)Table 3: Results on the atheism and Christianity subreddits.
In general sentiment does not help on this dataset (see row 1).
Butthe NNP and subreddit features again consistently improve recall without hurting precision.
And, as above, `1`2regularizationshrinks variance (see Figures 2 and 3).Figure 2: Results from 500 independent train/test splits of the development subset of our political data.
Shown are histogramswith smoothed kernel density estimates of differences in recall and precision between the baseline bag-of-words based approachand each feature space/method (one per row).
The solid black line at 0 indicates no difference; solid and dotted blue linesdemarcate means and medians, respectively.
Features are as in Table 1.
The ?
symbol denotes interactions; + indicatesaddition.
The proposed contextual features substantially improve recall, with little to no loss in precision.
Moreover, in general,the `1`2regularization approach reduces variance.
(We note that in constructing histograms we have excluded a handful ofpoints ?
never more than 1% ?
where the difference exceeded 0.15).median recall (std.
dev.)
median precision (std.
dev.
)baseline 0.331 (0.146) 0.148 (0.022)(overall) sent.
0.351 (0.054) 0.125 (0.003)NNP 0.364 (0.119) 0.135 (0.021)NNP ?
subreddit 0.357 (0.108) 0.143 (0.020)NNP+ ?
sent.
?
subreddit 0.344 (0.116) 0.142 (0.019)NNP+ ?
sent.
?
subreddit (`1`2) 0.325 (0.052) 0.141 (0.008)NNP+ ?
sent.
?
subreddit + sent.
0.377 (0.104) 0.141 (0.014)NNP+ ?
sent.
?
subreddit + sent.
(`1`2) 0.370 (0.056) 0.140 (0.008)Table 4: Results on the held-out political dataset, using the entire development corpus as a training set.
Abbreviations are asdescribed in the caption for Figure 2.
Due to the variance inherent to the stochastic gradient descent procedure, we repeatthe experiment 100 times and report the median performance and standard deviations (of different SGD runs).
Results areconsistent with those reported for the development corpus.1040Figure 3: Results from 500 independent train/test splits of the development subset of the religion corpus).
The description isthe same as for Figure 2.the expense of more than 2 points in precision.5.3 Results on the religion datasetTo assess the general applicability of the proposedapproach, we also evaluate the method on com-ments from a separate pair of polarized communi-ties: atheism and Christianity, as described in Sec-tion 4.1.
This dataset was not used during modeldevelopment.
We follow the experimental setupdescribed in Section 4.2.In this case, capitalizing on the NNP ?
subred-dit features produces a mean 2.3% absolute gain inrecall (median: 2.4%) over the baseline approach,with a (very) slight gain in precision.
The `1`2approach achieves a lower expected gain in recall(median: 1.5%), but again shrinks the variancew.r.t.
model performance (see Figure 3).
More-over, as we show in Figure 4, this is achieved witha much more compact (sparser) model.
We notethat for the religion data, inferred sentiment fea-tures do not seem to improve performance, in con-trast to the results on the political subreddits.
Atpresent, we are not sure why this is the case.These results demonstrate that introducing fea-tures that encode entities and user communities(NNPs ?
subreddit) improve recall for irony de-tection in comments addressing relatively diversetopics (politics and religion).5.4 Predictive featuresWe report the interaction features that are the bestpredictors of verbal irony in the respective subred-progressive conservativefeature weight feature weightfreedom 0.102 (0.048) racist 0.148 (0.043)god 0.085 (0.045) news 0.100 (0.044)christmas 0.081 (0.046) way 0.078 (0.044)jesus 0.060 (0.038) obamacare 0.068 (0.041)kenya 0.052 (0.035) white 0.059 (0.037)brave 0.043 (0.035) let 0.058 (0.038)bravo 0.041 (0.035) course 0.046 (0.033)know 0.038 (0.030) huh 0.044 (0.036)dennis 0.038 (0.029) education 0.043 (0.032)ronald 0.036 (0.030) president 0.039 (0.031)Table 5: Average weights (and standard deviations calculatedacross samples) for top 10 NNP ?
subreddit features fromthe progressive and conservative subreddits.dits (for both polar community pairs).
Specifically,we estimated the weights for every interaction fea-ture using the entire training dataset, and repeatedthis process 100 times to account for variation dueto the SGD procedure.Table 5 displays the top 10 NNP ?
subredditfeatures for the political subreddits, with respect tothe mean magnitude of the weights associated withthem.
We report these means and the standard de-viations calculated across the 100 runs.
This tableimplies, for example, that mentions of ?freedom?and ?kenya?
indicate irony in the progressive sub-reddit; while mentions of ?obamacare?
and ?pres-ident?
(for example) in the conservative subreddittend to imply irony.Table 6 reports analagous results for the religionsubreddits.
Here we can see, e.g., that ?god?
is agood predictor of irony in the atheism subreddit,and ?professor?
is in the Christianity subreddit.We also report the top ranking ?three-way?
in-teraction features that cross NNP?s extracted from1041atheism Christianityfeature weight feature weightright 0.353 (0.014) professor 0.297 (0.013)god 0.324 (0.013) let 0.084 (0.014)women 0.214 (0.013) peter 0.080 (0.019)christ 0.160 (0.014) geez 0.054 (0.016)news 0.146 (0.013) evil 0.054 (0.015)trust 0.139 (0.013) killing 0.053 (0.015)shit 0.132 (0.015) liberal 0.049 (0.014)believe 0.123 (0.013) antichrist 0.049 (0.014)great 0.121 (0.016) rock 0.047 (0.014)ftfy 0.108 (0.016) pedophilia 0.046 (0.014)Table 6: Top 10 NNP ?
subreddit features from the atheismand Christianity subreddits.progressive conservativefeature weight feature weightamerican (+) 0.045 (0.023) mr (+) 0.041 (0.021)yay (+) 0.042 (0.022) cruz (+) 0.040 (0.021)ollie (+) 0.036 (0.019) king (+) 0.036 (0.019)north (+) 0.036 (0.019) onion (+) 0.035 (0.018)fuck (+) 0.034 (0.018) russia (+) 0.034 (0.018)washington (+) 0.034 (0.018) oprah (+) 0.030 (0.016)times* (+) 0.034 (0.018) science (+) 0.027 (0.015)world (+) 0.030 (0.016) math (+) 0.027 (0.015)magic (+) 0.024 (0.013) america (+) 0.026 (0.014)where (+) 0.024 (0.013) ben (+) 0.020 (0.011)Table 7: Average weights for top 10 NNP ?
subreddit ?sentiment features.
The parenthetical ?+?
indicates that theinferred sentiment was positive.
In general, (ostensibly) pos-itive sentiment indicates irony.sentences with subreddits and the inferred senti-ment for the political corpus (Table 7).
This wouldimply, e.g., that if a sentence in the progressivesubreddit conveys an ostensibly positive sentimentabout the political commentator ?Ollie?,4then thissentence is likely to have been intended ironically.Some of these may seem counter-intuitive, suchas ostensibly positive sentiment regarding ?Cruz?
(as in the conservative senator Ted Cruz) in theconservative subreddit.
On inspection of the com-ments, it would seem Ted Cruz does not findgeneral support even in this community.
Exam-ple comments include: ?Stay classy Ted Cruz?and ?Great idea on the talkathon Cruz?.
The?mr?
and ?king?
terms are almost exclusively ref-erences to Obama in the conservative subreddit.In any case, because these are three-way interac-tion terms, they are all relatively rare: therefore wewould caution against over interpretation here.6 Related WorkThe task of automated irony detection has recentlyreceived a great deal of attention from the NLP andML communities (Tepperman et al, 2006; Davi-dov et al, 2010; Carvalho et al, 2009; Burfoot andBaldwin, 2009; Tsur et al, 2010; Gonz?alez-Ib?a?nezet al, 2011; Filatova, 2012; Reyes et al, 2012;Lukin and Walker, 2013; Riloff et al, 2013).
Thiswork has mostly focussed on exploiting token-4?Ollie?
is a conservative political commentator.based indicators of verbal irony.
For example, itis clear that gratuitous punctuation (e.g.
?oh re-ally??!!!?)
signals irony (Carvalho et al, 2009).Davidov et al (2010) proposed a semi-supervised approach in which they look for sen-tence templates indicative of irony.
Elsewhere,Riloff et al (2013) proposed a method that ex-ploits apparently contrasting sentiment in the sameutterance to detect irony.
While innovative, theseapproaches still rely on features intrinsic to com-ments; i.e., they do not attempt to capitalize oncontextualizing features external to the commenttext.
This means that there will necessarily be cer-tain (subtle) ironies that escape detection by suchapproaches.
For example, without any additionalinformation about the speaker, it would be impos-sible to deduce whether the comment ?Obamacareis a great program?
is intended sarcastically.Other related recent work has shown thepromise of sparse models, both for prediction andinterpretation (Eisenstein et al, 2011a; Eisensteinet al, 2011b; Yogatama and Smith, 2014a).
Yo-gatama (2014a; 2014b), e.g., has leveraged thegroup lasso approach to impose ?structured?
spar-sity on feature weights.
Our work here may simi-larly be viewed as assuming a specific sparsity pat-tern (specifically that feature weights for ?interac-tion features?
will be sparse) and expressing thisvia regularization.7 Conclusions and Future DirectionsWe have shown that we can leverage contextual-izing information to improve identification of ver-bal irony in online comments.
This is in contrastto previous models, which have relied predomi-nantly on features that are intrinsic to the textsto be classified.
We exploited features that indi-cate user communities crossed with sentiment andextracted noun phrases.
This led to consistentlyimproved recall with little to no cost in precision.We also proposed a novel composite regulariza-tion strategy that imposes a sparsifying `1penaltyon the interaction features, as we expect most ofthese to be irrelevant.
This reduced performancevariance.Future work will include expanding the corpusand experimenting with datasets outside of the po-litical domain.
We also plan to evaluate this strat-egy on data from different online sources, e.g.,Twitter or YouTube.1042AcknowledgementsThis work was supported by ARO grant W911NF-14-1-0442.ReferencesC Burfoot and T Baldwin.
2009.
Automatic satire de-tection: are you having a laugh?
In ACL-IJCNLP,pages 161?164.
ACL.P Carvalho, L Sarmento, MJ Silva, and E de Oliveira.2009.
Clues for detecting irony in user-generatedcontents: oh...!!
it?s so easy;-).
In CIKM workshopon Topic-sentiment analysis for mass opinion, pages53?56.
ACM.HH Clark and RJ Gerrig.
1984.
On the pretense the-ory of irony.
Journal of Experimental Psychology,113:121?126.D Davidov, O Tsur, and A Rappoport.
2010.
Semi-supervised recognition of sarcastic sentences in twit-ter and amazon.
Conference on Natural LanguageLearning (CoNLL), page 107.J Eisenstein, A Ahmed, and EP Xing.
2011a.
Sparseadditive generative models of text.
In InternationalConference on Machine Learning (ICML).J Eisenstein, NA Smith, and EP Xing.
2011b.
Dis-covering sociolinguistic associations with structuredsparsity.
In Proceedings of the Annual Meetingof the Association for Computational Linguistics(ACL), pages 1365?1374.E Filatova.
2012.
Irony and sarcasm: Corpus gener-ation and analysis using crowdsourcing.
In LREC,volume 12, pages 392?398.R Gonz?alez-Ib?a?nez, S Muresan, and N Wacholder.2011.
Identifying sarcasm in twitter: a closer look.In ACL, volume 2, pages 581?586.
Citeseer.HP Grice.
1975.
Logic and conversation.
1975, pages41?58.T Joachims.
1998.
Text categorization with supportvector machines: Learning with many relevant fea-tures.
Springer.S Lukin and M Walker.
2013.
Really?
well.
ap-parently bootstrapping improves the performance ofsarcasm and nastiness classifiers for online dialogue.NAACL, pages 30?40.F Pedregosa, G Varoquaux, A Gramfort, V Michel,B Thirion, O Grisel, M Blondel, P Prettenhofer,R Weiss, V Dubourg, J Vanderplas, A Passos,D Cournapeau, M Brucher, M Perrot, and E Duch-esnay.
2011.
Scikit-learn: Machine learning inPython.
Journal of Machine Learning Research,12:2825?2830.A Reyes, P Rosso, and T Veale.
2012.
A multidimen-sional approach for detecting irony in twitter.
LREC,pages 1?30.E Riloff, A Qadir, P Surve, LD Silva, N Gilbert, andR Huang.
2013.
Sarcasm as contrast between a pos-itive sentiment and negative situation.
In EMNLP,pages 704?714.R Socher, A Perelygin, JY Wu, J Chuang, CD Man-ning, AY Ng, and C Potts.
2013.
Recursive deepmodels for semantic compositionality over a senti-ment treebank.
In Proceedings of the Conference onEmpirical Methods in Natural Language Processing(EMNLP), pages 1631?1642.
Citeseer.D Sperber and D Wilson.
1981.
Irony and the use-mention distinction.
1981.J Tepperman, D Traum, and S Narayanan.
2006.?Yeah Right?
: Sarcasm Recognition for Spoken Di-alogue Systems.K Toutanova, D Klein, CD Manning, and Y Singer.2003.
Feature-rich part-of-speech tagging with acyclic dependency network.
In Proceedings of the2003 Conference of the North American Chapterof the Association for Computational Linguistics onHuman Language Technology-Volume 1, pages 173?180.
Association for Computational Linguistics.O Tsur, D Davidov, and A Rappoport.
2010.
ICWSM-a great catchy name: Semi-supervised recognitionof sarcastic sentences in online product reviews.
InAAAI Conference on Weblogs and Social Media.Y Tsuruoka, J Tsujii, and S Ananiadou.
2009.Stochastic gradient descent training for l1-regularized log-linear models with cumulativepenalty.
In Proceedings of the Joint Conference ofthe Annual Meeting of the ACL and the InternationalJoint Conference on Natural Language Processingof the AFNLP, pages 477?485.
Association forComputational Linguistics.BC Wallace, DK Choe, L Kertz, and E Charniak.
2014.Humans require context to infer ironic intent (socomputers probably do, too).
Proceedings of theAnnual Meeting of the Association for Computa-tional Linguistics (ACL), pages 512?516.BC Wallace.
2013.
Computational irony: A surveyand new perspectives.
Artificial Intelligence Review,pages 1?17.D Yogatama and NA Smith.
2014a.
Linguistic struc-tured sparsity in text categorization.
In Proceedingsof the Annual Meeting of the Association for Com-putational Linguistics (ACL), pages 786?796.D Yogatama and NA Smith.
2014b.
Making the mostof bag of words: Sentence regularization with alter-nating direction method of multipliers.
In Proceed-ings of The 31st International Conference on Ma-chine Learning, pages 656?664.1043H Zou and T Hastie.
2005.
Regularization and variableselection via the elastic net.
Journal of the RoyalStatistical Society: Series B (Statistical Methodol-ogy), 67(2):301?320.1044
