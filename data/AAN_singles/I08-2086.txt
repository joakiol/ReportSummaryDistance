Effects of Related Term Extraction in Transliteration into ChineseHaiXiang Huang Atsushi FujiiGraduate School of Library, Information and Media StudiesUniversity of Tsukuba1-2 Kasuga, Tsukuba, 305-8550, Japan{lectas21,fujii}@slis.tsukuba.ac.jpAbstractTo transliterate foreign words, in Japaneseand Korean, phonograms, such as Katakanaand Hangul, are used.
In Chinese, thepronunciation of a source word is spelledout using Kanji characters.
Because Kanjiis ideogrammatic representation, differentKanji characters are associated with thesame pronunciation, but can potentially con-vey different meanings and impressions.
Toselect appropriate Kanji characters, an ex-isting method requests the user to provideone or more related terms for a source word,which is time-consuming and expensive.
Inthis paper, to reduce this human effort, weuse the World Wide Web to extract relatedterms for source words.
We show the effec-tiveness of our method experimentally.1 IntroductionReflecting the rapid growth of science, technology,and economies, new technical terms and productnames have progressively been created.
These newwords have also been imported into different lan-guages.
There are two fundamental methods for im-porting foreign words into a language.In the first method?translation?the meaning ofthe source word in question is represented by an ex-isting or new word in the target language.In the second method?transliteration?the pronun-ciation of the source word is represented by usingthe phonetic alphabet of the target language, such asKatakana in Japanese and Hangul in Korean.
Tech-nical terms and proper nouns are often transliterated.In Chinese, Kanji is used to spell out both conven-tional Chinese words and foreign words.
BecauseKanji is ideogrammatic, an individual pronunciationcan be represented by more than one character.
Ifseveral Kanji strings are related to the same pronun-ciation of the source word, their meanings will bedifferent and convey different impressions.For example, ?Coca-Cola?
can be represented bydifferent Kanji strings in Chinese with similar pro-nunciations, such as ??????
and ?????
?.The official transliteration is ?????
?, whichcomprises ???
(tasty)?
and ???
(pleasant)?, andis therefore associated with a positive connotation.However, ??????
is associated with a nega-tive connotation because this word includes ???
?,which is associated with ?choking?.For another example, the official transliteration ofthe musician Chopin?s name in Chinese is ???
?,where ???
is commonly used for Chinese familynames.
Other Kanji characters with the same pro-nunciation as ???
include ???.
However, ??
?,which means ?to disappear?, is not ideal for a per-son?s name.Thus, Kanji characters must be selected carefullyduring transliteration into Chinese.
This is espe-cially important when foreign companies intend tointroduce their names and products into China.In a broad sense, the term ?transliteration?
hasbeen used to refer to two tasks.
The first task istransliteration in the strict sense, which creates newwords in a target language (Haizhou et al, 2004;Wan and Verspoor, 1998; Xu et al, 2006).
The sec-ond task is back-transliteration (Knight and Graehl,1998), which identifies the source word correspond-643ing to an existing transliterated word.
Both tasksrequire methods that model pronunciation in thesource and target languages.However, by definition, in back-transliteration,the word in question has already been transliter-ated and the meaning or impression of the sourceword does not have to be considered.
Thus, back-transliteration is outside the scope of this paper.
Inthe following, we use the term ?transliteration?
torefer to transliteration in the strict sense.Existing transliteration methods for Chi-nese (Haizhou et al, 2004; Wan and Verspoor,1998), which aim to spell out foreign names ofpeople and places, do not model the impression thetransliterated word might have on the reader.Xu et al (2006) proposed a method to model boththe impression and the pronunciation for transliter-ation into Chinese.
In this method, impression key-words that are related to the source word are used.However, a user must provide impression keywords,which is time-consuming and expensive.In this paper, to reduce the amount of human ef-fort, we propose a method that uses the World WideWeb to extract related terms for source words.2 OverviewFigure 1 shows our transliteration method, whichmodels pronunciation, impression, and target lan-guage when transliterating foreign words into Chi-nese.
Figure 1 is an extension of the method pro-posed by Xu et al (2006) and the part surrounded bya dotted line is the scheme we propose in this paper.We will explain the entire process using Figure 1.There are two parts to the input for our method.First, a source word to be transliterated into Chi-nese is requested.
Second, the category of the sourceword, such as ?company?
or ?person?, is requested.The output is one or more Kanji strings.Using the pronunciation model, the source wordis converted into a set of Kanji strings whose pro-nunciation is similar to that of the source word.
Eachof these Kanji strings is a transliteration candidate.Currently, we use Japanese Katakana words assource words, because Katakana words can be easilyconverted into pronunciations using the Latin alpha-bet.
In Figure 1, the Katakana word ?epuson (EP-SON)?
is used as an example source word.
How-Source wordRelated term(s)Transliteration candidates Kanji charactersCategory of source wordRanked list of transliteration candidatespronunciation model impression modelranking candidateslanguage model????(epuson)??(like)??(popularize)??(general)?(good)???(company)?????????
...??????
?????????
?World Wide WebKanji charactersFigure 1: Overview of our transliteration method.ever, in principle, any language that uses a phoneticscript can be a source language for our method.Using the impression model, one or more relatedterms are converted into a set of Kanji characters.In Xu et al (2006), one or more words that de-scribe the impression of the source word are used asrelated terms (i.e., impression keywords).
Becauseimpression keywords are given manually, users musthave a good command of Chinese.
In addition, thetask of providing impression keywords is expensive.We solve these problems by automatically extractingterms related to the source word from the Web.Unlike Xu at al.
(2006), the language model forthe category of the source word is used.
For ex-ample, if the category is ?person?, Kanji charactersthat are often used for personal names in Chinese arepreferably used for the transliteration.Because of the potentially large number of se-lected candidates, we need to rank the candidates.We model pronunciation, impression, and target lan-guage in a probabilistic framework, so that candi-dates are sorted according to their probability score.In practice, the Kanji characters derived via the im-pression and language models are used to re-rank thecandidates derived via the pronunciation model.3 Probabilistic Transliteration ModelGiven a romanized source word R, a set of relatedterms W , and the category of the source word C,our purpose is to select the Kanji string K that max-imizes P (K|R,W,C), which is evaluated as shownin Equation (1), using Bayes?s theorem.644P (K|R,W,C)= P (R,W,C|K)?P (K)P (R,W,C)?
P (R|K)?P (W |K)?P (C|K)?P (K)P (R,W,C)?
P (R|K)?P (W |K)?P (C|K)?P (K)= P (R|K)?P (W |K)?P (C,K)(1)Xu et al (2006) did not consider the category of thesource word and computed P (K|R,W ).In the third line of Equation (1), we assume theconditional independence of R, W , and C given K.In the fourth line, we omit P (R,W,C), which isindependent of K. This does not affect the rela-tive rank of Kanji strings, when ranked in terms ofP (K|R,W,C).
If a user intends to select more thanone Kanji string, those Ks associated with higherprobabilities should be selected.
In Figure 1, R, W ,and C are ?epuson?, ??????????
and ????
?, respectively, and a K is ????
?.In Equation (1), P (K|R,W,C) can be approx-imated by the product of P (R|K), P (W |K), andP (C,K).
We call these three factors the pronuncia-tion, impression, and language models, respectively.The implementation of P (R|K) and P (W |K) isthe same as in Xu et al (2006).
While P (R|K) hascommonly been used in the literature, the basis ofP (W |K) should perhaps be explained.
P (W |K) iscomputed using co-occurrence frequencies of eachword in W and each character in K, for which weextracted co-occurrences of a word and a Kanji char-acter from a dictionary of Kanji in Chinese.
Pleasesee Xu et al (2006) for details.
However, unlike Xuet al (2006), in which W was provided manually,we automatically extract W from the Web.While Xu et al (2006) did not use the languagemodel, we compute P (C,K) by Equation (2).P (C,K) = P (C)?P (K|C) ?
P (K|C) (2)We omit P (C), which is independent of K. Thus,we compute P (K|C), which is the probability thata Kanji string K is selected given category C.To compute P (K|C), we decompose K into sin-gle Kanji characters.
We used a character unigrammodel and produced the following three languagemodels.?
general model: one month of newspaper arti-cles in the PFR corpus1 were used.
In thismodel, 4 540 character types (12 229 563 to-kens) are modeled.?
company model: a list of 22 569 companynames in CNLP (Chinese Natural LanguageProcessing)2 was used.
In this model, 2 167character types (78 432 tokens) are modeled.?
person model: a list of 38 406 personal namesin CNLP was used.
In this model, 2 318 char-acter types (104 443 tokens) are modeled.To extract Kanji characters from the above corpusand lists, we performed morphological analysis bySuperMorpho3 and removed functional words andsymbols.
While the general model is not adapted toany specific category, the other models are adaptedto the company and person categories, respectively.Although the effect of adapting language models hasbeen explored in spoken language processing, no at-tempt has been made for transliteration.4 Extracting Related TermsTo extract related terms for a source word, we usedWikipedia4, which is a free encyclopedia on the Weband includes general words, persons, places, compa-nies, and products, as headwords.
We extracted re-lated term candidates for a source word as follows.1.
We consulted the Japanese Wikipedia for thesource word and obtained the result page.2.
We deleted HTML tags from the result pageand performed morphological analysis byChaSen5.3.
We extracted nouns and adjectives as relatedterm candidates.We used mutual information (Turney, 2001) tomeasure the degree of relation between the sourceword and a related term candidate by Equation (3).I(X,Y ) = log P (X,Y )P (X) ?
P (Y )(3)1http://icl.pky.edu.cn/2http://www.nlp.org.cn/3http://www.omronsoft.com/4http://ja.wikipedia.org/wiki/5http://chasen.naist.jp/hiki/ChaSen/645X and Y denote the source word and a related termcandidate, respectively.
P (X) and P (Y ) denoteprobabilities of X and Y , respectively.
P (X,Y ) de-notes the joint probability of X and Y .To estimate the above three probabilities, we fol-lowed the method proposed by Turney (2001).
Weused the Yahoo!JAPAN6 search engine and replacedP (A) in Equation (3) with the number of pages re-trieved by the query A.
Here, ?A?
can be ?X?, ?Y ?,or ?X and Y ?.
Then, we selected up to 10 Y s withthe greatest I(X,Y ) and translated them into Chi-nese using the Yahoo!JAPAN machine translationsystem.Table 1 shows examples of related terms for thesource word ???
(mass)?, such as ???
(cere-mony)?
and ?
??
(dedication)?.
Irrelevant candi-dates, such as ?
?
(meeting)?
and ???
(thing)?,were discarded successfully.Table 1: Example of related terms for ???
(mass)?.Extracted related terms Discarded candidatesJapanese English Japanese English??
ceremony ?
meeting??
dedication ??
thing??
bishop ??
meeting??
church ??
join5 Experiments5.1 MethodTo evaluate the effectiveness of the related term ex-traction in the transliteration, we compared the ac-curacy of the following three methods.?
A combination of the pronunciation and lan-guage models that does not use the impressionmodel, P (W |K), in Equation (1),?
Our method, which uses Equation (1) and usesautomatically extracted related terms as W ,?
Equation (1), in which manually provided im-pression keywords are used as W .To make the difference between the second andthird methods clear, we use the terms ?related term(RT)?
and ?impression keyword (IK)?
to refer to6http://www.yahoo.co.jp/words provided automatically and manually, respec-tively.
Then, we call the above three methods?PL?, ?PL+RT?, and ?PL+IK?, respectively.
PL andPL+IK are the lower bound and the upper bound ofthe expected accuracy, respectively.
PL+IK is thesame as in Xu et al (2006), but the language modelis adapted to the category of source words.To produce test words for the transliteration, wefirst collected 210 Katakana words from a Japanese?Chinese dictionary.
These 210 words were also usedby Xu et al (2006) for experiments.
We then con-sulted Wikipedia for each of the 210 words and se-lected 128 words that were headwords in Wikipedia,as test words.
Details of the 128 test words areshown in Table 2.Table 2: Categories of test words.Category #WordsExample wordJapanese Chinese EnglishGeneral 24 ?????
???
angelCompany 35 ????
???
IntelProduct 27 ????
??
AudiPerson 13 ????
??
ChopinPlace 29 ????
???
OhioWe selectively used the three language models ex-plained in Section 3.
We used the general modelfor general words.
We used the company model forcompany and product names, and used the personmodel for person and place names.
A preliminarystudy showed that the language model adaptationwas generally effective for transliteration.
However,because the focus of this paper is the related termextraction, we do not describe the evaluation of thelanguage model adaptation.Two Chinese graduate students who had a goodcommand of Japanese served as assessors and pro-duced reference data, which consisted of impressionkeywords used for PL+IK and correct answers forthe transliteration.
Neither of the assessors was anauthor of this paper.
The assessors performed thesame task for the 128 test words independently, toenhance the objectivity of the evaluation.We produced the reference data via the followingprocedure that is the same as that of Xu et al (2006).First, for each test word, each assessor pro-vided one or more impression keywords in Chinese.We did not restrict the number of impression key-646words per test word; the number was determinedby each assessor.
We provided the assessors withthe descriptions for the test words from the sourceJapanese?Chinese dictionary, so that the assessorscould understand the meaning of each test word.Second, for each test word, we applied the threemethods (PL, PL+RT, and PL+IK) independently,which produced three lists of ranked candidates.Third, for each test word, each assessor identi-fied one or more correct transliterations, accordingto their impression of the test word.
It was impor-tant not to reveal to the assessors which method pro-duced which candidates.
By these means, we se-lected the top 100 transliteration candidates from thethree ranked lists.
We merged these candidates, re-moved duplications, and sorted the remaining can-didates by character code.
The assessors judgedthe correctness of up to 300 candidates for eachtest word.
The average number of candidates was36 976.The resultant reference data were used to evaluatethe accuracy of each method in ranking translitera-tion candidates.
We used the average rank of correctanswers in the list as the evaluation measure.
If morethan one correct answer was found for a single testword, we first averaged the ranks of these answersand then averaged the ranks over the test words.For each test word, there was more than one typeof ?correct answer?, as follows:(a) transliteration candidates judged as correct byeither of the assessors independently,(b) transliteration candidates judged as correct byboth assessors,(c) transliteration defined in the source Japanese?Chinese dictionary.In (a), the coverage of correct answers is the largest,whereas the objectivity of the judgment is the low-est.
In (c), the objectivity of the judgment is thelargest, whereas the coverage of correct answers isthe lowest.
In (b), where the assessors did not dis-agree about the correctness, the coverage of the cor-rectness and the objectivity are in between.The number of test words was 128 for both (a) and(c), but 76 for (b).
The average numbers of correctanswers were 1.65, 1.04, and 1 for (a), (b), and (c),respectively.5.2 Results and AnalysesTable 3 shows the average rank of correct answersfor different cases.
Looking at Table 3, for certaincategories, such as ?Place?, when the impressionmodel was used, the average rank was low.
How-ever, on average, the average rank for PL+RT waslower than that for PL+IK, but was higher than thatfor PL, irrespective of the answer type.Figures 2 and 3 show the distribution of correctanswers for different ranges of ranks, using answertypes (a) and (c) in Table 3, respectively.
Becausethe results for types (a) and (b) were similar, weshow only the results of type (a), for the sake of con-ciseness.
In Figure 2, the number of correct answersin the top 10 for PL+RT was smaller than that forPL+IK, but was greater than that for PL.In Figure 3, the number of correct answers in thetop 10 for PL+RT was greater than those for PL andPL+IK.
Because in Figure 3, the correct answerswere defined in the dictionary and were independentof the assessor judgments, PL+IK was not as effec-tive as in Figure 2.In summary, the use of automatically extracted re-lated terms was more effective than the method thatdoes not use the impression model.
We also reducedthe manual cost of providing impression keywords,while maintaining the transliteration accuracy.Table 4 shows examples of related terms or im-pression keywords for answer type (c).
In Table4, the column ?Rank?
denotes the average rankof correct answers for PL+RT and PL+IK, respec-tively.
For ???
(mass)?, the rank for PL+RT washigher than that for PL+IK.
However, for ?????
(the State of Qatar)?, the rank for PL+RT waslower than that for PL+IK.
One reason for this isthat most related terms for PL+RT were names ofcountries that border Qatar, which do not describeQatar well, compared with impression keywords forPL+IK, such as ???
(desert)?
and ?
??
(oil)?.This example indicates room for improvement in therelated term extraction algorithm.6 ConclusionFor transliterating foreign words into Chinese, thepronunciation of a source word is spelled out withKanji characters.
Because Kanji is an ideogram-matic script, different Kanji characters are associ-647Table 3: Average rank of correct answers for different methods in different cases.CategoryAnswer type (a) Answer type (b) Answer type (c)PL PL+RT PL+IK PL PL+RT PL+IK PL PL+RT PL+IKGeneral 189 165 167 44 49 52 84 61 65Company 232 208 203 33 29 27 317 391 325Product 197 175 166 34 27 21 313 198 198Person 98 69 44 4 4 4 114 154 75Place 85 133 95 13 14 16 76 98 89Avg.
160 150 135 26 25 24 181 160 150?????????????????
?????
??????
???????
?????????????????
?????????????????????????????
PL PL?RT PL?IKFigure 2: Rank for correct answer type (a).???????????????????
?????
??????
???????
????????
?????????
?????????????????????????????
PL PL?RT PL?IKFigure 3: Rank for correct answer type (c).Table 4: Examples of related terms and impression keywords used for experiments.Source word Answer Method Rank Examples of related terms or impression keywords???
?PL+RT 8 ??
(ceremony),??
(bishop),??
(dedication),??
(church)(mass) PL+IK 10 ??
(ceremony),??
(bishop),??
(belief),??
(church)??????
?PL+RT 103 ???
(State of Kuwait),??
(Republic of Yemen)(State of Qatar) PL+IK 61 ???
(Arab),??
(desert),??
(oil),??
(dryness)ated with the same pronunciation, but can poten-tially convey different meanings and impressions.In this paper, to select appropriate characters fortransliterating into Chinese, we automatically ex-tracted related terms for source words using theWeb.
We showed the effectiveness of our methodexperimentally.ReferencesLi Haizhou, Zhang Min, and Su Jian.
2004.
A jointsource-channel model for machine transliteration.
InProceedings of the 42nd Annual Meeting of the Asso-ciation for Computational Linguistics, pages 160?167.Kevin Knight and Jonathan Graehl.
1998.
Machinetransliteration.
Computational Linguistics, 24(4):599?612.Peter D. Turney.
2001.
Mining the Web for Synonyms:PMI-IR versus LSA on TOEFL.
In Proceedings of theTwelfth European Conference on Machine Learning,pages 419?502.Stephen Wan and Cornelia Maria Verspoor.
1998.
Auto-matic English-Chinese name transliteration for devel-opment of multilingual resources.
In Proceedings ofthe 36th Annual Meeting of the Association for Com-putational Linguistics and the 17th International Con-ference on Computational Linguistics, pages 1352?1356.LiLi Xu, Atsushi Fujii, and Tetsuya Ishikawa.
2006.Modeling Impression in Probabilistic Transliterationinto Chinese.
Proceedings of the 2006 Conference onEmpirical Methods in Natural Language Processing,pages 242?249.648
