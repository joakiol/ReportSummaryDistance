EBL2: AN APPROACH TOAUTOMATIC  LEXICAL ACQUIS IT IONLARS ASKER* BJ()R N GAM BACK ~ CllRISTER SAM UELSSON 1asker@day, nu.
ne  gam?sics, so  christ er~sics, seKeywords:  linguistic tools: /exical acquisiti(ul; explanation-based l arningAbst rac tA method for automatic lexical acquisition is outlined.
An existing lexicon that, in addition Io ordi-nary \]exical entries, contains prototypical cntrips forvarious non-exclusive paradigms of open-cl~,.ss words,is extended by inferring new lexical entries from textscontaining unknown words.
This is done by com-paring the constraints placed on the unknown wordshy the natural anguage system's grammar with theprototypes and a number of hand-coded phras(, tem-plates specific for each paradigm.
Once a sufficientnumber of observations of the word in different con-texts have been made, a lexical entry is constructedfor the word by assigning it to one or sew~ral para-digm(s),Parsing sentences with ullknown words is nor-mally very time-consuming due to the large nmn-ber of grammatically possible analyses.
To cir~cumvent his problem, other ilhrase templates areextracted automatically from tim gramlnal anddomain-specific texts using an explanation basedlearning method.
These templates represent gram-matically correct, sentence patterns.
When a sell-tence matches a template, the original I)arsing com-ponent can be bypassed, reducing parsing times dra-matically.1 IntroductionA persisting trend in unification-based approaches tonatural language processing is to incorporate largequantirAes of information in the lexicon, informatio,ithat has traditionally resided in the gran,mar rules.Acquiring a lexicon has thus becolne a diflicull andtime consuming txsk, even for moderately sized lexira.
In addition to this, an.
',' natural language pro-cessing system intended for serious applications mustinclude a large lexicon -- several thousands of wordsor more is commonly considered a minimun~ sizewhich adds even more to the complexity of the lu'ob-lem.
In view Of this, tools for lexical acqusition arenot only desirable they become a necessity.Most.
approaches to this problem hay,' been*Department of (.\]onlpuler ,~lld S)'steRIS ScieIIC('S, S\[ock.hohn University, Electrnm 23(/, S - 16.t ,In \]<.ISTA, Sweden.I NLP-group, Swedish hmtitute tff Computer Science, Box1263, S 16.1 28 KIST& Stockhohn, Sweden.to const ruc t  a range  of  too ls  that  requ i re  vari-nus degrees of inleraclive support when new lexi-cal entries are created, either from raw text ma-terial (as ill e.g., \['frost & Bnchberger 86, Grosz ctal 87, Wilensky 90\] and tile early work by Zernik\[Zernik ~(," Dyer 85, Zernik 87\]), or from machinereadable dictionaries (see e.g., \[Bognraev el al 87,('.alzolari &" Bindi 90\]).
Although interactive tools|or h'xical acquisition greatly simplifies tile task ofconstructing a lexicon, it.
is desirable to go oue stepfurther and fully remow" the need for user interac-tion.One of the first systems that aimed at construct-ing lexica\] entries automatically from raw text wasGranger's FOUL-U'P system \[Granger 77\].
FOUL-UP extended a lexicon by referring restrictionsplaced on unknown words by instantiating scriptsthat matched the sentences containing the nnknownwords.
This I)uilt on a immber of assumptions whichin general do nol bold, in particular: that all theinformation eeded to create all entry is containedill one text: that no nmrphological information isneeded; tha~ specific (hand-coded) scripts coveringthe domain can be made available in advance, hione of the later approaches to automatic lexical ac-quisition from raw text, \[dacobs ,to Zernik 88\] haveshown the need to consult a variety of knowledgesources such ~s morphological, syntactic, semantic,and contextual knowledge when determining a newlexical entry.This paper describes an automatic nlethod to ac-quire new lexical entries by using analytical learningin coml,inalion wit.h strategies used in an existinginteractive tool for lexical acquisition (VEX \[Carter89}).
In the process of constructing a lexical en-try.
the system combines everal different sources ofinformation: the underlying NL system (CLE, \[Al-shawi red.)
92\]) will contribute information on syn-tactically and semantically permissible phrases andon tile rules for inIlectional nmrl)hology.
The corpuswilt contrihute information on which of these con-structions actually occur.
This information is com-bined with tile the linguistic knowledge ncoded inthe interactive l xical acquisition tool to infer lexicalentries for unknown words m the text.The rest of Ihe paller is laid out as follows: Sec-tion :2 contains information al)out the various ele-ments on which the method is based.
Section 3 de-AcrEs DE COLING-92, NANTES, 23-28 Aot)'r 1992 1 l 7 2 PRec.
el: COLING-92,  NANTES, AUG. 23-28, 1992scribes the method itself and Section 4 reports on For these "paradigm words" only, the complete setthe current state of the implementation, of feature vahles is explicitly specified.2 The  e lements  of  the  scheme2.1 The  Core  Language Eng ine ,  CLEThe Core Language Engine is a general purpose nat-ural language processing system for English devel-oped by SRI Cambridge.
It is intended to be usedas a building block in a broad range of applications,e.g.
data-b~.se query systems, machine translationsystems, text-to-speecb/speech-to-text systems, etc.The object of the CLE is to map certain naturallanguage xpressions into appropriate predicates inlogical form (or Quasi-Logical Form \[Alshawi ,(.
: vanEijck 89\]).
The system is based completely on tmilication and facilitates a reversible phrase-structuretype grammar.The Swedish Institute of Computer ,'qci(m(e haswith support from 8RI generalized the fi'anwworkand developed all equivahmt system for Swedish (theS-CLE, \[Gamback & Rayner 92\]).
The two copies ofthe CLE have been used together to form a machinetranslation system \[Alshawi et a191\].
The S-('LE hasa fairly large gramnmr covering most of the commonconstructions in Swedish.
There is a good treatmentof inflectional morphology, covering all main inflec-tional closes of nouns, verbs and adjectives.The wide range of l)ossihle applications have putsevere restrictions on the type of lexicon that canbe used.
The S-CLE h~ a function-word lexico~Jcontaining about 400 words, including most Swedishpronouns, conjllnctlous, prepositions, determiners,particles and "special" verbs.
In addition, there isa "core" content-word lexicon (with common ouns,verbs and adjectives) and domain specitic h'xica.This part of tbe system is still under developmentand all these content-word lexica together haw, about750 entries.The lexical entries contain information about il~-flectional morphology, syntactic and semantic sub-categorization, anti sortal (selectional) restrictions.Information abont the linguistic properties of an en-try is represented by complex categories that includea principal category symbol and specifications ofcon-straints on the values of syntactic/semantic features.Such categories also appear in the C.LF,'s grammarand matching and merging of the information en-coded in them is carried out by unification duringparsing.
Two categories can be unified if the con-straints on their feature values are compatibleIn the actual "core" and domain Icxica, this infor-mation is kept implicit and represented as pointersto entries in a "paradigm" lexicon with a number ofwords representing basic word usages and inflections.2.2  The Vocabu lary  EXpander ,  VEXIn the English CLE, new lexicon entries can be addedby tile users with a tool developed for the purpose.q'his lexicon acquisition tool, the Vocabulary EX-pander, is fully described in \[Carter 89\].
In parallelwith the development of the S-CLE, a Swedish ver-sion of the VEX system was designed \[Gamback 92\].VEX allows for the creation of lexical entries byusers with knowledge both of a natural anguage andof a Sl)ecilic application domain, but not of linguistictheory or of tile way lexical entries are represented inthe CLE.
It presents examl)le sentences to the userand asks lor information on tile grammaticality ofthe sentences, and for selcctional restrictions on ar-guments of predicates VEX adopts a copy and editstrategy in colmtrnctiug Icxical entries.
It builds onthe "paradigm" lexicon and sentence patterns, thatis, declarative knowledge of the range of sententialcontexts ill which the word usages in that lexiconCall OCCUI'.In the present work we want to investigate towhat extent snch creation of lexicon entries can beperformed with a minimum of user interaction, ln-stead of presenting exaruple sentences to the user weare allowing the program to use a very large textwhere hopefully unknown words will occur in sev-eral ditlbrenl sentence patterns.
This strategy willhe filrther described i~, the following sections.First, however, we will define what we mean bythe notion of (subcategorization) "paradigm".
Tiledefinition we adopt here is based on the one used in\[Carter 89\], namely thatDefinit ion 1a paradigm zs any minimal non.empty intersectionof Icxical entries.
Every category in a pa,'adlgm willoccur in czaclly the same set of entries in the lexiconas every other category Of auy) in that paradigm.Every ent,y consists of a dis3o2ul union of paradigms.lh're, we assume that a lexicon can be describedin terms of (a small set of) sucb paradigms, relyingon ttle fact.
that the open-class words exhibit at leastapproximate r gularities)2.3  The Lex icon  Learn ing  sys tem,  L 2Previous experiments in automatic lexical acquisti-lion at.
S1CS (L ~ - Lexicon Learning) used a set of1 The system does not attempt to cope with c|oaed-categc)rywords.
'\['hey have to be entered into a apecific function-wordlexicon by a skilled linguist.ACTES DE COLING-92, NANTES, 23-28 AO~r 1992 1 1 7 3 I'gOC.
OF COLING-92, NAN'rES, AUG. 23-28, 1992sentences and a formal grammar to infer the lexi-cal categorit.
'-s of the words in the sentences.
Theoriginal idea wa.q to start with an empty lexicon, as-suming that the grammar would place restrictions onthe words in the sentences sufficient to determine anassignment of lexical categories to them \[Rayner elal 88\].
This can I)e viewed as solving a set of equa-tions where the words are variables that are Io beassigned lexical categories and the constraints thatall sentences parse with respect o the grammar arethe equations.Unfortunately, it proved almost impossit,le toparse sentenees containing several nnknown words.For this reason the scheme was revised in severalways \[tlgrmander 88\]; instead of starting with aneu/pty lexicon, the starting point bccanw, a lexi-con coutaining clnsed-cl;kss words snel l  ;L~ l)FOllOIlnS~prepositions and determiners.
The system wouldthen at each stage only process entences that coilrained exactly one unknown word, the hop,, I)eingthat tlie words learned from these sentences wouldreduce the number of unknown words in the otherones.
In addition to this, a rnorphologicat componentw~s included to guide the assignments.
Although theproject proved the femsibility of the scheme, it alsorevealed some of its inherent problems, especially theneed for fa.ster parsing methods.2.4  Exp lanat ion -based  learn ing ,  EBLA problem with all natural language grammars ithat they allow a vemt number of possible con-structions that very rarely, if ever, occur in realsentences.
The application of explanation-basedlearning ~(EBL) to natural language processing al-lows us to reduce tim set of possible analyses andprovides a solution to the parsing inefficiency prob-lem mentioned above (Subsection 2.3).The original idea \[Rayner 88\] was t.o bypass llOl'-lna\] processing and instead use a set of learlled rulesthat perh)rmed the t.~qks of the normal parsing com-ponent, l:ly indexing the learned rules eflicieutly,analysing an input sentence using the learned rules isw~ry much faster than normal processing \[Samuels-son & Rayner 9t\].
The learned rules can be viewedas templates for grammatically correct phrases whichare extracted from the.
granmmr and a set of trainingsentences using explanatiou-bmqed l arning, llere, weassume the following definition:Definit ion 2a ten'tplate ts a generalization constrvcted from lheparse tree for a successfidly processed phrase, .,1 tem-plate is a tree spanning the parse with a mother cat-egory as root and a collection of its ancestor nodes2t~xplanation-lmsed learning is n machine learning tech-Illqlle closely related to tllaCro-operator learllil|g, chtlllkillg,and parliM evaluation and is described in e.g.. \[I)e.long &Mooney 8~';, Mitchell et at 86\].
(at arbitrary, but pre-defined, deep levels of nesting)as I~a~les.The fact that the templates are derived from theoriginal gramlnar guarantees that they represent cor-rect phrlLses and the fact that they are extracted fromreal senteuces ensnres Ihat they represent construc-tions that actually occur.3 Exp lanat ion -basedlexical learning, EBL  2The basic algorithm goes ,xs follows:1.
Using a large corpus from the domain, extractteUll)lates from the sentences contaiuing uo 1.111-known words.2.
Analyse the remaining sentences (the ones con-taiuing unknown words) using the templates,while maintaining an interim lexicon for the un-known words.3.
Compare the restrictions placed on the unknownwords by the analyses obtained with other hand-coded phrase templates pecific for the para-digms m the lexicond.
(2reate "rear' lexical entries from the mforma-ti<m m the intcrhn lcxicon when a full set ofsuch templates \[covering a paradigm) has beenfound.In the following subsections, we will address theseissues in turn.3 .1 Ext rac t ing  templates  f roma domain -spec i f i c  corpusA typical situation where we think that this methodis well suited is when a general purpose NL systemwith a core lexicon (such as the S-CLE) is to be cus-tomized to a specific application domain.
Tile vocab-ulary used in the domain will include e.g.
technicalterms that are not present in the core lexicon.
Also,the use of the words in the core lexicon may differbetween domains.
In addition to this, some typesof gralnmatieal coustrilcts may be more eonllnon illone domain than ill allother.
We will try to "get theflavour of the language" in a particular applicationeuviromnenl from domain-specific texts.The corpus is divided into two parts: one withseatellces containing ilnknown words, all(\] anotherwhere all the words are known, The latter groupis used to extract plmme templates that capturetile grammatical constructions occurring in tile do-main.
rFhe process of extracting phrase templatesfrom training sentences i  outlined in Subsection 2.4.AcrEs nl~ COTING-92, NAt,rl~s, 23-28 Ao(rr 1992 1 !
7 4 PRec.
OF COLING-92, NAmV:s, AUG. 23-28, 19923.2 Analysing theremaining sentencesAssuming that a partieular set of phrase tenlplalesis applicable to a sentence containing an unknownword will associate a set of constraints with the word.Naturally, the constraints Oil I\[le kBowlt words ofthe sentence should be satisfied if this tcmplatv isto be e(msidered.
3 This will correspond to a partic+-ular parse or analysis of the seutenee.
Thus a sol ofconstraints i a.ssociated with each different pm'seA number of entries in the prot.otype i xicou willmatcll the set of constraints associated with a sen-teuce.
\['\]aeh prototyI)e is all illCal'llatioIl of il paradigtn, Thus we can a.ssociate a word with a set ofparadigms.
(Note thai the paradigms may be non-exclusive.)
All such +msociatious (corresponding todifferent parses of the same sentence) are collected,and used to update the+ interim h'xieon.'\['h(!
IllOSt obv ious  cons l ra iu ts  colnt!
frol l l  syllt{ictie considerations.
If, in Ihe sentence John loves a ca(the word loves were unknown, while the other wordsdid indeed have the obvious lexicai entries, the grammar will require loves to be a transitive verb of thirdperson singular agreement.
Since the prototYl)eS ofverbs are iu tl,e imperative form, we nmst associatea finite verb form with the imperatiw~, This is doneby applying a omrphologieal rule that strips the '-s'from the word loves, reinforcing the hypothesis andgaining the tense information in the process.Now, this ntorphological information lnay seemuniml)ortant in Fnglish, but it definitely is +lol it,Swedish: a word with more that+ one sy\]lal,h+ end-ing with '-or' has to be an in(h.finite common gel,dernoun.
If it is not of latin origin it lnusl, be a phiral form an(I thus ils entire morl)hology is kJvm, nThe odds that it is a countabh" noun (like d.ck), as(}\[)posed tO 1t l l laSS IIOIln (such {IS walev), ;ll'C ()vet"whehning.3.3 Constructing lexical entriesDuring tile analysis of the set of sentences conlain-ing unknown words, an interim lexicon for these un-known words is kept.
The interim lexieon is imlexedon word sterns and updated each t i t l ie a IWW Sellfence is i)roeessed.
\["or each word  sI, eul+ t'e/o piecesof information are retained in this lexicon: a hypo-thesis about which paradigm or set.
of paradigms lheword is assumed to belong to, and a justifieat.ion Ihatencodes all evidence relevant to the word.
The jnsti-fieation is used to make the hypothesis aml is maintained so that the entry may be Ul)(lat, ed whett newinlbrmation about tim word arrives.
When all thel)hrase templates (sentence patterns) for lhlfilhnent3 UldeSs tile)' Ih) ill fact COll't!sp(lltd to othtT llr)ll lexicaliz,:dSl?llSeS of tile word, in' to hO|llO~l.&l)hS,of a Sl)ecilic para(ligm have been found, an entry forthe word is made in the domaimspecifie lexicon thatis bcmg constructed.
This is done while still keepingthe justilication reformation, since this might con-taht evidence indicating other word-senses or holno-graphs4 hn I ) lementat ion  s tatusA prelimiuary versi(~u of the lexieal acquisition systern has been implemented in Prolog.
"File meal-tile ext rac t ing  te lnp la tes  f ro ln  Se l l tences  w i th  knowl lwords is \[uily operational.
The parser for sentenceswitil unkuown words has also been tested, while tileiaterim lexicon still is subject to experimentatiolLPresenl.ly, a w'ry siml)le strategy for the interiln lex-icon has been tesled.
This version uses the set ofall hypotheses ns the justification and use their dis-.itmetion as the era'rent hypothesis.
We are currentlyworking Oll extending this sd len le  to one incorporat-ing the full algorithm deseril)ed above.Unknowu wor(l~ are matched with tim subcalego-rizatiou paradigms of the S-CLE.
In total 62 differ-enl synl.aet.ic/semantic paradigms are known by thepresent systmn: 5 for Swedish nmms, l0 for adjec-tives, aud all tim others for verbs.
Tim morphologi-cal inflections are subdivided into 14 different inflec-tional cbLsses of nouns, 3 classes of adjectives, and 24classes of verbs.5 Conclus ionsWe have (mt.lin<'d a method for autonlatic lexieal ae-(luisilion.
An existing lexicon built on the usageof i)rolotypica\] entries for l)aradigms of opemela.sswords, is ext.end~'d b 5 infi~rring new lexical entriesfl'OIII tex ts  conta in ing  Dnk l /own words.
The COll-straints placed on these words by the gramnlar arccompared with the prototypes and a hypothesis ismade al)ouI what paradigm the word is most likelyto l)olong to.The hy\]lotheses ai)otlt, the ilnknown words arekept+ m an interim lexicon until a suflicient level ofconfidence is reached.
Phrase templat<~s are bothhand-cod<+d aud extracted front the grammar anddonlaiu-spt!citic texts using an explanation-basedh,arning method.6 AcknowledgementsThe work reported here was fimded by the Founda-tion tot the Swedish Institute of Computer Scienceaud the Swedish National Board for Industrial andT<,ch nical l)evelol)mel\]t ( NUTEK).Aeries nE COLINGO2.
N,~t~"nis, 23-28 ^ ot~rl 1992 1 l 7 5 I)roc.
OF COLlNG-92, NANTES, AU().
23-28, 1992We would like to thank Manny Rayner and DavidCarter (SRI Cambridge) and Seif llaridi (SICS) forhelpful discussions and suggestions, and Pierre Gan-der (Stockholm University) for valuable supl)ort.ReferencesAlshawi, 11. and J. van Eijek (1989).
"Logical t"ormsin the Core Language I';ngine", the 271h An-nual Meeling of the Association for Coalpala-tional Linguistics, Vancouver, llritish Columbia,pp.
25- 32.Alshawi, tl., D. ('.after, B. Gaml)iiek and M. Ray-net 11991 ).
"Translation by Quasi Logical FormTransfer", the ~9lh Annual Meeting of th~ Asso-ciation for Computational Li)tgaisltes, Univer-sity of California, Berkeley.
California, pp.
161..168.Alshawi, I1.
(ed.)
(1992).
7'h~ Core LangttageEngine, C'ambridge.
Massachusetts: The MITPress.Boguraev, B., T. tlriscoe, J. Carroll, D. Carterand C. Grovcr (1987).
"The Derivation of aGrammatically Indexed Lexicon from the Long-lnan Dictionary of Contemporary English", the251h Annual Meeting of the Associattoa forComputational Linguistics, Stanford, Califor-nia, pp.
193-200.C.arter, D. 11989).
"Lexical Acquisition in the (_loreLanguage Engine", the 4th Conference of theEuropean Chapter of the Association Jbr Com-putational Liaguisttcs, Manchester, Eugland,pp.
137- 144.
Also available as SRI lnternat ioaa\[Report CCSRC-012, Cambridge, EnglandCalzolari, N. and R.. Bindi (1990).
"Aequisilionof Lexical Information from a Large TextualItalian Corpus", Ihe 131h International Con-ference on Computational Linguistics, lh'lsinki,Finland, Vol.
3, pp.
54 59.DeJong, G and R. Mooney 11986).
"ExplanationBased Learning: An Alternative View".
Ma-chine Learning, 1:145-- 176.Ganfl)~ck I:L and M. ll.ayner (1992).
"The SwedishCore Language Engine", the 2rd Nordic Confer-ence of Tex!
Comprehension i  Man aad Ma-chine, LinkSping, Sweden.Gamb/iek B.
(1992).
"I,exieal Acquisition: TheSwedish VEX System", the 2rd Nordic Confer-ence of Tert Comprehension i  Man and Ma-chine.
LinkiSpiag, Sweden.Granger, R.It.
(1977).
"FOlrl,-UP: A program thatfigures Otlt meallings of words from colltex(',the 5tb lnter~*atio)ml Joint Conference on Ar-tificial Intelligence, Cambridge, Massachusetts,pp.
172- 178.Grosz, B.J., D.E.
Appelt, P. Martin, andF.C.N.
Pereira 11!)87).
"TEAM: An Experi-ment in the Design of Transportable Natural-Language Interfaces", Artificial Intelligence,32:173 243.tl6rmander, S. 11988).
"The Problems of Learninga 1,exicou with a Formal Grammar", SICS R,e-search l/eport R88019, Stockholm, Sweden.Jacob.~.
P. a~l?l U. Zernik 11988).
"Acquiring LexiealKnowledge from Text: A Case Study", the 7thNational Conference on Artificial Intelligence,Saint Paul, Minnesota, pp.
739 744.Mitchell, T.M., ItM.
Keller and S.T.
Kedar-Cabelli(1986).
"Explanation-ltased Generalization: AUnifying View".
Machine Learning, 1:47 80.Rayner, M. 11988).
"Applying Explanation-BasedGeneralization to Natural-Language Process-ing", the lntcrnalional Conference on FifthGeaeration C'ompuler Systems, 'lk)kyo, Japan,pp.
1267- 1274Rayner, M., /~.
Hugosson and G. Ilagert (1988).-lIsmg a Logic Grammar to Learn a Lexicon",the 12th International Conference on Computa-tional Linguistics Budapest, llungary, pp.
524-529  Also available ,as SICS Research Report -R88001, Stockhohu, Sweden.Samuelsson, C. and M. Rayner (1991).
"Quantita-tive Evaluation of Explanation-Based Learninga~ an Optimization Tool for a Large-Scale Nat-ural i,anguage System", the 12th InternationalJotnl Conference on Artificial Intelligence, Syd-ney, Australia.Trost.
tl.
and E. Buchberger 11986).
"Towardsthe Automatic Acquisition of Lexieal Data",the l lth International Conference on Computa-tional Linguistics, ltonn, Germany, pp.
387 389.Wilensky, R. (1990).
"Extending the Lexicon byExploiling Subregnlarities", the DA RPA Speechand Natural Language Workshop, llidden Val-ley, Pennsylvania, pp.
365-370.Zernik, U. and M. Dyer 11985).
'"lbwards a Self-Extending Lexicon", the 22rd Annual Meetingof the Associatio~t for Computational Linguis-tics, University of Chicago, Chicago, Illinois,pp 284 292.Zernik, U.
(1987).
"l:mguage Acquisition: Learninga lIierarehy of Phrases", the lOth InternationalJoint Conference o)1 Artzficial lntelliqence, Mi-lan, italy, pp.
125 131ACTXS DE COLING-92, NAN'W.S, 23-28 AO(Yr 1992 1 I 7 6 PROC.
OF COLING-92, NANTES, AUG. 23-28, 1992
