MCDONNELL DOUGLAS ELECTRONIC SYSTEMS COMPAN YMUC-4 TEST RESULTS AND ANALYSISAmnon Meyers and David de HilsterMcDonnell Douglas Electronic Systems CompanyAdvanced Computing Technologies Lab1801 E. St .
Andrew PlaceSanta Ana, CA 92705-6520(vox, hilster)@young .mdc.com(714) 566-5956RESULTSOur test results for TST3 and TST4 were as follows :TST3 Recall Precision OvergenerationMATCHED/MISSING 20 60 1 3MATCHED/SPURIOUS 41 30 5 7MATCHED ONLY 41 60 1 3ALL TEMPLATES 20 30 5 7SET FILLS ONLY 24 69 14STRING FILLS ONLY 13 46 1 6F-MEASURESP&R24 .02P&R27.27P&2R21 .4 3TST4 Recall Precision OvergenerationMATCHED/MISSING 23 63 1 1MATCHED/SPURIOUS 46 32 56MATCHED ONLY 46 63 1 1ALL TEMPLATES 23 32 56SET FILLS ONLY 26 70 1 2STRING FILLS ONLY 18 59 1 5F-MEASURESP&R26.762P&R29.68P&2R24 .37Our MUC4 TexUS system not only incorporates many of the concepts, knowledge, and algorithm sfrom our MUC3 INLET system, but also represents our first version of a domain-independent end-to-endnatural language processing capability.
Although we are excited that our system correctly process tex tfrom the lexical to the discourse level for the first time, we stress that the MUC4 system is a frameworkthat will not be complete until the end of the year .
Relative to MUC3, our scores reflect an increase i nprecision due to our system's end-to-end completeness, and a lowering of recall due to the curren tincompleteness of our knowledge base and implementation .
As TexUS nears completion, we expect ourperformance on the MUC4 task to improve substantially .TEST SETTING SNo test settings were incorporated during testing .11 3EFFORTA total of 3 .5 person-months were expended during our MUC4 customization effort.
Five peoplewere involved in MUC4 related activities: Amnon Meyers (task leader, analyzer, knowledge addition) ,David de Hilster (analyzer, knowledge addition, testing)?
Charlene Kowalski and Laurie Johnston (corpusstudy, knowledge addition), and George Vamos (automated testing) .LIMITING FACTORSThe greatest limiting factor for us again was time.
Development of our new system TexUS reflect sabout one man-year of development and less than 4 man-months for the MUC4 task.
Nevertheless, in aperiod of less than two months with a total of 3 persons, TexUS received a new and very thorough lexicalprocessor and new baseline semantic and discourse processors .
According to our development plans, th eperformance of the system should match that of the best participants at MUC4 by the end of 1992 .TRAINING THE SYSTE MExtensive testing facilities were set up to automatically run and score TexUS on all 1300 message sof the development corpus.
Testing was distributed on 5 to 9 Sun workstations (running in the background)processing 1300 messages within 6 to 10 hours.
In addition, any 100 message set could be distributed,processed, and scored within one hour .Another program for testing key phrases, linguistic phenomena, and slot fills, was also set up t omonitor the consistency and progress of TexUS .
These tests consist of pairs of small hand-made MUC4templates and their corresponding key-templates.
The current version of TexUS is then run on these hand-made templates and the differences printed out to monitor progress .
One advantage of this testing format isthat performance on individual slots is easy to isolate .Due to a lack of time and incompleteness of the current system, the testing facilities were no textensively used prior to the official testing .
The few times they were used on all 1300 messages of thedevelopment set, the results provided useful feedback.
These tools, in conjunction with the developmen tset, will be used extensively between MUC4 and MUC5 to monitor and speed development of our system .SUCCESSES AND NON-SUCCESSE SOur greatest success was in the fact that our system is now an end-to-end system .
Last year wit honly the pattern matching algorithm complete, we quickly reached the limitations of such a capability an dour score could not go much higher without MUC-specific prodding.
This year's system, TexUS, being acomplete end-to-end system, has great potential to grow and score much higher than last year's system.The lack of development time was the major cause of our difficulties .
We needed more time to addknowledge and expand the linguistic coverage of the system .REUSABILIT YOne of TexUS' greatest strengths is its portability to new domains.
TexUS not only is written in Cand can be compiled into any C or C++ program, but it also is domain-independent.
Only threecustomization tasks were needed to perform the MUC4 task : identification of key words and concepts,special semantic classification of words for the MUC4 domain, and a post-processing module to conver tgeneric output to MUC4 output.Less than 10 percent of the current code is dedicated to MUC4-like processing, 90 percent of whic hconsists of template generation and merging as dictated by MUC4 template guidelines.
The time needed tocustomize TexUS to a new domain is a matter of a few man-months, as demonstrated by our system duringMUC3 and MUC4.
Development time is cut further by the use of our graphic interface tools .114LESSONS LEARNED?
At MUC3, we fielded a system with limited potential, and substantially achieved that potential.
AtMUC4, we have fielded a system with far greater potential, but have not yet achieved that potential .
?Regarding the MUC task, we realize that greater manpower resources will be required to achiev ethe performance of top-ranking systems .?
As in MUC3, MUC4 demonstrates the importance of test and evaluation in driving development .115
