EXPLORER: A Natural Language ProcessingSystem for Oil ExplorationWendy G. LehnertDepartment of Computer and In fo rmat ion  Sc iencesGraduate Research CenterUniversity of MassachusettsAmherst ,  Mass.
01003Steven P. ShwartzCogn i t ive  Systems Inc .234 Church St reetNew Haven, Ct.  06510EXPLORER (Lehnert  and Sbwartz ,  1982;Shwartz 1982) is  a non- f rag i le ,  'bands -on"language ana lys i s  system that  a l lows o i lexp lora t ion is ts  w i th  no knowledge of computersor  computer progra- .
- ing  to c reate  customizedmaps.
Users in Tu lsa ,  Denver, and New Or leanscur rent ly  have d ia l -up  access  to a DEC-20where EXPLORER is  implemented in TLISP.
Auser  converses  wi th  EXI~LORER about ?
des i redmap unt i l  both par t ies  have agreed on anadequate and unambiguous set  ofspecifications.
Another phone link thencarries EXPLORER's output to an IBM 3033 whichruns database re t r ieva l  rout ines  on co~aerc ie lwel l  data .
When a l l  the in fo rmat ion  has beensecured from wel l  data ,  a g raph ics  systemtakes  over to perform the actua l  mapgenerat ion .
EXPLORER is  cur rent ly  undergo ingeva luat ion ,  and i t  is  ta rget ted  for  a 1983i ns ta l la t ion  in a l l  reg iona l  o f f i ces  of amajor o i l  company* for  res t r i c ted  use bygeo log is ts  and geophys ic i s ts .Since our intended user  popu la t ion  isnaive about computers ,  EXPLORER's in teract ivedes ign is  dominated by "user-friendly"features.
EXPLORER processes informationre t r ieva l  requests  s ta ted  in Eng l i sh ,  w i thoutimposing vocabu lary  l im i ta t ions  or syntact i cres t r i c t ions  on the user .
Using a 7000-wordd ic t ionary ,  EXPLORER makes in fe rences  aboutwhat a user is saying and initiatesi n te ract ive  d ia logues  when m:p spec i f i ca t ionsare not adequate or potent ia l l y  ambiguous.While "user-friendly" system des ignso f ten  accomodate novice users  at the expenseof e f f i c ient  in teract ions  with expert  users ,EXPLORER naturally tunes itself to both noviceand expert users.
An expert can state arequest  very conc ise ly ,  wi thout  a longin teract ive  sess ion ,  whi le a novice is  guidedby a quest ion -and-answer  d ia logue .
Since a l lusers  are expected to enter  mispe l l ings  andtypos, an intelligent spelling correctorenables the user to correct typographicalerrors quickly and easily.
*A proprietary agreement forbids us fromidentifying them.Once a request  has been analyzed by EXPLORER,the user  is  g iven an oppor tun i ty  to ver i fyEXI~LORER*s unders tand ing  of that  request  ormake changes as needed.The following example will illustrate thecomplexity of the map requests that EXPLORERi s  des igned to hand le .
Fo l lowing the input ,EXPLORER d isp lays  i t s  in terpretat ion  of therequest  fo r  ver i f i ca t ion  by the user .EXPLORER Version 02 9/23/81READY*Show me a map of all tight wells drilled*before May I, 1980 but since May I, 1970*by texaco that  show o i l  deeper  than 2000",*ere themselves  deeper than 5000", are now*operated  by she l l ,  are w i ldcat  we l l s  where*the operator  repor ted  a dr i l l i ng  problem,*and have mechanica l  ogs ,  d r i l l  stem tes ts ,*and a commercial  o i l  ana lys i s ,  that  were*dr i l l ed  w i th in  the area def ined by la t i tude*30 deg 20 min 30 sec to 31:20:30 and"80-81. sca le  2000 lest.By FEST, do you mean FEET (Y or N) *yUser requests  a POSTED mapla t i tude  30.34167 - 31.34167long i tude  80 - 81output  medium: PAPERoutput device: PHOTODOTfilters: DRILLING DEPTH > 5000 FEETCOMPLETION DATE >- 5/I/1970COMPLETION DATE < 5/I/1980OIL ANALYSIS AVAILABLEDRILL STEM TESTS PERFORMEDMECHANICAL LOG FILE WELLDRILLING PROBLEMWILDCAT WELLSHELL CURRENT OPERATORWELL SHOW OF OIL > 2000"TEXACO ORIGINAL OPERATORTIGHT HOLE WELLscale of I" = 2000.0"69As th i s  example shows, EXPLORER canhandle long and ungrammat ica l  requests ,  makein ferences ,  and perform compl icated  word sensedisambiguation.
For example, the word "show"has two distinct meanings in the aboverequest.
The first instance of "show" issynonymous with "display", whereas the secondtime "show" is used i t  has a technical meaning(i.e., an indicator of oil or gas in a well).The sur round ing  conceptua l  context  i s  used todetermine which sense of "show" i s  appropr ia tein each case .We suspect expert users who utilizeEXPLORER regularly will develop a feel forEXPLORER's limitations and flexibilities.
Ifsuch a user wants to enter a request asefficiently as possible, EXPLORER will handle"telegraphic" English which does not have toconform to standard syntact i c  conventions:EXPLORER Version 02 9/23'/81READYPlease input county or counties by name ornumber.
*BibbBibb County is  in  the fo l low ing  s ta tes :ALABAMA GEORGIAPlease input the appropriate state or a newcounty specification.
*make i t  new haven,  c t .A contour  in terva l  was not spec i f ied .Would you like the CI from the prev iousrequest?
(?
or N)Previous CI = tO0"*yA scale was not spec i f ied .Would you like the sca le  from the prev iousrequest?
(Y or  N)P rev ious  sca le  - 2000.0 FT-PER-IN*tcg bibb georg ia  ci 100 scale 2000.
*yUser requests a STRUCTURE mapoutput-medium: PAPERoutput  device: PHOTODOTcounty:  BIBB, GEORGIAon TCGCI - I00"scale of i" - 2000.0"User requests  a STRUCTURE mapoutput  medium: PAPERoutput  dev ice :  photodotcounty :  NEW HAVEN, CONNECTICUTon TCGCI - I00"scale of i" = 2000.
9"As long as the request is conceptuallycoherent and unambiguous, EXPLORER will beable to handle a wide range of stylisticconstructs.
This last request wassufficiently specified for EXELORER tointerpret it without further user interaction,but many requests (especially those generatedby novice users) are likely tO require aninteractive dialog.
For example, thefollowing interaction might take place with anextremely novice user:EXPLORER Version 02 9123/81READY~Map the to&.A map region was not specified.Do you want the same geographic region as thelast request (Y or N)?
*nDo you wish to specify the map region bycounty or by geographic coordinates?
*cEXPLORER will query a user as needed toget missing information and resolve anyambiguities that may be present.
Notice thatEXPLORER naturally offers the user an optionof inheriting many specifications from theprevious map request.
Explorationists oftenfind it useful to examine a sequence ofrelated maps, so our interface has beendesigned to make map sequences easy togenerate.EXPLORER has been undergoing an initialtest phase since July 13, 1982.
During thistime a variety of oil company employees havedialed up the program and entered maprequests.
While we do not yet have enoughtest requests for a comprehensive evaluationof the system, we have analyzed EXPLORER'sperformance over the three-week period from7/13/82 tO 8/6/82 in an effort to assess itsstrengths and weaknesses.
During this time 39requests were successfully transmitted toEXPLORER by 8 different individuals.
In orderco evaluate EXPLORER's performance, we willconsider the following categories ofperformance:(Al) original input is interpreted correctlyon the first try - perfect performance.70TABLE - 1REQUEST TYPE NO.
OF REQUESTS SURFACE INTERACTIVE CONCEPTUALAI 4 (10%)A2 26 (67%)A3 9 (23%)to ta l  39 (I00%)(AZ) or ig ina l  input  is i n te rpreted  cor rec t lya f te r  one or more c la r i fy ing  in ter -ac t ions .
These in teract ions  may be dueto typ ing  er rors ,  spe l l ing  er rors ,miss ing  in fo rmat ion ,  or system er rors .
(A3) o r ig ina l  input  i s  never  in terpretedcor rec t ly  due to a system fa i lu re  ofsome sor t .I f  a request  can be categor i zed  as an AI or A~request ,  EXPLORER i s  fu l l y  funct iona l  eventhough i t  may make a mis take  at  some po in t  ini t s  p rocess ing .
For example ,  i f  EXPLORER doesnot recogn ize  a word, i t  w i l l  query  the userfor  synonyms.
I f  one of the  synonyms isrecogn ized ,  EZLPORER recovers  from i t s  ownrecogn i t ion  er ror ,  and the request  will becategor i zed  as an A2 request .
When a systemer ror  i s  fa ta l  in  the sense  that  the  user  doesnot or cannot  recover  from i t ,  we categor i zethe request  as an A3 request :  an A3 requestshou ld  not resu l t  in  map generat ion .
We haveomi t ted  from th i s  ana lys i s  any requests  Chatwere abor ted  due to t ransmiss ion  er rors  oruser - in i t ia ted  in ter rupts .In  add i t ion  to our th ree  per formancecategor ies ,  we w i l l  character i ze  the genera lcomplex i ty  of a request  in th ree  ways:\[I\] Surface Complexity:The number of words in the originalinput request .\[2\] In teract ive  Complex i ty :The number of complete  in teract ionsbetween the user  and EXPLORER dur inga s ing le  request  d ia log .\[3\] Conceptual Complexity:The number of lines generated in thetarget query language.We realize that some users will try tomaximize efficient communication by minimizingthe number of complete  interactions.
At thesame time, still other users will find iteasier to enter a minimal request and let thesystem ask for more information as needed.
Sowhile there is an apparent trade-off betweenthe length of the initial request (surfacecomplexity) and the number of interactionsneeded to fully interpret that request(interactive complexity), we cannot evaluateEXPLORER's effectiveness by trying to minimizeone or the other.19(15-25) 3(3-3) 9(9-10)22(1-87) 7(3-14) 11(9-22)37(9-57) 8(5-12) 12(10-L4)25(1-87) 7(3-14) 11(9-22)We must also note  that  conceptualcomplex i ty  as i t  i s  de f ined  here can on ly  g ivea very  rough idea  of the  conceptua l  contentand in fo rmat ion  process ing  invo lved .
It mightbe tempt ing  to look  fo r  conceptua l  complex i tyas a function of surface complexity andi n te ract ive  complex i ty ,  but any s imp ledecomposition along these lines will bemisleading- If a user changes the scale of amap I0 times, we will see a large interactivecomplexity with no change in conceptualcomplex i ty .
A more sens i t i ve  set  ofcomplex i ty  measures  w i l l  have co be des ignedbe fore  we can expect  to see cor re la t ionsacross  the  var ious  measures .The resu l t s  of our  t r ia l  tes t  per iod  aresue~ar i zed  in  Tab le  1.
We see that  theaverage  sur face  complex i ty  of a l l  requests  i s25 words ,  w i th  requests  rang ing  from I to 87words in  length .
Each request  averaged 7complete  in teract ions ,  w i th  some tak ing  as fewas 3 and o thers  requ i r ing  as many as 14user - in teract ions .
The ta rget  query  languagerequests  averaged l l  l i nes  of code,  w i th  arange  between 9 and 22 l ines .In  terms of per formance  categor ies ,  fu l l y67% of a l l  requests  were A2 requests .
Only10% qua l i f i ed  as AI requests ,  w i th  theremain ing  23% fa l l ing  in to  the A3 category .A~ requests  tended co be s l ight ly  morecompl i ca ted  on average  than A2 requests ,  buti t  i s  impor tant  Co note chat  the most complexrequests  in  terms of a l l  th ree  measures  werenever the less  A2 requests .
The re la t ive lysmal l  precenCage of AI requests may not besignificant given the size of our sample, butit is likely that the failed A3 requests wouldhave been A2 requests  had they been processedsuccess fu l l y .
As the sys tem's  h i t  ra teimproves ,  we expect  to see the A2 ra te  r i sewhile the AI rate remains stable.
It isi n te res t ing  co note that  the average  sur facecomplexity of the AI requests is very close ~othe average surface complexity of the A2requests .Almost a l l  of the er rors  under ly ing  ourA3 requests  were programmer er rors  due to animper fec t  unders tand ing  of user  vocabu lary  orthe ta rget  query language.
This  was expectedand can on ly  be rec t i f i ed  w i th  cont inuedtes t ing  by qua l i f i ed  users .
We are ext remelyp leased  to have a 77% success  ra te  at th i sin i t ia l  s tage  of program tes t -deve lopment :EXPLORER's e r ror  ra te  shou ld  decrease  overtime as changes are made to correct the errorswe uncover .71Our exper ience  wi th  EXPLORER suggeststhat  i t  is imposs ib le  to complete a system ofthis complexity without some such testingphase for feedback purposes.
A high degree ofcooperation between program designers andintended users is therefore critical in thesefinal stages of system development.Our next step is to continue testingrevised versions of EXPLORER, expanding ouruser  popu la t ion  as the system becomes morecompetent .
At the cur rent  ra te  of userfeedback,  we pro jec t  a 3-6 month per iod  ofsystem rev is ions  be fore  we f reeze  theimplementat ion  fo r  a f ina l  eva luat ion .REFERENCESLehner t ,  W. and $hwartz ,  S. (1982) .
Natura lLanguage Data Base Access w i th  Pear l .Proceedings of the Ninth InternationalConference on Computational Linguistics.Prague,  Czechos lovak ia .Shwartz, $.
(1982).
Problems withdomain-independent natural , languagedatabase  access  sys tems.
Proceedings  ofthe Assoc ia t ion  for  Computat iona lL ingu is t i cs .
Toronto ,  Canada.7!
