Proceedings of the EACL 2012 Joint Workshop of LINGVIS & UNCLH, pages 35?43,Avignon, France, April 23 - 24 2012. c?2012 Association for Computational LinguisticsAutomating Second Language Acquisition Research:Integrating Information Visualisation and Machine LearningHelen YannakoudakisComputer LaboratoryUniversity of CambridgeUnited KingdomHelen.Yannakoudakis@cl.cam.ac.ukTed BriscoeComputer LaboratoryUniversity of CambridgeUnited KingdomTed.Briscoe@cl.cam.ac.ukTheodora AlexopoulouDTALUniversity of CambridgeUnited Kingdomta259@cam.ac.ukAbstractWe demonstrate how data-driven ap-proaches to learner corpora can supportSecond Language Acquisition researchwhen integrated with visualisation tools.We present a visual user interface support-ing the investigation of a set of linguisticfeatures discriminating between pass andfail ?English as a Second or Other Lan-guage?
exam scripts.
The system displaysdirected graphs to model interactionsbetween features and supports exploratorysearch over a set of learner scripts.
Weillustrate how the interface can supportthe investigation of the co-occurrenceof many individual features, and discusshow such investigations can shed light onunderstanding the linguistic abilities thatcharacterise different levels of attainmentand, more generally, developmental aspectsof learner grammars.1 IntroductionThe Common European Framework of Referencefor Languages (CEFR)1 is an international bench-mark of language attainment at different stages oflearning.
The English Profile (EP)2 research pro-gramme aims to enhance the learning, teachingand assessment of English as an additional lan-guage by creating detailed reference level descrip-tions of the language abilities expected at eachlevel.
As part of our research within that frame-work, we modify and combine techniques devel-oped for information visualisation with method-ologies from computational linguistics to supporta novel and more empirical perspective on CEFR1http://www.coe.int/t/dg4/linguistic/cadre en.asp2http://www.englishprofile.org/levels.
In particular, we build a visual user in-terface (hereafter UI) which aids the develop-ment of hypotheses about learner grammars us-ing graphs of linguistic features discriminatingpass/fail exam scripts for intermediate English.Briscoe et al (2010) use supervised discrimi-native machine learning methods to automate theassessment of ?English as a Second or Other Lan-guage?
(ESOL) exam scripts, and in particular, theFirst Certificate in English (FCE) exam, whichassesses English at an upper-intermediate level(CEFR level B2).
They use a binary discrimina-tive classifier to learn a linear threshold functionthat best discriminates passing from failing FCEscripts, and predict whether a script can be clas-sified as such.
To facilitate learning of the clas-sification function, the data should be representedappropriately with the most relevant set of (lin-guistic) features.
They found a discriminative fea-ture set includes, among other feature types, lexi-cal and part-of-speech (POS) ngrams.
We extractthe discriminative instances of these two featuretypes and focus on their linguistic analysis3.
Ta-ble 1 presents a small subset ordered by discrimi-native weight.The investigation of discriminative features canoffer insights into assessment and into the linguis-tic properties characterising the relevant CEFRlevel.
However, the amount and variety of datapotentially made available by the classifier is con-siderable, as it typically finds hundreds of thou-sands of discriminative feature instances.
Evenif investigation is restricted to the most discrim-inative ones, calculations of relationships be-3Briscoe et al (2010) POS tagged and parsed the datausing the RASP toolkit (Briscoe et al, 2006).
POS tags arebased on the CLAWS tagset.35tween features can rapidly grow and become over-whelming.
Discriminative features typically cap-ture relatively low-level, specific and local prop-erties of texts, so features need to be linked to thescripts they appear in to allow investigation of thecontexts in which they occur.
The scripts, in turn,need to be searched for further linguistic prop-erties in order to formulate and evaluate higher-level, more general and comprehensible hypothe-ses which can inform reference level descriptionsand understanding of learner grammars.The appeal of information visualisation is togain a deeper understanding of important phe-nomena that are represented in a database (Card etal., 1999) by making it possible to navigate largeamounts of data for formulating and testing hy-potheses faster, intuitively, and with relative ease.An important challenge is to identify and assessthe usefulness of the enormous number of pro-jections that can potentially be visualised.
Explo-ration of (large) databases can lead quickly to nu-merous possible research directions; lack of goodtools often slows down the process of identifyingthe most productive paths to pursue.In our context, we require a tool that visu-alises features flexibly, supports interactive inves-tigation of scripts instantiating them, and allowsstatistics about scripts, such as the co-occurrenceof features or presence of other linguistic proper-ties, to be derived quickly.
One of the advantagesof using visualisation techniques over command-line database search tools is that Second Lan-guage Acquisition (SLA) researchers and relatedusers, such as assessors and teachers, can accessscripts, associated features and annotation intu-itively without the need to learn query languagesyntax.We modify previously-developed visualisationtechniques (Di Battista et al, 1999) and build avisual UI supporting hypothesis formation aboutlearner grammars.
Features are grouped in termsof their co-occurrence in the corpus and directedgraphs are used in order to illustrate their rela-tionships.
Selection of different feature combi-nations automatically generates queries over thedata and returns the relevant scripts as well as as-sociations with meta-data and different types oferrors committed by the learners4.
In the next sec-4Our interface integrates a command-line Lucene searchtool (Gospodnetic and Hatcher, 2004) developed by Gramand Buttery (2009).Feature ExampleVM RR (POS bigram: +) could clearly, because (word bigram: ?)
, because ofnecessary (word unigram: +) it is necessary thatthe people (word bigram: ?)
*the people are cleverVV?
VV?
(POS bigram: ?)
*we go see filmNN2 VVG (POS bigram: +) children smilingTable 1: Subset of features ordered by discriminativeweight; + and ?
show their association with eitherpassing or failing scripts.tions we describe in detail the visualiser, illustratehow it can support the investigation of individualfeatures, and discuss how such investigations canshed light on the relationships between featuresand developmental aspects of learner grammars.To the best of our knowledge, this is the firstattempt to visually analyse as well as performa linguistic interpretation of discriminative fea-tures that characterise learner English.
We alsoapply our visualiser to a set of 1,244 publically-available FCE ESOL texts (Yannakoudakis et al,2011) and make it available as a web service toother researchers5.2 DatasetWe use texts produced by candidates taking theFCE exam, which assesses English at an upper-intermediate level.
The FCE texts, which arepart of the Cambridge Learner Corpus6, are pro-duced by English language learners from aroundthe world sitting Cambridge Assessment?s ESOLexaminations7.
The texts are manually taggedwith information about linguistic errors (Nicholls,2003) and linked to meta-data about the learners(e.g., age and native language) and the exam (e.g.,grade).3 The English Profile visualiser3.1 Basic structure and front-endThe English Profile (EP) visualiser is developedin Java and uses the Prefuse library (Heer etal., 2005) for the visual components.
Figure 1shows its front-end.
Features are represented5Available by request: http://ilexir.co.uk/applications/ep-visualiser/6http://www.cup.cam.ac.uk/gb/elt/catalogue/subject/custom/item3646603/7http://www.cambridgeesol.org/36Figure 1: Front-end of the EP visualiser.by a labelled node and displayed in the centralpanel; positive features (i.e., those associated withpassing the exam) are shaded in a light greencolour while negative ones are light red8.
A fieldat the bottom right supports searching for fea-tures/nodes that start with specified characters andhighlighting them in blue.
An important aspect isthe display of feature patterns, discussed in moredetail in the next section (3.2).3.2 Feature relationsCrucial to understanding discriminative featuresis finding the relationships that hold betweenthem.
We calculate co-occurrences of features atthe sentence-level in order to extract ?meaningful?relations and possible patterns of use.
Combi-nations of features that may be ?useful?
are keptwhile the rest are discarded.
?Usefulness?
is mea-sured as follows:Consider the set of all the sentences in the cor-pus S = {s1, s2, ..., sN} and the set of all the fea-tures F = {f1, f2, ..., fM}.
A feature fi ?
F isassociated with a feature fj ?
F , where i 6= jand 1 ?
i, j ?
M , if their relative co-occurrencescore is within a predefined range:score(fj , fi) =?Nk=1 exists(fj , fi, sk)?Nk=1 exists(fi, sk)(1)8Colours can be customised by the user.where sk ?
S, 1 ?
k ?
N , exists() is abinary function that returns 1 if the input fea-tures occur in sk, and 0 ?
score(fj , fi) ?
1.We group features in terms of their relative co-occurrence within sentences in the corpus and dis-play these co-occurrence relationships as directedgraphs.
Two nodes (features) are connected byan edge if their score, based on Equation (1), iswithin a user-defined range (see example below).Given fi and fj , the outgoing edges of fi are mod-elled using score(fj , fi) and the incoming edgesusing score(fi, fj).
Feature relations are shownvia highlighting of features when the user hoversthe cursor over them, while the strength of the re-lations is visually encoded in the edge width.For example, one of the highest-weighted pos-itive discriminative features is VM RR (see Ta-ble 1), which captures sequences of a modalauxiliary followed by an adverb as in will al-ways (avoid) or could clearly (see).
Investigat-ing its relative co-occurrence with other featuresusing a score range of 0.8?1 and regardless ofdirectionality, we find that VM RR is related tothe following: (i) POS ngrams: RR VB?
AT1,VM RR VB?, VM RR VH?, PPH1 VM RR,VM RR VV?, PPIS1 VM RR, PPIS2 VM RR,RR VB?
; (ii) word ngrams: will also, can only,can also, can just.
These relations show us the37syntactic environments of the feature (i) or itscharacteristic lexicalisations (ii).3.3 Dynamic creation of graphs via selectioncriteriaQuestions relating to a graph display may includeinformation about the most connected nodes, sep-arate components of the graph, types of intercon-nected features, etc.
However, the functionality,usability and tractability of graphs is severely lim-ited when the number of nodes and edges growsby more than a few dozen (Fry, 2007).
In orderto provide adequate information, but at the sametime avoid overly complex graphs, we support dy-namic creation and visualisation of graphs usinga variety of selection criteria.
The EP visualisersupports the flexible investigation of the top 4,000discriminative features and their relations.The Menu item on the top left of the UI in Fig-ure 1 activates a panel that enables users to selectthe top N features to be displayed.
The user canchoose whether to display positive and/or neg-ative features and set thresholds for, as well asrank by discriminative weight, connectivity withother features (i.e., the number of features it isconnected to), and frequency.
For instance, auser can choose to investigate features that havea connectivity between 500 and 900, rank themby frequency and display the top 100.
Highly-connected features might tell us something aboutthe learner grammar while infrequent features, al-though discriminative, might not lead to usefullinguistic insights.
Additionally, users can in-vestigate feature relations and set different scoreranges according to Equation (1), which controlsthe edges to be displayed.Figure 2(a) presents the graph of the 5 mostfrequent negative features, using a score rangeof 0.8?1.
The system displays only one edge,while the rest of the features are isolated.
How-ever, these features might be related to other fea-tures from the list of 4,000 (which are not dis-played since they are not found in the top Nlist of features).
Blue aggregation markers in theshape of a circle, located at the bottom right ofeach node, are used to visually display that in-formation.
When a node with an aggregationmarker is selected, the system automatically ex-pands the graph and displays the related features.The marker shape of an expanded node changesto a star, while a different border stroke pattern(a) Graph of the top 5 most fre-quent negative features using ascore range of 0.8?1.
(b) Expanded graph when the aggregation marker for thefeature VVD II is selected.Figure 2: Dynamic graph creation.is used to visually distinguish the revealed nodesfrom the top N .
Figure 2(b) presents the ex-panded graph when the aggregation marker for thefeature VVD II is selected.
If the same aggrega-tion marker is selected twice, the graph collapsesand returns to its original form.3.4 Feature?Error relationsThe FCE texts have been manually error-coded(Nicholls, 2003) so it is possible to find associa-tions between discriminative features and specificerror types.
The Feature?Error relations compo-nent on the left of Figure 1 displays a list of thefeatures, ranked by their discriminative weight,together with statistics on their relations with er-rors.
Feature?error relations are computed at thesentence level by calculating the proportion ofsentences containing a feature that also containa specific error (similar to Equation (1)).
In theexample in Figure 1, we see that 27% of the sen-tences that contain the feature bigram the peoplealso have an unnecessary determiner (UD) error,while 14% have a replace verb (RV) error9.9In the example image we only output the top 5 errors(can be customised by the user).38Figure 3: Sentences, split by grade, containing occurrences of how to and RGQ TO VV?.
The list on the leftgives error frequencies for the matching scripts, including the frequencies of lemmata and POSs inside an error.3.5 Searching the dataIn order to allow the user to explore how fea-tures are related to the data, the EP visualisersupports browsing operations.
Selecting multiplefeatures ?
highlighted in yellow ?
and clickingon the button get scripts returns relevant scripts.The right panel of the front-end in Figure 1 dis-plays a number of search and output options.Users can choose to output the original/error-coded/POS-tagged text and/or the grammaticalrelations found by the RASP parser (Briscoe etal., 2006), while different colours are used in or-der to help readability.
Data can be retrieved atthe sentence or script level and separated accord-ing to grade.
Additionally, Boolean queries can beexecuted in order to examine occurrences of (se-lected features and) specific errors only10.
Also,users can investigate scripts based on meta-datainformation such as learner age.Figure 3 shows the display of the system whenthe features how to and RGQ TO VV?
(how tofollowed by a verb in base form) are selected.
Thetext area in the centre displays sentences instanti-ating them.
A search box at the top supports nav-10For example, users can activate the Scripts with errors:option and type ?R OR W?.
This will return sentences con-taining replace or word order errors.igation, highlighting search terms in red, whilea small text area underneath displays the currentsearch query, the size of the database and the num-ber of matching scripts or sentences.
The Errorsby decreasing frequency pane on the left showsa list of the errors found in the matching scripts,ordered by decreasing frequency.
Three differenttabs (lemma, POS and lemma POS) provide in-formation about and allow extraction of counts oflemmata and POSs inside an error tag.3.6 Learner native languageResearch on SLA highlights the possible effect ofa native language (L1) on the learning process.Using the Menu item on the top left corner ofFigure 1, users can select the language of inter-est while the system displays a new window withan identical front-end and functionality.
Feature?error statistics are now displayed per L1, whileselecting multiple features returns scripts writtenby learners speaking the chosen L1.4 Interpreting discriminative features: acase studyWe now illustrate in greater depth how the EP vi-sualiser can support interpretation of discrimina-tive features: the POS trigram RG JJ NN1 (?)
is39the 18th most discriminative (negative) feature.
Itcorresponds to a sequence of a degree adverb fol-lowed by an adjective and a singular noun as invery good boy.
The question is why such a fea-ture is negative since the string is not ungrammat-ical.
Visualisation of this feature using the ?dy-namic graph creation?
component of the visualiserallows us to see the features it is related to.
Thisoffers an intuitive and manageable way of inves-tigating the large number of underlying discrimi-native features.We find that RG JJ NN1 is related to its dis-criminative lexicalisation, very good (?
), whichis the 513th most discriminative feature.
Also,it is related to JJ NN1 II (?)
(e.g., difficult sportat), ranked 2,700th, which suggests a particularcontext for RG JJ NN1 when the noun is fol-lowed by a preposition.
Searching for this con-junction of features in scripts, we get productionexamples like 1a,b,c.
Perhaps more interestingly,RG JJ NN1 is related to VBZ RG (?)
(ranked243rd): is followed by a degree adverb.
Thisrelation suggests a link with predicative struc-tures since putting the two ngrams together yieldsstrings VBZ RG JJ NN1 corresponding to exam-ples like 1c,d; if we also add II we get exampleslike 1c.1a It might seem to be very difficult sport at thebeginning.1b We know a lot about very difficult situationin your country.1c I think it?s very good idea to spending vaca-tion together.1d Unix is very powerful system but there is onething against it.The associations between features already givean idea of the source of the problem.
In the se-quences including the verb be the indefinite ar-ticle is omitted.
So the next thing to investigateis if indeed RG JJ NN1 is associated with ar-ticle omission, not only in predicative contexts,but more generally.
The Feature?Error relationscomponent of the UI reveals an association withMD (missing determiner) errors: 23% of sen-tences that contain RG JJ NN1 also have a MDerror.
The same holds for very good, JJ NN1 IIand VBZ RG with percentages 12%, 14% andLanguage f1 f2 f3 f4all 0.26 0.40 0.02 0.03Turkish 0.29 0.48 0.04 0.03Japanese 0.17 0.39 0.02 0.02Korean 0.30 0.58 0.06 0.03Russian 0.35 0.52 0.03 0.03Chinese 0.25 0.56 0.02 0.03French 0.21 0.41 0.00 0.03German 0.19 0.41 0.00 0.02Spanish 0.27 0.32 0.00 0.03Greek 0.30 0.35 0.02 0.02Table 2: f1/2/3/4:doc ratios for different L1s.15% respectively.
We then compared the num-ber of MD errors per script across different typesof scripts.
Across all scripts the ratio MD:docis 2.18, that is, approximately 2 MD errors perscript; in RG JJ NN1 scripts this ratio goes upto 2.75, so that each script has roughly 3 MDerrors.
VBZ RG follows with 2.68, JJ NN1 IIwith 2.48, and very good with 2.32.
In scriptscontaining all features the ratio goes up to 4.02(3.68 without very good), and in scripts contain-ing VBZ RG JJ the ratio goes up to 2.73.
Also,in most of these scripts the error involves the in-definite article.
The emerging picture then is thatthere is a link between these richer nominal struc-tures that include more than one modifier and theomission of the article.
Two questions arise: (i)why these richer nominals should associate witharticle omission and (ii) why only singular nounsare implicated in this feature.Article omission errors are typical of learn-ers coming from L1s lacking an article sys-tem (Robertson, 2000; Ionin and Montrul, 2010;Hawkins and Buttery, 2010).
Trenkic (2008) pro-poses that such learners analyse articles as adjecti-val modifiers rather than as a separate category ofdeterminers or articles.
When no adjective is in-volved, learners may be aware that bare nominalsare ungrammatical in English and provide the ar-ticle.
However, with complex adjectival phrases,learners may omit the article because of the pres-ence of a degree adverb.
In order to evaluate thishypothesis further we need to investigate if arti-cle omission is indeed more pronounced in ourdata with more complex adjectival phrases e.g.,very difficult situation than with simpler ones e.g.,nice boy and whether this is primarily the case for40learners from L1s lacking articles.Again, using the Errors by decreasing fre-quency pane we found that the MD:doc ratio inscripts containing the bigram JJ NN1 is 2.20.
Ad-ditionally, in scripts containing JJ NN1 and notRG JJ NN1 it goes down to 2.04.
These resultsare much lower compared to the MD:doc ratioin scripts containing RG JJ NN1 and/or the fea-tures with which it is related (see above), fur-ther supporting our hypothesis.
We also foundthe ratio of RG JJ NN1 (f1) occurrences per doc-ument across different L1s, as well as the ratioof VBZ RG JJ (f2), VBZ RG JJ NN1 (f3) andRG JJ NN1 II (f4).
As shown in Table 2 thereis no correlation between these features and theL1, with the exception of f1 and f2 which aremore pronounced in Korean and Russian speak-ers, and of f3 which seems completely absentfrom French, German and Spanish which all havearticles.
The exception is Greek which has articlesbut uses bare nominals in predicative structures.However, a more systematic pattern is revealedwhen relations with MD errors are considered (us-ing the Feature?Error relations and Errors by de-creasing frequency components for different L1s).As shown in Table 3, there is a sharp contrast be-tween L1s with articles (French, German, Spanishand Greek) and those without (Turkish, Japanese,Korean, Russian, Chinese), which further sup-ports our hypothesis.
A further question is whyonly the singular article is implicated in this fea-ture.
The association with predicative contextsmay provide a clue.
Such contexts select nomi-nals which require the indefinite article only in thesingular case; compare Unix is (a) very powerfulsystem with Macs are very elegant machines.In sum, navigating the UI, we formed someinitial interpretations for why a particular featureis negatively discriminative.
In particular, nomi-nals with complex adjectival phrases appear par-ticularly susceptible to article omission errors bylearners of English with L1s lacking articles.
Theexample illustrates not just the usefulness of visu-alisation techniques for navigating and interpret-ing large amounts of data, but, more generallythe relevance of features weighted by discrimina-tive classifiers.
Despite being superficial in theirstructure, POS ngrams can pick up syntactic envi-ronments linked to particular phenomena.
In thiscase, the features do not just identify a high rate ofarticle omission errors, but, importantly, a partic-sentences% MD:docLanguage f1 f2 f1 f2all 23.0 15.6 2.75 2.73Turkish 45.2 29.0 5.81 5.82Japanese 44.4 22.3 4.48 3.98Korean 46.7 35.0 5.48 5.31Russian 46.7 23.4 5.42 4.59Chinese 23.4 13.5 3.58 3.25French 6.9 6.7 1.32 1.49German 2.1 3.0 0.91 0.92Spanish 10.0 9.6 1.18 1.35Greek 15.5 12.9 1.60 1.70Table 3: f1/2 relations with MD errors for differentL1s, where sentences% shows the proportion of sen-tences containing f1/2 that also contain a MD.ular syntactic environment triggering higher ratesof such errors.5 Previous workTo the best of our knowledge, this is the first at-tempt to visually analyse as well as perform alinguistic interpretation of discriminative featuresthat characterise learner English.Collins (2010) in his dissertation addresses vi-sualisation for NLP research.
The Bubble Sets vi-sualisation draws secondary set relations aroundarbitrary collections of items, such as a linguis-tic parse tree.
VisLink provides a general plat-form within which multiple visualisations of lan-guage (e.g., a force-directed graph and a radialgraph) can be connected, cross-queried and com-pared.
Moreover, he explores the space of contentanalysis.
DocuBurst is an interactive visualisationof document content, which spatially organizeswords using an expert-created ontology (e.g.,WordNet).
Parallel Tag Clouds combine keywordextraction and coordinated visualisations to pro-vide comparative overviews across subsets of afaceted text corpus.
Recently, Rohrdantz et al(2011) proposed a new approach to detecting andinvestigating changes in word senses by visuallymodelling and plotting aggregated views aboutthe diachronic development in word contexts.Visualisation techniques have been success-fully used in other areas including the humanities(e.g., Plaisant et al (2006) and Don et al (2007)),as well as genomics (e.g., Meyer et al (2010a)and Meyer et al (2010b)).
For example, Meyer41et al (2010a) present a system that supports theinspection and curation of data sets showing geneexpression over time, in conjunction with the spa-tial location of the cells where the genes are ex-pressed.Graph layouts have been effectively used inthe analysis of domains such as social networks(e.g., terrorism network) to allow for a system-atic exploration of a variety of Social NetworkAnalysis measures (e.g., Gao et al (2009) andPerer and Shneiderman (2006)).
Heer and Boyd(2005) have implemented Vizster, a visualisationsystem for the exploration of on-line social net-works (e.g., facebook) designed to facilitate thediscovery of people, promote awareness of com-munity structure etc.
Van Ham et al (2009) intro-duce Phrase Net, a system that analyses unstruc-tured text by taking as input a predefined patternand displaying a graph whose nodes are wordsand whose edges link the words that are found asmatches.We believe our integration of highly-weighteddiscriminative features identified by a supervisedclassifier into a graph-based visualiser to supportlinguistic SLA research is, however, novel.6 ConclusionsWe have demonstrated how a data-driven ap-proach to learner corpora can support SLA re-search when guided by discriminative featuresand augmented with visualisation tools.
We de-scribed a visual UI which supports exploratorysearch over a corpus of learner texts using di-rected graphs of features, and presented a casestudy of how the system allows SLA researchersto investigate the data and form hypotheses aboutintermediate level learners.
Although the use-fulness of the EP visualiser should be con-firmed through more rigorous evaluation tech-niques, such as longitudinal case studies (Shnei-derman and Plaisant, 2006; Munzner, 2009) witha broad field of experts, these initial explorationsare encouraging.
One of the main advantages ofusing visualisation techniques over command-linedatabase search tools is that SLA researchers canstart developing and testing hypotheses withoutthe need to learn a query syntax first.We would also like to point out that we adopteda user-driven development of the visualiser basedon the needs of the third author, an SLA re-searcher who acted as a design partner duringthe development of the tool and was eager to useand test it.
There were dozens of meetings overa period of seven months, and the feedback onearly interfaces was incorporated in the versiondescribed here.
After the prototype reached a sat-isfactory level of stability, the final version overallfelt enjoyable and inviting, as well as allowed herto form hypotheses and draw on different types ofevidence in order to substantiate it (Alexopoulouet al, 2012).
Future work will include the devel-opment, testing and evaluation of the UI with awider range of users, as well as be directed to-wards investigation and evaluation of different vi-sualisation techniques of machine learned or ex-tracted features that support hypothesis formationabout learner grammars.AcknowledgmentsWe are grateful to Cambridge ESOL for support-ing this research.
We would like to thank MarekRei, ?istein Andersen, Paula Buttery and Ange-liki Salamoura for fruitful discussions and feed-back, Tim Parish for making the tool available onthe web, as well as the anonymous reviewers fortheir valuable comments and suggestions.ReferencesTheodora Alexopoulou, Helen Yannakoudakis, andAngeliki Salamoura.
2012.
Classifying interme-diate Learner English: a data-driven approach tolearner corpora.
to appear.Ted Briscoe, John Carroll, and Rebecca Watson.
2006.The second release of the RASP system.
In Pro-ceedings of the COLING/ACL, volume 6.Ted Briscoe, Ben Medlock, and ?istein Andersen.2010.
Automated Assessment of ESOL Free TextExaminations.
University of Cambridge, ComputerLaboratory, TR-790.Stuart K. Card, Jock D. Mackinlay, and Ben Shneider-man.
1999.
Readings in information visualization:using vision to think.
Morgan Kaufmann.Christopher M. Collins.
2010.
Interactive Visualiza-tions of natural language.
Ph.D. thesis, Universityof Toronto.Giuseppe Di Battista, Peter Eades, Roberto Tamassia,and Ioannis G. Tollis.
1999.
Graph Drawing: Al-gorithms for the Visualization of Graphs.
PrenticeHall Press.Anthony Don, Elena Zheleva, Machon Gregory,Sureyya Tarkan, Loretta Auvil, Tanya Clement, BenShneiderman, and Catherine Plaisant.
2007.
Dis-covering interesting usage patterns in text collec-tions: integrating text mining with visualization.
In42Proceedings of the sixteenth ACM conference on in-formation and knowledge management, pages 213?222.
ACM.Ben Fry.
2007.
Visualizing Data: Exploring andExplaining Data with the Processing Environment.O?Reilly Media.Jie Gao, Kazuo Misue, and Jiro Tanaka.
2009.
AMultiple-Aspects Visualization Tool for ExploringSocial Networks.
Human Interface and the Man-agement of Information, pages 277?286.Otis Gospodnetic and Erik Hatcher.
2004.
Lucene inAction.
Manning Publications.Lu Gram and Paula Buttery.
2009.
A tutorial intro-duction to iLexIR Search.
unpublished.John Hawkins and Paula Buttery.
2010.
Criterial fea-tures in Learner Corpora: theory and illustrations.English Profile Journal, 1(1):1?23.Jeffrey Heer and Danah Boyd.
2005.
Vizster: visual-izing online social networks.
IEEE Symposium onInformation Visualization (INFOVIS), pages 32?39.Jeffrey Heer, Stuart K. Card, and James A. Landay.2005.
Prefuse: a toolkit for interactive informa-tion visualization.
In Proceedings of the SIGCHIconference on Human factors in computing systems,pages 421?430, New York, USA.
ACM.Tania Ionin and Silvina Montrul.
2010.
The roleof l1 transfer in the interpretation of articles withdefinite plurals in l2 english.
Language Learning,60(4):877?925.Miriah Meyer, Tamara Munzner, Angela DePace, andHanspeter Pfister.
2010a.
MulteeSum: a tool forcomparative spatial and temporal gene expressiondata.
IEEE transactions on visualization and com-puter graphics, 16(6):908?17.Miriah Meyer, Bang Wong, Mark Styczynski, TamaraMunzner, and Hanspeter Pfister.
2010b.
Pathline:A tool for comparative functional genomics.
Com-puter Graphics, 29(3).Tamara Munzner.
2009.
A Nested Model for Visual-ization Design and Validation.
IEEE Transactionson Visualization and Computer Graphics, 15(6).Diane Nicholls.
2003.
The Cambridge LearnerCorpus-error coding and analysis for lexicographyand ELT.
In Proceedings of the Corpus Linguistics2003 conference, pages 572?581.Adam Perer and Ben Shneiderman.
2006.
Balanc-ing Systematic and Flexible Exploration of SocialNetworks.
IEEE Transactions on Visualization andComputer Graphics, 12(5):693?700.Catherine Plaisant, James Rose, Bei Yu, Loretta Auvil,Matthew G. Kirschenbaum, Martha N. Smith,Tanya Clement, and Greg Lord.
2006.
Exploringerotics in Emily Dickinson?s correspondence withtext mining and visual interfaces.
In Proceedings ofthe 6th ACM/IEEE-CS joint conference on Digitallibraries, pages 141?150.
ACM.Daniel Robertson.
2000.
Variability in the use of theEnglish article system by Chinese learners of En-glish.
Second Language Research, 2:135?172.Christian Rohrdantz, Annette Hautli, Thomas Mayer,and Miriam Butt.
2011.
Towards tracking seman-tic change by visual analytics.
Proceedings of the49th Meeting of the Association for ComputationalLinguistics, pages 305?310.Ben Shneiderman and Catherine Plaisant.
2006.Strategies for evaluating information visualizationtools: multi-dimensional in-depth long-term casestudies.
In Proceedings of the 2006 AVI workshopon BEyond time and errors: novel evaluation meth-ods for information visualization.
ACM.Danijela Trenkic.
2008.
The representation of Englisharticles in second language grammars: Determinersor adjectives?
Bilingualism: Language and Cogni-tion, 11(01):1?18.Frank Van Ham, Martin Wattenberg, and Fernanda B.Vie?gas.
2009.
Mapping text with phrase nets.IEEE Transactions on Visualization and ComputerGraphics, 15(6):1169?76.Helen Yannakoudakis, Ted Briscoe, and Ben Medlock.2011.
A New Dataset and Method for Automati-cally Grading ESOL Texts.
In Proceedings of the49th Annual Meeting of the Association for Com-putational Linguistics: Human Language Technolo-gies.43
