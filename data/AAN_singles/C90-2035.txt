Representing and Integrating Linguistic Knowledge*Danie l  Ju ra fsky573 Ewms Ha l lComputer  Sc ience  D iv i s ionUn ivers i ty  of  Ca l i fo rn ia  a t  Berke leyBerke ley ,  CA  94720ju ra fsky@teak .Berke ley .EDUIn t roduct ionThis paper describes a theory of the representationand use of linguistic knowledge in a natural anguageunderstanding system.
The representation systemdraws much of its insight from the linguistic the-ory of Fillmore el al.
(1988).
This models knowl-edge of language as a large collection of grammati-cal constructions, each a description of a linguisticregularity.
I describe a representation language forconstructions, and principles for encoding linguisticknowledge in this representation.
The second part ofthe theory is a conceptual analyzer which is designedto model the on-line nature of the hunmn languageunderstanding mechanism.
I discuss the core of thisanalyzer, an information-combining operation calledintegration which combines constructions to producecomplete interpretations of an utterance.Representat ionA natural way to model knowledge of language isas a large collect.ion of facts or regularities aboutthe language.
In this theory I use a single repre-sentational device, the grammatical construction, torepresent hese regularities.
Our entire model of lin-guistic knowledge consists of a database of these con-structions, uniforrnly representing lexieal knowledge,syntactic knowledge, and semantic knowledge.Although the notion of grammatical construction Iuse is based on that of Fillmore e!
al.
(1988) it differsin a few respects.
Filhnore et al define a construe-tion as a structure which represents a "pairi~9 of asyntaclic pallcrn with, a meanin 9 sl'ruclure".
Such aconstruction is a sig., in the sense of Saussure, or arule-pairing in the sense of Montague.
1 use a some-what extended notion: a construction is a relationbetween one information structure and one or moreothers.
These information structures can be seman-tic, syntactic or both.
Thus, whereas the "sign" ex-pressed a relation between a set of ordered phonemes~md a meaning structure, the construction abstractsover this by replacing 'ordered sets of phonemes' with*I want to express my tha.nks to Peter Norvig, NigelWard, and l{obert Wilensky for many helpfld com-ments and discussions on these ideas.
This research was~ponsored by the Defense Advanced Research ProjectsAgency (DoD), monitored by the Space and Naval War-Ikre Systems Command under N00039-88-C-0292, andthe Office of Naval Research, under contract N00014-89.-,1-3205.abstractions over them.
These abstractions can besyntactic or semantic ways of expressing more ab-stract categories to which these phoneme sequencesbelong.
The construction is then a part-whole struc-turing relating these categories.An Example  Const ruct ionTo make this idea more concrete, consider some spe-cific examples from the grammar, which currentlyincludes about 30 constructions.
In the examples Iwill be focusing on the knowledge that is necessaryto handle the sentence:"IIow cart I find out how much disk space Iam using ?
"The top-level construction for the sentence is theWhNonSub jeetQuest lon  construction.
This con-struction is a sub-type of the WhQuest lon  con-struction.
The wh-questions are those which beginwith a wh-element - -  an element which is semanti-cally questioned.
In the WhNonSub jeetQuest lonthis questioned element begins the sentence but doesnot flmction as the grammatical subject of the sen-tence.
Following are two other examples of WhNon-S ab ject  Q uest ions:Why did you run ~he wrong way?What did you pick up at the store?
'/'he construction is represented in figure 1 below:(constr WhNonSubjectQuestion (Freq p)\[(a Sq($q AIO Question)($var -Queried $q)(\[$\v $\presup\] -Presupposed Sq))\]->\[(a St(St AIO Identify)(Svar -Specified St)($presup -Presupposed St)) \]\[(a $v($V AIO SubjectSecondClause))\])F igure  1Figure 1 can be summarized as follows: There isa construction in English called WhNonSub jec -tQuest ion .
It consists of' two constituents, $t andSv, and a "whole", $% (In tile example sentence,the St constituent consists only of the word "How",1 199while t:he $v constituent consists of the phrase "canI find out how much disk space I am using.")
Thesethree elements consist of statements in a knowledgerepresentation language based on Wilensky (1986).The representation language is relatively perspicu-ous, not differing greatly from other popular repre-sentation languages (such as KL-ONE (Brachman &Schmolze 1985)).
The operator "a" creates an exis-tentially quantified variable, and is followed by thevariable name and a set of statements in its scope.The infix operator "A IO" (An  Instance Of) estab-lishes one element as an instance of another, and theinfix operator "AKO"  (A Kind Of) establishes oneelement as a sub-type of another.The first constituent, St, is an instance of theIdent i fy  concept, which will be described later.This concept contains two relations, Ident i fy -Speci f ied and Ident i fy -P resupposed .
(Note thatthey are referred to simply as -Spec i f ied  and -P resupposed . )
The second constituent, $v, mustbe an instance of the construction Sub jec tSecond-Clause.
This is a clause where the subject follows aninitial "verbal auxiliary.
The name Sub jec tSecond-C lause  was chosen to replace the traditional termAux-Inversion in order to avoid employing terminol-ogy that uses the "movement" metaphor.The construction builds the $q element, which isan instance of the Quest ion  concept.
Note thatthe variable which fills the -Quer ied  relation ofthe Quest ion  is the same element hat fills the -Speci f ied relation in St.
The -P resupposed  re-lation is filled with the integration of the semanticsof St and Sv.
The integration process is discussedbelow.Each constituent (enclosed in square brackets) iscomposed of a set of semantic relations.
These con-stituents correspond to what are cMled informationalelements in the unification literature.
Each consistsof a group of semantic relations expressing some in-formation about some linguistic entity.The relation among these informational elementsis represented by the right-arrow "--," symbol.
Inthe current version of thc representational system,the right-arrow indicates the eonflation of part-wholeand ordering relations.
That is, the default is forconstructions to be ordered.
In order to indicate apart-whole relation without the ordering relations,the right-arrow is followed by the keyword "UN-ORDERED".
Figure 2 below provides an exampleof an unordered construction.Features of the RepresentationThe representation language and the granm~ar of-fer a number of distinguishing features.
First is theability to define constituents of constructions seman-tically as well as syntactically.
For example, notethat the first constituent of the WhNonSub jec -tQuest ion ,  St, was defined ~s any informationalelement which is an instance of a certain Ident i fyconcept.
The Ident i fy  concept indicates ome ques-tion about the identity of the individual filling theIdent i fy -Spec l f ied  relation.
The information thatis known about the individual fills the Ident i fy -P resupposed  relation.
The Ident i fy  concept is themain characteristic of the lexieal semantics of thewh-words.
Thus this constituent is specified seman-tically, simply by requiring the presence of the Iden-t i fy semantics.
In more traditional grammars, theconstituent would be defined syntactically~ as somesort of WhPhrase .
Capturing the syntax of theWhPhrase  would entail duplicating huge parts ofthe grammar or introducing significant syntactic ap-paratus.
Since the semantics of Ident i fy  must bein the grammar anyhow, using it to specify the con-struction simplifies the grammar at no cost 1A construction's constituents can be constrainedto be instances of other constructions.
For example,the second constituent in figure 1 is constrained to bean instance of Sub jec tSecondClause .
But theseconstraints are the only form of syntactic knowledgethat this representational system allows.
That is,constituency and ordering are the only syntactic re-lations in the system.
All others are semantic.
Inkeeping with these last two ideas, this representa-tion dispenses with any enrichment of surface forrn.Thus phenomena which might traditionally be han-dled by gaps, traces, or syntactic oindexing are han-dled with semantic relations.
Thus, as we saw above,the first constituent of the WhNonSnb jectQues -t lon construction is specified semantically, and nogaps or traces are involved 2Relations Among Const ruct ionsAs with other kinds of knowledge, linguistic knowl-edge includes an abstraction hierarchy.
All exampleof two constructions related by abstraction is givenin figure 2.
Constructions are also augmented byinformation concerning their frequency.
The use offrequency information in comprehension (suggestedin Bresnan 1982) is discussed in Wu (1989), and isnot discussed further here.I noted above that a construction may constrainone of its constituents to be an instance of some otherconstruction.
In a similar manner, a constructionmay require that several of its constituents partici-pate together in a second construction.
This is repre-sented by including specifications for additional con-structions after the keyword WITH.
The relevantconstituents of these extra constructions are thenmarked with the proper constituent variables fromthe main construction.To illustrate the last few points, consider theVerbPar t l c le l  construction in figure 3.
It is oneof two constructions in which discontinuous phrasalverbs like "find out" or "look up" occur.
Thesetwo constructions pecify the ordering of the verband particle, differing in that VerbPar t i c le2 ,  whichcovers phrases like "find it out", includes an extra1This makes it more difficult for the parser to indexconstructions to consider.
Because a construction's con-stituents may be defined by any set of semantic relationsrather than by a small set of syntactic ategories, it isno longer possible to simply look for a syntactic han-dle in the input.
Indeed, the "construction access prob-lent" becomes much more like the general memory accessproblem.
In this sense this analyzer esembles the DirectMemory Access Parser of Riesbeck (1986).2Jur~fsky (1988) discusses how other phenomena clas-sically handled by transformations and redundancy rulescan be represented as constructions.200  2constituent.
But VerbPar t le le l  and VerbPar t l -cle2 both require that their constituents be filled byphrasal verbs like "find out".
This fact is representedby requiring that these constituents be instances ofthe unordered Lex lca lVerbPar t i c le  construction,which is the ancestor of all these phr~al verbs.
Inthe representation f the VerbPar t i c le  constructionbelow, constituents Sv and Sp are constrained tobe the Sverb and $part lc le  respectively of a Lexi-ca lVerbPar t l c le  construction.
Since F indOut  is asubtype of Lex lea lVerbPart lc le ,  it meets the nec-essary constraints, and can integrate with VerbPar -tlcle a(constr VerbParticlel (Freq Sz)\[ (a $a($a hIO Verb))\]->\[(a $v)\]\ [ (a$p) \ ]WITH(constr LexicalVerbParticle\[ (a Sa )\]-> UNOKDERED\[ (a ?v)\]\[ (a$p) \ ] ) )F igure  2(constr LexicalVerbParticle (Freq Sz)\[\]-> UNORDERED\[(a $v)\]\ [ (a$p) \ ] )(constr FindOut AIO LexicalVerbParticle(Freq Sz)\ [ (a $~($ IA IO  FindingOut))\]~> UNORDERED\[$verb (word find)\]\[$particle (word out)\])F igure  3The  Bas ic  In tegrat ion  Operat ionAssociated with the representational system is aninformation-combining operation called integration,used here in two ways.
The more complex one isdiscussed in the next section.
The simpler version ofintegration is used to match informational elementsto constituents of a constructions.
The set of rela-tions which constitute a constituent act as a set ofconstraints on any candidate constituents.
For ex-ample, consider what semantics must be prcsent inan informational element for it to be a constituent ofaNote that a parse which uses WITH constraints doesnot have a parse tree, but a parse graph, q'his is becauseboth VerbParticle and LexicalVerbParticle would occurin the parse tree above the phrase "find out".
However,this grammar obviates the need to keep a parse tree at all,as the grammar itself specifics how semantic integrationis to be (tone.the HowSca le  construction.
Examples of this con-struction include:IIow wide/strong/aceurale ... ?How much~often/quickly~far ... ?How many ... ?The construction has two constituents, the lexi-cal item "how" and a second constituent which issemantically specified to be some sort of semanticscale.
This constituent may be an adjective, an ad-verb, or a quantifer so long as it has the propersemantics.
In the cases above, the scales range oversuch things as width, strength, speed, and amount.The construction takes a constituent with these se-mantics, and builds an instance of the Ident i fy  con-cept.
The -P resupposed  relation of this Ident i fyconcept is filled by the semantics of the constitucnt.The -Spec i f ied  relation is bound to the -Locat ionof the presupposed object on this scale.
That is, thememfing of the construction is something like "Thelocalion of objec~ Sz on scale Ss is in queslion".
(constr HowScale\ [ (a $?($?
($x($s($x=>\[ $h\[ (ahIO Identify)-Specified $i)-Presupposed $i)-Location Sz Ss)\](word how) \]$s($s AI0 Scale)($z -On Ss)) \ ]F igure  4In order for an informational element o integratewith the Ss constituent of the HowSca le  construc-tion, its sernantics must already include an instanceof a scale, with some object on the scale.
As in stan-dard unification, the constraints are matched withthe elements in a recursive fashion, binding variablesin the process.
Unlike unification, a match cannotsucceed if a candidate constituent is merely compat-ible with the required information.
For example, theelement \[ (a Sx ($x A IO  ScAle))\] would u,~ify withthe $s constituent.
However, it would ~ot inlegratc,because it lacks the -On relation.
We can summarizethe simple integration algorithm as follows:S imple In tegrat ion  A lgor i thm:Unify the set of constituent relations withthe relations present in the candidate, sub-ject to the constraint that every relation inthe constraint must already bc instantiatedin the candidate.There arc times when wc want the semantics ofunification rather than integration.
That is, we maywant to ensure that a certain relation is in the se-mantics of a construction regardless of which con-stituents it may also occur in.
We can accomplishthis by putting information in the "whole" of theconstruction's part-whole structure.
For example, infigure 4, the information "($x -Locat ion  Sz $s)" isadded to the final semantics whether or not it waspresent in the $s constituent.Thus there is an asymmetry in the application ofthe integration operation, caused by the part-whole3 201structure of the construction.
The relations in theconstituent slots of the construction definition areviewed as conslraints on candidate constituents.
Therelations in the "whole" element, on the other hand,arc used as instructions for creating a whole semanticstructure.Note that this interpretation of the constructionis limited to its use in comprehension.
When a con-struction is used in generation the exact oppositesituation holds - -  the "whole" element imposes con-straints, while the constituents give instructions.More  Complex  In tegrat ionThe algorithm above is sufficient o match candidateconstituents to the constraints of a construction.
Butthis sort of simplistic combination is not commonin natural language when combining constructions.Integrating constituents usually involves modifyingsome of t:he structure of one of the constituents.
Aparticularly common type of modification involvesbinding the value of one constituent o some openvariable in another constituent 4.
That is, we mustdecide whether two relations are at the same level, orwhether one should fill some semantic gap in another.In some cases, deciding the level and finding an ap-propriate semantic gap can be quite simple.
For ex-ample, part of the verb phrase construction is shownin figure 5 below.
Note that the variable $ /v  ismarked with a slash.
This indicates that the verb$v is the matrix structure, while the complement $cis to be integrated to some gap inside of $v.
Thisslash can be used for any variable to indicate that itis the matrix for some integration.
(constr gerbPhrase (Freq Sp)\[ (a \ [$/v $c\])->\[ (a Sv($v AIO Verb))\]\[ (a $c)\])F igure  5For a more complex example, consider figure 1 (du-plicated below), examining how the two constituentsof the WhNonSub jectQuest ion  are integrated forthe sentence "How can \[ f ind out how much diskspace I am usingF'.
I will not discuss the details ofthe Sv constituent except to note that its semanticsinvolve an Ab i l i tyState  predicated of some personasking a question, and concerning some f inding-outaction.The first constituent (St) of the WhNonSub-jec tQuest lon  is filled here by the lexical construc-tion how6, one of the various "how" constructions.How6 is concerned with the means of some action,asking for a specification of the means or plan bywhich some goal is accomplished.
We can ignore for4This occurs in such common phenomena s WH-movement, Y-Movement, Topicalization, and other phe-nomenon classically analyzed as movement rules, wherethere is some long-distance link between some ele-ment and the valence-bearing predicate into which itintegrates.
(constr WhNonSubj ectQuestion (Freq p)\[(a $q($q AIO Question)($var -Queried Sq)(\[$\v $\presup\] -Presupposed $q))\]->\[(a St(St AIO Identify)($var -Specified St)($presup -Presupposed St)) \]\[(a $v($v AIO SubjectSecondClause))\])F igure  Inow exactly how this sense is related to the othersenses of "how".
(word how6 (Freq x)\[(a Sh($h AIO Identify)(Sp -Specified $h)($X -Presupposed Sh)($x AIO Planfor)($p -Plan $x)($g-Goal Sx))\])Figure 6Given the semantics of the two constituents of theWhNonSub jectQuest lon  construction, the finalresult of the integration will look something like fig-ure 7.\[(a $q($q Aio question)($p -Queried $q)($pr -Presupposed $q)($pr AIO Planfor)($p -Plan $pr)($g -Goal $pr)($g AIO AbilityState))\]Figure 7tlere in integrating $ /v  and $ /presup ,  the algo-r ithm finds a gap inside the second structure.
Thatis, the integration algorithm integrated the Planfor ofthe first constituent with the AbilityState of the sec-ond, in effect unifying the variable Sg in the PlanForstructure with Sv, the AbilityStatc structure.
Thusthe complete algorithm might be expressed as fol-lows:Full  In tegrat ion  A lgor i thm:  Inte-grate the set of constituent relations withthe relations present in the candidate byfinding an appropriate gap (variable) in oneof the two structures to integrate with theother.Integration is an augmentation of unification.
Inorder to handle more complex constructions, the op-eration would need to be augmented further, addingmore inferential power.
For example, a certainclass of inference is required to integrate construc-tions like DoubleNoun (Wu 1990), where the re-lation between the constituents can be quite indi-rect and contextually-influenced.
Such an integra-tion algorithm might also need to make the kind202  4ol!
metaphoric inferences tudied by Martin (1988),ok: the abductive inferences of Charniak & Goldman(11988) or Hobbs et al (1988).
But rather than mak-ing these inferences in the pipelined fashion thatthese other mechanisms use, augmenting the inte-gi:ation algorithm allows these inferences to be madeir~ an on-line manner.Prev ious  ResearchThe theory I have presented raws many elementsfrom other theories of grammar, especially Fillmoreel al.
(1988).
The use of ordered and unorderedconstructions is based on the ID/LP notation ofCazdar et al (1985) The theory differs from theseand most other grammars (such as Bresnan (1982),Marcus (1980), Pereira (1985)) in allowing semanticconstraints on constituents (indeed in emphasizingthem), and in disallowing syntactic relations otherthan ordering and constituency.
It also differs byconstraining the grammar to be semantically intbr-mative enough to allow the analyzer to produce in-terpretations in an on-line fashion.As for the tradition which has concentrated on se-mantic analysis, this theory owes much to such sys-tems as ELI (Pdesbeck & Schank 1978) and the WordExpert Parser (Small & Rieger 1982).
It ditfers fromthese in its commitment to representing high-levellinguistic onstructions, to the use of declarative rep-resentations, and to capturing linguistic generaliza-tions.A nmnber of earlier systems have integrated lin-guistic knowledge with other knowledge, includingP~I--KLONE (Bobrow & Webber 1980) and Jacobs's(1985) ACE/KING system, on which this theorydraws heavily.
The use of constructions here drawsal~o on the pattern-concept pair of Wilensky & Arens(1980) and Becket's 1975 work on the phra.sal lexi-con.The integration operation is based on unificationin ways discussed above.
Unification was first pro-posed by Kay (1979), and has since been used andex~ended by many other theories of grammar.Conc lus ionI draw three conclusions for the representation anduse of linguistic knowledge::1.
Allowing constructions to include semantic aswell as syntactic constraints removes a greatdeal of complexity from the syntactic omponentof a grammar.
This is useful because no cor-responding complexity is added to the semanticcomponent.
Semantic knowledge which must bein the system anyway is employed.2.
Committing to exploring semantically rich con-structions like HowSeale froln a semantic per-spective produces a grammar of sufficient rich-ness to .allow lexical semantics to influence theintegration process, and thus the interpretation,in an on-line way.3.
Using a single representational device, the gram-matical construction, avoids the proliferation ofsyntactic devices and simplifies the representa-tional theory.
This may also simplify the torte-sponding learning theory.4.
Extending unification-style approaches fi'omsyntax to semantics requires augmenting thefeature-based unification operation to richer, re-lational knowledge representation languages.
Ihave shown how one such extension has beenimplemented, allowing some gap-seeking intelli-gence to guide the integration process.ReferencesBacker, J.
(1975).
The phrasal lexicon.
In R. Schank& B. L. Nash-Webber, editors, Proceedings ofthe First Interdisciplinary Workshop on Theo-retical Issues in Natural Language Processing,Cambridge, MA.Bobrow, R.. J.
& B. Webber (1980).
Knowledgerepresentation for syntactic/semantic process-ing.
In Proceedings of the First National Con-ferenee on Artificial Intelligence, pp.
316-323.Morgan Kaufmann.Brachman, R. J.
& J. G. Schmolze (1985).
Anoverview of the KL-ONE knowledge represen-tation system.
Cognitive Science, 9(2):171-216.Bresnan, J., editor (1982).
The Mental Represen-tation of Grammatical Relations.
MIT Press,Cambridge.Charniak, E. & R. Goldman (1988).
A logic for se-mantic interpretation.
In Proceedings of the 26thAnnual Conference of the Association for Com-putational Linguistics.Fillmore, C., P. Kay, & M. C. O'Connor (1988).Regularity and idiomaticity in grammatical con-structions: The case of let alne.
Language,64(3):501-538.Gazdar, G., E. Klein, G. Pullum, & I.
Sag (1985).Generalized Phrase Structure Grammar.
BasilBlackwell, Oxford.IIobbs, J. R., M. Stickel, P. Martin, & D. Edwards(1988).
Interpretation as abduction, in Pro-ceedings of the 26th Annual Conference of theAssociation for Computational Linguistics, pp.95-103, Buffalo, NY.Jacobs, P. (1985).
A knowledge-based approach tolanguage generation.
Technical Report 86/254,University of California at Berkeley ComputerScience Division, Berkeley, CA.Jurafsky, D. (1988).
Issues in relating syntax andsemantics.
In Proceedings of the Twelfth Inter-national Conference on Computational Linguis-tics, pp.
278-284, Budapest.Kay, M. (1979).
Functional grammar.
In Proceedingsof the Fifth Annual Meeting of the Berkeley Lin-guistics Society, pp.
142-158, Berkeley, CA.Marcus, M. P. (1980).
A Theory of Syntactic Recog-nition for Natural Language.
MIT Press, Cam-bridge.Martin, J.
(1988).
A computational theory ofmetaphor.
Technical Report 88/465, Universityof California at Berkeley, Computer Science Di-vision, Berkeley, CA.5 203Pereira, F. C. N. (1985).
Characterization of at-tachment preferences.
In D. R. Dowty, L. Kar-tunnen, & A. Zwicky, editors, Natural Lan-guage Parsing, pp.
307-319.
Cambridge Univer-sity Press, New York.Riesbeck, C. K. (1986).
From conceptual analyzer todirect memory access parsing: An overview.
InAdvances in Cognitive Science 1, pp.
236-258.Ellis Horwood, Chichester.Riesbeck, C. K. & R. C. Schank (1978).
Comprehen-sion by computer: Expectation-based analysisof sentences in context.
In W. J. M. Levelt &G. B. F. d'Arcais, editors, Studies in the percep-tion of language, pp.
247-293.
Wiley, London.Small, S. L. & C. Rieger (1982).
Parsing and compre-hending with word experts.
In W. G. Lehnert&: M. H. Ringlet editors, Strategies for NaturalLanguage Processing, pp.
89-147.
Lawrence Erl-baum, New Jersey.Wilensky, R. (1986 i.
Some problems and proposalsfor knowledge representation.
In J. L. Kolodner& C. K. Riebeck, editors, Experience, Memory,and Reasoning, pp.
15-28.
Lawrence Erlbaum,New Jersey.Wilensky, R. & Y. Arens (1980).
Phran - aknowledge-based approach to natural languageanalysis.
Technical Report UCB/ERL M80/34,University of California at Berkeley, ElectronicsResearch Laboratory, Berkeley, CA.Wu, D. (1989).
A probabalistic approach to markerpropagation.
In Proceedings of the Eleventh In-ternational Joint Conference on Artificial Intel-ligence, pp.
574-580, Detroit, MI.
Morgan Kauf-mann.Wu, D. (1990).
Probabalistic unification-based in-tegration of syntactic and semantic preferencesfor nominal compounds.
In Proceedings of theThirteenth International Conference on Compu-tational Linguistics, ttelsinki.204 6
