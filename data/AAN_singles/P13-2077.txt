Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 434?439,Sofia, Bulgaria, August 4-9 2013. c?2013 Association for Computational LinguisticsLatent Semantic Tensor Indexingfor Community-based Question AnsweringXipeng Qiu, Le Tian, Xuanjing HuangFudan University, 825 Zhangheng Road, Shanghai, Chinaxpqiu@fudan.edu.cn, tianlefdu@gmail.com, xjhuang@fudan.edu.cnAbstractRetrieving similar questions is veryimportant in community-based ques-tion answering(CQA).
In this paper,we propose a unified question retrievalmodel based on latent semantic index-ing with tensor analysis, which can cap-ture word associations among differentparts of CQA triples simultaneously.Thus, our method can reduce lexicalchasm of question retrieval with thehelp of the information of question con-tent and answer parts.
The experimen-tal result shows that our method out-performs the traditional methods.1 IntroductionCommunity-based (or collaborative) ques-tion answering(CQA) such as Yahoo!
An-swers1 and Baidu Zhidao2 has become a pop-ular online service in recent years.
Unlike tra-ditional question answering (QA), informationseekers can post their questions on a CQAwebsite which are later answered by otherusers.
However, with the increase of the CQAarchive, there accumulate massive duplicatequestions on CQA websites.
One of the pri-mary reasons is that information seekers can-not retrieve answers they need and thus postanother new question consequently.
There-fore, it becomes more and more important tofind semantically similar questions.The major challenge for CQA retrieval is thelexical gap (or lexical chasm) among the ques-tions (Jeon et al, 2005b; Xue et al, 2008),1http://answers.yahoo.com/2http://zhidao.baidu.com/Query:Q: Why is my laptop screen blinking?Expected:Q1: How to troubleshoot a flashingscreen on an LCD monitor?Not Expected:Q2: How to blinking text on screenwith PowerPoint?Table 1: An example on question retrievalas shown in Table 1.
Since question-answerpairs are usually short, the word mismatch-ing problem is especially important.
However,due to the lexical gap between questions andanswers as well as spam typically existing inuser-generated content, filtering and rankinganswers is very challenging.The earlier studies mainly focus on generat-ing redundant features, or finding textual cluesusing machine learning techniques; none ofthem ever consider questions and their answersas relational data but instead model them asindependent information.
Moreover, they onlyconsider the answers of the current question,and ignore any previous knowledge that wouldbe helpful to bridge the lexical and se manticgap.In recent years, many methods have beenproposed to solve the word mismatching prob-lem between user questions and the questionsin a QA archive(Blooma and Kurian, 2011),among which the translation-based (Riezler etal., 2007; Xue et al, 2008; Zhou et al, 2011)or syntactic-based approaches (Wang et al,2009) methods have been proven to improvethe performance of CQA retrieval.However, most of these approaches used434pipeline methods: (1) modeling word asso-ciation; (2) question retrieval combined withother models, such as vector space model(VSM), Okapi model (Robertson et al, 1994)or language model (LM).
The pipeline meth-ods often have many non-trivial experimentalsetting and result to be very hard to repro-duce.In this paper, we propose a novel unifiedretrieval model for CQA, latent semantictensor indexing (LSTI), which is an exten-sion of the conventional latent semantic index-ing (LSI) (Deerwester et al, 1990).
Similarto LSI, LSTI can integrate the two detachedparts (modeling word association and questionretrieval) into a single model.In traditional document retrieval, LSI is aneffective method to overcome two of the mostsevere constraints on Boolean keyword queries:synonymy, that is, multiple words with similarmeanings, and polysemy, or words with morethan one meanings.Usually in a CQA archive, each en-try (or question) is in the following tripleform:?question title, question content,answer?.
Because the performance basedsolely on the content or the answer part isless than satisfactory, many works proposedthat additional relevant information should beprovided to help question retrieval(Xue et al,2008).
For example, if a question title containsthe keyword ?why?, the CQA triple, whichcontains ?because?
or ?reason?
in its answerpart, is more likely to be what the user looksfor.Since each triple in CQA has three parts, thenatural representation of the CQA collectionis a three-dimensional array, or 3rd-order ten-sor, rather than a matrix.
Based on the tensordecomposition, we can model the word associ-ation simultaneously in the pairs: question-question, question-body and question-answer.The rest of the paper is organized as fol-lows: Section 3 introduces the concept of LSI.Section 4 presents our method.
Section 5 de-scribes the experimental analysis.
Section 6concludes the paper.2 Related WorksThere are some related works on question re-trieval in CQA.
Various query expansion tech-niques have been studied to solve word mis-match problems between queries and docu-ments.
The early works on question retrievalcan be traced back to finding similar ques-tions in Frequently Asked Questions (FAQ)archives, such as the FAQ finder (Burke et al,1997), which usually used statistical and se-mantic similarity measures to rank FAQs.Jeon et al (2005a; 2005b) compared fourdifferent retrieval methods, i.e., the vectorspace model(Jijkoun and de Rijke, 2005),the Okapi BM25 model (Robertson et al,1994), the language model, and the trans-lation model, for question retrieval on CQAdata, and the experimental results showedthat the translation model outperforms theothers.
However, they focused only on similar-ity measures between queries (questions) andquestion titles.In subsequent work (Xue et al, 2008), atranslation-based language model combiningthe translation model and the language modelfor question retrieval was proposed.
Theresults showed that translation models helpquestion retrieval since they could effectivelyaddress the word mismatch problem of ques-tions.
Additionally, they also explored an-swers in question retrieval.Duan et al (2008) proposed a solution thatmade use of question structures for retrievalby building a structure tree for questions ina category of Yahoo!
Answers, which gavemore weight to important phrases in questionmatching.Wang et al (2009) employed a parser tobuild syntactic trees for questions, and ques-tions were ranked based on the similarity be-tween their syntactic trees and that of thequery question.It is worth noting that our method is to-tally different to the work (Cai et al, 2006)of the same name.
They regard documentsas matrices, or the second order tensors togenerate a low rank approximations of ma-trices (Ye, 2005).
For example, they converta 1, 000, 000-dimensional vector of word spaceinto a 1000 ?
1000 matrix.
However in ourmodel, a document is still represented by avector.
We just project a higher-dimensionalvector to a lower-dimensional vector, but nota matrix in Cai?s model.
A 3rd-order tensor is435also introduced in our model for better repre-sentation for CQA corpus.3 Latent Semantic IndexingLatent Semantic Indexing (LSI) (Deer-wester et al, 1990), also called Latent Seman-tic Analysis (LSA), is an approach to auto-matic indexing and information retrieval thatattempts to overcome these problems by map-ping documents as well as terms to a represen-tation in the so-called latent semantic space.The key idea of LSI is to map documents(and by symmetry terms) to a low dimen-sional vector space, the latent semantic space.This mapping is computed by decomposingthe term-document matrix N with SVD, N =U?V t, where U and V are orthogonal matri-ces U tU = V tV = I and the diagonal matrix?
contains the singular values of N .
The LSAapproximation of N is computed by just keepthe largest K singular values in ?, which isrank K optimal in the sense of the L2-norm.LSI has proven to result in more robust wordprocessing in many applications.4 Tensor Analysis for CQA4.1 Tensor AlgebraWe first introduce the notation and basicdefinitions of multilinear algebra.
Scalars aredenoted by lower case letters (a, b, .
.
.
), vectorsby bold lower case letters (a,b, .
.
.
), matri-ces by bold upper-case letters (A,B, .
.
.
), andhigher-order tensors by calligraphic upper-caseletters (A,B, .
.
.
).A tensor, also known as n-way array, is ahigher order generalization of a vector (firstorder tensor) and a matrix (second order ten-sor).
The order of tensor D ?
RI1?I2????
?IN isN .
An element of D is denoted as di1,...,N .An Nth-order tensor can be flattened intoa matrix by N ways.
We denote the matrixD(n) as the mode-n flattening of D (Kolda,2002).Similar with a matrix, an Nth-order tensorcan be decomposed through ?N -mode singu-lar value decomposition (SVD)?, which is a anextension of SVD that expresses the tensor asthe mode-n product of N -orthogonal spaces.D = Z?1 U1?2 U2 ?
?
?
?n Un ?
?
?
?N UN .
(1)Tensor Z, known as the core tensor, is analo-gous to the diagonal singular value matrix inconventional matrix SVD.
Z is in general afull tensor.
The core tensor governs the in-teraction between the mode matrices Un, forn = 1, .
.
.
, N .
Mode matrix Un contains theorthogonal left singular vectors of the mode-nflattened matrix D(n).The N -mode SVD algorithm for decompos-ing D is as follows:1.
For n = 1, .
.
.
, N , compute matrix Un inEq.
(1) by computing the SVD of the flat-tened matrix D(n) and setting Un to bethe left matrix of the SVD.2.
Solve for the core tensor as follows Z =D ?1 UT1 ?2 UT2 ?
?
?
?n UTn ?
?
?
?N UTN .4.2 CQA TensorGiven a collection of CQA triples, ?qi, ci, ai?
(i = 1, .
.
.
,K), where qi is the question andci and ai are the content and answer of qirespectively.
We can use a 3-order tensorD ?
RK?3?T to represent the collection, whereT is the number of terms.
The first dimensioncorresponds to entries, the second dimension,to parts and the third dimension, to the terms.For example, the flattened matrix of CQAtensor with ?terms?
direction is composedby three sub-matrices MTitle, MContent andMAnswer, as was illustrated in Figure 1.
Eachsub-matrix is equivalent to the traditionaldocument-term matrix.Figure 1: Flattening CQA tensor with ?terms?
(right matrix)and ?entries?
(bottom matrix)Denote pi,j to be part j of entry i.
Then we436have the term frequency, defined as follows.tfi,j,k =ni,j,k?i ni,j,k, (2)where ni,j,k is the number of occurrences of theconsidered term (tk) in pi,j , and the denomi-nator is the sum of number of occurrences ofall terms in pi,j .The inverse document frequency is a mea-sure of the general importance of the term.idfj,k = log|K|1 +?i I(tk ?
pi,j), (3)where |K| is the total number of entries andI(?)
is the indicator function.Then the element di,j,k of tensor D isdi,j,k = tfi,j,k ?
idfj,k.
(4)4.3 Latent Semantic Tensor IndexingFor the CQA tensor, we can decompose itas illustrated in Figure 2.D = Z ?1 UEntry ?2 UPart ?3 UTerm, (5)where UEntry, UPart and UTerm are left sin-gular matrices of corresponding flattened ma-trices.
UTerm spans the term space, and wejust use the vectors corresponding to the 1, 000largest singular values in this paper, denotedas U?Term.Figure 2: 3-mode SVD of CQA tensorTo deal with such a huge sparse data set, weuse singular value decomposition (SVD) im-plemented in Apache Mahout3 machine learn-ing library, which is implemented on topof Apache Hadoop4 using the map/reduceparadigm and scalable to reasonably largedata sets.3http://mahout.apache.org/4http://hadoop.apache.org4.4 Question RetrievalIn order to retrieve similar question effec-tively, we project each CQA triple Dq ?R1?3?T to the term space byD?i = Di ?3 U?TTerm.
(6)Given a new question only with title part,we can represent it by tensor Dq ?
R1?3?T ,and its MContent and MAnswer are zero ma-trices.
Then we project Dq to the term spaceand get D?q.Here, D?q and D?i are degraded tensors andcan be regarded as matrices.
Thus, we can cal-culate the similarity between D?q and D?i withnormalized Frobenius inner product.For two matrices A and B, the Frobeniusinner product, indicated as A : B, is thecomponent-wise inner product of two matricesas though they are vectors.A : B =?i,jAi,jBi,j (7)To reduce the affect of length, we use thenormalized Frobenius inner product.A : B = A : B?A : A?
?B : B(8)While given a new question both with titleand content parts, MContent is not a zero ma-trix and could be also employed in the questionretrieval process.
A simple strategy is to sumup the scores of two parts.5 Experiments5.1 DatasetsWe collected the resolved CQA triples fromthe ?computer?
category of Yahoo!
Answersand Baidu Zhidao websites.
We just selectedthe resolved questions that already have beengiven their best answers.
The CQA triples arepreprocessed with stopwords removal (Chinesesentences are segmented into words in advanceby FudanNLP toolkit(Qiu et al, 2013)).In order to evaluate our retrieval system, wedivide our dataset into two parts.
The firstpart is used as training dataset; the rest is usedas test dataset for evaluation.
The datasets areshown in Table 2.437DataSet trainingdata sizetest datasizeBaidu Zhidao 423k 1000Yahoo!
Answers 300k 1000Table 2: Statistics of Collected DatasetsMethods MAPOkapi 0.359LSI 0.387(Jeon et al, 2005b) 0.372(Xue et al, 2008) 0.381LSTI 0.415Table 3: Retrieval Performance on Datasetfrom Yahoo!
Answers5.2 EvaluationWe compare our method with two baselinemethods: Okapi BM25 and LSI and two state-of-the-art methods: (Jeon et al, 2005b)(Xueet al, 2008).
In LSI, we regard each tripleas a single document.
Three annotators areinvolved in the evaluation process.
Given areturned result, two annotators are asked tolabel it with ?relevant?
or ?irrelevant?.
If anannotator considers the returned result seman-tically equivalent to the queried question, helabels it as ?relevant?
; otherwise, it is labeledas ?irrelevant?.
If a conflict happens, the thirdannotator will make the final judgement.We use mean average precision (MAP)to evaluate the effectiveness of each method.The experiment results are illustrated in Ta-ble 3 and 4, which show that our method out-performs the others on both datasets.The primary reason is that we incorpo-rate the content of the question body andthe answer parts into the process of ques-tion retrieval, which should provide addi-tional relevance information.
Different toMethods MAPOkapi 0.423LSI 0.490(Jeon et al, 2005b) 0.498(Xue et al, 2008) 0.512LSTI 0.523Table 4: Retrieval Performance on Datasetfrom Baidu Zhidaothe translation-based methods, our methodcan capture the mapping relations in threeparts (question, content and answer) simulta-neously.It is worth noting that the problem of datasparsity is more crucial for LSTI since the sizeof a tensor in LSTI is larger than a term-document matrix in LSI.
When the size of datais small, LSTI tends to just align the commonwords and thus cannot find the correspond-ing relations among the focus words in CQAtriples.
Therefore, more CQA triples may re-sult in better performance for our method.6 ConclusionIn this paper, we proposed a novel re-trieval approach for community-based QA,called LSTI, which analyzes the CQA tripleswith naturally tensor representation.
LSTIis a unified model and effectively resolves theproblem of lexical chasm for question retrieval.For future research, we will extend LSTI toa probabilistic form (Hofmann, 1999) for bet-ter scalability and investigate its performancewith a larger corpus.AcknowledgmentsWe would like to thank the anony-mous reviewers for their valuable com-ments.
This work was funded by NSFC(No.61003091 and No.61073069) and 973 Pro-gram (No.2010CB327900).ReferencesM.J.
Blooma and J.C. Kurian.
2011.
Researchissues in community based question answering.In PACIS 2011 Proceedings.R.
Burke, K. Hammond, V. Kulyukin, S. Lytinen,N.
Tomuro, and S. Schoenberg.
1997.
Ques-tion answering from frequently asked questionfiles: Experiences with the faq finder system.AI Magazine, 18(2):57?66.Deng Cai, Xiaofei He, and Jiawei Han.
2006.
Ten-sor space model for document analysis.
In SI-GIR ?06: Proceedings of the 29th annual inter-national ACM SIGIR conference on Researchand development in information retrieval.S.
Deerwester, S.T.
Dumais, G.W.
Furnas, T.K.Landauer, and R. Harshman.
1990.
Index-ing by latent semantic analysis.
Journal ofthe American society for information science,41(6):391?407.438Huizhong Duan, Yunbo Cao, Chin-Yew Lin, andYong Yu.
2008.
Searching questions by iden-tifying question topic and question focus.
InProceedings of ACL-08: HLT, pages 156?164,Columbus, Ohio, June.
Association for Compu-tational Linguistics.T.
Hofmann.
1999.
Probabilistic latent semanticindexing.
In Proceedings of the 22nd annual in-ternational ACM SIGIR conference on Researchand development in information retrieval, pages50?57.
ACM Press New York, NY, USA.J.
Jeon, W.B.
Croft, and J.H.
Lee.
2005a.
Find-ing semantically similar questions based on theiranswers.
In Proceedings of the 28th annual in-ternational ACM SIGIR conference on Researchand development in information retrieval, pages617?618.
ACM.J.
Jeon, W.B.
Croft, and J.H.
Lee.
2005b.
Findingsimilar questions in large question and answerarchives.
Proceedings of the 14th ACM interna-tional conference on Information and knowledgemanagement, pages 84?90.V.
Jijkoun and M. de Rijke.
2005.
Retrieving an-swers from frequently asked questions pages onthe web.
Proceedings of the 14th ACM interna-tional conference on Information and knowledgemanagement, pages 76?83.T.G.
Kolda.
2002.
Orthogonal tensor decompo-sitions.
SIAM Journal on Matrix Analysis andApplications, 23(1):243?255.Xipeng Qiu, Qi Zhang, and Xuanjing Huang.
2013.Fudannlp: A toolkit for chinese natural lan-guage processing.
In Proceedings of ACL.S.
Riezler, A. Vasserman, I. Tsochantaridis,V.
Mittal, and Y. Liu.
2007.
Statistical ma-chine translation for query expansion in answerretrieval.
In Proceedings of the Annual Meetingof the Association for Computational Linguis-tics.S.E.
Robertson, S. Walker, S. Jones, M.M.Hancock-Beaulieu, and M. Gatford.
1994.Okapi at trec-3.
In TREC, pages 109?126.K.
Wang, Z. Ming, and T.S.
Chua.
2009.
A syn-tactic tree matching approach to finding similarquestions in community-based QA services.
InProceedings of the 32nd international ACM SI-GIR conference on Research and development ininformation retrieval, pages 187?194.
ACM.X.
Xue, J. Jeon, and W.B.
Croft.
2008.
Retrievalmodels for question and answer archives.
In Pro-ceedings of the 31st annual international ACMSIGIR conference on Research and developmentin information retrieval, pages 475?482.
ACM.J.M.
Ye.
2005.
Generalized low rank approxima-tions of matrices.
Mach.
Learn., 61(1):167?191.G.
Zhou, L. Cai, J. Zhao, and K. Liu.
2011.Phrase-based translation model for question re-trieval in community question answer archives.In Proceedings of the 49th Annual Meeting ofthe Association for Computational Linguistics:Human Language Technologies-Volume 1, pages653?662.
Association for Computational Lin-guistics.439
