Proceedings of the First Workshop on Computational Approaches to Compound Analysis, pages 72?80,Dublin, Ireland, August 24 2014.Multiword noun compound bracketing using WikipediaCaroline Barri`ere Pierre Andr?e M?enardCentre de Recherche Informatique de Montr?eal (CRIM)Montr?eal, QC, Canada{caroline.barriere;pierre-andre.menard}@crim.caAbstractThis research suggests two contributions in relation to the multiword noun compound bracketingproblem: first, demonstrate the usefulness of Wikipedia for the task, and second, present a novelbracketing method relying on a word association model.
The intent of the association modelis to represent combined evidence about the possibly lexical, relational or coordinate nature oflinks between all pairs of words within a compound.
As for Wikipedia, it is promoted for itsencyclopedic nature, meaning it describes terms and named entities, as well as for its size, largeenough for corpus-based statistical analysis.
Both types of information will be used in measuringevidence about lexical units, noun relations and noun coordinates in order to feed the associa-tion model in the bracketing algorithm.
Using a gold standard of around 4800 multiword nouncompounds, we show performances of 73% in a strict match evaluation, comparing favourablyto results reported in the literature using unsupervised approaches.1 IntroductionThe noun compound bracketing task consists in determining related subgroups of nouns within a largercompound.
For example (from Lauer (1995)), (woman (aid worker)) requires a right-bracketing inter-pretation, contrarily to ((copper alloy) rod) requiring a left-bracketing interpretation.
When only threewords are used, n1 n2 n3, bracketing is defined as a binary decision between grouping (n1,n2) or group-ing (n2,n3).
Two models, described in early work by Lauer (1995), are commonly used to inform suchdecision: the adjacency model and the dependency model.
The former compares probabilities (or moreloosely, strength of association) of two alternative adjacent noun compounds, that of n1 n2 and of n2 n3.The latter compares probabilities of two alternative dependencies, either between n1 and n3 or betweenn2 and n3.Most compound bracketing research has focused on three-noun compounds as described above.
Somerecent work (Pitler et al.
(2010), Vadas and Curran (2007b)) looks at larger compounds, experimentingwith a dataset created by Vadas and Curran (2007a) which we also use in our research.
For largernoun compounds, the adjacency model alone will not allow longer range dependencies to be taken intoaccount.
This had been noted much earlier in Barker (1998) using examples such as (wooden (((French(onion soup)) bowl) handle)) to show a long-range dependency between wooden and handle.To allow for such long-range dependencies, our bracketing algorithm looks at all possible word as-sociations within the full expression to make its decisions.
The word associations are captured withinan association model which goes beyond the adjacency and dependency models.
The association modelrepresents combined evidence about the possibly lexical, relational or coordinate nature of the links be-tween all word pairs.
In its current implementation, our association model relies on Wikipedia as aresource for obtaining all three types of evidence.
Wikipedia is used in two forms: first as a list of termsand named entities (Wikipedia page titles), and second, as a large corpus obtained from the merging ofall its pages.
The resulting corpus is large enough to be used for statistical measures.
The most currentversion contains 14,466,099 pages in English for an uncompressed file size of 47 gigabytes (includingThis work is licenced under a Creative Commons Attribution 4.0 International License.
License details: http://creativecommons.org/licenses/by/4.0/72some metadata).
To the best of our knowledge, no previous research has used Wikipedia for the nounbracketing task, and this research will explore its usefulness.The reminder of this article will unfold as follows.
Section 2 presents a brief literature review.
Sec-tion 3 describes the dataset used in our experiments.
Section 4 presents the bracketing algorithm, andSection 5 the implementation of a word association model using Wikipedia.
Section 6 describes ourevaluation approach, while results are presented and analysed in Section 7.
Section 8 concludes andsuggests future work.2 Related workNoun compound bracketing has not received as much attention as many other Natural Language Pro-cessing (NLP) tasks.
Nakov and Hearst (2005) call it an understudied language analysis problem.
Earlywork by Lauer (1995) took inspiration in even earlier linguistic work by Levi (1978).
Lauer (1995) hav-ing devised a small dataset of 3-word noun compounds, his dataset was reused by various researchers(Lapata et al.
(2004), Girju et al.
(2005), Nakov and Hearst (2005)) who promoted the use of corpus-based empirical methods for the task.To address the noun compound bracketing task, different authors use different datasets, different viewson the problem (adjacency, dependency), different methods of resolution (supervised, unsupervised)and different constraints on the problem (compound seen in isolation or in context).
Independentlyof such differences, all researchers have an interest in evaluating word-pair associations.
Most recentresearch uses the Web for providing word pair association scores to their bracketing algorithm.
The workof Lapata et al.
(2004) shows usefulness of web counts for different tasks, including noun compoundbracketing.
The work of Pitler et al.
(2010) intensively uses web-scale ngrams in a supervised task forlarge NP bracketing, showing that coverage impacts on accuracy.
Beyond bigram counts on the web,varied and clever searches (Nakov and Hearst, 2005) have been suggested such as the use of paraphrases(n1 causes n2) or simpler possessive markers (n1?s n2) or even the presence of an hyphen between words(n1-n2).
All variations are to provide better word association estimates and improve bracketing.
The useof web counts is sometimes complemented by the use of more structured resources, such as in Vadas andCurran (2007b) who combines web counts with features from Wordnet.In our research, instead of web counts, we rely on a community-based encyclopedic resource,Wikipedia, for corpus-based evidence.
We rely on the same resource to access a list of terms and entities.Although not much of the structure of Wikipedia is used in our current implementation, such as its cate-gories or page links, we can envisage to use it in future work.
Similarly to other researchers mentionedabove, our goal is to gather evidence for word-pair association, although an important contribution ofour work is to refine this notion of word-pair association into three subtypes of association: lexical, re-lational and coordinate.
We suggest that a better characterization of the possible links among word pairsin a large compound will better inform the bracketing algorithm.3 DatasetVadas and Curran (2007a) manually went through the Penn Treebank (Marcus et al., 1994) to furtherannotate large NPs.
They openly published a diff file of the Penn Treebank to show their annotationswhich differ from the original.
From this available file, we constructed our gold-standard dataset byextracting large NPs (three or more words) which only include relevant items (common and propernouns, adverbs and adjectives), removing determiners, numbers, punctuations and conjunctions.
Theexpressions were then verified for completeness, so that the opening bracket should be closed within thelength of text defined in the differential file.
Finally, tags and single words enclosing parentheses wereremoved to produce simplified versions of the bracketed expressions (e.g (NML (NNP Nesbitt) (NNPThomson) (NNP Deacon) ) becomes (Nesbitt (Thomson Deacon)) ).Vadas and Curran (2007a) used a Named Entity annotator to suggest bracketing to the human anno-tators (who could accept or reject them).
The entity types used were the ones defined by Weischedeland Ada Brunstein (2005) (e.g.
Person, Facility, Organization, Nationality, Product, Event, etc).
Named73entities could be kept as-is by the annotators or could be bracketed if deemed compositional.
Annotatorswere also instructed to use a default right-bracketing (implicit in Penn Treebank) for difficult decision.In our dataset, we transformed the ones left as-is into right-bracketed in order to have all expressionsfully bracketed.
This process might seem controversial, as it assumes compositionality of all namedentities, which for sure, is a wrong hypothesis.
The alternative, though, would require the bracketing al-gorithm to recognize named entities, which we consider outside the scope of this research.
Furthermore,it would also be wrong to assume all named entities are non-compositional.
For example New York StockExchange is clearly compositional, and a Named Entity Tagger based on Wikipedia would easily iden-tify it as a named entity (although the use of Wikipedia as a source of named entities is also debatable).Clearly, no solution is satisfying.
We opted for the approximation which provided a fully bracketed goldstandard to which our results could be compared.
We are aware that this will have a negative impact, insome cases, on our results.The extraction produced a total 6,600 examples from which we removed duplicate expressions, yield-ing a corpus of 4,749 unique expressions.
Among those unique expressions, 2,889 (60.95%) were threewords long (e.g.
Mary Washington College), 1,270 (26.79%) had four words (e.g.
standardized achieve-ment tests scores), 413 (8.71%) with five words (e.g.
annual gross domestic product growth) and theremaining longer expressions (up to nine words) covered around 3.5% of the dataset1.4 Bracketing methodAs in the work of Pitler et al.
(2010), our bracketing algorithm takes into account all possible wordpairs within the noun compound.
This differs from Barker?s algorithm Barker (1998) used in Vadasand Curran (2007b) which only uses local information, three-words at a time, in a right-to-left movingwindow.
We briefly present our algorithm below and refer the reader to M?enard and Barri`ere (2014) fora more detailed explanation.First, a list (L1) is created to contain every word pair that can be generated, in order, from an ex-pression.
For example, a list L1 {(A,B), (A,C), (A,D), (B,C), (B,D), (C,D)} would be created fromexpression ?A B C D?.
Second, a dependency score needs to be assigned to each pair.
Our bracketingalgorithm actually builds a dependency tree and requires these dependency scores.
We make the assump-tion that dependencies are implicitly directed left-to-right.
This is an oversimplification, as there are afew cases, such as Vitamin C or Cafe Vienna, pointed in (Nakov, 2013), where the direction is reversed.Furthermore, this hypothesis is valid only for English and renders our algorithm less applicable to otherlanguages.
Although fair for English, this hypothesis should be revisited in future work.The next step is building a final list of dependencies (L2) to represent the full dependency tree.
To doso, the algorithm repeatedly selects from L1 the word pair with the maximum score and adds it to L2only if both (a) the modifier has not already been used, and (b) the new pair does not create a crossingof modifier/head pairs in the expression.
For example, if L2 already contains (AB)(C(DE)), then (BD)would create an invalid crossing and is not accepted.
The selection of pairs from L1 ends when all wordsfrom the expression, except for the right-most one, are used as modifiers in L2.Our algorithm is greedy and considers only the best score at every step.
We have experimented withrandomized greedy algorithms as well, choosing randomly between top N scores at each step, but sinceresults did not improve, we do not report on them in the current article.
The bracketing algorithm favourshigh dependency scores without consideration for the actual distance between word pairs in the sourceexpression.
This helps linking far reaching dependencies in noun compounds, but might also force somestrong association between two distant words without regard to the soundness of using nearer words.5 Implementing an association model using WikipediaOur association model contains three types of association: lexical, relational and coordinate.
Each onewill be measured using Wikipedia through different approximation strategies.
The challenge is the inte-gration of the association model with the bracketing algorithm.
We mainly explore a solution of score1We describe our dataset in more details in M?enard and Barri`ere (2014), and our extraction method is published as part ofthe LREC resources sharing effort.74modulation which does not require the bracketing algorithm to be modified but rather use the three asso-ciation scores to modulate the dependency score required by the bracketing algorithm.
We present belowa basic dependency score, and then different strategies to transform the three types of association intomodulation factors on that dependency score.Basic dependency association: Based simply on the co-occurrence of two words in a corpus, this basicassociation will be influenced by the actual corpus (domain and size), and the association measure used.In our current experiment, Wikipedia pages are merged into a large corpus (47 Gigabytes) coveringmultiple domains.
As for the association measure, we compare Dice and Point-Wise MutualInformation (PMI), although many more exist in the literature.
Co-occurrence is not a direct measure ofdependency, it is an approximation.
A true dependency measure would require a syntactic analysis(using a link parser) of the whole corpus.
We will explore this idea in future work.Relational association: The relational association is a refinement to the dependency association.
Insemantic analysis of noun compounds, an important goal is to characterize the nature of the dependencebetween its words, such as cause, purpose, location, etc (see work by Girju et al.
(2005), Nakov andHearst (2005), Nastase et al.
(2013) among many).
Here, we do not require the identity relations, butrather search for indications of the relational status of a word pair.
In our current implementation,relational association is na?
?vely determined by the presence of a preposition between two nouns.
Weuse the prepositions: about, at, by, for, from, in, of, on, to, with.
We search in the corpus for patternssuch as ?N1 at N2?
and ?N1 for N2?, etc.
The frequency of these will be used to boost the basicdependency association scores.Coordinate association: Proximity sometimes refers implicitly to coordination, as for example thewords cotton and polyester in the expression cotton polyester shirt.
Explicit external evidence that thesewords often co-occur in a coordination relation could lower their dependency association in expressionssuch as cotton polyester shirt.
To gather such evidence, we measure the frequency of explicitcoordination between word pairs in Wikipedia.
The common conjunctions: or, and, nor are used.
Wesearch in the corpus for patterns such as ?N1 or N2?
and ?N1 and N2?, etc.
Contrarily to relationalassociations boosting the basic dependency association scores, coordinate associations should attenuatethe dependency scores.Lexical association: Based on the idea that many compounds, even named entities, are compositional,we want to determine the likeliness that a subexpression in a compound forms itself a lexical unit with ameaning of its own.
To do so, we use a first approach requiring a set of corpus-based statisticalapproximations and a second approach requiring Wikipedia page titles.?
Statistical approximation: The presence of determiners (a, an, the) and plural forms are used asstatistical evidence of lexical association.
For example, starting with expression cotton polyestershirt, corpus analysis shows that the cotton shirts is frequent, which can be used to boost the depen-dency score between cotton and shirt.
On the other hand, the cotton polyesters will be much lessfrequent.
The presence of indicators (determiners and plurals) can be used independently, search-ing for patterns such as ?the N1 N2?
and ?N1 plural(N2)?, or together for patterns such as ?a N1plural(N2)?.?
Presence in Wikipedia: A second strong indicator of lexical association for a word pair is its pres-ence in an encyclopedic resource (Wikipedia).
In fact, not only word pairs, but for any subcompoundof two or more words are considered for look-up as Wikipedia entries.
Since we now have lexicalunits of any length, rather than word pairs, our score modulation is not as straight forward.
Wethought of two different strategies.The first strategy, in line with score modulation, uses all word pairs found in the lexical units toboost dependency scores.
For example, assuming the compound ABCDE, with [BCD] found asa lexical unit in Wikipedia.
Then, the association scores of pairs [BC],[CD],[BD] are boostedequally (uniform boost).
This will not help for any internal bracketing of [BCD], but will reinforcethe fact that [BCD] should stay together within the larger compound.
A variant to uniform boost75Gold EvaluatedGold elementsStrictLenientSubexpression Binary tree Subexpression Binary tree(a b) c (a b) c (a b) a-b, b-c 100% 100% 100%(a b) c a (b c) (a b) a-b, b-c 0% 0% 50%(a b) (c d) (a b) (c d) (a b), (c d) a-b, c-d, b-d 100% 100% 100%(a b) (c d) a (b (c d)) (a b), (c d) a-b, b-d, c-d 0% 50% 66.6%(((a b) c) d) (e f) a (b (c (d (e f)))) (a b), (a b c), (a bc d), (e f)a-b, b-c, c-d, d-f, e-f 0% 25% 40%Average: 40% 55% 71.3%Table 1: Applied examples of evaluation metrics.is a right-attachment boost to mimic the default right bracketing in the gold standard for the longerunits.The second strategy is one of compound segmentation, in which lexical units found become seg-mentation constraints on the bracketing algorithm.
Association scores are them measured betweenpairs of lexical units instead of between words pairs.
We also try to minimize the number of en-tities within the compound.
For example, assuming again we wish to bracket compound ABCDE,and find the possible three segmentations into lexical units using Wikipedia: (1)[AB][CDE], (2)[AB][CD][E], (3) [ABC][DE].
Only segmentations (1) and (3) are kept since they have two lexicalunits and not three.
The association scores must then be calculated between pairs of lexical units,and within each lexical unit containing three words or more (to perform full bracketing).
Bracketingwithin a lexical unit will be performed using the same bracketing methods described above.
Brack-eting between lexical units requires association scores between these units.
For doing so, using theexample above, we will search in corpus for cooccurrences of [AB] with [CDE] for segmentation(1), and [ABC] with [DE] for segmentation (3).
Since statistics on longer units will be sparse in thecorpus, we will also measure association scores between heads of the lexical units.
For example, insegmentation (1) the association between heads [B] and [E] would be measured.6 Evaluation metricsThree methods are used to evaluate performances: strict, lenient binary tree and lenient sub-expression.The strict evaluation verifies that all bracketed groups of the gold-standard expression are exactly thesame as those found in the evaluated expression, providing a score of 1 or 0.
The two lenient evaluationscompute the ratio between the number of matching groups from a gold expression with those found inthe evaluated expression.
In other words, lenient is the recall score based on the gold elements.In lenient binary tree, each fully bracketed expression is parsed as a binary tree.
From that tree, eachmodifier/head pair becomes a basic evaluation element.
For example, in (A (B C)), two elements A-C andB-C are used for the evaluation process.
This method boosts the performance level on most expressions,but especially those composed of three words, for which a minimum 50% is always obtained.In lenient sub-expression, evaluation elements are rather sub-expressions to provide a more balancedscore.
The method extracts each bracketed group except the top-level group and removes all internalparentheses from each one.
Thus, from the expression (((A B) C) D), the method extracts (A B) and (A BC).
The two resulting sub-expressions become gold elements for comparison with those obtained fromthe evaluated expression.
Table 1 shows five examples illustrating score variations using the differentmethods on expressions of different length.7 ResultsIn section 5, we described various approaches to capture, using Wikipedia, the different types of asso-ciation proposed in our model: lexical, relational and coordinate.
We also presented two solutions forcombining this more complex model with the bracketing algorithm of section 4 which expects a singletype of association, that of dependency.
Below, using a dataset of 4749 compound nouns, presented insection 3, we report on some interesting results.76Resource Algorithm Strict LenientWikipediaDice 55.00% 67.63%PMI 56.25% 68.98%Google Web NgramDice 51.80% 63.90%PMI 60.41% 72.47%Table 2: Comparing basic association scores in Wikipedia and Google Web.7.1 BaselineTo measure the impact of combining different types of associations, we first establish our baseline asthe bracketing results obtained solely with the basic dependency association scores, as measured onWikipedia.
To further validate our baseline, we wish to compare it to the literature.
The closest researchproviding comparable results on large compounds are Vadas and Curran (2007b) and Pitler et al.
(2010),although both focus on supervised approaches, and furthermore, Vadas and Curran (2007b) use con-textual features, assuming the noun compounds are to be bracketed in context.
Still, Vadas and Curran(2007b) give some baseline results for an unsupervised approach (the supervised approach was promotedin their article) to which we compare our baseline.
Far from an ideal comparison (which would be withthe exact same dataset and setting), it still provides some indication of the performance of our baseline.They report exact match for complex NPs to be 54.66% for default right branching, 32.66% chi-squaredependency and 35.86% chi-square adjacency.
As we obtain around 55% for strict matches (see Table 2,first row), we seem above the unsupervised approach they used, which combined their association scoreswithin an implementation of Barker?s algorithm.To confirm that merged Wikipedia pages form a large enough corpus in comparison to most recentwork on noun bracketing using web counts (see section 2), we use the English Google Web Ngrams (Linet al., 2010) (GWN), a 1T corpus contains n-gram counts collected from 1 trillion words of web text, andperformed our bracketing algorithm with Wikipedia basic dependency scores, and GWN bigram scores.As shown in Table 2, results are comparable, slightly higher for Dice (55.0% compared to 51.8%) andslightly lower for PMI (56.25% compared to 60.41%).Throughout our experiments, we have continued using both association measures (Dice and PMI),as well as performing both Barker?s algorithm and our bracketing algorithm, but since our algorithmwith Dice always gave better results (contrarily to the baseline in which PMI performed better), we onlypresent those results in the following sections.7.2 Corpus-based improvementsIn Section 5, we described how the use of stop words (conjunctions, prepositions, determiners) com-bined with word pairs of interest could respectively modulate the basic dependency association scores toemphasize coordinate, relational, or lexical association.For lexical association, word pairs preceded by determiners were searched for in the corpus.
We trieddifferent ways of combining association scores between the form with the determiner (?the N1 N2?)
andthe word pair only (N1 N2), such as adding scores, keeping the maximum or minimum score.
As well,we tried different ways of combining the scores obtained with the different determiners (a, the, an), againadding, keeping the maximum or the minimum score.
Unfortunately, none of these variations helped.We also experimented with searching for plural forms in corpus to emphasize lexical association, whichprovided a small increase to the baseline as shown in Table 3.For relational association, we searched for noun pairs with prepositions.
The same merging strategiesgiven above for the use of determiners we tried.
The best configuration uses a relational boosting strategyof adding scores and a preposition merging strategy of using the minimum score among all prepositions.Even with the best combination, overall, the improvement is marginal as shown in Table 3.For coordinate association, we searched for noun pairs with conjunctions.
Similarly to determinersand prepositions, we tried different merging strategies.
Since we are interested in an attenuation of thedependency score with the coordinate score, our merging strategies were of subtracting scores or using77Option Strict Lenient BinaryBaseline 0.5500 0.6763 0.8132Only including lexical association 0.5842 0.7106 0.8321Only including relational association 0.5854 0.7093 0.8314Only including coordinate association 0.5867 0.7110 0.8325Table 3: Impact of corpus-based statistics (lexical, relational, coordinate association)Option Strict Lenient BinaryBaseline 0.5500 0.6763 0.8132Using entity-based refinement (uniform distribution) 0.6020 0.7257 0.8408Using entity-based compound segmentation 0.7316 0.8213 0.8940Table 4: Use of entitiesthe minimum.
Again, unfortunately, improvement is marginal, as shown in Table 3.7.3 Entity-based improvementsOur second approach to promote the lexical unit association score is to find which sub-expressions ofthe compound are Wikipedia page titles.
In Section 5, we suggested two strategies of using these entries,either score modulation or compound segmentation.In score modulation, we tried uniform boosting and right boosting as explained in Section 5, withdifferent boosting factors arbitrarily set between 10 and 100.
The best result, obtained using a uniformboost with a factor of 50 is presented in Table 4.
There is a small improvement using this method.
Thesecond strategy of compound segmentation is the one providing the most significant gain.
An increase of13% is obtained for the strict evaluation as shown in the last row of Table 4.
For the sake of completeness,we reran all the different variations and parameters which are used for performing the within and betweenlexical units bracketing.
The best configuration required that (1) basic dependency scores were actuallyreplaced by scores obtained by finding plural forms in the corpus (lexical association), (2) determinerswere not used, (3) the negative modulation from conjunctions (coordinate association) is obtained bysubtracting their frequency from the basic scores, (4) the positive modulation of prepositions (relationalassociation) is obtained by adding their frequency to the basic scores, (5) as different prepositions aresearched in corpus, the one with minimum frequency should be taken to alter basic scores, same forconjunctions (6) the head of lexical units is used to measure the ?between units?
association scores.7.4 Result analysisWe first note some aspects of the gold standard that would affect the adequacy of our algorithm, and ourresults.?
Noun compound status: A few examples in the dataset contain very generic adjectives, such as:(certain ((natural resource) assets)), (such ((gas management) contracts)),(most (structural engi-neers)), or ((too much) attention).
These are not problematic in themselves, but our statisticalapproximations for lexical, relational and coordinate associations are not adequate for these cases.?
Abbreviations: Some examples in the gold standard contain abbreviations, for example, (republican(u.s. sen.)), ((american president) cos.) or (((el dorado) investment) co.).
Again, these are notproblematic in themselves, but we have not yet implemented anything in our algorithm to managesuch cases.?
Ambiguity: Some examples found in the gold standard, such as ((sun ((life assurance) society)) plc)or ((magnetic (resonance imaging)) equipment) are not obvious to us as being correct.?
Compositional examples: On the positive side, the dataset certainly contains many interesting ex-amples, such as ((new england) ((medical center) hospitals)), ((northern california) (home prices)),78(world-wide ((advanced materials) operations)), (((lone star) spokesman) (michael london)), or((magnetic (resonance imaging)) equipment).
These examples are interesting because they show avariety of right and left bracketing needed and a variety of named entities and terms of differentcompositional nature.
Research on compound bracketing is required for those examples, as theywill probably never end-up in even the most extensive lists of terms and named entities.To better understand this dataset and the adequacy of our algorithm to its content, we intend, in futurework, to perform a manual sampling to determine the types of compounds, and the possible ambiguities.As for Wikipedia as a resource, it is very valuable and contains many named entities (places, corpora-tions, persons, etc), but it can never contain all entities.
For example, we will find tadeusz mazowiecki tohelp in bracketing (polish (prime minister)) (tadeusz mazowiecki), but we will not find bruno lucisano,and wrongly bracket (((rome (film producer)) bruno) lucisano).Independently of the gold standard and the resource used, our method has multiple limitations andpeculiarities.
We believe that the general approach presented in this research is quite valid: a proposalfor the refinement of generic association scores into three subtypes of associations: lexical, relationaland coordinate associations.
Nevertheless, the statistical approximations used for evaluating the differentassociation types should be revisited and refined.8 ConclusionAlthough bracketing of three-word expressions has been performed quite successfully using unsuper-vised approaches with web-corpus resources ((Nakov and Hearst, 2005), (Vadas and Curran, 2007b)),compound bracketing of large expressions remains a challenge.One research direction, taken by Vadas and Curran (2007b) and Pitler et al.
(2010) is to investigatesupervised learning approaches which will be able to build on the redundancy within the dataset.
Wetake a different direction, that of developing a more complex association model and exploring Wikipediain an unsupervised manner.
Our research presents a noun compound bracketing algorithm which goesbeyond the adjacency / dependency models presented so far in the literature.
We suggest a method thattakes into account different meaning of the proximity of two words, that of being part of the same lexicalunit, or being coordinates, or being in a relation.Our current implementation of our association model certainly provides improvement on the basicassociation scores, but it does not give a clear view of whether our corpus-based approximations arecorrect or not.
This deserves future investigation into how to best approximate with statistical measuresthe notions of relational, coordinate and lexical associations.
On the other hand, the use of Wikipediaas an encyclopedic resource to help determine lexical units certainly provides the most gain and the bestresults.
On the dataset of 4749 compounds, our best results are 73.16% strict, 82.13% lenient and 89.40%binary tree evaluation.
Further use of the structure of Wikipedia can be investigated to help characterizethe different types of associations.An important future goal is to refine the association model, and better anchor it in both linguistic andcomputational linguistic traditions of noun compound analysis.
The model deserves to be studied in itsown, regardless of its implementation, which here was performed using Wikipedia.
A better understand-ing of the model and its impact on noun compound bracketing might direct us to better choices for theimplementation of the association measures.Lastly, similarly to other researchers who look at noun compound bracketing as the first step of se-mantic analysis of NPs to elicit semantic relations (purpose, cause, location, etc) between subgroups ofwords (Girju et al.
(2005), Nastase et al.
(2013)), we want to pursue our work into a more fine-grained un-derstanding of noun compounds (Nakov, 2013), combining bracketing with the identification of specificnoun relations.9 AcknowledgementsThis research project is partly funded by an NSERC grant RDCPJ417968-11, titled Toward a secondgeneration of an automatic product coding system.79ReferencesKen Barker.
1998.
A Trainable Bracketer for Noun Modifiers.
In Twelfth Canadian Conference on ArtificialIntelligence (LNAI 1418).Roxana Girju, Dan Moldovan, Marta Tatu, and Daniel Antohe.
2005.
On the semantics of noun compounds.Computer Speech & Language, 19(4):479?496, October.Mirella Lapata, Portobello St, S Sheffield, and Frank Keller.
2004.
The Web as a Baseline : Evaluating thePerformance of Unsupervised Web-based Models for a Range of NLP Tasks.
In Proceedings of the HLT-NAACL, pages 121?128.Mark Lauer.
1995.
Corpus statistics meet the noun compound: some empirical results.
Proceedings of the 33rdannual meeting on Association for Computational Linguistics, pages 47?54.Judith Levi.
1978.
The syntax and semantics of complex nominals.D Lin, KW Church, H Ji, and S Sekine.
2010.
New Tools for Web-Scale N-grams.
LREC.Mitchell P Marcus, Santorini Beatrice, and Mary A Marcinkiewicz.
1994.
Building a large annotated corpus ofEnglish: the Penn Treebank.
Computational Linguistics, 19:313?330.Pierre Andr?e M?enard and Caroline Barri`ere.
2014.
Linked Open Data and Web Corpus Data for noun compoundbracketing.
In Proceedings of the Ninth International Conference on Language Resources and Evaluation(LREC?14), pages 702?709, Reykjavik, Iceland.Preslav Nakov and M Hearst.
2005.
Search engine statistics beyond the n-gram: Application to noun compoundbracketing.
Proceedings of the Ninth Conference on Computational Natural Language Learning, (June):17?24.Preslav Nakov.
2013.
On the interpretation of noun compounds: Syntax, semantics, and entailment.
NaturalLanguage Engineering, 19(03):291?330, May.Vivi Nastase, Preslav Nakov, Diarmuid O Seaghdha, and Stan Szpakowicz.
2013.
Semantic Relations BetweenNominals.
Morgan and Claypool Publishers.Emily Pitler, Shane Bergsma, Dekang Lin, and Kenneth Church.
2010.
Using web-scale N-grams to improvebase NP parsing performance.
Proceedings of the 23rd International Conference on Computational Linguistics,(August):886?894.David Vadas and JR Curran.
2007a.
Adding noun phrase structure to the Penn Treebank.
45th Annual Meeting ofthe Association of Computational Linguistics, (June):240?247.David Vadas and JR Curran.
2007b.
Large-scale supervised models for noun phrase bracketing.
10th Conferenceof the Pacific Association for Computational Linguistics, (2004):104?112.Ralph Weischedel and Ada Brunstein.
2005.
BBN pronoun coreference and entity type corpus.
Technical report,Linguistic Data Consortium.80
