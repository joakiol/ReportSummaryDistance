Proceedings of the Fourth Workshop on Statistical Machine Translation , pages 100?104,Athens, Greece, 30 March ?
31 March 2009. c?2009 Association for Computational LinguisticsLIMSI?s statistical translation systems for WMT?09Alexandre Allauzen, Josep Crego, Aur?lien Max and Fran?ois YvonLIMSI/CNRS and Universit?
Paris-Sud 11, FranceBP 133, 91403 Orsay C?dexfirstname.lastname@limsi.frAbstractThis paper describes our Statistical Ma-chine Translation systems for the WMT09(en:fr) shared task.
For this evaluation, wehave developed four systems, using twodifferent MT Toolkits: our primary sub-mission, in both directions, is based onMoses, boosted with contextual informa-tion on phrases, and is contrasted with aconventional Moses-based system.
Addi-tional contrasts are based on the Ncodetoolkit, one of which uses (part of) the En-glish/French GigaWord parallel corpus.1 IntroductionThis paper describes our Statistical MachineTranslation systems for the WMT09 (en:fr) sharedtask.
For this evaluation, we have developed foursystems, using two different MT toolkits: ourprimary submission, in both direction, is basedon Moses, boosted with contextual informationon phrases; we also provided a contrast with avanilla Moses-based system.
Additional contrastsare based on the N-code decoder, one of whichtakes advantage of (part of) the English/French Gi-gaWord parallel corpus.2 System architecture and resourcesIn this section, we describe the main characteris-tics of the baseline phrase-based systems used inthis evaluation and the resources that were used totrain our models.2.1 Pre- and post-processing toolsAll the available textual corpora were processedand normalized using in-house text processingtools.
Our last year experiments (D?chelotte etal., 2008) revealed that using better normalizationtools provides a significant reward in BLEU, a factthat we could observe again this year.
The down-side is the need to post-process our outputs so asto ?detokenize?
them for scoring purposes, whichis unfortunately an error-prone process.Based again on last year?s experiments, our sys-tems are built in ?true case?
: the first letter of eachsentence is lowercased when it should be, and theremaining tokens are left as is.Finally, the N-code (see 2.5) and the context-aware (see 3) systems require the source to bemorpho-syntactically analysed.
This was per-formed using the TreeTagger1 for both languages.2.2 Alignment and translation modelsOur baseline translation models (see 2.4 and 2.5)use all the parallel corpora distributed for this eval-uation: Europarl V4, news commentary (2006-2009) and the additional news data, totalling 1.5Msentences.
Our preliminary attempts with largertranslation models using the GigaWord corpus arereported in section 3.2.
All these corpora werealigned with GIZA++2 using default settings.2.3 Language ModelsTo train our language models (LMs), we took ad-vantage of the a priori information that the testset would be of newspaper/newswire genre.
We1http://www.ims.uni-stuttgart.de/projekte/corplex/TreeTagger.2http://www.fjoch.com/GIZA++.html.100Source Period M. wordsNews texts 1994-06 3 317En BN transcripts 2000-07 341WMT 86Newswires 1994-07 723Newspapers 1987-06 486Fr WEB 2008 23WMT 46News-train08 167Table 1: Corpora used to train the target languagemodels in English and French.thus built much larger LMs for translating both toFrench and to English, and optimized their combi-nation on the first part of the official developmentdata (dev2009a).Corpora and vocabulary Statistics regardingthe training material are summarized in table 1 interms of source, time period, and millions of oc-currences.
?WMT?
stands for all text providedfor the evaluation.
Development sets and the largetraining corpora (news-train08 and the GigaWordcorpus) were not included.
Altogether, these datacontain a total number of 3.7 billion tokens for En-glish and 1.4 billion tokens for French.To estimate such large LMs, a vocabulary wasfirst defined for both languages by including all to-kens in the WMT parallel data.
This initial vocab-ulary of 130K words was then extended by addingthe most frequent words observed in the additionaltraining data.
This procedure yielded a vocabularyof one million words in both languages.Language model training The training datawere divided into several sets based on dates ongenres (resp.
7 and 9 sets for English and French).On each set, a standard 4-gram LM was estimatedfrom the 1M word vocabulary with in-house toolsusing absolute discounting interpolated with lowerorder models.
The resulting LMs were then lin-early interpolated using interpolation coefficientschosen so as to minimise perplexity of the devel-opment set (dev2009a).
Due to memory limita-tions, the final LMs were pruned using perplexityas pruning criterion.Out of vocabulary word and perplexity Toevaluate our vocabulary and LMs, we used the of-ficial devtest and test sets.
The out-of-vocabulary(OOV) rate was drastically reduced by increasingthe vocabulary size, the mean OOV rate decreas-ing from 2.5% to 0.7%, a trend observed in bothlanguages.For French, using a small LM trained on the"WMT" data only resulted in a perplexity of 301on the devtest corpus and 299 on the test set.
Us-ing all additional data yielded a large decrease inperplexity (106 on the devtest and 108 on the test);again the same trend was observed for English.2.4 A Moses baselineOur baseline system was a vanilla phrase-basedsystem built with Moses (Koehn et al, 2007) us-ing default settings.
Phrases were extracted usingthe ?grow-diag-final-and?
heuristics, using a max-imum phrase length of 7; non-contextual phrasescores contain the 4 translation model scores, plusa fixed phrase penalty; 6 additional scores param-eterize the lexicalized reordering model.
Defaultdecoding options were used (20 alternatives perphrase, maximum distortion distance of 7, etc.
)2.5 A N-code baselineN-code implements the n-gram-based approachto Statistical Machine Translation (Mari?o et al,2006).
In a nutshell, the translation model is im-plemented as a stochastic finite-state transducertrained using a n-gram model of (source,target)pairs (Casacuberta and Vidal, 2004).
Trainingsuch a model requires to reorder source sentencesso as to match the target word order.
This is alsoperformed via a stochastic finite-state reorderingmodel, which uses part-of-speech information togeneralise reordering patterns beyond lexical reg-ularities.
The reordering model is trained on a ver-sion of the parallel corpora where the source sen-tences have been reordered via the unfold heuris-tics (Crego and Mari?o, 2007).
A conventional n-gram language model of the target language pro-vides the third component of the system.In all our experiments, we used 4-gram reorder-ing models and bilingual tuple models built usingKneser-Ney backoff (Chen and Goodman, 1996).The maximum tuple size was also set to 7.2.6 Tuning procedureThe Moses-based systems were tuned using theimplementation of minimum error rate train-ing (MERT) (Och, 2003) distributed with theMoses decoder, using the development corpus(dev2009a).
For the context-less systems, tun-ing concerned the 14 usual weights; tuning the10122 weights of the context-aware systems (see 3.1)proved to be much more challenging, and theweights used in our submissions are probably farfrom optimal.
The N-code systems only rely on9 weights, since they dispense with the lexical re-ordering model; these weights were tuned on thesame dataset, using an in-house implementation ofthe simplex algorithm.3 Extensions3.1 A context-aware systemIn phrase-based translation, source phrases aretranslated irrespective of their (source) context.This is often not perceived as a limitation as(i) typical text domains usually contain only fewsenses for polysemous words, thus limiting theuse of word sense disambiguation (WSD); and (ii)using long-span target language models (4-gramsand more) often capture sufficient context to se-lect the more appropriate translation for a sourcephrase based on the target context.
In fact, at-tempts at using source contexts in phrase-basedSMT have to date failed to show important gainson standard evaluation test sets (Carpuat and Wu,2007; Stroppa et al, 2007; Gimpel and Smith,2008; Max et al, 2008).
Importantly, in all con-ditions where gains have been obtained, the tar-get language was the ?morphologically-poor?
En-glish.Nonetheless, there seems to be a clear consen-sus on the importance of better exploiting sourcecontexts in SMT, so as to improve phrase disam-biguation.
The following sentence extract fromthe devtest corpus is a typical example where thelack of context in our phrase-based system yieldsan incorrect translation:Source: the long weekend comes with a price .
.
.Target: Le long week-end vient avec un prix .
.
.
(the long weekend comes accompanied by a price)While grammatically correct, the French trans-lation sounds unnatural, and getting the correctmeaning requires knowledge of the idiom in thesource language.
In such a situation, the right con-text of the phrase comes with can be successfullyused to propose a better translation.3From an engineering perspective, integratingcontext into phrase-based SMT systems can beperformed by (i) transforming source words intounique tokens, so as to record the original context3Our context-aware phrase-based system indeed proposesthe appropriate translation: Le long week-end a un prix.of each entry of the phrase table; and by (ii) addingone or several contextual scores to the phrase ta-ble.
Using standard MERT, the correspondingweights can be optimized on development data.A typical contextual score corresponds top(e|f , C(f)), where C(f) is some contextual in-formation about the source phrase f .
An exter-nal disambiguation system can be used to pro-vide one global context score (Stroppa et al, 2007;Carpuat and Wu, 2007; Max et al, 2008)); alter-natively, several scores based on single featurescan be estimated using relative frequencies (Gim-pel and Smith, 2008):p(e|f , C(f)) =count(e, f , C(f))?e?
count(e?, f , C(f))For these experiments, we followed the latter ap-proach, restricting ourselves to features represent-ing the local context up to a fixed distance d (usingthe values 1 and 2 in our experiments) from thesource phrase f endstart:?
lexical context features:?
left context: p(e|f , f start?1start?d )?
right context: p(e|f , f end+dend+1 )?
shallow syntactic features (denoting tF1 thesequence of POS tags for the source sen-tence):?
left context: p(e|f , tstart?1start?d)?
right context: p(e|f , tend+dend+1)As in (Gimpel and Smith, 2008), we filtered outall translations for which p(e|f) < 0.0002.
Thiswas necessary to make score computation practi-cal given our available hardware resources.Results on the devtest corpus forEnglish?French were similar for the context-aware phrase-based and the baseline phrase-basedsystem; small gains were achieved in the reversedirection (see Table 2).
The same trend wasobserved on the test data.Manual inspection of the output of the base-line and context-aware systems on the devtestcorpus for English?French translation confirmedtwo facts: (1) performing phrase translation dis-ambiguation is only useful if a more appropriatetranslation has been seen during training ; and (2)phrase translation disambiguation can capture im-portant source dependencies that the target lan-guage model can not recover.
The following ex-102ample, involving an unseen sense4 (ball in the se-mantic field of dance rather than sports), illus-trates our first remark:Source: about 500 people attended the ball .Baseline : Environ 500 personnes ont assist?
?
laballe.+Context: Environ 500 personnes ont particip?
?la balle.The next example is a case where contextual in-formation helped selecting an appropriate transla-tion, in constrast to the baseline system.Source: .
.
.
the new method for calculating pen-sions due to begin next year .
.
.Baseline : .
.
.
le nouveau mode de calcul des pen-sions due ?
commencer l?ann?e prochaine .
.
.+Context: .
.
.
la nouvelle m?thode de calcul despensions qui va d?buter l?ann?e prochaine .
.
.3.2 Preliminary experiments with theGigaWord parallel corpusOne exciting novelty of this year?s campaign wasthe availability of a very large parallel corpus forthe en:fr pair, containing about 20M aligned sen-tences.Our preliminary work consisted in selecting themost useful pairs of sentences, based on their av-erage perplexity, as computed on our develop-ment language models.
The top ranking sen-tences (about 8M sentences) were then fed into theusual system development procedure: alignment,reordering (for the N-code system), phrase pairextraction, model estimation.
Given the unusualsize of this corpus, each of these steps provedextremely resource intensive, and, for some sys-tems, actually failed to complete.
Contrarily, theN-code systems, conceptually simpler, proved toscale nicely.Given the very late availability of this cor-pus, our experiments were very limited and weeventually failed to deliver the test submissionsof our ?GigaWord?
system.
Preliminary exper-iments using the N-code systems (see Table 2),however, showed a clear improvement of perfor-mance.
There is no reason to doubt that similargains would be observed with the Moses systems.3.3 ExperimentsThe various systems presented above were all de-veloped according to the same procedure: train-ing used all the available parallel text; tuning was4This was confirmed after careful inspection of the phrasetables of the baseline system.en ?
fr fr ?
enMoses Ncode Moses Ncodesmall LM 20.06 18.98 21.14 20.41Large LM 22.93 21.95 22.20 22.28+context 23.06 22.69+giga 23.21 23.14Table 2: Results on the devtest setperformed on dev2009a (1000 sentences), and ourinternal tests were performed on dev2009b (1000sentences).
Results are reported in table 2.Our primary submission corresponds tothe +context entry, our first contrast toMoses+LargeLM, and our second contrast toNcode+largeLM.
Due to lack of time, no officialsubmission was submitted for the +giga variant.For the record, the score we eventually obtainedon the test corpus was 26.81, slightly better thanour primary submission which obtained a score of25.74 (all these numbers were computed on thecomplete test set).4 ConclusionIn this paper, we presented our statistical MT sys-tems developed for the WMT?09 shared task.
Weused last year experiments to build competitivesystems, which greatly benefited from in-housenormalisation and language modeling tools.One motivation for taking part in this campaignwas to use the GigaWord corpus.
Even if time didnot allow us to submit a system based on this data,it was a interesting opportunity to confront our-selves with the technical challenge of scaling upour system development tools to very large paral-lel corpora.
Our preliminary results indicate thatthis new resource can actually help improve oursystems.Naturally, future work includes adapting oursystems so that they can use models learnt fromcorpora of the size of the GigaWord corpus.
Inparallel, we intend to keep on working on context-aware systems to study the impact of more typesof scores, e.g.
based on grammatical dependenciesas in (Max et al, 2008).
Given the difficulties wehad tuning our systems, we feel that a preliminarytask should be improving our tuning tools beforeaddressing these developments.103AcknowledgmentsThis work was partly realised as part of the QuaeroProgram, funded by OSEO, the French agency forinnovation.ReferencesM.
Carpuat and D. Wu.
2007.
Context-DependentPhrasal Translation Lexicons for Statistical MachineTranslation.
In Proceedings of Machine TranslationSummit XI, pages 73?80, Copenhagen, Denmark.F.
Casacuberta and E. Vidal.
2004.
Machine transla-tion with inferred stochastic finite-state transducers.Computational Linguistics, 30(3):205?225.S.
F. Chen and J. T. Goodman.
1996.
An empiricalstudy of smoothing techniques for language mod-eling.
In Proceedings of the 34th Annual Meetingof the Association for Computational Linguistics,pages 310?318, Santa Cruz, NM.J.
M. Crego and J.
B. Mari?o.
2007.
ImprovingSMT by coupling reordering and decoding.
Ma-chine Translation, 20(3):199?215.D.
D?chelotte, G. Adda, A. Allauzen, O. Galibert, J.-L.Gauvain, H. Meynard, and F. Yvon.
2008.
Limsi?sstatistical translation systems for WMT?08.
In Pro-ceedings of the NAACL-HTL Statistical MachineTranslation Workshop, pages 107-100, Columbus,Ohio.K.
Gimpel and N. A. Smith.
2008.
Rich Source-SideContext for Statistical Machine Translation.
In Pro-ceedings of the Third Workshop on Statistical Ma-chine Translation, pages 9?17, Columbus, Ohio.P.
Koehn, H. Hoang, A. Birch, C. Callison-Burch,M.
Federico, N. Bertoldi, B. Cowan, W. Shen,C.
Moran, R. Zens, C. Dyer, O. Bojar, A. Constantin,and E. Herbst.
2007.
Moses: Open source toolkitfor statistical machine translation.
In ACL, demon-stration session, Prague, Czech Republic.A.
Max, R. Makhloufi, and P. Langlais.
2008.
Explo-rations in using grammatical dependencies for con-textual phrase translation disambiguation.
In Pro-ceedings of EAMT, poster session, Hamburg, Ger-many.J.
B. Mari?o, R. E. Banchs R, J.M.
Crego, A. de Gis-pert, P. Lambert, J.A.R.
Fonollosa, and M. R. Costa-Juss?.
2006.
N-gram-based machine translation.Computational Linguistics, 32(4):527?549.F.
J. Och.
2003.
Minimum error rate training in statis-tical machine translation.
In Proceedings of the 41stAnnual Meeting of the Association for Computa-tional Linguistics, pages 160?167, Sapporo, Japan.N.
Stroppa, A. van den Bosch, and A.
Way.
2007.Exploiting source similarity for SMT using context-informed features.
In Proceedings of the 11th In-ternational Conference on Theoretical and Method-ological Issues in Machine Translation (TMI?07),pages 231?240, Sk?vde, Sweden.104
