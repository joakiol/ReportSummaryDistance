Proceedings of the SIGDIAL 2013 Conference, pages 92?96,Metz, France, 22-24 August 2013. c?2013 Association for Computational LinguisticsOn the contribution of discourse structure to topic segmentationPaula C. F. Cardoso1, Maite Taboada2, Thiago A. S. Pardo11N?cleo Interinstitucional de Lingu?stica Computacional (NILC)Instituto de Ci?ncias Matem?ticas e de Computa?
?o, Universidade de S?o PauloAv.
Trabalhador S?o-carlense, 400 - CentroCaixa Postal: 668 ?
CEP: 13566-970 ?
S?o Carlos/SP2Department of Linguistics ?
Simon Fraser University8888 University Dr., Burnaby, B.C., V5A 1S6 - Canadapcardoso@icmc.usp.br, mtaboada@sfu.ca, taspardo@icmc.usp.brAbstractIn this paper, we describe novel methods fortopic segmentation based on patterns of dis-course organization.
Using a corpus of newstexts, our results show that it is possible to usediscourse features (based on Rhetorical Struc-ture Theory) for topic segmentation and thatwe outperform some well-known methods.1 IntroductionTopic segmentation aims at finding the bounda-ries among topic blocks in a text (Chang andLee, 2003).
This task is useful for a number ofimportant applications such as information re-trieval (Prince and Labadi?, 2007), automaticsummarization (Wan, 2008) and question-answering systems (Oh et al 2007).In this paper, following Hearst (1997), we as-sume that a text or a set of texts develop a maintopic, exposing several subtopics as well.
Wealso assume that a topic is a particular subjectthat we write about or discuss (Hovy, 2009), andsubtopics are represented in pieces of text thatcover different aspects of the main topic (Hearst,1997; Hennig, 2009).
Therefore, the task of topicsegmentation aims at dividing a text into topical-ly coherent segments, or subtopics.
The granular-ity of a subtopic is not defined, as a subtopic maycontain one or more sentences or paragraphs.Several methods have been tested for topicsegmentation.
There are, however, no studies onhow discourse structure directly mirrors topicboundaries in texts and how they may contributeto such task, although such possible correlationhas been suggested (e.g., Hovy and Lin, 1998).In this paper, we follow this research line,aiming at exploring the relationship of discourseand subtopics.
In particular, our interest is main-ly on the potential of Rhetorical Structure Theory(RST) (Mann and Thompson, 1987) for this task.We propose and evaluate automatic topic seg-mentation strategies based on the rhetoricalstructure of a text.
We also compare our resultsto some well-known algorithms in the area,showing that we outperform these algorithms.Our experiments were performed using a corpusof news texts manually annotated with RST andsubtopics.The remainder of this paper is organized asfollows.
Section 2 gives a brief background ontext segmentation.
Section 3 describes our auto-matic strategies to find the subtopics.
The corpusthat we use is described in Section 4.
Section 5presents some results and Section 6 contains theconclusions and future work.2 Related workSeveral approaches have tried to measure thesimilarity across sentences and to estimate wheretopic boundaries occur.
One well-known ap-proach, that is heavily used for topic segmenta-tion, is TextTiling (Hearst, 1997), which is basedon lexical cohesion.
For this strategy, it is as-sumed that a set of lexical items is used duringthe development of a subtopic in a text and,when that subtopic changes, a significant propor-tion of vocabulary also changes.Passoneau and Litman (1997), in turn, havecombined multiple linguistic features for topicsegmentation of spoken text, such as pause, cuewords, and referential noun phrases.
Hovy andLin (1998) have used various complementary92techniques for topic segmentation, includingthose based on text structure, cue words andhigh-frequency indicative phrases for topic iden-tification in a summarization system.
Althoughthe authors do not mention an evaluation of thesefeatures, they suggested that discourse structuremight help topic identification.
For this, theysuggested using RST.RST represents relations among propositionsin a text and discriminates nuclear and satelliteinformation.
In order to present the differencesamong relations, they are organized in twogroups: subject matter and presentational rela-tions.
In the former, the text producer intendsthat the reader recognizes the relation itself andthe information conveyed, while in the latter theintended effect is to increase some inclination onthe part of the reader (Taboada and Mann, 2006).The relationships are traditionally structured in atree-like form (where larger units ?
composed ofmore than one proposition ?
are also related inthe higher levels of the tree).To the best of our knowledge, we have notfound any proposal that has directly employedRST for topic segmentation purposes.
Followingthe suggestion of the above authors, we investi-gated how discourse structure mirrors topic shiftsin texts.
Next section describes our approach tothe problem.3 Strategies for topic segmentationFor identifying and partitioning the subtopics ofa text, we developed four baseline algorithmsand six other algorithms that are based on dis-course features.The four baseline algorithms segment at para-graphs, sentences, random boundaries (randomlyselecting any number of boundaries and wherethey are in a text) or are based on word reitera-tion.
The word reiteration strategy is an adapta-tion of TextTiling1 (Hearst, 1997) for the charac-teristics of the corpus that we used (introducedlatter in this paper).The algorithms based on discourse considerthe discourse structure itself and the RST rela-tions in the discourse tree.
The first algorithm(which we refer to as Simple Cosine) is based onMarcu?s idea (2000) for measuring the ?good-ness?
of a discourse tree.
He assumes that a dis-course tree is ?better?
if it exhibits a high-levelstructure that matches as much as possible the1  We have specifically used the block comparisonmethod with block size=2.topic boundaries of the text for which that struc-ture was built.
Marcu associates a clusteringscore to each node of a tree.
For the leaves, thisscore is 0; for the internal nodes, the score is giv-en by the lexical similarity between the immedi-ate children.
The hypothesis underlying suchmeasurements is that better trees show highersimilarity among their nodes.
We have adoptedthe same idea using the cosine measure.
We haveproposed that text segments with similar vocabu-lary are likely to be part of the same topic seg-ment.
In our case, nodes with scores below theaverage score are supposed to indicate possibletopic boundaries.The second algorithm (referred to as CosineNuclei) is also a proposal by Marcu (2000).
It isassumed that whenever a discourse relation holdsbetween two textual spans, that relation alsoholds between the most salient units (nuclei) as-sociated with those spans.
We have used thisformalization and measured the similarity be-tween the salient units associated with two spans(instead of measuring among all the text spans ofthe relation, as in the previous algorithm).The third (Cosine Depth) and fourth (NucleiDepth) algorithms are variations of Simple Co-sine and Cosine Nuclei.
For these new strategies,the similarity for each node is divided by thedepth where it occurs, traversing the tree in abottom-up way.
These should guarantee thathigher nodes are weaker and might better repre-sent topic boundaries.
Therefore, we have theassumption that topic boundaries are more likelyto be mirrored at the higher levels of the dis-course structure.
We also have used the averagescore to find out less similar nodes.
Figure 1shows a sample RST tree.
The symbols N and Sindicate the nucleus and satellite of each rhetori-cal relation.
For this tree, the score betweennodes 3 and 4 is divided by 1 (since we are at theleaf level); the score between Elaboration andnode 5 is divided by 2 (since we are in a higherlevel, 1 above the leaves on the left); and thescore between Sequence and Volitional-result isdivided by 3 (1 above the leaves on the right).Figure 1.
Example of an RST structure93The next algorithms are based on the idea thatsome relations are more likely to represent topicshifts.
For estimating this, we have used theCSTNews (described in next section), which ismanually annotated with subtopics and RST.In this corpus, there are 29 different types ofRST relations that may connect textual spans.
Inan attempt to characterize topic segmentationbased on rhetorical relations, we recorded thefrequency of those relations in topic boundaries.We realized that some relations were more fre-quent on topic boundaries, whereas others neveroccurred at the boundaries of topics.
Out of the29 relations, 16 appeared in the reference annota-tion.
In topic boundaries, Elaboration was themost frequent relation (appearing in 60% of theboundaries), followed by List (20%) and Non-Volitional Result (5%).
Sequence and Evidenceappeared in 2% of the topic boundaries, andBackground, Circumstance, Comparison, Con-cession, Contrast, Explanation, Interpretation,Justify, and Non-Volitional Cause in 1% of theboundaries.We used this knowledge about the relations?frequency and attributed a weight associated withthe possibility that a relation indicates a bounda-ry, in accordance with its frequency on topicboundaries in the reference corpus.
Figure 2shows how the 29 relations were distributed.
Onerelation is weak if it usually indicates a bounda-ry; in this case, its weight is 0.4.
One relation ismedium because it may indicate a boundary ornot; therefore, its weight is 0.6.
On the otherhand, a strong relation almost never indicates atopic boundary; therefore, its weight is 0.8.
Suchvalues were empirically determined.
Anotherfactor that may be observed is that all presenta-tional relations are classified as strong, with theexception of Antithesis.
This is related to the def-inition of presentational relations, and Antithesiswas found in the reference segmentation with alow frequency.Class RelationsWeak(0.4)Elaboration, Contrast, Joint, ListMedium(0.6)Antithesis, Comparison, EvaluationMeans, Non-Volitional Cause, Non-Volitional Result, Solutionhood, Voli-tional Cause, Volitional Result, SequenceStrong(0.8)Background, Circumstance, Concession,Conclusion, Condition, Enablement, Evi-dence, Explanation, Interpretation, Justi-fy, Motivation, Otherwise, Purpose, Re-statement, SummaryFigure 2.
Classification of RST relationsFrom this classification we created two morestrategies: Relation_Depth and Nu-clei_Depth_Relation.
Relation_Depth associatesa score to the nodes by dividing the relationsweight by the depth where it occurs, in a bottom-up way of traversing the tree.
We also have usedthe average score to find out nodes that are lesssimilar.
As we have observed that some im-provement might be achieved every time nucleiinformation was used, we have tried to combinethis configuration with the relations?
weight.Hence, we computed the scores of the NucleiDepth strategy times the proposed relationsweight.
This was the algorithm that we calledNuclei_Depth_Relation.
Therefore, these twolast algorithms enrich the original Cosine Depthand Nuclei Depth strategies with the relationstrength information.The next section presents the data set we haveused for our evaluation.4 Overview of the corpusWe used the CSTNews corpus2 that is composedof 50 clusters of news articles written in Brazili-an Portuguese, collected from several sections ofmainstream news agencies: Politics, Sports,World, Daily News, Money, and Science.
Thecorpus contains 140 texts altogether, amountingto 2,088 sentences and 47,240 words.
On aver-age, the corpus conveys in each cluster 2.8 texts,41.76 sentences and 944.8 words.
All the texts inthe corpus were manually annotated with RSTstructures and topic boundaries in a systematicway, with satisfactory annotation agreement val-ues (more details may be found in Cardoso et al2011; Cardoso et al 2012).
Specifically for topicboundaries, groups of trained annotators indicat-ed possible boundaries and the ones indicated bythe majority of the annotators were assumed tobe actual boundaries.5 EvaluationThis section presents comparisons of the resultsof the algorithms over the reference corpus.The performance of topic segmentation is usu-ally measured using Recall (R), Precision (P),and F-measure (F) scores.
These scores quantifyhow closely the system subtopics correspond tothe ones produced by humans.
Those measurescompare the boundary correspondences withoutconsidering whether these are close to each oth-er: if they are not the same (regardless of wheth-2 www2.icmc.usp.br/~taspardo/sucinto/cstnews.html94er they are closer or farther from one another),they score zero.
However, it is also important toknow how close the identified boundaries are tothe expected ones, since this may help to deter-mine how serious the errors made by the algo-rithms are.
We propose a simple measure to this,which we call Deviation (D) from the referenceannotations.
Considering two algorithms thatpropose the same amount of boundaries for a textand make one single mistake each (having, there-fore, the same P, R, and F scores), the best onewill be the one that deviates the least from thereference.
The best algorithm should be the onewith the best balance among P, R, F, and Dscores.The results achieved for the investigatedmethods are reported in Table 1.
The first 4 rowsshow the results for the baselines.
The algorithmsbased on RST are in the last 6 rows.
The last rowrepresents the human performance, which werefer by topline.
It is interesting to have a toplinebecause it possibly indicates the limits that au-tomatic methods may achieve in the task.
To findthe topline, a human annotator of the corpus wasrandomly selected for each text and his annota-tion was compared with the reference one.As expected, the paragraph baseline was verygood, having the best F values of the baselineset.
This shows that, in most of the texts, the sub-topics are organized in paragraphs.
Although thesentence baseline has the best R, it has the worstD.
This is due to the fact that not every sentenceis a subtopic, and to segment all of them be-comes a problem when we are looking for majorgroups of subtopics.
TextTiling is the algorithmthat deviates the least from the reference seg-mentation.
This happens because it is very con-servative and detects only a few segments, some-times only one (the end of the text), causing it tohave a good deviation score, but penalizing R.Algorithm R P F DTextTiling 0.405 0.773 0.497 0.042Paragraph 0.989 0.471 0.613 0.453Sentence 1.000 0.270 0.415 1.000Randomly 0.674 0.340 0.416 0.539Simple Cosine 0.549 0.271 0.345 0.545Cosine Nuclei 0.631 0.290 0.379 0.556Cosine Depth 0.873 0.364 0.489 0.577Nuclei Depth 0.899 0.370 0.495 0.586Relation_Depth 0.901 0.507 0.616 0.335Nuclei_DepthRelation0.908 0.353 0.484 0.626Topline 0.807 0.799 0.767 0.304Table 1.
Evaluation of algorithmsIn the case of the algorithms based on RST, wemay notice that they produced the best results interms of R, P, and F, with acceptable D values.We note too that every time the salient unitswere used, R and P increase, except for Nu-clei_Depth_Relation.
Examining the measures,we notice that the best algorithm was Rela-tion_Depth.
Although its F is close to the one ofthe Paragraph baseline, the Relation_Depth algo-rithm shows a much better D value.
One may seethat the traditional TextTiling was also outper-formed by Relation_Depth.As expected, the Topline (the human, there-fore) has the best F with acceptable D. Its F val-ue is probably the best that an automatic methodmay expect to achieve.
It is 25% better than ourbest method (Relation_Depth).
There is, there-fore, room for improvements, possibly using oth-er discourse features.We have run t-tests for pairs of algorithms forwhich we wanted to check the statistical differ-ence.
As expected, the F difference is not signifi-cant for Relation_Depth and the Paragraph algo-rithms, but it was significant with 95% confi-dence for the comparison of Relation_Depth withNuclei_Depth and TextTiling (also regarding theF values).
Finally, the difference between Rela-tion_Depth and the Topline was also significant.6 Conclusions and future workIn this paper we show that discourse structuresmirror, in some level, the topic boundaries in thetext.
Our results demonstrate that discourseknowledge may significantly help to find bound-aries in a text.
In particular, the relation type andthe level of the discourse structure in which therelation happens are important features.
To thebest of our knowledge, this is the first attempt tocorrelate RST structures with topic boundaries,which we believe is an important theoretical ad-vance.At this stage, we opted for a manually anno-tated corpus, because we believe an automaticRST analysis would surely decrease the corre-spondence that was found.
However, better dis-course parsers have arisen and this may not be aproblem anymore in the future.AcknowledgmentsThe authors are grateful to FAPESP, CAPES,CNPq and Natural Sciences and Engineering Re-search Council of Canada (Discovery Grant261104-2008) for supporting this work.95ReferencesPaula C.F.
Cardoso, Erick G. Maziero, Maria L.R.Castro Jorge, Eloize M.R.
Seno, Ariani Di Fellipo,L?cia H.M. Rino, Maria G.V.
Nunes, Thiago A.S.Pardo.
2011.
CSTNews ?
A discourse-annotatedcorpus for single and multidocument summariza-tion of texts in Brazilian Portuguese.
In: Proceed-ings of the 3rd RST Brazilian Meeting, pp.
88-105.Paula C.F.
Cardoso, Maite Taboada, Thiago A.S. Par-do.
2013.
Subtopics annotation in a corpus of newstexts: steps towards automatic subtopic segmenta-tion.
In: Proceedings of the Brazilian Symposiumin Information and Human Language Technology.T-H Chang and C-H Lee.
2003.
Topic segmentationfor short texts.
In: Proceedings of the 17th PacificAsia Conference Language, pp.
159-165.Marti Hearst.
1997.
TextTiling: Segmenting Text intoMulti-Paragraph Subtopic Passages.
Computation-al Linguistics 23(1), pp.
33-64.Leonhard Hennig.
2009.
Topic-based multi-documentsummarization with probabilistic latent semanticanalysis.
In: Recent Advances in Natural LanguageProcessing, pp.
144-149.Eduard Hovy and C-Y Lin.
1998.
Automated TextSummarization and the SUMMARIST system.
In:Proceedings of TIPSTER, pp.
197-214.Eduard Hovy.
2009.
Text Summarization.
In: RuslanMitkov.
The Oxford Handbook of ComputationalLinguistics, pp.
583-598.
United States: OxfordUniversity.Anna Kazantseva and Stan Szpakowicz.
2012.
Topi-cal Segmentation: a study of human performanceand a new measure of quality.
In:  Proceedings ofthe 2012 Conference of the North American Chap-ter of the Association for Computational Linguis-tics: Human Language Technologies, pp.
211-220.Willian C. Mann and Sandra A. Thompson.
1987.Rhetorical Structure Theory: A Theory of Text Or-ganization.
Technical Report ISI/RS-87-190.Daniel Marcu.
2000.
The Theory and Practice of Dis-course Parsing and Summarization.
The MITPress.
Cambridge, Massachusetts.Hyo-Jung Oh, Sung Hyon Myaeng and Myung-GilJang.
2007.
Semantic passage on sentence topicsfor question answering.
Information Sciences177(18), pp.
3696-3717.Rebecca J. Passonneau and Diane J. Litman.
1997.Discourse segmentation by human and automatedmeans.
Computational Linguistics 23(1), pp.
103-109.Violaine Prince and Alexandre Labadi?.
2007.
Textsegmentation based on document understanding forinformation retrieval.
In: Proceedings of the 12thInternational Conference on Applications of Natu-ral Language to Information Systems, pp.
295-304.Maite Taboada and William C. Mann.
2006.
Rhetori-cal Structure Theory: Looking back and movingahead.
Discourse Studies 8(3), pp.423-459.Xiaojun Wan.
2008.
An exploration of document im-pact on graph-based multi-document summariza-tion.
In: Proceedings of the Conference on Empiri-cal Methods in Natural Language Processing, pp.755-762.96
