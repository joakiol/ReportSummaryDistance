Proceedings of the SIGDIAL 2014 Conference, pages 300?309,Philadelphia, U.S.A., 18-20 June 2014.c?2014 Association for Computational LinguisticsComparative Error Analysis of Dialog State TrackingRonnie W. SmithDepartment of Computer ScienceEast Carolina UniversityGreenville, North Carolina, 27834rws@cs.ecu.eduAbstractA primary motivation of the Dialog StateTracking Challenge (DSTC) is to allowfor direct comparisons between alterna-tive approaches to dialog state tracking.While results from DSTC 1 mention per-formance limitations, an examination ofthe errors made by dialog state trackerswas not discussed in depth.
For the newchallenge, DSTC 2, this paper describesseveral techniques for examining the er-rors made by the dialog state trackers in or-der to refine our understanding of the lim-itations of various approaches to the track-ing process.
The results indicate that noone approach is universally superior, andthat different approaches yield different er-ror type distributions.
Furthermore, theresults show that a pairwise comparativeanalysis of tracker performance is a usefultool for identifying dialogs where differ-ential behavior is observed.
These dialogscan provide a data source for a more care-ful analysis of the source of errors.1 IntroductionThe Dialog State Tracking Challenge (Hendersonet al., 2013) provides a framework for compari-son of different approaches to tracking dialog statewithin the context of an information-seeking dia-log, specifically information about restaurants inthe Cambridge, UK, area.
The challenge makesavailable an annotated corpus that includes systemlogs from actual human-machine dialog interac-tions.
These logs include information about thesystem dialog acts, the N-best speech recognitionhypotheses, and the hypothesized interpretation(including confidence estimates) of the user?s spo-ken utterances as provided by the dialog system?sSpoken Language Understanding (SLU) module.Consequently, standalone algorithms for track-ing the state of the dialog can be developed andtested.
While performance as part of an actualdialog interaction cannot easily be evaluated (be-cause differing results produced by different track-ers may lead to different choices for system dialogacts in a real-time interaction), performance on aturn-by-turn basis can be evaluated and compared.Results from the first challenge were presentedin several papers at SIGDial 2013 (general refer-ence Williams et al.
(2013)) and highlighted sev-eral different approaches.
These papers focusedon comparative performance as well as a descrip-tion of the various techniques for tracking dialogstate that were employed.
However, there was nodetailed error analysis about tracker performance,either within or across trackers.
Such analysis canhelp further our understanding of the sources andimpact of dialog miscommunication.
This paperpresents such an analysis from the current Dia-log State Tracking Challenge (DSTC 2) using thepublicly available results of the challenge (http://camdial.org/?mh521/dstc/).
This pa-per describes techniques for examining the follow-ing aspects of performance as it relates to trackingerrors and their potential impact on effective com-munication in dialog.?
Estimating an upper bound on accuracy.?
Error distribution as a function of tracker?both globally and subdivided by acousticmodel or attribute type.?
Pairwise comparative accuracy of trackers?for what types of dialogs does one trackerperform better than another?Initial results based on application of these tech-niques are also presented.3002 Data Source: DSTC 2DSTC 2 is based on corpora collected on dialogsabout restaurant information for Cambridge, UK.Besides introducing a different domain from theoriginal DSTC (that dealt with bus timetables)DSTC 2 is structured in such a way as to allowfor the possibility of changing user goals and thusrepresents a more significant challenge for dialogstate tracking.
An overview of the current chal-lenge and results can be found in Henderson et al.
(2014).2.1 Nature of DialogsUnlike the dialogs of the original DSTC that werebased on actual uses of the bus timetable informa-tion system, the dialogs for DSTC 2 were collectedin the more traditional experimental paradigmwhere system users were given a dialog scenarioto follow.
Example scenario descriptions extractedfrom two of the log files are given below.?
Task 09825: You want tofind a cheap restaurant andit should be in the south partof town.
Make sure you getthe address and phone number.?
Task 05454: You want to findan expensive restaurant and itshould serve malaysian food.If there is no such venue howabout korean type of food.Make sure you get the addressand area of the venue.The basic structure of the dialogs has the fol-lowing pattern.1.
Acquire from the user a set of constraintsabout the type of restaurant desired.
Usersmay supply constraint information aboutarea, food, name, and price range.
This phasemay require multiple iterations as user goalschange.2.
Once the constraints have been acquired, pro-vide information about one or more restau-rants that satisfy the constraints.
Usersmay request that additional attributes abouta restaurant be provided (such as address andphone number).2.2 Measuring Task PerformanceBecause of the complex nature of statistical dia-log state tracking there are many different reason-able ways to measure tracker performance.
Be-sides evaluating the accuracy of the 1-best hypoth-esis there are also a number of possible measuresbased on the quality of the estimate for dialog state(see Henderson et al.
(2013) for details).For the purpose of this paper the analysis will bebased on tracker performance on accuracy (1-bestquality) for the joint goal based on the four previ-ously mentioned constraint attributes (area, food,name, and price range).
The reason for this choiceis that in an actual human-system dialog in aninformation-seeking domain, the dialog managermust choose an action based on the system?s be-liefs about the constraining attributes.
While levelof belief might positively influence when to en-gage in explicit or implicit confirmation, ultimatesuccess depends on correct identification of valuesfor the constraining attributes.
Having too muchconfidence in inaccurate information has alwaysbeen a major error source in dialog systems.
Con-sequently, 1-best joint goal accuracy is the focusof study in this paper.2.3 Description of Error TypesSince we are focused on joint goal accuracy, er-ror type classification will be based on the follow-ing three types of possible deviations from the truejoint goal label for a given turn.1.
Missing Attributes (MA) - these are situa-tions where a value for an attribute has beenspecified in the actual data (e.g.
?belgian?for the attribute ?food?
), but the dialog statetracker has no value for the attribute in thejoint belief state.12.
Extraneous Attributes (EA) - these are situ-ations where the tracker has a value for theattribute in the joint belief state, but the at-tribute has not been mentioned in the actualdialog.1The format of DSTC 2 allows for automatic compilationof the joint belief state by the scoring software.
The probabil-ity mass for a given attribute that is not assigned to specificvalues for attributes is assigned to a special value None.
If novalue for the attribute has a probability estimate exceedingNone, then no value for that attribute is included in the jointbelief state.
It is also possible for a dialog state tracker to ex-plicitly provide a joint belief state.
In DSTC 2 some systemsdo explicitly provide a joint belief state while others use thedefault.3013.
False Attributes (FA) - these are situationswhere a value for an attribute has been spec-ified in the actual data (e.g.
?catalan?
for theattribute ?food?
), but the dialog state trackerhas a different value (such as ?fusion?
for?food?
).For turns where there are errors, it is certainlypossible that multiple errors occur, both multipleerrors of a given type, and multiple errors of dif-ferent types.
This is taken into consideration asdescribed next.2.4 Recording Tracker PerformanceFor each tracker a data file consists of a sequenceof tuples of the form (Correct,EA,MA,FA) thatwere generated for each turn for which there was avalid joint goal label.2.
The meaning of each valuein the tuple is given below.?
Correct - has the value 1 if the tracker jointgoal label is correct and 0 if it was incorrect.?
EA - a count of the number of different ex-traneous attributes that occurred in the turn.Will always be 0 if Correct = 1.?
MA - a count of the number of differentmissing attributes that occurred in the turn.Will always be 0 if Correct = 1.?
FA - a count of the number of different falseattributes that occurred in the turn.
Will al-ways be 0 if Correct = 1.Consequently, whenever Correct is 1, the tuplewill always be of the form (1,0,0,0).
If Correct is0, at least one of the three following entries in thetuple will have a non-zero value.These files were generated by modifying thescoring script provided by the DSTC organizingcommittee.
The modification causes the neces-sary information to be output for each relevantturn.
These data files represent the result of trackerperformance on 1117 dialogs over a total of 9689turns.2In some cases at the start of dialogs, no SLU hypothe-ses have yet to mention any values for any of the joint goalattributes.
As mentioned in Henderson et al.
(2013), thoseturns are not included in the joint-goal accuracy evaluation.This occurred in a total of 201 turns over 193 dialogs.2.5 Mapping Labels to DialogsAnother modified version of the scoring script wasused to iterate through the dialogs to produce atemplate that associates each of the 9689 labeledturns with the specific (dialog ID, turn within dia-log) pair that the turn represents.
This informationwas used in the error analysis process to identifyspecific dialogs for which tracking was not partic-ularly accurate (see section 4).2.6 Choice of TrackersThere were a total of 9 different teams that sub-mitted a total of 31 trackers for DSTC 2.
For thisstudy, one tracker from each team is being used.The choice of tracker is the one that performedthe best on 1-best joint goal accuracy, one of theoverall ?featured metrics?
of the challenge (Hen-derson et al., 2013).
Their performance on thismetric ranged from 50.0% to 78.4%.
Seven of thenine trackers had performance of better than 69%,while there were two performance outliers at 50%and 60%.For purposes of this study, it seemed best toinclude a tracker from all groups since part ofthe intent of the challenge is to carefully exam-ine the impact of different approaches to dialogstate tracking.
Based on the optional descrip-tions that teams submitted to the challenge, therewere quite a variety of approaches taken (thoughnot all teams provided a description).
Some sys-tems used the original SLU results.
Other sys-tems ignored the original SLU results and fo-cused on the ASR hypotheses.
Some systems cre-ated their own modified versions of the originalSLU results.
Modeling approaches included Max-imum Entropy Markov model, Deep Neural Net-work model, rule-based models, Hidden Informa-tion State models, and conditional random fields.Hybrid approaches were used as well.
A few moredetails about our submitted tracker will be pro-vided in section 4.One of the purposes of this study was to lookat the distribution of errors based on the differenttypes discussed in section 2.3, both in absolute andrelative terms.
Consequently, one intended inves-tigation is to see if there is a difference in errortype distribution depending on a number of param-eters, including the approach used to dialog statetracking.
Thus, examining the results from the toptrackers of all teams can provide valuable infor-mation regardless of the absolute accuracy of the302tracker.
As it turned out, each tracker studied hadmultiple turns where it was the only tracker to pro-vide a correct joint goal label.
This happened onabout 4% of all the turns.
The number of turns forwhich a tracker was the only tracker to provide acorrect joint goal label ranged from 5 to 89 andtended to follow the general ranking of accuracy(i.e., more accurate trackers tended to have moreturns where it was the only tracker correct).
How-ever, it did not follow the relative rankings pre-cisely.3 Analysis: Global Tracker Performance3.1 How much misunderstanding can beexpected?Another way to ask this question would be, ?whaterror rate should be expected from a high perfor-mance tracker?
For example, there were 21 di-alogs consisting of 8 user turns or more wherenone of the trackers under study correctly repre-sented the joint goal for any turn.Looking more broadly, there were 1332 turnsover the entire set of dialogs for which none ofthe trackers had a correct representation of thejoint goal.
Thus, if we could construct an ?oracle?tracker that could always select the correct repre-sentation of the joint goal from among the ninetrackers under study (when at least one of themhad the correct representation), this would implyan error rate of 13.7%.3This contrasts with an er-ror rate of 21.6% for the best performing trackersubmitted as part of DSTC 2.
If we look at trackerperformance as a function of acoustic model (ar-tificially degraded (A0), and optimized (A1)), theerror rate estimate for the oracle tracker is 17.0%using model A0 and 10.3% using model A1.3.2 Global Error Type DistributionUsing the classification of error types describedin section 2.3: Extraneous Attributes (EA), Miss-ing Attributes (MA), and False Attributes (FA),we can explore the distribution of error types asa function of the dialog tracker.
Table 1 provides asummary view of the distributions over all the di-alogs of the test set.
For comparison, the baselinefocus tracker provided by the DSTC 2 organizers3Note that this is not any sort of an absolute estimate.For example, if provided baseline trackers are included (oneprovided by the DSTC 2 organizers and another by ZhuoranWang of Heriot-Watt University), the number of turns whereno tracker correctly represents the joint goal reduces to 1325turns.
(see Henderson et al.
(2013)) and the HWU base-line tracker provided by Zhuoran Wang of Heriot-Watt University (see http://camdial.org/?mh521/dstc/) are also included.
While track-ers 1 and 9 are also presented for completeness,the main focus of the analysis is on trackers 2through 8, the trackers with higher levels of per-formance on the featured metric of 1-best jointgoal accuracy.
Each row represents the relativedistribution of errors by a given tracker.
For ex-ample, for our tracker, tracker 3, there were 2629turns (out of the total 9689 turns) where the trackermade one or more errors for the attributes of thejoint goal.
There were a total of 3075 differentattribute errors of which 545 or 17.7% of the er-rors were of type EA, 1341 or 43.6% were of typeMA, and 1189 or 38.7% of type FA.
A visual rep-resentation of this information is provided in theAppendix in figure 1.
Some general observationsare the following.?
Other than tracker 5, the relative number oferrors of type MA exceeded the relative num-ber of errors of type FA.
For attributes actu-ally mentioned by the user, trackers in gen-eral were more likely to reject a correct hy-pothesis (leading to a type MA error) thanaccept an incorrect hypothesis (leading to atype FA error).?
Based on the brief description provided withsubmission of the tracker, tracker 5 uses a hy-brid approach for tracking the different goals(one of the baseline trackers for the food at-tribute, but an n-best approach to the oth-ers).
This approach seemed to lead to theacceptance of more spurious hypotheses thanthe other trackers (hence the higher EA rate).Tracker 8 also had a slightly higher error ratefor EA.
Its submission description indicatesthe combined use of several models, at leastone of which used the training data for devel-oping model parameters.3.3 Error Type Distribution as a Function ofAcoustic ModelSince publicly available spoken dialog systemscannot control the environment in which they areused, speech recognition rates can vary widely.One of the general goals of the DSTC is to eval-uate tracker performance for varying levels ofspeech recognition accuracy.
Hence the use in303Total Errors EA MA FATracker # Turns # Errors Count Percent Count Percent Count PercentFocus 2720 3214 652 20.3% 1124 35.0% 1438 44.7%HWU 2802 3352 601 17.9% 1526 45.5% 1225 36.6%1 3865 4411 673 15.3% 2436 55.2% 1302 29.6%2 2090 2432 451 18.5% 1177 48.4% 804 33.1%3 2629 3075 545 17.7% 1341 43.6% 1189 38.7%4 2246 2598 441 17.0% 1100 42.3% 1057 40.7%5 2956 3618 947 26.2% 1218 33.7% 1453 40.2%6 2730 3231 552 17.1% 1410 43.6% 1269 39.3%7 2419 2791 446 16.0% 1205 43.2% 1140 40.8%8 2920 3546 763 21.5% 1456 41.0% 1327 37.4%9 4857 6183 781 12.6% 4222 68.3% 1180 19.1%Table 1: Error Distribution: all dialogsDSTC 2 of two acoustic models: model A1 whichis a model optimized for the domain, and modelA0 which has artificially degraded acoustic mod-els (Henderson et al., 2013).
For the test set, therewere 542 dialogs yielding 4994 turns with jointgoal labels for model A0, and 575 dialogs yielding4695 turns with joint goal labels for model A1.
Itis unsurprising that the average number of turns ina dialog was shorter for the dialogs using the moreaccurate speech recognizer.The previous table looked at the global behav-ior combining all the dialogs.
An interesting ques-tion to examine is if the error distributions changeas a function of acoustic model.
Tables 2 and 3give some insight into that question.
Table 2, theresults using the optimized model A1, unsurpris-ingly shows that when the speech signal is bet-ter and by implication the SLU confidence scoresare stronger and more accurate, the relative rateof type FA errors declines while the relative rateof type MA errors increases (when compared tothe overall results of Table 1).
For errors of typeEA it is about an even split?for some the relativenumber of EA errors decreases, and for some it in-creases.
The results in Table 3 for the A0 modelshow the opposite trend for the relative errors oftype MA compared to type FA.3.4 Error Type Distribution as a Function ofAttributeWhile it is future work to do an exact count to de-termine the frequency with which the four differ-ent constraining attributes (area, food, name, andprice range) are actually mentioned in the dialogs,it is clear from the data that the primary objectsof conversation are area, food, and price range.This makes sense, since there are often alterna-tive effective ways to access information about arestaurant other than to interact with a dialog sys-tem given that the name has already been deter-mined by the user.4Consequently, for the remain-ing three attributes, an investigation into the rela-tive distribution of errors as a function of attributetype within error type was conducted.
The resultsare presented in Table 4.
This table is looking atall the test data combined and not separating byacoustic model.
Again the focus of discussion willbe trackers 2 through 8.
For brevity, the results forerror type FA are omitted as they are pretty similarfor all trackers.relative error rate for food >> than rel-ative error rate for area >> than relativeerror rate for price range.This follows naturally from the fact that there are91 possible values for food, 5 possible values forarea, and only 3 possible values for price range.Thus, there are many more possibilities for confu-sion for the value for the food attribute.
When weexamine the results in Table 4, there are a varietyof interesting observations.?
Within error type EA, the only trackers forwhich the relative error rate for price rangeexceeds the relative error rate for area aretrackers 5 and 7.?
Trackers 3 and 4 are more prone to have EAerrors for the food attribute.4One of the anonymous reviewers pointed out that thechoice of scenarios used in the data collection process is alsoa factor.304Tracker EA MA FA1 12.4% 61.7% 25.9%2 20.5% 53.4% 26.1%3 16.1% 50.3% 33.7%4 17.8% 45.7% 36.6%5 25.7% 40.9% 33.4%6 17.5% 49.9% 32.6%7 15.0% 53.6% 31.5%8 23.0% 43.0% 34.0%9 11.6% 71.7% 16.7%Table 2: Error Distribution: A1 dialogsTracker EA MA FA1 17.3% 50.5% 32.1%2 17.5% 45.8% 36.6%3 18.7% 39.8% 41.5%4 16.5% 40.4% 43.0%5 26.4% 29.9% 43.7%6 16.8% 40.0% 43.2%7 16.5% 37.4% 46.0%8 20.6% 39.9% 39.5%9 13.3% 65.8% 20.8%Table 3: Error Distribution: A0 dialogs?
Trackers 2, 6, 7, and 8 all have a noticeablejump in the relative error rate for the food at-tribute for type MA errors over type EA er-rors.
In contrast, trackers 3, 4, and 5 show anoticeable decrease.What of course is missing from these obser-vations is any conjecture of causality based ona careful analysis of individual tracker behav-ior.
Given the lack of accessibility to the detailsof system implementations for all the trackers,other techniques of investigation are needed.
Thenext section explores another potentially valuabletechnique?comparing the results of two trackerson a turn-by-turn basis, and using these resultsto identify particular dialogs that exhibit radicallydifferent outcomes in performance.4 Analysis: Pairwise ComparativeAccuracyAnother avenue of analysis is to directly comparethe performance of two trackers.
How do they dif-fer in terms of the types of dialog situations thatthey handle effectively?
We will examine theseissues through comparison of the top performingtracker in the challenge (with respect to the fea-tured metric 1-best joint goal accuracy) with ourtracker entry, Pirate.54.1 Pirate methodology: what should dialogexpectation mean?The overarching philosophy behind the develop-ment of Pirate is simply the following.There is belief about what we think weknow, but there should also be an expec-tation about what comes next if we arecorrect.One of the first dialog systems to make use ofa hierarchy of dialog expectations was the CircuitFix-It Shop (Smith et al., 1995) which was alsoone of the first working dialog systems to be care-fully and extensively evaluated (Smith and Gor-don, 1997) and (Smith, 1998).
However, at thetime, the ability to make use of large corpora insystem development was largely non-existent.6Our approach in DSTC 2 for making use ofthe extensive training data combined the SLU hy-potheses with confidence scores (interpreted asprobabilities) with a simple statistical model ofdialog expectation to create modified SLU con-fidence scores.
The model of dialog expectationwas based on a simple bigram model using fre-quency counts for (system dialog act, user speechact) pairs.
This can be normalized into a prob-abilistic model that gives the probability of a userspeech act given the context of the most recent sys-tem dialog act to which the user is responding.
Theequation used to modify SLU confidence scores isthe following.
Let Prob(SLU) represent the con-fidence score (expressed as a probability) for thehypothesis SLU , and let V al(SLU) represent theactual hypothesis (e.g.
inform(food = belgian)).Prob(SLUmod) = 0.7?Prob(SLU)+0.3?Expctwhere Prob(SLU) is the original confidencescore for the hypothesis, and Expct is the prob-ability of the occurrence of the speech act used5The mascot name of East Carolina sports teams is thePirates.
In addition, the code development process for ourtracker was based on modification of the simple baselinetracker provided by the DSTC 2 organizers.6Moody (1988) used the Wizard-of-Oz paradigm to col-lect dialogs relevant to the Circuit Fix-It Shop domain aspart of her research into the effects of restricted vocabularyon discourse structure, but the total number of dialogs wasabout 100.
In contrast, DSTC 2 provided 1612 actual human-computer dialogs for the training set, 506 dialogs for the de-velopment set, and 1117 dialogs for the test set.305EA MATracker Food Price Area Food Price Area1 41.2% 25.6% 29.9% 41.5% 36.7% 20.2%2 29.5% 34.8% 35.7% 41.4% 26.6% 27.8%3 36.0% 23.7% 33.0% 30.9% 34.1% 31.9%4 44.4% 25.8% 27.7% 30.4% 35.4% 29.8%5 32.2% 40.5% 27.0% 19.5% 34.0% 42.4%6 28.8% 34.2% 37.0% 46.0% 27.7% 22.8%7 26.7% 38.3% 31.4% 35.7% 33.1% 28.0%8 28.3% 25.7% 44.2% 49.4% 28.9% 18.9%9 28.3% 17.7% 34.3% 54.5% 17.8% 26.8%Table 4: Error Distribution by Attributein the SLU hypothesis given the current systemspeech act (i.e., the probability that comes fromthe statistical model of dialog expectation).
The0.3 weighting factor was determined through trialand error to perform the best given the trainingdata (basing performance on 1-best joint goal ac-curacy).7After calculating the modified values, the scoresare renormalized so that the confidence valuessum to 1.
Given the renormalized values forProb(SLUmod), dialog state was updated by us-ing the following rules.
Let V al(HypCur) repre-sent the current hypothesis in the dialog state forthe value of an attribute, and its confidence scorebe denoted by Prob(HypCur).1.
Increase Prob(SLUmod) by Prob(X)where V al(X) == NULL (i.e.
the defaultNULL hypothesis for the SLU), wheneverProb(X) is < 0.5.
Reset Prob(X) to 0.2.
Replace HypCur with the highest scoringSLUmod for that attribute if the user speechact is an inform, and the following relation-ship holds.Prob(SLUmod) + Tol ?
Prob(HypCur)where Tol is an experimentally determinedtolerance value (currently set at 0.1).3.
If the system speech act was a canthelpact that specifies particular attribute values(e.g.
food = belgian), and the current cho-sen hypothesis (SLUmod) provides informa-tion about that attribute, overwrite the state7For recent work using a Bayesian-based alternative forcombining dialog history with the current utterance to calcu-late probabilities, see Raux and Ma (2011).information for the attribute listed in canthelpeven if the confidence score is less.The motivation for these rules comes from theassumption that the Gricean Cooperative Principlefor conversation (Grice, 1975) applies to this di-alog environment.
Given this assumption, rule 1is based on the belief that the human dialog par-ticipant is attempting to make an appropriate dia-log contribution at every turn.
Consequently whenreasonable, we will augment the top hypothesizedSLU?s confidence score with any weight given tothe NULL hypothesis.
Rule 2 is based on the ideathat an intended new contribution should replacea previous contribution and that some allowanceshould be made for ?signal noise?
in calculatingSLU confidence.
Rule 3 reflects the idea that whenthe system cannot provide assistance about a spec-ified attribute value, any new information aboutthe attribute should be considered a replacement.The above rules are for updating choices forthe individual attributes that are possible compo-nents of the goal state (area, food, name and pricerange).
In our modeling of dialog state, we onlymaintain the top actual hypothesis for each at-tribute, For producing the joint goal, we used thedefault that the joint goal is the product of themarginal goals.8With this fairly simple approach, Pirate had a1-best joint goal accuracy of 72.9%.
This accu-racy rate exceeded the performance of all baselinetrackers, and was 13th out of 31 for the trackerssubmitted.98Consequently, if our confidence score for the top hypoth-esis is < 0.5, that hypothesis will not be included in the jointgoal, as the default ?None?
is associated with higher confi-dence.9The set of 12 trackers that performed better is comprisedof 4 trackers each from 3 other teams.3064.2 Comparison to the Best PerformingTrackerAn entry from team2 achieved 78.4% accuracy onthe 1-best joint goal accuracy metric.
A compar-ative analysis was conducted whereby the perfor-mance of each tracker was compared on a turn-by-turn basis.
Highlights of this analysis include thefollowing.?
The two trackers were both correct 70.6% ofthe time and both incorrect 19.3% of the time.?
7.8% of the time Pirate was incorrect whenthe team2 tracker was correct.?
2.2% of the time, Pirate was correct when theteam2 tracker was incorrect.Further exploration examined performancewithin dialogs.
It was discovered that therewere 18 dialogs where Pirate was incorrect forat least 8 turns where the team2 tracker was cor-rect.
Furthermore, there were no turns in those di-alogs where the team2 tracker was incorrect whenPirate was correct.
Given that the team2 trackerperformed several percentage points better over-all, this is not surprising.
What might be surprisingis that there are 7 dialogs where the opposite wastrue, and Pirate performed better than the team2tracker.
An initial glance at an actual dialog fromeach situation indicated the following.?
While team2 did not offer a description oftheir methodology in their submission, it canbe inferred that they used the original ASRhypotheses as part of its dialog state track-ing.
Pirate was unable to detect in the 2ndturn that the goal (area=dontcare) was beingcommunicated because it did not show up inthe SLU hypotheses.
However, the top ASRhypothesis was ?area?.
Integrating SLU withdialog context is known to be a good ideawhen technically feasible, and is borne out bythis example.
This missing attribute for goalstate was propagated throughout all subse-quent turns of the dialog.
However, it shouldbe noted that omitting an attribute where thecorrect value is ?dontcare?
is a somewhat be-nign error as discussed in the next example.?
The dialog reviewed where the team2 trackerhad trouble that Pirate did not revolvedaround the fact that at an important mo-ment in the dialog, the team2 trackeradded an unstated hypothesis of the form(food=dontcare) to its joint goal.
This wasretained for the duration of the dialog.
It canbe readily argued that this is a benign error.If the user never explicitly gave a constraintabout food (implying that None is the correctvalue for the attribute), the dialog manageris not likely to make a wrong decision if it?sbasing its action instead on (food=dontcare).Time constraints have prohibited further exam-ination of the other dialogs, but clearly this is afruitful area of exploration for understanding be-havioral differences between approaches to dialogstate tracking.5 ConclusionA primary motivation of the DSTC is to allowfor direct comparisons between alternative ap-proaches to dialog state tracking.
The results fromDSTC 1 focused on performance aspects with-out providing a detailed analysis of errors sources.This paper describes several techniques for exam-ining the errors made by the dialog state trackers inorder to refine our understanding of the limitationsof various approaches to the tracking process.Though the analysis at this point is incomplete,one immediate observation is that no one approachis universally superior to other approaches with re-spect to the performance metric 1-best joint goalaccuracy.
However, being able to carefully de-termine the conditions under which one approachoutperforms another and determining if there areways to combine alternative techniques into amore effective but sufficiently efficient trackingmodel is very much an unsolved problem.
Theresults from this paper suggest that a careful anal-ysis of errors can provide further insight into ourknowledge about the difficult challenge of dialogstate tracking.
We would like to explore someof the trends observed with appropriate statisti-cal tests as well as look more carefully at di-alogs where pairwise comparative analysis indi-cates highly differential behavior.AcknowledgmentsThe author would like to acknowledge the valu-able work of East Carolina graduate student RyanDellana in developing several tools that assistedwith compilation of the statistical based expecta-tions as well as tools for generating selected tran-scripts from the DSTC 2 corpus.
A special thanks307goes to the organizers of the DSTC 2 challenge formaking this work possible.
Thanks also go to theanonymous reviewers for their constructive com-ments.
Their suggestions have been very helpfulin producing the final version of this paper.ReferencesH.
P. Grice.
1975.
Logic and conversation.
In P. Coleand J.L.
Morgan, editors, Syntax and Semantics, Vol.3: Speech Acts, pages 41?58.
Academic Press, NewYork.M.
Henderson, B. Thomson, and J. Williams,2013.
Dialog State Tracking Challenge 2 &3. http://camdial.org/?mh521/dstc/downloads/handbook.pdf, accessed March5, 2014.M.
Henderson, B. Thomson, and J. Williams.
2014.The second dialog state tracking challenge.
In Pro-ceedings of the SIGdial 2014 Conference, Philadel-phia, U.S.A., June.T.
S. Moody.
1988.
The Effects of Restricted Vocab-ulary Size on Voice Interactive Discourse Structure.Ph.D.
thesis, North Carolina State University.A.
Raux and Y. Ma.
2011.
Efficient probabilistic track-ing of user goal and dialog history for spoken dialogsystems.
In Proceedings of INTERSPEECH-2011,pages 801?804.R.W.
Smith and S.A. Gordon.
1997.
Effects of variableinitiative on linguistic behavior in human-computerspoken natural language dialog.
Computational Lin-guistics, 23:141?168.R.W.
Smith, D.R.
Hipp, and A.W.
Biermann.
1995.An architecture for voice dialog systems based onProlog-style theorem-proving.
Computational Lin-guistics, 21:281?320.R.W.
Smith.
1998.
An evaluation of strategies forselectively verifying utterance meanings in spokennatural language dialog.
International Journal ofHuman-Computer Studies, 48:627?647.J.
Williams, A. Raux, D. Ramachandran, and A. Black.2013.
The dialog state tracking challenge.
InProceedings of the SIGDIAL 2013 Conference,pages 404?413, Metz, France, August.
Associationfor Computational Linguistics.
http://www.aclweb.org/anthology/W13-4065.308Figure 1: Error Distribution: all dialogsAppendixFigure 1 displays in a graphical fashion the er-ror counts for the different types of missing at-tributes for the trackers listed in Table 1.
Forclarity, the data for trackers 1 and 9 are omitted.?Focus?
is the baseline focus tracker provided bythe DSTC 2 organizers (Henderson et al., 2013),and ?HWU?
is the baseline tracker provided byZhuoran Wang (see http://camdial.org/?mh521/dstc/).
?Trk 3?
is our tracker, Pirate.As a reminder, the best overall performing trackeris the one labeled ?Trk 2?.
One observation fromthe figure is that its best performance is in mini-mizing False Attribute (FA) errors.309
