2.
Text  Generat ionWi l l iam Mann,  Cha i rpersonInstitute for Scientific Information (ISI)at the University of Southern CaliforniaMarina del Ray, CA 90291PanelistsMadeline Bates, Bolt, Beranek and NewmanBarbara Grosz, SRI InternationalDavid D. McDonald, University of MassachusettsKathleen R. McKeown, University of PennsylvaniaWilliam Swartout, Institute for Scientific Information2.1 IntroductionThis report consists of two documents describingthe state of the art of computer generation of naturallanguage text.
Both were prepared by a panel of indi-viduals who are active in research on text generation.The first document assesses the state of the art, identi-fying four kinds of technical developments which willshape the art in the coming decade: linguistically justi-fied grammars, knowledge representation methods,models of the reader, and models of discourse.
Thesecond document is a comprehensive bibliography ontext generation, the first of its kind.
In addition tocitations of documents, it includes descriptions of on-going research efforts.2.2 Assess ing Text Generation TechnologyOur goal here is to assess the state of the art oftext generation for two purposes: to help people whointend to apply that art in the near future and to aid inthe design or selection of appropriate research.This assessment covers all of the technical methodsby which computer programs create and present Eng-lish text in their outputs.
(For simplicity we alwayscall the output language English.)
Because text gener-ation has not always been taken seriously from a tech-nical point of view, it has been actively pursued onlyrecently as a topic in artificial intelligence.
As a resultof this late start, much of the technology available forapplication today is still rather superficial.
However,text generation is now such an active researchtopic that this superficial technology will soon be sur-passed.
(The last part of this report contains an ex-tensive bibliography on the subject.
)2.3 What  Techniques Are Now Avai lable for Usein System Designs?Two kinds of practical text generation techniquesare already in general use and fairly well understood.The first is displaying previously prepared text (orcanned text), and the second is producing text by di-rect translation of knowledge structures.The simplest and most commonly used way to havea computer system produce text is for the implemen-ters of the system to figure out in advance what sortsof English output will be required and then store it astext strings.
The computer merely displays the textthat has been stored.
(For example, almost all errormessages are produced in this way.)
It is relativelyeasy to have a program produce English in this way,and the text can be complex and elegantly written ifdesired.
Unfortunately, because the text strings canbe changed independently of any knowledge structuresthe program might use, there is no guarantee of con-sistency between what the program does and what itsays it does.
Another problem with canned text is thatall questions and answers must be anticipated in ad-wance; for large systems, that may prove to be impos-sible.
Finally, since one text string looks like any oth-er as far as the computer is concerned, the computerprogram cannot easily have a conceptual model ofwhat it is saying.
This means that one should notexpect to see much closure: satisfying 100 needs fortext will not make the second 100 much easier.Another approach to providing English outputproduces text by translating knowledge structures ofthe program directly to English.
This method over-comes many of the problems with canned text, whileintroducing some of its own.
Since the structures be-ing transformed (or translated) are the same ones usedin the program's reasoning process, consistency can beassured.
Closure can be realized because transforma-tions are written to handle large classes of knowledgestructures.
However,  since the transformations per-formed are usually relatively simple, the quality of thetext depends to a great degree on how the knowledgeis structured.
If the text is to be understandable, theknowledge used by the program must be structured so62 American Journal of Computational Linguistics, Volume 8, Number 2, April-June 1982William Mann Text Generationthat it is readily understood.
Finally, systems employ-ing this technique typically have had very little linguis-tic knowledge, so they have produced text that is ver-bose, stilted, and redundant, although readable.Practical, near-term applications of text generationwill share certain characteristics:1.
They require short texts: one to three sentences.2.
They have well-elaborated program data structurescorresponding in fairly simple ways to the desiredtexts.3.
The important knowledge can be represented wellwith present techniques; it does not involve thedifficulties listed in section 2.6.4.
Limited fluency of output is acceptable.Some so-called "expert systems" that explain theirreasoning in English have these characteristics.We believe that text-producing systems of the fu-ture will continue to include processes that producetext by translating knowledge structures.
However,they will be integrated with other processes that useextensive linguistic knowledge, a discourse model, amodel of the reader, and enhanced knowledge repre-sentations.Because of the limited capabilities of present tech-niques, a new project aiming to produce a benchmarkapplication program in the text generation area wouldcurrently be counterproductive, since it would producelittle or no transferable technology and would detractfrom the community's ability to make progress on thegeneral problem.2.4 Basic Components  for a Text  Generat ionFacil ityHow can the very limited capabilities now availablebe developed into fluent, powerful text generationmethods that are easily applied to new tasks?
The nextfew sections describe the kinds of methods that areneeded and are being developed.The underlying model presumed here, which pres-ent research is moving toward, has the following char-acteristics:1.
Responsibility for text generation is in a text gener-ation module rather than being scattered at thepoints of use.2.
A major portion of the text generation module isportable and is developed cumulatively throughmany systems.
The portable components include agrammar that encodes general knowledge of Eng-lish and processes that handle linguistic, task-independent information.We feel strongly that a competent ext generationfacility must have the following four identifiable com-ponents, and that limitations on these will be limita-tions on the overall state of the art for the foreseeablefuture:1.
A comprehensive, linguistically justified grammar.2.
A knowledge-representation f rmalism that canencode diverse kinds of information.3.
A model of the intended reader of the text.4.
A model of discourse structure and control.Each of these draws on existing noncomputationalprecedents, and each requires some special adaptationto the text generation task.Below we describe each of these basic componentsin a form that it might achieve in five to ten years ofresearch.
(These descriptions are followed by a pro-jection of the practical alternatives available to systemdesigners five years hence.
)2.5 Lingust ical ly Just i f ied Grammars  for TextGenerat ionGrammars are ordinarily developed by linguistsover periods of ten to twenty or more years, in depart-ments of linguistics.
The best ones may be written bya single individual, but they reflect the ideas of dozensor hundreds of people who have contributed to refin-ing particular forms.Present practice in linguistics emphasizes carefullyreasoned evelopment of small fragments of grammars.Hence comprehensive, linguistically justified gram-mars, the sort we need, are very rare.Several linguistic traditions (some associated withcomputation and some not) are particularly likely toproduce suitably refined, comprehensive grammars fortext generators.
They are:1.
The systemic tradition, founded by Michael A. K.Halliday around 1961.2.
The transformational tradition, decisively articulat-ed by Noam Chomsky starting in 1957.3.
The Generalized Phrase Structure Grammar tradi-tion, currently associated with Gerald Gazdar.4.
The ATN tradition, begun by Bill Woods and nowbeing developed by him and many others.5.
The LSP tradition, developed so far mainly underthe direction of Naomi Sager.6.
The Diamond (or Diagram) grammar by Jane Rob-inson.Grammars do not appear in computers withoutextensive effort.
Most linguists are not interested inproviding or seeing the level of detail and precise defi-nition needed for effective computational use.
Thereare enormous social barriers between the source ofthese grammars (linguists) and their potential users.
Itwill be necessary to sponsor text generation researchprojects with linguists on the staff; projects staffedentirely by computer people can be expected to yieldonly short-term results.American Journal of Computational Linguistics, Volume 8, Number 2, April-June 1982 63William Mann Text Generation2.6 Knowledge Representat ion FormalismsText generation programs cannot improve much onthe knowledge they are given.
The notation forknowledge must already contain appropriate abstrac-tions in an easily accessible form.
Today's notationsare relatively good at representing logical formulas anddeductive necessities, and also hierarchies of objects.Coverage is particularly weak for these other kinds ofknowledge:1.
Time2.
Space3.
Events and actions4.
Cause5.
Collectives6.
Likelihood7.
Obligation8.
Possibility9.
Negation10.
Quantification11.
Continuity and discreteness2.7 Models  of the ReaderText prepared without considering the reader isuniformly awful.
Programs must have explicit modelsof the reader that encode (or make available) at leastthe following four kinds of information:1.
What is obvious - including common factual knowl-edge and certain "obvious"  inferable information.Obviousness does not agree with logical validity.2.
What has already been told, and what is obviousfrom that.3.
Wha~ others believe - including mutual beliefs andbeliefs about the writer's belief.4.
What is currently in the reader's attention.Beyond these, the program should be able to reasonabout belief and intent.2.8 Models  of DiscourseThis is another linguistic matter, distinct f romgrammar.
Running text has subtle interactions be-tween its parts.
When we generate multisententialtext, we need a set of principles for organizing it.
Afew linguists and philosophers are making importantcontributions, but far more work is needed.
Again, todevelop effective models of discourse, research pro-jects will need to have linguists on the staff.An adequate discourse model will include somerepresentation of at least the following:1.
The structures that can be built out of sentencesand larger units.2.
The needs of the writer that each discourse struc-ture meets.3.
The principal effects that the use of each structureproduces.4.
The effects of various discourse structures on thereader's attention.2.9 Relating the Basic Components  to TextGenerationHow are these basic components related to thewhole task?
Why are they necessary, and how doestheir quality affect what can be done?2.9.1 The Text  Qual ity Limitations of GrammarsIn order to generate text that is not awkward ormisleading, one must be able to control a wide varietyof language effects at the sentence level.
Effects willbe, present in the mind of the reader in any case, andso the program must either control them or take seri-ous risks of misunderstanding and error.
The effectsare produced by the arrangements of words used, andso a theory of the arrangements of words is needed inorder to achieve control.
Theories of the arrange-ments of words are (or include) grammars.
The abilityof a text generation system to express many differentideas well will be limited to the different effects con-trollable through its grammar.Use of an ad hoc grammar limits the generator toexpressing a narrow range of ideas.
It may do well ina short, carefully planned demonstration, but it will betoo narrow for many practical purposes.We can think of the grammar as a bottleneck orfilter at the output of the text generator.
Only thoseexpressive techniques that the system can controlthrough its grammar will be used.2.9.2 The Knowledge RepresentationThe knowledge representat ion frameworks in aprogram limit the range of things that the program canu,;efully operate upon.
Since a text generator mustcreate text out of some knowledge representation, it islikewise limited.Limitations on knowledge representat ions includetwo important kinds:1.
Presence of abstract ions--are the concepts thatmust be conveyed in text actually symbolized?2.
Ease of access--is there a fast, uniform method forfinding the symbols that represent particular con-cepts?We can think of these limits as a bott leneck orfilter at the input of the text generator.
Only thoseconcepts that pass through the filter will appear in thetext.2,9.3 Models  of the Reader or System UserGenerating acceptable text requires that the gener-ator take into account the knowledge of the reader.
Ifthis is not done, text quality is so bad that the results64 American Journal of Computational Linguistics, Volume 8, Number 2, April-June 1982William Mann Text Generationmay be useless.
(With canned text, this problem isusually avoided because the writer knows a great dealabout the reader's knowledge.)
To take the reader'sknowledge into account requires an explicit model ofthat knowledge.Of the four kinds of knowledge previously identi-fied in section 2.7, the most critical for basic textquality are the knowledge of what is obvious and theknowledge of what has already been conveyed.2.9.4 Models of DiscourseWe know that single sentences are too limited toexpress some things.
Moving to multisentential textnecessarily creates discourse, which involves manykinds of effects that programs cannot yet control.
Forexample, putting one sentence after another can beused to express time sequence, deductive necessity,cause, exemplification or other relationships, withoutany words being used to express the relation.Creating these effects when they are desired, andavoiding them when they are not, requires explicitmodels of discourse phenomena.
At a higher level,sequences of sentences and paragraphs of a text mustbe organized in a principled way.
This also requiresexplicit discourse models.
Until such models are de-veloped, texts will be awkward and misunderstandingwill be common.2.10 Des igning in 1986 for  Pract ical  TextGenerat ionWhat sort of practical application of text genera-tion will be possible in five years?
We expect thedesigner to be in the following situation:?
There will be several examinable systems with devel-oped methods for creating the four basic compo-nents.
For each kind of component, there will besome attractive precedents for future work.
Noone system will have a thoroughly elaborated ap-proach to all four.?
System design based on adaptation of these preced-ents will be possible.
The design work will involvecreating "handcraf ted"  systems that embody andreconcile the good techniques.
It will require thepersonal attention of computer scientists, linguists,and programmers who have been involved in theprior research.?
The resulting system can be expected to create ac-ceptable, effective texts, limited by quality consid-erations to be about one page in length.For the message-system problem used as a focalproblem for the workshop, there were two tasks iden-tified for text generation: a task of reporting systemstatus and a task of reporting how and to whom par-ticular messages would be relevant for an identifiedcollection of people.
For both of these tasks it seemsfeasible for design of a practical text generation mo-dule to begin in five years.
However, it is questiona-ble whether adequate techniques would be available todetermine what message relevance to report.2.11 Present Research StatusThe most influential research in the next few yearswill be focused on the four basic components: linguis-tically justified grammars, knowledge representationformalisms, models of readers, and models of discoursestructure and control.
Part of the effort will go intodeveloping these components individually, part intolearning how to combine them.Appropriately, most of the current effort is goinginto either developing single components or combiningtwo of them.
Although there are several institutionsand individuals working on all four of these compo-nents, no one has yet demonstrated a system in whichall four approach the scopes of action indicated forthem above.Malay important opics are being neglected for lackof research support.
(There is no lack of interestedpeople; natural language processing continually gener-ates high interest in the AI community.
We are notsure whether there is a shortage of interested qualifiedpeople.
)More information on the state of the art and cur-rent activity can be found in the bibliography on textgeneration, the last part of this report, which includesa section on research in progress.2.12 Text Generation BibliographyThis bibliography was prepared in connection withthe authors' report on the state of the art in text gen-eration.
It includes published works on generation ofnatural language text by computer programs as well assome prior noncomputational work that has been usedas a basis for such computer programs.
It is not ex-haustive in any sense, and no evaluation is implied bythe presence or absence of a citation of any particularpublication.Allen, J.
1978 Recognizing Intention in Dialogue.
Ph.D. thesis.University of Toronto.Appelt, D.E.
1980a A planner for reasoning about knowledge andaction.
In Proceedings of the First Annual National Conference onArtificial Intelligence.
Stanford University (August).Appelt, D.E.
1980b Problem solving applied to language genera-tion.
In Proceedings of the Eighteenth Annual Meeting of theAssociation for Computational Linguistics.Appelt, D.E.
1981 Planning natural language utterances to satisfymultiple goals.
Forthcoming Ph.D. thesis.
Stanford University.Badler, N.I.
1975 The conceptual description of physical activi-ties.
In Proceedings of the Thirteenth Annual Meeting of theAssociation for Computational Linguistics.Bates, M., Brown, G., and Collins, A.
1978 Socratic Teaching ofCausal Knowledge and Reasoning.
Bolt Beranek and Newman,Inc., Technical Report 3995 (December).American Journal of Computational Linguistics, Volume 8, Number 2, April-June 1982 65Will iam Mann Text GenerationBates, M. 1980 Language instruction without pre-stored examples.In Proceedings of the Third Canadian Symposium on InstructionalTechnology.
(February)Bates, M. and Ingria, R. 1981a Controlled transformational sen-tence generation.
In The Nineteenth Annual Meeting of the Asso-ciation for Computational Linguistics.
Stanford University(June).Bates, M. et al 1981b Generative tutorial systems.
In Proceedingsof the 1981 ADCIS Conference (March).Bates, M. et al 1981c ILIAD Final Report.
Bolt Beranek andNewman, Inc., Technical Report 4771 (September).Berry, M. 1975 Introduction to Systemic Linguistics: Structures andSystems.
B.T.
Batsford, Ltd., London.Berry, M. 1977 Introduction to Systemic Linguistics: Levels andLinks.
B.T.
Batsford, Ltd., London.Birnbaum, L., Flowers, M., and McGuire, R. 1980 Towards anA.I.
model of argumentation.
In Proceedings of the First Na-tional Conference on Artificial Intelligence.
Stanford University(August).Boguraev, B.K.
1979 Automatic Resolution of LinguisticAmbiguities.
Computational Laboratory, Cambridge University,England, Technical Report 11 (August).Bossie, S. 1981 A Tactical Component for Text Generation: SentenceGeneration Using a Functional Grammar.
University of Pennsyl-vania, Technical Report MS-CIS-81-5.Brown, G.P.
1974 Some problems in German to English MachineTranslation.
Massachusetts Institute of Technology, TechnicalReport 142 (December).
Project MAC.Brown, R.H. 1974 Use of multiple-body interrupts in discoursegeneration.
Massachusetts Institute of Technology, Departmentof Electrical Engineering and Computer Science, BachelorsDegree thesis.Bruce, B.C.
1975 Generation as a social action.
In Proceedings ofTheoretical lssues in Natural Language Processing - I (TINLAP).Cambridge, MA (June) 64-67.Bruce, B.C., Collins, A., Rubin, A.D., and Gentner, D. 1978 ACognitive Science Approach to Writing.
Bolt Beranek and New-man, Inc., Technical Report 89 (June).Carbonell, J.R. and Collins, A.M. 1973 Natural semantics inartificial intelligence.
In Proceedings of the Third InternationalJoint Conference on Artificial Intelligence.
Stanford, CA: 344-351.Carr, B. and Goldstein, I.
1977 Overlays: A Theory of Modeling forComputer Aided Instruction.
Massachusetts Institute of Technol-ogy, Artificial Intelligence Laboratory, Memo 406 (February).Chafe, W.L.
1977 Creativity and verbalization and its implicationsfor the nature of stored knowledge.
In Freedle, R.O., Ed.,Discourse Processes: Advances in Research and Theory.
Volume 1:Discourse Production and Comprehension.
Ablex, N J: 41-55.Chafe, W.L.
1979 The flow of thought and the flow of language.In Givon, T., Ed., Syntax and Semantics.
Volume 12: Discourseand Syntax.
Academic Press, NY.Chester, D. 1976 The translation of formal proofs into English.Artificial Intelligence 7 (3) Fall.Clancey, W.J.
1978a Tutoring Rules for Guiding a Case MethodDialogue.
Stanford University, Department of Computer Sci-ence, Heuristic Programming Project, Technical Report HPP-78-25 (December).
Also International Journal of Man-MachineStudies I1 (1979) 25-49.Clancey, W.J.
t978b An Antibiotic Therapy Selector Which Providesfor Explanation.
Stanford University, Technical Report HPP-78-26 (December).Clancey, W.J.
1979 Dialogue management for rule-based tutorials.In Proceedings of the Sixth International Joint Conference onArtificial Intelligence.
Tokyo (Agusut) 155-161.Clippinger, J.H.
1974 A Discourse Speaking Program as a Prelimi-nary Theory of Discourse Behavior and a Limited Theory of Psy-choanalytic Discourse.
Ph.D. thesis, University of Pennsylvania.Clippinger, J.H.
1975 Speaking with many tongues: Some prob-lems in modelling speakers of actual discourse.
In Proceedingsof Theoretical Issues in Natural Language Processing - I(TINLAP).
Cambridge, MA (June) 68-73.Codd, E.F. et al 1978 Rendezvous Version 1: An ExperimentalEnglish-Language Query Formulation System for Casual Users ofRelational Databases.
IBM Research Laboratory, San Jose, CA.Technical Report RJ2144.Colhen, P.R.
and Perrault, C.R.
1977 Overview of planning speechacts.
In Proceedings of the Fifth International Joint Conference onArtificial Intelligence.
Cambridge, MA (August).Cohen, P.R.
1978 On Knowing What to Say: Planning Speech Acts.University of Toronto, Technical Report 118.Cohen, P.R.
and Perrault, C.R.
1979 Elements of a plan-basedtheory of speech acts.
Cognitive Science 3.Collins, A.M., Passafiume, J., Gould, L., and Carbonell, J.G.
1973Improving Interactive Capabilities in Computer-Assisted Instruction.Bolt Beranek and Newman, Inc., Technical Report 2631(August).Cullingford, R.E., Krueger, M.W., Selfridge, M., and Bienkowsky,M.A.
1981 Automated explanations as a component of acomputer-aided design system.
To appear in IEEE Transactionson Systems, Man, and Cybernetics.Danes, F., Ed.
1974 Papers on Functional Sentence Perspective.Academia, Publishing House of the Czechoslovak Academy ofSciences.Davey, A.
1979 Discourse Production.
Edinburgh University Press,Edinburgh.de Beaugrande, Robert 1980 Advances in Discourse Processes.Volume IV: Text, Discourse, and Process: Toward a Multidiscipli-nary Science of Texts.
Ablex, Norwood, NJ.de Joia, A. and Stenton, A.
1980 Terms in Systemic Linguistics.Batsford Academic and Educational, Ltd., London.Dehn, N. 1981a Memory in story invention.
In Proceedings of theThird Annual Conference of the Cognitive Science Society.
Univer-sity of California, Berkeley (August).Dehn, N. 1981b Story generation after TALE-SPIN.
In Proceed-ings of the Seventh International Joint Conference on ArtificialIntelligence.
University of British Columbia (August).Fawcett, R.P.
1980 Exeter Linguistic Studies.
Volume 3: CognitiveLinguistics and Social Interaction.
Julius Groos Verlag Heidel-berg and Exeter University.Fillmore, C.J.
1976 The case for Case reopened.
In Cole, P. andSadock, J.M., Eds., Syntax and Semantics.
Volume 8: Grammati-cal Relations.
Academic Press, NY.Forbus, K. and Stevens, A.
1981 Using Qualitative Simulation toGenerate Explanations.
Bolt Beranek and Newman, Inc., Techni-cal Report 4490 (March).
Also Cognitive Science 3.Friedman, J.
1969 Directed random generation of sentences.Communications of the ACM 12 (6).Gabriel, R.P.
1980 An Organization for Programs in Fluid Domains.Ph.D.
thesis, Stanford University, 1980.Goldman, N.M. 1974 Computer Generation of Natural Languagefrom a Deep Conceptual Base.
Ph.D. thesis, Stanford University.Stanford Artificial Intelligence Laboratory Memo AIM-247.Goldman, N.M. 1975a The boundaries of language generation.
InProceedings of Theoretical Issues in Natural Language Processing -I (T1NLAP).
Cambridge, MA (June) 74-78.Goldman, N.M. 1975b Conceptual generation.
In Schank, R.C.,Ed., Conceptual Information Processing.
North-Holland, Amster-clam.Goldstein, I.
1978 Developing a Computational Representation ofProblem Solving Skills.
Massachusetts Institute of Technology,66 American Journal of Computational Linguistics, Volume 8, Number 2, April-June 1982Will iam Mann Text GenerationArtificial Intelligence Laboratory, Cambridge, MA, memo 495(October).Grimes, I.E.
1975 The Thread of Discourse.
Mouton, The Hague.Grishman, R. 1979 Response generation in question-answeringsystems.
In Proceedings of the Seventeenth Annual Meeting of theAssociation for Computational Linguistics (August) 99-101.Grosz, B.J.
1979 Utterance and objective: Issues in natural an-guage communication.
In Proceedings of the Sixth InternationalJoint Conference on Artificial Intelligence.Grosz, B.J.
1980 Focusing and description in natural languagedialogs.
In Joshi, A. et al, Eds., Elements of  Discourse Under-standing: Proceedings of a Workshop on Computational Aspects ofLinguistic Structure and Discourse Setting.
Cambridge UniversityPress, Cambridge.Habel, C., Schmit, A., and Schweppe, H. 1977 On AutomaticParaphrasing of Natural Language Expressions.
Technische Univ-ersiteit, Berlin, Technical Report 3/ /17.
Semantic NetworkProject.Halliday, M.A.K.
1961 Categories of the theory of grammar.Word 17.Halliday, M.A.K.
1967a Notes on transitivity and theme in Eng-lish.
Journal of Linguistics 3 (1) 37-81.Halliday, M.A.K.
1967b Notes on transitivity and theme in Eng-lish.
Journal of Linguistics 3 (2) 199-244.Halliday.
M.A.K.
1968 Notes on transitivity and theme in English.Journal of Linguistics 4 (2) 179-215.Halliday, M.A.K.
1970 Language structure and language function.In Lyons, J., Ed., New Horizons in Linguistics.
Penguin.Halliday, M.A.K.
1976 System and Function in Language.
OxfordUniversity Press, London.Halliday, M.A.K.
1978 Language as Social Semiotic.
UniversityPark Press, Baltimore, MD.Halliday, M.A.K.
and Hasan, R. 1976 Cohesion in English.
Long-man, London.
English Language Series, Title No.
9.Heidorn, G. 1972 Natural Language Inputs to a Simulation Pro-gramming System.
Naval Postgraduate School, Monterey, CA,Technical Report NPS-55HD72101A.Heidorn, G. 1975 Augmented phrase structure grammar.
InProceedings of Theoretical Issues in Natural Language Processing -I (TINLAP).
Cambridge, MA (June) 1-5.Herskovits, A.
1973 The Generation of French from SemanticStructure.
Stanford Artificial Intelligence Laboratory, TechnicalReport 212.Hobbs, J. and Evans, D. 1980 Conversation as planned behavior.Cognitive Science 4, 349-377.Hudson, R. A.
1971 North-Holland Linguistic Series.
Volume 4:English Complex Sentences.
North-Holland, London and Am-sterdam.Hudson, R. A.
1976 Arguments for a Non-TransformationalGrammar.
University of Chicago Press, Chicago, 1976.Hutchins, W.J .
1971 The Generation of Syntactic Structures from aSyntactic Base.
North-Holland, Amsterdam.Kay, M. 1979 Functional grammar.
In Proceedings of the FifthAnnual Meeting of the Berkeley Linguistic Society.Kempen, G. 1977 Building a psychologically plausible sentencegenerator.
Presented at the Conference on Empirical and Meth-odological Foundations of Semantic Theories for Natural Lan-guage, Nijmegen, The Netherlands.Kempen, G. and Hoenkamp, E. 1979 A Procedural Grammar forSentence Production.
University of Nijmegen, Department ofPsychology, The Netherlands, Technical Report, 1979.Klein, S. 1965 Automatic paraphrasing in essay format.
Mechani-cal Translation 8 (3).Klein, S. 1975 Meta-compiling text grammars as a model forhuman behavior.
In Proceedings of  Theoretical lssues in NaturalLanguage Processing - I (TINLAP).
Cambridge, MA (June)94-98.Knaus, R. 1975 Incremental sentence processing.
American Jour-nal of Computational Linguistics Fiche 33.Kripke, S. 1977 Speaker eference and semantic reference.
InFrench, P.A.
et al, Eds., Contemporary Perspectives in the Phi-losophy of Language.
University of Minnesota Press, Minneapo-lis.Levin, J.A., and Goldman, N.M. 1978 Process Models of Referencein Context.
USC/lnformation Sciences Institute, RR-78-72.Levy, D.M.
1979a Communicative goals and strategies: Betweendiscourse and syntax.
In Givon, T., Ed., Syntax and Semantics.Volume 12: Discourse and Syntax.
Academic Press, New York.Levy, D.M.
1979b The Architecture of the Text.
Ph.D. thesis,Stanford University, Department of Computer Science.Linde C. and Labov, W. 1975 Spatial networks as a site for thestudy of language and thought.
Language 50 (IV) 924-939.Mann, W.C. and Moore, J.A.
1980 Computer as Author - Resultsand Prospects.
USC/Information Sciences Institute, RR-79-82.Mann, W.C. and Moore, J.A.
1981a Computer generation ofmultiparagraph English text.
American Journal of ComputationalLinguistics 7 (1) January - March.Mann, W.C. 1981b Two discourse generators.
In The NineteenthAnnual Meeting of the Association for Computational Linguistics.Sperry Univac.Matthiessen, C.M.I.M.
1981 A grammar and a lexicon for a text-production system.
In The Nineteenth Annual Meeting of  theAssociation for Computational Linguistics.
Sperry Univac.McCoy, K.F.
1981 Automatic Enhancement of a DatabaseKnowledge Representation for Natural Language Generation.University of Pennsylvania, Technical Report MS-CIS-81-6.McDonald, D.D.
1975a A preliminary report on a program forgenerating natural anguage.
In Proceedings of the Third Interna-tional Joint Conference on Artificial Intelligence.
Tibilisi, USSR(August).McDonald, D.D.
1975b A framework for writing generationgrammars for interactive computer programs.
American Journalof Computational Linguistics Fiche 33.McDonald, D.D.
1977 Language generation: The linguistics com-ponent (short note).
In Proceedings of the Fifth InternationalJoint Conference on Artificial Intelligence.
Cambridge, MA(August).McDonald, D.D.
1978 Subsequent references: Syntactic andrhetorical constraints.
In Theoretical Issues in Natural LanguageProcessing - 2 (TINLAP).
ACM, New York.McDonald, D.D.
1980a Natural Language Production as a Processof Decision-Making Under Constraints.
Ph.D. thesis, Massachu-setts Institute of Technology, Dept.
of Electricial Engineeringand Computer Science.
To appear as an MIT Artificial Intelli-gence Laboratory technical report.McDonald, D.D.
1980b The role of discourse structure in lan-guage production.
In The Proceedings of the Third BiannualMeeting of the SCSIO/SCEIO.McDonald, D.D.
1981 Language production: The source of thedictionary.
In The Nineteenth Annual Meeting of  the Associationfor Computational Linguistics.
Stanford University (June).McKeown, K.R.
1979 Paraphrasing using given and new informationin a question-answer system.
Master's thesis, University of Penn-sylvania, Philadelphia.
Number MS-CIS-80-13.
Also in Pro-ceedings of the Seventeenth Annual Meeting of the Association forComputational Lingustics (August) 67-72.McKeown, K.R.
1980a Generating Descriptions and Explanations:Applications to Questions about Database Structure.
University ofPennsylvania, Technical Report MS-CIS-80-9.McKeown, K.R.
1980b Generating relevant explanations: Naturallanguage responses to questions about database structure.
InAmerican Journal of Computational Linguistics, Volume 8, Number 2, April-June 1982 67William Mann Text GenerationProceedings of The First Annual National Conference on ArtificialIntelligence.
Stanford, CA (August) 306-309.McKeown, K.R.
1981 Generating Natural Language: DecidingWhat to Say Next.
University of Pennsylvania, Technical Re-port MS-CIS-81-1.Meehan, J.R. 1975 Using planning structures to generate stories.American Journal of Computational Linguistics Fiche 33.Meehan, J.R. 1977 TALE-SPIN, an interactive program thatwrites stories.
In Proceedings of the Fifth International JointConference on Artificial Intelligence (August).Moore, R. 1980 Reasoning about Knowledge and Action.
SR1 Inter-national, Artificial Intelligence Center, Technical Note 191.Perrault, C.R.
and Cohen, C.R.
1978 Planning Speech Acts.
Uni-versity of Toronto, Department of Computer Science, TechnicalReport.Sacerdoti, E. 1977 A Structure for Plans and Behavior.
Elsevier,North-Holland, Amsterdam.Schank, R., Goldman, N., and Reiger, C. 1975 Inference andparaphrase by computer.
Journal of the ACM 22 (3) July,309-328.Schlesinger, I.M.
1977 Production and Comprehension f Utterances.Lawrence Erlbaum Associates.Shapiro, S.C. 1975 Generation as parsing from a network into alinear string.
American Journal of Computational LinguisticsFiche 33.Shapiro, S.C. 1979 Generalized augmented transition etworkgrammars for generation from semantic networks.
In Proceed-ings of the Seventeenth Meeting of the Association for Computa-tional Linguistics (August) 25-29.Simmons, R. and Slocum, J.
1972 Generating English discoursefrom semantic networks.
Communications of the ACM 15 (10)October, 891-905.Sleeman, D.J.
and Hendley, R.J. 1979 ACE: A system whichanalyses complex explanations.
International Journal of Man-Machine Studies I I  125-144.Slocum, J.
1973 Question Answering via Cannonical Verbs andSemantic Models: Generating English from the Model.
Universityof Texas, Department of Computer Sciences, Austin, TechnicalReport NL 13.Slocum, J.
1975 Speech generation from semantic nets.
AmericanJournal of Computational Linguistics Fiche 33.Stevens, A. and C. Steinberg 1981 A Typology of Explanations andits Application to Intelligent Computer Aided Instruction.
BoltBeranek and Newman, Inc., Technical Report 4626 (March).Swartout, W.R. 1977 A Digitalis Therapy Advisor with Explanations.Massachusetts Institute of Technology, Laboratory for Comput-er Science, Technical Report (February).Swartout, W.R. 1981a Producing Explanations and Justifications ofExpert Consulting Programs.
Massachusetts Institute of Technol-ogy, Technical Report M1T/LCS/TR-251 (January).Swartout, W.R. 1981b Explaining and justifying expert consultingprograms.
In Proceedings of the Seventh International Joint Con-ference on Artificial Intelligence.
University of British Columbia(August).Thompson, H.S.
1977 Strategy and tactics: A model for languageproduction.
In Papers from the Thirteenth Regional Meeting.Chicago Linguistic Society.Thompson, H.S.
1980 Stress and Salience in English: Theory andPractice.
Xerox Palo Alto Research Center, Technical ReportCSL-80-8 (May).Waltz, D.L.
1978 An English language question answering systemfor a large relational database.
Communications of the ACM 21(7) July.Weiner, J.L.
1980 BLAH, a system which explains its reasoning.Artificial Intelligence 15 (November) 19-48.Winograd, T. 1972 Understanding Natural Language.
AcademicPress, Edinburgh.Wong, H.K.T.
1975 Generating English Sentences from SemanticStructures.
University of Toronto, Department of ComputerScience, Technical Report 84.Yngve, V.H.A.
1960 A model and a hypothesis for languagestructure.
In Proceedings of the American Philosophical Society,444-466.Yngve, V.H.A.
1962 Random generation of English sentences.
InThe 1961 Conference on Machine Translation of Languages andApplied Language Analysis.
Her Majesty's Stationery Office,London.2.13 Research  in P rogressThis section describes research in text generat ioneither current ly in progress or recently completed butnot yet described comprehensively  in any publ icat ion.Like the set of references, it is not exhaustive.Barbara Grosz and Doug Appe l t(SRI International)Barbara Grosz and Doug Appelt  are developing aprob lem-so lv ing approach to the design of text, ex-tend ing from prior work by Al len,  Cohen,  and Per-rault.
A hierarchical  p lann ing  system called KAMP(Knowledge and Modal i t ies P lanner )  is being devel-oped, capable of p lanning actions that affect anotheragent 's  knowledge and wants.
It includes critic proc-esses that examine the plan globally for interact ionsbetween the effects of actions and propose modif ica-t ions to the plan that will enable the utterance beingp lanned to realize mult iple i l locut ionary acts.
KAMP'sknowledge representat ion is based on Moore 's  possibleworlds semantics approach to reasoning about  knowl-edge and action.David McDona ld(University of Massachusetts, Amherst)David McDona ld  is the author of MUMBLE, a sys-tem that performs utterance construct ion,  grammaticalsmoothing,  and maintenance  of l inguist ic constra intsfor natura l  language generat ion  by expert programs.MUMBLE is available to interested researchers in thecommon dialect of LISP machine LISP and NIL.
Theauthor  is current ly  extending Mumble 's  grammatica lpower so that it plans word select ion in descr ib ingviLsual scenes and also plans the use of certain connec-tives such as "but , "  "a lso,"  and " thus .
"VVilliam Mann and Chr ist ian Mat th iessen(Information Sciences Institute)Wil l iam Mann,  Chr is t ian Matth iessen,  and othersare developing the Penman system to explore theproblems of creating a portable text generat ion facil ityuseful in mult iple knowledge domains.
Penman willseek to deliver knowledge (in Engl ish) from inside asystem that was not designed to have a text generat ioncomponent .The l inguistic components  of Penman are based onHal l iday's Systemic Grammar.
A large systemic gram-68 American Journal of Computational Linguistics, Volume 8, Number 2, April-June 1982William Mann Text Generationmar of English has been implemented and is beingfitted with semantic parts.The knowledge representation, which resemblesBrachman's early KL-ONE, is being used for both thesubject matter of Penman's generation and the textplans by which Penman generates text.
The emphasisof the research is on providing fluent English outputfrom an easily controlled source.Kathleen McKeown(University of Pennsylvania)Research is being completed on a text generationsystem that embodies computational solutions to thequestions of what to say next and how to organize iteffectively.
Two mechanisms are used to handle theseproblems: (1) rhetorical techniques for communica-tion, encoded as schemas, guide the generation proc-ess, and (2) a focusing mechanism helps maintain dis-course coherence.
Schemas define aspects of dis-course structure and are associated with explicit dis-course purposes.
The focusing mechanism aids in theorganization of the message by constraining the selec-tion of what to talk about next to that which ties inwith the previous discourse in an appropriate way.This work is being done within the framework of anatural language interface to a database system; thecompleted system will generate responses to questionsabout database structure.Steven Bossie, Kath leen McCoy(University of Pennsylvania)Two systems are being developed at the Universityof Pennsylvania in conjunction with McKeown's textgeneration system.
One, developed by KathleenMcCoy, automatically enhances a metalevel descrip-tion of a database for use by McKeown's text genera-tion system.
This system generates subclasses ofclasses in a given generalization hierarchy.
It usesinformation in the database and a set of axioms tocreate the subclasses and select salient informationdescribing the subclass divisions.Steven Bossie is developing a system that will takethe ordered message created by McKeown's text gen-eration system and translate it into English.
Bossie'ssystem uses a functional grammar, based on a formal-ism defined by Kay 1979, which will allow for thedirect encoding of focus constraints in the grammar.Thus, eventually, the system will use the focusing in-formation provided by McKeown's system to selectsyntactic onstructions.Rod McGui re(Yale)Working toward his Ph.D. dissertation, RodMcGuire is developing a model of knowledge repre-sentation in human memory to account for observedconstraints on the content of oral text.
In this model,sentences are generated without building syntacticstructures.
In multisentential text, coherence arisesdirectly from the form of representation i memoryand from memory representation traversal algorithms,using a homogeneous representation to cover syntacticstructure, rhetorical structure, and text plans.Made l ine  Bates, Robert  Ingria, and Kirk Wi l son(BBN and Boston University)The ILIAD system is an intelligent CAI system be-ing developed by Madeline Bates, Robert Ingria, KirkWilson (of Learning Tools, Inc., Brookline, Mass.)
andothers to give instruction and practice in English.
Theemphasis is not on teaching grammar, but the systemneeds to have a deep understanding of the syntacticrelationships in the sentences used in examples andexercises.
For this reason, the heart of the ILIADsystem is a sentence generator that is based on theparadigm of transformational grammar.ILIAD's grammar blends some aspects of standardtransformational theory with the extended standardtheory.
Rules have been developed to generate notonly most of the common English structures but alsoungrammatical sentences typical of those produced bypeople with language-delaying handicaps uch as deaf-ness.
To control the operation of the generator, sever-al layers of control structures have been developed.Constraints and syntactic specifications allow the userand the system to determine the syntactic form of thesentences at a very high level.
Although semanticinformation is currently used only in lexical insertion,a KL-ONE INTERFACE is being designed.American Journal of Computational Linguistics, Volume 8, Number 2, April-June 1982 69
