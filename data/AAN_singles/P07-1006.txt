Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 41?48,Prague, Czech Republic, June 2007. c?2007 Association for Computational LinguisticsLearning Expressive Models for Word Sense DisambiguationLucia SpeciaNILC/ICMCUniversity of S?o PauloCaixa Postal 668, 13560-970S?o Carlos, SP, Brazillspecia@icmc.usp.brMark StevensonDepartment of Computer ScienceUniversity of SheffieldRegent Court, 211 Portobello St.Sheffield, S1 4DP, UKmarks@dcs.shef.ac.ukMaria das Gra?as V. NunesNILC/ICMCUniversity of S?o PauloCaixa Postal 668, 13560-970S?o Carlos, SP, Brazilgracan@icmc.usp.brAbstractWe present a novel approach to the wordsense disambiguation problem whichmakes use of corpus-based evidence com-bined with background knowledge.
Em-ploying an inductive logic programmingalgorithm, the approach generates expres-sive disambiguation rules which exploitseveral knowledge sources and can alsomodel relations between them.
The ap-proach is evaluated in two tasks: identifica-tion of the correct translation for a set ofhighly ambiguous verbs in English-Portuguese translation and disambiguationof verbs from the Senseval-3 lexical sam-ple task.
The average accuracy obtained forthe multilingual task outperforms the othermachine learning techniques investigated.In the monolingual task, the approach per-forms as well as the state-of-the-art sys-tems which reported results for the sameset of verbs.1 IntroductionWord Sense Disambiguation (WSD) is concernedwith the identification of the meaning of ambi-guous words in context.
For example, among thepossible senses of the verb ?run?
are ?to move fastby using one's feet?
and ?to direct or control?.WSD can be useful for many applications, includ-ing information retrieval, information extractionand machine translation.
Sense ambiguity has beenrecognized as one of the most important obstaclesto successful language understanding since the ear-ly 1960?s and many techniques have been pro-posed to solve the problem.
Recent approachesfocus on the use of various lexical resources andcorpus-based techniques in order to avoid the sub-stantial effort required to codify linguistic know-ledge.
These approaches have shown good results;particularly those using supervised learning (seeMihalcea et al, 2004 for an overview of state-of-the-art systems).
However, current approaches relyon limited knowledge representation and modelingtechniques: traditional machine learning algorithmsand attribute-value vectors to represent disambigu-ation instances.
This has made it difficult to exploitdeep knowledge sources in the generation of thedisambiguation models, that is, knowledge thatgoes beyond simple features extracted directlyfrom the corpus, like bags-of-words and colloca-tions, or provided by shallow natural languagetools like part-of-speech taggers.In this paper we present a novel approach forWSD that follows a hybrid strategy, i.e.
combinesknowledge and corpus-based evidence, and em-ploys a first-order formalism to allow the represen-tation of deep knowledge about disambiguationexamples together with a powerful modeling tech-nique to induce theories based on the examples andbackground knowledge.
This is achieved usingInductive Logic Programming (ILP) (Muggleton,1991), which has not yet been applied to WSD.Our hypothesis is that by using a very expres-sive representation formalism, a range of (shallowand deep) knowledge sources and ILP as learningtechnique, it is possible to generate models that,when compared to models produced by machinelearning algorithms conventionally applied to41WSD, are both more accurate for fine-grained dis-tinctions, and ?interesting?, from a knowledge ac-quisition point of view (i.e., convey potentiallynew knowledge that can be easily interpreted byhumans).WSD systems have generally been more suc-cessful in the disambiguation of nouns than othergrammatical categories (Mihalcea et al, 2004).
Acommon approach to the disambiguation of nounshas been to consider a wide context around theambiguous word and treat it as a bag of words orlimited set of collocates.
However, disambiguationof verbs generally benefits from more specificknowledge sources, such as the verb?s relation toother items in the sentence (for example, by ana-lysing the semantic type of its subject and object).Consequently, we believe that the disambiguationof verbs is task to which ILP is particularly well-suited.
Therefore, this paper focuses on the disam-biguation of verbs, which is an interesting tasksince much of the previous work on WSD has con-centrated on the disambiguation of nouns.WSD is usually approached as an independenttask, however, it has been argued that differentapplications may have specific requirements (Res-nik and Yarowsky, 1997).
For example, in machinetranslation, WSD, or translation disambiguation, isresponsible for identifying the correct translationfor an ambiguous source word.
There is not alwaysa direct relation between the possible senses for aword in a (monolingual) lexicon and its transla-tions to a particular language, so this represents adifferent task to WSD against a (monolingual)lexicon (Hutchins and Somers, 1992).
Although ithas been argued that WSD does not yield bettertranslation quality than a machine translationsystem alone, it has been recently shown that aWSD module that is developed following specificmultilingual requirements can significantly im-prove the performance of a machine translationsystem (Carpuat et al, 2006).This paper focuses on the application of our ap-proach to the translation of verbs in English to Por-tuguese translation, specifically for a set of 10mainly light and highly ambiguous verbs.
We alsoexperiment with a monolingual task by using theverbs from Senseval-3 lexical sample task.
Weexplore knowledge from 12 syntactic, semanticand pragmatic sources.
In principle, the proposedapproach could also be applied to any lexical dis-ambiguation task by customizing the sense reposi-tory and knowledge sources.In the remainder of this paper we first presentrelated approaches to WSD and discuss their limi-tations (Section 2).
We then describe some basicconcepts on ILP and our application of this tech-nique to WSD (Section 3).
Finally, we describedour experiments and their results (Section 4).2 Related WorkWSD approaches can be classified as (a) know-ledge-based approaches, which make use of lin-guistic knowledge, manually coded or extractedfrom lexical resources (Agirre and Rigau, 1996;Lesk 1986); (b) corpus-based approaches, whichmake use of shallow knowledge automatically ac-quired from corpus and statistical or machinelearning algorithms to induce disambiguationmodels (Yarowsky, 1995; Sch?tze 1998); and (c)hybrid approaches, which mix characteristics fromthe two other approaches to automatically acquiredisambiguation models from corpus supported bylinguistic knowledge (Ng and Lee 1996; Stevensonand Wilks, 2001).Hybrid approaches can combine advantagesfrom both strategies, potentially yielding accurateand comprehensive systems, particularly whendeep knowledge is explored.
Linguistic knowledgeis available in electronic resources suitable forpractical use, such as WordNet (Fellbaum, 1998),dictionaries and parsers.
However, the use of thisinformation has been hampered by the limitationsof the modeling techniques that have been ex-plored so far: using deep sources of domain know-ledge is beyond the capabilities of such techniques,which are in general based on attribute-value vec-tor representations.Attribute-value vectors consist of a set ofattributes intended to represent properties of theexamples.
Each attribute has a type (its name) anda single value for a given example.
Therefore,attribute-value vectors have the same expressive-ness as propositional formalisms, that is, they onlyallow the representation of atomic propositions andconstants.
These are the representations used bymost of the machine learning algorithms conven-tionally employed to WSD, for example Na?veBayes and decision-trees.
First-order logic, a moreexpressive formalism which is employed by ILP,allows the representation of variables and n-arypredicates, i.e., relational knowledge.42In the hybrid approaches that have been ex-plored so far, deep knowledge, like selectional pre-ferences, is either pre-processed into a vectorrepresentation to accommodate machine learningalgorithms, or used in previous steps to filter outpossible senses e.g.
(Stevenson and Wilks, 2001).This may cause information to be lost and, in addi-tion, deep knowledge sources cannot interact in thelearning process.
As a consequence, the modelsproduced reflect only the shallow knowledge thatis provided to the learning algorithm.Another limitation of attribute-value vectors isthe need for a unique representation for all the ex-amples: one attribute is created for every knowl-edge feature and the same structure is used tocharacterize all the examples.
This usually resultsin a very sparse representation of the data, giventhat values for certain features will not be availablefor many examples.
The problem of data sparse-ness increases as more knowledge is exploited andthis can cause problems for the machine learningalgorithms.A final disadvantage of attribute-value vectorsis that equivalent features may have to be boundedto distinct identifiers.
An example of this occurswhen the syntactic relations between words in asentence are represented by attributes for each pos-sible relation, sentences in which there is morethan one instantiation for a particular grammaticalrole cannot be easily represented.
For example, thesentence ?John and Anna gave Mary a present.
?contains a coordinate subject and, since each fea-ture requires a unique identifier, two are required(subj1-verb1, subj2-verb1).
These will be treated astwo independent pieces of knowledge by the learn-ing algorithm.First-order formalisms allow a generic predicateto be created for every possible syntactic role, re-lating two or more elements.
For examplehas_subject(verb, subject), which could then havetwo instantiations: has_subject(give, john) andhas_subject(give, anna).
Since each example isrepresented independently from the others, the datasparseness problem is minimized.
Therefore, ILPseems to provide the most general-purpose frame-work for dealing with such data: it does not sufferfrom the limitations mentioned above since thereare explicit provisions made for the inclusion ofbackground knowledge of any form, and the repre-sentation language is powerful enough to capturecontextual relationships.3 A hybrid relational approach to WSDIn what follows we provide an introduction to ILPand then outline how it is applied to WSD by pre-senting the sample corpus and knowledge sourcesused in our experiments.3.1 Inductive Logic ProgrammingInductive Logic Programming (Muggleton, 1991)employs techniques from Machine Learning andLogic Programming to build first-order theoriesfrom examples and background knowledge, whichare also represented by first-order clauses.
It allowsthe efficient representation of substantial know-ledge about the problem, which is used during thelearning process, and produces disambiguationmodels that can make use of this knowledge.
Thegeneral approach underlying ILP can be outlinedas follows:Given:-  a set of positive and negative examples E =E+ ?
E-- a predicate p specifying the target relation tobe learned- knowledge ?
of the domain, described ac-cording to a language Lk, which specifies whichpredicates qi can be part of the definition of p.The goal is: to induce a hypothesis (or theory)h for p, with relation to E and ?, which coversmost of the E+, without covering the E-, i.e., K ?
hE+ and K ?
h  E-.We use the Aleph ILP system (Srinivasan, 2000),which provides a complete inference engine andcan be customized in various ways.
The defaultinference engine induces a theory iteratively usingthe following steps:1.
One instance is randomly selected to be gen-eralized.2.
A more specific clause (the bottom clause) isbuilt using inverse entailment (Muggleton, 1995),generally consisting of the representation of all theknowledge about that example.3.
A clause that is more generic than the bottomclause is searched for using a given search (e.g.,best-first) and evaluation strategy (e.g., number ofpositive examples covered).4.
The best clause is added to the theory and theexamples covered by that clause are removed fromthe sample set.
Stop if there are more no examplesin the training set, otherwise return to step 1.433.2 Sample dataThis approach was evaluated using two scenarios:(1) an English-Portuguese multilingual setting ad-dressing 10 very frequent and problematic verbsselected in a previous study (Specia et.
al., 2005);and (2) an English setting consisting of 32 verbsfrom Senseval-3 lexical sample task (Mihalcea et.al.
2004).For the first scenario a corpus containing 500sentences for each of the 10 verbs was constructed.The text was randomly selected from corpora ofdifferent domains and genres, including literaryfiction, Bible, computer science dissertation ab-stracts, operational system user manuals, newspa-pers and European Parliament proceedings.
Thiscorpus was automatically annotated with the trans-lation of the verb using a tagging system based onparallel corpus, statistical information and transla-tion dictionaries (Specia et al, 2005), followed bya manual revision.
For each verb, the sense reposi-tory was defined as the set of all the possible trans-lations of that verb in the corpus.
80% of thecorpus was randomly selected and used for train-ing, with the remainder retained for testing.
The 10verbs, number of possible translations and the per-centage of sentences for each verb which use themost frequent translation are shown in Table 1.For the monolingual scenario, we use the sensetagged corpus and sense repositories provided forverbs in Senseval-3.
There are 32 verbs with be-tween 40 and 398 examples each.
The number ofsenses varies between 3 and 10 and the averagepercentage of examples with the majority (mostfrequent) sense is 55%.Verb # Translations Most frequenttranslation - %ask 7 53come 29 36get 41 13give 22 72go 30 53live 8 66look 12 41make 21 70take 32 25tell 8 66Table 1.
Verbs and possible senses in our corpusBoth corpora were lemmatized and part-of-speech(POS) tagged using Minipar (Lin, 1993) andMxpost (Ratnaparkhi, 1996), respectivelly.
Addi-tionally, proper nouns identified by the tagger werereplaced by a single identifier (proper_noun) andpronouns replaced by identifiers representingclasses of pronouns (relative_pronoun, etc.
).3.3 Knowledge sourcesWe now describe the background knowledgesources used by the learning algorithm, having asan example sentence (1), in which the word ?com-ing?
is the target verb being disambiguated.
(1) "If there is such a thing as reincarnation, Iwould not mind coming back as a squirrel".KS1.
Bag-of-words consisting of 5 words to theright and left of the verb (excluding stop words),represented using definitions of the formhas_bag(snt, word):has_bag(snt1, mind).has_bag(snt1, not).
?KS2.
Frequent bigrams consisting of pairs of adja-cent words in a sentence (other than the targetverb) which occur more than 10 times in the cor-pus, represented by has_bigram(snt, word1,word2):has_bigram(snt1, back, as).has_bigram(snt1, such, a).
?KS3.
Narrow context containing 5 content words tothe right and left of the verb, identified using POStags, represented by has_narrow(snt,word_position, word):has_narrow(snt1, 1st_word_left, mind).has_narrow(snt1, 1st_word_right, back).
?KS4.
POS tags of 5 words to the right and left ofthe verb, represented by has_pos(snt,word_position, pos):has pos(snt1, 1st_word_left, nn).has pos(snt1, 1st_word_right, rb).
?KS5.
11 collocations of the verb: 1st preposition tothe right, 1st and 2nd words to the left and right,1st noun, 1st adjective, and 1st verb to the left andright.
These are represented using definitions of theform has_collocation(snt, type, collocation):has_collocation(snt1, 1st_prep_right, back).has_collocation(snt1, 1st_noun_left, mind).?44KS6.
Subject and object of the verb obtained usingMinipar and represented by has_rel(snt, type,word):has_rel(snt1, subject, i).has_rel(snt1, object, nil).
?KS7.
Grammatical relations not including the tar-get verb also identified using Minipar.
The rela-tions (verb-subject, verb-object, verb-modifier,subject-modifier, and object-modifier) occurringmore than 10 times in the corpus are representedby has_related_pair(snt, word1, word2):has_related_pair(snt1, there, be).
?KS8.
The sense with the highest count of overlap-ping words in its dictionary definition and in thesentence containing the target verb (excluding stopwords) (Lesk, 1986), represented byhas_overlapping(sentence, translation):has_overlapping(snt1, voltar).KS9.
Selectional restrictions of the verbs definedusing LDOCE (Procter, 1978).
WordNet is usedwhen the restrictions imposed by the verb are notpart of the description of its arguments, but can besatisfied by synonyms or hyperonyms of those ar-guments.
A hierarchy of feature types is used toaccount for restrictions established by the verb thatare more generic than the features describing itsarguments in the sentence.
This information isrepresented by definitions of the form satis-fy_restriction(snt, rest_subject, rest_object):satisfy_restriction(snt1, [human], nil).satisfy_restriction(snt1, [animal, human], nil).KS1-KS9 can be applied to both multilingual andmonolingual disambiguation tasks.
The followingknowledge sources were specifically designed formultilingual applications:KS10.
Phrasal verbs in the sentence identified usinga list extracted from various dictionaries.
(Thisinformation was not used in the monolingual taskbecause phrasal constructions are not consideredverb senses in Senseval data.)
These arerepresented by definitions of the formhas_expression(snt, verbal_expression):has_expression(snt1, ?come back?).KS11.
Five words to the right and left of the targetverb in the Portuguese translation.
This could beobtained using a machine translation system thatwould first translate the non-ambiguous words inthe sentence.
In our experiments it was extractedusing a parallel corpus and represented using defi-nitions of the form has_bag_trns(snt, portu-guese_word):has_bag_trns(snt1, coelho).has_bag_trns(snt1, reincarna??o).
?KS12.
Narrow context consisting of 5 collocationsof the verb in the Portuguese translation, whichtake into account the positions of the words,represented by has_narrow_trns(snt,word_position, portuguese_word):has_narrow_trns(snt1, 1st_word_right, como).has_narrow_trns(snt1, 2nd_word_right, um).
?In addition to background knowledge, the systemlearns from a set of examples.
Since all knowledgeabout them is expressed as background knowledge,their representation is very simple, containing onlythe sentence identifier and the sense of the verb inthat sentence, i.e.
sense(snt, sense):sense(snt1,voltar).sense(snt2,ir).
?Based on the examples, background knowledgeand a series of settings specifying the predicate tobe learned (i.e., the heads of the rules), the predi-cates that can be in the conditional part of therules, how the arguments can be shared among dif-ferent  predicates and several other parameters, theinference engine produces a set of symbolic rules.Figure 1 shows examples of the rules induced forthe verb ?to come?
in the multilingual task.Figure 1.
Examples of rules produced for the verb?come?
in the multilingual taskRule_1.
sense(A, voltar) :-has_collocation(A, 1st_prep_right, back).Rule_2.
sense(A, chegar) :-has_rel(A, subj, B), has_bigram(A, today, B),has_bag_trans(A, hoje).Rule_3.
sense(A, chegar) :-satisfy_restriction(A, [animal, human], [concrete]);has_expression(A, 'come at').Rule_4.
sense(A, vir) :-satisfy_restriction(A, [animate], nil);(has_rel(A, subj, B),(has_pos(A, B, nnp); has_pos(A, B, prp))).45Models learned with ILP are symbolic and can beeasily interpreted.
Additionally, innovative knowl-edge about the problem can emerge from the ruleslearned by the system.
Although some rules simplytest shallow features such as collocates, others poseconditions on sets of knowledge sources, includingrelational sources, and allow non-instantiated ar-guments to be shared amongst them by means ofvariables.
For example, in Figure 1, Rule_1 statesthat the translation of the verb in a sentence A willbe ?voltar?
(return) if the first preposition to theright of the verb in that sentence is ?back?.
Rule_2states that the translation of the verb will be?chegar?
(arrive) if it has a certain subject B,which occurs frequently with the word ?today?
as abigram, and if the partially translated sentence con-tains the word ?hoje?
(the translation of ?today?
).Rule_3 says that the translation of the verb will be?chegar?
(reach) if the subject of the verb has thefeatures ?animal?
or ?human?
and the object hasthe feature ?concrete?, or if the verb occurs in theexpression ?come at?.
Rule_4 states that the trans-lation of the verb will be ?vir?
(move toward) if thesubject of the verb has the feature ?animate?
andthere is no object, or if the verb has a subject B thatis a proper noun (nnp) or a personal pronoun (prp).4 Experiments and resultsTo assess the performance of the approach themodel produced for each verb was tested on thecorresponding set of test cases by applying therules in a decision-list like approach, i.e., retainingthe order in which they were produced and backingoff to the most frequent sense in the training set toclassify cases that were not covered by any of therules.
All the knowledge sources were made avail-able to be used by the inference engine, since pre-vious experiments showed that they are all relevant(Specia, 2006).
In what follows we present the re-sults and discuss each task.4.1 Multilingual taskTable 2 shows the accuracies (in terms of percen-tage of corpus instances which were correctly dis-ambiguated) obtained by the Aleph models.Results are compared against the accuracy thatwould be obtained by using the most frequenttranslation in the training set to classify all the ex-amples of the test set (in the column labeled ?Ma-jority sense?).
For comparison, we ran experimentswith three learning algorithms frequently used forWSD, which rely on knowledge represented asattribute-value vectors: C4.5 (decision-trees),Naive Bayes and Support Vector Machine (SVM)1.In order to represent all knowledge sources inattribute-value vectors, KS2, KS7, KS9 and KS10had to be pre-processed to be transformed into bi-nary attributes.
For example, in the case of selec-tional restrictions (KS9), one attribute was createdfor each possible sense of the verb and a true/falsevalue was assigned to it depending on whether thearguments of the verb satisfied any restrictions re-ferring to that sense.
Results for each of these algo-rithms are also shown in Table 2.As we can see in Table 2, the accuracy of theILP approach is considerably better than the mostfrequent sense baseline and also outperforms theother learning algorithms.
This improvement isstatistically significant (paired t-test; p < 0.05).
Asexpected, accuracy is generally higher for verbswith fewer possible translations.The models produced by Aleph for all the verbsare reasonably compact, containing 50 to 96 rules.In those models the various knowledge sourcesappear in different rules and all are used.
Thisdemonstrates that they are all useful for the disam-biguation of verbs.Verb Majori-ty senseC4.5 Na?veBayesSVM Alephask 0.68 0.68 0.82 0.88 0.92come 0.46 0.57 0.61 0.68 0.73get 0.03 0.25 0.46 0.47 0.49give 0.72 0.71 0.74 0.74 0.74go 0.49 0.61 0.66 0.66 0.66live 0.71 0.72 0.64 0.73 0.87look 0.48 0.69 0.81 0.83 0.93make 0.64 0.62 0.60 0.64 0.68take 0.14 0.41 0.50 0.51 0.59tell 0.65 0.67 0.66 0.68 0.82Average 0.50 0.59 0.65 0.68 0.74Table 2.
Accuracies obtained by Aleph and otherlearning algorithms in the multilingual taskThese results are very positive, particularly if weconsider the characteristics of the multilingual sce-nario: (1) the verbs addressed are highly ambi-guous; (2) the corpus was automatically tagged andthus distinct synonym translations were sometimes1The implementations provided by Weka were used.
Weka isavailable from http://www.cs.waikato.ac.nz/ml/weka/46used to annotate different examples (these count asdifferent senses for the inference engine); and (3)certain translations occur very infrequently (just 1or 2 examples in the whole corpus).
It is likely thata less strict evaluation regime, such as one whichtakes account of synonym translations, would re-sult in higher accuracies.It is worth noticing that we experimented with afew relevant parameters for both Aleph and theother learning algorithms.
Values that yielded thebest average predictive accuracy in the trainingsets were assumed to be optimal and used to eva-luate the test sets.4.2 Monolingual taskTable 3 shows the average accuracy obtained byAleph in the monolingual task (Senseval-3 verbswith fine-grained sense distinctions and using theevaluation system provided by Senseval).
It alsoshows the average accuracy of the most frequentsense and accuracies reported on the same set ofverbs by the best systems submitted by the siteswhich participated in this task.
Syntalex-3 (Mo-hammad and Pedersen, 2004) is based on an en-semble of bagged decision trees with narrowcontext part-of-speech features and bigrams.CLaC1 (Lamjiri et al, 2004) uses a Naive Bayesalgorithm with a dynamically adjusted contextwindow around the target word.
Finally, MC-WSD(Ciaramita and Johnson, 2004) is a multi-class av-eraged perceptron classifier using syntactic andnarrow context features, with one componenttrained on the data provided by Senseval and othertrained on WordNet glosses.System % Average accuracyMajority sense 0.56Syntalex-3 0.67CLaC1 0.67MC-WSD 0.72Aleph 0.72Table 3.
Accuracies obtained by Aleph and otherapproaches in the monolingual taskAs we can see in Table 3, results are very encour-aging: even without being particularly customizedfor this monolingual task, the ILP approach signif-icantly outperforms the majority sense baseline andperforms as well as the state-of-the-art system re-porting results for the same set of verbs.
As withthe multilingual task, the models produced containa small number of rules (from 6, for verbs with afew examples, to 88) and all knowledge sourcesare used across different rules and verbs.In general, results from both multilingual andmonolingual tasks demonstrate that the hypothesisput forward in Section 1, that ILP?s ability to gen-erate expressive rules which combine and integratea wide range of knowledge sources is beneficial forWSD systems, is correct.5 ConclusionWe have introduced a new hybrid approach toWSD which uses ILP to combine deep and shallowknowledge sources.
ILP induces expressive disam-biguation models which include relations betweenknowledge sources.
It is an interesting approach tolearning which has been considered promising forseveral applications in natural language processingand has been explored for a few of them, namelyPOS-tagging, grammar acquisition and semanticparsing (Cussens et al, 1997; Mooney, 1997).
Thispaper has demonstrated that ILP also yields goodresults for WSD, in particular for the disambigua-tion of verbs.We plan to further evaluate our approach forother sets of words, including other parts-of-speechto allow further comparisons with other approach-es.
For example, Dang and Palmer (2005) also usea rich set of features with a traditional learning al-gorithm (maximum entropy).
Currently, we areevaluating the role of the WSD models for the 10verbs of the multilingual task in an English-Portuguese statistical machine translation system.ReferencesEneko Agirre and German Rigau.
1996.
Word SenseDisambiguation using Conceptual Density.
Proceed-ings of the 15th Conference on Computational Lin-guistics (COLING-96).
Copenhagen, pages 16-22.Marine Carpuat, Yihai Shen, Xiaofeng Yu, and DekaiWU.
2006.
Toward Integrating Word Sense and Enti-ty Disambiguation into Statistical Machine Transla-tion.
Proceedings of the Third InternationalWorkshop on Spoken Language Translation,.
Kyoto,pages 37-44.Massimiliano Ciaramita and Mark Johnson.
2004.
Mul-ti-component Word Sense Disambiguation.
Proceed-ings of Senseval-3: 3rd International Workshop onthe Evaluation of Systems for the Semantic Analysisof Text, Barcelona, pages 97-100.47James Cussens, David Page, Stephen Muggleton, andAshwin Srinivasan.
1997.
Using Inductive LogicProgramming for Natural Language Processing.Workshop Notes on Empirical Learning of NaturalLanguage Tasks, Prague, pages 25-34.Hoa T. Dang and Martha Palmer.
2005.
The Role ofSemantic Roles in Disambiguating Verb Senses.Proceedings of the 43rd Meeting of the Associationfor Computational Linguistics (ACL-05), Ann Arbor,pages 42?49.Christiane Fellbaum.
1998.
WordNet: An ElectronicLexical Database.
MIT Press, Massachusetts.W.
John Hutchins and Harold L. Somers.
1992.
An In-troduction to Machine Translation.
Academic Press,Great Britain.Abolfazl K. Lamjiri, Osama El Demerdash, Leila Kos-seim.
2004.
Simple features for statistical WordSense Disambiguation.
Proceedings of Senseval-3:3rd International Workshop on the Evaluation of Sys-tems for the Semantic Analysis of Text, Barcelona,pages 133-136.Michael Lesk.
1986.
Automatic sense disambiguationusing machine readable dictionaries: how to tell apine cone from an ice cream cone.
ACM SIGDOCConference, Toronto, pages 24-26.Dekang Lin.
1993.
Principle based parsing withoutovergeneration.
Proceedings of the 31st Meeting ofthe Association for Computational Linguistics (ACL-93), Columbus, pages 112-120.Rada Mihalcea, Timothy Chklovski and Adam Kilga-riff.
2004.
The Senseval-3 English Lexical SampleTask.
Proceedings of Senseval-3: 3rd InternationalWorkshop on the Evaluation of Systems for SemanticAnalysis of Text, Barcelona, pages 25-28.Saif Mohammad and Ted Pedersen.
2004.
Complemen-tarity of Lexical and Simple Syntactic Features: TheSyntaLex Approach to Senseval-3.
Proceedings ofSenseval-3: 3rd International Workshop on the Eval-uation of Systems for the Semantic Analysis of Text,Barcelona, pages 159-162.Raymond J. Mooney.
1997.
Inductive Logic Program-ming for Natural Language Processing.
Proceedingsof the 6th International Workshop on ILP, LNAI1314, Stockolm, pages 3-24.Stephen Muggleton.
1991.
Inductive Logic Program-ming.
New Generation Computing, 8(4):295-318.Stephen Muggleton.
1995.
Inverse Entailment and Pro-gol.
New Generation Computing, 13:245-286.Hwee T. Ng and Hian B. Lee.
1996.
Integrating mul-tiple knowledge sources to disambiguate word sense:an exemplar-based approach.
Proceedings of the 34thMeeting of the Association for ComputationalLinguistics (ACL-96), Santa Cruz, CA, pages 40-47.Paul Procter (editor).
1978.
Longman Dictionary ofContemporary English.
Longman Group, Essex.Adwait Ratnaparkhi.
1996.
A Maximum Entropy Part-Of-Speech Tagger.
Proceedings of the Conference onEmpirical Methods in Natural Language Processing,New Jersey, pages 133-142.Phillip Resnik and David Yarowsky.
1997.
A Perspec-tive on Word Sense Disambiguation Methods andtheir Evaluating.
Proceedings of the ACL-SIGLEXWorkshop Tagging Texts with Lexical Semantics:Why, What and How?, Washington.Hinrich Sch?tze.
1998.
Automatic Word Sense Discrim-ination.
Computational Linguistics, 24(1): 97-123.Lucia Specia, Maria G.V.
Nunes, and Mark Stevenson.2005.
Exploiting Parallel Texts to Produce aMultilingual Sense Tagged Corpus for Word SenseDisambiguation.
Proceedings of the Conference onRecent Advances on Natural Language Processing(RANLP-2005), Borovets, pages 525-531.Lucia Specia.
2006.
A Hybrid Relational Approach forWSD - First Results.
Proceedings of theCOLING/ACL 06 Student Research Workshop, Syd-ney, pages 55-60.Ashwin Srinivasan.
2000.
The Aleph Manual.
TechnicalReport.
Computing Laboratory, Oxford University.Mark Stevenson and Yorick Wilks.
2001.
The Interactionof Knowledge Sources for Word Sense Disambiguation.Computational Linguistics, 27(3):321-349.Yorick Wilks and Mark Stevenson.
1998.
The Grammarof Sense: Using Part-of-speech Tags as a First Step inSemantic Disambiguation.
Journal of Natural Lan-guage Engineering, 4(1):1-9David Yarowsky.
1995.
Unsupervised Word-Sense Dis-ambiguation Rivaling Supervised Methods.Proceedings of the 33rd Meeting of the Associationfor Computational Linguistics (ACL-05), Cambridge,MA, pages 189-196.48
