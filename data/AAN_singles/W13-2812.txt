Proceedings of the Second Workshop on Hybrid Approaches to Translation, pages 82?87,Sofia, Bulgaria, August 8, 2013. c?2013 Association for Computational LinguisticsExperiments with POS-based restructuring and alignment-based re-ordering for statistical machine translationShuo Li, Derek F. Wong and Lidia S. ChaoDepartment of Computer and Information ScienceUniversity of Macau, Macau S.A.R., China.leevis1987@gmail.com, {derekfw, lidiasc}@umac.moAbstractThis paper presents the methods which arebased on the part-of-speech (POS) and autoalignment information to improve the qualityof machine translation result and the wordalignment.
We utilize different types of POStag to restructure source sentences and use analignment-based reordering method to im-prove the alignment.
After applying the reor-dering method, we use two phrase tables in thedecoding part to keep the translation perfor-mance.
Our experiments on Korean-Chineseshow that our methods can improve the align-ment and translation results.
Since the pro-posed approach reduces the size of the phrasetable, multi-tables are considered.
The combi-nation of all these methods together would getthe best translation result.1 IntroductionTranslating between two morphological differentlanguages is more difficult in the descriptions byKoehn (2005).
In Statistical Machine Translation(SMT) system, the surface word in a morpholog-ically poor language is difficult to be generatedfrom a morphologically richer language.
Takethe example of Korean and Chinese, their mor-phologies are different from European languages.Korean is a kind of subject-object-verb (SOV)language while Chinese is subject-verb-object(SVO) language which is a little similar to Eng-lish.
This leads to a problem of word order: de-spite the automatic word alignment tool GIZA++(Och and Ney, 2003) is widely applied, there arestill many generated misaligned language pairsamong these two languages.In Korean, a functional word may have differ-ent morphologies under different conditions.
Theverb and adjective usually end with suffixes in asentence to represent different meanings (Li et al2012).
On the other hand, alignment mistakes areoften generated when many Korean words withdifferent morphologies are aligned with the sameChinese tokens in Korean-Chinese translation.We applied a simple but efficient approach byutilizing different part-of-speech (POS) infor-mation to restructure Korean, after restructuring,many Korean words share the same Chinesemeaning with different morphologies can be re-stored to their original forms.
In particular, weexpect to reduce the problem of misalignmentdue to the verb and adjective variations.
Besidesword restructuring, an alignment?based wordreordering method which would improve thealignment result indirectly was applied in ourexperiment.
This method is simple but effectiveand language-independent by modifying somealignment files.
The lack of the off-the-shelf Ko-rean-Chinese corpus is also an important prob-lem.
Most of these corpora are not open sourcefor users, so it is hard for people applying Kore-an-Chinese corpus in the experiments like Euro-parl (Koehn, 2005), we built a small size corpusby ourselves in a short time to do the experi-ments based on the proposed methods.
A script isdeveloped for crawling parallel corpus of somespecific websites.In this paper, section 2 will review previousrelated works.
In section 3, the POS-based re-structuring method and alignment-based reorder-ing approaches to improve the quality of align-ment will be introduced.
Experimental resultsand the analysis will be given in the followingsection 4.
Finally, section 5 is the conclusion.2 Related workSeveral studies have been proposed to use POStags and morphological information to enrich82languages to tackle some problems in SMT: Li etal.
(2009) proposed an approach focused on us-ing pre-processing and post-processing methods,such as reordering the source sentences in a Chi-nese-Korean phrase-based SMT using syntacticinformation.
Lee et al(2010) transformed thesyntactic relations of Chinese SVO patterns andinserted the corresponding transferred relationsas pseudo words to solve the problem of wordorder.
In order to reduce the morpheme-leveltranslation ambiguity in an English-ChineseSMT system, Wu et al(2008) grouped the mor-phemes into morpheme phrase and used the do-main information for translation candidate selec-tion.
A contraction separation for Spanish in aSpanish-English SMT system was proposed in(Gispert and Mari?o, 2008).
Habash et al(2009)proposed methods to tackle the Arabic enclitics.The experiment in Stymne et al(2008) describedthat using POS information to split the com-pounds in a morphologically rich language(German nouns and adjectives) gave an effect fortranslation output.
Holmqvist et al(2009) alsoreported that using POS-based and morphology-based sequence model would give an improve-ment to the translation quality between Englishand German in WMT09 shared task.In accordance with adding richer informationto the training model, reordering the source lan-guage text to make it more similar to the targetside is confirmed to be another kind of method toimprove the word alignment.
Collins et al(2005)employed the forms of syntactic analysis andhand?written rules on the corpus, Xia andMcCord (2004) extracted the rules from a paral-lel text automatically.
A statistical machine pre-reordering method which addressed the reorder-ing problems as a translation from the sourcesentence to a monotonized source sentence wasproposed by Costa-juss?
and Fonollosa (2006).Visweswariah et al(2011) proposed a methodwhich learns a model that can directly reordersource side text from a small parallel corpus withhigh quality word alignment, but this is hard forpeople to get such a high-quality aligned parallelcorpus.
Ma et al(2007) packed some words to-gether with the help of the existing statisticalword aligner, which simplify the task of automat-ic word alignment by packing consecutive wordstogether.These approaches are integrated with morpho-logical information in the translation and decod-ing model.
Our approach is inspired by the ap-proach proposed by Lee et al2006) which addedPOS information; reordered the word sequencein the source corpus; deleted case particle andfinal ending words in Korean; appended the ex-ternal dictionary in the training step between Ko-rean and English.
In the experiment reported byLi et al(2012), these pre-processing methods onthe Korean to Chinese translation system tookadvantage of POS in their additional factoredtranslation model.
In these studies, POS infor-mation was reported that it would improve thetranslation quality, but their taxonomy of POStag is sole and less.
On the word alignment side,we try to implement the idea proposed byHolmqvist et al(2012), which was reported as asimple, language-independent reordering methodto improve the quality of word alignment.
Buttheir method did not consider the problem thatthe probability and the amount would be changedwhen updated with an improved word alignment.The accuracy of alignment would be improvedbut the size of phrase-table would be less thanthe original one because there are more surealignments generated.
The probabilities of wordand phrase also have the same problem.Our works are based on the integration ofthese two methods.
We utilized POS informationand applied a richer taxonomy of POS tags in therestructuring of Korean, applied reorderingmethod on Korean-Chinese, and combined thePOS-based restructuring and alignment-basedreordering together in the experiment.3 POS-based restructuring and align-ment-based reorderingThe POS information is helpful when dealingwith morphologically rich languages.
In themorphological analysis, the Korean POS taggerinvolves the analytical task to identify the stemand suffixes of Korean, followed by assigningcorresponding POS tags to both the morphemesand extracted stems.
As described in Li et al(2012), Korean is considered as a highly aggluti-native language: the verbs, adjectives and ad-verbs are able to attach with affixes and particles.We considered that different category of POS tagwould lead to different results of the translation.The more complex of tag would get a better re-sult of alignment and the quality of translation.The method of processing Chinese POS is simi-lar to Korean, which applies a more complexPOS tag category from a Chinese POS tagger.Another simple but effective and language-independent reordering method which83Figure 1.
Different types of POS tag of Koreanimproves the quality of automatic word align-ment is applied on Korean-Chinese.
The methodis implemented by modifying the alignment filein Moses (Koehn et al 2007), which needs tworuns of GIZA++.
After this step, an improvedword alignment is generated potentially.
Then,we combine the restructuring and reordering to-gether to compare the superposed quality ofthese two methods.3.1 POS-based restructuringBecause Korean is a kind of morphologicallyrich language, most of Korean verbs, adjectivesand adverbs can be taken as the compound wordslike Germany.
For example, the negative verb???
??
(do not go)?
should be restored to itsoriginal form ???
(go)?
and the negative verbsuffix ??
??
(do not)?.
Another example isthe future tense verb ????
(will go)?
is thecombination of original stem ??
(go)?
and suf-fix with future tense ???
(will)?.
With the helpof POS tagger, we can restructure the Koreanwith the 22 tags category instead of 9 tags in (Liet al 2012).
Here is an example of Korean re-structuring in Figure 1, POS tagger can be de-tected the compound word and analyze its com-bination (tagged with ?+?).
The taxonomy with22 tags is more specific than 9 tags, when tag-ging a noun, 22 tags will use NC (normal noun)instead of N (noun, pronoun, numeral) in 9 tags.When dealing with the compound verb ????
(in order to avoid)?, ???
(avoid) +???
ismore reasonable than ???+?
?, because????
represents ?in order to?
in correspondingChinese grammar.
Then the tags were removedand restructured to a new sentence.
After restruc-turing, the length of original sentence increasedfrom 5 to 9 (9 tags) and 10 (22 tags).
Based onprevious relative simple tags, more complex tax-onomy gives a deeper analysis of the sentencewhich would influence the alignment and thelexical possibility between the source and targetlanguage.3.2 Alignment-based reorderingThe aim of utilizing the alignment information isto make the order in source text same as the tar-get text.
It is believed that statistical word align-ment methods perform better on translation withsimilar word orders.The method needs two runs of word alignment,in the first run of GIZA++: the alignment infor-mation is acquired based on the original order.Then the source text is reordered by the order ofthe target text based on the information in thefirst alignment.
Next, the reordered source textand the original target text are applied on thesecond run of GIZA++, which means this newparallel corpus includes the word with more sim-ilar order than before.
After this step, a newalignment file would be generated, which coverspotential improved word alignment with the re-ordered source language.
Finally, the order ofsource text in the new alignment file is restoredin its original order but kept with its new align-ment information.Figure 2.
The alignmentThe algorithm processes the corpus and thealignment results in a single direction: sourceside (Holmqvist et al 2012).
As an example, inthe Korean-Chinese single direction in Figure 2,each Korean word aligns with the correspondingChinese word, but Chinese is different.
There arecross alignments between ???
?, ????,????
?, ????
?, ????
and ???
?, ???,????
????
????
???
??
?.9 tags:???
?/N ?
?/N+?/X+?/E ???
?/N ?
?/N+?/J ?
?/P+?/E ./S22 tags:???
?/NC ?
?/NC+?/XS+?/EC ???
?/NC ?
?/NC+?/JC ??/PV+?
?/EC ./SF9 tags deleted:????
??
?
?
????
??
?
??
?
.22 tags deleted:????
??
?
?
????
??
?
??
??
.First alignment:Bill?
??
????
??
??
???
???
????
1?
2??
3 6 7 8 ??
null ??
null ?
4??
5(Bill is very quiet, try to encourage him to speak)Second alignment (reordered):Bill?
??
????
???
???
??
??
????
1?
2??
3 4 ??
5 6 ??
null ?
7??
884????.
Moreover, the alignment of these wordsis not totally correct.Before the second run of GIZA++, the originalKorean is reordered to the alignment of the Chi-nese side, so a new Korean sentence is generatedby the Chinese order.
After the second alignment,in Figure 2, there are no cross points and the ad-ditional correct alignment between ?????,????
and ????
is generated, the misalign-ment is decreased.Figure 3.
The improved alignmentIn Figure 3, the new alignment information(new) is kept in the restored file.
The crossingalignment still exists but it is more correct thanthe previous one (old).
Based on this alignment,the establishment of word alignment, the estima-tion of lexical translation table and the extractionof phrase table are changed.We assume that after applying our method, thesize of the extracted words would increase be-cause more alignments are generated at the endof the second run of GIZA++.
Another assump-tion is that the size of the phrase table would de-crease if two languages share such a differentword order, because additional alignments wouldresult in some cross alignments but the phraseextraction algorithm could not extract them.Based on two assumptions, we utilize multiplemodels in the decoding stage.
This approach wasproposed in (Koehn and Schroeder, 2007; Axel-rod et al 2011) which passes phrase and reor-dering tables in parallel.
We used our modifiedtables (small size) as the main tables, and thebaseline tables (big size) as the additional tablewhen decoding.
This can guarantee that if aphrase in testing sentence does not occur in themodified tables, the decoder would find thephrase in the original table.
This method is effec-tive in avoiding translation mistakes if our meth-od harms the result.4 Experimental resultsWe apply our methods on Korean-Chinesephrase-based statistical machine translation sys-tems.
The system is built based on Moses, andour reordering method is applied at the secondstep among the nine steps during the training inMoses.
An additional combination of the POS-based restructuring and alignment-based reorder-ing is considered in our experiment.4.1 Corpus and system informationThe Korean-Chinese (KOR-CHN) corpus iscrawled from the Internet by our script1 and welimited the length of sentence to be under 25words.
We use 990 sentences as the testing cor-pus.
On the other hand, we use a monolingualcorpus of 600k Chinese sentences to build a Chi-nese 3-gram language model.
ICTCLAS 2 is anopen source Chinese segmenter applied to delim-iter the word boundaries and label with properPOS tags, while the Korean text is processed bythe Korean POS tagger, HanNanum 3.
Table 1shows the average information of each corpus.All the experiment was trained without tuning.Token Avg.LengthSentenceCHN 664,290 7.36 90,237KOR 539,903 5.98KOR (9) 969,445 10.74KOR (22) 1,010,117 11.19Table 1.
Summary of training corpora4.2 Korean-Chinese machine translationThe Korean-Chinese translation system containsa reordering model in the translation model.
Thereordering model is trained as the default settingfrom the training corpus itself.
The ?grow-diag-final-and?
symmetrization heuristic is applied intwo directions word alignment.
As described inthe previous section, we restructured the Koreanby POS tagger and applied our reordering ap-proach to the translation system.
Since the re-structured Korean can be considered as a newcorpus, it could be applied to our reorderingmethod.According to the study of Holmqvist et al(2012), when dealing with the morphologicallydifferent language pair, reordering the morpho-logically richer side performs better.
In the ex-periments, Korean was reordered and the exper-imental result is shown in Table 2.From the results, applying more POS tags onthe morphological analysis of Korean got a betterperformance and our reordering method im-1 http://nlp2ct.sftw.umac.mo/views/tools/WebpageCrawler2 http://ictclas.nlpir.org/3 http://semanticweb.kaist.ac.kr/home/index.php/HanNanumBill?
??
????
??
??
???
???
????
1?
2??
3 6 ??
7 8 ??
null ?
4??
5 (new)??
1?
2??
3 6 7 8 ??
null ??
null ?
4??
5  (old)85proved the translation result from 14.98 to 15.50in BLEU (Papineni et al 2002).
The combina-tion of POS and reordering methods based on themultiple phrase tables and reordering tables gotthe best performance with BLEU score 17.35.Corpus KOR-CHNBLEUBaseline 14.98POS-based (9 tags) 16.61POS-based (22 tags) 16.92Alignment-based 15.50POS (9 tags) + Alignment 16.71POS (22 tags) + Alignment 17.03POS (22 tags) + Alignment + two tables 17.35Table 2.
The translation results4.3 Analysis and discussionAfter the modification of the alignment file, thechanges of size of the lexical file and the tables(phrase and reordering) file are shown in Table 3.Tables KOR-CHNbaselineKOR-CHNmodifiedWord 12.39 MB 12.52 MBPhrase 19.41 MB 19.04 MBReordering 10.01 MB 9.83 MBTable 3.
The size changes of the word andphrase tablesFrom the table we found that the lexical ex-traction is bigger than the original system, butthe size of phrase tables and the reordering tablesdecreased slightly.
The result of these changesshows that our assumption is reasonable: ourmethod can improve the quality of automaticalignment, but the phrase extracted from the cor-pus would decrease.
The more word alignmentpoints were generated by using our method, themore words would be extracted.
But this willbring some cross alignments when dealing withtwo morphological different languages.5 ConclusionIn this paper, we presented some pre-processing methods to deal with Korean, whichis a morphological rich language.
POS-basedrestructuring restores most of the Korean verbs,adjectives and adverbs to their original format.
Itis shown that the POS tag set with a richer tax-onomy gives a higher translation result.
Moreo-ver, two runs of automatic alignment informationgot better results on the morphologically richerside.
All of these methods can be combined to-gether and improve the final translation.
Finally,using two tables instead of one modified table inthe decoding part will guarantee the translationquality if the reordering model harms the transla-tion result.AcknowledgmentsThis work is partially supported by the ResearchCommittee of University of Macau, and Scienceand Technology Development Fund of Macauunder the grants RG060/09-10S/CS/FST, and057/2009/A2.ReferencesAmittai Axelrod, Xiaodong He, and Jianfeng Gao.2011.
Domain adaptation via pseudo in-domain da-ta selection.
In Proceedings of the Conferenceon Empirical Methods in Natural LanguageProcessing.
pages 355?362, Edinburgh, Scotland,UK.Michael Collins, Philipp Koehn, and Ivona Kucerov?.2005.
Clause restructuring for statistical machinetranslation.
In Proceedings of the 43rd AnnualMeeting on Association for ComputationalLinguistics.
pages 531?540, Ann Arbor, Michigan.Marta Ruiz Costa-juss?
and Jos?
A. R. Fonollosa.2006.
Statistical machine reordering.
In Proceed-ings of the 2006 Conference on EmpiricalMethods in Natural Language Processing,pages 70?76, Sydney, Australia.Adri?
de Gispert and Jos?
B. Mari?o.
2008.
On theimpact of morphology in English to Spanish statis-tical MT.
Speech Communication.
Pages50:1034?1046.Maria Holmqvist, Sara Stymne, Jody Foo, and LarsAhrenberg.
2009.
Improving alignment for SMTby reordering and augmenting the training corpus.In Proceedings of the Fourth Workshop onStatistical Machine Translation, Athens,Greece.Maria Holmqvist, Sara Stymne, Lars Ahrenberg, andMagnus Merkel.
2012.
Alignment-based reorderingfor SMT.
In Proceedings of the Eight Interna-tional Conference on Language Resources andEvaluation (LREC?12).
pages 3436?3440, Istan-bul, Turkey.86Nizar Habash, Owen Rambow, and Ryan Roth.
2009.MADA+TOKAN: A toolkit for arabic tokenization,diacritization, morphological disambiguation, postagging, stemming and lemmatization.
In Pro-ceedings of the 2nd International Conferenceon Arabic Language Resources and Tools(MEDAR), pages 102?109, Cairo, Egypt.Philipp Koehn.
2005.
Europarl: A parallel corpus forstatistical machine translation.
In Machine Trans-lation Summit X, pages 79-86, Phuket, Thailand.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran,Richard Zens, Chris Dyer, Ondrej Bojar, AlexandraConstantin, and Evan Herbst.
2007.
Moses: Opensource toolkit for statistical machine translation.
InProceedings of the 45th Annual Meeting of theACL, Demonstration session, Prague, CzechRepublic.Philipp Koehn and Josh Schroeder.
2007.
Experi-ments in domain adaptation for statistical machinetranslation.
In Proceedings of the Second Work-shop on Statistical Machine Translation, pag-es 224?227, Prague, Czech Republic.Shuo Li, Derek F. Wong, and Lidia S. Chao.
2012.Korean-Chinese statistical translation model.
InMachine Learning and Cybernetics (ICMLC),2012 International Conference, 2:767-772, Xian,Shannxi, China.Jin-Ji Li, Jungi Kim, Dong-Il Kim, and Jong-HyeokLee.
2009.
Chinese syntactic reordering for ade-quate generation of Korean verbal phrases in Chi-nese-to-Korean SMT.
In Proceedings of theFourth Workshop on Statistical MachineTranslation, pages 190?196, Athens, Greece.Jae-Hee Lee, Seung-Wook Lee, Gumwon Hong,Young-Sook Hwang, Sang-Bum Kim, and Hae-Chang Rim.
2010.
A post-processing approach tostatistical word alignment reflecting alignment ten-dency between part-of-speeches.
In Proceedingsof the 23rd International Conference on Com-putational Linguistics: Posters, pages 623?629,Beijing, China.Jonghoon Lee, Donghyeon Lee, and Gary GeunbaeLee.
2006.
Improving phrase-based Korean-English statistical machine translation.
In Pro-ceedings of the Ninth International Confer-ence on Spoken Language Processing, Pitts-burgh, Pennsylvania.Yanjun Ma, Nicolas Stroppa, and Andy Way.
2007.Bootstrapping word alignment via word packing.In Proceedings of Annual Meeting-associationfor Computational Linguistic, pages 304-311,Prague, Czech Republic.Franz Josef Och and Hermann Ney.
2003.
A system-atic comparison of various statistical alignmentmodels.
Computational Linguistics, 29(1):19?51.Kishore Papineni, Salim Roukos, Todd Ward, andWei-Jing Zhu.
2002.
BLEU: a method for automat-ic evaluation of machine translation.
In Proceed-ings of the 40th Annual Meeting on Associa-tion for Computational Linguistics.
pages 311?318, Philadelphia, USA.Sara Stymne, Maria Holmqvist, and Lars Ahrenberg.2008.
Effects of morphological analysis in transla-tion between German and English.
In Proceedingsof the Third Workshop on Statistical MachineTranslation, pages 135?138, Columbus, Ohio,USA.Karthik Visweswariah, Rajakrishnan Rajkumar,Ankur.
Gandhe, Ananthakrishnan Ramanathan, andJiri Navratil.
2011.
A word reordering model forimproved machine translation.
In Proceedings ofthe Conference on Empirical Methods in Nat-ural Language Processing, pages 486?496, Ed-inburgh, Scotland, UK.Xianchao Wu, Naoaki Okazaki, Takashi Tsunakawa,and Jun?ichi Tsujii.
2008.
Improving English-to-Chinese translation for technical terms using mor-phological information.
In Proceedings of the8th AMTA Conference, Hawaii, USA.Fei Xia and Michael McCord.
2004.
Improving a sta-tistical MT system with automatically learned re-write patterns.
In Proceedings of the 20th Inter-national Conference on Computational Lin-guistics, pages 508, Geneva, Switzerland.87
