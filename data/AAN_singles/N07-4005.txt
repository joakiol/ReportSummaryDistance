NAACL HLT Demonstration Program, pages 9?10,Rochester, New York, USA, April 2007. c?2007 Association for Computational LinguisticsAutomatic Segmentation and Summarization of Meeting SpeechGabriel Murray, Pei-Yun Hsueh, Simon TuckerJonathan Kilgour, Jean Carletta, Johanna Moore, Steve RenalsUniversity of EdinburghEdinburgh, Scotlandfgabriel.murray,p.hsuehg@ed.ac.uk1 IntroductionAMI Meeting Facilitator is a system that per-forms topic segmentation and extractive sum-marisation.
It consists of three components: (1)a segmenter that divides a meeting into a num-ber of locally coherent segments, (2) a summa-rizer that selects the most important utterancesfrom the meeting transcripts.
and (3) a com-pression component that removes the less im-portant words from each utterance based on thedegree of compression the user specied.
Thegoal of the AMI Meeting Facilitator is two-fold:rst, we want to provide sucient visual aids forusers to interpret what is going on in a recordedmeeting; second, we want to support the devel-opment of downstream information retrieval andinformation extraction modules with the infor-mation about the topics and summaries in meet-ing segments.2 Component Description2.1 SegmentationThe AMI Meeting Segmenter is trained using aset of 50 meetings that are seperate from the in-put meeting.
We rst extract features from theaudio and video recording of the input meetingin order to train the Maximum Entropy (Max-Ent) models for classifying topic boundaries andnon-topic boundaries.
Then we test each utter-ance in the input meeting on the Segmenter tosee if it is a topic boundary or not.
The featureswe use include the following ve categories: (1)Conversational Feature: These include a setof seven conversational features, including theamount of overlapping speech, the amount ofsilence between speaker segments, the level ofsimilarity of speaker activity, the number of cuewords, and the predictions of LCSEG (i.e., thelexical cohesion statistics, the estimated poste-rior probability, the predicted class).
(2) Lex-ical Feature: Each spurt is represented as avector space of uni-grams, wherein a vector is 1or 0 depending on whether the cue word appearsin the spurt.
(3) Prosodic Feature: Theseinclude dialogue-act (DA) rate-of-speech, max-imum F0 of the DA, mean energy of the DA,amount of silence in the DA, precedent and sub-sequent pauses, and duration of the DA.
(4)Motion Feature: These include the averagemagnitude of speaker movements, which is mea-sured by the number of pixels changed, over theframes of 40 ms within the spurt.
(5) Contex-tual Feature: These include the dialogue acttypes and the speaker role (e.g., project man-ager, marketing expert).
In the dialogue act an-notations, each dialogue act is classied as oneof the 15 types.2.2 SummarizationThe AMI summarizer is trained using a set of98 scenario meetings.
We train a support vec-tor machine (SVM) on these meetings, using 26features relating to the following categories: (1)Prosodic Features: These include dialogue-act (DA) rate-of-speech, maximum F0 of theDA, mean energy of the DA, amount of silencein the DA, precedent and subsequent pauses,9and duration of the DA.
(2) Speaker Fea-tures: These features relate to how dominantthe speaker is in the meeting as a whole, andthey include percentage of the total dialogueacts which each speaker utters, percentage oftotal words which speaker utters, and amountof time in meeting that each person is speak-ing.
(3) Structural Features: These featuresinclude the DA position in the meeting, and theDA position in the speaker's turn.
(4) TermWeighting Features: We use two types ofterm weighting: tf.idf, which is based on wordsthat are frequent in the meeting but rare acrossa set of other meetings or documents, and a sec-ond weighting feature which relates to how wordusage varies between the four meeting partici-pants.After training the SVM, we test on each meet-ing of the 20 meeting test set in turn, rankingthe dialogue acts from most probable to leastprobable in terms of being extract-worthy.
Sucha ranking allows the user to create a summaryof whatever length she desires.2.3 CompressionEach dialogue act has its constituent wordsscored using tf.idf, and as the user compressesthe meeting to a greater degree the browsergradually removes the less important words fromeach dialogue act, leaving only the most infor-mative material of the meeting.3 Related WorkPrevious work has explored the eect of lexi-cal cohesion and conversational features on char-acterizing topic boundaries, following Galley etal.(2003).
In previous work, we have also studiedthe problem of predicting topic boundaries atdierent levels of granularity and showed that asupervised classication approach performs bet-ter on predicting a coarser level of topic segmen-tation (Hsueh et al, 2006).The amount of work being done on speechsummarization has accelerated in recent years.Maskey and Hirschberg(September 2005) haveexplored speech summarization in the domainof Broadcast News data, nding that combin-ing prosodic, lexical and structural features yieldthe best results.
On the ICSI meeting corpus,Murray et al(September 2005) compared apply-ing text summarization approaches to feature-based approaches including prosodic features,while Galley(2006) used skip-chain ConditionalRandom Fields to model pragmatic dependen-cies between meeting utterances, and rankedmeeting dialogue acts using a combination orprosodic, lexical, discourse and structural fea-tures.4 acknowledgementThis work was supported by the EuropeanUnion 6th FWP IST Integrated Project AMI(Augmented Multi- party Interaction, FP6-506811)ReferencesM.
Galley, K. McKeown, E. Fosler-Lussier, andH.
Jing.
2003.
Discourse segmentation of multi-party conversation.
In Proceedings of the 41st An-nual Meeting of the Association for ComputationalLinguistics.M.
Galley.
2006.
A skip-chain conditional ran-dom eld for ranking meeting utterances by im-portance.
In Proceedings of EMNLP-06, Sydney,Australia.P.
Hsueh, J. Moore, and S. Renals.
2006.
Automaticsegmentation of multiparty dialogue.
In the Pro-ceedings of the 11th Conference of the EuropeanChapter of the Association for Computational Lin-guistics.S.
Maskey and J. Hirschberg.
September 2005.
Com-paring lexial, acoustic/prosodic, discourse andstructural features for speech summarization.
InProceedings of the 9th European Conference onSpeech Communication and Technology, Lisbon,Portugal.G.
Murray, S. Renals, and J. Carletta.
Septem-ber 2005.
Extractive summarization of meetingrecordings.
In Proceedings of the 9th EuropeanConference on Speech Communication and Tech-nology, Lisbon, Portugal.10
