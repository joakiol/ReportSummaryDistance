Proceedings of the UCNLG+Eval: Language Generation and Evaluation Workshop, pages 12?22,Edinburgh, Scotland, UK, July 31, 2011. c?2011 Association for Computational LinguisticsGRE3D7: A Corpus of Distinguishing Descriptionsfor Objects in Visual ScenesJette Viethen1,2jette.viethen@mq.edu.au1TiCCUniversity of TilburgTilburg, The NetherlandsRobert Dale2robert.dale@mq.edu.au2Centre for Language TechnologyMacquarie UniversitySydney, AustraliaAbstractRecent years have seen a trend towards em-pirically motivated and more data-driven ap-proaches in the field of referring expressiongeneration (REG).
Much of this work has fo-cussed on initial reference to objects in visualscenes.
While this scenario of use is one ofthe strongest contenders for real-world appli-cations of referring expression generation, ex-isting data sets still only embody very sim-ple stimulus scenes.
To move this researchforward, we require data sets built around in-creasingly complex scenes, and we need muchlarger data sets to accommodate their higherdimensionality.
To control the complexity,we also need to adopt a hypothesis-driven ap-proach to scene design.
In this paper, we de-scribe GRE3D7, the largest corpus of human-produced distinguishing descriptions availableto date, discuss the hypotheses that underlie itsdesign, and offer a number of analyses of the4480 descriptions it contains.1 IntroductionWhenever we engage in any form of discourse weneed to find a way to describe to our readers orlisteners the entities that we are talking or writingabout.
This act of referring to real-world entities isone of the central tasks in human language produc-tion.
Of course, it is also central when a machineis charged with the task of generating natural lan-guage, which makes referring expression generation(REG) an important subtask in any natural languagegeneration (NLG) system.It is therefore not surprising that REG has attracteda great deal of attention from the NLG communityover the past three decades.
A key factor that hasled to the popularity of REG is the widespread agree-ment that the central task involved is content selec-tion: choosing those attributes of a target referentthat best distinguish it from other distractor enti-ties around it (Dale and Reiter, 1995; van Deemter,2000; Gardent, 2002; Krahmer et al, 2003; Ho-racek, 2003; van der Sluis, 2005; Kelleher and Krui-jff, 2006; Gatt, 2007; Viethen and Dale, 2008).Recent work in particular has concentrated on thedevelopment of algorithms concerned with the gen-eration of context-free identifying descriptions ofobjects, as emphasised by three shared-task evalu-ation competitions (STECs) targeting this particularproblem (Belz and Gatt, 2007; Gatt et al, 2008; Gattet al, 2009).
Referring expressions of this kind areoften referred to as distinguishing descriptions.
Weare still far from a full understanding of how suchdescriptions should best be generated.
Much workremains to be done before many issues, such as, forexample, the generation of relational descriptionsand over-specified descriptions or the number of thesurrounding objects to be taken into account in vi-sual settings, can be considered resolved.Although many authors have explicitly or implic-itly acknowledged the importance of generating re-ferring expressions that sound natural (Dale, 1989;Dale and Reiter, 1995; Gardent et al, 2004; Ho-racek, 2004; van der Sluis and Krahmer, 2004;Kelleher and Kruijff, 2006; Gatt, 2007; Gatt et al,2007), much of the original work in REG was nei-ther developed based on empirical evidence about12Figure 1: The screen showing the first stimulus scene.how humans refer, nor evaluated against human-produced referring expressions.
The REG STECs onthe task of content determination form part of a re-cent trend towards more data-oriented developmentand evaluation of REG algorithms that responds di-rectly to this concern (Gupta and Stent, 2005; Jordanand Walker, 2005; Gatt et al, 2007; Viethen et al,2010; Belz and Gatt, 2007; Gatt et al, 2008; Gatt etal., 2009).However, the existing data sets used in theseexperiments involve very simple and usually ab-stract visual displays of objects rather than coher-ent scenes.
This is a reasonable starting point forbootstrapping research; but if we want to developalgorithms that can be used in real-world scenarios,we ultimately need to work with scenes which aremuch more realistic.
At the same time, given thenon-deterministic nature of choice in the productionof natural language, corpora based on these scenesneed to be very large, and should ideally contain re-ferring expressions from as many different speakersas possible for each target referent in each referentialscenario.
The choice of stimuli and data collectionprocedure should provide a controlled environmentthat allows the isolation of a small number of factorsinfluencing the choices that have to be made by theparticipants, in order to facilitate the replication ofthe same controlled environment for REG algorithmsattempting the same reference task in an evaluationsituation.
The way forward, we believe, is to build asuccession of corpora with incrementally more com-plex scenes.In this paper, we describe the design of a data col-lection experiment for distinguishing descriptionsand give an overview of the resulting corpus, whichis, at 4480 instances, the largest corpus of distin-guishing descriptions developed to date.1 Consis-tent with the common focus on initial reference invisual scenes, we used visual stimuli containing asmall number of simple objects (cubes and balls) ina 3D scene, similar to our much smaller GRE3D3Corpus (Viethen and Dale, 2008), and elicited indi-vidual descriptions in the absence of a complicatingpreceding discourse.
Additionally, we introducedfactors that allow the study of the use of spatial re-lations in referring expressions by creating stimu-lus scenes that encourage the use of relations be-tween objects, but do not require them.
Most ex-isting REG algorithms that can make use spatial rela-tions between objects only do so if no distinguishingdescription can be found otherwise (Dale and Had-dock, 1991; Gardent, 2002; Krahmer and Theune,2002; van der Sluis and Krahmer, 2005; Kelleherand Kruijff, 2006), often based on the argument thatmentioning two entities imposes a higher cognitiveload than referring to only one entity.
We are inter-ested in investigating in how far this behaviour cor-responds to the human use of spatial relations in dis-tinguishing descriptions, as well as testing a numberof concrete hypotheses about the factors that mightlead people to use spatial relations.2 Stimulus DesignThe stimulus scenes used for the GRE3D7 corpusare three-dimensional scenes containing only sim-ple geometric shapes, created in Google SketchUp.Each stimulus scene contains seven objects; theseare grouped into three pairs of two and one singleobject.
The target object is always part of one ofthe pairs and the second object of that pair is whatwe call the landmark object in these scenes.
We at-tempted to place the target?landmark pair as closeto the centre of the scene as possible to encouragethe use of the target?s direct object properties and itsspatial relations to other objects, rather than its over-all location in the scene, as in in the left.
The othertwo object pairs were placed slightly further back to1The corpus is available for download online atwww.clt.mq.edu.au/research/projects/gre3d7.13the left and right of the target?landmark pair, andthe single object was always placed in the far rightor the far left of the scene.
Objects were of one oftwo types (ball or cube) and otherwise distinguish-able by their size and colour.
Each object could beeither large or small, and in each scene we used onlytwo colours.
Figure 1 shows a close-up of one ofthe scenes as presented to the subjects, and Figure 2shows the complete set of stimulus scenes.The design of the stimulus scenes was based on anumber of hypotheses about the factors that mightinfluence people?s use of spatial relations to thelandmark object.
The two main hypotheses are con-cerned with the influence of the landmark object?ssize on its visual salience and the likelihood of thetarget?landmark relation being used in a referringexpression:Hypothesis 1: A large landmark is more salientthan a small one because it occupies more ofthe visual space of a scene.
Therefore, a largelandmark is more likely to be mentioned in a re-ferring expression via its spatial relation to thetarget referent than a small landmark.Hypothesis 2: A landmark that shares its size witha number of other objects in the scene is lesssalient than one that is unique in size.
There-fore, a landmark with unique size is more likelyto be mentioned in a referring expression viaits spatial relation to the target referent than alandmark with a common size.Hypotheses 1 and 2 are concerned with the land-mark?s overall salience in the scene, or what is usu-ally called bottom-up salience in the literature onvisual attention (cf., Yantis, 1998).
A second con-sideration that might influence the use of relations isthe top-down salience of the target and landmark ob-jects, as determined by the task the participants areperforming.
At the time when the landmark?s visualsalience is taken into account, the participants arefocusing their attention on the target object.
As thelandmark is the closest object to the target, it is likelythat the difference or similarity between these twoobjects plays a particularly important role in the de-cision whether to include the relation between themor not.
Two conflicting hypotheses can be formu-lated here:Hypothesis 3: The difference between the land-mark and the target object impacts on the visualsalience of the landmark because it impacts onthe landmark?s overall uniqueness in the scene.Therefore, a landmark that is visually differentfrom the target is more likely to be included in areferring expression than one that looks similarto the target.Hypothesis 4: The more similar the landmark andtarget objects are, the more they appear as onevisual unit rather than two separate objects.
Ifthey are perceived and conceptualised as a vi-sual unit, they are more likely to be mentionedtogether.
Therefore, the more similar the land-mark is to the target, the more likely it is to beincluded in a referring expression.The fifth hypothesis that this experiment is designedto test concerns the preference that participants inpsycholinguistic work have shown for vertical rela-tions over horizontal ones (Lyons, 1977; Bryant etal., 1992; Gapp, 1995; Bryant et al, 2000; Landau,2003; Arts, 2004; Tenbrink, 2004).
To make surethat the landmark is never obscured by the target ob-ject, we use lateral relations rather than frontal onesin this experiment.Hypothesis 5: A target placed on top of a landmarkobject is more likely to be described in termsof its spatial relation to the landmark than a tar-get that is sitting directly adjacent to the left orright of the landmark.We report the results of putting these five hypothe-ses to the test in Section 5.4.
To be able to per-form these tests systematically, the experiment wasdesigned as a 2?2?2?2?2 grid with the followingfive variables:?
LM Size: the landmark is either large or small.[Large/Small]?
LM Size Rare: the size of the landmark is ei-ther a common size in the scene, or it is asrare as possible, and possibly unique.
If it iscommon and the landmark is large, it sharesits size with two of the objects; if it is small,with three.
These numbers are not the samebecause in each scene in which the landmark14size was common, three objects were largeand four small.
In +LM Size Rare scenes thatare also +TG Size = LM Size, the landmarkshares size only with the target.
Only if thescene is ?TG Size = LM Size can the land-mark?s size be truly unique in the scene.
[+/?]?
TG Size = LM Size: target and landmark areeither the same size or different.
[+/?]?
TG Col = LM Col: The target and the land-mark are either of the same colour or differentin colour.
[+/?]?
Relation: The relation between the target andthe landmark is either vertical (the target is ontop of the landmark) or lateral, in which casethe target is placed directly to the left or rightof the landmark.
[Vertical/Lateral]This resulted in 32 experimental conditions.
We cre-ated one stimulus scene for each of these conditions.We then split the stimuli into two trial sets along thefactor TG Size = LM Size, so that this variable be-came a between-participant factor, while the otherfour are within-participant factors.We followed a number of other criteria for the de-sign of the stimulus scenes to ensure maximum ex-perimental control over the factors influencing thecontent of the referring expressions provided by ourparticipants:Target uniqueness: The target was always distin-guishable in terms of its inherent properties alone,2which means that the relation to the landmark orother external properties, such as the location in thescene, were never necessary to fully distinguish thetarget from all other objects in the scene.Landmark uniqueness: As the target, the land-mark was always distinguishable in terms of its in-herent properties alone.Colour balance: Each scene followed one of twocolour schemes: either blue?green or red?yellow.The colour schemes were distributed in a balancedway across the five experimental variables, so that2We use the term inherent property to refer to any propertyof an entity which that entity has independent of the context inwhich it appears.half of the scenes in each condition were blue?greenand the other half red?yellow.
The colour schemewas not expected to have an influence on the con-tent of the referring expressions people produced.
Ineach scene, four objects were of one colour of thecolour scheme for this scene and three had the othercolour.Relation balance: The relation between the targetand the object was never unique.
One of the twoother object pairs in each scene was arranged in thesame spatial relation as the target?landmark pair andthe third pair had the other relation.
However, theobjects in the pair with the same relation were neverof the same types as the target and landmark, so thata description containing the type of the target, a re-lation to the landmark and the type of the landmarkwas always fully distinguishing.Constant landmark and target types: The land-mark was always a cube, in order to avoid sceneswhere the target would have to be balanced on topof a ball, which might look unnatural.
The targetwas always a ball to make sure that the similarity intype between these two objects was always constant.No obscured objects: The objects were placed inthe scenes in such a way that no object occluded anyother.
In particular, as mentioned above, there wereno frontal relations within the object pairs, to avoidlarger objects obscuring smaller ones completely orto a large degree.Figure 2 shows the 2?2?2?2?2 grid of the 32stimuli scenes.
Scenes 1?16, shown on a green back-ground, constitute Trial Set 1, and Scenes 17?32,shown on a blue background, constitute Trial Set 2.3 Procedure and ParticipantsThe data gathering experiment was designed as aself-paced on-line language production study.
Par-ticipants visited a website, where they first saw anintroductory page with a set of simple instructionsand a sample stimulus scene.
Each participant wasassigned one of the two trial sets containing 16 stim-ulus scenes each.
After the instruction page, thescenes were presented consecutively in an order thatwas randomised for every participant.
Below eachscene, the participants had to complete the sentence15TG_Col=/=LM_ColTG_Col=LM_ColTG_Col=/=LM_Col1 135 92 106 141511734 8 1612TG_Col=LM_Col2925211718 22 30263123 27193224 2820LM_SizeCommonLM_SizeRareLM_SizeCommonLM_SizeRareVerticalRelationLateralRelationLM Large LM SmallLM_SizeCommonLM_SizeRareLM_SizeCommonLM_SizeRareLM Large LM SmallTG_Size =/= LM_Size TG_Size = LM_SizeFigure 2: The 32 stimulus scenes for GRE3D7: The left half constitutes Trial Set 1 and the right half is Trial Set 2.Please pick up the .
.
.
in a text box before click-ing a button labelled ?DONE?
to move on to the nextscene, as shown in Figure 1.
The task was to de-scribe the target referent in the scene (marked by agrey arrow) in a way that would enable a friend look-ing at the same scene to pick it out from the otherobjects.
To encourage the use of fully distinguish-ing descriptions, participants were told that they hadonly one chance at describing the object.Before each of the 16 stimulus scenes, the partic-ipants were shown a filler scene, which means eachparticipant had to describe 32 scenes in total.
Themain motivation for using filler scenes was to min-imise the decline in relation use over time, whichmight otherwise happen if participants realised thatrelations were never necessary.The filler scenes were also designed with the in-tention of making the experiment less monotonous,and to stop participants from noticing the strict de-sign features of the stimulus scenes.
In particular,each participant saw: four scenes with twelve ob-jects in all four colours, as opposed to the two-colourschemes; two scenes containing only three objects;and ten further filler scenes which intentionally vio-lated the above design criteria.
The filler scenes foreach participant were chosen such that in eleven ortwelve scenes the target was a cube instead of a ball,in two scenes the landmark was a ball, in four scenesthere was no obvious landmark close to the target, ineight scenes the target was unique (i.e.
it could notbe described by its inherent visual properties alone),in nine or ten scenes the target and landmark sharedtype, and in two or three scenes target and landmarkwere of the same size; for participants who saw TrialSet 2 all stimulus scenes also had a target and land-mark of the same size.The sequence of the 32 scenes that were shown toa particular participant was determined by the fol-lowing three steps:1.
Pick the opposite trial set to the one that the lastparticipant saw and randomise its order.2.
Pick the set of 16 filler scenes to be shown tothis participant and randomise their order.3.
Interleave the two sets so that each stimulusscene is preceded by one filler scene.After having described all 32 scenes in the trial,participants were asked to complete an exit ques-tionnaire, which gave them the option of havingtheir data discarded and asked for their opinion onwhether the task became easier over time and anyother comments they might wish to make.The experiment was started by 318 native Englishspeakers, of which 294 completed all 32 scenes.They were recruited by word of mouth via a widely-circulated call for participation and two electronicmailing lists.3 The participants were predominantlyin their twenties or thirties and mostly university-educated.
A slight majority (54%) were female.None of them reported colour-blindness.
Each re-ferring expression in the corpus is tagged with ananonymous ID number linking it to some simple de-mographic data about the contributing participant,including gender, age, type of English spoken, andfield of education.3The Corpora List and the SIGGEN List.164 Data Filtering and AnnotationOf the 294 participants who completed the experi-ment, five consistently used only type, although thetarget?s type was never fully distinguishing in any ofthe stimulus scenes.
For example, these participantsdescribed the target in Figure 1 simply as ball, whichdoes not distinguish it from the two other balls inthe scene.
We discarded the data of these partici-pants under the assumption that they had not under-stood the instruction that their descriptions were touniquely identify the target.
Two participants?
datawere discarded because they provided text that wasunrelated to the displayed scenes.
Of the remaining287 participants, 140 saw Trial Set 2 and 147 sawTrial Set 1.
The data from seven randomly-chosenparticipants from Trial Set 1 were discarded to bal-ance the corpus in terms of the between-participantfeature TG Size = LM Size.
Each person describedthe 16 scenes contained in either of the trial sets, re-sulting in a corpus of 4480 descriptions in total, with140 descriptions for each scene.
No other corpus ofreferring expressions contains as many descriptionsfor each referential scenario from different speak-ers, which makes this corpus ideal for the study ofspeaker-specific preferences and non-deterministicchoices in content selection.Only five of the 4480 descriptions used the ternaryspatial relation between, and one description men-tioned two distinct spatial relations, one to the in-tended landmark and one to another object.
The re-lation to the third object in these six descriptions wasdisregarded in the analysis presented here.In order to be able to analyse the semantic contentof the referring expressions, we semi-automaticallyannotated the inherent attributes and relations con-tained in each of them.
The attributes annotated are?
type[ball, cube]?
colour[blue, green, red, yellow]?
size[large, small]?
location[right, left, front, top, bottom, centre]?
relation[horizontal, vertical]Each attribute (except relation) is prefixed by eithertg or lm to mark which of the objects it pertainsto.
For example, tg size indicates that the size of thetarget was mentioned.% of total % of all 6004480 relationalattribute count descriptions descriptionstg size 2587 57.8 ?tg colour 4423 98.7 ?tg location 81 1.8 ?relation 600 13.4 ?lm size 327 7.3 54.5lm colour 521 11.6 86.8lm location 10 0.2 1.7Table 1: Attribute counts in GRE3D7In the 83 descriptions containing comparatives,such as Example (1), we ignored the second objectthat the target was being compared to.
In all of thesecases, the target?s colour and type were also men-tioned, which means that in the context of the sim-ple scenes at stake here, Example (1) is semanticallyequivalent to Example (2).
(1) the smaller of the two red balls(2) the small red ballThe question of how to deal with the relative na-ture of size is a separate, non-trivial, issue; see (vanDeemter, 2000; van Deemter, 2006).5 Analysis of the GRE3D7 CorpusIn this section we examine the content of the 4480descriptions that make up the GRE3D7 Corpus.
Wefirst give an overview of the use of the non-relationalattributes, and then proceed to investigate the hy-potheses from Section 2 regarding the use of spatialrelations.The target object?s type was mentioned in eachdescription in the corpus, and each relational de-scription contained the landmark object?s type.
Ta-ble 1 shows the number of descriptions containingeach of the other attributes.5.1 Sparing Use of locationOnly 81 descriptions (1.8%) made reference to thetarget referent?s location in the scene, as in Exam-ple (3); and of the 600 relational descriptions in thecorpus, only ten (1.7%) contained the location of thelandmark, as in Example (4).
(3) the large yellow ball on the left [Scene 9]17(4) the small ball next to the large cube on the lefthand side [Scene 6]There were no descriptions containing bothtg location and lm location.
This might indicatethat participants who used a relation were morelikely to conceptualise the target?landmark pairas a unit with just one location rather than as twoindividual entities.
However, the corpus was notdesigned to investigate this issue and the numbersfor use of location are too low to draw any definiteconclusions.5.2 Abundant Use of colourColour was used in the vast majority of descriptions:98.7% of all descriptions included the colour of thetarget object and 86.8% of the relational descriptionsincluded the colour of the landmark object.
A highnumber of descriptions containing colour could beexpected, as colour was part of the shortest possi-ble minimal description not containing any spatialinformation (we call this the inherent MD of the tar-get) for 20 of the 32 scenes (all but Scenes 17?24and 29?32).
However, the fact that colour was alsoincluded in the majority of the descriptions contain-ing spatial information, in the form of a relation orthe location, confirms previous findings to the effectthat colour is often included in descriptions redun-dantly (Belke and Meyer, 2002; Arts, 2004; Gatt,2007).5.3 Utilitarian Use of sizeThe target?s size was mentioned in 57.8% of all de-scriptions, and the landmark?s size in 54.8% of therelational descriptions.Considering that tg size was part of the inherentMD in only 12 of 32 scenes (37.5%) of the stimu-lus scenes (Scenes 2, 4, 9?12, 18, 20 and 25?28),57.8% seems like a high proportion of descriptionsto be using this attribute.
The use of tg size forscenes where it was part of the inherent MD was at90.2% very high, but this only accounts for just un-der 60% of all the descriptions that contained thisattribute.
The remaining 40% of descriptions con-taining tg size were given for scenes in which thisattribute was not strictly necessary to distinguish thetarget from the other objects.Findings from eye-tracking experiments in psy-cholinguistics have shown that size is rarely used insituations where it adds no discriminatory power tothe referring expression at all, and that it is morelikely to be used to compare to or distinguish fromother objects of the same type, while the same isnot true for colour (Sedivy, 2003; Brown-Schmidtand Tanenhaus, 2006).
Let us therefore consider inparticular the scenes where tg size was not part ofthe inherent MD, and look at the differing utility oftg size in these scenes: 12 of the 20 scenes wheretg size was not necessarily part of the inherent MD(Scenes 1, 3, 5?8, 13?16, 17, 19, 21?24 and 29?32) nonetheless contained another object that sharedthe target?s type (ball) but not its size (Scenes 1, 3,17, 19, 21?24 and 29?32).
In these scenes, tg sizeremains a useful attribute to use, even if tg type isalso included.Based on the psycholinguistic findings mentionedabove, one might expect that the use of tg size ishigher for these scenes because here it helps distin-guish from another object of the same type ratherthan only from objects of a different type.
This hy-pothesis is supported by the data: tg size was usedin 45.6% of the descriptions for scenes where it wasnot part of the inherent MD but there was another ob-ject of same type and different size as the target.
Forscenes where tg size could only distinguish the tar-get from objects of the other type, it was only usedin 27.3% of cases (?2=94.97, df=1, p.01).5.4 The Use of Spatial Relations600 of the 4480 descriptions in the GRE3D7 Cor-pus (13.4%) mentioned a spatial relation.
This wasdespite the fact that spatial information was not re-quired in any of the stimulus scenes.
Most existingapproaches to spatial relations in REG would there-fore never include a relation for any of the stimuli.In this section, we examine the circumstances un-der which the participants of the GRE3D7 data col-lection experiment used the spatial relation betweenthe target object and the intended landmark.
Wewill first examine participant-dependent and tempo-ral factors and then move on to analyse the impactthat the design features of the scenes, described inSection 2, had on the use of relations.General FactorsWe first checked for broad participant-dependentpreferences for or against using relations in the18GRE3D7 Corpus.
The behaviour of participantswho use an exclusive strategy of either always ornever including a relation in their referring expres-sions would be easy to predict in a computationalmodel and does not contribute to any variationacross different scenes.
In order to gain a clear un-derstanding of this variation, we will concentrate onthe data from participants who varied their use ofrelations between scenes.Half of the participants (50.3%) adopted an ex-clusive strategy regarding the use of relations.
How-ever, the split between the two exclusive strategieswas very uneven: 135 participants never used a spa-tial relation and only six used a spatial relation forall 16 stimulus scenes they saw.
In the following, weanalyse the data from the 139 participants who useda relation for some scenes but not for others.
On av-erage, these participants used a relation in 22.7% oftheir descriptions.In (Viethen and Dale, 2008), we observed a ?lazi-ness effect?
whereby participants?
use of relationsdecreased over the course of the experiment.
A num-ber of participants mentioned in the exit interviewthat they noticed over time that relations were neverrequired and stopped using them.
Such a conscious,or semi-conscious, adjustment masks people?s nat-ural propensity to use a relation in a reference situ-ation where they come anew at the task rather thandescribing one object after another.In the GRE3D7 collection experiment, each par-ticipant saw eight filler scenes in which spatial rela-tions were required to distinguish the target.
Thesefiller scenes were included to stop participants fromconsciously noticing that relations were never re-quired in the stimulus scenes.
We hoped that thiswould reduce the laziness effect and thereby pro-duce results that better approximate people?s natu-ral tendency to use a relation.
However, Figure 3shows that, despite the use of these filler scenes, theuse of relations declined over the course of the ex-periment.
Participants who did not follow an exclu-sive strategy clearly used more relations for scenesthey saw early on than for those they saw towardsthe end.
We divided the data set into quartiles inorder to test the statistical significance of this de-cline.
The falling trend was statistically significantat p.01 (?2=55.42, df=3).
However, any tem-poral effect in GRE3D7 should not interfere with!"#$"#%!"#%$"#&!"#&$"#'!"#'$"#(!"#($"#%)*#&+,#'-,#(*.#$*.#/*.#0*.#1*.#2*.#%!*.#%%*.#%&*.#%'*.#%(*.#%$*.#%/*.#!"#$#"%#&'#(')*+,%#&,+'-*./"0$%#&.'1/*&*.
'0&'2*3$#",+'4"5*"'Figure 3: Temporal effect on use of relation!"#$%&!'#"%&!(#"%&!)#*%&()#"%&!!#"%&(*#$%&!+#$%&('#,%&"$#$%&$%&)%&($%&()%&!$%&!
)%&"$%&-./0123& -./0123/4563& 78/0123&9&-./0123& 78/:;<&9&-./:;<& 43<5=;>&!"#$#"%#&''#(')*+,%#&,+'-*./"0$%#&.'3?
@3AB3C&<;D& 3?@3AB3C&E1FE&!
"#$$ $#%&' (%)' (%)' (%)' $#('%#$*#$!'
*#$!'
*#$!'
+'%(,-#$./01023/45/53675726889/54:;4<26;3/63/=>>?
@A./././Figure 4: Effect of design variables on use of relationbetween-stimulus effects, as the stimuli were pre-sented in a randomised order.Influence of Scene Features on Relation UseWe will now turn to the examination of Hypothe-ses 1?5 from Section 2.
Figure 4 shows the impactthat each of the five variables of the scene design hadon the use of relations.
The left (green) columns rep-resent the conditions for which we expected fewerrelations to be used, and the right (yellow) columnsrepresent the conditions for which we expected ahigher use of relations, according to Hypotheses 1?3 and 5.
Hypothesis 4 expected the reverse resultsfor TG Size = LM Size and TG Col = LM Col. Allfactors except LM Size and TG Size = LM Size hada statistically significant effect.Hypotheses 1 and 2, which expected a largelandmark with a rare or unique size to be moresalient and therefore more likely to be used, arenot supported by the data here.
LM Size did nothave a reliable effect (?2=0.16, df=1, p>.6) and19LM Size Rare shows the opposite effect of the onewe expected: a relation to a landmark with a com-mon size is significantly more likely to be includedin a referring expression than one to a landmark witha rare or unique size (?2=56.19, df=1, p.01).
Oncloser inspection, this is likely to be due to a fac-tor that was not explicitly tested or controlled for inthis experiment: the length of the inherent MD of thetarget referent.
In most scenes with a common land-mark size (all but Scenes 1, 3, 17, and 19), all threeinherent attributes (size, colour and type) are neces-sary to distinguish the target from the other objectswithout using locational information.
In all sceneswhere the landmark?s size is rare or unique, colourand type suffice.
In other words, targets which areharder to describe using inherent visual propertiesonly are more likely to be described by a relation toa nearby landmark.Hypotheses 3 and 4 predicted two mutually ex-clusive scenarios based on the assumption that thesimilarity between the target and the landmark ob-ject is of special importance, as the participant?s vi-sual attention is likely to be focussed on these twoobjects.
Hypothesis 3 predicted that a visual dif-ference between the landmark and the target wouldincrease the landmark?s salience and therefore theuse of the spatial relation to this landmark.
Hypoth-esis 4 predicted that high visual similarity betweentarget and landmark might result in these two ob-jects being conceptualised as a unit, which wouldincrease the likelihood of both objects being men-tioned.
The target and landmark object were al-ways of different types, so their similarity dependson their size and their colour, captured in the vari-ables TG Size = LM Size and TG Col = LM Col.TG Size = LM Size did not show a significant ef-fect on the use of relations (?2=2.29, df=1, p>.1).The effect of TG Col = LM Col favours Hypothe-sis 4, as a landmark of the same colour as the targetis more likely to be included in the target?s descrip-tion than one that has a different colour from the tar-get (?2=11.18, df=1, p0.01).The variable Relation had the expected effect: Avertical relation is significantly more likely to beused than a lateral one (?2=69.00, df=1, p.01).This confirms Hypotheses 5.6 ConclusionWe have described the GRE3D7 Corpus, a collec-tion of human-produced distinguishing descriptionsthat is considerably larger than any other existingcorpus.
The collection also uses scenes that are adegree more complex than those found in existingcorpora; these are based on a principled design inorder to provide a measure of control over what canbe learned from the data.
In this paper we have de-scribed the details of the collection experiment andhave presented an analysis of the impacts that the de-sign variables had on the content of the resulting de-scriptions.
The main outcomes of this analysis are:Colour is used in 99% of all descriptions.
It isalso used redundantly in 87% of all relational de-scriptions.
This is in accordance with findings inother corpora and psycholinguistic studies.Size is used when it is distinguishing.
The sizeof the target referent was much more likely to beincluded when it was useful in distinguishing fromanother object in the scene, especially those of thesame type.Just over half of the participants follow an ex-clusive strategy for the use of relations.
A largeproportion of participants (135) opted to never usea relation, while a much smaller number of people(6) used a relation in all of their descriptions.
Theremaining 139 participants are responsible for thevariation in the data, as they used a relation to de-scribe the target in some but not all scenes.The target?landmark relation is used more oftenif it is vertical than if it is lateral.
This confirmsprevious psycholinguistic findings showing that hu-mans prefer vertical relations and prepositions overhorizontal, and in particular lateral, ones.If a landmark shares colour with the target it ismore likely to be used in a referring expression.
Thislends support to the hypothesis that visual similar-ity between target and landmark increases the likeli-hood of the relation between them being used.The data thus sheds additional light on the natureof human-produced descriptions of objects in visualscenes.
It also, of course, provides a rich corpus ofdata that can be readily used to evaluate the perfor-mance of computational algorithms for the genera-tion of referring expressions.20ReferencesAnja Arts.
2004.
Overspecification in Instructive Texts.Ph.D.
thesis, University of Tilburg, The Netherlands.Eva Belke and Antje S. Meyer.
2002.
Tracking thetime course of multidimensional stimulus discrimina-tion: Analysis of viewing patterns and processing timeduring same-different decisions.
European Journal ofCognitive Psychology, 14(2):237?266.Anja Belz and Albert Gatt.
2007.
The Attribute Selectionfor GRE Challenge: Overview and evaluation results.In Proceedings of the Workshop on Using Corpora forNLG: Language Generation and Machine Translation(UCNLG+MT), pages 75?83, Copenhagen, Denmark.Sarah Brown-Schmidt and Michael K. Tanenhaus.
2006.Watching the eyes when talking about size: An investi-gation of message formulation and utterance planning.Journal of Memory and Language, 54:592?609.David J. Bryant, Barbara Tversky, and Nancy Franklin.1992.
Internal and external spatial frameworks rep-resenting described scenes.
Journal of Memory andLanguage, 31:74?98.David J. Bryant, Barbara Tversky, and M. Lanca.2000.
Retrieving spatial relations from observationand memory.
In Emile van der Zee and Urpo Nikanne,editors, Cognitive interfaces: Constraints on linkingcognitive information, pages 94?115.
Oxford Univer-sity Press, Oxford, UK.Robert Dale and Nicholas Haddock.
1991.
Content de-termination in the generation of referring expressions.Computational Intelligence, 7(4):252?265.Robert Dale and Ehud Reiter.
1995.
Computationalinterpretations of the Gricean maxims in the gener-ation of referring expressions.
Cognitive Science,19(2):233?263.Robert Dale.
1989.
Cooking up referring expressions.In Proceedings of the 27th Annual Meeting of the As-sociation for Computational Linguistics, pages 68?75,Vancouver BC, Canada.Klaus-Peter Gapp.
1995.
Angle, distance, shape, andtheir relationship to projective relations.
In Proceed-ings of the 17th Annual Meeting of the Cognitive Sci-ence Society, pages 112?117, Pittsburgh PA, USA.Claire Gardent, He?le`ne Manue?lian, Kristina Striegnitz,and Marilisa Amoia.
2004.
Generating definite de-scriptions: Non incrementality, inference and data.In Thomas Pechmann and Christopher Habel, edi-tors, Multidisciplinary Approaches to Language Pro-duction, pages 53?86.
Walter de Gruyter, Berlin, Ger-many.Claire Gardent.
2002.
Generating minimal definite de-scriptions.
In Proceedings of the 40th Annual Meet-ing of the Association for Computational Linguistics,pages 96?103, Philadelphia PA, USA.Albert Gatt, Ielka van der Sluis, and Kees van Deemter.2007.
Evaluating algorithms for the generation of re-ferring expressions using a balanced corpus.
In Pro-ceedings of the 11th European Workshop on NaturalLanguage Generation, pages 49?56, Schlo?
Dagstuhl,Germany.Albert Gatt, Anja Belz, and Eric Kow.
2008.
The TUNAChallenge 2008: Overview and evaluation results.
InProceedings of the 5th International Conference onNatural Language Generation, pages 198?206, SaltFork OH, USA.Albert Gatt, Anja Belz, and Eric Kow.
2009.
The TUNA-REG Challenge 2009: Overview and evaluation re-sults.
In Proceedings of the 12th European Work-shop on Natural Language Generation, pages 174?182, Athens, Greece.Albert Gatt.
2007.
Generating Coherent Reference toMultiple Entities.
Ph.D. thesis, University of Ab-erdeen, UK.Surabhi Gupta and Amanda Stent.
2005.
Automaticevaluation of referring expression generation usingcorpora.
In Proceedings of the Workshop on UsingCorpora for Natural Language Generation, pages 1?6, Brighton, UK.Helmut Horacek.
2003.
A best-first search algorithmfor generating referring expressions.
In Proceedingsof the 10th Conference of the European Chapter ofthe Association for Computational Linguistics, pages103?106, Budapest, Hungary.Helmut Horacek.
2004.
On referring to sets of objectsnaturally.
In Proceedings of the 3rd International Con-ference on Natural Language Generation, pages 70?79, Brockenhurst, UK.Pamela W. Jordan and Marilyn Walker.
2005.
Learningcontent selection rules for generating object descrip-tions in dialogue.
Journal of Artificial Intelligence Re-search, 24:157?194.John Kelleher and Geert-Jan Kruijff.
2006.
Incremen-tal generation of spatial referring expressions in situ-ated dialog.
In Proceedings of the 21st InternationalConference on Computational Linguistics and the 44thAnnual Meeting of the Association for ComputationalLinguistics, pages 1041?1048, Sydney, Australia.Emiel Krahmer and Marie?t Theune.
2002.
Efficientcontext-sensitive generation of referring expressions.In Kees van Deemter and Rodger Kibble, editors, In-formation Sharing: Reference and Presupposition inLanguage Generation and Interpretation, pages 223?264.
CSLI Publications, Stanford CA, USA.Emiel Krahmer, Sebastiaan van Erk, and Andre?
Verleg.2003.
Graph-based generation of referring expres-sions.
Computational Lingustics, 29(1):53?72.Barbara Landau.
2003.
Axes and direction in spatiallanguage and spatial cognition.
In Emilie van der Zee21and Jon M. Slack, editors, Representing Direction inLanguage and Space, pages 18?38.
Oxford UniversityPress, Oxford, UK.John Lyons.
1977.
Semantics, volume 2.
CambridgeUniversity Press, Cambridge, UK.Julie C. Sedivy.
2003.
Pragmatic versus form-based ac-counts of referential contrast: Evidence for effects ofinformativity expectations.
Journal of Psycholinguis-tic Research, 32(1):3?23.Thora Tenbrink.
2004.
Identifying objects on the basisof spatial contrast: An empirical study.
In ChristianFreksa, Markus Knauff, Bernd Krieg-Brckner, Bern-hard Nebel, and Thomas Barkowsky, editors, Spatialcognition IV: Reasoning, action, interaction, number3343 in Lecture Notes in Computer Science, pages124?146.
Springer, Berlin/Heidelberg, Germany.Kees van Deemter.
2000.
Generating vague descrip-tions.
In Proceedings of the 1st International Con-ference on Natural Language Generation, pages 179?185, Mitzpe Ramon, Israel.Kees van Deemter.
2006.
Generating referring expres-sions that involve gradable properties.
ComputationalLinguistics, 32(2):195?222.Ielka van der Sluis and Emiel Krahmer.
2004.
Evalu-ating multimodal NLG using production experiments.In Proceedings of the 3rd International Conference onLanguage Resources and Evaluation, Lisbon, Portu-gal, 26-28 May.Ielka van der Sluis and Emiel Krahmer.
2005.
Towardsthe generation of overspecified multimodal referringexpressions.
In Proceedings of the Symposium on Di-alogue Modelling and Generation at the 15th AnnualMeeting of the Society for Text and Discourse, Ams-terdam, The Netherlands, 6-9 July.Ielka van der Sluis.
2005.
Multimodal Reference, Stud-ies in Automatic Generation of Multimodal ReferringExpressions.
Ph.D. thesis, Tilburg University, TheNetherlands.Jette Viethen and Robert Dale.
2008.
The use of spatialrelations in referring expression generation.
In Pro-ceedings of the 5th International Conference on Natu-ral Language Generation, pages 59?67, Salt Fork OH,USA.Jette Viethen, Simon Zwarts, Robert Dale, and MarkusGuhe.
2010.
Dialogue reference in a visual domain.In Proceedings of the 7th International Conference onLanguage Resources and Evaluation, Valetta, Malta.Steven Yantis.
1998.
Control of visual attention.
InHarold Pashler, editor, Attention, chapter 6, pages223?256.
Psychology Press, Hove, UK.22
