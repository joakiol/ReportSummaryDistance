Proceedings of SIGDIAL 2010: the 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 233?236,The University of Tokyo, September 24-25, 2010. c?2010 Association for Computational LinguisticsCollaborating on Utterances with a Spoken Dialogue SystemUsing an ISU-based Approach to Incremental Dialogue ManagementOkko Bu?, Timo Baumann, David SchlangenDepartment of LinguisticsUniversity of Potsdam, Germany{okko|timo|das}@ling.uni-potsdam.deAbstractWhen dialogue systems, through theuse of incremental processing, arenot bounded anymore by strict, non-overlapping turn-taking, a whole range ofadditional interactional devices becomesavailable.
We explore the use of one suchdevice, trial intonation.
We elaborateour approach to dialogue managementin incremental systems, based on theInformation-State-Update approach, anddiscuss an implementation in a micro-domain that lends itself to the use ofimmediate feedback, trial intonations andexpansions.
In an overhearer evaluation,the incremental system was judged as sig-nificantly more human-like and reactivethan a non-incremental version.1 IntroductionIn human?human dialogue, most utterances haveonly one speaker.1 However, the shape that anutterance ultimately takes on is often determinednot just by the one speaker, but also by her ad-dressees.
A speaker intending to refer to some-thing may start with a description, monitor whilethey go on whether the description appears to beunderstood sufficiently well, and if not, possiblyextend it, rather than finishing the utterance in theform that was initially planned.
This monitoringwithin the utterance is sometimes even made veryexplicit, as in the following example from (Clark,1996):(1) A: A man called Annegra?
-B: yeah, AllegraA: Allegra, uh, replied and, uh, .
.
.In this example, A makes use of what Sacks andSchegloff (1979) called a try marker, a ?question-ing upward intonational contour, followed by a1Though by far not all; see (Clark, 1996; Purver et al,2009; Poesio and Rieser, 2010).brief pause?.
As discussed by Clark (1996), thisdevice is an efficient solution to the problem posedby uncertainty on the side of the speaker whethera reference is going to be understood, as it checksfor understanding in situ, and lets the conversationpartners collaborate on the utterance that is in pro-duction.Spoken dialogue systems (SDS) typically can-not achieve the close coupling between produc-tion and interpretation that is needed for this towork, as normally the smallest unit on which theyoperate is the full utterance (or, more precisely,the turn).
(For a discussion see e.g.
(Skantze andSchlangen, 2009).)
We present here an approachto managing dialogue in an incremental SDS thatcan handle this phenomenon, explaining how it isimplemented in system (Section 4) that works ina micro-domain (which is described in Section 3).As we will discuss in the next section, this goes be-yond earlier work on incremental SDS, combiningthe production of multimodal feedback (as in (Aistet al, 2007)) with fast interaction in a semanticallymore complex domain (compared to (Skantze andSchlangen, 2009)).2 Related WorkCollaboration on utterances has not often beenmodelled in SDS, as it presupposes fully incre-mental processing, which itself is still somethingof a rarity in such systems.
(There is work oncollaborative reference (DeVault et al, 2005; Hee-man and Hirst, 1995), but that focuses on writteninput, and on collaboration over several utterancesand not within utterances.)
There are two systemsthat are directly relevant here.The system described in (Aist et al, 2007) isable to produce some of the phenomena that weare interested in here.
The set-up is a simplereference game (as we will see, the domain wehave chosen is very similar), where users can re-fer to objects shown on the screen, and the SDSgives continuous feedback about its understand-233ing by performing on-screen actions.
While wedo produce similar non-linguistic behaviour in oursystem, we also go beyond this by producingverbal feedback that responds to the certainty ofthe speaker (expressed by the use of trial intona-tion).
Unfortunately, very little technical detailsare given in that paper, so that we cannot comparethe approaches more fully.Even more closely related is some of our ownprevious work, (Skantze and Schlangen, 2009),where we modeled fast system reactions to deliv-ery of information in installments in a number se-quence dictation domain.
In a small corpus study,we found a very pronounced use of trial or in-stallment intonations, with the first installments ofnumbers being bounded by rising intonation, andthe final installment of a sequence by falling into-nation.
We made use of this fact by letting the sys-tem distinguish these situations based on prosody,and giving it different reaction possibilities (back-channel feedback vs. explicit confirmation).The work reported here is a direct scaling up ofthat work.
For number sequences, the notion ofutterance is somewhat vague, as there are no syn-tactic constraints that help demarcate its bound-aries.
Moreover, there is no semantics (beyondthe individual number) that could pose problems?
the main problem for the speaker in that do-main is ensuring that the signal is correctly identi-fied (as in, the string could be written down), andthe trial intonation is meant to provide opportuni-ties for grounding whether that is the fact.
Here,we want to go beyond that and look at utteranceswhere it is the intended meaning whose recogni-tion the speaker is unsure about (grounding at level3 rather than (just) at level 2 in terms of (Clark,1996).)
This difference leads to differences in thefollow up potential: where in the numbers domain,typical repair follow-ups were repetitions, in se-mantically more complex domains we can expectexpansions or reformulations.3 The Puzzle Micro-DomainTo investigate these issues in a controlled set-ting, we chose a domain that makes complex andpossibly underspecified references likely, and thatalso allows a combination of linguistic and non-linguistic feedback.
In this domain, the user?s goalis to instruct the system to pick up and manipu-late Tetris-like puzzle pieces, which are shown onthe screen.
We recorded human?human as wellas human?
(simulated) machine interactions in thisdomain, and indeed found frequent use of ?pack-aging?
of instructions, and immediate feedback, asin (2) (arrow indicating intonation).
(2) IG-1: The cross in the corner?
...IF-2: ermIG-3: the red one .. yeahIF-4: [moves cursor]IG-5: take that.We chose these as our target phenomena for theimplementation: intra-utterance hesitations, possi-bly with trial intonation (as in line 2);2 immediateexecution of actions (line 4), and their groundingrole as display of understanding (?yeah?
in line 3).The system controls the mouse cursor, e.g.
movingit over pieces once it has a good hypothesis abouta reference; other actions are visualised similarly.4 Implementation4.1 OverviewOur system is realised as a collection of incre-mental processing modules in the InproToolKit(Schlangen et al, 2010), a middle-ware pack-age that implements some of the features of themodel of incremental processing of (Schlangenand Skantze, 2009).
The modules used in the im-plementation will be described briefly below.4.2 ASR, Prosody, Floor Tracker & NLUFor speech recognition, we use Sphinx-4 (Walkeret al, 2004), with our own extensions for incre-mental speech recognition (Baumann et al, 2009),and our own domain-specific acoustic model.
Forthe experiments described here, we used a recog-nition grammar.Another module performs online prosodic anal-ysis, based on pitch change, which is measured insemi-tone per second over the turn-final word, us-ing a modified YIN (de Cheveigne?
and Kawahara,2002).
Based on the slope of the f0 curve, we clas-sify pitch as rising or falling.This information is used by the floor track-ing module, which notifies the dialogue manager(DM) about changes in floor status.
These sta-tus changes are classified by simple rules: silencefollowing rising pitch leads to a timeout signal2Although we chose to label this ?intra-utterance?
here,it doesn?t matter much for our approach whether one consid-ers this example to consist of one or several utterances; whatmatters is that differences in intonation and pragmatic com-pleteness have an effect.234{< a ( 1 action=A=take; 2 prepare(A) ; 3 U),( 4 tile=T ; 5 highlight(T) ; 6 U),( 7 ; 8 execute(A,T) ; 9 U) >< b (10 action=A=del ;11 prepare(A) ;12 U),(13 tile=T ;14 highlight(T) ;15 U),(16 ;17 execute(A,T) ;18 U) >}Figure 1: Example iQUDsent to the DM faster (200ms) than silence afterfalling pitch (500ms).
(Comparable to the rules in(Skantze and Schlangen, 2009).
)Natural language understanding finally is per-formed by a unification-based semantic composer,which builds simple semantic representations outof the lexical entries for the recognised words; anda resolver, which matches these representationsagainst knowledge of the objects in the domain.4.3 Dialogue Manager and Action ManagerThe DM reacts to input from three sides: semanticmaterial coming from the NLU, floor state signalsfrom the floor tracker, and notifications about exe-cution of actions from the action manager.The central element of the information stateused in the dialogue manager is what we call theiQUD (for incremental Question under Discus-sion, as it?s a variant of the QUD of (Ginzburg,1996)).
Figure 1 gives an example.
The iQUDcollects all relevant sub-questions into one struc-ture, which also records what the relevant non-linguistic actions are (RNLAs; more on this in asecond, but see also (Bu?
and Schlangen, 2010),where we?ve sketched this approach before), andwhat the grounding status is of that sub-question.Let?s go through example (2).
The iQUD inFigure 1 represents the state after the system hasasked ?what shall I do now??.
The system an-ticipates two alternative replies, a take request, ora delete request; this is what the specification ofthe slot value in 1 and 10 in the iQUD indicates.Now the user starts to speak and produces what isshown in line 1 in the example.
The floor trackerreacts to the rising pitch and to the silence of ap-propriate length, and notifies the dialogue man-ager.
In the meantime, the DM has received up-dates from the NLU module, has checked for eachupdate whether it is relevant to a sub-question onthe iQUD, and if so, whether it resolves it.
In thissituation, the material was relevant to both 4 and13, but did not resolve it.
This is a precondition forthe continuer-questioning rule, which is triggeredby the signal from the floor tracker.
The systemthen back-channels as in the example, indicatingacoustic understanding (Clark?s level 2), but fail-ure to operate on the understanding (level 3).
(Asan aside, we found that it is far from trivial to findthe right wording for this prompt.
We settled onan ?erm?
with level pitch.
)The user then indeed produces more material,which together with the previously given informa-tion resolves the question.
This is where the RN-LAs come in: when a sub-question is resolved, theDM looks into the field for RNLAs, and if thereare any, puts them up for execution to the actionmanager.
In our case, slots 4 and 13 are bothapplicable, but as they have compatible RNLAs,this does not cause a conflict.
When the actionhas been performed, a new question is accommo-dated (not shown here), which can be paraphrasedas ?was the understanding displayed through thisaction correct??.
This is what allows the user replyin line 3 to be integrated, which otherwise wouldneed to be ignored, or even worse, would confusea dialogue system.
A relevant continuation, on theother hand, would also have resolved the question.We consider this modelling of grounding effectsof actions an important feature of our approach.Similar rules handle other floor tracker events;not elaborated here for reasons of space.
Inour current prototype the rules are hard-coded,but we are preparing a version where rules andinformation-states can be specified externally andare read in by a rule-engine.4.4 Overhearer EvaluationEvaluating the contribution of one of the manymodules in an SDS is notoriously difficult (Walkeret al, 1998).
To be able to focus on evaluation ofthe incremental dialogue strategies and avoid in-terference from ASR problems (and more techni-cal problems; our system is still somewhat frag-ile), we opted for an overhearer evaluation.
(Sucha setting was also used for the test of the incremen-tal system of (Aist et al, 2007).
)We implemented a non-incremental version ofthe system that does not give non-linguistic feed-back during user utterances and has only one,fixed, timeout of 800ms (comparable to typicalsettings in commercial dialogue systems).
Twoof the authors then recorded 30 minutes of inter-actions with the two versions of the system.Wethen identified and discarded ?outlier?
interac-tions, i.e.
those with technical problems, or where235recognition problems were so severe that a non-understanding state was entered repeatedly.
Thesecriteria were meant to be fair to both versionsof the system, and indeed we excluded similarnumbers of failed interactions from both versions(around 10% of interactions in total).We measured the length of interactions in thetwo sets, and found that the interactions in the in-cremental setting were significantly shorter (t-test,p< 0.005).
This was to be expected, of course,as the incremental strategies allow faster reactions(execution time can be folded into the user utter-ance); other outcomes would have been possible,though, if the incremental version had systemati-cally more understanding problems.We then had 8 subjects (university students,not involved in the research) watch and directlyjudge (questionnaire, Likert-scale replies to ques-tions about human-likeness, helpfulness, and re-activity) 34 randomly selected interactions fromeither condition.
Human-likeness and reactivitywere judged significantly higher for the incremen-tal version (Wilcoxon rank-sum test; p< 0.05 andp< 0.005, respectively), while there was no effectfor helpfulness (p= 0.06).5 ConclusionsWe described our incremental micro-domain dia-logue system, which is capable of reacting to sub-tle signals from the user about expected feedback,and is able to produce overlapping non-linguisticactions, modelling their effect as displays of un-derstanding.
Interactions with the system werejudged by overhearers to be more human-like andreactive than with a non-incremental variant.
Weare currently working on extending and generalis-ing our approach to incremental dialogue manage-ment, porting it to other domains.Acknowledgments Funded by an ENP grant from DFG.ReferencesGregory Aist, James Allen, Ellen Campana, Car-los Gomez Gallo, Scott Stoness, Mary Swift, andMichael K. Tanenhaus.
2007.
Incremental under-standing in human-computer dialogue and experi-mental evidence for advantages over nonincremen-tal methods.
In Proceedings of Decalog (Semdial2007), Trento, Italy.Timo Baumann, Michaela Atterer, and DavidSchlangen.
2009.
Assessing and Improving thePerformance of Speech Recognition for IncrementalSystems.
In Proceedings of NAACL-HLT 2009,Boulder, USA.Okko Bu?
and David Schlangen.
2010.
Modellingsub-utterance phenomena in spoken dialogue sys-tems.
In Proceedings of Semdial 2010 (?Pozdial?
),pages 33?41, Poznan, Poland, June.Herbert H. Clark.
1996.
Using Language.
CambridgeUniversity Press, Cambridge.Alain de Cheveigne?
and Hideki Kawahara.
2002.
YIN,a fundamental frequency estimator for speech andmusic.
Journal of the Acoustical Society of America,111(4):1917?1930.David DeVault, Natalia Kariaeva, Anubha Kothari, IrisOved, and Matthew Stone.
2005.
An information-state approach to collaborative reference.
In ShortPapers, ACL 2005, Michigan, USA, June.Jonathan Ginzburg.
1996.
Interrogatives: Ques-tions, facts and dialogue.
In Shalom Lappin, editor,The Handbook of Contemporary Semantic Theory.Blackwell, Oxford.Peter A. Heeman and Graeme Hirst.
1995.
Collabo-rating on referring expressions.
Computational Lin-guistics, 21(3):351?382.Massimo Poesio and Hannes Rieser.
2010.
Comple-tions, coordination, and alignment in dialogue.
Dia-logue and Discourse, 1(1):1?89.Matthew Purver, Christine Howes, Eleni Gre-goromichelaki, and Patrick Healey.
2009.
Splitutterances in dialogue: a corpus study.
In Proceed-ings of the SIGDIAL 2009, pages 262?271, London,UK, September.Harvey Sacks and Emanuel A. Schegloff.
1979.
Twopreferences in the organization of reference to per-sons in conversation and their interaction.
In GeorgePsathas, editor, Everyday Language: Studies in Eth-nomethodology, pages 15?21.
Irvington Publishers,Inc., New York, NY, USA.David Schlangen and Gabriel Skantze.
2009.
A gen-eral, abstract model of incremental dialogue pro-cessing.
In Proceedings of EACL 2009, pages 710?718, Athens, Greece, March.David Schlangen, Timo Baumann, HendrikBuschmeier, Okko Bu?, Stefan Kopp, GabrielSkantze, and Ramin Yaghoubzadeh.
2010.
Middle-ware for incremental processing in conversationalagents.
In Proceedings of SIGDIAL 2010, Tokyo,Japan.Gabriel Skantze and David Schlangen.
2009.
Incre-mental dialogue processing in a micro-domain.
InProceedings of EACL 2009, pages 745?753, Athens,Greece, March.Marilyn A. Walker, Diane J. Litman, Candace A.Kamm, and Alicia Abella.
1998.
Evaluating spokendialogue agents with PARADISE: Two case studies.Computer Speech and Language, 12(3).Willie Walker, Paul Lamere, Philip Kwok, BhikshaRaj, Rita Singh, Evandro Gouvea, Peter Wolf, andJoe Woelfel.
2004.
Sphinx-4: A flexible opensource framework for speech recognition.
Techni-cal report, Sun Microsystems Inc.236
