Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1139?1145,October 25-29, 2014, Doha, Qatar.
c?2014 Association for Computational LinguisticsExploiting Social Relations and Sentiment for Stock PredictionJianfeng Si* Arjun Mukherjee?
Bing Liu?
Sinno Jialin Pan* Qing Li?
Huayi Li?
* Institute for Infocomm Research, Singapore{ thankjeff@gmail.com, jspan@i2r.a-star.edu.sg}?Department of Computer Science, University of Illinois at Chicago, Chicago, IL 60607, USA{ arjun4787@gmail.com, liub@cs.uic.edu, lhymvp@gmail.com}?
Department of Computer Science, City University of Hong Kong, Hong Kong, Chinaqing.li@cityu.edu.hkAbstractIn this paper we first exploit cash-tags (?$?
fol-lowed by stocks?
ticker symbols) in Twitter tobuild a stock network, where nodes are stocksconnected by edges when two stocks co-occurfrequently in tweets.
We then employ a labeledtopic model to jointly model both the tweets andthe network structure to assign each node andeach edge a topic respectively.
This SemanticStock Network (SSN) summarizes discussiontopics about stocks and stock relations.
We fur-ther show that social sentiment about stock(node) topics and stock relationship (edge) topicsare predictive of each stock?s market.
For predic-tion, we propose to regress the topic-sentimenttime-series and the stock?s price time series.
Ex-perimental results demonstrate that topic senti-ments from close neighbors are able to help im-prove the prediction of a stock markedly.1 IntroductionExisting research has shown the usefulness ofpublic sentiment in social media across a widerange of applications.
Several works showed so-cial media as a promising tool for stock marketprediction (Bollen et al., 2011; Ruiz et al., 2012;Si et al., 2013).
However, the semantic relation-ships between stocks have not yet been explored.In this paper, we show that the latent semanticrelations among stocks and the associated socialsentiment can yield a better prediction model.On Twitter, cash-tags (e.g., $aapl for AppleInc.)
are used in a tweet to indicate that the tweettalks about the stocks or some other related in-formation about the companies.
For example,one tweet containing cash-tags: $aapl and $goog(Google Inc.), is ?$AAPL is loosing customers.everybody is buying android phones!
$GOOG?.Such joint mentions directly reflect some kind oflatent relationship between the involved stocks,which motivates us to exploit such informationfor the stock prediction.We propose a notion of Semantic Stock Net-work (SSN) and use it to summarize the latentsemantics of stocks from social discussions.
Toour knowledge, this is the first work that usescash-tags in Twitter for mining stock semanticrelations.
Our stock network is constructed basedon the co-occurrences of cash-tags in tweets.With the SSN, we employ a labeled topic modelto jointly model both the tweets and the networkstructure to assign each node and each edge atopic respectively.
Then, a lexicon-based senti-ment analysis method is used to compute a sen-timent score for each node and each edge topic.To predict each stock?s performance (i.e., theup/down movement of the stock?s closing price),we use the sentiment time-series over the SSNand the price time series in a vector autoregres-sion (VAR) framework.We will show that the neighbor relationships inSSN give very useful insights into the dynamicsof the stock market.
Our experimental resultsdemonstrate that topic sentiments from closeneighbors of a stock can help improve the predic-tion of the stock market markedly.2 Related work2.1 Social Media & Economic IndicesMany algorithms have been proposed to producemeaningful insights from massive social mediadata.
Related works include detecting and sum-marizing events (Weng and Lee, 2011; Weng etal., 2011; Baldwin et al., 2012; Gao et al., 2012)and analyzing sentiments about them (Pang andLee, 2008; Liu, 2012), etc.
Some recent literaturealso used Twitter as a sentiment source for stockmarket prediction (Bollen et al., 2011; Si et al.,2013).
This paper extends beyond the correlationbetween social media and stock market, but fur-1139ther exploits the social relations between stocksfrom the social media context.Topic modeling has been widely used in socialmedia.
Various extensions of the traditional LDAmodel (Blei et al., 2003) has been proposed formodeling social media data (Wang et al., 2011,Jo and Oh, 2011; Liu et al., 2007; Mei et al.,2007; Diao et al., 2012).
Ramage et al.
(2009;2011) presented a partially supervised learningmodel called Labeled LDA to utilize supervisionsignal in topic modeling.
Ma et al.
(2013) pre-dicted the topic popularity based on hash-tags onTwitter in a classification framework.2.2 Financial Networks for StockFinancial network models study the correlationsof stocks in a graph-based view (Tse et al., 2010;Mantegna, 1999; Vandewalle et al., 2001; On-nela et al., 2003; Bonanno et al., 2001).
The usu-al approach is to measure the pairwise correla-tion of stocks?
historical price series and thenconnect the stocks based on correlation strengthsto build a correlation stock network (CSN).However, our approach leverages social mediaposts on stock tickers.
The rationale behind isthat micro-blogging activities have been shownto be highly correlated with the stock market(Ruiz et al., 2012; Mao et al., 2012).
It is moreinformative, granular to incorporate latest devel-opments of the market as reflected in social me-dia instead of relying on stocks?
historical price.3 Semantic Stock Network (SSN)3.1 Construction of SSNWe collected five months (Nov. 2 2012 - Apr.
32013) of English tweets for a set of stocks in theStandard & Poor's 100 list via Twitter?s RESTAPI, using cash-tags as query keywords.
Forpreprocessing, we removed tweets mentioningmore than five continuous stock tickers as suchtweets usually do not convey much meaning forour task.
Finally, we obtained 629,977 tweets intotal.
Table 1 shows the top five most frequentstocks jointly mentioned with Apple Inc. in ourdataset.
Formally, we define the stock network asan undirected graph ?
= {?
, ?}.
The node set?
comprises of stocks, ??,?
?
?
stands for theedge between stock nodes ?
and ?
and the edgeweight is the number of co-occurrences.
On ex-ploring the co-occurrence statistics in pilot stud-ies, we set a minimum weight threshold of 400 tofilter most non-informative edges.
Figure 1demonstrates a segment of the stock networkconstructed from our dataset.3.2 Semantic Topics over the NetworkFigure 2 illustrates our annotation for each tweet.For a tweet, ?
with three cash-tags: {?1, ?2, ?3}, we annotate ?
with the label set, ??
={?1, ?2, ?3, ?1,2, ?1,3, ?2,3}.
(?1,2 is ?aapl_goog?if ?1is ?aapl?
and ?2 is ?goog?).
Then, the topic assignments of words in ?
are constrained to top-ics indexed by its label set, ??.
Given the annota-tions as labels, we use the Labeled LDA model(Ramage et al., 2009) to jointly learn the topicsover nodes and edges.
Labeled-LDA assumesthat the set of topics are the distinct labels in alabeled set of documents, and each label corre-sponds to a unique topic.
Similar to LDA (Blei etal., 2003), Labeled-LDA models each documentas an admixture of latent topics and generateseach word from a chosen topic.
Moreover, La-beled-LDA incorporates supervision by simplyconstraining the model to use only those topicsthat correspond to a document?s observed labelset (Ramage et al., 2009).
For model inference,we use collapsed Gibbs sampling (Bishop, 2006)and the symmetric Dirichlet Priors are set to:?
= 0.01, ?
= 0.01 as suggested in (Ramage etal., 2010).
The Gibbs Sampler is given as:?(??
= ?|???)~?(??,?
)?1+ ??(??,?
)?1+ |???|???
?(?,??)?1+??(?,?
)?1+ |?
|??
(1)where ?(?
?, ?)
is the number of words in ??
as-signed to topic ?, while ?(??,?)
is the marginal-ized sum.
|???
| is the size of label subset of ?
?.Figure 2.
Tweet label design.$goog $amzn $ebay $msft $intc43263 23266 14437 11891 2486Table 1. co-occurrence statistics with $aapl.Figure 1.
An example stock network.1140?
(?, ?)
is the term frequency of word ?
in topic?.
|?
| is the vocabulary size.
The subscript -1 isused to exclude the count assignment of the cur-rent word ??
.
The posterior on the document?s topic distribution {??,?}
and topic?s word distri-bution {??,?}
can be estimated as follows:??,?
=?(??,?
)+ ??(??,?
)+ |???|??(2)??,?
=?(?,??)+??(?,?
)+ |?
|??
(3)Later, parameters {??,?}
will be used to computethe sentiment score for topics.3.3 Leveraging Sentiment over SSN forStock PredictionWe define a lexicon based sentiment score in theform of opinion polarity for each node-indexedand edge-indexed topic as follows:?(?)
= ?
??,?|?
|?=1?(?
), ?(?)
?
[?1,1]  (4)where ?(?)
denotes the opinion polarity of word?.
??,?
is the word probability of ?
in topic ?(Eq.3).
Based on an opinion lexicon ?, ?(?)
=+1 if ?
?
???
?, ?(?)
= -1 if ?
?
????
and ?(?
)= 0 otherwise.
We use the opinion English lexi-con contributed by Hu and Liu (2004).Considering the inherent dynamics of both thestock markets and social sentiment, we organizethe tweets into daily based sub-sets according totheir timestamps to construct one ????
( ?
?
[1, ? ])
for each day.
Then, we apply a LabeledLDA for each ????
and compute the sentiment scores for each ????
?s nodes and edges.
This yields a sentiment time series for the node, ?
,{?(?
)1, ?(?
)2, ?
, ?(?)? }
and for the edge, ??,?,{?(??,?
)1, ?(??,?
)2, ?
, ?(??,?)? }
.
We intro-duce a vector autoregression model (VAR)(Shumway and Stoffer, 2011) by regressing sen-timent time series together with the stock pricetime series to predict the up/down movement ofthe stock?s daily closing price.As usual in time series analysis, the regressionparameters are learned during a training phaseand then are used for forecasting under slidingwindows, i.e., to train in period [?, ?
+ ?]
and topredict on time ?
+ ?
+ 1.
Here the window size?
refers to the number of days in series used inmodel training.
A VAR model for two variables{??}
and {??}
can be written as:??
=  ?
(???????
+ ???????)???
?=1 + ??
(5) where {?}
are white noises, {?}
are model pa-rameters, and ???
notes the time steps of histori-cal information to use.
In our experiment, {??}
is the target stock?s price time series, {??}
is the covariate sentiment/price time series, and we willtry ???
?
?2,3?.
We use the ?dse?
library in Rlanguage to fit our VAR model based on leastsquare regression.4 Experiments4.1 Tweets in Relation to the Stock MarketMicro-blogging activities are well correlatedwith the stock market.
Figure 3 shows us how theTwitter activities response to a report announce-ment of $aapl (Jan. 23 2013).
The report wasmade public soon after the market closed at4:00pm, while the tweets volume rose about twohours earlier and reached the peak at the time ofannouncement, then it arrived the second peak atthe time near the market?s next opening (9:30am).By further accumulating all days?
tweet volumein our dataset as hourly based statistics, we plotthe volume distribution in Figure 4.
Again, wenote that trading activities are well reflected bytweet activities.
The volume starts to rise drasti-cally two or three hours before the market opens,and then reaches a peak at 9:00pm.
It drops dur-ing the lunch time and reaches the second peakaround 2:00pm (after lunch).
Above observationsclearly show that market dynamics are discussedin tweets and the content in tweets?
discussionvery well reflects the fine-grained aspects ofstock market trading, opening and closing.Figure 3.
Tweet activity around $aapl?s earningsreport date on Jan. 23 2013.Figure 4.
Tweet volume distribution in our dataover hours averaged across each day.05001000150020002500Time (date-hour)00.020.040.060.080.10 2 4 6 8 10 12 14 16 18 20 22Time (hourly)11414.2 Stock PredictionThis section demonstrates the effectiveness ofour SSN based approach for stock prediction.We leverage the sentiment time-series on twokinds of topics from SSN: 1).
Node topic fromthe target stock itself, 2).
Neighbor node/edgetopics.
We note that the price correlation stocknetwork (CSN) (e.g., Bonanno et al., 2001; Man-tegna, 1999) also defines neighbor relationshipsbased on the Pearson's correlation coefficient(Tse et al., 2010) between pair of past price se-ries (We get the stock dataset from Yahoo!
Fi-nance, between Nov. 2 2012 and Apr.
3 2013).We build a two variables VAR model to pre-dict the movement of a stock?s daily closingprice.
One variable is the price time series of thetarget stock ({??}
in Eq.5); another is the covari-ate sentiment/price time series ({??}
in Eq.5).
We setup two baselines according to the sourcesof the covariate time series as follows:1.
Covariate price time series from CSN, we trythe price time series from the target stock?sclosest neighbor which takes the maximumhistorical price correlation in CSN.2.
With no covariate time series, we try the tar-get stock?s price only based on the univariateautoregression (AR) model.To summarize, we try different covariate sen-timent (?(. ))
or price (?(. ))
time series fromSSN or CSN together with the target stock?sprice time series (?
?)
to predict the movement ofone day ahead price (???).
The accuracy is com-puted based on the correctness of the predicteddirections as follows, i.e., if the prediction ??
?takes the same direction as the actual price value,we increment #(???????)
by 1, #(?????????)
isthe total number of test.????????
= #(???????)#(?????????)
(6)Figure 5 details the prediction of $aapl on dif-ferent training window sizes of [15, 60] and lags.{?(????
), ?(????
), ?(????
), ?(????_????)}
arefrom SSN, ?(????)
is from CSN ($dell (DellInc.)
takes the maximum price correlation scoreof 0.92 with $aapl), and ?
?
=  ?(????)
is theunivariate AR model, using the target stock?sprice time series only.
Table 2 further summariz-es the performance comparison of different ap-proaches reporting the average (and best) predic-tion accuracies over all time windows and dif-ferent lag settings.
Comparing to the univariateAR model (??
only), we see that the sentimentbased time-series improve performances signifi-cantly.
Among SSN sentiment based approach-es, the ?(????)
helps improve the performancemostly and gets the best accuracy of 0.78 on ??
?2 and training window size of 53.
On average,?(????)
achieves a net gain over ?(????)
in therange of 29% with lag 2 (0.62 = 1.29 x 0.48) and14% with lag 3 (0.57 = 1.14 x 0.50).
Also,?(????_????)
performs better than ?(????)
.The result indicates that $aapl?s stock perfor-mance is highly influenced by its competitor.?(????)
also performs well, but we will see rela-tionships from CSN may not be so reliable.We further summarize some other predictioncases in Table 3 to show how different covariatesentiment sources ( ?(. )
) and price sources(?(. ))
from their closest neighbor nodes helppredict their stocks, which gives consistent con-clusions.
We compute the ?-test for SSN basedprediction accuracies against that of CSN orprice only based approaches among all testingSource Lag = 2 Lag = 3??
only self 0.49(0.57)	 0.47(0.52)CSN:P(.)+??
dell	 0.55(0.64)	 0.57(0.67)SSN:S(.)+?
?aapl 0.48(0.56)	 0.50(0.61)goog 0.62(0.78) 0.57(0.69)aapl_goog 0.55(0.65) 0.52(0.56)msft 0.52(0.65) 0.54(0.61)Table 2.
Performance comparison of the average andbest (in parentheses) prediction accuracies over alltraining window sizes for prediction on $aapl.Figure 5.
Prediction on $aapl.
(x-axis is the trainingwindow size, y-axis is the prediction accuracy)with different covariate sources.0.20.30.40.50.60.70.815 18 21 24 27 30 33 36 39 42 45 48 51 54 57 60(a) Prediction of $aapl on lag 2P* P(dell)+P*S(aapl)+P* S(goog)+P*S(aapl_goog)+P* S(msft)+P*0.20.30.40.50.60.715 18 21 24 27 30 33 36 39 42 45 48 51 54 57 60(b) Prediction of $aapl on lag 3P* P(dell)+P*S(aapl)+P* S(goog)+P*S(aapl_goog)+P* S(msft)+P*1142window sizes ([15, 60]), and find that SSN basedapproaches are significantly (?
-value < 0.001)better than others.We note that tweet volumes of most S&P100stocks are too small for effective model building,as tweets discuss only popular stocks, otherstocks are not included due to their deficienttweet volume.We make the following observations:1.
CSN may find some correlated stock pairslike $ebay and $amzn, $wmt and $tgt, but some-times, it also produces pairs without real-worldrelationships like $tgt and $vz, $qcom and $pfe,etc.
In contrast, SSN is built on large statistics ofhuman recognition in social media, which is like-ly to be more reliable as shown.2.
Sentiment based approaches {?(?)}
consist-ently perform better than all price based ones{?
?, ?
(?)}.
For ?(?)
based predictions, senti-ment discovered from the target stock?s closestneighbors in SSN performs best in general.
Thisempirical finding dovetails with qualitative re-sults in the financial analysis community (Mizik& Jacobson, 2003; Porter, 2008), where compa-nies?
market performances are more likely to beinfluenced by their competitors.
But for Google,its stock market is not so much influenced byother companies (it gets the best prediction accu-racy on ?(????
), i.e., the internal factor).
It canbe explained by Google Inc.?s relatively stablerevenue structure, which is well supported by itsleading position in the search engine market.3.
The business of offline companies like TargetCorp.
($tgt) and Wal-Mart Stores Inc. ($wmt) arehighly affected by online companies like $amzn.Although competition exists between $tag and$wmt, their performances seem to be affectedmore by a third-party like $amzn (In Table 3,???????
predicts the best for both).
Not surpris-ingly, these offline companies have already beentrying to establish their own online stores andmarkets.5 ConclusionThis paper proposed to build a stock networkfrom co-occurrences of ticker symbols in tweets.The properties of SSN reveal some close rela-tionships between involved stocks, which pro-vide good information for predicting stocksbased on social sentiment.
Our experiments showthat SSN is more robust than CSN in capturingthe neighbor relationships, and topic sentimentsfrom close neighbors of a stock significantly im-prove the prediction of the stock market.AcknowledgmentsThis work was supported in part by a grant fromthe National Science Foundation (NSF) undergrant no.
IIS-1111092).Target ?
????
only CSN:  P(.)+??
SSN:  S(.)+?
?googdis(0.96) goog aapl amzn2 0.48(0.59) 0.53(0.60) 0.59(0.65) 0.44(0.53) 0.42(0.49)3 0.46(0.54) 0.53(0.62) 0.56(0.67) 0.50(0.59) 0.43(0.49)amzncsco(0.90) amzn goog msft2 0.48(0.54) 0.48(0.55) 0.47(0.54) 0.57(0.66) 0.60(0.68)3 0.46(0.53) 0.49(0.53) 0.43(0.50) 0.55(0.63) 0.57(0.66)ebayamzn(0.81) ebay amzn goog2 0.49(0.55) 0.51(0.57) 0.44(0.53) 0.57(0.64) 0.56(0.62)3 0.48(0.58) 0.49(0.54) 0.45(0.58) 0.54(0.64) 0.54(0.61)tgtvz(0.88) tgt wmt amzn2 0.43(0.53) 0.43(0.54) 0.46(0.55) 0.49(0.56) 0.49(0.59)3 0.44(0.50) 0.40(0.53) 0.44(0.48) 0.41(0.48) 0.48(0.54)wmttgt(0.86) wmt tgt amzn2 0.53(0.59) 0.53(0.63) 0.52(0.61) 0.52(0.60) 0.60(0.65)3 0.53(0.64) 0.48(0.57) 0.55(0.66) 0.48(0.58) 0.58(0.66)qcompfe(0.88) qcom aapl intc2 0.53(0.6) 0.55(0.63) 0.57(0.61) 0.46(0.54) 0.63(0.70)3 0.54(0.61) 0.48(0.55) 0.56(0.65) 0.51(0.61) 0.61(0.67)Table 3.
Average and best (in parentheses) prediction accuracies (over window sizes of [15,60]) of some other cases with different covariates, cell of dis(0.96) means ?$dis?
takes themaximum price correlation strength of 0.96 with ?$goog?
(similar for others in columnCSN).
The best performances are highlighted in bold.1143ReferencesBaldwin T., Cook P., Han B., Harwood A., Karuna-sekera S., and Moshtaghi M. 2012.
A support plat-form for event detection using social intelligence.In Proceedings of the Demonstrations at the 13thConference of the European Chapter of the Associ-ation for Computational Linguistics (EACL '12).Association for Computational Linguistics,Stroudsburg, PA, USA, 69-72.Bishop C.M.
2006.
Pattern Recognition and MachineLearning.
Springer.Blei D., NG A., and Jordan M. 2003.
Latent Dirichletallocation.
Journal of Machine Learning Research3:993-1022.Bollen J., Mao H., and Zeng X.J.
2011.
Twitter moodpredicts the stock market.
Journal of ComputerScience 2(1):1-8.Bonanno G., Lillo F., and Mantegna R.N.
2001.
High-frequency cross-correlation in a set of stocks,Quantitative Finance, Taylor and Francis Journals,vol.
1(1), 96-104.Cohen J., Cohen P., West S.G., and Aiken L.S.
2003.Applied Multiple Regression/Correlation Analysisfor the Behavioral Sciences, (3rd ed.)
Hillsdale, NJ:Lawrence Erlbaum Associates.Diao Q., Jiang J., Zhu F., and Lim E.P.
2012.
Findingbursty topics from microblogs.
In Proceedings ofthe 50th Annual Meeting of the Association forComputational Linguistics: Long Papers - Volume1 (ACL '12), Vol.
1.
Association for ComputationalLinguistics, Stroudsburg, PA, USA, 536-544.Gao W., Li P., and Darwish K. 2012.
Joint topic mod-eling for event summarization across news and so-cial media streams.
CIKM 2012: 1173-1182Hu M. and Liu B.
2004.
Mining and summarizingcustomer reviews.
In Proceedings of the ACMSIGKDD International Conference on KnowledgeDiscovery & Data Mining, 22-25.
Seattle, Wash-ington (KDD-2004).Jo Y. and Oh A.
2011.
Aspect and sentiment unifica-tion model for online review analysis.
In ACMConference in Web Search and Data Mining(WSDM-2011).Liu B.
2012.
Sentiment analysis and opinion mining.Morgan & Claypool Publishers.Liu Y., Huang X., An A., and Yu X.
2007.
ARSA: asentiment-aware model for predicting sales per-formance using blogs.
In Proceedings of the 30thAnnual International ACM SIGIR Conference onResearch and Development in Information Retriev-al, 607-614.
ACM, New York, NY.Ma Z., Sun A., and Cong G. 2013.
On predicting thepopularity of newly emerging hashtags in Twitter.In Journal of the American Society for InformationScience and Technology, 64(7): 1399-1410 (2013)Mantegna R. 1999.
Hierarchical structure in financialmarkets, The European Physical Journal B - Con-densed Matter and Complex Systems, Springer, vol.11(1), pages 193-197, September.Mao Y., Wei W., Wang B., and Liu B.
2012.
Corre-lating S&P 500 stocks with Twitter data.
In Pro-ceedings of the First ACM International Workshopon Hot Topics on Interdisciplinary Social Net-works Research (HotSocial '12).
ACM, New York,NY, USA, 69-72Mei Q., Ling X., Wondra M., Su H., and Zhai C. 2007.Topic sentiment mixture: modeling facets andopinions in weblogs.
In Proceedings of Interna-tional Conference on World Wide Web (WWW-2007).Mizik N. and Jacobson R. 2003.
Trading off betweenvalue creation and value appropriation: The finan-cial implications of shifts in strategic emphasis.Journal of Marketing, 63-76.Onnela J.P., Chakraborti A., and Kaski K. 2003.
Dy-namics of market correlations: taxonomy and port-folio analysis, Phys.
Rev.
E 68, 056110.Pang B. and Lee L. 2008.
Opinion Mining and Senti-ment Analysis.
Now Publishers Inc.Porter M.E.
2008.
The Five Competitive Forces ThatShape Strategy.HBR, Harvard Business Review.Ramage D., Dumais S.T., and Liebling D. 2010.Characterizing microblogging using latent topicmodels.
In Proceedings of ICWSM 2010.Ramage D., Hall D., Nallapati R., and Manning C.D.2009.
Labeled LDA: A supervised topic model forcredit attribution in multi-labeled corpora.
In Pro-ceedings of the 2009 Conference on EmpiricalMethods in Natural Language Processing (EMNLP2009).Ramage D., Manning C.D., and Dumais S.T.
2011.Partially labeled topic models for interpretable textmining.
In Proceedings of KDD 2011Ruiz E.J., Hristidis V., Castillo C., Gionis A., andJaimes A.
2012.
Correlating financial time serieswith micro-blogging activity.
In Proceedings of thefifth ACM international conference on Web searchand data mining, pp.
513-522.
ACM Press, NY(WSDM-2012).Shumway R.H. and Stoffer D.S.
2011.
Time SeriesAnalysis and Its Applications: With R Examples,3rd ed.Si J., Mukherjee A., Liu B., Li Q., Li H., and Deng X.2013.
Exploiting Topic based Twitter Sentimentfor Stock Prediction.
In Proceedings of the 51st1144Annual Meeting of the Association for Computa-tional Linguistics.
ACL?13, Sofia, Bulgaria, 24-29.Tse C.K., Liu J., and Lau F.C.M.
2010.
A networkperspective of the stock market, Journal of Empiri-cal Finance.
17(4): 659-667.Vandewalle N., Brisbois F., and Tordoir X.
2001.Self-organized critical topology of stock markets,Quantit.
Finan., 1, 372?375.Wang X., Wei F., Liu X., Zhou M., and Zhang M.2011.
Topic sentiment analysis in twitter: a graph-based hashtag sentiment classification approach.CIKM 2011: 1031-1040Weng J. and Lee B.S.
2011.
Event Detection in Twit-ter.
In Proceedings of the International AAAI Con-ference on Weblogs and Social Media 2011.Weng J.Y., Yang C.L., Chen B.N., Wang Y.K., andLin S.D.
2011.
IMASS: An Intelligent MicroblogAnalysis and Summarization System.
ACL (Sys-tem Demonstrations) 2011: 133-138.1145
