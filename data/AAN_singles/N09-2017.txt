Proceedings of NAACL HLT 2009: Short Papers, pages 65?68,Boulder, Colorado, June 2009. c?2009 Association for Computational LinguisticsEvaluation of a System for Noun Concepts Acquisition from Utterancesabout Images (SINCA) Using Daily Conversation DataYuzu UCHIDAGraduate School ofInformation Science and TechnologyHokkaido UniversitySapporo, 060-0814, Japanyuzu@media.eng.hokudai.ac.jpKenji ARAKIGraduate School ofInformation Science and TechnologyHokkaido UniversitySapporo, 060-0814, Japanaraki@media.eng.hokudai.ac.jpAbstractFor a robot working in an open environment,a task-oriented language capability will notbe sufficient.
In order to adapt to the en-vironment, such a robot will have to learnlanguage dynamically.
We developed a Sys-tem for Noun Concepts Acquisition from ut-terances about Images, SINCA in short.
It isa language acquisition system without knowl-edge of grammar and vocabulary, which learnsnoun concepts from user utterances.
Werecorded a video of a child?s daily life tocollect dialogue data that was spoken to andaround him.
The child is a member of a fam-ily consisting of the parents and his sister.
Weevaluated the performance of SINCA usingthe collected data.
In this paper, we describethe algorithms of SINCA and an evaluationexperiment.
We work on Japanese languageacquisition, however our method can easily beadapted to other languages.1 IntroductionThere are several other studies about language ac-quisition systems.
Rogers et al (1997) proposed?Babbette?, which learns language rules from pro-vided examples.
Levinson et al (2005) describetheir research with a robot which acquires languagefrom interaction with the real world.
Kobayashi etal.
(2002) proposed a model for child vocabulary ac-quisition based on an inductive logic programmingframework.
Thompson (1995) presented a lexicalacquisition system that learns a mapping of wordsto their semantic representation from training exam-ples consisting of sentences paired with their seman-tic representations.As mentioned above, researchers are interested inmaking a robot learn language.
Most studies seemto be lacking in the ability to adapt to the real world.In addition, they should be more independent fromlanguage rules.
We believe that it is necessary tosimulate human language ability in order to create acomplete natural language understanding system.As the first step in our research, we devel-oped a System for Noun Concepts Acquisition fromutterances about Images, called SINCA in short(which means ?evolution?
in Japanese) (Uchida etal., 2007).
It is a language acquisition system with-out knowledge of grammar and vocabulary, whichlearns noun concepts from a user?s input.
SINCAuses images as a meaning representation in order toeliminate ambiguity of language.
SINCA can onlyacquire concrete nouns.Currently, SINCA is for Japanese only.
The lan-guage acquisition method of this system is very gen-eral and it is independent of language rules.
SINCAis expected to work successfully using any language.In this paper, we describe the algorithms ofSINCA and an experiment to test what kind of inputwould be appropriate for our system.
We would em-phasize that we prepared a large video data of dailylife of a family with young children.2 The Algorithms of SINCAFigure 1 shows the SINCA user interface.
The situ-ation shown in Fig.1 is that the affection of SINCAis directed to an eraser by the user, and after therecognition process, SINCA asks ?KESHIGOMU?65Figure 1: The SINCA Interface recognizing an eraser(Eraser?).
?We describe SINCA?s process in detail in the fol-lowing subsections.2.1 InputA user input consists of an image paired with a spo-ken utterance.First, a user chooses an object O which he or shelikes and captures an image of it with a web camerawith 300,000 pixels effective sensor resolution.
Theuser has to try to capture the whole object O in theimage.Next, a user imagines an utterance that an infantmight be exposed to when listening to caregiverswhile gazing at the object O in the environment.The user enters the utterance on the keyboard as alinguistic input.
The linguistic input is written inHiragana, which are Japanese phonetic characters,to avoid the linguistic input containing some directmeanings as in the case of Chinese Kanji ideograms.This is also intended to standardize the transcrip-tion.
SINCA does not carry out morphological anal-ysis of the linguistic input, because we believe thatinfant capability for word segmentation is not per-fect (Jusczyk et al, 1999).Figure 2 shows some example inputs.
12.2 Image ProcessingThe ERSP 3.1 Software Development Kit 2 providescutting edge technologies for vision, navigation, and1The Japanese words are written in italics in all followingfigures.2Evolution Robotics, Inc.:ERSP 3.1 Robotic DevelopmentPlatform OEM Software by Evolution RoboticsKore-ha KAPPU-tte iu-n-da-yo.
(This is a thing called a cup.
)KAPPU-ni gyunyu ireyoka.
(Let?s pour some milk into the cup.
)Strings indicated by boldface are labels.Figure 2: Examples of input datasystem development.
ERSP Vision included in theERSP enables a robot or device to recognize 2D and3D objects in real world settings where lighting andplacement are not controlled.
We use the ERSP vi-sion for image processing.
ERSP Vision informs thesystem whether the object in the present input imageappears in the previously input images or not.2.3 Common PartsWhen a user inputs an image of an object O andan utterance, the system extracts all sections of thestring matching section of previously input utter-ances accompanied by the image of the same objectO.
We call these strings common parts.
After thisprocess, the system deals with them as candidatesfor a label for the object O.The system provides every common part with a?basic score?.
The basic score is based on frequencyof appearance and the number of characters, and in-dicates how appropriate as a label the common partis.
The higher the score, the more appropriate thecommon part is.
The basic score is defined as fol-lows:SCORE = ??
FPN ?
?L (1)where, ?
is a coefficient which reduces the basicscore if the common part has appeared with otherobjects than O, F is frequency of appearance of thecommon part with the images of O, PN is the num-ber of use inputs with images of O, and L is the num-ber of characters of the common part.662.4 OutputIf the system finds a common part whose basic scoreexceeds a threshold, it outputs it as text.
The reasonfor doing this is the assumption that there is a highpossibility that such common parts are appropriateas labels.A user evaluates an output by choosing one of thefollowing keywords:?
Good : It is appropriate as a label.?
Almost : It makes some sense but is notproper for the label.?
Bad : It makes no sense.Infants cannot understand these keywords com-pletely, but they can get a sense of some meaningsfrom the tone of an adult?s voice or facial expres-sions.
In our research, we use the keywords as asubstitute for such information.
The system recalcu-lates the basic score based on the keyword chosen bythe user.
Specifically, the system multiplies the basicscore by the coefficient ?
dependent on the keyword.2.5 Acquisition of the Noun ConceptsAfter repeating these processes, if there is a com-mon part whose score is more than 30.0 and whichhas been rated as ?Good?, the system acquires thecommon part as the label for O.2.6 Label Acquisition RulesHumans can use their newfound knowledge to learntheir native language effectively.
This system imi-tates humans?
way with ?label acquisition rules?.A label acquisition rule is like a template, whichenables recursive learning for acquisition of nounconcepts.
The system generates label acquisitionrules after acquisition of a label.
When the systemacquires a string S as a label for an object, the systempicks up the previous linguistic inputs with the im-ages of the object which contain the string S. Then,the system replaces the string S in the linguistic in-puts with a variable ???.
These abstracted sentencesare called label acquisition rules.
An example of thelabel acquisition rules is shown in Fig.3.If the rules match other parts of previoiusly inputstrings, the parts corresponding to the ???
variableare extracted.
The scores of these extracted stringsare then increased.Acquired Label : WAN-CHAN (a doggy)Previous Input : Acchi-ni WAN-CHAN-ga iru-yo.
(There is a doggy over there.
)Label Acquisition Rule : Acchi-ni ?1-ga iru-yo.
(There is ?1 over there.
)Strings indicated by boldface are labels.Figure 3: An example of a label acquisition rule3 Evaluation ExperimentWe carried out an experiment to test what kinds ofinput would be appropriate for SINCA.
This sectiondescribes the experiment.3.1 Experimental ProcedureTwo types of linguistic input data were collectedin two different ways: a questionnaire and a videorecording.
We had SINCA acquire labels for 10 im-ages using the linguistic input data.
The followingare the details about the data collection methods.3.1.1 Questionnaire10 images were printed on the questionnaire, andit asked ?What would you say to a young child ifhe or she pays attention to these objects??.
The re-spondents are allowed to answer with whatever theycome up with.
31 people responded to this question-naire, and 13 of them have children of their own.We collected 324 sentences, and the average moralength of them was 11.0.3.1.2 Video recordingWe recorded a video of a child?s daily life to col-lect dialogue data that was spoken to and aroundhim.
The child is a member of a family consistingof his parents and his sister.The recordings are intended to collect daily con-versation, therefore we did not set any tasks.
Thetotal recording period comprised 125 days and werecorded about 82 hours of video data.
The first au-thor watched about 26 hours of the video data, andwrote parents?
dictation in Hiragana.
We selected353 sentences for linguistic input data that were spo-ken when joint attention interactions between a par-ent and a child were recognized.
On average, theirmora length was 9.8.673.2 Experimental ResultWe input sentences from the collected inputs one ata time until SINCA acquired a noun concept for animage.
SINCA was able to acquire labels for 10 im-ages, with each type of linguistic input.
When weused the questionnaire data, SINCA needed on aver-age 6.2 inputs to acquire one label, and SINCA ac-quired 52 rules through the experiment.
They cover83.8% of the total number of inputs.
When we usedthe video data, SINCA needed on average 5.3 inputsto acquire one label, and SINCA acquired 44 rulesthrough the experiment.
They cover 83.0% of thetotal number of inputs.3.3 ConsiderationsThe experimental results indicate that using videodata makes the acquisition of labels more efficient.There are 3 factors that contribute to this.The first factor is the number of one-word sen-tences.
There are 66 one-word sentences in thevideo data (18.6% of the total).
Therefore, the lengthof the sentences from the video data tends to beshort.The second factor is the lack of particles.
The re-spondents of the questionnaire hardly ever omit par-ticles.
By contrast, of the 53 sentences which wereinput, 23 sentences lack particles (42.6% of the to-tal) in video data.
Spoken language is more likelyto have omitted particles compared with written lan-guage.The third factor is the variety of words.
We ran-domly selected 100 sentences from both sets of lin-guistic input data and checked the words adjacent toa label.
Table 1 shows the number of different wordsthat occur adjacent to a label.
Because the respon-dents of the questionnaire all try to explain some-thing in an image, they use similar expressions.When SINCA uses the video data, it can extractlabels more easily than using the questionnaire databecause of the factors listed above.
This means thatSINCA is well suited for spoken language.
If weassume one application of SINCA is for communi-cation robots, this result is promising.4 Conclusions and Future WorkIn this paper, we described the algorithms ofSINCA.
SINCA can acquire labels for images with-Table 1: Variety of wordsPrevious(WA) following(WB)Video 19 42Questionnaire 15 22Sentence : W1 W2 ... WA label WB ... .out ready-made linguistic resources, lexical infor-mation, or syntactic rules.
Additionally, it targetsimages of real world objects.We collected linguistic input data in two ways.One method is videos of a family?s daily life.
Theother method is a questionnaire.
We had SINCA ac-quire noun concepts using both video and question-naire data.
As a result, we have showed that spokenlanguage is well suited to SINCA?s algorithm for ac-quiring noun concepts.In the next step, we will focus on acquisition ofadjectives.ReferencesJusczyk, P. W. Houston, D. M. and Newsome, M. 1999.The beginnings of word segmentation in english-learning infants.
Cognitive Psychology.
39. pp.159?207.Kobayashi, I. Furukawa, K. Ozaki, T. and Imai, M.2002.
A Computational Model for Children?s Lan-guage Acquisition Using Inductive Logic Program-ming.
Progress in Discovery Science.
2281 pp.140?155.Levinson S. E. Squire, K. Lin, R. S. and McClain, M.2005.
Automatic language acquisition by an au-tonomous robot.
AAAI Spring Symposium on Devel-opmental Robotics.Rogers, P. A. P. and Lefley, M. 1997.
The baby project.Machine Conversations.
ed.
Wilks, Y. Kluwer Aca-demic Publishers.Thompson, C, A.
1997.
Acquisition of a Lexicon fromSemantic Representations of Sentences.
Proceedingsof the 33rd Annual Meeting of the Association forComputational Linguistics.
pp.335?337.Uchida, Y. and Araki, K. 2007.
A System for Acquisitionof Noun Concepts from Utterances for Images Usingthe Label Acquisition Rules.
Springer-Verlag LectureNotes in Artificial Intelligence (LNAI).
pp.798?802.68
