Information Extraction and Semantic ConstraintsRalph Grishman and John SterlingComputer Science DepartmentNew York UniversityNew York, NY 10003, USAgrishman@nyu.eduAbstractWe consider the problem of extracting specifiedtypes of information from natural anguage text.To properly analyze the text, we wish to applysemantic (selectional) constraints whenever possi-ble; however, we cannot expect o have semanticpatterns for all the input we may encounter in realtexts.
We therefore use preference semantics:selecting the analysis which maximizes the numberof semantic patterns matched.
We describe aspecific information extraction task, and report onthe benefits of using preference semantics for thistask.Task and ApproachInformation extraction is the task of extractingspecified types of intonnation from a naturallanguage text - -  for example, information aboutspecific classes of events.
Typically, however, thetext to he processed will contain many types ofevents besides the classes of interest.
The systemdesigner therefore faces a quandary in imposingsemantic (selectional) constraints.
Selectional con-straints could be strictly enforced: a sentenceanalysis is not accepted unless "all relationships arcidentified as semantically valid.
In this case, thedesigner either must encode all the semantic rela-tionships which may occur in the text - -  animpractical if not impossible task - -  or be resignedto losing events of interest occurring in sentenceswhich also contain unexpected semantic relation-ships.
On the other hand, if selectional constraintsare not enforced, sentences containing events ofinterest may be incorrectly analyzed.Several approaches have been suggested to extri-cate ourselves from this quandary.
One approachhas been an analyzer driven by semantic expecta-tions, ignoring intervening text not matching theseexpectations \[1\]; this is robust but can lead to seri-ous en'ors.
Another approach as been to identify"interesting" words and attempt only partial sen-tence parses around those words \[2\].
As an alter-native, we have explored the use of full syntacticanalysis of the input, coupled with preferencesemantics'.
Preference semantics, as introduced byWilks \[3\], penalizes but does not reject analyseswhich violate semantic onstraints; it selects theanalysis with the fewest constraint violations.The task to which we have applied preferencesemantics i that of creating a data base from U SNavy messages describing nawd encounters.
"Paese messages are relatively brief (average length30 words) and are highly telegraphic, with manysentence fragments and frequent run-on sentences.The specific task was to identify live classes ofevents within these messages and, for each event,identify the initiating force (friend or foe) and 8other parameters (agent, object, instrument, loca-tion, time, etc.).
Our and other systems wereported to this domain and evaluated over a periodof 3 months in the spring of 1989 as part of Mes-sage Understanding Conference-II \[4\] (held at theNaval Ocean Systems Center, San Diego, Calilbronia, USA, in June 1989).System DesignThe principal system components are 1o a syntactic analyzer, using an attgmentedcontext-free grammar, which produces a parseand a regularized syntactic structure?
a semantic analyzer, which maps clauses andnominalizations into domain-specific predicates?
reference resolution, which deteirninesreferents for anaphoric and omitted arguments?
data base creation, which maps predicatesdescribing events of interest into data baseentriesi In addition to these principal components, there is asmall semantic rcgularization component (following semanticanalysis), which performs some decomposition andsimplification of semantic forms.
There is also a discourseanalysis component (following reference resolution) whichidentifies possible causal and enabling relations in a message.If reference resolution generates alternative hypotheses, thoseleading to the identification of such relations in the messagewill be preferred.
We found, however, that in our applicationdiscourse analysis made only a minimal contribution tooverallsystem performance.1 355The telegraphic message style is accomodatedexplicitly in the grammar, following the approachof Ma~h and Sager \[5\], by including productionsfor various fragment types in the grammar.
Run-on sentences are also explicitly provided for in thegrammar.
Some inputs can be analyzed either asfull sentences or as fragments; we prefer the full-sentence analysis by associating a penalty (reducedscore) with fragment analyses and using a best-firstsearch algorithm in the parser.
The reference reso-lution component assists in the analysis of frag-ments by attempting to recover omitted butsemantically essential arguments 2 (a similarapproach is taken in \[61).The verbs, nouns, and entity names are organizedinto a domain-specific semantic classificationhierarchy.
Knowledge of the meaningful semanticrelationships i then encoded as a set of patternsfor each noun and verb, indicating the semanticclass of each argument and modifier, and whetherthe argument is required or optional.
Thisknowledge plays a role at two points in theanalysis process.
During parsing it is used tocheck selectional constraints; during semanticanalysis it is used to guide the mapping intodomain predicates.In keeping with the basic tenet of preferencesemantics, we do not require a perfect matchbetween the input and our semantic patterns.Beyond that, however, our approach differs fromWilks', reflecting the difference in our analysisprocedures (we perform a full syntactic analysis,whereas Wilks did not) and in our application.
Inenforcing selectional constraints, we insist that allrequired arguments be present.
We impose a smallpenalty for extraneous arguments and modifiers(phrases in the input which do not match the pat-tern) and a larger penalty for clauses and nounphrases which do not match any pattern at all.These penalties are applied during parsing, and arecombined with the syntactic penalties (for sentencefragments) noted above.
We then use our best-firstparser to seek the analysis with the lowest penalty.In the process of mapping into domain predicates,we ignore these extraneous arguments andmodifiers.These messages contain a wide variety of informa-tion besides the events identified as being of2 Following the terminology of \[6\], arguments whichmust be present in the input text are termed required, while ar-guments which may be absent in the input text but must bepresent in the final logical form are termed essential.interest; it was not feasible to incorporate seman-tic patterns for all these verbs and noun phrases.Rather, we confined ourselves to creating pattemsfor the events and objects of interest, verbs andadjectives with sentential complements ("began to", "unable to "), and a few other high-frequency verbs.
In principle, this would allow usto get correct analyses for sentences or portions ofsentences containing events of interest, whilepreference semantics would allow us to "getthrough" the remaining text.ResultsThe effects of switching from strict selection topreference semantics were dramatic.
The maintraining corpus contained 105 messages with 132events to be identified.
With strict selection, only43 (33%) were correctly identified as to type ofaction and initiating force; with preference seman-tics, this improved to 90 events (68%).
Withfurther heuristics, described in \[7\], our system wasable to correctly identify 101 (77%).Interestingly, the number of incorrect data baseentries 3 generated increased only slightly: from 10with strict selection to 13 with preference seman-tics (and did not increase further with the addi-tional heuristics), while the omission rate, ot'course, went down sharply.
This may be a conse-quence of our conservative semantic interpretationstrategy, which will make use of the semantics ofan embedded structure only if the higher-levelstructure in which it is embedded has been "under-stood" (matched to a pattern).
For example, thiswould avoid the extraction of the information "shipwas sinking" from the phrase "denied that ship wassinking" if we did not have any semantics for"deny".Concluding RemarksLike others who are attempting to construct robusttext analysis ystems (e.g., \[8\]), we believe that thekey lies in the successful integration of a variety ofconstraints: syntactic, semantic, domain, anddiscourse information.
We want these constraintsto be as rich as possible, yet we also recognizethat, because of system limitations and ill-formedinput, each may be violated.
To allow for this, weassociate a penalty with each violation and seek a'best analysis' which minimizes these penalties.We have demonstrated the effectiveness of this3 Event records with an incorrect ype of action or ini-tiating force.356 2approach with regard to semantic onstraints and alimited set of syntactic prel~rences (preferringwhole sentence to fragment analyses).
We arecurrently experimenting with a stochastic grammar(trained on a sample corpus of messages) in orderto provide a richer and systematically derivable setof syntactic preferences.ImplementationThis system is implemented entirely in CommonLisp and has been run on a Symbolics LISPmactfine.AcknowledgementThis research was supported by the DefenseAdvanced Research Projects Agency under Con-tract N00014-85-K-0163 from the Office of NavalResearch.References\[1\] G.F. DeJong, An Overview of the FRUMPSystem.
In W. G. Lenhert and M. H.
Ringle(eds.
), Strategies for Natural Language Pro-cessing.
Lawrence Erlbaum Assoc., Hills-dale, NJ, 1982, pages 149-176.\[2\] David Allport, The TICC: parsing interest-ing text.
Proc.
Second Conf.
Applied NaturalLanguage Processing.
1988, pages 211-218.\[3\] Yorick Wilks, An intclligcnt analyzer andunderstander of English.
Comm.
Assn.Comp.
Mach.
18, 264--274, 1975.\[4\] Beth Sundheim, Plans for a task-orientedevaluation of natural anguage understandingsystems.
Proc.
Speech and NaturalLanguage Workshop, Philadelphia, PA,February, 1989, Morgan Kaufmann, pages197-202.\[5\] Elaine Marsh and Naomi Sager, Analysis andProcessing of Compact Text.
Proc.
COLING82, pages 201-206.\[6\] Martha Palmer, Deborah Dahl, RebeccaSchil'finan, Lynette Hirschman, Marcia Line-barger, and John Dowding, RecoveringImplicit Information.
Proc.
24th Annl.
Meet-ing Assn.
Computational Linguistics, 1986,pages 10-19.\[17\] R. Grishman and J.
Sterling, PreferenceSemantics lbr Message Understanding.Proc.
Speech and Natural LanguageWorkshop, Harwich Port, MA, October,1989, Morgan Kauthaann, pages 71-74.\[8\] Lisa Rau and Paul Jacobs, Integrating Top-down and Bottom-up Strategies in a TextProcessing System.
Proc.
Second Conf.Applied Natural Language Processing, 1988,pages 129-135.3 357
