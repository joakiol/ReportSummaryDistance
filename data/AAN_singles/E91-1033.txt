EXPLOITING CONVERSATIONAL IMPLICATUREFOR GENERATING CONCISE EXPLANATIONSHELMUT HORACEKUniversit~t BielefeldFakultlit f'dr Linguistik und LiteraturwissenschaftPostfach 8640, D-4800 Bielefeld 1, DeutschlandABSTRACTThis paper presents an approach for achievingconciseness in generating explanations, whichis clone by exploiting formal reconstructions ofaspects of the Gricean principle of relevance tosimulate conversational implicature.
By apply-ing contextually motivated inference rules in ananticipation feed-back loop, a set of propo-sitions explicitly representing an explanation'scontent is reduced to a subset which, in theactual context, can still be considered to conveythe message adequately.1.
INTRODUCTIONThe task of providing informative naturallanguage xplanations for illustrating the resultsproduced by decision support systems has beengtven increased attention recently.
The pro-posed methods preferably address tailoring ofexplanations to the needs of their addressees,including, for instance, object descriptions \[8\]and presentation of taxonomic knowledge \[7\].In addition, particular emphasis has been put onreactive xplanation techniques for selecting anappropriate content according to contextualinterpretation \[6\], and on the way of presentingexplanations by taking the information Seekingperson's knowledge into account \[1\].Whereas these approaches attack various issuesimportant for the generation of natural languageexplanations, none of them has focussed on theconciseness of explanations in a broader con-text.
Aiming at the production of natural andconcise texts, we have concentrated our effortson presenting different ypes of knowledge andtheir interrelations because this kind of infor-mation is typically relevant for explanations.We formally reconstruct aspects of the Griceanprinciple of relevance \[3\] and exploit the resultsobtained for creating concise explanations toquestions about solutions proposed by the ex-pert system OFFICE-PLAN \[5\].
This system isable to appropriately assign a set of employeesto a set of rooms in offices, which is guided bya number of constraints expressing variouskinds of the persons" requirements.2.
REPRESENTING DOMAINAND INFERENCE KNOWLEDGETerminological knowledge is represented in asorted type hierarchy, which identifies classesof entities and their relevant subsorts, as well asrelations that may hold between two types ofentities.
Moreover, assertions which refer to thereferential level must be consistent with the on-tology provided by these taxonomic definitions.Inferential knowledge is represented in terms ofrules which express constraints to be satisfiedin the problem solving process.
Rules arerepresented according to the syntax of IRS \[2\],which is loosely based on predicate logic.
Thequantifiers used in our system are all, some,and unique.
The predications contained are re-stricted to be one- or two-place predicationscorresponding to class and relation definitionsintroduced in the taxonomic hierarchy.
In addi-tion, the recta-predicate implies is contained inthe innermost predication of a rule, which con-stitutes the rule's conclusion (see Figure 1).The original representation f an explanation toa certain question consists of a set of propo-sitions (created by the preceeding component inthe generation process \[4\]) which includesinference rules and individual facts that comple-tely identify the reasons behind.
The task isthen to reduce this set of propositions as muchas possible by exploiting a given context so thatthe subset obtained still conveys the same infor-mation - in a partially implicit and more conciseform, but without leading to wrong implica-tions.
The intuition behind this mechanism is asfollows: After having asked a certain expla-nation seeking question the questioner mentallyattempts to build links between entities referredto in the question and facts or rules provided as"explanation'.
Hence, if a regularity valid for aclass of entities is uttered, the person attemptsto find out which of the entities mentioned pre-viously this rule is thought o apply to.i i ,((some r (and (room r) (in r g)))(implies (single-room r))))Figure 1: Inference rule I-Rule 11- 191 -3.
EXPRESS ING CONVERSAT IONALIMPL ICATUREThe reduction of the set of propositions that ori-ginally represents he explanation is performedby exploiting a set of rules which are contex-tually motivated and express conversational im-plicature.
These rules represent formal recon-structions of aspects of the Gricean principle ofrelevance.
They have the same format as therules which constitute the system's inferentialknowledge, but, in addition, they contain meta-predications referring to contextual, conversa-tional, or processing states associated with theindividuals referred to (see Figure 2 below).The rules expressing conversational implicatureallow variables to denote propositions, thoughin an extremely limited sense only: a variable xdenoting a proposition must always be restrict-ed by the predication (newinfo x) so that the eva-luation process can rely on a definite set of en-tities when generating legal instances of x.We have defined three rules that constitute afundamental repertoire for exploiting conversa-tional implicature (see Figure 3).
They expresscontextually motivated inferences of a fact fromanother one, of a fact from an inference rule,and the relevance of an inference rule justifiedby a fact.
Moreover, logical substitution is ap-plied to those domain inference rules which be-come bound to variables of a contextually moti-vated inference rule at some processing stage.The first rule, C-Rule 1, refers to two (sets of)entities el and e2, which have been both addres-sed (expressed by topic) in the question andshare the most general superclass (topclass).
If, , , , ,  , ,  J , ,Predicate ~?a.0Jag(topic a) the entity referred to by a is mentionedin the explanation seeking question(topclass a) the most general class a is a subclassof (the root node does not count)(unknown p) the truth value of proposition p isconsidered tobe unknown to the user(newinfo p) p is contained in the set of propo-sitions constituting the explanation(no-newinfo a) the information about he entity refer-!red to by variable a is not effected bythe explanation given(subst p a b) b is substituted for a in proposition p I(contains p a) proposition p refers to entity a \[(aboutfa c) formulafcontains a proposition asser-ting variable a to belong to class c(not-falsep) p is either unknown to the user oriconsidered by him/her to be true(relevant gr ir) rule gr is relevant for instantiation irFigure 2: Meta-predications and their meaningsthe explanation also contains new facts p (newin-fo) about el and the same assertion also appliesto e2 (expressed by subst), and nothing is saidabout e2 (no-newinfo), conversational relevancedictates that the contrary of the newly introdu.ted facts p is true for e2 (otherwise, the relevantpart of the message would also mention e2).C-Rule 2 may be applicable if the explanationcontains an inference rule r (referred to by new.info).
In that case an attempt is made to establisha link between a class el which occurs (about) inthe rule's premise and all entities e2 mentionedin the prior question (topic) which could fit (not-false) the class membership of el.
ff this is suc-cessful for some e2, their class membershipconcerning el is considered to be valid.Finally, C-Rule 3 tries to strenghten the rele-vance of a proposition (newinfo) concerning anentity el.
First, a unique inference rule r has tobe found (in the addressee's mental state)which contains avariable e2 in its premise suchthat el could fit (not-false) the class membershipof e2.
Secondly, the rule's conclusion must beconsistent with the information available so far;hence, it must be possible to associate all vari-ables e3 occurring in the conclusion with vari-ables e4 by means of a class membership rela,tion.
Then the rule is considered to be relevant.
((all p (and (proposition p) (newinfo p)))((all el (and (entity el) (topic el) (contains p el)))((all e2 (and (entity e2) (topic e2)(equal (topclass e2) (topclass el))(no-newinfo e2)(unknown (subst p el e2))))(implies (not (subst p el ?2))))))C-Rule 1 : Inferring a fact from another fact((all r (and (rule r) (newinfo r)))((all el (about (premise r)el c))((all e2 (and (entity e2) (topic e2)(not.false (subclass (class e2) c))))(implies (equal (class e2) c)))))C-Rule 2 : Inferring a fact from a rulei((all p (and (proposition p) (newinfo p)))((all el (and (entity el) (topic el) (contains p el)))((unique r (and (rule r) (knows user )))((all e2 (and (about (premise r) e2 cl)(not-false (subclass (class el) cl))))((all e3 (about (conclusion r)e3 c2))((some o4 (and (topic e4)(not-false (or (subclass (class e4) c2)(subclass c2 (c "lass o4))))))(implies (relevant r (subst r e2 ?1))))))))C-Rule 3 : Inferring a rule from a factFigure 3: Contextually motivated rules- 192 -4.
THE INFERENCE MECHANISMThe inference mechanism is applied by using asimulated anticipation feed-back loop fed byheuristically generated hypotheses.
They aresubsets of the set of propositions that originallyrepresent the explanation.
After the first suc-cessful application of a contextually motivatedrule only C-Rule 1 and logical substitution arc ta-ken into account for further inferencing.
Thisprocess is continued until all propositions con-mined in the explanation's explicit form occur?
in the current hypothesis, or?
in the user model, or?
in the set of propositions inferred,(thus, the explanation is complete) and no con-tradictions have been derived (it is also impli-cature-free) - hence, the hypothesis consideredrepresents a valid explanation.
The hypothesesare created by starting with the smallest sub-sets, so that the first valid hypothesis can beexpected to be the best choice.
In addition, allinference rules referred to in the explicit form ofthe explanation and unknown to the user arealso contained ineach hypothesis, as there is nochance to infer the relevance of a rule withoutbeing acquainted with it (see the clause (knowsuser r) in C-Rule 3).
Even if the addressee isfamiliar with a certain rule, this rule must eitherbe mentioned or it must be inferable, becauseevidence for its relevance in the actual instanceis required.
In fact, hypotheses not includingsuch a rule are preferred because u'iggering theinference of a rule's relevance by means ofuttering an additonal fact can usually be achiev-ed by shorter utterances than by expressing theinference rule explicitly.
This heuristics has itssource in the Gricean principle of brevity.5.
EXAMPLESThe mechanism described has been implement-ed in CommonLisp on a SUN4.
We demon-strate the system's behavior by means of theeffects of three different user models whenexpressing most adequately the expIanation(represented in Figure 4) to the question: "Whyis person A in room B and not in room C?
"The user models applied comprise stereotypesfor a "local employee" (he/she is acquaintedwith all information about he actual office), fora "novice" (who does not know anything), andfor an "office plan expert" (who is assumed toknow I-Rule 1 (1) only).
Fact (5) is known toanybody, as it is presupposed by the question.The process is simple for the "local employee':Since he/she also knows facts (2) to (4), thefirst hypothesis (I-Rule 1) provides the missinginformation.
The first hypothesis identical forthe "novice', but a series of inferences i need-ed to prove its adequacy.
First, a part of C-Rule2 matches (1) and, as A is the only person refer-red to in the question, it is inferred that A is agroup leader, which is what fact (2) expresses.Then, substituting A and B in I-Rule 1 results inthe evidence that B is a single room, thus prov-ing fact (3) as well.
Finally, C-Rule 1 is appli-cable by substituting B and C for the variablesel and e2, respectively, concluding that C is nota single room (and, in fact, a double room ifthis is the only other possible type of room).The first hypothesis for the "expert" consists of(2) only.
Because xperts are assumed to be ac-quainted with I-Rule 1, C-Rule 3 can be appliedproving the relevance of (1).
Then, processingcan continue as this is done after the first infer-ence step for the "novice', so that fact (2) isobtained as the best explanation for the expert.,m i ,,J l i(1) (and (Rule 1) "Group leaders mustbe in single rooms"(2) (group-leader A) "A is a group leader"(3) (single-room B) "B is a single room"(4) (double-room (2) "(2 is a double room"(5) (in B A)) "A is in room B"Figure 4:Representing anexplanationREFERENCES\[1\] Bateman J., Paris C.: Phrasing a Text in Terms theUser can Understand.
In IJCAI-89, pp.
1511-1517,1989.\[2\] Bergmann H., Fliegner M., Gerlach M., MarburgerH., Poesio M.: IRS - The Internal RepresentationLanguage.
WISBER Report Nr.
14, University ofHamburg, 1987.\[3\] Gdce H.: LOgic and Conversation.
In Syntax andSemantics: Vol 3.
Speech Acts.
pp.
43-58, Acade-mic Pr., 1975.\[4\] Horacek H.: Towards Finding the Reasons Behind-Generating the Content of Explanations.
Submittedto IJCAI-91,\[5\] Karbach W., Linster M., VoB A.: OFFICE-PLAN:Tackling the Synthesis Frontier.
In Metzing D.(ed.
), GWAI-89.
Springer, pp.
379-387, 1989.\[6\] Moore J., Swartout W.: A Reactive Approach toExplanation.
In IJCAI-89, pp.
1504-1510, 1989.\[7\] Paris C.: Tailoring Object Descriptions to a User'sLevel of Expertise.
In ComPutational Linguistics14, pp.
64-78, 1988.\[8\] Reiter E.: Generating Descriptions that Exploit aUser'sDomain Knowledge.
In Current Issues in Na-tural Language Generation, Dale R., Mellish C.,Zock M.
(eds.
), pp.
257-285, Academic Pr., 1990.- 193 -
