Proceedings of the 2nd Workshop on Cognitive Modeling and Computational Linguistics, pages 1?9,Portland, Oregon, June 2011. c?2011 Association for Computational LinguisticsTesting the Robustness of Online Word Segmentation:Effects of Linguistic Diversity and Phonetic VariationLuc Boruta1,2, Sharon Peperkamp2, Beno?
?t Crabbe?1, and Emmanuel Dupoux21 Univ.
Paris Diderot, Sorbonne Paris Cite?, ALPAGE, UMR-I 001 INRIA, F-75205, Paris, France2 LSCP?DEC, E?cole des Hautes E?tudes en Sciences Sociales, E?cole Normale Supe?rieure,Centre National de la Recherche Scientifique, F-75005, Paris, Franceluc.boruta@inria.fr, peperkamp@ens.fr, benoit.crabbe@inria.fr, emmanuel.dupoux@gmail.comAbstractModels of the acquisition of word segmen-tation are typically evaluated using phonem-ically transcribed corpora.
Accordingly, theyimplicitly assume that children know how toundo phonetic variation when they learn to ex-tract words from speech.
Moreover, whereasmodels of language acquisition should per-form similarly across languages, evaluationis often limited to English samples.
Us-ing child-directed corpora of English, Frenchand Japanese, we evaluate the performanceof state-of-the-art statistical models given in-puts where phonetic variation has not been re-duced.
To do so, we measure segmentationrobustness across different levels of segmen-tal variation, simulating systematic allophonicvariation or errors in phoneme recognition.We show that these models do not resist an in-crease in such variations and do not generalizeto typologically different languages.
From theperspective of early language acquisition, theresults strengthen the hypothesis according towhich phonological knowledge is acquired inlarge part before the construction of a lexicon.1 IntroductionSpeech contains very few explicit boundaries be-tween linguistic units: silent pauses often mark ut-terance boundaries, but boundaries between smallerunits (e.g.
words) are absent most of the time.
Pro-cedures by which infants could develop word seg-mentation strategies have been discussed at length,from both a psycholinguistic and a computationalpoint of view.
Many models relying on statisticalinformation have been proposed, and some of themexhibit satisfactory performance: MBDP-1 (Brent,1999), NGS-u (Venkataraman, 2001) and DP (Gold-water, Griffiths and Johnson, 2009) can be consid-ered state-of-the-art.
Though there is evidence thatprosodic, phonotactic and coarticulation cues maycount more than statistics (Johnson and Jusczyk,2001), it is still a matter of interest to know howmuch can be learned without linguistic cues.
To useVenkataraman?s words, we are interested in ?the per-formance of bare-bones statistical models.
?The aforementioned computational simulationshave two major downsides.
First, all models oflanguage acquisition should generalize to typolog-ically different languages; however, the word seg-mentation experiments mentioned above have neverbeen carried out on phonemically transcribed, child-directed speech in languages other than English.Second, these experiments use phonemically tran-scribed corpora as the input and, as such, make theimplicit simplifying assumption that, when childrenlearn to segment speech into words, they have al-ready learned phonological rules and know how toreduce the inherent variability in speech to a finite(and rather small) number of abstract categories: thephonemes.
Rytting, Brew and Fosler-Lussier (2010)addressed this issue and replaced the usual phone-mic input with probability vectors over a finite setof symbols.
Still, this set of symbols is limited tothe phonemic inventory of the language: the reduc-tion of phonetic variation is taken for granted.
Inother words, previous simulations evaluated the per-formance of the models given idealized input but of-fered no guarantee as to the performance of the mod-1els on realistic input.We present a comparative survey that evaluatesthe extent to which state-of-the-art statistical modelsof word segmentation resist segmental variation.
Todo so, we designed a parametric benchmark wheremore and more variation was gradually introducedinto phonemic corpora of child-directed speech.Phonetic variation was simulated applying context-dependent allophonic rules to phonemic corpora.Other corpora in which noise was created by ran-dom phoneme substitutions were used as controls.Furthermore, to draw language-independent conclu-sions, we used corpora from three typologically dif-ferent languages: English, French and Japanese.2 Robustness benchmark2.1 Word segmentation modelsThe segmentation task can be summarized as fol-lows: given a corpus of utterances in which wordboundaries have been deleted, the model has to putthem back.
Though we did not challenge the usualidealization that children are able to segment speechinto discrete, phoneme-sized units, modeling lan-guage acquisition imposes significant constraints onthe models (Brent, 1999; Gambell and Yang, 2004):they must generalize to different (if not all) lan-guages, start without any knowledge specific to aparticular language, learn in an unsupervised man-ner and, most importantly, operate incrementally.Online learning is a sound desideratum for anymodel of language acquisition: indeed, humanlanguage-processors do not wait, in Brent?s words,?until the corpus of all utterances they will everhear becomes available?.
Therefore, we favored an?infant-plausible?
setting and only considered on-line word segmentation models, namely MBDP-1(Brent, 1999) and NGS-u (Venkataraman, 2001).Even if DP (Goldwater et al, 2009) was shown tobe more flexible than both MBDP-1 and NGS-u,we did not include Goldwater et al?s batch model,nor recent online variants by Pearl et al (in press),in the benchmark.
All aforementioned models relyon word n-grams statistics and have similar perfor-mance, but MBDP-1 and NGS-u are minimally suf-ficient in providing an quantitative evaluation of howcross-linguistic and/or segmental variation impactthe models?
performance.
We added two randomsegmentation models as baselines.
The four modelsare described below.2.1.1 MBDP-1The first model is Heinz?s implementation ofBrent?s MBDP-1 (Brent, 1999; Heinz, 2006).
Thegeneral idea is that the best segmentation of an ut-terance can be inferred from the best segmentationof the whole corpus.
However, explicitly search-ing the space of all possible segmentations of thecorpus dramatically increases the model?s computa-tional complexity.
The implementation thus uses anincremental approach: when the ith utterance is pro-cessed, the model computes the best segmentation ofthe corpus up to the ith utterance included, assumingthe segmentation of the first i?1 utterances is fixed.2.1.2 NGS-uThis unigram model was described and imple-mented by Venkataraman (2001).
MBDP-1?s prob-lems of complexity were circumvented using an in-trinsically incremental n-gram approach.
The strat-egy is to find the most probable word sequence foreach utterance, according to information acquiredwhile processing previous utterances.
In the end,the segmentation of the entire corpus is the con-catenation of each utterance?s best segmentation.
Itis worth noting that NGS-u satisfies all three con-straints proposed by Brent: strict incrementality,non-supervision and universality.2.1.3 RandomThis dummy model rewrites its input, uniformlychoosing after each segment whether to insert aword boundary or not.
It defines a chance line atand below which models can be considered ineffi-cient.
The only constraint is that no empty word isallowed, hence no consecutive boundaries.2.1.4 Random+The second baseline is weakly supervised: thougheach utterance is segmented at uniformly-chosenrandom locations, the correct number of wordboundaries is given.
This differs from Brent?s base-line, which was given the correct number of bound-aries to insert in the entire corpus.
As before, con-secutive boundaries are forbidden.2English French JapaneseTokens Types Tokens Types Tokens TypesU 9,790 5,921 10,000 7,660 10,000 6,315W 33,399 1,321 51,069 1,893 26,609 4,112P 95,809 50 121,486 35 102,997 49Table 1: Elementary corpus statistics, including numberof utterances (U), words (W) and phonemes (P).2.2 CorporaThe three corpora we used were derived from tran-scribed adult-child verbal interactions collected inthe CHILDES database (MacWhinney, 2000).
Foreach sample, elementary textual statistics are pre-sented in Table 1.
The English corpus contains9790 utterances from the Bernstein?Ratner corpusthat were automatically transcribed and manuallycorrected by Brent and Cartwright (1996).
It hasbeen used in many word segmentation experiments(Brent, 1999; Venkataraman, 2001; Batchelder,2002; Fleck, 2008; Goldwater et al, 2009; amongothers) and can be considered a de facto standard.The French and the Japanese corpora were bothmade by Le Calvez (2007), the former by automati-cally transcribing the Champaud, Leveille?
and Ron-dal corpora, the latter by automatically transcribingthe Ishii and Noji corpora from ro?maji to phonemes.To get samples comparable in size to the Englishcorpus, 10,000 utterances were selected at randomin each of Le Calvez?s corpora.
All transcriptionchoices made by the authors in terms of phonemicinventory and word segmentation were respected.12.3 Variation sourcesThe main effect of the transformations we appliedto the phonemic corpora was the increase in the av-erage number of word forms per word.
We refer tothis quantity, similar to a type-token ratio, as the cor-pora?s lexical complexity.
As allophonic variationis context-dependent, the increase in lexical com-plexity is, in this condition, limited by the phono-tactic constraints of the language: the fewer con-texts a phoneme appears in, the fewer contextual al-lophones it can have.
By contrast, the upper limitis much higher in the control condition, as phoneme1Some transcription choices made by Brent and Cartwrightare questionable (Blanchard and Heinz, 2008).
Yet, we used thecanonical version of the corpus for the sake of comparability.substitutions are context-free.From a computational point of view, the applica-tion of allophonic rules increases both the number ofsymbols in the alphabet and, as a byproduct, the lex-ical complexity.
Obviously, when any kind of noiseor variation is added, there is less information in thedata to learn from.
We can therefore presume thatthe probability mass will be scattered, and that as aconsequence, statistical models relying on word n-grams statistics will do worse than with phonemicinputs.
Yet, we are interested in quantifying howsuch interference impacts the models?
performance.2.3.1 Allophonic variationIn this experiment, we were interested in the per-formance of online segmentation models given richphonetic transcriptions, i.e.
the input children pro-cess before the acquisition of allophonic rules.
Con-sider the following rule that applies in French:/r/ ?
{[X] before a voiceless consonant[K] otherwiseThe application of this rule creates two contextualvariants for /kanar/ (canard, ?duck?
): [kanaK Zon](canard jaune, ?yellow duck?)
and [kanaX flotA?]
(ca-nard flottant, ?floating duck?).
Before learning therule, children have to store both [kanaK] and [kanaX]in their emerging lexicon as they are not yet able toundo allophonic variation and construct a single lex-ical entry: /kanar/.Daland and Pierrehumbert (2010) compared theperformance of a phonotactic segmentation modelusing canonical phonemic transcripts and transcriptsimplementing conversational reduction processes.They found that incorporating pronunciation vari-ation has a mild negative impact on performance.However, they used adult-directed speech.
Even if,as they argue, reduced adult-directed speech maypresent a worst-case scenario for infants (comparedto hyperarticulated child-direct speech), it offers noquantitative evaluation of the models?
performanceusing child-directed speech.Because of the lack of phonetically transcribedchild-directed speech data, we emulated rich tran-scriptions applying allophonic rules to the phonemiccorpora.
To do so, we represented the internal struc-ture of the phonemes in terms of articulatory fea-tures and used the algorithm described by Boruta3(2011) to create artificial allophonic grammars ofdifferent sizes containing assimilatory rules whoseapplication contexts span phonologically similarcontexts of the target phoneme.
Compared to Da-land and Pierrehumbert?s manual inspection of thetranscripts, this automatic approach gives us a finercontrol on the degree of pronunciation variation.The rules were then applied to our phonemic cor-pora, thus systematizing coarticulation between ad-jacent segments.
We made two simplifying assump-tions about the nature of the rules.
First, all al-lophonic rules we generated are of the type p ?a / c where a phoneme p is realized as its allo-phone a before context c. Thus, we did not modelrules with left-hand or bilateral contexts.
Second,we ensured that no two allophonic rules introducedthe same allophone (as in English flapping, whereboth /t/ and /d/ have an allophone [R]), using parentannotation: each phone is marked by the phonemeit is derived from (e.g.
[R]/t/ and [R]/d/).
This wasdone to avoid probability mass derived from differ-ent phonemes merging onto common symbols.The amount of variation in the corpora is de-termined by the average number of allophones perphoneme.
We refer to this quantity as the corpora?sallophonic complexity.
Thus, at minimal allophoniccomplexity, each phoneme has only one possible re-alization (i.e.
phonemic transcription), whereas atmaximal allophonic complexity, each phoneme hasas many realizations as attested contexts.
For eachlanguage, the range of attested lexical and allo-phonic complexities obtained using Boruta?s (2011)algorithm are reported in Figure 1.2.3.2 Phoneme substitutionsAllophonic variation is not the only type of varia-tion that may interfere with word segmentation.
In-deed, the aforementioned simulations assumed thatall phonemes are recognized with 100% accuracy,but ?due to factors such as noise or speech rate?human processors may mishear words.
In this con-trol condition, we examined the models?
perfor-mance on corpora in which some phonemes werereplaced by others.
Thus, substitutions increase thecorpus?
lexical complexity without increasing thenumber of symbols: phoneme misrecognitions givea straightforward baseline against which to comparethe models?
performance when allophonic variation5 10 15 201.01.52.02.53.03.54.0lllllllll EnglishFrenchJapaneseFigure 1: Lexical complexity (the average number ofword forms per word) as a function of allophonic com-plexity (the average number of allophones per phoneme).has not been reduced.
Such corpora can be consid-ered the output of a hypothetical imperfect speech-to-phoneme system or a winner-take-all scalar re-duction of Rytting et al?s (2010) probability vectors.We used a straightforward model of phonememisrecognition: substitutions are based neither ona confusion matrix (Nakadai et al, 2007) nor onphoneme similarity.
Starting from the phonemiccorpus, we generated 10 additional corpora con-trolling the proportion of misrecognized phonemes,ranging from 0 (perfect recognition) to 1 (constanterror) in increments of 0.1.
A noise intensity of nmeans that each phoneme has probability n of beingrewritten by another phoneme.
The random choiceof the substitution phoneme is weighted by the rela-tive frequencies of the phonemes in the corpus.
Theprobability P (p ?
x) that a phoneme x rewrites aphoneme p is defined asP (p?
x) =???1?
n if p = xn(f(x) +f(p)|P| ?
1)otherwisewhere n is the noise intensity, f(x) the relative fre-quency of phoneme x in the corpus andP the phone-mic inventory of the language.42.4 EvaluationWe used Venkataraman?s (2001) implementation ofthe now-standard evaluation protocol proposed byBrent (1999) and then extended by Goldwater et al(2009).
Obviously, orthographic words are not theoptimal target for a model of language acquisition.Yet, in line with previously reported experiments,we used the orthographic segmentation as the stan-dard of correct segmentation.2.4.1 ScoringFor each model, we report (as percentages) thefollowing scores as functions of the lexical complex-ity of the corpus:?
Ps, Rs, Fs: precision, recall and F -score onword segmentation as defined by Brent;?
Pl, Rl, Fl: precision, recall and F -score on theinduced lexicon of word types: let L be thestandard lexicon and L?
the one discovered bythe algorithm, we define Pl = |L ?
L?|/|L?|,Rl = |L?L?|/|L| and Fl = 2?Pl ?Rl/(Pl+Rl).The difference between scoring the segmenta-tion and the lexicon can be exemplified consider-ing the utterance [@wUd?2kwUd?2kwUd] (a wood-chuck would chuck wood).
If it is segmented as[@ wUd?2k wUd ?2k wUd], both the segmentationand the induced lexicon are correct.
By contrast, ifit is segmented as [@ wUd ?2k wUd?2k wUd], thelexicon is still accurate while the word segmentationis incorrect.
A good segmentation inevitably yields agood lexicon, but the reverse is not necessarily true.2.4.2 k-shuffle cross-validationAs the segmental variation procedures and thesegmentation baselines are non-deterministic pro-cesses, all scores were averaged over multiple simu-lations.
Moreover, as MBDP-1 and NGS-u operateincrementally, their output is conditioned by the or-der in which utterances are processed.
To lessen theinfluence of the utterance order, we shuffled the cor-pora for each simulation.
Testing all permutations ofthe corpora for each combination of parameter val-ues is computationally intractable.
Thus, scores re-ported below were averaged over three distinct sim-ulations with shuffled corpora.JPFRENa.
Segmentation F?score0 10 20 30 40 50 60 70 80 90JPFRENb.
Lexicon F?score0 10 20 30 40 50 60 70 80 90MBDP?1NGS?uRandom+RandomFigure 2: Cross-linguistic performance of MBDP-1 andNGS-u on child-directed phonemic corpora in English(EN), French (FR) and Japanese (JP).3 Results and discussion3.1 Cross-linguistic evaluationPerformance of the segmentation models2 on phone-mic corpora is presented in Figure 1 in terms of Fs-and Fl-score (upper and lower panel, respectively).We were able to replicate previous results on En-glish by Brent and Venkataraman almost exactly; thesmall difference, less than one percent, was probablycaused by the use of different implementations.From a cross-linguistic point of view, the mainobservation is that these models do not seemto generalize to typologically different languages.Whereas MBDP-1 and NGS-u?s Fs value is 69%for English, it is only 54% for French and 41% forJapanese.
Similar observations can be made for Fl.Purely statistical strategies seem to be particularlyineffective on our Japanese sample: inserting wordboundaries at random yields a better lexicon than us-ing probabilistic models.A crude way to determine whether a word seg-mentation model tends to break words apart (over-segmentation) or to cluster various words in a singlechunk (under-segmentation) is to compare the aver-age word length (AWL) in its output to the AWL inthe standard segmentation.
If the output?s AWL isgreater than the standard?s, then the output is under-segmented, and vice versa.
Even if NGS-u produces2The full table of scores for each language, variation source,and segmentation model was not included due to space limita-tions.
It is available upon request from the first author.5shorter words than MBDP-1, both models exhibit,once again, similar within-language behaviors.
En-glish was slightly under-segmented by MBDP-1 andover-segmented by NGS-u: ouputs?
AWL are re-spectively 3.1 and 2.7, while the standard is 2.9.Our results are consistent with what Goldwater et al(2009) observed for DP: error analysis shows thatboth MBDP-1 and NGS-u also break off frequentEnglish morphological affixes, namely /IN/ (-ing)and /s,z/ (-s).
As for French, AWL values suggestthe corpus was under-segmented: 3.1 for MBDP-1?soutput and 2.9 for NGS-u?s, while the standard is2.4.
On the contrary, Japanese was heavily over-segmented: many monophonemic words emergedand, whereas the standard AWL is 3.9, the ouputs?AWL is 2.7 for both models.Over-segmentation may be correlated to the num-ber of syllable types in the language: Englishand French phonotactics allow consonantal clusters,bringing the number of syllable types to a few thou-sands.
By contrast, Japanese has a much simplersyllabic structure and less syllable types which, asa consequence, are often repeated and may (incor-rectly) be considered as words by statistical mod-els.
The fact that the models do worse for Frenchand Japanese is not especially surprising: both lan-guages have many more affixal morphemes than En-glish.
Consider French, where the lexical autonomyof clitics is questionable: whereas /s/ (s?
or c?)
or/k/ (qu?)
are highly frequent words in our ortho-graphic standard, many errors are due to the aggluti-nation of these clitics to the following word.
Theseare counted as segmentation errors, but should they?Furthermore, none of the segmentation modelswe benchmarked exhibit similar performance acrosslanguages: invariably, they perform better on En-glish.
There may be a correlation between the per-formance of segmentation models and the percent-age of word hapaxes, i.e.
words which occur onlyonce in the corpus: the English, French and Japanesecorpora contain 31.7%, 37.1% and 60.7% of wordhapaxes, respectively.
The more words tend to occuronly once, the less MBDP-1, NGS-u and DP per-form on segmentation.
This is consistent with theusual assumption that infants use familiar words tofind new ones.
It may also be the case that thesemodels are not implicitly tuned to English, but thatthe contribution of statistical cues to word segmen-tation differs across languages.
In French, for exam-ple, stress invariably marks the end of a word (al-though the end of a word is not necessarily markedby stress).
By contrast, there are languages likeEnglish or Spanish where stress is less predictable:children cannot rely solely on this cue to extractwords and may thus have to give more weight tostatistics.3.2 Robustness to segmental variationThe performance of MBDP-1, NGS-u and the twobaselines on inputs altered by segmental variationis presented in Figure 2.3 The first general observa-tion is that, as predicted, MBDP-1 and NGS-u do notseem to resist an increase in lexical complexity.
Inthe case of allophonic variation, their performanceis inversely related to the corpora?s allophonic com-plexity.
However, as suggested by the change inthe graphs?
slope, performance for English seemsto stabilize at 2 word forms per word.
Similar ob-servations can be made for French and Japanese onwhich the performance of the models is even worse:Fl values are below chance at 1.7 and 3 variants perword for Japanese and French, respectively; like-wise, Fs is below chance at 1.5 for Japanese and2.5 for French.
Phoneme substitutions also impedethe performance of MBDP-1 and NGS-u: the morephonemes are substituted, the more difficult it be-comes for the algorithms to learn how to insert wordboundaries.
Furthemore, Fl is below chance forcomplexities greater than 4 for French, and approx-imately 2.5 for Japanese.
It is worth noting that, inboth conditions, the models exhibit similar within-language performance as the complexity increases.The potential lexicon that can be built by com-bining segments into words may account for thediscrepancy between the two conditions, as it is infact the models?
search space.
In the control con-dition, substituting phonemes does not increase itssize.
However, the likelihood of a given phoneme ina given word being replaced by the same substitu-tion phoneme decreases as words get longer.
Thus,the proportion of hapax increases, making statisti-cal segmentation harder to achieve.
By contrast, the3For the control condition, we did not graph scores for noiseintensities greater than 0.2: 80% accuracy is comparable to theerror rates of state-of-the-art systems in speaker-independent,continuous speech recognition (Makhoul and Schwartz, 1995).61 2 3 4 5 6 7 810203040506070a.
English: segmentation F?scoreSegmentation F?scorellll ll l lll1 2 3 4 5 6 7 810203040506070b.
English: lexicon F?scoreLexiconF?scorel MBDP?1NGS?uRandom+RandomAllophonySubstitutionslll l l l l lll1 2 3 4 5 6102030405060c.
French: segmentation F?scoreSegmentation F?scorellll lll l lll1 2 3 4 5 6102030405060d.
French: lexicon F?scoreLexiconF?scorellll l l l llll1.0 1.5 2.0 2.5 3.01020304050e.
Japanese: segmentation F?scoreSegmentation F?scorellllllllll1.0 1.5 2.0 2.5 3.01020304050f.
Japanese: lexicon F?scoreLexiconF?scorell l lllllllFigure 3: Fs-score (left column) and Fl-score (right column) as functions of the lexical complexity, i.e.
the number ofword forms per word, in the English (top row), French (middle row) and Japanese (bottom row) corpora.7application of allophonic rules increases the numberof objects to build words with; as a consequence, thesize of the potential lexicon explodes.As neither MBDP-1 nor NGS-u is designed tohandle noise, the results are unsurprising.
Indeed,any word form found by these models will be incor-porated in the lexicon: if [l?NgwI?]
and [l?NgwI?
]are both found in the corpus, these variants will beincluded as is in the lexicon.
There is no mechanismfor ?explaining away?
data that appear to have beengenerated by systematic variation or random noise.It is an open issue for future research to create ro-bust models of word segmentation that can handlesegmental variation.4 ConclusionsWe have shown, first, that online statistical mod-els of word segmentation that rely on word n-gramstatistics do not generalize to typologically differ-ent languages.
As opposed to French and Japanese,English seems to be easier to segment using onlystatistical information.
Such differences in perfor-mance from one language to another emphasize therelevance of cross-linguistic studies: any conclusiondrawn from the monolingual evaluation of a modelof language acquisition should be considered withall proper reservations.
Second, our results quan-tify how imperfect, though realistic, inputs impactMBDP-1?s and NGS-u?s performance.
Indeed, bothmodels become less and less efficient in discover-ing words in transcribed child-directed speech asthe number of variants per word increases: thoughthe performance drop we observed is not surpris-ing, it is worth noting that both models are less ef-ficient than random procedures at about twenty al-lophones per phoneme.
However, the number ofcontext-dependent allophones we introduced is farless than what is used by state-of-the-art models ofspeech recognition (Makhoul and Schwartz, 1995).To our knowledge, there is no computationalmodel of word segmentation that both respects theconstraints imposed on a human learner and accom-modates noise.
This highlights the complexity ofearly language acquisition: while no accurate lex-icon can be learned without a good segmentationstrategy, state-of-the-art models fail to deliver goodsegmentations in non-idealized settings.
Our re-sults also emphasize the importance of other cuesfor word segmentation: statistical learning may behelpful or necessary for word segmentation, but it isunlikely that it is sufficient.The mediocre performance of the modelsstrengthens the hypotheses that phonologicalknowledge is acquired in large part before theconstruction of a lexicon (Jusczyk, 1997), or thatallophonic rules and word segmentations could beacquired jointly (so that neither is a prerequisitefor the other): children cannot extract words fromfluent speech without knowing how to undo at leastpart of contextual variation.
Thus, the knowledgeof allophonic rules seems to be a prerequisite foraccurate segmentation.
Recent simulations of wordsegmentation and lexical induction suggest thatusing phonological knowledge (Venkataraman,2001; Blanchard and Heinz, 2008), modelingmorphophonological structure (Johnson, 2008) orpreserving subsegmental variation (Rytting et al,2010) invariably increases performance.
Viceversa, Martin et al (submitted) have shown that thealgorithm proposed by Peperkamp et al (2006) forundoing allophonic variation crashes in the face ofrealistic input (i.e.
many allophones), and that itcan be saved if it has approximate knowledge ofword boundaries.
Further research is needed, atboth an experimental and a computational level, toexplore the performance and suitability of an onlinemodel that combines the acquisition of allophonicvariation with that of word segmentation.ReferencesE.
Batchelder.
2002.
Bootstrapping the lexicon: a com-putational model of infant speech segmentation.
Cog-nition, 83:167?206.D.
Blanchard and J. Heinz.
2008.
Improving word seg-mentation by simultaneously learning phonotactics.
InProceedings of the Conference on Natural LanguageLearning, pages 65?72.L.
Boruta.
2011.
A note on the generation of allophonicrules.
Technical Report 0401, INRIA.M.
R. Brent and T. A. Cartwright.
1996.
Distributionalregularity and phonotactic constraints are useful forsegmentation.
Cognition, 61:93?125.M.
R. Brent.
1999.
An efficient, probabilistically soundalgorithm for segmentation and word discovery.
Ma-chine Learning, 34(1?3):71?105.8R.
Daland and J.
B. Pierrehumbert.
2010.
Learn-ing diphone-based segmentation.
Cognitive Science,35(1):119?155.M.
Fleck.
2008.
Lexicalized phonotactic word segmen-tation.
In Proceedings of ACL-2008, pages 130?138.T.
Gambell and C. Yang.
2004.
Statistics learning anduniversal grammar: Modeling word segmentation.
InProceedings of the 20th International Conference onComputational Linguistics.S.
Goldwater, T. L. Griffiths, and M. Johnson.
2009.
Abayesian framework for word segmentation: exploringthe effects of context.
Cognition, 112(1):21?54.J.
Heinz.
2006.
MBDP-1, OCaml implementation.
Re-trieved from http://phonology.cogsci.udel.edu/?heinz/on January 26, 2009.E.
K. Johnson and P. W. Jusczyk.
2001.
Word segmenta-tion by 8-month-olds: When speech cues count morethan statistics.
Journal of Memory and Language,44:548?567.M.
Johnson.
2008.
Unsupervised word segmentation forSesotho using adaptor grammars.
In Proceedings ofthe 10th Meeting of ACL SIGMORPHON, pages 20?27.P.
Jusczyk.
1997.
The Discovery of Spoken Language.MIT Press.R.
Le Calvez.
2007.
Approche computationnelle del?acquisition pre?coce des phone`mes.
Ph.D. thesis,UPMC.B.
MacWhinney.
2000.
The CHILDES Project: Toolsfor Analyzing Talk.
Lawrence Elbraum Associates.J.
Makhoul and R. Schwartz.
1995.
State of the art incontinuous speech recognition.
PNAS, 92:9956?9963.A.
Martin, S. Peperkamp, and E. Dupoux.
Submitted.Learning phonemes with a pseudo-lexicon.K.
Nakadai, R. Sumiya, M. Nakano, K. Ichige, Y. Hi-rose, and H. Tsujino.
2007.
The design of phonemegrouping for coarse phoneme recognition.
In IEA/AIE,pages 905?914.L.
Pearl, Sh.
Goldwater, and M. Steyvers.
In press.
On-line learning mechanisms for bayesian models of wordsegmentation.
Research on Language and Computa-tion.S.
Peperkamp, R. Le Calvez, J. P. Nadal, and E. Dupoux.2006.
The acquisition of allophonic rules: statisti-cal learning with linguistic constraints.
Cognition,101(3):B31?B41.C.
A. Rytting, C. Brew, and E. Fosler-Lussier.
2010.Segmenting words from natural speech: subsegmen-tal variation in segmental cues.
Journal of Child Lan-guage, 37:513?543.A.
Venkataraman.
2001.
A statistical model for worddiscovery in transcribed speech.
Computational Lin-guistics, 27(3):351?372.9
