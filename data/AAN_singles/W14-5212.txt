Proceedings of the Workshop on Open Infrastructures and Analysis Frameworks for HLT, pages 101?109,Dublin, Ireland, August 23rd 2014.EUMSSI: a Platform for Multimodal Analysis and Recommendationusing UIMAJens GrivollaUniversitat Pompeu FabraBarcelona, Spainjens.grivolla@upf.eduMaite MeleroUniversitat Pompeu FabraBarcelona, Spainmaite.melero@upf.eduToni BadiaUniversitat Pompeu FabraBarcelona, Spaintoni.badia@upf.eduCosmin CabuleaDeutsche WelleBonn, Germanycosmin.cabulea@dw.deYannick Est`eveUniversit?e du MaineLe Mans, Franceyannick.esteve@lium.univ-lemans.frEelco HerderL3S Research CenterHannover, Germanyherder@l3s.deJean-Marc OdobezIDIAP Research InstituteMartigny, Switzerlandodobez@idiap.chSusanne Preu?Gesellschaft zur F?orderung derAngewandten InformationsforschungSaarbr?ucken, Germanysusannep@iai.uni-sb.deRa?ul Mar?
?nVSN Innovationand Media SolutionsAlicante, Spainrmarin@vsn.esAbstractThe EUMSSI project (Event Understanding through Multimodal Social Stream Interpretation)aims at developing technologies for aggregating data presented as unstructured information insources of very different nature.
The multimodal analytics will help organize, classify and clus-ter cross-media streams, by enriching its associated metadata in an interactive manner, so thatthe data resulting from analysing one media helps reinforce the aggregation of information fromother media, in a cross-modal semantic representation framework.
Once all the available de-scriptive information has been collected, an interpretation component will dynamically reasonover the semantic representation in order to derive implicit knowledge.
Finally the enriched in-formation will be fed to a hybrid recommendation system, which will be at the basis of twowell-motivated use-cases.
In this paper we give a brief overview of EUMSSI?s main goals andhow we are approaching its implementation using UIMA to integrate and combine various layersof annotations coming from different sources.1 IntroductionNowadays, a multimedia journalist has access to a vast amount of data from a plurality of types of sourcesto document a story.
In order to put information into context and tell his story from all significant angles,he needs to go through an enormous amount of records with information of very diverse degrees ofgranularity.
At the same time, he needs to reduce the noise of irrelevant content.
This is extremelytime-consuming, especially when a topic or event is interconnected with multiple entities from differentdomains.
At a different level, many TV viewers are getting used to navigating with their tablets or iPadswhile watching the TV, the tablet effectively functioning as a second screen, often providing backgroundinformation on the program or interaction in social networks about what is being watched.
Both theThis work is licenced under a Creative Commons Attribution 4.0 International License.
Page numbers and proceedings footerare added by the organizers.
License details: http://creativecommons.org/licenses/by/4.0/101journalist and the TV viewer would greatly benefit from a system capable of automatically analysing andinterpreting unstructured multimedia data stream and its social background, and, with this understanding,be able of contextualising the data, and contributing with new, related information.The FP7-ICT-2013-10 STREP project EUMSSI, which started in December 2013, is developingmethodologies and techniques for identifying and aggregating data presented as unstructured informa-tion in sources of very different nature (video, image, audio, speech, text and social context), includingboth online (e.g., YouTube) and traditional media (e.g.
audiovisual repositories), and for dealing withinformation of very different degrees of granularity.This will be accomplished thanks to the integration in a UIMA-based1multimodal platform of state-of-the-art information extraction and analysis techniques from the different fields involved (image, audio,text and social media analysis).
The multimodal interpretation platform, in an optimized process chain,will analyze a vast amount of multimedia content, aggregate all the resulting information and semanti-cally enrich it with additional metadata layers.
The resulting system will be potentially useful for anyapplication in need of cross-media data analysis and interpretation, such as intelligent content manage-ment, recommendation, real time event tracking, content filtering, etc.
In particular, the EUMSSI projectwill use the semantically enriched information to make personalized content-based recommendation.2 Multimodal analytics and Semantic EnrichmentFor reasoning with and about the multimedia data, the EUMSSI platform needs to recognize entities,such as actors, places, topics, dates and genres.
A core idea is that the process of integrating informationcoming from different media sources is carried out in an interactive manner, so that the metadata resultingfrom analyzing one media helps reinforce the aggregation of information from other media.
For example,the quality of speech recognition heavily depends on the audio quality and background noise.
Existingtext, tags and other metadata will be exploited for disambiguation.
Further, OCR on video data, speechanalysis and speaker recognition mutually reinforce one another.
The combined and integrated results ofthe audio, video and text analysis will significantly enhance the existing metadata, which can be used forretrieval and recommendation.
In addition, the extracted entities and other annotations will be exploitedfor identifying specific video fragments in which a particular person speaks, a new topic begins, or anentity is mentioned.
Figure 1 illustrates some of the different layers of analysis that may exist for a videocontent item.Once the entities and concepts have been identified in the different modalities, all the information is ag-gregated and semantically enriched, using general ontologies or structured knowledge bases.
Wikipediacategories have been successfully exploited with this purpose in different works: e.g.
to describe chemi-cal documents (K?ohncke and Balke, 2010), to identify topics of interest for Twitter users (Michelson andMacskassy, 2010), and also to improve Web video categorization (Chen et al., 2010).
Moreover, (Hahn etal., 2010) have shown that the structured information gathered from Wikipedia infoboxes can be used toanswer complex questions, like ?Which Rivers flow into the Rhine and are longer than 50 kilometers?
?For this purpose, text documents need to be previously annotated using DBpedia Spotlight (Mendes etal., 2011), which automatically annotates text with links to articles in Wikipedia.
The process of se-mantic enrichment is still largely domain-dependent; therefore, apart from the available general-purposeknowledge bases and ontologies (DBpedia, FOAF, DublinCore...), the EUMSSI platform needs special-ized resources for categorizing videos on different dimensions.
Linked Data technologies (Heath andBizer, 2011) and the Linked Open Data cloud2provide access to several of these resources, includinggeodata, movie databases and program information.3 Content-based Recommendation and the DemonstratorsThe semantically enriched information is then used by the EUMSSI system to make personalizedcontent-based recommendation.
We propose a novel recommender system that leverages matrix factor-ization (Koren, 2008) with implicit feedback in order to integrate content-based similarity, usage history1Unstructured Information Management Architecture: http://uima.apache.org/2http://lod-cloud.net/102Figure 1: Video Mining Analysis(i.e.
collaborative filtering), as well as user demographics.
This integrated approach reduces the cold-start problems typical of collaborative filtering, both for new users and for new content.
Recommendationand aggregation of related content in EUMSSI is expected to use varying degrees of personalization, giv-ing more weight in some cases to the individual user?s interests, based on his viewing history, but beingbased primarily on the similarity to the currently shown content in other cases.On top of the recommender, two demonstrators will be implemented within the EUMSSI project, eachcatering to a different use-case: (i) a computer-assisted storytelling tool integrated in the workflow of amultimedia news editor, empowering the journalist to monitor and gather up-to-date documents relatedwith his investigation, without the need of reviewing an enormous amount of insufficiently annotatedrecords; and (ii) a second-screen application for an end-user, able to make relevant suggestions of mul-timedia content based on what the user is watching, what other people have watched, and what peopleare saying about these contents in the social networks.
Figure 2 shows how both applications build on acommon base of multimedia analysis and content aggregation/recommendation algorithms.4 Architecture overviewAll new content coming into the system is first normalized to a common metadata schema (based onschema.org) and stored in a database (MAM/media asset manager, or MongoDB3) to make it availablefor further processing.
Analysis results, as well as the original metadata, are stored in CAS format toallow integration of different aligned layers of analysis.The process flow, pictured in Figure 3, can be summarized as follows:1. new data arrives (or gets imported)2. preprocessing stage(a) make content available through unique URI (from central MAM)(b) create initial CAS with aligned metadata / text content and content URI3it will be developed in parallel as an open source MongoDB based solution, as well as integrated into VSN?s proprietaryplatform103Figure 2: Multimodal platform catering both for the journalist and the end-user?s use-cases(c) add content to processing queues3.
processing / content analysis(a) distributed analysis systems query queue when they have processing capacity(b) retrieve CAS with existing data (or get relevant metadata from wrapper API)(c) retrieve raw content based on content URI(d) process(e) update CAS (possibly through wrapper API)(f) update queuesi.
mark as processedii.
add to queues for other processes that depend on previous analysis results4.
indexing when processing is complete for a content item (e.g.
with Solr)Note that this architecture design mainly depicts the data analysis part of the EUMSSI system ?
thedeployment by Web applications is not visible in the figure.
These will be built upon the Solr indexescreated from the CAS.5 Aligned data representationMuch of the reasoning and cross-modal integration depends on an aligned view of the different annotationlayers, e.g., in order to connect person names detected from OCR with corresponding speakers from thespeaker recognition component, or faces detected by the face recognition.The Apache UIMA4CAS (common analysis structure) representation is a good fit for the needs of theEUMSSI project as it has a number of interesting characteristics:?
Annotations are stored ?stand-off?, meaning that the original content is not modified in any way byadding annotations.
Rather, the annotations are entirely separate and reference the original contentby offsets4http://uima.apache.org/104Data SourcescrawlersDWfeeds...extract metadata /contentcreateinitial CASadd to / updateprocessing queuesvideoanalysisaudioanalysistextanalysisMAM /MongoDB1.
get raw content /previous CAS2.
process3.
update CASPreprocessProcessingqueuemanager...Figure 3: Architecture design?
Annotations can be defined freely by defining a ?type system?
that specifies the types of anno-tations (such as Person, Keyword, Face, etc.)
and the corresponding attributes (e.g.
dbpediaUrl,canonicalRepresentation, ...)?
Source content can be included in the CAS (particularly for text content) or referenced as externalcontent via URIs (e.g.
for multimedia content)?
While each CAS represents one ?document?
or ?content item?, it can have several Views that rep-resent different aspects of that item, e.g.
the video layer, audio layer, metadata layer, transcribedtext layer, etc., with separate source content (SofA or ?subject of annotation?)
and separate sets ofannotations?
CASes can be passed efficiently in-memory between UIMA analysis engines?
CASes can be serialized in a standardised OASIS format5for storage and interchangeIn the case of the EUMSSI project, the common base for alignment for different annotation layersreferring to multimedia content is timestamps relative to the original content.Annotations based directly on multimedia content (video and audio) will naturally refer to that contentvia timestamps, whereas text analysis modules normally work with character offsets relative to the textcontent.
It is therefore fundamental that any textual views created from multimedia content (e.g.
via ASRor OCR) refer back to the timestamps in the original content.
This will be done by creating annotations,e.g.
tokens, that include the original timestamps as attributes in addition to the character offsets.As an example, we may have a CAS with an audio view on which we apply automatic speech recogni-tion (ASR), providing the transcription as a series of tokens/words with a timestamp for each word.
Thesystem then creates a new view in the CAS that has the full plain-text transcription as SofA and a seriesof Token annotations with both character offsets relative to the plain-text SofA, and timestamp offsetsrelative to the multimedia content.In this way it is possible to apply standard text analysis modules (that rely on character offsets) on thetextual representation, while maintaining the possibility to later map the resulting annotations back ontothe temporal scale.Timestamps will be represented in milliseconds in order to avoid floating point values.
In this way, allannotations can be subtypes of the standard UIMA Annotation type6, which provides access to a number5http://docs.oasis-open.org/uima/v1.0/uima-v1.0.html6otherwise annotations would need to derive from the more generic TOP type105of utility functions that help find sets of overlapping annotations, retrieve annotations in offset order, etc.SofA-aware UIMA components are able to work on multiple views, whereas ?normal?
analysis en-gines only see one specific view that is presented to them.
This means that e.g.
standard text analysisengines don?t need to be aware that they are being applied to an ASR view or an OCR view; they justsee a regular text document.
SofA-aware components, however, can explicitly work on annotations fromdifferent views and can therefore be used to integrate and combine the information coming from differentsources or layers, and create new, integrated views with the output from that integration and reasoningprocess.6 Flow managementUIMA provides a platform for execution of analysis components (Analysis Engines or AEs), as well asfor managing the flow between those components.CPE or uimaFIT7(Ogren and Bethard, 2009) can be used to design and execute pipelines made up of asequence of AEs (and potentially some more complex flows), and UIMA-AS8(Asynchronous Scaleout)permits the distribution of the process among various machines or even a cluster (with the help of UIMADUCC9).Analysis Engines can either be ?natively?
written for UIMA or can be wrappers that translate inputsand outputs for existing analysis components so they can be integrated in UIMA.
All text analysis com-ponents, as well as the integration and reasoning components, will be available as UIMA AEs and cantherefore be configured and executed directly within the UIMA environment.There are some components of the EUMSSI platform, however, that do not integrate easily in thisfashion.
This is the case of computationally expensive processes that are optimized for batch execution.A UIMA AE needs to expose a process() method that operates on a single CAS (= document), and istherefore not compatible with batch processing.
This is particularly true for processes that need to be runon a cluster, with significant startup overhead, such as many video and audio analysis tasks.It is therefore necessary to have an alternative flow mechanism for offline or batch processes, whichneeds to integrate with the processing performed within the UIMA environment.The main architectural and integration issues revolve around the data flow, rather than the computa-tion.
In fact, the computationally complex and expensive aspects are specific to the individual analysiscomponents, and should not have an important impact on the design of the overall platform.As such, the design of the flow management is presented in terms of transformations between datastates, rather than from the procedural point of view.
The resulting system should only rely on therobustness of those data states to ensure the reliability and robustness of the overall system, protectingagainst potential problems from server failures or other causes.
At any point, the system should be ableto resume its function purely from the state of the persisted data.To ensure reliability and performance of the data persistence, we expect to use a well-established andwidely used database system such as MongoDB.Figure 4 shows the general flow of the EUMSSI system, focusing on the data states needed for thesystem to function.In order to avoid synchronization issues, the state of the data processing is stored together with thedata, and the list of pending tasks can be extracted at any point through simple database queries.For example in order to retrieve the list of content items that have been crawled or received from feeds,but still need to be converted to the unified EUMSSI schema, it is sufficient to query for items that havea ?source meta:original?
but no ?source meta:eumssi?.Similarly, the queues for analysis processes can be constructed directly from the ?processing state?
ofan item by selecting (for a given queue) all items that have not yet been processed by that queue and thatfulfil all prerequisites (dependencies).7https://uima.apache.org/uimafit.html8http://uima.apache.org/doc-uimaas-what.html9http://uima.apache.org/doc-uimaducc-whatitam.html106Figure 4: data flow and transformationsAs an illustration, each content item has approximately the following structure:{"content_id" : UUID,"source_meta" : {"original" : ORIGINAL_SOURCE_METADATA,"eumssi" : EUMSSI_SOURCE_METADATA},"cas" : {"xmi" : XMI_CAS,"binary" : BINARY_CAS},"processing_state" : {"queue1" : "done","queue2" : "in_process",..."queueN" : "pending"},"extracted_meta" : METADATA_FROM_CAS}where:107?
UUID is a system-wide unique content id, created when first inserting the content into the system?
ORIGINAL SOURCE METADATA is the metadata as provided from the original content fields?
EUMSSI SOURCE METADATA is the original metadata mapped to the EUMSSI vocabulary /schema?
XMI CAS is the CAS serialized in XMI format (and possibly compressed)?
BINARY CAS is the CAS serialized in binary format (alternative to XMI CAS)?
METADATA FROM CAS is metadata that is generated by EUMSSI analysis processes, using theEUMSSI schemaNormally, the CAS will be stored only in one of the available formats, but potentially different serial-izations could be used.
The ?extracted meta?
information can be used for analysis results that are usedas inputs to other annotators (such as detected Named Entities as input to speech recognition), to avoidthe overhead of extracting that information from the CAS on demand.MongoDB allows to stored structured information (corresponding to a JSON structure), so that thecontent of fields like ORIGINAL SOURCE METADATA can reflect whatever internal structure the orig-inal data had.The final applications are not expected to use the information stored in MongoDB directly, but ratheraccess Solr indexes created from that information to respond specifically to the types of queries neededby the applications.
Those indexes will typically be created from the CAS when all analysis steps havebeen performed.It is, however, possible to have indexing processes that only depend on a subset of analyses, and thusmake content items (at least partially) accessible to the applications before they have been fully processed(which may take a relatively long time).
The indexing processes can be managed in the same way as anyanalysis process, with their own queues that specify the necessary dependencies, and taking the currentstate of the CAS as input.In its simplest form, the processes responsible for the data transitions are fully independent and pollthe database periodically to retrieve pending work.
Those processes can then be implemented in anylanguage that can communicate comfortably with MongoDB.
As an efficiency improvement, in orderto reduce the polling load, message queues (such as managed by ActiveMQ10) can be used to notifyprocesses of pending work after performing the preceding steps.7 Conclusions and future workIn this paper, we have presented the main goals and approaches of the EUMSSI project, which aimsto innovatively integrate state-of-the-art text and A/V analysis technologies, semantic enrichment andreasoning, social intelligence and collaborative content-based recommendation, in order to build a mul-timodal, interoperable platform potentially useful for any application in need of automatic cross-mediadata analysis and interpretation, such as intelligent content management, personalized recommendation,real time event tracking, content filtering, etc.The project is still in an early stage, and many aspects will need to be defined later on.
The differentanalysis modalities are handled by separate research groups that will each improve the individual types ofanalysis in their are of expertise.
This paper only reports on the platform that will integrate and combinethe analysis results.Additionally, possible interactions between modalities will need to be defined as it becomes clearerwhat information each analysis can provide or benefit from.
We have at this point identified some of themore obvious interactions, such as doing text analysis on speech recognition output, or adding NamedEntities from surrounding text to the vocabulary known to the ASR system, but many more may becomeapparent as the different research groups learn from each other.10http://activemq.apache.org/108One of the main innovative aspects of the project also lies in the combination of the outputs of differentanalysis layers, and the capacity to perform reasoning or inference over this combined view to create aricher model of the content than can be obtained individually.
This is an important research task thathas not started yet, and we hope to report on it in the near future.
As such, this article is limited to thetechnological foundation that will enable this work by providing a flexible platform with easy access toall available information layers.Development of the platform has recently begun and all developments will become publicly availableat https://github.com/EUMSSI/.AcknowledgementsThe work presented in this article is being carried out within the FP7-ICT-2013-10 STREPproject EUMSSI under grant agreement n?611057, receiving funding from the EuropeanUnion?s Seventh Framework Programme managed by the REA-Research Executive Agencyhttp://ec.europa.eu/research/rea.ReferencesZhineng Chen, Juan Cao, Yicheng Song, Yongdong Zhang, and Jintao Li.
2010.
Web video categorization basedon Wikipedia categories and content-duplicated open resources.
In Proceedings of the international conferenceon Multimedia - MM ?10, page 1107, New York, New York, USA, October.
ACM Press.Rasmus Hahn, Christian Bizer, Christopher Sahnwaldt, Christian Herta, Scott Robinson, Michaela B?urgle, HolgerD?uwiger, and Ulrich Scheel.
2010.
Faceted wikipedia search.
In Business Information Systems, pages 1?11.Springer.Tom Heath and Christian Bizer.
2011.
Linked data: Evolving the web into a global data space.
Synthesis Lectureson the Semantic Web: Theory and Technology.Benjamin K?ohncke and Wolf-Tilo Balke.
2010.
Using Wikipedia categories for compact representations of chem-ical documents.
In Proceedings of the 19th ACM international conference on Information and knowledgemanagement - CIKM ?10, page 1809, New York, New York, USA, October.
ACM Press.Yehuda Koren.
2008.
Factorization meets the neighborhood.
In Proceeding of the 14th ACM SIGKDD interna-tional conference on Knowledge discovery and data mining - KDD 08, page 426, New York, New York, USA,August.
ACM Press.Pablo N. Mendes, Max Jakob, Andr?es Garc?
?a-Silva, and Christian Bizer.
2011.
DBpedia spotlight.
In Proceedingsof the 7th International Conference on Semantic Systems - I-Semantics ?11, pages 1?8, New York, New York,USA, September.
ACM Press.Matthew Michelson and Sofus A. Macskassy.
2010.
Discovering users?
topics of interest on twitter.
In Proceed-ings of the fourth workshop on Analytics for noisy unstructured text data - AND ?10, page 73, New York, NewYork, USA, October.
ACM Press.Philip V. Ogren and Steven J. Bethard.
2009.
Building test suites for UIMA components.
SETQA-NLP ?09Proceedings of the Workshop on Software Engineering, Testing, and Quality Assurance for Natural LanguageProcessing, pages 1?4, June.109
