Modifying Beliefs in a Plan-Based Dialogue ModelLynn LambertDepartment of Computer and Information SciencesUniversity of DelawareNewark, Delaware 1971611 IntroductionPrevious models of discourse have inadequatelyaccounted for how beliefs change during a conversation.This paper outlines a model of dialogue which main-tains and updates a user's multi-level belief model asthe discourse proceeds.
This belief model is used in aplan-recognition framework to identify communicativegoals such as expressing surprise.2 Plans, Beliefs, and ProcessingMy plan-based model of dialogue incrementallybuilds a structure of the discourse (a Dialogue Model,or DM) using a multi-level belief model updated aftereach utterance.
The belief model contains the beliefs as-cribed to the user during the course of the conversationand how strongly each belief is held.Researchers \[1, 3, 5\] have noted that discourseunderstanding can be enhanced by recognizing a user'sgoals, and that this recognition process requires reason-ing about the agent's beliefs \[7\].
For example, in orderto recognize from utterance IS2 in the following dia-logue that the speaker has the communicative goal ofexpressing surprise at the proposition that Dr. Smithis teaching CIS360 and not just asking if Dr. Smith isteaching CIS420, it is necessary for the system to beable to plausibly ascribe to IS the beliefs that 1) Dr.Smith is teaching CIS420; 2) that this somehow impliesthat Dr. Smith is not teaching CIS360; and 3) that IPbelieves that Dr. Smith is teaching CIS360.ISI: Who is teaching CIS 360?IPl: Dr. Smith.IS2: Dr. Smith is teaching CIS 420, isn't she?IP2: Yes, she is.
Dr. Smith is teaching two courses.IS3: What time is CIS 360?My model ascribes these beliefs to IS as the discourseproceeds, anti uses the ascribed beliefs for recognizingutterances that involve negotiation dialogues.
Withoutthe ability to modify a belief model as a dialogue pro-gresses, it would not be possible to plausibly ascribe1) or 3), so it is unclear how recognizing expressionsof surprise would be accomplished in systems uch asLitman's \[5\] that recognize discourse goals but do notmaintain belief models.
IS2 also exemplifies how peoplemay have levels of belief and indicate those levels in theThis  mater ia l  is based upon  work supported by the NationalScience Foundat ion under  Grant  No.
IRI-8909332.
The Govern-ment  has certain r ights in this material .surface form of utterances.
Here, IS uses a tag questionto indicate that he thinks that Dr. Smith is teachingCIS420, but is not certain of it.
My belief model main-tains three levels of belief, three levels of disbelief, andone level indicating no belief about a proposition.My process model begins with the semantic rep-resentation of an utterance.
The effects of the surfacespeech act, such as a tag question, are used to suggestaugmentations to the belief model.
Plan inference rulesare used to infer actions that might motivate the utter-ance; the belief ascription process during constraint sat-isfaction determines whether it is reasonable to ascribethe requisite beliefs to the agent of the action and, ifnot, the inference is rejected.
Focusing heuristics allowexpectations derived from the existing dialogue contextto guide the recognition process by preferring those in-ferences that lead to the most coherent expansions ofthe existing dialogue model.The resultant DM contains astructure of the dia-logue at every point in the discourse, including three dif-ferent kinds of goals, each modeled on a separate level:the domain level models domain goals such as travel-ing by train; the problem-solving level, plan-constructiongoals such as instantiating a variable in a plan; and thediscourse level, communicative goals such as express.ing surprise.
Within each of these levels, actions maycontribute to other actions on the same level; for exam-ple, on the discourse level, providing background ata,asking a question, and answering a question all can bepart of obtaining information.
2 So, actions at each levelform a tree structure in which each node represents anaction that a participant is performing and the chil-dren of a node represent actions pursued in order toperform the parent action.
This tree structure allowsmy model to capture the relationship among several ut-terances that are all part of the same higher-level dis-course plan, which is not possible in Litman's model\[5\].
In addition, an action on one level may contributeto, or link to, an action on an immediately higher level.For example, discourse actions may be executed to at-tain the knowledge needed for problem-solving actionsat the middle level.This tripartite, plan-based model of discourse fa-2The DM is really a menta l  model  of intent ions \[7\] which im-plicitly captures a number  of intent ions that  are at t r ibuted  to thepart ic ipants,  such as the intent ion that  the part ic ipants followthrough with the subact ions that  are part  of p lans for act ions inthe DM.349cilitates recognition of changing beliefs as the dialogueprogresses.
Allen's representation f an Inform speechact \[1\] assumed that a listener adopted the communi-cated proposition.
Clearly, listeners do not adopt every-thing they are told (e.g., IS2 indicates that IS does notimmediately accept hat Dr. Smith is teaching CIS360).Perrault \[6\] assumed that a listener adopted the com-municated proposition unless the listener had conflict-ing beliefs, as in IS2.
Unfortunately, Perrault assumesthat people's beliefs persist so it would not be possiblefor Perranlt to model IS adopting IP's explanation inIP2.
I am assuming that the participants are involvedin a cooperative dialogue, so try to square away theirbeliefs \[4\].
Thus, after every Inform action, a speakerexpects the listener either to accept any claims that thespeaker made or to initiate a negotiation dialogue.
3 Ac-ceptance can be communicated in two ways.
Either thelistener can explicitly indicate acceptance ( .g., "oh, al-right"), or the listener can implicitly convey acceptance\[2\] by making an utterance which cannot be interpretedas initiating a negotiation dialogue.
Since both partiesare engaged in a cooperative dialogue in which beliefsare squared away, this failure to initiate a negotiation di-alogue by default indicates (implicit) acceptance of anyclaims not disputed.
This corresponds with a restrictedform of Perrault's default reasoning about the effects ofInform acts \[6\].
An example of implicit acceptance isconsidered in the next section.3 ExampleConsider the dialogue model given in Section 2.The process model infers from the first utterance that ISis executing a high level discourse action of Obtain.Info-Ref to determine who is teaching CIS360 and problem-solving actions of Insfanfiate- Var and Build-Plan in or-der to build a plan to take CIS360 so that IS may even-tually execute a domain action, Take-Course, to takeCIS360.
IS2 is recognized as an expression of surpriseat IP's answer since acceptance or negotiation of theanswer is expected and since the following beliefs canbe ascribed to IS: 1) as a default rule, that teachersgenerally teach only one course; 2) that Dr. Smith isalready teaching CIS420 (from the tag question form);and 3) that the combination of 1) and 2) implies thatDr.
Smith is not teaching CIS360.
IP responds by try-ing to make her answer believable and to resolve theconflict.
This is done by informing IS that his beliefabout Dr. Smith teaching CIS420 is correct, but thatDr.
Smith is an exception to the default rule.Focusing heuristics uggest explicit acceptance ofor objection to IP~ as ways to continue the current dis-course plan.
However utterance IS3, instead, pursues a3A third possibility exists: that the participants agree to dis-agree about a particular point, and continue the dialogue.
Mymodel  will handle this also, but it is not preferred, and for spacereasons will not  be considered further here.completely new discourse action, Obtain-Info-Ref, un-related to the original Obtain-Info-Ref, though still re-lated to the problem-solving action of Instantiate-Varin order to build a plan to take CIS360.
Since a newdiscourse plan is being pursued, the process model in-fers by default hat IP2 has been accepted because oth-erwise IS would have initiated a negotiation dialogue.Since the inform action is accepted (implicitly), this ac-tion, and the higher level actions that it contributes to,are considered to be successfully completed, so the goalsand effects of these plans are considered to hold.
Someof the goals of these plans are that 1) IS believes thatDr.
Smith teaches both CIS360 and CIS420, and thus isan exception to the default rule that teachers only teachone course and 2) IS knows that Dr. Smith is the facultymember that teaches CIS360, the answer to the originalquestion that IS asked.
Once the process model recog-nizes IS3 as pursuing this new Obtain-Info-Ref action,the belief model is updated accordingly.4 Conc lus ionPrevious models of dialogue have inadequatelyaccounted for changing beliefs of the participants.
Thispaper has outlined a plan-based model of dialogue thatmakes use of beliefs currently ascribed to the user, ex-pectations derived from the focus of attention in the di-alogue, and implicit or explicit cues from the user bothto identify communicative goals and to recognize altereduser beliefs.Re ferences\[1\] James F. Allen.
A Plan-Based Approach to Speech ActRecognition.
PhD thesis, University of Toronto, Toronto,Ontario, Canada, 1979.\[2\] S. Carberry.
A pragmatics-based approach to ellipsis res-olution.
Computational Linguistics, 15(2):75-96, 1989.\[3\] B. Grosz and C. Sidner.
Attention, intention, andthe structure of discourse.
Computational Linguistics,12(3):175-204, 1986.\[4\] Aravind K. Joshi.
Mutual beliefs in question-answer sys-tems.
In N. Smith, editor, Mutual Beliefs, pages 181-197, New York, 1982.
Academic Press.\[5\] D. Litman and J. Allen.
A plan recognition model forsubdialogues in conversation.
Cognitive Science, 11:163-200, 1987.\[6\] R. Perrault.
An application of default logic to speechact theory.
In P. Cohen, J. Morgan, and M. Pollack,editors, Intentions in Communication, pages 161-185.MIT Press, Cambridge, Massachusetts, 1990.\[7\] Martha Pollack.
A model of plan inference that distin-guishes between the beliefs of actors and observers.
InProceedings of the ~th Annual Meeting o;f the Associa-tion for Computational Linguistics, pages 207-214, NewYork, New York, 1986.350
