Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1584?1589,Seattle, Washington, USA, 18-21 October 2013. c?2013 Association for Computational LinguisticsPair Language Models for Deriving AlternativePronunciations and Spellings from Pronunciation DictionariesRussell BeckleyOregon Health and Science Universitybeckleyr@ohsu.comBrian RoarkGoogle Inc.roarkbr@gmail.comAbstractPronunciation dictionaries provide a readilyavailable parallel corpus for learning to trans-duce between character strings and phonemestrings or vice versa.
Translation models canbe used to derive character-level paraphraseson either side of this transduction, allowingfor the automatic derivation of alternative pro-nunciations or spellings.
We examine finite-state and SMT-based methods for these relatedtasks, and demonstrate that the tasks havedifferent characteristics ?
finding alternativespellings is harder than alternative pronunci-ations and benefits from round-trip algorithmswhen the other does not.
We also show thatwe can increase accuracy by modeling sylla-ble stress.1 IntroductionRobust processing of speech and language requiresdealing with variation in language production, ei-ther in terms of pronunciation in the spoken domainor spelling in the written domain.
Predicting theintended words of an acoustic or textual sequenceis an important recognition task, often required fordownstream processing such as spoken language un-derstanding or knowledge extraction.
Informal textgenres, such as those found in social media, sharesome characteristics with speech; in fact such text isoften informed by pronunciation variation.
For ex-ample, consider the following tweet:He aint gotta question my loyalty, cuz he knwwen sh!t get real.
Ill be right here!where several tokens (e.g.
?cuz?, ?wen?)
representspelling alternations related to pronunciation.
Workin text normalization and spelling correction ?
e.g.,Toutanova and Moore (2002); Li and Liu (2012) ?has included pronunciation information to improverecognition of the intended word, via grapheme tophoneme (g2p) conversion modeling derived frompronunciation dictionaries.Pronunciation dictionaries provide natural par-allel corpora, with strings of characters paired tostrings of phones.
Thus, standard lexicons havebeen used in recent years with machine transla-tion systems such as Moses (Koehn et al 2007),to train g2p systems (Laurent et al 2009; Gerosaand Federico, 2009).
Further, other algorithms us-ing such dictionaries also use translation phrasetables, but not for translation tasks.
For exam-ple, data-driven paraphrasing methods (Bannard andCallison-Burch, 2005) use translation phrase-tablesas a ?pivot?
to learn sets of phrases which trans-lated to the same target phrase.
In a similar manner,with a pronunciation dictionary instead of a phrse-table, pivoting can be used to learn alternative pro-nunciations (Karanasou and Lamel, 2010), i.e., di-rect phoneme-to-phoneme (p2p) ?translation?
sys-tems that yield alternative pronunciations.
Alterna-tively, round-trip translation could be used, e.g., tomap from letter strings to phone strings in one step,then from the resulting phone strings to letter stringsin a second step, as the means to find alternativespellings (Li and Liu, 2012).In this study, we explore dictionary-derived mod-els to find either alternative pronunciations or alter-native spellings, using either direct (p2p or g2g) orround-trip algorithms (p2g2p or g2p2g).
We com-pare methods based on weighted finite-state trans-ducers (WFST) with phrase-based models trainedwith Moses.
Our main interest is to evaluate Karana-sou and Lamel (2010) methods ?
shown to be usefulfor deriving alternative pronunciations ?
for deriv-ing alternative spellings, and thus to determine therelative difficulty of these two tasks.
We also exam-ine when, if ever, round-trip processing yields ben-efits over direct transduction.
Our results indicatethat real alternative pronunciations are substantiallyeasier to find than real alternative spellings, partic-1584ularly when pronunciation features such as syllablestress are available.
Second, round trip translationyields no gain (and some loss) over direct transduc-tion for finding alternative pronunciations, yet yieldssome modest gains for finding alternative spellings.Further, WFST methods perform as well as or bet-ter than Moses trained models.
Finally, combiningthe methods yields further gains, indicating that themodels are learning complementary sets of patterns.The primary contribution of this work is to in-troduce a competitive method of building and us-ing pair language model WFSTs for generating al-ternative spellings and pronunciations which reflectreal-world variability.
This could improve results fordownstream processes, e.g., epidemiological studies(Chew and Eysenbach, 2010) or sentiment analysis(Barbosa and Feng, 2010) derived from social me-dia text.
Further, we present a controlled compari-son between the two tasks, and demonstrate that theydiffer in terms of task difficulty2 Related workText normalization has been a major focus in text-to-speech (TTS) research for many years.
Notably,Sproat et al(2001) deemed it a problem in itself,rather than ad hoc preparatory work, and definedmany of the issues involved, as well as offering a va-riety of initial solutions.
Similar approaches apply toautomatic spelling correction, where Toutanova andMoore (2002) extended the noisy channel spellingcorrection method of Brill and Moore (2000), bymodeling pronunciation alternations to infer frommisspellings to correct spellings.
Similarly, Li andLiu (2012) extended the character-based translationapproach to text normalization of Pennell and Liu(2011), by adding an additional round-trip trans-lation to-and-from pronunciations.
Karanasou andLamel (2010) used Moses to generate alternativepronunciations from an English dictionary, usingboth direct and round-trip methods.
They validatedtheir systems on a set of words with multiple pro-nunciations, measuring the degree to which alterna-tive pronunciations are generated from one of thegiven pronunciations.
Our task and method of eval-uation is similar to theirs, though we also look atalternative spellings.3 MethodsTo generate alternative spellings and pronunciations,we built phrase-based translation and finite-statetransduction models from a parallel corpus.
Whenpronunciations were part of the model ?
i.e., notdirect grapheme-to-grapheme ?
we included condi-tions with and without vowel stress.3.1 CorpusOur training corpus is the CMU Pronouncing Dictio-nary1, which contains nearly 130k entries.
From thiscorpus, we identified homophone sets, i.e., sets ofmultiple spellings sharing the same pronunciation,such as ?colonel?
and ?kernel?.
We found 9,977such sets, and randomly selected 1000 for testing;the rest we used for training.
Each set had, on aver-age, 2.46 members.
We also identified homographsets, i.e., sets of multiple pronunciations all spelledthe same, such as potato (/potato/ and /p@teto/).
Wefound 8,216 such homograph sets, and randomly se-lected 1000 for testing; the rest we used for training.These sets averaged 2.13 members.We construct seven parallel training corpora fromthe lexicon, each disjoint from its relevant testset.
For round-trip models, the parallel corpus iseach grapheme string in the lexicon aligned withits phoneme string, if neither the grapheme stringnor phoneme string appear in the test set.
Thereare four such corpora, corresponding to these op-tions: stress or no stress, and g2p2g or p2g2p.
Theg2p2g and p2g2g conditions require different cor-pora because they are differently partitioned for test-ing.
For direct grapheme-to-grapheme training sets,non-homophone words are self-aligned; for homo-phones, from each homophone set, each possiblepair of spellings are aligned.
For example, for apronunciation with four spellings?a, b, c, and d?there would be six alignments: a:b, a:c, a:d, b:c, b:d,c:d. Similarly for direct phoneme-to-phoneme train-ing sets, non-homograph words are self-aligned;words from the training homograph sets are pairwisealigned in all pairings.
There are two direct p2p cor-pora: with and without stress.3.2 Phrase-based translation modelsAs a baseline system, we used the Moses statisti-cal machine translation package (Koehn et al 2007)to build grapheme-based and phoneme-based trans-lation systems, using a bigram language model.2These are trained on the parallel corpus resultingfrom the homophone or homograph sets detailed in1http://www.speech.cs.cmu.edu/cgi-bin/cmudict2Higher order language models yielded no improvements.1585the previous section for the direct methods.
For thispaper, we did not perform round-trip translation withMoses, rather present it as a baseline for the directapproach.3.3 Pair language modelsOur weighted finite-state transducer approach isbased on pair language models (Bisani and Ney,2008; Deligne and Bimbot, 1997; Ghoshal et al2009), or, more recently, (Sagae et al 2012).)
Thebasic idea in a pair LM is to align strings, then train alanguage model over sequences whose symbols arethe input:output pairs of the alignment.
This lan-guage model can then be converted to transducers.For a g2g example, homophones ?their?
and ?there?are aligned via the standard Levenshtein edit dis-tance algorithm as ?t:t h:h e:e i: r:r :e?.
A trigrammodel over these x:y strings would use standard n-gram modeling to estimate, for example, P(:e | i:r:r); i.e., the probability of a silent ?r?
in a given con-text.Building the pair language model transducers re-quires two phases.
In the first phase we create newcorpora by aligning the elements of the parallel cor-pora outlined above.
In the second phase we usethese corpora of string alignments to build a pair lan-guage model.3.3.1 Alignment and Corpora BuildingWe use extensions to the Levenshtein edit dis-tance algorithm to align g2g, p2p and g2p strings,with substitution matrices created to provide use-ful alignments (Wagner and Fischer, 1974).
As inBrill and Moore (2000), we allow for certain multi-symbol strings to be substituted with a single cost,e.g., substituting ?th?
with /?/ in g2p alignment.
Forg2g alignment, our substitution cost is 0 for identityand 2 for a few pairs of commonly interchangeablegraphemes, such as ?c?
and ?k?.
Other substitutionsare not permitted, and delete and insertion have cost10.
For p2p alignment there are two conditions, withand without stress.
Without vowel stress, no substi-tutions other than identity are allowed; with vowelstress, substitution cost is 2.5 for the same vowelwith differing stress; and 5.0 if substituting a vowelwith another vowel.
Other substitutions are not per-mitted, and, again, delete and insertion have cost 10.For training round-trip models, we have to per-form g2p and p2g alignment, with differing al-phabets on the input and output of the alignment.We begin with a basic substitution table that al-lows graphemes and their most likely phonemes toalign.
We then re-estimate the substitution costsbased on relative frequency estimation (-logP), andalso aggregate sequences of consecutively deletedgraphemes so that they collectively map to a singlephoneme.
For example, given the alignment ?o:/a/u:// g:// h:// t:/t/?, (?ought?, /at/), we make a newrule: ough:/a/, and give it a cost based on its rela-tive frequency.
Grapheme strings that appear suffi-ciently often with a given phoneme will thus accu-mulate sufficient probability mass to compete.Each alignment produced as described above is astring in a training corpus for creating a pair lan-guage model.
As such, each alignment pair (e.g.a:/@/) is a token.3.3.2 From Corpora to WFSTsWe use the open source OpenGrm NGram library(Roark et al 2012) to build 5-gram language mod-els from the strings of input:output pairs.
These lan-gauge models are encoded as weighted finite-stateacceptors in the OpenFst format (Allauzen et al2007).
We shrink the models with the ngramshrinkcommand, using the relative entropy method (Stol-cke, 1998), with the ?theta?
threshold set at 1.0e?6.These finite state acceptors are then converted intotransducers by modifying the arcs: split the labelsof each arc, x:y, making x the input label for thatarc, and y the output label.
Thus traversing suchan arc will consume an x a return a y.
Such pairlanguage models we use for all WFST methods dis-cussed here.3.4 Producing k-best outputEach tested input string, spelling or pronunciation,is encoded as a cost-free linear chain WFST andcomposed with a pair language model transducer de-scribed in the previous section.
The resulting latticeis converted to an acceptor by projecting onto its out-put labels, i.e., for each arc, the input label is set tothe value of the output label.
Epsilons are then re-moved and the result is determinized.
The k-bestpaths are extracted using the shortest path algorithmin the OpenFst library.For direct models (g2g and p2p), the k-best out-put from this first transduction is our result, rankedaccording the probability of each path.
For round-trip methods (e.g.
g2p2g), however, we do a secondtransduction in the other direction.
For example, for1586g2p2g, the first transduction would have transducedfrom a spelling to a set of candidate pronunciations;the second transduction will transduce from pronun-ciations to spellings.
For this second transduction,we take each string s from the k-best list from thefirst transduction, and process them as we did in thefirst transduction, now using the inverse transducer.So, for each s in the first k-best list, we now have a k-best list from the second transduction.
Thus, for theoriginal input string, we have up to k2 alternatives.Finally, we score each alternative by combining theirscores from both transductions.Let p?
represent a phoneme string, and g?
agrapheme string.
If we perform a transduction fromp?
to g?, the weights from the transducer provide the(negative log) joint probability P(p?, g?).
By perform-ing a soft-max normalization over the k-best list out-put, we obtain the (negative log) conditional proba-bility P(g?
| p?).
For round-trip methods, we take theproduct of the conditional probability in each direc-tion, and marginalize out the intermediate graphemesequence, i.e.,P(p?2 | p?1) =?g?P(p?2 | g?)
P(g?
| p?1).4 Experimental resultsFor evaluation purposes, we reserved a set of 1000test homophone sets and 1000 test homograph sets,as described in Section 3.1.
From each set, we gen-erate alternatives from the longest set member (tiesbroken alphabetically) and examine the resulting k-best list for presence of other members of the set.Note that the input string itself is not a target, and,before evaluation, is removed from the k-best list.Recall is the proportion of the k-best list returned bythe system:Recall({k-best}) =| {k-best} ?
{gold-list} || {gold-list} |.Results for generating alternative pronunciationsare listed in Table 1; those for generating alternativespellings are in Table 2.
For alternative spellings,we also present results that combine the outputs ofdirect, round-trip (no stress) and Moses into a sin-gle list using a simple ranked voting scheme (simpleBorda count).A noteworthy result is the apparent usefulness ofstress modeling for predicting pronunciation varia-tion using WFSTs with the direct method; this isRecall: Alternative Pronunciationsk- pair language model Mosesbest Direct Roundtrip Directsize stress none stress none stress none1 0.43 0.54 0.38 0.37 0.44 0.463 0.77 0.71 0.59 0.58 0.60 0.625 0.82 0.77 0.66 0.66 0.64 0.6510 0.86 0.80 0.73 0.76 0.68 0.69Table 1: Recall for generating alternative pronunciationsseen in the first two data columns of 1.
This sug-gests that stress has an effect on phoneme alteration,something we discuss in more detail in Section 5.However, while providing a large gain in the p2pcondition, pronunciation modeling gives small ornegative effects elsewhere.
In the round trip meth-ods, the effects of stress are lost: stress has littleinfluence of how a particular phoneme is spelled.Thus, graphemes do not retain much stress informa-tion, hence any pass through the orthographic do-main will shed it.Recall is higher for alternative pronunciationsthan for alternative spellings.
One reason for thisis that spellings in our test set average eight let-ters, whereas the pronunciations average around fivephonemes.
Furthermore, the average Levenshteindistance between original spellings and their tar-get alrnatives, is 2.6, while for pronunciations, itis 2.2.
Combining these factors, we see that, forspellings, more edit operations are required, andthere are more symbols to which to apply them.Therefore, for spellings, there are more incorrectcandidates.The results also show gains resulting from theroundtrip method when applied to finding alternativespellings, but no such gains when roundtrip methodsare applied to alternative pronunciations.
Suppose,when seeking alternatives for some spelling, we al-ter grapheme g1 to g2.
With a direct method, wemust have instances of g1 mapping to g2 in the train-ing set.
The roundtrip method, however, is less con-strained: there must exist some phoneme p1 in thetraining set such that g1 maps to p1, and p1 maps tog2; thus, the set of possible alternations at testing are{g1 ?
p1} ?
{p1 ?
g2}.
This argument also ap-plies to finding alternative pronunciations.
Thus theroundtrip method offers more possible mappings.These extra possible mappings may be helpful orharmful, depending on how likely they are comparedto the possible mappings they displace.
Why arethey helpful for alternative spellings, but not for al-1587Recall: Alternative Spellingsk- pair language model Moses Comb.best Direct Roundtrip Direct Directsize none stress none none none1 0.19 0.19 0.19 0.20 0.303 0.36 0.38 0.37 0.39 0.525 0.45 0.49 0.48 0.48 0.6010 0.55 0.63 0.62 0.60 0.69Table 2: Recall for generating alternative spellingsternative pronunciations?
We discuss one possibleexplanation in Section 5.Comparing Moses to the pair language modelmethods, Moses does slightly better for smaller n(n = 1, 3), and slightly worse for larger n (n = 10).Our only partial explanation for this is that Mosesdoes well at weighing alternatives but, possibly, doesnot generate a large number of viable alternatives.System combination yields solid gains in finding al-ternative spellings, demonstrating that these differ-ent systems are coming up with diverse options.Finally, we note that many of the false positivepronunciations given by the WFST system are plau-sibly correct although they are not included in theCMU dictionary.
For example, for the spelling, ad-equate, the CMU dictionary provides two pronun-ciations: /?d@kw@t/ and /?d@kwet/.
Meanwhile,the p2p WFST system (with stress modeling) pro-duces /?d@kwIt/.
This suggests that we can learnfrom CMU dictionary to predict actual pronuncia-tions that CMU dictionary does not itself list.5 Discussion and SummaryThe experimental results demonstrated the utility ofstress modeling for generating alternative pronunci-ations, which we suggested was due to the impact ofstress on phoneme alternation.
To examine this moreclosely, we looked at each phoneme, stress class,(ph, s)?e.g.
(/@/, primary)?and determined howlikely is an occurrence of (ph, s) to have an alter-native phoneme in a homograph set.
We found thatprimary and secondary stressed vowels had an alter-ation probability of 0.017, while non-stressed vow-els had an alteration probability of 0.036.
This dif-ference should be picked up in the transition proba-bilities of our WFSTs, resulting in a preference foralterations of unstressed vowels.
This is analogousto results found in (Greenberg et al 2002) for spon-taneous American English discourse.
A further anal-ysis of the system output might shed more light onrelationships between stress and phoneme choice.Why are round-trip methods useful for finding al-ternative spellings but not for finding alternative pro-nunciations?
One possible explanation is that thevariety of orthographic alternations is greater thanthat of pronunciation alternations.
Thus, the train-ing set for spelling may provide less relative cover-age of the alternations in its test set than the trainingset for pronunciation provides for its test set.
Thisis supported by the fact that pronunciation recall ex-ceeds spelling recall.
The roundtrip method allowsfor finding mappings not seen in training.
These ex-tra mappings might be no better for spelling thanthey are for pronunciation, but for spelling, the map-pings they replace in the k-best list are worse, sothey yield an improvement.
For pronunciation, themappings they replace in the k-best list are better,so they yield a loss.
Further research is required tovalidate this explanation.Ultimately, we would like to apply these meth-ods to the normalization of social media text, espe-cially to find alternative spellings based on alterna-tive pronunciations.
To apply such methods to, say,Twitter normalization requires a sizable corpus map-ping canonical spellings to non-standard spellings.To assess domain portability, we applied a modelbuilt from the CMU dictionary to just over 100 al-ternative spellings observed in a small Twitter col-lection.
Using the direct g2g method, we generatedalternative spellings from the canonical spelling ofeach term, and measured the recall of the output, i.e.,whether the observed alternatives were present in thek-best list.
Recall was extremely low (less than 5%),suggesting that the type of orthographic alterationsthat are found in dictionary pronunciations are verydifferent from the orthographic variations found onTwitter, and that those differences have a profoundeffect on our ability to recover alternatives.In sum, we have presented a small study ofthe utility of pronunciation dictionaries for findingspelling and pronunciation alternatives, demonstrat-ing key differences between these tasks.AcknowledgmentsThis work was supported in part by NSF grant#BCS-1049308.
Any opinions, findings, conclu-sions or recommendations expressed in this publica-tion are those of the authors and do not necessarilyreflect the views of the NSF.1588ReferencesCyril Allauzen, Michael Riley, Johan Schalkwyk, Woj-ciech Skut, and Mehryar Mohri.
2007.
OpenFst: Ageneral and efficient weighted finite-state transducerlibrary.
In Proceedings of the Twelfth InternationalConference on Implementation and Application of Au-tomata (CIAA 2007), Lecture Notes in Computer Sci-ence, volume 4793, pages 11?23.Colin Bannard and Chris Callison-Burch.
2005.
Para-phrasing with bilingual parallel corpora.
In Proceed-ings of the 43rd Annual Meeting on Association forComputational Linguistics, pages 597?604.Luciano Barbosa and Junlan Feng.
2010.
Robust senti-ment detection on twitter from biased and noisy data.In Proceedings of the 23rd International Conferenceon Computational Linguistics: Posters, pages 36?44.Maximilian Bisani and Hermann Ney.
2008.
Joint-sequence models for grapheme-to-phoneme conver-sion.
Speech Communication, 50(5):434 ?
451.Eric Brill and Robert C Moore.
2000.
An improved errormodel for noisy channel spelling correction.
In Pro-ceedings of the 38th Annual Meeting on Associationfor Computational Linguistics, pages 286?293.Cynthia Chew and Gunther Eysenbach.
2010.
Pan-demics in the age of twitter: content analysis oftweets during the 2009 h1n1 outbreak.
PloS one,5(11):e14118.Sabine Deligne and Frdric Bimbot.
1997.
Inference ofvariable-length linguistic and acoustic units by multi-grams.
Speech Communication, 23(3):223 ?
241.Matteo Gerosa and Marcello Federico.
2009.
Copingwith out-of-vocabulary words: open versus huge vo-cabulary asr.
In Proceedings of the IEEE InternationalConference on Acoustics, Speech, and Signal Process-ing (ICASSP), pages 4313?4316.A.
Ghoshal, M. Jansche, S. Khudanpur, M. Riley, andM.
Ulinski.
2009.
Web-derived pronunciations.
InProc.
ICASSP.Steven Greenberg, Hannah Carvey, and Leah Hitchcock.2002.
The relation between stress accent and pro-nunciation variation in spontaneous american englishdiscourse.
In In Proceedings of ISCA Workshop onProsody in Speech Processing (Speech Prosody 2002),Aix-enProvence.Panagiota Karanasou and Lori Lamel.
2010.
ComparingSMT methods for automatic generation of pronuncia-tion variants.
In Advances in Natural Language Pro-cessing, pages 167?178.
Springer.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran, RichardZens, et al2007.
Moses: Open source toolkit for sta-tistical machine translation.
In Proceedings of the 45thAnnual Meeting of the ACL on Interactive Poster andDemonstration Sessions, pages 177?180.Antoine Laurent, Paul Dele?glise, Sylvain Meignier, andFrance Spe?cinov-Tre?laze?.
2009.
Grapheme tophoneme conversion using an smt system.
In Proceed-ings of Interspeech, pages 708?711.Chen Li and Yang Liu.
2012.
Normalization of text mes-sages using character-and phone-based machine trans-lation approaches.
In Proceedings of Interspeech.Deana Pennell and Yang Liu.
2011.
A character-levelmachine translation approach for normalization of smsabbreviations.
In Proceedings of IJCNLP, pages 974?982.Brian Roark, Richard Sproat, Cyril Allauzen, MichaelRiley, Jeffrey Sorensen, and Terry Tai.
2012.
TheOpenGrm open-source finite-state grammar softwarelibraries.
In Proceedings of the ACL 2012 SystemDemonstrations, pages 61?66.Kenji Sagae, Maider Lehr, Emily TuckerPrud?hommeaux, Puyang Xu, Nathan Glenn, Dami-anos Karakos, Sanjeev Khudanpur, Brian Roark,Murat Saraclar, Izhak Shafran, Daniel M. Bikel,Chris Callison-Burch, Yuan Cao, Keith Hall, EvaHasler, Philipp Koehn, Adam Lopez, Matt Post, andDarcey Riley.
2012.
Hallucinated n-best lists fordiscriminative language modeling.
In ICASSP, pages5001?5004.
IEEE.Richard Sproat, Alan W Black, Stanley Chen, ShankarKumar, Mari Ostendorf, and Christopher Richards.2001.
Normalization of non-standard words.
Com-puter Speech & Language, 15(3):287?333.Andreas Stolcke.
1998.
Entropy-based pruning of back-off language models.
In Proc.
DARPA Broadcast NewsTranscription and Understanding Workshop, pages270?274.Kristina Toutanova and Robert C Moore.
2002.
Pronun-ciation modeling for improved spelling correction.
InProceedings of the 40th Annual Meeting on Associa-tion for Computational Linguistics, pages 144?151.Robert A Wagner and Michael J Fischer.
1974.
Thestring-to-string correction problem.
Journal of theACM (JACM), 21(1):168?173.1589
