Proceedings of ACL-IJCNLP 2015 System Demonstrations, pages 55?60,Beijing, China, July 26-31, 2015.c?2015 ACL and AFNLPA system for fine-grained aspect-based sentiment analysis of ChineseJanna LipenkovaAnacodejanna.lipenkova@anacode.deAbstractThis paper presents a pipeline for aspect-based sentiment analysis of Chinese texts inthe automotive domain.
The input to thepipeline is a string of Chinese characters;the output is a set of relationships betweenevaluations and their targets.
The main goalis to demonstrate how knowledge about sen-tence structure can increase the precision,insight value and granularity of the output.We formulate the task of sentiment analysisin two steps, namely unit identification andrelation extraction.
In unit identification,we identify fairly well-delimited linguisticunits which describe features, emotions andevaluations.
In relation extraction, we dis-cover the relations between evaluations andtheir ?target?
features.1 IntroductionWhereas most work on sentiment analysis, and es-pecially on less covered languages such as Chi-nese, is based on probabilistic models and theuse of general sentiment lexica, we believe thata holistic approach should also take into ac-count general linguistic knowledge.
On the onehand, this allows to leverage the results of severaldecades of research in theoretical linguistics.
Onthe other hand, the hard-coding of general prin-ciples of language structure allows us to create alinguistically adequate training space for furtherapplication of probabilistic models.In the following, we present the ?bottom-up?component of our sentiment system which buildsopinion representations by a progression alongthree levels - the lexical, the phrasal and the sen-tence level.
The system has been conceptualizedmanually and bootstrapped on a corpus of about 1mio.
automotive reviews with an average lengthof 135 Chinese characters.1We use a prebuilt lex-1The reviews were crawled from popular automo-icon with ca.
2000 entries which contains opin-ion words, their modifiers, car features as well asa large number of functional categories relevantfor the syntactic analysis of phrases and sentences.The performance of the system is evaluated on atestset of 800 annotated sentences.
In practice, thepresented model is complemented by a probabilis-tic model which performs topic and polarity clas-sification on the sentence and the document levels;this component will not be described below due tospace limitations.The basic assumption on which the modelbuilds is that language follows rules.
Many ofthese rules have been extensively studied in thelinguistic literature and have been taken to a levelof abstraction which allows for a straightforwardencoding.
Incorporating these rules spares us theconstruction of probabilistic models for the dis-covery of already established general knowledgeabout linguistic structure.
For example, it haslong been observed that Chinese phrase struc-ture is largely head-final (Huang 1982, Li 1990,i.
a.
): nominal modifiers precede their head nouns,whereas degree and negation adverbs normallyprecede the adjectives or verbs they modify.
Dueto the relative rigidity of word order in Chineseon the phrasal level, a small set of correspond-ing phrase-level rules achieves a high coverage onour dataset.
Rules do not perform as well on sen-tence level; nevertheless, some general observa-tions are possible: for example, AP targets precedetheir APs.
These high-level observations form thebasis of a sequence classifier which determineswhether a sequence of words between two syntac-tic phrases establishes or disrupts one of the targetrelations between these phrases.The paper is structured as follows: after a verybrief review of research on aspect-based senti-ment analysis (henceforth ABSA), we formulatetive sites: http://www.autohome.com.cn, http://auto.16888.com, http://auto.qq.com.55our task and, specifically, present the output for-mat of the system (Section 3).
In the second step,we briefly describe the categories used in our lex-ical resources (Section 4).
In the third step, wedescribe the three levels of processing (Section 5).Finally, we present the evaluation of our system(Section 6).2 Previous workABSA has been exploited as a refined alternativeto sentiment analysis on the sentence and the doc-ument level: whereas the latter targets the generalsentiment or polarity of a piece of text, ABSA out-puts a mapping from specific aspects of the dis-cussed topic to their evaluations.
Different ABSAapproaches have been exploited; thus, Popescuand Etzioni (2005) and Kim and Hovy (2006)present unsupervised algorithms for extracting as-pects and determining sentiment in review text.Ding et al.
(2008) and Liu (2012) describe ap-proaches based on rules of semantic compositionand distance metrics for the identification of rela-tions between aspects and their opinions.
Due tothe relatively fine granularity of the task, parsing-based approaches have been proposed to capturethe aspect/sentiment relations based on sentencestructure (Jiang et al.
2011, Boiy and Moens 2009,i.
a.).
Further, the SemEval-2014 task on ABSA(Pontiki et al., 2014) has been addressed with anumber of promising approaches and also signif-icantly contributed to a unified understanding ofABSA.Still, most research is focussed on the Englishlanguage; for Chinese, most approaches to senti-ment analysis are targeted on lexicon construction(e. g. Liu et al.
2013) or sentence/document-levelsentiment classification.2Only few contributionsaim at a finer-grained analysis at the aspect level(Ku et al.
(2009), Su et al.
(2008)).3 TaskThe goal of aspect-based sentiment analysis isto derive the opinions of a speaker about an entityand its features (Liu, 2012, p. 58).
In our frame-work, opinions can be subclassified into evalua-tions and emotions.
Evaluations express how theauthor evaluates a specific feature (e. g. good, ex-pensive), whereas emotions express how the au-2Cf.
Proceedings of the evaluation task on polarity anal-ysis organized by the Professional Committee of InformationRetrieval (????????????)
2008 - 2014.thor feels about a specific feature (e. g. to please,angry).We formulate the task in two stages - the iden-tification of syntactic units and the extraction ofrelations between the syntactic units.
Thus, givenan opinion statement on a specific product, we?translate?
the statement into a set of (feature,<evaluation|emotion > ) pairs in two processingsteps:1.
Build three sets of syntactic units F (fea-tures), EV (evaluations) and EM (emo-tions).
For convenience, we will use E =EM ?
EV in cases where the evalua-tion/emotion distinction is not relevant.2.
For each e ?
E, find whether it has an opin-ion target f ?
F .A word is in place about the semantic orga-nization of evaluations and emotions in our sys-tem.
It has long been observed that many evalu-ation words come with implicit features; for ex-ample, the evaluation beautiful implicitly containsthe feature VisualAppearance.
In order to preservethis meaning, we adopt a scalar representation ofevaluations (cf.
Kennedy and McNally (2005) fora linguistic analysis of scalar expressions): eval-uations are represented as pairs of a feature anda numerical value which ?maps?
the evaluationto some point on the feature scale [-3, 3].
Thus,beautiful gets the representation (VisualAppear-ance, 2), whereas ugly gets the representation (Vi-sualAppearance, -2).
Similarly, emotions are alsorepresented as pairs of the emotion concept and anumerical value representing the intensity of theemotion (e. g. angry: (Anger, 2)).The final mapping goes from sequences of fea-tures to numerical evaluations.
In a feature se-quence [f1, f2.
.
.
fn], features are ordered by thesubfeature relation, such that fi(with i > 0) is asubfeature of fi?1.
Consider the following featureexpression:(1) ???steering.wheel?DE?
?indicatorthe indicator of the steering wheelOur representation is [SteeringWheel, Indica-tor], whereby Indicator is interpreted as a subfea-ture of SteeringWheel.Further, implicit features that are contained inassociated evaluations are also ?moved?
into thefeature sequence:56(2) ???steering.wheel?DE??indicator?very??
?preciseThe indicator of the steering wheel is veryprecise.This sentence contains the evaluation ?precise?.According to the above description, it is decom-posed into a feature (Precision) and a positive eval-uation.
The feature is moved into the feature se-quence.
The resulting mapping is as follows:(3) [SteeringWheel, Indicator, Precision] ?+2Thus, instead of limiting ourselves to entitiesand restricted sets of their immediate features, weadapt a ?higher-order?
view and allow a hierarchi-cal feature sequence of arbitrary depth.
This struc-ture seamlessly integrates implicit features andflexibly captures any granularity that is intendedby the author of the text.
At the same time, thevalue of the evaluation is reduced to a single nu-merical value, which allows for a straightforwardaggregation of the final results.4 Lexical basisOut lexical resources contain functional and se-mantic categories.
Members of ?functional?
cat-egories (e. g. conjunctions, phrase-final markers)are only relevant for the syntactic analysis.
Se-mantic categories are relevant for the interpreta-tion of opinions.
The top-level semantic categoriesare:?
Features, e. g.
??
(?look?
), ??
(?seat?),??
(?color?)?
Evaluations:?
with implicit features, e. g.
??(?beautiful?
?
VisualAppearance), ??
(?cheap??
Price)?
without implicit features, e. g.
??
(?not bad?
), ??
(?ordinary?
), ???(?OK?)?
Emotions, e. g.
??
(?admire?
), ??
(?an-noying?)?
Degree adverbs and negation words, e. g.
??
(?very?),??
(?a little bit?),?
(?not?
)Each of these categories is in turn subclassifiedinto more fine-grained classes which capture in-formation about the linguistic use of the subclassmembers.5 Processing stepsFigure illustrates the in- and output, the threeprocessing steps as well as the resources involvedin these steps.5.1 PreprocessingWe use the third-party tool jieba3for word seg-mentation and POS tagging; both steps are cus-tomized in order to achieve a better performanceon domain- and task-specific data.
Specifically,the dictionary provided by the tool is inter-sected with a user-specified dictionary.
This user-specified dictionary contains all words from ourlexical resources.
The user-added words are anno-tated with customized POS tags, such as ?F?
forfeature, ?EV?
for evaluation etc.
The followingtwo examples depict the same sentence as outputby jieba without and with customization:(4) a. original jieba output without cus-tomization:??/vnrear.row??/nspace??/dalready?/vmake?/udDE?/dvery?
?/anot.bad?/ulPFV?/xThe rear space is already quite notbad.b.
after customization:????/Frear.space??/dalready?/vmake?/udDE?/Dvery?
?/EVnot.bad?/ulPFV?/xThe rear space is already quite notbad.Thus, we see that the two words ??
(?rearrow?)
and??
(?space?)
are merged into one wordin the customized output since this combinationoccurs frequently in automotive texts and has aquasi-lexicalized meaning; the resulting word getsour custom POS tag ?F?
(feature).
Further, thePOS tag of??
is changed from the original jiebatag ?a?
to the custom tag ?EV?
(evaluation).5.2 Unit identificationIn the next step, we identify phrasal units corre-sponding to features, evaluations, emotions.
Weuse a phrase rule grammar which is based on reg-ular expressions involving the POS tags of the3https://github.com/fxsjy/jieba57Figure 1: Overall architecture of the systemFigure 2: Phrasal analysis of the sentence?????????????words.
Figure 2 shows the parsed version of ex-ample (4b).In the following, we present some of the mostcommon phrase structures for features and evalu-ations/emotions that are used in our system.Feature phrases Besides simple NPs consistingonly of one feature word, the most frequent typesof feature phrases are phrases with nominal mod-ifiers, coordinated NPs and NPs with pronominalmodifiers:(5) NP modifier:??seat?DE?
?materialthe material of the seats(6) ?it?DE?
?designits design(7) ??front.row??/??(and)?
?rear.rowthe front and the rear rowEvaluation and emotion chunks The class ofevaluations consists of adjectives, whereas theclass of emotions consists both of adjectives andverbs.
However, evaluations and emotions get aunified treatment at the unit level, since Chinesestative verbs behave similarly to adjectives: theycan also be modified by degree adverbs, used incomparative constructions etc.Besides simple lexical units, the following arethe most frequent phrase types for the E class:(8) a. Verb or adjective preceded by nega-tion or degree adverb:?very?
?difficult.to.bearvery difficult to bearb.
Adjective followed by degree adverb:?small?PFV?a.bita bit smallEvaluations can be coordinated in various ways;for example, coordination can be expressed bysimple juxtaposition, with a comma or in the ?E1?
E2 construction:(9) a. juxtaposition / punctuation:??precise(?)(,)?
?flexibleprecise and flexible58b.
?
E1?
E2:?CONJ??precise?CONJ?
?flexibleboth precise and flexibleBesides, evaluations are often expressed by so-called ?possessed features?
: the evaluation valueis derived from the ?amount?
to which a feature ispossessed by the discussed entity:(10) ?NEG?have?
?vigornot vigorous5.3 Relation extractionAfter identifying the syntactic units of interest, weproceed with identifying sentence-level relationsbetween these units.
In the literature, there aretwo major approaches to the identification of rela-tions between evaluations and their targets.
On theone hand, some authors recur to parsing and iden-tify evaluation targets based on dependency rela-tions (Wu et al.
2009, Jiang et al.
2011, i.
a.).
Onthe other hand, distance metrics can be used (Dinget al., 2008; Liu, 2012).
Since we want to avoid theoverhead of full-fledged syntactic parsing, but alsowant to improve the accuracy of simple distancemetrics, we develop a sequence classifier whichdetermines whether a given sequence of words be-tween a feature and an evaluation/emotion phraseindicates a target relation.The two semantic relations of interest are thecauser and the theme relation.
Additionally, thesystem analyzes a third non-semantic relation ?the topic ?
which provides relevant discourse-structural information on the overall aspect dis-cussed in a sentence.The causer relation The causer relation is afairly well-delimited relation which describes thecauser of some state of event.
In our model, itis applied to emotions caused by specific features.In the most basic cases, the causer is expressed assubject of one of the causative verbs (?,?
etc.
):(11) ??power?CAUS?me??very??
?desperateThe power really makes me desperate.The theme relation The theme relation is ex-pressed differently for evaluations and emotions.In the case of evaluations, it can be realized as thesingle argument of an AP or the nominal head ofan adjectival modifier:(12) a.
Single argument of an AP:??design??particularly??
?fashionableThe design is particularly fashionable.b.
Nominal head of an adjectival modi-fier:??particularly??fashionable?DE?
?designa particularly fashionable designWith respect to emotions, the theme relation isonly relevant for verbs; the feature targets of ad-jectives are covered by the causer relation.
Thus,themes can be expressed as (possibly topicalized)objects of emotion verbs:(13) a.
Object in canonical postverbal posi-tion:?me?very??like?it?DE??
?designI like its design a lot.b.
Topicalized object:??design?very?
?like?,......The design, I like it a lot, ...5.4 Relation extractionIn the above examples, relations hold between ad-joined constituents and can thus be easily recog-nized.
However, in many cases, several words oc-cur between the evaluation/emotion and its target:(14) ????rear.row??space?already?make?DE??very?
?not.bad PFVThe rear space is already quite not bad.From our corpus, we bootstrap the most fre-quent sequences that occur between themes andemotions/evaluations, emotions and themes aswell as causers and emotions.
We then apply asimple classifier for the classification of unseen se-quences.6 EvaluationThe system is evaluated on a testset of 800 sen-tences annotated for feature, evaluation and emo-tion phrases and for relations between them.
Theannotation was carried out according to previouslydeveloped annotation guidelines; we worked with59Precision RecallF-phrases 87.43% 85.37%EV-phrases 89.21 % 84.29%EM-phrases 88.56% 85.32%Table 1: Results of unit identificationPrecision RecallF-EV relations - theme 89.2% 87.33%F-EM relations - theme 84.01% 83.10%F-EM relations - causer 86.49% 87.90%Table 2: Results of relation extractiontwo independent annotators - a native Chinese stu-dent without specialized linguistic knowledge anda non-native linguist with very good mastery ofthe Chinese language.
They proceeded in threesteps: at the phrase level, the total F-score of inter-annotator agreement was 91.3%.
The divergingitems were discussed with a third team memberto create a unified phrase-level annotation.
The re-viewed corpus was then annotated for relations be-tween opinion and their targets; in this step, inter-annotator agreement reached 93.4%.Table 1 shows the results achieved in unit iden-tification; table 2 shows the results achieved forrelation extraction on the test set with finalized an-notation of F/EV/EM phrases.7 OutlookWe have shown that the use of a prebuilt lexicontogether with the application of general languagerules allows to achieve a considerable accuracy inABSA for Chinese.
Currently, the presented sys-tem is being extended with a number of more com-plex sentence-level relations, specifically compar-ative structures and modal operators.
Further,ReferencesBoiy, Erik and Moens, Marie-Francine.
2009.
Amachine learning approach to sentiment analy-sis in multilingual Web texts.
Inf.
Retr.
12(5),526?558.Ding, Xiaowen, Liu, Bing and Yu, Philip S. 2008.A Holistic Lexicon-based Approach to OpinionMining.
In Proceedings of WSDM?08, WSDM?08, pages 231?240.Huang, James C.-T. 1982.
Logical relationsin Chinese and the theory of grammar.Ph.
D.thesis, MIT, Massachusetts.Jiang, Long, Yu, Mo, Zhou, Ming, Liu, Xiaohuaand Zhao, Tiejun.
2011.
Target-dependent Twit-ter Sentiment Classification.
In Proceedings ofACL?11 - Volume 1, pages 151?160.Kennedy, Christopher and McNally, Louise.
2005.Scale structure, degree modification, and the se-mantics of gradable predicates.
Language 81,345 ?
381.Kim, Soo-Min and Hovy, Eduard.
2006.
Extract-ing Opinions, Opinion Holders, and Topics Ex-pressed in Online News Media Text.
In Pro-ceedings of the Workshop on Sentiment andSubjectivity in Text, SST ?06, pages 1?8.Ku, Lunwei, Huang, Tinghao and Chen, Hsinhsi.2009.
Using Morphological and SyntacticStructures for Chinese Opinion Analysis.
InProceedings of EMNLP?09, pages 1260?1269.Li, Audrey Yen-Hui.
1990.
Order and Con-stituency in Mandarin Chinese.
Studies in Natu-ral Language and Linguistic Theory, Dordrecht:Kluwer Academic Publishers.Liu, Bing.
2012.
Sentiment Analysis and OpinionMining.Liu, Lizhen, Lei, Mengyun and Wang, Hanshi.2013.
Combining Domain-Specific SentimentLexicon with Hownet for Chinese SentimentAnalysis.
Journal of Computers 8(4).Pontiki, Maria, Galanis, Dimitris, Pavlopoulos,John, Papageorgiou, Harris, Androutsopoulos,Ion and Manandhar, Suresh.
2014.
SemEval-2014 Task 4: Aspect Based Sentiment Analy-sis.
In Proceedings of the SemEval?14, pages27?35, Dublin, Ireland: ACL and Dublin CityUniversity.Popescu, Ana Maria and Etzioni, Oren.
2005.
Ex-tracting Product Features and Opinions fromReviews.
In Proceedings of HLT & EMNLP?05,pages 339?346, Stroudsburg, USA.Su, Qi, Xu, Xinying, Guo, Honglei, Guo, Zhili,Wu, Xian, Zhang, Xiaoxun, Swen, Bin and Su,Zhong.
2008.
Hidden Sentiment Association inChinese Web Opinion Mining.
In Proceedingsof WWW?08.Wu, Yuanbin, Zhang, Qi, Huang, Xuanjing andWu, Lide.
2009.
Phrase Dependency Parsing forOpinion Mining.
In Proceedings of EMNLP?09,pages 1533?1541, Stroudsburg, USA.60
