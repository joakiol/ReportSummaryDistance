COMMUNICAT ING WITH MULT IPLE  AGENTS*Elizabeth A. Hinkelman and Stephen P. SpackmanDeutsches  l '~orschungszent rum f/it K f ins t l i che  ln te l l igenzS l ;uh lsatzenhausweg 3, 66123 Ger lmmyhinkelman@dtki.uni-sb.de, st phen@_acm.orgAbstractPrevious dialogue systems have focussed on dia.logues betwe(:n two agents.
Many ~q)plications,however, require conversations between severall)articipants.
This paper extends speech act deft-nitions to handle multi-agent conversations, basedon a model of multi-agent belief attr ibution withsome unique properties.
Our approach as |,lie ad-vantage of capturing a lnnnlmr of interesting phe-nomena in a straightforward way.Motivat ionThe rise of spoken language NI, P applications has le.dto increased inte.rest in such issues as real t ime pro--cessing and on-line error recovery.
But dialogue is aninherently online process; this manifests in such linguis-tic phenomena as turntaking \[Sacks et al, 1974\], repair\[Schegtoff et el., 1977\], and content grounding \[Chu:kand Schaefer, 1989\].
Grounding is the phenonlenonthat establishes shared beliefs, lbr which simply mak-ing or hearing an utterance does )tot suffice, It makeshearers into hill participants who actively signal suc-cess or failure of communication, as in this excltange:Steph: |;hat's friday at seven then.Lgnn : at, seven.Our long term goal is to show how, Ji'om the per-spective of a pattie|peril, one plans and acts in an envi-ronment with other communicating individuals, evenwhen those other individuals are not perfectly reli-able, and ewm when the groups involw~.d may be largeenough that it is impractical to model all participants.For examl)le, consider this familiar exchange, from thepoint of view of someone who remembers that |;tie nextgrou I) meeting is on tuesday:Jan : so we should dro I) the ram.
cancel tit('.meeting on thursday.Les tuesdayAll,; tuesdayLou yeah.Jan \[yes, right.Ilere both our sub jeer, and another participant of_fer a correction, which is confirmed by l,ou and by theoriginal speaker.
Other participants may I)e pre.sent.In this paper, we focus on the elfects of comnm-nicative actions on the particil)ant's model of the situ-at, ion.
In contrast with previous diMogue work, we are*The wm'k underlying this paper was suppovlx,.d by a re-si!al'(:h gratl(;, \])'KZ I'FW 9002 0, fl'om t, he Gel'tn&n thmdes-nfinisterium ffir 1,'orschung mid Technologie to the 1)FK1project DISCO.interested ill czuses whe.re there are more than threeagents, in a group of ten or more, it is hard to imagine.how a participant can track the beliefs and disbeliet~sof others accurately; it, may not even be practical totrack who they all are.The advantages of analysing natural language utter-elites ~us coilimnnicative actioi,s are by now well unde>stood; they serve to slmnnarise conversations for long-term storage \[Schupeta, t993\], as a basis for generation\[Moore and Paris, 1989\], in top--down prediction of ut-terance flmction and structure \[Alexanderssou el el.,1!
)94\], and most importantly, to provide a represen-tation of natural language utterances that is uniformwith that used in general facilities for planning andaction \[Allen, 1{)83\].We tollow \[Traum and l l inkehnan, 1992\] in regard-ing speech acts as fully joint actions between conver-sational participants.
Not only are joint speech actsco..operatively undertake.n, but they have at least nora-.|nelly.joint etDcts: if they complete but still fail to re-sult in shared goals or shared beliefs, this should beattr ibutable to politeness, dishonesty (of.
\[Perrault,1991)\]), or other social funelions.This perslmctiw; on speech act processing forces usto deal with issues of jointly hehl goals and beliefiq at aw.
'ry b~usic level.
These matters are by now quite well-studied, but analytic solutions from logical tirst primcipies tend to be relatiw;ly complex, yielding neitherperspicuous notations nor plausible computational orcognitive models.
In short, normative analyses are notnecessarily descriptive, ones.Aside from relatiw~ly involved calculations, thereare sew:ral sources of dilliculty:?
when nrultiple participants are involved, the nnm-I)er of 'belief spaces ) (patterns of modal embedding)tends to blow ul) rapidly;?
when the actual state of atl;~irs regarding the extentof others' knowledge is unknown (a~s is the ease \['oran online converse(renal participant) the nmnber ofcases to be considered can become large;,, when dealing with large organisations, ome form ofaggregate modelling I)ecomes an absolute necessity.Consider, for instanee, (;lie case in which you believethat the governnieut knows your iltcome, frol-n lash year.What you believe is not that each individnal govern-men|  mnl)loyee knows it, bnt that  anyone from tile taxdepartment, wl,ose 1)usiness it is to know, and whoactually wants to, will.
Thus we would typically as-~';ilnie that an employee of the tax department who,in a professional capacity, lnakes contact, with youraccountant, would actually have this information tohand.
We want to abstract away from the commuui-1191cation channels that make this possible while retainingthe availability of the conclusion; and we would ideallylike to do so in a manner consistent with the needs ofonline dialogue processing.In the next section we describe a method of repre-senting the information ecessary for processing mul-tiparticipant speech acts, one which treats groups asagents in their own right, and does so in such a waythat speech acts can operate on them naturally anddirectly.Corporate  Agents  and  At t i tudePropagat ionThe basis of our model is the corporate agent.
These'agents' represent groups, but, like individual agents,they may have beliefs (which we write BagentP ) andgoals (GagentP) ascribed to them directly.
Thus, theycan be thought of as intermediate in status betweensets of component agents and prototypical group mem-bers.
They differ from simple sets in three strikingways: first, they are intensional structures that may bedistinct even when co-extensive (as, for example, whenthe members of the marketing department form a vol-leyball team on tuesday nights); second, attitudes areascribed to them directly, and potentially at variancewith any attitudes we might a.scribe to their members,or other subagents (see the discussion section); andthird, that (other than perhaps in the case of a 'real',singleton agent) subsethood is not a sufficient condi-tion for subagency--some intramural volleyball teamsare clearly, as social entities, agents of the company,and others rather the reverse.While not in a position to make detailed psycho-logical claims, we believe that structures of this kindare compatible with what we know about the linguisticand cognitive handling of aggregates in other contexts.These corporate agents will be used to representboth long-term social groups and transient groups ofconversational participants.
(sfe~veJa~y~S also a subagent ~ 17 eryoncD_J =t U' U UFigure 1: AgentsIn the remainder of this paper we illustrate rela-tionships between agents with diagrams uch as that infigure 1.
Here the playing-card shapes represent agentsand the heavy lines connecting them the subagent rela-tion (_): the agents include the system itself (sec.Jan),the system's boss (Jan), Jan's office, their coworkerLes, their common corporate mployer (WidgetCorp),and another 'random' person, Steph, who does not be-long to WidgetCorp.
Later we will represent attitudesascribed to agents by small stlapes within the playingcards and their propagation by thin curved arrows be-tween them.Note that since we are discussing the system's ownrepresentation of the world, the double-bordered play-ing card really represents the system's elf-model andthe whole diagram the system; but we shall not be-labour the point here, assuming that information pass-es freely between the two.The model we use to compute the transfer of attitudesbetween agents is approximate, partly to simplify com-putation and partly because it is in any case unusualto have enough empirical data to compute an exact so-lution.
The same model (with parametric variation inthe domain knowledge) is applied to all the attitudesthe system ascribes to agents; in our present imple-mentation, these may be either beliefs or goals) Un-like representations based on conventional logics of be-lief, it does not introduce nested contexts unless theyare explicitly represented in the content of utterances(as would be the case with a sentence like "But Lynnthinks we should have the meeting anyway.
"), thoughextended reasoning processes may compatibly do so.In this simplified model, the propagation of atti-tudes is performed lazily, as determined by their se-mantic relevance to the varions agents involved.
Ide-ally, this judgment would derive from social world-knowledge and information about the purposes ofgroups; in our current implementation it is approxi-mated using a simple classification of corporate agents,participant roles and message topics into the domainontology.
Delays and chance are not modelled; all rel-evant attitudes are presumed to propagate betweenagents, subject to the following constraints:idgetCorp" ' " / \ ]  ~ i'"'"'"'">'x., impossible-/ / / .
.
",, 7L27 "?
"~_~'sec'Jan U Jan  OStephFigure 2: Common context constraint1Since our nlodel is not analytic we do not want or needa notion of 'knowledge': the system lacks direct access toempirical truth and to social consensus, and does not havethe cognitive sophistication to validate argmnents againststone independent notion of rationality.
In short, none ofthe usual theories of truth can in principle be made toapply.1192l.
Attitudes propagate only between superageut andsubagent (or vice-versa).
This stipulation anlountsto saying that comnmnication only occurs betweenagents in the presence of some common social con-text.
Of course, new corporations can be introducedwhen new social groups form.Thus in ligure 2, beliefs ascribed to WidgetCorpcan propagate to the subagents, Jan and Jan's elec-tronic secretary; but they do not reach Steph, whois not a subagent of WidgetCorp.
~ We use the con-vention that attitudes are drawn filled in if theyare known by direct evidence, hollow otherwise; andthat dotted structures are 'negated'---they do notarise ms drawn because they violate some constraintunder discussion.~ i  filet'Jan'''' conflicting prior J ~blocked- belief~____~sec'Jau W JanFigure 3: Propagation as default2.
Attitude propagation is only a default (the particu-lar choice of default logic need not concern us here).If there is direct evidence for ascribing a contraryattitude to an agent, propagation from an exter-nal som:ce is inhibited.
This property is crucial tomodelling dishonesty, negotiation, compromise, andatypical group members in general.Such blocking is illustrated in figure 3.
In thisease our model of Jan fails to inherit a goal fromotfice.Jan because it conflicts with another goal (thesquare box) for the ascription of which to Jan wehave prior independent evidence.3.
The system may never assume that its own attitudesantomatically propagate upwards to a snperagent.The ut)ward attitude propagation path models tt,eeffect of external agents independently attending totheir various communicative goals, but the systemnmst still plan--and execute- its own actions.Thus, in figure 4 the system--see.Jan-- is pro-hibited from simply assuming that its own beliet~ areshared by its employer, though those of fellow em-ployees would be propagated when otherwise consis-tent.
(Some hmnans seem to relax this constraint.
)2In order to place some limit on the promiscuity of atti-tude propagation, it seems best to insist that indirect rans-fer must occur through a siligle agent that is a transitiveSllper- or Sill)- agellt of both terniinal agents, Thus, evenif Jan and Steph both belonged to some peer of Widget-Corp with a similar seniantic domain, propagation wouldstill be not permitted along the resulting N-shaped path.Gonlmon membership n Everyone will not transmit beliefseithe.r, because its relewuice tilter is maximally restrictive./ffice.Jan / / , / /  \requires xplicit action 2U'"Figure 4: The exceptional natnre of self~ office.JanFigure 5: The need for speech4.
Nonce corporations, i troduced ynamically to rep-resent the temporary grouping of participants inan active conversation, ever inherit a titudes fromtheir subagents, but must acquire them <as the ef-fects of observable actions.
The idea here is thatwhile participating in (or directly observing) a con-versation, the system is in a position to observe theconstruction of the public record of that conversation\[Lewis, 1983\] directly, and this record consists exact-ly to the attitudes we wish to ascribe to tile conver-sational group itself.
In conversation even a new 'un-spoken understanding' should be based on inferencefi'om observed communication, and not just the sys-tem's private beliefs about other participants' views.The fact that we still permit conversationalgroups to inherit from superagents allows us to placea discussion within a social context that suppliesshared background a,ssumptions.
The fact that wepermit their subagents t,o inherit from them modelsthe actual adoption of information from the publicrecord by individual participants, including the sys-tem itself, without additional mechanism.Figure 5 depicts this situation: noncel, the coll-versational grouping, represents a shared social con-strnct distinct from our understanding of Jan's pri-vate views.
This allows us to deal gracefully withthe situation in which we, see.Jan, catch (or perhapseven conspire with) Jan in telling a lie.The most important property of this model of at-titude ascription is that the only belief spaces it imtroduces are those that are independently motivated1193by identified social groupings or the records of the ac~tual conversations in which the system participates.This reduces the chance that the system will becomemired in irrelevant structural detail, and specificallyavoids the 'spy novel' style of belief space nesting thatis characteristic of cla,ssical normative models.
Attri-bution by default inference allows an individual to berepresented as a member of several different groupsholding conflicting beliefs, and inheriting only thosebeliefs consistent with those represented as being heldprivately.The results are thus substantially different fromthose obtail, ed in classical ogics \[Allen, 1983; Krausand Lehmann, 1988; Appelt, 1985; Cohen andLevesqne, 1990\].
They differ from other path-basedalgorithms \[Ballim and Wilks, 1991\] in the provisionof semantic relevance conditions and in addressing theneed for shared attitudes by ascribing them directly togroups, rather than by maintaining complex accountsof which agents believe what.
This allows us to de-scribe and process conversational mechanics withontrecourse to nested (x believes that y believes that .
.
.
)belief spaces, though snch structures may remain nec-essary for other, less routine feats of cognition.In the next section we show how our model of at-titude ascription can be used to implement multipar-ticipant speech act processing.Mu l t ipar t i c ipant  Speech  ActsAs in \[Traum and Hinkelman, 1992\], we assume thata core speech act is ultimately realised by a sequenceof utterances that ernbody the grounding process.
Themodel requires thai; the definitions of the speech actsthemselves abstract away from grounding and providehigh level actions that can be integrated with non-linguistic domain actions in planning.
Using our multi-agent attitude attribution mechanism, we can simplifymatters fllrther, defining speech acts as joint actionswhose effects apply directly to the conversational groupbeing modelled.Consider the generalised action operator repre-senting one simple core speech act:Informal)conditions : BbPA b K aAl iveaeffects : BapThis Inform is a true joint action.
Agent a is thenonce corporation representing all the participants tak-en jointly (the live predicate requires that this noncecorrespond to an a ongoing conversation).
Though thesingleton subagent b is the source of the information,the action has its effect directly on our model of thegroup.
From that point propagation downwards to theindividual participants is a function of the attitude as-cription model, and is subject to the constraints giv-en above.
(The system effectively assumes that corre-sponding updates actually take place in the minds ofthe conversational participants.
)The correctness of this formulation relies on twofacts.
The first is that the grounding structure realis-3Our current implementation actually deals with (mailrather than live speech, and must cope with mul(.iple acl;ivedialogues.ing the core speech act operator ensures the content issuccessfully conveyed.
The second is that if a speechact that has an efl~ct on the conversational gronp isflflly realised and properly grounded, then any hearerwho dissents from those effects must explicitly act tocancel them.
That is, acknowledgement of receipt ofa message stablishes a presumption of assent to thecontent.
Note, however, that when the speech act re-mains unchallenged this means only that the conversa-tional participants will let it stand as part of the publicrecord; it does not mean that they are tndy persuadedof its content, and the rules we have given only pre-dict that they adopt it if there is no evidence to thecontrary.St, ecessful requests have effects on the goals ratherthan the beliefs of the group.
It is crucial that bothcommunicative and noncommnnicative are introduced.The first goal below is noncommunicative and repre-sents simply that the requested action be performed.Note that although the requested action's (possiblycorporate) agent participates in the dialogue, there isno restriction that it not include the requester.
Writ-ing B i fap for Bop V Ba~p and O for eventually, wehaveRequestaeconditions : agent e E a A live aeffe.cts : (~a<~ eA GaBi fa@ eThe second goal in the effects is a communicativeone; the group acquires the goal of finding out whetherthe requested action will be performed.
The conse-quence of this is that the requester gets an indicationof whether the request was successful: even lmder theassunrption of co-operativity, goal conflicts and planconstraints ometimes lead to the rejection of a suc-cessfully communicated request.In tile next section we describe how OOSMA, ourimplemented calendar management system, processesall actual exchange.P rocess ing  an  N-Way Speech  ActSpeech acts like the above can now fignre in the plan-and inference- based algorithms of communicative in-telligent agents.
Since dialogue may include unpredict-ed events, such agents must be able to react to chang-ing circumstances rather than relying completely onadvance planning.
As each incoming speech act ar-rives, the agent updates its beliefs and goals; these be-liefs and goals are the basis for subsequent action.
Thisis not only appropriate for the interface between taskand dialogue, but absolutely crucial for the groundingprocess.A typical application task for Noway speech actsin a multiagent environment is appointment schedul-ing, with dialogue systems erving as personal appoint-ment secretaries to human agents.
Our implementedsystem, COSMA, operates in this domain.
We modela human/secretarial pair as a kind of corporate agentin which beliefs about appointments propagate up anddown from both members, and in which goals aboutappointments propagate fl'om the hnman up to the pairand from there down to the secretary.When this example begins, the dialogue system1194(see.Jan) has the role of a personal aplmintment sec-retary to a human agent (Jan), forming the hu-man/secretarial corporation ofliee..hm.
Jan sendssec.aaa email text; referring to a pre-existing appoint-I nent :Jau: Cancel tit(', meeting with thehardware group.
\[--',sec.a an\]'\]_'he COSMA system interprets this input by firstconstructing a nonce corporation for the new dialogue,nonce1, withdan, see.Jan E nonce/ E ofl~ce.aanQ =GOcancel~e~.ja.meeting2 ~ office.Jani =G Blrn~*l~canc?l~'l=" meeling2- :~.
Transmission by core al~eech act i~  L _~ec.Jatl JanFigure 6: Making a requestAll members of a nonce corporation inherit belief~and communicative goals from it;.
The interpretationof the first utterance as a speech act is:Request{Jan, sec.Jan} Cancel sec.danmeeting2This interpretation is checked for consistency withcontext according to the method of \[llinkelmau, 1992\],and forms an acceptable reading.
Its effects on thegroup are asserted (Q, @ in figure 6):G norn:e l ~ ca heel see.dan meeting2G nonce l B i f  nonce l 0 cancelsec.3a n meeting2- _~of f i cc .
.
l au  ~ =(y ~'cancol 8ec,l~n l teetlllg 2I=GB r Ocancel  .
meethlg2A =Ocancol ~eaanltlemhng2//g,Figure 7: t/.espondingWhen it has finished processing all inputs, the sys-tem exalnines its own goals in order to determine whatactions, if any, it will perform.
It finds no immediatepriwtte goals, but there are two that it inherits.
Be-cause it is a participant; in the ongoing discussion withJan it inherits the nom'e's communicative goal g i f .
.
.
(@ in figure 7).
It also inherits the goal to ensurethat the cancellation actually does happen (@)4 (Aless compliant agent thau the current COSMA wouhlnot acquire non-communicative goals directly from thenonce, but would obtain the cancellation goal indirectlythrough office.Jan.
The implementation could be w.'rysimilar, because the indirect inheritance path can becompiled out when the nonce is initially constructed.
)The dialogue system thus retrieves the followinggoals:Gsec.Jan ~ canc elsec.Janmeeting2Gsec.,lanBifnoncel 0 cancelsec.danmeeting2These goals become input for the planning process.The first goal can be achieved in the current contextby ltrst opening the appointment file, then perform-ing a stored subplan \['or cancelling appointments hatincludes modifying the database ntry and notifyingthe participants.
Our reactive algorithm allows com-nlunicative phms to be freely embedded within domainactiotls, and vice versa.ltaving found this sequence of actions, the systemnow knows that the ~> ... part holds.
It is therefore ableto plan to Informnoncel(O ...), satisfying the secondgoal (@).
The output for the second goal is:hfformnoncel (O ca ned see.dan meeting2)see.,lan: Ok, I'll cancel it.
\[--~-3all\]WidgctCorpFigure 8: Informing the groupFinally, it must conlph.
'te the execution of its planto satisfy the first goal by updating the appointmentfile and notifying MI participants.
The notification stepinvolves constructing a suitable conversational I:tOltce,this time a descendant of WidgetCorp itself (in spoken dialogue this requires, aside front setting up thenecessary internal data structures, meeting the ad-dressees and greeting them; when communicating viaemail the analogous requirement is just composing asuit~ble mail message header).
Then, as show in figure8, the system initiates a further Inform action of itsOWll',Informnonce4 (-,7) meeting2)whk:h (:an be verbalised as follows:see.dan: The meeting of Monday, Feb. 13at 3 I'M will not take place.\[~sec.aan, Jan, gou, Le G Lee\]4Nol.e that if the system were asked, it could now inflwthat, Jan also has these goals, but tohat his is not part ofthe speech act interpretation algorithm itself.1195DiscussionAn important  property of the corporate agent modelpresented in this paper is its scaling behaviour.
Al-though the number of 'agents' in a nontrivial worldmodel may be large, we only introduce belief spacescorresponding to 'actual '  objects about which the sys-tem has knowledge.
In particular, the corporate agentsthat are used correspond to either durable social gronp-ings or records of actual conversations.
Individualspeech act definitions, though they acconnt for all theagents in the dialogue, need make reference to at mosttwo agents.In contrast with normative models, our speech actprocessing model at no point requires that individualaddressees be modelled.
Of course, dialogue is typical-ly motivated by the desire to modify the addressees'mental states, but our system is free to make theseupdates on demand.
Thus, so long as constructing de-tailed partner models is not independently necessary,the effort required to plan and respond to speech actsremains almost constant as the number of conversa-tional participants grows.We have thus achieved the extension of speechacts to multiagent environments, a step beyond otherspeech act based models\[Dols and van der Sloot, 1992;Meyer, 1992; Bunt, 1989; Traum and I l inkehnan,1992\].
In the process, we have reduced the complexityof the task/dialogue interface.WidgetCorp~ ~  ~' -  I nonce5Figure 9: WidgetCorp expandsAn interesting consequence of not needing to nlodel allmembers of a conversational group is that it becomesunnecessary to identify them.
While in some circum-stances this may be an advantage, it does leave thedoor open to an interesting litch: without an indepen-dent check, the system's model of who it is addressingmay turn out to be inaccurate.
A related thing canhappen when the system plans on the basis of attitudepropagation: it can perform an action that 'ought' toresult in a given agent's coming to hold some viewthrough social processes, but since social channels arequite imperfect, the message never gets through.
Hu-man agents are at times more cautious, and may mod-el delays in the grapevine, but this 'lost sheep' phe-nomenon occurs sufficiently ofl;en in real life to makethe utterance "Oh, I 'm sorry, I guess you weren't atthe meeting."
sound very familiar.Generalisatiou remains a hard problem, of course.Our system has no special advantages when faced witha question like "Are conservatives porcupine-lovers?
"Vague questions about large groups require extensivesearch or some independent theory of generalisation,and seem to be difficult even for hunians.Related to this is the Nixon diamond anomalyfaced by many default inference systems.
In our case,when we find propagation paths that will support theascription of contradictory attitudes to a single agent,how should we choose between them?
It turns out thatselecting whichever esult we first discover we wouldlike to use is a surprisingly good solution.
Such 'ar-bitrary'  judgments tend to facilitate the conversationby using the inference mechanism not to seek a reli-able proof but to find the most convenient supportableargument, regardless of actual truth.Perhaps the most interesting deviation of our modelfrom the behaviour of systems founded on mutual  be-lief is the social fiction anomaly: one can fairly e~i-ly reach a state in which an attitude is ascribed to acorporation which is held by none of its members.
In-credibly, this also corresponds to a familiar situation ineveryday life.
Three examples hould serve to il lustratethe point.
In the first place, consider this exchange, inwhich Jan asks Les to compile a tedious report:Jan: I'll need that on my desk by friday.Les: friday, no problem.Such a dialogue may occur even when Jan will nothave time to look at the report until the middle of thefollowing week, and Les knows that the work cannotpossibly be completed before the weekend.
'~Secondly, we propose the example of a couple whoare jointly but not severally on a diet.
When together,neither partner ever takes dessert, and this policy isverbally reinforced.
Yet either of' them will happily joinyou in eating a large slice of strawberry cheesecake, ifthey are apart.Finally, imagine that you are a lone bicyclist ap-proaching a Very Large Hill.
You might now say toyourself--a conversational nonce of one- -" I t ' s  not farto the top!"
Processing this speech act results in an-other unsupported belief.
You can now try to be con-vinced.In light of all of tile above anomalies, it begins to ap-pear that human agents may be struggling with limi-tations similar to those of our own model.It may still be objected that onr model falls shortin failing to support the detailed 'spy novel' reason-ing used in conventional logics of belief, keeping trackof whether Loll believes that Lee believes that p, andwhether or not common beliefs are truly mutual.
Ourresponse is threefold:* Reflective l)rol)lem solving is always an option, but inhumans appears to be an independent process.
Re-sponsiveness demands make it unsuitable for manda-tory online use m dialogue processing, though it maybe important to use models (like ours) with which itcan be integrated simply.
* Conversational mechanisms have evolved to copewith the cognitive shortcomings of humans, qb theSThe authors disagree as to whether t,his par~,iculm' pat-tern is more likely to arise througla malice or optinlism.7196extent that the pertBrmance rrors of a dialogueagent mirror huinan failings, co-operatiw.'
recov-ery performance wil;h hlltrla\[l communicative toolsshould be enhanced.?
Even given access to an ideal normative dialoguemodel, a fltll system would benetit li'om running aless precise and lnore descriptive model in parallel.This would a~ssist in isolating those parts of a com-municat ive plait where confllsioll on tim part of otheragents is predictable.Corporate agents are an alternative to normativelogics of belief which capture a mind)or of interestingsocial and commtmicative phenonmna straightforward-ly.
With their help, we can refornmlate core speech actdelinitions cleanly and seahd)ly tbr the case of nranyagents.
The level of planning abstraction that resultsseems well-suited to the needs of intelligent commu-nicative agents operating in an environment that in-.
(:htdes I/laity lnlnlall agents.Re ferences\[Alexandersson ctal., 1994\] Jan A lexandersson, l';lis-almth Maier, and Norbert l{eithinger.
A robustand eflicient three-layered ialog component for aspeech-to-speech translation system, subm.
(Jon-ference on Applied Natural Language Processing,Stuttgart, 1994.\[Allen, 1983\] James Allen.
ll.eeognizing intentionsfrom natural angm~ge utterances.
In Michael Bradyand l{obert C. Berwiek, editors, ComputalioualModels of Discourse.
MIT Press, 1983.\[Appelt, 198'5\] D. E. Appelt.
Planning English S'en-tences.
Cambridge University l'ress, Can,bridge,1985.\[Ballim and Wilks, 1991\] At~al Ballim and YorickWilks.
Arti\]icial Believers: The Aseriplion of He-lief.
Lawrence I';rlbaum Assoeiates~ 1991.\[Bunt, 1989\] II.
C. lhmt.
Information dialogues ascommunicative action in relation to t)artner mod-elling and inforntation l)roeessing.
In M,M Taylor,1".
Neel, and 1).
G. llouwhuis, editors, 7'he Struetm'eof Multimodal Dialogue.
Elsevier Science PublishersI / .V.,  :1989.\[Clark and Schaefer, 1989\] flerbert \[1.
('lark and l';dward F. Schaefer.
Contrilmting to discourse.
(,'oqui-live Science, 13:259 294, 1.98!/.\[Cohen and Lew'.sque, 11990\] Phillip R. Cohen audHector J. Levesque.
I'ersistence, intention, and eoln-mitment.
In P. R. Cohen, ,/.
Morgan, and M. E.Pollack, editors, Intentions in Communication.
MITPress, 1990.\[l)ols and van der Sloot, 1992\] I,'.
J. I1.
l)ols andK.
van der Sloot.
Modelling mutual elfi~et,; in beliet:based interactive systems.
In W. J.
Black, G. Sabah,and T. J. Wachtel, editors, Abduetion, Beliefs and(;ontext: Proeeedings of the seeotM 1'2,S'111117 ' PLUS'workshop in computational pra.qmatie.s, 1992.\[llinkehnan, 1992\] Elizabe.th A. ll inkehnan, intona-tion and the Request/(,~uestion l)istinetiou.
In Pro-ceedings of the h~ternational Co,fi~reuce on ,~,'pokenLanguage Processing, P, anlf, Canada, 19!12.\[Kraus and l,ehmann, :1988\] Sarit graus and DauMl,ehmann.
Knowledge, belief and time.
In "\['hcore&ical (Jomputer ,5'cieuce, vohune 58, pages 155-174,1988.\[Lewis, 198:t\] I).
Lewis.
Scorekeeping in a LanguageGame, volume 1, chapter.
13.
Oxford UniversityPress, Oxford, 1983. l)hilosophical Papers.\[Meyer, 1992\] lt.alph Meyer.
Towards a conceptualmodel of belief and intention in dialogue situations.In W. J.
Black, G. Sabah, and T. J. Wachtel, editors,Abduction, Beliefs and Context: PTveeedings of thesecond E,qPRIT PLU,q workshop in computationalpragmatics, 1992.\[Moore and Paris, 1989\] J.D.
Moore and C.L.
Paris.Planning text for advisory dialogues.
In Proe.
Confof the 27th Ammal Meeting of the ACL, pages 203-211, Varmouver, l !/8!
).\[Perrault, 1!
)90\] C. II.
l'erranlt.
An al)plication of de-fault logic to speech act theory.
In P. \[{.
Cohen,J.
Morgan, ~tnd M. E. Pollaek, editors, Intentions inCommunication.
MIT Press, 1990.\[Sacks et al, :1974\] 11.
Sacks, E.A.
Schegloff, and (I.A.Jef\[hrson.
A simplest systematies for the organi-zation of tin:n-taking in conversation.
Language,50:696 7a5, 1974.\[Schegloff el al., 1977\] E. A. Schegloff, G. .
le t ferson,and I I. Sacks.
The preference for self correction inthe organization of repair in conversation.
Language ,5:t:36l ,'t82, 1977.\[Schnpeta, :199:{\] Achinl W. Sclmpeta.
Cosma: F, inverteilter terminplauer als fidlstudie der verteiltenld.
In Jucrgen Mueller and l)onald ,qteinel:, ed-itors, lk'oopericrende A.qenten, Saarbriieken, Get:-many, 1!19:t.\[Tranln and llinkehnan, 19!12\] I)avid 11.. Traum andElizabeth A. Ilinkehnan.
Conversation acts in task-oriented spokeu dialogue.
Computational Intelli-gence, 8(:11:,575 .
99, 1992.
Special Issue on Non-literal language.1197
