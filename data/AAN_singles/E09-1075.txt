Proceedings of the 12th Conference of the European Chapter of the ACL, pages 657?665,Athens, Greece, 30 March ?
3 April 2009. c?2009 Association for Computational LinguisticsMeasuring frame relatednessMarco PennacchiottiYahoo!
Inc.Santa Clara, CA 95054pennac@yahoo-inc.comMichael WirthComputational LinguisticsSaarland University, Germanymiwirth@coli.uni-sb.deAbstractIn this paper we introduce the notionof ?frame relatedness?, i.e.
relatednessamong prototypical situations as repre-sented in the FrameNet database.
We firstdemonstrate the cognitive plausibility ofthat notion through an annotation experi-ment, and then propose different types ofcomputational measures to automaticallyassess relatedness.
Results show that ourmeasures provide good performance onthe task of ranking pairs of frames.1 IntroductionMeasuring relatedness among linguistic entitiesis a crucial topic in NLP.
Automatically assess-ing the degree of similarity or relatedness be-tween two words or two expressions, is of greathelp in a variety of tasks, such as Question An-swering, Recognizing Textual Entailment (RTE),Information Extraction and discourse processing.Since the very beginning of computational lin-guistics, many studies have been devoted to thedefinition and the implementation of automaticmeasures for word relatedness (e.g.
(Ruben-stein and Goodenough, 1965; Resnik, 1995; Lin,1998; Budanitsky and Hirst, 2006; Mohammadand Hirst, 2006)).
More recently, relatednessbetween lexical-syntactic patterns has also beenstudied (Lin and Pantel, 2001; Szpektor et al,2004), to support advanced tasks such as para-phrasing and RTE.
Unfortunately, no attention hasbeen paid so far to the definition of relatedness atthe more abstract situational level ?
i.e.
related-ness between two prototypical actions, events orstate-of-affairs, taken out of context (e.g.
the sit-uations of Killing and Death).
A prominent defi-nition of ?prototypical situation?
is given in framesemantics (Fillmore, 1985), where a situation ismodelled as a conceptual structure (a frame) con-stituted by the predicates that can evoke the situ-ation, and the semantic roles expressing the situa-tion?s participants.As measures of word relatedness help in discov-ering if two word occurrences express related con-cepts, so measures of frame relatedness shouldhelp to discover if two large text fragments are re-lated or talk about similar situations.
Such mea-sures would be valuable in many tasks.
For exam-ple, consider the following fragment, in the con-text of discourse processing:?In the 1950s the Shah initiated Iran ?s nu-clear research program and developed an ambi-tious plan to produce 23,000MW from nuclearpower.
The program was stopped by the IslamicRevolution in 1979, but it was revived later in thedecade, when strategic interests began to drive thenuclear program.
?The underlined words evoke highly relatedframes, namely ACTIVITY START, ACTIV-ITY STOP and CAUSE TO RESUME.
This couldsuggest to link the three textual fragments associ-ated to the words, into a single coherent discourseunit, where the semantic roles of the differentfragments can be easily mapped as co-referential(e.g.
?Iran?s nuclear research program?
- ?Theprogram?
- ?it?).
Frame relatedness can alsohelp in RTE.
Consider for example the followingentailment pair:Text : ?An avalanche has struck a popular skiingresort in Austria, killing at least 11 people.
?Hypothesis : ?Humans died in an avalanche.
?The frames KILLING and DEATH, respectivelyevoked by killing and died, are highly related andcan then be mapped.
Leveraging this mapping, anRTE system could easily discover that the Text en-tails the Hypothesis, by verifying that the fillers ofthe mapped semantic roles of the two frames aresemantically equivalent.657In this paper we investigate the notion of re-latedness in the context of frame semantics, andpropose different types of automatic measures tocompute relatedness between frames.
Our maincontributions can be summarized as follows: (1)We empirically show that the notion of frame re-latedness is intuitive and principled from a cogni-tive perspective: to support this claim, we reportagreement results over a pool of human annota-tors on the task of ranking frame pairs on relat-edness; (2) We propose a variety of measures forcomputing frame relatedness, inspired by differ-ent approaches and by existing measures for wordrelatedness; (3) We show that our measures offergood performance, thus opening the path to the useof frame relatedness as a practical tool for NLP,and showing that measures for word relatednesscan be successfully adapted to frames.
The paperis organized as follows.
In Section 2 we summa-rize related work.
In Section 3 we describe the ex-periment of humans ranking frame pairs, and dis-cuss the results.
In Section 4 and 5 we respectivelyintroduce our relatedness measures, and test themover a manual gold standard.
In Section 6 we drawfinal conclusions and outline future work.2 Related WorkMuch research in NLP has studied similarity andrelatedness between words.
Rubenstein and Good-enough (1965) were the first to propose a pro-cedure to assess human agreement on rankingpairs of words on relatedness.
Their experi-ment was later replicated by Resnik (1995) andCharles (2000).
All these studies reported goodlevels of agreements among annotators, suggest-ing that the notion of word relatedness is cogni-tively principled.
In our experiment in Section 3.2we apply the same procedure to assess agreementon ranking frames.Measures for estimating word relatedness havebeen systematically proposed since the early 90?s,and are today widely used in NLP for varioustasks.
Most measures can be classified either ascorpus-based or ontology-based.
Corpus-basedmeasures compute relatedness looking at the dis-tributional properties of the two words: words thattend to co-occur in the same contexts or havingsimilar distributional profiles, are deemed to behighly related.
A complete survey on these mea-sures is reported in (Mohammad and Hirst, 2006).Ontology-based measures estimate relatedness bystudying the path connecting the two words in anontology or a hierarchical lexicon (e.g.
WordNet).The basic idea is that closer words are more relatedthan distant ones.
Budanitsky and Hirst (2006)provide an extensive survey of these measures.Budanitsky and Hirst (2006) also point out animportant distinction, between relatedness andsimilarity.
Two words are related if any type ofrelation stands between them, e.g.
antonymy ormeronymy; they are similar when related throughan is-a like hierarchy.
Similarity is then a spe-cial case of relatedness.
Following Budanitsky andHirst (2006), we consider two frames as similar ifthey are linked via is-a like relations (e.g.
GET-TING and COMMERCE BUY), while as related ifany relation stands between them (e.g.
causationbetween KILLING and DEATH).
In this paper, wefocus our attention solely on the notion of framerelatedness.3 Defining frame relatednessIn this section we check if the notion of frame re-latedness is intuitive and principled from a cog-nitive perspective.
In Section 3.1 we first intro-duce the basic concepts or frame semantics; inSection 3.2 we report the agreement results ob-tained by human annotators, on the task of rankinga dataset of frame pairs according to relatedness.3.1 Frame Semantics and FrameNetFrame semantics (Fillmore, 1985) seeks to de-scribe the meaning of a sentence as it is actu-ally understood by characterizing the backgroundknowledge necessary to understand the sentence.Background knowledge is represented in the formof frames, conceptual structures modelling proto-typical situations.
Linguistically, a frame is a se-mantic class containing predicates called lexicalunits (LU), that can evoke the described situation(see example in Table 1).
Each frame comes withits own set of semantic roles, called frame ele-ments (FE).
These are the participants and props inthe abstract situation described.
Roles are local toindividual frames, thus avoiding the commitmentto a small set of universal roles, whose specifica-tion has turned out to be unfeasible in the past.The Berkeley FrameNet project (Baker et al,1998) has been developing a frame-semantic lexi-con for the core vocabulary of English since 1997.The current FrameNet release contains about 800frames and 10,000 lexical units.
Part of FrameNet658Frame: STATEMENTThis frame contains verbs and nouns that communicatethe act of a SPEAKER to address a MESSAGE to someADDRESSEE using language.
A number of the wordscan be used performatively, such as declare and insist.SPEAKER Evelyn said she wanted to leave.MESSAGE Evelyn announced that she wantedto leave.ADDRESSEE Evelyn spoke to me about her past.TOPIC Evelyn?s statement about her pastFEs MEDIUM Evelyn preached to me over thephone.LUs acknowledge.v, acknowledgment.n, add.v, ad-dress.v, admission.n, admit.v, affirm.v, affirma-tion.n, allegation.n, allege.v, announce.v, .
.
.Table 1: Example frame from FrameNet.is also a corpus of annotated example sentencesfrom the British National Corpus, currently con-taining 135,000 sentences.In FrameNet, asymmetric frame relations canrelate two frames, forming a complex hierarchy(Ruppenhofer et al, 2005): Inheritance: anythingtrue in the semantics of the parent frame, mustalso be true for the other (e.g.
KILLING ?
EX-ECUTION).
Uses: a part of the situation evokedby one frame refers to the other.
Subframe: oneframe describes a subpart of a complex situationdescribed in the other (e.g.
CRIMINAL-PROCESS?
SENTENCING).
Causative of : the action inone frame causes the event described in the other(e.g.
KILLING ?
DEATH).
Inchoative of : theevent in one frame ends in the state described inthe other (e.g.
DEATH ?
DEAD OR ALIVE).
Pre-cedes: one frame temporally proceeds the other(e.g.
FALL ASLEEP ?
SLEEP).
Perspective on:one frame describes a specific point-of-view on aneutral frame.The first two are is-a like relations, while theothers are non-hierarchical.3.2 Manually ranking related framesWe asked a pool of human annotators to manuallyrank a set of frame pairs according to their relat-edness.
The goal was twofolds.
First, we wantedto check how intuitive the notion of frame related-ness is, by computing inter-annotator agreement,and by comparing the agreement results to thoseobtained by Rubenstein and Goodenough (1965)for word relatedness.
Second, we planned to usethe produced dataset as a gold standard for test-ing the relatedness measures, as described in Sec-tion 5.
In the rest of the section we describe theannotation process in detail.Dataset creation.
We created two differentdatasets, a simple and a controlled set, each con-taining 155 pairs.
Frame pairs in the simpleset were randomly selected from the FrameNetdatabase.
Frame pairs in the controlled set wereeither composed of two frames belonging to thesame scenario1, or being so that one frame is oneedge from the scenario of the other.
This ensuredthat all pairs in the controlled set contained seman-tically related frames.
Indeed, we use the con-trolled set to check if human agreement and au-tomatic measure accuracy get better when consid-ering only highly related frames.Human ranking agreement.
A preliminary an-notation phase involved a group of 15 annotatorsconsisting of graduate students and researchers,native or nearly native speakers of English.
Foreach set, each annotator was given 15 frame pairsfrom the original 155 set: 5 of these where sharedwith all other annotators.
This setting has threeadvantages: (1) The set is small enough to obtaina reliable annotation in a short time; (2) We cancompute the agreement among the 15 annotatorsover the shared pairs; (3) We can check the relia-bility of the final gold standard created in the sec-ond phase (see following section) by comparing tothe annotations.
Each annotator was asked to or-der a shuffled deck of 15 cards, each one describ-ing a pair of frames.
The card contained the fol-lowing information about the two frames: names;definitions; the lists of core FEs; a frame anno-tated sentence for each frame, randomly chosenfrom the FrameNet database.
Similarly to Ruben-stein and Goodenough (1965) we gave the anno-tators the following instructions: (i) After lookingthrough the whole deck, order the pairs accordingto amount of relatedness; (ii) You may assign thesame rank to pairs having the same degree of re-latedness (i.e.
ties are allowed).We checked the agreement among the 15 an-notators in ranking the 5 shared pairs by usingthe Kendall?s ?
correlation coefficient (Kendall,1938).
Kendall?s ?
can be interpreted as the dif-ference between the probability that in the datasettwo variables are in the same order versus theprobability that they are in different orders (see(Lapata, 2006) for details).
The average corre-1A scenario frame is a ?hub?
frame describing a gen-eral topic; specific frames modelling situations related to thetopic are linked to it (e.g.
COMMERCE BUY and COMMER-CIAL TRANSACTION are linked to COMMERCE SCENARIO).FrameNet contains 16 scenarios.659lation2 among annotators on the simple and con-trolled sets was ?
= 0.600 and ?
= 0.547.Gold standard ranking.
The final dataset wascreated by two expert annotators, jointly workingto rank the 155 pairs collected in the data creationphase.
We computed the rank correlation agree-ment between this annotation and the 15 annota-tion produced in the first stage.
We obtained an av-erage Kendall?s ?
= 0.530 and ?
= 0.566 respec-tively on the simple and controlled sets (Standarddeviations from the average are StdDev = 0.146and StdDev = 0.173).
These results are all statis-tically significant at the 99% level, indicating thatthe notion of ?frame relatedness?
is intuitive andprincipled for humans, and that the final datasetsare reliable enough to be used as gold standard forour experiments.
Table 2 reports the first and last5 ranked frame pairs for the two datasets.We compared the correlation results obtainedabove on ?frame relatedness?, to those derivedfrom previous works on ?word relatedness?.
Thiscomparison should indicate if ranking relatedframes (i.e.
situations) is more or less complexand intuitive than ranking words.3 As for words,we computed the average Kendall?s ?
among threedifferent annotation efforts (namely, (Rubensteinand Goodenough, 1965; Resnik, 1995; Charles,2000)) carried out over a same dataset of 28 wordpairs originally created by Rubenstein and Goode-nough.
Note that the annotation schema followedin the three works is the same as ours.
We ob-tained a Kendall?s ?
= 0.775, which is statisti-cally significant at the 99% level.
As expected,the correlation for word relatedness is higher thanfor frames: Humans find it easier to compare twowords than two complex situations, as the formerare less complex linguistic entities than the latter.4 Measures for frame relatednessManually computing relatedness between all pos-sible frame pairs in FrameNet is an unfeasibletask.
The on-going FrameNet project and auto-matic methods for FrameNet expansion (e.g.
(Pen-2Average correlation is computed by averaging the ?
ob-tained on each pair of annotators, as suggested in (Siegel andCastellan, 1988); note that the obtained value correspondsto the Kendall u correlation coefficient.
Ties are properlytreated with the correction factor described in (Siegel andCastellan, 1988).3The comparison should be taken only as indicative, aswords can be ambiguous while frames are not.
A more prin-cipled comparison should involve word senses, not words.nacchiotti et al, 2008)) are expected to produce anever growing set of frames.
The definition of auto-matic measures for frame relatedness is thus a keyissue.
In this section we propose different types ofsuch measures.4.1 WordNet-based measuresWordNet-based measures estimate relatedness byleveraging the WordNet hierarchy.
The hypothesisis that two frames whose sets of LUs are close inWordNet are likely to be related.
We assume thatLUs are sense-tagged, i.e.
we know which Word-Net senses of a LU map to a given frame.
For ex-ample, among the 25 senses of the LU charge.v,only the sense charge.v#3 (?demand payment?
)maps to the frame COMMERCE COLLECT.Given a frame F , we define SF as the setof all WordNet senses that map to any frame?sLU (e.g.
for COMMERCE COLLECT, SF con-tains charge.v#3, collect.v#4, bill.v#1).
A genericWordNet-based measure is then defined as fol-lows:wn(F1, F2) =?s1?SF1?s2?SF2wn rel(s1, s2)|SF1 | ?
|SF2 |(1)where wn rel(s1, s2) is a sense function estimat-ing the relatedness between two senses in Word-Net.
Since we focus on frame relatedness, weare interested in assigning high scores to pairs ofsenses which are related by any type of relationsin WordNet (i.e.
not limited to is-a).
We there-fore adopt as function wn rel the Hirst-St.Ongemeasure (Hirst and St.Onge, 1998) as it accountsfor different relations.
We also experiment withthe Jiang and Conrath?s (Jiang and Conrath, 1997)measure which relies only on the is-a hierarchy,but proved to be the best WordNet-based mea-sure in the task of ranking words (Budanitskyand Hirst, 2006).
We call the frame relatednessmeasures using the two functions respectively aswn hso(F1, F2) and wn jcn(F1, F2).4.2 Corpus-based measuresCorpus-based measures compute relatedness look-ing at the distributional properties of the twoframes over a corpus.
The intuition is that relatedframes should occur in the same or similar con-texts.660SIMPLE SET CONTROLLED SETMeasure volume - Measure mass (1) Knot creation - Rope manipulation (1,5)Communication manner - Statement (2) Shoot projectiles - Use firearm (1,5)Giving - Sent items (3) Scouring - Scrutiny (3)Abundance - Measure linear extent (4) Ambient temperature - Temperature (4)Remembering information - Reporting (5) Fleeing - Escaping (5)... ...Research - Immobilization (126) Reason - Taking time (142)Resurrection - Strictness (126) Rejuvenation - Physical artworks (142)Social event - Word relations (126) Revenge - Bungling (142)Social event - Rope manipulation (126) Security - Likelihood (142)Sole instance - Chatting (126) Sidereal appearance - Aggregate (142)Table 2: Human gold standard ranking: first and last 5 ranked pairs (in brackets ranks allowing ties).4.2.1 Co-occurrence measuresGiven two frames F1 and F2, the co-occurrencemeasure computes relatedness as the pointwisemutual information (pmi) between them:pmi(F1, F2) = log2P (F1, F2)P (F1)P (F2)(2)Given a corpus C consisting of a set of documentsc ?
C, we estimate pmi as the number of contextsin the corpus (either documents or sentences)4 inwhich the two frames co-occur:cr occ(F1, F2) = log2|CF1,F2 ||CF1 ||CF2 |(3)where CFi is the set of documents in which Fi oc-curs, and CF1,F2 is the set of documents in whichF1 and F2 co-occur.
A frame Fi is said to occur ina document if at least one of its LUs lFi occurs inthe document, i.e.
:CFi = {c ?
C : ?lFi in c} (4)CF1,F2 = {c ?
C : ?lF1 and ?lF2 in c} (5)A limitation of the above measure is that it doesnot treat ambiguity.
If a word is a LU of a frameF , but it occurs in a document with a senses /?
SF , it still counts as a frame occurrence.For example, consider the word charge.v, whosethird sense charge.v#3 maps in FrameNet to COM-MERCE COLLECT.
In the sentence: ?Tripp Isen-hour was charged with killing a hawk on pur-pose?, charge.v co-occurs with kill.v, which inFrameNet maps to KILLING.
The sentence wouldthen result as a co-occurrence of the two aboveframes.
Unfortunately this is not the case, asthe sentence?s sense charge.v#2 does not map tothe frame.
Ideally, one could solve the problemby using a sense-tagged corpus where senses?
oc-currences are mapped to frames.
While sense-to-frame mappings exist (e.g.
mapping between4For sake of simplicity in the rest of the section we referto documents, but the same holds for sentences.frames and WordNet senses in (Shi and Mihal-cea, 2005)), sense-tagged corpora large enough fordistributional studies are not yet available (e.g.,the SemCor WordNet-tagged corpus (Miller et al,1993) consists of only 700,000 words).We therefore circumvent the problem, by imple-menting pmi in a weighted co-occurrence mea-sure, which gives lower weights to co-occurrencesof ambiguous words:cr wgt(F1, F2) = log2?c?CF1,F2wF1(c) ?
wF2(c)?c?CF1wF1(c) ?
?c?CF2wF2(c)(6)The weighting function wF (c) estimates theprobability that the document c contains a LUof the frame F in the correct sense.
For-mally, given the set of senses Sl of a LU (e.g.charge.v#1...charge.v#24), we define SlF as the setof senses mapping to the frame (e.g.
charge.v#3for COMMERCE COLLECT).
The weighting func-tion is then:wF (c) = argmaxlF?LF in cP (SlF |lF ) (7)where LF is the set of LUs of F .
We estimateP (SlF |lF ) by counting sense occurrences of lFover the SemCor corpus:P (SlF |lF ) =|SlF ||Sl|(8)In other terms, a frame receives a high weight ina document when the document contains a LUwhose most frequent senses are those mapped tothe frame.5 For example, in the sentence: ?TrippIsenhour was charged with killing a hawk on pur-pose.
?, wF (c) = 0.17, as charge.v#3 is not veryfrequent in SemCor.5In Eq.8 we use Lidstone smoothing (Lidstone, 1920) toaccount for unseen senses in SemCor.
Also, if a LU does notoccur in SemCor, an equal probability (corresponding to theinverse of the number of word?s senses) is given to all senses.6614.2.2 Distributional measureThe previous measures promote (i.e.
give a higherrank to) frames co-occurring in the same con-texts.
The distributional measure promotes framesoccurring in similar contexts.
The distributionalhypothesis (Harris, 1964) has been widely andsuccessfully used in NLP to compute relatednessamong words (Lin, 1998), lexical patterns (Linand Pantel, 2001), and other entities.
The underly-ing intuition is that target entities occurring in sim-ilar contexts are likely to be semantically related.In our setting, we consider either documents andsentences as valid contexts.Each frame F is modelled by a distributionalvector ~F , whose dimensions are documents.
Thevalue of each dimension expresses the associationratioA(F, c) between a document c and the frame.We say that a document is highly associated to aframe when most of the FrameNet LUs it contains,map to the given frame in the correct senses:A(F, c) =?l?LF in cP (SlF |lF )?Fi?F?l?Fi in cP (SlFi |lFi)(9)where F is the set of all FrameNet frames, andP (SlF |lF ) is as in Eq.
8.
We then compute relat-edness between two frames using cosine similar-ity:cr dist(F1, F2) =~F1 ?
~F2| ~F1| ?
| ~F2|(10)When we use sentences as contexts we re-fer to cr dist sent(F1, F2), otherwise tocr dist doc(F1, F2)4.3 Hierarchy-based measuresA third family or relatedness measures leveragesthe FrameNet hierarchy.
The hierarchy forms adirected graph of 795 nodes (frames), 1136 edges,86 roots, 7 islands and 26 independent compo-nents.
Similarly to measures for word related-ness, we here compute frame relatedness leverag-ing graph-based measures over the FrameNet hi-erarchy.
The intuition is that the closer in the hier-archy two frames are, the more related they are6.We here experiment with the Hirst-St.Onge andthe Wu and Palmer (Wu and Palmer, 1994) mea-sures, as they are pure taxonomic measures, i.e.they do not require any corpus statistics.6The Pathfinder Through FrameNet tool gives a prac-tical proof of this intuition: http://fnps.coli.uni-saarland.de/pathsearch.WU and Palmer: this measure calculates relat-edness by considering the depths of the two framesin the hierarchy, along with the depth of their leastcommon subsumer (LCS):hr wu(F1, F2) =2?dp(LCS)ln(F1, LCS)+ln(F2, LCS)+2?dp(LCS)(11)where ln is the length of the path connecting twoframes, and dp is the length of the path betweena frame and a root.
If a path does not exist, thenhr wu(F1, F2) = 0.Hirst-St.Onge: two frames are semanticallyclose if they are connected in the FrameNet hier-archy through a ?not too long path which does notchange direction too often?
:hr hso(F1, F2) = M?
path length ?k ?d (12)where M and and k are constants, and d is thenumber of changes of direction in the path.
If apath does not exist, hr hso(F1, F2) = 0.
For bothmeasures we consider as valid edges all relations.The FrameNet hierarchy also provides for eachrelation a partial or complete FE mapping betweenthe two linked frames (for example the role Vic-tim of KILLING maps to the role Protagonist ofDEATH).
We leverage this property implementinga FE overlap measure, which given the set of FEsof the two frames, FE1 and FE2 , computes re-latedness as the percentage of mapped FEs:hr fe(F1, F2) =|FE1 ?
FE2|max(|FE1|, |FE2|)(13)The intuition is that FE overlap between framesis a more fine grained and accurate predictor ofrelatedness wrt.
simple frame relation measuresas those above ?
i.e.
two frames are highly relatednot only if they describe connected situations, butalso if they share many participants.5 ExperimentsWe evaluate the relatedness measures by compar-ing their rankings over the two datasets describedin Section 3.2, using the manual gold standard an-notation as reference.
As evaluation metrics weuse Kendall?s ?
.
As baselines, we adopt a def-inition overlap measure that counts the percent-age of overlapping content words in the definitionof the two frames;7 and a LU overlap baseline7We use stems of nouns, verbs and adjectives.662Measure Simple Set Controlled Setwn jcn 0.114 0.141wn hso 0.106 0.141cr occ sent 0.239 0.340cr wgt sent 0.281 0.349cr occ doc 0.143 0.227cr wgt doc 0.173 0.240cr dist doc 0.152 0.240hr wu 0.139 0.286hr hso 0.134 0.296hr fe 0.252 0.326def overlap baseline 0.056 0.210LU overlap baseline 0.080 0.253human upper bound 0.530 0.566Table 3: Kendall?s ?
correlation results for differ-ent measures over the two dataset.that counts the percentage of overlapping LUs be-tween the two frames.
We also defined as upper-bound the human agreement over the gold stan-dard.
As regards distributional measures, statis-tics are drawn from the TREC-2002 Vol.2 cor-pus, consisting of about 110 million words, orga-nized in 230,401 news documents and 5,433,048sentences8.
LUs probabilities in Eq.
8 are esti-mate over the SemCor 2.0 corpus, consisting of700,000 running words, sense-tagged with Word-Net 2.0 senses.9.
WordNet-based measures arecomputed using WordNet 2.0 and implementedas in (Patwardhan et al, 2003).
Mappings be-tween WordNet senses and FrameNet verbal LUsare taken from Shi and Mihalcea (2005); as map-pings for nouns and adjectives are not available,for the WordNet-based measures we use the firstsense heuristic.Note that some of the measures we adopt needsome degree of supervision.
The WordNet-basedand the cr wgt measures rely on a WordNet-FrameNet mapping, which has to be created man-ually or by some reliable automatic technique.Hierarchy-based measures instead rely on theFrameNet hierarchy that is also a manual artifact.5.1 Experimental ResultsTable 3 reports the correlation results over the twodatasets.
Table 4 reports the best 10 ranks pro-duced by some of the best performing measures.Results show that all measures are positively cor-related with the human gold standard, with a level8For computational limitations we could not afford exper-imenting the cr dist sent measure, as the number and size ofthe vectors was too big.9We did not use directly the SemCor for drawing distribu-tional statistics, because of its small size.of significance beyond the p < 0.01 level , butthe wn jcn measure which is at p < 0.05.
Allmeasures, but the WordNet-based ones, signifi-cantly outperform the definition overlap baselineon both datasets, and most of them also beat themore informed LU overlap baseline.10 It is in-teresting to notice that the two best performingmeasures, namely cr wgt sent and hr fe, use re-spectively a distributional and a hierarchy-basedstrategy, suggesting that both approaches are valu-able.
WordNet-based measures are less effective,performing close or below the baselines.Results obtained on the simple set are in gen-eral lower than those on the controlled set, sug-gesting that it is easier to discriminate among pairsof connected frames than random ones.
A possi-ble explanation is that when frames are connected,all measures can rely on meaningful evidence formost of the pairs, while this is not always the casefor random pairs.
For example, corpus-based mea-sures tend to suffer the problem of data sparsenessmuch more on the simple set, because many of thepairs are so loosely related that statistical informa-tion cannot significantly emerge from the corpus.WordNet-based measures.
The low perfor-mance of these measures is mainly due to thefact that they fail to predict relatedness for manypairs, e.g.
wn hso assigns zero to 137 and 119pairs, respectively on the simple and controlledsets.
This is mostly caused by the limited set ofrelations of the WordNet database.
Most impor-tantly in our case, WordNet misses the situationalrelation (Hirst and St.Onge, 1998), which typi-cally relates words participating in the same sit-uation (e.g.
child care - school).
This is exactlythe relation that would help in mapping frames?LUs.
Another problem relates to adjectives andadverbs: WordNet measures cannot be trustfullyapplied to these part-of-speech, as they are nothierarchically organized.
Unfortunately, 18% ofFrameNet LUs are either adjectives or adverbs,meaning that such amount of useful informationis lost.
Finally, WordNet has in general an incom-plete lexical coverage: Shi and Mihalcea (2005)show that 7% of FrameNet verbal LUs do not havea mapping in WordNet.Corpus-based measures.
Table 3 shows thatco-occurrence measures are effective when using10The average level of correlation obtained by our mea-sures is comparable to that obtained in other complexinformation-ordering tasks, e.g.
measuring compositionalityof verb-noun collations (Venkatapathy and Joshi, 2005)663WN JCN CR WGT SENT HR FEAmbient temperature - Temperature (4) Change of phase - Cause change of phase (7) Shoot projectiles - Use firearm (1,5)Run risk - Endangering (27) Knot creation - Rope manipulation (1,5) Intentionally affect - Rope manipulation (37,5)Run risk - Safe situation (51) Ambient temperature - Temperature (4) Knot creation - Rope manipulation (1,5)Knot creation - Rope manipulation (1,5) Shoot projectiles - Use firearm (1,5) Ambient temperature - Temperature (4)Endangering - Safe situation (62) Hit target - Use firearm (18) Hit target - Intentionally affect (91,5)Shoot projectiles - Use firearm (1,5) Run risk - Safe situation (51) Safe situation - Security (28)Scouring - Scrutiny (3) Safe situation - Security (28) Suspicion - Criminal investigation (40)Reliance - Contingency (109) Cause impact - Hit target (10) Age - Speed (113)Safe situation - Security (28) Rape - Arson (22) Motion noise - Motion directional (55)Change of phase - Cause change of phase (7) Suspicion - Robbery (98) Body movement - Motion (45)Table 4: First 10 ranked frame pairs for different relatedness measure on the Controlled Set; in brackets,the rank in the gold standard (full list available at (suppressed)).sentences as contexts, while correlation decreasesby about 10 points using documents as contexts.This suggest that sentences are suitable contex-tual units to model situational relatedness, whiledocuments (i.e.
news) may be so large to includeunrelated situations.
It is interesting to noticethat corpus-based measures promote frame pairswhich are in a non-hierarchical relation, more thanother measures do.
For example the pair CHANGEOF PHASE - CAUSE CHANGE OF PHASE scorefirst, and RAPE - ARSON score ninth, while theother measures tend to rank them much lower.By contrast, the two frames SCOURING - IN-SPECTING which are siblings in the FrameNet hi-erarchy and rank 17th in the gold standard, areranked only 126th by cr wgt sent.
This is dueto the fact that hierarchically related frames aresubstitutional ?
i.e.
they tend not to co-occurin the same documents; while otherwise relatedframes are mostly in syntagmatic relation.
As forcr dist doc, it performs in line with cr wgt doc,but their ranks differ; cr dist doc promotes morehierarchical relations: distributional methods cap-ture both paradigmatically and syntagmatically re-lated entities.Hierarchy-based measures.
As results show,the FrameNet hierarchy is a good indicator of re-latedness, especially when considering FE map-pings.
Hierarchy-based measures promote framepairs related by diverse relations, with a slight pre-dominance of is-a like ones (indeed, the FrameNethierarchy contains roughly twice as many is-a re-lations as other ones).
These measures are slightlypenalized by the low coverage of the FrameNethierarchy.
For example, they assign zero toCHANGE OF PHASE - ALTERED PHASE, as an in-choative link connecting the frames is missing.Correlation between measures.
We computedthe Kendall?s ?
among the experimented mea-sures, to investigate if they model relatedness indifferent or similar ways.
As expected, measuresof the same type are highly correlated (e.g.
hr feand hr wu have ?
= 0.52), while those of differ-ent types seem complementary, showing negativeor non-significant correlation (e.g.
cr wgt sent has?
= ?0.034 with hr wu, and ?
= 0.078 withwn jcn).
The LU overlap baseline shows signif-icant correlation only with hr wu (?
= 0.284),suggesting that in the FrameNet hierarchy framescorrelated by some relation do share LUs.Comparison to word relatedness.
The bestperforming measures score about 0.200 points be-low the human upper bound, indicating that rank-ing frames is much easier for humans than for ma-chines.
A direct comparison to the word rankingtask, suggests that ranking frames is harder thanwords, not only for humans (as reported in Sec-tion 3.2), but also for machines: Budanitsky andHirst (2006) show that measures for ranking wordsget much closer to the human upper-bound thanour measures do, confirming that frame related-ness is a fairly complex notion to model.6 ConclusionsWe empirically defined a notion of frame relat-edness.
Experiments suggest that this notion iscognitively principled, and can be safely used inNLP tasks.
We introduced a variety of measuresfor automatically estimating relatedness.
Resultsshow that our measures have good performance,all statistically significant at the 99% level, thoughimprovements are expected by using other evi-dence.
As future work, we will build up and refinethese basic measures, and investigate more com-plex ones.
We will also use our measures in appli-cations, to check their effectiveness in supportingvarious tasks, e.g.
in mapping frames across Textand Hypothesis in RTE, in linking related framesin discourse, or in inducing frames for LU whichare not in FrameNet (Baker et al, 2007).664ReferencesCollin F. Baker, Charles J. Fillmore, and John B. Lowe.1998.
The Berkeley FrameNet project.
In Proceed-ings of COLING-ACL, Montreal, Canada.Collin Baker, Michael Ellsworth, and Katrin Erk.2007.
SemEval-2007 Task 19: Frame SemanticStructure Extraction.
In Proceedings of the FourthInternational Workshop on Semantic Evaluations(SemEval-2007), pages 99?104, Prague, Czech Re-public, June.Alexander Budanitsky and Graeme Hirst.
2006.
Eval-uating WordNet-based measures of lexical semanticrelatedness.
Computational Linguistics, 32(1):13?47.Walter Charles.
2000.
Contextual correlates of mean-ing.
Applied Psycholinguistics, (21):502?524.C.
J. Fillmore.
1985.
Frames and the Semantics ofUnderstanding.
Quaderni di Semantica, IV(2).Zellig Harris.
1964.
Distributional structure.
In Jer-rold J. Katz and Jerry A. Fodor, editors, The Philos-ophy of Linguistics, New York.
Oxford UniversityPress.Graeme Hirst and David St.Onge, 1998.
Lexical chainsas representations of context for the detection andcorrection of malapropisms, pages 305?332.
MITpress.Jay J. Jiang and David W. Conrath.
1997.
Seman-tic similarity based on corpus statistics and lexicaltaxonomy.
In Proceedings of International Confer-ence on Research in Computational Linguistics (RO-CLING X), Taiwan.Maurice Kendall.
1938.
A new measure of rank corre-lation.
Biometrika, (30):81?93.Mirella Lapata.
2006.
Automatic evaluation of infor-mation ordering: Kendall?s tau.
Computational Lin-guistics, 32(4):471?484.G.J.
Lidstone.
1920.
Note on the general case of theBayes-Laplace formula for inductive or a posterioriprobabilities.
Transactions of the Faculty of Actuar-ies, 8:182?192.Dekang Lin and Patrick Pantel.
2001.
DIRT-discoveryof inference rules from text.
In Proceedings ofKDD-01, San Francisco, CA.Dekang Lin.
1998.
Automatic retrieval and clusteringof similar word.
In Proceedings of COLING-ACL,Montreal, Canada.G.
A. Miller, C. Leacock, T. Randee, and Bunker R.1993.
A Semantic Concordance.
In In Proceedingsof the 3rd DARPA Workshop on Human LanguageTechnology, Plainsboro, New Jersey.Saif Mohammad and Graeme Hirst.
2006.
Distribu-tional measures of concept-distance.
a task-orientedevaluation.
In Proceedings of EMNLP-2006, Syd-ney,Australia.S.
Patwardhan, S. Banerjee, and T. Pedersen.
2003.Using measures of semantic relatedness for wordsense disambiguation.
In Proceedings of Fourth In-ternational Conference on Intelligent Text Process-ing and Computational Linguistics, Mexico City,Mexico.Marco Pennacchiotti, Diego De Cao, Paolo Marocco,and Roberto Basili.
2008.
Towards a vector spacemodel for framenet-like resources.
In Proceedingsof LREC, Marrakech, Marocco.Philip Resnik.
1995.
Using information content toevaluate semantic similarity.
In Proceedings of the14th International Joint Conference on Artificial In-telligence, Montreal, Canada.H.
Rubenstein and J.B. Goodenough.
1965.
Contex-tual correlates of synonymy.
Communications of theACM, 8(10):627?633.Josef Ruppenhofer, Michael Ellsworth, Miriam R. L.Petruck, and Christopher R. Johnson.
2005.FrameNet II: Extended Theory and Practice.
In ICSITechnical Report.Lei Shi and Rada Mihalcea.
2005.
Putting Pieces To-gether: Combining FrameNet, VerbNet and Word-Net for Robust Semantic Parsing.
In In Proceedingsof Cicling, Mexico.S.
Siegel and N. J. Castellan.
1988.
Nonparamet-ric Statistics for the Behavioral Sciences.
McGraw-Hill.Idan Szpektor, Hristo Tanev, Ido Dagan, and Bonaven-tura Coppola.
2004.
Scaling web-based acquisitionof entailment relations.
In Proceedings of the 2004Conference on Empirical Methods in Natural Lan-guage Processing, Barcellona, Spain.Sriram Venkatapathy and Aravind K. Joshi.
2005.Measuring the relative compositionality of verbnoun (V-N) collocations by integrating features.
InProceedings of HLT/EMNLP, Vancouver, Canad.Z.
Wu and M. Palmer.
1994.
Verb semantics and lex-ical selection.
In 32nd Annual Meeting of the Asso-ciation for Computational Linguistics, pages 133?138, Las Cruces, New Mexico.665
