Proceedings of the Joint 5th Workshop on Statistical Machine Translation and MetricsMATR, pages 321?326,Uppsala, Sweden, 15-16 July 2010. c?2010 Association for Computational LinguisticsBBN System Description for WMT10 System Combination TaskAntti-Veikko I. Rosti and Bing Zhang and Spyros Matsoukas and Richard SchwartzRaytheon BBN Technologies, 10 Moulton Street, Cambridge, MA 02138, USA{arosti,bzhang,smatsouk,schwartz}@bbn.comAbstractBBN submitted system combination out-puts for Czech-English, German-English,Spanish-English, French-English, and All-English language pairs.
All combinationswere based on confusion network decod-ing.
An incremental hypothesis alignmentalgorithm with flexible matching was usedto build the networks.
The bi-gram de-coding weights for the single source lan-guage translations were tuned directly tomaximize the BLEU score of the decod-ing output.
Approximate expected BLEUwas used as the objective function in gra-dient based optimization of the combina-tion weights for a 44 system multi-sourcelanguage combination (All-English).
Thesystem combination gained around 0.4-2.0 BLEU points over the best individualsystems on the single source conditions.On the multi-source condition, the systemcombination gained 6.6 BLEU points.1 IntroductionThe BBN submissions to the WMT10 systemcombination task were based on confusion net-work decoding.
The confusion networks werebuilt using the incremental hypothesis alignmentalgorithm with flexible matching introduced in theBBN submission for the WMT09 system combi-nation task (Rosti et al, 2009).
This year, thesystem combination weights were tuned to max-imize the BLEU score (Papineni et al, 2002) ofthe 1-best decoding output (lattice based BLEUtuning) using downhill simplex method (Press etal., 2007).
A 44 system multi-source combina-tion was also submitted.
Since the gradient-freeoptimization algorithms do not seem to be able tohandle more than 20-30 weights, a gradient ascentto maximize an approximate expected BLEU ob-jective was used to optimize the larger number ofweights.The lattice based BLEU tuning may be imple-mented using any optimization algorithm that doesnot require the gradient of the objective function.Due to the size of the lattices, the objective func-tion evaluation may have to be distributed to mul-tiple servers.
The optimizer client accumulates theBLEU statistics of the 1-best hypotheses from theservers for given search weights, computes the fi-nal BLEU score, and passes it to the optimiza-tion algorithm which returns a new set of searchweights.
The lattice based tuning explores the en-tire search space and does not require multiple de-coding iterations with N -best list merging to ap-proximate the search space as in the standard min-imum error rate training (Och, 2003).
This allowsmuch faster turnaround in weight tuning.Differentiable approximations of BLEU havebeen proposed for consensus decoding.
Trombleet al (2008) used a linear approximation and Paulset al (2009) used a closer approximation calledCoBLEU.
CoBLEU is based on the BLEU for-mula but the n-gram counts are replaced by ex-pected counts over a translation forest.
Due to themin-functions required in converting the n-gramcounts to matches and a non-differentiable brevitypenalty, a sub-gradient ascent must be used.
Inthis work, an approximate expected BLEU (Exp-BLEU) defined over N -best lists was used as adifferentiable objective function.
ExpBLEU usesexpected BLEU statistics where the min-functionis not needed as the statistics are computed off-line and the brevity penalty is replaced by a dif-ferentiable approximation.
The ExpBLEU tun-ing yields comparable results to direct BLEU tun-ing using gradient-free algorithms on combina-tions of small number of systems (fewer than 20-30 weights).
Results on a 44 system combinationshow that the gradient based optimization is morerobust with larger number of weights.321This paper is organized as follows.
Section2 reviews the incremental hypothesis alignmentalgorithm used to built the confusion networks.Decoding weight optimization using direct lattice1-best BLEU tuning and N -best list based Exp-BLEU tuning are presented in Section 3.
Exper-imental results on combining single source lan-guage to English outputs and all 44 English out-puts are detailed in Section 4.
Finally, Section 5concludes this paper with some ideas for futurework.2 Hypothesis AlignmentThe confusion networks were built by using theincremental hypothesis alignment algorithm withflexible matching introduced in Rosti et al (2009).The algorithm is reviewed in more detail here.
Itis loosely related to the alignment performed inthe calculation of the translation edit rate (TER)(Snover et al, 2006) which estimates the editdistance between two strings allowing shifts ofblocks of words in addition to insertions, dele-tions, and substitutions.
Calculating an exact TERfor strings longer than a few tokens1 is not compu-tationally feasible, so the tercom2 software usesheuristic shift constraints and pruning to find anupper bound of TER.
In this work, the hypothe-ses were aligned incrementally with the confusionnetwork, thus using tokens from all previouslyaligned hypotheses in computing the edit distance.Lower substitution costs were assigned to tokensconsidered equivalent and the heuristic shift con-straints of tercom were relaxed3.First, tokens from all hypotheses are put intoequivalence classes if they belong to the sameWordNet (Fellbaum, 1998) synonym set or havethe same stem.
The 1-best hypothesis from eachsystem is used as the confusion network skeletonwhich defines the final word order of the decod-ing output.
Second, a trivial confusion networkis generated from the skeleton hypothesis by gen-erating a single arc for each token.
The align-ment algorithm explores shifts of blocks of wordsthat minimize the edit distance between the cur-rent confusion network and an unaligned hypothe-1Hypotheses are tokenized and lower-cased prior to align-ment.
Tokens generally refer to words and punctuation.2http://www.cs.umd.edu/?snover/tercom/current version 0.7.25.3This algorithm is not equivalent to an incremental TER-Plus (Snover et al, 2009) due to different shift constraints andthe lack of paraphrase matching30 1cat(1) 2sat(1) mat(1)(a) Skeleton hypothesis.40 1cat(1,1) 2sat(1,1) 3on(0,1)NULL(1,0) mat(1,1)(b) Two hypotheses (insertion).40 1cat(1,1,0)NULL(0,0,1) 2sat(1,1,1) 3on(0,1,0)NULL(1,0,1) mat(1,1,1)(c) Three hypotheses (deletion).40 1cat(1,1,0,1)NULL(0,0,1,0) 2sat(1,1,1,1) 3on(0,1,0,0)NULL(1,0,1,1) mat(1,1,1,0)hat(0,0,0,1)(d) Four hypotheses (substitution).Figure 1: Example of incrementally aligning ?catsat mat?, ?cat sat on mat?, ?sat mat?, and ?cat sathat?.sis.
Third, the hypothesis with the lowest edit dis-tance to the current confusion network is alignedinto the network.
The heuristically selected editcosts used in the WMT10 system were 1.0 forinsertions, deletions, and shifts, 0.2 for substitu-tions of tokens in the same equivalence class, and1.0001 for substitutions of non-equivalent tokens.An insertion with respect to the network alwaysresults in a new node and two new arcs.
The firstarc contains the inserted token and the second arccontains a NULL token representing the missingtoken from all previously aligned hypotheses.
Asubstitution/deletion results in a new token/NULLarc or increase in the confidence of an existing to-ken/NULL arc.
The process is repeated until allhypotheses are aligned into the network.For example, given the following hypothesesfrom four systems: ?cat sat mat?, ?cat sat on mat?,?sat mat?, and ?cat sat hat?, an initial network inFigure 1(a) is generated.
The following two hy-potheses have a distance of one edit from the initialnetwork, so the second can be aligned next.
Figure1(b) shows the additional node created and the twonew arcs for ?on?
and ?NULL?
tokens.
The thirdhypothesis has deleted token ?cat?
and matches the322?NULL?
token between nodes 2 and 3 as seen inFigure 1(c).
The fourth hypothesis matches all butthe final token ?hat?
which becomes a substitutionfor ?mat?
in Figure 1(d).
The binary vectors inthe parentheses following each token show whichsystem generated the token aligned to that arc.
Ifthe systems generated N -best hypotheses, a frac-tional increment could be added to these vectorsas in (Rosti et al, 2007).
Given these system spe-cific scores are normalized to sum to one over allarcs connecting two consecutive nodes, they maybe viewed as system specific word arc posteriorestimates.
Note, for 1-best hypotheses the scoressum to one without normalization.Given system outputs E = {E1, .
.
.
, ENs},an algorithm to build a set of Ns confusionnetworks C = {C1, .
.
.
, CNs} may be writtenas:for n = 1 to Ns doCn ?
Init(En) {initialize confusion net-work from the skeleton}E ?
?
E ?
En {set of unaligned hypotheses}while E ?
6= ?
doEm ?
argminE?E ?
Dist(E,Cn){compute edit distances}Cn ?
Align(Em, Cn) {align closest hy-pothesis}E ?
?
E ?
?
Em {update set of unalignedhypotheses}end whileend forThe set of Ns confusion networks are expanded toseparate paths with distinct bi-gram contexts andconnected in parallel into a big lattice with com-mon start and end nodes with NULL token arcs.A prior probability estimate is assigned to the sys-tem specific word arc confidences connecting thecommon start node and the first node in each sub-network.
A heuristic prior is estimated as:pn =1Zexp(?100enNn) (1)where en is the total cost of aligning all hypothe-ses when using system n as the skeleton, Nn isthe number of nodes in the confusion network be-fore bi-gram expansion, and Z is a scaling factorto guarantee pn sum to one.
This gives a higherprior for a network with fewer alignment errorsand longer expected decoding output.3 Weight OptimizationStandard search algorithms may be used to find N -best hypotheses from the final lattice.
The scorefor arc l is computed as:sl = log( Ns?n=1?nsnl)+ ?L(wl|wP (l)) + ?S(wl)(2)where ?n are the system weights constrained tosum to one, snl are the system specific arc pos-teriors, ?
is a language model (LM) scaling fac-tor, L(wl|wP (l)) is the bi-gram log-probability forthe token wl on the arc l given the token wP (l)on the arc P (l) preceding the arc l, ?
is the wordinsertion scaling factor, and S(wl) is zero if wlis a NULL token and one otherwise.
The pathwith the highest total score under summation isthe 1-best decoding output.
The decoding weights?
= {?1, .
.
.
, ?Ns , ?, ?}
are tuned to optimize twoobjective functions described next.3.1 Lattice Based BLEU OptimizationPowell?s method (Press et al, 2007) on N -bestlists was used in system combination weight tun-ing in Rosti et al (2007).
This requires multipledecoding iterations and merging the N -best listsbetween tuning runs to approximate the full searchspace as in Och (2003).
To speed up the tuningprocess, a distributed optimization method can beused.
The lattices are divided into multiple chunkseach of which are loaded into memory by a server.A client runs the optimization algorithm relyingon the servers for parallelized objective functionevaluation.
The client sends a new set of searchweights to the servers which decode the chunksof lattices and return the 1-best hypothesis BLEUstatistics back to the client.
The client accumulatesthe BLEU statistics from all servers and computesthe final BLEU score used as the objective func-tion by the optimization algorithm.
Results similarto Powell?s method can be obtained with fewer it-erations by using the downhill simplex method inmulti-dimensions (Amoeba) (Press et al, 2007).To enforce the sum to one constraint of the sys-tem weights ?n, the search weights are restrictedto [0, 1] by assigning a large penalty if any cor-responding search weight breaches the limits andthese restricted search weights are scaled to sumto one before the objective function evaluation.After optimizing the bi-gram decoding weightsdirectly on the lattices, a 300-best list are gener-323ated.
The 300-best hypotheses are re-scored usinga 5-gram LM and another set of re-scoring weightsare tuned on the development set using the stan-dard N -best list based method.
Multiple randomrestarts may be used in both lattice and N-best listbased optimization to decrease chances of findinga local minimum.
Twenty sets of initial weights(the weights from the previous tuning and 19 ran-domly perturbed weights) were used in all experi-ments.3.2 Approximate Expected BLEUOptimizationThe gradient-free optimization algorithms likePowell?s method and downhill simplex work wellfor up to around 20-30 weights.
When the numberof weights is larger, the algorithms often get stuckin local optima even if multiple random restartsare used.
The BLEU score for a 1-best output isdefined as follows:BLEU =4?n=1(?i mni?i hni) 14?
(1 ?
?i ri?i h1i)(3)where mni is the number of n-gram matches be-tween the hypothesis and reference for segmenti, hni is the number of n-grams in the hypothesis,ri is the reference length (or the reference lengthclosest to the hypothesis if multiple references areavailable), and ?
(x) = min(1.0, ex) is the brevitypenalty.
The first term in Equation 3 is a harmonicmean of the n-gram precisions up to n = 4.
Theselection of 1-best hypotheses is discrete and thebrevity penalty is not continuous, so the BLEUscore is not differentiable and gradient based op-timization cannot be used.
Given a posterior dis-tribution over all possible decoding outputs couldbe defined, an expected BLEU could be optimizedusing gradient ascent.
However, this posterior dis-tribution can only be approximated by expensivesampling methods.A differentiable objective function over N -bestlists to approximate the BLEU score can be de-fined using expected BLEU statistics and a con-tinuous approximation of the brevity penalty.
Theposterior probability for hypothesis j of segment iis simply the normalized decoder score:pij =e?Sij?k e?Sik(4)where ?
is a posterior scaling factor and Sij is thetotal score of hypothesis j of segment i.
The pos-terior scaling factor controls the shape of the pos-terior distribution: ?
> 1.0 moves the probabilitymass toward the 1-best hypothesis and ?
< 1.0flattens the distribution.
The BLEU statistics inEquation 3 are replaced by the expected statistics;for example, m?ni =?j pijmij , and the brevitypenalty ?
(x) is approximated by:?
(x) =ex ?
1e1000x + 1+ 1 (5)ExpBLEU has a closed form solution for the gra-dient, provided the total decoder score is differen-tiable.The penalty used to restrict the search weightscorresponding to the system weights ?n ingradient-free BLEU tuning is not differentiable.For expected BLEU tuning, the search weights ?nare unrestricted but the system weights are ob-tained by a sigmoid transform and normalized tosum to one:?n =?
(?n)?m ?
(?m)(6)where ?
(?n) = 1/(1 + e?
?n).The expected BLEU tuning is performed on N -best lists in similar fashion to direct BLEU tuning.Tuned weights from one decoding iteration areused to generate a new N -best list, the new N -bestlist is merged with the N -best list from the previ-ous tuning run, and a new set of weights are op-timized using limited memory Broyden-Fletcher-Goldfarb-Shanno method (lBFGS) (Liu and No-cedal, 1989).
Since the posterior distribution isaffected by the size of the N -best list and differ-ent decoding weights, the posterior scaling factorcan be set for each tuning run so that the perplex-ity of the posterior distribution given the mergedN -best list is constant.
A target perplexity of 5.0was used in the experiments.
Four iterations ofbi-gram decoding weight tuning were performedusing 300-best lists.
The final 300-best list was re-scored with a 5-gram and another set of re-scoringweights was tuned on the development set.4 Experimental EvaluationSystem outputs for all language pairs with En-glish as the target were combined.
Unpruned En-glish bi-gram and 5-gram language model com-ponents were trained using the WMT10 corpora:EuroParl, GigaFrEn, NewsCommentary,and News.
Additional six Gigaword v4 com-ponents were trained: AFP, APW, XIN+CNA,324tune cz-en de-en es-en fr-enSystem TER BLEU TER BLEU TER BLEU TER BLEUworst 68.99 13.85 68.45 15.07 60.86 21.02 71.17 15.00best 56.77 22.84 57.76 25.05 51.81 30.10 53.66 28.64syscomb 57.31 25.11 54.97 27.75 50.46 31.54 51.35 31.16test cz-en de-en es-en fr-enSystem TER BLEU TER BLEU TER BLEU TER BLEUworst 68.65 14.29 67.50 15.66 60.52 21.86 68.36 16.82best 56.13 23.56 58.12 24.34 51.45 30.56 52.16 29.79syscomb 56.89 25.12 55.60 26.38 50.33 31.59 51.36 30.16Table 1: Case insensitive TER and BLEU scores on syscombtune (tune) and syscombtest (test)for combinations of outputs from four source languages.LTW, NYT, and Headlines+Datelines.
In-terpolation weights for the ten componentswere tuned so as to minimize perplexity onthe newstest2009-ref.en development set.The LMs used modified Kneser-Ney smoothing.On the multi-source condition (xx-en) anotherLM was trained from the system outputs and in-terpolated with the general LM using an interpola-tion weight 0.3 for the LM trained on the systemoutputs.
This LM is referred to as biasLM later.A tri-gram true casing model was trained using allavailable English data.
This model was used torestore the case of the lower-case system combi-nation output.All six 1-best system outputs on cz-en, 16outputs on de-en, 8 outputs on es-en, and14 outputs on fr-en were combined.
The lat-tice based BLEU tuning was used to optimize thebi-gram decoding weights and N-best list basedBLEU tuning was used to optimize the 5-gram re-scoring weights.
Results for these single sourcelanguage experiments are shown in Table 1.
Thegains on syscombtune were similar to those onsyscombtest for all but French-English.
Thetuning set contained only 455 segments but ap-peared to be well matched with the larger (2034segments) test set.
The characteristics of the indi-vidual system outputs were probably different forthe tuning and test sets on French-English transla-tion.
In our experience, optimizing system com-bination weights using the ExpBLEU tuning fora small number of systems yields similar resultsto lattice based BLEU tuning.
The lattice basedBLEU tuning is faster as there is no need for mul-tiple decoding and tuning iterations.
Using the bi-asLM on the single source combinations did notxx-en tune testSystem TER BLEU TER BLEUworst 71.17 13.85 68.65 14.29best 51.81 30.10 51.45 30.56lattice 43.15 35.72 43.79 35.29expBLEU 44.07 36.91 44.35 36.62+biasLM 43.63 37.61 44.50 37.12Table 2: Case insensitive TER and BLEU scoreson syscombtune (tune) and syscombtest(test) for xx-en combination.
Combinations us-ing lattice BLEU tuning, expected BLEU tuning,and after adding the system output biased LM areshown.yield any gains.
The output for these conditionsprobably did not contain enough data for biasLMtraining given the small tuning set and small num-ber of systems.Finally, experiments combining all 44 1-bestsystem outputs were performed to produce amulti-source combination output.
The first experi-ment used the lattice based BLEU tuning and gavea 5.6 BLEU point gain on the tuning set as seen inTable 2.
The ExpBLEU tuning gave an additional1.2 point gain which suggests that the direct latticebased BLEU tuning got stuck in a local optimum.Using the system output biased LM gave an addi-tional 0.7 point gain.
The gains on the test set weresimilar and the best combination gave a 6.6 pointgain over the best individual system.5 ConclusionsThe BBN submissions for WMT10 system com-bination task were described in this paper.
Thecombination was based on confusion network de-325coding.
The confusion networks were built us-ing an incremental hypothesis alignment algo-rithm with flexible matching.
The bi-gram de-coding weights for the single source conditionswere optimized directly to maximize the BLEUscores of the 1-best decoding outputs and the 5-gram re-scoring weights were tuned on 300-bestlists.
The BLEU gains over the best individualsystem outputs were around 1.5 points on cz-en,2.0 points on de-en, 1.0 points on es-en, and0.4 points on fr-en.
The system combinationweights on xx-en were tuned to maximize Exp-BLEU, and a system output biased LM was used.The BLEU gain over the best individual systemwas 6.6 points.
Future work will investigate tuningof the edit costs used in the alignment.
A latticebased ExpBLEU tuning will be investigated.
Also,weights for more complicated functions with addi-tional features may be tuned using ExpBLEU.AcknowledgmentsThis work was supported by DARPA/IPTO Con-tract No.
HR0011-06-C-0022 under the GALEprogram.ReferencesChristiane Fellbaum, editor.
1998.
WordNet: An Elec-tronic Lexical Database.
MIT Press.Dong C. Liu and Jorge Nocedal.
1989.
On the limitedmemory method for large scale optimization.
Math-ematical Programming, 45(3):503?528.Franz J. Och.
2003.
Minimum error rate training instatistical machine translation.
In Proceedings of the41st Annual Meeting of the Association for Compu-tational Linguistics, pages 160?167.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
BLEU: a method for automaticevaluation of machine translation.
In Proceedingsof the 40th Annual Meeting of the Association forComputational Linguistics, pages 311?318.Adam Pauls, John DeNero, and DanKlein.
2009.
Con-sensus training for consensus decoding in machinetranslation.
In Proceedings of the 2009 Conferenceon Empirical Methods in Natural Language Pro-cessing, pages 1418?1427.William H. Press, Saul A. Teukolsky, William T. Vet-terling, and Brian P. Flannery.
2007.
Numericalrecipes: the art of scientific computing.
CambridgeUniversity Press, 3rd edition.Antti-Veikko I. Rosti, Spyros Matsoukas, and RichardSchwartz.
2007.
Improved word-level system com-bination for machine translation.
In Proceedings ofthe 45th Annual Meeting of the Association of Com-putational Linguistics, pages 312?319.Antti-Veikko I. Rosti, Bing Zhang, Spyros Matsoukas,and Richard Schwartz.
2009.
Incremental hy-pothesis alignment with flexible matching for build-ing confusion networks: BBN system descriptionfor WMT09 system combination task.
In Proceed-ings of the Fourth Workshop on Statistical MachineTranslation, pages 61?65.Matthew Snover, Bonnie Dorr, Richard Schwartz, Lin-nea Micciula, and John Makhoul.
2006.
A study oftranslation edit rate with targeted human annotation.In Proceedings of the 7th Conference of the Associa-tion for Machine Translation in the Americas, pages223?231.Matthew Snover, Nitin Madnani, Bonnie Dorr, andRichard Schwartz.
2009.
Fluency, adequacy, orHTER?
exploring different human judgments witha tunable MT metric.
In Proceedings of the FourthWorkshop on Statistical Machine Translation, pages259?268.Roy W. Tromble, Shankar Kumar, Franz Och, andWolfgang Macherey.
2008.
Lattice minimumbayes-risk decoding for statistical machine transla-tion.
In Proceedings of the 2008 Conference on Em-pirical Methods in Natural Language Processing,pages 620?629.326
