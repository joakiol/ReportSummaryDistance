Proceedings of the SIGDIAL 2013 Conference, pages 154?156,Metz, France, 22-24 August 2013. c?2013 Association for Computational LinguisticsDemonstration of the Parlance system: a data-driven,incremental, spoken dialogue system for interactive searchHelen Hastie, Marie-Aude Aufaure?, Panos Alexopoulos, Heriberto Cuay?huitl, Nina Dethlefs,Milica Gasic, James Henderson, Oliver Lemon, Xingkun Liu, Peter Mika, Nesrine Ben Mustapha,Verena Rieser, Blaise Thomson, Pirros Tsiakoulis, Yves Vanrompay, Boris Villazon-Terrazas, Steve Youngemail: h.hastie@hw.ac.uk.
See http://parlance-project.eu for full list of affiliationsAbstractThe Parlance system for interactivesearch processes dialogue at a micro-turn level, displaying dialogue phe-nomena that play a vital role in hu-man spoken conversation.
These di-alogue phenomena include more nat-ural turn-taking through rapid sys-tem responses, generation of backchan-nels, and user barge-ins.
The Par-lance demonstration system differen-tiates from other incremental systemsin that it is data-driven with an infras-tructure that scales well.1 IntroductionThe Parlance system provides interactivesearch through a Spoken Dialogue System(SDS).
This SDS aims to be incremental to al-low for more natural spoken interaction.
Tra-ditionally, the smallest unit of speech process-ing for interactive systems has been a full ut-terance with strict, rigid turn-taking.
TheParlance architecture, however, is an incre-mental framework that allows for processingof smaller ?chunks?
of user input, which en-ables one to model dialogue phenomena suchas barge-ins and backchannels.
This work iscarried out under the FP7 EC project Par-lance 1, the goal of which is to develop inter-active search through speech in multiple lan-guages.
The domain for the demonstrationsystem is interactive search for restaurants inSan Francisco.
An example dialogue is givenin Table 1.?Authors are in alphabetical order1http://www.parlance-project.euSYS Thank you for calling the Parlance Restaurantsystem.
You may ask for information by cuisinetype, price range or area.
How may I help you?USR I want to find an Afghan restaurant.........which isin the cheap price range.SYS .......................................................[uhuhh]........The Helmand Palace is a cheerful setting for au-thentic Afghan cuisine.USR What is the address and phone number?SYS The address 2424 Van Ness Ave ....Table 1: Example dialogue excerpt for restaurant in-formation in San Francisco2 BackgroundPrevious work includes systems that can dealwith ?micro-turns?
(i.e.
sub-utterance process-ing units), resulting in dialogues that are morefluid and responsive.
This has been backed upby a large body of psycholinguistic literaturethat indicates that human-human interactionis in fact incremental (Levelt, 1989).It has been shown that incremental dia-logue behaviour can improve the user experi-ence (Skantze and Schlangen, 2009; Baumannet al 2011; Selfridge et al 2011) and en-able the system designer to model several di-alogue phenomena that play a vital role inhuman discourse (Levelt, 1989) but have sofar been absent from systems.
These dialoguephenomena that will be demonstrated by theParlance system include more natural turn-taking through rapid system responses, gener-ation of backchannels and user barge-ins.
Thesystem differentiates from other incrementalsystems in that it is entirely data-driven withan infrastructure that potentially scales well.3 System ArchitectureFigure 1 gives an overview of the Par-lance system architecture, which maintains154LOCAL SEARCH ENGINEAUTOMATIC SPEECH RECOGNITIONNLGAUDIO I/OTTSBACKCHANNEL GENERATORIMMIMHUBKNOWLEDGE BASEWavePackets1-Best WordsSegmentlabelN-Best Phrase ListWavePacketsMicro-Turn Dialogue ActSystem Dialogue ActString PacketsStringPacketsVoIP Interface (PJSIP)N-best Dialogue Act UnitsAPI call ( + metadata)Search ResponsePartial Dialogue Act (in case of interruption)PartialString(in case of interruption)SPOKEN LANGUAGE UNDERSTANDING Decode from t0 to t1Figure 1: Overview of the Parlance systemarchitecturethe modularity of a traditional SDS while atthe same time allowing for complex interactionat the micro-turn level between components.Each component described below makes useof the PINC (Parlance INCremental) dialogueact schema.
In this scheme, a complete dia-logue act is made up of a set of primitive di-alogue acts which are defined as acttype-itempairs.
The PINC dialogue act scheme supportsincrementality by allowing SLU to incremen-tally output primitive dialogue acts whenevera complete acttype-item pair is recognised withsufficient confidence.
The complete dialogueact is then the set of these primitive acts out-put during the utterance.3.1 Recognition and UnderstandingThe Automatic Speech Recogniser (ASR) andSpoken Language Understanding (SLU) com-ponents operate in two passes.
The audio in-put is segmented by a Voice Activity Detec-tor and then coded into feature vectors.
Forthe first pass of the ASR2, a fast bigram de-coder performs continuous traceback generat-ing word by word output.
During this pass,while the user is speaking, an SLU modulecalled the ?segment decoder?
is called incre-2http://mi.eng.cam.ac.uk/research/dialogue/ATK_Manual.pdfmentally as words or phrases are recognised.This module incrementally outputs the set ofprimitive dialogue acts that can be detectedbased on each utterance prefix.
Here, the ASRonly provides the single best hypothesis, andSLU only outputs a single set of primitive dia-logue acts, without an associated probability.On request from the Micro-turn InteractionManager (MIM), a second pass can be per-formed to restore the current utterance using atrigram language model, and return a full dis-tribution over the complete phrase as a con-fusion network.
This is then passed to theSLU module which outputs the set of alter-native complete interpretations, each with itsassociated probability, thus reflecting the un-certainty in the ASR-SLU understanding pro-cess.3.2 Interaction ManagementFigure 1 illustrates the role of the Micro-turnInteraction Manager (MIM) component in theoverall Parlance architecture.
In order toallow for natural interaction, the MIM is re-sponsible for taking actions such as listening tothe user, taking the floor, and generating back-channels at the micro-turn level.
Given variousfeatures from different components, the MIMselects a micro-turn action and sends it to theIM and back-channel generator component togenerate a system response.Micro-turn Interaction Manager Abaseline hand-crafted MIM was developedusing predefined rules.
It receives turn-takinginformation from the TTS, the audio-outputcomponent, the ASR and a timer, and updatesturn-taking features.
Based on the currentfeatures and predefined rules, it generatescontrol signals and sends them to the TTS,ASR, timer and HUB.
In terms of micro-turntaking, for example, if the user interruptsthe system utterance, the system will stopspeaking and listen to the user.
The systemalso outputs a short back-channel and stays inuser turn state if the user utterance provideslimited information.Interaction Manager Once the MIM hasdecided when the system should take the floor,it is the task of the IM to decide what to say.The IM is based on the partially observable155Markov decision process (POMDP) frame-work, where the system?s decisions can be op-timised via reinforcement learning.
The modeladopted for Parlance is the Bayesian Updateof Dialogue State (BUDS) manager (Thom-son and Young, 2010).
This POMDP-basedIM factors the dialogue state into condition-ally dependent elements.
Dependencies be-tween these elements can be derived directlyfrom the dialogue ontology.
These elementsare arranged into a dynamic Bayesian networkwhich allows for their marginal probabilitiesto be updated during the dialogue, compris-ing the belief state.
The belief state is thenmapped into a smaller-scale summary spaceand the decisions are optimised using the nat-ural actor critic algorithm.HUB The HUB manages the high level flowof information.
It receives turn change infor-mation from the MIM and sends commandsto the SLU/IM/NLG to ?take the floor?
in theconversation and generate a response.3.3 Generation and TTSWe aim to automatically generate language,trained from data, that is (1) grammaticallywell formed, (2) natural, (3) cohesive and (4)rapidly produced at runtime.
Whilst the firsttwo requirements are important in any dia-logue system, the latter two are key require-ments for systems with incremental processing,in order to be more responsive.
This includesgenerating back-channels, dynamic content re-ordering (Dethlefs et al 2012), and surfacegeneration that models coherent discourse phe-nomena, such as pronominalisation and co-reference (Dethlefs et al 2013).
Incremen-tal surfacce generation requires rich contextawareness in order to keep track of all that hasbeen generated so far.
We therefore treat sur-face realisation as a sequence labelling task anduse Conditional Random Fields (CRFs), whichtake semantically annotated phrase structuretrees as input, in order to represent long dis-tance linguistic dependencies.
This approachhas been compared with a number of compet-itive state-of-the art surface realisers (Deth-lefs et al 2013), and can be trained fromminimally labelled data to reduce developmenttime and facilitate its application to new do-mains.The TTS component uses a trainable HMM-based speech synthesizer.
As it is a paramet-ric model, HMM-TTS has more flexibility thantraditional unit-selection approaches and is es-pecially useful for producing expressive speech.3.4 Local Search and Knowledge BaseThe domain ontology is populated by the localsearch component and contains restaurants in5 regional areas of San Francisco.
Restaurantsearch results are returned based on their lon-gitude and latitude for 3 price ranges and 52cuisine types.4 Future WorkWe intend to perform a task-based evaluationusing crowd-sourced users.
Future versionswill use a dynamic Knowledge Base and UserModel for adapting to evolving domains andpersonalised interaction respectively.AcknowledgementsThe research leading to this work was funded by the ECFP7 programme FP7/2011-14 under grant agreementno.
287615 (PARLANCE).ReferencesT.
Baumann, O. Buss, and D. Schlangen.
2011.
Eval-uation and Optimisation of Incremental Processors.Dialogue and Discourse, 2(1).Nina Dethlefs, Helen Hastie, Verena Rieser, and OliverLemon.
2012.
Optimising Incremental Generationfor Spoken Dialogue Systems: Reducing the Needfor Fillers.
In Proceedings of INLG, Chicago, USA.N.
Dethlefs, H. Hastie, H. Cuay?huitl, and O. Lemon.2013.
Conditional Random Fields for ResponsiveSurface Realisation Using Global Features.
In Pro-ceedings of ACL, Sofia, Bulgaria.W.
Levelt.
1989.
Speaking: From Intenion to Articu-lation.
MIT Press.E.
Selfridge, I. Arizmendi, P. Heeman, and J. Williams.2011.
Stability and Accuracy in Incremental SpeechRecognition.
In Proceedings of SIGDIAL, Portland,Oregon.G.
Skantze and D. Schlangen.
2009.
Incremental Dia-logue Processing in a Micro-Domain.
In Proceedingsof EACL, Athens, Greece.B Thomson and S Young.
2010.
Bayesian update ofdialogue state: A POMDP framework for spokendialogue systems.
Computer Speech and Language,24(4):562?588.156
