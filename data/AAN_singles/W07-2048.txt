Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-2007), pages 227?230,Prague, June 2007. c?2007 Association for Computational LinguisticsLTH: Semantic Structure Extraction using Nonprojective Dependency TreesRichard Johansson and Pierre NuguesDepartment of Computer Science, Lund University, Sweden{richard, pierre}@cs.lth.seAbstractWe describe our contribution to the SemEvaltask on Frame-Semantic Structure Extrac-tion.
Unlike most previous systems de-scribed in literature, ours is based on depen-dency syntax.
We also describe a fully auto-matic method to add words to the FrameNetlexical database, which gives an improve-ment in the recall of frame detection.1 IntroductionThe existence of links between grammatical rela-tions and various forms of semantic interpretationhas long been observed; grammatical relations playa crucial role in theories of linking, i.e.
the realiza-tion of the semantic arguments of predicates as syn-tactic units (Manning, 1994; Mel?c?uk, 1988).
Gram-matical relations may be covered by many defini-tions but it is probably easier to use them as an exten-sion of dependency grammars, where relations takethe form of arc labels.
In addition, some linguisticphenomena such as wh-movement and discontinu-ous structures are conveniently described using de-pendency syntax by allowing nonprojective depen-dency arcs.
It has also been claimed that dependencysyntax is easier to understand and to teach to peoplewithout a linguistic background.Despite these advantages, dependency syntax hasrelatively rarely been used in semantic structure ex-traction, with a few exceptions.
Ahn et al (2004)used a post-processing step to convert constituenttrees into labeled dependency trees that were thenused as input to a semantic role labeler.
Pradhan etal.
(2005) used a rule-based dependency parser, butthe results were significantly worse than when usinga constituent parser.This paper describes a system for frame-semanticstructure extraction that is based on a dependencyparser.
The next section presents the dependencygrammar that we rely on.
We then give the de-tails on the frame detection and disambiguation, theframe element (FE) identification and classification,and dictionary extension, after which the results andconclusions are given.2 Dependency Parsing with the PennTreebankThe last few years have seen an increasing interestin dependency parsing (Buchholz and Marsi, 2006)with significant improvements of the state of the art,and dependency treebanks are now available for awide range of languages.
The parsing algorithmsare comparatively easy to implement and efficient:some of the algorithms parse sentences in linear time(Yamada and Matsumoto, 2003; Nivre et al, 2006).In the semantic structure extraction system, weused the Stanford part-of-speech tagger (Toutanovaet al, 2003) to tag the training and test sentences andMaltParser, a statistical dependency parser (Nivre etal., 2006), to parse them.We trained the parser on the Penn Treebank (Mar-cus et al, 1993).
The dependency trees used totrain the parser were created from the constituenttrees using a conversion program (Johansson andNugues, 2007)1.
The converter handles most ofthe secondary edges in the Treebank and encodesthose edges as (generally) nonprojective dependencyarcs.
Such information is available in the Penn Tree-bank in the form of empty categories and secondaryedges, it is however not available in the output oftraditional constituent parsers, although there havebeen some attempts to apply a post-processing stepto predict it, see Ahn et al (2004), inter alia.Figures 1 and 2 show a constituent tree from theTreebank and its corresponding dependency tree.Note that the secondary edge from the wh-trace toWhy is converted into a nonprojective PRP link.3 Semantic Structure ExtractionThis section describes how the dependency trees areused to create the semantic structure.
The system1Available at http://nlp.cs.lth.se/pennconverter227NPNPADVPWHADVPPRPSBJVPSQSBARQ*T*Why would intelligent beings kidnap seven Soviet mailmen *T* ?Figure 1: A constituent tree from the Penn Treebank.Why would intelligent beings kidnap seven Soviet mailmen ?NMODNMODNMODOBJVCPROOT?SBARQSBJPRPFigure 2: Converted dependency tree.is divided into two main components: frame detec-tion and disambiguation, and frame element detec-tion and classification.3.1 Frame Detection and Disambiguation3.1.1 Filtering RulesSince many potential target words appear insenses that should not be tagged with a frame, weuse a filtering component as a first step in the framedetection.
We also removed some words (espe-cially prepositions) that caused significant perfor-mance degradation because of lack of training data.With the increasing availability of tagged runningtext, we expect that we will be able to replace thefiltering rules with a classifier in the future.?
have was retained only if it had an object,?
be only if it was preceded by there,?
will was removed in its modal sense,?
of course and in particular were removed,?
the prepositions above, against, at, below, be-side, by, in, on, over, and under were removedunless their head was marked as locative,?
after and before were removed unless theirhead was marked as temporal,?
into, to, and through were removed unless theirhead was marked as direction,?
as, for, so, and with were always removed,?
since the only sense of of was PARTITIVE,we removed it unless it was preceded by only,member, one, most, many, some, few, part, ma-jority, minority, proportion, half, third, quar-ter, all, or none, or if it was followed by all,group, them, or us.We also removed all targets that had been taggedas support verbs for some other target.3.1.2 Sense DisambiguationFor the target words left after the filtering, weused a classifier to assign a frame, followingErk (2005).
We trained a disambiguating SVM clas-sifier on all ambiguous words listed in FrameNet.
Itsaccuracy was 84% on the ambiguous words, com-pared to a first-sense baseline score of 74%.The classifier used the following features: targetlemma, target word, subcategorization frame (forverb targets only), the set of dependencies of thetarget, the set of words of the child nodes, and theparent word of the target.The subcategorization frame feature was formedby concatenating the dependency labels of the chil-dren, excluding subject, parentheticals, punctuationand coordinations.
For instance, for kidnap in Fig-ure 2, the feature is PRP+OBJ.3.1.3 Extending the Lexical DatabaseCoverage is one of the main weaknesses of thecurrent FrameNet lexical database ?
it lists only10,197 lexical units, compared to 207,016 word?sense pairs in WordNet 3.0 (Fellbaum, 1998).
Wetried to remedy this problem by training classifiersto find words that are related to the words in a frame.We designed a feature representation for eachlemma in WordNet, which uses a sequence of iden-tifiers for each synset in its hypernym tree.
Allsenses of the lemma were used, and the featureswere weighted with respect to the relative frequencyof the sense.
Using this feature representation, wetrained an SVM classifier for each frame that tellswhether a lemma belongs to that frame or not.The FrameNet dictionary could thus be extendedby 18,372 lexical units.
If we assume a Zipf distri-bution and that the lexical units already in FrameNetare the most common ones, this would increase the228coverage by up to 9%.
In the test set, the new lexicalunits account for 53 out of the 808 target words oursystem detected (6.5%).
We roughly estimated theprecision to 70% by manually inspecting 100 ran-domly selected words in the extended dictionary.This strategy is most successful when the frameis equivalent to one or a few synsets (and theirsubtrees).
For instance, for the frame MEDI-CAL_CONDITION, we can add the complete sub-tree of the synset pathological state, resulting in641 new lemmas referring to all sorts of diseases.On the other hand, the strategy also works well formotion verbs (which often exhibit complex patternsof polysemy): 137 lemmas could be added to theSELF_MOTION frame.
Examples of frames with fre-quent errors are LEADERSHIP, which includes manyinsects (probably because the most frequent senseof queen in SemCor is the queen bee), and FOOD,which included many chemical substances as wellas inedible plants and animals.3.2 Frame Element ExtractionFollowing convention, we divided the FE extractioninto two subtasks: argument identification and argu-ment classification.
We did not try to assign multiplelabels to arguments.
Figure 3 shows an overview.
Inaddition to detecing the FEs, the argument identifi-cation classifier detects the dependency nodes thatshould be tagged on the layers other than the frameelement layer: SUPP, COP, NULL, EXIST, and ASP.The ANT and REL labels could be inserted usingsimple rules.
Similarly to Xue and Palmer (2004),ArgumentidentificationFESuppCopAspExistNullArgumentNoneSelf_moverPathetcclassificationFigure 3: FE extraction steps.we could filter away many nodes before the argu-ment identification step by assuming that the argu-ments for a given predicate correspond to a subset ofthe dependents of the target or of its transitive heads.Both classifiers were implemented using SVMsand use the following features: target lemma, voice(for verb targets only), subcategorization frame (forverb targets only), the set of dependencies of the tar-get, part of speech of the target node, path throughthe dependency tree from the target to the node, po-sition (before, after, or on), word and part of speechfor the head, word and part of speech for leftmostand rightmost descendent.In the path feature, we removed steps throughverb chains and coordination.
For instance, in thesentece I have seen and heard it, the path from heardto I is only SBJ?
and to it OBJ?.3.3 Named Entity RecognitionIn addition to the frame-semantic information, theSemEval task also scores named entities.
We usedYamCha (Kudo and Matsumoto, 2003) to detectnamed entities, and we trained it on the SemEvalfull-text training sets.
Apart from the word and partof speech, we used suffixes up to length 5 as fea-tures.
We think that results could be improved fur-ther by using an external NE tagger.4 ResultsThe system was evaluated on three texts.
Table 1shows the results for frame detection averaged overthe test texts.
In the Setting colums, the first showswhether Exact or Partial frame matching was usedby the evaluation script, and the second whether La-bels or Dependencies were used.
Table 2 comparesthe results of the system using the extended dictio-nary with one using the orignal FrameNet dictio-nary, using the Partial matching and Labels scoring.The extended dictionary introduces some noise andthus lowers the precision slightly, but the effects onthe recall are positive.
Table 3 shows the aver-Table 1: Results for frame detection.Setting Recall Precision F1E L 0.528 0.688 0.597P L 0.581 0.758 0.657E D 0.549 0.715 0.621P D 0.601 0.784 0.681Table 2: Comparison of dictionaries.Dictionary Recall Precision F1Original 0.550 0.767 0.634Extended 0.581 0.758 0.657229aged precision, recall, and F1 measures for differ-ent evaluation parameters.
The third column showswhether named entities were used (Y) or not (N).Interestingly, the scores are higher for the seman-tic dependency graphs than for flat labels, while thetwo other teams generally had higher scores for flatlabels.
We believe that the reason for this is that weused a dependency parser, and that the rules that weused to convert dependency nodes into spans mayhave produced some errors.
It is possible that the fig-ures would have been slightly higher if our programproduced semantic dependency graphs directly.Table 3: Results for frame and FE detection.Setting Recall Precision F1E L Y 0.372 0.532 0.438P L Y 0.398 0.570 0.468E D Y 0.389 0.557 0.458P D Y 0.414 0.594 0.488E L N 0.364 0.530 0.432P L N 0.391 0.570 0.464E D N 0.384 0.561 0.456P D N 0.411 0.600 0.4885 Conclusion and Future WorkWe have presented a system for frame-semanticstructure extraction that achieves promising results.While most previous systems have been based onconstituents, our system relies on a dependencyparser.
We also described an automatic method toadd new units to the FrameNet lexical database.To improve labeling quality, we would like to ap-ply constraints to the semantic output so that se-mantic type and coreness rules are obeyed.
In ad-dition, while the system described here is based onpipelined classification, recent research on seman-tic role labeling has shown that significant perfor-mance improvements can be gained by exploitinginterdependencies between arguments (Toutanova etal., 2005).
With an increasing amount of runningtext annotated with frame semantics, we believe thatthis insight can be extended to model interdependen-cies between frames as well.Our motivation for using dependency grammar isthat we hope that it will eventually make semanticstructure extraction easier to implement and moretheoretically well-founded.
How to best design thedependency syntax is also still an open question.Ideally, all arguments would be direct dependents ofthe predicate node and we could get rid of the sparseand brittle Path feature in the classifier.ReferencesDavid Ahn, Sisay Fissaha, Valentin Jijkoun, and Maartende Rijke.
2004.
The university of Amsterdam atSenseval-3: Semantic roles and logic forms.
In Pro-ceedings of SENSEVAL-3.Sabine Buchholz and Erwin Marsi.
2006.
CoNLL-Xshared task on multilingual dependency parsing.
InProceedings of the CoNLL-X.Katrin Erk.
2005.
Frame assignment as word sense dis-ambiguation.
In Proceedings of IWCS 6.Christiane Fellbaum, editor.
1998.
WordNet: An elec-tronic lexical database.
MIT Press.Richard Johansson and Pierre Nugues.
2007.
Extendedconstituent-to-dependency conversion for English.
InProceedings of NODALIDA 2007.
To appear.Taku Kudo and Yuji Matsumoto.
2003.
Fast methods forkernel-based text analysis.
In ACL-2003.Chistopher Manning.
1994.
Ergativity: Argument struc-ture and grammatical relations.Mitchell P. Marcus, Beatrice Santorini, and Mary AnnMarcinkiewicz.
1993.
Building a large annotated cor-pus of English: the Penn Treebank.
ComputationalLinguistics, 19(2):313?330.Igor A. Mel?c?uk.
1988.
Dependency Syntax: Theory andPractice.
State University Press of New York, Albany.Joakim Nivre, Johan Hall, and Jens Nilsson.
2006.
Malt-Parser: A data-driven parser generator for dependencyparsing.
In Proceedings of LREC.Sameer Pradhan, Wayne Ward, Kadri Hacioglu, JamesMartin, and Daniel Jurafsky.
2005.
Semantic role la-beling using different syntactic views.
In ACL-2005.Kristina Toutanova, Dan Klein, Christopher Manning,and Yoram Singer.
2003.
Feature-rich part-of-speechtagging with a cyclic dependency network.
In Pro-ceedings of HLT-NAACL.Kristina Toutanova, Aria Haghighi, and Christopher D.Manning.
2005.
Joint learning improves semantic rolelabeling.
In Proceedings of ACL 2005.Nianwen Xue and Martha Palmer.
2004.
Calibrating fea-tures for semantic role labeling.
In Proc.
of EMNLP.Hiroyasu Yamada and Yuji Matsumoto.
2003.
Statisticaldependency analysis with support vector machines.
InProceedings of IWPT-03.230
