Proceedings of the Workshop on Textual Entailment and Paraphrasing, pages 78?82,Prague, June 2007. c?2007 Association for Computational LinguisticsCombining Lexical-Syntactic Information with Machine Learning forRecognizing Textual EntailmentArturo Montejo-Ra?ez, Jose Manuel Perea, Fernando Mart?
?nez-Santiago,Miguel A?ngel Garc?
?a-Cumbreras, Maite Mart?
?n-Valdivia, Alfonso Uren?a-Lo?pezDpto.
de Informa?tica, Universidad de Jae?nCampus de las Lagunillas s/n, 23071 - Jae?n{amontejo, jmperea, dofer, magc, maite, laurena}@ujaen.esAbstractThis document contains the description ofthe experiments carried out by SINAI group.We have developed an approach based onseveral lexical and syntactic measures inte-grated by means of different machine learn-ing models.
More precisely, we have eval-uated three features based on lexical sim-ilarity and 11 features based on syntactictree comparison.
In spite of the relativelystraightforward approach we have obtainedmore than 60% for accuracy.
Since thisis our first participation we think we havereached a good result.1 Approach descriptionWe fill face the textual entailment recognition us-ing Machine Learning methods, i.e.
identifying fea-tures that characterize the relation between hypothe-sis and associated text and generating a model usingexisting entailment judgements that will allow us toprovide a new entailment judgement agains unseenpairs text-hypothesis.
This approach can be split intothe two processes shown in Figures 1 and 2.In a more formal way, given a text t and an hy-pothesis h we want to define a function e which takesthese two elements as arguments and returns and an-swer to the entailment question:e(t, h) ={ Y ES if h is entailed by tNO otherwise (1)Now the question is to find that ideal functionFigure 1: Training processesFigure 2: Classification processese(t, h).
We will approximate this function using abinary classifier:e?
(t, h) = bc(f,m) (2)wherebc is a binary classifierf is a set of featuresm is the learned model for the classifierTherefore, it only remains to select a binary clas-sifier and a feature extraction method.
We have per-formed two experiments with different choices forboth decisions.
These two experiments are detailedbelow.781.1 Lexical similarityThis experiment approaches the textual entailmenttask being based on the extraction of a set of lexicalmeasures that show the existing similarity betweenthe hypothesis-text pairs.
Our approach is similarto (Ferrandez et al, 2007) but we make matchingbetween similar words too while (Ferrandez et al,2007) apply exact matching (see below).The first step previous to the calculation of thedifferent measures is to preprocess the pairs usingthe English stopwords list.
Next we have used theGATE1 architecture to obtain the stems of tokens.Once obtained stems, we have applied four differentmeasures or techniques:?
Simple Matching: this technique consists ofcalculating the semantic distance between eachstem of the hypothesis and text.
If this dis-tance exceeds a threshold, both stems are con-sidered similar and the similarity weight valueincreases in one.
The accumulated weight isnormalized dividing it by the number of ele-ments of the hypothesis.
In this experiment wehave considered the threshold 0.5.
The valuesof semantic distance measure range from 0 to1.
In order to calculate the semantic distancebetween two tokens (stems), we have tried sev-eral measures based on WordNet (AlexanderBudanitsky and Graeme Hirst, 2001).
Lin?ssimilarity measure (Lin, 1998) was shown tobe best overall measures.
It uses the notion ofinformation content and the same elements asJiang and Conrath?s approach (Jiang and Con-rath, 1997) but in a different fashion:simL(c1, c2) = 2?
log p(lso(c1, c2))log p(c1) + log p(c2)where c1 and c2 are synsets, lso(c1,c2) isthe information content of their lowest super-ordinate (most specific common subsumer) andp(c) is the probability of encountering an in-stance of a synset c in some specific corpus(Resnik, 1995).
The Simple Matching tech-nique is defined in the following equation:SIMmatching =?i?H similarity(i)|H|1http://gate.ac.uk/where H is the set that contains the elements ofthe hypothesis and similarity(i) is defined like:similarity(i) ={ 1 if ?j ?
TsimL(i, j) > 0.50 otherwise?
Binary Matching: this measure is the samethat the previous one but modifying the simi-larity function:similarity(i) ={ 1 if ?j ?
T i = j0 otherwise?
Consecutive Subsequence Matching: thistechnique relies on forming subsequences ofconsecutive stems in the hypothesis and match-ing them in the text.
The minimal size of theconsecutive subsequences is two and the max-imum is the maximum size of the hypothesis.Every correct matching increases in one the fi-nal weight.
The sum of the obtained weights ofthe matching between subsequences of a cer-tain size or length is normalized by the numberof sets of consecutive subsequences of the hy-pothesis created for this length.
These weightsare accumulated and normalized by the size ofthe hypothesis less one.
The Consecutive Sub-sequence Matching technique is defined in thefollowing equations:CSSmatching =?|H|i=2 f(SHi)|H| ?
1where SHi is the set that contains the subse-quences of the hypothesis with i size or lengthand f(SHi) is defined like:f(SHi) =?j?SHi matching(j)|H| ?
i+ 1wherematching(i) ={ 1 if ?k ?
STi k = j0 otherwisewhere STi represents the set that contains thesubsequences with i size from text.?
Trigrams: this technique relies on forming tri-grams of words in the hypothesis and match-ing them in the text.
A trigram is a group of79three words.
If a hypothesis trigram matches intext, then the similarity weight value increasesin one.
The accumulated weight is normalizeddividing it by the number of trigrams of the hy-pothesis.1.2 Syntactic tree comparisonSome features have been extracted from pairshypothesis-text related to the syntactic informationthat some parser can produce.
The rationale be-hind it consists in measuring the similarity betweenthe syntactic trees of both hypothesis and associatedtext.
To do that, terms appearing in both trees areidentified (we call this alignment) and then, graphdistances (number of nodes) between those terms inboth trees are compared, producing certain values asresult.In our experiments, we have applied theCOLLINS (Collins, 1999) parser to generate thesyntactic tree of both pieces of text.
In Figure 3 theoutput of the syntactic parsing for a sample pair isshown.
This data is the result of the syntactical anal-ysis performed by the mentioned parser.
A graphbased view of the tree corresponding to the hypoth-esis is drawn in Figure 4.
This graph will help us tounderstand how certain similarity measures are ob-tained.Figure 3: Syntactic trees of sample hypothesis andits associated text<t>(TOP (S (LST (LS 0302) (.
.))
(NP (JJ Next) (NN year))(VP (VBZ is) (NP (NP (DT the) (JJ 50th) (NN anniversary))(PP (IN of) (NP (NP (DT the) (NNP Normandy) (NN invasion)(, ,)) (NP (NP (DT an)(NN event)) (SBAR (IN that) (S (VP(MD would) (RB n?t) (VP (VB have) (VP (VBN been) (ADJP(JJ possible)) (PP (IN without) (NP (NP (DT the) (NNPLiberty) (NN ships.))
(SBAR (S (NP (DT The) (NNSvolunteers)) (VP (VBP hope) (S (VP (TO to) (VP (VB raise)(NP (JJ enough) (NN money)) (S (VP (TO to) (VP (VB sail)(NP (DT the) (NNP O?Brien)) (PP (TO to) (NP (NNP France)))(PP (IN for)(NP (DT the) (JJ big) (NNP D-Day) (NN celebration)(.
.
))))))))))))))))))))))))))</t><h>(TOP (S (NP (NP (CD 50th) (NNP Anniversary)) (PP (IN of)(NP (NNP Normandy) (NNP Landings)))) (VP (VBZ lasts) (NP(DT a) (NN year) (.
.
)))))</h>From the sample above, the terms normandy, yearand anniversary appear in both pieces of text.
Wesay that these terms are ?aligned?.
Therefore, forthe three possible pairs of aligned terms we can com-pute the distance, in nodes, to go from one term tothe other at each tree.
Then, the difference of theseFigure 4: Syntact tree of sample hypothesisdistances is computed and some statistics are gener-ated.
We can summarize the process of computingthis differences in the algorithm detailed in Figure 6.Figure 5: Tree comparison processFor instance, in the tree represented in Figure 4we can see that we have to perform 5 steps to gofrom node Anniversary to node Normandy.
Sincethere are no more possible occurrences of these twoterms, then the minimal distance between them is5.
This value is also measured on the tree corre-80sponding to the text, and the absolute difference be-tween these two minimal distances is stored in orderto compute final feature weights consisting in basicstatistical values.
The algorithm to obtain the distri-bution of distance differences is detailed in Figure 6.Figure 6: Extraction of features based on syntacticdistanceInput:a syntactic tree of the hypothesis Sha syntactic tree of the text StOutput :the set of distance differencesDd = {ddij : ti, tj ?
T}Pseudo code:T ?
aligned terms between Sh and StDd ?
?for i = 1..n dofor j = i+ 1..n dodisth ?
minimal distance betweennodes ti and tj in Shdistt ?
minimal distance betweennodes ti and tj in Stddij ?
|disth ?
distt|Dd ?
{ddij} ?Ddend-forend-forThe statistics generated from the resulting list ofdistances differences Dd are the following:1.
The number of aligned terms (3 in the givenexample).2.
The number of matched POS values of alignedterms, that is, if the term appears with the samePOS label in both texts (in the example An-niversary differs in the POS label assigned).3.
The number of unmatched POS labels ofaligned terms.4.
The average distance in nodes through the syn-tactic tree to go from one aligned term to an-other.5.
The minimal distance difference found.Table 1: Results with TiMBL and BBR classifiers(Exp5 is the only official result reported in this pa-per).Experiment Classifier AccuracyExp1 BBR 0.6475Exp2 BBR 0.64625Exp3 BBR 0.63875Exp4 TiMBL 0.6062Exp5 TiMBL 0.6037Exp6 TiMBL 0.576.
The maximal distance difference found.7.
The standard deviation of distance differences.In a similar way, differences in the depth level ofnodes for aligned terms are also calculated.
Fromthe example exposed the following values werecomputed:* Aligned 3* MatchedPOS 2* UnmatchedPOS 1* AvgDistDiff 0.0392156863* MinDistDiff 0.0000000000* MaxDistDiff 0.0588235294* StdevDistDiff 0.0277296777* AvgDepthDiff 2.0000000000* MinDepthDiff 1.0000000000* MaxDepthDiff 3.0000000000* StdevDepthDiff 0.81649658092 Experiments and resultsThe algorithms used as binary classifiers are two:Bayesian Logistic Regression (BBR)2 and TiMBL(Daelemans et al, 1998).
Both algorithms have beentrained with the devel data provided by the organiza-tion of the Pascal challange.
As has been explainedin previous sections, a model is generated via thesupervised learning process.
This model m is thenfeed into the classification variant of the algorithm,which will decide whether a new hypothesis sampleis entailed by the given text or not.The experiments and results are shown in Table 1:where:?
Exp1 uses four features: three lexical similari-ties (SIMmatching + CSSmatching + Trigrams)and Syntactic tree comparison.2http://www.stat.rutgers.edu/?madigan/BBR/ [available atMarch 27, 2007]81?
Exp2 uses five features: four lexical similari-ties (SIMmatching + CSSmatching + Trigrams+ BINmatching) and Syntactic tree compari-son.?
Exp3 uses only three lexical similarities(SIMmatching + CSSmatching + Trigrams).?
Exp4 uses the four lexical similarities(SIMmatching + CSSmatching + Trigrams +BINmatching)?
Exp5 uses only three lexical similarities(SIMmatching + CSSmatching + Trigrams).?
Exp6 uses four features: three lexical similari-ties (SIMmatching + CSSmatching + Trigrams)and Syntactic tree comparison.As we expected, the best result we have obtainedis by means of the integration of the whole of thefeatures available.
More surprising is the good resultobtained by using lexical features only, even betterthan experiments based on syntactical features only.On the other hand, we expected that the integrationof both sort of features improve significatively theperformance of the system, but the improvement re-spect of lexical features is poor (less than 2%).
.Similar topics share similar vocabulary, but not sim-ilar syntax at all.
Thus, we think we should to inves-tigate semantic features better than the syntacticalones.3 Conclusions and future workIn spite of the simplicity of the approach, we haveobtained remarkable results: each set of features hasreported to provide relevant information concerningto the entailment judgement determination.
On theother hand, these two approaches can be merged intoone single system by using different features all to-gether and feeding with them several binary classi-fiers that could compose a voting system.
We willdo that combining TiMBL, SVM and BBR.We ex-pect to improve the performance of the entailmentrecognizer by this integration.Finally, we want to implement a hierarchical ar-chitecture based on constraint satisfaction networks.The constraints will be given by the set of avail-able features and the maintenance of the integrationacross the semantic interpretation process.4 AcknowledgementsThis work has been partially financed by theTIMOM project (TIN2006-15265-C06-03) grantedby the Spanish Government Ministry of Science andTechnology and the RFC/PP2006/Id 514 granted bythe University of Jae?n.ReferencesAlexander Budanitsky and Graeme Hirst.
2001.
Seman-tic distance in wordnet: An experimental, application-oriented evaluation of five measures.Michael Collins.
1999.
Head-Driven Statistical Modelsfor Natural Language Parsing.
Ph.D. thesis, Univer-sity of Pennsylvania.Walter Daelemans, Jakub Zavrel, Ko van der Sloot, andAntal van den Bosch.
1998.
Timbl: Tilburg memorybased learner, version 1.0, reference guide.Oscar Ferrandez, Daniel Micolo, Rafael Mu noz, andManuel Palomar.
2007.
Te?cnicas le?xico-sinta?cticaspara reconocimiento de inmplicacio?n textual.
.
Tec-nolog?
?as de la Informaco?n Multilingu?e y Multimodal.In press.Jay J. Jiang and David W. Conrath.
1997.
Semanticsimilarity based on corpus statistics and lexical taxon-omy.
In Proceedings of International Conference onResearch in Computational Linguistics, Taiwan.Dekang Lin.
1998.
An information-theoretic definitionof similarity.
In Proceedings of the 15th InternationalConference on Machine Learning.Philip Resnik.
1995.
Using information content to evalu-ate semantic similarity.
In Proceedings of the 14th In-ternational Joint Conference on Artificial Intelligence,Montreal.82
