Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 833?840,Sydney, July 2006. c?2006 Association for Computational LinguisticsJapanese Dependency Parsing Using Co-occurrence Information and aCombination of Case ElementsTakeshi AbekawaGraduate School of EducationUniversity of Tokyoabekawa@p.u-tokyo.ac.jpManabu OkumuraPrecision and Intelligence LaboratoryTokyo Institute of Technologyoku@pi.titech.ac.jpAbstractIn this paper, we present a method thatimproves Japanese dependency parsing byusing large-scale statistical information.
Ittakes into account two kinds of informa-tion not considered in previous statistical(machine learning based) parsing meth-ods: information about dependency rela-tions among the case elements of a verb,and information about co-occurrence re-lations between a verb and its case ele-ment.
This information can be collectedfrom the results of automatic dependencyparsing of large-scale corpora.
The resultsof an experiment in which our method wasused to rerank the results obtained using anexisting machine learning based parsingmethod showed that our method can im-prove the accuracy of the results obtainedusing the existing method.1 IntroductionDependency parsing is a basic technology for pro-cessing Japanese and has been the subject of muchresearch.
The Japanese dependency structure isusually represented by the relationship betweenphrasal units called bunsetsu, each of which con-sists of one or more content words that may befollowed by any number of function words.
Thedependency between two bunsetsus is direct froma dependent to its head.Manually written rules have usually been usedto determine which bunsetsu another bunsetsutends to modify, but this method poses problems interms of the coverage and consistency of the rules.The recent availability of larger-scale corpora an-notated with dependency information has thus re-sulted in more work on statistical dependencyanalysis technologies that use machine learning al-gorithms (Kudo and Matsumoto, 2002; Sassano,2004; Uchimoto et al, 1999; Uchimoto et al,2000).Work on statistical Japanese dependency analy-sis has usually assumed that all the dependency re-lations in a sentence are independent of each other,and has considered the bunsetsus in a sentence in-dependently when judging whether or not a pairof bunsetsus is in a dependency relation.
In judg-ing which bunsetsu a bunsetsu modifies, this typeof work has used as features the information oftwo bunsetsus, such as the head words of the twobunsetsus, and the morphemes at the ends of thebunsetsus (Uchimoto et al, 1999).
It is necessary,however, to also consider features for the contex-tual information of the two bunsetsus.
One suchfeature is the constraint that two case elementswith the same case do not modify a verb.Statistical Japanese dependency analysis takesinto account syntactic information but tends not totake into account lexical information, such as co-occurrence between a case element and a verb.The recent availability of more corpora has en-abled much information about dependency rela-tions to be obtained by using a Japanese depen-dency analyzer such as KNP (Kurohashi and Na-gao, 1994) or CaboCha (Kudo and Matsumoto,2002).
Although this information is less accu-rate than manually annotated information, theseautomatic analyzers provide a large amount ofco-occurrence information as well as informationabout combinations of multiple cases that tend tomodify a verb.In this paper, we present a method for improv-ing the accuracy of Japanese dependency analy-sis by representing the lexical information of co-occurrence and dependency relations of multiplecases as statistical models.
We also show the re-sults of experiments demonstrating the effective-ness of our method.833Keisatsu-de umibe-dehitori-de arui-teiru syonen-wo hogo-shita(The police/subj) (on the beach)(alone) (was walking) (boy/obj) (had custody)(The police had custody of the boy who was walking alone on the beach.
)Figure 1: Example of a Japanese sentence, bunsetsu and dependencies2 Parsing JapaneseThe Japanese language is basically an SOV lan-guage, but word order is relatively free.
In Englishthe syntactic function of each word is representedby word order, while in Japanese it is representedby postpositions.
For example, one or more post-positions following a noun play a role similar tothe declension of nouns in German, which indi-cates grammatical case.The syntax of a Japanese sentence is analyzedby using segments, called bunsetsu, that usuallycontain one or more content words like a noun,verb, or adjective, and zero or more functionwords like a particle (case marker) or verb/nounsuffix.
By defining a bunsetsu in this manner, wecan analyze a sentence in a way similar to that usedwhen analyzing the grammatical roles of words ininflected languages like German.Japanese dependencies have the following char-acteristics:?
Each bunsetsu except the rightmost one hasonly one head.?
Each head bunsetsu is always placed to theright of (i.e.
after) its modifier.?
Dependencies do not cross one another.Statistical Japanese dependency analyzers(Kudo and Matsumoto, 2005; Kudo and Mat-sumoto, 2002; Sassano, 2004; Uchimoto et al,1999; Uchimoto et al, 2000) automatically learnthe likelihood of dependencies from a taggedcorpus and calculate the best dependencies for aninput sentence.
These likelihoods are learned byconsidering the features of bunsetsus such as theircharacter strings, parts of speech, and inflectiontypes, as well as information between bunsetsussuch as punctuation and the distance betweenbunsetsus.
The weight of given features is learnedfrom a training corpus by calculating the weightsfrom the frequencies of the features in the trainingdata.3 Japanese dependency analysis takingaccount of co-occurrence informationand a combination of multiple casesOne constraint in Japanese is that multiple nounsof the same case do not modify a verb.
Previ-ous work on Japanese dependency analysis has as-sumed that all the dependency relations are inde-pendent of one another.
It is therefore necessaryto also consider such a constraint as a feature forcontextual information.
Uchimoto et al, for ex-ample, used as such a feature whether a particu-lar type of bunsetsu is between two bunsetsus in adependency relation (Uchimoto et al, 1999), andSassano used information about what is just be-fore and after the modifying bunsetsu and modi-fyee bunsetsu (Sassano, 2004).In the artificial example shown in Figure 1, itis natural to consider that ?keisatsu-de?
will mod-ify ?hogo-shita?.
Statistical Japanese dependencyanalyzers (Uchimoto et al, 2000; Kudo and Mat-sumoto, 2002), however, will output the resultwhere ?keisatsu-de?
modifies ?arui-teiru?.
This isbecause in sentences without internal punctuationa noun tends to modify the nearest verb, and theseanalyzers do not take into account a combinationof multiple cases.Another kind of information useful in depen-dency analysis is the co-occurrence of a noun anda verb, which indicates to what degree the nountends to modify the verb.
In the above example,the possible modifyees of ?keisatsu-de?
are ?arui-teiru?
and ?hogo-shita?.
Taking into account in-formation about the co-occurrence of ?keisatsu-de?
and ?arui-teiru?
and of ?keisatsu-de?
and?hogo-shita?
makes it obvious that ?keisatsu-de?is more likely to modify ?hogo-shita?.834In summary, we think that statistical Japanesedependency analysis needs to take into accountat least two more kinds of information: the de-pendency relation between multiple cases wheremultiple nouns of the same case do not modify averb, and the co-occurrence of nouns and verbs.One way to use such information in statistical de-pendency analysis is to directly use it as features.However, Kehler et al pointed out that this doesnot make the analysis more accurate (Kehler et al,2004).
This paper therefore presents a model thatuses the co-occurrence information separately andreranks the analysis candidates generated by theexisting machine learning model.4 Our proposed modelWe first introduce the notation for the explanationof the dependency structure T :m(T ) : the number of verbs in Tvi(T ) : the i-th verb in Tci(T ) : the number of case elements that mod-ify the i-th verb in Tesi(T ) : the set of case elements that modify thei-th verb in Trsi(T ) : the set of particles in the set of case el-ements that modify the i-th verb in Tnsi(T ) : the set of nouns in the set of case ele-ments that modify the i-th verb in Tri,j(T ) : the j-th particle that modifies the i-thverb in Tni,j(T ) : the j-th noun that modifies the i-th verbin TWe defined case element as a pair of a nounand following particles.
For the dependencystructure we assume the conditional probabilityP (esi(T )|vi(T )) that the set of case elementsesi(T ) depends on the vi(T ), and assume the setof case elements esi(T ) is composed of the set ofnoun nsi(T ) and particles rsi(T ).P (esi(T )|vi(T ))def= P (rsi(T ), nsi(T )|vi(T )) (1)= P (rsi(T )|vi(T )) ?P (nsi(T )|rsi(T ), vi(T )) (2)' P (rsi(T )|vi(T )) ?ci(T )?j=1P (ni,j(T)|rsi(T),vi(T)) (3)' P (rsi(T )|vi(T )) ?ci(T )?j=1P (ni,j(T)|ri,j(T),vi(T)) (4)In the transformation from Equation (2) to Equa-tion (3), we assume that the set of noun nsi(T ) isindependent of the verb vi(T ).
And in the trans-formation from Equation (3) to Equation (4), weassume that the noun ni,j(T ) is dependent on onlyits following particle ri,j(T ).Now we assume the dependency structure T ofthe whole sentence is composed of only the depen-dency relation between case elements and verbs,and propose the sentence probability defined byEquation (5).P (T ) =m(T )?i=1P (rsi(T )|vi(T )) ?ci(T )?j=1P (ni,j(T )|ri,j(T ), vi(T )) (5)We call P (rsi(T )|vi(T )) the co-occurrence prob-ability of the particle set and the verb, and wecall P (ni,j(T )|ri,j(T ), vi(T )) the co-occurrenceprobability of the case element set and the verb.In the actual dependency analysis, we try to se-lect the dependency structure T?
that maximizesthe Equation (5) from the possible parses T for theinputted sentence:T?
= argmaxTm(T )?i=1P (rsi(T )|vi(T )) ?ci(T )?j=1P (ni,j(T )|ri,j(T ), vi(T )).
(6)The proposed model is inspired by the semanticrole labeling method (Gildea and Jurafsky, 2002),which uses the frame element group in place of theparticle set.It differs from the previous parsing models inthat we take into account the dependency relationsamong particles in the set of case elements thatmodify a verb.
This information can constrain thecombination of particles (cases) among bunsetsusthat modify a verb.
Assuming the independenceamong particles, we can rewrite Equation (5) asP (T ) =m(T )?i=1ci(T )?j=1P (ni,j(T ), ri,j(T )|vi(T )).
(7)4.1 Syntactic property of a verbIn Japanese, the ?ha?
case that indicates a topictends to modify the main verb in a sentence andtends not to modify a verb in a relative clause.
The835verb: ?aru-ku?
verb: ?hogo-suru?case elements particle set case elements particle seta keisatsu-de umibe-de hitori-de { de,de,de } syonen-wo {wo}b umibe-de hitori-de {de,de} keisatsu-de syonen-wo {de,wo}c hitori-de {de} keisatsu-de umibe-de syonen-wo {de,de,wo}d {none} keisatsu-de umibe-de hitori-de syonen-wo { de,de,de,wo }Table 1: Analytical process of the example sentenceco-occurrence probability of the particle set there-fore tends to be different for verbs with differentsyntactic properties.Like (Shirai, 1998), to take into account the re-liance of the co-occurrence probability of the par-ticle set on the syntactic property of a verb, insteadof using P (rsi(T )|vi(T )) in Equation (5), we useP (rsi(T )|syni(T ), vi(T )), where syni(T ) is thesyntactic property of the i-th verb in T and takesone of the following three values:?verb?
when v modifies another verb?noun?
when v modifies a noun?main?
when v modifies nothing (when it is at theend of the sentence, and is the main verb)4.2 Illustration of model applicationHere, we illustrate the process of applying our pro-posed model to the example sentence in Figure 1,for which there are four possible combinations ofdependency relations.
The bunsetsu combinationsand corresponding sets of particles are listed in Ta-ble 1.
In the analytical process, we calculate forall the combinations the co-occurrence probabilityof the case element set (bunsetsu set) and the co-occurrence probability of the particle set, and weselect the T?
that maximizes the probability.Some of the co-occurrence probabilities of theparticle sets for the verbs ?aru-ku?
and ?hogo-suru?
in the sentence are listed in Table 2.
How toestimate these probabilities is described in section5.3.
Basically, the larger the number of particles,the lower the probability is.
As you can see in thecomparison between {de, wo} and {de, de}, theprobability becomes lower when multiple samecases are included.
Therefore, the probability canreflect the constraint that multiple case elementsof the same particle tend not to modify a verb.5 ExperimentsWe evaluated the effectiveness of our model ex-perimentally.
Since our model treats only the de-rsi P (rsi|noun, v1) P (rsi|main, v2)v1 = ?aru-ku?
v2 = ?hogo-suru?
{none} 0.29 0.35{wo} 0.30 0.24{ga} 0.056 0.072{ni} 0.040 0.041{de} 0.032 0.033{ha} 0.035 0.041{de, wo} 0.022 0.018{de, de} 0.00038 0.00038{de, de, wo} 0.00022 0.00018{de, de, de} 0.0000019 0.0000018{de, de, de, wo} 0.00000085 0.00000070Table 2: Example of the co-occurrence probabili-ties of particle setspendency relations between a noun and a verb, wecannot determine all the dependency relations ina sentence.
We therefore use one of the currentlyavailable dependency analyzers to generate an or-dered list of n-best possible parses for the sentenceand then use our proposed model to rerank themand select the best parse.5.1 Dependency analyzer for outputtingn-best parsesWe generated the n-best parses by using the ?pos-terior context model?
(Uchimoto et al, 2000).
Thefeatures we used were those in (Uchimoto et al,1999) and their combinations.
We also added ouroriginal features and their combinations, with ref-erence to (Sassano, 2004; Kudo and Matsumoto,2002), but we removed the features that had a fre-quency of less than 30 in our training data.
Thetotal number of features is thus 105,608.5.2 Reranking methodBecause our model considers only the dependencyrelations between a noun and a verb, and thuscannot determine all the dependency relations ina sentence, we restricted the possible parses for836reranking as illustrated in Figure 2.
The possi-ble parses for reranking were the first-ranked parseand those of the next-best parses in which theverb to modify was different from that in the first-ranked one.
For example, parses 1 and 3 in Figure2 are the only candidates for reranking.
In our ex-periments, n is set to 50.The score we used for reranking the parses wasthe product of the probability of the posterior con-text model and the probability of our proposedmodel:score = Pcontext(T )?
?
P (T ), (8)where Pcontext(T ) is the probability of the poste-rior context model.
The ?
here is a parameter withwhich we can adjust the balance of the two proba-bilities, and is fixed to the best value by consider-ing development data (different from the trainingdata)1.RerankingCandidate 1Candidate 2Candidate 3Candidate 4: Case element : VerbCandidateCandidateFigure 2: Selection of possible parses for rerankingMany methods for reranking the parsing of En-glish sentences have been proposed (Charniak andJohnson, 2005; Collins and Koo, 2005; Hender-son and Titov, 2005), all of which are discrimina-tive methods which learn the difference betweenthe best parse and next-best parses.
While ourreranking model using generation probability isquite simple, we can easily verify our hypothesisthat the two proposed probabilities have an effecton improving the parsing accuracy.
We can alsoverify that the parsing accuracy improves by usingimprecise information obtained from an automati-cally parsed corpus.Klein and Manning proposed a generativemodel in which syntactic (PCFG) and semantic(lexical dependency) structures are scored withseparate models (Klein and Manning, 2002), but1In our experiments, ?
is set to 2.0 using developmentdata.they do not take into account the combination ofdependencies.
Shirai et al also proposed a statis-tical model of Japanese language which integrateslexical association statistics with syntactic prefer-ence (Shirai et al, 1998).
Our proposed model dif-fers from their method in that it explicitly uses thecombination of multiple cases.5.3 Estimation of co-occurrence probabilityWe estimated the co-occurrence probability of theparticle set and the co-occurrence probability ofthe case element set used in our model by analyz-ing a large-scale corpus.
We collected a 30-yearnewspaper corpus2, applied the morphological an-alyzer JUMAN (Kurohashi and Nagao, 1998b),and then applied the dependency analyzer witha posterior context model3.
To ensure that wecollected reliable co-occurrence information, weremoved the information for the bunsetsus withpunctuation4.Like (Torisawa, 2001), we estimated the co-occurrence probability P (?n, r, v?)
of the caseelement set (noun n, particle r, and verb v)by using probabilistic latent semantic indexing(PLSI) (Hofmann, 1999)5.
If ?n, r, v?
is theco-occurrence of n and ?r, v?, we can calculateP (?n, r, v?)
by using the following equation:P (?n, r, v?)
=?z?ZP (n|z)P (?r, v?|z)P (z), (9)where z indicates a latent semantic class of co-occurrence (hidden class).
Probabilistic parame-ters P (n|z), P (?r, v?|z), and P (z) in Equation (9)can be estimated by using the EM algorithm.
Inour experiments, the dimension of the hidden classz was set to 300.
As a result, the collected ?n, r, v?total 102,581,924 pairs.
The number of n and v is57,315 and 15,098, respectively.The particles for which the co-occurrence prob-ability was estimated were the set of case particles,the ?ha?
case particle, and a class of ?fukujoshi?213 years?
worth of articles from the Mainichi Shimbun,14 years?
worth from the Yomiuri Shimbun, and 3 years?worth from the Asahi Shimbun.3We used the following package for calculation ofMaximum Entropy:http://homepages.inf.ed.ac.uk/s0450736/maxent toolkit.html.4The result of dependency analysis with a posterior con-text model for the Kyodai Corpus showed that the accuracyfor the bunsetsu without punctuation is 90.6%, while the ac-curacy is only 76.4% for those with punctuation.5We used the following package for calculation of PLSI:http://chasen.org/?taku/software/plsi/.837Bunsetsu accuracy Sentence accuracyWhole data Context model 90.95% (73,390/80,695) 54.40% (5,052/9,287)Our model 91.21% (73,603/80,695) 55.17% (5,124/9,287)Only for reranked sentences Context model 90.72% (68,971/76,026) 48,33% (3,813/7,889)Our model 91.00% (69,184/76,026) 49.25% (3,885/7,889)Only for case elements Context model 91.80% (28,849/31,427) ?Our model 92.47% (29,062/31,427) ?Table 3: Accuracy before/after rerankingparticles.
Therefore, the total number of particleswas 10.We also estimated the co-occurrence probabilityof the particle set P (rs|syn, v) by using PLSI.
Weregarded the triple ?rs, syn, v?
(the co-occurrenceof particle set rs, verb v, and the syntactic prop-erty syn) as the co-occurrence of rs and ?syn, v?.The dimension of the hidden class was 100.
Thetotal number of ?rs, syn, v?
pairs was 1,016,508,v was 18,423, and rs was 1,490.
The particle setshould be treated not as a non-ordered set but asan occurrence ordered set.
However, we think cor-rect probability estimation using an occurrence or-dered set is difficult, because it gives rise to an ex-plosion in the number of combination,5.4 Experimental environmentThe evaluation data we used was Kyodai Cor-pus 3.0, a corpus manually annotated with depen-dency relations (Kurohashi and Nagao, 1998a).The statistics of the data are as follows:?
Training data: 24,263 sentences, 234,474bunsetsus?
Development data: 4,833 sentences, 47,580bunsetsus?
Test data: 9,287 sentences, 89,982 bunsetsusThe test data contained 31,427 case elements, and28,801 verbs.The evaluation measures we used were bunsetsuaccuracy (the percentage of bunsetsu for which thecorrect modifyee was identified) and sentence ac-curacy (the percentage of sentences for which thecorrect dependency structure was identified).5.5 Experimental results5.5.1 Evaluation of our modelOur first experiment evaluated the effectivenessof reranking with our proposed model.
BunsetsuOur reranking modelcorrect incorrectContext model correct 73,119 271incorrect 484 6,821Table 4: 2 ?
2 contingency table of the number ofcorrect bunsetsu (posterior context model ?
ourmodel)and sentence accuracies before and after rerank-ing, for the entire set of test data as well as foronly those sentences whose parse was actuallyreranked, are listed in Table 3.The results showed that the accuracy could beimproved by using our proposed model to rerankthe results obtained with the posterior contextmodel.
McNemar testing showed that the null hy-pothesis that there is no difference between the ac-curacy of the results obtained with the posteriorcontext model and those obtained with our modelcould be rejected with a p value < 0.01.
Thedifference in accuracy is therefore significant.5.5.2 Comparing variant modelsWe next experimentally compare the followingvariations of the proposed model:(a) one in which the case element set is assumedto be independent [Equation (7)](b) one using the co-occurrence probability ofthe particle set, P (rs|syn, v), in our model(c) one using only the co-occurrence probabilityof the case element, P (n|r, v), in our model(d) one not taking into account the syntacticproperty of a verb (i,e.
a model in whichthe co-occurrence probability is defined asP (r|v), without the syntactic property syn)(e) one in which the co-occurrence probability ofthe case element, P (n|r, v), is simply added838Bunsetsu Sentenceaccuracy accuracyContext model 90.95% 54.40%Our model 91.21% 55.17%model (a) 91.12% 54.90%model (b) 91.10% 54.69%model (c) 91.11% 54.91%model (d) 91.15% 54.82%model (e) 90.96% 54.33%model (f) 89.50% 48.33%Kudo et al2005 91.37% 56.00%Table 5: Comparison of various modelsto a feature set used in the posterior contextmodel(f) one using only our proposed probabilitieswithout the probability of the posterior con-text modelThe accuracies obtained with each of thesemodels are listed in Table 5, from which we canconclude that it is effective to take into account thedependency between case elements because model(a) is less accurate than our model.Since the accuracy of model (d) is comparableto that of our model, we can conclude that the con-sideration of the syntactic property of a verb doesnot necessarily improve dependency analysis.The accuracy of model (e), which uses the co-occurrence probability of the case element set asfeatures in the posterior context model, is compa-rable to that of the posterior context model.
Thisresult is similar to the one obtained by (Kehler etal., 2004), where the task was anaphora resolution.Although we think the co-occurrence probabilityis useful information for dependency analysis, thisresult shows that simply adding it as a feature doesnot improve the accuracy.5.5.3 Changing the amount of training dataChanging the size of the training data set, weinvestigated whether the degree of accuracy im-provement due to reranking depends on the accu-racy of the existing dependency analyzer.Figure 3 shows that the accuracy improvementis constant even if the accuracy of the dependencyanalyzer is varied.5.6 DiscussionThe score used in reranking is the product of theprobability of the posterior context model and the0.8940.8960.8980.90.9020.9040.9060.9080.910.9120.9144000  6000  8000  10000  12000  14000  16000  18000  20000  22000  24000  26000No.
of training sentencesBunsetsuaccuracyposterior context modelproposed modelFigure 3: Bunsetsu accuracy when the size of thetraining data is changedprobability of our proposed model.
The results inTable 5 show that the parsing accuracy of model(f), which uses only the probabilities obtained withour proposed model, is quite low.
We think thereason for this is that our two co-occurrence prob-abilities cannot take account of syntactic proper-ties, such as punctuation and the distance betweentwo bunsetsus, which improve dependency analy-sis.Furthermore, when the sentence has multipleverbs and case elements, the constraint of our pro-posed model tends to distribute case elements toeach verb equally.
To investigate such bias, wecalculated the variance of the number of case ele-ments per verb.Table 6 shows that the variance for our proposedmodel (Equation [5]) is the lowest, and this modeldistributes case elements to each verb equally.
Thevariance of the posterior context model is higherthan that of the test data, probably because thesyntactic constraint in this model affects parsingtoo much.
Therefore the variance of the rerankingmodel (Equation [8]), which is the combinationof our proposed model and the posterior contextmodel, is close to that of the test data.The best parse which uses this data set is (Kudoand Matsumoto, 2005), and their parsing accuracyis 91.37%.
The features and the parsing methodused by their model are almost equal to the poste-rior context model, but they use a different methodof probability estimation.
If their model couldgenerate n-best parsing and attach some kind ofscore to each parse tree, we would combine theirmodel in place of the posterior context model.At the stage of incorporating the proposed ap-proach to a parser, the consistency with other pos-839context model test data Equation [8] Equation [5]variance (?2) 0.724 0.702 0.696 0.666*The average number of elements per verb is 1.078.Table 6: The variance of the number of elements per verbsible methods that deal with other relations shouldbe taken into account.
This will be one of our fu-ture tasks.6 ConclusionWe presented a method of improving Japanese de-pendency parsing by using large-scale statisticalinformation.
Our method takes into account twotypes of information, not considered in previousstatistical (machine learning based) parsing meth-ods.
One is information about the dependency re-lations among the case elements of a verb, and theother is information about co-occurrence relationsbetween a verb and its case element.
Experimen-tal results showed that our method can improve theaccuracy of the existing method.ReferencesEugene Charniak and Mark Johnson.
2005.
Coarse-to-fine n-best parsing and maxent discriminativereranking.
In Proceedings of the 43rd Annual Meet-ing of the ACL, pages 173?180.Michael Collins and Terry Koo.
2005.
Discriminativereranking for natural language parsing.
Computa-tional Linguistics, 31(1):25?69.Daniel Gildea and Daniel Jurafsky.
2002.
Automaticlabeling of semantic roles.
Computational Linguis-tics, 28(3):245?288.James Henderson and Ivan Titov.
2005.
Data-definedkernels for parse reranking derived from probabilis-tic models.
In Proceedings of the 43rd Annual Meet-ing of the ACL, pages 181?188.Thomas Hofmann.
1999.
Probabilistic latent semanticindexing.
In Proceedings of the 22nd Annual Inter-national SIGIR Conference on Research and Devel-opment in Information Retrieval, pages 50?57.Andrew Kehler, Douglas Appelt, Lara Taylor, andAleksandr Simma.
2004.
The (non)utility ofpredicate-argument frequencies for pronoun inter-pretation.
In Proceedings of the HLT/NAACL 2004,pages 289?296.Dan Klein and Christopher D. Manning.
2002.
Fastexact inference with a factored model for naturallanguage parsing.
In Advances in Neural Informa-tion Processing Systems 15 (NIPS 2002), pages 3?10.Taku Kudo and Yuji Matsumoto.
2002.
Japanesedependency analysis using cascaded chunking.
InCoNLL 2002: Proceedings of the 6th Conference onNatural Language Learning 2002 (COLING 2002Post-Conference Workshops), pages 63?69.Taku Kudo and Yuji Matsumoto.
2005.
Japanese de-pendency parsing using relative preference of depen-dency.
Transactions of Information Processing So-ciety of Japan, 46(4):1082?1092.
(in Japanese).Sadao Kurohashi andMakoto Nagao.
1994.
Kn parser:Japanese dependency/case structure analyzer.
InProceedings of the Workshop on Sharable NaturalLanguage Resources, pages 48?55.Sadao Kurohashi and Makoto Nagao.
1998a.
Buildinga Japanese parsed corpus while improving the pars-ing system.
In Proceedings of the 1st InternationalConference on Language Resources and Evaluation,pages 719?724.Sadao Kurohashi andMakoto Nagao.
1998b.
JapaneseMorphological Analysis System JUMAN version3.5.
Department of Informatics, Kyoto University.
(in Japanese).Manabu Sassano.
2004.
Linear-time dependency anal-ysis for Japanese.
In Proceedings of the COLING2004, pages 8?14.Kiyoaki Shirai, Kentaro Inui, Takenobu Tokunaga, andHozumi Tanaka.
1998.
An empirical evaluation onstatistical parsing of Japanese sentences using lexi-cal association statistics.
In Proceedings of the 3rdConference on EMNLP, pages 80?87.Kiyoaki Shirai.
1998.
The integrated natural languageprocessing using statistical information.
TechnicalReport TR98?0004, Department of Computer Sci-ence, Tokyo Institute of Technology.
(in Japanese).Kentaro Torisawa.
2001.
An unsupervised method forcanonicalization of Japanese postpositions.
In Pro-ceedings of the 6th Natural Language ProcessingPacific Rim Symposium (NLPRS), pages 211?218.Kiyotaka Uchimoto, Satoshi Sekine, and Hitoshi Isa-hara.
1999.
Japanese dependency structure analy-sis based on maximum entropy models.
Transac-tions of Information Processing Society of Japan,40(9):3397?3407.
(in Japanese).Kiyotaka Uchimoto, Masaki Murata, Satoshi Sekine,and Hitoshi Isahara.
2000.
Dependency modelusing posterior context.
In Proceedings of theSixth International Workshop on Parsing Technol-ogy (IWPT2000), pages 321?322.840
