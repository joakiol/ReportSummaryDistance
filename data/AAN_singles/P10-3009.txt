Proceedings of the ACL 2010 Student Research Workshop, pages 49?54,Uppsala, Sweden, 13 July 2010. c?2010 Association for Computational LinguisticsGrowing Related Words from Seed via User Behaviors: A Re-rankingBased ApproachYabin Zheng Zhiyuan Liu Lixing XieState Key Laboratory on Intelligent Technology and SystemsTsinghua National Laboratory for Information Science and TechnologyDepartment of Computer Science and Technology, Tsinghua University, Beijing 100084,China{yabin.zheng, lzy.thu, lavender087}@gmail.comAbstractMotivated by Google Sets, we study the prob-lem of growing related words from a singleseed word by leveraging user behaviors hidingin user records of Chinese input method.
Ourproposed method is motivated by the observa-tion that the more frequently two words co-occur in user records, the more related they are.First, we utilize user behaviors to generatecandidate words.
Then, we utilize search en-gine to enrich candidate words with adequatesemantic features.
Finally, we reorder candi-date words according to their semantic rela-tedness to the seed word.
Experimental resultson a Chinese input method dataset show thatour method gains better performance.1 IntroductionWhat is the relationship between ????????
(Natural Language Processing) and ?????
?
(Artificial Intelligence)?
We may regardNLP as a research branch of AI.
Problems arisewhen we want to find more words related to theinput query/seed word.
For example, if seedword ???????
?
(Natural LanguageProcessing) is entered into Google Sets (Google,2010), Google Sets returns an ordered list of re-lated words such as  ??????
(Artificial In-telligence) and ?????
(Computer).
Generallyspeaking, it performs a large-scale clustering al-gorithm that can gather related words.In this paper, we want to investigate the ad-vantage of user behaviors and re-ranking frame-work in related words retrieval task using Chi-nese input method user records.
We construct aUser-Word bipartite graph to represent the in-formation hiding in user records.
The bipartitegraph keeps users on one side and words on theother side.
The underlying idea is that the morefrequently two words co-occur in user records,the more related they are.
For example, ??????
(Machine Translation) is quite related to ??????
(Chinese Word Segmentation) becausethe two words are usually used together by re-searchers in natural language processing com-munity.
As a result, user behaviors offer a newperspective for measuring relatedness betweenwords.
On the other hand, we can also recom-mend related words to users in order to enhanceuser experiences.
Researchers are always willingto accept related terminologies in their researchfields.However, the method is purely statistics basedif we only consider co-occurrence aspect.
Wewant to add semantic features.
Sahami and Hel-man (2006) utilize search engine to supply webqueries with more semantic context and gainsbetter results for query suggestion task.
We bor-row their idea in this paper.
User behaviors pro-vide statistic information to generate candidatewords.
Then, we can enrich candidate wordswith additional semantic features using searchengine to retrieve more relevant candidates earli-er.
Statistical and semantic features can comple-ment each other.
Therefore, we can gain betterperformance if we consider them together.The contributions of this paper are threefold.First, we introduce user behaviors in relatedword retrieval task and construct a User-Wordbipartite graph from user behaviors.
Words areused by users, and it is reasonable to measurerelatedness between words by analyzing userbehaviors.
Second, we take the advantage of se-mantic features using search engine to reordercandidate words.
We aim to return more relevantcandidates earlier.
Finally, our method is unsu-pervised and language independent, which meansthat we do not require any training set or manuallabeling efforts.The rest of the paper is organized as follows.Some related works are discussed in Section 2.Then we introduce our method for related wordsretrieval in Section 3.
Experiment results anddiscussions are showed in Section 4.
Finally,Section 5 concludes the whole paper and givessome future works.492 Related WorkFor related words retrieval task, Google Sets(Google, 2010) provides a remarkably interestingtool for finding words related to an input word.As stated in (Zheng et al, 2009), Google Setsperforms poor results for input words in Chineselanguage.
Bayesian Sets (Ghahramani and Heller,2006) offers an alternative method for relatedwords retrieval under the framework of Bayesianinference.
It computes a score for each candidateword by comparing the posterior probability ofthat word given the input, to the prior probabilityof that candidate word.
Then, it returns a rankedlist of candidate words according to their com-puted scores.Recently, Zheng et al (2009) introduce userbehaviors in new word detection task via a colla-borative filtering manner.
They extend their me-thod to related word retrieval task.
Moreover,they prove that user behaviors provide a newpoint for new word detection and related wordretrieval tasks.
However, their method is purelystatistical method without considering semanticfeatures.We can regard related word retrieval task asproblem of measuring the semantic relatednessbetween pairs of very short texts.
Sahami andHelman (2006) introduce a web kernel functionfor measuring semantic similarities using snip-pets of search results.
This work is followed byMetzler et al, (2007), Yih and Meek, (2007).They combine the web kernel with other metricsof similarity between word vectors, such as Jac-card Coefficient and KL Divergence to enhancethe result.In this paper, we follow the similar idea of us-ing search engine to enrich semantic features of aquery word.
We regard the returned snippets asthe context of a query word.
And then we reordercandidate words and expect more relevant candi-date words can be retrieved earlier.
More detailsare given in Section 3.3 Related Words RetrievalIn this section, we will introduce how to findrelated words from a single seed word via userbehaviors and re-ranking framework.First, we introduce the dataset utilized in thispaper.
All the resource used in this paper comesfrom Sogou Chinese pinyin input method (Sogou,2006).
We use Sogou for abbreviation hereafter.Users can install Sogou on their computers andthe word lists they have used are kept in theiruser records.
Volunteers are encouraged to upl-oad their anonymous user records to the serverside.
In order to preserve user privacy, user-names are hidden using MD5 hash algorithm.Then we demonstrate how to build a User-Word bipartite graph based on the dataset.
Theconstruction can be accomplished while travers-ing the dataset with linear time cost.
We willgive more details in Section 3.1.Second, we adopt conditional probability(Deshpande and Karypis, 2004) to measure therelatedness of two words.
Intuitively, two wordsare supposed to be related if there are a lot ofusers who have used both of them.
In otherwords, the two words always co-occur in userrecords.
Starting from a single seed word, we cangenerate a set of candidate words.
This is thecandidate generation step.Third, in order to take the advantage of seman-tic features, we carry out feature extraction tech-niques to represent generated candidate wordswith enriched semantic context.
In this paper, wegenerally make use of search engine to conductthe feature extraction step.
After this step, inputseed word and candidate words are representedas feature vectors in the vector space.Finally, we can reorder generated candidatewords according to their semantic relatedness ofthe input seed word.
We expect to retrieve morerelevant candidate words earlier.
We will makefurther explanations about the mentioned steps inthe next subsections.3.1 Bipartite Graph ConstructionAs stated before, we first construct a User-Wordbipartite graph from the dataset.
The bipartitegraph has two layers, with users on one side andthe words on the other side.
We traverse the userrecords, and add a link between user u and wordw if w appears in the user record of u.
Thus thisprocedure can be accomplished in linear time.In order to give better explanations of bipartitegraph construction step, we show some userrecords in Figure 1 and the corresponding bipar-tite graph in Figure 2.Fig.
1.
User Records SampleUser1 Word1 ????
(Natural Language)Word2????
(Artificial Intelligence)Word3 ????
(Machine Translation)Word2????
(Artificial Intelligence)Word4 ????
(Information Retrieval)Word3 ????
(Machine Translation)Word1 ????
(Natural Language)User2User350Fig.
2.
Corresponding Bipartite GraphFrom Figure 1, we can see that Word1 andWord2 appear in User1?s record, which indicatesthat User1 has used Word1 and Word2.
As a result,in Figure 2, node User1 is linked with nodeWord1 and Word2.
The rest can be done in thesame manner.3.2 Candidates GenerationAfter the construction of bipartite graph, we canmeasure the relatedness of words from the bipar-tite graph.
Intuitively, if two words always co-occur in user records, they are related to eachother.
Inspired by (Deshpande and Karypis,2004), we adopt conditional probability to meas-ure the relatedness of two words.In particular, the conditional probability ofword j occurs given that word i has already ap-peared is the number of users that used bothword i and word j divided by the total number ofusers that used word i.
( )( | )         (1)( )Freq ijP j i Freq i?In formula 1, Freq(X) is the number of usersthat have used words in the set X.
We can clearlysee that P(j|i) ?
P(i|j), which means that condi-tional probability leads to asymmetric relations.The disadvantage is that each word i tends tohave a close relationship with stop words that areused quite frequently in user records, such as???
(of) and ????
(a).In order to alleviate this problem, we considerthe conditional probabilities P(j|i) and P(i|j) to-gether.
Word i and word j is said to be quite re-lated if conditional probabilities P(j|i) and P(i|j)are both relatively high.
We borrow the idea pro-posed in (Li and Sun, 2007).
In their paper, aweighted harmonic averaging is used to definethe relatedness score between word i and word jbecause either P(j|i) or P(i|j) being too small is asevere detriment.11( , )    (2)( | ) ( | )Score i j P i j P j i?
?
??
???
??
??
?In formula 2, parameter [0,1]?
?
is the weightfor P(i|j), which denotes how much P(i|j) shouldbe emphasized.
We carry out some comparativeexperiments when parameter ?
varies from 0 to 1stepped by 0.1.
We also tried other co-occurrence based measures like mutual informa-tion, Euclidean and Jaccard distance, and foundthat weight harmonic averaging gives relativelybetter results.
Due to space limitation, we are notable to report detailed results.So far, we have introduced how to calculatethe relatedness Score(i, j) between word i andword j.
When a user enters an input seed word w,we can compute Score(w,c) between seed wordw and each candidate word c, and then sort can-didate words in a descending order.
Top N can-didate words are kept for re-ranking, we aim toreorder top N candidate words and return themore related candidate words earlier.
Alterna-tively, we can also set a threshold for Score(w,c),which keeps the candidate word c with Score(w,c)larger than the threshold.
We argue that this thre-shold is difficult to set because different seedwords have different score thresholds.Note that this candidate generation step iscompletely statistical method as we only consid-er the co-occurrence of words.
We argue thatsemantic features can be a complement of statis-tical method.3.3 Semantic Feature Representation andRe-rankingAs stated before, we utilize search engine toenrich semantic features of the input seed wordand top N candidate words.
To be more specific,we issue a word to a search engine (Sogou, 2004)and get top 20 returned snippets.
We regardsnippets as the context and the semantic repre-sentation of this word.For an input seed word w, we can generate topN candidate words using formula (2).
We issueeach word to search engine and get returnedsnippets.
Then, each word is represented as afeature vector using bag-of-words model.
Fol-lowing the conventional approach, we calculatethe relatedness between the input seed word wand a candidate word c as the cosine similaritybetween their feature vectors.
Intuitively, if weintroduce more candidate words, we are morelikely to find related words in the candidate sets.However, noisy words are inevitably included.We will show how to tune parameter N in theexperiment part.W1U1U2U3W2W3W451As a result, candidate words with higher se-mantic similarities can be returned earlier withenriched semantic features.
Re-ranking can beregarded as a complementary step after candidategeneration.
We can improve the performance ofrelated word retrieval task if we consider userbehaviors and re-ranking together.4 ExperimentIn this section, we demonstrate our experimentresults.
First, we introduce the dataset used inthis paper and some statistics of the dataset.
Then,we build our ground truth for related word re-trieval task using Baidu encyclopedia.
Third, wegive some example of related word retrieval task.We show that more related words can be re-turned earlier if we consider semantic features.Finally, we make further analysis of the parame-ter tuning mentioned before.4.1 Experiment SettingsWe carry out our experiment on Sogou Chineseinput method dataset.
The dataset contains10,000 users and 183,870 words, and the numberof edges in the constructed bipartite graph is42,250,718.
As we can see, the dataset is quitesparse, because most of the users tend to use onlya small number of words.For related word retrieval task, we need tojudge whether a candidate word is related to theinput seed word.
We can ask domain experts toanswer this question.
However, it needs a lot ofmanual efforts.
To alleviate this problem, weadopt Baidu encyclopedia (Baidu, 2006) as ourground truth.
In Baidu encyclopedia, volunteersgive a set of words that are related to the particu-lar seed word.
As related words are provided byhuman, we are confident enough to use them asour ground truth.We randomly select 2,000 seed words as ourvalidation set.
However, whether two words arerelated is quite subjective.
In this paper, Baiduencyclopedia is only used as a relatively accuratestandard for evaluation.
We just want to investi-gate whether user behaviors and re-rankingframework is helpful in the related word retrievaltask under various evaluation metrics.We give a simple example of our method inTable 1.
The input seed word is ??????
(Machine Learning).
Generally speaking, allthese returned candidate words are relevant tothe seed word to certain degree, which indicatesthe effectiveness of our method.????
(feature vector) ???
(kernel function)???
(training set) ???
(decision tree)???
(classifier) ???
(test set)??
(dimension reduc-tion)????
(feature ex-traction)Table 1.
Words Related to ?Machine Learning?4.2 Evaluation MetricsIn this paper, we use three evaluation metrics tovalidate the performance of our method:1.
Precision@N (P@N).
P@N measures howmuch percent of the topmost results returnedare correct.
We consider P@5 and P@10.2.
Binary preference measure (Bpref) (Buck-ley and Voorhees, 2004).
As we cannot listall the related words of an input seed word,we use Bpref to evaluate our method.
For aninput seed word with R judged candidatewords where r is a related word and n is anonrelated word.
Bpref is defined as follow:1 |     |1     (3)rn ranked higher than rBpref R R?
??3.
Mean reciprocal rank of the first retrievedresult (MRR).
For a sample of input seedwords W, ranki is the rank of the first relatedcandidate word for the input seed word wi,MRR is the average of the reciprocal ranksof results, which is defined as follow:1 1      (4) i iMRR W rank?
?4.3 Candidate Re-rankingIn order to show the effectiveness of semanticfeatures and re-ranking framework, we give anexample in Table 2.
The input seed word is ?????
(Ericsson), and if we only take user beha-viors into consideration, top 5 words returned areshown on the left side.
After using search engineand semantic representation, we reorder the can-didate words as shown on the right side.Input Seed Word: ???
(Ericsson)Top 5 Candidates After Re-ranking??
(Nortel) ?????
(SonyEricsson)??
(ZTE Corporation) ??
(Sony Ericsson)??
(Base Station) ????
(Alcatel)????
(Alcatel) ??
(Sony)???
(Core Network) ??
(Huawei)Table 2.
Candidate Re-ranking52As shown in Table 2, we can clearly see thatwe return the most related candidate words suchas ???????
(Sony Ericsson) and ????
(the abbreviation of Sony Ericsson in Chinese) inthe first two places.
Moreover, after re-ranking,top candidate words are some famous brands thatare quite related to query word ?????
(Erics-son).
Some words like ?????
(Core Network)that are not quite related to the query word areremoved from the top list.
From this observation,we can see that semantic features and re-rankingframework can improve the performance.4.4 Parameter TuningAs discussed in Section 3, we have introducedtwo parameters in this paper.
The first is the pa-rameter ?
in the candidate generation step, andthe other is the parameter N in the re-rankingstep.
We show how these two parameters affectthe performance.
In addition, we should emphas-ize that the ground truth is not a complete answer,so all the results are only useful for comparisons.The absolute value is not very meaningful.As we have shown in Section 3.2, parameter ?adjusts the weight of conditional probability be-tween two word i, j.
The parameter ?
is variedfrom 0 to 1 stepped by 0.1.
We record the cor-responding values of P@5, P@10, Bpref andMRR.
The results are shown in Figure 3.We can clearly see that all the values increasewhen ?
increases first.
And then all the valuesdecrease dramatically when ?
is close to 1.
Thisindicates that either P(j|i) or P(i|j) being toosmall is a severe detriment.
The result reachespeak value when ?=0.5, i.e.
we should treat P(j|i)and P(i|j)equally to get the best result.
Therefore,we use ?=0.5 to generate candidate words, thosecandidates are used for re-ranking.Fig.
3.
Parameter ?
for Candidate GenerationWe also carry out the comparisons with Baye-sian Sets, which is shown in Table 3.
It is clearthat our method gains better results than Baye-sian Sets with different values of parameter ?.Results of Google Sets are omitted here becauseZheng et al (2009) have already showed thatGoogle Sets performs worse than Bayesian Setswith query words in Chinese.Bpref MRR P@5 P@10?
= 0.4 0.2057 0.4267 0.2352 0.195?
= 0.5 0.2035 0.4322 0.2414 0.2019?
= 0.6 0.2038 0.4292 0.2408 0.2009Bayesian Sets 0.2033 0.3291 0.1842 0.1512Table 3.
Comparisons with Bayesian SetsTo investigate the effectiveness of re-rankingframework, we also conduct experiments on theparameter N that is used for re-ranking.
The ex-perimental results are shown in Figure 4.Fig.
4.
Top N Candidates for Re-rankingWe can observe that more candidates tend toharm the performance as noisy words are intro-duced inevitably.
For example, Bpref drops toless than 0.25 when N = 100.
More comparativeresults are shown in Table 4.
We can see that N =20 gives relatively best results, which indicatesthat we should select Top 20 candidate words forre-ranking.Bpref MRR P@5 P@10Non Re-ranking 0.2035 0.4322 0.2414 0.2019N = 10 0.3208 0.456 0.2752 0.2019N = 20 0.3047 0.4511 0.2769 0.2301N = 30 0.2899 0.4444 0.272 0.2305Table 4.
Comparisons with Re-ranking Method5 Conclusions and Future WorkIn this paper, we have proposed a novel methodfor related word retrieval task.
Different fromother method, we consider user behaviors, se-mantic features and re-ranking framework to-gether.
We make a reasonable assumption that iftwo words always co-occur in user records, then53they tend to have a close relationship with eachother.
Based on this assumption, we first gener-ate a set of candidate words that are related to aninput seed word via user behaviors.
Second, weutilize search engine to enrich candidates withsemantic features.
Finally, we can reorder thecandidate words to return more related candi-dates earlier.
Experiment results show that ourmethod is effective and gains better results.However, we also observed some noisy wordsin the returned results.
As our dataset is generat-ed from Chinese input method, users can typewhatever they want, which will bring some noisein the dataset.
We plan to remove noisy words inthe future.
Furthermore, we want to take the ad-vantage of learning to rank literature (Liu, 2009)to further improve the performance of relatedword retrieval task.
We may need to extract morefeatures to represent the word pairs and build alabeled training set.
Then various machine learn-ing techniques can be used in this task.Another important issue is how to build acomplete and accurate ground truth for relatedword retrieval task.
People may have differentopinions about whether two words are related ornot, which makes this problem complicate.Thirdly, our method can only process a singleseed word, so we aim to extend our method toprocess multiple seed words.
In addition, wewant to build a network of Chinese word associa-tion.
We can discover how words are organizedand connected within this network.
And thisword association network will be quite useful forforeigners to learn Chinese.Fourthly, how to deal with ambiguous queryword is also left as our future work.
For example,query word ?apple?
can refer to a kind of fruit oran IT company.
As a result, we are expected toreturn two groups of related words instead ofmixing them together.Finally, our dataset provides a new perspectivefor many interesting research tasks like newword detection, social network analysis, user be-havior analysis, and so on.
We are trying to re-lease our dataset for research use in the future.AcknowledgementWe thank Xiance Si and Wufeng Ke for provid-ing the Baidu encyclopedia corpus for evaluation.We also thank the anonymous reviewers for theirhelpful comments and suggestions.
This work issupported by a Tsinghua-Sogou joint researchproject.ReferencesBaidu.
2006.
Baidu Encyclopedia.
Available athttp://baike.baidu.comChris Buckley and Ellen M. Voorhees.
2004.
Retriev-al Evaluation with Incomplete Information.
In Pro-ceedings of the 27th annual international ACMSIGIR conference on Research and development ininformation retrieval, pp 25-32Mukund Deshpande and George Karypis.
2004.
Item-Based Top-N Recommendation Algorithms, ACMTrans.
Information Systems, 22(1): 143-177Zoubin Ghahramani and Katherine A. Heller.
2005.Bayesian Sets.
In Advances in Neural InformationProcessing SystemsGoogle.
Google Sets.
Accessed on Feb. 9th, 2010,available at: http://labs.google.com/setsJingyang Li and Maosong Sun.
2007.
Scalable termselection for text categorization, In Proceedings ofthe 2007 Joint Conference on Empirical Methodsin Natural Language Processing and Computa-tional Natural Language Learning, pp.
774-782Tie-Yan Liu.
2009.
Learning to Rank for InformationRetrieval, Foundation and Trends on InformationRetrieval, Now PublishersDonald Metzler, Susan T. Dumais, and ChristopherMeek.
2007.
Similarity measures for short seg-ments of text.
In Proceeding of the 29th EuropeanConference on Information Retrieval, pp 16-27Mehran Sahami and Timothy D. Heilman.
2006.
Aweb-based kernel function for measuring the simi-larity of short text snippets.
In Proceedings of the15th International Conference on World Wide Web,pp 377-386Sogou.
2006.
Sogou Chinese Pinyin Input Method.Available at http://pinyin.sogou.com/Sogou.
2004.
Sogou Search Engine.
Available athttp://www.sogou.comWen-Tau Yih and Christopher Meek.
2007.
Improv-ing similarity measures for short segments of text.In Proceedings of AAAI 2007, pp 1489-1494Yabin Zheng, Zhiyuan Liu, Maosong Sun, Liyun Ru,and Yang Zhang.
2009.
Incorporating User Beha-viors in New Word Detection.
In Proceedings ofthe Twenty-First International Joint Conference onArtificial Intelligence, pp 2101-210654
