A Powerful and General Approach to Context Exploitation in NaturalLanguage ProcessingRobert W. Means1*, Syrus C. Nemat-Nasser1,Adrian T. Fan1, and Robert Hecht-Nielsen2,11 Fair Isaac Corporation3661 Valley Centre DriveSan Diego, CA 92130* rwm@fairisaac.com2 Computational NeurobiologyInstitute for Neural ComputationECE DepartmentUniversity of California, San DiegoLa Jolla, CA 92093-0407rh-n@ucsd.eduAbstractIn natural language, the meaning of a lexemeoften varies due to the specific surroundingcontext.
Computational approaches to naturallanguage processing can benefit from a reli-able, long-range-context-dependent represen-tation of the meaning of each lexeme thatappears in a given sentence.
We have devel-oped a general new technique that produces acontext-dependent ?meaning?
representationfor a lexeme in a specific surrounding context.The ?meaning?
of a lexeme in a specific con-text is represented by a list of semantically re-placeable elements the members of which areother lexemes from our experimental lexicon.We have performed experiments with a lexi-con composed of individual English wordsand also with a lexicon of individual wordsand selected phrases.
The resulting lists can beused to compare the ?meaning?
of conceptualunits (individual words or frequently-occurring phrases) in different contexts andalso can serve as features for machine learningapproaches to classify semantic roles and rela-tionships.1 IntroductionStatistical natural language approaches build modelsbased on annotated corpora as well as unlabeled cor-pora.
The latter, requiring unsupervised knowledge ac-quisition, has the advantage of larger training sets?it ispossible to exploit corpora composed of billions ofwords.
A number of researchers have observed that suchuse of very large corpora improves the stability of statis-tical models (e.g.
Banko and Brill, 2001).The mathematical procedures employed here are basedupon Hecht-Nielsen?s neuroscience theory of cognition(Hecht-Nielsen, 2003).
In a nutshell, this theory holdsthat cognition is based upon a procedure of ruling out allunreasonable conclusions and then deciding, of the re-maining conclusions, which are the least worst ones.This mathematical symbolic predictive technique iscalled confabulation.
The knowledge employed by con-fabulation is vast quantities of conditional probabilitiesfor pairs of symbols.
This knowledge, which is of novalue for reasoning or probabilistic inference, is readilyobtainable.
Hecht-Nielsen?s discovery is that, given theproper coding of a problem into symbols, confabulationworks essentially as well as reasoning would if we werein possession of the necessary ?omniscient?
knowledgethat reasoning requires.
Unfortunately, ?omniscient?knowledge is not practically obtainable, thereby makingattempts to implement reasoning, in any form, futile.Confabulation, on the other hand, although it does re-quire storage and use of large volumes of knowledge, issimple and practical (e.g., see Table 5 for the number ofitems of knowledge used in the experiments reportedhere).
Confabulation provides an explicit mechanismthat can now be used to build artificial intelligence.Our approach to ?meaning?
representation for lex-emes is to provide a set of similar elements that aregrammatically and/or semantically interchangeable witha given lexeme.
Others have constructed lexical similar-ity clusters using order-dependent co-occurrence statis-tics, particularly with N-gram models?see Brown et al(1992) for an example where words are sorted into ex-clusive classes based on bigram statistics.
The occur-rence statistics of bigrams do stabilize for frequentwords given a training corpus of hundreds of millions ofwords.
However, beyond tri-grams, the theoretical sizeof a training corpus required for completeness is unrea-sonable.
Our method uses only pairwise conditionals.To analyze a given text stream, we use a hierarchyconsisting of a word-level representation and a concep-tual-unit-level representation to analyze arbitrary sin-gle-clause English sentences.
Each of these representa-tions uses a lexicon of language element tokens toencode free text as described below.
The representationof a sentence with two levels of hierarchy at the wordlevel and the phrase level is consistent with Late As-signment of Syntax Theory, an analysis by synthesismodel advocated by Townsend and Bever (2001).2 Lexicon ConstructionWe construct a case-sensitive word-level lexicon basedon frequency of occurrence in our large English textcorpus of approximately 100 million sentences contain-ing more than 2.3 billion white-space-separated tokens.The raw corpus was assembled from a number ofnewswire corpora, spanning roughly 14 years beginningin 1988, and hand-selected modern-English, after 1800,Gutenberg texts.
We limit our lexicon to 63,000 tokensat which point the frequency rank corresponds to aminimum of 1000 occurrences.After construction of our word-level lexicon, weconstruct a postword word-level knowledge base for usein creating a conceptual-unit lexicon.
To create thisword-level knowledge base, we count token bigramoccurrences within our corpus and then calculate ante-cedent support conditional probabilities as follows:  Fora given token ti representing the ith word in our lexicon,for each word lexicon token tj that occurs immediatelyfollowing ti in the training corpus, the antecedent sup-port probability is approximated as:)t(c)t,t(c)t|t(p jjiji ?
(1)where )t,t(c ji  is the count of the times the jth wordfollows the ith word in the corpus and )t(c j  is the totalcount of the jth word in the corpus, excluding occur-rences immediately following a punctuation mark.Based on these quantities, ?meaningful?
knowledge isidentified and assigned non-zero weights in the post-word knowledge base if it has a co-occurrence count3)t,t(c ji ?
and antecedent support probability4ji 100.1)t|t(p?
?> .
Approximately 17 million token-to-token knowledge items satisfied these two condi-tions.We compose our conceptual-unit lexicon from the63,000 word-level tokens plus an additional 63,000automatically identified conceptual units, each consist-ing of between two and five word tokens.
Conceptualunits are identified using the pairwise postword word-level knowledge base as follows for each sentence in thetraining corpus:?
Assume the ith word of a sentence starts a concep-tual unit;?
As long as p(ith word| (ith+1) word) > T0, the con-ceptual unit continues up to a maximum length;?
Punctuation marks, such as commas and quota-tion marks terminate a conceptual unit directly.The maximum conceptual unit length and the thresholdT0 have been somewhat arbitrarily chosen as 5 and 02.0respectively.
We implement a complete frequency sortof all observed conceptual units in the corpus.
All con-ceptual units with a minimum of 1000 occurrences areretained.
These 63,000 additional tokens are added tothe word level lexicon resulting in a conceptual unitlexicon with 126,000 unique tokens.
Figure 1 illustratesthe segmentation of an example sentence into word-level tokens and conceptual-unit-level tokens.Figure 1.
Segmentation of a sentence into wordtokens and conceptual unit tokens3 SRE ExpansionA Semantically Replaceable Element (SRE) is a wordor conceptual unit that can be used as a grammatically-consistent, semantically similar substitute in a givenlinguistic context.
An SRE is similar to a synonym.However, words and conceptual units are rarely exactsynonyms and often have multiple meanings that onlybecome clear in context.
Our SRE expansion methoduses knowledge derived from the entire training corpusto produce a list of ?synonyms?
and then uses specificsurrounding context in a sentence to prune this list ofcandidates into a list of SREs.SRE expansion proceeds as follows: A test sentencewithout internal punctuation is presented to the system.This sentence is represented twice, once as a sequenceof individual word tokens and once as a sequence ofconceptual unit tokens (Figure 1).
Figure 2 illustratesthe hierarchical architecture used for SRE expansion.The hierarchy has two layers: a word analysis layer anda conceptual unit analysis layer.
We create knowledgebases between the tokens in the conceptual unit layerand the tokens in the word layer in the same mannerdescribed for the postword word-level knowledge base.A conceptual unit has connections both to and from itspostwords and prewords.
Separate knowledge bases toand from the conceptual unit layer are created for bothpostwords and prewords of conceptual units out to adistance of plus or minus two words (see Figure 2).These knowledge bases are normalized to limit the dy-namic range of the strengths.
Normalization proceeds asfollows:?
If ti is not followed by tj at least 3 times in our cor-pus, the knowledge item is discarded;?
If )t|t(p ji  is less than or equal to a threshold41 100.1T?
?= , the knowledge item is discarded;?
The strength Wji to token tj from token ti is calcu-lated as )T/)t|t(p(logW 1ji2ji = .Logarithmic scaling of the antecedent support probabil-ity reflects a biologically-inspired compression of dy-namic range.Figure 2.
The hierarchical knowledge architecture:One conceptual unit representation region is usedfor SRE expansion along with two preceding wordregions and two postword regions.
Solid arrowsindicate independent pairwise unidirectionalknowledge bases.
Dashed arrows indicate the cor-respondence between a conceptual unit and theindividual word tokens from which it is composed.The knowledge bases between the conceptual unit layerand the word layer are used to create a list of potentialsynonyms.
This is done by activating a token for the ithconceptual unit in the sentence in the conceptual unitregion (Y in Figure 2).
The conceptual-unit-to-wordknowledge bases activate other tokens in the four pre-word and postword regions (X-2, X-1, X+1, and X+2 inFigure 2).
Each token within these regions is activatedwith the strength Wji.
Those word tokens, in turn, acti-vate tokens back in the conceptual unit region by meansof the word-to-conceptual-unit knowledge bases.
Theresult is a set of active tokens in the original conceptualunit region that are potential synonyms.
This processdoes not rely on the specific sentence context; it uses theknowledge bases, trained on the entire corpus, to pro-duce candidate synonyms.
For example, when a word(e.g.
?suit?)
is placed on the conceptual unit region, itspreword and postword tokens are ?excited?
in the wordregions below with strength of excitation equal to thecorresponding weights.
Those words in turn excite po-tential synonyms that have most potential senses in theconceptual unit region (e.g.
lawsuit, jacket).
The firstfourteen potential synonyms are listed in Table 1.
Othersenses of ?suit?
are also excited with strengths that de-pend on their usage in the training corpus.suitsuitslawsuitjacketshirtpantslawsuitsjacketstrouserscoatshirtssweaterblazerslackscivil suitTable 1.
The first fourteen potential synonymsof the conceptual unit ?suit?To perform SRE expansion for a given sentence, wefirst generate a list of up to 100 candidate synonyms foreach conceptual unit?It is possible though rare for aword token to return less than 100 potential synonymsusing the procedure described above.
The words sur-rounding the conceptual unit are then used to removeentries, pruning the list of potential synonyms.
We useup to two prewords and two postwords.
Due to edgeeffects at the start and end of the sentence, we alwayshave 2, 3, or 4 context words.
The pruning operationproceeds in two steps: First, we count the number ofknowledge base connections from the surrounding con-text words to the actual word in the sentence; theseitems of knowledge must be present in the word-to-conceptual unit knowledge bases (Figure 2).
Second, we?confirm?
potential synonyms that receive an equal orgreater number of connections from the surroundingcontext words.
The pruned list is termed an SRE expan-sion.
It tends to have semantic and syntactic agreementwith the given conceptual unit.Apple filed a suit against IBMSun Microsystems had filed a lawsuit against Microsoft AT&TCompaq alleges a civil suit versus IntelIntel dismissed a complaint was filed Intel Corp.IGM settled the suit vs. HewlettPackardSun to drop lawsuits filed DellMicrosoft copyright suits alleging MicrosoftLotus the lawsuit accusing OracleDigital suits that gave MotorolaMicrosoft Corp. classaction lawsuit struggle against SonyIntel Corp. a petition in federal court Apple ComputerComputer an appeal were filed General MotorsPower a motion charging General ElectricAST a claim against Yugoslavia's NECGenentech civil suits that ended DigitalInternational Business Machines lawsuit was sparked 3MAscend in a suit that followed American ExpressMCI a class action brought Philip MorrisAT&T in a lawsuit to oust Procter & GambleMotorola the complaint stemming from KodakTable 2.
SRE expansion example: the word ?suit?
as in lawsuit.
The first nineteen expansion terms aredisplayed.He wore a suit to the weddingWearing the suit to his birthdaywearing suits to their bridalwore a jacket to our funeralwears a coat to the traditional graduationwho wore a white to his own marriagewas wearing a shirt to the military galaand wearing a black to her cocktailwho wears a gray to a Weddingdonned a helmet to my Christmasto wear a T-shirt to your mourningwear camouflage lavishdon inauguralis wearing black-tiedonning festivehis trademark coronationhe wore promshirt glitteringjacket chiffontrademark eveningTable 3.
SRE expansion example: the word ?suit?
as in clothing.
The first nineteen expansion termsare displayed.These arbitrarily chosen phrases demonstrate our meaning representationThose unfairly chose words demonstrated one's significance representationsMany randomly constructed language to demonstrate to our truth protectionsThe two automatically shaped songs demonstrates my purpose protectionA few strictly themes demonstrating on our motives treatmentThey deliberately symbols illustrate people's interpretation distributionYou properly rhetoric indicate our commitment dimension expressionThe first they have been sentences have demonstrated their sense approximationcarefully images have shown the government's motives imagesshould not be poems prove your nature participationwho have been words confirm its commitment dimensions and democraticshould be remarks suggest America's expression descriptionare being the word reveal of their phrase supervisioncorrectly names underscore to their truths recognitionappropriately to describe show the ability insight statuswere being texts to prove the administration's identity constituencythey will be scenes assess the president's emotion votingthey had been colors underline their skills themes equationsroutinely comments reflect Washington's message immunityselectively doubts about the party's vitality disclosureTable 4.
SRE expansion example: an arbitrary sentence.Knowledge Base Items of KnowledgeY to X-2 16,432,495Y to X-1 16,189,554Y to X+1 13,594,106Y to X+2 16,796,927X-2 to Y 22,451,444X-1 to Y 22,089,368X+1 to Y 17,597,506X+2 to Y 23,973,514Table 5.
Size of knowledge bases used for theSRE expansionThe SRE expansion procedure was applied to 33 sen-tences which contained a total of 233 words.
Each wordhad 100 possible synonyms.
The average number ofconfirmed synonyms due to the surrounding contextwas 28.2 with a standard deviation of 35.7.
Tables 2, 3,and 4 present three example sentences that have beenexpanded using our method?a maximum of nineteenexpansion terms are displayed.4 DiscussionOur SRE expansion method provides a context-specific?meaning?
representation providing application builderswith features that could be applied to problems includ-ing word sense disambiguation and named entity recog-nition.
Miller et al (2004) describe a relevant techniquefor the latter.
To quantify the quality of our SRE expan-sions will require an end-user application demonstrationthat we are unable to provide at this time.Our approach uses a very large training corpus, a hi-erarchical architecture, and nine independent pairwiseco-occurrence knowledge bases.
Individually, thesecomponents have, in some form, been applied to com-putational natural language processing by other re-searchers.
However, the combination of thesecomponents in our biologically-inspired framework hasalready produced novel methods that may prove usefulto the computational linguistics community.Our knowledge bases are large, but they are not ex-haustive.
Our confirmation method accommodates acertain amount of missing knowledge?instances  wheretwo language elements should be linked, but our train-ing procedure has failed to identify this link.
This ap-proach is a compromise reflecting the fact that ourknowledge bases still need improvement.
To fix defi-ciencies in our current knowledge bases, we requirefurther development.
We do not believe that a pure un-supervised statistical learning approach will suffice.Instead, we are working to develop ?education?
proce-dures that apply supervised learning and hybrid learningtechniques to improve the quality and completeness ofour pairwise knowledge bases.The authors wish to acknowledge significant pastand present contributions to this project by Rion L.Snow and Katherine Mark.ReferencesBanko, Michele and Brill, Eric, ?Learning Curves andNatural Language Disambiguation?, Proceedings ofHLT, pp.
93-99, 2001.Brown, P.F., V.J.
Della Pietra, P.V.
deSouza, J.C. Lai,and R.L.
Mercer, ?Class-based n-gram models ofnatural language?, Association for ComputationalLinguistics, 1992.Hecht-Nielsen, R., ?A theory of thalamocortex?
In:Hecht-Nielsen, R. and T. McKenna (Eds.
), Compu-tational Models for Neuroscience, pp.
85?124, Lon-don: Springer-Verlag, 2003.Miller, S., Guineness, J., and A. Zamanian, ?Name tag-ging with word clusters and discriminative training?,To appear in Proceedings of HLT, 2004.Townsend, David J. and Thomas G. Bever, SentenceComprehension, The MIT Press, Cambridge MA,2001.
