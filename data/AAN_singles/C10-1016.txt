Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 134?142,Beijing, August 2010Simultaneous Ranking and Clustering of Sentences: A ReinforcementApproach to Multi-Document Summarization1Xiaoyan Cai, 1Wenjie Li, 1You Ouyang, 2Hong Yan1Department of Computing, The Hong Kong Polytechnic University{csxcai,cswjli,csyouyang}@comp.polyu.edu.hk2Department of Logistics and Maritime Studies, The Hong Kong Polytechnic Universitylgthyan@polyu.edu.hkAbstractMulti-document summarization aims toproduce a concise summary that containssalient information from a set of sourcedocuments.
In this field, sentence rankinghas hitherto been the issue of most concern.Since documents often cover a number oftopic themes with each theme representedby a cluster of highly related sentences,sentence clustering was recently explored inthe literature in order to provide moreinformative summaries.
Existing cluster-based ranking approaches applied clusteringand ranking in isolation.
As a result, theranking performance will be inevitablyinfluenced by the clustering result.
In thispaper, we propose a reinforcement approachthat tightly integrates ranking and clusteringby mutually and simultaneously updatingeach other so that the performance of bothcan be improved.
Experimental results onthe DUC datasets demonstrate itseffectiveness and robustness.1 IntroductionAutomatic multi-document summarization hasdrawn increasing attention in the past with therapid growth of the Internet and informationexplosion.
It aims to condense the original textinto its essential content and to assist infiltering and selection of necessary information.So far extractive summarization that directlyextracts sentences from documents to composesummaries is still the mainstream in this field.Under this framework, sentence ranking is theissue of most concern.Though traditional feature-based rankingapproaches and graph-based approachesemployed quite different techniques to ranksentences, they have at least one point incommon, i.e., all of them focused on sentencesonly, but ignored the information beyond thesentence level (referring to Figure 1(a)).Actually, in a given document set, thereusually exist a number of themes (or topics)with each theme represented by a cluster ofhighly related sentences (Harabagiu andLacatusu, 2005; Hardy et al, 2002).
Thesetheme clusters are of different size andespecially different importance to assist usersin understanding the content in the wholedocument set.
The cluster level information issupposed to have foreseeable influence onsentence ranking.Figure 1.
Ranking vs. ClusteringIn order to enhance the performance ofsummarization, recently cluster-based rankingapproaches were explored in the literature(Wan and Yang, 2006; Sun et al 2007; Wanget al 2008a,b; Qazvinian and Radev, 2008).Normally these approaches applied a clusteringalgorithm to obtain the theme clusters first andthen ranked the sentences within each clusteror by exploring the interaction betweensentences and obtained clusters (referring toFigure 1(b)).
In other words, clustering andranking are regarded as two independentprocesses in these approaches although thecluster-level information has been incorporatedinto the sentence ranking process.
As a result,Ranking RankingClusteringRankingClustering(a)                           (b)                           (c)134the ranking performance is inevitablyinfluenced by the clustering result.To help alleviate this problem, we argue inthis paper that the quality of ranking andclustering can be both improved when the twoprocesses are mutually enhanced (referring toFigure 1(c)).
Based on it, we propose areinforcement approach that updates rankingand clustering interactively and iteratively tomulti-document summarization.
The maincontributions of the paper are three-fold: (1)Three different ranking functions are definedin a bi-type document graph constructed fromthe given document set, namely global, within-cluster and conditional rankings, respectively.
(2) A reinforcement approach is proposed totightly integrate ranking and clustering ofsentences by exploring term rank distributionsover the clusters.
(3) Thorough experimentalstudies are conducted to verify theeffectiveness and robustness of the proposedapproach.The rest of this paper is organized as follows.Section 2 reviews related work in cluster-basedranking.
Section 3 defines ranking functionsand explains reinforced ranking and clusteringprocess and its application in multi-documentsummarization.
Section 4 presents experimentsand evaluations.
Section 5 concludes the paper.2 Related WorkClustering has become an increasinglyimportant topic with the explosion ofinformation available via the Internet.
It is animportant tool in text mining and knowledgediscovery.
Its ability to automatically groupsimilar textual objects together enables one todiscover hidden similarity and key concepts, aswell as to summarize a large amount of textinto a small number of groups (Karypis et al,2000).To summarize a scientific paper, Qazvinianand Radev (2008) presented two sentenceselection strategies based on the clusters whichwere generated by a hierarchicalagglomeration algorithm applied in the citationsummary network.
One was called C-RR,which started with the largest cluster andextracted the first sentence from each cluster inthe order they appeared until the summarylength limit was reached.
The other was calledC-LexRank, which was similar to C-RR butadopted LexRank to rank the sentences withineach cluster and chose the most salient one.Meanwhile, Wan and Yang (2008) proposedtwo models to incorporate the cluster-levelinformation into the process of sentenceranking for generic summarization.
While theCluster-based Conditional Markov RandomWalk model (ClusterCMRW) incorporated thecluster-level information into the text graphand manipulated clusters and sentences equally,the Cluster-based HITS model (ClusterHITS)treated clusters and sentences as hubs andauthorities in the HITS algorithm.Besides, Wang et al (2008) proposed alanguage model to simultaneously cluster andsummarize documents.
Nonnegativefactorization was performed on the term-document matrix using the term-sentencematrix as the base so that the document-topicand sentence-topic matrices could beconstructed, from which the document clustersand the corresponding summary sentenceswere generated simultaneously.3 A Reinforcement Approach toMulti-document Summarization3.1 Document Bi-type GraphFirst of all, let?s introduce the sentence-termbi-type graph model for a set of givendocuments D, based on which the algorithm ofreinforced ranking and clustering is developed.Let >=< WEVG ,, , where V is the set ofvertices that consists of the sentence set},,,{ 21 nsssS ?=  and the term set},,{ 21 mtttT ,?= , i.e., TSV ?= , E is the set ofedges that connect the vertices, i.e.,},|,{ VvvvvE jiji ?><= .
W is the adjacencymatrix in which the element ijw  represents theweight of the edge connecting iv  and jv .Formally, W can be decomposed into fourblocks, i.e., SSW , STW , TSW  and TTW , eachrepresenting a sub-graph of the textual objectsindicated by the subscripts.
W can be written as???????
?=TTTSSTSSWWWWW ,where ),( jiWST  is the number of times theterm jt  appears in the sentence is .
)(i,jWSS  is135the number of common terms in the sentencesis  and js .
TSW  is equal toTSTW  as therelationships between terms and sentences aresymmetric.
For simplification, in this study weassume there is no direct relationships betweenterms, i.e., 0=TTW .
In the future, we willexplore effective ways to integrate termsemantic relationships into the model.3.2 Basic Ranking FunctionsRecall that our ultimate goal is sentenceranking.
As an indispensable part of theapproach, the basic ranking functions need tobe defined first.3.2.1 Global Ranking (without Clustering)Let )( isr  (i=1, 2, ?, n) and )( jtr  (j=1, 2, ?,m) denote the ranking scores of the sentence isand the term jt  in the whole document set,respectively.
Based on the assumptions that?Highly ranked terms appear in highly rankedsentences, while highly ranked sentencescontain highly ranked terms.
Moreover, asentence is ranked higher if it contains manyterms that appear in many other highly rankedsentences.
?we define)(),()1()(),()(11jnjSSmjjSTi srjiWtrjiWsr ??==???+?
?= ??
(1)and)(),()(1iniTSj srijWtr ?=?= .
(2)For calculation purpose, )( isr  and )( jtr  arenormalized by?=?niiiisrsrsr1'' )()()(  and?=?mjjjjtrtrtr1'' )()()( .Equations (1) and (2) can be rewritten usingthe matrix form, i.e.,?????????=????+??
?=||)(||)()(||)(||)()1(||)(||)()(SrWSrWTrSrWSrWTrWTrWSrTSTSSSSSSTST ??.
(3)We call )(Sr  and )(Tr  the ?global rankingfunctions?, because at this moment sentenceclustering is not yet involved and all thesentences/terms in the whole document set areranked together.Theorem: The solution to )(Sr  and )(Trgiven by Equation (3) is the primaryeigenvector of SSTSST WWW ??+??
)1( ??
andSTSSTS WWIW ?????
?1))1(( ??
, respectively.Proof: Combine Equations (1) and (2), we get||)(||)()1(||)(||)(||)(||)()1(||||)(||)(||||)(||)(SrWSrWSrWWSrWWSrWSrWSrWSrWWSrWSrWWSrSSSSTSSTTSSTSSSSTSTSSTTSTSST????+?????=????+???????=????
)(As the iterative process is a power method,it is guaranteed that )(Sr  converges to theprimary eigenvector of +??
TSST WW?SSW??
)1( ?
.
Similarly,  )(Tr  is guaranteed toconverge to the primary eigenvector ofSTSSTS WWIW ?????
?1))1(( ??
.
?3.2.2 Local Ranking (within Clusters)Assume now K theme clusters have beengenerated by certain clustering algorithm,denoted as },,,{ 21 KCCCC ?=  where kC  (k=1,2, ?, K) represents a cluster of highly relatedsentences )( kC CS k ?
which contain the terms)( kC CT k ?
.
The sentences and terms withinthe cluster kC  form a cluster bi-type graphwith the adjacency matrixkCW .
Let )( kk CC Srand )(kk CC Tr  denote the ranking scores of kCSandkCT  within kC .
They are calculated by anequation similar to Equation (3) by replacingthe document level adjacency matrix W  withthe cluster level adjacency matrixkCW .
Wecall )(kk CC Sr  and )( kk CC Tr  the ?within-cluster ranking functions?
with respect to thecluster kC .
They are the local rankingfunctions, in contrast to )(Sr  and )(Tr  thatrank all the sentences and terms in the wholedocument set D. We believe that it will benefitsentence overall ranking when knowing moredetails about the ranking results at the finergranularity of theme clusters, instead of at thecoarse granularity of the whole document set.1363.2.3 Conditional Ranking (across Clusters)To facilitate the discovery of rank distributionsof terms and sentences over all the themeclusters, we further define two ?conditionalranking functions?
)|( kCSr  and )|( kCTr .These rank distributions are necessary for theparameter estimation during the reinforcementprocess introduced later.
The conditionalranking score of the term jt  on the cluster kC ,i.e., )|( kCTr  is directly derived from kCT , i.e.,=)|( kj Ctr )( jC tr k  if kj Ct ?
, and 0)|( =kj Ctrotherwise.
It is further normalized as?
==mj kjkjkjCtrCtrCtr1)|()|()|( .
(4)Then the conditional ranking score of thesentence is  on the cluster kC  is deduced fromthe terms that are included in is , i.e.,?
?
?= ==?
?=nimj kjSTmj kjSTkiCtrjiWCtrjiWCsr1 11)|(),()|(),()|( .
(5)Equation (5) can be interpreted as that theconditional rank of is  on kC  is higher if manyterms in is  are ranked higher in kC .
Now wehave sentence and term conditional ranks overall the theme clusters and are ready tointroduce the reinforcement process.3.3 Reinforcement between Within-Cluster Ranking and ClusteringThe conditional ranks of the term jt  across theK theme clusters can be viewed as a rankdistribution.
Then the rank distribution of thesentence is  can be considered as a mixturemodel over K conditional rank distributions ofthe terms contained in the sentence is .
And thesentence is  can be represented as a K-dimensional vector in the new measure space,in which the vectors can be used to guide thesentence clustering update.
Next, we willexplain the mixture model of sentence and useEM algorithm (Bilmes, 1997) to get thecomponent coefficients of the model.
Then, wewill present the similarity measure betweensentence and cluster, which is used to adjustthe clusters that the sentences belong to and inturn modify within-cluster ranking for thesentences in the updated clusters.3.3.1 Sentence Mixture ModelFor each sentence  is , we assume that itfollows the distribution )|( isTr  to generate therelationship between the sentence is  and theterm set T. This distribution can be consideredas a mixture model over K componentdistributions, i.e.
the term conditional rankdistributions across K theme clusters.
We useki,?
to denote the probability that is  belongsto kC , then )|( isTr  can be modeled as:?=?=Kkkki CTrsTr1i, )|()|( ?
and ?==Kkk1i, 1?
.
(6)ki,?
can be explained as )|( ik sCp  andcalculated by the Bayesian equation??
)|()|( kiik CspsCp )( kCp , where )|( ki Cspis assumed to be )|( ki Csr  obtained from theconditional rank of is  on kC  as introducedbefore and )( kCp  is the prior probability.3.3.2 Parameter EstimationWe use EM algorithm to estimate thecomponent coefficients ki,?
along with)}({ kCp .
A hidden variable zC , },,2,1{ Kz ?
?is used to denote the cluster label that asentence term pair ),( ji ts  are from.
In addition,we make the independent assumption that theprobability of is  belonging to kC  and theprobability of jt  belonging to kC  areindependent, i.e., ?= )|()|,( kikji CspCtsp)|( kj Ctp , where )|,( kji Ctsp is the probabilityof is  and jt  both belonging to kC .
Similarly,)|( kj Ctp  is assumed to be )|( kj Ctr .Let ?
be the parameter matrix, which is aKn?
matrix }{ ,kiKn ?=?
?
;,,1( ni ?=),,1 Kk ?= .
The best ?
is estimated from therelationships observed in the document bi-typegraph, i.e., STW  and SSW .
The likelihood ofgenerating all the relationships under theparameter ?
can be calculated as:???
?= == =???=??
?=?ninjjiWjinimjjiWjiSSSTSSSTSSST ssptspWpWpWWL1 1),(1 1),(')|,()|,()|()|(),|(137where )|,( ?ji tsp  is the probability that isand jt  both belong to the same cluster, giventhe current parameter.
As )|,( ?ji ssp  does notcontain variables from ?
, we only need toconsider maximizing the first part of thelikelihood in order to get the best estimation of?
.
Let )|( STWL ?
be the first part oflikelihood.Taking into account the hidden variable zC ,the complete log-likelihood can be written as( )( )( )?????
?= == == =???=??
?=?=?nimjzjiZSTnimjzzjinimjjiWzjiZSTCptspjiWCpCtspCtspCWLjiSTWST1 11 11 1),()|(),(log),()|(),|,(log)|,,(log),|(log),( .In the E-step, given the initial parameter 0?
,which is set to Kki10, =?
for all i and k, theexpectation of log-likelihood under the currentdistribution of ZC  is:?????
?= = == = =??=??=?+?=??=?=?
?niKkmjjikzkzSTKknimjjikzjikSTZSTWCftsCCpCCpjiWtsCCptspjiWCWLEQSTZ1 1 101 1 10),|(0),,|())|(log(),(),,|()),(log(),(),|((log),( 0The conditional distribution in the aboveequation, i.e., ),,|( 0?= jikz tsCCp , can becalculated using the Bayesian rule as follows:)()|()|()|(),|,(),,|(000000kzkjkikzkzjijikzCCpCtpCspCCpCCtsptsCCp=??=?=??=.
(7)In the M-Step, we first get the estimation of)( kz CCp =  by maximizing the expectation),( 0?
?Q .
By introducing a Lagrangemultiplier ?
, we get the equation below.?=?=+??=??
?=0)]1)((),([)( 10KkkzkzCCpQCCp??
?= ==+?==nimjjikzkzST tsCCpCCpjiW1 10 0),,|()(1),( ?Thus, the estimation of )( kz CCp =  givenprevious 0?
is???
?= == =?===nimjSTnimjjikzSTkzjiWtsCCpjiWCCp1 11 10),(),,|(),()( .
(8)Then, the parameters ki,?
can be calculatedwith the Bayesian rule as?====KllzlikzkikiCCpCspCCpCsp1,)()|()()|(?
.
(9)By setting ?=?0 , the whole process canbe repeated.
The updating rules provided inEquations (7)-(9) are applied at each iteration.Finally ?
will converge to a local maximum.A similar estimation process has been adoptedin (Sun et al, 2009), which was used toestimate the component coefficients for author-conference networks.3.3.3 Similarity MeasureAfter we get the estimations of the componentcoefficients ki,?
for is  , is  will be representedas a K dimensional vector ,,,( 2,1, ?iiis ??=),Ki?
.
The center of each cluster can thus becalculated accordingly, which is the mean ofis  for all is  in the same cluster, i.e.,|| kCsiCCsCenter kik?
?= ,where || kC  is the size of kC .Then the similarity between each sentenceand each cluster can be calculated as the cosinesimilarity between them, i.e.,??
?====Kl CKl iKl CikilCenterlslCenterlsCssimkk12121))())()()(),( .
(10)Finally, each sentence is re-assigned to acluster that is the most similar to the sentence.Based on the updated clusters, within-clusterranking is updated accordingly, which triggersthe next round of clustering refinement.
It isexpected that the quality of clusters should beimproved during this iterative update processsince the similar sentences under newattributes will be grouped together, andmeanwhile the quality of ranking will beimproved along with the better clusters and138thus offers better attributes for furtherclustering.3.4 Ensemble RankingThe overall sentence ranking function f isdefined as the ensemble of all the sentenceconditional ranking scores on the K clusters.
?=?=Kkkiki Csrsf1)|()( ?
,  (11)where k?
is a coefficient evaluating theimportance of kC .
It can be formulated as thenormalized cosine similarity between a themecluster and the whole document set for genericsummarization, or between a theme cluster anda given query for query-based summarization.]1,0[?k?
and ?==Kkk11?
.Figure 2 below summarizes the wholeprocess that determines the overall sentenceensemble ranking scores.Input: The bi-type document graph >=< WETSG ,,?
,ranking functions, the cluster number K, 1=?
,001.0=Tre , 10=IterNum .Output: sentence final ensemble ranking vector )(Sf .1.
0?t ;2.
Get the initial partition for S, i.e.
tkC , Kk ?,2,1= ,calculate cluster centers tkCCenter accordingly.3.
For (t=1; t<IterNum && Tre>?
; t++)4.
Calculate the within-cluster ranking )(kk CC Tr,)(kCkCSr  and the conditional ranking )|( ki Csr ;5.
Get new attribute is  for each sentence is , andnew attribute tkCCenter  for each clustertkC ;6.
For each sentence is in S7.
For k=1 to K8.
Calculate similarity value ),( tki Cssim9.
End For10.
Assign is to 10+tkC , ),(maxarg0tkik Cssimk =11.
End For12.
||max 1 tkCtkCkCenterCenter ?= +?13.
1+?
tt14.
End For15.
For each sentence is  in S16.
For k=1 to K17.
?=?=Kkkiki Csrsf1)|()( ?18.
End For19.
End ForFigure 2.
The Overall Sentence Ranking Algorithm3.5 Summary GenerationIn multi-document summarization, the numberof documents to be summarized can be verylarge.
This makes information redundancyappears to be more serious in multi-documentsummarization than in single-documentsummarization.
Redundancy control isnecessary.
We apply a simple yet effectiveway to choose summary sentences.
Each time,we compare the current candidate sentence tothe sentences already included in the summary.Only the sentence that is not too similar to anysentence in the summary (i.e., the cosinesimilarity between them is lower than athreshold) is selected into the summary.
Theiteration is repeated until the length of thesentences in the summary reaches the lengthlimitation.
In this paper, the threshold is set to0.7 as always in our past work.4 Experiments and EvaluationsWe conduct the experiments on the DUC 2004generic multi-document summarization datasetand the DUC 2006 query-based multi-document summarization dataset.
According totask definitions, systems are required toproduce a concise summary for each documentset (without or with a given query description)and the length of summaries is limited to 665bytes in DUC 2004 and 250 words in DUC2006.A well-recognized automatic evaluationtoolkit ROUGE (Lin and Hovy, 2003) is usedin evaluation.
It measures summary quality bycounting overlapping units between system-generated summaries and human-writtenreference summaries.
We report two commonROUGE scores in this paper, namely ROUGE-1 and ROUGE-2, which base on Uni-grammatch and Bi-gram match, respectively.Documents and queries are pre-processed bysegmenting sentences and splitting words.
Stopwords are removed and the remaining wordsare stemmed using Porter stemmer.4.1 Evaluation of PerformanceIn order to evaluate the performance ofreinforced clustering and ranking approach, wecompare it with the other three rankingapproaches: (1) Global-Rank, which does notapply clustering and simply relies on the139sentence global ranking scores to selectsummary sentences; (2) Local-Rank, whichclusters sentences first and then rank sentenceswithin each cluster.
A summary is generated inthe same way as presented in (Qazvinian andRadev, 2008).
The clusters are ordered bydecreasing size; (3) Cluster-HITS, which alsoclusters sentences first, but then regardsclusters as hubs and sentences as authorities inthe HITS algorithm and uses the obtainedauthority scores to rank and select sentences.The classical clustering algorithm K-means isused where necessary.
For query-basedsummarization, the additional query-relevance(i.e.
the cosine similarity between sentencesand query) is involved to re-rank the candidatesentences chosen by the ranking approachesfor generic summarization.Note that K-means requires a predefinedcluster number K. To avoid exhaustive searchfor a proper cluster number for each documentset, we employ the spectra approachintroduced in (Li et al, 2007) to predict thenumber of the expected clusters.
Based on thesentence similarity matrix using thenormalized 1-norm, for its eigenvalues i?
(i=1,2, ?, n), the ratio )1(/ 21 ?= + ????
ii   isdefined.
If 05.01 >?
+ii ??
and i?
is still closeto 1, then set K=i+1.
Tables 1 and 2 belowcompare the performance of the fourapproaches on DUC 2004 and 2006 accordingto the calculated K.DUC 2004 ROUGE-1 ROUGE-2Reinforced 0.37082 0.08351Cluster-HITS 0.36463 0.07632Local-Rank 0.36294 0.07351Global-Rank 0.35729 0.06893Table 1.
Results on the DUC 2004 datasetDUC 2006 ROUGE-1 ROUGE-2Reinforced 0.39531 0.08957Cluster-HITS 0.38315 0.08632Local-Rank 0.38104 0.08841Global-Rank 0.37478 0.08531Table 2.
Results on the DUC 2006 datasetIt is not surprised to find that ?Global-Rank?shows the poorest performance, when itutilizes the sentence level information onlywhereas the other three approaches allintegrate the additional cluster levelinformation in various ways.
In addition, asresults illustrate, the performance of ?Cluster-HITS?
is better than the performance of?Local-Rank?.
This can be mainly credited tothe ability of ?Cluster-HITS?
to consider notonly the cluster-level information, but also thesentence-to-cluster relationships, which areignored in ?Local-Rank?.
It is happy to see thatthe proposed reinforcement approach, whichsimultaneously updates clustering and rankingof sentences, consistently outperforms theother three approaches.4.2 Analysis of Cluster QualityOur original intention to propose thereinforcement approach is to hope to generatemore accurate clusters and ranking results bymutually refining within-cluster ranking andclustering.
In order to check and monitor thevariation trend of the cluster quality during theiterations, we define the following measure?
?=?= ??
?=KkKklljiCsCskiCssssimCssimquanljkiki1,1 ,)),(min),(min( , (12)where ),(min kiCsCssimki?denotes the distancebetween the cluster center and the bordersentence in a cluster that is the farthest awayfrom the center.
The larger it is, the morecompact the cluster is.
),(min,jiCsCssssimljki ?
?, onthe other hand, denotes the distance betweenthe most distant pair of sentences, one fromeach cluster.
The smaller it is, the moreseparated the two clusters are.
The distance ismeasured by cosine similarity.
As a whole, thelarger quan means the better cluster quality.Figure 3 below plots the values of quan in eachiteration on the DUC 2004 and 2006 datasets.Note that the algorithm converges in less than6 rounds and 5 rounds on the DUC 2004 and2006 datasets, respectively.
The curves clearlyshow the increasment of quan and thus theimproved cluster quality.00.511.522.533.544.555.566.577.51 2 3 4 5 6IterNumQuanDUC2004 DUC2006Figure 3.
Cluster Quality on DUC 2004 and 2006140While quan directly evaluate the quality ofthe generated clusters, we are also quiteinterested in whether the improved clustersquality can further enhance the quality ofsentence ranking and thus consequently raisethe performance of summarization.
Therefore,we evaluate the ROUGEs in each iteration aswell.
Figure 4 below illustrates the changes ofROUGE-1 and ROUGE-2 result on the DUC2004 and 2006 datasets, respectively.
Now, wehave come to the positive conclusion.0.290.30.310.320.330.340.350.360.370.380.390.41 2 3 4 5 6IterNumROUGE-1DUC2004 DUC20060.0450.050.0550.060.0650.070.0750.080.0850.090.0951 2 3 4 5 6IterNumROUGE-2Figure 4.
ROUGEs on DUC 2004 and 20064.3 Impact of Cluster NumbersIn previous experiments, the cluster number ispredicted through the eigenvalues of 1-normnormalized sentence similarity matrix.
Thisnumber is just the estimated number.
Theactual number is hard to predict accurately.
Tofurther examine how the cluster numberinfluences summarization, we conduct thefollowing additional experiments by varyingthe cluster number.
Given a document set, welet S denote the sentence set in the documentset, and set K in the following way:|| SK ?= ?
,   (13)where )1,0(??
is a ratio controlling theexpected cluster number.
The larger ?
is, themore clusters will be produced.
?
ranges from0.1 to 0.9 in the experiments.
Due to pagelimitation, we only provide the ROUGE-1 andROUGE-2 results of the proposed approach,?Cluster-HITS?
and ?Local-Rank?
on the DUC2004 dataset in Figure 5.
The similar curvesare also observed on the 2006 dataset.0.3550.360.3650.370.3750.380.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9ROUGE-1Cluster-HITS Local Rank Reinforced?0.0720.0750.0780.0810.0840.0870.090.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9ROUGE-2?Figure 5.
ROUGEs vs.?
on DUC 2004It is shown that (1) the proposed approachoutperforms ?Cluster-HITS?
and ?Local-Rank?
in almost all the cases no matter howthe cluster number is set; (2) the performancesof ?Cluster-HITS?
and ?Local-Rank?
are moresensitive to the cluster number and a largenumber of clusters appears to deteriorate theperformances of both.
This is reasonable.Actually when ?
getting close to 1, ?Local-Rank?
approaches to ?Global-Rank?.
Theseresults demonstrate the robustness of theproposed approach.5 ConclusionIn this paper, we present a reinforcementapproach that tightly integrates ranking andclustering together by mutually andsimultaneously updating each other.Experimental results demonstrate theeffectiveness and the robustness of theproposed approach.
In the future, we willexplore how to integrate term semanticrelationships to further improve theperformance of summarization.AcknowledgementThe work described in this paper wassupported by an internal grant from the HongKong Polytechnic University (G-YG80).141ReferencesJ.
Bilmes.
1997.
A Gentle Tutorial on the emAlgorithm and Its Application to ParameterWstimation for Gaussian Mixture and HiddenMarkov Models.
Technical Report ICSI-TR-97-02, University of Berkeley.Brin, S., and Page, L. 1998.
The Anatomy of aLarge-scale Hypertextual Web Search Engine.
InProceedings of WWW1998..Harabagiu S. and Lacatusu F. 2005.
Topic Themesfor Multi-Document Summarization.
InProceedings of SIGIR2005.Hardy H., Shimizu N., Strzalkowski T., Ting L.,Wise G. B., and Zhang X.
2002.
Cross-Document Summarization by ConceptClassification.
In Proceedings of SIGIR2002.Jon M. Kleinberg.
1999.
Authoritative Sources in aHyperlinked Environment.
In Proceedings of the9th ACM-SIAM Symposium on DiscreteAlgorithms.Karypis, George, Vipin Kumar and MichaelSteinbach.
2000.
A Comparison of DocumentClustering Techniques.
KDD workshop on TextMining.Lin, C. Y. and Hovy, E. 2000.
The AutomatedAcquisition of Topic Signature for TextSummarization.
In Proceedings of COLING2000.Li W.Y., Ng W.K., Liu Y.  and Ong K.L.
2007.Enhancing the Effectiveness of Clustering withSpectra Analysis.
IEEE Transactions onKnowledge and Data Engineering (TKDE).19(7): 887-902.Li, F., Tang, Y., Huang, M., Zhu, X.
2009.Answering Opinion Questions with RandomWalks on Graphs.
In Proceedings of ACL2009.Otterbacher J., Erkan G. and Radev D. 2005.
UsingRandomWalks for Question-focused SentenceRetrieval.
In Proceedings of HLT/EMNLP 2005.Qazvinian  V. and Radev D. R. 2008.
Scientificpaper summarization using citation summarynetworks.
In Proceedings of COLING2008.Sun P., Lee J.H., Kim D.H., and Ahn C.M.
2007.Multi-Document Using Weighted SimilarityBetween Topic and Clustering-Based Non-negative Semantic Feature.
APWeb/WAIM2007.Sun Y., Han J., Zhao P., Yin Z., Cheng H., and WuT.
2009.
Rankclus: Integrating Clustering withRanking for Heterogenous Information NetworkAnalysis.
In Proceedings of EDBT 2009.Wang D.D., Li T., Zhu S.H., Ding Chris.
2008aMulti-Document Summarization via Sentence-Level Semantic Analysis and Symmetric MatrixFactorization.
In Proceedings of SIGIR2008.Wang D.D., Zhu S.H., Li T., Chi Y., and Gong Y.H.2008b.
Integrating Clustering and Multi-Document Summarization to Improve DocumentUnderstanding.
In Proceedings of CIKM 2008.Wan X. and Yang J.
2006.
Improved Affinity Graphbased Multi-Document Summarization.
InProceedings of HLT-NAACL2006.Zha H. 2002.
Generic Summarization and KeyPhrase Extraction using Mutual ReinforcementPrinciple and Sentence Clustering.
InProceedings of SIGIR2002.142
