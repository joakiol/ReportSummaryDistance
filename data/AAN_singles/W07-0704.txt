Proceedings of the Second Workshop on Statistical Machine Translation, pages 25?32,Prague, June 2007. c?2007 Association for Computational LinguisticsExploring Different Representational Units in English-to-Turkish StatisticalMachine TranslationKemal Oflazer?,?
?Language Technologies InstituteCarnegie Mellon UniversityPittsburgh, PA, 15213, USAoflazer@sabanciuniv.eduI?lknur Durgar El-Kahlout??
Faculty of Engineering and Natural SciencesSabanc?
UniversityIstanbul, Tuzla, 34956, Turkeyilknurdurgar@su.sabanciuniv.eduAbstractWe investigate different representationalgranularities for sub-lexical representationin statistical machine translation work fromEnglish to Turkish.
We find that (i) rep-resenting both Turkish and English at themorpheme-level but with some selectivemorpheme-grouping on the Turkish side ofthe training data, (ii) augmenting the train-ing data with ?sentences?
comprising onlythe content words of the original trainingdata to bias root word alignment, (iii) re-ranking the n-best morpheme-sequence out-puts of the decoder with a word-based lan-guage model, and (iv) using model iterationall provide a non-trivial improvement overa fully word-based baseline.
Despite ourvery limited training data, we improve from20.22 BLEU points for our simplest modelto 25.08 BLEU points for an improvementof 4.86 points or 24% relative.1 IntroductionStatistical machine translation (SMT) from English-to-Turkish poses a number of difficulties.
Typo-logically English and Turkish are rather distant lan-guages: while English has very limited morphologyand rather fixed SVO constituent order, Turkish is anagglutinative language with a very rich and produc-tive derivational and inflectional morphology, and avery flexible (but SOV dominant) constituent order.Another issue of practical significance is the lack oflarge scale parallel text resources, with no substan-tial improvement expected in the near future.In this paper, we investigate different represen-tational granularities for sub-lexical representationof parallel data for English-to-Turkish phrase-basedSMT and compare them with a word-based base-line.
We also employ two-levels of language mod-els: the decoder uses a morpheme based LM while itis generating an n-best list.
The n-best lists are thenrescored using a word-based LM.The paper is structured as follows: We first brieflydiscuss issues in SMT and Turkish, and review re-lated work.
We then outline how we exploit mor-phology, and present results from our baseline andmorphologically segmented models, followed bysome sample outputs.
We then describe discussmodel iteration.
Finally, we present a comprehen-sive discussion of our approach and results, andbriefly discuss word-repair ?
fixing morphologicalymalformed words ?
and offer a few ideas about theadaptation of BLEU to morphologically complexlanguages like Turkish.2 Turkish and SMTOur previous experience with SMT into Turkish(Durgar El-Kahlout and Oflazer, 2006) hinted thatexploiting sub-lexical structure would be a fruitfulavenue to pursue.
This was based on the observationthat a Turkish word would have to align with a com-plete phrase on the English side, and that sometimesthese phrases on the English side could be discontin-uous.
Figure 1 shows a pair of English and Turkishsentences that are aligned at the word (top) and mor-pheme (bottom) levels.
At the morpheme level, wehave split the Turkish words into their lexical mor-phemes while English words with overt morphemeshave been stemmed, and such morphemes have beenmarked with a tag.The productive morphology of Turkish impliespotentially a very large vocabulary size.
Thus,sparseness which is more acute when very modest25Figure 1: Word and morpheme alignments for a pair of English-Turkish sentencesparallel resources are available becomes an impor-tant issue.
However, Turkish employs about 30,000root words and about 150 distinct suffixes, so whenmorphemes are used as the units in the parallel texts,the sparseness problem can be alleviated to some ex-tent.Our approach in this paper is to represent Turk-ish words with their morphological segmentation.We use lexical morphemes instead of surface mor-phemes, as most surface distinctions are man-ifestations of word-internal phenomena such asvowel harmony, and morphotactics.
With lexi-cal morpheme representation, we can abstract awaysuch word-internal details and conflate statistics forseemingly different suffixes, as at this level of repre-sentation words that look very different on the sur-face, look very similar.1 For instance, although thewords evinde ?in his house?
and masas?nda ?on histable?
look quite different, the lexical morphemesexcept for the root are the same: ev+sH+ndA vs.masa+sH+ndA.We should however note that although employ-ing a morpheme based representations dramaticallyreduces the vocabulary size on the Turkish side, italso runs the risk of overloading distortion mecha-nisms to account for both word-internal morphemesequencing and sentence level word ordering.The segmentation of a word in general is notunique.
We first generate a representation that con-tains both the lexical segments and the morpho-logical features encoded for all possible segmenta-1This is in a sense very similar to the more general problemof lexical redundancy addressed by Talbot and Osborne (2006)but our approach does not require the more sophisticated solu-tion there.tions and interpretations of the word.
For the wordemeli for instance, our morphological analyzer gen-erates the following with lexical morphemes brack-eted with (..):(em)em+Verb+Pos(+yAlH)?DB+Adverb+Sincesince (someone) sucked (something)(emel)emel+Noun+A3sg(+sH)+P3sg+Nomhis/her ambition(emel)emel+Noun+A3sg+Pnon(+yH)+Accambition (as object of a transitive verb)These analyses are then disambiguated with a sta-tistical disambiguator (Yu?ret and Tu?re, 2006) whichoperates on the morphological features.2 Finally, themorphological features are removed from each parseleaving the lexical morphemes.Using morphology in SMT has been recently ad-dressed by researchers translation from or into mor-phologically rich(er) languages.
Niessen and Ney(2004) have used morphological decomposition toimprove alignment quality.
Yang and Kirchhoff(2006) use phrase-based backoff models to translatewords that are unknown to the decoder, by morpho-logically decomposing the unknown source word.They particularly apply their method to translatingfrom Finnish ?
another language with very similarstructural characteristics to Turkish.
Corston-Oliverand Gamon (2004) normalize inflectional morphol-ogy by stemming the word for German-Englishword alignment.
Lee (2004) uses a morphologicallyanalyzed and tagged parallel corpus for Arabic-English SMT.
Zolmann et al (2006) also exploitmorphology in Arabic-English SMT.
Popovic andNey (2004) investigate improving translation qual-2This disambiguator has about 94% accuracy.26ity from inflected languages by using stems, suffixesand part-of-speech tags.
Goldwater and McClosky(2005) use morphological analysis on Czech text toget improvements in Czech to English SMT.
Re-cently, Minkov et al (2007) have used morphologi-cal postprocessing on the output side using structuralinformation and information from the source side, toimprove SMT quality.3 Exploiting MorphologyOur parallel data consists mainly of documents ininternational relations and legal documents fromsources such as the Turkish Ministry of Foreign Af-fairs, EU, etc.
We process these as follows: (i) Wesegment the words in our Turkish corpus into lex-ical morphemes whereby differences in the surfacerepresentations of morphemes due to word-internalphenomena are abstracted out to improve statisticsduring alignment.3 (ii) We tag the English side us-ing TreeTagger (Schmid, 1994), which provides alemma and a part-of-speech for each word.
We thenremove any tags which do not imply an explicit mor-pheme or an exceptional form.
So for instance, ifthe word book gets tagged as +NN, we keep bookin the text, but remove +NN.
For books tagged as+NNS or booking tagged as +VVG, we keep bookand +NNS, and book and +VVG.
A word like went isreplaced by go +VVD.4 (iii) From these morpholog-ically segmented corpora, we also extract for eachsentence, the sequence of roots for open class con-tent words (nouns, adjectives, adverbs, and verbs).For Turkish, this corresponds to removing all mor-phemes and any roots for closed classes.
For En-glish, this corresponds to removing all words taggedas closed class words along with the tags such as+VVG above that signal a morpheme on an openclass content word.
We use this to augment the train-ing corpus and bias content word alignments, withthe hope that such roots may get a chance to alignwithout any additional ?noise?
from morphemes andother function words.From such processed data, we compile the datasets whose statistics are listed in Table 1.
One cannote that Turkish has many more distinct word forms(about twice as many as English), but has much less3So for example, the surface plural morphemes +ler and+lar get conflated to +lAr and their statistics are hence com-bined.4Ideally, it would have been very desirable to actually doderivational morphological analysis on the English side, so thatone could for example analyze accession into access plus amarker indicating nominalization.Turkish Sent.
Words (UNK) Uniq.
WordsTrain 45,709 557,530 52,897Train-Content 56,609 436,762 13,767Tune 200 3,258 1,442Test 649 10,334 (545) 4,355EnglishTrain 45,709 723,399 26,747Train-Content 56,609 403,162 19,791Test 649 13,484 (231) 3,220Morph- Uniq.
Morp./ Uniq.
Uniq.Turkish emes Morp.
Word Roots Suff.Train 1,005,045 15,081 1.80 14,976 105Tune 6,240 859 1.92 810 49Test 18,713 2,297 1.81 2,220 77Table 1: Statistics on Turkish and English trainingand test data, and Turkish morphological structurenumber of distinct content words than English.5 Forlanguage models in decoding and n-best list rescor-ing, we use, in addition to the training data, a mono-lingual Turkish text of about 100,000 sentences (ina segmented and disambiguated form).A typical sentence pair in our data looks likethe following, where we have highlighted the con-tent root words with bold font, coindexed them toshow their alignments and bracketed the ?words?that evaluation on test would consider.?
T: [kat1 +hl +ma] [ortakl?k2 +sh +nhn][uygula3 +hn +ma +sh] [,] [ortakl?k4][anlas?ma5 +sh] [c?erc?eve6 +sh +nda][izle7 +hn +yacak +dhr] [.]?
E: the implementation3 of the acces-sion1 partnership2 will be monitor7+vvn in the framework6 of theassociation4 agreement5 .Note that when the morphemes/tags (starting witha +) are concatenated, we get the ?word-based?version of the corpus, since surface words are di-rectly recoverable from the concatenated represen-tation.
We use this word-based representation alsofor word-based language models used for rescoring.We employ the phrase-based SMT framework(Koehn et al, 2003), and use the Moses toolkit(Koehn et al, 2007), and the SRILM language mod-elling toolkit (Stolcke, 2002), and evaluate our de-coded translations using the BLEU measure (Pap-ineni et al, 2002), using a single reference transla-tion.5The training set in the first row of 1 was limited to sen-tences on the Turkish side which had at most 90 tokens (rootsand bound morphemes) in total in order to comply with require-ments of the GIZA++ alignment tool.
However when only thecontent words are included, we have more sentences to includesince much less number of sentences violate the length restric-tion when morphemes/function word are removed.27Moses Dec. Parms.
BLEU BLEU-cDefault 16.29 16.13dl = -1, -weight-d = 0.1 20.16 19.77Table 2: BLEU results for baseline experiments.BLEU is for the model trained on the training setBLEU-C is for the model trained on training set augmented withthe content words.3.1 The Baseline SystemAs a baseline system, we trained a model usingdefault Moses parameters (e.g., maximum phraselength = 7), using the word-based training corpus.The English test set was decoded with both defaultdecoder parameters and with the distortion limit (-dlin Moses) set to unlimited (-1 in Moses) and distor-tion weight (-weight-d in Moses) set to a very lowvalue of 0.1 to allow for long distance distortions.6We also augmented the training set with the con-tent word data and trained a second baseline model.Minimum error rate training with the tune set did notprovide any tangible improvements.7 Table 2 showsthe BLEU results for baseline performance.
It canbe seen that adding the content word training dataactually hampers the baseline performance.3.2 Fully Morphologically Segmented ModelWe now trained a model using the fully morpho-logically segmented training corpus with and with-out content word parallel corpus augmentation.
Fordecoding, we used a 5-gram morpheme-based lan-guage model with the hope of capturing local mor-photactic ordering constraints, and perhaps somesentence level ordering of words.8 We then decodedand obtained 1000-best lists.
The 1000-best sen-tences were then converted to ?words?
(by concate-nating the morphemes) and then rescored with a 4-gram word-based language model with the hope ofenforcing more distant word sequencing constraints.For this, we followed the following procedure: We6We arrived at this combination by experimenting with thedecoder to avoid the almost monotonic translation we were get-ting with the default parameters.7We ran MERT on the baseline model and the morphologi-cally segmented models forcing -weight-d to range a very smallaround 0.1, but letting the other parameters range in their sug-gested ranges.
Even though the procedure came back claimingthat it achieved a better BLEU score on the tune set, runningthe new model on the test set did not show any improvement atall.
This may have been due to the fact that the initial choiceof -weight-d along with -dl set to 1 provides such a drasticimprovement that perturbations in the other parameters do nothave much impact.8Given that on the average we have almost two bound mor-phemes per ?word?
(for inflecting word classes), a morpheme5-gram would cover about 2 ?words?.tried various linear combinations of the word-basedlanguage model and the translation model scores onthe tune corpus, and used the combination that per-formed best to evaluate the test corpus.
We also ex-perimented with both the default decoding parame-ters, and the modified parameters used in the base-line model decoding above.The results in Table 3 indicate that the default de-coding parameters used by the Moses decoder pro-vide a very dismal results ?
much below the baselinescores.
We can speculate that as the constituent or-ders of Turkish and English are very different, (root)words may have to be scrambled to rather long dis-tances along with the translations of functions wordsand tags on the English side, to morphemes on theTurkish side.
Thus limiting maximum distortionand penalizing distortions with the default higherweight, result in these low BLEU results.
Allowingthe decoder to consider longer range distortions andpenalizing such distortions much less with the mod-ified decoding parameters, seem to make an enor-mous difference in this case, providing close to al-most 7 BLEU points improvement.9We can also see that, contrary to the case withthe baseline word-based experiments, using the ad-ditional content word corpus for training actuallyprovides a tangible improvement (about 6.2% rel-ative (w/o rescoring)), most likely due to slightlybetter alignments when content words are used.10Rescoring the 1000-best sentence output with a 4-gram word-based language model provides an addi-tional 0.79 BLEU points (about 4% relative) ?
from20.22 to 21.01 ?
for the model with the basic train-ing set, and an additional 0.71 BLEU points (about3% relative) ?
from 21.47 to 22.18?
for the modelwith the augmented training set.
The cumulative im-provement is 1.96 BLEU points or about 9.4% rela-tive.3.3 Selectively Segmented ModelA systematic analysis of the alignment files pro-duced by GIZA++ for a small subset of the train-ing sentences showed that certain morphemes on the9The ?morpheme?
BLEU scores are much higher (34.43on the test set) where we measure BLEU using decoded mor-phemes as tokens.
This is just indicative and but correlates withword-level BLEU which we report in Table 3, and can be usedto gauge relative improvements to the models.10We also constructed phrase tables only from the actualtraining set (w/o the content word section) after the alignmentphase.
The resulting models fared slightly worse though we donot yet understand why.28Moses Dec. Parms.
BLEU BLEU-cDefault 13.55 NAdl = -1, -weight-d = 0.1 20.22 21.47dl = -1, -weight-d = 0.1+ word-level LM rescoring 21.01 22.18Table 3: BLEU results for experiments with fullymorphologically segmented training setTurkish side were almost consistently never alignedwith anything on the English side: e.g., the com-pound noun marker morpheme in Turkish (+sh) doesnot have a corresponding unit on the English sidesince English noun-noun compounds do not carryany overt markers.
Such markers were never alignedto anything or were aligned almost randomly to to-kens on the English side.
Since we perform deriva-tional morphological analysis on the Turkish sidebut not on the English side, we noted that most ver-bal nominalizations on the English side were justaligned to the verb roots on the Turkish side andthe additional markers on the Turkish side indicat-ing the nominalization and agreement markers etc.,were mostly unaligned.For just these cases, we selectively attached suchmorphemes (and in the case of verbs, the interven-ing morphemes) to the root, but otherwise kept othermorphemes, especially any case morphemes, still bythemselves, as they almost often align with preposi-tions on the English side quite accurately.11This time, we trained a model on just the content-word augmented training corpus, with the better per-forming parameters for the decoder and again did1000-best rescoring.12 The results for this experi-ment are shown in Table 4.
The resulting BLEUrepresents 2.43 points (11% relative) improvementover the best fully segmented model (and 4.39 points21.7% compared to the very initial morphologicallysegmented model).
This is a very encouraging resultthat indicates we should perhaps consider a muchmore detailed analysis of morpheme alignments touncover additional morphemes with similar status.Table 5 provides additional details on the BLEU11It should be noted that what to selectively attach to the rootshould be considered on a per-language basis; if Turkish wereto be aligned with a language with similar morphological mark-ers, this perhaps would not have been needed.
Again one per-haps can use methods similar to those suggested by Talbot andOsborne (2006).12Decoders for the fully-segmented model and selectivelysegmented model use different 5-gram language models, sincethe language model corpus should have the same selectivelysegmented units as those in the training set.
However, the word-level language models used in rescoring are the same.Moses Dec. Parms.
BLEU-cdl = -1, -weight-d = 0.1+ word-level LM rescoring 22.18(Full Segmentation (from Table 3))dl = -1, -weight-d = 0.1 23.47dl = -1, -weight-d = 0.1+ word-level LM rescoring 24.61Table 4: BLEU results for experiments with selec-tively segmented and content-word augmented train-ing setRange Sent.
BLEU-c1 - 10 172 44.361 - 15 276 34.635 - 15 217 33.001 - 20 369 28.841 - 30 517 27.881 - 40 589 24.90All 649 24.61Table 5: BLEU Scores for different ranges of(source) sentence length for the result in Table 4scores for this model, for different ranges of (En-glish source) sentence length.4 Sample Rules and TranslationsWe have extracted some additional statistics fromthe translations produced from English test set.
Ofthe 10,563 words in the decoded test set, a total of957 words (9.0 %) were not seen in the training cor-pus.
However, interestingly, of these 957 words, 432(45%) were actually morphologically well-formed(some as complex as having 4-5 morphemes!)
Thisindicates that the phrase-based translation modelis able to synthesize novel complex words.13 Infact, some phrase table entries seem to capturemorphologically marked subcategorization patterns.An example is the phrase translation pairafter examine +vvg ?+acc incele+dhk +abl sonrawhich very much resembles a typical structuraltransfer rule one would find in a symbolic machinetranslation systemPP(after examine +vvg NPeng) ?PP(NPturk+acc incele+dhk +abl sonra)in that the accusative marker is tacked to thetranslation of the English NP.Figure 2 shows how segments are translated toTurkish for a sample sentence.
Figure 3 shows thetranslations of three sentences from the test data13Though whether such words are actually correct in theircontext is not necessarily clear.29c?ocuk [[ child ]]hak+lar+sh +nhn [[ +nns +pos right ]]koru+hn+ma+sh [[ protection ]]+nhn [[ of ]]tes?vik et+hl+ma+sh [[ promote ]]+loc [[ +nns in ]] ab [[ eu ]]ve ulus+lararasi standart +lar[[ and international standard +nns ]]+dat uygun [[ line with ]] +dhr .
[[ .
]]Figure 2: Phrasal translations selected for a samplesentenceInp.
: 1 .
everyone?s right to life shall be protected by law .Trans.
: 1 .
herkesin yas?ama hakk?
kanunla korunur.Lit.
: everyone?s living right is protected with law .Ref.
: 1 .
herkesin yas?am hakk?
yasan?n korumas?
alt?ndad?r .Lit.
: everyone?s life right is under the protection of the law.Inp.
: promote protection of children?s rights in line with eu andinternational standards .Trans.
: c?ocuk haklar?n?n korunmas?n?n ab ve uluslararas?standartlara uygun s?ekilde gelis?tirilmesi.Lit.
: develop protection of children?s rights in accordance witheu and international standards .Ref.
: ab ve uluslararas?
standartlar dog?rultusunda c?ocukhaklar?n?n korunmas?n?n tes?vik edilmesi.Lit.
: in line with eu and international standards pro-mote/motivate protection of children?s rights .Inp.
: as a key feature of such a strategy, an accession partner-ship will be drawn up on the basis of previous european councilconclusions.Trans.
: bu stratejinin kilit unsuru bir kat?l?m ortakl?g??
bel-gesi haz?rlanacak kadar?n temelinde , bir o?nceki avrupa konseyisonuc?lar?d?r .Lit.
: as a key feature of this strategy, accession partnership doc-ument will be prepared ???
based are previous european councilresolutions .Ref.
: bu stratejinin kilit unsuru olarak , daha o?nceki ab zirvesonuc?lar?na dayan?larak bir kat?l?m ortakl?g??
olus?turulacakt?r.Lit.
: as a key feature of this strategy an accession partnershipbased on earlier eu summit resolutions will be formed .Figure 3: Some sample translationsalong with the literal paraphrases of the translationand the reference versions.
The first two are quiteaccurate and acceptable translations while the thirdclearly has missing and incorrect parts.5 Model IterationWe have also experimented with an iterative ap-proach to use multiple models to see if further im-provements are possible.
This is akin to post-editing(though definitely not akin to the much more so-phisticated approach in described in Simard et al(2007)).
We proceeded as follows: We used theselective segmentation based model above and de-coded our English training data ETrain and Englishtest data ETest to obtain T1Train and T1Test re-Step BLEUFrom Table 4 24.61Iter.
1 24.77Iter.
2 25.08Table 6: BLEU results for two model iterationsspectively.
We then trained the next model usingT1Train and TTrain, to build a model that hopefullywill improve upon the output of the previous model,T1Test, to bring it closer to TTest.
This model whenapplied to T1Train and T1Test produce T2Train andT2Test respectively.We have not included the content word corpusin these experiments, as (i) our few very prelimi-nary experiments indicated that using a morpheme-based models in subsequent iterations would per-form worse than word-based models, and (ii) that forword-based models adding the content word trainingdata was not helpful as our baseline experiments in-dicated.
The models were tested by decoding theoutput of the previous model for original test data.For word-based decoding in the additional iterationswe used a 3-gram word-based language model butreranked the 1000-best outputs using a 4-gram lan-guage model.
Table 6 provides the BLEU results forthese experiments corresponding to two additionalmodel iterations.The BLEU result for the second iteration, 25.08,represents a cumulative 4.86 points (24% relative)improvement over the initial fully morphologicallysegmented model using only the basic training setand no rescoring.6 DiscussionTranslation into Turkish seems to involve processesthat are somewhat more complex than standard sta-tistical translation models: sometimes words on theTurkish side are synthesized from the translationsof two or more (SMT) phrases, and errors in anytranslated morpheme or its morphotactic positionrender the synthesized word incorrect, even thoughthe rest of the word can be quite fine.
If we justextract the root words (not just for content wordsbut all words) in the decoded test set and the ref-erence set, and compute root word BLEU, we ob-tain 30.62, [64.6/35.7/23.4/16.3].
The unigram pre-cision score shows that we are getting almost 65% ofthe root words correct.
However, the unigram pre-cision score with full words is about 52% for ourbest model.
Thus we are missing about 13% of thewords although we seem to be getting their roots30correct.
With a tool that we have developed, BLEU+(Tantug?
et al, 2007), we have investigated such mis-matches and have found that most of these are ac-tually morphologically bogus, in that, although theyhave the root word right, the morphemes are eithernot the applicable ones or are in a morphotacticallywrong position.
These can easily be identified withthe morphological generator that we have.
In manycases, such morphologically bogus words are onemorpheme edit distance away from the correct formin the reference file.
Another avenue that could bepursued is the use of skip language models (sup-ported by the SRILM toolkit) so that the contentword order could directly be used by the decoder.14At this point it is very hard to compare how our re-sults fare in the grand scheme of things, since thereis not much prior results for English to Turkish SMT.Koehn (2005) reports on translation from English toFinnish, another language that is morphologically ascomplex as Turkish, with the added complexity ofcompounding and stricter agreement between mod-ifiers and head nouns.
A standard phrase-based sys-tem trained with 941,890 pairs of sentences (about20 times the data that we have!)
gives a BLEU scoreof 13.00.
However, in this study, nothing specific forFinnish was employed, and one can certainly em-ploy techniques similar to presented here to improveupon this.6.1 Word RepairThe fact that there are quite many erroneous wordswhich are actually easy to fix suggests some ideas toimprove unigram precision.
One can utilize a mor-pheme level ?spelling corrector?
that operates onsegmented representations, and corrects such formsto possible morphologically correct words in or-der to form a lattice which can again be rescoredto select the contextually correct one.15 With theBLEU+ tool, we have done one experiment thatshows that if we could recover all morphologicallybogus words that are 1 and 2 morpheme edit dis-tance from the correct form, the word BLEU scorecould rise to 29.86, [60.0/34.9/23.3/16.]
and 30.48[63.3/35.6/23.4/16.4] respectively.
Obviously, theseare upper-bound oracle scores, as subsequent candi-date generation and lattice rescoring could make er-14This was suggested by one of the reviewers.15It would however perhaps be much better if the decodercould be augmented with a filter that could be invoked at muchearlier stages of sentence generation to check if certain gener-ated segments violate hard-constraints (such as morphotacticconstraints) regardless of what the statistics say.rors, but nevertheless they are very close to the rootword BLEU scores above.Another path to pursue in repairing words is toidentify morphologically correct words which areeither OOVs in the language model or for whichthe language model has low confidence.
One canperhaps identify these using posterior probabilities(e.g., using techniques in Zens and Ney (2006)) andgenerate additional morphologically valid wordsthat are ?close?
and construct a lattice that can berescored.6.2 Some Thoughts on BLEUBLEU is particularly harsh for Turkish and the mor-pheme based-approach, because of the all-or-nonenature of token comparison, as discussed above.There are also cases where words with differentmorphemes have very close morphosemantics, con-vey the relevant meaning and are almost inter-changeable:?
gel+hyor (geliyor - he is coming) vs. gel+makta(gelmekte - he is (in a state of) coming) are essentiallythe same.
On a scale of 0 to 1, one could rate these atabout 0.95 in similarity.?
gel+yacak (gelecek - he will come) vs. gel+yacak+dhr(gelecektir - he will come) in a sentence final position.Such pairs could be rated perhaps at 0.90 in similarity.?
gel+dh (geldi - he came (past tense)) vs. gel+mhs (gelmis?- he came (hearsay past tense)).
These essentially markpast tense but differ in how the speaker relates to the eventand could be rated at perhaps 0.70 similarity.Note that using stems and their synonyms as usedin METEOR (Banerjee and Lavie, 2005) could alsobe considered for word similarity.Again using the BLEU+ tool and a slightly dif-ferent formulation of token similarity in BLEU com-putation, we find that using morphological similar-ity our best score above, 25.08 BLEU increases to25.14 BLEU, while using only root word synonymyand very close hypernymy from Wordnet, gives us25.45 BLEU.
The combination of rules and Wordnetmatch gives 25.46 BLEU.
Note that these increasesare much less than what can (potentially) be gainedfrom solving the word-repair problem above.7 ConclusionsWe have presented results from our investigationinto using different granularity of sub-lexical rep-resentations for English to Turkish SMT.
We havefound that employing a language-pair specific rep-resentation somewhere in between using full word-forms and fully morphologically segmented repre-sentations and using content words as additional31data provide a significant boost in BLEU scores,in addition to contributions of word-level rescoringof 1000-best outputs and model iteration, to give aBLEU score of 25.08 points with very modest par-allel text resources.
Detailed analysis of the errorspoint at a few directions such as word-repair, to im-prove word accuracy.
This also suggests perhapshooking into the decoder, a mechanism for imposinghard constraints (such as morphotactic constraints)during decoding to avoid generating morphologi-cally bogus words.
Another direction is to introduceexploitation of limited structures such as bracketednoun phrases before considering full-fledged syntac-tic structure.AcknowledgementsThis work was supported by TU?BI?TAK ?
The Turk-ish National Science and Technology Foundationunder project grant 105E020.
We thank the anony-mous reviewer for some very useful comments andsuggestions.ReferencesSatanjeev Banerjee and Alon Lavie.
2005.
METEOR: An au-tomatic metric for MT evaluation with improved correlationwith human judgments.
In Proceedings of the ACL Work-shop on Intrinsic and Extrinsic Evaluation Measures for Ma-chine Translation and/or Summarization, pages 65?72, AnnArbor, Michigan, June.Simon Corston-Oliver and Michael Gamon.
2004.
Normaliz-ing German and English inflectional morphology to improvestatistical word alignment.
In Proceedings of AMTA, pages48?57.I?lknur Durgar El-Kahlout and Kemal Oflazer.
2006.
Initial ex-plorations in English to Turkish statistical machine transla-tion.
In Proceedings on the Workshop on Statistical MachineTranslation, pages 7?14, New York City, June.Sharon Goldwater and David McClosky.
2005.
Improving sta-tistical MT through morphological analysis.
In Proceedingsof Human Language Technology Conference and Confer-ence on Empirical Methods in Natural Language Process-ing, pages 676?683, Vancouver, British Columbia, Canada,October.Philipp Koehn, Franz J. Och, and Daniel Marcu.
2003.Statistical phrase-based translation.
In Proceedings ofHLT/NAACL.Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan,Wade Shen, Christine Moran, Richard Zens, Chris Dyer, On-drej Bojar, Alexandra Constantin, and Evan Herbst.
2007.Moses: Open source toolkit for statistical machine trans-lation.
In Proceedings of the 45th Annual Meeting of theAssociation for Computational Linguistics (ACL?07) ?
Com-panion Volume, June.Philip Koehn.
2005.
Europarl: A parallel corpus for statisticalmachine translation.
In MT Summit X, Phuket, Thailand.Young-Suk Lee.
2004.
Morphological analysis for statisticalmachine translation.
In Proceedings of HLT-NAACL 2004 -Companion Volume, pages 57?60.Einat Minkov, Kristina Toutanova, and Hisami Suzuki.
2007.Generating complex morphology for machine translation.
InProceedings of the 45th Annual Meeting of the Associationfor Computational Linguistics (ACL?07), Prague, Czech Re-public, June.Sonja Niessen and Hermann Ney.
2004.
Statistical machinetranslation with scarce resources using morpho-syntatic in-formation.
Computational Linguistics, 30(2):181?204.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-JingZhu.
2002.
Bleu: a method for automatic evaluation of ma-chine translation.
In Proceedings of the 40th Annual Meetingof the Association for Computational Linguistics, Universityof Pennsylvania.Maja Popovic and Hermann Ney.
2004.
Towards the use ofword stems and suffixes for statistical machine translation.In Proceedings of the 4th International Conference on Lan-guage Resources and Evaluation (LREC), pages 1585?1588,May.Helmut Schmid.
1994.
Probabilistic part-of-speech tagging us-ing decision trees.
In Proceedings of International Confer-ence on New Methods in Language Processing.Michel Simard, Cyril Goutte, and Pierre Isabelle.
2007.
Statis-tical phrase-based post-editing.
In Proceedings of NAACL,April.Andreas Stolcke.
2002.
SRILM ?
an extensible language mod-eling toolkit.
In Proceedings of the Intl.
Conf.
on SpokenLanguage Processing.David Talbot and Miles Osborne.
2006.
Modelling lexical re-dundancy for machine translation.
In Proceedings of the 21stInternational Conference on Computational Linguistics and44th Annual Meeting of the Association for ComputationalLinguistics, pages 969?976, Sydney, Australia, July.Cu?neyd Tantug?, Kemal Oflazer, and I?lknur Durgar El-Kahlout.2007.
BLEU+: a tool for fine-grained BLEU computation.in preparation.Mei Yang and Katrin Kirchhoff.
2006.
Phrase-based backoffmodels for machine translation of highly inflected languages.In Proceedings of EACL, pages 41?48.Deniz Yu?ret and Ferhan Tu?re.
2006.
Learning morphologicaldisambiguation rules for Turkish.
In Proceedings of the Hu-man Language Technology Conference of the NAACL, MainConference, pages 328?334, New York City, USA, June.Richard Zens and Hermann Ney.
2006.
N-gram posterior prob-abilities for statistical machine translation.
In Proceedingson the Workshop on Statistical Machine Translation, pages72?77, New York City, June.
Association for ComputationalLinguistics.Andreas Zollmann, Ashish Venugopal, and Stephan Vogel.2006.
Bridging the inflection morphology gap for Arabicstatistical machine translation.
In Proceedings of the HumanLanguage Technology Conference of the NAACL, Compan-ion Volume: Short Papers, pages 201?204, New York City,USA, June.32
