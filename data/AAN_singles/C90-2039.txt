Strategic Lazy Incremental Copy Graph UnificationKiyoshi KOGUREtATR Interpreting Telephony Research LaboratoriesSanpeidani Inuidani, Seika-cho, Soraku-gun, Kyoto 619-02, Japankeg ure% atom.ntt.jp@relay.cs.netAbstractThe strategic lazy incremental copy graph unificationmethod is a combination of two methods for unifyinghmture structures.
One, called the lazy incremental copygraph unification method, achieves tructure sharingwith constant order data access time which reduces thecequired memory.
The other, called ti~e strategicincremental copy graph unification method, uses an earlyfailure finding strategy which first tries to unify:;ubstructures tending to fail in unification; this methodis; based on stochastic data on tim likelihood of failure and,'educes unnecessary computation.
The combined method.makes each feature structure unification efficient andalso reduces garbage collection and page swappingoccurrences, thus increasing the total efficiency ofnatural language processing systems mainly based onI.yped feature structure unification such as naturallanguage analysis and generation sysl~ems.1.
Introdu(tionVarious kinds of grammatical formalisms withoutt,ranstormation were proposed from the late 1970sI;hrough the 1980s l(\]azder Lal 85, l(aplan and Bresnan 82, Kay1~5, Pollm'd and Sag 871.
These furnmlisms were developedrelatively independentIy but actually had commonproperties; th'~t is, they used data structures calledftmctional structures or feature structures and they werebased on unilieathm operation on these data structures.These formalisms were applied in the field of naturallanguage processing and, based on these formalisms,~:~ystems such as machine translation systems weredeveloped \[l<ol;u, e et a l 8gJ.In such uni f icat ion-based formal isms,  feature~trueture (FS) unification is the most fundamental and..~ignifieant operation.
The efficiency of systems based on..~uch formalisms, such as natural language analysis andgeneration systems very much depends on their FS~lnifieatlon efficiencies.
Tiffs dependency is especiallycruc ia l  for lex icon-dr iven  approaches  such astlPSO\[Pollard and Sag 861 and JPSG\[Gunji 871 because richlexieal information and phrase structure information isdescribed in terms of FSs.
For example, a spokenPresent.
affiliation: Infi)rmation Science Research 1,aboratory,NTT Basic Research i.aboratories.lh'esenl, address: 9 11, Midori cho 3-theme, Musashino-shi,Tokyo 180, Japan.Japanese analysis ystem based on llPSG\[Kogure 891 uses90% - 98% of the elapsed time in FS unification.Several FS unificatioa methods were proposed inIKarttunen 86, l'ereira 85, Wroblewski 871.
These methods usesrooted directed graphs (DGs) to represent FSs.
Thesemethods take two DGs as their inputs and give aunification result DG.
Previous research identified DGcopying as a significant overhead.
Wroblewski claimsthat copying is wrong when an algorithm copies too much(over copying) or copies too soon (early copying).
Ileproposed an incremental copy graph unification methodto avoid over copying and early copying.itowever, the problem with his method is that aunitication result graph consists only of newly createdstructures.
This is unnecessary because there are ofteninput snbgraphs that can be used as part of the resultgraph without any modification, or as sharable partsbetween one of the input graphs and the result graph.Copying sharable parts is called redundant copying.
Abetter method would nfinimize the copying of sharablevarts.
The redundantly copied parts are relatively largewhen input graphs have few common feature paths.
Innatural language processing, such cases are ubiquitous.I"or example, in unifying an FS representing constraintson phrase structures and an FS representing a daughterphrase structure, such eases occur very h'equent, ly.
InKasper's disjunctive feature description unification\[Kasper 861, such cases occur very h'equently in unifyingdefinite and disjunct's definite parts.
Memory is wastedby such redundant copying and this causes frequentgarbage collection and page swapping which decrease thetotal system efficiency.
I)eveloping a method whichavoids memory wastage is very important.Pereira's tructure sharing FS unification method canavoid this problem.
The method achieves structuresharing by importing the Bayer and Moore approach forterm structurestl~oyer and Moore 721.
The method uses adata structure consisting of a skeleton part to representoriginal informat ion and an env i ronment  part torepresent updated information.
3'he skeleton part isshared by one of the input FSs and the result FS.Therefore, Pereira's method needs relatively few newstructures when two input FSs are difference in size andwhich input is larger are known before unification.However, Pereira's method can create skeleton-enviromnent structures that are deeply embedded, forexample, in reeursively construct ing large phrasestructure fl'om their parts.
This causes O(log d) graphnode access time overhead in assembling the whole DG223from the skeleton and environments where d is thenumber of nodes in the DG.
Avoiding this problem in hismethod requires a special operation of merging askeleton-environment structure into a skeleton structure,but this prevents structure sharing.This paper proposes an FS unification method thatallows structure sharing with constant m'der node accesstime.
This method achieves structure shar ing byintroducing lazy copying to Wroblewski's incrementalcopy graph unification method.
The method is called thelazy i2!cremental copy IFaph unification reel, hod (theLING unifieation method for short).In a natural anguage proeessing system that usesdeelarative constra int  rules in terms of FSs, FSunification provides constraint-checking and structure-building mechanisms.
The advantages of such a systeminclude:(1)rule writers are not required to describe controlinfimnation such as eonstraiut application order in arule, and(12) rule descriptions can be used iu different processingdirections, i.e., analysis and general,ion.However, these advantages in describing rules aredisadvantages in applying them because of tt~e lack ofcontrol information.
For example, when constructing aphrase structure from its parts (e.g., a sentence fi'om asubject NP and VP), unueeessary computation can bereduced if the semantic representation is assembled afterchecking constraints such as grammatical greements,which can fail.
This is impossible in straightforwardunification-based formalisms.In contrast, in a procedure-based system which usesIF-TItEN style rules (i.e., consisting of explicit test andstructure-building operations), it is possible to constructthe semantic representation (TIIEN par'g) after checkingthe agreement (IF part).
Such a system has theadvantage of processing efficiency but the disadvantageof lacking multi-directionality.In this paper, some of the efficiency of the procedure-based system is introduced into an FS unification-basedsystem.
That is, an FS unification method is proposedthat introduces a strategy called the e_arly failure ?indingstrategy (the EFF strategy) to make FS unif icationefficient, in this method, FS unification orders are notspecified explicitly by rule wril.ers, but are controlled bylearned information on tendencies of FS constraintapplication failures.
This method is called the strategicij!~crementaI copy graph unification method (the SINGunification method).These two methods can be combined into a singlemethod called the strategic lazy ijAcremeatal copy g~raphunification method (the SLING unification method).Section 2 explains typed feature structures (TFSs) andunification on them.
Section 3 explains aTFS unificationmethod based on Wroblewski's method and then explainsthe problem with his method.
The section also introducesthe key idea of the EFF strategy wlfich comes fromobservations of his method.
Section 3 and 4 introduce theLING method and the SING method, respectively.2.
Typed Feature StructuresOrdinary FSs used in unification-based grammarformalisms uch as PAT\].
{\[Shieher 851 arc classified intotwo classes, namely, atomic leSs and complex FSs.
Anatomic FS is represented by an atomic symbol and acomplex FS is represented by a set of feature-value pairs.Complex FSs are used to partially describe objects byspecifying values for certain features or attributes ofdescribed objects.
Complex FSs can have complex FSs astheir feature values and can share certain values amongfeatures.
For ordinary FSs, unification is defined byus ing  par t ia l  o rder ing  based on subsumpt ionre lat ionships.
These propert ies enable  f lexibledescriptions.An extension allows complex FSs to have type symbolswhich define a lattice structure on them, for example, asin \[Pollard and Sag 8"11.
The type symbol attice contains thegreatest type symbol Top, which subsumes every typesymbol, and the least type symbol Bottom, which issubsumed by every I.ype symbol.
An example of a typesymbol attice is shown in Fig.
1.An extended complex FS is represented by a typesymbol and a set of feature-value pairs.
Once complexIeSs are extended as above, an atomic FS can be seen as anextended complex FS whose type symbol has only Top asits greater type symbol and only Bottom as its lesser typesymbol and which has an empty set of feature value pairs.Extended complex FSs are called typed feature structures(TFSs).
TFSs are denoted by feature-value pair matricesor rooted irected graphs as shown in Fig.
2.Among such structures, unification c'm be defined IAP,-Kaci 861 by using the following order;ATFS tl is less than or equal to a TFS t2 if and only if:?
the type symbol of tl is less than or equal to the typesyn'bol of/2; and?
each of the features of t2 exists in t1 and.
has as itsvalue a TFS which is not less than its counterpart intl ; andeach of the coreference r lationships in t2 is also heldin t l .TopSign Syn Head List POSLexical PhraseSlgn/77Sign NonEmpty Empty V N P ADVLi .
Lis~ ust I I I INonEmpty Emply I I i ISign Sign I I /  /List List 5 /  /5.
.
.
.
U_BottomFigure 1: Exainple of a type symbol lattice224- -2 - -T IpeSymb?10eaturel TypeSymboll \] \]\]I feature2 TypeSymbol2I feature3 ?Tag T ypeSymbol3\] \]feature4 TypeSymbol4L \[.feature5 TypeSymbol5eature3 7Tag(a) feature-value matrix notation"?"
i~ the prefix for a tag and TFSs with the same tag aretoken-identical.TypeSym bol/~feo~.,o/ ITypeSymboll ~ \[.
.TypeSymbol2 4?"
'~?~'~/.~ypeSymbol3featury  "X~ature5TypeSymbol4 r "~TypeSymbol5(b) directed graph notationFigure 2: TFS notationsPhrase\[sub(at ?X2 SignListdtrs CHconst i 'oo Sign syn I head SynI ubcat\]U?Xl .
\]NonEmptySignLIst |\['first ?
?3 \]1Lrest ?X2 J jPhrase-dtrs CHconsthdtr LexicalSign-syn Syn-head Headpos Porm Gasubcat NonEmptySignListSignyn Synead HeadL~,os N\]Irest EmptySignkist ,11Phrase"syn Synhead ?X1 HeadFpos PLform GaLsubcat ?X2 Empl.ySignListdtrs CHconstccltr ?X3 Signsyn iyn head Head_ \[pos Nhdtr\]LexicalSignl-syn Syn l I F head :x~ 7/ Lsubcat NonEinptySignList l l \[ P"" ~?~ ll l lLrest ?X2 J J j JFigure 3: Example of TFS unificationThen, the unification of tl anti t2 is defined as theirgreatest lower bound or the meet.
A unification exampleis shown in Fig.
3.
In tile directed graph notation, TFSunification corresponds tograph mergi ng.
TFSs are veryconvenient for describing l inguistic information inunlfication-based formalisms.3.
Wroblewski's Incremental Copy Graph UnifitationMethod and Its ProblemsIn TFS unification based on Wrobtewski's method, aDG is represented by tile NODE and ARC structurescorresponding to a TFS and a feature-va lue pairrespectively, as shown in Fig.
4.
The NODE structure hasthe slots TYPESYMBOL to represent a type symbol, ARCSto represent a set of feature-value pairs, GENERATION tospecify the unification process in which the structure hasbeen created, FORWARD, and COPY.
When a NODE'sGENERATION value is equal to the global value specifyingthe current unit\]cation process, the structure has beencreated in the current process or that the structure iscur re l~ l .The characterist ics which allow nondestruct iveincremental copy are the NODE's two different slots,FORWARD and COPY, for represent ing forwardingrelationships.
A FORWARD slot value represents aneternal relationship while a COPY slot value represents atemporary relationship.
When a NODE node1 has a NODEnode2 as its FORWARD value, the other contents of tilenode1 are ignored and tim contents of node2 are used.t{owever, when a NODE has another NODE as its COPYvalue, the contents of the COPY value are used only whenthe COPY value is cub:rent.
After the process finishes, allCOPY slot values are ignored and thus original structuresare not destroyed.The unification procedure based on this method takesas its input two nodes which are roots of the DGs to beunified.
The procedure incrementally copies nodes andares on the subgraphs of each input 1)G until a node withan empty ARCS value is found.The procedure first dereferences both root nodes of theinput DGs (i.e., it follows up FORWARD and COPY slotvalues).
If the dereferenee r sult nodes arc identical, theprocedure finishes and returns one of the dereferenceresult nodes.Next, the procedure calculates the meet of their typesymbol.
I f  the meet  is Bot tom,  which meansinconsistency, the procedure finishes and returns Bottom.Otherwise, the procedure obtains the output node withthe meet as its TYPESYMBOL.
The output node has beencreated only when neither input node is current; orotherwise the output node is an existing current node.Next, the procedure treats arcs.
The procedureassumes the existence of two procedures, namely,SharedArcs and ComplementArcs.
The SharedArcsprocedure takes two lists of arcs as its arguments andgives two lists of arcs each of which contains arcs whoselabels exists in both lists with the same arc label order.The ComplementArcs procedure takes two lists of arcs as225NODETYPESYMBOL: <symbol>\[ ARCS: <a list of ARC structures >FORWARD: "<a NODE structure orN IL>/ COPY: < a NODE structure or N i l ,  >GENERATION: <an integer>ARCLABEL: <symbol>VALUE: <:a NODE structure>Figure 4: Data Structures for Wroblewski's methodInput graph GI Input graph 62....... '77  ........ ?
i: Sobg,'aphs not required to be copiedL .
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.Output graph G3Figure 5: Incremental copy graph unificationIn this figure, type symbols are omitted.its arguments and gives one list of arcs whose labels areunique to one input list.The unification procedure first treats arc pairsobtained by SharedArcs.
The procedure applies itself,'ecursively to each such arc pair values and adds to theoutput node every arc with the same label as its label andthe uni f icat ion result  of their  values unless thetmification result is Bottom.Next,  the procedure t reats  arcs obta ined  byComplementArcs.
Each arc value is copied and an arcwith the same label and the copied value is added to theoutput node.
For example, consider the case when featurea is first treated at the root nodes of G1 and G2 in Fig.
5.The unification procedure is applied recursively tofeature a values of the input nodes.
The node specified bythe feature path <a> fi'om input graph G1 (G l /<a>)has an arc with the label c and the corresponding node ofinput graph G2 does not.
The whole subgraph rooted by6 l /<a  c> is then copied.
This is because such subgraphscan be modified later.
For example, the node Y(G3/<o cg>)  will be modified to be the unification result of G 1/<ac g> (or G1/<b d>) and G2/<b d> when the featurepath <b d> will be treated.Incremental  Copy Graph Uni f icat ionPROCEDURE Unify(node1, node2)node1 = Dereference(nodel).node2 = Dereferencelnode2).IF Eq?
(nodel, node2) THENReturn(node1).ELSEmeet = Meet(nodel.typesymbol, node2.typesymbol)IF Equal?
(meet, Bottom) THENReturn(Bottom).ELSEoutnode = GetOutNode(nodel, node2, meet).
(sharedst, shareds2)= SharedArcs(nodel.arcs, node2.arcs).complements1= ComplementArcs(node|.arcs, node2.arcs).complements2= ComplementArcs(node2.arcs, nodel.arcs).FOR ALL (sharedt, shared2) IN (sharedsl, shareds2)DOarcnode = Unify(sharedl.value, shared2.value).IF Equal?
(arcnode, Bottom) \]HENReturn(Bottom).ELSEAddArc(outnode, sharedl.label, arcnode).ENDIFIF Eq?
(outnode, node1) THENcoi'nplements = complement2.ELSE IF Eq?
(outnode, node2) THENcomplements = complementLELSEcomplements= Append(complements1, complements2\].ENDIFFORALL complement IN complementsDOnewnode = CopyNode(complement.value).AddArc(outnode, complement.label, newnode).Return(outnode).ENDIFENDIEENDPROCEDUREFigure 6: Incremental copy graph unification procedureThe problem with Wroblewski's method is that tilewhole result DG is created by using only newly createdstructures.
In the example in Fig.
5, the subgraphs of theresult DG surrounded by the dashed rectangle can beshared with subgraphs of input structures G1 and G2,Section 4 proposes a method t.hat avoids this problem,Wroblewski's method first treats arcs with labels thatexist in both input nodes and then treats arcs with uniquelabels.
This order is related to the unification failuretendency.
Unification fails in treating arcs with commonlabels more often than in treating arcs with uniquelabels.
Finding a failure can stop further computation aspreviously described, and thus f inding failures firstreduces unnecessary computation.
This order strategycan be generalized tothe EFF and applied to the orderingof arcs with common labels.
In Section 5, a method whichuses this generalized strategy is proposed.4.
The Lazy Incremental Copy Graph Unification MethodIn Wroblewski's method, copying unique label arcvalues whole in order to treat cases like \]Pig.
5 disablesstructure sharing, ttowever, this whole copying is notnecessary if a lazy evaluation method is used.
With sucha method, it is possible to delay copying a node unti leither its own contents need to change (e.g., node G3/Ka  c226!7>) or until it is found to have an arc (sequence) toa nodet, hat needs to be copied (e.g., node X G3/<a c> in Fig.
5due to a change of node Y G3/<a c g>).
To achieve this,I, he LING un i f i cat ion  method,  which uses copydependency information, was developed.The LING unif ication procedure uses a revisedCopyNode procedure which does not copy structuresimmediately.
The revised procedure uses a newlyintroduced slot COPY-DEPENDENCY.
The slot has pairsconsisting of nodes and arcs as its value.
The revisedCopyNode procedure takes as its inputs the node to becopied node I and the arc arc I with node I as its value andnode2 as its immediate ancestor node (i.e., the arc'sinitial node), and does the following (set Fig.
7):(1) if node l  ', the dereference r sult of node/,  is current,then CopyNode returns node l" to indicate that theancestor node node2 must be coiffed immediately;(2)otherwise, CopyArcs is applied to node1"  and if itreturns ,~;everal rc copies, CopyNode creates a newcopy node.
It then adds the arc copies and arcs ofnode/ '  that are not copied to the new node, andreturns the new node;(3) otherwise, CopyNode adds the pair consisting of theancestor node node2 and the are arcl into the COPY-DEPENDENCY slot of node 1" and returns Nil_.,',:opyArcs applies CopyNode to each arc value withnode l '  as the new ancestor node and returns the set ofnew arcs for non-Nil_ CopyNode results.When a new copy of a node is needed later, the LINGunification procedure will actually copy structures usingthe  COPY-DEPENDENCY slot value of the node (inGetOutNode procedure in lJ'ig.
6).
It substitutes arcs withnewly copied nodes for existing arcs.
That is, antecedentnodes in the COPY-DEPENDENCY values are also copied.In the above explanation, both COPY-DEPENDENCYand COPY slots are used for the sake of simplicity.\]lowever, this method can be achieved with only theCOPY slot because a node does not have non-NIL COPY-I)EPENDENCY and COPY values imultaneously.The data in the COPY-DEPENDENCY slot areI;emporary and they are discarded uring an extensiveprocess uch as analyzing a sentence, ttowever, this doesnot result in any incompleteness or in any partialanalysis structure being test.
Moreover, data can beaccessed in a constant order time relative to the numberof DG nodes and need not be reconstructed because thismethod does not use a data structure consisl, ing of,';keleton and environments a does Pereira's method.The efficiency of the LING unification method ependson the proportion of newly created structures in theunification result structures.
Two worst eases can beconsidered:(t) If there are no arcs whose labels are unique to an inputnode witlh respect to each other, the procedure in LINGunification method behaves in the same way as theprocedure in the Wroblewski's method.
(2) In the worst eases, in which there are unique label arcsbut all result structures are newly created, the methodCopyNodePROCEDURE CopyNode(node, arc, ancestor)node = Dereference(node).IF Current?
(node) THENReturn(node).ELSE IF NotEmpty?
(newarcs = CopyArcs(node))THENnewnode = Create(node.typesymbol).node.copy = newnode.FOR ALL arc IN node.arcs DOIF NotNIL?
(newarc = FindArc(arc.label, newarcs))THENAddArc(newnode, newarc.label, newarc.value}.ELSEAddArc(newnode, arc.label, arc.value).ENDIFReturo(newnode).ELSEnode.copy-dependency= node.copy-dependency U {Cons(ancestor, arc)}.Return(Nil_).ENDIFENDPROCEDURECopyArcsPROCEDURE AlcsCopied(node)newarcs = O-FOR ALL arc IN node.arcs DOnewnode = CopyNode(arc.value, arc, node).IF NotNIL?
(newnode) THENnewarc = CreateArc(arc.label, newnode).newarcs = {newarc} U newarcs.ENDIFReturn(newarcs).ENDPROCEDUREFigure 7: The revised CopyNode procedurehas the disadvantage of treating copy dependencyinformation.However, these two cases are very rare.
Usually, thenumber of features in two input structures is relativelysmall and the sizes of the two input structures are oftenvery different.
For example, in Kasper's disjunctivefeature description unification, a definite part \["S islarger than a disjunet definite part t"S.5.
The Strategic Incremental Copy Graph UnificationMethodIn a system where FS unification is applied, there arefeatures whose values fail relatively often in unificationwith other values and there are features whose values donot fail so often.
For example, in Japanese sentenceanalysis, unification of features for conjugation forms,case markers, and semantic selectional restrictions tendsto fail but un i f i cat ion  of features  for semant icrepresentations does not fail.
In such cases, application ofthe EFF strategy, that is, treating features tending to fallin unification first, reduces unnecessary computationwhen the unification finally fails.
For example, whenunification of features for case markers does fail, treatingthese features first avoids treating features for senmnticrepresentations.
The SING unification method uses thisfailure tendency infornmtion.These unification fai lure tendencies depend onsystems uch as analysis systems or generation systems.227Unl ike the analysis case, unif ication of features forsemantic representations tends to fail.
in this method,theretbre, the failure tendency information is acquired bya learning process.
That is, the SING unification methodapplied in an analysis system uses the failure tendencyinformation acquired by a learning analysis process.in the learn ing  process, when FS uni f icat ion isapplied, feature treatment orders are randomized for thesake of random extraction.
As in TFS unif ication,failure tendency information is recorded in terms of atriplet consisting of the greatest lower bound type symbolof the input  TFSs '  type symbols ,  a feature  andsuccess/failure flag.
This is because the type symbol of a'rFS represents sal ient information on the whole TFS.By us ing learned fa i lure tendency in fo rmat ion ,feature value unification is applied in an order that firsttreats features with the greatest tendency to fail.
This isachieved by the sorting procedure of common label arcpairs attached to the meet type symbol.
The arc pairsobtained by the SharedArcs procedure are sorted beforetreating arcs.The efficiency of the SING unification method dependson the following factors:(1) The overall FS unification failure rate of the process:in extreme cases, if Go unification failure occurs, themethod has no advantages except the overhead offeature unification order sorting.
However, such casesdo not occur in practice.
(2) Number of features FSs have: if each FS has only asmall number of features, the efficiency gain from theSING unification method is small.
(3) Unevenness of FS unification fai lure tendency: inext reme cases, i f  every  feature  has the sameunif ication fai lure tendency,  this method has noadvantage.
However, such cases do not occur or arevery rare, and for example, in many cases of naturallanguage analysis, FS unification failures occur int reat ing only l imited kinds of features re lated togrammatical  agreement such as number and/or personagreement and semantic selectional constraints.
Insuch cases, the SING unif icat ion method obta insefl\]ciency gains.The above factors can be examined by inspect ingfailure tendency information, from which the efficiencygain from the SING method can be predicted.
Moreover,it is possible for each type symbol to select whether toapply feature unification order sorting or not.6.
ConclusionThe strategic lazy incremental copy graph (SLING)unification method combines two incremental copy graphunif ication methods: the lazy incremental copy graph(LING) unification method and the strategic incrementalcopy graph (SING) uni f icat ion method.
The L INGunification method achieves structure shar ing withoutthe O(log d) data access overhead of Pereira's method.Structure sharing avoids memory wastage'.
Furthermore,structure sharing increases the portion of token identicalsubstructures of FSs which makes it eff icient to keepunif ication results of substructures of FSs and reusethem.
This reduces repeated calculation of substructures.The SING unification method introduces the conceptof feature uni f icat ion strategy.  '
the method t reatsfeatures tending to fail in unification first.
Thus, theefficiency gain fi'om this method is high when the overallFS unification failure rate of the application process ishigh.The combined method Inakes each FS uni f icat ionefficient and also reduces garbage collection and pageswapping occurrences by avoiding memory wastage, thusincreasing the total efficiency of li'S unif icat ion-basednatural  language processing systems such aa analysisand generation systems based on I l I 'SG.AcknowledgementI would like to thank Akira Kurematsu, tIitoshi Iida,and my other  co l leagues hoth at A'I'I~ in terpret ingTe lephony  Research  Laborator ies  and NTT BasicResearch l ,aborator ies for their  encouragement  andthought-provoklng discussions.Reference\[A~td~aci 861 t\[.
Ait--Kaei.
An algebraic .
'romantics approach to theeffective resolution of tyite equations.
In Journal of TheoreticalComputer Science 45, 1986.\[Boyerand Moore721 R.S.
\[loyerandd.
S  Moore.
The sharing ofstructures in t}',eoretn-provillg programs, lit B. Meltzer and D.Miehie, editors, Machine ir~teliigence 7, 19'12.\[Gazder etal 851 (3.
(.
;azder, G. K. l'ullum, E. Klein and 1.
A. Sag.G~neraIizedPhrase ,'~traela,'e (/ramnzar.
BuM\[ lllackwell, 1985.\[Gunji 871 T. Ounji.
Jttpanese Phrr*se St,',cture Grammar.
1).
l~.eidel,1987.\[Kaplan and Bresnan 821 R. Kaplan and ,I. l;resnan.
LexicalFunctional Grammar: a formal system f,~r grammaticalrepresentation.
In d. Bresnan, edilor, The ,'~fetlg,:ff Representation fGramntalieoll~elrdions, .\'liT Pres.% 1982.\[Karttunen 86} L. Karttunen.
D-PATIt - A DevelopmentEnvironment for Ur6fication-Based Grammar.~.
CS1,1-86-91, CSLI,t986,\[Kasper 871 R. '1'.
Kasper.
A unification method for disjunctivefeature descriptions.
In the Proceedi~lgs ofthe 25th Annual Meetingof the Assoeiatioa for Com putatianal l.iulj,istics, 1987.\[Kay 85\[ M. Kay.
I~at'sing in funel, imm\[ grammar.
,in D. Dowry, L.Kartttmen and A. Zwieky, editors, Natura( I,anguage Parsing,Cambridge University Press, 1985.\[Kogure L al 88J l(.
Kogure et al A method ofanalyzlng Japanesespeech act types.
In the Proceedings of the 2~td InternationalCorlferenee oa Theoretical attd Metl~odological Issues in MachineTraasl~lion of Natural t,anguages, 1988.\[Kogure891 K. Kogute.
Parsing Japanese spoken sentences basedon IIPSG.
In the Proceedings of the lateraationcd Workshop onParsing Technologies, 1989.\[Pereira8,SI F.C.N.
Pereira.
Structure sharlngrepresentaLion forunificatiort-based formalisms, in the Proceedings of the 23rd Anttua\[Meeang of the Association for Computalianal Linguistics, 1985.IPollard and Sag 871 (3.
Pollard and I.
Sag.
Art Information.BasedSyntax and Semantics.
CSI,I Lecture Notes No.
13, CSI,I, 198'/.\[Shieber 8131 S. Shieber.
An Introduction to Unification-BasedApproaches to Grammar.
CSL1 Lecture.
Notes No.
4, CSLI, lg86.\[Wroblewski 871 1).
Wroblewski.
Nondestructive graph unification.In the Proceedings of the 6th National Conference on Arlificialhttelligenee, 1987.228
