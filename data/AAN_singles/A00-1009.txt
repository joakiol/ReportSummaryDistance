A Framework for MT and Multilingual NLG Systems Based onUniform Lexico-Structural ProcessingBenoit LavoieCoGenTex, Inc.840 Hanshaw RoadIthaca, NYUSA, 14850benoit@cogentex.comRichard KittredgeCoGenTex, Inc.840 Hanshaw RoadIthaca, NYUSA, 14850richard @ cogentex.comTanya KorelskyCoGenTex, Inc.840 Hanshaw RoadIthaca, NYUSA, 14850tanya @ cogentex.comOwen Rambow *ATT Labs-Research, B233180 Park Ave, PO Box 971Florham Park, NJUSA, 07932rambow @research.att.comAbstractIn this paper we describe an implementedframework for developing monolingual ormultilingual natural language generation(NLG) applications and machine translation(MT) applications.
The frameworkdemonstrates a uniform approach togeneration and transfer based on declarativelexico-structural transformations ofdependency structures of syntactic orconceptual levels ("uniform lexico-structuralprocessing").
We describe how thisframework has been used in practical NLGand MT applications, and report he lessonslearned.1 IntroductionIn this paper we present a linguisticallymotivated framework for uniform lexico-structural processing.
It has been used fortransformations of conceptual and syntacticstructures during generation i monolingual ndmultilingual natural language generation (NLG)and for transfer in machine translation (MT).Our work extends directions taken in systemssuch as Ariane (Vauquois and Boitet, 1985),FoG (Kittredge and Polgu6re, 1991), JOYCE(Rainbow and Korelsky, 1992), and LFS(Iordanskaja et al, 1992).
Although it adoptsthe general principles found in the above-mentioned systems, the approach presented inthis paper is more practical, and we believe,would eventually integrate better with emergingstatistics-based approaches toMT.
* The work performed on the framework by this co-author was done while at CoGenTex, Inc.The framework consists of a portable Javaenvironment for building NLG or MTapplications by defining modules using a coretree transduction engine and single declarativeASCII specification language for conceptual orsyntactic dependency tree structures 1 and theirtransformations.
Developers can define newmodules, add or remove modules, or modifytheir connections.
Because the processing of thetransformation engine is restricted totransduction of trees, it is computationallyefficient.Having declarative rules facilitates their reusewhen migrating from one programmingenvironment toanother; if the rules are based onfunctions pecific to a programming language,the implementation f these functions might nolonger be available in a different environment.In addition, having all lexical information andall rules represented eclaratively makes itrelatively easy to integrate into the frameworktechniques for generating some of the rulesautomatically, for example using corpus-basedmethods.
The declarative form oftransformations makes it easier to process them,compare them, and cluster them to achieveproper classification and ordering.1 In this paper, we use the term syntactic dependency(tree) structure as defined in the Meaning-TextTheory (MTT; Mel'cuk, 1988).
However, weextrapolate from this theory when we use the termconceptual dependency (tree) structure, which has noequivalent in MTT (and is unrelated to Shank's CDstructures proposed inthe 1970s).60Thus, the framework represents a generalizedprocessing environment that can be reused indifferent ypes of natural language processing(NLP) applications.
So far the framework hasbeen used successfully to build a wide variety ofNLG and MT applications in several limiteddomains (meteorology, battlefield messages,object modeling) and for different languages(English, French, Arabic, and Korean).In the next sections, we present the design of thecore tree transduction module (Section 2),describe the representations that it uses (Section3) and the linguistic resources (Section 4).
Wethen discuss the processing performed by thetree transduction module (Section 5) and itsinstantiation for different applications (Section6).
Finally, we discuss lessons learned fromdeveloping and using the framework (Section 7)and describe the history of the frameworkcomparing it to other systems (Section 8).2 The Framework's Tree Transduction ModuleThe core processing engine of the framework isa generic tree transduction module for lexico-structural processing, shown in Figure 1.
Themodule has dependency stuctures as input andoutput, expressed in the same tree formalism,although not necessarily at the same level (seeSection 3).
This design facilitates the pipeliningof modules for stratificational transformation.
Ifact, in an application, there are usually severalinstantiations of this module.The transduction module consists of threeprocessing steps: lexico-structural pre-processing, main lexico-structural processing,and lexico-structural post-processing.
Each ofthese steps is driven by a separate grammar, andall three steps draw on a common feature database and lexicon.
The grammars, the lexiconand the feature data base are referred to as thelinguistic resources (even if they sometimesapply to a conceptual representation).
Alllinguistic resources are represented in adeclarative manner.
An instantiation of the treetransduction module consists of a specificationof the linguistic resources.Input Dependency Structure~ L exlco-Structural Preproce~ingIntermediate Dependency StructttreL_~Lexico-Structm'al ProcessingIntermediate + Dependency Structure~ Lexico-StructuralPostprocessingOutput / /~Dependency SUucturciFigure 1: Design of the Tree Transduction Module3 The Framework's RepresentationsThe representations used by all instantiations ofthe tree transduction module in the frameworkare dependency tree structures.
The maincharacteristics of all the dependency treestructures are:?
A dependency tree is unordered (in contrastwith phrase structure trees, there is noordering between the branches of the tree).?
All the nodes in the tree correspond tolexemes (i.e., lexical heads) or conceptsdepending on the level of representation.
Icontrast with a phrase structurerepresentation, there are no phrase-structurenodes labeled with nonterminal symbols.Labelled arcs indicate the dependencyrelationships between the lexemes.The first of these characteristics makes adependency tree structure a very usefulrepresentation for MT and multilingual NLG,since it gives linguists a representation thatallows them to abstract over numerous cross-linguistic divergences due to language specificordering (Polgu~re, 1991).We have implemented 4 different types ofdependency tree structures that can be used forNLG, MT or both:?
Deep-syntactic structures (DSyntSs);?
Surface syntactic structures (SSyntSs);61?
Conceptual structures (ConcSs);?
Parsed syntactic structures (PSyntSs).The DSyntSs and SSyntSs correspond closely tothe equivalent structures of the Meaning-TextTheory (MTT; Mel'cuk, 1988): both structuresare unordered syntactic representations, but aDSyntS only includes full meaning-bearinglexemes while a SSyntS also contains functionwords such as determiners, auxiliaries, andstrongly governed prepositions.
In theimplemented applications, the DSyntSs are thepivotal representations involved in mosttransformations, as this is also often the case inpractice in linguistic-based MT (Hutchins andSomers, 1997).
Figure 2 illustrates a DSyntSfrom a meteorological application, MeteoCogent(Kittredge and Lavoie, 1998), represented usingthe standard graphical notation and also theRealPro ASCII notation used internally in theframework (Lavoie and Rambow, 1997).
AsFigure 2 illustrates, there is a straightforwardmapping between the graphical notation and theASCII notation supported in the framework.This also applies for all the transformation rulesin the framework which illustrates thedeclarative nature of our approach,I 1LOW-5 TO'tLOw(A'I~R -5ATTR TO(il HIGH(A'\]I~R 20)))Low -S to high 20Figure 2: DSyntS (Graphical nd ASCII Notation)The ConcSs correspond to the standard frame-like structures used in knowledge representation,with labeled arcs corresponding to slots.
Wehave used them only for a very limitedmeteorological domain (in MeteoCogent), andwe imagine that they will typically be defined ina domain-specific manner.Figure 3 illustrates the mapping between aninterlingua defined as a ConcS and acorresponding English DSyntS.
This example,also taken from MeteoCogent, illustrates that theconceptual interlingua in NLG can be closer to adatabase representation f domain data than toits linguistic representations.As mentioned in (Polgu~re, 1991), the high levelof abstraction of the ConcSs makes them asuitable interlingua for multilingual NLG sincethey bridge the semantic discrepancies betweenlanguages, and they can be produced easily fromthe domain data.
However, most off-the-shelfparsers available for MT produce only syntacticstructures, thus the DSyntS level is often moresuitable for transfer.Cones#TEMPERATURELow -5 to Mlgh 20DS~tSLOW-5 TOItlGHFigure 3: ConcS Interlingua nd English DSyntSFinally, the PSyntSs correspond to the parseroutputs represented using RealPro's dependencystructure formalism.
The PSyntSs may not bevalid directly for realization or transfer sincethey may contain unsupported features ordependency relations.
However, the PSyntSsare represented in a way to allow the frameworkto convert hem into valid DSyntS via lexico-structural processing.
This conversion is donevia conversion grammars customized for eachparser.
There is a practical need to convert onesyntactic formalism to another and so far wehave implemented converters for three off-the-shelf parsers (Palmer et al, 1998).4 The Framework's Linguistic ResourcesAs mentioned previously, the framework iscomposed of instantiations of the tree62transduction module shown in Figure 1.
Eachmodule has the following resources:?
Feature Data-Base: This consists of thefeature system defining available featuresand their possible values in the module.?
Lexicon: This consists of the availablelexemes or concepts, depending on whetherthe module works at syntactic or conceptuallevel.
Each lexeme and concept is definedwith its features, and may contain specificlexico-structural ules: transfer rules for MT,mapping rules to the next level ofrepresentation for surface realization ofDSyntS or lexicalization of ConcS.?
Main Grammar: This consists of the lexico-structural mapping rules that apply at thislevel and which are not lexeme- or concept-specific (e.g.
DSynt-rules for the DSynt-module, Transfer-rules for the Transfermodule, etc.)?
Preprocessing rammar: This consists ofthe lexico-structural mapping rules fortransforming the input structures in order tomake them compliant with the maingrammar, if this is necessary.
Such rules areused to integrate new modules togetherwhen discrepancies in the formalism need tobe fixed.
This grammar can also be usedfor adding default features (e.g.
setting thedefault number of nouns to singular) or forapplying default transformations (e.g.replacing non meaning-bearing lexemeswith features).Postprocessing rammar: This consists oflexico-structural mapping rules fortransforming the output structures beforethey can be processed by the next module.As for the preprocessing rules, these rulescan be used to fix some discrepanciesbetween modules.Our representation f the lexicon at the lexicallevel (as opposed to conceptual) is similar to theone found in RealPro.
Figure 4 shows aspecification for the lexeme SELL.
This lexemeis defined as a verb of regular morphology withtwo lexical-structural mappings, the first oneintroducing the preposition TO for its 3 r?
actant,and the preposition FOR for its 4 th actant: (aseller) X1 sells (merchandise) X2 to (a buyer)X3 for (a price) X4.
What is important is thateach mapping specifies a transformationbetween structures at different levels ofrepresentation but that are represented in oneand the same representation formalism (DSyntSand SSyntS in this case).
As we will seebelow, grammar ules are also expressed in asimilar way.LEX~ME: SELLCATEGORY:  verbFEATURES:  \[ \]GOV-PATTERN: \ [DSYNT-RULE:SELL ( I I I  $X3 )<- ->SELL( complet ive2  TO( p repos i t iona l  $X3 ) )DSYNT-RULE :SELL ( IV $X4 )<- ->SELL( complet ive3  FOR( p repos i t iona l  $X4 )\]MORPHOLOGY:  \[( \[ tense :past  \] so ld  \[ inv( \[ mood:past -par t  \] so ld  \[ inv( \[ \] sel l  \[ reg\]Figure 4: Specification ofLexeme SELLAt the conceptual level, the conceptual lexiconassociates lexical-structural mapping withconcepts in a similar way.
Figure 5 illustratesthe mapping at the deep-syntactic levelassociated with the concept #TEMPERATURE.Except for the slight differences in the labelling,this type of specification is similar to the oneused on the lexical level.
The first mapping rulecorresponds to one of the lexico-structuraltransformations u ed to convert he interlingualConcS of Figure 3 to the corresponding DSyntS.ZONCEPT:  #TEMPERATURE5EXICAL:  \[L~-RULE:#TEMPERATURE ( #min imum SX#maxim~ $Y<- ->LOW ( ATTR $XATTR TO( II H IGH( ATTR SY ) ) )LEX-RULE:#TEMPERATURE ( #min im~ SX<- ->LOW ( ATTR $X )LEX-RULE:#TEMPE~TURE ( #max imum $X<- ->H IGH ( ATTR SX )\]Figure 5: Specification ofConcept #TEMPERATURE63Note that since each lexicon entry can havemore than one lexical-structural mapping rule,the list of these rules represents a small grammarspecific to this lexeme or concept.Realization grammar ules of the main grammarinclude generic mapping rules (which are notlexeme-specific) such as the DSyntS-ruleillustrated in Figure 6, for inserting a determiner.DSYNT-RULE:$X  \[ c lass :noun ar t i c le :de f  \]$X  ( determinat ive  THE )Figure 6: Deep-Syntactic Rule for Determiner InsertionThe lexicon formalism has also been extended toimplement lexeme-specific lexico-structuraltransfer rules.
Figure 7 shows the lexico-structural transfer of the English verb lexemeMOVE to French implemented for a militaryand weather domain (Nasr et al, 1998):Cloud will move into the western regions.Des nuages envahiront les rdgions ouest.They moved the assets forward.-.9 lls ont amen~ les ressources vers l 'avant.The 79 dcg moves forward.---~ La 79 dcg avance  vers l'avant.A disturbance will move north of Lake Superior.--~ Une perturbation se diplacera au nord du lacsupdrieur.LEXEME : MO~'ECATEGORY : verbFEATORES : \[ \]TRANSFER: \[TRANSFER-RULE:MOVEI ATTR INTO \ [ c lass :prepos i t ion \ ]( II SXl ) ).-.>E2~VAH IR \[class:verb\]( II SX1 )TRANSFER-RULE :MOVE( II $X2 )AMENER \[class:verb\]\[ II $X2 )TRANSFER-RULE:MOVE( ATTR SX \[Iexe~e:FORWARD class:adverb\] )AVANCER( ATTR SX )TRANSFER-RULE :MOVE<-->DEPLACER \[class:verb refl:?\]\]Figure 7: Lexico-Structural Transfer of English LexerneMOVE to FrenchMore general exico-structural rules for transfercan also be implemented using our grammar ruleformalism.
Figure 8 gives an English-Frenchtransfer ule applied to a weather domain for thetransfer of a verb modified by the adverbALMOST:It almost rained.--o II a fail l i  pleuvoir.TRANSFER-RULE:SX  \[ c lass :verb  \]( ATTR ALMOST )<- ->FA ILL IR  \[ c lass :verb  \]( I I  SX  \[ mood: in f  \] )Figure 8: English to French Lexico-StructuralTransfer Rule with Verb Modifier ALMOSTMore details on how the structural divergencesdescribed in (Dorr, 1994) can be accounted forusing our formalism can be found in (Nasr etal., 1998).5 The Rule ProcessingBefore being processed, the rules are firstcompiled and indexed for optimisation.
Eachmodule applies the following processing.The rules are assumed to be ordered from mostspecific to least specific.
The application of therules to the structures i  top-down in a recursiveway from the f'n-st rule to the last.
For the maingrammar, before applying a grammar ule to agiven node, dictionary lookup is carried out inorder to first apply the lexeme- or concept-specific rules associated with this node.
Theseare also assumed to be ordered from the mostspecific to the least specific.If a lexico-structural transformation involvesswitching a governor node with one of itsdependents in the tree, the process is reappliedwith the new node governor.
When no morerules can be applied, the same process is appliedto each dependent of the current governor.When all nodes have been processed, theprocessing is completed,6 Using the Framework to build ApplicationsFigure 9 shows how different instantiations ofthe tree transduction module can be combined to64build NLP applications.
The diagram does notrepresent a particular system, but rather showsthe kind of transformations that have beenimplemented using the framework, and how theyinteract.
Each arrow represents one type ofprocessing implemented by an instantiation ofthe tree transduction module.
Each trianglerepresents a different level of representation.Scope of theFramework~Conversion blParsedPSyntS LIParsingSentencePI "ngC'?nezoa~ 1~ e Transfer ~_~ , Co.verMonD$ ntS LI~SyntS ~ealizalion/ \SSyntS LI SSyntS 1.2 ~ yntS ealizationA DSyntS L2 Parsed DSym51 PSyntS L2Realiza~o~SSym~ Realizatio parsinInput Generated Generated InputSentence LI Sentence LI Sentence 1.2 Sentence L2.I concS Concepmd suar.tm~ SSyntS Suffaee:Syntnetlc su'uet~'eos~ts t~sy~ac~ Psy~s ~d:~n~cFigure 9: Scope of the Framework's TransformationsFor example, in Figure 9, starting with the"Input Sentence LI" and passing throughParsing, Conversion, Transfer, DSyntSRealization and SSyntS Realization to"Generated Sentence L2" we obtain an Ll-to-L2MT system.
Starting with "Sentence Planning"and passing through DSyntS Realization, andSSyntS Realization (including linearization andinflection) to "Generated Sentence LI", weobtain a monolingual NLG system for L1.So far the framework has been used successfullyfor building a wide variety of applications indifferent domains and for different languages:NLG:?
Realization of English DSyntSs via SSyntSlevel for the domains of meteorology(MeteoCogent; Kittredge and Lavoie, 1998)and object modeling (ModelExplainer;Lavoie et al, 1997).?
Generation of English text from conceptualinterlingua for the meteorology domain(MeteoCogent).
(The design of theinterlingua can also support he generationof French but this functionality has not yetbeen implemented.)MT:?
Transfer on the DSyntS level and realizationvia SSyntS level for English--French,English--Arabic, English---Korean andKorean--English.
Translation in themeteorology and battlefield omains (Nasret al, 1998).?
Conversion of the output structures fromoff-the-shelf English, French and Koreanparsers to DSyntS level before theirprocessing by the other components in theframework (Palmer et al, 1998).7 Lessons Learned Using the FrameworkEmpirical results obtained from the applicationslisted in Section 6 have shown that the approachused in the framework is flexible enough andeasily portable to new domains, new languages,and new applications.
Moreover, the time spentfor development was relatively short comparedto that formerly required in developing similartypes of applications.
Finally, as intended, thelimited computational power of the transductionmodule, as well as careful implementation,including the compilation of declarativelinguistic knowledge to Java, have ensuredefficient run-time behavior.
For example, in theMT domain we did not originally plan for aseparate conversion step from the parser outputto DSyntS.
However, it quickly became apparentthat there was a considerable gap between theoutput of the parsers we were using and theDSyntS representation that was required, andfurthermore, that we could use the treetransduction module to quickly bridge this gap.Nevertheless, our tree transduction-basedapproach has some important limitations.
Inparticular, the framework requires the developerof the transformation rules to maintain them andspecify the order in which the rules must beapplied.
For a small or a stable grammar, thisdoes not pose a problem.
However, for large orrapidly changing grammar (such as a transfergrammar in MT that may need to be adjustedwhen switching from one parser to another), the65burden of the developer's task may be quiteheavy.
In practice, a considerable amount oftime can be spent in testing a grammar after itsrevision.Another major problem is related to themaintenance of both the grammar and thelexicon.
On several occasions during thedevelopment of these resources, the developer incharge of adding lexical and grammatical datamust make some decisions that are domainspecific.
For example, in MT, writing transferrules for terms that can have several meanings oruses, they may simplify the problem bychoosing a solution based on the context foundin the current corpus, which is a perfectly naturalstrategy.
However, later, when porting thetransfer esources to other domains, the chosenstrategy may need to be revised because thecontext has changed, and other meanings or usesare found in the new corpora.
Because thecurrent approach is based on handcrafted rules,maintenance problems of this sort cannot beavoided when porting the resources to newdomains.An approach such as the one described in (Nasret al, 1998; and Palmer and al., 1998) seems tobe solving a part of the problem when it usescorpus analysis techniques for automaticallycreating a first draft of the lexical transferdictionary using statistical methods.
However,the remaining work is still based on handcraftingbecause the developer must refine the rulesmanually.
The current framework offers nosupport for merging handcrafted rules with newlexical rules obtained statistically whilepreserving the valid handcrafted changes anddeleting the invalid ones.
In general, a betterintegration of linguistically based and statisticalmethods during all the development phases isgreatly needed.8 History of the Framework and Comparisonwith Other SystemsThe framework represents a generalization ofseveral predecessor NLG systems based onMeaning-Text Theory: FoG (Kittredge andPolgu~re, 1991), LFS (Iordanskaja et al, 1992),and JOYCE (Rambow and Korelsky, 1992).The framework was originally developed for therealization of deep-syntactic structures in NLG(Lavoie and Rambow, 1997).
It was laterextended for generation of deep-syntacticstructures from conceptual interlingua (Kittredgeand Lavoie, 1998).
Finally, it was applied toMT for transfer between deep-syntacticstructures of different languages (Palmer et al,1998).
The current framework encompasses thefull spectrum of such transformations, i.e.
fromthe processing of conceptual structures to theprocessing of deep-syntactic structures, eitherfor NLG or MT.Compared to its predecessors (Fog, LFS,JOYCE), our approach as obvious advantagesin uniformity, declarativity and portability.
Theframework has been used in a wider variety ofdomains, for more languages, and for moreapplications (NLG as well as MT).
Theframework uses the same engine for all thetransformations at all levels because all thesyntactic and conceptual structures arerepresented asdependency tree structures.In contrast, the predecessor systems were notdesigned to be rapidly portable.
These systemsused programming languages or scripts for theimplementation f the transformation rules, andused different ypes of processing at differentlevels of representation.
For instance, in LFSconceptual structures were represented asgraphs, whereas syntactic structures wererepresented as trees which required differenttypes of processing at these two levels.Our approach also has some disadvantagescompared with the systems mentioned above.Our lexico-structural transformations are farless powerful than those expressible using anarbitrary programming language.
In practice,the formalism that we are using for expressingthe transformations is inadequate for long-rangephenomena (inter-sentential or intra-sentential),including syntactic phenomena such as long-distance wh-movement and discoursephenomena such as anaphora nd ellipsis.
Theformalism could be extended to handle intra-sentential syntactic effects, but inter-sententialdiscourse phenomena probably requireprocedural rules in order to access lexemes in66other sentences.
In fact, LFS and JOYCEinclude a specific module for elliptical structureprocessing.Similarly, the limited power of the treetransformation rule formalism distinguishes theframework from other NLP frameworks basedon more general processing paradigms uch asunification of FUF/SURGE in the generationdomain (Elhadad and Robin, 1992).9 StatusThe framework is currently being improved inorder to use XML-based specifications forrepresenting the dependency structures and thetransformation rules in order to offer a morestandard development environment and tofacilitate the framework extension andmaintenance.AcknowledgementsA first implementation of the framework (C++processor and ASCII formalism for expressingthe lexico-structural transformation rules)applied to NLG was developed under SBIRF30602-92-C-0015 awarded by USAF RomeLaboratory.
The extensions to MT weredeveloped under SBIR DAAL01-97-C-0016awarded by the Army Research Laboratory.
TheJava implementation and general improvementsof the framework were developed under SBIRDAAD17-99-C-0008 awarded by the ArmyResearch Laboratory.
We are thankful to TedCaldwell, Daryl McCullough, Alexis Nasr andMike White for their comments and criticism onthe work reported in this paper.ReferencesDorr, B. J.
(1994) Machine translation divergences:A formal description and proposed solution.
InComputational Linguistics, vol.
20, no.
4, pp.
597-635.Elhadad, M. and Robin, J.
(1992) ControllingContent Realization with Functional UnificationGrammars.
In Aspects of Automated NaturalLanguage Generation, Dale, R., Hovy, E., Rosner,D.
and Stock, O.
Eds., Springer Verlag, pp.
89-104.Hutchins, W. J. and Somers, H. L. (1997) AnIntroduction to Machine Translation.
AcademicPress, second edition.Iordanskaja, L., Kim, M., Kittredge, R., Lavoie, B.and Polgu6re, A.
(1992) Generation of ExtendedBilingual Statistical Reports.
In Proceedings of the15th International Conference on ComputationalLinguistics, Nantes, France, pp.
1019-1023.Kittredge, R. and Lavoie, B.
(1998) MeteoCogent: AKnowledge-Based Tool For Generating WeatherForecast Texts.
In Proceedings of the AmericanMeteorological Society AI Conference (AMS-98),Phoenix, Arizona, pp.
80--83.Kittredge, R. and Polgu~re, A.
(1991) DependencyGrammars for Bilingual Text Generation: InsideFoG's Stratificational Models.
In Proceedings ofthe International Conference on Current Issues inComputational Linguistics, Penang, Malaysia, pp.318-330.Lavoie, B.
(1995) Interlingua for Bilingual StatisticalReports.
In Notes of IJCAI-95 Workshop onMultilingual Text Generation, Montr6al, Canada,pp.
84---94.Lavoie, B. and Rambow, O.
(1997) A Fast andPortable Realizer for Text Generation Systems.
InProceedings of the Fifth Conference on AppliedNatural Language Processing, Washington, DC.,pp.
265-268.Lavoie, B., Rambow, O. and Reiter, E. (1997)Customizable Descriptions of Object-OrientedModels.
In Proceedings of the Fifth Conference onApplied Natural Language Processing,Washington, DC., pp.
253-256.Mel'cuk, I.
(1988) Dependency Syntax.
StateUniversity of New York Press, Albany, NY.Nasr, A., Rambow, O., Palmer, M. and Rosenzweig,J.
(1998) Enriching lexical transfer with cross-linguistic semantic features.
In Proceedings of theInterlingua Workshop at the MT Summit, SanDiego, California.Palmer, M., Rambow, O. and Nasr, A.
(1998) RapidPrototyping of Domain-Specific MachineTranslation Systems.
In Proceedings of the ThirdConference on Machine Translation in theAmericas (AMTA-98), PA, USA, pp.
95-102.Polgu6re, A.
(1991) Everything has not been saidabout interlinguae: the case of multi-lingual textgeneration system.
In Proc.
of Natural LanguageProcessing Pacific Rim Symposium, Singapore.Rambow, O. and Korelsky, T. (1992) Applied TextGeneration.
In Proceedings of the 6th InternationalWorkshop on Natural Language Generation,Trento, Italy, pp.
40--47.Vauquois, B. and Boitet C. (1985) Automatedtranslation at Grenoble University.
InComputational Linguistics, Vol.
11, pp.
28-36.67
