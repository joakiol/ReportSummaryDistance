Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the ACL, pages 110?118,Boulder, Colorado, June 2009. c?2009 Association for Computational LinguisticsContext-Dependent Alignment Models for Statistical Machine TranslationJamie Brunning, Adria` de Gispert and William ByrneMachine Intelligence LaboratoryDepartment of Engineering, Cambridge UniversityTrumpington Street, Cambridge, CB2 1PZ, U.K.{jjjb2,ad465,wjb31}@eng.cam.ac.ukAbstractWe introduce alignment models for Machine Trans-lation that take into account the context of a sourceword when determining its translation.
Since the useof these contexts alone causes data sparsity prob-lems, we develop a decision tree algorithm for clus-tering the contexts based on optimisation of theEM auxiliary function.
We show that our context-dependent models lead to an improvement in align-ment quality, and an increase in translation qualitywhen the alignments are used in Arabic-English andChinese-English translation.1 IntroductionAlignment modelling for Statistical Machine Translation(SMT) is the task of determining translational correspon-dences between the words in pairs of sentences in paralleltext.
Given a source language word sequence f J1 and atarget language word sequence eI1, we model the transla-tion probability as P(eI1|fJ1 ) and introduce a hidden vari-able aI1 representing a mapping from the target word po-sitions to source word positions such that ei is aligned tofai .
Then P(eI1|f j1 ) =?aI1 P(eI1, aI1|fj1 ) (Brown et al,1993).Previous work on statistical alignment modelling hasnot taken into account the source word context when de-termining translations of that word.
It is intuitive that aword in one context, with a particular part-of-speech andparticular words surrounding it, may translate differentlywhen in a different context.
We aim to take advantageof this information to provide a better estimate of theword?s translation.
The challenge of incorporating con-text information is maintaining computational tractabilityof estimation and alignment, and we develop algorithmsto overcome this.The development of efficient estimation proceduresfor context-dependent acoustic models revolutionised thefield of Automatic Speech Recognition (ASR) (Young etal., 1994).
Clustering is used extensively for improv-ing parameter estimation of triphone (and higher order)acoustic models, enabling robust estimation of param-eters and reducing the computation required for recog-nition.
Kannan et al (1994) introduce a binary tree-growing procedure for clustering Gaussian models fortriphone contexts based on the value of a likelihood ra-tio.
We adopt a similar approach to estimate context-dependent translation probabilities.We focus on alignment with IBM Model 1 and HMMs.HMMs are commonly used to generate alignments fromwhich state of the art SMT systems are built.
Model 1 isused as an intermediate step in the creation of more pow-erful alignment models, such as HMMs and further IBMmodels.
In addition, it is used in SMT as a feature in Min-imum Error Training (Och et al, 2004) and for rescor-ing lattices of translation hypotheses (Blackwood et al,2008).
It is also used for lexically-weighted phrase ex-traction (Costa-jussa` and Fonollosa, 2005) and sentencesegmentation of parallel text (Deng et al, 2007) prior tomachine translation.1.1 OverviewWe first develop an extension to Model 1 that allows theuse of arbitrary context information about a source wordto estimate context-dependent word-to-word translationprobabilities.
Since there is insufficient training data toaccurately estimate translation probabilities for less fre-quently occurring contexts, we develop a decision treeclustering algorithm to form context classes.
We go on todevelop a context-dependent HMM model for alignment.In Section 3, we evaluate our context-dependent mod-els on Arabic-English parallel text, comparing them toour baseline context-independent models.
We performmorphological decomposition of the Arabic text usingMADA, and use part-of-speech taggers on both lan-guages.
Alignment quality is measured using AlignmentError Rate (AER) measured against a manually-alignedparallel text.
Section 4 uses alignments produced by110our improved alignment models to initialise a statisticalmachine translation system and evaluate the quality oftranslation on several data sets.
We also apply part-of-speech tagging and decision tree clustering of contexts toChinese-English parallel text; translation results for theselanguages are presented in Section 4.2.1.2 Previous and related workBrown et al (1993) introduce IBM Models 1-5 for align-ment modelling; Vogel et al (1996) propose a HiddenMarkov Model (HMM) model for word-to-word align-ment, where the words of the source sentence are viewedas states of an HMM and emit target sentence words;Deng and Byrne (2005a) extend this to an HMM word-to-phrase model which allows many-to-one alignments andcan capture dependencies within target phrases.Habash and Sadat (2006) perform morphological de-composition of Arabic words, such as splitting of pre-fixes and suffixes.
This leads to gains in machine trans-lation quality when systems are trained on parallel textcontaining the modified Arabic and processing of Arabictext is carried out prior to translation.
Nie?en and Ney(2001a) perform pre-processing of German and Englishtext before translation; Nie?en and Ney (2001b) use mor-phological information of the current word to estimatehierarchical translation probabilities.Berger et al (1996) introduce maximum entropy mod-els for machine translation, and use a window either sideof the target word as context information.
Varea et al(2002) test for the presence of specific words within awindow of the current source word to form features foruse inside a maximum entropy model of alignment.Toutanova et al (2002) use part-of-speech informa-tion in both the source and target languages to estimatealignment probabilities, but this information is not in-corporated into translation probabilities.
Popovic?
andNey (2004) use the base form of a word and its part-of-speech tag during the estimation of word-to-word transla-tion probabilities for IBM models and HMMs, but do notdefined context-dependent estimates of translation prob-abilities.Stroppa et al (2007) consider context-informed fea-tures of phrases as components of the log-linear modelduring phrase-based translation, but do not address align-ment.2 Use of source language context inalignment modellingConsider the alignment of the target sentence e = eI1 withthe source sentence f = fJ1 .
Let a = aI1 be the align-ments of the target words to the source words.
Let cj bethe context information of fj for j = 1, .
.
.
, J .
This con-text information can be any information about the word,e.g.
part-of-speech, previous and next words, part-of-speech of previous and next words, or longer range con-text information.We follow Brown et al (1993), but extend their mod-elling framework to include information about the sourceword from which a target word is emitted.
We model thealignment process as:P(eI1, aI1, I |fJ1 , cJ1 ) =P(I |fJ1 , cJ1 )I?i=1[P(ei|ai1, ei?11 , fJ1 , cJ1 , I)?
P(ai|ei?11 , ai?11 , fJ1 , cJ1 , I)] (1)We introduce word-to-word translation tables that dependon the source language context for each word, i.e.
theprobability that f translates to e given f has context c ist(e|f, c).
We assume that the context sequence is givenfor a source word sequence.
This assumption can berelaxed to allow for multiple tag sequences as hiddenprocesses, but we assume here that a tagger generatesa single context sequence cJ1 for a word sequence fJ1 .This corresponds to the assumption that, for a context se-quence c?J1 , P(c?J1 |fJ1 ) = ?cJ1 (c?J1 ); henceP(eI1, aI1|fJ1 ) =?c?J1P(eI1, aI1, c?J1 |fJ1 ) = P(eI1, aI1|cJ1 , fJ1 )For Model 1, ignoring the sentence length distribution,PM1(eI1, aI1|fJ1 , cJ1 ) = 1(J + 1)II?i=1t(ei|fai , cai).
(2)Estimating translation probabilities separately for ev-ery possible context of a source word individually leadsto problems with data sparsity and rapid growth of thetranslation table.
We therefore wish to cluster source con-texts which lead to similar probability distributions.
LetCf denote the set of all observed contexts of source wordf .
A particular clustering is denotedKf = {Kf,1, .
.
.
,Kf,Nf},where Kf is a partition of Cf .
We define a class mem-bership function ?f such that for any context c, ?f (c)is the cluster containing c. We assume that all contextsin a cluster give rise to the same translation probabilitydistribution for that source word, i.e.
for a cluster K,t(e|f, c) = t(e|f, c?)
for all contexts c, c?
?
K and alltarget words e; we write this shared translation probabil-ity as t(e|f,K).The Model 1 sentence translation probability for agiven alignment (Equation 2) becomesPM1(eI1, aI1|fJ1 , cJ1 ) = 1(J + 1)II?i=1t(ei|fai , ?f (cai)).
(3)111For HMM alignment, we assume that the transition prob-abilities a(ai|ai?1) are independent of the word contextsand the sentence translation probability isPH(eI1, aI1|fJ1 , cJ1 ) =I?i=1a(ai|ai?1, J)t(ei|fai , ?f (cai)).
(4)Section 2.1.1 describes how the context classes are deter-mined by optimisation of the EM auxiliary function.
Al-though the translation model is significantly more com-plex than that of context-independent models, once classmembership is fixed, alignment and parameter estimationuse the standard algorithms.2.1 EM parameter estimationWe train using Expectation Maximisation (EM), optimis-ing the log probability of the training set {e(s), f (s)}Ss=1(Brown et al, 1993).
Given model parameters ?
?, we es-timate new parameters ?
by maximisation of the EM aux-iliary function?s,aP??
(a|f (s), c(s), e(s)) log P?
(e(s), a, I(s)|f (s), c(s)).We assume the sentence length distribution and align-ment probabilities do not depend on the contexts of thesource words; hence the relevant part of the auxiliaryfunction is?e?f?c?Cf??
(e|f, c) log t(e|f, c), (5)where??
(e|f, c) = ?sI(s)?i=1J(s)?j=1[?c(c(s)j )?e(e(s)i )?f (f (s)j )?
P??
(ai = j|e(s), f (s), c(s))]Here ??
can be computed under Model 1 or the HMM,and is calculated using the forward-backward algorithmfor the HMM.2.1.1 Parameter estimation with clustered contextsWe can re-write the EM auxiliary function (Equation5) in terms of the cluster-specific translation probabilities:?e?f|Kf |?l=1?c?Kf,l??
(e|f, c) log t(e|f, c)= ?e?f?K?Kf??
(e|f,K) log t(e|f,K) (6)where ??
(e|f,K) = ?c?K??
(e|f, c)Following the usual derivation, the EM update for theclass-specific translation probabilities becomest?
(e|f,K) = ??(e|f,K)?e?
??(e?|f,K).
(7)Standard EM training can be viewed a special case of this,with every context of a source word grouped into a sin-gle cluster.
Another way to view these clustered context-dependent models is that contexts belonging to the samecluster are tied and share a common translation proba-bility distribution, which is estimated from all trainingexamples in which any of the contexts occur.2.2 Decision trees for context clusteringThe objective for each source word is to split the contextsinto classes to maximise the likelihood of the trainingdata.
Since it is not feasible to maximise the likelihoodof the observations directly, we maximise the expectedlog likelihood by considering the EM auxiliary function,in a similar manner to that used for modelling contextualvariations of phones for ASR (Young et al, 1994; Singerand Ostendorf, 1996).
We perform divisive clustering in-dependently for each source word f , by building a binarydecision tree which forms classes of contexts which max-imise the EM auxiliary function.
Questions for the treeare drawn from a set of questions Q = {q1, .
.
.
, q|Q|}concerning the context information of f .Let K be any set of contexts of f , and defineL(K) = ?e?c?K??
(e|f, c) log t(e|f, c)= ?e?c?K??
(e|f, c) log?c?K ??
(e|f, c)?e?
?c?K ??
(e?|f, c).This is the contribution to the EM auxiliary function ofsource word f occurring in the contexts of K. Let q bea binary question about the context of f , and considerthe effect on the partial auxiliary function (Equation 6)of splitting K into two clusters using question q. DefineKq be the set of contexts in K which answer ?yes?
to qand Kq?
be the contexts which answer ?no?.
Define theobjective functionQf,q(K) =?e?c?Kq??
(e|f, c) log t(e|f, c)+?e?c?Kq???
(e|f, c) log t(e|f, c)= L(Kq) + L(Kq?
)When the node is split using question q, the increase inobjective function is given byQf,q(K)?
L(K) = L(Kq?)
+ L(Kq)?
L(K).112We choose q to maximise this.In order to build the decision tree for f , we take the setof all contexts Cf as the initial cluster at the root node.We then find the question q?
such that Qf,q(Cf ) is maxi-mal, i.e.q?
= arg maxq?QQf,q(Cf )This splits Cf , so our decision tree now has two nodes.We iterate this process, at each iteration splitting (intotwo further nodes) the leaf node that leads to the great-est increase in objective function.
This leads to a greedysearch to optimise the log likelihood over possible stateclusterings.In order to control the growth of the tree, we put inplace two thresholds:?
Timp is the minimum improvement in objective func-tion required for a node to be split; without it, wewould continue splitting nodes until each containedonly one context, even though doing so would causedata sparsity problems.?
Tocc is the minimum occupancy of a node, based onhow often the contexts at that node occur in the train-ing data; we want to ensure that there are enough ex-amples of a context in the training data to estimateaccurately the translation probability distribution forthat cluster.For each leaf node l and set of contextsKl at that node,we find the question ql that, when used to split Kl, pro-duces the largest gain in objective function:ql = arg maxq?Q[L(Kl,q) + L(Kl,q?)?
L(Kl)]= arg maxq?Q[L(Kl,q) + L(Kl,q?
)]We then find the leaf node for which splitting gives thelargest improvement:l?
= arg maxl[L(Kl,ql) + L(Kl,q?l)?
L(Kl)]If the following criteria are both satisfied at that node, wesplit the node into two parts, creating two leaf nodes inits place:?
The objective function increases sufficientlyL(Kl,ql) + L(Kl,q?l)?
L(Kl) > Timp?
The occupancy threshold is exceeded for both childnodes:?e?c?Kl,x??
(e|f, c) > Tocc for x = q, q?We perform such clustering for every source word in theparallel text.shares NNS ?
?
?
?
?
?
?bank NN ?
?
?
?
?
?
?the DT ?
?
?
?
?
?
?of IN ?
?
?
?
?
?
?% PUNC ?
?
?
?
?
?
?12 NN ?
?
?
?
?
?
?selling VBG ?
?
?
?
?
?
?of IN ?
?
?
?
?
?
?deal NN ?
?
?
?
?
?
?the DT ?
?
?
?
?
?
?SfqpNNbyENN12NN%PUNCmnIN>shmNNAlbnkNNcity NN ?
?
?
?
?
?
?
?the DT ?
?
?
?
?
?
?
?in IN ?
?
?
?
?
?
?
?liquor NN ?
?
?
?
?
?
?
?selling VBG ?
?
?
?
?
?
?
?were VBD ?
?
?
?
?
?
?
?owners NNS ?
?
?
?
?
?
?
?whose WP$ ?
?
?
?
?
?
?
?houses NNS ?
?
?
?
?
?
?
?several JJ ?
?
?
?
?
?
?
?and CC ?
?
?
?
?
?
?
?w+CCmnAzlNNEdpJJ>SHAbhANNybyEwnVBPAlxmwrNNfyINAlmdynpNNFigure 1: Alignment of the English selling in different contexts.In the first, it is preceded by of and links to the infinitive of theArabic verb byE; in the second, it is preceded by were and linksto an inflected form of the same Arabic verb, ybyEwn.3 Evaluation of alignment qualityOur models were built using the MTTK toolkit (Dengand Byrne, 2005b).
Decision tree clustering was imple-mented and the process parallelised to enable thousandsof decision trees to be built.
Our context-dependent (CD)Model 1 models trained on context-annotated data werecompared to the baseline context-independent (CI) mod-els trained on untagged data.The models were trained using data allowed for theNIST 08 Arabic-English evaluation1, excluding the UNcollections, comprising 300k parallel sentence pairs, a to-tal of 8.4M words of Arabic and 9.5M words of English.The Arabic language incorporates into its words sev-eral prefixes and suffixes which determine grammaticalfeatures such as gender, number, person and voice.
TheMADA toolkit (Habash and Sadat, 2006) was used toperform Arabic morphological word decomposition andpart-of-speech tagging.
It determines the best analysisfor each word in a sentence and splits word prefixes andsuffixes, based on the alternative analyses provided byBAMA (Buckwalter, 2002).
We use tokenisation scheme1http://nist.gov/speech/tests/mt/2008113?D2?, which splits certain prefixes and has been reportedto improve machine translation performance (Habash andSadat, 2006).
The alignment models are trained on thisprocessed data, and the prefixes and suffixes are treatedas words in their own right; in particular their contextsare examined and clustered.The TnT tagger (Brants, 2000), used as distributedwith its model trained on the Wall Street Journal portionof the Penn treebank, was used to obtain part-of-speechtags for the English side of the parallel text.
Marcus et al(1993) gives a complete list of part-of-speech tags pro-duced.
No morphological analysis is performed for En-glish.Automatic word alignments were compared to amanually-aligned corpus made up of the IBM Arabic-English Word Alignment Corpus (Ittycheriah et al,2006) and the word alignment corpora LDC2006E86 andLDC2006E93.
This contains 28k parallel text sentencespairs: 724k words of Arabic and 847k words of English.The alignment links were modified to reflect the MADAtokenisation; after modification, there are 946k word-to-word alignment links.Alignment quality was evaluated by computing Align-ment Error Rate (AER) (Och and Ney, 2000) relative tothe manual alignments.
Since the links supplied con-tain only ?sure?
links and no ?possible?
links, we use thefollowing formula for computing AER given referencealignment links S and hypothesised alignment links A:AER = 1?
2|S?A||S|+|A| .3.1 Questions about contextsThe algorithm presented in Section 2 allows for any infor-mation about the context of the source word to be consid-ered.
We could consider general questions of the form ?Isthe previous word x??
and ?Does word y occur within nwords of this one??.
To maintain computational tractabil-ity, we restrict the questions to those concerning the part-of-speech tag assigned to the current, previous and nextwords.
We do not ask questions about the identities of thewords themselves.
For each part-of-speech tag T , we askthe question ?Does w have tag T??.
In addition, we grouppart-of-speech tags to ask more general questions: e.g.the set of contexts which satisfies ?Is w a noun??
containsthose that satisfy ?Is w a proper noun??
and ?Is w a sin-gular or mass noun??.
We also ask the same questionsof the previous and next words in the source sentence.In English, this gives a total of 152 distinct questions,each of which is considered when splitting a leaf node.The MADA part-of-speech tagger uses a reduced tag set,which produces a total of 68 distinct questions.Figure 1 shows the links of the English source wordselling in two different contexts where it links to differentwords in Arabic, which are both forms of the same verb.The part-of-speech of the previous word is useful for dis--4.22e+07-4.2e+07-4.18e+07-4.16e+07-4.14e+07-4.12e+07-4.1e+07-4.08e+07-4.06e+07-4.04e+0711  12  13  14  15  16  17  18  19  20LogprobabilityoftrainingdataIterationCI Model 1Threshold 10Threshold 20Threshold 60-3.1e+06-3.05e+06-3e+06-2.95e+06-2.9e+06-2.85e+06-2.8e+06-2.75e+0611  12  13  14  15  16  17  18  19  20LogprobabilityoftrainingdataIterationCI Model 1Threshold 10Threshold 20Threshold 60Figure 2: Increase in log probability of training data duringtraining for varying Timp, with Model 1, for Arabic to English(top) and English to Arabic (bottom)criminating between the two cases, whereas a context-independent model would assign the same probability toboth Arabic words.3.2 Training Model 1Training is carried out in both translation directions.
ForArabic to English, the Arabic side of the parallel text istagged and the English side remains untagged; we viewthe English words as being generated from the Arabicwords and questions are asked about the context of theArabic words to determine clusters for the translation ta-ble.
For English to Arabic, the situation is reversed: weused tagged English text as the source language and un-tagged Arabic text, with morphological decomposition,as the target language.Standard CI Model 1 training, initialised with a uni-form translation table so that t(e|f) is constant for allsource/target word pairs (f, e), was run on untagged datafor 10 iterations in each direction (Brown et al, 1993;Deng and Byrne, 2005b).
A decision tree was built tocluster the contexts and a further 10 iterations of trainingwere carried out using the tagged words-with-context toproduce context-dependent models (CD Model 1).
The114English question FrequencyIs Next Preposition 1523Is Prev Determiner 1444Is Prev Preposition 1209Is Prev Adjective 864Is Next Noun Singular Mass 772Is Prev Noun Singular Mass 690Is Next Noun Plural 597Is Next Noun 549Arabic question FrequencyIs Prev Preposition 1110Is Next Preposition 993Is Prev Noun 981Is Next Noun 912Is Prev Coordinating Conjunction 627Is Prev Noun SingularMass 607Is Next Punctuation 603Is Next Adjective Adverb 559Table 1: Most frequent root node context questionsmodels were then evaluated using AER at each train-ing iteration.
A number of improvement thresholds Timpwere tested, and performance compared to that of modelsfound after further iterations of CI Model 1 training onthe untagged data.
In both alignment directions, the logprobability of the training data increases during training(see Figure 2).
As expected, the training set likelihoodincreases as the threshold Timp is reduced, allowing moreclusters and closer fitting to the data.3.2.1 Analysis of frequently used questionsTable 1 shows the questions used most frequently atthe root node of the decision tree when clustering con-texts in English and Arabic.
Because they are used first,these are the questions that individually give the great-est ability to discriminate between the different contextsof a word.
The list shows the importance of the left andright contexts of the word in predicting its translation: ofthe most common 50 questions, 25 concern the previousword, 19 concern the next, and only 6 concern the part-of-speech of the current word.
For Arabic, of the mostfrequent 50 questions, 21 concern the previous word, 20concern the next and 9 the current word.3.2.2 Alignment Error RateSince MT systems are usually built on the union of thetwo sets of alignments (Koehn et al, 2003), we considerthe union of alignments in the two directions as well asthose in each direction.
Figure 3 shows the change inAER of the alignments in each direction, as well as thealignment formed by taking their union at correspondingthresholds and training iterations.Timp Arabic-English (%) English-Arabic (%)10 30601 (25.33) 26011 (39.87)20 11193 (9.27) 18365 (28.15)40 1874 (1.55) 9104 (13.96)100 307 (0.25) 1128 (1.73)Table 2: Words [number (percentage)] with context-dependenttranslation for varying Timp3.2.3 Variation of improvement threshold TimpThere is a trade-off between modelling the data accu-rately, which requires more clusters, and eliminating datasparsity problems, which requires each cluster to containcontexts that occur frequently enough in the training datato estimate the translation probabilities accurately.
Use ofa smaller threshold Timp leads to more clusters per wordand an improved ability to fit to the data, but this can leadto reduced alignment quality if there is insufficient datato estimate the translation probability distribution accu-rately for each cluster.
For lower thresholds, we observeover-fitting and the AER rises after the second iteration ofCD training, similar to the behaviour seen in Och (2002).Setting Timp = 0 results in each context of a word havingits own cluster, which leads to data sparsity problems.Table 2 shows the percentage of words for which thecontexts are split into multiple clusters for CD Model 1with varying improvement thresholds.
This occurs whenthere are enough training data examples and sufficientvariability between the contexts of a word that splittingthe contexts into more than one cluster increases the EMauxiliary function.
For words where the contexts are notsplit, all the contexts remain in the same cluster and pa-rameter estimation is exactly the same as for the unclus-tered context-independent models.3.3 Training HMMsAdding source word context to translation has so far ledto improvements in AER for Model 1, but the perfor-mance does not match that of HMMs trained on untaggeddata; we therefore train HMMs on tagged data.We proceed with Model 1 and Model 2 trained in theusual way, and context-independent (CI) HMMs weretrained for 5 iterations on the untagged data.
Statisticswere then gathered for clustering at various thresholds,after which 5 further EM iterations were performed withtagged data to produce context-dependent (CD) HMMs.The HMMs were trained in both the Arabic to Englishand the English to Arabic directions.
The log likelihoodof the training set varies with Timp in much the sameway as for Model 1, increasing at each iteration, withgreater likelihood at lower thresholds.
Figure 4 showshow the AER of the union alignment varies with Timpduring training.
As with Model 1, the clustered HMM11549.249.449.649.85050.250.450.650.810  11  12  13  14  15  16  17  18  19  20AERIterationCI Model 1Threshold 10Threshold 20Threshold 6049.649.850.050.250.450.650.851.051.210  11  12  13  14  15  16  17  18  19  20AERIterationCI Model 1Threshold 10Threshold 20Threshold 60Threshold 10049.049.249.449.649.850.050.250.450.650.851.010  11  12  13  14  15  16  17  18  19  20AERIterationCI Model 1Threshold 10Threshold 20Threshold 60Figure 3: Variation of AER during Model 1 training for varyingTimp, for Arabic to English (top), English to Arabic (middle)and their union (bottom)34.434.534.634.734.834.935.035.135.235.35  6  7  8  9  10AERIterationCI HMMThreshold 10Threshold 20Threshold 60Figure 4: AER of the union alignment for varying Timp with theHMM model727476788040  45  50  55  60PrecisionRecallp0=0.95p0=0.00p0=0.95p0=0.00English-Arabic CD HMMEnglish-Arabic CI HMMArabic-English CD HMMArabic-English CI HMMFigure 5: Precision/recall curves for the context-dependentHMM and the baseline context-independent HMM, for Arabicto English and English to Arabic.
p0 varies from 0.00 to 0.95 insteps of 0.05.models produce alignments with a lower AER than thebaseline model, and there is evidence of over-fitting tothe training data.3.3.1 Alignment precision and recallThe HMM models include a null transition probability,p0, which can be modified to adjust the number of align-ments to the null token (Deng and Byrne, 2005a).
Wherea target word is emitted from null, it is not included inthe alignment links, so this target word is viewed as notbeing aligned to any source word; this affects the preci-sion and recall.
The results reported above use p0 = 0.2for English-Arabic and p0 = 0.4 for Arabic-English; wecan tune these values to produce alignments with the low-est AER.
Figure 5 shows precision-recall curves for theCD HMMs compared to the CI HMMs for both transla-tion directions.
For a given value of precision, the CDHMM has higher recall; for a given value of recall, theCD HMM has higher precision.We do not report F-score (Fraser and Marcu, 2006)since in our experiments we have not found strong cor-relation with translation performance, but we note thatthese results for precision and recall should lead to im-proved F-scores as well.4 Evaluation of translation qualityWe have shown that the context-dependent models pro-duce a decrease in AER measured on manually-aligneddata; we wish to show this improved model performanceleads to an increase in translation quality, measured byBLEU score (Papineni et al, 2001).
In addition to theArabic systems already evaluated by AER, we also reportresults for a Chinese-English translation system.Alignment models were evaluated by aligning thetraining data using the models in each translation direc-116tion.
HiFST, a WFST-based hierarchical translation sys-tem described in (Iglesias et al, 2009), was trained onthe union of these alignments.
MET (Och, 2003) wascarried out using a development set, and the BLEU scoreevaluated on two test sets.
Decoding used a 4-gram lan-guage model estimated from the English side of the entireMT08 parallel text, and a 965M word subset of monolin-gual data from the English Gigaword Third Edition.For both Arabic and English, the CD HMM modelswere evaluated as follows.
Iteration 5 of the CI HMMwas used to produce alignments for the parallel text train-ing data: these were used to train the baseline system.The same data is aligned using CD HMMs after twofurther iterations of training and a second WFST-basedtranslation system built from these alignments.
The mod-els are evaluated by comparing BLEU scores with thoseof the baseline model.4.1 Arabic to English translationAlignment models were trained on the NIST MT08Arabic-English parallel text, excluding the UN portion.The null alignment probability was chosen based on theAER, resulting in values of p0 = 0.05 for Arabic toEnglish and p0 = 0.10 for English to Arabic.
We per-form experiments on the NIST Arabic-English transla-tion task.
The mt02 05 tune and mt02 05 test data setsare formed from the odd and even numbered sentencesof the NIST MT02 to MT05 evaluation sets respectively;each contains 2k sentences and 60k words.
We usemt02 05 tune as a development set and evaluate the sys-tem on mt02 05 test and the newswire portion of theMT08 set, MT08-nw.
Table 3 shows a comparison of thesystem trained using CD HMMs with the baseline sys-tem, which was trained using CI HMM models on un-tagged data.
The context-dependent models result in again in BLEU score of 0.3 for mt02 05 test and 0.6 forMT08-nw.4.2 Chinese to English translationThe Chinese training set was 600k random parallel textsentences of the newswire LDC collection allowed forNIST MT08, a total of 15.2M words of Chinese and16.6M words of English.
The Chinese text was tagged us-ing the MXPOST maximum-entropy part of speech tag-ging tool (Ratnaparkhi, 1996) trained on the Penn Chi-nese Treebank 5.1; the English text was tagged using theTnT part of speech tagger (Brants, 2000) trained on theWall Street Journal portion of the English Penn treebank.The development set tune-nw and validation set test-nwcontain a mix of the newswire portions of MT02 throughMT05 and additional developments sets created by trans-lation within the GALE program.
We also report resultson the newswire portion of the MT08 set.
Again we seean increase in BLEU score for both test sets: 0.5 for test-Arabic-EnglishAlignments tune mt02 05 test MT08-nwCI HMM 50.0 49.4 46.3CD HMM 50.0 49.7 46.9Chinese-EnglishAlignments tune test-nw MT08-nwCI HMM 28.1 28.5 26.9CD HMM 28.5 29.0 27.7Table 3: Comparison, using BLEU score, of the CD HMM withthe baseline CI HMMnw and 0.8 for MT08-nw.5 Conclusions and future workWe have introduced context-dependent Model 1 andHMM alignment models, which use context informationin the source language to improve estimates of word-to-word translation probabilities.
Estimation of parame-ters using these contexts without smoothing leads to datasparsity problems; therefore we have developed decisiontree clustering algorithms to cluster source word contextsbased on optimisation of the EM auxiliary function.
Con-text information is incorporated by the use of part-of-speech tags in both languages of the parallel text, and theEM algorithm is used for parameter estimation.We have shown that these improvements to the modellead to decreased AER compared to context-independentmodels.
Finally, we compare machine translation sys-tems built using our context-dependent alignments.
Forboth Arabic- and Chinese-to-English translation, wereport an increase in translation quality measured byBLEU score compared to a system built using context-independent alignments.This paper describes an initial investigation intocontext-sensitive alignment models, and there are manypossible directions for future research.
Clustering theprobability distributions of infrequently occurring mayproduce improvements in alignment quality, differentmodel training schemes and extensions of the context-dependence to more sophisticated alignment models willbe investigated.
Further translation experiments will becarried out.AcknowledgementsThis work was supported in part by the GALE program ofthe Defense Advanced Research Projects Agency, Con-tract No.
HR0011-06-C-0022.
J. Brunning is supportedby a Schiff Foundation graduate studentship.
Thanks toYanjun Ma, Dublin City University, for training the Chi-nese part of speech tagger.117ReferencesA.
L. Berger, S. Della Pietra, and V. J. Della Pietra.
1996.
Amaximum entropy approach to natural language processing.Computational Linguistics, 22(1):39?71.Graeme Blackwood, Adria` de Gispert, Jamie Brunning, andWilliam Byrne.
2008.
European language translation withweighted finite state transducers: The CUED MT system forthe 2008 ACL workshop on SMT.
In Proceedings of theThird Workshop on Statistical Machine Translation, pages131?134, Columbus, Ohio, June.
Association for Computa-tional Linguistics.Thorsten Brants.
2000.
TnT ?
a statistical part-of-speech tag-ger.
In Proceedings of the 6th Applied Natural LanguageProcessing Conference: ANLP-2000, Seattle, USA.Peter F. Brown, Vincent J. Della Pietra, Stephen A. Della Pietra,and Robert L. Mercer.
1993.
The mathematics of statisticalmachine translation: parameter estimation.
ComputationalLinguistics, 19(2):263?311.T.
Buckwalter.
2002.
Buckwalter Arabic morphological ana-lyzer.Marta Ruiz Costa-jussa` and Jos?e A. R. Fonollosa.
2005.Improving phrase-based statistical translation by modifyingphrase extraction and including several features.
In Proceed-ings of the ACL Workshop on Building and Using ParallelTexts, pages 149?154, June.Yonggang Deng and William Byrne.
2005a.
HMM word andphrase alignment for statistical machine translation.
In Proc.of HLT-EMNLP.Yonggang Deng and William Byrne.
2005b.
JHU-Cambridgestatistical machine translation toolkit (MTTK) user manual.Yonggang Deng, Shankhar Kumar, and William Byrne.
2007.Segmentation and alignment of parallel text for statisticalmachine translation.
Journal of Natural Language Engineer-ing, 13:3:235?260.Alexander Fraser and Daniel Marcu.
2006.
Measuring wordalignment quality for statistical machine translation.
Tech-nical Report ISI-TR-616, ISI/University of Southern Califor-nia, May.Nizar Habash and Fatiha Sadat.
2006.
Arabic preprocessingschemes for statistical machine translation.
In HLT-NAACL.G.
Iglesias, A. de Gispert, E. R. Banga, and W. Byrne.
2009.Hierarchical phrase-based translation with weighted finitestate transducers.
In Procedings of NAACL-HLT, 2009,Boulder, Colorado.Abraham Ittycheriah, Yaser Al-Onaizan, and Salim Roukos.2006.
The IBM Arabic-English word alignment corpus, Au-gust.A.
Kannan, M. Ostendorf, and J. R. Rohlicek.
1994.
Maxi-mum likelihood clustering of Gaussians for speech recogni-tion.
Speech and Audio Processing, IEEE Transactions on,2(3):453?455, July.Philipp Koehn, Franz Josef Och, and Daniel Marcu.
2003.
Sta-tistical phrase-based translation.
In NAACL ?03: Proceed-ings of the 2003 Conference of the North American Chapterof the Association for Computational Linguistics on HumanLanguage Technology, pages 48?54.Mitchell P. Marcus, Mary Ann Marcinkiewicz, and BeatriceSantorini.
1993.
Building a large annotated corpus ofEnglish: the Penn Treebank.
Computational Linguistics,19(2):313?330.Sonja Nie?en and Hermann Ney.
2001a.
Morpho-syntacticanalysis for reordering in statistical machine translation.
InProceedings of MT Summit VIII, pages 247?252, September.Sonja Nie?en and Hermann Ney.
2001b.
Toward hierarchicalmodels for statistical machine translation of inflected lan-guages.
In Proceedings of the workshop on Data-drivenmethods in machine translation, pages 1?8, Morristown, NJ,USA.
Association for Computational Linguistics.Franz Josef Och and Hermann Ney.
2000.
A comparison ofalignment models for statistical machine translation.
In Pro-ceedings of the 18th conference on Computational Linguis-tics, pages 1086?1090.F.
Och, D. Gildea, S. Khudanpur, A. Sarkar, K. Yamada,A.
Fraser, S. Kumar, L. Shen, D. Smith, K. Eng, V. Jain,Z.
Jin, and D. Radev.
2004.
A smorgasbord of features forstatistical machine translation.
In Proceedings of NAACL.Franz Josef Och.
2002.
Statistical Machine Translation: FromSingle Word Models to Alignment Templates.
Ph.D. thesis,Franz Josef Och.Franz Josef Och.
2003.
Minimum error rate training in statisti-cal machine translation.
In ACL ?03: Proceedings of the 41stAnnual Meeting on Association for Computational Linguis-tics, pages 160?167.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-JingZhu.
2001.
Bleu: a method for automatic evaluation of ma-chine translation.
In Proceedings of ACL, pages 311?318.Maja Popovic?
and Hermann Ney.
2004.
Improving word align-ment quality using morpho-syntactic information.
In In Pro-ceedings of COLING, page 310.Adwait Ratnaparkhi.
1996.
A maximum entropy model forpart-of-speech tagging.
In In Proceedings of the Confer-ence on Empirical Methods in Natural Language Processing,pages 133?142.H.
Singer and M. Ostendorf.
1996.
Maximum likelihood suc-cessive state splitting.
Proceedings of ICASSP, 2:601?604.Nicolas Stroppa, Antal van den Bosch, and Andy Way.
2007.Exploiting source similarity for SMT using context-informedfeatures.
In Proceedings of the 11th Conference on Theoreti-cal and Methodological Issues in Machine Translation (TMI2007), pages 231 ?
240.Kristina Toutanova, H. Tolga Ilhan, and Christopher D. Man-ning.
2002.
Extensions to HMM-based statistical wordalignment models.
In Proceedings of EMNLP, pages 87?94.Ismael Garc?
?a Varea, Franz J. Och, Hermann Ney, and Fran-cisco Casacuberta.
2002.
Improving alignment quality instatistical machine translation using context-dependent max-imum entropy models.
In Proceedings of COLING, pages1?7.Stephan Vogel, Hermann Ney, and Christoph Tillmann.
1996.HMM-based word alignment in statistical translation.
InProceedings of COLING, pages 836?841.S.
J.
Young, J. J. Odell, and P. C. Woodland.
1994.
Tree-basedstate tying for high accuracy acoustic modelling.
In HLT ?94:Proceedings of the workshop on Human Language Technol-ogy, pages 307?312.118
