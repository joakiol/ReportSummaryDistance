SESSION 1: LEXICONS, CORPORA, AND EVALUATIONGeorge A. Miller, ChairCognitive Science LaboratoryPrinceton UniversityPrinceton, NJ 08542Our technologies for collecting, storing, and disseminatingvast amounts of information have gotten ahead of our tech-nologies for collating and analyzing it, and that situation hasposed a serious challenge for human language technology.As a consequence, natural anguage processing has beenmoving rapidly towards large-scale systems addressed toreal tasks.
Demos that won't scale up are no longer interest-ing.Large-scale systems are not feasible, however, withoutlarge-scale resources for development and evaluation.Toward this end, the Linguistic Data Consortium wascreated in 1992 with a combination of government andprivate funds.
The Consortium's mandate is to create arepository of linguistic resources and to make them availablefor research and development in human language technol-ogy.
Much of this session was devoted to a description oftheir progress toward that goal.In order to deal with the range and variety of words encoun-tered in real life communications, it has been necessary toobtain bigger and better lexicons, and the Linguistic DataConsortium has supported the creation a syntactic lexicon,Comlex.
In their report on the Comlex Syntax project,Macleod, Grishman, and Meyers explain how they haveadded syntactic information to their lexicon, information farmore detailed than is found in standard dictionaries.In order to evaluate proposed systems, it has been necessaryto obtain good spoken and textual corpora--large and hal-anced if possible, but certainly large.
A series of threepapers describe what the Linguistic Data Consortium hasbeen doing to meet hat need in a wide variety of languages.Corpora of telephone speech that are being collected at SRIand at the Oregon Center for Spoken Language Understand-ing (both with support from the Linguistic Data Consortium)are also described.
It is important that these copora will begenerally available.
If systems are developed or evaluatedon different corpora, there is no way to know whether differ-ences in performance should be attributed to the systems orto the corpora.In some quarters, the opinion seems to be that the singularvalue of the large corpora that are becoming available nowis that hey permit statistical analyses that were not possiblebefore.
I have nothing against statistical analyses--I havewalked both sides of that street in my time---but it is impor-tant to realize that there are other good reasons for wantingto collect large corpora nd make them generally available.For example, a large textual corpus is an enormous aid incompiling the lexicons that we need.
As a lexicon grows insize, the entries come closer and closer to the limits of alexicographer's personal knowledge.
Then it becomesimportant to be able to consult examples drawn from actualusage.
But to get, say, 20 examples of a rare word, access toa very large corpus is needed.Large corpora of spoken language are needed to assessspeaker differences and to sample speech as it occurs underreal conditions.
What people say to one another is very dif-ferent from the edited prose found in books or newspapers.Here again, as recognition vocabularies get bigger, increas-ingly large corpora are needed in order to have adequatesamples of the spontaneous e of rare words.Still another reason is that corpora are needed to test claimsthat are made for natural anguage processing systems.
Itdoesn't matter whether a system is developed with hiddenMarkov models or with augmented transition etworks; inorder to test it, you need a representative corpus that hasbeen processed in advance by human language users.Recent approaches to the evaluation of speech systems, andthe results of the 1993 benchmark tests of spoken languagesystems are described.Finally, although language technologists have little to sayabout it, another good reason to compile corpora is that thematerial merits preservation and study in its own right.Humanistic scholars are busily at work collecting localdialects or machine-readable text for their own purposes.
Itis probably the humanistic background of publishers thatleads them to think that their machine-readable t xt hassome intrinsic value, thus causing us legal problems whenwe try to get permission to use it.There are, in short, many reasons to make lexicons and cor-pora readily available to the research community.
This ses-sion, however, is not concerned to defend their usefulness,but rather to make sure that everyone knows what is avail-able and how to get iLUnfortunately, the amount and variety of work presented inthis initial session left no time for the group discussion thatsuch important topics merit.7
