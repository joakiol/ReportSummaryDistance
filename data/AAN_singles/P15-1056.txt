Proceedings of the 53rd Annual Meeting of the Association for Computational Linguisticsand the 7th International Joint Conference on Natural Language Processing, pages 575?585,Beijing, China, July 26-31, 2015.c?2015 Association for Computational LinguisticsBring you to the past: Automatic Generation of Topically Relevant EventChroniclesTao Ge1,2, Wenzhe Pei1, Heng Ji3, Sujian Li1,2, Baobao Chang1,2, Zhifang Sui1,21Key Laboratory of Computational Linguistics, Ministry of Education,School of EECS, Peking University, Beijing, 100871, China2Collaborative Innovation Center for Language Ability, Xuzhou, Jiangsu, 221009, China3Computer Science Department, Rensselaer Polytechnic Institute, Troy, NY 12180, USAgetao@pku.edu.cn, wenzhepei@pku.edu.cn, jih@rpi.edu,lisujian@pku.edu.cn, chbb@pku.edu.cn, szf@pku.edu.cnAbstractAn event chronicle provides people withan easy and fast access to learn the past.In this paper, we propose the first novelapproach to automatically generate a top-ically relevant event chronicle during acertain period given a reference chronicleduring another period.
Our approach con-sists of two core components ?
a time-aware hierarchical Bayesian model forevent detection, and a learning-to-rankmodel to select the salient events to con-struct the final chronicle.
Experimental re-sults demonstrate our approach is promis-ing to tackle this new problem.1 IntroductionHuman civilization has developed for thousands ofyears.
During the long period, history witnessedthe changes of societies and dynasties, the revo-lution of science and technology, as well as theemergency of celebrities, which are great wealthfor later generations.
Even nowadays, people usu-ally look back through history either for their workor interests.
Among various ways to learn history,many people prefer reading an event chroniclesummarizing important events in the past, whichsaves much time and efforts.The left part of Figure 1 shows a disaster eventchronicle from Infoplease1, by which people caneasily learn important disaster events in 2009.
Un-fortunately, almost all the available event chron-icles are created and edited manually, which re-quires editors to learn everything that happened inthe past.
Even if an editor tries her best to gener-ate an event chronicle, she still cannot guaranteethat all the important events are included.
More-over, when new events happen in the future, she1http://www.infoplease.com/world/disasters/2009.htmlneeds to update the chronicle in time, which islaborious.
For example, the event chronicle of2010 in Wikipedia2has been edited 8,488 timesby 3,211 distinct editors since this page was cre-ated.
In addition, event chronicles can vary ac-cording to topic preferences.
Some event chroni-cles are mainly about disasters while others mayfocus more on sports.
For people interested insports, the event chronicle in Figure 1 is unde-sirable.
Due to the diversity of event chronicles,it is common that an event chronicle regarding aspecific topic for some certain period is unavail-able.
If editing an event chronicle can be done bycomputers, people can have an overview of any pe-riod according to their interests and do not have towait for human editing, which will largely speedup knowledge acquisition and popularization.Based on this motivation, we propose a new taskof automatic event chronicle generation, whosegoal is to generate a topically relevant event chron-icle for some period based on a reference chroni-cle of another period.
For example, if an disasterevent chronicle during 2009 is available, we canuse it to generate a disaster chronicle during 2010from a news collection, as shown in Figure 1.To achieve this goal, we need to know whatevents happened during the target period, whetherthese events are topically relevant to the chron-icle, and whether they are important enough tobe included, since an event chronicle has only alimited number of entries.
To tackle these chal-lenges, we propose an approach consisting of twocore components ?
an event detection componentbased on a novel time-aware hierarchical Bayesianmodel and a learning-to-rank component to selectthe salient events to construct the final chronicle.Our event detection model can not only learn topicpreferences of the reference chronicle and mea-sure topical relevance of an event to the chronicle2http://en.wikipedia.org/wiki/2010575Figure 1: Example for automatic generation of a topically relevant event chronicle.but also can effectively distinguish similar eventsby taking into account time information and event-specific details.
Experimental results show our ap-proach significantly outperforms baseline methodsand that is promising to tackle this new problem.The major novel contributions of this paper are:?
We propose a new task automatic generationof a topically relevant event chronicle, whichis meaningful and has never been studied tothe best of our knowledge.?
We design a general approach to tacklethis new problem, which is language-independent, domain-independent and scal-able to any arbitrary topics.?
We design a novel event detection model.
Itoutperforms the state-of-the-art event detec-tion model for generating topically relevantevent chronicles.2 Terminology and Task OverviewFigure 2: An example of relevance-topic-event hi-erarchical structure for a disaster event chronicle.As shown in Figure 1, an event (entry) in anevent chronicle corresponds to a specific occur-rence in the real world, whose granularity dependson the chronicle.
For a sports chronicle, an evententry may be a match in 2010 World Cup, whilefor a comprehensive chronicle, the World Cup isregarded as one event.
In general, an event can berepresented by a cluster of documents related toit.
The topic of an event can be considered as theevent class.
For example, we can call the topic ofMH17 crash as air crash (fine-grained) or disaster(coarse-grained).
The relation between topic andevent is shown through the example in Figure 2.An event chronicle is a set of important eventsoccurring in the past.
Event chronicles vary ac-cording to topic preferences.
For the disasterchronicle shown in Figure 1, earthquakes and aircrashes are relevant topics while election is not.Hence, we can use a hierarchical structure to orga-nize documents in a corpus, as Figure 2 shows.Formally, we define an event chronicle E ={e1, e2, ..., en} where eiis an event entry inE and it can be represented by a tuple ei=?Dei, tei, zei?.
Deidenotes the set of documentsabout ei, teiis ei?s time and zeiis ei?s topic.
Spe-cially, we use ?
to denote the time period (inter-val) covered by E, and ?
to denote the topic distri-bution of E, which reflects E?s topic preferences.As shown in Figure 1, the goal of our task is togenerate an (target) event chronicle ETduring ?Tbased on a reference chronicle ERduring ?R.
Thetopic distributions of ETand ER(i.e., ?Tand ?R)should be consistent.3 Event Detection3.1 Challenges of Event DetectionFigure 3: Documents that are lexically similar butrefer to different events.
The underlined words areevent-specific words.576For our task, the first step is to detect topicallyrelevant events from a corpus.
A good event de-tection model should be able to(1) measure the topical relevance of a detectedevent to the reference chronicle.
(2) consider document time information.
(3) look into a document?s event-specific details.The first requirement is to identify topically rele-vant events since we want to generate a topicallyrelevant chronicle.
The second and third require-ments are for effectively distinguishing events, es-pecially similar events like the example in Figure3.
To distinguish the similar events, we must con-sider document time information (for distinguish-ing events in d1and d2) and look into the docu-ment?s event-specific details (the underlined wordsin Figure 3) (for distinguishing events in d1andd3).3.2 TaHBM: A Time-aware HierarchicalBayesian ModelTo tackle all the above challenges mentioned inSection 3.1, which cannot be tackled by conven-tional detection methods (e.g., agglomerative clus-tering), we propose a Time-aware HierarchicalBayesian Model (TaHBM) for detecting events.Model OverviewFigure 4: The plate diagram of TaHBM.
Theshaded nodes are observable nodes.The plate diagram and generative story ofTaHBM are depicted in Figure 4 and Figure 5respectively.
For a corpus with M documents,TaHBM assumes each document has three labels ?s, z, and e. s is a binary variable indicating a doc-ument?s topical relevance to the reference eventchronicle, whose distribution is a Bernoulli dis-tribution pisdrawn from a Beta distribution withDraw pis?
Beta(?s)For each s ?
{0, 1}: draw ?(s)?
Dir(?
)For each z = 1, 2, 3, ...,K: draw ?(z)?Dir(?
), ?(z)z?
Dir(?z)For each e = 1, 2, 3, ..., E: draw ?
(e)e?Dir(?e)For each document m = 1, 2, 3, ...,M :Draw s ?
Bernoulli(pis)Draw z ?Multi(?
(s))Draw e ?Multi(?
(z))Draw t??
Gaussian(?e, ?e), t?
bt?cDraw pix?
Beta(?x)For each word w in document m:Draw x ?
Bernoulli(pix)If x = 0: draw w ?
?
(z)zElse: draw w ?
?
(e)eFigure 5: The generative story of TaHBMsymmetric hyperparameter ?s.
s=1 indicates thedocument is topically relevant to the chroniclewhile s=0 means not.
z is a document?s topic labeldrawn from a K-dimensional multinomial distri-bution ?, and e is a document?s event label drawnfrom an E-dimensional multinomial distribution?.
?
and ?
are drawn from Dirichlet distributionswith symmetric hyperparameter ?
and ?
respec-tively.
For an event e?, it can be represented by aset of documents whose event label is e?.In TaHBM, the relations among s, z and e aresimilar to the hierarchical structure in Figure 2.Based on the dependencies among s, z and e, wecan compute the topical relevance of an event tothe reference chronicle by Eq (1) where P (e|z),P (e), P (s) and P (z|s) can be estimated usingBayesian inference (some details of estimation ofP (s) and P (s|z) will be discussed in Section 3.3)and thus we solve the first challenge in Section 3.1(i.e., topical relevance measure problem).P (s|e) =P (s)?
P (z|s)?
P (e|z)P (e)(1)Now, we introduce how to tackle the secondchallenge ?
how to take into account a document?stime information for distinguishing events.
InTaHBM, we introduce t, document timestamps.We assume t = bt?c where t?is drawn from aGaussian distribution with mean ?
and variance?2.
Each event e corresponds to a specific Gaus-sian distribution which serves as a temporal con-577straint for e. A Gaussian distribution has only onepeak around where the probability is concentrated.Its value trends to zero if a point lies far awayfrom the mean.
For this reason, a Gaussian dis-tribution is suitable to describe an event?s tempo-ral distribution whose probability usually concen-trates around the event?s burst time and it will beclose to zero if time lies far from the burst time.Figure 6 shows the temporal distribution of theJuly 2009 Urumqi riots3.
The probability of thisevent concentrates around the 7th day.
If we use aGaussian distribution (the dashed curve in Figure6) to constrain this event?s time scope, the doc-uments whose timestamps are beyond this scopeare unlikely to be grouped into this event?s cluster.Now that the problems of topical relevancemeasure and temporal constraints have beensolved, we discuss how to identify event-specificdetails of a document for distinguishing events.By analyzing the documents shown in Figure 3,we find that general words (e.g., earthquake, kill,injury, devastate) indicate the document?s topicwhile words about event-specific details (e.g.,Napa, California, 3.4-magnitude) are helpful todetermine what events the document talks about.Assuming a person is asked to analyze what eventa document discusses, it would be a natural wayto first determine topic of the document based itsgeneral words, and then determine what event ittalks about given its topic, timestamp and event-specific details, which is exactly the way ourTaHBM works.For simplicity, we call the general words astopic words and call the words describing event-specific information as event words.
Inspired bythe idea of Chemudugunta et al (2007), given thedifferent roles these two kinds of words play, weassume words in a document are generated by twodistributions: topic words are generated by a topicword distribution ?zwhile event words are gen-erated by an event word distribution ?e.
?zand?eare |V |-dimensional multinomial distributionsdrawn from Dirichlet distributions with symmetrichyperparameter ?zand ?erespectively, where |V |denotes the size of vocabulary V .
A binary indica-tor x, which is generated by a Bernoulli distribu-tion pixdrawn from a Beta distribution with sym-metric hyperparameter ?x, determines whether aword is generated by ?zor ?e.
Specifically, ifx = 0, a word is drawn from ?z; otherwise the3http://en.wikipedia.org/wiki/July 2009 Urumqi riotsFigure 6: The temporal distribution of documentsabout the Urumqi riots, which can be described bya Gaussian distribution (the dashed curve).
Thehorizontal axis is time (day) and the vertical axisis the number of documents about this event.word is drawn from ?e.
Since ?zis shared by allevents of one topic, it can be seen as a backgroundword distribution which captures general aspects.In contrast, ?etends to describe the event-specificaspects.
In this way, we can model a document?sgeneral and specific aspects and use the informa-tion to better distinguish similar events4.Model InferenceLike most Bayesian models, we use collapsedGibbs sampling for model inference in TaHBM.For a document m, we present the conditionalprobability of its latent variables s, z and x forsampling:P (sm|~s?m, ~z, ?s, ?)
=cs+ ?s?s(cs+ ?s)?cs,zm+ ?
?z(cs,z+ ?
)(2)P (zm|~z?m, ~e, ~s, ~wm, ~xm, ?, ?, ?z)=csm,z+ ?
?z(csm,z+ ?
)?cz,em+ ?
?e(cz,e+ ?
)?Nm?n=1(cz,wm,n+?n?1i=11(wm,i= wm,n) + ?z?w?V(cz,w+ ?z) + n?
1)(1?xm,n)(3)P (xm,n|~wm, ~x?m,n, zm, em, ?x)=cm,x+ ?xNm+ 2?x?
(czm,wm,n+ ?z?w?V(czm,w+ ?z))(1?x)?
(cem,wm,n+ ?e?w?V(cem,w+ ?e))x(4)where V denotes the vocabulary, wm,nis the nthword in a document m, csis the count of docu-ments with topic relevance label s, cs,zis the count4TaHBM is language-independent, which can identifyevent words without name tagging.
But if name tagging re-sults are available, we can also exploit them (e.g., we can fix xof a named entity specific to an event to 1 during inference.
).578of documents with topic relevance label s andtopic label z, cz,wis the count of word w whosedocument?s topic label is z, cm,xis the count ofwords with binary indicator label x in m and 1(?
)is an indicator function.Specially, for variable e which is dependent onthe Gaussian distribution, its conditional probabil-ity for sampling is computed as Eq (5):P (em|~e?m, ~z, ~wm, ~xm, tm, ?, ?e, ?e, ?e)=czm,e+ ?
?e(czm,e+ ?)?
?tm+1tmpG(tm;?e, ?
?e)?Nm?n=1(ce,wm,n+?n?1i=11(wm,i= wm,n) + ?e?w?V(ce,w+ ?e) + n?
1)xm,n(5)where pG(x;?, ?)
is a Gaussian probability massfunction with parameter ?
and ?.The function pG(?)
can be seen as the temporaldistribution of an event, as discussed before.
Inthis sense, the temporal distribution of the wholecorpus can be considered as a mixture of Gaussiandistributions of events.
As a natural way to esti-mate parameters of mixture of Gaussians, we useEM algorithm (Bilmes, 1998).
In fact, Eq (5) canbe seen as the E-step.
The M-step of EM updates?
and ?
as follows:?e=?d?Detd|De|, ?e=??d?De(td?
?e)2|De|(6)where tdis document d?s timestamp and Deis theset of documents with event label e.Specially, for sampling e we use ?
?edefined as?
?e= ?e+ ?
(?
is a small number for smoothing5)because when ?
is very small (e.g., ?
= 0), anevent?s temporal scope will be strictly constrained.Using ?
?ecan help the model overcome this ?trap?for better parameter estimation.Above all, the model inference and parameterestimation procedure can be summarized by algo-rithm 1.3.3 Learn Topic Preferences of the EventChronicleA prerequisite to use Eq (1) to compute an event?stopical relevance to an event chronicle is thatwe know P (s) and P (z|s) which reflects topicpreferences of the event chronicle.
Nonetheless,P (s) and P (z|s) vary according to different eventchronicles.
Hence, we cannot directly estimate5?
is set to 0.5 in our experiments.Algorithm 1 Model inference for TaHBM1: Initialize parameters in TaHBM;2: for each iteration do3: for each document d in the corpus do4: sample s according to Eq (2)5: sample z according to Eq (3)6: sample e according to Eq (5)7: for each word w in d do8: sample x according to Eq (4)9: end for10: end for11: for each event e do12: update ?e, ?eaccording to Eq (6)13: end for14: end forthem in an unsupervised manner; instead, we pro-vide TaHBM some ?supervision?.
As we men-tioned in section 3.2, the variable s indicates adocument?s topical relevance to the event chron-icle.
For some documents, s label can be easilyderived with high accuracy so that we can exploitthe information to learn the topic preferences.To obtain the labeled data, we use the descrip-tion of each event entry in the reference chroni-cle ERduring period ?Ras a query to retrieverelevant documents in the corpus using Lucene(Jakarta, 2004) which is an information retrievalsoftware library.
We define R as the set of doc-uments in hits of any event entry in the referencechronicle returned by Lucene:R = ?e?ERHit(e)where Hit(e) is the complete hit list of event e re-turned by Lucene.
For document dwith timestamptd, if d /?
R and td?
?R, then d is considered ir-relevant to the event chronicle and thus it would belabeled as a negative example.To generate positive examples, we use a strictcriterion since we cannot guarantee that all thedocuments in R are actually relevant.
To pre-cisely generate positive examples, a document d islabeled as positive only if it satisfies the positivecondition which is defined as follows:?e?ER0 ?
td?
te?
10 ?
sim(d, e) ?
0.4where teis time6of event e, provided by the ref-erence chronicle.
sim(d, e) is Lucene?s score ofd given query e. According to the positive con-dition, a positive document example must be lexi-6The time unit of tdand teis one day.579cally similar to some event in the reference chron-icle and its timestamp is close to the event?s time.As a result, we can use the labeled data to learntopic preferences of the event chronicle.
For thelabeled documents, s is fixed during model infer-ence.
In contrast, for documents that are not la-beled, s is sampled by Eq (2).
In this manner,TaHBM can learn topic preferences (i.e., P (z|s))without any manually labeled data and thus canmeasure the topical relevance between an eventand the reference chronicle.4 Event RankingGenerating an event chronicle is beyond event de-tection because we cannot use all detected eventsto generate the chronicle with a limited number ofentries.
We propose to use learning-to-rank tech-niques to select the most salient events to generatethe final chronicle since we believe the referenceevent chronicle can teach us the principles of se-lecting salient events.
Specifically, we use SVM-Rank (Joachims, 2006).4.1 Training and Test Set GenerationThe event detection component returns many doc-ument clusters, each of which represents an event.As Section 3.2 shows, each event has a Gaussiandistribution whose mean indicates its burst time inTaHBM.
We use the events whose burst time isduring the reference chronicle?s period as trainingexamples and treat those during the target chroni-cle?s period as test examples.
Formally, the train-ing set and test set are defined as follows:Train = {e|?e?
?R}, Test = {e|?e?
?T}In the training set, events containing at least onepositive document (i.e.
relevant to the event chron-icle) in Section 3.3 are labeled as high rank pri-ority while those without positive documents arelabeled as low priority.4.2 FeaturesWe use the following features to train the rankingmodel, all of which can be provided by TaHBM.?
P (s = 1|e): the probability that an event e istopically relevant to the reference chronicle.?
P (e|z): the probability reflects an event?s im-pact given its topic.?
?e: the parameter of an event e?s Gaussiandistribution.
It determines the ?bandwidth?of the Gaussian distribution and thus can beconsidered as the time span of e.?
|De|: the number of documents related toevent e, reflecting the impact of e.?|De|?e: For an event with a long time span (e.g.,Premier League), the number of relevant doc-uments is large but its impact may not be pro-found.
Hence, we use|De|?eto normalize |De|,which may better reflect the impact of e.5 Experiments5.1 Experiment SettingData: We use various event chronicles during2009 as references to generate their counterpartsduring 2010.
Specifically, we collected disaster,sports, war, politics and comprehensive chroni-cles during 2009 from mapreport7, infoplease andWikipedia8.
To generate chronicles during 2010,we use 2009-2010 APW and Xinhua news in En-glish Gigaword (Graff et al, 2003) and removedocuments whose titles and first paragraphs do notinclude any burst words.
We detect burst words us-ing Kleinberg algorithm (Kleinberg, 2003), whichis a 2-state finite automaton model and widelyused to detect bursts.
In total, there are 140,557documents in the corpus.Preprocessing: We remove stopwords and useStanford CoreNLP (Manning et al, 2014) to dolemmatization.Parameter setting: For TaHBM, we empiricallyset ?
= 0.05, ?z= 0.005, ?e= 0.0001, ?s=0.05, ?x= 0.5, ?
= 0.01, the number of topicsK = 50, and the number of events E = 5000.
Werun Gibbs sampler for 2000 iterations with burn-inperiod of 500 for inference.
For event ranking, weset regularization parameter of SVMRank c = 0.1.Chronicle display: We use a heuristic way togenerate the description of each event.
Since thefirst paragraph of a news article is usually a goodsummary of the article and the earliest documentin a cluster usually explicitly describes the event,for an event represented by a document cluster,we choose the first paragraph of the earliest doc-ument written in 2010 in the cluster to generatethe event?s description.
The earliest document?stimestamp is considered as the event?s time.7http://www.mapreport.com8http://en.wikipedia.org/wiki/20095805.2 Evaluation Methods and BaselinesSince there is no existing evaluation metric for thenew task, we design a method for evaluation.Although there are manually edited eventchronicles on the web, which may serve as ref-erences for evaluation, they are often incomplete.For example, the 2010 politics event chronicle onWikipedia has only two event entries.
Hence, wefirst pool all event entries of existing chronicles onthe web and chronicles generated by approachesevaluated in this paper and then have 3 humanassessors judge each event entry for generating aground truth based on its topical relevance, impactand description according to the standard of thereference chronicles.
An event entry will be in-cluded in the ground-truth only if it is selected asa candidate by at least two human judges.
On aver-age, the existing event chronicles on the web cover50.3% of event entries in the ground-truth.Given the ground truth, we can use Precision@kto evaluate an event chronicle?s quality.Precision@k = |EG?
Etopk|/kwhere EGand Etopkare ground-truth chronicleand the chronicle with top k entries generated byan approach respectively.
If there are multipleevent entries corresponding to one event in theground-truth, only one is counted.For comparison, we choose several baseline ap-proaches.
Note that event detection models exceptTaHBM do not provide features used in learning-to-rank model.
For these detection models, we usea criterion that considers both relevance and im-portance to rank events:rankscorebasic(e) =?d?Demaxe?
?ERsim(d, e?
)whereERis the reference chronicle and sim(d, e?
)is Lucene?s score of document d given query e?.We call this ranking criterion as basic criterion.?
Random: We randomly select k documentsto generate the chronicle.?
NB+basic: Since TaHBM is essentially anextension of NB, we use Naive Bayes (NB)to detect events and basic ranking criterion torank events.?
B-HAC+basic: We use hierarchical agglom-erative clustering (HAC) based on BurstVSMschema (Zhao et al, 2012) to detect events,which is the state-of-the-art event detectionmethod for general domains.?
TaHBM+basic: we use this baseline to verifythe effectiveness of learning-to-rank.As TaHBM, the number of clusters in NB is set to5000 for comparison.
For B-HAC, we adopt thesame setting with (Zhao et al, 2012).5.3 Experiment ResultsUsing the evaluation method introduced above,we can conduct a quantitative evaluation for eventchronicle generation approaches9.Table 1 shows the overall performance.
Ourapproach outperforms the baselines for all chron-icles.
TaHBM beats other detection models forchronicle generation owing to its ability of incor-porating the temporal information and identifica-tion of event-specific details of a document.
More-over, learning-to-ranking is proven more effectiveto rank events than the basic ranking criterion.Among these 5 chronicles, almost all ap-proaches perform best on disaster event chroniclewhile worst on sports event chronicle.
We ana-lyzed the results and found that many event entriesin the sports event chronicle are about the open-ing match, or the first-round match of a tourna-ment due to the display method described in Sec-tion 5.1.
According to the reference sport eventchronicle, however, only matches after quarterfi-nals in a tournament are qualified to be event en-tries.
In other words, a sports chronicle shouldprovide information about the results of semi-finaland final, and the champion of the tournament in-stead of the first-round match?s result, which ac-counts for the poor performance.
In contrast, theearliest document about a disaster event always di-rectly describes the disaster event while the fol-lowing reports usually concern responses to theevent such as humanitarian aids and condolencefrom the world leaders.
The patterns of reportingwar events are similar to those of disasters, thusthe quality of war chronicle is also good.
Pol-itics is somewhat complex because some politi-cal events (e.g., election) are arranged in advancewhile others (e.g., government shutdown) are un-expected.
It is notable that for generating com-prehensive event chronicles, learning-to-rank does9Due to the space limitation, we display chronicles gener-ated by our approach in the supplementary notes.581sports politics disaster war comprehensiveP@50 P@100 P@50 P@100 P@50 P@100 P@50 P@100 P@50 P@100Random 0.02 0.08 0 0 0.02 0.04 0 0 0.02 0.03NB+basic 0.08 0.12 0.18 0.19 0.42 0.36 0.18 0.17 0.38 0.31B-HAC+basic 0.10 0.13 0.30 0.26 0.50 0.47 0.30 0.22 0.36 0.32TaHBM+basic 0.18 0.15 0.30 0.29 0.50 0.43 0.46 0.36 0.38 0.33Our approach 0.20 0.15 0.38 0.36 0.64 0.53 0.54 0.41 0.40 0.33Table 1: Performance of event chronicle generation.Topically Irrelevant Trivial Events Indirect Description Redundant Entriesdisaster 31.91% 17.02% 44.68% 6.38%sports 38.82% 55.29% 3.52% 2.35%comp - 67.16% 31.34% 1.49%Table 2: Proportion of errors in disaster, sports and comprehensive event chronicles.not show significant improvement.
A possible rea-son is that a comprehensive event chronicle doesnot care the topical relevance of a event.
In otherwords, its ranking problem is simpler so that thelearning-to-rank does not improve the basic rank-ing criterion much.Moreover, we analyze the incorrect entries inthe chronicles generated by our approaches.
Ingeneral, there are four types of errors.Topically irrelevant: the topic of an event entryis irrelevant to the event chronicle.Minor events: the event is not important enoughto be included.
For example, ?20100828:Lebanon beat Canada 81-71 in the opening roundof the basketball world championships?
is a minorevent in the sports chronicle because it is about anopening-round match and not important enough.Indirect description: the entry does not describea major event directly.
For instance, ?20100114:Turkey expressed sorrow over the Haiti earth-quake?
is an incorrect entry in the disaster chroni-cle though it mentions the Haiti earthquake.Redundant entries: multiple event entries de-scribe the same event.We analyze the errors of the disaster, sports andcomprehensive event chronicle since they are rep-resentative, as shown in Table 2.Topical irrelevance is a major error source forboth disaster and sports event chronicles.
Thisproblem mainly arises from incorrect identifica-tion of topically relevant events during detection.Moreover, disaster and sports chronicles have theirown more serious problems.
Disaster event chron-icles suffer from the indirect description problemsince there are many responses (e.g., humanitar-ian aids) to a disaster.
These responses are top-ically relevant and contain many documents, andthus appear in the top list.
One possible solutionmight be to increase the event granularity by ad-justing parameters of the detection model so thatthe documents describing a major event and thosediscussing in response to this event can be groupedinto one cluster (i.e., one event).
In contrast, thesports event chronicle?s biggest problem is on mi-nor events, as mentioned before.
Like the sportschronicle, the comprehensive event chronicle alsohas many minor event entries but its main prob-lem results from its strict criterion.
Since com-prehensive chronicles can include events of anytopic, only extremely important events can be in-cluded.
For example, ?Netherlands beat Uruguayto reach final in the World Cup 2010?
may be acorrect event entry in sports chronicles but it is nota good entry in comprehensive chronicles.
Com-pared with comprehensive event chronicles, eventsin other chronicles tend to describe more details.For example, a sports chronicle may regard eachmatch in the World Cup as an event while compre-hensive chronicles consider the World Cup as oneevent, which requires us to adapt event granularityfor different chronicles.Also, we evaluate the time of event entries inthese five event chronicles because event?s hap-pening time is not always equal to the timestampof the document creation time (UzZaman et al,2012; Ge et al, 2013).
We collect existing man-ually edited 2010 chronicles on the web and usetheir event time as gold standard.
We define ametric to evaluate if the event entry?s time in ourchronicle is accurate:diff =?e?E?E?|(te?
t?e)|/|E ?
E?|where E and E?are our chronicle and the manu-ally edited event chronicle respectively.
teis e?s582time labeled by our method and t?eis e?s correcttime.
Note that for multiple entries referring thesame event in event chronicles, the earliest entry?stime is used as the event?s time to compute diff.sports politics disaster war comprehensive0.800 3.363 1.042 1.610 2.467Table 3: Difference between an event?s actual timeand the time in our chronicles.
Time unit is a day.Table 3 shows the performance of our approachin labeling event time.
For disaster, sports and war,the accuracy is desirable since important eventsabout these topics are usually reported in time.In contrast, the accuracy of political event timeis the lowest.
The reason is that some politicalevents may be confidential and thus they are notreported as soon as they happen; on the other hand,some political events (e.g., a summit) are reportedseveral days before the events happen.
The com-prehensive event chronicle includes many politicalevents, which results in a lower accuracy.6 Related WorkTo the best of our knowledge, there was no previ-ous end-to-end topically relevant event chroniclegeneration work but there are some related tasks.Event detection, sometimes called topic detec-tion (Allan, 2002), is an important part of our ap-proach.
Yang et al (1998) used clustering tech-niques for event detection on news.
He et al(2007) and Zhao et al (2012) designed burst fea-ture representations for detecting bursty events.Compared with our TaHBM, these methods lackthe ability of distinguishing similar events.Similar to event detection, event extraction fo-cuses on finding events from documents.
Mostwork regarding event extraction (Grishman et al,2005; Ahn, 2006; Ji and Grishman, 2008; Chenand Ji, 2009; Liao and Grishman, 2010; Hong etal., 2011; Li et al, 2012; Chen and Ng, 2012; Li etal., 2013) was developed under Automatic ContentExtraction (ACE) program.
The task only defines33 event types and events are in much finer grainthan those in our task.
Moreover, there was work(Verhagen et al, 2005; Chambers and Jurafsky,2008; Bethard, 2013; Chambers, 2013; Chamberset al, 2014) about temporal event extraction andtracking.
Like ACE, the granularity of events inthis task is too fine to be suitable for our task.Also, timeline generation is related to our work.Most previous work focused on generating a time-line for a document (Do et al, 2012), a centroidentity (Ji et al, 2009) or one major event (Hu etal., 2011; Yan et al, 2011; Lin et al, 2012; Li andLi, 2013).
In addition, Li and Cardie (2014) gen-erated timelines for users in microblogs.
The mostrelated work to ours is Swan and Allan (2000).They used a timeline to show bursty events alongthe time, which can be seen as an early form ofevent chronicles.
Different from their work, wegenerate a topically relevant event chronicle basedon a reference event chronicle.7 Conclusions and Future WorkIn this paper, we propose a novel task ?
automaticgeneration of topically relevant event chronicles.It can serve as a new framework to combine themerits of Information Retrieval, Information Ex-traction and Summarization techniques, to rapidlyextract and rank salient events.
This framework isalso able to rapidly and accurately capture a user?sinterest and needs based on the reference chronicle(instead of keywords as in Information Retrievalor event templates as in Guided Summarization)which can reflect diverse levels of granularity.As a preliminary study of this new challenge,this paper focuses on event detection and rank-ing.
There are still many challenges for gener-ating high-quality event chronicles.
In the fu-ture, we plan to investigate automatically adapt-ing an event?s granularity and learn the principleof summarizing the event according to the refer-ence event chronicle.
Moreover, we plan to studythe generation of entity-driven event chronicles,leveraging more fine-grained entity and event ex-traction approaches.AcknowledgmentsWe thank the anonymous reviewers for theirthought-provoking comments.
This work is sup-ported by National Key Basic Research Pro-gram of China 2014CB340504, NSFC project61375074, China Scholarship Council (CSC, No.201406010174) and USA ARL NS-CTA No.W911NF-09-2-0053.
The contact author of thispaper is Zhifang Sui.ReferencesDavid Ahn.
2006.
The stages of event extraction.
InWorkshop on Annotating and Reasoning about Timeand Events.583James Allan.
2002.
Topic detection and tracking:event-based information organization, volume 12.Springer Science & Business Media.Steven Bethard.
2013.
Cleartk-timeml: A minimalistapproach to tempeval 2013.
In Second Joint Confer-ence on Lexical and Computational Semantics.Jeff A Bilmes.
1998.
A gentle tutorial of the em algo-rithm and its application to parameter estimation forgaussian mixture and hidden markov models.
Inter-national Computer Science Institute, 4(510):126.Nathanael Chambers and Dan Jurafsky.
2008.
Jointlycombining implicit constraints improves temporalordering.
In EMNLP.Nathanael Chambers, Taylor Cassidy, Bill McDowell,and Steven Bethard.
2014.
Dense event orderingwith a multi-pass architecture.
TACL, 2:273?284.Nathanael Chambers.
2013.
Navytime: Event andtime ordering from raw text.
Technical report, DTICDocument.Chaitanya Chemudugunta and Padhraic Smyth MarkSteyvers.
2007.
Modeling general and specific as-pects of documents with a probabilistic topic model.In NIPS.Zheng Chen and Heng Ji.
2009.
Language specific is-sue and feature exploration in chinese event extrac-tion.
In NAACL.Chen Chen and Vincent Ng.
2012.
Joint modeling forchinese event extraction with rich linguistic features.In COLING.Quang Xuan Do, Wei Lu, and Dan Roth.
2012.Joint inference for event timeline construction.
InEMNLP.Tao Ge, Baobao Chang, Sujian Li, and Zhifang Sui.2013.
Event-based time label propagation for auto-matic dating of news articles.
In EMNLP.David Graff, Junbo Kong, Ke Chen, and KazuakiMaeda.
2003.
English gigaword.
Linguistic DataConsortium, Philadelphia.Ralph Grishman, David Westbrook, and Adam Meyers.2005.
Nyu?s english ace 2005 system description.In ACE 2005 Evaluation Workshop.Qi He, Kuiyu Chang, and Ee-Peng Lim.
2007.
Usingburstiness to improve clustering of topics in newsstreams.
In ICDM.Yu Hong, Jianfeng Zhang, Bin Ma, Jian-Min Yao,Guodong Zhou, and Qiaoming Zhu.
2011.
Usingcross-entity inference to improve event extraction.In ACL.Po Hu, Minlie Huang, Peng Xu, Weichang Li, Adam KUsadi, and Xiaoyan Zhu.
2011.
Generatingbreakpoint-based timeline overview for news topicretrospection.
In ICDM.Apache Jakarta.
2004.
Apache lucene-a high-performance, full-featured text search engine li-brary.Heng Ji and Ralph Grishman.
2008.
Refining event ex-traction through cross-document inference.
In ACL.Heng Ji, Ralph Grishman, Zheng Chen, and PrashantGupta.
2009.
Cross-document event extractionand tracking: Task, evaluation, techniques and chal-lenges.
In RANLP.Thorsten Joachims.
2006.
Training linear svms in lin-ear time.
In SIGKDD.Jon Kleinberg.
2003.
Bursty and hierarchical structurein streams.
Data Mining and Knowledge Discovery,7(4):373?397.Jiwei Li and Claire Cardie.
2014.
Timeline generation:Tracking individuals on twitter.
In WWW.Jiwei Li and Sujian Li.
2013.
Evolutionary hierarchi-cal dirichlet process for timeline summarization.
InACL.Peifeng Li, Guodong Zhou, Qiaoming Zhu, and LibinHou.
2012.
Employing compositional semanticsand discourse consistency in chinese event extrac-tion.
In EMNLP.Qi Li, Heng Ji, and Liang Huang.
2013.
Joint eventextraction via structured prediction with global fea-tures.
In ACL.Shasha Liao and Ralph Grishman.
2010.
Using doc-ument level cross-event inference to improve eventextraction.
In ACL.Chen Lin, Chun Lin, Jingxuan Li, Dingding Wang,Yang Chen, and Tao Li.
2012.
Generating eventstorylines from microblogs.
In CIKM.Christopher D Manning, Mihai Surdeanu, John Bauer,Jenny Finkel, Steven J Bethard, and David Mc-Closky.
2014.
The stanford corenlp natural lan-guage processing toolkit.
In ACL System Demon-strations.Russell Swan and James Allan.
2000.
Automatic gen-eration of overview timelines.
In SIGIR.Naushad UzZaman, Hector Llorens, James Allen, LeonDerczynski, Marc Verhagen, and James Pustejovsky.2012.
Tempeval-3: Evaluating events, time ex-pressions, and temporal relations.
arXiv preprintarXiv:1206.5333.Marc Verhagen, Inderjeet Mani, Roser Sauri, RobertKnippen, Seok Bae Jang, Jessica Littman, AnnaRumshisky, John Phillips, and James Pustejovsky.2005.
Automating temporal annotation with tarsqi.In ACL demo.Rui Yan, Xiaojun Wan, Jahna Otterbacher, Liang Kong,Xiaoming Li, and Yan Zhang.
2011.
Evolution-ary timeline summarization: a balanced optimiza-tion framework via iterative substitution.
In SIGIR.584Yiming Yang, Tom Pierce, and Jaime Carbonell.
1998.A study of retrospective and on-line event detection.In SIGIR.Wayne Xin Zhao, Rishan Chen, Kai Fan, Hongfei Yan,and Xiaoming Li.
2012.
A novel burst-based textrepresentation model for scalable event detection.
InACL.585
