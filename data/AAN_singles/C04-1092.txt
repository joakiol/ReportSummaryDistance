Automatic extraction of paraphrastic phrasesfrom medium size corporaThierry PoibeauLaboratoire d?Informatique de Paris-Nord ?
CNRS UMR 7030Av.
J.B. Cl?ment ?
F-93430 Villetaneusethierry.poibeau@lipn.univ-paris13.frAbstractThis paper presents a versatile systemintended to acquire paraphrastic phrasesfrom a representative corpus.
In order todecrease the time spent on the elaboration ofresources for NLP system (for exampleInformation Extraction, IE hereafter), wesuggest to use a knowledge acquisitionmodule that helps extracting newinformation despite linguistic variation(textual entailment).
This knowledge isautomatically derived from the textcollection, in interaction with a largesemantic network.1 IntroductionRecent researches in NLP have promoted anow widely-accepted shallow-based analysisframework that has proven to be efficient for anumber of tasks, including informationextraction and question answering.
However,this approach often leads to over-simplifiedsolutions to complex problems.
For example,the bag-of-words approach fails in examplessuch as: Lee Harvey Oswald, the gunman whoassassinated President John F. Kennedy, waslater shot and killed by Jack Ruby (exampletaken from Lin and Katz, 2003).
In this case, itis essential to keep track of the argumentstructure of the verb, to be able to infer that itis Jack Ruby and not John Kennedy who is themurderer of Lee Harvey Oswald.
A wrongresult would be obtained considering tooshallow analysis techniques or heuristics,based for example of the proximity betweentwo person names in the sentence.Several studies have recently proposedsome approaches based on the redundancy ofthe web to acquire extraction patterns andsemantic structures.
However, these methodscannot be applied to medium size corpora.Moreover, existing structured knowledgecontained in dictionaries, thesauri or semanticnetworks can boost the learning process byproviding clear intuition over text units.In this paper, we propose a knowledge richapproach to paraphrase acquisition.
We willfirstly describe some related work for theacquisition of knowledge, especiallyparaphrases, from texts.
We then describe howsemantic similarity between words can beinferred from large semantic networks.
Wepresent an acquisition process, in which thesemantic network is projected on the corpus toderive extraction patterns.
This mechanism canbe seen as a dynamic lexical tuning ofinformation contained in the semantic networkin order to generate paraphrases of an originalpattern.
In the last section, we propose anevaluation and some perspectives.2 Related workThis section presents some related worksfor the acquisition of extraction patterns andparaphrases from texts.2.1 IE and resource acquisitionIE is known to have established a nowwidely accepted linguistic architecture basedon cascading automata and domain-specificknowledge (Appelt et al 1993).
However,several studies have outlined the problem ofthe definition of the resources.
For example,E.
Riloff (1995) says that about 1500 hours arenecessary to define the resources for a textclassification system on terrorism1.
Most ofthese resources are variants of extractionpatterns, which have to be manuallyestablished.1We estimate that the development of resources forIE is at least as long as for text classification.To address this problem of portability, arecent research effort focused on usingmachine learning throughout the IE process(Muslea, 1999).
A first trend was to directlyapply machine learning methods to replace IEcomponents.
For example, statistical methodshave been successfully applied to the named-entity task.
Among others, (Bikel et a., 1997)learns names by using a variant of hiddenMarkov models.2.2 Extraction pattern learningAnother research area trying to avoid thetime-consuming task of elaborating IEresources is concerned with the generalizationof extraction patterns from examples.
(Muslea,1999) gives an extensive description of thedifferent approaches of that problem.
Autoslog(Riloff, 1993) was one of the very first systemsusing a simple form of learning to build adictionary of extraction patterns.
Ciravegna(2001) demonstrates the interest ofindependent acquisition of left and rightboundaries of extraction patterns during thelearning phase.
In general, the left part of apattern is easier to acquire than the right partand some heuristics can be applied to infer theright boundary from the left one.
The samemethod can be applied for argumentacquisition: each argument can be acquiredindependently from the others since theargument structure of a predicate in context israrely complete.Collins and Singer (1999) demonstrate howtwo classifiers operating on disjoint featuressets recognize named entities with very littlesupervision.
The method is interesting in thatthe analyst only needs to provide some seedexamples to the system in order to learnrelevant information.
However, theseclassifiers must be made interactive in ordernot to diverge from the expected result, sinceeach error is transmitted and amplified bysubsequent processing stages.
Contrary to thisapproach, partially reproduced by Duclaye etal.
(2003) for paraphrase learning, we prefer aslightly supervised method with clearinteraction steps with the analyst during theacquisition process, to ensure the solution isconverging.3 Overview of the approachArgument structure acquisition is acomplex task since the argument structure israrely complete.
To overcome this problem, wepropose an acquisition process in which all thearguments are acquired separately.Figure 1 presents an outline of the overallparaphrase acquisition strategy.
The process ismade of automatic steps and manual validationstages.
The process is weakly supervised sincethe analyst only has to provide one example tothe system.
However, we observed that thequality of the acquisition process highlydepends from this seed example, so thatseveral experiments has to be done for theacquisition of an argument structure, in orderto be sure to obtain an accurate coverage of adomain.From the seed pattern, a set of paraphrasesis automatically acquired, using similaritymeasures between words and a shallowsyntactic analysis of the found patterns, inorder to ensure they describe a predicativesequence.
All these stages are described below,after the description of similarity measuresallowing to calculate the semantic proximitybetween words.Seed pattern selectionAutomatic stepParaphrase acquisitionSyntactic expansionSemantic expansionSemanticnetCorpusValidationFigure 1: Outline of the acquisition processEnd-user inputInteraction withthe end-user4 Similarity measuresSeveral studies have recently proposedmeasures to calculate the semantic proximitybetween words.
Different measures have beenproposed, which are not easy to evaluate (see(Lin and Pantel, 2002) for proposals).
Themethods proposed so far are automatic ormanual and generally imply the evaluation ofword clusters in different contexts (a wordcluster is close to another one if the words itcontains are interchangeable in some linguisticcontexts).Budanitsky and Hirst (2001) present theevaluation of 5 similarity measures based onthe structure of Wordnet.
All the algorithmsthey examine are based on the hypernym-hyponym relation which structures theclassification of clusters inside Wordnet (thesynsets).
They sometimes obtain unclearconclusions about the reason of theperformances of the different algorithms (forexample, comparing Jiang and Conrath?smeasure (1997) with Lin?s one (1998): ?Itremains unclear, however, just why itperformed so much better than Lin?s measure,which is but a different arithmetic combinationof the same terms?).
However, the authorsemphases on the fact that the use of the solehyponym relation is insufficient to capture thecomplexity of meaning: ?Nonetheless, itremains a strong intuition that hyponymy isonly one part of semantic relatedness;meronymy, such as whee l?ca r, is mostdefinitely an indicator of semantic relatedness,and, a fortiori, semantic relatedness can arisefrom little more than common or stereotypicalassociations or statistical co-occurrence in reallife (for example, penguin?Antarc t i ca;birthday?candle; sleep?pajamas)?.In this paper, we propose to use thesemantic distance described in (Dutoit et al,2002) which is based on a knowledge-richsemantic net encoding a large variety ofsemantic relationships between set of words,including meronymy and stereotypicalassociations.The semantic distance between two words Aand B  is based on the notion of  nearestcommon ancestors (NCA) between A and B .NCA is defined as the set of nodes that aredaughters of c(A) ?
c(B) and that are notancestors in c(A) ?
c(B).
The activationmeasure d_is equal to the mean of the weightof each NCA calculated from A and  B?:d?
(A, B)=?=+n1iii ))NCA,B(d)NCA,A(d(n1Please, refer to  (Dutoit and Poibeau, 2002) formore details and examples.
However, thismeasure is sensitive enough to give valuableresults for a wide variety of applications,including text filtering and informationextraction (Poibeau et al, 2002).5 The acquisition processThe process begins as the end-user providesa predicative linguistic structure to the systemalong with a representative corpus.
The systemtries to discover relevant parts of text in thecorpus based on the presence of plain wordsclosely related to the ones of the seed pattern.A syntactic analysis of the sentence is thendone to verify that these plain wordscorrespond to a paraphrastic structure.
Themethod is close to the one of Morin andJacquemin (1999), who first try to locatecouples of relevant terms and then applyrelevant patterns to analyse the nature of theirrelationship.
However, Morin and Jacqueminonly focus on term variations whereas we areinterested in predicative structures, being eitherverbal or nominal.
The syntactic variations wehave to deal with are then different and, for apart, more complex than the ones examined byMorin and Jacquemin.The detail algorithm is described below:1.
The head noun of the example pattern iscompared with the head noun of thecandidate pattern using the proximitymeasure from (Dutoit et al, 2002).
Thisresult of the measure must be under athreshold fixed by the end-user.2.
The same condition must be filled by the?expansion?
element (possessive phraseor verb complement in the candidatepattern).3.
The structure must be predicative (eithera nominal or a verbal predicate, thealgorithm does not make any differenceat this level).The following schema (Figure 2) resumes theacquisition process.Figure 2: paraphrase acquisitionFinally, this process is formalized throughoutthe algorithm 1.
Note that the predicative formis acquired together with its arguments, as in aco-training process.P ?
pattern to be foundS ?
Sentence to analyzeC ?
Phrases(S)W ?
Plain_words(S)Result ?
empty listhead ?
Head word of the pattern Pexp ?
Expansion word of the pattern PThreshold ?
threshold fixed by theanalystFor every word wifrom W doProx1= d??
(head, wi)If (Prox1<= Threshold) thenwi+1?
Next element from W (if end ofsentence then exit)Prox2= d??
(exp, wi+1)If (Prox2<= Threshold) thenIf there is c ?
C so that (wi?
c) and(wi+1?
c) thenResult ?
Add (wi, wi+1)End_ifEnd_ifEnd_ifEnd_forAlgorithm 1?
: Paraphrastic phrasesacquisitionThe result of this analysis is a tablerepresenting predicative structures, which aresemantically equivalent to the initial examplepattern.
The process uses the corpus and thesemantic net as two different complementaryknowledge sources:?
The semantic net provides informationabout lexical semantics and relationsbetween words?
The corpus attests possible expressionsand filter irrelevant ones.We performed an evaluation on differentFrench corpora, given that the semantic net isespecially rich for this language.
We take theexpression cession de soci?t?
(companytransfer) as an initial pattern.
The system thendiscovered the following expressions, each ofthem being semantic paraphrases of the initialseed pattern:reprise des activit?srachat d?activit?acqu?rir des magasinsracheter *c-company*cession de *c-company*?The result must be manually validated.
Somestructures are found even if they are irrelevant,due to the activation of irrelevant links.
It is thecase of the expression renoncer ?
se porteracqu?reur (to give up buying sthg), which isnot relevant.
In this case, there was a spuriouslink between to give up and company in thesemantic net.5.1 Dealing with syntactic variationsThe previous step extract semanticallyrelated predicative structures from a corpus.These structures are found in the corpus invarious linguistic structures, but we want thesystem to be able to find this information evenif it appears in other kind of linguisticsequences.
That is the reason why we associatesome meta-graphs with the linguisticstructures, so that different transformations canbe recognized.
This strategy is based on Harristheory of sublanguages (1991).
Thesetransformations concern the syntactic level,either on the head (H) or on the expansion part(E) of the linguistic structure.SemanticlinkAcquisitionHeadCompanyExpEnterpriseFactoryHolding?AcquireBuySeizure?Predicative  linkSemanticlinkThe meta-graphs encode transformationsconcerning the following structures:?
Subject ?
verb,?
Verb ?
direct object,?
Verb ?
indirect object (especially whenintroduced by the French preposition ?or de),?
Noun ?
possessive phrase.These meta-graphs encode the major part ofthe linguistic structures we are concern with inthe process of IE.The graph on Figure 4 recognizes thefollowing sequences (in brackets we underlinethe couple of words previously extracted fromthe corpus):Reprise des activit?s charter?
(H:reprise, E: activit?
)Reprendre les activit?s charter?
(H: reprendre, E: activit?
)Reprise de l?ensemble des magasinssuisse?
(H: reprise, E: magasin)Reprendre l?ensemble des magasinssuisse?
(H: reprendre, E: magasin)Racheter les diff?rentes activit?s?
(H: racheter, E: activit?
)Rachat des diff?rentes activit?s?
(H: rachat, E: activit?
)This kind of graph is not easy to read.
Itincludes at the same time some linguistic tagsand some applicability constraints.
Forexample, the first box contains a reference tothe @A  column in the table of identifiedstructures.
This column contains a set of binaryconstraints, expressed by some signs +  or - .The sign + means that the identified pattern isof type verb-direct object: the graph can thenbe applied to deal with passive structures.
Inother words, the graph can only be applied in asign + appears in the @ A column of theconstraints table.
The constraints are removedfrom the instantiated graph.
Even if theresulting graph is normally not visible (thecompilation process directly produced a graphin a binary format), we give an image of a partof that graph on Figure 4.This mechanism using constraint tables andmeta-graph has been implemented in the finite-state toolbox INTEX (Silberztein, 1993).
26meta-graphs have been defined modelinglinguistic variation for the 4 predicativestructures defined above.
The phenomenamainly concern the insertion of modifiers (withthe noun or the verb), verbal transformations(passive) and phrasal structures (relativeclauses like ?Vivendi, qui a rachet?Universal?Vivendi, that bought Universal).The compilation of the set of meta-graphsproduces a graph made of 317 states and 526Figure 4: a syntactic meta-graphFigure 3: the linguistic constraint tablerelations.
These graphs are relatively abstractbut the end-user is not intended to directlymanipulate them.
They generate instantiatedgraphs, that is to say graphs in which theabstract variables have been replaced linguisticinformation as modeled in the constrainttables.
This method associates a couple ofelements with a set of transformation thatcovers more examples than the one of thetraining corpus.
This generalization process isclose to the one imagined by Morin andJacquemin (1999) for terminology analysis but,as we already said, we cover sequences that arenot only nominal ones.6 EvaluationThe evaluation concerned the extraction ofinformation from a French financial corpus,about companies buying other companies.
Thecorpus is made of 300 texts (200 texts for thetraining corpus, 100 texts for the test corpus).A system was first manually developed andevaluated.
We then tried to perform the sametask with automatically developed resources,so that a comparison is possible.
The corpus isfirstly normalized.
For example, all thecompany names are replaced by a variable *c-company* thanks to the named entityrecognizer.
In the semantic network, *c-company* is introduced as a synonym ofcompany, so that all the sequences with aproper name corresponding to a companycould be extracted.For the slot corresponding to the companythat is being bought, 6 seed example patternswere given to semantic expansion module.This module acquired from the corpus 25 newvalidated patterns.
Each example patterngenerated 4.16 new patterns on average.
Forexample, from the pattern rachat de*c-company* we obtain the following list:reprise de *c-company*achat de *c-company*acqu?rir *c-company*racheter *c-company*cession de *c-company*This set of paraphrastic patterns includesnominal phrases (reprise de *c-company*)and verbal phrases (racheter *c-company*).The acquisition process concerns at the sametime, the head and the expansion.
Thesimultaneous acquisition of different semanticclasses can also be found in the co-trainingalgorithm proposed for this kind of task by E.Riloff and R. Jones (Riloff et Jones, 1999).The proposed patterns must be filtered andvalidated by the end-user.
We estimate thatgenerally 25% of the acquired pattern shouldbe rejected.
However, this validation process isvery rapid: a few minutes only were necessaryto check the 31 proposed patterns and retain 25of them.We then compared these results with theones obtained with the manually elaboratedsystem.
The evaluation concerned the threeslots that necessitate a syntactic and semanticanalysis: the company that is buying anotherone (arg1) the company that is being bought(arg2), the company that sells (arg3).
Theseslots imply nominal phrases, they can becomplex and a functional analysis is most ofthe time necessary (is the nominal phrase thesubject or the direct object of the sentence?
).We thus chose to perform an operationalevaluation: what is evaluated is the ability of agiven phrase or pattern to fill a given slot (alsocalled textual entailment by Dagan andGlickman [2004]).
This kind of evaluationavoids, as far as possible, the bias of humanjudgment on possibly ambiguous expressions.An overview of the results is given below(P refers to precision, R to recall, F to theharmonic mean between P and R):Arg 1 Arg 2 Arg 3P: 100R: 90P: 100R: 91.6P: 99R: 92HumanannotatorsF: 94.7 F: 95.6 F: 94.2P: 79.6R: 62.6P: 93.4R: 73P: 88.4R: 70Automatically acquiredresourcesF: 70 F: 81.9 F: 77We observed that the system running withautomatically defined resources is about 10%less efficient than the one with manuallydefined resources.
The decrease ofperformance may vary in function of the slot(the decrease is less important for the arg2 thanfor arg1 or arg3).
Two kind of errors areobserved: Certain sequences are not foundbecause a relation between words is missing inthe semantic net.
Some sequences are extractedby the semantic analysis but do not correspondto a transformation registered in the syntacticvariation management module.7 ConclusionIn this paper, we have shown an efficientalgorithm to semi-automatically acquireparaphrastic phrases from a semantic net and acorpus.
We have shown that this approach ishighly relevant in the framework of IEsystems.
Even if the performance decreasewhen the resources are automatically defined,the gain in terms of development time issufficiently significant to ensure the usabilityof the method.8 ReferencesAppelt D.E, Hobbs J., Bear J., Israel D., KameyanaM.
and Tyson M. (1993) FASTUS: a finite-stateprocessor for information extraction from real-world text.
Proceedings of IJCAI?93, Chamb?ry,France, pp.
1172?1178.Bikel D., Miller S., Schwartz R. and Weischedel R.(1997) Nymble: a high performance learningname-finder.
Proceeding of the 5thANLPConference, Washington, USA.Budanitsky A. and Hirst G. (2001) Semanticdistance in WordNet: An experimental,application-oriented evaluation of five measures.Workshop on WordNet and Other LexicalResources, in NAACL 2001, Pittsburgh.Ciravegna F. (2001) Adaptive InformationExtraction from Text by Rule Induction andGeneralisation.
Proceedings of the 17thInternational Joint Conference on ArtificialIntelligence (IJCAI?2001), Seattle, pp.1251?1256.Collins M. and Singer Y.
(1999) Unsupervisedm o d e l s  for named entity classification.Proceedings of EMNLP-WVLC?99, CollegePark, pp.
100?110.Dagan I. and Glickman O.
(2004) ProbabilisticTextual Entailment: Generic Applied Modelingof Language Variability.
Workshop LearningMethods for Text Understanding and Mining.Grenoble, France.Duclaye F., Yvon F. and Collin O.
(2003) Learningparaphrases to improve a question answeringsystem.
Proceeding of the EACL Workshop?NLP for Question Answering?, Budapest,Hungary.Dutoit D. and Poibeau T. (2002) Derivingknowledge from a large semantic network,Proceedings of COLING?2002, Taipei, Taiwan,pp.
232?238.Fellbaum C. (1998) WordNet : An ElectronicLexical Database, edited by Fellbaum, MITpress.Grefenstette G. (1998) Evaluating the adequancy ofa multilingual transfer dictionary for the CrossLanguage Information Retrieval, LREC 1998.Harris Z.
(1991) A theory of language andinformation: a mathematical approach.
OxfordUniversity Press.
Oxford.Jiang J. and Conrath D. (1997) Semantic similaritybased on corpus statistics and lexical taxonomy.Proceedings of International Conference onResearch in Computational Linguistics, Taiwan.Jones R., McCallum A., Nigam K. and Riloff E.(1999) Bootstrapping for Text Learning Tasks.Proceedings of the IJCAI?99 Workshop on TextMining: Foundations, Techniques andApplications, Stockholm, 1999, pp.
52?63.Lin D. (1998) An information-theoretic definitionof similarity.
Proceedings of the 15th InternationalConference on Machine Learning, Madison, WI.Lin D. and Pantel P. (2002) Concept Discoveryfrom Text.
Proceedings of COLING?2002,Taipei, Taiwan, pp.
577?583.Lin J. and Katz B.
(2003) Q/A techniques forWWW.
Tutorial.
10thMeeting of the EuropeanAssociation for Computational Linguistics(EACL?03), Budapest, 2003.Morin E. and Jacquemin C. (1999) Projectingcorpus-based semantic links on a thesaurus.Proceedings of the 37th ACL, pp.
389?396.Muslea I.
(1999) Extraction patterns forInformation Extraction tasks: a survey, AAAI?99(avai lable  a t  the  fol lowing URL:http://www.isi.edu/~muslea/ RISE/ML4IE/)Pazienza M.T, ed.
(1997) Information extraction.Springer Verlag  (Lecture Notes in computerScience), Heidelberg, Germany.Poibeau T.,?Dutoit D., Bizouard S.?
(2002)Evaluating resource acquisition tools forInformation Extraction.
Proceeding of theInternational Language Resource and EvaluationConference (LREC 2002), Las Palmas.Riloff E. (1993) Automatically constructing adictionary for formation extraction tasks,AAAI?93, Stanford, USA, pp.
811?816.Riloff E. (1995) Little Words Can Make a BigDifference for Text Classification, Proceedings ofthe SIGIR'95, Seattle, USA, pp.
130?136.Riloff E. et Jones R.?
(1999) Learning Dictionariesfor Information Extraction by Multi-LevelBootstrapping.
Proceedings of the 16th NationalConference on Artificial Intelligence (AAAI?99),Orlando, 1999, pp.
474?479.Silberztein M. (1993) Dictionnaires ?lectroniqueset analyse automatique des textes, Masson, Paris,France.
