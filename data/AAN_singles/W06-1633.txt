Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing (EMNLP 2006), pages 275?283,Sydney, July 2006. c?2006 Association for Computational LinguisticsBESTCUT: A Graph Algorithm for Coreference ResolutionCristina Nicolae and Gabriel NicolaeHuman Language Technology Research InstituteDepartment of Computer ScienceUniversity of Texas at DallasRichardson, TX 75083-0688{cristina, gabriel}@hlt.utdallas.eduAbstractIn this paper we describe a coreferenceresolution method that employs a classi-fication and a clusterization phase.
In anovel way, the clusterization is producedas a graph cutting algorithm, in whichnodes of the graph correspond to the men-tions of the text, whereas the edges of thegraph constitute the confidences derivedfrom the coreference classification.
In ex-periments, the graph cutting algorithm forcoreference resolution, called BESTCUT,achieves state-of-the-art performance.1 IntroductionRecent coreference resolution algorithms tacklethe problem of identifying coreferent mentions ofthe same entity in text as a two step procedure: (1)a classification phase that decides whether pairs ofnoun phrases corefer or not; and (2) a clusteriza-tion phase that groups together all mentions thatrefer to the same entity.
An entity is an object ora set of objects in the real world, while a men-tion is a textual reference to an entity1.
Most ofthe previous coreference resolution methods havesimilar classification phases, implemented eitheras decision trees (Soon et al, 2001) or as maxi-mum entropy classifiers (Luo et al, 2004).
More-over, these methods employ similar feature sets.The clusterization phase is different across currentapproaches.
For example, there are several linkingdecisions for clusterization.
(Soon et al, 2001) ad-vocate the link-first decision, which links a men-tion to its closest candidate referent, while (Ng andCardie, 2002) consider instead the link-best deci-sion, which links a mention to its most confident1This definition was introduced in (NIST, 2003).candidate referent.
Both these clustering decisionsare locally optimized.
In contrast, globally opti-mized clustering decisions were reported in (Luoet al, 2004) and (DaumeIII and Marcu, 2005a),where all clustering possibilities are considered bysearching on a Bell tree representation or by us-ing the Learning as Search Optimization (LaSO)framework (DaumeIII and Marcu, 2005b) respec-tively, but the first search is partial and driven byheuristics and the second one only looks back intext.
We argue that a more adequate clusterizationphase for coreference resolution can be obtainedby using a graph representation.In this paper we describe a novel representa-tion of the coreference space as an undirectededge-weighted graph in which the nodes repre-sent all the mentions from a text, whereas theedges between nodes constitute the confidencevalues derived from the coreference classificationphase.
In order to detect the entities referred inthe text, we need to partition the graph such thatall nodes in each subgraph refer to the same entity.We have devised a graph partitioning method forcoreference resolution, called BESTCUT, which isinspired from the well-known graph-partitioningalgorithm Min-Cut (Stoer and Wagner, 1994).BESTCUT has a different way of computing thecut weight than Min-Cut and a different way ofstopping the cut2.
Moreover, we have slightlymodified the Min-Cut procedures.
BESTCUT re-places the bottom-up search in a tree representa-tion (as it was performed in (Luo et al, 2004))with the top-down problem of obtaining the bestpartitioning of a graph.
We start by assuming thatall mentions refer to a single entity; the graph cutsplits the mentions into subgraphs and the split-2Whenever a graph is split in two subgraphs, as defined in(Cormen et al, 2001), a cut of the graph is produced.275ting continues until each subgraph corresponds toone of the entities.
The cut stopping decision hasbeen implemented as an SVM-based classification(Cortes and Vapnik, 1995).The classification and clusterization phases as-sume that all mentions are detected.
In order toevaluate our coreference resolution method, wehave (1) implemented a mention detection proce-dure that has the novelty of employing informationderived from the word senses of common nouns aswell as selected lexico-syntactic information; and(2) used a maximum entropy model for corefer-ence classification.
The experiments conducted onMUC and ACE data indicate state-of-the-art resultswhen compared with the methods reported in (Ngand Cardie, 2002) and (Luo et al, 2004).The remainder of the paper is organized as fol-lows.
In Section 2 we describe the coreferenceresolution method that uses the BESTCUT cluster-ization; Section 3 describes the approach we haveimplemented for detecting mentions in texts; Sec-tion 4 reports on the experimental results; Section5 discusses related work; finally, Section 6 sum-marizes the conclusions.2 BESTCUT Coreference ResolutionFor each entity type (PERSON, ORGANIZATION,LOCATION, FACILITY or GPE3) we create a graphin which the nodes represent all the mentionsof that type in the text, the edges correspond toall pairwise coreference relations, and the edgeweights are the confidences of the coreference re-lations.
We will divide this graph repeatedly bycutting the links between subgraphs until a stopmodel previously learned tells us that we shouldstop the cutting.
The end result will be a partitionthat approximates the correct division of the textinto entities.We consider this graph approach to clustering amore accurate representation of the relations be-tween mentions than a tree-based approach thattreats only anaphora resolution, trying to connectmentions with candidate referents that appear intext before them.
We believe that a correct reso-lution has to tackle cataphora resolution as well,by taking into account referents that appear in thetext after the anaphors.
Furthermore, we believethat a graph representation of mentions in a text ismore adequate than a tree representation becausethe coreference relation is symmetrical in addi-3Entity types as defined by (NIST, 2003).tion to being transitive.
A greedy bottom-up ap-proach does not make full use of this property.
Agraph-based clusterization starts with a completeoverall view of all the connections between men-tions, therefore local errors are much less proba-ble to influence the correctness of the outcome.
Iftwo mentions are strongly connected, and one ofthem is strongly connected with the third, all threeof them will most probably be clustered togethereven if the third edge is not strong enough, and thatworks for any order in which the mentions mightappear in the text.2.1 Learning AlgorithmThe coreference confidence values that becomethe weights in the starting graphs are provided bya maximum entropy model, trained on the train-ing datasets of the corpora used in our experi-ments.
For maximum entropy classification weused a maxent4 tool.
Based on the data seen, amaximum entropy model (Berger et al, 1996) of-fers an expression (1) for the probability that thereexists coreference C between a mention mi and amention mj .P (C|mi,mj) =e(?k ?kgk(mi,mj ,C))Z(mi,mj)(1)where gk(mi,mj , C) is a feature and ?k is itsweight; Z(mi,mj) is a normalizing factor.We created the training examples in the sameway as (Luo et al, 2004), by pairing all men-tions of the same type, obtaining their featurevectors and taking the outcome (coreferent/non-coreferent) from the key files.2.2 Feature RepresentationWe duplicated the statistical model used by (Luoet al, 2004), with three differences.
First, no fea-ture combination was used, to prevent long run-ning times on the large amount of ACE data.
Sec-ond, through an analysis of the validation data, weimplemented seven new features, presented in Ta-ble 1.
Third, as opposed to (Luo et al, 2004), whorepresented all numerical features quantized, wetranslated each numerical feature into a set of bi-nary features that express whether the value is incertain intervals.
This transformation was neces-sary because our maximum entropy tool performsbetter on binary features.
(Luo et al, 2004)?s fea-tures were not reproduced here from lack of space;please refer to the relevant paper for details.4http://homepages.inf.ed.ac.uk/s0450736/maxent toolkit.html276Category Feature name Feature descriptionlexical head-match true if the two heads are identicaltype-pair for each mention: name?
its type, noun?
NOUN , pronoun?
its spellingname-alias true if a mention is an alias of the other onesyntactic same-governing-category true if both mentions are covered by the same type of node, e.g.
NP, VP, PPpath the parse tree path from m2 to m1coll-comm true if either mention collocates with a communication verbgrammatical gn-agree true if the two mentions agree in gender and numberTable 1: The added features for the coreference model.2.3 Clusterization Method: BESTCUTWe start with five initial graphs, one for each en-tity type, each containing all the mentions of thattype and their weighted connections.
This initialdivision is correct because no mentions of differ-ent entity types will corefer.
Furthermore, by do-ing this division we avoid unnecessary confusionin the program?s decisions and we decrease its run-ning time.
Each of these initial graphs will be cutrepeatedly until the resulting partition is satisfac-tory.
In each cut, we eliminate from the graph theedges between subgraphs that have a very weakconnection, and whose mentions are most likelynot part of the same entity.Formally, the graph model can be defined as fol-lows.
Let M = {mi : 1..n} be n mentions in thedocument and E = {ej : 1..m} be m entities.
Letg : M ?
E be the map from a mention mi ?
Mto an entity ej ?
E. Let c : MxM ?
[0, 1] be theconfidence the learning algorithm attaches to thecoreference between two mentions mi,mj ?
M .Let T = {tk : 1..p} be the set of entity typesor classes.
Then we attach to each entity class tkan undirected, edge-weighted graph Gk(Vk, Ek),where Vk = {mi|g(mi).type = tk} and Ek ={(mi,mj , c(mi,mj))|mi,mj ?
Vk}.The partitioning of the graph is based at eachstep on the cut weight.
As a starting point, weused the Min-Cut algorithm, presented and provedcorrect in (Stoer and Wagner, 1994).
In this simpleand efficient method, the weight of the cut of agraph into two subgraphs is the sum of the weightsof the edges crossing the cut.
The partition thatminimizes the cut weight is the one chosen.
Themain procedure of the algorithm computes cuts-of-the-phase repeatedly and selects the one withthe minimum cut value (cut weight).
We adaptedthis algorithm to our coreference situation.To decide the minimum cut (from here on calledthe BESTCUT), we use as cut weight the numberof mentions that are correctly placed in their set.The method for calculating the correctness score ispresented in Figure 1.
The BESTCUT at one stageis the cut-of-the-phase with the highest correctnessscore.cut-weight(Graph G, Cut C = (S,T))1 corrects-avg ?
corrects-max ?
02 foreach m ?
G.V3 if m ?
S.V then setm ?
S4 else setm ?
T7 if avgn?setm.V,n6=mweight(m,n) >avgn?G.V \setm.V weight(m,n)6 then corrects-avg++7 if maxn?setm.V,n6=mweight(m,n) >maxn?G.V \setm.V weight(m,n)8 then corrects-max++9 return (corrects-avg +corrects-max) / 2Figure 1: Computing the cut-weight.An additional learning model was trained to de-cide if cutting a set of mentions is better or worsethan keeping the mentions together.
The modelwas optimized to maximize the ECM-F score5.
Wewill denote by S the larger part of the cut and Tthe smaller one.
C.E is the set of edges crossingthe cut, and G is the current graph before the cut.S.V and T.V are the set of vertexes in S and inT , respectively.
S.E is the set of edges from S,while T.E is the set of edges from T .
The featuresfor stopping the cut are presented in Table 2.
Themodel was trained using 10-fold cross-validationon the training set.
In order to learn when to stopthe cut, we generated a list of positive and nega-tive examples from the training files.
Each train-ing example is associated with a certain cut (S, T ).Since we want to learn a stop function, the positiveexamples must be examples that describe when thecut must not be done, and the negative examplesare examples that present situations when the cutmust be performed.
Let us consider that the listof entities from a text is E = {ej : 1..m} withej = {mi1 ,mi2 , ...mik} the list of mentions thatrefer to ej .
We generated a negative example foreach pair (S = {ei}, T = {ej}) with i 6= j ?each entity must be separated from any other en-5As introduced by (Luo et al, 2004).277Feature name Feature descriptionst-ratio |S.V |/|T.V | ?
the ratio between the cutpartsce-ratio |C.E|/|G.E| ?
the proportion of the cutfrom the entire graphc-min min(C.E) ?
the smallest edge crossingthe cutc-max max(C.E) ?
the largest edge crossingthe cutc-avg avg(C.E) ?
the average of the edgescrossing the cutc-hmean hmean(C.E) ?
the harmonic mean ofthe edges crossing the cutc-hmeax hmeax(C.E) ?
a variant of the har-monic mean.
hmeax(C.E) = 1 ?hmean(C.E?)
where each edge fromE?
has the weight equal to 1 minus thecorresponding edge from Elt-c-avg-ratio how many edges from the cut are lessthan the average of the cut (as a ratio)lt-c-hmean-ratiohow many edges from the cut are lessthan the harmonic mean of the cut (as aratio)st-avg avg(S.E + T.E) ?
the average of theedges from the graph when the edgesfrom the cut are not consideredg-avg avg(G.E) ?
the average of the edgesfrom the graphst-wrong-avg-ratiohow many vertexes are in the wrong partof the cut using the average measure forthe ?wrong?
(as a ratio)st-wrong-max-ratiohow many vertexes are in the wrong partof the cut using the max measure for the?wrong?
(as a ratio)lt-c-avg-ratio< st-lt-c-avg-ratio1 if r1 < r2, 0 otherwise; r1 is the ratioof the edges from C.E that are smallerthan the average of the cut; r2 is the ratioof the edges from S.E + T.E that aresmaller than the average of the cutg-avg > st-avg1 if the avg(G.E) > avg(S.E + T.E),and 0 otherwiseTable 2: The features for stopping the cut.tity.
We also generated negative examples for allpairs (S = {ei}, T = E \ S) ?
each entity mustbe separated from all the other entities consideredtogether.
To generate positive examples, we simu-lated the cut on a graph corresponding to a singleentity ej .
Every partial cut of the mentions of ejwas considered as a positive example for our stopmodel.We chose not to include pronouns in the BEST-CUT initial graphs, because, since most featuresare oriented towards Named Entities and commonnouns, the learning algorithm (maxent) links pro-nouns with very high probability to many possi-ble antecedents, of which not all are in the samechain.
Thus, in the clusterization phase the pro-nouns would act as a bridge between different en-tities that should not be linked.
To prevent this,we solved the pronouns separately (at the end ofBESTCUT(Graph Gi)1 entities.clear()2 queue.push back(Gi)3 while not queue.empty()4 G ?
queue.pop front()5 (S,T) ?
ProposeCut(G)6 if StopTheCut(G,S,T)7 then8 entities.add(NewEntity(G))9 else10 queue.push back(S)11 queue.push back(T)12 return entitiesFigure 2: The general algorithm for BESTCUT.the BESTCUT algorithm) by linking them to theirantecedent with the best coreference confidence.Figure 2 details the main procedure of theBESTCUT algorithm.
The algorithm receives asinput a weighted graph having a vertex for eachmention considered and outputs the list of entitiescreated.
In each stage, a cut is proposed for allsubgraphs in the queue.
In case StopTheCut de-cides that the cut must be performed on the sub-graph, the two sides of the cut are added to thequeue (lines 10-11); if the graph is well connectedand breaking the graph in two parts would be abad thing, the current graph will be used to cre-ate a single entity (line 8).
The algorithm endswhen the queue becomes empty.
ProposeCut (Fig-ProposeCut(Graph G)1 while |G.V | > 12 (S,T) ?
ProposeCutPhase(G)3 if the cut-of-the-phase (S,T)is-lighter than the currentbest cut (Sb, Tb)4 then store the cut-of-the-phaseas (Sb, Tb)5 return (Sb, Tb)Figure 3: The algorithm for ProposeCut.ure 3) returns a cut of the graph obtained withan algorithm similar to the Min-Cut algorithm?sprocedure called MinimumCut.
The differencesbetween our algorithm and the Min-Cut proce-dure are that the most tightly connected vertexin each step of the ProposeCutPhase procedure, z,is found using expression 2:z = argmaxy 6?Awa(A, y) (2)where wa(A, y) = 1|A|?x?A w(x, y), and the is-lighter test function uses the correctness scorepresented before: the partial cut with the largercorrectness score is better.
The ProposeCutPhasefunction is presented in Figure 4.278ProposeCutPhase(Graph G)1 A ?
{G.V.first}2 while |A| < |G.V |3 last ?
the most tightlyconnected vertex4 add last to A5 store the cut-of-the-phase andshrink G by merging the twovertexes added last6 return (G.V \ {last}, last)Figure 4: The algorithm for ProposeCutPhase.2.4 An ExampleLet us consider an example of how the BESTCUTalgorithm works on two simple sentences (Fig-ure 5).
The entities present in this example are:{Mary1, the girl5} and {a brother2, John3, Theboy4}.
Since they are all PERSONs, the algorithmMary1 has a brother2, John3.
The boy4 is older thanthe girl5.Figure 5: An example.will be applied on a single graph, corresponding tothe class PERSON and composed of all these men-tions.The initial graph is illustrated in Figure 6, withthe coreference relation marked through a differ-ent coloring of the nodes.
Each node number cor-responds to the mention with the same index inFigure 5.                         21                         45                         30.20.10.60.50.10.7 0.5Figure 6: The initial graphThe strongest confidence score is between abrother2 and John3, because they are connectedthrough an apposition relation.
The graph wassimplified by eliminating the edges that have aninsignificant weight, e.g.
the edges between John3and the girl5 or between Mary1 and a brother2.Function BESTCUT starts with the whole graph.The first cut of the phase, obtained by functionProposeCutPhase, is the one in Figure 7.a.
This                         21                              45                         32b) Cut  = ({1, 4, 5}, {2, 3})Score(Cut )= 420.20.70.60.50.10.50.1                         21                         45                         3c) Cut  = ({1, 5}, {2, 3, 4})3Score(Cut ) = 5; Cut  = BestCut3 30.20.10.60.50.10.7 0.5                         21                              45                         34d) Cut  = ({1}, {2, 3, 4, 5})Score(Cut ) = 3.540.20.70.60.50.10.50.1                         21                         45                         31Score(Cut ) = 3a) Cut  = ({1, 3, 4, 5}, {2})10.20.10.60.50.10.50.7Figure 7: Cuts-of-the-phasecut separates node 2 from the rest of the graph.In calculating the score of the cut (using the algo-rithm from Figure 1), we obtain an average num-ber of three correctly placed mentions.
This canbe verified intuitively on the drawing: mentions1, 2 and 5 are correctly placed, while 3 and 4 arenot.
The score of this cut is therefore 3.
The sec-ond, the third and the fourth cuts of the phase, inFigures 7.b, 7.c and 7.d, have the scores 4, 5 and3.5 respectively.
An interesting thing to note atthe fourth cut is that the score is no longer an in-teger.
This happens because it is calculated as anaverage between corrects-avg = 4 and corrects-max = 3.
The methods disagree about the place-ment of mention 1.
The average of the outgo-ing weights of mention 1 is 0.225, less than 0.5(the default weight assigned to a single mention)therefore the first method declares it is correctlyplaced.
The second considers only the maximum;0.6 is greater than 0.5, so the mention appears tobe more strongly connected with the outside thanthe inside.
As we can see, the contradiction is be-cause of the uneven distribution of the weights ofthe outgoing edges.The first proposed cut is the cut with the great-279FACILITY ORGANIZATION PERSON LOCATION GPEPOWER#9PERSON#1 PEOPLE#1CHARACTER#1...expert#1Peter_Pan#2womankind#1population#1homeless#2........................Frankenstein#2 oil_tycoon#1worker#1Figure 8: Part of the hierarchy containing 42 WordNet equivalent concepts for the five entity types, withall their synonyms and hyponyms.
The hierarchy has 31,512 word-sense pairs in totalest score, which is Cut3 (Figure 7.c).
Because thisis also the correct cut, all cuts proposed after thisone will be ignored?
the machine learning algo-rithm that was trained when to stop a cut will al-ways declare against further cuts.
In the end, thecut returned by function BESTCUT is the correctone: it divides mentions Mary1 and the girl5 frommentions a brother2, John3 and The boy4.3 Mention DetectionBecause our BESTCUT algorithm relies heavilyon knowing entity types, we developed a methodfor recognizing entity types for nominal mentions.Our statistical approach uses maximum entropyclassification with a few simple lexical and syn-tactic features, making extensive use of WordNet(Fellbaum, 1998) hierarchy information.
We usedthe ACE corpus, which is annotated with men-tion and entity information, as data in a super-vised machine learning method to detect nominalmentions and their entity types.
We assigned sixentity types: PERSON, ORGANIZATION, LOCA-TION, FACILITY, GPE and UNK (for those who arein neither of the former categories) and two gener-icity outcomes: GENERIC and SPECIFIC.
Weonly considered the intended value of the mentionsfrom the corpus.
This was motivated by the factthat we need to classify mentions according to thecontext in which they appear, and not in a generalway.
Only contextual information is useful furtherin coreference resolution.
We have experimentallydiscovered that the use of word sense disambigua-tion improves the performance tremendously (aboost in score of 10%), therefore all the featuresuse the word senses from a previously-appliedword sense disambiguation program, taken from(Mihalcea and Csomai, 2005).For creating training instances, we associatedan outcome to each markable (NP) detected in thetraining files: the markables that were present inthe key files took their outcome from the key fileannotation, while all the other markables were as-sociated with outcome UNK.
We then created atraining example for each of the markables, withthe feature vector described below and as targetfunction the outcome.
The aforementioned out-come can be of three different types.
The first typeof outcome that we tried was the entity type (onemember of the set PERSON, ORGANIZATION, LO-CATION, FACILITY, GPE and UNK); the secondtype was the genericity information (GENERIC orSPECIFIC), whereas the third type was a combi-nation between the two (pairwise combinationsof the entity types set and the genericity set, e.g.PERSON SPECIFIC).The feature set consists of WordNet features,lexical features, syntactic features and intelligentcontext features, briefly described in Table 3.
Withthe WordNet features we introduce the WordNetequivalent concept.
A WordNet equivalent con-cept for an entity type is a word-sense pair fromWordNet whose gloss is compatible with the def-inition of that entity type.
Figure 8 enumerates afew WordNet equivalent concepts for entity classPERSON (e.g.
CHARACTER#1), with their hier-archy of hyponyms (e.g.
Frankenstein#2).
Thelexical feature is useful because some words arealmost always of a certain type (e.g.
?com-pany?).
The intelligent context set of featuresare an improvement on basic context features thatuse the stems of the words that are within a win-dow of a certain size around the word.
In addi-tion to this set of features, we created more fea-tures by combining them into pairs.
Each paircontains two features from two different classes.For instance, we will have features like: is-a-280Category Feature name Feature descriptionWordNet is-a-TYPE true if the mention is of entity type TYPE; five featuresWN-eq-concept-hyp true if the mention is in hyponym set of WN-eq-concept; 42 featuresWN-eq-concept-syn true if the mention is in synonym set of WN-eq-concept; 42 featureslexical stem-sense pair between the stem of the word and the WN sense of the word by the WSDsyntactic pos part of speech of the word by the POS taggeris-modifier true if the mention is a modifier in another noun phrasemodifier-to-TYPE true if the mention is a modifier to a TYPE mentionin-apposition-with TYPE of the mention our mention is in apposition withintelligent context all-mods the nominal, adjectival and pronominal modifiers in the mention?s parse treepreps the prepositions right before and after the mention?s parse treeTable 3: The features for the mention detection system.PERSON?in-apposition-with(PERSON).All these features apply to the ?true head?
ofa noun phrase, i.e.
if the noun phrase is a parti-tive construction (?five students?, ?a lot of com-panies?, ?a part of the country?
), we extract the?true head?, the whole entity that the part wastaken out of (?students?, ?companies?, ?coun-try?
), and apply the features to that ?true head?instead of the partitive head.For combining the mention detection modulewith the BESTCUT coreference resolver, we alsogenerated classifications for Named Entities andpronouns by using the same set of features minusthe WordNet ones (which only apply to nominalmentions).
For the Named Entity classifier, weadded the feature Named-Entity-type as obtainedby the Named Entity Recognizer.
We generateda list of all the markable mentions and their en-tity types and presented it as input to the BEST-CUT resolver instead of the list of perfect men-tions.
Note that this mention detection does notcontain complete anaphoricity information.
Onlythe mentions that are a part of the five consid-ered classes are treated as anaphoric and clus-tered, while the UNK mentions are ignored, evenif an outside anaphoricity classifier might catego-rize some of them as anaphoric.4 Experimental ResultsThe clusterization algorithms that we imple-mented to evaluate in comparison with our methodare (Luo et al, 2004)?s Belltree and Link-Best(best-first clusterization) from (Ng and Cardie,2002).
The features used were described in section2.2.
We experimented on the ACE Phase 2 (NIST,2003) and MUC6 (MUC-6, 1995) corpora.
Sincewe aimed to measure the performance of corefer-ence, the metrics used for evaluation are the ECM-F (Luo et al, 2004) and the MUC P, R and F scores(Vilain et al, 1995).In our first experiment, we tested the threecoreference clusterization algorithms on thedevelopment-test set of the ACE Phase 2 corpus,first on true mentions (i.e.
the mentions annotatedin the key files), then on detected mentions (i.e.the mentions output by our mention detection sys-tem presented in section 3) and finally without anyprior knowledge of the mention types.
The resultsobtained are tabulated in Table 4.
As can be ob-served, when it has prior knowledge of the men-tion types BESTCUT performs significantly bet-ter than the other two systems in the ECM-F scoreand slightly better in the MUC metrics.
The moreknowledge it has about the mentions, the better itperforms.
This is consistent with the fact that thefirst stage of the algorithm divides the graph intosubgraphs corresponding to the five entity types.
IfBESTCUT has no information about the mentions,its performance ranks significantly under the Link-Best and Belltree algorithms in ECM-F and MUCR.
Surprisingly enough, the Belltree algorithm, aglobally optimized algorithm, performs similarlyto Link-Best in most of the scores.Despite not being as dramatically affected asBESTCUT, the other two algorithms also decreasein performance with the decrease of the mentioninformation available, which empirically provesthat mention detection is a very important modulefor coreference resolution.
Even with an F-scoreof 77.2% for detecting entity types, our mentiondetection system boosts the scores of all three al-gorithms when compared to the case where no in-formation is available.It is apparent that the MUC score does not varysignificantly between systems.
This only showsthat none of them is particularly poor, but it is nota relevant way of comparing methods?
the MUCmetric has been found too indulgent by researchers((Luo et al, 2004), (Baldwin et al, 1998)).
TheMUC scorer counts the common links between the281MUC scoreClusterization algorithm Mentions ECM-F% MUC P% MUC R% MUC F%BESTCUT key 82.7 91.1 88.2 89.63detected 73.0 88.3 75.1 81.17undetected 41.2 52.0 82.4 63.76Belltree (Luo et al, 2004) key 77.9 88.5 89.3 88.90detected 70.8 86.0 76.6 81.03undetected 52.6 40.3 87.1 55.10Link-Best (Ng and Cardie, 2002) key 77.9 88.0 90.0 88.99detected 70.7 85.1 77.3 81.01undetected 51.6 39.6 88.5 54.72Table 4: Comparison of results between three clusterization algorithms on ACE Phase 2.
The learningalgorithms are maxent for coreference and SVM for stopping the cut in BESTCUT.
In turn, we obtainthe mentions from the key files, detect them with our mention detection algorithm or do not use anyinformation about them.annotation keys and the system output, while theECM-F metric aligns the detected entities with thekey entities so that the number of common men-tions is maximized.
The ECM-F scorer overcomestwo shortcomings of the MUC scorer: not consid-ering single mentions and treating every error asequally important (Baldwin et al, 1998), whichmakes the ECM-F a more adequate measure ofcoreference.Our second experiment evaluates the impactthat the different categories of our added featureshave on the performance of the BESTCUT sys-tem.
The experiment was performed with a max-ent classifier on the MUC6 corpus, which was pri-orly converted into ACE format, and employedmention information from the key annotations.MUC scoreModel ECM-F% P% R% F%baseline 78.3 89.5 91.5 90.49+grammatical 78.4 89.2 92.5 90.82+lexical 83.1 92.4 91.6 92.00+syntactic 85.1 92.7 92.4 92.55Table 5: Impact of feature categories on BEST-CUT on MUC6.
Baseline system has the (Luo etal., 2004) features.
The system was tested on keymentions.From Table 5 we can observe that the lexi-cal features (head-match, type-pair, name-alias)have the most influence on the ECM-F and MUCscores, succeeded by the syntactic features (same-governing-category, path, coll-comm).
Despitewhat intuition suggests, the improvement thegrammatical feature gn-agree brings to the systemis very small.5 Related WorkIt is of interest to discuss why our implementa-tion of the Belltree system (Luo et al, 2004) iscomparable in performance to Link-Best (Ng andCardie, 2002).
(Luo et al, 2004) do the clus-terization through a beam-search in the Bell treeusing either a mention-pair or an entity-mentionmodel, the first one performing better in their ex-periments.
Despite the fact that the Bell tree is acomplete representation of the search space, thesearch in it is optimized for size and time, whilepotentially losing optimal solutions?
similarly toa Greedy search.
Moreover, the fact that the twoimplementations are comparable is not inconceiv-able once we consider that (Luo et al, 2004) nevercompared their system to another coreference re-solver and reported their competitive results ontrue mentions only.
(Ng, 2005) treats coreference resolution as aproblem of ranking candidate partitions generatedby a set of coreference systems.
The overall per-formance of the system is limited by the perfor-mance of its best component.
The main differ-ence between this approach and ours is that (Ng,2005)?s approach takes coreference resolution onestep further, by comparing the results of multiplesystems, while our system is a single resolver; fur-thermore, he emphasizes the global optimizationof ranking clusters obtained locally, whereas ourfocus is on globally optimizing the clusterizationmethod inside the resolver.
(DaumeIII and Marcu, 2005a) use the Learningas Search Optimization framework to take into ac-count the non-locality behavior of the coreferencefeatures.
In addition, the researchers treat men-tion detection and coreference resolution as a jointproblem, rather than a pipeline approach like we282do.
By doing so, it may be easier to detect theentity type of a mention once we have additionalclues (expressed in terms of coreference features)about its possible antecedents.
For example, label-ing Washington as a PERSON is more probable af-ter encountering George Washington previously inthe text.
However, the coreference problem doesnot immediately benefit from the joining.6 ConclusionsWe have proposed a novel coreference clusteri-zation method that takes advantage of the effi-ciency and simplicity of graph algorithms.
Theapproach is top-down and globally optimized, andtakes into account cataphora resolution in additionto anaphora resolution.
Our system compares fa-vorably to two other implemented coreference sys-tems and achieves state-of-the-art performance onthe ACE Phase 2 corpus on true and detected men-tions.
We have also briefly described our mentiondetection system whose output we used in con-junction with the BESTCUT coreference system toachieve better results than when no mention infor-mation was available.AcknowledgmentsWe would like to thank the three anonymous re-viewers for their very helpful suggestions andcomments on the early draft of our paper.ReferencesB.
Baldwin, T. Morton, A. Bagga, J. Baldridge,R.
Chandraseker, A. Dimitriadis, K. Snyder, andM.
Wolska.
1998.
Description of the university ofpennsylvania camp system as used for coreference.In Proceedings of the 7th Message UnderstandingConference (MUC-7).A.
L. Berger, S. A. D. Pietra, and V. J. D. Pietra.
1996.A maximum entropy approach to natural languageprocessing.
Computational Linguistics, 1(22):39?71.T.
H. Cormen, C. E. Leiserson, R. L. Rivest, andC.
Stein.
2001.
Introduction to Algorithms, SecondEdition.
MIT.C.
Cortes and V. Vapnik.
1995.
Support-vector net-works.
Machine Learning, 20(3):273?297.H.
DaumeIII and D. Marcu.
2005a.
A large-scale ex-ploration of effective global features for a joint en-tity detection and tracking model.
pages 97?104,Vancouver.H.
DaumeIII and D. Marcu.
2005b.
Learning as searchoptimization: Approximate large margin methodsfor structured prediction.
In The International Con-ference on Machine Learning (ICML).C.
Fellbaum, editor.
1998.
WordNet: An ElectronicLexical Database and Some of its Applications.
MITPress.X.
Luo, A. Ittycheriah, H. Jing, N. Kambhatla, andS.
Roukos.
2004.
A mention-synchronous corefer-ence resolution algorithm based on the bell tree.
InProceedings of the 42nd Meeting of the Associationfor Computational Linguistics, Barcelona, Spain.R.
Mihalcea and A. Csomai.
2005.
Senselearner:Word sense disambiguation for all words in unre-stricted text.
In Proceedings of the 43rd Meeting ofthe Association for Computational Linguistics, AnnArbor, MI.MUC-6.
1995.
Coreference task definition.V.
Ng and C. Cardie.
2002.
Improving machine learn-ing approaches to coreference resolution.
In Pro-ceedings of the 4Oth Meeting of the Association forComputational Linguistics, Philadelphia, Pennsyl-vania.V.
Ng.
2004.
Learning noun phrase anaphoricity toimprove conference resolution: Issues in representa-tion and optimization.
In Proceedings of the 42ndMeeting of the Association for Computational Lin-guistics, Barcelona, Spain.V.
Ng.
2005.
Machine learning for coreference resolu-tion: From local classification to global ranking.
InProceedings of the 43rd Meeting of the Associationfor Computational Linguistics, pages 157?164, AnnArbor, MI.NIST.
2003.
Entity detection and tracking - phase1; edt and metonymy annotation guidelines.
version2.5.1 20030502.M.
Pasca and S. Harabagiu.
2001.
High performancequestion/answering.
In Proceedings of the 24th An-nual International ACM SIGIR Conference on Re-search and Development in Information Retrieval,pages 366?374, New Orleans, LA.W.
M. Soon, H. T. Ng, and D. C. Y. Lim.
2001.
Amachine learning approach to coreference resolu-tion of noun phrases.
Computational Linguistics,4(27):521?544.M.
Stoer and F. Wagner.
1994.
A simple min cut al-gorithm.
In Jan van Leeuwen, editor, Proceedings ofthe 1994 European Symposium on Algorithms, pages141?147, New York.
Springer-Verlag.M.
Vilain, J.Burger, J. Aberdeen, D. Connolly, andL.
Hirschman.
1995.
A model-theoretic coreferencescoring scheme.
In Proceedings of the Sixth Mes-sage Understanding Conference (MUC-6), pages45?52.283
