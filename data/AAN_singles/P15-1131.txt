Proceedings of the 53rd Annual Meeting of the Association for Computational Linguisticsand the 7th International Joint Conference on Natural Language Processing, pages 1354?1364,Beijing, China, July 26-31, 2015.c?2015 Association for Computational LinguisticsTopic Modeling based Sentiment Analysis on Social Mediafor Stock Market PredictionThien Hai Nguyen Kiyoaki ShiraiSchool of Information ScienceJapan Advanced Institute of Science and Technology1-1 Asahidai, Nomi, Ishikawa 923-1292, Japan{nhthien, kshirai}@jaist.ac.jpAbstractThe goal of this research is to build amodel to predict stock price movement us-ing sentiments on social media.
A newfeature which captures topics and theirsentiments simultaneously is introduced inthe prediction model.
In addition, a newtopic model TSLDA is proposed to obtainthis feature.
Our method outperformeda model using only historical prices byabout 6.07% in accuracy.
Furthermore,when comparing to other sentiment anal-ysis methods, the accuracy of our methodwas also better than LDA and JST basedmethods by 6.43% and 6.07%.
The resultsshow that incorporation of the sentimentinformation from social media can help toimprove the stock prediction.1 IntroductionStock price forecasting is very important in theplanning of business activity.
However, buildingan accurate stock prediction model is still a chal-lenging problem.
In addition to historical prices,the current stock market is affected by the moodof society.
The overall social mood with respectto a given company might be one of the importantvariables which affect the stock price of that com-pany.
Nowadays, the emergence of online socialnetworks makes large amounts of mood data avail-able.
Therefore, incorporating information fromsocial media with the historical prices can improvethe predictive ability of the models.The goal of our research is to develop a model topredict a stock price movement using informationfrom social media (Message Board).
In our pro-posed method, the model predicts the movementof the stock value at t using features derived frominformation at t ?
1 and t ?
2, where t stands fora transaction date.
It will be trained by supervisedmachine learning.
Apart from the mood informa-tion, the stock prices are affected by many factorssuch as microeconomic and macroeconomic fac-tors.
However, this research only focuses on howthe mood information from social media can beused to predict the stock price movement.
Thatis, the mood of topics in social media is extractedby sentiment analysis.
Then, the topics and theirsentiments are integrated into the model to pre-dict the stocks.
To achieve this goal, discover-ing the topics and sentiments in a large amountof social media is important to get opinions ofinvestors as well as events of companies.
How-ever, sentiment analysis on social media is diffi-cult.
The text is usually short, contains many mis-spellings, uncommon grammar constructions andso on.
In addition, the literature shows conflict-ing results in sentiment analysis for stock marketprediction.
Some researchers report that the senti-ments from social media have no predictive capa-bilities (Antweiler and Frank, 2004; Tumarkin andWhitelaw, 2001), while other researchers have re-ported either weak or strong predictive capabilities(Bollen et al, 2011).
Therefore, how to use opin-ions in social media for stock price predictions isstill an open problem.Our contributions are summarized as follows:1.
We propose a new feature ?topic-sentiment?for the stock market prediction model.2.
We propose a new topic model, Topic Sen-timent Latent Dirichlet Allocation (TSLDA),which can capture the topic and sentiment si-multaneously.3.
Large scale evaluation.
Most of the previousresearches are limited on predicting for onestock (Bollen et al, 2011; Qian and Rasheed,2007; Si et al, 2013), and the number ofinstances (transaction dates) in a test set israther low such as 14 or 15 instances (Bollen1354et al, 2011; Vu et al, 2012).
With only a fewinstances in the test set, the conclusion mightbe insufficient.
This is the first research thatshows good prediction results on evaluationof many stocks using a test set consisting ofmany transaction dates.The rest of the paper is organized as follows.Section 2 introduces some previous approaches onsentiment analysis for stock prediction.
Section 3explains our model for sentiment analysis by si-multaneously inferring the topic and sentiment inthe text.
Section 4 describes two kinds of datasetsrequired for stock prediction.
Section 5 describesour prediction models and also proposes a novelfeature based on the topics and sentiments.
Sec-tion 6 assesses the results of the experiments.
Fi-nally, Section 7 concludes our research.2 Related WorkStock market prediction is one of the most at-tracted topics in academic as well as real life busi-ness.
Many researches have tried to address thequestion whether the stock market can be pre-dicted.
Some of the researches were based onthe random walk theory and the Efficient MarketHypothesis (EMH).
According to the EMH (Famaet al, 1969; Fama, 1991), the current stock mar-ket fully reflects all available information.
Hence,price changes are merely due to new informationor news.
Because news in nature happens ran-domly and is unknowable in the present, stockprices should follow a random walk pattern andthe best bet for the next price is the current price.Therefore, they are not predictable with more thanabout 50% accuracy (Walczak, 2001).
On theother hand, various researches specify that thestock market prices do not follow a random walk,and can be predicted in some degree (Bollen et al,2011; Qian and Rasheed, 2007; Vu et al, 2012).Degrees of accuracy at 56% hit rate in the pre-dictions are often reported as satisfying results forstock predictions (Schumaker and Chen, 2009b; Siet al, 2013; Tsibouris and Zeidenberg, 1995).Besides the efficient market hypothesis and therandom walk theories, there are two distinct trad-ing philosophies for stock market prediction: fun-damental analysis and technical analysis.
The fun-damental analysis studies the company?s financialconditions, operations, macroeconomic indicatorsto predict the stock price.
On the other hand, thetechnical analysis depends on historical and time-series prices.
Price moves in trends, and historytends to repeat itself.
Some researches have triedto use only historical prices to predict the stockprice (Zuo and Kita, 2012a; Zuo and Kita, 2012b).To discover the pattern in the data, they usedBayesian network (Zuo and Kita, 2012a; Zuo andKita, 2012b), time-series method such as Auto Re-gressive, Moving Average, Auto Regressive Mov-ing Average model (Zuo and Kita, 2012a) and soon.2.1 Extracting Opinions from TextSentiment analysis has been found to play a sig-nificant role in many applications such as prod-uct and restaurant reviews (Liu and Zhang, 2012;Pang and Lee, 2008).
There are some researchestrying to apply sentiment analysis on informationsources to improve the stock prediction model.There are two main such sources.
In the past, themain source was the news (Schumaker and Chen,2009a; Schumaker and Chen, 2009b), and in re-cent years, social media sources.
A simple ap-proach is combining the sentiments in the textualcontent with the historical prices through the lin-ear regression model.Most of the previous work primarily used thebag-of-words as text representation that are incor-porated into the prediction model.
Schumaker andChen tried to use different textual representationssuch as bag-of-words, noun phrases and namedentities for financial news (Schumaker and Chen,2009b).
However, the textual representations arejust the words or named entity tags, not exploit-ing the mood information so much.
A novel treerepresentation based on semantic frame parsers isproposed (Xie et al, 2013).
By using stock pricesfrom Yahoo Finance, they annotated all the newsin a transaction date with going up or down cate-gories.
However, the weakness of this assumptionis that all the news in one day will have the samecategory.
In addition, this is a task of text classifi-cation, not stock prediction.Naive Bayes was used to classify messagesfrom message boards into three classes: buy, holdand sell (Antweiler and Frank, 2004).
They wereintegrated into the regression model.
However,they concluded that their model does not success-fully predict stock returns.A method to measure collective hope and fearon each day and analyze the correlation betweenthese indices and the stock market indicators was1355proposed (Zhang et al, 2011).
They used themood words to tag each tweet as fear, worry, hopeand so on.
They concluded that the ratio of theemotional tweets significantly negatively corre-lated with Down Jones, NASDAQ and S&P 500,but positively with VIX.
However, they did not usetheir model to predict the stock price values.Two mood tracking tools, OpinionFinder andGoogle Profile of Mood States, were used to an-alyze the text content of daily Twitter (Bollen etal., 2011).
The former measures the positive andnegative mood.
The latter measures the mood interms of six dimensions (Calm, Alert, Sure, Vital,Kind, and Happy).
They used the Self OrganizingFuzzy Neural Network model to predict DJIA val-ues.
The results showed 86.7% direction accuracy(up or down) and 1.79% Mean Absolute Percent-age Error.
Although they achieved the high accu-racy, there were only 15 transaction dates (fromDecember 1 to 19, 2008) in their test set.
Withsuch a short period, it might not be sufficient toconclude the effectiveness of their method.A keyword-based algorithm was proposed toidentify the sentiment of tweets as positive, neu-tral and negative for stock prediction (Vu et al,2012).
Their model achieved around 75% accu-racy.
However, their test period was short, from8thto 26thin September 2012, containing only 14transaction dates.Continuous Dirichlet Process Mixture (cDPM)model was used to learn the daily topic set of Twit-ter messages to predict the stock market (Si et al,2013).
A sentiment time series was built basedon these topics.
However, the time period of theirwhole dataset is rather short, only three months.Most of the researches tried to extract only theopinions or sentiments.
However, one importantmissing thing is that opinions or sentiments are ex-pressed on topics or aspects of companies.
There-fore, understanding on which topics of a givenstock people are expressing their opinion is veryimportant.
Although the models for inferring thetopics and sentiments simultaneously have alreadyproposed as discussed in Subsection 2.2, to thebest of our knowledge, such models have neverapplied for stock market prediction.2.2 Aspect based Sentiment AnalysisSome researches tried to identify the sentiment ex-pressed toward an aspect in a sentence rather thana whole sentence or document.
The simple ap-proach is to define a sentiment score of a given as-pect by the weighted sum of opinion scores of allwords in the sentence, where the weight is definedby the distance from the aspect (Liu and Zhang,2012; Pang and Lee, 2008).
This method is furtherimproved by identifying the aspect-opinion rela-tions using tree kernel method (Nguyen and Shi-rai, 2015).Other researches trying to extract both the topicand sentiment for some domains such as on-line product, restaurant and movie review dataset.ASUM is a model for extracting both the aspectand sentiment for online product review dataset(Jo and Oh, 2011).
Joint sentiment/topic model(JST) is another model to detect the sentiment andtopic simultaneously, which was applied for moviereview dataset (Lin and He, 2009).
These modelsassume that each word is generated from a jointtopic and sentiment distribution.
It means thatthese models do not distinguish the topic word andopinion word distributions.Besides the general opinion words, topic mod-els considering aspect-specific opinion wordswere also proposed.
MaxEnt-LDA hybrid modelcan jointly discover both aspects and aspect-specific opinion words on a restaurant reviewdataset (Zhao et al, 2010), while FACTS,CFACTS, FACTS-R, and CFACTS-R model wereproposed for sentiment analysis on a product re-view data (Lakkaraju et al, 2011).
However, oneof the weaknesses of these methods is that there isonly one opinion word distribution correspondingto one topic (aspect).
It makes difficult to knowwhich sentiment (e.g.
positive or negative) is ex-pressed by the opinion words on that topic.To overcome this drawback, we propose a newtopic model called Topic Sentiment Latent Dirich-let Allocation (TSLDA), which estimates differ-ent opinion word distributions for individual sen-timent categories for each topic.
To the best of ourknowledge, such a model has not been proposed.TSLDA is suitable for not only sentiment analy-sis for stock prediction but also general sentimentanalysis of the document, sentence and aspect.3 TSLDA: Topic Sentiment LatentDirichlet AllocationThe proposed model TSLDA infers the topics andtheir sentiments simultaneously.
It is an extendedmodel of Latent Dirichlet Allocation (LDA) (Bleiet al, 2003).
We assume that one sentence ex-1356Figure 1: Graphical Model Representation ofTSLDApresses only one topic and one opinion on thattopic.
The topics are usually nouns, whereas theopinion words are adjectives or adverbs.
Thewords in the document are classified into three cat-egories, the topic word (category c = 1), opinionword (c = 2) and others (c = 0).
Then, we sup-pose the different opinion words are used for thedifferent topics.
Depending on the topic, an opin-ion word may express different sentiment mean-ing.
For example, the opinion word ?low?
in ?lowcost?
and ?low salary?
have opposite polarity.
Inour model, different topics, which are also repre-sented by word distributions, will have differentopinion word distributions.
Finally, to capture thesentiment meanings such as positive, negative orneutral of the opinion words for each topic, wedistinguish opinion word distributions for differ-ent sentiment meanings.Figure 1 shows the graphical model representa-tion of TSLDA.
Observed and hidden variables areindicated by shaded and clear circles, respectively.Table 1 shows the notations in Figure 1.
The gen-eration process in TSLDA is as follows:1.
Choose a distribution of background words?b?
Dirichlet(?)2.
For each topic k:?
Choose a distribution of topic words?tk?
Dirichlet(?)?
For each sentiment s of topic k:?
Choose a distribution of sentimentwords ?ok,s?
Dirichlet(?
)Table 1: Notations in TSLDANotation Definition?, ?, ?, ?
Dirichlet prior vectorsK # of topicsS # of sentiments?bdistribution over background words?tdistribution over topic words?odistribution over sentiment wordsD # of documentsMd# of sentences in document dNd,m# of words in sentence min document d?tdtopic distribution for document d?odsentiment distribution for document dztd,mtopic assignment for sentence min document dzod,msentiment assignmentfor sentence m in document dwd,m,nnthword in sentence min document dcd,m,nnthword?s category (background,topic or sentiment) in sentence min document d3.
For each document d:?
Choose a topic distribution?td?
Dirichlet(?)?
Choose a sentiment distribution?od?
Dirichlet(?)?
For each sentence m:?
Choose a topic assignmentztd,m?Multinomial(?td)?
Choose a sentiment assignmentzod,m?Multinomial(?od)?
For each word in the sentence:?
Choose a wordwd,m,nas in Equa-tion (1).wd,m,n?????
?Multinomial(?b) if cd,m,n= 0Multinomial(?tztd,m) if cd,m,n= 1Multinomial(?oztd,m,zod,m) if cd,m,n= 2(1)We will define some notations for explanationof our method.
Wk,sd,m,v,cis the number of times theword v with the category c appears in the sentencem in the document d, where m discusses the topick and the sentiment s. Let Zk,sdbe the number oftimes the document d has the topic k and the sen-timent s. If any of these dimensions is not limited1357to a specific value, we used an asterisk ?
to denoteit.
For example, Wk,s?,?,v,cis the number of appear-ance of combination (v, c, k, s) in any sentencesin any documents.
Similarly, Zk,?dis the numberof times the document d has the topic k with anysentiments.A bold-font variable denotes the list of the vari-ables.
For instance, ztand w denote all of topicassignments and words in all documents, respec-tively.?
(d,m) stands for exclusion of the value inthe sentence m in the document d. For example,zt?
(d,m) denotes all of topic assignment variablesztbut ztd,m.
Za,??
(d,m)ddenotes the value of Za,?dnot counting times at the sentence m in the docu-ment d.We used square brackets for specifying thevalue at the index of a vector or distribution.
Forinstance, ?
[v] denotes the value of ?
at index v.Collapsed Gibbs Sampling was implementedfor inference in TSLDA.
It will sequentially sam-ple hidden variables ztd,mand zod,mfrom the dis-tribution over these variables given the currentvalues of all other hidden and observed vari-ables.
In other words, in order to perform Col-lapsed Gibbs Sampling, conditional probabilityP (ztd,m= a, zod,m= b|zt?
(d,m), zo?
(d,m),w, c)is calculated by marginalizing out random vari-ables ?b, ?t, ?o, ?tand ?o.
Because of thelimit of spaces, we only show the final formulaof this conditional probability as in Equation (2).Let Vd,mbe a set of words in the sentencem in thedocument d. V is a set of all of the words in alldocuments.P (ztd,m= a, zod,m= b|zt?
(d,m), zo?
(d,m),w, c, )?
(Za,??
(d,m)d+ ?[a])(Z?,b?
(d,m)d+ ?[b])?Vd,m?v=1W?,?d,m,v,1?j=1(Wa,??
(d,m)?,?,v,1+ ?
[v] + j ?
1)W?,?d,m,?,1?j=1(V?v=1Wa,??
(d,m)?,?,v,1+ ?
[v] + j ?
1)?Vd,m?v=1W?,?d,m,v,2?j=1(Wa,b?
(d,m)?,?,v,2+ ?
[v] + j ?
1)W?,?d,m,?,2?j=1(V?v=1Wa,b?
(d,m)?,?,v,2+ ?
[v] + j ?
1)(2)Multinomial parameters: Finally, samples ob-tained from Collapsed Gibbs Sampling can beused to approximate the multinomial parametersets.
The distributions of topics and sentiments inthe document d are estimated as in Equation (3).
?td[a] =Za,?d+ ?
[a]K?k=1Zk,?d+ ?
[k]; ?od[b] =Z?,bd+ ?
[b]S?s=1Z?,sd+ ?
[s](3)The background word distribution, topic worddistribution of the topic k and sentiment word dis-tribution of the sentiment s for k are estimated inEquation (4), (5) and (6), respectively.
?b[r] =W?,?
?,?,r,0+ ?[r]V?v=1W?,?
?,?,v,0+ ?
[v](4)?tk[r] =Wk,?
?,?,v,1+ ?[r]V?v=1Wk,?
?,?,v,1+ ?
[v](5)?ok,s[r] =Wk,s?,?,v,2+ ?
[r]V?v=1Wk,s?,?,v,2+ ?
[v](6)4 DatasetTwo datasets are used for the development of ourstock prediction model.
One is the historical pricedataset, and the other is the message board dataset.4.1 Historical Price DatasetHistorical prices are extracted from Yahoo Fi-nance for 5 stocks.
The list of the stock quotesand company names is shown in Table 2.
Foreach transaction date, there are open, high, low,close and adjusted close prices.
The adjusted closeprices are the close prices which are adjusted fordividends and splits.
They are often used for stockmarket prediction as in other researches (Rechen-thin et al, 2013).
Therefore, we chose it as thestock price value for each transaction date.4.2 Message Board DatasetTo get the mood information of the stocks, we col-lected 5 message boards of the 5 stocks from Ya-hoo Finance Message Board for a period of oneyear (from July 23, 2012 to July 19, 2013).
On themessage boards, users usually discuss company1358Table 2: Statistics of Our DatasetStocks Company Names #DocumentsXOM Exxon Mobil Corporation 11027DELL Dell Inc. 10339EBAY eBay Inc. 7168IBMInternational Business5008Machines CorporationKO The Coca-Cola Company 2024news, prediction about stock going up or down,facts, comments (usually negative) about specificcompany executives or company events.
The stockmarket is not opened at the weekend and holiday.To assign the messages to the transaction dates, themessages which were posted from 4 pm of the pre-vious transaction date to 4 pm of the current trans-action date will belong to the current transaction.We choose 4 pm because it is the time of closingtransaction.
There are 249 transaction dates in theone year period in our dataset.5 Stock Prediction Models withSentiment AnalysisThis paper focuses on prediction of not the stockprice but movement of it.
That is, our goal is todevelop a model that predicts if the stock pricegoes up or down.
Support Vector Machine (SVM)has long been recognized as being able to effi-ciently handle high dimensional data and has beenshown to perform well on many tasks such as textclassification (Joachims, 1998; Nguyen and Shi-rai, 2013).
Therefore, we chose SVM with the lin-ear kernel as the prediction model.
Furthermore,features derived by sentiment analysis on the mes-sage board are incorporated in it.
To assess the ef-fectiveness of sentiment analysis, four sets of fea-tures are designed.
The first one uses only the his-torical prices.
The other sets include topic and sen-timent features obtained by different methods.
Allthe feature values are scaled into [?1, 1] value.
Ta-ble 3 summarizes our features used in the model topredict the price movement at the transaction datet.
The details of each feature will be explained inthe next subsections.5.1 Price OnlyIn this method, only historical prices are used topredict the stock movement.
The purpose of thismethod is to investigate whether there are patternsof the price movement in the history of the stock.In addition, it is a baseline for evaluation of theTable 3: Features of the Prediction ModelMethod FeaturesPrice Only pricet?1, pricet?2LDA-based Method pricet?1, pricet?2,ldai,t, ldai,t?1JST-based Method pricet?1, pricet?2,jsti,j,t, jsti,j,t?1TSLDA-based Method pricet?1, pricet?2,tsldai,j,t, tsldai,j,t?1effectiveness of the sentiment features.
Featuresused for training SVM are pricet?1and pricet?2which are the price movements (up, down) at thetransaction dates t?
1, t?
2, respectively.5.2 LDA-based MethodIn this model, we consider each message as a mix-ture of hidden topics.
LDA is a generative prob-abilistic model of a corpus1.
The basic idea isthat documents are represented as random mix-tures over latent topics, where each topic is charac-terized by a distribution over words.
Hidden topicsof LDA are incorporated into the prediction modelas follows.
First, stop words are removed fromthe messages, and all the words are lemmatized byStanford CoreNLP (Manning et al, 2014).
Topicsare inferred by Gibbs Sampling with 1000 itera-tions.
Next, the probability of each topic for eachmessage is calculated.
For each transaction date t,the probability of each topic is defined as the aver-age of the probabilities of the topic in all messagesposted on that transaction date.Features used for training SVM are pricet?1,pricet?2, ldai,tand ldai,t?1.
ldai,tand ldai,t?1are the probabilities of the topic i (i ?
{1, ?
?
?
,K}) for the transaction dates t and t ?
1.The number of the topics K is empirically deter-mined as explained in Subsection 6.1.5.3 JST-based MethodWhen people post the message on social media toexpress their opinion for a given stock, they tendto talk their opinions for a given topic or aspectsuch as profit and dividend.
They would thinkthat the future price of the stock goes up or downby seeing pairs of topic-sentiment written by oth-ers.
Following the above intuition, we propose anew feature topic-sentiment for the stock predic-1We used the LDA implementation from the Mallet li-brary.1359Figure 2: Graphical Model Representation of JSTTable 4: Notations in JSTNotation Definition?, ?, ?
Dirichlet prior vectors?
distribution over wordsT # of topicsS # of sentiments?
message and sentiment specific topicdistributionz topicw word in the message dl sentiment labelpi message specific sentiment distributionNd# of words in the message dD # of messagestion model.
Two methods are used to extract thepairs of topic-sentiment from the message board.One is a latent topic based model called JST (Linand He, 2009).
The other is TSLDA discussed inSection 3.
This subsection introduces the methodusing the former.We consider each message as a mixture of hid-den topics and sentiments.
JST model is used toextract topics and sentiments simultaneously.
Fig-ure 2 shows the graphical model representation ofJST.
Notations in Figure 2 are shown in Table 4.
InLDA model, there is only one document specifictopic distribution.
In contrast, each document inJST is associated with multiple sentiment labels.Each sentiment label is associated with a docu-ment specific topic distribution.
A word in thedocument is drawn from a distribution over wordsdefined by the topic and sentiment label.After removal of stop words and lemmatiza-tion, JST model is trained by Gibbs Sampling with1000 iterations.
We chose 3 as the number ofsentiments which might represent negative, neu-tral and positive.
The number of the topics Kis empirically determined as explained in Subsec-tion 6.1.
Next, the joint probability of each pairof topic and sentiment is calculated for each mes-sage.
For each transaction date t, the joint proba-bility of each topic-sentiment pair is defined as theaverage of the joint probabilities in the messageson that transaction date.
Then we integrate theseprobabilities into the prediction model.Features used for training SVM are pricet?1,pricet?2, jsti,j,tand jsti,j,t?1.
jsti,j,tandjsti,j,t?1are the joint probabilities of the sen-timent i (i ?
{1, 2, 3}) and topic j (j ?
{1, ?
?
?
,K}) for the transaction dates t and t?
1.5.4 TSLDA-based MethodWe use our TSLDA model to capture the topicsand sentiments simultaneously.
First, a rule-basedalgorithm is applied to identify the category ofeach word in the documents.
Consecutive nounsare considered as topic words.
If a word is not anoun and in a list of opinion words in SentiWord-Net (Baccianella et al, 2010), it is considered asan opinion word.
The rest of words are classifiedas background words.After lemmatization, TSLDA model is trainedby Collapsed Gibbs Sampling with 1000 itera-tions.
We chose 3 as the number of sentimentswhich might represent for negative, neutral andpositive.
K (number of topics) is determined asexplained in Subsection 6.1.
The topic and its sen-timent in each sentence are gotten from the topicassignment and sentiment assignment in TSLDA.If there is a sentence expressing the sentiment jon the topic i, we represent the tuple (i, j) = 1,and 0 otherwise.
The proportion of (i, j) over allsentences are calculated for each message.
Foreach transaction date, a weight of the tuple (i, j)is defined as the average of the proportions overall messages.
Then we integrated the weights ofthe topics and their sentiments into the predictionmodel.Features used for training SVM are pricet?1,pricet?2, tsldai,j,tand tsldai,j,t?1.
tsldai,j,tandtsldai,j,t?1are the weights of the topic i (i ?
{1, ?
?
?
,K}) with the sentiment j (j ?
{1, 2, 3})for the transaction dates t and t?
1.1360Table 5: Accuracies of Stock Movement Predic-tionStocks Price Only LDA JST TSLDAXOM 0.5000 0.4464 0.5179 0.5357DELL 0.5893 0.5357 0.5000 0.5536EBAY 0.6071 0.6071 0.5000 0.6429IBM 0.4107 0.3929 0.5357 0.5536KO 0.4107 0.5179 0.4643 0.5357Average 0.5036 0.5000 0.5036 0.56436 Evaluation6.1 Experiment SetupWe divided the dataset described in Section 4 intothree parts: training set from July 23, 2012 toMarch 31, 2013, development set from April 01,2013 to April 30, 2013, and test set from May01, 2013 to July 19, 2013.
The label of ?up?and ?down?
is assigned to each transaction date bycomparing the price of the current and previousdates.To optimize the number of topics K for eachstock, we run the models with four values of K:10, 20, 50 and 100.
The best K is chosen for eachstock on the development set, and the systems withthe chosen K is evaluated on the test data.
Theperformance of the prediction is measured by ac-curacy.For the hyperparameters of LDA, JST andTSLDA, we simply selected symmetric Dirich-let prior vectors, that is all possible distributionsare likely equal.
We used the default values ofthese hyperparameters for LDA and JST.
Con-cretely speaking, ?
= 0.5, ?
= 0.01 in LDA and?
=50#topics, ?
= 0.01, ?
= 0.3 were used in JST.For TSLDA, we set ?
= 0.1, ?
= 0.1, ?
= 0.01and ?
= 0.01.6.2 ResultsThe result of each stock is shown in Table 5.
Inaddition, the average of 5 stocks for each model isrevealed in the last row of this table for easy com-parison.
Our model TSLDA-based method out-performed the other methods on the average of thestocks.
Table 6 shows the number of true posi-tive (TP), true negative (TN), false positive (FP)and false negative (FN) of models for the stocks.For easy comparison, the summation for these fivestocks are calculated in the last row.To assess the effectiveness of integrating moodinformation, we compare our TSLDA-basedTable 6: TP, TN, FP, FN of Stock Movement Pre-dictionStocks Metrics Price Only LDA JST TSLDAXOMTP 14 13 15 18TN 14 12 14 12FP 8 10 8 10FN 20 21 19 16DELLTP 17 13 5 13TN 16 17 23 18FP 17 16 10 15FN 6 10 18 10EBAYTP 17 18 20 20TN 17 16 8 16FP 9 10 18 10FN 13 12 10 10IBMTP 15 15 7 31TN 8 7 23 0FP 17 18 2 25FN 16 16 24 0KOTP 12 14 16 10TN 11 15 10 20FP 17 13 18 8FN 16 14 12 18SumTP 75 73 63 92TN 66 67 78 66FP 68 67 56 68FN 71 73 83 54method with Price Only method.
The resultsshowed that the model using mood informationoutperformed the model without mood by 3.57%,3.58%, 14.29% and 12.5% accuracy for XOM,EBAY, IBM and KO stock, respectively.
On theother hand, the performance on DELL stock wasnot improved.
It means that the use of the mooddoes not always make the performance better.
Themood from social media could lead to a wrong pre-diction because of wrong prediction of messagewriters, fault information and so on.
However,TSLDA was better than Price Only method on av-erage of these stocks.
In addition, TSLDA can re-duce the number of FN, especially for IBM, al-though FP was not changed in the sum of 5 stocks.Thus, we can conclude that integrating the moodinformation from social media can help to predictstock price movement more precisely.Next, let us compare the models for inferring la-tent topics only (LDA) and topics and sentiments(JST and TSLDA) in the stock movement predic-tion.
The accuracy of JST-based method was bet-ter than LDA for two stocks (XOM and IBM),worse for three stocks and comparable in the aver-age of five stocks.
While, TSLDA-based methodoutperformed LDA and JST by 2 to 17% in theaccuracy for five stocks.
TSLDA was also better1361Table 7: Top Words in Topics of TSLDATopic1 Topic2 Topic3 Topic4 Topic5 Topic6ko split drink customer company countryceo stock coke budget competitor taxcompany share water campaign buy governorreport price produce promotion sell obamaearning dividend product growth hold rommeyanalyst year health sale problem mittshare date juice volumn soda presidentnews market make come product billdowngrade time p.o.s revenue people christianthan LDA and JST on average as shown in Table5.
The improvement of the accuracy was derivedby increase of TP and decrease of FN.
These re-sults indicate that (1) our idea to use both latenttopics and sentiments as the features is effective,(2) TSLDA is more appropriate model than JST instock movement prediction.Table 7 shows examples of highly associatedwords of some topics for stock KO (Coca-ColaCompany) in TSLDA.
For example, ?split?, ?stock?and ?share?
are words highly associated with thehidden topic 2, and ?drink?, ?coke?
and ?water?
arehighly associated with the topic 3.
The first fivehidden topics in Table 7 may represent the man-agement, stock market trading, product, customercare service, competitors of the company, whilethe last one indicates macroeconomic factors.
Ta-ble 8 shows examples of highly associated wordsof three sentiments of the hidden topic 1 and 2.
Forthe hidden topic 1, ?growth?, ?strong?, ?solid?
etc.are the words highly associated with the hiddensentiment 3 (which may corresponds to positiveclass), while ?old?, ?tired?, ?unreal?
etc.
with thehidden sentiment 1 (may be negative).
In general,however, it is rather difficult to interpret the mean-ing of the hidden sentiment because the sentimentshave many dimensions such as happy, anger, sad,vital and so on.
We also found that the wordswith high probabilities in the background distribu-tion were the stop words, punctuations, functionwords, messy characters written in social media,e.g.
?.
?, ?the?, ?and?, ?you?, ?$?, ?for?
and ??
?.Table 9 shows top words in some joint senti-ment topic distributions of JST model for stockKO.
For example, ?yahoo?, ?ko?
and ?finance?
arehighly associated with the distribution defined byhidden sentiment 1 and hidden topic 1.
However,it is rather difficult to guess which sentiment ortopic in this joint distribution actually means.Table 8: Top Words in Sentiments of Topics ofTSLDATopic1 Topic2S1 S2 S3 S1 S2 S3old value grow down straight goodtired even strong tough warm longunreal difference solid troll informative moremuch list gain breakthrough interesting highobviously together full ex later stillmuch serve continue sugary responsible rightnot americans growth ep yeah surehelpful operation value richly used samehere get quarter major though manyTable 9: Top Words in Distributions Defined bySentiments and Topics of JSTS1 S2 S3Topic1 Topic2 Topic1 Topic2 Topic1 Topic2yahoo juice ko new spam splitko minute buy american board sharefinance maid get country post datechart orange sell obama ignore stockfree apple go top idiot recordfire drink make fall get pricewebsite fruit money health read augustaone edit much government another receivedownload punch next place report get7 ConclusionThis paper presents the method to infer the top-ics and their sentiments on the documents and usethem for prediction of the stock movement.
Theresults of the experiments show the effectivenessof our proposed TSLDA-based method.
Although56% accuracy of our method is not so high, it canbe satisfying results as regarded in the previous pa-pers.
Another advantage of the paper is the eval-uation by the large scale experiment (five stocks,three month transaction dates in the test set).The drawback of TSLDA is that we have tospecify the number of topics and sentiment be-forehand.
To overcome it, TSLDA should be ex-tended as a non-parametric topic model estimatingthe number of topics inherent in the data.
This willbe done in our future work.ReferencesWerner Antweiler and Murray Z Frank.
2004.
Is allthat talk just noise?
the information content of inter-net stock message boards.
The Journal of Finance,59(3):1259?1294.Stefano Baccianella, Andrea Esuli, and Fabrizio Sebas-tiani.
2010.
Sentiwordnet 3.0: An enhanced lexi-cal resource for sentiment analysis and opinion min-ing.
In Proceedings of the Seventh Conference on1362International Language Resources and Evaluation(LREC?10), volume 10, pages 2200?2204.David M. Blei, Andrew Y. Ng, and Michael I. Jordan.2003.
Latent dirichlet alocation.
Journal of Ma-chine Learning Research, 3:993?1022.Johan Bollen, Huina Mao, and Xiaojun Zeng.
2011.Twitter mood predicts the stock market.
Journal ofComputational Science, 2(1):1?8.Eugene F Fama, Lawrence Fisher, Michael C Jensen,and Richard Roll.
1969.
The adjustment of stockprices to new information.
International economicreview, 10(1):1?21.Eugene F Fama.
1991.
Efficient capital markets: Ii.The journal of finance, 46(5):1575?1617.Yohan Jo and Alice H Oh.
2011.
Aspect and senti-ment unification model for online review analysis.In Proceedings of the fourth ACM international con-ference on Web search and data mining, pages 815?824.
ACM.Thorsten Joachims.
1998.
Text categorization withsupport vector machines: Learning with many rel-evant features.
Springer.Himabindu Lakkaraju, Chiranjib Bhattacharyya, Indra-jit Bhattacharya, and Srujana Merugu.
2011.
Ex-ploiting coherence for the simultaneous discoveryof latent facets and associated sentiments.
In Pro-ceedings of the Eleventh SIAM International Con-ference on Data Mining, SDM 2011, April 28-30,2011, Mesa, Arizona, USA, pages 498?509.
SIAM /Omnipress.Chenghua Lin and Yulan He.
2009.
Joint senti-ment/topic model for sentiment analysis.
In Pro-ceedings of the 18th ACM conference on Informa-tion and knowledge management, pages 375?384.ACM.Bing Liu and Lei Zhang.
2012.
A survey of opinionmining and sentiment analysis.
In Mining Text Data,pages 415?463.
Springer.Christopher D. Manning, Mihai Surdeanu, John Bauer,Jenny Finkel, Steven J. Bethard, and David Mc-Closky.
2014.
The Stanford CoreNLP natural lan-guage processing toolkit.
In Proceedings of 52ndAnnual Meeting of the Association for Computa-tional Linguistics: System Demonstrations, pages55?60.Thien Hai Nguyen and Kiyoaki Shirai.
2013.
Textclassification of technical papers based on text seg-mentation.
In Elisabeth Mtais, Farid Meziane,Mohamad Saraee, Vijayan Sugumaran, and SunilVadera, editors, Natural Language Processing andInformation Systems, volume 7934 of Lecture Notesin Computer Science, pages 278?284.
SpringerBerlin Heidelberg.Thien Hai Nguyen and Kiyoaki Shirai.
2015.
Aspect-based sentiment analysis using tree kernel based re-lation extraction.
In Alexander Gelbukh, editor,Computational Linguistics and Intelligent Text Pro-cessing, volume 9042 of Lecture Notes in ComputerScience, pages 114?125.
Springer International Pub-lishing.Bo Pang and Lillian Lee.
2008.
Opinion mining andsentiment analysis.
Foundations and trends in infor-mation retrieval, 2(1-2):1?135.Bo Qian and Khaled Rasheed.
2007.
Stock marketprediction with multiple classifiers.
Applied Intelli-gence, 26(1):25?33.Michael Rechenthin, W Nick Street, and PadminiSrinivasan.
2013.
Stock chatter: Using stock sen-timent to predict price direction.
Algorithmic Fi-nance, 2(3):169?196.Robert P Schumaker and Hsinchun Chen.
2009a.
Aquantitative stock prediction system based on finan-cial news.
Information Processing & Management,45(5):571?583.Robert P. Schumaker and Hsinchun Chen.
2009b.
Tex-tual analysis of stock market prediction using break-ing financial news: The azfin text system.
ACMTrans.
Inf.
Syst., 27(2):12:1?12:19, March.Jianfeng Si, Arjun Mukherjee, Bing Liu, Qing Li,Huayi Li, and Xiaotie Deng.
2013.
Exploiting topicbased twitter sentiment for stock prediction.
In Pro-ceedings of the 51st Annual Meeting of the Associ-ation for Computational Linguistics, ACL 2013, 4-9August 2013, Sofia, Bulgaria, Volume 2: Short Pa-pers, pages 24?29.
The Association for ComputerLinguistics.George Tsibouris and Matthew Zeidenberg.
1995.Testing the efficient markets hypothesis with gradi-ent descent algorithms.
In Neural Networks in theCapital Markets, pages 127?136.
Wiley: Chichester.Robert Tumarkin and Robert F Whitelaw.
2001.
Newsor noise?
internet postings and stock prices.
Finan-cial Analysts Journal, 57(3):41?51.Tien Thanh Vu, Shu Chang, Quang Thuy Ha, and NigelCollier.
2012.
An experiment in integrating sen-timent features for tech stock prediction in twitter.In 24th International Conference on ComputationalLinguistics, pages 23?38.Steven Walczak.
2001.
An empirical analysis of datarequirements for financial forecasting with neuralnetworks.
Journal of management information sys-tems, 17(4):203?222.Boyi Xie, Rebecca J Passonneau, Leon Wu, andGerm?an Creamer.
2013.
Semantic frames to pre-dict stock price movement.
In Proceedings of the51st Annual Meeting of the Association for Compu-tational Linguistics, pages 873?883.1363Xue Zhang, Hauke Fuehres, and Peter A Gloor.
2011.Predicting stock market indicators through twitter ?Ihope it is not as bad as I fear?.
Procedia-Social andBehavioral Sciences, 26(0):55?62.Wayne Xin Zhao, Jing Jiang, Hongfei Yan, and Xiaom-ing Li.
2010.
Jointly modeling aspects and opin-ions with a maxent-lda hybrid.
In Proceedings of the2010 Conference on Empirical Methods in NaturalLanguage Processing, pages 56?65.
Association forComputational Linguistics.Yi Zuo and Eisuke Kita.
2012a.
Stock price forecastusing bayesian network.
Expert Systems with Ap-plications: An International Journal, 39(8):6729?6737.Yi Zuo and Eisuke Kita.
2012b.
Up/down analysis ofstock index by using bayesian network.
EngineeringManagement Research, 1(2):46?52.1364
