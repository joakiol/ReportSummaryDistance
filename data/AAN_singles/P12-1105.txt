Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 997?1005,Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational LinguisticsPolarity Consistency Checking for Sentiment DictionariesEduard DragutCyber CenterPurdue Universityedragut@purdue.eduHong Wang Clement Yu Prasad SistlaComputer Science Dept.University of Illinois at Chicago{hwang207,cyu,sistla}@uic.eduWeiyi MengComputer Science Dept.Binghamton Universitymeng@cs.binghamton.eduAbstractPolarity classification of words is importantfor applications such as Opinion Mining andSentiment Analysis.
A number of sentimentword/sense dictionaries have been manuallyor (semi)automatically constructed.
The dic-tionaries have substantial inaccuracies.
Be-sides obvious instances, where the same wordappears with different polarities in differentdictionaries, the dictionaries exhibit complexcases, which cannot be detected by mere man-ual inspection.
We introduce the concept ofpolarity consistency of words/senses in senti-ment dictionaries in this paper.
We show thatthe consistency problem is NP-complete.
Wereduce the polarity consistency problem to thesatisfiability problem and utilize a fast SATsolver to detect inconsistencies in a sentimentdictionary.
We perform experiments on foursentiment dictionaries and WordNet.1 IntroductionThe opinions expressed in various Web and mediaoutlets (e.g., blogs, newspapers) are an importantyardstick for the success of a product or a govern-ment policy.
For instance, a product with consis-tently good reviews is likely to sell well.
The gen-eral approach is to summarize the semantic polarity(i.e., positive or negative) of sentences/documentsby analysis of the orientations of the individualwords (Pang and Lee, 2004; Danescu-N.-M. et al,2009; Kim and Hovy, 2004; Takamura et al, 2005).Sentiment dictionaries are utilized to facilitate thesummarization.
There are numerous works that,given a sentiment lexicon, analyze the structure ofa sentence/document to infer its orientation, theholder of an opinion, the sentiment of the opin-ion, etc.
(Breck et al, 2007; Ding and Liu, 2010;Kim and Hovy, 2004).
Several domain indepen-dent sentiment dictionaries have been manually or(semi)-automatically created, e.g., General Inquirer(GI) (Stone et al, 1996), Opinion Finder (OF) (Wil-son et al, 2005), Appraisal Lexicon (AL) (Taboadaand Grieve, 2004), SentiWordNet (Baccianella et al,2010) and Q-WordNet (Agerri and Garc??a-Serrano,2010).
Q-WordNet and SentiWordNet are lexical re-sources which classify the synsets(senses) in Word-Net according to their polarities.
We call them sen-timent sense dictionaries (SSD).
OF, GI and ALare called sentiment word dictionaries (SWD).
Theyconsist of words manually annotated with their cor-responding polarities.
The sentiment dictionarieshave the following problems:?
They exhibit substantial (intra-dictionary) inac-curacies.
For example, the synset{Indo-European, Indo-Aryan, Aryan} (of or re-lating to the former Indo-European people),has a negative polarity in Q-WordNet, whilemost people would agree that this synset has aneutral polarity instead.?
They have (inter-dictionary) inconsistencies.For example, the adjective cheap is positive inAL and negative in OF.?
These dictionaries do not address the concept ofpolarity (in)consistency of words/synsets.We concentrate on the concept of (in)consistencyin this paper.
We define consistency among the po-larities of words/synsets in a dictionary and givemethods to check it.
A couple of examples help il-lustrate the problem we attempt to address.997The first example is the verbs confute anddisprove, which have positive and negative po-larities, respectively, in OF.
According to WordNet,both words have a unique sense, which they share:disprove, confute (prove to be false) ?The physicistdisproved his colleagues?
theories?Assuming that WordNet has complete informationabout the two words, it is rather strange that thewords have distinct polarities.
By manually check-ing two other authoritative English dictionaries, Ox-ford1 and Cambridge2, we note that the informationabout confute and disprove in WordNet is thesame as that in these dictionaries.
So, the problemseems to originate in OF.The second example is the verbs tantalizeand taunt, which have positive and negative po-larities, respectively, in OF.
They also have a uniquesense in WordNet, which they share.
Again, thereis a contradiction.
In this case Oxford dictionarymentions a sense of tantalize that is missingfrom WordNet: ?excite the senses or desires of(someone)?.
This sense conveys a positive polarity.Hence, tantalize conveys a positive sentimentwhen used with this sense.In summary, these dictionaries have conflictinginformation.
Manual checking of sentiment dictio-naries for inconsistency is a difficult endeavor.
Wedeem words such as confute and disprove in-consistent.
We aim to unearth these inconsistenciesin sentiment dictionaries.
The presence of inconsis-tencies found via polarity analysis is not exclusivelyattributed to one party, i.e., either the sentiment dic-tionary or WordNet.
Instead, as emphasized by theabove examples, some of them lie in the sentimentdictionaries, while others lie in WordNet.
Therefore,a by-product of our polarity consistency analysis isthat it can also locate some of the likely places whereWordNet needs linguists?
attention.We show that the problem of checking whetherthe polarities of a set of words is consistent is NP-complete.
Fortunately, the consistency problem canbe reduced to the satisfiability problem (SAT).
Afast SAT solver is utilized to detect inconsistenciesand it is known such solvers can in practice deter-mine consistency or detect inconsistencies.
Experi-mental results show that substantial inconsistencies1http://oxforddictionaries.com/2http://dictionary.cambridge.org/are discovered among words with polarities withinand across sentiment dictionaries.
This suggests thatsome remedial work needs to be performed on thesesentiment dictionaries as well as on WordNet.
Thecontributions of this paper are:?
address the consistency of polarities ofwords/senses.
The problem has not beenaddressed before;?
show that the consistency problem is NP-complete;?
reduce the polarity consistency problem to thesatisfiability problem and utilize a fast SATsolver to detect inconsistencies;?
give experimental results to demonstrate that ourtechnique identifies considerable inconsistenciesin various sentiment lexicons as well as discrep-ancies between these lexicons and WordNet.2 Problem DefinitionThe polarities of the words in a sentiment dictionarymay not necessarily be consistent (or correct).
Inthis paper, we focus on the detection of polarity as-signment inconsistencies for the words and synsetswithin and across dictionaries (e.g., OF vs. GI).
Weattempt to pinpoint the words with polarity inconsis-tencies and classify them (Section 3).2.1 WordNetWe give a formal characterization of WordNet.
Thisconsists of words, synsets and frequency counts.
Aword-synset network N is quadruple (W,S, E , f)where W is a finite set of words, S is a finite set ofsynsets, E is a set of undirected edges between el-ements in W and S, i.e., E ?
W ?
S and f is afunction assigning a positive integer to each elementin E .
For an edge (w, s), f(w, s) is called the fre-quency of use of w in the sense given by s. For anyword w and synset s, we say that s is a synset of wif (w, s) ?
E .
Also, for any word w, we let freq(w)denote the sum of all f(w, s) such that (w, s) ?
E .If a synset has a 0 frequency of use we replace itwith 0.1, which is a standard smoothing technique(Han, 2005).
For instance, the word cheap has foursenses.
The frequencies of occurrence of the word inthe four senses are f1 = 9, f2 = 1, f3 = 1 and f4 =0, respectively.
By smoothing, f4 = 0.1.
Hence,freq(cheap) = f1 + f2 + f3 + f4 = 11.1.
Therelative frequency of the synset in the first sense ofcheap, which denotes the probability that the wordis used in the first sense, is f1freq(cheap) =911.1 = 0.81.9982.2 Consistent Polarity AssignmentWe assume that each synset has a unique polarity.We define the polarity of a word to be a discreteprobability distribution: P+, P?, P0 with P++P?+P0 = 1, where they represent the ?likelihoods?
thatthe word is positive, negative or neutral, respec-tively.
We call this distribution a polarity distribu-tion.
For instance, the word cheap has the polaritydistribution P+ = 0.81, P?
= 0.19 and P0 = 0.The polarity distribution of a word is estimated usingthe polarities of its underlying synsets.
For instancecheap has four senses, with the first sense beingpositive and the last three senses being negative.
Theprobability that the word expresses a negative senti-ment is P?
= f2+f3+f4freq(cheap) = 0.19, while the proba-bility that the word expresses a positive sentiment isP+ = f1freq(cheap) = 0.81.
P0 = 1?
P+ ?
P?
= 0.Our view of characterizing the polarity of a wordusing a polarity distribution is shared with other pre-vious works (Kim and Hovy, 2006; Andreevskaiaand Bergler, 2006).
Nonetheless, we depart fromthese works in the following key aspect.
We saythat a word has a (mostly) positive (negative) po-larity if the majority sense of the word is positive(negative).
That is, a word has a mostly positive po-larity if P+ > P?
+ P0 and it has a mostly nega-tive polarity if P?
> P+ + P0.
Or, equivalently, ifP+ > 12 or P?
>12 , respectively.
For example,on majority, cheap conveys positive polarity sinceP+ = .081 > 12 , i.e., the majority sense of the wordcheap has positive connotation.Based on this study, we contend that GI, OF andAL tacitly assume this property.
For example, theverb steal is assigned only negative polarity inGI.
This word has two other less frequently occur-ring senses, which have positive polarities.
The po-larity of steal according to these two senses is notmentioned in GI.
This is the case for the overwhelm-ing majority of the entries in the three dictionaries:only 112 out of a total of 14,105 entries in the threedictionaries regard words with multiple polarities.For example, the verb arrest is mentioned withboth negative and positive polarities in GI.
We re-gard an entry in an SWD as the majority sense of theword has the specified polarity, although the wordmay carry other polarities.
For instance, the adjec-tive cheap has positive polarity in GI.
The only as-sumption we make about the word is that it has a po-larity distribution such that P+ > P?
+P0.
This in-terpretation is consistent with the senses of the word.In this work we show that this property allows thepolarities of words in input sentiment dictionaries tobe checked.
We formally state this property.Definition 1.
Let w be a word and Sw its set ofsynsets.
Each synset in Sw has an associated po-larity and a relative frequency with respect to w. whas polarity p, p ?
{positive, negative} if there isa subset of synsets S?
?
Sw such that each synsets ?
S?
has polarity p and?s?S?f(w,s)freq(w) > 0.5.
S?is called a polarity dominant subset.
If there is nosuch subset then w has a neutral polarity.S?
?
Sw is a minimally dominant subset ofsynsets (MDSs) if the sum of the relative frequen-cies of the synsets in S?
is larger than 0.5 and theremoval of any synset s from S?
will make the sumof the relative frequencies of the synsets in S?
?
{s}smaller than or equal to 0.5.The definition does not preclude a word from hav-ing a polarity with a majority sense and a differentpolarity with a minority sense.
For example, the def-inition does not prevent a word from having bothpositive and negative senses, but it prevents a wordfrom concomitantly having a majority sense of beingpositive and a majority sense of being negative.Despite using a ?hard-coded?
constant in the def-inition, our approach is generic and does not depen-dent on the constant 0.5.
This constant is just a lowerbound for deciding whether a word has a majoritysense with a certain polarity.
It also is intuitivelyappealing.
The constant can be replaced with an ar-bitrary threshold ?
between 0.5 and 1.We need a formal description of polarity assign-ments to the words and synsets in WordNet.
We as-sign polarities from the set P = {positive, negative,neutral} to elements in W ?
S. Formally, a polar-ity assignment ?
for a network N is a function fromW ?
S to the set P .
Let ?
be a polarity assignmentfor N .
We say that ?
is consistent if it satisfies thefollowing condition for each w ?
W:For p ?
{positive, negative}, ?
(w) = p iff thesum of all f(w, s) such that (w, s) ?
E and ?
(s) =p, is greater than freq(w)2 .
Note that, for any w ?W , ?
(w) = neutral iff the above inequality is notsatisfied for both values of p in {positive, negative}.We contend that our approach is applicable to do-999Table 1: Disagreement between dictionaries.Pairs of Word Polarity DisagreementDictionaries Inconsistency OverlapOF & GI 90 2,924OF & AL 73 1,150GI & AL 18 712main dependent sentiment dictionaries, too.
We canemploy WordNet Domains (Bentivogli et al, 2004).WordNet Domains augments WordNet with domainlabels.
Hence, we can project the words/synsets inWordNet according to a domain label and then applyour methodology to the projection.3 Inconsistency ClassificationPolarity inconsistencies are of two types: input andcomplex.
We discuss them in this section.3.1 Input Dictionaries Polarity InconsistencyInput polarity inconsistencies are of two types:intra-dictionary and inter-dictionary inconsistencies.The latter are obtained by comparing (1) two SWDs,(2) an SWD with an SSD and (3) two SSDs.3.1.1 Intra-dictionary inconsistencyAn SWDmay have triplets of the form (w, pos, p)and (w, pos, p?
), where p ?= p?.
For instance, theverb brag has both positive and negative polaritiesin OF.
For these cases, we look up WordNet and ap-ply Definition 1 to determine the polarity of word wwith part of speech pos.
The verb brag has negativepolarity according to Definition 1.
Such cases sim-ply say that the team who constructs the dictionarybelieves the word has multiple polarities as they donot adopt our dominant sense principle.
There are58 occurrences of this type of inconsistency in GI,OF and AL.
Q-WordNet, a sentiment sense dictio-nary, does not have intra-inconsistencies as it doesdo not have a synset with multiple polarities.3.1.2 Inter-dictionary inconsistencyA word belongs to this category if it appears withdifferent polarities in different SWDs.
For instance,the adjective joyless has positive polarity in OFand negative polarity in GI.
Table 1 depicts the over-lapping relationships between the three SWDs: e.g.,OF has 2,933 words in common with GI.
The threedictionaries largely agree on the polarities of thewords they pairwise share.
For instance, out of 2,924words shared by OF and GI, 2,834 have the same po-larities.
However, there are also a significant numberof words which have different polarities across dic-tionaries.
Case in point, OF and GI disagree on thepolarities of 90 words.
Among the three dictionar-ies there are 181 polarity inconsistent words.
Thesewords are manually corrected using Definition 1 be-fore the polarity consistency checking is applied tothe union of the three dictionaries.
This union iscalled disagreement-free union.3.2 Complex Polarity InconsistencyThis kind of inconsistency is more subtle and cannotbe detected by direct comparison of words/synsets.They consist of sets of words and/or synsets whosepolarities cannot concomitantly be satisfied.
Recallthe example of the verbs confute and disprovein OF given in Section 1.
Recall our argument thatby assuming that WordNet is correct, it is not pos-sible for the two words to have different polarities:the sole synset, which they share, would have twodifferent polarities, which is a contradiction.The occurrence of an inconsistency points out thepresence of incorrect input data:?
the information given inWordNet is incorrect, or?
the information in the given sentiment dictionaryis incorrect, or both.Regarding WordNet, the errors may be due to (1)a word has senses that are missing from WordNet or(2) the frequency count of a synset is inaccurate.
Acomprehensive analysis of every synset/word withinconsistency is a tantalizing endeavor requiring notonly a careful study of multiple sources (e.g., dictio-naries such as Oxford and Cambridge) but also lin-guistic expertise.
It is beyond the scope of this paperto enlist all potentially inconsistent words/synsetsand the possible remedies.
Instead, we limit our-selves to drawing attention to the occurrence of theseissues through examples, welcoming experts in thearea to join the corrective efforts.
We give more ex-amples of inconsistencies in order to illustrate addi-tional discrepancies between input dictionaries.3.2.1 WordNet vs.
Sentiment DictionariesThe adjective bully is an example of a discrep-ancy between WordNet and a sentiment dictionary.The word has negative polarity in OF and has a sin-gle sense in WordNet.
The sense is shared with theword nifty, which has positive polarity in OF.
Byapplying Definition 1 to nifty we obtain that thesense is positive, which in turn, by Definition 1, im-plies that bully is positive.
This contradicts the1000input polarity of bully.
According to the Websterdictionary, the word has a sense (i.e., resembling orcharacteristic of a bully) which has a negative po-larity, but it is not present in WordNet.
The exampleshows the presence of a discrepancy between Word-Net and OF, namely, OF seems to assign polarity toa word according to a sense that is not in WordNet.3.2.2 Across Sentiment DictionariesWe provide examples of inconsistencies acrosssentiment dictionaries here.
Our first exampleis obtained by comparing SWDs.
The adjectivecomic has negative polarity in AL and the adjectivelaughable has positive polarity in OF.
Throughdeduction (i.e., by successive applications of Defini-tion 1), the word risible, which is not present ineither of the dictionaries, is assigned negative polar-ity because of comic and is assigned positive po-larity because of laughable.The second example illustrates that an SWD andan SSD may have contradicting information.
Theverb intoxicate has three synsets in WordNet,each with the same frequency.
Hence, their rela-tive frequencies with respect to intoxicate are13 .
On one hand, intoxicate has a negative po-larity in GI.
This means that P?
> 12 .
On the otherhand, two of its three synsets have positive polarityin Q-WordNet.
So, P+ = 23 >12 , which means thatP?
< 12 .
This is a contradiction.
This example canalso be used to illustrate the presence of a discrep-ancy between WordNet and sentiment dictionaries.Note that all the frequencies of use of the senses ofintoxicate in WordNet are 0.
The problem isthat when all the senses of a word have a 0 frequencyof use, wrong polarity inference may be produced.3.3 Consistent Polarity AssignmentGiven the discussion above, it clearly is important tofind all occurrences of inconsistent words.
This inturn boils down to finding those words with the prop-erty that there does not exist any polarity assignmentto the synsets, which is consistent with their polar-ities.
It turns out that the complexity of the prob-lem of assigning polarities to the synsets such thatthe assignment is consistent with the polarities ofthe input words, called Consistent PolarityAssignment problem, is a ?hard?
problem, as de-scribed below.
The problem is stated as follows:Consider two sets of nodes of type synsets andtype words, in which each synset of a word has arelative frequency with respect to the word.
Eachsynset can be assigned a positive, negative or neu-tral polarity.
A word has polarity p if it satisfies thehypothesis of Definition 1.
The question to be an-swered is: Given an assignment of polarities to thewords, does there exist an assignment of polaritiesto the synsets that agrees with that of the words?In other words, given the polarities of a subset ofwords (e.g., that given by one of the three SWDs)the problem of finding the polarities of the synsetsthat agree with this assignment is a ?hard?
problem.Theorem 1.
The Consistent Polarity Assignmentproblem is NP-complete.4 Polarity Consistency CheckingTo ?exhaustively?
solve the problem of finding thepolarity inconsistencies in an SWD, we propose asolution that reduces an instance of the problem toan instance of CNF-SAT.
We can then employ afast SAT solver (e.g., (Xu et al, 2008; Babic et al,2006)) to solve our problem.
CNF-SAT is a deci-sion problem of determining if there is an assign-ment of True and False to the variables of a Booleanformula ?
in conjunctive normal form (CNF) suchthat ?
evaluates to True.
A formula is in CNF ifit is a conjunction of one or more clauses, each ofwhich is a disjunction of literals.
CNF-SAT is a clas-sic NP-complete problem, but, modern SAT solversare capable of solving many practical instances ofthe problem.
Since, in general, there is no easy wayto tell the difficulty of a problem without trying it,SAT solvers include time-outs, so they will termi-nate even if they cannot find a solution.We developed a method of converting an instanceof the polarity consistency checking problem into aninstance of CNF-SAT, which we will describe next.4.1 Conversion to CNF-SATThe input consists of an SWD D and the word-synset network N .
We partition N into connectedcomponents.
For each synset s we define threeBoolean variables s?, s+ and s0, corresponding tothe negative, positive and neutral polarities, respec-tively.
In this section we use ?,+, 0 to denote neg-ative, positive and neutral polarities, respectively.Let ?
be the Boolean formula for a connectedcomponent M of the word-synset network N .
Weintroduce its clauses.
First, for each synset swe needa clause C(s) that expresses that the synset can have1001only one of the three polarities: C(s) = (s+??s??
?s0) ?
(s?
?
?s+ ?
?s0) ?
(s0 ?
?s?
?
?s+).Since a word has a neutral polarity if it has nei-ther positive nor negative polarities, we have thats0 = ?s+ ?
?s?.
Replacing this expression in theequation above and applying standard Boolean logicformulas, we can reduce it toC(s) = ?s+ ?
?s?
(1)For each word w with polarity p ?
{?,+, 0} inD we need a clause C(w, p) that states that w haspolarity p. So, the Boolean formula for a connectedcomponent M of the word-synset network N is:?
=?s?MC(s) ??
(w,p)?DC(w, p).
(2)From Definition 1, w is neutral if it is neither pos-itive nor negative.
Hence, C(w, 0) = ?C(w,?)
??C(w,+).
So, we need to define only the clausesC(w,?)
and C(w,+), which correspond to w hav-ing polarity negative and positive, respectively.
So,herein p ?
{?,+}, unless otherwise specified.Our method is based on the following statementin Definition 1: w has polarity p if there exists apolarity dominant subset among its synsets.
Thus,C(w, p) is defined by enumerating all the MDSs ofw.
If at least one of them is a polarity dominantsubset then C(w, p) evaluates to True.Exhaustive Enumeration of MDSs Method(EEM) We now elaborate the construction ofC(w, p).
We enumerate all the MDSs of w and foreach of them we introduce a clause.
The clauses arethen concatenated by OR in the Boolean formula.Let C(w, p, T ) denote the clause for an MDS T ofw, when w has polarity p ?
{?,+}.
Hence,C(w, p) =?T?MDS(w)C(w, p, T ), (3)where MDS(w) is the set of all MDSs of w.For each MDS T of w, the clause C(w, p, T ) isthe AND of the variables corresponding to polarityp of the synsets in T .
That is,C(w, p, T ) =?s?Tsp, p ?
{?,+}.
(4)The formula ?
is not in CNF after this construc-tion and it needs to be converted.
The conversion toCNF is a standard procedure and we omit it in thispaper.
?
in CNF is input to a SAT solver.Example 1.
Consider a connected componentconsisting of the words w = cheap, v =inexpensive and u = sleazy.
cheap hasa positive polarity, whereas inexpensive andsleazy have negative polarities.
The synsetsof these words are: {s1, s2, s3, s4}, {s1} and{s3, s4, s5}, respectively (refer to WordNet).
Therelative frequencies of s3, s4 and s5 w.r.t.
sleazyare all equal to 1/3.
We have 15 binary variables,3 per synset, si?, si+, si0, 1 ?
i ?
5.
The onlyMDS of cheap is {s1}, which coincides with thatof inexpensive.
Those of sleazy are {s3, s4},{s3, s5} and {s4, s5}.
For each si we need a clauseC(si).
Hence, C(w,+) = s1+, C(v,?)
= s1?
andC(u,?)
= (s3?
?
s4?)
?
(s3?
?
s5?)
?
(s4?
?
s5?
).Thus, ?
=?iC(si) ?
[s1+ ?
s1?
?
((s3?
?
s4?)
?(s3?
?
s5?)
?
(s4?
?
s5?))].
?
is not in CNF andneeds to be converted.
For ?
to be True, the clausesC(w,+) = s1+ and C(v,?)
= s1?
must be True.But, this makes C(s1) False.
Hence, ?
is not satisfi-able.
The clauses C(w,+) = s1+ and C(v,?)
= s1?are unsatisfiable and thus the polarities of cheapand inexpensive are inconsistent.4.2 Implementation IssuesThe above reduction is exponential in the numberof clauses (see, Equation 3) in the worst case.
Apolynomial reduction is possible, but it is signifi-cantly more complicated to implement.
We chooseto present the exponential reduction in this paper be-cause it can handle over 97% of the words in Word-Net and it is better suited to explain one of the maincontributions of paper: the translation from the po-larity consistency problem to SAT.WordNet possesses nice properties, which allowsthe exponential reduction to run efficiently in prac-tice.
First, 97.2% of its (word, part-of-speech) pairshave 4 or fewer synsets.
Thus, these words add veryfew clauses to a CNF formula (Equation 3).
Second,WordNet can be partitioned into 33,015 non-trivialconnected components, each of which correspondsto a Boolean formula and they all are independentlyhandled.
A non-trivial connected component has atleast two words.
Finally, in practice, not all con-nected components need to be considered for an in-put sentiment dictionary D, but only those having atleast two words in D. In our experiments the largestnumber of components that need to be processed is1002Table 2: Distribution of words and synsetsPOSWordsSynsets OF GI AL QWNNoun117,798 82,115 1,907 1,444 2 7,403Verb 11,529 13,767 1,501 1,041 0 4006Adj.
21,479 18,156 2,608 1,188 1,440 4050Adv.
4,481 3,621 775 51 317 40Total155,287 117,659 6,791 3,961 1,759 15,4991,581, for the disagreement-free union dictionary.5 Detecting InconsistenciesIn this section we describe how we detect the wordswith polarity inconsistencies using the output of aSAT solver.
For an unsatisfiable formula, a mod-ern SAT solver returns a minimal unsatisfiable core(MUC) from the original formula.
An unsatisfiablecore is minimal if it becomes satisfiable wheneverany one of its clauses is removed.
There are noknown practical algorithms for computing the min-imum core (Dershowitz et al, 2006).
In our prob-lem a MUC corresponds to a set of polarity incon-sistent words.
The argument is as follows.
Con-sider W the set of words in a connected componentand ?
the CNF formula generated with the abovemethod.
During the transformation we keep track ofthe clauses introduced in ?
by each word.
Suppose?
is inconsistent.
Then, the SAT solver returns aMUC.
Each clause in a MUC is mapped back to itscorresponding word(s).
We obtain the correspond-ing subset of words W ?,W ?
?
W .
Suppose that ?
?is the Boolean CNF formula for the words in W ?.The set of clauses in ??
is a subset of those in ?.Also, the clauses in the MUC appear in ??.
Thus, ?
?is unsatisfiable and the words inW ?
are inconsistent.To find all inconsistent words we ought to gener-ate all MUCs.
Unfortunately, this is a ?hard?
prob-lem (Dershowitz et al, 2006) and no open sourceSAT solver possesses this functionality.
We how-ever observe that the two SAT solvers we use for ourexperiments (SAT4j and PicoSAT (Biere, 2008)) re-turn different MUCs for the same formula and weuse them to find as many inconsistencies as possi-ble.6 ExperimentsThe goal of the experimental study is to show thatour techniques can identify considerable inconsis-tencies in various sentiment dictionaries.Table 3: Intra- and inter-dictionaries inconsistencyPOS OF QW GI QW AL QW UF QWNoun 23 119 4 61 0 42 90 140Verb 66 113 2 67 0 0 63 137Adj.
90 170 8 48 0 0 27 177Adv.
61 1 0 0 2 0 69 1Total 240 403 14 176 2 42 249 455Data sets In our experiments, we use WordNet3.0, GI, OF, AL and Q-WordNet.
Their statistics aregiven in Table 2.
The table shows the distribution ofthe words and synsets per part of speech.
Columns2 and 3 pertain to WordNet.
There are 3,961 entriesin GI, 1,759 entries in AL and 6,791 entries in OFwhich appear in WordNet.
Q-WordNet has 15,499entries, i.e., synsets with polarities.Inconsistency Detection We applied our methodto (1) each of AL, GI and OF; (2) the disagreement-free union (UF); (3) each of AL, GI and OF togetherwith Q-WordNet and (4) UF and Q-WordNet.
Ta-ble 3 summarizes the outcome of the experimentalstudy.
EEM finds 240, 14 and 2 polarity inconsis-tent words in OF, GI and AL, respectively.
The ratiobetween the number of inconsistent words and thenumber of input words is the highest for OF and thelowest for AL.
The union dictionary has 7,794 wordsand 249 out of them are found to be polarity incon-sistent words.
Recall that we manually correctedthe polarities of 181 words, to the best of our un-derstanding.
So, in effect the three dictionaries have249 + 181 = 430 polarity inconsistent words.
As dis-cussed in the previous section, these may not be allthe polarity inconsistencies in UF.
In general, to findall inconsistencies we need to generate all MUCs.Generating all MUCs is an ?overkill?
and the SATsolvers we use do not implement such a functional-ity.
In addition, the intention of SAT solver design-ers is to use MUCs in a interactive manner.
Thatis, the errors pointed out by a MUC are correctedand then the new improved formula is re-evaluatedby the SAT solver.
If an error is still present a newMUC is reported, and the process repeats until theformula has no errors.
Or, in our problem, until adictionary is consistent.We also paired Q-WordNet with each of theSWDs.
Table 3 presents the results.
Observe that po-larities assigned to the words in AL and GI largelyagree with the polarities assigned to the synsets in1003Q-WordNet.
This is expected for AL because ithas only two nouns and no verb, while Q-WordNethas only 40 adverbs.
Consequently, these two dic-tionaries have limited ?overlay?.
The union dictio-nary and Q-WordNet have substantial inconsisten-cies: the polarity of 455 words in the union dictio-nary disagrees with the polarities assigned to theirunderlying synsets in Q-WordNet.Sentence Level Evaluation We took 10 pairs ofinconsistent words per part of speech; in total, wecollected a set IW of 80 inconsistent words.
Let?w, pos, p?
?
IW , p is the polarity of w. We col-lected 5 sentences for ?w, pos?
from the set of snip-pets returned by Google for query w. We parsedthe snippets and identified the first 5 occurrences ofw with the part of speech pos.
Then two graduatestudents with English background analyzed the po-larities of ?w, pos?
in the 5 sentences.
We countedthe number of times ?w, pos?
appears with polarity pand polarities different from p. We defined an agree-ment scale: total agreement (5/5), most agreement(4/5), majority agreement (3/5), majority disagree-ment (2/5), most disagreement (1/5), total disagree-ment (0/5).
We computed the percentage of wordsper agreement category.
We repeated the experimentfor 40 randomly drawn words (10 per part of speech)from the set of consistent words.
In total 600 sen-tences were manually analyzed.
Figure 1 shows thedistribution of the (in)consistent words.
For exam-ple, the annotators totally agree with the polaritiesof 55% of the consistent words, whereas they onlytotally agree with 16% of the polarities of the incon-sistent words.
The graph suggests that the annota-tors disagree to some extent (total disagreement +most disagreement + major disagreement) with 40%of the polarities of the inconsistent words, whereasthey disagree to some extent with only 5% of theconsistent words.
We also manually investigated thesenses of these words in WordNet.
We noted that36 of the 80 inconsistent words (45%) have missingsenses according to one of these English dictionar-ies: Oxford and Cambridge.Computational Issues We used a 4-core CPUcomputer with 12GB of memory.
EEM requires10GB of memory and cannot handle words withmore than 200,000 MDSs: for UF we left the SATsolver running for a week without ever terminating.In contrast, it takes about 4 hours if we limit the setFigure 1: Human classification of (in)consistent words.of words to those that have up to 200,000 MDSs.EEM could not handle words such as make, giveand break.
Recall however that we did not gener-ate all MUCs.
We do not know how long would thatmight have taken.
(The polynomial method handlesall the words in WordNet and it takes 5GB of mem-ory and about 2 hours to finish.
)7 Related WorkSeveral researchers have studied the problem offinding opinion words (Liu, 2010).
There are twolines of work on sentiment polarity lexicon induc-tion: corpora-based (Hatzivassiloglou and McKe-own, 1997; Kanayama and Nasukawa, 2006; Qiu etal., 2009; Wiebe, 2000) and dictionary-based (An-dreevskaia and Bergler, 2006; Agerri and Garc?
?a-Serrano, 2010; Dragut et al, 2010; Esuli and Se-bastiani, 2005; Baccianella et al, 2010; Hu andLiu, 2004; Kamps et al, 2004; Kim and Hovy,2006; Rao and Ravichandran, 2009; Takamura et al,2005).
Our work falls into the latter.
Most of theseworks use the lexical relations defined in WordNet(e.g., synonym, antonym) to derive sentiment lexi-cons.
To our knowledge, none of the earlier worksstudied the problem of polarity consistency check-ing for a sentiment dictionary.
Our techniques canpinpoint the inconsistencies within individual dictio-naries and across dictionaries.8 ConclusionWe studied the problem of checking polarity consis-tency for sentiment word dictionaries.
We provedthat this problem is NP-complete.
We showed thatin practice polarity inconsistencies of words bothwithin a dictionary and across dictionaries can beobtained using an SAT solver.
The inconsistenciesare pinpointed and this allows the dictionaries to beimproved.
We reported experiments on four senti-ment dictionaries and their union dictionary.1004AcknowledgmentsThis work is supported in part by the following NSFgrants: IIS-0842546 and IIS-0842608.ReferencesRodrigo Agerri and Ana Garc??a-Serrano.
2010.
Q-wordnet: Extracting polarity from wordnet senses.
InLREC.A.
Andreevskaia and S. Bergler.
2006.
Mining word-net for fuzzy sentiment: Sentiment tag extraction fromwordnet glosses.
In EACL.Domagoj Babic, Jesse Bingham, and Alan J. Hu.
2006.B-cubing: New possibilities for efficient sat-solving.TC, 55(11).Stefano Baccianella, Andrea Esuli, and Fabrizio Sebas-tiani.
2010.
SentiWordNet 3.0: An Enhanced LexicalResource for Sentiment Analysis and Opinion Mining.In LREC, Valletta, Malta, May.Luisa Bentivogli, Pamela Forner, Bernardo Magnini, andEmanuele Pianta.
2004.
Revising the wordnet do-mains hierarchy: semantics, coverage and balancing.MLR.Armin Biere.
2008.
PicoSAT essentials.
JSAT, 4(2-4):75?97.Eric Breck, Yejin Choi, and Claire Cardie.
2007.
Identi-fying expressions of opinion in context.
In IJCAI.Cristian Danescu-N.-M., Gueorgi Kossinets, Jon Klein-berg, and Lillian Lee.
2009.
How opinions are re-ceived by online communities: a case study on ama-zon.com helpfulness votes.
In WWW, pages 141?150.Nachum Dershowitz, Ziyad Hanna, and Er Nadel.
2006.A scalable algorithm for minimal unsatisfiable core ex-traction.
In In Proc.
SAT06.
Springer.Xiaowen Ding and Bing Liu.
2010.
Resolving object andattribute coreference in opinion mining.
In COLING.Eduard C. Dragut, Clement T. Yu, A. Prasad Sistla, andWeiyi Meng.
2010.
Construction of a sentimentalword dictionary.
In CIKM, pages 1761?1764.Andrea Esuli and Fabrizio Sebastiani.
2005.
Determin-ing the semantic orientation of terms through glossclassification.
In CIKM, pages 617?624.Jiawei Han.
2005.
Data Mining: Concepts and Tech-niques.
Morgan Kaufmann Publishers Inc.Vasileios Hatzivassiloglou and Kathleen R. McKeown.1997.
Predicting the semantic orientation of adjec-tives.
In ACL, pages 174?181, Stroudsburg, PA, USA.Association for Computational Linguistics.Minqing Hu and Bing Liu.
2004.
Mining and summariz-ing customer reviews.
In ACM SIGKDD, pages 168?177, New York, NY, USA.
ACM.J.
Kamps, M. Marx, R. Mokken, and M. de Rijke.
2004.Using wordnet to measure semantic orientation of ad-jectives.
In LREC.Hiroshi Kanayama and Tetsuya Nasukawa.
2006.
Fullyautomatic lexicon expansion for domain-oriented sen-timent analysis.
In Proceedings of the 2006 Confer-ence on Empirical Methods in Natural Language Pro-cessing, EMNLP ?06, pages 355?363, Stroudsburg,PA, USA.
Association for Computational Linguistics.M.
Kim and E. Hovy.
2004.
Determining the sentimentof opinions.
In COLING.Soo-Min Kim and Eduard Hovy.
2006.
Identifying andanalyzing judgment opinions.
In HLT-NAACL.Bing Liu.
2010.
Sentiment analysis and subjectivity.
InNitin Indurkhya and Fred J. Damerau, editors, Hand-book of Natural Language Processing, Second Edi-tion.
CRC Press, Taylor and Francis Group, Boca Ra-ton, FL.
ISBN 978-1420085921.B.
Pang and L. Lee.
2004.
A sentimental education:Sentiment analysis using subjectivity summarizationbased on minimum cuts.
In ACL.Guang Qiu, Bing Liu, Jiajun Bu, and Chun Chen.
2009.Expanding domain sentiment lexicon through doublepropagation.
In IJCAI, pages 1199?1204.Delip Rao and Deepak Ravichandran.
2009.
Semi-supervised polarity lexicon induction.
In EACL.P.
Stone, D. Dunphy, M. Smith, and J. Ogilvie.
1996.The general inquirer: A computer approach to contentanalysis.
In MIT Press.M.
Taboada and J. Grieve.
2004.
Analyzing appraisalautomatically.
In AAAI Spring Symposium.Hiroya Takamura, Takashi Inui, and Manabu Okumura.2005.
Extracting semantic orientations of words usingspin model.
In ACL, pages 133?140.Janyce Wiebe.
2000.
Learning subjective adjectivesfrom corpora.
In Proceedings of the SeventeenthNational Conference on Artificial Intelligence andTwelfth Conference on Innovative Applications of Ar-tificial Intelligence, pages 735?740.
AAAI Press.T.
Wilson, J. Wiebe, and P. Hoffmann.
2005.
Recogniz-ing contextual polarity in phrase-level sentiment anal-ysis.
In HLT/EMNLP.Lin Xu, Frank Hutter, Holger H. Hoos, and KevinLeyton-Brown.
2008.
Satzilla: portfolio-based algo-rithm selection for sat.
J. Artif.
Int.
Res., 32:565?606,June.1005
