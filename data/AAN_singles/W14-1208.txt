Proceedings of the 3rd Workshop on Predicting and Improving Text Readability for Target Reader Populations (PITR) @ EACL 2014, pages 66?73,Gothenburg, Sweden, April 26-30 2014.c?2014 Association for Computational LinguisticsSegmentation of patent claims for improving their readabilityGabriela Ferraro1 2, Hanna Suominen1?4, Jaume Nualart1 31NICTA / Locked Bag 8001, Canberra ACT 2601, Australia2The Australian National University3University of Canberra4University of Turkufirstname.lastname@nicta.com.auAbstractGood readability of text is importantto ensure efficiency in communicationand eliminate risks of misunderstanding.Patent claims are an example of text whosereadability is often poor.
In this paper,we aim to improve claim readability bya clearer presentation of its content.
Ourapproach consist in segmenting the origi-nal claim content at two levels.
First, anentire claim is segmented to the compo-nents of preamble, transitional phrase andbody, using a rule-based approach.
Sec-ond, a conditional random field is trainedto segment the components into clauses.An alternative approach would have beento modify the claim content which is, how-ever, prone to also changing the mean-ing of this legal text.
For both segmen-tation levels, we report results from sta-tistical evaluation of segmentation perfor-mance.
In addition, a qualitative erroranalysis was performed to understand theproblems underlying the clause segmenta-tion task.
Our accuracy in detecting thebeginning and end of preamble text is 1.00and 0.97, respectively.
For the transitionalphase, these numbers are 0.94 and 1.00and for the body text, 1.00 and 1.00.
Ourprecision and recall in the clause segmen-tation are 0.77 and 0.76, respectively.
Theresults give evidence for the feasibility ofautomated claim and clause segmentation,which may help not only inventors, re-searchers, and other laypeople to under-stand patents but also patent experts toavoid future legal cost due to litigations.1 IntroductionClear language is important to ensure efficiency incommunication and eliminate risks of misunder-standing.
With written text, this clarity is mea-sured by readability.
In the last years, we havewitnessed an increasing amount work towards im-proving text readability.
In general, these effortsfocus on making general text easier to understandto non-native speakers and people with specialneeds, poor literacy, aphasia, dyslexia, or otherlanguage deficits.In this paper, we address making technical textmore readable to laypeople, defined as those with-out professional or specialised knowledge in agiven field.
Technical documentation as scientificpapers or legal contracts are two genres of writ-ten text that are difficult to understand (Albertset al., 2011).
An extreme example that takes theworst from both these worlds is the claim sectionof patent documents: it defines the boundaries ofthe legal protection of the invention by describingcomplex technical issues and using specific legaljargon (Pressman, 2006).
Moreover, due to inter-national conventions, each patent claim must bewritten into a single sentence.
This leads to verylong sentences with complex syntactic structuresthat are hard to read and comprehend not only forlaypeople but also for technical people who are nottrained to read patent claims.As an example of other efforts with similargoals to improve the readability of technical text tolaypeople, we mention the CLEF eHealth sharedtasks in 2013 and 2014 (Suominen et al., 2013).However, instead of inventors, researchers, andother claim readers, they target patients and theirnext-of-kins by developing and evaluating tech-nologies to improve the readability of clinical re-ports and help them in finding further informationrelated to their condition in the Internet.Some proposals have also been made in order toimprove claim readability, for example, by apply-ing simplification, paraphrasing, and summarisa-tion methods (see Section 2).
However, these ap-proaches modify the claim content.
This increases66the risk of changing also the meaning, which is notdesirable in the context of patent claims and otherlegal documents.In this paper, we propose an alternative methodthat focuses on clarifying the presentation of theclaim content rather than its modification.
Sincereadability strongly affects text comprehension(Inui et al., 2003), the aim of this study is to makethe content of the patent claims more legible andconsequently make them easier to comprehend.As the first steps towards this improved presen-tation of the patent claims, we propose to segmentthe original text.
Our approach is data driven andwe perform the segmentation at two levels: first,an entire claim is segmented into three compo-nents (i.e., preamble, transition, and body text) andsecond, the components are further segmented intoclauses.
At the first level, we use a rule-basedmethod and at the second level, we apply a con-ditional random field.We evaluate segmentation performance statisti-cally at both levels and in addition, we analyse er-rors in clause segmentation qualitatively; becauseour performance at the first level is almost perfect(i.e., for detecting the beginning and end of thepreamble, the accuracy percentages are 100 and97 and these numbers are 94 and 100 for the tran-sition and 100 and 100 for the body text), we focuson the errors at the second level alone.
In com-parison, we have the precision of 77 per cent andrecall of 76 per cent in clause segmentation.
Eventhough this performance at the second level is notperfect, it is significantly better than the respec-tive percentages of 41 and 29 (0.2 and 0.3) for abaseline based on both punctuation and keywords(punctuation only).The rest of the paper is organised as follows:Section 2 describes as background informationof this study includes an explanation about whatpatent claims are, how to read them, and what kindof related work exists on claim readability.
Sec-tion 3 outlines our materials and methods.
Section4 presents the experiments results and discussion.Finally, conclusions and ideas for future work arepresented in Section 5.2 Background2.1 Patent claimsPatent documents have a predefined documentstructure that consists of several sections, such asthe title, abstract, background of the invention, de-[Toolholder]p, [comprising]t[a holder body withan insert site at its forward end comprising abottom surface and at least one side wall wherethere projects a pin from said bottom surfaceupon which there is located an insert havinga central bore, a clamping wedge for wedgingengagement between a support surface of theholder and an adjacent edge surface of saidinsert and an actuating screw received in saidwedge whilst threadably engaged in a bore ofsaid holder, said support surface and said edgesurface are at least partially converging down-wards said wedge clamp having distantly pro-vided protrusions for abutment against the topface and the edge surface of said insert, char-acterised in that the wedge consists of a pair ofdistantly provided first protrusions for abutmentagainst a top face of the insert, and a pair ofdistantly provided second protrusions for abut-ment against an adjacent edge surface]b.Figure 1: An example patent claim.
We have usedbrackets to illustrate claim components and thesub-scripts p, t, and b correspond to the preamble,transition, and body text, respectively.scription of the drawings, and claims.
As alreadymentioned, the claims can be seen as the most im-portant section as they define the scope of legalprotection of the invention.
In most modern patentlaws, patent applications must have at least oneclaim (Pressman, 2006).The claims are written into a single sentence be-cause of international conventions.
Figure 1 pro-vides an example claim.Furthermore, a claim should be composed by, atleast, the following parts,1.
Preamble is an introduction, which describesthe class of the invention.2.
Transition is a phrase or linking word that re-lates the preamble with the rest of the claim.The expressions comprising, containing, in-cluding, consisting of, wherein and charac-terise in that are the most common transi-tions.3.
Body text describes the invention and recitesits limitations.We have also included an illustration of theseclaim components in Figure 1.Because a claim is a single sentence, specialpunctuation conventions have been developed andare being used by patent writers.
Modern claimsfollow a format where the preamble is separated67Table 1: Per claim demographicsTraining set Test set# tokens mean 60 66min 7 8max 440 502# boundaries mean 5 5min 1 1max 53 41from the transition by a comma, the transitionfrom the body text by a colon, and each inventionelement in the body text by a semicolon (Radack,1995).
Other specifications regarding punctua-tion are the following text elaboration and elementcombination conventions:- A claim should contain a period only inthe end.- A comma should be used in all natu-ral pauses.- The serial comma1should be used to separatethe elements of a list.- Dashes, quotes, parentheses, and abbrevia-tions should be avoided.Because a claim takes the form of a single sen-tence, long sentences are common.
Meanwhile,in the general discourse (e.g., news articles) sen-tences are composed of twenty to thirty words,claim sentences with over a hundred words arevery frequent (see, e.g., Table 1 related to mate-rials used in this paper).
As a consequence, claimsusually contain several subordinate and coordi-nate clauses, as they enable the aforementionedelaboration and the combination of elements ofequal importance, respectively.As claims are difficult to read and interpret, sev-eral books and tutorials suggest how claims shouldbe read (Radack, 1995; Pressman, 2006).
The firststep towards reading a claim is to identify its com-ponents (i.e., preamble, transition, and body text).Another suggestion is to identify and highlight thedifferent elements of the invention spelled out inthe body text of the claims.1The serial comma (also known as the Oxford comma)is the comma used mediately before a coordination con-junction (e.g., CDs, DVDs, and magnetic tapes where thelast comma indicates that DVDs and magnetic tapes arenot mixed).
http://oxforddictionaries.com (ac-cessed 28 Feb, 2014)The clear punctuation marks and lexical mark-ers enable the claim component segmentation, assuggested above.
Moreover, the predominanceof intra-sentential syntactic structures (e.g., subor-dinate and coordinate constructions) favours seg-menting patent claims into clauses.
These clausescan then be presented as a sequence of segmentswhich is likely to improve claim readability.2.2 Related workSo far, not many studies have addressed the prob-lem of improving the readability of patents claims.In particular, to the best of our knowledge, thereis no research that specifically targets the problemof presenting the claims in a more readable lay-out.
Consequently, we focus on efforts devoted toclaim readability in general with an emphasis ontext segmentation.We begin by discussing three studies that ad-dress text simplification in patent claims.
Note thatthese approaches modify the claim content whichmay also change their meaning.
This is riskier inthe context of patent documents and other legaltext than our approach of clarifying the presen-tation.
Moreover, in order achieve a reasonableperformance, the methods of these studies requiresophisticated tools for discourse analysis and syn-tactic parsing.
Usually these tools also need to betailored to the genre of claim text.First, a parsing methodology to simplify sen-tences in US patent documents has been pro-posed (Sheremetyeva, 2003).
The resulting analy-sis structure is a syntactic dependency tree and thesimplified sentences are generated based on the in-termediate chunking structure of the parser.
How-ever, neither the tools used to simplify sentencesnor the resulting improvement in readability hasbeen formally measured.Second, simplification of Japanese claim sen-tences has been addressed through a rule-basedmethod (Shinmori et al., 2003).
It identifies thediscourse structure of a claim using cue phrasesand lexico-syntactic patterns.
Then it paraphraseseach discourse segment.Third, a claim simplification method to para-phrase and summarise text has been intro-duced (Bouayad-Agha et al., 2009).
It is multilin-gual and consists of claim segmentation, corefer-ence resolution, and discourse tree derivation.
Inclaim segmentation, a rule-based system is com-pared to machine learning with the conclusion of68the former approach outperforming the latter.
Themachine learning approach is, however, very sim-ilar to the clause segmentation task described inthis paper.
They differ in the features used tocharacterized the clause boundaries and in eval-uation.
For the evaluation, these authors use thecosine similarity to calculate a 1:1 term overlapbetween the automated solution and gold standardset whereas we assess whether a token is an accu-rate segment boundary or not.We continue by discussing a complementarymethod to our approach of improving the read-ability of claims through their clearer presentationwithout modifying the text itself.
This work byShinmori et al.
(2012) is inspired by the fact thatclaims must be understood in the light of the def-initions provided in the description section of thepatents.
It aims to enrich the content by aligningclaim phrases with relevant text from the descrip-tion section.
For the evaluation, the authors haveinspected 38 patent documents.
The automatedmethod generates 35 alignments for these docu-ments (i.e., twenty correct and fifteen false) andmisses only six.
It would be interesting to test ifthis alignment method and the claim segmentationproposed in this paper complement each other.We end by noting that the task of segmentingclaim phrases is similar to the task of detectingphrase boundaries by Sang and D?ejean (2001) inthe sense that the segments we want to identify areintra-sentential.
However, the peculiar syntacticstyle of claims makes the phrase detection strate-gies not applicable (see Ferraro (2012) for a de-tailed study on the linguistic idiosyncrasy of patentclaims).3 Materials and methodsIn this paper, we performed statistical experimentsand qualitative error analyses related to two seg-mentation tasks (see Figure 2):1.
Segmenting claims section to the componentsfor preamble, transition, and body text.2.
Segmenting each claim to subordinate andcoordinate clauses.For Task 1, we developed a rule-based methodusing the General Architecture for Text Engineer-ing (GATE) (Cunningham et al., 2011).
The sys-tem had three rules, one for each of the claim partswe were interested in identifying.
The rules wereTable 2: Dataset demographics# claims # segments # wordsTraining set 811 4397 48939Development set 10 15 260Test set 80 491 5517written in terms of JAPE grammars.2In order toprocess the rules, the GATE pipeline illustrated inFigure 3 was applied.
Because transitions shouldmatch with the first instance of a closed set of key-words (we used comprise, consist, wherein, char-acterize, include, have, and contain), our first ruleidentified a transition and, using its boundary in-dices, we restricted the application of our furtherrules.
This resulted in the following applicationorder:transition ??
preamble ??
body text.Our two other rules relied on lexico-syntacticpatterns and punctuation marks.
Note that eventhough punctuation conventions have been devel-oped for claim writing (see Section 2.1), their fol-lowing is not mandatory.
This led us to experi-ment these more complex rules.
The first task wasapplied to the complete dataset (training, develop-ment, and test sets merged into one single dataset)described in Table 2.For Task 2, our method was based on supervisedmachine learning (ML).
To train this ML classi-fier, we used a patent claim corpus annotated withclause boundaries.
This corpus was provided bythe TALN Research Group from Universitat Pom-peu Fabra.
The aim of the segmentation classifierwas to decide whether a claim token is a segmentboundary or not, given a context.
Thus, every to-ken was seen as a candidate for placing a segmentboundary.
Following standard ML traditions, wesplit the dataset in training, development, and testsets (Tables 2 and 1).The corpus was analysed with a transitional3version of Bohnet?s parser (Bohnet and Kuhn,2012).
It was one of the best parsers in the CoNLLShared Task 2009 (Haji?c et al., 2009).2JAPE, a component of GATE, is a finite state transducerthat operates over annotations based on regular expressions.3Patent claim sentences can be very long which im-plies long-distance dependencies.
Therefore, transition-based parsers, which typically have a linear or quadratic com-plexity (Nivre and Nilsson, 2004; Attardi, 2006), are bettersuited for parsing patent sentences than graph-based parsers,which usually have a cubic complexity.69Figure 2: Example of the claim segmentation experimentsANNI Tokenizer ??
RegEx Sentence Splitter ??
OpenNLPPOS Tagger ??
Noun Phrase Chunker ??
JAPEFigure 3: GATE pipeline for Task 1In order to characterise the clause boundaries,the following features were used for each token inthe corpus:- lemma of the current token,- part-of-speech (POS) tag4of the current to-ken as well as POS-tags of the two immedi-ately preceding and two immediately subse-quent words,- syntactic head and dependent of the currenttoken, and- syntactic dependency relation between thecurrent token and its head and dependent to-kens.Moreover, the fifteen most frequent lemmas andfive most frequent POS-tags and punctuationmarks were used as features we called segmenta-tion keywords (Table 3).For classification we used the CRF++ toolkit,an open source implementation of conditional ran-dom fields (Lafferty et al., 2001).
This frameworkfor building probabilistic graphical models to seg-ment and label sequence data has been success-fully applied to solve chunking (Sha and Pereira,4The POS-tag corresponds to the Peen Tree Bank tag set(Marcus et al., 1993) whereas IN = preposition or conjunc-tion, subordinating; CC = Coordinating Conjunction; VBN =Verb, past participle; VBG = verb, gerund or present partici-ple; WRB = Wh-adverb.Table 3: The most frequent lemmas and POS-tagsin the beginning of a segment.Rank Lemmas Abs.
Freq.
Rel.
Freq.1 and 675 0.1372 wherein 554 0.1123 for 433 0.0884 which 174 0.0355 have 158 0.0326 to 155 0.0317 characterize 152 0.0318 a 149 0.0309 the 142 0.02810 say 140 0.02811 is 64 0.01312 that 62 0.01213 form 59 0.01214 in 58 0.01115 when 56 0.011Rank POS-tag Abs.
Freq.
Rel.
Freq.1 IN 739 0.1502 CC 686 0.1393 VBN 511 0.1044 VBG 510 0.1045 WRB 409 0.0832003), information extraction (Smith, 2006), andother sequential labelling problems.
We comparedthe results obtained by CRF++ with the followingbaselines:- Baseline 1: each punctuation mark is a seg-ment boundary, and- Baseline 2: each punctuation mark and key-word is a segment boundary.70Table 4: Evaluation of claim componentsCorrect IncorrectPreamble Beginning 100% 0%End 97% 3%Transition Beginning 94% 6%End 100% 0%Body text Beginning 100% 0%End 100% 0%Performance in Task 1 was assessed using theaccuracy.
Due to the lack of a corpus anno-tated with claims components, we selected twentyclaims randomly and performed the annotationourselves (i.e., one of the authors annotated theclaims).
The annotator was asked to assesswhether the beginning and ending of a claim com-ponent was successfully identified.Performance in Task 2 was evaluated using theprecision, recall, and F-score on the test set.
Weconsidered that clause segmentation is a precisionoriented task, meaning that we emphasised the de-mand for a high precision at the expense of a pos-sibly more modest recall.In order to better understand errors in clausesegmentation, we analysed errors qualitatively us-ing content analysis (Stemler, 2001).
This methodis commonly used in evaluation of language tech-nologies.
Fifty segmentation errors were ran-domly selected and manually analysed by one ofthe authors.4 Results and discussion4.1 Statistical performance evaluation inTasks 1 and 2We achieved a substantial accuracy in Task 1,claim component segmentation (Table 4).
Thatis, the resulting segmentation was almost perfect.This was not surprising since we were processingsimple and well defined types of segments.
How-ever, there was a small mismatch in the bound-ary identification for the preamble and the transi-tion segments.Our ML method clearly outperformed both itsbaselines in Task 2 (Table 5).
It had the precisionof 77 per cent and recall of 76 per cent in clausesegmentation.
The respective percentages were 41and 29 for the baseline based on both punctuationand keywords.
If punctuation was used alone, boththe precision and recall were almost zero.Table 5: Evaluation of claim clausesPrecision Recall F-scoreBaseline 1 0.2% 0.3% 2.6%Baseline 2 41% 29% 34%CRF++ 77% 76% 76%4.2 Qualitative analysis of errors in Task 2The most common errors in clause segmentationwere due to two reasons: first, ambiguity in co-ordinating conjunctions (e.g., commas as wll asand, or, and other particles) and second, consec-utive segmentation keywords.Segmentation errors caused by ambiguous coor-dinating conjunctions were due to the fact that notall of them were used as segment delimiters.
Letus illustrate this with the following automaticallysegmented claim fragment with two coordinatingconjunctions (a segment is a string between squarebrackets, the integer sub-script indicating the seg-ment number, and the conjunctions in italics):.
.
.
[said blade advancing member comprises a wormrotatable by detachable handle]1[or key]2[and meshin-georm wheel secured to a shift]3. .
.In this example, the two conjunctions were con-sidered as segment delimiters which resulted inan incorrect segmentation.
The correct analysiswould have been to maintain the fragment as a sin-gle segment since simple noun phrases are not an-notated as individual segments in our corpus.Segmentation errors due to consecutive seg-mentation keywords resulted in undesirable seg-ments only once in our set of fifty cases.
This hap-pened because the classifier segmented every en-counter with a segmentation keyword, even whenthe keywords were consecutive.
We illustrate thiscase with the following example, which containstwo consecutive keywords, a verb in past partici-ple (selected) and a subordinate conjunction (for).Example (a) shows a wrong segmentation, whileexample (b) shows its correct segmentation.. .
.
(a) [said tool to be]1[selected]2[for the next work-ing operation]3. .
.. .
.
(b) [said tool to be selected]1[for working]2. .
.In general, correcting both these error typesshould be relatively straightforward.
First, to solvethe problem of ambiguous commas, a possible so-lution could be to constrain their application askeywords, for example, by combining commas71with other context features.
Second, segmentationerrors caused by consecutive segmentation key-words could be solved, for example, by applying aset of correction rules after the segmentation algo-rithm (Tjong and Sang, 2001).5 Conclusion and future workIn this paper we have presented our on-going re-search on claim readability.
We have proposed amethod that focuses on presenting the claims ina clearer way rather than modifying their text con-tent.
This claim clarity is an important characteris-tic for inventors, researchers, and other laypeople.It may also be useful for patent experts, becauseclear clauses may help them to avoid future legalcost due to litigations.
Moreover, better capabili-ties to understand patent documents contribute todemocratisation of the invention and, therefore, tohuman knowledge.For future work, we plan to conduct a user-centered evaluation study on claim readability.
Wewish to ask laypeople and patents experts to as-sess the usability and usefulness of our approach.Furthermore, we plan to consider text highlight-ing, terminology linking to definitions, and othercontent enrichment functionalities as ways of im-proving claim readability.AcknowledgmentsNICTA is funded by the Australian Governmentthrough the Department of Communications andthe Australian Research Council through the ICTCentre of Excellence Program.
We also expressour gratitude to the TALN Research Group fromUniversitat Pompeu Fabra for their corpus devel-opment.
Finally, we thank the anonymous review-ers of The 3rd Workshop on Predicting and Im-proving Text Readability for Target Reader Popu-lations (PITR 2014), held in conjunction with the14th Conference of the European Chapter of theAssociation for Computational Linguistics (EACL2014), for their comments and suggestions.ReferencesD.
Alberts, C. Barcelon Yang, D. Fobare-DePonio,K.
Koubek, S. Robins, M. Rodgers, E. Simmons,and D. DeMarco.
2011.
Introduction to patentsearching.
In M Lupu, J Tait, .
Mayer, and A JTrippe, editors, Current Challenges in Patent In-formation Retrieval, pages 3?44, Toulouse, France.Springer.G.
Attardi.
2006.
Experiments with a multilanguagenon-projective dependency parser.
In Proceedingsof the Tenth Conference on Computational NaturalLanguage Learning, CoNLL-X ?06, pages 166?170,Stroudsburg, PA, USA.
Association for Computa-tional Linguistics.B.
Bohnet and J. Kuhn.
2012.
The best of both worlds:a graph-based completion model for transition-based parsers.
In Proceedings of the 13th Confer-ence of the European Chapter of the Association forComputational Linguistics, EACL ?12, pages 77?87,Stroudsburg, PA, USA.
Association for Computa-tional Linguistics.N.
Bouayad-Agha, G. Casamayor, G. Ferraro, S. Mille,V.
Vidal, and Leo Wanner.
2009.
Improving thecomprehension of legal documentation: the case ofpatent claims.
In Proceedings of the 12th Interna-tional Conference on Artificial Intelligence and Law,ICAIL ?09, pages 78?87, New York, NY, USA.
As-sociation for Computing Machinery.H.
Cunningham, D. Maynard, K. Bontcheva, V. Tablan,N.
Aswani, I. Roberts, G. Gorrell, A. Funk,A.
Roberts, D. Damljanovic, T. Heitz, M. A. Green-wood, H. Saggion, J. Petrak, Y. Li, and W. Peters.2011.
Text Processing with GATE (Version 6).
Gate-way Press CA, Shefield.
UK.G.
Ferraro.
2012.
Towards Deep Content Extrac-tion: The Case of Verbal Relations in Patent Claims.PhD Thesis.
Department of Information and Com-munication Technologies, Pompeu Fabra Univesity,Barcelona.
Catalonia.
Spain.J.
Haji?c, M. Ciaramita, R. Johansson, D. Kawahara,M.
A.
Mart, L. M?arquez, A. Meyers, J. Nivre,S.
Pad, J. Stepanek, et al.
2009.
The CoNLL-2009shared task: syntactic and semantic dependenciesin multiple languages.
In Proceedings of the Thir-teenth Conference on Computational Natural Lan-guage Learning: Shared Task, page 118, Strouds-burg, PA, USA.
Association for Computational Lin-guistics.K.
Inui, A. Fujita, T. Takahashi, R. Iida, and T. Iwakura.2003.
Text simplification for reading assistance: Aproject note.
In In Proceedings of the 2nd Interna-tional Workshop on Paraphrasing: Paraphrase Ac-quisition and Applications, IWP ?03, pages 9?16,Stroudsburg, PA, USA.
Association for Computa-tional Linguistics.D.
Lafferty, A. McCallum, and F. C. N. Pereira.
2001.Conditional random fields: Probabilistic models forsegmenting and labeling sequence data.
In Proceed-ings of the Eighteenth International Conference onMachine Learning, ICML ?01, pages 282?289, SanFrancisco, CA, USA.
Morgan Kaufmann PublishersInc.M.
P. Marcus, B. Santorini, and M. A. Marcinkiewicz.1993.
Building a large annotated corpus of En-glish: The Penn Treebank.
Computational Linguis-tics, 19(2):313?330.72J.
Nivre and J. Nilsson.
2004.
Memory-based depen-dency parsing.
In Proceedings of the Eight Confer-ence on Computational Natural Language Learning,CoNLL ?04, Stroudsburg, PA, USA.
Association forComputational Linguistics.D.
Pressman.
2006.
Patent It Yourself.
Nolo, Berkeley,CA.D.
V. Radack.
1995.
Reading and understanding patentclaims.
JOM, 47(11):69?69.E.
T. K. Sang and H. D?ejean.
2001.
Introduction to theCoNLL-2001 shared task: Clause identification.
InW.
Daelemans and R. Zajac, editors, Proceedings ofthe Fith Conference on Computational Natural Lan-guage Learning, volume 7 of CoNLL ?01, pages 53?57, Toulouse, France.F.
Sha and F. Pereira.
2003.
Shallow parsing with con-ditional random fields.
In Proceedings of the 2003Conference of the North American Chapter of theAssociation for Computational Linguistics on Hu-man Language Technology, volume 1 of NAACL ?03,pages 134?141, Stroudsburg, PA, USA.
Associationfor Computational Linguistics.S.
Sheremetyeva.
2003.
Natural language analysisof patent claims.
In Proceedings of the ACL 2003Workshop on Patent Processing, ACL ?03, Strouds-burg, PA, USA.
Association for Computational Lin-guistics.A.
Shinmori, M. Okumura, Y. Marukawa, andM.
Iwayama.
2003.
Patent claim processing forreadability: structure analysis and term explana-tion.
In Proceedings of the ACL-2003 Workshop onPatent Corpus Processing, volume 20 of PATENT?03, pages 56?65, Stroudsburg, PA, USA.
Associa-tion for Computational Linguistics.A.
Shinmori, M. Okumura, and Marukawa.
2012.Aligning patent claims with the ?detailed descrip-tion?
for readability.
Journal of Natural LanguageProcessing, 12(3):111?128.A.
Smith.
2006.
Using Gazetteers in discrimina-tive information extraction.
In Proceedings of theTenth Conference on Computational Natural Lan-guage Learning, CoNLL ?06, pages 10?8, Strouds-burg, PA, USA.
Association for Computational Lin-guistics.S.
Stemler.
2001.
An overview of content analy-sis.
Practical Assessment, Research and Evaluation,7(17).H.
Suominen, S. Salantera, S. Velupillai, W. W. Chap-man, G. Savova, N. Elhadad, S. Pradhan, B. R.South, D. L. Mowery, G. J. F. Jones, J. Leveling,L.
Kelly, L. Goeuriot, Da Martinez, and Gu Zuc-con.
2013.
Overview of the ShARe/CLEF eHealthEvaluation Lab 2013.
In Pa Forner, H M?uller, R Pa-rades, P Rosso, and B Stein, editors, InformationAccess Evaluation: Multilinguality, Multimodality,and Visualization.
Proceedings of the 4th Interna-tional Conference of the CLEF Initiative, volume8138 of Lecture Notes in Computer Science, pages212?231, Heidelberg, Germany.
Springer.E.
F. Tjong and Kim Sang.
2001.
Memory-based clause identification.
In Proceedings of the2001 workshop on Computational Natural Lan-guage Learning - Volume 7, ConLL ?01, Strouds-burg, PA, USA.
Association for Computational Lin-guistics.73
