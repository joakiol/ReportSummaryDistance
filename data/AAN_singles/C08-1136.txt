Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 1081?1088Manchester, August 2008Extracting Synchronous Grammar RulesFrom Word-Level Alignments in Linear TimeHao Zhang and Daniel GildeaComputer Science DepartmentUniversity of RochesterRochester, NY 14627, USADavid ChiangInformation Sciences InstituteUniversity of Southern CaliforniaMarina del Rey, CA 90292, USAAbstractWe generalize Uno and Yagiura?s algo-rithm for finding all common intervals oftwo permutations to the setting of twosequences with many-to-many alignmentlinks across the two sides.
We show howto maximally decompose a word-alignedsentence pair in linear time, which can beused to generate all possible phrase pairsor a Synchronous Context-Free Grammar(SCFG) with the simplest rules possible.We also use the algorithm to preciselyanalyze the maximum SCFG rule lengthneeded to cover hand-aligned data fromvarious language pairs.1 IntroductionMany recent syntax-based statistical machinetranslation systems fall into the general formalismof Synchronous Context-Free Grammars (SCFG),where the grammar rules are found by first align-ing parallel text at the word level.
From word-level alignments, such systems extract the gram-mar rules consistent either with the alignmentsand parse trees for one of languages (Galley etal., 2004), or with the the word-level alignmentsalone without reference to external syntactic anal-ysis (Chiang, 2005), which is the scenario we ad-dress here.In this paper, we derive an optimal, linear-timealgorithm for the problem of decomposing an ar-bitrary word-level alignment into SCFG rules suchthat each rule has at least one aligned word and isminimal in the sense that it cannot be further de-composed into smaller rules.
Extracting minimalrules is of interest both because rules with fewerwords are more likely to generalize to new data,c?
2008.
Licensed under the Creative CommonsAttribution-Noncommercial-Share Alike 3.0 Unported li-cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).Some rights reserved.and because rules with lower rank (the number ofnonterminals on the right-hand side) can be parsedmore efficiently.This algorithm extends previous work on factor-ing permutations to the general case of factoringmany-to-many alignments.
Given two permuta-tions of n, a common interval is a set of numbersthat are consecutive in both.
The breakthroughalgorithm of Uno and Yagiura (2000) computesall K common intervals of two length n permu-tations in O(n + K) time.
This is achieved bydesigning data structures to index possible bound-aries of common intervals as the computation pro-ceeds, so that not all possible pairs of beginningand end points need to be considered.
Landau etal.
(2005) and Bui-Xuan et al (2005) show that allcommon intervals can be encoded in O(n) space,and adapt Uno and Yagiura?s algorithm to producethis compact representation in O(n) time.
Zhangand Gildea (2007) use similar techniques to factor-ize Synchronous Context Free Grammars in lineartime.These previous algorithms assume that the inputis a permutation, but in machine translation it iscommon to work with word-level alignments thatare many-to-many; in general any set of pairs ofwords, one from each language, is a valid align-ment for a given bilingual sentence pair.
In thispaper, we consider a generalized concept of com-mon intervals given such an alignment: a commoninterval is a pair of phrases such that no word pairin the alignment links a word inside the phraseto a word outside the phrase.
Extraction of suchphrases is a common feature of state-of-the-artphrase-based and syntax-based machine transla-tion systems (Och and Ney, 2004a; Chiang, 2005).We generalize Uno and Yagiura?s algorithm to thissetting, and demonstrate a linear time algorithmfor a pair of aligned sequences.
The output is a treerepresentation of possible phrases, which directlyprovides a set of minimal synchronous grammar1081rules for an SCFG-based machine translation sys-tem.
For phrase-based machine translation, onecan also read all phrase pairs consistent with theoriginal alignment off of the tree in time linear inthe number of such phrases.2 Alignments and Phrase PairsLet [x, y] denote the sequence of integers betweenx and y inclusive, and [x, y) the integers betweenx and y ?
1 inclusive.
An aligned sequence pairor simply an alignment is a tuple (E,F,A), whereE = e1?
?
?
enand F = f1?
?
?
fmare strings, andA is a set of links (x, y), where 1 ?
x ?
n and1 ?
y ?
m, connecting E and F .
For most of thispaper, since we are not concerned with the identityof the symbols in E and F , we will assume forsimplicity that ei= i and fj= j, so that E =[1, n] and F = [1,m].In the context of statistical machine translation(Brown et al, 1993), we may interpretE as an En-glish sentence, F its translation in French, and Aa representation of how the words correspond toeach other in the two sentences.
A pair of sub-strings [s, t] ?
E and [u, v] ?
F is a phrase pair(Och and Ney, 2004b) if and only if the subset oflinks emitted from [s, t] in E is equal to the sub-set of links emitted from [u, v] in F , and both arenonempty.Figure 1a shows an example of a many-to-many alignment, where E = [1, 6], F =[1, 7], and A = {(1, 6), (2, 5), (2, 7), (3, 4),(4, 1), (4, 3), (5, 2), (6, 1), (6, 3)}.
The eightphrase pairs in this alignment are:([1, 1], [6, 6]), ([1, 2], [5, 7]),([3, 3], [4, 4]), ([1, 3], [4, 7]),([5, 5], [2, 2]), ([4, 6], [1, 3]),([3, 6], [1, 4]), ([1, 6], [1, 7]).In Figure 1b, we show the alignment matrix rep-resentation of the given alignment.
By default, thecolumns correspond to the tokens in E, the rowscorrespond to the tokens in F , and the black cellsin the matrix are the alignment links in A. Usingthe matrix representation, the phrase pairs can beviewed as submatrices as shown with the black-lined boundary boxes.
Visually, a submatrix rep-resents a phrase pair when it contains at least onealignment link and there are no alignment links di-rectly above, below, or to the right or left of it.e1e2e3e4e5e6f1f2f3f4f5f6f71122334455667(a) (b)Figure 1: An example of (a) a many-to-manyalignment and (b) the same alignment as a matrix,with its phrase pairs marked.2.1 Number of Phrase PairsIn this section, we refine our definition of phrasepairs with the concept of tightness and give anasymptotic upper bound on the total number ofsuch phrase pairs as the two sequences?
lengthsgrow.
In the original definition, the permissivemany-to-many constraint allows for unaligned to-kens in both sequences E and F .
If there is an un-aligned token adjacent to a phrase pair, then thereis also a phrase pair that includes the unalignedtoken.
We say that a phrase pair ([s, t], [u, v]) istight if none of es, et, fuand fvis unaligned.
Byfocusing on tight phrase pairs, we eliminate thenon-tight ones that share the same set of alignmentlinks with their tight counterpart.Given [s, t] in E, let l be the first member ofF that any position in [s, t] links to, and let u bethe last.
According to the definition of tight phrasepair, [l, u] is the only candidate phrase in F to pairup with [s, t] in E. So, the total number of tightphrase pairs is upper-bounded by the total numberof intervals in each sequence, which is O(n2).If we do not enforce the tightness constraint, thetotal number of phrase pairs can grow much faster.For example, if a sentence contains only a singlealignment link between the midpoint of F and themidpoint of E, then there will be O(n2m2) possi-ble phrase pairs, but only a single tight phrase pair.From now on, term phrase pair always refers to atight phrase pair.2.2 Hierarchical Decomposition of PhrasePairsIn this section, we show how to encode all the tightphrase pairs of an alignment in a tree of sizeO(n).Lemma 2.1.
When two phrase pairs overlap, theintersection, the differences, and the union of thetwo are also phrase pairs.The following picture graphically represents thetwo possible overlapping structures of two phrase1082([1, 6], [1, 7])([1, 3], [4, 7])([1, 2], [5, 7])([1, 1], [6, 6])([3, 3], [4, 4])([4, 6], [1, 3])([5, 5], [2, 2])Figure 2: The normalized decomposition tree ofthe alignment in Figure 1.pairs: ([s, t], [u, v]) and ([s?, t?
], [u?, v?
]).s s?
t t?uu?vv?s s?
t t?u?uv?vLet AB and BC be two overlapping Englishphrases, with B being their overlap.
There are sixpossible phrases, A, B, C, AB, BC, and ABC,but if we omit BC, the remainder are nested andcan be represented compactly by ((AB)C), fromwhich BC can easily be recovered.
If we system-atically apply this to the whole sentence, we obtaina hierarchical representation of all the phrase pairs,which we call the normalized decomposition tree.The normalized decomposition tree for the exam-ple is shown in Figure 2.Bui-Xuan et al (2005) show that the family ofcommon intervals is weakly partitive, i.e.
closedunder intersection, difference and union.
This al-lows the family to be represented as a hierarchi-cal decomposition.
The normalized decomposi-tion focuses on the right strong intervals, thosethat do not overlap with any others on the right.Lemma 2.1 shows that the family of phrase pairsis also a weakly partitive family and can be hierar-chically decomposed after normalization.
A minordifference is we prefer left strong intervals sinceour algorithms scan F from left to right.
Anotherdifference is that we binarize a linearly-arrangedsequence of non-overlapping phrase pairs insteadof grouping them together.In the following sections, we show how to pro-duce the normalized hierarchical analysis of agiven alignment.3 Shift-Reduce AlgorithmIn this section, we present anO(n2+m+|A|) algo-rithm that is similar in spirit to a shift-reduce algo-rithm for parsing context-free languages.
This al-gorithm is not optimal, but its left-to-right bottom-up control will form the basis for the improved al-gorithm in the next section.First, we can efficiently test whether a span[x, y] is a phrase as follows.
Define a pair of func-tions l(x, y) and u(x, y) that record the minimumand maximum, respectively, of the positions on theFrench side that are linked to the positions [x, y]:l(x, y) = min{j | (i, j) ?
A, i ?
[x, y]}u(x, y) = max{j | (i, j) ?
A, i ?
[x, y]}Note that l(?, y) is monotone increasing and u(?, y)is monotone decreasing.
Define a step of l(?, y)(or u(?, y)) to be a maximal interval over whichl(?, y) (resp., u(?, y)) is constant.
We can computeu(x, y) in constant time from its value on smallerspans:u(x, y) = max{u(x, z), u(z + 1, y)}and similarly for l(x, y).We define the following functions to count thenumber of links emitted from prefixes of F and E:Fc(j) = |{(i?, j?)
?
A | j??
j}|Ec(i) = |{(i?, j?)
?
A | i??
i}|Then the difference Fc(u) ?
Fc(l ?
1) counts thetotal number of links to positions in [l, u], andEc(y)?Ec(x?1) counts the total number of linksto positions in [x, y].
Ecand Fccan be precom-puted in O(n + m + |A|) time.Finally, letf(x, y) = Fc(u(x, y))?
Fc(l(x, y)?
1)?
(Ec(y)?
Ec(x?
1))Note that f is non-negative, but not monotonic ingeneral.
Figure 4 provides a visualization of u, l,and f for the example alignment from Section 2.This gives us our phrase-pair test:Lemma 3.1.
[x, y] and [l(x, y), u(x, y)] are aphrase pair if and only if f(x, y) = 0.This test is used in the following shift-reduce-style algorithm:X ?
{1}for y ?
[2, n] from left to right doappend y to Xfor x ?
X from right to left docompute u(x, y) from u(x + 1, y)compute l(x, y) from l(x + 1, y)if f(x, y) = 0 then[x, y] is a phrase1083remove [x+ 1, y] from Xend ifend forend forIn the worst case, at each iteration we traversethe entire stack X without a successful reduction,indicating that the worst case time complexity isO(n2).4 A Linear AlgorithmIn this section, we modify the shift-reduce algo-rithm into a linear-time algorithm that avoids un-necessary reduction attempts.
It is a generalizationof Uno and Yagiura?s algorithm.4.1 MotivationThe reason that our previous algorithm is quadraticis that for each y, we try every possible combina-tion with the values in X .
Uno and Yagiura (2000)point out that in the case of permutations, it is notnecessary to examine all spans, because it is pos-sible to delete elements from X so that f(?, y) ismonotone decreasing on X .
This means that allthe x ?
X such that f(x, y) = 0 can always beconveniently found at the end of X .
That this canbe done safely is guaranteed by the following:Lemma 4.1.
If x1< x2< y and f(x1, y) <f(x2, y), then for all y??
y, f(x2, y?)
> 0 (i.e.,[x2, y?]
is not a phrase).Let us say that x2violates monotonicity if x1is the predecessor of x2in X and f(x1, y) <f(x2, y).
Then by Lemma 4.1, we can safely re-move x2from X .Furthermore, Uno and Yagiura (2000) show thatwe can enforce monotonicity at all times in such away that the whole algorithm runs in linear time.This is made possible with a shortcut based on thefollowing:Lemma 4.2.
If x1< x2< y and u(x1, y ?
1) >u(x2, y ?
1) but u(x1, y) = u(x2, y), then for ally??
y, f(x2, y?)
> 0 (i.e., [x2, y?]
is not a phrase).The same holds mutatis mutandis for l.Let us say that y updates a step [x?, y?]
of u (orl) if u(x?, y) > u(x?, y ?
1) (resp., l(x?, y) <l(x?, y?1)).
By Lemma 4.2, if [x1, y1] and [x2, y2]are different steps of u(?, y ?
1) (resp., l(?, y ?
1))and y updates both of them, then we can removefrom X all x?such that x2?
x?< y.u(?, y ?
1)l(?, y ?
1)u(?, y)l(?, y)x?1y?2yx?2y?1Figure 3: Illustration of step (3) of the algorithm.The letters indicate substeps of (3).4.2 Generalized algorithmThese results generalize to the many-to-manyalignment case, although we must introduce a fewnuances.
The new algorithm proceeds as follows:Initialize X = {1}.
For y ?
[2, n] from left toright:1.
Append y to X .2.
Update u and l:(a) Traverse the steps of u(?, y ?
1) fromright to left and compute u(?, y) until wehave found the leftmost step [x?, y?]
ofu(?, y ?
1) that gets updated by y.
(b) Do the same for l.We have computed two values for x?
; let x?1be the smaller and x?2be the larger.
Similarly,let y?1be the smaller y?.3.
Enforce monotonicity of f(?, y) (see Fig-ure 3):(a) The positions left of the smaller x?al-ways satisfy monotonicity, so do noth-ing.
(b) For x ?
[x?1, x?2) ?
X while x violatesmonotonicity, remove x from X .
(c) For x ?
[x?2, y?1] ?
X while x violatesmonotonicity, remove x from X .
(d) The steps right of y?1may or may notviolate monotonicity, but we use thestronger Lemma 4.2 to delete all of them(excluding y).11In the special case where [x?, y?]
is updated by y to the1084y = 1 :1122334455667u, lx1021324354656fxy = 2 :1122334455667u, lx1021324354656fxy = 3 :1122334455667u, lx1021324354656fxy = 4 :1122334455667u, lx1021324354656fxy = 5 :1122334455667u, lx1021324354656fxy = 6 :1122334455667u, lx1021324354656fxFigure 4: The evolution of u(x, y) , l(x, y), and f(x, y) as y goes from 1 to 6 for the example alignment.Each pair of diagrams shows the state of affairs between steps (3) and (4) of the algorithm.
Light greyboxes are the steps of u, and darker grey boxes are the steps of l. We use solid boxes to plot the valuesof remaining x?s on the list but also show the other values in empty boxes for completeness.
(e) Finally, if y violates monotonicity, re-move it from X .4.
For x ?
X from right to left until f(x, y) >0, output [x, y] and remove x?s successor inX .2An example of the algorithm?s execution isshown in Figure 4.
The evolution of u(x, y),l(x, y), and f(x, y) is displayed for increasing y(from 1 to 6).
We point out the interesting steps.When y = 2, position 2 is eliminated due to step(3e) of our algorithm to ensure monotonicity off at the right end, and [1, 2] is reduced.
Whensame value as the step to its left, we can use Lemma 4.2 todelete [x?, y?]
and y as well, bypassing steps (3b),(3c), and(3e).2If there are any such x, they must lie to the left of x?1.Therefore a further optimization would be to perform step (4)before step (3), starting with the predecessor of x?1.
If a re-duction is made, we can jump to step (3e).y = 3, two reductions are made: one on [3, 3] andthe other on [1, 3].
Because of leftmost normaliza-tion, position 3 is deleted.
When y = 6, we havex?1= x?2= y?1= 5, so that position 5 is deleted bystep (3c) and position 6 is deleted by step (3e).4.3 CorrectnessWe have already argued in Section 4.1 that thedeletion of elements fromX does not alter the out-put of the algorithm.
It remains to show that step(3) guarantees monotonicity:Claim 4.3.
For all y, at the end of step (3), f(?, y)is monotone decreasing.Proof.
By induction on y.
For y = 1, the claimis trivially true.
For y > 1, we want to showthat for x1, x2adjacent in X such that x1< x2,f(x1, y) ?
f(x2, y).
We consider the five regionsof X covered by step (3) (cf.
Figure 3), and then1085the boundaries between them.Region (a): x1, x2?
[1, x?1].
Since u(xi, y) =u(xi, y ?
1) and l(xi, y) = l(xi, y ?
1), we have:f(xi, y)?f(xi, y?1) = 0?
(Ec(y)?Ec(y?1))i.e., in this region, f shifts down uniformly fromiteration y ?
1 to iteration y.
Hence, if f(?, y ?1) was monotonic, then f(?, y) is also monotonicwithin this region.Region (b): x1, x2?
[x?1, x?2).
Since u(x1, y ?1) = u(x2, y ?
1) and u(x1, y) = u(x2, y) andsimilarly for l, we have:f(x1, y)?
f(x1, y?
1) = f(x2, y)?
f(x2, y?
1)i.e., in this region, f shifts up or down uniformly.3Hence, if f(?, y ?
1) was monotonic, then f(?, y)is also monotonic within this region.Region (c): x1, x2?
[x?2, y?1].
Same as Case 2.Region (d) and (e): Vacuous (these regions have atmost one element).The remaining values of x1, x2are those thatstraddle the boundaries between regions.
Butstep (3) of the algorithm deals with each ofthese boundaries explicitly, deleting elements untilf(x1) ?
f(x2).
Thus f(?, y) is monotonic every-where.4.4 Implementation and running timeX should be implemented in a way that allowslinear-time traversal and constant-time deletion;also, u and l must be implemented in a way thatallows linear-time traversal of their steps.
Doubly-linked lists are appropriate for all three functions.Claim 4.4.
The above algorithm runs in O(n +m + |A|) time.We can see that the algorithm runs in linear timeif we observe that whenever we traverse a part ofX , we delete it, except for a constant amount ofwork per iteration (that is, per value of y): the stepstraversed in (2) are all deleted in (3d) except four(two for u and two for l); the positions traversed in(3b), (3c), and (4) are all deleted except one.4.5 SCFG Rule extractionThe algorithm of the previous section outputs thenormalized decomposition tree depicted in Fig-ure 2.
From this tree, it is straightforward to obtain3It can be shown further that in this region, f shifts up oris unchanged.
Therefore any reductions in step (4) must be inregion (a).A?
B(1)C(2), C(2)B(1)B ?
D(1)E(2), E(2)D(1)D ?
G(1)e2, f5G(1)f6G?
e1, f6E ?
e3, f4C ?
e4F(1)e6, f1F(1)f3F ?
e5, f2Figure 5: Each node from the normalized decom-position tree of Figure 2 is converted into an SCFGrule.a set of maximally-decomposed SCFG rules.
Asan example, the tree of Figure 2 produces the rulesshown in Figure 5.We adopt the SCFG notation of Satta and Pe-serico (2005).
Each rule has a right-hand side se-quence for both languages, separated by a comma.Superscript indices in the right-hand side of gram-mar rules such as:A?
B(1)C(2), C(2)B(1)indicate that the nonterminals with the same indexare linked across the two languages, and will even-tually be rewritten by the same rule application.The example above inverts the order of B and Cwhen translating from the source language to thetarget language.The SCFG rule extraction proceeds as follows.Assign a nonterminal label to each node in the tree.Then for each node (S, T ) in the tree top-down,where S and T are sequences of positions,1.
For each child (S?, T?
), S?and T?must besubsequences of S and T , respectively.
Re-place their occurrences in S and T with a pairof coindexed nonterminals X?, where X?isthe nonterminal assigned to the child.2.
For each remaining position i in S, replace iwith ei.3.
For each remaining position j in T , replace jwith fj.4.
Output the rule X ?
S, T , where X is thenonterminal assigned to the parent.As an example, consider the node ([4, 6], [1, 3])in Figure 2.
After step 1, it becomes(4F(1)6, 1F(1)3)and after steps 2 and 3, it becomes(e4F(1)e6, f1F(1)f3)10860 1 2 3 4 5 6Hindi/English 52.8 53.5 99.9 99.9 100.0Chinese/English 51.0 52.4 99.7 99.8 100.0 100.0 100.0French/English 52.1 53.5 99.9 100.0 100.0 100.0Romanian/English 50.8 52.6 99.9 99.9 100.0 100.0Spanish/English 50.7 51.8 99.9 100.0 100.0 100.0Table 1: Cumulative percentages of rule tokens by number of nonterminals in right-hand side.
A blankindicates that no rules were found with that number of nonterminals.Finally, step 4 outputsC ?
e4F(1)e6, f1F(1)f3A few choices are available to the user depend-ing on the application intended for the SCFG ex-traction.
The above algorithm starts by assigninga nonterminal to each node in the decompositiontree; one could assign a unique nonterminal to eachnode, so that the resulting grammar produces ex-actly the set of sentences given as input.
But formachine translation, one may wish to use a singlenonterminal, such that the extracted rules can re-combine freely, as in Chiang (2005).Unaligned words in either language (an emptyrow or column in the alignment matrix, not presentin our example) will be attached as high as possi-ble in our tree.
However, other ways of handlingunaligned words are possible given the decompo-sition tree.
One can produce all SCFG rules con-sistent with the alignment by, for each unalignedword, looping through possible attachment pointsin the decomposition tree.
In this case, the num-ber of SCFG rules produced may be exponentialin the size of the original input sentence; however,even in this case, the decomposition tree enables arule extraction algorithm that is linear in the outputlength (the number of SCFG rules).4.6 Phrase extractionWe briefly discuss the process of extracting allphrase pairs consistent with the original alignmentfrom the normalized decomposition tree.
First ofall, every node in the tree gives a valid phrasepair.
Then, in the case of overlapping phrase pairssuch as the example in Section 2.1, the decom-position tree will contain a left-branching chainof binary nodes all performing the same permuta-tion.
While traversing the tree, whenever we iden-tify such a chain, let ?1, .
.
.
, ?kbe the sequence ofall the children of the nodes in the chain.
Then,each of the subsequences {?i, .
.
.
, ?j| 1 < i <j ?
k} yields a valid phrase pair.
In our exam-ple, the root of the tree of Figure 2 and its leftchild form such a chain, with three children; thesubsequence {([3, 3], [4, 4]), ([4, 6], [1, 3])} yieldsthe phrase ([3, 6], [1, 4]).
In the case of unalignedwords, we can also consider all combinations oftheir attachments, as discussed for SCFG rule ex-traction.5 Experiments on Analyzing WordAlignmentsOne application of our factorization algorithmis analyzing human-annotated word alignments.Wellington et al (2006) argue for the necessityof discontinuous spans (i.e., for a formalism be-yond Synchronous CFG) in order for synchronousparsing to cover human-annotated word alignmentdata under the constraint that rules have a rankof no more than two.
In a related study, Zhangand Gildea (2007) analyze the rank of the Syn-chronous CFG derivation trees needed to parse thesame data.
The number of discontinuous spansand the rank determine the complexity of dynamicprogramming algorithms for synchronous parsing(alignment) or machine translation decoding.Both studies make simplifying assumptions onthe alignment data to avoid dealing with many-to-many word links.
Here, we apply our alignmentfactorization algorithm directly to the alignmentsto produce a normalized decomposition tree foreach alignment and collect statistics on the branch-ing factors of the trees.We use the same alignment data for thefive language pairs Chinese-English, Romanian-English, Hindi-English, Spanish-English, andFrench-English as Wellington et al (2006).
Ta-ble 1 reports the number of rules extracted by therank, or number of nonterminals on the right-handside.
Almost all rules are binary, implying boththat binary synchronous grammars are adequatefor MT, and that our algorithm can find such gram-mars.
Table 2 gives similar statistics for the num-ber of terminals in each rule.
The phrases we ex-tract are short enough that they are likely to gener-alize to new sentences.
The apparent difficulty of10870 1 2 3 4 5 6 7 8 9 ?10 maxHindi/English 39.6 92.2 97.7 99.5 99.7 99.9 99.9 100.0 7Chinese/English 39.8 87.2 96.2 99.0 99.7 99.9 100.0 100.0 100.0 100.0 100.0 12French/English 44.5 89.0 93.4 95.8 97.5 98.4 99.0 99.3 99.6 99.8 100.0 18Romanian/English 42.9 89.8 96.9 98.9 99.5 99.8 99.9 100.0 100.0 9Spanish/English 47.5 91.8 97.7 99.4 99.9 99.9 100.0 100.0 100.0 9Table 2: Cumulative percentages of rule tokens by number of terminals in right-hand side.
A blankindicates that no rules were found with that number of terminals.the French-English pair is due to the large numberof ?possible?
alignments in this dataset.6 ConclusionBy extending the algorithm of Uno and Yagiura(2000) from one-to-one mappings to many-to-many mappings, we have shown how to construct ahierarchical representation of all the phrase pairs ina given aligned sentence pair in linear time, whichyields a set of minimal SCFG rules.
We have alsoillustrated how to apply the algorithm as an analyt-ical tool for aligned bilingual data.Acknowledgments Thanks to Bob Moore forsuggesting the extension to phrase extraction atSSST 2007.
This work was supported in partby NSF grants IIS-0546554 and ITR-0428020,and DARPA grant HR0011-06-C-0022 under BBNTechnologies subcontract 9500008412.ReferencesBrown, Peter F., Stephen A. Della Pietra, Vincent J.Della Pietra, and Robert L. Mercer.
1993.
The math-ematics of statistical machine translation: Parameterestimation.
Computational Linguistics, 19(2):263?311.Bui-Xuan, Binh Minh, Michel Habib, and ChristophePaul.
2005.
Revisiting T. Uno and M. Yagiura?s al-gorithm.
In The 16th Annual International Sympo-sium on Algorithms and Computation (ISAAC ?05),pages 146?155.Chiang, David.
2005.
A hierarchical phrase-basedmodel for statistical machine translation.
In Pro-ceedings of ACL 2005, pages 263?270.Galley, Michel, Mark Hopkins, Kevin Knight, andDaniel Marcu.
2004.
What?s in a translation rule?In Proceedings of NAACL 2004.Landau, Gad M., Laxmi Parida, and Oren Weimann.2005.
Gene proximity analysis across wholegenomes via PQ trees.
Journal of Computational Bi-ology, 12(10):1289?1306.Och, Franz Josef and Hermann Ney.
2004a.
The align-ment template approach to statistical machine trans-lation.
Computational Linguistics, 30(4).Och, Franz Josef and Hermann Ney.
2004b.
The align-ment template approach to statistical machine trans-lation.
Computational Linguistics, 30:417?449.Satta, Giorgio and Enoch Peserico.
2005.
Somecomputational complexity results for synchronouscontext-free grammars.
In Proceedings of EMNLP2005, pages 803?810, Vancouver, Canada, October.Uno, Takeaki and Mutsunori Yagiura.
2000.
Fast al-gorithms to enumerate all common intervals of twopermutations.
Algorithmica, 26(2):290?309.Wellington, Benjamin, Sonjia Waxmonsky, and I. DanMelamed.
2006.
Empirical lower bounds on thecomplexity of translational equivalence.
In Proceed-ings of COLING-ACL 2006.Zhang, Hao and Daniel Gildea.
2007.
Factorizationof synchronous context-free grammars in linear time.In Proceedings of the NAACL Workshop on Syntaxand Structure in Statistical Translation (SSST).1088
