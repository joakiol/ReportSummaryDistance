ANALYZING THE STRUCTURE OF  ARGUMENTATIVE  D ISCOURSERob in  CohenDepartment  of  Computer  Sc ienceUniversity of  Water looWater loo,  Ontario, Canada N2L 3G1Consider a discourse situation where the speaker tries to convince the hearer of a particular point of view.The first task for the hearer is to understand what it is the speaker wants him to believe - to analyze thestructure of the argument being presented, before judging credibility and eventually responding.This paper describes a model for the analysis of arguments that includes:?
a theory of expected coherent structure which is used to limit analysis to the reconstruction of particulartransmission forms;?
a theory of linguistic clues which assigns a functional interpretation to special words and phrases used bythe speaker to indicate the structure of the argument;?
a theory of evidence relationships which includes the demand for pragmatic analysis to accommodatebeliefs not currently held.The implications of this particular design for dialogue analysis in general are thus:?
structure is an important feature to extract in a representation to control the processing;?
linguistic constructions can be assigned useful interpretations;?
pragmatic analysis is crucial in cases where the participants differ in beliefs.1 THE PROBLEM AREAConsider the task of designing an "argument understand-ing system", a natural language understanding system(NLUS) where the input is restricted to arguments.Consider as well arguments constructed in a dialoguesituation, where a speaker (S) tries to convince a hearer(H) of a particular point of view.
The hearer patientlylistens; hence, the input is "one-way communication".The argument understanding system therefore plays therole of the hearer, and tries to analyze the structure ofthe argument being presented.
This task is isolated as anecessary first step for a hearer, in order to be a success-ful participant in a conversation.
In other words, thehearer must have some representation of what it is thespeaker wants him to believe, before judging credibilityand eventually responding.Note that this language problem is relatively new andyet feasible.
It is distinct from other NLU endeavors,such as story understanding, which appeal to a stereotypeof content in order to reduce processing.
In arguments,one is never sure what points the speaker will address;content can't be stereotyped.
However, arguments have adefining characteristic - they are necessarily goal-orient-ed.
The speaker wants to convince the hearer of someoverall point.
Thus, there is an overall ogical structure tothe input and this fact may be used by a hearer to controlanalysis.For our model, the representation for the structure ofthe argument is restricted to an indication of the claimand evidence relations between the propositions.
Thenotion of evidence is discussed in more detail in section4.
A useful starting definition is: "A proposition E isevidence for a proposition C if there is some rule ofinference such that E is premise to C's conclusion - inother words, there is some logical connection between Eand C".In order to design an argument understanding system,what is then required is a computational model for theanalysis of arguments.
This in turn necessitates a theoryof argument understanding, as a basis for the model.
Wesuggest the following three components for the model:?
a theory of expected coherent structure, used to drive arestricted processing strategy.
Analysis is kept to acomputationally reasonable task, by limiting the inputto be recognized to a characterization of expectedcoherent forms of transmission.Copyright1987 bythe Association for Computational Linguistics.
Permission tocopy without fee all or part of this material isgranted provided thatthe copies are not made for direct commercial dvantage and the CL reference and this copyright notice are included on the first page.
To copyotherwise, or to republish, requires a fee and/or specific permission.0362-613X/87/010011-24503.00Computational Linguistics, Volume 13, Numbers 1-2, January-June 1987 11Robin Cohen Analyzing the Structure of Argumentative Discourse?
a theory of linguistic clue interpretation, includinginsight into both the occurrence of clue words and theirpossible function in overall discourse.
Clue words arethose words and phrases used by the speaker to direct-ly indicate the structure of the argument to the hearer(e.g.
connectives).
Detecting clues can thus also serveto constrain the processing for the hearer.
Moreover, itis important o have some facility for recognizing andinterpreting clue words, to build a model that is robustenough to process a wide variety of input.?
a theory of evidence relationships.
The most importantobservation is that pragmatic analysis is mandatory foran analysis model in order to recognize beliefs of thespeaker, not currently held by the hearer.
Evidenceconnections between propositions often appeal tounstated information ot currently in the hearer's et ofbeliefs, but recognizable as an intended supportrelation on the part of the speaker.2 RESTRICTED PROCESSING STRATEGYConsider the following framework for the model.
Anargument is considered to be a set of propositions.
Themodel is then designed to analyze the argument a propo-sition at a time, incrementally building a representationfor the underlying structure.
The representation devel-oped is a tree of claim and evidence relations comprisingthe argument, where a claim node is father to its evidencesons.
In order to assign an interpretation for a givenproposition, one must thus simply assign it a place in thetree.
In this way, one can tell to which propositions itserves as evidence and from which other propositions itreceives upport.A key design decision is to separate the two mainoperations of determining for each proposition (i) whereit fits with respect o the argument so far, and (ii) howitrelates to some prior proposition.
The question of howtwo propositions relate in this framework is one of veri-fying that an evidence relation holds between the prop-ositions.
This task is extracted and relegated to anevidence oracle, which, passed two propositions A and B,will respond "yes" or "no", as to whether A is evidencefor B.With the problem of evidence determination factored,the model must still cope with the question of where aproposition may fit.
This is handled by characterizingpossible coherent transmissions (ordering of prop-ositions) on the part of the speaker and then limitinganalysis to reception algorithms designed to recognizethese coherent ransmissions.
In the section below weillustrate possible coherent strategies from the speaker,and present he associated reception algorithm requiredto recognize the input.Note that the computational model for the analysis ofarguments i designed with certain aims and limitations.In particular, the model is to provide for analysis of"spontaneous discourse", demanding construction of arepresentation for the argument as each new statement isprocessed.
The following restriction to the processingmodel is thus applied: the processor does not weigh allpossible interpretations for a proposition; if the oraclesends back a yes answer to the question Is P evidence forQ?, then P is attached as a son to Q in the tree.
In otherwords, the model simulates a hearer who does not havethe luxury of "looking back" and re-interpreting previousstatements.
Moreover, the model aims to provide aninterpretation for the current proposition, so that once aninterpretation has been found (e.g.
that P suppliesevidence for Q) that proposition has been processed.
Theevidence relation is also taken to be transitive - i.e., if Pis evidence for Q and Q is evidence for R, then P isevidence for R. (See Section 4 for more detail on theevidence relation).2.1 PRE-ORDERPre-order transmissions are those where the speakerconsistently presents a claim and then states evidence.The example below illustrates this form:EXI:1)2)3)4)5)With the tree representation:Jones would make a good presidentHe has lots of experienceHe's been on the city board 10 yearsAnd he's very honestHe refused bribes while on the force42.2 POST-ORDERAnother coherent strategy is post-order, where thespeaker consistently presents evidence and then statesthe claim.
Consider the comparable example below:EX2:1)2)3)4)5)With the representation:Js 4J 1Jones has been on the board 10 yearsHe has lots of experienceAnd he's refused bribesSo he's honestHe would really make a good president3In this example, the claim is the same as in EX1, thatJones would make a good president, but the evidenceprecedes the claim in each case - i.e., 1 is evidence for 2;3 is evidence for 4; and 2 and 4 together are evidence forthe final claim 5.12 Computational Linguistics, Volume 13, Numbers I-2, January-June 1987Robin Cohen Analyzing the Structure of Argumentative DiscourseThe associated reception algorithms for pre- and post-order are described in detail  in Cohen (1981).
Both canbe shown to operate in l inear time (linear in the numbernodes of the tree) and so are quite efficient.
The pre-ord-er reception essentially finds an interpretat ion for thecurrent proposit ion of an argument by searching for afather, up the right border of the tree.
The post-orderalgorithm employs a stack; the current proposit ion teststo be father to the top of the stack; then all sons arepopped off the stack, and the resulting tree pushed onthe stack.We trace the construction of the trees of EX1 and EX2below, to provide details of the pre-order and post-orderreception algorithms.EXI: PRE-ORDERAlgorithm:- The current proposit ion is NEW.- The proposit ion immediately prior is LAST.1) Try NEW as evidence for LAST.2) If that fails, try NEW as evidence for each of LAST'sancestors, in turn, up to the root of the tree.3) If the test in 1 succeeds, stop.Consider as well a dummy root (D) for the tree for whichall nodes are evidence (to place the first proposit ion).evidencecandidates oraclein order test for NEW response1,D 2 ev.
for 1?
yes2,1,D 3 ev.
for 2?
yes3,2,1,D 4 ev.
for 3?
no4 ev.
for 2?
no4 ev.
for 1?
yes4,1,D 5 ev.
for 4?
yesEX2: POST-ORDERAlgorithm:- Keep a stack of elements eligible to be evidence fora current proposit ion, with the latest one as TOP.- To interpret he current proposit ion NEW:1) Test if TOP is evidence for NEW2) If yes, then pop TOP (TOP:= TOP - 1) and make ita son of NEW (build a tree under NEW); then repeatstep 1 with NEW value of TOP.3) If no, make the tree with NEW as root the new TOPof stack (push NEW onto stack).
In essence, all sonsfor a proposit ion are picked up at once.stacke lements1t ree: l  under 23, 1 under 23 under 4, 1 under 2evidencetest for oracleevidence response1 ev.
for 2?
yes2 ev.
for 3?
no3 ev.
for 4?
yes2 ev.
for 4?
no4 ev.
for 5?
yes2 ev.
for 5?
yes1)2)3)4)5)With the representation:2.3 HYBRIDAs a first approximation to a general processing strategy,consider designing a reception algorithm to accept hybridpre- and post-order  arguments (i.e., any given sub-argu-ment may be transmitted in pre- or post-order) .
Anexample of hybrid transmission is EX3 below.EX3:Jones would make a good presidentHe has lots of experienceHe's  been on the board 10 yearsAnd he's refused bribesSo he's honest12 j3 JHere, the first sub-argument is in pre-order,  the secondone in post-order,  and the argument overall is still coher-ent.The reception algorithm for accepting hybrid trans-missions is basically a combinat ion of techniques fromthe pre- and post-order  eceptions.
Now, to process acurrent proposit ion both a father and possible sons mustbe searched for.
But the search is still restricted - certainproposit ions get closed off as possible "relat ives" to thecurrent one (e.g., earlier brothers of an ancestor).
Thus,the complexity of the algorithm is still reasonable; it canalso be shown to be linear.
Once more, see Cohen(1981) for further examples.A full descript ion of the hybrid algorithm is includedbelow.L is kept as a pointer to the lowest node of the treestill eligible to receive evidence.
It is initially set to adummy root node to which all other nodes succeed asevidence.
Consider as well a labelling where the lastproposit ion in the stream that succeeds as evidence for anode is stored as the r ightmost son.For  each node NEW in the input stream do:/ *  find father * /do while (NEW is not evidence for Land L is not dummy root)set L to father of Lend;Computational Linguistics, Volume 13, Numbers 1-2, January-June 1987 13Robin Cohen Analyzing the Structure of Argumentative Discourse/* see if there are any sons to re-attach */if (rightmost son of L is not evidence for NEW )/* no sons to re-attach */then do;attach NEW to Lset L to NEWend;elsedo;/* some son will re-attach; attach all sons of Lwhich are evidence for NEW below NEW */do while (rightmost son of L evidence for NEW)attach rightmost son of L to NEWremove rightmost son of L from Lend;attach NEW to Lend;Note that the hybrid algorithm, in searching for bothsons and father to the current node, must contend withcases where a proposition is attached to a higher ancestorand must be re-attached to its immediate father.
Thisoccurs in a framework where the evidence relation isconsidered transitive.
The kinds of orderings that involvethis "re-location" are of the form: A, C, B - where C isevidence for B, B evidence for A (hence C also succeedsas evidence for A when tested).For EX3:candidatesD1,D2,1,D3,2,1,D4,1 ,D(3&2"closed off")test for evidence oracleevidence response1 ev.
for D?
yes2 ev.
for 1?
yes3 ev.
for 2?
yes4 ev.
for 3?
no4 ev.
for 2?
no4 ev.
for 1?
yes5 ev.
for 4?
no(4 is a case of 5, so can'tassume 5 ev.
for 4)5 ev.
for 1?
yes4 ev.
for 5?
yes(testing re-attach ofsons)2.4 SUMMARY OF PROCESSING STRATEGYThe processing strategy proposed for our model of argu-ment analysis is designed to produce a selective interpre-tation.
The particular estrictions to processing chosenfor the model are, moreover, both?
useful for measuring the efficiency of the model, sinceexpressed in a framework of an algorithm operating ona tree structure, where complexity of the algorithm canbe studied and?
well-motivated, since based on a characterization ofcoherent input.In fact, it is an expression of a theory of argument coher-ence that serves to produce a model that is both efficientand robust (can handle a wide variety of input).Note that the particular restrictions suggested aredrawn from analysis of a body of examples from rhetorictexts, together with some "naturally occurring" argu-ments (letters to the editor in newspapers).
The aim is tocharacterize coherent transmission forms (ordering ofpropositions) that can be understood, without additional"clue words" to the underlying structure.
We feel thatthe hybrid model is a good first approximation becauseexamples of various forms of hybrid were encountered,and exceptions to the form all involved additional clueinformation.
This leaves the study of clues and possibleextended transmission forms to the next section.
(InCohen (1983) a few longer examples are run through themodel to illustrate the forms it can accept and to moti-vate provision for the recognition of a wide variety ofargument forms.
Note that an actual implementation wasnot produced.
There is now a scaled-down first imple-mentation (Smedley 1986), which will be discussedfurther in section 6.
)3 LINGUISTIC CLUESThe second main component of the argument under-standing model is a theory of linguistic clues.
These arethe words and phrases often used by the speaker todirectly indicate the structure of the argument o thehearer.
It is important to specify?
what kinds of clues exist?
the function of these clues in analysis - i.e., what inter-pretation can be assigned to a proposition that containsa clue word, and?
(a more difficult question) when clues are necessary toensure comprehension f the argument structure by thehearer.This approach to the study of clue words is much moredetailed than the initial suggestions of Hobbs (1976) onhow to interpret a few connectives uch as and in hisframework.
It is also distinct from the investigations ofReichman (1981) and (recently) Grosz and Sidner(1986).
Grosz and Sidner acknowledge the existence ofclues and discuss various discourse structures that can beformed in the presence of clues.
Reichman also gives alonger list of clue words and the particular conversationalmoves they signal.
But there is no systematic proposal forinterpreting a clue word that may occur (classification),and there is little discussion of how to process some ofthese more complex discourse structures without clues(suggesting when clues are necessary).
In this section weclarify more deeply some of the discussion of clues inCohen (1983, 1984b).3.1 CLUES OF RE-DIRECTIONOne type.
of clue is expressions that specifically re-directthe hearer to an earlier part of the argument.
Consider:14 Computational Linguistics, Volume 13, Numbers 1-2, January-June 1987Robin Cohen Analyzing the Structure of Argumentative DiscourseEX4:1) The city is a mess2) The parks are a mess3) The park benches are broken4) The grassy areas are parched5) Returning to city problems, the highways are bad tooWith the representation:3 / ~ 4  5Here, the clue in proposition 5, returning to city problemssignals additional support for proposition 1.
In theabsence of a clue, the specifications for the hybrid algo-rithm would have 5 test to be a son for 4, 2, and 1 (upthe right border of the tree).
So, adding clues shouldreduce the processing effort of the hearer.
(In fact, ifclues are consistently used by the speaker after longchains of evidence, the processing complexity of thereception algorithm can reduce from linear to real-time).3.2 CONNECTIVESAnother popular type of clue word is the connective.
Wepresent a classification or taxonomy of connectives, andthen associate a common interpretation rule within theclaim and evidence framework for each category of thetaxonomy.
In this way, the interpretation of any proposi-tion containing a connective can be determined on thebasis of the clue word's classification.
For example:EX5:1) This city is a disaster area2) Houses have been demolished3) Trees have been uprooted4) As a result, we need national aidWith the representation:Here,the connective as a result in proposition 4 belongsto a category known as inference, indicating that thereshould be some prior proposition that connects to 4 andserves as son to 4 - i.e., supplies evidence for "theresult".
In this example, in fact, 1 acts as the son.
Theinterpretation rules are necessarily default suggestions fortranslating the semantic relations between propositionsinto our claim and evidence classification.
(See furtherdiscussion on the evidence relation (section 4) for possi-ble exceptions).The taxonomy and its associated interpretation rulesare presented below.Each category is a classification of connectives, madeon the basis of semantic meaning of the connective -e.g., the parallel category would include all words thatextended a list, including next, then, first, secondly, third-ly, etc.
The set of classes was produced by consideringthe categories proposed in Quirk et al (1972), and merg-ing some classes that had similar semantics and suggestedthe same interpretation rule for claim and evidence.
Theinference category covers phrases that suggest oneproposition can be inferred from another - e.g., as aresult, because of  this, etc.
The detail category moves inthe other direction, and includes connectives that specifyfurther - e.g., in particular, specifically, etc.
The summarycategory is used for phrases that conclude a list.
Refor-mulation captures clue words that repeat an earlier idea -e.g., in other words, once more, etc.
Finally, contrastcovers the phrases that introduce comparisons, like on theother hand or but.In conjunction with the semantic classes, evidenceinterpretation rules were then assigned as default inter-pretations.
(See Section 4.3 for pragmatic "overrides" tothe defaults).
Note that some words may fall into morethan one category, based on the meaning used - e.g.,then meaning 'next' (in a list of actions) compared withthen meaning 'as a result'.
Clue interpretation thusrequires a classification process as well.P is prior proposition; S is the proposition with theclueCATEGORY RELATION: P to S EXAMPLEparallel brother First, Secondinference son As a resultdetail father In particularsummary multiple sons In sumreformulation son (& father) In other wordscontrast brother or father On the other handThe taxonomy is described in detail in Cohen(1984b).
We include discussion of one category here, asan example.
The detail class is one case where connec-tives with a range of meanings were merged into onecategory.
The title "detail" suggests that the connectivewill further specify some prior proposition.
Includedcases are: for  example, in particular, and as anotherinstance.
The interpretation rule assigned to this categoryis that the proposition with the connective providesevidence for the earlier connecting statement.
The moti-vation is that an accumulation of specific cases leads to aconclusion of a general statement (a form of reasoningused very often in naturally occurring arguments).EX6:1) The people in this town deserve a city-wide holiday2) For example, Old Man Jones has worked non-stopsince Christmas3) And Mayor Flood is still recovering from all hisefforts for the tornado relief4) In short, all of us are tiredComputational Linguistics, Volume 13, Numbers 1-2, January-June 1987 15Robin Cohen Analyzing the Structure of Argumentative Discourse1 /42J "--32 is son to 1 (detail class); 3 is also son to 1 (brother to2) (parallel class); 4 is father to 2 and 3 (summary class).3.3 THE FUNCTION OF CLUE WORDSSo far we have discussed two types of clue words thatcan occur in conjunction with arguments transmittedaccording to the specifications of the hybrid algorithmpresented in section 2 (our characterization for coherentdiscourse).
We point out that re-direction clues provideadditional information concerning which of the eligiblepropositions is related to the current one, and thatconnective clues specify the kind of relation that must befound between the current proposition and one of theeligible priors.In certain cases these restrictions will prevent some ofthe tests for evidence that would Otherwise have beenconducted, thus saving some processing effort.
For exam-ple, consider the following:EX7:1) The city is in serious trouble2) There are some fires going3) Three separate blazes have broken out4) In addition, a tornado is passing throughwith the representation:1The clue in 4 prescribes an interpretation for 4 as brotherto some prior proposition.
This means that 4 must act asevidence for some different proposition.
Thus, eventhough 3 is technically the first proposition to test outwhen interpreting a new proposition (NEW evidence forLAST is the test), in this particular case this option is notpossible.
Thus, one round of work for the evidence oracleis avoided.
In fact, for this example, the test "4 evidencefor 2" fails, and the final test of "4 evidence for 1"succeeds.
(Note that the brother elation is tested by wayof son relation to a (common) father.
This is because themodel only processes evidence relationships).3.3.1 THE NECESSITY FOR CLUESWe now examine the use of clue words in conjunctionwith transmissions that violate the specifications of thehybrid base case.
The hypothesis is that more complextransmissions can be accommodated by the argumentanalysis model provided there exist clues to assist thehearer in recognition.
In these cases, the clues are thereby necessity.
Their function in the discourse is not tomerely add detail on the interpretation of the containedproposition, but to allow that proposition an interpreta-tion that would otherwise be denied.There is an advantage to adhering to the base ease ofacceptable argument structures and treating the use ofclues with other transmission forms as exceptional.
In thefirst place, this provides a framework for detecting oneinterpretation for an argument when another possibleinterpretation could be generated if further testingoccurred.
In other words, in this model a representationdrawn using the rules of the hybrid reception will alwaysbe accepted as the intention of the speaker, unless cluesspecifically override possible tests.To explain, consider the following example:EX8:1) The park benches are rotting2) The parks are a mess3) The highways are run down4) (And another problem with the parks is that) thegrass is dying5) This city is in sad shapeWithout the clue phrase in 4, re-directing to proposition2, to add more evidence out of turn, a coherent represen-tation could be built just the same, as below:, JIf the speaker intends 4 to add detail to the parks prob-lem, he cannot expect he hearer to make this connectionwithout more information, simply because a more effort-less interpretation of 4 is possible (and the speakershould realize that it is this representation that the hearerwill draw).Another important reason for separating the base caseof acceptable transmissions i  to allow for input that canbe characterized assomehow a coherently generated planof the speaker.
Recall that the proposition analyzer willcontinuously call on an evidence oracle to determine ifsome proposition A acts as evidence for some otherproposition B.
Suppose there were no restrictions in thetesting of evidence relations.
Then, tests for evidencethat would be interpreted as positive would return thisresponse, regardless of when asked.
In other words, atotally random display of propositions would result in thesame representation for the argument as the reception ofa coherently ordered presentation.
Consider the follow-ing example:EX9:1) Yogi's been a shrewd manager2) He hired a hitter who now bats .4003) He traded in a pitcher who is now 0 and 124) But he got involved in drug deals to the players5) And that's inexcusable for a manager6) He really needs to be axed16 Computational Linguistics, Volume 13, Numbers 1-2, January-June 1987Robin Cohen Analyzing the Structure of Argumentative Discoursewith the representation:4 j 2 j ~ 3(where 5 and 1 are contrasting evidence to 6).EX9B: The argument as above, presented in the order::2,5,3,6,4,11) Yogi hired a .400 hitter2) (And) that's inexcusable for a manager3) He traded in a pitcher who is now 0 and 124) Yogi really needs to be axed5) He got involved in drug deals to the players6) He is a shrewd managerThis argument now appears incoherent.
One reason isthat there is contrast overall that must be clearly sepa-rated.
In any case, the ordering does not conform to thespecifications of the hybrid and as such is a candidate foran unacceptable t/'ansmission.This example suggests that the use of clue words,though helpful to signal exceptional transmissions, houldstill be studied as a systematic process of the speaker toassist the hearer in comprehension.
In EX9B, could anynumber of clue words be added to still make this recogni-zable?
Consider the following attempted repair to EX9B:EX9C:1) Yogi hired a .400 hitter2) But he's done some things inexcusable for a manag-er3) Although he also did other smart things like tradinga pitcher who is now 0 and 124) No, Yogi really has to be axed5) He got involved in drug deals to the players6) Though he still is a shrewd managerThe question is whether an argument of this form wouldstill be judged coherent.
Our preference will be to specifyparticular types of exceptional transmissions that may bejudged coherent.
To this end, we have tried to isolate afew specific cases where clues can be used in conjunctionwith coherent orderings beyond the specifications of thehybrid algorithm.
These are highlighted in the next sub-section below.One more point about the last example above is that itemphasizes our concern that the analysis of arguments bedone efficiently.
In this case, we want to avoid makingtests for evidence relations that could not exist betweencertain propositions as part of a coherent input.
In otherwords, we don't want the model to simply test out allpossible combinations of evidence relations (even thoughthis would only be n*n vs. k*n number of operations),because an input that is not coherent would then beaccepted.We would also not want to derive computationally arepresentation for an argument that involved morecomputational effort, if a simpler interpretation of thesame argument could be derived.
(Again, the speaker isto assume that the hearer will not be searching unneces-sarily).
This is illustrated in EX8 above.3.3.2 CASES OF NECESSITYThree kinds of acceptable xtended transmission strate-gies are studied in Cohen (1983): parallel evidence, multi-ple evidence (a proposition acting as evidence for severalclaims, in restricted conditions) and mixed-mode sub-ar-guments (with evidence both preceding and following aclaim).
We present an example of the parallelconstruction below.
See Cohen (1984b, 1983) for furtherexamples.EXI0:1) The city has problems2) The parks are a mess3) The highways are a mess4) The buildings are a mess5) Here's some evidence for the fact that the parks area problem: the benches are broken6) As for the highways, they're full of potholesWith the representation:15/2  6 ~ ~  ~ 4Here, the argument breaks the rules of hybrid trans-mission by adding evidence for an earlier brother (propo-sition 2); however, this shift is signalled with a phrase ofintention in proposition 5, and the hearer may thenexpect a parallel expansion of additional support for eachof the earlier brothers, in turn.
(Note that without theclue, the argument structure derived would simply recordall of 2 to 6 as evidence for 1, in the same vein as EX8).This example illustrates another interesting feature ofclues - the variety of possible surface forms that cansignal the same evidence relation between propositions.In EX10, the clue in 5 could also have been The problemwith the parks is... or I will now explain why the parks aresuch a problem - .... A range of explicitness i thus possi-ble.
In cases other than this parallel construction, in fact,a signal to a relation between propositions may be advo-cated by the simple use of an anaphor.
For example:EXI 1:1) The mayor hasn't'done much for this city2) He doesn't seem to want to do much3) That man is a complete loserHere, the phrase that man signals a link to the mayor.
It isdifficult to decide whether the phrase qualifies as a clueword.
The problem is determining a "bottom line" - i.e.,"can't every sentence be seen to have some clue, fromsemantics, to its interpretation within the argument?
".For now, we do not consider the cases of anaphora asabove.Computational Linguistics, Volume 13, Numbers 1-2, January-June 1987 17Robin Cohen Analyzing the Structure of Argumentative Discourse3.4 SUMMARY AND FUTURE DIRECTIONS OF CLUE THEORYOur theory of clue interpretation so far has outlined thefollowing principles:?
Clues may occur with expected coherent ransmissionsor to signal exceptional cases.?
Connective clues can be assigned common interpreta-tion rules according to the semantics of the clue.?
To distinguish elpful versus necessary clues, the pref-erence will always be to recognize the hybrid trans-mission; if clue rules or semantics force an exceptionalreading, only certain exceptional structures hould beaccepted.?
In all cases, a reading that can be derived with lesscomputational effort will always be taken as theintended reading.?
The cases where clues are necessary to force a certaininterpretation provide insight into the function of clues;their use in conjunction with acceptable transmissionssuggests a function of additional processing reductions.In order to recognize clues and incorporate their inter-pretation into a larger model that derives argument struc-ture, we propose a separate clue interpretation module,interacting with the basic reception algorithm and thecalls to the evidence oracle.
Exactly how this modulewould function is left as future work.
We do have a fewinitial insights, to suggest hat clue interpretation is notonly quite useful (argued previously in this section) butfeasible.For connectives, the clue can be recognized from aclassification.
Then, determining whether a relatedproposition available from the list of eligibles is in factrelated can be tested, according to the restrictions of theinterpretation rule (as suggested in EX7).
Further, therequired semantic relation to the prior proposition can bepassed as additional information to the oracle.
The prob-lem is that this oracle must do some kind of search forconnections between facts and axioms of a knowledgebase.
How this semantic analysis is achieved epends onthe underlying representation, but additional semanticconstraints should help to restrict operations.For re-direction clues, a processor would first have torecognize the appropriate phrase used.
Some standard list(e.g., returning to, on the topic of) may be specified as astart.
Then, the phrase should suggest some particularsemantic ontent o the prior proposition (e.g., returningto the parks mentions parks as central).
Now it is theform of representation of the propositions which mayinfluence what is acceptable on a list of eligibles.
If thissemantic processing can be done very broadly, some callsto the oracle may be avoided, and this would be animprovement, assuming the oracle's operations encom-pass a more extensive search.4 EVIDENCE DETERMINATIONThe third main component of the argument analysismodel is a theory of evidence, to govern the verificationof evidence relations between propositions.An initial definition for evidence offered in Section 1is: "A proposition P is evidence for a proposition Q ifthere is some logical connection from P to Q - i.e., somerule of inference such that P is premise to Q'sconclusion".
The main problem in establishing evidencerelations is that not all the premises are stated.
For exam-ple, one common rule of inference used in arguments iModus Ponens, of the form: P ~ Q, P therefore Q. Theway this rule is most often used, the speaker will simplystate P and Q and leave out the major premise "P ~ Q",expecting the hearer to be able to fill in the unstatedconnection to recognize the evidence relation from P toQ.
Omitting certain premises is referred to as ModusBrevis and studied in Sadock (1977).We list below the rule of inference frames included forour model.
Each rule has a slot for major premise, minorpremise, and conclusion, to be filled by stated or unstatedpropositions, in recognizing an evidence relationship.RULE OF INFERENCE FRAMES:Major Minor ConclusionModus Ponens P ~ Q P QModus Tollens P ~ Q ~Q ~PModus Tollendo Ponens P v ~Q Q PModus Ponendo Tollens P v Q Q ~PThe form most often used is Modus Ponens.
When themajor premise is missing, this is the rule of inference toconsider as the intended link from P to Q.EXI2:The Jays had a fantastic team this yearAll their players had averages over .2501)2)fill:3) If a team has all players with averages over .250,then that team is fantasticThe common form for arguments, then, is one where thehearer must supply missing statements in order to estab-lish the connections for the representation of the argu-ment.There are several possible Modus Brevis forms foreach frame above.
The possible missing parts are classi-fied below for the case of Modus Ponens.MODUS BREVIS FORMS (MODUS PONENS):GivenPremises ConclusionNormal P ~ Q, P QMissing Minor P--,- Q QMissing Major P Q (most popular form)Only Major P ~ Q (assume rest)Only Minor P (assume rest)4.1.
OVERVIEW OF ORACLE'S PROCESSINGIt is important to demonstrate hat the part of processingrelegated to the evidence oracle within the overall modelis not insurmountable, to defend the model as useful.
Inthis section we examine more closely the operation of the18 Computational Linguistics, Volume 13, Numbers 1-2, January-June 1987Robin Cohen Analyzing the Structure of Argumentative Discourseoracle, opening up the "black box" just enough tosuggest how it operates.In general, the oracle is asked to test two propositionsto be in an evidence relationship, responding "yes" or"no" to a question of the form: "is P evidence for Q?
".We sketch the operation of the oracle for the examplebelow:EXI3:1) Joey is a dangerous2) He is a sharkAssuming some resolution of anaphora, etc., a cruderepresentation f the example in terms of predicates andarguments i :P: Shark(j); Q: Dangerous(j) (j: Joey).A Modus Ponens template would be of the form: S(j),for-all (x) (S(x)  ~ D(x) ), therefore D(j) (S:is-shark,D:is-dangerous).
(Note that we are not addressingcertain questions here such as the significance that is ashark is definitional, while is dangerous i really assertion-al).Recall that the argument analysis model seeks torecognize intended argument structures.
So, in this exam-ple the hearer can at least recognize that "P is evidencefor Q" would follow through if All sharks are dangerouswere believed (i.e., for-all(x) (S(x) ~ D(x) ).It is thus proposed that the oracle:1. identify missing premises (the Modus Brevis form ofthe argument being presented);2. verify plausibility of these missing premises (thatthey could be intended by the speaker to be believedby the hearer); and3.
conclude that an evidence relation holds if the miss-ing premises are plausible.For step 2, we try to specify more precisely in theremainder of this section the kind of tests the hearer canapply.
A summary is provided below:a) Identify the missing premise within a knowledgebase of shared knowledge.b) Identify a "relaxed version" of the missing premisewithin own private knowledge.c) Identify the missing premise within a model of thespeaker's beliefs.d) Judge the beliefs of a hypothetical third party(which could be simplified if the bottom line is"believe it, unless there's reason to strongly doubt,from within one's own beliefs").We have found in simulations of the model on a varie-ty of examples that most of the tests for evidence can beanswered through (a) and (b).
We hypothesize that,given a specification of a knowledge base, the search forconnections between propositions can be controlled.
Thishypothesis would be best verified with an implementationof the oracle and extensive analysis of examples, andcould be the focus of the next stage of our implementa-tion (beyond Smedley (1986)).
(The two large examplesdissected in Cohen (1983) do have this property.
)In addition to the problem that the major premise maybe unstated is the problem that this premise should reallybe tempered by the beliefs of the speaker.
In otherwords, the missing major premise that the hearer must fillin is really of the form: H believes that S wants H tobelieve (P ~ Q).
In other words, this premise is notnecessarily one of the hearer's beliefs.
It is important oemphasize the importance of pragmatic processing inestablishing evidence relations.
The tree of claim andevidence relations built as a representation for the argu-ment is really an indication of the plan of the speaker, inthe sense that each evidence relation recorded is thebearer's conception of a support connection intended bythe speaker.Note that it is difficult to specify how a plan of aspeaker is determined uring analysis.
What we are advo-cating is to interpret he intention of each proposition ofthe argument, the other propositions for which itprovides evidence.
The result of processing the entirediscourse is not a complete plan of the speaker, in thesense that each of the "steps" could be executed and thetop level goal (convince the hearer of some overall point)would then follow.
It is more an indication of the moti-vation behind each utterance towards the ultimate goal ofconvincing the hearer.
The difficulties in plan inferencefor discourse are discussed in more detail in Grosz andSidner (1986), and are in fact a topic of our currentconcern (see discussion of future work in Section 6).There is in fact a whole spectrum of problems thehearer must face in recognizing evidence relationshipsbetween propositions.
The four main tests for the hearercan be described as:?
use logic,?
relax the logic,?
stereotype the speaker,?
judge plausibility (reason as a "hypothetical person").We illustrate these possible operations with examplesbelow.4.2 LOGIC AND RELAXED LOGICIn example EX14, all the premises of the Modus Ponensargument are present.
The hearer should realize that 1and 2 are evidence for the claim in 3.
Then EXI5 illus-trates the more typical case of missing major premise.
Ifthe hearer fills in All machine candidates win, theconnection from 1 to 2 can be seen.
The problem is thatthe speaker probably believes something more along thelines of: Most machine candidates win.
And yet, onecouldn't record a Modus Ponens relation in the argumentwith a quantifier such as most instead of for all.
Thus, thehearer must use some relaxation to the rules of logic torecognize the evidence relation.
The detection ofevidence through "relaxed logic" can be accomplished byhaving the hearer judge the unstated connection as aplausible generalization, based on a few known cases.For example, if the hearer tries to recognize an evidencerelation from 1 to 2 in EX16 below, by filling in AllComputational Linguistics, Volume 13, Numbersl-2, January-June 1987 19Robin Cohen Analyzing the Structure of Argumenlative Discoursesharks are dangerous, and the hearer doesn't believe this"axiom" but knows of a few sharks that are dangerous,he may reason that the missing major premise is reason-able.EX14:1) Aristotle is a man2) All men are mortal3) So Aristotle is mortalEXI5:1) Bilandic will win2) He's the machine candidateThe point is that the hearer is still able to recognizeconnections he does not believe.
In EXI7, the hearershould be able to understand an evidence relation from 1to 2, upon filling in a missing premise of the form "If aperson stands for apple pie and Morn then he is great".
Ifthe hearer does not believe this statement himself, hemay still consider it to be a reasonable belief of thespeaker; having stereotyped knowledge of the speaker'sviews may thus be use'ful.EXI7:1) Reagan is great2) He stands for apple pie and MornEXI6:l) Joey is a shark2) So, he is dangerousThe idea of recognizing an intended connection fromsome other conversant based on one's own beliefs is notnecessarily simple to implement.
There has been somerecent work by Pollack (1986) that suggests a moreconcrete foundation for this operation.
Pollack discussesthe problem of inferring a questioner Q's plan from hisdiscourse.
A first process has the responder R ascribingto Q a belief about some connection ("conditional gener-ation relation") that she herself believes true.
Occa-sionally, R will need to recognize a connection that is notone of her beliefs.
Then Pollack suggests there is a rulewhere "R ascribes to Q a belief about a relation betweenact-types that is a slight variation of one she herself has".In particular, one slight difference possible has Q believ-ing a stronger conditional generation relation, which ismissing one of the required conditions.This related research is quoted here, not to argue thatthis problem is solved, but to acknowledge that it isimportant o specify this "relaxed" connection betweenone's own beliefs and those attributed to another.
Somegroundwork is being laid with more formal descriptionsof plans such as Pollack's.4.3 DIFFERENCE IN BELIEFSThe other type of problem faced by a hearer in recogniz-ing evidence relations arises because of difference inbeliefs between speaker and hearer.
As mentioned, thehearer is actually discerning intended relations on thepart of the speaker, and must often reason outside hispersonal framework of knowledge.
Again, an issue israised of how to discern intentions from discourse.
Somework has been done at the level of one utterance (e.g.,Allen 1979).
We are mostly concerned with advocatingthe inclusion of reasoning beyond one's own beliefs,without a full theory of how to infer another person'sbeliefs.
Instead, we advocate a simplified framework,discerning evidence relations and allowing a connectionto be drawn as intended if it is plausible to the hearer.For future work, we are studying how to specify thisprocess more precisely.
(See also Grosz and Sidner1986).Finally, if the hearer is testing a possible evidencerelation between two propositions, does not believe themissing premise, and has no prior knowledge of thespeaker, the best option available is to try to judge theplausibility of the unstated information.
Essentially, thehearer must postulate new facts (which he may not besure he wants to also believe) and consider elationshipsbetween these facts as plausible or not.
It is in this sensethat he adopts a "hypothetical person's" beliefs.
Notethat it is often the case that one will accept new factsunless something from one's own beliefs suggests acontradiction.
In this sense, the judgement of plausibilitydoes relate back to the hearer's own beliefs.An example with an implausible missing connection isEX18 below.
If the hearer tests 2 as possible evidence for1, a major premise of the form "All sharks like tapdancing" would establish the relation.
But the hearerwould not regard this as a plausible belief of the speaker,and so would fail to recognize an evidence relationbetween the two propositions.EXId:1) Joey likes to tap dance2) He is a sharkThe problem of judging plausibility is difficult.
Tomake this process more computationally tractable, onesuggestion is to incorporate into the model some trackingof mutual belief between speaker and hearer.
(See Cohen(1978) for further discussion on the use of mutual beliefin natural language processing.)
Then, certain tests forevidence relations can be blocked in the oracle, based onmutual belief.For instance, rules can be postulated regarding the useof claims and evidence that are mutually believed.
Twosample rules are:(i) "If P is mutually believed, it can't be used asclaim".
(ii) "If ~P is mutually believed, P can't be used asevidence".In addition, some of the default interpretation rulesassociated with the taxonomy of linguistic clues can beoverruled by pragmatic onsiderations.
The idea is topossibly override the default semantic interpretations ofevidence relations otherwise specified, by testing whether20 Computational Linguistics, Volume 13, Numbers 1-2, January-June !
987Robin Cohcn Analyzing ihc Siructurc of Argumcntalivc Discoursepropositions are already mutually believed.
Note that theidea of a "pragmatic override" is also employed inGazdar (1979) for the problem of determining presuppo-sitions.
The importance of pragmatic processing for argu-ment analysis is once more emphasized, as it is a criticalcomponent to the difficult procedure of judging plausibil-ity.While considering mutual belief will help to eliminatesome potentially difficult tests for the oracle, the modelwould require a more detailed specification of the main-tenance and use of mutual belief.
This is left as a topicfor future work.
Some current ideas are explored in moredetail in Cohen (1985).4.4 SUMMARY OF EVIDENCE THEORYThe "theory" of evidence relationships, developed tospecify the operation of the evidence oracle componentof the argument analysis model, really presents insightinto the problems relevant o evidence relations, ratherthan offering solutions.
Still, the fundamental question ofhow connections between propositions can be verifiedhas not been studied to any extent by other researchers.It is extremely worthwhile to acknowledge that it is notsufficient to indicate what relations do occur, withoutalso suggesting how these relations could be establishedduring analysis.In addition, we have provided some insight into themore general question of how to accommodate a possibledifference in beliefs between conversants in a naturallanguage dialogue processing system.
We also suggestthat a less sophisticated oracle can be constructed thatmerely searches known facts and axioms, possibly includ-ing relaxations, to handle a large amount of naturallyoccurring arguments.5 RELATED WORK5.1 ARGUMENT UNDERSTANDINGOther researchers in natural anguage have studied argu-ments, in particular.
However, the focus of the researchin each case has been different.
Birnbaum and the groupat Yale (Birnbaum et al 1980, McGuire et al 1981)study two-way communication, developing an argumentgraph to display the points raised by both conversants.This graph is then used to determine the best moves onthe part of an adversary, to challenge the position of theother conversant.
Thus, the question of what responsesto generate is investigated.
On the other hand, there islittle insight into how a hearer can detect he points beingraised by the speaker, to construct his argument graph.Our focus has thus been on this preliminary problem toargument understanding.Archbold (Archbold 1976, Archbold and Hobbs1980) is most concerned with evaluative arguments,those with strong underlying ideologies.
For example,Lenin's speeches are appropriate sample input.
Thus, thedifficult question of recognizing differing opinions is afocus to Archbold's investigations.
In addition, he studiestext rather than discourse, allowing for a deeper review(re-reading) of the input in order to derive an analysis.Weiner (1979) describes a representation for argu-ments that is also a tree structure, with a variety of linkspossible.
His main concern is to characterize types ofargument structures, for use in the generation of explana-tions.
There is thus little attention on the problemsencountered in deriving argument structures during anal-ysis.Weiner's (1979) model for the structure of explana-tion bears some resemblance to the representationdescribed for arguments here.
Weiner claims that naturalexplanation can be regarded as a series of transforma-tions of an underlying tree structure that represents theabstract form of the argument being developed.
Theways in which support can be supplied are listed moreextensively, including examples, alternatives, etc.
Howthe tree can be built up relies on tracking a node that is"in focus".
The fact  that determining the relationsbetween statements may make use of clue words ismentioned briefly as well.
Basically, some of the featureswe advocate appear in this research.
But we are trying toprovide more insight into operational questions uch as:?
How do you determine the (best) relation betweenpropositions??
How is the focus set?
and?
When are clue words likely to occur?By contrast, Weiner concentrates on how to generateexplanations using his precisely specified characteriza-tion.Reichman (1981) is concerned with a larger problemof producing a model of discourse (not just arguments),but her approach should handle arguments as well.
Thecore of the model is an ATN grammar for parsing andgeneration, coupled with a representation of "contextspaces" containing conversational moves.
The conversa-tional moves provide a classification of larger compo-nents of discourse (not just single propositions).
Forexample, there is an extensive study of a "challenge"operation.
Since Reichman's aims are broader than ours,the lower level issues we address of verifying evidenceand studying the necessity for clue words are not consid-ered for the model.
Moreover, there is an intentionallack of concern with pragmatic processing, anothercrucial feature our model.
Instead, Reichman presents amodel for the analysis of a variety of two-person inter-actions.In sum, our efforts in argument understanding areworthwhile because we focus on the necessary first stepin argument analysis - determining the intended struc-ture, or "what the argument is about".
We study thepossible structural relations between propositions, andinvestigate the difficult issue of verifying evidencerelationships.
The importance of pragmatic analysis torecognize whole classes of arguments that involve differ-ing beliefs is stressed in our work.
And finally, the useand interpretation of clue words is addressed.
It is worthComputational Linguistics, Volume 13, Numbers 1-2, January-June 1987 21Robin Cohen Analyzing the Structure of Argumentative Discoursenoting that the differences in our existing studies canpossibly be exploited by pooling efforts and suggesting apowerful general model for argument analysis.5.2 REFERENCE RESOLUTION AND FOCUSSome of the work on using focus for reference resolutioncontains similarities to the model presented here foranalyzing argument structure.
Sidner (1979) maintains afocus stack of possible items in focus and an alternatefocus list to support shifts of focus.
The candidates forresolving references are thus restricted and ordered.
Thepoint is that these restrictions are drawn from a charac-terization of coherent discourse, the same approachtaken for our control of processing.
Grosz (1977)presents a model of focus spaces which may be used forseveral purposes, including the resolution of definitenoun phrase resolution.
The spaces are organized into ahierarchy, thus similar to our tree representation forargument structure.
Both active and 9Pen spaces aretracked, similar to our tracking candidates eligible to berelatives to the current proposition.Because of similarities in the representations and tech-niques for controlling search for interpretations, it isworth investigating as future work the precise relation-ship among coherence, reference resolution and focusdetermination for dialogues (some of this is being done(Grosz and Sidner 1986)).5.3 PSYCHOLOGICAL RESEARCHAlthough our model is not designed according to psycho-logical studies of discourse comprehension, there aresome interesting parallels with existing psychologicalresearch.
Labov and Fanshel (1977) investigate thera-peutic discourse, dialogue between a psychologist and hispatient.
The research describes everal properties of thearguments advanced by the patients including: the use ofpoor logic, the tendency to omit premises in arguments, avariety of transmission forms (claims before and after),and the existence of statements about the structure of theargument (clues).
Since our characterization of inputprovides for all these forms, it strengthens our case forhaving a robust model.Geva (1981) investigates the usefulness of flowchart-ing text structure to assist students in comprehending theunderlying structure.
The top-down influence of buildingand using a representation is mentioned as important.The fact that many texts do not follow a strict linearordering of connections between statements againconfirms our concern with a variety of possible coherenttransmissions.In brief, discovering psychological experiments thatagree with the constraints of our model serve to defendits design.
Further, some suggestions we make aboutcomputational measures of discourse processing mayserve to inspire new experiments into the nature ofhuman processing.
So, the relationship with psychologyshould be a two-way exchange, and suggests future work.6 USEFULNESS OFTHE THEORYThe computational model for the analysis of arguments,as described in the previous sections, is built on a theoryof argument understanding; it, in turn, can be used as thebasis for an implementation of an argument understand-ing system.
One suggested real-life application area is acomplaint bureau for department stores.
Future workcould include a full implementation of the mbdel, andfine-tuning the design by selecting a particular applica-tion area for arguments.Although there is no complete implementation of themodel to date, an overview of a possible design ispresented here, to indicate how the various componentsof the model could come together into one integrated"system".
(Note that an initial implementation of themodel does exist now, written in Prolog (Smedley 1986).But this program merely tests the various reception algo-rithms described in section 2.
The evidence oracle isreplaced by a "query the user" facility.
Nonetheless, thegroundwork is in place for a future implementation thattests the other components of the model).In Figure 1, there are three main modules: the Propo-sition Analyzer, Clue Interpreter, and Evidence Oracle.The Proposition Analyzer takes as input the argumentitself and produces a representation of its underlyingstructure.
For each proposition of the argument theProposition Analyzer attempts to assign it a location inthe representation tree, indicating to which other propo-sition it relates (provides evidence for or receivesevidence from).
The  Proposition Analyzer may call onthe Clue Interpreter in the presence of clues, to assist inthe interpretation.
In addition, once an eligible relative tothe current proposition is selected, the decision of wheth-er an evidence relation exists is made by the EvidenceOracle, which is passed the two propositions andresponds with a yes or no answer.
The Evidence Oraclehas available, a knowledge base of shared facts and, if,possible a model of the speaker.
Moreover, if certainbeliefs of the speaker can be extracted uring the testsfor unstated premises, the model of the speaker may evenbe updated by the Evidence Oracle, to aid in the process-ing of later propositions.In the absence of an implementation, the model canstill be defended as a useful prescription of analysis ofarguments.
This is accomplished in Cohen (1983) byhand simulations of a variety of examples, to demon-strate robustness, and analysis of the complexity of theprocessing algorithms, to demonstrate efficiency.Another argument for the usefulness of the argumentanalysis model is that the theories developed for themodel may be applied to the solution of other languageunderstanding problems.
As a result, the study of argu-ments may be viewed as a worthwhile exercise in thestudy of language.
Some examples of the wider applica-bility of the model are:?
It has been shown that extracting the underlying struc-ture of discourse is useful to study the complexity of22 Computational Linguistics, Volume 13, Numbers 1-2, January-June 1987Robin Cohen Analyzing the Structure of Argumentative DiscoursePROPOSIT ION ANALYZER0EVIDENCE ORACLEmodel of speaker\knowledge baseargument representat ion~ argument inputCLUEINTERPRETER- --> data flow- -> control f lowFigure 1.
System design.analysis.
In the modal, the separation of where andhow proposit ions relate has provided a means of moni-toring the number of calls to an inference engine, apartfrom the more difficult measurement of the process ofactually filling in missing inferences.
Hopeful ly,  somecharacterizat ion of structures for language problemsother than arguments would be extremely beneficial.?
It has been shown that certain linguistic constructionsserve a function in facil itating the analysis process forthe hearer.
Developing common interpretation rulesfor various "linguistic clues" should continue forseveral anguage understanding tasks.?
Some insight has been offered into how communicat ioncan proceed despite differing beliefs of speaker andhearer.
The ideas outl ined for recognizing beliefs simi=lar to one's own, for judging plausible generalizations,should extend to other problems where reasoningbeyond one's current beliefs is required.In addition, very few researchers seem concerned withtruly " low-level"  operations, determining not just"what 's  a good representat ion for discourse" but alsohow this representat ion can be derived, the specif icationof some algorithm for processing.
It is in this domain thatwe feel our research is making a contribution.For  future work, we are currently developing a modelfor discourse analysis in general, based on the principlesof this model 's design.
A hypothesis worth investigatingfrom the existing model is that the resulting represen-tation serves to outline both the linguistic structure of thediscourse and the intentional structure (the speaker'sintentions behind utterances).
The idea is that determin-ing evidence relations in an argumentative discourse maybest be described as uncovering the intended uses ofutterances (e.g., speaker utters P in order to get hearer tobelieve Q), hence reflecting the plan of the speaker.
Butthis main function of deriving intentional structure mustbe performed in conjunction with testing " logical"connections between proposit ions, and recognizingclues, thus isolating linguistic structure (or grouping intosegments).
We are interested in specifying a processingmodel for discourse understanding that operates at thelevel of individual utterances, in the manner of the argu-ment model, to gain insight into how to derive linguisticand intentional structure simultaneously.
This research isof significance to the current work of Grosz and Sidner(1986).ACKNOWLEDGMENTSThis work was supported in part by the Natural  Sciencesand Engineering Research Counci l  of Canada.
I amgrateful to the anonymous referees for their valuablecomments and to Ray Perrault  for his initial supervisionof this research.REFERENCESArchbold, A.
1976 A Study of Some Argument Forms in a PersuasionDialogue.
ISI internal document, Marina del Rey, California.Archbold, A. and Hobbs, J.
1980 Notes on "The Analysis of Evalua-tive Argumentation i Text": A Report on On-Going Work.
SRIunpublished draft, Menlo Park, California.Birnbaum, L.; Flowers, M.; and McGuire, R. 1980 Towards an AIModel of Argumentation.
Proceedings of American Association .forArtificial Intelligence (AAAI) Conference: 313-315.Cohen, P. 1978 On Knowing What to Say: Planning Speech Acts.Technical Report No.
118, Computer Science Department, Univer-sity of Toronto, Toronto, Ontario, Canada.Cohen, R. 1980 Understanding Arguments.
Proceedings of CanadianSociety for Computational Studies of Intelligence (CSCSI) Conference:272-279.Cohen, R. 1981 Investigation of Processing Strategies for the Struc-tural Analysis of Arguments.
Proceedings of the Association forComputational Linguistics (ACL) Conference: 71-75.Cohen, R. 1983 A Computational Model for the Analysis of Argu-ments.
Ph.D. thesis, Technical Report No.
151, Computer SystemsResearch Group, University of Toronto, Toronto, Ontario, Canada.Cohen, R. 1984a A Theory of Discourse Coherence for ArgumentUnderstanding.
Proceedings of Canadian Society for ComputationalStudies of lntelligence(CSCSl) Conference: 6-10.Cohen, R. 1984b A Computational Theory of the Function of ClueWords in Argument Understanding.
Proceedings of lOth Interna-tional Conference on Computational Linguistics (COLING 84):251-258.Cohen, R. 1985 The Need for Pragmatics inNatural Language Under-standing.
Proceedings of CSCSI-sponsored Theoretical Advances inNatural Language Understanding Conference.Gazdar, G. 1979 Pragmatics: lmplicature.
Presupposition and LogicalForm.
Academic Press, New York, New York.Geva, E. 1981 Flowcharting Expository Texts and Reading Compre-hension.
Paper presented al, Annual Meeting of American Educa-tional Research Association.Grosz, B.
1977 The Representation and Use of Focus in DialogueUnderstanding.
SRI Technical Note No.
151, Menlo Park, Califor-nia.Grosz, B. and Sidner, C. 1986 The Structures of Discourse Structure.Report No.
6097.
Bolt, Beranek and Newman (BBN) Cambridge.Computational Linguistics, Volume 13, Numbers 1-2, January-June 1987 23Robin Cohen Analyzing the Structure of Argumentative DiscourseMassachusetts.
(also Report No.
CSLI-85-39; Attention, Intentions,and the Structure of Discourse, Computational Linguistics 12(3):175-204.Hobbs, J.
1976 A Computational Approach to Discourse Analysis.Rescarch Report No.
76-2.
City University of New York Depart-ment of Computer, New York, New York.Labov, W. and Fanshel, D. 1977 Therapeutic Discourse.
AcademicPress, New York, New York.McCarty, L. and Sridharan, N.S.
1981 A Computational Theory ofLegal Argumentation.
Research Report LRP-TR-13, RutgersUnivcrsity Lab for Computer Science, New Brunswick, New Jersey.McGuirc, R., Birnbaum, L. and Flowers, M. 1981 Opportunistic Proc-cssing in Arguments.
Proceedings of the International Joint Conferenceon Artificial lntelligence.bf one;(lJCAl) Conference: 58-60.Pollack, M. 1986 A Model of Plan Inference that DistinguishesBetween the Beliefs of Actors and Observers.
Proceedings of theAssociation for Computational Linguistics (ACL) Conference: 207-214.Quirk, R. et.
al.
1972 A Grammar of Contemporary English.
LongmansCo., London, England.Reichman, R. 1981 Plain Speaking: A Theory and Grammar of Spon-taneous Discourse.
Report No.
4681, Bolt, Beranek and Newman(BBN), Cambridge, Massachusetts..Sadock, J.
1977 Modus Brevis: The Truncated Argument.
Papers fromthe 13th Regional Meeting, Chicago Linguistics Society: 545-554.Sidner, C. 1979 Towards a Computational Theory of DefiniteAnaphora Comprehension i English Discourse.
AI Lab ReportTR-537, Massacusetts Institute of Technology (MIT), Cambridge,Massachusetts.Smedley, T. 1986 An Implementation f a Computational Model forthe Analysis of Arguments: An Introduction to the First Attempt.Research Report CS-86-26, University of Waterloo Department ofComputer Science, Waterloo, Ontario, Canada.Weiner, J.
1979 BLAH, A System which Explains Its Reasoning.
Tech-nical Report TR 79-14, University of New Hampshire ComputerScience Department, Durham, New Hampshire.24 Computational Linguistics, Volume 13, Numbers 1-2, January-June 1987
