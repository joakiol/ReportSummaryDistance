Upper Modeling: organizing knowledge for naturallanguage processingJ ohn  A .
BatemanUSC/ In format ion  Sciences Inst i tute4676 Admira l ty  WayMar ina  del Rey, CA 90292-6695, U.S.A.e-mail:  bateman@isi .eduAbst rac tA general, reusable computational resource has been de-veloped within the Penman text generation project fororganizing domain knowledge appropriately for linguis-tic realization.
This resource, called the upper  model,provides a domain- and task-independent classificationsystem' that supports sophisticated natural languageprocessing while significantly simplifying the interfacebetween domain-specific knowledge and general linguis-tic resources.
This paper presents the results of our ex-periences in designing and using the upper model in avariety of applications over the past 5 years.
In par-ticular, we present our conclusions concerning the ap-propriate organization of an upper model, its domain-independence, and the types of interrelationships thatneed to be supported between upper model and gram-mar and semantics.In t roduct ion :  in ter fac ing  w i th  a textgenerat ion  sys temConsider the task of interfacing a domain-independent,reusable, general text generation system with a partic-ular application domain, in order to allow that appli-cation to express ystem-internal information in one ormore natural anguages.
Internal information eeds tobe related to strategies for expressing it.
This couldbe done in a domain-specific way by coding how theapplication domain requires its information to appear.This is clearly problematic, however: it requires de-tailed knowledge on the part of the system builder bothof how the generator controls its output forms and thekinds of information that the application domain con-tains.
A more general solution to the interfacing prob-lem is thus desirable.We have found that the definition of a mapping be-tween knowledge and its linguistic expression is facil-itated if it is possible to classify any particular in-stances of facts, states of affairs, situations, etc.
thatoccur in terms of a set of general objects and re-lations of specified types that behave systematicallywith respect to their possible linguistic realizations.This approach has been followed within the PENMANtext generation system \[Mann and Matthiessen, 1985;The Penman Project, 1989\] where, over the past 5years, we have been developing and using an extensive,domain- and task-independent organization of knowl-edge that supports natural language generation: thislevel of organization is called the upper  model  \[Bate-man et aL, 1990; Mann, 1985; Moore and Arens, 1985\].The majority of natural anguage processing systemscurrently planned or under development are now recog-nizing the necessity of some level of abstract 'semantic'organization similar to the upper model that classifiesknowledge so that it may be more readily expressedlinguisticaUy.
1 However, they mostly suffer from eithera lack of theoretical constraint concerning their internalcontents and organization and the necessary mappingsbetween them and surface realization, or a lack of ab-straction which binds them too closely with linguisticform.
It is important both that the contents of sucha level of abstraction be motivated on good theoreticalgrounds and that the mapping between that level andlinguistic form is specifiable.Our extensive xperiences with the implementationand use of a level of semantic organization of this kindwithin the PENMAN system now permit us to state someclear design criteria and a well-developed set of neces-sary functionalities.The  Upper  Mode l ' s  Cont r ibut ion  to  theSo lu t ion  to  the  In ter face  Prob lem:Domain  independence  and  reusab i l i tyThe upper model decomposes the mapping problem byestablishing a level of linguistically motivated knowl-edge organization specifically constructed as a reponseXIncluding, for example: the Functional Sentence Struc-ture of  XTRA: \[Allgayer et al, 1989\]; \[Chen and Cha,1988\]; \[Dahlgren et al, 1989\]; POLYGLOSS: \[Emele et ai.,1990\]; certain of the Domain and Text Structure Objectsof SPOKESMAN: \[Meteer, 1989\]; TRANSLATOR: \[Nixenberg etaL, 1987\]; the Semantic Relations of ~UROTa^-D: \[Steineret al, 1987\]; JANUS: \[Weischedel, 1989\].
Space naturallyprecludes detailed comparisons here: see \[Bateman, 1990\]for further discussion.54to the task of constraining linguistic realizations2; gen-erally we refer to this level of organization as mean-ing rather than as knowledge in order to distinguishit from language-independent k owledge and to em-phasize its tight connection with linguistic forms (cf.\[Matthiessen, 1987:259-260\]).
While it may not be rea-sonable to insist that application domains organize theirknowledge in terms that respect linguistic realizations- -  as this may not provide suitable orgunizations for,e.g., domain-internal reasoning - -  we have found thatit is reasonable, indeed essential, that domain knowl-edge be so organized if it is also to support expressionin natural anguage relying on general natural anguageprocessing capabilities.The general types constructed within the uppermodel necessarily respect generalizations concerninghow distinct semantic types can be realized.
We thenachieve the necessary link between particular domainknowledge and the upper model by having an appli-cation classify its knowledge organization in terms ofthe general semantic ategories that the upper modelprovides.
This does not require any expertise in gram-mar or in the mapping between upper model and gram-mar.
An application eeds only to concern itself withthe 'meaning' of its own knowledge, and not with finedetails of linguistic form.
This classification functionssolely as an interface between domain knowledge andupper model; it does not interfere with domain-internalorganization.
The text generation system is then re-sponsible for realizing the semantic types of the levelof meaning with appropriate grammatical forms, s Fur-ther, when this classification has been established fora given application, application concepts can be usedfreely in input specifications since their possiblities forlinguistic realization are then known.
This supportstwo significant functionalities:?
interfacing with a natural language system is radi-cally simplified since much of the information spe-cific to language processing is factored out of the in-put specifications required and into the relationshipbetween upper model and linguistic resources;?
the need for domain-specific linguistic processingrules is greatly reduced since the upper model pro-vides a domain-independent, general and reusableconceptual organization that may be used to classifyall domain-specific knowledge when linguistic pro-cessing is to be performed.~Although my discussion here is oriented towards textgeneration, our current research aims at fully bi-directionallinguistic resources \[Kasper, 1988; Kasper, 1989\]; the map-ping is therefore to be understood as a bi.directional map-ping throughout.3This is handled in the PeNM*N system by the grammar'sinquiry semantics, which has been described and illustratedextensively elsewhere (e.g., \[Bateman, 1988; Mann, 1983;Matthiessen, 1988\]).An example of the simplification that use of the uppermodel offers for a text generation system interface lan-guage can be seen by contrasting the input specificationrequired for a generator such as MUMBLE-86 \[Meteer elal., 1987\] - -  which employs realization classes consid-erably less abstract han those provided by the uppermodel - -  with the input required for Penman.
4 Fig-ure 1 shows corresponding inputs for the generation ofthe simple clause: Fluffy is chasing little mice.
The ap-propriate classification of domain knowledge conceptssuch as chase, cat, mouse, and little in terms of thegeneral semantic types of the upper model (in this case,directed-action, object, object, and size respectively - -for definitions ee: \[Bateman et al, 1990\]) automaticallyprovides information about syntactic realization thatneeds to be explicitly stated in the MUMBLE-86 input(e.g., S-V-O_two-explicit-args, rip-common-noun,restrictive-modifier, adjective).
Thus, for ex-ample, the classification of a concept mouse as an ob-ject in the upper model is sufficient for the grammarto consider a realization such as, in MUMBLE-86 terms,a general -np with a particular np-common-noun a daccessor ies  of gender neuter.
Similarly, the classi-fication of chase as a directed-action opens up linguis-tic realization possibilities including clauses with a cer-tain class of transitive verbs and characteristic possi-bilities for participants, corresponding nominalizations,etc.
Such low-level syntactic information is redundentfor the PENMAN input.The further domain-independence of the upper modelis shown in the following example of text generationcontrol.
Consider two rather different domains: a navydatabase of ships and an expert system for digital cir-cuit diagnosis.
5 The navy data base contains informa-tion concerning ships, submarines, ports, geographicalregions, etc.
and the kinds of activities that ships, sub-marines, etc.
can take part in.
The digital circuit di-agnosis expert system contains information about sub-components ofdigital circuits, the kinds of connectionsbetween those subcomponents, heir possible functions,etc.
A typical sentence from each domain might be:circuit domain: The faulty system is connected tothe inputnavy domain: The ship which was inoperative issailing to SaseboThe input specifications for both of these sentencesare shown in Figure 2.
These specifications freely in-termix upper model roles and concepts (e.g., domain,'Note that this is not intended to single out MUMBL~-88:the problem is quite general; cf.
unification-based fframe-works such as \[McKeown and Paris, 1987\], or the Lexi-cal Functional Grammar (LFG)-based approach of \[Mommaand DSrre, 1987\].
As mentioned above, the current devel-opments within most such approaches are now consideringextensions similar to that covered by the upper model.SThese are, in fact, two domains with which we have hadexperience generating texts using the upper model.55(general-clause:head (CHASFES/S-V-0_two-explicit -args(genereL1-np:head (rip-proper-name ?
'Fluffy"): accessor ies  ( : number s ingu lar: gender mascul ine:person th i rd: determiner -po l i cyno-determiner)  )(genera l -np:head (np-common-noun "mouse"): accessor ies  ( : number p lu ra l: gender neuter: person th i rd: detei~miner-pol icyinit iall y-inde f init e): further-specifications( ( : attachment-functionrestrictive-mod/fier: specification(predication-to-be *self*(ad jec t ive  "little"))))) ):accessories (:tense-modal present :progressive:unmarked) ).- Input to MUMSLE-86 for the clause:Fluffy is chasing little micefrom: Meteer, McDonald, Anderson, Forster, Gay,Huettner, and Sibun (1987)(e / chase:ac tor  (e / cat  :name F lu f fy ):ac tee  (m / mouse:size-ascription (s / little):lultiplicity-q multiple: s ingu lax i t  y-q nonsinbmlar): tense present -progress ive)Corresponding input to PENMANFigure 1: Comparison of input requirements forMUMBLE-86 and PENMANrange, property-ascription) and the respective domainroles and concepts (e.g., system, faulty, input, destina-tion, sail, ship, inoperative).
Both forms are renderedinterpretable by the subordination of the domain con-cepts to the single generalized hierarchy of the uppermodel.
This is illustrated graphically in Figure 3.
Herewe see the single hierarchy of the upper model beingused to subordinate concepts from the two domains.The domain concept system, for example, is subordi-nated to the upper model concept object, domain con-cept inoperat ive to upper model concept quality, etc.By virtue of these subordinations, the grammar and se-mantics of the generator can interpret the input speci-fications in order to produce appropriate linguistic re-alizations: the upper model concept object licenses aparticular set of realizations, as do the concepts qual-ity, material-process, etc.Our present upper model contains approximately 200(e l  / connects:domain (v2 / system: relations(v3 / property-ascription: domain v2:range (v4 / faulty))):range (v5 / input): tense present)Input for digital circuit example sentence:The faulty system is connected to the input(el / sail:actor (v2 / ship: relat ions(v3 / property-ascription: domain v2:range (v4 / inoperative): tense past):destination (sasebo / port):tense present-progressive)Input for navy example sentence:The ship which was inoperative is sailing to SaseboFigure 2: Input specifications from navy and digitalcircuit domainssuch categories, as motivated by the requirements of thegrammar, and is organized as a structured inheritancelattice represented in the LOOM knowledge representa-tion language \[MacGregor and Bates, 1987\].
Generally,the upper model represents the speaker's experience interms of generalized linguistically-motivated 'ontolog-ical' categories.
More specifically, the following infor-mation is required (with example categories drawn fromthe current PENMAN upper model):?
abstract specifications of process-type/relations andconfigurations of participants and circumstances(e.g., NO NDIRECTED-ACTION, ADDRESSEE-ORIENTED-VERBAL-PROCESS,ACTOR, SENSER, RECIPIENT, SPATIO-TEMPORAL,CAUSAL-RELATION, GENERALIZED-MEANS),?
abstract specifications of object types, for, e.g., se-mantic selection restrictions (e.g.,DECOMPOSABLE-OBJECT, ABSTRACTION, PERSON,SPATIAL-TEMPORAL),?
abstract specifications ofquality types, and the typesof entities which they may relate (e.g., BEHAVIORAL-QUALITY, SENSE-AND-MEASURE'QUALITY, STATUS-QUALITY),?
abstract specifications of combinations of events (e.g.,DISJUNCTION, EXEMPLIFICATION, RESTATEMENT).These are described in full in \[Bateman et al, 1990\].Appropriate linguistic realizations are not in a one-to-one correspondence with upper model concepts, how-ever.
The relationship needs to be rather more complexand so the question of justification of upper model con-cepts and organization becomes crucial.56IFigure 3: Upper model organization reuse with differingdomainsDegree of Abstraction vs. LinguisticResponsibilityThe general semantic types defined by a level of mean-ing such as the upper model need to be 'linguisti-cally responsible', in that mappings between them andlinguistic form may be constructed.
In addition, tobe usable by an application, they must also be suf-ficiently operationalizable so as to support consistentcoding of application knowledge.
Both of these require-ments have tended to push the level of organizationdefined closer towards linguistic form.
However, it isalso crucial for this organization to be su~ciently ab-stract, i.e., removed from linguistic form, so that it ispossible for an application to achieve its classificationpurely on grounds of meaning.
It is thus inadequateto rely on form-oriented criteria for upper model con-struction because grammatical classifications are oftennon-isomorphic tosemantic lassifications: they there-fore need to deviate from semantic organization i or-der to respect he syntactic riteria that define them.Reliance on details of linguistic realization also compro-mises the design aim that the applications should notbe burdened with grammatical knowledge, eeThis is also resonant with the design aim in text gen-eration that higher level processes -- e.g., text plannersshould not need irect access to low level information such asthe grammar \[Hovy et al, 1988\].
For descriptions ofall theseThus, the level of abstraction of an upper model mustbe sufficiently high that it generalizes across syntac-tic alternations, without being so high that the map-ping between it and surface form is impossible to state.This tension between the requirements of abstractnessand linguistic responsibility presents perhaps the ma-jor point of general theoretical difficulty and interestfor future developments of upper model-like levels ofmeaning.
Without a resolution, substantive progressthat goes beyond revisions of what the PENMAN up-per model already contains is unlikely to be achieved.It is essential for constraints to be found for what anupper model should contain and how it should be orga.nized so that an appropriate level of abstraction may beconstructed.Constraining the Organization of anUpper ModelFigure 4 sets several methodologies have been pursuedfor uncovering the organization" and contents of a levelof meaning such as an upper model, with examples ofapproaches that have adopted them, along the contin-uum of abstraction from linguistic form to abstract on-tology.
While the problem of being too bound to lin-guistic form has been mentioned, there are also severeproblems with attempts to construct an upper modelindependent of form and motivated by other criteria,e.g., a logical theory of the organization of knowledgeper se.
Without a strong theoretical connection to thelinguistic system the criteria for organizing an abstrac-tion hierarchy remain ill-specified; there is very littleguarantee that such systems will organize themselvesin a way appropriate for interfacing well with the lin-guistic system.
7An alternative route is offered by the approachesin the middle of the continuum, i.e., those which ab-stract beyond linguistic form but which still maintaina commitment to language as a motivating force.
Thisis further strengthened by the notion, now resurgentwithin current linguistics, that the organization of lan-guage informs us about the organization of 'knowl-edge' (e.g., \[HaUiday, 1978; Jackendoff, 1983; Lan-gacker, 1987; Matthiessen, 1987; Talmy, 1987\]): that is,the relation between grammar and semantics/meaningis not arbitrary.
Detailed theories of grammar can thenbe expected to provide us with insights concerning theorganization that is required for the level of meaning.We have found that the range of meanings required tosupport one particular generalized functional region ofdistinctions in detail, see the PENMAN documentation \[ThePenman Project, 1989\].7Furthermore, the experience of the JANUS project (e.g.,\[Weischedel, 1989\]) has been that the cost of using a suffi-ciently rich logic to permit axiomatization of the complexphenomenon required is very high, motivating augmentationby an abstraction hierarchy very similar to that of the uppermodel and facing the same problem of definitional criteria.57nonlinguisticlinguisticreahtyknowledgemeaningformcognit ive-  'psychological'situational - -'socio/psycho-logical'grammatical semanticsinquiry semanticsclause-basedlexicai semanticsword sensesword-basedsyntactic realization classessyntaxWeischedel (1989)Langacker (1987)Steiner (fc)Halllday & Matthiessen (fc)PENMAN UPPER MODELJackendoff (1983), LVGMel'euk & ~holkovskij (1970)Steiner et al (1987)LFGFigure 4: Sources of motivations for upper model developmentthe grammar developed within the PENMAN system pro-vides a powerful set of organizing constraints concern-ing what an upper model should contain.
It providesfor the representation f'conceptual' meanings at a highlevel of abstraction while still maintaining a mapping tolinguistic form.
This functional region corresponds withthe Systemic Functional Linguistic notion of the expe-riential metafunction \[Matthiessen, 19877\], one of fourgeneralized meaning types which are simultanously andnecessarily made whenever language is used.
Any sen-tence must contain contributions to its function from allfour 'metafunctions' R each metafunction providing adistinct type of constraint.
The value of this factoriza-tion of distinct meaning types as far as the design ofan upper model is concerned can best be seen by ex-amining briefly what it ezcludes from consideration forinclusion within an upper model: i.e., all informationthat is controlled by the remaining three metafunctionsshould not be represented.The logical metaf~nction is responsible for the con-struction of composite semantic entities using the re-sources of interdependency; it is manifested in grammarby dependency relationships such as those that hold be-tween the head of a phrase and its dependents and theassociation of concepts to be expressed with particu-lar heads in the sentence structure.
The removal ofthis kind of information permits upper model specifi-cations to be independent of grammatical constituentsand grammatical dominance relations.This relaxes, for example, the mapping between ob-jects and processes at the upper model level and nomi-nals and verbals at the grammatical level, enabling en-eralizations to be captured concerning the existence ofverbal participants in nominalizations, and permits thelargely textual variations hown in (1) and (2) 8 to beremoved from the upper model coding.
(1) It will probably rain tomorrowIt is fikely that it will rain tomorrowSExample taken from \[Meteer, 1988\].There is a high probability that it will rain tomorrow(2) independentlyin a way that is independentNo change in upper model representation r classifica-tion is required to represent these variations.This can be seen more specifically by considering thefollowing PENMAN input specification that uses only up-per model terms:((cO / came-effect: domain discharge: range breakdown)(discharge / d i rected-act ion:actee (e lec t r i c i ty  / substance))(breakdoen / nondirected-action:actor (system / object)))This states that there are two configurations of pro-cesses and participants - -  one classified as an uppermodel directed-action, the other as a nondirected-action- -  which are related by the upper model relationshipcause-effect.
Now, the assignment of concepts to differ-ently 'ranked' heads in the grammar governs realizationvariants including the following:Electricity being discharged resulted in the systembreaking down.Because electricity was discharged, the system brokedown.Because of electricity being discharged the system brokedown.. .
.
the breakdown of the system due to an electricaldischarge...Electricity was discharged causing the system to breakdown.. .
.
an electrical discharge causing the breakdown of thesystem...etc.Many such 'paraphrase' issues are currently of concernwithin the text generation community (e.g., \[Meteer,1988; Iordanskaja et al, 1988; Bateman and Paris,1989; Bateman, 1989\]).The textual metafunction is responsible for the cre-ation and presentation of text in context, i.e., for estab-58lishing textual cohesion, thematic development, rhetori-cal organization, information salience, etc.
The removalof this kind of information allows upper model specifi-cations to be invariant with respect o their particularoccasions of use in texts and the adoption of textuallymotivated perspectives, such as, e.g., theme/rheme s -lections, definiteness, anaphora, etc.
Thus, with thesame input specification as above, the following varia-tions are supported by varying the textual constraints:It was the electricity being discharged that resulted inthe system breaking down.The discharge of electricity resulted in the system break-ing down.The system breaking down --  the electricity being dis-charged did it!etc.These textual variations are controlled uring theconstruction oftext (cf.
\[Matthiessen, 1987; Dale, 1989;Hovy and McCoy, 1989; Meteer, 1989; Bateman andMatthiessen, 1990\]) and, again, are factored out of theupper model.The interpersonal metafunction is responsible for thespeaker's interaction with the listener, for the speechact type of an utterance, the force with which it is ex-pressed, etc.
Thus, again with the same input specifi-cation, the following variants are possible:Did electricity being discharged result in the systembreaking down?Electricity being discharged resulted surprisingly in thewhole damn thing breaking down.1 rather suspect hat electricity being discharged mayhave resulted in the system breaking down.etc.The metafunctional factorization thus permits theupper model to specify experiential meanings that areinvariant with respect to the linguistic alternationsdriven by the other metafunetions.
That is, a speci-fication in upper model terms is consistent with a set oflinguistic realizations that may be regarded as 'experi-ential paraphrases': the specification expresses the 'se-mantic' content that is shared across those paraphrasesand often provides just the level of linguistically de-committed representation required for nonlinguisticallyoriented applications.
Generation of any unique sur-face realization is achieved by additionally respectingthe functional constraints hat the other metafunctionsbring to bear; particular surface forms are only specifi-able when a complete set of constraints from each of thefour metafunctions are combined.
The application ofthese constraints i  directly represented in the PENMANgrammar, which provides for the perspicuous and mod-ular integration of many disparate sources of informa-tion.
The interdependencies b tween these constraintsand their conditions of applicability are also directlyrepresented in the grammar.
This organization of thegrammar allows us to construct a rather abstract up-per model while still preserving the necessary mappingto linguistic form.
The value of achieving the abstractspecification ofmeaning supported by the upper modelis then that it permits a genuinely form-independent,but nevertheless form-constraining, 'conceptual' repre-sentation that can be used both as a statement of thesemantic ontents of an utterance and as an abstractspecification ofcontent for application domains that re-quire linguistic output.Summary  and  Conc lus ionsA computational resource has been developed withinthe PENMAN text generation project that significantlysimplifies control of a text generator.
This resource,called the upper model, is a hierarchy of concepts thatcaptures emantic distinctions necessary for generatingnatural anguage.
Although similar levels of abstractsemantic organization are now being sought in manynatural language systems, they are often built anew foreach project, are to an unnecessary extent domain ortheory specific, are required to fulfill an ill-determinedset of functionalities, and lack criteria for their design.This paper has presented the results of our experiencesin designing and using the upper model in a variety ofapplications; in particular, it presented our conclusionsconcerning the appropriate source of constraints con-cerning the organization of an upper model.
We havefound that restricting the information contained in anupper model to experiential meaning has significantlyimproved our understanding of how a semantic hier-archy should be organized and how it needs to relateto the rest of the linguistic system.
We strongly feel,therefore, that subsequently constructed semantic or-ganizations should follow the guidelines et out by themetafunctional hypothesis; the factorization that it pro-vides concerning what should, and should not, be rep-resented in an 'abstract semantic knowledge' hierarchysupports functionalities well beyond those envisioned incurrent ext generation/understanding systems.AcknowledgmentsThe upper model has been under development for severalyears, and many have and continue to contribute to it.
Theideas I have reported on here would not have been possi-ble without hat development.
Those responsible for thepresent form of the upper model include: William Mann,Christian Matthiessen, Robert Kasper, Richard Whitney,Johanna Moore, Eduard Hovy, Yigal Arens, and mysel?Thanks also to C~:ile Pads and Eduard Hovy for improvingthe paper's organization.
Financial support was provided byAFOSR contract F49620-87-C-0005, and in part by DARPAcontract MDA903-87-C-641.
The opinions in this report aresolely those of the author.References\[Allgayer et al, 1989\] JSrgen Allgayer, Karin Har-busch, Alfred Kobsa, Carola Reddig, Norbert Rei-thinger, and Dagmar Schmauks.
Xtra: a natural-language access system to expert systems.
Inter-59national Journal of Man-Machine Communication,1989.\[Bateman and Matthiessen, 1990\] John A. Batemanand Christian M.I.M.
Matthiessen.
Uncovering thetext base.
In Hermann Bluhme and Hag Keqi, edi-tors, Selected Papers from the International Confer-ence on Research in Text and Language, Xi'an Jiao-tong University, Xi'an, P.R.
China, 29-31 March1989.
1990.\[Bateman and Paris, 1989\] John A. Bateman andC~cile L. Paris.
Phrasing a text in terms the usercan understand.
In Proceedings of the Eleventh Inter-national Joint Conference on Artificial Intelligence,Detroit, Michigan, 1989.
IJCAI-89.\[Bateman etaL, 1990\] John A. Bateman, Robert T.Kasper, Johanna D. Moore, and Richard A. Whitney.A general organization of knowledge for natural lan-guage processing: the penman upper model.
Techni-cal report, USC/Information Sciences Institute, Ma-rina .del Rey, California, 1990.\[Bateman, 1988\] John A. Bateman.
Aspects of clausepoliteness in Japanese: an extended inquiry seman-tics treatment.
In Proceedings of the 26th Inter-national Conference on Computational Linguistics,pages 147-154, Buffalo, New York, 1988.
Associationfor Computational Linguistics.
Also available as ISIReprint Series report RS-88-211, USC/InformationSciences Institute, Marina del Rey, California.\[Bateman, 1989\] John A. Baternan.
Upper modellingfor machine translation: a level of abstraction forpreserving meaning.
Technical Report EUROTRA-D Working Papers, No.
12, Institut fdr AngewandteInformationsforschung, Saarbriicken, West Germany,1989.\[Bateman, 1990\] John A. Bateman.
Upper modeling:current states of theory and practise, 1990.
PENMANDevelopment Note, USC/Inforrnation Sciences Insti-tute.\[Chen and Cha, 1988\] Keh-Jiann Chen and Chuan-ShuCha.
The design of a conceptual structure and its re-lation to the parsing of chinese sentences.
In Proceed-ings of the 1988 International Conference on Com-puter Processing of Chinese and Oriental Languages,Toronto, Canada, August 29 - September 1 1988.\[Dahlgren etat., 1989\] Kathleen Dahlgren, Joyee Me-Dowell, and Edward P. Stabler.
Knowledge represen-tation for commonsense r asoning with text.
Com-putational Linguistics, 15(3):149-170, 1989.\[Dale, 1989\] Robert Dale.
Cooking up referring expres-sions.
In Proceedings of the Twenty-Seventh AnnualMeeting of the Association for Computational Lin-guistics, Vancouver, British Columbia, June 1989.Association for Computational Linguistics.\[Emele t al., 1990\] Martin Emele, Ulrich Heid, WalterKehl, Stefan Momma, and R~mi Zajac.
Organizinglinguistic knowledge for multilingual generation.
InCOLING-90, 1990.
Project Polygloss Paper, Univer-sity of Stuttgart, West Germany.\[Halliday and Matthiessen, forthcoming\] Michael A.K.Halliday and Christian M.I.M.
Matthiessen.
TheBloomington Lattice.
Technical Report in prepara-tion, University of Sydney, Linguistics Department,Sydney, Aystralia, forthcoming.\[Halliday, 1978\] Michael A. K. Halliday.
Language associal semiotic.
Edward Arnold, London, 1978.\[Hovy and McCoy, 1989\] Eduard H. Hovyand Kathy F. McCoy.
Focusing your RST: A steptowards generating coherent multisentential text.
InProceedings of the llth.
Annual Conference of theCognitive Science Society, pages p667--674, Univer-sity of Michigan, Ann Arbor, Michigan, August 16-19 1989.
Hillsdale, New Jersey: Lawrence ErlbaumAssociates.J\[Hovy et al, 1988\] Eduard H. Hovy, Douglas Appelt,and David D. McDonald.
Workshop on text plan-ning and natural anguage generation, August 1988.Sponsored by American Association for Artificial In-teUigence.\[Iordanskaja et al, 1988\] Lidija Iordanskaja, RichardKittredge, and Polgu~re Alain.
Lexical selectionand paraphrase in a meaning-text generation model,July 1988.
Presented at the Fourth InternationalWorkshop on Natural Language Generation.
Also ap-pears in selected papers from the workshop: Paris,Swartout and Mann (eds.)(1990)(op.
cir.
).\[Jackendoff, 1983\] Ray Jaekendoff.
Semantics andCognition.
MIT Press, Cambridge, MA, 1983.\[Kasper, 1988\] Robert T. Kasper.
An ExperimentalParser for Systemic Grammars.
In Proceedings ofthe 12th International Conference on ComputationalLinguistics, August 1988, Budapest, Hungary, 1988.Association for Computational Linguistics.
Alsoavailable as Information Sciences Institute TechnicalReport No.
ISI/RS-88-212, Marina del Rey, CA.\[Knsper, 1989\] Robert T. Kasper.
Unification and clas-sification: an experiment in information-based pars-ing.
In Proceedings of the International Workshopon Parsing Technologies, pages 1-7, 1989.
28-31 Au-gust, 1989, Carnegie-Mellon University, Pittsburgh,Pennsylvania.\[Langacker, 1987\] Ronald W. Langaeker.
Foundationsin Cognitive Grammar.
Stanford University Press,Stanford, California, 1987.\[MacGregor and Bates, 1987\] Robert MacGregor andRaymond Bates.
The LOOM knowledge represen-tation language.
In Proceedings of the Knowledge-Based Systems Workshop, 1987.
Held in St. Louis,60Missouri, April 21-23, 1987.
Also available as ISIreprint series report, RS-87-188, USC/InformationSciences Institute, Marina del Rey, CA.\[Mann and Matthiessen, 1985\] William C. Mann andChristian M.I.M.
Matthiessen.
Demonstration f thenigel text generation computer program.
In J. Ben-son and W. Greaves, editors, Systemic Perspectiveson Discourse, Volume 1.
Ablex, Norwood, New Jer-sey, 1985.\[Mann, 1983\] William C. Mann.
The anatomy of asystemic hoice.
Discourse processes, 1983.
Alsoavailable as USC/Information Sciences Institute, Re-search Report ISI/RR-82-104, 1982.\[Mann, 1985\] William C. Mann.
Janus abstractionstructure - draft 1, 1985.
An informal project ech-nical memo of the Janus project at ISI.\[Matthiessen, 1987\]Christian M.I.M.
Matthiessen.
Notes on the organi-zation of the environment ofa text generation gram-mar.
In G. Kempen, editor, Natural Language Gen-eration: Recent Advances in Artificial Intelligence,Psychology, and Linguistics.
Kluwer Academic Pub-lishers, Boston/Dordrecht, 1987.
Paper presentedat the Third International Workshop on NaturalLanguage Generation, August 1986, Nijmegen, TheNetherlands.\[Matthiessen, 1988\] Christian M.I.M.
Matthiessen.
Se-mantics for a systemic grammar: the chooser andinquiry framework.
In James Benson, Michael Cum-mings, and William Grenves, editors, Linguistics in aSystemic Perspective.
Benjamins, Amsterdam, 1988.Also available as USC/Information Sciences Insti-tute, Reprint Series Report ISI/RS-87-189, Marinadel Rey, CA.\[McKeown and Paris, 1987\] Kathleen R.McKeown and C~cile L. Paris.
Functional unifica-tion grammar evisited.
In Proceedings of the 25thAnnual Meeting of the ACL, Palo Alto, California,1987.
Association of Computational Linguistics.\[Mel'~uk and Zholkovskij, 1970\] A. Mel'~uk, Igor andA.K.
Zholkovskij.
Towards a functioning "meaning-text" model of language.
Linguistics, 57:10-47, 1970.\[Meteer et al, 1987\] Marie W. Meteer, David D. Mc-Donald, S.D.
Anderson, D. Forster, L.S.
Gay, A.K.Huettner, and P. Sibun.
MUMBLE-86: Design andimplementation.
Technical Report 87-87, COINS,University of Massachusetts, 1987.\[Meteer, 1988\] Marie W. Mercer.
Defining a vocabu-lary for text planning, August 1988.
Presented atthe AAAI-88 Workshop on Text Planning and Real-ization, organized by Eduard H. Hovy, Doug Appelt,David McDonald and Sheryl Young.\[Meteer, 1989\] W Meteer, Marie.
The SPOKESMAN nat-ural language generation system.
Technical ReportBBN Report No.
7090, BBN Systems and Technolo-gies Corporation, Cambridge, MA., 1989.\[Momma nd DSrre, 1987\] Stefan Momma and JochenDSrre.
Generation from f-structures.
In Ewan Kleinand Johann Van Bentham, editors, Categories, Poly-morphism and Unification.
Cognitive Science Centre,University of Edinburgh, Edinburgh, Scotland, 1987.\[Moore and Areas, 1985\] Johanna D. Moore and Yi-gal Arens.
A hierarchy for entities, 1985.USC/Information Sciences Institute, Internal Draft.\[Nirenberg el al., 1987\] Sergei Nirenberg, V. Raskin,and A. Tucker.
The structure of interlingua inTRANSLATOR.
In Sergei Nirenberg, editor, MachineTranslation: Theoretical and Methodological Issues.Cambridge University Press, Cambridge, 1987.\[Paris et al, 1990\] C~cile L.Paris, William R. Swartout, and William C. Mann,editors.
Natural Language Generation in ArtificialIntelligence and Computational Linguistics.
KluwerAcademic Publishers, 1990.\[Steiner et al, 1987\] Erich H. Steiner, Ursula Eckert,Birgit Week, and Jutta Winter.
The development ofthe EUROTRA-D system of semantic relations.
Tech-nical Report Eurotra-D Working Papers, No.
2, In-stitut der angewandten I formationsforschung, Uni-versit~it des Saarlandes, Saarbriicken, West Germany,1987.\[Steiner, 1990\] Erich H. Steiner.
A model off goal-directed-action as a structuring principle for the con-text of situation in systemic linguistics.
Mouton andde Gruyter, Berlin, 1990.\[Talmy, 1987\] Leonard Talmy.
The relation of gram-mar to cognition.
In B. Rudzka-Ostyn, editor, Topicsin Cognitive Linguistics.
John Benjamins, 1987.\[The Penman Project, 1989\] The PenmanProject.
The PENMAN documentation: User guide,primer, reference manual, and nigel manual.
Techni-cal report, USC/Information Sciences Institute, Ma-rina del Rey, CA, 1989.\[Weischedel, 1989\] Ralph M. Weischedel.
A hybrid ap-proach to representation in the janus natural an-guage processor.
In ~Tth Annual Meeting of the As-sociation for Computational Linguistics, pages 193-202, Vancouver, British Columbia, 1989.6:i.
