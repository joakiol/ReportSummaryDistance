GE-CMU :DESCRIPTION OF THE TIPSTER/SHOGUN SYSTEM ASUSED FOR MUC-4 1Paul Jacobs, George .Krupka and Lisa Ra uArtificial Intelligence Laborator yGE Research and DevelopmentSchenectady, NY 12301 US AE-mail : rau?crd .ge.comPhone: (518) 387 - 505 9andTodd Kaufmann and Michael Mauldi nCenter for Machine TranslationCarnegie Mellon UniversityAbstractThe GE-CMU team is developing the TIPSTER/SHOGUN system under the government-sponsored TIPSTER program, which aims to advance coverage, accuracy, and portability in tex tinterpretation .
The system will soon be tested on Japanese and English news stories in tw onew domains .
MUC-4 served as the first substantial test of the combined system.
Because th eSHOGUN system takes advantage of most of .the components of the GE NLTooLsET excep tfor the parser, this paper supplements the NLTOOLSET system description by explaining th erelationship between the two systems and comparing their performance on the examples fromMUC-4 .INTRODUCTIO NWork on the GE-CMU TIPSTER-SHOGUN system began in the fall of 1991 .
The first stage of the projec tinvolved integrating the resources and algorithms of the existing GE and CMU systems, in order that thecombined team could effectively explore new data extraction methods .
This integration was barely complete din time for MUC-4: There are still some loose ends, and the combined system is still an infant .
The syste mperformed well on MUC-4 because it takes advantage of most of the capabilities of the GE system, an dbecause of the overall system architecture in which different parsers can be easily interchanged .
This paperdescribes this architecture and compares the results of the two parsers on MUC-4 .SYSTEM OVERVIEWThe TIPSTER-SHOGUN system as configured for MUC-4 uses exactly the same architecture as the G Esystem, except that it uses the CMU generalized LR parser instead of the TRUMP analyzer .
The core lexiconand grammar of the GE system, as well as MUC-specific restrictions and additions to the knowledge base ,have been converted to a form that the LR parser can use, and the system interfaces allow the two parser sto be interchanged at the flip of a switch .
In fact, it occasionally proved useful in MUC to test the syste mby toggling between parsers .
'This research was sponsored (in part) by the Defense Advanced Research Project Agency (DOD) and other governmen tagencies .
The views and conclusions contained in this document are those of the authors and should not be interpreted asrepresenting the official policies, either expressed or implied, of the Defense Advanced Research Project Agency or the U SGovernment.186While the integration of the system required some person-months and is still not refined, the effort fo rMUC-4 was very limited .
Most of the time spent on MUC went into testing and executing the final test ,and fixing several important system problems that doubled the system ' s recall between the interim and finaltest .In addition to sharing lexicons, grammars, ontologies, and run-time data structures, the two parsers shar ean evolving control mechanism, which allows for the insertion of new control strategies into both systems .To enable this, the LR parser was augmented to provide dynamic data that look just like TRUMP 'S, andto receive signals and preferences in the same way that TRUMP does .
This helped the parser (which use san all-paths style algorithm) to manage the complexity of the MUC corpus, and allowed the re-use of th erecovery control algorithm .
These additions were required to run the LR parser in MUC, because the systemwas designed for machine translation applications, which have very different requirements (more detaile dprocessing and less ambiguity) .The two parsers, while drastically different algorithmically, are quite similar when used in MUC, wit ha common lexicon and grammar .
The LR parser explores many more parses than TRUMP, but this seem sto make very little difference other than to consume more CPU cycles .
When the parsers fail, they exhibi tdifferent patterns of behavior, but the same recovery strategies work well .
The main difference in recal lbetween the two systems seems to come from the lack of certain recovery strategies in the LR parser, leadingto a greater number of failures, in addition to a variety of system problems that come from having a les smature system at this point .The analysis of the example that follows will illustrate some of these similarities and differences .ANALYSIS OF TST2-004 8Overview of Exampl eProcessing of this example proceeds much as in the NLTooLsET system; the only difference between th etwo systems is that the LR parser fails in one case where TRUMP does not, and fails to recover in anothe rcase .
As a result, the GE-CMU system missed 6 total slots that the GE system got (four from one pars eand two from the other), for .53 recall at .59 precision and .40 overgeneration .Detail of Message Ru nThe two sentences where the parsers differed in TST2-0048 were Si and S13 .
In both cases, the GE systemshad heuristics that covered up potential problems, while the combined system, which had not been teste das extensively, slipped up .On S1, the LR parser failed because of the construct "THE FARABUNDO MARTI NATIONAL LIB-ERATION FRONT" .
Names of organizations are treated quite restrictively in the grammar?they are no tallowed to have modifiers before or after, because this might lead to misinterpretation .
To compensate forthis, the pre-processor recognizes names of organizations and usually deletes determiners or brackets outmodifiers that appear beforehand .
In this case, the pre-processor failed to delete the determiner because i tappeared inside of a larger bracketed construct (ACCUSED .
.
.OF) .
TRUMP corrected for this by applyingone of a handful of parser-specific recovery strategies, which assumes only as it is about to fail that a nam ecould have been interpreted as a noun .
The LR parser, with no such strategy, failed catastrophically in th esecond clause of the sentence, though it still got the first clause .In S13, both parsers failed on the phrase "A 15-YEAR-OLD NIECE OF MERINO'S" because of th eunusual use of the possessive as a noun (rather than a modifier) .
TRUMP recovered the whole sentence byattaching the phrase without the apostrophe-s to the verb phrase after ; the LR parser failed to execute thesame strategy because it could not, for some reason, complete the noun phrase without the apostrophe-s .While this, of course, is a rare case, it is fairly common that the LR parser misses a reduction at the pointof failure, and it is thus somewhat less robust on recovery .Interpretation of Key SentencesBecause the two parsers produce almost identical output, we will not review the sentences here .187Comparison of Program Answers with Answer Ke yAs we have explained, the answers of the GE-CMU system were the same as those of the GE system, excep tfor 6 additional missing slots that came from two parser failures .SUMMARY AND CONCLUSIO NThe experience of testing the TIPSTER-SHOGUN system on MUC-4 was surprisingly rewarding .
Itprovided motivation for pulling together the pieces of the system quickly, and gave the system its first realtest, without the extra overhead of developing new code and knowledge for a particular task .
We wereastonished that each system could benefit from the other to the degree that this experiment proved, andpleasantly surprised at the ability of one parser to emulate another as well as the success with which w eshared algorithms and even code .The rewards come with a price : Maintaining two parsers is more work than maintaining one, and adaptingand testing code and data structures is a tedious process .While the major benefit of the experiment was to prove the degree to which resources could be shared ,the ability to compare differences has advantages as well .
The GE-CMU system exposed some bugs outsideof the parser that for some reason didn't turn up in the GE-only system ; likewise, the comparison of the twoallowed the new strategies to advance much more rapidly than they would have without a reference point .This suggests a wide range of new things to try, from broadly defining the architecture to accommodat eother parsers, to running multiple parsers in parallel as a way of improving accuracy and fault-tolerance .The plug-compatible integration of systems takes task-driven evaluation in MUC to its extreme, allowing acontrolled comparison of modules based on their influence on the system as a whole .188
