Interpreter for Highly Portable Spoken Dialogue SystemMasamitsu UmedaDepartment of Information andComputer Science,Toyohashi University of TechnologyAichi, JAPAN, 441-8580umeda@slp.ics.tut.ac.jpSatoru KogureFaculty of Education,Aichi University of EducationAichi, JAPAN, 448-8542skogure@auecc.aichi-edu.ac.jpSeiichi NakagawaDepartment of Information andComputer Science,Toyohashi University of TechnologyAichi, JAPAN, 441-8580nakagawa@slp.ics.tut.ac.jpAbstractRecently the technology for speech recog-nition and language processing for spokendialogue systems has been improved, andspeech recognition systems and dialoguesystems have been developed to the ex-tent of practical usage.
In order to becomemore practical, not only those fundamen-tal techniques but also the techniques ofportability and expansibility should be de-veloped.
In our previous research, wedemonstrated the portability of the speechrecognition module to a developed portalspoken dialogue system.
And we con-structed a dialogue strategy design toolof dialogue script for controlling the dia-logue strategy.In this paper, we report a highly portableinterpreter using a commercial electronicdictionary.
We apply this to three do-mains/tasks and confirm the validity of theinterpreter for each domain/task.Keywords: spoken dialogue system, robust inter-preter, portability, dialogue script1 IntroductionRecently, much research has been done on the ro-bustness and reliability of spoken dialogue sys-tems.
We developed a ?Mt.Fuji sightseeing guid-ance?
system which uses touch screen input, speechinput/output and graphical output, and have im-proved the sub-modules of a speech recognizer, nat-ural language interpreter, response generator andmulti-modal interface (Kai and Nakagawa, 1995;Itoh et al, 1995; Denda et al, 1996; Kogure et al,1999; Nakagawa et al, 2000).
General speaking, allof these modules except for the speech recognitionmodule depended on a given task or domain.As speech recognition systems are increasinglybeing used in practical applications, spoken dialoguesystems will also become more widespread.
How-ever, the cost of developing a new spoken dialoguesystem is enormous.
The systems that have been de-veloped so far can not be transferred to other do-mains easily, and a highly-portable system that canbe easily adapted to another domain or task urgentlyshould be developed.
There are several examples ofresearches that focused on high portability and ex-pansibility (Kaspar and Hoffmannn, 1998; Brond-sted et al, 1998; Sutton et al, 1998; Sasajima et al,1999; Abella and Gorin, 1999; Levin et al, 2000).In (Kaspar and Hoffmannn, 1998), a prototypecould be simply constructed even in a complicatedspeech dialogue system using the PIA system, whichwas implemented using Visual Basic.
This sys-tem placed priority on achieving high robustness ofspeech recognition and high naturalness of gener-ated dialogue.
However, the system limited the taskto the domain of knowledge search.
E. Levin etal.
reported the design and implementation of theAT&T Communicator mixed-initiative spoken dia-logue system (Levin et al, 2000).
The communica-tor project sponsored by DARPA launched in 1999.On the other hand, we have also considered theportability of spoken dialogue system (Kogure andNakagawa, 2000).
We showed from experience thatFigure 1: System overview.it was difficult to transfer from the Mt.
Fuji sight-seeing guidance existing system to the East Mikawasightseeing guidance.Therefore?we built portable spoken dialogue sys-tem developing tools based on GUI (Kogure andNakagawa, 2000).
Especially, we focused on thedeveloping tools of spoken dialogue system fordatabase retrieval.Some spoken language systems focused on ro-bust matching to handle ungrammatical utterancesand illegal sentences.
The Template Matcher (TM)at the Stanford Research Institute (Moore and Pod-lozny, 1991) instantiates competing templates, eachof which seeks to fill its slots with appropriate wordsand phrases from the utterance.
The template withthe highest score yields the semantic representation.R.Kuhn and R.De Mori suggest a method where thesystem?s rules for semantic interpretation are learntautomatically from training data (Kuhn and Mori,1995).
The rules are encoded in forest of special-ized decision trees called as Semantic Classifica-tion Trees (SCTs).
The learned rules are robust toungrammatical sentences and misrecognition in theinput.
Minker compared a rule-based case framegrammar analysis and a stochastics based case framegrammar analysis for understanding(Minker, 1998).Globally speaking, the performances of the stochas-tic and rule-based parsers were comparable for ATIS(Air Travel Information Service).
Y. Wang sug-gests a robust chart parser which is the major Spo-ken Language Understanding (SLU) engine compo-nent behind MiPad(Wang, 2001).
The robustness toungrammaticality and noise can be attributed to itsability of skipping minimum unparsable segments inthe input.
The robust parsing algorithm is an exten-sion of the bottom-up chart-parsing algorithm.In (Nakagawa et al, 2000), the dialogue systemunderstands spontaneous speech which has manyambiguous phenomena such as interjections, el-lipses, inversions, repairs, unknown words and soon, and responds to the user?s utterance.
But the sys-tem fails to analyze some utterances.
?Incomplete-ness?
with the interpreter mainly causes the analy-sis failure, and leads to domain/task dependent de-velopment.
Therefore, in this paper we focused onimproving the interpreter in order to make it a ro-bust/portable one.For this purpose, we used the EDR electronic dic-tionary as a semantic dictionary and improved theinterpreter so that it had some new functions.
Fi-nally, we applied the system to three domains/tasks;hotel retrieval, Mt.Fuji sightseeing guidance and lit-erature retrieval.2 Highly-portable System for InformationRetrieval from DatabaseThe proposed system in the dialogue processingparts consists of semantics interpreter, retrievalmodule, response generator and dialogue man-ager which integrates three modules.
The systemoverview is shown in Figure 1.Each module has the following roles:?
Speech Recognizer: This module recognizesa user utterance via speech input and generatesa recognized sentence.
We used SPOJUS (Kaiand Nakagawa, 1995) for this.?
Semantic Interpreter: This module under-stands a user utterance via recognized sentenceand generates semantic representation.?
Retrieval Module: This module that extractsthe word as retrieval key word/phrase from thesemantic representation.?
Response Generator: This module is acti-vated by a dialogue manager, selects a kindof response strategies and generates a responsesentence.?
Text-to-speech Module: This module gener-ates a response sentence, synthesizes speechsignals and playbacks this audio files to user.In this paper, we focused on three modules: Se-mantic Interpreter, Retrieval Module and Re-sponse Generator.
We believe that the SpeechRecognizer except for the language models and theText-to-speech Module are domain and task inde-pendent.
A domain/task adaptation technique of thelanguage models for the speech recognizer was pre-liminarily evaluated (Kogure and Nakagawa, 2000).3 Improving the Semantic Interpreter3.1 Adding New FunctionalityOur purpose is to improve our previous inter-preter (Kogure and Nakagawa, 2000) to make itmore robust and portable.
In this study, we imple-mented new functions into the interpreter as follows:?
Processing of Correction Utterance: The sys-tem omits the word sequence as restatementFigure 2: An example of processing of correctionutterance.Figure 3: An example of removing recognition errorcaused by logging error.and word preceding this sequence.
The omittedword sequence is the word or word sequencewhich the user uses when he/she tells the sys-tem to repair the wrong word or word sequence.Figure 2 shows this process.?
Removing Recognition Error by LoggingError: The system ignores non-semanticwords at the head or the tail of the sentencecaused by detection errors of beginning/endingspeech and adopts the grammaticaly longestcandidate from plural candidates as the validFigure 4: An example of improving keyword re-trieval.Figure 5: An example of concept classification.sentence.
Speech segmentation errors in back-ground noise environments yield non-semanticwords.
Figure 3 shows this process.?
Improving Keyword Retrieval: If an inputsentence is inadequate for parsing, the systemcreates a retrieval condition from the semanticlabels which are attached to the word used asthe keyword in a sentence.
Figure 4 shows thisprocess.3.2 EDR Electronic Dictionary for SemanticInterpreterIn the study, we clearly separated domain/task in-dependent parts and dependent parts.
When an ap-plication developer wants to change a domain ortask, he/she modifies or prepares only domain/taskdependent parts, such as semantic features, propernouns, and so on.
In this section, we describe the do-main/task dependent information obtained from theEDR electronic dictionary, which is used to analyzethe utterance in the interpreter.The EDR electronic dictionary1 has widely beenused for research and application development of1http://www.jsa.co.jp/EDR/?
?search[3cec34] :::agent 30f6b0;30f746 =GA,object 3f97b1 =WO?
?Figure 6: An example of case frame.Japanese language processing.
We developed a highportable semantic dictionary for the interpreter usingthe EDR electronic dictionary.3.2.1 Concept DictionaryThe EDR electronic dictionary is constructed by ahierarchical tree structure with classification recordswhich are composed of 410,000 concepts.Figure 5 shows a part of concept classificationfrom ?location.?
?30f751?
denotes the concept clas-sification for ?location.
?We assign the concept for domain/task dependentwords to the existing hierarchical structure.
In Fig-ure 5, ?G-PLACE?
is a keyword which is used forreferencing to a place.
Since the morphologicalanalysis assigns the concept to the word, the inter-preter can use the concept information.3.2.2 Dictionary of Selectional Restriction forJapanese VerbsThe interpreter analyzes an input sentence us-ing the dictionary of selectional restrictions or caseframes for Japanese verbs, which are attached as aco-occurrence dictionary for the EDR electronic dic-tionary.
This dictionary contains information relatedto the surface case and the deep case about mainverbs.
The interpreter converts the input sentenceto the case frame format information using this dic-tionary, which is formalized from the information ona deep case and the conceptual classification infor-mation for every verb using the technique of a selec-tional restriction.Figure 6 shows the case frame of the verb?search?.
It shows that ?3cec34?
is the conceptclassification of ?search.?
When the deep case is?agent?
and the surface case is ?GA?, ?30f6b0?
or?30f746?
is selected, and when the deep case is ?ob-ject?
and the surface case is ?WO?, ?3f97b1?
is se-lected.
Where ?GA?
and ?WO?
are particle peculiars(postpositions) in Japanese.Figure 7: An example of semantic interpreter.3.3 An ExampleFigure 7 shows an example of the interpreter flow.In Figure 7 , the user inputs a Japanese utterancethat means ?What hotels are there along YamanoteLine??
in English.
The interpreter executes the pro-cesses of a morphological analysis and parsing, andgenerates a parsing result that is represented by atree-structure in accordance to the prepared gram-mar.
This sentence?s verb is ?ARU?
(There are, inEnglish), and the concept classification of ?ARU?
is?0e5a74?.
The interpreter generates a semantic anal-ysis result from the parsing result using this conceptclassification information, that is, the case frame of?ARU?.
The system transfers the semantic analysisresult into a retrieval condition.
This condition isused to generate SQL language for the retrieval.4 Domain/Task Independency andDependency4.1 Domain/Task Independency/DependencyIn this section, we describe how to realize the highportability which has the benefit of efficiency whenapplication developers design a new dialogue sys-tem.
That is, while the system performance is kept ata certain level, we will shorten the period of develop-ing the dialogue system as possible.
Therefore, wedefine the domain/task independency/dependency.Domain independency means that application devel-opers can use common data for all domains 2.
Do-main dependency means that applications are not do-main independent.
Task independency means thatapplication developers can use these common datafor all tasks 3 in a certain domain.
Task dependencymeans that is not task independent.
Hereafter, fourdata types are abbreviated as DI, DD, TI, TD, respec-tively.We clearly separated semantics, retrieval and re-sponse modules into DI/DI, DD/TI, TI/TD, and TI/TIparts, respectively.
The system core was built whilstkeeping it completely domain and task independent(DI/TI).
We can divide data sets three types4 asshown in Table 1; DI/TI, DD/TI and DD/TD.
DI/TIdata sets served as information for a morphologicalanalysis except for nouns or verbs with respect tothe domain/task and so on.
DD/TI data sets are usedas information for morphological analysis of nounsor verbs with respect to the domain/task, informa-tion for semantics analysis and so on.
DD/TD datasets are used as information for format that the sys-tem responds the retrieval results and so on.
In the2Domain is a field or area of dialogue object.3Task is the problem or process that the user wants to realizein a particular domain.4Since we define a domain and a task as the above, all do-main independent data sets are surely task independent datasets, therefore DI/TD data sets are none.Table 1: Separation of domain/task dependent data sets and domain/task independent data sets.types DataDI/TIsyllable HMMs, morphological dictionary exceptfor noun and verb, syntactic grammar, noun and verbsemantic dictionary for dialogue processing ,seman-tic dictionary, case frameDD/TI morphological dictionary for noun and verb field in-formation of database, databaseDD/TD convert rule from semantic representation to re-trieval pattern, display format of retrieval resultDI: domain independent DD: domain dependentTI: task independent TD: task dependentFigure 8: Task adaptation.next section, we describe how application develop-ers prepare DD/TI and DD/TD data sets.4.2 System CoreWe used Chasen 5 as Japanese morphological analy-sis and PostgreSQL 6 as a database retrieval man-agement system.
We have constructed SemanticsModules based on the Mt.
Fuji sightseeing guidancesystem (Nakagawa et al, 2000) with separating taskdependent and independent parts.
All parts of thesystem core are clearly DI/TI.5http://chasen.aist-nara.ac.jp/6http://www.pgsql.com/4.3 Data SetsData sets consist of DI/TI, DD/TI and DD/TD datasets.
The separated results are shown in Table 1.5 Task Adaptation -Hotel RetrievalSystem-Figure 8 shows the flow chart of the task adaptation.We consider what kind of data may be prepared astask-dependent knowledge when a new task is ap-plied.
In the proposed framework, the applicationdeveloper prepares the following:?
A generally usable database (machine read-able)?
The format information of each field of thedatabaseA generally usable database------------------------------------------------------------<name>GrandCentralHotel</name><address>2-2 Kandatsukasa-machi Chiyoda Tokyo</address><access>On foot-from JR line and subway line Kanda station 3 minutes</access><land>Tokyo Tower,TOKYO DOME</land><single>8900,7120</single>:------------------------------------------------------------The format information of each field of the databaseDatabase format information------------------------------------------------------------S|<name>|</name>|nameS|<address>|</address>|addressR|<access>|:|,|</access>|accessR|<land>|:|,|</land>|landR|<single>|:|,|</single>|single:------------------------------------------------------------Transfer format information------------------------------------------------------------DATABASE:::hotel:$hotel_id{int},$name{varchar(200)},$address{varchar(200)},$checkin{varchar(10)},$checkout{varchar(10)},$scale{varchar(20)},$room{varchar(20)},$smoking{varchar(20)}acc:$acc_id{int},$hotel_id{int},$access[]{varchar(200)}land:$land_id{int},$hotel_id{int},$land[]{varchar(200)}single:$single_id{int},$hotel_id{int},$single[]{varchar(200)}double:$double_id{int},$hotel_id{int},$double[]{varchar(200)}twin:$twin_id{int},$hotel_id{int},$twin[]{varchar(200)}inside_hotel:$inside_hotel_id{int},$hotel_id{int},$inside_hotel[]{varchar(200)}room:$room_id{int},$hotel_id{int},$room[]{varchar(200)}service:$service_id{int},$hotel_id{int},$service[]{varchar(200)}card:$card_id{int},$hotel_id{int},$card[]{varchar(200)}DATABASE:::Figure 9: An example of hotel information and the definition given by a developer.?
A corpus of user utterances (dialogue exam-ples)The database information retrieval system first re-quires a database (generally, one that is open to thepublic) as a retrieval target.
The format informationof each field in the database should be given in orderto access the database.
In addition, since the dictio-nary and language model are adapted to the databaseinformation retrieval system in the task, a corpus ofthe user utterances is required.For examples, Figure 9 shows a generally usabledatabase and the format information of each fieldof the database in a hotel retrieval system.We used the hotel data of Hornet7 of the hotel ref-erence site in Japan.
The web page of this site canbe automatically translated into a database.
The dataobtained from the HTML source is translated into adata format like the generally usable database inFigure 9.This is translated according to the rules of Fig-ure 9.
In Figure 9, hotel information consists of7http://www.inn-info.co.jp/the name of the hotel, address of the hotel, accessmethod to the hotel, and so on.
Transfer format in-formation describes how each item of hotel informa-tion is processed.In Figure 9, the landmarks, ?Tokyo Tower?
and?Tokyo Dome?
are substituted into an array variable?landmark?
which represents a landmark.From the description of this file, the constructionof a database and creation of the table for every cat-egory can be performed automatically.
And wordregistration to an analysis dictionary can be auto-matically performed using a morphological-analysisdictionary tool and a semantic dictionary registra-tion tool.
In this way, the hotel retrieval system wasconstructed in about 10 hours.The sample of a dialogue is shown in Figure 10.6 Other Task Adaptation6.1 Application to Mt.
Fuji SightseeingGuidance SystemWe applied the portable system to Mt.
Fuji sight-seeing guidance system as well as the hotel retrieval===== Speech Input =====Input :What hotels are there around Kanda Station?<=== input utterance:What hotels are there near in Kanda Station?<=== recognized sentence===== System Output =====5 facilities were found.===== Retrieval Result =====No.1 Olympic in Kanda, single room:11000yenNo.2 Grand Central Hotel,single room:8900yen,double room:12200yen, twin room:142000yenNo.3 Sun Hotel Kanda,single room:8400yen,twin room:13600yenNo.4 Central Hotel,single room:6500yen,double room:9800yen,twin room:9300yenNo.5 New Central Hotel,single room:7000yen,double room:7500yen,twin room:9600yen===== System Output =====The retrieval result is the above.===== Speech Input =====Input :Please display the data of No.2.<=== input utterance:Please display the data of No.2.<=== recognized sentence===== System Output =====The details of the data of No.2 are displayed.===== Retrieval Result =====*** Grand Central Hotel ***2-2 Kandatsukasa-machi Chiyoda TokyoOn foot-from JR line and subway line Kanda station 3 minutesLandmark:Room charge :: single:8900yen double:12200yen twin:14200yencheck in time is 15:00,check out time is 11:0011 stories,157 roomsNo smoking room is NothingInside-a-hotel equipment:conference room,vendingmachine,laundromat,restaurant,banquet hallindoor equipment:bath,toilet,air conditioning,lightingdesk,refrigerator,Japanese tea,drier,amenityset,television,video broadcast,satellite broadcasting,telephoneservice:Room service,copy,facsimile,word processor loan,ironloan,trouser press loan,parcel delivery servicereceptionist,cleaning receptionist,massage,mail servicUsable credit card:DC,VISA,JCB,Master,UC,AMEX,Million,Dainers,NICOSFigure 10: Dialogue example (hotel retrieval system).===== Speech Input =====Input :What is there in Kawaguchi Lake?
<=== input utterance-1===== System Output =====29 facilities were found.The reference conditions which can be used by addition are shown below.action : reading(9) lodging(7) appreciation(2) resting(2) camping(2)kind : hotel(4) museum(3) concert hall(2) pension(2) campsite(2)===== Speech Input =====Input :Campsite.
<=== input utterance-2===== System Output =====(Facility-kind campsite) <=== retrieval condition2 facilities were found.===== Retrieval Result =====Kitagishi no Myoukosan(campsite), Kawaguchi Lake, 0yenTozawa center(campsite), Kawaguchi Lake, 4000yen===== Speech Input =====The retrieval result is the above.Figure 11: Dialogue example (Mt.
Fuji sightseeing guidance system).===== System Output =====This is a document retrieval system.
Please input retrieval conditions.===== Speech Input =====input: Is there a paper on the multi modal?
<=== input utteranceYet uh uh.. is there a paper on the multi modal such?<=== recognized sentence===== System Output =====23 papers were found.Please input additional retrieval conditions.===== Speech Input =====input: This is related to Internet.
<=== input utteranceThis is related to Internet.
<=== recognized sentence===== System Output =====3 paper were found.===== Retrieval Result =====No.1 A. Nakashima, et al:"Intelligent network for personal movecommunication",Institute of Electronics, Information andCommunication Engineers Journal of Japan, 1995)No.2 K. Ono, et al:"Development of new generation communicationnetwork",Institute of Electronics, Information and CommunicationEngineers Journal of Japan, 1995)No.3 H. Aiso, et al:"Future prospects of information highway",Institute of Electronics, Information and Communication EngineersJournal of Japan, 1995)===== System Output =====The retrieval result is the above.Figure 12: Dialogue example (literature retrieval system).system.
An example of using the system is shown inFigure 11.The dialogue manager uses the dialogue script inorder to decide a dialogue strategy.
This scripts havethe functions that if retrieval results are too numer-ous, the system does not display all retrieval resultsbut inquires the user for additional retrieval condi-tions.
Of course, application developers can easilychange this dialogue strategy with the GUI tools.For example, since input utterance-2 inFigure 11 is not a sentence, the interpreter may failat the step of the semantic analysis.
The interpreteradapts Improved Keyword Retrieval described inSection 3.
The concept classification of campsiteis ?G-KIND?, so the interpreter directly changesthis word (see retrieval condition) to ?G-KIND.
?6.2 Application to Literature Retrieval SystemWe also applied the system to a literature retrievalsystem as well as the hotel retrieval system.Figure 12 shows an example of using the system.In this example the recognized sentence hasmisrecognition and interjections.
So the CFG gram-mar cannot accept this sentence.
Therefore, Re-moving Recognition Error by Lodging Errorin Section 3 is used for this sentence.
So yet,uh, uh and such are omitted in the recognizedutterance.If there are some related papers catalogues asretrieved results and the user inputs an utterance?Please display detailed information of the secondpaper.
?, the system displays detailed informationlike the abstract of the second paper in the paper cat-alogue.6.3 Evaluation of PortabilityWe evaluated the portability of our dialogue sys-tem and robustness of the interpreter through theMt.Fuji sightseeing system and literature retrievalsystem, and we confirmed that the developing periodwas shortened to the time of the hotel?s one, whichmeans a reduction to 10 hours from 15 hours in theprevious system (Kogure and Nakagawa, 2000).7 SummaryWe improved the portable semantic interpreter forspoken dialogue systems.
The highly portable se-mantic interpreter was constructed using the EDRelectronic dictionary.
By the example of the hotelretrieval system, we explained the structure of a highportable system.We also constructed the Mt.Fuji sightseeing sys-tem and literature retrieval system, and we con-firmed that the developing effort/period was reducedto the same as the hotel?s one, which means a re-duction to 10 hours from 15 hours in the previoussystem.In the near future, we will construct a system thatcan change a task during a dialogue.ReferencesA.
Abella and A. L. Gorin.
1999.
Construct algebra:Analytical dialog management.
In Proc.
of ACL ?99,pages 191?199.T.
Brondsted, B. Bai, and J. Olsen.
1998.
The rewardservice creation environment.
an overview.
In Proc.
ofICSLP ?98, pages 1175?1178.A.
Denda, T. Itoh, and S. Nakagawa.
1996.
A robustdialogue system with spontaneous speech and touchscreen.
In Proc.
of ICMI ?96, pages 144?151.T.
Itoh, M. Hidano, M. Yamamoto, and S. Nakagawa.1995.
Spontaneous speech understanding for a robustdialogue system.
In Proc.
of NLPRS ?95, volume 2,pages 538?543.A.
Kai and S. Nakagawa.
1995.
Investigation on un-known word processing and strategies for spontaneousspeech understanding.
In Proc.
of EUROSPEECH ?95,pages 2095?2098.S.
Kaspar and A. Hoffmannn.
1998.
Semi-automatedincremental prototyping of spoken dialog systems.
InProc.
of ICSLP ?98, pages 859?862.S.
Kogure and S. Nakagawa.
2000.
A portable devel-opment tool for spoken dialogue systems.
In Proc.
ofICSLP ?2000, pages 238?241.S.
Kogure, T. Itoh, and S. Nakagawa.
1999.
A seman-tic interpreter for a robust spoken dialogue system.
InProc.
ICMI ?99, pages II 61?66.R.
Kuhn and R. De Mori.
1995.
The application of se-mantic classification trees to natural language under-standing.
In IEEE Trans.
Pattern Analysis and Ma-chine Intelligence, volume 17, pages 449?460.E.
Levin, S. Narayanan, R. Pieraccini, K. Biatov, E. Bia-tov, E. Bocchieri, G. Di Fabbrizio, W. Eckert, S. Lee,A.
Pokrovsky, M. Rahim, P. Ruscitti, and M. Walker.2000.
The at&t-darpa communicator mixed-initiativespoken dialog system.
In Proc.
of ICSLP ?2000, vol-ume 2, pages 122?125.W.
Minker.
1998.
Stochastic versus rule-based speechunderstanding for information retrieval.
In SpeechCommunication, pages 223?147.R.
Moore and A. Podlozny.
1991.
A template matcherfor robust nl interpretation.
In Proc.
Speech andNatural Language Workshop, Morgan Kaufmann Inc.,pages 190?194.S.
Nakagawa, S. Kogure, and T. Itoh.
2000.
A semanticinterpreter and a cooperative response generator for arobust spoken dialogue system.
IJPRAI, 14(5):553?569.M.
Sasajima, T. Yano, and Y. Kono.
1999.
Europa:generic framework for developing spoken dialoguesystes.
In Proc.
of EUROSPEECH ?99, pages 1163?1166.S.
Sutton, R. Cole, J. de Villiers, J. Schalkwyk, P. Ver-meulen, M. Macon, Y.Yan, E. Kaiser, B. Rundle,K.
Shobaki, P. Hosom, A. Kain, J. Wouters, D. Mas-saro, and M. Cohen.
1998.
Universal speech tools:thecslu toolkit.
In Proc.
of ICSLP ?98, pages 3221?3224.Y.
Wang.
2001.
Robust language understanding in mi-pad.
In Proc.
of EUROSPEECH ?2001, pages 1555?1558.
