Proceedings of the NAACL HLT 2010 Young Investigators Workshop on Computational Approaches to Languages of the Americas,pages 46?53, Los Angeles, California, June 2010. c?2010 Association for Computational LinguisticsFostering Digital Inclusion and Accessibility:The PorSimples project for Simplification of Portuguese TextsSandra Maria Alu?sio and Caroline GasperinDepartment of Computer Sciences, University of S?o PauloAv.
Trabalhador S?o-Carlense, 400.
13560-970 - S?o Carlos/SP, Brazil{sandra,cgasperin}@icmc.usp.brAbstractIn this paper we present the PorSimplesproject, whose aim is to develop text adapta-tions tools for Brazilian Portuguese.
The toolsdeveloped cater for both people at poor litera-cy levels and authors that want to producetexts for this audience.
Here we describe thetools and resources developed over two yearsof this project and point directions for futurework and collaboration.
Since Portuguese andSpanish have many aspects in common, webelieve our main point for collaboration lies intransferring our knowledge and experience toresearches willing to developed simplificationand elaboration tools for Spanish.1 IntroductionIn Brazil, according to the index used to measurethe literacy level of the population (INAF - Na-tional Indicator of Functional Literacy) (INAF,2007), only 28% of the population is classified asliterate at the advanced level, while 65% of thepopulation face difficulties in activities involvingreading and comprehension depending on textlength and complexity; therefore, their access totextual media is limited.
The latter ones belong tothe so-called rudimentary and basic literacy levels.These people are only able to find explicit informa-tion in short texts (rudimentary level) and alsoprocess slightly longer texts and make simple infe-rences (basic level).The production of texts with different lengthsand complexities can be addressed by the task ofText Adaptation (TA), a very well known practicein educational settings.
Young (1999) and Burstein(2009) mention two different techniques for TA:Text Simplification and Text Elaboration.The first can be defined as any task that reducesthe lexical or syntactic complexity of a text, whiletrying to preserve meaning and information.
TextSimplification can be subdivided into SyntacticSimplification, Lexical Simplification, AutomaticSummarization, and other techniques.As to Text Elaboration, it aims at clarifying andexplaining information and making connectionsexplicit in a text, for example, providing short de-finitions or synonyms for words known to only afew speakers of a language.The PorSimples project1 (Simplification of Por-tuguese Text for Digital Inclusion and Accessibili-ty) (Aluisio et al 2008a) started in November 2007and will finish in April 2010.
It aims at developingtechnologies to make access to information easierfor low-literacy individuals, and possibly forpeople with other kinds of reading disabilities, bymeans of Automatic Summarization, Lexical Sim-plification, Syntactic Simplification, and Text Ela-boration.
More specifically, the goal is to helpthese readers to process documents available onthe web.
Additionally, it could help children learn-ing to read texts of different genres, adults beingalphabetized, hearing-impaired people who com-municate to each other using sign languages andpeople undertaking Distance Education, in whichtext intelligibility is of great importance.The focus is on texts published in governmentsites or by relevant news agencies, both of impor-1 http://caravelas.icmc.usp.br/wiki/index.php/Principal46tance to a large audience with various literacy le-vels.
The language of the texts is Brazilian Portu-guese, for which there are no text simplificationsystems to the best of our knowledge.In the project we have developed resources inPortuguese for research on text simplification, textsimplification technology for Portuguese, and cur-rently we are developing and adapting resourcesand technologies for text elaboration.
We have alsobuilt applications that make the developed technol-ogy available to the public.
In the Sections 2 to 4we describe all these outcomes of the project.We intend to foster a new interdisciplinary re-search area to study written text comprehensionproblems via the research on readability assess-ment, text simplification and elaboration once Por-Simples ends.
In Section 5 we describe futurework, and in Section 6 we outline potential pointsfor collaboration with researchers from Brazil andthe rest of the Americas.2 ResourcesIn order to understand the task of text simplifica-tion in Portuguese and to build training and evalua-tion data for the systems developed in the project,we have created a set of resources that formed thebasis of PorSimples.
Moreover, we are currentlyworking on building resources for text elaboration.Below we describe these resources.2.1 Manual for Syntactic Simplification in Por-tugueseWe have created a Manual for Syntactic Simplifi-cation for Portuguese (Specia et al, 2008).
Thismanual recommends how particular syntactic phe-nomena should be simplified.
It is based on a care-ful study of the Brazilian Portuguese grammar, ofsimplification systems developed for English (forexample, (Siddharthan, 2003)), and on the PlainLanguage initiative2 (Aluisio et al, 2008b).The manual was the basis for the developmentof our rule-based system for syntactic simplifica-tion described in Section 3.2.2.2 Corpora of Simple and Simplified TextsWe have built 9 corpora within 2 different genres(general news and popular science articles).
Our2 http://www.plainlanguage.gov/first corpus is composed of general news articlesfrom the Brazilian newspaper Zero Hora (ZH orig-inal).
We had these articles manually simplified bya linguist, specialized in text simplification, ac-cording to the two levels of simplification pro-posed in PorSimples, natural (ZH natural) andstrong (ZH strong).
The Zero Hora newspaper alsoprovides along its articles a simple version of themtargeting children from 7 to 11 years old; this sec-tion is called Para seu Filho Ler (ZH PFSL) andour corpus from this section contains simple ar-ticles corresponding to the articles in the ZH origi-nal corpus plus additional ones.Popular science articles compose our next set ofcorpora.
We compiled a corpus of these articlesfrom the Caderno Ci?ncia issue of the Braziliannewspaper Folha de S?o Paulo, a leading newspa-per in Brazil (CC original).
We also had this cor-pus manually simplified according to the natural(CC natural) and strong (CC strong) levels.
Wealso collected texts from a popular science maga-zine called Ci?ncia Hoje (CH) and from its versionaimed at children from 12-15, called Ci?ncia HojeCrianca (CHC).
Table 1 shows a few statisticsfrom these corpora.2.3 Dictionary of Simple WordsWhile for English some lexical resources that helpto identify difficult words using psycholinguisticmeasures are available, such as the MRC Psycho-linguistic Database3, no such resources exist forPortuguese.
In PorSimples, we have compiled adictionary of simple words composed by wordsthat are common to youngsters (from Biderman(2005)), a list of frequent words from news textsfor children and nationwide newspapers and a listof concrete words (from Janczura et.
al (2007)).Corpus Art.
Sent.Words Avg.
wordsper text (std.deviation)Avg.words p.sentenceZH original 104 2184 46190 444.1 (133.7) 21.1ZH natural 104 3234 47296 454.7 (134.2) 14.6ZH strong 104 3668 47938 460.9 (137.5) 13.0ZH PSFL 166 1224 22148 133.4 (48.6) 18.0CC original 50 882 20263 405.2 (175.6) 22.9CC natural 50 975 19603 392.0 (176.0) 20.1CC strong 50 1454 20518 410.3 (169.6) 14.1CH 130 3624 95866 737.4 (226.1) 26.4CHC 127 3282 65124 512.7 (185.3) 19.8Table 1.
Corpus statistics.3 http://www.psych.rl.ac.uk/47This dictionary is being used in applications de-scribed in Section 4, such as SIMPLIFICA and theSimplification Annotation Editor.3 Simplification & Elaboration technology3.1 Lexical SimplificationLexical simplification consists on replacing com-plex words by simpler words.The first step of lexical simplification consists oftokenizing the original text and selecting the wordsthat are considered complex.
In order to judge aword as complex or not, we use the dictionaries ofsimple words described in Section 2.3.The lexical simplification system also uses theUnitex-PB dictionary4 for finding the lemma of thewords in the text, so that it is possible to look for itin the simple words dictionaries.
The problem oflooking for a lemma directly in a dictionary is thatthere are ambiguous words and we are not able todeal with different word senses.
For dealing withpart-of-speech (POS) ambiguity, we use theMXPOST POS tagger5 trained over NILC tagset6.Among the words that were selected as com-plex, the ones that are not proper nouns, preposi-tions and numerals are processed: their POS tagsare used to look for their lemmas in the dictiona-ries.
As the tagger has not a 100% precision andsome words may not be in the dictionary, we lookfor the lemma only (without the tag) when we arenot able to find the lemma-tag combination in thedictionary.
Still, if we are not able to find the word,the lexical simplification module assumes that theword is complex and marks it for simplification.The last step of the process consists in providingsimpler synonyms for the complex words.
For thistask, we use the thesauri for Portuguese TeP 2.07and the lexical ontology for Portuguese PAPEL8.This task is carried out when the user clicks on amarked word, which triggers a search in the the-sauri for synonyms that are also present in thecommon words dictionary.
If simpler words arefound, they are sorted from the simpler to the morecomplex.
To determine this order, we used Google4 http://www.nilc.icmc.usp.br/nilc/projects/unitex-pb/web/dicionarios.html5 http://sites.google.com/site/adwaitratnaparkhi/home6 www.nilc.icmc.usp.br/nilc/TagSet/ManualEtiquetagem.htm7 http://www.nilc.icmc.usp.br/tep2/8 http://www.linguateca.pt/PAPEL/API to search each word in the web: we assumethat the higher a word frequency, the simpler it is.Automatic word sense disambiguation is left forfuture work.
In PorSimples, we aim to use TextualEntailment (Dagan et al, 2005) as a method forgathering resources for lexical simplification.3.2 Syntactic SimplificationSyntactic simplification is accomplished by a rule-based system, which comprises seven operationsthat are applied sentence-by-sentence to a text inorder to make its syntactic structure simpler.Our rule-based text simplification system isbased on the manual for Brazilian Portuguese syn-tactic simplification described in Section 2.1.
Ac-cording to this manual, simplification operationsshould be applied when any of the 22 linguisticphenomena covered by our system (see Candido etal.
(2009) for details) is detected.
Our system treatsappositive, relative, coordinate and subordinateclauses, which have already been addressed byprevious work on text simplification (Siddharthan,2003).
Additionally, we treat passive voice, sen-tences in an order other than Subject-Verb-Object(SVO), and long adverbial phrases.
The simplifica-tion operations to treat these phenomena are: splitsentence, change particular discourse markers bysimpler ones, change passive to active voice, invertthe order of clauses, convert to subject-verb-objectordering, and move long adverbial phrases.Each sentence is parsed in order to identify syn-tactic phenomena for simplification and to segmentthe sentence into portions that will be handled bythe operations.
We use the parser PALAVRAS(Bick, 2000) for Portuguese.
Gasperin et al (2010)present the evaluation of the performance of oursyntactic simplification system.Since our syntactic simplifications are conserva-tive, the simplified texts become longer than theoriginal due to sentence splitting.
We acknowledgethat low-literacy readers prefer short texts; this iswhy we use summarization before applying simpli-fication in FACILITA (see (Watanabe et al,2009)).
In the future we aim to provide summariza-tion also within SIMPLIFICA.
These two applica-tions are described in Section 4.3.3 Natural and Strong SimplificationTo attend the needs of people with different levelsof literacy, PorSimples propose two types of sim-48plification: natural and strong.
The first is aimed atpeople with a basic literacy level and the second,rudimentary level.
The difference between thesetwo is the degree of application of simplificationoperations to the sentences.
For strong simplifica-tion we apply the syntactic simplification processto all complex phenomena found in the sentence inorder to make the sentence as simple as possible,while for natural simplification the simplificationoperations are applied only when the resulting textremains ''natural'', considering the overall complex-ity of the sentence.
This naturalness is based on agroup of factors which are difficult to define usinghand-crafted rules, and we intend to learn themfrom examples of natural simplifications.We developed a corpus-based approach for se-lecting sentences that require simplification.
Basedon parallel corpora of original and natural simpli-fied texts (ZH original, ZH natural, CC original,CC natural), we apply a binary classifier to decidein which circumstances a sentence should be splitor not so that the resulting simplified text is naturaland not over simplified.
Sentence splitting is themost important and most frequent syntactic simpli-fication operation, and it can be seen as a key dis-tinctive feature between natural and strong simpli-fication.
We described this system in detail in(Gasperin et al, 2009).Our feature set contains 209 features, includingsuperficial, morphological, syntactic and dis-course-related features.
We did several feature se-lection experiments to determine the optimal set offeatures.
As classification algorithm we use We-ka's9 SMO implementation of Support Vector Ma-chines (SVM).
The ZH corpus contains 728 exam-ples of the splitting operation and 1328 examplesof non-split sentences, and the CC corpus contains59 positive and 510 negatives examples.
The clas-sifier?s average performance scores (optimal fea-ture set, both corpora as training data, and cross-validation) are 80.5% precision and 80.7% recall.3.4 Readability AssessmentWe developed a readability assessment system thatcan predict the complexity level of a text, whichcorresponds to the literacy level expected from thetarget reader: rudimentary, basic or advanced.We have adopted a machine-learning classifier9 http://www.cs.waikato.ac.nz/ml/weka/to identify the level of the input text; we use theSupport Vector Machines implementation fromWeka toolkit (SMO).
We have used 7 of our cor-pora presented in Section 2.2 (all but the ones withtexts written for children) to train the classifier.Our feature set is composed by cognitively-motivated features derived from the Coh-Metrix-PORT tool10, which is an adaptation for BrazilianPortuguese of Coh-Metrix 2.0 (free version ofCoh-Metrix (Graesser et al 2004)) also developedin the context of the PorSimples project.
Coh-Metrix-PORT implements the metrics in Table 2.We also included seven new metrics to Coh-Metrix-PORT: average verb, noun, adjective andadverb ambiguity, incidence of high-level constitu-ents, content words and functional words.Categories Subcategories MetricsShallowReadabili-ty metric- Flesch Reading Ease indexfor Portuguese.Words andtextualinforma-tionBasic counts Number of words, sen-tences, paragraphs, wordsper sentence, sentences perparagraph, syllables perword, incidence of verbs,nouns, adjectives and ad-verbs.Frequencies Raw frequencies of contentwords and minimum fre-quency of content words.Hyperonymy Average number of hyper-nyms of verbs.Syntacticinforma-tionConstituents Incidence of nominalphrases, modifiers pernoun phrase and wordspreceding main verbs.Pronouns,Types andTokensIncidence of personal pro-nouns, number of pronounsper noun phrase, types andtokens.Connectives Number of connectives,number of positive andnegative additive connec-tives, causal / temporal /logical positive and nega-tive connectives.Logicaloperators- Incidence of the particles?e?
(and), ?ou?
(or), ?se?
(if), incidence of negationand logical operators.Table 2.
Metrics of Coh-Metrix-PORT.We measured the performance of the classifieron identifying the levels of the input texts by a10 http://caravelas.icmc.usp.br:3000/49cross-validation experiment.
We trained the clas-sifier on our 7 corpora and reached 90% F-measureon identifying texts at advanced level, 48% at basiclevel, and 73% at rudimentary level.3.5 Semantic Role Labeling: UnderstandingSense Relations between Verb and ArgumentsTo attend the goal of eliciting sense relations be-tween verbs and their arguments through the exhi-bition of question words such as who, what, which,when, where, why, how, how much, how many,how long, how often and what for, we are specify-ing a new annotation task that assigns these wh-question labels to verbal arguments in a corpus ofsimplified texts in Portuguese.
The aim is to pro-vide a training corpus for machine learning, aimingat automatic assignment of wh-questions (Duran etal., 2010a; Duran et al, 2010b).The annotation task involves recognizing seg-ments that constitute answers to questions made tothe verbs.
Each segment should suitably answer thewh-question label.
For example, in the sentence?Jo?o acordou ?s 6 horas da manh?.?
(John wokeup at 6 in the morning.
), two questions come upnaturally in relation to the verb ?acordar?
(wakeup): 1) Who woke up?
and 2) When?.Linking the verb and its arguments through wh-questions is a process that requires text understand-ing.
This is a skill that the target audience of thisproject is weak at.
In Figure 1 we show the linkbetween the verb and its arguments (which can besubject, direct object, indirect object, time or loca-tion adverbial phrases, and also named entities).Who woke up?John   woke up   at 6 in the morningWhen?
__ _________Figure 1.
Assigning wh-question labels to arguments.The corpus chosen for this work consists of thestrong simplified version of 154 texts extractedfrom general news and popular science articles(ZH strong and CC strong) which were describedin Section 2.2.Results of such a semantic layer of annotationmay be used, in addition, to identify adjunct se-mantic roles and multi-word expressions with spe-cific adverbial syntactic roles.
This training corpus,as well as the automatic labeling tool, an ?answer-questioning?
system, will be made publicly availa-ble at PorSimples site.
Besides helping poor-literacy readers, the assignment of wh-questionswill be used in the near future to map adjunct se-mantic roles (ArgMs of Propbank (Palmer et al,2005)) in a project to build the PropBank.Br forPortuguese language.
One may also take profit ofthis automatic tool and its training corpus to im-prove its opposite, question-answering systems.4 ApplicationsThe text simplification and elaboration technolo-gies developed in the context of the project areavailable by means of three systems aimed to dis-tinct users:An authoring system, called SIMPLIFICA11, tohelp authors to produce simplified texts target-ing people with low literacy levels,An assistive technology system, called FACI-LITA12, which explores the tasks of summari-zation and simplification to allow poor literatepeople to read Web content, andA web content adaptation tool, named Educa-tional FACILITA, for assisting low-literacyreaders to perform detailed reading.
It exhibitsquestions that clarify the semantic relationslinking verbs to their arguments, highlightingthe associations amongst the main ideas of thetexts, named entities, and perform lexical ela-boration.In the following subsections we detail these andother systems developed in the project.4.1 SIMPLIFICA Authoring ToolSIMLIFICA is a web-based WYSIWYG editor,based on TinyMCE web editor13.
The user inputs atext in the editor and customizes the simplificationsettings, where he/she can choose: (i) strong sim-plification, where all the complex syntactic phe-nomena (see details in Section 3.2) are treated foreach sentence, or customized simplification, wherethe user chooses one or more syntactic simplifica-tion phenomena to be treated for each sentence,and (ii) one or more thesauri to be used in the syn-tactic and lexical simplification processes.
Then11 http://www.nilc.icmc.usp.br/porsimples/simplifica/12 http://vinho.intermidia.icmc.usp.br:3001/facilita/13 http://tinymce.moxiecode.com/50the user activates the readability assessment mod-ule to predict the complexity level of a text.
Thismodule maps the text to one of the three levels ofliteracy defined by INAF: rudimentary, basic oradvanced.
According to the resulting readabilitylevel the user can trigger the lexical and/or syntac-tic simplifications modules, revise the automaticsimplification and restart the cycle by checking thereadability level of the current version of the text.4.2 FACILITAFACILITA is a browser plug-in that aims to facili-tate the reading of online content by poor literatepeople.
It includes separate modules for text sum-marization and text simplification.
The user canselect a text on any website and call FACILITA tosummarize and simplify this text.
The system isdescribed in details in Watanabe et al (2009).The text summarization module aims to extractonly the most important information from a text.
Itrelies on the EPC-P technique (extraction of key-words per pattern), which checks the presence ofkeywords in the sentences: sentences that containkeywords are retained for the final summary.
Thesummarization system is reported in Margarido etal.
(2008).The text simplification module follows the syn-tactic simplification framework described in Sec-tion 3.2.
We have chosen to run the summarizationprocess first and then proceed to the simplificationof the summarized text since simplification in-creases text length.4.3 Educational FACILITAEducational FACILITA14 is a Web applicationaimed at assisting users in understanding textualcontent available on the Web.
Currently, it ex-plores the NLP tasks of lexical elaboration andnamed entity labeling to assist poor literacy readershaving access to web content.
It is described inWatanabe et al (2010).Lexical Elaboration consists of mechanisms thatpresent users with synonymous or short definitionsfor words, which are classified as unusual or diffi-cult to be understood by the users.
This processrelies on the framework developed for lexical sim-plification described in Section 3.1.14 http://vinho.intermidia.icmc.usp.br/watinha/Educational-Facilita/Named-entity labeling consists of displaying ad-ditional and complementary semantic and descrip-tive information about named entities that are con-tained on the Web sites text.
The descriptions areextracted from Wikipedia.It is expected that these additional informationpresented in the text by the proposed approachwould help users better understand websites?
tex-tual content and allow users to learn the meaningof new or unusual words/expressions.4.4 Simplification Annotation EditorThis editor15 was created to support the manualsimplification of texts for the creation of our cor-pus of simplified texts.
It records and labels all theoperations made by the annotator and encode textsusing a new XCES16-based schema for linking theoriginal-simplified information.
XCES has beenused in projects involving both only one language,e.g.
American National Corpus (ANC)17 (English)and PLN-BR18 (Brazilian Portuguese); and mul-tiple languages as parallel data, e.g.
: CroCo19 (Eng-lish-German).
However, to our knowledge, Por-Simples is the first project to use XCES to encodeoriginal-simplified parallel texts and also the sim-plification operations.
Two annotation layers havebeen added to the traditional stand-off annotationlayers in order to store the information related tosimplification (Caseli et al, 2009).4.5 Portal of Parallel CorporaThe portal20 allows for online querying anddownload of our corpora of simplified texts.
Thequeries can include information about syntacticconstructions, simplification operations, etc.5 Future WorkOur main area for future work lies on the evalua-tion of the simplified texts resulting from our sys-tems with the end user, that is, people at low litera-cy levels.
We are carrying out a large-scale studywith readers who fit in the rudimentary and basicliteracy levels to verify whether syntactic and lexi-15 http://caravelas.icmc.usp.br/anotador16 http://www.w3.org/XML/17 http://americannationalcorpus.org18 http://www.nilc.icmc.usp.br/plnbr19 http://fr46.uni-saarland.de/croco/index_en.html20 http://caravelas.icmc.usp.br/portal/index.php51cal simplification indeed contribute to the under-standing of Portuguese texts.
We are applyingreading comprehension tests with original texts(control group) and manually simplified texts atstrong level.
However we still need to assess theimpact of automatic lexical and syntactic simplifi-cation and text elaboration on the understanding ofa text by the target user of our applications.We also intend to investigate how to balancesimplification/elaboration and text length.
We haveshown that in our syntactic simplification approachit is usual to divide long sentences, which reducesentence length but increase text length due to therepetition of the subject in the new sentences.
Onthe other hand, in summarization-based Text Sim-plification, such as FACILITA?s approach, textlength is reduced, but relevant information can belost, which may hinder text comprehensibility.Text Elaboration enhances text comprehensibility,but it always increases text length, since it insertsinformation and repetition to reinforce understand-ing and make explicit the connections between theparts of a text.
Therefore, since we cannot achieveall the requisites at once there is a need to evaluateeach aspect of our systems with the target users.We also intend to improve the performance ofour syntactic simplification approach by experi-menting with different Portuguese syntactic pars-ers.
Moreover, several methods of text elaborationare still under development and will be imple-mented and evaluated in this current year.As future research, we aim to explore the impactof simplification on text entailment recognitionsystems.
We believe simplification can facilitatethe alignment of entailment pairs.
In the oppositedirection, text entailment or paraphrase identifica-tion may help us find word pairs for enriching thelexical resources used for lexical simplification.6 Opportunities for CollaborationEnhancing the accessibility of Portuguese andSpanish Web texts is of foremost importance toimprove insertion of Latin America (LA) into theinformation society and to preserve the diversecultures in LA.
We believe several countries in LApresent similar statistics to Brazil in relation to thenumber of people at low literacy levels.
We see ourexperience in developing text simplification andelaboration tools for Portuguese as the major con-tribution that we can offer to other research groupsin LA.
We are interested in actively taking part injoint research projects that aim to create text sim-plification and elaboration tools for Spanish.Since all resources that we have developed arelanguage-dependent, they cannot be used directlyfor Spanish, but we foresee that due to similaritiesbetween Portuguese and Spanish a straightforwardadaptation of solutions at the lexical and syntactic-al levels can be achieved with reasonable effort.We are willing to share the lessons learned duringthe PorSimples project and offer our expertise onselecting and creating the appropriate resources(e.g.
corpora, dictionaries) and technology for textsimplification and elaboration in order to createsimilar ones for Spanish.The advances in text simplification and elabora-tion methods strongly depend on the availability ofannotated corpora for several tasks: text simplifica-tion, text entailment, semantic role labeling, toname only a few.
English has the major number ofdata resources in Natural Language Processing(NLP); Portuguese and Spanish are low-densitylanguages.
To solve this problem, we believe thatthere is a need for: (i) the development of a newarea recently coined as Annotation Science; (ii) acentralized resource center to create, collect anddistribute linguistic resources in LA.We would appreciate collaboration with re-searchers in the USA in relation to readability as-sessment measures, such as those of Coh-Metrix(see Section 3.4), whose researchers already devel-oped up to 500 measures.
Only 60 of them areopen to public access.
Besides, the know-howneeded to develop a proposition bank of Portu-guese would be welcome since this involves lexi-cal resources, such as a Verbnet21, which do notexist for Portuguese.
Other lexical resources suchas the MRC Psycholinguistic Database, which helpto identify difficult words using psycholinguisticmeasures, are also urgent for Portuguese since wehave sparse projects dealing with several aspects ofthis database but no common project to unite them.Brazilian research funding agencies, mainlyCAPES22, CNPq23 and FAPESP24, often releasecalls for projects with international collaboration;these could be a path to start the collaborative re-search suggested above.21 http://verbs.colorado.edu/~mpalmer/projects/verbnet.html22 http://www.capes.gov.br/23 http://www.cnpq.br/24 http://www.fapesp.br/52AcknowledgmentsWe thank FAPESP and Microsoft Research forsupporting the PorSimples project.ReferencesSandra Alu?sio, Lucia Specia, Thiago Pardo, Erick Ma-ziero and Renata Fortes.
2008a.
Towards BrazilianPortuguese Automatic Text Simplification Systems.In: Proceedings of The Eight ACM Symposium onDocument Engineering (DocEng 2008), 240-248,S?o Paulo, Brazil.Sandra Alu?sio, Lucia Specia, Thiago Pardo, Erick Ma-ziero, Helena de M. Caseli, Renata Fortes.
2008b.
ACorpus Analysis of Simple Account Texts and theProposal of Simplification Strategies: First Steps to-wards Text Simplification Systems In: Proceedingsof The 26th ACM Symposium on Design of Commu-nication (SIGDOC 2008), pp.
15-22.Eckhard Bick.
2000.
The Parsing System "Palavras":Automatic Grammatical Analysis of Portuguese in aConstraint Grammar Framework.
PhD Thesis.
Aar-hus University.Maria Teresa Biderman.
2005.
DICION?RIO ILU-STRADO DE PORTUGU?S.
S?o Paulo, Editora?tica.
1?.
ed.
S?o Paulo: ?tica.
(2005)Jill Burstein.
2009.
Opportunities for Natural LanguageProcessing Research in Education.
In the Proceedingsof CICLing, 6-27.Arnaldo Candido Junior, Erick Maziero, Caroline Gas-perin, Thiago Pardo, Lucia Specia and Sandra M.Aluisio.
2009.
Supporting the Adaptation of Textsfor Poor Literacy Readers: a Text Simplification Edi-tor for Brazilian Portuguese.
In the Proceedings ofthe NAACL HLT Workshop on Innovative Use ofNLP for Building Educational Applications, pages34?42, Boulder, Colorado, June 2009.Helena Caseli, Tiago Pereira, Lucia Specia, Thiago Par-do, Caroline Gasperin and  Sandra Alu?sio.
2009.Building a Brazilian Portuguese parallel corpus oforiginal and simplified texts.
In Alexander Gelbukh(ed), Advances in Computational Linguistics, Re-search in Computer Science, vol 41, pp.
59-70.
10thConference on Intelligent Text Processing and Com-putational Linguistics (CICLing-2009).Ido Dagan, Oren Glickman and Bernado Magnini.
2005.The PASCAL Recognising Textual Entailment Chal-lenge.
In: Proceedings of The First PASCAL Recog-nising Textual Entailment Challenge (RTE 1), [S.l.
]:Springer, 2005. p. 1?8.Magali Duran, Marcelo Am?ncio and Sandra Alu?sio.2010a.
Assigning wh-questions to verbal argumentsin a corpus of simplified texts.
Accepted for publica-tion at Propor 2010 (http://www.inf.pucrs.br/~propor2010).Magali Duran, Marcelo Am?ncio and Sandra Alu?sio.2010b.
Assigning Wh-Questions to Verbal Argu-ments: Annotation Tools Evaluation and CorpusBuilding.
Accepted for publication in LREC 2010.Caroline Gasperin, Lucia Specia, Tiago Pereira andSandra Alu?sio.
2009.
Learning When to SimplifySentences for Natural Text Simplification.
In: Pro-ceedings of ENIA 2009, 809-818.Caroline Gasperin, Erick Masiero and Sandra M. Alui-sio.
2010.
Challenging choices for text simplifica-tion.
Accepted for publication at Propor 2010(http://www.inf.pucrs.br/~propor2010).Arthur Graesser, Danielle McNamara, Max  Louwerseand Zhiqiang Cai.
2004.
Coh-Metrix: Analysis oftext on cohesion and language.
In: Behavioral Re-search Methods, Instruments, and Computers, 36,p?ginas 193-202.INAF.
2007.
Indicador de Alfabetismo Funcional IN-AF/Brasil - 2007.
Available at http://www.acaoeducativa.org.br/portal/images/stories/pdfs/inaf2007.pdfGerson A Janczura, Goiara M Castilho, Nelson O Ro-cha, Terezinha de Jesus C. van Erven and Tin PoHuang.
2007.
Normas de concretude para 909 pala-vras da l?ngua portuguesa.
Psicologia: Teoria e Pes-quisa Abr-Jun 2007, Vol.
23 n. 2, pp.
195-204.Martha Palmer, Daniel Gildea and Paul Kingsbury.2005.
The Proposition Bank: A Corpus Annotatedwith Semantic Roles, Computational LinguisticsJournal, 31:1.Advaith Siddharthan.
2003.
Syntactic Simplificationand Text Cohesion.
PhD Thesis.
University ofCambridge.Lucia Specia, Sandra Aluisio and Tiago Pardo.
2008.Manual de Simplifica?
?o Sint?tica para o Portugu?s.Technical Report NILC-TR-08-06, 27 p. Junho 2008,S?o Carlos-SP.Willian Watanabe, Arnaldo Candido Junior, Vin?ciusUz?da, Renata Fortes, Tiago Pardo and SandraAlu?sio.
2009.
Facilita: reading assistance for low-literacy readers.
In: Proceedings of the 27th ACM In-ternational Conference on Design of Communica-tion.
SIGDOC '09.
ACM, New York, NY, 29-36.Willian Watanabe, Arnaldo Candido Junior, MarceloAmancio, Matheus de Oliveira, Renata Fortes, TiagoPardo, Renata Fortes, Sandra Alu?sio.
2010.
Adapt-ing web content for low-literacy readers by using lex-ical elaboration and named entities labeling.
Ac-cepted for publication at W4A 2010(http://www.w4a.info/).Dolly J.
Young.
Linguistic simplification of SL readingmaterial: effective instructional practice.
The ModernLanguage Journal, 83(3):350?366, 1999.53
