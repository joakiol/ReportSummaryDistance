Proceedings of the 53rd Annual Meeting of the Association for Computational Linguisticsand the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 309?313,Beijing, China, July 26-31, 2015.c?2015 Association for Computational LinguisticsRecovering dropped pronouns from Chinese text messagesYaqin YangPaypal Inc.yaqin276@gmail.comYalin LiuBrandeis Universityyalin@brandeis.eduNianwen XuBrandeis Universityxuen@brandeis.eduAbstractPronouns are frequently dropped in Chi-nese sentences, especially in informal datasuch as text messages.
In this work wepropose a solution to recover dropped pro-nouns in SMS data.
We manually annotatedropped pronouns in 684 SMS files andapply machine learning algorithms to re-cover them, leveraging lexical, contextualand syntactic information as features.
Webelieve this is the first work on recover-ing dropped pronouns in Chinese text mes-sages.1 IntroductionText messages generated by users via SMS or Chathave distinct linguistic characteristics that poseunique challenges for existing natural languageprocessing techniques.
Since such text messagesare often generated via mobile devices in infor-mal settings and are limited in length, abbrevia-tions and omissions are commonplace.
In this pa-per, we report work on detecting one particulartype of omission in Chinese text messages, namelydropped pronouns.It is well-known that Chinese is a pro-drop lan-guage, meaning pronouns can be dropped froma sentence without causing the sentence to be-come ungrammatical or incomprehensible whenthe identity of the pronoun can be inferred fromthe context.
Pronouns can be dropped even informal text genres like newswire, but the extentto which this happens and the types of pronounsthat are dropped in text messages and formal gen-res like newswire are very different.
For exam-ple, the most frequently dropped pronouns in Chi-nese newswire is the third person singular?(?it?
)(Baran et al 2012 ), and one reason is that firstand second person pronouns are rarely used innewswire in the first place.
In contrast, in textmessages, the first person singular ?
and thesecond person singular ?
are commonly foundin text messages due to their conversational style,and they are often dropped as well when their ref-erent is understood in the context.
This is illus-trated in (1), where there are instances of droppedfirst person singular, second person singular andthird person singular pronouns.
There is also aninstance where the dropped pronoun in Chinesedoes not have any actual referent, translating to theEnglish pleonastic ?it?.
Dropped pronouns are inparentheses:(1) A ??your?area??snow?ASP,,?you??how?go?
?work?It snowed in your area.
How do you goto work?
?B (?)(I)??walk?or?
?take the bus?
(I) walk or take the bus.
?A (pleonastic)(it)?
?look like???transportation????relatively??developed?.?
(It) looks like you have a relatively de-veloped transportation system.
?B (pleonastic)(it)??snow(?)(I)?then?not?can?
?go to work?ASP?When (it) snows, (I) cannot go to work.
?B (?)(it)???OK?
(It) is OK.?Detecting dropped pronouns involves first of alldetermining where in the sentence pronouns are309dropped and then determining what the droppedpronoun is, i.e., whether the dropped pronounshould be ?, ?, ?, etc.
The dropped pronouncould either correspond to one of possible pro-nouns in Chinese, or it can be an abstract pronounthat does not correspond to any of the Chinesepronouns.
For example, Chinese does not havea pronoun that is the equivalent of the pleonastic?it?
in English, but there are sentences in which adropped pronoun occurs in a context that is sim-ilar to where ?it?
occurs.
In this case we labelthe dropped pronoun as a type of abstract pronoun.Note that we do not attempt to resolve these pro-nouns to an antecedent in this work.
We thinkthere is value in just detecting these pronouns.
Forexample, if we translate Chinese sentences withdropped pronouns into English, they may have tobe made explicit.We approach this as a supervised learning prob-lem, so first we need a corpus annotated with thelocation and type of dropped pronouns to trainmachine learning models.
We annotated 292,455words of Chinese SMS/Chat data with droppedpronouns and we describe our annotation in moredetail in Section 2.
We then present our machinelearning approach in Section 3.
Experimental re-sults are presented in Section 4, and related workis described in Section 5.
Finally we conclude inSection 6.2 Dropped pronoun annotationWe annotated 684 Chinese SMS/Chat files follow-ing the dropped pronoun annotation guidelines de-scribed in (Baran et al 2012 ).
The original guide-lines are mainly designed for annotating droppedpronouns in newswire text, and we had to extendthe guidelines to accommodate SMS/Chat data.For example, (Baran et al 2012 ) identify 14 typesof pronouns, which include four abstract pronounswhich do not correspond to any actual pronounsin Chinese.
To accommodate SMS/Chat data, weadd one more type of abstract pronoun that refersto the previous utterance.
The full list of pronounsthat we use are listed below:1.
?
(I): first person singular2.
??
(we): first person plural3.
?
(you): second person singular4.
??
(you): second person plural5.
?
(he): third person masculine singular6.
??
(they): third person masculine plural7.
?
(she): third person feminine singular8.
??
(they): third person feminine plural9.
?
(it): third person inanimate singular10.
??
(they): third person inanimate plural11.
Event: abstract pronoun that refers to anevent12.
Existential: abstract pronoun that refers toexistential subject13.
Pleonastic: abstract pronoun that refers topleonastic subject14.
generic: abstract pronoun thatrefers to something generic or unspecific15.
Previous Utterance: abstract pronoun thatrefers to previous utterance16.
Other: cases where it is unclear what the cor-rect pronoun should be3 LearningWe have formulated dropped pronoun recovery asa sequential tagging problem, following (Yang andXue.
2010 ).
We check each word token in asentence and decide if there is a pronoun droppedbefore this word.
If there is one, then we furtheridentify what type of pronoun it should be.
Insteadof doing this in two separate steps, we trained a 17-class Maximum Entropy classifier with the Mallet(McCallum et al 2002) machine learning pack-age to tag each word token with one of the pro-nouns or None in one run.
None indicates thatthere is no dropped pronoun before this word.We leveraged a set of lexical features from pre-vious work (Yang and Xue.
2010 ).
To our knowl-edge, the work we report here represents the firsteffort on dropped pronoun recovery on ChineseSMS/Chat data.
As described in Section 2, SMSdata is different from newswire data which is com-monly used in previous work (Converse.
2006;Zhao and Ng.
2007; Peng and Araki.
2007; Kongand Zhou.
2010; Chung and Gildea 2010; Cai etal.
2011; Xiang et al 2013) in many aspects.The frequency of pronoun being dropped is muchhigher in SMS/Chat data compared to newswiredata.
The distribution of dropped pronoun typesin SMS data is also very different from that ofnewswire data.
In SMS/Chat data, the identitiesof the participants who send the messages are crit-ical in identifying the dropped pronoun type, whilethere is no participant information in newswiredata.
Thus, we also design a new set of contextbased features to capture the stylistic properties oftext messages.310Lexical Features: Information embedded inthe target and surrounding words provide clues foridentifying dropped pronouns, e.g.,(2) (?)(it)?broken?ASP..?
(It) is broken.
?In (2), a pronoun is dropped at the beginning ofthe sentence.
The follwing words ????
means?is broken?, and it indicates that the subject refersto a thing, not a person.
Part-of-speech tags arealso crucial in finding the location of a droppedpronoun.
Just like pronouns are usually locatedbefore verbs, it is more likely to have a pronoundropped before an verb than a noun.
We imple-mented a set of lexical features along with part-of-speech tags within a sliding window of five wordsto capture such information.
The contextual fea-tures are listed below:?
unigrams within current window;?
previous and following (including currentword) bigrams;?
POS tags of unigrams within current window;?
POS tags of the previous and following (in-cluding current word) bigrams;?
POS tags of the following (including currentword) trigram;?
combination previous word and POS tag ofcurrent word;?
combination of POS tag of previous word andcurrent word;?
POS tag sequence from the previous word tothe beginning of a sentence or a punctuationmark.Context-based Features: It is hard to recoverdropped pronouns without understanding the con-text.
In SMS data, one sometimes needs to traceback a few sentences to figure out what a droppedpronoun refers to.
(3) a.
?I?want?buy?CL?
?SLR camera..?I want to buy a SLR camera.?b.
(?)(I)??
?Independent Day?
?go out?travel?..?
(I) will travel on Independent Day.
?In (3), the two sentences are attributed to thesame person, and a pronoun is dropped at the be-ginning of the second sentence.
While we couldeasily understand the dropped pronoun refers to??(I)?
from the previous sentence, it is difficultto make this determination by just looking at thesecond sentence independently.
Thus, we proposea list of novel context-based features tailored to-wards SMS/Chat data to capture such information:?
previous pronoun used by the same partici-pant;?
previous pronoun used by the other partici-pant;?
all previous pronouns till the beginning of asentence or a punctuation mark used;?
next punctuation mark;?
if it is a question;?
if the POS tag of the last word is SP;?
for the first word in a sentence, use first twonouns/pronouns from the previous sentence.Syntactic Features: Syntactic features havebeen shown to be useful in previous work (?).
Wealso implemented the following syntactic features:?
if it is the left frontier of the lowest IP an-tecedent;?
if current word is ??
?, then find it?s subject;?
path from current word to the root node.4 Experiments and discussion4.1 Data splitTable 1 presents the data split used in our experi-ments.data set # of words # of filesTrain 235,184 487Dev 24,769 98Test 32,502 99Table 1: Training, development and test data onSMS data set.4.2 ResultsAs mentioned in Section 3, we extract lexical,context and syntactic features from SMS data andtrain a 17-class classifier to automatically recoverdropped pronouns.
To obtain syntactic features,we divided 684 SMS files into 10 portions, andparsed each portion with a model trained on otherportions, using the Berkeley parser (Petrov andKlein 2007).
The parsing accuracy stands at82.11% (F-score), with a precision of 82.57% anda recall of 81.65%.
The results of our experimentsare presented in Table 2.311tag pre.
(%) rec.
(%) f. countNE 99.1 95.7 97.3 28963?
48 53.1 50.4 1155?
34.4 48.1 40.1 787?
12.1 54.6 19.8 488prev utterance 87.6 65.3 74.8 314pleonastic 7 10.2 8.3 172?
4.3 27.8 7.4 117?
11 22.2 14.7 109??
24 41 30.3 104generic 6.6 17.1 9.5 91??
2.7 11.1 4.4 73event 4.3 25 7.3 47??
4.7 100 8.9 43other 0 0 0 16??
0 0 0 13existential 12.5 2 3.4 8??
0 0 0 2Table 2: precision, recall and f-score for differ-ent dropped pronoun categories on test set.
Thecombination of ??
(I)?, ??
(singular you)?
and?utterance?
accounts for 63.7% of the overalldropped pronoun population.
The overall accu-racy is 92.1%.
?NE?
stands for None, meaningthere is no dropped pronoun.4.3 Error AnalysisFrom Table 3, which is a confusion matrix gen-erated from results on the test set, showing theclassification errors among different types, we cansee that the classifier did a better job of recover-ing ??
(I)?, ??
(singular you)?
and ?previous ut-terance?, the combination of which accounts for63.7% of the total dropped pronoun instances.However, it is hard for the classifier to recover??
(it)?, e.g.,?*pro*???
(*pro* that kind?
)?SMS sentences are usually short.
To understandwhat the dropped pronoun stands for, one needs tolook at its previous context.
But it is hard for ma-chine to capture such long distance information.5 Related WorkOne line of work that is closely related to ours iszero pronoun resolution.
In zero pronoun reso-lution (Converse.
2006; Zhao and Ng.
2007;Peng and Araki.
2007; Kong and Zhou.
2010),pronouns are typically resolved in three steps:zero pronoun detection, anaphoricity determina-tion, and antecedent resolution.
In the work weNE ?
?
?
ut pl ?
?
??
ge ??
ev ??
ot ??
ex ?
?NE 28695 130 77 9 8 7 2 10 9 8 1 .
.
.
1 6 .?
433 554 101 11 5 13 2 5 10 4 1 1 .
.
1 14 .?
327 135 271 6 3 16 1 6 6 9 1 1 .
.
.
5 .?
199 85 49 59 23 42 1 10 1 3 5 1 .
.
1 9 .utterance 23 7 1 4 275 4 .
.
.
.
.
.
.
.
.
.
.pleonastic 36 17 5 5 88 12 1 1 1 .
1 .
.
.
.
5 .?
47 21 21 5 1 6 5 5 1 .
3 1 .
.
.
1 .?
46 23 10 2 6 5 1 12 .
1 .
.
.
.
.
3 .??
47 17 5 2 .
.
2 2 25 .
1 1 .
.
.
2 .generic 52 20 5 .
.
.
.
2 2 6 .
.
.
.
.
4 .??
38 15 7 2 .
3 2 .
1 2 2 1 .
.
.
.
.event 16 4 3 2 11 6 1 1 .
.
1 2 .
.
.
.
.??
14 11 4 .
1 3 .
.
3 2 2 .
2 .
.
1 .other 15 .
.
.
.
1 .
.
.
.
.
.
.
.
.
.
.??
6 2 4 1 .
.
.
.
.
.
.
.
.
.
.
.
.existential 4 2 .
.
.
.
.
.
1 .
.
.
.
.
.
1 .??
1 .
.
.
.
.
.
.
1 .
.
.
.
.
.
.
.Table 3: Confusion matrix for each annotation cat-egory.
Columns correspond to Maxent predictedvalues and rows refer to annotated values.report here, we are more interested in detectingdropped pronouns and determining what types ofpronoun they are.Dropped pronoun detection is also related toEmpty Category (EC) detection and resolution(Chung and Gildea 2010; Cai et al 2011; Xi-ang et al 2013), the aim of which is to recoverlong-distance dependencies, discontinuous con-stituents, and certain dropped elements in phrasestructure treebanks (Marcus et al 1993; Xue etal.
2005).
In previous work on EC detection(Chung and Gildea 2010; Cai et al 2011; Xianget al 2013), ECs are recovered from newswiredata by leveraging lexical and syntactic informa-tion from each sentence.
Context information be-yond the current sentence is typically not used.When recovering dropped pronouns in SMS/Chatmessages, it is crucially important to make use ofinformation beyond the current sentence.6 Conclusion and Future WorkIn this paper we report work on recoveringdropped pronouns in Chinese SMS/Chat mes-sages.
Based on the properties of SMS data, wedesigned a set of lexical, contextual and syntac-tic features, and trained a Maxent classifier torecover dropped pronouns in Chinese SMS/Chatmessages.
We believe this is the first work on re-covering dropped pronouns in Chinese text mes-sages.
This proves to be a very challenging task,and much remains to be done.
In future work, weplan to experiment with applying more expressivemachine learning techniques to this task.312AcknowledgmentsWe want to thank the anonymous reviewers fortheir suggestions.
This work was partially sup-ported by the National Science Foundation viaGrant No.0910532 entitled ?Richer Representa-tions for Machine Translation?.
All views ex-pressed in this paper are those of the authors anddo not necessarily represent the view of the Na-tional Science Foundation.ReferencesZhao, Shanheng and Ng, Hwee Tou 2007 Identifi-cation and Resolution of Chinese Zero Pronouns:A Machine Learning Approach..
Proceedings ofthe 2007 Joint Conference on Empirical Methodsin Natural Language Processing and ComputationalNatural Language Learning (EMNLP-CoNLL).Kong, Fang and Zhou, Guodong 2010 A tree kernel-based unified framework for Chinese zero anaphoraresolution..
Proceedings of the 2010 Conference onEmpirical Methods in Natural Language Processing.Fang Kong and Hwee Tou Ng 2013 Exploiting ZeroPronouns to Improve Chinese Coreference Resolu-tion..
Proceedings of the 2013 Conference on Em-pirical Methods in Natural Language Processing.Shu Cai, David Chiang, and Yoav Goldberg.
2011Language-independent parsing with empty ele-ments..
In Proceedings of the 49th Annual Meetingof the Association for Computational Linguistics:Human Language Technologies, pages 212?216,Portland, Oregon, USA, June.
Association for Com-putational Linguistics.Tagyoung Chung and Daniel Gildea.
2010.
Effectsof empty categories on machine translation.
InProceedings of the 2010 Conference on EmpiricalMethods in Natural Language Processing.Elizabeth Baran, Yaqin Yang and Nianwen Xue.
2012Annotating dropped pronouns in Chinese newswiretext..
In Proceedings of the 8th International Con-ference on Language Resources and Evaluation(LREC), Istanbul, Turkey.Andrew Kachites McCallum.
2002 Mallet:A machine learning for language toolkit..http://mallet.cs.umass.edu.Nianwen Xue and Yaqin Yang.
2013 Dependency-based empty category detection via phrase structuretrees..
In Proceedings of NAACL HLT.
Atlanta,Georgia.Yaqin Yang and Nianwen Xue.
2010 Chasing theghost: recovering empty categories in the ChineseTreebank..
In Proceedings of the 23rd InternationalConference on Computational Linguistics (COL-ING).
Beijing, China.Bing Xiang, Xiaoqiang Luo, Bowen Zhou.
2013.
En-listing the Ghost: Modeling Empty Categories forMachine Translation.
In Proceedings of the ACL.Converse, Susan 2006 Pronominal anaphora resolu-tion for Chinese.. Ph.D. thesis.Mitchell P. Marcus, Beatrice Santorini, and Mary AnnMarcinkiewicz.
1993 Building a large annotatedcorpus of english: The penn treebank.. Computa-tional Linguistics, 19(2):313?330.Nianwen Xue, Fei Xia, Fu dong Chiou, and MarthaPalmer.
2005 The Penn Chinese TreeBank: PhraseStructure Annotation of a Large Corpus.
NaturalLanguage Engineering, 11(2):207?238.Slav Petrov and Dan Klein.
2007.
Improved Infer-encing for Unlexicalized Parsing.
In Proceedings ofHLT-NAACL 2007.Jing Peng and Kenji Araki.
2007 Zero-Anaphora Res-olution in Chinese Using Maximum Entropy.. IEICETransactions.313
