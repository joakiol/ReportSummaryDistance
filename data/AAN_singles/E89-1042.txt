ON FORMALISMS AND ANALYSIS, GENERATION ANDSYNTHESIS IN MACHINE TRANSLATIONZaharin YusoffProjek Terjemahan Melalui KomputerPPS.
Matematik & Sains KomputerUniversiti Sains Malaysia11800 PenangMalaysiaIntroductionA formalism is a set of notation withwell-defined semantics (namely for theinterpretation of the symbols used andtheir manipulation), by means of whichone formally expresses certain domainknowledge, which is to be utilised forspecific purposes.
In this paper, we areinterested in formalisms which are beingused or have applications in the domainof machine translation (MT).
These canrange from specialised languages forlinguistic programming (SLLPs) in NIT,like ROBRA in the ARIANE systemand GRADE in the Mu-system, tolinguistic formalisms like those of theGovernment and Binding theory and theLexical Functional Grammar theory.
Ourinterest lies mainly in their role in thedomain in terms of the ease inexpressing linguistic knowledge requiredfor MT, as well as the ease ofimplementation in NIT systems.We begin by discussing formalismswithin the general context of MT, clearlyseparating the role of linguisticformalisms on one end, which are moreapt for expressing linguistic knowledge,and on the other, the SLLPS which arespecifically designed for MT systems.We argue for another type of formalism,the general formalism, to bridge the gapbetween the two.
Next we discuss therole of formalisms in analysis and ingeneration, and then more specific toNIT, in synthesis.
We sum up with amention on a relevant part of our currentwork, the building of a compiler thatgenerates a synthesis program in SLLPfrom a set of specifications written in ageneral formalism.On formalisms in MTThe field of computational linguisticshas seen many formalisms beenintroduced, studied and compared withother formalisms.
Some get establishedand have been or are still being widelyused, some get modified to suit newerneeds or to be used for other purposes,while some simply die away.
Those thatwe are interested in are formalismswhich play some role in MT.The MT literature has cited formalismslike the formalisms for the governmentand Binding Theory (GB) \[Chomsky81\], the Lexical Functional Grammar(LFG) \[Bresnan & Kaplan 82\], theGeneralized Phrase structure Grammar(GPSG) \[Gazdar & Pullum 82\] (herewe refer to the formalisms provided bythese linguistic theories and not thelinguistic content), Context FreeGrammar (CFG), TransformationalGrammar (TG), Augmented TransitionNetworks (ATN) \[Woods 70\], ROBRA\[Boitet 79\], grade \[Nagao et al 80\],metal \[Slocum 84\], Q-systems\[Colmerauer 71\], Functional UnificationGrammar (FUG) \[Kay 82\], StaticGrammar (SG) \[Vauquois & Chappuy85\], String-Tree CorrespondenceGrammar (STCG) \[Zaharin 87a\],Definite Clause Grammar (DCG)\[Warren & Pereira 80\], Tree AdjoiningGrammar (TAG) \[Joshi et al 75\], etc.To put in perspective the discussions tofollow, we present in Figure 1 a rathernaive but adequate view of the role ofcertain formalisms in biT.- 319  -Genera l  SLLPsFormal i smsFig.
1 - The role of formalisms in MT.GB, LFG and GPSG formalisms areclassed as linguistic formalisms as theyhave been designed purely for linguisticwork, clearly reflecting the hypothesesof the linguistic theories they areassociated to.
Although there have been'LFG-based' and 'GPSG- inspired' MTsystems, a LFG or GPSG system forMT has yet to exist.
Whether or notlinguistic formalisms are suitable for MT(one argues that linguistic formalismstend to lean towards generativeprocesses as opposed to analysis, thelatter being considered very important toMT) is not a major concern to linguists.Indeed it should not be, as one tends toget the general feeling that formallinguistics and MT are separateproblems, although tapping from thesame source.
If this is indeed true, thereis no reason why one should try tochange linguistic formalisms into a formmore suitable for MT.Linguistics has been, is still, and willcontinually be used in MT.
What iscurrently been done is that linguisticknowledge, preferably expressed informal terms using a linguisticformalism, is coded into a MT system bymeans of the SLLPs.
SLLPs includeformalisms like ATN, ROBRA, GRADE,METAL and Q- systems.
Treestructures are the main type of datastructure manipulated in MT systems,and the SLLPs are mainly treetransducers, string-tree transducersand/or tree-string transducers.
Suchmechanisms are arguably very suitablefor defining the analysis process(parsing a text to some representationof its meaning) and the synthesisprocess (generating a text form a givenrepresentation of meaning).
SLLPswhich work on feature structures havealso been introduced, but these alsowork on the same principle.Despite the fact that SLLPs arespecifically designed for programminglinguistic data, and that most of themseparate the static linguistic data(linguistic rules) from the algorithmicdata (the control structure), the problemis that they are still basicallyprogramming languages.
Indeed, duringthe period of their inception, they mayhave been thought of as the MT'sanswer to a linguistic formalism, but it isno longer true these days.
To begin with,most if not all SLLPs are procedural innature, which means that a descriptioncan be read in only one direction (notbidirectional), either for analysis or forsynthesis.
Consequently, for everynatural language treated in a MTsystem, two sets of data will have to bewritten: one for analysis and one forsynthesis.
Furthermore, also due to thisprocedural nature, ling.uistic rules inSLLPs are usually written with somealgorithm in mind.
Hence, althoughseparated from the algorithmiccomponent, hese linguistic rules are nottotally as declarative as one would havehoped (not declarative).
For thesereasons, as well as for the fact thatSLLPs are very system oriented, datawritten in SLLPs are rarely retrievablefor use in other systems (not portable).It was due to these shortcomings thatother formalisms for MT which arebidirectional, declarative and not totallysystem oriented have been designed.Such formalisms include the SG and itsmore formal version, the STCG.
Onefirst notes that these formalisms are notdesigned to replace linguisticformalisms.
There may be somelinguistic justifications (e.g.
in terms ofthe linguistic model \[Zaharin 87b\], but- 320  -they are designed principally for bridgingthe gap between linguistic formalismsand SLLPs.
Such formalisms aredesigned to cater for MT problems, andhence may not directly reflect linguistichypotheses but simply have thepossibility to express them in a mannermore easibly interl?.retable for MT.
Theyare declarative m nature and alsobidirectional.
Only one set of data isrequired to describe both analysis andgeneration.
They are also general innature, meaning that it is possible toexpress different linguistic theoriesusing these formalisms, and also that itis possible to implement theseformalisms using various SLLPs.
Onecan view such formalisms asspecifications for writing SLLPs, asillustrated in Figure 2 (akin tospecifications used in softwareengineering).I linguistic knowledge(in linguistic formalisms)I specifications(in general formalisms)%implementation(in SLLPs)Fig.
2 General formalisms asspecificationsOther formalisms that can beconsidered to be within this class ofgeneral formalisms are TAG, FUG, andperhaps DCG.
With such formalisms,one may express knowledge fromvarious linguistic theories (possibly amixture), and that the same set ofrepresented knowledge may beimplemented for both analysis andsynthesis using various SLLPs indifferent MT systems (as illustrated inFigure 3).D I LF?
I l?PS?l .
.
.
.
.lROBRAinARIANEgeneralformalismsGRADEinMu-systemATLASFig.
3 - the central role of generalformalismsOn specifications for analysisand synthesisThe two main processes in MT areanalysis and synthesis (a third processcalled transfer is present if the approachis not interlingual).
Analysis is theprocess of obtaining somerepresentation(s) of meaning (adequatefor translation) from a given text, whilesynthesis is the reverse process ofobtaining a text from a givenrepresentation of meaning 1.
Analysisand synthesis can be considered to betwo different ways of interpreting asingle concept, this concept being acorrespondence between the set of allpossible texts and the set of all possiblerepresentations of meaning in alanguage.
This correspondence isbasically made up of a set of texts (T), aset of representations (S), and a relationbetween the two R(T,S), defined interms of relations between elements ofT and elements of S. We illustrate thisin Figure 4.- 321 -f Set of  "Representat ionsT- re lat ion betweentexts and.~ .
.
- - representat ionsR(T ,S)  ={R(T,S)  : t ~ T, s ~ S}Fig.
4 - The correspondence b tweentexts and their representationsSupposing that a correspondence asgiven in Figure 4 has been defined,analysis is then the process ofinterpreting the relation R(T,S) in such away that given a text t, itscorresponding representation s isobtained.
Conversely, synthesis is theprocess of interpreting R(T,S) in such away that given s, t is obtained.
Clearly,a general formalism to be used asspecifications must be capable ofdefining the correspondence in Figure 4.Defining the correspondence may entaildefining just one, two, or all threecomponents of Figure 4 depending onthe complexity of the results required.When one works on a natural anguage,one cannot hope to define the set oftexts T (unless it is a very restrictedsublanguage).
Instead, one wouldattempt to define it by means of thedefinition of the other two components.As an example, the CFG formalismdefines only the component R(T,S) bymeans of context-free rules.
Thiscomponent generates the set of texts (t)as well as all possible representations(S) given by the parse trees.
Theformalism of GB defines the relationR(T,S) by means of context-free rules(constrained by the Xbar-theory), move-o~ rules (constrained by boundingtheory), the phonetic interpretativecomponent and the logical interpretativecomponent.
This relation generates theset of all texts (T) and all candidaterepresentations (S) (logical structures).The set S is however further defined(constrained) by the binding theory, 0-theory and the empty category principle.As a third example, the STCG formalismdefines R(T,S) by means of its rules,which in turn generates S and T. The setS is however further defined by means ofconstraints on the writing of the STCGrules.Having set the specifications foranalysis and synthesis by means of ageneral formalism, one can then proceedto implement the analysis andsynthesis.
Ideally, one should have aninterpreter for the formalism that worksboth ways.
However, an interpreteralone is not enough to complete a MTsystem : one has to consider othercomponents like a morphologicalanalyser, a morphological generator,monolingual dictionaries, and for non-interlingual systems, a transfer phaseand bilingual dictionaries.
In fact, suchan interpreter alone will not completethe analysis nor the synthesis, a pointwhich shall be discussed as of the nextparagraph.
For these reasons, thespecifications given by the generalformalism are usually implemented usingavailable integrated systems, and hencein their SLLPs.For analysis, apart from the linguisticrules given by the general formalism,there is the algorithmic omponent to beadded.
This is the control structure thatdecides on the sequence of application ofrules.
A general formalism does not, andshould not, include the algorithmiccomponent in its description.
Thedescription should be static.
There isalso the problem of lexical and structuralambiguities, which a general formalismdoes not, and should not, take intoconsideration either.
A fully descriptiveand modular specification for analysisshould have separate components forlinguistic rules (given by the formalism),algorithmic structure, anddisambiguation rules.
Apart from beingtheoretically attractive, such modularityleads to easier maintenance (thisdiscussion is taken further in \[Zaharin88\]); but most important is the fact thesame linguistic rules given by the- 322 -formalism will serve as specifications forsynthesis, whereas the algorithmiccomponent and disambiguation rules willnot.In general, synthesis in MT lacks aproper definition, in particular for transfersystems 2.
It is for this reason (and otherreasons similar to those for analysis)That the specifications for synthesisgiven by the general formalism play amajor role but do not suffice for thewhole synthesis process.
To clarify thispoint, let us look at the classical globalpicture for MT in second generations.ystems given in Figure 5.
The figuregives the possible levels for transferfrom the word level up to interlingua, thehigher one goes the deeper themeaning.Inter\]inguaRelationsLogical RelatkmumSyntactic FunctionSyntagmatic ClassI bLexical UnitsLemmasWordsSource TargetText TextFig.
5 - The levels of transfer in secondgeneration MT systemsMost current systems attempt o go ashigh as the level of semantic relations(eg.
AGENT, PATIENT,INSTRUMENT) before embarking onthe transfer.
Most systems also retainsome lower level information (eg.
logicalrelations, syntactic functions andsyntagmatic classes) as the analysisgoes deeper, and the information getsmapped to their equivalents in the targetlanguage.
The reason for this is thatcertain lower level information may beneeded to help choose the target text tobe generated amongst the manypossibilities that can be generated froma given target representation; the otherreason is for cases that fail to attain acomplete analysis (hence fail-softmeasures).The consequence to the above is thatthe output of the transfer, and hence theinput to synthesis, may contain amixture of the information.
Some of thisinformation are pertinent, namely theinformation associated to the level oftransfer (in this case the semanticrelations, and to a large extent thelogical relations), while the rest areindicative.
The latter can be consideredas heuristics that helps the choice of thetarget text as described above.Whatever the level of transfer chosen,there is certainly a difference betweenthe input to synthesis and therepresentative structure described in theset S in Figure 4, the latter beingprecisely the representative structurespecified in the general formalism.
Inconsequence, if the synthesis is to beimplemented true to the specificationsgiven by the general formalism (whichhave also served as the specificationsfor analysis), the synthesis phase has tobe split into two subphases: the firstphase has the role of transforming theinput into a structure conforming to theone specified by the formalism (let uscall this subphase SYN1), and the otherdoes exactly as required by the generalformalism, ie.
generate the required textfrom the given structure (call this phraseSYN2).
The translation process is thenas illustrated in Figure 6.As mentioned, the phase SYN2 isexactly as specified by the generalformalism used as specifications.
Whatis missing is the algorithmic omponent,which is the control structure whichdecides on the applications of rules.However, the phase SYN1 needs somecareful study.
Some indication is given inthe discussion on some of our currentwork.- 323 -AnalysSource \[TextTransfer~'- ( Input//Specificationsin General ~ )FormalismFig.6 - The splitting of synthesisSYN1SpecifiedStructureSYN2\[ T~eg~t JSome relevant current work atPTMK-GETARelevant to the discussion in thispaper, the following is some currentwork undertaken within the cooperationin MT between PTMK (ProjekTerjemahan Melalui Komputer) inPenang and GETA (Groupe d'Etudespour la Traduction Automatique) inGrenoble.The formalisms of SG, and its moreformal version STCG, have been used asspecifications for analysis and synthesissince 1983, namely for MT applicationsfor French-English, English-French andEnglish-Malay, using the ARIANEsystem.
However, not only theimplementations have been in the SLLPROBRA in ARIANE, the transfer fromspecifications (given by the generalformalism) to the implementationformalism has also been done manually.One .project undertaken is theconstruction of an interpreter for theSTCG which will do both analysis andgeneration.
Some appropriatemodifications will enable the interpreterto handle synthesis (SYN2 above).
Atthe moment, implementationspecifications are about to be completed,and the implementation is proposed tobe carried out in the programminglanguage C.Another project is the construction of acompiler that generates a synthesisprogram in ROBRA from a given set ofspecifications written in SG or STCG.Implementation specifications for SYN2is about to be completed, and theimplementation is proposed to be cardedout in Turbo-Pascal.
The algorithmiccomponent in SYN2 will beautomatically deduced from theREFERENCE mechanism of theSG/STCG formalism.
The automaticgeneration of a SYN1 program poses abigger problem.
For this, the outputspecifications are given by the SG/STCGrules, but as mentioned earlier, the inputspecifications can be rather vague.
Toovercome this problem, we are forced tolook more closely into the definitions ofthe various levels of interpretation asindicated in Figure 5, from which weshould be able to separate out thepertinent from the indicative type ofinformation in the input structure toSYN1 (as discussed earlier).
Once thisis done, the interpretation of SG/STCGrules for generating a SYN1 program inROBRA will not pose such a bigproblem (the problem is theoretical, notof implementation in fact,specifications for implementation for thislatter part have been laid down, pendingon the results of the theoreticalresearch).Concluding remarksThe MT literature cites numerousformalisms.
The formalisms, can begenerally classed as linguistic- 324 -formalisms, SLLPs and generalformalisms.
The linguistic formalismsare designed purely for linguistic work,while SLLPs, although designed for MTwork, may lack certain desirableproperties like bidirectionality,declarativeness and portability.
Generalformalisms have been designed to bridgethe gap between the two extremes, butmore important, they can serve asspecifications in MT.
However, suchformalisms may still be insufficient tospecify the entire MT process.
There isperhaps a call for more theoreticalfoundations with more formal definitionsfor the various processes in MT.Footnotes1.
The term generation has sometimesbeen used in place of synthesis, but thisis quite incorrect.
Generation refers tothe process of generating all possibletexts from a given representation,usually an axiom, and this is irrelevantin MT apart from the fact that synthesiscan be viewed as a subprocess ofgeneration.2.
Interlingual systems may not lackthe definition for synthesis, but they lackthe definition for interlingua itself.
Todate, all interlingual systems can beargued to be transfer systems in adifferent guise.ReferencesCh.
Boitet - Automatic production ofCF and CS-analyzers using a generaltree transducer.
2.
InternationaleK.
olloquium i iber MaschinelleUbersetzung, Lexicographie undAnalyse, Saarbrticken, 16-17 Nov. 1979.J.
Bresnan and R.M.
Kaplan - LexicalFunctional Grammar: a formal systemfo r  grammatical representations.
In TheMental Representation f GrammaticalRelations, J. Bresnan (ed), Mrr  Press,Cambridge, Mass., 1982.N.
Chomsky - Lectures on Governmentand Binding (the Pisa Lectures), Foris,Dordrecht, 1981.A.
Colmerauer - Les syst~mes-Q ouun formalisme pour analyser etsynthttiser des phrases sur ordinateur.TAUM, Universit6 de Montrtal, 1971.G.
Gazdar and G.K. Pullum -Generalized Phrase Structure Grammar:a theoretical synopsis.
IndianaUniversity Linguistics Club,Bloomington, Indiana, 1982.A.
Joshi, L. Levy and M. Takahashi -Tree Adjunct Grammars.
Journal of theComputer and System Sciences 10:1,1975.M.
Kay - Unification Grammar.
XeroxPalo Alto Research Center, 1982.M.
Nagao, J. Tsujii, K. Mitamura, H.Hirakawa and M. Kume A machinetranslation system from Japanese intoEnglish another perspective of MTsystems.
Proceedings of COLING 80,Tokyo, 1980.J.
Slocum - METAL: The LRC machinetranslation system.
ISSCO Tutorial onMachine Translation, Lugano,Switzerland, 1984.B.
Vauquois and S. Cilappuy - StaticGrammars: a formalism for thedescription of linguistic models.Proceedings of the Conference onTheoretical and Methodological Issuesin Machine Translation of NaturalLanguages, Colgate University,Hamilton, NY, 1985.D.H.D.
Warren and F.C.N.
Pereira -Definite Clause Grammars for languageanalysis.
A survey of the formalism anda comparison with ATNs; ArtificialIntelligence 13, 1980.W.A.
Woods Transition NetworkGrammars for natural language analysis.Communications of the ACM 13:10, 1970.Y.
Zaharin - String-TreeCorrespondence Grammar: a declarativegrammar formalism for defining thecorrespondence between strings ofterms and tree structures.
3rdConference of the European Chapter ofthe Association for ComputationalLinguistics, Copenhagen, 1987.- 325  -Y. Zaharin - The linguistic approach atGETA: a synopsis.
Technologos 4(printemps 1987), LISH-CNRS, Paris.Y.
Zaharin - Towards an analyser(parser) in a machine translation systembased on ideas from expert systems.Computational Intelligence 4:2, 1988.- 326-
