Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 621?631,Berlin, Germany, August 7-12, 2016.c?2016 Association for Computational LinguisticsCollective Entity Resolution with Multi-Focal AttentionAmir Globerson?and Nevena Lazic and Soumen Chakrabarti?andAmarnag Subramanya and Michael Ringgaard and Fernando PereiraGoogle, Mountain View CA, USAgamir@post.tau.ac.il, nevena@google.com, soumen@cse.iitb.ac.in,{asubram, ringgaard, pereira}@google.comAbstractEntity resolution is the task of linking eachmention of an entity in text to the cor-responding record in a knowledge base(KB).
Coherence models for entity resolu-tion encourage all referring expressions ina document to resolve to entities that arerelated in the KB.
We explore attention-like mechanisms for coherence, where theevidence for each candidate is based on asmall set of strong relations, rather thanrelations to all other entities in the doc-ument.
The rationale is that document-wide support may simply not exist fornon-salient entities, or entities not denselyconnected in the KB.
Our proposed sys-tem outperforms state-of-the-art systemson the CoNLL 2003, TAC KBP 2010,2011 and 2012 tasks.1 IntroductionEntity resolution (ER) is the task of mapping men-tions of entities in text to corresponding records ina knowledge base (KB) (Bunescu and Pasca, 2006;Cucerzan, 2007; Kulkarni et al, 2009; Dredze etal., 2010; Hoffart et al, 2011; Hachey et al, 2013).ER is a challenging problem because mentions areoften ambiguous on their own, and can only beresolved given appropriate context.
For example,the mention Beirut may refer to the capital ofLebanon, the band from New Mexico, or a drink-ing game (Figure 1).
Names may also refer to en-tities that are not in the KB, a problem known asNIL detection.Most ER systems consist of a mention model,a context model, and a coherence model (Milneand Witten, 2008; Cucerzan, 2007; Ratinov et al,?Currently at Tel Aviv University?Currently at IIT Bombay2011; Hoffart et al, 2011; Hachey et al, 2013).The mention model associates each entity withits possible textual representations (also known asaliases or surface forms).
The context model helpsresolve an ambiguous mention using textual fea-tures extracted from the surrounding context.
Thecoherence model, the focus of this work, encour-ages all mentions to resolve to entities that are re-lated to each other.
Relations may be establishedvia the KB, Web links, embeddings, or other re-sources.Coherence models often define an objectivefunction that includes local and pairwise candi-date scores, where the pairwise scores correspondto some notion of coherence or relation strength.1Support for a candidate is typically aggregatedover relations to all other entities in the document.One problem with this approach is that it may di-lute evidence for entities that are not salient in thedocument, or not well-connected in the KB.
Ourwork aims to address this issue.We introduce a novel coherence model with anattention mechanism, where the score for eachcandidate only depends on a small subset of men-tions.
Attention has recently been used with con-siderable empirical success in tasks such as trans-lation (Bahdanau et al, 2014) and image captiongeneration (Xu et al, 2015).
We argue that atten-tion is also desirable for collective ER due to thediscussed imbalance in the number of relations fordifferent entities.Attention models typically have a single focus,implemented using the softmax function.
Ourmodel allows each candidate to focus on multi-ple mentions, and, to implement it, we introduce anovel smooth version of the multi-focus attention1An exception to this framework are topic models inwhich a topic may generate both entities and words, e.g.,(Kataria et al, 2011; Han and Sun, 2012; Houlsby and Cia-ramita, 2014).621Beirut(city in Leb.
)Beirut(band)Beirut(game)y1Santa Fe(city in NM)Santa Fe(film)Santa Fe(city in Cuba)y2New Mexico(state)New Mexico(university)New Mexico(ship)y3Figure 1: Illustration of the ER problem for three mentions ?Beirut?, ?New Mexico?
and ?Santa Fe?.each mention has three possible disambiguations.
Edges link disambiguations that have Wikipedia linksbetween their respective pages.function, which generalizes soft-max.Our system uses mention and context modelssimilar to those of Lazic et al (2015), along withour novel multi-focal attention model to enforcecoherence, leading to significant performance im-provements on CoNLL 2003 (Hoffart et al, 2011)and TAC KBP 2010?2012 tasks (Ji et al, 2010;Ji et al, 2011; Mayfield et al, 2012).
In partic-ular, we achieve a 20% relative reduction in er-ror from Chisholm and Hachey (2015) on CoNLL,and a 22% error reduction from Cucerzan (2012)on TAC 2012.
Our contributions thus consist ofdefining a novel multi-focal attention model andapplying it successfully to an entity resolution sys-tem.2 Definitions and notationWe are given a document with n mentions, whereeach mention i has a set of nicandidate entitiesCi= {ci,1, ..., ci,ni}.
The goal is to assign a labelyi?
Cito each mention.Similarly to previous work, our approach to dis-ambiguation relies on local and pairwise candidatescores, which we denote by si(yi) and sij(yi, yj)respectively.
The local score is based only on lo-cal evidence, such as the mention phrase and tex-tual features, while the pairwise score is basedon the relatedness of the two candidates.
In Sec-tions 3.2 and 3.3 we discuss how these scoresmay be parameterized and learned.
Many systems(Cucerzan, 2007; Milne and Witten, 2008; Kulka-rni et al, 2009) simply hardwire pairwise scores.Coherence models typically attempt to maxi-mize a global objective function that assigns ascore to each complete labeling y = (y1, .
.
.
, yn).An example of such a function is the sum of allsingleton and pairwise scores for each label:2g(y) =?isi(yi) +?i?j:j 6=isij(yi, yj).
(1)One disadvantage of this approach is that max-imizing g corresponds to finding the MAP as-signment of a general pairwise Markov randomfield, and is hence NP hard for the general case(Wainwright and Jordan, 2008).
Another limi-tation is that non-salient entities may be relatedto very few other entities mentioned in the doc-ument, and summing over all mentions may dilutethe evidence for such entities.
In this paper weexplore alternative objectives, relying on attentionand tractable inference.3 Attention modelWe now describe our multi-focal attention model.We first introduce the inference approach and op-timization objective, and then provide details onhow scores are calculated and learned.3.1 InferenceAs noted earlier, the global score function inEq.
(1) is hard to maximize.
Here we simplify in-ference by decomposing the task over mentions,which makes it easy to integrate attention in termsof both inference and learning.3.1.1 Star modelWe start by considering a simple attention-freemodel in which inference is tractable, which wecall a star model.
For a particular mention i, thestar model is a graphical model that contains yi,2The scores usually depend not only on the labels, but alsoon the input text.
We omit this dependence for brevity.622y1y2y3y4(a)y1y2y3y4(b)y1y2y3y4(c)Figure 2: (a) The complete graph corresponding toEq.
(1).
(b) A star shaped subgraph correspondingto y2.
This will be used to obtaining the label y2.
(c) The star graph for y3.all interactions between yiand other labels, andno other interactions, as illustrated in Fig.
2.While the star graph centered at i contains up ton variables, we will only use it to infer the label ofmention i.
Let qij(yi) be the support for label yifrom mention j, defined as follows:qij(yi) = maxyjsij(yi, yj) + sj(yj), (2)and we also define qii(yi) = ??
to simplify nota-tion for later.
We define the following score func-tion for mention i:fi(yi) = si(yi) +?j:j 6=iqij(yi) (3)and predict the label yi= arg maxyfi(y).Due to the structure of the star graph, infer-ence is easy and can be done in O(nC2), whereC is the maximum number of candidates.
A simi-lar decomposition has previously been used in thecontext of approximate learning for structured pre-diction (Sontag et al, 2011).
Note that we donot view this approach as an approximation to theglobal problem, but rather as our inference proce-dure.3.1.2 Adding attentionThe score function in Eq.
(3) aggregates pairwisescores for each label yiover all mentions.
Inthis section, we restrict this to only consider Kmentions with the strongest relations to yi.3LetamxK(z) be the sum of the largest K values in thevector z = (z1, .
.
.
, zn).
For each label yi, weredefine the score function to befi(yi) = si(yi) + amxK(qi(yi)), (4)3It is possible to relax this to allow up to K relations, butwe focus on exactly K for simplicity.where qi(yi) = (qi1(yi), .
.
.
, qin(yi)) and qij(yi)is as defined in Eq.
(2).
The inference rule is againyi= arg maxyfi(y), and the computational costis O(nC2+ n log n) since sorting is required.43.1.3 Soft attentionPrevious work on attention has shown that it is ad-vantageous to use a soft form of attention, wherethe level of attention is not zero or one, but canrather take intermediate values.
Existing attentionmodels focus on a single object, such as a singleword (Bahdanau et al, 2014) or a single imagewindow (Xu et al, 2015).
In such models, it isnatural to change the max function in the attentionoperator to a soft-max.
In our case, the attentionbeam contains K elements, and we require a dif-ferent notion of a soft-max, which we develop be-low.To obtain a soft version of the functionamxK(z), we first use an alternative definition.Denote by S the set u = (u1, .
.
.
, un) such that0 ?
ui?
1 and?iui= K. Then amxK(z) isequivalent to the optimization problem:max?u?Sz ?
u (5)The optimization problem above is a linear pro-gram, whose solution is the sum of topK elementsof z as required.
This follows since the optimal uican easily be shown to attain only integral values.Given this optimization view of amxK(z) it isnatural to smooth it (Nesterov, 2005) by adding anon-linearity to the optimization.
Since the vari-ables are non-negative, one possible choice is anentropy-like regularizer.
We shall see that thischoice results in a closed form solution, and alsorecovers the standard soft-max case for K = 1.Consider the optimization problem:smxK(z) = maxu?S?iziui?
?
?1?iuilog ui,(6)where ?
is a tuned hyperparameter.5The follow-ing proposition provides a closed form solution forsmxK, as well as its gradient.Proposition 3.1.
Assume w.l.o.g.
that z is sortedsuch that z1?
.
.
.
?
zn.
Denote by R the maxi-mum index r ?
{1, .
.
.
,K ?
1} such that:zr?
?
?1log?nj=r+1exp (?zj)K ?
r(7)4Note that if K < logn, we spend only nK instead ofn logn time.5Note that ?
?iuilog uiis different from the entropyfunction since variables uisum to K and not to 1.623If this doesn?t hold for any r, set R = 0.
Then:smxK(z) =R?j=1zj+K ?R?log?nj=R+1exp (?zj)K ?R(8)The function smxK(z) is differentiable with a gra-dient v given by:vi={1 1 ?
i ?
R(K ?R)exp(?zi)?nj=R+1exp(?zj)R < i ?
n}(9)Proof is provided in the appendix.As noted, K = 1 recovers the standard soft-max function.6As ?
?
?, smxKwill approachthe sum of the top K elements as expected.
Forfinite ?
we have a soft version of amxK.Our soft attention based model will thereforeconsider the soft-variant of Eq.
(4):fi(yi) = si(yi) + smxK(qi(yi)) , (10)and maximize f(yi) to obtain the label.3.2 Score parameterizationThus far we assumed the singleton and pairwisescores were given.
We next discuss how to param-eterize and learn these scores.
As in other struc-tured prediction work, we will assume that thescores are functions of the features of the input xand labels.
Specifically, denote a set of singletonfeatures for mention i and label yiby ?si(x, yi) ?Rnsand a set of pairwise features for mentionsi and j and their labels by ?pij(x, yi, yj) ?
Rnp.Then the model has two sets of weights wsandwpand the scores are obtained as a linear combi-nation of the features.
Namely:7si(yi;ws) = ws?
?si(x, yi)sij(yi, yj;wp) = wp?
?pij(x, yi, yj) ,where we have explicitly denoted the dependenceof the scores on the weight vectors.
See Sec.
6.2.2for details on how the features are chosen.
It is ofcourse possible to consider non-linear alternativesfor the score function, as in recent deep learning6When we refer to the soft-max function, we mean thefunction ?
?1log?exp (?ai), which is an often used differ-entiable convex upper bound of the max function (e.g., see(Gimpel and Smith, 2010)).
Soft-max sometimes also refersto the activation functionexp(ai)?jexp(aj).
The latter is in fact thegradient of the former (for ?
= 1).7We again omit the dependence of the scores on the inputx for brevity.parsing models (Chen and Manning, 2014; Weisset al, 2015), but we focus on the linear case forsimplicity.3.3 Parameter learningThe parameters ws,wpare learned from labeleddata, as explained next.
Since inference decom-poses over mentions, we use a simple hinge lossfor each mention.
Denote by y?ithe groundtruth label for mention i, and let si(yi) ?
(si1(yi), .
.
.
, sin(yi)).
Then the hinge loss formention i is:Li= maxyi[si(yi) + smxK(si(yi))?si(y?i)?
smxK(si(y?i)) + ?
(yi, y?i)]where ?
(yi, y?i) is zero if yi= y?iand one other-wise.
If there are unlabeled mentions in the train-ing data, we add those to the star graph, and max-imize over the unknown labels in the positive andnegative part of the hinge loss.
The overall lossis simply the sum of losses for all the mentions,plus `2regularization over ws,wp.
We minimizethe loss using AdaGrad (Duchi et al, 2011) withlearning rate ?
= 0.1.4 Single-link modelTo motivate our modeling choices of using multi-focal attention and decomposed inference, we ad-ditionally consider a simple baseline model withsingle-focus attention and global inference.
In thisapproach, which we name single-link, each men-tion i attends to exactly one other mention thatmaximizes the pairwise relation score.
The cor-responding objective can be written asgSL(y) =?i(si(yi) + maxjsij(yi, yj))(11)where sij(yi, yj) = ??
if there is no relation be-tween yiand yj, and we set sii(yi, yi) = 0.While exact inference in this model remains in-tractable, we can find approximate solutions us-ing max-sum belief propagation (Kschischang etal., 2001).
As a reminder, max-sum is an itera-tive algorithm for MAP inference which can bedescribed in terms of messages sent from modelfactors ga(ya) to each of their variables y ?
ya.At convergence, each variable is assigned to thevalue that maximizes belief b(y), defined as thesum of incoming messages.
The message updates624have the following form:?ga?Y(y) = maxya\y[ga(ya) +?j 6=iq\aj(yj)](12)where q\aj(yj) is the sum of all messages to yjexcept the one from factor ga.
While the single-link model contains high-order factors over n vari-ables, computing the messages from these factorsis tractable and requires sorting.5 Related workJi (2016) and Ling et al (2015) provide summariesof recent ER research.
Here we review work re-lated to the three main facets of our approach.5.1 Coherence scoresSeveral systems (Milne and Witten, 2008; Kulka-rni et al, 2009; Hoffart et al, 2011) use the ?Milneand Witten?
measure for relatedness between apair of entities, which is based on the number ofWikipedia articles citing each entity page, and thenumber of articles citing both; Cucerzan (2007)has also relied on the Wikipedia category struc-ture.
Internal links from one entity page to an-other in Wikipedia also provide direct evidenceof relatedness between them.
Another (possiblymore noisy) source of information are Web pagescontaining links (Singh et al, 2012) to Wikipediapages of both entities.
Such links have beenused in several recent systems (Cheng and Roth,2013; Chisholm and Hachey, 2015).
Yamada etal.
(2016) train embedding vectors for entities, anduse them to define similarities.5.2 Collective inference for EROptimizing most global coherence objectives is in-tractable.
Milne and Witten (2008) and Ferraginaand Scaiella (2010) decompose the problem overmentions and select the candidate that maximizestheir relatedness score, which includes relations toall other mentions.
Hoffart et al (2011) use an it-erative heuristic to remove unpromising mention-entity edges.
Cucerzan (2007) creates a relationvector for each candidate, and disambiguates eachentity to the candidate whose vector is most sim-ilar to the aggregate (which includes both correctand incorrect labels).
Cheng and Roth (2013) usean integer linear program solver and Kulkarni etal.
(2009) use a convex relaxation.
Ratinov et al(2011) use relation scores as features in a rank-ing SVM.
Belief propagation without attention hasbeen used by Ganea et al (2015).
PersonalizedPageRank (PPR) (Jeh and Widom, 2003) is an-other tractable alternative, adopted by several re-cent systems (Han and Sun, 2011; He et al, 2013;Alhelbawy and Gaizauskas, 2014; Pershina et al,2015).
Laplacian smoothing (Huang et al, 2014)is closely related.5.3 Attention modelsAttention models have shown great promise inseveral applications, including machine transla-tion (Bahdanau et al, 2014) and image captiongeneration (Xu et al, 2015).
We address a new ap-plication of attention, and introduce a significantlydifferent attention mechanism, which allows eachvariable to focus on multiple objects.
We developa novel smooth version of the multi-focus atten-tion function, which generalizes the single focussoftmax-function.
While some existing entity res-olution systems (Jin et al, 2014; Lazic et al, 2015)may be viewed as having attention mechanisms,these are intended for single textual features andnot readily extensible to structured inference.6 Experiments6.1 Evaluation dataCoNLL: The CoNLL dataset (Hoffart et al,2011) contains 1393 articles with about 34K men-tions, and the standard performance metric ismention-averaged accuracy.
The documents arepartitioned into train, test-a and test-b.
Like mostauthors, we report performance on the 231 test-bdocuments with 4483 linkable mentions.TAC KBP: The TAC KBP 2010, 2011, and2012 evaluation datasets (Ji et al, 2010; Ji et al,2011; Mayfield et al, 2012) include 2250, 2250,and 2226 mentions respectively, of which roughlyhalf are linkable to the reference KB.
The compe-tition evaluation includes NIL entities; participantsare required to cluster NIL mentions across docu-ments so that all mentions of each unknown entityare assigned a unique identifier.
For these datasets,we report in-KB accuracy, overall accuracy (withall NILs in one cluster), and the competition metricB3+F1which evaluates NIL clustering.6.2 Experimental setup6.2.1 KB and entity aliasesOur KB is derived from the Wikipedia subset ofFreebase (Bollacker et al, 2008), with about 4M625entities.
To obtain our mention prior (the proba-bility of candidate entities given a mention), wecollect alias counts from Wikipedia page titles (in-cluding redirects and disambiguation pages), Free-base aliases, and Wikipedia anchor text.
99.31%of CoNLL test-b mentions are covered by the KB,and 96.19% include the gold entity in the candi-dates.We optionally use the mapping from aliasesto candidate entities released by Hoffart et al(2011), obtained by extending the ?means?
tablesof YAGO (Hoffart et al, 2013).
When released,it had 100% mention and gold recall on CoNLL,i.e.
every annotated mention could be mapped toat least one entity, and the set of entities includedthe gold entity.
However, changes in canonicalWikipedia URLs, accented characters and unicodeusually result in mention losses over time, as notall URLs can be mapped to the KB (Hasibi et al,2016, Sec.
4).For CoNLL only, we experiment with a thirdalias-entity mapping derived from Hoffart et al(2011) by Pershina et al (2015); we call it ?HP?.It is not known how candidates were pruned, butit has high recall and very low ambiguity: only12.6 on CoNLL test-b, compared to 22.34 in ourKB and 65.9 in YAGO.
Unsurprisingly, using onlythis source of aliases results in high accuracy onCoNLL (Pershina et al, 2015; Yamada et al,2016).Table 1 lists the statistics of the three alias-entitymappings and some of their combinations on theCoNLL test-b dataset.
Table 2 provides the samestatistics on the TAC KBP datasets (restricted tonon-NIL mentions) for the of the YAGO+KB alias-entity mapping.6.2.2 Local and pairwise scoresOur baseline system is similar in design and accu-racy to Plato (Lazic et al, 2015).
Given the ref-erent phrase miand textual context features bi,it computes the probability of a candidate entityas pi(c) ?
p(c|mi)p(bi|c).
The system resolvesmentions independently and does not have an ex-plicit coherence model; however, it does capturesome coherence information indirectly as referentphrases are included as string context features.
Weexperiment with several versions of the mentionprior p(c|mi) as described in the previous section.Scores for single-link model: In the single-linkmodel, we simply set the local score for mention iAlias Mention Gold Uniq.
Avg.map recall recall % ambig.KB 99.31 96.19 17.93 22.3YAGO 97.17 96.30 15.50 65.9+KB 99.84 99.51 16.28 73.6HP 99.87 99.84 17.98 12.6+KB 99.87 99.87 16.40 28.7All 99.87 99.87 15.37 78.7Table 1: Alias-entity map statistics on CoNLLtest-b, 4483 gold mentions.
Mention recall is thepercentage of mentions with at least one knownentity; gold recall is the percentage of mentionswhere the gold entity was included in the candi-dates.
Unique aliases map to exactly one entity.The last column shows the number of candidatesaveraged over test-b mentions.Dataset Mention Gold Uniq.
Avg.recall recall % ambig.TAC 2010 98.14 93.04 22.45 45.34TAC 2011 98.40 89.23 27.82 49.13TAC 2012 97.36 87.83 20.00 68.93Table 2: YAGO+KB alias-entity map statistics onthe TAC KBP datasets, restricted to non-NIL men-tions.and candidate c to si(c) = lnpi(c)1?pi(c), so that likelycandidates get positive scores.
We set the pair-wise score between two candidates heuristically tosij(yi, yj) = ln o(yi, yj) + 2.3, where o(yi, yj) isthe number of outlinks from the Wikipedia pageof yito the page of yj.
We consider up to threecandidates for each mention for CONLL, and tenfor TAC; if the baseline probability of the top can-didate exceeds 0.9, we only consider the top can-didate.
Including more candidates did not makea difference in performance, as additional candi-dates had low baseline scores and were almostnever chosen in practice.Scores for attention model: Local features?si(x, yi) for the attention model are derived frompi(c).
As the attention models have no probabilis-tic interpretation, we inject as features log pi(c)and log(1 ?
pi(c)).
We set log 0 = 0 by conven-tion, and handle the case where log is undefinedby introducing two additional binary indicator fea-tures for pi(c) = 0 and pi(c) = 1.Edge features ?pijare set based on three sourcesof information: (1) number of Freebase relations626System Alias map In-KB acc.
%Lazic (2015) N/A 86.4Our baseline KB 87.9Single link KB 88.2Attention KB 89.5Chisholm (2015) YAGO 88.7Ganea (2015) YAGO 87.6Our baseline KB+YAGO 85.2Single link KB+YAGO 86.6Attention KB+YAGO 91.0Our baseline KB+HP 89.9Single link KB+HP 89.9Attention KB+HP 91.7Our baseline KB+HP* 91.9Single link KB+HP* 92.1Attention KB+HP* 92.7Pershina (2015) HP 91.8Yamada (2016) HP 93.1Table 3: CoNLL test-b evaluation for recent com-petitive systems and our models, using differentalias-entity maps.
?KB+HP*?
means we train andscore entities using KB+HP, but output entitiesonly in HP.between yiand yj, (2) number of hyperlinks be-tween Wikipedia pages of yiand yj(in either di-rection), and (3) number of mentions of yion theWikipedia page of yjand vice versa, after annotat-ing Wikipedia with our baseline resolver.
We capeach count to five and encode it using five binaryindicator features, where the jthfeature is set to 1if the count is j and 0 otherwise.
Additionally, foreach count c we add a feature log (1 + c).
We alsoadded a binary feature which is one if yi= yj.We train the scores for the attention model onthe 946 CoNLL train documents for CoNLL, andon the TAC 2009 evaluation and TAC 2010 train-ing documents for TAC.6.3 ResultsCoNLL: Table 3 compares our models to recentcompetitive systems on CoNLL test-b in terms ofmention-averaged (micro) accuracy.
We also notethe alias-entity map used in each system, as thecorresponding gold recall is an upper bound onaccuracy, and alias ambiguity determines the dif-ficulty of the task.
Therefore performance is notstrictly comparable between maps.Our baseline is slightly better than Lazic et al(2015), but degrades after adding YAGO aliaseswhich increase ambiguity.
The attention modelprovides a substantial gain over the baseline,and outperforms Chisholm and Hachey (2015) by2.3% in absolute accuracy.The extremely low ambiguity (Tab.
1) of the HPalias mapping, coupled with guaranteed gold re-call, makes the task too easy to be considered arealistic benchmark.
Although we match Pershinaet al (2015) using KB+HP, for completeness, weprovide the performance of our system with candi-date entities restricted to those in HP (KB+HP*),but this is not equivalent to using only HP duringtraining and inference.
With KB+HP*, we outper-form Pershina et al (2015), and are competitivewith recent unpublished work by Yamada et al(2016), which uses entity and word embeddings.Including embeddings as features in our systemmay lead to further gains.TAC KBP: Table 4 shows our results for theTAC KBP 2010, 2011, and 2012 evaluationdatasets, where we used the KB+YAGO entity-alias map for all our experiments.
To compute NILclusters required for B3+ F1, we simply rely onthe fact that our KB is larger than the TAC ref-erence KB, similarly to previous work.
We as-sign a unique NIL label to all mentions of an en-tity that is in our KB but not in TAC.
For men-tions that cannot be linked to our KB, we simplyuse the mention string as the NIL identifier.
Onceagain, our attention models improve the perfor-mance over the baseline system in nearly all exper-iments, with multi-focus attention outperformingsingle-link.
Compared to prior work, we achievecompetitive performance on TAC 2010 and thebest results to date on TAC 2011 and TAC 2012.Table 5 shows two examples from the TAC 2011dataset in which our multi-focus attention modelimproves over the baseline, along with the focusmentions in the document.6.4 Effect of K and ?
on attentionWe set the size of the multi-focus attention beamK based on accuracy on CoNLL test-a (forCoNLL) and training accuracy (for TAC).
Fig.3 shows the effect of K on the performance onCoNLL test-a dataset.
Performance peaks forK = 6, with a sharp decrease after K = 10.
Thisvalidates our central premise: all-pairs label cou-pling may hurt accuracy.In Sec.
3.1.3 we proposed an extension of soft-max smoothing to the K attention case.
In our627System In-KB Overall B3+F1acc.
(%) acc.
(%)Chisholm (2015) 80.7 - -Ling (2015) - 88.8 -Yamada (2016) 85.2 - -Our baseline 84.5 87.6 83.0Single link 84.3 87.5 82.8Attention 87.2 88.7 84.4Cucerzan (2011) - 86.8 84.1Lazic (2015) 79.3 86.5 84.0Ling (2015) - - 81.6Our baseline 81.5 86.8 84.3Single link 82.8 87.3 84.9Attention 84.3 88.0 85.6Cucerzan (2012) R1 72.0 76.2 72.1Cucerzan (2012) R3 71.2 76.6 73.0Lazic (2015) 74.2 76.6 71.2Ling (2015) - - 66.7Our baseline 78.8 80.3 76.9Single link 79.7 80.7 77.3Attention 82.4 81.9 78.9Table 4: Results on the TAC 2010 (top), TAC2011 (middle), and TAC 2012 bottom evaluationdatasets.1 2 3 4 5 6 7 8 10 1588899091KAccuracy(%)Figure 3: Effect of parameter K on entity linkingaccuracy.
Trained on CoNLL train and tested onCoNLL test-a.experiments we cross-validated over a wide rangeof ?
values, including ?
= ?
which correspondsto taking the exact sum of K largest values.
Wefound that the optimal value in most cases waslarge: ?
= 10, 100, or even?.
This suggests thata hard attention model, where exactlyK mentionsare picked is adequate in the current settings.7 ConclusionWe have described an attention-based approach tocollective entity resolution, motivated by the ob-servation that a non-salient entity in a long doc-ument may only have relations to a small subsetof other entities.
We explored two approachesto attention: a multi-focus attention model withtractable inference decomposed over mentions,and a single-focus model with global inference im-plemented using belief propagation.
Our empir-ical results show that the methods results in sig-nificant performance gains across several bench-marks.Experiments in varying the size of the atten-tion beam K in the star-shaped model suggest thatmulti-focus attention is beneficial.
It is of coursepossible to extend the global single-link model tothe multi-focus case, by modifying the model fac-tors and resulting messages.
However, the sim-plicity of the star-shaped model, its empirical ef-fectiveness, and ease of learning parameters makeit an attractive approach for easily incorporatingattention into existing resolution models.
Themodel can also readily be applied to other struc-tured prediction problems in language processing,such as selecting antecedents in coreference reso-lution.Deep learning has recently been used in mutli-ple NLP applications, including parsing (Chen andManning, 2014) and translation (Bahdanau et al,2014).
Learning the local and pairwise scores inour model using a deep architecture rather thana linear model would likely lead to performanceimprovements.
The star-shaped model is partic-ularly amenable to this architecture, as it can beimplemented via a feed-forward sequence of op-erations (including sorting, which can be imple-mented with soft-max gates).Finally, one may consider a more elaboratemodel in which attention depends on the currentstate of the system; for example, the state can sum-marize the mention context.
The dynamics of theunderlying state can be modeled by recurrent neu-ral networks or LSTMs (Bahdanau et al, 2014).In conclusion, we have shown that attention isan effective mechanism for improving entity reso-lution models, and that it can be implemented viaa simple inference mechanism, where model pa-rameters can be easily learned.8 Proof of Proposition 3.1Begin with the optimization problem in Eq.
(6).Introduce the following Lagrange multipliers: ?for the?iui= K constraint, and ?i?
0 forthe ui?
1 constraint.
We can ignore the ui?
0constraint, as it will turn out to be satisfied.
Denote628Sentence with mention Entity Attn.
focus mentionsCaroline has dropped her name base: Caroline (given name) Democratic Partyfrom consideration for the seat attn: Caroline Kennedy New Yorkthat Hillary has left vacant.
Robert KennedyChris Johnson had just 13 tackles last base: Chris Johnson (running back) Oakland Raidersseason, and the Raiders currently have attn: Chris Johnson (cornerback) Oakland Raidershave 11 defensive backs on their roster.
Oakland RaidersTable 5: Examples of gains by our algorithm, showing the resolved mention, the entities it resolves to in the baseline and theattention models, and the mentions in the document that are attended to (here K = 3).
In the first example, the baseline labelsthe mention ?Caroline?
as the given name, whereas the attention model attends to mentions that identify it as the diplomatCaroline Kennedy.
In the second example, both models resolve ?Chris Johnson?
to football players, but the attention modelfinds the correct one by attending to three mentions of his former team, the Oakland Raiders.the corresponding Lagrangian by L(u, ?, ?).
Wewill show the result by using the dual g(?, ?)
=maxuL(u, ?, ?)
and the fact that the solution ofEq.
(6) is min?,?g(?, ?
).Maximizing L with respect to uiyields:ui= e?zi?1+????
?i(13)From this we can obtain the convex dual g(?, ?
),and after minimizing over ?
we arrive at:g(?)
= K??1log?ie?zi??
?iK+?i?i(14)Next, we maximize the above with respect to ?
?0.
Introduce Lagrange multipliers ?ifor the con-straint ?i?
0 and the corresponding Lagrangian?L(?, ?).
We propose a solution for ?, ?
and showthat it satisfies the KKT conditions.
Minimizing?Lwrt ?
we can characterize the optimal ?
as:?i= ?Ke?zi???i?ie?zi??
?i+ 1 (15)Set ?ias follows:?i={zi?1?log?ni=R+1e?ziK?R1 ?
i ?
R0 R < i ?
n(16)It can now be confirmed that the ?, ?
from Equa-tions 16 and 15 satisfy the KKT conditions.
Plug-ging the ?
value into g(?)
yields the solutionin the proposition.
Differentiability follows fromNesterov (2005) and the gradient is uiin Eq.
(13).References[Alhelbawy and Gaizauskas2014] Ayman Alhelbawyand Robert Gaizauskas.
2014.
Graph rankingfor collective named entity disambiguation.
InProc.
52nd Annual Meeting of the Association forComputational Linguistics, ACL 14, pages 75?80.
[Bahdanau et al2014] Dzmitry Bahdanau, KyunghyunCho, and Yoshua Bengio.
2014.
Neural machinetranslation by jointly learning to align and translate.arXiv preprint arXiv:1409.0473.
[Bollacker et al2008] Kurt D. Bollacker, Colin Evans,Praveen Paritosh, Tim Sturge, and Jamie Taylor.2008.
Freebase: a collaboratively created graphdatabase for structuring human knowledge.
In Proc.of the 2008 ACM SIGMOD International Confer-ence on Management of Data, pages 1247?1250.ACM.
[Bunescu and Pasca2006] Razvan C. Bunescu and Mar-ius Pasca.
2006.
Using encyclopedic knowledge fornamed entity disambiguation.
In Proc.
11th Confer-ence of the European Chapter of the Association forComputational Linguistics, EACL 06.
[Chen and Manning2014] Danqi Chen and Christo-pher D Manning.
2014.
A fast and accurate de-pendency parser using neural networks.
In EMNLP,pages 740?750.
[Cheng and Roth2013] Xiao Cheng and Dan Roth.2013.
Relational inference for wikification.
InEMNLP Conference, pages 1787?1796.
[Chisholm and Hachey2015] Andrew Chisholm andBen Hachey.
2015.
Entity disambiguation withweb links.
Transactions of the Association forComputational Linguistics, 3:145?156.
[Cucerzan2007] Silviu Cucerzan.
2007.
Large-scalenamed entity disambiguation based on Wikipediadata.
In Proc.
of EMNLP-CoNLL 2007, pages 708?716.
[Cucerzan2012] Silviu Cucerzan.
2012.
The MSR sys-tem for entity linking at TAC 2012.
In In Proc.
ofthe Text Analysis Conference, TAC 12.
[Dredze et al2010] Mark Dredze, Paul McNamee,Delip Rao, Adam Gerber, and Tim Finin.
2010.629Entity disambiguation for knowledge base popula-tion.
In Proc.
of the 23rd International Conferenceon Computational Linguistics, COLING 10, pages277?285.
[Duchi et al2011] John Duchi, Elad Hazan, and YoramSinger.
2011.
Adaptive subgradient methods for on-line learning and stochastic optimization.
The Jour-nal of Machine Learning Research, 12:2121?2159.
[Ferragina and Scaiella2010] Paolo Ferragina and UgoScaiella.
2010.
TAGME: on-the-fly annotation ofshort text fragments (by Wikipedia entities).
InProc.
of the 19th ACM International Conference onInformation Knowledge and Management, CIKM10, pages 1625?1628.
ACM.
[Ganea et al2015] Octavian-Eugen Ganea, MarinaHorlescu, Aurelien Lucchi, Carsten Eickhoff, andThomas Hofmann.
2015.
Probabilistic bag-of-hyperlinks model for entity linking.
arXiv preprintarXiv:1509.02301.
[Gimpel and Smith2010] Kevin Gimpel and Noah ASmith.
2010.
Softmax-margin crfs: Training log-linear models with cost functions.
In Human Lan-guage Technologies: The 2010 Annual Conferenceof the North American Chapter of the Associationfor Computational Linguistics, pages 733?736.
As-sociation for Computational Linguistics.
[Hachey et al2013] Ben Hachey, Will Radford, JoelNothman, Matthew Honnibal, and James R. Curran.2013.
Evaluating entity linking with Wikipedia.
Ar-tificial Intelligence, 194(0):130 ?
150.
[Han and Sun2011] Xianpei Han and Le Sun.
2011.
Agenerative entity-mention model for linking entitieswith knowledge base.
In Proc.
of the 49th AnnualMeeting of the Association for Computational Lin-guistics: Human Language Technologies, volume 1of ACLHLT 11.
ACL.
[Han and Sun2012] Xianpei Han and Le Sun.
2012.An entity-topic model for entity linking.
InEMNLP-CoNLL, pages 105?115.
[Hasibi et al2016] Faegheh Hasibi, Krisztian Balog,and Svein Erik Bratsberg.
2016.
On the repro-ducibility of the TagMe entity linking system.
InAdvances in Information Retrieval, pages 436?449.Springer.
[He et al2013] Zhengyan He, Shujie Liu, Mu Li, MingZhou, Longkai Zhang, and Houfeng Wang.
2013.Learning entity representation for entity disam-biguation.
In Proc.
of the 51st Annual Meeting ofthe Association for Computational Linguistics, ACL13, pages 30?34.
[Hoffart et al2011] Johannes Hoffart, Mohamed AmirYosef, Ilaria Bordino, Hagen F?urstenau, Man-fred Pinkal, Marc Spaniol, Bilyana Taneva, StefanThater, and Gerhard Weikum.
2011.
Robust disam-biguation of named entities in text.
In Proc.
of the2011 Conference on Empirical Methods in NaturalLanguage Processing, EMNLP11.
ACL.
[Hoffart et al2013] Johannes Hoffart, Fabian MSuchanek, Klaus Berberich, and Gerhard Weikum.2013.
Yago2: A spatially and temporally en-hanced knowledge base from wikipedia.
ArtificialIntelligence, 194:28?61.
[Houlsby and Ciaramita2014] Neil Houlsby and Massi-miliano Ciaramita.
2014.
A scalable Gibbs samplerfor probabilistic entity linking.
In Advances in In-formation Retrieval, pages 335?346.
Springer.
[Huang et al2014] Hongzhao Huang, Yunbo Cao, Xi-aojiang Huang, Heng Ji, and Chin-Yew Lin.2014.
Collective tweet wikification based on semi-supervised graph regularization.
In Proceedingsof the 52nd Annual Meeting of the Association forComputational Linguistics (Volume 1: Long Pa-pers), pages 380?390, Baltimore, Maryland, June.Association for Computational Linguistics.
[Jeh and Widom2003] Glen Jeh and Jennifer Widom.2003.
Scaling personalized web search.
In Proceed-ings of the 12th international conference on WorldWide Web, pages 271?279.
ACM.
[Ji et al2010] Heng Ji, Ralph Grishman, Hoa TrangDang, Kira Griffitt, and Joe Ellis.
2010.
Overviewof the TAC 2010 knowledge base population track.In Proc.
of the 3rd Text Analysis Conference, TAC10.
[Ji et al2011] Heng Ji, Ralph Grishman, and Hoa TrangDang.
2011.
Overview of the TAC 2011 knowledgebase population track.
In Proc.
of the 4th Text Anal-ysis Conference, TAC 11.
[Ji2016] Heng Ji.
2016.
Entity discovery andlinking and Wikification reading list.
On-line.
http://nlp.cs.rpi.edu/kbp/2014/elreading.html.
[Jin et al2014] Yuzhe Jin, Emre Kiciman, KuansanWang, and Ricky Loynd.
2014.
Entity linking atthe tail: sparse signals, unknown entities, and phrasemodels.
In Proc.
of the 7th ACM International Con-ference on Web Search and Data Mining, WSDM?14, pages 453?462, New York, NY, USA.
ACM.
[Kataria et al2011] Saurabh S. Kataria, Krishnan S.Kumar, Rajeev R. Rastogi, Prithviraj Sen, and Srini-vasan H. Sengamedu.
2011.
Entity disambiguationwith hierarchical topic models.
In Proc.
of the 17thACM SIGKDD Conference on Knowledge Discoveryand Data Mining, pages 1037?1045.
ACM.
[Kschischang et al2001] Frank R Kschischang, Bren-dan J Frey, and Hans-Andrea Loeliger.
2001.
Factorgraphs and the sum-product algorithm.
IEEE Trans-actions on Information Theory, 47(2):498?519.
[Kulkarni et al2009] Sayali Kulkarni, Amit Singh,Ganesh Ramakrishnan, and Soumen Chakrabarti.2009.
Collective annotation of Wikipedia entities inweb text.
In Proc.
of the 15th ACM SIGKDD Con-ference on Knowledge Discovery and Data Mining,pages 457?466.
ACM.630[Lazic et al2015] Nevena Lazic, Amarnag Subra-manya, Michael Ringgaard, and Fernando Pereira.2015.
Plato: A selective context model for entityresolution.
Transactions of the Association forComputational Linguistics, 3:503?515.
[Ling et al2015] Xiao Ling, Sameer Singh, andDaniel S Weld.
2015.
Design challenges forentity linking.
Transactions of the Association forComputational Linguistics, 3:315?328.
[Mayfield et al2012] James Mayfield, Javier Artiles,and Hoa Trang Dang.
2012.
Overview of the TAC2012 knowledge base population track.
In Proc.
ofthe 5th Text Analysis Conference, TAC 12.
[Milne and Witten2008] David N. Milne and Ian H.Witten.
2008.
Learning to link with Wikipedia.In Proc.
of the 17th ACM Conference on Informa-tion and Knowledge Management, CIKM 07, pages509?518.
[Nesterov2005] Yu Nesterov.
2005.
Smooth minimiza-tion of non-smooth functions.
Mathematical pro-gramming, 103(1):127?152.
[Pershina et al2015] Maria Pershina, Yifan He, andRalph Grishman.
2015.
Personalized Page Rankfor named entity disambiguation.
In Proc.
2015 An-nual Conference of the North American Chapter ofthe ACL, NAACL HLT 14, pages 238?243.
[Ratinov et al2011] Lev-Arie Ratinov, Dan Roth, DougDowney, and Mike Anderson.
2011.
Local andglobal algorithms for disambiguation to Wikipedia.In Proc.
of the 49th Annual Meeting of the As-sociation for Computational Linguistics: HumanLanguage Technologies, ACLHLT 11, pages 1375?1384.
ACL.
[Singh et al2012] Sameer Singh, Amarnag Subra-manya, Fernando Pereira, and Andrew McCallum.2012.
Wikilinks: A large-scale cross-documentcoreference corpus labeled via links to Wikipedia.Technical Report UM-CS-2012-015, University ofMassachusetts, Amherst.
[Sontag et al2011] D. Sontag, O. Meshi, T. Jaakkola,and A. Globerson.
2011.
More data means lessinference: A pseudo-max approach to structuredlearning.
In R. Zemel and J. Shawe-Taylor, editors,Advances in Neural Information Processing Systems23, pages 2181?2189.
MIT Press, Cambridge, MA.
[Wainwright and Jordan2008] Martin J Wainwright andMichael I Jordan.
2008.
Graphical models, expo-nential families, and variational inference.
Founda-tions and TrendsR?
in Machine Learning, 1(1-2):1?305.
[Weiss et al2015] David Weiss, Chris Alberti, MichaelCollins, and Slav Petrov.
2015.
Structured trainingfor neural network transition-based parsing.
In Pro-ceedings of the 53rd Annual Meeting of the Associ-ation for Computational Linguistics and the 7th In-ternational Joint Conference on Natural LanguageProcessing (Volume 1: Long Papers), pages 323?333, Beijing, China, July.
Association for Computa-tional Linguistics.
[Xu et al2015] Kelvin Xu, Jimmy Ba, Ryan Kiros,Aaron Courville, Ruslan Salakhutdinov, RichardZemel, and Yoshua Bengio.
2015.
Show, attend andtell: Neural image caption generation with visual at-tention.
arXiv preprint arXiv:1502.03044.
[Yamada et al2016] Ikuya Yamada, Hiroyuki Shindo,Hideaki Takeda, and Yoshiyasu Takefuji.
2016.Joint learning of the embedding of words and en-tities for named entity disambiguation.
CoRR,abs/1601.01343.631
