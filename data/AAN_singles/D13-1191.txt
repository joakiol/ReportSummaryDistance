Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1858?1868,Seattle, Washington, USA, 18-21 October 2013. c?2013 Association for Computational LinguisticsLearning Topics and Positions from DebatepediaSwapna Gottipati?
Minghui Qiu?
Yanchuan Sim?
Jing Jiang?
Noah A.
Smith?
?School of Information Systems, Singapore Management University, Singapore?Language Technologies Institute, Carnegie Mellon University, Pittsburgh, PA 15213, USA?{swapnag.2010,minghui.qiu.2010,jingjiang}@smu.edu.sg?
{ysim,nasmith}@cs.cmu.eduAbstractWe explore Debatepedia, a community-authored encyclopedia of sociopolitical de-bates, as evidence for inferring a low-dimensional, human-interpretable representa-tion in the domain of issues and positions.
Weintroduce a generative model positing latenttopics and cross-cutting positions that givesspecial treatment to person mentions and opin-ion words.
We evaluate the resulting repre-sentation?s usefulness in attaching opinionateddocuments to arguments and its consistencywith human judgments about positions.1 IntroductionThe social web has evolved into a forum for largeportions of the population to discuss and debatecomplex issues of societal importance.
Websites likeDebatepedia,1 an online, community-authored ency-clopedia of debates (?2), seek to organize some ofthis exchange into structured information resourcesthat summarize arguments and link externally totexts (editorials, blog posts, etc.)
that express andevoke them.
Empirical NLP, we propose, has arole to play in creating a more compact and easily-interpretable way to understand the opinion space.In particular, we envision applications to computa-tional journalism, where there is high demand fortransformation of and pattern discovery in unman-ageable, unstructured, evolving data (including text)to inform the public (Cohen et al 2011).In this paper, we develop a generative model fordiscovering such a representation (?3), using De-batepedia as a corpus of evidence.
We draw in-spiration from Lin et al(2008) and Ahmed and1http://dbp.idebate.orgXing (2010), who used generative models to infertopics?distributions over words?and other word-associated variables representing perspectives orideologies.
We view topics as lexicons, and proposethat grounding a topic model with evidence beyondbags of words can lead to more lexicon-like repre-sentations.
Specifically, our generative topic modelgrounds topics using the hierarchical organizationof arguments within Debatepedia.
Further, we usenamed entity recognition as a preprocessing step, anexisting sentiment lexicon to construct an informedprior, and we incorporate a latent, discrete positionvariable that cuts across debates.2We evaluate the model informally and formally(?4).
Subjectively, the model identifies reasonabletopic and perspective terms, and it associates topicssensibly with important public figures.
In quanti-tative evaluations, we find the model?s representa-tion superior to topics from vanilla latent Dirichletallocation (Blei et al 2003) and the joint sentimenttopic model (Lin and He, 2009) in matching externaltexts to debates.
Further, the position variables canbe used to infer the side of an argument within a de-bate; our model performs with an accuracy of 86%on position prediction of the debate argument.
Thecross-cutting position variable is not especially con-sistent with human judgments, suggesting that fur-ther knowledge sources may be required to improveinterpretability across issues.2 DataDebatepedia, like Wikipedia, is constructed by vol-unteer contributors and has a system of community2This variable might serve to cluster debate sides accordingto ?abstract beliefs commonly shared by a group of people,?sometimes called ideologies (Van Dijk, 1998).
We do not claimthat our model infers ideologies (see ?4).1858Debate: Gun control; should laws be passed to limit gun ownership further?Question: Self-defense ?
Is self-defense a good reason for gun ownership?Side: Yes Side: NoArgument: A citizen has a ?right?
to guns as a meansto self-defense: Many groups argue that a citizenshould have the ?right?
to defend themselves, and thata gun is frequently the .
.
.Argument: The protection of property is not a goodjustification for yielding a lethal weapon.
While peo-ple have a right to their property, this should not justifywielding a lethal .
.
.Argument: Gun restrictions and bans disadvantage cit-izens against armed criminals.
Citizens that are not al-lowed to carry guns are disadvantaged against lawlesscriminals that .
.
.Argument: Robert F. Drinan, Former Democratic USCongressman, ?Gun Control: The Good Outweighsthe Evil?, 1976 ?
?These graphic examples of individ-ual instances of .
.
.Question: Economic benefits ?
Is gun control economically beneficial?Side: Yes Side: NoArgument: Lax gun control laws are economicallycostly.
The Coalition for Gun Control claims that, ?inCanada, the costs of firearms death and injury alonehave been estimated at .
.
.Argument: Gun sports have economic benefits.
Fieldsports bring money into poor rural economies and pro-vide a motivation for landowners to value environmen-tal protection.Table 1: An example of a Debatepedia debate on the topic ?Gun control.?moderation.
Many of the debate issues covered arecontroversial and salient in current public discourse.Because it is primarily expressed as text, Debatepe-dia is a corpus of debate topics, but it is organizedhierarchically, with multiple issues in each debatetopic, questions within each issue, and arguments ontwo sides of each question.
An important feature ofthe corpus is the widespread quotation and linking toexternal articles on the web, including news stories,blog postings, wiki pages, and social media forums;here we use these external articles in evaluation (?4).Table 1 shows excerpts from a debate page3 fromDebatepedia.
Each debate contains ?questions,?which reflect the different aspects of a debate.
In thisparticular debate, there are 13 questions (2 shown),ranging from economic benefits to enforceability tosocial impacts.
For each question, there are two dis-tinct sides, each with its own set of supporting argu-ments.
Many of these arguments also contains linksto online articles where the quotes are extracted from(not shown in Table 1).
For example, in the secondargument on the ?No?
side, there is an inline link tothe article written by Congressman Drinan.4Within a debate topic, the sides cut across differ-ent questions, aligning arguments together.
In gen-3http://dbp.idebate.org/en/index.php/Debate:_Gun_control4http://www.saf.org/LawReviews/Drinan1.htmlDebates 1,303Arguments 33,556Articles linked by exactly one argument 3,352Tokens 1,710,814Types (excluding NE mentions) 59,601Person named entity mentions 9,496Table 2: Debatepedia corpus statistics.
Types and tokensinclude unigrams, bigrams and person named entities.eral, the questions are phrased so that a consistent?pro?
and ?con?
structure is apparent throughouteach debate, aligned to a high-level question (i.e.,the ?Yes?
sides of all the questions are consistentwith the same side of the larger debate).
The ex-ample of Table 1 deviates from this pattern, with theself-defense ?Yes?
arguing ?no?
to the high-level de-bate question?Should laws be passed to limit gunownership further?
?and the economic ?Yes?
argu-ing ?yes?
to the high-level question.Table 2 presents statistics of our corpus.2.1 PreprocessingWe scraped the Debatepedia website and extractedthe debate, question, argument, and side structureof the debate topics.
We crawled the externalweb articles that were linked from the Debatepe-dia arguments.
For the web articles, we extractedthe main text content (ignoring boilerplate elementssuch as navigation and advertisments) using Boil-1859erpipe (Kohlschu?tter et al 2010).5 We tokenizedthe text and filtered stopwords.6 We considered bothunigrams and bigrams in our model, keeping all uni-grams and removing bigram types that appeared lessthan 5 times in the corpus.
Although our modelingapproach ultimately treats texts as bags of terms (un-igrams and bigrams), one important preprocessingstep was taken to further improve the interpretabil-ity of the inferred representation: named entity men-tions of persons.
We identified these mentions ofpersons using Stanford NER (Finkel et al 2005)and treated each person mention as a single token.
Inour qualitative analysis of the model (?4.2), we willshow how this special treatment of person mentionsenables the association of well-known individualswith debate topics.
Though not part of our exper-imental evaluation in this paper, such associationsare, we believe, an interesting direction for futureapplications of the model.3 ModelOur model defines a probability distribution overterms7 that are observed in the corpus.
Each termoccurs in a context defined by the tuple ?d, q, s, a?
(respectively, a debate, a question within the debate,a side within the debate, and an argument).
At eachlevel of the hierarchy is a different latent variable:?
Each question q within debate d is associatedwith a distribution over topics, denoted ?d,q.8?
Each side s of the debate d is associated with aposition, denoted id,s and we posit a global dis-tribution ?
that cuts across different questionsand arguments.
In our experiments, there aretwo positions, and the two sides of a debateare constrained to associate with opposing po-sitions.
As illustrated by Table 1, this assump-5http://code.google.com/p/boilerpipe6www.ranks.nl/resources/stopwords.html7Recall that our model includes bigrams.
We treat each un-igram and bigram token (after filtering discussed in ?2.1) as aseparate term.8In future work, more sharing across questions within adebate, or more differentiation among the topic distributionsfor arguments under a question, might be explored.
Wallach(2006) describes suitable techniques using hierarchical Dirich-let draws, and Eisenstein et al(2011) suggests the use of sparseshocks to log-odds at different levels.
Here we work on theassumption that Debatepedia?s questions are the most topicallycoherent level, and work with a single topic mixture at this level.wz yNd,q,s,aAd,q,s??Qd??
?tt?oi,t?ii ?etK TKT?b?i ?o ?t ?e?bi?
?SdDFigure 1: Plate diagram.
K is the number of positions,and T is number of topics.
The shaded variables are ob-served and dashed variables are marginalized.
?,?,?and all ?
are fixed hyperparameters (?3.1).tion is not always correct, though it tends tohold most of the time.?
Each term wd,q,s,a,n (n is the position indexof the term within an argument) is associatedwith one of five functional term types, denotedyd,q,s,a,n.
This variable is latent, except when ittakes the value ?entity?
(e) for terms marked asnamed entity mentions.
When it is not an en-tity, it takes one of the other four values: ?gen-eral position?
(i), ?topic-specific position?
(o),?topic?
(t), or ?background?
(b).
Thus, everyterm w is drawn from one of these 5 types ofbags, and y acts as a switching variable to se-lect the type of bag.?
For some term types (the ones where y ?
{o, t}), each term wd,q,s,a,n is associated withone of T discrete topics, as indexed byzd,q,s,a,n.Figure 1 illustrates the plate diagram for thegraphical model underlying our approach.
The gen-erative story is given in Figure 2.3.1 PriorsTypical probabilistic topic models assume a sym-metric Dirichlet prior over its term distributions or18601.
?
topics t, draw topic-term distribution ?tt ?
Dirichlet(?t) and topic-entity distribution ?et ?
Dirichlet(?e).2. ?
positions i, draw position-term distribution ?ii ?
Dirichlet(?i).3. ?
topics t, ?
positions i, draw topic-position term distribution ?oi,t ?
Dirichlet(?o).4.
Draw background term distribution ?b ?
Dirichlet(?b).5.
Draw functional term type distribution ?
?
Dirichlet(?).6.
Draw position distribution ?
?
Dirichlet(?).7.
?
debates d:a.
Draw id,1, id,2 ?
Multinomial(?
), assigning each of the two sides to a position.b.
?
questions q in d:i.
Draw topic mixture proportions ?d,q ?
Dirichlet(?).ii.
?
arguments a under question q and term positions n in a:A.
Draw topic label zd,q,s,a ?
Multinomial(?d,q).B.
Draw functional term type yd,q,s,a ?
Multinomial(?).C.
Draw term wd,q,s,a ?
Multinomial (?yd,q,s,a | id,1, id,2, zd,q,s,a).Figure 2: Generative story for our model of Debatepedia.apply empirical Bayesian techniques to estimate thehyperparameters.
Motivated by past efforts to ex-ploit prior knowledge (Zhao et al 2010; Lin andHe, 2009), we use the OpinionFinder sentiment lex-icon9 (Wilson et al 2005) to construct ?i and ?o.Specifically, terms w in the lexicon were given pa-rameters ?iw = ?ow = 0.01, and other terms weregiven ?iw = ?ow = 0.001, capturing our prior beliefthat opinion-expressing terms are likely to be usedin expressing positions.
5,451 types were given a?boost?
through this prior.Information retrieval has long exploited the ob-servation that a term?s document frequency (i.e., thenumber of documents a term occurs in) is inverselyrelated its usefulness in retrieval (Jones, 1972).
Weencode this in ?b, the prior over the backgroundterm distribution, by setting each value to the log-arithm of the term?s argument frequency.The other priors were set to be symmetric: ?e =0.01 (entity topics), ?t = 0.001 (topics), ?
=50/T = 1.25 (topic mixture coefficients), ?
= 0.01(positions), and ?
= 0.01 (functional term types).Preliminary tests showed that final topics are rela-tively insensitive to the values of the hyperparame-ters.3.2 Inference and Parameter EstimationExact inference under this model, like most latent-variable topic models, is intractable.
We apply col-lapsed Gibbs sampling, a standard approach for such9http://mpqa.cs.pitt.edu/lexicons/subj_lexicon/models (Griffiths and Steyvers, 2004).10 The no-table deviations from typical uses of collapsed Gibbssampling are: (i) we jointly sample id,1 and id,2 torespect the constraint that they differ; and (ii) wefix the priors, in some cases to be asymmetric, asdiscussed in ?3.1.
We perform Gibbs sampling for2,000 iterations over the dataset, discarding the first500 iterations for burn-in, and averaging over every10th iteration thereafter to get estimates for our termdistributions.3.3 T andKIn all experiments, we use T = 40 topics andK = 2positions.
We did not extensively explore differentvalues for T and K; preliminary exploration sug-gested that interpretability, gauged informally by theauthors, degraded for higher values of either.4 EvaluationRecall that the aim of this work is to infer a low-dimensional representation of debate text.
We esti-mated our model on the Debatepedia debates (not in-cluding hyperlinked articles), and conducted severalevaluations of the model, each considering a differ-ent aspect of the goal.
We exploit external articleshyperlinked from Debatepedia described in ?2 assupporting texts for arguments, treating each one?sassociation to an argument as variable to be pre-dicted.
Firstly, we evaluate our model on the articleassociating task.
Secondly, we evaluate our modelon the position prediction task.
Then, we compare10Because this technique is well known in NLP, details arerelegated to supplementary material.186102004006008001000120014000.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  0.9  1NoofArticlesJS DivergenceLDAJSTOur ModelFigure 3: The distribution over Jensen-Shannon diver-gences between a hyperlinked article and the correspond-ing Debatepedia argument, n = 3, 352.our model?s positional assignment of arguments tohuman annotated clusterings.
Finally, we presentqualitative discussion.4.1 Quantitative Evaluation4.1.1 TopicsAs described in ?2, our corpus includes 3,352 ar-ticles hyperlinked by Debatepedia arguments.11 Ourmodel can be used to infer the posterior over top-ics associated with such an article, and we comparethat distribution to that of the Debatepedia articlethat links to it.
Calculating the similarity of thesedistributions, we get an estimate of how closely ourmodel can associate text related to a debate with thespecific argument that linked to it.
We compare withLDA (Blei et al 2003), which ignores sentiment,and the joint sentiment topic (JST) model (Lin andHe, 2009), an unsupervised model that jointly cap-tures sentiment and topic.12 Using Jensen-Shannondivergence, we find that our approach embeds thesepairs significantly closer than LDA and JST (alsotrained with 40 topics), under a Wilcoxon signedrank test (p < 0.001).
Figure 3 shows the histogramof divergences between our model, JST, and LDA.Associating external articles.
More challenging,of course, is selecting the argument to which anexternal article should be associated.
We used theJensen-Shannon divergence between topic distribu-tions of articles and arguments to rank the latter,for each article.
The mean reciprocal rank scores(Voorhees, 1999) for LDA, JST, and our model were11We consider only those articles linked by a single Debate-pedia argument.12JST multiplies topics out by the set of sentiment labels, as-signing each token to both a topic and a sentment.
We use theOpinionFinder lexicon in JST?s prior in the same way it is usedin our model.0.080.10.120.140.160.185 10 15 20 25 infMRRKLDAJSTOur ModelFigure 4: Mean reciprocal ranks for the association task.0.1272, 0.1421, and 0.1507, respectively; the differ-ence is significant (Wilcoxon signed rank test, p <0.001).
We found the same pattern for MRR@k,k ?
{5, 10, 15, 20, 25,?
}, as shown in Figure 4.It is likely possible to engineer more accuratemodels for attaching articles to arguments, but theattachment task is our aim only insofar as it con-tributes to an overall assessment of an inferred rep-resentation?s quality.4.1.2 PositionsPositional distance by topic.
We next considerthe JS divergences of position term distributions bytopic; for each topic t, we consider the divergencebetween inferred values for ?o1,t and ?o2,t.
Figure 5shows these measurements sorted from most to leastdifferent; these might be taken as evidence for whichissue areas?
arguments are more lexically distin-guishable by side, perhaps indicating less commonground in discourse or (more speculatively) greatercontroversy.
For example, our model suggests thatdebates relating to topics like presidential politics,foreign policy, teachers, women?s health, religion,and Israel/Palestine are more heated (within the De-batepedia community at the time the debates tookplace) than those about the minimum wage, Iran asa nuclear threat, or immigration.Predicting positions for arguments.
We testedour model?s ability to infer the positions of argu-ments.
In this experiment (only), we held out 3,000arguments during parameter estimation.
The held-out arguments were selected so that every debateside maintained at least one argument whose in-ferred side could serve as the correct answer for theheld-out argument.
We then inferred i for each held-out argument from debate d and side s, given theparameters, and compared it with the value of id,sinferred during parameter estimation.
The modelachieved 86% accuracy (Table 3 shows the confu-1862sion matrix).
Note that JST does not provide a base-line for comparison, since it does not capture debatesides.i = 1 i = 2i?
= 1 1,272 216i?
= 2 199 1,313Table 3: Confusion matrix for position prediction onheld-out arguments.Predicting positions for external articles.
Wecan also use the model to predict the positionadopted in an external text.
For articles linked fromwithin Debatepedia, we have a gold standard: fromwhich side of a debate was it linked?
After usingthe model to infer a position variable for such a text,we can check whether the inferred position variablematches that of the argument that links to it.
Table 4shows that our model does not successfully com-plete this task, assigning about 60% of both kindsof articles i = 1.i = 1 i = 2i?
= 1 1,042 623i?
= 2 1,043 644Table 4: Confusion matrix for position prediction on hy-perlinked articles.Genre.
We manually labeled 500 of these articlesinto six genre categories.
We had two annotators forthis task (Cohen?s ?
= 0.856).
These categories,in increasing order of average Jensen-Shannon di-vergence, are: blogs, editorials, wiki pages, news,other, and government.
Figure 6 shows the results.While the only difference between the first and lastgroups are surprising by chance, we are encouragedby our model?s suggestion that blogs and editori-als may be more ?Debatepedia argument-like?
thannews and government articles.Note that our model is learned only from textwithin Debatepedia; it does not observe the text ofexternal linked articles.
Future work might incorpo-rate this text as additional evidence in order to cap-ture effects on language stemming from the interac-tion of position and genre.0.1 0.2 0.3 0.4 0.5comment, minimum, wage, poverty, capitalismnuclear, weapons, iran, states, threatparty, vote, republican, political, votersenergy, gas, power, fuel, windtax, economic, trade, cost, percentimmigration, cameras, police, immigrants, crimepeople, dont, time, lot, makefood, consumers, products, calorie, informationdeath, crime, punishment, penalty, justicemarijuana, drug, drugs, alcohol, agemarriage, gay, mars, space, moonrights, law, people, individual, amendmentsouth, kosovo, independence, state, republichuman, rights, animals, life, animalchildren, child, sex, parents, sexualschool, schools, students, education, publicchina, tibet, chinese, people, tibetanglobal, emissions, climate, carbon, warminginternational, court, war, crimes, iccenglish, language, violence, people, videoorleans, euthanasia, city, suicide, priestsspeech, corporations, corporate, public, moneyhealth, care, insurance, public, privatecircumcision, men, sexual, circumcised, foreskininformation, torture, science, evidence, wikipediacompanies, market, industry, business, bailoutlaw, workers, union, rights, legalcollege, cloning, game, football, incesttimes, york, ban, june, januarycountries, eu, european, international, statesoil, water, production, ethanol, environmentalmilitary, war, iraq, forces, marcheconomy, financial, spending, economic, governmentgovernment, social, governments, state, programsisrael, gaza, hamas, israeli, palestinianwomen, religious, abortion, god, lifeteachers, pay, test, left, meritpeace, state, west, united, actionunited, states, president, administration, foreignpresident, washington, obama, american, americaFigure 5: Jensen-Shannon divergences between topic-specific positional term distributions, for each topic.
Top-ics are labeled by their most frequent terms from ?t.4.1.3 Comparison to Human Judgments ofPositionsWe compared our model?s inferred positions tohuman judgments.
For each of the 11 topics in Ta-ble 8, we selected two associated debates with morearguments than average (24.99).
The debates wereprovided to each of three human annotators,13 who13All were native English-speaking American graduate stu-dents not otherwise involved in this research.
Each is knownby the authors to have basic literacy with issues and debates in0.40.450.50.550.60.650.7blog(12) edit(14) wiki(11) news(33) other(18) gov(12)JSDivergence ScoreArticle type(% of articles)Figure 6: Position prediction on 500 hyperlinked articlesby genre.1863?Israel-Palestine?
?Same-sex marriage?
?Drugs?
?Healthcare?
?Death penalty?
?Abortion?i1pre emptive same sex hands free single payer anti death pro choiceisraeli palestinian long term performance enhancing so called non violent pro lifeopen and shut second class in depth self sustaining african american non muslimi2two state opposite sex long term government run semi automatic would belong term well intentioned high speed government approved high profile full timeself destructive day time short term high risk hate crime late terma.
Our model: topic-specific position bigrams associated with six selected topics.
?war large illegal support death powerassault possibility abuse force penalty limitdisproportionate problems high threat murder civil+peace civil disease care power careindependence rights nature universal clean suicideself-determination affirmative potential uninsured waste deathb.
JST: sentiments associated with six selected topics manually aligned to our model?s topics.Table 6: Terms associated with selected topics.
The labels and alignments between the two models?
topics wereassigned manually.
(a.)
Our model: topic-specific position bigrams which are ranked by comparing the log oddsconditioned on the position and topic: log ?oi1,t,w?
log ?oi2,t,w.
We show the top three terms for each position (b.)
JST:we show the top three terms for each sentiment (negative and positive).A1 (11) A2 (5) A3 (16)Model (2) 3.21 2.58 3.45A1 (11) 2.15 2.15A2 (5) 2.63Table 5: Variation of information scores for each pairingof annotators and model.were instructed to group the 44 sides of the debates.The instructions stated:Our goal is to see what you think about howthe different sides of different debates can belined up.
You might find it convenient tothink of these in terms of political philoso-phies, contemporary political party platforms,or something else.
Any of these is fine; wewant you to tell us the grouping you find mostreasonable.All three annotators (hereafter denoted A1, A2, andA3) used fairly involved labeling schemes; the an-notators used 37, 30, and 16 unique labels, respec-tively.14 A1 used keyword lists to label items; wecoarsened his labels manually by removing or merg-ing less common keywords (resulting in: Republi-can, Democrat, science/environment, nanny, politi-cal reform, fiscal liberal, fiscal conservative, liber-tarian, Israel, Palestine, and one unlabeled side).A2 provided a coarse annotation along with eachAmerican politics.14In a small number of cases, an annotator declined to labela side.
Each unlabeled item received its own cluster.fine-grained one (liberal, conservative, ?, and twounlabeled sides).
We used 100 samples from ourGibbs sampler to estimate posteriors for each id,s;these were always 99% or more in agreement, so wemapped each debate side into its single most proba-ble cluster.
Recall that the two sides of each debatemust be in different clusters.Table 5 shows the variation of information mea-sure (Meila, 2003) for each pairing among the threeannotators and our model.
The model agrees withA2?s coarse clustering most closely, and in fact iscloser to A2?s clustering than A2 is to A3?s; it alsoagrees with A2?s coarse clustering better than A2?scoarse and fine clusterings agree (3.36, not shownin the table).
This is promising, but we do nothave confidence that the positional dimension is be-ing captured especially well in this model; for thosedebate-sides labeled liberal or conservative by A2,the best match of our two positions was still only inagreement only about 60% of the time, and agree-ment with each human annotator is within the inter-val of what would be expected if each debate?s sideswere assigned uniformly at random to positions.15Remarks.
Within debates and within topics, themodel uses the position variable to distinguish sideswell.
For external text, the model performs wellon articles such as blogs and editorials but on oth-ers the positional categories do not seem meaning-15This was determined using a Monte Carlo simulation with1,000 samples.1864Topic i = 1 i = 2None (?i) vice president, c sections, twenty four, cross pressures,pre dates, anti ballistic, cost effectiveness, anti land-mine, court appointed, child povertycross examination, under runs, hand outs, half million,non christians, break down, counter argument, seventyfive, co workers, run up?Israel-Palestine?pre emptive, israeli palestinian, open and shut, firsttime, hamas controlled, democratically electedtwo state, long term, self destructive, secretary general,right wing, all out, near daily, short term?Same-sexmarriage?same sex, long term, second class, blankenhorn rauch,wrong headed, self denial, left handedopposite sex, well intentioned, day time, planet wide,day night, child rearing, low earth, one way, one third?Drugs?
hands free, performance enhancing, in depth, handheld, best kept, non pharmaceutical, anti marijuanalong term, high speed, short term, peer reviewed, alco-hol related, mind altering, inner city, long lasting?Healthcare?
single payer, so called, self sustaining, public private,for profit, long run, high cost, multi payergovernment run, government approved, high risk, twotier, government appointed, low cost, set up?Deathpenalty?anti death, non violent, african american, self help, cutand cover, heavy handed, dp equivalentsemi automatic, high profile, hate crime, assaultweapons, military style, high dollar, self protective?Abortion?
pro choice, pro life, non muslim, well educated, antiabortion, much needed, church state, birth controlwould be, full time, late term, judeo christian, lifestyle, day to day, non christian, child bearingTable 7: General position (first row) and topic-specific position bigrams associated with six selected topics.Topic Terms Person entity mentions?Israel-Palestine?israel, gaza, hamas, israeli, pales-tinianBenjamin Netanyahu, Al Jazeera, Mavi Marmara, Nicholas Kristoff,Steven R. David?Same-sexmarriage?marriage, gay, mars, space, moon Buzz Aldrin, Andrew Sullivan, Moon Base, Scott Bidstrup, Ted Olson?Drugs?
marijuana, drug, drugs, alcohol, age Four Loko, Evo Morales, Toni Meyer, Sean Flynn, Robert Hahn?Healthcare?
health, care, insurance, public, pri-vateKent Conrad, Paul Hsieh, Paul Krugman, Ezra Klein, Jacob Hacker?Deathpenalty?death, crime, punishment, penalty,justiceAdam Bedau, Thomas R. Eddlem, Jeff Jacoby, John Baer, Peter Bronson?Abortion?
women, religious, abortion, god, life Ronald Reagan, John Paul II, Sara Malkani, Mother Teresa, MarcellaAlsanTable 8: For 6 selected topics (labels assigned manually), top terms (?t) and person entities (?e).
Bigrams wereincluded but did not rank in the top five for these topics.
The model has conflated debates relating to same-sexmarriage with the space program.ful, perhaps due to the less argumentative natureof other kinds of articles.
Noting the vast litera-ture focusing on ideological positions expressed intext, we believe this failure suggests (i) that broad-based positions that hold across many topics mayrequire richer textual representations (see, e.g., the?syntactic priming?
of Greene and Resnik, 2009),or (ii) that an alternative representation of positions,such as the spatial models favored by political sci-entists (Poole and Rosenthal, 1991), may be morediscoverable.
Aside from those issues, a strongertheory of positions may be required.
Such a the-ory could be encoded in a more informative prior orweaker independence assumptions across debates.Finally, exploiting explicitly ideological texts along-side the moderated arguments of Debatepedia mightalso help to identify textual associations with gen-eral positions (Sim et al 2013).
We leave these di-rections to future work.4.2 Qualitative AnalysisOf the T = 40 topics our model inferred, we subjec-tively judged 37 to be coherent; a glimpse of each isgiven in Figure 5.
We manually selected six of themost interpretable topics for further evaluation.As a generative modeling approach, our modelwas designed for the purpose of reducing the dimen-sionality of the sociopolitical debate space, as evi-denced by Debatepedia.
It is like other topic modelsin this regard, but we believe that some effects of ourdesign choices are noteworthy.
Table 6 compares thepositional bigrams of our model to the sentiments in-ferred by JST.
We observe the benefit of our modelin identifying terms associated with positions on so-cial issues, while JST selects more general sentimentterms.1865Table 7 shows bigrams most strongly associatedwith general position distributions ?i and selectedtopic-position distributions ?o.16 We see the poten-tial benefit of multiword expressions.
Although wehave used frequent bigrams as a poor man?s approx-imation to multiword expression analysis, we findthe topic-specific positions terms to be subjectivelyevocative.
While somewhat internally coherent, wedo not observe consistent alignment across topics,and the general distributions ?i are not suggestive.The separation of personal name mentions intotheir own distributions, shown for some topics inTable 8, gives a distinctive characterization of top-ics based on relevant personalities.
Subjectively, thetop individuals are relevant to the subject matter as-sociated with each topic (though the topics are notalways pure; same-sex marriage and the space pro-gram are merged, for example).5 Related WorkInsofar as debates are subjective, our study is relatedto opinion mining.
Subjective text classification(Wiebe and Riloff, 2005) leads to opinion miningtasks such as opinion extraction (Dave et al 2003),positive and negative polarity classification (Pang etal., 2002), sentiment target detection (Hu and Liu,2004; Ganapathibhotla and Liu, 2008), and feature-opinion extraction (Wu et al 2009).
The abovestudies are conducted mostly on product reviews, adomain with a simpler opinion landscape and moreconcrete rationales for those opinions, compared tosociopolitical debates.Generative topic models have been successfullyimplemented in opinion mining tasks such as featureidentification (Titov and McDonald, 2008), entity-topic extraction (Newman et al 2006), mining con-tentious expressions and interactions (Mukherjeeand Liu, 2012) and specific aspect-opinion word ex-traction from labeled data (Zhao et al 2010).
Mostrelevant to this research is work on feature-sentimentextraction (Lin and He, 2009; Mei et al 2007).
Meiet al(2007) built on PLSI, which is problematicfor generalizing beyond the training sample.
TheJST model of Lin and He (2009) is an LDA-basedtopic model in which each word token is assignedboth a sentiment and a topic; they exploited a sen-16For more topics, please refer to the supplementary notes.timent lexicon in the prior distribution.
Our modelis closely related, but introduces a switching vari-able that assigns some tokens to positions, some totopics, and some to both.
Unlike Lin and He?s senti-ments, our model?s positions are associated with thetwo sides of a debate, and we incorporate topics atthe level of questions within debates.Some studies have specifically analyzed con-trastive viewpoints or stances in general discussiontext.Agrawal et al(2003) used graph mining basedmethod to classify authors in to opposite camps fora given topic.
Paul et al(2010) developed an unsu-pervised method for summarizing contrastive opin-ions from customer reviews.
Abu-Jbara et al(2012)and Dasigi et al(2012) developed techniques to ad-dress the problem of automatically detecting sub-groups of people holding similar stances in a dis-cussion thread.Several prior studies have considered debates.Cabrio and Villata (2012) developed a system basedon argumentation theory which recognizes the en-tailment and contradiction relationships betweentwo texts.
Awadallah et al(2011) used a debatecorpus as a seed for extracting person-opinion-topictuples from news and other web documents and inlater work classified the quotations to specific top-ics and polarity using language models (Awadal-lah et al 2012).
Somasundaran and Wiebe (2009)and Anand et al(2011) were interested in ideolog-ical content in debates, relying on discourse struc-ture and leveraging sentiment lexicons to recognizestances.Closer to the methodology we describe, Lin etal.
(2008) presented a statistical model for politi-cal discourse that incorporates both topics and ide-ologies; they used debates on the Israeli-Palestinianconflict.
Fortuna et al(2009) showed that it is pos-sible to isolate a subset of terms from media contentthat are informative of a news organization?s bias to-wards a particular issue.
Ahmed and Xing (2010) in-troduced multi-level latent Dirichlet alcation, andEisenstein et al(2011) introduced sparse additivegenerative models, both conceived as extensions towell-established probabilistic modeling techniques(Blei et al 2003); these were applied to debatesand political blog datasets.
Our approach builds onthese models (especially the switching variables ofAhmed and Xing).
We go farther in jointly modeling1866text across many debates evidenced by the structureof Debatepedia, thus grounding our models moresolidly in familiar sociopolitical issues, and in mak-ing extensive use of existing NLP resources.6 ConclusionUsing text from Debatepedia, we inferred topics andposition term lexicons in the domain of sociopoliti-cal debates.
Our approach brings together tools frominformation extraction and sentiment analysis into alatent-variable topic model and exploits the hierar-chical structure of the dataset.
Our qualitative andquantitative evaluations show the model?s strengthsand weaknesses.AcknowledgmentsThe authors thank several anonymous reviewers,Justin Gross, David Kaufer, and members of theARK group at CMU for helpful feedback on thiswork and gratefully acknowledge the assistance ofthe annotators.
This research is supported by theSingapore National Research Foundation under itsInternational Research Centre@Singapore FundingInitiative and administered by the IDM ProgrammeOffice, by an A?STAR fellowship to Y.S., and byGoogle?s support of the Reading is Believing projectat CMU.ReferencesAmjad Abu-Jbara, Mona Diab, Pradeep Dasigi, andDragomir Radev.
2012.
Subgroup detection in ide-ological discussions.
In Proceedings of ACL.Rakesh Agrawal, Sridhar Rajagopalan, RamakrishnanSrikant, and Yirong Xu.
2003.
Mining newsgroupsusing networks arising from social behavior.
In WWW?03.Amr Ahmed and Eric P. Xing.
2010.
Staying in-formed: supervised and semi-supervised multi-viewtopical analysis of ideological perspective.
In Pro-ceedings of EMNLP.Pranav Anand, Marilyn Walker, Rob Abbott, Jean E. FoxTree, Robeson Bowmani, and Michael Minor.
2011.Cats rule and dogs drool!
: classifying stance in onlinedebate.
In Proceedings of the Second Workshop onComputational Approaches to Subjectivity and Senti-ment Analysis.Rawia Awadallah, Maya Ramanath, and GerhardWeikum.
2011.
OpinioNetIt: Understanding theopinions-people network for politically controversialtopics.
In Proceedings of CIKM.Rawia Awadallah, Maya Ramanath, and GerhardWeikum.
2012.
PolariCQ: Polarity classification ofpolitical quotations.
In Proceedings of CIKM.David M. Blei, Andrew Y. Ng, and Michael I. Jordan.2003.
Latent Dirichlet alcation.
Journal of MachineLearning Research, 3:993?1022.Elena Cabrio and Serena Villata.
2012.
Combiningtextual entailment and argumentation theory for sup-porting online debates interactions.
In Proceedings ofACL.Sarah Cohen, James T. Hamilton, and Fred Turner.
2011.Computational journalism.
Communications of theACM, 54(10):66?71.Pradeep Dasigi, Weiwei Guo, and Mona Diab.
2012.Genre independent subgroup detection in online dis-cussion threads: a pilot study of implicit attitude usinglatent textual semantics.
In Proceedings of ACL.Kushal Dave, Steve Lawrence, and David M. Pennock.2003.
Mining the peanut gallery: opinion extractionand semantic classification of product reviews.
In Pro-ceedings of WWW.Jacob Eisenstein, Amr Ahmed, and Eric P Xing.
2011.Sparse additive generative models of text.
In Proceed-ings of ICML.Jenny Rose Finkel, Trond Grenager, and ChristopherManning.
2005.
Incorporating non-local informationinto information extraction systems by gibbs sampling.In Proceedings of ACL.Blaz Fortuna, Carolina Galleguillos, and Nello Cristian-ini.
2009.
Detecting the bias in media with statis-tical learning methods.
In Ashok N .
Srivastava andMehran Sahami, editors, Text Mining: Classification,Clustering, and Applications, pages 27?50.
Chapman& Hall/CRC.Murthy Ganapathibhotla and Bing Liu.
2008.
Miningopinions in comparative sentences.
In Proceedings ofCOLING.Stephan Greene and Philip Resnik.
2009.
More thanwords: Syntactic packaging and implicit sentiment.
InProceedings of HLT-NAACL.Thomas L. Griffiths and Mark Steyvers.
2004.
Find-ing scientific topics.
Proceedings of the NationalAcademy of Sciences, 101(Suppl.
1):5228?5235.Minqing Hu and Bing Liu.
2004.
Mining and summariz-ing customer reviews.
In Proceedings of CIKM.Karen Sparck Jones.
1972.
A statistical interpretation ofterm specificity and its application in retrieval.
Jour-nal of documentation, 28(1):11?21.Christian Kohlschu?tter, Peter Fankhauser, and WolfgangNejdl.
2010.
Boilerplate detection using shallow textfeatures.
In Proceedings of WSDM.1867Chenghua Lin and Yulan He.
2009.
Joint sentiment/topicmodel for sentiment analysis.
In Proceedings ofCIKM.Wei-Hao Lin, Eric Xing, and Alexander Hauptmann.2008.
A joint topic and perspective model for ideo-logical discourse.
In Proceedings of ECML-PKDD.Qiaozhu Mei, Xu Ling, Matthew Wondra, Hang Su, andChengXiang Zhai.
2007.
Topic sentiment mixture:modeling facets and opinions in weblogs.
In Proceed-ings of WWW.Marina Meila.
2003.
Comparing clusterings by the vari-ation of information.
In Bernhard Scho?lkopf and Man-fred K. Warmuth, editors, Learning Theory and KernelMachines, volume 2777 of Lecture Notes in ComputerScience, pages 173?187.
Springer.Arjun Mukherjee and Bing Liu.
2012.
Mining con-tentions from discussions and debates.
In Proceedingsof KDD.David Newman, Chaitanya Chemudugunta, and PadhraicSmyth.
2006.
Statistical entity-topic models.
In Pro-ceedings of KDD.Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.2002.
Thumbs up?
: sentiment classification using ma-chine learning techniques.
In Proceedings of EMNLP.Michael J. Paul, ChengXiang Zhai, and Roxana Girju.2010.
Summarizing contrastive viewpoints in opin-ionated text.
In Proceedings of EMNLP.Keith Poole and Howard Rosenthal.
1991.
Patterns ofcongressional voting.
American Journal of PoliticalScience, pages 118?178.Yanchuan Sim, Brice Acree, Justin H. Gross, andNoah A. Smith.
2013.
Measuring ideological propor-tions in political speeches.
In Proceedings of EMNLP.Swapna Somasundaran and Janyce Wiebe.
2009.
Rec-ognizing stances in online debates.
In Proceedings ofACL.Ivan Titov and Ryan McDonald.
2008.
Modeling onlinereviews with multi-grain topic models.
In Proceedingsof WWW.Teun A.
Van Dijk.
1998.
Ideology: A MultidisciplinaryApproach.
Sage Publications Limited.Ellen M. Voorhees.
1999.
The trec-8 question answeringtrack report.
In Proceedings of TREC.Hanna M. Wallach.
2006.
Topic modeling: beyond bag-of-words.
In Proceedings of ICML.Janyce Wiebe and Ellen Riloff.
2005.
Creating sub-jective and objective sentence classifiers from unan-notated texts.
In Proceedings of CICLing.Theresa Wilson, Paul Hoffmann, Swapna Somasun-daran, Jason Kessler, Janyce Wiebe, Yejin Choi, ClaireCardie, Ellen Riloff, and Siddharth Patwardhan.
2005.Opinionfinder: a system for subjectivity analysis.
InProceedings of HLT-EMNLP.Yuanbin Wu, Qi Zhang, Xuanjing Huang, and Lide Wu.2009.
Phrase dependency parsing for opinion mining.In Proceedings of EMNLP.Wayne Xin Zhao, Jing Jiang, Hongfei Yan, and XiaomingLi.
2010.
Jointly modeling aspects and opinions witha maxent-lda hybrid.
In Proceedings of EMNLP.1868
