Workshop on TextGraphs, at HLT-NAACL 2006, pages 9?16,New York City, June 2006. c?2006 Association for Computational LinguisticsGraph Based Semi-Supervised Approach for Information ExtractionHany Hassan Ahmed Hassan Sara NoemanIBM Cairo Technology Development CenterGiza, EgyptP.O.
Box 166 Al-Ahramhanyh@eg.ibm.com hasanah@eg.ibm.com noemans@eg.ibm.comAbstractClassification techniques deploy supervisedlabeled instances to train classifiers forvarious classification problems.
Howeverlabeled instances are limited, expensive,and time consuming to obtain, due to theneed of experienced human annotators.Meanwhile large amount of unlabeled datais usually easy to obtain.
Semi-supervisedlearning addresses the problem of utilizingunlabeled data along with supervised la-beled data, to build better classifiers.
Inthis paper we introduce a semi-supervisedapproach based on mutual reinforcement ingraphs to obtain more labeled data to en-hance the classifier accuracy.
The approachhas been used to supplement a maximumentropy model for semi-supervised trainingof the ACE Relation Detection and Charac-terization (RDC) task.
ACE RDC is con-sidered a hard task in informationextraction due to lack of large amounts oftraining data and inconsistencies in theavailable data.
The proposed approach pro-vides 10% relative improvement over thestate of the art supervised baseline system.1 IntroductionClassification techniques use labeled data to trainclassifiers for various classification problems.
Yetthey often face a shortage of labeled training data.Labeled instances are often difficult, expensive,and /or time consuming to obtain.
Meanwhile largenumbers of unlabeled instances are often available.Semi-supervised learning addresses the problem ofhow unlabeled data can be usefully employed,along with labeled data, to build better classifiers.In this paper we propose a semi-supervised ap-proach for acquiring more training instances simi-lar to some labeled instances.
The approachdepends on constructing generalized extractionpatterns, which could match many instances, anddeploying graph based mutual reinforcement toweight the importance of these patterns.
The mu-tual reinforcement is used to automatically identifythe most informative patterns; where patterns thatmatch many instances tend to be correct.
Similarly,instances matched by many patterns also tend to becorrect.
The labeled instances should have moreeffect in the mutual reinforcement weighting proc-ess.
The problem can therefore be seen as hubs(instances) and authorities (patterns) problemwhich can be solved using the Hypertext InducedTopic Selection (HITS) algorithm (Kleinberg,1998 ).HITS is an algorithmic formulation of the notionof authority in web pages link analysis, based on arelationship between a set of relevant ?authorita-tive pages?
and a set of ?hub pages?.
The HITSalgorithm benefits from the following observation:when a page (hub) links to another page (author-ity), the former confers authority over the latter.By analogy to the authoritative web pages prob-lem, we could represent the patterns as authoritiesand instances as hubs, and use mutual reinforce-ment between patterns and instances to weight themost authoritative patterns.
Instances from unsu-9pervised data matched with the highly weightedpatterns are then used in retraining the system.The paper proceeds as follows: in Section 2 wediscuss previous work followed by a brief defini-tion of our general notation in Section 3.
A detaileddescription of the proposed approach then followsin Section 4.
Section 5 discusses the application ofthe proposed approach to the problem of detectingsemantic relations from text.
Section 6 discussesexperimental results while the conclusion is pre-sented in Section 7.2 Previous Work(Blum and Mitchell, 1998) proposed an approachbased on co-training that uses unlabeled data in aparticular setting.
They exploit the fact that, forsome problems, each example can be described bymultiple representations.
They develop a boostingscheme which exploits conditional independencebetween these representations.
(Blum and Chawla, 2001) proposed  a generalapproach utilizing unlabeled data by constructing agraph on all the data points based on distance rela-tionships among examples, and then to use theknown labels to perform a graph partitioning usingthe minimum cut that agrees with the labeled data.
(Zhu et al, 2003) extended this approach by pro-posing a  cut based on the assumption that labelsare generated according to a Markov RandomField on the graph , (Joachims, 2003) presented  analgorithm based on spectral graph partitioning.
(Blum et al, 2004) extended the min-cut  approachby adding randomness to the graph structure, theiralgorithm addresses several shortcomings of thebasic mincut approach, yet it may not help in caseswhere the graph does not have small cuts for agiven classification problem.3 BackgroundIn graph theory, a graph is a set of objects calledvertices joined by links called edges.
A bipartitegraph, also called a bigraph, is a special graphwhere the set of vertices can be divided into twodisjoint sets with no two vertices of the same setsharing an edge.The Hypertext Induced Topic Selection (HITS)algorithm is an algorithm for rating, and thereforeranking, web pages.
The HITS algorithm makesuse of the following observation: when a page(hub) links to another page (authority), the formerconfers authority over the latter.
HITS uses twovalues for each page, the "authority value" and the"hub value".
"Authority value" and "hub value" aredefined in terms of one another in a mutual recur-sion.
An authority value is computed as the sum ofthe scaled hub values that point to that authority.
Ahub value is the sum of the scaled authority valuesof the authorities it points to.A template, as we define for this work, is a se-quence of generic forms that could generalize overthe given training instance.
An example templateis:COUNTRY  NOUN_PHRASE PERSONVERB_PHRASEThis template could represent the sentence:?American vice President Al Gore visited ...?.This template is derived from the representation ofthe Named Entity tags, Part-of-Speech (POS) tagsand semantic tags.
The choice of the template rep-resentation here is for illustration purpose only;any combination of tags, representations and tag-ging styles might be used.A pattern is more specific than a template.
Apattern specifies the role played by the tags (firstentity, second entity, or relation).
An example of apattern is:COUNTRY(E2) NOUN_PHRASE(R) PERSON(E1)VERB_PHRASEThis pattern indicates that the word(s) with thetag COUNTRY in the sentence represents the sec-ond entity (Entity 2) in the relation, while theword(s) tagged PERSON represents the first entity(Entity 1) in this relation.
Finally, the word(s) withthe tag NOUN_PHRASE represents the relationbetween the two previous entities.A tuple, in our notation during this paper, is theresult of the application of a pattern to unstructuredtext.
In the above example, one result of applyingthe pattern to some raw text is the following tuple:Entity 1:  Al GoreEntity 2: United StatesRelation: vice President4 The ApproachThe semi-supervised graph-based approach wepropose depends on the construction of generalizedextraction patterns that could match many traininginstances.
The patterns are then weighted accord-ing to their importance by deploying graph based10mutual reinforcement techniques.
Patterns derivedfrom the supervised training instances should havea superior effect in the reinforcement weightingprocess.
This duality in patterns and tuples relationcould be stated that patterns could match differenttuples, and tuples in turn could be matched by dif-ferent patterns.
The proposed approach is com-posed of two main steps namely, pattern extractionand pattern weighting or induction.
Both steps aredetailed in the next subsections.4.1 Patterns ExtractionAs shown in Figure 1, several syntactic, lexical,and semantic analyzers could be applied to thetraining instances.
The resulting analyses could beemployed in the construction of extraction pat-terns.
Any extraction pattern could match differentrelations and hence could produce several tuples.As an example let?s consider the pattern depictedin figure 1:Figure 1:  An example of a pattern and its possibletuples.PEOPLE_Inhabitant(E2) NOUN_PHRASE(R)PERSON(E1) VERB_PHRASEThis pattern could extract the tuple:Entity 1: Al GoreEntity 2: AmericanRelation: vice PresidentAnother tuple that could be extracted by the samepattern is:Entity 1: BerlusconiEntity 2: ItalianRelation: Prime MinisterOn the other hand, many other patterns could ex-tract the same information in the tuple from differ-ent contexts.
It is worth mentioning that theproposed approach is general enough to accommo-date any pattern design; the introduced pattern de-sign is for illustration purposes only.To further increase the number of patterns thatcould match a single tuple, the tuple space mightbe reduced i.e.
by grouping tuples conveying thesame information content together into a singletuple.
This will be detailed further in the experi-mental setup section.4.2   Pattern InductionThe inherent duality in the patterns and tuples rela-tion suggests that the problem could be interpretedas a hub authority problem.
This problem could besolved by applying the HITS algorithm to itera-tively assign authority and hub scores to patternsand tuples respectively.Figure 2: A bipartite graph representing patternsand tuplesPatterns and tuples are represented by a bipartitegraph as illustrated in figure 2.
Each pattern or tu-ple is represented by a node in the graph.
Edgesrepresent matching between patterns and tuples.The pattern induction problem can be formu-lated as follows: Given a very large set of data Dcontaining a large set of patterns P which match aPPPPPTTTTTPPTTPatterns TuplesAmerican vice President   Al Gore said today...Word: AmericanEntity: PEOPLEPOS : ADJSem: InhabitantWord: vice presidentEntity:POS: NOUN_PHRASESem:Word: Al GoreEntity: PERSONPOS:Sem:PEOPLE_Inhabitant    NOUN_PHRASE        PERSONVERB_PHRASEEntity 1:  Al GoreEntity 2: AmericanRelation: vice PresidentAmerican vice Presi-dent   Al Gore saidtoday?Italian Prime MinisterBerlusconi  visited?..Entity 1: BerlusconiEntity 2: ItalianRelation: prime minister11large set of tuples T, the problem is to identify P~,the set of patterns that match the set of the mostcorrect tuplesT~.
The intuition is that the tuplesmatched by many different patterns tend to be cor-rect and the patterns matching many different tu-ples tend to be good patterns.
In other words; wewant to choose, among the large space of patternsin the data, the most informative, highest confi-dence patterns that could identify correct tuples;i.e.
choosing the most ?authoritative?
patterns inanalogy with the hub authority problem.
However,both P~andT~are unknown.
The induction processproceeds as follows:  each pattern p in P is associ-ated with a numerical authority weight av whichexpresses how many tuples match that pattern.Similarly, each tuple t in T has a numerical hubweight ht which expresses how many patterns werematched by this tuple.
The weights are calculatediteratively as follows:( ) ( )( )=+=pTu iiiHuhpa1 )()()1((1)( ) ( )( )=+=tPu iiiAuath1 )()()1((2)where T(p) is the set of tuples matched by p, P(t) isthe set of patterns matching t, ( )pa i )1( +  is the au-thoritative weight of pattern p  at iteration  )1( +i ,and ( )th i )1( +  is the hub weight of tuple t  at itera-tion  )1( +i  .
H(i) and A(i) are normalization fac-tors defined as:( )( ) = ==||1 1)()( PppTuii uhH  (3)( )( ) = ==||1 1)()( TvtPuii uaA(4)Patterns with weights lower than a predefinedthreshold are rejected, and examples associatedwith highly ranked patterns are then used in unsu-pervised training.It is worth mentioning that both T and P containsupervised and unsupervised examples, howeverthe proposed method could assign weights to thecorrect examples (tuples and patterns) in a com-pletely unsupervised setup.
For semi-superviseddata some supervised examples are provided,which are associated in turn with tuples and pat-terns.We adopt the HITS extension introduced in(White and Smyth, 2003) to extend HITS with Pri-ors.
By analogy, we handle the supervised exam-ples as priors to the HITS induction algorithm.A prior probabilities vector pr ={pr1, .
.
.
, prn}is defined such that the probabilities sum to 1,where prv denotes the relative importance (or?prior bias?)
we attach to node v. A pattern Pi isassigned a prior pri=1/n if pattern Pi matches asupervised tuple, otherwise pri is set to zero, n isthe total number of patterns that have a supervisedmatch.
We also define a ?back probability? , 0    1 which determines how often we bias the su-pervised nodes:( ) ( ) ( )( ) ppTu iii prHuhpa *11 )()()1( ??
+?= =+(5)( ) ( ) ( )( ) ttPu iii prAuath *11 )()()1( ??
+?= =+(6)where T(p) is the set of tuples matched by p , P(t)is the set of patterns matching t, and H(i) and A(i)are normalization factors defined as in  equations(3) and (4)Thus each node in the graph (pattern or tuple) hasan associated prior weight depending on its super-vised data.
The induction process proceeds to itera-tively assign weights to the patterns and tuples.
Inthe current work we used 5.0=?
.5 Experimental Setup5.1 ACE Relation Detection and Characteri-zationIn this section, we describe Automatic ContentExtraction (ACE).
ACE is an evaluation conductedby NIST to measure Entity Detection and Tracking(EDT) and Relation Detection and Characteriza-tion (RDC).
The EDT task is concerned with thedetection of mentions of entities, and groupingthem together by identifying their coreference.
TheRDC task detects relations between entities identi-fied by the EDT task.
We choose the RDC task toshow the performance of the graph based semi-supervised information extraction approach wepropose.
To this end we need to introduce the no-tion of mentions and entities.
Mentions are anyinstances of textual references to objects like peo-12ple, organizations, geo-political entities (countries,cities ?etc), locations, or facilities.
On the otherhand, entities are objects containing all mentions tothe same object.Type Subtype Number of InstancesUser-OwnerInventor ARTOther331DISC DISC 143Employ-ExecEmploy-StaffEmploy-UndeterminedMember-of-GroupSubsidiaryEMP-ORGOther1673EthnicIdeology Other-AFFOther153Citizen-ResidentBased-in GPE-AFFOther695BusinessFamily PER-SOCOther358LocatedNear PHYSPart-Whole1411Table 1.
Types and subtypes of ACE relationsTable 1 lists the types and subtypes of relationsfor the ACE RDC task.
Here, we present an exam-ple for those relations:Spain?s Interior Minister an-nounced this evening the ar-rest of separatistorganization Eta?s presumedleader Ignacio Garcia Ar-regui.
Arregui, who is con-sidered to be the Etaorganization?s top man, wasarrested at 17h45 Greenwich.The Spanish judiciary sus-pects Arregui of ordering afailed attack on King JuanCarlos in 1995.In this fragment, all the underlined phrases arementions to Eta organization, or to ?Garcia Ar-regui?.
There is a management relation betweenleader which references to ?Garcia Arregui?
andEta.5.2 Baseline SystemThe base line system uses a Maximum Entropymodel that combines diverse lexical, syntactic andsemantic features derived from text, like the sys-tem described in (Nanda, 2004).
The system wastrained on the ACE training data provided by LDC.The training set contained 145K words, and 4764instances of relations, the number of instances cor-responding to each relation is shown in Table 1.The test set contained around 41K words, and1097 instances of relations.
The system was evalu-ated using standard ACE evaluation procedure.ACE evaluation procedure assigns the system anACE value for each relation type and a total ACEvalue.
The ACE value is a standard NIST metricfor evaluating relation extraction.
The reader isreferred to the ACE web site (ACE, 2004) for moredetails.5.3 Pattern ConstructionWe used the baseline system described in the pre-vious section to label a large amount of unsuper-vised data.
The data comes from LDC EnglishGigaword corpus, Agence France Press EnglishService (AFE).
The data contains around 3Mwords, from which 80K instances of relations havebeen extracted.We start by extracting a set of patterns that rep-resent the supervised and unsupervised data.
Weconsider each relation type separately and extract apattern for each instance in the selected relation.The pattern we used consists of a mix between thepart of speech (POS) tags and the mention tags forthe words in the training instance.
We use the men-tion tag, if it exists; otherwise we use the part ofspeech tag.
An example of a pattern is:Text: Eta?s presumed leaderArregui ?Pos: NNP POS JJ NN NNPMention: ORG 0 0 0 PERSONPattern: ORG(E2) POS JJ NN(R)PERSON(E1)135.4 Tuples ClusteringAs discussed in the previous section, the tuplespace should be reduced to allow more matchingbetween pattern-tuple pairs.
This space reductioncould be accomplished by seeking a tuple similar-ity measure, and constructing a weighted undi-rected graph of tuples.
Two tuples are linked withan edge if their similarity measure exceeds a cer-tain threshold.
Graph clustering algorithms couldbe deployed to partition the graph into a set of ho-mogeneous communities or clusters.
To reduce thespace of tuples, we seek a matching criterion thatgroup similar tuples together.
Using WordNet, wecan measure the semantic similarity or relatednessbetween a pair of concepts (or word senses), andby extension, between a pair of sentences.
We usethe similarity measure described in (Wu andPalmer, 1994) which finds the path length to theroot  node from the least common subsumer (LCS)of the two word senses which is the most specificword sense they share as an ancestor.
The similar-ity score of two tuples, ST, is calculated as follows:.2221 EET SSS +=   (9)where SE1, and SE2 are the similarity scores of thefirst entities in the two tuples, and their second en-titles respectively.The tuple matching procedure assigns a similaritymeasure to each pair of tuples in the dataset.
Usingthis measure we can construct an undirected graphG.
The vertices of G are the tuples.
Two verticesare connected with an edge if the similarity meas-ure between their underlying tuples exceeds a cer-tain threshold.
It was noticed that the constructedgraph consists of a set of semi isolated groups asshown in figure 3.
Those groups have a very largenumber of inter-group edges and meanwhile arather small number of intra-group edges.
This im-plies that using a graph clustering algorithm wouldeliminate those weak intra-group edges and pro-duce separate groups or clusters representing simi-lar tuples.
We used Markov Cluster Algorithm(MCL) for graph clustering (Dongen, 2000).
MCLis a fast and scalable unsupervised cluster algo-rithm for graphs based on simulation of stochasticflow.A bipartite graph of patterns and tuple clusters isconstructed.
Weights are assigned to patterns andtuple clusters by iteratively applying the HITS withPriors?
algorithm.
Instances associated with highlyranked patterns are then added to the training dataand the model is retrained.
Samples of some highlyranked patterns and corresponding matching textare introduced in Table 2.Figure 3: Applying Clustering Algorithms to TuplegraphPattern MatchesGPE PERSONPERSON PERSONZimbabwean PresidentRobert MugabeGPE POS PERSONPERSONZimbabwe 's PresidentRobert MugabeGPE JJ PERSON American diplomatic per-sonnelPERSON IN JJ GPE candidates for local gov-ernmentORGANIZATIONPERSON Airways spokesmanORGANIZATIONPERSON      Ajax playersPERSON IN DT JJORGANIZATIONchairman of the oppositionpartiesORGANIZATIONPERSON    parties chairmansTable 2: Examples of patterns with high weights6 Results and DiscussionWe train several models like the one described insection 5.2 on different training data sets.
In allexperiments, we use both the LDC ACE trainingdata and the labeled unsupervised data inducedwith the graph based approach we propose.
We usethe ACE evaluation procedure and ACE test cor-pus, provided by LDC, to evaluate all models.We incrementally added labeled unsuperviseddata to the training data to determine the amount ofdata after which degradation in the system per-formance occurs.
We sought this degradation pointseparately for each relation type.
Figure 4 showsthe effect of adding labeled unsupervised data onTT TTTTTTTTTTT TTT TTTTTTTTTTT TBefore Clustering After Clustering14the ACE value for each relation separately.
Wenotice from figure 4 and table 1 that relations witha small number of training instances had a highergain in performance compared to relations with alarge number of training instances.
This impliesthat the proposed approach achieves significantimprovement when the number of labeled traininginstances is small but representative..01020304050600 50 100 200 300 400 500Number of Added DocumentsACEValueEMP-ORGPER-SOCARTPHYSGPE-AFFOTHER-AFFFigure 4: The effect of adding labeled unsuper-vised data on the ACE value for each relation.
Theaverage number of relations per document is 4.From figure 4, we determined the number oftraining instances resulting in the maximum boostin performance for each relation.
We added thetraining instances corresponding to the maximumboost in performance for all relations to the super-vised training data and trained a new model onthem.
Figure 5 compares the ACE values for eachrelation in the base line model and the final modelThe total system ACE value has been improvedby 10% over the supervised baseline system.
Allrelation types, except the DSC relation, had sig-nificant improvement ranging from 7% to 30%over the baseline supervised system.
The DISCrelation type had a small degradation; noting that italready has a low ACE value with the baseline sys-tem.
We think this is due to the fact that the DISCrelation has few and inconsistent examples in thesupervised data set.To assess the usefulness of the smoothingmethod employing WordNet distance, we repeatedthe experiment on EMP-ORG relation without it.We found out that it contributed to almost 30% ofthe total achieved improvement.
We also repeatedthe experiment but with considering hub scoresinstead of authority scores.
We added the examplesassociated with highly ranked tuples to the trainingset.
We noticed that using hub scores yielded verylittle variation in the ACE value (i.e.
0.1 point forEMP-ORG relation).01020304050ACEValueBaseLine 36.7 6 33.1 22.3 23.6 42.2 26.4 30.5Final Model 39.6 4.2 35.8 24.7 30.8 46.6 28.2 33.5ART DISC EMP-ORGGPE-AFFOTHER-AFFPER-SOC PHYS TOTALFigure 5: A comparison of base line ACE values,and final ACE values for each relation.To evaluate the quality and representativeness ofthe labeled unsupervised data, acquired using theproposed approach, we study the effect of replac-ing supervised data with unsupervised data whileholding the amount of training data fixed.
Severalsystems have been built using mixture of the su-pervised and the unsupervised data.
In Figure 6,the dotted line shows the degradation in the systemperformance when using a reduced amount of su-pervised training data only, while the solid lineshows the effect of replacing supervised trainingdata with unsupervised labeled data on the systemperformance.
We notice from Figure 6 that the un-supervised data could replace more than 50% ofthe supervised data without any degradation in thesystem performance.
This is an indication that theinduced unsupervised data is good for training theclassifier.2627282930313233340% 25% 50% 75%100% 75% 50% 25%Percentage of Unsupervised/SupervisedDataACEValue Sup + UnsupDataSup Data OnlyUnsupervisedSupervisedFigure 6: The effect of removing portions of thesupervised data on the ACE value.
And the effect15of replacing portions of the supervised data withlabeled training data.7 ConclusionWe introduce a general framework for semi-supervised learning based on mutual reinforcementin graphs.
We construct generalized extraction pat-terns and deploy graph based mutual reinforcementto automatically identify the most informative pat-terns.
We provide motivation for our approachfrom a graph theory and graph link analysis per-spective.We present experimental results supporting theapplicability of the proposed approach to ACE Re-lation Detection and Characterization (RDC) task,demonstrating its applicability to hard informationextraction problems.
Our approach achieves a sig-nificant improvement over the base line supervisedsystem especially when the number of labeled in-stances is small.8 AcknowledgementsWe would like to thank Nanda Kambhatla for pro-viding the ACE baseline system.
We would alsolike to thank Salim Roukos for several invaluablesuggestions and guidance.
Finally we would like tothank the anonymous reviewers for their construc-tive criticism and helpful comments.ReferencesACE.
2004.
The NIST ACE evaluation website.http://www.nist.gov/speech/tests/ace/Avrim Blum, and Tom Mitchell.
1998.
Combining La-beled and Unlabeled data with Co-training.
Proceed-ings of the 11th Annual Conference onComputational Learning Theory.Avrim Blum and Shuchi Chawla.
2001.
Learning FromLabeled and Unlabeled Data Using Graph Mincuts.Proceedings of International Conference on MachineLearning (ICML).Avrim Blum, John Lafferty, Mugizi Rwebangira, andRajashekar Reddy.
2004.
Semi-supervised LearningUsing Randomized Mincuts.
Proceedings of the In-ternational Conference on Machine Learning(ICML).Stijn van Dongen.
2000.
A Cluster Algorithm forGraphs.
Technical Report INS-R0010, National Re-search Institute for Mathematics and Computer Sci-ence in the Netherlands.Stijn van Dongen.
2000.
Graph Clustering by FlowSimulation.
PhD thesis, University of UtrechtRadu Florian, Hany Hassan, Hongyan Jing, NandaKambhatla, Xiaqiang Luo, Nicolas Nicolov, andSalim Roukos.
2004.
A Statistical Model for multi-lingual entity detection and tracking.
Proceedings ofthe Human Language Technologies Conference(HLT-NAACL?04).Dayne Freitag, and Nicholas Kushmerick.
2000.Boosted wrapper induction.
The 14th European Con-ference on Artificial Intelligence Workshop on Ma-chine Learning for Information ExtractionTaher Haveliwala.
2002.
Topic-sensitive PageRank.Proceedings of the 11th International World WideWeb ConferenceThorsten Joachims.
2003.
Transductive Learning viaSpectral Graph Partitioning.
Proceedings of the In-ternational Conference on Machine Learning(ICML).John Kleinberg.
1998.
Authoritative Sources in a Hy-perlinked Environment.
Proceedings of the.
9thACM-SIAM Symposium on Discrete Algorithms.Nanda Kambhatla.
2004.
Combining Lexical, Syntactic,and Semantic Features with Maximum Entropy Mod-els for Information Extraction.
Proceedings of the42nd Annual Meeting of the Association for Compu-tational LinguisticsTed  Pedersen, Siddharth Patwardhan, and Jason Mich-elizzi, 2004, WordNet::Similarity - Measuring theRelatedness of Concepts.
Proceedings of Fifth An-nual Meeting of the North American Chapter of theAssociation for Computational Linguistics (NAACL-2004)Scott White, and Padhraic Smyth.
2003.
Algorithms forDiscoveing Relative Importance in Graphs.
Proceed-ings of Ninth ACM SIGKDD International Confer-ence on Knowledge Discovery and Data Mining.Zhibiao Wu, and Martha Palmer.
1994.
Verb semanticsand lexical selection.
Proceedings of the 32nd An-nual Meeting of the Association for ComputationalLinguistics.Xiaojin Zhu, Zoubin Ghahramani, and John Lafferty.2003.
Semi-supervised Learning using GaussianFields and Harmonic Functions.
Proceedings of the20th International Conference on Machine Learning.16
