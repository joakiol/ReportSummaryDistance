HITIQA: A Data Driven Approach to Interactive Analytical QuestionAnsweringSharon Small and Tomek StrzalkowskiThe State University of New York at Albany1400 Washington AvenueAlbany, NY 12222{small,tomek}@cs.albany.eduAbstractIn this paper we describe the analytic questionanswering system HITIQA (High-Quality In-teractive Question Answering) which has beendeveloped over the last 2 years as an advancedresearch tool for information analysts.HITIQA is an interactive open-domain ques-tion answering technology designed to allowanalysts to pose complex exploratory ques-tions in natural language and obtain relevantinformation units to prepare their briefing re-ports.
The system uses novel data-driven se-mantics to conduct a clarification dialoguewith the user that explores the scope and thecontext of the desired answer space.
The sys-tem has undergone extensive hands-on evalua-tions by a group of intelligence analysts repre-senting various foreign intelligence services.This evaluation validated the overall approachin HITIQA but also exposed limitations of thecurrent prototype.1   IntroductionOur objective in HITIQA is to allow the user to submitexploratory, analytical questions, such as ?What hasbeen Russia?s reaction to U.S. bombing of Kosovo?
?The distinguishing property of such questions is that onecannot generally anticipate what might constitute theanswer.
While certain types of things may be expected(e.g., diplomatic statements), the answer is heavily con-ditioned by what information is in fact available on thetopic.
From a practical viewpoint, analytical questionsare often underspecified, thus casting a broad net on aspace of possible answers.
Questions posed by profes-sional analysts are aimed to probe the available dataalong certain dimensions.
The results of these probesdetermine follow up questions, if necessary.
Further-more, at any stage clarifications may be needed to adjustthe scope and intent of each question.
Figure 1a shows afragment of an analytical session with HITIQA; pleasenote that these questions are not aimed at factoids, de-spite appearances.
HITIQA project is part of the ARDAAQUAINT program that aims to make significant ad-vances in state of the art of automated question answer-ing.User: What is the history of the nuclear arms program be-tween Russia and Iraq?HITIQA: [responses and clarifications]User: Who financed the nuclear arms program in Iraq?HITIQA:?User: Has Iraq been able to import uranium?HITIQA:?User: What type of debt does exist between Iraq and Russia?FIGURE 1a: A fragment of analytic session2   Factoid vs. Analytical QAThe process of automated question answering is nowfairly well understood for most types of factoid ques-tions.
Factoid questions display a fairly distinctive ?an-swer type?, which is the type of the information itemneeded for the answer, e.g., ?person?
or ?country?, etc.Most existing factoid QA systems deduct this expectedanswer type from the form of the question using a finitelist of possible answer types.
For example, ?How longwas the Titanic??
expects some length measure as ananswer, probably in yards and feet, or meters.
This isgenerally a very good strategy that has been exploitedsuccessfully in a number of automated QA systems thatappeared in recent years, especially in the context ofTREC QA1  evaluations (Harabagiu et al, 2002; Hovyet al, 2000; Prager at al., 2001).This answer-typing process is not easily applied toanalytical questions because the type of an answer foranalytical questions cannot always be anticipated due totheir inherently exploratory character.
In contrast to afactoid question, an analytical question has an unlimitedvariety of syntactic forms with only a loose connectionbetween their syntax and the expected answer.
Giventhe unlimited potential of the formation of analyticalquestions, it would be counter-productive to restrictthem to a limited number of question/answer types.Therefore, the formation of an answer in analytical QAshould instead be guided by the user?s interest as ex-pressed in the question, as well as through an interactivedialogue with the system.In this paper we argue that the semantics of an ana-lytical question is more likely to be deduced from the1 TREC QA is the annual Question Answering evaluation sponsoredby the U.S. National Institute of Standards and Technologywww.trec.nist.govinformation that is considered relevant to the questionthan through a detailed analysis of its particular form.Determining ?relevant?
information is not the same asfinding an answer; indeed we can use relatively simpleinformation retrieval methods (keyword matching, etc.
)to obtain perhaps 200 ?relevant?
documents from a da-tabase.
This gives us an initial answer space to workfrom in order to determine the scope and complexity ofthe answer, but we are nowhere near the answer yet.
Inour project, we use structured templates, which we callframes, to map out the content of pre-retrieved docu-ments, and subsequently to delineate the possible mean-ing of the question before we can attempt to formulatean answer.3   Text FramingIn HITIQA we use a text framing technique to delineatethe gap between the meaning of the user?s question andthe system?s ?understanding?
of this question.
Theframing process does not attempt to capture the entiremeaning of the passages; instead it imposes a partialstructure on the text passages that would allow the sys-tem to systematically compare different passagesagainst each other and against the question.
Framing isjust sufficient enough to communicate with the userabout the differences in their question and the returnedtext.
In particular, the framing process may uncovertopics or aspects within the answer space which the userhas not explicitly asked for, and thus may be unaware oftheir existence.
If these topics or aspects align closelywith the user?s question, we may want to make the useraware of them and let him/her decide if they should beincluded in the answer.Frames are built from the retrieved data, after clus-tering it into several topical groups.
Retrieved docu-ments are first broken down into passages, mostly ex-ploiting the naturally occurring paragraph structure ofthe original sources, filtering out duplicates.
The re-maining passages are clustered using a combination ofhierarchical clustering and n-bin classification (Hardy etal., 2002).
Typically three to six clusters are generated.Each cluster represents a topic theme within the re-trieved set: usually an alternative or complimentary in-terpretation of the user?s question.
Since clusters arebuilt out of small text passages, we associate a framewith each passage that serves as a seed of a cluster.
Wesubsequently merge passages, and their associatedframes whenever anaphoric and other cohesive links aredetected.HITIQA starts by building a general frame on theseed passages of the clusters and any of the top N (cur-rently N=10) scored passages that are not already in acluster.
The general frame represents an event or a rela-tion involving any number of entities, which make upthe frame?s attributes, such as LOCATION, PERSON,COUNTRY, ORGANIZATION, etc.
Attributes are extractedfrom text passages by BBN?s Identifinder, which tags24 types of named entities.
The event/relation itselfcould be pretty much anything, e.g., accident, pollution,trade, etc.
and it is captured into the TOPIC attributefrom the central verb or noun phrase of the passage.
Ingeneral frames, attributes have no assigned roles; theyare loosely grouped around the TOPIC.We have also defined three slightly more specializedtyped frames by assigning roles to selected attributes inthe general frame.
These three ?specialized?
frames are:(1) a Transfer frame with three roles including FROM, TOand OBJECT; (2) a two-role Relation frame with AGENTand OBJECT roles; and (3) a one-role Property frame.These typed frames represent certain genericevents/relationships, which then map into more specificevent types in each domain.
Other frame types may bedefined if needed, but we do not anticipate there will bemore than a handful all together.2 Where the generalframe is little more than just a ?bag of attributes?, thetyped frames capture some internal structure of anevent, but only to the extent required to enable an effi-cient dialogue with the user.
Typed frames are ?trig-gered?
by appearance of specific words in text, for ex-ample the word export may trigger a Transfer frame.
Asingle text passage may invoke one or more typedframes, or none at all.
When no typed frame is invoked,the general frame is used as default.
If a typed frame isinvoked, HITIQA will attempt to identify the roles, e.g.FROM, TO, OBJECT, etc.
This is done by mapping generalframe attributes selected from text onto the typed attrib-utes in the frames.
In any given domain, e.g., weaponnon-proliferation, both the trigger words and the roleidentification rules can be specialized from a trainingcorpus of typical documents and questions.
For exam-ple, the role-ID rules rely both on syntactic cues and theexpected entity types, which are domain adaptable.Domain adaptation is desirable for obtaining morefocused dialogue, but it is not necessary for HITIQA towork.
We used both setups under different conditions:the generic frames were used with TREC documentcollection to measure impact of IR precision on QAaccuracy (Small et al, 2004).
The domain-adaptedframes were used for sessions with intelligence analystsworking with the WMD Domain (see below).
Currently,the adaptation process includes manual tuning followedby corpus bootstrapping using an unsupervised learningmethod (Strzalkowski & Wang, 1996).
We generallyrely on BBN?s Identifinder for extraction of basic enti-ties, and use bootstrapping to define additional entitytypes as well as to assign roles to attributes.The version of HITIQA reported here and used byanalysts during the evaluation has been adapted to the2 Scalability is certainly an outstanding issue here, and we are work-ing on effective frame acquisition methods, which is outside of thescope of this paper.Weapons of Mass Destruction Non-Proliferation do-main (WMD domain, henceforth).
Figure 1b containsan example passage from this data set.
In the WMDdomain, the typed frames were mapped ontoWMDTransfer 3-role frame, and two 2-role framesWMDTreaty  and WMDDevelop.
Adapting the frames toWMD domain required only minimal modification,such as adding WEAPON entity to augment Identifinderentity set, specializing OBJECT attribute in WMDTrans-fer to WEAPON, generating a list of international weaponcontrol treaties, etc.HITIQA frames define top-down constraints on howto interpret a given text passage, which is quite differentfrom MUC3 template filling task (Humphreys et al,1998).
What we?re trying to do here is to ?fit?
a frameover a text passage.
This means also that multipleframes can be associated with a text passage, or to beexact, with a cluster of passages.
Since most of the pas-sages that undergo the framing process are part of somecluster of very similar passages, the added redundancyhelps to reinforce the most salient features for extrac-tion.
This makes the framing process potentially lesserror-prone than MUC-style template filling4.The Bush Administration claimed that Iraq was within oneyear of producing a nuclear bomb.
On 30 November 1990...Leonard Spector said that Iraq possesses 200 tons of naturaluranium imported and smuggled from several countries.
Iraqpossesses a few working centrifuges and the blueprints tobuild them.
Iraq imported centrifuge materials from Nukem ofthe FRG and from other sources.
One decade ago, Iraq im-ported 27 pounds of weapons-grade uranium from France, ...FIGURE 1b: A text passage from the WMD domain dataA very similar framing process is applied to theuser?s question, resulting in one or more Goal frames,which are subsequently compared to the data framesobtained from retrieved text passages.
A Goal frame canbe a general frame or any of the typed frames.
The Goalframe generated from the question, ?Has Iraq been ableto import uranium??
is shown in Figure 2.
This frame isof WMDTransfer type, with 3 role attributes TRF_TO,TRF_FROM and TRF_OBJECT, plus the relation type(TRF_TYPE).
Each role attribute is defined over an un-derlying general frame attribute (given in parentheses),which is used to compare frames of different types.HITIQA automatically judges a particular dataframe as relevant, and subsequently the correspondingsegment of text as relevant, by comparison to the Goalframe.
The data frames are scored based on the numberof conflicts found with the Goal frame.
The conflicts aremismatches on values of corresponding attributes.
If a3 MUC, the Message Understanding Conference, funded by DARPA,involved the evaluation of information extraction systems applied to acommon task.4 We do not have enough data to make a definite comparison at thistime.data frame is found to have no conflicts, it is given thehighest relevance rank, and a conflict score of zero.FRAME TYPE: WMDTransferTRF_TYPE (TOPIC): importTRF_TO (LOCATION): IraqTRF_FROM (LOCATION, ORGANIZATION): ?TRF_OBJECT (WEAPON): uraniumFIGURE 2: A domain Goal frame from the Iraq questionFRAME TYPE: WMDTransferTRF_TYPE (TOPIC): importedTRF_TO (LOCATION): IraqTRF_FROM (LOCATION): France [missed: Nukem of FRG]TRF_OBJECT (WEAPON): uraniumCONFLICT SCORE: 0FIGURE 3: A frame obtained from the text passage inFigure 1b, in response to the Iraq questionAll other data frames are scored with an increasingvalue based on the number of conflicts, score 1 forframes with one conflict with the Goal frame, score 2for two conflicts etc.
Frames that conflict with all in-formation found in the query are given the score 99 in-dicating the lowest rank.
Currently, frames with a con-flict score 99 are excluded from further processing asoutliers.
The frame in Figure 3 is scored as relevant tothe user?s query and included in the answer space.4   Clarification DialogueData frames with a conflict score of zero form theinitial kernel answer space and HITIQA proceeds bygenerating an answer from this space.
Depending uponthe presence of other frames outside of this set, the sys-tem may initiate a dialogue with the user.
HITIQA be-gins asking the user questions on these near-miss framegroups, groups with one or more conflicts, with thelargest group first.
In order to keep the dialogue fromgetting too winded, we set thresholds on number of con-flicts and group size that are considered by the dialoguemanager.A 1-conflict frame has only a single attribute mis-match with the Goal frame.
This could be a mismatchon any of the general frame attributes, for example, LO-CATION, ORGANIZATION, TIME, etc., or in one of therole-assigned attributes, TO, FROM, OBJECT, etc.
A spe-cial case arises when the conflict occurs on the TOPICattribute, which indicates the event type.
Since all otherattributes match, we may be looking at potentially dif-ferent events of the same kind involving the same enti-ties, possibly occurring at the same location or time.The purpose of the clarification dialogue in this case isto probe which of these topics may be of interest to theuser.
Another special case arises when the Goal frame isof a different type than a data frame.
The purpose of theclarification dialogue in this case is to see if the userwishes to expand the answer space to include events ofa different type.
This situation is illustrated in the ex-change shown in Figure 4.
Note that the user can exam-ine a partial answer prior to answering clarificationquestions.User: ?Has Iraq been able to import uranium??
[a partial answer displayed in an answer window]HITIQA: ?Are you also interested in background informationon the uranium development program in Iraq?
?FIGURE 4:  Clarification question generated for theIraq/uranium questionThe clarification question in Figure 4 is generated bycomparing the Goal frame in Figure 2 to a partly match-ing frame (Figure 5) generated from some other textpassage.
We note first that the Goal frame for this ex-ample is of WMDTransfer type, while the data frame inFigure 5 is of the type WMDDevelop.
Nonetheless, bothframes match on their general-frame attributes WEAPONand LOCATION.
Therefore, HITIQA asks the user if itshould expand the answer space to include developmentof uranium in Iraq as well.During the dialogue, as new information is obtainedfrom the user, the Goal frame is updated and the scoresof all the data frames are reevaluated.
If the user re-sponds the equivalent of ?yes?
to the system clarifica-tion question in the dialogue in Figure 4, a correspond-ing WMDDevelop frame will be added to the set of ac-tive Goal frames and all WMDDevelop frames obtainedfrom text passages will be re-scored for possible inclu-sion in the answer.FRAME TYPE: WMDDevelopDEV_TYPE (TOPIC): development, producedDEV_OBJECT (WEAPON): nuclear weapons, uraniumDEV_AGENT (LOCATION): Iraq, TuwaithaCONFLICT SCORE: 2Conflicts with FRAME_TYPE and TOPICFIGURE 5: A 2-conflict frame against the Iraq/uranium ques-tion that generated the dialogue in Figure 4.The user may end the dialogue at any point using thegenerated answer given the current state of the frames.Currently, the answer is simply composed of text pas-sages from the zero conflict frames.
In addition,HITIQA will generate a ?headline?
for the text passagesin the answer space.
This is done using a combinationof text templates and simple grammar rules applied tothe attributes of the passage frame.5   HITIQA Qualitative EvaluationsIn order to assess our progress thus far, and to alsodevelop metrics to guide future evaluation, we invited agroup of analysts employed by the US government toparticipate in two three-day workshops, held in Septem-ber and October 2003.The two basic objectives of the workshops were:1.
To perform a realistic assessment of the useful-ness and usability of HITIQA as an end-to-end system,from the information seeker's initial questions to com-pletion of a draft report.2.
To develop metrics to compare the answers ob-tained by different analysts and evaluate the quality ofthe support that HITIQA provides.The analysts' primary task was preparation of reportsin response to scenarios - complex questions that usu-ally encompassed multiple sub-questions.
The scenarioswere developed in conjunction with several U.S. gov-ernment offices.
These scenarios, detailing informationrequired for the final report, were not normally useddirectly as questions to HITIQA, instead, they weretreated as a basis to issues possibly leading to a series ofquestions, as shown in Figure 1a.The results of these evaluations strongly validatedour approach to analytical QA.
At the same time, welearned a great deal about how analysts work, and abouthow to improve the interface.Analysts completed several questionnaires de-signed to assess their overall experience with the sys-tem.
Many of the questions required the analysts tocompare HITIQA to other tools they were currentlyusing in their work.
HITIQA scores were quite high,with mean score 3.73 out of 5.
We scored particularlyhigh in comparison to current analytic tools.
We havealso asked the analysts to cross-evaluate their productreports obtained from interacting with HITIQA.
Again,the results were quite good with a mean answer qualityscore of 3.92 out of 5.
While this evaluation was onlypreliminary, it nonetheless gave us confidence that ourdesign is ?correct?
in a broad sense.5AcknowledgementsThis paper is based on work supported by the AdvancedResearch and Development Activity (ARDA)?s AdvancedQuestion Answering for Intelligence (AQUAINT) Programunder contract number 2002-H790400-000.ReferencesHardy, H., et al 2002.
Cross-Document Summarization by ConceptClassification.
Proceedings of SIGIR, Tampere, Finland.Harabagiu, S., et.
al.
2002.
Answering Complex, List and Contextquestions with LCC?s Question Answering Server.
In Proceed-ings of Text Retrieval Conference (TREC-10).Hovy, E., et al 2000.
Question Answering in Webclopedia.
Notebook.Proceedings of Text Retrieval Conference (TREC-9).Humphreys, R. et al 1998.
Description of the LaSIE-II System asUsed for MUC-7.
Proc.
of  7th Message Under.
Conf.
(MUC-7.
).Prager, J. et al 2003.
In Question-Answering Two Heads are BetterThan One.
Proceedings of HLT-NAACL 2003, pp 24-31.Strzalkowski, T and J. Wang.
1996.
A self-learning Universal ConceptSpotter.
Proceedings of COLING-86, pp.
931-936.Small S., Strzalkowski T., et al 2004.
A Data Driven Approach toInteractive Question Answering.
In M. Maybury (ed).
Future Di-rections in Automated Question Answering.
MIT Press (to appear)5 Space limitations do not allow for more complete discussion of theanalysts workshops and the results of the evaluations.
