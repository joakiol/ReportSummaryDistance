Proceedings of the 11th International Conference on Parsing Technologies (IWPT), pages 129?133,Paris, October 2009. c?2009 Association for Computational LinguisticsHebrew Dependency Parsing: Initial ResultsYoav Goldberg and Michael ElhadadBen Gurion University of the NegevDepartment of Computer SciencePOB 653 Be?er Sheva, 84105, Israel{yoavg,elhadad}@cs.bgu.ac.ilAbstractWe describe a newly available HebrewDependency Treebank, which is extractedfrom the Hebrew (constituency) Tree-bank.
We establish some baseline un-labeled dependency parsing performanceon Hebrew, based on two state-of-the-artparsers, MST-parser and MaltParser.
Theevaluation is performed both in an artifi-cial setting, in which the data is assumedto be properly morphologically segmentedand POS-tagged, and in a real-world set-ting, in which the parsing is performed onautomatically segmented and POS-taggedtext.
We present an evaluation measurethat takes into account the possibility ofincompatible token segmentation betweenthe gold standard and the parsed data.Results indicate that (a) MST-parser per-forms better on Hebrew data than Malt-Parser, and (b) both parsers do not makegood use of morphological informationwhen parsing Hebrew.1 IntroductionHebrew is a Semitic language with rich morpho-logical structure and free constituent order.Previous computational work addressed unsu-pervised Hebrew POS tagging and unknown wordresolution (Adler, 2007), Hebrew NP-chunking(Goldberg et al, 2006), and Hebrew constituencyparsing (Tsarfaty, 2006; Golderg et al, 2009).Here, we focus on Hebrew dependency parsing.Dependency-parsing got a lot of research at-tention lately, in part due to two CoNLL sharedtasks focusing on multilingual dependency parsing(Buchholz and Erwin, 2006; Nivre et al, 2007).These tasks include relatively many parsing re-sults for Arabic, a Semitic language similar to He-brew.
However, parsing accuracies for Arabic usu-ally lag behind non-semitic languages.
Moreover,while there are many published results, we couldnot find any error analysis or even discussion ofthe results of Arabic dependency parsing models,or the specific properties of Arabic making it easyor hard to parse in comparison to other languages.Our aim is to evaluate current state-of-the-artdependency parsers and approaches on Hebrewdependency parsing, to understand some of thedifficulties in parsing a Semitic language, and toestablish a strong baseline for future work.We present the first published results on Depen-dency Parsing of Hebrew.Some aspects that make Hebrew challengingfrom a parsing perspective are:Affixation Common prepositions, conjunctionsand articles are prefixed to the following word,and pronominal elements often appear as suffixes.The segmentation of prefixes and suffixes is of-ten ambiguous and must be determined in a spe-cific context only.
In term of dependency pars-ing, this means that the dependency relations oc-cur not between space-delimited tokens, but in-stead between sub-token elements which we?ll re-fer to as segments.
Furthermore, any mistakes inthe underlying token segmentations are sure to bereflected in the parsing accuracy.Relatively free constituent order The orderingof constituents inside a phrase is relatively free.This is most notably apparent in the verbal phrasesand sentential levels.
In particular, while most sen-tences follow an SVO order, OVS and VSO con-figurations are also possible.
Verbal argumentscan appear before or after the verb, and in manyordering.
For example, the message ?went fromIsrael to Thailand?
can be expressed as ?went toThailand from Israel?, ?to Thailand went from Is-rael?, ?from Israel went to Thailand?, ?from Israelto Thailand went?
and ?to Thailand from Israelwent?.
This results in long and flat VP and S struc-tures and a fair amount of sparsity, which suggests129that a dependency representations might be moresuitable to Hebrew than a constituency one.Rich templatic morphology Hebrew has avery productive morphological structure, whichis based on a root+template system.
The pro-ductive morphology results in many distinct wordforms and a high out-of-vocabulary rate, whichmakes it hard to reliably estimate lexical param-eters from annotated corpora.
The root+templatesystem (combined with the unvocalized writingsystem) makes it hard to guess the morphologicalanalyses of an unknown word based on its prefixand suffix, as usually done in other languages.Unvocalized writing system Most vowels arenot marked in everyday Hebrew text, which re-sults in a very high level of lexical and morpho-logical ambiguity.
Some tokens can admit as manyas 15 distinct readings, and the average number ofpossible morphological analyses per token in He-brew text is 2.7, compared to 1.4 in English (Adler,2007).
This means that on average, every token isambiguous with respect to its POS and morpho-logical features.Agreement Hebrew grammar forces morpho-logical agreement between Adjectives and Nouns(which should agree in Gender and Number anddefiniteness), and between Subjects and Verbs(which should agree in Gender and Number).2 Hebrew Dependency TreebankOur experiments are based on the Hebrew De-pendency Treebank (henceforth DepTB), whichwe derived from Version 2 of the HebrewConstituency Treebank (Guthmann et al, 2009)(henceforth TBv2).
We briefly discuss the conver-sion process and the resulting Treebank:Parent-child dependencies TBv2 marks sev-eral kinds of dependencies, indicating the mother-daughter percolation of features such as number,gender, definiteness and accusativity.
See (Guth-mann et al, 2009) for the details.
We followTBv2?s HEAD, MAJOR and MULTIPLE depen-dency marking in our-head finding rules.
Whenthese markings are not available we use head find-ing rules in the spirit of Collins.
The head-findingrules were developed by Reut Tsarfaty and usedin (Tsarfaty and Sima?an, 2008).
We slightly ex-tended them to handle previously unhandled cases.Some conventions in TBv2 annotations resulted inbad dependency structures.
We identified theseconstructions and transformed the tree structure,Figure 1: Coordinated VerbsFigure 2: Coordinated Sentenceeither manually or automatically, prior to the de-pendency extraction process.The conversion process revealed some errorsand inconsistencies in TBv2, which we fixed.We take relativizers as the head S and SBAR,and prepositions as the heads of PPs.
In the casethe parent of a word X is an empty element, wetake the parent of the empty element as the par-ent of X instead.
While this may result in non-projective structures, in practice all but 34 of theresulting trees are projective.We take conjunctions to be the head of a coordi-nated structure, resulting in dependency structuressuch as the one in Figures 1 and 2.
Notice howin Figure 1 the parent of the subject ????/He?
isthe coordinator ?
?/and?, and not one of the verbs.While this makes things harder for the parser, wefind this representation to be much cleaner andmore expressive than the usual approach in whichthe first coordinated element is taken as the headof the coordinated structure.1Dependency labels TBv2 marks 3 kinds offunctional relations: Subject, Object and Comple-mentizer.
We use these in our conversion pro-cess, and label dependencies as being SBJ, OBJor CMP, as indicated in TBv2.
We also triviallymark the ROOT dependency, and introduce the re-lations INF PREP, AT INF POS INF RB INF be-tween a base word and its suffix for the cases ofsuffix-inflected prepositions, accusative suffixes,possessive suffixes and inflected-adverbs, respec-tively.
Still, most dependency relations remain un-labeled.
We are currently seeking a method of re-liably labeling the remaining edges with a rich set1A possible alternative would be to allow multiple par-ents, as done in (de Marneffe et al, 2006), but current parsingalgorithms require the output to be tree structured.130of relations.
However, in the current work we fo-cus on the unlabeled dependency structure.POS tags The Hebrew Treebank follows a syn-tactic tagging scheme, while other Hebrew re-sources prefer a more morphological/dictionary-based scheme.
For a discussion of these two tag-ging schemes in the context of parsing, see (Gold-erg et al, 2009).
In DepTB, we kept the twotagsets, and each token has two POS tags asso-ciated with it.
However, as current dependencyparsers rely on an external POS tagger, we per-formed all of our experiments only with the mor-phological tagset, which is what our tagger pro-duces.3 The Parsing ModelsTo establish some baseline results for Hebrew de-pendency parsing, we experiment with two pars-ing models, the graph-based MST-parser (Mc-Donald, 2006) and the transition-based MaltParser(Nivre et al, 2006).
These two parsers repre-sent the current mainstream approaches for de-pendency parsing, and each was shown to pro-vide state-of-the-art results on many languages(CoNLL Shared Task 2006, 2007).Briefly, a graph-based parsing model works byassigning a score to every possible attachment be-tween a pair (or a triple, for a second-order model)of words, and then inferring a global tree struc-ture that maximizes the sum of these local scores.Transition-based models work by building the de-pendency graph in a sequence of steps, where eachstep is dependent on the next input word(s), theprevious decisions, and the current state of theparser.
For more details about these parsing mod-els as well as a discussion on the relative benefitsof each model, see (McDonald and Nivre, 2007).Contrary to constituency-based parsers, depen-dency parsing models expect a morphologicallysegmented and POS tagged text as input.4 ExperimentsData We follow the train-test-dev split estab-lished in (Tsarfaty and Sima?an, 2008).
Specifi-cally, we use Sections 2-12 (sentences 484-5724)of the Hebrew Dependency Treebank as our train-ing set, and report results on parsing the develop-ment set, Section 1 (sentences 0-483).
We do notevaluate on the test set in this work.The data in the Treebank is segmented andPOS-tagged.
All of the models were trained on thegold-standard segmented and tagged data.
Whenevaluating the parsing models, we perform twosets of evaluations.
The first one is an oracle ex-periment, assuming gold segmentation and tag-ging is available.
The second one is a real-worldexperiment, in which we segment and POS-tag thetest-set sentences using the morphological disam-biguator described in (Adler, 2007; Goldberg etal., 2008) prior to parsing.Parsers and parsing models We use the freelyavailable implementation of MaltParser2 andMSTParser3, with default settings for each of theparsers.For MaltParser, we experiment both with the de-fault feature representation (MALT) and the fea-ture representation used for parsing Arabic inCoNLL 2006 and 2007 multilingual dependencyparsing shared tasks (MALT-ARA).For MST parser, we experimented with first-order (MST1) and second-order (MST2) models.We varied the amount of lexical informationavailable to the parser.
Each of the parsers wastrained on 3 datasets: LEXFULL, in which all thelexical items are available, LEX20, in which lexi-cal items appearing less than 20 times in the train-ing data were replaced by an OOV token, andLEX100 in which we kept only lexical items ap-pearing more than 100 times in training.We also wanted to control the effect of the richmorphological information available in Hebrew(gender and number marking, person, and so on).To this end, we trained and tested each model ei-ther with all the available morphological informa-tion (+MORPH) or without any morphological in-formation (-MORPH).Evaluation Measure We evaluate the resultingparses in terms of unlabeled accuracy ?
the percentof correctly identified (child,parent) pairs4.
To beprecise, we calculate:number of correctly identified pairsnumber of pairs in gold parseFor the oracle case in which the gold-standardtoken segmentation is available for the parser, thisis the same as the traditional unlabeled-accuracyevaluation metric.
However, in the real-word set-ting in which the token segmentation is done auto-matically, the yields of the gold-standard and the2http://w3.msi.vxu.se/?jha/maltparser/3http://sourceforge.net/projects/mstparser/4All the results are macro averaged.
The micro-averagednumbers are about 2 percents higher for all cases.131Features MST1 MST2 MALT MALT-ARA-MORPH Full Lex 83.60 84.31 80.77 80.32Lex 20 82.99 84.52 79.69 79.40Lex 100 82.56 83.12 78.66 78.56+MORPH Full Lex 83.60 84.39 80.77 80.73Lex 20 83.60 84.77 79.69 79.84Lex 100 83.23 83.80 78.66 78.56Table 1: Unlabeled dependency accuracy withoracle token segmentation and POS-tagging.Features MST1 MST2 MALT MALT-ARA-MORPH Full Lex 75.64 76.38 73.03 72.94Lex 20 75.48 76.41 72.04 71.88Lex 100 74.97 75.49 70.93 70.73+MORPH Full Lex 73.90 74.62 73.03 73.43Lex 20 73.56 74.41 72.04 72.30Lex 100 72.90 73.78 70.93 70.97Table 2: Unlabeled dependency accuracy withautomatic token segmentation and POS-tagging.automatic parse may differ, and one needs to de-cide how to handle the cases in which one or moreelements in the identified (child,parent) pair arenot present in the gold-standard parse.
Our evalua-tion metric penalizes these cases by regarding anysuch case as a mistake.5 Results and AnalysisResults are presented in Tables 1 and 2.It seems that the graph-based parsers performbetter than the transitions-based ones.
We at-tribute this to 2 factors: first, our representa-tion of coordinated structure is hard to capturewith a greedy local search as performed by atransition-based parser, because we need to de-fer many attachment decisions until the final co-ordinator is revealed.
The global inference of thegraph-based parser is much more robust to thesekinds of structure.
Indeed, when evaluating thegold-morphology, fully-lexicalized models on asubset of the test-set (314 sentences) which doesnot have coordinated structures, the accuracy ofMALT improves in 3.98% absolute (from 80.77 to84.75), while MST improves only in 2.66% abso-lute (from 83.60 to 86.26).
Coordination is hardfor both parsing models, but more so to the transi-tion based MALT.Second, it might be hard for a transition-basedparser to handle the free constituent order of He-brew, as it has no means of generalizing from thetraining set to various possible constituent order-ing.
The graph-based parser?s features and infer-ence method do not take constituent order into ac-count, making it more suitable for free constituentorder language.As expected, the Second-order graph basedmodels perform better than the first-order ones.Surprisingly, the Arabic-optimized feature-set donot perform better than the English one for thetransition-based parsers.
Overall, morphologicalinformation seems to contribute very little (if atall) to any of the parsers in the gold-morphology(oracle) setting.
MALTARA gets some benefitfrom the morphological information in the fully-lexicalized case, while the MST variants benefitfrom morphology in the lexically-pruned models.Overall, full lexicalization is not needed.
In-deed, less lexicalized LEX20 2nd-order graph-based models perform better than the fully lexi-calized ones.
This strengthens our intuition thatrobust lexical statistics are hard to acquire fromsmall annotated corpora, even more so for a lan-guage with productive morphology such as He-brew.Moving from the oracle morphological disam-biguation to an automatic one greatly hurts the per-formance of all the models.
This is in line with re-sults for Hebrew constituency parsing, where go-ing from gold segmentation to a parser derived onecaused a similar drop in accuracy (Golderg et al,2009).
This suggests that we should either striveto improve the tagging accuracy, or perform jointinference for parsing and morphological disam-biguation.
We believe the later would be a betterway to go, but it is currently unsupported in state-of-the-art dependency parsing algorithms.Interestingly, in the automatic morphologicaldisambiguation setting MALTARA benefits a littlefrom the addition of morpological features, whilethe MST models perform better without these fea-tures.6 ConclusionsWe presented the first results for unlabeled de-pendency parsing of Hebrew, with two state-of-the-art dependency parsing models of differentfamilies.
We experimented both with gold mor-phological information, and with an automaticallyderived one.
It seems that graph-based modelshave a slight edge in parsing Hebrew over currenttransition-based ones.
Both model families are notcurrently making good use of morphological infor-mation.132ReferencesMeni Adler.
2007.
Hebrew Morphological Disam-biguation: An Unsupervised Stochastic Word-basedApproach.
Ph.D. thesis, Ben-Gurion University ofthe Negev, Beer-Sheva, Israel.Sabine Buchholz and Marsi Erwin.
2006.
CoNLL-Xshared task on multilingual dependency parsing.
InProc.
of CoNLL.Marie-Catherine de Marneffe, Bill MacCartney, andChristopher D. Manning.
2006.
Generating typeddependency parses from phrase structure parses.
InProc.
of LREC.Yoav Goldberg, Meni Adler, and Michael Elhadad.2006.
Noun phrase chunking in hebrew: Influenceof lexical and morphological features.
In Proc.
ofCOLING/ACL.Yoav Goldberg, Meni Adler, and Michael Elhadad.2008.
EM can find pretty good HMM POS-Taggers(when given a good start).
In Proc.
of ACL.Yoav Golderg, Reut Tsarfaty, Meni Adler, and MichaelElhadad.
2009.
Enhancing unlexicalized parsingperformance using a wide coverage lexicon, fuzzytag-set mapping, and EM-HMM-based lexical prob-abilities.
In Proc of EACL.Noemie Guthmann, Yuval Krymolowski, Adi Milea,and Yoad Winter.
2009.
Automatic annotation ofmorpho-syntactic dependencies in a modern hebrewtreebank.
In Proc of TLT.Ryan McDonald and Joakim Nivre.
2007.
Character-izing the errors of data-driven dependency parsingmodels.
In Proc.
of EMNLP.Ryan McDonald.
2006.
Discriminative Training andSpanning Tree Algorithms for Dependency Parsing.Ph.D.
thesis, University of Pennsylvania.Joakim Nivre, Johan Hall, and Jens Nillson.
2006.MaltParser: A data-driven parser-generator for de-pendency parsing.
In Proc.
of LREC.Joakim Nivre, Johan Hall, Sandra Kubler, Ryan Mc-Donald, Jens Nilsson, Sebastian Riedel, and DenizYuret.
2007.
The CoNLL 2007 shared task on de-pendency parsing.
In Proc.
of the EMNLP-CoNLL.Reut Tsarfaty and Khalil Sima?an.
2008.
Relational-realizational parsing.
In Proc.
of CoLING, August.Reut Tsarfaty.
2006.
Integrated morphological andsyntactic disambiguation for modern hebrew.
InProceedings of ACL-SRW.133
