INCREMENTAL DEPENDENCY PARSINGVincenzo LombardoDipartimento di Informatica - Universita" di TorinoC.so Svizzera 185 - 10149 Torino - Italye-mail: vincenzo@di.unito.itAbstractThe paper introduces a dependency-based grammar ndthe associated parser and focusses on the problem ofdeterminism in parsing and recovery from errors.First, it is shown how dependency-based parsing canbe afforded, by taking into account the suggestionscoming from other approaches, and the preferencecriteria for parsing are briefly addressed.
Second, theissues of the interconnection between the syntacticanalysis and the semantic interpretation inincremental processing are discussed and the adoptionof a TMS for the recovery of the processing errors issuggested.THE BAS IC  PARSING ALGORITHMThe parser has been devised for a system that workson the Italian language.
The structure that resultsfrom the parsing process is a dependency tree, thatexhibits yntactic and semantic information.The dependency structure: The structurecombines the traditional view of dependency s ntaxwith the feature terms of the unification basedformalisms (Shieber 86): single attributes (likenumber or tense) appear inside the nodes of the tree,while complex attributes (like grammatical relations)are realized as relations between odes.
The choice ofa dependency structure, which is very suitable for freeword order languages (Sgall et al 86), reflects theintuitive idea of a language with few constraints onthe order of legal constructions.
Actually, theflexibility of a partially configurational l nguage likeItalian (that can be considered at an intermediate levelbetween the totally configurational l nguages likeEnglish and the totally inflected free-ordered Slavoniclanguages) can be accounted for with a relaxation ofthe strong constraints posed by a constituencygrammar (Stock 1989) or by constraining to a certainlevel a dependency grammar.
Cases of topicalization,likeun dolce di frutta ha ordinato il maestroa cake with fruits has ordered the teacherand in general all the five permutations of the "basic"(i.e.
more likely) SVO structure of the sentence areso common in Italian, that it seems much moreeconomical to express the syntactic knowledge interms of dependency relations.Every node in the structure is associated with aword in the sentence, in such a way that the relationbetween two nodes at any level is of a head&modifiertype.
The whole sentence has a head, namely theverb, and its roles (the subj is included) are itsmodifiers.
Every modifier in turn has a head (a noun,which can be a proper, common or pro-noun, forparticipants not marked by a preposition, apreposition, or a verb, in case of subordinatesentences not preceded by a conjunction) and furthermodifiers.Hence the dependency tree gives an immediaterepresentation f the thematic structure of thesentence, thus being very suitable for the semanticinterpretation.
Such a structure also allows theapplication of the rules, based on grammaticalrelations, that govern complex syntactic phenomena,as revealed by the extensive work on RelationalGrammar.The dependency grammar isexpressed declarativelyvia two tables, that represent he relations ofimmediate dominance and linear order for pairs ofcategories.
The constraints on the order between ahead and one of its modifiers and between twomodifiers of the same head are reflected by the nodesin the dependency structure.
The formation of thecomplex structure that is associated with the nodes isaccomplished by means of unification: the basicterms are originated by the lexicon and associatedwith the nodes.
There exist principles that govern thepropagation of the features in the dependency treeexpressed as analogous conventions toGPSG ones.The incremental parser: In the system, thesemantic, as well as the contextual nd the anaphoricbinding analysis, is interleaved with the syntacticparsing.
The analysis is incremental, in the sense thatit is carried out in a piecemeal strategy, by takingcare of partial results too.In order to accomplish the incremental parsing andto build a dependency representation f the sentence,the linguistic knowledge of the two tables is291compiled into more suitable data structures, calleddiamonds.
Diamonds represent a redundant version ofthe linguistic knowledge of the tables: their graphicalrepresentation (see the figure) gives an immediate ideaof how to employ them in an incremental parsingwith a dependency grammar.OUNI ~  /cat (ADJ,~ /  NOUN)PREP ~VERBVERB ~at  (DET, NOUN,/ ADJ,VERB) &head.
tense=+NOUNcat ,~  I | cat (RELPRON) &DET d.tense=+I~ 121 eat ( D~.~J ~PREP)ADY 2 I --PR PI~ADJ )i ~"~AD JThe center of the diamond is instanfiated as a node ofthe category indicated during the course of theanalysis.
The lower half of the diamond represents hecategories that can be seen as modifiers of the centercategory.
In particular, the categories on the left willprecede the head, while the categories on the rightwill follow it (the number on the edges totally orderthe modifiers on the same side of the head).
Theupper half of the diamond represents the possibleheads of the center: the categories on the right willfollow it, while the categories on the left, thatprecede it, indicate the type of node that will becomeactive when the current center has no more modifiersin the sentence.The ( incremental)  parsing algorithm isstraightforward: if the current node is of category X,the correspondent diamond (which has X as thecenter) individuates the possible alternatives in theparsing.
The next input word can be one of itspossible modifiers that follow it (right-low branch),its head (right-up branch), another modifier of itshead, i.e.
a sister (right-up branch and the followingleft-down one in the diamond activated immediatelynext), or a modifier of its head's head, an aunt (left-upbranch).The edges are augmented with conditions on theinput word (cat is a predicate which tests its categoryas belonging to a set of categories allowed to be theleft-corner of the subtree headed by a node of thecategory that stands at the end of the edge).Constraints on features are tested on the node itself orstored for a subsequent verification.Which edge to follow in the currently activediamond is almost always a matter of a nondeterministic choice.
Non determinism can be handledvia the interaction of many knowledge sources thatuse the dependency tree as a shared informationstructure, that represents the actual state of theparsing.
Such a structure does not contain onlysyntactic, but also semantic information.
Forexample, every node associated with a non functionalword points to a concept in a terminologicalknowledge base and the thematic structure of the verbis explicitly represented by the edges of thedependency tree.PARSING PREFERENCESMany preference strategies have been proposed in theliterature for guiding parsers (Hobbs and Bear (1990)present a review).
There are some preferences ofsyntactic (i.e.
structural) nature, like the RightAssociation and the Minimal Attachment, hat wereamong the first to be devised.
Semantic preferences,like the assignment of thematic roles to the elementsin the sentence 1 can contradict the expectations of thesyntactic preferences (Schubert 1984).
Contextualinformation (Crain, Steedman 1985) has also beendemonstrated to affect the parsing of sentences in aseries of psycholinguistic experiments.
Lexicalpreferencing (Stock 1989) (van der Linden 1991) isparticularly useful for the treatment of idiomaticexpressions.Parsing preferences are integrated in the frameworkdescribed above, by making the syntactic parserinteract with condition-action rules, that implementsuch preferences, at each step on the diamondstructure.
This technique can be classified under theweak integration strategy (Crain, Steedman 1985) atthe word level.
The rules for the resolution ofambiguities that belong to the various knowledgesources analyze the state of the parsing on thedependency structure and take into account the currentinput word.
For example, in the two sentencesa) G iorg io  le d iede con r i lu t tanza  unaingente somma di denaroGiorgio (to) her gave with reluctance a big amount ofmoneyb) Giorgio le diede con r i luttanza a PamelaGiorgio them gave with reluctance to Pamelathe pronoun "le" can be a plural accusative or asingular dative case.
In an incremental parser, whenwe arrive to "le" we are faced with an ambiguity thatcan be solved in a point which is arbitrarily ahead(impossibility of using Marcus' (1980) bounded1As we have noted in the beginning, this is not an easytask to accomplish, since flexible languages like Italianfeature a hardly predictable behavior in ordering: suchassignments must sometimes be revised (see below).292lookahead), when we find which grammatical relationis needed to complete the subcategorization frame ofthe verb.
Contextual information can help in solvingsuch an ambiguity, by binding the pronoun to areferent, which can be singular or plural.
Of coursethere could be more than one possible referent for thepronoun in the example above: in such a case thereexist a preference choice based on the meaning of theverb and its selectional restrictions, and, in case offurther ambiguity, a default choice among thepossible referents.
This choice must be stored as abacktracking point (in JTMS style) or as being anassumption of a context (in ATMS style), since itcan reveal to be wrong in the subsequent analysis.The revision of the interpretation can beaccomplished via a reason maintenance system.INTEGRATION WITH A REASONMAINTENANCE SYSTEMZernik and Brown (1988) have described a possibleintegration of default reasoning in natural anguageprocessing.
Their use of a JTMS has been criticizedbecause of the impossibility to evaluate the best wayin presence of multiple contexts, that are available ata certain point of the parsing process.
This is thereason why more recent works have focussed onATMS techniques (Charniak, Goldman 1988) andtheir relations to chart parsing (Wiren 1990).
ATMSallows to continue the processing, by reactivatinginterpretations, which have been previously discarded.Currently, the integration with a reasonmaintenance system (which can possibly be morespecialized for this particular task) is under study.
Thedependency structure contains the short termknowledge about the sentence at hand, with a"dependency" (in the TMS terminology) net thatkeeps the information on what relations have beeninferred from what choices.
Once that new elementscontradict some previous conclusions, the dependencynet alows to individuate the choice points that aremeaningful for the current situation and to relabel,according to the IN and OUT separation, the assertedfacts.
In the example a) if we have disambiguated thepronoun "le" as an object, such an interpretationmust be revised when we find the actual object Cabig amount of money").
One of the reasons foradopting truth maintenance t chniques i that all thefacts that must be withdrawn and the starting of anew analysis (in JTMS style) or to make relevant anew context in place of an old one (in ATMS) musttake into account that partial analyses, not related tothe changes at hand ("with reluctance" in theexample), must be left unchanged.
The specificsubstructure A, affected by the value chosen for theelement B, and the element B are connected via a(direct or indirect) link in the "dependency" net.
Achange of value for B is propagated through the nettoward all the linked substructures and, particularly,to A, which is to be revised.
In the example a), oncedetected that "le" is an indirect object, and then thatits referent must be female and singular, anew searchin the focus is attempted according to this newsetting.
Hence, the revision process operates on boththe syntactic structure, with changes of categoryand/or features values for the nodes involved (genderand number for "le") and of attachment points forwhole substructures, and the semantic representation(from direct to indirect object relation), which hasbeen previously built.ACKNOWLEDGEMENTSI thank prof. Leonardo Lesmo for his active andprecious upport.REFERENCESCharniak, E., Goldman, R. (1988).
A Logic forSemantic Interpretation.
In Proceedings of the 26thACL (87-94).Crain, S., Steedman, M. (1985).
On not being led upthe Garden Path: The Use of Context by thepsychological Syntax Processor.
In D. Dowty, L.Karttunen and A. Zwicky (eds), Natural LanguageParsing.
Psychological, Computational, andTheoretical Perspectives, Cambridge UniversityPress, Cambridge, England (320-358).Hobbs, J., Bear, J.
(1990).
Two Principles of ParsePreference.
InCOLING 90 (162-167).van der Linden, E., J.
(1991).
Incremental Processingand Hierarchical Lexicon.
To appear.Marcus, M. (1980).
A Theory of SyntacticRecognition for Natural Language.
MIT Press,Cambridge, Massachussets.Schubert, L. (1984).
On parsing preferences.
InCOLING 84 (247-250).Sgall, P., Haijcova, E. and Panevova, J.
(1986).
TheMeaning of the Sentence in its Semantic andPragmatic Aspects.
D. Reidel Publishing Company.Shieber, S., M. (1986).
An Introduction toUnification-Based Approach to Grammar.
CSLILecture Notes 4, CSLI, Stanford.Stock, O.
(1989).
Parsing with flexibility, dynamicstrategies and idioms in mind.
In ComputationalLinguistics 15 (1-19).Wiren, M. (1990).
Incremental Parsing and ReasonMaintenance.
In COLING 90 (287-292).Zernik, U., Brown, A.
(1988).
Default Reasoning inNatural Language Processing.
In COLING 88 (801-805).293
