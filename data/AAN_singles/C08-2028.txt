Coling 2008: Companion volume ?
Posters and Demonstrations, pages 111?114Manchester, August 2008A Complete and Modestly Funny System for Generating and PerformingJapanese Stand-Up ComedyJonas Sj?oberghHokkaido Universityjs@media.eng.hokudai.ac.jpKenji ArakiHokkaido Universityaraki@media.eng.hokudai.ac.jpAbstractWe present a complete system that gen-erates Japanese stand-up comedy.
Differ-ent modules generating different types ofjokes are tied together into a performancewhere all jokes are connected in some wayto the other jokes.
The script is convertedto speech and two robots perform the com-edy routine.
Evaluations show that the per-formances are perceived as funny by many,almost half the evaluation scores for the to-tal impression were 4 or 5 (top score).1 IntroductionWhen it comes to computer processing of humortwo main areas exist, humor recognition and hu-mor generation (Binsted et al, 2006).
This paperfalls under generation.
We present a system thatautomatically creates short stand-up comedy likeperformances.
Most generation systems only gen-erate simple types of jokes, by themselves.
Thereare few systems generating complete comic shows.Our system combines several different methods forgenerating quite simple jokes and then combinesthese into one short performance made for two per-formers.
This is then automatically converted intospeech audio, and presented by two small robots.The performances generated are in Japanese,and similar to Japanese manzai, a form of standup comedy.
Manzai is generally performed by twocomedians, one straight-man (tsukkomi) and onefunny man (boke).
Boke misunderstands or saysstupid things, and tsukkomi has to berate or cor-c?
2008.
Licensed under the Creative CommonsAttribution-Noncommercial-Share Alike 3.0 Unported li-cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).Some rights reserved.rect, for instance by exclaiming ?Idiot!?
and hit-ting boke on the head.2 SystemSeveral components are combined to produce shortcomedy performances.
We first give an overviewof the system and then explanations of the com-ponents.
Though the system only generates jokesin Japanese, for ease of understanding examples inEnglish similar to the Japanese original jokes areused in the explanations.2.1 Overall SystemFirst a script for the performance is generated.
Itstarts with an introduction like ?Hi, we are twonot very proficient joke robots, please listen toour performance.
?, simply selected from a shortlist.
Next, one robot uses a proverb or saying inJapanese, along the lines of ?Recently my life hasfelt like ?jack of all trades, master of none?, youknow.?
The other robot then makes a vulgar jokeby modifying this, perhaps like ?For me it has beenmore like ?jacking off all trades, masturbate none?,I must say.?.
The way of berating your stupid part-ner common in Japanese comedy has been incor-porated in the system.
After the vulgar joke above,the first (tsukkomi) robot says a phrase from a listof fairly generic put-down phrases, like ?What thehell are you saying?
?.Then the boke robot tells a joke from a databaseof wordplay jokes, selected from those with onenoun already in the script.
So in the exampleabove, perhaps: ?Speaking of ?life?
[mentioned be-fore], ?shotgun wedding: a case of wife or death?comes to mind.?
Again followed by a put-down bythe tsukkomi robot.Next comes a simple punning riddle generator.A noun already used that also sounds like a rude111word is selected and a riddle is created.
The rid-dle jokes are quite weak, similar to: ??speaking?
[used earlier] is ?speaking?, but what is a naughtykind of speaking?
?, ?What?
?, ?Spanking the mon-key!?
(?speak?
sounds like ?spank?
and ?spankingthe monkey?
is a euphemism).
Again followed bya put-down, ?Idiot!
Would you please stop.
?.Finally, one more joke from the database andanother put-down are used.
The robots then closewith ?Thank you, the end.?
or similar.
All the linesare then converted to speech using a text-to-speechtool.
The audio files are then input into two smallrobots, that perform the routine.2.2 Proverb JokesThe proverb joke module has a list of almost 1,000proverbs and sayings in Japanese.
These werecollected by simply downloading a few lists ofJapanese proverbs.
Since many of these are quiterare and thus people in general would not un-derstand them or any joke based on them, rareproverbs are filtered out automatically.
This isdone by simply searching the web for the proverbverbatim.
If it occurs more times than some thresh-old value (currently arbitrarily set to 50) it is con-sidered common and can be used to make jokes,starting with a generic statement like ?Recently mylife has felt like <proverb>?.To make a joke, a proverb is twisted into anew variant by changing words to similar sound-ing dirty words instead.
The dirty words are takenfrom a collection a few hundred dirty words inJapanese.
These have been grouped into threecategories, sex related, feces related, and insults.Words can belong to several or all of these groups(e.g.
?asshole?)
and are then present in all groups.A dirty variant of a proverb has to contain atleast two new words, and these must be of thesame type, and they must also sound reasonablysimilar to the words they replace.
This is deter-mined using a table of which sounds are how sim-ilar in Japanese, which is almost the same as theone used in (Takizawa et al, 1996).
Since thesame character in Japanese can have several dif-ferent readings, we use a standard morphologicalanalyzer for Japanese called ChaSen (Matsumotoet al, 1997) to get the pronunciation for the words.This leads to some problems, since the analyzerdoes not work all that well on proverbs (often us-ing rare grammatical constructions, words, etc.
),nor on dirty words (often missing from ChaSen?slexicons).
If there are more than one way to changea proverb into a new variant, one is selected at ran-dom.
The joke is then presented as described in theoverview section, i.e.
one robot saying the originalproverb and the other saying the variant.2.3 Riddle JokesThere have been a few systems that generate wordplay riddles (Binsted, 1996; Binsted and Takizawa,1998) and our module is not very innovative, it fol-lows the same basic ideas.
First, the script that hasbeen created so far is run through the ChaSen mor-phological analyzer also used earlier.
Nouns andtheir pronunciations are then checked against thecollection of dirty words to see if there are anydirty words with similar pronunciation.
A randomnoun sounding similar to a dirty word is then used.The riddle is built with this noun and the corre-sponding dirty word using a simple pattern.
Theboke robot says :?A <noun> is a <noun>, butwhat kind of <noun> is <hint>??
followed by:?What?
?, and the answer: ?<Dirty word>?.
Themost difficult part is finding a hint that describesthe dirty word in a good but not too obviousway without also being a good description of theoriginal word.
Hints are generated by searchingthe Internet for phrases like ?a <dirty word> is<hint>.?
Things found in this way are then as-sumed to be reasonable descriptions of the dirtyword (often not true, unfortunately), and are thenchecked to see if they are also often used for theoriginal word.
This is done by checking the co-occurrences of the hint and the original noun, andthe hint and the dirty word, also using web fre-quencies.
The log-likelihood ratios are then com-pared, and if the hint is more closely connected tothe dirty word it is used.
There is also a short stoplist of hints that are very common but useless, suchas Japanese particles similar to the word ?exist?.Since the dirty words in our collection are notthat common on the Internet, it happens that nousable hints are found at all.
In such cases a sim-ple hint meaning ?naughty?, ?rude?, or ?dirty?, isused for sex related words, insults, and feces re-lated words respectively.
It is also happens that nonoun used in the script sounds similar to a dirtyword.
Currently, for such cases, the whole script isabandoned and the system starts over.2.4 Database of PunsWe automatically collected a database of wordplay jokes in Japanese, using a few seed jokes.
If112for instance a seed joke occurred in an HTML liston the Internet, all other list items were taken asjokes too.
The database consists of almost 2,200jokes, mostly very weak word play jokes, thoughsome are perceived as quite funny by many peo-ple.
The jokes are often written using contrac-tions (e.g.
?dontcha?
), dialectal pronunciation in-stead of standard orthography, strange punctuationor choice of alphabets etc.
This causes problemsfor the morphological analyzer, leading to errors.When a joke from the database is needed, allthe nouns from the script up until this point areextracted as above.
A joke from the database con-taining at least one of these is then selected andpresented along the lines of ?Speaking of<noun>,this reminds me of <joke with noun>?.2.5 Put-Downs and Come-BacksWe asked an amateur comedian to write a shortlist of generic put-down phrases, giving things like?Ha ha, very funny?, ?What the hell are you talk-ing about?
?, ?Idiot?, ?That is not what I meant?,and similar.
Put-downs are drawn at random fromthe list, excluding any phrase already used.For database jokes, two other put-downs are alsopossible.
There is a a simple web frequency checkto see if the joke is old.
Any joke occurring morethan 20 times on the Internet is currently consid-ered ?Old!?.
Jokes that are not old can instead getthe ?Stupid foreigner!?
put-down (quite commonin Japanese comedy).
This is used on jokes withwords written either in English letters or katakanaletters.
Katakana is mainly used for foreign loanwords in Japanese, but is also other things (simi-lar perhaps to using upper case in English), whichleads to some errors.For some put-downs it is also possible for theboke robot to make a come-back.
When possiblethis is also added to the script.
For instance, whenthe tsukkomi robot says ?Old!?
it goes on to say forexample: ?By the way, how is the new apartmentyou moved into?
?, and the boke robot replies withthe phrase used on him, ?Old!
?.2.6 RobotsThe script is converted into audio for the robotsusing the AquesTalk1text-to-speech system, andthe robots are given different synthetic voices.
Thetext-to-speech conversion works fairly well, butsometimes the speech is hard to understand.1http://www.a-quest.com/aquestal/Figure 1: The robots used.The two robots used in the performances areboth Robovie-i robots, see Figure 1, one blue andone gold.
The Robovie-i can move its legs andlean its body sideways.
It has a small speaker at-tached, to produce the speech.
This is the weak-est link in the system so far, since the speaker isquite weak.
The sound quality is not great, andthe volume is low.
This is also compounded bythe text-to-speech system output sometimes beingquite hard to understand to begin with, and alsoby the generated jokes sometimes being incompre-hensible.
The main merits of the Robovie-i are thatit is easily programmable, cheap, and cute.
Therobots did not move very much.
They walked alittle bit forward and bowed during the introduc-tion, then remained stationary, leaning their torsosa little to one side when speaking.3 EvaluationWe generated two scripts and had the robots per-form them for evaluators.
Script 1 was shown first,then a short questionnaire for script 1 was filledout, then script 2 was performed and another ques-tionnaire filled out.
The impression of each wholeperformance was rated from 1 (not funny) to 5(funny).
Each individual joke was also rated.Evaluators were found by going to a studentcafeteria and offering chocolate for participating.Since the speech from the robot was a bit diffi-cult to understand it was sometimes very difficultto hear some jokes when there was a lot of back-ground noise.
The evaluators where also given thescript in written form after they had watched theperformance and could thus read any parts they didnot hear before evaluating the funniness.
33 eval-uators took part in the evaluations.
How funny thejokes are thought to be of course varies a lot fromperson to person.
The highest and lowest meansof an evaluator were 4.2 and 1.2 respectively.
Theresults are shown in Tables 1 and 2.Table 1 shows the overall impression of thescripts, 3.3 on a scale from 1 to 5.
Joke genera-113Script 1 Script 2 BothScore 3.4 (0.9) 3.2 (1.0) 3.3 (1.0)4 or 5 16 (48%) 14 (42%) 30 (45%)Table 1: Mean (and standard deviation) evaluationscores and the number of 4s or 5s assigned, for thetotal impression of the two evaluated scripts.tion systems tend to get fairly low scores, so webelieve a score of over 3 is good.
What meaningevaluators put into a 3 on a scale from 1 to 5 is hardto estimate, but many seemed to enjoy the perfor-mances.
It was also not uncommon to laugh a lotduring the performance and still rate everything as1 or 2 so, for some, laughter does not equal funny.A score of 4 or more should reasonably indicate afunny joke.
For the total impression of the perfor-mances, 30 scores (of 66) were either a 4 or a 5, soalmost half of the evaluators though it was funnyin this sense.
We believe this is a good result, con-sidering that individual tastes in humor vary a lot.In Table 2 the scores of the individual jokes areshown.
It seems that the proverb jokes are of aboutthe same level as the human made jokes from theInternet.
The riddle jokes lag a little behind, asdoes the come-back joke that was included.While the system makes mistakes, joke gen-eration seems rather robust to errors.
Since therobots are supposed to say stupid things anyway,if they do so by mistake instead of on purpose itcan still be funny.
There were comments fromevaluators about mistakes that they disliked too,though: ?This put-down is inappropriate for thatjoke?, ?They should bow while saying thank you,not after.
?, ?The dirty jokes are too direct, subtle isfunnier?.The biggest problem was the robot speakers.This should be fairly easy to fix.
The other prob-lems stem mainly from the generated jokes not be-ing overly funny, which seems harder to deal with.4 ConclusionsWe have implemented a complete system for auto-matically generating and performing short stand-up comedy routines in Japanese.
Different mod-ules generate different types of jokes then tied to-gether so that the jokes used have something incommon.
This is then converted to speech and up-loaded into two robots that perform the comedy.In the evaluation, the performances were ratedScore 4 or 5Proverb 1 2.6 (1.2) 9 (27%)Proverb 2 3.0 (1.0) 11 (33%)Proverb Avg.
2.8 (1.1) 20 (30%)Riddle 1 2.4 (1.1) 4 (12%)Riddle 2 2.3 (1.1) 5 (15%)Riddle Avg.
2.4 (1.1) 9 (13%)Comeback 2.6 (1.1) 6 (18%)Database 1a 3.6 (1.1) 19 (57%)Database 1b 2.5 (1.2) 6 (18%)Database 2a 3.1 (1.1) 13 (39%)Database 2a 2.9 (1.1) 13 (39%)Database Avg.
3.0 (1.2) 51 (38%)Table 2: Mean (and standard deviation) evaluationscores and the number of 4s or 5s assigned to thedifferent jokes.as 3.3 on a scale from 1 (not funny) to 5 (funny)and many evaluators enjoyed the performances.Almost half of the evaluation scores assigned tothe total impression of the system were 4 or 5.
Thisseems quite promising, though there are still manythings that can be improved in the system.ReferencesBinsted, Kim and Osamu Takizawa.
1998.
BOKE:A Japanese punning riddle generator.
Journalof the Japanese Society for Artificial Intelligence,13(6):920?927.Binsted, Kim, Benjamin Bergen, Seana Coulson, AntonNijholt, Oliviero Stock, Carlo Strapparava, GraemeRitchie, Ruli Manurung, Helen Pain, Annalu Waller,and Dave O?Mara.
2006.
Computational humor.IEEE Intelligent Systems, 21(2):59?69.Binsted, Kim.
1996.
Machine Humour: An Imple-mented Model of Puns.
Ph.D. thesis, University ofEdinburgh, Edinburgh, United Kingdom.Matsumoto, Y., A. Kitauchi, T. Yamashita, Y. Hirano,O.
Imaichi, and T. Imamura.
1997.
Japanese mor-phological analysis system ChaSen manual.
Techni-cal Report NAIST-IS-TR97007, NAIST.Takizawa, Osamu, Masuzo Yanagida, Akira Ito, andHitoshi Isahara.
1996.
On computational processingof rhetorical expressions - puns, ironies and tautolo-gies.
In International Workshop on ComputationalHumor, pages 39?52, Enschede, The Netherlands.114
