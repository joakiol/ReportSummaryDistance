Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 65?68,Avignon, France, April 23 - 27 2012. c?2012 Association for Computational LinguisticsPRESEMT: Pattern Recognition-based Statistically Enhanced MTGeorge Tambouratzis, Marina Vassiliou, Sokratis SofianopoulosInstitute for Language and Speech Processing, Athena R.C.6 Artemidos & Epidavrou Str., Paradissos Amaroussiou, 151 25, Athens, Greece.
{giorg_t; mvas ; s_sofian}@ilsp.grAbstractThis document contains a brief presentationof the PRESEMT project that aims in the de-velopment of a novel language-independentmethodology for the creation of a flexible andadaptable MT system.1.
IntroductionThe PRESEMT project constitutes a novel ap-proach to the machine translation task.
This ap-proach is characterised by (a) introducing cross-disciplinary techniques, mainly borrowed fromthe machine learning and computational intelli-gence domains, in the MT paradigm and (b) us-ing relatively inexpensive language resources.The aim is to develop a language-independentmethodology for the creation of a flexible andadaptable MT system, the features of which en-sure easy portability to new language pairs oradaptability to particular user requirements andto specialised domains with minimal effort.PRESEMT falls within the Corpus-based MT(CBMT) paradigm, using a small bilingual paral-lel corpus and a large TL monolingual corpus.Both these resources are collected as far as pos-sible over the web, to simplify the developmentof resources for new language pairs.The main aim of PRESEMT has been to alle-viate the reliance on specialised resources.
Incomparison, Statistical MT requires large parallelcorpora for the source and target languages.PRESEMT relaxes this requirement by using asmall parallel corpus, augmented by a large TLmonolingual corpus.2.
PRESEMT system structureThe PRESEMT system is distinguished intothree stages, as shown in Figure 1:1.
Pre-processing stage: This is the stage wherethe essential resources for the MT system arecompiled.
It consists of four discrete modules: (a)the Corpus creation & annotation module,being responsible for the compilation of mono-lingual and bilingual corpora over the web andtheir annotation; (b) the Phrase aligner module,which processes a bilingual corpus to performphrasal level alignment within a language pair; (c)the Phrasing model generator that elicits an SLphrasing model on the basis of the aforemen-tioned alignment and employs it as a parsing toolduring the translation process; (d) the Corpusmodelling module, which creates semantics-based TL models used for disambiguation pur-poses during the translation process.2.
Main translation engine: The translation inPRESEMT is a top-down two-phase process,distinguished into the Structure selection mod-ule, where the constituent phrases of an SL sen-tence are reordered according to the TL, and theTranslation equivalent selection module wheretranslation disambiguation is resolved and wordorder within phrases is established.
Closely inte-grated to the translation engine, but not part ofthe main translation process, is the Optimisationmodule, which is responsible for automaticallyimproving the performance of the two translationphases by fine-tuning the values of the varioussystem parameters.3.
Post-processing stage: The third stage is user-oriented and comprises (i) the Post-processingand (ii) the User Adaptation modules.
The firstmodule allows the user to modify the system-generated translations towards their requirements.The second module enables PRESEMT to adaptto this input so that it learns to generate transla-tions closer to the users?
requirements.
The post-processing stage represents work in progress tobe reported in future publications, the presentarticle focussing on the actual strategy for gener-ating the translation.653.
Processing of the bilingual corpusThe bilingual corpus contains literal translations,to allow the extrapolation of mapping informa-tion from SL to TL, though this may affect thetranslation quality.
The Phrase aligner module(PAM) performs offline SL ?
TL word andphrase alignment within this corpus.
PAM servesas a language-independent method for mappingcorresponding terms within a language pair, bycircumventing the problem of achieving com-patibility between the outputs of two differentparsers, one for the SL and one for the TL.
PAMrelies on a single parser for the one language andgenerates an appropriate phrasing model for theother language in an automated manner.The phrases are assumed to be flat and linguisti-cally valid.
As a parser, any available tool maybe used (the TreeTagger (Schmid, 1994) is usedin the present implementation for English).
PAMprocesses a bilingual corpus of SL ?
TL sentencepairs, taking into account the parsing informationin one language (in the current implementationthe TL side) and making use of a bilingual lexi-con and information on potential phrase heads;the output being the bilingual corpus aligned atword, phrase and clause level.
Thus, at a phrasallevel, the PAM output indicates how an SL struc-ture is transformed into the TL.
For instance,based on a sentence pair from the parallel corpus,the SL sentence with structure A-B-C-D is trans-formed into A?-C?-D?-B?, where X is a phrase inSL and X?
is a phrase in TL.
Further PAM detailsare reported in Tambouratzis et al (2011).The PAM output in terms of SL phrases isthen handed over to the Phrasing model genera-tor (PMG), which is trained to determine thephrasal structure of an input sentence.
PMGreads the SL phrasing as defined by PAM andgenerates an SL phrasing model using a probabil-istic methodology.
This phrasing model is thenapplied in segmenting any arbitrary SL text beinginput to the PRESEMT system for translation.PMG is based on the Conditional Random Fieldsmodel (Lafferty et al, 1999) which has beenfound to provide the highest accuracy.
The SLtext segmented into phrases by PMG is then in-put to the 1st translation phase.
For a new lan-guage pair, the PAM-PMG chain is implementedwithout any manual correction of outputs.4.
Organising the monolingual corpusThe language models created by the Corpusmodelling module can only serve translation dis-ambiguation purposes; thus another form of in-terfacing with the monolingual corpus is essen-tial for the word reordering task within eachphrase.
The size of the data accessed is verylarge.
Typically, a monolingual corpus contains 3billion words, 108 sentences and approximately109 phrases.
Since the models for the TL phrasesneed to be accessed in real-time to allow wordreordering within each phrase, the module usesthe phrase indexed representation of the mono-lingual corpus.
This phrase index is createdbased on four criteria: (i) phrase type, (ii) phrasehead lemma, (iii) phrase head PoS tag and (iv)number of tokens in the phrase.Indexing is performed by extracting allphrases from the monolingual corpus, each ofwhich is transformed to the java object instanceused within the PRESEMT system.
The phrasesare then organised in a hash map that allows mul-tiple values for each key, using as a key the 4aforementioned criteria.
Statistical informationabout the number of occurrences of each phrasein the corpus is also included.
Finally, each mapis serialised and stored in the appropriate file inthe PRESEMT path, with each file being given asuitable name for easy retrieval.
For example, forthe English monolingual corpus, all verb phraseswith head lemma ?read?
(verb) and PoS tag?VV?
containing 2 tokens in total are stored inthe file ?Corpora\EN\Phrases\VC\read_VV?.
Ifany of these criteria has a different value, then aseparate file is created (for instance for verbphrases with head ?read?
that contain 3 tokens).5.
Main translation engineThe PRESEMT translation process entails firstthe establishment of the sentence phrasal struc-ture and then the resolution of the intra-phrasalarrangements, i.e.
specifying the correct wordorder and deciding upon the appropriate candi-date translation.
Both phases involve searchingfor suitable matching patterns at two differentlevels of granularity, the first (coarse-grained)aiming at defining a TL-compatible ordering ofphrases in the sentence and the second (fine-grained) determining the internal structure ofphrases.
While the first phase utilises the smallbilingual corpus, the second phase makes use ofthe large monolingual corpus.
To reduce thetranslation time required, both corpora are proc-essed in advance and the processed resources arestored in such a form as be retrieved as rapidly aspossible during translation.665.1 Translation Phase 1: Structure selectionmoduleEach SL sentence input for translation is taggedand lemmatised and then it is segmented intophrases by the Phrasing model generator on thebasis of the SL phrasing model previously cre-ated.
For establishing the correct phrase orderaccording to the TL, the parallel corpus needs tobe pre-processed using the Phrase aligner moduleto identify word and phrase alignments betweenthe equivalent SL and TL sentences.During structure selection, the SL sentence isaligned to each SL sentence of the parallel cor-pus, as processed by the PAM and assigned asimilarity score using an algorithm from the dy-namic programming paradigm.
The similarityscore is calculated by taking into account editoperations (replacement, insertion or removal)needed to be performed in the input sentence inorder to transform it to the corpus SL sentence.Each of these operations has an associated cost,considered as a system parameter.
The alignedcorpus sentence that achieves the highest similar-ity score is the most similar one to the inputsource sentence.
This comparison process relieson a set of similarity parameters (e.g.
phrase type,phrase head etc.
), the values of which are opti-mised by employing the optimisation module.The implementation is based on the Smith-Waterman algorithm (Smith and Waterman,1981), initially proposed for determining similarregions between two protein or DNA sequences.The algorithm is guaranteed to find the optimallocal alignment between the two input sequencesat clause level.5.2 Translation Phase 2: Translationequivalent selection moduleAfter establishing the order of phrases withineach sentence, the second phase of the translationprocess is initiated, comprising two distincttasks.
The first task is to resolve the lexical am-biguity, by picking one lemma from each set ofpossible translations (as provided by a bilingualdictionary).
In doing so, this module makes useof the semantic similarities between words whichhave been determined by the Corpus Modellingmodule through a co-occurrence analysis on themonolingual TL corpus.
That way, the best com-bination of lemmas from the sets of candidatetranslations is determined for a given context.In the second task, the most similar phrases tothe TL structure phrases are retrieved from themonolingual corpus to provide local structuralinformation such as word-reordering.
A match-ing algorithm selects the most similar from theset of the retrieved TL phrases through a com-parison process, which is viewed as an assign-ment problem, using the Gale-Shapley algorithm(Gale and Shapley, 1962).6.
Experiments & evaluation resultsTo date MT systems based on the PRESEMTmethodology have been created for a total of 8languages, indicating the flexibility of the pro-posed approach.
Table 1 illustrates an indicativeset of results obtained by running automaticevaluation metrics on test data translated by the1st PRESEMT prototype for a selection of lan-guage pairs, due to space restrictions.In the case of the language pair English-to-German, these results are contrasted to the onesobtained when translating the same test set withMoses (Koehn et al, 2007).It is observed that forthe English-to-German language pair, PRESEMTachieved approximately 50% of the MOSESBLEU score and 80% of the MOSES with re-spect to the Meteor and TER scores.
These arereasonably competitive results compared to anestablished system such as Moses.
Furthermore,it should taken into consideration that (a) thePRESEMT results were obtained by the 1st sys-tem prototype, (b) PRESEMT is still under de-velopment and (c) only one reference translationwas used per sentence.Newer versions of the PRESEMT system, in-corporating more advanced versions of the dif-ferent modules are expected to result in substan-tially improved translation accuracies.
In particu-lar, the second translation phase will be furtherresearched.
In addition, experiments have indi-cated that the language modelling module canprovide additional improvement in the perform-ance.
Finally, refinements in PAM and PMGmay lead in increased translation accuracies.7.
LinksFind out more about the project on the PRE-SEMT website: www.presemt.eu.
Also, thePRESEMT prototype may be tried at:presemt.cslab.ece.ntua.gr:8080/presemt_interface_testAcknowledgmentsThe research leading to these results has receivedfunding from the European Community's Sev-enth Framework Programme (FP7/2007-2013)under grant agreement n?
248307.67ReferencesGale D. and L. S. Shapley.
1962.
College Admissionsand the Stability of Marriage.
American Mathe-matical Monthly, Vol.
69, pp.
9-14.Koehn P., H. Hoang, A. Birch, C. Callison-Burch, M.Federico, N. Bertoldi, B. Cowan, W. Shen, C.Moran, R. Zens, C. Dyer, O. Bojar, A. Constantin,and E. Herbst.
2007.
Moses: Open Source Toolkitfor Statistical Machine Translation.
In Proceedingsof the ACL-2007 Demo and Poster Sessions.Kuhn H. W. 1955.
The Hungarian method for the as-signment problem.
Naval Research Logistics Quar-terly, Vol.
2, pp.83-97.Lafferty J., A. McCallum, F. Pereira.
2001.
Condi-tional Random Fields: Probabilistic Models forSegmenting and Labelling Sequence Data.
Pro-ceedings of ICML Conference, pp.282-289.Munkres J.
1957.
Algorithms for the assignment andtransportation problems.
Journal of the Society forIndustrial and Applied Mathematics, Vol.
5, pp.32-38.Schmid, H. 1994.
Probabilistic Part-of-Speech Tag-ging Using Decision Trees, Proceedings of Interna-tional Conference on New Methods in LanguageProcessing, Manchester, UK.Smith T. F. and M. S. Waterman.
1981.
Identificationof Common Molecular Subsequences.
Journal ofMolecular Biology, 147: 195?197.Tambouratzis G., F. Simistira, S. Sofianopoulos, N.Tsimboukakis and M. Vassiliou 2011.
A resource-light phrase scheme for language-portable MT,Proceedings of the 15th International Conference ofthe European Association for Machine Translation,30-31 May 2011, Leuven, Belgium, pp.
185-192.Table 1 ?
PRESEMT Evaluation results for different language pairs.Language Pair Sentence set MetricsSL TL Number Source BLEU NIST Meteor TEREnglish German 189 web 0.1052 3.8433 0.1939 83.233German English 195 web 0.1305 4.5401 0.2058 74.804Greek English 200 web 0.1011 4.5124 0.2442 79.750English German 189 web 0.2108 5.6517 0.2497 68.190 MosesFigure 1 ?
PRESEMT system architecture.Tagging-Lemmatising,Lexicon look-up &Token generationPhase 1: Structure selectionFinaltranslationPhase 2: Translation equivalentselectionBilingualLexiconTL MonolingualCorpus &Corpus modelPost-processing& UseradaptationmodulesWEBOffline corporacreationPhrase alignermoduleCorpus creation& annotationmoduleCorpus modellingmodulePhrasing modelgeneratorSL textBilingual parallelcorpusBilingual alignedcorpusPhrase reordering of eachsentence in the SL textWord reordering &disambiguationOptimisation module68
