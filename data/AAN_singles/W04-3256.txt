Multi-document Biography SummarizationLiang Zhou, Miruna Ticrea, Eduard HovyUniversity of Southern CaliforniaInformation Sciences Institute4676 Admiralty WayMarina del Rey, CA 90292-6695{liangz, miruna, hovy} @isi.eduAbstractIn this paper we describe a biographysummarization system using sentenceclassification and ideas from informationretrieval.
Although the individual techniquesare not new, assembling and applying them togenerate multi-document biographies is new.Our system was evaluated in DUC2004.
It isamong the top performers in task 5?shortsummaries focused by person questions.1 IntroductionAutomatic text summarization is one form ofinformation management.
It is described asselecting a subset of sentences from a documentthat is in size a small percentage of the original andyet is just as informative.
Summaries can serve assurrogates of the full texts in the context ofInformation Retrieval (IR).
Summaries are createdfrom two types of text sources, a single documentor a set of documents.
Multi-documentsummarization (MDS) is a natural and moreelaborative extension of single-documentsummarization, and poses additional difficulties onalgorithm design.
Various kinds of summaries fallinto two broad categories: generic summaries arethe direct derivatives of the source texts; special-interest summaries are generated in response toqueries or topic-oriented questions.One important application of special-interestMDS systems is creating biographies to answerquestions like ?who is Kofi Annan??.
This taskwould be tedious for humans to perform insituations where the information related to theperson is deeply and sparsely buried in largequantity of news texts that are not obviouslyrelated.
This paper describes a MDS biographysystem that responds to the ?who is?
questions byidentifying information about the person-in-question using IR and classification techniques,and creates multi-document biographicalsummaries.
The overall system design is shown inFigure 1.To determine what and how sentences areselected and ranked, a simple IR method andexperimental classification methods bothcontributed.
The set of top-scoring sentences, afterredundancy removal, is the resulting biography.As yet, the system contains no inter-sentence?smoothing?
stage.In this paper, work in related areas is discussedin Section 2; a description of our biography corpusused for training and testing the classificationcomponent is in Section 3; Section 4 explains theneed and the process of classifying sentencesaccording to their biographical state; theapplication of the classification method inbiography extraction/summarization is described inSection 5; an accompanying evaluation on thequality of the biography summaries is shown inSection 6; and future work is outlined in Section 7.2 Recent DevelopmentsTwo trends have dominated automaticsummarization research (Mani, 2001).
One is thework focusing on generating summaries byextraction, which is finding a subset of thedocument that is indicative of its contents (Kupiecet al, 1995) using ?shallow?
linguistic analysis andstatistics.
The other influence is the exploration ofFigure 1.
Overall design of the biographysummarization system.?deeper?
knowledge-based methods forcondensing information.
Knight and Marcu (2000)equate summarization with compression atsentence level to achieve grammaticality andinformation capture, and push a step beyondsentence extraction.
Many systems use machine-learning methods to learn from readily alignedcorpora of scientific articles and theircorresponding abstracts.
Zhou and Hovy (2003)show a summarization system trained fromautomatically obtained text-summary alignmentsobeying the chronological occurrences of newsevents.MDS poses more challenges in assessingsimilarities and differences among the set ofdocuments.
The simple idea of extract-and-concatenate does not respond to problems arisenfrom coherence and cohesion.
Barzilay et al(1999) introduce a combination of extractedsimilar phrases and a reformulation throughsentence generation.
Lin and Hovy (2002) apply acollect ion of  known single-documentsummarization techniques, cooperating positionaland topical information, clustering, etc., and extendthem to perform MDS.While many have suggested that conventionalMDS systems can be applied to biographygeneration directly, Mani (2001) illustrates that theadded functionality of biographical MDS comes atthe expense of a substantial increase in systemcomplexity and is somewhat beyond thecapabilities of present day MDS systems.
Thediscussion was based in part on the only knownMDS biography system (Schiffman et al, 2001)that uses corpus statistics along with linguisticknowledge to select and merge description ofpeople in news.
The focus of this work was onsynthesizing succinct descriptions of people bymerging appositives from semantic processingusing WordNet (Miller, 1995).3 Corpus DescriptionIn order to extract information that is related to aperson from a large set of news texts written notexclusively about this person, we need to identifyattributes shared among biographies.Biographies share certain standard components.We annotated a corpus of 130 biographies of 12people (activists, artists, leaders, politicians,scientists, terrorists, etc.).
We found 9 commonelements: bio  (info on birth and death), f a m efactor, personality, personal, social, education,nationality, scandal, and w o r k .
Collectedbiographies are appropriately marked at clause-level with one of the nine tags in XML format, forexample:Martin Luther King <nationality>was born in Atlanta, Georgia</nationality>.
?
He <bio>wasassassinated on April 4, 1968</bio>.
?
King <education> enteredthe Boston University as adoctoral student </education>.
?In all, 3579 biography-related phrases wereidentified and recorded for the collection, amongthem 321 bio , 423 fame , 114 personality, 465personal, 293 social, 246 education, 95 nationality,292 scandal, and 1330 work.
We then used 100biographies for training and 30 for testing theclassification module.4 Sentence ClassificationRelating to human practice on summarizing,three main points are relevant to aid the automationprocess (Sp?rck Jones, 1993).
The first is a strongemphasis on particular purposes, e.g., abstractingor extracting articles of particular genres.
Thesecond is the drafting, writing, and revision cyclein constructing a summary.
Essentially as aconsequence of these first two points, thesummarizing process can be guided by the use ofchecklists.
The idea of a checklist is especiallyuseful for the purpose of generating biographicalsummaries because a complete biography shouldcontain various aspects of a person?s life.
From acareful analysis conducted while constructing thebiography corpus, we believe that the checklist isshared and common among all persons in question,and consists the 9 biographical elementsintroduced in Section 3.The task of fulfilling the biography checklistbecomes a classification problem.
Classification isdefined as a task of classifying examples into oneof a discrete set of possible categories (Mitchell,1997).
Text categorization techniques have beenused extensively to improve the efficiency oninformation retrieval and organization.
Here theproblem is that sentences, from a set of documents,need to be categorized into different biography-related classes.4.1 Task DefinitionsWe designed two classification tasks:1) 10 -Class: Given one or more texts about aperson, the module must categorize eachsentence into one of ten classes.
The classesare the 9 biographical elements plus a classcalled none that collects all sentences withoutbiographical information.
This fine-grainedclassification task will be beneficial ingenerating comprehensive biographies onpeople of interest.
The classes are:biofamepersonalitysocialeducationnationalityscandalpersonalworknone2) 2-Class: The module must make a binarydecision of whether the sentence should beincluded in a biography summary.
The classesare:biononeThe label bio appears in both task definitions butbears different meanings.
Under 10-Class, class biocontains information on a person?s birth or death,and under 2-Class it sums up all 9 biographicalelements from the 10-Class.4.2 Machine Learning MethodsWe experimented with three machine learningmethods for classifying sentences.Na?ve BayesThe Na?ve Bayes classifier is among the mosteffective algorithms known for learning to classifytext documents (Mitchell, 1997), calculatingexplicit probabilities for hypotheses.
Using kfeatures Fj: j = 1, ?, k, we assign to a givensentence S the class C:?C = argmaxCP(C |F1,F2,...,Fk)It can be expressed using Bayes?
rule, as (Kupiecet al, 1995):?P(S ?
C |F1,F2,...Fk) =P(F1,F2,...Fj| S ?
C)?P(S ?
C)P(F1,F2,...Fk)Assuming statistical independence of thefeatures:?P(S ?
C |F1,F2,...Fk) =P(Fj| S ?
C)?P(S ?
C)j=1k?P(Fjj=1k?
)Since P(Fj) has no role in selecting C:?P(S ?
C |F1,F2,...Fk) = P(Fj| S ?
C)?P(S ?
C)j=1k?We trained on the relative frequency ofP(Fj|S?C) and P(S?C), with add-one smoothing.This method was used in classifying both the 10-Class and the 2-Class tasks.Support Vector MachineSupport Vector Machines (SVMs) have beenshown to be an effective classifier in textcategorization.
We extend the idea of classifyingdocuments into predefined categories to classifyingsentences into one of the two biography categoriesdefined by the 2-Class task.
Sentences arecategorized based on their biographical saliency (apercentage of clearly identified biography words)and their non-biographical saliency (a percentageof clearly identified non-biography words).
Weused LIBSVM (Chang and Lin, 2003) for trainingand testing.Decision Tree (4.5)In addition to SVM, we also used a decision-treealgorithm, C4.5 (Quinlan, 1993), with the sametraining and testing data as SVM.4.3 Classification ResultsThe lower performance bound is set by abaseline system that randomly assigns abiographical class given a sentence, for both 10-Class and 2-Class.
2599 testing sentences are from30 unseen documents.10-Class ClassificationThe Na?ve Bayes classifier was used to performthe 10-Class task.
Table 1 shows its performancewith various features.Table 1.
Performance of 10-Class sentenceclassification, using Na?ve Bayes Classifier.Part-of-speech (POS) information (Brill, 1995)and word stems (Lovins, 1968) were used in somefeature sets.We bootstrapped 10395 more biography-indicating words by recording the immediatehypernyms, using WordNet (Fellbaum, 1998), ofthe words collected from the controlled biographycorpus described in Section 3.
These words arecalled Expanded Unigrams and their frequencyscores are reduced to a fraction of the originalword?s frequency score.Some sentences in the testing set were labeledwith multiple biography classes due to the fact thatthe original corpus was annotated at clause level.Since the classification was done at sentence level,we relaxed the matching/evaluating programallowing a hit when any of the several classes wasmatched.
This is shown in Table 1 as the Relaxedcases.A closer look at the instances where the falsenegatives occur indicates that the classifiermislabeled instances of class work as instances ofclass none.
To correct this error, we created a listof 5516 work specific words hoping that this wouldset a clearer boundary between the two classes.However performance did not improve.2-Class ClassificationAll three machine learning methods wereevaluated in classifying among 2 classes.
Theresults are shown in Table 2.
The testing data isslightly skewed with 68% of the sentences beingnone.In addition to using marked biographical phrasesas training data, we also expanded themarking/tagging perimeter to sentence boundaries.As shown in the table, this creates noise.5 Biography ExtractionBiographical sentence classification module isonly one of two components that supply the overallsystem with usable biographical contents, and isfollowed by other stages of processing (see systemdesign in Figure 1).
We discuss the other modulesnext.5.1 Name-filterA filter scans through all documents in the set,eliminating sentences that are direct quotes,dialogues, and too short (under 5 words).
Person-oriented sentences containing any variation (firstname only, last name only, and the full name) ofthe person?s name are kept for subsequent steps.Sentences classified as biography-worthy aremerged with the name-filtered sentences withduplicates eliminated.5.2 Sentence RankingAn essential capability of a multi-documentsummarizer is to combine text passages in a usefulmanner for the reader (Goldstein et al, 2000).This includes a sentence ordering parameter (Mani,2001).
Each of the sentences selected by thename-filter and the biography classifier is eitherrelated to the person-in-question via some newsevent or referred to as part of this person?sbiographical profile, or both.
We need amechanism that will select sentences that are ofinformative significance within the sourcedocument set.
Using inverse-term-frequency(ITF), i.e.
an estimation of information value,words with high information value (low ITF) aredistinguished from those with low value (highITF).
A sorted list of words along with their ITFscores from a document set?topic ITFs?displaysthe important events, persons, etc., from thisparticular set of texts.
This allows us to identifypassages that are unusual with respect to the textsabout the person.However, we also need to identify passages thatare unusual in general.
We have to quantify howthese important words compare to the rest of theworld.
The world is represented by 413307562w o r d s  f r o m  T R E C - 9  c o r p u s(http://trec.nist.gov/data.html), with correspondingITFs.The overall informativeness of each word w is:?Cw=ditfwWitfwwhere ditfis the document set ITF of word w andWitfis the world ITF of w .
A word that occursfrequently bears a lower Cwscore compared to ararely used word (bearing high information value)with a higher Cwscore.Top scoring sentences are then extractedaccording to:Table 2.
Classification results on 2-Class usingNa?ve Bayes, SVM, and C4.5.
?Cs=Cwii=1n?len(s)The following is a set of sentences extractedaccording to the method described so far.
Theperson-in-question is the famed cyclist LanceArmstrong.1.
Cycling helped him win hisbattle with cancer, andcancer helped him win theTour de France.2.
Armstrong underwent fourrounds of intensechemotherapy.3.
The surgeries andchemotherapy eliminated thecancer, and Armstrong beganhis cycling comeback.4.
The foundation supportscancer patients and survivorsthrough education, awarenessand research.5.
He underwent months ofchemotherapy.5.3 Redundancy EliminationSummaries that emphasize the differences acrossdocuments while synthesizing commoninformation would be the desirable final results.Removing similar information is part of all MDSsystems.
Redundancy is apparent in the Armstrongexample from Section 5.2.
To eliminate repetitionwhile retaining interesting singletons, we modified(Marcu, 1999) so that an extract can beautomatically generated by starting with a full textand systematically removing a sentence at a timeas long as a stable semantic similarity with theoriginal text is maintained.
The original extractionalgorithm was used to automatically create largevolume of (extract, abstract, text) tuples fortraining extraction-based summarization systemswith (abstract, text) input pairs.Top-scoring sentences selected by the rankingmechanism described in Section 5.2 were the inputto this component.
The removal process wasrepeated until the desired summary length wasachieved.Applying this method to the Armstrong example,the result leaves only one sentence that containsthe topics ?chemotherapy?
and ?cancer?.
Itchooses sentence 3, which is not bad, thoughsentence 1 might be preferable.6 Evaluation6.1 OverviewExtrinsic and intrinsic evaluations are the twoclasses of text summarization evaluation methods(Sparck Jones and Galliers, 1996).
Measuringcontent coverage or summary informativeness is anapproach commonly used for intrinsic evaluation.It measures how much source content waspreserved in the summary.A complete evaluation should includeevaluations of the accuracy of componentsinvolved in the summarization process (Schiffmanet al, 2001).
Performance of the sentenceclassifier was shown in Section 4.
Here we willshow the performance of the resulting summaries.6.2 Coverage EvaluationAn intrinsic evaluation of biography summarywas recently conducted under the guidance ofDocument Understanding Conference (DUC2004)using the automatic summarization evaluation toolROUGE (Recall-Oriented Understudy for GistingEvaluation) by Lin and Hovy (2003).
50 TRECEnglish document clusters, each containing onaverage 10 news articles, were the input to thesystem.
Summary length was restricted to 665bytes.
Brute force truncation was applied on longersummaries.The ROUGE-L metric is based on LongestCommon Subsequence (LCS) overlap (Saggion etal., 2002).
Figure 2 shows that our system (86)performs at an equivalent level with the bestsystems 9 and 10, that is, they both lie within oursystem?s 95% upper confidence interval.
The 2-class classification module was used in generatingthe answers.
The figure also shows theperformance data evaluated with lower and higherconfidences set at 95%.
The performance data arefrom official DUC results.Figure 3 shows the performance results of oursystem 86, using 10-class sentence classification,comparing to other systems from DUC byreplicating the official evaluating process.
Onlysystem 9 performs slightly better with its scorebeing higher than our system?s 95% upperconfidence interval.A baseline system (5) that takes the first 665bytes of the most recent text from the set as theresulting biography was also evaluated amongstthe peer systems.
Clearly, humans still perform at alevel much superior to any system.Measuring fluency and coherence is alsoimportant in reflecting the true quality of machine-generated summaries.
There is no automated toolfor this purpose currently.
We plan to incorporateone for the future development of this work.6.3 DiscussionN-gram recall scores are computed by ROUGE,in addition to ROUGE-L shown here.
While cosinesimilarity and unigram and bigram overlapdemonstrate a sufficient measure on contentcoverage, they are not sensitive on howinformation is sequenced in the text (Saggion et al,2002).
In evaluating and analyzing MDS results,metrics, such as ROUGE-L, that consider linguisticsequence are essential.Radev and McKeown (1998) point out whensummarizing interesting news events from multiplesources, one can expect reports with contradictoryand redundant information.
An intelligentsummarizer should attain as much information aspossible, combine it, and present it in the mostconcise form to the user.
When we look at thedifferent attributes in a person?s life reported innews articles, a person is described by the jobpositions that he/she has held, by educationinstitutions that he/she has attended, and etc.
Thosedata are confirmed biographical information anddo not bear the necessary contradiction associatedwith evolving news stories.
However, we do feelthe need to address and resolve discrepancies if wewere to create comprehensive and detailed0.250.30.350.40.450.50.55B E F H G A D C 9 10 11 12 13 86 15 16 17 18 19 20 5 22 23 24 25 26 27 28 29 30 31ROUGE-L95% CI Lower95% CI HigherFigure 2.
Official ROUGE performance results from DUC2004.
Peer systems are labeled with numeric IDs.Humans are numbered A?H.
86 is our system with 2-class biography classification.
Baseline is 5.0.170.220.270.320.370.420.470.520.57B F E G H A D C 9 10 11 12 13 86 15 16 17 18 19 20 21 22 23 24 25 5 27 28 29 30 31ROUGE-L95% CL Lower95% CL HigherFigure 3.
Unofficial ROUGE results.
Humans are labeled A?H.
Peer systems are labeled with numeric IDs.86 is our system with 10-class biography classification.
Baseline is 5.biographies on people-in-news since miscellaneouspersonal facts are often overlooked and told inconflicting reports.
Misrepresented biographicalinformation may well be controversies and maynever be clarified.
The scandal element from ourcorpus study (Section 3) is sufficient to identifyinformation of the disputed kind.Extraction-based MDS summarizers, such as thisone, present the inherent problem of lacking thediscourse-level fluency.
While sentence orderingfor single document summarization can bedetermined from the ordering of sentences in theinput article, sentences extracted by a MDS systemmay be from different articles and thus need astrategy on ordering to produce a fluent surfacesummary (Barzilay et al, 2002).
Previoussummarization systems have used temporalsequence as the guideline on ordering.
This isespecially true in generating biographies where aperson is represented by a sequence of events thatoccurred in his/her life.
Barzilay et al alsointroduced a combinational method with analternative strategy that approximates theinformation relatedness across the input texts.
Weplan to use a fixed-form structure for the majorityof answer construction, fitted for biographies only.This will be a top-down ordering strategy, contraryto the bottom-up algorithm shown by Barzilay etal.7 Conclusion and Future WorkIn this paper, we described a system that uses IRand text categorization techniques to providesummary-length answers to biographical questions.The core problem lies in extracting biography-related information from large volumes of newstexts and composing them into fluent, concise,multi-document summaries.
The summariesgenerated by the system address the question aboutthe person, though not listing the chronologicalevents occurring in this person?s life due to thelack of background information in the newsarticles themselves.
In order to obtain a ?normal?biography, one should consult other means ofinformation repositories.Question: Who is Sir John Gielgud?Answer: Sir John Gielgud, one ofthe great actors of the Englishstage who enthralled audiences formore than 70 years with hiseloquent voice and consummateartistry, died Sunday at his homeGielgud?s last major film role wasas a surreal Prospero in PeterGreenaway?s controversialShakespearean rhapsody.Above summary does not directly explain whothe person-in-question is, but indirectly does so inexplanatory sentences.
We plan to investigatecombining fixed-form and free-form structures inanswer construction.
The summary would includean introductory sentence of the form ?x is<type/fame-category> ?
?, possibly throughquerying outside online resources.
A main bodywould follow the introduction with an assembly ofchecklist items generated from the 10-Classclassifier.
A conclusion would contain open-endeditems of special interest.Furthermore, we would like to investigatecompression strategies in creating summaries,specifically for biographies.
Our biography corpuswas tailored for this purpose and will be thestarting point for further investigation.AcknowledgementWe would like to thank Chin-Yew Lin from ISIfor many insightful discussions on MDS,biography generation, and ROUGE.ReferencesRegina Barzilay, Kathleen McKeown, and MichaelElhadad.
1999.
Information fusion in the contextof multi-document summarization.
InProceedings of the 37thAnnual Meeting of theAssociation of Computational Linguistics (ACL-99), University of Maryland, 1999, pp.
550?557.Regina Barzilay, Noemie Elhadad, KathleenMcKeown.
2002.
Inferring strategies forsentence ordering in multidocumentsummarization.
JAIR, 17:35?55, 2002.Eric Brill.
1995.
Transformation-based error-driven learning and natural language processing:A case study in part of speech tagging.Computational Linguistics, December 1995.Chih-Chung Chang and Chih-Jen Lin.
2003.LIBSVM?A Library for support vectormachines.http://www.csie.ntu.edu.tw/~cjlin/libsvm/Christiane Fellbaum, editor.
WordNet: Anelectronic lexical database.
Cambridge, MA:MIT Press.Jade Goldstein, Vibhu Mittal, Jaime Carbonell, andMark Kantrowitz.
2000.
Multi-documentsummarization by sentence extraction.
InProceedings of the ANLP?2000 Workshop onAutomatic Summarization,  40?48.
NewBrunswick, New Jersey: Association forComputational Linguistics.Thorsten Joachims.
1998.
Text categorization withsupport vector machines: Learning with manyrelevant features.
In Proceedings of theEuropean Conference on Machine Learning(ECML), pages 137?142.Kevin Knight and Daniel Marcu.
2000.
Statistics-Based summarization step one: sentencecompression.
In Proceedings of the 17thNationalConference of the American Association forArtificial Intelligence (AAAI 2000).Julian Kupiec, Jan Pedersen, and Francine Chen.1995.
A trainable document summarizer.
InSIGIR?95 , Proceedings of the 18thAnnualInternational ACM SIGIR Conference onResearch and Development in InformationRetrieval, pp.
68?73.Chin-Yew Lin and Eduard Hovy.
2002.
Automatedmulti-document summarization in NeATS.
InProceedings of the Human LanguageTechnology Conference (HLT2002), San Diego,CA, U.S.A., March 23-27, 2002.Chin-Yew Lin and Eduard Hovy.
2003.
Automaticevaluation of summaries using n-gram co-occurrence statistics.
In HLT-NAACL 2003:Main Proceedings, pp.150?157.Julie Beth Lovins.
1968.
Development of astemming algorithm.
Mechanical translation andcomputational linguistics, 11:22?31, 1968.Inderjeet Mani.
2001.
Automatic summarization(natural language processing, 3).Inderjeet Mani.
2001.
Recent developments in textsummarization.
In CIKM?2001, Proceedings ofthe Tenth International Conference onInformation and Knowledge Management,November 5-10, 2001, 529?531.Daniel Marcu.
1999.
The automatic construction oflarge-scale corpora for summarization research.The 22ndInternational ACM SIGIR Conferenceon Research and Development in InformationRetrieval (SIGIR?99), pages 137-144, Berkeley,CA, August 1999.George Miller.
1995.
WordNet: a lexical databasefor English.
Communications of the ACM, pages39?41.Tom Mitchell.
1997.
Machine Learning.
McGrawHill, 1997.Ross J. Quinlan.
1993.
C4.5: Programs formachine learning.
San Mateo, CA: MorganKaufmann.Dragomir R. Radev, Kathleen McKeown.
1998.Generating natural language summaries frommultiple on-line sources.
ComputationalLinguistics 24(3): 469?500 (1998).Horacio Saggion, Dragomir Radev, Simone Teufel,and Wai Lam.
Meta-evaluation of summaries ina cross-lingual environment using content-basedmetrics.
In Proceedings of COLING?2002,Taipei, Taiwan, August 2002.Barry Schiffman, Inderjeet Mani, and KristianConcepcion.
2001.
Producing biographicalsummaries: combining linguistic knowledge withcorpus statistics.
In Proceedings of the 39thAnnual Meeting of the Association forComputational Linguistics (ACL?2001),450?457.
New Brunswick, New Jersey:Association for Computational Linguistics.Karen Sp?rck Jones and Julia R. Galliers.
1996.Evaluating Natural Language ProcessingSystems: An Analysis and Review.
Lecture Notesin Artificial Intelligence 1083.
Berlin: Springer.Karen Sp?rck Jones.
1993.
What might be in asummary?
Information Retrieval 1993: 9?26.Liang Zhou and Eduard Hovy.
A web-trainedextraction summarization system.
InProceedings of the Human LanguageTechnology Conference (HLT-NAACL 2003),pages 284?290.
