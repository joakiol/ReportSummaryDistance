Hybrid Text Summarization: Combining External Relevance Meas-ures with Structural AnalysisGian Lorenzo Thione,  Martin van den Berg, Livia Polanyi and Chris CulyFX Palo Alto Laboratory3400 Hillview Ave, Bldg.
4Palo Alto, CA 94304{thione|vdberg|polanyi|culy}@fxpal.comAbstractIn this paper, a novel linguistically advanced textsummarization system is described for reducingthe minimum size of highly readable variable -sized summaries of digitized text documents pro-duced by text summarization methods that usediscourse analysis to rank sentences for inclusionin the final summary.
The basic algorithm used inFXPAL?s PALSUMM text summarization sys-tem combines text structure methods that pre-serve readability and correct reference resolutionwith statistical methods to reduce overall sum-mary length while promoting the inclusion ofimportant material.1 IntroductionIn this paper, we present algorithms to address theshortcomings of both purely structural and purelystatistical methods of sentence extraction summa-rization.
We present the PALSUMM hybrid sum-marization algorithms that use structural methodsbased on discourse parsing to construct a repre-sentation of the text, apply conventional statisticalmethods to identify salient information (See dis-cussion and references in Marcu 2003) and thenconstruct a partial discourse tree that includes theinformation identified as most salient along withthe text at all nodes dominating that salient infor-mation.
Optionally, sentence compression tech-niques are applied to the resulting summary tofurther compress text length (Grefenstette, 1998;Knight and Marcu, 2002).The novelty of our approach lies in combiningtext structural methods with sentence extractionmethods which evaluate relevance on the basis ofexternal factors such as lexical frequency or lexi-cal field information in the specific document, inrelated or documents in general or, alternativelyby matching lexical items in a query against lexi-cal items in a document.
The sentences selectedby the external oracle are then providing contextfor anaphora resolution and reference interpreta-tion through inclusion of hierarchically superordi-nate information from the structural tree.2 The PALSUMM SystemPALSUMM summarization algorithms operate ondata structures generated by FX Palo Alto?s Lin-guistic Discourse Analysis System (LIDAS).LIDAS is a computational discourse parser im-plementing the Unified Linguistic DiscourseModel (U-LDM).
A description of the LIDASsystem and the U-LDM as well as a summary ofan article from the New Yorker are described inearlier work (Polanyi et al 2004a, b, Thione2004).
Due to space limitations we can onlysketch the main points of the system here.The LIDAS parser itself is purely symbolic.
Itparses a text discourse segment by discourse seg-ment to construct a tree that captures discoursecontinuity and accessibility relations between thesegments.
The tree identifies what discourse con-stituents are available for further development andwhat information given by discourse constituentsis available to be referred to.
We use the fact thatthe resulting tree encodes (semantic) accessibilityrelations between the segments, and not rhetoricalrelations, to guarantee that the pruning algorithmused to summarize preserve antecedents for ana-phors thus fostering readability.The basic units of this theory (Basic DiscourseUnit or BDUs) are the syntactic reflexes of lin-guistically realized minimal semantic unit ofmeaning1 or functions, interpreted relative to thecontext given by the preceding discourse.
To iden-tify the BDUs in a text, LIDAS relies on theXerox Linguistic Environment to parse sentencesfrom a text (Maxwell and Kaplan, 1989).
Aftersentential parsing is complete, the XLE sentenceparse trees are segmented into BDUs using a setof robust sentence and discourse level rules de-scribed in detail in Polanyi et al2004a, b. Afterparsing, BDUs (which need not be contiguous) arerecombined into one or more discourse trees cor-responding to (parts of) the sentence, called BDU-trees.For each BDU-tree, one BDU, normally themain clause of a sentence or a compound unit ofdiscourse directly derived from it, is designated asthe Main-BDU (M-BDU) and is represented bythe root node of the BDU-tree.
The entire BDU-tree is attached as a unit to the emerging OpenRight Tree representation of the structure of thediscourse by relating syntactic, semantic and lexi-cal information in the M-BDU (and preposed ad-verbial modifiers, clauses and ?cue?
words) toinformation available in nodes along the rightedge of the tree using formal linguistic discourseattachment rules involving relationships amongsemantic, syntactic and lexical information tocompute both the site of attachment and the at-tachment relation.Although a full discussion of these rules liesbeyond the scope of this paper, Table 1 sketchessome simple principles which are both languageand domain independent.2These rules are weighted and ordered in appli-cation, and multiple rules may ?vote?
for the sameor different attachment points and discourse rela-tions.
The precise relationships among the rulesremains a subject for future research.The U-LDM is similar in form to RST, but itsprimitives are rather different.
Whereas RST takesrhetorical relations as primitives, the LDM takesits primitives from syntactic structure.
The ontol-ogy of LDM relations has three top relations: co-ordination, subordination and n-ary.1 We understand a minimum unit of Meaning to communicate informationabout not more than one ?event?
or state of affairs in a ?possible world?
ofsome type (roughly event -type predicates); while a minimal Functional unitencodes information about how previously occurring (or possibly subsequent)utterances relate structurally, semantically, interactionally or rhetorically toother units in the discourse or context in which the discourse takes place(Greetings, discourse PUSH/POP markers, connectives etc.
are all Functionalsegments).2 One reviewer remarked, quite correctly: ?how a sentence is attached to theemerging representation of the structure of the discourse ?
is the heart of  thealgorithm?.
This issue is discussed in detail in Polanyi et al, 2004a,b  ; Thioneet al 2004.Evidence attachment is a subordinationSyntactic promotion: If the subject of an M-BDUco-refers with the object of the AP.Sub-cases: If the subject of the M-BDU refers to asub-case of the subject of the AP.
Sub-cases includesubsets (all children /some children), sub-types  (peo-ple/children), etc.Verbal properties: If the tense, aspect, modality orgenericity of the verbs are different.Evidence attachment is a coordinationNarrative: If the verbs express events.Lists: If the subjects are synonyms/antonyms and/orthe syntactic structures of M-BDU and AP are suffi-ciently similar.Table 1: Some simple examples of dis-course principlesCoordinations express a symmetric relation-ship between the children, including: lists, narra-tives, etc.
Subordinations express an asymmetricrelationship between children, including: elabora-tions, interruptions, etc.
Finally, n-aries include anumber of cases where the structure is defined byspecific language constructions.
Note that theseconstructions are not arbitrary, and often followfrom (sentence) syntactic constructions.
Examplesinclude scope setting operators and units (whenjohn comes, he will be happy), and more or lessfixed forms like greetings and question-answerpairs, etc.
It is the practice to also consider genre-specific structures (e.g.
?a paper consists of a title,an abstract, an introduction, some sections, a con-clusion, and references?)
to be n-aries.Because to characterize the large structure ofthe discourse we only need to refer to coordina-tions, subordinations and n-aries, it is oftenclaimed that the number of relations in the LDMis much smaller than in RST, even though strictlyspeaking this depends on which versions of LDMand RST one compares.
The real difference be-tween the two theories lies in the rather differentorigins of the rules.All non-terminal nodes in U-LDM trees arefirst class citizens and contain, in addition to anode label, content and context information inher-ited from child nodes.
Under RST only terminalnodes have content; non-terminal nodes that rep-resent the relationships obtaining among spans ofthe text longer than one sentence are labeled forthe relationship between daughter nodes only.As in Summarist (Hovy and Lin, 1999), oncethe source text has been parsed and a discoursetree incrementally constructed, text summarizationalgorithms are applied to the resulting tree.
How-ever, the difference between constructing asemantic rather than a rhetorical representation ofthe text  accounts for how PALSUMM summariespreserve readability and reference resolution: be-cause the entire analysis involves matching se-mantically defined contextual units to theappropriate contexts available on the tree, nodesthat structurally dominate other nodes necessarilycontain the information needed to contextuallyinterpret the dominated units.3 Pruning PALSUMM TreesSummarization methods based on discourse struc-ture all rely on assigning a numeric value to allintermediate and leaf nodes encoding their impor-tance , based on the labels at the nodes.
The dif-ference between different methods orig inates inthe different ways this importance measure is cal-culated.
Because RST (Marcu, 2000) and U-LDMtrees differ, there are key differences between thesimple pruning methods applied to U-LDM treesas opposed to RST trees.Under the U-LDM theory of discourse, theasymmetric relationship expressed by subordina-tions implicitly encodes a notion of importance.The subordinated child elaborates or further quali-fies the head, or temporarily interrupts the flow ofdiscourse.
Subordinated material is almost alwaysless important to the main line of the text thansubordinating material: the level of embeddingthus gives a first rough measure of importance ofa unit of discourse.Our original summarization algorithm, Sym-Trim, used the level of embedding directly.
Itpruned the tree at a given level of embedding, andgenerated a summary based on the span of theremaining tree.
The number of possible summarylengths, however, was restricted to the number ofembedding levels, resulting in a discreet numberof summaries of a fixed length, often ones longerthan desired.
This led to a need for more subtlepruning algorithms.3.1 Solving the SymTrim RestrictionThere are two theoretic problems that underlie thepractical problems of SymTrim.
First, across theboard pruning at a fixed level is of limited utility.If two sections of a document differ significantlyin size, the larger section will have more space fordeeper sub-trees.
Consequently, units of equalimportance may occur at deeper levels of largersub-trees.Secondly, no method that relies solely onpurely structural information can determine whatparts of the document contain important informa-tion.
For this an approximation the meaning of theunits is needed.
A description of the relationshipsamong them does not suffice.We address the first issue by not trimming thetree at an absolute level, but at a level relative tothe depth of the sub-branch in which a node isfound.
We address the second issue by skewingthe pruning level using statistical methods3 as anoracle to indicate relative importance.3.2 Score Adjustment and PercolationWe assign every node a relative depth T(l), basedon the local and global structure of the tree branchto which it belongs, calculated as follows: (1) es-tablish the absolute depth D(l) of each node, (2)calculate an embedding branch weight W(l) bypercolating the value of D(l) up from the leavesaccording to the percolation algorithm outlined inFigure 1, (3) assign each node a relative depth T(l)= 1 ?
(D(l) ?
1) / W(l).4We also compute a statistical score that ap-proximates the ?semantic importance?
of everynode.
To do so, we begin by seeding every leafnode l with a statistical seed S(l) using the MEADstatistical summarizer.
Each segment is scored byMEAD in the context of the full document, with ascore that mirrors its judgment of the relevance ofthat segment for a summary.
MEAD?s metricsinclude: TF/IDF cosine similarity between a seg-ment and the document ?
optionally skewed to-wards a query entered by the user, the relativeposition of a segment within the document, anadverse score against segments deemed as toosimilar to the current summary, and our own im-plementation of a feature concerning the presenceof certain cue words (Hirschberg and Litman,1993).
After scoring, the values are percolated upthrough the tree, as before.
During percolation ofboth structurally and statistically obtained scores,the new value of a node that receives a higherscore from a child node is percolated downwardsthrough all non-subordinated children.
Children of3 We use the publicly available MEAD (Radev et al 2003).
Adopting a sen-tence extraction approach, it is capable of assigning scores to each and everysentence.
PALSUMM does its own discourse segmentation and sends thesegments to MEAD as if they were sentences.
This allows us to assign inde-pendent scores to discourse segments, thus enabling sub -sentential summariza-tion (segment-extraction vs. sentence extraction) and yielding morecompressed yet still highly readable summ aries.4 The expression for T(l) was chosen to assign the top node relative depth 1.coordinations and n-aries are considered equallyrelevant and scored equally, whereas subordinatedchildren are less relevant then subordinatingones.5 After percolation we normalize the statisti-cal scores, dividing by the maximum occurringvalue.Different summarization algorithms result fromthe choice of seeding algorithms and methods ofcombining scores.
Note that the percolation algo-rithm in Figure 1 respects structural embedding byalways assigning lower or equal scores to subor-dinated nodes.3.3 Pruning AlgorithmsIn order for summaries to maintain textual coher-ence and readability, constituents that contain con-textual or referential information necessary tointerpreting other constituents selected for thesummary must be marked for inclusion.
For anynode, this information is available in nodes thatare siblings of the same coordination or n-ary, andin nodes that dominate it through subordination-type relations.
As long as the score assigned tonodes respects subordinations as in Figure 1, anypruning of the tree that excludes constituentswhose final relevance score is smaller than a cho-sen value is guaranteed to preserve the antece-dents for the anaphora in the text, preserving well-formedness of the resulting tree and the readabil-ity of the summary it yields.In Table 2 we list four different final score as-signments, based on the embedding level of thenodes (L), their percolated statistical score (S) andthe percolated relative depth score (T).SymTrim F = 1/LSymTrim-R F =1/THybReduce F = 1/L * SHybReduce-R F = 1/T * STable 2: Different scoring algorithms.5 In a modified percolation scheme, downward percolation is restricted topreceding siblings in discourse-level coordination nodes.
This is a result of thefact that contextual information necessary to preserve readability and referen-tial integrity must appear before access.After scores are calculated and combined, arelative threshold is computed by sorting the set ofconstituent by final score and identifying the cut-off value that more closely approximates the re-quest of the user in terms of desired summarylength.
Note that the root node will always havenormalized score 1 and will therefore always beincluded in a full summary.
64 Evaluating PALSUMMThe PALSUMM corpus contains over 300FXPAL Technical Reports in a wide range of do-mains.
The Reports vary in size from 10 to 30pages.
To evaluate the readability of summariesand create a baseline for evaluating the SymTrim-R and HybRduce-R algorithms, we conducted asmall pilot study on five documents selected fromthe corpus.
The documents were hand-annotatedwith their U-LDM discourse structures.
The Sym-Trim-R and HybReduce-R variants were thenautomatically applied to these discourse struc-tures, and the summaries submitted to a panel of12 non-experts.
The panelists were asked to judgethe summaries on a 6-point scale for readabilityby answering a set of questions including "Howreadable is this summary?"
and "Did you get con-fused at any point in the summary??
The initialresults suggest that the discourse algorithms pro-duced readable summaries and that the relativeeffectiveness of the discourse algorithms variesaccording to some still to be determined propertyof the documents.5 ConclusionStructural sentence extraction systems includingSummarist and PALSUMM that create summariesby choosing sentences or parts of sentences corre-sponding to nodes at a given level of depth of a6 In other applications of the algorithms described here, where the purpose isnot that of retrieving a full summary of a document but rather that of buildingthe necessary minimal context for interpreting a certain selected discourseconstituent, percolation is only limited to the immediate surrounding context,where certain relations (usually ad-hoc binaries) constitute a barrier to furtherpercolation towards upwards constituent.1.
For seeding V, each leaf node l is assigned an a priori score V(l).2.
Repeat for each node c0 with children c1 ?cn, and relation type R until  no values change:2.1 Percolate or maintain highest score: V(c0) := maxi (V(ci)) , 0=i=n2.2 Percolate highest score downwards into non-subordinated nodes:if R is subordination and ci is  the head of n: V(ci) := V(c0) if V(ci) < V(c0)if R is coordination or n-aries: for all i=n, V(ci) := V(c0) if V(ci) < V(c0),Figure 1: General percolation algorithm.
Both statistical seeds (V=S) and structural seeds(V=T) are percolated according to this algorithm, resulting in values S(n) and T(n) for nodes n.tree structured representation of the structure ofthe text produce excellent summaries that preservethe style and ?flavor?
of the original text.
How-ever, the summaries constructed may be longerthan needed, including information that could beomitted without serious loss of informativity7.
Theexcessive length results from the top-down natureof standard structural extraction algorithms whichstart by choosing the top context and then includesevery possible sub-context down to a certain level.In this paper, we have proposed hybrid algo-rithms which capitalize on the strengths of thesemethods while compensating for their limitationsby proposing additional manipulations on the basetrees.
In our view, the value of the summarizationmethods described here, is the ability to compressa summary further without substantia l loss of in-formativity.
For summaries, especially those de-signed for display on various sized devices, thework presented here constitutes an advance in thestate of the art.6 AcknowledgementsThe authors would like to thank Dr. Sara Bly(Sara Bly Consulting) who designed and carriedout the evaluation and Dr. Candace Kamm ofFXPAL who provided help and guidance in thedesign and organization of the study.7 ReferencesGregory Grefenstette.
1998.
Producing intelligenttext reduction to provide an audio screeningservice for the blind.
Working Notes of AAAISpring Symposium on Intelligent Text Summa-rization, Pages 111?118,  Stanford.Julia Hirschberg and Diane Litman.
1993.
Empir i-cal studies on the disambiguation of cuephrases.
Computational Linguistics, 19-3:501-530.Ed Hovy and C-Y.
Lin.
1999.
Automated TextSummarization in SUMMARIST.
In I. Maniand M. Maybury (eds), Advances in AutomatedText Summarization, pages 81-94, MIT Press,Cambridge.Kevin Knight and Daniel Marcu.
2000.
StatisticsBased Summarization ?
Step One: SentenceCompression.
In AAAI-2000 Proceedings,pages 703-710, Austin TX.7 Some of this excessive length can be addressed through compressing lessrelevant aspects of constituent sentences as in Grefenstette, 1998; Knight andMarcu, 2002.Daniel Marcu.
2000.
The Theory and Practice ofDiscourse Parsing and Summarization.
TheMIT Press,  Cambridge, MA.Daniel Marcu.
2003.
Automatic abstracting.
InEncyclopedia of Library and Information Sci-ence, pages 245-256.John Maxwell and Ronald M. Kaplan.
1989.
Anoverview of disjunctive constraint satisfaction.In Proceedings of the International Workshopon Parsing Technologies.
Pittsburgh, PA.Livia Polanyi, Martin van den Berg, Chris Culy,Gian Lorenzo Thione, and David Ahn.
2004a.A rule based approach to discourse parsing.
5thSigDial Workshop.Livia Polanyi, Martin van den Berg, Chris Culy,and Gian Lorenzo Thione 2004b.
Sententialstructure and discourse parsing.
Discourse An-notation Workshop, ACL04.Dragomir Radev, Timothy Allison, Sasha Blair-Goldensohn, and John Blitzer, Arda ?elebi,Elliott Drabek, Wai Lam, Danyu Liu, Hong Qi,Horacio Saggion, Simone Teufel, MichaelTopper, and Adam Winkel.
2003.
The MEADMultidocument Summarizer.http://www.summarization.com/mead/Radu Soricut and Daniel Marcu.
2003.
Sentencelevel discourse parsing using syntactic and lexi-cal information.
In Proceedings ofHLT/NAACL, May 27-June 1, Edmonton, Can-ada.Gian Lorenzo Thione, Martin van den Berg, LiviaPolanyi, and Chris Culy.
2004.
LiveTree: Anintegrated workbench for discourse processing.Discourse Annotation Workshop, ACL04.
