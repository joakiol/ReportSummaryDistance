Software Engineering, Testing, and Quality Assurance for Natural Language Processing, pages 14?20,Columbus, Ohio, USA, June 2008. c?2008 Association for Computational LinguisticsEvaluating the Effects of Treebank Size in a Practical Application forParsingKenji Sagae1, Yusuke Miyao1, Rune S?tre1 and Jun'ichi Tsujii1,2,31Department of Computer Science, Univerisity of Tokyo, Japan2School of Computer Science, University of Manchester3National Center for Text Mining, Manchester, UK{sagae,yusuke,rune.saetre,tsujii@is.s.u-tokyo.ac.jp}AbstractNatural language processing modules such aspart-of-speech taggers, named-entity recog-nizers and syntactic parsers are commonlyevaluated in isolation, under the assumptionthat artificial evaluation metrics for individualparts are predictive of practical performanceof more complex language technology sys-tems that perform practical tasks.
Althoughthis is an important issue in the design and en-gineering of systems that use natural languageinput, it is often unclear how the accuracy ofan end-user application is affected by parame-ters that affect individual NLP modules.
Weexplore this issue in the context of a specifictask by examining the relationship betweenthe accuracy of a syntactic parser and theoverall performance of an information extrac-tion system for biomedical text that includesthe parser as one of its components.
Wepresent an empirical investigation of the rela-tionship between factors that affect the accu-racy of syntactic analysis, and how thedifference in parse accuracy affects the overallsystem.1 IntroductionSoftware systems that perform practical tasks withnatural language input often include, in addition totask-specific components, a pipeline of basic natu-ral language processing modules, such as part-of-speech taggers, named-entity recognizers, syntacticparsers and semantic-role labelers.
Although suchbuilding blocks of larger language technology so-lutions are usually carefully evaluated in isolationusing standard test sets, the impact of improve-ments in each individual module on the overallperformance of end-to-end systems is less wellunderstood.
While the effects of the amount oftraining data, search beam widths and various ma-chine learning frameworks have been explored indetail with respect to speed and accuracy in basicnatural language processing tasks, how these trade-offs in individual modules affect the performanceof the larger systems they compose is an issue thathas received relatively little attention.
This issue,however, is of great practical importance in theeffective design and engineering of complex soft-ware systems that deal with natural language.In this paper we explore some of these issuesempirically in an information extraction task in thebiomedical domain, the identification of protein-protein interactions (PPI) mentioned in papers ab-stracts from MEDLINE, a large database of bio-medical papers.
Due in large part to the creation ofbiomedical treebanks (Kulick et al, 2004; Tateisiet al, 2005) and rapid progress of data-drivenparsers (Lease and Charniak, 2005; Nivre et al,2007), there are now fast, robust and accurate syn-tactic parsers for text in the biomedical domain.Recent research shows that parsing accuracy ofbiomedical corpora is now between 80% and 90%(Clegg and Shepherd, 2007; Pyysalo et al, 2007;Sagae et al, 2008).
Intuitively, syntactic relation-ships between words should be valuable in deter-mining possible interactions between entitiespresent in text.
Recent PPI extraction systemshave confirmed this intuition (Erkan et al, 2007;S?tre et al, 2007; Katrenko and Adriaans, 2006).While it is now relatively clear that syntacticparsing is useful in practical tasks that use naturallanguage corpora in bioinformatics, several ques-14tions remain as to research issues that affect thedesign and testing of end-user applications, includ-ing how syntactic analyses should be used in apractical setting, whether further improvements inparsing technologies will result in further im-provements in practical systems, whether it is im-portant to continue the development of treebanksand parser adaptation techniques for the biomedi-cal domain, and how much effort should be spenton comparing and benchmarking parsers for bio-medical data.
We attempt to shed some light onthese matters by presenting experiments that showthe relationship of the accuracy of a dependencyparser and the accuracy of the larger PPI systemthat includes the parser.
We investigate the effectsof domain-specific treebank size (the amount ofavailable manually annotated training data for syn-tactic parsers) and final system performance, andobtain results that should be informative to re-searchers in bioinformatics who rely on existingNLP resources to design information extractionsystems, as well as to members of the parsingcommunity who are interested in the practical im-pact of parsing research.In section 2 we discuss our motivation and re-lated efforts.
Section 3 describes the system foridentification of protein-protein interactions usedin our experiments, and in section 4 describes thesyntactic parser that provides the analyses for thePPI system, and the data used to train the parser.We describe our experiments, results and analysisin section 5, and conclude in section 6.2 Motivation and related workWhile recent work has addressed questions relatingto the use of different parsers or different types ofsyntactic representations in the PPI extraction task(S?tre et al, 2007, Miyao et al, 2008), little con-crete evidence has been provided for potential ben-efits of improved parsers or additional resourcesfor training syntactic parsers.
In fact, althoughthere is increasing interest in parser evaluation inthe biomedical domain in terms of precision/recallof brackets and dependency accuracy (Clegg andShepherd, 2007; Pyysalo et al, 2007; Sagae et al,2008), the relationship between these evaluationmetrics and the performance of practical informa-tion extraction systems remains unclear.
In theparsing community, relatively small accuracy gainsare often reported as success stories, but again, theprecise impact of such improvements on practicaltasks in bioinformatics has not been established.One aspect of this issue is the question of do-main portability and domain adaptation for parsersand other NLP modules.
Clegg and Shepherd(2007) mention that available statistical parsersappear to overfit to the newswire domain, becauseof their extensive use of the Wall Street Journalportion of the Penn Treebank (Marcus et al, 1994)during development and training.
While this claimis supported by convincing evaluations that showthat parsers trained on the WSJ Penn Treebankalone perform poorly on biomedical text in termsof accuracy of dependencies or bracketing ofphrase structure, the benefits of using domain-specific data in terms of practical system perfor-mance have not been quantified.
These expectedbenefits drive the development of domain-specificresources, such as the GENIA treebank (Tateisi etal., 2005), and parser domain adaption (Hara et al,2007), which are of clear importance in parsingresearch, but of largely unconfirmed impact onpractical systems.Quirk and Corston-Oliver (2006) examine asimilar issue, the relationship between parser accu-racy and overall system accuracy in syntax-informed machine translation.
Their research issimilar to the work presented here, but they fo-cused on the use of varying amounts of out-of-domain training data for the parser, measuring howa translation system for technical text performedwhen its syntactic parser was trained with varyingamounts of Wall Street Journal text.
Our work, incontrast, investigates the use of domain-specifictraining material in parsers for biomedical text, adomain where significant amounts of effort areallocated for development of domain-specific NLPresources in hope that such resources will result inbetter overall performance in practical systems.3 A PPI extraction system based on syn-tactic parsingPPI extraction is an NLP task to identify proteinpairs that are mentioned as interacting in biomedi-cal papers.
Figure 2 shows two sentences that in-clude protein names: the former sentence mentionsa protein interaction, while the latter does not.Given a protein pair, PPI extraction is a task ofbinary classification; for example, <IL-8, CXCR1>15is a positive example, and <RBP, TTR> is a ne-gative example.Following recent work on using dependencyparsing in systems that identify protein interactionsin biomedical text (Erkan et al, 2007; S?tre et al,2007; Katrenko and Adriaans, 2006), we have builta system for PPI extraction that uses dependencyrelations as features.
As exemplified, for the pro-tein pair IL-8 and CXCR1 in the first sentence ofFigure 2, a dependency parser outputs a dependen-cy tree shown in Figure 1.
From this dependencytree, we can extract a dependency path betweenIL-8 and CXCR1 (Figure 3), which appears to bea strong clue in knowing that these proteins arementioned as interacting.The system we use in this paper is similar to theone described in S?tre et al (2007), except that ituses syntactic dependency paths obtained with adependency parser, but not predicate-argumentpaths based on deep-parsing.
This method is basedon SVM with SubSet Tree Kernels (Collins, 2002;Moschitti, 2006).
A dependency path is encodedas a flat tree as depicted in Figure 4.
Because a treekernel measures the similarity of trees by countingcommon subtrees, it is expected that the systemfinds effective subsequences of dependency paths.In addition to syntactic dependency features, weincorporate bag-of-words features, which are re-garded as a strong baseline for IE systems.
We uselemmas of words before, between and after the pairof target proteins.In this paper, we use Aimed (Bunescu andMooney, 2004), which is a popular benchmark forthe evaluation of PPI extraction systems.
TheAimed corpus consists of 225 biomedical paperabstracts (1970 sentences), which are sentence-split, tokenized, and annotated with proteins andPPIs.4 A data-driven dependency parser forbiomedical textThe parser we used as component of our PPI ex-traction system was a shift-reduce dependencyparser that uses maximum entropy models to de-termine the parser?s actions.
Our overall parsingapproach uses a best-first probabilistic shift-reducealgorithm, working left-to right to find labeled de-pendencies one at a time.
The algorithm is essen-tially a dependency version of the constituentparsing algorithm for probabilistic parsing withLR-like data-driven models described by Sagaeand Lavie (2006).
This dependency parser hasbeen shown to have state-of-the-art accuracy in theCoNLL shared tasks on dependency parsing(Buchholz and Marsi, 2006; Nivre, 2007).
Sagaeand Tsujii (2007) present a detailed description ofthe parsing approach used in our work, includingthe parsing algorithm and the features used to clas-sify parser actions.
In summary, the parser uses analgorithm similar to the LR parsing algorithm(Knuth, 1965), keeping a stack of partially builtsyntactic structures, and a queue of remaining in-put tokens.
At each step in the parsing process, theparser can apply a shift action (remove a tokenfrom the front of the queue and place it on top ofthe stack), or a reduce action (pop the two topmostThis study demonstrates that IL-8 recognizesand activates CXCR1, CXCR2, and the Duf-fy antigen by distinct mechanisms.The molar ratio of serum retinol-binding pro-tein (RBP) to transthyretin (TTR) is notuseful to assess vitamin A status during infec-tion in hospitalized children.Figure 2: Example sentences with protein namesFigure 1: A dependency treeROOT  IL-8  recognizes  and  activates  CXCR1ROOTSBJOBJCOORDCCENTITY1(IL-8)    recognizes   ENTITY2(CXCR1)Figure 3: A dependency path between protein namesSBJ OBJ16stack items, and push a new item composed of thetwo popped items combined in a single structure).This parsing approach is very similar to the oneused successfully by Nivre et al (2006), but weuse a maximum entropy classifier (Berger et al,1996) to determine parser actions, which makesparsing considerably faster.
In addition, our pars-ing approach performs a search over the space ofpossible parser actions, while Nivre et al?s ap-proach is deterministic.The parser was trained using 8,000 sentencesfrom the GENIA Treebank (Tateisi et al, 2005),which contains abstracts of papers taken fromMEDLINE, annotated with syntactic structures.To determine the effects of training set size on theparser, and consequently on the PPI extraction sys-tem, we trained several parsing models with differ-ent amounts of GENIA Treebank data.
We startedwith 100 sentences, and increased the training setby 100 sentence increments, up to 1,000 sentences.From that point, we increased the training set by1,000 sentence increments.
Figure 5 shows thelabeled dependency accuracy for the varying sizesof training sets.
The accuracy was measured on aportion of the GENIA Treebank reserved as devel-opment data.
The result clearly demonstrates thatthe increase in the size of the training set contri-butes to increasing parse accuracy.
Training theparser with only 100 sentences results in parse ac-curacy of about 72.5%.
Accuracy rises sharplywith additional training data until the size of thetraining set reaches about 1,000 sentences (about82.5% accuracy).
From there, accuracy climbsconsistently, but slowly, until 85.6% accuracy isreached with 8,000 sentences of training data.It should be noted that parser accuracy on theAimed data used in our PPI extraction experimentsmay be slightly lower, since the domain of theGENIA Treebank is not exactly the same as theAimed corpus.
Both of them were extracted fromMEDLINE, but the criteria for data selection werenot the same in the two corpora, creating possibledifferences in sub-domains.
We also note that theaccuracy of a parser trained with more than 40,000sentences from the Wall Street Journal portion ofthe Penn Treebank is under 79%, a level equivalentto that obtained by training the parser with only500 sentences of GENIA data.Figure 5: Data size vs. parse accuracy5 Experiments and ResultsIn this section we present our PPI extraction expe-riments applying the dependency parsers trainedwith the different amounts of the GENIA Treebankin our PPI system.
As we mentioned, the GENIATreebank is used for training the parser, while theAimed is used for training and evaluation of PPIextraction.
A part-of-speech tagger trained withGENIA and PennBioIE was used.
We do not ap-ply automatic protein name detection, and insteaduse the gold-standard protein annotations in theAimed corpus.
Before running a parser, multiwordprotein names are concatenated and treated as sin-gle words.
As described in Section 3, bag-of-wordsand syntactic dependency paths are fed as featuresto the PPI classifier.
The accuracy of PPI extrac-tion is measured by the abstract-wise 10-fold crossvalidation (S?tre et al 2007).When we use the part-of-speech tagger and thedependency parser trained with WSJ, the accuracy(F-score) of PPI extraction on this data set is 55.2.The accuracy increases to 56.9 when we train thepart-of-speech tagger with GENIA and Penn BioIE,while using the WSJ-trained parser.
This confirmsthe claims by Lease and Charniak (2005) that sub-sentential lexical analysis alone is helpful in adapt-ing WSJ parsers to the biomedical domain.
WhileLease and Charniak looked only at parse accuracy,70758085900 2000 4000 6000 8000Figure 4: A tree kernel representation of the dependencypath(dep_path (SBJ (ENTITY1 ecognizes))(rOBJ (recognizes ENTITY2)))17our result shows that the increase in parse accuracyis, as expected, beneficial in practice.Figure 6 shows the relationship between theamount of parser training data and the F-score forthe PPI extraction.
The result shows that the accu-racy of PPI extraction increases with the use ofmore sentences to train the parser.
The best accu-racy was obtained when using 4,000 sentences,where parsing accuracy is around 84.3.
Althoughit may appear that further increasing the trainingdata for the parser may not improve the PPI extrac-tion accuracy (since only small and inconsistentvariations in F-score are observed in Figure 6),when we plot the curves shown in Figures 5 and 6in a single graph (Figure 7), we see that the twocurves match each other to a large extent.
This issupported by the strong correlation between parseaccuracy and PPI accuracy observed in Figure 8.While this suggests that training the parser with alarger treebank may result in improved accuracy inPPI extraction, we observe that a 1% absolute im-provement in parser accuracy corresponds roughlyto a 0.25 improvement in PPI extraction F-score.Figure 5 indicates that to obtain even a 1% im-provement in parser accuracy by using more train-ing data, the size of the treebank would have toincrease significantly.Although the results presented so far seem tosuggest the need for a large data annotation effortto achieve a meaningful improvement in PPI ex-traction accuracy, there are other ways to improvethe overall accuracy of the system without an im-provement in parser accuracy.
One obvious alter-native is to increase the size of the PPI-annotatedcorpus (which is distinct from the treebank used totrain the parser).
As mentioned in section 3, oursystem is trained using the Aimed corpus, whichcontains 225 abstracts from biomedical papers withmanual annotations indicating interactions betweenproteins.
Pairs of proteins with no interaction de-scribed in the text are used as negative examples,and pairs of proteins described as interacting areused as positive examples.
The corpus contains atotal of roughly 9,000 examples.
Figure 9 showshow the overall system accuracy varies when dif-ferent amounts of training data (varying amountsof training examples) are used to train the PPI sys-tem (keeping the parse accuracy constant, using allof the available training data in the GENIA tree-bank to train the parser).
While Figure 5 indicatesthat a significant improvement in parse accuracyrequires a large increase in the treebank used totrain the parser, and Figure 7 shows that improve-ments in PPI extraction accuracy may require asizable improvement in parse accuracy, Figure 9suggests that even a relatively small increase in thePPI corpus may lead to a significant improvementin PPI extraction accuracy.Figure 6: Parser training data size vs. PPI extractionaccuracyFigure 7: Parser training data size vs. parser accuracyand PPI extraction accuracyFigure 8: Parse accuracy vs. PPI extraction accuracy5354555657580 2000 4000 6000 80005354555657586872768084880 5000 10000ParserPPI F-score53545556575870 75 80 85 9018Figure 9: Number of PPI training examples vs. PPI ex-traction accuracyWhile some of the conclusions that can bedrawn from these results may be somewhat sur-prising, most are entirely expected.
However, evenin these straightforward cases, our experimentsprovide some empirical evidence and concretequantitative analysis to complement intuition.
Wesee that using domain-specific training data for theparsing component for the PPI extraction systemproduces superior results, compared to using train-ing data from the WSJ Penn Treebank.
When theparser trained on WSJ sentences is used, PPI ex-traction accuracy is about 55, compared to over 57when sentences from biomedical papers are used.This corresponds fairly closely to the differences inparser accuracy: the accuracy of the parser trainedon 500 sentences from GENIA is about the sameas the accuracy of the parser trained on the entireWSJ Penn Treebank, and when these parsers areused in the PPI extraction system, they result insimilar overall task accuracy.
However, the resultsobtained when a domain-specific POS tagger iscombined with a parser trained with out-of-domaindata, overall PPI results are nearly at the same lev-el as those obtained with domain-specific trainingdata (just below 57 with a domain-specific POStagger and out-of-domain parser, and just above 57for domain-specific POS tagger and parser).
Atthe same time, the argument against annotatingdomain-specific data for parsers in new domains isnot a strong one, since higher accuracy levels (forboth the parser and the overall system) can be ob-tained with a relatively small amount of domain-specific data.Figures 5, 6 and 7 also suggest that additionalefforts in improving parser accuracy (through theuse of feature engineering, other machine learningtechniques, or an increase in the size of its trainingset) could improve PPI extraction accuracy, but alarge improvement in parser accuracy may be re-quired.
When we combine these results with thefindings obtained by Miyao et al (2008), they sug-gest that a better way to improve the overall sys-tem is to spend more effort in designing a specificsyntactic representation that addresses the needs ofthe system, instead of using a generic representa-tion designed for measuring parser accuracy.Another potentially fruitful course of action is todesign more sophisticated and effective ways forinformation extraction systems to use NLP tools,rather than simply extracting features that corres-pond to small fragments of syntactic trees.
Ofcourse, making proper use of natural languageanalysis is a considerable challenge, but one thatshould be kept in mind through the design of prac-tical systems that use NLP components.6 ConclusionThis paper presented empirical results on the rela-tionship between the amount of training data usedto create a dependency parser, and the accuracy ofa system that performs identification of protein-protein interactions using the dependency parser.We trained a dependency parser with differentamounts of data from the GENIA Treebank to es-tablish how the improvement in parse accuracycorresponds to improvement in practical task per-formance in this information extraction task.While parsing accuracy clearly increased withlarger amounts of data, and is likely to continueincreasing with additional annotation of data forthe GENIA Treebank, the trend in the accuracy ofPPI extraction indicates that a sizable improvementin parse accuracy may be necessary for improveddetection of protein interactions.When combined with recent findings by Miyaoet al (2008), our results indicate that further workin designing PPI extraction systems that use syn-tactic dependency features would benefit frommore adequate syntactic representations or moresophisticated use of NLP than simple extraction ofsyntactic subtrees.
Furthermore, to improve accu-racy in this task, efforts on data annotation shouldfocus on task-specific data (manual annotation of4045505560650 5000 10000 1500019protein interactions in biomedical papers), ratherthan on additional training data for syntactic pars-ers.
While annotation of parser training data mightseems like a cost-effective choice, since improvedparser results might be beneficial in a number ofsystems where the parser can be used, our resultsshow that, in this particular task, efforts should befocused elsewhere, such as the annotation of addi-tion PPI data.AcknowledgementsWe thank the anonymous reviewers for their in-sightful comments.
This work was partially sup-ported by Grant-in-Aid for Specially PromotedResearch (MEXT, Japan), Genome NetworkProject (MEXT, Japan), and Grant-in-Aid forYoung Scientists (MEXT, Japan).ReferencesBerger, A., S. A. Della Pietra, and V. J. Della Pietra.1996.
A maximum entropy approach to natural lan-guage processing.
Computational Linguistics,22(1):39?71.Clegg, A. and Shepherd, A.
2007.
Benchmarking natu-ral-language parsers for biological applications usingdependency graphs.
BMC Bioinformatics, 8:24.Erkan, G., A. Ozgur, and D. R. Radev.
2007.
Semisu-pervised classification for extracting protein interac-tion sentences using dependency parsing.
InProceedings of CoNLL-EMNLP 2007.Hara, T., Miyao, Y and Tsujii, J.
2007.
Evaluating Im-pact of Re-training a Lexical Disambiguation Modelon Domain Adaptation of an HPSG Parser.
In Pro-ceedings of the International Conference on ParsingTechnologies (IWPT).Katrenko, S. and P. W. Adriaans.
2006.
Learning rela-tions from biomedical corpora using dependencytrees.
In Proceedings of the first workshop on Know-ledge Discovery and Emergent Complexity in BioIn-formatics (KDECB), pages 61?80.Kulick, S., A. Bies, M. Liberman, M. Mandel, R.McDonald, M. Palmer, A. Schein and L. Ungar.
2004.Integrated Annotation for Biomedical InformationExtraction.
In Proceedings of Biolink 2004: LinkingBiological Literature, Ontologies and Databases(HLT-NAACL workshop).Lease, M. and Charniak, E. 2005.
Parsing BiomedicalLiterature.
In R. Dale, K.-F. Wong, J. Su, and O.Kwong, editors, Proceedings of the 2nd InternationalJoint Conference on Natural Language Processing(IJCNLP'05), volume 3651 of Lecture Notes inComputer Science, pages 58 ?
69.Miyao, Y., S?tre, R., Sagae, K., Matsuzaki, T. and Tsu-jii, J.
2008.
Task-Oriented Evaluation of SyntacticParsers and Their Representations.
In Proceedings ofthe 46th Annual Meeting of the Association for Com-putational Linguistics.Nivre, J., Hall, J., Kubler, S., McDonald, R., Nilsson, J.,Riedel, S. and Yuret, D. 2007.
The CoNLL 2007Shared Task on Dependency Parsing.
In Proceedingsthe CoNLL 2007 Shared Task in EMNLP-CoNLL.Nivre, Joakim, Johan Hall, Jens Nilsson, Gulsen Eryi-git,and Svetoslav Marinov.
2006.
Labeled pseudo-projective dependency parsing with support vectormachines.
In Proceedings of the Tenth Conference onComputational Natural Language Learning, sharedtask session.Pyysalo S., Ginter F., Haverinen K., Heimonen J., Sala-koski T. and Laippala V. 2007.
On the unification ofsyntactic annotations under the Stanford dependencyscheme: A case study on BioInfer and GENIA.
InProceedings of BioNLP 2007: Biological, Transla-tional and Clinical Language Processing.Quirk, C. and Corston-Oliver S. 2006.
The impact ofparse quality on syntactically-informed statisticalmachine translation.
In Proceedings of EMNLP 2007.S?tre, R., Sagae, K., and Tsujii, J.
2007.
Syntactic fea-tures for protein-protein interaction extraction.
InProceedings of the International Symposium on Lan-guages in Biology and Medicine (LBM short oralpresentations).Sagae, K. and Lavie, A.
2006.
A best-first probabilisticshift-reduce parser.
In Proceedings of theCOLING/ACL 2006 Main Conference Poster Ses-sions, pages 691?698, Sydney, Australia, July.
Asso-ciation for Computational Linguistics.Sagae, K., Miyao, Y. and Tsujii, J.
2008.
Challenges inMapping of Syntactic Representations for Frame-work-Independent Parser Evaluation.
In Proceedingsof the Workshop on Automated Syntatic Annotationsfor Interoperable Language Resources at the FirstInternational Conference on Global Interoperabilityfor Language Resources (ICGL'08).Tateisi, Y., Yakushiji, A., Ohta, T., and Tsujii, J.
2005.Syntax annotation for the GENIA corpus.
In Pro-ceedings Second International Joint Conference onNatural Language Processing: Companion Volumeincluding Posters/Demos and tutorial abstracts.20
