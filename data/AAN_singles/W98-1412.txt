ABDUCTIVE REASON G FOR SYNTACTIC REALIZATION*Ralf KlabundeUniversity of HeidelbergCentre for Computational Linguisticsklabunde~novell i. gs.uni-heidelberg, deMartin JanscheThe Ohio State UniversityDepartment of LinguisticsJansche.
l?osu, eduAbstractAbductive reasoning is ?used in a bidirectional framework for syntactic realization and semanticinterpretation.
The use of the framework is illustrated in a case study of sentence generation,where different syntactic forms are generated depending on the status of discourse information.Examples are given involving three differen t syntactic onstructions in German root clauses.1 Pragmatics in Natural Language GenerationThe computational treatment of pragmatics in natural anguage generation is often---directly or indirectly--?
oriented around the Gricean maxims \[Grice 7?5\].
Their effects emerge from the pragmatic model of thegeneration system so that the generated text s satisfy these maxims.
The texts should be a true characteri-zation of a state of affairs, they should be as informative as possible, relevant, and perspicuous.
While thefirst three maxims are related to what is said, the last maxim is related to how it is said.
The category ofperspicuity principles includes constraints on avoiding obscurity and ambiguity, or being brief and orderly.I t  is anything but clear how these principles hould be interpreted precisely.
Several attempts have been?
made to remedy this in computational work on generating texts that best satisfy these maxims, especiallywith respect o the generation of referring expressions (e.g.
\[Dale t al.
95\]).However, there is?more to  pragmatics than satisfying Gricean maxims.
In particular, the category ofperspicuity principles does not usually cover the important fact that texts are tailored toa specific addressee,not only in content,?
i.e., with respect o her or his informational needs, but also in the linguistic form, i.e.,word order, syntactic onstructions, the choice of lexical items, and eventually prosodic information.
Thistailoring of  the linguistic form to the listener is termed "information structuring".
In generating texts,information Structuring requires, among other things, the use of some listener model, which may includeinformation about he listener's knowledge, goals, properties, etc.LinguiStic approaches to describing the principles of information structuring have sometimes charac-terized information structure as an instruction to the listener about how to construct a model of the com-municated state of affairs \[Prince 81\]~ In AI and Computational Linguistics, tailoring the message to the?
- .
Usercomprises very often solely content planning, which only indirectly determines the linguistic output.- : : ~:i. i .
/ For:~xaniple, Systems tailor the information "density" to the user (e.g.\[Pads 93\]), or they drive the dialogue?
-, depending on an estimation of what the user might be interested in (e.g.
\[Jameson et al 94\]).
Realizing texts.
by determining the information structure of the respective sentences, which again is a reflex of addressee?
orientation, has not yet.received its due attention.?
*The authors would like to thank Bob Kasper, Nathan Vaillette, Shravan Vasishth, and twoanonymous referees for helpfulcomments and suggestions.
All remaining mistake s are, of course,..our own.108 5 " "III!1IIIII!2 The Topic/Comment Structure in Information StructuringThe notion of information structure comprises at least wo separate notions of how the information of a sen,tence may be structured, viz.
the topic/comment structure and the focus/background structure \[Vallduvf 92,Lambrecht 94\].t In order to motivate these structuring mechanisms, consider the following simple example.Suppose the purpose of a generation system is to describe aspatial scenario.
One of the sentences might be(1) Behind the town hall is a BAKERY.with "bakery" the prosodically most prominent constituent ( he focus exponent).
In this sentence; the prepo- "sitional phrase "behind the town hall" functions as topic and the noun phrase "a bakery" is in focus, we willignore aspects of focus and its role in language generation, especially since selecting the focus exponent isbetter understood as being part of utterance planning, and are limiting our attention to the topic/comment-structure only.
The topic provides familiar discourse referents whose properties are further illuminated bythe sentence; the relation between these discourse referents and the sentential predication is also referredto as an aboutness-relation.
Many languages possess pecial topicalization constructions or morpholog-ical markers to single out the topic in a sentence.
In German (and probably English as well), referringphrases provide topicreferents, and the clause-initial position is their preferred position.
Thus clause-initialpositioning is the most important topic-relevant feature in generation.
2The same propositional content expressed by (1) can be realized with different information structuresand, therefore, different sentence forms, as the following English examples demonstrate:(2) A bakery is behind the town hall.
(3) Behind the town hall, there is a bakery.
(4) As for the town hal!, behind it is a bakery.Discourse referents functioning as topics must be identifiable for the listener.
This is the reason whytopics are usually packaged as definite noun phrases, or as prepositional phrases that contain definite noun~hrases.
Topic candidates will be selected from the set of discourse referents that the listener knows accord-ing to a topic acceptance scale.
\[Lambrecht 94\] proposes the following scale: .
(5) active > accessible (textually, situationally, or inferentially)> unused > brand-new anchored > brand-new unanchoredActive referents are those that are currently lit up; they are in the center of attention.
They are the mostacceptable topics because the listener's mental effort needed for processing the respective sentence is-mini-mal as compared with the effort needed to identify and anchor an unfamiliar or inactive topic referent.
Weconsider the candidates below the accessible referents to be inappropriate as topics in most instances, andwe limit our attention to a scale with three regions: active referents, accessible referents, and inaccessiblereferents.To summarize, the first task in generating texts with sentences with appropriate opic/comment struc-tures is to determine for each sentence the topic discourse referent.
This referent should be identifiable forthe listener and as high on the topic acceptance scale as possible.
The phrase xpressing the topic shouldI Depending on one's theoretical background and/or affiliation with different schools, terminology differs considerably.2\[Ahmann 81, 150\] gives ~?ome counterexamples to this default.
These xamples are pr0sodically marked, however.109be placed in clause-initial position.
However, these are only guideiines, not fixed rules.
Hence, we need amechanism to handle this kind of uncertainty.This is of course not the whole story of topic-hood.
In addition to selecting topic referents, we have to?
solve the problem of how one and the same topic/comment structure can be realized by-different syntacticstructures.
German examples resembling the previous three ones are:(6) Die Vitrine steht rechts vonder  Lampe. "
~'The Showcase is standing to the fight of the lamp."
(subject realization)(7) Die Vitrine, die steht rechts yon der Lampe.
"The showcase, it is standing to the right of the lamp?
(left dislocation)?
(8) Was die Vitrine betrifft, die steht rechts vonder Lampe.
- .
.
.
.?
?
.?
"As for the showcase, it is standing to the right of the lamp.'
(hanging topic)In the first clause the topic is realized as the subject ?in clause-initial position.
The second clause exhibits aleft  dislocation for the topic, and the third one uses a so-called hanging topic.We assume that the functions of these three syntactic forms are more or  less ?identical for German and: English.
All.three examples express the same propositional content, viz.
the localization of a uniquelyidentifiable showcase with respect o a uniquely identifiable ?lamp.
Furthermore, all three examples exhibitthe same topic/comment structure: "the Showcase" functions as topic, i.e., the anchor for the proposition,and the rest of the clause comments on certain aspects of the showcase.
However, these three forms are notmutually interchangeable in each imaginable context, because they invite different pragmatic inferences.?
The subject realization is neutral with respect o ?topic accessibility.
There is a strong correlation be-tween the grammatical function of subjectand the information structural notion of topic.
The subject is the?
unmarked topic.Left dislocation constructions, they can indicate a topic shift because the syntactically autonomousposition of the detached noun phrase signals a change in the status of its discourse referent from beinginactive to active \[Lambrecht 94\].
Additionally, left dislocations must satisfy a presupposition condition,namely to support he existence of another individual not having the property expressed by the matrixclause \[Wiltschko 95\].
The discourse referent is in some way related to a previously established set whichthe referent is a member of.
This resembles the presuppositions restrictive relative clauses establish.As  fora hanging topic, it also indicates a topic shift.
It introduces a new topic of the discourse froma set of discourse referents that have already been established in the discourse.
The common property ofshifting the discourse topic implies that hanging topics and left dislocations are not mutually exclusive.A distinction on pragmatic grounds is complicated by the fact that the various set phrases usable for thehanging topic can have different discourse functions and that left dislocations can be interpreted as specialhanging topics.
However, the main difference between left dislocations and hanging topics with the setphrase was das X betrifft ("as for the X") seems to be: left dislocations must satisfy the presuppositioncondition and they establish a topic shift by means of changing the status of a discourse referen t, whereasi: hanging topics establish atopic shift by means of selecting adiscourse referent from a previously established?
set of referents.
3 Despite?
their overlapping discourse functions, we confine ourselves to the distinctivepragmatic properties of both constructions for their generation.Hence, the second Problem that needs to be solved is to correlate the syntactic form with the statusof discourse referents with respect o their ?being.
active or accessible, as well as with other discourse in-formation and factual information pertaining to the presupposition conditions.
How can we incorporate3See the extensive descriptive analyses in\[Altmann 81 \].110IiiIiIII,!
!I!m ?IIIIII,IiIIIiIIIIIIthis informal characterization f topic, topic acceptability, and syntactic onstructions into a unified andformally precise mechanism for a natural language generation system?
We propose an abductive settingin the spirit of \[Hobbs et al 93\] as a framework for integrating the diverse knowledge sources involved inthe generation and interpretation f sentential information structure.
The basic idea is 6a view generatinga single proposition as finding the best proof for why a sentence and its information structure is congruentwith the listener model.
In the process of finding this proof, the sentence is generated by incrementallyinstantiating unbound variables.Our  basic scenario is the generation of spatial descriptions.
The mechanism for content planning isnot the subject of this paper (cf.
\[Jansche et al 96, Meyer-Klab6nde 96, Porzel et al in press\]).
For spatial.descriptions, content planning comprises for each proposition the selection of a reference object from theset of objects, the selection of a primary object, the selection of a point of view, and the computationof a spatial relation between both objects depending on the chosen point of view.
For present purposeswe assume that thepropositional content of a sentence has already been established.
What remains to bedone is to construct a pragmatically appropriate s ntence that conveys the new and informative part of thispropositional information to the listener.
It is for this syntactic/pragmatic realization process that we use theabductive framework.
Ultimately, we aim to incorporate the abductive reasoning mechanism directly intothe content planner so as to achieve auniform framework.3 ?
Generat ion  by Abduct ionAbductive reasoning is reasoning about he best explanation for a given observation.
To make precise whatcounts as a good explanation, one introduces a preference criterion by which alternative explanations canbe compared.
A preferred explanation for an observation might be the least specific one, the most specificone, the one with the lowest proof costs, etc.
Abductive xplanation is classically characterized asfollows(C f. \[Mayer et al 96\]): a knowledge base K, the usual consequence r lation ~, and an observation E to beexplained, such that K t~ E, are given.
A statement H is taken as the best explanation of E in K iff:1.
KU {H} ~ E; and2.
H is "better" than any other statement in the set {H ~ \[ K U {H'} ~ E}, according to the preferencecriterion.We use a generalized version of what \[Stickel 90, 236\] calls predicate specific abduction, where only el-ements from a distinguished set of litemls may be assumed.
What counts as the best explanation will bebased on the (preferably minimal)?
number of assumptions made.Abduction has been used in natural language processing for interpretation tasks such as met0nymyresolution, understanding vague expressions, or plan recognition.
Recently, abductive reasoning has also?been proposed for use in generation, partly for planning \[Lascarides tal.
92, Thomason et al 96\], and asa framework for both the interpretation a d the generation of discourse \[Thomasonet al 97\].
The basicidea behind these approaches i  to find the best way to obtain a communicative goal state by modifyingthe conversational record, which roughly corresponds toour listener model, with applicable operators.
Theplan is the set of hypotheses discovered by an abductive proof of the proposition that the goal state has beenachieved.What remains open in these approaches i to make precise the relation between the planned propo-sitional content of an Utterance and an appropriate sentence form.
only very simple example sentences111!
'lcould be generated because the local pragmatics of the sentence form does not play a role in the previ-ous approaches.
We are bridging this pragmatic gap between content planning and surface realization byabductive mechanisms.3.1 The Abductive ComponentFor our purposes it is helpful to view abductive proofs as essentially relational.
An abductive proof d e-termines the relation between a knowledge base, an observation, a specification of what assumptions canbe made, and proved and assumed literals that jointly provide an explanation for the initial observation.
-The prototypes we have implemented inProlog make this relation available xplicitly, and great care wastaken to ensure that queries Such as (9), where not all arguments are instantiated, are handled correctly bygenerating a manageable subset of all possible solutions.
"(9) ?
?- abduce(Goal, Assumable, ?Proved, Assumed).In the above query, Goal is the observation to be proved by the abductive meta-interpreter, Assumableis a set of literals that may be assumed, and Proved and Assumed are multisets of literals that were usedor assumed, respectively, during the abductive proof of Goal.
Interpretation mode corresponds to querieswhere the goal is instantiated and everything can be assumed in principle, as in (10); during generation themeta-interpreter is invoked with the goal at least partially uninstantiated, while the set of assumable literalsis specified, as in (11).
?
(10) ?- abduce (sentence ( \[die,vitrine, steht ; rechts,von, der, lampe\] ), u, Pr, As).
(II) ?- abduce(sentence(S), \[showcase(s),lamp(1),loc(s,r),rightof(r,l)\], Pr, As).From the fact that queries like (11) are accepted it is clear that the abduction scheme we use is somewhatmore generaithan predicate specific abduction: we supply information as to what literals may be assumed,whereas predicate specific abduction would only specify the functors and arities of those literals.It is well worth noting that on our approach generation is not simply the inverse of interpretation.
If thatwere the case, one would call the abductive meta-interpreter with the goal instantiated deriving the assumed?
literals during interpretation, while forgeneration the opposite instantiation pattern would be used.
BUt forthe latter case this amounts to requiring that all literals must be assumed in the proof, which is clearly toostrong since some of them might be derivable from the knowledge base.
Instead we only specify whichliterals may be assumed, leaving open the possibility that some of them are provable from the knowledgebase.Also note that since we do not use weighted abduction, the problem of assigning different assumptioncosts for generation and interpretation (cf.
\[Thomason etal.
97\]) is avoided.
On the other hand, what shouldwe use as a preference criterion?
A sequence of several criteria is used.
First, proofs are preferred for thenumber of provable literals used,the more the better.
In the cases we consider, there, seems to be a loosecorrespondence b tween this criterion and the Gricean maxims of relevance and quality.
Second, proofsare preferred compared to other proofs if they involve less assumptions.
The number of assumptions madeis determined by the cardinality of the set that is the reduction of the multiset foundduring an abductiveproof.
Third, everything, else being equal, we prefer proofs with the highest amount of assumption re-use.This is determined by the difference between the cardinalities of the multiset of assumptions and o f  itscorresPonding set.
The relevant idea--an assumption becomes more plausible if it is used to explain morethan one th ing~is  essentially the same as the one behind the factoring rule of \[Stickel 90\].112Ii.IIillI!!
?-I .IIIIIIIIINow we are in a position to consider some examples involving the interaction of discourse pragmaticsand syntax in German root clauses.3.2 Generating Phrases in Initial Position "In a language like German with relatively free word order, any argument of the verbal head of a sentence?
may appear first, depending on the relevance for the discourse.
For the spatial scenarios we consider, thereis almost always a choice between several noun phrases or prepositional phrases that can be arranged inalmost any order, As seen before, elements referring to familiar entities usually precede phrases denotingthings not mentioned before.Consider the case of locative verbs such as stehen ('to stand'), sich befinden ('to be located'), etc.
Weuse the conventional Prolog translations of extended phrase structure rules to generate sentences headed bythese verbs:(12) v2_sentence(PO,P)  "-access ib le  (X),accessible(R),np(syn(nom,_), X, PO,PI), ~, a nominative NP with discourse referent Xloc_vp(X, R, PI,P2), ~, verb locating X inside the region Rpp(R, P2,P).
~, a PP denoting a region R?
(13) v2_sentence(PO,P) : -  (14)access ib le (R) ,pp(R, P0,P1) ,loc_vp(X, R, P1 ,P2) ,np(syn(nom, . )
,  X, P2 ,P) .v2_sentence(PO,P)  "-np(syn(nom,_ ) ,  X, PO,P1),loc_vp(X, R, P1 ,P2) ,pp(R, P2 ,P) .Suppose we want to generate the sentence Rechts vonder Lampe steht eine ~trine, a variation of (6).The propositional content of this sentence--lamp (1), r ighter  ( r ,  11, loc  (s , r ) ,  showcase (s ) - -mustbe .assumable, and access ib le  (17 must be derivable from the listener model.
Backward-chaining onv2_sentence(S ,  \[\] ) is not possible using rule (12) since access ib le (s )  is not provable and cannotbe assumed.
Rule (13) is applicable, but so is the weaker (14).
Proofs involving these two rules will beequivalent except for the presence or absence of sub-proofs of access ib le  ( r ) ,  which is derivable fromaccess ib le  (11.
But since proofs using more proved literals axe preferred, the best abductive proof willresult in a sentence with an initial definite PP preceding both the verb and the indefinite subject NP.3.3 Generating Hanging TopicsTo model the "topic shift" signaled by hanging topics, we need some way to represent the currently activediscourse referent.
This is achieved by introducing two predicates, ac t ive  (X) and act ivate  (X), whichtest whether a given discourse referent is active or declare a discourse referent as active, respectively.
Forreasons of simplicity, we present hese predicates as though they depend on a state external to the rules;in the implemented prototypes, each predicate is actually equipped with two additional variables that areused to drag along, test, and update the discourse State, in order to ensure a simple declarative semantics.
Inany proof, the literal ac t ivate  (X) cannot be proved and has to be assumed, whereas ac t ive  (X) must be113.
.
\ [  ."t.)
;'",/' " ' "resolved exactly once with the closest matching literal of the form act ivate  (X).
Thus the active referentis identified with the last activated one.?
The rule for a sentence with a hanging topic can be seen in (15).
Here it is not sufficient that the discourse?
referent associated with the noun phrase be inferentially accessible, a stronger condition is imposed, therequirement that the discourse referent must be taken from a set of thematic referents presumably establishedin a superordinate planning stage,(15) sentence(PO,P)  "-active(A),?
thematic_referent(X), ., : .
.
.distinct_objects(A, X),'C'(PO,?
was, PI),np(syn(acc,Gender),  X, PI,P2),'C'(P2, betrifft,  P3),activate(X)?v2_sentence(P3,P).Since a sentence with a hanging topic is used to re-activate an inactive discourse referent, and since anNP may be realized as a pronoun if its discourse referent is active, sentences of this type usually contain apronoun, rather than a full NP, that refers back to the hanging topic, as in (8) above.3.4 Generating Left DislocationsLeft dislocation constructions involve a semantics beyond the first-order theories used so far.
This construc-tion type presupposes that some salient object other than the discourse referent of the dislocated constituentlacks the property predicated by the sentence.
Since we are dealing with highly specific rules for sentenceswith locative verbs, it is possible to express these conditions without reference to negative properties.
Allwe ?have to do is to find some salient object distinct from the discourse referent of the dislocated NP, and aregion where it is located istinct from the region in which the head verb locates the object denoted by theNP.
In addition to this, the familiar discourse referent of the dislocated NP is made active.
The resultingrule is displayed in (16):(16) sentence(PO,P) - -active (A),- famil iar(X),d ist inct_objects(A,  X) ?accessible (Y),dist inct_objects (Y, X),l oc (Y ,  R2),?
- distinct_objects(Rl,  R2),?
.
.
.
.
', " , -~ -.
:.
np(syn(nom,Gender)?
:.X, PO?PI)..\] .
.
.
?
, .... .
.
.
.
.
?act ivate (X), "pron (syn (nom, Gender), P I, P2),loc_vp(X, R1, P2,P3),pp(R1, P3,P).114II,IIiil!iIJ,|t .,!p,!1I!IIIIII.IIIIIIIIIII3.5 An Example  ProofFinally, we consider in some detail an example proof that illustrates everal of the techniques used in gen-erating the syntactic forms discussed previously.
The sentence we want to derive should express that a?
showcase is located to the right of the lamp; additionally, we know that the immediately preceding dis-course was about a different object, and some time ago we had explicitly mentioned the lamp.
(17) facts: active(c); couch(c), thematic_referent(l), lamp(l), etc.assumable: showcase(s ) ,  lamp(1), loc(s,r), right_of(r,!
), activate(.
)to prove: ?
sentence (S, \[\] )sentence  (S, \[\] )ac t ive  (A) "/, resolution with fact, A bound to cthemat ic_ re ferent (Y )  7. resolution with fact, Y bound to 1d i s t inc t_ob jec ts  (c ,  1) 7. provable from knowledge base' C' (S, was, P 1) 7. provable from knowledge base7.
S bound to \[was I P1\]np(syn(acc ,Gender ) ,  1, P1 ,P3)?
det (syn(acc ,Gender ) ,  P1 ,P2) 7.
Gender bound to fem" familiar(l)thematic_referent (i) 7. resolution with fact'C' (P1, d ie ,  P2)  7. provable fromknowledge base7.
P1 bound to \ [d ie IP2\]n (syn(acc , fem) ,  1, P2,P3)lamp (1) 7. resolution with fact'C ' (P2 ,  lampe,  P3) 7. provable from knowledge base7.
P2 bound to \[lampe I P3\]'C!
(P3,  bet r i f f t ,  P4) 7. provable from knowledge base% P3 bound to \ [bet r i f f t  I P4\]ac t ivate  (1) Y, can only be assumedv2_sentence (P4, \[\] )accessible (1%)tel(R, Z) " ".
.
"spat_tel (1%, Z)right_of (I~, Z)familiar(l)thematic_referent (i) ~, resolution with a fact "pp(r, P4,PG).active (W)activate (W) 7. factoring with a previous assumption, W bound to 1r ight_o f  ( r ,  1) 7. factoring with a previous assumption'C'  (P4, rechts ,  P5) ~, provable from knowledge base7, P4 bound to \ [ rechts  \[P5\]'C'  (P5, davon,  P6) 7, provable from knowledge base7.
P5 bound to \[davonlP6\]loc_vp(X,: r ,  PG,P7)7. can only be assumed, R bound to r, Z bound tO 1?
115'C ' (P6,  n teht ,  P7) 7.- provable from knowledge base7.
P6 bound to \ [ s teht  I PT\]loc (X ,  r )  " 7. can ?only be assumed, X bound to snp(syn(nom, . )
,  s ,  P7,  \ [ \ ] )det (syn(nom,Gender), P7,P8) 7, Gender bound to fern?
'C ~ (P7, e ine ,  P8) 7. provable from knowledge base7.
P7 bound to \ [e ine i P8\]n (syn(nom, fem) ,  s ,  P8 , \ [ \ ] )showcase (s )  7. can only be assumed? '
C' (P8, v i t r ine ,  \[\] ) 7. provable from knowledge base7.
P8 bound to \ [v i t r ine \ ]  .?
result: S bound to \[was, d ie ,  lampe, bet r i f f t  , rechts ,  davon, s teht ,  e ine ,v i t r ine \ ]assumed: ac t ivate  (1 ) ,  r ight_o f  ( r ,1 ) ,  ac t ivate  (1 ) ,  r ight_o f  ( r ,1 ) ,  l oc  ( s , r ) ,showcase(s )  including two factored assumptions .
.Our preference criteria favor this proof over competing ones, since many goals could be proved, fewhad to be ?assumed, and assumptions could be re-used.4 Conclusion and Outlook ?We have presented a specification of  how information packaging and syntactic structure interact in Germanroot clauses.
This specification is purely declarative, and neutral with respect to the task at hand.
Theaxioms we use provide that kind of"thorough integration of syntax, semantics, and pragmatics" in the senseof \[Hobbs et al 93, 104ft.\] that makes it possible to use the same knowledge base for both interpretation and?
generation.
The mechanism used for either task is essentially the same too, viz.
a reversible generalization ofpredicate specific abduction where only the set of?facts that may be assumed differs depending on the task.?
The rule s covering ?different syntactic forms and ?their information structure have antecedents of differentstrengths, sometimes ubsuming each other, and the abductive mechanism ensures that the best explanationis the one that uses a rule with the strongest abductively provable antecedent.?
As a direction for further research we suggest hat a logical framework is needed that extends traditionalknowledge representation and reasoning.
Existing prototypes like the one described in ?
\[Hobbs et al 93\]are dealing to a large extent with static data: when trying to interpret a discourse, information is simplyaccumulated, Once one tries to incorporate ?reasoning about information packaging, one is faced directlywith the problem of having to update the conversational record several times while a single sentence isinterpreted or generated.
The relevant reasoning is not so much about facts, but about actions or resources.We suggest hat it is this dynamic aspect of information flow that is constant across the different tasks,and that the difference in generation and interpretation lies in the different status of information sources and?
sinks.
A uniform framework that permits explicit reasoning about these dynamic aspects is highly desirable.?
A second line of investigation should be concerned with trying to integrate content planning and syntac-tic realization.
This could be exploited to allow for incremental generation?, O r be used for the generation ofidiomatic expressions and syntactic patterns that are not linked to any semantic ontent, but rather to certaindiscourse goals.
If this task is carried out successfully, we might see a thorough integration of all aspects of?
natural language generation.
:116I.|IIIII!I!l,,IrIIIIIIIII1II|IIIIIIIReferences\[Altmann 81\] Altmann, H. I98 I. Formen der "'Herausstellung" imDeutschen.
Ttibingen: Niemeyer.\[Dale t al.
95\] Dale, R., and E. Reiter.
1995.
Computational interpretations of the Gricean maxims in thegeneration ofreferring expressions.
Cognitive Science 18, 233-263.\[Grice 75\] Grice, H.P.
1975.
Logic and conversation.
In P. Cole, and J,L.
Morgan (eds), Syntax andSemantics 3: Speech Acts, New York: Academic Press, 41-58.\[Hobbs et al 93\] Hobbs, J.R., M.E.
Stickel, D;E. Appelt, and P. Martin.
1993.
Interpretation as abduction.Artificial Intelligence 63, 69-142.\[Jameson etal.
94\] Jameson, A., B. Kipper, A. Ndiaye, R. Sch~ifer, J. Simons, T. Weis, and D. Zimmer-mann.
1994.
Cooperating to be noncooperative: The dialog system PRACMA.
In B. Nebel, andL.
Dreschler-Fischer ( ds), Proceedings of the Eighteenth Annual German Conference on ArtificialIntelligence, Berlin: Springer, 106-I 17.\[Jansche etal.
96\] Jansche, M., and R. Porzel.
1996.
PAROLE: A Cognitively Motivated NLG System forSpatial Descriptions.
UniversiNten Heidelberg/Mannheim: Arbeiten aus dem Sonderforschungsbe-reich 245 "Sprache und Situation"; Report Nr.
93.\[Lambrecht 94\] Lambrecht, K. 1994, Information Structure and Sentence Form.
Cambridge: CambridgeUniversity Press.\[Lascarides t al.
92\] Lascarides, A., and J. Oberlander.
1992.
Abducing temporal discourse.
In R. Dale,E.
Hovy, D. Rtisner, and O.
Stock (eds), Aspects of Automated Natural Language Generation, Berlin:Springer, 167-182.\[Mayer et al 96\] Mayer, M.C., and E Pirri.
1996.
A study on the logic of abduction, in W. Wahlster (ed),Proceedings of the 12th European Conference on Artificial Intelligence (ECA196), Chichester; Wiley,18-22.\[Meyer-Klabunde 96\] Meyer-Klabunde, R. 1996.
A case study on feedback incognitive models oflanguageproduction.
In W. Hoeppner (ed), Proceedings of the 6th European Workshop on Natural LanguageGeneration, UniversitSt-GH Duisburg, Institut ftir Informatik; Report Nr.
SI- 17, 61-71.\[Pads 93\] Paris, C. 1993.
User Modelling in Text Generation.
London: Pinter.\[Porzel et al in press\] Porzel, R., M. Jansche, and R. Meyer-Klabunde.
In press.
The generation ofspatialdescriptions from a cognitive point of view.
In P. Olivier (ed), Vision and Language, Berlin: Springer.\[Prince 81\] Prince, E.E 1981.
Toward a taxonomy Of given-new information.
In P. Cole (ed), RadicalPragmatics, New York: Academic Press, 223-255.\[Stickel 90\] Stickel, M.E.
1990.
Rationale and methods for abductive r asoning in natural language inter-pretation.
In R. Studer (ed), Natural Language and Logic, Berlin: Springer, 233-252.\[Thomason et al 96\] Thomason, R.H., J.R. Hobbs, and J.D.
Moore.
i996.
Communicative goals.
:InK.
Jokinen, M. Maybury, M. Zock, and I. Zukerman (eds), Proceedings of the ECAI 96 WorkshopGaps and Bridges: New Directions in Planning and Natural Language Generation, Budapest, 7-12.\[Thomason et al 97\] Thomason, R.H., and J.R. Hobbs.
1997.
Interrelating interpretation a d generationin an abductive framework.
Paper presented atthe AAAI Fall 1997 Symposium on CommunicativeAction in Humans and Machines.
Cambridge, MA.\[Vallduvf 92\] Vallduvf, E. 1992.
The Informational Component.
New York: Garland.\[Wiltschko 95\] Wiltschko, M. 1995.
Presuppositions i  German dislocation constructions.
Folia Linguis-tica XXIX, 265-295.117
