First Joint Conference on Lexical and Computational Semantics (*SEM), pages 482?486,Montre?al, Canada, June 7-8, 2012. c?2012 Association for Computational LinguisticsSB: mmSystem - Using Decompositional Semantics for LexicalSimplificationMarilisa AmoiaDepartment of Applied LinguisticsUniversity of Saarlandm.amoia@mx.uni-saarland.deMassimo RomanelliDFKI GmBHSaarbrcken, Germanyromanell@dfki.deAbstractIn this paper, we describe the system we sub-mitted to the SemEval-2012 Lexical Simplifi-cation Task.
Our system (mmSystem) com-bines word frequency with decompositionalsemantics criteria based on syntactic structurein order to rank candidate substitutes of lexicalforms of arbitrary syntactic complexity (one-word, multi-word, etc.)
in descending orderof (cognitive) simplicity.
We believe that theproposed approach might help to shed light onthe interplay between linguistic features andlexical complexity in general.1 IntroductionLexical simplification is a subtask of the more gen-eral text simplification task which attempts at re-ducing the cognitive complexity of a text so thatit can be (better) understood by a larger audience.Text simplification has a wide range of applicationswhich includes applications for the elderly, learnersof a second language, children or people with cog-nitive deficiencies, etc.Works on text simplification mostly focus on re-ducing the syntactic complexity of the text (Sid-dharthan, 2011; Siddharthan, 2006) and only littlework has addressed the issue of lexical simplifica-tion (Devlin, 1999; Carroll et al, 1999).The Lexical Simplification Task (Specia et al,2012) proposed within the SemEval-2012 is the firstattempt to explore the nature of the lexical simpli-fication more systematically.
This task requires par-ticipating systems, given a context and a target word,to automatically generate a ranking of substitutes,i.e.
lexical forms conveying similar meanings tothe target word, such that cognitively simpler lexi-cal forms are ranked higher than more difficult ones.In this paper, we describe the system we sub-mitted to the SemEval-2012 Lexical SimplificationTask.
In order to rank the candidate substitutes of alexical form in descending order of simplicity, oursystem (mmSystem) combines word frequency withdecompositional semantics criteria based on syntac-tic structure.
The mmSystem achieved an averageranking if compared with the other participating sys-tems and the baselines.
We believe that the approachproposed in this paper might help to shed light onthe interplay between linguistic features and cogni-tive complexity in general.2 The Lexical Simplification TaskThe SemEval-2012 Lexical Simplification Task re-quires participating systems to automatically gen-erate a ranking of lexical forms conveying similarmeanings on cognitive simplicity criteria and can bedefined as follows.
Given a short text C called thecontext and which generally corresponds to a sen-tence, a target word T and a list LS of candidatesubstitutes for T , i.e.
a list of quasi-synonyms of thetarget word, the task for a system consists in pro-viding a ranking on LS such that the original list ofsubstitutes is sorted over simplicity, from the cogni-tively simplest to the cognitively most difficult lexi-cal form.As the examples from (1) to (3) show, the LexicalSimplification Task includes substitutes of differentsyntactic complexity which might vary from simpleone-word substitutes as in (1) (the lexical forms that482can function as substitutes include content words,i.e.
nouns (n), verbs (v), adjectives (a) and adverbs(r)) to collocations, negated forms as in (2) or evendefinition-like paraphrases as for instance wind andknock the breath out of in example (3).
(1)C: He suggested building an experimental hy-pertext ?web?
for the worldwide.a communityof physicists who used CERN and its publica-tions.T: worldwide.aLS: worldwide, global, international(2)C: Go to hell!
she remembers Paul yelling ather shortly.r after their wedding.T: shortly.rLS: soon, a little, just, almost immediately,shortly, not long(3)C: Now however she was falling through thatskylight, the strong dark figure that had ap-peared out of nowhere falling through with her,his arms tightly entwined about her, his shoul-der having winded.v her.T: winded.vLS: knock her breathless, knock the wind outof, choke, wind, knock the breath out of, knockthe air out ofThe organizers of the Lexical Simplification Taskprovide a corpus of 300 trial and 1710 test sentencesdefining the context of the target word and the as-sociated list of candidate substitutes.
To produce agold standard, 5 human annotators manually rankedthe list of substitutes associated to each context.
Fi-nally, a scoring algorithm is provided for comput-ing agreement between the output of the system andthe manually ranked gold standard.
The scoring al-gorithm is based on the Kappa measure for inter-annotator agreement.3 The mmSystemOur aim by participating in the SemEval-2012 Lexi-cal Simplification Task (Task 1) was to investigatethe nature of lexical simplicity/complexity and toidentify the linguistic features that are responsiblefor it.
The system we have developed is a first stepin this direction.
The idea behind our frameworkis the following.
We build on previous work (De-vlin, 1999; Carroll et al, 1999) that approximatesimplicity with word frequency, such that the cog-nitively simpler lexical form is the one that is morefrequent in the language.
While this definition mighteasily apply to one-word substitutes or collocations,it poses some problems in the case of multi-word-expressions or of syntactically more complex lexi-cal forms (e.g.
definition like paraphrases) like thoseproposed in the substitute lists in the SemEval-2012Task 1.Our approach builds on the baseline definition ofsimplicity based on word frequency and integratesit with (de)compositional semantics considerations.Therefore, in order to operationalize the notion ofsimplicity in our system we adopt different strategiesdepending on the syntactic complexity of the lexicalform that forms the substitute.?
In the case of one-word substitutes or commoncollocations we use the frequency associated byWordNet (Fellbaum, 1998) to the lexical formas a metric to rank the substitutes, i.e.
thesubstitute with the highest frequency is rankedhigher.
For instance, the lexical item intelligentis ranked lower than clever as it has a lowerfrequency in the language (as defined in Word-Net).?
In the case of multi-words or syntactic complexsubstitutes, we apply so-called relevance rules.Those are based on (de)compositional semanticcriteria and attempt to identify a unique contentword in the substitute that better approximatesthe whole lexical form.
Thus, we assign to thewhole lexical form the frequency associated tothis most relevant content word and use it forranking the whole substitute.
For instance, rel-evance rules assign to multi-word substitutessuch as most able or not able the same fre-quency, and namely that associated with thecontent word able.4833.1 ImplementationIn this section we describe in more details the im-plementation of the mmSystem.
The system designcan be summarized as follows.Step 1: POS-Tagging In the first step, context andthe associated substitutes are parsed1 so to ob-tain a flat representation of their syntax.
Ba-sically at this level, we collect Part-Of-Speechinformation for all content words in the contextas well as in the substitute list.Step 2: Relevance Rules In the second step, de-pending on the syntactic representation of thesubstitutes, the system selects a relevance rulethat identifies the one-word lexical form thatwill be used for representing the meaning of thewhole substitute.Step 3: Word Sense Tagging The system ap-plies word sense tagging and assigns a Word-Net sense to the target words and their can-didate substitutes.
In this step, we relyon the SenseRelate::TargetWord package (Pat-wardhan et al, 2005) and use the Lesk algo-rithm (Lesk, 1986) for word sense disambigua-tion.Step 4: Substitute Ranking Following (Carroll etal., 1999) that pointed out that rare words gen-erally have only one sense, in order to associatea frequency index to each candidate substitute(wi), we use the number of senses associatedby WordNet to a lexical item of a given partof speech, as an approximation of its frequency(fi).
Further, we extract from WordNet the fre-quency of the word sense (fwnsi) associated tothe lexical item wi at step 3.
Words not found inWordNet it assigned a null frequency (fi = 0,fwnsi = 0).
Finally, we rank the substitute inthe following way:?
if f1 6= f2w1 < w2, if f1 > f2 andw2 < w1 otherwise,?
else if f1 = f2w1 < w2, if fwns1 > fwns2 andw2 < w1 otherwise.Input:Sentence 993: ?It is light.a and easy to use.
?Substitutes: portable;unheavy;not heavy;lightStep 1: POS-Taggingportable#A; unheavy#A; not#Neg heavy#A; light#AStep 2: Relevance Rulesportable#A; unheavy#A; heavy#A#; light#AStep 3: WSDportable#A#wns:2; unheavy#A#wns:?
; heavy#A#wns:2;light#A#wns:25Step 4: Rankingportable#f:2; unheavy#f:0; heavy#f:27; light#f:25not heavy < light < portable < unheavyGold Ranking:light < not heavy < portable < unheavyTable 1: Example of mmSystem processing steps.Table 1 shows an example of data processing.3.2 Relevance RulesRelying on previous work on compositional seman-tics of multi-word-expression (Reddy et al, 2011;Venkatapathy and Joshi, 2005; Baldwin et al, 2003)we defined a set of hand-written rules to assign therelevant meaning to a complex substitute.
Relevancerules are used to decompose the meaning of a com-plex structure and identify the most relevant wordconveying the semantics of the whole, so that thefrequency associated to the whole lexical form is ap-proximated by the frequency of this most relevantform:?
a one-word lexical item is mapped to itself, e.g.run.v ?
run.v?
a multi-word lexical form including only onecontent word is mapped to this content word,e.g.
not.Neg nice.a?
nice.a orbe.Cop able.a?
able.a?
in the case of a multi-word lexical item includ-ing more than one content word, we take intoaccount the syntactic structure of the lexicalitem and apply heuristics to decide which con-tent word is more relevant for the meaning ofthe whole.
The heuristics we used are basedon the empirical analysis of the trial data setprovided by the Task 1 organizers that contains1We used the Stanford Parser (Klein and Manning, 2003).484about 300 contexts.
As an example consider alexical item including a verb construction withstructure V1 + to + V2 that is mapped by ourrules to the second verb form V2, e.g.
try.V1 toescape.V2 ?
escape.V2.Table 2 shows some examples of relevance rules de-fined in the mmSystem.Syntax Example R FormV + Prep engage for VCop + Adj be able AdjCop + V be worried VAdv + V anxiously anticipate AdvAdj+N adnormal growth AdjN1 + N2 death penalty N1N1 + PrepOf + N2 person of authority N2V+N take notice NV1+to+V2 try to escape V2Table 2: Example of relevance rules.These relevance rules allow for a preliminary in-vestigation of the nature of lexical complexity.
Forinstance, we found that in many cases, it is the mod-ifying element of a complex expression that is re-sponsible for a shift in lexical complexity:(4) a. lie<say falsely<say untruthfullyb.
sample< typical sample < representativesample4 ResultsThe Task 1 overall result can be found in (Speciaet al, 2012).
The mmSystem achieved an averageranking (score=0.289) if compared with the otherparticipating systems and the baselines that corre-sponds to an absolute inter-annotator agreement be-tween system output and golden-standard around66%.
Interestingly none of the systems achievedan absolute agreement higher than 75% in this task.This confirms that lexical simplification still remainsa difficult task and that the nature of the phenomenaunderlying it should be better explored.Table 3 shows the performance of our system persyntactic category.
The values are a bit higher thanin the official results of Task 1 as the system versionused for submission was buggy, however the rank-ing of our system with respect to the other partici-pating systems remains the same.
Interestingly, thebest score were achieved for adverbs (0.352) and ad-jectives (0.342).
This can be explained with the factthat the decompositional semantics of these categoryis better accounted for by our rules.The relative low performance achieved by themmSystem can be explained by the fact that ourrules only select one content word and use its fre-quency for ranking.
This metric alone is clearly notenough to explain all cases of lexical simplification.As an example of the complexity of this issue, con-sider the interplay of negation and compositional se-mantics: The negation of a very frequent verb formmight not be so simple to understand as its antonym,e.g.
don?t, not remember/forget vs. omit to, fail toremember/forget.
We believe, that a more system-atic analysis of the lexical semantics involved in lex-ical simplicity might improve the performance of thesystem.Noun Verb Adj Adv TOTcAgr: 0.5 0.5 0.5 0.5 0.5aAgr: 0.658 0.658 0.671 0.676 0.665Score: 0.316 0.315 0.342 0.352 0.329Table 3: mmSystem scores per syntactic category.
In thetable cAgr represents the agreement by chance, aAgr isthe absolute inter-annotator agreement between systemoutput and gold ranking and score is the normalized sys-tem score.
These values corresponds to P(A) and P(E)observed in the data.5 ConclusionIn this paper we presented the mmSystem for lexicalsimplification we submitted to the SemEval-2012Task 1.
The system combines simplification strate-gies based on word frequency with decompositionalsemantic criteria.
The mmSystem achieved an aver-age performance.
The aim of our work was in facta preliminary investigation of the interplay between(de)compositional semantics and lexical or cognitivesimplicity in general.
Doubtlessly much remain tobe done in order to provide a more efficient formal-ization of such effects.
In future work, we want toperform a wider corpus analysis and study the im-pact of other linguistic features such as lexical se-mantics on lexical simplicity.485ReferencesTimothy Baldwin, Colin Bannard, Takaaki Tanaka, andDominic Widdows.
2003.
An empirical model ofmultiword expression decomposability.
In Proceed-ings of the ACL 2003 workshop on Multiword expres-sions: analysis, acquisition and treatment - Volume 18,MWE ?03, pages 89?96, Stroudsburg, PA, USA.
Asso-ciation for Computational Linguistics.John Carroll, Guido Minnen, Darren Pearce, YvonneCanning, Siobhan Devlin, and John Tait.
1999.
Sim-plifying text for language-impaired readers.
In In Pro-ceedings of the 9th Conference of the European Chap-ter of the Association for Computational Linguistics(EACL, pages 269?270.S.
Devlin.
1999.
Simplifying natural language for apha-sic readers.
Ph.D. thesis, University of Sunderland,UK.Christiane Fellbaum.
1998.
WordNet: An ElectronicLexical Database.
Cambridge, MA: MIT Press.Dan Klein and Christopher D. Manning.
2003.
Accu-rate unlexicalized parsing.
In Proceedings of the 41stMeeting of the Association for Computational Linguis-tics, pages 423?430.M.
Lesk.
1986.
Automatic sense disambiguation usingmachine readable dictionaries: How to tell a pine conefrom a ice cream cone.
In Proceedings of SIGDOV?86.Siddharth Patwardhan, Satanjeev Banerjee, and Ted Ped-ersen.
2005.
Senserelate::targetword - a generalizedframework for word sense disambiguation.
In Pro-ceedings of the Demonstration and Interactive PosterSession of the 43rd Annual Meeting of the Associationfor Computational Linguistics, pages 73?76, Ann Ar-bor, MI.Siva Reddy, Diana McCarthy, and Suresh Manandhar.2011.
An empirical study on compositionality in com-pound nouns.
In Proceedings of the InternationalJoint Conference on Natural Language Processing2011 (IJCNLP-2011), Thailand.Advaith Siddharthan.
2006.
Syntactic simplification anttext cohesion.
Research on Language and Computa-tion, 4(1):77?109.Advaith Siddharthan.
2011.
Text simplification usingtyped dependencies: A comparision of the robustnessof different generation strategies.
In Proceedings ofthe 13th European Workshop on NLG.Lucia Specia, Sujay K. Jauhar, and Rada Mihalcea.2012.
Semeval-2012 task 1: English lexical simplifi-cation.
In Proceedings of the 6th International Work-shop on Semantic Evaluation (SemEval 2012), Mon-treal, Canada.Sriram Venkatapathy and Aravind K. Joshi.
2005.
Mea-suring the relative compositionality of verb-noun (v-n)collocations by integrating features.
In Proceedings ofthe conference on Human Language Technology andEmpirical Methods in Natural Language Processing,HLT ?05, pages 899?906, Stroudsburg, PA, USA.
As-sociation for Computational Linguistics.486
