Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 834?843,Uppsala, Sweden, 11-16 July 2010. c?2010 Association for Computational LinguisticsBilingual Sense Similarity for Statistical Machine TranslationBoxing Chen, George Foster and Roland KuhnNational Research Council Canada283 Alexandre-Tach?
Boulevard, Gatineau (Qu?bec), Canada J8X 3X7{Boxing.Chen, George.Foster, Roland.Kuhn}@nrc.caAbstractThis paper proposes new algorithms to com-pute the sense similarity between two units(words, phrases, rules, etc.)
from parallel cor-pora.
The sense similarity scores are computedby using the vector space model.
We then ap-ply the algorithms to statistical machine trans-lation by computing the sense similarity be-tween the source and target side of translationrule pairs.
Similarity scores are used as addi-tional features of the translation model to im-prove translation performance.
Significant im-provements are obtained over a state-of-the-arthierarchical phrase-based machine translationsystem.1 IntroductionThe sense of a term can generally be inferredfrom its context.
The underlying idea is that aterm is characterized by the contexts it co-occurswith.
This is also well known as the Distribu-tional Hypothesis (Harris, 1954): terms occurringin similar contexts tend to have similar mean-ings.
There has been a lot of work to compute thesense similarity between terms based on theirdistribution in a corpus, such as (Hindle, 1990;Lund and Burgess, 1996; Landauer and Dumais,1997; Lin, 1998; Turney, 2001; Pantel and Lin,2002; Pado and Lapata, 2007).In the work just cited, a common procedure isfollowed.
Given two terms to be compared, onefirst extracts various features for each term fromtheir contexts in a corpus and forms a vectorspace model (VSM); then, one computes theirsimilarity by using similarity functions.
The fea-tures include words within a surface window of afixed size (Lund and Burgess, 1996), grammati-cal dependencies (Lin, 1998; Pantel and Lin2002; Pado and Lapata, 2007), etc.
The similari-ty function which has been most widely used iscosine distance (Salton and McGill, 1983); othersimilarity functions include Euclidean distance,City Block distance (Bullinaria and Levy; 2007),and Dice and Jaccard coefficients (Frakes andBaeza-Yates, 1992), etc.
Measures of monolin-gual sense similarity have been widely used inmany applications, such as synonym recognizing(Landauer and Dumais, 1997), word clustering(Pantel and Lin 2002), word sense disambigua-tion (Yuret and Yatbaz 2009), etc.Use of the vector space model to computesense similarity has also been adapted to the mul-tilingual condition,  based on the assumption thattwo terms with similar meanings often occur incomparable contexts across languages.
Fung(1998) and Rapp (1999) adopted VSM for theapplication of extracting translation pairs fromcomparable or even unrelated corpora.
The vec-tors in different languages are first mapped to acommon space using an initial bilingual dictio-nary, and then compared.However, there is no previous work that usesthe VSM to compute sense similarity for termsfrom parallel corpora.
The sense similarities, i.e.the translation probabilities in a translation mod-el, for units from parallel corpora are mainlybased on the co-occurrence counts of the twounits.
Therefore, questions emerge: how good isthe sense similarity computed via VSM for twounits from parallel corpora?
Is it useful for multi-lingual applications, such as statistical machinetranslation (SMT)?In this paper, we try to answer these questions,focusing on sense similarity applied to the SMTtask.
For this task, translation rules are heuristi-cally extracted from automatically word-alignedsentence pairs.
Due to noise in the training cor-pus or wrong word alignment, the source andtarget sides of some rules are not semanticallyequivalent, as can be seen from the following834real examples which are taken from the rule tablebuilt on our training data (Section 5.1):??
?
X ??
||| one of X (*)??
?
X ??
||| one of X in the world??
??
||| many citizens??
??
||| many hong kong residents (*)The source and target sides of the rules with (*)at the end are not semantically equivalent; itseems likely that measuring the semantic similar-ity from their context between the source andtarget sides of rules might be helpful to machinetranslation.In this work, we first propose new algorithmsto compute the sense similarity between twounits (unit here includes word, phrase, rule, etc.
)in different languages by using their contexts.Second, we use the sense similarities between thesource and target sides of a translation rule toimprove statistical machine translation perfor-mance.This work attempts to measure directly thesense similarity for units from different languag-es by comparing their contexts1.
Our contributionincludes proposing new bilingual sense similarityalgorithms and applying them to machine trans-lation.We chose a hierarchical phrase-based SMTsystem as our baseline; thus, the units involvedin computation of sense similarities are hierar-chical rules.2 Hierarchical phrase-based MT systemThe hierarchical phrase-based translation method(Chiang, 2005; Chiang, 2007) is a formal syntax-based translation modeling method; its transla-tion model is a weighted synchronous contextfree grammar (SCFG).
No explicit linguistic syn-tactic information appears in the model.
AnSCFG rule has the following form:~,,??
?Xwhere X is a non-terminal symbol shared by allthe rules; each rule has at most two non-terminals.
?
(? )
is a source (target) string con-sisting of terminal and non-terminal symbols.
~defines a one-to-one correspondence betweennon-terminals in ?
and ?
.1There has been a lot of work (more details in Section 7) onapplying word sense disambiguation (WSD) techniques inSMT for translation selection.
However, WSD techniquesfor SMT do so indirectly, using source-side context to helpselect a particular translation for a source rule.source targetIni.
phr.
?
??
?
??
he attended the meetingRule 1Context 1?
??
?
X1?
?he attended X1the, meetingRule 2Context 2??
?, ?
?, ?the meetinghe, attendedRule 3Context 3?
X1???
?, ?he X1 the meetingattendedRule 4Context 4??
??,?
?attendedhe, the, meetingFigure 1: example of hierarchical rule pairs and theircontext features.Rule frequencies are counted during rule ex-traction over word-aligned sentence pairs, andthey are normalized to estimate features on rules.Following (Chiang, 2005; Chiang, 2007), 4 fea-tures are computed for each rule:?
)|( ?
?P  and )|( ?
?P  are direct and in-verse rule-based conditional probabilities;?
)|( ?
?wP  and )|( ?
?wP are direct and in-verse lexical weights (Koehn et al, 2003).Empirically, this method has yielded betterperformance on language pairs such as Chinese-English than the phrase-based method because itpermits phrases with gaps; it generalizes thenormal phrase-based models in a way that allowslong-distance reordering (Chiang, 2005; Chiang,2007).
We use the Joshua implementation of themethod for decoding (Li et al, 2009).3 Bag-of-Words Vector Space ModelTo compute the sense similarity via VSM, wefollow the previous work (Lin, 1998) andrepresent the source and target side of a rule byfeature vectors.
In our work, each feature corres-ponds to a context word which co-occurs withthe translation rule.3.1 Context FeaturesIn the hierarchical phrase-based translation me-thod, the translation rules are extracted by ab-stracting some words from an initial phrase pair(Chiang, 2005).
Consider a rule with non-terminals on the source and target side; for a giv-en instance of the rule (a particular phrase pair inthe training corpus), the context will be thewords instantiating the non-terminals.
In turn, thecontext for the sub-phrases that instantiate thenon-terminals will be the words in the remainderof the phrase pair.
For example in Figure 1, if we835have an initial phrase pair ?
??
?
??
||| heattended the meeting, and we extract four rulesfrom this initial phrase: ?
??
?
X1 ||| he at-tended X1, ??
||| the meeting, ?
X1??
||| heX1 the meeting, and??
?
||| attended.
There-fore, the and meeting are context features of tar-get pattern he attended X1; he and attended arethe context features of the meeting; attended isthe context feature of he X1 the meeting;  also he,the and meeting are the context feature of at-tended (in each case, there are also source-sidecontext features).3.2 Bag-of-Words ModelFor each side of a translation rule pair, its contextwords are all collected from the training data,and two ?bags-of-words?
which consist of col-lections of source and target context words co-occurring with the rule?s source and target sidesare created.
},...,,{},...,,{2121JeIfeeeBfffB==(1)where )1( Iifi ??
are source context wordswhich co-occur with the source side of rule ?
,and )1( Jje j ??
are target context wordswhich co-occur with the target side of rule ?
.Therefore, we can represent source and targetsides of the rule by vectors fvvand evvas in Eq-uation (2):},...,,{},...,,{2121JIeeeeffffwwwvwwwv==vv(2)whereifw  and jew are values for each sourceand target context feature; normally, these valuesare based on the counts of the words in the cor-responding bags.3.3 Feature Weighting SchemesWe use pointwise mutual information (Church etal., 1990) to compute the feature values.
Let c( fBc ?
or eBc ?  )
be a context word and),( crF  be the frequency count of a rule r (?
or? )
co-occurring with the context word c. Thepointwise mutual information ),( crMI  is de-fined as:NcFNrFNcrFcrMIcrw )(log)(log),(log),(),(?==(3)where N is the total frequency counts of all rulesand their context words.
Since we are using thisvalue as a weight, following (Turney, 2001), wedrop log, N and )(rF .
Thus (3) simplifies to:)(),(),(cFcrFcrw =(4)It can be seen as an estimate of )|( crP , the em-pirical probability of observing r given c.A problem with )|( crP  is that it is biasedtowards infrequent words/features.
We thereforesmooth ),( crw  with add-k smoothing:kRcFkcrFkcrFkcrFcrw Rii++=++=?=)(),()),((),(),(1(5)where k is a tunable global smoothing constant,and R is the number of rules.4 Similarity FunctionsThere are many possibilities for calculating simi-larities between bags-of-words in different lan-guages.
We consider IBM model 1 probabilitiesand cosine distance similarity functions.4.1 IBM Model 1 ProbabilitiesFor the IBM model 1 similarity function, we takethe geometric mean of symmetrized conditionalIBM model 1 (Brown et al, 1993) bag probabili-ties, as in Equation (6).
))|()|((),( feef BBPBBPsqrtsim ?=??
(6)To compute )|( ef BBP , IBM model 1 as-sumes that all source words are conditionallyindependent, so that:?==Iieief BfpBBP1)|()|(                (7)To compute, we use a ?Noisy-OR?
combina-tion which has shown better performance thanstandard IBM model 1 probability, as describedin (Zens and Ney, 2004):)|(1)|( eiei BfpBfp ?=                       (8)?=??
?Jjjiei efpBfp1))|(1(1)|(          (9)where )|( ei Bfp  is the probability that if  is notin the translation of eB , and  is the IBM model 1probability.4.2 Vector Space MappingA common way to calculate semantic similarityis by vector space cosine distance; we will also836use this similarity function in our algorithm.However, the two vectors in Equation (2) cannotbe directly compared because the axes of theirspaces represent different words in different lan-guages, and also their dimensions I and J are notassured to be the same.
Therefore, we need tofirst map a vector into the space of the other vec-tor, so that the similarity can be calculated.
Fung(1998) and Rapp (1999) map the vector one-dimension-to-one-dimension (a context word is adimension in each vector space) from one lan-guage to another language via an initial bilingualdictionary.
We follow (Zhao et al, 2004) to dovector space mapping.Our goal is ?
given a source pattern ?
to dis-tinguish between the senses of its associated tar-get patterns.
Therefore, we map all vectors intarget language into the vector space in thesource language.
What we want is a representa-tionavvin the source language space of the targetvectorevv.
To getavv, we can let ifaw , the weightof the ith source feature, be a linear combinationover target features.
That is to say, given asource feature weight for fi, each target featureweight is linked to it with some probability.
Sothat we can calculate a transformed vector fromthe target vectors by calculating weights ifaw  us-ing a translation lexicon:?==Jjejifa ji wefw1)|Pr(                    (10)where )|( ji efp  is a lexical probability (we useIBM model 1 probability).
Now the source vec-tor and the mapped vector avvhave the same di-mensions as shown in (11):},...,,{},...,,{2121IIfafafaaffffwwwvwwwv==vv(11)4.3 Na?ve Cosine Distance SimilarityThe standard cosine distance is defined as theinner product of the two vectors fvvand avvnor-malized by their norms.
Based on Equation (10)and (11), it is easy to derive the similarity as fol-lows:)()()|Pr(||||),cos(),(12121 1???
?=== ==?
?==IifaIIfIiJjejifafafafiijiwsqrtwsqrtwefwvvvvvvsim vvvvvv??
(12)where I and J are the number of the words insource and target bag-of-words;ifw  and jew arevalues of source and target features; ifaw  is thetransformed weight mapped from all target fea-tures to the source dimension at word fi.4.4 Improved Similarity FunctionTo incorporate more information than the origi-nal similarity functions ?
IBM model 1 proba-bilities in Equation (6) and na?ve cosine distancesimilarity function in Equation (12) ?
we refinethe similarity function and propose a new algo-rithm.As shown in Figure 2, suppose that we have arule pair ),( ??
.
fullfC  and fulleC  are the contextsextracted according to the definition in section 3from the full training data for ?and for ?
, re-spectively.
coocfC and cooceC  are the contexts for?and ?
when ?and ?
co-occur.
Obviously,they satisfy the constraints: fullfcoocf CC ?
andfullecooce CC ?
.
Therefore, the original similarityfunctions are to compare the two context vectorsbuilt on full training data directly, as shown inEquation (13).
),(),( fullefullf CCsimsim =??
(13)Then, we propose a new similarity function asfollows:321 ),(),(),(),(????
?coocefullecoocecoocfcoocffullf CCsimCCsimCCsimsim?
?=(14)where the parameters i?
(i=1,2,3) can be tunedvia minimal error rate training (MERT) (Och,2003).Figure 2: contexts for rule ?and ?
.A unit?s sense is defined by all its contexts inthe whole training data; it may have a lot of dif-ferent senses in the whole training data.
Howev-er, when it is linked with another unit in the otherlanguage, its sense pool is constrained and is just?
?fullfC  coocfCfulleC  cooceC837a subset of the whole sense set.
),( coocffullf CCsimis the metric which evaluates the similarity be-tween the whole sense pool of ?
and the sensepool when ?
co-occurs with ?
;),( coocefulle CCsim  is the analogous similarity me-tric for ?
.
They range from 0 to 1.
These twometrics both evaluate the similarity for two vec-tors in the same language, so using cosine dis-tance to compute the similarity is straightfor-ward.
And we can set a relatively large size forthe vector, since it is not necessary to do vectormapping as the vectors are in the same language.
),( coocecoocf CCsim  computes the similarity betweenthe context vectors when ?and ?
co-occur.
Wemay compute ),( coocecoocf CCsim by using IBMmodel 1 probability and cosine distance similari-ty functions as Equation (6) and (12).
Therefore,on top of the degree of bilingual semantic simi-larity between a source and a target translationunit, we have also incorporated the monolingualsemantic similarity between all occurrences of asource or target unit, and that unit?s occurrenceas part of the given rule, into the sense similaritymeasure.5 ExperimentsWe evaluate the algorithm of bilingual sense si-milarity via machine translation.
The sense simi-larity scores are used as feature functions in thetranslation model.5.1 DataWe evaluated with different language pairs: Chi-nese-to-English, and German-to-English.
ForChinese-to-English tasks, we carried out the ex-periments in two data conditions.
The first one isthe large data condition, based on training datafor the NIST 2  2009 evaluation Chinese-to-English track.
In particular, all the allowed bilin-gual corpora except the UN corpus and HongKong Hansard corpus have been used for esti-mating the translation model.
The second one isthe small data condition where only the FBIS3corpus is used to train the translation model.
Wetrained two language models: the first one is a 4-gram LM which is estimated on the target side ofthe texts used in the large data condition.
Thesecond LM is a 5-gram LM trained on the so-2http://www.nist.gov/speech/tests/mt3LDC2003E14called English Gigaword corpus.
Both languagemodels are used for both tasks.We carried out experiments for translatingChinese to English.
We use the same develop-ment and test sets for the two data conditions.We first created a development set which usedmainly data from the NIST 2005 test set, andalso some balanced-genre web-text from theNIST training material.
Evaluation was per-formed on the NIST 2006 and 2008 test sets.
Ta-ble 1 gives figures for training, development andtest corpora; |S| is the number of the sentences,and |W| is the number of running words.
Fourreferences are provided for all dev and test sets.Chi EngParallelTrainLargeData|S| 3,322K|W| 64.2M 62.6MSmallData|S| 245K|W| 9.0M 10.5MDev |S| 1,506 1,506?4Test NIST06 |S| 1,664 1,664?4NIST08 |S| 1,357 1,357?4Gigaword |S| - 11.7MTable 1: Statistics of training, dev, and test sets forChinese-to-English task.For German-to-English tasks, we used WMT20064 data sets.
The parallel training data con-tains 21 million target words; both the dev setand test set contain 2000 sentences; one refer-ence is provided for each source input sentence.Only the target-language half of the paralleltraining data are used to train the language modelin this task.5.2 ResultsFor the baseline, we train the translation modelby following (Chiang, 2005; Chiang, 2007) andour decoder is Joshua5, an open-source hierar-chical phrase-based machine translation systemwritten in Java.
Our evaluation metric is IBMBLEU (Papineni et al, 2002), which performscase-insensitive matching of n-grams up to n = 4.Following (Koehn, 2004), we use the bootstrap-resampling test to do significance testing.By observing the results on dev set in the addi-tional experiments, we first set the smoothingconstant k in Equation (5) to 0.5.Then, we need to set the sizes of the vectors tobalance the computing time and translation accu-4http://www.statmt.org/wmt06/5http://www.cs.jhu.edu/~ccb/joshua/index.html838racy, i.e., we keep only the top N context wordswith the highest feature value for each side of arule 6 .
In the following, we use ?Alg1?
torepresent the original similarity functions whichcompare the two context vectors built on fulltraining data, as in Equation (13); while we use?Alg2?
to represent the improved similarity as inEquation (14).
?IBM?
represents IBM model 1probabilities, and ?COS?
represents cosine dis-tance similarity function.After carrying out a series of additional expe-riments on the small data condition and observ-ing the results on the dev set, we set the size ofthe vector to 500 for Alg1; while for Alg2, weset the sizes of fullfC  and fulleC N1 to 1000, and thesizes of coocfC  and cooceC N2 to 100.The sizes of the vectors in Alg2 are set in thefollowing process: first, we set N2 to 500 and letN1  range from 500 to 3,000, we observed that thedev set got best performance when N1 was 1000;then we set N1 to 1000 and let N1 range from 50to 1000, we got best performance when N1 =100.We use this setting as the default setting in allremaining experiments.Algorithm NIST?06 NIST?08Baseline 27.4 21.2Alg1 IBM 27.8* 21.5Alg1 COS 27.8* 21.5Alg2 IBM 27.9* 21.6*Alg2 COS 28.1** 21.7*Table 2: Results (BLEU%) of small data Chinese-to-English NIST task.
Alg1 represents the original simi-larity functions as in Equation (13); while Alg2represents the improved similarity as in Equation(14).
IBM represents IBM model 1 probability, andCOS represents cosine distance similarity function.
*or ** means result is significantly better than thebaseline (p < 0.05 or p < 0.01, respectively).Ch-En De-EnAlgorithm NIST?06 NIST?08 Test?06Baseline 31.0 23.8 26.9Alg2 IBM 31.5* 24.5** 27.2*Alg2 COS 31.6** 24.5** 27.3*Table 3: Results (BLEU%) of large data Chinese-to-English NIST task and German-to-English WMTtask.6We have also conducted additional experiments by remov-ing the stop words from the context vectors; however, wedid not observe any consistent improvement.
So we filterthe context vectors by only considering the feature values.Table 2 compares the performance of Alg1and Alg2 on the Chinese-to-English small datacondition.
Both Alg1 and Alg2 improved theperformance over the baseline, and Alg2 ob-tained slight and consistent improvements overAlg1.
The improved similarity function Alg2makes it possible to incorporate monolingualsemantic similarity on top of the bilingual se-mantic similarity, thus it may improve the accu-racy of the similarity estimate.
Alg2 significantlyimproved the performance over the baseline.
TheAlg2 cosine similarity function got 0.7 BLEU-score (p<0.01) improvement over the baselinefor NIST 2006 test set, and a 0.5 BLEU-score(p<0.05) for NIST 2008 test set.Table 3 reports the performance of Alg2 onChinese-to-English NIST large data conditionand German-to-English WMT task.
We can seethat IBM model 1 and cosine distance similarityfunction both obtained significant improvementon all test sets of the two tasks.
The two similari-ty functions obtained comparable results.6 Analysis and Discussion6.1 Effect of Single FeaturesIn Alg2, the similarity score consists of threeparts as in Equation (14): ),( coocffullf CCsim ,),( coocefulle CCsim , and ),( coocecoocf CCsim ; where),( coocecoocf CCsim  could be computed by IBM mod-el 1 probabilities ),( coocecoocfIBM CCsim  or cosine dis-tance similarity function ),( coocecoocfCOS CCsim .Therefore, our first study is to determine whichone of the above four features has the most im-pact on the result.
Table 4 shows the results ob-tained by using each of the 4 features.
First, wecan see that ),( coocecoocfIBM CCsim  always gives abetter improvement than ),( coocecoocfCOS CCsim .
Thisis because  ),( coocecoocfIBM CCsim  scores are morediverse than the latter when the number of con-text features is small (there are many rules thathave only a few contexts.)
For an extreme exam-ple, suppose that there is only one context wordin each vector of source and target context fea-tures, and the translation probability of the twocontext words is not 0.
In this case,),( coocecoocfIBM CCsim   reflects the translation proba-bility of the context word pair, while),( coocecoocfCOS CCsim  is always 1.Second, ),( coocffullf CCsim  and ),( coocefulle CCsimalso give some improvements even when used839independently.
For a possible explanation, con-sider the following example.
The Chinese word??
?
can translate to ?red?, ?communist?, or?hong?
(the transliteration of ?, when it is usedin a person?s name).
Since these translations arelikely to be associated with very different sourcecontexts, each will have a low ),( coocffullf CCsimscore.
Another Chinese word ??
may translateinto synonymous words, such as ?brook?,?stream?, and ?rivulet?, each of which will havea high  ),( coocffullf CCsim  score.
Clearly, ?
is amore ?dangerous?
word than?
?, since choos-ing the wrong translation for it would be a badmistake.
But if the two words have similar trans-lation distributions, the system cannot distinguishbetween them.
The monolingual similarity scoresgive it the ability to avoid ?dangerous?
words,and choose alternatives (such as larger phrasetranslations) when available.Third, the similarity function of Alg2 consis-tently achieved further improvement by incorpo-rating the monolingual similarities computed forthe source and target side.
This confirms the ef-fectiveness of our algorithm.CE_LD CE_SDtestset (NIST) ?06 ?08 ?06 ?08Baseline 31.0 23.8 27.4 21.2),( coocffullf CCsim  31.1 24.3 27.5 21.3),( coocefulle CCsim  31.1 23.9 27.9 21.5),( coocecoocfIBM CCsim  31.4 24.3 27.9 21.5),( coocecoocfCOS CCsim  31.2 23.9 27.7 21.4Alg2 IBM 31.5 24.5 27.9 21.6Alg2 COS 31.6 24.5 28.1 21.7Table 4: Results (BLEU%) of Chinese-to-Englishlarge data (CE_LD) and small data (CE_SD) NISTtask by applying one feature.6.2 Effect of Combining the Two Similari-tiesWe then combine the two similarity scores byusing both of them as features to see if we couldobtain further improvement.
In practice, we usethe four features in Table 4 together.Table 5 reports the results on the small datacondition.
We observed further improvement ondev set, but failed to get the same improvementson test sets or even lost performance.
Since theIBM+COS configuration has one extra feature, itis possible that it overfits the dev set.Algorithm Dev NIST?06 NIST?08Baseline 20.2 27.4 21.2Alg2 IBM 20.5 27.9 21.6Alg2 COS 20.6 28.1 21.7Alg2 IBM+COS 20.8 27.9 21.5Table 5: Results (BLEU%) for combination of twosimilarity scores.
Further improvement was only ob-tained on dev set but not on test sets.6.3 Comparison with Simple ContextualFeaturesNow, we try to answer the question: can the si-milarity features computed by the function inEquation (14) be replaced with some other sim-ple features?
We did additional experiments onsmall data Chinese-to-English task to test thefollowing features: (15) and (16) represent thesum of the counts of the context words in Cfull,while (17) represents the proportion of words inthe context of ?
that appeared in the context ofthe rule ( ??
, ); similarly, (18) is related to theproperties of the words in the context of ?
.?
?= fullfi Cf if fFN ),()( ??
(15)?
?= fullej Ce je eFN ),()( ??
(16))(),(),(???
?fCf if NfFEcoocfi?
?=           (17))(),(),( ???
?eCe je NeFEcoocej?
?=           (18)where ),( ifF ?
and ),( jeF ?
are the frequencycounts of rule ?
or ?
co-occurring with thecontext word if  or je   respectively.Feature Dev NIST?06 NIST?08Baseline 20.2 27.4 21.2+Nf 20.5 27.6 21.4+Ne 20.5 27.5 21.3+Ef 20.4 27.5 21.2+Ee 20.4 27.3 21.2+Nf+Ne 20.5 27.5 21.3Table 6: Results (BLEU%) of using simple featuresbased on context on small data NIST task.
Some im-provements are obtained on dev set, but there was nosignificant effect on the test sets.Table 6 shows results obtained by adding theabove features to the system for the small data840condition.
Although all these features have ob-tained some improvements on dev set, there wasno significant effect on the test sets.
This meanssimple features based on context, such as thesum of the counts of the context features, are notas helpful as the sense similarity computed byEquation (14).6.4 Null Context FeatureThere are two cases where no context word canbe extracted according to the definition of con-text in Section 3.1.
The first case is when a rulepair is always a full sentence-pair in the trainingdata.
The second case is when for some rulepairs, either their source or target contexts areout of the span limit of the initial phrase, so thatwe cannot extract contexts for those rule-pairs.For Chinese-to-English NIST task, there areabout 1% of the rules that do not have contexts;for German-to-English task, this number is about0.4%.
We assign a uniform number as their bi-lingual sense similarity score, and this number istuned through MERT.
We call it the null contextfeature.
It is included in all the results reportedfrom Table 2 to Table 6.
In Table 7, we show theweight of the null context feature tuned by run-ning MERT in the experiments reported in Sec-tion 5.2.
We can learn that penalties always dis-courage using those rules which have no contextto be extracted.Alg.TaskCE_SD CE_LD DEAlg2 IBM -0.09 -0.37 -0.15Alg2 COS -0.59 -0.42 -0.36Table 7: Weight learned for employing the null con-text feature.
CE_SD, CE_LD and DE are Chinese-to-English small data task, large data task and German-to-English task respectively.6.5 DiscussionOur aim in this paper is to characterize the se-mantic similarity of bilingual hierarchical rules.We can make several observations concerningour features:1) Rules that are largely syntactic in nature,such as ?
X ||| the X of, will have very diffuse?meanings?
and therefore lower similarityscores.
It could be that the gains we obtainedcome simply from biasing the system againstsuch rules.
However, the results in table 6 showthat this is unlikely to be the case: features thatjust count context words help very little.2) In addition to bilingual similarity, Alg2 re-lies on the degree of monolingual similarity be-tween the sense of a source or target unit within arule, and the sense of the unit in general.
This hasa bias in favor of less ambiguous rules, i.e.
rulesinvolving only units with closely related mean-ings.
Although this bias is helpful on its own,possibly due to the mechanism we outline in sec-tion 6.1, it appears to have a synergistic effectwhen used along with the bilingual similarityfeature.3) Finally, we note that many of the featureswe use for capturing similarity, such as the con-text ?the, of?
for instantiations of X in the unitthe X of, are arguably more syntactic than seman-tic.
Thus, like other ?semantic?
approaches, ourscan be seen as blending syntactic and semanticinformation.7 Related WorkThere has been extensive work on incorporatingsemantics into SMT.
Key papers by Carpuat andWu (2007) and Chan et al(2007) showed thatword-sense disambiguation (WSD) techniquesrelying on source-language context can be effec-tive in selecting translations in phrase-based andhierarchical SMT.
More recent work has aimedat incorporating richer disambiguating featuresinto the SMT log-linear model (Gimpel andSmith, 2008; Chiang et al 2009); predicting co-herent sets of target words rather than individualphrase translations (Bangalore et al 2009; Maus-er et al 2009); and selecting applicable rules inhierarchical (He et al 2008) and syntactic (Liu etal, 2008) translation, relying on source as well astarget context.
Work by Wu and Fung (2009)breaks new ground in attempting to match se-mantic roles derived from a semantic parseracross source and target languages.Our work is different from all the above ap-proaches in that we attempt to discriminateamong hierarchical rules based on: 1) the degreeof bilingual semantic similarity between sourceand target translation units; and 2) the monolin-gual semantic similarity between occurrences ofsource or target units as part of the given rule,and in general.
In another words, WSD explicitlytries to choose a translation given the currentsource context, while our work rates rule pairsindependent of the current context.8 Conclusions and Future WorkIn this paper, we have proposed an approach thatuses the vector space model to compute the sense841similarity for terms from parallel corpora andapplied it to statistical machine translation.
Wesaw that the bilingual sense similarity computedby our algorithm led to significant improve-ments.
Therefore, we can answer the questionsproposed in Section 1.
We have shown that thesense similarity computed between units fromparallel corpora by means of our algorithm ishelpful for at least one multilingual application:statistical machine translation.Finally, although we described and evaluatedbilingual sense similarity algorithms applied to ahierarchical phrase-based system, this method isalso suitable for syntax-based MT systems andphrase-based MT systems.
The only difference isthe definition of the context.
For a syntax-basedsystem, the context of a rule could be definedsimilarly to the way it was defined in the workdescribed above.
For a phrase-based system, thecontext of a phrase could be defined as its sur-rounding words in a given size window.
In ourfuture work, we may try this algorithm on syn-tax-based MT systems and phrase-based MT sys-tems with different context features.
It wouldalso be possible to use this technique duringtraining of an SMT system ?
for instance, to im-prove the bilingual word alignment or reduce thetraining data noise.ReferencesS.
Bangalore, S. Kanthak, and P. Haffner.
2009.
Sta-tistical Machine Translation through Global Lexi-cal Selection and Sentence Reconstruction.
In:Goutte et al(ed.
), Learning Machine Translation.MIT Press.P.
F. Brown, V. J. Della Pietra, S. A. Della Pietra &R. L. Mercer.
1993.
The Mathematics of StatisticalMachine Translation: Parameter Estimation.
Com-putational Linguistics, 19(2) 263-312.J.
Bullinaria and J.
Levy.
2007.
Extracting semanticrepresentations from word co-occurrence statistics:A computational study.
Behavior Research Me-thods, 39 (3), 510?526.M.
Carpuat and D. Wu.
2007.
Improving StatisticalMachine Translation using Word Sense Disambig-uation.
In:  Proceedings of EMNLP, Prague.M.
Carpuat.
2009.
One Translation per Discourse.
In:Proceedings of NAACL HLT Workshop on Se-mantic Evaluations, Boulder, CO.Y.
Chan, H. Ng and D. Chiang.
2007.
Word SenseDisambiguation Improves Statistical MachineTranslation.
In:  Proceedings of ACL, Prague.D.
Chiang.
2005.
A hierarchical phrase-based modelfor statistical machine translation.
In: Proceedingsof ACL, pp.
263?270.D.
Chiang.
2007.
Hierarchical phrase-based transla-tion.
Computational Linguistics.
33(2):201?228.D.
Chiang, W. Wang and K. Knight.
2009.
11,001new features for statistical machine translation.
In:Proc.
NAACL HLT, pp.
218?226.K.
W. Church and P. Hanks.
1990.
Word associationnorms, mutual information, and lexicography.Computational Linguistics, 16(1):22?29.W.
B. Frakes and R. Baeza-Yates, editors.
1992.
In-formation Retrieval, Data Structure and Algo-rithms.
Prentice Hall.P.
Fung.
1998.
A statistical view on bilingual lexiconextraction: From parallel corpora to non-parallelcorpora.
In: Proceedings of AMTA, pp.
1?17.
Oct.Langhorne, PA, USA.J.
Gimenez and L. Marquez.
2009.
DiscriminativePhrase Selection for SMT.
In: Goutte et al(ed.
),Learning Machine Translation.
MIT Press.K.
Gimpel and N. A. Smith.
2008.
Rich Source-SideContext for Statistical Machine Translation.
In:Proceedings of WMT, Columbus, OH.Z.
Harris.
1954.
Distributional structure.
Word,10(23): 146-162.Z.
He, Q. Liu, and S. Lin.
2008.
Improving StatisticalMachine Translation using Lexicalized Rule Selec-tion.
In: Proceedings of COLING, Manchester,UK.D.
Hindle.
1990.
Noun classification from predicate-argument structures.
In: Proceedings of ACL.
pp.268-275.
Pittsburgh, PA.P.
Koehn, F. Och, D. Marcu.
2003.
Statistical Phrase-Based Translation.
In: Proceedings of HLT-NAACL.
pp.
127-133, Edmonton, CanadaP.
Koehn.
2004.
Statistical significance tests for ma-chine translation evaluation.
In:  Proceedings ofEMNLP, pp.
388?395.
July, Barcelona, Spain.T.
Landauer and S. T. Dumais.
1997.
A solution toPlato?s problem: The Latent Semantic Analysistheory of the acquisition, induction, and representa-tion of knowledge.
Psychological Review.
104:211-240.Z.
Li, C. Callison-Burch, C. Dyer, J. Ganitkevitch, S.Khudanpur, L. Schwartz, W. Thornton, J. Weeseand O. Zaidan, 2009.
Joshua: An Open SourceToolkit for Parsing-based Machine Translation.
In:Proceedings of the WMT.
March.
Athens, Greece.D.
Lin.
1998.
Automatic retrieval and clustering ofsimilar words.
In: Proceedings of COLING/ACL-98.
pp.
768-774.
Montreal, Canada.842Q.
Liu, Z.
He, Y. Liu and S. Lin.
2008.
MaximumEntropy based Rule Selection Model for Syntax-based Statistical Machine Translation.
In: Proceed-ings of EMNLP, Honolulu, Hawaii.K.
Lund, and C. Burgess.
1996.
Producing high-dimensional semantic spaces from lexical co-occurrence.
Behavior Research Methods, Instru-ments, and Computers, 28 (2), 203?208.A.
Mauser, S. Hasan and H. Ney.
2009.
ExtendingStatistical Machine Translation with Discrimina-tive and Trigger-Based Lexicon Models.
In: Pro-ceedings of EMNLP, Singapore.F.
Och.
2003.
Minimum error rate training in statistic-al machine translation.
In: Proceedings of ACL.Sapporo, Japan.S.
Pado and M. Lapata.
2007.
Dependency-based con-struction of semantic space models.
ComputationalLinguistics, 33 (2), 161?199.P.
Pantel and D. Lin.
2002.
Discovering word sensesfrom text.
In: Proceedings of ACM SIGKDD Con-ference on Knowledge Discovery and Data Mining,pp.
613?619.
Edmonton, Canada.K.
Papineni, S. Roukos, T. Ward, and W. Zhu.
2002.Bleu: a method for automatic evaluation of ma-chine translation.
In Proceedings of ACL, pp.
311?318.
July.
Philadelphia, PA, USA.R.
Rapp.
1999.
Automatic Identification of WordTranslations from Unrelated English and GermanCorpora.
In: Proceedings of ACL, pp.
519?526.June.
Maryland.G.
Salton and M. J. McGill.
1983.
Introduction toModern Information Retrieval.
McGraw-Hill, NewYork.P.
Turney.
2001.
Mining the Web for synonyms:PMI-IR versus LSA on TOEFL.
In: Proceedings ofthe Twelfth European Conference on MachineLearning, pp.
491?502, Berlin, Germany.D.
Wu and P. Fung.
2009.
Semantic Roles for SMT:A Hybrid Two-Pass Model.
In: Proceedings ofNAACL/HLT, Boulder, CO.D.
Yuret and M. A. Yatbaz.
2009.
The Noisy ChannelModel for Unsupervised Word Sense Disambigua-tion.
In: Computational Linguistics.
Vol.
1(1) 1-18.R.
Zens and H. Ney.
2004.
Improvements in phrase-based statistical machine translation.
In: Proceed-ings of NAACL-HLT.
Boston, MA.B.
Zhao, S. Vogel, M. Eck, and A. Waibel.
2004.Phrase pair rescoring with term weighting for sta-tistical machine translation.
In Proceedings ofEMNLP, pp.
206?213.
July.
Barcelona, Spain.843
