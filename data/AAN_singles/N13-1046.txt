Proceedings of NAACL-HLT 2013, pages 439?444,Atlanta, Georgia, 9?14 June 2013. c?2013 Association for Computational LinguisticsDudley North visits North London:Learning When to Transliterate to ArabicMahmoud Azab Houda BouamorCarnegie Mellon UniversityP.O.
Box 24866, Doha, Qatar{mazab, hbouamor, behrang, ko}@qatar.cmu.eduBehrang Mohit Kemal OflazerAbstractWe report the results of our work on automat-ing the transliteration decision of named en-tities for English to Arabic machine trans-lation.
We construct a classification-basedframework to automate this decision, evalu-ate our classifier both in the limited news andthe diverse Wikipedia domains, and achievepromising accuracy.
Moreover, we demon-strate a reduction of translation error andan improvement in the performance of anEnglish-to-Arabic machine translation sys-tem.1 IntroductionTranslation of named entities (NEs) is importantfor NLP applications such as Machine Translation(MT) and Cross-lingual Information Retrieval.
ForMT, NEs are major subset of the out-of-vocabularyterms (OOVs).
Due to their diversity, they cannotalways be found in parallel corpora, dictionaries orgazetteers.
Thus, state-of-the-art of MT needs tohandle NEs in specific ways.
For instance, in theEnglish-Arabic automatic translation example givenin Figure 1, the noun ?North?
has been erroneouslytranslated to ?
?J?A???
@ /Al$mAlyp ?
(indicating thenorth direction in English) instead of being translit-erated to ?
HP?
K / nwrv?.As shown in Figure 1, direct translation of in-vocabulary terms could degrade translation quality.Also blind transliteration of OOVs does not neces-sarily contribute to translation adequacy and may ac-tually create noisy contexts for the language modeland the decoder.English Input: Dudley North was an English merchant.SMT output: .
?KQ?m.'B@ Qk.
AK?J?A???
@ ?
?X?X 	?A?kAn dwdly Al$mAlyp tAjr AlInjlyzyp.Correct Translation: .
?Q?m.' @Qk.
AK HP?
K ?
?X?X 	?A?kAn dwdly nwrv tAjr Injlyzy.Figure 1: Example of a NE translation error.An intelligent decision between translation andtransliteration should use semantic and contextualinformation such as the type of the named-entityand the surrounding terms.
In this paper, we con-struct and evaluate a classification-based frameworkto automate the translation vs. transliteration deci-sion.
We evaluate our classifier both in the limitednews and diverse Wikipedia domains, and achievepromising accuracy.
Moreover, we conduct an ex-trinsic evaluation of the classifier within an Englishto Arabic MT system.
In an in-domain (news) MTtask, the classifier contributes to a modest (yet sig-nificant) improvement in MT quality.
Moreover, fora Wikipedia translation task, we demonstrate thatour classifier can reduce the erroneous translation of60.5% of the named entities.In summary our contributions are: (a) We au-tomatically construct a bilingual lexicon of NEspaired with the transliteration/translation decisionsin two domains.1 (b) We build a binary classi-fier for transliteration and translation decision witha promising accuracy (c) We demonstrate its utility1The dataset can be found athttp://www.qatar.cmu.edu/?behrang/NETLexicon.439within an MT framework.2 Learning when to transliterateWe model the decision as a binary classification atthe token level.
A token (within a named-entity)gets translation or transliteration label.
In ?DudleyNorth?
and ?North London?, our classifier is ex-pected to choose transliteration of ?North?
in theformer case, as opposed to translation in the latter.The binary decision needs to use a rich set of localand contextual features.
We use the Support VectorMachines as a robust framework for binary classifi-cation using a set of interdependent features.2 Webuild two classifiers: (a) Classifier Cnews, trainedon a large set of distinct NEs extracted from news-related parallel corpora; and (b) Classifier Cdiverse,trained on a combination of the news related NEsand a smaller set of diverse-topic NEs extractedfrom Wikipedia titles.
We evaluate the two classi-fiers in both news and the diverse domains to ob-serve the effects of noise and domain change.2.1 Preparing the labeled dataOur classifier requires a set of NEs with token-levelgold labels.
We compile such data from two re-sources: We heuristically extract and label parallelNEs from a large word aligned parallel corpus andwe use a lexicon of bilingual NEs collected fromArabic and Wikipedia titles.
Starting with a wordaligned parallel corpus, we use the UIUC NE tag-ger (Ratinov and Roth, 2009) to tag the Englishsentences with four classes of NEs: Person (PER),Location (LOC), Organization (ORG) and Miscella-neous (MISC).
Furthermore, we use the word align-ments to project and collect the span of the asso-ciated Arabic named-entities.
To reduce the noisynature of word alignments, we designed a procedureto clean up the noisy Arabic NE spans by POS ver-ification, and heuristically filtering impossible items(e.g.
verbs).
This results in a bilingual lexicon ofabout 57K named-entity pairs.
The distribution ofNEs categories is reported in Table 1.To train and evaluate the Cdiverse classifier, weexpand our labeled data with Wikipedia NEs us-ing the cross-lingual hyperlinks.
Wikipedia articletitles often correspond to NEs (Kazama and Tori-2We use the LIBSVM package (Chang and Lin, 2011).PER LOC ORG MISCNews/57K 43.0% 10.0% 40.0% 7.0%Wiki/4K 73.0% 19.0% 2.5% 5.5%Table 1: Distribution of the four NE categories used in57K News and 4K Wiki datasets.sawa, 2007) and have been already used in differentworks for NEs recognition (Nothman et al 2013)and disambiguation (Cucerzan, 2007).
We improvethe Arabic-English Wikipedia title lexicon of Mo-hit et al(2012) and build a Wikipedia exclusivelexicon with 4K bilingual entities.
In order to testthe domain effects, our lexicon includes only NEswhich are not present in the parallel corpus.
Thestatistics given in Table 1 demonstrate different na-ture of the labeled datasets.
The two datasets werelabeled semi-automatically using the transliterationsimilarity measure (Frscore) proposed by Freeman etal.
(2006), a variant of edit distance measuring thesimilarity between an English word and its Arabictransliteration.
In our experiments, English tokenshaving an Frscore > 0.6 are considered as translit-eration, others having Frscore < 0.5 as transla-tion.
These thresholds were determined after tuningwith a held out development set.
For tokens havingFrscore between 0.5 and 0.6, the decision is not ob-vious.
To label these instances (around 5K uniquetokens), we manually transliterate them using Mi-crosoft Maren tool.3 We again compute the Frscorebetween the obtained transliteration, in its Buckwal-ter form and the corresponding English token anduse the same threshold to distinguish between thetwo classes.
Some examples of NEs and their ap-propriate classes are presented in Table 2.Transliteration TranslationMinnesota ?
AK?
?JJ?/mynyswta : 0.77 Agency ?
??A?
?/wkAlp : 0.33Fluke ?
???
?
/flwk : 0.57 Islamic ?
?J?C?B@/AlAslAmyp : 0.55Table 2: Examples of NEs labeled using Freeman Score.2.2 Classification FeaturesWe use a total of 32 features selected from the fol-lowing classes:Token-based features: These consist of severalfeatures based on the token string and indicate3http://afkar.microsoft.com/en/maren440whether the token is capital initial, composed en-tirely of capital letters, ends with a period (suchas Mr.), contains a digit or a Latin number (e.g.Muhammad II) or contains punctuation marks.
Thestring of the token is also added as a feature.
Wealso add the POS tag, which could be a good indica-tor for proper nouns that should mainly be translit-erated.
We also check if the token is a regular nounin the WORDNET (Fellbaum, 1998) which increasesits chance of being translated as opposed to translit-erated.Semantic features: These features mainly indi-cate the NE category obtained using an NE tag-ger.
We also define a number of markers of person(such as Doctor, Engineer, etc.)
and organization(such as Corp.) names.
We used the list of mark-ers available at: http://drupal.org/node/1439292, that we extended manually.Contextual features: These features are relatedto the token?s local context within the NE.
Theseinclude information about the current token?s sur-rounding tokens, its relative position in the NE (be-ginning, middle or end).
Another feature representsthe length of the NE in number of tokens.2.3 ExperimentsWe train two classifiers and tune their parameters us-ing a held out development set of 500 NEs drawnrandomly from the news parallel corpus.
We use 55kNEs from the same corpus to train the Cnews clas-sifier.
Furthermore, we train the Cdiverse classifiercumulatively with the 55K news NEs and another4600 NEs from Wikipedia titles.The classifiers are evaluated on three differentdatasets: TestNews which consists of 2K of NEsselected randomly from the news corpus, TestWikiconsisting of 1K NEs extracted from the Wikipediaand TestCombination, an aggregation of the two pre-vious sets.
We manually reviewed the labels of thesetest sets and fixed any incorrect labels.
Table 3 com-pares the accuracy of the two classifiers under dif-ferent training and test data settings.
Starting witha majority class baseline, our classifiers achieve apromising performance in most settings.
The major-ity class for both classifiers is the translation whichperforms as a baseline approach with an accuracyequal to the distribution of the two classes.
We alsoTestNews TestWiki TestCombinationBaseline 56.70 57.09 56.89Cnews 90.40 84.10 88.64Cdiverse 90.42 86.00 89.18Table 3: Accuracy results for the two classifiers and thebaseline on the three test datasetsobserve that the addition of a small diverse trainingset in Cdiverse provides a relatively large improve-ment (about 2%) when tested on Wikipedia.
Fi-nally, Figure 2 illustrates the contribution of differ-ent classes of features on our diverse classifier (eval-uated on TestWiki).
We observe a fairly linear rela-tionship between the size of the training data and theaccuracy.
Furthermore, we observe that the featuresdescribing the category of the NE are more impor-tant than the token?s local context.
For example, inthe case of ?Dudley North?
and ?North London?, themost effective feature for the decision is the categoryof the named entities.20,000 30,000 40,000 50,000 60,000768186 All \Token \Context \Semantic# of examples in the train setAccu racyFigure 2: Learning curves obtained on Wiki dataset byremoving features individually.3 Extrinsic MT evaluationWe evaluate the effects of the classifier on an En-glish to Arabic statistical MT system.
Our first eval-uation focuses on the utility of our classifier in pre-venting erroneous translation of NEs which need tobe transliterated.
In the following experiments weuse Cnews classifier.
In order to experiment with adiverse set of NEs, we conducted a study on a smallcorpus (98,197 terms) of Wikipedia articles from a441diverse set of topics.
We use 10 Wikipedia articlesdescribing: Anarchism, Artemis, Buddhism, Isfa-han, Shawn Michaels, Turkey, etc.
We first use ourclassifier to locate the subset of NEs which shouldbe transliterated.
An annotator validates the deci-sion and examines the phrase table on the defaultMT decision on those NEs.
We observe that out of1031 NE tokens, 624 tokens (60.5%) which wouldhave been translated incorrectly, are directed to thetransliteration module.Finally, we deploy the transliteration classifier asa pre-translation component to the MT system.4 OurMT test set is the MEDAR corpus (Maegaard etal., 2010).
The MEDAR corpus consists of about10,000 words English texts on news related to theclimate change with four Arabic reference transla-tions.
Due to the lack of non-news English-Arabiccorpus, we have to limit this experiment only tothe news domain.
However, we expect that manyof the NEs may already exist in the training cor-pus and the effects of the classifier is more limitedthan using a diverse domain like Wikipedia.
We au-tomatically locate the NEs in the source languagesentences and use the classifier to find those whichshould be transliterated.
For such terms, we offerthe transliterated form as an option to the decoderaiming to improve the decoding process.
For thata human annotator selected the transliterations fromthe suggested list that is provided by the automatictransliterator (Maren) without any knowledge of thereference transliterations.Table 4 shows the impact of adding the classifierto the SMT pipeline with a modest improvement.Moreover, a bilingual annotator examined the au-tomatically tagged NEs in the MT test set and la-beled them with the translation vs. transliteration4The baseline MT system is the MOSES phrase-based de-coder (Koehn et al 2007) trained on a standard English-Arabicparallel corpus.
The 18 million parallel corpus consists ofthe non-UN parts of the NIST corpus distributed by the Lin-guistic Data Consortium.
We perform the standard prepro-cessing and tokenization on the English side.
We also useMADA+TOKAN (Habash et al 2009) to preprocess and tok-enize the Arabic side of the corpus.
We use the standard settingof GIZA++ and the grow-diagonal-final heuristic of MOSESto get the word alignments.
We use a set of 500 sentencesto tune the decoder parameters using the MERT (Och, 2003).We use El Kholy and Habash (2010) detokenization frameworkfor the Arabic decoding.
We evaluate the MT system with theBLEU metric (Papineni et al 2002).MT Baseline MT Baseline + ClassifierBLEU 16.63 16.91Table 4: Results of the extrinsic usage of the classifier inSMTdecisions.
Having such gold standard decisions, weevaluated the classifier against the MT test set.
Theclassifier?s accuracy was 89% which is as strong asthe earlier intrinsic evaluation.
The false positivesare 5% which represents around 12.6% of the totalerrors.The following example shows how our classifierprevents the MT to choose a wrong decoding forthe NE Python (being transliterated rather thantranslated).
Moreover, the MT system transliteratesthe term Monty that is unknown to the underlyingsystem.
Such entities tend to be unseen in thestandard news corpora and consequently unknown(UNK) to the MT systems.
Using our classi-fier in such conditions is expected to reduce thedomain gap and improve the translation quality.English Input: The British comedy troupe Monty Python.Baseline MT: .
???
@ UNK ?JK A?Q.
?
@?KYJ????@?Q???
@Alfrqp Alkwmydyp AlbryTAnyp UNK AfEYMT+Classifier: .
??JKAK.
??
K?
??JK A?Q.
?
@?KYJ????@?Q???
@Alfrqp Alkwmydyp AlbryTAnyp mwntybAyvwn.4 Related workA number of efforts have been made to undertake the NEtranslation problem for different language pairs.
Amongthem some use sequence of phonetic-based probabilisticmodels to convert names written in Arabic into the En-glish script (Glover-Stalls and Knight, 1998) for translit-eration of names and technical terms that occurs in Ara-bic texts and originate in English.
Others rely on spelling-based model that directly maps an English letter sequenceinto an Arabic one (Al-Onaizan and Knight, 2002a).
In arelated work, Al-Onaizan and Knight (2002b) describe acombination of a phonetic-based model and a spelling-based one to build a transliteration model to generateArabic to English name translations.
In the same direc-tion, Hassan et al(2007) extracted NE translation pairsfrom both comparable and parallel corpora and evaluatetheir quality in a NE translation system.
More recently,Ling et al(2011) propose a Web-based method that trans-lates Chinese NEs into English.
Our work is similar inits general objectives and framework to the work pre-442sented by Hermjakob et al(2008), which describes anapproach for identifying NEs that should be transliter-ated from Arabic into English during translation.
Theirmethod seeks to find a corresponding English word foreach Arabic word in a parallel corpus, and tag the Ara-bic words as either NEs or non-NEs based on a match-ing algorithm.
In contrast, we tackle this problem in thereverse direction (translating/transliterating English NEsinto Arabic).
We also present a novel binary classifier foridentifying NEs that should be translated and those thatshould be transliterated.5 Conclusion and future workWe reported our recent progress on building a classi-fier which decides if an MT system should translate ortransliterate a given named entity.
The classifier showsa promising performance in both intrinsic and extrinsicevaluations.
We believe that our framework can be ex-panded to new languages if the required data resourcesand tools (mainly parallel corpus, Named Entity taggerand transliteration engine) are available.
We plan to ex-pand the features and apply the classifier to new lan-guages and conduct MT experiments in domains otherthan news.6 AcknowledgementsWe thank Nizar Habash and colleagues for the MADA,Arabic detokenization and the transliteration similaritysoftware and also their valuable suggestions.
We thankanonymous reviewers for their valuable comments andsuggestions.
This publication was made possible bygrants YSREP-1-018-1-004 and NPRP-09-1140-1-177from the Qatar National Research Fund (a member ofthe Qatar Foundation).
The statements made herein aresolely the responsibility of the authors.ReferencesYaser Al-Onaizan and Kevin Knight.
2002a.
Named-Entity translation.
In Proceedings of HLT, San Fran-cisco, USA.Yaser Al-Onaizan and Kevin Knight.
2002b.
TranslatingNamed Entities Using Monolingual and Bilingual Re-sources.
In Proceedings of ACL, Philadelphia, USA.Chih-Chung Chang and Chih-Jen Lin.
2011.
LIB-SVM: A Library for Support Vector Machines.
ACMTransactions on Intelligent Systems and Technology,2:27:1?27:27.
Software available at http://www.csie.ntu.edu.tw/?cjlin/libsvm.Silviu Cucerzan.
2007.
Large-Scale Named-Entity Dis-ambiguation Based on Wikipedia Data.
In Proceed-ings of EMNLP-CoNLL, Prague, Czech Republic.Ahmed El Kholy and Nizar Habash.
2010.
Techniquesfor Arabic Morphological Detokenization and Ortho-graphic Denormalization.
In Proceedings of LREC,Valletta, Malta.Christiane Fellbaum.
1998.
WordNet: An ElectronicLexical Database.
The MIT Press.Andrew Freeman, Sherri Condon, and Christopher Ack-erman.
2006.
Cross Linguistic Name Matching inEnglish and Arabic.
In Proceedings of NAACL, NewYork City, USA.Bonnie Glover-Stalls and Kevin Knight.
1998.
Trans-lating Named and Technical Terms in Arabic Text.
InProceeding of the COLING/ACL Workshop on Compu-tational Approaches to Semitic Languages, Montreal,Canada.Nizar Habash, Owen Rambow, and Ryan Roth.
2009.Mada+Tokan: A Toolkit for Arabic Tokenization, Dia-critization, Morphological Disambiguation, POS Tag-ging, Stemming and Lemmatization.
In Proceed-ings of the Second International Conference on Ara-bic Language Resources and Tools (MEDAR), Cairo,Egypt.Ahmed Hassan, Haytham Fahmy, and Hany Hassan.2007.
Improving Named Entity Translation by Ex-ploiting Comparable and Parallel Corpora.
In Pro-ceedings of RANLP, Borovets, Bulgaria.Ulf Hermjakob, Kevin Knight, and Hal Daume?
III.
2008.Name Translation in Statistical Machine Translation- Learning When to Transliterate.
In Proceedings ofACL-HLT, Columbus, Ohio.Jun?ichi Kazama and Kentaro Torisawa.
2007.
Ex-ploiting Wikipedia as External Knowledge for Named-Entity Recognition.
In Proceedings of EMNLP-CoNLL, Prague, Czech Republic.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran, RichardZens, Chris Dyer, Ondrej Bojar, Alexandra Con-stantin, and Evan Herbst.
2007.
Moses: Open SourceToolkit for Statistical Machine Translation.
In Pro-ceedings of ACL: Demo session, Prague, Czech Re-public.Wang Ling, Pavel Calado, Bruno Martins, Isabel Tran-coso, and Alan Black.
2011.
Named-Entity Transla-tion using Anchor Texts.
In Proceedings of IWSLT,San Francisco, USA.Bente Maegaard, Mohamed Attia, Khalid Choukri,Olivier Hamon, Steven Krauwer, and Mustafa Yaseen.2010.
Cooperation for Arabic Language Resourcesand Tools?The MEDAR Project.
In Proceedings ofLREC, Valetta, Malta.Behrang Mohit, Nathan Schneider, Rishav Bhowmick,Kemal Oflazer, and Noah A. Smith.
2012.
Recall-443Oriented Learning of Named Entities in ArabicWikipedia.
In Proceedings of EACL, Avignon, France.Joel Nothman, Nicky Ringland, Will Radford, Tara Mur-phy, and James R. Curran.
2013.
Learning Multilin-gual Named Entity Recognition from Wikipedia.
Ar-tificial Intelligence, 194(0):151 ?
175.Franz Josef Och.
2003.
Minimum Error Rate Trainingin Statistical Machine Translation.
In Proceedings ofACL, Sapporo, Japan.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
BLEU: a Method for AutomaticEvaluation of Machine Translation.
In Proceedings ofACL, Philadelphia, USA.Lev Ratinov and Dan Roth.
2009.
Design Challengesand Misconceptions in Named Entity Recognition.
InProceedings of CONLL, Boulder, USA.444
