An Expert Lexicon Approach to Identifying English Phrasal VerbsWei Li, Xiuhong Zhang, Cheng Niu, Yuankai Jiang, Rohini SrihariCymfony Inc.600 Essjay RoadWilliamsville, NY 14221, USA{wei, xzhang, cniu, yjiang, rohini}@Cymfony.comAbstractPhrasal Verbs are an important featureof the English language.
Properlyidentifying them provides the basis foran English parser to decode the relatedstructures.
Phrasal verbs have been achallenge to Natural LanguageProcessing (NLP) because they sit atthe borderline between lexicon andsyntax.
Traditional NLP frameworksthat separate the lexicon module fromthe parser make it difficult to handlethis problem properly.
This paperpresents a finite state approach thatintegrates a phrasal verb expert lexiconbetween shallow parsing and deepparsing to handle morpho-syntacticinteraction.
With precision/recallcombined performance benchmarkedconsistently at 95.8%-97.5%, thePhrasal Verb identification problemhas basically been solved with thepresented method.1 IntroductionAny natural language processing (NLP) systemneeds to address the issue of handling  multiwordexpressions, including Phrasal Verbs (PV) [Saget al 2002; Breidt et al 1996].
This paperpresents a proven approach to identifyingEnglish PVs based on pattern matching using aformalism called Expert Lexicon.Phrasal Verbs are an important feature of theEnglish language since they form about one thirdof the English verb vocabulary.
1  Properly1 For the verb vocabulary of our system based onmachine-readable dictionaries and two Phrasal Verbdictionaries, phrasal verb entries constitute 33.8% ofthe entries.recognizing PVs is an important condition forEnglish parsing.
Like single-word verbs, eachPV has its own lexical features includingsubcategorization features that determine itsstructural patterns [Fraser 1976; Bolinger 1971;Pelli 1976; Shaked 1994], e.g., look for hassyntactic subcategorization and semantic featuressimilar to those of search; carry?on shareslexical features with continue.
Such lexicalfeatures can be represented in the PV lexicon inthe same way as those for single-word verbs, buta parser can only use them when the PV isidentified.Problems like PVs are regarded as ?a pain inthe neck for NLP?
[Sag et al 2002].
A propersolution to this problem requires tighterinteraction between syntax and lexicon thantraditionally available [Breidt et al 1994].Simple lexical lookup leads to severedegradation in both precision and recall, as ourbenchmarks show (Section 4).
The recallproblem is mainly due to separable PVs such asturn?off which allow for syntactic units to beinserted inside the PV compound, e.g., turn it off,turn the radio off.
The precision problem iscaused by the ambiguous function of the particle.For example, a simple lexical lookup will mistaglooked for as a phrasal verb in sentences such asHe looked for quite a while but saw nothing.In short, the traditional NLP framework thatseparates the lexicon module from a parsermakes it difficult to handle this problem properly.This paper presents an expert lexicon approachthat integrates the lexical module with contextualchecking based on shallow parsing results.Extensive blind benchmarking shows that thisapproach is very effective for identifying phrasalverbs, resulting in the precision/recall combinedF-score of about 96%.The remaining text is structured as follows.Section 2 presents the problem and defines thetask.
Section 3 presents the Expert Lexiconformalism and illustrates the use of thisformalism in solving this problem.
Section 4shows the benchmarking and analysis, followedby conclusions in Section 5.2 Phrasal Verb ChallengesThis section defines the problems we intend tosolve, with a checklist of tasks to accomplish.2.1 Task DefinitionFirst, we define the task as the identification ofPVs in support of deep parsing, not as the parsingof the structures headed by a PV.
These two areseparated as two tasks not only because ofmodularity considerations, but more importantlybased on a natural labor division between NLPmodules.Essential to the second argument is that thesetwo tasks are of a different linguistic nature: theidentification task belongs to (compounding)morphology (although it involves a syntacticinterface) while the parsing task belongs tosyntax.
The naturalness of this division isreflected in the fact that there is no need for aspecialized, PV-oriented parser.
The same parser,mainly driven by lexical subcategorizationfeatures, can handle the structural problems forboth phrasal verbs and other verbs.
Thefollowing active and passive structures involvingthe PVs look after (corresponding to watch) andcarry?on (corresponding to continue) aredecoded by our deep parser after PVidentification: she is being carefully ?lookedafter?
(watched); we should ?carry on?
(continue)the business for a while.There has been no unified definition of PVsamong linguists.
Semantic compositionality isoften used as a criterion to distinguish a PV froma syntactic combination between a verb and itsassociated adverb or prepositional phrase[Shaked 1994].
In reality, however, PVs reside ina continuum from opaque to transparent in termsof semantic compositionality [Bolinger 1971].There exist fuzzy cases such as take somethingaway2 that may be included either as a PV or as aregular syntactic sequence.
There is agreement2  Single-word verbs like ?take?
are oftenover-burdened with dozens of senses/uses.
Treatingmarginal cases like ?take?away?
as independentphrasal verb entries has practical benefits in relievingthe burden and the associated noise involving ?take?.on the vocabulary scope for the majority of PVs,as reflected in the overlapping of PV entries frommajor English dictionaries.English PVs are generally classified into threemajor types.
Type I usually takes the form of anintransitive verb plus a particle word thatoriginates from a preposition.
Hence the resultingcompound verb has become transitive, e.g., lookfor, look after, look forward to, look into, etc.Type II typically takes the form of a transitiveverb plus a particle from the set {on, off, up,down}, e.g., turn?on, take?off, wake?up,let?down.
Marginal cases of particles may alsoinclude {out, in, away} such as take?away,kick ?in, pull?out.3Type III takes the form of an intransitive verbplus an adverb particle, e.g., get by, blow up, burnup, get off, etc.
Note that Type II and Type IIIPVs have considerable overlapping invocabulary, e.g., The bomb blew up vs. Theclown blew up the balloon.
The overlappingphenomenon can be handled by assigning both atransitive feature and an intransitive feature to theidentified PVs in the same way that we treat theoverlapping of single-word verbs.The first issue in handling PVs is inflection.
Asystem for identifying PVs should match theinflected forms, both regular and irregular, of theleading verb.The second is the representation of the lexicalidentity of recognized PVs.
This is to establish aPV (a compound word) as a syntactic atomic unitwith all its lexical properties determined by thelexicon [Di Sciullo and Williams 1987].
Theoutput of the identification module based on a PVlexicon should support syntactic analysis andfurther processing.
This translates into twosub-tasks: (i) lexical feature assignment, and (ii)canonical form representation.
After a PV isidentified, its lexical features encoded in the PVlexicon should be assigned for a parser to use.The representation of a canonical form for anidentified PV is necessary to allow for individualrules to be associated with identified PVs infurther processing and to facilitate verb retrievalin applications.
For example, if we use turn_offas the canonical form for the PV turn?off,identified in both he turned off the radio and he3 These three are arguably in the gray area.
Since theydo not fundamentally affect the meaning of theleading verb, we do not have to treat them as phrasalverbs.
In principle, they can also be treated as  adverbcomplements of verbs.turned the radio off, a search for turn_off willmatch all and only the mentions of this PV.The fact that PVs are separable hurts recall.
Inparticular, for Type II, a Noun Phrase (NP) objectcan be inserted inside the compound verb.
NPinsertion is an intriguing linguistic phenomenoninvolving the morpho-syntactic interface: amorphological compounding process needs tointeract with the formation of a syntactic unit.Type I PVs also have the separability problem,albeit to a lesser degree.
The possible insertedunits are adverbs in this case, e.g., lookeverywhere for, look carefully after.What hurts precision is spurious matches ofPV negative instances.
In a sentence with thestructure V+[P+NP], [V+P] may be mistagged asa PV, as seen in the following pairs of examplesfor Type I and Type II:(1a) She [looked for] you yesterday.
(1b) She looked [for quite a while] (but sawnothing).
(2a) She [put on] the coat.
(2b) She put [on the table] the book sheborrowed yesterday.To summarize, the following is a checklist ofproblems that a PV identification system shouldhandle: (i) verb inflection, (ii) lexical identityrepresentation, (iii) separability, and (iv)negative instances.2.2 Related WorkTwo lines of research are reported in addressingthe PV problem: (i) the use of a high-levelgrammar formalism that integrates theidentification with parsing, and (ii) the use of afinite state device in identifying PVs as a lexicalsupport for the subsequent parser.
Bothapproaches have their own ways of handling themorpho-syntactic interface.
[Sag et al 2002] and [Villavicencio et al2002] present their project LinGO-ERG thathandles PV identification and parsing together.LingGO-ERG is based on Head-driven PhraseStructure Grammar (HPSG), a unification-basedgrammar formalism.
HPSG provides amono-stratal lexicalist framework that facilitateshandling intricate morpho-syntactic interaction.PV-related morphological and syntacticstructures are accounted for by means of a lexicalselection mechanism where the verb morphemesubcategorizes for its syntactic object in additionto its particle morpheme.The LingGO-ERG lexicalist approach isbelieved to be effective.
However, their coverageand testing of the PVs seem preliminary.
TheLinGO-ERG lexicon contains 295 PV entries,with no report on benchmarks.In terms of the restricted flexibility andmodifiability of a system, the use of high-levelgrammar formalisms such as HPSG to integrateidentification in deep parsing cannot becompared with the alternative finite stateapproach [Breidt et al 1994].
[Breidt et al1994]?s approach is similar to ourwork.
Multiword expressions including idioms,collocations, and compounds as well as PVs areaccounted for by using local grammar rulesformulated as regular expressions.
There is nodetailed description for English PV treatmentsince their work focuses on multilingual,multi-word expressions in general.
The authorsbelieve that the local grammar implementation ofmultiword expressions can work with generalsyntax either implemented in a high-levelgrammar formalism or implemented as a localgrammar for the required morpho-syntacticinteraction, but this interaction is notimplemented into an integrated system and henceit is impossible to properly measure performancebenchmarks.There is no report on implemented solutionscovering the entire English PVs that are fullyintegrated into an NLP system and are well testedon sizable real life corpora, as is presented in thispaper.3 Expert Lexicon ApproachThis section illustrates the system architectureand presents the underlying Expert Lexicon (EL)formalism, followed by the description of theimplementation details.3.1 System ArchitectureFigure 1 shows the system architecture thatcontains the PV Identification Module based onthe PV Expert Lexicon.This is a pipeline system mainly based onpattern matching implemented in local grammarsand/or expert lexicons [Srihari et al2003].
44 POS and NE tagging are hybrid systems involvingboth hand-crafted rules and statistical learning.English parsing is divided into two tasks: shallowparsing and deep parsing.
The shallow parserconstructs Verb Groups (VGs) and basic NounPhrases (NPs), also called BaseNPs [Church1988].
The deep parser utilizes syntacticsubcategorization features and semantic featuresof a head (e.g., VG) to decode both syntactic andlogical dependency relationships such asVerb-Subject, Verb-Object, Head-Modifier, etc.Part-of-Speech(POS) TaggingGeneralLexicon Lexical lookupNamed Entity(NE) TaggigShallow ParsingPV IdentificationDeep parsingGeneralLexiconPV ExpertLexiconFigure 1.
System ArchitectureThe general lexicon lookup componentinvolves stemming that transforms regular orirregular inflected verbs into the base forms tofacilitate the later phrasal verb matching.
Thiscomponent also performs indexing of the wordoccurrences in the processed document forsubsequent expert lexicons.The PV Identification Module is placedbetween the Shallow Parser and the Deep Parser.It requires shallow parsing support for therequired syntactic interaction and the PV outputprovides lexical support for deep parsing.Results after shallow parsing form a properbasis for PV identification.
First, the inserted NPsand adverbial time NEs are already constructedby the shallow parser and NE tagger.
This makesit easy to write pattern matching rules foridentifying separable PVs.Second, the constructed basic units NE, NPand VG provide conditions forconstraint-checking in PV identification.
Forexample, to prevent spurious matches insentences like she put the coat on the table, it isnecessary to check that the post-particle unitshould NOT be an NP.
The VG chunking alsodecodes the voice, tense and aspect features thatcan be used as additional constraints for PVidentification.
A sample macro ruleactive_V_Pin that checks the ?NOT passive?constraint and the ?NOT time?, ?NOT location?constraints is shown in 3.3.3.2 Expert Lexicon FormalismThe Expert Lexicon used in our system is anindex-based formalism that can associate patternmatching rules with lexical entries.
It isorganized like a lexicon, but has the power of alexicalized local grammar.All Expert Lexicon entries are indexed,similar to the case for the finite state tool inINTEX [Silberztein 2000].
The pattern matchingtime is therefore reduced dramatically comparedto a sequential finite state device [Srihari et al2003].5The expert lexicon formalism is designed toenhance the lexicalization of our system, inaccordance with the general trend of lexicalistapproaches to NLP.
It is especially beneficial inhandling problems like PVs and many individualor idiosyncratic linguistic phenomena that cannot be covered by non-lexical approaches.Unlike the extreme lexicalized word expertsystem in [Small and Rieger 1982] and similar tothe IDAREX local grammar formalism [Breidt etal.1994], our EL formalism supports aparameterized macro mechanism that can beused to capture the general rules shared by a setof individual entries.
This is a particular usefulmechanism that will save time for computationallexicographers in developing expert lexicons,especially for phrasal verbs, as shall be shown inSection 3.3 below.The Expert Lexicon tool provides a flexibleinterface for coordinating lexicons and syntax:any number of expert lexicons can be placed atany levels, hand-in-hand with othernon-lexicalized modules in the pipelinearchitecture of our system.5 Some other unique features of our EL formalisminclude: (i) providing the capability of proximitychecking as rule constraints in addition to patternmatching using regular expressions so that the rulewriter or lexicographer can exploit the combinedadvantages of both, and (ii) the propagationfunctionality of semantic tagging results, toaccommodate principles like one sense per discourse.3.3 Phrasal Verb Expert LexiconTo cover the three major types of PVs, we use themacro mechanism to capture the shared patterns.For example, the NP insertion for Type II PV ishandled through a macro called V_NP_P,formulated in pseudo code as follows.V_NP_P($V,$P,$V_P,$F1, $F2,?)
:=Pattern:$VNP(?right?|?back?|?straight?
)$PNOT NPAction:$V: %assign_feature($F1, $F2,?
)%assign_canonical_form($V_P)$P: %deactivateThis macro represents cases like Take the coatoff, please; put it back on, it?s raining now.
Itconsists of two parts: ?Pattern?
in regularexpression form (with parentheses for optionality,a bar for logical OR, a quoted string for checkinga word or head word) and ?Action?
(signified bythe prefix %).
The parameters used in the macro(marked by the prefix $) include the leading verb$V, particle $P, the canonical form $V_P, andfeatures $Fn.
After the defined pattern is matched,a Type II separable verb is identified.
The Actionpart ensures that the lexical identity berepresented properly, i.e.
the assignment of thelexical features and the canonical form.
Thedeactivate action flags the particle as being partof the phrasal verb.In addition, to prevent a spurious case in (3b),the macro V_NP_P checks the contextualconstraints that no NP (i.e.
NOT NP) shouldfollow a PV particle.
In our shallow parsing, NPchunking does not include identified time NEs,so it will not block the PV identification in (3c).
(3a) She [put the coat on].
(3b) She put the coat [on the table].
(3c) She [put the coat on] yesterday.All three types of PVs when used without NPinsertion are handled by the same set of macros,due to the formal patterns they share.
We use aset of macros instead of one single macro,depending on the type of particle and the voice ofthe verb, e.g., look for calls the macro[active_V_Pfor | passive_V_Pfor], fly in calls themacro [active_V_Pin | passive_V_Pin], etc.The distinction between active rules andpassive rules lies in the need for differentconstraints.
For example, a passive rule needs tocheck the post-particle constraint [NOT NP] toblock the spurious case in (4b).
(4a) He [turned on] the radio.
(4b)  The world [had been turned] [on itshead] again.As for particles, they also require differentconstraints in order to block spurious matches.For example, active_V_Pin (formulated below)requires the constraints ?NOT location NOTtime?
after the particle while active_V_Pfor onlyneeds to check ?NOT time?, shown in (5) and (6).
(5a) Howard [had flown in] from Atlanta.
(5b) The rocket [would fly] [in 1999].
(6a) She was [looking for] California on themap.
(6b) She looked [for quite a while].active_V_Pin($V, in, $V_P,$F1, $F2,?)
:=Pattern:$V NOT passive(Adv|time)$PNOT location NOT timeAction:$V: %assign_feature($F1, $F2, ?
)%assign_canonical_form($V_P)$P: %deactivateThe coding of the few PV macros requiresskilled computational grammarians and arepresentative development corpus for ruledebugging.
In our case, it was approximately 15person-days of skilled labor including dataanalysis, macro formulation and five iterations ofdebugging against the development corpus.
Butafter the PV macros are defined, lexicographerscan quickly develop the PV entries: it only costone person-day to enter the entire PV vocabularyusing the EL formalism and the implementedmacros.
We used the Cambridge InternationalDictionary of Phrasal Verbs and Collins CobuildDictionary of Phrasal Verbs as the majorreference for developing our PV ExpertLexicon.
6  This expert lexicon contains 2,590entries.
The EL-rules are ordered with specificrules placed before more general rules.
A sampleof the developed PV Expert Lexicon is shownbelow (the prefix @ denotes a macro call):abide:  @V_P_by(abide, by, abide_by, V6A,APPROVING_AGREEING)accede: @V_P_to(accede, to, accede_to, V6A,APPROVING_AGREEING)add:  @V_P(add, up, add_up, V2A,MATH_REASONING);@V_NP_P(add, up, add_up, V6A,MATH_REASONING)???
?In the above entries, V6A and V2A aresubcategorization features for transitive andintransitive verb respectively, whileAPPROVING_AGREEING andMATH_REASONING are semantic features.These features provide the lexical basis for thesubsequent parser.The PV identification method as describedabove resolves all the problems in the checklist.The following sample output shows theidentification result:NP[That]VG[could slow: slow_down/V6A/MOVING]NP[him]down/deactivated .4 BenchmarkingBlind benchmarking was done by twonon-developer testers manually checking theresults.
In cases of disagreement, a third testerwas involved in examining the case to helpresolve it.
We ran benchmarking on both theformal style and informal style of English text.4.1 Corpus PreparationOur development corpus (around 500 KB)consists of the MUC-7 (Message Understanding6 Some entries that are listed in these dictionaries donot seem to belong to phrasal verb categories, e.g.,relieve?of (as used in relieve somebody of something),remind?of (as used in remind somebody ofsomething), etc.
It is generally agreed that such casesbelong to syntactic patterns in the form ofV+NP+P+NP that can be captured bysubcategorization.
We have excluded these cases.Conference-7) dryrun corpus and an additionalcollection of news domain articles from TREC(Text Retrieval Conference) data.
The PV expertlexicon rules, mainly the macros, were developedand debugged using the development corpus.The first testing corpus (called English-zonecorpus) was downloaded from a website that isdesigned to teach PV usage in Colloquial English(http://www.english-zone.com/phrasals/w-phrasals.html).
It consists of 357 lines of samplesentences containing 347 PVs.
This addresses thesparseness problem for the less frequently usedPVs that rarely get benchmarked in running texttesting.
This is a concentrated corpus involvingvarieties of PVs from text sources of an informalstyle, as shown below.7"Would you care for some dessert?
We haveice cream, cookies, or cake.
"Why are you wrapped up in that blanket?After John's wife died, he had to get throughhis sadness.After my sister cut her hair by herself, we hadto take her to a hairdresser to even herhair out!After the fire, the family had to get by withouta house.We have prepared two collections from therunning text data to test written English of a moreformal style in the general news domain:  (i) theMUC-7 formal run corpus (342 KB) consistingof 99 news articles, and (ii) a collection of 23,557news articles (105MB) from the TREC data.4.2 Performance TestingThere is no available system known to the NLPcommunity that claims a capability for PVtreatment and could thus be used for a reasonableperformance comparison.
Hence, we havedevised a bottom-line system and a baselinesystem for comparison with our EL-drivensystem.
The bottom-line system is defined as asimple lexical lookup procedure enhanced withthe ability to match inflected verb forms but withno capability of checking contextual constraints.There is no discussion in the literature on what7 Proper treatment of PVs is most important in parsingtext sources involving Colloquial English, e.g.,interviews, speech transcripts, chat room archives.There is an increasing demand for NLP applications inhandling this type of data.constitutes a reasonable baseline system for PV.We believe that a baseline system should havethe additional, easy-to-implement ability to jumpover inserted object case pronouns (e.g., turn iton) and adverbs (e.g., look everywhere for) in PVidentification.Both the MUC-7 formal run corpus and theEnglish-zone corpus were fed into thebottom-line  and the baseline systems as well asour EL-driven system described in Section 3.3.The benchmarking results are shown in Table 1and Table 2.
The F-score is a combined measureof precision and recall, reflecting the overallperformance of a system.Table 1.
Running Text Benchmarking 1Bottom-line Baseline ELCorrect 303 334 338Missing 58 27 23Spurious 33 34 7Precision 90.2% 88.4% 98.0%Recall 83.9% 92.5% 93.6%F-score 86.9% 91.6% 95.8%Table 2.
Sampling Corpus BenchmarkingBottom-line Baseline ELCorrect 215 244 324Missing 132 103 23Spurious 0 0 0Precision 100% 100% 100%Recall 62.0% 70.3% 93.4%F-score 76.5% 82.6% 96.6%Compared with the bottom-line performanceand the baseline performance, the F-score for thepresented method has surged 9-20 percentagepoints and 4-14 percentage points, respectively.The high precision (100%) in Table 2 is due tothe fact that, unlike running text, the samplingcorpus contains only positive instances of PV.This weakness, often associated with samplingcorpora, is overcome by benchmarking runningtext corpora (Table 1 and Table 3).To compensate for the limited size of theMUC formal run corpus, we used the testingcorpus from the TREC data.
For such a largetesting corpus (23,557 articles, 105MB), it isimpractical for testers to read every article tocount mentions of all PVs in benchmarking.Therefore, we selected three representative PVslook for, turn?on and blow?up and used thehead verbs (look, turn, blow), including theirinflected forms, to retrieve all sentences thatcontain those verbs.
We then ran the retrievedsentences through our system for benchmarking(Table 3).All three of the blind tests show fairlyconsistent benchmarking results (F-score95.8%-97.5%), indicating that these benchmarksreflect the true capability of the presented system,which targets the entire PV vocabulary instead ofa selected subset.
Although there is still someroom for further enhancement (to be discussedshortly), the PV identification problem isbasically solved.Table 3.
Running Text Benchmarking 2?look for?
?turn?on?
?blow?up?Correct 1138 128 650Missing 76 0 33Spurious 5 9 0Precision 99.6% 93.4% 100.0%Recall 93.7% 100.0% 95.2%F-score 96.6% 97.5% 97.5%4.3 Error AnalysisThere are two major factors that cause errors: (i)the impact of errors from the preceding modules(POS and Shallow Parsing), and (ii) the mistakescaused by the PV Expert Lexicon itself.The POS errors caused more problems thanthe NP grouping errors because the inserted NPtends to be very short, posing little challenge tothe BaseNP shallow parsing.
Some verbsmis-tagged as nouns by POS were missed in PVidentification.There are two problems that require thefine-tuning of the PV Identification Module.
First,the macros need further adjustment in theirconstraints.
Some constraints seem to be toostrong or too weak.
For example, in the Type Imacro, although we expected the possibleinsertion of an adverb, however, the constraint onallowing for only one optional adverb and notallowing for a time adverbial is still too strong.As a result, the system failed to identifylistening?to and meet?with in the followingcases: ?was not listening very closely onThursday to American concerns about humantights?
and ... meet on Friday with his Chinese...The second type of problems cannot be solvedat the macro level.
These are individual problemsthat should be handled by writing specific rulesfor the related PV.
An example is the possiblespurious match of the PV have?out in thesentence ...still have our budget analysts outworking the numbers.
Since have is a verb withnumerous usages, we should impose moreindividual constraints for NP insertion to preventspurious matches, rather than calling a commonmacro shared by all Type II verbs.4.4 Efficiency TestingTo test the efficiency of the index-based PVExpert Lexicon in comparison with a sequentialFinite State Automaton (FSA) in the PVidentification task, we conducted the followingexperiment.The PV Expert Lexicon was compiled as aregular local grammar into a large automaton thatcontains 97,801 states and 237,302 transitions.For a file of 104 KB (the MUC-7 dryrun corpusof 16,878 words), our sequential FSA  runnertakes over 10 seconds for processing on theWindows NT platform with a Pentium PC.
Thisprocessing only requires 0.36 second using theindexed PV Expert Lexicon module.
This isabout 30 times faster.5 ConclusionAn effective and efficient approach to phrasalverb identification is presented.
This approachhandles both separable and inseparable phrasalverbs in English.
An Expert Lexicon formalismis used to develop the entire phrasal verb lexiconand its associated pattern matching rules andmacros.
This formalism allows the phrasal verblexicon to be called between two levels ofparsing for the required morpho-syntacticinteraction in phrasal verb identification.Benchmarking using both the running text corpusand sampling corpus shows that the presentedapproach provides a satisfactory solution to thisproblem.In future research, we plan to extend thesuccessful experiment on phrasal verbs to othertypes of multi-word expressions and idiomsusing the same expert lexicon formalism.AcknowledgmentThis work was partly supported by a grant fromthe Air Force Research Laboratory?s InformationDirectorate (AFRL/IF), Rome, NY, undercontract F30602-03-C-0044.
The authors wish tothank Carrie Pine and Sharon Walter of AFRLfor supporting and reviewing this work.
Thanksalso go to the anonymous reviewers for theirconstructive comments.ReferencesBreidt.
E., F. Segond and G. Valetto.
1994.
LocalGrammars for the Description of Multi-WordLexemes and Their Automatic Recognition inText.
Proceedings of Comlex-2380 - Papersin Computational Lexicography, LinguisticsInstitute, HAS, Budapest, 19-28.Breidt, et al 1996.
Formal description ofMulti-word Lexemes with the Finite Stateformalism: IDAREX.
Proceedings ofCOLING 1996, Copenhagen.Bolinger, D. 1971.
The Phrasal Verb in English.Cambridge, Mass., Harvard University Press.Church, K. 1988.
A stochastic parts program andnoun phrase parser for unrestricted text.Proceedings of ANLP 1988.Di Sciullo, A.M. and E. Williams.
1987.
On TheDefinition of Word.
The MIT Press,Cambridge, Massachusetts.Fraser, B.
1976.
The Verb Particle Combinationin English.
New York: Academic Press.Pelli, M. G. 1976.
Verb Particle Constructions inAmerican English.
Zurich: Francke VerlagBern.Sag, I., T. Baldwin, F. Bond, A. Copestake and D.Flickinger.
2002.
Multiword Expressions: APain in the Neck for NLP.
Proceedings ofCICLING 2002, Mexico City, Mexico, 1-15.Shaked, N. 1994.
The Treatment of PhrasalVerbs in a Natural Language ProcessingSystem, Dissertation, CUNY.Silberztein, M. 2000.
INTEX: An FST Toolbox.Theoretical Computer Science, Volume231(1): 33-46.Small, S. and C. Rieger.
1982.
Parsing andcomprehending with word experts (a theoryand its realisation).
W. Lehnert and M.Ringle, editors, Strategies for NaturalLanguage Processing.
Lawrence ErlbaumAssociates, Hillsdale, NJ.Srihari, R., W. Li, C. Niu and T. Cornell.
2003.InfoXtract: An Information Discovery EngineSupported by New Levels of InformationExtraction.
Proceeding of HLT-NAACLWorkshop on Software Engineering andArchitecture of Language TechnologySystems, Edmonton, Canada.Villavicencio, A. and A. Copestake.
2002.Verb-particle constructions in acomputational grammar of English.Proceedings of the Ninth InternationalConference on Head-Driven Phrase StructureGrammar, Seoul, South Korea.
