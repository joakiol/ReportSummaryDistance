How to obey the 7 commandments for spoken dialogue?Emie l  K rahmer ,  Jan  Landsbergen ,  Xav ier  PouteauIPO,  Center  for Research  on User -System In teract ionP .O .Box  513NL-5600 MB,  E indhoven,  The  Nether lands{krahmer/landsbrn/pout eau}?ipo, tue, nlAbst rac tWe describe the design and implementation fthe dialogue management module in a voiceoperated car-driver information system.
Theliterature on designing 'good' user interfacesinvolving natural anguage dialogue in generaland speech in particular is abundant with use-ful guidelines for actual development.
We havetried to summarize these guidelines in 7 'meta-guidelines', or commandments.
Even thoughstate-of-the-art Speech Recognition modulesperform well, speech recognition errors can-not be precluded.
For'the current application,the fact that the car is an acoustically hostileenvironment is an extra complication.
Thismeans that special attention should be paidto effective methods to compensate for speechrecognition errors.
Moreover, this should bedone in a way which is not disturbing for thedriver.
In this paper, we show how these con-straints influence the design and subsequentimplementation f the Dialogue Manager mod-ule, and how the additional requirements fit inwith the 7 commandments.keywords :  spoken dialogue management, error-prevention, error-recovery, design issues1 In t roduct ionThere are many good reasons why spoken languagemight be a main in- and output device for a user-interface.
One of them is that in certain situ-ations it is difficult for a user to operate a sys-tem in another way, because (s)he is involved ina task with heavy manual requirements.
Con-sider the case of a car-driver: the current genera-tion of driver information Systems (usually involvingHiFi equipment, but also route-guidance omputers,traffic-messaging (RDS/TMC) and mobile telephone(GSM)) is getting more and more complex, and op-erating these devices is becoming a significant askas well.
Since the driver's visual and gestural chan-nels are heavily involved in the main, driving task,it seems worthwhile to study the possibilities of aspoken interface for such driver information systems,and this is the main objective of VODIS, a Europeanproject dedicated to the design and implementationof a vocal interface to an existing driver informationsystem.Even though the state of the art Speech Recog-nition (SR) modules perform well (see e.g., Cole etal.
1996), speech recognition errors cannot be pre-cluded.
For the current application, the fact thatthe car is a notorious acoustically hostile environ-ment is an additional complication.
This means thatspecial attention should be paid to effective meth-ods to compensate for SR errors.
Moreover, thisshould be done in a way which is not disturbingfor the driver.
This is one of the central tasks ofa Dialogue Manager module.
In general, the Dia-logue Manager module can be seen as an intermedi-ate agent between user and application, helping theformer in maintaining a good representation of thelatter.
Relevant literature points out that there isno general theory for the development of a DialogueManager (henceforth DM).
On the other hand, a lotof guidelines for the development of 'good' vocal in-terfaces exist.In this paper, we describe some of the meth-ods used for the DM module in the VODIS pro-ject, with the focus on error-prevention and error-handling.
A recurrent heme in our description ofthe DM module is the relation between the designand the many guidelines found in the literature.
Tofacilitate the discussion, we have tried to summar-ize these guidelines into a limited number of 'meta-guidelines': the 7 commandments for spoken lan-guage dialogues (section 2).
Most of these corn-82mandments can be related to general recommend-ations about user-interfaces (as found in e.g., Shnei-derman 1992:72-73 and Karis & Debroth 1991:578),but here the emphasis is on spoken user-interfaces.The 7 commandments may sound obvious and gen-eral, although hard to obey in real life.
We con-tend that this is a basic property of commandments.Be that as it may, we feel that it is worthwhile topresent hese 7 commandments, if only to give thereader an impression of the kind of things that haveto be kept in mind when designing and implement-ing a DM module.
The 7 commandments are givenin section 2.1 In section 3 we describe the main gen-eric methods used within the DM to compensate forspeech errors in VODIS and in section 4 we brieflydescribe how they are implemented.
Finally, in sec-tion 5 there is some discussion on the applicabilityof the commandments and the generalizability of theDM in VODIS.2 The  7 commandments  fo r  spokenlanguage d ia loguesI.
THY  SYSTEM SHALL MAINTAIN CONSISTENCYA system should assign the same response to thesame input (Lea 1994: 26).
However, one shouldbalance consistency with commandment v (adaptab-ility): be consistent but not rigid (cf.
Grudin 1989),e.g., enable reduced dialogues (Leiser 1993:287).IT.
THOU SHALT BE AWARE OF THE PROFOUNDINFLUENCE OF BOTH CONTENT AND FORM OFPROMPTSThis commandment essentially says that the systemshould be a good dialogue partner.
To achieve this,the system should first of all pay attention to theway prompts are formulated.
They should be asbrief as possible without being compendious; wordyprompts (system: "I heard you say .
.
. "
)  lead toconfusion (Fraser 1994:137,Lea 1994:15).
Consist-ency is also relevant here: use a consistent linguisticstyle (Fraser 1994:137).Second, prompts should fit in with the ongoingdialogue.
Thus, the system should ensure that,where possible, each prompt finishes with an expli-cit question or command; proceed with the discourserather than looking back to verify the past (Fraser1994:137, Lea 1994: 15).1This list of 7 commandments is primarily based onthe guidelines found in Fraser (1994), Lea (1994), andLeiser (1993), the two first mentioned references sum upa lot of  the  re levant  l i te rature .
Lea  comes  to a l ist ofseven ' card ina l  ru les '  that  par t ia l ly  over laps  our  7 com-mandments .
Leiser  is speci f ical ly  concerned  w i th  speechin ter faces  in the  car.Third, different kinds of prompts can be used tomark different contexts.
E.g., different voices can beused as the auditive counterparts of different 'act-ive windows' in a windows-based operating system.However, one should use such distinctions carefullyand ensure that each voice serves an intuitively dif-ferent purpose (Fraser 1994: 137, Lea 1994: 31,Leiser 1993: 287).Fourth, when a speech-recognition-error occurs,re-prompt in such a way that the user receives ex-tra guidance on how to behave in the desired way(Fraser 1994:137).
E.g, repeat he attempt contain-ing an error once, so that the user can recognize theerror, and at the same time error-loops are avoided(Lea 1994:32).III.
WHY SYSTEM SHALL BE EASY TO COMPREHENDPut differently: the system should have a lowthreshold for actualusage.
Use progressive disclos-ure of information.
Structure tasks into small pieces,so that the user does not have to remember too manythings at a given point (Lea 1994:28).
Keep the userinformed about the currently available options (Lea1994: 28, Leiser 1993:287).IV.
THOU SHALT MAKE THY SYSTEM 'GOOF-PROOF ' ,  FOR TO ERR IS HUMAN,  BUT TO FORGIVEDESIGNThis commandment, based on an old adage (cf.
Lea1994: 18, Hix & Hartson 1993), subsumes error-prevention (Iv.a) and error-handling (iv.b).Ad Iv.a: keep the user informed about the currentsituation (Leiser 1993: 287).
One way to achieve thisis by providing a clear response after every spokeninput from the user, so the user knows that the sys-tem received input and can determine which inter-pretation is assigned to the input (Lea 1994: 31).In general: use visual and/or auditory cues to in-dicate the current interaction context, and emphas-ize switches from one application to another (Leiser1993: 287).
Another means to avoid errors is todefine phonetically distinct words or phrases for al-lowed inputs, and make 'erroneous' choices unavail-able (compare the different shading of unavailablemenu options or icons in a windows-based operatingsystem) (Lea 1994:31).
For potentially 'dangerous'or 'expensive' actions (i.e., undoing them is relat-ively costly/time-consuming), include a validationstep.
Such a validation strategy should not be usedfor 'harmless' actions; that would slow down the in-teraction unnecessarily.Ad Iv.b: If an error does occur, let the systemtake the blame (e.g., system: "I didn't understandyour utterance.").
Do not blame the user (thus notsystem: "What you did was illegal!").
Focus on re-83covering the error.
One important element is thepresence of a vocal 'undo' command.
If possible, al-low correction of local errors: avoid the necessity tore-enter the entire command (Lea 1994: 32).V.
THY SYSTEM SHALL BE ADAPTABLEDo not force interaction, rather make the user awareof currently available options on a take-it-or-leave-itbasis (Leiser 1993: 286).
Only interrupt he ongo-ing dialogue in 'urgent' situations, and justify theinterruption.
Distinguish novice and expert users,and adapt to their levels.Where possible guide thenaive user, but also allow the expert user to initiateactions and use short-cuts.
(Lea 1994:30).
Supportinterruption and recovery: use the 'normal manners'for interrupting the user in his current activities, i.e.,only interrupt in 'critical' or 'urgent' situations, andprovide the user with a justification for the inter-ruption.
Also, reassure the user that the system isrobust against sudden interruptions (e.g., by usingsynthesized speech; the user will feel less social ur-gency to respond when .he or she is aware of thefact that the dialogue partner is a computer (Leiser1993); contrast his with commandment vI).VI.
WHY INTERFACE SHALL BE TRANSLUCENTAllow inputs which perform several steps, or whichallow jumping from one point to another (Lea1994:30).
Use natural speech output (as opposedto synthesized speech) for prompts, to avoid focuson the quality of the machine voice (Lea 1994: 25).VII.
THOU SHALT COGITATE BEFORE THOU COM-MENCETHLast but not least, the necessity of a design phaseshould not be underestimated, and this is wherecommandments I to vI are useful.
Also, always keepthe added value of speech in mind (Lea 1994:15).3 On the  des ign  o f  the  DM modu leHow to obey these 7 commandments when designinga DM module?
As usual with commandments, someare conceptually clearer and easier to obey than oth-ers.
The best way to follow commandments is totake them as a source of inspiration and not followthem to the letter.
In fact, obeying all guidelinessubsumed by the 7 commandments is effectively im-possible, since - -as the reader will have noticed--they contain some inconsistencies.While living by all these commandments whendesigning a system to be used in 'normal situations'is effectively impossible, to obey them when design-ing for in-car systems might appear to be even moredifficult.
One reason for this is that the interactionwith the system must never interfere with the user'sprimary task (the actual driving).
Moreover, sincethe car is an acoustically hostile environment, helimits of speech recognition have to be taken specialcare of.
In this section, we look in more detail atthe design of the DM module within VODIS, withspecial attention to the specific conditions posed bythe vehicle-context and the relation with the 7 com-mandments.
In the section hereafter we discuss theactual implementation i  more detail.3.1 The  VODIS  pro jec tThe main objective of the VODIS project is to in-tegrate and further develop the technologies whichare required for the design and implementation ofvoice-based user-system interfaces.
More concretely,the project aims at developing a vocal interface toan existing driver information system (namely theBerlin RCM303A of Robert Bosch GmbH), whichintegrates a tuner, an amplifier, a CD changer, a cas-sette player, a navigation computer and a GSM tele-phone.
The vocal interface is speaker independent,and is developed for German and French.
The pro-ject consists of two stages: for the first stage a basiccommand & control anguage is defined consisting ofabout 70 keywords, which essentially encompassesthe functionalities of the current system (selectinga device: "navigation", "tuner", choosing a destin-ation, making phone calls, etc.
), as well as dialoguecontrol keywords ("no", "OK", "abort", etc.).
Ex-perimental evaluations of the first prototype will bethe input to design and development of the secondprototype, which also aims at broadening the rangeof possible user's input by allowing spontaneouslyspoken database queries for the navigation task.
Thereader can visit http ://www.
is.
cs.
cmu.
edu/VODISfor more details.Figure 1 depicts the general architecture of theVODIS  system.
As said, the purpose is to designand implement a voice interface to the Berlin driverinformation system.
A controller module providesa software interface to the Berlin system: it canmodify the state of the Berlin system, and it canretrieve information from it.
If the user wants tosay something, (s)he can indicate this by pressing abutton, located near the steering wheel (the Push-To-Talk (PTT)  button).
The result of a PTT  pushaction is that the speech recognition unit is activated.The DM module fills the gap between the speech re-cognition and the controller.
The DM can provideinformation to the user via Text-To-Speech (TTS)synthesis and via a small display.This architecture can already be related to somecommandments.
The PTT  button allows the user totake the initiative: interaction is not forced, the sys-84Dia'1 Theuser I"\[ Speech Recognition \]--V---V-- i logue ManagerTI ITBEI~LIN \[Figure 1: The VODIS architecturetem just presents the user with his/her options, andby pressing the button the user requests attentionof the speech recognition unit (cf.
v).
Additionally,TTS is used instead of pre-recorded natural speech(v/v I ) .
This choice is more or less forced upon us,since there is no fixed vocabulary from the system'spoint of view.
For instance, each user has a personalphone book stored in his GSM telephone, and to pro-nounce the names in this phone book the system canonly use TTS.3.2 Cop ing  w i th  the  l imi tat ions  of  speechrecognitionGood results from speech recognition is a conditiosine qua non for any spoken dialogue system.
A sys-tem with bad results from speech recognition makesit impossible to satisfy many of the commandments(how could a user judge a system as flexible, consist-ent, adaptive, simple etc., if (s)he is often misunder-stood by the system?
).Commandment Iv stresses the importance oferror-prevention (IV.a) and error-handling (Iv.b).With regard to Iv.a, several techniques are usedwithin VODIS to prevent SR errors.
First of all,a lot of attention is paid to optimizing the speechrecognition unit 'off line', e.g., by noise reduction.Fortunately, the kind of noise in the car (engine ro-tation, tires, wind, etc.)
is rather specific, and highlycorrelated to the driving speed, which is available allthe time, which means that distortion canbe  com-pensated effectively.
Moreover, the recognition unitis trained on the basic command and control lan-guage developed for the first phase of the project.A third way to optimize speech recognition is basedon the fact that not all the keywords need to beavailable all the time.
'Since these keywords em-brace the functionalities of the original Berlin sys-tem, they are partitioned in a more or less compar-able way (thus, when the interaction is dealing withHiFi, the user cannot enter a destination for route-guidance).
This makes it possible to partition thelanguage by means of a number of sub-grammars(roughly speaking: there is a default-set of alwaysactive keywords, and each mode is associated withits own grammar, thus one could speak of a HiFi-subgrammar, a navigation-subgrammar etc.).
TheDM module decides which sub-grammar(s) houldbe active at any point in the dialogue, and sendsthis information to the speech recognition unit.
Asa consequence, the branching factor (= the numberof available keywords at a given point) is always sig-nificantly less than the total number of key-words,which further decreases the chance of speech recog-nition errors.
2Nevertheless, SR errors cannot be precluded.
Thelowest error rate for speaker independent recogni-tion achieved up to now on a task with a perplexitycomparable to the one in VODIS is around 4% (Coleet al 1996).
And it is unlikely that recognition inthe car will lead to better results.
In other words:recognition errors will occur and this means that amethod has to be developed to handle them.
Eachtime the user utters something, the SR unit sendsan n-best list of results to the DM.
When the topelement of this list is different from the user's actualutterance, we are facing a SR error.
In general, thesystem cannot decide whether the first candidate ofthe list is:1. the right candidate (as it will be in mostcases)~2.
an error due to confusion within the SRunit, or3.
an error due to the user, e.g., becausea phrase was uttered outside thecurrently active vocabulary.The only way to detect and solve an error is via2A disadvantage of this partitioning is that there is acertain risk of the user uttering a keyword which does notcorrespond to the current state of the system, and sincethe speech recognition unit will not be able to recognizethe user's utterance in that case only a relatively non-specific warning can be given (e.g, system: "The systemcannot interpret your utterance.").
Thus, this choicemight lead to a reduction in 'user-friendliness' of the sys-tem.
However: as noted above, good results of speechrecognition is the basic requirement for a voice interface.Thus, the actual partitioning is a compromise betweencommandment Iv on the one hand, and commandmentsI, III, V and vI on the other.
Notice that this comprom-ise puts extra emphasis on the marking of the currentinteraction context (cf.
m), since a user which is wellaware of the current state of the system is less likely toperform an input which is not allowed at that point.85a validation process (more of which below).
Whenthe first candidate of speech recognition is rejec-ted by the user, the system has to initiate a re-cover strategy.
It would be a bad strategy to sys-tematically request a repetition from the user, asusers are known to vary their pronunciation duringsubsequent attempts (volume, pitch, rate) as theywould do when a human dialogue partner made a'speech recognition' error, which has the undesiredside effect of deteriorating speech recognition results.These two considerations imply that the handling ofspeech recognition results by the DM should be asystem controlled strategy, which is applied to allresults given by the speech recognition.
Figure 2shows a strategy develop.ed in VODIS for that pur-pose.vesul~ off S~ 'qnol challenged \[.
.
.
.
by She user ieeanacKI .
.
.
.
.
.
~l~ ~on current\[.
.
.
.
.
I \]candidateSR result cancelled\[ by ~he user \[?feedback gz Fprompt forre-utteringchallenged \[ by the useryesothercandidatesavailable?noincrement \[number ofattemptsFigure 2: The handling of SR resultsLet us illustrate this view diagram via an example.One place where SR errors might arise is in therecognition of names in the user's personal phonebook.
Suppose that the user's phone book containstwo nicknames: "Phil" and "Bill".
Now the userutters "Call Bill".
The SR unit returns an orderedtuple of results to the DM: ( "Call Phil", "Call Bill"/.
Thus, "Call Phil" is a~signed a higher confidencescore than the designated, second candidate "CallBill".
The DM now proposes the first candidate ofspeech recognition via a validation feedback, e.g.,the system says "Call Phil?".
At this stage, the usercan do three things:1. cancel the SR results,2.
challenge the first candidate, or3.
accept it.In the current example, the user can be expected togo for the second option.
Then the DM proceedswith the the next candidate ("Call Bill?
"), whichcorresponds with the actual utterance.
Again, theuser can do three things, but now we may assumethat the user will not challenge this proposed can-didate, as it corresponds with the actual input fromthe user.
The advantage of such a routine is that itapplies to all inputs from the user in a uniform way,and does not put a too heavy burden on the user'sattention.
Naturally, the user has to 'know' what isexpected from him, and this puts high demands onfeedback and prompt design.Summarizing, the basic mechanism sketched infigure 2 applies to every spoken input of the user inthe same way, which complies with commandment I(be consistent).
Whenever an error occurs, the error-handling part of commandment IV is obeyed as well:no blame is assigned, the focus is on recovering theerror and there is an undo option ("abort").3.3 Feedback  and prompt  designIn general, feedback aims at helping the user in keep-ing a good mental representation f the system (com-mandments II-IV), and a good representation gener-ally increases the efficiency of the communication(e.g., the chances of out-of-vocabulary input are re-duced).
The DM can give feedback to the user viatwo modalities: sound and vision.
In general, it isdifficult to decide which modality should be chosento present a given piece of information (witness e.g.,Kariagiannides et al 1995).
However, two practicalguidelines apply for VODIS:1.
Since a relatively short visual message might bemissed (vision is employed for driving), essentialinformation should at least (see 2.)
be conveyedvia sound,2.
Since speech is transient, information which theuser may need to consult more than once shouldbe available via vision.A central ingredient of the procedure which handlesuser's inputs, sketched above, is the system's valid-ation feedback on the current SR candidate.
Leiser(1993:276) mentions two extremes regarding to val-idation: 1. assume that no errors have occurred,and leave it to the user to recover from any in-opportune change of state as a result, and 2. al-ways ask the user to explicitly confirm.
The firstalternative ignores error-handling (Iv.b) and is ob-viously in conflict with the underlying philosophyof the handling of user's input.
The second altern-ative, however, disobeys commandments 11 (lookingback too much) and IV (forcing unnecessary valid-ation), and both violate v (by not being adaptive).An adequate balance between both strategies, to-gether with implicit validation, would greatly im-prove the situation.
This is the strategy chosen inVODIS.
Suppose, for example, that the n-best listof SR results contains "radio" as the first candidate.86This candidate is presented for validation to the uservia a feedback message which tells the user that thesystem will switch to the radio and start playing thelast selected radio station, e.g., "Switching to radiostation BBC 1".
Once this message has been syn-thesized, the user can do various things.
The usercan challenge the prompt by explicitly saying "no"or "abort".
But the user can also validate it, eitherexplicitly by saying "yes" or "OK", or implicitly bykeeping silent ('those who don't speak, agree'), orby proceeding with the discourse via the utteranceof a new command (e.g., "play KISS FM").For this approach to work, the feedback messageshave to meet certain criteria.
It is well known thatpeople are not only sensitive to the content of a mes-sage but also to the way it is sent.
3 A syntacticallymarked yes/no question ("Do you want to switchto navigation mode?")
or a clear question contour('high and rising', in the notation of Pierrehumbertand Hirschberg (1990): H* H H%) will cause the userto feel forced to explicitly confirm or reject.
This in-dicates why feedback messages hould be phrasedin a consistent style (I and If).
Sometimes, it maybe useful to violate these'commandments, most not-ably in non-standard situations, e.g., after an errorhas been detected.
Notice that in such cases, 're-packaging' of the message serves a purpose: the useris provided with extra clues which are significant inthat they provide additional information which mayhelp the user in updating his model of the system.Thus: prompts hould be short and to the point, andviolations of this principle should serve a purpose.
44 On the  imp lementat ion  o f  the  DMOur ultimate objective is the development of a'good' DM module as part of the VODIS system,and we believe that designing a dialogue managerwhich obeys the 7 commandments a  far as possibleis a first, indispensable step towards that objective.The second step, which is addressed in this section,is implementing a DM module based on this design,as part of the first VODIS prototype.
Since this pro-totype will be tested by drivers in the car, it runs ona stand-alone machine.
The DM module is a separ-ate block in the VODIS architecture, which interacts3This relates to the notion of information packaging(cf.
Chafe 1976).
Chafe points out that the format of amessage is only partially related with the content of themessage, "\[information packaging has\] to do primarilywith how the message is sent and only secondarily withthe message itself, just as the packaging of toothpastecan affect sales in partial independence to the quality ofthe toothpaste inside".4Put differently, what holds for human speakers (cf.Grice 1975), should hold for speaking systems as well.with other blocks via intercommunication protocols.The DM is written in C++.The DM receives messages from two sources: thecontroller (the software interface to the Berlin sys-tem) and the SR unit.
Messages from the control-ler concern state-changes of the system.
They canlead to an update of the state-representation of thesystem, or to an interruption (e.g., in the case ofan incoming phone call).
In the case of an inter-ruption, the DM can support he interruption of themain thread of the dialogue and restore the previouscontext, employing stack mechanisms.
In general,change of status information (as far as it is directlyrelevant for the user) is handled via specific systeminitiated routines.The other, from the point of view of this paper,more interesting source of messages received by theDM are mostly the result of a user initiative: theuser has said something.
Whenever the user indic-ates that (s)he wants to say something by pressingthe PTT  button, the DM is notified of this PTTevent and waits for the actual results of speech re-cognition.
Figure 3 depicts the modules of the DMwhich are involved in the subsequent handling of theinput from the user./DM ~ '?
!_Result s ilexicon IIl parses  I Ilexicon task  ,,J Interpreter context ilI candidates IIValidation~ I\[ gwzez~uzj----------j protoco l  \ ]~,  .
.
.
.
f. .
.
.
.
.
~"~ 2 ~  .
.
.
.
.
.
.l co"roUe~ lFigure 3: DM software architectureThe DM module has a modular structure.
Afterthe user's input has been analysed in the speech re-cognition unit, the DM receives a message consist-ing of a list SR._results, which contains the recog-nized phrases and their respective confidence scores.In the DM module, this list is unwrapped, andthe phrases are parsed.
Each recognized phrase is87mapped to a set of representations a found in thelexicon.
If parsing one candidate results in a non-singleton set of interpretations, it is ambiguous.
TheParser returns a new l ist , 'parses,  to the Interpreter.In this module, the lexical items are mapped to tasks(found in the task lexicon) and related to a con-text, containing information about the current situ-ation (including application and dialogue).
We fol-low the common treatment of resolving ambiguitiesusing this contextual information.
5 The result ofthis process is a list cand idates ,  the first element ofwhich consists of the task representation f the firstdisambiguated SR_result.
This is the first candidatewhich is proposed for validation to the user (via TTSand/or the display, depending on the kind of mes-sage); an implementation of the validation protocolgiven in figure 2.
The feedback messages are for-mulated by a generator module.
In most cases, thefirst candidate will be the right one (see discussionin section 3).
If a proposed candidate is (explicitlyor implicitly) accepted by the user, the DM sends amessage (containing the validated Task) to the con-trol unit requesting modification of the status of theBerlin system according to the user's wishes.
Also,the DM sends a message to the speech recognition(using the Select_SR_Grammar function) to activatea new set of sub-grammars corresponding to the newstate of the system and the ongoing dialogue.5 Discussion: future workIn this discussion section we want to address threeissues.
The first is evaluation, the second concernsthe generalizability of the methods described in thispaper, the third the applicability of the 7 command-ments.5.1 Eva luat ionThe DM module described in this paper will be partof the first VODIS prototype, to be completed in fall1997.
As mentioned, this first prototype will be ex-tensively evaluated by users.
For this purpose, thevocal interface to the Berlin system will be placed ina car, and evaluated by French and German drivers,in Paris and Karlsruhe respectively.
During the eval-uation, attention will be paid to (i) the speech re-cognition performance, and (ii) the user-system in-terface, with the emphasis on security, safety, ac-ceptability and effectiveness.
~The results of theseexperiments will constitute the input for the devel-opment of the second prototype, which also aims at50f course, the limited control-and-command lan-guage will not give rise to many ambiguities.
The situ-ation is expected to change when the range of user's in-puts is widened at a later stage.broadening the range of the possible user's input byallowing more 'natural anguage like' database quer-ies for the navigation task.
This raises the questionwhether the DM methods described in this paper aretransmissible to the second prototype.5.2 How genera l i zab le  are the  DMmethods?The primary aim of the first VODIS prototype isto build a simple, but robust spoken language sys-tem which can be used effectively in the car.
TheDM methods described in this paper are also in-tended to be simple, but robust, and that is whythe prevention and handling of speech errors playsa central role.
Of course, the step from a limitedcommand and control language to more 'spontan-eous' speech is a big one, and is likely to affect theDM.
However, we would like to claim that the basicDM methodology can remain largely unchanged.
Tobackup this claim, let us first describe the (planned)second prototype in somewhat more detail.
Themain difference in architecture between the two pro-totypes is that in the first one the results from theSR unit are directly fed to the DM module, whilein the second one the two modules are connectedvia a semantic parser (see e.g., Ward 1994).
Thisparser is trained on a language model, and differsfrom classical parsers in that it does not (only) use'syntactic' information, but also domain dependent'semantic' information.
That  is: it does not lookin the input for NPs and APs, but rather for, say,'destination phrases' and 'arrival time phrases'.
Ittries to extract as much information as possible fromthe received input, simply ignoring input it cannotparse (e.g., interjections and false starts).
This en-tails that the DM will not be confronted with an nbest list of recognized key-words, but with a morecomplex structure; a kind of list of parses annotatedwith confidence scores from both the SR and the se-mantic parser.
Again, the DM can validate the firstcandidate in the way described above.
Suppose thefirst candidate of the input list received by the DMindicates that the user wants to go to Bistro Le potde terre in Paris.
The DM can put up this first can-didate for validation.
Essentially, the user will havethe same options as for the keyboard based commu-nication (Figure 2), except that (s)he now will havethe additional opportunity of clarifying his challenge(user: "No, I don't want to go to Bistro Le pot defer, but to Bistro Le pot de terre").
6 On the basis6The recognition of proper names (and in particularcity names) is a major problem to be tackled for thesecond demonstrator.
For example, the German navig-ation computer knows 30.000 city names.
Plain recog-88of such corrections the DM can perform an updateon the original list of annotated inputs.
Of course,this is all speculative, but it indicates that the DMmethods to deal with SR results presented above canbe used for the second prototype as well.5.3 How app l i cab le  are the  7commandments?In the Introduction we noted that the literature doesnot contain a general theory for the development ofa DM module, while it does contain a lot of prac-tical guidelines.
On the one hand, this can be seen asan indication that this is still a relatively immaturearea of research.
On the other hand, it also indicatesthat the characteristics of a Dialogue Manager arelargely determined by the kind of application.
Ofcourse, the many guidelines found in the literature(summarized in our 7 commandments) are poten-tially very useful when one designs a DM module.However, we also saw that obeying all command-ments is effectively impossible, since some of theguidelines they subsume are inconsistent with eachother.
This raises an obvious question: how applic-able are the 7 commandments?
Or more in general:what are useful guidelines?
The evaluation of thefirst VODIS prototype may give some indications inthis respect.
For example, it might turn out thatusers do not like to proceed with the discourse, butwould prefer explicit validation of each input.
Inour opinion, it would be very interesting to find outwhich specific guidelines are useful in which specificsituations.
However, this research program will notbe carried out within VODIS.6 Conc lus ionsWe have described some aspects of the design of theDM module within the VODIS project, with spe-cial attention to the methods the DM can employto compensate for the limitations of speech recogni-tion.
Where possible, we have related our propos-Ms to guidelines found in the literature, summarizedin our 7 commandments for spoken dialogue.
Ofcourse, the ultimate objective is the development ofa "good" dialogue manager module as part of theVODIS project, and we believe that designing a dia-logue manager which obeys the 7 commandments afar as possible is an indispensable step towards thatobjective.
The implementation, briefly described insection 4, will be part of the first VODIS prototype,which will be evaluated by users.
The results of thesenition (user: Ich m~chte nach Himmelpforten fahren)on such a list will cause problems, for which alternativestrategies have to be chosen.experiments will be the input for the development ofthe second prototype.AcknowledgmentsThis work was funded by the Language Engineer-ing/Telematics Applications Program, project LE-1 2277 (VODIS).
Thanks are due to Maddy Janse,Kees van Deemter and Gert Veldhuijzen van Zantenfor comments on an earlier version of this paper.Re ferencesChafe, W. 1976 Givenness, contrastiveness, definiteness,subjects, topics and point of view.
In: C. Li (ed.
),Subject and topic, 25-55, New York, Academic Press.Cole, R. et al 1996 Survey of the state of the art inhuman language technology, to appear.
7Fraser, N., 1994, Interactive diMogue, In: EAGLESspoken language systems (draft), ESPRIT.Grice, H. P. 1975, Logic and conversation.
In: Syntaxand semantics 3: speech acts, P. Cole (ed.)
AcademicPress, New YorkGrudin, J.
1989, The case against user interface con-sistency.
In: Communications of the ACM, 32 (10):1164-1173Hix, D. & H. Hartson, 1993, Developing user interfaces,Wiley, New YorkKariagiannides, C., et al 1995 Media/modalities in in-telligent multimedia interfaces.
In: J. Lee (ed.)
Firstinternational workshop on intelligence and multimod-ality in multimedia interfaces, HCRCKaris, D. & Dobroth, K. 1991, Automating services withspeech recognition over the public switched telephonenetwork: human factors considerations.
In: IEEE J.Selected Areas in Commun., 9 (4), 574-585Lea, W., 1994, Developing usable voice interfaces.
In:Journal of the American Voice I /0  Society, 16Leiser, R., 1993, Driver-vehicle interface: dialogue designfor voice input.
In: A. Parkes ~z S. Franzen (eds),Driving future vehicles, Taylor & Francis, 275-294Pierrrehumbert, J.
& J. Hirschberg 1990 The meaningof intonational contours in the interpretation of dis-course.
In: P. Cohen et al (eds.
), Intentions in com-munication, 271-311, MIT PressShneiderman, B., 1987, Designing the user interface -strategies for effective human-computer interaction,Second edition, Addison Wesley, Reading, MA.Ward, W., 1994, Extracting information in spontaneousspeech.
In: Proceedings of ICSLP 94, YokohamaThttp : I/www.
cse.
ogi.
edu /CSLU/HLTsurvey /  for theweb-version.89
