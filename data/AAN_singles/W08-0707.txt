Proceedings of the Tenth Meeting of the ACL Special Interest Group on Computational Morphology and Phonology, pages 39?48,Columbus, Ohio, USA June 2008. c?2008 Association for Computational LinguisticsPhonotactic Probability and the Ma?ori Passive:A Computational Approach?O?iwi Parker JonesOxford University Phonetics Laboratory41 Wellington SquareOxford, OX1 2JF, UKoiwi.parkerjones@phon.ox.ac.ukAbstractTwo analyses of Ma?ori passives and gerundshave been debated in the literature.
Both as-sume that the thematic consonants in theseforms are unpredictable.
This paper reportson three computational experiments designedto test whether this assumption is sound.
Theresults suggest that thematic consonants arepredictable from the phonotactic probabilitiesof their active counterparts.
This study haspotential implications for allomorphy in otherPolynesian languages.
It also exemplifies thebenefits of using computational methods inlinguistic analyses.1 IntroductionThe Ma?ori passive is perhaps the most famous prob-lem in Polynesian linguistics.
It has received atten-tion from Williams (1971, first published in 1844),Biggs (1961), Hohepa (1967), Hale (1968; 1973;1991), Kiparsky (1971), Kaye (1975), Kenstowiczand Kisseberth (1979), McCarthy (1981), Moorfield(1988), Sanders (1990; 1991), Harlow (1991; 2001;2007), Bauer (1993), Blevins (1994), Kibre (1998),de Lacy (2004), and Boyce (2006).
Some represen-tative examples of active and passive verbs are givenin Table 1 (Ryan, 1989).Two types of analysis have been proposed forthese data (Hale, 1968).
These are known as the?morphological?
and ?phonological?
analyses.
Forthe subset of passives with thematic consonants, theanalyses parse the data differently into stems andsuffixes.
To illustrate this, the examples from Table1 have been parsed in Table 2 with hyphens insertedActive Passive Gloss/FeRa/ /FeRahia/ ?to spread?/oma/ /omakia/ ?to run?/inu/ /inumia/ ?to drink?/eke/ /ekeNia/ ?to climb?/tupu/ /tupuRia/ ?to grow?/aFi/ /aFitia/ ?to embrace?/huna/ /hunaia/ ?to conceal?/kata/ /kataina/ ?to laugh?/ako/ /akona/ ?to teach?/heke/ /hekea/ ?to descend?Table 1: Examples of active and passive verbs in Ma?ori.between the stems and suffixes.
The thematic con-sonants have also been flagged.In both types of analysis, the qualities of the the-matic consonants are assumed to be unpredictableand are therefore lexicalized.
To cite just one ex-ample, Blevins writes that ?a consonant of unpre-dictable quality appears in the passive and gerundialforms, but this consonant is absent when the verboccurs unsuffixed?
(Blevins, 1994, p. 29, my em-phasis).In the phonological analysis, the thematic con-sonants are lexicalized with the rest of the stem.The active forms are derived by a rule that deletesstem-final consonants.
Although less obvious, themorphological analysis also lexicalizes the thematicconsonants by allowing stems to be stored with ?dia-critic features?.
The reason for the diacritic features39MOR PHON THEME/FeRa-hia/ /FeRah-ia/ /h//oma-kia/ /omak-ia/ /k//inu-mia/ /inum-ia/ /m//eke-Nia/ /ekeN-ia/ /N//tupu-Ria/ /tupuR-ia/ /R//aFi-tia/ /aFit-ia/ /t//huna-ia/ /huna-ia/ none/kata-ina/ /kata-ina/ none/ako-na/ /ako-na/ none/heke-a/ /heke-a/ noneTable 2: Morphological analyses (MOR), phonologicalanalyses (PHON), and thematic consonants (THEME).is to constrain the free combination of stems and suf-fixes, which, if unconstrained, would over-generateunattested passive forms.
As an illustration, if weassume the exhaustive association of /inu/ with thediacritic feature [+m], then the stem would be al-lowed to combine with /-mia/, but not with anyother suffixes.
(In short, to store the diacritic fea-ture is to lexicalize the quality of the thematic con-sonant.)
Although lack of a diacritic feature is al-lowed for stems that take ?default?
suffixes (/-tia/,/-ia/, or /-a/, depending on stem?s size and compo-sition), this would only be one thematic consonant(out of six) that would not be lexicalized; the phono-logical analysis could still be seen as lexicalizing themajority of the thematic consonants.
Furthermore, acase could be made that the contrastive absence ofa [+t] diacritic feature effectively lexicalizes /-tia/,too.
Finally, it is worth noting that the purpose of thedefault suffixes is to provide analyses for previouslyunseen stems, such as nonce words or borrowings; inother words, the purpose of defaults is not to make/-tia/ non-lexical.In this paper, I want to question the assumptionthat thematic consonants are unpredictable in Ma?oripassives.
To do so, I will focus on the phonotac-tic probabilities of active verbs as predictive of theirpassive and gerundial forms.
I implemented theanalysis as an artificial neural network, which I de-scribe below.
This follows from a rich tradition ofusing neural networks in phonology and morphol-ogy, as exemplified by the English past tense modelsof Rumelhart and McClelland (1987) and Plunkettand Marchman (1991).
Incidentally, I chose neu-ral networks to implement my analysis because oftheir computational properties, not because of an ar-gument for the biological plausibility of my analy-sis.
I suspect that similar results could have beenobtained from another statistical formalism, like thek-nearest neighbor approach of TiMBL (Daelemansand van den Bosch, 2005).The paper is laid out as follows.
The networkis described in section 2, the data and experimen-tal methodology are presented in section 3, and theexperimental results are reported in section 4.
Thediscussion and conclusion follow in sections 5 and6, respectively.2 Network architecture and settingsThe network I used in this study was designed tomodel a function from the representation of an activeverb in Ma?ori (alternatively, from a verb stem in themorphological analysis) to a set of output categoriescorresponding to passive formations (i.e., to a set ofpassive suffixes in the morphological analysis).For the simulations in this study, I used a 3-layerfeed-forward architecture with 199 input units, 100hidden units, and 10 output units.
The connectiv-ity between adjacent layers was all-to-all.
One fullyactivated bias unit was connected to every unit inthe hidden and output layers (to model a threshold-ing effect and to aid learning).
Figure 1 provides arough blueprint of the network in ?slab?
notation.Figure 1: Network architecture; all-to-all connections be-tween units in adjacent layers; bias unit not shown.To calculate the output or activation of a node i in40the network, I used a sigmoid functionai =11 + e?neti, (1)where e is the exponential and neti is the net input tonode i.
As usual, the net input to node i was definedasneti =?jwijaj , (2)where wij refers to the weights on the connectionsfrom nodes j to node i, and where aj refers to theactivations of nodes j (Plunkett and Elman, 1997).Learning was achieved using back-propagation anda learning rate of 0.1 (Werbos, 1974).
No momen-tum was used.
Let us turn now to the design of eachlayer in the network?s architecture.2.1 The input layerThere were 199 input units, where the number of in-put units was chosen to allow up to 18 segments inthe input.
Each segment was transformed into an 11-bit vector according to the feature encodings in Ta-ble 3.
The unaccounted-for unit was used to tell themodel if it was learning a passive or a gerund func-tion; it can be thought of as specifying the semanticvalue PASS or NMLZ.vocaliclongroundhighlowbilabialalveolarvelarplosivefricativenasal/a/ 1 0 0 0 1 0 0 0 0 0 0/a:/ 1 1 0 0 1 0 0 0 0 0 0/e/ 1 0 0 0 0 0 0 0 0 0 0/e:/ 1 1 0 0 0 0 0 0 0 0 0/i/ 1 0 0 1 0 0 0 0 0 0 0/i:/ 1 1 0 1 0 0 0 0 0 0 0/o/ 1 0 1 0 0 0 0 0 0 0 0/o:/ 1 1 1 0 0 0 0 0 0 0 0/u/ 1 0 1 1 0 0 0 0 0 0 0/u:/ 1 1 1 1 0 0 0 0 0 0 0/p/ 0 0 0 0 0 1 0 0 1 0 0/t/ 0 0 0 0 0 0 1 0 1 0 0/k/ 0 0 0 0 0 0 0 1 1 0 0/F/ 0 0 0 0 0 1 0 0 0 1 0/h/ 0 0 0 0 0 0 0 0 0 1 0/m/ 0 0 0 0 0 1 0 0 0 0 1/n/ 0 0 0 0 0 0 1 0 0 0 1/N/ 0 0 0 0 0 0 0 1 0 0 1/R/ 0 0 0 0 0 0 1 0 0 0 0/w/ 0 0 0 0 0 1 0 0 0 0 0// 0 0 0 0 0 0 0 0 0 0 0Table 3: Ma?ori phonemes and feature encodings.I approached the representation of active verbsempirically.
Three coding schemes were considered,one of which was segment-based and two of whichwere syllable-based.
Table 4 provides a handful ofexamples in the segmental coding scheme.
Noticethat each representation is right-aligned within thematrix and that there are no gaps between the seg-ments.
Null phonemes were used to fill the emptycells so that each input vector would be exactly 199bits long.6 5 4 3 2 1/a:/ 7?
a:/uhi/ 7?
u h i/waiho/ 7?
w a i h o/inoi/ 7?
i n o i/tia/ 7?
t i aTable 4: Examples of segmental coding.For both syllabic coding schemes, I used a 3-cellsequence to represent a CVV syllable template.
Toillustrate this, the examples from Table 4 have beenreanalyzed in Table 5 to be consistent with both syl-labic coding schemes.Syll SyllC V V C V V/a:/ 7?
a:/uhi/ 7?
u h i/waiho/ 7?
w a i h o/inoi/ 7?
i n o i/tia/ 7?
t i aTable 5: Examples of syllabic coding.Within each syllable sequence (Syll) in Table 5,the first position (C) was reserved for an onset, thesecond position (V) was reserved for the primaryvowel, and the third position (V) was reserved forthe second vowel of a diphthong.
Again, everyrepresentation was right-aligned.
Any sequence ofshort vowels in an active verb was treated as a diph-thong, unless the vowels were equal in quality or thesecond vowel was lower than the first.
For exam-ple, /ei/ and /eo/ would be diphthongs, but /ee/and /ea/ would be analyzed as hiatus.The syllabic coding schemes differed in theirtreatment of a long vowel followed by a short vowel,where the two vowels had non-identical qualitiesand the second was not lower than the first (i.e.,41where they would be diphthongs if both were phone-mically short).
The first coding treated these se-quences as diphthongs (Coding 1); the second didnot (Coding 2).
Table 6 contrasts the two syl-labic schemes for the word /ta:oRo/ ?to break down?.Since de Lacy (2004) advanced the analysis onwhich I based Coding 2, I shall sometimes distin-guish these schemes by referring to Coding 2 as ?thede Lacy analysis?.Syll Syll SyllC V V C V V C V VCoding 1 t a: o R oCoding 2 t a: o R oTable 6: Two syllabic codings for /ta:oRo/.In the section on experiments below, I report onwhich of these three schemes worked best.
For now,my aim has been to motivate the network?s inputlayer.
Notice that 199 input units provides space forinput representations of up to 6 syllables (6 sylla-bles ?
3 prosodic positions ?
11 features = 198),with room for the semantic unit mentioned above.None of the active verbs in the passive dataset re-quired more than 6 syllables in any of the codingschemes.2.2 The output layerSince there were 10 passive categories in my dataset(corresponding to the passive suffixes in the mor-phological analysis, illustrated in Figure 2), 10 out-put units were employed in the network.
It was con-sidered appropriate to model membership to eachcategory independently, as many verbs show multi-ple passive forms (as /motu/ ?to separate, wound?does in its passive forms /motu-hia/ and /motu-kia/).
The key to reading the model?s passiveoutput can be given as the vector [/-hia/, /-kia/,/-mia/, /-Nia/, /-Ria/, /-tia/, /-ia/, /-ina/, /-na/,/-a/].
Although the model represents its outputs asbits, they can be interpreted by reference to this key.For example, the passive output for /tapa/ ?to name?should be [1, 0, 0, 0, 0, 0, 1, 1, 0, 0], since Ryan?sdictionary attests /tapa-hia/, /tapa-ia/, and /tapa-ina/.
Note that these alternative outputs are takento represent ?free?
variation within a single speaker,rather than dialectical variation between speakers.While the main focus of the model is the Ma?oripassive, the network can also be used to associate ac-tive verbs (alternatively, morphological verb stems)with their gerundial forms (i.e., gerund suffixes, in amorphological analysis).
Although there are fewergerund suffixes than passive suffixes, there is a well-known parallel between the existing gerund suffixesand the subset of passive suffixes with thematicconsonants.
Consider the vector [/-haNa/, /-kaNa/,/-maNa/, /-Na/, /-RaNa/, /-taNa/, /-aNa/, N/A, N/A,N/A], which can be used as the key for interpretinggerund outputs in the network.
Notice that the pas-sive and gerund keys both order the thematic con-sonants as in the vector [/h/, /k/, /m/, /N/, /R/,/t/, //, N/A, N/A, N/A].
(Here, the null segment //has parallels in both keys.)
So, interpretation of thegerundial output can also be performed by lookup.For example, the target output for /Fi:tiki/ ?to tieup?
on the gerund task is [0, 0, 0, 0, 1, 0, 0, 0, 0,0], since the dataset from Ryan?s dictionary attests/Fi:tiki-RaNa/.
Finally, output activations for the lastthree nodes are undefined in the gerund task.
I wouldhave interpreted a significant activation for any ofthem as a false prediction.2.3 The hidden layerIn general, too few hidden units do not provide anetwork with enough computational power to learna desired function; too many units will result in thenetwork overfitting the data, in which case its abil-ity to generalize will suffer.
Given the dimensionsof the input and output layers, I was able to esti-mate the required number of hidden units empiri-cally.
Starting with a conservatively small numberof hidden units, I trained the network for 100 epochson 371 patterns in the passive dataset (i.e., approxi-mately 80% of 464 patterns, which did not containany known loanwords), and then froze the network?sweights and tested its predictions on 46 of the with-held patterns (i.e., approximately 10% of the pas-sive dataset), measuring the mean squared error.
Irepeated this procedure for increasingly populatedhidden layers, until a trend emerged suggesting anoptimum number of hidden units to minimize themean squared error on the test set.
For this task,100 hidden units seemed to work well.
The resultsfor the estimation of hidden units have been graphedin Figure 2.42Figure 2: Minimizing error in the network.3 Methodology3.1 DataThe passive data in this study were drawn from theMa?ori-English section of The Revised Dictionary ofModern Ma?ori (Ryan, 1989).
This provided 476passive patterns, 12 of which were flagged as En-glish borrowings.Active Passive Gloss/taRaiwa/ /taRaiwa-tia/ ?drive?/Raka/ /Raka-ina/ ?lock?/paeRa/ /paeRa-tia/ ?boil?/wepu/ /wepu-a/ ?whip?/peRehi/ /peRehi-tia/ ?press, print?/pauRa/ /pauRa-tia/ ?powder?/Faka-ho:noRe/ /Faka-ho:noRe-tia/ ?honor?/pauna/ /pauna-tia/ ?to weigh?
(< pound)/paRau/ /paRau-tia/ ?plough?/minita/ /minita-tia/ ?minister?/Faka-Rapihi/ /Faka-Rapihi-tia/ ?to make rubbish of?/paRai/ /paRai-tia/ ?fry?Table 7: 12 English borrowings with their passive forms.Since I only found two gerund patterns in Ryan?sdictionary (viz.
/hu:pana-taNa/ and /Fi:tiki-RaNa/), Ialso searched the Ma?ori Broadcast Corpus (MBC)for words ending as if they had gerundial suffixes(Boyce, 2006).
This turned up 1537 gerund-like to-kens, which reduced to 139 gerund-like types.An overview of the data is provided in Tables 8and 9.
Table 8 shows that 464 passive patterns mapto 28 output categories, the most populous of whichcontains 188 members.
In other words, 188 verbstems take the passive suffix /-a/ and no other.
Bycontrast, only one verb stem takes either /-tia/ or/-na/ as its passive suffixes.
Similarly, Table 9shows that 233 gerund-like patterns map to 16 out-put categories.
For example, 120 (presumed) verbstems take the gerund suffix /-taNa/.Category Members Category Members{/-a/} 188 {/-Nia/, /-a/} 2{/-tia/} 112 {/-Ria/, /-tia/} 2{/-hia/} 33 {/-hia/, /-ia/, /-ina/} 1{/-na/} 27 {/-hia/, /-kia/} 1{/-Nia/} 19 {/-hia/, /-mia/} 1{/-ia/} 17 {/-ia/, /-ina/, /-a/} 1{/-Ria/} 16 {/-ina/, /-a/} 1{/-ina/} 13 {/-Nia/, /-ia/} 1{/-kia/} 6 {/-Nia/, /-Ria/} 1{/-tia/, /-a/} 6 {/-Nia/, /-tia/} 1{/-mia/} 4 {/-Nia/, /-tia/, /-a/} 1{/-ia/, /-a/} 3 {/-Ria/, /-ia/} 1{/-hia/, /-a/} 2 {/-tia/, /-ina/} 1{/-hia/, /-tia/} 2 {/-tia/, /-na/} 1Table 8: 464 passive patterns map to 28 output categories.Category Members Category Members{/-taNa/} 120 {/-Na/, /-taNa/} 2{/-haNa/} 35 {/-RaNa/, /-taNa/} 2{/-Na/} 21 {/-haNa/, /-aNa/} 1{/-aNa/} 20 {/-haNa/, /-kaNa/} 1{/-RaNa/} 16 {/-haNa/, /-maNa/} 1{/-kaNa/} 6 {/-Na/, /-aNa/} 1{/-maNa/} 3 {/-Na/, /-RaNa/} 1{/-haNa/, /-taNa/} 2 {/-RaNa/, /-aNa/} 1Table 9: 233 gerund-like patterns map to 16 categories.3.2 ProcedureFor the various experiments conducted, differentsubsets of the collected corpus were employed.
Ingeneral, a sub-corpus was selected and then (ran-domly) split into training and testing sets.
The sizeof these sets differed for the different experiments,since different amounts of relevant data were avail-able.
In every case, the stimuli consisted of inputvectors and their corresponding target vectors.Before training, the weights in the network wereinitialized using a random seed.
Stimuli from thetraining set were then presented to the network ran-domly without replacement, so that each stimuluswas seen once per epoch.
Training lasted for 100epochs.
The weights were then frozen before eachof the training stimuli were presented to the networkagain in order to validate the network?s performance.The validated network was then presented with thetest stimuli and its predictions were compared withthe activations of the targets.
In every experiment,43the networks were run 5 times using 5 different ran-dom seeds to initialize the weights.
I did this sothat the results would be a little more robust.
Perfor-mance was evaluated by taking the average percentcorrect over the 5 runs and variability was measuredby calculating the standard deviation of the 5 runs.Outputs were evaluated by fist rounding their acti-vations to 0 or 1, before comparing them to the targetpatterns.
It should be noted that this is a relativelyliberal measure of the network?s performance, givensuch alternatives as measuring the distance from out-put to target using a deviation < 0.1.
Nonetheless,evaluation by rounding was justified on grounds thatthe only meaningful output patterns for the networkwere the non-negative integers 0 and 1.I used chance as the null hypothesis when it wasrequired for comparison with the network?s perfor-mance, as chance represents the baseline for unpre-dictability.
The chance of guessing the output acti-vations correctly was calculated by assuming binaryactivations for the outputs (which is fair given therounding of network outputs to 0 and 1).
For 10 out-put nodes, 210 = 1024 possible guesses were pos-sible.
In such cases, the probability of guessing thecorrect output pattern for any stimulus was calcu-lated as 11024 ?
100 = 0.1%.
Except where other-wise noted, the chance of guessing the right outputpatterns for n stimuli was calculated as n1024 ?
100.In some cases, I used other calculations as com-parisons against the network?s performance.
I willintroduce these where applicable.4 Experimental results4.1 Segmental and syllabic representationsAs mentioned above, the question of input represen-tation is an empirical one.
I introduced three codingschemes in section 2.1 (a segmental one and two syl-labic ones).
In order to compare the schemes?
abil-ity to predict the passive forms (including the the-matic consonants), a sub-corpus of 464 patterns wasselected (i.e., the full set of 476 passives found inRyan?s dictionary minus the 12 loanwords).
Sincethese stimuli had already been randomly split into80%-10%-10% subsets to estimate the number ofhidden units in the network, I started by reusing thissplit.
The 10% used as a test set for the hidden unitstask were then lumped back into the training set, re-sulting in a random 90%-10% split (i.e., 418 trainingpatterns and 46 test patterns).
Each coding schemewas then applied to the same training and test sets,and the network was run as described in the methodssection.The results are summarized numerically in Table10 and graphically in Figure 3.
They suggest thateither syllabic coding scheme is better than the seg-mental one, and that the de Lacy analysis is bet-ter than the alternative syllabic coding scheme (i.e.,Coding 2 beats Coding 1).
This suggests that it isbetter to represent a long vowel followed by a shortvowel in Ma?ori as two syllables.Coding Scheme % Correct Standard deviationSegmental 90.43 2.92Syllable 1 91.74 2.83Syllable 2 93.91 1.82Table 10: Representation experiment results, rounded tothe nearest hundredth.Figure 3: Test results for different representations of thestems, 5 runs apiece; error bars show standard deviations.The results also challenge the assumption that the-matic consonants are strongly unpredictable (i.e.,governed by chance).
I note that 30 of the test pat-terns did not take a suffix with a thematic conso-nant, while 15 did.
So, of the 15 relevant test cases,the null hypothesis would have guessed 23.44% cor-rect (i.e., 1526 ?
100); I adjusted the calculation ofthe null hypothesis here to reflect the focus on just6 of the 10 output patterns (i.e., the ones with the-matic consonants).
Without adjusting the calcula-tion, the null hypothesis would have done muchworse (cf.
15210 ?
100).
By contrast, the network pre-dicts 46.67% correct (i.e., 715 ?
100), since it cor-rectly predicted 7 out of the 15 patterns.
So, thenetwork correctly predicted 23.23% more of the the-44matic consonant patterns than chance.
This suggeststhat lexicalization is not the only way to addressthematic consonants in Ma?ori.
Since the problemcan be specified in terms of active and passive verbs(rather than in terms of stems and suffixes), this alsosuggests that the Ma?ori passive need not be framedin terms of the ?morphological?
and ?phonological?analyses of Hale (1968).The model also does well predicting the passiveform of a verb in general.
Note that the null hy-pothesis would only get 4.49% of the 46 test stim-uli correct (i.e., 461024 ?
100).
Using the de Lacyanalysis, the network correctly predicted 93.91% ofthe 46 test stimuli, which is a massive difference of89.42%.
Moreover, the network also outperforms a?majority choice?
strategy, whereby all verb stemstake the most frequent output category (i.e., {/-a/}).Majority choice correctly predicts 40.52% of the464 passive patterns (i.e., 188464 ), which is 53.39% lessthan the network?s coverage.4.2 GerundsTo test beyond the passive dataset, two sets ofgerunds were considered.
The idea was to see iftraining a network on a dataset of passives wouldbe able to predict the suffix patterns of gerunds.By training the network on the entire passivedataset 5 different times, and then testing each oneon the 2 gerunds found in Ryan?s dictionary, the net-work predicted the 100% of the results correct for all5 runs.
(For 2 test items, the null hypothesis wouldhave only guessed 21024 ?
100 = 0.2% correct.
)Using the same training set, but testing the net-work on the 139 gerund-like words in the MBC, thenetwork correctly predicted an average of 90.36%correct (with a standard deviation of 0.82).
For 139test patterns, the null hypothesis would only predict13.57% correct.
In both cases, the model does no-ticeably better than chance.4.3 LoanwordsWhen new verbs enter the Ma?ori language, speakersgeneralize their knowledge about the passive end-ings to them.
How well does the network do at mod-eling this ability?
12 loanwords were flagged in thepassive dataset.
By training the network on the 464non-loanword passives and then testing it on the 12loanwords, the network got 100% correct for all 5runs.
Chance would only predict 1.17% of this testset correctly (i.e., 121024 ?
100).The network also outperforms majority choice onthis task, since majority choice for the 12 loanwordspredicts 83.33% (i.e., 1012 ).
(The most common out-put category for the 12 loanwords is {/-tia/}.
)In this case, however, there is probably a morecharitable null hypothesis against which to comparethe network?s performance.
I refer to the defaultanalysis, where verbs take /-tia/, /-ia/, or /-a/.
Onthis analysis, any stem containing more than twomorae takes /-tia/ as its default, any stem containingfewer than three morae and ending with /a/ takes/-ia/ as its default, and any other stem (i.e., one con-taining fewer than three morae and not ending with/a/) takes /-a/.
(Incidentally, one single-mora stemexists in my database; it is /ko/ ?to dig?, which takes/-ia/.
)So, how does the default analysis compare withthe network?s analysis?
Of the 12 loanwords in thepassive database, the default analysis gets 91.67%correct (i.e., 1112 ).
Again, the network gets 100%correct every time, for 5 runs.
Interestingly, allbut one of the 12 loanwords takes /-tia/, /-ia/, or/-a/.
Furthermore, the exception, /Raka-ina/ (< En-glish lock), would appear to be a systematic hole inthe default analysis, since analogous examples exist,such as /tia-ina/ (< English steer) (Paul de Lacy,personal communication).
Since both of these stemsconsist of fewer than three morae and end with /a/,the default analysis incorrectly predicts that theirpassive forms should be */Raka-ia/ and */tia-ia/, re-spectively.
In other words, while the network onlyoutperformed the default analysis by one examplefrom the dataset, that one example would appear tobe representative of a class of stems that the defaultanalysis necessarily gets wrong, but which the neu-ral network analysis could possibly get right.
How-ever, since the network needs to be run in order tosee what it actually predicts, additional work wouldbe needed to address this further.5 DiscussionThus far, the model has been evaluated on its perfor-mance.
But while a model that performs well on atask is valuable in its own right, one would also liketo understand how the model is succeeding.
Neu-45Figure 4: Hinton diagram for a typical weight matrix from input units (x-axis) to hidden units (y-axis).ral network simulations are sometimes critiqued forbeing black box solutions, where a problem can besolved but the solution cannot be understood.
There-fore, in this discussion section, I would like to beginto address the question of what properties in stemrepresentations are responsible for the prediction oftheir output categories.A few relevant sub-regularities have already beenreported in the Ma?ori literature, which are worth re-view.
Citing Moorfield (1988, p. 66), Harlow re-ports that /-ina/ only occurs after words ending with/a/, while /-mia/ only occurs after words endingwith /o/ and /u/ (i.e., the [+round] vowels); hisexamples, with the stem-final vowels underlined,are /hua-ina/ ?be named?, /aRoha-ina/ ?be loved?,/Faka-NaRo-mia/ ?be made to disappear?, and /inu-mia/ ?be drunk?
(Harlow, 2007, p. 117).
Althoughthese observations provide necessary but not suffi-cient conditions for inferring a passive suffix froma verb stem, they exemplify the type of pattern thatone might like to find.
The problem is to find betterpatterns in the verb stems.For ideas of what to investigate, we might lookinside one of the trained networks.
Figure 4 illus-trates the weights from input units to hidden unitsin a network trained on the Ma?ori passive data usingthe de Lacy coding scheme (from section 4.1).
No-tice the dark vertical bands around inputs 176, 141,and 113 (there are fainter bands around input 78 and43, and faint and narrow bands around input 190and 155).
These bands represent stronger weights(both positive and negative) between the two layersin the network.
In order to understand the network?sperformance, we might ask what these bands rep-resent.
Given that the syllabic coding scheme or-ganizes the segments into vowels and consonants ina similar pattern, one hypothesis would be that thevertical bands represent vowels in the input; a com-plementary hypothesis would hold that they repre-sent consonants in the input.
While this is a rathercrude distinction to make, it begins to narrow downthe hypothesis space.To test such hypotheses, we may use ?degraded?inputs.
For example, to test one hypothesis, onemight replace all consonants in the input represen-tations with null phonemes; to test the other hypoth-esis, one might replace all vowels in the input repre-sentations with null phonemes.
An example of thesedegraded input representations is given in Table 11for the word /FeRa/ ?to spread?.In a preliminary study (running the network justonce), I found that the model with vowel-only inputoutperformed the model with consonant-only inputby a slight margin.
Further investigation is surelyneeded.
But the methodological use of degraded in-puts provides a way to probe which parts of theserepresentations contribute most to the model?s per-formance.Additional studies might use degraded inputs withonly the final syllables represented compared with46Syll SyllC V V C V VAll segments F e R aNo consonants e aNo vowels F RTable 11: Three representations of /FeRa/ ?to spread?.The top one is an uncorrupted input using the de Lacysyllabic coding.
The bottom two are degraded in differ-ent ways: one has no consonants, the other has no vowels.ones in which only the penultimate or antipenul-timate syllables are represented; they might evennarrow down which phonetic features predict whichpassive and gerundial categories.6 ConclusionThe work described here is clearly preliminary withrespect to the problem of predicting passives andgerunds in Ma?ori.
But the experimental results aresuggestive, especially as they challenge the long-held assumption that thematic consonants cannot bepredicted.
This research has implications for fu-ture investigations of allomorphy in Ma?ori and otherPolynesian languages, since Polynesian allomorphyhas never before been explored using phonotacticprobabilities (at least to the best of my knowledge).In general, a computational approach makes itmuch easier to run complex statistical analyses overlarge datasets (compared with manual analyses us-ing paper and pen).
The success of utilizing statisticsin this study exemplify the benefits of using compu-tational methods in linguistics.AcknowledgmentsFor various feedback, I am grateful to acknowledgeJohn Coleman, Julien Mayor, Sharon Goldwater,Paul de Lacy, Doug Ball, Mary Boyce, and threeanonymous reviewers.
This research was supportedby a Lamaku?
Scholarship.
All imperfections are myown.ReferencesWinifred A. Bauer.
1993.
Maori.
Routledge, Londonand New York.Bruce Biggs.
1961.
The structure of New ZealandMaaori.
Anthropological Linguistics, 3:1?53.Juliette Blevins.
1994.
A phonological and morphologi-cal reanalysis of the Maori passive.
Te Reo, 37:29?53.Mary Teresa Boyce.
2006.
A Corpus of Modern SpokenMa?ori.
Ph.D. thesis, Victoria University of Welling-ton.Walter Daelemans and Antal van den Bosch.
2005.Memory-Based Language Processing.
CambridgeUniversity Press, Cambridge.Paul de Lacy.
2004.
Maximal words and the Maori pas-sive.
In John McCarthy, editor, Optimality Theory inPhonology: A Reader, pages 495?512.
Blackwell, Ox-ford.Kenneth Hale.
1968. Review of Hohepa (1967).
Journalof the Polynesian Society, 77:83?99.Kenneth Hale.
1973.
Deep-surface canonical disparitiesin relation to analysis and change: An Australian ex-ample.
In Thomas Sebeok, editor, Current Trends inLinguistics 11, pages 401?458.
The Hague, Mouton.Kenneth Hale.
1991.
Remarks on G. Sanders?
?Level-ling in the history of Polynesian passive formations.Journal of the Polynesian Society, 100:99?101.Ray Harlow.
1991.
Consonant dissimilation in Maori.In Currents in Pacific Linguistics: Papers in Aus-tronesian Languages and Ethnolinguistics in honourof George W. Grace, pages 117?128.
Australian Na-tional Universiy, Canberra.Ray Harlow.
2001.
A Ma?ori Reference Grammar.
Pear-son Education, Auckland.Ray Harlow.
2007.
Ma?ori: A Linguistic Introduction.Cambridge University Press, Cambridge.Patrick W. Hohepa.
1967.
A Profile Generative Gram-mar of Maori.
Indiana University Press, Bloomington,Indiana.J.
Kaye.
1975.
A functional explanation for rule orderingin phonology.
In R. Grossman, L.J.
San, and T. Vance,editors, Papers from the Parasession on Functional-ism.
Chicago Linguistics Society, Chicago.Michael Kenstowicz and Charles Kisseberth.
1979.
Gen-erative Phonology: Description and Theory.
Aca-demic Press, San Diego.Nicholas Kibre.
1998.
Formal property inheritance andconsonant/zero alternations in Maori verbs.
RutgersOptimality Archive 285.Paul Kiparsky.
1971.
Historical linguistics.
In WilliamDingwall, editor, A Survey of Linguistic Science, pages577?649.
University of Maryland Press, College Park,Maryland.47John J. McCarthy.
1981.
The role of the evaluation met-ric in the acquisition of morphology.
In C.L.
Bakerand John J. McCarthy, editors, The Logical Problemof Language Acquisition, pages 218?248.
MIT Press,Cambridge, Massachusetts.John C. Moorfield.
1988.
Whanake I Te Ka?kano.
Long-man Paul, Auckland.Kim Plunkett and Jeffrey L. Elman.
1997.
Exercises inRethinking Innateness: A Handbook for ConnectionistSimulations.
MIT Press, Cambridge, Massachusetts.Kim Plunkett and Virginia Marchman.
1991.
U-shapedlearning and frequency effects in a multi-layered per-ceptron: Implications for child language acquisition.Cognition, 38:43?102.David E. Rumelhart and James L. McClelland.
1987.Learning the past tenses of English verbs: Implicitrules or parallel distributed processing.
In BrianMacWhinney, editor, Mechanisms of Language Acqui-sition, pages 194?248.
Erlbaum, Mahwah, New Jersey.P.M.
Ryan.
1989.
The Revised Dictionary of ModernMa?ori.
Heinemann Education, Auckland, third edi-tion.Gerald Sanders.
1990.
On the analysis and implicationsof Maori verb alternations.
Lingua, 80:149?196.G.
Sanders.
1991.
Levelling and reanalysis in the his-tory of Polynesian passive formations.
Journal of thePolynesian Society, 100:71?91.Paul J. Werbos.
1974.
Beyond Regression: New Tools forPrediction and Analysis in the Behavioral Sciences.Ph.D.
thesis, Harvard University.H.W.
Williams.
1971.
A Dictionary of the Maori Lan-guage.
Government Printer, Wellington, seventh edi-tion.
Originally published in 1844.48
