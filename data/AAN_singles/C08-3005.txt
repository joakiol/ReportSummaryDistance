Coling 2008: Companion volume ?
Posters and Demonstrations, pages 161?164Manchester, August 2008?Build Your Own?
Spoken Dialogue Systems:Automatically Generating ISU Dialogue Systems from Business UserResourcesOliver Lemon, Xingkun Liu, and Helen HastieSchool of InformaticsUniversity of EdinburghInformatics Forum10 Crichton StreetEdinburgh, EH8 9AB{olemon,xliu4,hhastie}@inf.ed.ac.ukAbstractBuilding effective spoken dialogue sys-tems (SDS) is currently a complex taskrequiring expert knowledge.
Our toolsgive control of SDS application develop-ment to non-experts, who need only usea Graphical User Interface or GUI to de-velop state-of-the-art ?Information StateUpdate?
(ISU) dialogue systems.
Behindthe GUI is a set of Advanced DialogueTools (ADT) that generate complete SDSbased on Business User Resources.
Theseresources include a database and a Pro-cess Model that captures the structure ofan application, for example, banking orrestaurant information.
Also generatedare speech recognition Language Modelsand grammars for robust interpretation ofspontaneous speech.
We will demonstratehow our simple GUI allows developers toeasily and quickly create and modify SDSwithout the need for expensive speech ap-plication service providers.
This demon-stration shows the interface, the ADT com-ponents, and discusses some of the re-search issues involved.
We also show anexample application built with the tools: atourist information system running on anultra-mobile PC.1 IntroductionAs automated call centres are becoming more andmore commonplace, new challenges are emerg-ing such as having to rely on expensive servicec?
2008.
Licensed under the Creative CommonsAttribution-Noncommercial-Share Alike 3.0 Unported li-cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).Some rights reserved.providers to build systems, the inability to quicklyand easily modify live systems, and the time andcost needed to create new SDS applications.
Thispaper describes a solution to these problems usingour Advanced Dialogue Tools (ADT).
This pro-totype system allows developers to take alreadyestablished business user resources such as Busi-ness Process Models (BPM) and databases, anduse them to automatically generate spoken dia-logue systems.
Simple customisations can thenbe made through the easy-to-use ADT interface orGUI, which is example-driven.
This radically newway of creating spoken dialogue systems will putcontrol into the hands of the business user who isfamiliar with customer needs and business goals,thus improving usability and making spoken dia-logue systems more widely and rapidly available.Currently, VoiceXML is widely used for suchtasks.
However, VoiceXML applications are dif-ficult to build and maintain, because develop-ers must anticipate and represent every possi-ble dialogue path in the finite-state VoiceXMLmodel.
ADT will generate VoiceXML dynami-cally, but the easy-to-use interface allows devel-opers to select, deploy, and monitor different ad-vanced dialogue strategies without needing to codeVoiceXML directly.
We apply the ?InformationState Update?
(ISU) approach (Lemon, 2004) thatenables more robust, flexible and natural conver-sations than VoiceXML.
ISU uses a more conciseand maintainable representation of dialogue flow,based on rules operating over dialogue contexts,which can generalise to unforeseen states.2 The ADT ArchitectureFigure 1 shows the ADT architecture whereby themain algorithm takes business user resources anddatabases as input and uses these to automatically161generate the spoken dialogue system.
Figure 2shows part of one such resource, namely a BPMfor hotel bookings.
First the caller will hear anintroduction, then they will be asked what pricerange they want, and then whether they want a ho-tel in the centre of town or not.
Advantages of us-ing BPMs include the fact that graphical interfacesand authoring environments are widely availablefor them, for example: Eclipse, IBM Websphere-Process Server, BEA WeblogicWorkshop etc.. Inaddition, Business User Resources can contain alot of additional information as well as call flowsincluding context, multi-media, and multiple cus-tomer interactions.Figure 1: The ADT ArchitectureFigure 2: Part of an example Business ProcessModel for searching for HotelsThe resulting spoken dialogue system deploysthe following main modules:?
Speech Recogniser module, e.g.
ATK/HTK(Young, 2007; Young, 1995) or Nuance (Nu-ance, 2002)?
Spoken Language Understanding module,e.g.
Grammatical Framework (GF) parser(Ranta, 2004)?
BPM and Database modules?
Speech synthesiser e.g.
Festival (Taylor et al,1998) or Cereproc (Aylett and Pidcock, 2007)2.1 Generic Dialogue ModellingSophisticated research systems have been devel-oped only for specific applications and cannot beeasily transferred to another, even very similar taskor domain.
The problem of components being do-main specific is especially prevalent in the corearea of dialogue management.
For example MIT?sPegasus and Mercury systems (Seneff, 2002) havedialogue managers (DM) that use approximately350 domain-specific hand-coded rules each.
Thesheer amount of labour required to construct sys-tems prevents them from being more widely andrapidly deployed.
Our solution uses BPMs andrelated authoring tools to specify domain-specificdialogue interactions which are combined with adomain-general dialogue manager.
Specifically,the DM consults the BPM to determine what task-based steps to take next, such as asking for a cin-ema name.
General aspects of dialogue, such asconfirmation and clarification strategies, are han-dled by the domain-general DM.
Values for con-straints on transitions and branching in the BPM,for example ?present insurance option if the user isbusiness-class?, are compiled into domain-specificparts of the DM?s update rules.
XML format isused for BPMs, and they are compiled into finitestate machines consulted by the spoken dialoguesystem through the BPM module.
The domain-general DM was mostly abstracted from the TALKsystem (Lemon et al, 2006).2.2 Compiling Grammars for Business UserResources and DatabasesFor Spoken Language Understanding, ADT cur-rently uses Grammatical Framework (GF) (Ranta,2004) which is a language for writing multilingualgrammars, on top of which various applicationssuch as machine translation and human-machineinteraction have been built.
A GF grammar notonly defines syntactic well-formedness, but alsosemantic content.Using ADT, system developers do not have towrite a single line of GF grammar code.
The sys-162tem compiles all database entries and their proper-ties into the appropriate ?slot-filling?
parts of theGF grammar for each specific BPM.For example, a generated GF rule is:Bpm generalTypeRule 4:town info hotels name->Utt=>{ s = np.s}This rule was generated because ?name?
is adatabase field for the subtask hotels in the?town info?
BPM.
It specifies that all hotel namesare valid utterances.A core GF grammar has been developed to coverbasic information-seeking interactions.
This iscombined with a domain-specific grammar whichis automatically generated from the BPM, databaseand the example utterances provided by the devel-oper in the GUI.
Finally, GF is a robust parser ?
itskips all disfluencies and unknown words to pro-duce an interpretation of the user input if one ex-ists.2.3 Speech Recognition and Text To SpeechThe grammars for Spoken Language Understand-ing generated by ADT are also compiled togrammar-based language models (LM) for speechrecognition.
ADT is plug-and-play and adheres toindustry standards such as GSML, GrXML.
Thisallows for greater flexibility since the applicationdeveloper is not tied to one recogniser or TTS en-gine.
For this demonstration, the speech recog-niser is ATK (Young, 2007; Young, 1995) andthe speech synthesiser is Cereproc (Aylett and Pid-cock, 2007).
Future work will involve automati-cally generating context sensitive language models(Lemon and Gruenstein, 2004).2.4 ADT GUIAs mentioned above, the prototype ADT GUI canbe used to define system prompts and add likelyuser responses to the grammar.
Figure 3 shows thedeveloper associating ?spotter?
phrases with sub-tasks in the BPM.
Here the developer is associatingthe phrases ?hotels, hotel, stay, room, night, sleep?and ?rooms?
with the hotels task.
This means that,for example, if the user says ?I need a place tostay?, the hotel-booking BPM will be triggered.Note that multi-word phrases may also be defined.The defined spotters are automatically compiledinto the GF grammar for parsing and speech recog-nition.
By default all the lexical entries for answer-types for the subtasks will already be present asFigure 3: Example: using the ADT GUI to define?spotter?
phrases for different BPM subtasksspotter phrases.
ADT also checks for possible am-biguities, for example whether ?pizza?
is a spot-ter for both cuisine type for a restaurant task andfood type for a shopping task, and it uses clarifica-tion sub-dialogues to resolve them at runtime.Figure 4 shows the developer?s overview of thesubtasks of a BPM, in this case hotel information.The developer can navigate this representation andedit it to define prompts and manipulate the asso-ciated databases.Figure 4: Sub-dialogue structure generated fromthe Hotel booking BPMFigure 5 shows the developer specifying therequired linguistic information to automate theask price subtask of the hotels BPM.
Here the de-veloper specifies the system prompt for the infor-mation ?Do you want something cheap or expen-sive??
; a phrase for implicit confirmation of pro-vided values ?a [X] hotel?, where [X] is the seman-tics of the speech recognition hypothesis for theuser input; and a clarifying phrase for this subtask163Figure 5: Example: using ADT to define prompts,answer sets, and database mappings for theask price subtask of the BPM in Figure 4?Do you mean the hotel price??
for use when dis-ambiguating between two or more tasks.
The de-veloper also specifies here the answer type that willresolve the system prompt.
There are many pre-defined answer-types extracted from the databasesassociated with the BPM, and the developer canselect and/or edit these.
Optionally, they can giveadditional example phrases that users might sayto answer the prompt, and these are automaticallyadded to the GF grammar.2.5 UsabilitySeveral demonstration systems have been built us-ing ADT with an average development time of un-der an hour.
However, our planned evaluation willtest the ability of novice users, with some knowl-edge of BPMs and databases, to iteratively developtheir own ISU dialogue systems.3 SummaryThis paper describes the Advanced Dialogue Toolsfor creating Information State Update based dia-logue systems automatically from Business UserResources such as BPMs and databases.
The toolsinclude automatic generation of grammars for ro-bust interpretation of spontaneous speech, and usesthe application databases and BPMs to generatelexical entries and grammar rules for speech recog-nition language modelling.
We also demonstratean easy-to-use prototype interface that allows theuser to easily and quickly modify aspects of thedialogue, thus eliminating the need for third partyservice providers.
This paper describes ADT, itsmain components, and some of the research issuesinvolved in its development.4 AcknowledgementThis project is funded by a Scottish EnterpriseProof of Concept Grant (project number 8-ELM-004).ReferencesAylett, Matthew P. and Christopher J. Pidcock.
2007.The cerevoice characterful speech synthesiser sdk.In AISB, pages 174?8.Lemon, Oliver and Alexander Gruenstein.
2004.
Mul-tithreaded context for robust conversational inter-faces: context-sensitive speech recognition and in-terpretation of corrective fragments.
ACM Trans-actions on Computer-Human Interaction (ACMTOCHI), 11(3):241?
267.Lemon, Oliver, Kallirroi Georgila, James Henderson,and Matthew Stuttle.
2006.
An ISU dialogue systemexhibiting reinforcement learning of dialogue poli-cies: generic slot-filling in the TALK in-car system.In Proceedings of EACL, pages 119?122.Lemon, Oliver.
2004.
Context-sensitive speech recog-nition in Information-State Update dialogue systems:results for the grammar switching approach.
In Pro-ceedings of the 8th Workshop on the Semantics andPragmatics of Dialogue, CATALOG?04, pages 49?55.Nuance, 2002. http://www.nuance.com.
As of 1 Feb2002.Ranta, A.
2004.
Grammatical framework.
a type-theoretical grammar formalism.
Journal of Func-tional Programming, 14(2):145?189.Seneff, Stephanie.
2002.
Response Planning and Gen-eration in the Mercury Flight Reservation System.Computer Speech and Language, 16.Taylor, P., A.
Black, and R. Caley.
1998.
The architec-ture of the the Festival speech synthesis system.
InThird International Workshop on Speech Synthesis,Sydney, Australia.Young, Steve.
1995.
Large vocabulary continuousspeech recognition: A review.
In Proceedings ofthe IEEE Workshop on Automatic Speech Recogni-tion and Understanding, pages 3?28.Young, Steve.
2007.
ATK: An Application Toolkitfor HTK, Version 1.6.
Technical report, CambridgeUniversity Engineering Department.164
