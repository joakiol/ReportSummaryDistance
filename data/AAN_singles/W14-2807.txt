Proceedings of the 2014 Joint Meeting of SIGMORPHON and SIGFSM, pages 55?63,Baltimore, Maryland USA, June 27 2014.c?2014 Association for Computational LinguisticsRules, Analogy, and Social Factors codetermine past-tense formationpatterns in EnglishP?eter R?aczNew Zealand Institute ofLanguage Brain and Behaviour,University of Canterburypeter.racz@Clay BecknerNew Zealand Institute ofLanguage Brain and Behaviour,University of Canterburyclayton.beckner@canterbury.ac.nzJennifer B. HayNew Zealand Institute ofLanguage Brain and Behaviour,University of Canterburyjen.hay@Janet B. PierrehumbertDepartment of Linguistics / NICONorthwestern University.New Zealand Institute ofLanguage Brain and Behaviour,University of Canterburyjbp@northwestern.eduAbstractWe investigate past-tense formation pref-erences for five irregular English verbclasses.
We gathered data on a large scaleusing a nonce probe study implemented onAmazon Mechanical Turk.
We comparea Minimal Generalization Learner (whichinfers stochastic rules) with a General-ized Context Model (which evaluates newitems via analogy with existing items) asmodels of participant choices.
Overall,the GCM is a better predictor, but thethe MGL provides some additional pre-dictive power.
Because variation acrossspeakers is greater than variation acrossitems, we also explore individual-levelfactors as predictors.
Females exhibitedsignificantly more categorical choices thanmales, a finding that can be related to re-sults in sociolinguistics.1 IntroductionIn this report, we present a psycholinguistic studyof English past tense categories, using a nonce-probe experiment implemented on Amazon Me-chanical Turk.
The English past tense has beena testing-ground for a wide range of theoriesand predictions in psycholinguistics, including theprocesses of acquisition, the nature of lexical rep-resentation, and the representation of inflectionalpatterns as rules or as generalizations over spe-cific items (Bybee and Slobin, 1982a; Rumelhartand McClelland, 1985; McClelland and Patterson,2002; Albright and Hayes, 2003).The present study investigates the factors in-fluencing patterns of preferred past tense formsfor particular verb classes.
English past tensesare not merely a memorized list, but rather, verbcategories can shrink, or expand to include newitems.
In everyday speech, there is evidence ofongoing influences from multiple verb classes, asverbs exhibit variation and slowly shift in their us-age (dived vs. dove, sneaked vs. snuck), (Haber,1976; Bybee and Moder, 1983).Given that speakers can adapt their verbal cate-gories to new situations, what is the best represen-tation for the relevant morphological generaliza-tions?
In analogical models, the focus is on exist-ing stored items in memory.
The acceptability ofa candidate past tense formation pattern for a par-ticular candidate item is determined by patterns ofsimilarity to stored items.
Morphological innova-tion and productivity arises from generalizationsover existing forms in the lexicon.
To account for aspeech error such as glew as the past tense of glow(Bybee and Slobin, 1982a), an analogical explana-tion would highlight the close similarity betweenglow and the present tense forms blow, throw,know, which provide the basis for an analogy withthe past forms blew, threw, knew.
Of particularinterest is the Generalized Context Model (GCM)(Nosofsky, 1990; Albright and Hayes, 2003), ananalogical model which assesses a category?s suit-ability to a target item on the basis of feature-based similarities summed over category items,in addition to the category?s size.
It has alreadybeen successfully applied to model regular and ir-regular patterns in Arabic morphology (Dawdy-Hesterberg and Pierrehumbert, 2014).Rule-based approaches propose more abstractrepresentations of generalizations.
Originally pro-posed to handle broadly applicable default pat-terns, (such as ?add -ed to express the pasttense?
), rule-based approaches have recently beenextended to incorporate multiple stochastic rules.Albright and Hayes (2003) assign scores to mor-phological rules by training a Minimal General-ization Learner (MGL) over a dataset, an algo-rithm that iterates over pairs of words in the lexi-con, hypothesizing generalizations conservativelyon the basis of any phonological features that are55shared across the words.
A rule is scored accord-ing to how many items it applies to in the lexi-con, weighted against cases in which the inferredphonological context is present but the rule failsto apply.
The resulting system consists of a cat-alog of weighted natural class-based generaliza-tions which compete with one another, and whichare more or less likely to apply in various phono-logical contexts (for regular as well as irregularverbs).
Albright and Hayes argue that the MGLoutperforms the GCM in predicting participant be-havior in a nonce-verb production task they con-ducted.2 ExperimentWe collected a large amount of data on irregularpast tense formation in English with a nonce probetest, a classic method for exploring the produc-tivity of inflectional morphology (Berko, 1958).Earlier studies used 30 or fewer participants percondition (Bybee and Slobin, 1982a; Albright andHayes, 2003).
By using Amazon MechanicalTurk, a burgeoning forum for psycholinguistic re-search (Munro et al., 2010), we were able to re-cruit a large number of participants and explorethe role of individual-level factors in the choiceof morphological patterns.
Moreover, we testedparticipant preferences across a large dataset (316nonce verbs) based on broad phonological sam-pling within verb classes, allowing for repeatedtrials across similar items for each participant.Participants in our online study were presentedwith a forced choice task in which they had to pickeither the regular or the irregular past tense formfor an English nonce verb, presented in a carriersentence.
This was followed by a vocabulary taskin which participants had to rate the familiarity ofEnglish nouns.2.1 StimuliWe set up five categories of irregular past tenseformation based on phonological form of thepresent tense verb, and its corresponding candi-date tense past forms.
Each category exhibitsphonological variability within the category, whilealso allowing for a specific phonological descrip-tion.
We avoided ?miscellaneous?
verb classes, aswell as wholly idiosyncratic patterns (such as go?went).
Moreover, we are particularly interestedin morphological classes which are known to dis-play some indeterminacy (Haber, 1976), i.e., thoseclasses which display some regular/irregular vari-ation (dived vs. dove), due to the ready availabil-ity of multiple generalizations.
The literature con-tains various taxonomies of English irregular verbclasses (Bybee and Slobin, 1982a), but our currentclassification mostly represents a subset of the de-tailed verb classes outlined by Moder (1992).The five categories of interest are as follows.?
SANG.
Verbs that form the past tense with avowel change from [I] to [?]
(e.g.
sing?sang,sink?sank, swim?swam).?
BURNT.
Verbs that form the past tense byadding a [t], with no change in the stem vowel(e.g.
burn?burnt, spill?spilt, learn?learnt).These items constitute a distinct set from reg-ular English pasts such as boss?bossed whichare articulated with a [t] allomorph, insofar asthe burnt verb bases actually end in a voicedconsonant but are nonetheless affixed with avoiceless stop.?
KEPT.
Verbs that form the past tense byadding a final [t] and changing the stemvowel from [i] to [E] (e.g.
keep?kept, mean?meant, feel?felt ).?
DROVE.
Verbs that form the past tense witha vowel change from [aI] or [i] to [oU] (e.g.drive?drove, weave?wove, ride?rode).?
CUT.
No-change past tense verbs, that is,verbs the past tense form of which is identi-cal to their present tense form.
(e.g.
cut?cut,cost?cost, hurt?hurt).
Verb bases in this classend in sounds that are already associated withthe English past tense ([t] or [d]) (Bybeeand Slobin, 1982a), although the nonce verbbases in the present study all end in [t].We generated nonce verb forms by combiningthe category-specific restrictions spelled out aboveon the stem with a set of syllable onsets that oc-cur in English.
Using CELEX (Baayen et al.,1993), we then filtered the orthographic and pho-netic transcriptions of the nonce stems, as well asthe resulting past tense forms, to exclude real En-glish words.
Two native speakers checked the finallist to remove additional real words that were notfiltered out via the CELEX database (e.g., slangand informal terms).
All our verb forms weremonosyllabic?
as are almost all English irregularverbs in general.
The method used to generate the56stimuli means that some nonce forms looked moresimilar to real English verbs than others.
This waywe can tell whether similarities to a single formwill strongly influence people?s behavior in thecase where the nonce form is highly similar to asingle real form.The sang and cut categories consist of 60forms.
The burnt category has 40, drove has 76,and kept has 80.
The total number of nonce verbsis 316.2.2 SetupThe experiment consisted of a forced choice task,in which participants had to pick a regular or ir-regular past tense form for each verb.
Verbs werepresented one at a time, visually, in a carrier sen-tence of the form ?I really like to VERB.
Yester-day, I .?.
Two buttons were presented under thecarrier sentence, one with the regular past tense,adding -ed, and one with the irregular past tense.The irregular past tense was always the dominantpattern for the category.
(So, for cut, it was identi-cal to the present tense, etc.)
The order of the twobuttons was randomized for each verb.
Each verbwas presented once and the order of verbs was ran-domized for each participant.The experiment was appended by a word fa-miliarity rating task.
The rating task was basedon Frisch and Brea-Spahn (2010).
It consisted of50 nouns of varying familiarity, as well as 10 ex-tremely common nouns and 10 nonce words.
The70 words were presented in a random order.
Theparticipant had to select, on a scale of 1-5, howfamiliar the given word was.
Incorrect answers tothe extremely common nouns and the nonce wordswere used as an exclusion criterion.
Answers forthe other items were used as an index of vocabu-lary level, which is predicted to affect morpholog-ical choices in both the GCM and MGL models.2.3 Participants111 people took part in the experiment on AmazonMechanical Turk during the course of two days.51 were women, 60 were men, and 1 did not spec-ify.
The age range of the participants was 20-65,and the mean age was 34.
All participants werenative speakers of American English.
Participantswere paid three dollars.
We excluded ten partici-pants from the analysis because they failed to dif-ferentiate familiar from unfamiliar words in thevocabulary test.Category Experiment Nonce Examplesdrove 0.52 skride: skrode, skridedsang 0.58 sking: skang, skingedkept 0.59 skeep: skept, skeepedburnt 0.67 skurn: skurnt, skurnedcut 0.83 skast: skast, skastedTable 1: Categories and mean regularization rat-ings.2.4 ResultsThe nonce verb categories have different rates ofregular vs. irregular usage, as can be seen in Ta-ble 1.
The Experiment column shows the meanregularization rates of the categories in our exper-iment.
The drove class was regularized the leastoften, and the cut class the most often, with a con-siderable difference between the two.The trends across verb classes are similar tothose of Moder?s (1992) nonce experiment.
Notein particular the high regularization rate (83%) ofthe no-change class of verbs (cut).
A search ofCELEX indicates that no-change [t]-final verbsare quite widespread in English, represented bymore than 30 types.
Yet based on nonce responses,the English no-change pattern is not very prone tobeing applied to novel items.
This finding matchesobservations by Bybee (1982b) that the no-changeverb class has been on the decline in English, asevident from increasing regularization.
One note-worthy feature of the cut-type verbs is that thephonological shape of the base is a quite unreliableindicator of verb class.
That is to say, there aremany [t]- final verb stems which typically take theregular -ed suffix (e.g., gritted, salted, blasted, andthese provide counterexamples to the no-changepattern (cf.
Moder (1992) on cue validity).We fit a simple stepwise logistic mixed-effectsregression model to the results with a maximalrandom effects structure, using regularization ofindividual verb form (yes or no) as an outcomevariable and category as predictor.
This modelconfirms the general finding that there is signif-icant variation across the verb classes.
(Signifi-cance values reported are based on difference withthe sang class.)
The cut class shows the highestrate of regularization (p<0.001), followed by theburnt class (p<0.01).
It is followed by the sangand kept classes (these two do not differ signifi-cantly).
The drove class shows the lowest rate ofregularization (p<0.01).57Participant gender, age, and vocabulary size arenot significant predictors of regularization in thesimple logistic mixed effects model.
However anexamination of the data (Figure 1) reveals that foreach verb class, variation across subjects is consid-erably greater than variation across items.
This ob-servation suggests that individual traits may playa role in morphological choices in a way that thesimple model fails to capture.
We will returnto this issue after presenting the GCM and MGLmodel fits, and will find in the end that gender doesaffect response patterns.lburnt cut drove kept sang0.40.60.8categorymeanrateofregularization itemslburnt cut drove kept sang0.00.20.40.60.81.0categorymeanrateofregularizationsubjectsFigure 1: Across-item variation in regularizationrates across category (above).
Across-subject vari-ation in regularization rates across category (be-low).3 Algorithmic Learning ModelsWe now turn our attention from the baseline ef-fects of category variables, to investigate the pre-dictions of particular algorithmic learning modelsthat provide alternate representations for general-izations on the basis of similarity.
Our analyses fo-cus on the predictions of the Minimal Generaliza-tion Learner and the Generalized Context Model(Albright and Hayes, 2003; Nosofsky, 1990).3.1 The two modelsThe Minimal Generalization Learner (MGL) (Al-bright and Hayes, 2002; Albright and Hayes,2003) is an algorithm for inferring stochasticmorphophonological generalizations over a set oftraining items (e.g., paired present and past tenseforms).
For each pair of items in the lexicon, thelearner maximally aligns wordforms and analyzesshared phonetic features, thereby merging word-specific rules (ring/rang and stink/stank) into rulesthat express the most general applicable environ-ment: [I]?
[?]
/ [+coronal, + cont] [N].Each rule inferred in this way is then fur-ther generalized on the basis of more compar-isons; for instance, taking note of swim/swam ex-pands the [I] ?
[?]
rule to specify that it oc-curs before all [+nasal] consonants.
The algorithmthus infers a set of natural-class based generaliza-tions, which are weighted by comparing the num-ber of hits for the past tense pattern (ring/rang,drink/drank, sing/sang, stink/stank, swim/swam,etc.)
divided by the number of cases in which thealternation fails to apply although it could apply(thus tallying exceptions such as think and blink).This appproach favors generalizations that covermany cases, but penalizes those that are too broadbecause their phonetic environments encompassmany exceptions.
The MGL reliability metric isfurther adjusted to a confidence score, in whichgeneralizations that apply to a smaller number ofword types are penalized.Note that the MGL algorithm automaticallygroups together items on the basis of sharedphonological properties; thus, monosyllabic verbsare most likely to form strong generalizations withother monosyllabic verbs.
Attempts to mergediverse wordforms under a single generalizationwould be more likely to incur penalties (i.e., ex-ceptions).
This feature of the MGL is impor-tant for comparing with the methods of the GCM(see below).
Both algorithms allow for category-58specific similarities to play a role.The Minimal Generalization Learner is imple-mented here from materials made available by Al-bright and Hayes (2003), including their Segmen-tal Similarity Calculator based on Frisch et al.(2004).
The MGL is trained on regular and irreg-ular English verbs with a minimum frequency cut-off of 10 in COBUILD (Baayen et al., 1993), andexcluding prefixed verb forms, thus encompassing4253 past/present verb transcriptions.
The MGL isimplemented here with its default settings, whichincludes a lower 75% confidence interval for pur-poses of adjusting the reliability score.The Generalized Context Model (GCM) is aninstance-based model of categorization.
To as-sign category membership to a novel instance, itfirst calculates its similarity to instances in pre-existing categories.
Then, it selects the categorywith members that are most similar to the novelinstance (Nosofsky, 1990).
Our implementationof the GCM has three notable aspects to it.First, we used the GCM to categorize our nonceverb stimuli, basing the categories on real Englishverb types extracted from CELEX (as with theMGL).
Second, we used the same segmental sim-ilarity calculator developed and used by Albrightand Hayes and used by the Minimal Generaliza-tion Learner to calculate the similarity of phoneti-cally transcribed word forms to each other, so thatwe could take the phonetic similarity of speechsounds into account instead of calculating simi-larity between word forms based on edit distancealone.
We did not weight parts of the word formsdifferently, because there is evidence that althoughpast tense formation in English is predominantlydriven by similarities in word endings, onsets alsoplay a role.
(cf.
the predominance of s+stop on-sets in irregular verbs forming the past tense witha vowel change, e.g.
sing, sink, etc.)
(Bybee andModer, 1983).Third, our implementation of the GCM re-flected the structure of the task.
Recall from Sec-tion 2 that participants were presented with thestems of the nonce verbs in a sequence and had topick either a regular or an irregular past tense formfor them.
The irregular past tense form was pre-determined by category, so that, for a given verb,the participants could only choose between theregular past tense form or the irregular past tenseform we assigned to the verb.
(So, for instance,for spling, they could choose either splinged orsplang, but not splung or splingt, etc.)
For a givencategory (such as sang verbs), the GCM had achoice between two sets.
The irregular set con-sisted of verb types in CELEX that form their pasttense according to the pattern captured by the cat-egory (such as an [I]?[?]
alternation).
The regularset consisted of verb types that have a stem thatmatches the category (such as ?monosyllabic andstem vowel [I]?)
but have a regular past tense.
Themodel calculated the similarity of a given nonceverb to these two sets (depending on its category).In this paper, we report on category weights as-signed to the regular category, which are compa-rable with both the results of the Minimal Gener-alization Learner and the rate of regularization inour experiment.
We only used monosyllabic verbsin identifying relevant matches, for regular as wellas irregular items.Values reported here were generated with nofrequency cutoff.
Alternate runs with the fre-quency threshold enforced produce no change inthe model.
The model is run with the default pa-rameter settings of s = 0.3, p = 1 with respectto calculating the weighted similarities betweenitems.
When p is set to 1, as here, the similar-ity function is exponential, rather than Gaussian.The weighting parameter s controls the tradeoff inthe relative importance of the size of the verb cat-egory (the ?gang size?)
vs. the amount of similar-ity (measured via edit distance between phonolog-ical forms) (Nosofsky, 1990; Nakisa et al., 2001;Albright and Hayes, 2003; Dawdy-Hesterberg andPierrehumbert, 2014).Figure 2 shows three plots.
The first one de-picts the relationship between the predictions ofthe GCM (regular category weight) and experi-mental ratings (mean participant regularization)for individual verb types used in the experiment.The Spearman rank correlation is highly signifi-cant (rho = 0.497, p < 0.001).
The second onedepicts the relationship between the MGL modelpredictions (reliability rating of the regular form)and mean participant regularization in the exper-iment.
The Spearman rank correlation betweenthese variables is highly significant (rho = 0.393,p < 0.001).
The predictions of the two models arez-scored to allow for comparability.
The third plotshows the relationship between the predictions ofthe GCM and the MGL for individual verb typesin the experiment.
The Spearman rank correla-tion between these variables is highly significant59CATEGORY GCM MGLSANG 0.65 0.55CUT 0.18 -0.19DROVE 0.37 0.64KEPT 0.52 0.18BURNT 0.48 0.24ALL 0.5 0.39Table 2: Correlations table: Spearman?s rank cor-relations between mean regularization in the ex-periment and the predictions of the two models(rho = 0.347, p < 0.001), but the correlation isfar from perfect.
Comparing the overall correla-tions and patterns in Figure 2, it appears that theGCM is doing a better job of predicting the varia-tion across items than the MGL is.
We now turn toan examination of the predictions within our verbclasses.3.2 Model comparisons within verb classTable 2 shows Spearman rank correlations be-tween mean regularization in the experiment andthe predictions of the two models for the five verbcategories.
Overall, GCM does a better job.
Theno-change (cut) verb class is especially illustra-tive of the differences between the two models.Note that the MGL is negatively correlated withour experimental data for this category.
As notedabove, this verb class appears to be strikingly non-productive; participants display a strong prefer-ence for regularizing a wide range of t-final forms.The MGL underestimates the regularization ofnonce verbs that resemble cut and hit, while over-estimating the regularization of forms like vurt,slurt, plurt.
The no-change irregular form of suchverbs must be modeled on a pattern with a sole En-glish exemplar (hurt?hurt), and the Minimal Gen-eralization model (in contrast with the GCM) isswayed very little in such cases.
This is one of sev-eral cases where the GCM predicts subject pref-erences better than the MGL does, seemingly be-cause the irregular form requires modeling a re-sponse on a sole exemplar.There is one verb category where the MGL out-performs the GCM: the drove class.
Here, theMGL does especially well because it makes an ac-curate prediction about one subcategory of items:nonce verbs like quine and sline are regularized byparticipants (quined,slined) more often than othermembers of the drove class.
Here, it seems thatlllllllllllll lll llllllllllllllllllllllllllllllllllllllll lllllllll l lllllllll ll lllllllllllllllllllllllllll llll llllllllllllllllllll lllllllllllllllllllllllllll llllllllllllllllllllllllllllllllllll lllll llllllllllll lllllllllllllllll lllllllllllllllllllllllllllllllllllllll lllll lllllllllllllllllllllll?3 ?2 ?1 0 10.40.50.60.70.80.9predicted regularityaverage regularityinexperimentRatings vs. GCMllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll lllllllllllllllllllllll?3 ?2 ?1 0 10.40.50.60.70.80.9predicted regularityaverage regularityinexperimentRatings vs. MGLllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll?3 ?2 ?1 0 1?3?2?101MGLGCMGCM vs. MGLFigure 2: Above: experimental ratings versusGCM predictions.
Middle: experimental ratingsversus MGL predictions.
Below: MGL predic-tions vs. GCM predictions.
(With lowess linesadded.
)60the irregular past would need to be modeled onone closely-related English item (shine?shone),but similar English verbs offer many exceptionsto any abstract generalization (line?lined, mine?mined, whine?whined, not to mention the transi-tive verb shine?shined).
Such a situation causesthe MGL to correctly classify all -ine final verbs ashighly prone to regularization, because -ine/-onetype irregulars are all dispreferred in the experi-ment.
However, the GCM makes a wide range ofpredictions for these stimuli on the basis of differ-ent segmental similarities with training items (e.g.,based on the syllable onsets).On the whole, comparing the two models on theverb classes suggests that analogy to individual in-stances is a better approximation of the behaviorof our subjects than recourse to abstract general-izations.
It is true, however, that both the GCMand the MGL each only explain a part of the ob-served variance.
In order to test whether the twomodels contribute differently to explaining partic-ipant behavior in our dataset, we fitted a simplestepwise logistic mixed-effects regression modelon the results with maximal random effects struc-ture, using regularization on the individual verbform (yes or no) as an outcome variable.
Insteadof verb category, we used the GCM and the MGLregularization rates as predictors.
Both predictorsare significant.
An analysis of variance test revealsthat the regression model that includes the predic-tions of both categorization models provides a sig-nificantly better fit than the models including ei-ther alone.
We tested nonlinear effects of MGLand GCM, using restricted cubic splines, but non-linearity did not significantly improve the model.Participant age and gender are not significant.
Vo-cabulary size explains some variation, though doesnot quite meet the threshold of .05 for significance.The interaction of GCM predictions and partici-pant gender, however, is significant.
The modelcoefficients can be seen in Table 3.3.3 Individual-level factorsAs both MGL and GCM make reference to exist-ing patterns in the lexicon, we hypothesized thatthe precise size and contents of an individual?s vo-cabulary is likely to produce individual variationin terms of the lexical support available for cer-tain patterns.
Individuals with higher vocabularyscores may be more likely to have robust storedinstances of irregular, lower frequency, minorityPredictor b z sig.
(Intercept) 0.71 4.5 ***MGL 12.4 3.38 ***GCM 1.11 5.05 ***gender (male) -0.02 -0.07 (n.s.
)vocabulary -0.25 -1.77 .GCM : gender (male) 0.47 2.12 *Table 3: Effects of rules vs. analogy in the regres-sion modelpast tense patterns.
We might therefore predictthat they are more accepting of irregular realiza-tions.
This is, to some degree, confirmed by thestrength of vocabulary as a predictor of regulariza-tion in our final model.
A potential interaction ofvocabulary size and the two models of past tenseformation is that these models likely have differ-ent predictions when trained on vocabulary sets ofvarious sizes ?
this is a clear direction of futureresearch.We also tested the effects of participant gender,as women have been reported to be more biasedtowards more standard language (Labov, 2001).This would mean that conformity to speech com-munity standards in whether a form is irregularor regular (essentially, getting it ?right?)
could behighly valued by women.
Consistent with thisobservation, we find a significant interaction be-tween GCM and participant gender.
Females showa steeper slope for the GCM than the males do.When there is low analogical support for regular-ization, females have a tendency to prefer irregularforms more than males do, but this difference is re-versed for items where the GCM provides strongsupport for the regular.
In that case, females preferregular forms more than males do.
To put it differ-ently, females categorize the verb forms more inour dataset than the males do.It is interesting to note that our results differfrom Hartshorne and Ullman?s (2006) child dataon real English verbs.
They found more over-regularization for girls than for boys.
The mecha-nism they suggest relies on girls having more pre-cocious verbal ability, as is commonly reported.These results may seem hard to reconcile, sincethe adult women in our study did not regularizemore than men (there was no significant overalleffect of gender), nor did they have larger vocab-ularies, as measured by our vocabulary inventory.However, they are compatible if we assume that61the real verbal lexicon is rather well learned byadulthood (as reflected in the weakness of vocab-ulary level as a statistical predictor in our model)and that the gender difference we observed tapsthe social factors mentioned by Labov, which arelearned gradually during childhood and adoles-cence.4 ConclusionsOur results suggest that both the GCM and MGLmodels contribute important insights into factorsunderpinning perceived wellformedness.
Individ-uals are heavily influenced by the combined ana-logical force of existing lexical forms.
They gen-eralize over items.
However, they also, it appears,generalize over these generalizations - formingmore abstract ?rules?
or associations that operate inparallel with the token-based analogical processes.While this seems to be the interpretation that ispointed to by this current data set, verification ofthe joint role of these types of processes clearlyrequires a lot more explicit testing in different andvaried data sets, including real verbs in addition tononce forms.
Recent models in phonological pro-cessing and speech perception certainly point to ahybrid model, in which instance-based processingand reasoning sits alongside more abstract struc-tures, and in which both types of processes maybe jointly operative ?
with the balance affected bymany factors including the particular nature of thetask at hand (Pierrehumbert, 2006).
Indeed, wewould predict that it should be possible to designmorphological tasks which more readily tap intopurely analogical processes, or into more abstractgeneralizations.AcknowledgmentsThis project was made possible through a grantfrom the John Templeton Foundation.
The opin-ions expressed in this publication are those of theauthors and do not necessarily reflect the views ofthe John Templeton Foundation.
Hay and Becknerwere also supported by a Rutherford DiscoveryFellowship awarded to Hay.
The authors wouldlike to thank Adam Albright, Patrick LaShell,Chun Liang Chan, and Lisa Garnard Dawdy-Hesterberg.
All faults remain ours.ReferencesAdam Albright and Bruce Hayes.
2002.
Modeling En-glish past tense intuitions with minimal generaliza-tion.
In Proceedings of the ACL-02 workshop onMorphological and phonological learning-Volume6, pages 58?69.
Association for Computational Lin-guistics.Adam Albright and Bruce Hayes.
2003.
Rulesvs.
analogy in English past tenses: A computa-tional/experimental study.
Cognition, 90(2):119?161.R Harald Baayen, Richard Piepenbrock, and Rijn vanH.
1993.
The CELEX lexical data base on CD-ROM.Jean Berko.
1958.
The child?s learning of English mor-phology.
Word, 14:150?177.Joan L Bybee and Carol Lynn Moder.
1983.
Mor-phological classes as natural categories.
Language,pages 251?270.Joan L Bybee and Dan I Slobin.
1982a.
Rules andschemas in the development and use of the Englishpast tense.
Language, pages 265?289.Joan L Bybee and Dan I Slobin.
1982b.
Why smallchildren cannot change language on their own: Sug-gestions from the English past tense.
In Papers fromthe 5th international conference on historical lin-guistics, volume 21.Lisa Garnand Dawdy-Hesterberg and Janet B Pierre-humbert.
2014.
Learnability and generalisation ofArabic broken plural nouns.
Language, Cognitionand Neuroscience, (ahead-of-print):1?15.Stefan A Frisch and Maria R Brea-Spahn.
2010.Metalinguistic judgments of phonotactics by mono-linguals and bilinguals.
Laboratory Phonology,1(2):345?360.Stefan Frisch, Michael Broe, and Janet Pierrehumbert.2004.
Similarity avoidance and the OCP.
NaturalLanguage and Linguistic Theory, 22:179?228.Lyn R Haber.
1976.
Leaped and leapt: a theoreticalaccount of linguistic variation.
Foundations of Lan-guage, pages 211?238.Joshua K Hartshorne and Michael T Ullman.
2006.Why girls say holded more than boys.
Developmen-tal Science, 9(1):21?32.William Labov.
2001.
Principles of linguistic changeVolume 2: Social factors.
Blackwell.James L McClelland and Karalyn Patterson.
2002.Rules or connections in past-tense inflections: Whatdoes the evidence rule out?
Trends in cognitive sci-ences, 6(11):465?472.Carol Lynn Moder.
1992.
Productivity and categoriza-tion in morphological classes.
Ph.D. thesis, StateUniversity of New York at Buffalo.62Robert Munro, Steven Bethard, Victor Kuperman,Vicky Tzuyin Lai, Robin Melnick, ChristopherPotts, Tyler Schnoebelen, and Harry Tily.
2010.Crowdsourcing and language studies: the new gen-eration of linguistic data.
In Proceedings of theNAACL HLT 2010 Workshop on Creating Speechand Language Data with Amazon?s MechanicalTurk, pages 122?130.
Association for Computa-tional Linguistics.Ramin C. Nakisa, Kim Plunkett, and Ulrike Hahn.2001.
A cross-linguistic comparison of single anddual-route models of inflectional morphology.
PeterBroeder, & Jaap Murre, Models of Language Acqui-sition: Inductive and Deductive Approaches, pages201?222.Robert M Nosofsky.
1990.
Relations betweenexemplar-similarity and likelihood models of clas-sification.
Journal of Mathematical Psychology,34(4):393?418.Janet B Pierrehumbert.
2006.
The next toolkit.
Jour-nal of Phonetics, 34(4):516?530.David E Rumelhart and James L McClelland.
1985.On learning the past tenses of English verbs.
Insti-tute for Cognitive Science, University of California,San Diego.63
