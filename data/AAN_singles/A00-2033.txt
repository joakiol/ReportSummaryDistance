Removing Left Recursion from Context-Free GrammarsRober t  C. MooreMicroso f t  ResearchOne Microsof t  WayRedmond,  Wash ington  98052bobmoore @microsoft.
cornAbst ractA long-standing issue regarding algorithms that ma-nipulate context-free grammars (CFGs) in a "top-down" left-to-right fashion is that left recursion canlead to nontermination.
An algorithm is knownthat transforms any CFG into an equivalent non-left-recursive CFG, but the resulting grammars areoften too large for practical use.
We present a newmethod for removing left recursion from CFGs thatis both theoretically superior to the standard algo-rithm, and produces very compact non-left-recursiveCFGs in practice.1 In t roduct ionA long-standing issue regarding algorithms that ma-nipulate context-free grammars (CFGs) in a "top-down" left-to-right fashion is that left recursion canlead to nontermination.
This is most familiar in thecase of top-down recursive-descent parsing (Aho etal., 1986, pp.
181-182).
A more recent motivationis that off-the-shelf speech recognition systems arenow available (e.g., from Nuance Communicationsand Microsoft) that accept CFGs as language modelsfor constraining recognition; but as these recogniz-ers process CFGs top-down, they also require thatthe CFGs used be non-left-recursive.The source of the problem can be seen by consid-ering a directly left-recursive grammar productionsuch as A -4 As.
Suppose we are trying to parse,or recognize using a speech recognizer, an A at agiven position in the input.
If we apply this pro-duction top-down and left-to-right, our first subgoalwill be to parse or recognize an A at the same inputposition.
This immediately puts us into an infiniterecursion.
The same thing will happen with an indi-rectly left-recursive grammar, via a chain of subgoalsthat will lead us from the goal of parsing or recogniz-ing an A at a given position to a descendant subgoalof parsing or recognizing an A at that position.In theory, the restriction to non-left-recursiveCFGs puts no additional constraints on the lan-guages that can be described, because any CFGcan in principle be transformed into an equivalentnon-left-recursive CFG.
However, the standard algo-rithm for carrying out this transformation (Aho etal., 1986, pp.
176-178) (Hopcroft and Ullman, 1979,p.
96)--attributed to M. C. Panll by Hopcroft andUllman (1979, p. 106)--can produce transformedgrammars that are orders of magnitude larger thanthe original grammars.
In this paper we develop anumber of improvements to Panll's algorithm, whichhelp somewhat but do not completely solve the prob-lem.
We then go on to develop an alternative ap-proach based on the left-corner grammar transform,which makes it possible to remove left recursion withno significant increase in size for several grammarsfor which Paull's original algorithm is impractical.2 Notat ion  and  Termino logyGrammar nonterminals will be designated by "loworder" upper-case letters (A, B, etc.
); and termi-nals will be designated by lower-case letters.
Wewill use "high order" upper-case letters (X, Y, Z)to denote single symbols that could be either ter-minals or nonterminals, and Greek letters to denote(possibly empty) sequences of terminals and/or non-terminals.
Any production of the form A --4 a willbe said to be an A-production, and a will be said tobe an expansion of A.We will say that a symbol X is a direct left cornerof a nonterminal A, if there is an A-production withX as the left-most symbol on the right-hand side.We define the left-corner elation to be the reflexivetransitive closure of the direct-left-corner relation,and we define the proper-left-corner relation to bethe transitive closure of the direct-left-corner rela-tion.
A nonterminal is left recursive if it is a properleft corner of itself; a nonterminal is directly left re-cursive if it is a direct left corner of itself; and anonterminal is indirectly left recursive if it is left re-cursive, but not directly left recursive.3 Test  GrammarsWe will test the algorithms considered here on threelarge, independently-motivated, natural-languagegrammars.
The CT grammar 1 was compiled intoa CFG from a task-specific unification grammar1Courtesy of John Dowding, SRI International249Grammar sizeTerminalsNonterminalsProductionsLR nonterminalsProductions for LR nonterminalsToy CT ATIS PTGrammar Grammar Grammar Grammar8840165542755,8301,0323,94624,4565352,21116,8723571924,59291,10967,904473815,0393314,993Table 1: Grammars used for evaluation.written for CommandTalk (Moore et al, 1997), aspoken-language interface to a military simulationsystem.
The ATIS grammar was extracted from aninternally generated treebank of the DARPA ATIS3training sentences (Dahl et al, 1994).
The PT  gram-mar 2 was extracted from the Penn Treebank (Mar-cus et al, 1993).
To these grammars we add a small"toy" grammar, simply because some of the algo-rithms cannot be run to completion on any of the"real" grammars within reasonable time and spacebounds.Some statistics on the test grammars are con-tained in Table 1.
The criterion we use to judgeeffectiveness of the algorithms under test is the sizeof the' resulting grammar, measured in terms of thetotal number of terminal and nonterminal symbolsneeded to express the productions of the grammar.We use a slightly nonstandard metric, counting thesymbols as if, for each nonterminal, there were asingle production of the form A --+ al  I ..- \[ a,~.This reflects the size of files and data structures typ-ically used to store grammars for top-down process-ing more accurately than counting a separate occur-rence of the left-hand side for each distinct right-hand side.It should be noted that the CT grammar has avery special property: none of the 535 left recursivenonterminals i indirectly left recursive.
The gram-mar was designed to have this property specificallybecause Paull's algorithm does not handle indirectleft recursion well.It should also be noted that none of these gram-mars contains empty productions or cycles, whichcan cause problems for algorithms for removing leftrecursion.
It is relatively easy to trasform an arbi-trary CFG into an equivalent grammar which doesnot contain any of the probelmatical cases.
In itsinitial form the PT  grammar contained cycles, butthese were removed at a cost of increasing the sizeof the grammar by 78 productions and 89 total sym-bols.
No empty productions or cycles existed any-where else in the original grammars.2Courtesy of Eugene Charniak, Brown University4 Paull's A lgor i thmPanll's algorithm for eliminating left recursion fromCFGs attacks the problem by an iterative procedurefor transforming indirect left recursion into directleft recursion, with a subprocedure for eliminatingdirect left recursion, This algorithm is perhaps morefamiliar to some as the first phase of the textbookalgorithm for transfomrming CFGs to Greibach nor-real form (Greibach, 1965).
3 The subprocedure toeliminate direct left recursion performs the followingtransformation (Hopcroft and UUman, 1979, p. 96):LetA Aa11... IAabe the set of all directly left recursive A-productions, and letI/?sbe the remaining A-productions.
Replaceall these productions withA --+/71 \ [ / ?
IA '  \[ .
.
.
\[/?8 \[/?sA',andA'  --+ az \[ a lA '  \[ .
.
.
I as \[ asA ' ,where A ~ is a new nonterminal not usedelsewhere in the grammar.This transformation is embedded in the full algo-rithm (Aho et al, 1986, p. 177), displayed in Fig-ure 1.The idea of the algorithm is to eliminate left re-cursion by transforming the grammar so that all thedirect left corners of each nonterminal strictly followthat nonterminal in a fixed total ordering, in whichcase, no nonterminal can be left recursive.
This isaccomplished by iteratively replacing direct left cor-ners that precede a given nonterminal with all theirexpansions in terms of other nonterminals that aregreater in the ordering, until the nonterminal hasonly itself and greater nonterminals as direct left3This has led some readers to attribute the algorithm toGreibach, but Greibach's original method was quite differentand much more complicated.250Assign an ordering A1, .
.
.
,  A,~ to the nonterminals of the grammar.for i := 1 to n do beginfor j :-- 1 to i - 1 do beginfor each production of the form Ai ~ Aja do beginremove Ai -+ Aja from the grammarfor each production of the form Aj -~/~ do beginadd Ai --~/~a to the grammarendendendtransform the Ai-productions to eliminate direct left recursionendFigure 1: Paull's algorithm.Grammar Description Grammar Sizeoriginal toy grammar 88PA, "best" ordering 156PA, lexicographical ordering 970PA, "worst" ordering 5696Table 2: Effect of nonterminal ordering on Paull's algorithm.corners.
Any direct left recursion for that nonter-minal is then eliminated by the first transformationdiscussed.The difficulty with this approach is that the it-erated substitutions can lead to an exponential in-crease in the size of the grammar.
Consider thegrammar consisting of the productions Az -+ 0 I 1,plus Ai+z -+ AiO I Ail for I < i < n. It is easy to seethat Paull's algorithm will transform the grammarso that it consists of all possible Ai-productions witha binary sequence of length i on the right-hand side,for 1 < i < n, which is exponentially larger thanthe original grammar.
Notice that the efficiency ofPauU's algorithm crucially depends on the orderingof the nonterminals.
If the ordering is reversed inthe grammar of this example, Paull's algorithm willmake no changes, since the grammar will alreadysatisfy the condition that all the direct left cornersof each nonterminal strictly follow that nonterminalin the revised ordering.
The textbook discussions ofPaull's algorithm, however, are silent on this issue.In the inner loop of Panll's algorithm, for nonter-minals Ai and Aj, such that i > j and Aj is a directleft corner of Ai, we replace all occurrences of Aj as adirect left corner of Ai with all possible expansionsof Aj.
This only contributes to elimination of leftrecursion from the grammar if Ai is a left-recursivenonterminal, and Aj \]ies on a path that makes Aileft recursive; that is, if Ai is a left corner of A3 (inaddition to Aj being a left corner of Ai).
We couldeliminate replacements hat are useless in removingleft recursion if we could order the nonterminals ofthe grammar so that, if i > j and Aj is a direct leftcorner of Ai, then Ai is also a left corner of Aj.
Wecan achieve this by ordering the nonterminals in de-creasing order of the number of distinct left cornersthey have.
Since the left-corner relation is transitive,if C is a direct left corner of B, every left corner ofC is also a left corner of /3.
In addition, since wedefined the left-corner relation to be reflexive, B is aleft corner of itself.
Hence, if C is a direct left cornerof B, it must follow B in decreasing order of numberof distinct left corners, unless B is a left corner ofC.Table 2 shows the effect on Paull's algorithm ofordering the nonterminals according to decreasingnumber of distinct left corners, with respect o thetoy grammar.
4 In the table, "best" means an or-dering consistent with this constraint.
Note thatif a grammar has indirect left recursion, there willbe multiple orderings consistent with our constraint,since indirect left recursion creates cycles in the theleft-corner elation, so every nonterminal in one ofthese cycles will have the same set of left corners.Our "best" ordering is simply an arbitrarily chosen4As mentioned previously, grammar sizes are given interms of total terminal and nonterminal symbols needed toexpress the grammar.251original grammarPALFLF+PALF+NLRG+PACT Grammar ATIS Grammar55,83062,49954,99159,79757,92416,872> 5,000,00011,5822,004,47372,035PT Grammar67,904> 5,000,00037,811> 5,000,000> 5,000,000Table 3: Grammar size comparisons with Panll's algorithm variantsordering respecting the constraint; we are unawareof any method for finding a unique best ordering,other than trying all the orderings respecting theconstraint.As a neutral comparison, we also ran the algo-rithm with the nonterminals ordered lexicographi-cally.
Finally, to test how bad the algorithm couldbe with a really poor choice of nonterminal ordering,we defined a "worst" ordering to be one with increas-ing numbers of distinct left corners.
It should benoted that with either the lexicographical or worstordering, on all of our three large grammars Panll'salgorithm exceeded a cut-off of 5,000,000 grammarsymbols, which we chose as being well beyond whatmight be considered a tolerable increase in the sizeof the grammar.Let PA refer to Paull's algorithm with the non-terminals ordered according to decreasing numberof distinct left corners.
The second line of Table 3shows the results of running PA on our three largegrammars.
The CT grammar increases only mod-estly in size, because as previously noted, it has noindirect left recursion.
Thus the combinatorial phaseof Paull's algorithm is never invoked, and the in-crease is solely due to the transformation applied todirectly left-recursive productions.
With the ATISgrammar and PT grammar, which do not have thisspecial property, Panll's algorithm exceeded our cut-off, even with our best ordering of nonterminals.Some additional optimizations of Panll's aglo-rithm are possible.
One way to reduce the num-ber of substitutions made by the inner loop of thealgorithm is to "left factor" the grammar (Aho etal., 1986, pp.
178-179).
The left-factoring transfor-mation (LF) applies the following grammar ewriteschema repeatedly, until it is no longer applicable:LF: For each nonterminal A, let a be thelongest nonempty sequence such that thereis more than one grammar production ofthe form A --+ a~.
Replace the set of allproductionsA-+af t1 ,  .
.
.
,  A -+a~nwith the productionsA -+ aA ' ,  A '  --~ il l, .
.
.
,  A '  --~ fin,where A' is a new nonterminal symbol.With left factoring, for each nonterminal A there willbe only one A-production for each direct left cornerof A, which will in general reduce the number ofsubstitutions performed by the algorithm.The effect of left factoring by itself is shown inthe third line of Table 3.
Left factoring actually re-duces the size of all three grammars, which may beunintuitive, since left factoring necessarily increasesthe number of productions in the grammar.
How-ever, the transformed productions axe shorter, andthe grammar size as measured by total number ofsymbols can be smaller because common left factorsare represented only once.The result of applying PA to the left-factoredgrammars is shown in the fourth line of Table 3(LF+PA).
This produces a modest decrease in thesize of the non-left-recursive form of the CT gram-mar, and brings the nomleft-recursive form of theATIS grammar under the cut-off size, but the non-left-recursive form of the PT  grammar still exceedsthe cut-off.The final optimization we have developed forPaull's algorithm is to transform the grammar tocombine all the non-left-recursive possibilities foreach left-recursive nonterminal under a new nonter-minal symbol.
This transformation, which we mightcall "non-left-recursion grouping" (NLRG), can bedefined as follows:NLRG: For each left-recursive nontermi-nal A, let a l , .
.
.
,an  be all the expansionsof A that do not have a left recursive non-terminal as the left most symbol.
If n > 1,replace the set of productionsA -~ a l  , .
.
.
,  A --~ a,~with the productionsA~A ~,A ~a l ,  .
.
.
,A  ~-~an,where A t is a new nonterminal symbol.Since all the new nonterminals introduced by thistransformation will be non-left-recursive, Paull's al-gorithm with our best ordering will never substitutethe expansions of any of these new nonterminals intothe productions for any other nonterminal, whichin general reduces the number of substitutions thealgorithm makes.
We did not empirically measure252original grammarLFLF+NLRG+PALCLCLRLF?LCLnLF+NLRG+LCLRCT Grammar ATIS Grammar PT  Grammar55,83054,99157,924762,57660,55658,89357,38016,87211,58272,035287,64940,66013,64112,24367,90437,811> 5,000,0001,567,1621,498,11267,16750,277Table 4: Grammar size comparisons for LC transform variantsthe effect on grammar size of applying the NLRGtransformation by itself, but it is easy to see thatit increases the grammar size by exactly two sym-bols for each left-recursive nontermina\] to which itis applied.
Thus an addition of twice the number ofleft-recursive nontermina\]s will be an upper boundon the increase in the size of the grammar, but sincenot every left-recursive nonterminal necessarily hasmore than one non-left-recursive expansion, the in-crease may be less than this.The fifth line of Table 3 (LF+NLRG+PA)  showsthe result of applying LF, followed by NLRG, fol-lowed by PA.
This produces another modest de-crease in the size of the non-left-recursive form ofthe CT grammar and reduces the size of the non-left-recursive form of the ATIS grammar by a factorof 27.8, compared to LF?PA.
The non-left-recursiveform of the PT  grammar emains larger than thecut-off size of 5,000,000 symbols, however.5 Le f t -Recurs ion  E l iminat ion  Basedon the  Lef t -Corner  T rans formAn alternate approach to eliminating left-recursionis based on the left-corner (LC) grammar transformof Rosenkrantz and Lewis (1970) as presented andmodified by Johnson (1998).
Johnson's second formof the LC transform can be expressed as follows, withexpressions of the form A-a, A -X ,  and A-B  beingnew nonterminals in the transformed grammar:1.
If a terminal symbol a is a proper left corner ofA in the original grammar, add A -4 aA-a tothe transformed grammar.2.
If B is a proper left corner of A and B --+ X~is a production of the original grammar, addA-X  -+ ~A-B to the transformed grammar.3.
If X is a proper left corner of A and A --+ X~is a production of the original grammar, addA-X  -+ ~ to the transformed grammar.In Rosenkrantz and Lewis's original LC transform,schema 2 applied whenever B is a left corner of A,including all cases where B = A.
In Johnson's ver-sion schema 2 applies when B -- A only if A is aproper left corner of itself.
Johnson then introducesschema 3 handle the residual cases, without intro-ducing instances of nonterminals of the form A-Athat need to be allowed to derive the empty string.The original purpose of the LC transform is toallow simulation of left-corner parsing by top-downparsing, but it also eliminates left recursion from anynoncyclic CFG.
5 Fhrthermore, in the worst case, thetotal number of symbols in the transformed gram-mar cannot exceed a fixed multiple of the square ofthe number of symbols in the original grammar, incontrast o Paull's algorithm, which exponentiatesthe size of the grammar in the worst case.Thus, we can use Johnson's version of the LCtransform directly to eliminate left-recursion.
Be-fore applying this idea, however, we have one gen-era\] improvement to make in the transform.
Johnsonnotes that in his version of the LC transform, a newnontermina\] of the form A-X  is useless unless X isa proper left corner of A.
We further note that anew nonterminal of the form A-X ,  as well as theorginal nonterminal A, is useless in the transformedgrammar, unless A is either the top nonterminal ofthe grammar or appears on the right-hand side ofan original grammar production in other than theleft-most position.
This can be shown by inductionon the length of top-down derivations using the pro-ductions of the transformed grammar.
Therefore,we will call the original nonterminals meeting thiscondition "retained nontermina\]s" and restrict theLC transform so that productions involving nonter-minals of the form A-X  are created only if A is aretained nonterminal.Let LC refer to Johnson's version of the LC trans-form restricted to retained nonterminals.
In Table 4the first three lines repeat he previously shown sizesfor our three original grammars, their left-factoredform, and their non-left-recursive form using ourbest variant of Panll's algorithm (LF+NLRG+PA).The fourth line shows the results of applying LC tothe three original grammars.
Note that this pro-duces a non-left-recursive form of the PT  gram-mar smaller than the cut-off size, but the non-left-recursive forms of the CT and ATIS grammars areSin the case of a cyclic CFG, the schema 2 fails to guar-antee a non-left-recursive transformed grammar.253considerably arger than the most compact versionscreated with Paull's algorithm.We can improve on this result by noting that,since we are interested in the LC transform only asa means of eliminating left-recursion, we can greatlyreduce the size of the transformed grammars by ap-plying the transform only to left-recursive nonter-minals.
More precisely, we can retain in the trans-formed grammar all the productions expanding non-left-recursive nonterminals of the original grammar,and for the purposes of the LC transform, we cantreat nomleft-recursive nonterminals as if they wereterminals:1.
If a terminal symbol or non-left-recursive non-terminal X is a proper left corner of a re-tained left-recursive nonterminal A in the orig-inal grammar, add A -+ XA-X  to the trans-formed grammar.2.
If B is a left-recursive proper left corner of aretained left-recursive nonterminal A and B --~X/~ is a production of the original grammar, addA-X -~ ~A-B to the transformed grammar.3.
If X is a proper left corner of a retained left-recursive nonterminal A and A --~ X/~ is a pro-duction of the original grammar, add A-X --~to the transformed grammar.4.
If A is a non-left-recursive nonterminal nd A -~/3 is a production of the original grammar, addA -~/~ to the transformed grammar.Let LCLR refer to the LC transform restrictedby these modifications so as to apply only to left-recursive nonterminals.
The fifth line of Table 4shows the results of applying LCLR to the three orig-inal grammars.
LCLR greatly reduces the size of thenon-left-recursive forms of the CT and ATIS gram-mars, but the size of the non-left-recursive form ofthe PT grammar is only slightly reduced.
This isnot surprising if we note from Table 1 that almostall the productions of the PT grammar are produc-tions for left-recursive nonterminals.
However, wecan apply the additional transformations that weused with Paull's algorithm, to reduce the num-ber of productions for left-recursive nonterminalsbefore applying our modified LC transform.
Theeffects of left factoring the grammar before apply-ing LCLR (LF+LCLR), and additionally combiningnon-left-recursive productions for left-recursive non-terminals between left factoring and applying LCLR(LF+NLRG+LCLR), are shown in the sixth andseventh lines of Table 4.With all optimizations applied, the non-left-recursive forms of the ATIS and PT grammars aresmaller than the originals (although not smallerthan the left-factored forms of these grammars),and the non-left-recursive form of the CT gram-mar is only slightly larger than the original.
In allcases, LF+NLRG+LCLR produces more compactgrammars than LF+NLRG+PA, the best variant ofPaull's algorithm--slightly more compact in the caseof the CT grammar, more compact by a factor of 5.9in the case of the ATIS grammar, and more compactby at least two orders of magnitude in the case of thePT grammar.6 Conc lus ionsWe have shown that, in its textbook form,the standard algorithm for eliminating left recur-sion from CFGs is impractical for three diverse,independently-motivated, natural-language ram-mars.
We apply a number of optimizations to thealgorithm--most notably a novel strategy for order-ing the nonterminals of the grammar--but one ofthe three grammars remains essentially intractable.We then explore an alternative approach based onthe LC grammar transform.
With several optimiza-tions of this approach, we are able to obtain quitecompact non-left-recursive forms of all three gram-mars.
Given the diverse nature of these grammars,we conclude that our techniques based on the LCtransform are likely to be applicable to a wide rangeof CFGs used for natural-language processing.ReferencesA.
V. Aho, R. Sethi, and J. D. Ullman.
1986.Compilers: Principles, Techniques, and Tools.Addison-Wesley Publishing Company, Reading,Massachusetts.D.
A. Da.hl et al 1994.
Expanding the scope of theATIS task: the ATIS-3 corpus.
In Proceedings o/the Spoken Language Technology Workshop, pages3-8, Plainsboro, New Jersey.
Advanced ResearchProjects Agency.S.
A. Greibach.
1965.
A new normal-form theoremfor context-free phrase structure grammars.
Jour-nal of the Association for Computing Machinery,12(1):42-52, January.J.
E. Hopcroft and J. D. Ullman.
1979.
Introduc-tion to Automata Theory, Languages, and Com-putation.
Addison-Wesley Publishing Company,Reading, Massachusetts.M.
Johnson.
1998.
Finite-state approximationof constraint-based grammars using left-cornergrammar transforms.
In Proceedings, COLING-ACL '98, pages 619-623, Montreal, Quebec,Canada.
Association for Computational Linguis-tics.M.
P. Marcus, B. Santorini, and M. A.Marcinkiewicz.
1993.
Building a large anno-tated corpus of English: The Penn Treebank.Computational Linguistics, 19(2):313-330, June.R.
Moore, J. Dowding, H. Bratt, J. M. Gawron,Y.
Gorfu, and A. Cheyer.
1997.
Commandtalk:254A spoken-language interface for battlefield simu-lations.
In Proceedings of the Fifth Conference onApplied Natural Language Processing, pages 1-7,Washington, DC.
Association for ComputationalLinguistics.S.
J. Rosenkrantz and P. M. Lewis.
1970.
Deter-ministic left corner parser.
In IEEE ConferenceRecord of the 11th Annual Symposium on Switch-ing and Automata Theory, pages 139-152.255
