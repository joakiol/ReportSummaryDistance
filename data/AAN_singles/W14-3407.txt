Proceedings of the 2014 Workshop on Biomedical Natural Language Processing (BioNLP 2014), pages 45?53,Baltimore, Maryland USA, June 26-27 2014.c?2014 Association for Computational LinguisticsCoreference Resolution for Structured Drug Product LabelsHalil Kilicoglu and Dina Demner-FushmanNational Library of MedicineNational Institutes of HealthBethesda, MD, 20894{kilicogluh,ddemner}@mail.nih.govAbstractFDA drug package inserts provide com-prehensive and authoritative informationabout drugs.
DailyMed database is arepository of structured product labels ex-tracted from these package inserts.
Mostsalient information about drugs remainsin free text portions of these labels.
Ex-tracting information from these portionscan improve the safety and quality of drugprescription.
In this paper, we present astudy that focuses on resolution of coref-erential information from drug labels con-tained in DailyMed.
We generalized andexpanded an existing rule-based coref-erence resolution module for this pur-pose.
Enhancements include resolution ofset/instance anaphora, recognition of ap-positive constructions and wider use ofUMLS semantic knowledge.
We obtainedan improvement of 40% over the baselinewith unweighted average F1-measure us-ing B-CUBED, MUC, and CEAF metrics.The results underscore the importance ofset/instance anaphora and appositive con-structions in this type of text and point outthe shortcomings in coreference annota-tion in the dataset.1 IntroductionAlmost half of the US population uses at least oneprescription drug and over 75% of physician of-fice visits involve drug therapy1.
Knowing howthese drugs will affect the patient is very impor-tant, particularly, to over 20% of the patients thatare on three or more prescription drugs1.
FDAdrug package inserts (drug labels or Structured1Centers for Disease Control and Preven-tion: FASTSTATS - Therapeutic Drug Use:http://www.cdc.gov/nchs/fastats/drugs.htmProduct Labels (SPLs)) provide curated informa-tion about the prescription drugs and many over-the-counter drugs.
The drug labels for most drugsare publicly available in XML format through Dai-lyMed2.
Some information in these labels, such asthe drug identifiers and ingredients, could be eas-ily extracted from the structured fields of the XMLdocuments.
However, the salient content about in-dications, side effects and drug-drug interactions,among others, is buried in the free text of thecorresponding sections of the labels.
Extractingthis information with natural language process-ing techniques can facilitate automatic timely up-dates to databases that support Electronic HealthRecords in alerting physicians to potential drug in-teractions, recommended doses, and contraindica-tions.Natural language processing methods are in-creasingly used to support various clinical andbiomedical applications (Demner-Fushman et al.,2009).
Extraction of drug information is playing aprominent role in these applications and research.In addition to earlier research in extraction of med-ications and relations involving medications fromclinical text and the biomedical literature (Rind-flesch et al., 2000; Cimino et al., 2007), in thethird i2b2 shared task (Uzuner et al., 2010), 23organizations have explored extraction of medica-tions, their dosages, routes of administration, fre-quencies, durations, and reasons for administra-tion from clinical text.
The best performing sys-tems used rule-based and machine learning tech-niques to achieve over 0.8 F-measure for extrac-tion of medication names; however, the remain-ing information was harder to extract.
Researchershave also tackled extraction of drug-drug interac-tions (Herrero-Zazo et al., 2013), side effects (Xuand Wang, 2014), and indications (Fung et al.,2013) from various biomedical resources.As for many other information extraction tasks,2DailyMed: http://dailymed.nlm.nih.gov/dailymed/about.cfm45extracting drug information is often made moredifficult by coreference.
Coreference is defined asthe relation between linguistic expressions that arereferring to the same entity (Zheng et al., 2011).Coreference resolution is a fundamental task inNLP and can benefit many downstream applica-tions, such as relation extraction, summarization,and question answering.
Difficulty of the task isdue to the fact that various levels of linguistic in-formation (lexical, syntactic, semantic, and dis-course contextual features) generally play a role.Coreference occurs frequently in all types ofbiomedical text, including the drug package in-serts.
Consider the example below:(1) Since amiodarone is a substrate forCYP3A and CYP2C8, drugs/substancesthat inhibit these isoenzymes may decreasethe metabolism .
.
.
.In this example, the expression these isoenzymesrefer to CYP3A and CYP2C8.
Resolving thiscoreference instance would allow us to capture thefollowing drug interactions mentioned in the sen-tence: inhibitors of CYP3A POTENTIATE amio-darone and inhibitors of CYP2C8 POTENTIATEamiodarone.In this paper, we present a study that focuses onidentification of coreference links in drug labels,with the view that these relations will facilitatethe downstream task of drug interaction recogni-tion.
The rule-based system presented is an exten-sion of the previous work reported in Kilicoglu etal.
(2013).
The main focus of the dataset, basedon SPLs, is drug interaction information.
Coref-erence is only annotated when it is relevant to ex-tracting such information.
In addition to evaluat-ing the system against a baseline, we also manu-ally assessed the system output for precision.
Fur-thermore, we also evaluated the system on a sim-ilarly drug-focused corpus annotated for anaphora(DrugNerAR) (Segura-Bedmar et al., 2010).
Ourresults demonstrate that set/instance anaphora res-olution and appositive recognition can play a sig-nificant role in this type of text and highlight someof the major areas of difficulty and potential en-hancements.2 Related WorkWe discuss two areas of research related to thisstudy in this section: processing of drug labelsand coreference resolution focusing on biomedi-cal text.
Drug labels, despite their availability andthe wealth of information contained within them,remain underutilized.
One of the reasons might bethe complexity of the text in the labels: in a reviewof publicly available text sources that could beused to augment a repository of drug indicationsand adverse effects (ADEs), Smith et al.
(2011)concluded that many indication and adverse drugevent relationships in the drug labels are too com-plex to be captured in the existing databases of in-teractions and ADEs.
Despite the complexity, thelabels were used to extract indications for drugs inseveral studies.
Elkin et al.
(2011) automaticallyextracted indications, mapped them to SNOMED-CT and then automatically derived rules in theform (?Drug?
HasIndication ?SNOMED CT?
).Fung et al.
(2013) used MetaMap (Aronson andLang, 2010) to extract indications and map themto the UMLS (Lindberg et al., 1993), and thenmanually validated the quality of the mappings.Oprea et al.
(2011) used information extractedfrom the adverse reactions sections of 988 drugsfor computer-aided drug repurposing.
Duke etal.
(2011) have developed a rule-based system thatextracted 534,125 ADEs from 5602 SPLs.
Zhuet al.
(2013) extracted disease terms from fiveSPL sections (indication, contraindication, ADE,precaution, and warning) and combined the ex-tracted terms with the drug and disease relation-ships in NDF-RT to disambiguate the PharmGKBdrug and disease associations.
A hybrid NLP sys-tem, AutoMCExtractor, uses conditional randomfields and post-processing rules to extract medicalconditions from SPLs and build triplets in the formof([drug name]-[medical condition]-[LOINC sec-tion header]) (Li et al., 2013).Coreference resolution in the biomedical do-main was addressed in the 2011 i2b2/VA sharedtask (Uzuner et al., 2012), and the 2011 BioNLPShared Task (Kim et al., 2012); however thesecommunity-wide evaluations did not change muchthe observation in the 2011 review by Zhenget al.
(2011) that only a handful of systemswere developed for handling anaphora and coref-erence in clinical text and biomedical publica-tions.
Since this comprehensive article was pub-lished, Yoshikawa et al.
(2011) proposed twocoference resolution models based on support vec-tor machine and joint Markov logic network toaid the task of biological event extraction.
Sim-ilarly, Miwa et al.
(2012) and Kilicoglu andBergler (2012) extended their biological event46extraction pipelines using rule-based corefer-ence systems that rely on syntactic informationand predicate argument structures.
Nguyen etal.
(2012) evaluated contribution of discourse pref-erence, number agreement, and domain-specificsemantic information in capturing pronominal andnominal anaphora referring to proteins.
An ef-fort similar to ours is that of Segura-Bedmar etal.
(2010), who resolve anaphora to support drug-drug interaction extraction.
They created a cor-pus of 49 interactions sections extracted from theDrugBank database, having on average 40 sen-tences and 716 tokens.
They then manually anno-tated pronominal and nominal anaphora, and de-veloped a rule-based approach that achieve 0.76F1-measure in anaphora resolution.3 Methods3.1 The datasetWe used a dataset extracted from FDA drug pack-age labels by our collaborators at FDA interestedin extracting interactions between cardiovascu-lar drugs.
The dataset consists of 159 drug la-bels, with an average of 105 sentences and 1787tokens per label.
It is annotated for three en-tity types (Drug, Drug Class, and Substance) andfour drug interaction types (Caution, Decrease, In-crease, and Specific).
377 instances of corefer-ence were annotated.
Two annotators separatelyannotated the labels and one of the authors per-formed the adjudication.
The relatively low num-ber of coreference instances is due to the fact thatcoreference was annotated only when it would berelevant to drug interaction recognition task.
Thisparsimonious approach to annotation presents dif-ficulty in automatically evaluating the system, andto mitigate this, we present an assessment of theprecision of our end-to-end coreference system, aswell.
We split the dataset into training and test setsby random sampling.
Training data consists of 79documents and the test set has 80 documents.
Weused the training data for analysis and as the basisof our enhancements.3.2 The systemThe work described in this paper extends andrefines earlier work, described in Kilicoglu etal.
(2013), which focused on disease anaphora andellipsis in the context of consumer health ques-tions.
We briefly recap that system here.
The sys-tem begins by mapping named entities to UMLSMetathesaurus concepts (CUIs).
Next, it identifiesanaphoric expressions in text, which include per-sonal (e.g., it, they) and demonstrative pronouns(e.g., this, those), as well as sortal anaphora (def-inite (e.g., with the) and demonstrative (e.g., withthat) noun phrases).
The candidate antecedentsare then recognized using syntactic (person, gen-der and number agreement, head word matching)and semantic (hypernym and UMLS semantic typematching) constraints.
Finally, the co-referent isthen selected as the focus of the question, which istaken as the first disease mention in the question.The coreference resolution pipeline used in thecurrent work, while enhanced significantly, fol-lows the same basic sequence.
The relatively sim-ple approach of earlier work is generally sufficientfor consumer health questions; however, we foundit insufficient when it comes to drug labels.
Asidefrom the obvious point that the approach was lim-ited to diseases, there are other stylistic differencesthat have an impact on coreference resolution.
Incontrast to informal and casual style of consumerhealth questions, drug labels are curated and pro-vide complex indication and ADE information ina formal style, more akin to biomedical literature.Our analysis of the training data highlighted sev-eral facts regarding coreference in drug labels: (1)the set/instance anaphora (including those involv-ing distributive anaphora such as both, each, ei-ther) instances are prominent, (2) demonstrativepronominal anaphora is non-existent in contrastto consumer health questions, (3) the focus-basedsalience scoring is simplistic for longer texts.
Wedescribe the system enhancements below.3.2.1 Generalizing from diseases to drugsand beyondWe generalized from resolution of disease coref-erence only to resolution of coreference involv-ing other entity types.
For this purpose, we para-materized semantic groups and hypernym lists as-sociated with each semantic group.
We general-ized the system in the sense that new semantictypes and hypernyms can be easily defined andused by the system.
In addition to Disorder se-mantic group and Disorder hypernym list definedin earlier work, we used Drug, Intervention, Pop-ulation, Procedure, Anatomy, and Gene/Proteinsemantic groups and hypernym lists.
Semanticgroup classification largely mimics coarse-grainedUMLS semantic groups (McCray et al., 2001).For example, UMLS semantic types Pharmaco-47logic Substance and Clinical Drug are aggregatedinto both Drug and Intervention semantic groups,while Therapeutic or Preventive Procedure is as-signed to Procedure group only.
Drug hypernyms,such as medication, drug, agent, were derivedfrom the training data.3.2.2 Set/instance anaphoraSet/instance anaphora instances are prevalent indrug labels.
In our dataset, 19% of all anno-tated anaphoric expressions indicate set/instanceanaphora (co-referring with 29% of antecedentterms).
An example was provided earlier (Ex-ample 1).
While recognizing anaphoric expres-sions that indicate set/instance anaphora is notnecessarily difficult (i.e., recognizing these isoen-zymes in the example), linking them to their an-tecedents can be difficult, since it generally in-volves correctly identifying syntactic coordina-tion, a challenging syntactic parsing task (Ogren,2010).
Our identification of these structures re-lies on collapsed Stanford dependency output (deMarneffe et al., 2006) and uses syntactic and se-mantic constraints.
We examine all the depen-dency relations extracted from a sentence and onlyconsider those with the type conj * (e.g., conj and,conj or).
For increased accuracy, we then checkthe tokens involved in the dependency (conjuncts)and ensure that there is a coordinating conjunc-tion (e.g., and, or, , (comma), & (ampersand)) be-tween them.
Once such a conjunction is identified,we then examine the semantic compatibility of theconjuncts.
In the case of entities, the compatibil-ity involves that at the semantic group level.
In thecurrent work, we also began recognizing distribu-tive anaphora, such as either, each as anaphoricexpressions.
When the recognized anaphoric ex-pression is plural (as in they, these agents or eitherdrug), we allow the coordinated structures previ-ously identified in this fashion as candidate an-tecedents.
The current work does not address amore complex kind of set/instance anaphora, inwhich the instances are not syntactically coordi-nated, such as in Example (2), where such agentsrefer to thiazide diuretics, in the preceding sen-tence, as well as Potassium-sparing diuretics andpotassium supplements.
(2) .
.
.
can attenuate potassium loss causedby thiazide diuretics.
Potassium-sparingdiuretics .
.
.
or potassium supplements canincrease .
.
.
.
if concomitant use ofsuch agents is indicated .
.
.3.2.3 Appositive constructionsCoreference involving appositive constructions3are annotated in some corpora, including theBioNLP shared task coreference dataset (Kimet al., 2012) and DrugNerAR corpus (Segura-Bedmar et al., 2010).
An example is given below,in which the indefinite noun phrase a drug and thedrug lovastatin are appositives.
(3) PLETAL does not, however, appear to causeincreased blood levels of drugs metabolizedby CYP3A4, as it had no effect on lovastatin,a drug with metabolism very sensitive toCYP3A4 inhibition.In our dataset, coreference involving apposi-tive constructions were generally left unannotated.However, it was consistently the case that whenone of the items in the construction is annotatedas the antecedent for an anaphoric expression,the other item in the construction was also anno-tated as such.
Therefore, we identified appositiveconstructions in text to aid the antecedent selec-tion task.
We used dependency relations for thistask, as well.
Identifying appositives is relativelystraightforward using syntactic dependency rela-tions.
We adapted the following rule from Kil-icoglu and Bergler (2012):APPOS(Antecedent,Anaphor) ?APPOS(Anaphor,Antecedent) ?COREF(Anaphor,Antecedent)where APPOS ?
{appos, abbrev, prep including,prep such as}.
In our case, this rule becomes(APPOS(Antecedent1,Antecedent2) ?APPOS(Antecedent2,Antecedent1)) ?COREF(Anaphor,Antecedent1) ?COREF(Anaphor,Antecedent2)which essentially states that a candidate is taken asan antecedent, only if its appositive has been rec-ognized as an antecedent.
Additionally, semanticcompatibility between the items is required.This allows us to identify their and Class Ia an-tiarrhythmic drugs as co-referents in the followingexample, due to the fact that the exemplificationindicated by the appositive construction betweenClass Ia antiarrythmic drugs and disopyramide isrecognized, the latter previously identified as anantecedent for their.3We use the term ?appositive?
to cover exemplifications,as well.48(4) Class Ia antiarrhythmic drugs, such asdisopyramide, quinidine and procainamideand other Class III drugs (e.g., amiodarone)are not recommended .
.
.
because of theirpotential to prolong refractoriness.3.2.4 Relative pronounsSimilar to appositive constructions, relative pro-nouns are annotated as anaphoric expressions insome corpora (same as those for appositives), butnot in our dataset.
In the example below, the rela-tive pronoun which refers to potassium-containingsalt substitutes.
(5) .
.
.
the concomitant use of potassium-sparingdiuretics, potassium supplements, and/orpotassium-containing salt substitutes, whichshould be used cautiously.
.
.Since we aim for generality and this type ofanaphora can be important for downstream ap-plications, we implemented a rule, again takenfrom Kilicoglu and Bergler (2012), which simplystates that the antecedent of a relative pronominalanaphora is the noun phrase head it modifies.rel(X,Anaphor) ?
rcmod(Antecedent,X) ?COREF(Anaphor,Antecedent)where rel indicates a relative dependency, and rc-mod a relative clause modifier dependency.
Weextended this in the current work to include thefollowing rules:(6) (a) LEFT(Antecedent,Anaphor) ?NO INT WORD(Antecedent,Anaphor)?
COREF(Anaphor,Antecedent)(b) LEFT(Antecedent,Anaphor) ?
rc-mod(Antecedent,X)?
LEFT(Anaphor,X)?
COREF(Anaphor,Antecedent)where LEFT indicates that the first argument isto the left of the second and NO INT WORD in-dicates that the arguments have no interveningwords between them.3.3 Drug ingredient/brand name synonymyA specific, non-anaphoric type of coreference,between drug ingredient name and drug?s brandname, is commonly annotated in our dataset.
Anexample is provided below, where COREG CR isthe brand name for carvedilol.
(7) The concomitant administration of amio-darone or other CYP2C9 inhibitors such asfluconazole with COREG CR may enhancethe -blocking properties of carvedilol .
.
.
.To identify this type of coreference, we use se-mantic information from UMLS Metathesaurus.We stipulate that, to qualify as co-referents, bothterms under consideration should map to the sameUMLS concept (i.e., that they are considered syn-onyms).
If the terms are within the same sentence,we further require that they are appositive.3.3.1 Demonstrative pronounsAnaphoric expressions of demonstrative pronountype generally have discourse-deictic use; in otherwords, they often refer to events, propositions de-scribed in prior discourse or even to the full sen-tences or paragraphs, rather than concrete objectsor entities (Webber, 1988).
This fact was implic-itly exploited in consumer health questions, sincethe coreference resolution focused on diseasesonly, which are essentially processes.
However,in drug labels, discourse-deictic use of demonstra-tives is much more overt.
Consider the sentencebelow, where the demonstrative This refers to theevent of increasing the exposure to lovastatin.
(8) Co-administration of lovastatin and SAMSCAincreases the exposure to lovastatin and .
.
.
.This is not a clinically relevant change.To handle such cases, we blocked entity an-tecedents (such as drugs) for demonstrative pro-nouns and only allowed predicates (verbs, nomi-nalizations) as candidate antecedents.3.3.2 Pleonastic itWe recognized pleonastic instances of the pronounit to disqualify them as anaphoric expressions (forinstance, it in It may be necessary to .
.
.
).
Gen-erally, lexical patterns involving sequence of to-kens are used to recognize such instances (e.g.,(Segura-Bedmar et al., 2010).
We used a simpledependency-based rule that mimics these patterns,given below.nsubj*(X,it) ?
DEP(X,Y) ?
PLEONASTIC(it)where nsubj* refers to nsubj or nsubjpass depen-dencies and DEP is any dependency, where DEP/?
{infmod, ccomp, xcomp}.3.3.3 Discourse-based constraintsPreviously, we did not impose limits on how farthe co-referents could be from each other, sincethe entire discourse was generally short and thesalient antecedent (often the topic of the question)appeared early in discourse.
This is often not the49case in drug labels, especially because often intri-cate interactions between the drug of interest andother medications are discussed.
Therefore, welimit the discourse window from which candidateantecedents are identified.
Generally, the searchspace for the antecedents is limited to the currentsentence as well as the two preceding sentences(Segura-Bedmar et al., 2010; Nguyen et al., 2012).In our dataset, we found that 98% of antecedentsoccurred within this discourse window and, thus,use the same search space.
We make an exceptionfor the cases in which the anaphoric expression ap-pear in the first sentence of a paragraph and nocompatible antecedent is found in the same sen-tence.
In this case, the search space is expanded tothe entire preceding paragraph.We also extended the system to include differenttypes of salience scoring methods.
For drug labels,we use linear distance between the co-referents (interms of surface elements) as the salience score;the lower this score, the better candidate the an-tecedent is.
Additionally, we implemented syn-tactic tree distance between the co-referents as apotential salience measure, even though this typeof salience scoring did not have an effect on ourresults on drug labels.Finally, we block candidate antecedents thatare in a direct syntactic dependency with theanaphoric expression, except when the anaphor isreflexive (e.g., itself ).3.4 EvaluationTo evaluate our approach, we used a baseline simi-lar to that reported in Segura-Bedmar et al.
(2010),which consists of selecting the closest precedingnominal phrase for the anaphoric expressions an-notated in their corpus.
These expressions in-clude pronominal (personal, relative, demonstra-tive, etc.)
and nominal (definite, possessive,etc.)
anaphora.
We compared our system tothis baseline using the unweighted average of F1-measure over B-CUBED (Bagga and Baldwin,1998), MUC (Vilain et al., 1995), and CEAF (Luo,2005) metrics, the standard evaluation metrics forcoreference resolution.
We used the scripts pro-vided by i2b2 shared task organizers for this pur-pose.
Since coreference annotation was parsimo-nious in our dataset, we also manually examined asubset of the coreference relations extracted by thesystem for precision.
Additionally, we tested oursystem on DrugNerAR corpus (Segura-Bedmar etal., 2010), which similarly focuses on drug inter-actions.
We compared our results to theirs, us-ing as evaluation metrics precision, recall, and F1-measure, the metrics that were used in their evalu-ation.4 Results and DiscussionWith the drug label dataset, we obtained the bestresults without relative pronominal anaphora reso-lution and drug ingredient/brand name synonymystrategies (OPTIMAL) and with linear distanceas the salience measure.
In this setting, usinggold entity annotations, we recognized 318 coref-erence chains, 54 of which were annotated in thecorpus.
The baseline identified 1415 coreferencechains, only 10 of which were annotated.
The im-provement provided by the system over the base-line is clear; however, the low precision/recall/F1-measure, given in Table 1, should be taken withcaution due to the sparse coreference annotationin the dataset.
To get a better sense of how wellour system performs, we also performed end-to-end coreference resolution and manually assesseda subset of the system output (22 randomly se-lected drug labels with 249 coreference instances).Of these 249, 181 were deemed correct, yielding aprecision of 0.73.
The baseline method extracted1439 instances, 56 of which were deemed cor-rect, yielding a precision of 0.04.
The precisionof our method is more in line with what has beenreported in the literature (Segura-Bedmar et al.,2010; Nguyen et al., 2012).
For i2b2-style eval-uation using the unweighted average F1measureover B-CUBED, MUC, and CEAF metrics, weconsidered both exact and partial mention overlap.These results, provided in Table 1, also indicatethat the system provides a clear improvement overthe baseline.Metric Baseline OPTIMALWith gold entity annotationsUnweighted F1Partial 0.55 0.77Unweighted F1Exact 0.66 0.78Precision 0.01 0.17Recall 0.04 0.26F1-measure 0.01 0.21End-to-end coreference resolutionPrecision 0.04 0.73Table 1: Evaluation results on drug labels50We also assessed the effect of various resolutionstrategies on results.
These results are presented inTable 2.Strategy F1-measureOPTIMAL 0.21OPTIMAL - SIA 0.21OPTIMAL - APPOS 0.15OPTIMAL + DIBS 0.16 (0.39 recall)Table 2: Effect of coreference strategiesDisregarding set/instance anaphora resolution(SIA) does not appear to affect the results bymuch; however, this is mostly due to the fact thatthe ?instance?
mentions are generally exemplifica-tions of a particular drug class which also appearin text.
In the absence of set/instance anaphoraresolution, the system often defaults to these drugclass mentions, which were annotated more oftenthan not, unlike the ?instance?
mentions.
Take thefollowing example:(9) Use of ZESTRIL with potassium-sparingdiuretics (e.g., spironolactone, eplerenone,triamterene or amiloride) .
.
.
may lead to sig-nificant increases .
.
.
if concomitant use ofthese agents .
.
.Without set-instance anaphora resolution, the sys-tem links these agents to potassium-sparing di-uretics, an annotated relation.
With set-instanceanaphora resolution, the same expression is linkedto individual drug names (spironolactone, etc.)
aswell as the the drug class, creating a number offalse positives, which, in effect, offsets the im-provement provided by this strategy.On the other hand, recognizing appositive con-structions (APPOS) appears to have a larger im-pact; however, it should be noted that this is mostlybecause it helps us expand the antecedent mentionlist in the case of set/instance anaphora.
For in-stance, in Example (9), this strategy allows us toestablish the link between the anaphora and thedrug class (diuretics), since the drug class and in-dividual drug name (spironolactone) are identifiedearlier as appositive.
We can conclude that, in gen-eral, set/instance anaphora benefits from recogni-tion of appositive constructions.Recognizing drug ingredient/brand name syn-onymy (DIBS) improved the recall and hurt theprecision significantly, the overall effect beingnegative.
Since this non-anaphoric type of coref-erence is strictly semantic in nature and resourcesfrom which this type of semantic information canbe derived already exist (UMLS, among others), itis perhaps not of utmost importance that a coref-erence resolution system recognizes such corefer-ence.We additionally processed the DrugNerAR cor-pus with our system.
The optimal setting forthis corpus was disregarding the drug ingredi-ent/brand name synonymy but using relative pro-noun anaphora resolution, based on the discus-sion in Segura-Bedmar et al.
(2010).
Somewhat toour surprise, our system did not fare well on thiscorpus.
We extracted 524 chains, 327 of which(out of 669) were annotated in the corpus, yield-ing a precision of 0.71, recall of 0.56, and F1-measure of 0.63.
This is about 20% lower thantheir reported results.
When we used their base-line method (explained earlier), we obtained simi-larly lower scores (precision of 0.18, recall of 0.45,F1-measure of 0.26, about 40% lower than theirreported results).
In light of this apparent discrep-ancy, which clearly warrants further investigation,it is perhaps more sensible to focus on ?improve-ment over baseline?
(reported as 73% in their pa-per and is 140% in our case).We analyzed some of the annotations moreclosely to get a better sense of the shortcomingsof the system.
The majority of errors were due tousing linear distance as the salience score.
For in-stance, in the following example, they is linked toACE inhibitors due to proximity, whereas the trueantecedent is these reactions (itself an anaphor andis presumably linked to another antecedent).
Itcould be possible to recover this link using prin-ciples of Centering Theory (Grosz et al., 1995),which suggests that subjects are more central thanobjects and adjuncts in an utterance.
Followingthis principle, the subject (these reactions) wouldbe preferred to ACE inhibitors as the antecedent.
(10) In the same patients, these reactions wereavoided when ACE inhibitors were temporar-ily withheld, but they reappeared upon inad-vertent rechallenge.Semantic (but not syntactic) coordination some-times leads to number disagreement between theanaphora and a true antecedent, as shown in Ex-ample (11), leading to false negatives.
In this ex-ample, such diuretics refers to both ALDACTONE51and a second diuretic; however, we are unable toidentify the link between them and the number dis-agreement between the anaphora and either of theantecedents blocks a potential coreference relationbetween these items.
(11) If, after five days, an adequate diuretic re-sponse to ALDACTONE has not occurred,a second diuretic that acts more proximallyin the renal tubule may be added to the reg-imen.
Because of the additive effect of AL-DACTONE when administered concurrentlywith such diuretics .
.
.5 ConclusionWe presented a coreference resolution system en-hanced based on insights from a dataset of FDAdrug package inserts.
Sparse coreference annota-tion in the dataset presented difficulties in evaluat-ing the results; however, based on various eval-uation strategies, the performance improvementdue to the enhancements seems evident.
Our re-sults show that recognizing coordination and ap-positive constructions are particularly useful andthat non-anaphoric cases of coreference can beidentified using synonymy in semantic resources,such as UMLS.
However, whether this is a taskfor a coreference resolution system or a conceptnormalization system is debatable.
We exper-imented with using hierarchical domain knowl-edge in UMLS (for example, the knowledge thatlisinopril ISA angiotensin converting enzyme in-hibitor) to resolve some cases of sortal anaphora.Even though we did not see an improvement dueto using this type of information on our dataset,further work is needed to assess its usefulness.While the enhancements were evaluated on druglabels only, they are not specific to this type oftext.
Their portability to different text types islimited only by the accuracy of underlying tools,such as parsers, for the text type of interest andthe availability of domain knowledge in the formof relevant semantic types, groups, hypernymsfor the entity types under consideration.
The re-sults also indicate that a more rigorous applicationof syntactic constraints in the spirit of CenteringTheory (Grosz et al., 1995) could be beneficial.Event (or clausal) anaphora and anaphora indicat-ing discourse deixis, while rarely annotated in ourdataset, appear to occur fairly often in biomedicaltext.
These types of anaphora are known to be par-ticularly challenging, and we plan to investigatethem in future research, as well.AcknowledgmentsThis work was supported by the intramural re-search program at the U.S. National Library ofMedicine, National Institutes of Health.ReferencesAlan R. Aronson and Franc?ois-Michel Lang.
2010.
Anoverview of MetaMap: historical perspective and re-cent advances.
Journal of the American Medical In-formatics Association (JAMIA), 17(3):229?236.Amit Bagga and Breck Baldwin.
1998.
Algorithmsfor scoring coreference chains.
In The First Interna-tional Conference on Language Resources and Eval-uation Workshop on Linguistics Coreference, pages563?566.James J. Cimino, Tiffani J.
Bright, and Jianhua Li.2007.
Medication reconciliation using natural lan-guage processing and controlled terminologies.
InKlaus A. Kuhn, James R. Warren, and Tze-YunLeong, editors, MedInfo, volume 129 of Studies inHealth Technology and Informatics, pages 679?683.IOS Press.Marie-Catherine de Marneffe, Bill MacCartney, andChristopher D. Manning.
2006.
Generating typeddependency parses from phrase structure parses.
InProceedings of the 5th International Conference onLanguage Resources and Evaluation, pages 449?454.Dina Demner-Fushman, Wendy W. Chapman, andClem J. McDonald.
2009.
What can natural lan-guage processing do for clinical decision support?Journal of Biomedical Informatics, 5(42):760?762.Jon Duke, Jeff Friedlin, and Patrick Ryan.
2011.
Aquantitative analysis of adverse events and ?over-warning?
in drug labeling.
Archives of internalmedicine, 10(171):944?946.Peter L. Elkin, John S. Carter, Manasi Nabar, MarkTuttle, Michael Lincoln, and Steven H. Brown.2011.
Drug knowledge expressed as computable se-mantic triples.
Studies in health technology and in-formatics, (166):38?47.Kin Wah Fung, Chiang S. Jao, and Dina Demner-Fushman.
2013.
Extracting drug indication infor-mation from structured product labels using naturallanguage processing.
JAMIA, 20(3):482?488.Barbara J. Grosz, Scott Weinstein, and Aravind K.Joshi.
1995.
Centering: a framework for model-ing the local coherence of discourse.
ComputationalLinguistics, 21(2):203?225.52Mar?
?a Herrero-Zazo, Isabel Segura-Bedmar, PalomaMart?
?nez, and Thierry Declerck.
2013.
The DDIcorpus: An annotated corpus with pharmacologicalsubstances and drug-drug interactions.
Journal ofBiomedical Informatics, 46(5):914?920.Halil Kilicoglu and Sabine Bergler.
2012.
Biolog-ical Event Composition.
BMC Bioinformatics, 13(Suppl 11):S7.Halil Kilicoglu, Marcelo Fiszman, and Dina Demner-Fushman.
2013.
Interpreting consumer health ques-tions: The role of anaphora and ellipsis.
In Proceed-ings of the 2013 Workshop on Biomedical NaturalLanguage Processing, pages 54?62.Jin-Dong Kim, Ngan Nguyen, YueWang, Jun?ichi Tsu-jii, Toshihisa Takagi, and Akinori Yonezawa.
2012.The Genia Event and Protein Coreference tasks ofthe BioNLP Shared Task 2011.
BMC Bioinformat-ics, 13(Suppl 11):S1.Qi Li, Louise Deleger, Todd Lingren, Haijun Zhai,Megan Kaiser, Laura Stoutenborough, Anil G.Jegga, Kevin B. Cohen, and Imre Solti.
2013.
Min-ing FDA drug labels for medical conditions.
BMCmedical informatics and decision making, 13(1):53.Donald A.
B. Lindberg, Betsy L. Humphreys, andAlexa T. McCray.
1993.
The Unified Medical Lan-guage System.
Methods of Information in Medicine,32:281?291.Xiaoqiang Luo.
2005.
On coreference resolutionperformance metrics.
In In Proc.
of HLT/EMNLP,pages 25?32.Alexa T. McCray, Anita Burgun, and Olivier Boden-reider.
2001.
Aggregating UMLS semantic typesfor reducing conceptual complexity.
Proceedings ofMedinfo, 10(pt 1):216?20.Makoto Miwa, Paul Thompson, and Sophia Ana-niadou.
2012.
Boosting automatic event ex-traction from the literature using domain adapta-tion and coreference resolution.
Bioinformatics,28(13):1759?1765.Ngan L. T. Nguyen, Jin-Dong Kim, Makoto Miwa,Takuya Matsuzaki, and Junichi Tsujii.
2012.
Im-proving protein coreference resolution by simple se-mantic classification.
BMC Bioinformatics, 13:304.Philip V. Ogren.
2010.
Improving Syntactic Coor-dination Resolution using Language Modeling.
InNAACL (Student Research Workshop), pages 1?6.The Association for Computational Linguistics.T.I.
Oprea, S.K.
Nielsen, O. Ursu, J.J. Yang,O.
Taboureau, S.L.
Mathias, L. Kouskoumvekaki,L.A.
Sklar, and C.G.
Bologa.
2011.
Associat-ing Drugs, Targets and Clinical Outcomes into anIntegrated Network Affords a New Platform forComputer-Aided Drug Repurposing.
Molecular in-formatics, 2-3(30):100?111.Thomas C. Rindflesch, Lorrie Tanabe, John N. We-instein, and Lawrence Hunter.
2000.
EDGAR:Extraction of drugs, genes, and relations from thebiomedical literature.
In Proceedings of PacificSymposium on Biocomputing, pages 514?525.Isabel Segura-Bedmar, Mario Crespo, C?esar de Pablo-S?anchez, and Paloma Mart??nez.
2010.
Resolvinganaphoras for the extraction of drug-drug interac-tions in pharmacological documents.
BMC Bioin-formatics, 11 (Suppl 2):S1.J.C.
Smith, J.C. Denny, Q. Chen, H. Nian, A.
3rdSpickard, S.T.
Rosenbloom, and R. A. Miller.
2011.Lessons learned from developing a drug evidencebase to support pharmacovigilance.
Applied clinicalinformatics, 4(4):596?617.
?Ozlem Uzuner, Imre Solti, and Eithon Cadag.
2010.Extracting medication information from clinicaltext.
JAMIA, 17(5):514?518.
?Ozlem Uzuner, Andrea Bodnari, Shuying Shen, TylerForbush, John Pestian, and Brett R. South.
2012.Evaluating the state of the art in coreference res-olution for electronic medical records.
JAMIA,19(5):786?791.Marc B. Vilain, John D. Burger, John S. Aberdeen,Dennis Connolly, and Lynette Hirschman.
1995.A model-theoretic coreference scoring scheme.
InMUC, pages 45?52.Bonnie L. Webber.
1988.
Discourse Deixis: Referenceto Discourse Segments.
In ACL, pages 113?122.Rong Xu and QuanQiu Wang.
2014.
Large-scale com-bining signals from both biomedical literature andthe FDA Adverse Event Reporting System (FAERS)to improve post-marketing drug safety signal detec-tion.
BMC Bioinformatics, 15:17.Katsumasa Yoshikawa, Sebastian Riedel, Tsutomu Hi-rao, Masayuki Asahara, and Yuji Matsumoto.
2011.Coreference Based Event-Argument Relation Ex-traction on Biomedical Text.
Journal of BiomedicalSemantics, 2 (Suppl 5):S6.Jiaping Zheng, Wendy W. Chapman, Rebecca S. Crow-ley, and Guergana K. Savova.
2011.
Corefer-ence resolution: A review of general methodologiesand applications in the clinical domain.
Journal ofBiomedical Informatics, 44(6):1113?1122.Qian Zhu, Robert R. Freimuth, Jyotishman Pathak,Matthew J. Durski, and Christopher G. Chute.
2013.Disambiguation of PharmGKB drug-disease rela-tions with NDF-RT and SPL.
Journal of BiomedicalInformatics, 46(4):690?696.53
