ON THE SUCCINCTNESS PROPERTIESOF  UNORDERED CONTEXT-FREE GRAMMARSM.
Drew Moshier and William C. RoundsElectrical Engineering and Computer Science DepartmentUniversity of MichiganAnn Arbor, Michigan 481091 AbstractWe prove in this paper that unordered, or ID/LPgrammars, are e.xponentially more succinct han context-free grammars, by exhibiting a sequence (L,~) of finitelanguages uch that the size of any CFG for L,~ mustgrow exponentially in n, but which can be described bypolynomial-size ID/LP grammars.
The results have im-plications for the description of free word order languages.2 In t roduct ionContext free grammars in immediate dominance andlinear precedence format were used in GPSG \[3\] as a skele-ton for metarule generation and feature checking.
It is in-tuitively obvious that grammars in this form can describelanguages which are closed under the operation of takingarbitrary permutations of strings in the language.
(Suchlanguages will be called symmetric.)
Ordinary context-free grammars, on the other hand, "seem to require thatall permutations of right-hand sides of productions be ex-plicitly listed, in order to describe certain symmetric lan-guages.
For an explicit example, consider the n-letter al-phabet E,~ = {al .
.
.
.
.
a,~}.
Let P,~ be the set of all stringswhich are permutations of exactly these letters.
It seemsobvious that no context-free grammar could generate thislanguage without explicitly listing it.
Now try to provethat this is the case.
This is in essence what we do in thispaper.
We also hope to get the audience for the paperinterested in why the proof works!To give some idea of the difficulty of our problem, webegin by recounting Barton's results \[1\] in this confer-ence in 1985.
(There is a general discussion in \[2\].)
Heshowed that the universal recognition problem (URP) forID/LP grammars is NP-complete.
1 This means that ifP :~ NP ,  then no polynomial algorithm can solve thisproblem.
The difficulty of the problem seems to arisefrom the fact that the translation from an ID/LP gram-mar to a weakly equivalent CFG blows up exponentially.It is easy to show, assuming P ~ NP,  that any reason-able transformation from ID/LP grammars to equivalentCFGs cannot be done in polynomial time; Rounds hasdone this as a remark in \[8\].
In this paper, we removethe hypothesis P ~: NP .
That is, we can show that noalgorithm whatever can effect the translation polynomi-The universal recognition problem is to tell for an ID/LP gram-mar G and a string w, whether  or  not w E L(G).ally in all cases.
(Unfortunately, this does not solve theP - NP  question!
)Barton's reduction took a known NP-complete prob-lem, the vertex-cover problem, and reduced it to the URPfor ID/LP.
The reduction makes crucial use of grammarswhose production size can be arbitrarily large.
Define thefan-out of a grammar to be the largest total number ofsymbol occurrences on the right hand side of any produc-tion.
For a CFG, this would be the maximum length ofany RHS; for an ID/LP grammar, we would count sym-bols and their multiplicities.
Barton's reduction does thefollowing.
For each instance of the vertex cover problem,of size n, he constructs a string w and an ID/LP grammarof fanout proportional to n such that the instance has avertex cover if and only if the string is generated by thegrammar.
He also notes that if all ID/LP grammars havefanout bounded by a fixed constant, then the URP canbe solved in polynomial time.This brings us to the statement of our results.
Let Pnbe the language described above.
Clearly this languagecan be generated by the ID/LP grammarS - -  a l , .
.
.
, anwhose size in bits is O(n log n).Theorem 1 There is a constant c > I such that anycontezt-free gr.mmar Gn generating Pn must have size~(cn).
2 Moreover, every \ [D/LP grammar'generating pn,whose fanout is bounded by a fized constant, must likewisehave ezponential size.The theorem does not actually depend on having avocabulary which grows with n. It is possible to codeeverything homomorphically into a two-letter alphabet.However, we think that the result shows that ordinaryCFGs, and bounded-fanout ID/LP grammars, are inade-quate for giving succinct descriptions of languages whosevocabulary is open, and whose word order can be veryfree.
Thus, we prefer the statement of the result as it is.We start the paper with the technical results, in Sec-tion 3, and continue with a discussion of the implicationsfor linguistics in Section 4.
The final section containsa proof of the Interchange Lemma of Ogden, Ross, andWinklmann \[7\], which is the main tool used for our re-suits.
This proof is included, not because it is new, butbecause we want to show a beautiful example of the use of2This notation meam.s that for inKnitely ram W n, the size of Gnmust  be bigger than c n.112combinatorial principles in formal inguistics, and becausewe think the proof may be generalized to other classes ofgrammars.3 Technical ResultsAs we have said, our basic tool is the InterchangeLemma, which was first used to show that the "embeddedreduplication" language {wzzy  I w, z, and y E {a, b, c}" }is not context-free.
It was also used in Kac, Manaster-Ramer, and Rounds \[6\] to show that English is not CF,and by Rounds, Manaster-Ramer, and Friedman to showthat reduplication even over length n strings requirescontext-free grammar size exponential in n. The cur-rent application uses the last-mentioned technique, butthe argument is more complicated.We will discuss the Interchange Lemma informally,then state it formally.
We will then show how to apply itin our case.The IL relies on the following basic observation.
Sup-pose we have a context-free language, and two strings inthat language, each of which has a substring which is theyield of a subtree labeled by the same nonterminal sym-bol at the respective roots of the subtrees.
Then thesesubstrings can be interchanged, and the resulting stringswill still be in the language.
This is what distinguishesthe IL from the Pumping Lemma, which finds repeatednonterminals in the derivation tree of just one string.The next observation about the IL is that it attemptsto find these interchangeable strings among the length nstrings of the given language.
Moreover, we want to finda whole set of such strings, such that in the set, the inter-changed substrings all have the same length, and all startat the same position in the host string.
The lemma letsus select a number m less than n, and tells us that thelength k of the interchangeable substrings is between roleand m, where r is the fanout of the grammar.
Finally, thelemma gives us an estimate of the size of the interchange-able subset.
We may choose an arbitrary subset Q(n) ofL(n), where L(n) is the set of length n strings in the lan-guage L. If we also choose an integer m < n, then theIL tells us that there is an interchangeable s t A C_ Q(n)such that IAI _> IQ(n)I/(INI" n=), where the vertical barsdenote cardinality, and N is the set of nonterminals ofthe given grammar.
(The interchanged strings do notstay in Q(n), but they do stay in L(n). )
Notice thatif Q(n) is exponential in size, then A will be also.
Thus,if a language has exponentially many strings of lengthn then it will have an interchangeable subset of roughlythe same exponential size, provided the set of nontermi-nals of the grammar is small.
Our proof turns this ideaaround.
We show that any CF description of the permu-tation language L(n) must have an exponentially largeset of nonterminals, because an interchangeable subset ofthis language cannot be of the same exponential order asn!, which is the size of L(n).Now we can give a more formal statement of thelem/'fla.Definition.
Suppose that A is a subset {zl .
.
.
.
.
-p}of L(n).
A has the k-interchangeability property iff thereare substrings Zh .
.
.
,  z v of zl, .
.
.
,  z v respectively, suchthat each z, has length k, each z~ occurs in the samerelative position in each zi, and such that if z~ = wiziy(and z i = wjziV j for any i and j, then wi~jVl is an elementof L(n).In terchange Lemma.
Let G be a CFG or ID/LPgrammar with fanout r, and with nonterminal alphabetN.
Let m and n be any positive natural numbers withr < m_< n. Let L(n) be the set of length nstr ings inL(G), and Q(n) be a subset of L(n).
Then we can finda k-interchangeable subset A of Q(n), such that m/r  <_k _< m, and such thatIal >_ IQ(n)l l  ( INI" n2).Now we can prove our main theorem.
First we showthat no CFG of fanout 2 can generate L(n) without anexponential number of nonterminals.
The theorem forany CFG then follows, because any CFG can be trans-formed, into a CFG with fanout 2 by a process essentiallylike that of transforming into Chornsky normal form, butwithout having to eliminate e-productions or unit produc-tions.
This process at most cubes the grammar size, andthe result follows because the cube root of an exponen-tial is still an exponential.
The proof for bounded-fanoutID/LP is a direct adaptation of the proof for fanout 2,which we now give.Let Pn be the permutation language above, and letG be a fanout 2 grammar for this language.
Apply theInterchange Lemma to G, choosing Q(n) = P~, r = 2,and m = n/2.
(n will be chosen as a multiple of 4.
)Observe that IQ(n)l = IL(n)\[ = n!.
From the IL, we get ak-interchangeable subset A of L(n), such that n/4 < k <n/2, and such thatn!IAI _> INI" n'-"Next we use the fact that A is k-interchangeable to get anupper bound on its cardinality.
Let wtztyt  and w~.=~.y~.be members of A, and let E(z) be the set of alphabetcharacters appearing in z.
We claim that E(zl) = ~(z~_).For if, say =t has a character not occurring in z~., thenthe interchanged string wtz2yl will have two occurrencesof that character, and thus not be in L(n), as required bythe IL.
Without loss of generality, ,.V.
(z) = {al .
.
.
.
.
ak}.The number of strings in A is thus less than or equal tothe number of ways of selecting the z string - that is, k!,times the number of ways of choosing the characters inthe rest of the string - that is, (n - k)!.
In other words,IAI < k!
(n - k)!.Putting the two inequalities together and solving for IN\[,113we getINI > k!
(n - k)! "
n "W = n -~" "From Pascal's triangle in high school mathematics, (i) in-creases with k until k - n/2.
Thus since n/4 < k < n/2,we have (i) > (n~4), which by using Stirling's approxi-mationm!
".., mm e-m~/27rmto estimate the various factorials, grows exponentiallywith n. Therefore, so does IN\[, and our theorem isproved.To obtain the result for a two-letter alphabet, con-sider the homomorphism sending the letter aj into 0 j 1.Let Ii'n be the image of Pn under this mapping.
Then,because the mapping is one-to-one, P.  is the inverse ho-momorphic image of Kn.
If for every c > 1 there is asequence of CFGs Gn generating K,  such that the size ofG,~ is not ft(c"), then the same is true for the languagePn, contradicting Theorem I.
The reason is that the sizeof a grammar for the inverse homomorphic image of alanguage need only be polynomiaUy bigger than the sizeof a grammar for the language itself.
The proof of thisclaim rests on inspection of one of the standard proofs,say Hopcroft and Ullman \[5\].
The result is proved us-ing pushdown automata, but all conversions from pdasto grammars require only polynomial increase in size.Our final technical result concerns an n-symbol ana-logue of the so-called MIX  language, which has been con-jectured by Marsh not to be an indexed language (see\[4\] for discussion.)
We define the language M,  to be theset of all strings over En which have identical numbersof occurrences of each character al in En.
Observe that/I,I,~ is infinite for each n. However, there is a sequence offinite sublanguages of the various Mn, such that this se-quence requires exponentially increasing context-free de-scriptions.
~Ve have the following theorem.Theorem 2 Consider the set Mn(n=) of all length n 2strings of Mn.
Then there is a constant c > 1 such thatany context.free grammar Gn generating Mn(n 2) musthave sue f~(cn).Proof.
This proof is really just a generalization of theproof of Theorem 1.
It uses, however, the Q subsets in away that the proof of Theorem 1 does not.First, we drop the n subscript in Mn(n2).
Observenext that in every string in M(n2), each character in Enoccurs exactly n times.
Let O(n 2) = {u '~ : lul - n} bethe subset of M(n 2) where, as indicated, each string iscomposed of n identical substrings concatenated in or-der.
Then each u substring must be a permutation ofE , ,  i.e., a member of P, .
Let Gn be a fanout 2 gram-mar generating M(n2).
As in the proof of Theorem I,apply the Interchange Lemma to G,~, choosing ~(n 2) asabove, r - 2, and m -- n/2.
Observe that we still haveIQ(n2)l - n!.
From the IL, we get a k-interchangeablesubset A of Q(n2), such that n/4 < k < n/2, and suchthatn!IAI _> I/Vl.
n4Once again we use the fact that A is k-interchangeableto get an upper bound on its cardinaiity.
Let wlztyland w2z2y2 be members of .4, and let E(z) be the setof alphabet characters appearing in z.
We claim onceagain that E(zt) - Z(z2).
To see this, notice that thez portions of the strings in A can overlap at most one ofthe boundaries between the successive u strings, because\]u\] -- n and \[z\[ <_ n/2.
If it does not overlap a bound-ary, then the reasoning is as before.
If it does overlap aboundary, then we claim that the characters in z occur-ring to the right of the boundary must all be differentfrom the characters in z to the left.
This is because ofthe "wraparound phenomenon": the u strings are iden-tical, so the z characters to the right of the boundaryare the same characters which occur to the right of theprevious u-boundary.
Since each u is a permutation ofEn, the claim holds.
The same reasoning now applies toshow that r-(zt) - E(z2).
For if, say, zt has a charac-ter not occurring in z2, then one of the u-portions of theinterchanged string wxz2yx will have two occurrences ofthat character, and thus not be in M(n~), as required bythe IL.
Without loss of generality, E(z) - {at ..... a~}.The number of strings in A is less than or equal to thenumber of ways of selecting one of the u strings.
Considerthe u string to the left of the boundary which z overlaps.Because of wraparound, this u string is still determinedby selecting k positions in the z, and then choosing thecharacters in the remaining n - k positions.
Thus we stillhaveIAI < k!
(n - k)!and we finish the proof as above.4 D iscuss ionWhat  do Theorems I and 2 literally mean as far aslinguistic descriptions are concerned?
First, we noticethat the permutation language P,~ really has s countingproperty: there is exactly one occurrence of each sym-bol in any string.
The same is true if we consider, forfixed m, the strings of length mn in Mn, as n varies.Here there must be exactly m occurrences of each symbolin En, in every string.
It seems unreasonable to requirethis counting property as a property of the sublanguagegenerated by any construction of ordinary language.
Forexample, a list of modifiers, say adjectives, could allowarbitrary repetitions of any of its basic elements, and notinsist that there be at most one occurrence of each modi-fier.
So these examples do not have any direct, naturallyoccurring, linguistic analogues.
It is only if we wish todescribe permutation-like behavior where the number ofoccurrences of each symbol is hounded, but with an un-114bounded number of symbols, that we encounter difficul-ties.The same observation, however, applies to Barton'sNP-cornpleteness result.
Exactly the same counting prop-erty is required to make the universal recognition problemintractable.
If we do not insist on an n-character alpha-bet, of course, then the universal recognition problem isonly polynomial for ID/LP grammars; and correspond-ingly, there is a polynomial-size weakly equivalent CFGfor each ID/LP grammar.
But even with a growing al-phabet, it is still possible that direct ID/LP recognitionis polynomial on the average.
One way to check this pos-sibility empirically would be to examine long utterances(sentences) in actual fragments of free word-order lan-guages, to see whether words are repeated a large num-ber of times in those utterances.
If there is a bound, andif all permutations are equally likely, then the above re-sults may have some relevance.
It is definitely the casethat speculations about the difficulty of processing theselanguages should be informed by more actual data.
How-ever, it is equally true that the conclusions of a theoreticalinvestigation can suggest what data to collect.5 Proo f  o f  the  ILHere we repeat the proof of the IL due to Ogden et alIt is an excellent example of the combinatory fact knownas the Pigeonhole Principle.
As we said, we want to en-courage more cooperation between theoretical computerscience and linguistics, and part of the way to do this is togive a full account of the techniques used in both areas.First we restate the lemma.Interchange Lemma.
Let G be a CFG or ID/LPgrammar with fanout r, and with nonterminal alphabetN.
Let m and n be any positive natural numbers withr < m <_ n. Let L(n) be the set of length n strings inL(G), and Q(n) be a subset of L(n).
Then we can finda k-interchangeable subset .4 of ~(n), such that m/r <k _< m, and such thatIAI >_ IQCn)I/( I .
'Vl ?
r ib .Proof.
The proof breaks into two distinct parts: oneinvolving the Pigeonhole Principle, and another involvingan argument about paths in derivation trees with fanoutr.
The two parts are related by the following definition.Fix n, r, and m as in the statement of the IL.
Atuple (j, k, B), where j and k are integers between i andn, and where B E N, is said to describe a string z oflength n, if (i) there is a (full) derivation tree for z inG, having a subtree whose root is labeled with B, andthe subtree exactly covers that portion of z beginning atposition j, and having length k; and (ii) k satisfies theinequality stated in the conclusion of the IL.
Notice thatif one tuple describes every string in a set A, then, sinceG is context-free, A is k-interchangeable.The part of the proof involving derivation trees cannow be stated: we claim that every string : in L(G) hasat least one tuple describing it.
To see that this is true,execute the following algorithm.
Let z E L(G).
Beginat the root (S) node of a derivation tree for :, and makethat the "current node."
At each stage of the algorithm,move the current node down to a daughter node havingthe longest possible yield length of its dominated subtree,while the yield length of the current node is strictly biggerthan m. Let B be the label of the final value of the currentnode, let j be the position where the yield of the finalvalue of the current node starts, and let k be the lengthof that yield.
By the algorithm, k <_ m. If k < m/r, thensince the grammar has fanout r, then the node above thefinal value of the current node would have yield lengthless than m, so it would have been the final value of thecurrent node, a contradiction.
This establishes the claim.Now we give the combinatory part of the proof.
LetE and F be finite sets, and let J~ be a binary relation (setof ordered pairs) between E and F. R is said to coverF if every element of F participates in at least one pairof R. Also, we define, for e E E, R(e) = {f \] e R f}.One version of the Pigeonhole Principle can be stated asfollows.Lemma 1 I f  R covers F, then there is an element e E Esuch thatIR(e)l > \[FI/IEI-Proof: Since R covers F, we knowIFI _< ~ IR(e)lereIf \]R(e)\[ < IFI/IEI for every e, thenIFI < ~"~(IFI/lED = IFI,eEEa contradiction.Now let E be the set of all tuples (j, k, B) where jand k are less than or equal to n, and B E N. Then\]E\[ = iN\[.
n 2.
Let F = Q(n).
Let e R f iff e describes f.By the first part of our proof, R covers F. Thus let e be atuple given by the conclusion of the Pigeonhole Principle,and let A be R(e).
The size of .4 is correct, and sincee describes everything in A, then A is k-interchangeable.This completes the proof and the paper.References\[1\] Barton, G.E, Jr., The Computational Difficulty ofID/LP Parsing.
Proc.
23rd Ann.
Meeting of ACL ,July 1985, 76-81.\[2\] Barton, G.E., Jr., R.C.
Berwick, and E.S.
Ristad,Computational Complezity and Natural Language.MIT Press, Cambridge, Mass., 1986.115\[3\] Gazdar, G. Klein, E., Pullum, G., and Sag, I., Gen-eralized Phrase Structure Grammar.
Harvard Univ.Press, Cambridge, biass., 1985.\[4\] Gazdar, G., Applicability of Indexed Grammars toNatural Languages, CSLI report CSLI-85-34, Stan-ford University, 1985.\[5\] Hopcroft, J., and J. Ullman, Introduction toAutomata Theory, Languages, and Computation,Addison-Wesley, Reading, Mass., 1979.\[6\] Kac, M., Manaster-Karner, A. and Rounds,W., Simultaneous-Distributive Coordination andContext-Freedom, Computational Linguistics, to ap-pear 1987.\[7\] Ogden, William, Rockford J. Ross, and Karl Winkl-mann, An 'interchange l mma' for context-free lan-guages.
SlAM Journal of Computing 14.410-415,1985.\[8\] Rounds, W., The Relevance of Complexity Results toNatural Language Processing, to appear in Process-ing of Linguistic Structure, P. Sells and T.
Wasow,eds., MIT Press.\[9\] Rounds, W., A. Manaster-Rarner, and J. Friedman,Finding Formal Languages a Home in Natural Lan-guage Theory, in Mathematics of Language, ed.
A.Manaster-Rarner, John Benjamins, Amsterdam, toappear.116
