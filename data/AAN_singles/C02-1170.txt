A Pattern-Based Analyzer for French in the Context of SpokenLanguage Translation: First Prototype and EvaluationHerv?
BLANCHONGETA-CLIPS (IMAG)BP 5338041 Grenoble Cedex 9, Franceherve.blanchon@imag.frAbstractIn this paper, we describe a first prototype ofa pattern-based analyzer developed in thecontext of a speech-to-speech translationproject using a pivot-based approach (thepivot is called IF).
The chosen situationinvolves a French client talking to an Italiantravel agent (both in their own language) toorganize a stay in the Trentino area.An IF consists of a dialogue act, and a list,possibly empty, of argument values.
Theanalyzer applies a "phrase spotting"mechanism on the output of the speechrecognition module.
It finds well-formedphrases corresponding to argument values.A dialogue act is then built according to theinstantiated arguments and some otherfeatures of the input.The current version of the prototype hasbeen involved in an evaluation campaign onan unseen corpus of four dialoguesconsisting of 235 speech turns.
The resultsare given and commented in the last part ofthe paper.
We think they pave the way forfuture enhancements to both the coverageand the development methodology.R?sum?Dans cet article, nous d?crivons la premi?reversion d'un analyseur fond?
sur des patronsdans le contexte d'un projet de traduction deparole utilisant une technique de traductionpar pivot (le pivot est appel?
IF).
Dans lasituation choisie, un client fran?ais parleavec un agent italien (chacun dans sa languematernelle) pour organiser un s?jour dans lar?gion du Trentin en Italie.Une IF se compose d'un acte de dialogue etd'une liste, ?ventuellement vide, de valeursd'arguments.
L'analyseur met en ?uvre unm?canisme de reconnaissance de syntagmessur la sortie du module de reconnaissance dela parole.
Cela permet de trouver dessyntagmes bien form?s qui correspondent ?des valeurs d'arguments.
L'acte de parole estalors construit en utilisant les argumentsinstanci?s ainsi que d'autres caract?ristiquesde l'entr?e.Cette version du prototype a ?t?
mis en?uvre lors d'une ?valuation sur un corpus dequatre dialogues, non utilis?s pour led?veloppement, compos?
de 235 tours deparole du client.
Les r?sultats sont donn?sdans la derni?re section de cet article.
Nouspensons qu'ils ouvrent la voix pour defutures am?liorations de la couverture ainsique de la m?thodologie de d?veloppement.IntroductionIn the framework of the NESPOLE!
project[Besacier, L., & al., 2001; Lazzari, G., 2000]funded by the EU and the NSF we are exploringfuture applications of automatic speech-to-speech translation in the e-commerce and e-services areas.
For the actual translation we areusing a pivot-based approach (the pivot is calledIF for Interchange Format).
Thus, we have todevelop the analysis from the textual output ofan automatic speech recognition module towardsthe IF and the generation from the IF towards atext-to-speech input text.In this context, the analyzer has to be robustagainst ill-formed input (in terms of syntax) andrecognition errors, both likely to be quitecommon.
To cope with these problems severalfamilies of methods may be used: a rule-basedapproaches with rules being relaxed if needed, a?let the number do every thing?
approaches(using aligned source language inputs andtheir pivot representations), a pattern-based approaches (focusing on importantfeatures of the input), and finally amixture of the previous ones.Taking into account the way the pivotrepresents the information present in the inputand the possible methods, we chose toinvestigate a pattern-based approach (as in[Zong, C., & al., 2000]).
In this paper we willfocus on the first prototype of an analysismodule from French to a pivot called IF(Interchange Format).
We will justify ourchoices with regard to the pivot specificationand describe the realization; finally we will giveseveral numbers about an evaluation thisanalyzer was involved in.1 Context and choices1.1 Interchange FormatThe IF we are currently using is an extension ofthe one used in the C-STAR II context [Levin,L., & al., 2000; Levin, L., & al., 1998].
It isdesigned to abstract away from peculiarities ofany particular language in order to allow fortranslation that are non-literal but capture thespeaker?s intent.The IF is based on domain actions (DAs) thatconsist of speech act and concepts.
We havecurrently defined 62 general speech acts (e.g.acknowledge, introduce-self, g i v e -information,).
The concepts are split into 9attitudes (e.g.
disposition, feasibility,obligation), and 97 main predications orpredication participants (e.g.
price , room,activity).In addition to the DA, an IF representation maycontain arguments (e.g.
disposition, price,room-spec).
The arguments have values thatrepresent information about the speech acts andthe concepts.
There is currently about 280arguments, 150 of them being top-level (e.g.disposition, p r i c e , room-spec).
Theothers arguments do not exist on their own, theyare embedded within the top-level arguments(e.g.
quantity, currency, identifiability).For an utterance meaning "je voudrais lachambre ?
70 euros"1 the IF would be:c: indicates that the client is speaking.
give-information+disposition+price+room isthe DA.
disposition, price, room-spec arethe top-level arguments.
quantity, currency,identifiability are embedded arguments.1.2 ConstaintsThe IF specification is giving constraints on theconstruction of an IF at each levels.Speech acts are defined with their possibleconcept continuations (e.g.
disposition,price, availability concepts may followgive-information ) and their licensedarguments (rhetorical relations, e.g.
cause ,conjunction, disjunction).
Concepts arealso defined with their possible continuations(e.g.
accommodation, room , activityconcepts may follow price) and arguments(e.g.
for-whom, price, time arguments maybe arguments of price).Arguments are defined by their possible value,relations and attributes.
The value may bequestion (the argument is questioned) or a setof actual values (e.g.
double, single, twinfor a room-spec).
It is also possible to handlerelatives and pronouns.
Relations define linksbetween two concepts (e.g.
bed-spec,location , p r i c e  for a room-spec).Attributes define links between a concept and aset of values (e.g.
quantity, identifiability).An attribute is defined only with a value andattributes, no relation.1.3 ChoicesWe had to choose a methodology for theanalysis from a speech recognition outputtowards an IF and the generation form an IF to aFrench text.For the generation it was decided to apply a rule-based approach under Ariane-G5 [Boitet, C.,1997].
We are using the IF specification files to1 "I would like the room that costs 70 euros"c:give-information+disposition+price+room( disposition=(who=i, desire),price=(quantity=70, currency=euro),room-spec=(identifiability=yes, room))automatically produce parts of the dictionariesand the grammars.
The IF is parsed into aFrench linguistic tree passed to a general-purpose French generation module.
Thisapproach forces us to develop a specification asclean as possible describing all the possible"events".
At the end, every potential IF inputshould be covered.
The drawbacks of thisapproach are the bootstrapping process, whichtakes a huge amount of time, and the continuouschanges in the IF specification we have to copewith.
For the generation, we are alsoexperimenting a pattern-based approach inwhich DA families are associated with templatesentences (a fill in the blanks sentence).
Ifpossible, the blanks are filled, with the Frenchphrase associated with the right argument value.For the analysis we are also pursuing two tracks.When the generation module will be availablewe are thinking of reversing the process to buildan analysis module (an analyzer realized for C-STAR II is described in [Blanchon, H. andBoitet, C., 2000, Boitet, C. and Guilbaud, J.-P.,2000]).
We are also using a pattern-basedapproach that is very convenient to deal with theoutput that may be produced by the speechrecognition module.
The operation of theanalyzer can be viewed as "phrase spotting"among the input so that insertion, deletion, andwrong agreements and word can be dealt with.The source code is written in Tcl with anintensive use of regular expressions matching.The next section is dedicated to this module.2 Overall processThe French to IF process is divided in four mainsteps.
The input text is first split into semanticdialogue units (SDUs2).
The topic of each SDUis then searched out.
According to the topic, thepossible arguments are then instantiated.
Finally,the Dialogue Act is built using the instantiatedarguments and some other features of the SDU.2.1 Turns splitting into SDUTo split the output of the ASR we are usingboundaries: simple phrases and articulations.2 An SDU is a part of an utterance that can beanalyzed into an unique IF.Simple phrases give speech acts withoutcontinuation.
They are classified into:- affirmations (e.g.
oui c'est ?a, bien s?r)3,- negations (e.g.
non pas du tout, non pas tr?sbien, non)4,- acknowledgments (e.g.
c'est d'accord, c'estok, c'est bien, ok, oui)5,- apologies (e.g.
excusez-moi, d?sol?, pas dequoi)6,- exclamations (e.g.
c'est excellent, tr?s bien,oh)7,- greetings (e.g.
bonjour, au revoir, bonnejourn?e)8,- dialogue management (e.g.
all?, j'entends,j'?coute)9,- thanks (e.g.
merci bien, merci)10, and someothers.Articulations are realizations of the rhetoricalarguments (e.g.
simple conjunctions,conjunction phrases) followed by a pronoun orthe beginning of a question (e.g.
et donc je, etpuis il, et j', donc on, est-ce que, quel est)11.Some thirty regular expressions are used for thesplitting.
Examples are given in annex 1.2.2 Topic detectionHere, the goal is to find either the terminalspeech act for the SDU (e.g.
apologize,contradict, exclamation, greeting) orwhat is the SDU talking about (e.g.a c c o m m o d a t i o n , r o o m , a c t i v i t y,attraction, price).A list of expressions and/or words is associatedwith the terminal speech acts (e.g.
bonjour,salut, ?
bient?t, bonsoir , au revoir,enchant?, ?
plus tard, ?
plus, bonnejourn?e for the greeting)12 and with the3 yes that it, of course4 no not at all, no not very well, no5 it's ok, it's ok, that's right, ok, yes6  excuse me, sorry, you are welcome7 that's excellent, very good, oh8 hello, good bye, have a good day9 hello, I can hear, I am listening10 thank you very much, thank you11 and thus I, and then I, and I, so we, is ?, what is12 hello, hi, see you soon, good evening, good bye,delighted, see you later, see you later (casual),have a good dayother topics (e.g.
place de camping, sallede conf?rence, chambre double, chambresimple, suite, ?
for room)13.The instantiated topic is the first matched one inthe utterance.
If there is no match, the topic isset to ?unknown?.
The latter concerns fragmentswith no explicit topic given (e.g.
an utterancecontaining only "1 3 5 7") or topics not handledyet.
There are currently 30 topics defined.2.3 Arguments fillingA Topic2If function is then in charge of findingthe instantiated arguments among the possibleones for the given speech act and/or topic.
Forexample, for the room  topic some of thepossible arguments are room-spec, location,and duration.An argument filling function (Argument2If) isassociated with each defined argument.
Thosefunctions are in charge of finding a possiblerealization for its argument in the input.
It takesinto account the value, the relations andattributes.
For example for a room-spec theRoomSpec2If function (given in annex 2) istrying to locate an identifiability, aquantity and a value (the type of room).
Thisis done by trying to match a sequence made ofan identifier (e.g.
une, un, des, plusieurs)14, anumber and a room type.
The smallestacceptable sequence being a room-type.
Iffound, the French room type is translated into anIF room type through the RoomSpec2Iffunction defined in the fifservdico spacename.
The result is the IF-encoded value of theargument or an empty string.Up to now we are covering one fifth of the top-level arguments (32 over 150, the most commonones) given that the 21 rhetorical arguments and8 out of the 9 attitude arguments are not handledyet.
Considering the total number of argumentsone fourth of them (73 over 281) is handled,knowing that among the 281 arguments, there is35 synonymous definitions.2.4 Dialogue act constructionThe dialogue act is built concatenating thespeech act,  the attitudes (currently13 camping lot, conference room, twin room, singleroom, suite14 a (feminine), a (masculine), some, severaldisposition only), the main predication andthe predication participants.The speech act is calculated using informationabout ?
the verbal construction (affirmation,question, and rejection), ?
the potential negationof the predicate, ?
the potential verification orrequest for verification of the predicate.verify- request-verification-negate- negate-affirmationacceptgive-informationintroduce-topicofferresume-topicsuggestsuggest-actionquestionrequest-acceptrequest-actionrequest-informationrequest-rejectrequest-suggestionrejectionrejectoptional pathIf present, the attitude is recognized with cuephrases.
The Disposition2If function isgiven in annex 3.Then, according to the matched arguments, themain predication and predication participant arecalculated.Finally the IF is built by concatenating thespeaker (a: or c:), the dialogue act and thearguments values.3 EvaluationThe analyzer has not been evaluated on its ownyet (grading the IFs produced).
We haveperformed a set of end-to-end evaluations on thetranslation chain (analysis and generation) thatgive some information on the performances ofthe analyzer itself.
The generator, beingdeveloped in parallel with the analyzer, coversthe IFs produced by the analyzer.3.1 Evaluation suitesWe performed both mono-lingual evaluation, aswell as cross-lingual evaluation We evaluated onboth textual manually transcribed input as wellas on input from actual speech-recognition of theoriginal audio.We graded the word accuracy rate obtained bythe recognition engine.
We also graded thespeech recognized output as a "paraphrase" ofthe transcriptions, to measure the semantic lossof information due to recognition errors.In the following we will give the results formono-lingual French-to-French evaluation.
Thewhole set of results is given in [Lavie, A.
& al.2002]3.2 Data and Grading3.2.1 Data setThe French data set was made of four dialogsextracted from the NESPOLE database [Burger& al.
2000].
Two of them were related to a client/ agent discussion for organizing winter holidaysin Val di Fiemme in Italy; the two others wererelated to summer vacations in the same region.Speech signals were then re-recorded from clientturn transcriptions of these 4 dialogs (8kHzsampling rate).
This data represents 235 signalsrelated to 235 speaker turns of two differentspeakers (1 male, 1 female).
Finally, these 235speaker turns were segmented manually into 427SDUs for translation evaluation.
These turnswere also segmented automatically into 407SDUs by the SDU segmentation step of theanalyzer.
We had thus 2 sets of SDUs.3.2.2 GradingAll graders then used these segmentations inorder to assign scores for each SDU present inthe utterance.
We followed the three-pointgrading scheme previously developed for the C-STAR consortium, as described in [Levin, L. &al.
2000].
Each SDU is graded as either Perfect(meaning translated correctly and output isfluent), OK (meaning is translated reasonablycorrect but output may be disfluent), or Bad(meaning not properly translated).
We calculatethe percent of SDUs that are graded with each ofthe above categories.
Pe r f e c t  and O Kpercentages are also summed together into acategory of Acceptable translations.
Averagepercentages are calculated for each dialogue,each grader, and separately for client and agentutterances.
We then calculated combinedaverages for all graders and for all dialogues foreach language pair.3.3 ResultsIn the following tables the result are given foracceptable paraphrase (for the ASR) andacceptable translation (for monolingual andcross lingual translation).3.3.1 Results on automatic SDUsMonolingual TranslationLanguage Transcribed Speech Rec.French-to-French 62% 48%Table 1: French Monolingual End-to-End TranslationResults (Percent Acceptable) on Transcribed andSpeech Recognized Input on Analyzer's SDUs3.3.2 Results on manual SDUsSpeech RecognitionLanguage WARs Acceptable ParaphraseFrench 71.2% 65.0%Table 2: Speech Recognition Word Accuracy Ratesand Results of Human Grading (Percent Acceptable)of recognition Output as a ParaphraseMonolingual TranslationLanguage Transcribed Speech Rec.French-to-French 54% 41%Table 3: Monolingual End-to-End TranslationResults (Percent Acceptable) on Transcribed andSpeech Recognized Input3.4 CommentsOn Speech RecognitionAbout 65% of the SDUs were judged correctlyparaphrased.
This score is more informative thanthe WAR% since it means that 35% of the SDUswill not be correctly translated.
This evaluationis also a good way to check that the graders givemore or less the same scores (it is the case here).On French-to-French Monolingual TranslationAbout 54% of the SDUs were judged acceptablytranslated on the transcribed data.
Thus, weknow for sure that 46% of the SDUs will not becorrectly translated anyway.
It is thus importantto know if this percentage includes the SDUsbadly recognized by the ASR system or not.That is shown in the next paragraph.About 41% of the SDUs were judged acceptablytranslated on the speech recognized data.
Thisresult alone would have been very difficult tointerpret, but the previous results show therespective contribution of ASR and Translationto this performance.
It is an importantinformation that will be used to further improvethe system.On the Results on Automatic SDUsThe results we are producing here are isolated asthe same experiment has not been done for theother languages.
The results for French-to-French are better, +7%.
The number ofautomatically produced SDUs (407) is lowerthan the number of manually produced SDUs(427).
A careful study of the results shows thatthe perfect scores are quite the same, but thenumber of OK  scores is higher with theautomatically produced SDUs.
However, thedata have to be checked carefully to give agrounded conclusion.This phenomenon, if it is confirmed by ourpartners, may explain part of the fact that userstudies and system demonstrations indicate thatwhile the current level of translation accuracycannot be considered impressive, it is alreadysufficient for achieving effective communicationwith real users.ConclusionIn this paper we have described our firstevaluated prototype of a pattern-based analyzerfrom spoken French into IF.We have tried to show that this approach seemsvery promising.
The "phrase spotting"mechanism we implemented handle quite wellthe output of a speech recognizer whoselanguage models allows for the construction ofisolated correct segments.Having a unique construction method for eachargument and a common DA constructionpattern shared between the topics allows forreusability and easy updating of the code tofollow the regular IF specification changes.The first results we have shown are encouragingand pave the way for better results in the nextNESPOLE!
evaluation studies.AcknowledgementsOur thanks go to the graders (L. Besacier, D.Vaufreydaz, S. Mazenot, S. Rossato, A.C.Descalle), and to the CLIPS and IRST teams fortheir contribution to this paper.ReferencesBesacier, L., Blanchon, H., Fouquet, Y., Guilbaud, J.-P., Helme, S., Mazenot, S., Moraru, D. andVaufreydaz, D. (2001) Speech Translation forFrench in the NESPOLE!
European Project.
Proc.Eurospeech.
Aalborg, Denmark.
September 3-7,2001. vol.
2/4: pp.
1291-1294.Blanchon, H. and Boitet, C. (2000) Spe e chTranslation for French within the C-STAR IIConsortium and Future Perspectives.
Proc.
ICSLP2000.
Beijing, China.
Oct. 16-20, 2000. vol.
4/4:pp.
412-417.Boitet, C. (1997) GETA's metodology and its currentdevelopment towards networking communicationand speech translation in the context of the UNLand C-STAR projets.
Proc.
PACLING-97.
Ome,Japan.
2-5 September, 1997. vol.
1/1: pp.
23-57.Boitet, C. and Guilbaud, J.-P. (2000) Analysis into aFormal Task-Oriented Pivot without ClearAbstract Semantics is Best Handled as "Usual"Translation.
Proc.
ICSLP 2000.
Beijing, China.Oct.
16-20, 2000. vol.
4/4: pp.
436-439.Burger, S., Besacier, L., Metze, F., Morel, C. andColetti, P. (2001) The NESPOLE!
VoIP DialogDatabase.
Proc.
Eurospeech.
Aalborg, Denmark.September 3-7, 2001.Lazzari, G. (2000) Spoken Translation: Challengesand Opportunities.
Proc.
ICSLP 2000.
Beijing,China.
Oct. 16-20, 2000. vol.
4/4: pp.
430-435.Levin, L., Gates, D., Lavie, A., Pianesi, F., Wallace,D., Watanabe, T. and Woszczyna, M. (2000)Evaluation of a Practical Interlingua for task-Oriented Dialogue.
Proc.
Workshop of the SIG-IL,NAACL 2000.
Seattle, Washington.
April 30,2000.
6 p.Levin, L., Gates, D., Lavie, A. and Waibel, A.
(1998)An Interlingua Based on Domaine Actions forMachine Translation of Task-Oriented Dialogues.Proc.
ICSLP'98.
Syndney, Australia.
30thNovember - 4th December 1998. vol.
4/7:pp.
1155-1158.Lavie A., Metze F., Pianesi F., Burger S., Gates D.,Levin L., Langley C., Peterson K., Schultz T.,Waibel A., Wallace D., McDonough J., Soltau H.,Laskowski K., Cattoni R., Lazzari G., Mana N.,Pianta E., Costantini E., Besacier L., Blanchon H.,Vaufreydaz D., Taddei L. (2002) Enhancing theUsability and Performance of Nespole!
?
a Real-World Speech-to-Speech Translation System.
Proc.HLT 2002.
San Diego, California (USA).
March22-27, 2002.
6p.Zong, C., Huang, T. and Xu, B., (2000).
An ImprovedTemplate-Based Approach to Spoken LanguageTranslation.
Proc.
ICSLP 2000.
Beijing, China.Oct.
16-20, 2000. vol.
4/4: pp.
440-443.AnnexesAnnex 1: Regular expression for splitting into SDUsIn the following extract of the SplitHypo procedure, a sequence made of a simple sentence (leading to an if), anon-empty string, another simple sentence, and a possibly empty string is searched.If such a sequence is found, the first simple sentence is an SDU (theSDU1), the non-empty string is split intoSDUs, the second simple sentence is an SDU (theSDU2), and the possibly empty string is split into SDUs.proc SplitHypo {inWho inString} {...#simple sentence} elseif {[regexp "^ ($simplesentences) (.+?)
($simplesentences) (.
*)"$inString lMatch lFirst lSecond lThird lFourth]!=0} {append theSDU1 "{<" $inWho "> " $lFirst " }"append the_rest1 " " $lSecond " "append theSDU2 "{<" $inWho "> " $lThird " }"append the_rest2 " " $lFourthconcat $theSDU1 [SplitHypo $inWho $the_rest1] $theSDU2 [SplitHypo $inWho $the_rest2]}...}Annex 2: room-spec argument value constructionIn the following extract of the RoomSpec2If  procedure, a sequence made of a number and a roomspecification expressed in French eventually preceded by the French plural definite article les is searched.If such sequence is found then the IF argumentroom-spec=(identifiability=yes/no, quantity=quantity, room_specification) is constructedwhether the article is found or not.proc RoomSpec2If {inString} {...} elseif {[regexp "(?
:les) (\[0\-9\]+) ($fifservdico::frenchroomspec)(?:x|s)?
"$inString lMatch lQuantity lRoomSpec]!=0} {append the_result "room-spec=(identifiability=yes, quantity=" $lQuantity ", "[fifservdico::RoomSpec2If $lRoomSpec] ")"} elseif {[regexp "(\[0\-9\]+) ($frenchroomspec)(?:x|s)?
"$inString lMatch lQuantity lRoomSpec]!=0} {append the_result "room-spec=(identifiability=no, quantity=" $lQuantity ", "[fifservdico::RoomSpec2If $lRoomSpec] ")"}...}Annex 3: disposition argument value constructionIn the following extract of the Disposition2If procedure, a sequence made of a French pronoun and adisposition verb eventually surrounded by negation markers is searched.If such sequence is found then the IF argument disposition=(who=pronoun, disposition_verb) isconstructed whether the verb is negated of not.proc Disposition2If {inString} {if {[regexp "($frenchpronoun) ?
(ne |n')?
($frenchdispositionverb) (pas)?
"$inString lMatch lPron lNe lVerb lPas]!=0} {if {$lNe!="" || $lPas!="" } {append the_result "disposition=(who=" [fifservdico::NormalizePronoun2If $lPron] ", "[fifservdico::NegativDisposition2If $lVerb] ")"} else {append the_result "disposition=(who=" [fifservdico::NormalizePronoun2If $lPron] ", "[fifservdico::PositivDisposition2If $lVerb] ")"}}...} else {return ""}}
