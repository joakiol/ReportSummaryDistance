Inheritance and Complementation: A CaseStudy of Easy Adjectives and RelatedNounsDan Flickinger*Hewlett-Packard LaboratoriesJohn Nerbonne tDeutsches Forschungszentrum ffirKfinstliche IntelligenzMechanisms for representing lexically the bulk of syntactic and semantic information for a lan-guage have been under active development, as is evident in the recent studies contained in thisvolume.
Our study serves to highlight some of the most useful tools available for structured lexicalrepresentation, i  particular (multiple) inheritance, default specification, and lexical rules.
It thenillustrates the value of these mechanisms in illuminating one corner of the lexicon involving anunusual kind of complementation among a group of adjectives exemplified by easy.
The virtuesof the structured lexicon are its succinctness and its tendency to highlight significant clusters oflinguistic properties.
From its succinctness follow two practical advantages, namely its ease ofmaintenance and modification.
In order to suggest how important these may be practically, weextend the analysis of adjectival complementation in several directions.
These further illustratehow the use of inheritance in lexical representation permits exact and explicit characterizationsof phenomena in the language under study.
We demonstrate how the use of the mechanisms em-ployed in the analysis of easy enables us to give a unified account of related phenomena featuringnouns such as pleasure, and even the adverbs (adjectival specifiers) too and enough.
Alongthe way we motivate some elaborations of the HPSG (head-driven phrase structure grammar)framework in which we couch our analysis, and offer several avenues for further study of thispart of the English lexicon.1.
IntroductionThe lexicon is a large and complex set of information about the words used in agrammar or natural anguage processing system.
Its importance has become morecentral in the research of the past decade, which has seen the rise of radically lexical-ized theories uch as head-driven phrase structure grammar (HPSG), in which phrasestructure rules play a vestigial role.
Newer theories place increasingly high demandson lexical representation.
A simple calculation may illustrate the quandary of lexicalrepresentation: feature systems for contemporary s stems normally distinguish at least30 features (while 40 or 50 is not rare).
The number of values a feature takes rangesfrom 2 to the number of categories (more exactly, to the number of sequences or setsof a small size, where all the members of the sequence, etc.
are categories).
Underthe undoubtedly optimistic assumption that feature value ranges could be reduced tobooleans, we still are faced with 230 -=- 109 feature combinations--whose individual* 1501 Page Mill Road, Palo Alto, CA 94304-1126, flickinger@hplabs.hp.com.t Stuhlsatzenhausweg 3, D-6600 Saarbr/icken 11, Germany, nerbonne@dfki.uni-sb.de.
(~) 1992 Association for Computational LinguisticsComputational Linguistics Volume 18, Number 3representation is clearly to be avoided, not "solved.
''1 The natural tack is certainly torepresent just the categories actually used in the vocabulary, but this could incur agood deal of redundancy if it meant hat each feature combination were representedseparately on each word.The structured or hierarchical lexicon solves this difficulty (cf.
Flickinger, Pollard,and Wasow 1985 and Flickinger 1987).
In structured lexicons, word classes may standin a relationship of inheritance to one another, in which case the properties of thebequeathing class accrue automatically to the inheriting class.
Once we allow that asingle class may be heir to more than one bequeathing class, we allow, in principle, thatno word class property ever need be examined more than once.
Thus we eliminate onecentral source of redundancy in lexical specification.
One of the goals of this paperis to motivate the use of inheritance in lexical specification.
To do this, we take anarrowly circumscribed phenomenon i English grammar--that of vp-complement-taking adjectives, as in hard + to deliver--and spell out the lexical specifications athorough treatment demands.
The sheer complexity of these specifications cries out fora redundancy-eliminating approach, and we propose a structured lexicon treatment.The grammatical analysis not only serves to motivate the general approach, it alsoillustrates everal key issues in the design of structured lexicons, such as the use ofdefault inheritance, the need for lexical rules, and the range of phenomena menableto this sort of treatment.The goals of this paper are to introduce the structured lexicon in a fairly simpleform, to motivate its basic theoretical device, that of inheritance, with a real exampletaken from an existing system, and finally to show how the elimination of redundancyachieved with the structured lexicon aids in maintaining the lexicon.
We argue for im-proved maintainability by examining concrete xtensions and potential modificationsof the grammatical description provided.
We turn now to a brief characterization fthis phenomenon.The rich collection of syntactic and semantic phenomena exhibited by a familiargroup of adjectives uch as tough and easy present a challenge to those who seek toprovide explicit formal characterizations of linguistic properties.
We offer here a de-tailed description of the properties of these adjectives, involving optional and obliga-tory complementation, control, long-distance dependence, optional modification, andspecification.
The purpose of this description here is not the linguistic analysis itself(which we find interesting nonetheless), but rather its use in demonstrating the prac-tical utility of inheritance as a tool for linguistic description, and also the predictiveanalytical power that inheritance affords in the study of the lexicon.
In illustration ofthe latter, we extend our analysis of easy adjectives to a similar group of nouns such aspleasure, and then to the unusual adverbs too and enough, which function as specifiersin adjectival gradation.The fundamental data are illustrated in (1); examples uch as these have not at-tracted attention in computational linguistics, even if they have often appeared instudies within the generative framework.
An early discussion of them is found inMiller and Chomsky (1963), with a score and more of additional studies published inthe years since.
Most of the salient properties of these adjectives have already beenbrought o light, but in piecemeal fashion and most often as part of a larger debateabout the nature of unbounded ependencies, where detailed syntactic and seman-tic characterizations of these missing object constructions proved less important.
2 We1 Cf.
Gazdar et al 1985, Appendix for a small grammar that nonetheless exceeds the size speculated onhere.2 Related work in theoretical nd descriptive linguistics includes Chomsky (1965), Rosenbaum (1967),270Dan Flickinger and John Nerbonne Inheritance and Complementationreturn to the characteristic properties of these adjectives in Section 3, where they arecatalogued and given formal representation.
(1) a.
Bill is easy to talk to.b.
It is easy to talk to Bill.c.
Bill is easy for Mary to talk to.d.
It is easy for Mary to talk to Bill.We chose this phenomenon as a vehicle to recommend lexical inheritance becauseit illustrates a wide range of grammatical phenomena, H of which make demands onlexical resources (at least in the lexicalized grammar in which the analysis is framed).In addition to the grammatical demands, the data justify the use of a lexical rule(derivational rule) to relate pairs such as (a) and (b) in (1)--so we shall argue at anyrate--thus illustrating a further inheritance-like r lationship in the lexicon.The remainder of the paper is structured as follows: Section 2 summarizes theaspects of HPSG that are important o our proposal, and Section 3 develops the fun-damental analysis that Section 4 illustrates in a series of analytical "snapshots" of asingle example.
Section 5 suggests extensions of the fundamental nalysis, especiallyto further lexical classes (developing the argument that structured lexicons are easilymaintained and extended), and a final section summarizes and suggests directions forfuture work.
Appendix A presents the framework for lexical description developed inFlickinger et al (1985) and Flickinger (1987).
The framework is convenient for feature-based grammars, but it allows the specification of other lexical properties as well.
ThisAppendix presents a notation that is precise while avoiding redundancy, e.g., in char-acterizing the kinds of complements hat these adjectives permit, and in expressingthe relationships that hold between pairs like the easy of (la) and that of (lb).
Since afundamental c aim of hierarchical lexicons is that they eliminate redundancy and thusimprove modifiability, there is a second appendix, Appendix B, which demonstratesthe modifiability of the structured lexicon.2.
Grammatical TheoryThe phenomena involved in the analysis of the easy adjective class illustrate (obligatoryand optional) subcategorization, control, long-distance dependence, optional modifi-cation, and specification (the last in its interaction with adjectival gradation with tooand enough).
As such, it represents an excellent demonstration vehicle for the lexi-cal demands of grammatical nalysis.
Our analysis is formulated within head-drivenphrase structure grammar (HPSG), the grammatical theory developed by Carl Pol-lard and Ivan Sag during the mid and late 1980s.
See Pollard (1984; 1985; 1988; 1989)and Pollard and Sag (1987; 1988; 1991).
As the lengthy list of publications might sug-gest, this grammatical theory is well enough documented so that we may restrict ourRoss (1967), Postal (1971), Bresnan (1971), Chomsky (1973), Lasnik and Fiengo (1974), Jackendoff (1975),Chomsky (1977), Fodor (1978), Brame (1979), Nanni (1980), Schachter (1981), Jacobson (1982,pp.
221-223), Sag (1982), Maling and Zaenen (1982, pp.
253--254), Kaplan and Bresnan (1982,pp.
255-263), Culicover and Wilkins (1984), Jacobson (1984), Gazdar et al (1985, pp.
150-152), Jacobson(1990), Jones (1990), Bayer (1990), and Hukari and Levine (1991).
None of these works has attempted athorough descriptive analysis of the range of data we address here, though we are of course indebtedto these studies for much of the data and many of the generalizations we seek to express.
In particular,our account is consistent with the brief generalized phrase structure grammar (GPSG) analysis ofthese adjectives given in Gazdar et al (1985, pp.
150-152) though we embrace a larger range of dataand extend the analysis to related nouns, a topic rarely discussed since its introduction by Lasnik andFiengo (1974).271Computational Linguistics Volume 18, Number 3remarks here to the distinctive characteristics of the assumptions used here.
We assumefamiliarity with feature-based grammars and basic familiarity with HPSG as well.In all linguistic theories there is a division of labor between grammatical rulesand the lexicon, and this concerns the amount of information contained in each.
Atthe rule-based extreme lie non-feature-based context-free grammars, where the lexiconmerely links lexical items to nonterminals; in these grammars it is indeed customaryto view the lexicon as a set of unary rules.
The grammatical rules thus effectivelyencode all linguistic information.
At the lexical extreme we find feature-based catego-rial grammars, which allow function argument application as the only grammaticalrule.
Here the lexicon bears the burden of encoding linguistic information, and thecontribution of rules is marginal.
We emphasize that HPSG is found very close to thelexical extreme, because this highlights the significance of the present work--HPSG isa framework whose lexical demands are very nearly maximal.Subcategorization information is lexically based in HPSG, much as it is in Cat-egorial Grammar (Bach 1988).
Grammatical heads specify the syntactic and semanticrestrictions they impose on their complements and adjuncts.
For example, verbs andverb phrases bear a feature SUBCAT whose content is a (perhaps ordered) set of fea-ture structures representing their unsatisfied subcategorization requirements.
Thus thefeature structures associated with transitive verbs include the information:\[subcat: / \ [  NPe:acc \ ] '  \[NPcase: nom \ ] /  \](where hip abbreviates a substantial feature structure.)
Applied to adjectival VP com-plementation, this treatment of subcategorization leads naturally to the postulation ofadjectives that subcategorize for VPs, etc.
(details follow).The significance of subcategorization information is that it represents a (perhapsordered) set of grammatical categories with which a subcategorizer combines in form-ing larger phrases.
When a subcategorizer combines with a subcategorized element,the resultant phrase no longer bears the subcategorization specification--it has beendischarged.
Compare Pollard and Sag (1987, p. 71) for a formulation of the HPSGsubcategorization principle.We shall in general present subcategorization specifications in a slightly differentway from that above, i.e., not as a single feature whose value is a list, but rather as acollection of complement features with category values.
Compare Borsley (1987) fora development of this approach, which we shall not attempt o justify here.
We willtherefore reorganize the information above in the following way:subject: \[ NPcase: nom?bject: \[ NP \]case: accWe choose this representation here only because we find the keywording of gram-matical functions, subject, etc., more perspicuous than an encoding in terms of listpositions, but nothing in the analysis hinges on the one or the other representation.We shall furthermore allow that subcategorized lements be either obligatorily sub-categorized or optionally subcategorized.
Optionally subcategorized elements neednot be discharged from subcategorization specifications.
(This necessitates an obvi-ous change to the principle that subcategorization must be satisfied in independent272Dan Flickinger and John Nerbonne Inheritance and Complementationutterances.)
In case an element is not discharged, something must be said about itssemantics.
Here we borrow an idea from Situation Theory, and specify that unsatu-rated predicate argument structures (or infons; see Devlin 1991) may hold when thereis some way of filling out the unfilled argument positions o that the result holds.
Thishas the effect of existentially quantifying over unfilled argument positions.
Linguis-tically, there are many other ways in which arguments may be omitted (cf.
Fillmore1985), but this seems to suffice for the adjectives under examination here.Control and modification, the latter being the relation between an adjunct and ahead, are both lexically realized in the case of the easy adjectives.
We regard there asbeing a control relation between for Smith and toget in complex adjectivals such as easyfor Smith to get (cf.
Gazdar et al 1985: 83ff).
Modification plays a role when complexadjectivals appear in construction with nominal heads, as in easy job for Smith to get.These are common assumptions in the analyses of control and modification.Long-distance dependence is treated in HPSG in much the same way it wastreated in GPSG (cf.
Gazdar et al 1985), and we assume basic familiarity with thistype of analysis.
We recall that the site of a missing element in a "gappy" constituentbears a feature SLASH whose value is a specification of the expected material.
TheSLASH specification is propagated by general principles (which we shall not elucidate)to the higher level constituents, until it is matched by a "filler" or a subcategorizingelement.
When the gappy constituent is adjoined to a filler or subcategorizing element,the result no longer bears the SLASH value.Important for our purposes is the possibility of a lexical entry specifying that adependent may contain a gap.
(Cf.
Gazdar et al 1985, pp.
150-153 for the first mentionof this suggestion.)
We shall exploit this in the analysis of several word classes below,viz., the ones that subcategorize for a VP with an NP in SLASH.
It is unusual to finda subcategorization specification for SLASH, but not unique: comparatives likewisesubcategorize for gappy complements, as in seen in examples uch as taller than itis A wide.
We shall require lexical specifications that lead to feature structures of thefollowing form:stem: easysere: easy( ~\ ] ,  ^  ~ \ ]  )syn.loc.subcat:sub j: \[ syn: NP-nom \]sem: ~-~pp-for: \[ sem:\[-~ \]xcomp:syn: VP-infsem: ~\ ]slash: \[ sem:\[~\] \]The tag \ [~ in the diagram above shows that the semantics of the SLASH value and theadjectival subject semantics have been identified.
Thus, once a VP/NP has combinedwith this adjective, the semantic ontribution of the SLASH element is assumed bythe subject.
Figure 1 shows an analysis tree for an example containing a long-distancedependency.273Computational Linguistics Volume 18, Number 3DetYNP /\NThese booksVP / \V AdjP / \are A.djeasyVP/NP  / \V VP /NP  / \to VhaveS/NP / \NP VP /NP  /\Bob V NP/NPreadFigure 1Complex adjectivals uch as easy subcategorize for a complement VP containing a "slashed"NP, i.e., a VP missing an NP (whose expected position may be arbitrarily deep).The variety of linguistic phenomena exemplified in the easy class of adjectivesguarantees that it is a demanding testing ground for theories of lexical representation.
33.
Adjectival VP ComplementationWe assume familiarity with the mechanisms of lexical inheritance and lexical rules inthe analysis to follow, but we provide an overview of these mechanisms for lexical3 It is also worth mentioning that HPSG has also been the subject of intensive implementation activityduring the past several years; we know of implementations at Hewlett-Packard Laboratories, TheGerman AI Center (DFKI), Stanford University, Carnegie Mellon University, The Ohio State University,Simon Fraser University, University of Edinburgh, ICOT, University of Stuttgart, the IBM LILOGproject in Stuttgart, and ATR.
We may therefore safely refer the reader to documentations of thoseimplementations, even if these are less generally available than the theoretical literature: Proudian andPollard (1985), Nerbonne and Proudian (1987), Franz (1990), Emele and Zajac (1990), and Carpenter,Pollard, and Franz (1991).274Dan Flickinger and John Nerbonne Inheritance and Complernentationrepresentation in Appendix A.
The fundamental data we shall be concerned with arerepeated in (2):(2) a.b.C.d.Other adjectivesamusingannoying(3) boringcomfortableconfusingBill is easy to talk to.It is easy to talk to Bill.Bill is easy for Mary to talk to.It is easy for Mary to talk to Bill.that show this same distribution include the following:depressing great nicedifficult hard painfulexhausting important tiresomefun impossible terriblegood impressive toughGiven pairs like (2a,b) and (2c, d), two dusters of properties begin to suggest them-selves as part of the definitions of the relevant lexical entries.
The first of these clusterswe will associate with the class of words containing lexical entries for the easy of (2a,c)and its counterparts in (3), a class we term SLASH-EASY.
The other cluster of prop-erties we associate with a second class termed IT-EASY, containing the lexical entriesfor the variant of easy in (2b, d) and its counterparts in (3).
We begin by simply iden-tifying the relevant properties in each of these two classes, supported by examples asnecessary; then we provide motivation for factoring these properties into several wordclasses linked by inheritance.Adjectives in the IT-EASY class have two obligatory complements, an NP subjectand a verbal complement; in addition they have one optional complement, a PP headedby the preposition for.
As seen in (4), the verbal complement can be either infinitivalor gerundive, and (5) shows that this complement can be a VP even with a PP-forpresent, or an infinitival S, again with or without the optional PP-for complement.The subject NP must be the expletive it.
(4) a.
It was great working for Bill.b.
It was great o work for Bill.
(5) a.
It's easiest for the dogs to feed them at noon.b.
For the dogs, it's easiest o feed them at noon.c.
It's easiest for the dogs to be chained up all day.d.
*For the dogs, it's easiest o be chained up all day.e.
It's easiest for me for the dogs to be chained up all day.f.
For me, it's easiest for the dogs to be chained up all day.Examples (5e, f) demonstrate hat not only VP complementation but also S comple-mentation, is involved in easy subcategorization.
Note that S complementation neverrequires a controller, and that the PP phrase in such structures i mobile (5f).
In addi-tion to the conclusion that a variety of complementation schemes are used with easy,the data above also demonstrate hat the exact specification of the controller (the un-derstood subject of the infinitival VP) is nontrivial.
Example (5a) demonstrates that thePP-FOR complement eed not control the VP, and (5b) suggests that noncontrollingPPs are more mobile than controllers (5d).275Computational Linguistics Volume 18, Number 3We accommodate hese facts semantically by aUowing that easy and similar adjec-tives denote two-place relations between individuals and states of affairs.
The relationholds between the pair, roughly, when it is easy (or convenient) for the individualwhen the state of affairs obtains.
Examples (5e,f) show that the individual involved inthe easy relation need not be involved in the state of affairs, i.e., that there is no nec-essary semantic ontrol involved in this relation.
4 The control facts are clear enough:when this easy is combined with an S, there is no semantic ontrol; and when it is com-bined with a VP, there is no grammatically specified controller of the VP--althoughthere may be pragmatic inference about the understood subject.Adjectives in the SLASH-EASY class also have two obligatory complements, anNP subject and a verbal complement, as well as an optional PP-for complement.
Incontrast o the first class, this class specifies that the subject is a normal (nonexpletive)NP, and that the verbal complement must contain an NP gap.
Moreover, this verbalcomplement must be infinitival, not gerundive, as seen in (6), and must be a VP, notan S, as shown in (7).
5(6) a.
Bill was great to work for.b.
*Bill was great working for.
(7) a.
For me, Bill was easy to talk to.b.
*Bill was easy for me for Mary to talk to.In the word class hierarchy we assume, sketched in Appendix A, there is a wordclass CONTROL, which introduces a verbal complement subcategorization, and whichserves as the superclass from which both of the classes IT-EASY and SLASH-EASYinherit.
However, neither of these classes is an immediate subclass of CONTROL; wedraw on the data provided in (8) and (9) below to motivate two intermediate wordclasses that will stand between CONTROL and these two in the hierarchy.The English lexicon contains two more groups of adjectives that have much incommon with the two variants of easy introduced above, but must be kept distinct.Lasnik and Fiengo (1974:535) identified a set of adjectives including pretty and melodi-ous, illustrated in (8).
(8) a. Disneyland is pretty to look at.b.
Sonatas are melodious to listen to.c.
*It is pretty to look at Disneyland.d.
*It is melodious to listen to sonatas.e.
?Disneyland is pretty for children to look at.f.
?Sonatas are melodious for serious musicians to listen to.4 There is an interesting pragmatic problem lurking in the control specifications involved here.
If onespecifies the control relationships exactly, then one needs to postulate systematic structural ambi-guity in examples uch as (5c), where the sequence of PP and VP may or may not be analyzed as anconstituent.
This seems plausible, but then we would like to have a pragmatic account of why there isnormally no distinction, i.e., why the control relationship is inferred, or, equivalently for all intents andpurposes, why the S reading is so strongly preferred.5 Hukari and Levine (1991) note in passing that there is a group of closely related adjectives uch asworth that do take a gerundive complement instead of the usual infinitival complement, as in Thatarticle is not worth looking at.
The extension of our analysis to worth is straightforward, but not given here.276Dan Flickinger and John Nerbonne Inheritance and ComplernentationMembers of this class of adjectives share much in common with the SLASH-EASYadjectives, but have two significant differences: first, as shown by (8c,d), they do nothave a corresponding entry with an expletive it subject, and second, they assign a realthematic role to their subjects.
That is, (8a) entails that Disneyland is pretty, while (la)does not entail that Bill is easy.
The two-place relation suggested above for IT-EASYand SLASH-EASY adjectives could not account for the validity of this inference, sincethe subject of the adjective plays no direct role in the relation whatsoever.
A distinctsemantic relation is called for here, one in which the subject does play a role (whicheffectively makes this class a kind of EQUI adjective in contrast o the raising easy).It also appears that these adjectives do not permit the optional PP-for complementlicensed by easy in (lc), though judgments are less clear.
In order to express thesedifferences, we introduce a class SLASH-COME which will include the entries forpretty adjectives, and which will also serve as the class from which SLASH-EASYinherits.
6Similarly, English has a set of adjectives that have much in common with theIT-EASY adjectives of (lb, d), but with no counterparts of the SLASH-EASY type.
(9) a.
It is possible to talk to Bill only at breakfast.b.
It is unnecessary to fire Bill.c.
*Bill is possible to talk to only at breakfast.d.
*Bill is unnecessary to fire.The second principal difference between adjectives such as possible and those of theIT-EASY class is that the former do not permit an optional PP-for phrase complement;they do allow the verbal complement to be either a VP or an S (containing a PP-forsubject), but (10) shows that if a PP-for is present, it must be contained within thecomplement.
(lO) a.
It is unnecessary for Mary to fire Bill.
(M firing B)b.
*For Mary, it is unnecessary to fire Bill.
(M firing B)c. *It is unnecessary for Mary for you to fire Bill.Again, we express the distinction between the set of adjectives like possible and theIT-EASY adjectives by introducing a fourth class IT-SUBJ parallel to SLASH-COME 7These four class definitions, together with one supporting class, are given in (11-16), with the Superclasses attribute showing the relevant inheritance relations.
(11)IT-SUNSuperclassesComplementsSubject-FeaturesSubject-RoleXComp-featuresControl(NForm it)none(VForm Infinitival) (Complete + - )6 Other adjectives of this SLASH-COMP class include delicious, handsome, attractive, and lovely.7 Additional members of this IT-SUBJ class include essential, necessary, sad, silly, and illegal.277Computational Linguistics Volume 18, Number 3The disjunctive specification (Complete + -)  overrides the default (Complete - )specified in the CONTROL class, and means that the verbal complement may be eithera VP (Complete - )  or an S (Complete +).
This is an example of further specifying adefault specification.
(12)SLASH-COMPSuperclasses ControlComplementsXComp-Subj-SemanticsXComp-featuresx(SLASH (Category Noun)(NForm Normal)(Complete +)(Predicative - )(Case Accusative) )(SemanticsSubject-Semantics) )The SLASH feature on the XComp specifies that the VP must contain a gap fora normal (non-expletive) noun phrase, which is accusative case and which is notpredicative.
This nonpredicative specification serves to exclude examples like *Bill isdifficult to become (assuming the complement of become is predicative), since the gapfor that complement would fail to satisfy the restriction on SLASH given in (12).
TheSLASH specification furthermore notes that the SLASH semantic value is identicalto that of Subject-Semantics.
As was explained in Section 2 above, this is the form alexical specification of semantic oindexing takes.The controller of the controlled complement is specified through the attributeXComp-Subj-Semantics; for example, in CONTROL, this attribute has the value Subject-Semantics, since subjects are default controllers.
But the complements of SLASH-COMP are not grammatically controlled (cf.
(8e,f)), a fact that requires an overwritingspecification.
The semantic variable x is used here because it will not represent thesemantics of any grammatical complement, which ensures that no grammatical con-trol is effected (see examples (9a,b)).
This is an example of a subregularity appearingwithin an exceptional specification.The classes for the two variants of easy adjectives we have discussed have onecluster of properties in common: they both license the optional PP-for phrase seen inpreceding examples.
To further reduce redundancy, we define in (13) the class FOR-EXPERIENCER, from which the two classes in (14-15) also inherit.
(13)FOR-EXPERIENCERSuperclassesComplementsPP-for-FeaturesPP-for-ObligPP-for-RolePP-for(Category Preposition) (Lexical - )(PForm For)NoFor278Dan Flickinger and John Nerbonne Inheritance and Complementation(14)IT-EASYSuperclasses It-Subj, For-ExperiencerComplementsXComp-Features (VForm Infinitival Gerund)SLASH-EASYSuperclasses Slash-Comp, For-ExperiencerComplementsSubject-Role noneXComp-Subj-Semantics PP-For-Semantics(15)As expected, the IT-EASY class eases one restriction on the verbal complement;note too that no controller is specified, in keeping with remarks on (5).
On the otherhand, the SLASH-EASY class blocks inheritance of the subject's thematic role assign-ment (the default value having been specified in the INCOMPLETE class from whichCONTROL inherits), and alters the control relationship (inherited from SLASH-COMPand ultimately from CONTROL) so that the PP-For phrase rather than the subject ofeasy is interpreted as the subject of the VP complement.
These are two further examplesof the way in which default overwriting is employed; note that the latter epresents asubregularity within a subregularity (cf.
SLASH-COMP).With reasonable assumptions about the definitions of other relevant classes in thehierarchy, along with an explicit definition of the class ADJECTIVE, provided here forclarity in (16-17), we can introduce the (sparse) lexical entries for the two variants ofeasy employed in (la,b), as given in (17,18):(16)ADJECTIVESuperclasses MajorFeatures (Category Adjective) (Predicative + -)(17)easy-laSuperclasses Adjective, Slash-EasySemantics easySpelling "easy"Phonology / iz i /easy-lbSuperclasses Adjective, It-EasySemantics easySpelling "easy"Phonology / iz i /(18)279Computational Linguistics Volume 18, Number 3FOR-EXPERIENCERCONTROLITq IUBJ SLAStt-COMPIT-EASY SLASH-EASYeasy-lb easy-laADJECTIVEFigure 2The structure of word classes directly involved in the definition of complex adjectival lexicalentries.Pairs of sparse lexical entries like those in (17,18) are related by a lexical rulewe label LR-EASY, which simply states that for each member of the class IT-EASYthere exists a corresponding lexical entry belonging to the class SLASH-EASY, witheverything but the Superclasses property identical in the two (sparse) entries.RuleLR-EASY lexical ruleLR-EASYLE2-Classes - IT-EASY = LE1-Classes - SLASH-EASYOnce each of (17) and (18) are fleshed out to include all of their inherited properties,they will of course be quite distinct, as needed to ensure the differences in distributionthat we have described.
Figure 2 summarizes the inheritance relationships thus far.4.
An Example AnalysisThe purpose of this section is primarily i l lustrative--we would like to demonstrate heeffect of the lexical specifications suggested on more familiar elements of grammaticalanalysis, viz.
phrases, parse trees, and predicate logic representations.The semantics of the easy-SLASH construction, which treats easy as a relationbetween an individual and a state of affairs, is treated as a normal case of lexically in-280Dan Flickinger and John Nerbonne Inheritance and Complementationherited semantics, i.e., one in which the relation denoted has an argument place for thedenotations of each of the role-playing complements, in this case the PP-FOR phraseand the XCOMP.
This class of adjectives also has a SUBJECT among its complements,but it bears no role (as word class SLASH-EASY specifies), because this is a raisingconstruction.
For this reason, there is no argument place reserved in the semantics ofeasy-SLASH adjectives for the subject's denotation.
To conserve space in the diagramsbelow, relations will be specified not using the keyword coding shown in word classand lexical entry specifications (above), but rather in the more familiar order coding.In order to make not only the semantics but also the syntax somewhat clearerin its intended effect, we include here somewhat elaborate analytical sketches of thecomplex adjectival phrase easy to get Mary to hire in (19):(19) Tom is easy to get Mary to hire.To begin, we note that the sparse lexical entry for the SLASH-EASY version of easymay be filled out to a much richer structure if inherited properties are noted explicitly.easy-laFeaturesComplementsPP-for-FeaturesPP-for-ObligPP-for-RolePP-for-SemanticsXComp-FeaturesXComp-Subj-SemanticsXComp-ObligXComp-SemanticsXComp-RoleSubject-RoleSemanticsSpellingPhonology(Category Adjective) (Predicative + -)PP-for, Subject, XComp(Category Preposition) (Lexical - )(PForm For)NoForPP-For-Semantics(Category Verb) (Complete -)(Lexical - )(SLASH (Category Noun) (Complete +)(NForm Normal) (Predicative - )(Case Accusative) )(Semantics Subject-Semantics) )PP-For-SemanticsYesXComp-SemanticsState-of-Affairsnoneeasy"easy"/ iz i /The features noted above were specified by the lexical entry together with the classesADJECTIVE, SLASH-EASY, SLASH-COMP, FOR-EXPERIENCER, and CONTROL.
Fur-ther subject properties would be inherited from INCOMPLETE, but for brevity theseare not listed.
(Of course many other properties, including e.g., gradation propertiesand the applicability of lexical rules, have likewise been suppressed in the interest ofclarity in presentation.)
This lexical description translates fairly directly (with somefurther simplifications and abbreviations) into a feature structure of the sort used byHPSG grammars.281Computational Linguistics Volume 18, Number 3stem: easysyn.loc.head: Adjsem: easy( \ [~ ,^ \ [~)syn.loc.subcat:sub j: \[ syn: NP-nom \]sem: ~\]pp_for: \[ sY n: PP-f?r \]sem: \ [ \ ]syn: VP-infsere: ~\ ]xcomp: subject.sem: \ [~slash: \[ 2eYnm:~ -acc \]We would like to draw attention to two semantic oindexings in the structure,which are lexically specified and which simplify subsequent (grammatical) processing.The coindexing of the xcomp's ubject with the pp-for is effected in the SLASH-EASYword class, and the semantic oindexing seen above is just a consequence of that.
Thecoindexing of the xcomp's lash's semantics value with the subject's emantics, on theother hand, derives ultimately from SLASH-COMP.In Figure 3 we examine the combination of a token from this class of easy adjectivesand a VP/NP.
The very sparse specification of the mother phrase's features is, in fact,solely for purposes of legibility--all of the information specified on the mother nodemay be derived from general HPSG principles, so that nothing is specified, e.g., on therule that licenses head-complement combinations.
The fact that the semantics attributeis identified with the subcategorizer's semantics follows from the HPSG SemanticsPrinciple, which states that the semantics of a phrasal node is always to be identifiedwith the semantics of a head in a head complement combination.
The fact that theslash value of the mother structure is empty follows from the Binding InheritancePrinciple, which states that slash values are collected going up a tree--unless a headsubcategorizes for an element containing a slash value, in which case the slash satisfiesthe subcategorization requirement.
The identification of the feature structure labeledV~, which is just the representation of the phrasal node dominating to get Mary tohire, with one of the adjective's ubcategorization specifications, that labeled ~\],  isjust a condition for the applicability of the head-complement rule, not an additionalspecification.
Of course, the phrasal node is massively underspecified here, but thesuppressed information is predictable, not merely hidden.This is an intriguing aspect of HPSG, but we dwell on it here for self-servingpurposes.
If the properties of the phrasal combination of this fairly intricate syntacticstructure require no further comment, hat is largely because the lexicon has provideda wealth of richly structured representation.
This would hardly be feasible in theabsence of efficient and sophisticated lexical representation mechanisms.282Dan Flickinger and John Nerbonne Inheritance and ComplementationAdjeasyslash: 0AdjPto get Mary to hire t?
stem: easysem: \[~ easy( \[-i-\], ^ ~\] )s bj: \[som\[\] ]pp or: \[ sem:\[  \]comps: subj: \[ som:\[  \]xcomp:\[\] sem:\[\]L slash.sem: \ [ \ ]sere :  get(x,m, 1 \ [ \ ]  " hire(m, ~\]))slash.sere: \ [ \ ]Figure 3The combination of complex adjective and slashed VP complement.To complete this illustration, we spell out the effects of unification on the structureabove in Figure 4.
Note in particular that because the slash semantics on the VP phraseis identified with the slash semantics on the subcategorized-for VP, which in turn isidentified with the semantics of the subject for easy, the resultant phrase will bind itssubject o the deeply embedded object argument position of the verb hire.
This takesplace even though the subject plays no role in the easy relation itself.
This is exactlywhat is wanted semantically of a raising construction.5.
Extensions and Lexical MaintenanceThe structured lexicon aims ideally at a redundancy-free specification of all lexicalproperties, and indeed, it achieves this largely through the use of inheritance.
Whilewe do see scientific parsimony as an end in itself, we see two further advantages inthe employment of the structured lexicon, one scientific and one practical.
The scien-tific advantage of the structured lexicon is that it identifies ignificant classes in thelanguage.
In a feature system with approximately 30atomic features (including seman-tics), each of which ranges over approximately 10values, it is certainly striking thatwe never see the need to distinguish 1030 classes of items.
In fact we distinguish ap-proximately 300 lexical classes in HP-NL, a large system with very broad grammaticalcoverage (see Nerbonne and Proudian 1987).283Computational Linguistics Volume 18, Number 3stem: easysem.logic: \ [ \ ]  easy( z, ^  get (z, m," hire(m, T,~\] U ~\])comps:\[ subj: \[sem:\[~\]U\[~\] ] \]Aa5to get Mary to hire tFigure 4The result of combining complex adjective and slashed VP complement.
Note that the subjectof easy is still semantically coindexed with the missing VP object.But the practical advantage of the structured lexicon may ultimately also be ofscientific value, and that is because a structured lexicon is more easily maintainedand extended than a nonstructured one.
This advantage derives immediately from thecharacteristic that lexical properties are normally specified only once.
Modificationstend then to be minimal and extensions less frightening.
The ultimate scientific benefitthis may bring derives from the fact that it is then easier in systems with structuredlexicons to experiment with grammatical description.The following section is an attempt to buttress the claim that structured lexiconsare easily extended.
We examine therefore xtensions to the analysis above of adjec-tives that govern VP complements--to n uns with similar subcategorizations, to theadjectival specifiers too and enough, and to adjectives that govern S complements ratherthan VP complements.5.1 Pleasure NounsAdjectives like easy have been the most widely studied group of lexical types thatpopulate the classes introduced in the analysis above, but they do not have exclusiveclaim to those classes.
Lasnik and Fiengo (1974) observed that the English lexicon alsocontains a group of nouns with similar properties, as illustrated in (20-21),(20) a. Nureyev is a pleasure to watch.b.
This course is a breeze to pass.c.
Venice is a delight o visit.
(21) a.
It is a pleasure to watch Nureyev.b.
It is a breeze to pass this course.c.
It is a delight o visit Venice.Like the adjectives discussed above, nouns such as pleasure have two variants, onethat appears with an ordinary NP subject and an infinitival complement containing an284Dan Flickinger and John Nerbonne Inheritance and ComplementationNP gap; and one that selects an expletive it subject and an infinitival complement withno gap.
Given the word class definitions developed on the strength of the adjectivalexamples, an obvious analysis of the nominal examples uggests itself: pleasure, likepleasant, has one lexical entry belonging to the SLASH-EASY class, and a second entrythat inherits from the IT-EASY class.
The (sparse) descriptions ofboth entries are givenin (22-23), parallel to those for easy given in (17-18) above, the salient difference beingthat the noun entries inherit from the class Common-Noun where the adjective ntriesinherited from the Adjective class.
8(22)pleasure-laSuperclasses Common-Noun, Slash-EasySpelling "pleasure"Semantics.Pred pleasurePhonology /plEzhr/pleasure-lbSuperclasses Common-Noun, It-EasySpelling "pleasure"Semantics.Pred pleasurePhonology /plEzhr/(23)Having declared nouns like pleasure to have entries that are members of SLASH-EASY and IT-EASY, nothing more needs to be said in order to capture the syntacticrelationship between these two forms of pleasure.
The lexical rule we proposed earlierto link pairs of adjectives like the two variants of easy is defined as a regularity holdingbetween the two classes SLASH-EASY and IT-EASY, making no mention of the classADJECTIVE in its formulation.
Hence it also serves to link the pair of noun entries in(22-23).Some further explanation eeds to be provided about the semantics of this classof nouns, since the nouns do seem semantically anomalous even if we shall maintainthat all of the apparent anomaly ultimately stems from their having a subject--andthus being available for control (by be and other raising verbs).
In general a commonnoun is interpreted as a relation between a theme argument and the denotation of itscomplements, if there are any.
For example, friend is interpreted as a relation between atheme argument and the denotation of the complement PP-OF phrase.
We refer to thetheme argument of the relation denoted by the common oun as its denotation.
Anapparent peculiarity of nouns such as pleasure is that there appears to be no denotationof the noun in the usual sense, e.g., in (20a).
At issue is whether there is any themeargument position for the "pleasure" in the relation denoted by pleasure.
That is, doespleasure denote the same two-place relation between individuals and states of affairsthat pleasant does, or is there a third argument position in pleasure that is occupied byan (abstract) "pleasure" individual?The suspicion that no denotation is involved likely stems from our intuition thatwe do not seem to refer to an object hat is a pleasure in uttering either (20a) or (21a),at least not any more than we would if we had used pleasant in the place of a pleasure.8 Other nouns in this class include disappointment, ordeal, challenge, joy, inspiration, and privilege.285Computational Linguistics Volume 18, Number 3Now this suggests that the noun (phrase) is used predicatively, much as many nounphrases are after the verb be.
Compare Tom is a linguist.This does not help a great deal, however.
Even though the analysis of predicativeNPs is an old topic semantically (cf.
the definition of be in Montague 1973, p. 261),there has been essentially no successful attempt to treat predicative nouns as if theyhad no denotation.
Any attempt to do so seems to run afoul of the standard (if limited)determination a d adjectival modification found in phrases uch as no great pleasure towatch; at least such examples point out the inevitable duplication a semantic analysiswould incur if predicative nominals had no denotation.We therefore interpret pleasure as a three-place r lationpleasure (theme : e~ for : x~ soa : s)which obtains just in case e is the pleasure x has in case s. It should of course alsoturn out that this relation for some e holds iff pleasant (for : x~ soa : y), but we willnot be concerned with showing that here.
e provides a denotation that is subject odetermination ( o) and (intersective) adjectival modification (great).
Under this anal-ysis, a pleasure to watch and no pleasure to watch denote quantifiers, i.e., in each casea set of properties of pleasures (e's from above).
Of course, a quantifier does not byitself represent a proposition, something that could be true or false---for that it mustbe paired with a property.
In these cases, the relevant property is always the universal(existence) property; i.e., utterances of sentences such as (20a) are true just in case thereis a pleasure of the relevant kind (and mutatis mutandis for the negative xistentials).We therefore postulate that the predicate be in these sentences denotes the universalproperty.
9What is striking about this proposal is that it assigns the common oun pleasureexactly the semantics the general scheme predicts--a relation between a theme andthe denotations of other complements.
For this reason, the word classes for pleasurenouns make no special stipulations about semantics.We therefore derive feature structures such as the following, which are used in thesyntax and semantics processing of the word pleasure.
The first structure representsthe member of the SLASH-EASY class, and the second the member of the IT-EASYclass.
(We have simplified the structures to highlight he semantically relevant parts.
)stem: "pleasure"sem.logic: pleasure (e, ~-~ \ [ \ ]  )subcat:subj: I sere : \ [ \ ]  \pp-for: I sem: \ [ \ ]  \]\[ subj: \[\[sem: \ [ \ ]  \ ]1xcomp: logic: 2~sem: slash:9 In fact, we do not stipulate a peculiar semantics for the raising verbs (such as be) that are involvedhere.
Instead, we allow be to denote the identity relation, which holds of a single argument just in casethere is some way of filling in the missing argument--i.e., in case the first exists.
This follows from thegeneral treatment of unsaturated relations in Situation Theory (cf.
Section 2 under subcategorization).Note, however, the one exceptional spect, i.e., that the subject of the verb be is not linked to anyargument position in the relation denoted by the controlled complement (in this case, pleasure).286Dan Flickinger and John Nerbonne Inheritance and Complementationstem: "pleasure"sere.logic: pleasure (e, ~-~,^ ~-\] )comps:subj: NP-itpp-for: \[ sem: \ [~  \[\]xcomp:Isubject:  sem:~\]  \] \]sere: \ [~On the other hand, the noun classes are exceptional in that the nouns involvedhave subjects--a property they inherent finally from INCOMPLETE, in the one casethrough CONTROL, IT-SUBJ, and IT-EASY; and in the other from CONTROL, SLASH-COMP, and SLASH-EASY.
It is this property, shared by the NPs they give rise to,that explains (i) their ability to be controlled, e.g., by the verb be--only unsaturatedphrases are subject o control; (ii) their inability to function in normal NPs, e.g., in thesubject position of any intransitive verb; and finally (iii) the fact that they can stand inconstruction with the main verb be without being asserted to be identical to its subject.We turn now to further points on the syntax of the pleasure nouns.
The two defini-tions of entries for "pleasure" also predict he grammaticality judgments een in (24),analogous to the examples given above for adjectives, and based on the definitionsgiven for the IT-EASY and SLASH-EASY word classes.
1?
(24) a. Nureyev is a pleasure for us to watch.b.
It is a pleasure for us to watch Nureyev.c.
For us, Nureyev is a real pleasure to watch.d.
*For us, Nureyev is a real pleasure for our parents to watch.e.
For us, it is a real pleasure for our parents to watch Nureyev.f.
It is a real pleasure for us for our parents to watch Nureyev.g.
*Nureyev is a pleasure watching.h.
It is a pleasure watching Nureyev.10 Nothing we have said so far captures the fact that some pairs of members of these two classes, such as"pleasant" and "pleasure," are morphologically related.
We do not offer here a proposal for capturingnonproductive r gularities of this kind, though some extension of the lexical rule mechanism ightserve, an extension that would depend heavily on the ability to specify negative xceptions to lexicalrules, given examples like the following.
(i) It is difficult to hire Bill.
(ii) *It is a difficulty to hire Bill.
(iii) *Bill is a difficulty to hire.
(iv) It is impossible to work with Bill.
(v) *It is an impossibility to work with Bill(vi) *Bill is an impossibility to work with.287Computational Linguistics Volume 18, Number 3Recalling further that the adjectives we looked at above fell into not two but fourdistinct classes, we might expect o find nouns as well that belong to the other twoclasses, IT-SUBJ and SLASH-COMP.
Such instances are found in English, as illustratedfor IT-SUBJ nouns by the examples in (25), and for SLASH-COMP nouns by those in(26), drawn from Lasnik and Fiengo.
11(25) a.
It would be a mistake to fire Bill.b.
It was a shock to find Bill here.c.
*Bill would be a mistake to fire.d.
*Bill was a shock to find here.
(26) a.
This room is a pigsty to behold.b.
Nureyev is a marvel to watch.c.
*It is a pigsty to behold this room.d.
*It is a marvel to watch Nureyev.The noun mistake and the adjective possible have in common just those propertiesspecified by the IT-SUBJ class (together with its superclasses); and like the differencesbetween pleasure and easy, their differences result from mistake being a member of theCOMMON-NOUN class while possible inherits from the ADJECTIVE class.
Since thelexical rule relating the two variants of pleasure (and the two variants of easy) is definedto link members of the two classes SLASH-EASY and IT-EASY, the rule correctly doesnot predict he existence of similar alternate ntries for nouns like mistake and pigsty.Interaction with lexical rules.
Given that the domain of lexical rules is always oneor more word classes, and that the LR-Intraposition rule is defined on the IT-SUBJclass, we predict the grammaticality of the following examples with pleasure nouns,since they also have entries belonging to the IT-SUBJ class, and should be expected toconform to the LR-Intraposition rule.
Here again, the combined evices of inheritanceand lexical rule produce the desired results for nouns without requiring that anythingbe added to the analysis motivated from data on adjectives and verbs.
(27) a.
(For me) to stay another day would be a real pleasure.b.
It would be a real pleasure (for me) to stay another day.c.
To visit Venice now might be a disappointment for you.d.
It might be a disappointment for you to visit Venice now.5.2 Too and EnoughTo drive home our central point about the expressive and predictive power of inher-itance in lexical representation, we turn to a third, small class of lexical entries thatshow complementation properties like those we have already seen.
Jackendoff (1972)noticed that the words too and enough also appear in constructions with an infinitivalcomplement that contains an NP gap, as illustrated in (28) with examples drawn from11 Additional IT-SUBI nouns include battle, disgrace, error, honor, relief, shock, and surprise.
OtherSLASH-COMP nouns include beauty and terror.288Dan Flickinger and John Nerbonne Inheritance and ComplementationLasnik and Fiengo (1974).
12(28) a.
The mattress is thin.b.
*The mattress is thin to sleep on.c.
The mattress is too thin to sleep on.d.
The football is soft.f.
*The football is soft to kick.g.
The football is soft enough to kick.In particular, the examples in (29) suggest hat these adverbs select for comple-ments that are the same as adjectives like pretty, entries that are not related via lexicalrule to variants that license an expletive it subject.
(29) a.
*It is too thin to sleep on this mattress.b.
*It is soft enough to kick this football:Informally, it seems that when too or enough combines with an ordinary adjec-tive, the resulting phrase (too thin and soft enough) exhibit complementation propertiesvery much like those of pretty adjectives.
By defining the lexical entries for these twoadverbial specifiers as members of the SLASH-COMP class, we begin to provide anaccount for examples (28c,g) as well as those in (29).
The entry for too is given in (30),inheriting both from the ADVERB class and from the SLASH-COMP class; the entryfor enough is similar, leaving out of the present discussion an account of the linearorder difference between the two adverbs with respect o the adjective they modify.
(30)"too"Superclasses Adverb, Slash-CompSpelling "too"Phonology / tu /With the inclusion of this class of adverbs, our lexical subhierarchy involving com-plementation of slashed VPs has grown to a point where it surely demonstrates thevirtues of the structured lexicon approach.
Figure 5 illustrates the more complete struc-ture.
It is a curious fact that the number of lexical classes does not grow enormouslyeven while fairly detailed analyses involving very different grammatical reas are un-dertaken.
In several years of development at Hewlett-Packard Laboratories involvingdetailed analyses of dozens of constructions, the number of word classes never ex-ceeded 400.
This must be due finally, not to the lexical analysis tool, but rather to thetendency of language to reuse significant classes.This analysis of these two unusual adverbs has left begging an important is-sue about how the complementation specifications provided by too are propagatedup to the phrase too thin.
13 We have said little here about how lexically supplied12 Baltin (1987) presents a more recent analysis of these "degree complements.
"13 One might be tempted to try a lexical rule approach that would treat oo thin as a derived lexical itemthat selects for a VP complement.
But slightly more complicated xamples quickly render this approachuntenable.
Cf.
This country is too thinly populated toworry about (where we take the scope of the specifiertoo to be thinly populated).
Here, the lexicalized form that selects for a VP complement would have to be289Computational Linguistics Volume 18, Number 3CONTROLIT-SUBJ SLASH-COMPFOR-EXPERIENCERIT-EASY SLASH-EASY/ ~ ~  ADJECTIVEpleasure-la ~ j/ ~~pleasure-lb ~\tooFigure 5The lexical subhierarchy involving elements that govern "slashed" verb phrases.
Note that theoriginal hierarchy needed very little modification, merely addition.
We speculate that this isdue to the fact that significant classes are being identified in detailed grammatical description.There is also a version of too that inherits from ADVERB and IT-EASY that is not shown (sinceit was not discussed).
The asymmetry is only apparent.subcategorization information is employed in parsing, referring the reader to full ac-counts given in Pollard and Sag (1987) and related references.
Yet it is clear that some-thing more must be said about this construction, given that in HPSG it is the syntactichead of a phrase that imposes constraints on its complements; and we assume thatthin, not too, is the head of the phrase too thin to sleep on.
To motivate the necessaryelaboration of our analysis for these two adverbs, we turn to one more set of datainvolving gappy infinitival complements, one that has received little study to date.Excursus on subcategorization transfer.
As the example in (31) shows, adjectives suchas easy appear not only in predicative constructions like those illustrated above, butalso as nominal modifiers.
(31) John is an easy man to talk to.too thinly populated, a consequence we regard as unacceptable.290Dan Flickinger and John Nerbonne Inheritance and ComplementationWhi le  the example  in (31) is good,  employ ing  the easy that  be longs to the EASY-SLASH class, the examples  in (32-33) are ungrammat ica l .
The analys is  we  have pro-v ided  thus far does not  yet  expla in the grammat ica l i ty  of (31) and the ungrammat i -cal i ty of (32,33).
(32) a.
*John is an easy to talk to man.b.
*John is an easy man.
(33) a.
*John is an easy man to talk to Bill.b.
*John is a man easy to talk to Bill.We wil l  focus on exp la in ing  the grammat ica l i ty  of (31), assuming  that the r ightsyntact ic structure for the sentence is the b inary -branch ing  structure g iven in (34),where  easy forms a const i tuent  with man, and where  to talk to is s ister to the phraseeasy man.
We adopt  the b inary  structure largely  because it wi l l  s impl i fy  the expos i t ionhere; it might  be equal ly  defens ib le  to ho ld  that easy, man,  and to talk to are all s istersof a s ingle phrase24What  is awkward  about  this structure is that the head noun man does not  by  itselfsubcategor ize  for the VP /NP .
~5 Rather, it seems that when easy combines  wi th  man, theresul t ing phrase  has a subcategor izat ion list that contains not  on ly  the opt iona l  andob l igatory  complements  that man started out  with,  but  also the ob l igatory  VP /NP  com-p lement  and the opt iona l  For-PP control ler  equ i red by  easy.
No mechan ism presentedso far p rov ides  for an adjunct  combin ing  wi th  its head to affect the subcategor izat ionof that head  or of the resul t ing phrase.
Yet if the phrase  structure proposed  in (33) iscorrect, some k ind of merg ing  of subcat  in format ion  between ad junct  and head mustbe prov ided  for.
1614 And it is worth noting that the alternative constituent s ructure would not modify the headrelationship, and therefore would not substantially alter the analytic problem--that of explaining howa complement to talk to can be licensed by a nonhead.15 At least not with the intended reading.
There is a suspiciously similar construction, illustrated in (i),which might be expected to shed some light on the proper analysis of (31), but which has a restrictedenough interpretation to suggest that it should be treated separately, probably inheriting a specificationfrom the more general construction exhibited in (31).a.
John is a man to admire.
(i) b. Mary is a woman to emulate.c.
This is a word to keep on the tip of your tongue.These examples seem to mean something like John is a good man to admire or Mary is a good woman toemulate, where the semantic contribution of good has been incorporated into the N-VP/NP constructionin (i).
To test this, consider the examples in (ii), where the good reading should lead to an anomalousinterpretation, and does (cf.
the corresponding examples in (iii)).
(ii) a.
?Mary is a person to underestimate.b.
?Sharks are animals to tame.
(iii) a. Mary is an easy person to underestimate.b.
Sharks are difficult animals to tame.Given the constrained interpretations of examples like those in (i-ii), it does not seem defensible totreat easy man to talk to as simply the modifier easy combining with man to talk to.
Any such attemptwould be strained in accounting for (ii); in addition, such an analysis would leave unexplained theungrammaticality of *John is an easy man.16 It is probably worth noting that extraposition seems unlikely to be generalizable to all cases involvingtransferable subcats, at least if extraposition is to be bounded uniformly:(i) An easy man to talk to arrived yesterday.
(ii) *An easy man arrived yesterday to talk to.291Computational Linguistics Volume 18, Number 3S / \NP VP / \Tom V NP / \Is Det N /an N /\A~ Neasy man ~o\VP/NP  / \V VP /NP  / \V PP /NP  /\talk P NP/NP~o tFigure 6Complex adjectivals "wrapped" around a modified noun.
Note that the N head of theI~I constituent in construction with the complex adjectival has not licensed it.Subcategorization transfer has taken place.The examples in (34-35) illustrate that the flow of information from an adjunct'slist of subcats to the head's must be quite restricted; it would not do to simply mergethe Complements list of any adjunct with that of the head in every case.
(34) a.
*an eager man to pleaseb.
*a fearful man of snakesc.
*a frightened man by snakesd.
*an angry man at John(35) a. a man eager to pleaseb.
a man fearful of snakesc.
a man frightened by snakesd.
a man angry at John292Dan Flickinger and John Nerbonne Inheritance and ComplementationThe above examples might suggest hat what distinguishes easy from these otheradjectives is that the VP /NP  complement of easy is obligatory, while the PP comple-ments of the above adjectives are optional.
While there are not many adjectives againstwhich to test this hypothesis, the one clear case of an adjective that takes an obligatorycomplement counts against he idea:(36) a. a man fond of snakesb.
*a fond manc.
*a fond man of snakes.The analysis we propose localizes in lexical entries the ability of a subcat tobe transferred from adjunct to head.
Just as subcats can be marked for the oblig-atory/opt ional  distinction in a class definition or in a lexical entry, so can they bemarked for a distinction we term transferable.
While as a default subcats will be non-transferable, those subcats that are identified by a class or lexical entry as transferablewill be subject o the following informally stated principle.Transferable Subcat Principle.
When a transferable subcat on a daugh-ter in a local subtree is not associated with some sister in that subtree,the subcat becomes part of the corresponding subcat list of the headdaughter in that subtree.In the constructions studied here, this principle applies in cases where the lexicalentry or phrase with a transferable subcat serves as an adjunct (easy) or a specifier (too),so that the word or phrase's ubcat list is not used directly.
The intent of the principle insuch cases is to make the transferable subcat a part of the head, so the subcategorizationprinciple will ensure that the information is propagated to the mother node.
This isintended as a modification of the subcategorization principle---note that it has theeffect of licensing a kind of "discontinuous constituent.
"~7Having introduced this additional property of subcats, that they can be specifiedas transferable, we note that the default value for this property must be negative, sincein general subcats from adjuncts and specifiers do not pass to heads, as seen in (33)and (34) above.
This default value will be overridden for the VP /NP  and the For-PP subcats in the SLASH-COMP class, to reflect the grammaticality of both examplesin (37).
(37) a.
That was a melodious onata to listen to.b.
John is an easy man to please.Members of the SLASH-COMP class, including the relevant lexical entry for easy,will inherit this nondefault transferable property for both the XComp and the For-PP,so when easy combines as an adjunct with the head noun man, these two subcatswill become part of the subcategorization f man, by the principle above, and willthen become part of the subcategorization f the node easy man, accounting for thegrammaticality of (31) above.Example (32a) will be ruled out because of an independent constraint hat re-stricts pre-head adjuncts to those that are (Head-Final +).
Example (32b) is excludedbecause asy has an obligatory VP /NP  complement, which must be included as an17 The ability to transfer asubcategorization requirement from a modifier to a mother (or to a head) isperhaps abit similar in effect o FUNCTION COMPOSITION in categorial grammar (Bach 1988).
But inHPSG the possibility may be lexically constrained.293Computational Linguistics Volume 18, Number 3obligatory complement of the phrase easy man, due to the convention adopted aboveabout merging of subcat information between a head and its sister.
Finally, (33a) isexcluded because the easy that requires an unslashed VP complement will not passon its XComp subcat o the noun it modifies, since that XComp is, like most subcats,nontransferrable.
So easy man to please Bill will be excluded for the same reason thateager man to please is excluded: nothing licenses the postnominal infinitival VP.Example (33b) is probably best excluded on semantic grounds, since the subjectof easy to please Bill is an expletive pronoun, the wrong sort to unify with the headnoun being modified.
On the assumption that a noun must serve semantically as thesubject of adjectival adjuncts, those adjuncts must specify some thematic role for thenoun to play.
Thus any adjective that requires an expletive subject should give rise toa semantically ill-formed expression when it appears as an adjunct o a noun.
Whatprevents the IT-EASY easy from serving as an adjunct o problem is the fact that thiseasy requires an expletive it subject.Given this transferable complement mechanism, we may straightforwardly com-plete the analysis of the earlier too/enough examples: the lexical entries for these twoadverbs imply specify that their gappy infinitival complement is transferable.
TM6.
Conc lus ions  and Future Direct ionsThe study of inheritance and, more generally, the study of structured lexical repre-sentations i an exciting and promising field.
We would like to use this section tosummarize how we view this work and to suggest directions in which we feel itshould move.6.1 Conc lus ionsWe have presented a treatment of complementation that uses nonmonotonic lexicalinheritance.
The lexical specifications are quite compact and therefore both readilyextendible and easily modified.
We pointed out cases where nonmonotonic, defaultspecification seems most natural, and the entire treatment turns on the possibility ofthere being genuine multiple inheritance of a "complements" attribute.We adopt a skeptical approach to inheritance conflict.
If there are inheritance con-flicts in the system presented here, nothing is inherited.
Mechanisms that warn usersabout such conflicts are useful, but we are wary of attempts to decide conflicts "in-telligently."
They seem likely to us to lead to cases where minor changes may haveremote consequences, which would detract from maintainability.We do not feel that we have overstated the case for structured lexicons by choosinga particularly messy or poorly understood area.
To insist on this point somewhat, letus note that we omitted significant aspects of the grammar of the "raising nouns," e.g.,their complements, specifiers, and adjuncts.
19Grammar abounds in poorly understoodareas, including comparatives, uperlatives, adverbials, internal NP syntax, and the"specialized grammars" found in dates, places, and technical vocabulary.
All of theseareas can benefit from the application of a tool for complex lexical description.18 This leaves much to be said about the lexical properties of too and enough, but more detailed analysis atthis point would take us too far afield; it is clear enough that, whatever their other properties, thesetwo adverbs hare complementation properties with the adjectives and nouns studied here.19 For example, for "pleasure" nouns, some adjectives are okay, but not all (a real/*competent pleasure towork with; relative clauses are impossible: Sally is a pleasure *\[that is real\] to work with; and some nominalcomplements are fine: Sally was a pleasure of the rarest kind to work with.294Dan Flickinger and John Nerbonne Inheritance and Cornplernentation6.2 Hypotheses or Tools?The conclusions above may be read as a plea for the employment of an important oolin computational linguistics, and, indeed, we see the primary significance of the use ofstructured lexicons not in new expressive power which they bring to natural anguageprocessing or description (there is perhaps none), but rather in the increased ease andreliability with which they allow old hypotheses to be formulated and put to use.Brachman (1983, p. 35) summarizes the dominant view of inheritance in knowl-edge representation:Even though much has been made in the past of the significance of in-heritance in semantic nets, no one has been able to show that it makesany difference in the expressive power of the system that advertisesit...
It is strictly implementational.Given this authority on the technical side, it may be surprising to hear moreapplication-oriented users of inheritance mechanisms hedging at all on whether thereis any scientific significance to the proposal here.
But there is at least a potentialcandidate: lexical rules may distinguish inherited from specified information.In expressing the relationships between members of two sets of lexical entries,we make crucial use of the distinction between idiosyncratically specified information(which appears in a sparse Inonredundant\] lexical entry) and inherited information.
Wehave adopted here the restrictive hypothesis, proposed in Flickinger (1987), that lexicalrules hold for minimally specified lexical entries, without having access to inherited,predictable information.
Adopting this hypothesis imposes a constraint on the formand function of lexical rules that is strong, perhaps too strong, but one that allows asimpler formulation of rules by keeping to a minimum the amount of information to bemanaged.
Only two kinds of information are relevant for a lexical rule: the word classesthat each of the two related entries belong to, and any idiosyncratic properties specifiedby either lexical entry.
We note that if lexical rules were insensitive to the distinctionbetween idiosyncratic and predictable properties of lexical entries, the statement ofeven a simple rule like LR-PAST, given earlier, would be much more difficult.
If thelexical rule for past tense verbs had to cope with fully specified entries that blurredthis distinction, it would be difficult to express in the rule just which properties of theone entry had to match in the other, related entry.For example, the verb like idiosyncratically requires a verbal complement that iseither infinitival or gerundive, while the verb enjoy does not allow the infinitival form,allowing only the gerundive form for its complement.
Since all of the inflected forms oflike allow the same choice of two permissible forms for the verbal complement, whileall of the inflected forms of enjoy insist on the gerundive complement, the lexical ruleslike LR-PAST or the similar one for present hird singular forms must preserve theseidiosyncracies.
Yet a fully specified entry for the base form enjoy stipulates not justthe form of the complement, which would have to be identical in the present hirdsingular entry enjoys; the fully specified base entry for enjoy also specifies that itssubject be unmarked for number, an indifference that crucially must not be shared bythe entry for enjoys.
Short of tagging each attribute value in a fully specified entry aslocal or inherited, it is not clear how the lexical rule for present hird singular formscould be constrained to ensure identity of the verbal complement's VFORM valuewhile ignoring differences in the subject's AGREEMENT value for these two entriesfor enjoy.
In sharp contrast, this difference in idiosyncratic vs. inherited informationcan be exploited by lexical rules without stipulation when they are constrained toapply only to minimally specified entries.295Computational Linguistics Volume 18, Number 3It may not be superfluous to add that, even if the argument above about distin-guishing inherited and specified information is ultimately fallacious, so that the useof inheritance were seen purely as a tool, and not at all as a scientific hypothesis, itmay nonetheless prove to be of great significance, just as many tools have advancedareas of science that nothing to do with their development.
The development of lensesrevolutionized astronomy, even though glass grinding embodied no astronomical hy-potheses.6.3 Emergent Issues in Structured LexiconsPerhaps more interesting are the many directions in which this research may be de-veloped.
We suggest some of these in the questions below.What are lexical classes and lexical entries?
The careful reader noted in Section 5above that our lexical specifications are translated into feature structures.
Theoretically,we could dispense with the translation for nearly all of the information involved, andhave the lexicon describe feature structures directly.
But this does not correspond toour implementation, or are we clear on how, e.g., information on lexical rules andtheir application ought to be rendered in features.
Perhaps lexical entries must bestructured so that one component of a lexical entry is a feature structure, while othersare not.
2?Can inheritance be exploited in the specification of inflectional variation?
Thisappears to be a promising area of application, since in general, one can view inflectedelements as further specifications of abstract lexemes (cf.
Evans and Gazdar 1989 foran intriguing proposal).Can derivational lexical rules be treated more satisfactorily?
For example, it isclear that at least some lexical rules relate not merely a pair of word classes, butrather entire lexical substructures (involving several classes) to one another.
Can thetechniques of inheritance be applied here, so that exceptional elements may be easilyaccommodated?AcknowledgmentsWe are indebted to Mark Gawron, MasayoIida, Bill Ladusaw, Joachim Laubsch, CarlPollard, and Tom Wasow for frequentconversations about his analysis.
We arealso grateful to Anthony Kroch, theparticipants at the Tilburg Workshop onInheritance in Natural Language Processing,and three referees for further comments.This work was partially supported by aresearch grant, ITW 9002 0, from theGerman Bundesministerium ftirForschungund Technologie to the DFKI DISCO project.ReferencesBach, Emmon.
(1988).
"Categorial grammarsas theories of language."
In CategorialGrammars and Natural Language Structures,edited by Richard T. Oehrle, EmmonBach, and Deirdre Wheeler.
Reidel.Baltin, Mark.
(1987).
"Degree complements.
"In Syntax and Semantics 20: DiscontinuousConstituency, edited by Geoffrey J. Huckand Almerindo E. Ojeda.
Academic Press.Bayer, Samuel.
(1990).
"Tough movement asfunction composition."
In Proceedings ofthe 9th West Coast Conference on FormalLinguistics, edited by Aaron Halpern.CSLI, Stanford, 29--42.Borsley, Robert.
(1983).
"A Welsh agreementprocess and the status of VP and S." InOrder, Concord, and Constituency, edited byGerald Gazdar, Ewan Klein, and GeoffreyPullum.
Foris Publications.Borsley, Robert.
(1987).
"Subjects andcomplements in HPSG."
CSLI ReportNo.
CSLI-87-107, Center for the Study ofLanguage and Information, StanfordUniversity, Stanford, CA.Brachman, Ronald J., and Schmolze, JamesG.
(1985).
"An overview of the KL-ONEknowledge representation system.
"Cognitive Science, 9, 171-216.20 Krieger and Nerbonne (1991) attempt to characterize all lexical information (including inflectional ndderivationat relationships) in typed feature structures--with no further information.296Dan Flickinger and John Nerbonne Inheritance and ComplementationBrachman, Ronald J.
(1983).
"What IS-A isand isn't: An analysis of taxonomic linksin semantic networks."
IEEE Computer,30-36.Brame, Michael.
(1979).
Essays TowardRealistic Syntax.
Noit Amrofer.Bresnan, Joan.
(1971).
"Sentence stress andsyntactic transformations."
Language, 47,257-281.Bresnan, Joan (ed.)
(1982).
The MentalRepresentation f Grammatical Relations.
MITPress.Carpenter, Bob, Pollard, Carl J., and Franz,Alex.
(1991).
"The specification andimplementation f constraint-basedunification grammar."
Unpublishedreport, CMU Laboratory forComputational Linguistics.Chomsky, Noam.
(1965).
Aspects of the Theoryof Syntax.
MIT Press.Chomsky, Noam.
(1973).
"Conditions ontransformations."
In A Festschrift for MorrisHalle, edited by Stephen Anderson andPaul Kiparsky.
Holt, Rhinehart andWinston.Chomsky, Noam.
(1977).
"On whmovement."
In Formal Syntax, edited byPeter Culicover, Tom Wasow, and AdrianAkrnajian.
Academic Press.Culicover, Peter, and Wilkens, Wendy.(1984).
Locality in Linguistic Theory.Academic Press.Devlin, Keith.
(1991).
Logic and Information.Oxford University Press.Emele, Martin, and Zajac, Remi.
(1990).
"Typed unification grammars."
InProceedings, 13th International Conference onComputational Linguistics, Helsinki.293-298.Evans, Roger and Gazdar, Gerald.
(1989a).
"Inference in DATR."
In Proceedings, 4thConference ofthe European Chapter of theAssociation for Computational Linguistics.66-71.Evans, Roger and Gazdar, Gerald.
(1989b).
"The Semantics of DATR."
In Proceedings,7th Conference ofthe Society for the Study ofArtificial Intelligence and Simulation ofBehaviour.
Pittman/Morgan Kaufmann,London, 79-87.Fillmore, Charles.
(1985).
"Pragmaticallycontrolled zero anaphora."
In Proceedings,7th Meeting of the Berkeley Linguistic Society.Flickinger, Daniel.
(1987).
Lexical rules inthe hierarchical lexicon.
Doctoraldissertation, Stanford University,Stanford, CA.Flickinger, Daniel, Pollard, Carl, andWasow, Tom.
(1985).
"Structure-sharinglexical representation."
In Proceedings, 23rdAnnual Meeting of the Association forComputational Linguistics, 262-267.Fodor, Janet D. (1978).
"Parsing strategiesand constraints on transformations.
"Linguistic Inquiry, 9: 427-473.Franz, Alex.
(1990).
'% parser for HPSG.
"Technical Report LCL-90-3, CMULaboratory for Computational Linguistics.Gazdar, Gerald; Klein, Ewan; Pullum,Geoffrey; and Sag, Ivan.
(1985).Generalized Phrase Structure Grammar.Harvard University Press.
Cambridge,MA.Goldstein, Ira and Roberts, B.
(1977).
"TheFRL Manual."
MIT-AI Memo 409, MIT.Cambridge, MA.Gunji, Takao.
(1987).
Japanese Phrase StructureGrammar.
Reidel.Hukari, Tom, and Levine, Robert.
(1991).
"On the disunity of unboundeddependency onstructions."
NaturalLanguage and Linguistic Theory, 9: 97-144.Jackendoff, Ray.
(1972).
SemanticInterpretation i  Generative Grammar.
MITPress.Jackendoff, Ray.
(1975).
"Tough and the tracetheory of movement rules."
LinguisticInquiry, 6: 437-446.Jacobson, Pauline.
(1982).
"Evidence forgaps."
In The Nature of SyntacticRepresentation, edited by Pauline Jacobsonand Geoffrey K. Pullum.
Reidel, 187-228.Jacobson, Pauline.
(1984).
"Connectivity inPhrase Structure Grammar."
NaturalLanguage and Linguistic Theory, 1: 535-581.Jacobson, Pauline.
(1987).
"Phrase structure,grammatical relations, and discontinuousconstituents."
In Syntax and Semantics 20:Discontinuous Constituency, edited byGeoffrey J. Huck and AlmerindoE.
Ojeda.
Academic Press.Jacobson, Pauline.
(1990).
"Raising asfunction composition."
Linguistics andPhilosophy, 13(4): 423--476.Johnson, Mark.
(1988).
Attribute Value Logicand the Theory of Grammar.
CLSI.Jones, Charles.
(1990).
"Decapitation (ofsome so-called 'Null-OperatorConstructions')."
In Proceedings ofthe 9thWest Coast Conference on Formal Linguistics,edited by Aaron Halpern.
CSLI, Stanford,317-30.Kaplan, Ronald, and Bresnan, Joan.
(1982).
"Lexical-functional grammar: A formalsystem for grammatical representation.
"In The Mental Representation f GrammaticalRelations, edited by Joan Bresnan.
MITPress.Krieger, Hans-Ulrich, and Nerbonne, John.(1991).
"Feature-based inheritancenetworks for computational lexicons.
"DFKl Research Report RR-91-31,297Computational Linguistics Volume 18, Number 3Deutsches Forschungszentrum f~irKiinstliche Intelligenz, SaarbrUcken,Germany.
(Also in: Ted Briscoe, AnneCopestake, and Valeria de Paiva, eds.,Proceedings ofthe ACQUILEX Workshop onDefault Inheritance in the Lexicon.
TechnicalReport No.
238, University of CambridgeComputer Laboratory, Cambridge, U.K.)Lasnik, Howard, and Fiengo, Robert.
(1974).
"Complement object deletion."
LinguisticInquiry, 5: 535-571.Maling, Joan, and Zaenen, Annie.
(1982).
"Aphrase structure account of Scandinavianextraction phenomena."
In The Nature ofSyntactic Representation, edited by PaulineJacobson and Geoffrey K. Pullum.
Reidel.Miller, George, and Chomsky, Noam.
(1963).
"Finitary models of language users."
InHandbook of Mathematical Psychology Vol.
II,edited by R. D. Luce, R. Bush, andE.
Galanter.
Wiley.Montague, Richard.
(1973).
"The propertreatment of quantification i ordinaryEnglish."
In Formal Philosophy, edited byRichmond Thomason.
Yale UniversityPress, 247-270.Nanni, Deborah L. (1980).
"On the surfacesyntax of constructions with easy-typeadjectives."
Language, 56: 568-81.Nerbonne, John, and Proudian, Derek.(1987).
"The HP-NL system."
Technicalreport, Hewlett-Packard Labs, Palo Alto,CA.Nerbonne, John.
(1992).
"A feature-basedsyntax/semantics nterface."
InProceedings, Second ConfErence on theMathematics of Language} edited by AlexisManaster-Ramer and~Wlodek Zadrozny.Annals of Mathematics and ArtificialIntelligence.Pollard, Carl.
(1984).
Head grammars,generalized phrase structure grammars, andnatural anguage.
Doctoral dissertation,Stanford University, Stanford, CA.Pollard, Carl.
(1985).
"Phrase structuregrammar without metarules."
InProceedings, 4th Annual Meeting of the WestCoast Conference on Formal Linguistics.CSLI, Stanford, 246-261.Pollard, Carl.
(1988).
"Categorial grammarand phrase structure grammar: Anexcursion on the syntax-semanticsfrontier."
In Categorial Grammars andNatural Language Structures, edited byRichard T. Oehrle, Emmon Bach, andDeidre Wheeler.
Reidel.Pollard, Carl.
(1989).
"The syntax-semanticsinterface in a unification-based phrasestructure grammar."
In Views of theSyntax-Semantics Interface: Proceedings oftheWorkshop " GPSG and Semantics," edited byStephan Busemann, Christa Hauenschild,and Carla Umbach.
TechnischeUniversit~it Berlin, 22-24.
Feb 1989,167-184.
KIT FAST, TechnischeUniversit~it Berlin.Pollard, Carl, and Sag, Ivan.
(1987).
AnInformation-Based Theory of Syntax andSemantics, Vol.
I. CSLI, Stanford.Pollard, Carl, and Sag, Ivan.
(1988).
"Aninformation-based theory of agreement.
"In Proceedings from the Parasession onAgreement, edited by Diana Brentari, GaryLarson, and Lynn McCleod.
ChicagoLinguistics Society, Chicago, 236-257.Pollard, Carl, and Sag, Ivan.
(1991).
"Aninformation-based theory of syntax andsemantics."
Vol.
II.
Unpublishedmanuscript in preparation.Postal, Paul.
(1971).
Cross-over Phenomena.Holt, Rinehart, and Winston.Proudian, Derek, and Pollard, Carl.
(1985).
"Parsing head-driven phrase structuregrammar."
In Proceedings, 25th AnnualMeeting of the Association for ComputationalLinguistics, 167-71.Purdy, William C. (1988).
"A lexicalextension of Montague semantics,"Report CIS-88-1, School of Computer andInformation Science, Syracuse University.Roberts, Diana.
(1991).
"Linking rules in anHPSG lexicon."
Master's thesis, CorneUUniversity.Rosenbaum, Peter S. (1967).
The Grammar ofEnglish Complement Constructions.
MITPress.Ross, John R. (1967).
Constraints on Variablesin Syntax.
Doctoral dissertation, MIT,Cambridge, MA.Sag, Ivan A.
(1982).
"A semantic theory of'NP movement' dependencies."
In TheNature of Syntactic Representation, edited byPauline Jacobson and Geoffrey K. Pullum.Reidel.Schachter, Paul.
(1981).
"Lovely to look at.
"Linguistic Analysis, 8: 431-48.Shieber, Stuart.
(1986).
An Introduction toUnification-Based Approaches to Grammar.CSLI, Stanford.298Dan Flickinger and John Nerbonne Inheritance and ComplementationAppendix A: Lexical FundamentalsIn the analysis of adjectives governing VP complements that we provide here, we adoptthe approach to lexical representation developed in Flickinger (1987).
We provide herea brief sketch of the framework, limiting our discussion to those aspects that arerelevant to the analysis in the main body of the paper.Lexical FrameworkMuch of the information i  a fully specified entry within the lexicon is not unique tothat particular entry.
Viewing this information as a set of discrete properties makingup the lexical entry, related lexical items will have in common some of the propertiesof that entry.
Lexical items can be grouped into classes defined by those propertiesthat are common to all members of the class.
By giving a precise characterizationof these word classes, one can eliminate a good deal of the redundancy found in alexicon that consisted of fully specified entries.
Put differently, one can make use ofthese word classes to capture generalizations about he elements of the lexicon and tomake predictions about the behavior and distribution of a lexical item on the basis ofthe classes it belongs to.To avoid redundancy entirely, each property relevant to representing the elementsof a lexicon should only be mentioned once in some single class, with all elements ofthe lexicon that have this property being members of that class.
If so, a given lexicalitem may have to belong to many classes in order to obtain all of its properties.
Theseword classes form a hierarchy over which rules are defined that govern the inheritanceof information from class to class, and ultimately to individual lexical entries.
One ofthe nicest aspects of this idea is that it is readily visualized (cf.
Figure 7).In order to present the class definitions that formally express the properties of theadjectives governing VP complements a collections of attributes with assigned values,we shall make use of the hierarchy of word classes above, where classes inherit theirproperties from other more general classes, or indeed from several such classes.
Thishierarchy of classes is intended as the repository of both the syntactic and semanticproperties that comprise the fully fleshed-out lexical entries of a language; we will ofcourse only present avery few of the classes that would populate acomplete hierarchy,sufficient we hope to prove the promise of such a representation.
Part of this hierarchyis devoted to specifying the number and types of complements hat predicates allowor require, and among this group of word classes is one defining the properties sharedby lexical entries that take a subject and a complement that is semantically controlled(possibly by the subject); we label this class simply CONTROL.
Above, we illustratethe barest outlines of the top of the word class hierarchy for English, to suggest wherethe CONTROL class fits in.
We provide the content of CONTROL later.It is important to note that word classes do not merely form a simple hierarchy, butrather that they form a set of interconnected hierarchies; as Chomsky (1965) argued inhis discussion of lexical representation in Aspects (pp.
79-83), the need to cross-classifya given lexical item according to several distinct properties renders impossible the useof a simple branching hierarchy to represent the lexicon.We take as adequate motivation for the existence of a word class the demonstrationthat some particular syntactic or morphological property (or cluster of properties) isshared by a number of lexical items.
The forcing function in the identification ofwordclasses is our assumption that the best representation for lexical information is onein which each new piece of information, each distinct property exhibited by one ormore elements of the lexicon, is introduced exactly once in the lexicon.
A property299Computational Linguistics Volume 18, Number 3WORDCOMPLEMENTATION /INCOMPLETEPART-OF-SPEECHCOMPLETE .
.
.
.
.
.CONTROL TRANSITIVEFigure 7A sample of lexical classes near the top of the lexical hierarchy.shared by more than one lexical item should be introduced in a word class commonto those items, or those lexical items should be related by lexical rule.
In the simplestcase where a word class or lexical entry belongs to just one superclass, the inheritancerule for how values of an attribute are assigned in the word class hierarchy is quitestraightforward.
The two alternatives to be considered epend on whether a givenattribute permits only one value, or multiple values.Inheritance of ValuesThe value assigned to a particular word class (or member) W for agiven attribute is determined as follows:a.
For a single-valued attribute, the assigned value is eitherintroduced irectly in W, or is the one introduced in themost specific class to which W belongs.
If there is no valueintroduced anywhere in the linked classes between W andthe root WORD-CLASS, inclusively, no value is assigned toW for that attribute.b.
For a multiple-valued attribute, the assigned values are themembers of the set consisting of all distinct values300Dan Flickinger and John Nerbonne Inheritance and Complementationintroduced for that attribute in W and in any of the classeslinking W with the root WORD-CLASS, inclusively.
2~In cases where a class or member belongs to more than one superclass, the picturemight be more complicated, since each of two immediate superclasses might specify adifferent value for the same single-valued attribute.
One way to address the potentialconflict would be to define another ule of inheritance to take account of multipleparents, a rule which for each attribute assigns priority to some one of the parentclasses (see the paper on the ELU lexicon in this collection).
We instead assume thatthe hierarchy is specified in such a way that each single-valued attribute of some givenclass or member was assigned a value by at most one of the immediate superclasses(or its parents), so conflicting values do not occur.In adopting this discipline for inheritance of lexical information, we follow Flick-inger (1987) rather than accepting the more rigorously defined but more restrictiverules of inheritance defined for DATR by Evans and Gazdar (1989a; 1989b).
As will beseen in the discussion to follow, we believe that the ability to inherit a lexical propertyfrom more than one potential source can be important in capturing relevant linguis-tic generalizations.
There would be no point to our use of multiple-valued attributesif we did not allow genuine multiple inheritance.
We employ the multiple-valuedattribute "complements" in order to collect subcategorization nformation about sev-eral subcategorized-for elements imultaneously.
In its most natural form, the singleproperty "complements" inherits from several ancestors simultaneously.
22We also follow Flickinger, this time accompanied by Evans and Gazdar, in as-suming that lexical attributes may be assigned efault values as part of a word classdefinition, with those defaults possibly being overridden i  the definition of a subclassor lexical entry inheriting from that word class.
In this we part ways with Pollard andSag (1987)'s trong assumption ofmonotonicity in the inheritance of lexical properties,again for reasons that we identify in the discussion to fo l low.
23While word classes and the associated mechanism of nonmonotonic inheritanceprovide powerful tools for representing one kind of shared information, that whichlinks a category to its subcategories, a distinct formal device is required to link twomorphologically related classes of different categories.
We employ the familiar notionof a lexical rule to represent this second kind of systematic (but not exceptionless)relationship.
Given a word belonging to the first set, a lexical rule predicts the exis-tence of a corresponding word belonging to the second set, with the differences andsimilarities between the two words captured both in the formulation of the rule, andin the definitions of the classes each word is a member of.We illustrate our notation for lexical rules with an example of a relatively simpleone, the inflectional rule relating the base forms of verbs with their past tense forms.We can express the relationship between, say, walk and walked as given in the LR-PASTrule below, leaving out specifics of phonology and only hinting at semantics.21 We employ multiple-valued attributes only within the lexicon in order to gather subcategorizationspecifications.
A translation step converts these to sets (or--with more information--lists) for use in thefeature system.22 The DATR position carefully disallows multiple inheritance of a single property from two or moreclasses, even while allowing inheritance from various classes into different properties (in a single wordclass).
We find genuine multiple inheritance seems useful, even if it may be dispensible; cf.
thetreatment of the lexical attribute "complements" below.23 But see Pollard and Sag 1987, p. 194 note.301Computational Linguistics Volume 18, Number 3RuleLR-PAST lexical ruleLR-PASTLE2-Classes - PAST = LE1-Classes - BASELE2-Spelling = (AFFIX-ED LE1-Spelling)LE2-Phonology .
.
.
.LE2-Semantics = (PAST LE1-Semantics)This lexical rule, like any other, expresses a relation holding between two sets oflexical entries, the first set represented by a canonical lexical entry LE1, and the secondset by LE2.
The rule's applicability is governed by the relevant classes that LE1 andLE2 each belong to, with these classes named in the statement within the rule thatrelates the one entry's list of parent classes with the other entry's class list.
Havingspecified the range of applicability, each rule then states the particular dependenciesholding between properties of LE1 and corresponding properties of LE2.
24We might view inheritance within a hierarchy of word classes as a tool that elimi-nates redundancy along one dimension within the lexicon, while lexical rules providethe same service along another dimension.
A given lexical item, by virtue of being amember of one or more word classes, shares inherited properties with other lexicalitems that belong to those same classes, but does not necessarily share a commonmorphological or semantic base (or indeed any idiosyncratic properties) with any ofthose other items.
That same lexical item, by participating in one or more lexical rules,has properties in common with a second set of lexical items, where the shared prop-erties crucially include some or all of the idiosyncratic nformation that distinguishesthe lexical item from others in its class.
The members of this second set, related bylexical rules, all do share a single common semantic and morphological base (exceptfor suppletions).Of course, if a lexical rule relates two entries that both belong to a given wordclass (as happens with the verbal inflection rules), those two entries will share someinherited properties as well as the idiosyncracies.
However, the lexical rule only es-tablishes joint membership n that given class and the relationship of the idiosyncraticinformation i  the two entries; all other properties hared by the two are establishedby inheritance within the word class hierarchy.Both of these formal devices, inheritance and lexical rules, serve to express thatwhich is common among (often overlapping) sets of fully specified lexical entries,including properties that are morphological, syntactic, and semantic.
In their capacityas redundancy mechanisms, the two devices permit a parsimonious representation fthe existing lexicon.Lexical ContentFor convenience of exposition, we view the syntactic properties of lexical items asbeing of two kinds: one a set of features, eparated into those with atomic values andthose with category values, and the other a set of subcategorization specifications, di-vided into complements (obligatory and optional), and adjuncts.
Even though HPSGrepresents both types of information (features and subcategorization specifications)24 We include this rule primarily in order to introduce the notation we shall later employ.
We would,however, be quite sympathetic toan alternative treatment of the relation between PAST tense formsand untensed lexemes that employed lexical inheritance rather than inflectional rules to account for therelationship.
We deny that this sort of treatment can be extended straightforwardly from inflectional toderivational rules, however.302Dan Flickinger and John Nerbonne Inheritance and Complementationuniformly as attribute-value pairs (as noted above), we shall represent them lexicaIIyas distinct.
We have two motivations for this: first, in representing the informationdifferently from its normal form in HPSG we demonstrate the independence of thelexical ideas presented here.
We employ HPSG in the grammatical nalysis presentedhere because it is a useful grammatical framework, and because it makes strenuouslexical demands; but the lexicon framework does not presuppose HPSG (for exam-ple, PATR-II systems can make use of structured lexicons, and nearly do, in the formof templates.
Compare Shieber 1986, pp.
54-55.).
Second, a uniform feature notationneeded for subcategorization a d nonsubcategorization nformation threatens to ob-scure points addressed below, so the two kinds of information are separated in therepresentations of lexical entries used here.The atomic-valued features that we employ in specifying lexical entries (and inspecifying categories) are drawn from a (small) finite set where each feature has alimited set of possible atomic values, 25 e.g., the binary feature INVERTED, indicatingwhether or not a verb can appear as the head of an inverted sentence.
The featureVFORM, on the other hand, draws its values from a set containing among othersBASE, PAST, and PAST-PARTICIPLE, to represent the morphological form of a verb.Category-valued features take as their value a feature structure, a specification forsome syntactic ategory.
Since any nonempty set of feature value pairs is (by definition)enough to specify a category, any such set constitutes a possible value for one of thesecategory-valued features.Each complement or adjunct entry, referred to here as a subcat, consists of a cat-egory specification and its semantic properties.
Since reference to subcategorizationproperties of subcats is excluded in specifying complements or adjuncts within a lex-ical entry (cf.
Pollard and Sag 1987:143-4 for a similar--but not identical--"locality"restriction), we make use of a feature COMPLETE, quite similar to the SUBJ fea-ture proposed by Borsley (1983), and employed in Gazdar et al (1985:61f) to distin-guish incomplete from complete categories.
Incomplete constituents lack one or moreof their obligatory complements, including at least their final complement (usuallythe subject), and are marked \[COMPLETE-\], while complete categories are marked\[COMPLETE+\] to represent the property that no obligatory arguments are missing.
(Complete categories correspond roughly to maximal projections in an X-bar frame-work.)
To distinguish lexical categories from phrasal ones, we use the binary featureLEXICAL.
With these two features COMPLETE and LEXICAL, we can follow Pollard(1984) in dispensing with the widely used (and abused) X-bar machinery, while main-taining the full range of necessary distinctions among lexical and phrasal categories.The content of the word-class CONTROL, promised above, is presented here.
(38)CONTROLSuperclassesComplementsXComp-FeaturesXComp-Subj-SemanticsXComp-ObligXComp-SemanticsXComp-RoleIncompleteXComp(Category Verb)(Complete - )(Lexical - )Subject-SemanticsYesXComp-SemanticsState-of-Affairs25 For linguistic defense of many of the actual features used here, see (Gazdar et al 1985).303Computational Linguistics Volume 18, Number 3As the hierarchy of word classes sketched above indicates, this class inherits fromthe INCOMPLETE class (which specifies an obligatory subject complement), and in-troduces a second obligatory complement that is a verb phrase (not complete, whichwould be its maximal projection, a sentence; and not lexical, which would be justa verb without any complements).
It will play the role State-of-Affairs (abbreviated'soa') in relations denoted by words inheriting from CONTROL, and it will be semanti-cally interpreted by the variable XComp-Semantics.
The specification of the semanticswill occasionally be omitted below, since the convention should be clear.
It is thisCONTROL class that will serve as the superclass from which both of the adjectivalVP complement classes (cf.
IT-EASY and SLASH-EASY below) inherit.Before concluding the sketch of the lexicon, we turn to the lexical representationof semantics, which likewise plays a role in the final analysis.Lexical SemanticsThe use of hierarchies of classes of information, advocated here as a means of rep-resentation for grammatical information, is also common in the representation f se-mantic hyponymy relations, e.g., the relation between boy and child (cf.
Brachman andSchmolze 1985).
Thus boy is a hyponym (subconcept) ofboth child and male, which arein turn hyponyms of more abstract words and concepts.
This may be modeled in thesame multihierarchical f shion we employ for grammatical information.
Such seman-tic hierarchies may be of utility in constructing more efficient NL inference ngines(Purdy 1988).We exploit a very different use of semantic inheritance in the present reatment,however, beginning with the observation familiar from categorial grammar (Bach 1988)that semantics and subcategorization are interdependent: subcategorizers denote re-lations among the denotations of their complements.
Montague (1973) effectively ex-ploited this by interpreting multiplace verbs and verb phrases as functions into thedenotations of lesser-place verbs.
We exploit the interdependence by allowing somesemantic inheritance to follow syntactic subcategorization li es.
To be more precise,we allow subcategorizers to specify not only the syntax of their complements, but alsothe semantic role the complement is assigned in the relation denoted by the subcate-gorizer.INCOMPLETESuperclasses ComplementationComplements SubjectSubject-Features (Complete+)(Category Noun)Subject-Role SourceTRANSITWESuperclasses IncompleteComplements ObjectObject-Features (Complete+)(Case Accusative)(Category Noun)Object-Role ThemeThus INCOMPLETE assigns its subject he role source; TRANSITIVE inherits this roleassignment and extends it by assigning theme to objects.Roles may be understood by their function in atomic formulas: in standard pred-icate logic the binding of arguments to argument positions is mediated by the order304Dan Flickinger and John Nerbonne Inheritance and Complementationin which arguments appear.
Rxy ~ Ryx.
The use of explicit roles in semantic rela-tions accomplishes this task and obviates the order of arguments: R(source:x, theme:y)= R(theme:y, source:x).
Role-coded formulas are more easily readable when thereare many roles, and the use of roles seems essential in semantic theories of topicssuch as variable-place r lations or variably-binding arguments such as the possessive.There is furthermore a substantial body of work on the so-called "linking" of seman-tic roles to syntactic information, including especially Roberts (1991) who applies thistheory to HPSG.
(Even though we use role- or keyword-coded arguments in lexicalspecifications, we will occasionally revert o order-coded representations for the pur-poses of illustration.
They are more concise.
Compare Nerbonne (1992) for discussionof the semantic status of roles.
)What is important about roles for the present application is that we may exploitthe inheritance mechanism to derive (specifications for) semantics for multiplace sub-categorizers.
Instances of the TRANSITIVE class are assigned the following semantics,using the multi-valued inheritance scheme discussed above.pred:source:theme:Subject-Semantics \]Object-SemanticsLexical specifications for the arguments to the roles have not been shown, but thegeneral scheme should be clean The predicate must of course be assigned by eachindividual lexical entry.
"Subject-Semantics" is used because it is useful to be able torefer to the semantics of a given complement (the controller) in cases of grammaticalcontrol, as the semantics specifications for the lexical class CONTROL demonstrate.Exceptions to Lexical RulesSince few if any lexical rules prove to be completely exceptionless, we assume thatindividual exical entries can and do stipulate among their idiosyncratic propertiesexceptional behavior with respect o particular lexical rules.
One such exceptionalproperty is that a given entry belongs to a class to which a lexical rule applies, butthat rule is not applicable to this entry.
26 Thus in the present case, adjectives such asnecessary and possible will include as part of their sparse lexical entries the stipulationthat the lexical rule that usually relates IT-SUBJ and S-SUBJ members does not applyto these entries.
Calling that lexical rule LR-Intraposition, given in (39), the entry fornecessary can then be represented asin (40).RuleLR-Intraposition lexical rule(39)LR-IntrapositionLE2-Classes - IT-SUBJ = LE1-Classes - S-SUBJ26 For a more complete discussion of the types of exceptional behavior exhibited by lexical entries withrespect to lexical rules in this framework, see Flickinger 1987 pp.
122ff.305Computational Linguistics Volume 18, Number 3(40)necessary-1Superclasses Adjective, It-SubjSpelling "necessary"Phonology /nEsIseri/Lexical-Rules (LR-Intraposition Not-Applicable)It may be worth noting that it seems unlikely that properties such as the applica-bility of lexical rules can be incorporated into the feature system of HPSG (i.e., in anyexplanatory way).
They seem inexpressible because they are a kind of second-orderproperty.
This is, in fact, exactly the sort of information that suggests to us that alexicon may have to be more than a particular kind of feature system.
See Pollard andSag (1987:209, note) for a concurring view.
Krieger and Nerbonne (1991), on the otherhand, propose a feature-based treatment of lexical rules that allows the expression ofexceptionality (without using rule applicability features)YAppendix B: Refinements and Lexical ModifiabilityIn addition to allowing extensions painlessly, we expect a lexical system to be easilymodified.
This is of practical value given the relatively inexact state of present linguisticknowledge.
Linguistic descriptions are under frequent revision, and lexical systemsmust accommodate this.
In the present section we examine several refinements of theanalyses above as a means of demonstrating the modifiability of structured lexicons.We wish to underscore the richness of detail that demands accommodation even inthis one corner of the lexicon, and we hope to probe the limits of the formalism wehave adopted for this lexical representation.We began our analysis by presenting two variants of adjectives like easy, one withan expletive it subject, and one with a normal NP subject and a verbal complementcontaining a gap.
There is, of course, a third variant for most adjectives of this kind,one with an infinitival VP or S as its subject, and no verbal complement, asillustratedin (41).
(41) a.
To talk to Bill would be great.b.
For me to talk to Bill would be great.c.
For Bill to lose this race would be great for Mary.This selection for infinitival subjects is a property shared with other classes ofwell-studied predicates, including verbs like bother and require, as illustrated in (42).
(42) a.
For me to talk to Bill would bother Mary.b.
To win this race will require your fullest commitment.27 The initial implementation f this lexicon was reported in Flickinger et al (1985), and was done inHP-RL, a language derived from MIT's frame representation language, FRL (Goldstein and Roberts1977).
It has since undergone reimplementations i  Common Lisp, Common Objects, and CLOS.
Thework reported on here was implemented and saw daily (experimental) use for over two years.
Thebasic analyses in Section 4 were all implemented and thoroughly tested through a good variety ofsurrounding rammars and application efforts.
We also suggest analyses in the main body of the paperthat were not implemented fully, in particular in the section on adjectival specification (too and enough)and nondenoting nominals S. is a pleasure to see.306Dan Flickinger and John Nerbonne Inheritance and ComplernentationTo see that these infinitival subjects must be lexically licensed, consider the ex-amples in (43), where at least some members of the IT-SUBJ class cannot appear withsuch subjects.
(43) a.
*In the final analysis, to win this race will not be necessary.(cf.
Winning this race will not be necessary.)b.
*To talk to Bill is possible only in the mornings.We thus define a subclass of INCOMPLETE here named S-SUBJ, similar to IT-SUBJand SLASH-COMP, to identify the relevant properties exhibited by lexical entries forthe adjectives and verbs in (41-42).
(44)S-SUBJSuperclassesComplementsSubject-featuresIncomplete(Category Verb) (VForm Infinitival)(Complete +- )To this class belong verbs like require and bother, but we must also define a subclassthat we call S-EASY for adjectives like great and difficult, since these, unlike the verbs,also permit an optional PP-for phrase, provided as before by the FOR-EXPERIENCERclass.
(45)S-EASYSuperclasses S-Subj, For-ExperiencerIt appears that in general adjectives of the IT-EASY class alternate with entries likethose in (41), while adjectives of the IT-SUBJ class do not.
Hence we are tempted todefine the lexical rule relating adjectives having it subjects with those having infinitivalsubjects o that the rule holds between the two classes S-EASY and IT-EASY.
However,verbs like bother and require with entries that are members of the IT-SUBJ class shouldalso be covered by this same lexical rule, suggesting that it must hold between thetwo classes IT-SUBJ and S-SUBJ.
This leaves us the task of excluding those IT-SUBJadjectives like necessary and possible that do not have S-SUBJ counterparts.Distinctions among Unbounded DependenciesA second refinement of our analysis of easy adjectives i  motivated by examples likethose in (46), which show that some further constraints need to be placed on the gappyverbal complement that such adjectives ubcategorize for.
Informally, the generaliza-tion seems to be that extraction is not possible out of finite clauses embedded withinthe complement to easy adjectives, but is otherwise licensed.
2s28 Jones (1990) attributes the observation to Chomsky (1977).307Computational Linguistics Volume 18, Number 3(46) a.
Bill was easy to get Mary to hire.b.
Palm trees are hard to learn to climb.c.
Arias are fun to try to sing.d.
*Bill was easy to see that Mary admired.(cf.
Bill, it's easy to see that Mary admires.)e.
*Palm trees are hard to learn that one can climb.f.
*Arias are fun to insist that people sing.General constraints imposed by the framework we have adopted here prevent usfrom attempting to describe these facts by making easy adjectives elect for a verbalcomplement whose head requires its complement tobe nonfinite.
29Instead, we followHukari and Levine (1991), who propose that two types of unbounded ependenciesmight be distinguished, with one dependency path, marked by the new binding featureSLASH ~, treating finite S's as islands, while the ordinary SLASH feature marks theusual dependency path that is insensitive to finite S nodes.
Then easy adjectives of theSLASH-EASY class would more precisely subcategorize for an infinitival complementthat has an NP gap of the marked SLASH' variety rather than the usual SLASH.To illustrate, consider example (46d): the SLASH' feature that would (by hypothesis)be introduced at the extraction site within the embedded S that Mary admired willbe passed up from that site by a general principle, but will stop its ascent when itreaches that S. Assuming that the verb see does not select for this unusual kind ofSLASH ~ complement, the sentence will not be admitted as grammatical.
In contrast,the example in (46a) will still be admitted since the SLASH t introduced at the extractionsite in to hire will be faithfully passed up by the same binding inheritance principleuntil it reaches the node dominating to get Mary to hire.
Now this VP\[SLASH / NP\]is, according to our proposed refinement, precisely the kind of complement that easyrequires, so the sentence is grammatical.Of course, to properly defend this addition of SLASH I to the collection of bindingfeatures for English, we would like to find independent evidence of the claim thatfinite S's can serve as islands for SLASH.
We leave the matter here as one meritingfurther study, and refer the interested reader to Jacobson (1987) for a similar suggestionto distinguish various slash attributes.Pied PipingA third refinement of the analysis given above is motivated by examples like those in(47), where the easy adjective appears in a noun phrase with an infinitival complementcontaining a pied piping construction, ot accounted for in what we have said thusfar.
3?
(47) a. Mary is an easy boss for whom to work.b.
New York would be an awkward city from which to flee.c.
Bill might be a hard person in whom to confide.The most straightforward characterization f phrases like for whom to work is todescribe them as infinitival VPs containing a relative pronoun.
Since English indepen-29 For discussion, see Flickinger 1987, pp.
67ff; Pollard and Sag 1987, p. 143.30 Chomsky (1977) cites examples like these; we appreciate Anthony Kroch's bringing them to ourattention.308Dan Flickinger and John Nerbonne Inheritance and Complementationdently prohibits relative pronouns from appearing in situ within a verb phrase, theonly way such a phrase can be produced is to have a pied piped prepositional phraseextracted from the VP and sister to it.
31 Assuming that such a phrase must be admit-ted by the grammar, we can formally represent i s syntactic ategory as shown in thefollowing definition for the new class REL-EASY.
What we make explicit here is theidea that adjectives of the SLASH-EASY class have corresponding members (linkedvia a lexical rule similar to ones seen above) that take an unusual kind of VP com-plement, differing further in that these REL-EASY adjectives do not seem to licensean optional PP-For complement.
The final property identified in this class is that itsmembers are marked as not predicative, ffectively restricting its members to attribu-tive adjectives.
This property accounts for the ungrammaticality of the examples givenin (49).
(48)REL-EASYSuperclassesFeaturesComplementsXComp-featuresControl,Adjective(Predicative -)(VForm Infinitival)(REL (Category Noun) (Complete +)(NForm Normal) (Predicative -)(Case Accusative Dative) )(49) a.
*Bill is easy for whom to work.
b.
*Bill is a pleasure for whom to work.In both examples in (49), the complement of the copula is must be predicative,but the phrases headed by easy and pleasure would have to be nonpredicative in or-der for those heads to license their VP\[REL NP\] complements.
Indeed, (49b) is alsoruled out by another constraint that we finessed in our brief introduction of pleasurenouns, for clarity of exposition: we described such nouns as belonging to the ordinaryCOMMON-NOUN class, but that assignment also needs refining in a more detailedaccount, since pleasure nouns exhibit only a few of the properties of regular commonnouns.
In particular, it seems clear that these nouns must be predicative, and henceunfit for membership n the REL-EASY class, since attempting to assign them to thisclass would introduce a conflict of inherited values for the attribute PREDICATIVE,and such conflicts are prohibited, as we noted above in our introduction to the generalframework.31 Among other details, the phrase structure linking rule that would be necessary to admit this\[VP\[REL NP\] --* PP\[REL NP\],VP/NP\] construction will also have to be made explicit in a fulleranalysis than we provide here, but that should not be problematic.
We have in mind a simplegeneralization f the sentential linking rule, so that no novel rule would be required.309
