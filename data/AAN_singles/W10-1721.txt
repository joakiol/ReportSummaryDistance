Proceedings of the Joint 5th Workshop on Statistical Machine Translation and MetricsMATR, pages 149?154,Uppsala, Sweden, 15-16 July 2010. c?2010 Association for Computational LinguisticsThe Cunei Machine Translation Platform for WMT ?10Aaron B. PhillipsCarnegie MellonPittsburgh, USA.aphillips@cmu.eduAbstractThis paper describes the Cunei MachineTranslation Platform and how it was usedin the WMT ?10 German to English andCzech to English translation tasks.1 The Cunei Machine TranslationPlatformThe Cunei Machine Translation Platform (Phillipsand Brown, 2009) is open-source softwareand freely available at http://www.cunei.org/.
Like Moses (Koehn et al, 2007) andJoshua (Li et al, 2009), Cunei provides a statisti-cal decoder that combines partial translations (ei-ther phase pairs or grammar rules) in order to com-pose a coherent sentence in the target language.What makes Cunei unique is that it models thetranslation task with a non-parametric model thatassesses the relevance of each translation instance.The process begins by encoding in a lattice allpossible contiguous phrases from the input.1 Foreach source phrase in the lattice, Cunei locates in-stances of it in the corpus and then identifies thealigned target phrase(s).
This much is standard tomost data-driven MT systems.
The typical step atthis stage is to model a phrase pair by computingrelative frequencies over the collection of transla-tion instances.
This model for the phrase pair willnever change and knowledge of the translation in-stances can subsequently be discarded.
In contrastto using a phrase pair as the basic unit of modeling,Cunei models each translation instance.
A dis-tance function, represented by a log-linear model,scores the relevance of each translation instance.Our model then sums the scores of translation in-stances that predict the same target hypothesis.The advantage of this approach is that it pro-vides a flexible framework for novel sources of1Cunei offers limited support for non-contiguous phrases,similar in concept to grammar rules, but this setting was dis-abled in our experiments.information.
The non-parametric model still usesinformation gleaned over all translation instances,but it permits us to define a distance function thatoperates over one translation instance at a time.This enables us to score a wide-variety of informa-tion represented by the translation instance withrespect to the input and the target hypothesis un-der consideration.
For example, we could computehow similar one translation instance?s parse tree ormorpho-syntactic information is to the input.
Fur-thermore, this information will vary throughoutthe corpus with some translation instances exhibit-ing higher similarity to the input.
Our approachcaptures that these instances are more relevant andthey will have a larger effect on the model.
Forthe WMT ?10 task, we exploited instance-specificcontext and alignment features which will be dis-cussed in more detail below.1.1 FormalismCunei?s model is a hybrid between the approachesof Statistical MT and Example-Based MT.
A typ-ical SMT model will score a phrase pair withsource s, target t, log features ?, and weights?
using a log-linear model, as shown in Equa-tion 1 of Figure 1.
There is no prototypical modelfor EBMT, but Equation 2 demonstrates a reason-able framework where evidence for the phrase pairis accumulated over all instances of translation.Each instance of translation from the corpus hasa source s?
and target t?.
In the most limited cases = s?
and t = t?, but typically an EBMT sys-tem will have some notion of similarity and useinstances of translation that do not exactly matchthe input.Cunei?s model is defined in such a way that wemaintain the distance function ?
(s, s?, t?, t) fromthe EBMT model, but compute it in a much moreefficient manner.
In particular, we remove the real-space summation within a logarithm that makes itimpractical to tune model weights.
However, our149score(s, t) =?k?k?k(s, t) (1)score(s, t) = ln?s?,t?e?k ?k?k(s,s?,t?,t) (2)score(s, t) = ?
+?k?k(?(s?,t?
)?C ?k(s, s?, t?, t)e?i ?i?i(s,s?,t?,t)?(s?,t?
)?C e?i ?i?i(s,s?,t?,t))(3)Figure 1: Translation model scores according to SMT (1), EBMT (2), and Cunei (2)model preserves the first-order derivative of Equa-tion 2, which is useful during optimization to lo-cally approximate the hypothesis space.
While theinner term initially appears complex, it is simplythe expectation of each feature under the distribu-tion of translation instances and can be efficientlycomputed with an online update.
Last, the in-troduction of ?, a slack variable, is necessary toadditionally ensure that the score of this modelis equal to Equation 2.
Specifying the model inthis manner ties together the two different mod-eling approaches pursued by SMT and EBMT;the SMT model of Equation 1 is merely a spe-cial case of our model when the features for allinstances of a translation are constant such that?k(s, s?, t?, t) = ?k(s, t) ?s?, t?.Indeed, this distinction illuminates the primaryadvantage of our model.
Each feature is calcu-lated particular to one translation instance in thecorpus and each translation instance is scored in-dividually.
The model is then responsible for ag-gregating knowledge across multiple instances oftranslation.
Unlike the SMT model, our aggregatemodel does not maintain feature independence.Each instance of translation represents a joint setof features.
The higher the score of a translationinstance, the more all its features inform the ag-gregate model.
Thus, our model is biased towardfeature values that represent relevant translationinstances.1.2 ContextNot all translations found in a corpus are equallyuseful.
Often, when dealing with data of vary-ing quality, training a SMT system on all of thedata degrades performance.
A common work-around is to perform some sort of sub-samplingthat selects a small quantity of novel phrase pairsfrom the large out-of-domain corpus such that theydo not overwhelm the number of phrase pairs ex-tracted from the smaller in-domain corpus.Instead of building our model from a heuristicsub-sample, we utilize Cunei?s modeling approachto explicitly identify the relevance of each transla-tion instance.
We add features to the model thatidentify when a translation instance occurs withinthe same context as the input.
This permits us totrain on all available data by dynamically weight-ing each instance of a translation.First, we capture the broader context or genre ofa translation instance by comparing the documentin the corpus from which it was extracted to theinput document.
These documents are modeled asa bag of words, and we use common document-level distance metrics from the field of informationretrieval.
Specifically, we implement as featuresdocument-level precision, recall, cosine distanceand Jensen-Shannon distance (Lin, 1991).In order to capture local, intra-sentential con-text, we compare the words immediately to the leftand right of each translation instance with the in-put.
We add one feature that counts the total num-ber of adjacent words that match the input and asecond feature that penalizes translation instanceswhose adjacent context only (or mostly) occurs inone direction.
As a variation on the same concept,we also add four binary features that indicate whena unigram or bigram match is present on the left orright hand side.The corpus in which an instance is located canalso substantially alter the style of a translation.For example, both the German to English and theCzech to English corpora consisted of in-domainNews Commenary and out-of-domain Europarltext.
When creating the index, Cunei stores thename of the corpus that is associated with eachsentence.
From this information we create a setof binary features for each instance of translationthat indicate from which corpus the instance origi-nated.
The weights for these origin features can be150conceived as mixture weights specifying the rele-vance of each corpus.1.3 AlignmentAfter a match is found on the source-side of thecorpus, Cunei must determine the target phrase towhich it aligns.
The phrase alignment is treated asa hidden variable and not specified during train-ing.
Ideally, the full alignment process wouldbe carried out dynamically at run-time.
Unfor-tunately, even a simple word alignment such asIBM Model-1 is too expensive.
Instead, we run aword aligner offline and our on-line phrase align-ment computes features over the the word align-ments.
The phrase alignment features are thencomponents of the model for each translation in-stance.
While the calculations are not exactly thesame, conceptually this work is modeled after (Vo-gel, 2005).For each source-side match in the corpus, analignment matrix is loaded for the complete sen-tence in which the match resides.
This align-ment matrix contains scores for all word corre-spondences in the sentence pair and can be createdusing GIZA++ (Och and Ney, 2003) or the Berke-ley aligner (Liang et al, 2006).
Intuitively, when asource phrase is aligned to a target phrase, this im-plies that the remainder of the source sentence thatis not specified by the source phrase is aligned tothe remainder of the target sentence not specifiedby the target phrase.
Separate features computethe probability that the word alignments for to-kens within the phrase are concentrated within thephrase boundaries and that the word alignmentsfor tokens outside the phrase are concentrated out-side the phrase boundaries.
In addition, wordswith no alignment links or weak alignments linksdemonstrate uncertainty in modeling.
To capturethis effect, we incorporate two more features thatcount the number of uncertain alignments presentin the source phrase and the target phrase.The features described above assess the phrasealignment likelihood for a particular translation in-stance.
Because they operate over all the wordalignments present in a sentence, the alignmentscores are contextual and usually vary from in-stance to instance.
As the model weights change,so too will the phrase alignment scores.
Eachsource phrase is modeled as having some proba-bility of aligning to every possible target phrasewithin a given sentence.
However, it is not prac-tical to compute all possible phrase alignments,so we extract translation instances using only afew high-scoring phrase alignments for each oc-currence of a source phrase in the corpus.2 As dis-cussed previously, these extracted translation in-stances form the basic modeling unit in Cunei.1.4 OptimizationCunei?s built-in optimization code closely followsthe approach of (Smith and Eisner, 2006), whichminimizes the expectation of the loss function overthe distribution of translations present in the n-best list.
Following (Smith and Eisner, 2006), weimplemented log(BLEU) as the loss function suchthat the objective function can be decomposed asthe expected value of BLEU?s brevity penalty andthe expected value of BLEU?s precision score.The optimization process slowly anneals the dis-tribution of the n-best list in order to avoid localminima.
This begins with a near uniform distribu-tion of translations and eventually reaches a distri-bution where, for each sentence, nearly all of theprobability mass resides on the top translation (andcorresponds closely with the actual 1-best BLEUscore).
In addition, Cunei supports the ability todecode sentences toward a particular set of refer-ences.
This is used to prime the optimization pro-cess in the first iteration with high-scoring, obtain-able translations.2 The WMT ?10 Translation TaskFor the WMT ?10 Translation Task we built twosystems.
The first translated from German to En-glish and was trained with the provided NewsCommentary and Europarl (Koehn, 2005) corpora.The second system translated from Czech to En-glish and used the CzEng 0.9 corpus (Bojar andZ?abokrtsky?, 2009), which is a collection of manydifferent texts and includes the Europarl.
To val-idate our results, we also trained a Moses systemwith the same corpus, alignments, and languagemodel.2.1 Corpus PreparationA large number of hand-crafted regular expres-sions were used to remove noise (control char-acters, null bytes, etc.
), normalize (hard spacesvs.
soft spaces, different forms of quotations,2This is controlled by a score ratio that typically selects2-6 translation instances per occurrence of a source phrase.151render XML codes as characters, etc.
), and tok-enize (abbreviations, numbers, punctuation, etc.
).However, these rules are fairly generic and appli-cable to most Western languages.
In particular,we did not perform any morphologically-sensitivesegmentation.
From the clean text we calculatedthe expected word and character ratios betweenthe source language and the target language.
Thenwe proceeded to remove sentence pairs accordingto the following heuristics:?
A sentence exceeded 125 words?
A sentence exceeded 1,000 characters?
The square of the difference between theactual and expected words divided by thesquare of the standard deviation exceeded 5?
The square of the difference between the ac-tual and expected characters divided by thesquare of the standard deviation exceeded 5All of these processing routines are included aspart of the Cunei distribution and are configurableoptions.
An overview of the resulting corpora isshown in Table 1.Finally, we used the GIZA++ toolkit (Och andNey, 2003) to induce word alignments in both di-rections for each language pair.
The resulting cor-pus and word alignments were provided to Mosesand Cunei for training.
Each system used theirrespective phrase extraction and model estimationroutines.2.2 Language ModelWe intentionally selected two language pairs thattranslated into English so that we could share onelanguage model between them.
We used the largemonolingual English News text made availablethrough the workshop and augmented this withthe Xinhua and AFP sections of the English Gi-gaword corpus (Parker and others, 2009).
In all,approximately one billion words of English textwere fed to the SRILM toolkit (Stolcke, 2002) toconstruct a single English 5-gram language modelwith Kneser-Ney smoothing.2.3 ExperimentsThe newswire evaluation sets from the prior twoyears were selected as development data.
636 sen-tences were sampled from WMT ?09 for tuningand all 2,051 sentences from WMT ?08 were re-served for testing.
Finally, a blind evaluation wasalso performed with the new WMT ?10 test set.All systems were tuned toward BLEU (Papineniet al, 2002) and all evaluation metrics were runon lowercased, tokenized text.The results in Table 2 and Table 3 show the per-formance of Cunei3 against the Moses system wealso built with the same data.
The first Cunei sys-tem we built included all the alignment featuresdiscussed in ?1.3.
These per-instance alignmentfeatures are essential to Cunei?s run-time phraseextraction and cannot be disabled.
The second,and complete, system added to this all the contextfeatures described in ?1.2.
Cunei, in general, per-forms significantly better than Moses in Germanand is competitive with Moses in Czech.
However,we hoped to see a larger gain from the addition ofthe context features.In order to better understand our results and seeif there was greater potential for the context fea-tures, we selectively added a few of the features ata time to the German system.
These experimentsare reported in Table 4.
What is interesting hereis that most subsets of context features did betterthan the whole and none degraded the baseline (atleast according to BLEU) on the test sets.
We didnot expect a fully additive gain from the combina-tion, as many of the context features do representdifferent ways of capturing the same phenomena.However, we were still surprised to find an appar-ently detrimental interaction among the full set ofcontext features.Theoretically adding new features should onlyimprove a system as a feature can always by ig-nored by assigning it a weight of zero.
How-ever, new features expand the hypothesis spaceand provide the model with more degrees of free-dom which may make it easier to get stuck in lo-cal minima.
While the gradient-based, annealingmethod for optimization that we use tends workbetter than MERT (Och, 2003), it is still suscep-tible to these issues.
Indeed, the variation on thetuning set?while relatively inconsequential?is ev-idence that this is occurring and that we have notfound the global optimum.
Further investigation isnecessary into the interaction between the contextfeatures and techniques for robust optimization.3These results have been updated since the officialWMT ?10 submission as a result of minor bug-fixes and codeimprovements to Cunei.152German English Czech EnglishTokens 41,245,188 43,064,069 63,776,164 72,325,831Sentences 1574044 6181270Table 1: Corpus Statistics2.4 ConclusionWe used the Cunei Machine Translation Platformto build German to English and Czech to Englishsystems for the WMT ?10 evaluation.
In bothsystems we experimented with per-instance align-ment and context features.
Our addition of thecontext features resulted in only minor improve-ment, but a deeper analysis of the individual fea-tures suggests greater potential.
Overall, Cuneiperformed strongly in our evaluation against acomparable Moses system.
We acknowledge thatthe actual features we selected are not particu-larly novel.
Instead, the importance of this workis the simplicity with which instance-specific fea-tures can be jointly modeled and integrated withinCunei as a result of its unique modeling approach.AcknowledgementsThe author would like to thank Ralf Brown forproviding suggestions and feedback on this paper.ReferencesOndr?ej Bojar and Zdene?k Z?abokrtsky?.
2009.Czeng0.9: Large parallel treebank with rich annota-tion.
Prague Bulletin of Mathematical Linguistics,92.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran,Richard Zens, Chris Dyer, Ondrej Bojar, AlexandraConstantin, and Evan Herbst.
2007.
Moses: Opensource toolkit for statistical machine translation.
InProceedings of the 45th Annual Meeting of the As-sociation for Computational Linguistics, pages 177?180, Prague, Czech Republic, June.Philipp Koehn.
2005.
Europarl: A parallel corpus forstatistical machine translation.
In Machine Transla-tion Summit X Proceedings (mts, 2005), pages 79?86.Zhifei Li, Chris Callison-Burch, Chris Dyer, San-jeev Khudanpur, Lane Schwartz, Wren Thornton,Jonathan Weese, and Omar Zaidan.
2009.
Joshua:An open source toolkit for parsing-based machinetranslation.
In Proceedings of the Fourth Workshopon Statistical Machine Translation, pages 135?139,Athens, Greece, March.Percy Liang, Ben Taskar, and Dan Klein.
2006.
Align-ment by agreement.
In Proceedings of the Hu-man Language Technology Conference of the NorthAmerican Chapter of the Association for Computa-tional Linguistics, pages 104?111, New York City,USA, June.Jianhua Lin.
1991.
Divergence measures based on theshannon entropy.
IEEE Transactions on InformationTheory, 37(1):145?151, January.2005.
Phuket, Thailand, September.Franz Josef Och and Hermann Ney.
2003.
A sys-tematic comparison of various statistical alignmentmodels.
Computational Linguistics, 29(1):19?51.Franz Josef Och.
2003.
Minimum error rate train-ing in statistical machine translation.
In Proceed-ings of the 41st Annual Meeting of the Associationfor Computational Linguistics, pages 160?167, Sap-poro, Japan, July.Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu.
2002.
Bleu: a method for automatic eval-uation of machine translation.
In Proceedings of the40th Annual Meeting of the Association for Com-putational Linguistics, pages 311?318, Philadelphia,USA, July.Robert Parker et al 2009.
English gigaword fourthedition.Aaron B. Phillips and Ralf D. Brown.
2009.
Cuneimachine translation platform: System description.In Mikel L. Forcada and Andy Way, editors, Pro-ceedings of the 3rd Workshop on Example-BasedMachine Translation, pages 29?36, Dublin, Ireland,November.David A. Smith and Jason Eisner.
2006.
Minimumrisk annealing for training log-linear models.
InProceedings of the 21st International Conference onComputational Linguistics and 44th Annual Meet-ing of the Association for Computational Linguis-tics, pages 787?794, Sydney, Australia, July.Andreas Stolcke.
2002.
Srilm - an extensible languagemodeling toolkit.
In 7th International Conferenceon Spoken Language Processing, pages 901?904,Denver, USA, September.Stephan Vogel.
2005.
Pesa: Phrase pair extraction assentence splitting.
In Machine Translation SummitX Proceedings (mts, 2005), pages 251?258.153DevelopmentTuningDevelopmentTestBlindTestBLEUNISTMeteorTERBLEUNISTMeteorTERBLEUNISTMeteorTERMoses0.19165.91560.52860.64750.20466.28020.53300.65230.20976.56570.55910.6313CuneiwithAlignment0.20185.98470.53260.63750.21256.36390.53420.64300.22106.63550.55730.6224CuneiwithAlignment&Context0.20226.00210.53310.63620.21276.37530.53440.64080.22146.64670.55750.6198Table2:OverviewofGermantoEnglishEvaluationsDevelopmentTuningDevelopmentTestBlindTestBLEUNISTMeteorTERBLEUNISTMeteorTERBLEUNISTMeteorTERMoses0.21416.19690.55360.61700.20416.35740.53610.64220.22976.79160.56170.6054CuneiwithAlignment0.22066.26340.55550.61280.20586.41160.54250.63910.22916.84640.56650.6003CuneiwithAlignment&Context0.21706.28020.55670.61250.20656.43910.53980.63620.23156.88290.56760.5984Table3:OverviewofCzechtoEnglishEvaluationsDevelopmentTuningDevelopmentTestBlindTestBLEUNISTMeteorTERBLEUNISTMeteorTERBLEUNISTMeteorTERCunei0.20185.98470.53260.63750.21256.36390.53420.64300.22106.63550.55730.6224+Origins0.20106.02330.53700.63530.21506.41540.53610.63910.22216.67190.56090.6208+AdjacentLength&Skew0.20026.00800.53380.64020.21476.41830.53540.64310.22376.73360.55740.6172+AdjacentN-grams0.20115.96480.53100.64100.21376.35980.53290.64340.22356.66560.55640.6202+DocCosine&JSD0.19875.95140.53050.64220.21346.34980.53240.64560.22286.66470.55790.6209+DocPrecision&Recall0.20075.97640.53150.63760.21456.39840.53610.64100.22446.69000.56080.6206Table4:BreakdownofContextFeaturesinGermantoEnglish154
