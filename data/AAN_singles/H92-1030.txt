AUTOMATICALLY  ACQUIR ING PHRASESTRUCTURE US ING D ISTR IBUT IONAL ANALYS ISEric Brill and Mitchell Marcus*Department ofComputer ScienceUniversity of PennsylvaniaPhiladelphia, Pa. 19104brill~unagi.cis.upenn.edu, mit ch@unagi.cis.upenn.eduABSTRACTIn this paper, we present evidence that the acquisition of thephrase structure of a natural anguage is possible without su-pervision and with a very small initial grammar.
We describea language learner that extracts distributional informationfrom a corpus annotated with parts of speech and is able touse this extracted information to accurately parse short sen-tences.
The phrase structure learner is part of an ongoingproject to determine just how much knowledge of languagecan be learned solely through distributional analysis.1.
INTRODUCTIONThis paper is an exploration into the possibility of auto-matically acquiring the phrase structure of a language.We use distributional analysis techniques imilar to thetechniques originally proposed by Zellig Harris \[5\] forstructural inguists to use as an aid in uncovering thestructure of a language.
Harris intended his techniquesto be carried out by linguists doing field work, as asubstitute for what he perceived as unscientific informa-tion gathering by linguists at the time.
The proceduresHarris describes are intended to uncover "regularities\[...\] in the distributional relations among the featuresof speech in question" (page 5).
To use distributionalanalysis to determine mpirically whether boy and girlare in the same word class, the linguist would need todetermine whether the two words are licensed to occurin the same environments.
Harris presented algorithmslinguists could use to detect distributionally similar en-tities.Harris did not intend the procedures he proposed to beused as a model of child language acquisition or as a toolfor computerized language learning.
This would not befeasible because the method Harris describes for deter-mining distributional similarity does not seem amenableto unsupervised acquisition.
One way of determiningwhether boy and girl are in the same word class is to seewhether it is the case that for all sentences that boy oc-curs in, the same sentence with girl substituted for boyis an allowable sentence.
To do this automatically from*This work was supported by DARPA and AFOSR jointly un-der grant No.
AFOSR-90-0066, and by ARO grant No.
DAAL03-89-C0031 PRI.text, one would need a prohibitively large corpus.
Thislack of sufficient data does not arise in field work be-cause the linguist has access to informants, who are ineffect infinite corpora.
If one hears the boy finished thehomework, the informant can be queried whether the girlfinished the homework is also permissible.The procedures Harris outlines for the linguist to use todiscover linguistic structure could be used to automat-ically acquire grammatical information if it were possi-ble to do away with the need for a human informant.It is possible that a variation of these procedures couldextract information by observing distributional similari-ties in a sufficiently large corpus of unparsed text.
In anearlier paper \[2\], we demonstrated that simple distribu-tional analysis over a corpus can lead to the discovery ofword classes.
In this paper, we describe work in whichwe apply distributional analysis in an attempt o auto-matically acquire the phrase structure of a language.We describe a system which automatically acquires En-glish phrase structure, given only the tagged Brown Cor-pus \[4\] as input.
The system acquires a context-freegrammar where each rule is assigned a score.
Once thegrammar is learned, it can be used to find and scorephrase structure analyses of a string of part of speechtags.
The nonterminal nodes of the resulting phrasestructure tree are not labelled.
The system is able toassign a phrase structure analysis consistent with thestring of part of speech tags with high accuracy.There have been several other recent proposals for au-tomatic phrase structure acquisition based on statisticsgathered over large corpora.
In \[1, 9\], a statistic basedon mutual information is used to find phrase boundaries.\[11\] defines a function to score the quality of parse trees,and then uses simulated annealing to heuristically ex-plore the entire space of possible parses for a given sen-tence.
A number of papers describe results obtained us-ing the Inside-Outside algorithm to train a probabilisticcontext-free grammar \[10, 6, 8\].
Below we describe analternate method of phrase structure acquisition.1552.
HOW IT WORKSThe system automatically acquires a grammar of scoredcontext-free rules, where each rule is binary branching.Two sources of distributional information are used toacquire and score the rules.
The score for the rule tag~tagy tagz is a function of:1.
The distributional similarity of the part of speechtag tagx and the pair of tags tagy tagz.2.
A comparison of the entropy of the environmenttagy _ and tagy tagz --.
The entropy of environ-ment tag~ _ is a measure of the randomness of thedistribution of tags occurring immediately after tag~in the corpus.2.1.
Substitutabil ityThe system is based upon the assumption that if twoadjacent part of speech tags are distributionally similarto some single tag, then it is probable that the two tagsform a constituent.
If tag~: is distributionally similar totagy tagz, then tags can be substituted for tagy tagz inmany environments.
If a single tag is substitutable fora pair of adjacent ags, it is highly likely that that pairof tags makes up a syntactically significant entity, i.e.
aphrase.For example, words labelled with the tag Pronoun andwords labelled with the tag pair Determiner Noun aredistributionally similar.
Distributionally, Pronoun canoccur in almost all environments in which DeterminerNoun can occur.
In the tag sequence Determiner NounVerb, we could discover that Determiner Noun is a con-stituent and Noun Verb is not, since no single lexical itemhas distributional behavior similar to the pair of tagsNoun Verb.
Once we know these distributional facts,as well as the fact that the single tag Verb and the tagpair Pronoun Verb distribute similarly (eat fish :: weeat fish), we can find the structure of the tag sequenceDeterminer Noun Verb by recursively substituting singlepart of speech tags for pairs of tags.
This would result inthe structurally correct (ignore the nonterminal labels):VerbDeterminer Noun VerbTo carry out the above analysis, we made use of ourknowledge of the language to determine that the tagPronoun is distributionally similar to (substitutable for)the pair of tags Determiner Noun.
Unfortunately, thesystem does not have access to such knowledge.
How-ever, an approximation to this knowledge can be learned.For each possible context-free rule tagx ~ tagu tagz, thesystem assigns a value indicating the distributional sim-ilarity of tagx to the pair of tags tagy tagz.
The measureused to compute the similarity of tag~ to tagy tagz isknown as divergence \[7\].Let P1 and P2 be two probability distributions over en-vironments.
The relative entropy between P1 and P2is:D(PiIIP2) = ~ Px(x) ?
tog Pa(x)Relative entropy D(PIIIP2) is a measure of the amount ofextra information beyond Pz needed to describe P1.
Thedivergence between P1 and P2 is defined as D(PIlIP2) +D(P21IP1), and is a measure of how difficult it is to distin-guish between the two distributions.
Two entities will beconsidered to distribute similarly, and therefore be sub-stitutable, if the divergence of their probability distribu-tions over environments i  low.
In part, this work is anattempt o test the claim that a very local definition ofenvironment is sufficient for determining distributionalsimilarity.
1We will now describe how we can use the distributionalsimilarity measure to extract a binary context-free gram-mar with scored rules from a corpus.
Statistics of thefollowing form are collected:1. word1 tag~ word2 number2.
word1 tagy tagz word2 numberwhere in (1), numberis the number of times in the corpusthe word between words word1 and word2 is tagged withtagx, and in (2), number is the number of times that thepair of words between word1 and word2 is tagged withtagy,tag~.
For instance, in the Brown Corpus, the partof speech tag NP 2 appears between the words gave anda three times, and the tags AT NN ?
occur six times inthis environment.1Evidence that this claim is valid for word class discovery ispresented in \[1, 2, 3\].2NP = proper noun.3AT = article, NN = sing.
noun.156From this, we obtain a set of context-free rules tag~tagy tags, scored by the distributional similarity of tag~and tagy tags .
The score given to the rule is the diver-gence between the probability distributions of tag~ andtagy tagz over environments, where an environment is ofthe form word  ---  word.Below are the five single tags found to be distributionallymost similar to the pair of tags AT NN, found by mea-suring divergence of distributions over the environmentsword  - -  word:  .1.
NP (Proper Noun)2.
CD (Number)3.
NN (Sing.
Noun)4.
NNS (Plural Noun)5.
PPO (Object Personal Pronoun)2 .2 .
Ad jus t ing  ScoresThe scored CFG described above works fairly well, butmakes a number of errors.
There are a number of caseswhere a phrase is posited when the pair of symbols donot really constitute a phrase.
For instance, VBD andVBD IN 4 have similar distributional behavior.
(Johnand Mary k i ssed /VBD in / IN  the car vs. John andMary bought /VBD the car).
If we had access to lexi-cal information, this would not be a problem.
The prob-lem results from discarding the lexical items and replac-ing them with their part of speech tags.
If we are tocontinue our analysis on part of speech tags, a differentinformation source is needed to recognize problematicrules such as VBD ~ VBD IN which are incorrectlygiven a good score.
We extract more n-gram statistics,this time of the form:1. tagx tagy number2.
tag~ tagy tagz numberOf all rules with AT NN on the right hand side, the ruleNP ~ AT NN would be given the best score.
Beloware the five tag pairs found to be closest o the single tagNP.
Of all rules with NP on the left hand side, NPNP NP  is given the best score.1.
NP NP (Robert/NP Snodgrass/NP)which is a file of pairs and triples of part of speech tagsand the number of times the tag strings occur in thecorpus.
The entropy of the position after tags in thecorpus is a measure of how constrained that position is.This entropy (H) is computed as:H(tag=_) = - ~ p(tagy I tag=)*log2p(tagy I tag=)tag~ETagSe~2.
PP$ NN (his/PP$ staff/NN)3.
NN NNS (city/NN employees/NNS)4.
NP$ NN (Gladden's/NP$ wife/NN)5.
AT iN  (the/AT man/NN)Once the scored context-free grammar is learned, thereare a number of ways to use that grammar to search forthe correct phrase structure analysis of a sentence.
Forthe results reported at the end of the paper, we used thesimplest method: find the best set of rules that allowthe part of speech string to be reduced to a single partof speech.
The best set is that set of rules whose scoressum to the lowest number.
In other words, we search forthe set of rules with the lowest total divergence betweenthe pair of tags on the right hand side of the rule andthe single tag these two tags will be reduced to.
Thestructure assigned by this set of rules, ignoring nonter-minal labels, is output as the structural description ofthe sentence.Likewise, we can compute the entropy of the positionfollowing the pair of tags tag~ and tagy.
If tag, tagy isindeed a constituent, we would expect:H(tagx --) < H(tagx tagy _)This is because a phrase internal position in a sentenceis more constrained as to what can follow than a phraseboundary position.
We can use this information to read-just the scores in the grammar.
The score of each ruleof the form tagz ---~ tagx tagy is multiplied by a functionof Entropy(tag~ tagy _) - Entropy(tag~ _), to rewardthose rules for which the entropy-based metric indicatesthat they span a true constituent and to penalize thoseinvolving nonconstituents.
For instance, the measureEntropy(tags tagy _) - Entropy(tag~ _)  has a value of1.4 for the pair of tags AT NN 5, and a value of -0.8 forthe pair of tags VBD IN, the troublesome tag pair men-tioned above.4VBD = past  verb ,  IN  = prepos i t ion .5AT  NN = Determiner  Noun - a t rue  phrase .157At this point the learner makes one major mistake onshort sentences.
Sometimes, but not always, the subjector some part of the subject is joined to the verb beforethe object is.
For example, the system assigns a slightlybetter score to the parse ((PPS VBD) PPO) 6 than tothe correct parse (PPS (VBD PPO)).
To remedy this,we need a rule specifying that a matrix verb must joinwith its object before joining with its subject.3.
RESULTSAfter running this learning procedure on the Brown Cor-pus, a grammar of 41,000 rules was acquired.
We took asubset of these rules (about 7,500), choosing the fifteenbest scoring rules for all tag pairs appearing on the righthand side of some rule.The parser is given a string of part of speech tags asinput and uses its automatically acquired grammar tooutput an unlabelled binary-branching syntactic tree forthe string.
Since lexical information is thrown away, acorrect answer is considered to be an analysis that is con-sistent with the tag set.
The goal of this work is to auto-matically create from a tagged corpus a corpus of simplesentences annotated with phrase structure.
In the nextphase of the project, we plan to extract a richer gram-mar from the corpus of trees.
Therefore, we were notconcerned when no answer was returned by the parser,as long as this did not happen with high probability.
Ifthe parser fails to parse a sentence, that sentence wouldnot be present in the corpus of trees.
However, if theparser incorrectly parses a sentence, the error will be en-tered into the corpus.
The higher the error rate of thiscorpus, the more difficult the next stage of acquisitionwould be.The table below shows the results obtained by testingthe system on simple sentences.
A simple sentence is de-fined as a sentence with between five and fourteen words,containing no coordinates, quotations, or commas.CorrectNo Unparsed Sents 71%With Unparsed Sents 62%Close Wrong11% 18%10% \[ 28%Table 1: Summary of Acquisition and Parsing AccuracyIn the table, correct means that the parse was a validparse for the string of tags, close means that by perform-ing the operation of moving one bracket and then bal-ancing brackets, the parse can be made correct.
Wrong6PPS = subject  pers.
pron., VBD = past  verb, PPO = obj.pets.
pron.means that the parse was more than one simple oper-ation away from being correct.
Of all test sentences,15% were not parsed by the system.
Of those sentences,many failed because the beam search we implementedto speed up parsing does not explore the entire space ofparses allowed by the grammar.
Presumably, many ofthese sentences could be parsed by widening the beamwhen a sentence fails to parse.One question that remains to be answered is whetherthere is a way to label the nonterminals in the treesoutput by the system.
The tree below was given the bestscore for that particular part of speech tag sequence.VBAT JJ NN VBD PPOThe daring boy chased himI f  all part of speech tags are assigned a particular non-terminal label (PPS and NN would be classed as NP .VB, VBD would be classed as VP)  7 and replaced thetags with their nonterminal labels, we would get a prop-erly labelled tree for the above structure.
It remainsto be seen whether this idea can be extended to accu-rately assign nonterminal labels to the trees output bythe parser.4.
CONCLUSIONWe believe that these results are evidence that automaticphrase structure acquisition is feasible.
In addition tothe problem of labelling nonterminals, we are currentlyworking on expanding the learner so it can handle morecomplex sentences and take lexical information into ac-count when parsing a sentence.~PPS = 3rd sing.
nom.
pi'onoun, NN = sing.
noun, VB =verb, VBD = past verb158References1.
Brill, E., Magerman, D., Marcus, M., and Santorini, B.
(1990) Deducing linguistic structure from the statisticsof large corpora.
In Proceedings of the DARPA Speechand Natural Language Workshop, Morgan Kaufmann,1990.2.
BriU, Eric.
(1991) Discovering the lexical features of alanguage.
In Proceedings off the 29th Annual Meeting ofthe Association for Computational Linguistics, Berkeley,CA.3.
Brown, P., Della Pietra, V., Della Pietra, S. and Mer-cer, R. (1990) Class-based n-gram models of natural an-guage.
In Proceedings of the IBM Natural Language ITL,pp.
283-298, Paris, France.4.
Francis, W. Nelson and Ku~era, Henry, Frequency anal-ysis of English usage.
Lexicon and grammar.
HoughtonMifflin, Boston, 1982.5.
Harris, Zelfig.
(1951) Structural Linguistics.
Chicago:University of Chicago Press.6.
Jelinek, F., Lafferty, J., and Mercer, R. (1990) Basicmethods of probabifistic context free grammars.
Techni-cal Report RC 16374 (72684), IBM, Yorktown Heights,New York 10598.7.
Kullback, Solomon.
(1959) Information Theory andStatistics.
New York: John Wiley and Sons.8.
Lari, K. and Young, S. (1990) The estimation of stochas-tic context-free grammars using the inside-outside algo-rithm.
Computer Speech and Language, 4:35-56.9.
Magerman, D. and Marcus, M. (1990) Parsing a naturallanguage using mutual information statistics, Proceed-ings, Eighth National Conference on Artificial Intelli-gence (AAA1 90), 1990.10.
Pereira, F. and Schabes, Y.
(1992) Inside-outside r esti-mation from partially bracketed corpora.
Also in theseproceedings.11.
Sampson, G. (1986) A stochastic approach to parsing.In Proceedings of COLING 1986, Bonn.159
