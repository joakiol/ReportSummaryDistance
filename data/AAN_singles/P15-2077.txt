Proceedings of the 53rd Annual Meeting of the Association for Computational Linguisticsand the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 470?476,Beijing, China, July 26-31, 2015.c?2015 Association for Computational LinguisticsEarly and Late Combinations of Criteria for Reranking DistributionalThesauriOlivier FerretCEA, LIST, Vision and Content Engineering Laboratory,Gif-sur-Yvette, F-91191 France.olivier.ferret@cea.frAbstractIn this article, we first propose to ex-ploit a new criterion for improving distri-butional thesauri.
Following a bootstrap-ping perspective, we select relations be-tween the terms of similar nominal com-pounds for building in an unsupervisedway the training set of a classifier perform-ing the reranking of a thesaurus.
Then, weevaluate several ways to combine thesaurireranked according to different criteria andshow that exploiting the complementaryinformation brought by these criteria leadsto significant improvements.1 IntroductionThe work presented in this article aims at im-proving thesauri built following the distributionalapproach as implemented by (Grefenstette, 1994;Lin, 1998; Curran and Moens, 2002).
A part ofthe work for improving such thesauri focuses onthe filtering of the components of the distribu-tional contexts of words (Padr?o et al., 2014; Po-lajnar and Clark, 2014) or their reweighting, ei-ther by turning the weights of these componentsinto ranks (Broda et al., 2009) or by adaptingthem through a bootstrapping method from thethesaurus to improve (Zhitomirsky-Geffet and Da-gan, 2009; Yamamoto and Asakura, 2010).
Theother part implies more radical changes, includ-ing dimensionality reduction methods such as La-tent Semantic Analysis (Pad?o and Lapata, 2007),multi-prototype (Reisinger and Mooney, 2010) orexemplar-based models (Erk and Pado, 2010),neural approaches (Huang et al., 2012; Mikolov etal., 2013) or the adoption of a Bayesian viewpoint(Kazama et al., 2010; Dinu and Lapata, 2010).Our work follows (Ferret, 2012), which pro-posed a different way from (Zhitomirsky-Geffetand Dagan, 2009) to exploit bootstrapping by se-lecting in an unsupervised way a set of semanti-cally similar words from an initial thesaurus andtraining from them a classifier to rerank the se-mantic neighbors of the initial thesaurus entries.More precisely, we propose a new criterion for thisselection, based on the similarity relations of thecomponents of similar compounds, and we showtwo modes ?
early and late ?
of combination ofthesauri reranked from different criteria, includingours, leading to significant further improvements.2 Reranking a distributional thesaurusDistributional thesauri are characterized by het-erogeneous performance in their entries, even forhigh frequency entries.
This is a favorable situa-tion for implementing a bootstrapping approach inwhich the results for ?good?
entries are exploitedfor improving the results of the other ones.
How-ever, such idea faces two problems: first, detect-ing ?good?
entries; second, learning a model fromthem for improving the performance of the otherentries.The first issue consists in selecting without su-pervision a set of positive and negative examplesof similar words that represents a good compro-mise between its error rate and its size.
Straight-forward solutions such as using the similarityvalue between an entry and its neighbors or relyingon the frequency of entries are not satisfactory interms of error rate.
Hence, we propose in Section 3a new method, based on the semantic composi-tionality hypothesis of compounds, for achievingthis selection in a more indirect way and show theinterest to combine it with the criterion of (Ferret,2012) for building a large training set with a rea-sonable error rate.We address the second issue by following(Hagiwara et al., 2009), which defined a Sup-port Vector Machine (SVM) model for decidingwhether two words are similar or not.
In our con-text, a positive example is a pair of nouns that are470semantically similar while a negative example isa pair of non similar nouns.
The features of eachpair of nouns are built by summing the weights ofthe elements shared by their distributional repre-sentations, which are vectors of weighted cooccur-rents.
Cooccurrents not shared by the two nounsare given a null weight.This SVM model is used for improving a the-saurus by reranking its semantic neighbors as fol-lows: for each entry E of the thesaurus, the rep-resentation as an example of the word pair (E,neighbor) is built for each of the neighbors of Eand submitted to the SVM model in classificationmode.
Finally, all the neighbors of E are rerankedaccording to the value of the decision functioncomputed for each neighbor by the SVM model.3 Unsupervised example selectionThe evaluation of distributional thesauri showsthat a true semantic neighbor is more likely to befound when the thesaurus entry is a high frequencynoun and the neighbor has a low rank.
However,relying only on these two criteria doesn?t lead toa good enough set of positive examples.
For in-stance, taking as positive examples from the ini-tial thesaurus of Section 4 the first neighbor of its2,148 most frequent entries, the number of pos-itive examples of (Hagiwara et al., 2009), onlyleads to 44.3% of correct examples.
Moreover,this percentage exceeds 50% only when the num-ber of examples is less than 654, which representsa very small training set for this kind of task.Hence, we propose a more selective approachfor choosing positive examples among high fre-quency nouns to get a more balanced solution be-tween the number of examples and their error rate.This approach exploits a form of semantic compo-sitionality hypothesis of compounds.
While muchwork has been done recently for defining the dis-tributional representation of compounds by com-posing the distributional representations of theircomponents (Mitchell and Lapata, 2010; Papernoet al., 2014), we adopt a kind of reverse viewpointby exploiting the possibility to link the meaningof a compound to the meaning of its components.More precisely, we assume that the mono-termsof two semantically related compounds with thesame syntactic role in their compound are likelyto be semantically linked themselves.In this work, we only consider compounds hav-ing one of these three term structures (with theirpercentage of the vocabulary of compounds):(a) <noun>mod<noun>head(30)(b) <adjective>mod<noun>head(58)(c) <noun>head<preposition><noun>mod(12)Each compound Ciis represented as a pair(Hi,Mi), where Histands for the head of thecompound whereas Mirepresents its modifier(mod).
According to the assumption underlyingour selection procedure, if a compound (H2,M2)is a semantic neighbor of a compound (H1,M1)(i.e.
at most its cthneighbor in a distributional the-saurus of compounds), we can expect H1and H2on one hand and M1and M2on the other hand tobe semantically similar.
Since distributional the-sauri of compounds are far from being perfect, weadded constraints on the matching of the compo-nents of two compounds.
More precisely, the posi-tive examples of semantically similar nouns (nounpairs after?)
are selected by the three followingrules, where H1= H2means that H1is the sameword asH2andH1?
H2means thatH2is at mostthe mthneighbor of H1in the initial thesaurus ofmono-terms (but is different from H1):(1) H1?
H2& M1= M2?
(H1, H2)(2) M1?M2& H1= H2?
(M1, M2)(3) M1?M2& H1?
H2?
(H1, H2), (M1, M2)The selection of negative examples is also animportant issue but benefits from the fact that thenumber of semantic neighbors of an entry thatare actually semantically linked to this entry in adistributional thesaurus quickly decreases as theirrank increase.
In the experiments of Section 4,we built negative examples from positive exam-ples by turning each positive example (A,B) intotwo negative examples: (A, rank 10 A neighbor)and (B, rank 10 B neighbor).
Choosing neighborswith a higher rank would have guaranteed fewerfalse negative examples but taking neighbors witha rather small rank for building negative examplesis more useful in terms of discrimination.4 Experiments and evaluation4.1 Building of distributional thesauriThe first step of the work we present is the build-ing of two distributional thesauri: the thesaurus ofmono-terms to improve (A2ST) and a thesaurusof compounds (A2ST-comp).
Similarly to (Ferret,2012), they were both built from the AQUAINT-2corpus, a 380 million-word corpus of news arti-cles in English.
The building procedure, defined471by (Ferret, 2010), was also identical to (Ferret,2012), with distributional contexts compared withthe Cosine measure and made of window-basedlemmatized cooccurrents (1 word before and af-ter) weighted by Positive Pointwise Mutual Infor-mation (PPMI).
For the thesaurus of compounds,a preprocessing step was added to identify nom-inal compounds in texts.
This identification wasdone in two steps: first, a set of compounds wereextracted from the AQUAINT-2 corpus by rely-ing on a restricted set of morpho-syntactic pat-terns applied by the Multiword Expression Toolkit(mwetoolkit) (Ramisch et al., 2010); then, themost frequent compounds in this set (frequency> 100) were selected as reference and their oc-currences in the AQUAINT-2 corpus were iden-tified by applying the longest-match strategy tothe output of the TreeTagger part-of-speech tagger(Schmid, 1994)1.
Finally, distributional contextsmade of mono-terms and compounds were built asstated above and neighbors were found for 29,174compounds.4.2 Example selectionWe applied the three rules of Section 3 with allthe entries of our thesaurus of compounds and theupper half in frequency of our mono-term entries.For mono-terms, we only took the first neighbor(m = 1) of each entry because of the rather lowperformance of the initial thesaurus while for com-pounds, a larger value (c = 3) was chosen forenlarging the number of selected examples sinceneighbors were globally more reliable (see resultsof Table 2).
As the selection method makes thedefinition of a development set quite difficult, thevalues of these two parameters were chosen in aconservative way.Table 1 gives for each rule and two combina-tions of them the number of selected positive ex-amples (#pos.
ex.)
and the percentage of positive(%good pos.)
and negative examples (%bad neg.
)found in our Gold Standard resource for thesaurusevaluation.
This resource results from the union ofthe synonyms of WordNet 3.0 and the associatedwords of the Moby thesaurus.
Table 1 also givesthe same data for examples selected by the methodof (Ferret, 2012) (symmetry row, sym.
for short),based on the fact that as similarity relations are1Longest-match strategy: if C1 is a reference compoundthat is part of a reference compound C2, the identificationof an occurrence of C2 blocks out the identification of theassociated occurrence of C1.method %good pos.
%bad neg.
#pos.
ex.symmetry 59.7 12.4 796(1) 56.9 16.1 921(2) 44.7 14.7 308(3) 46.2 16.9 40rules (1,2) 53.0 16.1 1,115rules (1,2,3) 52.4 15.9 1,131sym.
+ (1,2) 54.3 15.0 1,710sym.
+ (1,2,3) 53.9 14.5 1,725Table 1: Selection of examples.symmetric, a pair of words (A,B) are more likelyto be similar if the first neighbor of A is B and thefirst neighbor of B is A.
The data for the union ofthe examples produced by the two methods alsoappear in Table 1.Concerning the method we propose, Table 1shows that rule (3), which is a priori the least reli-able of the three rules as it only requires similarityand not equality for both heads and modifiers, ac-tually produces a very small set of examples thattends to degrade global results.
As a consequence,only the combination of rules (1) and (2) is usedthereafter (row in bold).
Table 1 also suggests thatthe heads of two semantically linked compoundsare more likely to be actually linked themselvesif they have the same modifier than the modifiersof two semantically linked compounds having thesame head.
This confirms our expectation that thehead of a compound is more related to the mean-ing of the compound than its modifier.
More glob-ally, Table 1 shows that the symmetry method hashigher results than the second one but their associ-ation produces an interesting compromise betweenthe number of examples, 1,710, and its error rate,45.7.
The fact that the two methods only share 201noun pairs also illustrates their complementarity.4.3 Reranking evaluationFor our SVM models, we adopted the RBF kernel,as (Hagiwara et al., 2009), and a grid search strat-egy for optimizing both the ?
and C parametersby applying a 5-fold cross validation procedure toour training set and adopting the precision mea-sure as the evaluation function to optimize.
Themodels were built with LIBSVM (Chang and Lin,2001) and then applied to the neighbors of our ini-tial thesaurus.Table 2 gives the results of the reranking forboth the method we propose, compound (comp.for short), with examples selected by rules (1) and472(2), and the one of (Ferret, 2012), symmetry.
Ineither case, they correspond to an intrinsic evalu-ation achieved by comparing the semantic neigh-bors of each thesaurus entry with the synonymsand related words of our Gold Standard resourcefor that entry.
12,243 entries with frequency > 10were present in this resource and evaluated in sucha way.
As the neighbors are ranked according totheir similarity value with their entry, we adoptedthe classical evaluation measures of InformationRetrieval by replacing documents with synonymsand queries with entries: R-precision (R-prec.
),Mean Average Precision (MAP) and precision atdifferent cut-offs (1, 5 and 10).More precisely, the initial row of Table 2 givesthe values of these measures for our initial the-saurus of mono-terms while its A2ST-comp rowcorresponds to the measures for our thesaurus ofcompounds.
It should be note that in the case ofthe A2ST-comp thesaurus, the number of evalu-ated entries is very small, restricted to 813 entries,with also a very small number of reference syn-onyms by entry.
Hence, the results of the evalu-ation of A2ST-comp have to be considered withcaution even if their high level for the very first se-mantic neighbors tends to confirm the positive im-pact of the low level of ambiguity of compoundscompared to mono-terms.The two following rows gives the results of thethesauri built from the best models of (Baroni etal., 2014), B14-count for the count model, whosemain parameters are close or identical to ours,and B14-predict for the predict model, built from(Mikolov et al., 2013).
These results first illus-trate the known importance of corpus size, as the(Baroni et al., 2014)?s corpus is more than 7 timeslarger than ours, and the fact that for building the-sauri, the count model is superior to the predictmodel.
This last observation is confirmed by theresults of the skip-gram model of (Mikolov et al.,2013) with its best parameters2for our corpus (5throw), which clearly exhibits worst results than ini-tial.
For this Mikolov thesaurus and the follow-ing reranked ones, each value corresponds to thedifference between the measure for the consideredthesaurus and the measure for the initial thesaurus.All these differences were found statistically sig-nificant according to a paired Wilcoxon test withp-value < 0.05.2word2vec -cbow 0 -size 600 -window 10 -negative 0 -hs0 -sample 1e-5Thesaurus R-prec.
MAP P@1 P@5 P@10initial (A2ST) 7.7 5.6 22.5 14.1 10.8A2ST-comp 32.7 39.5 34.9 12.3 7.1B14-count 12.5 9.8 31.9 19.6 15.2B14-pred 10.9 8.5 30.3 18.4 13.8Mikolov -2.2 -1.4 -6.2 -4.6 -3.8symmetry +0.3 +0.1 +2.1 +0.8 +0.6compound +0.1 +0.0 +2.0 +0.9 +0.6sym.+comp.
+0.3 +0.2 +2.8 +1.2 +0.9RRF +0.7 +0.6 +3.7 +1.9 +1.4borda +0.7 +0.5 +3.6 +1.7 +1.3condorcet +0.5 +0.4 +3.4 +1.6 +1.2CombSum +0.9 +0.8 +4.7 +2.2 +1.5CS-w-Mik +1.2 +1.4 +4.2 +2.0 +1.5Table 2: Evaluation of our initial thesaurus and itsreranked versions (values = percentages).The analysis of the next two rows of Table 2first shows that each criterion used for rerankingour initial thesaurus leads to a global increase ofresults.
The extent of this increase is quite sim-ilar for the two criteria: symmetry slightly out-performs compound but the difference is not sig-nificant.
This increase is higher for P@{1,5,10}than for R-precision and MAP, which can be ex-plained by the high number of synonyms and re-lated words, 38.7 on average, that an entry of ourinitial thesaurus has in our reference.
Hence, evena significant increase of P@{1,5,10} may have amodest impact on R-precision and MAP as theoverall recall, equal to 9.8%, is low.4.4 Thesaurus fusionHaving several thesauri reranked according to dif-ferent criteria offers the opportunity to apply en-semble methods.
Such idea was already experi-mented in (Curran, 2002) for thesauri built withdifferent parameters (window or syntactic basedcooccurrents, etc).
We tested more particularlytwo general strategies for data fusion (Atrey et al.,2010): early and late fusions.
The first one con-sists in our case in fusing the training sets builtfrom our two criteria.
As for each criterion, a clas-sifier is then built from the fused training set andapplied for reranking the initial thesaurus (see thesym.+comp.
row of Table 2).Table 3 illustrates qualitatively the impact ofthis first strategy for the entry esteem.
Its Word-Net row gives all the synonyms for this entry inWordNet while its Moby row gives the first re-lated words for this entry in Moby.
In our initial473WordNet respect, admiration, regardMobyadmiration, appreciation, accep-tance, dignity, regard, respect, ac-count, adherence, consideration,estimate, estimation, fame, great-ness, homage + 79 words moreinitialcordiality, gratitude, admiration,comradeship, back-scratching,perplexity, respect, ruination,appreciation, neighbourliness .
.
.sym.+comp.respect, admiration, trust, recog-nition, gratitude, confidence, af-fection, understanding, solidarity,dignity, appreciation, regard, sym-pathy, acceptance .
.
.Table 3: Reranking for the entry esteem with theearly fusion strategy.thesaurus, the first two neighbors of esteem thatare present in our reference resources are admira-tion (rank 3) and respect (rank 7).
The rerankingproduces a thesaurus in which these two words ap-pear as the first two neighbors of the entry whileits third synonym in WordNet raises from rank 22to rank 12.
Moreover, the number of neighborsamong the first 14 ones that are present in Mobyincreases from 3 to 6.The late fusion strategy relies on the methodsused in Information Retrieval for merging rankedlists of retrieved documents.
More precisely, weexperimented the Borda, Condorcet (Nuray andCan, 2006) and Reciprocal Rank (RRF) (Cormacket al., 2009) fusions based on ranks and the Comb-Sum fusion based on similarity values, normalizedin our case with the Zero-one method (Wu et al.,2006).
The corresponding thesauri were built byfusing, entry by entry, the lists of neighbors com-ing from the initial, symmetry and compound the-sauri.Table 2 first shows that all the thesauri pro-duced by our ensemble methods outperform ourfirst three thesauri, which confirms that initial,symmetry and compound can bring complemen-tary information, exploited by the fusion.
It alsoshows that our late fusion methods are more ef-fective than our early fusion method.
However,no specific element advocates at this stage for ageneralization of this observation.
The evaluationreported by Table 2 also suggests that for fusingdistributional thesauri, the similarity of a neighborwith its entry is a more relevant criterion than itsrank.
Among the rank based methods, we observethat RRF is clearly superior to condorcet but onlyweakly superior to borda.
Finally, the last rowof Table 2 ?
CS-w-Mik ?
illustrates one step fur-ther the interest of ensemble methods for distribu-tional thesauri: whereas the ?Mikolov thesaurus?gets the worst results among all the thesauri of Ta-ble 2, adding it to the initial, symmetry and com-pound thesauri in the CombSum method leads toimprove both R-precision and MAP, with a onlysmall decrease of P@1 and P@5.
From a moreglobal perspective, it is interesting to note that ourbest method, CombSum, clearly outperforms thereranking method of (Ferret, 2013) with the sameinitial starting point.5 Conclusion and perspectivesIn this article, we have presented a method basedon bootstrapping for improving distributional the-sauri.
More precisely, we have proposed a newcriterion, based on the relations of mono-terms insimilar compounds, for the unsupervised selectionof training examples used for reranking the seman-tic neighbors of a thesaurus.
We have evaluatedtwo different strategies for combining this crite-rion with an already existing one and showed that alate fusion approach based on the merging of listsof neighbors is particularly effective compared toan early fusion approach based on the merging oftraining sets.We plan to extend this work by studying howthe combination of the unsupervised selection ofexamples and their use for training supervisedclassifiers can be exploited for improving distribu-tional thesauri through feature selection.
We willalso investigated the interest of taking into accountword senses in this framework, as in (Huang et al.,2012) or (Reisinger and Mooney, 2010).ReferencesPradeep K. Atrey, M. Anwar Hossain, AbdulmotalebEl Saddik, and Mohan S. Kankanhalli.
2010.
Mul-timodal fusion for multimedia analysis: a survey.Multimedia Systems, 16(6):345?379.Marco Baroni, Georgiana Dinu, and Germ?anKruszewski.
2014.
Don?t count, predict!
asystematic comparison of context-counting vs.context-predicting semantic vectors.
In 52ndAn-nual Meeting of the Association for ComputationalLinguistics (ACL 2014), pages 238?247, Baltimore,Maryland.Bartosz Broda, Maciej Piasecki, and Stan Szpakow-icz.
2009.
Rank-Based Transformation in Measur-474ing Semantic Relatedness.
In 22ndCanadian Con-ference on Artificial Intelligence, pages 187?190.Chih-Chung Chang and Chih-Jen Lin.
2001.
LIB-SVM: a library for support vector machines.http://www.csie.ntu.edu.tw/?cjlin/libsvm.Gordon V. Cormack, Charles L. A. Clarke, and Ste-fan Buettcher.
2009.
Reciprocal rank fusion outper-forms condorcet and individual rank learning meth-ods.
In 32ndInternational ACM SIGIR Conferenceon Research and Development in Information Re-trieval (SIGIR?09), pages 758?759.James R. Curran and Marc Moens.
2002.
Improve-ments in automatic thesaurus extraction.
In Work-shop of the ACL Special Interest Group on the Lexi-con (SIGLEX), pages 59?66, Philadelphia, USA.James Curran.
2002.
Ensemble methods for auto-matic thesaurus extraction.
In 2002 Conference onEmpirical Methods in Natural Language Processing(EMNLP 2002), pages 222?229.Georgiana Dinu and Mirella Lapata.
2010.
Measur-ing distributional similarity in context.
In 2010 Con-ference on Empirical Methods in Natural LanguageProcessing (EMNLP 2010), pages 1162?1172, MIT,Massachusetts, USA.Katrin Erk and Sebastian Pado.
2010.
Exemplar-basedmodels for word meaning in context.
In 48thth An-nual Meeting of the Association for ComputationalLinguistics (ACL 2010), short paper, pages 92?97,Uppsala, Sweden, July.Olivier Ferret.
2010.
Testing semantic similarity mea-sures for extracting synonyms from a corpus.
InSeventh conference on International Language Re-sources and Evaluation (LREC?10), Valletta, Malta.Olivier Ferret.
2012.
Combining bootstrapping andfeature selection for improving a distributional the-saurus.
In 20thEuropean Conference on ArtificialIntelligence (ECAI 2012), pages 336?341, Montpel-lier, France.Olivier Ferret.
2013.
Identifying bad semanticneighbors for improving distributional thesauri.
In51stAnnual Meeting of the Association for Com-putational Linguistics (ACL 2013), pages 561?571,Sofia, Bulgaria.Gregory Grefenstette.
1994.
Explorations in auto-matic thesaurus discovery.
Kluwer Academic Pub-lishers.Masato Hagiwara, Yasuhiro Ogawa, and KatsuhikoToyama.
2009.
Supervised synonym acquisitionusing distributional features and syntactic patterns.Information and Media Technologies, 4(2):59?83.Eric H. Huang, Richard Socher, Christopher D. Man-ning, and Andrew Y. Ng.
2012.
Improving wordrepresentations via global context and multiple wordprototypes.
In 50th Annual Meeting of the Associa-tion for Computational Linguistics (ACL?12), pages873?882.Jun?ichi Kazama, Stijn De Saeger, Kow Kuroda,Masaki Murata, and Kentaro Torisawa.
2010.
Abayesian method for robust estimation of distribu-tional similarities.
In 48thAnnual Meeting of theAssociation for Computational Linguistics, pages247?256, Uppsala, Sweden.Dekang Lin.
1998.
Automatic retrieval and cluster-ing of similar words.
In 17thInternational Confer-ence on Computational Linguistics and 36thAnnualMeeting of the Association for Computational Lin-guistics (ACL-COLING?98), pages 768?774, Mon-tral, Canada.Tomas Mikolov, Wen-tau Yih, and Geoffrey Zweig.2013.
Linguistic regularities in continuous spaceword representations.
In 2013 Conference of theNorth American Chapter of the Association forComputational Linguistics: Human Language Tech-nologies (NAACL HLT 2013), pages 746?751, At-lanta, Georgia.Jeffrey Mitchell and Mirella Lapata.
2010.
Composi-tion in distributional models of semantics.
CognitiveScience, 34(8):1388?1439.Rabia Nuray and Fazli Can.
2006.
Automatic rank-ing of information retrieval systems using data fu-sion.
Information Processing and Management,42(3):595?614.Sebastian Pad?o and Mirella Lapata.
2007.Dependency-based construction of semantic spacemodels.
Computational Linguistics, 33(2):161?199.Muntsa Padr?o, Marco Idiart, Aline Villavicencio, andCarlos Ramisch.
2014.
Nothing like good old fre-quency: Studying context filters for distributionalthesauri.
In 2014 Conference on Empirical Methodsin Natural Language Processing (EMNLP 2014),pages 419?424, Doha, Qatar.Denis Paperno, Nghia The Pham, and Marco Baroni.2014.
A practical and linguistically-motivated ap-proach to compositional distributional semantics.
In52ndAnnual Meeting of the Association for Compu-tational Linguistics (ACL 2014), pages 90?99, Bal-timore, Maryland.Tamara Polajnar and Stephen Clark.
2014.
Improv-ing distributional semantic vectors through contextselection and normalisation.
In 14thConference ofthe European Chapter of the Association for Compu-tational Linguistics (EACL 2014), pages 230?238,Gothenburg, Sweden.Carlos Ramisch, Aline Villavicencio, and ChristianBoitet.
2010. mwetoolkit: a Framework for Multi-word Expression Identification.
In Seventh Interna-tional Conference on Language Resources and Eval-uation (LREC 2010), Valetta, Malta, May.475Joseph Reisinger and Raymond J. Mooney.
2010.Multi-prototype vector-space models of word mean-ing.
In Human Language Technologies: The 2010Annual Conference of the North American Chap-ter of the Association for Computational Linguistics(HLT-NAACL 2010), pages 109?117, Los Angeles,California, June.Helmut Schmid.
1994.
Probabilistic part-of-speechtagging using decision trees.
In International Con-ference on New Methods in Language Processing.Shengli Wu, Fabio Crestani, and Yaxin Bi.
2006.
Eval-uating score normalization methods in data fusion.In Third Asia Conference on Information RetrievalTechnology (AIRS?06), pages 642?648.
Springer-Verlag.Kazuhide Yamamoto and Takeshi Asakura.
2010.Even unassociated features can improve lexical dis-tributional similarity.
In Second Workshop onNLP Challenges in the Information Explosion Era(NLPIX 2010), pages 32?39, Beijing, China.Maayan Zhitomirsky-Geffet and Ido Dagan.
2009.Bootstrapping Distributional Feature Vector Quality.Computational Linguistics, 35(3):435?461.476
