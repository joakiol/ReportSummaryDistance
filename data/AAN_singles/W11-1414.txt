Proceedings of the Sixth Workshop on Innovative Use of NLP for Building Educational Applications, pages 111?119,Portland, Oregon, 24 June 2011. c?2011 Association for Computational LinguisticsGenerating Concept Map Exercises from TextbooksAndrew M. Olney, Whitney L. Cade, and Claire WilliamsInstitute for Intelligent SystemsUniversity of Memphis365 Innovation Drive, Memphis, TN 38152aolney@memphis.eduAbstractIn this paper we present a methodology forcreating concept map exercises for students.Concept mapping is a common pedagogicalexercise in which students generate a graph-ical model of some domain.
Our method auto-matically extracts knowledge representationsfrom a textbook and uses them to generateconcept maps.
The purpose of the study is togenerate and evaluate these concept maps ac-cording to their accuracy, completeness, andpedagogy.1 IntroductionConcept mapping is an increasingly common educa-tional activity, particularly in K-12 settings.
Conceptmaps are graphical knowledge representations thatrepresent a concept, question or process (Novak andCanas, 2006).
A recent meta-analysis of 55 studiesinvolving over five thousand participants found thestudents creating concept maps had increased learn-ing gains (d = .82) and students studying conceptmaps had increased learning gains ( d = .37 ) (Nesbitand Adesope, 2006).
In comparison, novice tutoringacross many studies have had more modest learninggains ( d = .40 ) (Cohen et al, 1982) ?
comparableto studying concept maps but not to creating them.For difficult topics, or for students new to con-cept mapping, some researchers propose so-calledexpert skeleton concept maps (Novak and Canas,2006).
These are partially specified concept mapsthat may have some existing structure and then a?word bank?
of concepts, properties, and relationsthat can be used to fill in the rest of the map.
Thisapproach is consistent with concept maps as instruc-tional scaffolds for student learning (O?Donnell etal., 2002).
As students increase in ability, they canmove from expert skeleton concept maps to self-generated maps.Because concept maps are essentially knowledgerepresentations based in words, analysis and syn-thesis of concept maps are theoretically amenableto knowledge-rich computational linguistic tech-niques.
This paper presents an approach to extract-ing concept maps from textbooks to create educa-tional materials for students.
The concept maps canbe used as expert skeleton concept maps.
The rest ofthe paper is organized as follows.
Section 2 presentsa brief overview of concept maps from the AI, psy-chological, and education literatures and motivates aparticular representation used in later sections.
Sec-tion 3 presents a general technique for extractingconcept maps from textbooks and generating graph-ical depictions of these as student exercises.
Sec-tion 4 describes a comparative evaluation of mapsextracted by the model to gold-standard human gen-erated concept maps.
Section 5 discusses these re-sults and their significance for generating conceptmap exercises for students.2 Perspectives on Concept MapsThere are many different kinds of concept maps, andeach variation imposes different computational de-mands.
One prominent perspective comes from theAI literature in formal reasoning, as an extension ofwork done a century ago by Pierce on existentialgraphs (Sowa, 2007; Sowa, 2009).
In this formula-tion (which is now an ISO standard), so-called con-111ceptual graphs are interchangeable with predicatecalculus.
Of particular importance to the current dis-cussion is grain size, that is the level of granularitygiven to nodes and relationships.
In these conceptualgraphs, grain size is very small, such that each argu-ment, e.g.
John, is connected to other arguments,e.g.
Mary, through an arbitrary predicate, e.g.
Johnloves Mary.
Aside from the tight correspondence tologic, grain size turns out to be a relevant differentia-tor amongst conceptualizations of conceptual graphsamongst different fields, and one that leads to impor-tant design decisions when extracting graphs from atext.Another prominent perspective comes from thepsychology literature (Graesser and Clark, 1985),with some emphasis on modeling question ask-ing and answering (Graesser and Franklin, 1990;Gordon et al, 1993).
In this formulationof conceptual graphs, nodes themselves can bepropositions, e.g.
?a girl wants to play witha doll,?
and relations are (as much as pos-sible) limited to a generic set of propositionsfor a given domain.
For example, one suchcategorization consists of 21 relations includingis-a, has-property, has-consequence,reason, implies, outcome, and means (Gor-don et al, 1993).
A particular advantage of limitingrelations to these categories is that the categories canthen be set into correspondence with certain ques-tion types, e.g.
definitional, causal consequent, pro-cedural, for both the purposes of answering ques-tions (Graesser and Franklin, 1990) as well as gen-erating them (Gordon et al, 1993).Finally, concept maps are widely used in scienceeducation (Fisher et al, 2000; Mintzes et al, 2005)for both enhancing student learning and assessment.Even in this community, there are several formu-lations of concept maps.
One such widely knownmap is a hierarchical map (Novak and Canas, 2006;Novak, 1990), in which a core concept/question atthe root of the map drives the elaboration of themap to more and more specific details.
In hierarchi-cal maps, nodes are not propositions, and the edgeslinking nodes are not restricted (Novak and Canas,2006).
Alternative formulations to hierarchicalmaps include cluster maps, MindMaps, computer-generated associative networks, and concept-circlediagrams, amongst others (Fisher et al, 2000).partabdomenarthropod posteriorhas-partis-ahas-propertyFigure 1: A concept map fragment.
Key terms have blacknodes.Of particular interest is the SemNet formulation,which is characterized by a central concept (whichhas been determined as highly relevant in the do-main) linked to other concepts using a relatively pre-scribed set of relations (Fisher, 2010).
End nodescan be arbitrary, and cannot themselves be linked tounless they are another core concept in the domain.Interestingly, in the field of biology, 50% of all linksare is-a, part-of, or has-property (Fisher et al, 2000),which suggests that generic relations may be ableto account for a large percentage of links in anydomain, with only some customization to be per-formed for specific domains.
An example SemNettriple (start node/relation/end node) is ?prophase in-cludes process chromosomes become visible.?
Sev-eral thousand of such triples are available online forbiology, illustrating the viability of this representa-tional scheme for biology (Fisher, 2010).3 Computational ModelOur approach for extracting concept maps from a bi-ology textbook follows the general SemNet formu-lation with some elements of the conceptual graphsof Graesser and Clark (1985).
There are two pri-mary reasons for adopting this formulation, ratherthan the others described in Section 2.
By using ahighly comparable formulation to the original Sem-Nets, one can compare generated graphs with sev-eral thousand, expert-generated triples that are freelyavailable.
Second, by making just a few modifica-tions to the SemNet formalism, we can create a for-malism that is more closely aligned with questionanswering/question generation, which we believe isa fruitful avenue for future research.112Our concept map representation has two signif-icant structural elements.
The first is key terms,shown as black nodes in Figure 1.
These are terms inour domain that are pedagogically significant.
Onlykey terms can be the start of a triple, e.g.
abdomenis-a part.
End nodes can contain key terms, otherwords, or complete propositions.
This structural el-ement is aligned with SemNets.
The second cen-tral aspect of our representation is labeled edges,shown as boxes in Figure 1.
As noted by (Fisheret al, 2000), a small set of edges can account for alarge percentage of relationships in a domain.
Thusthis second structural element aligns better with psy-chological conceptual graphs (Gordon et al, 1993;Graesser and Clark, 1985), but remains consistentwith the spirit of the SemNet representation.
Thenext sections outline the techniques and models usedfor defining key terms and edges, followed by ourmethod of graph extraction.3.1 Key TermsGeneral purpose key term extraction procedures arethe subject of current research (Medelyan et al,2009), but they are less relevant in a pedagogicalcontext where key terms are often already providedin learning materials.
For example, both glossaries(Navigli and Velardi, 2008), and textbook indices(Larran?aga et al, 2004) have previously been usedas resources in constructing domain models and on-tologies.
To develop our key terms, we used theglossary and index from a textbook in the domain ofbiology (Miller and Levine, 2002) as well as the key-words given in a test-prep study guide (Cypress Cur-riculum Services, 2008).
Thus we can skip the key-word extraction step of previous work on conceptmap extraction (Valerio and Leake, 2008; Zouaq andNkambou, 2009) and the various errors associatedwith that process.3.2 Edge RelationsSince edge relations used in conceptual graphs oftendepict abstract, domain-independent relationships(Graesser and Clark, 1985; Gordon et al, 1993), itmight be inferred that these types of relationships,e.g.
is-a, has-part, has-property, areexhaustive.
While such abstract relationships maybe able to cover a sizable percentage of all relation-ships previous work suggests new content can drivenew additions to that set (Fisher et al, 2000).
In or-der to verify the completeness of our edge relations,we undertook an analysis of concept maps from bi-ology.Over a few hours, we manually clustered 4371 bi-ology triples available on the Internet1 that span thetwo topics of molecules & cells and population bi-ology.
Although these two topics represent a smallsubset of biology topics, we hypothesize that as theextremes of levels of description in biology, their re-lations will be representative of the levels betweenthem.Consistent with previous reported concept mapresearch in biology (Fisher et al, 2000), our clusteranalysis revealed that 50% of all relations wereeither is-a, has-part, or has-property.Overall, 252 relation types clustered into 20 rela-tions shown in Table 1.
The reduction from 252relation types to 20 clusters generally lost littleinformation because the original set of relationsincluded many specific subclass relationships, e.g.part-of had the subclasses composed of, hasorganelle, organelle of, componentin, subcellular structure of, hassubcellular structure.
In most casessubclassing of this kind is recoverable from infor-mation distributed across nodes.
For example, if weknow that golgi body is-a organelle and we knowthat eukaryotic cell has-part golgi body, thenthe original relation golgi body organelle ofeukaryotic cell is implied.Additional edge relations were added based onthe psychology literature (Graesser and Clark, 1985;Gordon et al, 1993) as well as adjunct informationgleaned from the parser described in the next sec-tion, raising the total number of edge relations to30.
As indicated by Table 1 a great deal of over-lap exists between the clustered edge relations andthose in the psychological literature.
However, nei-ther goal-oriented relationships nor logical relation-ships (and/or) were included as these did not seemappropriate for the domain (a cell divides because itmust, not because it ?wants to?).
We also removedgeneral relations that overlapped with more specificones, e.g.
temporal is replaced by before, during,after.
We hypothesize that the edge relation scheme1http://www.biologylessons.sdsu.edu113Relation Clustered Gordon Adjunct Relation Clustered Gordon Adjunctafter * has-consequence * * *before * has-part * *combine * has-property * *connect * * implies *contain * * isa * *contrast * lack *convert * location * *definition * manner * *direction * not *during * * possibility *enable * produce *example * purpose *extent * reciprocal *follow * require *function * same-as * *Table 1: Edge relations from cluster analysis, Gordon et al (1993), and parser adjunct labelsin Table 1 would be portable to other domains, butsome additional tuning would be necessary to cap-ture fine-grained, domain specific relationships.3.3 Automatic ExtractionAccording to the representational scheme definedabove, triples always begin with a key term that isconnected by a relation to either another key termor a propositional phrase.
In other words, each keyterm is the center of a radial graph.
Triples begin-ning and ending with key terms bridge these radialgraphs.
The automatic extraction process followsthis representational scheme.
Additionally, the fol-lowing process was developed using a biology glos-sary and biology study guide as a development dataset, so training and testing data were kept separate inthis study.We processed a high school biology text (Millerand Levine, 2002), using its index and glossary assources of key terms as described above, using theLTH SRL2 parser.
The LTH SRL parser is a seman-tic role labeling parser that outputs a dependencyparse annotated with PropBank and NomBank pred-icate/argument structures (Johansson and Nugues,2008; Meyers et al, 2004; Palmer et al, 2005).
Foreach word token in a parse, the parser returns in-2The Swedish ?Lunds Tekniska Ho?gskola?
translates as?Faculty of Engineering?formation about the word token?s part of speech,lemma, head, and relation to the head.
Moreover,it uses PropBank and NomBank to identify pred-icates in the parse, either verbal predicates (Prop-Bank) or nominal predicates (NomBank), and theirassociated arguments.
A slightly abbreviated exam-ple parse corresponding to the concept map in Fig-ure 1 is shown in Table 2.In Table 2 the root of the sentence is ?is,?
whosehead is token 0 (the implied root token) and whosedependents are ?abdomen?
and ?part,?
the subjectand predicate, respectively.
Predicate ?part.01,?
be-ing a noun, refers to the Nombank predicate ?part?roleset 1.
This predicate has a single argument oftype A1, i.e.
theme, which is the phrase domi-nated by ?of,?
i.e.
?of an arthopod?s body.?
Predi-cate ?body.03?
refers to Nombank predicate ?body?roleset 3 and also has a single argument of type A1,?arthopod,?
dominating the phrase ?an arthopod?s.
?Potentially each of these semantic predicates repre-sents a relation, e.g.
has-part, and the syntactic in-formation in the parse also suggests relations, e.g.ABDOMEN is-a.The LTH parser also marks adjunct arguments.For example, consider the sentence ?During electrontransport, H+ ions build up in the intermembranespace, making it positively charged.?
There are fouradjuncts in this sentence: ?During electron trans-114port?
is a temporal adjunct, ?in the intermembranespace?
is a locative adjunct, ?making it positivelycharged?
is an adverbial adjunct, and ?positively?
isa manner adjunct.
The abundance of these adjunctsled to the pragmatic decision to include them as edgerelation indicators in Table 1.After parsing, four triple extractor algorithms areapplied to each sentence, targeting specific syntac-tic/semantic features of the parse, is-a, adjectives,prepositions, and predicates.
Each extractor first at-tempts to identify a key term as a possible start node.The search for key terms is greedy, attempting tomatch an entire phrase if possible, e.g.
?abiotic fac-tor?
rather than ?factor,?
by searching the depen-dents of an argument and applying morphologicalrules for pluralization.
If no key term can be found,the prospective triple is discarded.
Potentially, someunwanted loss can occur at this stage because ofunresolved anaphora.
However, it appears that thewriting style of the particular textbook used, Millerand Levine (2002), generally minimizes anaphoricreference.As exemplified by Figure 1 and Table 2, severaledge relations are handled purely syntactically.
Theis-a extractor considers when the root verb of thesentence is ?be,?
but not a helping verb.
Is-a rela-tions can create a special context for processing ad-ditional relations.
For example, in the sentence, ?Anabdomen is a posterior part of an arthropod?s body,??posterior?
modifies ?part,?
but the desired triple isabdomen has-property posterior.
This is an ex-ample of the adjective extraction algorithm runningin the context of an is-a relation: rather than al-ways using the head of the adjective as the start ofthe triple, the adjective extractor considers whetherthe head is a predicate nominative.
Prepositions cancreate a variety of edge relations.
For example, ifthe preposition has part of speech IN and has a LOCdependency relation to its head (a locative relation),then the appropriate relation is location, e.g.
?bymigrating whales in the Pacific Ocean.?
becomeswhales location in the Pacific Ocean.The predicates from PropBank and NomBank usespecialized extractors that consider both their argu-ment structure as well as the specific sense of thepredicate used.
As illustrated in some of the preced-ing examples, not all predicates have an A0.
Like-wise not all predicates have patient/instrument roleslike A1 and A2.
Ideally, every predicate wouldstart with A0 and end with A1, but the variabilityin predicate arguments makes simple mapping unre-alistic.
To assist the predicate extractors, we createda manual mapping between predicates, arguments,and edge relations, for every predicate that occurredmore that 40 times in the textbook.
Table 3 lists thefour most common predicates and their mappings.Predicate Edge Relation Start Endhave.03 HAS PROPERTY A0 Spanuse.01 USE A0 Spanproduce.01 PRODUCE A0 Spancall.01 HAS DEFINITION A1 A2Table 3: Predicate map examplesThe label ?Span?
in the last column indicates thatthe end node of the triple should be the text domi-nated by the predicate.
Consider the example, ?Themenstrual cycle has four phases?
has AO cycle andA1 phases.
Using just A0 and A1, the extractedtriple would be menstrual cycle has-propertyphases.
Using the span dominated by the predi-cate yields menstrual cycle has-property fourphases, which is more correct in this situation.
Ascan be seen in this example, end nodes based onpredicate spans tend to contain more words andtherefore have closer fidelity to the original sen-tence.After triples are extracted from the parse, theyare filtered to remove triples that are not particularlyuseful for generating concept map exercises.
Filtersare applied on the back end rather than during theextraction process because the triples discarded atthis stage might be usefully used for other applica-tions such as student modeling or question genera-tion.
The first three filters used are straightforwardand require little explanation: the repetition filter,the adjective filter, and the nominal filter.
The repeti-tion filter considers the number of words in commonbetween the start and end nodes.
If the number ofshared words is more than half the words in the endnode, the triple is filtered.
This helps alleviate redun-dant triples such as cell has-property cell.
Theadjective filter removes any triple whose key term isan adjective.
These triples violate the assumption bythe question generator that all key terms are nouns.115Id Form Lemma POS Head Dependency Relation Predicate Arg 1 Arg 21 abdomen abdomen NN 2 SBJ2 is be VBZ 0 ROOT3 a DT 5 NMOD4 posterior posterior JJ 5 NMOD5 part part NN 2 PRD part.016 of IN 5 NMOD A17 an DT 8 NMOD8 arthropod arthropod NN 10 NMOD A19 s POS 8 SUFFIX10 body body NN 6 PMOD body.0311 .
.
2 PTable 2: A slightly simplified semantic parseHas-property edge relations based on adjectiveswere also filtered because they tend to overgener-ate.
Finally the nominal filter removes all NomBankpredicates except has-part predicates, since these of-ten have Span end nodes and so contain themselves,e.g.
light has-property the energy of sunlight.The final filter uses likelihood ratios to establishwhether the relation between start and end nodesis meaningful, i.e.
something not likely to occurby chance.
This filter measures the association be-tween the start and end node using likelihood ratios(Dunning, 1993) and a ?2 significance criterion toremove triples with insignificant association.
As afirst step in the filter, words from the end node thathave low log entropy are removed prior to calcula-tion.
This penalizes non-distinctive words that occurin many contexts.
Next, the remaining words fromstart and end nodes are pooled into bags of words,and the likelihood ratio calculated.
By transformingthe likelihood ratio to be ?2 distributed (Manningand Schu?tze, 1999), and applying a statistical signif-icance threshold of .0001, triples with a weak associ-ation between start and end nodes were filtered out.The likelihood ratio filter helps prevent sentences re-lated to specific examples from being integrated intoconcept maps for a general concept.
For example,the sentence ?In most houses, heat is supplied bya furnace that burns oil or natural gas.?
from thetextbook is part of a larger discussion about home-ostatis.
An invalid triple implied by the sentence isheat has-property supplied by a furnace.
Sinceheat and furnace do not have a strong association inthe textbook overall, the likelihood ratio filter woulddiscard this triple.After filtering, triples belonging to a graph arerendered to image files using the NodeXL3 graphinglibrary.
In each image file, a key term defines thecenter of a radial graph.
To prevent visual clutter,triples that have the same edge type can be mergedinto a single node as is depicted in Figure 2.4 EvaluationA comparison study using gold-standard, humangenerated maps was performed to test the qualityof the concept maps generated by the method de-scribed in Section 3.
The gold-standard maps weretaken from Fisher (2010).
Since these maps coveronly a small section of biology, only the correspond-ing chapters from Miller and Levine (2002), chap-ters two and seven, were used to generate conceptmaps.
All possible concept maps were generatedfrom these two chapters, and then 60 of these con-cept maps that had a corresponding map in the gold-standard set were selected for evaluation.Two judges having background in biology andpedagogy were recruited to rate both the gold stan-dard and generated maps.
Each map was ratedon the following three dimensions: the cover-age/completeness of the map with respect to the keyterm (Coverage), the accuracy of the map (Accu-racy), and the pedagogical value of the map (Ped-agogy).
A consistent four item scale was used for3http://nodexl.codeplex.com/116Figure 2: Comparison of computer and human generated concept maps for ?cohesion.?
The computer generatedconcept map is on the left, and the human generated map is on the right.all ratings dimensions.
An example of the four itemscale is shown in Table 4.Score Criteria1 The map covers the concept.2 The map mostly covers the concept.3 The map only slightly covers the concept.4 The map is unrelated to the concept.Table 4: Rating scale for coverageJudges rated half the items, compared their scores,and then rated the second half of the items.
Inter-rater reliability was calculated on each of the threemeasures using Cronbach?s ?.
Cronbach?s ?
is moreappropriate than Cohen?s ?
because the ratings areordinal rather than categorical.
A Cronbach?s ?
foreach measure is presented in Table 5.
Most of thereliability scores in Table 5 are close to .70, whichis typically considered satisfactory reliability.
How-ever, reliability for accuracy was poor at ?
= .41.Scale Cronbach?s ?Coverage .75Accuracy .41Pedagogy .71Table 5: Inter-rater reliabilityComputer HumanScale Mean SD Mean SDCoverage 2.47 .55 1.67 .82Accuracy 1.87 .67 1.47 .55Pedagogy 2.53 .74 1.83 .90Table 6: Inter-rater reliability and mean ratings for com-puter and human generated mapsMeans and standard deviations were computed foreach measure per condition as shown in Table 6.
Ingeneral, the means for the computer generated mapswere in between 2 and 3 on the respective scales,while the human generated maps were between 1and 2.
The outlier is accuracy for the computer gen-erated maps, which was significantly higher than forthe other scales.
However, since the inter-rater reli-ability for this scale was relatively low, the mean foraccuracy requires closer analysis.
Inspection of theindividual means for each judge revealed that judgeA had the same mean accuracy for both human andcomputer generated maps, (M = 1.73), while judgeB rated the human maps higher (M = 1.2) and thecomputer generated maps lower (M = 2).
Thusit is reasonable to use this more conservative lowermean, (M = 2), as the estimate of accuracy for thecomputer-generated concept maps.117Wilcoxon signed ranks tests pairing computer andhuman generated maps based on their key termswere computed for each of the three scales.
Therewas a significant effect for coverage, Z = 2.95,p < .003, a significant effect for accuracy, Z =2.13, p < .03, and a significant effect for pedagogyZ = 2.46, p < .01.Since the purpose of the computer generated mapsis to help students learn, pedagogy is clearly themost important of the three scales.
In order to assesshow the other scales were related to pedagogy, cor-relations were calculated.
Accuracy and pedagogywere strongly correlated, r(28) = .57, p < .001.Coverage and pedagogy were even more stronglycorrelated, r(28) = .86, p < .001.The strong relationship between coverage andpedagogy suggests that the number of the triples inthe map might be strongly contributing to the judgesratings.
An inspection of the number of triples in thehuman maps compared to the computer generatedmaps reveals that there are approximately 3.5 timesas many triples in the human maps as the computergenerated maps.
To further explore this relationship,a linear regression was conducted using the log ofnumber of triples in each graph to predict the meanpedagogy score for that graph.
The log number oftriples in a graph significantly predicted pedagogyratings, b = ?.96, t(28) = ?3.47, p < .002.
Thelog number of triples in the graph explained a sig-nificant proportion of variance in pedagogy ratings,r2 = .30, F (1, 28) = 12.02, p < .002.These results are encouraging on two fronts.
First,the computer generated maps are on average ?mostlyaccurate.?
Secondly, the computer generated mapsfare less well for coverage and pedagogy, but thesetwo scale are highly correlated, suggesting thatjudges are using a criterion largely based on com-pleteness when scoring maps.
The strength of thelog number of triples in a graph as a predictor of ped-agogy likewise indicates that increasing the numberof triples in each graph, which would require accessto a larger sample of texts on these topics, wouldincrease the pedagogical ratings for the computergenerated maps.
However, while gaps in the mapswould be problematic if the students were usingthe maps as an authoritative source for study, gapsare perfectly acceptable for expert skeleton conceptmaps.5 ConclusionIn this paper we have presented a methodology forcreating expert skeleton concept maps from text-books.
Our comparative analysis using human gen-erated concept maps as a gold standard suggests thatour maps are mostly accurate and are appropriate foruse as expert skeleton concept maps.Ideally student concept maps that extend theseskeleton maps would be automatically scored andfeedback given as is already done in intelligent tu-toring systems like Betty?s Brain and CIRCSIM Tu-tor(Biswas et al, 2005; Evens et al, 2001).
Bothof these systems use expert-generated maps as goldstandards by which to evaluate student maps.
There-fore automatic scoring of our expert skeleton con-cept maps would require a more complete map inthe background.In future work we will examine increasing thenumber of knowledge sources to see if this will in-crease the pedagogical value of the concept mapsand allow for automatic scoring.
However, increas-ing the knowledge sources will also likely lead toan increase not only in total information but also inredundant information.
Thus extending this workto include more knowledge sources will likely re-quire incorporating techniques from the summariza-tion and entailment literatures to remove redundantinformation.AcknowledgmentsThe research reported here was supported by the In-stitute of Education Sciences, U.S. Department ofEducation, through Grant R305A080594 and by theNational Science Foundation, through Grant BCS-0826825, to the University of Memphis.
The opin-ions expressed are those of the authors and do notrepresent views of the Institute or the U.S. Depart-ment of Education or the National Science Founda-tion.ReferencesGautam Biswas, Daniel Schwartz, Krittaya Leelawong,and Nancy Vye.
2005.
Learning by teaching: A newagent paradigm for educational software.
Applied Ar-tificial Intelligence, 19:363?392, March.Peter A. Cohen, James A. Kulik, and Chen-Lin C. Ku-lik.
1982.
Educational outcomes of tutoring: a meta118analysis of findings.
American Educational ResearchJournal, 19:237?248.LLC Cypress Curriculum Services.
2008.
TennesseeGateway Coach, Biology.
Triumph Learning, NewYork, NY.Ted Dunning.
1993.
Accurate methods for the statisticsof surprise and coincidence.
Computational Linguis-tics, 19:61?74, March.Martha W. Evens, Stefan Brandle, Ru-Charn Chang,Reva Freedman, Micheal Glass, Yoon Hee Lee,Leem Seop Shim, Chong Woo Woo, Yuemei Zhang,Yujian Zhou, Joel A. Michael, and Allen A. Rovick.2001.
CIRCSIM-Tutor: An intelligent tutoring sys-tem using natural language dialogue.
In Proceedingsof the 12th Midwest AI and Cognitive Science Confer-ence (MAICS 2001), pages 16?23, Oxford, OH.Kathleen M. Fisher, James H. Wandersee, and David E.Moody.
2000.
Mapping biology knowledge.
KluwerAcademic Pub.Kathleen Fisher.
2010.
Biology Lessons at SDSU.http://www.biologylessons.sdsu.edu, January.Sallie E. Gordon, Kimberly A. Schmierer, and Richard T.Gill.
1993.
Conceptual graph analysis: Knowledgeacquisition for instructional system design.
HumanFactors: The Journal of the Human Factors and Er-gonomics Society, 35(3):459?481.Arthur C. Graesser and Leslie C. Clark.
1985.
Struc-tures and procedures of implicit knowledge.
Ablex,Norwood, NJ.Arthur C. Graesser and Stanley P. Franklin.
1990.
Quest:A cognitive model of question answering.
DiscourseProcesses, 13:279?303.Richard Johansson and Pierre Nugues.
2008.Dependency-based syntactic-semantic analysiswith PropBank and NomBank.
In CoNLL ?08:Proceedings of the Twelfth Conference on Computa-tional Natural Language Learning, pages 183?187,Morristown, NJ, USA.
Association for ComputationalLinguistics.Mikel Larran?aga, Urko Rueda, Jon A. Elorriaga, andAna Arruarte Lasa.
2004.
Acquisition of the domainstructure from document indexes using heuristic rea-soning.
In Intelligent Tutoring Systems, pages 175?186.Christopher D. Manning and Hinrich Schu?tze.
1999.Foundations of Statistical Natural Language Process-ing.
MIT Press, Cambridge, MA.Olena Medelyan, Eibe Frank, and Ian H. Witten.2009.
Human-competitive tagging using automatickeyphrase extraction.
In Proceedings of the 2009 Con-ference on Empirical Methods in Natural LanguageProcessing, pages 1318?1327, Singapore, August.
As-sociation for Computational Linguistics.Adam Meyers, Ruth Reeves, Catherine Macleod, RachelSzekely, Veronika Zielinska, Brian Young, and RalphGrishman.
2004.
The NomBank project: An interimreport.
In A. Meyers, editor, HLT-NAACL 2004 Work-shop: Frontiers in Corpus Annotation, pages 24?31,Boston, Massachusetts, USA, May 2 - May 7.
Associ-ation for Computational Linguistics.Kenneth R. Miller and Joseph S. Levine.
2002.
PrenticeHall Biology.
Pearson Education, New Jersey.Joel J. Mintzes, James H. Wandersee, and Joseph D. No-vak.
2005.
Assessing science understanding: A hu-man constructivist view.
Academic Press.Roberto Navigli and Paola Velardi.
2008.
From glos-saries to ontologies: Extracting semantic structurefrom textual definitions.
In Proceeding of the 2008conference on Ontology Learning and Population:Bridging the Gap between Text and Knowledge, pages71?87, Amsterdam, The Netherlands, The Nether-lands.
IOS Press.John C. Nesbit and Olusola O. Adesope.
2006.
Learningwith concept and knowledge maps: A meta-analysis.Review of Educational Research, 76(3):413?448.Joeseph D. Novak and Alberto J. Canas.
2006.
Thetheory underlying concept maps and how to constructthem.
Technical report, Institute for Human and Ma-chine Cognition, January.Joeseph D. Novak.
1990.
Concept mapping: A usefultool for science education.
Journal of Research in Sci-ence Teaching, 27(10):937?49.Angela O?Donnell, Donald Dansereau, and Richard Hall.2002.
Knowledge maps as scaffolds for cognitive pro-cessing.
Educational Psychology Review, 14:71?86.10.1023/A:1013132527007.Martha Palmer, Daniel Gildea, and Paul Kingsbury.2005.
The Proposition Bank: An annotated corpus ofsemantic roles.
Comput.
Linguist., 31(1):71?106.John F. Sowa.
2007.
Conceptual graphs.
InF.
Van Harmelen, V. Lifschitz, and B. Porter, editors,Handbook of knowledge representation, pages 213?237.
Elsevier Science, San Diego, USA.John F. Sowa.
2009.
Conceptual graphs for representingconceptual structures.
In P. Hitzler and H. Scharfe,editors, Conceptual Structures in Practice, pages 101?136.
Chapman & Hall/CRC.Alejandro Valerio and David B. Leake.
2008.
Associ-ating documents to concept maps in context.
In A. J.Canas, P. Reiska, M. Ahlberg, and J. D. Novak, editors,Proceedings of the Third International Conference onConcept Mapping.Amal Zouaq and Roger Nkambou.
2009.
Evaluatingthe generation of domain ontologies in the knowledgepuzzle project.
IEEE Trans.
on Knowl.
and Data Eng.,21(11):1559?1572.119
