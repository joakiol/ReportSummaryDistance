Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 6?10,Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational LinguisticsJoint Evaluation of Morphological Segmentation and Syntactic ParsingReut Tsarfaty Joakim Nivre Evelina AnderssonBox 635, 751 26, Uppsala University, Uppsala, Swedentsarfaty@stp.lingfil.uu.se, {joakim.nivre, evelina.andersson}@lingfil.uu.seAbstractWe present novel metrics for parse evalua-tion in joint segmentation and parsing sce-narios where the gold sequence of terminalsis not known in advance.
The protocol usesdistance-based metrics defined for the spaceof trees over lattices.
Our metrics allow usto precisely quantify the performance gap be-tween non-realistic parsing scenarios (assum-ing gold segmented and tagged input) and re-alistic ones (not assuming gold segmentationand tags).
Our evaluation of segmentation andparsing for Modern Hebrew sheds new lighton the performance of the best parsing systemsto date in the different scenarios.1 IntroductionA parser takes a sentence in natural language as in-put and returns a syntactic parse tree representingthe sentence?s human-perceived interpretation.
Cur-rent state-of-the-art parsers assume that the space-delimited words in the input are the basic units ofsyntactic analysis.
Standard evaluation proceduresand metrics (Black et al, 1991; Buchholz and Marsi,2006) accordingly assume that the yield of the parsetree is known in advance.
This assumption breaksdown when parsing morphologically rich languages(Tsarfaty et al, 2010), where every space-delimitedword may be effectively composed of multiple mor-phemes, each of which having a distinct role in thesyntactic parse tree.
In order to parse such input thetext needs to undergo morphological segmentation,that is, identifying the morphological segments ofeach word and assigning the corresponding part-of-speech (PoS) tags to them.Morphologically complex words may be highlyambiguous and in order to segment them correctlytheir analysis has to be disambiguated.
The multiplemorphological analyses of input words may be rep-resented via a lattice that encodes the different seg-mentation possibilities of the entire word sequence.One can either select a segmentation path prior toparsing, or, as has been recently argued, one can letthe parser pick a segmentation jointly with decoding(Tsarfaty, 2006; Cohen and Smith, 2007; Goldbergand Tsarfaty, 2008; Green and Manning, 2010).
Ifthe selected segmentation is different from the goldsegmentation, the gold and parse trees are renderedincomparable and standard evaluation metrics breakdown.
Evaluation scenarios restricted to gold inputare often used to bypass this problem, but, as shall beseen shortly, they present an overly optimistic upper-bound on parser performance.This paper presents a full treatment of evaluationin different parsing scenarios, using distance-basedmeasures defined for trees over a shared commondenominator defined in terms of a lattice structure.We demonstrate the informativeness of our metricsby evaluating joint segmentation and parsing perfor-mance for the Semitic language Modern Hebrew, us-ing the best performing systems, both constituency-based and dependency-based (Tsarfaty, 2010; Gold-berg, 2011a).
Our experiments demonstrate that, forall parsers, significant performance gaps between re-alistic and non-realistic scenarios crucially dependon the kind of information initially provided to theparser.
The tool and metrics that we provide arecompletely general and can straightforwardly applyto other languages, treebanks and different tasks.6(tree1) TOPPPIN0B1?in?NPNPDEF1H2?the?NPNN2CL3?shadow?PPPOSS3FL4ofPRN4HM5?them?ADJPDEF5H6?the?JJ6NEIM7?pleasant?
(tree2) TOPPPIN0B1?in?NPNPNN1CL2?shadow?PPPOSS2FL3?of?PRN3HM4?them?VB4HNEIM5?made-pleasant?Figure 1: A correct tree (tree1) and an incorrect tree (tree2) for ?BCLM HNEIM?, indexed by terminal boundaries.Erroneous nodes in the parse hypothesis are marked in italics.
Missing nodes from the hypothesis are marked in bold.2 The Challenge: Evaluation for MRLsIn morphologically rich languages (MRLs) substan-tial information about the grammatical relations be-tween entities is expressed at word level using in-flectional affixes.
In particular, in MRLs such as He-brew, Arabic, Turkish or Maltese, elements such asdeterminers, definite articles and conjunction mark-ers appear as affixes that are appended to an open-class word.
Take, for example the Hebrew word-token BCLM,1 which means ?in their shadow?.
Thisword corresponds to five distinctly tagged elements:B (?in?/IN), H (?the?/DEF), CL (?shadow?/NN), FL(?of?/POSS), HM (?they?/PRN).
Note that morpho-logical segmentation is not the inverse of concatena-tion.
For instance, the overt definite article H andthe possessor FL show up only in the analysis.The correct parse for the Hebrew phrase ?BCLMHNEIM?
is shown in Figure 1 (tree1), and it pre-supposes that these segments can be identified andassigned the correct PoS tags.
However, morpholog-ical segmentation is non-trivial due to massive word-level ambiguity.
The word BCLM, for instance, canbe segmented into the noun BCL (?onion?)
and M (agenitive suffix, ?of them?
), or into the prefix B (?in?
)followed by the noun CLM (?image?
).2 The multi-tude of morphological analyses may be encoded in alattice structure, as illustrated in Figure 2.1We use the Hebrew transliteration in Sima?an et al (2001).2The complete set of analyses for this word is provided inGoldberg and Tsarfaty (2008).
Examples for similar phenom-ena in Arabic may be found in Green and Manning (2010).Figure 2: The morphological segmentation possibilitiesof BCLM HNEIM.
Double-circles are word boundaries.In practice, a statistical component is required todecide on the correct morphological segmentation,that is, to pick out the correct path through the lat-tice.
This may be done based on linear local context(Adler and Elhadad, 2006; Shacham and Wintner,2007; Bar-haim et al, 2008; Habash and Rambow,2005), or jointly with parsing (Tsarfaty, 2006; Gold-berg and Tsarfaty, 2008; Green and Manning, 2010).Either way, an incorrect morphological segmenta-tion hypothesis introduces errors into the parse hy-pothesis, ultimately providing a parse tree whichspans a different yield than the gold terminals.
Insuch cases, existing evaluation metrics break down.To understand why, consider the trees in Figure 1.Metrics like PARSEVAL (Black et al, 1991) cal-culate the harmonic means of precision and recallon labeled spans ?i, label, j?
where i, j are termi-nal boundaries.
Now, the NP dominating ?shadowof them?
has been identified and labeled correctlyin tree2, but in tree1 it spans ?2,NP, 5?
and in tree2it spans ?1,NP, 4?.
This node will then be countedas an error for tree2, along with its dominated anddominating structure, and PARSEVAL will score 0.7A generalized version of PARSEVAL which con-siders i, j character-based indices instead of termi-nal boundaries (Tsarfaty, 2006) will fail here too,since the missing overt definite article H will causesimilar misalignments.
Metrics for dependency-based evaluation such as ATTACHMENT SCORES(Buchholz and Marsi, 2006) suffer from similarproblems, since they assume that both trees have thesame nodes ?
an assumption that breaks down inthe case of incorrect morphological segmentation.Although great advances have been made in pars-ing MRLs in recent years, this evaluation challengeremained unsolved.3 In this paper we present a solu-tion to this challenge by extending TEDEVAL (Tsar-faty et al, 2011) for handling trees over lattices.3 The Proposal: Distance-Based MetricsInput and Output Spaces We view the joint taskas a structured prediction function h : X ?
Y frominput space X onto output space Y .
Each elementx ?
X is a sequence x = w1, .
.
.
, wn of space-delimited words from a setW .
We assume a lexiconLEX, distinct fromW , containing pairs of segmentsdrawn from a set T of terminals and PoS categoriesdrawn from a set N of nonterminals.LEX = {?s, p?|s ?
T , p ?
N}Each word wi in the input may admit multiplemorphological analyses, constrained by a language-specific morphological analyzer MA.
The morpho-logical analysis of an input word MA(wi) can berepresented as a lattice Li in which every arc cor-responds to a lexicon entry ?s, p?.
The morpholog-ical analysis of an input sentence x is then a latticeL obtained through the concatenation of the latticesL1, .
.
.
, Ln where MA(w1) = L1, .
.
.
, MA(wn) =Ln.
Now, let x = w1, .
.
.
, wn be a sentence witha morphological analysis lattice MA(x) = L. Wedefine the output space YMA(x)=L for h (abbreviatedYL), as the set of linearly-ordered labeled trees suchthat the yield of LEX entries ?s1, p1?,.
.
.
,?sk, pk?
ineach tree (where si ?
T and pi ?
N , and possiblyk 6= n) corresponds to a path through the lattice L.3A tool that could potentially apply here is SParseval (Roarket al, 2006).
But since it does not respect word-boundaries, itfails to apply to such lattices.
Cohen and Smith (2007) aimed tofix this, but in their implementation syntactic nodes internal toword boundaries may be lost without scoring.Edit Scripts and Edit Costs We assume aset A={ADD(c, i, j),DEL(c, i, j),ADD(?s, p?, i, j),DEL(?s, p?, i, j)} of edit operations which can addor delete a labeled node c ?
N or an entry ?s, p?
?LEX which spans the states i, j in the lattice L. Theoperations in A are properly constrained by the lat-tice, that is, we can only add and delete lexemes thatbelong to LEX, and we can only add and delete themwhere they can occur in the lattice.
We assume afunction C(a) = 1 assigning a unit cost to every op-eration a ?
A, and define the cost of a sequence?a1, .
.
.
, am?
as the sum of the costs of all opera-tions in the sequence C(?a1, ..., am?)
=?mi=1 C(ai).An edit script ES(y1, y2) = ?a1, .
.
.
, am?
is a se-quence of operations that turns y1 into y2.
The tree-edit distance is the minimum cost of any edit scriptthat turns y1 into y2 (Bille, 2005).TED(y1, y2) = minES(y1,y2)C(ES(y1, y2))Distance-Based Metrics The error of a predictedstructure p with respect to a gold structure g is nowtaken to be the TED cost, and we can turn it into ascore by normalizing it and subtracting from a unity:TEDEVAL(p, g) = 1?TED(p, g)|p|+ |g| ?
2The term |p| + |g| ?
2 is a normalization factor de-fined in terms of the worst-case scenario, in whichthe parser has only made incorrect decisions.
Wewould need to delete all lexemes and nodes in p andadd all the lexemes and nodes of g, except for roots.An Example Both trees in Figure 1 are containedin YL for the lattice L in Figure 2.
If we re-place terminal boundaries with lattice indices fromFigure 2, we need 6 edit operations to turn tree2into tree1 (deleting the nodes in italic, adding thenodes in bold) and the evaluation score will beTEDEVAL(tree2,tree1) = 1?
614+10?2 = 0.7273.4 ExperimentsWe aim to evaluate state-of-the-art parsing architec-tures on the morphosyntactic disambiguation of He-brew texts in three different parsing scenarios: (i)Gold: assuming gold segmentation and PoS-tags,(ii) Predicted: assuming only gold segmentation,and (iii) Raw: assuming unanalyzed input text.8SEGEVAL PARSEVAL TEDEVALGold PS U: 100.00 U: 94.35L: 100.00 L: 88.75 L: 93.39Predicted PS U: 100.00 U: 92.92L: 90.85 L: 82.30 L: 86:26Raw PS U: 96.42 U: 88.47L: 84.54 N/A L: 80.67Gold RR U: 100.00 U: 94.34L: 100.00 L: 83.93 L: 92.45Predicted RR U: 100.00 U: 92.82L: 91.69 L: 78.93 L: 85.83Raw RR U: 96.03 U: 87.96L: 86.10 N/A L: 79.46Table 1: Phrase-Structure based results for the Berke-ley Parser trained on bare-bone trees (PS) and relational-realizational trees (RR).
We parse all sentences in the devset.
RR extra decoration is removed prior to evaluation.SEGEVAL ATTSCORES TEDEVALGold MP 100.00 U: 83.59 U: 91.76Predicted MP 100.00 U: 82.00 U: 91.20Raw MP 95.07 N/A U: 87.03Gold EF 100.00 U: 84.68 U: 92.25Predicted EF 100.00 U: 83.97 U: 92:02Raw EF 95.07 N/A U: 87.75Table 2: Dependency parsing results by MaltParser (MP)and EasyFirst (EF), trained on the treebank converted intounlabeled dependencies, and parsing the entire dev-set.For constituency-based parsing we use two mod-els trained by the Berkeley parser (Petrov et al,2006) one on phrase-structure (PS) trees and oneon relational-realizational (RR) trees (Tsarfaty andSima?an, 2008).
In the raw scenario we let a lattice-based parser choose its own segmentation and tags(Goldberg, 2011b).
For dependency parsing we useMaltParser (Nivre et al, 2007b) optimized for He-brew by Ballesteros and Nivre (2012), and the Easy-First parser of Goldberg and Elhadad (2010) with thefeatures therein.
Since these parsers cannot choosetheir own tags, automatically predicted segmentsand tags are provided by Adler and Elhadad (2006).We use the standard split of the Hebrew tree-bank (Sima?an et al, 2001) and its conversion intounlabeled dependencies (Goldberg, 2011a).
Weuse PARSEVAL for evaluating phrase-structure trees,ATTACHSCORES for evaluating dependency trees,and TEDEVAL for evaluating all trees in all scenar-ios.
We implement SEGEVAL for evaluating seg-mentation based on our TEDEVAL implementation,replacing the tree distance and size with string terms.Table 1 shows the constituency-based parsing re-sults for all scenarios.
All of our results confirmthat gold information leads to much higher scores.TEDEVAL allows us to precisely quantify the dropin accuracy from gold to predicted (as in PARSE-VAL) and than from predicted to raw on a singlescale.
TEDEVAL further allows us to scrutinize thecontribution of different sorts of information.
Unla-beled TEDEVAL shows a greater drop when movingfrom predicted to raw than from gold to predicted,and for labeled TEDEVAL it is the other way round.This demonstrates the great importance of gold tagswhich provide morphologically disambiguated in-formation for identifying phrase content.Table 2 shows that dependency parsing resultsconfirm the same trends, but we see a much smallerdrop when moving from gold to predicted.
This isdue to the fact that we train the parsers for predictedon a treebank containing predicted tags.
There ishowever a great drop when moving from predictedto raw, which confirms that evaluation benchmarkson gold input as in Nivre et al (2007a) do not pro-vide a realistic indication of parser performance.For all tables, TEDEVAL results are on a simi-lar scale.
However, results are not yet comparableacross parsers.
RR trees are flatter than bare-bonePS trees.
PS and DEP trees have different labelsets.
Cross-framework evaluation may be conductedby combining this metric with the cross-frameworkprotocol of Tsarfaty et al (2012).5 ConclusionWe presented distance-based metrics defined fortrees over lattices and applied them to evaluatingparsers on joint morphological and syntactic dis-ambiguation.
Our contribution is both technical,providing an evaluation tool that can be straight-forwardly applied for parsing scenarios involvingtrees over lattices,4 and methodological, suggestingto evaluate parsers in all possible scenarios in orderto get a realistic indication of parser performance.AcknowledgementsWe thank Shay Cohen, Yoav Goldberg and SpenceGreen for discussion of this challenge.
This workwas supported by the Swedish Science Council.4The tool can be downloaded http://stp.ling.uu.se/?tsarfaty/unipar/index.html9ReferencesMeni Adler and Michael Elhadad.
2006.
An unsuper-vised morpheme-based HMM for Hebrew morpholog-ical disambiguation.
In Proceedings of COLING-ACL.Miguel Ballesteros and Joakim Nivre.
2012.
MaltOpti-mizer: A system for MaltParser optimization.
Istan-bul.Roy Bar-haim, Khalil Sima?an, and Yoad Winter.
2008.Part-of-speech tagging of Modern Hebrew text.
Natu-ral Language Engineering, 14(2):223?251.Philip Bille.
2005.
A survey on tree-edit distanceand related.
problems.
Theoretical Computer Science,337:217?239.Ezra Black, Steven P. Abney, D. Flickenger, ClaudiaGdaniec, Ralph Grishman, P. Harrison, Donald Hin-dle, Robert Ingria, Frederick Jelinek, Judith L. Kla-vans, Mark Liberman, Mitchell P. Marcus, SalimRoukos, Beatrice Santorini, and Tomek Strzalkowski.1991.
A procedure for quantitatively comparing thesyntactic coverage of English grammars.
In Proceed-ings of the DARPA Workshop on Speech and NaturalLanguage.Sabine Buchholz and Erwin Marsi.
2006.
CoNLL-Xshared task on multilingual dependency parsing.
InProceedings of CoNLL-X, pages 149?164.Shay B. Cohen and Noah A. Smith.
2007.
Joint morpho-logical and syntactic disambiguation.
In Proceedingsof EMNLP-CoNLL, pages 208?217.Yoav Goldberg and Michael Elhadad.
2010.
Easy-firstdependency parsing of Modern Hebrew.
In Proceed-ings of NAACL/HLT workshop on Statistical Parsingof Morphologically Rich Languages.Yoav Goldberg and Reut Tsarfaty.
2008.
A single frame-work for joint morphological segmentation and syn-tactic parsing.
In Proceedings of ACL.Yoav Goldberg.
2011a.
Automatic Syntactic Processingof Modern Hebrew.
Ph.D. thesis, Ben-Gurion Univer-sity of the Negev.Yoav Goldberg.
2011b.
Joint morphological segmen-tation and syntactic parsing using a PCFGLA latticeparser.
In Proceedings of ACL.Spence Green and Christopher D. Manning.
2010.
BetterArabic parsing: Baselines, evaluations, and analysis.In Proceedings of COLING.Nizar Habash and Owen Rambow.
2005.
Arabic tok-enization, part-of-speech tagging and morphologicaldisambiguation in one fell swoop.
In Proceedings ofACL.Joakim Nivre, Johan Hall, Sandra Ku?bler, Ryan McDon-ald, Jens Nilsson, Sebastian Riedel, and Deniz Yuret.2007a.
The CoNLL 2007 shared task on dependencyparsing.
In Proceedings of the CoNLL Shared TaskSession of EMNLP-CoNLL 2007, pages 915?932.Joakim Nivre, Jens Nilsson, Johan Hall, Atanas Chanev,Gu?lsen Eryigit, Sandra Ku?bler, Svetoslav Marinov,and Erwin Marsi.
2007b.
MaltParser: A language-independent system for data-driven dependency pars-ing.
Natural Language Engineering, 13(1):1?41.Slav Petrov, Leon Barrett, Romain Thibaux, and DanKlein.
2006.
Learning accurate, compact, and inter-pretable tree annotation.
In Proceedings of ACL.Brian Roark, Mary Harper, Eugene Charniak, Bon-nie Dorr C, Mark Johnson D, Jeremy G. KahnE, Yang Liu F, Mari Ostendorf E, John HaleH, Anna Krasnyanskaya I, Matthew Lease D,Izhak Shafran J, Matthew Snover C, Robin Stewart K,and Lisa Yung J.
2006.
Sparseval: Evaluation metricsfor parsing speech.
In Proceesings of LREC.Danny Shacham and Shuly Wintner.
2007.
Morpholog-ical disambiguation of Hebrew: A case study in clas-sifier combination.
In Proceedings of the 2007 JointConference of EMNLP-CoNLL, pages pages 439?447.Khalil Sima?an, Alon Itai, Yoad Winter, Alon Altman,and Noa Nativ.
2001.
Building a Tree-Bank forModern Hebrew Text.
In Traitement Automatique desLangues.Reut Tsarfaty and Khalil Sima?an.
2008.
Relational-Realizational parsing.
In Proceedings of CoLing.Reut Tsarfaty, Djame Seddah, Yoav Goldberg, San-dra Kuebler, Marie Candito, Jennifer Foster, Yan-nick Versley, Ines Rehbein, and Lamia Tounsi.
2010.Statistical parsing for morphologically rich language(SPMRL): What, how and whither.
In Proceedings ofthe first workshop on Statistical Parsing of Morpho-logically Rich Languages (SPMRL) at NA-ACL.Reut Tsarfaty, Joakim Nivre, and Evelina Andersson.2011.
Evaluating dependency parsing: Robust andheuristics-free cross-framework evaluation.
In Pro-ceedings of EMNLP.Reut Tsarfaty, Joakim Nivre, and Evelina Andersson.2012.
Cross-framework evaluation for statistical pars-ing.
In Proceedings of EACL.Reut Tsarfaty.
2006.
Integrated morphological and syn-tactic disambiguation for Modern Hebrew.
In Pro-ceeding of ACL-SRW.Reut Tsarfaty.
2010.
Relational-Realizational Parsing.Ph.D.
thesis, University of Amsterdam.10
