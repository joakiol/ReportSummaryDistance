Morphological Analyzer as Syntactic ParserG~ibor P r6sz6kyMorphol,ogicNdmctvOlgyi 0t 25, lhtdapcst, 11-1126 11ungaryh6109pro(a\]clhl.huAbstract.
We describe how a simple parser can be built ontile basis of nmrphology and a morphological analyzer.
Ourinitial conditions have been tile tcclmiques and principlesol: Humor, a reversible, shing-bascd tmification tool(Prdszdky 1994).
Parsing is perlorlngd by the Sillllc engineas morphological analysis.
It is usefld when therc is notenough space to add a new engine to an existing morpl\]ofogy-based application (e.g.
a spell-checker), but you wouldlike to handle sentence-level information, its well (e.g.
agramnlar checker).
The morpimlogical analyzer breaks upwords into several parts, all of which stored it\] tile mainlexicon, l:,ach part has a feature structure and the validily oftile input word is checked by unifying them.
Thc mor-phological analyzer returns various information about aword including its categorization.
In a sentence, the cate-gory of each word (or morphcme) is considered a recta-letter, and the sentencc itself can be transformed into arecta-word that essentially behaves like a real one.
Thus timset of sentences recognized by tile parser called Hum0rESl(can form a lexicon of recta-words that are processed muchrite same way as lexicons of real words (morphology).
Thismeans that algorithmic parsing step are substituted by lexi-con look-up, which, by definition, is pcrforn~cd followingtile stlrJ'ace order of string elements.
Both the finitizer thattransfimns fornml grammars into finite lexicons and timtun-tinm parser of the proposed model have running im-plementations.11 INTROI )UCT ION\[,exical entries in a morphology-lmsed system are words.Because of tile similarity, syntactic onstructions occurringas entries in a mctaqcxicon can be called recta-words.Mcta-letters, that is, letters o1" a recta-word arc morpho-syntactic categories having an internal structure that de-scribes syntaelic behavior of the entry in higher level con?structions.
The system called Hum0rE,~K (Humor l';nhancedwith Syntactic Knowledge, where Humor stands lbr I ligh-speed Unification Morphology) to be shown here consistsel: nulnerous recta-lexicons.
Each o1: them has a name: lhesyntactic category it describes.
Categories like S', S, NP,VI< etc.
are described in separate lexicons.
Meta-lexiconsl'ornl a hierarchy, that is, letters in a lnetadexicon can referto other (but only lower level) lexicons.
Parsing on eachlevel, therefore, can be realized as lexical h)ok-up.
Neitherbacktracking, look-ahcad, tier other tilnc-consuming pars-ing steps arc needed in order to get the analysis of a sen-tence.
The only on-line Ol)eratitm is a unit\]ability check foreach possible lexical entry that matches lhe sentence inquestion.IThis work was partially supported by the Ihmgm tan NationalScientific Fund (()TKA).Gramnmrs are compiled into a nmtti-lcvel patternslrttchtrc.
()n a lower level, parsing a word results in arecta-letter, that is, part of a recta-word on a higher level.Such structures, lbr example, NI' and VP, are recta-letterscoming from lower levels and form a recta-word that canbe parsed as a sentence, because of the existence of a rule S-~ NP VP in the original gratltlllar.
A COtlIpIcx setliellcegratllt/lar can be broken up into non-rectlrsivc, gralnttlarsdescribing smaller grammatical units on different levels.These granlmars are, of course, nmch simpler than theoriginal one.
Recursive transition etworks (P, TN) can alsobe made according to similar principles, but their recursivcnattu'e cannot be Ionnd in our method.
In other words: theoutput symbol of any level does not occur in the actual orlowcr level dictionaries.Tile whole lexicon cascade can be generated front arbi-trary grmnmars writ/en in any usual (for the time being,CI:, but in tile near furore any fcahne-based) tbrnmlism.We call this step grammar learninL< The sotl\wue tool wehave developed for this reason lakes tile grallllllar ~ts inpttt,creates the largest regular subset of tile language it de-scribes regarding the string-completion limit of Kornai(1985), then lbrms it finite pattern structure by depth limitand length limit fronl the above I'egtliar description.2 PARSING WITH PATTERNSl'arsers are (conlputational) tools that read and analyze asentence, and return a wide range of information ~tl)(,lttt it,that is, they recognize(1) if the input is a valid sentence (according to the yules ofthe object hmguage),(2) segment he input sentence as tnany ways its possible,tllld(3) provide stone custonl infornmtion.The latter custom information can be a simple '()I<' signindicating that tile sentence is well-formed (grammarchecker), but it can also be the same sentence in anotherlanguage (translation tool), or, in case of a (granunatically)incorrect sentence, it cat\] bc a list e l  suggestions how itnlW be corrected (~,,rammar correcter).
In the present im-plementation we use morpho-syntactic categories as outputit\]lormation  every level (parser).I:or the input sentenceThe dog sinRs.tile l';nglish module of Humor returns the following mor-phological categorization:The\] 1)1:/\['\] dog\[N\] S/hA, IV\] t \[3S(; I .IENI)Il,ct us now strip off tile actual words fronl the nmrphologi-cal information (from now on we call them morphologicalcodes or mo,7)h-codes ).
Wriling only the morph-codes, wegelI)ETN V 3S(; I';NI).The problcnl is now how wc recognize this as a sentence.This sequence must smnehow bc stored in another lexicon1123describing phrases and phrase structures.
It is quite clearthat in the above string, DET, N, and V are simple symbolsthat can easily be encoded as single letters like d, n, v, xand e. Transforming the sequence of morph-codes we getthe word dnvxe.
Earlier we said thai the I'tum0r engine islexicon-independent, so if we have another lexicon, we caneasily switch to it and instruct Humor to analyze the actualword.
Humor eturns something like dnvxe\[S\] where'S'  isnow the category of the input word indicating that it is asentence.The meta-lcvel, of course, can be split tip to further lev-els.
Let us use, for the sake of simplicity, a simple toygrammar of two levels for the nominal phrase and the sen-tence:(Level 2) S -~ NP S, S -~, S NP, S -+ V (3SG)(t,evel ) NP --~ DET NG, NG -~ ADJ NG, NG -+ NNow we feel a need for a tool that generates a set of finitepatterns out of this grammar description.
We, therefore,developed a tool that finds the largest regular subset of acontext free language (regarding a special parameter set)and then uses a recursive generator to produce the finitepatterns.
\]For the above toy grammar a possible lexicon canbe the following:(Level 2): V END, V 3SG END, NP V END.
NP V 3SG END, NPV NP END, NP V 3SG NP END, V NP END, V 3SG NP END ....(Level 1): DET N, DET ADJ N, DET ADJ ADJ N ....If we use letters v, m, x, n, a and d for V, NP, 3SG, N,ADJ and DET, respectively, we get the following lexicons:(1 ,evel S) re, vxe, mve.
mvxe, mvme, m~xme, vine, vxme ....(Level NP) dn, dan, daan ....If the appropriate l xicons are built from the pattern listsfor grammars of both levels, the parser is ready to run.
Theparsing algorithm can be outlined as follows.
\]'he parserruns a morphological analysis on each word in the inputsentence and encodes the morph-codes into meta-letters.Using our example, The dog sings (DET N V 3SGEND) the parser will find that the string 'DET N' forms anoun phrase, because dn can be found in the NP lexicon.The meta-morphological analysis (a search in the lexiconof the patterns of Level 1) returns dn\[m\], that is, DET N\[NP\].
For level 2, the parser exchanges the substring 'DETN' with the meta-letter 'NP'.
So the new recta-word is mve,that is, 'NP V END' which is accepted by the Level 2grammar (sentences).
In fact, we have another meta-wordhere, namely, a single n (='N') that can also be categorizedas a noun phrase (m); and this yields dmve, that is, 'DETNP V END' which is not accepted by the Level 2 grammar.Giving these two as input to the Level 2 meta-morphological analysis, the system will reject dmve 'I)ETNP V END' but will accept mve 'NP V END' by returningmve\[S\], that is, NP V END \[S\].It is clear that no backtracking is possible in our run-time system, that is, a meta-word cannot be categorized bya symbol that is a recta-letter of meta-words on the same orlower level.
It is an important restriction: category symbolsmust be recta-letters used only on higher levels.
This con-straint providcs us with another advantage: any set of cate-gory symbols (higher level meta-letters or meta-morph-codes) is disjoint from the set of lower level meta-letters(or recta-letters used on the level of morphology), there-fore, parsing lexicons can be unified: meta-words(morphological or any set of phrase structure patterns) forall levels can be stored in a single lexicon.In the explanation of the parsing techniques we have ex-cluded one aspect until this point, and this is unification.Without feature structures and unification, however, nu-merous incorrectly formed sentences are accepted by theparser.
If a meta-word is not ~bund, it is rejected and theprocess goes on to the next meta-word.
If the meta-word isfound, then it may still be incorrect.
This is checkedthrough the unifiability-checking of the feature structuresof its ineta-letters.
For instance, in a noun phrase 'DET N',the unifiability of the feature structures assigned to I)ETand N is checked.
If they are not unifiable, the recta-wordis rejected and the process goes on to the next recta-word.If they are unifiable, the output is passed on to the nextlevel.
The last level is responsible for providing the userwith the proper analysis, that is, all the information coblected so far.3 FROM GRAMMARS TO LEX ICALPATTERNSAll infinite structures generated by recursion can be re-stricted by limiting the recursion depth.
This means a con-straint of the depth of the derivation tree of a sentence in alanguage.
We can also restrict he direction of branching inthe derivation tree.
'\['his means that we could generate(finite) patterns directly fi'om the original (context-free)language imposing various limits on embedding; but thesemethods can be too weak or too strong and, most of all, ir-relevant to the ol~iect language.
There is, however, aslighter constraint that helps transfbrming context-freegrammars.
According to Kornai's hypothesis (Kornai1985), any string that can be the beginning of a grammati-cal string can be completed with k or less terminal symbols,where k is a small integer.
This k is called the string com-pletion limit (SCL).
A grammar transformation device canbe instructcd to discard sentence beginnings that have aminimal SCL larger than specified (by the user).
SCL lim-its center-embedding but allows arbitrary deep right-branching structures (easily defined by right regular gram-mars), l,eft branching is also limited, but this limitatibn isless pronounced than that of center-embedding.Our special tool, GRAM2LEX, takes a CF grammar asinput.
As a first step, it reads the grammar and creates theappropriate RTNs from it.
Goldberg and Kfilmfin (1992)describe an algorithm unifying recursive transition net-works.
We have improved their algorithm.
Its implementa-tion is incorporated into the GRAM21,EX tool as a secondprocessing phase.
The algorithm creates the largest regularsubset of a context-free language that respects the SCI,.
Interms of finite state autonmta, SCL is the number ofbranches in the longest path fi'om a non-accepting state toan accepting one (regarding all such pmhs).
The process re-stilts a finite state automaton.
In order to get a finite dc-scription, from the FSA we introduced two independent pa-rameters.
The length of the output string (in terms of ter-minal symbols) If the current string reaches the maximumlength, the recursion is cut and the process immediatelytracks back a level.
The maximum number of passing thesame branch during the generation of an output string canalso be specified.
In the current implementation, this1124maximum is global to a whole output string.
There is, how-ever, another approach: this number can be related to thecurrent recursion level, so if a certain iteration occurs atmore than one position in a sentence, the maxinmm lengthof the iteration is the same at both positions and the actttallengths are independent.The GRAM2I J.iX tool takes all thc three parameters (theS('I,, the maximum string length and the maximum itera-tion length) as user-defined ones.
The set of finite patternscan be compiled into a compressed lexicon with Morphol,-ogic's lexicon compiler.
The GP, AM21J!X tool produces afile in the input format required by this compiler.l,evels of the parser are individual processes that com-municate with each other.
The most important medium isthe internal pmwing table that represents the parsing graphdescribed below.
Based on lhat graph, the process of a par-ticular level is able to execute its main Rmctional lnodnles,namelyto create the appropriate input to call the morphologyengine,?
switch tn the phrase pattern lexicon of the currentlevel,run the morphology engine and process the output ofthe morphology engine, and?
if possible, insert new branches into the parsing graphlbr the next level.Each level is an independent process communicatingwith the others (including level 0, the morphological naly-sis).
The medium of commtulication is the parsing graph ofwhich there is only one copy and is generally accessed byall levels.
The parsing process on each level can be decom-posed into three layers.
All levels have the same function-ality; it is nnly the internal operation of the first layer thatdiflcrs in the case or' the lowest level (morphology) alld tilehighest one (sentences):?
pre-process that based on the current structure of theparsing graph (if it exists), produces tile set of the pos-sine phrasc slructurcs,+ search that checks all the elements of the set generatedby l,ayer 1 if they are acceptable by the eurrcnt levelusing the ttumor engine equipped with the current levcl'sparsing lexicon,?
post-process that based on the patterns accepted byl,ayer 2, inserts new nodes and branches into the pars-ing graph.The different levels are cnnnected to each other like tilelayers of a single level.
The structure of our present(demonstrational) 0-1-2-level parser for l lungarian is thetbllowing:?
Morphology (Preprocess Words, Search Morphologyl+cxicon, Create/Modify Parsing Graph),?
Noun Phrases (Create Patterns, Search l,evel 1 l'atternl,exicon, Modit~?
Parsing Graph),?
Sentences (Create I'atterns, Search I,evel 2 l'attcrnl,exicon, Modify Parsing Graph).4 IMPLEMENTING THE RUN-TIMEPARSERIn the current implementation, the parsing levels are exe-cuted sequentially, but they can be made concttrrent: dur-ing one session, level (/reads a word from the input sen-tence, analyzes it and inserts the appropriate nodes andbranches into tile parsing graph.
Further on, tile system hasa self-driving structure: tile level that made changes to theparsing graph sends all indication to the next level whichthen starts the same processing phase, The changes in theparsing graph are thus spread upwards in the level struc-ture.
When the last level (usually the highest) finished up-dating the graph, it sends a 'ready for next' signal to level 0which starts the next session.Termination is controlled by level 0: if it finished am>lyzing the htst word (morpheme) of the sentence, it sends a'ternainate' signal to the next level.
Receiving this signal,intermediate l vels pass it to the next level after finishingthe processing the changes that were made to the parsinggraph.
The last level (usually the highest) thcn terminatesall levels and passes the parsing graph to tile output gen-erator.I,ct us see an example:Patterns: s: NI' VI' ENDNit N I N N I D|:,T N I DET AI)J N Il)l{'I' ADJ AI)J NVP: V I V 3SG \] V NP I 131,2 VING \[ FH:, VINGADV I V NPEND: .
I !lnpnt: Pro/bss'or Smith is coming home.Output: S - ,  \[NI' VP t';ND INP-> IN NIN--+ ProfessorlNIN - ~, Smith\[PROP\]VP -> \[lie VING AI)VIBI,2 > isllW\]VING -+> eeme\[V\] t-ing\[lNGIADV +.
home\[AI)V\]END ->.This is the inherent agging of the sentence built from theinformation stored directly in the phrase structure patterns.We have begun, however, the development of another typeof tagging where phrases correspond to the source gram-mars' non-terminal symbols, like this:(S(NP(N professor)(N Smith))(VP(BE is)(V(J(V\[N(;(V eome)(ING ing))(ADV home))))The cur,ent average speed of this multi-level system(even for dictionaries with 100.000 entries) is arotnld 50input/see for each module on a Pentium/75 machine, whereinput can mean either sentence or phrase or word to bcanalyzed.5 USER INTERFACEThe current implementation of the Humotl:$K parser allowsthe run-li,ne expansion of the user-defined lexicon file.This was achieved by developing a small user interface thatperforms the following functions:1125?
Works in both batch and interactive mode.?
Users can review all the different taggings of a sentence.?
Users can view the internal parsing table from which theparser output was generated.
This means the review ofthe analysis of each morpheme and the recta-words gen-erated from them.
?Uscrs  can view both the morpho-lexical nd the syntacti-cal part of the user-defined lexicons.?
The user can acid new entries to the user-defined lexiconfile on any level.
The changes take effect suddenly, thatis, when processing the next sentence or re-parsing thelast one.6 CONCLUSIONWe have developed a parser called {-lum0rl:Sl( that is quitepowerful (even in its present format, without feature struc-tures) and has several important features:1. unified processing method of every linguistic level2.
possible parallel processing of the levels (morphology,phrase levels, sentence l vel, etc.)3.
morphological, phrasal and syntactic lexicons can be en-hanced, even in run-time4.
easy handling of unknown elements (with re-analysis)5. easy correction of gramnmtical Errors6.
reversible (generation with the 'synthesis by analysis' )7. the same system can be used both for corpus tagging andfinE-grained parsingl"eature I seems important if thcrc is not enough spaceto add a new engine to an existing lnorphology-ascdapplication (e.g.
a spell-checker), but you must handlesentence-level information, as well (e.g.
a grammarchecker).
Real parallelism indicated in 2 has not yet beenimplemented.
Usefulness of attributes 3-6 are going to bcproven in practice, because we have just finished the firstversion of the first I lungarian gramma," checker called Hely-esebb.
It uses the spelling corrector and morphological na-lyzcr/gcnerator modules relying on the Humor morphologi-cal system -.
the basis of Hurn0rE,~l( that are widely used bytens of thousands of both professional and non-professional End-users (Prdszdky 1994, Prdszdky et al1994).
We have results in proving the first part o1' \['caturc 7,namely corpus tagging.
Fine-grained parsing would needthe extended use of features.
This system .- as wc men-tioned earlier - is under development.7 REFERENCES\[1\] Goldbcrg, J. and I,.
K/dmfin, ?The First BUG Report',Proceedings of COLING-92, Nantes (1992).\[21 Kis, B.
'Parsing Based on Morphology', UnpublishedMaster's Thesis, Budapest Technical 1Jniversity, 1995.131 Kornai, A.
'Natural ,anguages and the Cholnsky Ilie,-archy', Proceedings (?f the 2nd Conf.
of the I:ACL, Ge-neva, 1-7.
(1985).1411 Prdsz6ky, G. 'Industrial Applications of UnificationMorphology', Proceedinjzs ()/ ANLP-94, Stuttgart(1994).\[5\] Prdszdky, G., M. Pal and I,.
Tihanyi, 'Hum0r-bascd Ap-plications', Proceedings o/C'OLING-94, Kyoto (1994).\[12\] A Duna ut&n a T isza a legnagyobh foly6nk.\[i/\] \] 0:00:02.9\]  HumorESK 2.0 REV\[F,WSS -> \[DP Cas DP DP End\]DP -> \[Det N\]Det -> a \ [Ar t i c \ ]e \ ] -AN -> Duna \[ProperNoun\]Cas -> ut6n \ [PostPos i t ion \ ]13P -> \[Det N\]Det -> a\[Art ic le\ ]N -> T isza\ [Noun\]D\] ) -> \[Det Adj\  Adj \Adj N PSfx\]Det -> a\[Art ic le\]Adj \  -> leg \[Superlat ive\]Adj -> +nagy\ [Ad ject ive \ ]\Adj -> +obb\ [Comparat ive \ ]N -> fo\]y6\[Noun\]PSfx -> +nk\ [PersSuf fP lu rF i r s t \ ]End ->First \[^HOME\] Last \[^END\] \[G\]o to Syntax except ions \ [A \ ] t+S\ ]\[P\]arse again Accept \ [AENTER\ ]  JR\]eject Word except ions \ [A l t~W\]Exit \ [ESC\]  Internal  pars ing  table\[F lO\]Figulc 1.
HumorESK-analysis of thc sentence"A Duna utdn a Tisza a legnagyobb folydnk.
"(After the Danube, our biggest rivet" is Tisza.
)1126
