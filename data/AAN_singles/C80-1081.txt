AN ATTEMPT TO COMPUTERIZED DICTIONARY DATA BASESM.
Nagao, J. Tsujii, Y. Ueda, M. TakiyamaDepartment of Electrical EngineeringKyoto UniversitySakyo, Kyoto, 606, JAPANSummar XTwo dictionary data base systems developed atKyoto University are presented in this paper.One is the system for a Japanese dictionary (Shinmeikai Kokugojiten, published by Sansei-do)and the other is for an English-Japanese diction-ary (New Concise English-Japanese Dictionary,also published by Sansei-do).
Both are mediumsize dictionaries which contain about 60,000 lex-ical items.
The topics discussed in this paperare divided into two sub-topics.
The first topicis about data translation problem of large, un-formatted linguistic data.
Up to now, no seriousattempts have been made to this problem, thoughseveral systems have been proposed to translatedata in a certain format into another.
A univer-sal data translator/verifier, called DTV, hasbeen developed and used for data translation ofthe two dictionaries.
The detailed constructionof DTV will be given.
The other sub-topic isabout the problem of data organization which isappropriate for dictionaries.
It is emphasizedthat the distinction between 'external structures'and 'internal structures' is important in a dic-tionary system.
Though the external structurescan be easily managed by general DBMS's, theinternal (or linguistic) structures cannot bewell manipulated.
Some additional, linguisticoriented operations should be incorprated in dic-tionary data base systems with universal DBMSoperations.
Some examples of applications of thedictionary systems will also be given.i.
IntroductionTo computerize large ordinary dictionaries issignificant from various reasons:i) Dictionaries are rich sources of referencein linguistic processings of words, phrases andtext.
Algorithms for natural language p~ocess-ing should be verified by a large corpus of textdata, and therefore, dictionaries to be preparedshould be large enough to cover large vocabulary.2) Dictionaries themselves are rich sources,as linguistic corpora.
A data base system, whena dictionary data is stored in it, enables us toexamine the data by making cross references fromvarious view points.
This will lead us to newdiscoveries of linguistic facts which are almostimpossible by the printed version.3) Computerized dictionaries have variousapplications in such areas as language teachingby computer, machine aided human translation,automatic key word extraction etc.
(3)We have been engaged in the construction of dic-tionary data base systems these three years,and have almost completed two such systems.
Oneis the system for a Japanese dictionary (Shin-meikai Kokugojiten, Published by Sansei-do) andthe other for an English-Japanese dictionary(New Concise English-Japanese Dictionary, alsoPublished by Sansei-do).
Both are medium sizedictionaries which contain about 60,000 items.In Addition to these two dictionary systems,we are now developing a system for an Englishdictionary (Longman dictionary of ContemporaryEnglish, Published by Longman Publishing Compa-ny, England).
(4)Two topics will be discussed in this paper.
Thefirst is about the problem of data translation,that is, how to obtain formatted data which aremore suitable for computer processings than theirprinted versions.
The second is the problem ofdata organization, that is, how to organize theformatted data into data base systems.
We willalso give some examples of applications of thesesystems.2.
Data Translation from Printed Imag~to Formatted DataWe decided to input the dectionary contentsalmost as they are printed, and to translatethem into certain formatted structures by com-puter programs rather than by hand.Ordinary dictionaries usually contain varietiesof information.
The description in English-Japanese dictionary, for example, consists ofI.
parts of speech 2. inflection forms3.
pronunciations 4. derivatives5.
compounds6.
translation equivalents in Japanese(Usually several equivalents exist andthey correspond tO different aspects ofmeaning of the entry word)7. idioms and their translations8.
typical usages and their translations9.
antonyms and synonymsetc.An entry may have several different parts ofspeech (homograms) and to each part of speech,the other information 2-9 is described (evenpronunciation may change depending on the partsof speech).
7, 8 and 9 are usually attached toone of the translation equivalents (see Fig.
i).In such a way, the description for a dictionaryentry has a certain structure, and the severalparts of the dictionary descriptions are relatedto each other.
In the printed dictionaries,these relationships are expressed implicitly inlinearized forms.
Various ingenious conventions--534~Heac 7ord 1IPronunciation I Japanese _ _  GrammaticalTranslations ExplanationIFig.
1 Relationships among Lexical Descriptionsare used to distinguish the relationships , in-cluding several kinds of parentheses, speciallydesigned symbols ( ~ , ~ , ~ etc.)
and char-acter types (italic, gothic etc.).
However, inorder to utilize these relationships by programs,we should recognize them in the printed versions,and reorganize them appropriately so that theprograms can manage them effectively.
Insteadof special symbols or character types, we shoulduse formatted records, links or pointers to ex-press such relationships explicitly.
We callthis sort of translation from the printed ver-sions to computer oriented formats as data trans-lation.
"~ The printed version of a dictionary highly relieson human ability of intuitive understanding, andconsists of many uncertain conventions.
Gothiccharacters, for example, indicate that the phrasesprinted by them are idioms, and italic charactersshow that the entry words have foreign origins.In the input texts for computer, these differenttypes of characters are indicated by a set ofshift codes.
Shift codes, together with variousspecial symbols such as ( , ), \[ , \], ~ etc,give us useful clues for the data translation.However, these codes should be interpreteddifferently, when they are used in differentparts of descriptions. "
( "  shows the begin-ning of the pronunc iat ion when it appears justafter a head word, and, on the other hand, whenit is used in the midst of an idiomatic express-ion, it shows the beginning of an alternativeexpression of just the preceeding one.
Suchconventions, however, have many exceptions.Moreover, the fact that there may be errors inthe input texts makes the translation processmore difficult.If we use an ordinary programming language likePL/I, the program for this purpose becomes acollection of tricky mechanisms and hard todebug.
Data translation of this kind is inevi-table whenever we want to process unformattedlinguistic data by computer.
It would be veryuseful if we could develop a universal systemfor data translation (in fact, our systemdescribed below has been used not only for dic-tionary data translations but also for thetranslations of bibliographic data in ethnologyat the National Museum of Ethnology).2-1.
Data Translator/Verifier -- DTVThe data translation can be seen as atranslat ionfrom linearized character strings to certainorganized structures.
The relationships implic-itly expressed in the linearized strings shouldbe recovered and explicitly represented in theorganized forms.
It is basically a process ofparsing.
It has many similarities with parsingof sentences in artificial or natural languages.It has more similarities with natural languageparsings in the sense that both are defined bymany uncertain rules.
Therefore, it is reason-able to expect that we can apply the same tech-niques to this problem that have beenprovenuseful in natural language parsings.
Severalpropos'als have been made to define data syntaxby using ordinary BNF notations (or CFG)(~'~)How -ever, we adopted here the framework of ATN(Augmented Transition Network) instead of CFGby the following reasons:(i) CFG is essentially a model of a recogniz-er.
Although it is possible to check the syn-tactic correctness of input texts by CFG rules,we need another component that transduces theparsed trees into formatted records we want.ATN gives us an adequate model of a data trans-ducer.
It has provisions for setting up inter-mediate translation results in registers (regis-ters in ATN are called 'buffers' in our system)and building them up into a single structure(called BUILDQ operation in ATN).
(2) CFG provides an adequate framework formanaging recursive structures such as embeddedsentences in natural languages.
Though recur-sive structures are also found in dictionarydata, they are not so conspicuous.
The struc-tures in dictionaries are rather flat.
In thissense, CFG is too powerful to define data syntaxof dictionaries.
(3) ATN provides a more procedural frameworkthan CFG.
Because a CFG based system assumes ageneral algorithm that applies the rules to theinput text, the user who defines the rules can-not control the algorithm.
This is a fataldisadvantage of CFG, when the input text containsmany input errors.
Whenever an input error isencountered during the translation process, aCFG system fails to produce a parsed tree.
Thesystem or the human user should trace back thewhole process to find the input error whichcauses the fai lure.
It would be a formidabletask.2-2.
Definition of Rules ~ Codes~ Buffers andFilesBased on ATN model, we modified it for datatranslation.
In this section, we will explainthe detailed syntax for the DTV (the formaldefinition of the DVT syntax is given in (8).
(A) Definition of CodesIn the case of syntactic analyses of naturallanguage sentences, the basic units are parts--535of speech of individual words or individualwords themselves.
Special checking functionssuch as CAT and WORD are prepared in the origin-al ATN model.
On the other hand, in the case ofdata translation, the basic units are individualcharacters.A restricted set of characters such as the char-acter set defined by ISO or ASCII are used andsufficient for ordinary computer applications.However, when we want to process real documentsor linguistic data like dictionaries, we needmuch richer set of characters.
Though, inprinciple, a single kind of parenthesis is suffi-cient for expressing tree-like structures,several different sorts of parentheses suqh as( , \[ , ~ , { , ~ etc.
are used to identifydifferent parts of descriptions in the publisheddictionaries.
We also found out that a certainset of characters, for example, phonetic symbols,appear only in a certain specific position (thepronunciation in the case of phonetic symbols)in the dictionary descriptions.
If we couldrecognize the scope of the pronunciatioL~ parts,we would not need to have extra sets of char-acter codes for phonetic symbols.
We couldinterpret ordinary ASCII codes in the pronun-ciation part not as usual alpha-numeric char-acters but as phonetic symbols, according tocertain pre-defined rules.However, these redundancies of descriptions areespecially useful for detecting input errors.Whenever we find out the codes for phoneticsymbols in the positions other than the pronun-ciation fields, or inversely, when we encounter,in the pronunciation fields, the codes for thecharacters other than phonetic symbols, somethingwron~ would be in the input texts.Because we have about i0,000 or more differentKanji-(Chinese) characters in Japanese, a stand-ard code system such as ISO, ASCII etc.
is nomore adequate, and therefore, a special codesystem has been determined as JIS (JapaneseIndustrial Standard).
The code system assignsa 2 byte code to each character.
We have 752extra codes which are not pre-defined by JISand to which the user can assign arbitrary char-acters.
Various types of parentheses, shiftcode, phonetic symbols etc.
have been definedby using these extra codes.
Because each char-acter, including alpha-numeric, Kanji, specifi-cally designed symbols, shift codes etc.,corre-spond to a 2 byte code, we can assign a decimalALPHA-SMALL = 9057 - 9082ALPHA-LARGE = 9025 - 9050ALPHA = ALPHA-SMALL, ALPHA-LARGEKANJI = 12321 - 20554SHIFT-GOTHIC = 10273Note : The lower case alphabet characters are defined asthe decimal numbers between 9057 and 9087.
The al-phabet characters are defined as the union of ALPHA-SMALL and ALPHA-LARGE.Fig.
2 Code Definition by Decimal Numbersnumber to each character by interpreting the 2byte code as an integer representation.
By usingthis decimal number notation, we can definearbitrary subsets of characters as shown in Fig.2.
These subsets of characters play the samerole for the data translation as the syntacticcategories for sentence analysis.
Notice thata character is allowed to belong to more thanone character set.
(B) Definition of RulesA rule of DTV is defined by a triplet as(condition action next-state).The condition-part is specified by using the codesets defined in (A), Two forms of specificationsare possible.i.
< subset-l, ..., subset-n >2.
( subset-l, .... subset-n )The first notation means that the characters inthe specified subsets should appear in thisorder.
The second is the notation for specifyingOR-conditions, that is, a character in one of thespecified subsets should appear.
Arbitrarycombinations of these two bracketing notations areallowed such as<(  < > ) ( )> .The action parts, which wil l  be carried out whenthe condition parts are satisfied, are describedby using a set of built- in functions.
These arethe functions for manipulating buffers and files.Some examples of such built- in functions areshown in Table i.Function Argument ResultWRITE *\[-number\] the currently scanned char-BUF(Buf-name) acter(or the 'number' pre-ceding chracter) iswitten inthe buffer.RECNO the ID number of the currentBUF(Buf-name) input record is written inthe buffer.PTR the position of the scannedBUF(Buf-name) character in the input recordis written in the buffer.
'arbitrary char- the specified characteracter string' string is written in theBUF(Buf-name) buffer.BUF(Buf-name) the content of the buffer isFILE(File-name) written out to the externalfile.MERGE BUF(Buf-nam~l,.. the contents of the n buffers., Btlf-namen ) are merged into a singleBUF(Buf-name) buffer specified by thesecond arguement.CLEAR CTR(Counter- the counter is cleared to 0name) or BUF( or the buffer is cleared hyBuf-name) blank characters.ADD CTR(Counter- the counter is counted up byname) the number.NumberTable 1 Built-in Functions in DTV- -536  -Several actions can be specified and they will beexecuted in sequence.The next-state specifies the state to which thecontrol is to be transferred after the currentrule is applied.
A typical state-diagram isshown in Fig.
3.I~- -~ ANGLE~__~ ~LPHABE rFig.
3 Tyipical State-Diagram(C) Definition of Buffers and FilesWe can define arbitrary numbers of buffers withvarious sizes as follows.BUF-NAME SIZE(BYTE) IF-OVERFLOW-STATESPELLING 40 SPELL-ERRORIDIOM 30 IDIOM-EXPANDOne of the typical input errors is the omissionsof delimiters which cause serious problems indata translation.
Various characters play theroles of delimiters.
They are shift codes,several sorts of parentheses, etc.
and they areused in pairs (right vs. left parentheses, shift-in vs. shift-out etc.)
to delimit scopes ofspecific data fields.
When one of the pair ismissing, two situations would occur: the bufferscorresponding to the fields may overflow orillegal characters for the fields may be scanned.The latter case can be easily detected becauseno transition rules are defined for that char-acter.
DTV put a message to the error messagefile which tells at which position the illegalcharacter is found.
The former case is rathertroublesome.
Checking overflow conditions byrules makes the whole definition Very clumsy.We can specify in the definition of a buffer, towhich state the control makes a transition ifthe buffer overflows.
In that state, some errormessages are printed out.2-3.
System ConfigurationFig.
4 shows the overall construction of DTV.By the compiling component, the definitions ofRaw DataCompilingComponentDefinition forRules, Codes, Buffers,Input File, Output Fileetc.Output FilesInternal (formatted)TablesExecuter V E ~~ MessageFileFig.
4 Overall Construction of DTVcodes, buffers, files, formats of input and Out-put, and translation rules are compiled intoseveral internal tables.
Based on these tables,the executer scans the input characters one byone from the input file and applies the rules.During the execution, the system will reportvarious error messages such as 'buffer overflow','illegal characters' etc.
into the error messagefiles.
Because the detailed information, suchas the position of the error in the input text,is associated with these messages, human proof-readers can easily recognize the input errors.A flexible editor has been developed for correct-ing input errors.
Because this editor has aspecial command to call DTV, the reviser cancheck the data syntax immediately after thecorrection (see Pig.
5).I FormattedrecordsNote : Data Editor output an input record with the corre-sponding error message.
The human proofreader caneasily recognize the input error and revise it.
Afterthe revision, he/she can check whether the input recordcontain no more errors, by calling the DTV.Fig.
5 Data Editor Accompanied by DTV2-4.
Experience with DTVWe used DTV for data translation of the English-Japanese dictionary.
About 500 rules and 150states were necessary to manage exceptionaldescription format of the dictionary.
BecauseDTV should scan and check every input character--537--and because the dictionary consists of 6,500,000characters, the whole process was very timeconsuming (it took about 130 min.
for translatingthe whole dictionary by FACOM M200 at KyotoUniversity Computing Center).In order to show the effectiveness of DTV, Table2 is prepared, which shows the input errorsdetected in the initial input.
Some of them canbe corrected automatically only by augmentingDTV rules.
Moreover, the data editor accompaniedby DTV was so effective that all of the detectederrors were completely removed by 3 man-monthefforts.
However, DTV can check mainly theconsistency of delimiting characters.
Therestill remain a lot of input errors in the textsuch as errors in spellings of words.
The de-tection of such input errors requires certainsemantic knowledge and is hardly done by DTVrules.
Human proofreader should do it.
Humanproofreaders can easily recognize these errors,but tend to overlock the errors such as omissionsof delimiting characters.
Certain effective co-operations between man and machine seem to beinevitable in correcting errors in a largeamount of linguistic corpora like dictionaries.Another point to discuss is the relations be-tween DTV and data entry systems.
Though ourattempt here is highly batch-oriented, someconsiderations about intractive data entrysystems will be necessary in future to augmentthe dictionary data in evolutional ways.
Anordinary data entry system usually guides theError TypeMlssings ofshift codesConfusionsof similarcharactersFluctuationsin charactersequencesExceptionalformats whichwere not ex-)ectedbeforehand.Misunder-standings ofkey punchersMiscellaneouserrorsTotalExplanations FrequenciesShift-out codes (the code for 792normal characters) are oftenmissin$.The phonetic symbol '~' is, 5434for example, often confusedwith the number character 3.Certain functional character 1166sequences can express a samething.
It is impossible tostandardize them in the casethat several key puncherswork in parallel.The description formats for 550acronyms, for example, arequite different from those ofordinary words.Though the key punchers con-sented to several standard-ization rules for input,some of them misunderstoodthem.1298127610516Note i: ~ shows that the errors of that type can be au-tomatically corrected only by augmenting DTV rules.?
~ shows that some of them can be corrected auto-matically by augmenting DTV rules.Note 2: The exceptional format errors are not input errorsin a true sense.Table 2 Error Frequencies in the Initial Datauser as to what he should input next, by print-ing prompting messages such as 'input the nextword', 'input the part of speech of the word'etc.
However, in the case that the input datahave rich varieties in their description formatslike the dictionary here, such a system becomesinfeasible.
Though some guidance by the entrysystem would be necessary, it is natural for theuser to input data in arbitrary fashion.
Thedata entry system should have the abilities oftranslating the texts into certain formattedstructure, and of checking the existence of in-put errors.
Our data editor accompanied by theDTV is the first step toward developing suchdata entry systems.3.
Data Base Systems for DictionariesA dictionary description has a certain hierar-chical structure such as previously shown inFig.
1.
Such a structure can be well represent-ed by a framework provided by ordinary DBMS's,because it is just a simple tree structure.However, the primitive data (or records) fromwhich the whole structure is built have certaininternal structures of their own.
For example,idioms or typical usages in English-Japanesedictionary are the primitive records which arelocated at certain fixed positions in the wholestructure and related to the other records suchas translation equivalents, head words etc.They ean be accessed as basic units throughusual DBMS operations.
At the same time, theyare composite expressions which consist ofseveral component words.
These component wordsare related to each other inside the idioms.
Wecall such structures inside the primitiverecords ' internal structures'.
(See Fig.
6)In other words, the primitive records in a dic-tionary data base system are not primitive in aEXTERNAL STRUCTURE.
ADw0 ;, \  NFL CT D \  .
'Took 'PP' oken'I~ ?PICAL-USAGESW it.upon o~e:e~f to ;ay sfmethinglJap .....TranslationINTERNAL (LINGUISTIC) STRUCTURE;~ ~ -c ~ I~  Verbal complement/which can be replacedJapanese Translation of the VC with various expres-is inserted here sionsfixed expression which can be varied such as'took it upon myself to''takes it upon himself to'Fig.
6 External Structure andInternal Structure in a Dictionary Data-~-538usual sense of DBMS.
Though the external struc-tures among primitive records can be managed byan ordinary DBMS, the internal linguistic struc-ture,in some sense, cannot be well manipulated.Moreover, what we want to do on the dictionarydata base systems is not only concerned withexternal structures, but also, in many cases,concerned with their internal, linguistic struc-tures.
Some additional operations should beincorporated with the usual DBMS operations fortreating such intermixed structures.3-1.
Japanese Dicti0nary Data BaseThe first thing we have to do is to incorporatemorpho/graphemic level of processings.
BecauseJapanese has a very peculiar writing method,special techniques are required to utilize thedictionary.
The main difficulty we encounteredin developing the dictionary consultation systemis from the fact that dictionary entries ofJapanese usually have more than one spelling.They have basically two different forms of spell-ings, Kana-spellings(spellings by Japanesephonetic symbols) and Kanji-spellings (spellingsby ideographs -- Chinese characters).
Correspond-ing to these two spellings, we have two types ofprinted dictionaries, one for Kana and the otherfor Kanji spellings.
However, in actual sen-tences, there often appear mixed forms of thesetwo spellings.
(See Fig.
7) Though these mixedKanj i-Spellin~ Kana-Spc \]\] ing Mixed Spell ing Mean \[ngFig.
7 Various Spellings of a Single Wordforms are not entered in the ordinary, printeddictionaries of both types, human readers areintelligent enough for converting them into oneof the two basic spellings.
As for a computer-ized dictionary system, a certain graphemiclevel of processing is necessary for consultingthe system from these mixed forms.In our system, the intermediate indexing struc-tures are provided for both Kana and Kanji-FCTKana-characterKanji-characterI d Meaning ~ Descr ip t ionFig.
8FCT : First Character TableFFCT : First Five Characters TableSCT : Second Kanji Character TableIT : Item TableIntermediate Indexing Structurefor Japanese Dictionaryspellings (Fig.
8).
The dotted line shows theaccess path for Kana-spellings and the bold lineis for Kanji-spellings.
The relationships amongFCT, FFCT, SCT and IT are illustrated in Fig.
9,and the required memory spaces for these struc-tures are given in Table 3.FFCT~ /I _  ~< ~b ......Note : Each record in IT(Item Table) contains apointer to the meaning description of the word.IT, FFCT and SCT are blocked and stored in thesecondary memory (disc file).
Each block con-tains 50 records.
A SCT record contains a setof Kanji-characters which follow the same(first)Kanji-charscter.Fig.
9 Relationships anong FCT, FFCT, SCT and ITIndex Table Storage RequirementFCT 24 KBFFCT 18.6 KBSCT 700 KBI T 4.3 MBTable 3 Required Memory SpaceMixed spellings are normalized into one of thesebasic spellings.
We can obtain Kana-spellingsfrom mixed ones, by systematically changing theKanji-characters in the mixed spellings intocorresponding Kana-strings.
However, becauseeach Kanji-character corresponds to three orfour (or more) different Kana-strings (eachKanji-character has several pronunciations ), theresultant Kana-strings are to be matched againstthe Kana-spellings in the dictionary.
Some ex-amples of retrieval results are shown in Fig.
i0.Another problem is the incorporation of themorphological analysis component.
Because theword inflection system for Japanese is much rich-er than English, the morphological analysSscomponent is indispensable for the Japanesedictionary system.
The morphological analysisprogram developed for our another project, i.e.,Machine Translation Project ( 7 ), has beenincorporated into the system.
The retrievalprogram has Japanese inflection rules in it andcan convert inflectional variants to their--539(i) Inpu?
spellln~ by KANA-charecterK*.~.o~= ~ ~" b* 9-,~--------Input~, t * 9 ~-Ret r ieved  entry~' Z * ~ ~'~--Retrieved entryNote : Two entries are retriev~ because they have thethe same spelling.
(2) Input spelling by a Mixed-spellingKANJ  ,= ~} ~' ~ inputFig.
i0**ONKUNI  BL u~\ [  l l * *~v,  b ~, ~ The _ j_ _ ~ NOT Foun~ ~N KOMOKU~BL Van~_characVe r ~ , is~, b ~ ~--replaced systematically by itsNoTNOT~ V" L - FOuNoFOUND< INI  K OMOK OT BL U \]corresponding KANA-stringe.KOMOKUSU : I : /An  entry which has theMATCI ' ING_KOMOKUSO= |; ~the mixed-spelling is~' ~' ~ ~ found.Retr ieva l  Resu l ts  o f  Japanese  D ic t ionaryinfinitive forms.
The rules are almost perfect,and more than 98% inflectional variants can beconverted correctly to their infinitive forms.3-2.
E_n.glish-Japanese Dictionary Data BaseThe morpho/graphemic processings which are re-quired for util izing this dictionary are muchsimpler than for the Japanese dictionary.Because most of derivatives are generally adopt-ed in the dictionary as head words, the process-ings for derivational suffixes are not necessary.We can retrieve the corresponding lexical entriesfrom their own spellings.
When we want to seethe original word from which the derivative isderived, it is required only to traverse theexternal structure (that is, a record for aderivative always contains a pointer to itsoriginal word).
Therefore, the current systemonly recognizes the inflectional suffixes ofEnglish to convert inflected forms to theirinfinitive forms.
As for the irregularyinf lect-ed words, all of their inflectional variantsare extracted from the dictionary, and are storedin the inverted files (all of the head words arealso stored in the inverted files).
Some resultsof retrieval are shown in Fig.
ii.As we described at the beginning of this section,some linguistic operations should be incorporat-ed in a dictionary data base system besidesusual operations provided by ordinary DBMS's.Morpho/graphemic processings are one of suchoperations.
Another example is the retrievalof 'similar' expressions.
English-Japanesei) An Example of Regularly Inflected WordsEST.//~_ input wordFLASH,f | a s h ?
y~.~- ~'~ 121 ~--- importanceff~ ~ P.O.S.f i ~e S i ~ pronunciationJapanese translations2) An Example of Irregularly Inflected WordsFo RE WE N~/ input  wordf o r e ?
g o~1~ ~ ~ P .O .S .~ f a r g 6 u /  f a : -~ ~ - w e n t \[ - w ~ n t \] ; ~ - ~~ ( ~ ~ ~ , ~ b ~ = ~  < ( \]~- Japanese  t rans la t ionF ig .
11  Ret r ieva l  Resu l ts  o f  In f lec ted  Var iantsd ic t ionary  conta ins  Eng l i sh  id ioms and the i rt rans la t ions ,  and  typ ica l  usages  o f  each  wordand  the i r  t rans la t ions .
The  e f fec t ive  u t i l i za -t ion  o f  these  by  computer  i s  a very  in teres t ingtop ic ,  because  th i s  i s  one  o f  the  essent ia l" reason-d 'e t res"  o f  the  d ic t ionary .
We havebeen deve lopp ing  some e lementary  programs tou t i l i ze  the  id ioms in  the  d ic t ionary .
Thesystem can retrieve idioms or usages which bearcertain similarities to the input phrases.
Forexample, when the user input a sentence such as'He wore a long face', the system retrieves theidiom 'pull \[make, wear\] a long face' which havethe highest similarity with the input.
In thisprocess, all of the words in the input are re-duced to their infinitive forms (in this case,'wore' is reduced to 'wear'), and all of theidioms and typical usages in the individual wordentries are retrieved for the comparison withthe input phrases.
The comparison is currentlyperformed as follows:i.
Each word in the retrieved idioms and usagesare reduced to their infinitive forms.2.
Literal string matching is performed.
In thematching process, extra words in the input andretrieved idioms or usages are ignored.
Onlythe oder of words is taken into consideration.3.
Similarity value is computed for each idiomsand usages.The expressions with the highest value are print-ed out.
In the current system, the similarityvalue is determined by a simple formula as\[the number of matched words\] / \[the numberof words in idioms or typicalusages\].Some results are shown in Fig.
12.
We shoulddevelop more sophisticated method of computingthe similarity value.
Especially, information~540- -F ILL  IN  THE FORM~ , input /spel lf i 1 1 i n t he  f o r m~'~ \[ ~ ~i :~.~-~ ~ .L Japanese translat ion: ~ input  str ingHE t4EA RED A LONG F AC E.J~p u l l \ [ w e a r \ ]  a 1 o n g f a c e~-- Japanese translat ion2 7B M 8E  C US ED .Fig.
12 Retr ieval  Results of Similar Express ionsabout semantic re lat ionships among words shouldbe taken into considerat ion.
Computer ized thesau-ri wi l l  be useful.
Certa in words in idioms andusages play the role of variables.
'Oneself' insuch a id iom as 'be a law unto oneself '  is look-ed as a var iable and should be able to be match-ed with 'myself', 'himself' etc.
'person' in'take a person about a town' should be matchedwi th  any person such as John, he, and so on.
Inthe latter case, 'a town' can also be replacedby many other words that have certain semanticfeatures in common, for example, 'placehood'We are now designing such semant ica l ly  guidedpattern mat chings.file HEADWORDKEY HEADWORD IMPORT- pointer number POS-I -2 -3 -4 -5spell TANCE to ofCOMPOUND POS' sWORD11T2 I 21 2 I 2POS po in ter  po in ter  po in ter  to po in ter  po in ter  po in tercode to to JAPANESE to to toPRONUN- INFLEC- TRANSLATION USAGE \]DIOM EXPLA-CIATION TION NATIONNOTE: i) Numbers in boxes are numbers of CHARACTERs.
( 1 CHARACTER = 2 bytes)2) For example, 'pointer to JAPANESE TRANSLATION'stands for the pair illustrated below.file JAPANESE-TRANSLATIONKEYpo inter  tothe first number ofrecord of JAPANESEJAPANESE TRANSLATIONsTRANSLATIONFig.
13Japanese- otherTranslation informationstextExamples of Formatted Records3-3.
Data Structure for Engl ish- JapaneseDict ionary Data BaseThe formats of records which are obtained as theresult of data t rans lat ion are shown in Fig.
13.The records in these formats contain a largeamount of extra spaces, because they are f ixedin length and, on the other hand, the length ofthe descr ipt ions in the d ict ionary var ies verymuch, depending on indiv idual  words.
The neces-sary memory size for these records amounts to150 Mbyte.
We have reorganized them for thepurpose of reducing the memory size.
The actualdata organizat ion is shown in Fig.
14, in whichthe required memory size is 35 Mbyte.
Al l  k indsof text data of var iable length are mainta inedin the same place (the Text Data File) in thisorganizat ion.higher-level files (EX.
HEADWORD, POS, etc.)
\[~ointer/Tlolx: cot4" : pointers to : higher-level files KEY @TEXT l#11 #2 ITAG IY/~//~ N @TEXT: pointer to the first .... rdof text: #1,#2: number of UNITs occupied torepresent the textText Data File NOTE: TAG indicates what type ofinformation (EX.
idiom, usage.pronunciation, etc.)
is storedin the corresponding text record.Fig.
14 Data Structure ofEng l i sh -  Japanese Dict ionaryThe informat ion which is necessary for managingthe records in the Text Data File is containedin a TCR.
A TCR consists of a pointer  to thecorresponding text record, the number of occupiedtext data records, a tag f ield etc.
The tagfield indicates what kind of text data are storedin the record.
Arb i t rary numbers of text datacan be l inked together.
The memory ef f ic iencyof this data structure is obvious.
And, theaverage time for retr iev ing and displaying theresult  on the screen is 320 msec .
About half  ofthe time is spent on the display control  (about120 msec~v l60  msec, depending on the data size).To access a head word record from its spel l ingrequires only 3 msec.
The remainder is spent onretr iev ing the other records such as pronuncia-tion, P.O.S.
idioms etc.- -541- -4.
Concludin S RemarksAll the systems described in this paper have beenimplemented on FACOM M-200 (Kyoto UniversityComputing Center) mostly by PL/I.
Because thecomputing center has introduced an MSS (MassStorage System) and will begin the service thissummer, these systems are to he maintained on it.Several other groups in our university, especial-ly a research group of the Faculty of Literature,are very interested in utilizing the dictionarysystems for their own researches.
Up to now, aset of utility programs have been developed.
Wehope that such a joint effort between computerscientists and linguists will lead us to new,fruitful research areas.AcknowledsementWe would like to thank the other members of Prof.Nagao's laboratory, and in particular, Mr. Yuki-nori YAMAMOTO for his efforts of implementingthe first version of DTV and for his valuablesuggestions for the data organization of Japanesedictionary data base.References(I) Fry,J.P., Frank, R.L.
et.al.
: A Developmen-al Model for Data Translation, ACM SIGFIDETWorkshop on Data Description and Access,1972(2) Fry, J.P., Smith, D.P.
et.al.
: An Approachto Stored Data Definition and Translation,ACM SIGFIDET Workshop on Data Descriptionand Access, 1972(3) Michiels, A., Moulin, A., Mullenders, J.,Noel, J. : Exploiting the Longman ComputerFiles for MT Lexicography and other Purposes,Technical Report, University of Liege,Belgium(4) Michiels, A., Moulin, A., Noel, J. : Work-ing with LDOCE, Technical Report, Universityof Liege, Belgium(5) Liu, S., Heller, J. : A Record Oriented,Grammar Driven Data Translation Model, ACMSIGFIDET Workshop on Data Description, Accessand Control, 1974(6) Nagao, M., Tsujii, J.:Data Structure of aLarge Japanese Dictionary and MorphologicalAnalysis by Using It, Journal of InformationProcessing Society of Japan, Vol.
19, No.
6,in Japanese(7) Nagao.
M., Tsujii, J., et.al.
: A MachineTranslation System from Japanese into Eng-lish, to be included in Proc.
of thisconference, 1980(8) Ueda, Y. : A Study for English-Japanese Dic-tionary Data Base, BS Thesis, Kyoto Univer-sity, 1980, in Japanese--542--
