Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 636?644,Los Angeles, California, June 2010. c?2010 Association for Computational LinguisticsCan Recognising Multiword Expressions Improve Shallow Parsing?Ioannis Korkontzelos, Suresh ManandharDepartment of Computer ScienceThe University of YorkHeslington, York, YO10 5NG, UK{johnkork, suresh}@cs.york.ac.ukAbstractThere is significant evidence in the literaturethat integrating knowledge about multiwordexpressions can improve shallow parsing ac-curacy.
We present an experimental study toquantify this improvement, focusing on com-pound nominals, proper names and adjective-noun constructions.
The evaluation set ofmultiword expressions is derived from Word-Net and the textual data are downloaded fromthe web.
We use a classification method toaid human annotation of output parses.
Thismethod allows us to conduct experiments ona large dataset of unannotated data.
Experi-ments show that knowledge about multiwordexpressions leads to an increase of between7.5% and 9.5% in accuracy of shallow pars-ing in sentences containing these multiwordexpressions.1 IntroductionMultiword expressions are sequences of words thattend to co-occur more frequently than chance andare characterised by various levels of idiosyncracy(Baldwin et al, 2003; Baldwin, 2006).
There is ex-tended literature on various issues relevant to mul-tiword expression; recognition, classification, lexi-cography, etc.
(see Section 6).
The vast majority ofthese publications identifies as motivation for mul-tiword expression research its potential contributionto deep or shallow parsing.
On the other side of thisissue, the state-of-the-art parsing systems seem toignore the fact that treating multiword expressionsas syntactic units would potentially increase parser?saccuracy.In this paper, we present an experimental studyattempting to estimate the contribution of integrat-ing multiword expressions into shallow parsing.
Wefocus on multiword expressions that consist of twosuccessive tokens; in particular, compound nominalsproper names and adjective-noun constructions.
Wealso present a detailed classification method to aidhuman annotation during the procedure of decidingif a parse is correct or wrong.
We present experi-mental results about the different classes of changesthat occur in the parser output while unifying multi-word expression components.We conclude that treating known multiwords ex-pressions as singletons leads to an increase of be-tween 7.5% and 9.5% in accuracy of shallow pars-ing of sentences containing these multiword expres-sions.
Increase percentages are higher for multiwordexpressions that consist of an adjective followed bya noun (12% to 15%); and even higher for non-compositional multiword expressions1 that consistof an adjective and a noun (15.5% to 19.5%).The rest of the paper is structured as follows: InSection 2 we present how multiword expressions canbe annotated in text and used by a shallow parser.
InSection 3 we present an overview of our experimen-tal process.
Section 4 explains how the set of targetmultiword expressions and textual corpora were cre-ated.
In Section 5 we present and discuss the resultsof the experimental process.
In Section 6 we presentparts of the related literature.
Section 7 concludesthe paper and proposes some future work.1Compositionality is defined as the degree to which themeaning of a multiword expression can be predicted by com-bining the meanings of its components (Nunberg et al, 1994).6362 Annotating Multiword expressionsIn this paper, we present a study to inspect the ex-tent to which knowledge of multiword expressionsimproves shallow parsing.
Our approach focuseson English multiword expressions that appear as se-quences in text.
In particular, we focus on com-pound nominals (e.g.
lemon tree), proper names(e.g.
prince Albert) and adjective-noun construc-tions (e.g.
red carpet).Shallow or deep parsing should treat multiwordexpression as units that cannot be divided in anyway.
We replace the multiword expression tokenswith a special made up token, i.e.
the multiword ex-pression constituents joined with an underscore.
Forexample, we replace all occurrences of ?lemon tree?with ?lemon tree?.We choose to replace the multiword expressionwords with a token that does not exist in the dictio-nary of the part of speech tagger.
This is quite animportant decision.
Usually, a part of sheech taggerassigns to an unknown words the part of speech thatbest fits to it with respect to the parts of speech ofthe words around it and the training data.
This is adesirable behaviour for our purposes.The experimental results of our study quantify thedifference between the shallow parser output of a bignumber of sentences after the replacement and theshallow parser output of the same sentences beforethe replacement.
The comparison is done ignoringchanges of parts of speech, assigned by the part ofspeech tagger.3 EvaluationThe target of our experiment is to evaluate whetherreplacing the multiword expression tokens with asingle token, unknown to the part of speech tagger,improves shallow parsing accuracy.
The ideal wayto perform this evaluation would be to use a cor-pus with manual annotation about parsing and mul-tiword expressions.
Given this corpus we would beable to measure the accuracy of a shallow (or deep)parser before and after replacing multiword expres-sions.
However, to the best of our knowledge thereis no corpus available to include this type of annota-tions in English.Instead, there are two options: Firstly, we canuse treebank data, where manual parsing annotationFigure 1: Evaluation processis readily available, and manually annotate multi-word expressions.
The advantage of this approachis that results are directly comparable with other re-sults of the literature, due to the use of benchmarkdata.
Manual annotation of multiword expressionsis a very time- and effort-consuming process due tothe large size of most treebanks.
Alternatively, mul-tiword expression annotation could be done using amethod of recognition.
Annotating the multiwordexpressions that appear in WordNet could be a safedecision, in terms of correctness, however, WordNetis reported to have limited coverage of multiwordexpressions (Baldwin, 2006; Laporte and Voyatzi,2008).
WordNet covers only 9.1 % and 16.1 % of thedatasets of Nicholson and Baldwin (2008) (484 nouncompounds) and Kim and Baldwin (2008) (2169noun compounds), respectively.Secondly, we can use a set of multiword expres-sions as a starting point and then create corpora thatcontain instances of these multiword expressions.
Insuccession, these sentences need to be manually an-notated in terms of parsing, and this requires hugehuman effort.
Alternatively, we can parse the cor-pora before and after replacing the multiword ex-pression and then compare the parser output.
Thisis the evaluation procedure that we chose to follow,and is shown in Figure 1.The above procedure is only able to retrieve in-stances where the replacement of the multiword ex-pression leads to a different parsing, a different allo-cation of tokens to phrases.
It is not able to spot in-stances where the parser output remains unchangedafter the replacement, no matter if they are correct.Since we are interested in measuring if replacing637Example A - Replacement causes no changeBefore: [NP they] [VP jumped] [PP over] [NP abonfire] and [VP rolled] [NP a fire wheel] .After: [NP they] [VP jumped] [PP over] [NP abonfire] and [VP rolled] [NP a fire wheel] .Example B - Replacement corrects an errorBefore: [NP the blades] [VP ignited] and [NP he][VP threw] [NP the fire] wheel up[PP into] [NP the air] .After: [NP the blades] [VP ignited] and [NP he][VP threw] [NP the fire wheel] [PRT up][PP into] [NP the air] .Table 1: 2 shallow parsing examples.
Multiword expres-sion: ?fire wheel?multiword expressions with a single token improvesparsing accuracy, we are not interested in instancesthat remain unchanged.
We focus on instances thatchanged; either they were corrected or they weremade wrong or they remain erroneous.
For example,the shallow parser output for example A in Table 1did not change after the replacement.
Example B inTable 1 shows a sentence which was corrected afterthe replacement.Instead of manually annotating the sentenceswhose parser output changed after the replacementas corrected or not, we identify a number of changeclasses under which we classify all these sentences.In the following section, we present the changeclasses.
For each we thoroughly discuss whetherits form guarantees that its sentences are wronglyparsed before the change and correctly parsed afterthe change.
In this case, the sentences of the corre-sponding class should be counted as false positives.We also discuss the opposite; if the form of eachchange class guarantees that its sentences are cor-rectly parsed before the change and wrongly parsedafter the change.
In this case, the sentences of thecorresponding class should be counted as true nega-tives.
For this discussion we hypothesize that amongthe possible output shallow parses for a given sen-tence the correct one has (a) the smallest numberphrases, and (b) the smallest number of tokens notassigned to any phrase.3.1 Shallow parsing change classesIn this section, we present a classification of caseswhere the shallow parser output of the sentence isFigure 2: Change classes (following the notation of Bille(2005)).
Triangles denote phrases and uppercase bold let-ters V...Z denote phrase labels.
Lowercase letters k...ndenote parsing leaves.
For change classes P2LMw andL2PMw, X includes the multiword expression tokens.For change classes P2L and L2P it does not.
For changeclass MwA, the multiword expression tokens are not as-signed to the same phrase Y or Z.different from the parser output of the same sen-tence after replacing the multiword expression witha single token.
The secondary focus of this discus-sion is to estimate whether the specific form of eachchange class can lead to a safe conclusion about ifthe parser output of the sentence under discussion:(a) was wrong before the replacement and was thencorrected, (b) was correct before the replacementand was then made wrong, or (c) was wrong beforethe replacement and remained wrong.
For this dis-cussion, we refer to words that are not assigned toany phase in the shallow parser output as ?leaves?.Hypothesis: We base our analysis on the hypoth-esis that among the possible output shallow parsesfor a given sentence the correct one has (a) the small-est number phrases, and (b) the smallest number ofleaves.
The theoretical intuitions behind the hypoth-esis are: (a) parse trees with just leaves are par-tial parse trees and hence should not be preferredover complete parse trees.
(b) when mistaken parse638trees are generally larger (with more phrases).
Wechecked the hypothesis by manually annotating 80randomly chosen instances; 10 for each change classthat is counted as correct or wrong (see Table 2).
74instances validated the hypothesis (92.5%).Table 2 shows one example for each change class.Figure 2 presents the classes as transformations be-tween trees, following the notation of Bille (2005).Change class P2LMw (Phrase to Leaves includ-ing the Multiword expression) Before replacing themultiword expression sequence with a single to-ken, the multiword expression is assigned to somephrase, possibly together with other words.
Afterthe replacement, the components of that phrase arenot assigned to any phrase, but instead as leaves.Change class P2L (Phrase to Leaves excludingthe multiword expression) Similarly to change classP2LMw, before the replacement, some successivetokens excluding the multiword expression itself areassigned to some phrase.
After the replacement, thecomponents of that phrase appear as leaves.Change class L2PMw (Leaves to Phrase includ-ing the Multiword expression) The changes coveredby this class are the opposite changes of change classP2LMw.
Before the replacing the multiword expres-sion sequence with a single token, the multiword ex-pression sequence is not assign to any phrase possi-bly among other words.
After the replacement, themultiword expression is assigned to a phrase.Change class L2P (Leaves to Phrase excludingthe multiword expression) Similarly to change classL2PMw, before the replacement, one or more suc-cessive tokens excluding the multiword expressionitself appear as leaves.
After the replacement, thesetokens are assigned to a phrase.Change class PL2P (Phrases or Leaves to Phrase)After the replacement, the tokens of more than onephrases or leaves are assigned to a single phrase.Change class P2PL (Phrase to Phrases or Leaves)In contrast to change class PL2P, after the replace-ment, the tokens of one phrase either are assigned tomore than one phrases or appear as leaves.Change class PN (Phrase label Name) After re-placing the multiword expression sequence with asingle token, one phrase appears with a differentphrase label, although it retains exactly the samecomponent tokens.Change class PoS (Part of Speech) After replac-ing the multiword expression sequence with a singletoken, one or more tokens appears with a differentpart of speech.
This class of changes comes from thepart of speech tagger, and are out of the scope of thisstudy.
Thus, in the results section we show a size es-timate of this class, and then we present results aboutchange classes, ignoring change class PoS.Change class P2P (Phrases to less Phrases) Afterreplacing the multiword expression sequence with asingle token, the component tokens of more than onesuccessive phrases?
are assigned to a different set ofsuccessive phrases ?.
However, it is always the casethat phrases ?
are less than phrases ?
(|?| < |?|).Change class MwA (Multiword expressionAllocation) Before replacing the multiword ex-pression sequence, the multiword expressionconstituents are assigned to different phrases.The instances of change classes where the parseroutput after the replacement has more parsing leavesor phrases than before are counted towards sen-tences that were parsed wrongly after the replace-ment.
For these classes, change classes P2LMw,P2L and P2PL, most probably the parser output afterthe replacement is wrong.In contrast, the instances of change classes wherea sequence of tokens is assigned to a phrase, or manyphrases are merged are counted towards sentencesthat were parsed wrongly before the replacementand correctly after the replacement.
These changes,that are described by classes L2PMw, L2P, PL2Pand P2P, most probably describe improvements inshallow parsing.
The instances of change class MwAare counted as correct after the replacement becauseby definition all tokens of a multiword expressionare expected to be assigned to the same phrase.The instances of change class PN can be eithercorrect or wrong after the replacement.
For this rea-son, we present our results as ranges (see Table 4).The minimum value is computed when the instancesof class PN are counted as wrong after the replace-ment.
In contrast, the maximum value is computedwhen the instances of this class are counted as cor-rect after the replacement.3.2 Shallow parsing complex change classesDuring the inspection of instances where the shal-low parser output before the replacement is dif-639P2LMw B [NP the(DT) action(NN) officer(NN)] [NP logistic(JJ) course(NN)] [VP is(VBZ) designed(VBN) ] 7[VP to(TO) educate(VB) ] and(CC) [VP train(VB)] [NP military(JJ) personnel(NNS)] ...A the(DT) action officer(NN) [NP logistic(JJ) course(NN)] [VP is(VBZ) designed(VBN)][VP to(TO) educate(VB) ] and(CC) [VP train(VB)] [NP military(JJ) personnel(NNS)] ...P2L B ... [NP the(DT) action(NN) officer(NN)] [PP in(IN)] [NP armenia(NN)] [VP signed(VBN)] ... 7A ... [NP the(DT) action officer(NN)] in(IN) [NP armenia(NN) ] [VP signed(VBN) ] ...L2PMw B ?(?)
affirmative(JJ) action(NN) officer(NN) ?(?)
[NP aao(NN)] [VP refers(VBZ)] [PP to(TO)]X[NP the(DT) regional(JJ) affirmative(JJ) action(NN) officer(NN)] or(CC) [NP director(NN)] ...A ?(?)
[NP affirmative(JJ) action officer(NN)] ?(?)
[NP aao(NN)] [VP refers(VBZ)] [PP to(TO)][NP the(DT) regional(JJ) affirmative(JJ) action officer(NN)] or(CC) [NP director(NN)] ...L2P B [NP the(DT) action(NN) officer(NN) ] usually(RB) [VP delivers(VBZ)] ... XA [NP the(DT) action officer(NN) ] [ADVP usually(RB)] [VP delivers(VBZ)] ...PL2PB ... [VP to(TO) immediately(RB) report(VB)] [NP the(DT) incident(NN)] [PP to(TO)] [NP the(DT)Xequal(JJ) opportunity(NN)] and(CC) [NP affirmative(JJ) action(NN) officer(NN)] .(.
)A ... [VP to(TO) immediately(RB) report(VB)] [NP the(DT) incident(NN)] [PP to(TO)] [NP the(DT)equal(JJ) opportunity(NN) and(CC) affirmative(JJ) action officer(NN)] .(.
)P2PL B ... [NP action(NN) officer(NN)] [VP shall(MD) prepare(VB) and(CC) transmit(VB)] ...7A ... [NP action officer(NN)] [VP shall(MD) prepare(VB)] and(CC) [VP transmit(VB)] ...PN B ... [NP an(DT) action(NN) officer(NN)] [SBAR for(IN)] [NP communications(NNS)] ... ?A ... [NP an(DT) action officer(NN)] [PP for(IN)] [NP communications(NNS)] ...PoS B ... [NP security(NN) officer(NN)] or(CC) ?(?)
[NP youth(JJ) action(NN) officer(NN) ] .(.)
?(?
)?A ... [NP security(NN) officer(NN)] or(CC) ?(?)
[NP youth(NN) action officer(NN)] .(.)
?(?
)P2PB ... ,(,) [PP as(IN)] [NP a(DT) past(JJ) action(NN) officer(NN)] and(CC) command(NN) and(CC)Xcontrol(NN) and(CC) [NP intelligence(NN) communications(NNS) inspector(NN)] ...A ... ,(,) [PP as(IN)] [NP a(DT) past(JJ) action officer(NN) and(CC) command(NN) and(CC)(control(NN) ] and(CC) [NP intelligence(NN) communications(NNS) inspector(NN)] ...MwA B the(DT) campus(NN) affirmative(JJ) action(NN) [NP officer(NN)] [VP serves(VBZ)] ...XA [NP the(DT) campus(NN) affirmative(JJ) action officer(NN)] [VP serves(VBZ)]...Table 2: Examples for change classes.
Multiword expression: ?action officer?.
Parts of speech appear within paren-theses.
?B?
stands for ?before?
and ?A?
for ?after?
(multiword expression replacement).
Xor 7 denote change classesthat count positively or negatively towards improving shallow parsing.
?
denotes classes that are treated specially.ferent from the shallow parser output after the re-placement, we came across a number of instancesthat were classified in more than one class of theprevious subsection.
In other words, two or moreclasses of change happened.
For example, in a num-ber of instances, before the replacement, the multi-word expression constituents are assigned to differ-ent phrases (change class MwA).
After the replace-ment, the tokens of more than one phrases are as-signed to a single phrase (change class PL2P).
Theseinstances consist new complex change classes andare named as the sum of names of the participatingclasses.
The instances of the example above consistthe complex change class PL2P+MwA.4 Target multiword expressions andcorpora collectionWe created our set of target multiword expres-sions using WordNet 3.0 (Miller, 1995).
Out of its52, 217 multiword expressions we randomly chose120.
Keeping the ones that consist of two tokensresulted in the 118 expressions of Table 3.
Manu-ally inspecting these multiword expressions provedthat they are all compound nominals, proper namesor adjective-noun constructions.
Each multiwordexpression was manually tagged as compositionalor non-compositional, following the procedure de-scribed in Korkontzelos and Manandhar (2009).
Ta-ble 3 shows the chosen multiword expressions to-gether with information about their compositionalityand the parts of speech of their components.640Compositional Multiword expressions (Noun - Noun sequences)action officer (3119) bile duct (21649) cartridge brass (479) field mushroom (789) fire wheel (480)key word (3131) king snake (2002) labor camp (3275) life form (5301) oyster bed (1728)pack rat (3443) palm reading (4428) paper chase (1115) paper gold (1297) paper tiger (1694)picture palace (2231) pill pusher (924) pine knot (1026) potato bean (265) powder monkey (1438)prison guard (4801) rat race (2556) road agent (1281) sea lion (9113) spin doctor (1267)tea table (62) telephone service (9771) upland cotton (3235) vegetable sponge (806) winter sweet (460)Non-Compositional Multiword expressions (Noun - Noun sequences)agony aunt (751) air conditioner (24202) band aid (773) beach towel (1937) car battery (3726)checker board (1280) corn whiskey (1862) corner kick (2882) cream sauce (1569) fire brigade (5005)fish finger (1423) flight simulator (5955) honey cake (843) jazz band (6845) jet plane (1466)laser beam (16716) lemon tree (3805) lip service (3388) love letter (3265) luggage van (964)memory device (4230) monkey puzzle (1780) motor pool (3184) power cord (5553) prince Albert (2019)sausage pizza (598) savoy cabbage (1320) surface fire (2607) torrey tree (10) touch screen (9654)water snake (2649) water tank (5158) wood aster (456)Compositional Multiword expressions (Adjective - Noun sequences)basic color (2453) cardiac muscle (6472) closed chain (1422) common iguana (668) cubic meter (4746)eastern pipistrel (128) graphic designer (8228) hard candy (2357) ill health (2055) kinetic theory (2934)male parent (1729) medical report (3178) musical harmony (1109) mythical monster (770) red fox (10587)relational adjective (279) parking brake (7199) petit juror (991) taxonomic category (1277) thick skin (1338)toxic waste (7220) universal donor (1454) parenthesis-free notation (113)Non-Compositional Multiword expressions (Adjective - Noun sequences)black maria (930) dead end (5256) dutch oven (4582) golden trumpet (607) green light (5960)high jump (4455) holding pattern (3622) joint chiefs (2865) living rock (985) magnetic head (2457)missing link (5314) personal equation (873) personal magnetism (2869) petit four (1506) pink lady (1707)pink shower (351) poor devil (1594) public eye (3231) quick time (2323) red devil (2043)red dwarf (6526) red tape (2024) round window (1380) silent butler (332) small beer (2302)small voice (4313) stocking stuffer (7486) sweet bay (1367) teddy boy (2413) think tank (4586)Table 3: 118 multiword expressions randomly chosen from WordNet.
The size of the respective corpus in sentencesappears within parentheses.For each multiword expression we created a dif-ferent corpus.
Each consists of webtext snippets oflength 15 to 200 tokens in which the multiword ex-pression appears.
Snippets were collected follow-ing Korkontzelos and Manandhar (2009).
Given amultiword expression, a set of queries is created:All synonyms of the multiword expression extractedfrom WordNet are collected2.
The multiword ex-pression is paired with each synonym to create a setof queries.
For each query, snippets are collectedby parsing the web-pages returned by Yahoo!.
Theunion of all snippets produces the multiword expres-sion corpus.In Table 3, the number of collected corpus sen-tences for each multiword expression are shownwithin parentheses.
GENIA tagger (Tsuruoka et al,2005) was used as part of speech tagger.
SNoW-based Shallow Parser (Munoz et al, 1999) was usedfor shallow parsing.2e.g.
for ?red carpet?, corpora are collected for ?red carpet?and ?carpet?.
The synonyms of ?red carpet?
are ?rug?, ?carpet?and ?carpeting?.5 Experimental results and discussionThe corpora collecting procedure of Section 4 re-sulted in a corpus of 376, 007 sentences, each onecontaining one or more multiword expressions.
In85, 527 sentences (22.75%), the shallow parser out-put before the replacement is different than the shal-low parser output after the replacement.
7.20% ofthese change instances are due to one or more partsof speech changes, and are classified to change classPoS.
In other words, in 7.20% of cases where thereis a difference between the shallow parses beforeand after replacing the multiword expression tokensthere is one or more tokens that were assigned a dif-ferent part of speech.
However, excluding parts ofspeech from the comparison, there is no other dif-ference between the two parses.The focus of this study is to quantify the effectof unifying multiword expressions in shallow pars-ing.
Part of speech tagging is a component of our ap-proach and parts of speech are not necessarily partsof the parser output.
For this reason, we chose toignore part of speech changes, the changes of classPoS.
Below, we discuss results for all other classes.641Multiword Shallow Parsingexpressions improvementclass PS sentences min.
max.On average - 376,007 7.47% 9.49%Comp.
N N 93,166 5.54% 7.19%Non-Comp.
N N 127,875 3.66% 4.44%Comp.
J N 68,707 7.34% 9.21%Non-Comp.
J N 86,259 15.32% 19.67%- N N 221,041 4.45% 5.60%J N 154,966 11.78% 15.03%Comp.
- 161,873 6.30% 8.05%Non-Comp.
- 214,134 8.36% 10.57%Table 4: Summary of results.
PS: parts of speech, Comp:compositional, N: noun, J: adjective, min.
: minimum,max.
: maximum.Table 4 shows a summary of our results.
The firsttwo columns describe classes of multiword expres-sion with respect to compositionality and the partsof speech of the component words.
The first line ac-counts for the average of all multiword expressions,the second one for compositional multiword expres-sions made of nouns, etc.
The third column showsthe number of corpus sentences of each class.For each one of the classes of Table 4, the fourthand fifth columns show the minimum and maxi-mum improvement in shallow parsing, respectively,caused by unifying multiword expression tokens.Let ?X?
be the function that returns the number ofinstances assigned to change class X .
With respectto the discussion of Subsection 3.1 about how the in-stances of each class should be counted towards thefinal results, the minimum and maximum improve-ments in shallow parsing are:min = ??P2LMw???P2L?+?L2PMw?+?L2P?++?PL2P???P2PL?+?PL2P+MwA?++?P2P?+?P2P+MwA???PN?
(1)max = ??P2LMw???P2L?+?L2PMw?+?L2P?++?PL2P???P2PL?+?PL2P+MwA?++?P2P?+?P2P+MwA?+?PN?
(2)On average of all multiword expressions, unify-ing multiword expression tokens contributes from7.47% to 9.49% in shallow parsing accuracy.
Itshould be noted that this improvement is reportedon sentences which contain at least one known mul-tiword expression.
To project this improvement onany general text, one needs to know the percentageof sentences that contain known multiword expres-Figure 3: Average change percentages per change class.sions.
Then the projected improvement can be com-puted by multiplying these two percentages.Table 4 shows that the increase in shallow pars-ing accuracy is lower for expressions that consist ofnouns than for those that consist of an adjective anda noun.
Moreover, the improvement is higher fornon-compositional expressions than compositionalones.
This is expected, due to the idiosyncratic na-ture of non-compositional multiword expressions.The highest improvement, 15.32% to 19.67%, oc-curs for non-compositional multiword expressionsthat consist of an adjective followed by a noun.Figure 3 shows the percentage of each class overthe sum of sentences whose parse before unify-ing multiword expression tokens is different for theparse after the replacement.
The most commonchange class is PL2P.
It contains sentences in theshallow parser output of which many phrases orleaves were all assigned to a single phrase.
34.03%of the changes are classified in this class.
The leastcommon classes are change classes P2L, L2PMwand L2P.
Each of these accounts for less than 3%of the overall changes.6 Related WorkThere have been proposed several ways to clas-sify multiword expressions according to variousproperties such as compositionality and institution-alisation3 (Moon, 1998; Sag et al, 2002; Bald-win, 2006).
There is a large variety of meth-ods in the literature that address recognising mul-tiword expressions or some subcategory.
Mc-Carthy (2006) divides multiword expression detect-3Institutionalisation is the degree that a multiword expres-sion is accepted as lexical item through consistent use over time.642ing methods into statistical (e.g.
pointwise mutualinformation (PMI)), translation-based, dictionary-based, substitution-based, and distributional.
Sta-tistical methods score multiword expression candi-dates based on co-occurrence counts (Manning andSchutze, 1999; Dunning, 1993; Lin, 1999; Frantzi etal., 2000).
Translation-based methods usually takeadvantage of alignment to discover potential multi-word expressions (Venkatapathy and Joshi, 2005).Other methods use dictionaries to reveal semanticrelationships between the components of potentialmultiword expressions and their context (Baldwinet al, 2003; Hashimoto et al, 2006).
Substitution-based methods decide for multiword expressionsby substituting their components with other similarwords and measuring their frequency of occurrence(Lin, 1999; Fazly and Stevenson, 2006).
These tech-niques can be enriched with selectional preferenceinformation (Van de Cruys and Moiro?n, 2007; Katzand Giesbrecht, 2006).
Fazly and Stevenson (2007)propose measures for institutionalisation, syntacticfixedness and compositionality based on the selec-tional preferences of verbs.
There are several studiesrelevant to detecting compositionality of noun-noun,verb-particle and light verb constructions and verb-noun pairs (e.g.
Katz and Giesbrecht (2006)).To the best of our knowledge there are no ap-proaches integrating multiword expression knowl-edge in deep or shallow parsing.
However, thereare several attempts to integrate other forms of lex-ical semantics into parsing.
Bikel (2000) mergedthe Brown portion of the Penn Treebank with Sem-Cor, and used it to evaluate a generative bilexicalmodel for joint word sense disambiguation and pars-ing.
Similarly, Agirre et al (Agirre et al, 2008)integrated semantic information in the form of se-mantic classes and observed significant improve-ment in parsing and PP attachment tasks.
Xiong etal.
(2005) integrated first-sense and hypernym fea-tures in a generative parse model applied to the Chi-nese Penn Treebank and achieved significant im-provement over their baseline model.
Fujita etal.
(2007) extended this work by implementing adiscriminative parse selection model, incorporatingword sense information and achieved great improve-ments as well.
Examples of integrating selectionalpreference information into parsing are Dowding etal.
(1994) and Hektoen (1997).7 Conlusion and future workIn this paper, we presented an experimental studyattempting to estimate the contribution of unify-ing multiword expression components into shallowparsing.
The evaluation is done based on 118 multi-word expressions extracted from WordNet 3.0.
Theyconsist of two successive components and are inparticular, compound nominals, proper names oradjective-noun constructions.Instead of using pre-annotated text, we collectedsentences that contain the above multiword expres-sions from the web.
We applied shallow parsing be-fore and after unifying multiword expression tokensand compared the outputs.
We presented a detailedclassification of changes in the shallow parser out-put to aid human annotation during the procedure ofdeciding if a parser output is correct or wrong.We presented experimental results about changeclasses and about the overall improvement of uni-fying multiword expression tokens with respect tocompositionality and the parts of speech of theircomponents.
We conclude that unifying the tokensof known multiwords expressions leads to an in-crease of between 7.5% and 9.5% in accuracy ofshallow parsing of sentences that contain these mul-tiword expressions.
Increase percentages are higheron adjective-noun constructions (12% to 15%); andeven higher on non-compositional adjective-nounconstructions (15.5% to 19.5%).Future work will focus in conducting similar ex-periments for multiword expressions longer thantwo words.
One would expect that due to theirsize, a wrong interpretation of their structure wouldaffect the shallow parser output more than it doesfor multiword expressions consisting of two words.Thus, unifying multiword expressions longer thantwo words would potentially contribute more toshallow parsing accuracy.Furthermore, the evaluation results presented inthis paper could be strengthened by adding man-ual multiword expression annotation to some tree-bank.
This would provide a way to avoid the changeclass analysis presented in Subsection 3.1 and com-pute statistics more accurately.
Finally, the results ofthis paper suggest that implementing a parser ableto recognise multiword expressions would be veryhelpful towards high accuracy parsing.643ReferencesE.
Agirre, T. Baldwin, and D. Martinez.
2008.
Improv-ing parsing and PP attachment performance with senseinformation.
In Proceedings of ACL, pages 317?325,USA.
ACL.T.
Baldwin, C. Bannard, T. Tanaka, and D. Widdows.2003.
An empirical model of multiword expressiondecomposability.
In proceedings of the ACL workshopon MWEs, pages 89?96, USA.
ACL.T.
Baldwin.
2006.
Compositionality and multiword ex-pressions: Six of one, half a dozen of the other?
Inproceedings of the ACL workshop on MWEs, Aus-tralia.
ACL.D.
Bikel.
2000.
A statistical model for parsing and word-sense disambiguation.
In proceedings of the 2000Joint SIGDAT conference: EMNLP/VLC, pages 155?163, USA.
ACL.P.
Bille.
2005.
A survey on tree edit distance and re-lated problems.
Theoretical Computer Science, 337(1-3):217?239.J.
Dowding, R. Moore, F. Andryt, and D. Moran.1994.
Interleaving syntax and semantics in an efficientbottom-up parser.
In proceedings of ACL, pages 110?116, USA.
ACL.T.
Dunning.
1993.
Accurate methods for the statistics ofsurprise and coincidence.
Computational Linguistics,19(1):61?74.A.
Fazly and S. Stevenson.
2006.
Automatically con-structing a lexicon of verb phrase idiomatic combina-tions.
In Proceedings of EACL, pages 337?344, Italy.A.
Fazly and S. Stevenson.
2007.
Distinguishing sub-types of multiword expressions using linguistically-motivated statistical measures.
In proceedings of theACL workshop on MWEs, pages 9?16, Czech Repub-lic.
ACL.K.
Frantzi, S. Ananiadou, and H. Mima.
2000.
Auto-matic recognition of multi-word terms: the c-value/nc-value method.
International Journal on Digital Li-braries, 3(2):115?130.S.
Fujita, F. Bond, S. Oepen, and T. Tanaka.
2007.
Ex-ploiting semantic information for hpsg parse selection.In proceedings of DeepLP, pages 25?32, USA.
ACL.C.
Hashimoto, S. Sato, and T. Utsuro.
2006.
Detectingjapanese idioms with a linguistically rich dictionary.Language Resources and Evaluation, 40(3):243?252.E.
Hektoen.
1997.
Probabilistic parse selection basedon semantic cooccurrences.
In proceedings of IWPT,pages 113?122, USA.G.
Katz and E. Giesbrecht.
2006.
Automatic identi-fication of non-compositional multi-word expressionsusing latent semantic analysis.
In proceedings of theACL workshop on MWEs, pages 12?19, Australia.ACL.S.
Kim and T. Baldwin.
2008.
Standardised evaluationof english noun compound interpretation.
In proceed-ings of the LREC workshop on MWEs, pages 39?42,Morocco.I.
Korkontzelos and S. Manandhar.
2009.
Detectingcompositionality in multi-word expressions.
In pro-ceedings of ACL-IJCNLP, Singapore.E.
Laporte and S. Voyatzi.
2008.
An Electronic Dictio-nary of French Multiword Adverbs.
In proceedings ofthe LREC workshop on MWEs, pages 31?34, Marocco.D.
Lin.
1999.
Automatic identification of non-compositional phrases.
In proceedings of ACL, pages317?324, USA.
ACL.C.
Manning and H. Schutze, 1999.
Foundations of Sta-tistical NLP, Collocations, chapter 5.
MIT Press.D.
McCarthy.
2006.
Automatic methods to detectthe compositionality of MWEs.
presentation slides.url: www.sunum.org/myfiles/B2/McCarthyCollocId-ioms06.ppt last accessed: 28/11/2009.G.
Miller.
1995.
Wordnet: a lexical database for english.Communications of the ACM, 38(11):39?41.R.
Moon.
1998.
Fixed Expressions and Idioms in En-glish.
A Corpus-based Approach.
Oxford: ClarendonPress.M.
Munoz, V. Punyakanok, D. Roth, and D. Zimak.1999.
A learning approach to shallow parsing.
In pro-ceedings of EMNLP/VLC, pages 168?178, USA.J.
Nicholson and T. Baldwin.
2008.
Interpreting com-pound nominalisations.
In proceedings of the LRECworkshop on MWEs, pages 43?45, Morocco.G.
Nunberg, T. Wasow, and I.
Sag.
1994.
Idioms.
Lan-guage, 70(3):491?539.I.
Sag, T. Baldwin, F. Bond, A. Copestake, andD.
Flickinger.
2002.
Multiword expressions: A painin the neck for nlp.
In proceedings of CICLing, pages1?15, Mexico.Y.
Tsuruoka, Y. Tateishi, J. Kim, T. Ohta, J. McNaught,S.
Ananiadou, and J. Tsujii.
2005.
Developing a ro-bust part-of-speech tagger for biomedical text.
Ad-vances in Informatics, pages 382?392.T.
Van de Cruys and B. Moiro?n.
2007.
Semantics-basedmultiword expression extraction.
In proceedings of theACL workshop on MWEs, pages 25?32, Czech Repub-lic.
ACL.S.
Venkatapathy and A. Joshi.
2005.
Measuring the rela-tive compositionality of verb-noun (V-N) collocationsby integrating features.
In proceedings of HLT, pages899?906, USA.
ACL.D.
Xiong, S. Li, Q. Liu, S. Lin, and Y. Qian.
2005.
Pars-ing the penn chinese treebank with semantic knowl-edge.
In proceedings of IJCNLP, pages 70?81, Korea.644
