KNOWLEDGE REPRESENTATION FOR COMMONSENSE REASONINGWITH TEXTKathleen DahlgrenJoyce McDowellIBM Los Angeles Scientific CenterEdward P. Stabler, Jr .
lUniversity of Western Ontario1 INTRODUCTION1.1 NAIVE SEMANTICSThe reader of a text actively constructs a rich picture ofthe objects, events, and situation described.
The text isa vague, insufficient, and ambiguous indicator of theworld that the writer intends to depict.
The readerdraws upon world knowledge to disambiguate and clar-ify the text, selecting the most plausible interpretationfrom among the (infinitely) many possible ones.
Inprinciple, any world knowledge whatsoever in the read-er's mind can affect the choice of an interpretation.
Isthere a level of knowledge that is general and commonto many speakers of a natural anguage?
Can this levelbe the basis of an explanation of text interpretation?Can it be identified in a principled, projectable way?Can this level be represented for use in computationaltext understanding?
We claim that there is such a level,called naive semantics (NS), which is commonsenseknowledge associated with words.
Naive semanticsidentifies words with concepts, which vary in type.Nominal concepts are categorizations of objects basedupon naive theories concerning the nature and typicaldescription of conceptualized objects.
Verbal conceptsare naive theories of the implications of conceptualizedevents and states.
2 Concepts are considered naive be-cause they are not always objectively true, and bearonly a distant relation to scientific theories.
An informalexample of a naive nominal concept is the followingdescription of the typical lawyer.1.
If someone is a lawyer, typically they are male orfemale, well-dressed, use paper, books, and brief-cases in their job, have a high income and highstatus.
They are well-educated, clever, articulate,and knowledgeable, as well as contentious, ag-gressive, and ambitious.
Inherently lawyers areadults, have gone to law school, and have passedthe bar.
They practice law, argue cases, adviseclients, and represent them in court.
Conversely,if someone has these features, he/she probably is alawyer.In the classical approach to word meaning, the aim is tofind a set of primitives that is much smaller than the setof words in a language and whose elements can beconjoined in representations that are truth-conditionallyadequate.
In such theories "bachelor" is represented asa conjunction of primitive predicates.2.
bachelor(X) ?~ adult(X) & human(X) &male(X) & unmarried(X)In such theories, a sentence such as (3) can be giventruth conditions based upon the meaning representationof "bachelor," plus rules of compositional semanticsthat map the sentence into a logical formula that assertsthat the individual denoted by "John" is in the set ofobjects denoted by "bachelor."3.
John is a bachelor.The sentence is true just in case all of the properties inthe meaning representation f "bachelor" (2) are true of"John."
This is essentially the approach in many com-putational knowledge representation schemes uch asKRYPTON (Brachman et al 1985), approaches follow-ing Schank (Schank and Abelson 1977), and linguisticsemantic theories such as Katz (1972) and Jackendoff(1985).Smith and Medin (1981), Dahlgren (1988a), Johnson-Laird (1983), and Lakoff (1987) argue in detail that all ofthese approaches are essentially similar in this way andall suffer from the same defects, which we summarizeCopyright 1989 by the Association for Computational Linguistics.
Permission to copy without fee all or part of this material is granted providedthat the copies are not made for direct commercial dvantage and the CL reference and this copyright notice are included on the first page.
Tocopy otherwise, or to republish, requires a fee and/or specific permission.0362-613X/89/010149-170503.00Computational Linguistics, Volume 15, Number 3, September 1989 149Kathleen Dahlgren, Joyce McDowell, and Edward P. Stabler, Jr.
Knowledge Representation for Commonsense Reasoning with Textbriefly here.
Word meanings are not scientific theoriesand do not provide criteria for membership in thecategories they name (Putnam 1975).
Concepts arevague, and the categories they name are sometimesvaguely defined (Labov 1973; Rosch et al 1976).
Mem-bership of objects in categories i gradient, while theclassical approach would predict hat all members harefull and equal status (Rosch and Mervis 1975).
Not allcategories can be decomposed into primitives (e.g.,color terms).
Exceptions to features in word meaningsare common (most birds fly, but not all) (Fahlman 1979).Some terms are not intended to be used truth-condition-ally (Dahlgren 1988a).
Word meanings hift in unpre-dictable ways based upon changes in the social andphysical environment (Dahlgren 1985b).
The classicaltheory also predicts that fundamentally new conceptsare impossible.NS sees lexical meanings as naive theories anddenies that meaning representations provide truth con-ditions for sentences in which they are used.
NS ac-counts for the success of natural language communica-tion, given the vagueness and inaccuracy of wordmeanings, by the fact that natural language is anchoredin the real world.
There are some real, stable classes ofobjects that nouns are used to refer to, and mentalrepresentations of their characteristics are close enoughto true, enough of the time, to make reference usingnouns possible (Boyd 1986).
Similarly, there are realclasses of events which verbs report, and mental repre-sentations of their implications are approximately true.The vagueness and inaccuracy of mental representa-tions requires non-monotonic reasoning in drawing in-ferences based upon them.
Anchoring is the mainexplanation of referential success, and the use of wordsfor imaginary objects is derivative and secondary.NS differs from approaches that employ exhaustivedecompositions into primitive concepts which are sup-posed to be true of all and only the members of the setdenoted by lawyer.
NS descriptions are seen as heuris-tics.
Features associated with a concept can be overrid-den or corrected by new information in specific cases(Reiter 1980).
NS accounts for the fact that whileEnglish speakers believe that an inherent function of alawyer is to practice law, they are also willing to be toldthat some lawyer does not practice law.
A non-prac-ticing lawyer is still a lawyer.
The goal in NS is not tofind the minimum set of primitives required to distin-guish concepts from each other, but rather, to representa portion of the naive theory that constitutes the cogni-tive concept associated with a word.
NS descriptionsinclude features found in alternative approaches, butmore as well.
The content of features is seen as essen-tially limitless and is drawn from psycholinguistic stud-ies of concepts.
Thus, in NS, featural descriptionsassociated with words have as values not primitives, butother words, as in Schubert et al (1979).In NS, the architecture of cognition that is assumedis one in which syntax, compositional semantics, andParserCompositkmalSemontTcaXwCompositional \[Augmentation of theDiscourseNaive InferenceFigure 1.
Components of Grammar in NS.naive semantics are separate components with uniquerepresentational forms and processing mechanisms.Figure l illustrates the components.
The autonomoussyntactic omponent draws upon naive semantic infor-mation for problems such as prepositional phrase at-tachment and word sense disambiguation.
Another au-tonomous component interprets the compositionalsemantics and builds discourse representation structures(DRSs) as in Kamp (1981) and Asher (1987).
Anothercomponent models naive semantics and completes thediscourse representation that includes the implicationsof the text.
All of these components operate in paralleland have access to each other's representations when-ever necessary.1.2 THE KT SYSTEMNaive semantics i the theoretical motivation for the KTsystem under development at the IBM Los AngelesScientiific Center by Dahlgren, McDowell, and others.
3The heart of the system is a commonsense knowledgebase with two components, a commonsense ontologyand databases of generic knowledge associated withlexical items.
The first phase of the project, which isnearly complete, is a text understanding and querysystem.
In this phase, text is read into the system andparsed by the MODL parser (McCord 1987), which hasvery wide coverage.
The parse is submitted to a module(DISAMBIG) that outputs a logical structure whichreflects the scope properties of operators and quantifi-ers, correct attachment of post-verbal adjuncts, andselects, word senses.
This is passed to a semantictranslator whose output (a DRS) is then converted tofirst-order logic (FOL).
We then have the text in twodifferent semantic forms (DRS and FOL), each of whichhas its advantages and each of which is utilized in thesystem in different ways.
Queries are handled in thesame way as text.
Answers to the queries are obtainedeither by matching to the FOL textual database or to thecommonsense databases.
However, the commonsenseknowledge is accessed at many other stages in theprocessing of text and queries, namely in parse disam-biguafion, in lexical retrieval, anaphora resolution, andin the construction of the discourse structure of theentire text.150 Computational Linguistics, Volume 15, Number 3, September 1989Kathleen Dahlgren, Joyce McDowell, and Edward P. Stabler ,  J r .
Knowledge Representation for Commonsense Reasoning with TextThe second phase of the project, which is at presentin the research stage, will be to use the commonsenseknowledge representations and the textual database toguide text selection.
We anticipate a system, NewSe-lector, which, given a set of user profiles, will distributetextual material in accordance with user interests, thus,in effect, acting as an automatic lipping service.
Ourtarget ext is the Wall Street Journal.
The inferencingcapabilities provided by the commonsense knowledgewill allow us to go well beyond simple keyword search.The theoretical underpinnings and practical work onthe KT system have been reported extensively else-where, in conference papers (Dahlgren and McDowell1986a, 1986b; McDowell and Dahlgren 1987) and in abook (Dahlgren 1988a).
Since the publication of thoseworks, a number of significant additions and modifica-tions have been made to the system.
The intended focusof this paper is this new work.
However, in order tomake this accessible to readers unfamiliar with ourprevious reports, we present in Section 2 an overview ofthe components of the present system.
(Readers famil-iar with our system can skip Section 2).
In the remainingsections on new work we have emphasized implemen-tation, because this paper is addressed to the computa-tional inguistics community: in Section 3, the details ofdisambiguation procedures that use the NS representa-tions and in Section 4 the details of the query system.Finally, Section 5 discusses work in progress regardingdiscourse and naive semantics.2 OVERVIEW or  THE KT  SYSTEM2.1 KNOWLEDGE REPRESENTATION2.1.1 THE ONTOLOGYNaive theories associated with words include beliefsconcerning the structure of the actual world and thesignificant "joints" in that structure.
People have theenvironment classified, and the classification scheme ofa culture is reflected in its language.
Since naive seman-tics is intended as a cognitive model, we constructed thenaive semantic ontology empirically, rather than intu-itix;ely.
We studied the behavior of hundreds of verbsand determined selectional restrictions, which are con-straints reflecting the naive ontology embodied in En-glish.
We also took into account psychological studiesof classification (Keil 1979), and philosophical studies ofepistemology (Strawson 1953).2.1.1.1 MATHEMATICAL PROPERTIES OF THE ONTOLOGYThe ontology has several properties which distinguish itfrom classical taxonomies.
It is a directed acyclic graph,rather than a binary tree, because many concepts havemore than two subordinate concepts (Rosch et al 1976).FISH, BIRD, MAMMAL, and so on, are subordinatesof VERTEBRATE.
It is a directed graph rather than atree, because it handles cross-classification.
Cross-clas-sification is justified by contrasts between individualand collective nouns such as "cow" and "herd."
ThisENTITYABSTRACTNUMERICALREALPHYS ICAL  --*NON-STAT IONARY --*COLLECT IVE  --*TEMPORAL --->RELAT IONAL --~EVENT --*Table 1.
(ABSTRACT v REAL)  & ( INDIV IDUAL vCOLLECT IVE)IDEAL  v PROPOSIT IONAL vNUMERICAL  v IRREALNUMBER v MEASURE(PHYS ICAL  v TEMPORAL v SENTIENT)& (NATURAL v SOCIAL)(STAT IONARY v NONSTATIONARY)  &(L IV ING v NONLIV ING)(SELFMOVING v NONSELFMOVING)MASS v SET v STRUCTURERELAT IONAL v NONRELAT IONAL(EVENT v STATIVE)  & (MENTAL vEMOTIONAL v NONMENTAL)(GOAL v NONGOAL)  & (ACTIVITY vACCOMPL ISHMENT v ACHIEVEMENT)The Ontological Schemaimplies that cognitively there are essentially parallelontological schemas for individuals and collectives.Thus we have the parallel ontology fragments in Figure2.
Table 2 illustrates cross-classification at the root ofthe ontology, where ENTITY cross-classifies a eitherREAL or ABSTRACT, and as either INDIVIDUAL orCOLLECTIVE.
Cross-classification is handled as inMcCord (1985, 1987).INDIVIDUAL COLLECTIVEENTITY ENTITYABSTRACT REAL ABSTRACT REAL/ /P~SICAL, N~U RAI_, SE ~M~ING PH~IC~,~TURAL,SE~VING/ /ANIMAL FAUNA / /COW HERDFigure 2.
Parallel Portions of the Ontology.INDIVIDUAL COLLECTIVEREAL cow herdABSTRACT idea bookTable 2.
Entity Node Cross ClassificationMultiple attachments of instantiations to leaves ispossible.
For example, an entity, John, is both a HU-MAN with the physical properties of a MAMMAL, andis also a PERSON, a SENTIENT.
As a SENTIENT,John can be the subject of mental verbs such as thinkand say.
Institutions are also SENTIENTs, so that theSENTIENT node reflects English usage in pairs like (4).4.
John sued Levine.
The government sued Levine.Computational Linguistics, Volume 15, Number 3, September 1989 151Kathleen Dahlgren, Joyce McDowell, and Edward P. Stabler, Jr.
Knowledge Representation for Commonsense Reasoning with TextOn the other hand, John, as a HUMAN, is like animals,and has physical properties.
Both John and a cow canfigure as subjects of verbs like "eat" and "weigh.
"Multiple attachment was justified by an examination ofthe texts.
It was found that references to human beingsin text, for example, deal with them either as persons(SENTIENTs) or as ANIMALs (physiological beings),but rarely as both at the same time.2.1.1.2 ONTOLOGICAL CATEGORIESThe INDIVIDUAL/COLLECTIVE cut was made atthe level of ENTITY (the highest level) because alltypes of entities are conceived individually or in collec-tions.
COLLECTIVE breaks into sets of identical mem-bers (herd, mob, crowd, fleet), masses that are con-ceived as stuff (sand, water), and structures where themembers have specified relations, such as in institutions(school, company, village).
Leaf node names, such asANIMAL and FAUNA, are shorthand for collections ofcategories inherited from dominating nodes and bycross-classification.
Thus "cow" and "herd" share allcategories except hat "cow" is an INDIVIDUAL termand "herd" is a COLLECTIVE term.The REAL node breaks into the categories PHYSI-CAL, TEMPORAL, and SENTIENT, and also NAT-URAL and SOCIAL.
Entities (or events) that come intobeing (or take place) naturally must be distinguishedfrom those that arise through some sort of social inter-vention.
Table 3 illustrates the assignment of examplewords under the REAL cross-classification.INDIVIDUAL COLLECTIVENATURAL SOCIAL NATURAL SOCIALPHYSICAL rock knife sand fleetSENTIENT man programmer mob clinicTEMPORAL earthquake party winter epochTable 3.
Attachment ofNouns under REALThe SENTIENT/PHYSICAL distinction is placed highbecause in commonsense r asoning, the properties ofpeople and things are very different.
Verbs select forSENTIENT arguments or PHYSICAL arguments, asillustrated in (5).
Notice also, that as a physical object,an individual entity like John can be the subject both ofverbs that require physical subjects and those thatrequire SENTIENT subjects, as in (6).5.
The lawyer/the grand jury indicted Levine.
*The cow indicted Levine.6.
John fell.John sued Levine.The cow fell.We make the SENTIENT/NON-SENTIENT distinc-tion high up in the hierarchy for several reasons.Philosophically, the most fundamental distinction inepistemology (human knowledge) is arguably that be-tween thinking and non-thinking beings (Strawson1953).
Psychology has shown that infants are able todistinguish umans from all other objects and theydevelop a deeper and more complex understanding ofhumans than of other objects (Gelman and Spelke 1981).In the realm of linguistics, a class of verbs selects forpersons, roles, and institutions as subjects or objects.Thus the SENTIENT distinction captures the similaritybetween persons and institutions or roles.
There is awidespread lexical ambiguity between a locational andinstitutional reading of nouns, which can be accountedfor by the SENTIENT distinction, as in (7).7.
The court is in the center of town.The court issued an injunction.The NATURAL/SOCIAL distinction also was placedhigh in the hierarchy.
Entities (including events) that areproducts of society, and thereby have a social function,are viewed as fundamentally different from naturalentities in the commonsense conceptual scheme.
Thedistinction is a basic one psychologically (Miller 1978;Gelman and Spelke 1981).
SOCIAL entities are thosethat come into being only in a social or institutionalsetting, with "institution" being understood in thebroadest sense, for instance family, government, edu-cation,, warfare, organized religion, etc.2.1.1.3 CONSTRUCTION OF THE ONTOLOGYThe ontological schema was constructed to handle theselectional restrictions of verbs in 4,000 words of geog-raphy text and 6,000 words of newspaper text.
Thesewere arranged in a hierarchical schema.
The hierarchywas examined and modified to reflect cognitive, philo-sophical, and linguistic facts, as described above.
It waspruned to make it as compact as possible.
We mini-mized empty terminal nodes.
A node could not be partof the ontology unless it systematically pervaded somesubhierarchy.
Distinctions found in various places wererelegated to feature status.
The full ontology withexamples may be found in Dahlgren (1988).2.1.1.4 VERBSIn KT, verbs are attached to the main ontology at thenode TEMPORAL because information concerning thetemporality of situations described in a sentence isencoded on the verb as tense and because the relationsindicated by verbs must be interpreted with respect otheir location in time in order to properly understand thediscourse structure of a text.
Thus the ontology impliesthat events are real entities, and that linguistic, notconceptual, structure distinguishes verbalized fromnominalized versions of events and states.We view the cognitive structure of the conceptsassociated with nouns and verbs as essentially different.Non-derived nouns in utterances refer to objects.
Lex-ical nouns name classes of entities that share certainfeatures.
Verbs name classes of events and states, but152 Computational Linguistics, Volume 15, Number 3, September 1989Kath|een Dahlgren, Joyce McDoweli, and Edward P. Stabler, Jr.
Knowledge Representation for Commonsense Reasoning with Textthese do not share featural descriptions.
Psychologi-cally, verbs are organized around goal orientation andargument types (Huttenlocher and Lui 1979; Graesserand Hopkinson 1987).The primary category cut at the node TEMPORAL isbetween ouns, which name classes of entities, in thiscase temporal entities like "party," "hurricane," and"winter," and verbs, which indicate relations betweenmembers of these nominal classes, like "hit," "love,""remember."
We attach temporal nouns to the TEM-PORAL/NON-RELATIONAL node and verbs to theTEMPORAL/RELATIONAL node.
Many nouns are,of course, relational, in the sense that "father" and"indictment" are relational.
Our node RELATIONALdoes not carry this intuitive sense of relational, butinstead simply indicates that words attached here re-quire arguments for complete interpretation.
So, while"father" is relational, it is possible to use "father" in atext without mentioning the related entity.
But verbsrequire arguments (usually overtly, but sometimes un-derstood, as in the case of commands) for full interpre-tation.
Nominalizations like "indictment" are a specialcase.
In our system, all deverbal nominalizations are somarked with a pointer to the verb from which they arederived.
Subsequent processing is then directed to theverb, which, of course, is attached under TEMPORAL,RELATIONAL.2.1.1.5 THE VENDLER CLASSIFICATIONOne basis of the relational ontology is the Vendler(1967) classification scheme, which categorizes verbsinto aspectual classes (see Dowty 1979).
According tothis classification, RELATIONAL divides into EVENTor STATIVE, and EVENT divides into ACTIVITY,ACHIEVEMENT, or ACCOMPLISHMENT.
Vendlerand others (particularly Dowty 1979) have found thefollowing properties, which distinguish these classes.8.
STATIVE and ACHIEVEMENT verbs may notappear in the progressive, but may appear in thesimple present.ACTIVITY and ACCOMPLISHMENT verbsmay appear in the progressive and if they appear inthe simple present, they are interpreted as describ-ing habitual or characteristic states.ACCOMPLISHMENTs and ACHIEVEMENTsentail a change of state associated with a terminus(a clear endpoint).
STATIVEs ("know") and AC-TIVITYs ("run") have no well-defined terminus.ACHIEVEMENTs are punctual (John killedMary) while ACCOMPLISHMENTs are gradual(John built a house).STATEs and ACTIVITYs have the subintervalproperty (cf.
Bennett and Partee 1978).Table 4 summarizes these distinctions.
There are sev-eral standard tests for the Vendler (1967) system whichcan be found in Dowty (1979) and others and which weapply in classification.The Vendler classification scheme is actually moreaccurately a classification of verb phrases than verbs.KT handles this problem in two ways.
First, in sentenceprocessing we take into account he arguments in theverb phrase as well as the verb classification to deter-mine clause aspect, which can be any of the Vendlerclasses.
Second, we classify each sense of a verbseparately.ProgressivesTerminusChange of StateSubintervalPropertyActivity Accomplish-mentrun, think build a house,read a novel+ +- +- Gradual+Achievementrecognizejqnd+PunctualStatehave, want+Table 4.
The Vendler Verb Classification SchemeThe other nodes in the relational ontology are motivatedby the psycholinguistic studies noted above.
The MEN-TAL/NONMENTAL/EMOTIONAL distinction is madeat the highest level for the same reasons that led us toplace SENTIENT at a high level in the main ontology.All EVENTs are also cross-classified as GOAL ori-ented or not.
This is supported by virtually everyexperimental study on the way people view situations,i.e., GOAL orientation is the most salient property ofevents and actions.
For example, Trabasso and Van denBroek (1985) find that events are best recalled whichfeature the goals of individuals and the consequences ofgoals and Trabasso and Sperry (1985) find that thesalient features of events are goals, antecedents, conse-quences, implications, enablement, causality, motiva-tion, and temporal succession and coexistence.
Thisview is further supported by Abbott, Black, and Smith(1985) and Graesser and Clark (1985).
NONGOAL,ACCOMPLISHMENT is a null category because AC-COMPLISHMENTS are associated with a terminusand thus inherently GOAL oriented.
On the other handNONGOAL, ACHIEVEMENT is not a null categorybecause the activity leading up to an achievement isalways totally distinct from the achievement i self.SOCIAL, NONGOAL, ACTIVITY is a sparse cate-gory.Cross-classifications i herited from the TEMPORALnode are SOCIAL/NATURAL and INDIVIDUAL/COLLECTIVE.
The INDIVIDUAL/COLLECTIVEdistinction isproblematical for verbs, because all eventscan be viewed as a collection of an infinitude of sub-events.2.1.2 GENERIC KNOWLEDGEGeneric descriptions ofthe nouns and verbs were drawnfrom psycholinguistic data to the extent possible.
In atypical experiment, subjects are asked to freelist fea-tures "characteristic" of and common to objects inComputational Linguistics, Volume 15, Number 3, September 1989 153Kathleen Dahlgren, Joyce McDoweH, and Edward P. Stabler, Jr.
Knowledge Representation for Commonsense Reasoning with Textcategories uch as DOG, LEMON, and SECRETARY(Rosch et al 1976; Ashcraft 1976; Dahlgren 1985a).
Thenumber of subjects in such an experiment ranges from20 to 75.
Any feature that is produced in a freelistingexperiment by several subjects is likely to be shared inthe relevant subpopulation (Rosch 1975; Dahlgren1985a).
Features that were freelisted by at least one-fifthof the subjects are chosen for a second experiment, inwhich different subject s are asked to rate the featuresfor typicality.
Those features rated as highly typical bythe second group can be considered a good first approx-imation to the content of the cognitive structures asso-ciated with the terms under consideration.
The numberof features hared in this way for a term averaged 15.The generic knowledge in the KT system is containedin two generic data bases, one for nouns and one forverbs.
There is a separate ntry for each sense of eachlexical item.
The content of the entries is a pair of listsof features drawn from the psycholinguistic data (asdescribed above) or constructed using these data as amodel.
A feature is, informally, any bit of knowledgethat is associated with a term.
In informal terms, thesecan be any items like "wears glasses" (programmer),"is red" (brick), or "can't be trusted" (used-car sales-man).
For each entry, the features are divided into twolists, one for typical features and one for inherentfeatures.
For example, abrick is typically red, but bloodis inherently red.
Together the lists comprise the entrydescription of the term that heads the entry.The source of descriptions of social roles were datacollected by Dahlgren (1985a).
For physical objects weused generic descriptions from Ashcraft (1976), includ-ing raw data generously supplied by the author.
Aninformal conceptualization for "lawyer" was shown in(1).
The corresponding generic description is shown in(9).
Features of the same feature type within either theinherent or typical list are AND'ed or OR'ed as re-quired.
Some features contain first-order formulas likethe conditions in discourse representations.
For exam-ple, one function feature has (advise(E,noun,Y) &cl ient(Y) & regarding(E,Z) & law(Z)).
The firstargument of the predicate advise is an event referencemarker.
This event is modified in the regarding predi-cate.
The second argument of advise is instantiated inthe processing as the same entity that is predicated asbeing in the extension of the noun generically describedin the representation, i  this case, "lawyer."9.
lawyer({behavior( contentious ),appearance(well-dressed),status(htgh)~mcome(hlgh),sex(male ),sex(feinale ),tools(paper ),tools(books ),tools(briefcase),function(negotlate(*jxoun,Y) ~?
settlement(Y)),internal_trait( ambitious);tnternaLtrait( articulate ),internal_trait( aggressive ),internal_trait(clever),interns\]_trait (knowledgeable) },{age( adult )'educatl?n(law-sch?
?l)'leg aLreq(pass(*jmun~) & bar(X))154fmlctlon(practlce(*,noun,Y) & law(Y)),functlon(advise(E,noun,Y) & client(Y) &regarcUng(E,Z) & law(Z)),ikmction(represent(E,noun,Y) & client(Y) &ln(E,Z) & court(Z)),function(argue(*jloun,Y) & case(Y))}).The entire set of features for nouns collected in this wayso far sort into 38 feature types.
These are age, agent,appearance, association, behavior, color, construc-tion, content, direction, duration, education, exem-plar, experienced-as, in-extension-of, frequency,function, goal, habitat, haspart,  hasrole, hierarchy,internal-trait, legal-requirement, length, level, loca-tion, manner,  material, name, object, odor, opera-tion, owner, partof, physiology, place, processing,propagation, prototype, relation, requirement,rolein, roles, sex, shape, size, source, speed, state,status, strength, structure, taste, texture, time.
Agiven feature type can be used in either typical orinherent feature lists.
Since these are not primitives, weexpect he list of feature types to expand as we enlargethe semantic domain of the system.There is a much smaller set of feature types forverbs.
We were guided by recent findings in the psy-cholinguistic literature which show that the types ofinformation that subjects associate with verbs are sub-stantially different from what they associate with nouns.Huttenlocher and Lui (1979) and Abbott, Black, andSmith (1985) in particular have convincingly argued thatsubjects conceive of verbs in terms of whether or notthe activities they describe are goal oriented, the causaland temporal properties of the events described, and thetypes of entities that can participate as arguments to theverb.
For the actual feature types, we adapted thefindings of Graesser and Clark (1985), whose researchfocused on the salient implications of events in narra-tives.
A small number of feature types is sufficient orepresent the most salient features of events.
These canbe thought of as answers to questions about the typicalevent described by the verb that heads the entry.
Inaddition, selectional restrictions on the verb are alsoencoded as a feature type.
Feature types for verbs arecause, goal, what.enabled, what.happened_next,consequence_oLevent, where, when, implies, how,selectioD..\]-restriction.
An example of a generic entryfor verbs follows.10.~v({wha~enabled(can(a~ox~l(mabj,obJ)) ),how(with(X) & money(X)),where(in(Y) & store(Y)),cause(need~bJ,obj) ),what_happened-next(use(subJ,obJ) )},{goal( own( subJ ,obJ ) ),consectuence_oLevent(own( ( subJ ,obJ ) ),selectionsLrestrtction(sentient(subJ )),implies(merchandise( obJ ) )} ).
4if someone buys something,typlca?ly he can af ford it,he uses money,he buys it in a store,he needs it,and later he uses it.Inherently, his goal is toown it,and after buying it, he doesOwTt it.The buyer is sentient andwhat  is bought ismerchandise.Computational Linguistics, Volume 15, Number 3, September 1989Kathleen Dahlgren, Joyce McDowell, and Edward P. Stabler, Jr.
Knowledge Representation for Commonsense Reasoning with TextNaive Semantic representations of generic knowledgecontain fifteen or more pieces of information per word,relatively more than required by other theories.
Themagnitude of the lexicon is counterbalanced by con-straints that naturally obtain in the generic knowledge.Study of the protocols of subjects in prototype xperi-ments reveals that people conceive of objects in con-strained patterns of feature types.
For example, animalsare conceived in terms of physical and behavioralproperties, while social roles are conceived in terms offunctional and relational properties.
Thus not all featuretypes occur in the representations of all nouns (orverbs).
The pattern of features relevant to each node inthe ontology is called a Kind Type.
Each feature isclassified by type as a COLOR, SIZE, FUNCTION,INTERNAL TRAIT or other.
At each node, onlycertain feature types are applicable.
Features at lowernodes inherit feature type constraints from the nodesabove them in the ontology.
For instance, any nodeunder SOCIAL may have certain feature types, and anynode under ROLE may have those feature types inher-ited from SOCIAL, as well as further feature types.Examples contrasting "elephant" and "lawyer" areshown in Tables 5 and 6.Node in Feature types associated Feature values forOntology with the node elephantENTITY haspart trunkhaspart 4 legspartof herdPHYSICAL color greysize vehiclesizedtexture roughLIVING propagation live birthshabitat jungleANIMAL sex male or femalebehavior lumbersbehavior eats grassTable 5.
Animal Kind TypeA lexical augmentation facility is used to creategeneric entries.
This facility exploits the fact that pos-sible feature types for any term are constrained by theontological ttachment of the term, by the Kind Type towhich they belong (Dahlgren & McDowell 1986a; Dahl-gren 1988a).
For example, it is appropriate to encodethe feature type "behavior" for "dog" but not for"truck."
Similarly, it is appropriate to encode thefeature type "goal" for "dig" but not for "fall."
Thelexical augmentation facility presents the user withappropriate choices for each term and then converts theentries to a form suitable for processing in the system.2.2 TEXT INTERPRETATION ARCHITECTURE2.2.1 PARSERThe overall goal of the KT project is text selectionbased on the extraction of discourse relations guided byNode in Feature types associated Feature values forOntology with the node lawyerSOCIAL function typesfunction practice lawfunction argue casesfunction advise clientsfunction represent clients in courtrequirement pass barappearance well-dressedSENTIENT internaltrait friendlyeducation law schoolinternaltrait cleverinternaltrait articulateinternaltrait contentioussex malesex femaleROLE relation high statusincome hightools bookstools briefcasesTable 6.
Social Role Kind Typenaive semantic representations.
This goal motivated thechoice of DRT as the compositional semantic formalismfor the project.
The particular implementation f DRTwhich we use assumes a simple, purely syntactic parseas input to the DRS construction procedures (Wada andAsher 1986).
Purely syntactic parsing and formal se-mantics are unequal to the task of selecting one of themany possible parses and interpretations of a given text,but human readers easily choose just one interpretation.NS representations are very useful in guiding thischoice.
They can be used to disambiguate parse trees,word senses, and quantifier scope.
We use an existingparser (MODL) to get one of the syntactic structures fora sentence and modify it based upon NS information.This allows us to isolate the power of NS representa-tions with respect o the parsing problem.
Not only areNS representations ecessary for a robust parsing ca-pability, but also in anaphora resolution and discoursereasoning.
Furthermore, the parse tree must be avail-able to the discourse coherence rules.
Thus our re-search has shown that not only must the NS represen-tations be accessible at all levels of text processing, butpurely syntactic, semantic, and pragmatic informationthat has been accumulated must also be available tolater stages of processing.
As a result, the architectureof the system involves separate modules for syntax,semantics, discourse and naive semantics, but each ofthe modules has access to the output of all others, asshown in Figure I.The parser chosen is the Modular Logic Grammar(McCord 1987), (MODL).
Both MODL and KT arewritten in VM/PROLOG (IBM 1985).
The input toMODL is a sentence or group of sentences (a text).
InKT we intercept the output of MODL at the stage of alabeled bracketing marked with grammatical featuresand before any disambiguation r semantic processingis done.
In effect, we bypass the semantics of MODL inComputational Linguistics, Volume 15, Number 3, September 1989 155Kathleen Dahlgren, Joyce McDowell, and Edward P. Stabler, Jr.
Knowledge Representation for Commonsense Reasoning with Textorder to test our NS representations.
In the labeledbracketing each lexical item is associated with an argu-ment structure that can be exploited in semantic inter-pretation.
The labeled bracketing output by MODL isslightly processed before being passed to our moduleDISAMBIG.
Here the commonsense knowledge base isaccessed to apply rules for prepositional phrase attach-ment (Dahlgren and McDowell 1986b) and word sensedisambiguation (Dahlgren 1988a), as well as to assignthe correct scope properties to operators and quantifi-ers.
The output is a modified parse.
All of these modulesare in place and functional.
The word sense disambig-uation rules are in the process of being converted.
Anexample of the input to DISAMBIG and the resultingoutput is as follows:11.
Input S:John put the money in the bank.Input to DISAMBIG:s(np(n(n(john(Vl)))) &vp(v(fin(pers3,sg,past,ind),put(V I,V2))np(detp(the(V3,V4)) & n(n(money(V2)))pp(p(in(V2,VS)) & np(detp(the(V6,VT))n(n(bank(VS))))))))Output of DISAMBIG:s(np(n(n(John(Vl))))vp (v(fln(pers3,sg,past~d),put i (V I,V2 ))np(detp(the(V3,V4)) & n(n(money(V2)))) &pp(p(in(V2,VS)) & np(detp(the(V6,VT)) &n(n(bank2(VS)))))))The differences are that the PP "in the bank" isVP-attached in the output of DISAMBIG rather thanNP-attached as in the output of MODL, and that thewords "put"  and "bank" are assigned index numbersand changed to putl and bank2, selecting the sensesindicated by the word sense disambiguation algorithm.2.2.2 SENTENCE-LEVEL SEMANTICSThe modified parse is then submitted to a semanticsmodule, which outputs a structure motivated in part bycurrent versions of discourse representation theory(DRT) (Kamp 1981; Wada and Asher 1986; Asher andWada 1988).
The actual form of the discourse represen-tation structure (DRS) and its conditions list in the KTsystem differ from standard formats in DRT in thattense arguments have been added to every predicateand tense predicates link the tense arguments to thetense of the verb of the containing clause.
The analysisof questions and negation was carried out entirely withrespect o the KT system and to serve its needs.
TheDRT semantics is in place and functional for moststructures covered by MODL.
The commonsenseknowledge representations are accessed in the DRTmodule for semantic interpretation of modals, the de-termination of sentence-internal pronoun anaphora(where simple C-command and agreement tests fail),and to determine some cases of quantifier scoping.2.2.3 DISCOURSE-LEVEL SEMANTICSAs each sentence of a text is processed it is added to theDRS built for the previous entence or sentences.
Thusan augmented DRS is built for the entire text.
In theaugmentation module the commonsense knowledge rep-resentations are accessed to determine definite nounphrase anaphora, sentence-external pronoun anaphora,temporal relations between the tense predicates gener-ated during sentence-level DRS construction, discourserelations (suc\]h as causal relations) between clauses, andthe rhetorical structure of the discourse as a whole.
Thediscourse work is being carried out mainly by Dahlgrenand is in various stages of completion.2.2.4 FOLSince standard proof techniques are available for usewith logical forms, the DRS formulated by the sentence-level and discourse-level semantic omponents i  con-verted to standard logic.
A number of difficultiespresent themselves here.
In the first place, given any ofthe proposed semantics for DRSs (e.g., Kamp 1981;Asher 1987), DRSs are not truth functional.
That is, thetruth walue of a DRS structure (in the actual world) isnot generally a function of the truth values of itsconstituents.
For example, this happens when verbsproduce opaque contexts (Asher 1987).
Since generalproof methods for modal logics are computationallydifficult, we have adopted the policy of mapping DRSsto naiw ~ , first-order translations in two steps, providinga special and incomplete treatment of non-truth func-tional contexts.
The first step produces representationsthat differ minimally from standard sentences of first-order logic.
The availability of this level of representa-tion enhances the modularity and the extensibility of thesystem.
Since first-order reasoning is not feasible in anapplication like this, a second step converts the logicalforms to clausal forms appropriate for the problemsolver or the textual knowledge base.
We describe achof these steps in turn.2.2.4.1 THE TRANSLATION TO STANDARD LOGICAL FORMSThe sentence-level and discourse-level semantic om-ponents disambiguate names and definite NPs, so thateach discourse reference marker is the unique canonicalname for an individual or object mentioned in thediscourse.
The scoping of quantifiers and negations hasalso been determined by the semantic processing.
Thisallows the transformation f a DRS to FOL to be rathersimple.
The basic ideas can be briefly introduced here;a more thorough discussion of the special treatment ofqueries is provided below.
The conditions of a DRS areconjoined.
Those conditions may include some that arealready related by logical operators (if-then, or, not), inwhich case the logical form includes the same opera-tors.
Discourse referents introduced in the consequentof an if-then construction may introduce r quantifiers:these are given narrow scope relative to quantifiers inthe consequent (cf.
Kamp's notion of a "subordinate"156 Computational Linguistics, Volume 15, Number 3, September 1989Kathleen Dahlgren, Joyce McDowell, and Edward P. Stabler, Jr.
Knowledge Representation for Commonsense Reasoning with TextDRS in Kamp 1981; Asher and Wada 1988).
Anyquantifiers needing wide scope will already have beenmoved out of the consequent by earlier semantic proc-essing.
The DRSs of questions contain special operatorsthat, like the logical operators, take DRS arguments thatrepresent the scope of the material being questioned.
Asimilar indication is needed in the logical form.
In thecase of a yes-no question, we introduce a specialvacuous quantifier just to mark the scope of the ques-tioned material for special treatment by the problemsolver (see below).
In the case of wh-questions, aspecial wh-quantifier is introduced, again indicating thescope of the questioned material and triggering a specialtreatment by the problem solver.
Verbs of propositionalattitude and other structures with opaque contexts aretreated as, in effect, introducing new isolated subtheo-des or "worlds."
For example, "John believes all menare mortal" is represented as a relation of belief holdingbetween John and a logical form (see below for moredetail), though it is recognized that this approach willneed to be supplemented to handle anaphora nd prop-ositional nominals (cf., e.g., Asher 1988).2.2.4.2 THE CONVERSION TO SPECIALIZEDCLAUSAL FORMSConsiderations ofefficiency motivate a further transfor-mation in our logical forms.
After the first step ofprocessing, we have standard first-order logical forms,except hat they may include special quantifiers indicat-ing questioned material.
Consider first those logicalforms that are not inside the scope of any questionquantifier.
These are taken as representations of poten-tial new knowledge for the textual data base.
Since theinference system must solve problems without userguidance, it would be infeasible to reason directly fromthe first-order formulations.
Clausal forms provide anenormous computational dvantage.
For these reasons,we transform each sentence of first-order logic into aclausal form with a standard technique (cf., e.g., Changand Lee 1973), introducing appropriate Skolem func-tions to replace existentially quantified variables.
Thetextual database can then be accessed by a clausaltheorem prover.
In the current system, we use efficientHorn clause resolution techniques (see below), so theknowledge representation is further restricted to Hornclauses, since completeness is less important han fea-sible resource use in the present application.
Definiteclauses are represented in a standard Prolog format,while negative clauses are transformed into definiteclauses by the addition of a special positive literal"false(n)," where n is an integer that occurs in no otherliteral with this predicate.
This allows a specializedincomplete treatment of negation-as-inconsistency (cf.Gabbay and Sergot 1986).
The definite clause transla-tions of the text can then be inserted into a textualknowledge base for use by the reasoning component.The presence of question quantifiers triggers a specialtreatment in the conversion to clausal form.
Our prob-lem solver uses standard resolution techniques: toprove a proposition, we show that its negation isincompatible with the theory.
Accordingly, the materialinside the scope of a question operator is treated as if itwere negated, and this implies an appropriately differ-ent treatment of any quantifiers inside the scope of theoperators.2.2.5 REASONERIn the architecture of the system, the reasoning moduleis broken into two parts: the specialized query process-ing system and a general purpose problem solver.
Thespecial processing of queries is described in detailbelow.
The problem solver is based on a straightforwarddepth-bounded Horn clause proof system, implementedby a Prolog metainterpreter (e.g.
Sterling and Shapiro1986).
The depth bound can be kept fixed when it isknown that no proofs should exceed a certain smalldepth.
When a small depth bound is not known, thedepth can be allowed to increase iteratively (cf.
Stickel1986), yielding a complete SLD resolution system.
Thisproof system is augmented with negation-as-failure forpredicates known to be complete (see the discussion ofopen and closed world assumptions below), and with aspecialized incomplete negation-as-inconsistency thatallows some negative answers to queries in cases wherenegation-as-failure cannot be used.2.2.6 RELEVANCEThe RELEVANCE module will have the responsibilityof determining the relevance of a particular text to aparticular user.
The text and user profiles will beprocessed through the system in the usual way resultingin two textual data bases, one for the target ext and onefor the profile.
Target and profile will then be comparedfor relevance and a decision made whether to dispatchthe target to the profiled user or not.
The relevancerules are a current research topic.
The commonsenseknowledge representations will form the primary basisfor determining relevance.3 NAIVE SEMANTICS IN THE KT  SYSTEMFrom the foregoing brief overview of the KT system, itshould be clear that naive semantics i used throughoutthe system for a number of different processing tasks.
Inthis section we show why each of these tasks is aproblem area and how NS can be used to solve it.3.1 PREPOSITIONAL PHRASE ATTACHMENT 5The proper attachment of post-verbal adjuncts is anotoriously difficult task.
The problem for prepositionalphrases can be illustrated by comparing the followingsentences.12.
\[S The government \[VP had uncovered \[NP anentire file \[PP about the scheme\]\]\]\].
613.
\[S Levine's lawyer \[VP announced \[NP the pleabargain\] [PP in a press conference\]Computational Linguistics, Volume 15, Number 3, September 1989 157Kathleen Dahigren, Joyce McDowell, and Edward P. Stabler, Jr.
Knowledge Representation for Commonsense Reasoning with Text14.
\[S\[S The judge adjourned the hearing\] [PP in theafternoon\]\]Each of these sentences takes the canonical form Sub-ject-Verb-Object-PP.
The task for the processing sys-tem is to determine whether the PP modifies the object(i.e., the PP is a constituent of the NP, as in (12)), theverb (i.e., the PP is a constituent of the VP, as in (13)),or the sentence (i.e., the PP is an adjunct to S, as in(14)).
Some deny the need for a distinction between VPand S-modification.
The difference is that with S-mod-ification, the predication expressed by the PP has scopeover the subject, while in VP-attachment i  does not.For example, in (15), "in the park" applies to Levine,while in (16), "with 1,000 dollars" does not apply toLevine.15.
Levine made the announcement in the park.16.
Levine bought he stock with 1,000 dollars.A number of solutions for the problem presented bypost-verbal prepositional phrases have been offered.The most common techniques depend on structural(Frazier and Fodor 1978), semantic (Ford, Bresnan, andKaplan 1982), or pragmatic (Crain and Steedman 1985)tests.
MODL (McCord 1987) employs a combination ofsyntactic and semantic information for PP attachment.Independently, we formulated a preference strategy forPP attachment which uses ontological, generic andsyntactic information to cover 99% of the cases in aninitial test corpus, and which is 93% reliable across anumber of types of text.
This is the preference strategywe employ in KT.
The PP attachment rules make use ofinformation about the verb, the object of the verb, andthe object of the preposition.
A set of global rules isapplied first, and if these fail to find the correct attach-ment for the PP, a set of rules specific to the prepositionare tried.
Each of these latter rules has a default.
Theglobal rules are stated informally in (17).
with examplesentences.17a.
time(POBJ)-, s_attach(PP)I f  the object of  the preposition is an expressionof time, then S-attach the PP.The judge adjourned the hearing in the after-noon.b.
lexical(V+Prep)--~ vp_attach(PP)I f  the verb and preposition form a lexicalizedcomplex verb, then VP-attach the PP.The defense depended on expert witnesses.c.
Prep=of--~ np_attach(PP)I f  the preposition is of then NP-attach the PP.The ambulance carried the victim of the shoot-ing.d.
intransit ive(V) & motion(V) & place(POBJ)--~ vp_attach(PP)I f  the verb is an intransitive verb of motion andthe object of the preposition is a place thenVP-attach the PP.The press scurried about the courtroom.e.
2intransitive(V) & (place(POBJ) OR temporal(POBJ) OR abstract(POBJ)) --* a.attach(PP)I f  the verb is intransitive and the object of thepreposition is a place, temporal, or abstract,then S-attach the PP.Levine worked in a brokerage house.f.
epistemic(POBJ)--* s_attach(PP)I f  the prepositional phrase expresses a proposi-tional attitude, then attach the PP to the S.Levine was guilty in my opinion.g.
xp(.
.
~_dj-PP...)--~ xp_attach(PP)I f  PP follows an adjective, then attach the PP tothe phrase which dominates and contains theadjective phrase.Levine is young for a millionaire.h.
measure(DO)--~ np_attach(PP)I f  the direct object is an expression of measure,then NP-attach the PP.The defendant had consumed several ounces ofwhiskey.i.
comparative-* np_attach(PP)I f  there is a comparative construction, thenNP-attach the PP.The judge meted out a shorter sentence thanusual.j.
mental(V) & medium(POBJ)-~ vp_attach(PP)I f  the verb is a verb of saying, and the object ofthe preposition is a medium of expression thenVP-attach the PP.Levine's lawyer announced the plea bargain ontelevision.Example 14 is handled by global rule (17a).
Example 13is handled by global rule (17j).
The global rules areinapplicable with example 12, so the rules specific to"about" are called.
These are shown below.18a.
intrsmsitive(V) & mental(V)--~ vp_attach(PP)I f  the verb is an intransitive mental verb, thenVP-attach the PP.Levine spoke about his feelings.b.
Elsewhere--* np_attach(PP)Otherwise, NP-attach the PP.The government had uncovered an entire fileabout the scheme.As a filrther example, the specific rules for "by"  usesboth generic (19a,b) and ontological (19c) knowledge.19 a. nom(DO)--~ np_attach(PP)I f  the direct object is marked as a nominaliza-tion, then NP-attach the PP.The soldiers withstood the attack by the en-emy.b.
location(DO,POBJ)--~ np_attach(PP)I f  tJ~e rel~.tion between the d.ireot obJeot andt~he object of t~he preposit ion Is one of  loos,-~ion, then lq'P-~t~ch t,he PP.The clerk adjusted the microphone by thewitness stand.158 Computational Linguistics, Volume 15, Number 3, September 1989Kathleen Dahlgren, Joyce McDowell, and Edward P. Stabler, Jr.
Knowledge Representation for Commortsense Reasoning with Textc.
proposltional(DO) & sentlent(POBJ)--, np_at-ta~h(PP)I f  the direct object is propositional and theobject of the preposition is sentient, then NP-attach the PP.The judge read out the statement by Levine.d.
Elsewhere---> s_attach(PP)Otherwise, S-attach the PP.The lawyers discussed the case by the parkinglot.These PP-attachment preference rules are remarkablysuccessful when applied to real examples from actualtext.
However, they are not foolproof and it is possibleto construct counterexamples.
Take the global ruleillustrated in (17a).
We can construct a counterexampleas in (20).20.
John described the meeting on Jan. 20th.Sentence 20 is ambiguous.
Jan. 20th can be the time ofthe describing or the time of the meeting.
Perhaps thereis a slight intuitive bias toward the latter interpretation,but the rules will assign the former interpretation.
Thisis a counterexample only because "meeting" is a TEM-PORAL noun and can plausibly have a time feature.Compare (21), which is identical except for the ontolog-ical attachment of the direct object and which is handledcorrectly by the global rule.21.
John described the proposal on Jan. 20th.The problem of the interpretation f event nominals is aresearch topic we are working on.The PP attachment rules are applied in the moduleDISAMBIG, which produces a disambiguated parsefrom the output of the MODL parser.
The first step is toidentify the sentence lements that form their inputs foreach clause using find..args.
The output of find_args is alist of the the direct object, object of the preposition,preposition, and main verb of the clause and the indexof the clause (main, subordinate, and so on).
ThePP-attachment rules are in place and functional for onepost-verbal prepositional phrase.
Where more than onepost-verbal prepositional phrase occurs, the currentdefault is to attach the second PP to the NP of the firstPP.
However, this will not get the correct attachment incases like the following.22.
The judge passed sentence on the defendant in aterse announcement.A planned extension of the PP-attachment functionalitywill attack this problem by also keeping a stack ofprepositions.
The top of the stack will be the head of therightmost PP.
The attachment rules will be applied toPPs and the other constituents in a pairwise fashionuntil all are attached.3.2 WORD SENSE DISAMBIGUATIONThe word sense disambiguation method used in thesystem is a combined local ambiguity reduction method(Dahlgren 1988b).
The method is local because wordsenses are disambiguated cyclically, from the lowestS-node up to the matrix node.
Only when intrasententialsources of information fail are other sentences in thetext considered by the disambiguation method.
Thealgorithm is combined because it employs three sourcesof information.
First it tries fixed and frequent phrases,then word-specific syntactic tests, and finally naivesemantic relationships in the clause.
If the fixed andfrequent phrases fail, the syntactic and naive semanticrules progressively reduce the number of senses rele-vant in the clausal context.
The algorithm was devel-oped by considering concordances of seven nouns witha total of 2,193 tokens of the nouns, and concordancesof four verbs with a total of 1,789 tokens of the verbs.The algorithm is 96% accurate for the nouns in theseconcordances, and 99% accurate for the verbs in theseconcordances.Fixed phrases are lists of phrases that decisivelydisambiguate the word senses in them.
For example, thenoun "hand" has 16 senses.
Phrases such as "byhand," "on hand," "on the one hand" have only onesense.Syntactic tests either educe the number of relevantsenses, or fully disambiguate.
For nouns, syntactic testslook for presence or absence of the determiner, the typeof determiner, certain prepositional phrase modifiers,quantifiers and number, and noun complements.
Forexample, only five of the 16 senses of "hand" arepossible in bare plural noun phrases.
For verbs, syntac-tic tests include the presence of a reflexive object,elements of the specifier, such as particular adverbs thepresence of a complement of the verb and particularprepositions.
For example, the verb "charge" has onlyits reading meaning "indict" when there is a VP-attached PP where the preposition is "with" (as deter-mined by the prepositional phrase attachment rules).Syntactic tests are encoded for each sense of eachword.
The remainder of this section will illustratedisambiguation using naive semantic information andgive examples of the naive semantic rules.
(The com-plete algorithm may be found in Dahlgren 1988a).3.2.1 NOUN DISAMBIGUATIONNaive semantic information was required for at least aportion of the disambiguation i  49% of the cases ofnouns in the concordance t st.
Naive semantic infer-ence involves either ontological similarity or genericrelationships.
Ontological similarity means that twonouns are relatively close to each other in the ontology,both upwards and across the ontology.
If there is noontological similarity, generic information is inspected.Generic information for the ambiguous noun, othernouns in the clause, the main verb, often disambiguatean ambiguous noun.Ontological similarity is tested for in several syntac-tic constructions: conjunction, nominal compounds,possessives, and prepositional phrase modifiers.
ManyComputational Linguistics, Volume 15, Number 3, September 1989 159Kathleen Dahlgren, Joyee McDowell, and Edward P. Stabler, Jr. Knowiedge Representation for Commonsense Reasoning with Textof the 16 senses of "hand" are ontologically distinct, asshown in Table 7.I.
HUMAN human body part2.
DIRECTION right or left3.
INSTRUMENT by hand4.
SOCIAL power, authority5.
TEMPORAL applause6.
ROLE laborer7.
ARTIFACT part of a clockTable 7.
Some senses of handIn (23), only the HUMAN and ROLE senses (I and6) are possible, by ontological similarity.
Genericknowledge of the verb "clear" is inspected for the finaldisambiguation to sense 6.23.
The farmer and his hand cleared the field.In contrast, in (24), the relevant senses of "hand" arethe HUMAN and ARTIFACT senses (1 and 7).24.
His arm and hand were broken.At the point in the algorithm where naive semantic testsare invoked, syntactic tests have already eliminated theARTIFACT sense, which does not occur with a per-sonal pronoun.
Thus the HUMAN sense is selected.
In(25), only the ARTIFACT sense (7) is possible, byontological similarity of "clock" and "hand."25.
The clock hand was black.In (26), again the HUMAN and ROLE senses (1 and 6)are the only relevant ones by ontological similarity.Selection restrictions on "shake" complete the disam-biguation.26.
John shook the man's hand.In (27), sense 4 is selected because "affair" and sense 4are both SOCIAL.27.
John saw his hand in the affair.In (28), sense I is selected because both sense 1 and asense of "paper" are attached to PHYSICAL.28.
The judge had the paper in his hand.The word sense disambiguation algorithm tests forgeneric relationships between the ambiguous noun andprepositional phrases modifiers, adjective modifiers,and the main verb of the sentence.
Two of the ninesenses of "court" are shown in Table 8.
In "the courtlistened to testimony," generic information for thesecond sense of "court" can be used to select sense 2.The generic information i cludes knowledge that one ofthe functions of courts has to do with testimony.
In (29),sense 1 of "court" is selected because the genericrepresentation of "court" contains information thatwitness tands are typical parts of courtrooms.courtlcourt2PLACE Typically, it has a bench,jury box, and witness tand.Inherently its function is fora judge to conduct rials in.It is part of a courthouse.INSTITUTION Typically, its function isjustice.
Examples are theSupreme Court and thesuperior court.
Its locationis a courtroom.
Inherently itis headed by a judge, hasbailiffs, attorneys, courtreporters as officers.Participants are defendants,witnesses and jurors.
Thefunction of a court is tohear testimony, examineevidence and reach averdict.
It is part of thejustice system.Table 8.
Generic Information for Two Senses of court 729.
The witness tand in Jones's court is made of oak.In (30), the adjective "wise" narrows the relevantsenses from nine to the two INSTITUTION senses of"cour t .
"30.
'The wise court found him guilty.Generic knowledge of one sense of the verb "find" isthen used to select between the court-of-law sense (2)and the-royal-court sense (4).
Verb selection restric-tions are powerful disambiguators of nouns, as manycomputational linguists have observed.
In (31), the verbchargelcharge2charge3Table 9.Typically, if someone is charged, next theyare indicted in court, convicted or acquitted.They are charged because they havecommitted a crime or the person whocharges them suspects they have.Inherently, the charger and chargee aresentient, and the thing charged with is acrime.Inherently, if someone charges thatsomething is true, that someone is sentient,his goal is that it be known, and thesomething is bad.Typically, if someone charges omeone lsean amount for something, the chargee has topay the amount o the charger, and thechargee is providing oods or services.Inherently, the charger and chargee aresentients, the amount is a quantity ofmoney, and the goal of the charger is tohave the chargee pay the amount.Generic Information for Thi'ee Senses of charge160 Computational Linguistics, Volume 15, Number 3, September 1989Kathleen Dahlgren, Joyce McDoweli, and Edward P. Stabler, Jr.
Knowledge Representation for Commonsense Reasoning with Text"last" requires a TEMPORAL subject, thus disambig-uating "hand."31.
They gave him a hand which lasted 10 minutes.3.2.2 VERB DISAMBIGUATIONJust as selectional restrictions of verbs disambiguatenouns, their arguments are powerful disambiguators ofverbs.
Subject, object, and oblique arguments are alltaken into account by the algorithm.
(32) and (33)illustrate the way that objects can disambiguate the verb"charge," generic entries for which are shown in Table9.In (32) the SENTIENT object selects ense 1.
In (33),the MONEY object selects ense 3.32.
The state charged the man with a felony.33.
The state charged ten dollars for the fine.The verb "present" can be disambiguated by its sub-ject.
It has at least three senses:34. present l - -"g ive"present2---"introduce"present3--"arrive in the mind of"Senses 1 and 2 require SENTIENT subjects, so thethird sense is selected in (35).35.
The decision presented a problem to banks.
(36) illustrates ubject and object disambiguation.
TheSENTIENT subject narrows the possibilities to sensesl and 2, and the "give" sense (1) is selected because itrequires a PHYSICAL object argument.36.
John presented a bouquet to Mary.3.2.3 OISAMBIGUATION RULESThe disambiguation method first tries fixed and frequentphrases, then syntactic tests, and finally naive semanticinformation.
Each set of rules reduces the number ofrelevant senses of a word in the sentential (and extra-sentential) context.
There is a fixed set of commonsenserules for nouns and another one for verbs.
They aretried in an order that inspects the main verb of theclause last, because the main verb often chooses be-tween the last two relevant senses.
An example of anoun rule is ppmod, which considers an ambiguousnoun in relation to the head of a prepositional phrasemodifier attached to the same higher NP as the ambig-uous noun.
There are two versions of the rule, onewhich looks for ontological similarity between senses ofthe ambiguous noun and the head of the PP, and onewhich looks for generic relationships between them.The output of find_args (in DISAMBIG, see Section 3. l)is used as a simplified syntactic structure inspected bythese rules.
This provides information as to whether ornot a head noun is modified by a prepositional phrase.In the first version of the rule, the ontological attach-ment of the head of the PP is looke d up and then sensesof the ambiguous word with that same ontologicalattachment are selected.
SI is the list of senses of theambiguous noun still relevant when the rule is invoked.$2 is the list of senses reduced by the rule if it succeeds.If the first version fails, the second is invoked.
It looksfor a generic relationship between senses of the ambig-uous word and the head of the PP.37.
ppmod(Ambig_Word,{.. _A_rnbig_Word,Prep,Noun...},Sl,S2) ~-ontattach(Noun, Node) &ontselect (Ambig_Word,Node, Sl,S2).ppmod(Ambig_Word,{.. _&mbig_Word,Prep,Noun...},Sl,S2) ~--generic_relation( Nound%rnbig_Word ).3.3 QUANTIFIER SCOPINGThe semantic module of the KT system is capable ofgenerating alternative readings in cases of quantifierscope ambiguities, as in the classic case illustrated in(38).38.
Every man loves a woman.In this example either the universally quantified NP("every man") or the existentially quantified NP ("awoman") can take widest scope.
In such sentences, it isgenerally assumed that the natural scope reading (left-most quantified expression taking widest scope) is to bepreferred and the alternative r ading chosen only underexplicit instructions of some sort (such as input from auser, for example, or upon failure to find a properantecedent for an anaphoric expression).
Under thisassumption, in a sentence like (39), the indefinite NPwould preferentially take widest scope.39.
A woman loves every man.But there are a number of cases similar to (39) where anexpression quantified by "every" appears to the right ofan indefinite NP and still seems to take widest scope.Ioup (1975) has discussed this phenomena, suggestingthat expressions uch as "every" take widest scopeinherently.
Another computational pproach to thisproblem is to assign precedence numbers to quantifiers,as described in McCord (1987).
However, our investi-gation has shown that commonsense knowledge plays atleast as large a role as any inherent scope properties ofuniversal quantifiers.Consider (40).
In the natural scope reading, "everylawyer" takes scope over "a letter" and we haveseveral etters, one from each of the lawyers, i.e.,several tokens of a one-to-one relationship.
In thealternative r ading, "a letter" takes scope over "everylawyer" and we have only one letter, i.e., one token ofa many-to-one relationship relationship.
Both scopereadings are plausible for (40).40.
The judge read a letter from every lawyer.In (41) only the alternative reading (several tokens ofone-to-one) is plausible.41.
The politician promised a chicken in every pot.In (42), however, only the natural reading (one token ofmany-to-one) is plausible.42.
The prince sought a wife with every charm.Even in (40), however, speakers prefer the one-to-onerelationship, the alternative reading.
That is, speakersprefer the reading that denotes several tokens of aone-to-one relationship (several letters) over one whichdenotes one token of a many-to-one r lationship unlessComputational Linguistics, Volume 15, Number 3, September 1989 161Kathleen Dahlgren, Joyce McDowell, and Edward P. Stabler, Jr.
Knowledge Representation for Commonsense Reasoning with Textthere is strong commonsense knowledge to override thispreference.
We know that in our culture princes canh~ive only one wife, so in the case of (42) speakers preferone token (one wife) of many-to-one to several tokensof one-to-one.
Similar arguments apply to the followingexamples (43)-(45), which correspond to (40)-(42) re-spectively.43.
A judge decided on every petition.44.
A lawyer arrived from every firm.45.
A company agent negotiated with every union.Thus, if there is an inherent tendency for universalquantifiers to take widest scope where scope ambiguityis possible, it derives from the human preference forviewing situations involving universally quantified enti-ties as many tokens of one-to-one relationships, s In KT,first we prefer wide scope for the universal quantifier.In cases where this is not the natural scope interpreta-tion, (i.e., the universal quantifier is to the right of acontaining existentially quantified NP), we can use factsencoded in the generic data base to override the pref-erence.
For example, when processing (42) we woulddiscover that a man may have only one wife.
Thegeneric entry for "wife" tells us that "wife" is a role ina "marriage."
The generic entry for "marriage" tells usthat "marriage" is a relation between exactly onehusband and exactly one wife.
This knowledge forcesthe many-to-one interpretation.
The cases where this isnecessary turn out to be rare.
Curiously, the preposition"with" correlates very highly with many-to-one rela-tionships.
Thus our strategy for the present has been toconsider overriding the preference only when the uni-versal quantifier is in an NP which is the object of"with."
In these cases we access the generic knowl-edge, as described above.3.4 OPAQUE CONTEXTSIn KT, clauses in opaque contexts (embedded underpropositional attitude verbs such as "hope," "be-lieve," "deny") are handled by asserting the predicatesgenerated from the clause into partitioned atabases,which correspond to the delineated DRSs of Asher(1987).
Each partition is associated with the speaker orthe individual responsible for the embedded clause.Reasoning can then proceed taking into account thereliability and bias of the originator of the partitionedstatements, as in Section 2.2.4.1 An example follows.46.
Text: Meese believes that Levine is guilty.Textual Database: believe(sl,meese,pl)Partition: p 1 :: guilty(s2,1evine)3.5 MODALS 9The English modals can, may, must, will, and shouldare high-frequency items in all kinds of texts.
They canbe easily parsed by a single rule similar to the rules thathandle auxiliary "have" and "be"  because all themodals occupy the same surface syntactic position (i.e.,the first element in the auxiliary sequence).
However,the~ modals present some considerable problems forsemantic interpretation because they introduce ambigu-ities and induce intensional contexts in which possibil-ity, necessity, belief, and value systems play a role.
Inthe KT system, we are concerned with what is knownby the system as a result of reading in a modal sentence.In particular we are interested in what status the systemassigns to the propositional content of such a sentence.To illustrate the problem, if the system reads"Levine engaged in insider trading," then an assertioncan justifiably be added to the knowledge base reflect-ing the fact that Levine engaged in insider trading.
Thesame is true if the system reads "The Justice Depart-ment knows that Levine engaged in insider trading.
"But this is not the case if the system reads "The JusticeDepartment believes that Levine engaged in insidertrading."
In this case the statement that Levine engagedin insider trading must be assigned some status otherthan fact.
Specifically, since "believe" introduces anopaque context, the propositional content of the embed-ded clause would be assigned to a partitioned ata baselinked to the speaker the Justice Department, as de-scribed in the previous ection.
A similar problem existsin modal sentences such as "Levine may have engagedin insider trading.
"There are two types of modal sentences.
In Type Imodal sentences the truth value of the propositionalcontent is evaluated with respect o the actual world ora set of possible other states of the actual world directlyinferable from the actual world.
Examples are47.
Levine must have engaged in insider trading.48.
The Justice Department will prosecute Levine.49.
Levine can plead innocent.In Type II modal sentences, we say that a secondspeech act is "semantically embedded" in the modalsentence.
The modal sentence is successful as an asser-tion just in case the secondary speech act is in effect inthe actual world.
In these cases the truth value of thepropositional content is evaluated with respect o someset of deontic or normative worlds.
The modal is viewedas a quantifier cum selection function.
Thus, for asentence of the form/~ = NP Modal VP, I~ is true in theactual world just in case NP VP is true in at leastone/every world (depending on Modal) in the set ofdeontic or normative worlds selected by Modal.
Exam-ples are50.
Levine must confess his guilt.51.
Levine may make one phone call.52.
Levine should get a good attorney.In (50) a command is semantically embedded in theassertion; in (51) a permission is semantically embeddedin the assertion; and in (51) the issuance of a norm issemantically embedded in the assertion.Type I modal sentences are of assertive type accord-ing to the speech act classification scheme in Searle andVanderveken (1985).
These include the standard asser-tions, reports, and predictions, and a proposed new162 Computational Linguistics, Volume 15, Number 3, September 1989Kathleen Dahlgren, Joyce McDowell, and Edward P. Stabler, Jr.
Knowledge Representation for Commonsense Reasoning with Texttype, quasi-assertion.
They must be distinguished in atext-understanding system from Type II modal sen-tences that embed other types of speech acts, becauseonly Type I modal sentences make a contribution to thetextual knowledge base.
In addition, some modal sen-tences are ambiguous between Type I and Type II, forexample (47), (51), and (50).For the KT system, disambiguating the ambiguousmodals "may" and "must" results in changing thesyntactic input to the semantic module.
The surfacesyntactic parse that is output by the parser is convertedinto the equivalent logical form where the epistemic(Type I) uses of ambiguous modals are treated assentential operators and the nonepistemic uses of am-biguous modals (Type II) are treated as modifiers of theverb.
Sentences containing ambiguous modals can beassigned the correct status by a simple disambiguationalgorithm that makes appeal to the ontological classifi-cation of the main verb, specifically whether or not theverb is STATIVE, following Steedman (1977).
Disam-biguation takes place in DISAMBIG, the same modulethat converts the labelled bracketing to a modified parsefor input to the DRT semantic translator.
At this point,a determination is made whether the modal is a senten-tial operator or a modifier of the verb.
The propositionalcontent of quasi-assertions and predictions can beadded directly to the dynamically constructed textualdata base if they are appropriately marked with proba-bility ratings.
On this view, "will" and one sense of"may" are taken as denoting strong and weak predic-tion and are not viewed as tenses.
That is, when usingthese modals, the speaker is indicating his confidencethat there is a high/moderate probability of the propo-sitional content being true in the future.
In the presentstate of the system, every predicate contains a tenseargument and there is a tense predicate relating everytense argument o a tense value (such as "pres.,""future," etc.).1?
In a planned extension to the systemthese tense predicates will also contain probabilityratings.
For example, given the continuum of speakercommitment to the truth of the statement "Leyineengaged in insider trading" illustrated in (53), we wouldhave the corresponding predicates in the DRS shown in(54).53.
Full Assertion: Levine engaged in insider tradingStrong Quasi-Assertion: Levine must have en-gaged in insider tradingWeak Quasi-Assertion: Levine may have en-gaged in insider trading54.
Full Assertion: engage(el,levine), tense(el ,past, 1)Strong Quasi-Assertion: engage(el,levine), tense(el,past,0.9)Weak Quasi-Assertion: engage(el,levine), tense(el,past,0.5)This hierarchy reflects the "epistemic paradox" ofKarttunen (1971), in which he points out that in stan-dard modal logic must(P) or necessarily, P is strongerthan plain assertion whereas epistemically-must(P) isweaker than plain assertion.
This results from the factthat the standard logic necessity operator quantifiesover every logically possible world, plain assertion of Pis evaluated with respect o the actual world, but theepistemic modal operator quantifies only over theepistemically accessible worlds, a set which could pos-sibly be null.Assertions of possibility (49) t?igger the inferring ofenabling conditions.
For any event there is a set ofenabling conditions that must be met before the event ispossible.
For John to play the piano, the followingconditions must be met:55.
1.
John knows how to play the piano.2.
John has the requisite permissions (if any).3.
A piano is physically available to John.4.
John is well enough to play.. .
.
.These can be ordered according to saliency as above.This, we claim, is why the sentence "John can play thepiano" most often receives the interpretation (I), lessoften (2), and practically never (3) or (4) unless explic-itly stated, as in "John can play the piano now that hismother has bought a new Steinway."
The enablingconditions are encoded in KT as part of the genericrepresentation for verbs.
When a modal sentence isinterpreted as a full assertion of possibility (poss(p)),this triggers the inference that the most salient of theenabling conditions is in fact true.
The difference be-tween poss(p) and p being processed for KT, is that ifpis output, then p is added to the textual database and themost salient enabling condition is also inferred.
But ifposs(p) is output, then only the most salient enablingcondition is inferred, but p is not added to the textualdatabase.
Notice that this simply reflects the fact that ifI say "John can play the piano," I am not saying thatJohn is playing the piano at that very moment.Type II modal sentences present a more complexproblem for interpretation.
The commands, permis-sions, and norms reported in Type II modal sentencesare asserted into partitioned atabases in the same wayas clauses in opaque contexts.
The only difference isthat in most cases the issuer of the command, permis-s ion, or norm reported in a modal sentence is notknown.
Semantic translation in DRT proceeds via cat-egorial combination.
By the time the modal sentencereaches the DRT module, the semantic type of themodal is unambiguous and the appropriate l xical entrycan be retrieved.
The creation of appropriate predicatesto express the variety of modal statements i  the task ofthe DRT module.4 THE QUERY' SYSTEM4.1 OPEN AND CLOSED WORLD ASSUMPTIONSIt is well known that negation-as-failure is a soundextension of SLD resolution only when the database isComputational Linguistics, Volume 15, Number 3, September 1989 163Kathleen Dahlgren, Joyce McDowell, and Edward P. Stabler, Jr.
Knowledge Representation for Commonsense Reasoning with Textcomplete, i.e., when it represents a closed world (Lloyd1984).
Since our databases will always include somepredicates about which we have only incomplete infor-mation, we cannot assume a completely closed world.The open world assumption, though, makes it unsoundto use the very useful negation-as-failure rule.
Fortu-nately, it is well known that we can restrict he use ofthis rule to just those predicates known to be complete,keeping an open world assumption for other predicates.We accordingly specify that some of our general knowl-edge comprises a complete, closed world in the appro-priate sense, but we do not make this assumption abouttextual knowledge.4.2 FUNCTIONING OF THE QUERY SYSTEMQueries are handled just like text up through conversionto FOL.
The FOL form of the query is then passed toREASONER, which decides which database is the mostlikely source of the answer.
REASONER can accessthe textual database, the verb and noun generic data-bases, and the ontology.
The reasoning is complex anddependent on whether the query form is ontological,factual, or generic.
A search sequence is then initiateddepending on these factors.
The form of the answerdepends on the search sequence and the place where theanswer is found.4.2.1 ANSWERSThe form of the answer depends on the reliability of theknowledge ncoded in the database where the answer isfound.
The text is considered authoritative.
If an answeris found in the text, search is terminated.
The ontologyis considered a closed world (see discussion above).This means that yes/no ontological questions are an-swered either "yes"  or "no."
The textual and genericdatabases are considered an open world.
If an answer isnot found, and no further search is possible, the systemconcludes, "I  don't know."
Answers found in thegeneric databases are prefaced by "Typically," forinformation found in the first list (of typical features) or"Inherently," for answers found in the second list (ofinherent features).4.2.2 QUESTION TYPESAn ontological question is in a copular sentence with anon-terminal ontological node in the predicate.56.
Ontological Questions:Is a man human?Is the man a plant?A factual question is one couched in the past tense,present progressive, and/or where the subject is specific(a name or a definite NP).
Specific NPs are assumed tohave already been introduced into the system.
Oursimplified definition of generic question is one whichcontains an inherently stative verb or a non-stative verbin the simple present combined with a non-specificsubject (indefinite NP).li57.
Factual Questions:Did John buy a book?Is the man happy?Who bought he book?Generic Questions:Does a man buy a book?Does the man love horses?Ontological questions are answered by looking in theontological database only.
If an answer is not found, theresponse will be "no"  if the query contained an onto-logical predicate (such as PLANT or ANIMAL) be-cause the ontology is a closed world.58.
Text: John is a man who bought a book.Is a plant living?--Yes.Is the man an animal?--Yes.Is the man a plant?----No.Factual queries (non-generic questions) go to the textualdatabase first.
If an answer is not found, then thegeneric knowledge is consulted.
If an answer is foundthere, the appropriate response (Typically.., Inher-ently..) is returned.
Otherwise the response is, " I  don'tknow."59.
Text: John is a man who bought a book.Did John buy a book?---Yes.Who bought a book?--John.Is John the President?mI don't know.Does John wear pants?---Typically so.Where did John buy the book?--Typically, in astore.Generic: queries go only to the generic database.60.
Does a man wear pants?--Typically so.What is the function of a lawyer?--Inherently,represents clients.Is an apple red?
Typically so.Does a man love flowers?--I don't know.Where does a man buy a book?
Typically, in astore.Who buys a book?---Inherently, a sentient.In addition to these general rules, there is specialhandling for certain types of queries.
Questions of theform "Who is .
.
."
and "What is .
.
."
are answeredby finding" every predicate in any data base that is trueof the questioned entity.
For example, in any of theexamples above, the question "Who is John?"
wouldtrigger a response that includes a list of all the nodes inthe ontology which dominate the position where"John" is attached plus the information that John is aman, is tall, and bought a book.
The question "What isa vehicle?"
would trigger only the list of ontologicalnodes because there is no specific vehicle in the domainof this example.
Questions such as "Who buys abook?"
and "What is driven?"
are answered by statingselectional restrictions on the verb-- Inherently, a sen-tient buys a book, and Inherently, a vehicle is driven.Finally, it is possible to override the generic informa-tion in specific cases while still retaining the capabilityof accessing the generic information later, as the follow-ing example shows.164 Computational Linguistics, Volume 15, Number 3, September 1989Kathleen Dahlgren, Joyce McDowell, and Edward P. Stabler, Jr.
Knowledge Representation for Commonsense Reasoning with Text61.
What color is an airplane?mTypically, white.John bought an airplane.--OK.What color is the airplane.
- The text does notsay, but typically white.The airplane is red.roOK.What color is the airplane?~The t xt says red.What color is an airplane?--Typically, white.Thus the system uses default logic (Reiter 1980).REASONER, therefore, is sensitive to a number offactors which make the system seem to understand thequeries in a natural way.
The responses generated alsoreflect he continuum of reliability of information whichis available to a human reasoner.
A flow chart of thesearch strategies in REASONER is shown in Figure 3.OntologicolQuestion?0o oo0,l \[ I, o^swer" I I ^nswer'Yes No i rextuolDB I I BUCCO~I r 'r'"?'?'
I~ uooeodTry Inherent Answer:.DB Typico y...Jfall \["~uceeed ~ucceedi i r, lnhnntiI I ~ ucceedAnswer: Answer:.I don't know Inherent y...Figure 3.
The Query System5 NAIVE SEMANTICS AND DISCOURSE PHENOMENA 12Most computational treatments of discourse phenom-ena acknowledge the role of world knowledge in ana-phora resolution, temporal reasoning, and causal rea-soning (Reichman 1985; Grosz and Sidner 1986; Wadaand Asher 1986).
However, in the past the only methodfor encoding and incorporating world knowledge in-volved writing a detailed script for every real-life situ-ation, directly encoding the probable sequence ofevents, participants, and so forth (Schank and Abelson1977).
This section will demonstrate that word levelnaive semantics offers a principled, transportable alter-native to scripts.
NS is a powerful source of informationin discourse reasoning.
Along with syntactic, composi-tional semantic, and discourse cue information, NS canbe used to reason heuristically about discourse anddrive many of the inferences drawn by people whenthey read a discourse.
The role of syntax and composi-tional semantics will be underplayed in what follows,only because these contributions have been thoroughlytreated by others (Reinhart 1982; Asher and Wada 1988;Kamp 1981; Grosz and Sidner 1986; Reichman 1985;Webber 1985).5.1 ANAPHORAIn anaphora resolution, syntactic onstraints, accessi-bility (in the sense of Kamp 1981), and discoursesegmentation work in concert to limit the number ofantecedents available to an anaphoric pronoun or defi-nite NP.
However, it is clear that the resultant saliencystack can end up with more than one member (Asherand Wada 1988).
It is at this point in the reasoning thatnaive inference is required.
Consider the following.62.
Levine's friend is a lawyer.
He won his case forhim.Syntactic rules exclude a reading in which "he" and"him" co-refer.
Since both Levine and the lawyer arepossible antecedents of all of the pronouns and there-fore are both in the saliency stack, the following read-ings remain:63. i. Levine won Levine's case for the lawyer.ii.
Levine won the lawyer's case for the lawyer.iii.
The lawyer won Levine's case for Levine.iv.
The lawyer won the lawyer's case for Levine.Reading (iii) is the one people select.
Generic knowl-edge of "lawyer" suffices to make this selection.
Thegeneric representation of "lawyer" in (9) includes in-formation that lawyers argue cases.
An inspection ofgeneric knowledge for "argue" reveals that one goal ofarguing is winning.
Using these two facts, the systemcan infer that the lawyer won, so the lawyer is thesubject of the sentence.
Thus the benefactee, by dis-jointness, must be Levine.
Now the feature of "lawyer"that says that lawyers represent their clients could beused to figure that the case is Levine's.Turning to definite anaphora, a definite descriptionoften has an implicit antecedent in the discourse, ratherthan an explicit or deictic one.
Unless world knowledgeis used, it is impossible to recover these.
Consider thefollowing.64.
Levine's trial was short.
The testimony took onlyone day.A generic representation of "trial" is shown below.Using it, the antecedent of "testimony" in (65) can beidentified as a part of the trial.65.
trial-Typically, in a trial first there are oaths, state-165 Computational Linguistics, Volume 15, Number 3, September 1989Kathleen Dahlgren, Joyce McDowell, and Edward P. Stabler, Jr.
Knowledge Representation for Comrnonsense Reasoning with Textments and testimony, then the judge instructs thejury, the jury deliberates and announces a ver-dict, and the judge pronounces the sentence.There are roles of witnesses and spectators.
Atrial lasts about three days.Inherently, a trial has roles of judge, clerk, bailiff,attorneys, plaintiff, and defendant.
The goal of atrial is to settle a dispute or determine the guilt orinnocence of a defendant.An interesting subset of definite anaphora is definiteevent anaphora (Asher 1988).
In (66), we know that"decis ion" refers to an event, because it is a deverbalnominal.
Generic knowledge for deverbal nominals isthe same as for verbs.
So we know that there is somedefinite SOCIAL MENTAL event.
Both commentingand sentencing are SOCIAL MENTAL verbs.
Genericknowledge of the verb "sentence"  includes knowledgethat a sentencing is enabled by a decision.
This can beused to infer that the antecedent of "the decision" is thesentencing event reported in the first sentence, ratherthan the commenting event.
Thus e 4 = e I.66.
(el) The judge sentenced Levine to a short term.
(e2) He commented that Levine had been coop-erative.
(e3) The decision (e4) surprised an attorney.If the generic knowledge has an implication which issimilar to the event nominal, the correct antecedent canbe inferred.
The resulting DRS is shown in (67).67.and speech time (now).
In a sequence of simple pasttense clauses, the reference time is updated each time.So in text (66), the temporal equations look as follows.68.
rl < now.el ~ r lr 1 ~ r 2e2 ~ r2r 2 .~ r 3e 3 C I" 3However, the reference time is not always updated by asimple past tense verb.
In addition to the effects ofclause aspect, which will be discussed below, common-sense knowledge affects temporal reasoning.
Twoevents reported in a sequence of simple past tenseclauses can overlap in time, or the second event (intextual sequence) can occur before the first.
Naivesemantic representations are sufficient o assign theserelations correctly in many cases.
The typical implica-tions of events in verb representations can be used toinfer overlap.
Consider the following discourse.69.
(el) Levine made a statement.
(e2) He said he wassorry.We know that a "statement"  is a deverbal nominal of"state,"  and that the goal of "s tate"  and of also "say"is communicating ideas.
This knowledge is used to inferthat e 2 C e 1.The regular temporal presuppositions of implica-tional features on verbs are very powerful in inferringthe relative order of events.
An event e i must occurbefore an event ej in order to cause ej.Xl ,  x2, a 1, e I, x 3, p, e 4, x 3, a2, e2, e3judge(xl)levine(x2)term(a0short(a0el sentence(x~,x2)to(el ,a0he(x3)e2 comment(xa,p)P: s2s2 cooperative(x2)X 3 = X Idecision(e3)attorney(a2)e2 surprise(ea,a2)e 3 = e 15.2 TEMPORAL REASONINGTemporal reasoning involves the assignment of relation-ships among the times of the events reported in thediscourse.
Following the Reichenbachian approach totense found in Partee (1984), there are three elements totemporal reasoning: event time (el), reference time (ri),cause(el,e2) e2 before elenable(el,e2) e 2 before e lgoal(el,e2) e 2 after e !consequence(e I,e2) e 2 after e lwhnext(el,e2) e 2 after e 1when(el,e2) e 2 overlap e 1where(el,e2) e2 overlap e Ihow(el,e2) e 2 overlap elTable 10.
Temporal Presuppositions of Verb ImplicationsTable 10 lists the temporal presuppositions of severalgeneric: features of verbs.
This works well when one ofthe implications of a verb mentions another verb (orrelated verb) in the text, and tense or adverbial modifi-ers do not give clues as to the temporal relations.
In(70), the fact that e2 is a typical cause of el, can be usedto infer that e 2 occurred before e l.70.
(ea) Levine was found guilty.
(e2) He broke thelaw.Similarly, in (71), the fact that buying typically takesplace in stores, can be used to infer that e 2 overlappedel in time.
(The stativity of the verb in the secondsentence is also a weak, but insufficient indicator of thetemporal relationship between the sentences).Computational Linguistics, Volume 15, Number 3, September 1989 166Kathleen Dahlgren, Joyce McDowell, and Edward P. Stabler, Jr.
Knowledge Representation for Commonsense Reasoning with Text71.
(el) Levine bought a book.
(e2) He was in a storeon 5th Ave.Temporal properties of nouns also require naive seman-tics.
Role terms have a temporal element (Enc 1987).
Aterm such as "President of the U.S." has a DURA-TION feature in the naive semantic representation.
Thisenables appropriate inferences concerning the occu-pants of roles.
In (72), the system can infer that theindividual who declared war on insider trading is prob-ably not the same as the one whose office indictedLevine.72.
The Attorney General declared war on insidertrading in 1964.
The Attorney General's officeindicted Levine six months ago.Another way in which naive semantic representationscan be used in temporal reasoning has to do with theassignment of tense to deverbal nominals.
In (73), thenominal "violations" refers to events which can beplaced in time before the sentencing.
Naive semanticknowledge can be used to infer that the violations tookplace before the sentencing, because violations areillegal, sentencing is the fnal stage of a trial, a trialdetermines whether the defendant is guilty, and guiltyparties have done something illegal.73.
Levine, who engaged in massive insider trading,was sentenced to two years in prison.
His viola-tions of the securities laws were shocking.Another way that naive semantics helps temporal rea-soning, comes from the assignment of coherence rela-tions using naive semantics.
How this can be done isdiscussed below (Section 5.4).
Given certain rhetoricalrelations between two clauses, certain temporal rela-tionships are indicated.
Table 11 lists the temporalpredications of certain coherence relations.
The firstgroup are relations which hold between events or states81 and 62, where 81 occurs before 62.
In (74) the systemcan recognize that e I is before e2, once it assigns therelation Cause between them.74.
(e0 Levine broke the law.
(e2) He was indicted.The same thing would work if the sentences were inreverse order in the text.
The second group in Table 1 1lists the coherence relations that indicate that events orstates overlap in time.
The third group lists thoserelations that require that the source event or state is inthe speech time (now).5.3 CLAUSE ASPECTClause aspect refers to the aspect of an entire clause.The classical example in (75) through (77) illustratesdiffering clause aspects with the same verb and tense.
(75) is telic, while (76) and (77) are activity clauses.75.
John pushed the cart under a shed.76.
John pushed the cart under adverse conditions.77.
John pushed the cart.Ciause-stative means not only the opposition between aninherently stative verb and an eventive verb (as in "be"vs. "hit"), but to the various ways in which a whole8 1 and 62---event or state reference markersr~ < rE--reference timesI.
t~ 1 C r l ,  62 C r 2 Elaboration(Si,62), Cause(81,62),Goal(62,81)Evidence(62,80,Enablement(81,62),Comment(62,Sl),2.
81, 62 C_ r I Parallel(81,62), Contrast(81,62),Description(61,62),Qualification(81,62),Evidence(81,62)Generalization(81,62),Import(81,62),3.
62 C_ now Impor t  (62,61) , Evaluation(62,81)Table 11.
Tense and Coherence Relationsclause can end up being stative, as with the presence ofthe progressive, or a number of other factors.
Clause-relic means that the clause reports a change of state witha terminus.
"John built the house" is clause-telic, while"John was building the house" is clause-stative.
A telicclause has an ACHIEVEMENT or ACCOMPLISH-MENT verb not in the progressive, not in the simplepresent (which would be habitual, and with no modal(e.g., "John will build the house" is not telic).
Clause-activity has to do with a clause which reports an eventwhich has no terminus, and which has the sub-intervalproperty (Bennett and Partee 1978), as "John ran.
"Naive semantic knowledge is used to assign clauseaspect.
In (75), naive semantic knowledge that a shed isa PLACE, and generic information of the relative sizesof carts and sheds, can be used to infer that the shedwas a destination for the cart.
An ACTIVITY verb suchas "push," with a destination argument in the verbphrase results in a telic clause.
This inference for (75)would not hold for (76).
Similarly, an ACHIEVEMENTor ACCOMPLISHMENT verb indicates a TELICclause, but other arguments can change them to AC-TIVITY (cf.
Moens and Steedman 1987).
For example,in (78) the clause is TELIC, while in (79) it is ACTIV-ITY, and in (80) it is ambiguous between TELIC andACTIVITY.78.
The prosecutor questioned the point,79.
The prosecutor questioned the witness for anhour.80.
The prosecutor questioned the witness.S.4 COHERENCE RELATIONSCoherence relations are handled in the KT system asadded predicates in a cognitive DRS.
In the DRSrepresenting two clauses connected by a discourse cueword such as "because," a predicate cause(el,e2) isrepresented.
Similarly, where the first event typicallycauses the second, the system guesses the cause rela-tion between the two event reference markers, and aComputational Linguistics, Volume 15, Number 3, September 1989 167Kathleen Dahlgren, Joyce McDowell, and Edward P. Stabler, Jr.
Knowledge Representation forCommonsense R asoning with Textcause predicate is introduced into the DRS, resulting ina cognitive (or inferred) DRS.
Coherence relations areassigned using syntax, temporal relations, clause as-pect, discourse cues, and naive semantics.
An algorithmfor coherence relation assignment has been developed(Dahlgren 1988c, 1989).
This section will illustrate onlythe contribution of naive semantics and will not delveinto the complex problem of the interactions among theseveral sources of information.
Grosz and Sidner (1986)argue that coherence relations are not a useful analyticaltool because no clear, closed set of them has beendiscovered.
However, there is ample psycholinguisticevidence that in constructing the interpretation of atext, and in recalling what it said, coherence relationsare inferred and used by readers (Rickheit and Strohner1985).
In terms of computational linguistics, coherencerelations are useful for text summarization and rele-vance reasoning.
In text summarization, only the gen-eral actions, not the elaborations, can be included in thesummary.
Descriptive and other background clausescan be ignored.
Similarly, relevance can be inferredfrom the causal implications of events reported in a text.If a reader says that he or she wants to read aboutevents that affect the construction i dustry, for exam-ple, and the typical consequence of some event in a textaffects the construction industry, then that reader isinterested in that text.The naive semantic representations of nouns andverbs contain sufficient information to handle a largenumber of cases in which world knowledge is requiredto structure the discourse.
Generic representations ofthe typical implications of verbs such as cause, goal,enablement, and consequence are the very same infor-mation as coherence r lations.
Their content means, " I fthere was an event (or state) of VERBling, then itprobably had as goal a later event (or state) ofVERB2ing."
For example, " I f  there was an event ofbuying, it probably had as goal a state of owning.
"Naive semantic representations contain generalizationsabout objects and actions which are common to alinguistic community, and thus explain the ability tounderstand a discourse without resort to particularscripts describing familiar eal-world situations.Using generic and ontological representations de-rived from psycholinguistic data, coherence relationscan be assigned.
To infer goal(el,e2) for text (81),knowledge that "profit" is money can be used to relate(e2) to the the goal feature of "invest."81.
(e0 John invested heavily.
(e2) He made a hugeprofit.Some of the naive semantic representation f "invest"is shown below:82.
Investing is typically lucrative and is accom-plished with money.
Inherently, sentients do theinvesting with the goal of making money.Similarly, in (83), the generic entry for "insider trading"can be used to infer that Levine broke the law.
Theentry associated with reading 1 of the verb "charge," asshown in Table 9, includes information that a typicalcause of charging someone is that that someone hascommitted a crime.
Putting these two together,cause(el,e2) can be inferred.83.
(e0 Levine engaged in insider trading.
(e2) The government charged him with violationsof the securities laws.The segmentation f discourse takes into account para-graphing, discourse cues such as Turning to .
.
.
.
Insummary, clause aspect, temporal relations, and coher-ence relations.
In this section we will briefly illustratethat nai, ve semantics is one source of information indiscourse segmentation.
I  narrative, a clear distinctioncan often be made between segments consisting ofsequences of actions that are the foreground of thenarrative, and segments hat provide the background orsetting for the action.
If the author does not give cleardiscourse cues of the switch to a setting or situationsegment, he shift can be inferred using naive seman-tics.
In our method, discourse segments are related toeach other the same way as clauses (as in Mann andThompson \[1987\] and Hobbs \[1985\]), so the relationshiphere is one of situation_activity(Seg2,Segl) where Seglis a sequence of actions.
Consider (84).84.
Levine engaged in insider trading at his firm.
Hewas charged and found guilty of violations of the,securities laws.
He was sentenced by JudgeGoetteL Levine was happy at his f irm.
The audi-ence waited with baited breath to hear whatJudge Goettel would say.In the text, there is a change of segment at "Levine washappy at his firm."
The segment is a SITUATION-ACTIVITY segment.
It describes what was going onwhen Levine was engaging in illegal practices.
Thechange from a sequence of actions to a backgroundsegment is indicated by several factors, including theuse of the stative and the place adverbial.
Anotherfactor is naive semantic knowledge of "f irm."
Workingtakes place at a firm, and this knowledge can be used toinfer that "Levine was happy at his firm" refers to along-term situation in which Levine was working.
Inthat situation, he was happy.
Thus the sentence is notabout some specific action, but is a generalization aboutLevine's condition as a worker.
Such a generalizationindicates a change of segment from a sequence ofactions to a SITUATION_ACTIVITY segment.6 CONCLUSIONNaive semantics i a level of cognitive representation fconcepts that can be discovered empirically and repre-sented in a principled way with FOL without resort o aspecial knowledge representation language.
BecauseNS representations are linked to ordinary words and donot depend on a special knowledge representation level,they should be transportable from one text to another.The KT system demonstrates that these rich represen-168 Computational Linguistics, Volume 15, Number 3, September 1989Kathleen Dahlgren, Joyce MeDowell, and Edward P. Stabler, Jr.
Knowledge Representation for Commonsense Reasoning with Texttations are powerful in resolving many of the largeresidue of ambiguities that remain after the work of apurely syntactic parser is completed.REFERENCESAbbott, V.; Black, B. J.; and Smith, E. 1985 The Representation ofScripts in Memory.
Journal of Memory and Language 24(1):179-199.Ashcraft, M. H. 1976 Property Norms for Typical and Atypical Itemsfrom 17 Categories: A Description and Discussion.
Memory andCognition 6(3):227-232.Asher, N. 1987 A Typology for Attitude Verbs and Their AnaphoricProperties.
Linguistics and Philosophy 10:125-198.Asher, N. 1988 The Semantics for Proposition-type Nominals andProposition-type Anaphora.
Paper presented at the University ofTexas Conference on the Structure of Events and Natural Lan-guage Metaphysics.Asher N. and Wada, H. 1988 A Computational Account of Syntactic,Semantic and Discourse Principles of Anaphora Resolution,Forthcoming in Journal of Semantics.Bennett, M. and Partee, B.
1978 Towards the Logic of Tense andAspect in English.
Indiana University Linguistics Club: Blooming-ton, IN.Boyd, R. 1986 Natural Kinds, Homeostasis and the Limits of Essen-tialism.
Forthcoming.Brachman, R. J.; Gilbert, V. P.; and Levesque, H. J.
1985 AnEssential Hybrid Reasoning System.
Proceedings of the Interna-tional Joint Committee on Artificial Intelligence.
IJCAI 1:532-539.Chang, C.-L. and Lee, R.C.-T. 1973 Symbolic Logic and MechanicalTheorem Proving.
Academic Press, New York, NY.Crain, S. and Steedman, M. 1985 On Not Being Led Up the GardenPath: the Use of Context by the Psychological Syntax Processor.In Natural Language Parsing, David R. Dowty, Laun Karttunenand Arnold M. Zwicky, (Eds.)
Cambridge University Press,320-358.Dahlgren, K. 1985a The Cognitive Structure of Social Categories.Cognitive Science 9:379-398.Dahlgren, K. 1985b Social Terms and Social Reality.
Folia Linguis-tica Historica 6:107-126.Dahlgren, K. 1988a Naive Semantics for Natural Language Under-standing.
Kluwer Academic Press, Boston, MA.Dahlgren, K. 1988b Using Commonsense Knowledge to Disambigu-ate Word Senses.
In: F. St. Dizier and V. Dahl, Eds., NaturalLanguage Understanding and Logic Programming 2.
North Hol-land, Amsterdam.Dahlgren, K. 1988c Coherence Relation Assignment.
Proceedings ofthe West Coast Conference of Linguistics, Fresno, CA.Dahlgren, K. 1989 Coherence Relations and Naive Semantics.
Papergiven at the Symposium on Modelling Discourse Structure: Dis-course Segments and Discourse Relations, University of Texas,Austin, TX.Dahlgren, K. and McDowell, J.
1986a Kind Types in KnowledgeRepresentation.
Proceedings of the l l th International Conferenceon Computational Linguistics (COLING-86).Dahlgren, K. and McDowell, J.
1986b Using Commonsense Knowl-edge to Disambiguate Prepositional Phrase Modifiers.
Proceed-ings of the American Association for Artificial Intelligence 86.Dowty, D. R. 1979 Word Meaning and Montague Grammar.
D.Reidel Publishing Company, Dordrecht, Holland.Enc, M. 1986 Towards a Referential Analysis of Temporal Expres-sions.
Linguistics and Philosophy 9:405--426.Fahlman, S. 1979 NETL: A System for Representing and UsingReal-World Knowledge.
MIT Press, Cambridge, MA.Ford, M.; Bresnan, J.; and Kaplan, R. 1981 A Competence-BasedTheory of Syntactic Closure.
In: Joan Bresnan, Ed., The MentalRepresentation of Grammatical Relations.
MIT Press, Cam-bridge, MA.Frazier, L. and Fodor, J.D.
1978 The Sausage Machine: A NewTwo-stage Parsing Model.
Cognition 6:291-325.Gabbay, D.M.
and Sergot, M.J. 1986 Negation as inconsistency.Journal of Logic Programming 1:1-35.Gelman, R. and Spelke, E. 1981 Thoughts about Animate andInanimate Objects.
In: J. H. FlaveU and L. Ross (Eds.
), SocialCognitive Development.
Cambridge University Press, Cambridge,England.Graesser, A. and Clark, L. 1985 Structure and Procedures oflmplicitKnowledge.
Ablex.
Norwood, NJ.Graesser, A. and Hopkinson, P. 1987 Differences in InterconceptOrganization between Nouns and Verbs.
Journal of Memory andLanguage 26.Grosz, B. and Sidner, C. 1986.
Attention, Intensions, and the Struc-ture of Discourse.
Association for Computational Linguistics12:175-204.Hobbs, J.
1985 On the Coherence and Structure of Discourse.
CSLIReport # CSLI-85-37, CSLI, Stanford University, Stanford, CA94305.Huttenlocher, J. and Lui, F. 1979 The Semantic Organization of SomeSimple Nouns and Verbs.
Journal of Memory and Language18:141-162.IBM 1985 VM Programming in Logic (VM/PROLOG), ProgramDescription and Operations Manual, IBM Corporation.Ioup, G. 1975 Some Universals for Quantifier Scope.
In: J.
Kimball(Ed.
), Syntax and Semantics 4.
Academic Press, New York, NY.Jackendoff, R. 1985 Semantics and Cognition.
MIT Press, Cam-bridge, MA.Johnson-Laird, P. N. 1983 Mental Models.
Harvard University Press,Cambridge, MA.Kamp, H. 1981 A Theory of Truth and Semantic Representation.
In:J. Groenendijk, Th.
Janssen, and M. Stokhof, Eds., FormalMethods in the Study of Language.
Mathematisch Centrum,Amsterdam: 277-322.Karttunen, L. 1971 "Possible and Must."
Syntax and Semantics 1,1-20.
Academic Press, New York, NY.Katz, J.J. 1972 Semantic Theory.
Harper & Row, New York, NY.Keil, F. C. 1979 Semantic and Conceptual Development, HarvardUniversity Press, Cambridge, MA.Labov, W. 1973 The Boundaries of Words and Their Meanings.
In:C-J.
N. Bailey and R. Shuy (Eds.
), New Ways of AnalyzingVariation in English.
Georgetown University Press, Washington,D.C.Lakoff, G. 1985 Women, Fire and Other Dangerous Things.
Univer-sity of Chicago Press, Chicago, IL.Lloyd, J.W.
1984 Foundations of Logic Programming.
Springer-Verlag, New York, NY.Mann, W. and Thompson, S. 1987 Rhetorical Structure Theory: ATheory of Text Organization.
ISI Reprint Series: ISI-RS-87-190.USC Information Sciences Institute.
Marina del Rey, California90292.McCord, M. 1985 The Lexical Base for Semantic Interpretation i aProlog Parser.
Presented at workshop on the Lexicon, Parsing andSemantic Interpretation.
City University of New York GraduateCenter.McCord, M. 1987 Natural Language Processing in Prolog.
In: A.Walker, Ed., Knowledge Systems and Prolog.
Addison-Wesley,Reading, MA.McDoweU, J.
1987 Assertion and Modality.
Ph.D. dissertation.
Uni-versity of Southern California, Los Angeles, California 90089.McDowell J. and Dahlgren, K. 1987 Commonsense R asoning withVerbs.
Proc.
IJCAI.Miller, G. 1978 Practical and Lexical Knowledge.
In: E. Rosch and B.B.
Lloyd (Eds.
), Cognition and Categorization.
Erlbaum, NewYork, NY.Computational Linguistics, Volume 15, Number 3, September 1989 169Kathleen Dahlgren, Joyce McDowell, and Edward P. Stabler, Jr.
Knowledge Representation for Commonsense Reasoning with TextMoens, M. and Steedman, M. 1987 Temporal Ontology in NaturalLanguage.
Proceedings of the Association for ComputationalLinguistics; 1-7.Partee, B.
1984 Nominal and Temporal Anaphora.
Linguistics andPhilosophy 7:243-286.Putnam, H. 1975 The Meaning of 'Meaning'.
Mind, Language andReality, Cambridge University Press, Cambridge, England.Reichman, R. 1985 Getting Computers to Talk Like You and Me.
MITPress, Cambridge, MA.Reinhart, T. 1982 Principles of Gestalt Perception in the TemporalOrganization of Narrative Texts.
Manuscript.Reiter, R. 1980 A Logic for Default Reasoning.
Artificial Intelligence13:81-132.Rickheit, G. and Strohner, H. 1985 Inferences in Text Processing.North-Holland, Amsterdam.Rosch, E. 1975 Cognitive Representations of Semantic Categories.Journal of Experimental Psychology-General 204:192-233.Rosch, E. and Mervis, C. B.
1975 Family Resemblances.
CognitivePsychology 7:573-605.Rosch, E.; Mervis, C. B.; Gray, W. D.; Johnson, D. M.; andBoyes-Braem, P. 1976 Basic Objects in Natural Categories.
Cog-nitive Psychology 8:382--439.Schank, R. C. and Abelson, R. P. 1977 Scripts, Plans, Goals andUnderstanding.
Erlbanm, Hillsdale, NJ.Schubert, L. K.; Goebel, R. G.; and Cercone, N. J.
1979 TheStructure and Organization of a Semantic Net for Comprehensionand Inference.
In: N.V. Findler (Ed.
), Associative Networks.Academic Press, New York, NY.Searle, J. and Vanderveken, D. 1985 Foundations of lllocutionaryLogic.
Cambridge University Press, Cambridge, England.Smith, E. E. and Medin, D. L. 1981 Categories and Concepts,Harvard University Press, Cambridge, MA.Steedman, M. 1977 Verbs, Time, and Modality.
Cognitive Science1:216-234.Sterling, L. and Shapiro, E. 1986 The Art of Prolog: AdvancedProgramming Techniques.
MIT Press, Cambridge, MA.Stickel, M. 1986 A Prolog technology theorem prover: implementa-tion by an extended prolog compiler.
Proceedings of the 8thInternational Conference on Automated Deduction, J.
Siekmann(ed.)
Lecture Notes in Computer Science Volume 230.
Springer-Verlag, New York, NY.Strawson, P. C. 1953 Individuals.
Methuen, London, England.Trabasso, T. and Sperry, L. L. 1985 Causal Relatedness and Impor-tance of Story Events.
Journal of Memory and Language 24.1:595--611.Trabasso, T. and van den Brock, P. 1985 Causal Thinking and theRepresentation of Narrative Events.
Journal of Memory andLanguage 24.5:612--630.Vendler, Z.
1967 Linguistics in Philosophy.
Cornell University Press,Ithaca, N'Y.Wada, H. and Asher, N. 1986 BUILDRS: An Implementation f DRTheory and LFG.
Proceedings International Conference on Com-putational Linguistics 540-545.Webber, B. L. 1985 Discourse Model Synthesis.
In M. Brady and R.Berwick, Eds., Computational Models of Discourse.
MIT Press,Cambridge, MA, 267-330.NOTES1.
Dahlgren and McDowell are the main investigators.
Stablercontributed the first-order logic and problem solver.2.
Nominalized verbs are treated as verbal concepts.3.
We are exlLremely grateful to Hajime Wada who wrote theoriginal version of the DRT module to provide DRSs for a widerange of syntactic onstructions.
The present DRT module is anextension of his work.
The lexical entries that form the NS databases are the result of the careful, diligent efforts of Carol Lord,Robert Hagiwara, and Susan Mordechay.
Susan Hirsh contrib-uted the programs that generate the FOL data bases andperformed other programming tasks.4.
The atoms subj, obj, obliq, pobj, which appear in the genericrepresentations, signal which element of the sentence is to beaccessed for the output response.
In answering questions, thegeneric representations are mapped to a small set of canonicalsentences whose slots are filled with elements from the inputquery.
Consider the feature representation implies(merchandise(obj)), which is part of the generic entry for buy.
If the queryWhat is implied if a man buys a truck?
is processed, since thedirect object of buy in the query is truck, the response is thetruck is merchandise.
If the query had been What is implied ifJohn buys a house?, the response would be the house ismerchandise.5.
The analysis work was originally reported in Dahlgren andMcDowell (1986b).
We review that here and also report on theimplementation.6.
For the most part, examples given in this paper are modifiedversions of actual sentences from the WSJ corpus that the KTresearchers are using.7.
For readability, the remaining eneric entries will be shown inEnglish paraphrase rather than as they are coded.8.
The question arises as to how natural or likely such sentenceswould be in use.
For example, would we be more likely toencounter a letter from all the lawyers rather than a letter fromevery lawyer.
The standard answer, which we adopt, is thatsemantics i not a predictive theory.
We can't tell what a personwill say, but we have to be able to interpret whatever is said.
Wecan restrict ourselves to likely expressions, but then we areputting ourselves in the position of predicting what is likely, andwe might be wrong.
We prefer to try to interpret what ispossible, even if unlikely.9.
A full theoretical discussion of the issues involved with medalscan be found in McDowell (1987).10.
The main predicate of a clause, whether it be a verb or a termthat is the complement of the copula, carries a DR-theoreticevent-type reference marker as its tense argument.
Other pred-icates carry an argument which is linked to tense, but which isnot a reference marker in DR-theoretic terms.11.
Actually, sentences interpreted as generics in English have acomplex combination of the following features: indefinite NPs,present tense, copula, and/or inherently stative verb (but not theprogressive).
Not all of these features are always present in allgenerically interpreted sentences.12.
In ~Lhis and the following sections we report on work in progressthat is not yet fully implemented.Computational Linguistics, Volume 15, Number 3, September 1989 170
