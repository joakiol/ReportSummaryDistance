Lexicalized Tree Automata-based Grammars forTranslating Conversational TextsKiyoshi YAMABANA Shinichi ANDO Kiyomi MIMURAComputer & Communication Media Research, NEC Corporation4-1-1, Miyazaki, Miyamae-ku, Kawasaki 216-8555, JAPANk-yamabana@ct.jp.nec.com s-ando@cw.jp.nec.com k-lnimura@dad p.nec.comAbstractWe propose a new lexicalizcd grammarformalism called Lexicalized TreeAutomata-based Grammar, which lcxicalizestree acccptors instead of trees themselves.
Wediscuss the properties of the grammar andpresent a chart parsing algorithm.
Wc haveimplemented a translation module forconversational texts using this formalism, andapplied it to an experimental automaticinterpretation system (speech translationsystem).1 IntroductionAchieving both broad coverage for general textsand better quality for texts from a restricted omainhas been an important issue in practical naturallanguage processing.
Conversational language is atypical domain this problem has been notable, sincethey often include idioms, colloquial expressionsand/or extra-grammatical expressions while amajority of utterances still obey a standardgrammar.Furusc and Iida (1994) proposed an approach tospoken-language translation based on patternmatching on the surface form, combined with ancxalnple-based disambiguation method.
Since thegrammar rules are simple patterns containingsurface expressions or constituent boundaries, theyare easy to write, and domain-specific knowledgecan be easily accumulated in the grammar.
On theother hand, relationships between two trees arc noteasy to describe, especially when they are separatedapart on a larger tree.
This might become anobstacle in expanding a domain-specific grammarinto a general gralnlnar with a wide coverage.Brown (1996) approached to this problememploying a nmlti-engine architecture, whereoutputs from Transfer Machine Translation (MT),Knowledge-based MT and Example-based MT arecombined on the chart during parsing.
Ruland et al(1998) employs a multi-parser multi-strategyarchitecture for robust parsing of the spokenlanguage, where the results fi'om different enginesare combined on the chart using probability-basedscores.
A difficult part with these hybridarchitectures is that it is not easy to properlycompare and combine the results fi'om differcntengines designed on different principles.
In addition,these methods will require much computationalpower, since multiple parsers have to be runsimultaneously.A third approach, such as Takeda (1996), isgrammar-based.
In this approach, a method isprovided to associate a grammar ule to a word or aset of words in order to encode their idiosyncraticsyntactic behaviour.
An associated grammar rulecan be sccn as a kind of example if it is describedmostly by the surface level information.
As isapparent fl'om this description, this approach is anapplication of strong lexicalization of a grammar(Schabes, Abeill6 and Joshi, 1988).This approach allows coexistence of generalrules and surface-level patterns in a uniformframework.
Combination of both types of rules isnaturally defined.
These advantages arc a goodreason to employ strongly lexicalized grammars asthe basic grammar formalism.
However, wc feelthere are some points to be improved in the currentstrongly lcxicalized grammar formalislns.The first point is the existence of globallydefined special tree operation, which requires aspecial parsing algorithm.
In a strongly lexicalizedgrammar formalism, each word is associated with afinite set of trees anchored by that word.
The treeoperations usually include substitution of a leafnode by another tree, corresponding to expansion ofa nonterminal symbol by a rewriting rule in CFG.However, if the tree operation is limited tosubstitution, the resulting grammar, namelyLexicalized Tree Substitution Grammar (LTSG),cannot even reproduce the trees obtained fi'omnon-lexicalized context free grammars.
This will beobvious from the fact that for any LTSG, there is a926constant such that, in any trees built by thegrammar, the distance of the root node and thenearest lexical item is less than that constant, whilethis property does not always hold for CFG.
TreeInsertion Grammar (TIG), introduced by Schabes etal.
(1995), had to be equipped with the insertionoperation in addition to substitution, so that it canbe strongly equivalent to an arbitrary CFG.
Theinsertion operation is a restricted form of theadjoining operation in the Lexicalized TreeAdjoining Grammar (LTAG) (Joshi and Schabes,1992).Thus, a special tree operation other thansubstitution is inevitable to strongly lexicatizedgrammars.
It is needed to grow an infinite numberof trees from a finitely ambiguous set of initial treesrepresenting the extended domain of locality(EDOL) of the word.However, such special tree operation requires aspecially devised parsing algorithm.
In addition, thealgorithm will be operation-specific and we have todevise a new algorithm if we want to add or modifythe operation at all.
Our first motivation was toeliminate the need for globally defined special treeoperations other than substitution wheneverpossible, without losing the existence of EDOL.Another point is the fact that lexicalization isapplied only to trees, not to the tree operations.
Forexample, in LTAG, initial tree sets anchored to aword is not enough to describe the whole set oftrees anchored by that word, since initial trees aregrown by adjunction of auxiliary trees.
Since anauxiliary tree is in the EDOL of another word, theformer word has limited direct control over whichauxiliary tree can be adjoined to certain node.
Fordetailed control, the grammar writer has to giveadditional adjoining restrictions to the node, and/ordetailed attribute-values to the nodes that cancontrol adjunction through node operations uch asunification.In short, we would like to define a lexicalizedgrammar such that 1) tree operation is substitutiononly, 2) it has extended omain of locality, and 3)tree operations as well as trees are lexicalizedwhenever possible.
In the next section, we proposea grammar formalism that has these properties.2 Lexicalized Tree Automata-basedGrammarsIn this section we introduce Lexicalized TreeAutomata-based Grammar (LTA-based Grammar)and present i s parsing algorithm.First, we define some basic terminologies.
Agrammar is strongly lexicalized if it consists of 1) afinite set of structures each associated with a lexicalitem; each lexical item will be called the anchor ofthe corresponding structure, and 2) an operation oroperations for composing the structures (Sehabes,Abeilld and Joshi, 1988).In the following, the word "tree automaton"(TA) will be used as a generic term for anautomaton that accepts trees as input.
It can be afinite tree automaton, a pushdown tree automaton,or any tree-accepting automaton having a state set?state transitions, initial and final states, and optionalmemories associated with states.
Although ourargument below does not necessarily requireunderstanding of these general TAs, definitions andproperties of finite and pushdown TAs can be foundin G6eseg and Steinby (1997) for example~2.1 Definition of LTA-based GrammarsThe basic idea of an LTA-based grammar is toassociate a tree automaton toeach word that definesthe set of local trees anchored to the word, insteadof associating the trees themselves.
The lexicalizedtree automaton (LTA) provides a finiterepresentation f a possibly non-finite set of localtrees.
This differs from other lexicalized grammarsas LTAG, where non-finiteness of local trees isintroduced through a global tree operation such asadjunction of auxiliary trees.We define a lexicalized tree automata-basedgrammar as follows.
LEt X be a set of terminalsymbols (words), and NT be the set of nonterminalsymbols disjoint fi'om 27.
Let Tw be a set of trees(elementary trees) associated with a word w in 2:.. Atree in Tw has nodes either from 27 or from N1, andits root )and one of its leaves are marked by adistinguished symbol self in NT.
Let A,v be the treeautomaton lcxicalized to the word w, which acceptsa subset of trees obtained by repeatedly joining twotrees in Tw at the special nodes labelled selfi one atthe root of a tree and the other at a foot of anothertree.
From this definition~ A1, can be identified witha string automaton; its alphabets are the trees in Tw,and a string of the elementary trees are identifiedwith the tree obtained by joining the elementarytrees in a bottom-up manner.
Sw is a set ofnonterminal symbols associated with the word WoThey are assigned to the root of a tree when the treeis accepted by A,~f For each word w, the set A,, l T,,, A,v, Sw} is theset of local trees associated with w. The structure isdescribed by Aw and 1'w~ the symbol at the root node927is fl-om Sw, and se./fin the loot is identified with w.We denote the family of Aw as A = {A,,,} for w in Z.A lexicalized tree automata-based grammar G isdefined to be the tree algebra whose trees are theset union of Aw for all w in Z', and the basic treeoperation being the substitution, that is, joining twotrees at the root node and a foot node when theyhave the same nonterminal in NT other than self.2,2 Some Remarks1 Strictly speaking, the definition above doesnot satisfy the definition of strongly lexicalizedgrammars that the structures associated to a wordmust form a finite set, since the tree set accepted bythe automaton may be an infinite set.
However,since a finite device, namely an automaton,describes this possibly infinite set, we will classifythe proposed formalism as a strongly lexicalizedgrallllTlar.2 We defined the lexicalized tree automatausing string automata where the alphabets are trees.The latter is obtained by linearizing the constituenttrees along the spine of the tree.
Because the I/I'Acan be any tree automaton as long as it accepts alland only the (possibly infinite) tree set beaded by aword, LTA are essentially tree automata.
Theseequivalent wo pictures (the tree automata pictureof a tree grammar and the string automata pictureemployed in the definition) will be usedinterchangeably in this paper.3 The grarnmar G can also be defined by a treeautomaton T that accepts all and only the trees ofthe grammar as follows: First we regard NT as theset of states of T. Its initial states are .Z', and thefinal states are also NT.
Sw is regarded as the set offinal states of A ....
The set of initial states ofAw arethe set of nonterminal symbols that appear in T,,.and w. The LTAs are combined into T through thecommon state set NT.
The recognition era  tree tproceeds in a bottom-up manner, beginning at theleaf nodes that are initial states for G and for someAw.
When a subtree of T has been recognized by anLTA Aw, its root node is in a state s fl'om S,,.
I fs  isXP- / \ Adjunction tO X' canSpecifier X" / \occur  arbitrary times\ X'/ ~ adjunctX complenletltFigure I.
General fOllll o1" X-bar theoryan initial state of another LTA A,., the recognitioncan proceed.
The tree t has been successfullyrecognized if the recognition step arrives at the rootnode.2.3 ExamplesAdjunetion in the X-bar TheoryWe demonstrate how the proposed formalismhandles the simplest case of an infinite set of thelocal trees.
The example is repeated adjunction atthe bar level 1 of the X-bar theory.
Figure I showsa general scheme of the X-bar theory.
X' at the barlevel 1 can be paired with some adjunct arbitrarytimes betbre it grows to the phrase level, XP.Figure 2 shows how this scheme is realized in theLTA-based grammar tbrmalism.
Figure 2 (a) showsthe tree set associated with the word.
It consists ofthree trees, corresponding to the bar levels.
r3 is forthe complement, "r2 for adjunction, and T3 for thespecifier.
(b) shows the tree automaton associatedwith this word in the (tree-alphabet) stringautomaton representation.
It first accepts "I'~, then"I'2 arbitrary times, finally T3 to arrive at the finalstate.
This sequence is identified with the trees in(d), obtained by concatenating "Fi through T3 in abottom-ut) manner.
When the ETA arrives at thefinal state, the root node is given a nonternlhmlsymbol lYom the set in (c), which is XP.Tree Adjoining LanguageFigure 3 shows a I~I'AG that generates a strictlycontext sensitive language anb"ec'~d n. The uniqueinitial tree 7" in (a) is adjoined repeatedly by theunique auxiliary tree A in (b) at the root nodelabeled S. The root and foot of A is labeled S, butadjunction to them is inhibited by the index NA.
(c)shows a tree obtained by adjoinhlg A once to T.Generally a string a"b"ec"d" is obtained as the yieldTzsell"T i I \sell" colnplementsell" sell"sell" adjunct spccil\]cr selfsell `=.
XP/ \specifier sell" re/waledsell"\\ a4iuncIself ~ complcn~enl(a) Tree set T,,, (d) accepted trees(b) -rree {ltitoln\[ll()n a,,, in Jls TI .
T.,n .
.r3tree sequence r presentation(c) set of start s) mbol S,,, {Xl':Figure 2.
I/fA?representation f the tree in Figure 1.928S S,,A S 'xe a S cb S,',:\ ca) initial tree ab) auxil iaD' tree ec) "1" adjoined onceFigure 3: LTAG tbr a"b'~ecIkt ''Ca) '.voi'd(b) tree setsell"a sell" dF Iself" / ?
\h self c?
I 2(C) tree autonlaton(Te).(Ti).
(d) slari symbols ~,<,jse l l -  F,a ~ db set f cb se l f  cIsell ":~ e(c) trec til l  i!
:: 2Figure 4: l,TA-based grallllllar lilt a'%"ec"d"era tree produced by adjoining :I n-times to T.The same language can be expressed by anIM'A-based grammar shown in l:igure 4.
"lhe wordis e Ca).
The tree set associated \rich e consists oftwo trees TI and 'I', as shown in (b).
The localautomaton is a pushdown automaton that acceptstree sequence (Tx)n(Tl)n, and accepted trees aregiven the nonterminal symbol S as in (d).
(e) showsa Wee with n = 2.
From this setting, it is apparentthat ibis l,l 'A-based grallllnar generates the samelanguage as the TAI, in the figure 3.By extending this construction, it will be obviousthat for any I/FAG, all equivalent 171'A-basedgrammar can be constructed within the class ofpushdown LTA.2.,4 Pars ing ,  LTA-based  GramnlarsParsing algorithm lbr the I/l'A-based granlnlar isa <;traiglltforward extension of the CFG case.
In theCFG case, an active edge is represented by arewriting rule with a dot in the right hand side.
Thedot shows that the terminals and ilOll-termillals upto that location have been ah'eady t'(')tllld, and therule application becomes a success when the (lotreaches the end of the rule.
If we regafd  theright-haild side of a rule as an automaton acceptinga sequence of terminals and non-terminals, with theclot representing the current state, this picture canbe easily generalized to the LTA-based grammarcase .Figure 7 shows an example parse for the sentence"'He eats dinner".
Figure 5 shows the dictionarycontent of the verb "'eats", which is basically thesame as llgure 2.
Figure 6 shows the dictionary of"he" and "dinner".
We suppose here that thesewords have no associated trees for simplicity.
Thebasic strategy is left to right bottom-up chartpall s ing .First, edges el, e, and e3 are loaded into the chartand set to the initial state.
They correspond to "'he","'eats" and "'dinner" respectively.
The parsingproceeds from left to right, and the parser triggersthe I,TA of el first.
Since its only possibletransition is a null transition, it arrives at the llnalstate immediately and creates an edge e4 labelled,~,'111)/.Then the focus moves one step to the right on thechart and the I,TA of e, is activated.
It tries to findHie tree T,I, and finds that an edge labelled d(;D isnecessary to its right.
Since there is no such edge,the I/I'A creates an active edge t with a hole Uoh, asin the case of'CFG, and the I/I'A goes into a pausewaiting tBr the hole to be filled.Creation of e5 from e3 is simihu" to the creation of% t'rorn el.
Then e5 starts the completion step as inthe CI:(I case.
At this step, the active edge createdabove is fouild, and es is found to match the hole.Then the I/FA of e, is reactivated, arrives at thestale Sl, then creates an edge ca.Next the I/I'A of e(, is actiwited.
It tries to find"t'a, or Ta3 In searching for Ta;, an active edge witha hole t)o.vlmcJd is created.
While searching for Ta,,the I.TA finds that an edge labelled mutT/to the leftr,, __ i- _(--~df_) ( dob )C~dC> <i, >Ta3 ~ "~ 2final state : sen le / i ceCa) tree set (b) tree automatonFigure 5:1 ,TA of"eats"I .,\miv?
edges are not shm~n hi the lT~tm:929final state su\]Tj final state :s'ubj Idob t prepol!jhe dinnerFigure 6: LTAs o f "he"  and "'dirmer'"is what is necessary, and finds that e4 satisfies thiscondition.
By accepting Ta2, tile LTA creates theedge ev, label it as senlence and advances to tilefinal state.
There is no more possible action on theChart, and the parsing is completed successlhlly.Please note that the algorithm exemplified abovedoes not depend on the concrete form of LTA.
Thesatne algorithm can be applied to pushdownatttomata and other class of automata havinginternal memories.3 Translation ModuleWe buih a bi-directional translation system betweenthe ,lapanese and English languages usitlg theproposed method.
It translates conversational textsas will appear in a dialogue between two people, tohelp them communicate in a foreign travel situation.Figttre 8 shows an overview of the system.3.1 Translation EngineSince each word in tile dictionary has its own treeset and tree automaton, a simple implementationwill lead to inefficiency.
To cope with this problem,we provided two mechanisms to share tile UI'A.
A"rule template" mechanism is provided to share thetriplet, tmrnely Aw it1 tile definition of I+TA, while a"'shared tree" mechanism is provided to sllare theelementary trees among different A+.The rule template is applied just after dictionaryloading, and assigns an LTA to a word that matchesthe condition in tile template.
It is mainly used forwords such as cotnmon nouns.
A shared tree isrepresented by a pointer to an elementary tree in thepool, and is loaded into the systetn when it is tisedlbr tile first time.The language conversion method is based onsynchronous deriwttion of analysis and generationtrees, basically the same as the syntax directedtranslation by Aho and Ulhnan (1969) and thesynchronous LTAG by Shieber and Schabes (1990).In this method, elementary analysis tree of eachword is paired with another tree (elementarygeneration tree).
Starting from the root, at each(?-A ~4AL?I".. C-c,,-s~bI I +3 / '~__ I +,r~777- -~ suh l  - I I ~- 85 ,)1% "+T .
e: !
I ,  e.; * .
.he i - ' eats dinner iFigure 7: ExamlJle Parsenode of the analysis tree+ the direct descendantnodes are reordered in the generation tree,according to tile correspondence of elementaryanalysis and generation trees.
Tiffs translationmechanisna is basically independent of how theanalysis tree is constructed, hence the grammarl'ornmlistri.
In our implerrientation, the gerlerationtree is a call graph of target language generatingftirmtioils, which enables detailed proceduralcontrol over the syntactic generation process.3.2 Grammars and Dictionaries forEnglish to Japanese Transh l t ionThe English to Japanese translation grammar anddictionary has been developed.
In order to achievewide coverage for general input and high qualityfor tile target dolnain, we developed generalgramrrlar l't.iles and donlain-specific rulessinltlltaneot, isly.
(\]eneral rules are based on astandard X-bar theory.
Nodes of a tree areassociated with attribute-value structure in astandaM way.
As nonterminals, we employed agrammatical function-centered approach as lankGrammar (Sleator and Temperley, 1991).
A phraseInputi,,+ ++I__ I /~c  Tcn'i +>tatcsj~ Grammar R,tos ~ i,al A~na++ ~ ~  _ _t ,Z,L,,<,,,Cy x,<,,,,,,<,,<,<+_,,<<+i _  ~Jt.
d ......\[ ()12,/C,'\[}t ll.ll\]\]1 J}Output t %K( I I '~2-~( I  }' I '+~}'okl - l l>O I\[I\])UI'-H ,~J<J " m/h'-~ub\] l/llillt'l'-d++ti C+HFigut'e 8: Trai~slatior~ Modttle930level node is assigned attribute-values that expresstheir syntactic ftlnction Stlch as subject, directobject, etc, instead of a single part-of-speechsymbol such as NP.
This approach is suitable tocapture idiosyncratic behaviour of words.Domain-specific rules are mostly pattern-likerules with special attention to aspects that areimportant for carrying conversations, such asmodality and the degree of politeness.
The Englishto Japanese translation dictionary contains aboutseventy thousand words.
The number of words thatrequired individual I,TA was a few thousand at tiletime of this report.3?3 Current Status of ImplementationThe system has been iml~lemented using C++,and runs on Windows 98 and NT.
The requirelnentis Pentium I\] 400MItz or above for tile CPU~ about61) MB of memory, and 200 MB of  disk space.Most of the disk space is used for statistical data fordisambiguation.We performed a preliminary evaluation of thetranslation quality of l';nglish to Japanesetranslation.
A widely used COlnmercial systeln waschosen as a reference system, of which thedictionaries were expanded for the target domain,t:ive hundred sentellces were randomly chosen froma large (about 40K) pool of conversatiolml texts ofthe target domain.
'\['hen the output of our systemand the reference system were mixed, and thenpresented to a single evahmtor at a random order.The evaluator classified them into (Bur levels(natural, good, understandable and bad).
The resultshowed that tile number of sentences classified to"'natural" increased about 45% compared to that oftlle reference system, i.e.
tile ratio of the ntlmber ofsentences was arotllld 1.45.
The ntllllber o|"sentences classified as "bad" decreased about 40%in the same measure.We applied this module to an experimentalspeech translation system (Watanabe t al., 2000).4 l)iscussionsThe proposed granllnar fornlalism is a kind oflexicalized granll'nar fcnTnalisnl and shares itsadvantages.
The largest difference frolll otherstrongly lexicalized granunar tbrnlalisms is that itemploys lexicalized tree automata (I,TA) todescribe the tree set associated with a word, whichallows a finite description of a non-finite set oflocal trees.
These automata's role is equivalent oadditional tree operations in other formalisms.
Inaddition, an LTA provide an extended domain oflocality (EDOL) of the word.I f  all the LTAs are finite automata in the stringautomaton representation, then the tree languagerecognized by this grammar is regular and its yieldis a context-free language.
The grammar can acceptgeneral Tree Adjoining Language (TAL) if" theLTAs belong to the class of pushdown atttomata inthe string autonlaton representation.
This is areflection of tile thct that pushdown tree automatacan accept the indexed languages (Gdcseg andSteinby, 1997), of which the TAL is a subclass.As shown in the section 2.4, the control strategyof bottom-up chart parsing does not rely ell theconcrete content of the I,TA, which is an adwmtageof the proposed formalism.
This implies that we canalter even tile grammar class without affecting theparsing.
Suppose the current L'I'As are finiteautomata, hence the yield language is context-free.If we want to introduce a word e that induces anon-context-fi'eeness, such as e in a"b"ec"d", thenwhat we have to do is to write a pushdownautomaton in tile figure 4 li)r the word e. Wechange neither tile grammar formalism nor theparsing algorithm, and the change is localized to theLTA of e.Writing automata by hand may seem much morecomplex than writing trees, but our experienceshows that it is not nlucll different fronlconvelltional granHllar development.
As long asappropriate notations are used, writing automata fora word anlounts to detornlining possible t'olnl oftrees headed by that word, a task ahvays required ingramil-iar development.
In fact, thei'e is tess alllOtllliof work since tile gralllnlar writer does not need topay attention to assigning proper nontcrminalsand/or proper attributes to internal nodes of trees inorder to control their growth.It is another advantage of the proposedformalisnl that it can utilize various autorriataoperations, such as conlposition and intersection.For exanlple, a word can append an atltOlllatoll tothai of the headword when it becomes a child,which enables to specify a constraint fi'onl ah)wer-positioned word to a higherq)ositioned v~oi'din tile tree.
Another example is cootdination.
Twoedges are conjoined when tile unapplied parts ofI,TAs have nonempty intersection as automata, andtile conjoined edge is given with this intersection asthe lTfA.
Verb phrase conjunction such as ",lohneats cookies and drinks beer" is handled in thismanner, by conjoining "'eats cookies" and "'drinksbeer.
The intersected automaton will accept thesubject ree and other sentence-level trees.931In the proposed method, elementary trees arealways anchored by the syntactic headword.
Forexample, a verb iit a relative clause is in the EDOLof the antecedent.
Then, if the embedded verb putsa constraint on the antecedent, hat constraint is notexpressed in a straightforward manner, which mayseem a weakness of the method.
We just poiltt outthat this type of problem occurs when the syntactichead and the semantic head are different, and iscommon to lexicalized grammars as long as a treeis anchored to one word, because constraints areoften reciprocal.
In our current implementation, theconstraint written in the verb's dictionary is foundand checked by the relative-clause-tree acceptingautomaton of the antecedent noun.There have been many work on syntactic analysisbased on automata ttached to the headword.
Evansand Weir (1998) used finite state automata asrepresentation of  trees that can be merged andminimized to improve parsing efficiency, lit theirmethod, the granlnlar is fixed to be I,TAG or seinelexicalized grammar and the automata re obtainedby automatic conversion from the trees.
Ournlethod differs frol11 theirs ilt the poiltt that oursemploys trees as the basic object of automata,which enables to handle general recursiveadjunction in LTAG,  whi le  their automata work Olltile nonter i l l inal  and ternl inal synlbols, lit the centerO\[" Ot.lr method is the notion of" the local orallllllal ofa word.
"\['he whole grammar is divided into theglobal part and the set of h)cal gralltntars specific tothe words, which is represented by tile LTAs.Alshawi (1996) introduced ttead Atitornata, aweighted finite machine that accepts a pair o\["sequences of relation symbols.
The difference issimilar as above.
Since the tree automata in ourmethod are used to define the set of the local trees,their role will be equivalent o building the headautomata themselves, but not to combining the treesthat are already built, like the I lead Automata.5 ConchlsionWe proposed a new lexicalized grammar formalism,called Lexicalized Tree Automata-based Grammar.In this formalism, the trees anchored to a word aredescribed by a tree automaton associated with it.We showed a chart parsing algo,ithm that does notdepend on the concrete content of the automata.
Wehave imt)lemented a bi-directional translationmodule between Japanese and English liarconversational texts using this formalism.
Apreliminary evaluation of English to Japanesetranslation quality revealed a promising result.AcknowledgementWe would like to thank Shinichiro Kamei tia" usefuldiscussions and Yoshinori Ishihara for his help inthe implelnentation work.ReferencesAbeilld, A., Schabes, Y. and .loshi, A.K.
(1990).
t.'si,z<.,,l.exicalized 771(;s fin" Machine 77"an.dalion.
tnf~roceedin<<.,,s oi ( 'OI, LVG- 90. p p. 1-6.Aho.
A.V.. and Ulhn:.ul..I.1).
(1969).
I'roFe#'lie.v qf,SlvntaxDirected 7)'anslations..Iotlrllal of C(Hllrltlicr {tlld g}stelllSciences.
vol.3, pp.319-334.AIshawi.
II.
(19961.
Ilead ..haomam and Bilini,,ual Tilin<<,c7)'aHs/alioll with Minima/ Rel)re.ventalion.v.
InProceedin.Ts of 34 If' .4#lnlla\[ .lleetlll?, (g {'onl/)lttattolla/Linguistics, pp.
167-176.P, rown.
P,.D.
(1996).
ICvamlJle-Based ,l/achine 7)'all.v/all'oilill the Pan gloss ,71'.s'lenl.
hi Proceedinw of ('Ol.l,VG-96.pp.
169-174.\]'vans, R. and Weir, I).,I.
(1998).
,4 .S'tructure-,S'harink,Parser jo t  Lexicalized (;rantmars.
In tb'oc'eedi, g.s" ofCOLING-,.ICL "98. pp.372-378.Furuse, O. and lida.
It.
(1994).
('onstituenl BoundaryParsing .for 1Crample-Ba,sed .Wachine 77"culs/ation.
Inl'roceedin?,s o/( 'Ol ,  lNG-94, pp.
105- I I I.Gdcsc,, F. and Stcinby, M. (1997).
Tree lA.ulguagcs.
Int/andbook of Formal l.anguages.
G. P, osenberg and it.Salomaa.
trillers.
Springer Vcrlag.
Vol.3.
pp.
1-68.Joshi.
A.K.
and Schabcs.
Y.
(1992).
Tree-..tcOoinin?4(Trammars and l, exicali_-ed Grammars.
II1 "\['I'CC i\tltOlllalaand lxmguages.
M. NiXal and A. l>odelski, cd,, ElsevierScience l~ublishcrs B.V., pp.409-43 I.ltuland.
T., ltupp.
C_I., Spilkcr.
J.. \Vcbcr, It.
itlld \VorilL K.(1998).
Jlakin<t~ The Most qf :WulttTUiciO'.- t Multi-I'ar.~er.llu/ti-.S'lrategy .-Irc/H'tecture for Hie l?olm.vt /~r,'.>c'e,v.vin~ of.q'poken l.ang ta?,e In IJroceedin,v.v oJ I('.S'/,/~ '98.pp.
1163-.
I 166.Schabes, Y.. Abcill6.
A. and Joshi.
A.
(1988).
/~ar.viu?,,~'t#'ategiex with "l, exicali=ed' (h'ammars.
In />roceedin?,.s"o/(  OI, I.\G 8<S.
pp.>78-_ 8.~.Schabcs.
Y. and \Vatcrs.
R.C.
(1995).
Tree ht.~'ertion(;#'CIIIIIII\[ll': .l ('u/Uc-JTme.
Par.valUe /.
'ormali.vm l/latLexicah-e.~" ('onte:~t-I;)'ee Oralllnlglr without ('han,,,,in<,.,, theTrees Prod\teed.
Computational ,inguisiics.
Vol.
21,pp.479-513.Shicbcr.
S.N,1.
and Schabcs, Y.
(1990)..S'vnchronou.s Tree..le(ioinin?, Grammars.
In Prlweedinr~4s ?
)/" (.'()I.I.V(;'90.pp.253-258.Slcaim.
I).I).K.
and Tempcrley.
\[).
(199t).
Par\in,, IGz,c, li.dlWl'lJt el l.l'tgk (;#'anlnlar.
CM\[J lechnical P, eport('N'llJ-C'.q-91- 196.Takcda.
K. (19961.
I~altermBa.seU .~lachine 77"an.v/alien.
Inl'roceedmgs qICOI.IN(; '96.
pp.
I 155- I 158.\Valai~abe.
T.. ()kunltlra, A...'qakai.
S.. Yail/abal'la.
K. alldl)oi..'4.
(2000)..IIIlOIIIHIIL' \]IIlL'ITJI'L'ILIII'OII.
"\['O apl:,ear inNI!
(_' Technical Jourrial.
Vol.53.
No.6.
(in .lapancseL932
