Coling 2010: Demonstration Volume, pages 29?32,Beijing, August 2010HCAMiner: Mining Concept Associations for Knowledge Dis-covery through Concept Chain QueriesWei JinDepartment of Computer ScienceNorth Dakota State Universitywei.jin@ndsu.eduXin WuDepartment of Computer Science & TechnologyUniversity of Science and Technology of Chinaxinwu@mail.ustc.edu.cnAbstractThis paper presents HCAMiner, a systemfocusing on detecting how concepts arelinked across multiple documents.
A tra-ditional search involving, for example,two person names will attempt to finddocuments mentioning both these indi-viduals.
This research focuses on a dif-ferent interpretation of such a query:what is the best concept chain acrossmultiple documents that connects theseindividuals?
A new robust framework ispresented, based on (i) generating con-cept association graphs, a hybrid contentrepresentation, (ii) performing conceptchain queries (CCQ) to discover candi-date chains, and (iii) subsequently rank-ing chains according to the significanceof relationships suggested.
These func-tionalities are implemented using an in-teractive visualization paradigm whichassists users for a better understandingand interpretation of discovered relation-ships.1 IntroductionThere are potentially valuable nuggets ofinformation hidden in large documentcollections.
Discovering them is important forinferring new knowledge and detecting newtrends.
Data mining technology is giving us theability to extract meaningful patterns from largequantities of structured data.
Collections of text,however, are not as amenable to data mining.
Inthis demonstration, we describe HCAMiner, atext mining system designed to detect hiddeninformation between concepts from large textcollections and expose previously unknown logicconnections that connect facts, propositions orhypotheses.In our previous work, we have defined conceptchain queries (CCQ) (Jin et al, 2007), a specialcase of text mining in document collections fo-cusing on detecting links between two conceptsacross text documents.
A traditional search in-volving, for example, two person names will at-tempt to find documents mentioning both ofthese names and produce a list of individualpages as result.
In the event that there are nopages contain both names, it will return ?nopages found?
or pages with one of the namesranked by relevancy.
Even if two or more interre-lated pages contain both names, the existingsearch engines cannot integrate information intoone relevant and meaningful answer.
This re-search focuses on a different interpretation ofsuch a query: what is the best concept chainacross documents that potentially connects thesetwo individuals?
For example, both may be foot-ball lovers, but are mentioned in different docu-ments.
This information can only be gleanedfrom multiple documents.
A generalization ofthis task involves query terms representing gen-eral concepts (e.g., airplane crash, foreign policy).The goal of this research is to sift through theseextensive document collections and find suchhidden links.Formally, a concept chain query involvingconcepts A and B has the following meaning:find the most plausible relationship between con-cept A and concept B assuming that one or moreinstances of both concepts occur in the corpus,but not necessarily in the same document.
We goone step further and require the response to in-clude text snippets extracted from multipledocuments in which the discovered relationship29occurs.
This may assist users with the seconddimension of the analysis process, i.e., when theuser has to peruse the documents to figure out thenature of the relationship underlying a suggestedchain.2 The Proposed Techniques2.1 The new representation frameworkA key part of the solution is the representationframework.
What is required is something thatsupports traditional IR models (such as the vectorspace model), graph mining and probabilisticgraphical models.
We have formulated a repre-sentation referred to as concept associationgraphs (CAG).
Figure 1 illustrates a small portionof CAG that has been constructed based on proc-essing the 9/11 commission report1 in the coun-terterrorism domain.
The inputs for this moduleare paths for data collection and domain-specificdictionary containing concepts.
In our experi-ments, we extract as concepts all named entities,as well as any noun or noun phrases participatingin Subject-Verb-Object relationships.
Domainontological links are also illustrated, e.g., whitehouse is a type of organization.Figure 1.
Portion of the CAG2.2 Concept profile (CP) and snippet clustergenerationA concept profile (CP) is essentially a set ofterms that together represent the correspondingconcept.
We generate concept profiles byadapting the Local Context Analysis technique inInformation Retrieval and then integrate theminto the graphical framework (Jin et al, 2007).1 http://www.9-11commission.gov/Particularly, the CP for concept c is built by firstidentifying a relevant set of text segments fromthe corpus in which concept c occurs, and thenidentifying characteristic concepts from this setand assessing their relative importance asdescriptors of concept c. Formally, the profileProfile(ci) for concept ci is described by a set ofits related concepts ck as follows:},,,,{)(Pr ,22,11, LL kkiiii ccccofile ??
?=Weight ?i,k denotes the relative importance ofck as an indicator of concept ci and is calculatedas follows:nidfkif kki log)),(log(,?+= ?
?Where n is the number of relevant text seg-ments considered for concept ci (in our experi-ments, the basic unit of segmentation is a sen-tence).
The function f (i, k) quantifies the correla-tion between concept ci and concept ck and isgiven by?=?=njjkji sfsfkif1,,),(Where sfi,j is the frequency of concept ci in thej-th sentence and sfk,j is the frequency of conceptck in the j-th sentence.
This can be easily com-puted by constructing ?concept by sentence?
ma-trix Q whose entry Qi,j is the number of timesconcept ci  occurs in sentence sj.
(QQT)ij thenrepresents the number of times concepts ci and cjco-occur in sentences across the corpus.
The in-verse document frequency factor is computed as)/log,1max( ?kknpNidf =Where N is the number of sentences in thedocument collection, npk is the number of sen-tences containing concept ck.
?
is a collectiondependent parameter (in the experiments ?=3).The factor ?
is a constant parameter which avoidsa value equals to zero for wi,k (which is useful,for instance, if the approach is to be used withprobabilistic framework).
Usually, ?
is a smallfactor with values close to 0.1.
Table 1 illustratesa portion of the CP constructed for concept Bin30Ladin.
The best concepts are shown based ontheir relative importance.Table 1.
Portion of CP for Concept ?BinLadin?Bin LadinDimension ValueAl-qaeda 0.569744Afghanistan 0.535689Sandi Arabia 0.527825Islamist 0.478891Islamist Army 0.448877Extremist 0.413376Ramzi Yorsef 0.407401Sudanese 0.370125Saddam Hussein 0.369928Covert Action 0.349815Embassy Bombings 0.313913Given the information provided by conceptprofiles, the strength of a relation (edge weight inthe CAG) between concept ci and concept cj ismeasured by the similarity between their respec-tive profiles.
If a concept X is related to anotherconcept Y which has a similar context as that ofX, then such a relation can be coherent andmeaningful.
More precisely, a scalar profile simi-larity matrix Si,j is defined as follows:)(?)(?)(?)(?,jijijicCcCcCcCS?
?=Where ?
(ci) and ?
(cj) are profile vectors forconcepts ci and cj respectively.
In terms of textmining and knowledge discovery, we also re-quire the graphical representation relate conceptsand associations to underlying text snippets inthe corpus.
Without this support, the frameworkis not complete since users need to validate con-clusions by looking at actual documents.
This isachieved by associating each edge with a Snip-pet Cluster, which links the snippets (e.g., sen-tences) in the corpus to the corresponding asso-ciations (e.g., co-occurrence of concepts in sen-tences) represented by edges in the CAG.
Theresulting snippet clusters offer a view of thedocument collection which is highly character-ized by the presence of concept associations (il-lustrated in Fig.
1).2.3 Concept Chain Generation and Rank-ingGiven two concepts of interest designated, con-cept chain query (CCQ) tries to find if (i) there isa direct connection (association) between them,or (ii) if they can be connected by several inter-mediate concepts (paths).
Note that finding directlinks between two concepts is trivial; in the fol-lowing we mainly focus on discovering and rank-ing indirect connections between concepts.We formulate the CCQ problem as finding op-timized transitive associations between conceptsin the CAG.
Given the source concept c1 and des-tination concept cn, the transitive strength of apath from c1 to cn made up of the links {(c1,c2), ?
, (cn-1, cn)}, denoted by TS(c1, c2 ,?
,cn), isgiven by:)),((),,,( 11121 +?=?= iinin ccwcccTS LWhere w(ci, ci+1) represents the weight of theedge connecting concepts ci and ci+1.
The formu-lation of generating and ranking transitive asso-ciations is then described as follows with inputand output constraints specified:Given: an edge-weighted graph CAG, verticess and t from CAG, and an integer budget lFind: ranked lists of concept chains CCs star-ing from s and ending at t, one list for each pos-sible length (i.e., between the shortest connectionlength and the specified maximum length l).Within each list, top-K chains that maximize the?goodness?
function TS(?)
is returned.Our optimization problem is now to find anoptimal path that maximizes the ?goodness?measure for each possible length.
This could beeasily computed using dynamic programminggiven the inductive definition of the goodnessfunction TS(?).
Notice that in real applicationsthere are often cases that users might be inter-ested in exploring more potential chains insteadof just one optimal chain, we have thus adaptedthe traditional dynamic programming algorithminto finding top-K chains connecting concepts foreach possible length efficiently.
The details ofalgorithm and implementation can be found in(Jin et al, 2007).3 The System InterfaceFigure 2 illustrates the main HCAMiner visuali-zation interface.
Given the user specified pathsfor data collection and domain specific thesaurus,31the Concept Association Graph is first con-structed.
Analyzers are then provided anotherpanel of parameters to guide the discovery proc-ess, e.g., max_len controls the maximum lengthof desired chains; chain_num specifies the num-ber of top ranked chains to be returned for eachpossible length.
The visualized result for conceptchain query involving person names ?Bush?
and?Bin Ladin?
with parameter values ?max_len?
3and ?chain-num?
5 is shown in Fig.
2.
The sys-tem offers different views of the generated output:a) Chain Solution View (in the left pane).
Thisview gives the overview of all the generatedconcept chains.b) XML Data View (in the upper-right pane).This view links each concept chain to theunderlying text snippets in the corpus inwhich the suggested association occurs.Snippets are presented in XML format andindexed by docId.snippetID.
This makes iteasier for analyzers to explore only the rele-vant snippet information concerning thequery.c) Concept Profile View.
This view providesthe profile information for any concept in-volved in the generated chains.
Figure 2shows portion of the CP generated for Con-cept ?Bin Ladin?
(illustrated on the bottomright).4 CONCLUSIONSThis paper introduces HCAMiner, a system fo-cusing on detecting cross-document links be-tween concepts.
Different from traditional search,we interpret such a query as finding the mostmeaningful concept chains across documents thatconnect these two concepts.
Specifically, the sys-tem generates ranked concept chains where thekey terms representing significant relationshipsbetween concepts are ranked high.
The discov-ered novel but non-obvious cross-document linksare the candidates for hypothesis generation,which is a crucial initial step for making discov-eries.We are now researching extensions of conceptchains to concept graph queries.
This will enableusers to quickly generate hypotheses graphswhich are specific to a corpus.
These matchedinstances can then be used to look for other,similar scenarios.
Ontology guided graph searchis another focus of future work.ReferencesJin, Wei, Rohini K. Srihari, and Hung Hay Ho.
2007.A Text Mining Model for Hypothesis Generation.In Proceedings of the 19th IEEE InternationalConference on Tools with Artificial Intelligence(ICTAI?07), pp.
156-162.Jin, Wei, Rohini K. Srihari, Hung Hay Ho, and XinWu.
2007.
Improving Knowledge Discovery inDocument Collections through Combining TextRetrieval and Link Analysis Techniques.
In Pro-ceedings of the 7th IEEE International Conferenceon Data Mining (ICDM?07), pp.
193-202.Figure 2.
Screenshot of the user interface32
