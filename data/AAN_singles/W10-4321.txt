Proceedings of SIGDIAL 2010: the 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 103?106,The University of Tokyo, September 24-25, 2010. c?2010 Association for Computational LinguisticsLearning Dialogue Strategies from Older and Younger Simulated UsersKallirroi GeorgilaInstitute for Creative TechnologiesUniversity of Southern CaliforniaPlaya Vista, USAkgeorgila@ict.usc.eduMaria K. WoltersSchool of InformaticsUniversity of EdinburghEdinburgh, UKmaria.wolters@ed.ac.ukJohanna D. MooreSchool of InformaticsUniversity of EdinburghEdinburgh, UKJ.Moore@ed.ac.ukAbstractOlder adults are a challenging user groupbecause their behaviour can be highly vari-able.
To the best of our knowledge, thisis the first study where dialogue strategiesare learned and evaluated with both sim-ulated younger users and simulated olderusers.
The simulated users were derivedfrom a corpus of interactions with a strictsystem-initiative spoken dialogue system(SDS).
Learning from simulated youngerusers leads to a policy which is close toone of the dialogue strategies of the under-lying SDS, while the simulated older usersallow us to learn more flexible dialoguestrategies that accommodate mixed initia-tive.
We conclude that simulated users area useful technique for modelling the be-haviour of new user groups.1 IntroductionState-of-the-art statistical approaches to dia-logue management (Frampton and Lemon, 2006;Williams and Young, 2007) rely on having ade-quate training data.
Dialogue strategies are typ-ically inferred from data using ReinforcementLearning (RL), which requires on the order ofthousands of dialogues to achieve good perfor-mance.
Therefore, it is no longer feasible to relyon data collected with real users.
Instead, trainingdata is generated through interactions of the sys-tem with simulated users (SUs) (Georgila et al,2006).
In order to learn good policies, the be-haviour of the SUs needs to cover the range ofvariation seen in real users (Georgila et al, 2006;Schatzmann et al, 2006).
Furthermore, SUs arecritical for evaluating candidate dialogue policies.To date, SUs have been used to learn dialoguestrategies for specific domains such as flight reser-vation, restaurant recommendation, etc., and tolearn both how to collect information from theuser (Frampton and Lemon, 2006) as well as howto present information to the user (Rieser andLemon, 2009; Janarthanam and Lemon, 2009).In addition to covering different domains, SUsshould also be able to model relevant user at-tributes (Schatzmann et al, 2006), such as coop-erativeness vs. non-cooperativeness (Lo?pez-Co?zaret al, 2006; Jung et al, 2009), or age (Georgila etal., 2008).
In this paper, we focus on user age.As the proportion of older people in the popu-lation increases, it becomes essential to make spo-ken dialogue systems (SDS) easy to use for thisgroup of people.
Only very few spoken dialoguesystems have been developed for older people (e.g.Nursebot (Roy et al, 2000)), and we are aware ofno work on learning specific dialogue policies forolder people using SUs and RL.Older people present special challenges for di-alogue systems.
While cognitive and perceptualabilities generally decline with age, the spread ofability in older people is far larger than in anyother segment of the population (Rabbitt and An-derson, 2005).
Older users may also use differ-ent strategies for interacting with SDS.
In our pre-vious work on studying the interactions betweenolder and younger users and a simulated appoint-ment scheduling SDS (Wolters et al, 2009b), wefound that some older users were very ?social?,treating the system like a human, and failing toadapt to the SDS?s system-initiative dialogue strat-egy.
A third of the older users, however, tendedto be more ?factual?, using short commands andconforming to the system?s dialogue strategy.
Inthat, they were very similar to the younger users(Wolters et al, 2009b).In previous work (Georgila et al, 2008), wesuccessfully built SUs for both older and younger103adults from the corpus used by (Wolters et al,2009b) and documented in (Georgila et al, 2010).When we evaluated the SUs using metrics such asprecision and recall (Georgila et al, 2006; Schatz-mann et al, 2006), we found that SUs trained onolder users?
data can cover behaviour patterns typ-ical of younger users, but not the opposite.
Thebehaviour of older people is too diverse to be cap-tured by a SU trained on younger users?
data.
Thisresult agrees with the findings of (Wolters et al,2009b; Georgila et al, 2010).In this study, we take our work one stepfurther?we use the SUs developed in (Georgilaet al, 2008) to learn dialogue policies and evalu-ate the resulting policies with data from both olderand younger users.
Our work is important for tworeasons.
First, to the best of our knowledge thisis the first time that people have used SUs andRL to learn dialogue strategies for the increas-ingly important population of older users.
Sec-ond, despite the fact that SUs are used for learn-ing dialogue strategies it is not clear whether theycan learn policies that are appropriate for differentuser populations.
We show that SUs can be suc-cessfully used to learn policies for older users thatare adapted to their specific patterns of behaviour,even though these patterns are far more varied thanthe behaviour patterns of younger users.
This pro-vides evidence for the validity of the user simula-tion methodology for learning and evaluating dia-logue strategies for different user populations.The structure of the paper is as follows: In sec-tion 2 we describe our data set, discuss the dif-ferences between older and younger users as seenin our corpus, and describe our user simulations.In section 3, we present the results of our experi-ments.
Finally, in section 4 we present our conclu-sions and propose future work.2 The CorpusIn the original dialogue corpus, people were askedto schedule health care appointments with 9 dif-ferent simulated SDS in a Wizard-of-Oz setting.The systems varied in the number of options pre-sented at each stage of the dialogue (1, 2, 4),and in the confirmation strategies used (explicitconfirmation, implicit confirmation, no confirma-tion).
System utterances were generated usinga simple template-based algorithm and synthe-sised using a female Scottish English unit selec-tion voice.
The human Wizard took over the func-tion of speech recognition (ASR), language under-standing (NLU), and dialogue management com-ponents.
No ASR or NLU errors were simulated,because having to deal with ASR and/or NLU er-rors in addition to task completion would have in-creased cognitive load (Wolters et al, 2009a).The system (Wizard) followed a strict policywhich resulted in dialogues with a fixed schema:First, users arranged to see a specific health careprofessional, then they arranged a specific half-day, and finally, a specific half-hour time slot onthat half-day was agreed.
Users were not allowedto skip any stage of the dialogue.
This design en-sured that all users were presented with the rele-vant number of options and the relevant confirma-tion strategy at least three times per dialogue.
In afinal step, the Wizard confirmed the appointment.The full corpus consists of 447 dialogues; 3 di-alogues were not recorded.
A total of 50 partici-pants were recruited, of which 26 were older, agedbetween 50 and 85 years, and 24 were younger,aged between 18 and 30 years.
The older userscontributed 232 dialogues, the younger ones 215.Older and younger users were matched for levelof education and gender.
All dialogues were tran-scribed orthographically and annotated with dia-logue acts and dialogue context information.
Us-ing a unique mapping, we associate each dialogueact with a ?speech act, task?
pair, where the speechact is task independent and the task corresponds tothe slot in focus (health professional, half-day ortime slot).
For example, ?confirm pos, hp?
cor-responds to positive explicit confirmation of thehealth professional slot.
For each dialogue, de-tailed measures of dialogue quality were recorded:objective task completion, perceived task comple-tion, appointment recall, length (in turns), and ex-tensive user satisfaction ratings.
For a detailed dis-cussion of the corpus, see (Georgila et al, 2010).The choice of dialogue strategy did not affecttask completion and appointment recall, but hadsignificant effects on efficiency (Wolters et al,2009a).
Task completion and appointment recallwere the same for older and younger users, butolder users took more turns to complete the task(Wolters et al, 2009a).
Clear differences betweenthe two user groups emerge when we look at in-teraction patterns in more detail (Wolters et al,2009b; Georgila et al, 2010).
Older people tendto ?ground?
information (using repetitions) andtake the initiative more than younger people.
Inour corpus it was very common that the older per-son would provide information about the half-dayand the time slot of the appointment before hav-ing been asked by the system.
However, due to the104Experiment 1 Experiment 2slot filled +50 +50appointment confirmed +200 +200dialogue length -5 per turn -5 per turnslot confirmed +100 not usedwrong order -500 not usedTable 1: Reward functions for the experiments.strict policy of the Wizard, this information wouldbe ignored and the system would later ask for theinformation that had already been provided.In our SUs, each user utterance corresponds to auser action described by a list of ?speech act, task?pairs.
There are 31 distinct system actions and 389distinct actions for older users.
Younger peopleused a subset of 125 of the older users?
actions.Our SUs do not simulate ASR or NLU errors sincesuch errors were not simulated in the collection ofthe corpus.We built n-grams of system and user actionswith n varying from 2 to 5.
Given a history of n-1actions from system and user, the SU generates anaction based on a probability distribution learnedfrom the training data (Georgila et al, 2006).
Inthe present study, n was set to 3, which means thateach user action is predicted based on the previoususer action and the previous system action.3 Learning Dialogue StrategiesWe performed two experiments.
In Experiment 1,our goal was to learn the policy of the Wizard, i.e.the strict system-initiative policy of requesting andconfirming information for each slot before mov-ing to the next slot, in the following order: healthprofessional, half-day, time slot.
In Experiment2, our goal was to learn a more flexible policy thatcould accommodate some degree of user initiative.The reward functions for both experiments arespecified in Table 1; they are similar to the rewardfunctions used in the literature, e.g.
(Frampton andLemon, 2006).
Slots that have been filled success-fully and confirmed appointments are rewarded,while long dialogues are penalised.
For Experi-ment 1, policies were rewarded that filled slots inthe correct order and that confirmed each slot af-ter it had been filled.
A large penalty was imposedwhen the policy deviated from the strict slot order(health professional, half-day, time slot).
For Ex-periment 2, these constraints were removed.
Slotscould be filled in any order.
Confirmations werenot required because there was no speech act inthe corpus for confirming more than one slot at atime.In both experiments we used the SARSA-?
al-gorithm (Sutton and Barto, 1998) for RL.
30,000iterations were used for learning the final pol-icy for each condition.
For each experiment,we learned two policies, Policy-Old, which wasbased on simulated older users, and Policy-Young,which was based on simulated younger users.The resulting policies were then tested on simu-lated older users (Test-Old) and simulated youngerusers (Test-Young).
To have comparable resultsbetween Experiment 1 and Experiment 2, dur-ing testing we score our policies using the rewardfunction of Experiment 2.
The best possible scoreis 190, i.e.
the user fills all the slots in one turnand then confirms the appointment.
(Note that +50points are given when a slot is only filled, not con-firmed too.)
For each test condition, we gener-ated 10,000 simulated dialogues.
Overall scoresfor each combination of policy and SU were es-tablished using 5-fold cross-validation.Our results are summarised in Figure 1.
Whileaverage rewards were not affected by policytype (ANOVA, F (1, 68)=1, p=0.3) or trainingdata set (F (1, 185)=3, p=0.09), we found a verystrong interaction between policy type and dataset (F (1, 3098)=51, p=0.000).
Learning withsimulated younger users yields better strict poli-cies than learning with older users (Tukey?s Hon-est Significant Difference Test, ?=20, 95% CI= [11, 30], p=0.000), while learning with simu-lated older users yields better flexible policies thanlearning with younger users (?=15, 95% CI =[6, 24], p=0.001).
This is what we would expectfrom our corpus analysis, since the interaction be-haviour of older users is far more variable than thatof younger users (Wolters et al, 2009b; Georgilaet al, 2010).The strict policy that was learned from sim-ulated younger users was as follows, with onlyslight variations: first request the type of healthprofessional, then implicitly confirm the healthprofessional and request the half-day slot, then im-plicitly confirm the half-day slot and request thetime slot, and then confirm the appointment.
Thestrict policy learned from simulated older userswas similar, but less successful, because mostolder users do not readily conform to the fixedstructure.The flexible policy learned from simulated olderusers takes into account initiative from the userand does not always confirm.
The score for theflexible policy learned from simulated youngerusers was relatively low, even though the resulting105Score140150160170180190Test?Old Test?YoungPolicy?OldReward?FlexTest?Old Test?YoungPolicy?YoungReward?FlexPolicy?OldReward?Strict140150160170180190Policy?YoungReward?StrictFigure 1: Mean scores for each combination ofreward function, training set, and test set (5-foldcross-validation).policy was very similar to the strict policy learnedfrom younger users (i.e.
a sequence of informa-tion requests and implicit confirmations), and eventhough the behaviour of younger users is far morepredictable than the behaviour of older users.
Itappears that the explicit penalty for violating theorder of slots is crucial for fully exploiting the pat-terns in younger users?
behaviour.4 ConclusionsWe have shown that SUs can be used to learn ap-propriate policies for older adults, even thoughtheir interaction behaviour is more complex anddiverse than that of younger adults.
Crucially, sim-ulated older users allowed us to learn a more flex-ible version of the strict system-initiative dialoguestrategies that were used for creating the originalcorpus of interactions.
These results are consis-tent with previous analyses of the original corpus(Wolters et al, 2009b; Georgila et al, 2010) andsupport the validity of the user simulation method-ology for learning and evaluating dialogue strate-gies.In our future work, we will experiment withmore complex SUs, e.g.
linear feature combina-tion models (Georgila et al, 2006), and see if theycan be used to learn similar policies.
We also planto study the effect of training and testing with dif-ferent user simulation techniques, such as n-gramsversus linear feature combination models.AcknowledgementsThis research was partially supported by the MATCH project(SHEFC-HR04016, http://www.match-project.org.uk).
Georgila is supported by the U.S. Army Research,Development, and Engineering Command (RDECOM).
Thecontent does not necessarily reflect the position or the policyof the U.S. Government, and no official endorsement shouldbe inferred.ReferencesM.
Frampton and O.
Lemon.
2006.
Learning more effectivedialogue strategies using limited dialogue move features.In Proc.
ACL.K.
Georgila, J. Henderson, and O.
Lemon.
2006.
User simu-lation for spoken dialogue systems: Learning and evalua-tion.
In Proc.
Interspeech.K.
Georgila, M. Wolters, and J. Moore.
2008.
Simulating thebehaviour of older versus younger users.
In Proc.
ACL.K.
Georgila, Maria Wolters, J.D.
Moore, and R.H. Logie.2010.
The MATCH corpus: A corpus of older andyounger users?
interactions with spoken dialogue systems.Language Resources and Evaluation, 44(3):221?261.S.
Janarthanam and O.
Lemon.
2009.
A two-tier user simula-tion model for reinforcement learning of adaptive referringexpression generation policies.
In Proc.
SIGdial.S.
Jung, C. Lee, K. Kim, and G.G.
Lee.
2009.
Hybrid ap-proach to user intention modeling for dialog simulation.In Proc.
ACL.R.
Lo?pez-Co?zar, Z. Callejas, and M. McTear.
2006.
Testingthe performance of spoken dialogue systems by means ofan artificially simulated user.
Artificial Intelligence Re-view, 26(4):291?323.P.
Rabbitt and M.M.
Anderson.
2005.
The lacunae ofloss?
Aging and the differentiation of human abilities.In F.I.
Craik and E. Bialystok, editors, Lifespan Cogni-tion: Mechanisms of Change, chapter 23.
Oxford Univer-sity Press, New York, NY.V.
Rieser and O.
Lemon.
2009.
Natural language gener-ation as planning under uncertainty for spoken dialoguesystems.
In Proc.
EACL.N.
Roy, J. Pineau, and S. Thrun.
2000.
Spoken dialog man-agement for robots.
In Proc.
ACL.J.
Schatzmann, K. Weilhammer, M. Stuttle, and S. Young.2006.
A survey of statistical user simulation tech-niques for reinforcement-learning of dialogue manage-ment strategies.
Knowlege Engineering Review, 21(2):97?126.R.S.
Sutton and A.G. Barto.
1998.
Reinforcement Learning:An Introduction.
MIT Press.J.
Williams and S. Young.
2007.
Partially observable Markovdecision processes for spoken dialog systems.
ComputerSpeech and Language, 21(2):393?422.M.
Wolters, K. Georgila, J.D.
Moore, R.H. Logie, S.E.MacPherson, and M. Watson.
2009a.
Reducing work-ing memory load in spoken dialogue systems.
Interactingwith Computers, 21(4):276?287.M.
Wolters, K. Georgila, J.D.
Moore, and S.E.
MacPherson.2009b.
Being old doesn?t mean acting old: How olderusers interact with spoken dialog systems.
ACM Trans.Accessible Computing, 2(1).106
