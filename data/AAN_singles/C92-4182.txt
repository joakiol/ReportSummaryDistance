PRI~;DICTING NOUN~PIIRASE SURFACh; I~'ORMS USING Q~ONTEXTUAL \[NFORMA'PIONTakayuki  YAMAOKA:  Hitoshi  I IDA~ and Hidekazu AILITA~ATR Interpreting Telephony Research Laboratories, Souraku-guu, Kyoto, JAPANtMitsubishi Electric Corporation, Amagasaki, tlyogo, JAPANAbst ractWe propose a context-sensitive method to predict noun-phrases ill the next utterance of a telephone inquiry di-alogue.
First, information about tile utterance type andthe discourse ntities of the next utterance is graspcd us-ing a dialogue interpretation model.
Second, a domain-dependent knowledge base for noun-phrase usage is de-veloped, focusing on the dialogue situations in context.Finally, we propose a strategy to make a set of the appro-priate expressions in the next utterance, using the infor-mation and the knowledge base.
This set of expressionsis used to select the correct candidate from tim speechrecognition output.
This paper exantines some of the pro-cesses creating sets of polite expressions, deicti6 expres-sions, and compound ilOUll pllra-~es, which ~tre COlnlUOllill telephone inquiry dialogue.1 In t roduct ionA high-quality spoken-language processing systemmust use knowledge of dialogue and spoken-language.Using dialogue knowledge facilitates understandingand predicting utterances in context.
Using spoken-language knowledge, that is knowledge about how tilespeaker expresses what he/she wants to say, makes itpossible for the system to recognize and generate themore complex expressions that are nornmlly ased illour daily dialogues.To make language processing in the whole spoken-langnage processing system more efficient, it.
is vitalhow to select he correct speech recognition output inthe speech-language interface.
The use of discourse-level knowledge is an effective way to do this\[6\]\[11\].For example, MINDS\[6\] applied dialogue-level knowl-edge, particularly for propositional contents, to pre-dict the expected utterance form for the speech recog-nition, ilowever, although MINDS showed good re-suits, several llroblems remain before it can lie madeinto a complete spoken-language processing system:1. how to construct he dialogue structure for thegiven domain,2.
how to treat predictive concepts regarding notonly the propositional contents but also thespeaker's intention,3.
and, how to etmose a set of surface forms tbatthe speaker might utter about the predicted con-cept.Also, MINDS was concerned with a system to par-ticipate in human-machine dialogue.
On the otherband, we want to monitor a human-human dialogue.We proposed a dialogue understanding model\[7\], anda context-sensitive method to predict abstract infor-mation allout both tile intentional and propositionalcontents of tile next utterance\[11\].
These are our an-swers to the above problems 1 and 2.From tile point of view of human behavior, a po-tential approacb to selecting the appropriate sur-face erpression forms (SEFs) is using spoken-lauguageknowledge.
In general, when we are talking about aconcept X, there are many possible surface expres-sious and forms to represent X.
From a psychological(or psyeholinguistic) point of view, Clark\[3\] pointedout five abstract factors which should be consideredill ,asking what linguistic devices hould speakers use ?.These are: knowledge of the listener, the coopeva-live principle, the reality principle, the social con-text, and the linguistic devices available.
In theeomputatioual linguistics area, Appelt\[1\] has devel-oped a framework to generate a sentence in a context-sensitive way, based on speech act tbeories.
Unfortu-nately, however, there also remains, as he describedms a future study, the problem of choosing a lexicallyappropriate SEF from among candidates in a socialconlexl.This paper describes a context-sensitive frameworkfor selectiug all SEF for noun-phrases(NPs).
Thismethod is sensitive to botb tbe utterance situationand the history of the dialogue.
To do this, first, weanalyze the relations between concepts and SEFs, andbetween applicable situations and contexts, using acorpus of Japanese inquiry dialogues.
Then, we makea domain-dependent k owledge source for NP usage,and define rules driven by applicable conditions todetermine a set of possible SEFs in the knowledgebase.
Finally, we give exanaples of the SEI" selection,especially for polite expressions, deictifi expressions,and compound NPs, which are common in our targetdomain, and describe asimple experiment toevaluateusing the ATR dialogue database.
The result showtllat tile method can choose tbe contextually correctexpression from the speech recognition output can-didates, and can be used in tile generation moduleof a spoken-language processing system to generateand determine all appropriate xpression under tiledialogue situation.Throughout this paper, all examples are inJapanese and written in italic.
English translationsfollow in parentheses.
NP denotes a noun phrase, andSEF denotes a surface expression form.
SEFs are en-closed ill double quotation marks and concepts areenclosed in single quotation marks.2 Dialogue In terpretat ion  and Pred ic t ingthe Next  Ut teranceThe next.
utterance call be predicted after under-standing the previous utterances, because predictedinformation must be affected by tile dialogue struc-AcrEs DE COLING-92, NANTES, 23-28 Aour 1992 1 1 5 2 PROC.
OF COLING-92, NANTES, AUO.
23-28, 1992lure.
This section brielly describes tile model for in-terpreting a dialogue\[7\] and tile ulethod of pre(lictngthe next uttcrance\[ll\]\[12\].In tile lnodel, an utterance is represented, by apredicate form.
An typical Japanese sentence, "(;0-juusyo we ouegai-shi-masu."
(May 1 have your address?
), uttered by the secretariat in a inquiry dia-logue, is shown below:(ASK-VALUE u q (address q) (IS (address q) ?va\].
))where constant s denotes the secretariat, q thequestioner, address tile concel)t of an a.ddress, andthe variable, ?val,  is the value for the address  of q.The dialogue interpretation model h;us \[our typesof plan and can interpret input utterances as the di-alogue proceeds, using au extended plain inferencemechanism\[7\].
Thus, a dialogue structure can be con-structed.lit order to provide contextual ieforlnation aboutdiscourse ntities we use typed variable notation\[2\] todescribe a discourse ntity in a plan schema, l';achtype in this notation corresponds to a particular con-cept node ill the domaiu-del)eudent NP knowledgebase (described in Section a.3) '\['he following de-scription is an example of a Domailt Pla~J to sendsomething:(Domain-Plan: SERD-SOMETHIN~(HEADER (SEND ?a:person ?r:person ?s:object))(PRECONDITION (KNON ?a ?d:destination))(EFFEECT (HAS ?r ?s))(CORSTRRINT (BELDNG ?d ?r)))The state of understanding is managed nsieg twopushdown stacks.
The mlders tand ing  llst storescompleted plans as the current understanding state,and tile goal list maintains incomplete plans ~Ls pos-sibilities and expectations tbr fltture goals.
By rcferring to tile goal list., the next utl.erance can I)epredicted on an abstract, level as the dialogue pro-ceeds, using the two generalized rules: e?imctationmid prefere.nee\[12\].Predicted utterances are tel)resented in the slttncstyle as intmt utterances.
As a result,, we can predicttwo types of infornlatiou, one about the COlllllltlUiCa-live act, types and the other about discourse ntitiesin the propositional contents (or in the topic slot,) (t\["the ilext uttcrarlce, lnforrnatioll abotlt a discourseentity lnay appear in the forlu of ;ill particular expression if it is ill a prvvious utterance that can berelated to the.
current atterauce.
Othe.rwise infornl~ties will be in the tbrm of a type represcuting a par-ticular concept in tile related domain plan.
We callsuch information conteztual information in tile t~skof selecting ttle constituents of tile next utterance.3 NP  Ident i f icat ion Model3.1 Chauge to  NP  Linguist ic Expressionshi general, when we are talking about a concept X,there are many possible surface xpressions and fornlsto represent X.
In llarticular, Japanese ha.s severalpossible SEFs for a given X, one from ttle Chinesereading and another based on tile original Japaneselanguage (e.g.
"oka~sakf' and "atesakf' for 'destina-tion' in Fig.
1).
In addition, there are particular phe-nomena of expression variations depending hi)on theparticular dialogue.
For exmnple, if a speaker is ut-tering his/her own address for tile concept 'address',he/she will use "3uusyo"(\[my\] address), e.g.
"Juusyo-wa Oosaka-sht desu.
"(My address is in Osaka~city.
).On the other hand, if he/she is uttering tile other par-ticipant's address, he/she will use ".qo.juusyo"(\[your\]address (polite fornl)), e.g.
"Go-juusyo-wo negai-shi-masu.
"(Your address, please?)
These facts leadrlS to  ilnplenmltt knowledge SOllrces elf s/Idl vari~.lions(we call them changes) in a computational l)rc~cessilr g systenl.Only by liltcriug using any intra-sentential knowl-edge sources, several candidates may remain ~m syn-tactically and semantically correct senteuces.
Forexample, "9ojuu-shichi'(fifl.y-seven) sounds like "yo-3uusyo', and the sentence "Gojuu-shichi-wo onegai-shi-masu.
"(Fifty-seveu, i)lea-ne.)
is not only well-formed but also correct in a particular context.
It ispossible to select the correct candidate by referringto both the context and the situation of the ongoingdialogue.
Ewm so, to pick the surface form, we nmstkllow wily tile speaker haq used ~t given expression torepresel~t a COIIgellt,If we can determine llow these NPs ehallge, ~,lldwhat effect they bawl then we can choose the speechrecognition candidates more accurately.3.2 Analysis of NP  ChangesIn order to analyze NI' changes in a dialogue we.
in-spected 50 dialogues in a corpus.
As a result of theanalysis, NP changes arc categorized into three mainclasses: 1) Change by lexical e.ohesion: (tiffs classcorresponds to reiteration\[5\]), 2  Change by dif-fere.nt v iewpoints:  (described in detail in the nextparagraph), and 3) Change by misrecognit ion.There are two aspects of viewpoint, which are thestandpoinl of the agent and the node of the concept.in an inquiry dialogue, the standpoints of the agentsare.
always different.
Thus, this class has only twostlb cla~ssl!s :2(a) iioint keeping: both agents see the s;uuet~odc of a concept, and this subclass is dividedaccording to the SEI.'
:i. ditferent expression-e.g.
"walashf' and "Yama0ka-san".il.
addit imt of prefixe.g.
"lUUSyO" and "9o-juusyo".iii.
COml)lex a mixture of 2(a)i and 2(a)ii,2(I)) shifting: the viewpoint of one of the agentsshifts from thc node of a conccpt o a node ofa related concept, and this is divided into:i. shorten inge.g.
"Kokusai-kaigf'(lntenrational Confer-euee) and "kaiqf' (tire conference).it.
un i t ing-e.g.
"ryousyuu-syo-to saNka-touroku-syo"(areceipt and an application form) and '"2-syurnt-uo syorltf'(two types of forms).ACRES DE COLlNG-92, NA~rzs, 23-28 lot's 1992 1 1 5 3 PRec.
OF COLING-92, NA~ri~s, Auo.
23-28, 1992Inode I ~ - .
,v .
.~ .~.
.
.
.
.
.
.
.
-Figure h Example of NP knowledge baseiii.
specif ication-e.g.
"niNzuu"(nnmber of people) and "saNka-niNzuu" (number of participants).3.3 Domain -dependent  KnowledgeConfiguration: q-'he domain-dependent k owledgebase consists of a network of nodes and links.
Basicnodes are divided into three types: a concept noderepresenting a particular thing or concept retained inhuman memory, a lexleal node representing a par-tieular word or phrase used when expressing some-thing, and a var iable node representing a particu-lar value corresponding to a valuable concept, whichcan have a specified value.
A variable node can be in-stantiated by executiug tbe effect of a completcd plan(usually by GET-VALUE-UNIT ill Inleractiou plan\[11\]),so that it can have a particular SEF as the valnc of thenode.
For example, "Yamaoka" could be the value ofa variable node corresponding to a concept node of'name' in a sentence like "My name is Yamaoka ".The following types of links are defined: is-alink, representing a superordinate/subordiuate rela-tion between two concept nodes, par t -o f  link, rep-resenting a whole/part relation between two conceptnodes, causal link, representing a causal relationbetween two concept nodes, prag llnk, representinga pragmatic relation to connect a particular conceptnode to a lexical node representing the tyllical SEFforthe concept, value link, representing an instancevalue relation between a particular valuable conceptnode and a variable node which has been bound tothe SEF of its value, and eq llnk, representing thesame meaning between two lexical nodes.Extension of eq link: In order to make the knowl-edge base sensitive to the changes considered in Sec-tion 3.2, tile eq link is extended.
This lets us toadd applicable conditions to eq links as sub-types oftile link.
Applicable conditions are defined based ouclasses of the categorization i 3.2.
For example, ifone lexical node is a polite SEF of another, the twolexical nodes can be emmected with an eq-if-politellnk, e.g.
"juusyo" and "go-juusyo"(see Fig.
1).4 Selnctlon St rategyIll the dialogue, a speaker chooses an expression ac-cording to tile situation, the preceding context, andhis/her beliefs.
Assuming that tile system has recog-nized such conditions, we can efficiently choose thecorrect speech recognition candidate by searching theSEFs that are appropriate under the conditions.4.1 Rules of Appl icable Condit ions\[terc, two terms are defined for explanation:seed: if the predicted contextual information isbolmd to a particular SEF, then the seed of tilecontextual information is tile SEI", otherwise theseed is the value of the lexieal node linked by tbel)rag llnk to the concept node corresponding tothe contextual information,preferable  set: a set of SEFs derived from a seed byan applicable rnlc, whicb then takes first priorityfor selecting the candidate.The basic rule for making a preferable set is: col-lect tile SEFs by following the eq link from the sced.Because in this paper we are focusing on dialoguesituations and contcxts ratber than the speaker's be-liefs, we only cover rules regarding changes by dif-ferent viewpoints.For a predicted contextual information I ,  consid-ering the dialogue situations ill Class 2(a):I. if I is in the territory of information of the otheragent, then make a preferable set by followingthe eq-if-pol ite link from the seed,additionally, considering the preceding context:2. if \[ has an antecedent which denotes the statusof the other agent, i.e., there is an instantiatedvariallle node corresponding to I , then replacethe seed with the antecedent, i.e., the SEF ofI.he variable node, and make a preferable sct byfollowing the eq-if-pol lte llnk from the seed.Considering the contexts ill Class 2(b):3. if 1 is a compound noun, (it's obviously the an-tecedent) hen shift the seed to the concept one-level up t and make a prefcrablc set using thebasic rule,4.
if l includes two or more concepts or SEFs andthere is a concept node which is the upper nodeof both of these concepts, then shift the seed tothe upper conceptand make a preferable set using the basic rule 2,I Precisely, shifting a seed to a concept metals an operationto replace the seed with the SI~F of the lexical node followedby the prag llnk from the concept node.In this case an auxilisa'y word is usually added.AcrEs DE COLING-92.
NA,'CrE.s, 23-28 AOt~r 1992 1 I 5 4 PRec.
ot: COLING-92, NANTES.
AUG. 23-28.
1992In daily dialogue, speakers apply combinations ofthe above rules and other rules, but in this study wearc concentrating on simpler cases.4.2 Seleetion A lgor i thmOur ultimate goal is to select the correct speechrecognition candidate from the predicted contextualinformation.
An algorithm to do this is roughly defined by following the three steps:1. provide contextual information,2.
make a prefcrable set from i by the rules,3.
compare speech recognition outputs with 2,and if all equivalent is foundthen pick it ms the ai)propriate candidate,else goto 2.Steps 1 and 2 above are I)acktracking points.
Fordetails of Step l, see \[1I\],\[12\].
l,'urthcr large-scaleexperiments may deternfinc hcuristically how manytimes Step 2 should be iterated.5 Examples  and Eva luat ionhi this section, we examine some polite expressionsaud compound NPs that are common in telel)holminquiry dialogues.5.1 Pol i te expressionsAn examl)le of the process for detecting the appropriate SEF given a polite expression, is shown throughthe following subdialogue, focusing on discourse n-tities.
(u l )  Q: TouT~oku-youshi-wo okutte-kudasai.
(Please send me a registration from.
)(u2) S: Go-juusyo-wo negai-shi-masu.
(May \[ haw~ your address?
)(u3)  Q: Juusyo-wa Osaka.shi .
.
.
.
.
.
desu.
(My address is Osaka-city .
.
.
.
.
.
.
)where agent Q is the questioner and S is tfie secre-tariat.This example can be recognized in the send-somthing domain plan (m Section 2).
First u l  isrecognized and understood a.s an utterance which ill-troduces the domain plan.
Then, fi)r the next utterance by S (u2), since the system does not hohl thestatement that S knows where to send a form, e.g.the wdue of Q's address, an utterance requesting thevalue of the destination is tirst predicted, and con-textual information about the 'destination' conceptcan be provided (Step 1).Next, due to the constraint in tile plan, Rule 1is applied to the contextual information.
'fhen, thepreferable set of SEFs is derived by the rule(Step 2).Although the tirst Step 3 fails because "go-juusyo" is not the exact polite form of the first seed"okurisakf'(destination), the second time it, picks"yo-juusyo" ms the appropriate SEF because one oftim lower concepts, 'address', can be the next seed.On the other band, when processing 113, the set ofpolite tbrms for the 'address' is not preferred.Table 1: Result of l)ataba.~e InspectionComm Act Type ~ SF, F Type Number\[)FFFR-ACTION SP -- polite 25normal 4Hit m)rmM 22REQUEST-ACTION SP normal 2}IR polite 4normal 3CDNFI tlII-AC'I'I fin HR polite 3normal 5The communicative act type in the first column:is ~-etype of the utterance "to send".
The speaker in the second colulnn is the speaker of the target SEF, with SP in-dicating the speaker in the first COblntn, and HR, hearer.Evaluati(m: We evaluated this tnethod by inspect-lug SEFs for 'destinatiou' in the ATR diak)guedatabase\[4\].
The target corpus, whose topic is "Confi~rence registration", has 85 conversations, 195fi ut-terance units, and 3085 sentences.
Moreover, the tar.get expressions are restricted to those uttered in asegment of the send-somet.hing domain plan.
TheevaluaLion was done in the tollowing way:1.
H.etrieve sentences which have the verb "okumg'(to Selld) or syllonylllOllS w~.rbs as tile lllaill verbof the sentelice (lfll sentences).Then, output the utterance refit together withthe next utterance unit ( 161 pairs).2.
Pick tim i)airs in which there is a expressionabout 'destination' (43 pairs).Filter by the send-something domain plan, andthose pairs that are not recognized are elimi-.nated (32 pairs remain).3.
Cl~kssify the target expressions (68 expressions)into tile othm"s territory (a2 polite and 12 nor-real) and the spe.aker's (24 normal).The results are shown in the Tal)le 1.
Tiffs inspection shows that ill (an" target, dOiqlaill, I~lle frameworkdescribed m the paper is useful for selecting a sur-face expression that is appropriate in the dialoguesituation.Example (Vocative): Consider the subdialoguethat follows tile above subdialogue:(u4) Q: Namae-wa Suzuki-Mayumi-desu.
(My name is Maymni Suzuki.
)(u5) ?
': ?'uzuki-Mayumi-sama-desa-ae.(Ms.
Mayumi Suzuki, correct?
)After recognizing 114 by the saule interaction plana.s the first example, a variable node correspondingto Q's name is instantiated and bound to "SuzukiMayumi".
Then, for the next utterance by S (u5),we can predict the confirmation utterance includingthe contextual intbrmation about Q's name as a dis-course entity.
Consequently, we can select the SI';F"Suzuki-Mayumi-sama"(polite form) by the contex-tual information and the applicable rule 2.ACII~S DE COLING-92, NAM'Es, 23-28 hotrr 1992 1 1 5 5 Pace, OF COLING-92, NANTES, AUG. 23-28, 19925.2 Compomld  NPsCompound NPs can roughly be classified into l)rol)erNPs and common NPs.
Predicting SEFs from a com-mon NP is usually done by shifting the seed to theupper level (by Rule 3).
For example;(u6) S: 7burokn.youshi-wa o-miehi-desyou-ka?
(Do you have an application form?
)(uT) Q: Mada-dcsu.
(Not yet.
)(u8) Youshi-wo okutte-kudasai.
(Please send me a form.
)In this example, u6 instantiates the sendsomething domain plan by tile effect chain\[7\].
Then,since we know from u7 that the effect (the goal ofthis subdialogue) is not satisfied, we can predict hatthe next utterance hy Q (u8) ruay concern introduc-ing the action to send a form, and it.
irmludes contextual information about 'application form'.
In theknowledge base, 'form' is tile concept node just above'application form'.
Consequently, by applicable ruin3, we select " YoushF(forn 0 directly.On the other l~and, predicting SEFs tbr proper NPsrequires another ule to creat.e the donlain-dependentknowledge base for shortening, llerc, we use thedependency relationships within NP\[91 to abbrevi-ate a proper compound NP.
For exalnph~, applyingthis rule to a proper compound NP "Kyoto-Kokusai-Kaigijoff'(Kyoto International Conference Center),we get a preferable set of SEFs inelnding "Kyoio-Kaigijon"(Kyoto Conference Center) and "Kokusai-Katgoou"(International Conference Center), ill addi-tion to the basic upper SEF "l(aiyzjou"(confcrencecenter).
Consequently, we call select "Kokusai-kaigOou" in u l0  in the following subdialogue witha take-transportation domain plan;(u9) S: Kyoto-koknsai-kaiyljou-ewa basu-gar~you-deki-masu(There is a bus that goes to the b:yotohlternational C,onferenee Center.
)(u l0)  Q: Kokusa~-ka~gUou-made ikur'a-desu-ka~(Ilow much is it to the InternationalConference Center?
)At the moment, we define a short link to connoel lexieal nodes created by abbreviation rules tothe proper compound NP thai instantiates a variablenode.6 ConclusionThis paper has proposed a context-sensitive methodof predicting NPs in the next utterance of tele-phone inquiry dialogues.
Abstract information aboutthe constituents of the next utterance can be pre-dicted based on the dialogue interpreting model.Then, domain-dependent knowledge for NP usagewas developed based on an extended NP identifica-tion model.
Tile knowledge base is characterized byits ability to derive the set of possible surface ex-pression forms from the predicted contextual infor-nration.
We define rules for applicable conditions,particularly ill polite Japanese, bmsed on an anal-ysis of NP changes.
Finally, using the above twomechanisms a strategy was proposed for selecting tileappropriate surface xpression form representing thepredicted concept in a context-sensitive way.In the fllture, we plan to integrate this method witha method of predicting expressions of tile speaker'sintention, tp form a complete system.
It is also vitalto make tile method more powerful, so it can au-tomatically construct he domain-dependent k owl-edge base from thesauri and/or corpora of tile do-main, and call model and recognize various dialoguesituations.AcknowledgementsTi~e authors wouhl like to thank Dr. Kurematsu, Presi-dent of ATR h, terpreting Telephony Labs., and other col-leagues for their encouragement and thought-provokingdiscussio,,.II.efi~rnnees\[1\] l)oug|~u E. Appelt.
Planning English Sentences.Studies in Natural Language Processing.
OambridgeUniversity Dress, 1985.\[2\] Eugene Charniak.
Motivation analysis, abductiveunification, and nonmonotonic equMity.
ArtificialIntelligence, 34:275-295, 1988.\[3\] llcrbert 11.
Clark and Eve V. Clark.
Psychology andLanguage -An bltroduction to Psycholinguistics-,chapter 6, pages 223-258. llarcourt Brace Jo-vanovich, 1977.\[4\] Terumasa Ehara, I<entaro Ogura, and Tsuyoshi Mo-rimoto.
ATR dialogue database.
In Proceedings of1CSLP'90, pages 1093 1096, November 1990.\[5\] M. A. K. llalliday and Ruqaiya Ilasan.
Cohesionin English, chapter 6, pages 274 292.
LONGMAN,1976.\[6\] Alexander G. llauptmann, Sheryl R. Young, andWayne II.
Ward.
Using dialog-level kaowledgesources to improve speech recognition, in Proceed-ings of AAA\['88, pages 729 733, 1988.\[7\] ttitoshi Iida, Takayski Yamaoka, and ItidekazuArita.
Three typed pragmatics for dialogue struc-ture analysis.
In Proceedings of COLING'90, pages370-372, August 1990.\[8\] Akio Kamio.
Proximal and Distal \[nforamtion: ATheory of Territory of ln\]ormation in En91ish andJapauese.
PhD thesis, University of Tsukuba, March1986.\[9\] Masahiro Miyazaki.
Automatic segmentationnlelhod for conq>ound words nsillg seluantic depen-dency relationships between words.
Journal oJ lnfofmarion Processing Society of Japan, 25(6):970-979,1984. is Japanese.Izuru Nogaito and flitoshi lida.
Noun phra.ue identi-fication in diMogue and its application.
In Proceed-ings of ~nd International Conference on Theoreticaland Methodological Issues in Machine Translation ofNatu,cd Languages, June 1988.Takayuki Yamaoka and Hitoshi lida.
A method topredict the next utterance using a four-layered planrecognitioa model.
In Proceedings of ECAI'90, pages726 731, Atlgust 1990.Takayuki Yamaoka and liitoshi lids.
Dialogue ill-terl>retation model and its application to next utter-anne prediction for spoken langm~ge processing.
InProceedings of Eurospeech'91, September 1991.\[io\]\[nlit2\]ACRES DE COLING-92, NAi'Z~S, 23-28 Ao~r 1992 1 1 S 6 PRoc.
or: COLING-92, N^NrEs, AO~.
23-28.
1992
