Engl ish-to-Mandarin Speech Translation with HeadTransducersHiyan  A lshawiAT&T Labs180 Park AvenueF lorham Park, NJ 07932-0971, USAhiyan@ research, at t. comAbst rac tWe describe the head transducer modelused in an experimental English-to-Mandarin speech translation system.Head transduction is a translationmethod in which weighted finite statetransducers are associated with source-target word pairs.
The method is suit-able for speech translation because itallows efficient bottom up processing.The head transducers in the experimen-tal system have a wider range of out-put positions than input positions.
Thisasymmetry is motivated by a tradeoff be-tween model complexity and search effi-ciency.1 In t roduct ionIn this paper we describe the head transducermodel used for translation in an experimentalEnglish-to-Mandarin speech translation system.Head transducer models consist of collections ofweighted finite state transducers associated withpairs of lexical items in a bilingual exicon.
Headtransducers operate "outwards" from the heads ofphrases; they convert the left and right depen-dents of a source word into the left and right de-pendents of a corresponding target word.The transducer model can be characterized asastatistical translation model, but unlike the mod-els proposed by Brown et al (1990, 1993), thesemodels have non-uniform linguistically motivatedstructure, at present coded by hand.
The under-lying linguistic structure of these models is similarto dependency grammar (Hudson 1984), althoughdependency representations are not explicitly con-structed in our approach to translation.
The origi-nal motivation for the head transducer models wasFei XiaDepar tment  of Computer  andInformat ion ScienceUniversity of PennsylvaniaPhi ladelphia,  PA 19104, USAfx iaQcis .upenn.eduthat they are simpler and more amenable to au-tomatic model structure acquisition as comparedwith earlier transfer models.We first describe the head transduction ap-proach in general in Section 2.
In Section 3 weexplain properties of the particular head transduc-ers used in the experimental English-to-Mandarinspeech translator.
In Section 4, we explain howhead transducers help satisfy the requirements ofthe speech translation application, and we con-clude in Section 5.2 B i l ingua l  Head Transduct ion2.1 Bilingual Head TransducersA head transducer M is a finite state machine as-sociated with a pair of words, a source word wand a target word v. In fact, w is taken from theset V1 consisting of the source language vocab-ulary augmented by the "empty word" e, and vis taken from V~, the target language vocabularyaugmented with e. A head transducer reads froma pair of source sequences, a left source sequenceL1 and a right source sequence Rt; it writes to apair of target sequences, a left target sequence L2and a right target sequence R2 (Figure 1).Head transducers were introduced in Alshawi1996b, where the symbols in the source and tar-get sequences are source and target words respec-tively.
In the model described in this paper, thesymbols written are dependency relation symbols,or the empty symbol e. The use of relation sym-bols here is a result of the historical developmentof the system from an earlier transfer model.
Aconceptually simpler translator can be built usinghead transducer models with only lexical items,in which case the distinction between different de-pendents i  implicit in the state of a transducer.In head transducer models, the use of relationscorresponds to a type of class-based model (cf Je-54Figure i: Head transducer M converts the se-quences of left and right relations (r~.. .
r~) and(r~+ 1 .
.
.
r~) of w into left and right relations2 2 2 2 ( r l .
.
.
r j )  and (rj+t...rv) of v.linek, Mercer and Roukos, 1992).We can think of the transducer as simultane-ously deriving the source and target sequencesthrough a series of transitions followed by a stopaction.
From a state qi these actions are as fol-lows:?
Selection of a pair of dependent words w' andv ~ and transducer M ~ given head words w andv and source and target dependency relationsrl and r s. (w ,w '  E V1; v ,v  t E Vs.)The recursion takes place by running a headtransducer (M ~ in the second action above) to de-rive local dependency trees for corresponding pairsof dependent words (w',vl).
In practice, we re-strict the selection of such pairs to those providedby a bilingual exicon for the two languages.
Thisprocess of recursive transduction of local trees isshown graphically in Figure 2 in which the pair ofwords starting the entire derivation is (w4, v4).2.3 T rans la torA translator based on head transducers consistsof the following components:* A bilingual lexicon in which entries are 5-tuples (w,v, M,q,c), associating a pair ofsource-target words with a head transducerM, an initial state q, and a cost c.Left transition: write a symbol rl onto theright end of L1, write symbol r2 to position ain the target sequences, and enter state qi+l.A parameter table giving the costs of actionsfor head transducers and the recursive trans-duction process.?
Right transition: write a symbol rl onto theleft end of R1, write a symbol r~ to position ain the target sequences, and enter state qi+l.?
Stop: stop in state qi, at which point the se-quences L1, R1, L~ and R~ are consideredcomplete.In simple head transducers, the target positionscan be restricted in a similar way to the sourcepositions, i.e., the right end of L2 or the left endof R2.
The version we used for English-to-Chinesetranslation allows additional target positions, asexplained in: Section 3.2.2 Recurs ive  Head Transduct ionWe can apply a set of head transducers recursivelyto derive a pair of source-target ordered depen-dency trees.
This is a recursive process in whichthe dependency relations for corresponding nodesin the two trees are derived by a head transducer.In addition to the actions performed by the headtransducers, this derivation process involves theactions:?
Selection of a pair of words w0 E V1 and v0 EV~, and a head transducer M0 to start theentire derivation.?
A transduction search engine for finding theminimum cost target string 'for an inputsource string (or recognizer speech lattice).The search algorithm used in our implemen-tation is a head-outwards ynamic program-ming algorithm similar to the parsing al-gorithm for monolingual head acceptors de-scribed in Alshawi 1996a.
Head-outwardsprocessing techniques were developed orign-inally for lexically-driven parsing (Sata andStock 1989, Kay 1989).3 Eng l i sh -Ch inese  HeadTransducers3.1 Source  and  Target  Pos i t ionsIn deciding the set of allowable positions for sourceand target transitions, there are tradeoffs involv-ing model size, flexibility for modeling word-orderchanges in translation, and computational effi-ciency of the search for lowest cost transductions.These tradeoffs led us to constrain the sourcepositions of transitions to just two, specifically thesimple left and right source positions mentioned inthe description of transitions in Section 2.1.
Thisrestriction means that the transduction search canbe carried out with the type of algorithm used for55wl  w2 w3 w4 w5 w6 w7 wSv$ v6 vii v3  v4 v lO  ~ v9 vO'Figure 2: Recursive head transduction of a stringtempora l ,+  1 , -9~.~actor , -  !
,- 11- -  ~ .
.
.
.
temporal,+ 1,-9Figure 3: Simplified transitive verb head transducer56head-outwards context free parsing.
In particular,we use a dynamic programming tabular algorithmto find the minimal cost transduction of a wordstring or word-lattice from a speech recognizer.The algorithm maintains optimal "active-edges"spanning a segment of the input string (or twostates in the recognition word-lattice).
This useof context free algorithms is not possible if thenumber of possible source positions for transduc-t ions is increased so that incomplete transducersource sequences are no longer simple segments.However, the number of target positions fortransductions is not constrained by these effi-ciency considerations.
For English-to-Chinesetranslation, we can decrease the complexity of thetransducers (i.e.
reduce the number of states andtransitions they have) by allowing multiple targetpositions to the left and right of the head.
Themotivation for this is that the required reorderingof dependents can be achieved with fewer trans-ducer states by accumulating the dependents intosubsequences to the left and right of the head.
Theactual left and right target sequences are formedby concatenating these subsequences.
We can usethe following notation to number these additionalpositions.
The head is notionally at position 0,and the "standard" positions immediately to theleft and right of the head are numbered as -1 and+1 respectively.
The position that extends the kthsubsequence to the left of the head outwards fromthe head is numbered -2k  + 1, while the positionthat extends this same subsequence inwards to-wards the head is labeled -2k .
The positions tothe right of the head are numbered analogouslywith positive integers.3.2 Examples  of  Dependency  Re la t ionHead TransducersAn example of the structure of a simplified headtransducer for converting the dependents of a typ-ical English transitive verb into those for a corre-sponding Chinese verb is shown in Figure 3.
Thenodes in the figure correspond to states; a bilin-gual lexical entry would specify q0 as the initialstate in this case.
Transitions are shown as arcsbetween states; the label on an arc specifies therelation symbol, source position, and target posi-tion, respectively.
Stop actions are not shown,though states allowing stop actions are shownas double circles, the usual convention for finalstates.
A typical path through the state diagramis shown in bold: this converts the English depen-dency sequence for statement sentences with thepatternactor head object temporalinto the corresponding Chinese sequenceactor temporal head object.Similarly, an English dependency sequence for yes-no questionsmodal actor head object temporalis converted into the Chinese sequenceactor temporal modal head object MA,the transducer stopping in state q6, MA being therelation between the head verb and the Chineseparticle for yes-no questions.
The final statesfor this transducer network are kept distinct sothat different costs can be assigned by training tothe stop actions and modifier transitions at thesestates.Another example is the English-to-Chinesehead transducer for noun phrase dependency rela-tions shown in Figure 4.
Typical target positionsfor transitions corresponding to noun phrase mod-ification (noun phrases are head-final in Chinese)are as follows:head: 0 ( f l ight )nominal: -1 (a i r l ine)ad ject ive:  -3 (cheap)possessive: -5 (Continental~s)relative: -6 (that leaves NYC)locative: -8 (from NYC)temporal: -9 (before one pm)classifier: -I0 (pint)specifier: -11 (a11)cardinal: -II (five)ordinal: -11 (first)DE: -2, -4, or -6The position for transitions emitting the Chi-nese particle pronounced DE may be either -2, -4,or -6, depending on the transducer states for thetransition.
The different states effectively codethe presence of different modifier types.
It shouldalso be noted that the above positions do not com-pletely define the order of modifiers in the trans-duction.
For example, the relative order of targetspecifiers, cardinals, and ordinals will depend onthe order of these modifiers in the source.3.3 Mode l  Construct ionThe head transducer model was trained and evalu-ated on English-to-Mandarin Chinese translationof transcribed utterances from the ATIS corpus(Hirschman et al 1993).
By training here we57DE,O.-2cardinaJ.. I.- I IcardinaL-l.-I In(~mmal,-I,-\[specifier,- I .- I Ispecifier,- I , .
I lpoueuive,+l,-5sl0ccifier,-l.-II ~ ctassifter,0.-10 | I I ~ Iocaiv?.+l,-8 I temporaL+l.-9specifier.- I .
.
!
Ipossessive.?
I .-5locative.+ t .-8 temporal.
?l.-9 ~ relative,+l,-6 \[ DE,0,-4locallve,+l,4 n tempond.+l,-9 ) mlative,+l,-6D~0.-6relanve.+ I..6relafive.,,.I ,-6Figure 4: Head transducer for noun phrase dependents58simply mean assignment of the cost functions forfixed model structures.
These model structureswere coded by hand as a head transducer lexicon.The head transducers were built by modifyingthe English head acceptors defined for an earliertransfer-based system (Alshawi 1996a).
This in-volved the addition of target relations, includingsome epsilon relations, to automaton transitions.In some cases, the automata needed to be mod-ified to include additional states, and also sometransitions with epsilon relations on the English(source) side.
Typically, such cases arise whenan additional particle needs to be generated onthe target side, for example the yes-no questionparticle in Chinese.
The inclusion of such parti-cles often depended on additional distinctions notpresent in the original English automata, hencethe requirement for additional states in the bilin-gual transducer versions.In fact, many of the automata in these entrieshad the same structure, and are independent ofthe ATIS domain.
Domain dependence and thedifferences in word behavior (for example the dif-ferences in behavior between two verbs with thesame subcategorization) were due to the costs ap-plied when running the automata.
The methodused to assign the cost parameters for the modelcan be characterized as "supervised iscriminativetraining".
In this method, costs are computed bytracing the events involved in producing transla-tions of sentences from a source training corpus;a bilingual speaker classifies the output transla-tions as positive or negative xamples of accept-able translations.
Details of this cost assignmentmethod are presented in Alshawi and Buchsbaum1997.4 Head Transducers in SpeechTranslationSpeech translation has special requirements forefficiency and robustness.
We believe that headtransduction models have certain advantages thathelp satisfy these requirements.Rank ing  Headtransduction models are weighted, so the costsfor translation derivations can be combined withthose from acoustic processing.
Weighted modelscan also contribute to efficiency because dynamicprogramming can be used to eliminate suboptimalderivations.
This is particularly important whenthe input is in the form of word lattices.
Sincethe contributions of both the source, target, andbilingual components of the models are applied si-multaneously when computing the costs of partialderivations, there is no need to pass multiple alter-natives forwards from source analysis to transferto generation; the translation ranked globally op-timal is computed with a single admissible search.Eff ic iency In addition to the points made inthe preceding paragraph on ranking, we notedearlier that transduction with appropriately re-stricted source positions for transitions can be car-ried out with search techniques imilar to con-text free parsing (e.g.
Younger 1967).
Headoutward processing with a lexicalized model alsothe obvious advantage to efficiency that only thepart of the model related to the source words inthe input needs to be active during the searchprocess.
In an experiment comparing the effi-ciency of head transduction to our earlier transferapproach, the average time for translating tran-scribed utterances from the ATIS corpus was 1.09seconds for transfer and 0.17 for head transduc-tion.
This speed improvement was possible whilealso improving memory usage and translation ac-curacy.
Details of the experiment are presentedin Alshawi, Buchsbaum, and Xia, 1997.
The ef-ficiency of head transduction has allowed us tostart experimenting with (pruned)" word latticesfrom speech recognition with the aim of produc-ing translations from such word lattices in realtime.Robustness  Bottom-up lexicalized translationis inherently more robust than top-down process-ing since it allows maximal incomplete partialderivations to be identified when complete deriva-tions are not possible.
This is particularly impor-tant in the case of speech translation because theinput string or word lattice often represents flag-mentary, illformed, or "after thought" phrases.When complete derivations are not possible, ourexperimental system searches for a span of the in-put string or lattice with the fewest fragments(or the lowest cost such span if there are sev-eral}.
Lowest-cost translations of such fragmentswill already have been produced by the transduc-tion algorithm, so an approximate translation ofthe utterance can be formed by concatenating thefragments in temporal order.
In the limit, thisapproach degrades gracefully into word-for-wordtranslation with the most likely translation of eachinput word being selected.59-5 Conc lUs ionHead transducers offer efficiency and robustnessadvantages to the speech translation application;there is empirical evidence supporting this claimat least in the case of comparison with a transferapproach.
We have also argued that allowing mul-tiple target positions for transitions increases theflexibility of transducers without an adverse ffecton efficiency.
The focus of our current researchis to take advantage of the relative simplicity ofhead transducer models in working towards fullyautomatic model acquisition.Re ferencesAlshawi, H., A.L.
Buchsbaum, and F. Xia.
1997.
"A Comparison of Head Transducers and Trans-fer for a Limited Domain Translation Applica-tion".
In Proceedings of the 35th Annual Meet-ing of the Association for Computational Lin-guistics, Madrid.Alshawi, H. and A.L.
Buchsbaum.
1997.
"State-Transition Cost Functions and an Applicationto Language Translation".
In Proceedings of theInternational Conference on Acoustics, Speech,and Signal Processing, IEEE, Munich, Ger-many.Hudson, R.A. 1984.
Word Grammar.
Blackwell,Oxford.Hirschman, L., M. Bates, D. Dahl, W. Fisher.J.
Garofolo, D. Pallett, K. Hunicke-Smith,P.
Price, A. Rudnicky, and E. Tzoukermann.1993.
"Multi-Site Data Collection and Evalu-ation in Spoken Language Understanding".
InProceedings of the Human Language TechnologyWorkshop, Morgan Kaufmann, San Francisco.19-24.Jelinek, F., R.L.
Mercer and S. Roukos.
1992.
"Principles of Lexical Language Modeling forSpeech Recognition".
In S. Furui and M.M.Sondhi (eds.
), Advances in Speech Signal Pro-cessing, Marcel Dekker, New York.Kay, M. 1989.
"Head Driven Parsing".
In Pro-ceedings of the Workshop on Parsing Technolo-gies, Pittsburgh, 1989.Sata, G. and O.
Stock.
1989.
"Head-Driven Bidi-rectional Parsing".
In Proceedings of the Work-shop on Parsing Technologies, Pittsburgh.Younger, D. 1967.
Recognition and Parsing ofContext-Free Languages in Time n 3.
Informa-tion and Control, 10, 189-208.Alshawi, H. 1996a.
"Head Automata and Bilin-gual Tiling: Translation with Minimal Repre-sentations".
In Proceedings of the 34th AnnualMeeting of the Association for ComputationalLinguistics, Santa Cruz, California, 167-176.Alshawi, H. 1996b.
"Head Automata for SpeechTranslation".
In Proceedings off the Interna-tional Conference on Spoken Language Process-in9, Philadelphia, Pennsylvania.Brown, P., J. Cocke, S. Della Pietra, V. DellaPietra, F. "Jelinek, J. Lafferty, R. Mercer and P.Rossin.
1990.
"A Statistical Approach to Ma-chine Translation".
Computational Linguistics16:79-85.Brown, P.F., S.A. Della Pietra, V.J.
Della Pietra,and R.L.
Mercer.
1993.
"The Mathematics ofStatistical Machine Translation: Parameter Es-timation".
Computational Linguistics 19:263-312.Chen, K.H.
and H. H. Chen.
1992.
"Attachmentand Transfer of Prepositional Phrases with Con-straint Propagation".
Computer Processing ofChinese and Oriental Languages, Vol.
6, No.
2,123-142.60
