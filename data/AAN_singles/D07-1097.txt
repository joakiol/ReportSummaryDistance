Proceedings of the CoNLL Shared Task Session of EMNLP-CoNLL 2007, pp.
933?939,Prague, June 2007. c?2007 Association for Computational LinguisticsSingle Malt or Blended?
A Study in Multilingual Parser OptimizationJohan Hall?
Jens Nilsson?
Joakim Nivre?
?Gu?ls?en Eryig?it?
Bea?ta Megyesi?
Mattias Nilsson?
Markus Saers??Va?xjo?
University, School of Mathematics and Systems EngineeringE-mail: firstname.lastname@vxu.se?Uppsala University, Dept.
of Linguistics and PhilologyE-mail: firstname.lastname@lingfil.uu.se?Istanbul Technical University, Computer Engineering Dept.E-mail: gulsen.cebiroglu@itu.edu.trAbstractWe describe a two-stage optimization of theMaltParser system for the ten languages inthe multilingual track of the CoNLL 2007shared task on dependency parsing.
Thefirst stage consists in tuning a single-parsersystem for each language by optimizing pa-rameters of the parsing algorithm, the fea-ture model, and the learning algorithm.
Thesecond stage consists in building an ensem-ble system that combines six different pars-ing strategies, extrapolating from the opti-mal parameters settings for each language.When evaluated on the official test sets, theensemble system significantly outperformsthe single-parser system and achieves thehighest average labeled attachment score.1 IntroductionIn the multilingual track of the CoNLL 2007 sharedtask on dependency parsing, a single parser must betrained to handle data from ten different languages:Arabic (Hajic?
et al, 2004), Basque (Aduriz et al,2003), Catalan, (Mart??
et al, 2007), Chinese (Chenet al, 2003), Czech (Bo?hmova?
et al, 2003), English(Marcus et al, 1993; Johansson and Nugues, 2007),Greek (Prokopidis et al, 2005), Hungarian (Csendeset al, 2005), Italian (Montemagni et al, 2003), andTurkish (Oflazer et al, 2003).1 Our contribution isa study in multilingual parser optimization using thefreely available MaltParser system, which performs1For more information about the task and the data sets, seeNivre et al (2007).deterministic, classifier-based parsing with history-based feature models and discriminative learning,and which was one of the top performing systemsin the CoNLL 2006 shared task (Nivre et al, 2006).In order to maximize parsing accuracy, optimiza-tion has been carried out in two stages, leading totwo different, but related parsers.
The first of these isa single-parser system, similar to the one describedin Nivre et al (2006), which parses a sentence deter-ministically in a single left-to-right pass, with post-processing to recover non-projective dependencies,and where the parameters of the MaltParser systemhave been tuned for each language separately.
Wecall this system Single Malt, to emphasize the factthat it consists of a single instance of MaltParser.The second parser is an ensemble system, whichcombines the output of six deterministic parsers,each of which is a variation of the Single Malt parserwith parameter settings extrapolated from the firststage of optimization.
It seems very natural to callthis system Blended.Section 2 summarizes the work done to optimizethe Single Malt parser, while section 3 explains howthe Blended parser was constructed from the SingleMalt parser.
Section 4 gives a brief analysis of theexperimental results, and section 5 concludes.2 The Single Malt ParserThe parameters available in the MaltParser systemcan be divided into three groups: parsing algorithmparameters, feature model parameters, and learn-ing algorithm parameters.2 Our overall optimization2For a complete documentation of these parameters, seehttp://w3.msi.vxu.se/users/nivre/research/MaltParser.html.933strategy for the Single Malt parser was as follows:1.
Define a good baseline system with the sameparameter settings for all languages.2.
Tune parsing algorithm parameters once andfor all for each language (with baseline settingsfor feature model and learning algorithm pa-rameters).3.
Optimize feature model and learning algorithmparameters in an interleaved fashion for eachlanguage.We used nine-fold cross-validation on 90% of thetraining data for all languages with a training set sizesmaller than 300,000 tokens and an 80%?10% train-devtest split for the remaining languages (Catalan,Chinese, Czech, English).
The remaining 10% ofthe data was in both cases saved for a final dry run,where the parser was trained on 90% of the data foreach language and tested on the remaining (fresh)10%.
We consistently used the labeled attachmentscore (LAS) as the single optimization criterion.Below we describe the most important parametersin each group, define baseline settings, and reportnotable improvements for different languages duringdevelopment.
The improvements for each languagefrom step 1 (baseline) to step 2 (parsing algorithm)and step 3 (feature model and learning algorithm)can be tracked in table 1.32.1 Parsing AlgorithmMaltParser implements several parsing algorithms,but for the Single Malt system we stick to the oneused by Nivre et al (2006), which performs labeledprojective dependency parsing in linear time, using astack to store partially processed tokens and an inputqueue of remaining tokens.
There are three basicparameters that can be varied for this algorithm:1.
Arc order: The baseline algorithm is arc-eager, in the sense that right dependents areattached to their head as soon as possible, butthere is also an arc-standard version, where theattachment of right dependents has to be post-poned until they have found all their own de-pendents.
The arc-standard order was found3Complete specifications of all parameter settings for alllanguages, for both Single Malt and Blended, are available athttp://w3.msi.vxu.se/users/jha/conll07/.to improve parsing accuracy for Chinese, whilethe arc-eager order was maintained for all otherlanguages.2.
Stack initialization: In the baseline versionthe parser is initialized with an artificial rootnode (with token id 0) on the stack, so that arcsoriginating from the root can be added explic-itly during parsing.
But it is also possible to ini-tialize the parser with an empty stack, in whichcase arcs from the root are only added implic-itly (to any token that remains a root after pars-ing is completed).
Empty stack initialization(which reduces the amount of nondeterminismin parsing) led to improved accuracy for Cata-lan, Chinese, Hungarian, Italian and Turkish.43.
Post-processing: The baseline parser performsa single left-to-right pass over the input, but itis possible to allow a second pass where onlyunattached tokens are processed.5 Such post-processing was found to improve results forBasque, Catalan, Czech, Greek and Hungarian.Since the parsing algorithm only produces projectivedependency graphs, we may use pseudo-projectiveparsing to recover non-projective dependencies, i.e.,projectivize training data and encode informationabout these transformations in extended arc labelsto support deprojectivization of the parser output(Nivre and Nilsson, 2005).
Pseudo-projective pars-ing was found to have a positive effect on over-all parsing accuracy only for Basque, Czech, Greekand Turkish.
This result can probably be explainedin terms of the frequency of non-projective depen-dencies in the different languages.
For Basque,Czech, Greek and Turkish, more than 20% of thesentences have non-projective dependency graphs;for all the remaining languages the corresponding4For Arabic, Basque, Czech, and Greek, the lack of im-provement can be explained by the fact that these data sets allowmore than one label for dependencies from the artificial root.With empty stack initialization all such dependencies are as-signed a default label, which leads to a drop in labeled attach-ment score.
For English, however, empty stack initialization didnot improve accuracy despite the fact that dependencies fromthe artificial root have a unique label.5This technique is similar to the one used by Yamada andMatsumoto (2003), but with only a single post-processing passparsing complexity remains linear in string length.934AttributesTokens FORM LEMMA CPOSTAG POSTAG FEATS DEPRELS: Top + + + + + +S: Top?1 +I: Next + + + + +I: Next+1 + +I: Next+2 +I: Next+3 +G: Head of Top +G: Leftmost dependent of Top +G: Rightmost dependent of Top +G: Leftmost dependent of Next +Figure 1: Baseline feature model (S = Stack, I = Input, G = Graph).figure is 10% or less.6The cumulative improvement after optimizationof parsing algorithm parameters was a modest 0.32percentage points on average over all ten languages,with a minimum of 0.00 (Arabic, English) and amaximum of 0.83 (Czech) (cf.
table 1).2.2 Feature ModelMaltParser uses a history-based feature model forpredicting the next parsing action.
Each feature ofthis model is an attribute of a token defined relativeto the current stack S, input queue I, or partially builtdependency graph G, where the attribute can be anyof the symbolic input attributes in the CoNLL for-mat: FORM, LEMMA, CPOSTAG, POSTAG andFEATS (split into atomic attributes), as well as theDEPREL attribute of tokens in the graph G. Thebaseline feature model is depicted in figure 1, whererows denote tokens, columns denote attributes, andeach cell containing a plus sign represents a modelfeature.7 This model is an extrapolation from manyprevious experiments on different languages andusually represents a good starting point for furtheroptimization.The baseline model was tuned for each of the tenlanguages using both forward and backward feature6In fact, for Arabic, which has about 10% sentences withnon-projective dependencies, it was later found that, with anoptimized feature model, it is beneficial to projectivize the train-ing data without trying to recover non-projective dependenciesin the parser output.
This was also the setting that was used forArabic in the dry run and final test.7The names Top and Next refer to the token on top of thestack S and the first token in the remaining input I, respectively.selection.
The total number of features in the tunedmodels varies from 18 (Turkish) to 56 (Hungarian)but is typically between 20 and 30.
This feature se-lection process constituted the major developmenteffort for the Single Malt parser and also gave thegreatest improvements in parsing accuracy, but sincefeature selection was to some extent interleaved withlearning algorithm optimization, we only report thecumulative effect of both together in table 1.2.3 Learning AlgorithmMaltParser supports several learning algorithms butthe best results have so far been obtained with sup-port vector machines, using the LIBSVM package(Chang and Lin, 2001).
We use a quadratic kernelK(xi, xj) = (?xTi xj + r)2 and LIBSVM?s built-in one-versus-one strategy for multi-class classifica-tion, converting symbolic features to numerical onesusing the standard technique of binarization.
As ourbaseline settings, we used ?
= 0.2 and r = 0 forthe kernel parameters, C = 0.5 for the penalty para-meter, and ?
= 1.0 for the termination criterion.
Inorder to reduce training times during development,we also split the training data for each language intosmaller sets and trained separate multi-class classi-fiers for each set, using the POSTAG of Next as thedefining feature for the split.The time spent on optimizing learning algorithmparameters varies between languages, mainly dueto lack of time.
For Arabic, Basque, and Catalan,the baseline settings were used also in the dry runand final test.
For Chinese, Greek and Hungarian,935Development Dry Run Test Test: UASLanguage Base PA F+L SM B SM B SM BArabic 70.31 70.31 71.67 70.93 73.09 74.75 76.52 84.21 85.81Basque 73.86 74.44 76.99 77.18 80.12 74.97 76.92 80.61 82.84Catalan 85.43 85.51 86.88 86.65 88.00 87.74 88.70 92.20 93.12Chinese 83.85 84.39 87.64 87.61 88.61 83.51 84.67 87.60 88.70Czech 75.00 75.83 77.74 77.91 82.17 77.22 77.98 82.35 83.59English 85.44 85.44 86.35 86.35 88.74 85.81 88.11 86.77 88.93Greek 72.67 73.04 74.42 74.89 78.17 74.21 74.65 80.66 81.22Hungarian 74.62 74.64 77.40 77.81 80.04 78.09 80.27 81.71 83.55Italian 81.42 81.64 82.50 83.37 85.16 82.48 84.40 86.26 87.77Turkish 75.12 75.80 76.49 75.87 77.09 79.24 79.79 85.04 85.77Average 77.78 78.10 79.81 79.86 82.12 79.80 81.20 84.74 86.13Table 1: Development results for Single Malt (Base = baseline, PA = parsing algorithm, F+L = feature modeland learning algorithm); dry run and test results for Single Malt (SM) and Blended (B) (with corrected testscores for Blended on Chinese).
All scores are labeled attachment scores (LAS) except the last two columns,which report unlabeled attachment scores (UAS) on the test sets.slightly better results were obtained by not splittingthe training data into smaller sets; for the remain-ing languages, accuracy was improved by using theCPOSTAG of Next as the defining feature for thesplit (instead of POSTAG).
With respect to the SVMparameters (?, r, C, and ?
), Arabic, Basque, Cata-lan, Greek and Hungarian retain the baseline set-tings, while the other languages have slightly dif-ferent values for some parameters.The cumulative improvement after optimizationof feature model and learning algorithm parameterswas 1.71 percentage points on average over all tenlanguages, with a minimum of 0.69 (Turkish) and amaximum of 3.25 (Chinese) (cf.
table 1).3 The Blended ParserThe Blended parser is an ensemble system basedon the methodology proposed by Sagae and Lavie(2006).
Given the output dependency graphs Gi(1 ?
i ?
m) of m different parsers for an input sen-tence x, we construct a new graph containing all thelabeled dependency arcs proposed by some parserand weight each arc a by a score s(a) reflecting itspopularity among the m parsers.
The output of theensemble system for x is the maximum spanningtree of this graph (rooted at the node 0), which canbe extracted using the Chu-Liu-Edmonds algorithm,as shown by McDonald et al (2005).
FollowingSagae and Lavie (2006), we let s(a) =?mi=1 wciai,where wci is the average labeled attachment score ofparser i for the word class c8 of the dependent of a,and ai is 1 if a ?
Gi and 0 otherwise.The Blended parser uses six component parsers,with three different parsing algorithms, each ofwhich is used to construct one left-to-right parserand one right-to-left parser.
The parsing algorithmsused are the arc-eager baseline algorithm, the arc-standard variant of the baseline algorithm, and theincremental, non-projective parsing algorithm firstdescribed by Covington (2001) and recently usedfor deterministic classifier-based parsing by Nivre(2007), all of which are available in MaltParser.Thus, the six component parsers for each languagewere instances of the following:1.
Arc-eager projective left-to-right2.
Arc-eager projective right-to-left3.
Arc-standard projective left-to-right4.
Arc-standard projective right-to-left5.
Covington non-projective left-to-right6.
Covington non-projective right-to-left8We use CPOSTAG to determine the part of speech.936root 1 2 3?6 7+Parser R P R P R P R P R PSingle Malt 87.01 80.36 95.08 94.87 86.28 86.67 77.97 80.23 68.98 71.06Blended 92.09 74.20 95.71 94.92 87.55 88.12 78.66 83.02 65.29 78.14Table 2: Recall (R) and precision (P) of Single Malt and Blended for dependencies of different length,averaged over all languages (root = dependents of root node, regardless of length).The final Blended parser was constructed by reusingthe tuned Single Malt parser for each language (arc-standard left-to-right for Chinese, arc-eager left-to-right for the remaining languages) and training fiveadditional parsers with the same parameter settingsexcept for the following mechanical adjustments:1.
Pseudo-projective parsing was not used for thetwo non-projective parsers.2.
Feature models were adjusted with respect tothe most obvious differences in parsing strategy(e.g., by deleting features that could never beinformative for a given parser).3.
Learning algorithm parameters were adjustedto speed up training (e.g., by always splittingthe training data into smaller sets).Having trained all parsers on 90% of the trainingdata for each language, the weights wci for eachparser i and coarse part of speech c was determinedby the labeled attachment score on the remaining10% of the data.
This means that the results obtainedin the dry run were bound to be overly optimistic forthe Blended parser, since it was then evaluated onthe same data set that was used to tune the weights.Finally, we want to emphasize that the time fordeveloping the Blended parser was severely limited,which means that several shortcuts had to be taken,such as optimizing learning algorithm parametersfor speed rather than accuracy and using extrapo-lation, rather than proper tuning, for other impor-tant parameters.
This probably means that the per-formance of the Blended system can be improvedconsiderably by optimizing parameters for all sixparsers separately.4 Results and DiscussionTable 1 shows the labeled attachment score resultsfrom our internal dry run (training on 90% of thetraining data, testing on the remaining 10%) and theofficial test runs for both of our systems.
It shouldbe pointed out that the test score for the Blendedparser on Chinese is different from the official one(75.82), which was much lower than expected dueto a corrupted specification file required by Malt-Parser.
Restoring this file and rerunning the parseron the Chinese test set, without retraining the parseror changing any parameter settings, resulted in thescore reported here.
This also improved the aver-age score from 80.32 to 81.20, the former being thehighest reported official score.For the Single Malt parser, the test results are onaverage very close to the dry run results, indicatingthat models have not been overfitted (although thereis considerably variation between languages).
Forthe Blended parser, there is a drop of almost onepercentage point, which can be explained by the factthat weights could not be tuned on held-out data forthe dry run (as explained in section 3).Comparing the results for different languages, wesee a tendency that languages with rich morphology,usually accompanied by flexible word order, getlower scores.
Thus, the labeled attachment score isbelow 80% for Arabic, Basque, Czech, Greek, Hun-garian, and Turkish.
By comparison, the more con-figurational languages (Catalan, Chinese, English,and Italian) all have scores above 80%.
Linguis-tic properties thus seem to be more important than,for example, training set size, which can be seen bycomparing the results for Italian, with one of thesmallest training sets, and Czech, with one of thelargest.
The development of parsing methods thatare better suited for morphologically rich languageswith flexible word order appears as one of the mostimportant goals for future research in this area.Comparing the results of our two systems, wesee that the Blended parser outperforms the SingleMalt parser for all languages, with an average im-937provement of 1.40 percentage points, a minimum of0.44 (Greek) and a maximum of 2.40 (English).
Asshown by McDonald and Nivre (2007), the SingleMalt parser tends to suffer from two problems: errorpropagation due to the deterministic parsing strat-egy, typically affecting long dependencies more thanshort ones, and low precision on dependencies orig-inating in the artificial root node due to fragmentedparses.9 The question is which of these problems isalleviated by the multiple views given by the compo-nent parsers in the Blended system.
Table 2 throwssome light on this by giving the precision and re-call for dependencies of different length, treating de-pendents of the artificial root node as a special case.As expected, the Single Malt parser has lower preci-sion than recall for root dependents, but the Blendedparser has even lower precision (and somewhat bet-ter recall), indicating that the fragmentation is evenmore severe in this case.10 By contrast, we see thatprecision and recall for other dependencies improveacross the board, especially for longer dependencies,which probably means that the effect of error propa-gation is mitigated by the use of an ensemble system,even if each of the component parsers is determinis-tic in itself.5 ConclusionWe have shown that deterministic, classifier-baseddependency parsing, with careful optimization, cangive highly accurate dependency parsing for a widerange of languages, as illustrated by the performanceof the Single Malt parser.
We have also demon-strated that an ensemble of deterministic, classifier-based dependency parsers, built on top of a tunedsingle-parser system, can give even higher accuracy,as shown by the results of the Blended parser, whichhas the highest labeled attachment score for five lan-guages (Arabic, Basque, Catalan, Hungarian, and9A fragmented parse is a dependency forest, rather than atree, and is automatically converted to a tree by attaching all(other) roots to the artificial root node.
Hence, children of theroot node in the final output may not have been predicted assuch by the treebank-induced classifier.10This conclusion is further supported by the observationthat the single most frequent ?frame confusion?
of the Blendedparser, over all languages, is to attach two dependents with thelabel ROOT to the root node, instead of only one.
The frequencyof this error is more than twice as high for the Blended parser(180) as for the Single Malt parser (83).Italian), as well as the highest multilingual averagescore.AcknowledgementsWe want to thank all treebank providers for makingthe data available for the shared task and the (other)organizers for their efforts in organizing it.
Specialthanks to Ryan McDonald, for fruitful discussionsand assistance with the error analysis, and to KenjiSagae, for showing us how to produce a good blend.Thanks also to two reviewers for useful comments.ReferencesA.
Abeille?, editor.
2003.
Treebanks: Building and UsingParsed Corpora.
Kluwer.I.
Aduriz, M. J. Aranzabe, J. M. Arriola, A. Atutxa,A.
Diaz de Ilarraza, A. Garmendia, and M. Oronoz.2003.
Construction of a Basque dependency treebank.In Proc.
of the 2nd Workshop on Treebanks and Lin-guistic Theories (TLT), pages 201?204.A.
Bo?hmova?, J.
Hajic?, E.
Hajic?ova?, and B. Hladka?.
2003.The PDT: a 3-level annotation scenario.
In Abeille?
(2003), chapter 7, pages 103?127.C.-C. Chang and C.-J.
Lin, 2001.
LIBSVM: A Libraryfor Support Vector Machines.
Software available athttp://www.csie.ntu.edu.tw/ cjlin/libsvm.K.
Chen, C. Luo, M. Chang, F. Chen, C. Chen, C. Huang,and Z. Gao.
2003.
Sinica treebank: Design criteria,representational issues and implementation.
In Abeille?
(2003), chapter 13, pages 231?248.M.
A. Covington.
2001.
A fundamental algorithm fordependency parsing.
In Proc.
of the 39th Annual ACMSoutheast Conf., pages 95?102.D.
Csendes, J. Csirik, T. Gyimo?thy, and A. Kocsor.
2005.The Szeged Treebank.
Springer.J.
Hajic?, O.
Smrz?, P. Zema?nek, J.
S?naidauf, and E. Bes?ka.2004.
Prague Arabic dependency treebank: Develop-ment in data and tools.
In Proc.
of the NEMLAR In-tern.
Conf.
on Arabic Language Resources and Tools,pages 110?117.R.
Johansson and P. Nugues.
2007.
Extendedconstituent-to-dependency conversion for English.
InProc.
of the 16th Nordic Conference on ComputationalLinguistics (NODALIDA).M.
Marcus, B. Santorini, and M. Marcinkiewicz.
1993.Building a large annotated corpus of English: the PennTreebank.
Computational Linguistics, 19(2):313?330.938M.
A.
Mart?
?, M.
Taule?, L. Ma`rquez, and M. Bertran.2007.
CESS-ECE: A multilingual and multilevelannotated corpus.
Available for download from:http://www.lsi.upc.edu/?mbertran/cess-ece/.R.
McDonald and J. Nivre.
2007.
Characterizing theerrors of data-driven dependency parsing models.
InProc.
of the Joint Conf.
on Empirical Methods in Nat-ural Language Processing and Computational NaturalLanguage Learning (EMNLP-CoNLL).R.
McDonald, F. Pereira, K. Ribarov, and J. Hajic?.
2005.Non-projective dependency parsing using spanningtree algorithms.
In Proc.
of the Human LanguageTechnology Conf.
and the Conf.
on Empirical Meth-ods in Natural Language Processing (HLT/EMNLP),pages 523?530.S.
Montemagni, F. Barsotti, M. Battista, N. Calzolari,O.
Corazzari, A. Lenci, A. Zampolli, F. Fanciulli,M.
Massetani, R. Raffaelli, R. Basili, M. T. Pazienza,D.
Saracino, F. Zanzotto, N. Nana, F. Pianesi, andR.
Delmonte.
2003.
Building the Italian Syntactic-Semantic Treebank.
In Abeille?
(2003), chapter 11,pages 189?210.J.
Nivre and J. Nilsson.
2005.
Pseudo-projective depen-dency.
In Proc.
of the 43rd Annual Meeting of the As-sociation for Computational Linguistics (ACL), pages99?106.J.
Nivre, J.
Hall, J. Nilsson, G. Eryig?it, and S. Marinov.2006.
Labeled pseudo-projective dependency parsingwith support vector machines.
In Proc.
of the TenthConf.
on Computational Natural Language Learning(CoNLL), pages 221?225.J.
Nivre, J.
Hall, S. Ku?bler, R. McDonald, J. Nilsson,S.
Riedel, and D. Yuret.
2007.
The CoNLL 2007shared task on dependency parsing.
In Proc.
of theJoint Conf.
on Empirical Methods in Natural Lan-guage Processing and Computational Natural Lan-guage Learning (EMNLP-CoNLL).J.
Nivre.
2007.
Incremental non-projective dependencyparsing.
In Human Language Technologies: The An-nual Conf.
of the North American Chapter of the Asso-ciation for Computational Linguistics (NAACL-HLT),pages 396?403.K.
Oflazer, B.
Say, D. Zeynep Hakkani-Tu?r, and G. Tu?r.2003.
Building a Turkish treebank.
In Abeille?
(2003),chapter 15, pages 261?277.P.
Prokopidis, E. Desypri, M. Koutsombogera, H. Papa-georgiou, and S. Piperidis.
2005.
Theoretical andpractical issues in the construction of a Greek depen-dency treebank.
In Proc.
of the 4th Workshop on Tree-banks and Linguistic Theories (TLT), pages 149?160.K.
Sagae and A. Lavie.
2006.
Parser combination byreparsing.
In Proc.
of the Human Language Technol-ogy Conference of the NAACL, Companion Volume:Short Papers, pages 129?132.H.
Yamada and Y. Matsumoto.
2003.
Statistical depen-dency analysis with support vector machines.
In Proc.8th International Workshop on Parsing Technologies(IWPT), pages 195?206.939
