Proceedings of the EMNLP 2014 Workshop on Arabic Natural Langauge Processing (ANLP), pages 93?103,October 25, 2014, Doha, Qatar.
c?2014 Association for Computational LinguisticsTransliteration of Arabizi into Arabic Orthography: Developing aParallel Annotated Arabizi-Arabic Script SMS/Chat CorpusAnn Bies, Zhiyi Song, Mohamed Maamouri, Stephen Grimes, Haejoong Lee,Jonathan Wright, Stephanie Strassel, Nizar Habash?, Ramy Eskander?, Owen Rambow?Linguistic Data Consortium, University of Pennsylvania{bies,zhiyi,maamouri,sgrimes,haejoong,jdwright,strassel}@ldc.upenn.edu?Computer Science Department, New York University Abu Dhabi?nizar.habash@nyu.edu?Center for Computational Learning Systems, Columbia University?
{reskander,rambow}@ccls.columbia.eduAbstractThis paper describes the process of creating anovel resource, a parallel Arabizi-Arabicscript corpus of SMS/Chat data.
The lan-guage used in social media expresses manydifferences from other written genres: its vo-cabulary is informal with intentional devia-tions from standard orthography such as re-peated letters for emphasis; typos and non-standard abbreviations are common; and non-linguistic content is written out, such aslaughter, sound representations, and emoti-cons.
This situation is exacerbated in thecase of Arabic social media for two reasons.First, Arabic dialects, commonly used in so-cial media, are quite different from ModernStandard Arabic phonologically, morphologi-cally and lexically, and most importantly,they lack standard orthographies.
Second,Arabic speakers in social media as well asdiscussion forums, SMS messaging andonline chat often use a non-standard romani-zation called Arabizi.
In the context of natu-ral language processing of social media Ara-bic, transliterating from Arabizi of variousdialects to Arabic script is a necessary step,since many of the existing state-of-the-art re-sources for Arabic dialect processing expectArabic script input.
The corpus described inthis paper is expected to support Arabic NLPby providing this resource.1 IntroductionThe language used in social media expressesmany differences from other written genres: itsvocabulary is informal with intentional devia-tions from standard orthography such as repeatedletters for emphasis; typos and non-standard ab-breviations are common; and non-linguistic con-tent is written out, such as laughter, sound repre-sentations, and emoticons.This situation is exacerbated in the case of Ar-abic social media for two reasons.
First, Arabicdialects, commonly used in social media, arequite different from Modern Standard Arabic(MSA) phonologically, morphologically and lex-ically, and most importantly, they lack standardorthographies (Maamouri et.al.
2014).
Second,Arabic speakers in social media as well as dis-cussion forums, Short Messaging System (SMS)text messaging and online chat often use a non-standard romanization called ?Arabizi?
(Dar-wish, 2013).
Social media communication inArabic takes place using a variety of orthogra-phies and writing systems, including Arabicscript, Arabizi, and a mixture of the two.
Alt-hough not all social media communication usesArabizi, the use of Arabizi is prevalent enough topose a challenge for Arabic NLP research.In the context of natural language processingof social media Arabic, transliterating fromArabizi of various dialects to Arabic script is anecessary step, since many of the existing state-of-the-art resources for Arabic dialect processingand annotation expect Arabic script input (e.g.,Salloum and Habash, 2011; Habash et al.
2012c;Pasha et al., 2014).To our knowledge, there are no naturally oc-curring parallel texts of Arabizi and Arabicscript.
In this paper, we describe the process ofcreating such a novel resource at the LinguisticData Consortium (LDC).
We believe this corpuswill be essential for developing robust tools forconverting Arabizi into Arabic script.93The rest of this paper describes the collectionof Egyptian SMS and Chat data and the creationof a parallel text corpus of Arabizi and Arabicscript for the DARPA BOLT program.1  Afterreviewing the history and features in Arabizi(Section 2) and related work on Arabizi (Section3), in Section 4, we describe our approach to col-lecting the Egyptian SMS and Chat data and theannotation and transliteration methodology of theArabizi SMS and Chat into Arabic script, whilein Section 5, we discuss the annotation results,along with issues and challenges we encounteredin annotation.2 Arabizi and Egyptian Arabic Dialect2.1 What is Arabizi?Arabizi is a non-standard romanization of Arabicscript that is widely adopted for communicationover the Internet (World Wide Web, email) orfor sending messages (instant messaging andmobile phone text messaging) when the actualArabic script alphabet is either unavailable fortechnical reasons or otherwise more difficult touse.
The use of Arabizi is attributed to differentreasons, from lack of good input methods onsome mobile devices to writers?
unfamiliaritywith Arabic keyboard.
In some cases, writing inArabizi makes it easier to code switch to Englishor French, which is something educated Arabicspeakers often do.
Arabizi is used by speakers ofa variety of Arabic dialects.Because of the informal nature of this system,there is no single ?correct?
encoding, so somecharacter usage overlaps.
Most of the encodingin the system makes use of the Latin character(as used in English and French) that best approx-imates phonetically the Arabic letter that onewants to express (for example, either b or p cor-responds to ?).
This may sometimes vary due toregional variations in the pronunciation of theArabic letter (e.g., j is used to represent ?
in theLevantine dialect, while in Egyptian dialect g isused) or due to differences in the most commonnon-Arabic second language (e.g., sh corre-sponds to ?
in the previously English dominatedMiddle East Arab countries, while ch shows apredominantly French influence as found inNorth Africa and Lebanon).
Those letters that donot have a close phonetic approximate in the Lat-in script are often expressed using numerals orother characters, so that the numeral graphically1 http://www.darpa.mil/Our_Work/I2O/Programs/Broad_Operational_Language_Translation_%28BOLT%29.aspxapproximates the Arabic letter that one wants toexpress (e.g., the numeral 3 represents ?
becauseit looks like a mirror reflection of the letter).Due to the use of Latin characters and alsofrequent code switching in social media Arabizi,it can be difficult to distinguish between Arabicwords written in Arabizi and entirely unrelatedforeign language words (Darwish 2013).
Forexample, mesh can be the English word, orArabizi for ??
?not?.
However, in context thesecases can be clearly labeled as either Arabic or aforeign word.
An additional complication is thatmany words of foreign origin have become Ara-bic words (?borrowings?).
Examples includebanadoora ??????
?tomato?
and mobile ??????
?mobile phone?.
It is a well-known practical andtheoretical problem to distinguish borrowings(foreign words that have become part of a lan-guage and are incorporated fully into the mor-phological and syntactic system of the host lan-guage) from actual code switching (a bilingualwriter switches entirely to a different language,even if for only a single word).
Code switchingis easy to identify if we find an extended passagein the foreign language which respects that lan-guage?s syntax and morphology, such as Bas ehra2yak I have the mask.
The problem ariseswhen single foreign words appear without Arabicmorphological marking: it is unclear if the writerswitched to the foreign language for one word orwhether he or she simply is using an Arabicword of foreign origin.
In the case of banadoora??????
?tomato?, there is little doubt that this hasbecome a fully Arabic word and the writer is notcode switching into Italian; this is also signaledby the fact that a likely Arabizi spelling (such asbanadoora) is not in fact the Italian orthography(pomodoro).
However, the case is less clear cutwith mobile ??????
?mobile phone?
: even if it is aborrowing (clearly much more recent than bana-doora ??????
?tomato?
), a writer will likely spellthe word with the English orthography as mobilerather than write, say, mubail.
More research isneeded on this issue.
However, because of thedifficulty of establishing the difference betweencode switching and borrowing, we do not attemptto make this distinction in this annotationscheme.2.2 Egyptian Arabic DialectArabizi is used to write in multiple dialects ofArabic, and differences between the dialectsthemselves have an effect on the spellings cho-sen by individual writers using Arabizi.
BecauseEgyptian Arabic is the dialect of the corpus cre-94ated for this project, we will briefly discuss someof the most relevant features of Egyptian Arabicwith respect to Arabizi transliteration.
For amore extended discussion of the differences be-tween MSA and Egyptian Arabic, see Habash etal.
(2012a) and Maamouri et al.
(2014).Phonologically, Egyptian Arabic is character-ized by the following features, compared withMSA:(a) The loss of the interdentals /?/ and /?/which are replaced by /d/ or /z/ and /t/ or /s/respectively, thus giving those two originalconsonants a heavier load.
Examples in-clude  ???
/zakar/ ?to mention?, ???
/daba?/?to slaughter?,  ???
/talg/ ?ice?,  ???
/taman/?price?, and  ???
/sibit/ ?to stay in place,become immobile?.
(b) The exclusion of /q/ and /?/ from the conso-nantal system, being replaced by the /?/ and/g/, e.g., ???
/?u?n/ ?cotton?, and  ??
?/gamal/ ?camel?.At the level of morphology and syntax, thestructures of Egyptian Arabic closely resemblethe overall structures of MSA with relatively mi-nor differences to speak of.
Finally, the EgyptianArabic lexicon shows some significant elementsof semantic differentiation.The most important morphological differencebetween Egyptian Arabic and MSA is in the useof some Egyptian clitics and affixes that do notexist in MSA.
For instance, Egyptian Arabic hasthe future proclitics h+ and ?+ as opposed to thestandard equivalent s+.Lexically, there are lexical differences be-tween Egyptian Arabic and MSA where no ety-mological connection or no cognate spelling isavailable.
For example, the Egyptian Arabic ??/bu?
?/ ?look?
is ????
/?unZur/ in MSA.3 Related WorkArabizi-Arabic Script Transliteration  Previ-ous efforts on automatic transliterations fromArabizi to Arabic script include work by Chalabiand Gerges (2012), Darwish (2013) and Al-Badrashiny et al.
(2014).
All of these approachesrely on a model for character-to-character map-ping that is used to generate a lattice of multiplealternative words which are then selected amongusing a language model.
The training data usedby Darwish (2013) is publicly available but it isquite limited (2,200 word pairs).
The work weare describing here can help substantially im-prove the quality of such system.
We use thesystem of Al-Badrashiny et al.
(2014) in this pa-per as part of the automatic transliteration stepbecause they target the same conventional or-thography of dialectal Arabic (CODA) (Habashet al., 2012a, 2012b), which we also target.There are several commercial products that con-vert Arabizi to Arabic script, namely: MicrosoftMaren, 2  Google Ta3reeb, 3  Basis Arabic chattranslator4 and Yamli.5  Since these products arefor commercial purposes, there is little infor-mation available about their approaches, andwhatever resources they use are not publiclyavailable for research purposes.
Furthermore, asAl-Badrashiny et al.
(2014) point out, Maren,Ta3reeb and Yamli are primarily intended as in-put method support, not full text transliteration.As a result, their users?
goal is to produce Arabicscript text not Arabizi text, which affects theform of the romanization they utilize as an in-termediate step.
The differences between such?functional romanization?
and real Arabizi in-clude that the users of these systems will use lessor no code switching to English, and may em-ploy character sequences that help them arrive atthe target Arabic script form faster, which other-wise they would not write if they were targetingArabizi (Al-Badrashiny et al., 2014).Name Transliteration  There has been somework on machine transliteration by Knight andGraehl (1997).
Al-Onaizan and Knight (2002)introduced an approach for machine translitera-tion of Arabic names.
Freeman et al.
(2006) alsointroduced a system for name matching betweenEnglish and Arabic.
Although the general goalof transliterating from one script to another isshared between these efforts and ours, we areconsidering a more general form of the problemin that we do not restrict ourselves to names.Code Switching  There is some work on codeswitching between Modern Standard Arabic(MSA) and dialectal Arabic (DA).
Zaidan andCallison-Burch (2011) were interested in thisproblem at the inter-sentence level.
Theycrawled a large dataset of MSA-DA news com-mentaries, and used Amazon Mechanical Turk toannotate the dataset at the sentence level.Elfardy et al.
(2013) presented a system, AIDA,that tags each word in a sentence as either DA orMSA based on the context.
Lui et al.
(2014)proposed a system for language identification in2 http://www.getmaren.com3 http://www.google.com/ta3reeb4 http://www.basistech.com/arabic-chat-translator-transforms-social-media-analysis/5 http://www.yamli.com/95multilingual documents using a generative mix-ture model that is based on supervised topicmodeling algorithms.
Darwish (2013) and Vosset al.
(2014) deal with exactly the problem ofclassifying tokens in Arabizi as Arabic or not.More specifically, Voss et al.
(2014) deal withMoroccan Arabic, and with both French andEnglish, meaning they do a three-way classifica-tion.
Darwish (2013)'s data is more focused onEgyptian and Levantine Arabic and code switch-ing with English.Processing Social Media Text  Finally, whileEnglish NLP for social media has attracted con-siderable attention recently (Clark and Araki,2011; Gimpel et al., 2011; Gouws et al., 2011;Ritter et al., 2011; Derczynski et al., 2013), therehas not been much work on Arabic yet.
Darwishet al.
(2012) discuss NLP problems in retrievingArabic microblogs (tweets).
They discuss manyof the same issues we do, notably the problemsarising from the use of dialectal Arabic such asthe lack of a standard orthography.
Eskander etal.
(2013) described a method for normalizingspontaneous orthography into CODA.4 Corpus CreationThis work was prepared as part of the DARPABroad Operational Language Translation(BOLT) program which aims at developing tech-nology that enables English speakers to retrieveand understand information from informal for-eign language sources including chat, text mes-saging and spoken conversations.
LDC collectsand annotates informal linguistic data of English,Chinese and Arabic, with Egyptian Arabic beingthe representative of the Arabic language family.Egyptian Arabic has the advantage over all otherdialects of Arabic of being the language of thelargest linguistic community in the Arab region,and also of having a rich level of internet com-munication.4.1 SMS and Chat CollectionIn BOLT Phase 2, LDC collected large volumesof naturally occurring informal text (SMS) andchat messages from individual users in English,Chinese and Egyptian Arabic (Song et al., 2014).Altogether we recruited 46 Egyptian Arabic par-ticipants, and of those 26 contributed data.
Toprotect privacy, participation was completelyanonymous, and demographic information wasnot collected.
Participants completed a brief lan-guage test to verify that they were native Egyp-tian Arabic speakers.
On average, each partici-pant contributed 48K words.
The Egyptian Ara-bic SMS and Chat collection consisted of 2,140conversations in a total of 475K words aftermanual auditing by native speakers of EgyptianArabic to exclude inappropriate messages andmessages that were not Egyptian Arabic.
96% ofthe collection came from the personal SMS orChat archives of participants, while 4% was col-lected through LDC?s platform, which pairedparticipants and captured their live text messag-ing (Song et al., 2014).
A subset of the collec-tion was then partitioned into training and evaldatasets.Table 1 shows the distribution of Arabic scriptvs.
Arabizi in the training dataset.
The conversa-tions that contain Arabizi were then further anno-tated and transliterated to create the Arabizi-Arabic script parallel corpus, which consists ofTotal Arabicscript onlyArabizionlyMix of Arabizi and Arabic scriptArabizi Arabic scriptConversations 1,503 233 987 283Messages 101,292 18,757 74,820 3,237 4,478Sentence units 94,010 17,448 69,639 3,017 3,906Words 408,485 80,785 293,900 10,244 23,556Table 1.
Arabic SMS and Chat Training Dataset1270 conversations.
6   All conversations in thetraining dataset were also translated into Englishto provide Arabic-English parallel training data.6 In order to form single, coherent units (Sentence units) ofan appropriate size for downstream annotation tasks usingthis data, messages that were split mid-sentence (often mid-Not surprisingly, most Egyptian conversationsin our collection contain at least some Arabizi;word) due to SMS messaging character limits were rejoined,and very long messages (especially common in chat) weresplit into two or more units, usually no longer than 3-4 sen-tences.96only 15% of conversations are entirely written inArabic script, while 66% are entirely Arabizi.The remaining 19% contain a mixture of the twoat the conversation level.
Most of the mixedconversations were mixed in the sense that oneside of the conversation was in Arabizi and theother side was in Arabic script, or in the sensethat at least one of the sides switched betweenthe two forms in mid-conversation.
Only rarelyare individual messages in mixed scripts.
Theannotation for this project was performed on theArabizi tokens only.
Arabic script tokens werenot touched and were kept in their originalforms.The use of Arabizi is predominant in the SMSand Chat Egyptian collection, in addition to thepresence of other typical cross-linguistic text ef-fects in social media data.
For example, the useof emoticons and emoji is frequent.
We also ob-served the frequent use of written out representa-tions of speech effects, including representationsof laughter (e.g., hahaha), filled pauses (e.g.,um), and other sounds (e.g., hmmm).
When theserepresentations are written in Arabizi, many ofthem are indistinguishable from the same repre-sentations in English SMS data.
Neologisms arealso frequently part of SMS/Chat in EgyptianArabic, as they are in other languages.
Englishwords use Arabic morphology or determiners, asin el anniversary ?the anniversary?.
SometimesEnglish words are spelled in a way that is closerphonetically to the way an Egyptian speakerwould pronounce them, for example lozar for?loser?, or beace for ?peace?.The adoption of Arabizi for SMS and onlinechat may also go some way to explaining thehigh frequency of code mixing in the EgyptianArabic collection.
While the auditing processeliminated messages that were entirely in a non-target language, many of the acceptable messag-es contain a mixture of Egyptian Arabic andEnglish.4.2 Annotation MethodologyAll of the Arabizi conversations, including theconversations containing mixtures of Arabizi andArabic script were then annotated and translit-erated:1.
Annotation on the Arabizi source text toflag certain features2.
Correction and normalization of the trans-literation according to CODA conventionsFigure 1.
Arabizi Annotation and Transliteration ToolThe annotators were presented with the sourceconversations in their original Arabizi form aswell as the transliteration output from an auto-matic Arabization system, and used a web-basedtool developed by LDC (see Figure 1) to performthe two annotation tasks, which allowed annota-tors perform both annotation and transliterationtoken by token, sentence by sentence and reviewthe corrected transliteration in full context.
TheGUI shows the full conversation in both the orig-inal Arabizi and the resulting Arabic script trans-literation for each sentence.
Annotators must97annotate each sentence in order, and the annota-tion is displayed in three columns.
The first col-umn shows the annotation of flag features on thesource tokens, the second column is the workingpanel where annotators correct the automatictransliteration and retokenize, and the third col-umn displays the final corrected and retokenizedresult.Annotation was performed according to anno-tation guidelines developed at the Linguistic Da-ta Consortium specifically for this task (LDC,2014).4.3 Automatic TransliterationTo speed up the annotation process, we utilizedan automatic Arabizi-to-Arabic script translitera-tion system (Al-Badrashiny et al., 2014) whichwas developed using a small vocabulary of 2,200words from Darwish (2013) and an additional6,300 Arabic-English proper name pairs (Buck-walter, 2004).
The system has an accuracy of69.4%.
We estimate that using this still allowedus to cut down the amount of time needed to typein the Arabic script version of the Arabizi bytwo-thirds.
This system did not identify Foreignwords or Names and transliterated all of thewords.
In one quarter of the errors, the providedanswer was plausible but not CODA-compliant(Al-Badrashiny et al., 2014).4.4 Annotation on Arabizi Source Text toFlag FeaturesThis annotation was performed only on sentencescontaining Arabizi words, with the goal of tag-ging any words in the source Arabizi sentencesthat would be kept the same in the output of anEnglish translation with the following flags:?
Punctuation (not including emoticons)o Eh ?
!//Puncto Ma32ula ?
!//Puncto Ebsty ?//Punct?
Sound effects, such as laughs (?haha?
orvariations), filled pauses, and other sounds(?mmmm?
or ?shh?
or ?um?
etc.
)o hahhhahhah//Sound akeed 3arfa :p daenty t3rafy ablia :ppo Hahahahaahha//Sound Tb ana ta7t felahwaao Wala Ana haha//Soundo Mmmm//Sound okay?
Foreign language words and numbers.
Allcases of code switching and all cases of bor-rowings which are rendered in Arabizi us-ing standard English orthography aremarked as ?Foreign?.o ana kont mt25er fe t2demm l pro-jects//Foreigno oltilik okay//Foreign ya Babyy//Foreignbalashhabal!!!
!o zakrty ll sat//Foreigno Bat3at el whatsapp//Foreigno La la la merci//Foreign gedan bs la2o We 9//Foreign galaeeb dandash lel ban-at?
Names, mainly person nameso Youmna//Name 7atigi?
?4.5 Correction and Normalization of theTransliteration According to CODAConventionsThe goal of this task was to correct all spelling inthe Arabic script transliteration to CODA stand-ards (Habash et al., 2012a, 2012b).
This meantthat annotators were required to confirm both (1)that the word was transliterated into Arabic scriptcorrectly and also (2) that the transliterated wordconformed to CODA standards.
The automatictransliteration was provided to the annotators,and manually corrected by annotators as needed.Correcting spelling to a single standard (CO-DA), however, necessarily included some degreeof normalization of the orthography, as the anno-tators had to correct from a variety of dialectspellings to a single CODA-compliant spellingfor each word.
Because the goal was to reach aconsistent representation of each word, ortho-graphic normalization was almost the inevitableeffect of correcting the automatic transliteration.This consistent representation will allow down-stream annotation tasks to take better advantageof the SMS/Chat data.
For example, more con-sistent spelling of Egyptian Arabic words willlead to better coverage from the CALIMA mor-phological analyzer and therefore improve themanual annotation task for morphological anno-tation, as in Maamouri et al.
(2014).Modern Standard Arabic (MSA) cognates andEgyptian Arabic sound changesAnnotators were instructed to use MSA or-thography if the word was a cognate of an MSA98root, including for those consonants that haveundergone sound changes in Egyptian Arabic.7?
use mqfwl ?????
and not ma>fwl ?????
for?locked??
use HAfZ ????
and not HAfz ????
for thename (a proper noun)Long vowelsAnnotators were instructed to reinstate miss-ing long vowels, even when they were written asshort vowels in the Arabizi source, and to correctlong vowels if they were included incorrectly.?
use sAEap ????
and not saEap  ???
for?hour??
use qAlt   ????
and not qlt ???
for ?
(she)said?Consonantal ambiguitiesMany consonants are ambiguous when writtenin Arabizi, and many of the same consonants arealso difficult for the automatic transliterationscript.
Annotators were instructed to correct anyerrors of this type.?
S vs. s/ ?
vs. ?o use SAyg ????
and not  sAyg  ????
for?jeweler??
D vs. Z/ ?
vs. ?o use DAbT ????
and not  ZAbT ????
for?officer?o use Zlmp  ????
and not Dlmp  ????
for?darkness??
Dotted ya vs. Alif Maqsura/ ?
vs. ?.
Alt-hough the dotted ya/ ?
and Alif Maqsura/ ?are often used interchangeably in EgyptianArabic writing conventions, it was neces-sary to make the distinction between thetwo for this task.o use Ely ???
and not ElY  ???
for ?Ali?
(the proper name)?
Taa marbouta.
In Arabizi and so also in theArabic script transliteration, the taa mar-bouta/ ?
may be written for both nominal fi-nal -h/ ?
and verbal final -t/ ?, but for dif-ferent reasons.o mdrsp Ely  ???
?????
?Ali?s school?o mdrsth  ??????
?his school?Morphological ambiguitiesSpelling variation and informal usage cancombine to create morphological ambiguities aswell.
For example, the third person masculine7 Both Arabic script and the Buckwalter transliteration(http://www.qamus.org/transliteration.htm) are shown forthe transliterated examples in this paper.singular pronoun and the third person plural ver-bal suffix can be ambiguous in informal texts.For example:?
use byHbwA bED  ???
??????
and not byHbhbED  ???
?????
for ?
(They) loved each oth-er??
use byEmlwA  ???????
and not byEmlh  ?????
?for ?
(They) did?
or ?
(They) worked?In addition, because final -h is sometimes re-placed in speech by final /-uw/, it was occasion-ally necessary to correct cases of overuse of thethird person plural verbal suffix (-wA) to thepronoun -h as well.Merging and splitting tokens written with in-correct word boundariesAnnotators were instructed to correct anyword that was incorrectly segmented.
The anno-tation tool allowed both the merging and splittingof tokens.Clitics were corrected to be attached whennecessary according to (MSA) standard writingconventions.
These include single letter proclit-ics (both verbal and nominal) and the negationsuffix -$, as well as pronominal clitics such aspossessive pronouns and direct object pronouns.For example,?
use fAlbyt  ??????
and notfAl  byt  ???
???
or  flbyt  ?????
for ?in thehouse??
use EAlsTH ??????
and notEAl sTH ???
???
or ElsTH ?????
for ?on theroof?The conjunction w- / -?
is always attached toits following word.?
use wkAn  ????
and not w kAn  ???
?
for?and was??
use wrAHt  ?????
and not w  rAHt ????
?for ?and (she) left?Words that were incorrectly segmented in theArabizi source were also merged.
For example,?
use msHwrp ??????
and notms Hwrp ????
??
for ?bewitched(fem.sing.)??
use $ErhA ?????
and not $Er hA  ??
???
for?her hair?Particles that are not attached in standardMSA written forms were corrected as necessaryby the splitting function of the tool.
For exam-ple,?
use yA Emry  ????
??
and not yAEmry??????
for ?Hey, dear!??
use lA trwH  ????
?
and not lAtrwH  ????
?for ?Do not go?99Abbreviations in ArabiziThree abbreviations in Arabizi received spe-cial treatment: msa, isa, 7ma.
These three abbre-viations only were expanded out to their fullform using Arabic words in the corrected Arabicscript transliteration.?
msa: use mA $A' All~h  ?
???
??
for ?AsGod wills??
isa: use <n $A' All~h  ?
???
??
for ?Godwilling??
7ma: use AlHmd ll~h for     ???
??
?ThankGod, Praised be the Lord?All other Arabic abbreviations were not ex-panded, and were transliterated simply letter forletter.
When the abbreviation was in English oranother foreign language, it was kept as is in thetransliteration, using both consonants and semi-vowels to represent it.?
use Awkyh  ????
for ?OK?
(note that this isan abbreviation in English, but not in Egyp-tian Arabic)Correcting Arabic typosAnnotators were instructed to correct typos inthe transliterated Arabic words, including typosin proper names.
However, typos and non-standard spellings in the transliteration of a for-eign words were kept as is and not corrected.?
Ramafan  ?????
should be corrected tormDAn  ?????
for ?Ramadan??
babyy  ????
since it is the English word ?ba-by?
it should not be correctedFlagged tokens in the correction taskTokens flagged during task 1 as Sound andForeign were transliterated into Arabic script butwere not corrected during task 2.
Note that evenwhen a whole phrase or sentence appeared inEnglish, the transliteration was not corrected.?
ks  ??
for ?kiss??
Dd yA hAf fAn  ???
???
??
??
for ?did youhave fun?The transliteration of proper names was cor-rected in the same way as all other words.Emoticons and emoji were replaced in thetransliteration with #.
Emoticons refer to a set ofnumbers or letters or punctuation marks used toexpress feelings or mood.
Emoji refers to a spe-cial set of images used in messages.
Both Emot-icons and Emoji are frequent in SMS/Chat data.5 DiscussionAnnotation and transliteration were performedon all sentence units that contain Arabizi.
Sen-tence units that contain only Arabic script wereignored and untouched during annotation.
Intotal, we reviewed 1270 conversations, amongwhich over 42.6K sentence units (more than300K words) were deemed to be containingArabizi and hence annotated and transliterated.The corpus files are in xml format.
All con-versations have six layers: source, annotation onthe source Arabizi tokens, automatic translitera-tion via 3ARRIB, manual correction of the au-tomatic transliteration, re-tokenized correctedtransliteration, and human translation.
See Ap-pendix A for examples of the file format.Each conversation was annotated by one anno-tator, with 10 percent of the data being reviewedby a second annotator as a QC procedure.
Twen-ty six conversations (roughly 3400 words) werealso annotated dually by blind assignment togauge inter-annotator agreement.As we noted earlier, code switching is fre-quent in the SMS and Chat Arabizi data.
Therewere about 23K words flagged as foreign words.Written out speech effects in this type of data arealso prevalent, and 6610 tokens were flagged asSounds (laughter, filled pause, etc.).
Annotatorsmost often agreed with each other in the detec-tion and flagging of tokens as Foreign, Name,Sound or Punctuation, with over 98% agreementfor all flags.The transliteration annotation was more diffi-cult than the flagging annotation, because apply-ing CODA requires linguistic knowledge of Ara-bic.
Annotators went through several rounds oftraining and practice and only those who passeda test were allowed to work on the task.
In ananalysis of inter-annotator agreement in the dual-ly annotated files, the overall agreement betweenthe two annotators was 86.4%.
We analyzed allthe disagreements and classified them in fourhigh level categories:?
CODA  60% of the disagreements were relatedto CODA decisions that did not carefully followthe guidelines.
Two-fifths of these cases wererelated to Alif/Ya spelling (mostly Alif Hamza-tion, rules of hamza support) and about one-fifthinvolved the spelling of common dialectal words.An additional one-third were due to non-CODAroot, pattern or affix spelling.
Only one-tenth ofthe cases were because of split or merge deci-sions.
These issues suggest that additional train-ing may be needed.
Additionally, since some of100the CODA errors may be easy to detect and cor-rect using available tools for morphologicalanalysis of Egyptian Arabic (such as the CALI-MA-ARZ analyzer), we will consider integratingsuch support in the annotation interface in thefuture.?
Task  In 23% of the overall disagreements, theannotators did not follow the task guidelines forhandling punctuation, sounds, emoticons, namesor foreign words.
Examples include disagree-ment on whether a question mark should be splitor kept attached, or whether a non-Arabic wordshould be corrected or not.
Many of these casescan also be caught as part of the interface; wewill consider the necessary extensions in the fu-ture.?
Ambiguity  In 12% of the cases, the annota-tors?
disagreement reflected a different readingof the Arabizi resulting in a different lemma orinflectional feature.
These differences are una-voidable and reflect the natural ambiguity in thetask.?
Typos  Finally, in less than 5% of the cases,the disagreement was a result of a typographicalerror unrelated to any of the above issues.Among the cases that were easy to adjudicate,one of the two annotators was correct 60% morethan the other.
This is consistent with the obser-vation that more training may be needed to fill insome of the knowledge gaps or increase the an-notator?s attention to detail.6 ConclusionThis is the first Arabizi-Arabic script parallelcorpus that supports research on transliterationfrom Arabizi to Arabic script.
We expect tomake this corpus available through the LinguisticData Consortium in the near future.This work focuses on the novel challenges ofdeveloping a corpus like this, and points out theclose interaction between the orthographic formof written informal genres of Arabic and the spe-cific features of individual Arabic dialects.
Theuse of Arabizi and the use of Egyptian Arabic inthis corpus come together to present a host ofspelling ambiguities and multiplied forms thatwere resolved in this corpus by the use of CODAfor Egyptian Arabic.
Developing a similar cor-pus and transliteration for other Arabic dialectswould be a rich area for future work.We believe this corpus will be essential forNLP work on Arabic dialects and informal gen-res.
In fact, this corpus has recently been used indevelopment by Eskander et al.
(2014).AcknowledgementsThis material is based upon work supported bythe Defense Advanced Research Projects Agency(DARPA) under Contract No.
HR0011-11-C-0145.
The content does not necessarily reflect theposition or the policy of the Government, and noofficial endorsement should be inferred.Nizar Habash performed most of his contribu-tion to this paper while he was at the Center forComputational Learning Systems at ColumbiaUniversity.ReferencesMohamed Al-Badrashiny, Ramy Eskander, Nizar Ha-bash, and Owen Rambow.
2014.
Automatic Trans-literation of Romanized Dialectal Arabic.
In Pro-ceedings of the Conference on Computational Nat-ural Language Learning (CONLL), Baltimore,Maryland, 2014.Tim Buckwalter.
2004.
Buckwalter Arabic Morpho-logical Analyzer Version 2.0.
LDC catalog numberLDC2004L02, ISBN 1-58563-324-0.Achraf Chalabi and Hany Gerges.
2012.
RomanizedArabic Transliteration.
In Proceedings of the Sec-ond Workshop on Advances in Text Input Methods(WTIM 2012).Eleanor Clark and Kenji Araki.
2011.
Text normaliza-tion in social media: Progress, problems and ap-plications for a pre-processing system of casualEnglish.
Procedia - Social and Behavioral Scienc-es, 27(0):2 ?
11.Kareem Darwish, Walid Magdy, and Ahmed Mourad.2012.
Language processing for arabic microblogre- trieval.
In Proceedings of the 21st ACM Inter-national Conference on Information andKnowledge Management, CIKM ?12, pages 2427?2430, New York, NY, USA.
ACM.Kareem Darwish.
2013.
Arabizi Detection and Con-version to Arabic.
CoRR, arXiv:1306.6755 [cs.CL].Leon Derczynski, Alan Ritter, Sam Clark, and KalinaBontcheva.
2013.
Twitter part-of-speech taggingfor all: Overcoming sparse and noisy data.
In Pro-ceedings of the International Conference RecentAdvances in Natural Language Processing RANLP2013, pages 198?206, Hissar, Bulgaria, September.INCOMA Ltd. Shoumen, Bulgaria.Heba Elfardy, Mohamed Al-Badrashiny, and MonaDiab.
2013.
Code Switch Point Detection in Ara-bic.
In Proceedings of the 18th International Con-ference on Application of Natural Language to In-formation Systems (NLDB2013), MediaCity, UK,June.Ramy Eskander, Mohamed Al-Badrashiny, Nizar Ha-bash and Owen Rambow.
2014.
Foreign Words101and the Automatic Processing of Arabic SocialMedia Text Written in Roman Script.
In ArabicNatural Language Processing Workshop, EMNLP,Doha, Qatar.Ramy Eskander, Nizar Habash, Owen Rambow, andNadi Tomeh.
2013.
Processing Spontaneous Or-thography.
In Proceedings of the 2013 Conferenceof the North American Chapter of the Associationfor Computational Linguistics: Human LanguageTechnologies (NAACL-HLT), Atlanta, GA.Andrew T. Freeman, Sherri L. Condon and Christo-pher M. Ackerman.
2006.
Cross Linguistic NameMatching in English and Arabic: A ?One to ManyMapping?
Extension of the Levenshtein Edit Dis-tance Algorithm.
In Proceedings of HLT-NAACL,New York, NY.Kevin Gimpel, Nathan Schneider, Brendan O?Connor,Dipanjan Das, Daniel Mills, Jacob Eisenstein, Mi-chael Heilman, Dani Yogatama, Jeffrey Flanigan,and Noah A. Smith.
2011.
Part-of-speech taggingfor twitter: Annotation, features, and experiments.In Proceedings of ACL-HLT ?11.Stephan Gouws, Donald Metzler, Congxing Cai, andEduard Hovy.
2011.
Contextual bearing on linguis-tic variation in social media.
In Proceedings of theWorkshop on Languages in Social Media, LSM?11, pages 20?29, Stroudsburg, PA, USA.
Associa-tion for Computational Linguistics.Nizar Habash, Mona Diab, and Owen Rambow(2012a).Conventional Orthography for DialectalArabic: Principles and Guidelines ?
Egyptian Ara-bic.
Technical Report CCLS-12-02, ColumbiaUniversity Center for Computational Learning Sys-tems.Nizar Habash, Mona Diab, and Owen Rabmow.2012b.
Conventional Orthography for DialectalArabic.
In Proceedings of the Language Resourcesand Evaluation Conference (LREC), Istanbul.Nizar Habash, Ramy Eskander, and Abdelati Haw-wari.
2012c.
A Morphological Analyzer for Egyp-tian Arabic.
In Proceedings of the Twelfth Meetingof the Special Interest Group on ComputationalMorphology and Phonology, pages 1?9, Montr?al,Canada.Kevin Knight and Jonathan Graehl.
1997.
MachineTransliteration.
In Proceedings of the Conferenceof the Association for Computational Linguistics(ACL).Linguistic Data Consortium.
2014.
BOLT Program:Romanized Arabic (Arabizi) to Arabic Translitera-tion and Normalization Guidelines, Version 3.1.Linguistic Data Consortium, April 21, 2014.Marco Lui, Jey Han Lau, and Timothy Baldwin.2014.
Automatic detection and language identifica-tion of multilingual documents.
In Proceedings ofthe Language Resources and Evaluation Confer-ence (LREC), Reykjavik, Iceland.Mohamed Maamouri, Ann Bies, Seth Kulick, MichaelCiul, Nizar Habash and Ramy Eskander.
2014.
De-veloping a dialectal Egyptian Arabic Treebank:Impact of Morphology and Syntax on Annotationand Tool Development.
In Proceedings of the Lan-guage Resources and Evaluation Conference(LREC), Reykjavik, Iceland.Yaser Al-Onaizan and Kevin Knight.
2002.
MachineTransliteration of Names in Arabic Text.
In Pro-ceedings of ACL Workshop on Computational Ap-proaches to Semitic Languages.Arfath Pasha, Mohamed Al-Badrashiny, Mona Diab,Ahmed El Kholy, Ramy Eskander, Nizar Habash,Manoj Pooleery, Owen Rambow, and Ryan M.Roth.
2014.
MADAMIRA: A Fast, ComprehensiveTool for Morphological Analysis and Disambigua-tion of Arabic.
In Proceedings of the Language Re-sources and Evaluation Conference (LREC), Rey-kjavik, Iceland.Alan Ritter, Sam Clark, Mausam, and Oren Etzioni.2011.
Named entity recognition in tweets: An ex-perimental study.
In Proceedings of the Conferenceon Empirical Methods in Natural Language Pro-cessing, EMNLP ?11.Wael Salloum and Nizar Habash.
2011.
Dialectal toStandard Arabic Paraphrasing to Improve Arabic-English Statistical Machine Translation.
In Pro-ceedings of the First Workshop on Algorithms andResources for Modelling of Dialects and LanguageVarieties, pages 10?21, Edinburgh, Scotland.Zhiyi Song, Stephanie Strassel, Haejoong Lee, KevinWalker, Jonathan Wright, Jennifer Garland, DanaFore, Brian Gainor, Preston Cabe, Thomas Thom-as, Brendan Callahan, Ann Sawyer.
CollectingNatural SMS and Chat Conversations in MultipleLanguages: The BOLT Phase 2 Corpus.
In Pro-ceedings of the Language Resources and Evalua-tion Conference (LREC) 2014, Reykjavik, Iceland.Clare Voss, Stephen Tratz, Jamal Laoudi, and Dou-glas Briesch.
2014.
Finding romanized Arabic dia-lect in code-mixed tweets.
In Proceedings of theNinth International Conference on Language Re-sources and Evaluation (LREC?14), Reykjavik,Iceland.Omar F Zaidan and Chris Callison-Burch.
2011.
Thearabic online commentary dataset: an annotated da-taset of informal arabic with high dialectal content.In Proceedings of ACL, pages 37?41.102Appendix A: File Format ExamplesExample 1:<su id="s1582"><source>marwan ?
ana walahi knt gaya today :/</source><annotated_arabizi><token id="t0" tag="name">marwan</token><token id="t1" tag="punctuation">?</token><token id="t2">ana</token><token id="t3">walahi</token><token id="t4">knt</token><token id="t5">gaya</token><token id="t6" tag="foreign">today</token><token id="t7">:/</token></annotated_arabizi><auto_transliteration> :/ ????
????
???
??
???
??????
</auto_transliteration><corrected_transliteration> # ????
????
???
??
???
??????
</corrected_transliteration><retokenized_transliteration> # ????
????
???
??
???
??????
</retokenized_transliteration><translation lang="eng">Marwan?
I swear I was coming today :/</translation><messages><message id="m2377" time="2013-10-01 22:03:34 UTC" participant="139360">marwan ?
anawalahi knt gaya today :/</message></messages></su>Example 2:<su id="s3"><source>W sha3rak ma2sersh:D haha</source><annotated_arabizi><token id="t0">W</token><token id="t1">sha3rak</token><token id="t2">ma2sersh:D</token><token id="t3" tag="sound">haha</token></annotated_arabizi><auto_transliteration> ??
# [-]?????
????
[+]?
</auto_transliteration><corrected_transliteration> ??
#[-]????[-]??
????
[+]?
</corrected_transliteration><retokenized_transliteration> ??
# ????
??
?????
</retokenized_transliteration><translation lang="eng">And your hair did not become short?
:D Haha</translation><messages><message id="m0004" medium="IM" time="2012-12-22 15:36:31 UTC" participant="138112">Wsha3rak ma2sersh:D haha</message></messages></su>103
