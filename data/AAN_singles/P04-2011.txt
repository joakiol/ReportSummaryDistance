Beyond N in N-gram TaggingRobbert PrinsAlfa-InformaticaUniversity of GroningenP.O.
Box 716, NL-9700 AS GroningenThe Netherlandsr.p.prins@let.rug.nlAbstractThe Hidden Markov Model (HMM) forpart-of-speech (POS) tagging is typi-cally based on tag trigrams.
As suchit models local context but not globalcontext, leaving long-distance syntacticrelations unrepresented.
Using n-grammodels for n > 3 in order to incorporateglobal context is problematic as the tagsequences corresponding to higher ordermodels will become increasingly rare intraining data, leading to incorrect esti-mations of their probabilities.The trigram HMM can be extended withglobal contextual information, withoutmaking the model infeasible, by incor-porating the context separately from thePOS tags.
The new information incor-porated in the model is acquired throughthe use of a wide-coverage parser.
Themodel is trained and tested on Dutch textfrom two different sources, showing anincrease in tagging accuracy comparedto tagging using the standard model.1 IntroductionThe Hidden Markov Model (HMM) used for part-of-speech (POS) tagging is usually a second-ordermodel, using tag trigrams, implementing the ideathat a limited number of preceding tags provide aconsiderable amount of information on the iden-tity of the current tag.
This approach leads togood results.
For example, the TnT trigram HMMtagger achieves state-of-the-art tagging accuracieson English and German (Brants, 2000).
In gen-eral, however, as the model does not considerglobal context, mistakes are made that concernlong-distance syntactic relations.2 A restriction of HMM taggingThe simplifying assumption, which is the basis forHMM tagging, that the context of a given tag canbe fully represented by just the previous two tags,leads to tagging errors where syntactic featuresthat fall outside of this range, and that are neededfor determining the identity of the tag at hand, areignored.One such error in tagging Dutch is related tofiniteness of verbs.
This is discussed in the nextparagraph and will be used in explaining the pro-posed approach.
Other possible applications of thetechnique include assignment of case in German,and assignment of chunk tags in addition to part-of-speech tags.
These will be briefly discussed atthe end of this paper.2.1 An example from DutchIn experiments on tagging Dutch text performedin the context of (Prins and van Noord, 2004), themost frequent type of error is a typical exampleof a mistake caused by a lack of access to globalcontext.
In Dutch, the plural finite form of a verbis similar in appearance to the infinitive form ofthe verb.
In example (1-a) the second verb in thesentence, vliegen, is correctly tagged as an infini-tive, but in example (1-b) the added adverb createsa surrounding in which the tagger incorrectly la-bels the verb as the finite plural form.
(1) a. JanJanzag?past sgsawvogelsbirdsvliegen?infflyb.
*JanJanzag?past sgsawvogelsbirdsvliegen?plflygisterenyesterdaySince a clause normally contains precisely one fi-nite verb, this mistake could be avoided by re-membering whether the finite verb for the currentclause has already occurred, and using this infor-mation in classifying a newly observed verb aseither finite or nonfinite.
The trigram tagger hasnormally ?forgotten?
about any finite verb uponreaching a second verb, and is led into a mistakeby other parts of the context even if the two verbsare close to each other.Basing the model on n-grams bigger than tri-grams is not a solution as the n-grams would oftennot occur in the training data, making the associ-ated probabilities hard to estimate.3 Extending the modelInstead of considering longer n-grams, the modelcan be extended with specific long-distance con-text information.
Analogous to how sequences oftags can be modeled as a probabilistic network ofevents, modeling the probability of a tag given anumber of preceding tags, in the same way we canmodel the syntactic context.For the example problem presented in sec-tion 2.1, this network would consist of two states:pre and post.
In state pre the finite verb for thecurrent clause has not yet been seen, while in statepost is has.
In general, the context feature C withvalues C1...j and its probability distribution is tobe incorporated in the model.In describing how the extra context informationis added to the HMM, we will first look at howthe standard model for POS tagging is constructed.Then the probability distribution on which the newmodel is based is introduced.
A distinction ismade between a naive approach where the extracontext is added to the model by extending thetagset, and a method where the context is addedseparately from the tags which results in a muchsmaller increase in the number of probabilities tobe estimated from the training data.3.1 Standard modelIn the standard second order HMM used forPOS tagging (as described for example in chap-ter 10.2 of (Manning and Schu?tze, 1999)), a sin-gle state corresponds to two POS tags, and theobserved symbols are words.
The transitions be-tween states are governed by probabilities thatcombine the probabilities for state transitions (tagsequences ti?2, ti?1, ti) and output of observedsymbols (words wi):P (ti, wi|ti?2, ti?1)This probability distribution over tags and wordsis factorized into two separate distributions, usingthe chain rule P (A,B|C) = P (A|C)?P (B|C,A):P (ti, wi|ti?2, ti?1) =P (ti|ti?2, ti?1) ?
P (wi|ti?2, ti?1, ti)Finally, the POS tagging assumption that the wordonly depends on the current tag is applied:P (ti, wi|ti?2, ti?1) ?
P (ti|ti?2, ti?1) ?
P (wi|ti)If ?
is the size of the tagset, ?
the size of thevocabulary, and n the length of the tag n-gramsused, then the number of parameters in this stan-dard model is ?n + ?
?.3.2 Extended modelAs a starting point in adding the extra feature tothe model, the same probability distribution usedas a basis for the standard model is used:P (ti, wi|ti?2, ti?1)Naive method: extending the tagset.
The con-textual information C with j possible values couldbe added to the model by extending the set of tags,so that every tag t in the tagset is replaced by aset of tags {tc1 , tc2 , .
.
.
, tcj}.
If ?
is the size ofthe original tagset, then the number of parametersin this extended model would be ?njn + ?j?, thenumber of tag n-grams being multiplied by eightin our example.
In experiments this increase in thenumber of parameters led to less accurate proba-bility estimates.Better method: adding context to states as aseparate feature.
In order to avoid the problemassociated with the naive method, the context fea-ture is added to the states of the model separatelyfrom the tags.
This way it is possible to com-bine probabilities from the different distributionsin an appropriate manner, restricting the increasein the number of parameters.
For example, it isnow stated that as far as the context feature is con-cerned, the model is first order.
The probabilitiesassociated with state transitions are defined as fol-lows, where ci is the value of the new context fea-ture at position i:P (ti, wi, ci|ti?2, ti?1, ci?1)As before, the probability distribution is factorizedinto separate distributions:P (ti, wi, ci|ti?2, ti?1, ci?1) =P (ti|ti?2, ti?1, ci?1) ?P (ci|ti?2, ti?1, ci?1, ti) ?P (wi|ti?2, ti?1, ci?1, ti, ci)The assumption made in the standard POS taggingmodel that words only depend on the correspond-ing tag is applied, as well as the assumption thatthe current context value only depends on the cur-rent tag and the previous context value:P (ti, wi, ci|ti?2, ti?1, ci?1) ?P (ti|ti?2, ti?1, ci?1) ?P (ci|ci?1, ti) ?P (wi|ti)The total numbers of parameters for this model is?nj+?j2+??.
In the case of the example problemthis means the number of tag n-grams is multipliedby two.
The experiments described in section 5will make use of this model.3.3 Training the modelThe model?s probabilities are estimated from an-notated training data.
Since the model is extendedwith global context, this has to be part of the an-notation.
The Alpino wide-coverage parser forDutch (Bouma et al, 2001) was used to automati-cally add the extra information to the data.
For theexample concerning finite plural verbs and infini-tives, this means the parser labels every word inthe sentence with one of the two possible contextvalues.
When the parser encounters a root clause(including imperative clauses and questions) or asubordinate clause (including relative clauses), itassigns the context value pre.
When a finite verbis encountered, the value post is assigned.
Past theend of a root clause or subordinate clause the con-text is reset to the value used before the embeddedclause began.
In all other cases, the value assignedto the previous position is continued.From the text annotated with POS tags and con-text labels the n-gram probabilities and lexicalprobabilities needed by the model are estimatedbased on the frequencies of the corresponding se-quences.4 The tagger4.1 Tagging methodThe trigram HMM tagger used in the experimentsof section 5 computes the a posteriori probabilityfor every tag.
This value is composed of the for-ward and backward probability of the tag at handas defined in the forward-backward algorithm forHMM-training.
This idea is also described in (Je-linek, 1998) and (Charniak et al, 1996).
Thetrigram data is combined with bigram and uni-gram data through linear interpolation to reducethe problem of sparse data.4.1.1 SmoothingApplying the method known as linear inter-polation, probabilities of unigrams, bigrams andtrigrams are combined in a weighted sum usingweights ?1, ?2 and ?3 respectively.
The weightsare computed for every individual case using thenotion of n-gram diversity (Collins, 1999).
The di-versity of an n-gram is the number of different tagsthat appear in the position following this n-gramin the training data.
The weight ?3 assigned tothe trigram t1t2t3 is computed on the basis of thediversity and frequency of the prefix bigram t1t2,using the following equation, where c regulates theimportance of diversity (c = 6 was used in the ex-periments described below), and C(x) and D(x)are respectively the count and diversity of x:?3 ={0 if C(t1t2) = 0C(t1t2)C(t1t2)+c?D(t1t2) if C(t1t2) > 0The bigram weight ?2 is computed as a fractionof 1 ?
?3 using the bigram version of the aboveequation.
The remaining weight 1 ?
?3 ?
?2 isused as the unigram weight ?1.4.1.2 Unknown wordsThe tagger uses a lexicon that has been createdfrom the training data to assign an initial set ofpossible tags to every word.
Words that were notseen during training are not in the lexicon, so thatanother method has to be used to assign initial tagsto these words.
A technique described and imple-mented by Jan Daciuk (Daciuk, 1999) was usedto create automata for associating words with tagsbased on suffixes of those words.5 Tagging experiment5.1 Experiment setup5.1.1 MethodAn extended model was created featuring con-text information on the occurrence of the finiteverb form.
The tagger is used to tag a set of sen-tences, assigning one tag to each word, first usingthe standard model and then using the extendedmodel.
The results are compared in terms of tag-ging accuracy.
The experiment is conducted twicewith different data sets used for both training andtesting.5.1.2 DataThe first set consists of a large amount of Dutchnewspaper text that was annotated with syntacticaltags by the Alpino parser.
This is referred to asthe ?Alpino?
data.
The second and much smallerset of data is the Eindhoven corpus tagged withthe Wotan tagset (Berghmans, 1994).
This dataset was also used in (van Halteren et al, 2001),therefore the second experiment will allow for acomparison of the results with previous work ontagging Dutch.
This data will be referred to as the?Wotan?
data.For both sets the contextual information con-cerning finite verbs is added to the training data bythe Alpino parser as described in section 3.3.
Dueto memory restrictions, the parser was not able toparse 265 of the 36K sentences of Wotan trainingdata.
These sentences received no contextual la-bels and thus not all of the training data used in(van Halteren et al, 2001) could be used in theWotan experiment.Training data for the Alpino experiment is fouryears of daily newspaper text, amounting to about2M sentences (25M words).
Test data is a col-lection of 3686 sentences (59K words) from theParool newspaper.
The data is annotated with atagset consisting of 2825 tags.
(The large sizeof the Alpino tagset is mainly due to a largenumber of infrequent tags representing specificuses of prepositions.)
In the Wotan experiment,36K sentences (628K words) are used for training(compared to 640K words in (van Halteren et al,2001)), and 4176 sentences (72K words) are usedfor testing.
The Wotan data is annotated with atagset consisting of 345 tags (although a numberof 341 is reported in (van Halteren et al, 2001)).5.1.3 Baseline methodAs a baseline method every word is assigned thetag it was most often seen with in the training data.Thus the baseline method is to tag each word wwith a tag t such that P (t|w) is maximized.
Un-known words are represented by all words thatoccurred only once.
The baseline accuracies are85.9% on the Alpino data and 84.3% on the Wotandata.5.2 Results5.2.1 ?Alpino?
experimentThe results on the Alpino data are shown intable 1.
Using the standard model, accuracy is93.34% (3946 mistakes).
Using the extendedmodel, accuracy is 93.62% (3779 mistakes).
Thisamounts to an overall error reduction of 4.23%.
Intable 2 and 3 the 6 most frequent tagging errors arelisted for tagging using the standard and extendedmodel respectively.
Mistakes where verb(pl)is mixed up with verb(inf) sum up to 241 in-stances (6.11% of all mistakes) when using thestandard model, as opposed to 82 cases (2.17%)using the extended model, an error reduction of65.98%.5.2.2 ?Wotan?
experimentThe results on the Wotan data can be seen intable 4.
Using the standard model, accuracy is92.05% (5715 mistakes).
This result is very simi-baseline accuracy 85.9%model standard extendedbigram accuracy 92.49% 92.94%trigram accuracy 93.34% 93.62%errors 3946 3779error reduction 167 = 4.23%pl/inf errors 241 (6.11%) 82 (2.17%)pl/inf error red.
159 = 65.98%Table 1: Tagging results on Alpino datafreq assigned correct159 verb(inf) verb(pl)82 verb(pl) verb(inf)68 proper name(both) 1-proper name(both)57 proper name(both) noun(de,sg)53 verb(psp) adjective(no e,adv)45 proper name(both) 2-proper name(both)Table 2: Most frequent tagging mistakes onAlpino data, using standard modellar to the 92.06% reported by Van Halteren, Zavreland Daelemans in (van Halteren et al, 2001) whoused the TnT trigram tagger (Brants, 2000) on thesame training and testing data.
Using the extendedmodel, accuracy is 92.26% (5564 mistakes).
Thisamounts to an overall error reduction of 2.64%.Mistakes where the plural verb is mixed up withthe infinitive sum up to 316 instances (5.53% ofall mistakes) when using the standard model, asopposed to 199 cases (3.58%) using the extendedmodel, an error reduction of 37.03%.5.3 Discussion of resultsExtending the standard trigram tagging modelwith syntactical information aimed at resolvingthe most frequent type of tagging error led toa considerable reduction of this type of error instand-alone POS tagging experiments on two dif-freq assigned correct69 proper name(both) 1-proper name(both)57 proper name(both) noun(de,sg)53 verb(inf) verb(pl)47 verb(psp) adjective(no e,adv)45 proper name(both) 2-proper name(both)42 punct(ligg streep) skipTable 3: Most frequent tagging mistakes onAlpino data, using extended modelbaseline accuracy 84.3%model standard extendedbigram accuracy 91.45% 91.73%trigram accuracy 92.05% 92.26%errors 5715 5564error reduction 151 = 2.64%pl/inf errors 316 (5.53%) 199 (3.58%)pl/inf error red.
117 = 37.03%Table 4: Tagging results on Wotan dataferent data sets.
At the same time, other types oferrors were also reduced.The relative error reduction for the specific typeof error involving finite and infinite verb formsis almost twice as high in the case of the Alpinodata as in the case of the Wotan data (respectively65.98% and 37.03%).
There are at least two pos-sible explanations for this difference.The first is a difference in tagsets.
Althoughthe Wotan tagset is much smaller than the Alpinotagset, the former features a more detailed treat-ment of verbs.
In the Alpino data, the differencebetween plural finite verb forms and nonfinite verbforms is represented through just two tags.
In theWotan data, this difference is represented by 20tags.
An extended model that predicts which ofthe two forms should be used in a given situationis therefore more complex in the case of the Wotandata.A further important difference between the twodata sets is the available amount of training data(25 million words for the Alpino experiment com-pared to 628 thousand words for the Wotan ex-periment).
In general a stochastic model such asthe HMM will become more accurate when moretraining data is available.
The Wotan experimentwas repeated with increasing amounts of trainingdata, and the results indicated that using more datawould improve the results of both the standard andthe extended model.
The advantage of the ex-tended model over the standard model increasesslightly as more data is available, suggesting thatthe extended model would benefit more from extradata than the standard model.6 Conclusion and future workThis work has presented how the HMM for POStagging was extended with global contextual in-formation without increasing the number of pa-rameters beyond practical limits.
Two tagging ex-periments, using a model extended with a binaryfeature concerning the occurrence of finite verbforms, resulted in improved accuracies comparedto using the standard model.
The annotation ofthe training data with context labels was acquiredautomatically through the use of a wide-coverageparser.The tagger described here is used as a POS tagfilter in wide-coverage parsing of Dutch (Prins andvan Noord, 2004), increasing parsing efficiency asfewer POS tags have to be considered.
In addi-tion to reducing lexical ambiguity, it would be in-teresting to see if structural ambiguity can be re-duced.
In the approach under consideration, thetagger supplies the parser with an initial syntac-tic structure in the form of a partial bracketing ofthe input, based on the recognition of larger syn-tactic units or ?chunks?.
Typically chunk tags willbe assigned on the basis of words and their POStags.
An alternative approach is to use an extendedmodel that assigns chunk tags and POS tags simul-taneously, as was done for finite verb occurrenceand POS tags in the current work.
In this way, re-lations between POS tags and chunk tags can bemodeled in both directions.Another possible application is tagging of Ger-man.
German features different cases, which canlead to problems for statistical taggers.
This is il-lustrated in (Hinrichs and Trushkina, 2003) whopoint out that the TnT tagger wrongly assignsnominative case instead of accusative in a givensentence, resulting in the unlikely combination oftwo nominatives.
The preference for just one as-signment of the nominative case might be learnedby including case information in the model.Acknowledgements.
This research was carriedout as part of the PIONIER Project Algorithmsfor Linguistic Processing, funded by NWO (DutchOrganization for Scientific Research) and the Uni-versity of Groningen.
I would like to thank Hansvan Halteren for supplying the Eindhoven corpusdata set as used in (van Halteren et al, 2001).ReferencesJ.
Berghmans.
1994.
Wotan, een automatische gram-matikale tagger voor het Nederlands.
Master?s the-sis, Dept.
of Language and Speech, University ofNijmegen.Gosse Bouma, Gertjan van Noord, and Robert Mal-ouf.
2001.
Wide coverage computational analysisof Dutch.
In Walter Daelemans, Khalil Sima?an,Jorn Veenstra, and Jakub Zavrel, editors, Compu-tational Linguistics in the Netherlands, CLIN 2000,pages 45?59, Amsterdam.
Rodopi.Thorsten Brants.
2000.
TnT ?
a statistical part-of-speech tagger.
In Proceedings of the 6th AppliedNatural Language Processing Conference, Seattle,WA.E.
Charniak, G. Carroll, J. Adcock, A. Cassandra,Y.
Gotoh, J. Katz, M. Littman, and J. McCann.1996.
Taggers for parsers.
Artificial Intelligence,85(1-2):45?57.Michael Collins.
1999.
Head-Driven Statistical Mod-els for Natural Language Parsing.
Ph.D. thesis,University of Pennsylvania, Philadelphia, Pennsyl-vania.Jan Daciuk.
1999.
Treatment of unknown words.
InProceedings of the Workshop on Implementing Au-tomata WIA?99, pages IX?1 ?
IX?9, Potsdam, Ger-many, July.Erhard W. Hinrichs and Julia Trushkina.
2003.
N-gram and PCFG models for morpho-syntactic tag-ging of German.
In Proceedings of The 2nd Work-shop on Treebanks and Linguistic Theories (TLT2003), pages 81?92, Va?xjo?, Sweden, November.Frederick Jelinek.
1998.
Statistical Methods forSpeech Recognition.
MIT Press.Christopher D. Manning and Hinrich Schu?tze.
1999.Foundations of Statistical Natural Language Pro-cessing.
MIT Press, Cambridge Mass.Robbert Prins and Gertjan van Noord.
2004.
Rein-forcing parser preferences through tagging.
Traite-ment Automatique des Langues (TAL), special issueon Evolutions in Parsing.
Accepted for publication,2004.H.
van Halteren, J. Zavrel, and W. Daelemans.
2001.Improving accuracy in word class tagging throughthe combination of machine learning systems.
Com-putational Linguistics, 27(2):199?230.
