JEP-TALN-RECITAL 2012, Atelier DEFT 2012: D?fi Fouille de Textes, pages 49?60,Grenoble, 4 au 8 juin 2012. c?2012 ATALA & AFCPTALN 2011, Montpellier, 27 juin ?
1er juillet 2011Participation de l?IRISA ?
DeFT2012 : recherched?information et apprentissage pour la g?n?ration demots-cl?sVincent Claveau, Christian RaymondIRISA-CNRS IRISA-INSACampus de Beaulieu, 35042 Rennes, Francevincent.claveau@irisa.frchristian.raymond@irisa.frR?SUM?Dans cet article, nous d?crivons notre participation au D?fi Fouille de Texte (DeFT) 2012.
Ced?fi consistait en l?attribution automatique de mots-cl?s ?
des articles scientifiques en fran?ais,selon deux pistes pour lesquelles nous avons employ?
des approches diff?rentes.
Pour lapremi?re piste, une liste de mots-cl?s ?tait fournie.
Nous avons donc abord?
ce probl?mecomme une t?che de recherche d?information dans laquelle les mots-cl?s sont les requ?tes.Cette approche a donn?
d?excellents r?sultats.
Pour la seconde piste, seuls les articles ?tantfournis, nous avons employ?
une approche s?appuyant sur un extracteur de terme et uner?ordonnancement par apprentissage.ABSTRACTIRISA participation to DeFT 2012 : information retrieval and machine learning forkeyword generationThis paper describes the IRISA participation to the DeFT 2012 text-mining challenge.
Itconsisted in the automatic attribution or generation of keywords to scientific journal articles.Two tasks were proposed which led us to test two different strategies.
For the first task, alist of keywords was provided.
Based on that, our first strategy is to consider that as anInformation Retrieval problem in wich the keyword are the queries, which are attributed tothe best ranked documents.
This approach yielded very good results.
For the second task,only the articles were known; for this task, our approach is chiefly based on a term extractionsystem whose results are reordered by machine learning.MOTS-CL?S : G?n?ration de mots-cl?s, Extraction de termes, Recherche d?information,Boosting, arbres de d?cision, TermoStat.KEYWORDS: Keyword generation, Term extraction, Information Retrieval, Boosting, Deci-sion tree, TermoStat.491 IntroductionDans cet article, nous d?crivons notre participation au D?fi Fouille de Texte (DeFT) 20121.
Ced?fi consistait en l?attribution automatique de mots-cl?s ?
des articles scientifiques en fran?ais,selon deux pistes pour lesquelles nous avons employ?
des approches diff?rentes.
Pour lapremi?re piste, une liste de mots-cl?s ?tait fournie.
Nous avons donc abord?
ce probl?mecomme une t?che de recherche d?information dans laquelle les mots-cl?s sont les requ?tes.Cette approche a donn?
d?excellents r?sultats.
Pour la seconde piste, seuls les articles ?tantfournis, nous avons employ?
une approche s?appuyant sur un extracteur de terme et unr?ordonnancement par apprentissage.La suite de l?article est structur?e en trois parties.
Nous d?crivons tout d?abord bri?vement lesyst?me d?extraction de termes et les n?cessaires pr?traitements que nous avons utilis?s pourles deux pistes.
La section 3 d?taille ensuite l?approche que nous avons adopt?e pour la piste1, et les r?sultats que nous y avons obtenu.
Notre contribution pour la piste 2 est quant ?
ellepr?sent?e dans la section 4.
Nous terminons enfin par quelques remarques et conclusions surle d?fi et les r?sultats obtenus.2 Pr?traitements et extraction terminologique2.1 Pr?-traitementsLes articles ?taient fournis encod?s en UTF8 et format?
sous un format XML structurantl?article en un r?sum?
et en paragraphes.
Beaucoup de ces articles portant sur la traduction, lalinguistique, ou l?ethnologie, ceux-ci contiennent des exemples, phrases et parfois paragraphescomplets en langue autre que le fran?ais (anglais, grec, inuktitut...).
Ces extraits pouvantfausser les processus suivants, il a ?t?
n?cessaire de les pr?traiter.
Dans certains cas, pour lesplus longs de ces extraits, ils ont ?t?
traduits automatiquement par Google Translate quandcela ?tait possible.
Dans les autres cas, ils ont ?t?
simplement supprim?s.
Certaines formulesmath?matiques, notations particuli?res ou caract?res sp?ciaux (ins?cables, puces...) ont ?t?aussi supprim?s.
Les textes ainsi nettoy?s peuvent alors ?tre trait?s par les ?tapes d?critesci-apr?s.2.2 Extraction de termes par TermoStatAussi bien pour la piste 1 que la piste 2, nous utilisons un extracteur de termes.
Ces outilsont pour but de d?tecter, extraire et normaliser les termes dans des textes de sp?cialit?.Ces termes sont dits soit simples (compos?s d?un seul mot-forme) ou complexes (plusieursmots-formes).
Deux approches sont usuellement employ?es : symbolique ou num?rique.L?approche symbolique repose sur des patrons morpho-syntaxiques, et est particuli?rementutilis?e pour extraire des termes complexes.
L?approche num?rique se base sur les fr?quencesd?apparition des termes pour d?cider s?ils sont particuliers au domaine ou non.
Ces deux1Ce travail a ?t?
en partie effectu?
dans le cadre du projet Quaero, financ?
par l?agence pour l?innovation fran?aiseOSEO.50approches sont habituellement utilis?es en conjonction au sein des outils d?extraction les plusconnus, dans un ordre variable selon les outils.Pour ce d?fi, nous avons utilis?
TermoStat (Drouin, 2003), d?velopp?
par Patrick Drouin ?l?OLST, Universit?
de Montr?al.
Il est librement accessible ?
http://olst.ling.umontreal.ca/~drouinp/termostat_web/.
Il appartient au groupe de techniques encha?nant une ex-traction bas?e sur des patrons morpho-syntaxiques et un filtrage num?rique.
Sa particularit?r?side dans ce dernier traitement : TermoStat compare les fr?quences d?apparition descandidats-termes dans le texte sp?cialis?
avec celles d?un tr?s gros corpus g?n?raliste.
Celalui permet de mettre au jour des usage sp?cifique au texte ?tudi?, aussi bien pour les termessimples que les termes complexes.
Le corpus g?n?raliste fran?ais est d?environ 28 500 000occurrences, correspondant ?
approximativement 560 000 formes diff?rentes.
Il est compos?d?articles de journaux portant sur des sujets vari?s tir?s du quotidien fran?ais Le Monde etpubli?s en 2002.TermoStat fonctionne en trois ?tapes.
Le texte est tout d?abord lemmatis?
et ?tiquet?
enparties-du-discours ?
l?aide TreeTagger (Schmid, 1997).
Cette premi?re ?tape permet ainsi ?TermoStat d?appliquer une s?rie d?expressions r?guli?res pr?d?finies pour extraire les mots oules ensembles de mots pouvant ?tre des termes.
Voici quelques uns de ces patrons syntaxiquestels que donn?s dans la notice de TermoStat :Nom : d?finition, dictionnaireNom + adj : champ s?mantique, d?finition lexicaleNom+ prep + nom : partie du discours, dictionnaire de langueNom+ prep + nom + adj : compl?ment de objet direct, principe de compositionalit?
s?mantiqueNom + part pass : variation li?e, langue ?criteNom + adj + prep + nom : structuration s?mantique du lexique, approche s?miotique du langageAdj : lexical, syntagmatiqueAdv : paradigmatiquement, syntagmatiquementVerbe : d?sambig?iser, lexicaliserLa derni?re ?tape calcule un score et s?lectionne les candidats-termes extraits avec les patrons?
l?
?tape pr?c?dente.
C?est ce score qui compare les fr?quences dans le texte consid?r?
etdans le corpus g?n?raliste.
Plusieurs indices sont impl?ment?s dans TermoStat (sp?cificit?,Loglikelihood, ?2...).
Dans notre cas, cet indice a relativement peu d?importance puisqu?il nesert qu??
limiter la liste des candidats-termes, l?ordre n?
?tant pas pris en compte (cf.
section 3)ou recalcul?
(voir section 4 pour les r?sultats avec l?ordonnacement original de TermoStat etavec r?ordonnancement).Outre la capacit?
?
extraire les termes simples, Termostat a l?avantage de g?rer les ph?nom?nesde variation simples comme la flexion.
Les listes de termes obtenues sont finalement filtr?espour ?ter quelques candidats erron?s dus ?
quelques erreurs r?currentes de TreeTagger ou ?la pr?sence de mots de langues ?trang?res qui seraient rest?s dans les textes.3 Piste 1 : un probl?me de recherche d?informationPour cette premi?re piste, une liste contenant tous les mots-cl?s des articles ?
traiter ?taitfournie en plus des articles eux-m?mes.
Comme nous l?avons expliqu?
pr?c?demment, nous51avons abord?
ce probl?me d?attribution des mots-cl?s comme un probl?me de recherched?information.
Nous d?crivons ci-dessous cette approche, et notamment la prise en comptede la morphologie, et les r?sultats obtenus.3.1 PrincipeLe principe adopt?
est relativement simple : les mots-cl?s sont tour ?
tour consid?r?s commedes requ?tes et les articles comme les documents d?une collection.
Pour une requ?te donn?e,ces documents sont ordonn?s du plus pertinent au moins pertinent ?
l?aide d?un syst?me derecherche d?information classique qui assigne un score ?
chaque document.
?
partir de cetordonnancement, diff?rentes strat?gies peuvent ?tre mises-en-?uvre : le mot-cl?
consid?r?peut par exemple ?tre attribu?
aux n premiers documents retourn?s, ou ?
tous les documentsobtenant un score sup?rieur ?
un certain seuil, ou autre.Le syst?me de recherche d?information que nous avons impl?ment?
pour cette t?che reposesur des techniques standard du domaine de la RI.
Nous avons en particulier utilis?
un mod?levectoriel et test?
diff?rents types de pond?rations.
Dans ce type de mod?le, chaque documentest repr?sent?
comme un sac de mots.
Les mots outils sont ?t?s ?
l?aide d?un anti-dictionnaire(stop-list).
Avec une telle repr?sentation, un document contenant la phrase ?
le pr?sident duparti vote contre la proposition ?
sera repr?sent?
par { pr?sident, parti, proposition, vote }.Il faut noter que la phrase ?
le parti du pr?sident vote pour la proposition ?
obtient la m?merepr?sentation.
Cette d?s?quencialisation du texte ne permet donc pas de prendre en compteles termes complexes qui permettraient ainsi de distinguer parti du pr?sident et pr?sident duparti.
Pour les besoins du d?fi, nous ajoutons donc ?
cette description classique les termescomplexes extraits par TermoStat.Diff?rentes pond?rations utilis?es en RI ont ?t?
exp?riment?es.
Celles-ci ont toutes pour butde donner plus ou moins d?importance aux termes apparaissant dans les documents selonleur repr?sentativit?
pour d?crire le contenu du document.
Cette pond?ration est un ?l?mentessentiel de la qualit?
des calculs de similarit?
; le TF-IDF est l?un des plus anciens (Luhn,1958; Sp?rck Jones, 1972).
Il est habituellement d?fini par :wTF?IDF (t, d) = tf(t, d) ?
log(N/df(t)) (1)avec tf est le nombre d?occurrence ou la fr?quence du terme t dans le document consid?r?,df sa fr?quence documentaire, c?est-?-dire le nombre de documents dans lequel il appara?t,N est le nombre total de documentsMais le TF-IDF n?est pas le seul choix possible et, de fait, rarement le meilleur (Claveau, 2012).Dans le cadre de ce d?fi, nous avons principalement utilis?
la pond?ration Okapi-BM25, dontla formule est donn?e dans l?
?quation 2 qui indique le poids du terme t dans le documentd (k1 = 2 and b = 0.75 sont des constantes, dl la longueur du document, dlavg la longueurmoyenne des documents).wBM25(t, d) = TFBM25(t, d) ?
IDFBM25(t)= tf(t, d) ?
(k1 + 1)tf(t, d) + k1 ?
(1?
b+ b ?
dl(d)/dlavg) ?
logN ?
df(t) + 0.5df(t) + 0.5(2)Cette pond?ration classique peut ?tre interpr?t?e comme une version moderne du TF-IDF.52Il faut noter que les techniques de type LSI, LDA ou vectorisation, permettant d?associer desrequ?tes et des documents m?me s?ils n?ont pas de termes en commun sont peu adapt?es ?notre t?che.
En effet, plut?t que de favoriser le rappel, on cherche au contraire ?
trouver ledocument contenant la formulation la plus proche de la requ?te.
Pour la m?me raison, onn?utilise pas de racinisation (stemming).
Cette technique aveugle de normalisation morpho-logique est jug?e trop agressive pour notre t?che puisqu?elle ne permet plus de distinguerentre social et socialisme de mani?re d?finitive (i.e.
quelle que soit la requ?te).
Nous proposonsune technique plus fine pour prendre en compte ces variations morphologiques dans lasous-section ci-dessous que s?applique diff?remment selon la requ?teEnfin l?assignation d?un mot-cl?
peut se faire selon diff?rente strat?gie une fois les calculs deRI effectu?s.
Nous en avons test?
deux.
Dans la premi?re, not?e run1, nous assignons tousles mots-cl?s pour lesquels le document est class?
premier, sans tenir compte du nombre demots-cl?s attendus par article.
La deuxi?me strat?gie, not?e run2 dans les r?sultats ci-dessous,assigne exactement le nombre de mots-cl?s attendus, en retenant ceux pour lesquels ledocument consid?r?
est le mieux class?.3.2 Prise en compte de la variation morphologiqueL?approche que nous avons adopt?e pour acqu?rir les variantes morphologiques des motscontenus dans les requ?tes s?appuie sur une technique que nous avons d?velopp?e initialement?
des fins terminologiques (Claveau et L?Homme, 2005) puis adapt?e au cas de la RI (Moreauet al, 2007).
Le principe de cette technique d?acquisition morphologique est relativementsimple et s?appuie sur la construction d?analogies.
En toute g?n?ralit?, une analogie peut ?trerepr?sent?e formellement par la proposition A : B .= C : D, qui signifie ?
A est ?
B ce que C est?
D ?
; c?est-?-dire que le couple A-B est en analogie avec le couple C-D.
Son utilisation enmorphologie, assez ?vidente, a d?j?
fait l?objet de plusieurs travaux (Hathout, 2001; Lepage,2003) : par exemple, si l?on postule l?analogie connecteur : connecter .= ?diteur : ?diteret si l?on sait par ailleurs que connecteur et connecter partagent un lien morpho-s?mantique, onpeut alors supposer qu?il en est de m?me pour ?diteur et ?diter .Le pr?alable essentiel ?
l?utilisation effective de l?apprentissage par analogie est la d?finitionde la notion de similarit?
qui permet de statuer que deux paires de propositions ?
dans notrecas deux couples de mots ?
sont en analogie.
La notion de similarit?
que nous utilisons, not?eSim, est simple mais adapt?e aux nombreuses autres langues dans lesquelles la flexion et lad?rivation sont principalement obtenues par pr?fixation et suffixation.
Intuitivement, Simv?rifie que, pour passer d?un mot m3 ?
un mot m4, les m?mes op?rations de pr?fixation et desuffixation que pour passer de m1 ?
m2 sont n?cessaires.
Plus formellement, notons lcss(X,Y)la plus longue sous-cha?ne commune ?
deux cha?nes de caract?res X et Y (e.g.
lcss(installer ,d?sinstallation) = install), et X +suf Y (respectivement +pre) la concat?nation du suffixe (resp.,pr?fixe) Y ?
X, et X?suf Y (respectivement ?pre) la soustraction du suffixe (resp., pr?fixe)Y ?
X.
La mesure de similarit?
Sim est alors d?finie de la mani?re suivante :Sim(m1-m2, m3-m4) = 1 si??????
?m1 = lcss(m1,m2) +pre Pre1 +suf Suf1, etm2 = lcss(m1,m2) +pre Pre2 +suf Suf2, etm3 = lcss(m3,m4) +pre Pre1 +suf Suf1, etm4 = lcss(m3,m4) +pre Pre2 +suf Suf253Sim(m1-m2, m3-m4) = 0 sinono?
Prei et Sufi sont des cha?nes de caract?res quelconques.
Si Sim(m1-m2, m3-m4) = 1, celasignifie que l?analogie m1 : m2 .= m3 : m4 est v?rifi?e et donc on suppose que la relationmorpho-s?mantique entre m1 et m2 est la m?me qu?entre m3 et m4.Notre processus de d?tection de variantes morphologiques consiste ainsi ?
v?rifier, au moyende la mesure Sim, si un couple de mots inconnus est en analogie avec un ou plusieurs exemplesde couples connus.
En pratique, pour des raisons d?efficacit?
lors de la recherche d?analogies,plut?t que les couples-exemples, ce sont les op?rations de pr?fixation et suffixation ?
l?
?uvredans la mesure de similarit?
Sim qui sont stock?es.
Ainsi, le couple-exemple d?sinstaller ?r?installation n?est pas stock?
en tant que tel, mais on conserve la r?gle : m2 = m1 ?pre d?s +prer?
?suf er +suf ationMontrer l?analogie d?shydrater : r?hydratation .= d?sinstaller : r?installation revient alors simplement ?tester que d?shydrater ?
r?hydratation v?rifie la r?gle pr?c?dente.La technique de d?tection de d?riv?s morphologiques par analogie pr?sent?e ci-avant requiertdes exemples de couples de mots morphologiquement li?s pour pouvoir fonctionner.
Cetaspect supervis?
n?est pas adapt?
?
une utilisation en RI o?
l?on souhaite au contraire unetotale autonomie du syst?me.
Pour r?pondre ?
ce probl?me, nous rempla?ons cette phasede supervision humaine par une technique d?amor?age simple permettant de constituerautomatiquement un ensemble de paires de mots pouvant servir d?exemples.Cette premi?re phase de recherche de couples-exemples se d?roule de la fa?on suivante :1 ?
choisir un article au hasard dans la collection ;2 ?
constituer tous les couples de mots possibles (issus de l?article) ;3 ?
ajouter aux exemples les couples m1-m2 tels que lcss(m1,m2) > l ;4 ?
retourner en 1.Dans les exp?riences rapport?es ci-dessous, ces ?tapes ont ?t?
r?p?t?es pour tous les docu-ments ?
traiter.Cette phase de constitution d?exemples repose donc sur la m?me hypoth?se que pr?c?dem-ment : la d?rivation et la flexion se font principalement par des op?rations de pr?fixationet suffixation.
Il n?est pas grave lors de cette phase de ne pas rep?rer des couples de motsmorphologiquement li?s ; cependant, pour le bon fonctionnement des analogies qui vont en?tre tir?es, il faut ?viter de constituer des couples qui ne seraient pas des exemples valides.Dans notre approche simple, deux pr?cautions sont prises.
D?une part, la longueur minimalede la sous-cha?ne commune l est fix?e ?
un chiffre assez grand (dans nos exp?riences, l = 7lettres), ce qui r?duit le risque de r?unir deux mots ne partageant aucun lien.
D?autre part,rechercher les variantes morphologiques au sein d?un m?me document maximise les chancesque les deux mots soient issus d?une m?me th?matique et donc d?un vocabulaire coh?rent.Une fois cette premi?re phase accomplie, il nous est maintenant possible de v?rifier si uncouple de mots inconnus est en analogie avec une paire connue et de d?duire ainsi si lesdeux mots inconnus sont en relation de d?rivation ou de flexion.
Dans le cadre de notreapplication, les mots dont on souhaite r?cup?rer les variantes morphologiques sont ceuxconstituants les requ?tes (les mots-cl?s).
Pour ce faire, chaque mot-forme des requ?tes est54confront?
?
chaque mot de la collection ; si le couple ainsi form?
est en analogie avec undes couples-exemples, il est alors utilis?
pour l?extension de la requ?te.
En pratique, pourdes questions de rapidit?, les r?gles d?analogies sont utilis?es de mani?re g?n?ratives : desmots sont produits ?
partir du terme de la requ?te en suivant les op?rations de pr?fixation etsuffixation indiqu?es dans les r?gles et ils sont conserv?s s?ils apparaissent dans l?index de lacollection.
L?apprentissage des r?gles se faisant hors-ligne, seule la recherche des variantesmorphologiques des termes des requ?tes dans l?index est faite en ligne ; en pratique, dans lesexp?riences report?es ci-apr?s, cela prend quelques dixi?mes de seconde.Ainsi, pour une requ?te ?
pollution des eaux souterraines ?, la requ?te ?tendue finalement utilis?edans le SRI sera ?
pollution des eaux souterraines polluants d?pollution anti-pollution pollutions pollu?espolluent eau souterraine souterrains souterrain ?.
Il est important de noter que, lors de l?extension,seuls les mots directement li?s aux termes de la requ?tes sont ajout?s ; les mots eux-m?mesli?s aux extensions ne sont pas pris en compte.
Cette absence volontaire de transitivit?
doitainsi ?viter de propager des erreurs (vision?
provision?
provisions ?
provisionner ?
approvisionner?
approvisionnement...).Enfin, comme nous l?avons d?j?
expliqu?, pour cette application, il est important de privil?gierla pr?cision.
Si le terme pr?sent dans la requ?te appara?t dans un ou peu de documents,nous n?utilisons pas d?extensions morphologiques.
Nous pr?f?rons en effet les documentscontenants exactement l?expression utilis?e comme mot-cl?.
En revanche, l?extension morpho-logique est d?clench?e dans deux cas oppos?s.
Si le terme n?appara?t dans aucun document,cette extension de requ?te permet ?ventuellement de ramener des documents.
Et si le termeappara?t dans beaucoup de documents, l?extension permet de privil?gier les documents conte-nant beaucoup plus le terme et ses variantes.
Ce d?clenchement de l?extension morphologiquedes requ?tes est donc guid?
par l?IDF.3.3 R?sultatsLe tableau 1 pr?sente les r?sultats selon les mesures d?
?valuation d?finies pour le challenge :pr?cision, rappel et f-mesure2.
Nous y indiquons les r?sultats obtenus par notre syst?meutilisant Okapi.
?
des fins de comparaison, les valeurs obtenues avec le m?me syst?me etdiff?rentes pond?rations sont ?galement pr?sent?es : TF-IDF, LSI (Dumais, 2004), Hellinger(Escoffier, 1978; Domeng?s et Volle, 1979).Pr?cision (%) Rappel (%) F-mesure (%)TF-IDF 73.86 57.36 64.57Hellinger 76.25 59.78 67.01LSI 72.79 56.80 63.81Okapi run1 80.36 64.80 71.75Okapi sans extension morphologique 81.38 57.67 67.50Okapi liste run2 69.03 69.05 69.04TABLE 1 ?
R?sultats sur la piste 1 de l?approche par recherche d?information2Ces valeurs, calcul?es par notre propre programme d?
?valuation, diff?rent tr?s l?g?rement de celles obtenuespar les organisateurs.554 Piste 2 : extraction et r?ordonnancement de termes4.1 PrincipeL?affectation de mots-cl?s ?
un article peut ?tre vu comme un probl?me de classificationbinaire.
Ainsi, ?
partir d?une liste de mots-cl?s candidats potentiels, ce probl?me d?apprentis-sage se pose sous la forme suivante : on cherche ?
apprendre quelles sont les caract?ristiquesqui font qu?un mot ou un syntagme, extrait d?un document, est ou non un mot-cl?
de cedocument.
On dispose de donn?es d?apprentissage : pour un document du jeu d?entra?nementdonn?, chaque mot-cl?/syntagme candidat est d?crit par un ensemble d?attributs et un labelinformant si ce candidat est un mot-cl?
(le label est not?
?CLEF?
ci-apr?s) ou non dans cedocument (le label est alors ?NON_CLEF?
).Un algorithme de classification supervis?
peut alors ?tre appliqu?
sur ces donn?es.
Pourchaque document de test, l?ensemble des mots-cl?s ayant le meilleur score au sens del?algorithme de classification est conserv?.
La classifieur que nous avons choisi est bonzaiboost(Raymond, 2010) une impl?mentation de l?algorithme de boosting AdaBoost.MH (Schapireet Singer, 2000) sur des arbres de d?cision ?
un niveau (2 feuilles), les r?sultats soumis ont?t?
obtenus avec 100 tours de boosting sur la t?che 1 comme la t?che 2.Notre syst?me a utilis?
les attributs suivants :?
la liste de mots-cl?s candidats est fournie pour la t?che 1.
Pour la t?che 2, elle a ?t?produite avec l?utilisation de TermoStat et enrichie avec les noms issus des citations del?article, les mots dont le suffixe est ?
isme ?
ainsi que les noms de pays.?
?
chaque mot-cl?
candidat sont attach?s les descripteurs suivants :?
le patron morpho-syntaxique extrait par TreeTagger (Schmid, 1997)?
la proportion de paragraphes du document dans lesquels il appara?t?
sa fr?quence dans le document complet (TF )?
sa fr?quence dans le r?sum??
sa fr?quence okapi dans le document complet (TFBM25)?
sa fr?quence okapi dans le r?sum??
son score IDF (IDF )?
son score IDF selon okapi (IDFBM25)?
le score TFIDF des mots composants le syntagme (wTFIDF )?
le score okapi des mots composants le syntagme (wBM25)4.2 R?sultatsLes r?sultats obtenus sur la t?che 1 suivant ce principe obtiennent 0.67 (run 3 de la piste 1)de f-mesure ce qui est moins performant que notre approche bas?
RI mais nous laisse ?
laseconde position du classement des participants.
Sur la t?che 2, la m?thode est appliqu?e56le patron morpho-syntaxique extrait par TreeTagger 17la proportion de paragraphes du document dans lesquels il apparait 15la fr?quence dans le document complet 5la fr?quence hors-r?sum?
3la fr?quence dans le r?sum?
1la fr?quence okapi dans le document complet 13la fr?quence okapi dans le r?sum?
4l?IDF 10l?IDF okapi 5le score tf*idf des mots composants le syntagme 10le score okapi des mots composants le syntagme 17TABLE 2 ?
Nombre de s?lection de chaque descripteur lors de l?apprentissage.pour r?ordonner une liste de mots-cl?s candidats g?n?r?e par TermoStat.
L?utilisation seulede TermoStat obtient un score 0.1699 (run 2 dans l?evaluation officielle) qui augmente?
0,2087 apr?s r?-ordonnancement (run 1).
Ce r?-ordonnancement nous permet de nousclasser troisi?me avec peu d?
?cart avec le second.Le mod?le obtenu pour la t?che 2 est r?sum?
dans les tableaux 2 et 3.
Le premier montre lenombre de s?lections de chaque descripteur.
Le second montre pour les 30 premiers tours deboosting, le test s?lectionn?
par l?arbre de d?cision ?
un niveau ainsi que son vote selon si ontombe dans la feuille gauche (test positif) ou droite (test n?gatif) de l?arbre.4.3 DiscussionL?approche par classification supervis?e donne des r?sultats convaincants, ?
la fois sur lat?che 1 et la t?che 2 avec pourtant un ensemble tr?s succinct de descripteurs et aucunesconnaissances ext?rieures au corpus de documents, mis ?
part le corpus de r?f?rence utilis?par TermoStat.
?tant donn?
la difficult?
de la t?che, le ph?nom?ne de sur-apprentissagese fait vite ressentir et augmenter le nombre de tour de boosting ou/et la complexit?
del?arbre de d?cision diminue le pouvoir de pr?diction du classifieur.
Il est probable que cetteapproche ait un potentiel d?am?lioration important avec l?ajout de nouveaux descripteurs etde connaissances ext?rieures au corpus, notamment dans le cas o?
les mots-cl?s ne sont paspr?sents dans le document.5 ConclusionLes approches utilis?es par notre ?quipe pour les deux pistes du d?fi rel?vent de deuxstrat?gies diff?rentes.
Toutes deux ont n?anmoins la particularit?
d?
?tre des techniques?prouv?es, mais c?est leur conjonction qui fait l?originalit?
de notre contribution.
D?autre part,les bons r?sultats obtenus valident ce choix, effectu?
cette ann?e encore, d?opter pour cestechniques simples.L?approche par RI se r?v?le tr?s efficace mais ne peut s?appliquer que lorsque les mots-cl?s57Test binaire Tour oui nonTF_general<1.5 1 NON_CLEF :3.49 NON_CLEF :1.94tfresumeokapi<0.730454 2 NON_CLEF :0.27 CLEF :0.71patron_pos="NOM " 3 NON_CLEF :0.10 CLEF :0.54IDF<0.488632 4 NON_CLEF :0.81 CLEF :0.05tfokapi<2.13327 5 NON_CLEF :0.11 CLEF :0.35paragraphe_apparition<0.00311962 6 CLEF :0.93 NON_CLEF :0.04score_syntagme<15.4967 7 NON_CLEF :0.10 CLEF :0.29patron_pos="NOM VER :pper " 8 NON_CLEF :3.38 CLEF :0.01patron_pos="nom NOM " 9 NON_CLEF :0.86 CLEF :0.03patron_pos="NOM NOM " 10 NON_CLEF :1.89 CLEF :0.01IDF<1.17607 11 NON_CLEF :0.33 CLEF :0.06patron_pos="PRP " 12 NON_CLEF :1.21 CLEF :0.01tfresumeokapi<1.2873 13 NON_CLEF :0.04 CLEF :0.46tfokapi<1.65131 15 NON_CLEF :0.13 CLEF :0.12patron_pos="nom ADJ " 16 NON_CLEF :2.86 CLEF :0.00IDF<0.00355873 17 NON_CLEF :2.81 CLEF :0.00paragraphe_apparition<0.00137276 18 CLEF :1.04 NON_CLEF :0.01tfokapi<0.879093 19 NON_CLEF :0.81 CLEF :0.02tfokapi<0.998128 20 CLEF :0.29 NON_CLEF :0.05score_syntagme<134.614 21 NON_CLEF :0.01 CLEF :0.52patron_pos="VER :pper " 22 NON_CLEF :0.69 CLEF :0.01score_syntagme_okapi<-10.8857 23 CLEF :0.05 NON_CLEF :0.12score_syntagme<33.7732 24 NON_CLEF :0.03 CLEF :0.22score_syntagme_okapi<10.7913 25 CLEF :0.01 NON_CLEF :0.49IDF<3.24816 26 NON_CLEF :0.09 CLEF :0.06paragraphe_apparition<0.050569 27 NON_CLEF :0.08 CLEF :0.08IDF_OKAPI<4.5372 29 CLEF :0.05 NON_CLEF :0.10score_syntagme_okapi<6.53596 30 NON_CLEF :0.02 CLEF :0.19TABLE 3 ?
Tests s?lectionn?s durant les 30 premiers tours de boosting.
Pour chaque tour, pourles cas o?
le test est positif ou n?gatif, est marqu?
le label pour lequel l?algorithme vote ainsique le poids donn?
?
ce vote.58possibles sont connus (piste 1).
Sauf ?
supposer que les mots-cl?s soient n?cessairementtir?s d?une terminologie fix?e (comme par exemple le MeSH pour les articles du domainebiom?dical), cette t?che ne pr?sente qu?un int?r?t limit?.
L?
?valuation qui en est faite nepermet d?ailleurs pas de juger parfaitement un tel type d?application puisque tous les mots-cl?sdes articles ?
traiter ?taient donn?s, mais seuls ceux-l?.
Chaque mot-cl?
devait donc ?treattribu?
?
au moins un article.
Il aurait pu ?tre int?ressant de noyer ces mots-cl?s parmid?autres et d?ainsi ?valuer la capacit?
r?elle des m?thodes ?
trouver les bons mots-cl?s et nonsimplement ?
trouver les bons appariements.Les r?sultats obtenus sur la piste 2 par l?approche par r?ordonnacement sont bien s?r moinsbons, mais la t?che est ?videmment bien plus compliqu?e.
Elle correspond de fait ?
uneapplication qui semble plus r?aliste mais dont l?
?valuation est aussi plus difficile.
En effet, unmot-cl?
pr?dit par le syst?me mais non donn?
par l?auteur n?est pas pour autant un mauvaismot-cl?.
Les habitudes d?indexation, le contexte de l?article (autres articles des m?mes auteurs,autres articles de la revue...) mais aussi hasard et parfois des choix discutables influent sur ler?sultat.
Il serait ?
ce titre int?ressant d?
?tudier l?accord inter-annotateur d?humains ayantpour t?che de produire ces mots-cl?s.R?f?rencesCLAVEAU, V. (2012).
Okapi, Vectorisation et calcul de similarit?
pour le TAL : pour oublierenfin le TF-IDF.
In Actes de la 19?me conf?rence Tratement Automatique du Langage Naturel,TALN?12, Grenoble, France.CLAVEAU, V. et L?HOMME, M.-C. (2005).
Structuring terminology by analogy machinelearning.
In Proceedings of the International conference on Terminology and KnowledgeEngineering, TKE?05, Copenhague, Danemark.DOMENG?S, D. et VOLLE, M. (1979).
Analyse factorielle sph?rique : une exploration.
Annalesde l?INSEE, 35:3?83.DROUIN, P. (2003).
Term extraction using non-technical corpora as a point of leverage.Terminology, 9(1):99?117.DUMAIS, S. (2004).
Latent semantic analysis.
ARIST Review of Information Science andTechnology, 38(4).ESCOFFIER, B.
(1978).
Analyse factorielle et distances r?pondant au principe d??quivalencedistributionnelle.
Revue de statistique appliqu?e, 26(4):29?37.HATHOUT, N. (2001).
Analogies morpho-synonimiques.
une m?thode d?acquisition auto-matique de liens morphologiques ?
partir d?un dictionnaire de synonymes.
In Actes de la 8econf?rence Traitement Automatique du Langage Naturel, TALN?01, Tours, France.LEPAGE, Y.
(2003).
De l?analogie ; rendant compte de la communication en linguistique.
Th?sed?habilitation (HDR), Universit?
de Grenoble 1, Grenoble, France.LUHN, H. P. (1958).
The automatic creation of literature abstracts.
IBM Journal on Researchand Development, 2(2).59MOREAU, F., CLAVEAU, V. et S?BILLOT, P. (2007).
Automatic morphological query expan-sion using analogy-based machine learning.
In Proceedings of the European Conference onInformation Retrieval, ECIR?07, Rome, Italie.RAYMOND, C. (2010).
Bonzaiboost.
http ://bonzaiboost.gforge.inria.fr/.SCHAPIRE, R. E. et SINGER, Y.
(2000).
BoosTexter : A boosting-based system for text cate-gorization.
Machine Learning, 39:135?168.
http://www.cs.princeton.edu/~schapire/boostexter.html.SCHMID, H. (1997).
NewMethods in Language Processing, Studies in Computational Linguistics,chapitre Probabilistic part-of-speech tagging using decision trees, pages 154?164.
UCL Press,London.
http://www.ims.uni-stuttgart.de/projekte/corplex/TreeTagger/.SP?RCK JONES, K. (1972).
A statistical interpretation of term specificity and its applicationin retrieval.
Journal of Documentation, 28(1).60
