Proceedings of the Workshop on Automatic Text Simplification: Methods and Applications in the Multilingual Society, pages 53?63,Dublin, Ireland, August 24th 2014.Assessing Conformance of Manually Simplified Corpora withUser Requirements: the Case of Autistic ReadersSanja?Stajner and Richard Evans and Iustin DornescuResearch Group in Computational LinguisticsResearch Institute of Information and Language ProcessingUniversity of Wolverhampton, UK{SanjaStajner, R.J.Evans, I.Dornescu2}@wlv.ac.ukAbstractIn the state of the art, there are scarce resources available to support development and evaluationof automatic text simplification (TS) systems for specific target populations.
These compriseparallel corpora consisting of texts in their original form and in a form that is more accessiblefor different categories of target reader, including neurotypical second language learners andyoung readers.
In this paper, we investigate the potential to exploit resources developed for suchreaders to support the development of a text simplification system for use by people with autisticspectrum disorders (ASD).
We analysed four corpora in terms of nineteen linguistic featureswhich pose obstacles to reading comprehension for people with ASD.
The results indicate that theBritannica TS parallel corpus (aimed at young readers) and the Weekly Reader TS parallel corpus(aimed at second language learners) may be suitable for training a TS system to assist peoplewith ASD.
Two sets of classification experiments intended to discriminate between original andsimplified texts according to the nineteen features lent further support for those findings.1 IntroductionAs a fundamental human right, people with reading and comprehension difficulties are entitled to accesswritten information (UN, 2006).
This entitlement enables better inclusion into society.
However, thevast majority of texts that such people encounter in their everyday life ?
especially newswire texts ?
arelexically and syntactically very complex.
Since the late nineties, several initiatives have emerged whichpropose guidelines for producing plain, easy-to-read and more accessible documents.
These includethe ?Federal Plain Language Guidelines?1, ?Make it Simple, European Guidelines for the Production ofEasy-to-Read Information for people with Learning Disability?
(Freyhoff et al., 1998), ?Am I makingmyself clear?
Mencap?s guidelines for accessible writing?2, and the W3C ?
Web Accessibility Initiativeguidelines3.
However, manual adaptation of texts cannot match the speed with which new texts are pub-lished on the web in order to provide up to date information.
The aim of Automatic Text Simplification(ATS) is to automatically (or at least semi-automatically) convert complex sentences into a more accessi-ble form while preserving their original meaning.
In the last twenty years, many ATS systems have beenproposed for different target populations in various languages (Carroll et al., 1998; Devlin and Unthank,2006; Saggion et al., 2011; Inui et al., 2003; Alu?
?sio et al., 2008).
Due to the scarcity of parallel corporaof original and manually simplified texts, most of these systems are rule-based.The emergence of Simple English Wikipedia (SEW)4, together with the existing English Wikipedia(EW)5provided a large amount of parallel TS training data, which motivated a shift in English TS fromrule-based to data-driven approaches (Yatskar et al., 2010; Biran et al., 2011; Woodsend and Lapata,2011; Coster and Kauchak, 2011; Wubben et al., 2012; Zhu et al., 2010).
However, no assessment hasThis work is licensed under a Creative Commons Attribution 4.0 International Licence.
Page numbers and proceedings footerare added by the organisers.
Licence details: http://creativecommons.org/licenses/by/4.0/1http://www.plainlanguage.gov/howto/guidelines/bigdoc/fullbigdoc.pdf2http://www.easy-read-online.co.uk/media/10609/making-myself-clear.pdf3http://www.w3.org/WAI/4http://simple.wikipedia.org/wiki/Main Page5http://wikipedia.org/wiki/Main Page53ever been made of the quality of the simplifications made in SEW and the usefulness of the transfor-mations learned from EW?SEW parallel corpora for any of the specified target populations.
The onlyinstructions given to the authors of SEW are to use Basic English vocabulary and shorter sentences.
Themain page states that SEW is for everyone, including children and adults who are learning English.
Allpreviously mentioned studies conducted on that corpus evaluated the quality of the generated output interms of grammaticality, meaning preservation, and simplicity, but not usefulness.
Also, there have beenno comparisons of the types of transformations present in EW?SEW with any of the other TS corporain English which were simplified with a specific target population in mind, e.g.
Encyclopedia Britan-nica and its manually simplified versions for children ?
Britannica Elementary (Barzilay and Elhadad,2003)6, Guardian Weekly and its manually simplified versions for language learners (Allen, 2009), andthe FIRST corpus of various texts simplified for people with autism spectrum disorder (ASD)7.In this study, we compare the original and simplified texts of the four aforementioned TS corpora interms of nineteen features which measure the complexity of texts for people with ASD.
Although thesefeatures were derived from user requirements for people with ASD, many of them are known to presentreading obstacles for other target populations as well (e.g.
children or language learners).
Given the lackof parallel TS corpora for people with ASD, our main goal is to investigate whether the EW?SEW or theother two corpora aimed at children and language learners could be used as training material for a TSsystem to assist people with ASD and thus enable data-driven approaches (instead of the currently usedrule-based ones).
In order to further support the results of this analysis, we conduct several classificationexperiments in which we try to distinguish between original and simplified texts in each of the fourcorpora, using the nineteen features.2 The FIRST Project and User RequirementsAutistic Spectrum Disorders (ASD) are neurodevelopmental disorders characterised by qualitative im-pairment in communication and stereotyped repetitive behaviour.
People with ASD show a diverse rangeof reading abilities: 5-10% have the capacity to read words from an early age without the need forformal learning (hyperlexia) but many demonstrate reduced comprehension of what has been read (Volk-mar and Wiesner, 2009).
They may have difficulty inferring contextual information or may have troubleunderstanding mental verbs, emotional language, and long sentences with complex syntactic structure(Tager-Flusberg, 1981; Kover et al., 2012).
To address these difficulties, a tool is being developed in theFIRST project8to assist in the process of making texts more accessible for people with ASD.
To achievethis, three modues are exploited:1.
Structural complexity processor, which detects syntactically complex sentences and generatesalternatives to such sentences in the form of sequences of shorter sentences (Evans et al., 2014;Dornescu et al., 2013).2.
Meaning disambiguator, which resolves pronominal references, performs word sense disambigua-tion, and detects lexicalised (conventional) metaphors (Barbu et al., 2013).3.
Personalised document generator, which aggregates the output of processors 1 and 2 and gener-ates additional elements such as glossaries, illustrative images, and document summaries.The system, named Open Book, is deployed as an editing tool for healthcare and educational serviceproviders.
It functions semi-automatically, exploiting the three processors and requiring the user toauthorise the application of the conversion operations.
The system is required to assess the readabilityof texts, not only to decide which texts should be converted, but also to assess the readability of textsthat are undergoing conversion.
It is expected that people working to improve the accessibiity of agiven text will benefit from relevant feedback concerning the effects of the changes being introduced.Automatic assessment of readability is one method by which such feedback can be delivered.
In the6http://www.cs.columbia.edu/ noemie/alignment/7Available at: http://www.first-asd.eu/?q=system/files/FIRST D7.2 20130228 annex.pdf8www.first-asd.eu54context of improving the accessibility of texts, relevant feedback should indicate the extent to whichdifferent versions of a text meet the particular requirements of intended readers.User requirements were obtained through consulatation of 94 subjects meeting the strict DSM-IV cri-teria for ASD and with IQ > 70.
43 user requirements were derived and assigned a reference code.
Therequirements link linguistic phenomena to editing operations, such as deletion, explanation, or trans-formation, that will convert the text to a more accessible form.
The linguistic phenomena of concerninclude instances of syntactic complexity such as long sentences containing more than 15 words (possi-bly containing multiple copulative coordinated clauses (UR301), subordinate adjective clauses (UR302),explicative clauses (UR303), non-initial adverbial clauses (UR307)), sentences containing passive verbs(UR313), rarely used conjunctions and antithetic conjuncts (UR304, UR305, UR306), uncommon syn-onyms of polysemic words (UR401, UR425, UR504, UR505, UR511), rarely-used symbols and punc-tuation marks (UR311), anaphors, words containing more than 7 characters, adjectives ending with -ly,long numerical expressions (UR417), negation (UR314), words more than 7 characters long and adverbswith suffix -ly (UR317-319), anaphors, including pronouns (UR418-420).Additional linguistic phenomena such as phraseological units (UR402, UR410, UR425, UR507), andnon-lexicalised metaphors (UR422, UR508), were also found to pose obstacles to reading comprehensionfor people with ASD.
At present, there is a scarcity of resources enabling accurate detection of theseitems.
For this reason, changes in the prevalence of these items in original and converted versions oftexts are not captured in this study.
The full set of user requirements is detailed in Martos et al.
(2013).More generally, it is infrequent linguistic phenomena that cause the greatest difficulty.3 Related WorkThere have been several studies analysing the existing TS corpora.
However, their main focus was ondetermining necessary transformations in TS: for children (Bautista et al., 2011); for people with intel-lectual disability (Drndarevi?c and Saggion, 2012); for language learners (Petersen and Ostendorf, 2007);and for people with low literacy (Gasperin et al., 2009).
Unfortunately, those studies are not directlycomparable (neither among themselves nor with our study), either because they focus on different typesof transformations (the study of Bautista et al.
(2011) focuses on general transformations while the otherthree studies focus on sentence transformations), or because they treat different languages (Spanish,English, and Brazilian Portuguese).Two previous studies most relevant to ours are those by Napoles and Dredze (2010), and by?Stajneret al.
(2013).
Napoles and Dredze (2010) built a statistical classification system that discriminatessimple English from ordinary English, based on EW?SEW corpus.
They used four different groups offeatures: lexical, part-of-speech, surface, and syntactic parse features.
The accuracy of the best classifier(SVM) on the document classification task when using all features was 99.90%, while the accuracyof the best classifier (maximum entropy) on the sentence classification task when using all featureswas 80.80%.
However, this study only demonstrated that it is fairly easy to discriminate sentences anddocuments of EW from those of SEW.
It did not investigate whether the simple English used in SEWcomplies with the user requirements of any specific population with reading difficulties.
?Stajner et al.
(2013) analysed a corpus of 37 newswire texts in Spanish and their manual simplifications aimed atpeople with Down?s syndrome, compiled in the Simplext project9.
They built a classification system thatdiscriminates the original texts from those which are simple with an F-measure of 1.00 using the SVM,and only seven features: average number of punctuation marks (not counting end of sentence markers),numerical expressions, average word length in characters, the ratio of simple and complex sentences,sentence complexity index, lexical density and lexical richness.
They reported the average sentencelength as being the feature with the best discriminative power, leading to an F-measure of 0.99 whenused on its own.In spite of the many linguistic phenomena that pose obstacles to reading comprehension for differenttarget populations, there have been almost no studies investigating whether a TS system built with aspecific target population in mind could be successfully applied ?
or adapted ?
to a different target9www.simplext.es55Corpus Aimed at Version Code Texts SentPerText WordsPerTextWeekly Reader Language learnersOriginal Learn.-O 100 39.41 ?
14.43 746.83 ?
174.25Simple Learn.-S 100 38.40?12.59 621.11 ?
157.17Enc.
Britannica ChildrenOriginal Brit.-O 20 27.10 ?
8.91 628.30 ?
198.19Simple Brit.-S 20 26.45 ?
9.35 382.35 ?
127.69Wikipedia VariousOriginal Wiki-O 110 34.55 ?
1.87 716.57 ?
117.82Simple Wiki-S 110 34.49 ?
1.82 675.07 ?
107.03FIRST People with ASDOriginal FIRST-O 25 13.64 ?
3.95 285.68 ?
34.46Simple FIRST-S 25 22.92 ?
4.79 311.36 ?
76.82Table 1: Corpora characteristicspopulation.
The only exception to this is the study by?Stajner and Saggion (2013), which demonstratedthat two classifiers ?
one which discriminates sentences which should be split from those which shouldbe left unsplit, and another which discriminates sentences which should be deleted from those whichshould be preserved ?
can successfully be trained on one type of corpora and applied to the other.
Bothcorpora consisted of texts in Spanish, one containing newswire texts manually simplified for people withDown?s syndrome, and the other various text genres manually simplified for people with ASD.Motivated by those previous studies and the lack of parallel corpora aimed specifically to people withASD, in this paper, we investigate whether some of already existing corpora for TS in English couldpotentially be used for building a data-driven TS system for this target population.4 MethodologyThe corpora, features, and experimental settings used in this study are described in Sections 4.1?4.3.4.1 CorporaFour parallel corpora of original and manually simplified texts for different target populations were usedin this study (Table 1):1.
The corpus of 100 texts from Weekly Reader and their manual simplifications provided by Macmil-lan English Campus and Onestopenglish10aimed at foreign language learners.
The corpus is dividedinto three sub-corpora ?
advanced, intermediate and elementary ?
each representing a different levelof simplification.
Given that the other three corpora used in this study contain original texts and onlyone level of simplification, we only used the texts from the advanced (henceforth original) and ele-mentary (henceforth simplified) levels.
A more detailed description of this corpus can be found in(Allen, 2009).2.
The corpus of 20 texts from the Encyclopedia Britannica and their manually simplified versionsaimed at children ?
Britannica Elementary (Barzilay and Elhadad, 2003)11.3.
The corpus of 110 randomly selected corresponding articles from EW and SEW.
Here, it is impor-tant to note that, in general, articles from SEW do not represent direct simplifications of the articlesfrom EW, they just have a matching topic.
For this reason, we did not use complete EW and SEWarticles.
We only used those sentences in original and simplified versions, which existed in thesentence-aligned parallel corpora version 2.012(Kauchak, 2013).4.
The corpus of 25 texts on various topics manually simplified for people with autism, compiled inthe FIRST project13, for the purpose of a piloting task14.
The texts were simplified by carers ofpeople with ASD in accordance with specified guidelines.10http://www.onestopenglish.com/11http://www.cs.columbia.edu/ noemie/alignment/12http://www.cs.middlebury.edu/ dkauchak/simplification/13www.first-asd.eu14http://www.first-asd.eu/?q=system/files/FIRST D7.2 20130228 annex.pdf564.2 Text Features Relevant to User RequirementsIn this paper, a set of 15 text complexity measures and 4 formulae exploiting these measures was usedto estimate the accessibility of the texts.
These features quantify the occurrence of linguistic phenomenaidentified as potential obstacles to reading comprehension for people with ASD.
The set of features ispresented in Table 2.
The set of formulae is presented in Table 3.
In every case, accessible texts areexpected to have smaller values of each metric.# Code Linguistic feature Explanation/relevance1 Illative Illative conjunctions Indicators of syntactic complexity, linking clauses.2 CompConj Comparative conjunctions [UR304-306]3 AdvConj Adversative conjunctions4 LongSent Long sentences Motivated by the assumption that deriving the propositions in5 Semicol Semicolons/suspensionpointscomplex sentences is more difficult than deriving connections be-tween related propositions expressed in simple sentences6 Passive Passive verbs (Arya et al., 2011).
[UR309-310, UR313]7 UnPunc Unusual punctuation Indicates syntactic complexity, ellipsis, alternatives, and mathe-matical expressions [UR311]8 Negations Negation The sum of adverbial and morphological negations (?Make it Sim-ple?
(Freyhoff et al., 1998), though contrary to the findings of Tat-tamanti (2008)) [UR314]9 Senses Possible senses The sum over all tokens in the text of the total number of possiblesenses of each token.
[UR401, UR425, UR504-505, UR511]10 PolyW Polysemic words Words with two or more senses listed in WordNet.
[UR401,UR425, UR504, UR505, UR511]11 Infreq Infrequent words Words that are not among the 5000 most frequent words in English[UR304-306, UR401, UR425, UR504-505, UR511]12 NumExp Numerical expressions Numbers written as sequences of words rather than digits [UR417]13 Pron Pronouns Studies have shown that people with ASD can have14 DefDescr Definite descriptions difficulty processing anaphora (Fine et al., 1994) [UR418-420]15 SylLongW Long words Words with more than three syllables [UR317-319]Table 2: Complexity measures (1 ?
words such as therefore and hence; 2 ?
words such as equally andcorrespondingly; 3 ?
words such as although and conversely; 4 ?
sentences more than 15 words long; 8 ?negative adverbials and negative prefixes such as un- and dis-; 11 ?
derived from Wiktionary frequencylists for English16)# Code Metric Formula Relevance16 PolyType Polysemic type ratioptyptypIndicates the proportion of the text vocabulary that ispolysemous.
[UR401, UR425, UR504-505, UR511]17 CommaInd Comma index10?cwIndicates the average syntactic complexity of thesentences in the text [UR301-303, UR307]18 WordsPerSent Words per sentencewsIndicates the average length of the sentences in the text[UR309]19 TypeTokRat Type-token ratiotyptokIndicate the range of vocabulary used in the text[UR401, UR425, UR504, UR505, UR511]Table 3: Text complexity formulae (w ?
the number of words in the text; s ?
the number of sentences inthe text; ptyp ?
the number of polysemic word types in the text; c ?
the number of commas in the text;typ ?
the number of word types in the text; tok ?
the number of word tokens in the text)Scores for these measures, and the text complexity formulae that exploit them where obtained auto-matically by the tokeniser, part-of-speech tagger, and lemmatiser distributed with LT TTT2 (Grover et al.,2000).
Detection of the features used to derive complexity measures also involved the use of additionalresources such as WordNet, gazetteers of rare illative, comparative, and adversative conjunctions, nega-tives (words and prefixes) and a set of lexico-syntactic patterns used to detect passive verbs (presented inFigure 1).57am/are/is/was/were wRB* w{V BN |V BD}am/are/is/was/were wRB* being wRB* w{V BN |V BD}have/has/had wRB* been wRB* w{V BN |V BD}will wRB* be wRB* w{V BN |V BD}am/is/are wRB* going wRB* to wRB* be wRB* w{V BN |V BD}wMDwRB* be w{V BN |V BD}wMDwRB* have wRB* been wRB* w{V BN |V BD}Figure 1: Lexico-syntactic patterns used to detect passive verbs (?*?
indicates zero or more repetitions ofthe item it is attached to, while RB, V BN , V BD, and MD are Penn treebank tags returned by the LTTTT PoS tagger: RB ?
adverb; V BN ?
past participle; V BD ?
past tense; and MD ?
modal verb)4.3 ExperimentsTwo sets of experiments were performed in this study:1.
Analysis of differences between original and simplified texts in terms of nineteen selected features(Section 4.2) across four corpora (Section 4.1).
Statistical difference was measured using the t-test for related samples in the cases where the features were normally distributed, and using therelated samples Wilcoxon signed rank test otherwise.
Normality of the data was tested using theShapiro-Wilk test of normality, which is preferred over the Kolmogorov-Smirnov test when thedataset contains less than 2,000 elements.
All tests were performed in SPSS.
Features 1?15 werefirst normalised (as an average per sentence) in order to allow a fair comparison across the four TScorpora (text length in words and sentences differed significantly across different corpora).2.
Classification experiments with the aim of discriminating original from simplified texts using thenineteen selected features.
All experiments were conducted using the Weka Experimenter (Wittenand Frank, 2005; Hall et al., 2009) in 10-fold cross-validation setup with 10 repetitions, using fourdifferent classification algorithms: NB ?
NaiveBayes (John and Langley, 1995), SMO ?
Weka im-plementation of Support Vector Machines (Keerthi et al., 2001) with normalisation, JRip ?
a propo-sitional rule learner (Cohen, 1995), and J48 ?
Weka implementation of C4.5 (Quinlan, 1993).
Thestatistical significance of the observed differences in F-measures obtained by different algorithmswas calculated using the corrected paired t-test provided in the Weka Experimenter.The TS system in FIRST is not only supposed to decide which texts should be converted, but alsoto assess the readability of texts that are undergoing conversion.
It is expected that people working toimprove the accessibility of a given text will benefit from relevant feedback concerning the effects of thechanges being introduced.
Automatic assessment of readability is one method by which such feedbackcan be delivered.
Deriving a subset of features which, when trained with an appropriate classificationalgorithm, can categorize a given text as either ?original?
or ?simplified?, would facilitate automatic eval-uation of TS systems.
The resulting classifier would be suitable for assessing whether those systemsperform an appropriate level of simplification.
This could serve as a rough estimation, an efficient firststep offering a quick evaluation prior to being tested with real users.5 Results and DiscussionThe results of the two sets of experiments are presented and discussed in the next two subsections.5.1 Analysis of the Features across the CorporaMean values (with standard deviations) of each of the first eight features on each sub-corpus are dis-played in Table 4.
The number of unusual punctuation marks (UnPunc) is the only feature whose valuedoes not differ significantly between the original and simplified versions of the texts in any of the fourcorpora.
This feature was thus excluded from further classification experiments.
The number of com-parative conjunctions per sentence (CompConj) significantly decreases only when simplifying texts for58Corpus Illative CompConj AdvConj LongSent Semicol UnPunc Passive NegationsLear.-O 0.24?0.12 0.04?0.13 0.21?0.08 0.62?0.15 0.03?0.05 0.00?0.01 0.21?0.10 0.33?0.15Lear.-S 0.20?0.13 0.03?0.09 0.19?0.09 0.51?0.14 *0.03?0.05 0.00?0.01 0.09?0.09 0.26?0.14Brit.-O 0.13?0.09 0.15?0.26 0.14?0.07 0.72?0.11 0.13?0.20 0?0 0.33?0.10 0.28?0.16Brit.-S 0.08?0.05 *0.02?0.10 0.06?0.04 0.38?0.11 0.00?0.02 0?0 0.25?0.12 0.14?0.09Wiki-O 0.20?0.11 0.11?0.19 0.16?0.10 0.65?0.12 0.04?0.04 0.04?0.10 0.34?0.15 0.32?0.23Wiki-S 0.18?0.11 0.11?0.20 0.14?0.09 0.62?0.12 0.03?0.04 0.03?0.10 0.33?0.15 0.29?0.24FIRST-O 0.18?0.14 0.06?0.19 0.18?0.15 0.68?0.15 0.03?0.10 0.01?0.02 0.27?0.23 0.42?0.28FIRST-S 0.11?0.10 0.01?0.06 0.09?0.07 0.33?0.19 0.00?0.01 0?0 0.20?0.15 0.22?0.13Table 4: Mean values (with standard deviation) of features 1?8 across the corpora (O ?
the original textsin the corpora; S ?
the simplified texts in the corpora; bold ?
significantly different from the value on theoriginal texts at a 0.01 level of significance; *bold ?
significantly different from the value on the originaltexts at a 0.05 level of significance (but not at 0.01); ?0.00?
?
a value different from zero which roundedat two decimals gives 0.00; ?0?
?
a value equal to zero)Corpus Senses PolyW Infreq NumExp Pron DefDescr SylLongWLear.-O 73.95?12.32 9.37?1.72 5.64?1.33 0.18?0.11 0.97?0.40 1.86?0.54 1.12?0.28Lear.-S 64.21?11.16 7.85?1.45 4.14?1.01 0.16?0.10 0.90?0.37 1.62?0.45 0.92?0.27Brit.-O 67.51?
8.83 9.87?1.15 9.37?1.10 0.18?0.12 0.40?0.18 2.86?0.44 1.45?0.20Brit.-S 48.68?
4.17 6.48?0.57 5.39?0.58 0.09?0.06 0.28?0.13 1.86?0.20 1.17?0.19Wiki-O 67.70?12.96 9.13?1.61 7.86?1.63 0.18?0.16 0.67?0.43 2.08?0.58 1.24?0.38Wiki-S 68.20?13.56 8.71?1.56 7.16?1.51 *0.17?0.16 0.68?0.44 1.97?0.54 1.10?0.42FIRST-O 82.28?24.20 10.16?2.65 7.11?2.72 0.19?0.19 1.05?0.73 2.12?0.92 1.17?0.58FIRST-S 57.13?15.96 6.47?1.77 3.92?1.56 0.09?0.07 *0.82?0.44 1.62?0.54 *0.92?0.43Table 5: Mean values (with standard deviation) of features 9?15 across the corpora (O ?
the original textsin the corpora; S ?
the simplified texts in the corpora; bold ?
significantly different from the value on theoriginal texts at a 0.01 level of significance; *bold ?
significantly different from the value on the originaltexts at a 0.05 level of significance (but not at 0.01))children (Brit.-S), while the average number of passive constructions per sentence (Passive) decreaseswhen simplifying for both children (Brit.-S) and language learners (Lear.-S).
It is interesting to note thatthe average number of passive constructions per sentence (Passive) does not decrease in the EW?SEWcorpus and that its value on the simplified versions of Wikipedia articles (Wiki-S) is significantly higherthan on Brit.-S and Lear.-S, although SEW claims to provide articles simplified for both those targetpopulations.
It can also be observed that the fact that all four corpora were reported to have significantdifferences between original and simplified texts in terms of features Illative, AdvConj, LongSent, andNegations does not necessarily mean that the average number of occurrences of those features is similarin all four simplified corpora.
The values of Illative, AdvConj, and LongSent in the simplified versionsof the texts in the FIRST corpus seem to correspond best to those in the simplified versions of the textsin the Britannica corpus (Brit.-S).
The value of Negations in FIRST-S, however, seems to correspondbest to that in Lear.-S.
This suggests that if we wish to build a component of our TS system (to assistpeople with ASD) which would remove negations (Negations), we should train it on the sentence pairsfrom the corpora with simplifications aimed at second language learners.
If we wish to build a com-ponent which would remove illative conjunctions (Illative), adversative conjuctions (AdvConj), or longsentences (LongSent), we should probably train it on the sentence pairs from the corpora with simplifi-cations aimed at young readers.The number of occurrences per sentence of features 9?15 in the original versions of the texts was sig-nificantly higher than in the simplified versions of the texts in all four corpora, with only two exceptions?
features Senses and Pron in the EW?SEW corpus (Wiki-O and Wiki-S), as can be observed in Table5.
Again, the mean values of all features in the simplified versions of the texts in the FIRST corporaFIRST-S, seems to correspond better to the simplified versions of Encyclopedia Britannica (Brit.-S) and59Corpus PolyType CommaInd WordsPerSent TypeTokRatLear.-O 0.76?0.04 0.56?0.12 19.91?3.46 0.51?0.04Lear.-S 0.77?0.04 0.46?0.15 16.69?2.78 0.47?0.05Brit.-O 0.69?0.03 0.78?0.15 23.46?2.78 0.51?0.04Brit.-S *0.71?0.02 *0.67?0.14 14.61?1.21 0.55?0.04Wiki-O 0.71?0.05 0.65?0.15 20.73?3.16 0.48?0.05Wiki-S 0.71?0.05 0.60?0.16 19.57?2.90 *0.48?0.05FIRST-O 0.73?0.04 0.51?0.18 22.20?5.43 0.59?0.05FIRST-S 0.75?0.06 0.19?0.15 13.86?3.41 0.53?0.08Table 6: Mean values (with standard deviation) of features 16?19 across the corpora (O ?
the originaltexts in the corpora; S ?
the simplified texts in the corpora; bold and *bold ?
used in the same way as inthe previous two tables)Weekly Readers (Lear.-S) than to those in the simplified versions of the Wikipedia articles (Wiki-S).
It isalso interesting to note that many of the features (LongSent, Negations, Senses, PolyW, Infreq, DefDesc)seem to have a significantly higher number of occurrences per sentence in the simplified versions ofthe Wikipedia articles (Wiki-S) than in the simplified versions of Encyclopedia Britannica (Brit.-S) andWeekly Reader (Lear.-S).The comma index (CommaInd), type-token ratio (TypeTokRat), and the average number of words persentence (WordsPerSent) were found to be significantly higher in original texts than in their simplifiedversions in all four corpora (Table 6).
However, the values of those three text complexity formulae werenot similar in the simplified texts across the four corpora.
In terms of the average number of wordsper sentence (WordsPerSent) and the type-token ratio (TypeTokRat), the simplified versions of the textsin the FIRST corpora (FIRST-S) seem to correspond better to the texts simplified for young readers(Brit.-S), than to those simplified for second language learners (Lear.-S) and those aimed at varioustarget populations (Brit.-S).
The comma index (CommaInd) obtained for simplified texts in the FIRSTcorpora was several times lower than that obtained for simplified texts in the three other corpora.
Thepolysemic type ratio (PolyType) was not significantly different in original and in simplified texts of theFIRST corpora (Table 6).
The higher polysemic type ratio (PolyType) for simplified rather than originalversions of the texts in the other three corpora was unexpected, as it is usually assumed that polysemouswords can pose an obstacle for various target populations.
However, it is important to bear in mind thatpolysemous words usually pose an obstacle when conveying one of their infrequently used meanings.Findings in cognitive psychology indicate that the words with the highest number of possible meaningsare actually understood more quickly, due to their high frequency (Jastrzembski, 1981).
A commonlexical simplification strategy is to replace infrequent words with their more frequent synonyms, andlong words with their shorter synonyms.
This strategy leads to a higher polysemic type ratio (PolyType)in simplified versions of the texts as the shorter words are usually more frequent (Balota et al., 2004),and frequent words tend to be more polysemous than infrequent ones (Glanzer and Bowles, 1976).5.2 Classification between Original and Simplified TextsClassification experiments were conducted using two different sets of features on each of the corpora:1. all ?
all 18 features (UnPunc was excluded as it was not reported as significant for any of thecorpora)2. best ?
11 features which were reported as significant for all four corpora (Illative, AdvConj,LongSent, Negations, PolyW, NumExp, DefDescr, SylLongW, CommaInd, WordsPerSent, Type-TokRat)As can be observed from Table 7, use of the SMO-n classification algorithm using the subset of 11best features achieves perfect 1.00 F-measure for discriminating original from simplified versions of theEncyclopedia Britannica.
The same classification algorithm performs less well on the FIRST and WeeklyReaders corpora (though still quite well), while it performs significantly worse on the Wikipedia corpus.60The baseline (which chooses majority class) would be 0.50 in all cases.
These results indicate that theEncyclopedia Britannica TS parallel corpus, and possibly the Weekly Readers TS parallel corpus, mayserve as suitable training material for building a TS system (or at least some of its components) aimed atpeople with ASD.Dataset SMO-n NB JRip J48Brit-all 0.98?0.09 0.94?0.12 0.94?0.14 0.97?0.11Brit-best 1.00?0.00 0.99?0.05 0.94?0.13 0.97?0.11FIRST-all 0.88?0.15 0.86?0.19 0.79?0.23 0.75?0.25FIRST-best 0.88?0.15 0.85?0.20 0.78?0.25 0.76?0.25Lear-all 0.81?0.08 0.74?0.10* 0.75?0.07* 0.72?0.10*Lear-best 0.77?0.08 0.74?0.11 0.70?0.10* 0.73?0.10Wiki-all 0.54?0.12 0.50?0.12 0.51?0.14 0.35?0.20*Wiki-best 0.55?0.13 0.55?0.12 0.51?0.12 0.33?0.20*Table 7: F-measure with standard deviation in a 10-fold cross-validation setup with 10 repetitions forfour classification algorithms: SMO-n, NB, JRip, and J48 (* ?
statistically significant degradation incomparison with SMO-n)6 ConclusionsAutomatic Text Simplification (ATS) aims to convert complex texts into a simpler form, which is moreaccessible to a wider audience.
Due to the lack of parallel corpora for TS consisting of original andmanually simplified texts, most of the ATS systems for specific target populations are still rule-based.Our main goal was to explore whether some of the existing TS parallel corpora in English, aimed at dif-ferent audiences (children ?
Encyclopedia Britannica, language learners ?
Weekly Reader, and various ?Wikipedia) could be used as training material to build a TS system aimed at people with ASD.
We anal-ysed the four corpora (FIRST, Britannica, Weekly Reader, and Wikipedia) in terms of nineteen linguisticfeatures which pose obstacles to reading comprehension for people with ASD.
The preliminary resultsindicate that the Britannica TS parallel corpus, and possibly the Weekly Reader TS parallel corpus, couldbe used to train a TS system aimed at people with ASD.
Two sets of classification experiments whichtried to discriminate original from simplified texts according to the nineteen features derived from userrequirements further supported those findings.
The results of the classification experiments indicatedthat the SVM classifier trained on the Britannica corpus might be suitable for discriminating originalfrom simplified texts for people with ASD, and thus might be used as the initial evaluation of the textssimplified by the TS system developed in the FIRST project.AcknowledgementsThe research described in this paper was partially funded by the European Commission under the Sev-enth (FP7-2007-2013) Framework Programme for Research and Technological Development (FP7-ICT-2011.5.5 FIRST 287607).ReferencesD.
Allen.
2009.
A Corpus-Based Study of the Role of Relative Clauses in the Simplification of News Texts forLearners of English.
System, 37(4):585?599.S.
M.
Alu?
?sio, L. Specia, T. A.S. Pardo, E. G. Maziero, and R. P.M. Fortes.
2008.
Towards brazilian portugueseautomatic text simplification systems.
In Proceedings of the eighth ACM symposium on Document engineering,DocEng ?08, pages 240?248, New York, NY, USA.
ACM.D.
J. Arya, Elfrieda H. Hiebert, and P. D. Pearson.
2011.
The effects of syntactic and lexical complexity onthe comprehension of elementary science texts.
International Electronic Journal of Elementary Education, 4(1):107?125.61D.
Balota, M. J. Cortese, S. D. Sergent-Marshall, D. H. Spieler, and M. J. Yap.
2004.
Visual word recognition ofsingle-syllabe words.
Journal of Experimental Psychology: General, 133:283?316.E.
Barbu, M.
Mart?
?n-Valdivia, L. Alfonso, and U. Lopez.
2013.
Open book: a tool for helping asd users?
semanticcomprehension.
In Proceedings of the 2th Workshop of Natural Language Processing for Improving TextualAccessibility (NLP4ITA), pages 11?19, Atlanta, US.
Association for Computational Linguistics.R.
Barzilay and N. Elhadad.
2003.
Sentence alignment for monolingual comparable corpora.
In Proceedings of the2003 conference on Empirical methods in natural language processing, EMNLP ?03, pages 25?32, Stroudsburg,PA, USA.
Association for Computational Linguistics.S.
Bautista, C. Le?on, R. Herv?as, and P. Gerv?as.
2011.
Empirical identification of text simplification strategies forreading-impaired people.
In European Conference for the Advancement of Assistive Technology.O.
Biran, S. Brody, and N. Elhadad.
2011.
Putting it Simply: a Context-Aware Approach to Lexical Simplification.In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human LanguageTechnologies, pages 496?501, Portland, Oregon, USA.
Association for Computational Linguistics.J.
Carroll, G. Minnen, Y. Canning, S. Devlin, and J. Tait.
1998.
Practical Simplification of English NewspaperText to Assist Aphasic Readers.
In Proceedings of AAAI-98 Workshop on Integrating Artificial Intelligence andAssistive Technology, pages 7?10.W.
Cohen.
1995.
Fast Effective Rule Induction.
In Proceedings of the Twelfth International Conference onMachine Learning, pages 115?123.W.
Coster and D. Kauchak.
2011.
Learning to Simplify Sentences Using Wikipedia.
In Proceedings of the 49thAnnual Meeting of the Association for Computational Linguistics, pages 1?9.S.
Devlin and G. Unthank.
2006.
Helping aphasic people process online information.
In Proceedings of the 8thinternational ACM SIGACCESS conference on Computers and accessibility, Assets ?06, pages 225?226, NewYork, NY, USA.
ACM.I.
Dornescu, R. Evans, and C. Orasan.
2013.
A Tagging Approach to Identify Complex Constituents for TextSimplification.
In Proceedings of Recent Advances in Natural Language Processing, pages 221 ?
229, Hissar,Bulgaria.B Drndarevi?c and H. Saggion.
2012.
Reducing Text Complexity through Automatic Lexical Simplification: anEmpirical Study for Spanish.
SEPLN Journal, 49.R.
Evans, C. Orasan, and I. Dornescu.
2014.
An evaluation of syntactic simplification rules for people withautism.
In Proceedings of the 3rd Workshop on Predicting and Improving Text Readability for Target ReaderPopulations (PITR), pages 131?140, Gothenburg, Sweden, April.
Association for Computational Linguistics.J.
Fine, G. Bartolucci, P. Szatmari, and G. Ginsberg.
1994.
Cohesive discourse in pervasive developmentaldisorders.
Journal of Autism and Developmental Disorders, 24:315?329.G.
Freyhoff, G. Hess, L. Kerr, B. Tronbacke, and K. Van Der Veken, 1998.
Make it Simple, European Guide-lines for the Production of Easy-toRead Information for People with Learning Disability.
ILSMH EuropeanAssociation, Brussels.C.
Gasperin, L. Specia, T. Pereira, and S.M.
Alu??sio.
2009.
Learning When to Simplify Sentences for Natural TextSimplification.
In Proceedings of the Encontro Nacional de Inteligncia Artificial (ENIA-2009), Bento Gonalves,Brazil., pages 809?818.M.
Glanzer and N. Bowles.
1976.
Analysis of the word frequency effect in recognition memory.
Journal ofExperimental Psychology: Human Learning and Memory, 2:21?31.C.
Grover, C. Matheson, A. Mikheev, and M. Moens.
2000.
Lt ttt - a flexible tokenisation tool.
In In Proceedingsof Second International Conference on Language Resources and Evaluation, pages 1147?1154.M.
Hall, E. Frank, G. Holmes, B. Pfahringer, P. Reutemann, and I. H. Witten.
2009.
The weka data miningsoftware: an update.
SIGKDD Explor.
Newsl., 11:10?18, November.K.
Inui, A. Fujita, T. Takahashi, R. Iida, and T. Iwakura.
2003.
Text simplification for reading assistance: a projectnote.
In Proceedings of the second international workshop on Paraphrasing - Volume 16, PARAPHRASE ?03,pages 9?16, Stroudsburg, PA, USA.
Association for Computational Linguistics.62J.
Jastrzembski.
1981.
Multiple meaning, number or related meanings, frequency of occurrence and the lexicon.Cognitive Psychology, 13:278?305.G.
H. John and P. Langley.
1995.
Estimating Continuous Distributions in Bayesian Classifiers.
In Proceedings ofthe Eleventh Conference on Uncertainty in Artificial Intelligence, pages 338?345.D.
Kauchak.
2013.
Improving text simplification language modeling using unsimplified text data.
In Proceedingsof the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages1537?1546, Sofia, Bulgaria, August.
Association for Computational Linguistics.S.
S. Keerthi, S. K. Shevade, C. Bhattacharyya, and K. R. K. Murthy.
2001.
Improvements to Platt?s SMOAlgorithm for SVM Classifier Design.
Neural Computation, 13(3):637?649.S.
T. Kover, E. Haebig, A. Oakes, A. McDuffie, R. J. Hagerman, and L. Abbeduto.
2012.
Syntactic comprehensionin boys with autism spectrum disorders: Evidence from specific constructions.
In Proceedings of the 2012International Meeting for Autism Research, Athens, Greece.
International Society for Autism Research.J.
Martos, S. Freire, A. Gonz?alez, D. Gil, R. Evans, V. Jordanova, A. Cerga, A. Shishkova, and C. Orasan.
2013.FIRST Deliverable - User preferences: Updated.
Technical Report D2.2, Deletrea, Madrid, Spain.C.
Napoles and M. Dredze.
2010.
Learning simple wikipedia: a cogitation in ascertaining abecedarian language.In Proceedings of the NAACL HLT 2010 Workshop on Computational Linguistics and Writing: Writing Pro-cesses and Authoring Aids, CL&W ?10, pages 42?50, Stroudsburg, PA, USA.
Association for ComputationalLinguistics.S.
E. Petersen and M. Ostendorf.
2007.
Text Simplification for Language Learners: A Corpus Analysis.
InProceedings of Workshop on Speech and Language Technology for Education.R.
Quinlan.
1993.
C4.5: Programs for Machine Learning.
Morgan Kaufmann Publishers, San Mateo, CA.H.
Saggion, E. G?omez Mart?
?nez, E. Etayo, A. Anula, and L. Bourg.
2011.
Text Simplification in Simplext:Making Text More Accessible.
Revista de la Sociedad Espa?nola para el Procesamiento del Lenguaje Natural,47:341?342.H.
Tager-Flusberg.
1981.
Sentence comprehension in autistic children.
Applied Psycholinguistics, 2:1:5?24.M.
Tattamanti, R. Manenti, P. A. Della Rosa, A. Falini, D. Perani, S. Cappa, and A. Moro.
2008.
Negation in thebrain: Modulating action representations.
NeuroImage, 43 (2008):358?367.UN.
2006.
Convention on the rigths of persons with disabilities.F.
R. Volkmar and L. Wiesner.
2009.
A Practical Guide to Autism.
Wiley, Hoboken, NJ, 2nd edition.S.
?Stajner and H. Saggion.
2013.
Adapting Text Simplification Decisions to Different Text Genres and TargetUsers.
Procesamiento del Lenguaje Natural, 51:135?142.S.
?Stajner, B. Drndarevi?c, and H. Saggion.
2013.
Corpus-based Sentence Deletion and Split Decisions for SpanishText Simplification.
Computaci?on y Systemas, 17(2):251?262.I.
H. Witten and E. Frank.
2005.
Data mining: practical machine learning tools and techniques.
Morgan Kauf-mann Publishers.K.
Woodsend and M. Lapata.
2011.
Learning to Simplify Sentences with Quasi-Synchronous Grammar andInteger Programming.
In Proceedings of the 2011 Conference on Empirical Methods in Natural LanguageProcessing (EMNLP).S.
Wubben, A. van den Bosch, and E. Krahmer.
2012.
Sentence simplification by monolingual machine transla-tion.
In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers- Volume 1, ACL ?12, pages 1015?1024, Stroudsburg, PA, USA.
Association for Computational Linguistics.M.
Yatskar, B. Pang, C. Danescu-Niculescu-Mizil, and L. Lee.
2010.
For the sake of simplicity: unsupervisedextraction of lexical simplifications from wikipedia.
In Human Language Technologies: The 2010 AnnualConference of the North American Chapter of the Association for Computational Linguistics, HLT ?10, pages365?368, Stroudsburg, PA, USA.
Association for Computational Linguistics.Z.
Zhu, D. Berndard, and I. Gurevych.
2010.
A Monolingual Tree-based Translation Model for Sentence Sim-plification.
In Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010),pages 1353?1361.63
