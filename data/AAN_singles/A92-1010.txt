Integrating Natural Language Components into Graphical DiscourseStephan Dilley, John Bateman,  Ulr ich Thiel, Anne TissenGMD,  Integrated Publ icat ion and Informat ion Systems Institute (IPSI)DolivostralSe 15, D-6100 Darmstadt,  FRGe -maih  { bateman,di l ley,thiel ,t issen }@darmstadt .gmd.deAbstractIn our current research into the design of cognitively well-mo-tivated interfaces relying primarily on the display of graphicalinformation, we have observed that graphical informationalone does not provide sufficient support to users particu-larly when situations arise that do not simply conform to theusers' expectations.
This can occur due to too much informa-tion being requested, too little, information of the wrong kind,etc.
To solve this problem, we are working towards the integra-tion of natural language generation toaugment the interactionfunctionalities of the interface.
This is intended to support thegeneration of flexible natural language utterances which pin-point possible problems with a user's request and which fur-ther go on to outline the user's most sensible courses of actionaway from the problem.
In this paper, we describe our first pro-totype, where we combine the graphical and interaction plan-ning capabilities of our graphical information system SIC!with the text generation capabilities of the Penman system.
Weillustrate the need for such a combined system, and also giveexamples of how a general natural language facility beneficial-ly augments the user's ability to navigate a knowledge basegraphically.I IntroductionNatural anguage interfaces to information systems allow theuser to converse with the system in a natural way without beingrestricted by the syntax of a formal query language.
However,users often have difficulties in stating their information eedprecisely (cf.
Brooks et al, 1986) and so a user interface designemphasizing multimedia aspects of information systems maybe more appropriate.
An object oriented presentation meetsthis requirement because users are allowed to investigate in-formation items directly.
Thus, the distance between the users'intentions and the objects they involve is reduced to a mini-mum (cf.
Hutchins et al, 1986).
However, visual presentationsof abslract information items have to be designed carefully tosupport he user in perceiving them correctly.
Often the in-herent limitations of available presentation forms, e.g.
thenumber ofdisplayable items, are an impediment toan adequatevisualization.
These difficulties which are well known in visu-al languages can be attacked by combining the presentation fgraphical objects to the user with cooperative system re-sponses in natural languages.Our approach to human-computer interaction providesthe basis for an integration ofdifferent interaction styles, in ourcase natural language and graphics, in a multi-modal informa-tion system.
The choice of an appropriate combination ofmodes is essential for a successful interface design.
As there isnot yet a complete theory of multi-modal interaction, this ques-tion has to be answered experimentally.
Therefore, we proposea modular architecture for multi-modal interfaces composedof interaction tools.
In this paper, we discuss the addition otnatural language generation tothe interaction tools provided.This capability isembodied inthe prototype IGiNG (_Integrat-ing Graphics and Natural Language Generation) which com-bines?
the graphical information system SIC!
(System for In-formation on Conferences) comprising a dialog man-ager which is able to track the user's goals and, conse-quently, to plan system reactions as cooperativeresponses (Tissen, 1991), a database access moduleproviding relevant data (Kracker, 1991) and apresen-tation manager generating visualizations of the re-trieved information items (Kerner and Thiel, 1991).?
the text generation component KOMET/Penman(Bateman et al, 1991; Penman, 1989), comprising ex-tensive grammatical, semantic, and text organization-al linguistic resources.The paper is organized as tbllows: first, we describe relate(work and how our approach goes beyond this, second, w~introduce the basic components ofour system and explain hovthey can be appropriately interfaced.
Then, we go on to discus:the benefits that including a natural language component caJbring for augmenting the coherence and functionality of~user's interaction with the system.
We offer some examples ohelpful responses that the system can make which would bqdifficult, if not impossible, to represent graphically ina non a,hoc fashion.
Finally, we describe some possible future directions.722 Related WorkOne body of related work has primarily intended to coordinatedifferent modes of expression within a framework of naturalcommunication (cf.
Hayes, 1987; Neal and Shapiro, 1988; Co-hen et al, 1989, Feiner and McKeown, 1990; Bandyopadhyay,1990; S tock, 1991; Wahlster et al, 1991).
The principle fforthere is to ascertain factors that can motivate the distribution ofinformation across different modes (e.g.
Arens and Hovy,1990).
A further body of related work moves towards prob-lems of interaction by exploring the potential of the combina-tion of natural language and deictic gestures (cf.
Allgayer etal., 1989; Moore and Swartout, 1990).
In a similar vein, ap-proaches to flexible graphical interaction based on the con-versationalmetaphor (cf.Reichman, 1986, 1989; Thiel, 1990)treat user inputs uch as mouse clicks, menu selections, etc.
notas invocations of methods that can be executed without regard-ing the dialog context, but instead as dialog acts expressing adiscourse goal of the user.
The direct manipulation fan objectthen becomes itself a part of the dialog of the user with the sys-tem, meaning that the system can respond in a more flexibleway by taking into account the illocutionary and semantic as-pects of the user's input.
Related work from generation i -cludes the correction of misconceptions i  the work of McCoy(1986) and the explicit representation f information about asystem's own knowledge and planning activities that is foundin the Explainable Expert Systems ystem of Swartout andSmoliar (1987).
None of this work, however, addresses theproblems of meta-dialog concerning graphically supported in-teraction.In our approach we bring the kind of natural language ca-pabilities required by the first body of related work (i.e., graph-ical and natural language information functioning together) tobear on the kinds of problems that arise in the second body ofrelated work when the direct manipulation fobjects by a usercreates goals that the system cannot fulfil.
Here we must notonly respond to the user's attempt to manipulate an object orthe user's deictic gesture as a dialog act, but also be able to en-gage in a meta-interaction t  debug that act if it creates a prob-lematic situation.
We show that natural language possessesproperties that make it preferable over the graphical mode ofexpression for such meta-interaction a d hence natural lan-guage generation needs to be supported even in graphics-ori-ented interfaces.3 The S IC!
-Sys temWe demonstrate the combination of graphics ,and natural lan-guage output in the context of the SIC!
system, SIC\[ is imple-mented using HyperNews (HyperNews, 1989), a hypermedia-like user-interface management system which can becontrolled from aLISP-client.
SIC!
offers information on con-ferences; its domain consists of abstract information on con-ferences including workshops, tutorials, persons, institutes,and conference topics.
A user who wants to obtain informationfrom SIC!
poses a query whereafter he can inspect the data re-trieved.
This is done by selecting a presentation form.
In SIC!we use several cognitively motivated presentation forms(Kemer and Thiel; 1991).One of these forms is the ring presentation form (cf.
Fig-ure 1 ) which surveys a structure of given data.
All items arepositioned on a virtual ring structure, the relations between theconcepts being presented as single lines.
In our example thering presentation form contains the categories workshop andtopic.
The concepts of the workshops are on the left side of thefigure, those of the topics on the right.
However, this presenta-tion form is clearly limited with respect to the quantity of datathat can be presented simultaneously.Consider, for example, the following situation: A userasks for a subset of the IJCAI89 workshops and their relatedtopics.
SIC!
retrieves three workshops and several topics.
Ifthe user wants to get an overview of the data's tructure, thenfor this goal the ring is the most adequate presentation formavailable in SIC!
But this causes aproblem when the ring formcannot display as many data s SIC!
retrieved.
There are sever-al ways of solving this problem, depending on the user's mainQ Int Interfaces(0o  Programming)( WS on graphs ( )Figure I :Ring presentation form73point of interest.
If he wants to see all the data he might select apresentation form that can show unlimited amounts of in-formation, e.g.
the table presentation form (cf.
Figure 2 ).
If heWorkshops and their topics: \]WorkshopsO0 ProgrammingInt.
InterfacesWS on graphsTopicsKn-E ngineefinD, 10Prg-Langua ge*, ILearning, IKn-Enginecring, iIKn-Engineering~ IP-Classes,Figure 2 : Table presentation formis interested more in the structure of the data, he might changehis initial query so that less data are retrieved.
But, importantly,the user cannot be aware of the details of the current situationof retrieval and its implications simply from the graphical in-formation displayed.
Hence the system has to inform him ofthe situation and offer possible alternatives.
This needs to bedone in a way that enables users to grasp the situation and tochoose the appropriate alternatives for their purpose.
Toachieve this, the system has to create a coherent informativeact that is concise and yet unambiguous (in context), giving allthe information ecessary for the user to determine his futureactions.Based on work by Feiner and McKeown (1990) on thecoordination of text and graphics in explanation generationand by Lombardi (1989), who examined the assignment of in-formation to media, we assume that ext is the appropriate me-dium for informative acts in meta-dialogs, ince a well-constructed text is not only concise and easy to understand, butalso guarantees the necessary flexibility to meet any situationthat ,arises.
Graphical 'acts' cannot be constructed composi-tionally to express possibly unforeseen complex circum-stances: novel graphics must first be learnt by users- -a situa-tion avoided by the generation of situationally appropriatenatural language.
Thus, generating natural language text, par-ticularly text involving controlled and appropriate deploymentof text-forming resources uch as rhetorical relations, en-hances the total coherence ofthe user's dialog with the system.Our hypothesis  that he user's understanding of the situationand its implications i increased by the natural language out-put, which becomes an intermediary between the various pos-sibilities for information presentation.4 KOMET/Penman Text  Generat ion  SystemWe are using the KOMET/Penman I system (Mann and Mat-thiessen, 1983) for generating the natural language output oursystem requires.
KOMET/Penman is a domain-independenttext generation system based on systemic-functional grammar(Halliday, 1978).
It consists of extensive grammars of Englishand German (Matthiessen, 1990; Teich, 1991), a linguisticallymotivated ontology, called the Upper Model (Bateman, Kasp-er, Moore and Whitney, 1989), a semantic interface that relatesthe categories of the conceptual ontology with their possiblegrammatical expressions in English and German (Matthies-sen, 1990), and a basic lexicon containing English and Germanclosed-class items and default lexical realizations for the con-cepts in the Upper Model ontology.
The definition of the lexi-cal items includes morphological information and sets of lexi-cal features that determine the grammatical contexts in whichitems are to be selected.The Upper Model is the component of the system that isprimarily responsible for mediating between the knowledgespecific to any given domain and the general lexical and gram-matical expressions that are provided by a language.
Because itis possible to state how any particular Upper Model concept isto be realized, subordinating domain concepts to particularUpper Model concepts causes those domain concepts to inheritappropriate forms of expression.
For example, concepts fromthe object-class are usually realized as nominal phrases, whileconcepts from theprocess-class (e.g., mental-process, verbal-process, action-process, relation-process) are often realized byclauses 2.The relationship between Upper Model and domainmodel is diagrammed in the context of its application for SIC!in Figure 3.Input to the KOMET/Penman text generation system isgiven in terms of the Sentence Plan Language (Kasper, 1989),of which we will see examples below.
An SPL expression de-fines the semantic content of a sentence tobe generated; it con-sists of a set of typed variables and relations defined betweenthose variables.
Both the types and the possible relations aredefined either by the Upper Model directly or by concepts orrelations in the domain model that have been subordinated tothe Upper Model.
In addition to this information, SPL expres-sions may also contain direct statements in terms of the gram-roar's semantic interface - -  in practical applications theselatter are often abbreviated by use of macros (e.g.
:tense pres-ent) or are defaulted.1 The original Penman system was developed at the InformationScience Institute of the University of Southern California; theKOMET system of GMD/IPSI builds on this, working towardsmultilinguality and enhanced text planning capabilities.z But not always: the existence of, for example, nominalizationsmotivates the maintenance of two distinct levels of representa-tion,74~i~i;i::iiiii--i;i;:~::.::::::::iiii#ii~:~::;~iiiiii.:i.:i~.:.
:~j::: I!ii 7.Figure 3 : Interfacing SIC!
with KOMET/Penman on the Knowledge Level5 Interfacing SIC!
with the Text GenerationSystemTo interface SIC!
with KOMET/Penman we have to provideseveral types of knowledge (cf.
Figure 3 )?
A domain model, which is a taxonomy of knowledgespecific to our application-domain.
We split the do-main into two parts: an Information-Domain (I-Do-main), which contains concepts related to the informa-tion that is shown by SIC!, e.g.
workshops and topics(cf.
Figure 1 ), and a Presentation-Domain (P-Do-main), which contains concepts related to the way thisinformation is presented by SIC!, e.g.
ring, table.
Bysplitting the domain model we increase the adaptabil-ity in case of changes in the underlying application do-main, e.g.
replacing the conference knowledge basewith a knowledge base on research projects.
Everyconcept in the domain model has to be linked to someUpper Model concept from which it inherits attributeswhich enable KOMET/Penman to express the conceptin a way that is grammatically correct.
The I-Domainconcepts can be generated automatically flom the un-derlying SIC!
knowledge bases (cf.
Figure 3 ).
Con-cepts can also be associated to lexical items.?
A domain lexicon, containing the definitions of lexi-cat items of all the words that may appear in the ap-plication domain.6 Creating the Natural Language Output6.1 Planning SentencesAs stated in our example above, we want to produce text that,in this case, informs the user that not all the information thatwas requested can be shown because the current presentation-form's capacity is limited.
Furthermore, we need to offer pos-sible actions which solve this problem.
In Figure 4, we showthe semantic nput o KOMET/Penman, expressed inSPL, thatwould cause KOMET/Penman to generate the first sentenceI (a / ascription :domain (c / capacity :owned-by (p / presentation-form)) :range (e / exceeded))Fig.
4 : SPL-Plan for"The presentation-form's capacity is exceeded.
"that we require: i.e., "The presentation-form's capacity is ex-ceeded."
One type of abstract concept that the system requiresis the status of a particular entity that may be displayed or used.Possible statuses are, for presentation-forms, exceeded, in-complete.
These status concepts can then be attributed to ob-jects by means of the Upper Model relation ascription, whichhas roles ':domain' and ':range'.
They represent the conceptswhich are related, in our example the presentation-form's ca-pacity and exceeded.
In general, ':domain' contains the essen-tial concept of the relation while ':range' contains additionalinformation.
The P-Domain concept capacity has been mod-eled as an object.6.2 Using Rhetorical RelationsFigure 5 shows a more complex SPL-plan which demon-strates ome of the more advanced possibilities given by KO-MET/Penman.
The most interesting aspect in this plan is theuse of rhetorical relations based on Rhetorical-Structure-Theory (RST).RST is a theory of the organization of natural anguagetexts (Mann and Thompson, 1987).
Mann and Thompson stu-died a wide variety of English texts and observed that here areapproximately 25 relations that usually occur between co-herent portions of English text.
An RST relation consists oftwo parts, a nucleus and a satellite.
The nucleus is that part thatis most essential to the speaker's purpose, while the satellitecontains additional information.
The satellite is more easily re-placed than the nucleus because of the nucleus' central role inthe thematical progression ofthe discourse.
Even though thereare some critics questioning the use of rhetorical relations indiscourse structure theory (Grosz and Sidner, 1986) we use75(rl /rst-nonvolitional-result:domain (el/  existence:domain (cl / concept:number mass:process (r2/show:saying cl:speechact denial:tense present))):range (a/ascription:domain (c2 / capacity:owned-by (p/pres-form)):range (ex / exceeded):tense present)))Figure 5 : SPL-Plan for "There are concepts that are notshown, because the presentation-form's capacity is exceeded".RST relations because they proved to be quite useful when welink portions of information.
In KOMET/Penman, RST-rela-tions are treated the same way as other elations, e.g.
ascriptionwhich we used in the plan shown in Figure 4.The SPL-plan shown in Figure 5 combines two relations:the ascription-relation, which we used in the SPL-plan in Fig-ure 4,  and the existence-relation.
Existence is a so called one-place-relation, because it contains only a :domain-role but no:range.
It is usually realized as "There is ...", where :domaindefines what exists.
We link these two relations via an RST-relation called rst-nonvolitional-result.
This RST-relation im-plies that he nucleus, which is defined in our :domain-role is aresult of the satellite, defined in :range.
One possible output is<domain>, because <range>, inour case "<There are concepts?
..>, because <... capacity is exceeded>".
Because what is de-fined in the :domain ("There are concepts that are not shown")is not volitional, we use rst-nonvolitional-result instead of rst-volitional-result.
The fact that here is data that is not shown bythe current presentation-form is essential to our informationalpurpose.
Therefore this fact becomes the nucleus (representedby :domain) of our plan.RST-relations which ensure the connectivity between our textsegments.
Pragmatic oherence is supported by the mere factthat we are using text as a medium for meta-dialogs, astheseare difficult o understand on a graphical level.7 Controlling Multimodal DiscourseThe dialog manager is one of the main components ofour in-terface system (cf.
Figure 6 ).
It chooses interaction modes(graphic or text) and controls the navigation or exploration ithe information space.In order to prevent he user from 'being lost in hyper-space', we guide the user by case-based dialog plans (Tissen,1991).
In a case-based planning system anew plan will be gen-erated by retrieving the plan which is most appropriate otheuser's goals and adapting it dynamically during the ongoingdialog.
Two types of adaptations can be distinguished: In'st,system-driven modifications using domain dependent back-ground knowledge, and second, corrections of misconcep-tions, handled interactively in meta-dialogs with the user.The dialog manager detects misconceptions, i.e.
situa-tions in which an intended goal cannot be realized, e.g.
moreitems were retrieved than can be displayed in the current pre-sentationform.
The corrector operates on knowledge bases ofmisconceptions and correction rules, e.g.
"if  there is a miscon-ception like 'ring presentation: ot all requested ata can bepresented in the ring' and there is no automatic plan modifica-tion possible then start a meta-dialog, which informs the userabout the situation and offers alternatives."
Because meta-dialogs will be handled in text mode, the dialog manager re-quests the SPL creator to produce SPL plans.
Therefore, thedialog manager informs the SPL creator on the current miscon-ception and possible alternatives the user has to choose from toresolve the situation.
Then, the SPL creator produces the ap-propriate SPL plans by combining information on the miscon-ception and possible alternatives with elements from the SPLlibrary.
The SPL plans are transformed into natural languagetext by the KOMET/Penman system.
The resulting text is re-turned to the dialog manager which presents it to the user.6.3 Supporting CoherenceIn his work on coherence in multi-modal discourse, Bandyo-padhyay (Bandyopadhyay, 1990) states that there are threelevels of coherence: syntactic oherence, semantic oherenceand pragmatic oherence.
Syntactic oherence deals with theimmediate connectivity among adjacent segments (in textsthis is often called text cohesion).
Semantic oherence ensuresthe wellformed thematic organization of a discourse.
Dis-course segments are connected by semantic ties (Hobbs,1983).
Bandyopadhyay defines adiscourse to bepragmatical-ly coherent if it is compatible with the addressees' interpreta-tive ability.
In our system syntactic oherence is enhanced bythe way we present the natural language output in our graphicalenvironment.
Semantic oherence is supported by the use of8 Controlling utterance selectionThe IGiNG system intends to produce user adapted naturaJlanguage output.
It is an object oriented system consisting olseveral object classes (cf.
Figure 7 )When IGiNG is requested toproduce an utterance it calls th~utterance's express method, which In'st builds a list ofplan-ob.jects starting from the initial plan-object given by the utteranceobject.
Then, it is determined whether complex or short state.ments are desired.
This information iskept in a user-stereotypeand determines in which direction the list of plan-objects i  tcbe traversed.
Now IGiNG tests each plan-object's select conditions.
If all conditions are satisfied, the plan-object isselectedotherwise IGiNG tries the succeeding plan-object.
Finally th4plan def'med by the plan-object ispassed to the KOMET\]Penman system which generates the utterance.76Figure 6 : Integrating SIC!
and KOMET/PenmanExample: Let us consider the IGiNG-objects given in Fig-ure 7.
IGiNG is requested to express rood-1.
It builds a listof possible plan-objects, which is (plan-1 plan-2).
As con-cise statements are desired, plan-1 is tested first.
Becausecon-1 is not satisfied (it demands that user-level is low whilethe current user level is advanced) plan-1 is rejected.
Next,plan-2 is tested.
As all conditions are satisfied, the plan givenby plan-2 is generated.Adapting to new situationsWhen a new situations is to be included, the followingsteps have to be performed:A new proposition-instance hasto be defined as the suc-cessor of an existing proposition-class.
If the new propositionis not a part of any of the existing proposition-classes, a newproposition-class should be defined first.For any of the possible utterances a parameterizable par-tial sentence plan has to be written, which is stored in a plan-object, together with a reference to the plan-object's select-condition-object.
Of course, it is possible to use existingplan-objects, if they are suitable for the intended purpose.Finally the plan-objects have to be linked to select-condi-tions.
As these are domain independent, preexisting select-conditions can be reused.These are all the steps necessary for defining new proposi-tions.
The new objects inherit from their ancestors all the func-tionality which is necessary for selection and expression.9 Future WorkWe are going to extend the use of natural language output oother situations which seem to be suited for textual informa-tion rather than graphics.
We are working on a closer examina-tion of what information has to be included in the user-stereo-type and how this knowledge can be obtained.
We intend tointegrate the conversational roles model approach by Sitterand Stein (1991), so that we are able to track meta-dialogs, andto incorporate he current work on text planning to further im-prove the dynamic generation of plan-objects.77IGiNG-Root-Objectproposition-object plan-object select-condition-objectB ~ sI !modification alternativeuser-stereotype-objectm~difia~ t t ioo n-1 !
J alt.ernati.ve_l I I pnan-, J select-condition-Ih a s _ p l a n ~  i ~ has-selcon C-,,jnextplan ~ ~,~, - I  user-levell?wl ~  select-condition-2t , .,,,J~'l reasoning-desiredplan-2has-selcon O".,~ select-condition-3- l ~  \[ give-alternativeshas-selcon O" Imadvanced-useruser-level lowreasoning-desired YESdetailed NOgive-alternatives YESFigure 7 : IGiNG object hierarchy and sample instancesReferencesAllgayer, J., Harbusch, K., Kobsa, A., Reddig, C., Reithin-ger, N., and Schmauks, D. 1989.
XTRA: A Natural Lan-guage Access System to Expert Systems.
In: Int.
J. Man-Machine Studies, Vol.
31, No.
2, 1989, pp.
161-195Arens, Y. and Hovy, E.H. 1990.
How to describe what ?Towards atheory of modality utilization.
In: twelfth annualconference ofthe Cognitive Science Society, pp.
487-94,Lawrence Erlbaum Associates, Hillsdale, New Jersey,1990, July 25-28, 1990, Cambridge, USABandyopadhyay, S. 1990.
Towards an Understanding ofCoherence in Multi-Modal Discourse, Technical MemoTM-90-01, Deutsches Forschungsinstitut fuer Kuenst-liche InteUigenz GmbH, Saarbruecken, 1990Bateman, J. Kasper, B., Moore, J., and Whitney, R. 1989.A general organization of knowledge for natural anguageprocessing: the Penman Upper Model.
USC/InformationSciences Institute, Technical Report, 1989Bateman, J. and Paris, C. 1989.
Phrasing text in terms theuser can understand.
In: Proceedings ofIJCAI-89Bateman, J., Maier, E., Teich, E., and Wanner,L.
19c~Towards an Architecture for Situated Text Generation, iInternational Conference on Current Issues in Compultional Linguistics, Penang, Malaysia, 1991Brooks, H.M., Daniels, P.J.
and Belkin, N.J. 1986./qsearch on Information Interaction and Intelligent lnforrrtion Provision Mechanisms.
In: J. of Information ScienlVol.
12, 1986, pp.
37--44Cohen, P. R., Dalrymple, M., Moran, D., Pereira, F., Su\]van, J., Gargan Jr., R., Schlossberg, J. and Tyler, S. 19tSynergistic Use of Direct Manipulation and Natural Lcguage.
In: Bice, K., and Lewis, C. (eds): ProceedingsCHI '89, (Austin, Texas, April 30 - May 4, 1989), NqYork: ACM, 1989, pp.
227-233Feiner, S.K.
and McKeown, K.R.
1990.
Coordinating T,and Graphics in Explanation Generation.
In: AAAI -c.Proc.
8th Nat.
Conf.
on Artificial Intelligence.
July1990- Aug. 3, 1990.
Vol.
I. Menlo Park et al: AAAI Pre:The MIT Press, 1990, pp.
442 ,149.78Grosz, B.J.
and Sidner, C.L.
1986.Attention, I tention, andthe Structure of Discourse, Computational Linguistics,Vol.
12, No.
3, pp.
175-204, 1986Halliday, 1978.
Language as Social Semiotic.
London: Ed-ward Arnold.Hayes, Philip J.
1987.
Steps towards Integrating NaturalLanguage and Graphical Interaction for Knowledge-Based Systems.
In: Boulay, B. du / Hogg, D. / Steels, L.(eds): Advances in Artificial Intelligence - -  II.
(Proc.ECAI-86), Amsterdam et al: North-Holland, 1987, pp.543--552Hobbs, J.
1983.
Why is Discourse Coherent ?
In: Neubauer(Editor), Coherence in Natural Language Texts, Buske,1983Hutchins, E.L., Hollan, J.D.
and Norman, D.A.
1986.
Di-rectManipulation Interfaces.
In: Norman, D.A,, and Drap-er, S.W.
(eds): User Centered System Design: New Per-spectives on Human-Computer Interaction.
Hillsdale, NJ& London: Lawrence Erlbaum, 1986, pp.
87--124HyperNews 1989.
HyperNeWS User's Guide, Hoff, Arthurvan (Editor), The Turing Institute, Glasgow, UK, 1989Kasper, R. 1989.
A flexible interface for linking applica-tions to Penman's entence generator.
Proceedings of theDARPA Workshop on Speech and Natural Language.Kerner, A. and Thiel, U.
1991.
Graphical Support forUsers' Inferences within Retrieval Dialogues.
In: Proceed-ings of the IEEE Workshop on Visual Languages 1991,pp.211-216,Kracker, M. 1991.
Unscharfes assoziativesBegriffswissenzur Unterstiitzung der Formulierung von Datenbankabfra-gen, Dissertation, TU Wien, April 1991.
Title in English:Fuzzy Associative Conceptual Knowledge for SupportingQuery Formulation.Lombardi, C. 1989.
Experiments for Determining the As-signment of Information to Media in COMET, ColumbiaUniversity, New York, N.Y., USA, 1989Mann W.C. and Matthiessen C. 1983.
Nigel: A SystemicGrammar for Text Generation, Technical ReportRR-83-105, USC/Information Sciences Institute, 1983Mann, W.C. and Thompson, S.A. 1987.
Rhetorical Struc-ture Theory: A Theory of Text Organization.
In: Polanyi, L.(Editor): The Structure of Discourse, Ablex PublishingCompany, Norwood, N.J., 1987.
Also available as US C/In-formation Sciences Institute Technical Report NumberRS-87-190Matthiessen, C.M.I.M.
1990.
Lexicogrammatical C rtog-raphy: the systems of English.Expanding ongoing draft.
Department ofLinguistics, Uni-versity of Sydney, Australia.McCoy, K.F.
1986.
The ROMPER system: responding toobject-related misconceptions using perspective.
Pro-ceedings of the 24th.
Annual Meeting of the Associationfor Computational Linguistics, New York.Moore, J.D.
and Swartout, J.R. 1990.
Pointing: A WayToward Explanation Dialogue.
In: AAAI-90: Proc.
8thNat.
Conf.
on Artificial Intelligence.
July 29, 1990-- Aug.3, 1990.
Vol.
I. Menlo Park et al: AAAI Press / The MITPress, 1990, pp.
457~464Neal, J.G.
and Shapiro S.C. 1988.
Intelligent Multi-MediaInterface Technology.
In: Sullivan, J.W./Tyler, S.W.
(eds):Proceedings ofthe Workshop on Architectures for Intelli-gent Interfaces: Elements and Prototypes.
ACM/Addison-Wesley, 1989, pp.
69--91Penman 1989.
The Penman Project: The Penman Primer,User Guide and Nigel Manual.
USC / InformationSciences Institute, Marina del Rey, CA, 1989Reichman, R. 1986.
Communication Paradigms for a Win-dow System.
In: Norman, D.A.
/ Draper, S.W.
(eds): UserCentered System Design: New Perspectives on Human-Computer Interaction.
Hillsdale, NJ & London: LawrenceErlbaum, 1986, pp.
285--313Reichman, R. 1989.
Integrated Interfaces Based on aTheory of Context and Goal Tracking.
In: Taylor, M.M.
/Neel, F. / Bouwhuis, D.G.
(eds): The Structure of Multimo-dal Dialogue.
Amsterdam et al: North-Holland, 1989, pp.209---228Sitter, S. and Stein, A.
1991.
Modeling the lllocutionaryAspects of Information-Seeking Dialogues, Arbeitspa-piere der Gesellschaft uer Mathematik und Datenverar-beitung 515, 1991Stock, O.
1991.
Natural Language and the Exploration ofan Information Space: the ALFresco Interactive System.IJCAI91, Sydney.
pp972-978.Swartout, W.R. and Smoliar, S. 1987.
Explaining the linkbetween causal reasoning and expert behavior.
In: Pro-ceedings of the Symposium on Computer Applications inMedical Care.
Washington, D.C.Teich, E. 1991.
A Systemic Grammar of German for TextGeneration, to appear in: Davies, M., L. Ravelli, Advancesin Systemic Linguistics: Recent Theory and Practice, inprogress.Thiel, U.
1990.
Konversationale graphische lnteraktionmit lnformationssystemen: Ein sprechakttheoretischer An-satz.
Dissertation, Universitat Konstanz.
Title in English:Conversational Graphical Interaction with Information-Systems.
An approach based on Speechact Theory.Tissen, A.
1991.
A Case-Based Architecture for a Dia-logue Manager for Information-Seeking Processes.
In:Procceedings ofSIGIR '91, October 13-16, 1991, Chica-go, USAWahlster, W., Andrt, E., Graf, W., and Rist, T. 1991.
De-signing illustrated texts: how language production is in-fluenced by the graphics generation.
Proceedings of the5th Conference ofthe European Chapter of the Associationfor Computational Linguistics.79
