Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: System Demonstrations,pages 6?9, Dublin, Ireland, August 23-29 2014.Claims on demand ?
an initial demonstration of a system for automaticdetection and polarity identification of context dependent claims inmassive corporaEhud Aharoni Carlos Alzate Roy Bar-Haim Yonatan BiluIBM Haifa ResearchLab, Haifa, IsraelIBM Dublin ResearchLab, IrelandIBM Haifa ResearchLab, Haifa, IsraelIBM Haifa ResearchLab, Haifa, IsraelLena Dankin Iris Eiron Daniel Hershcovich Shay HummelIBM Haifa ResearchLab, Haifa, IsraelIBM Haifa ResearchLab, Haifa, IsraelIBM Haifa ResearchLab, Haifa, IsraelIBM Haifa ResearchLab, Haifa, IsraelMitesh Khapra Tamar Lavee1 Ran Levy Paul MatchenIBM Bangalore Re-search Lab, IndiaIBM Haifa ResearchLab, Haifa, IsraelIBM Haifa ResearchLab, Haifa, IsraelIBM YKT ResearchLab, USAnatoly Polnarov Vikas Raykar Ruty Rinott Amrita SahaHebrew University,Jerusalem, IsraelIBM Bangalore Re-search Lab, IndiaIBM Haifa ResearchLab, Haifa, IsraelIBM Bangalore Re-search Lab, IndiaNaama Zwerdling David Konopnicki Dan Gutfreund Noam Slonim2IBM Haifa ResearchLab, Haifa, IsraelIBM Haifa ResearchLab, Haifa, IsraelIBM Haifa ResearchLab, Haifa, IsraelIBM Haifa ResearchLab, Haifa, IsraelAbstractWhile discussing a concrete controversial topic, most humans will find it challenging to swiftly raise adiverse set of convincing and relevant claims that should set the basis of their arguments.
Here, we dem-onstrate the initial capabilities of a system that, given a controversial topic, can automatically pinpointrelevant claims in Wikipedia, determine their polarity with respect to the given topic, and articulate themper the user's request.1 IntroductionThe ability to argue in a persuasive manner is an important aspect of human interaction that naturallyarises in various domains such as politics, marketing, law, and health-care.
Furthermore, good decisionmaking relies on the quality of the arguments being presented and the process by which they are re-solved.
Thus, it is not surprising that argumentation has long been a topic of interest in academic re-search, and different models have been proposed to capture the notion of an argument (Freeley andSteinberg, 2008).A fundamental component which is common to all these models is the concept of claim (or conclu-sion).
Specifically, at the heart of every argument lies a single claim, which is the assertion the argu-ment aims to prove.
Given a concrete topic, or context, most humans will find it challenging to swiftlyraise a diverse set of convincing and relevant claims that should set the basis of their arguments.This work is licensed under a Creative Commons Attribution 4.0 International License.
Page numbers and proceedings footerare added by the organizers.
License details: http:// creativecommons.org/licenses/by/4.0/1 Present affiliation: Yahoo!2 Corresponding author, at noams@il.ibm.com6In this work we demonstrate the initial capabilities of a system that, given a controversial topic, canautomatically pinpoint relevant claims in Wikipedia, determine their polarity with respect to the giventopic, and articulate them per the user's request.2 Basic concepts and associated challengesWe define and rely on the following two concepts:Topic: Short, usually controversial statement that defines the subject of interest.Context Dependent Claim (CDC): General, and concise statement, that directly supports or conteststhe given Topic.Given these definitions, as well as a few more detailed criteria to reduce the variability in the manu-ally labeled data, human labelers were asked to detect CDCs for a diverse set of Topics, in relevantWikipedia articles.
The collected data were used to train and assess the performance of the statisticalmodels that underlie our system.
These data are freely available for academic research (Aharoni et al2014).The distinction between a CDC and other related texts can be quite subtle, as illustrated in Table 1.For example, automatically distinguishing a CDC like S1 from a statement that simply defines a rele-vant concept like S4, from a claim which is not relevant enough to the given Topic like S5, from astatement like S6 that merely repeats the given Topic in different words, or from a statement that repre-sents a relevant claim which is not general enough like S7, is clearly challenging.
Further, CDCs canbe of different flavors, ranging from factual assertions like S1 to statements that are more of a matter ofopinion (Pang and Lee 2008) like S2, adding to the complexity of the task.
Moreover, our data suggestthat even if one focuses on Wikipedia articles that are highly relevant to the given Topic, only ?2% oftheir sentences include CDCs.Furthermore, since CDCs are by definition concise statements, they typically do not span entireWikipedia sentences but rather sub-sentences.
This is illustrated in Table 2.
There are many optionalboundaries to consider when trying to identify the exact boundaries of a CDC within a typical Wikipe-dia sentence.
This task further complicates the CDC detection problem.
Thus, we are faced with a largenumber of candidate CDCs, of which only a tiny fraction represents positive examples that might bequite reminiscent of some of the negative examples.
Finally, automatically determining the correctPro/Con polarity of a candidate CDC with respect to the Topic poses additional unique challenges.Nonetheless, by breaking the problem into a set of modular tangible problems and by employing vari-ous techniques - specifically designed to the problems at hand - we obtain promising results, demon-strated by the capabilities of our system.Topic The sale of violent video games to minors should be banned(Pro) CDC S1: Violent video games can increase children?s aggression(Pro) CDC S2: Video game publishers unethically train children in the use of weaponsNote, that a valid CDC is not necessarily factual.
(Con) CDC S3: Violent games affect children positivelyInvalidCDC 1S4: Video game addiction is excessive or compulsive use of computer and video gamesthat interferes with daily life.This statement defines a concept relevant to the Topic, not a relevant claim.InvalidCDC 2S5: Violent TV shows just mirror the violence that goes on in the real world.This statement is not relevant enough to the Topic.InvalidCDC 3S6: Violent video games should not be sold to children.This statement simply repeats the Topic, and thus is not considered a valid CDC.InvalidCDC 4S7: ?Doom?
has been blamed for nationally covered school shooting.This statement is not general enough to represent a CDC, as it focuses on a specificsingle video game.Table 1.
Examples of CDCs and invalid CDCs.7Because violence in video games is interactive and not passive, critics such as Dave Grossman andJack Thompson argue that violence in games  hardens children to unethical acts, calling first-personshooter games ``murder simulators'', although no conclusive evidence has supported this belief.Table 2.
A CDC is often only a small part of a single Wikipedia sentence - e.g., the part marked in boldin this example.Figure 1.
High level architecture of the demonstrated system.3 High Level ArchitectureThe demonstrated system relies on a cascade of engines, depicted in Figure 1.
In general, these enginesrely on various IR, NLP and ML technologies, as well as different resources and lexicons likeWordNet (Miller, 1995).
Some engines are more mature than others, and, correspondingly, alreadyemploy a complex inner architecture, that will be discussed in more detail elsewhere.
Given a Topic,the Topic Analysis engine starts with initial semantic analysis of the Topic, aiming to identify themain concepts mentioned in this Topic and the sentiment towards each concept.
Next, the CDCOriented Article Retrieval engine employs IR and opinion mining techniques in order to retrieveWikipedia articles that with high probability contain CDCs.
Next, the CDC Detection engine relies ona combination of NLP and ML techniques to zoom-in within the retrieved articles and detect candidateCDCs.
A detailed description of this engine can be found in (Levy et al 2014).
Next, the CDCPro/Con engine aims to automatically determine the polarity of the candidate CDC with respect to thegiven Topic by analyzing and contrasting the sentiment towards key concepts mentioned in the Topicand within the candidate CDC.
Next, the CDC Equivalence engine uses techniques reminiscent ofautomatic paraphrase detection to identify whether two candidate CDCs are semantically equivalent, soto avoid redundancy in the generated output.
Finally, the CDC Refinement engine aims to improvethe precision of the generated output, based on the results collected thus far; e.g., using a simple rule-based approach, we remove candidate CDCs for which the predicted Pro/Con polarity has lowconfidence.
The remaining predictions are sent to the Text To Speech engine that articulates the topCDC predictions at the user's request.4 SummaryGiven a Topic, the demonstrated system is currently focused on detecting and articulating relevantCDCs.
Combining this system with technologies that could automatically detect evidence to supportthese CDCs, may give rise to a new generation of automatic argumentation systems.
In principle, suchsystems may swiftly detect relevant CDCs in massive corpora, and support these CDCs with evidencedetected within other articles, or even within entirely different corpora, ending up with automatically8generated arguments that were never explicitly proposed before in this form by humans.
The systemdescribed herein represents an important step in pursuing this vision.AcknowledgmentsWe would like to thank our colleagues in the IBM debating technologies team who participate ingenerating more advanced versions of the system presented in this work, and further continue tocontribute to essential aspects of this project.
These include Priyanka Agrawal, Indrajit Bhattacharya,Feng Cao, Lea Deleris, Francesco Dinuzzo, Liat Ein-Dor, Ron Hoory, Hui Jia Zhu, Qiong Kai Xu,Abhishek Kumar, Ofer Lavi, Naftali Liberman, Yosi Mass, Yuan Ni, Asaf Rendel, Haggai Roitman,Bogdan Sacaleanu, Dafna Sheinwald, Eyal Shnarch, Mathieu Sinn, Orith Toledo-Ronen, DoronVeltzer and Yoav Katz.ReferencesAustin J. Freeley and David L. Steinberg.
2008.
Argumentation and Debate.
Wadsworth, Belmont,California.Ehud Aharoni, Anatoly Polnarov, Tamar Lavee, Daniel Hershcovich, Ran Levy, Ruty Rinott, Dan Gut-freund, and Noam Slonim.
2014.
"A Benchmark Dataset for Automatic Detection of Claims andEvidence in the Context of Controversial Topics", in Proceedings of the First Workshop on Argu-mentation and Computation, ACL 2014, to appear.Bo Pang and Lillian Lee.
2008.
"Opinion mining and sentiment analysis" in Foundations and Trends inInformation Retrieval, Vol.
2, pp.
1-135.George A Miller.
1995. "
WordNet: A Lexical Database for English" in Communications of the ACM,Vol.
38, pp.
29-41.Ran Levy, Yonatan Bilu, Daniel Hershcovich, Ehud Aharoni and Noam Slonim.
2014.
?Context De-pendent Claim Detection.?
In Proceedings of the 25th International Conference on ComputationalLinguistics, COLING 2014, to appear.9
