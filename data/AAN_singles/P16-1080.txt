Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 843?854,Berlin, Germany, August 7-12, 2016.c?2016 Association for Computational LinguisticsAnalyzing Biases in Human Perception of User Age and Gender from TextLucie Flekova?Ubiquitous Knowledge Processing LabDepartment of Computer ScienceTechnische Universit?at Darmstadtwww.ukp.tu-darmstadt.deJordan Carpenter and Salvatore GiorgiPositive Psychology CenterUniversity of PennsylvaniaLyle Ungar and Daniel Preot?iuc-PietroComputer & Information ScienceUniversity of PennsylvaniaAbstractUser traits disclosed through written text,such as age and gender, can be used to per-sonalize applications such as recommendersystems or conversational agents.
However,human perception of these traits is not per-fectly aligned with reality.
In this paper,we conduct a large-scale crowdsourcing ex-periment on guessing age and gender fromtweets.
We systematically analyze the qual-ity and possible biases of these predictions.We identify the textual cues which lead tomiss-assessments of traits or make annota-tors more or less confident in their choice.Our study demonstrates that differences be-tween real and perceived traits are notewor-thy and elucidates inaccurately used stereo-types in human perception.1 IntroductionThere are notable differences between actual usertraits and their perception by others (John andRobins, 1994; Kobrynowicz and Branscombe,1997).
Assessments of the perceived traits are de-pendent, for example, on the interpretation skillsof a judge (Kenny and Albright, 1987) and the abil-ity of users to deliberately adjust their behavior tothe way they intend to be perceived e.g., for fol-lowing a social goal (Kanellakos, 2002).
Peopletypically use stereotypes ?
a set of beliefs, gener-alizations, and associations about a social group ?to make judgements about others.
The discrepancybetween stereotypes and actual group differences is?Project carried out during a research stay at the Univer-sity of Pennsylvaniaan important topic in psychological research (Eagly,1995; Dovidio et al, 1996; John and Robins, 1994;Kobrynowicz and Branscombe, 1997).
Such differ-ences are likely reflected through one?s writing.With the Internet a substantial part of daily life,users leave enough footprints which allow algo-rithms to learn a range of individual traits, somewith even higher accuracy than the users?
own fam-ily (Youyou et al, 2015).
With an increase in read-ily available user generated content, prediction ofuser attributes has become more popular than ever.Researchers built learning models to infer differentuser traits from text, such as age (Rao et al, 2010),gender (Burger et al, 2011; Flekova and Gurevych,2013), location (Eisenstein et al, 2010), politicalorientation (Volkova et al, 2014), income (Preot?iuc-Pietro et al, 2015c), socio-economic status (Lam-pos et al, 2016), popularity (Lampos et al, 2014),personality (Schwartz et al, 2013) or mental ill-nesses (De Choudhury et al, 2013; Coppersmith etal., 2014; Preot?iuc-Pietro et al, 2015a).Prediction models are trained on large datasets with labels extracted either from user self-reports (Preot?iuc-Pietro et al, 2015b) or perceivedfrom annotations (Volkova et al, 2015; Volkovaand Bachrach, 2015).
The former is useful in ob-taining accurate prediction models for unknownusers while the latter is more suitable in appli-cations that interact with humans.
Previous stud-ies showed the implications of perceived individ-ual traits to the believability and likability of au-tonomous agents (Bates, 1994; Loyall and Bates,1997; Baylor and Kim, 2004).This study aims to emphasize the differencesbetween real user traits and how these are perceivedby humans from Twitter posts.
In this context, weaddress the following research questions:843?
How accurate are people at judging traits ofother users??
Are there systematic biases humans are sub-ject to??
What are the implications of using human per-ception as a proxy for truth??
Which textual cues lead to a false perceptionof the truth??
Which textual cues make people more or lessconfident in their ratings?We use age and gender as target traits for ouranalysis, as these are considered basic categoriesin person assessment (Quinn and Macrae, 2005)and are highly studied by previous research.
Us-ing a large-scale crowdsourcing experiment, wedemonstrate that human annotators are generallyaccurate in assessing the traits of others.
However,they make systematically different types of errorscompared to a prediction model trained using thebag-of-words assumption.
This hints at the fact thatannotators over-emphasize some linguistic featuresbased on their stereotypes.
We show how this phe-nomenon can be leveraged to improve predictionperformance and demonstrate that by replacing self-reports with perceived annotations we introducesystematic biases into our models.In our analysis section, we directly test the accu-racy of these stereotypes, as the human predictionsmust rely on these theories of relative differencesbetween groups if no explicit cues are mentioned.We uncover remarkable differences between actualand perceived traits by using multiple lexical fea-tures: unigrams, clusters of words built from wordembeddings and emotions expressed through posts.In our analysis of features that lead to wrong as-sessments we uncover that humans mostly rely onaccurate stereotypes from textual cues, but some-times over-emphasize them.
For example, anno-tators assume that males post more than they doabout sports and business, females show more joy,older users more interest in politics and youngerusers use more slang and are more self-referential.Similarly, we highlight the textual features whichlead to higher self-reported confidence in guesses,such as the mentions of family and beauty productsfor gender or college and school related topics forage.2 Related WorkStudying gender differences has been a popular psy-chological interest over the past decades (Gleser etal., 1959; McMillan et al, 1977).
Traditional stud-ies worked on small data sets, which sometimesled to contradictory results ?
(Mulac et al, 1990)cf.
(Pennebaker et al, 2003).
Over the past years,researchers discovered a wide range of gender dif-ferences using large collections of data from socialmedia or books combined with more sophisticatedtechniques.
For example, Schler et al (2006) ap-ply machine learning techniques to a corpus of37,478 blogs from the Blogger platform and finddifferences in the topics males and females discuss.Newman et al (2008) showed that female authorsare more likely to include pronouns, verbs, refer-ences to home, family, friends and to various emo-tions.
Male authors use longer words, more articles,prepositions and numbers.
Topical differences in-clude males writing more about current concerns(e.g., money, leisure or sports).
More recent authorprofiling experiments (Rangel et al, 2014; Rangelet al, 2015) revealed that gender can be well pre-dicted from a large spectrum of textual features,ranging from paraphrase choice (Preot?iuc-Pietro etal., 2016), emotions (Volkova and Bachrach, 2016),part-of-speech (Johannsen et al, 2015) and abbrevi-ation usage to social network metadata, web traffic(Culotta et al, 2015), apps installed (Seneviratne etal., 2015) or Facebook likes (Kosinski et al, 2013).Bamman et al (2014) also examine individualswhose language does not match their automaticallypredicted gender.
Most of these experiments werebased on self-reported gender in social media pro-files.The relationship between age and language hasalso been extensively studied by both psychologistsand computational linguists.
Schler et al (2006)automatically classified blogposts into three agegroups based on self-reported age using featuresfrom the Linguistic Inquiry and Word Count Frame-work (Pennebaker et al, 2001), online slang andpart-of-speech information.
Rosenthal and McK-eown (2011) analyzed how both stylistic and lex-ical cues relate to gender on blogs.
On Twitter,Nguyen et al (2013) analyzed the relationship be-tween language use and age, modelled as a contin-uous variable.
They found similar language usagetrends for both genders, with increasing word andtweet length with age, and an increasing tendencyto write more grammatically correct, standardized844text.
Flekova et al (2016) identified age specificdifferences in writing style and analyzed their im-pact beyond income.
Recently, Nguyen et al (2014)showed that age prediction is more difficult as ageincreases, specifically over 30 years.
Hovy andS?gaard (2015) showed that the author age is afactor influencing training part-of-speech taggers.Recent results on social media data report a per-formance of over 90% for gender classification anda correlation of r ?
0.85 for age prediction (Sapet al, 2014).
However, authors can introduce theirbiases in text (Recasens et al, 2013).
Accurateprediction of the true user traits is important forapplications such as recommender systems (Braun-hofer et al, 2015) or medical diagnoses (Chattopad-hyay et al, 2011).
Influencing perceived traits, onthe other hand, enables a whole different rangeof applications - for example, researchers demon-strated that the perceived demographics influencestudent attitude towards a tutor (Baylor and Kim,2004; Rosenberg-Kima et al, 2008).
Perceptionalterations do not only strive for likeability - peo-ple intentionally use linguistic nuances to expresssocial power (Kanellakos, 2002), which can berecognized by computational means (Bramsen etal., 2011).
McConnell and Fazio (1996) show howgender-marked language colors the perception oftarget personality characteristics ?
enhanced ac-cessibility of masculine and feminine attributesbrought about by frequent exposure to occupationtitle suffixes influences the inferences drawn aboutthe target person.3 DataIn this study, we focus on analyzing human percep-tion of two user traits: gender and age.
For judg-ing, we build data sets using publicly availableTwitter posts from users with known self-reportedage and gender.
To study gender, we use the usersfrom Burger et al (2011), which are mapped totheir self-identified gender as mentioned in otheruser public profiles linked to their Twitter account.This data set consists of 67,337 users, from whichwe subsample 2,607 users for human assessment.The age data set consists of 826 users that self-reported their year of birth and Twitter handle aspart of an online survey.We use the Twitter API to download up to 3200tweets from these users.
These are filtered for En-glish language using an automatic method (Lui andBaldwin, 2012) and duplicate tweets are eliminated(i.e., having the same first 6 tokens) as these areusually generated automatically by apps.
TweetURLs and @-mentions are anonymized as theymay contain sensitive information or cues exter-nal to language use.
For human assessment, werandomly select 100 tweets posted in the same 6month time interval from the users where gender isknown.
For the users of known age we randomlyselect 100 tweets posted during the year 2015.4 Experimental SetupWe use Amazon Mechanical Turk to create crowd-sourcing tasks for predicting age and gender fromtweets.
Each HIT consists of 20 tweets randomlysampled from the pool of 100 tweets of a singleuser.
Each user was assessed independently by 9different annotators.
Using only these tweets ascues, the annotators were asked to predict eitherage (integer value) or gender (forced choice binarymale/female) and self-rate the confidence of theirguess on a scale from 1 (not at all confident) to 5(very confident).Participants received a small compensation(.02$) for each rating and could repeat the taskas many times as they wished, but never for thesame author.
They were also presented with an ini-tial bonus (.25$) and a similar one upon completinga number of guesses.
For quality control, we useda set of HITs where the user?s age or gender wasexplicitly stated within the top 10 tweets displayedin the task.
The control HIT appeared 10% of thetime and all annotators missing the correct answertwice were excluded from annotation and all theirHITs invalidated.
A total of 28 annotators werebanned from the study.
Further, we limited annota-tor location to the US and they had to spend at least10 seconds on each HIT before they were allowedto submit their guess.5 Crowdsourcing ResultsWe first analyze the annotator performance on thegender and age prediction tasks from text.
For gen-der, individual ratings have an overall accuracy of75.7% (78.3% for females and 72.8% for males).The pairwise inter-annotator agreement for 9 anno-tators is 70.0%, Fleiss?
Kappa 39.6% and Krippen-dorf?s Alpha 39.6%, while keeping in mind that theannotators are not the same for all Twitter users.
Interms of confidence, average self-rated confidencefor correct guesses is ?
= 3.47, while average con-fidence for wrong guesses is ?
= 2.84.
In total,8451083 individual annotators performed an averageof ?
= 22.3 ratings with the standard deviation?
= 32.76 and the median of 12.We use the majority vote as the method of la-bel aggregation for gender prediction.
The majorityvote accuracy on predicting the gender of Twit-ter users is 85.8% with the majority class baselinebeing 51.9% female, a result comparable to a previ-ous study (Nguyen et al, 2014).
Table 1a presentsthe gender confusion matrix.
Female users weremore often classified into a correct class (88.3%recall for females cf.
83.5% for males).
The major-ity of errors was caused by male users mislabeledas female.
This results in higher precision on clas-sifying male users (86.9% cf.
85.3% for females).In terms of overall self-reported confidence of theannotators, decisions on actual female users wereon average more confidently rated (?
= 3.60) com-pared to males (?
= 3.31), which is in consensuswith higher accuracy for females.
Figure 2 showsthe relationship between annotation accuracy andaverage confidence per Twitter users.
The relation-ship is non-linear, with the average confidence inthe 1?3 range for gender having little impact on theprediction accuracy.For the age annotations, the correlation betweenpredicted and real age for individual ratings isr = 0.416.
The mean absolute error (MAE) is 7.31,while the baseline MAE obtained if predicted thesample mean real age is 8.61.
The intraclass corre-lation coefficient between the 9 ratings is 0.367 andtaking into account the fact that the annotators weredifferent across users (Shrout and Fleiss, 1979),while the average standard deviation of the 9 userguesses for a single Twitter user is ?
= 5.60.
In-dividual rating confidence and the Mean AbsoluteError (MAE) are anti-correlated with r = ?0.112,matching the expectation that higher self-reportedconfidence leads to lower errors.
The 691 differ-ent annotators performed on average ?
= 10.68ratings with standard deviation ?
= 21.95 and amedian of only 4 ratings.
Based on feedback, thiswas due to the difficulty of the age task.In the rest of the age experiments, we considerthe predicted age of a user as a mean of the 9 humanguesses.
Overall, the correlation between averagepredicted age and real age is r = 0.631.
The MAEof the average predicted age is 6.05.
MAE and av-erage self-rated confidence by user are negativelycorrelated with r = ?0.21.
Figure 3 plots annota-tion confidence on a Twitter user level and MAE of102030405020 30 40 50 60 70Real AgePerceived AgeFigure 1: Real age predictions compared to averagepredicted age.
The line shows a LOESS fit.age guesses.
Again, the relationship between con-fidence and MAE is non-linear, with confidencesof 1?2 having similar average MAE, with the errordecreasing as the average of the confidence ratingsper author is higher.
Figure 1 shows a scatter plotcomparing real and predicted age together with anon-linear fit of the data.
From this figure, we ob-serve that annotators under-predict age, especiallyfor older users.
The correlation of MAE with realage is very high (r = 0.824) and the residuals arenot normally distributed.Figures 4 and 5 show the accuracy if only a sub-sample of the ratings is used and the labels areaggregated using majority vote for gender and us-ing average ratings for age.
For gender, we noticethat accuracy abruptly increases from 1 to 3 votesand to a lesser extent from 3 to 5 votes, but thedifferences between 5, 7 and 9 votes are very small.Similarly, for age, MAE decreases up until using4 guesses, where it reaches a plateau.
These exper-iments suggest that a human perception accuracycan be sufficiently approximated using up to 5 rat-ings - additional annotations after this point havenegligible contribution.Finally, the individual annotator accuracy is in-dependent on the number of users rated.
For gender,the Pearson correlation between accuracy and num-ber of ratings performed is r = .009 (p = .75)and for age the Pearson correlation between MAEand the number of ratings performed by a user isr = ?.013 (p = .71).
This holds even when ex-cluding users who performed few ratings.6 Uncovering Systematic BiasesIn this section, we use the extended gender dataset in order to investigate if human guesses containsystematic biases by comparing these guesses tothose from a bag-of-words prediction model.
Wethen test what is the impact of using human guessesas labels and if human ratings offer additional in-8460.50.60.70.80.91.01 2 3 4 5Avg.
Confidence / UserFraction CorrectFigure 2: Gender ?
Fraction of correct guesses asa function of average confidence per rated Twitteruser.
Black line shows a LOESS fit.051015201 2 3 4 5Avg.
Confidence / UserMAEFigure 3: Age ?
Mean Absolute Error as a functionof average confidence per rated Twitter user.
Blackline shows a LOESS fit.70758085901 3 5 7 9No.VotesAccuracyFigure 4: Gender ?
Majority vote accuracy basedon number of annotator guesses aggregated.5.56.06.57.07.51 3 5 7 9No.VotesMAEFigure 5: Age ?
Average Mean Absolute Errorbased on number of annotator guesses aggregated.formation to predictive models.16.1 Comparison to Bag-of-Words PredictionsFirst, we test the hypothesis that annotators em-phasize certain stereotypical words to make theirguesses.
To study their impact, we compare humanguesses with those from a statistical model usingthe bag-of-words assumption for systematic dif-ferences.
The automatic prediction method using1Experiments for age could not be replicated due to insuf-ficient labeled users.bag-of-words text features offers a generalisationof individual word usage patterns shielded frombiases.We use Support Vector Machines (SVM) witha linear kernel and `1regularization (Tibshirani,1996), similarly to the state-of-the-art method inpredicting user age and gender (Sap et al, 2014).The features for these models are unigram fre-quency distributions computed over the aggregateset of messages from each user.
Due to the sparseand large vocabulary of social media data, we limitthe unigrams to those used by at least 1% of users.We train a classifier on a balanced set of 11,196Twitter users from our extended data set.
We teston the 2,607 users rated by the annotators usingonly the 100 tweets the humans had access whenmaking their predictions.
Table 1b shows the sys-tem performance reaching an accuracy of 82.9%,with the human performance on the same data at85.88%.
In contrast to the human prediction, theprecision is higher for classifying females (84.9%cf.
80.9% for males) and the recall is higher formales (85.4% cf.
80.4% for female).
This is causedby both higher classifier accuracy for males andby a switch in rank between the type I and type IIerrors.In Table 1c we directly compare the human andautomatic predictions, highlighting that 13.6% ofthe labels are different.
Moreover, there is an asym-metry between the tendency of humans to mislabelmales with females and the classifier.
This leadsto the conclusion that humans are sensitive to bi-ases which we will qualitatively investigate in thefollowing sections.6.2 Human Predictions as LabelsPreviously, we have shown that perceived anno-tated traits are different in many aspects to actualtraits.
To quantify their impact, we use these labelsfor training two classifiers and compare them onpredicting the true gender for unseen users.Both systems are trained on the 260,700 mes-sages from 2,607 users and only differ in the la-bels assigned to users: majority annotator vote orself-reports.
Results on the held-out set of 11,196users (of which 6,851 males and 7,596 females) arepresented in Table 2.
The system trained on reallabels outperforms that trained on perceived ones(accuracy of 85.32% cf.
83.40%).
Furthermore, inthe system trained on perceived labels, the sametype of error as for the human annotation is moreprevalent and is overemphasized compared to our847(a) Majority annotator vote.Pred.HMale FemaleRealMale 40.1% 7.9%Female 6.1% 45.8%(b) Classifier.Pred.CMale FemaleRealMale 42.2% 7.2%Female 9.9% 40.7%(c) Classifier compared to majority an-notator vote.Pred.HPred.CMale FemaleMale 40.3% 8.0%Female 5.6% 46.1%Table 1: Normalized confusion matrices of human annotations (Pred.H) to ground truth (Real), classifierperformance (Pred.C) to ground truth (Real), and human annotations (Pred.H) to classifier performance(Pred.C) on the same data set.previous results ?
males are predicted with highprecision (85%) but low recall (79%) and many ofthem are misclassified as women.
In the systemtrained on ground truth, both types of errors aremore balanced with more males classified correctly?
similar precision (84%) but higher recall (86%).6.3 Combining Human and AutomaticPredictionsWe have shown that human perceived labels andautomatic methods capture different information.This information may be leveraged to obtain bet-ter overall predicting performance.
We test this byusing a linear model that combines two features:the human guesses ?
measured as the proportionof guesses for female ?
and classifier prediction?
binary value.
Even this simple method of labelcombination obtains a classification accuracy of87.7%, significantly above majority vote of humanguesses (85.8%) and automatic prediction (82.9%)individually.
This demonstrates that both methodscan complement each other if an increase in accu-racy is needed.
(a) Trained on perceived gender.
Accu-racy = 83.4%Pred.Male FemaleRealMale 37.5% 9.9%Female 6.6% 45.9%(b) Trained on actual gender.
Accuracy= 85.3%Pred.Male FemaleRealMale 40.5% 6.9%Female 7.8% 44.7%Table 2: Normalized confusion matrices for systemcomparison when using perceived or ground truthlabels.7 Textual Differences between Perceivedand Actual TraitsWe have so far demonstrated that differences existbetween the human perception of traits and realtraits.
Further, human errors differ systematicallyfrom a statistical model which generalizes wordoccurrence patterns.
In this section, we directlyidentify the textual cues that bias humans and causethem to mislabel users.In addition to unigram analysis, in order to aidinterpretability of the feature analysis, we groupwords into clusters of semantically similar wordsor topics using a method from (Preot?iuc-Pietro etal., 2015b).
We first obtain word representationsusing the popular skip-gram model with negativesampling introduced by Mikolov et al (2013) andimplemented in the Gensim package (layer size 50,context window 5).
We train this model on a sep-arate reference corpus containing ?
400 milliontweets.
After computing the word vectors, we cre-ate a word?
word semantic similarity matrix usingcosine similarity between the vectors and group thewords into clusters using spectral clustering (Shiand Malik, 2000).
Each word is only assigned toone cluster.
We choose a number of 1,000 topicsbased on preliminary experiments.
Further, we usethe NRC Emotion Lexicon (Mohammad and Tur-ney, 2013) to measure eight emotions (anger, fear,anticipation, trust, surprise, sadness, joy and dis-gust) and two sentiments (negative and positive).
Auser?s score in each of these 10 dimensions is rep-resented as a weighted sum of its words multipliedby their lexicon score.7.1 Gender PerceptionTo study gender perception, we first define a mea-sure of perceived gender expression, calculated asthe fraction of female guesses out of the 9 guessesfor each Twitter user.
We then compute univariatecorrelations the text-derived features and the user848Perceived ?
Female Perceived ?
MaleTopic Perc Real Cont Topic Perc Real Contsuch, loving, pretty, beautiful, gorgeous .416 .348 .176 nation, held, rally, defend, supporters -.372 -.281 -.176bed, couch, blanket, lying, cozy .424 .376 .165 players, teams, crowds, athletes, clubs -.370 -.284 -.171hair, blonde, shave, eyebrows, dye .379 .325 .152 training, team, field, coach, career -.323 -.246 -.148friend, boyfriend, bf, bff, gf .365 .308 .149 heat, game, nba, lakers, playoff -.314 -.237 -.145girl, lucky, she?s, you?re, he?s .378 .336 .143 draft, trade, deadline, stat, retire -.303 -.223 -.143sweet, angel, honey, pumpkin, bunny .365 .322 .138 ref, offensive, foul, defensive, refs -.324 -.255 -.142cleaning, laundry, packing, dishes, washing .350 .307 .133 second, third, grade, century, period -.282 -.195 -.142awake, dream, sleep, asleep, nights .327 .276 .130 former, leader, chief, vice, minister -.316 -.244 -.142cry, heart, smile, deep, whenever .331 .288 .125 private, claim, jail, removed, banned -.299 -.224 -.138cake, christmas, gift, cupcakes, gifts .330 .287 .125 war, action, army, battle, zone -.323 -.263 -.135evening, day, rest, today, sunday .249 .180 .118 security, transition, administration, support -.295 -.225 -.134light, dark, colors, bright, rainbow .244 .178 .114 general, major, impact, signs, conflict -.295 -.227 -.132shopping, home, spend, packed, grocery .326 .301 .111 largest, launches, announces, lands, add -.273 -.196 -.132dreams, live, forget, remember, along .247 .194 .107 guns, planes, riot, weapons, soldiers -.251 -.165 -.131darling, xo, hugs .259 .211 .106 title, tech, stats, division, technical -.314 -.258 -.129brother, mom, daddy, daughter, sister .302 .275 .105 breaking, turns, breaks, falls, puts -.266 -.190 -.128moment, awkward, laugh, excitement, laughter .282 .247 .103 million, billion -.277 -.206 -.128totally, awesome, favorite, love, fave .272 .233 .103 steve, joe, dave, larry, phil -.294 -.236 -.124breakfast, dinner, lunch, cooking, meal .280 .245 .103 football, pitch, blues, derby, lineup -.276 -.211 -.124makeup, glasses, lipstick .264 .223 .102 ceo, warren -.240 -.160 -.123Unigrams Perc Real Cont Unigrams Perc Real Contlove,my,so,!,you,I,her,hair,feel,today, .339 .259 .156 game,the,sports,against,football,teams, -.270 -.236 -.130friends,baby,cute,girls,beautiful,me,heart,??player,fans,report,team,ebola,vs,nba,games,?
?little,shopping,happy,because,wonderful, economy,score,government,ceo,americans,gorgeous,bed,clothes,am,have,yay,your .179 .081 .071 goals,app,penalties,play,shit,political,war -.117 -.062 -.065Emotion Perc Real Cont Emotion Perc Real ContJoy .255 .245 .091 Anger -.156 -.117 -.076Fear -.183 -.145 -.084Table 3: Textual features highlighting errors in human perception of gender compared to ground truthlabels.
Table shows correlation to perceived gender expression (Perc), to ground truth (Real) and toperceived gender expression controlled for ground truth (Cont).
All correlations of gender unigrams,topics and emotions are statistically significant at p < .001 (t-test)Gender ?
High Confidence Gender ?
Low ConfidenceTopic Conf Real Cont Topic Conf Real Contsibling,flirted,married,husband,wife (.028) (.071) .240 wiser,easier,shittier,happier,worse -.277 (.081) -.295fellaz,boyss,dayz,girlz,gurlz,sistas (.118) (.113) .221 agenda,planning,activities,schedule -.285 (.020) -.289brother, mom, daddy, daughter, sister (.127) .241 .214 horoscope,zodiac,gemini,taurus,virgo -.269 (.087) -.288bathroom,wardrobe,toilet,clothes,bath (.017) .220 .212 reshape,enable,innovate,enhance,create -.253 (-.110) -.235looked,winked,smiled,lol?d,yell,stare (.035) (.089) .201 imperfect,emotional,break-down,commit -.227 .024 -.232hair, blonde, shave, eyebrows, dye .163 .182 .199 major,brief,outlined,indicates,wrt -.234 (-.045) -.226pyjama,shirt,coat,hoody,trousers (.077) (-.010) .191 justification,circumstance,boundaries -.224 (-.014) -.221awake, dream, sleep, asleep, nights .160 (.132) .184 experiencing, explanations, expressive -.225 (-.039) -.217totally, awesome, favorite, love, fave (.063) (.135) .
183 inferiority,sufficiently,adequately -.209 (-.015) -.206days,minutes,seconds,years,months (.087) (-.013) .177 specified,negotiable,exploratory,expert -.190 (-.014) -.187baldy,gangster,boy,kid,skater,dude (.071) (.027) .173 multiple,desirable,extensive,increasingly -.199 (-.092) -.183shopping,grocery,ikea,manicure (.052) .204 .173 anticipate,optimist,unrealistic,exceed (.053) (.023) -.182happy,birthdayyyy,happyyyy,bday .180 .222 .172 organisation,communication,corporate -.200 -.148 -.175girl, lucky, she?s, you?re, he?s (.118) (.060) .172 hostile,choppy,chaotic,cautious,neutral -.178 (-.033) -.172worst,happiest,maddest,slowest,funniest .173 (.113) .172 security, transition, administration, supports .185 (-.079) -.170bazillion,shitload,nonstop,spent,aand .162 (.084) .167 diminished,unemployment,rapidly -.181 (-.101) -.163Emotion Conf Real Cont Emotion Conf Real ContJoy .202 .245 .164 ?Anticipation .140 (.086) .124Unigrams Conf Real Cont Unigrams Conf Real ContI,my,this,was,me,so,had,like, .312 .267 .360 more,may,might,although, .290 .081 .310her,night,she,just,hair,gonna,??emotional,your,eager,url,?
?ever,last,shirt, desires,relationship,seem,existing,kid,girls,love (.076) (.047) .160 emotions,surface,practical,source .150 -.014 .180Table 4: Textual features highlighting high and low confidence in human perception of gender.
Table showscorrelation to average self-reported confidence (Conf), to ground truth (Real) and with self-reportedconfidence controlled for ground truth (Cont).
All correlations of gender unigrams, topics and emotionsare statistically significant at p < .001 (t-test), except of the values in brackets.849Perceived ?
Older Perceived ?
YoungerTopic Perc Real Cont Topic Perc Real Contgolf, sport, semi, racing .278 (.085) .226 she?s, youre, hes, lucky, girl, slut -.328 -.243 -.184bill, union, gov, labor, cuts .349 .287 .181 boys, girls, hella, homies, ya?ll -.297 -.236 -.155states, public, towns, area, employees, immigrants .301 .213 .173 dumb, petty, weak, lame, bc, corny -.295 -.232 -.155roger, stanley, captain .232 (.105) .167 miss, doing, chilling, how?s -.305 -.268 -.145available, service, apply, package, customer .279 .197 .160 heart, cry, smile, deep, hug -.258 -.186 -.144serving, prime, serve, served, freeze .215 (.097) .154 friend, bestfriend, boyfriend, bff, bestest -.281 -.254 -.127support, leaders, group, youth, educate .228 .121 .153 ugly, stubborn, bein, rude, childish, greedy -.238 -.182 -.126hillary, clinton, obama, president, scott, ed, sarah .289 .230 .150 bitch, fuck, hoe, dick, slap, suck -.278 -.251 -.125via, daily, press, latest, report, globe .311 .272 .149 kinda, annoying, weird, silly, emo, retarded, random -.242 -.193 -.124diverse, developed, multiple, among, several, highly .266 .195 .147 everyone, everything, nothing, does, anyone, else -.201 -.218 -.118military, terrorist, citizens, iraq, refugees .287 .235 .146 bruh, aye, fam, doin, yoo, dawg -.227 -.178 -.117julia, emma, annie, claire .180 (.056) .145 ever, cutest, worst, weirdest, biggest, happiest -.275 -.264 -.115liberty, pacific, north, eastern, 2020 .260 .198 .139 seriously, crazy, bad, shitty, yikes, insane -.208 -.152 -.114brooklyn, nyc, downtown, philly, hometown .213 .120 .139 whoops, oops, remembered, forgot -.179 (-.104) -.113Unigrams Perc Real Cont Unigrams Perc Real Contgolf, our, end, delay, favourite, low, holes, original, .321 .
(063) .282 me, i, when, like, you, so, dude, don?t, hate, im, u, -.535 -.489 -.294branch, the, of, stanley, our, .
, story, , ,?
?girl, hate, life, my, wanna, literally,?
?forever, exciting, great, what, community, hurricane, r, really, cute, someone, youre, miss, me , want, thisfor, brands, toward, kids, regarding, upcoming .208 (.101) .145 okay, rt, school, snapchat, shit, crying -.256 (-.051) -.117Emotion Perc Real Cont Emotion Perc Real ContPositive .325 .268 .166 Disgust -.177 -.131 -.094Trust .243 .184 .130 Negative -.104 (-.031) -.084Anticipation .212 .176 .102 Sadness -.126 -.072 -.081Anger -.070 (-.009) -.065Table 5: Textual features highlighting errors in human perception of age compared to ground truth labels.Table shows correlation to perceived age expression (Perc), to ground truth (Real) and to perceived ageexpression controlled for ground truth (Cont).
All correlations of age unigrams, topics and emotions arestatistically significant at p < .001 (t-test), except of the values in brackets.Age ?
High Confidence Age ?
Low ConfidenceTopic Conf Real Cont Topic Conf Real Contschool, student, college, teachers, grad, classroom .242 (-.054) .227 mocho, gracias, chicos, corazon, quiero -.195 (-.042) -.207done, homework, finished, essay, procrastinating .251 -.125 .219 sweepstakes, giveaway, enter, retweet, prize (-.044) -.278 -.134math, chem, biology, test, study, physics .227 (-.060) .210 injures, shot, penalty, strikes, cyclist, suffered -.149 .153 -.108cant, can?t, wait, till, believe, afford .226 -.171 .183 final, cup, europa, arsenal, match, league -.135 .107 -.106tomorrow, friday, saturday, date, starts .175 (-.014) .171 juventus, munich, lyon, bayern, 0-1 (-.101) (-.005) -.103invitations, prom, attire, wedding, outfit, gowns .172 (.005) .170 castlevania, angels, eagles, demons, flames -.138 .138 (-.101)soexcited, next, week, weekend, summer, graduation .153 (.009) .155 devil, sword, curse, armor, die, obey (-.081) (-.055) (-.097)aaand, after, before, literally, off, left, gettingold .182 (-.103) .154 football, reds, kickoff, derby, pitch, lineup -.125 .106 (-.096)sleepy, work, shifts, longday, exhausted, nap .126 (.064) .144 anime, invader, shock, madoka, dragonball (-.071) (-.080) (-.095)life, daydream, remember, cherish, eternally, reminiscing .200 -.228 .143 paranormal, dragon, alien, zombie, dead (-.099) (.025) (-.092)happyyyy, birthdaaaay, b-day, bday, belated .187 -.173 .142 earthquake, magniture, aftermath, devastating, victims (-.101) (.040) (-.090)Unigrams Conf Real Cont Unigrams Conf Real Contmy, i?m, can?t, i, school, so, to, class, .375 -.350 .314 rt, his, league, epic (-.023) -.320 -.128semester, college, homework, prom, me, in my,?warriors, !
,?friends, literally, when, exam, nap .180 (.080) .157 vintage -.130 (.071) -.111Emotion Conf Real Cont Emotion Conf Real ContTrust (.077) .184 .134 ?Joy .125 (.009) .128Positive (.031) .268 .115Anticipation (.060) .176 .114Table 6: Textual features highlighting high and low confidence in human perception of age.
Table showscorrelation to average self-reported confidence (Conf), to ground truth (Real) and with self-reportedconfidence controlled for ground truth (Cont).
Correlation values of age unigrams, topics and emotionsstatistically significant at p < .001 (t-test) unless in brackets.labels.
Table 3 displays the features with significantcorrelation to perceived gender expression whencontrolled for real gender using partial correlation,as well as the standalone correlations with the realgender label and perceived gender expression.
Notethat all correlations with both males and femaleshave the same sign for both perceived gender andreal gender.
This highlights that humans are notwrong in using these features to make gender as-sessments.
Rather, these stereotypical associatesare overestimated by humans.By analyzing the topics that are still correlatedwith perception after controlling for ground truthcorrelation, we see that topics related to sports,politics, business and technology are consideredby annotators to be stronger cues for predictingmales than they really are.
Female perception isdominated by topics and words relating to feelings,850shopping, dreaming, housework and beauty.
Foremotions, joy is perceived to be more associated tofemales than the data shows, while users expressingmore anger and fear are significantly more likelyto be perceived as males than the data supports.Our crowdsourcing experiment allowed annota-tors to self-report their confidence in each choice.This gives us the opportunity to measure whichtextual features lead to higher self-reported confi-dence in predicting user traits.
Table 4 shows thetextual features most correlated with self-reportedconfidence of the annotators when controlled forground truth, in order to account for the effect thatoverall confidence is on average higher for groupsof users that are easier to predict (i.e., females incase of gender, younger people in case of age).Annotations are most confident when family re-lationships or other people are mentioned, whichaid them to easily assign a label to a user (e.g.,?husband?).
Other topics leading to high confidenceare related to apparel or beauty.
Also the presenceof joy leads to higher confidence (for predictingfemales based on the previous result).
Low con-fidence is associated with work related topics orastrology as well as to clusters of general adverbsand verbs and tentatively, to a more formal vocab-ulary e.g., ?specified?, ?negotiable?, ?exploratory?.Intriguingly, low confidence in predicting gender isalso related to unigrams like ?emotions?, ?relation-ship?, ?emotional?.7.2 Age PerceptionTable 5 displays the features most correlated withperceived age ?
the average of the 9 annotatorguesses ?
when controlled for real age, and theindividual correlations to perceived and real age.Again, annotators relied on correct stereotypes,but relied on them more heavily than warranted bydata.
The results show that the perception of usersas being older compared to their biological age, isdriven by topics including politics, business andnews events.
Vocabulary contains somewhat longerwords (e.g., ?regarding?, ?upcoming?, ?original?
).Additionally, annotators perceived older users to ex-press more positive emotions, trust and anticipation.This is in accordance with psychology research,which showed that both positive emotion (Matherand Carstensen, 2005) and trust (Poulin and Haase,2015) increase as people get older.The perception of users being younger than theirbiological age is highly correlated with the useof short and colloquial words, and self-references,such as the personal pronoun ?I?.
Remarkably, thenegative sentiment is perceived as more specificof younger users, as well as the negative emotionsof disgust, sadness and anger, the later of which isactually uncorrelated to age.Table 6 displays the features with the highestcorrelation to annotation confidence in predictingage when controlling for the true age, as well asseparate correlations to real and perceived age.
An-notators appear to be more confident in their guesswhen the posts display more joy, positive emotion,trust and anticipation words.
In terms of topics men-tioned, these are more informal, self-referential orrelated to school or college.
Topics leading to lowerconfidence are either about sports or online contestsor are frequently retweets.8 ConclusionsThis is the first study to systematically analyzedifferences between real user traits and traits as per-ceived from text, here Twitter posts.
Overall, par-ticipants were generally accurate in guessing a per-son?s traits supporting earlier research that stereo-typical associations are frequently accurate (Mc-Cauley, 1995).
However, we have demonstratedthat humans use stereotypes which lead to sys-tematic biases by comparing their guesses to pre-dictions from statistical models using the bag-of-words assumption.
While qualitatively different,these predictions were shown to offer complimen-tary information in case of gender, boosting overallaccuracy when used jointly.Our experimental design allowed us to directlytest which textual cues lead to inaccurate assess-ments.
Correlation analysis showed that aspects ofstereotypes associated with errors tended not to becompletely wrong but rather poorly applied.
Anno-tators generally exaggerated the diagnostic utilityof behaviors that they correctly associated withone group or another.
Further, we used the samemethodology to analyze self-reported confidence.Follow-up studies can analyze the perception ofother user traits such as education level, race orpolitical orientation.
Another avenue of future re-search can look at the annotators?
own traits andhow these relate to perception (Flekova et al, 2015).This would allow to uncover demographic or psy-chological traits that influence the ability to makemore accurate judgements.
This is particularly use-ful in offering task requesters a prior over whichannotators are expected to perform tasks better.851AcknowledgmentsThe authors acknowledge the support from Tem-pleton Religion Trust, grant TRT-0048.
The workof the first author was further supported by theGerman Research Foundation under grant No.
GU798/14-1 and the German Federal Ministry of Ed-ucation and Research (BMBF) under the promo-tional reference 01-S12054.
We wish to thank Prof.Iryna Gurevych for supporting the collaboration,the Mechanical Turk annotators for their diligenceand the reviewers for their thoughtful comments.ReferencesDavid Bamman, Jacob Eisenstein, and Tyler Schnoe-belen.
2014.
Gender Identity and Lexical Varia-tion in Social Media.
Journal of Sociolinguistics,18(2):135?160.Joseph Bates.
1994.
The Role of Emotion in Be-lievable Agents.
Communications of the ACM,37(7):122?125.Amy L Baylor and Yanghee Kim.
2004.
PedagogicalAgent Design: The Impact of Agent Realism, Gen-der, Ethnicity, and Instructional Role.
In IntelligentTutoring Systems, volume 3220, pages 592?603.Philip Bramsen, Martha Escobar-Molano, Ami Patel,and Rafael Alonso.
2011.
Extracting Social PowerRelationships from Natural Language.
In Proceed-ings of the 49th Annual Meeting of the Associationfor Computational Linguistics, ACL, pages 773?782.Matthias Braunhofer, Mehdi Elahi, and FrancescoRicci.
2015.
User personality and the new userproblem in a context-aware point of interest recom-mender system.
In Information and CommunicationTechnologies in Tourism, pages 537?549.D.
John Burger, John Henderson, George Kim, andGuido Zarrella.
2011.
Discriminating Gender onTwitter.
In Proceedings of the 2015 Conference onEmpirical Methods in Natural Language Processing,EMNLP, pages 1301?1309.Subhagata Chattopadhyay, Preetisha Kaur, Fethi Rabhi,and Rajendra Acharya.
2011.
An AutomatedSystem to Diagnose the Severity of Adult Depres-sion.
In Second International Conference on Emerg-ing Applications of Information Technology, EAIT,pages 121?124.Glen Coppersmith, Mark Dredze, and Craig Harman.2014.
Quantifying Mental Health Signals in Twitter.In Proceedings of the Workshop on ComputationalLinguistics and Clinical Psychology: From Linguis-tic Signal to Clinical Reality, ACL, pages 51?60.Aron Culotta, Nirmal Kumar Ravi, and Jennifer Cutler.2015.
Predicting the Demographics of Twitter Usersfrom Website Traffic Data.
In Proceedings of the9th International AAAI Conference on Weblogs andSocial Media, ICWSM, pages 72?78.Munmun De Choudhury, Scott Counts, and EricHorvitz.
2013.
Social Media as a MeasurementTool of Depression in Populations.
In Proceedingsof the 5th Annual ACM Web Science Conference,pages 47?56.John F Dovidio, John C Brigham, Blair T Johnson, andSamuel L Gaertner.
1996.
Stereotyping, Prejudice,and Discrimination: Another Look.
Stereotypes andStereotyping, 276:319.Alice H Eagly.
1995.
The Science and Politics ofComparing Women and Men.
American Psycholo-gist, 50(3):145?158.Jacob Eisenstein, Brendan O?Connor, Noah A. Smith,and Eric P. Xing.
2010.
A Latent Variable Modelfor Geographic Lexical Variation.
In Proceedingsof the Conference on Empirical Methods in NaturalLanguage Processing, EMNLP, pages 1277?1287.Lucie Flekova and Iryna Gurevych.
2013.
Can WeHide in the Web?
Large Scale Simultaneous Age andGender Author Profiling in Social Media - Notebookfor PAN at CLEF 2013.
In CLEF 2013 Labs andWorkshops - Online Working Notes.Lucie Flekova, Daniel Preot?iuc-Pietro, Jordan Carpen-ter, Salvatore Giorgi, and Lyle Ungar.
2015.
An-alyzing Crowdsourced Assessment of User Traitsthrough Twitter Posts.
In Third AAAI Conference onHuman Computation and Crowdsourcing, HCOMP.Lucie Flekova, Lyle Ungar, and Daniel Preoctiuc-Pietro.
2016.
Exploring Stylistic Variation withAge and Income on Twitter.
In Proceedings of the54th Annual Meeting of the Association for Compu-tational Linguistics, ACL.Goldine C. Gleser, Louis A. Gottschalk, and WatkinsJohn.
1959.
The Relationship of Sex and Intelli-gence to Choice of Words: A Normative Study ofVerbal Behavior.
Journal of Clinical Psychology,15(2):182?191.Dirk Hovy and Anders S?gaard.
2015.
Tagging Perfor-mance Correlates with Author Age.
In Proceedingsof the 53rd Annual Meeting of the Association forComputational Linguistics, ACL, pages 483?488.Anders Johannsen, Dirk Hovy, and Anders S?gaard.2015.
Cross-lingual Syntactic Variation over Ageand Gender.
In Proceedings of the 19th Conferenceon Computational Language Learning, CONNL,pages 103?112.Oliver P John and Richard W Robins.
1994.
Accu-racy and Bias in Self-Perception: Individual Differ-ences in Self-enhancement and the Role of Narcis-sism.
Journal of Personality and Social Psychology,66(1):206?219.852Leda E. Kanellakos.
2002.
Formal Vocabulary as aStatus Cue: Interactions with Diffuse Status Charac-teristics.David A. Kenny and Linda Albright.
1987.
Accu-racy in Interpersonal Perception: A Social RelationsAnalysis.
Psychological Bulletin, 102(3):390?402.Diane Kobrynowicz and Nyla R Branscombe.
1997.Who Considers themselves Victims of Discrimina-tion?
: Individual Difference Predictors of PerceivedGender Discrimination in Women and Men.
Psy-chology of Women Quarterly, 21(3):347?363.Michal Kosinski, David Stillwell, and Thore Grae-pel.
2013.
Private Traits and Attributes are Pre-dictable from Digital Records of Human Behavior.Proceedings of the National Academy of Sciences,110(15):5802?5805.Vasileios Lampos, Nikolaos Aletras, Daniel Preot?iuc-Pietro, and Trevor Cohn.
2014.
Predicting and Char-acterising User Impact on Twitter.
In Proceedings ofthe 14th Conference of the European Chapter of theAssociation for Computational Linguistics, EACL,pages 405?413.Vasileios Lampos, Nikolaos Aletras, Jens K. Geyti, BinZou, and Ingemar J. Cox.
2016.
Inferring the So-cioeconomic Status of Social Media Users based onBehaviour and Language.
In Proceedings of the38th European Conference on Information Retrieval,ECIR, pages 689?695.A Bryan Loyall and Joseph Bates.
1997.
Personality-rich believable agents that use language.
In FirstInternational Conference on Autonomous Agents,AGENTS, pages 106?113.Marco Lui and Timothy Baldwin.
2012.
Langid.Py:An Off-the-shelf Language Identification Tool.
InProceedings of the ACL 2012 System Demonstra-tions, ACL, pages 25?30.Mara Mather and Laura L Carstensen.
2005.
Ag-ing and Motivated Cognition: The Positivity Effectin Attention and Memory.
Trends in Cognitive Sci-ences, 9(10):496?502.Clark R. McCauley.
1995.
Are Stereotypes Exag-gerated?
A Sampling of Racial, Gender, Academic,Occupational, and Political Stereotypes.
Stereotypeaccuracy: Toward appreciating group differences,pages 215?243.Allen R McConnell and Russell H Fazio.
1996.Women as Men and People: Effects of Gender-marked Language.
Personality and Social Psychol-ogy Bulletin, 22(10).Julie R. McMillan, A. Kay Clifton, Diane McGrath,and Wanda S. Gale.
1977.
Women?s language: Un-certainty or interpersonal sensitivity and emotional-ity?
Sex Roles, 3(6):545?559.Tomas Mikolov, Kai Chen, Greg Corrado, and JeffreyDean.
2013.
Efficient Estimation of Word Represen-tations in Vector Space.
In Proceedings of Workshopat the International Conference on Learning Repre-sentations, ICLR, pages 1?12.Saif M. Mohammad and Peter D. Turney.
2013.Crowdsourcing a Word-Emotion Association Lexi-con.
Computational Intelligence, 29(3):436?465.Anthony Mulac, Lisa B. Studley, and Sheridan Blau.1990.
The Gender-linked Language Effect in Pri-mary and Secondary Students?
Impromptu Essays.Sex Roles, 23(9-10):439?470.Matthew L Newman, Carla J Groom, Lori D Handel-man, and James W Pennebaker.
2008.
Gender Dif-ferences in Language Use: An Analysis of 14,000Text Samples.
Discourse Processes, 45(3):211?236.Dong Nguyen, Rilana Gravel, Dolf Trieschnigg, andTheo Meder.
2013.
?How Old do you Think I am??
;A Study of Language and Age in Twitter.
In Pro-ceedings of the 7th International AAAI Conferenceon Weblogs and Social Media, ICWSM, pages 439?448.Dong-Phuong Nguyen, RB Trieschnigg, AS Do?gru?oz,Rilana Gravel, Mari?et Theune, Theo Meder, andFMG de Jong.
2014.
Why Gender and Age Pre-diction from Tweets is Hard: Lessons from a Crowd-sourcing Experiment.
In Proceedings of the 25thInternational Conference on Computational Linguis-tics, COLING, pages 1950?1961.James W. Pennebaker, Martha E. Francis, and Roger J.Booth.
2001.
Linguistic Inquiry and Word Count.James W. Pennebaker, Matthias R. Mehl, and Kate G.Niederhoffer.
2003.
Psychological Aspects of Nat-ural Language Use: Our Words, our Selves.
AnnualReview of Psychology, 54(1):547?577.Michael Poulin and Claudia Haase.
2015.
Growingto Trust.
Evidence That Trust Increases and SustainsWell-Being Across the Life Span.
Social Psycholog-ical and Personality Science, 6(6):614?621.Daniel Preot?iuc-Pietro, Johannes Eichstaedt, GregoryPark, Maarten Sap, Laura Smith, Victoria Tobolsky,H Andrew Schwartz, and Lyle H Ungar.
2015a.
TheRole of Personality, Age and Gender in Tweetingabout Mental Illnesses.
In Proceedings of the Work-shop on Computational Linguistics and Clinical Psy-chology: From Linguistic Signal to Clinical Reality,NAACL, pages 21?30.Daniel Preot?iuc-Pietro, Vasileios Lampos, and Niko-laos Aletras.
2015b.
An Analysis of the User Oc-cupational Class through Twitter Content.
In Pro-ceedings of the 53rd Annual Meeting of the Associ-ation for Computational Linguistics and the 7th In-ternational Joint Conference on Natural LanguageProcessing, ACL, pages 1754?1764.853Daniel Preot?iuc-Pietro, Svitlana Volkova, VasileiosLampos, Yoram Bachrach, and Nikolaos Aletras.2015c.
Studying User Income through Language,Behaviour and Affect in Social Media.
PLoS ONE,10(9).Daniel Preot?iuc-Pietro, Wei Xu, and Lyle Ungar.
2016.Discovering User Attribute Stylistic Differences viaParaphrasing.
In Proceedings of the Thirtieth AAAIConference on Artificial Intelligence, AAAI, pages3030?3037.Kimberly Quinn and Neil Macrae.
2005.
CategorizingOthers: The Dynamics of Person Construal.
Journalof Personality and Social Psychology, 88(3):467?479.Francisco Rangel, Paolo Rosso, Irina Chugur, MartinPotthast, Martin Trenkmann, Benno Stein, Ben Ver-hoeven, and Walter Daelemans.
2014.
Overviewof the 2nd Author Profiling Task at PAN 2014.
InProceedings of the Conference and Labs of the Eval-uation Forum (Working Notes), CLEF.Francisco Rangel, Paolo Rosso, Martin Potthast, BennoStein, and Walter Daelemans.
2015.
Overview ofthe 3rd Author Profiling Task at PAN 2015.
In Pro-ceedings of the Conference and Labs of the Evalua-tion Forum (Working Notes), CLEF.Delip Rao, David Yarowsky, Abhishek Shreevats, andManaswi Gupta.
2010.
Classifying Latent User At-tributes in Twitter.
In Proceedings of the 2nd In-ternational Workshop on Search and Mining User-generated Contents, SMUC, pages 37?44.Marta Recasens, Cristian Danescu-Niculescu-Mizil,and Dan Jurafsky.
2013.
Linguistic Models for Ana-lyzing and Detecting Biased Language.
In Proceed-ings of the 51st Annual Meeting of the Associationfor Computational Linguistics, pages 1650?1659.Rinat B Rosenberg-Kima, Amy L Baylor, E AshbyPlant, and Celeste E Doerr.
2008.
Interface Agentsas Social Models for Female Students: The Effectsof Agent Visual Presence and Appearance on Fe-male Students?
Attitudes and Beliefs.
Computers inHuman Behavior, 24(6):2741?2756.Sara Rosenthal and Kathleen McKeown.
2011.
AgePrediction in Blogs: A Study of Style, Content, andOnline Behavior in pre- and post-Social Media Gen-erations.
In Proceedings of the 49th Annual Meet-ing of the Association for Computational Linguistics,ACL, pages 763?772.Maarten Sap, Gregory Park, Johannes Eichstaedt, Mar-garet Kern, Lyle Ungar, and H Andrew Schwartz.2014.
Developing Age and Gender Predictive Lex-ica over Social Media.
In Proceedings of the 2014Conference on Empirical Methods in Natural Lan-guage Processing, EMNLP, pages 1146?1151.Jonathan Schler, Moshe Koppel, Shlomo Argamon, andJames W Pennebaker.
2006.
Effects of Age andGender on Blogging.
AAAI Spring Symposium,pages 199?205.H Andrew Schwartz, Johannes C Eichstaedt, Mar-garet L Kern, Lukasz Dziurzynski, Stephanie MRamones, Megha Agrawal, Achal Shah, MichalKosinski, David Stillwell, Martin EP Seligman, andLyle H Ungar.
2013.
Personality, Gender, andAge in the Language of Social Media: The Open-Vocabulary Approach.
PLoS ONE, 8(9).Suranga Seneviratne, Aruna Seneviratne, Prasant Mo-hapatra, and Anirban Mahanti.
2015.
Your InstalledApps Reveal your Gender and More!
ACM SIGMO-BILE Mobile Computing and Communications Re-view, 18(3):55?61.Jianbo Shi and Jitendra Malik.
2000.
Normalized Cutsand Image Segmentation.
Transactions on PatternAnalysis and Machine Intelligence, 22(8):888?905.Patrick E. Shrout and Joseph L. Fleiss.
1979.
Intra-class Correlations: Uses in Assessing Rater Reliabil-ity.
Psychological Bulletin, 86:420?428.Robert Tibshirani.
1996.
Regression Shrinkage andSelection via the Lasso.
Journal of the Royal Sta-tistical Society.
Series B (Methodological), 58:267?288.Svitlana Volkova and Yoram Bachrach.
2015.
On Pre-dicting Sociodemographic Traits and Emotions fromCommunications in Social Networks and Their Im-plications to Online Self-Disclosure.
Cyberpsychol-ogy, Behavior, and Social Networking, 18(12):726?736.Svitlana Volkova and Yoram Bachrach.
2016.
Infer-ring Perceived Demographics from User EmotionalTone and User-Environment Emotional Contrast.
InProceedings of the 54th Annual Meeting of the Asso-ciation for Computational Linguistics, ACL.Svitlana Volkova, Glen Coppersmith, and BenjaminVan Durme.
2014.
Inferring User Political Pref-erences from Streaming Communications.
In Pro-ceedings of the 52nd Annual Meeting of the Asso-ciation for Computational Linguistics, ACL, pages186?196.Svitlana Volkova, Yoram Bachrach, Michael Arm-strong, and Vijay Sharma.
2015.
Inferring LatentUser Properties from Texts Published in Social Me-dia.
In Proceedings of the Twenty-Ninth Confer-ence on Artificial Intelligence (Demo), AAAI, pages4296?4297.Wu Youyou, Michal Kosinski, and David Stillwell.2015.
Computer-based Personality Judgments aremore Accurate than those Made by Humans.
PNAS,112(4):1036?1040.854
