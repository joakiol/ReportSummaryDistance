Proceedings of the 7th Workshop on Statistical Machine Translation, pages 345?348,Montre?al, Canada, June 7-8, 2012. c?2012 Association for Computational LinguisticsPROMT DeepHybrid system for WMT12 shared translation taskAlexander MolchanovPROMT LLC16A, Dobrolubova av.197198, St. Petersburg, RussiaAlexander.Molchanov@promt.ruAbstractThis paper describes the PROMT submissionfor the WMT12 shared translation task.
Weparticipated in two language pairs: English-French and English-Spanish.
The translationswere made using the PROMT DeepHybridengine, which is the first hybrid version of thePROMT system.
We report on improvementsover our baseline RBMT output both in termsof automatic evaluation metrics and linguisticanalysis.1 IntroductionIn this paper we present the PROMT DeepHy-brid submission for WMT12 shared translationtask for two language pairs: English-French andEnglish-Spanish.A common approach to create hybrid machinetranslation (MT) systems on the basis of rule-basedmachine translation (RBMT) systems is to build astatistical phrase-based post-editing (SPE) systemusing state-of-the-art SMT technologies (see Si-mard et al 2007).
An SPE system views the outputof the RBMT system as the source language, andreference human translations as the target lan-guage.
SPE systems are used to correct typicalmistakes of the RBMT output and to adapt RBMTsystems to specific domains.
(Dugast et al 2007)report on good results both in terms of automaticevaluation metrics and human evaluation for theSPE systems based on PORTAGE (Sadat et al2005) and Moses (Koehn et al 2007).
However, anSMT model in fact makes translation output lesspredictable in comparison with RBMT output.
Wepropose a different approach to hybrid MT tech-nology.
We developed and incorporated the SPEcomponent into our translation system (the statisti-cal post-editing data is controlled by the PROMThybrid translation engine).
Besides, we have aninternal language model (LM) component thatscores the generated translation candidates.The remainder of the paper is organized as fol-lows: in section 2 we provide the detailed descrip-tion of our hybrid MT technology.
In section 3 weevaluate the performance of the technology on twolanguage pairs: English-French and English-Spanish.
We gain improvements over the baselineRBMT system in terms of BLEU score on test sets.We also introduce the results of linguistic evalua-tion performed by our experts.
Section 4 summa-rizes the key findings and outlines open issues forfuture work.2 System descriptionThe PROMT DeepHybrid system is based onour RBMT engine.
The baseline system has beenaugmented with several modules for hybrid train-ing and translation.
The training technology is fullyautomated, but each step can be fulfilled and tunedseparately.2.1 Rule-based componentPROMT covers 51 language pairs for 13 differ-ent source languages.
Our system is traditionallyclassified as a ?rule-based?
system.
PROMT usesmorphosyntactic analyzers to analyze the sourcesentence and transfer rules to translate the sentence345into the target language.
The crucial component ofour system is the PROMT bilingual dictionarieswhich contain up to 250K entries for each lan-guage pair.
Each entry is supplied with variouslinguistic (lexical and grammatical, morphological,semantic) features.
Besides the ?baseline?
diction-aries the PROMT system has a large number ofdomain-specific dictionaries.2.2 Parallel corpus processingWe have a specific component for processingparallel corpora before training the hybrid system.This component can process data in plain text andXML formats.
We also perform substantial datafiltering.
All punctuation and special symbols(ligatures etc.)
are normalized.
The length of thewords in a sentence and the length of sentences aretaken into account (sentences having length abovea set threshold are discarded).
All duplicated sen-tences are discarded as well.
On top of that, weremove parallel segments with different number ofsentences because such segments corrupt phrasealignment.
Strings containing few alphabetic sym-bols and untranslated sentences are filtered outfrom the parallel corpus.2.3 Automated dictionary extractionThe extraction technology is shown in figure 1.The whole process can be subdivided into twoseparate tasks: 1) statistical alignment of a parallelcorpus 2) extraction of syntactic phrases from thesource and target sides of the parallel corpus.
Wethen combine the results of these tasks to extractbilingual terminology.
We use GIZA++ to performthe word alignment (Och and Ney, 2003).
Then weuse the common heuristics to extract parallelphrase pairs (Koehn et al 2007).
We use thePROMT parsers to extract grammatically correctphrases from source and target sides of the parallelcorpora.
PROMT parsers are rule-based multi-levelmorphosyntactic analyzers.
Parsers extract nounphrases, verb phrases and adverbial phrases.
Theextraction is done as follows: each sentence of thecorpus is parsed, a parse tree is created, the ex-tracted syntactic phrases are stored in memory;after the whole corpus is processed, all extractedphrases are lemmatized and presented in a list.Each phrase is supplied with a set of linguistic fea-tures (part of speech, lemma, lemma frequencyetc.).
The next step is building a bilingual glossaryusing two sets of syntactic phrases extracted fromthe source and the target sides of the parallel cor-pus on the one hand and a statistically aligned setof phrase pairs on the other hand.
We do not addgeographic names, proper names and named enti-ties (dates etc.)
to the glossary because they arewell processed by the RBMT engine.2.4 Statistical phrase-based post-editingThe technology of obtaining data for statisticalpost-editing is standard.
We translate the sourcecorpus using the RBMT engine.
Then we align theMT corpus and the target corpus using GIZA++and extract parallel phrase pairs to obtain a phrase-table.
Then the phrase-table is filtered.
The phraselength and translation probability are taken intoaccount.
Only pairs having length of the sourcephrase from three to seven words are selected.
Thisspecific length range was chosen according to thedetailed analysis of the resulting hybrid MT qualityperformed by our linguists.
The selected phrasepairs are stored in the special SPE component ofthe hybrid engine and are used to apply post-editing to the translation candidates generated bythe RBMT engine during the translation process.2.5 Language model componentThe language model (LM) component is used toscore the translation candidates generated by theFigure 1.
Dictionary extraction pipeline.346engine.
The RBMT engine can generate severaltranslation candidates depending on the number ofhomonymic words and phrases and transfer rulesvariants.
Statistical phrase-based post-editing isapplied separately to each of the generated candi-dates.
All of the candidates (with and without post-edition) are scored by the LM component and thecandidate with the lowest perplexity one is se-lected.3 Experimental settingWe used the total Europarliament (EP) andNewsCommentary (NC) corpora provided by theorganizers for the English-Spanish submission.
Wetranslated both (EP and NC) corpora using theRBMT engine and then built a single phrase-tablefor both corpora.
Then we filtered the phrase-tableaccording to the source phrase length and transla-Table 2.
Number of entries in the extracted English-French dictionary.tion probabilities as described in section 2.4.
Only10% of the initial phrase-table were used as statis-tical post-editing data.
The target 5-gram languagemodel was trained on all provided monolingualdata except the LDC corpora.
We did not extractthe dictionary for this language pair.As for the English-French submission, we per-formed bilingual training data selection from EPand United Nations (UN) corpora.
We trained thesource and target language models on English andFrench monolingual News corpora respectively.These models were used to score each sentencepair of EP and UN corpora.
Then we selected sen-tence pairs from EP and UN corpora via the geo-metric mean of perplexities of the source and targetsentences.
About 85% of EP (35M words of thesource corpus) and 35% of UN (68M words of thesource corpus) were selected.
Then we translatedthe selected EP and UN subcorpora and the wholeNC corpus with the RBMT engine.
A singlephrase-table was built for all three corpora.
Thephrase-table was fitered with the same parametersas for the English-Spanish submission.
Approxi-mately 8% of the initial phrase-table were used asstatistical post-editing data.
The target 5-gram lan-guage model was trained on all provided monolin-gual data except the LDC corpora.We also performed automated dictionary extrac-tion for the English-French pair.
Examples of theextracted entries can be found in Table 1.
The de-tails about the extracted dictionary can be found inTable 2.
We only extracted verbs, nouns and nounphrases for this shared task.
The translations forextracted verbs and nouns are automatically addedinto the existing PROMT dictionary entries usingour multifunctional dictionary component.
Thuswe increase the number of lexical variants andgenerated translation candidates.
The extractednoun phrases are added to the PROMT dictionaryas new entries.
We only extract ?informative?
en-tries, i.e.
the noun phrases which are absent in thebaseline PROMT dictionary or have an incorrect orinfrequent translation.
It should also be mentionedthat the initial size of the noun phrases glossarywas over 25K entries, but we decided to raise thesource phrase frequency threshold a bit.
Our hy-pothesis was that non-frequent phrases from out-of-domain corpora (EP and UN) would not fit fortranslation of news texts.
20K entries are selected.4 Experimental results and linguisticevaluationIn this section we present the results of our ex-periments on newstest2012.
BLEU scores for dif-ferent system configurations are presented inTable 3.
The percentage of sentences changed bystatistical post-editing compared to baselineRBMT output is presented in Table 4.
We alsoPart of speech nouns noun phrases verbsNumber of entries 1187 19780 215KEY KEY_FRQ TRANSLATION PROB POScomprehensive peace agreement 2427 accord de paix global 0,803049 nautomaker 7 constructeur automobile  0,428571 ncontemplate 452 envisager  0,400443 vTable 1.
Examples of extracted dictionary entries.347provide details of linguistic evaluation performedfor the English-French submission.Table 3.
Translation results in terms of BLEU score fornewstest2012.Language pair ImpactEnglish-French 43%English-Spanish 48%Table 4.
Impact of statistical post-editing onnewstest2012 (percentage of sentences changed by sta-tistical post-editing).Table 5.
Statistics on improvements, degradations andequivalents for the DeepHybrid translation compared tobaseline RBMT output (newstest2012).Our linguists compared 100 random RBMT andDeepHybrid (with extracted dictionary and statisti-cal post-editing) translations for both languagepairs in terms of improvements and degradations.The results presented in Table 5 show that theDeepHybrid engine outperforms the RBMT engineaccording to human evaluation.
Most of the degra-dations are minor grammatical issues (wrong num-ber, disagreement etc.
).5 Conclusions and future workWe presented the PROMT DeepHybrid systemsubmissions for WMT12 shared translation task.We showed improvements both in terms of BLEUscores and human evaluation compared to baselinePROMT RBMT engine.We extracted a dictionary from a corpus of over200M words.
The size of the dictionary (~20K en-tries) is relatively small due to our robust linguisticand statistical data filtering.
However, such filter-ing minimizes the number of possible mistransla-tions and guarantees that the extracted entries areuniversal.
We are planning to add the extracteddata to our baseline English-French dictionary aftermanual check and perform the same experimentsfor other language pairs.As for statistical post-editing, the impact on theRBMT output is quite moderate (less than 50%).This is also due to our approach which includesfiltering out infrequent phrase pairs from statisticalpost-editing data.
We assume that the RBMT out-put is already good enough and therefore does notrequire much statistical post-editing to be applied.It should be mentioned that for the present we onlyuse perplexity to score translation candidates.
Sev-eral other features will be implemented in the nextversion of the hybrid engine.
To avoid grammaticalinconsistency in the hybrid MT output, we areplanning to apply linguistic filters to statisticalpost-editing data.ReferencesL.
Dugast, J. Senellart, and P. Koehn.
2007.
StatisticalPost-Edition on SYSTRAN Rule-Based TranslationSystem.
In Proceedings of the Second Workshop OnStatistical Machine Translation, Prague, Czech Re-public.Koehn Philipp, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran, Rich-ard Zens, Chris Dyer, Ondrej Bojar, Alexandra Con-stantin, and Evan Herbst.
2007.
Moses: Open sourcetoolkit for statistical machine translation.
ACL 2007,demonstration session.
Prague, Czech Republic.Och, Franz Josef and Hermann Ney.
2003.
A SystematicComparison of Various Statistical Alignment Models.Computational Linguistics, Vol.
29(1).
19-51.F.
Sadat, H. Johnson, A. Agbago, G. Foster, R. Kuhn, J.Martin, and A. Tikuisis.
2005.
PORTAGE: A Phrase-Based Machine Translation System.
In Proceedingsof the ACL Workshop on Building and Using Paral-lel Texts, pages 129-132, Ann Arbor, USA.M.
Simard, C. Goutte, and P. Isabelle.
2007.
StatisticalPhrase-Based Post-Editing.
In Human LanguageTechnologies 2007: The Conference of the NorthAmerican Chapter of the Association for Computa-tional Linguistics; Proceedings of the Main Confer-ence, pages 08.515, Rochester, USA.System configuration BLEU(English-French)BLEU(English-Spanish)RBMT (baseline) 24.00 27.26Hybrid (+LM) 24.09 27.26Hybrid (+LM +dictionary) 24.25 -Hybrid (+LM +SPE) - 28.60Hybrid (+LM +dictionary +SPE) 24.80 -LanguagepairImprov Degrad EquivEnglish-French 54 16 30English-Spanish 48 20 32348
