Proceedings of the 6th Workshop on Statistical Machine Translation, pages 284?293,Edinburgh, Scotland, UK, July 30?31, 2011. c?2011 Association for Computational LinguisticsInvestigations on Translation Model Adaptation Using Monolingual DataPatrik Lambert, Holger Schwenk, Christophe Servan and Sadaf Abdul-RaufLIUM, University of Le Mans72085 Le Mans, FranceFirstName.LastName@lium.univ-lemans.frAbstractMost of the freely available parallel data totrain the translation model of a statistical ma-chine translation system comes from very spe-cific sources (European parliament, UnitedNations, etc).
Therefore, there is increasinginterest in methods to perform an adaptationof the translation model.
A popular approachis based on unsupervised training, also calledself-enhancing.
Both only use monolingualdata to adapt the translation model.
In this pa-per we extend the previous work and providenew insight in the existing methods.
We reportresults on the translation between French andEnglish.
Improvements of up to 0.5 BLEUwere observed with respect to a very com-petitive baseline trained on more than 280Mwords of human translated parallel data.1 IntroductionAdaptation of a statistical machine translation sys-tem (SMT) is a topic of increasing interest duringthe last years.
Statistical (n-gram) language modelsare used in many domains and several approaches toadapt such models were proposed in the literature,for instance in the framework of automatic speechrecognition.
Many of these approaches were suc-cessfully used to adapt the language model of anSMT system.
On the other hand, it seems more chal-lenging to adapt the other components of an SMTsystem, namely the translation and reordering mod-els.
In this work we consider the adaptation of thetranslation model of a phrase-based SMT system.While rule-based machine translation rely onrules and linguistic resources built for that purpose,SMT systems can be developed without the need ofany language-specific expertise and are only basedon bilingual sentence-aligned data (?bitexts?)
andlarge monolingual texts.
However, while monolin-gual data are usually available in large amounts andfor a variety of tasks, bilingual texts are a sparse re-source for most language pairs.Current parallel corpora mostly come from onedomain (proceedings of the Canadian or EuropeanParliament, or of the United Nations).
This is prob-lematic when SMT systems trained on such corporaare used for general translations, as the language jar-gon heavily used in these corpora is not appropriatefor everyday life translations or translations in someother domain.
This problem could be attacked by ei-ther searching for more in-domain training data, e.g.by exploring comparable corpora or the WEB, or byadapting the translation model to the task.
In thiswork we consider translation model adaptation with-out using additional bilingual data.
One can dis-tinguish two types of translation model adaptation:first, adding new source words or/and new transla-tions to the model; and second, modifying the prob-abilities of the existing model to better fit the topicof the task.
These two directions are complementaryand could be simultaneously applied.
In this workwe focus on the second type of adaptation.In this work, we focus on statistical phrase-based machine translations systems (PBSMT), butthe methods could be also applied to hierarchicalsystems.
In PBSMT, the translation model is rep-resented by a large list of all known source phrasesand their translations.
Each entry is weighted us-ing several probabilities, e.g.
the popular Moses284system uses phrase translation probabilities in theforward and backward direction, as well as lexicalprobabilities in both directions.
The entries of thephrase-table are automatically extracted from sen-tence aligned parallel data and they are usually quitenoisy.
It is not uncommon to encounter several hun-dreds, or even thousands of possible translations offrequent source phrases.
Many of these automati-cally extracted translations are probably wrong andare never used since their probabilities are (fortu-nately) small in comparison to better translations.Therefore, several approaches were proposed to fil-ter these phrase-tables, reducing considerably theirsize without any loss of the quality, or even achiev-ing improved performance (Johnson et al, 2007).Given these observations, adaptation of the trans-lation model of PBSMT systems could be performedby modifying the probability distribution of the ex-isting phrases without necessarily modifying the en-tries.
The idea is of course to increase the prob-abilities of translations that are appropriate to thetask and to decrease the probabilities of the otherones.
Ideally, we should also add new translations orsource phrase, but this seems to be more challengingwithout any additional parallel data.A common way to modify a statistical model is touse a mixture model and to optimize the coefficientsto the adaptation domain.
This was investigated inthe framework of SMT by several authors, for in-stance for word alignment (Civera and Juan, 2007),for language modeling (Zhao et al, 2004; Koehnand Schroeder, 2007) and to a lesser extent for thetranslation model (Foster and Kuhn, 2007; Chen etal., 2008).
This mixture approach has the advan-tage that only few parameters need to be modified,the mixture coefficients.
On the other hand, manytranslation probabilities are modified at once and itis not possible to selectively modify the probabilitiesof particular phrases.Another direction of research is self-enhancing ofthe translation model.
This was first proposed byUeffing (2006).
The idea is to translate the test data,to filter the translations with help of a confidencescore and to use the most reliable ones to train anadditional small phrase table that is jointly used withthe generic phrase table.
This could be also seen as amixture model with the in-domain component beingbuild on-the-fly for each test set.
In practice, suchan approach is probably only feasible when largeamounts of test data are collected and processed atonce, e.g.
a typical evaluation set up with a test set ofabout 50k words.
This method of self-enhancing thetranslation model seems to be more difficult to applyfor on-line SMT, e.g.
a WEB service, since often thetranslation of some sentences only is requested.
Infollow up work, this approach was refined (Ueffinget al, 2007).
Domain adaptation was also performedsimultaneously for the translation, language and re-ordering model (Chen et al, 2008).A somehow related approach was named lightly-supervised training (Schwenk, 2008).
In that workan SMT system is used to translate large amounts ofmonolingual texts, to filter them and to add them tothe translation model training data.
This approachwas reported to obtain interesting improvementsin the translations quality (Schwenk and Senellart,2009; Bertoldi and Federico, 2009).
In comparisonto self enhancing as proposed by Ueffing (2006),lightly-supervised training does not adapt itself tothe test data, but large amounts of monolingual train-ing data are translated and a completely new modelis built.
This model can be applied to any test data,including a WEB service.In this paper we propose to extend this approachin several ways.
First, we argue that the automatictranslations should not be performed from the sourceto the target language, but in the opposite direction.Second, we propose to use the segmentation ob-tained during translation instead of performing wordalignments with GIZA++ (Och and Ney, 2003) ofthe automatic translations.
Finally, we propose toenrich the vocabulary of the adapted system by de-tecting untranslated words and automatically infer-ring possible translations from the stemmed formand the existing translations in the phrase table.This paper is organized as follows.
In the nextsection we first describe our approach in detail.
Sec-tion 3 describes the considered task, the availableresources and the baseline PBSMT system.
Resultsare summarized in section 4 and the paper concludeswith a discussion and perspectives of this work.2 Architecture of the approachIn this paper we propose to extend in several waysthe translation model adaptation by unsupervised285training as proposed by Schwenk (2008).
In thatpaper the authors propose to first build a PBSMTsystem using all available human translated bi-texts.
This system is then used to translate largeamounts of monolingual data in the source language.These automatic translations are filtered using thesentence-length normalized log score of Moses, i.e.the sum of the log-scores of all feature functions.Putting a threshold on this score, only the most re-liable translations are kept.
This threshold was de-termined experimentally.
The automatic translationswere added to the parallel training data and a newPBSMT model was build, performing the completepipeline of word alignment with GIZA++, phraseextraction and scoring and tuning the system ondevelopment data with MERT.
In Schwenk (2009)significant improvement were obtained by this ap-proach when translating from Arabic to French.2.1 Choice of the translation directionFirst, we argue that it should be better to translatemonolingual data in the opposite translation direc-tion of the system that we want to improve, i.e.
fromthe target into the source language.
When translat-ing large amounts of monolingual data, the systemwill of course produce some wrong translations withrespect to choice of the vocabulary, to word order,to morphology, etc.
If we translate from the sourceto the target language, these wrong translations areadded to the phrase table and may be used in futuretranslations performed by the adapted system.
Whenwe add the automatic translations performed in theopposite direction to the training data, the possiblywrong translations will appear on the source side ofthe entries in the adapted phrase table.
PBSMT sys-tems segment the source sentence according to theavailable entries in the phrase table.
Since the sourcesentence is usually grammatically and semanticallycorrect, with the eventual exception of speech trans-lation, it is unlikely that the wrong entries in thephrase table will be ever used, e.g.
phrases with badword choice or wrong morphology.The question of the choice of the translation di-rection was already raised by Bertoldi and Fed-erico (2009).
However, when data in the sourcelanguage is available they adapt only the translationmodel (TM), while they adapt the TM and the lan-guage model (LM) when data in the target languageis given.
Of course the system with adapted LM ismuch better, but this doesn?t prove that target mono-lingual data are better than source monolingual datafor TM adaptation.
In our paper, we use the same,best, LM for all systems and we adapt the baselinesystem with bitexts synthesized from source or tar-get monolingual data.2.2 Word alignmentIn the work of Schwenk (2008), the filtered auto-matic translation were added to the parallel trainingdata and the full pipeline to build a PBSMT sys-tem was performed again, including word alignmentwith GIZA++.
Word alignment of bitexts of severalhundreds of millions of words is a very time con-suming step.
Therefore we propose to use the seg-mentation into phrases and words obtained implic-itly during the translation of the monolingual datawith the moses toolkit.
These alignments are simplyadded to the previously calculated alignments of thehuman translated bitexts and a new phrase table isbuilt.This new procedure does not only speed-up theoverall processing, but there are also investigationsthat these alignments obtained by decoding are moresuitable to extract phrases than the symmetrizedword alignments produced by GIZA++.
For in-stance, Wuebker et al (2010) proposed to trans-late the training data, using forced alignment anda leave-one-out technique, and to use the inducedalignments to extract phrases.
They have observedimprovements with respect to word alignment ob-tained by GIZA++.
On the other hand, Bertoldi andFederico (2009) adapted an SMT system with au-tomatic translations and trained the translation andreordering models on the word alignment used bymoses.
They reported a very small drop in per-formance with respect to training word alignmentswith GIZA++.
Similar ideas were also used in pivottranslation.
Bertoldi et al (2008) translated from thepivot language to the source language to create par-allel training data for the direct translation.2.3 Treatment of unknown wordsStatistical machine translation systems have sometrouble dealing with morphologically rich lan-guages.
It can happen, in function of the avail-able training data, that translations of words are only286Source language Source language Target languageFrench stemmed form Englishfinies fini finishedefface?s efface?
erasedhawaienne hawaien Hawaiian... ... ...Table 1: Example of translations from French to Englishwhich are automatically extracted from the phrase-tablewith the stemmed form.known in some forms and not in others.
For in-stance, for a user of MT technology it is quite dif-ficult to understand why the system can translatethe French word ?je pense?1, but not ?tu penses?2.There have been attempts in the literature to addressthis problem, for instance by Habash (2008) to dealwith the Arabic language.
It is actually possible toautomatically infer possible translations when trans-lating from a morphologically rich language, to asimpler language.
In our case we use this approachto translate from French to English.Several of the unknown words are actually adjec-tives, nouns or verbs in a particular form that itselfis not known, but the phrase table would contain thetranslation of a different form.
As an example wecan mention the French adjective finies which is inthe female plural form.
After stemming we may beable to find the translation in a dictionary which isautomatically extracted from the phrase-table (seeTable 1).
This idea was already outlined by (Bo-jar and Tamchyna, 2011) to translate from Czech toEnglish.First, we automatically extract a dictionary fromthe phrase table.
This is done, be detecting all 1-to-1entries in the phrase table.
When there are multi-ple entries, all are kept with their lexical translationsprobabilities.
Our dictionary has about 680k uniquesource words with a total of almost 1M translations.source segment les travaux sont finisstemmed les travaux sont finisegment les travaux sont <n translation=?finished||ended?proposed prob=?0.008||0.0001?>finis</n>Table 2: Example of the treatment of an unknown Frenchword and its automatically inferred translation.The detection of unknown words is performed by1I think2you thinkcomparing the n-grams contained in the phrase ta-ble and the source segment in order to detect iden-tical words.
Once the unknown word is selected,we are looking for its stemmed form in the dictio-nary and propose some translations for the unknownword based on lexical score of the phrase table (seeTable 2 for some examples).
The stemmer used isthe snowball stemmer3.
Then the different hypothe-sis are evaluated with the target language model.This kind of processing could be done either be-fore running the Moses decoder, i.e.
using theXML mark-up of Moses, or after decoding by post-processing the untranslated words.
In both cases, weare unable to differentiate the possible translationsof the same source phrase with meaningful transla-tion probabilities, and they won?t be added to thephrase-table, nor put into a context with other wordsthat may trigger their use.Therefore, we propose to use this technique to re-place unknown words during the translation of themonolingual data that we use to adapt the transla-tion model.
By these means, the automatically in-duced translations of previously unknown morpho-logical forms will be put into a context and actuallyappear in the new adapted phrase-table.
The corre-sponding translation probabilities will be those cor-responding to their frequency in the monolingual in-domain data.This procedure has been implemented, but wewere not able to obtain improvements in the BLEUscore.
However, one can ask if automatic metrics,evaluated on a test corpus of limited size, are the bestchoice to judge this technique.
In fact, in our settingwe have observed that less than 0.2% of the wordsin the test set are unknown.
We argue that the abilityto complement the phrase-table with many morpho-logical forms of other wise known words, can onlyimprove the usability of SMT systems.3 Task Description and resourcesIn this paper, we consider the translation of newstexts between French and English, in both direc-tions.
In order to allow comparisons, we used ex-actly the same data as those allowed for the inter-national evaluation organized in the framework ofthe sixth workshop on SMT, to be held in Edinburgh3http://snowball.tartarus.org/287Parallel data Size English/French French/English[M words] Dev Test Dev TestEparl + nc 54 26.20 (0.06) 28.06 (0.2) 26.70 (0.06) 27.41 (0.2)Eparl + nc + crawled1 168 26.84 (0.09) 29.08 (0.1) 27.96 (0.09) 28.20 (0.04)Eparl + nc + crawled2 286 26.95 (0.04) 29.29 (0.03) 28.20 (0.03) 28.57 (0.1)Eparl + nc + un 379 26.57 28.52 - -Eparl + nc + crawled1 + un 514 26.87 28.99 - -Eparl + nc + crawled2 + un 631 26.99 29.26 - -Table 4: Case sensitive BLEU scores as a function of the amount of parallel training data.
(Eparl=Europarl, nc=NewsCommentary, crawled1/2=sub-sampled crawled bitexts, un=sub-sampled United Nations bitexts).Corpus English FrenchBitexts:Europarl 50.5M 54.4MNews Commentary 2.9M 3.3MUnited Nations 344M 393MCrawled (109 bitexts) 667M 794MDevelopment data:newstest2009 65k 73knewstest2010 62k 71kMonolingual data:LDC Gigaword 4.1G 920MCrawled news 2.6G 612MTable 3: Available training data for the translation be-tween French and English for the translation evaluationat WMT?11 (number of words after tokenisation).in July 2011.
Preliminary results of this evaluationare available on the Internet.4 Table 3 summarizesthe available training and development data.
We op-timized our systems on newstest2009 and usednewstest2010 as internal test set.
For both cor-pora, only one reference translations is available.Scoring was performed with NIST?s implementationof the BLEU score (?mt-eval?
version 13).3.1 Baseline systemThe baseline system is a standard phrase-based SMTsystem based on the the Moses SMT toolkit (Koehnet al, 2007).
It uses fourteen features functionsfor translation, namely phrase and lexical translationprobabilities in both directions, seven features forthe lexicalized distortion model, a word and a phrasepenalty, and a target language model.
It is con-4http://matrix.statmt.orgstructed as follows.
First, word alignments in bothdirections are calculated.
We used a multi-threadedversion of the GIZA++ tool (Gao and Vogel, 2008).Phrases and lexical reorderings are extracted usingthe default settings of the Moses toolkit.
All the bi-texts were concatenated.
The parameters of Mosesare tuned on the development data using the MERTtool.
For most of the runs, we performed three op-timizations using different starting points and reportaverage results.
English and French texts were to-kenised using a modified version of the tools of theMoses suite.
Punctuation and case were preserved.The language models were trained on all the avail-able data, i.e.
the target side of the bitexts, the wholeGigaword corpus and the crawled monolingual data.We build 4-gram back-off LMs with the SRI LMtoolkit using Modified Kneser-Ney and no cut-offon all the n-grams.
Past experience has shown thatkeeping all n-grams slightly improves the perfor-mance although this produces quite huge models(10G and 30G of disk space for French and Englishrespectively).Table 4 gives the baseline results using variousamounts of bitexts.
Starting with the Europarl andthe News Commentary corpora, various amounts ofhuman translated data were added.
The organizersof the evaluation provide the so called 109 French-English parallel corpus which contains almost 800million words of data crawled from Canadian andEuropean Internet pages.
Following works from the2010 WMT evaluation (Lambert et al, 2010), wefiltered this data using IBM-1 probabilities and lan-guage model scores to keep only the most reliabletranslations.
Two subsets were built with 115M and232M English words respectively (using two differ-288alignment Dev TestBLEU BLEU TERgiza 27.34 (0.01) 29.80 (0.06) 55.34 (0.06)reused giza 27.40 (0.05) 29.82 (0.10) 55.30 (0.02)reused moses 27.42 (0.02) 29.77 (0.06) 55.27 (0.03)Table 5: Results for systems trained via different word alignment configurations.
The values are the average over3 MERT runs performed with different seeds.
The numbers in parentheses are the standard deviation of these threevalues.
Translation was performed from English to French, adding 45M words of automatic translations (translatedfrom French to English) to the baseline system ?eparl+nc+crawled2?.ent settings of the filter thresholds).
They are re-ferred to as ?crawled1?
and ?crawled2?
respectively.Adding this data improved the BLEU score of al-most 1 BLEU point (28.30 ?
29.27).
This is ourbaseline system to be improved by translation modeladaptation.
Using the UN data gave no significantimprovement despite its huge size.
This is probablya typical example that it is not necessarily useful touse all available parallel training data, in particularwhen a very specific (out-of domain) jargon is used.Consequently, the UN data was not used in the sub-sequent experiments.We were mainly working on the translation fromEnglish to French.
Therefore only one baseline sys-tem was build for the reverse translation direction.4 Experimental EvaluationThe system trained on Europarl, News Commen-tary and the sub-sampled version of the 109 bitexts(?eparl+nc+crawled2?, in the third line of Table 3),was used to translate parts of the crawled news inFrench and English.
Statistics on the translated dataare given in Table 6.We focused on the most recent data since thetime period of our development and test data wasend of 2008 and 2009 respectively.
In the futurewe will translate all the available monolingual dataand make it available to the community in order toease the widespread use of this kind of translationmodel adaptation methods.
These automatic trans-lations were filtered using the sentence normalizedlog-score of the decoder, as proposed by (Schwenk,2008).
However, we did not perform systematic ex-periments to find the optimal threshold on this score,but simply used a value which seems to be a goodcompromise of quality and quantity of the transla-tions.
This gave us about 45M English words ofCorpus French (fe) English (ef)available filtered available filtered2009 92 31 121 452010 43 12 112 492011 8 2 15 6total 219 45 177 100Table 6: Monolingual data used to adapt the systems,given in millions of English words.
Under ?French (fe)?,we indicated the number of translated English wordsfrom French, and under ?English (ef)?
we reported thenumber of source English words translated into French.Thus ?fe?
and ?ef?
refer respectively to French?Englishand English?French translation direction of monolingualdata.
In the experiments we used the 100M English?French (ef) filtered monolingual data, as well as a 45M-word subset (in order to have the same amount of data asfor French?English) and a 65M-word subset.automatic translations from French, as well as thetranslations into French of 100M English words, tobe used to adapt the baseline systems.4.1 Word alignmentIn order to build a phrase table with the translateddata, we re-used the word alignment obtained dur-ing the translation with the moses toolkit.
We com-pared the system trained via these alignments tothe systems built by running GIZA++ on all thedata.
When word alignments of the baseline corpus(not adapted) are trained together with the translateddata, they could be affected by phrase pairs com-ing from incorrect translations.
To measure this ef-fect, we trained an additional system, for which thealignments of the baseline corpus are those trainedwithout the translated data.
For the translated data,we re-use the GIZA++ alignments trained on all thedata.
Results for these three alignment configura-289baseline translated bitexts Dev TestBLEU BLEU TEREparl + nc - 26.20 (0.06) 28.06 (0.22) 56.85 (0.09)news fe 45M 27.18 (0.09) 29.03 (0.07) 55.97 (0.07)news ef 45M 26.15 (0.04) 28.44 (0.09) 56.56 (0.11)Eparl + nc + crawled2 - 26.95 (0.04) 29.29 (0.03) 55.77 (0.19)news fe 45M 27.42 (0.02) 29.77 (0.06) 55.27 (0.03)news ef 45M 26.75 (0.04) 28.88 (0.10) 56.06 (0.05)Table 7: Translation results of the English?French systems augmented with a bitext obtained by translating news datafrom English to French (ef) and French to English (fe).
45M refers to the number of English running words.baseline translated bitexts Dev TestBLEU BLEU TEREparl + nc - 26.70 (0.06) 27.41 (0.24) 55.07 (0.17)news fe 45M 27.47 (0.08) 27.77 (0.23) 54.84 (0.13)news ef 45M 27.55 (0.05) 28.51 (0.10) 54.12 (0.09)news ef 65M 27.58 (0.03) 28.70 (0.09) 54.06 (0.17)news ef 100M 27.63 (0.06) 28.68 (0.06) 54.02 (0.06)Eparl + nc + crawled2 - 28.20 (0.03) 28.54 (0.12) 54.17 (0.15)news fe 45M 28.02 (0.11) 28.40 (0.10) 54.45 (0.06)news ef 45M 28.24 (0.06) 28.93 (0.22) 53.90 (0.08)news ef 65M 28.16 (0.19) 28.75 (0.06) 54.03 (0.14)news ef 100M 28.28 (0.09) 28.96 (0.03) 53.79 (0.09)Table 8: Translation results of the French?English systems augmented with a bitext obtained by translating news datafrom English to French (ef) and French to English (fe).
45M/65M/100M refers to the number of English runningwords.tions are presented in Table 5.
In these systemsFrench sources and English translations (45 mil-lion words) were added to the ?eparl+nc+crawled2?baseline corpus.
According to BLEU and TER met-rics, reusing Moses alignments to build the adaptedphrase table has no significant impact on the systemperformance.
We repeated the experiment withoutthe 109 corpus and with the smaller selection of 109(crawled1) and arrived to the same conclusion.However, the re-use of Moses alignments saves timeand resources.
On the larger baseline corpus, themGiza process lasted 46 hours with two jobs of 4thread running and a machine with two Intel X5650quad-core processors.4.2 Choice of the translation directionA second point under study in this work is the effectof the translation direction of the monolingual dataused to adapt the translation model.
Tables 7 and8 present results for, respectively, English?Frenchand French?English systems adapted with news datatranslated from English to French (ef) and Frenchto English (fe).
The experiment was repeated withtwo baseline corpora.
The results show clearlythat target to source translated data are more use-ful than source to target translated data.
The im-provement in terms of BLEU score due to the use oftarget-to-source translated data instead of source-to-target translated data ranges from 0.5 to 0.9 for theFrench?English and English?French systems.
Forinstance, when translating from English to French(Table 7), the baseline system ?eparl+nc?
achievesa BLEU score of 28.06 on the test set.
This couldbe improved to 29.03 using automatic translationsin the reverse direction (French to English), whilewe only achieve a BLEU score of 28.44 when us-ing automatic translation performed in the same di-rection as the system to be adapted.
The effect iseven clearer when we try to adapt the large system290?eparl+nc+crawled2?.
Adding automatic transla-tions translated from English-to-French did actuallylead to a lower BLEU score (29.29 ?
28.88) whilewe observe an improvement of nearly 0.5 BLEU inthe other case.With target-to-source translated news data,the gain with respect to the baseline corpusfor English-French systems (Table 7) is nearly1 BLEU for ?Eparl+nc?
and 0.5 BLEU for?Eparl+nc+crawled2?.
With the same amountof translated data (45 million English words),approximately the same gains are observed inFrench?English systems.
Due to the larger avail-ability of English news data, we were able to uselarger sets of target-to-source translated data forFrench-English systems, as can be seen in Table 8.With a bitext containing additionally 20 millionEnglish words, we get a further improvement of0.2 BLEU for ?Eparl+nc?
(28.51 ?
28.70), but noimprovement for ?Eparl+nc+crawled2?
(the BLEUscore is even lower, but the scores lie within theerror interval).
No further gain on the test data isachieved if we add again 35 million English words(total of 100M words) to the system ?Eparl+nc?.With the ?Eparl+nc+crawle2?
baseline, no sig-nificant improvement is observed if we adapt thesystem with 100M words instead of only 45M.4.3 Result analysisTo get more insight into what happens to the modelwhen we add the automatic translations, we cal-culated some statistics of the phrase table, pre-sented in Table 9.
Namely, we calculated thenumber of entries in the phrase table, the aver-age number of translation options of each sourcephrase, the average entropy for each source phrase,the average source phrase length (in words) andthe average target phrase length.
The entropy iscalculated over the probabilities of all translationoptions for each source phrase.
Comparing thebaseline with ?Eparl+nc?
and the baseline with?Eparl+nc+crawl2?, we can observe that the aver-age number of translation options was nearly mul-tiplied by 3 with the addition of 230 million wordsof human translated bitexts.
As a consequence theaverage entropy was increased from 1.84 to 2.08.On the contrary, adding 100 million words of in-domain automatic translations, the average num-ber of translation options increased by only 5%for the ?Eparl+nc?
baseline, and decreased for the?Eparl+nc+crawl2?
baseline.
A decrease may occurif new source phrases with less translation optionsthan the average are added.
Furthermore, with theaddition of 45 million words of in-domain data, theaverage entropy dropped from 1.84 to 1.33 or 1.60for the ?Eparl+nc?
baseline, and from 2.08 to 1.81 or1.96 for the ?Eparl+nc+crawl2?
baseline.
With bothbaselines, the more translations are added to the sys-tem, the lower the entropy, although in some casethe number of translation options increases (this isthe case when we pass from 65M to 100M wordsof synthetic data).
These results illustrate the factthat the automatic translations only reinforce someprobabilities in the model, with the subsequent de-crease in entropy, while human translations add newvocabulary.
Note also that in the corpus using au-tomatic translations, new words can only occur inthe source side.
Thus when translating from Frenchto English, automatic translations from English toFrench are expected to yield more translation op-tions and a higher entropy than the automatic trans-lations from French to English.
This is what is ef-fectively observed in Table 9.5 ConclusionUnsupervised training is widely used in other ar-eas, in particular large vocabulary speech recogni-tion.
The statistical models in speech recognitionuse a generative approach based on small units, usu-ally triphones.
Each triphone is modeled by a hid-den Markov model and Gaussian mixture probabil-ity distributions (plus many improvements like pa-rameter tying etc).
Many methods were developedto adapt such models.
The corresponding modelin statistical machine translation is the phrase table,a long list of known words with their translationsand probabilities.
It seems much more challengingto adapt this kind of statistical model with unsuper-vised training, i.e.
monolingual data.
Nevertheless,we believe that unsupervised training can be alsovery useful in SMT.
To the best of our knowledge,work in this area is very recent and only in its begin-nings.
This paper tries to give additional insights inthis promising method.Our work is based on the approach initially pro-291baseline translated bitexts entries (M) translations entropy src size trg sizeEparl + nc - 7.16 83.83 1.84 1.80 2.81news fe 45M 7.42 70.00 1.33 1.83 2.80news ef 45M 8.24 81.58 1.60 1.86 2.79news ef 65M 8.42 81.58 1.55 1.88 2.79news ef 100M 9.21 85.93 1.54 1.90 2.79Eparl + nc + crawl2 - 25.42 235.16 2.08 1.76 2.93news fe 45M 25.54 217.21 1.81 1.77 2.93news ef 45M 26.09 228.07 1.96 1.78 2.93news ef 65M 26.21 226.45 1.91 1.78 2.93news ef 100M 26.79 227.08 1.89 1.79 2.93Table 9: Phrase table statistics for French?English systems augmented with bitexts built via automatic translations.Only the entries useful to translate the development set were present in the considered phrase table.posed in (Schwenk, 2008): build a first SMT sys-tem, use it to translate large amounts of monolingualdata, filter the obtained translations, add them to thebitexts and build a new system from scratch.We proposed several extensions to this techniquewhich seem to improve the translations quality inour experiments.
First of all, we have observed thatit is clearly better to add automatically translatedtexts to the translations model training data whichwere translated from the target to the source lan-guage.
This seems to ensure that potentially wrongtranslations are not used in the new model.Second, we were able to skip the process of per-forming word alignment of this additional paralleldata without any significant loss in the BLEU score.Performing word alignments with GIZA++ can eas-ily take several days when several hundred millionsof bitexts are available.
Instead, we directly used theword alignments produced by Moses when translat-ing the monolingual data.
This resulted in an appre-ciable speed-up of the procedure, but has also inter-esting theoretical aspects.
Reusing the word align-ment from the translation process is expected to re-sult in a phrase extraction process that is more con-sistent with the use of the phrases.Finally, we outlined a method to automaticallyadd new translations without any additional paralleltraining data.
In fact, when translating from a mor-phologically rich language to an easier one, in ourcase from French to English, it is often possible toinfer the translations of unobserved morphologicalforms of nouns, verbs or adjectives.
This is obtainedby looking up the stemmed form in an automati-cally constructed dictionary.
This kind of approachcould be also applied to a classical PBSMT system,by adding various forms to the phrase table, but itis not obvious to come up with reasonable transla-tions probabilities for these new entries.
In our ap-proach, the unknown word forms are processed inlarge amounts of monolingual data and the inducedtranslations will appear in the context of completesentences.
Wrong translations can be blocked by thelanguage model and the new translations can appearin phrases of various lengths.This paper provided a detailed experimental eval-uation of these methods.
We considered the trans-lation between French and English using the samedata than was made available for the 2011 WMTevaluation.
Improvement of up to 0.5 BLEU wereobserved with respect to an already competitive sys-tem trained on more than 280M words of humantranslated parallel data.AcknowledgmentsThis work has been partially funded by the FrenchGovernment under the project COSMAT (ANRANR-09-CORD-004.)
and the European Commis-sion under the project EUROMATRIXPLUS (ICT-2007.2.2-FP7-231720).292ReferencesNicola Bertoldi and Marcello Federico.
2009.
Domainadaptation for statistical machine translation.
In ForthWorkshop on SMT, pages 182?189.Nicola Bertoldi, Madalina Barbaiani, Marcello Federico,and Roldano Cattoni.
2008.
Phrase-based statisticalmachine translation with pivot languages.
In IWSLT,pages 143?149.Ondr?ej Bojar and Ales?
Tamchyna.
2011.
Forms Wanted:Training SMT on Monolingual Data.
Abstract atMachine Translation and Morphologically-Rich Lan-guages.
Research Workshop of the Israel ScienceFoundation University of Haifa, Israel, January.Boxing Chen, Min Zhang, Aiti Aw, and Haizhou Li.2008.
Exploiting n-best hypotheses for SMT self-enhancement.
In ACL, pages 157?160.Jorge Civera and Alfons Juan.
2007.
Domain adaptationin statistical machine translation with mixture mod-elling.
In Second Workshop on SMT, pages 177?180,June.George Foster and Roland Kuhn.
2007.
Mixture-modeladaptation for SMT.
In EMNLP, pages 128?135.Qin Gao and Stephan Vogel.
2008.
Parallel implemen-tations of word alignment tool.
In Software Engi-neering, Testing, and Quality Assurance for NaturalLanguage Processing, pages 49?57, Columbus, Ohio,June.
Association for Computational Linguistics.Nizar Habash.
2008.
Four techniques for online handlingof out-of-vocabulary words in arabic-english statisticalmachine translation.
In ACL 08.Howard Johnson, Joel Martin, George Foster, and RolandKuhn.
2007.
Improving translation quality by dis-carding most of the phrasetable.
In EMNLP, pages967?975, Prague, Czech Republic.Philipp Koehn and Josh Schroeder.
2007.
Experiments indomain adaptation for statistical machine translation.In Second Workshop on SMT, pages 224?227, June.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran, RichardZens, Chris Dyer, Ondrej Bojar, Alexandra Con-stantin, and Evan Herbst.
2007.
Moses: Open sourcetoolkit for statistical machine translation.
In ACL,demonstration session.Patrik Lambert, Sadaf Abdul-Rauf, and Holger Schwenk.2010.
LIUM SMT machine translation system forWMT 2010.
In Workshop on SMT, pages 121?126.Franz Josef Och and Hermann Ney.
2003.
A systematiccomparison of various statistical alignement models.Computational Linguistics, 29(1):19?51.Holger Schwenk and Jean Senellart.
2009.
Translationmodel adaptation for an Arabic/French news trans-lation system by lightly-supervised training.
In MTSummit.Holger Schwenk.
2008.
Investigations on large-scale lightly-supervised training for statistical machinetranslation.
In IWSLT, pages 182?189.Nicola Ueffing, Gholamreza Haffari, and Anoop Sarkar.2007.
Transductive learning for statistical machinetranslation.
In ACL, pages 25?32.Nicola Ueffing.
2006.
Using monolingual source-language data to improve MT performance.
In IWSLT,pages 174?181.Joern Wuebker, Arne Mauser, and Hermann Ney.
2010.Training phrase translation models with leaving-one-out.
In ACL, pages 475?484, Uppsala, Sweden, July.Association for Computational Linguistics.Bing Zhao, Matthias Eck, and Stephan Vogel.
2004.Language model adaptation for statistical machinetranslation with structured query models.
In Coling.293
