Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 24?29,Seattle, Washington, USA, 18-21 October 2013. c?2013 Association for Computational LinguisticsCombining Generative and Discriminative Model Scores for DistantSupervisionBenjamin Roth, Dietrich KlakowSaarland UniversitySpoken Language SystemsSaarbru?cken, Germany{benjamin.roth|dietrich.klakow}@lsv.uni-saarland.deAbstractDistant supervision is a scheme to generatenoisy training data for relation extraction byaligning entities of a knowledge base withtext.
In this work we combine the output ofa discriminative at-least-one learner with thatof a generative hierarchical topic model to re-duce the noise in distant supervision data.
Thecombination significantly increases the rank-ing quality of extracted facts and achievesstate-of-the-art extraction performance in anend-to-end setting.
A simple linear interpo-lation of the model scores performs betterthan a parameter-free scheme based on non-dominated sorting.1 IntroductionRelation extraction is the task of finding relationalfacts in unstructured text and putting them into astructured (tabularized) knowledge base.
Trainingmachine learning algorithms for relation extractionrequires training data.
If the set of relations is pre-specified, the training data needs to be labeled withthose relations.Manual annotation of training data is laboriousand costly, however, the knowledge base may al-ready partially be filled with instances from the rela-tions.
This is utilized by a scheme known as distantsupervision (DS) (Mintz et al 2009): text is au-tomatically labeled by aligning (matching) pairs ofentities that are contained in a knowledge base withtheir textual occurrences.
Whenever such a match isencountered, the surrounding context (sentence) isassumed to express the relation.This assumption, however, can fail.Consider the example given in (Taka-matsu et al 2012): If the tupleplace_of_birth(Michael Jackson, Gary)is contained in the knowledge base, one matchingcontext could be:Michael Jackson was born in Gary ...And another possible context:Michael Jackson moved from Gary ...Clearly, only the first context indeed expresses therelation and should be labeled accordingly.Three basic approaches have been proposed todeal with noisy distant supervision instances: Thediscriminative at-least-one approach (Riedel et al2010), that requires that at least one of the matchesfor a relation-entity tuple indeed expresses therelation; The generative approach (Alfonseca etal., 2012) that separates relation-specific distribu-tions from noise distributions by using hierarchicaltopic models; And the pattern correlation approach(Takamatsu et al 2012) that assumes that contextswhich match argument pairs have a high overlap inargument pairs with other patterns expressing the re-lation.In this work we combine 1) a discriminative at-least-one learner, that requires high scores for botha dedicated noise label and the matched relation, and2) a generative topic model that uses a feature-basedrepresentation to separate relation-specific patternsfrom background or pair-specific noise.
We scoresurface patterns and show that combining the twoapproaches results in a better ranking quality of re-lational facts.
In an end-to-end evaluation we set athreshold on the pattern scores and apply the pat-24Figure 1: Hierarchical topic models.
Intertext model(left) and feature model (right).terns in a TAC KBP-style evaluation.
Althoughthe surface patterns are very simple (only strings oftokens), they achieve state-of-the-art extraction re-sults.2 Related Work2.1 At-Least-One ModelsThe original form of distant supervision (Mintz etal., 2009) assumes all sentences containing an entitypair to be potential patterns for the relation holdingbetween the entities.
A variety of models relax thisassumption and only presume that at least one of theentity pair occurrences is a textual manifestation ofthe relation.
The first proposed model with an at-least-one learner is that of Riedel et al(2010) andYao et al(2010).
It consists of a factor graph thatincludes binary variables for contexts, and groupscontexts together for each entity pair.
MultiR (Hoff-mann et al 2011) can be viewed as a multi-labelextension of (Riedel et al 2010).
A further exten-sion is MIMLRE (Surdeanu et al 2012), a jointlytrained two-stage classification model.2.2 Hierarchical Topic ModelThe hierarchical topic model (HierTopics) by Alfon-seca et al(2012) models the distant supervision databy a generative model.
For each corpus match of anentity pair in the knowledge base, the correspondingsurface pattern is assumed to be typical for either theentity pair, the relation, or neither.
This principle isthen used to infer distributions over patterns of oneof the following types:1.
For every entity pair, a pair-specific distribu-tion.2.
For every relation, a relation-specific distribu-tion.3.
A general background distribution.The generative process assumes that for each ar-gument pair in the knowledge base, all patternsare generated by first choosing a hidden variable zwhich can take on three values,B for background,Rfor relation and P for pair.
Corresponding vocabu-lary distributions (?bg, ?rel, ?pair) for generating thecontext patterns are chosen according to the value ofz.
The Dirichlet-smoothed vocabulary distributionsare shared on the respective levels.
Figure 1 showsthe plate diagram of the HierTopics model.3 Model Extensions and Combination3.1 Generative ModelWe use a feature-based extension (Roth and Klakow,2013) of Alfonseca et al(2012) to include bigramsfor a more fine-grained representation of the pat-terns.
For including features in the model, the modelis extended with a second layer of hidden variables.A variable x represents a choice of B,R or P forevery pattern, i.e.
there is one variable x for everypattern.
Each feature is generated conditioned ona second variable z ?
{B,R, P}, i.e.
there are asmany variables z for a pattern as there are featuresfor it.
First, the hidden variable x is generated, thenall z variables are generated for the correspondingfeatures (see Figure 1).
The values B,R or P of zdepend on the corresponding x by a transition distri-bution:P (Zi = z|Xj(i) = x) ={psame, if z = x1?psame2 , otherwisewhere features at indices i are mapped to the corre-sponding pattern indices by a function j(i); psameis set to .99 to enforce the correspondence betweenpattern and feature topics.
13.2 Discriminative ModelAs a second feature-based model, we employ a per-ceptron model that enforces constraints on the labelsfor patterns (Roth and Klakow, 2013).
The modelconsists of log-linear factors for the set of relations1The hyper-parameters used for the feature-based topicmodel are ?
= (1, 1, 1) and ?
= (.1, .001, .001).25Algorithm 1 At-Least-One Perceptron Training?
?
0for r ?
R dofor pair ?
kb pairs(r) dofor s ?
sentences(pair) dofor r?
?
R \ r doif P (r|s, ?)
?
P (r?|s, ?)
then?
?
?
+ ?
(s, r)?
?
(s, r?
)if P (NIL|s, ?)
?
P (r?|s, ?)
then?
?
?
+ ?(s,NIL)?
?
(s, r?
)if ?s?sentences(pair) : P (r|s, ?)
?
P (NIL|s, ?)
thens?
= argmaxsP (r|s,?
)P (NIL|s,?)?
?
?
+ ?
(s?, r)?
?
(s?, NIL)R as well as a factor for the NIL label (no relation).Probabilities for a relation r given a sentence pat-tern s are calculated by normalizing over log-linearfactors defined as fr(s) = exp (?i ?i(s, r)?i), with?
(s, r) the feature vector for sentence s and labelassignment r, and ?r the feature weight vector.The learner is directed by the following se-mantics: First, for a sentence s that has a distantsupervision match for relation r, relation r shouldhave a higher probability than any other relationr?
?
R \ r. As extractions are expected to benoisy, high probabilities for NIL are enforcedby a second constraint: NIL must have a higherprobability than any relation r?
?
R \ r. Third, atleast one DS sentence for an argument pair is ex-pected to express the corresponding relation r. Forsentences s for an entity pair belonging to relationr, this can be written as the following constraints:?s,r?
: P (r|s) > P (r?|s) ?
P (NIL|s) > P (r?|s)?s : P (r|s) > P (NIL|s)The violation of any of the above constraintstriggers a perceptron update.
The basic algorithm issketched in Algorithm 1.23.3 Model CombinationThe per-pattern probabilities P (r|pat) are calcu-lated as in Alfonseca et al(2012) and aggregatedover all pattern occurrences: For the topic model,the number of times the relation-specific topic hasbeen sampled for a pattern is divided by n(pat), thenumber of times the same pattern has been observed.Analogously for the perceptron, the number of timesa pattern co-occurs with entity pairs for r is multi-plied by the perceptron score and divided by n(pat).2The weight vectors are averaged over 20 iterations.Figure 2: Score combination by non-dominated sorting:Circles indicate patterns on the Pareto-frontier, which areranked highest.
They are followed by the triangles, thesquare indicates the lowest ranked pattern in this exam-ple.For the patterns of the form [ARG1] context[ARG2], we compute the following scores:?
Maximum Likelihood (MLE):n(pat,r)n(pat)?
Topic Model:n(pat,topic(r))n(pat)?
Perceptron:n(pat,r)n(pat) ?P (r|s,?
)P (r|s,?
)+P (NIL|s,?)?
Interpolation:0.5?n(pat,topic(r))n(pat) +0.5?n(pat,r)?P (r|s,?)n(pat)?
(P (r|s,?
)+P (NIL|s,?
))The topic model and perceptron approaches arebased on plausible yet fundamentally different prin-ciples of modeling noise without direct supervision.It is therefore an interesting question how comple-mentary the models are and how much can be gainedfrom a combination.
As the two models do not usedirect supervision, we also avoid tuning parametersfor their combination.We use two schemes to obtain a combined rank-ing from the two model scores: The first is a rank-ing based on non-dominated sorting by successivelycomputing the Pareto-frontier of the 2-dimensionalscore vectors (Borzsony et al 2001; Godfrey etal., 2007).
The underlying principle is that all datapoints (patterns in our case) that are not dominatedby another point3 build the frontier and are rankedhighest (see Figure 2), with ties broken by linear3A data point h1 dominates a data point h2 if h1 ?
h2 in allmetrics and h1 > h2 in at least one metric.26combination.
Sorting by computing the Pareto-frontier has been applied to training machine transla-tion systems (Duh et al 2012) to combine the trans-lation quality metrics BLEU, RIBES and NTER,each of which is based on different principles.
In thecontext of machine translation it has been found tooutperform a linear interpolation of the metrics andto be more stable to non-smooth metrics and non-comparable scalings.
We compare non-dominatedsorting with a simple linear interpolation with uni-form weights.4 Evaluation4.1 Ranking-Based EvaluationEvaluation is done on the ranking quality accordingto TAC KBP gold annotations (Ji et al 2010) of ex-tracted facts from all TAC KBP queries from 2009-2011 and the TAC KBP 2009-2011 corpora.
First,candidate sentences are retrieved in which the queryentity and a second entity with the appropriate typeare contained.
Candidate sentences are then usedto provide answer candidates if one of the extractedpatterns matches.
The answer candidates are rankedaccording to the score of the matching pattern.The basis for pattern extraction is the noisy DStraining data of a top-3 ranked system in TAC KBP2012 (Roth et al 2012).
The retrieval componentof this system is used to obtain sentence and an-swer candidates (ranked according to their respec-tive pattern scores).
Evaluation results are reportedas averages over per-relation results of the standardranking metrics mean average precision (map), geo-metric map (gmap), precision at 5 and at 10 (p@5,p@10).The maximum-likelihood estimator (MLE) base-line scores patterns by the relative frequency theyoccur with a certain relation.
The hierarchical topic(hier orig) as described in Alfonseca et al(2012)increases the scores under most metrics, howeverthe increase is only significant for p@5 and p@10.The feature-based extension of the topic model(hier feat) has significantly better ranking quality.Slightly better scores are obtained by the at-least-one perceptron learner.
It is interesting to see that themodel combinations both by non-dominated sortingperc+hier (pareto) as well as uniform interpolationperc+hier (itpl) give a further increase in rankingmethod map gmap p@5 p@10MLE .253 .142 .263 .232hier orig .270 .158 .353* .297*hier feature .318?
* .205?
* .363* .321*perceptron .330?
* .210?
* .379* .337*perc+hier (pareto) .340?
* .220?
* .400* .340*perc+hier (itpl) .344?
* .220?
* .426?
* .353?
*Table 1: Ranking quality of extracted facts.
Significance(paired t-test, p < 0.05) w.r.t.
MLE(*) and hier orig(?
).0.10.20.30.40.50.60.70  0.2  0.4  0.6  0.8  1PrecisionRecallInterpolated Precision/RecallMLEhier orighier featperceptronperc+hier (itpl)Figure 3: Precision at recall levels.quality.
The simpler interpolation scheme gener-ally works best.
Figure 3 shows the Precision/Recallcurves of the basic models and the linear interpola-tion.
On the P/R curve, the linear interpolation isequal or better than the single methods on all recalllevels.4.2 End-To-End EvaluationWe evaluate the extraction quality of the inducedperc+hier (itpl) patterns in an end-to-end setting.We use the evaluation setting of (Surdeanu et al2012) and the results obtained with their pipeline forMIMLRE and their re-implementation of MultiR asa point of reference.In Surdeanu et al(2012) evaluation is done us-ing a subset of queries from the TAC KBP 2010 and2011 evaluation.
The source corpus is the TAC KBPsource corpus and a 2010 Wikipedia dump.
Onlythose answers are considered in scoring that are con-tained in a list of possible answers from their can-didates (reducing the number of gold answers from1601 to 576 and thereby considerably increasing thevalue of reported recall).For evaluating our patterns, we take the same27queries for testing as Surdeanu et al(2012).
As thedocument collection, we use the TAC KBP sourcecollection and a Wikipedia dump from 07/2009 thatwas available to us.
From this document collec-tion, we use our retrieval pipeline of Roth et al(2012) and take those sentences that contain queryentities and slot filler candidates according to NE-tags.
We filter out all candidates that are not con-tained in the list of candidates considered in (Sur-deanu et al 2012), and use the same reduced setof 576 gold answers as the key.
We tune a singlethreshold parameter t = .3 on held-out developmentdata and take all patterns with higher scores.
Ta-ble 2 shows that results obtained with the inducedpatterns compare well with state-of-the-art relationextraction systems.method Recall Precision F1MultiR .200 .306 .242MIMLRE .314 .247 .277perc+hier (itpl) .248 .401 .307Table 2: TAC Scores on (Surdeanu et al 2012) queries.4.3 Illustration: Top-Ranked PatternsFigure 4 shows top-ranked patterns for per:titleand org:top members employees, the two rela-tions with most answers in the gold annotations.
Formaximum likelihood estimation the score is 1.0 ifthe patterns occurs only with the relation in question?
this includes all cases where the pattern is onlyfound once in the corpus.
While this could be cir-cumvented by frequency thresholding, we leave thelong tail of the data as it is and let the algorithm dealwith both frequent and infrequent patterns.One can see that while the maximum likelihoodpatterns contain some reasonable relational con-texts, they are less prototypical and more prone todistant supervision errors.
The patterns scored highby the proposed combination generalize better, vari-ation at the top is achieved by re-combining ele-ments that carry relational meaning (?is an?, ?vicepresident?, ?president director?)
or are closely cor-related to the particular relation.5 ConclusionWe have combined two models based on distinctprinciples for noise reduction in distant supervision:per:title, MLE[ARG1] , a singing [ARG2]*[ARG1] Best film : Capote ( as [ARG2][ARG1] Nunn ( born October 7 , 1957 in Little Rock , Arkansas) is an American jazz [ARG2]*[ARG2] Kevin Weekes , subbing for a rarely rested [ARG1][ARG1] Butterfill FRICS ( born February 14 , 1941 , Surrey ) isa British [ARG2]per:title, perc+hier (itpl)[ARG1] , is a Canadian [ARG2][ARG1] Hilligoss is an American [ARG2][ARG1] , is an American film [ARG2][ARG1] , is an American film and television [ARG2]*[ARG1] for Best [ARG2]org:top members employees, MLE[ARG2] remained chairman of [ARG1]*[ARG2] asks the ball whether he and [ARG1][ARG2] was chairman of the [ARG1]*[ARG1] , Joe Lieberman and [ARG2]*[ARG1] ?s responsibility to pin down just how the governmentdecided to front $ 30 billion in taxpayer dollars for the BearStearns deal , ?
Chairman [ARG2]org:top members employees, perc+hier (itpl)[ARG2] , Vice President of the [ARG1][ARG1] Vice president [ARG2][ARG1] president director [ARG2][ARG1] vice president director [ARG2][ARG1] Board member [ARG2]Figure 4: Top-scored patterns for maximum likelihood(MLE) and the interpolation (perc+hier itpl) method.
In-exact patterns are marked by *.a feature-based extension of a hierarchical topicmodel, and an at-least-one perceptron.
Interpola-tion increases the quality of extractions and achievesstate-of-the-art extraction performance.
A combina-tion scheme based on non-dominated sorting, thatwas inspired by work on combining machine trans-lation metrics, was not as good as a simple linearcombination of scores.
We think that the good re-sults motivate research into more integrated combi-nations of noise reduction approaches.AcknowledgmentBenjamin Roth is a recipient of the Google EuropeFellowship in Natural Language Processing, and thisresearch is supported in part by this Google Fellow-ship.28ReferencesEnrique Alfonseca, Katja Filippova, Jean-Yves Delort,and Guillermo Garrido.
2012.
Pattern learning forrelation extraction with a hierarchical topic model.
InProceedings of the 50th Annual Meeting of the Asso-ciation for Computational Linguistics: Short Papers-Volume 2, pages 54?59.
Association for Computa-tional Linguistics.S Borzsony, Donald Kossmann, and Konrad Stocker.2001.
The skyline operator.
In Data Engineering,2001.
Proceedings.
17th International Conference on,pages 421?430.
IEEE.Kevin Duh, Katsuhito Sudoh, Xianchao Wu, HajimeTsukada, and Masaaki Nagata.
2012.
Learning totranslate with multiple objectives.
In Proceedings ofthe 50th Annual Meeting of the Association for Com-putational Linguistics: Long Papers-Volume 1, pages1?10.
Association for Computational Linguistics.Parke Godfrey, Ryan Shipley, and Jarek Gryz.
2007.
Al-gorithms and analyses for maximal vector computa-tion.
The VLDB JournalThe International Journal onVery Large Data Bases, 16(1):5?28.Raphael Hoffmann, Congle Zhang, Xiao Ling, LukeZettlemoyer, and Daniel S Weld.
2011.
Knowledge-based weak supervision for information extraction ofoverlapping relations.
In Proceedings of the 49th An-nual Meeting of the Association for ComputationalLinguistics: Human Language Technologies, vol-ume 1, pages 541?550.Heng Ji, Ralph Grishman, Hoa Trang Dang, Kira Grif-fitt, and Joe Ellis.
2010.
Overview of the tac 2010knowledge base population track.
In Third Text Anal-ysis Conference (TAC 2010).Mike Mintz, Steven Bills, Rion Snow, and Dan Jurafsky.2009.
Distant supervision for relation extraction with-out labeled data.
In Proceedings of the Joint Confer-ence of the 47th Annual Meeting of the ACL and the4th International Joint Conference on Natural Lan-guage Processing of the AFNLP: Volume 2-Volume 2,pages 1003?1011.
Association for Computational Lin-guistics.Sebastian Riedel, Limin Yao, and Andrew McCallum.2010.
Modeling relations and their mentions with-out labeled text.
In Machine Learning and KnowledgeDiscovery in Databases, pages 148?163.
Springer.Benjamin Roth and Dietrich Klakow.
2013.
Feature-based models for improving the quality of noisy train-ing data for relation extraction.
In Proceedings of the22nd ACM International Conference on Informationand Knowledge Management (CIKM).
ACM.Benjamin Roth, Grzegorz Chrupala, Michael Wiegand,Mittul Singh, and Dietrich Klakow.
2012.
General-izing from freebase and patterns using distant supervi-sion for slot filling.
In Proceedings of the Text AnalysisConference (TAC).Mihai Surdeanu, Julie Tibshirani, Ramesh Nallapati, andChristopher D Manning.
2012.
Multi-instance multi-label learning for relation extraction.
In Proceedingsof the 2012 Joint Conference on Empirical Methodsin Natural Language Processing and ComputationalNatural Language Learning, pages 455?465.
Associa-tion for Computational Linguistics.Shingo Takamatsu, Issei Sato, and Hiroshi Nakagawa.2012.
Reducing wrong labels in distant supervi-sion for relation extraction.
In Proceedings of the50th Annual Meeting of the Association for Compu-tational Linguistics: Long Papers - Volume 1, ACL?12, pages 721?729, Stroudsburg, PA, USA.
Associ-ation for Computational Linguistics.Limin Yao, Sebastian Riedel, and Andrew McCallum.2010.
Collective cross-document relation extractionwithout labelled data.
In Proceedings of the 2010 Con-ference on Empirical Methods in Natural LanguageProcessing, pages 1013?1023.
Association for Com-putational Linguistics.29
