Proceedings of the SIGDIAL 2011: the 12th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 194?203,Portland, Oregon, June 17-18, 2011. c?2011 Association for Computational LinguisticsMultilingual Annotation and Disambiguation of Discourse Connectives forMachine TranslationThomas Meyer and Andrei Popescu-BelisIdiap Research InstituteRue Marconi 19, 1920 Martigny, SwitzerlandThomas.Meyer@idiap.ch, Andrei.Popescu-Belis@idiap.chSandrine Zufferey and Bruno CartoniDepartment of Linguistics, University of GenevaRue de Candolle 2, 1211 Geneva 4, SwitzerlandSandrine.Zufferey@unige.ch, Bruno.Cartoni@unige.chAbstractMany discourse connectives can signal severaltypes of relations between sentences.
Theirautomatic disambiguation, i.e.
the labeling ofthe correct sense of each occurrence, is impor-tant for discourse parsing, but could also behelpful to machine translation.
We describenew approaches for improving the accuracyof manual annotation of three discourse con-nectives (two English, one French) by usingparallel corpora.
An appropriate set of labelsfor each connective can be found using infor-mation from their translations.
Our results forautomatic disambiguation are state-of-the-art,at up to 85% accuracy using surface features.Using feature analysis, contextual features areshown to be useful across languages and con-nectives.1 IntroductionDiscourse connectives are generally considered asindicators of discourse structure, relating two sen-tences of a written or spoken text, and making ex-plicit the rhetorical or coherence relation betweenthem.
Leaving aside the cases when connectives areonly implicit, the presence of a connective does notunambiguously signal a specific discourse relation.In fact, many connectives can indicate several typesof relations between sentences, i.e.
they have severalpossible ?senses?
in context.This paper studies the manual and automated dis-ambiguation of three ambiguous connectives in twolanguages: alors que in French, since and while inEnglish.
We will show how the multilingual per-spective helps to improve the accuracy of annota-tion, and how it helps to find appropriate labels forautomated processing and MT.
Results from auto-matic annotation experiments, which are close to thestate of the art, as well as feature analysis, help to as-sess the usefulness of the proposed labels.The paper is organized as follows.
Section 2 ex-plains the motivation of our experiments, and of-fers a wider perspective on our research goals, illus-trating them with examples of translation problemswhich arise from ambiguous discourse connectives.Current resources and methods for discourse anno-tation are discussed in Section 3.
Section 4 analyzesour experiments in manual annotation and in partic-ular the influence of the set of labels on the reliabilityof annotation.
The automatic disambiguation exper-iments, the features used, the results and the analysisof features are described in Section 5.
Section 6 con-cludes the paper and outlines future work.2 Explicit Connectives and theirTranslation2.1 Three Multi-functional ConnectivesDiscourse connectives form a functional category oflexical items that are used to mark coherence rela-tions such as Cause or Contrast between units ofdiscourse.
Along with other function words, manyconnectives appear among the most frequent words,as shown for instance by counts (Cartoni et al,2011) over the Europarl corpus (Koehn, 2005).
ThePenn Discourse Treebank (Prasad et al, 2008) (seeSection 3.1 below) includes around 100 connectivetypes, but the exact number varies across studies,194depending on the discourse theory used to classifythem.
Among these types, Pitler et al(2008) haveshown that most of them are unambiguous and easyto identify, but others, especially temporal ones, of-ten signal multiple senses depending on their con-text.Following the terminology of Petukhova andBunt (2009, Section 2), we are interested here in?sequential?
multi-functionality, i.e.
the fact that thesame connective can signal different relations in dif-ferent contexts.
We do not deal with ?simultane-ous?
multi-functionality, i.e.
the possibility for asingle occurrence to signal several relations, whichhas been less frequently studied for connectives (seePetukhova and Bunt (2009) for the discourse usageof and).We identified the two English connectives whileand since, along with the French connective alorsque, as being particularly problematic because theyare highly multi-functional, i.e.
they can signal mul-tiple senses.
For alors que, a French database ofconnectives (LexConn (Roze et al, 2010), see Sec-tion 3 below) contains examples of sentences wherealors que expresses either a Background or a Con-trast relation.
For the English connective since,Miltsakaki et al (2005) identified three possiblemeanings: Temporal, Causal, and simultaneouslyTemporal/Causal.
For while, even more senses areobserved: Comparison, Contrast, Concession, andOpposition.
In fact, in the Penn Discourse Tree-bank, the connective while is annotated with morethan twenty different senses.2.2 Wider Research ObjectivesOur long-term goal is to identify automatically thesenses of connectives for an application to machinetranslation (MT).
Going beyond the labels providedby discourse theories, the goal is thus to find themost appropriate labels in a new multilingual, em-pirical approach that makes use of parallel corpora toannotate and then learn the various senses of connec-tives.
The disambiguation of such connectives in asource text is crucial for its translation, because eachsense may be translated by a different connectiveand/or syntactical construct in the target language.More specifically, we hypothesize that correctlylabeled connectives are easier to learn and to trans-late by statistical MT systems than unlabeled ones.To support this hypothesis, we set up an experiment(Meyer, 2011) in which we constrained the transla-tion of the three senses of the discourse connectivewhile that were previously annotated as Temporal,Contrast and Concession.
The system was forced touse predefined French translations known to be cor-rect, by directly modifying the phrase table of thetrained MT system.
This modification noticeablyhelped to improve translation quality and rose theBLEU score by 0.8 for a preliminary test set of 20sentences.2.3 Illustration of MistranslationsAmong the connectives that we plan to process in or-der to improve MT, the three connectives we focuson in this paper are frequent, ambiguous and there-fore difficult to translate correctly by MT systems,as illustrated in the following examples.A first reason why machine translation of connec-tives can be difficult is that there may be no directlexical correspondence for the explicit source lan-guage connective in the target language, as shownin the reference translation of the first example inTable 1, taken from the Europarl corpus (Koehn,2005).EN It is also important that we should not leave these indica-tors floating in the air while congratulating ourselves onthe fact that we have produced them.FR Il est e?galement important de ne pas laisser ces indicateursflotter, en nous fe?licitant de les avoir instaure?s.EN Finally, and in conclusion, Mr President, with the expiry ofthe ECSC Treaty, the regulations will have to be reviewedsince [causal] I think that the aid system will have to con-tinue beyond 2002 .
.
.FR *Enfin, et en conclusion, Monsieur le pre?sident, a`l?expiration du traite?
ceca, la re?glementation devra e?trerevu depuis que [temporal] je pense que le syste`me d?aidesdevront continuer au-dela` de 2002 .
.
.FR Oui, bien entendu, sauf que le de?veloppement ne se ne?gociepas, alors que [contrast] le commerce, lui, se ne?gocie.EN *Yes, of course, but development cannot be negotiated, so[causal] that trade can.EN Between 1998 and 1999, loyalists assaulted and shot 123people, while [contrast] republicans assaulted and shot 93people.FR *Entre 1998 et 1999, les loyalistes ont attaque?
et abattu123 personnes, ?
93 pour les re?publicains.Table 1: Translation examples from Europarl.
Discourseconnectives, their translations, and their senses are indi-cated in bold.
The first example is a reference transla-tion from EN into FR, while the others are wrong transla-tions generated by MT (EN/FR and respectively FR/EN),hence marked with an asterisk.195When an ambiguous connective is explicitlytranslated by another connective, the incorrect ren-dering of its sense can lead to erroneous translations,as in the second and third examples in Table 1, whichare translated by the Moses SMT decoder (Koehn etal., 2007) trained on the Europarl corpus.
The ref-erence translation for the second example uses theFrench connective car with a correct causal sense,instead of the wrong depuis que generated by SMT,which expresses a temporal relation.
In the third ex-ample, the French connective alors que, in its con-trastive usage, is wrongly translated into the Englishconnective so, which has a causal meaning (the ref-erence translation uses whereas to express contrast).It may even occur that the system fails to translate aconnective at all, as in the fourth example where thediscourse information provided by while, namely aContrast relation, is lost in the French translation,which is hardly coherent any longer.3 Related Work3.1 Annotated ResourcesOne of the very few available discourse annotatedcorpora is the Penn Discourse Treebank (PDTB) inEnglish (Prasad et al, 2008).
For this resource, onehundred types of explicit discourse connectives weremanually annotated, as well as implicit relations notsignaled by a connective.
The sense hierarchy usedfor annotation consists of three levels, from four top-level senses (Temporal, Contingency, Comparison,and Expansion), to 16 subsenses on the second level,and 23 further ones on the third level.
The annota-tors were allowed to assign more than one sense toeach occurrence, so 129 simple or complex labelsare observed, over more than 18,000 explicit con-nectives.
For French, the ANNODIS project (Pe?ry-Woodley et al, 2009) will provide annotation of dis-course on an original corpus.
Resources for Czechare also becoming available (Zika?nova?
et al, 2010).For German, a lexicon of discourse markersnamed DiMLex exists since the 1990s (Stede andUmbach, 1998).
An equivalent, more recentdatabase for French is the LexConn lexicon of con-nectives (Roze et al, 2010) containing a list of 328explicit connectives.
For each of them, LexConnindicates and exemplifies the possible senses, cho-sen from a list of 30 labels inspired from RhetoricalStructure Theory (Mann and Thompson, 1988).3.2 Automatic Disambiguation of ConnectivesThe release of the PDTB had quite an impact onautomatic disambiguation experiments.
The state-of-the-art for recognizing all types of explicit con-nectives in English is therefore already high, at97% accuracy for disambiguating discourse vs. non-discourse uses (Lin et al, 2010) and 94% for disam-biguating the four main senses from the PDTB hier-archy (Pitler and Nenkova, 2009).
Lin et al (2010)recently built the first end-to-end PDTB discourseparser, which is able to parse unrestricted text withan F1 score of 38.18% for senses on the second levelof the PDTB hierarchy.
Other important contribu-tions to automatic discourse connective classifica-tion and feature analysis has been provided by Well-ner et al (2006) and Elwell and Baldrige (2008).Fewer studies focus on the detailed analysis ofspecific discourse connectives.
In Section 5.3, wewill compare our results to Miltsakaki et al (2005)who report classification results for the connectivessince, while and when.
In their study, as in thepresent one, the goal is to disambiguate senses fromthe second level of the PDTB hierarchy, a levelwhich, as we will show, is appropriate for the trans-lation of these connectives as well.4 Connective Annotation in ParallelCorporaThe resources mentioned above are either monolin-gual only (PDTB, LexConn) and/or not yet publiclyavailable (ANNODIS, DiMLex).
Moreover, ouroverall goal is related to multilingualism and trans-lation, as explained in Section 2.2 above.
There-fore, we performed manual annotation of connec-tives in a multilingual, aligned resource: the Eu-roparl corpus (Koehn, 2005).
We extracted from Eu-roparl two subcorpora for each translation direction,EN/FR and FR/EN, to take into account the varyingdistribution of connectives in translated vs. originallanguage, as explained in Cartoni et al (2011).As the full PDTB hierarchy seemed too fine-grained given current capabilities for automatic la-beling and the needs for translating connectives,we defined a simplified set of labels for the sensesof connectives, by considering their usefulness and196granularity with respect to translation, focusing onthose that may lead to different connectives or syn-tactical constructs in the target language.4.1 MethodThere are two major ways to annotate explicit dis-course connectives.
The first approach is to labeleach occurrence of a connective with a label forits sense, similar to the PDTB or LexConn hierar-chies of senses.
However, as shown among othersby Zikanova et al (2010), this is a difficult and time-consuming task even when the annotators are trainedover a long period of time.
This is confirmed by therather low kappa scores resulting from the manualsense annotations as can be seen for each connectivein detail below.The second approach to annotation, which is theone put forward in this paper, is based on translationspotting.
In a first step, human annotators work onbilingual sentence pairs, and annotate the translationof each connective in the target language.
The trans-lations are either a target language connective (sig-naling in principle the same sense(s) as the sourceone), or a reformulation, or a construct with no con-nective at all.
In a second step of the annotation,all translations of a connective are manually clus-tered by the experimenters to derive sense labels, bygrouping together similar translations.As demonstrated in the following subsections, forthe three connectives under study, the second ap-proach to connective annotation not only facilitatesthe annotation task, but also helps to derive the ap-propriate level of granularity for the sense labels.4.2 Annotation of alors queThis first manual annotation involved two experi-enced annotators who annotated alors que in 423original French sentences.
The two main sensesidentified for alors que are Background (labeled B)Contrast (labeled C), as in the LexConn database.Annotators were also allowed to use the J label ifthey did not know which label to assign, and aD label for discarded sentences ?
due to a non-connective use of the two words which could not befiltered out automatically (e.g.
Alors, que fera-t-on?).
The annotators found 20 sentences labeled withD, which were removed from the data.
15 sentenceswere labeled with J by one annotator (but none byboth), and it was decided to assign to them the label(either B or C) provided by the other annotator.The inter-annotator agreement on the B vs. C la-bels was quite low, showing the difficulty of the task:kappa reached 0.43, quite below the 0.7 mark oftenconsidered as indicating reliability.
The followingexample from Europarl illustrates the difficulty ofchoosing between B and C. In particular, the refer-ence translation into English also uses an ambiguousconnective, namely while.FR La monnaie unique va entrer en vigueur au milieude la tourmente financie`re, alors que de nombreuxcomple?ments, logiques, mais que les E?tats ne sem-blaient pas avoir pre?vus, n?ont pas encore e?te?
ap-porte?s.EN The single currency is going to come into force in themidst of financial turmoil, while a great many ad-ditional factors which were only to be expected, butwhich the states do not seem to have anticipated, havenot been taken into consideration.Two methods were applied to deal with diverg-ing manual annotations.
To prepare the datasets forthe automated disambiguation experiments, one so-lution (named A1, see Table 2) is to use the double-sense label B/C for sentences labeled differently byannotators (B vs. C).
This label reflects the diffi-culty of manual annotation and preserves the am-biguity which might be genuinely present in eachoccurrence.
The relevance of the B/C label is alsosupported by results from automatic labeling in Sec-tion 5.3 below.For comparison purposes, a second dataset namedA2 was derived from translation spotting on thesame French sentences aligned to English ones, asexplained in Section 4.1.
Alors que appeared to bemainly translated by the following English equiv-alents and constructs: although, whereas, while,whilst, when, at a time when.
Through this opera-tion, inter-annotator disagreement can sometimes besolved: when the translation is a clearly contrastiveEnglish connective (whereas or although), then theC label was assigned instead of B/C.
Conversely,when the English translation was still ambiguous(while, whilst, or when), the experimenters made adecision in favor of either B or C by re-examiningsource and target sentences.4.3 Annotation of sinceFor since, 30 sentences were annotated by four ex-perimenters in a preliminary round, with a kappa197ID Connective Sent.
Labels (nb.
of occ.
)A1 alors que 403 B (92), C (191), B/C (120)A2 alors que 403 B (126), C (277)B1 since 727 T (375), C (341), T/C (11)B2 since 727 T (375), C (352)C1 while 299 T/C (92), CONC (134), C (43)T/CAUSAL (19), T/DUR (7)T/PUNCT (4)C2 while 299 T (30), C (135), CONC (134)Table 2: The six datasets resulting from the manual anno-tation of the three connectives, with total number of sen-tences, possible labels and their number of occurrences.The explanations of the labels are given in Sections 4.2through 4.4.score of 0.77, indicating good agreement.
Then,each half of the entire dataset (727 sentences) wasannotated by another person with three possiblesense labels: T for Temporal, C for Causal andT/C for a simultaneously Temporal/Causal meaning.Two datasets were again derived from this manualannotation.
To study the effects of a supplementarylabel, we kept the label T/C for dataset B1, but con-densed it under label C in dataset B2, as shown inTable 2.4.4 Annotation of whileThe English connective while is highly ambiguous.In the PDTB, occurrences of while are annotatedwith no less than 21 possible senses, ranging fromConjunction to Contrast, Concession, or Synchrony.We performed a pilot annotation of 30 sentencescontaining while with five different experimenters,resulting in a quite low inter-annotator agreement,?
= 0.56.
We therefore decided to perform atranslation spotting task only, with two experiencedannotators fluent in English and French.
The ob-served translations into French confirm the ambigu-ity of while, as they include several connectives andconstructs, quite evenly distributed in terms of fre-quency: alors que, gerundive reformulations, otherreformulations, si, tandis que, me?me si, bien que,etc.The translations were manually clustered to de-rive senses for while, in an empirical manner.For example, alors que signals Temporal/Contrast,which is also true for tandis que.
Similarly, me?me siand bien que are clustered under the label Conces-sion, and so forth.
The translation spotting showsthat at least Contrast, Concession, and several tem-poral senses are necessary to account for a correcttranslation.
These distinctions are comparable to thesemantic granularity of the second PDTB hierarchylevel.To generate training sets for automated classifica-tion out of a total of 500 sentences, we discarded 201sentences labeled by annotators with G (gerundiveconstructions), P (reformulations) or Z (no transla-tion at all) ?
these cases could be reconsidered in fur-ther work, as they represent valid translation prob-lems.
For the remaining 299 sentences, we createdthe following six labels by clustering the spottedtranslations: T/C (Temporal/Contrast), T/PUNCT(Temporal/Punctual), T/DUR (Temporal/Duration),T/CAUSAL (Temporal/Causal), CONC (Conces-sion) and C (Contrast).
These were used to tag theremaining 299 sentences, forming dataset C1.
Asecond dataset (C2) with fewer senses was obtainedfrom C1 by merging T/C to C (Contrast only) andall T/x to T (Temporal only).5 Disambiguation ExperimentsThe features for connective classification, the re-sults obtained and a detailed feature analysis are dis-cussed in this section.
We show that an automateddisambiguation system can be used to determine themost appropriate set of labels, and thus to corrob-orate the selection we made using translation spot-ting.5.1 FeaturesFor feature extraction, all the datasets described inSection 4 were processed as follows.
The Englishtexts were parsed and POS-tagged by Charniak andJohnson?s (2005) reranking parser.
The French textswere POS-tagged with the MElt tagger (Denis andSagot, 2009) and parsed with MaltParser (Nivre,2003).
As the English parser provides constituencytrees, and the parser for French generates depen-dency trees, the features are slightly different in thetwo languages.
The other features below were ex-tracted using elementary pre-processing of the sen-tences.For English sentences, we used the following fea-tures: the sentence-initial character of the connec-198tive (yes/no); the POS tag of the first verb in thesentence; the type of first auxiliary verb in the sen-tence (if any); the word preceding the connective;the word following the connective; the POS tag ofthe first verb following the connective; the type ofthe first auxiliary verb after the connective (if any).For French sentences, the features were the fol-lowing: the sentence-initial character of the connec-tive (yes/no); the dependency tag of the connective;the first verb in the sentence; its dependency tag; theword preceding the connective; its POS tag; its de-pendency tag; the word following the connective; itsPOS tag; its dependency tag; the first verb after theconnective; its dependency tag.The cased connective word forms from the cor-pus were not lower-cased, thus keeping the implicitindication of the sentence-initial character of the oc-currence, i.e.
whether it starts a sentence or not.
Theoutput of the POS taggers was used for neighboringwords, but not for the connectives, which almost al-ways received the same tag.
Charniak?s parser forEnglish provides POS tags which differentiate theverb tenses, such as VBD (past), VBG (gerund), andso on.
These were considered for the verb directlypreceding and the one directly following the connec-tive.
Tense was believed to be potentially relevantbecause since and while can have temporal mean-ings.The occurrence of auxiliary verbs (be, have, do,or need) may give additional indications about tem-poral relations in the sentence.
We therefore usedthe types of auxiliary verbs as features, includingthe elementary conjugations, represented for to beas: be present, be past, be part, be inf, be gerund?
and similarly for the other auxiliary verbs, as in(Miltsakaki et al, 2005).As shown by Lin et al (2010), duVerle andPrendinger (2009) or Wellner et al (2006), the con-text of a connective is very important.
We there-fore extracted the words preceding and followingeach connective, the verbs and the first and the lastword of the sentences.
These may include numbers,sometimes indicating a numerical comparison, timeexpressions, or antonyms, which could indicate con-trastive relations, such as rise vs. fall (e.g.
It is inter-esting to see the fundamental stock pickers scream?foul?
on program trading when the markets de-cline, while hailing the great values still aboundingas the markets rise.
).For French, we likewise extracted the words im-mediately preceding and following each connective,supplemented by their POS tags.
In contrast to con-stituents, dependency structures contain informationabout the grammatical function of each word (heads)and link the dependents belonging to the same head.However, as the dependency parser provides no dif-ferentiated verb tags, we extracted the verb wordforms themselves and added their dependency tags.The same applies to the connective itself, and pre-ceding and following words and their dependencytags.The dependency tag of the non-connectives variesbetween subj (subject), det (determiner), mod (mod-ifier) and obj (object).
The first verb in the sentenceoften belongs to the root dependency while the verbfollowing the connective most often belongs to theobj dependency.
For alors que, the most frequentdependency tags were mod mod and mod obj, indi-cating the connective?s main function as a modifierof its argument.5.2 Experimental SettingOur classification experiments made use of theWEKA machine learning toolkit (Hall et al, 2009)to run and compare several classification algorithms:Random Forest (sets of decision trees), Naive Bayes,and Support Vector Machine.
The results are re-ported with 10-fold cross validation on the entiredata for each connective, using all features.Table 3 lists for each method ?
including the ma-jority classifier as a baseline ?
the percentage of cor-rectly classified instances (or accuracy, noted Acc.
),and the kappa values.
Significance above the base-line is computed using paired t-tests at 95% confi-dence.
When a score is significantly above the base-line, it is shown in italics in Table 3.
The best scoresfor each dataset, across classifiers, are indicated inboldface.
When these scores were not significantlyabove the baseline, at least they were never signifi-cantly below either.5.3 Results and DiscussionOverall, the SVM classifier performed best, whichmay be due to the large number of textual features(3 for EN data and 5 for FR data), as SVMs areknown to handle them well (Joachims, 1998; du-199ID Connective # Labels Baseline R. Forest N. Bayes SVMAcc.
Acc.
?
Acc.
?
Acc.
?A1 alors que 403 B, C, B/C 46.9 53.1 0.2 55.7 0.3 54.2 0.3A2 alors que B, C 68.7 69.2 0.1 68.3 0.2 64.7 0.1B1 since 727 T, C, T/C 51.6 79.8 0.6 82.3 0.7 85.4 0.7B2 since T, C 51.6 80.7 0.6 84.0 0.7 85.7 0.7C1 while 299 T/C, T/PUNCT, T/DUR,T/CAUSAL, CONC, C44.8 43.2 0.1 49.9 0.2 52.2 0.2C2 while T, C, CONC 43.5 60.5 0.3 59.9 0.3 60.9 0.3Table 3: Disambiguation scores for three connectives (number of occurrences in the training sets), with two sets oflabels each, for various classification algorithms.
Accuracy (Acc.)
is in percentage (%), and kappa is zero for thebaseline method (majority class).
The best scores for each data set are in boldface, and scores significantly above thebaseline (95% t-test) are in italics.Verle and Prendinger, 2009).
The maximum accu-racy for alors que is 55.7%, for since it is 85.7%, andfor while it is 60.9%.
While close to other reportedvalues, there is still potential for improvement in thefuture.The analysis of results for each data sets leadsto observations that are specific to each connective.The high improvement of over the baseline for A1,as opposed to no improvement for A2, confirms theusefulness of the double-sense B/C label for alorsque, showing that in this case the three-way classi-fication is probably better adapted to the linguisticproperties of alors que than a two-way classifica-tion.
Indeed, alors que, just as its frequently spot-ted translation while, is linguistically ambiguous insome contexts (see for instance the example in Sec-tion 4.2), in which the temporal and the contrastivemeaning are likely to co-exist.
In the case of A2,where the labels were forced to B or C only, auto-matic classifiers do not significantly outperform thebaseline.
While more elaborate features might help,these low scores can be related to the difficulties ofhuman annotators (Section 4.2), and make a strongcase against using a two-label schema for alors que.The features used so far lead to high scores forsince in datasets B1 and B2.
The results are com-parable to those from Miltsakaki et al (2005), whoused similar features and labels, though with a Max-imum Entropy classifier.
Moreover, they provide re-sults for individual connectives, and not, as most ofthe related work for the PDTB, on the whole setof ca.
100 discourse connective types.
However,Miltsakaki et al (2005) used their own datasets foreach connective, which are different from the PDTB,because the PDTB was not available at that time.Our SVM classifier outperforms considerably theMaximum Entropy classifier on the three-way clas-sification task (with T, C, T/C), with an accuracyof 85.4% vs. 75.5%, obtained however on differ-ent datasets.
For the two-way classification (T, C),again on different datasets, our accuracy of 85.7% isslightly lower than the 89.5% given in Miltsakaki etal.
(2005).1For while, when comparing C1 to C2, it appearsthat reducing the number of labels from six to threeincreases accuracy by 8-10%.
This is probablydue to the small number of training instances forthe labels T/PUNCT and T/DUR in C1 for exam-ple.
However, even for the larger set of labels, thescores are significantly above baseline (52.2% vs.44.8%), which indicates that such a classifier mightstill be useful as input to an MT system, possiblyimproved thanks to a larger training set.
The perfor-mance obtained by Miltsakaki et al (2005) on whileis markedly better than ours, with an accuracy of71.8% compared to ours of 60.9% with three labels.5.4 Feature AnalysisThe relevance of features can be measured usingWEKA by computing the information gain (IG)brought by each feature to the classification task,1In another experiment (Meyer, 2011), we also applied ourclassifiers to the PDTB data, with less features however.
Theresults were in the same range as those from Miltsakaki etal.
(2005), i.e.
75.3% accuracy for since and 59.6% for while.200R Feature IGA1 A21 preceding word 1.12 0.642 following verb 0.81 0.513 first verb 0.74 0.424 following word 0.68 0.235 preceding word?s POS tag 0.15 0.055 first verb?s dep.
tag 0.14 0.065 following word?s POS tag 0.19 0.038 preceding word?s dep.
tag 0.10 0.038 connective?s dep.
tag 0.09 0.0410 following word?s dep.
tag 0.13 0.01310 following verb?s dep.
tag 0.04 0.0312 sentence initial 0.05 0.001Table 4: Information gain (IG) of features for French con-nective alors que, ordered by decreasing average ranking(R) in experiments A1 and A2.
Features 1?4 are consid-erably more relevant than the following ones.R Feature IGB1 B21 preceding word 0.83 0.752 following word 0.56 0.523 following verb?s POS tag 0.24 0.214 type of following aux.
verb 0.13 0.125 type of first aux.
verb 0.11 0.116 first verb?s POS tag 0.02 0.017 sentence initial 0.00 0.00Table 5: Information gain (IG) of features for EN con-nective since, ordered by decreasing average ranking (R)in experiments B1 and B2.i.e.
the reduction in entropy with respect to desiredclasses (Hall et al, 2009) ?
the higher the IG, themore relevant the feature.
Features can be rankedby decreasing IG, as shown in Tables 4, 5 and 6, inwhich ranks were averaged over the first and the sec-ond data set in each series.The tables show that across all three connectivesand the two languages, the contextual features arealways in the first positions, thus confirming the im-portance of the context of a connective.
Followingthese are verbal features, which are, for these con-nectives, of importance because the temporal mean-ings are additionally established by verbal tenses.POS and dependency features seem the least help-R Feature IGC1 C21 preceding word 1.02 0.652 following word 0.83 0.553 type of first aux.
verb 0.12 0.074 following verb?s POS tag 0.16 0.045 first verb?s POS tag 0.07 0.095 type of following aux.
verb 0.12 0.057 sentence initial 0.08 0.07Table 6: Information gain (IG) of features for EN con-nective while, ordered by decreasing average ranking (R)in experiments C1 and C2.
The first two features are con-siderably more relevant than the remaining ones.ful for disambiguation.6 Conclusion and Future WorkWe have described a translation-oriented approachto the manual and automatic annotation of discourseconnectives, with the goal of identifying their sensesautomatically, prior to machine translation.
Themanual annotation of the senses of connectives hasbeen enhanced through parallel corpora and transla-tion spotting.
This has lead to tag sets that improvedboth inter-annotator agreement and automatic label-ing, which reached state-of-the-art scores.
The ana-lysis of relevant features has shown the utility ofcontextual information.To improve over these initial results, we will usemore semantic information, such as relations foundin WordNet between words in the neighborhood ofconnectives ?
e.g.
word similarity measures and se-mantic relations such as antonymy.
To generatemore training instances of the labels found, man-ual annotation will continue in order to see whetherthe senses found through translation spotting can im-prove automatic disambiguation of many more con-nectives.
The annotation of a large parallel corpuswill then help to train disambiguation tools alongwith statistical MT systems that use their output.AcknowledgmentsWe are grateful for the funding of this work by theSwiss National Science Foundation (SNSF) underthe COMTIS Sinergia Project, n. CRSI22 127510(see www.idiap.ch/comtis/).201ReferencesBruno Cartoni, Sandrine Zufferey, Thomas Meyer, andAndrei Popescu-Belis.
2011.
How comparable areparallel corpora?
Measuring the distribution of gen-eral vocabulary and connectives.
In Proceedings of 4thWorkshop on Building and Using Comparable Cor-pora, Portland, OR.Eugene Charniak and Mark Johnson.
2005.
Coarse-to-fine n-best parsing and maxent discriminative rerank-ing.
In Proceedings of ACL 2005 (43rd Annual Meet-ing of the ACL), pages 173?180, Ann Arbor, MI.Pascal Denis and Beno?
?t Sagot.
2009.
Coupling an anno-tated corpus and a morphosyntactic lexicon for state-of-the-art POS tagging with less human effort.
InProceedings of PACLIC 2009 (23rd Pacific Asia Con-ference on Language, Information and Computation),pages 110?119, Hong Kong, China.David duVerle and Helmut Prendinger.
2009.
A noveldiscourse parser based on support vector machine clas-sification.
In Proceedings of ACL-IJCNLP 2009 (47thAnnual Meeting of the ACL and 4th International JointConference on NLP of the AFNLP), pages 665?673,Singapore.Robert Elwell and Jason Baldridge.
2008.
Discourseconnective argument identification with connectivespecific rankers.
In Proceedings of ICSC 2008 (2ndIEEE International Conference on Semantic Comput-ing), pages 198?205, Santa Clara, CA.Mark Hall, Eibe Frank, Geoffrey Holmes, BernhardPfahringer, Peter Reutemann, and Ian H. Witten.2009.
The WEKA data mining software: An update.ACM SIGKDD Explorations Newsletter, 11:10?18.Thorsten Joachims.
1998.
Text categorization with sup-port vector machines: Learning with many relevantfeatures.
In Proceedings of ECML 1998 (10th Euro-pean Conference on Machine Learning), pages 137?142, Chemnitz, Germany.Philipp Koehn, Hieu Hoang, Alexandra Birch, ChrisCallison-Burch, Marcello Federico, Nicola Bertoldi,Brooke Cowan, Wade Shen, Christine Moran, RichardZens, Chris Dyer, Ondrej Bojar, Alexandra Con-stantin, and Evan Herbs.
2007.
Moses: Open sourcetoolkit for statistical machine translation.
In Pro-ceedings of ACL 2007 (45th Annual Meeting of theACL), Demonstration Session, pages 177?180, Prague,Czech Republic.Philipp Koehn.
2005.
Europarl: A parallel corpus forstatistical machine translation.
In Proceedings of MTSummit X, pages 79?86, Phuket, Thailand.Ziheng Lin, Hwee Tou Ng, and Min-Yen Kan. 2010.
APDTB-styled end-to-end discourse parser.
TechnicalReport TRB8/10, School of Computing, National Uni-versity of Singapore, Singapore.William C. Mann and Sandra A. Thompson.
1988.Rhetorical Structure Theory: towards a functional the-ory of text organization.
Text, 8(3):243?281.Thomas Meyer.
2011.
Disambiguating temporal-contrastive discourse connectives for machine transla-tion.
In Proceedings of ACL-HLT 2011 (49th AnnualMeeting of the ACL: Human Language Technologies),Student Session, Portland, OR.Eleni Miltsakaki, Nikhil Dinesh, Rashmi Prasad, AravindJoshi, and Bonnie Webber.
2005.
Experiments onsense annotations and sense disambiguation of dis-course connectives.
In Proceedings of the TLT 2005(4th Workshop on Treebanks and Linguistic Theories),Barcelona, Spain.Joakim Nivre.
2003.
An efficient algorithm for pro-jective dependency parsing.
In Proceedings of IWPT2008 (8th International Workshop on Parsing Tech-nologies), pages 149?160, Tokyo, Japan.Marie-Paule Pe?ry-Woodley, Nicholas Asher, PatriceEnjalbert, Farah Benamara, Myriam Bras, Ce?cileFabre, Ste?phane Ferrari, Lydia-Mai Ho-Dac, AnneLe Draoulec, Yann Mathet, Philippe Muller, LaurentPre?vot, Josette Rebeyrolle, Ludovic Tanguy, MarianneVergez-Couret, Laure Vieu, and Antoine Widlo?cher.2009.
Annodis: une approche outille?e de l?annotationde structures discursives.
In Proceedings of TALN2009 (16e`me Confe?rence sur le Traitement Automa-tique des Langues Naturelles), Paris, France.Volha Petukhova and Harry Bunt.
2009.
Towards amultidimensional semantics of discourse markers inspoken dialogue.
In Proceedings of IWCS-8 (8th In-ternational Conference on Computational Semantics),pages 157?168, Tilburg, The Netherlands.Emily Pitler and Ani Nenkova.
2009.
Using syntax todisambiguate explicit discourse connectives in text.
InProceedings of ACL-IJCNLP 2009 (47th Annual Meet-ing of the ACL and 4th International Joint Conferenceon NLP of the AFNLP), Short Papers, pages 13?16,Singapore.Emily Pitler, Mridhula Raghupathy, Hena Mehta, AniNenkova, Alan Lee, and Aravind Joshi.
2008.
Eas-ily identifiable discourse relations.
In Proceedings ofColing 2008 (22nd International Conference on Com-putational Linguistics), Companion Volume: Posters,pages 87?90, Manchester, UK.Rashmi Prasad, Nikhil Dinesh, Alan Lee, Eleni Milt-sakaki, Livio Robaldo, Aravind Joshi, and BonnieWebber.
2008.
The Penn Discourse Treebank 2.0.
InProceedings of LREC 2008 (6th International Confer-ence on Language Resources and Evaluation), pages2961?2968, Marrakech, Morocco.Charlotte Roze, Laurence Danlos, and Phillippe Muller.2010.
LEXCONN: a French lexicon of discourse con-nectives.
In Proceedings of MAD 2010 (Multidis-202ciplinary Approaches to Discourse), pages 114?125,Moissac, France.Manfred Stede and Carla Umbach.
1998.
DiMLex: alexicon of discourse markers for text generation andunderstanding.
In Proceedings of ACL 1998 (36th An-nual Meeting of the ACL), pages 1238?1242, Mon-treal, Canada.Ben Wellner, James Pustejovsky, Catherine Havasi,Roser Sauri, and Anna Rumshisky.
2006.
Classifica-tion of discourse coherence relations: An exploratorystudy using multiple knowledge sources.
In Proceed-ings of 7th SIGDIAL Workshop on Discourse and Di-alogue, pages 117?125, Sydney, Australia.Sa?rka Zika?nova?, Lucie Mladova?, Jir???
M?
?rovsky?, andPavlina J??nova?.
2010.
Typical cases of annotators?disagreement in discourse annotations in Prague De-pendency Treebank.
In Proceedings of LREC 2010(7th International Conference on Language Resourcesand Evaluation), pages 2002?2006, Valletta, Malta.203
