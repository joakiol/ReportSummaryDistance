Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 516?525,Jeju, Republic of Korea, 8-14 July 2012. c?2012 Association for Computational LinguisticsTweet Recommendation with Graph Co-RankingRui Yan?
?Department of ComputerScience and Technology,Peking University,Beijing 100871, Chinar.yan@pku.edu.cnMirella Lapata?
?Institute for Language,Cognition and Computation,University of Edinburgh,Edinburgh EH8 9AB, UKmlap@inf.ed.ac.ukXiaoming Li?, \\State Key Laboratory of SoftwareDevelopment Environment,Beihang University,Beijing 100083, Chinalxm@pku.edu.cnAbstractAs one of the most popular micro-bloggingservices, Twitter attracts millions of users,producing millions of tweets daily.
Shared in-formation through this service spreads fasterthan would have been possible with tradi-tional sources, however the proliferation ofuser-generation content poses challenges tobrowsing and finding valuable information.
Inthis paper we propose a graph-theoretic modelfor tweet recommendation that presents userswith items they may have an interest in.
Ourmodel ranks tweets and their authors simulta-neously using several networks: the social net-work connecting the users, the network con-necting the tweets, and a third network thatties the two together.
Tweet and author entitiesare ranked following a co-ranking algorithmbased on the intuition that that there is a mu-tually reinforcing relationship between tweetsand their authors that could be reflected in therankings.
We show that this framework can beparametrized to take into account user prefer-ences, the popularity of tweets and their au-thors, and diversity.
Experimental evaluationon a large dataset shows that our model out-performs competitive approaches by a largemargin.1 IntroductionOnline micro-blogging services have revolutionizedthe way people discover, share, and distribute infor-mation.
Twitter is perhaps the most popular suchservice with over 140 million active users as of2012.1 Twitter enables users to send and read text-based posts of up to 140 characters, known as tweets.Twitter users follow others or are followed.
Being afollower on Twitter means that the user receives allthe tweets from those she follows.
Common prac-tice of responding to a tweet has evolved into a well-defined markup culture (e.g., RT stands for retweet,?@?
followed by an identifier indicates the user).The strict limit of 140 characters allows for quickand immediate communication in real time, whilstenforcing brevity.
Moreover, the retweet mecha-nism empowers users to spread information of theirchoice beyond the reach of their original followers.Twitter has become a prominent broadcast-ing medium, taking priority over traditional newssources (Teevan et al, 2011).
Shared informationthrough this channel spreads faster than would havebeen possible with conventional news sites or RSSfeeds and can reach a far wider population base.However, the proliferation of user-generated con-tent comes at a price.
Over 340 millions of tweetsare being generated daily amounting to thousandsof tweets per second!2 Twitter?s own search en-gine handles more than 1.6 billion search queries perday.3 This enormous amount of data renders it in-feasible to browse the entire Twitter network; evenif this was possible, it would be extremely difficultfor users to find information they are interested in.A hypothetical tweet recommendation system could1For details see http://blog.twitter.com/2012/03/twitter-turns-six.html2In fact, the peak record is 6,939 tweets per second, reportedby http://blog.twitter.com/2011/03/numbers.html.3See http://engineering.twitter.com/2011/05/engineering-behind-twitters-new-search.html516alleviate this acute information overload, e.g., bylimiting the stream of tweets to those of interest tothe user, or by discovering intriguing content outsidethe user?s following network.The tweet recommendation task is challenging forseveral reasons.
Firstly, Twitter does not merelyconsist of a set of tweets.
Rather, it contains manylatent networks including the following relationshipsamong users and the retweeting linkage (which in-dicates information diffusion).
Secondly, the rec-ommendations ought to be of interest to the userand likely to to attract user response (e.g., to beretweeted).
Thirdly, recommendations should bepersonalized (Cho and Schonfeld, 2007; Yan et al,2011), avoid redundancy, and demonstrate diversity.In this paper we present a graph-theoretic approachto tweet recommendation that attempts to addressthese challenges.Our recommender operates over a heterogeneousnetwork that connects the users (or authors) and thetweets they produce.
The user network representslinks among authors based on their following be-havior, whereas the tweet network connects tweetsbased on content similarity.
A third bipartite graphties the two together.
Tweet and author entities inthis network are ranked simultaneously following aco-ranking algorithm (Zhou et al, 2007).
The mainintuition behind co-ranking is that there is a mu-tually reinforcing relationship between authors andtweets that could be reflected in the rankings.
Tweetsare important if they are related to other importanttweets and authored by important users who in turnare related to other important users.
The model ex-ploits this mutually reinforcing relationship betweentweets and their authors and couples two randomwalks, one on the tweet graph and one on the authorgraph, into a combined one.
Rather than creating aglobal ranking over all tweets in a collection, we ex-tend this framework to individual users and producepersonalized recommendations.
Moreover, we in-corporate diversity by allowing the random walk onthe tweet graph to be time-variant (Mei et al, 2010).Experimental results on a real-world dataset con-sisting of 364,287,744 tweets from 9,449,542 usersshow that the co-ranking approach substantially im-proves performance over the state of the art.
We ob-tain a relative improvement of 18.3% (in nDCG) and7.8% (in MAP) over the best comparison system.2 Related WorkTweet Search Given the large amount of tweetsbeing posted daily, ranking strategies have be-come extremely important for retrieving informationquickly.
Many websites currently offer a real-timesearch service which returns ranked lists of Twit-ter posts or shared links according to user queries.Ranking methods used by these sites employ threecriteria, namely recency, popularity and content rel-evance (Dong et al, 2010).
State-of-art tweet re-trieval methods include a linear regression model bi-ased towards text quality with a regularization factorinspired by the hypothesis that documents similarin content may have similar quality (Huang et al,2011).
Duan et al (2010) learn a ranking model us-ing SVMs and features based on tweet content, therelations among users, and tweet specific character-istics (e.g., urls, number of retweets).Tweet Recommendation Previous work has alsofocused on tweet recommendation systems, assum-ing no explicit query is provided by the users.Collaborative filtering is perhaps the most obviousmethod for recommending tweets (Hannon et al,2010).
Chen et al (2010) investigate how to se-lect interesting URLs linked from Twitter and rec-ommend the top ranked ones to users.
Their rec-ommender takes three dimensions into account: thesource, the content topic, and social voting.
Sim-ilarly, Abel et al (2011a; 2011b; 2011c) recom-mend external websites linked to Twitter.
Theirmethod incorporates user profile modeling and tem-poral recency, but they do not utilize the socialnetworks among users.
R. et al (2009) proposea diffusion-based recommendation framework es-pecially for tweets representing critical events byconstructing a diffusion graph.
Hong et al (2011)recommend tweets based on popularity related fea-tures.
Ramage et al (2010) investigate which topicsusers are interested in following a Labeled-LDA ap-proach, by deciding whether a user is in the followeelist of a given user or not.
Uysal and Croft (2011) es-timate the likelihood of a tweet being reposted froma user-centric perspective.Our work also develops a tweet recommendationsystem.
Our model exploits the information pro-vided by the tweets and the underlying social net-works in a unified co-ranking framework.
Although517these sources have been previously used to searchor recommend tweets, our model considers themsimultaneously and produces a ranking that is in-formed by both.
Furthermore, we argue that thegraph-theoretic framework upon which co-rankingoperates is beneficial as it allows to incorporate per-sonalization (we provide user-specific rankings) anddiversity (the ranking is optimized so as to avoid re-dundancy).
The co-ranking framework has been ini-tially developed for measuring scientific impact andmodeling the relationship between authors and theirpublications (Zhou et al, 2007).
However, the adap-tation of this framework to the tweet recommenda-tion task is novel to our knowledge.3 Tweet Recommendation FrameworkOur method operates over a heterogeneous networkthat connects three graphs representing the tweets,their authors and the relationships between them.Let G denote the heterogeneous graph with nodes Vand edges E, and G = (V,E) = (VM ?VU ,EM ?EU ?EMU).
G is divided into three subgraphs, GM, GUand GMU .
GM = (VM,EM) is a weighted undirectedgraph representing the tweets and their relationships.Let VM = {mi|mi ?VM} denote a collection of |VM|tweets and EM the set of links representing relation-ships between them.
The latter are established bymeasuring how semantically similar any two tweetsare (see Section 3.4 for details).
GU = (VU ,EU) isan unweighted directed graph representing the so-cial ties among Twitter users.
VU = {ui|ui ?
VU} isthe set of users with size |VU |.
Links EU amongusers are established by observing their followingbehavior.
GMU = (VMU ,EMU) is an unweighted bi-partite graph that ties GM and GU together and repre-sents tweet-author relationships.
The graph consistsof nodes VMU = VM ?VU and edges EMU connect-ing each tweet with all of its authors.
Typically, atweet m is written by only one author u. However,because of retweeting we treat all users involved inreposting a tweet as ?co-authors?.
The three subnet-works are illustrated in Figure 1.The framework includes three random walks, oneon GM, one on GU and one on GMU .
A random walkon a graph is a Markov chain, its states being thevertices of the graph.
It can be described by a squaren?
n matrix M, where n is the number of verticesin the graph.
M is a stochastic matrix prescribingFigure 1: Tweet recommendation based on a co-rankingframework including three sub-networks.
The undirectedlinks between tweets indicate semantic correlation.
Thedirected links between users denotes following.
A bipar-tite graph (whose edges are shown with dashed lines) tiesthe tweet and author networks together.the transition probabilities from one vertex to thenext.
The framework couples the two random walkson GM, and GU that rank tweets and theirs authors inisolation.
and allows to obtain a more global rank-ing by taking into account their mutual dependence.In the following sections we first describe how weobtain the rankings on GM and GU , and then moveon to discuss how the two are coupled.3.1 Ranking the Tweet GraphPopularity We rank the tweet network follow-ing the PageRank paradigm (Brin and Page, 1998).Consider a random walk on GM and let M be thetransition matrix (defined in Section 3.4).
Fix somedamping factor ?
and say that at each time step withprobability (1-?)
we stick to random walking andwith probability ?
we do not make a usual randomwalk step, but instead jump to any vertex, chosenuniformly at random:m = (1??
)MTm+?|VM|11T (1)Here, vector m contains the ranking scores for thevertices in GM.
The fact that there exists a unique so-518lution to (1) follows from the random walk M beingergodic (?
>0 guarantees irreducibility, because wecan jump to any vertex).
MT is the transpose of M.1 is the vector of |VM| entries, each being equal toone.
Let m?
RVM , ||m||1 = 1 be the only solution.Personalization The standard PageRank algo-rithm performs a random walk, starting from anynode, then randomly selects a link from that node tofollow considering the weighted matrix M, or jumpsto a random node with equal probability.
It pro-duces a global ranking over all tweets in the col-lection without taking specific users into account.As there are billions of tweets available on Twit-ter covering many diverse topics, it is reasonableto assume that an average user will only be inter-ested in a small subset (Qiu and Cho, 2006).
Weoperationalize a user?s topic preference as a vec-tor t = [t1, t2, .
.
.
, tn]1?n, where n denotes the num-ber of topics, and ti represents the degree of prefer-ence for topic i.
The vector t is normalized suchthat ?ni=1 ti = 1.
Intuitively, such vectors will bedifferent for different users.
Note that user prefer-ences can be also defined at the tweet (rather thantopic) level.
Although tweets can illustrate user in-terests more directly, in most cases a user will onlyrespond to a small fraction of tweets.
This meansthat most tweets will not provide any informationrelating to a user?s interests.
The topic preferencevector allows to propagate such information (basedon whether a tweet has been reposted or not) to othertweets within the same topic cluster.Given n topics, we obtain a topic distribution ma-trix D using Latent Dirichlet Allocation (Blei et al,2003).
Let Di j denote the probability of tweet mi tobelong to topic t j.
Consider a user with a topic pref-erence vector t and topic distribution matrix D. Wecalculate the response probability r for all tweets forthis user as:r = tDT (2)where r=[r1, r2, .
.
.
, rVM ]1?|VM | represents the re-sponse probability vector and ri the probability for auser to respond to tweet mi.
We normalize r so that?ri?r ri = 1.
Now, given the observed response prob-ability vector r = [r1,r2, .
.
.
,rw]1?w, where w<|VM|for a given user and the topic distribution ma-trix D, our task is estimate the topic preferencevector t. We do this using maximum-likelihoodestimation.
Assuming a user has responded to wtweets, we approximate t so as to maximize the ob-served response probability.
Let r(t) = tDT.
As-suming all responses are independent, the probabil-ity for w tweets r1, r2, .
.
.
, rw is then ?wi=1 ri(t) undera given t. The value of t is chosen when the proba-bility is maximized:t = argmaxt( w?i=1ri(t))(3)In a simple random walk, it is assumed that allnodes in the matrix M are equi-probable before thewalk.
In contrast, we use the topic preference vectoras a prior on M. Let Diag(r) denote a diagonal ma-trix whose eigenvalue is vector r. Then m becomes:m = (1??
)[Diag(r)M]Tm+?r= (1??
)[Diag(tDT)M]Tm+?tDT(4)Diversity We would also like our output to bediverse without redundant information.
Unfortu-nately, equation (4) will have the opposite effect,as it assigns high scores to closely connected nodecommunities.
A greedy algorithm such as Maxi-mum Marginal Relevance (Carbonell and Goldstein,1998; Wan et al, 2007; Wan et al, 2010) mayachieve diversity by iteratively selecting the mostprestigious or popular vertex and then penalizing thevertices ?covered?
by those that have been alreadyselected.
Rather than adopting a greedy vertex selec-tion method, we follow DivRank (Mei et al, 2010)a recently proposed algorithm that balances popular-ity and diversity in ranking, based on a time-variantrandom walk.
In contrast to PageRank, DivRank as-sumes that the transition probabilities change overtime.
Moreover, it is assumed that the transitionprobability from one state to another is reinforced bythe number of previous visits to that state.
At eachstep, the algorithm creates a dynamic transition ma-trix M(.).
After z iterations, the matrix becomes:M(z) = (1??
)M(z?1) ?m(z?1)+?tDT (5)and hence, m can be calculated as:m(z) = (1??
)[Diag(tDT)M(z)]Tm+?tDT (6)Equation (5) increases the probability for nodeswith higher popularity.
Nodes with high weights are519likely to ?absorb?
the weights of their neighbors di-rectly, and the weights of their neighbors?
neighborsindirectly.
The process iteratively adjusts the ma-trix M according to m and then updates m accordingto the changed M. Essentially, the algorithm favorsnodes with high popularity and as time goes by thereemerges a rich-gets-richer effect (Mei et al, 2010).3.2 Ranking the Author GraphAs mentioned earlier, we build a graph of au-thors (and obtain the affinity U) using the follow-ing linkage.
We rank the author network usingPageRank analogously to equation (1).
Besidespopularity, we also take personalization into ac-count.
Intuitively, users are likely to be interestedin their friends even if these are relatively unpopu-lar.
Therefore, for each author, we include a vec-tor p = [p1, p2, .
.
.
, p|VU |]1?|VU | denoting their prefer-ence for other authors.
The preference factor for au-thor u toward other authors ui is defined as:pui =#tweets from ui#tweets of u(7)which represents the proportion of tweets inheritedfrom user ui.
A large pui means that u is more likelyto respond to ui?s tweets.In theory, we could also apply DivRank on the au-thor graph.
However, as the authors are unique, weassume that they are sufficiently distinct and there isno need to promote diversity.3.3 The Co-Ranking AlgorithmSo far we have described how we rank the networkof tweets GM and their authors GU independentlyfollowing the PageRank paradigm.
The co-rankingframework includes a random walk on GM, GU ,and GMU .
The latter is a bipartite graph representingwhich tweets are authored by which users.
The ran-dom walks on GM and GU are intra-class randomwalks, because take place either within the tweets?or the users?
networks.
The third (combined) ran-dom walk on GMU is an inter-class random walk.
Itis sufficient to describe it by a matrix MU|VM|?|VU|and a matrix UM|VU|?|VM|, since GMU is bipartite.One intra-class step changes the probability distribu-tion from (m, 0) to (Mm, 0) or from (0, u) to (0, Uu),while one inter-class step changes the probabilitydistribution from (m, u) to (UMT u, MUT m).
Thedesign of M, U, MU and UM is detailed in Sec-tion 3.4.The two intra-class random walks are coupledusing the inter-class random walk on the bipartitegraph.
The coupling is regulated by ?, a parameterquantifying the importance of GMU versus GM andGU .
In the extreme case, if ?
is set to 0, there is nocoupling.
This amounts to separately ranking tweetsand authors by PageRank.
In general, ?
representsthe extent to which the ranking of tweets and theirauthors depend on each other.There are two intuitions behind the co-ranking al-gorithm: (1) a tweet is important if it associates toother important tweets, and is authored by impor-tant users and (2) a user is important if they asso-ciate to other important users, and they write impor-tant tweets.
We formulate these intuitions using thefollowing iterative procedure:Step 1 Compute tweet saliency scores:m(z+1) = (1??
)([Diag(r)M(z)]T)m(z)+?UMTu(z)m(z+1) = m(z+1)/||m(z+1)|| (8)Step 2 Compute author saliency scores:u(z+1) = (1??
)([Diag(p)U]T)u(z)+?MUTm(z)u(z+1) = u(z+1)/||u(z+1)|| (9)Here, m(z) and u(z) are the ranking vectors for tweetsand authors for the z-th iteration.
To guarantee con-vergence, m and u are normalized after each itera-tion.
Note that the tweet transition matrix M is dy-namic due to the computation of diversity while theauthor transition matrix U is static.
The algorithmtypically converges when the difference between thescores computed at two successive iterations for anytweet/author falls below a threshold ?
(set to 0.001in this study).3.4 Affinity MatricesThe co-ranking framework is controlled by fouraffinity matrices: M, U, MU and UM.
In this sectionwe explain how these matrices are defined in moredetail.The tweet graph is an undirected weighted graph,where an edge between two tweets mi and m j repre-sents their cosine similarity.
An adjacency matrix M520describes the tweet graph where each entry corre-sponds to the weight of a link in the graph:Mij =F (mi,m j)?kF (mi,mk), F (mi,m j) =~mi ?~m j||~mi||||~m j||(10)where F (.)
is the cosine similarity and ~m is a termvector corresponding to tweet m. We treat a tweetas a short document and weight each term with tf.idf(Salton and Buckley, 1988), where tf is the term fre-quency and idf is the inverse document frequency.The author graph is a directed graph based on thefollowing linkage.
When ui follows u j, we add a linkfrom ui to u j.
Let the indicator function I (ui,u j) de-note whether ui follows u j.
The adjacency matrix Uis then defined as:Uij =I (ui,u j)?k I (ui,uk), I (ui,u j)={1if ei j ?
EU0if ei j /?
EU(11)In the bipartite tweet-author graph GMU , theentry EMU(i, j) is an indicator function denotingwhether tweet mi is authored by user u j:A(mi,u j) ={1 if ei j ?
EMU0 if ei j /?
EMU(12)Through EMU we define MU and UM, using theweight matrices MU= [W?ij] and UM=[W?ji], con-taining the conditional probabilities of transitioningfrom mi to u j and vice versa:W?ij =A(mi,u j)?kA(mi,uk), W?ji =A(mi,u j)?kA(mk,u j)(13)4 Experimental SetupData We crawled Twitter data from 23 seed users(who were later invited to manually evaluate theoutput of our system).
In addition, we collectedthe data of their followees and followers by travers-ing the following edges, and exploring all newlyincluded users in the same way until no newusers were added.
This procedure resulted ina relatively large dataset consisting of 9,449,542users, 364,287,744 tweets, 596,777,491 links, and55,526,494 retweets.
The crawler monitored thedata from 3/25/2011 to 5/30/2011.
We used approx-imately one month of this data for training and therest for testing.Before building the graphs (i.e., the tweet graph,the author graph, and the tweet-author graph), thedataset was preprocessed as follows.
We removedtweets of low linguistic quality and subsequentlydiscarded users without any linkage to the remain-ing tweets.
We measured linguistic quality follow-ing the evaluation framework put forward in Pitleret al (2010).
For instance, we measured the out-of-vocabulary word ratio (as a way of gauging spellingerrors), entity coherence, fluency, and so on.
We fur-ther removed stopwords and performed stemming.Parameter Settings We ran LDA with 500 itera-tions of Gibbs sampling.
The number of topics nwas set to 100 which upon inspection seemed gen-erally coherent and meaningful.
We set the damp-ing factor ?
to 0.15 following the standard PageRankparadigm.
We opted for more or less generic param-eter values as we did not want to tune our frame-work to the specific dataset at hand.
We examinedthe parameter ?
which controls the balance of thetweet-author graph in more detail.
We experimentedwith values ranging from 0 to 0.9, with a step sizeof 0.1.
Small ?
values place little emphasis on thetweet graph, whereas larger values rely more heav-ily on the author graph.
Mid-range values take bothgraphs into account.
Overall, we observed betterperformance with values larger than 0.4.
This sug-gests that both sources of information ?
the contentof the tweets and their authors ?
are important forthe recommendation task.
All our experiments usedthe same ?
value which was set to 0.6.System Comparison We compared our approachagainst three naive baselines and three state-of-the-art systems recently proposed in the literature.
Allcomparison systems were subject to the same fil-tering and preprocessing procedures as our own al-gorithm.
Our first baseline ranks tweets randomly(Random).
Our second baseline ranks tweets ac-cording to token length: longer tweets are rankedhigher (Length).
The third baseline ranks tweetsby the number of times they are reposted assum-ing that more reposting is better (RTnum).
We alsocompared our method against Duan et al (2010).Their model (RSVM) ranks tweets based on tweetcontent features and tweet authority features usingthe RankSVM algorithm (Joachims, 1999).
Ourfifth comparison system (DTC) was Uysal and Croft521(2011) who use a decision tree classifier to judgehow likely it is for a tweet to be reposted by a spe-cific user.
This scenario is similar to ours when rank-ing tweets by retweet likelihood.
Finally, we com-pared against Huang et al (2011) who use weightedlinear combination (WLC) to grade the relevance ofa tweet given a query.
We implemented their modelwithout any query-related features as in our settingwe do not discriminate tweets depending on theirrelevance to specific queries.Evaluation We evaluated system output in twoways, i.e., automatically and in a user study.
Specif-ically, we assume that if a tweet is retweeted it is rel-evant and is thus ranked higher over tweets that havenot been reposted.
We used our algorithm to predicta ranking for the tweets in the test data which wethen compared against a goldstandard ranking basedon whether a tweet has been retweeted or not.
Wemeasured ranking performance using the normalizedDiscounted Cumulative Gain (nDCG; Ja?rvelin andKeka?la?inen (2002)):nDCG(k,VU) =1|VU|?u?VU1Zuk?i=12rui ?1log(1+ i)(14)where VU denotes users, k indicates the top-k posi-tions in a ranked list, and Zu is a normalization factorobtained from a perfect ranking for a particular user.rui is the relevance score (i.e., 1: retweeted, 0: notretweeted) for the i-th tweet in the ranking list foruser u.We also evaluated system output in terms of MeanAverage Precision (MAP), under the assumptionthat retweeted tweets are relevant and the rest irrele-vant:MAP =1|VU|?u?VU1Nuk?i=1Pui ?
rui (15)where Nu is the number of reposted tweets for user u,and Pui is the precision at i-th position for user u(Manning et al, 2008).The automatic evaluation sketched above does notassess the full potential of our recommendation sys-tem.
For instance, it is possible for the algorithm torecommend tweets to users with no linkage to theirpublishers.
Such tweets may be of potential interest,however our goldstandard data can only provide in-formation for tweets and users with following links.System nDCG@5 nDCG@10 nDCG@25 nDCG@50 MAPRandom 0.068 0.111 0.153 0.180 0.167Length 0.275 0.288 0.298 0.335 0.258RTNum 0.233 0.219 0.225 0.249 0.239RSVM 0.392 0.400 0.421 0.444 0.558DTC 0.441 0.468 0.492 0.473 0.603WLC 0.404 0.421 0.437 0.464 0.592CoRank 0.519 0.546 0.550 0.585 0.617Table 1: Evaluation of tweet ranking output produced byour system and comparison baselines against goldstan-dard data.System nDCG@5 nDCG@10 nDCG@25 nDCG@50 MAPRandom 0.081 0.103 0.116 0.107 0.175Length 0.291 0.307 0.246 0.291 0.264RTNum 0.258 0.318 0.343 0.346 0.257RSVM 0.346 0.443 0.384 0.414 0.447DTC 0.545 0.565 0.579 0.526 0.554WLC 0.399 0.447 0.460 0.481 0.506CoRank 0.567 0.644 0.715 0.643 0.628Table 2: Evaluation of tweet ranking output produced byour system and comparison baselines against judgmentselicited by users.We therefore asked the 23 users whose Twitter dataformed the basis of our corpus to judge the tweetsranked by our algorithm and comparison systems.The users were asked to read the systems?
recom-mendations and decide for every tweet presented tothem whether they would retweet it or not, under theassumption that retweeting takes place when usersfind the tweet interesting.In both automatic and human-based evaluationswe ranked all tweets in the test data.
Then for eachdate and user we selected the top 50 ones.
OurnDCG and MAP results are averages over users anddates.5 ResultsOur results are summarized in Tables 1 and 2.
Ta-ble 1 reports results when model performance isevaluated against the gold standard ranking obtainedfrom the Twitter network.
In Table 2 model per-formance is compared against rankings elicited byusers.As can be seen, the Random method performsworst.
This is hardly surprising as it recommendstweets without any notion of their importance or userinterest.
Length performs considerably better than522System nDCG@5 nDCG@10 nDCG@25 nDCG@50 MAPPageRank 0.493 0.481 0.509 0.536 0.604PersRank 0.501 0.542 0.558 0.560 0.611DivRank 0.487 0.505 0.518 0.523 0.585CoRank 0.519 0.546 0.550 0.585 0.617Table 3: Evaluation of individual system componentsagainst goldstandard data.System nDCG@5 nDCG@10 nDCG@25 nDCG@50 MAPPageRank 0.557 0.549 0.623 0.559 0.588PersRank 0.571 0.595 0.655 0.613 0.601DivRank 0.538 0.591 0.594 0.547 0.589CoRank 0.637 0.644 0.715 0.643 0.628Table 4: Evaluation of individual system componentsagainst human judgments.Random.
This might be due to the fact that infor-mativeness is related to tweet length.
Using merelythe number of retweets does not seem to capture thetweet importance as well as Length.
This suggeststhat highly retweeted posts are not necessarily in-formative.
For example, in our data, the most fre-quently reposted tweet is a commercial advertise-ment calling for reposting!The supervised systems (RSVM, DTC, andWLC) greatly improve performance over the naivebaselines.
These methods employ standard machinelearning algorithms (such as SVMs, decision treesand linear regression) on a large feature space.
Asidefrom the learning algorithm, their main differencelies in the selection of the feature space, e.g., the waycontent is represented and whether authority is takeninto account.
DTC performs best on most evalua-tion criteria.
However, neither DTC nor RSVM, orWLC take personalization into account.
They gen-erate the same recommendation lists for all users.Our co-ranking algorithm models user interest withrespect to the content of the tweets and their pub-lishers.
Moreover, it attempts to create diverse out-put and has an explicit mechanism for minimizingredundancy.
In all instances, using both DCG andMAP, it outperforms the comparison systems.
Inter-estingly, the performance of CoRank is better whenmeasured against human judgments.
This indicatesthat users are interested in tweets that fall outsidethe scope of their followers and that recommenda-tion can improve user experience.We further examined the contribution of the in-dividual components of our system to the tweetrecommendation task.
Tables 3 and 4 show howthe performance of our co-ranking algorithm varieswhen considering only tweet popularity using thestandard PageRank algorithm, personalization (Per-sRank), and diversity (DivRank).
Note that DivRankis only applied to the tweet graph.
The PageR-ank algorithm on its own makes good recommenda-tions, while incorporating personalization improvesthe performance substantially, which indicates thatindividual users show preferences to specific topicsor other users.
Diversity on its own does not seemto make a difference, however it improves perfor-mance when combined with personalization.
Intu-itively, users are more likely to repost tweets fromtheir followees, or tweets closely related to thoseretweeted previously.6 ConclusionsWe presented a co-ranking framework for a tweetrecommendation system that takes popularity, per-sonalization and diversity into account.
Central toour approach is the representation of tweets andtheir users in a heterogeneous network and the abil-ity to produce a global ranking that takes both in-formation sources into account.
Our model obtainssubstantial performance gains over competitive ap-proaches on a large real-world dataset (it improvesby 18.3% in DCG and 7.8% in MAP over the bestbaseline).
Our experiments suggest that improve-ments are due to the synergy of the two informationsources (i.e., tweets and their authors).
The adoptedgraph-theoretic framework is advantageous in thatit allows to produce user-specific recommendationsand incorporate diversity in a unified model.
Evalua-tion with actual Twitter users shows that our recom-mender can indeed identify interesting informationthat lies outside the the user?s immediate followingnetwork.
In the future, we plan to extend the co-ranking framework so as to incorporate informationcredibility and temporal recency.Acknowledgments This work was partiallyfunded by the Natural Science Foundation of Chinaunder grant 60933004, and the Open Fund of theState Key Laboratory of Software DevelopmentEnvironment under grant SKLSDE-2010KF-03.Rui Yan was supported by a MediaTek Fellowship.523ReferencesFabian Abel, Qi Gao, Geert-Jan Houben, and Ke Tao.2011a.
Analyzing temporal dynamics in Twitter pro-files for personalized recommendations in the socialweb.
In Proceedings of the ACM Web Science Confer-ence 2011, pages 1?8, Koblenz, Germany.Fabian Abel, Qi Gao, Geert-Jan Houben, and Ke Tao.2011b.
Analyzing user modeling on Twitter for per-sonalized news recommendations.
User Modeling,Adaptation and Personalization, pages 1?12.Fabian Abel, Qi Gao, Geert-Jan Houben, and Ke Tao.2011c.
Semantic enrichment of twitter posts for userprofile construction on the social web.
The SemanicWeb: Research and Applications, pages 375?389.David M. Blei, Andrew Y. Ng, and Michael I. Jordan.2003.
Latent Dirichlet alddress.
Journal of MachineLearning Research, 3:993?1022.Sergey Brin and Lawrence Page.
1998.
The anatomyof a large-scale hypertextual web search engine.
Pro-ceedings of the 7th International Conference on WorldWide Web, 30(1-7):107?117.Jaime Carbonell and Jade Goldstein.
1998.
The use ofMMR, diversity-based reranking for reordering doc-uments and producing summaries.
In Proceedingsof the 21st Annual International ACM SIGIR Confer-ence on Research and Development in Information Re-trieval, pages 335?336, Melbourne, Australia.Jilin Chen, Rowan Nairn, Les Nelson, Michael Bernstein,and Ed Chi.
2010.
Short and tweet: experiments onrecommending content from information streams.
InProceedings of the 28th International Conference onHuman Factors in Computing Systems, pages 1185?1194, Atlanta, Georgia.Junghoo Cho and Uri Schonfeld.
2007.
Rankmasscrawler: a crawler with high personalized pagerankcoverage guarantee.
In Proceedings of the 33rd Inter-national Conference on Very Large Data Bases, pages375?386, Vienna, Austria.Anlei Dong, Ruiqiang Zhang, Pranam Kolari, JingBai, Fernando Diaz, Yi Chang, Zhaohui Zheng, andHongyuan Zha.
2010.
Time is of the essence: improv-ing recency ranking using Twitter data.
In Proceed-ings of the 19th International Conference on WorldWide Web, pages 331?340, Raleigh, North Carolina.Yajuan Duan, Long Jiang, Tao Qin, Ming Zhou, andHeung-Yeung Shum.
2010.
An empirical study onlearning to rank of tweets.
In Proceedings of the 23rdInternational Conference on Computational Linguis-tics, pages 295?303, Beijing, China.John Hannon, Mike Bennett, and Barry Smyth.
2010.Recommending twitter users to follow using contentand collaborative filtering approaches.
In Proceedingsof the 4th ACM Conference on Recommender Systems,pages 199?206, Barcelona, Spain.Liangjie Hong, Ovidiu Dan, and Brian D. Davison.
2011.Predicting popular messages in Twitter.
In Proceed-ings of the 20th International Conference Companionon World Wide Web, pages 57?58, Hyderabad, India.Minlie Huang, Yi Yang, and Xiaoyan Zhu.
2011.Quality-biased ranking of short texts in microbloggingservices.
In Proceedings of the 5th International JointConference on Natural Language Processing, pages373?382, Chiang Mai, Thailand.Kalervo Ja?rvelin and Jaana Keka?la?inen.
2002.
Cumu-lated gain-based evaluation of IR techniques.
ACMTransactions on Information Systems, 20:422?446.Thorsten Joachims.
1999.
Making large-scale svm learn-ing practical.
In Advances in Kernel Methods: SupportVector Learning, pages 169?184.
MIT press.Christopher D. Manning, Prabhakar Raghavan, and Hin-rich Schutze.
2008.
Introduction to Information Re-trieval, volume 1.
Cambridge University Press.Qiaozhu Mei, Jian Guo, and Dragomir Radev.
2010.Divrank: the interplay of prestige and diversity ininformation networks.
In Proceedings of the 16thACM SIGKDD International Conference on Knowl-edge Discovery and Data Mining, pages 1009?1018,Washington, DC.Emily Pitler, Annie Louis, and Ani Nenkova.
2010.Automatic evaluation of linguistic quality in multi-document summarization.
In Proceedings of the 48thAnnual Meeting of the Association for ComputationalLinguistics, pages 544?554, Uppsala, Sweden.Feng Qiu and Junghoo Cho.
2006.
Automatic identi-fication of user interest for personalized search.
InProceedings of the 15th International Conference onWorld Wide Web, pages 727?736, Edinburgh, Scot-land.Sun Aaron R., Cheng Jiesi, Zeng, and Daniel Dajun.2009.
A novel recommendation framework for micro-blogging based on information diffusion.
In Pro-ceedings of the 19th Annual Workshop on InformationTechnologies and Systems, pages 199?216, Phoenix,Arizona.Daniel Ramage, Susan Dumais, and Dan Liebling.
2010.Characterizing microblogs with topic models.
In In-ternational AAAI Conference on Weblogs and SocialMedia, pages 130?137.
The AAAI Press.Gerard Salton and Christopher Buckley.
1988.
Term-weighting approaches in automatic text retrieval.
In-formation Processing and Management, 24(5):513?523.Jaime Teevan, Daniel Ramage, and Meredith Ringel Mor-ris.
2011.
#Twittersearch: a comparison of microblogsearch and web search.
In Proceedings of the 4th ACM524International Conference on Web Search and DataMining, pages 35?44, Hong Kong, China.Ibrahim Uysal and W. Bruce Croft.
2011.
User orientedtweet ranking: a filtering approach to microblogs.In Proceedings of the 20th ACM International Con-ference on Information and Knowledge Management,pages 2261?2264, Glasgow, Scotland.Xiaojun Wan, Jianwu Yang, and Jianguo Xiao.
2007.Single document summarization with document ex-pansion.
In Proceedings of the 22nd Conferenceon Artificial Intelligence, pages 931?936, Vancouver,British Columbia.Xiaojun Wan, Huiying Li, and Jianguo Xiao.
2010.Cross-language document summarization based onmachine translation quality prediction.
In Proceed-ings of the 48th Annual Meeting of the Association forComputational Linguistics, pages 917?926, Uppsala,Sweden.Rui Yan, Jian-Yun Nie, and Xiaoming Li.
2011.
Sum-marize what you are interested in: An optimiza-tion framework for interactive personalized summa-rization.
In Proceedings of the 2011 Conference onEmpirical Methods in Natural Language Processing,pages 1342?1351.
Association for Computational Lin-guistics.Ding Zhou, Sergey A. Orshanskiy, Hongyuan Zha, andC.
Lee Giles.
2007.
Co-ranking authors and docu-ments in a heterogeneous network.
In Proceedings ofthe 7th IEEE International Conference on Data Min-ing, pages 739?744.
IEEE.525
