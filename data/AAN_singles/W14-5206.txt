Proceedings of the Workshop on Open Infrastructures and Analysis Frameworks for HLT, pages 53?59,Dublin, Ireland, August 23rd 2014.A Conceptual Framework of Online Natural Language ProcessingPipeline ApplicationChunqi Shi, Marc Verhagen, James PustejovskyBrandeis UniversityWaltham, United States{shicq, jamesp, marc}@cs.brandeis.eduAbstractThis paper describes a conceptual framework that enables online NLP pipelined applications tosolve various interoperability issues and data exchange problems between tools and platforms;e.g., tokenizers and part-of-speech taggers from GATE, UIMA, or other platforms.
We proposea restful wrapping solution, which allows for universal resource identification for data manage-ment, a unified interface for data exchange, and a light-weight serialization for data visualization.In addition, we propose a semantic mapping-based pipeline composition, which allows expertsto interactively exchange data between heterogeneous components.1 IntroductionThe recent work on open infrastructures for human language technology (HLT) research and develop-ment has stressed the important role that interoperability should play in developing Natural LanguageProcessing (NLP) pipelines.
For example, GATE (Cunningham et al., 2002), UIMA (Ferrucci and Lally,2004), and NLTK (Loper and Bird, 2002) all allow integrating components from different categoriesbased on common XML, or object-based (e.g., Java or Python) data presentation.
The major categoriesof components included in these capabilities include: Sentence Splitter, Phrase Chunker, Tokenizer,Part-of-Speech (POS) Tagger, Shallow Parser, Name Entity Recognizer (NER), Coreference Solution,etc.
Pipelined NLP applications can be built by composing several components; for example, a textanalysis application such as ?relationship analysis from medical records?
can be composed by SentenceSplitter, Tokenizer, POS Tagger, NER, and Coreference Resolution components.In addition to interoperability, the very availability of a component can also play an important role inbuilding online application based on distributed components, especially in tasks such as online testingand judging new NLP techniques by comparing to existing components.
For example, the Language Grid(Ishida, 2006) addresses issues relating to accessing components from different locations or providersbased on Service-Oriented Architecture (SOAs) models.
In this paper, we explore structural, conceptualinteroperability, and availability issues, and provide a conceptual framework for building online pipelinedNLP applications.The conventional view of structural interoperability is that a common set of data formats and com-munication protocols should be specified by considering data management, data exchange, and datavisualization issues.
Data management determines how to access, store and locate sources of data.
Forexample, GATE provides pluggable document readers or writers and XML (with meta-data configura-tion) serialization of reusable objected-based data.
UIMA provides document or database readers andwriters and XMI serialization of common object-based data structures.
The Language Grid provides Javaobject serialization of data collections.
Data exchange strategies describe how components communi-cate their data.
For example, GATE provides CREOLE (Collection of REusable Objects for LanguageEngineering) data collections for data exchange.
UIMA provides CAS (Common Analysis Structure),and NLTK provides API modules for each component type.
Similarly, the Language Grid provides LSIThis work is licenced under a Creative Commons Attribution 4.0 International License.
Page numbers and proceedings footerare added by the organizers.
License details: http://creativecommons.org/licenses/by/4.0/53(Language Service Interface) for a concrete ontology for a given language infrastructure.
Data visu-alization facilitates manual reading, editing and adjudication.
For example, GATE and UIMA provideXML-based viewers for selection, searching, matching and comparison functionality.The conventional view of conceptual interoperability is that expert knowledge should be used in bridg-ing heterogeneous components.
For example, GATE provides integration plugins for UIMA, OpenNLP,and Stanford NLP, where experts have already engineered the specific knowledge on conversion strate-gies among these components.
This leaves open the question of how one would ensure the interoperablepipelining of new or never-before-seen heterogeneous components, for which experts have not encodedbridge protocols.In order to achieve an open infrastructure of online pipelined applications, we will argue two pointsregarding the conceptual design, considering both interoperability and availability:?
Universal resource identification, a SQL-like data management, and a light-weight data serializationshould be added with structural interoperability in online infrastructure of distributed components.?
By verifying and modifying inconsistent ontology mappings, experts can interactively learn con-ceptual interoperability for online heterogeneous components pipelines.2 Data, Tool and Knowledge TypesInteroperability in building pipelined NLP applications is intended ensure the exchange of informationbetween the different NLP tools.
For this purpose, existing infrastructures like GATE or UIMA havepaid a lot of attention to common entity based data exchanges between the tools.
When exchangingdata between heterogeneous tools (e.g., the GATE tokenizer pipelined with the NLTK POS tagger),the knowledge of how these different entity based NLP tools can work together becomes much moreimportant, because there might be exchange problems between heterogeneous data or tool information,and we may need specific knowledge to fix them.
Thus, when considering interoperability, the main flowof information should be exchanged in the open infrastructure consisting of source data information,NLP tools information, and the knowledge that allows the tools to work together.What are the main entity types of data and tools in designing an open infrastructure for online NLPpipeline applications?
From an abstract view of how linguistic analysis is related to human knowledge,there are the following: Morphological, Lexical, Syntactic, Semantic, Pragmatic tool classifications; andUtterance, Phoneme, Morpheme, Token, Syntactic Structure, Semantic Interpretation, and Pragmatic In-terpretation data classifications.
(Manaris, 1998; Pustejovsky and Stubbs, 2013).
From a concrete appli-cation perspective, where tools are available for concrete text mining for communities such as OpenNLP,Stanford CoreNLP and NLTK, there are classification tools such as Sentence Splitter, Tokenizer, POSTagger, Phrase Chunker, Shallow Parser, NER, Lemmatizer, Coreference; and data classifications suchas Document, Sentence, Annotation, and Feature (Cunningham et al., 2002).LexicalSyntacticSemanticPragmaticMorphologicalFigure 1: A NLP pipeline can be a (sub)-process of an abstract five-step processPOSTaggingNoun-phrasechunkingLemmatizationNERSentence SplitterTokenizationCoreferenceResolutionFigure 2: An example NLP pipeline of a concrete six-step process54The knowledge types needed for designing an open infrastructure also can be seen abstractly or con-cretely.
Abstractly, an NLP pipeline should be part of the process of morphological, lexical, syntactic,semantic to pragmatic processing (see Figure 1).
From a concrete view, each component of an NLPpipeline should have any requisite preprocessing.
For example, tokenization is required preprocessingfor POS tagging (see Figure 2).
Such knowledge for building NLP pipelines can be interactively deter-mined by the NLP expert or preset as built-in pipeline models.KnowledgeToolD ataDocument Format, Structure, StyleMorphological(Splitter, Tokenizer , POS Tagger)Meta-InformationofKnowledge,Tool, andData.Lexical & Syntactic(Lemmatization, Chunking, Parsing)Semantic(N ER, Coreference )Pragmatic(Indexing, Retrieval)Knowledge of Tool Requirements, DataInterpretationFigure 3: Information for NLP pipeline application descriptionWe can put the above analyzed data, tool, and knowledge types with their meta-information together asthe information required for describing an NLP pipeline application (see Figure 3).
Regarding the docu-ment format, structure and style, for example, the Text Encoding Initiative (TEI)1provides one standardfor text encoding and interchange, which also enables meta-information description.
Concerning themain part (see dashdotted-line part of Figure 3), it is generally referred to as the model of annotation.For example, GATE has its own single unified model of annotation, which is organized in annotationgraphs.
The arcs in the graph have a start node and an end node, an identifier, a type and a set offeatures (Bontcheva et al., 2004).
One standardization effort (Ide and Romary, 2004), the LinguisticAnnotation Framework (LAF) architecture is designed so that a pivot format, such as GrAF (Ide andSuderman, 2007), can bridge various annotation collections.
Another standardization effort, the Syntac-tic Annotation Framework (SynAF) (Declerck, 2006), has evolved into the Morpho-syntactic annotationframework (MAF) (Declerck, 2008), which is based on the TEI and designed as the XML serializationfor morpho-syntactic annotations.
A NLP processing middleware, the Heart of Gold, treats XML stand-off annotations for natively XML support, and provides XSLT-based online integration mechanism ofvarious annotation collections (Sch?afer, 2006).
The UIMA specifies a UML-based data model of anno-tation, which also has a unified XML serialization (Hahn et al., 2007).
Differently from Heart of Gold?sXSLT-based mechanism, the conversion tools that bridge GATE annotation and UIMA annotation useGrAF as a pivot and are provided as GATE plugins and UIMA modules (Ide and Suderman, 2009).Thus, while a pivot standard annotation model like GrAF seems very promising, popular annotationmodels like those provided by GATE annotations (see Figure 4) or UIMA annotations (see Figure 4)will continue to exist and evolve for a long time.
As a result, more bridge strategies, like the conversionplugin (module) of GATE (UIMA) and the XSLT-based middleware mechanism, will continue to be nec-essary.
In the following sections, we consider the issue of the continuing availability of such conversionfunctions, and whether the current realization of those two conversion strategies is sufficient to bridge thevarious annotations made available by linguistic experts, without further substantial engineering work.3 Towards A Conceptual Design of Online InfrastructureIn this section, we discuss the conceptual design of online infrastructure, focusing on both the interop-erability and availability of the tools.
Concerning the latter, the Service-oriented architecture (SOA) is1http://www.tei-c.org/55<!-- GATE --><GateDocument><TextWithNodes><Node id="15"/>Sonnet<Node id="21"/></TextWithNodes><AnnotationSet><Annotation Id="18" Type="Token"StartNode="15" EndNode="21"><Feature><Name className="java.lang.String">length</Name><Value className="java.lang.String">6</Value></Feature><Feature><Name className="java.lang.String">category</Name><Value className="java.lang.String">NNP</Value></Feature><Feature><Name className="java.lang.String">kind</Name><Value className="java.lang.String">word</Value></Feature><Feature><Name className="java.lang.String">string</Name><Value className="java.lang.String">Sonnet</Value></Feature></Annotation></AnnotationSet></GateDocument><!-- UIMA --><xmi:XMIxmlns:xmi="http://www.omg.org/XMI"xmlns:opennlp="http:///org/apache/uima/examples/opennlp.ecore"xmlns:cas="http:///uima/cas.ecore"xmi:version="2.0"><cas:Sofaxmlns:cas="http:///uima/cas.ecore"xmi:id="1" sofaNum="1" sofaID="_InitialView"mimetype="text"sofaString="Sonnet."
/><opennlp:Tokenxmi:id="18" sofa="1"begin="0" end="6"posTag="NNP" /><cas:View sofa="1"members="18"/></xmi:XMI>Figure 4: Examples of GATE XML annotation and UIMA XML annotationa promising approach.
For example, while the Language Grid infrastructure makes NLP tools highlyavailable (Ishida, 2006), it can still have limitations regarding interoperability issues.
Generally, serviceinterfaces can be either operation-oriented which allows flexible operations with simple input/outputdata, or resource-oriented which allows flexible input/output data with simple operations.
The NLPprocessing services of Language Grid are more or less operation-oriented, and lack a certain structuralflexibility for composing with each other.
We present a resource-oriented view of NLP tools, whichshould have universal resource identification for distributed reference, an SQL-like data management,and a light-weight data serialization for online visualization.
We propose Restful wrapping both data andtools into Web services for this purpose.Restful wrapping makes both data and tools easy-to-access and with a unified interface, enablingstructural interoperability between heterogeneous tools, assuming standoff annotation from various NLPtools is applied.
For example, if the NLP tools are wrapped into Restful services so that they are operatedthrough HTTP GET protocol, and the XML serialization of UIMA annotation is applied for input andoutput, each NLP components will have the same interface and data structure.Once an internationalized resource identifier (IRI) is given, all the input and output of tools can bedistributed and ubiquitously identified.
Moreover, a PUT/GET/POST/DELETE protocol of restful datamanagement is equivalent to an SQL-like CRUD data management interface.
For example, an IRI canbe defined by a location identifier and the URL of the data service (Wright, 2014).In addition, a lightweight serialization of stand-off annotation can benefit the online visualization ofdata, which will be easy for experts to read, judge, or edit.
For example, the XML serialization of UIMAannotation can be transferred into JSON serialization, which is preferred for online reading or editing.NLP tool services will be available by applying restful wrapping (see Figure 5).
However, structuralinteroperability based on the restful wrapping is not enough for conceptual interoperability.
For example,if an OpenNLP tokenizer is wrapped using HTTP GET protocol and GATE annotation, but a StanfordNLP POS tagger is wrapped using UIMA annotation, it will raise conceptual interoperability issues.Based on the previously mentioned bridging strategies, a conversion service from GATE annotation toUIMA annotation should work, or a transformation interaction with a XSLT-like service should work.We would like to assume that the interaction and contribution of linguistic experts without online supportby engineers can solve this issue.
But how can we design the interaction to take advantage of such expertknowledge?We present a semantic mapping-based composer for building an NLP pipeline application (see Fig-56NLP Pipeline ApplicationNLP Tool ServiceSource Data(Document, Database)NLP Tool( OpenNLP, StandardNLP,  NLTK, etc )Restful Wrapping1.
International resource identifier (IRI) ID2.
Unified interface, GET/PUT/POST/DELETE3.
Self-description message like XML or JSONMeta-Information( Provider, License,Location)Semantic Mapping based Composing1.
NLP tool service pipeline engine2.
Proxy service of interactive ontology mappingWorkflow Engine( BPEL )Stand-off Ontology(Vocabulary)Meta-Information(Process Requirements)Figure 5: Conceptual design of online NLP pipeline applicationure 5).
Conceptual interoperability requires the same vocabularies for the same concept of a standoffannotation.
Once we have the standoff ontology of annotation, we can perform automatic semantic map-ping from NLP tool output to that ontology.
The interaction from experts will be triggered once theautomatic semantic mapping has failed (see Figure 6).
For example, both GATE and UIMA XML an-notations could be transformed into JSON formation, which is easy to present as tree structure entities.Based on these tree structure entities, automatic ontology mapping tools like UFOme, which identifiescorrespondences among entities in different ontologies (Pirr?o and Talia, 2010), can be applied to buildup various mapping solutions.
Knowledge from experts can also be applied interactively, and successfulmapping solutions can be stored for further reference and use.<!
-- GATE -- >< GateDocument >< TextWithNodes ><Node id="1 5 " />Sonnet<Node id="2 1 " /></ TextWithNodes >< AnnotationSet><Annotation Id=" 1 8 " Type="Token"StartNode ="1 5 " EndNode ="2 1 " ><Feature><Name clas sName =" java.lang.String ">length</Name><Value clas sName =" java.lang.String ">6 </Value></Feature><Feature><Name clas sName =" java.lang.String ">category</Name><Value clas sName =" java.lang.String ">NNP</Value></Feature><Feature><Name clas sName =" java.lang.String ">kind</Name><Value clas sName =" java.lang.String ">word</Value></Feature><Feature><Name clas sName =" java.lang.String ">string</Name><Value clas sName =" java.lang.String ">Sonnet</Value></Feature></Annotation></ AnnotationSet></ GateDocument >< !
- - UIMA -- >< xmi:XM Ixmlns:xmi ="http://www.omg.org/XM I"xmlns:opennlp ="http:///org/apache/uima/examples/opennlp.ecore"xmlns:cas ="http:/// uima/cas.ecore"xmi:version ="2.
0">< cas:Sofaxmlns:cas ="http:/// uima/cas.ecore"xmi:id ="1" sofaNum ="1" sofaID ="_ InitialView "mimetype ="text"sofaString ="Sonnet."
/>< opennlp:Tokenxmi:id ="18"  sofa="1"begin="0" end="6"posTag ="NNP" />< cas:View sofa="1"members="18"/ >< / xmi:XM I >OntologyMappingVocabularyMappingStorage@Id@ StartNode@ EndNodeFeatureAnnotationLengthCategoryString@id@sofa@begin@endToken@ posTag@TypeGATE AnnotationUIMA AnnotationFigure 6: Interactive ontology mapping of two different annotations of NLP tools (Tree structures arelearned from XML annotations in Figure 4 )The semantic mapping will be interactively created by the experts, when heterogeneous componentswith different data models are used in the NLP pipeline created by the end-users, who create the NLPpipeline without consideration of components interoperability.
It means that this semi-automaticallycreated semantic mapping separates acquiring the knowledge of tool requirements from end-users andacquiring the knowledge of data interpretation from experts (see Figure 3).
For example, the end-userschooses two POS Taggers (OpenNLP and NLTK) and two NER tools (OpenNLP and Stanford NLP)components in the NLP application of ?relationship analysis from medical records?.
When NLTK POS57Tagger output are serialized in to JSON formats but cannot be directly used as the input of Stanford NLPNER component which requires the UIMA annotation, a semantic mapping issue will be automaticallycreated and reported to experts.
This NLTK POS Tagger JSON format output will be mapped intothe standoff ontology of annotation of POS Tagger.
After that, this output will bridge with the UIMAannotation of the Stanford NLP NER.
This particular semantic mapping between JSON serialization ofa NLTK POS Tagger and the standoff ontology of annotation of POS Tagger, and between the standoffontology of annotation of POS Tagger and the UIMA annotation of Stanford NLP NER will be reused inthe NLP application created by other end-users.Our conceptual framework does not exclusively rely on the above interoperability design.
Our con-ceptual framework (see Figure 5) should integrate existing knowledge of various annotation frameworks,for example, the alignment knowledge from the Open Annotation models (Verspoor and Livingston,2012) and the pivot bridge knowledge from the GrAF (Ide and Suderman, 2007) under the LinguisticAnnotation Framework (LAF).
Thus, existing pivot conversion solutions and XSLT-based middlewaresolutions can also be applied.
Our interactive ontology mapping design provides a more flexible choicefor linguistic experts to build up NLP pipeline applications on top of heterogeneous components, withoutonline help from engineers.
Below we present varying levels of online NLP applications, according towhat kind of extra support would be needed for composing different NLP components:?
Components are interoperable without extra data exchange issues.
For example, tools are from thesame community (e.g., only using OpenNLP tools).?
Components are interoperable with existing solutions of data exchange issues.
For example, toolsare from popular communities such as GATE plugins or UIMA modules.?
Components are interoperable with extra knowledge from experts.
For example, tools are both frompopular communities and personal developments or inner group software.?
Components are interoperable with considerable effort from both experts and engineers.
For exam-ple, tools are developed under novel ontology designs.According to these levels, our conceptual framework is targeted at the third level of interoperabilityissues.
Our proposal will generate a ontology mapping storage (see Figure 6), which we hope willcontribute to improving a standard annotation ontology.4 ConclusionIn this paper, we have tried to present a conceptual framework for building online NLP pipeline applica-tions.
We have argued that restful wrapping based on the Service-Oriented Architecture and a semanticmapping based pipeline composition benefit both the availability and interoperability of online pipelineapplications.
By looking at the information surrounding the data, tools, and knowledge needed for NLPcomponents pipelines, we explained how experts can be limited in building online NLP pipeline applica-tions without help from engineers, and our restful wrapping and interactive ontology mapping design canhelp in such situations.
Finally, we have described various levels of support needed for building onlineNLP pipelines, and we believe that this study can contribute to further online implementations of NLPapplications.AcknowledgementsThis work was supported by National Science Foundation grants NSF-ACI 1147944.ReferencesKalina Bontcheva, Valentin Tablan, Diana Maynard, and Hamish Cunningham.
2004.
Evolving gate to meet newchallenges in language engineering.
Nat.
Lang.
Eng., 10(3-4):349?373, September.58Hamish Cunningham, Diana Maynard, Kalina Bontcheva, and Valentin Tablan.
2002.
GATE: A Frameworkand Graphical Development Environment for Robust NLP Tools and Applications.
In Proceedings of the 40thAnniversary Meeting of the Association for Computational Linguistics (ACL?02).Thierry Declerck.
2006.
Synaf: Towards a standard for syntactic annotation.
In Proceedings of the Fifth In-ternational Conference on Language Resources and Evaluation (LREC?06).
European Language ResourcesAssociation (ELRA).Thierry Declerck.
2008.
A framework for standardized syntactic annotation.
In Bente Maegaard JosephMariani Jan Odijk Stelios Piperidis Daniel Tapias Nicoletta Calzolari (Conference Chair), Khalid Choukri,editor, Proceedings of the Sixth International Conference on Language Resources and Evaluation(LREC?08), Marrakech, Morocco, may.
European Language Resources Association (ELRA).
http://www.lrec-conf.org/proceedings/lrec2008/.David Ferrucci and Adam Lally.
2004.
Uima: An architectural approach to unstructured information processingin the corporate research environment.
Nat.
Lang.
Eng., 10(3-4):327?348, September.Udo Hahn, Ekaterina Buyko, Katrin Tomanek, Scott Piao, John McNaught, Yoshimasa Tsuruoka, and SophiaAnaniadou.
2007.
An annotation type system for a data-driven nlp pipeline.
In Proceedings of the LinguisticAnnotation Workshop, LAW ?07, pages 33?40, Stroudsburg, PA, USA.
Association for Computational Linguis-tics.Nancy Ide and Laurent Romary.
2004. International standard for a linguistic annotation framework.
Nat.
Lang.Eng., 10(3-4):211?225, September.Nancy Ide and Keith Suderman.
2007.
Graf: A graph-based format for linguistic annotations.
In Proceedings ofthe Linguistic Annotation Workshop, LAW ?07, pages 1?8, Stroudsburg, PA, USA.
Association for Computa-tional Linguistics.Nancy Ide and Keith Suderman.
2009.
Bridging the gaps: Interoperability for graf, gate, and uima.
In Pro-ceedings of the Third Linguistic Annotation Workshop, ACL-IJCNLP ?09, pages 27?34, Stroudsburg, PA, USA.Association for Computational Linguistics.T.
Ishida.
2006.
Language grid: an infrastructure for intercultural collaboration.
In Applications and the Internet,2006.
SAINT 2006. International Symposium on, pages 5 pp.
?100, Jan.Edward Loper and Steven Bird.
2002.
Nltk: The natural language toolkit.
In Proceedings of the ACL-02 Work-shop on Effective Tools and Methodologies for Teaching Natural Language Processing and ComputationalLinguistics - Volume 1, ETMTNLP ?02, pages 63?70, Stroudsburg, PA, USA.
Association for ComputationalLinguistics.Bill Manaris.
1998.
Natural language processing: A human-computer interaction perspective.Giuseppe Pirr?o and Domenico Talia.
2010.
Ufome: An ontology mapping system with strategy prediction capa-bilities.
Data Knowl.
Eng., 69(5):444?471, May.James Pustejovsky and Amber Stubbs.
2013.
Natural language annotation for machine learning.
O?Reilly Media,Sebastopol, CA.Ulrich Sch?afer.
2006.
Middleware for creating and combining multi-dimensional nlp markup.
In Proceedings ofthe 5th Workshop on NLP and XML: Multi-Dimensional Markup in Natural Language Processing, NLPXML?06, pages 81?84, Stroudsburg, PA, USA.
Association for Computational Linguistics.Karin Verspoor and Kevin Livingston.
2012.
Towards adaptation of linguistic annotations to scholarly annotationformalisms on the semantic web.
In Proceedings of the Sixth Linguistic Annotation Workshop, LAW VI ?12,pages 75?84, Stroudsburg, PA, USA.
Association for Computational Linguistics.Jonathan Wright.
2014.
Restful annotation and efficient collaboration.
In Nicoletta Calzolari (Conference Chair),Khalid Choukri, Thierry Declerck, Hrafn Loftsson, Bente Maegaard, Joseph Mariani, Asuncion Moreno, JanOdijk, and Stelios Piperidis, editors, Proceedings of the Ninth International Conference on Language Resourcesand Evaluation (LREC?14), Reykjavik, Iceland, may.
European Language Resources Association (ELRA).59
