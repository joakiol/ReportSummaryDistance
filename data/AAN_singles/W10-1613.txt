Proceedings of the NAACL HLT 2010 Young Investigators Workshop on Computational Approaches to Languages of the Americas,pages 92?99, Los Angeles, California, June 2010. c?2010 Association for Computational LinguisticsThe TermiNet Project: an OverviewAriani Di FelippoInterinstitutional Center for Research and Development in Computational Linguistics (NILC)/Research Group of Terminology (GETerm), Federal University of S?o Carlos (UFSCar)Rodovia Washington Lu?s, km 235 - SP-310CP 676, 13565-905, S?o Carlos, SP, Brazilariani@ufscar.brAbstractLinguistic resources with domain-specificcoverage are crucial for the development ofconcrete Natural Language Processing (NLP)systems.
In this paper we give a global intro-duction to the ongoing (since 2009) TermiNetproject, whose aims are to instantiate a gener-ic NLP methodology for the development ofterminological wordnets and to apply the in-stantiated methodology for building a termi-nological wordnet in Brazilian Portuguese.1 IntroductionIn knowledge-based Natural Language Processing(NLP) systems, the lexical knowledge database isresponsible for providing, to the processing mod-ules, the lexical units of the language and theirmorphological, syntactic, semantic-conceptual andeven illocutionary properties (Hanks, 2004).In this scenario, there is an increasing need ofaccurate general lexical-conceptual resources fordeveloping NLP applications.A revolutionary development of the 1990s wasthe Princeton WordNet (WN.Pr) (Fellbaum, 1998),an online reference lexical database built forNorth-American English that combines the designof a dictionary and a thesaurus with a rich ontolog-ical potential.Specifically, WN.Pr is a semantic network, inwhich the meanings of nouns, verbs, adjectives,and adverbs are organized into ?sets of cognitivesynonyms?
(or synsets), each expressing a distinctconcept.
Synsets are interlinked through concep-tual-semantic (i.e., hypernymy1/hyponymy2, holo-nymy/meronymy, entailment3, and cause4) andlexical (i.e., antonymy) relations.
Moreover,WN.Pr encodes a co-text sentence for each word-form in a synset and a concept gloss for each syn-set (i.e., an informal lexicographic definition of theconcept evoked by the synset).The success of WN.Pr is largely due to its ac-cessibility, linguistic adequacy and potential interms of NLP.
Given that, WN.Pr serves as a mod-el for similarly conceived wordnets in several lan-guages.
In other words, the success of WN.Pr hasdetermined the emergence of several projects thataim the construction of wordnets for other lan-guages than English or to develop multilingualwordnets (the most important project in this line isEuroWordNet) (Vossen, 2002).Many recent projects with the objective of (i) in-tegrating generic and specialized wordnets (e.g.,Magnin and Speranza, 2001; Roventini and Mari-nelli, 2004; Bentivogli et al, 2004), (ii) enrichinggeneric wordnets with terminological units (e.g.,Buitelaar and Sacaleanu, 2002) or (iii) constructingterminological wordnets (e.g.
: Sagri et al, 2004;Smith and Fellbaum, 2004) have shown that con-1 The term Y is a hypernym of the term X if the entity denotedby X is a (kind of) entity denoted byY.2 If the term Y is a hypernym of the term X then the term X isa hyponym of Y.3 The action A1 denoted by the verb X entails the action A2denoted by the verb Y if A1 cannot be done unless A2 is, orhas been, done4 The action A1 denoted by the verb X causes the action A2denoted by the verb Y.92crete NLP application must be able to comprehendboth expert and non-expert vocabulary.Despite the existence of a reasonable number ofterminological wordnets, there is no a general me-thodology for building this type of lexical data-base.
Thus, motivated by this gap and by the factthat Brazilian Potuguese (PB) is a resource-poorlanguage, the two-years TermiNet project has beendeveloped since September 2009.This paper gives an overview of the TermiNetproject.
Accordingly, in Section 2 we brief de-scribe the original WN.Pr design that motivated theproject.
In Section 3 we present the aims of theTermiNet project and its methodological approach.In Section 4 we depict the current state of theproject.
In Section 5 we describe future work, andin Section 6 we outline potential points for collabo-ration with researchers from the rest of the Ameri-cas.2 Princeton WordNet and its DesignWN.Pr contains information about nouns, verbs,adjectives and adverbs in North-American Englishand is organized around the notion of a synset.
Asmentioned, a synset is a set of words with the samepart-of-speech that can be interchanged in a certaincontext.
For example, {car; auto; automobile; ma-chine; motorcar} form a synset because they can beused to refer to the same concept.
A synset is oftenfurther described by a concept gloss5, e.g.
: ?4-wheeled; usually propelled by an internal combus-tion engine?.Finally, synsets can be related to each other bythe conceptual-semantic relations of hyperonymy/hyponymy, holonymy/meronymy, entailment andcause, and the lexical relation of antonymy.In the example, taken from WN.Pr (2.1), thesynset {car; auto; automobile; machine; motorcar}is related to:(i) more general concepts or the hyperonym syn-set: {motor vehicle; automotive vehicle};(ii) more specific concepts or hyponym synsets:e.g.
{cruiser; squad car; patrol car; police car;prowl car} and {cab; taxi; hack; taxicab}; and(iii) parts it is composed of: e.g.
{bumper}; {cardoor}, {car mirror} and {car window}.5 An informal lexicographic definition of the concept evokedby the synset.WN.Pr also includes an English co-text sen-tence for each word-form in a synset, and a seman-tic type for each synset.Based on WN.Pr design, Brazilian PortugueseWordNet (WordNet.Br or WN.Br) projectlaunched in 2003 departed from a previous lexicalresource: the Brazilian Portuguese Thesaurus (Di-as-da-Silva et al 2002).
The original WN.Br data-base is currently being refined, augmented, andupgraded.
The improvements include the encodingof the following bits of information in to the data-base: (a) the co-text sentence for each word-formin a synset; (b) the concept gloss for each synset;and (c) the relevant language-independent hierar-chical conceptual-semantic relations.The current WN.Br database presents the fol-lowing figures: 11,000 verb forms (4,000 synsets),17,000 noun forms (8,000 synsets), 15,000 adjec-tive forms (6,000 synsets), and 1,000 adverb forms(500 synsets), amounting to 44,000 word formsand 18,500 synsets (Dias-da-Silva et al 2008).3 The TermiNet ProjectThe TermiNet (?Terminological WordNet?
)project started in September 2009 and shall be fi-nished finish in August 2011.
It has been devel-oped in the laboratory of the Research Group ofTerminology6 (GETerm) in Federal University ofS?o Carlos (UFSCar) with the collaboration of theInterinstitutional Center for Research and Devel-opment in Computational Linguistics7(NILC/University of S?o Paulo) researchers.The TermiNet project has two main objectives.The first is to instantiate the generic NLP metho-dology, proposed by Dias-da-Silva (2006), for de-veloping terminological databases according to theWN.Pr model.
Such methodology distinguishesitself by conciliating the linguistic and computa-tional facets of the NLP researches.
The second isto apply the instantiated methodology to build aterminological wordnet or terminet8 in BP, sinceBP is a resource-poor language in NLP for whichdomain-specific databases in wordnet format havenot been built yet.It is important to emphasize that the mainterminological resources in BP, which are availa-6 http://www.geterm.ufscar.br/7 http://www.nilc.icmc.usp.br8 In the TermiNet project, a terminological wordnet databaseis called ?terminet?.93ble through the OntoLP9 website, are in fact (for-mal) ontologies or taxonomies.
There is nonological WordNet-like database in BP.In order to achieve its objectives, TermiNet has,apart from the project leader (Prof. Ariani Di Fe-lippo), an interdisciplinary team that includes sixundergraduate students: five from Linguistics andone from Computer Science courses.
The Linguis-tics students are responsible for specific linguistictasks in the project, such as: (i) corpus compila-tion, (ii) candidate terms extraction, (iii) synonymyidentification, and (iv) semantic-conceptual rela-tions extraction (hypernymy/hyponymy).
The res-ponsability of the Computer Science student is tosupport the automatic processing related to the lin-guistic (e.g., tagging, parsing, term extraction,etc.)
and linguistic-computational domains duringthe initial stages of the project.Moreover, the project counts with the collabora-tion of four PhD researchers from NILC.
Specifi-cally, TermiNet has the support of Prof. GladisMaria de Barcellos Almeida, a specialist in termi-nological research and the coordinator of GETerm;Prof. Maria da Gra?as Volpe Nunes, the coordina-tor of NILC and one of the most important Brazili-an NLP researchers; Prof. Sandra Aluisio, aspecialist in corpus construction, and Prof. ThiagoPardo, who has interests in the development of lex-ical resources for the automatic processing of BP.3.1 Instantiation of the NLP Tree-DomainMethodologyBased on Expert Systems development, Dias-da-Silva (2006) established a three-domain approachmethodology to develop any research in NLP do-main, assuming a compromise between HumanLanguage Technology and Linguistics (Dias-da-Silva, 1998).The linguistic-related information to be compu-tationally modeled is likened to a rare metal.
So, itmust be "mined", "molded", and "assembled" intoa computer-tractable system (Durkin, 1994).
Ac-cordingly, the processes of designing and imple-menting a terminet lexical database have to bedeveloped in the following complementary do-mains: the linguistic domain, the linguistic-computational domain, and implementational orcomputational domain.9 http://www.inf.pucrs.br/~ontolp/downloads.php(a) The Linguistic-related DomainIn this domain, the lexical resources and the lexi-cal-conceptual knowledge are mined.
More specif-ically, the research activities in the linguisticdomain are divided in two processes: the selectionof the lexical resources for building the terminetdatabase, and the specification of the lexical-conceptual knowledge that characterize a terminet.The linguist starts off these procedures by deli-mitating the specialized domain that will be en-coded in wordnet format.According to Almeida and Correia (2008), deal-ing with an entire specialized domain is a veryproblematic task because the domains (e.g.
: Mate-rials Engineering) in general are composed of sub-domains (e.g.
: Ceramic Materials, Polymers andMetals) with different characteristics, generating alarge universe of sources from which the lexical-conceptual knowledge will have to be mined.Consequently, the authors present some criteriathat may lead to delimitate a specialized domain:(i) the interest of the domain experts by termino-logical products (in this case, by a terminet); (ii)the relevance of the domain in the educational, so-cial, political, economic, scientific and/or technol-ogical scenarios, and (iii) the availability ofspecialized resources in digital format from whichthe lexical-conceptual knowledge will be extracted.After delimitating the domain, it is necessary toselect the lexical resources describe in (iii).
Ac-cording to Rigau (1998), the two main sources ofinformation for building wide-coverage lexiconsfor NLP systems are: structured resources (e.g.
:conventional monolingual and bilingual dictiona-ries, thesauri, taxonomies, vocabularies, etc.)
andunstructured resources (i.e., corpora10).Due to the unavailability of reusing structuredresources, the corpora have become the mainsource of lexical knowledge (Nascimento, 2003;Agbago and Barri?re, 2005; Cabr?
et al, 2005;Almeida, 2006).
The increasing use of corpora interminological researches is also due to the factthat ?el car?cter de t?rmino no se da per se, sino enfunci?n del uso de una unidad l?xica en un contex-to expresivo y situacional determinado?
(Cabr?,1999: 124).
Thus, in the TermiNet project, the cor-10 ?A corpus is a collection of pieces of language text in elec-tronic form, selected according to external criteria torepresent, as far as possible, a language or language variety asa source of data for linguistic research?
(Sinclair, 2005).94pus is considered the main lexical resource that canbe used to construct a terminet.Although there are available several specializedcorpora, the development of a terminet of certaindomains may require the compilation of a corpus.Based on the assumptions of Corpus Linguistics(Aluisio and Alemida, 2007), the construction of acorpus must follow three steps: (i) the corpus pro-jection, i.e., the specification of the corpus typolo-gy according to the research purposes; (ii) thecompilation of the texts that will compose the cor-pus, and (iii) the pre-processing of the corpus (i.e.,conversion, clean-up, manipulation, and annotationof the texts).From the corpus, the specialized knowledge willbe extracted, i.e., the terminological units (orterms), the lexical relations, and the conceptual-semantic relations11.As mentioned in previous sections, the lexicalunits are organized into four syntactic categories inWN.Pr: verbs, nouns, adjectives and adverbs.
Giv-en the relevance of nouns in the organization ofany terminology (i.e., the set of all terms related toa given subject field or discipline), we decided torestrict the construction of a terminet to the catego-ry of nouns.
In other words, a terminet database, inprinciple, will only contain information about con-cepts lexicalized by nouns.
Additionally, it willonly encode the hyperonymy/hyponymy relations,which are the most important conceptual-semanticrelations between nouns.
The co-text sentence foreach word-form in a synset and the concept glossfor each synset will not be focused in building aterminet.As the TermiNet a corpus-based project, we willapply approaches and strategies to automaticallyrecognize and extract candidate terms and relationsfrom corpus.In order to better understand the automatic can-didate terms and extraction, it can be useful toidentify two mainstream approaches to the prob-lem.
In the first approach, statistical measures havebeen proposed to define the degree of termhood ofcandidate terms, i.e., to find appropriate measuresthat can help in selecting good terms from a list ofcandidates.
In the second approach, computationalterminologists have tried to define, identify andrecognize terms looking at pure linguistic proper-11 The glosses and co-text sentences will not be specificied inthe TermiNet projet.ties, using linguistic filtering techniques aiming toidentify specific syntactic term patterns (Bernhard,2006; Pazienza et al, 2005; Cabr?
et al, 2001).Once extrated, the candidate terms have be vali-dated.
Two validation estrategies will be consi-dered in the TermiNet project.
The first strategyconsists on manually validating by domain experts.The second consists on automatically comparingthe list of candidate terms with a list of lexical un-ities extracted from a general corpus in BP.The automatic acquisition of hyper-onym/hyponymy relation from corpus is common-ly based on linguistic methods.
These methodslook for linguistic clues that indisputably indicatethe relation of interest (Hearst, 1992).
The linguis-tic clues are basically lexico-syntactic patters suchas: [NP such {NP,}*{(or|and)} NP] (e.g., ?worksby such authors as Herrick, and Shakespeare?
).The hierarchical relations extrated from corpus arecommonly validated by domain experts.
(b) The Linguistic-Computational DomainIn this domain, the overall information selectedand organized in the preceding domain is moldedinto a computer-tractable representation; in thecase of a WordNet-like database, the computer-tractable representation is based on the notions of:word form ?
a orthographic representation of anindividual word or a string of individual wordsjoined with underscore characters;synset ?
a set of words built on the basis of thenotion of synonymy in context, i.e.
word inter-changeability in some context;lexical matrix ?
associations of sets of wordforms and the concepts they lexicalize;relational pointers ?
formal representations ofthe relations between the word forms in a syn-set and other synsets; synonymy of word formsis implicit by inclusion in the same synset;hyperonymy always relates one synset toanother, and is an example of a semantic rela-tion; hyperonymy, in particular, is representedby reflexive pointers (i.e., if a synset contains apointer to another synset, the other synsetshould contain a corresponding reflexive poin-ter back to the original synset).
(c) The Computational DomainIn this domain, the computer-tractable representa-tions are assembled by utilities (i.e., a computa-tional tool to create and edit lexical knowledge).
In95other words, it is generated, in this domain, theterminet database.
The software tool that we willuse to generate the terminet database is under in-vestigation.4 TermiNet: Past and Current Stages ofDevelopmentThe project, which started in September 2009, isstill in its early stages.
Consequently, the researchtasks that have been developed so far are those re-lated to the linguistic domain.
As described in Sec-tion 3.1a, there are several linguistic tasks in theTermiNet project.
Two of them ?
the delimitationof the specialized domain and the corpus projec-tion ?
are completed.
In subsections 4.1 and 4.2,we present these finished processes and in 4.3 wefocus on the current activity.4.1 Delimitation of the specialized domainDE is conventionally defined as "any educationalor learning process or system in which the teacheror instructor is separated geographically or intime from his or her students or educational re-sources?.According to the second Brazilian Yearbook ofStatistics on Open and Distance Education(Anu?rio Brasileiro Estat?stico de Educa?
?o Abertae a Dist?ncia12), in 2007 there were approximately2,5 millions of students enrolled in accredited DEcourses, from basic to graduate education, in 257accredited institutions.
The number of students inDE courses has grown 24.9% in relation to 2006.Thus, we can see the relevance of the DE modalityin Brazil.
Despite the relevance of the DE in theBrazilian educational (and political) scenario, thereis no a lexical-conceptual representation of thisdomain, especially in a machine-readable format.Consequently, the instantiated methodology willbe validated by building DE.WordNet (DE.WN), aspecialized wordnet of the Distance Education (orDistance Learning) domain in BP.
The construc-tion of such database has been supported by do-main experts from the ?Open University of Brazil?
(Universidade Aberta do Brasil ?
UAB) project ofthe Federal University of S?o Carlos (UFSCar).DE.WN can be integrated into the wordnet lexi-cal database for BP, the WordNet.Br (Dias-da-12 http://www.abraead.com.br/anuario/anuario_2008.pdfSilva et al, 2008), enriching it with domain specif-ic knowledge.4.2 Corpus projectionFollowing the assumptions of Corpus Linguisticsdescribed in Section 3, the corpus of DE domainhas been constructed according to the steps: (i)corpus projection, (ii) corpus compilation, and (iii)the pre-processing of the texts.The corpus typology in the TermiNet projectwas specified based on: (i) the conception of ?cor-pus?, (ii) the type of lexical resource to be built,and (iii) the project decisions (Di Felippo and Sou-za, 2009).The corpus definition or conception is common-ly related to three criteria: representativeness, bal-ance and authenticity.According to the representativeness criterion,we have been compiled a representative corpus ofthe DE domain.
There have been many attempts toset the size, or at least establish a minimum num-ber of texts, from which a specialized corpus maybe compiled.
To satisfy the representativeness cri-terion, we have been constructed a medium-largecorpus, with at least 1 million of words.In a specialized corpus, it is important to gathertexts from different genres (i.e.
technical-scientific,scientific divulgation, instructional, informative,and technical-administrative) and media (i.e,newswire, books, periodicals, etc.).
Following thebalance and authenticity criteria, we have beenconstructed a corpus with a balanced number ofreal texts per genre.Besides, the format of the lexical database (i.e.
aterminet) determined some characteristics of thecorpus.
Specifically, the corpus has to be syn-chronic/ contemporary, since a wordnet (termino-logical or not) encodes synchronic lexical-conceptual knowledge.
The corpus has only tostore written texts, since wordnets are lingwaresfor written language processing.
Finally, the cor-pus in the TermiNet project has only to store textsfrom a specialized domain and in one language.Additionally, some project decisions deter-mined other characteristics of the corpus.
Two ini-tial decisions in the project were: (i) to apply semi-automatic methods of lexical-conceptual know-ledge extraction, and (ii) to share the resources andresults of the TermiNet project with ComputationalLinguistics community.
As a consequency of theproject decision described in (i), the corpus will be96annotated with part-of-speech (PoS) information,since some automatic extraction methods requireit.
As a consequency of the decision presented in(ii), the corpus will be available and usable aswidely as possible on the web.Finally, we also decided that once the corpushas been assembled, it will not be changed until thefirst version of DE.WN is ready.Based on the typology proposed by Giouli andPeperidis (2002), the Table 1 summarizes the cha-racteritics of the corpus previously described.Modality Written corpusText Type Written corpusMedium Newspapers, books, jour-nals, manuals and othersLanguage coverage Specialized corpusGenre/register Technical-scientific, scien-tific divulgation, instruc-tional, informative and,technical-administrativeLanguage variables Monolingual corpusMarkup Annotated corpus (PoSannotation)Production Com-munityNative speakersOpen-endedness Closed corpusHistorical variation Synchronic corpusAvailability Online corpusTable 1.
The corpus design.The specialized domain and corpus typology werespecified by the undergraduate student responsiblefor the corpus compilation under the supervision ofa PhD in Linguistics (leader of the project).4.3 Corpus compilationCurrently, one undergraduate student from Lin-guistics has been compiled the corpus.
Specifical-ly, the corpus compilation comprises twoprocesses: (i) the selection of resources and (ii) thecollect of texts from these resources.In the TermiNet project, the web is the mainsource for collecting texts of DE.
The choice ofweb reflects the fact that web has become an un-precedented and virtually inexhaustible source ofauthentic natural language data for researchers inlinguistics.Although there are many computational toolsthat assist in gathering a considerable amount oftexts on the web, the selection/collection of textshas been followed a manual process, which iscomposed of three steps: (i) to access a webpagewhose content is important for compiling the cor-pus, (ii) to search the texts on the webpage bysearch queries as ?distance education?
and ?dis-tance learning?, and (iii) to save the text files onthe computer.In the pre-processing step, the text files in a non-machine readable format (e.g.
pdf) are manuallyconverted to text format (txt), which is readable bymachines.
This process is important because thelexical-conceptual knowledge will be(semi)automatically extracted from the corpus, andthe extraction tools require a corpus whose textsare in txt format.Data corrupted by the conversion or even unne-cessary to the research (e.g.
references, informa-tion about filliation, etc.)
are excluded during thecleaning process.
After that, the metadata or exter-nal information (e.g.
authorship, publication de-tails, genre and text type, etc.)
on each text arebeing automatically annotated and encoded in aheader.
In the TermiNet project, we are using theheader editor available at the ?Portal de Corpus?website13.5 Future WorkAccording to the three-domain methodology, fu-ture steps will involve the following tasks of thelinguistic domain: candidate terms and relationsextraction (and validation).In the TermiNet project, two specific softwaretools constructed based on lingustic approacheswill be used to extract candidate terms from theDE corpus: EXATOLP (Lopes et al, 2009) and On-toLP (Ribeiro Jr., 2008).
Additionally, we intend toextract the terms from corpus using the NSP(Ngram Statistics Package) tool (Bannerjee andPedersen, 2003), i.e., a flexible and easy-to-usesoftware tool that supports the identification andanalysis of Ngrams.To extract the hyperonymy and hyponymy rela-tions, we will also use the OntoLP, which is a tool,actually a plug-in, for the ontologies editorProt?g?14, a widely used editor in the scientificcommunity and which gives support to the con-struction of ontologies.
The process of automatic13 http://www.nilc.icmc.usp.br:8180/portal/14 http://protege.stanford.edu/97ontology construction in the OntoLP tool also en-globes the identification of hierarchical relationbetween the terms.The synonymy relation will be also recognizedand extracted automatically from the corpus.
How-ever, the automatic extraction method of such lexi-cal relation is still under investigation.After the acquisition of all lexical-conceptualinformation, we will develop the tasks or processesof the linguistic-computational and computationaldomains.Among the expected results of the TermiNetprojet are: (i) a methodological framework forbuilding a specific type of lingware, i.e.
termino-logical wordnets; (ii) a specialized corpus of theDE domain; (iii) a terminological lexical databasebased on the WN.Pr format of the DE domain.Moreover, there is the possibility of extending theWN.Br database through the inclusion of specia-lized knowledge.Besides the benefits to NLP domain, theDE.WN may also contribute to the development ofstandard terminographic products (e.g., glossary,dictionary, vocabulary, etc.
), of the DE domainsince the organization of the lexical-conceptualknowledge is an essential step in building suchproducts.6 Collaborative OpportunitiesWe consider our experience in developing a termi-net in BP as the major contribution that we canoffer to other researchers in Latin America.
Sincethe resources (i.e., corpus and lexical database) andtools (i.e., terms and relations extractors) that wehave been used are language-dependent, they can-not be used directly for Spanish and English.
But,we are willing to share our expertise on (i) compil-ing a terminological corpus, (ii) automatically ex-tracting lexical-conceptual knowledge fromcorpus, and (iii) constructing a terminet database inorder to develop similar projects for Spanish andEnglish.We are really interested in actively taking part injoint research projects that aim to construct termi-nological lexical database for Spanish or English,especially in wordnet format.Collaboration of researchers from the USA thatwere directly involved in the development ofwordnet databases (terminological or not), willingto share their experience and tools, would be wel-come.We would appreciate collaboration from re-searchers in the USA specifically in relation tocomputational programs or software tools used inbuilding WordNet-like lexical database, which areresponsible for the computer-tractable representa-tion described in 3.1(b).
The current WN.Br edit-ing tool, which was originally designed to aid thelinguist in carrying out the tasks of building syn-sets, selecting co-text sentences from corpora, andwriting synset concept glosses, has been modifiedto aid the linguistic in carrying out the task of en-coding conceptual relations.
However, this editor isjust able to deal with the hypernymy/hyponymyrelations when they are inherited from WN.Prthrough a conceptual-semantic alignment strategy(Dias-da-Silva et al 2008).
So, the WN.Br editor isnot the most appropriate tool to TermiNer projecttasks.
Consequently, contributions to develop ?akind of?
Grinder15 for TermiNet would be wel-come.
We would also appreciate collaborationfrom re-searchers in the USA in relation to metho-dological approaches to enriching generic word-nets with terminological units.AcknowledgmentsWe thank the Brazilian National Council for Scien-tific and Technological Development (CNPq)(471871/2009-5), and the State of S?o Paulo Re-search Foundation (FAPESP) (2009/06262-1) forsupporting the TermiNet project.
We also thank theNAACL HLT Young Investigators Workshop refe-rees, who helped make this paper better.ReferencesAdriana Roventini and Rita Marinelli.
2004.
Extendingthe Italian Wordnet with the specialized language ofthe maritime domain.
In: Proceedings of the 2nd In-ternational Global Wordnet Conference.
MasarykUniversity, Brno, 193-198.Akakpo Agbago and Caroline Barri?re.
2005.
Corpusconstruction for Terminology.
In: Proceedings of theCorpus Lingustics Conference.
Birmingham, 14-17.Bento Carlos Dias-da-Silva.
2006.
Bridging the gapbetween linguistic theory and natural languageprocessing.
In: Proceedings of the 16th International15 This is the most important program used in building WN.Pr.Lexicographers make their additions and changes in the lexi-cal source files, and the Grinder takes those files and convertsthem into a lexical database (in wordnet format).98Congress of Linguistics, 1997.
Oxford: ElsevierSciences, 1998, 1-10.Bento Carlos Dias-da-Silva.
2006.
O estudo lingu?stico-computacional da linguagem.
Letras de Hoje, 41(2):103-138.Bento Carlos Dias-da-Silva, Ariani Di Felippo and Ma-ria G. V. Nunes.
2008.
The automatic mapping ofPrinceton Wordnet lexical-conceptual relations ontothe Brazilian Portuguese Wordnet database.
In: Pro-ceedings of the 6th LREC.
Marrakech, Morocco.Bento Carlos Dias-da-Silva, Mirna Fernanda de Olivei-ra, H?lio Roberto de Moraes.
2002.
Groundwork forthe development of the Brazilian Portuguese Word-net.
In: Proceedings of the 3rd International Confe-rence Portugal for Natural Language Processing(PorTal).
Faro, Portugal.
Berlin: Springer-Verlag,189-196.Bernardo Magnini and Manuela Speranza.
2001.
Inte-grating generic and specialized wordnets.
In: Pro-ceedings of the Conference on Recent Advances inNatural Language Processing.
Bulgaria.Christiane Fellbaum (ed.).
1998.
Wordnet: an electroniclexical database.
The MIT Press, Ca, MA: 423p.Delphine Bernhard.
2006.
Multilingual term extractionfrom domain-specific corpora using morphologicalstructure.
In: Proceedings of the 11th EuropeanChapter Meeting of the ACL, Trento, Italy, 171-174.German Rigau Claramunt.
1998.
Automatic acquisitionof lexical knowledge from MRDs.
PhD Thesis.
De-partament de Llenguatges i Sistemes Inform?tics,Barcelona.Gladis Maria Barcellos de Almeida.
2006.
A TeoriaComunicativa da Terminologia e a sua pr?tica.
Alfa,50:81-97Gladis Maria de Barcellos Almeida and MargaritaCorreia.
2008.
Terminologia e corpus: rela?
?es,m?todos e recursos.
In: Stella E. O. Tagnin and OtoAra?jo Vale (orgs.).
Avan?os da Ling?
?stica de Cor-pus no Brasil.
1 ed.
Humanitas/FFLCH/USP; S?oPaulo, volume 1, 63-93.Gladis Maria Barcellos de Almeida, Sandra Maria Alui-sio and Leandro H. M. Oliveira.
2007.
O m?todo emTerminologia: revendo alguns procedimentos.
In:Aparecida N. Isquerdo and Ieda M. Alves.
(orgs.
).Ci?ncias do l?xico: lexicologia, lexicografia, termi-nologia.
1 ed.
Editora da UFMS/Humanitas: CampoGrande/S?o Paulo, volume 3, 409-420.John Durkin.
1994.
Expert Systems: Design and Devel-opment.
Prentice Hall International, London, 800p.John Sinclair, J.
2005.
Corpus and text: basic principles.In: Martin Wynne (ed.).
Developing linguistic corpo-ra: a guide to good practice.
Oxbow Books: Oxford,1-16.
Available at http://ahds.ac.uk/linguistic-corpora/Lucelene Lopes, Paulo Fernandes, Renata Vieira andGustavo Fedrizzi.
2009.
ExATOlp - an automatictool for term extraction from Portuguese languagecorpora.
In: Proceedings of the LTC?09, Poznam,Poland.Luisa Bentivogli, Andrea Bocco and Emanuele Pianta.2004.
ArchiWordnet: integrating Wordnet with do-main-specific knowledge.
In: Proceedings of the 2ndInternational Global Wordnet Conference.
MasarykUniversity, Brno, 39-47.Luiz Carlos Ribeiro Jr. 2008.
OntoLP: constru?
?o semi-autom?tica de ontologias a partir de textos da l?nguaportuguesa.
MSc Thesis, UNISINOS, 131p.Maria Fernanda Bacelar do Nascimento.
2003.
O papeldos corpora especializados na cria?
?o de bases termi-nol?gicas.
In: I. Castro and I. Duarte (orgs.).
Raz?ese emo?
?es, miscel?nea de estudos em homenagem aMaria Helena Mateus.
Imprensa Nacional-Casa daMoeda: Lisboa, volume II, 167-179.Maria Tereza Cabr?.
1999.
La terminolog?a: represen-taci?n y comunicaci?n: elementos para una teor?a debase comunicativa y otros art?culos.
Institut Univer-sitari de Lingu?stica Aplicada: Barcelona.Maria Tereza Cabr?, Anne Condamines and FideliaIbekwe-SanJuan.
2005.
Application-driven terminol-ogy engineering.
Terminology, 11(2):1-19.Maria Tereza Cabr?, Rosa Estop?
and Jordi VivaldiPalatresi.
2001.
Automatic term detection: a reviewof current systems, In: Didier Bourigault et al (eds.
).Recent Advances in Computational Terminology.John Benjamins Publishing Co: Amsterdam & Phila-delphia, 53-87.Maria Teresa Pazienza, Marco Pennacchiotti and FabioMassimo Zanzotto.
2005.
Terminology extraction: ananalysis of linguistic and statistical approaches.
Stu-dies in Fuzziness and Soft Computing, 185:255-280.Maria Teresa Sagri, Daniela Tiscornia and FrancescaBertagna.
2004.
Jur-Wordnet.
In: Proceedings of the2nd International Global Wordnet Conference.
Ma-saryk University, Brno, 305-310.Marti A. Hearst, M. 1992.
Automatic acquisition ofhyponyms from large text corpora.
In: Proceedings14th of the International Conference on Computa-tional Linguistics.
Nantes, 539-545.Paul Buitelaar and Bogdan Sacaleanu.
2002.
Extendingsynsets with medical terms.
In: Proceedings of the1st International Global Wordnet Conference.
My-sore, India, 2002.Piek Vossen (ed.).
2002.
EuroWordnet general docu-ment (Version 3?Final).
Available at:http://www.vossen.info/docs/2002/EWNGeneral.pdf.Satanjeev Banerjee and Ted Pedersen.
2003.
The De-sign, Implementation, and Use of the Ngram Statis-tics Package.
In: Proceedings of the FourthInternational Conference on Intelligent TextProcessing and Computational Linguistics.
MexicoCity.99
