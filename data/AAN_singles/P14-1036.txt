Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 380?390,Baltimore, Maryland, USA, June 23-25 2014.c?2014 Association for Computational LinguisticsCollective Tweet Wikification based on Semi-supervised GraphRegularizationHongzhao Huang1, Yunbo Cao2, Xiaojiang Huang2, Heng Ji1, Chin-Yew Lin21Computer Science Department, Rensselaer Polytechnic Institute, Troy, NY 12180, USA2Microsoft Research Asia, Beijing 100080, P.R.China{huangh9,jih}@rpi.edu1,{yunbo.cao,xiaojih,cyl}@microsoft.com2AbstractWikification for tweets aims to automat-ically identify each concept mention in atweet and link it to a concept referent ina knowledge base (e.g., Wikipedia).
Dueto the shortness of a tweet, a collectiveinference model incorporating global ev-idence from multiple mentions and con-cepts is more appropriate than a non-collecitve approach which links each men-tion at a time.
In addition, it is chal-lenging to generate sufficient high qualitylabeled data for supervised models withlow cost.
To tackle these challenges, wepropose a novel semi-supervised graphregularization model to incorporate bothlocal and global evidence from multi-ple tweets through three fine-grained re-lations.
In order to identify semantically-related mentions for collective inference,we detect meta path-based semantic rela-tions through social networks.
Comparedto the state-of-the-art supervised modeltrained from 100% labeled data, our pro-posed approach achieves comparable per-formance with 31% labeled data and ob-tains 5% absolute F1 gain with 50% la-beled data.1 IntroductionWith millions of tweets posted daily, Twitter en-ables both individuals and organizations to dis-seminate information, from current affairs tobreaking news in a timely fashion.
In thiswork, we study the wikification (Disambiguationto Wikipedia) task (Mihalcea and Csomai, 2007)for tweets, which aims to automatically identifyeach concept mention in a tweet, and link it to aconcept referent in a knowledge base (KB) (e.g.,Wikipedia).
For example, as shown in Figure 1,Hawks is an identified mention, and its correct ref-erent concept in Wikipedia is Atlanta Hawks.
Anend-to-end wikification system needs to solve twosub-problems: (i) concept mention detection, (ii)concept mention disambiguation.Wikification is a particularly useful task forshort messages such as tweets because it allowsa reader to easily grasp the related topics and en-riched information from the KB.
From a system-to-system perspective, wikification has demon-strated its usefulness in a variety of applica-tions, including coreference resolution (Ratinovand Roth, 2012) and classification (Vitale et al,2012).Sufficient labeled data is crucial for supervisedmodels.
However, manual wikification annota-tion for short documents is challenging and time-consuming (Cassidy et al, 2012).
The challengesare: (i) unlinkability, a valid concept may not ex-ist in the KB.
(ii) ambiguity, it is impossible todetermine the correct concept due to the dearthof information within a single tweet or multiplecorrect answer.
For instance, it would be diffi-cult to determine the correct referent concept for?Gators?
in t1in Figure 1.
Linking ?UCONN?in t3to University of Connecticut may also be ac-ceptable since Connecticut Huskies is the athleticteam of the university.
(iii) prominence, it is chal-lenging to select a set of linkable mentions thatare important and relevant.
It is not tricky to select?Fans?, ?slump?, and ?Hawks?
as linkable men-tions, but other mentions such as ?stay up?
and?stay positive?
are not prominent.
Therefore, itis challenging to create sufficient high quality la-beled tweets for supervised models and worth con-sidering semi-supervised learning with the explo-ration of unlabeled data.380Stay up Hawk Fans.
We are goingthrough a slump now, but we have tostay positive.
Go Hawks!Congrats to UCONN and Kemba Walker.5 wins in 5 days, very impressive...Just getting to the Arena, we play theBucks tonight.
Let's get it!Fan (person); Mechanical fanSlump (geology);  Slump (sports)Atlanta Hawks;  Hawks (film)University of Connecticut; Connecticut HuskiesKemba WalkerArena; Arena (magazine); Arena (TV series)Bucks County, Pennsylvania; Milwaukee BucksTweets Concept CandidatesGo Gators!!!
Florida Gators football; Florida Gators men's basketballt1t2t3t4Figure 1: An illustration of Wikification Task for Tweets.
Concept mentions detected in tweets aremarked as bold, and correctly linked concepts are underlined.
The concept candidates are ranked bytheir prior popularity which will be explained in section 4.1, and only top 2 ranked concepts are listed.However, when selecting semi-supervisedlearning frameworks, we noticed another uniquechallenge that tweets pose to wikification dueto their informal writing style, shortness andnoisiness.
The context of a single tweet usuallycannot provide enough information for prominentmention detection and similarity computing fordisambiguation.
Therefore, a collective inferencemodel over multiple tweets in the semi-supervisedsetting is desirable.
For instance, the four tweetsin Figure 1 are posted by the same author withina short time period.
If we perform collectiveinference over them we can reliably link am-biguous mentions such as ?Gators?, ?Hawks?,and ?Bucks?
to basketball teams instead of otherconcepts such as the county Bucks County.In order to address these unique challengesfor wikification for the short tweets, we employgraph-based semi-supervised learning algorithms(Zhu et al, 2003; Smola and Kondor, 2003; Blumet al, 2004; Zhou et al, 2004; Talukdar andCrammer, 2009) for collective inference by ex-ploiting the manifold (cluster) structure in bothunlabeled and labeled data.
These approachesnormally assume label smoothness over a definedgraph, where the nodes represent a set of labeledand unlabeled instances, and the weighted edgesreflect the closeness of each pair of instances.
Inorder to construct a semantic-rich graph capturingthe similarity between mentions and concepts forthe model, we introduce three novel fine-grainedrelations based on a set of local features, socialnetworks and meta paths.The main contributions of this paper are sum-marized as follows:?
To the best of our knowledge, this is the firsteffort to explore graph-based semi-supervisedlearning algorithms for the wikification task.?
We propose a novel semi-supervised graph reg-ularization model performing collective infer-ence for joint mention detection and disam-biguation.
Our approach takes advantage ofthree proposed principles to incorporate both lo-cal and global evidence from multiple tweets.?
We propose a meta path-based unified frame-work to detect both explicitly and implicitly rel-evant mentions.2 PreliminariesConcept and Concept Mention We define a con-cept c as a Wikipedia article (e.g., Atlanta Hawks),and a concept mentionm as an n-gram from a spe-cific tweet.
Each concept has a set of textual repre-sentation fields (Meij et al, 2012), including title(the title of the article), sentence (the first sentenceof the article), paragraph (the first paragraph ofthe article), content (the entire content of the arti-cle), and anchor (the set of all anchor texts withincoming links to the article).Wikipedia Lexicon Construction We firstconstruct an offline lexicon with each entry as?m, {c1, ..., ck}?, where {c1, ..., ck} is the set ofpossible referent concepts for the mention m.Following the previous work (Bunescu, 2006;Cucerzan, 2007; Hachey et al, 2013), we extractthe possible mentions for a given concept c usingthe following resources: the title of c; the aliasesappearing in the introduction and infoboxes of c(e.g., The Evergreen State is an alias of Wash-ington state); the titles of pages redirecting to c(e.g., State of Washington is a redirecting page ofWashington (state)); the titles of the disambigua-381tion pages containing c; and all the anchor textsappearing in at least 5 pages with hyperlinks to c(e.g., WA is a mention for the concept Washing-ton (state) in the text ?401 5th Ave N [[Seattle]],[[Washington (state)?WA]] 98109 USA?.
We alsopropose three heuristic rules to extract mentions(i.e., different combinations of the family nameand given name for a person, the headquarters ofan organization, and the city name for a sportsteam).Concept Mention Extraction Based on theconstructed lexicon, we then consider all n-gramsof size?
n (n=7 in this paper) as concept mentioncandidates if their entries in the lexicon are notempty.
We first segment @usernames and #hash-tags into regular tokens (e.g., @amandapalmer issegmented as amanda palmer and #WorldWater-Day is split as World Water Day) using the ap-proach proposed by (Wang et al, 2011).
Segmen-tation assists finding concept candidates for thesenon-regular mentions.3 Principles and Approach OverviewR elational Graph ConstructionKnowledge Base(Wikipedia)Labeled andUnlabeled TweetsWikipedia Lex icon ConstructionConcept Mention andConcept Candidate E x tractionLocal Compatibility(local features,cosine similarity)Coreference(meta path,mentionsimilarity)Semantic R elatedness(meta path, conceptsemantic relatedness)Semi- Supervised Graph R egularization<Mention, Concept>PairsFigure 2: Approach Overview.3.1 PrinciplesA single tweet may not provide enough evidenceto identify prominent mentions and infer their cor-rect referent concepts due to the lack of contextualinformation.
To tackle this problem, we propose toincorporate global evidence from multiple tweetsand performing collective inference for both men-tion identification and disambiguation.
We first in-troduce the following three principles that our ap-proach relies on.Principle 1 (Local compatibility): Two pairsof ?m, c?
with strong local compatibility tend tohave similar labels.
Mentions and their correctreferent concepts usually tend to share a set ofcharacteristics such as string similarity betweenmand c (e.g., ?Chicago, Chicago?
and ?Facebook,Facebook?).
We define the local compatibility tomodel such set of characteristics.Principle 2 (Coreference): Two coreferentialmentions should be linked to the same concept.For example, if we know ?nc?
and ?North Car-olina?
are coreferential, then they should both belinked to North Carolina.Principle 3 (Semantic Relatedness): Twohighly semantically-related mentions are morelikely to be linked to two highly semantically-related concepts.
For instance, when ?Sweet 16?and ?Hawks?
often appear together within rel-evant contexts, they can be reliably linked totwo baseketball-related concepts NCAA Men?s Di-vision I Basketball Championship and AtlantaHawks, respectively.3.2 Approach OverviewGiven a set of tweets ?t1, ..., t|T |?, our system firstgenerates a set of candidate concept mentions, andthen extracts a set of candidate concept referentsfor each mention based on the Wikipedia lexicon.Given a pair of mention and its candidate referentconcept ?m, c?, the remaining task of wikificationis to assign either a positive label if m should beselected as a prominently linkable mention and cis its correct referent concept, or otherwise a neg-ative label.
The label assignment is obtained byour semi-supervised graph regularization frame-work based on a relational graph, which is con-structed from local compatibility, coreference, andsemantic relatedness relations.
The overview ofour approach is as illustrated in Figure 2.4 Relational Graph ConstructionWe first construct the relational graphG = ?V,E?,where V = {v1, ..., vn} is a set of nodes and E ={e1, ..., em} is a set of edges.
Each vi= ?mi, ci?represents a tuple of mention miand its referentconcept candidate ci.
An edge is added betweentwo nodes viand vjif there is a proposed rela-tion based on the three principles described in sec-tion 3.1.4.1 Local CompatibilityWe first compute local compatibility (Principle 1)by considering a set of novel local features to cap-382ture the importance and relevance of a mention mto a tweet t, as well as the correctness of its link-age to a concept c. We have designed a numberof features which are similar to those commonlyused in wikification and entity linking work (Meijet al, 2012; Guo et al, 2013; Mihalcea and Cso-mai, 2007).Mention Features We define the following fea-tures based on information from mentions.?
IDFf(m) = log(|C|df(m)), where |C| is the totalnumber of concepts in Wikipedia and df(m) isthe total number of concepts in whichm occurs,and f indicates the field property, including ti-tle, content, and anchor.?
Keyphraseness(m) =|Ca(m)|df(m)to measurehow likely m is used as an anchor in Wikipedia,where Ca(m) is the set of concepts where mappears as an anchor.?
LinkProb(m) =?c?Ca(m)count(m,c)?c?Ccount(m,c), wherecount(m, c) indicates the number of occurrenceof m in c.?
SNIL(m) and SNCL(m) to count the numberof concepts that are equal to or contain a sub-n-gram of m, respectively (Meij et al, 2012).Concept Features The concept features aresolely based on Wikipedia, including the numberof incoming and outgoing links for c, and the num-ber of words and characters in c.Mention + Concept Features This set of fea-tures considers information from both mentionsand concepts:?
prior popularity prior(m, c) =count(m,c)?c?count(m,c?
), where count(m, c) mea-sures the frequency of the anchor links from mto c in Wikipedia.?
TFf(m, c) =countf(m,c)|f |to measure the rela-tive frequency of m in each field representationf of c, normalized by the length of f .
The fieldsinclude title, sentence, paragraph, content andanchor.?
NCT (m, c), TCN(m, c), and TEN(m, c) tomeasure whether m contains the title of c,whether the title of c contains m, and whetherm equals to the title of c, respectively.Context Features This set of features include(i) Context Capitalization features, which indicatewhether the current mention, the token before, andthe token after are capitalized.
(ii) tf-idf based fea-tures, which include the dot product of two wordvectors vcand vt, and the average tf-idf value ofcommon items in vcand vt, where vcand vtarethe top 100 tf-idf word vectors in c and t.Local Compatibility Computation For eachnode vi= ?mi, ci?, we collect its local featuresas a feature vector Fi= ?f1, f2, ..., fd?.
To avoidfeatures with large numerical values that domi-nate other features, the value of each feature isre-scaled using feature standardization approach.The cosine similarity is then adopted to computethe local compatibility of two nodes and constructa k nearest neighbor (kNN) graph, where eachnode is connected to its k nearest neighboringnodes.
We compute the weight matrix that rep-resents the local compatibility relation as:Wlocij={cosine(Fi, Fj) j ?
kNN(i)0 Otherwise4.2 Meta PathMentionHashtagTweet Userpost - 1postcontain - 1containcontain - 1 containFigure 3: Schema of the Twitter network.In this subsection, we introduce the conceptmeta path which will be used to detect corefer-ence (section 4.3) and semantic relatedness rela-tions (section 4.4).A meta-path is a path defined over a networkand composed of a sequence of relations betweendifferent object types (Sun et al, 2011b).
In ourexperimental setting, we can construct a natu-ral Twitter network summarized by the networkschema in Figure 3.
The network contains fourtypes of objects: Mention (M), Tweet (T), User(U), and Hashtag (H).
Tweets and mentions areconnected by links ?contain?
and ?contained by?
(denoted as ?contain?1?
); and other linked rela-tionships can be described similarly.We then define the following five types of metapaths to connect two mentions as:?
?M - T - M?,?
?M - T - U - T - M?,?
?M - T - H - T - M?,?
?M - T - U - T - M - T - H - T - M?,?
?M - T - H - T - M - T - U - T - M?.383Each meta path represents one particular seman-tic relation.
For instance, the first three paths arebasic ones expressing the explicit relations thattwo mentions are from the same tweet, posted bythe same user, and share the same #hashtag, re-spectively.
The last two paths are concatenatedones which are constructed by concatenating thefirst three simple paths to express the implicit rela-tions that two mentions co-occur with a third men-tion sharing either the same authorship or #hash-tag.
Such complicated paths can be exploited todetect more semantically-related mentions fromwider contexts.
For example, the relational linkbetween ?narita airport?
and ?Japan?
would bemissed without using the path ?narita airport - t1- u1- t2- american - t3- h1- t4- Japan?
since theydon?t directly share any authorships or #hashtags.4.3 CoreferenceA coreference relation (Principle 2) usually occursacross multiple tweets due to the highly redundantinformation in Twitter.
To ensure high precision,we propose a simple yet effective approach utiliz-ing the rich social network relations in Twitter.We consider two mentions miand mjcorefer-ential if miand mjshare the same surface formor one is an abbreviation of the other, and at leastone meta path exists betweenmiandmj.
Then wedefine the weight matrix representing the corefer-ential relation as:Wcorefij=??
?1.0 if miand mjare coreferential,and ci= cj0 Otherwise4.4 Semantic RelatednessEnsuring topical coherence (Principle 3) has beenbeneficial for wikification on formal texts (e.g.,News) by linking a set of semantically-relatedmentions to a set of semantically-related conceptssimultaneously (Han et al, 2011; Ratinov et al,2011; Cheng and Roth, 2013).
However, the short-ness of a single tweet means that it may not pro-vide enough topical clues.
Therefore, it is impor-tant to extend this evidence to capture semantic re-latedness information from multiple tweets.We define the semantic relatedness score be-tween two mentions as SR(mi,mj) = 1.0 if atleast one meta path exists between miand mj,otherwise SR(mi,mj) = 0.
In order to computethe semantic relatedness of two concepts ciandcj, we adopt the approach proposed by (Milne andWitten, 2008a):SR(ci, cj) = 1?logmax(|Ci|, |Cj|)?
log |Ci?
Cj|log(|C|)?
logmin(|Ci|, |Cj|),where |C| is the total number of concepts inWikipedia, and Ciand Cjare the set of conceptsthat have links to ciand cj, respectively.Then we compute a weight matrix representingthe semantic relatedness relation as:Wrelij={SR(Ni, Nj) if SR(Ni, Nj) ?
?0 Otherwisewhere SR(Ni, Nj) = SR(mi,mj) ?
SR(ci, cj)and ?
= 0.3, which is optimized from a develop-ment set.4.5 The Combined Relational Graphhawks,Atlanta Hawksuconn,ConnecticutHuskiesbucks,MilwaukeeBuckskemba walker,Kemba Walker0 .40 4gators,Florida Gatorsmen's basketballnow,N owdays,D aytonight,Tonight0 .9 320 .7 6 40 .6 6 50 .46 70 .56 3 0 .5380 .447Figure 4: A example of the relational graph con-structed for the example tweets in Figure 1.
Eachnode represents a pair of ?m, c?, separated by acomma.
The edge weight is obtained from the lin-ear combination of the weights of the three pro-posed relations.
Not all mentions are included dueto the space limitations.Based on the above three weight matricesWloc,Wcoref, and Wrel, we first obtain their corre-sponding transition matrices Ploc, Pcoref, andPrel, respectively.
The entry Pijof the transitionmatrix P for a weight matrix W is computed asPij=Wij?kWiksuch that?kPik= 1.
Then weobtain the combined graph G with weight matrixW , where Wij= ?Plocij+ ?Pcorefij+ ?Prelij.
?,?, and ?
are three coefficients between 0 and 1with the constraint that ?+ ?
+ ?
= 1.
They con-trol the contributions of these three relations in oursemi-supervised graph regularization model.
Wechoose transition matrix to avoid the dominationof one relation over others.
An example graph ofG is shown in Figure 4.
Compared to the referentgraph which considers each mention or conceptas a node in previous graph-based re-ranking ap-proaches (Han et al, 2011; Shen et al, 2013), our384novel graph representation has two advantages: (i)It can easily incorporate more features related toboth mentions and concepts.
(ii) It is more appro-priate for our graph-based semi-supervised modelsince it is difficult to assign labels to a pair of men-tion and concept in the referent graph.5 Semi-supervised Graph RegularizationGiven the constructed relational graph with theweighted matrix W and the label vector Y of allnodes, we assume the first l nodes are labeled asYland the remaining u nodes (u = n?
l) are ini-tialized with labels Y0u.
Then our goal is to refineY0uand obtain the final label vector Yu.Intuitively, if two nodes are strongly connected,they tend to hold the same label.
We propose anovel semi-supervised graph regularization frame-work based on the graph-based semi-supervisedlearning algorithm (Zhu et al, 2003):Q(Y) = ?n?i=l+1(yi?y0i)2+12?i,jWij(yi?yj)2.The first term is a loss function that incorporatesthe initial labels of unlabeled examples into themodel.
In our method, we adopt prior popular-ity (section 4.1) to initialize the labels of the un-labeled examples.
The second term is a regular-izer that smoothes the refined labels over the con-structed graph.
?
is a regularization parameter thatcontrols the trade-off between initial labels and theconsistency of labels on the graph.
The goal of theproposed framework is to ensure that the refinedlabels of unlabeled nodes are consistent with theirstrongly connected nodes, as well as not too faraway from their initial labels.The above optimization problem can be solveddirectly since Q(Y) is convex (Zhu et al, 2003;Zhou et al, 2004).
Let I be an identity matrixand DWbe a diagonal matrix with entries Dii=?jWij.
We can split the weighted matrix W intofour blocks as W =[WllWluWulWuu], where Wmnisanm?nmatrix.
Dwis split similarly.
We assumethat the vector of the labeled examples Ylis fixed,so we only need to infer the refined label vector ofthe unlabeled examples Yu.
In order to minimizeQ(Y), we need to find Y?usuch that?Q?Yu???
?Yu=Y?u= (Duu+ ?Iuu)Yu?WuuYu?WulYl?
?Y0u= 0.Therefore, a closed form solution can be derivedas Y?u= (Duu+ ?Iuu?Wuu)?1(WulYl+ ?Y0u).However, for practical application to a large-scale data set, an iterative solution would be moreefficient to solve the optimization problem.
LetYtube the refined labels after the tthiteration, theiterative solution can be derived as:Yt+1u= (Duu+?Iuu)?1(WuuYtu+WulYl+?Y0u).The iterative solution is more efficient since(Duu+ ?Iuu) is a diagonal matrix and its inverseis very easy to compute.6 ExperimentsIn this section we compare our approach withstate-of-the-art methods as shown in Table 1.6.1 Data and Scoring MetricFor our experiments we use a public data set (Meijet al, 2012) including 502 tweets posted by 28verified users.
The data set was annotated by twoannotators.
We randomly sample 102 tweets fordevelopment and the remaining for evaluation.
Weuse a Wikipedia dump on May 3, 2013 as ourknowledge base, which includes 30 million pages.For computational efficiency, we also filter somemention candidates by applying the preprocess-ing approach proposed in (Ferragina and Scaiella,2010), and remove all the concepts with prior pop-ularity less than 2% from an mention?s concept setfor each mention, similar to (Guo et al, 2013).A mention and concept pair ?m, c?
is judged ascorrect if and only if m is linkable and c is thecorrect referent concept for m. To evaluate theperformance of a wikification system, we use thestandard precision, recall and F1 measures.6.2 Experimental ResultsThe overall performance of various approachesis shown in Table 2.
The results of the super-vised method proposed by (Meij et al, 2012) areobtained from 5-fold cross validation.
For oursemi-supervised setting, we experimentally sam-ple 200 tweets for training and use the remain-ing set as unlabeled and testing sets.
In our semi-supervised regularization model, the matrix Wlocis constructed by a kNN graph (k = 20).
The reg-ularization parameter ?
is empirically set to 0.1,and the coefficients ?, ?, and ?
are learnt from thedevelopment set by considering all the combina-385Methods DescriptionsTagMe The same approach that is described in (Ferragina and Scaiella, 2010), which aims to annotate shorttexts based on prior popularity and semantic relatedness of concepts.
It is basically an unsupervisedapproach, except that it needs a development set to tune the probability threshold for linkable mentions.Meij A state-of-the-art system described in (Meij et al, 2012), which is a supervised approach based on therandom forest model.
It performs mention detection and disambiguation jointly, and it is trained from400 labeled tweets.SSRegu1Our proposed model based on Principle 1, using 200 labeled tweets.SSRegu12Our proposed model based on Principle 1 and 2, using 200 labeled tweets.SSRegu13Our proposed model based on Principle 1 and 3, using 200 labeled tweets.SSRegu123Our proposed full model based on Principle 1, 2 and 3, using 200 labeled tweets.Table 1: Description of Methods.Methods Precision Recall F1TagMe 0.329 0.423 0.370Meij 0.393 0.598 0.475SSRegu10.538 0.435 0.481SSRegu120.638 0.438 0.520SSRegu130.541 0.457 0.495SSRegu1230.650 0.441 0.525Table 2: Overall Performance.tions of values from 0 to 1 at 0.1 intervals1.
Inorder to randomize the experiments and make thecomparison fair, we conduct 20 test runs for eachmethod and report the average scores across the 20trials.The relatively low performance of the baselinesystem TagMe demonstrates that only relying onprior popularity and topical information within asingle tweet is not enough for an end-to-end wik-ification system for the short tweets.
As an exam-ple, it is difficult to obtain topical clues in orderto link the mention ?Clinton?
to Hillary RodhamClinton by relying on the single tweet ?wolfblitzer-cnn: Behind the scenes on Clinton?s Mideast trip#cnn?.
Therefore, the system mistakenly links itto the most popular concept Bill Clinton.In comparision with the supervised baselineproposed by (Meij et al, 2012), our modelSSRegu1relying on local compatibility alreadyachieves comparable performance with 50% oflabeled data.
This is because that our modelperforms collective inference by making use ofthe manifold (cluster) structure of both labeledand unlabeled data, and that the local compat-ibility relation is detected with high precision2(89.4%).
For example, the following three pairsof mentions and concepts ?pelosi, Nancy Pelosi?,?obama, Barack Obama?, and ?gaddafi, Muam-1These three coefficients are slightly different with differ-ent training data, a sample of them is: ?
= 0.4, ?
= 0.5, and?
= 0.12Here we define precision as the percentage of links thatholds the same label.mar Gaddafi?
have strong local compatibility witheach other since they share many similar char-acteristics captured by the local features such asstring similarity between the mention and the con-cept.
Suppose the first pair is labeled, then its pos-itive label will be propagated to other unlabelednodes through the local compatibility relation, andcorrectly predict the labels of other nodes.Incorporating coreferential or semantic related-ness relation into SSRegu1provides further gains,demonstrating the effectiveness of these two re-lations.
For instance, ?wh?
is correctly linked toWhite House by incorporating evidence from itscoreferential mention ?white house?.
The corefer-ential relation (Principle 2) is demonstrated to bemore beneficial than the semantic relatedness re-lation (Principle 3) because the former is detectedwith much higher precision (99.7%) than the latter(65.4%).Our full model SSRegu123achieves significantimprovement over the supervised baseline (5% ab-solute F1 gain with 95.0% confidence level bythe Wilcoxon Matched-Pairs Signed-Ranks Test),showing that incorporating global evidence frommultiple tweets with fine-grained relations is ben-eficial.
For instance, the supervised baseline failsto link ?UCONN?
and ?Bucks?
in our examplesto Connecticut Huskies and Milwaukee Bucks, re-spectively.
Our full model corrects these twowrong links by propagating evidence through thesemantic links as shown in Figure 4 to obtain mu-tual ranking improvement.
The best performanceof our full model also illustrates that the three re-lations complement each other.We also study the disambiguation performancefor the annotated mentions, as shown in Table 3.We can easily see that our proposed approachusing 50% labeled data achieves similar perfor-mance with the state-of-the-art supervised modelwith 100% labeled data.
When the mentions aregiven, the unpervised approach TagMe has already386Methods TagMe Meij SSRegu123Accuracy 0.710 0.779 0.772Table 3: Disambiguation Performance.Methods Precision Recall F1SSRegu120.644 0.423 0.510SSRegu130.543 0.441 0.486SSRegu1230.657 0.419 0.512Table 4: The Performance of Systems Without Us-ing Concatenated Meta Paths.achieved reasonable performance.
In fact, mentiondetection actually is the performance bottleneck ofa tweet wikification system (Guo et al, 2013).
Oursystem performs better in identifying the promi-nent mention.6.3 Effect of Concatenated Meta PathsIn this work, we propose a unified framework uti-lizing meta path-based semantic relations to ex-plore richer relevant context.
Beyond the basicmeta paths, we introduce concatenated ones byconcatenating the basic ones.
The performance ofthe system without using the concatenated metapaths is shown in Table 4.
In comparison withthe system based on all defined meta paths, wecan clearly see that the systems using concate-nated ones outperform those relying on the sim-ple ones.
This is because the concatenated metapaths can incorporate more relevant informationwith implicit relations into the models by increas-ing 1.6% coreference links and 9.3% semantic re-latedness links.
For example, the mention ?naritaairport?
is correctly disambiguated to the concept?Narita International Airport?
with higher confi-dence since its semantic relatedness relation with?Japan?
is detected with the concatenated metapath as described in section 4.2.6.4 Effect of Labeled Data Size5 0 1 0 0 1 5 0 2 0 0 2 5 0 3 0 0 3 5 0 4 0 00 .
3 00 .
3 50 .
4 00 .
4 50 .
5 00 .
5 50 .
6 0F1 L a b e l e d  T w e e t  S i z e S S R e g u 1 2 3 M e i jFigure 5: The effect of Labeled Tweet Size.In previous experiments, we experimentally setthe number of labeled tweets to be 200 for over-all performance comparision with the baselines.In this subsection, we study the effect of labeleddata size on our full model.
We randomly sam-ple 100 tweets as testing data, and randomly se-lect 50, 100, 150, 200, 250, and 300 tweets aslabeled data.
20 test runs are conducted and theaverage results are reported across the 20 trials,as shown in Figure 5.
We find that as the sizeof the labeled data increases, our proposed modelachieves better performance.
It is encouraging tosee that our approach, with only 31.3% labeledtweets (125 out of 400), already achieves a perfor-mance that is comparable to the state-of-the-art su-pervised model trained from 100% labeled tweets.6.5 Parameter Analysis0 .
1 0 .
5 1 2 5 1 0 2 0 3 0 4 0 5 00 .
3 00 .
3 50 .
4 00 .
4 50 .
5 00 .
5 50 .
6 0F1 R e g u l a r i z a t i o n  P a r a m e t e r  ?
S S R e g u 1 2 3Figure 6: The effect of parameter ?.In previous experiments, we empirically set theparameter ?
= 0.1. ?
is the regularization pa-rameter that controls the trade-off between initiallabels and the consistency of labels on the graph.When ?
increases, the model tends to trust more inthe initial labels.
Figure 6 shows the performanceof our models by varying ?
from 0.02 to 50.
Wecan easily see that the system performce is stablewhen ?
< 0.4.
However, when ?
?
0.4, the sys-tem performance dramatically decreases, showingthat prior popularity is not enough for an end-to-end wikification system.7 Related WorkThe task of linking concept mentions to a knowl-edge base has received increased attentions overthe past several years, from the linking of conceptmentions in a single text (Mihalcea and Csomai,2007; Milne and Witten, 2008b; Milne and Witten,2008a; Kulkarni et al, 2009; He et al, 2011; Rati-nov et al, 2011; Cassidy et al, 2012; Cheng andRoth, 2013), to the linking of a cluster of corefer-387ent named entity mentions spread throughout dif-ferent documents (Entity Linking) (McNamee andDang, 2009; Ji et al, 2010; Zhang et al, 2010; Ji etal., 2011; Zhang et al, 2011; Han and Sun, 2011;Han et al, 2011; Gottipati and Jiang, 2011; He etal., 2013; Li et al, 2013; Guo et al, 2013; Shen etal., 2013; Liu et al, 2013).A significant portion of recent work considersthe two sub-problems mention detection and men-tion disambiguation separately and focus on thelatter by first defining candidate concepts for adeemed mention based on anchor links.
Men-tion disambiguation is then formulated as a rank-ing problem, either by resolving one mention ateach time (non-collective approaches), or by dis-ambiguating a set of relevant mentions simulta-neously (collective approaches).
Non-collectivemethods usually rely on prior popularity and con-text similarity with supervised models (Mihalceaand Csomai, 2007; Milne and Witten, 2008b; Hanand Sun, 2011), while collective approaches fur-ther leverage the global coherence between con-cepts normally through supervised or graph-basedre-ranking models (Cucerzan, 2007; Milne andWitten, 2008b; Han and Zhao, 2009; Kulkarni etal., 2009; Pennacchiotti and Pantel, 2009; Ferrag-ina and Scaiella, 2010; Fernandez et al, 2010;Radford et al, 2010; Cucerzan, 2011; Guo et al,2011; Han and Sun, 2011; Han et al, 2011; Rati-nov et al, 2011; Chen and Ji, 2011; Kozareva etal., 2011; Cassidy et al, 2012; Shen et al, 2013;Liu et al, 2013).
Especially note that when apply-ing the collective methods to short messages fromsocial media, evidence from other messages usu-ally needs to be considered (Cassidy et al, 2012;Shen et al, 2013; Liu et al, 2013).
Our methodis a collective approach with the following noveladvancements: (i) A novel graph representationwith fine-grained relations, (ii) A unified frame-work based on meta paths to explore richer rele-vant context, (iii) Joint identification and linkingof mentions under semi-supervised setting.Two most similar methods to ours were pro-posed by (Meij et al, 2012; Guo et al, 2013)by performing joint detection and disambiguationof mentions.
(Meij et al, 2012) studied severalsupervised machine learning models, but withoutconsidering any global evidence either from a sin-gle tweet or other relevant tweets.
(Guo et al,2013) explored second order entity-to-entity rela-tions but did not incorporate evidence from multi-ple tweets.This work is also related to graph-based semi-supervised learning (Zhu et al, 2003; Smolaand Kondor, 2003; Zhou et al, 2004; Talukdarand Crammer, 2009), which has been success-fully applied in many Natural Language Process-ing tasks (Niu et al, 2005; Chen et al, 2006).We introduce a novel graph that incorporates threefine-grained relations.
Our work is further re-lated to meta path-based heterogeneous informa-tion network analysis (Sun et al, 2011b; Sun etal., 2011a; Kong et al, 2012; Huang et al, 2013),which has demonstrated advantages over homoge-neous information network analysis without dif-ferentiating object types and relational links.8 ConclusionsWe have introduced a novel semi-supervised graphregularization framework for wikification to si-multaneously tackle the unique challenges of an-notation and information shortage in short tweets.To the best of our knowledge, this is the first workto explore the semi-supervised collective inferencemodel to jointly perform mention detection anddisambiguation.
By studying three novel fine-grained relations, detecting semantically-relatedinformation with semantic meta paths, and ex-ploiting the data manifolds in both unlabeled andlabeled data for collective inference, our work candramatically save annotation cost and achieve bet-ter performance, thus shed light on the challengingwikification task for tweets.AcknowledgmentsThis work was supported by the U.S. Army Re-search Laboratory under Cooperative AgreementNo.
W911NF-09-2-0053 (NS-CTA), U.S. NSFCAREER Award under Grant IIS-0953149, U.S.DARPA Award No.
FA8750-13-2-0041 in theDeep Exploration and Filtering of Text (DEFT)Program, IBM Faculty Award, Google ResearchAward and RPI faculty start-up grant.
The viewsand conclusions contained in this document arethose of the authors and should not be inter-preted as representing the official policies, eitherexpressed or implied, of the U.S. Government.The U.S. Government is authorized to reproduceand distribute reprints for Government purposesnotwithstanding any copyright notation here on.388ReferencesA.
Blum, J. Lafferty, M. Rwebangira, and R. Reddy.2004.
Semi-supervised learning using randomizedmincuts.
In Proceedings of the Twenty-first Interna-tional Conference on Machine Learning, ICML ?04.Razvan Bunescu.
2006.
Using encyclopedic knowl-edge for named entity disambiguation.
In EACL,pages 9?16.T.
Cassidy, H. Ji, L. Ratinov, A. Zubiaga, andH.
Huang.
2012.
Analysis and enhancement of wik-ification for microblogs with context expansion.
InProceedings of COLING 2012.Z.
Chen and H. Ji.
2011.
Collaborative ranking: Acase study on entity linking.
In Proc.
EMNLP2011.J.
Chen, D. Ji, C Tan, and Z. Niu.
2006.
Rela-tion extraction using label propagation based semi-supervised learning.
In Proceedings of the 21st In-ternational Conference on Computational Linguis-tics and 44th Annual Meeting of the Association forComputational Linguistics.X.
Cheng and D. Roth.
2013.
Relational inferencefor wikification.
In Proceedings of the 2013 Con-ference on Empirical Methods in Natural LanguageProcessing.Silviu Cucerzan.
2007.
Large-scale named entity dis-ambiguation based on wikipedia data.
In EMNLP-CoNLL 2007.S.
Cucerzan.
2011.
Tac entity linking by performingfull-document entity extraction and disambiguation.In Proc.
TAC 2011 Workshop.N.
Fernandez, J.
A. Fisteus, L. Sanchez, and E. Mar-tin.
2010.
Webtlab: A cooccurence-based approachto kbp 2010 entity-linking task.
In Proc.
TAC 2010Workshop.P.
Ferragina and U. Scaiella.
2010.
Tagme: on-the-fly annotation of short text fragments (by wikipediaentities).
In Proceedings of the 19th ACM inter-national conference on Information and knowledgemanagement, CIKM ?10.S.
Gottipati and J. Jiang.
2011.
Linking entities to aknowledge base with query expansion.
In Proceed-ings of the 2011 Conference on Empirical Methodsin Natural Language Processing.Y.
Guo, W. Che, T. Liu, and S. Li.
2011.
A graph-based method for entity linking.
In Proc.
IJC-NLP2011.S.
Guo, M. Chang, and E. Kiciman.
2013.
To linkor not to link?
a study on end-to-end tweet entitylinking.
In Proceedings of the 2013 Conference ofthe North American Chapter of the Association forComputational Linguistics: Human Language Tech-nologies.B.
Hachey, W. Radford, J. Nothman, M. Honnibal, andJ.
Curran.
2013.
Evaluating entity linking withwikipedia.
Artif.
Intell.X.
Han and L. Sun.
2011.
A generative entity-mentionmodel for linking entities with knowledge base.
InProc.
ACL2011.X.
Han and J. Zhao.
2009.
Named entity disam-biguation by leveraging wikipedia semantic knowl-edge.
In Proceedings of the 18th ACM conferenceon Information and knowledge management, CIKM2009.X.
Han, L. Sun, and J. Zhao.
2011.
Collective entitylinking in web text: A graph-based method.
In Proc.SIGIR2011.J.
He, M. de Rijke, M. Sevenster, R. van Ommering,and Y. Qian.
2011.
Generating links to backgroundknowledge: A case study using narrative radiologyreports.
In Proceedings of the 20th ACM inter-national conference on Information and knowledgemanagement.
ACM.Z.
He, S. Liu, Y.
Song, M. Li, M. Zhou, and H. Wang.2013.
Efficient collective entity linking with stack-ing.
In Proceedings of the 2013 Conference on Em-pirical Methods in Natural Language Processing.H.
Huang, Z. Wen, D. Yu, H. Ji, Y.
Sun, J. Han, andH.
Li.
2013.
Resolving entity morphs in censoreddata.
In Proceedings of the 51st Annual Meeting ofthe Association for Computational Linguistics (Vol-ume 1: Long Papers).H.
Ji, R. Grishman, H.T.
Dang, K. Griffitt, and J. El-lis.
2010.
Overview of the tac 2010 knowledge basepopulation track.
In Text Analysis Conference (TAC)2010.H.
Ji, R. Grishman, and H.T.
Dang.
2011.
Overviewof the tac 2011 knowledge base population track.
InText Analysis Conference (TAC) 2011.X.
Kong, P. Yu, Y. Ding, and J.
Wild.
2012.
Metapath-based collective classification in heterogeneousinformation networks.
In Proceedings of the 21stACM International Conference on Information andKnowledge Management, CIKM ?12.Z.
Kozareva, K. Voevodski, and S. Teng.
2011.
Classlabel enhancement via related instances.
In Proc.EMNLP2011.S.
Kulkarni, A. Singh, G. Ramakrishnan, andS.
Chakrabarti.
2009.
Collective annotation ofwikipedia entities in web text.
In KDD.Y.
Li, C. Wang, F. Han, J. Han, D. Roth, and X. Yan.2013.
Mining evidences for named entity dis-ambiguation.
In Proceedings of the 19th ACMSIGKDD International Conference on KnowledgeDiscovery and Data Mining, KDD ?13.389X.
Liu, Y. Li, H. Wu, M. Zhou, F. Wei, and Y. Lu.2013.
Entity linking for tweets.
In Proceedings ofthe 51st Annual Meeting of the Association for Com-putational Linguistics (Volume 1: Long Papers).P.
McNamee and H.T.
Dang.
2009.
Overview of thetac 2009 knowledge base population track.
In TextAnalysis Conference (TAC) 2009.E.
Meij, W. Weerkamp, and M. de Rijke.
2012.Adding semantics to microblog posts.
In Proceed-ings of the fifth ACM international conference onWeb search and data mining, WSDM ?12.R.
Mihalcea and A. Csomai.
2007.
Wikify!
: linkingdocuments to encyclopedic knowledge.
In Proceed-ings of the sixteenth ACM conference on Conferenceon information and knowledge management, CIKM?07.D.
Milne and I.H.
Witten.
2008a.
Learning to linkwith wikipedia.
In An effective, low-cost measure ofsemantic relatedness obtained from wikipedia links.the Wikipedia and AI Workshop of AAAI.D.
Milne and I.H.
Witten.
2008b.
Learning to linkwith wikipedia.
In Proceeding of the 17th ACM con-ference on Information and knowledge management,pages 509?518.
ACM.Z.
Niu, D. Ji, and C. Tan.
2005.
Word sense dis-ambiguation using label propagation based semi-supervised learning.
In Proceedings of the 43rd An-nual Meeting of the Association for ComputationalLinguistics (ACL?05).M.
Pennacchiotti and P. Pantel.
2009.
Entity extractionvia ensemble semantics.
In Proc.
EMNLP2009.W.
Radford, B. Hachey, J. Nothman, M. Honnibal, andJ.
R. Curran.
2010.
Cmcrc at tac10: Document-level entity linking with graph-based re-ranking.
InProc.
TAC 2010 Workshop.L.
Ratinov and D. Roth.
2012.
Learning-based multi-sieve co-reference resolution with knowledge.
InEMNLP.L.
Ratinov, D. Roth, D. Downey, and M. Anderson.2011.
Local and global algorithms for disambigua-tion to wikipedia.
In Proc.
of the Annual Meeting ofthe Association of Computational Linguistics (ACL).W.
Shen, J. Wang, P. Luo, and M. Wang.
2013.
Link-ing named entities in tweets with knowledge basevia user interest modeling.
In Proceedings of the19th ACM SIGKDD International Conference onKnowledge Discovery and Data Mining, KDD ?13.A.
Smola and R. Kondor.
2003.
Kernels and regular-ization on graphs.
COLT.Y.
Sun, R. Barber, M. Gupta, C. Aggarwal, and J. Han.2011a.
Co-author relationship prediction in hetero-geneous bibliographic networks.
In Proceedings ofthe 2011 International Conference on Advances inSocial Networks Analysis and Mining, ASONAM?11.Y.
Sun, J. Han, X. Yan, P. Yu, and T. Wu.
2011b.
Path-sim: Meta path-based top-k similarity search in het-erogeneous information networks.
PVLDB, 4(11).P.
Talukdar and K. Crammer.
2009.
New regularizedalgorithms for transductive learning.
In Proceed-ings of the European Conference on Machine Learn-ing and Knowledge Discovery in Databases: Part II,ECML PKDD ?09.D.
Vitale, P. Ferragina, and U. Scaiella.
2012.
Clas-sification of short texts by deploying topical annota-tions.
In ECIR, pages 376?387.K.
Wang, C. Thrasher, and B. Hsu.
2011.
Web scalenlp: A case study on url word breaking.
In Proceed-ings of the 20th International Conference on WorldWide Web, WWW ?11.W.
Zhang, J. Su, C. Tan, and W. Wang.
2010.
En-tity linking leveraging automatically generated an-notation.
In Proceedings of the 23rd InternationalConference on Computational Linguistics (Coling2010).W.
Zhang, J. Su, and C. L. Tan.
2011.
A wikipedia-ldamodel for entity linking with batch size changing.
InProc.
IJCNLP2011.D.
Zhou, O. Bousquet, T. Lal, J. Weston, andB.
Sch?olkopf.
2004.
Learning with local and globalconsistency.
In Advances in Neural InformationProcessing Systems 16.X.
Zhu, Z. Ghahramani, and J. Lafferty.
2003.
Semi-supervised learning using gaussian fields and har-monic functions.
In ICML.390
